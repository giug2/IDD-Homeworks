{
    "PAPER'S NUMBER OF TABLES": 17,
    "S6.T1": {
        "caption": "TABLE I: The default FL system parameter settings.",
        "table": "<table id=\"S6.T1.19\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S6.T1.19.20\" class=\"ltx_tr\">\n<td id=\"S6.T1.19.20.1\" class=\"ltx_td ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"></td>\n<td id=\"S6.T1.19.20.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Explanation</td>\n<td id=\"S6.T1.19.20.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">MNIST-0.1</td>\n<td id=\"S6.T1.19.20.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">MNIST-0.5</td>\n<td id=\"S6.T1.19.20.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Fashion-MNIST</td>\n<td id=\"S6.T1.19.20.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">CIFAR-10</td>\n<td id=\"S6.T1.19.20.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">HAR</td>\n<td id=\"S6.T1.19.20.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">CH-MNIST</td>\n</tr>\n<tr id=\"S6.T1.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><math id=\"S6.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"n\" display=\"inline\"><semantics id=\"S6.T1.1.1.1.m1.1a\"><mi id=\"S6.T1.1.1.1.m1.1.1\" xref=\"S6.T1.1.1.1.m1.1.1.cmml\">n</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.1.1.1.m1.1b\"><ci id=\"S6.T1.1.1.1.m1.1.1.cmml\" xref=\"S6.T1.1.1.1.m1.1.1\">ğ‘›</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.1.1.1.m1.1c\">n</annotation></semantics></math></td>\n<td id=\"S6.T1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"># clients</td>\n<td id=\"S6.T1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\" colspan=\"4\">100</td>\n<td id=\"S6.T1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">30</td>\n<td id=\"S6.T1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">40</td>\n</tr>\n<tr id=\"S6.T1.3.3\" class=\"ltx_tr\">\n<td id=\"S6.T1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><math id=\"S6.T1.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\tau\" display=\"inline\"><semantics id=\"S6.T1.2.2.1.m1.1a\"><mi id=\"S6.T1.2.2.1.m1.1.1\" xref=\"S6.T1.2.2.1.m1.1.1.cmml\">Ï„</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.2.2.1.m1.1b\"><ci id=\"S6.T1.2.2.1.m1.1.1.cmml\" xref=\"S6.T1.2.2.1.m1.1.1\">ğœ</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.2.2.1.m1.1c\">\\tau</annotation></semantics></math></td>\n<td id=\"S6.T1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"># clients selected in each iteration</td>\n<td id=\"S6.T1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\" colspan=\"6\"><math id=\"S6.T1.3.3.2.m1.1\" class=\"ltx_Math\" alttext=\"n\" display=\"inline\"><semantics id=\"S6.T1.3.3.2.m1.1a\"><mi id=\"S6.T1.3.3.2.m1.1.1\" xref=\"S6.T1.3.3.2.m1.1.1.cmml\">n</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.3.3.2.m1.1b\"><ci id=\"S6.T1.3.3.2.m1.1.1.cmml\" xref=\"S6.T1.3.3.2.m1.1.1\">ğ‘›</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.3.3.2.m1.1c\">n</annotation></semantics></math></td>\n</tr>\n<tr id=\"S6.T1.4.4\" class=\"ltx_tr\">\n<td id=\"S6.T1.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><math id=\"S6.T1.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"R_{l}\" display=\"inline\"><semantics id=\"S6.T1.4.4.1.m1.1a\"><msub id=\"S6.T1.4.4.1.m1.1.1\" xref=\"S6.T1.4.4.1.m1.1.1.cmml\"><mi id=\"S6.T1.4.4.1.m1.1.1.2\" xref=\"S6.T1.4.4.1.m1.1.1.2.cmml\">R</mi><mi id=\"S6.T1.4.4.1.m1.1.1.3\" xref=\"S6.T1.4.4.1.m1.1.1.3.cmml\">l</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.4.4.1.m1.1b\"><apply id=\"S6.T1.4.4.1.m1.1.1.cmml\" xref=\"S6.T1.4.4.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S6.T1.4.4.1.m1.1.1.1.cmml\" xref=\"S6.T1.4.4.1.m1.1.1\">subscript</csymbol><ci id=\"S6.T1.4.4.1.m1.1.1.2.cmml\" xref=\"S6.T1.4.4.1.m1.1.1.2\">ğ‘…</ci><ci id=\"S6.T1.4.4.1.m1.1.1.3.cmml\" xref=\"S6.T1.4.4.1.m1.1.1.3\">ğ‘™</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.4.4.1.m1.1c\">R_{l}</annotation></semantics></math></td>\n<td id=\"S6.T1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"># local iterations</td>\n<td id=\"S6.T1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\" colspan=\"6\">1</td>\n</tr>\n<tr id=\"S6.T1.5.5\" class=\"ltx_tr\">\n<td id=\"S6.T1.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><math id=\"S6.T1.5.5.1.m1.1\" class=\"ltx_Math\" alttext=\"R_{g}\" display=\"inline\"><semantics id=\"S6.T1.5.5.1.m1.1a\"><msub id=\"S6.T1.5.5.1.m1.1.1\" xref=\"S6.T1.5.5.1.m1.1.1.cmml\"><mi id=\"S6.T1.5.5.1.m1.1.1.2\" xref=\"S6.T1.5.5.1.m1.1.1.2.cmml\">R</mi><mi id=\"S6.T1.5.5.1.m1.1.1.3\" xref=\"S6.T1.5.5.1.m1.1.1.3.cmml\">g</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.5.5.1.m1.1b\"><apply id=\"S6.T1.5.5.1.m1.1.1.cmml\" xref=\"S6.T1.5.5.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S6.T1.5.5.1.m1.1.1.1.cmml\" xref=\"S6.T1.5.5.1.m1.1.1\">subscript</csymbol><ci id=\"S6.T1.5.5.1.m1.1.1.2.cmml\" xref=\"S6.T1.5.5.1.m1.1.1.2\">ğ‘…</ci><ci id=\"S6.T1.5.5.1.m1.1.1.3.cmml\" xref=\"S6.T1.5.5.1.m1.1.1.3\">ğ‘”</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.5.5.1.m1.1c\">R_{g}</annotation></semantics></math></td>\n<td id=\"S6.T1.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"># global iterations</td>\n<td id=\"S6.T1.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\" colspan=\"2\">2,000</td>\n<td id=\"S6.T1.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">2,500</td>\n<td id=\"S6.T1.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">1,500</td>\n<td id=\"S6.T1.5.5.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">1,000</td>\n<td id=\"S6.T1.5.5.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">2,000</td>\n</tr>\n<tr id=\"S6.T1.6.6\" class=\"ltx_tr\">\n<td id=\"S6.T1.6.6.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><math id=\"S6.T1.6.6.1.m1.1\" class=\"ltx_Math\" alttext=\"b\" display=\"inline\"><semantics id=\"S6.T1.6.6.1.m1.1a\"><mi id=\"S6.T1.6.6.1.m1.1.1\" xref=\"S6.T1.6.6.1.m1.1.1.cmml\">b</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.6.6.1.m1.1b\"><ci id=\"S6.T1.6.6.1.m1.1.1.cmml\" xref=\"S6.T1.6.6.1.m1.1.1\">ğ‘</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.6.6.1.m1.1c\">b</annotation></semantics></math></td>\n<td id=\"S6.T1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">batch size</td>\n<td id=\"S6.T1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\" colspan=\"3\">32</td>\n<td id=\"S6.T1.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">64</td>\n<td id=\"S6.T1.6.6.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\" colspan=\"2\">32</td>\n</tr>\n<tr id=\"S6.T1.12.12\" class=\"ltx_tr\">\n<td id=\"S6.T1.7.7.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><math id=\"S6.T1.7.7.1.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha\\cdot\\beta\" display=\"inline\"><semantics id=\"S6.T1.7.7.1.m1.1a\"><mrow id=\"S6.T1.7.7.1.m1.1.1\" xref=\"S6.T1.7.7.1.m1.1.1.cmml\"><mi id=\"S6.T1.7.7.1.m1.1.1.2\" xref=\"S6.T1.7.7.1.m1.1.1.2.cmml\">Î±</mi><mo lspace=\"0.222em\" rspace=\"0.222em\" id=\"S6.T1.7.7.1.m1.1.1.1\" xref=\"S6.T1.7.7.1.m1.1.1.1.cmml\">â‹…</mo><mi id=\"S6.T1.7.7.1.m1.1.1.3\" xref=\"S6.T1.7.7.1.m1.1.1.3.cmml\">Î²</mi></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.7.7.1.m1.1b\"><apply id=\"S6.T1.7.7.1.m1.1.1.cmml\" xref=\"S6.T1.7.7.1.m1.1.1\"><ci id=\"S6.T1.7.7.1.m1.1.1.1.cmml\" xref=\"S6.T1.7.7.1.m1.1.1.1\">â‹…</ci><ci id=\"S6.T1.7.7.1.m1.1.1.2.cmml\" xref=\"S6.T1.7.7.1.m1.1.1.2\">ğ›¼</ci><ci id=\"S6.T1.7.7.1.m1.1.1.3.cmml\" xref=\"S6.T1.7.7.1.m1.1.1.3\">ğ›½</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.7.7.1.m1.1c\">\\alpha\\cdot\\beta</annotation></semantics></math></td>\n<td id=\"S6.T1.12.12.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">combined learning rate</td>\n<td id=\"S6.T1.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\" colspan=\"2\"><math id=\"S6.T1.8.8.2.m1.1\" class=\"ltx_Math\" alttext=\"3\\times 10^{-4}\" display=\"inline\"><semantics id=\"S6.T1.8.8.2.m1.1a\"><mrow id=\"S6.T1.8.8.2.m1.1.1\" xref=\"S6.T1.8.8.2.m1.1.1.cmml\"><mn id=\"S6.T1.8.8.2.m1.1.1.2\" xref=\"S6.T1.8.8.2.m1.1.1.2.cmml\">3</mn><mo lspace=\"0.222em\" rspace=\"0.222em\" id=\"S6.T1.8.8.2.m1.1.1.1\" xref=\"S6.T1.8.8.2.m1.1.1.1.cmml\">Ã—</mo><msup id=\"S6.T1.8.8.2.m1.1.1.3\" xref=\"S6.T1.8.8.2.m1.1.1.3.cmml\"><mn id=\"S6.T1.8.8.2.m1.1.1.3.2\" xref=\"S6.T1.8.8.2.m1.1.1.3.2.cmml\">10</mn><mrow id=\"S6.T1.8.8.2.m1.1.1.3.3\" xref=\"S6.T1.8.8.2.m1.1.1.3.3.cmml\"><mo id=\"S6.T1.8.8.2.m1.1.1.3.3a\" xref=\"S6.T1.8.8.2.m1.1.1.3.3.cmml\">âˆ’</mo><mn id=\"S6.T1.8.8.2.m1.1.1.3.3.2\" xref=\"S6.T1.8.8.2.m1.1.1.3.3.2.cmml\">4</mn></mrow></msup></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.8.8.2.m1.1b\"><apply id=\"S6.T1.8.8.2.m1.1.1.cmml\" xref=\"S6.T1.8.8.2.m1.1.1\"><times id=\"S6.T1.8.8.2.m1.1.1.1.cmml\" xref=\"S6.T1.8.8.2.m1.1.1.1\"></times><cn type=\"integer\" id=\"S6.T1.8.8.2.m1.1.1.2.cmml\" xref=\"S6.T1.8.8.2.m1.1.1.2\">3</cn><apply id=\"S6.T1.8.8.2.m1.1.1.3.cmml\" xref=\"S6.T1.8.8.2.m1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S6.T1.8.8.2.m1.1.1.3.1.cmml\" xref=\"S6.T1.8.8.2.m1.1.1.3\">superscript</csymbol><cn type=\"integer\" id=\"S6.T1.8.8.2.m1.1.1.3.2.cmml\" xref=\"S6.T1.8.8.2.m1.1.1.3.2\">10</cn><apply id=\"S6.T1.8.8.2.m1.1.1.3.3.cmml\" xref=\"S6.T1.8.8.2.m1.1.1.3.3\"><minus id=\"S6.T1.8.8.2.m1.1.1.3.3.1.cmml\" xref=\"S6.T1.8.8.2.m1.1.1.3.3\"></minus><cn type=\"integer\" id=\"S6.T1.8.8.2.m1.1.1.3.3.2.cmml\" xref=\"S6.T1.8.8.2.m1.1.1.3.3.2\">4</cn></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.8.8.2.m1.1c\">3\\times 10^{-4}</annotation></semantics></math></td>\n<td id=\"S6.T1.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><math id=\"S6.T1.9.9.3.m1.1\" class=\"ltx_Math\" alttext=\"6\\times 10^{-3}\" display=\"inline\"><semantics id=\"S6.T1.9.9.3.m1.1a\"><mrow id=\"S6.T1.9.9.3.m1.1.1\" xref=\"S6.T1.9.9.3.m1.1.1.cmml\"><mn id=\"S6.T1.9.9.3.m1.1.1.2\" xref=\"S6.T1.9.9.3.m1.1.1.2.cmml\">6</mn><mo lspace=\"0.222em\" rspace=\"0.222em\" id=\"S6.T1.9.9.3.m1.1.1.1\" xref=\"S6.T1.9.9.3.m1.1.1.1.cmml\">Ã—</mo><msup id=\"S6.T1.9.9.3.m1.1.1.3\" xref=\"S6.T1.9.9.3.m1.1.1.3.cmml\"><mn id=\"S6.T1.9.9.3.m1.1.1.3.2\" xref=\"S6.T1.9.9.3.m1.1.1.3.2.cmml\">10</mn><mrow id=\"S6.T1.9.9.3.m1.1.1.3.3\" xref=\"S6.T1.9.9.3.m1.1.1.3.3.cmml\"><mo id=\"S6.T1.9.9.3.m1.1.1.3.3a\" xref=\"S6.T1.9.9.3.m1.1.1.3.3.cmml\">âˆ’</mo><mn id=\"S6.T1.9.9.3.m1.1.1.3.3.2\" xref=\"S6.T1.9.9.3.m1.1.1.3.3.2.cmml\">3</mn></mrow></msup></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.9.9.3.m1.1b\"><apply id=\"S6.T1.9.9.3.m1.1.1.cmml\" xref=\"S6.T1.9.9.3.m1.1.1\"><times id=\"S6.T1.9.9.3.m1.1.1.1.cmml\" xref=\"S6.T1.9.9.3.m1.1.1.1\"></times><cn type=\"integer\" id=\"S6.T1.9.9.3.m1.1.1.2.cmml\" xref=\"S6.T1.9.9.3.m1.1.1.2\">6</cn><apply id=\"S6.T1.9.9.3.m1.1.1.3.cmml\" xref=\"S6.T1.9.9.3.m1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S6.T1.9.9.3.m1.1.1.3.1.cmml\" xref=\"S6.T1.9.9.3.m1.1.1.3\">superscript</csymbol><cn type=\"integer\" id=\"S6.T1.9.9.3.m1.1.1.3.2.cmml\" xref=\"S6.T1.9.9.3.m1.1.1.3.2\">10</cn><apply id=\"S6.T1.9.9.3.m1.1.1.3.3.cmml\" xref=\"S6.T1.9.9.3.m1.1.1.3.3\"><minus id=\"S6.T1.9.9.3.m1.1.1.3.3.1.cmml\" xref=\"S6.T1.9.9.3.m1.1.1.3.3\"></minus><cn type=\"integer\" id=\"S6.T1.9.9.3.m1.1.1.3.3.2.cmml\" xref=\"S6.T1.9.9.3.m1.1.1.3.3.2\">3</cn></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.9.9.3.m1.1c\">6\\times 10^{-3}</annotation></semantics></math></td>\n<td id=\"S6.T1.10.10.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><math id=\"S6.T1.10.10.4.m1.1\" class=\"ltx_Math\" alttext=\"2\\times 10^{-4}\" display=\"inline\"><semantics id=\"S6.T1.10.10.4.m1.1a\"><mrow id=\"S6.T1.10.10.4.m1.1.1\" xref=\"S6.T1.10.10.4.m1.1.1.cmml\"><mn id=\"S6.T1.10.10.4.m1.1.1.2\" xref=\"S6.T1.10.10.4.m1.1.1.2.cmml\">2</mn><mo lspace=\"0.222em\" rspace=\"0.222em\" id=\"S6.T1.10.10.4.m1.1.1.1\" xref=\"S6.T1.10.10.4.m1.1.1.1.cmml\">Ã—</mo><msup id=\"S6.T1.10.10.4.m1.1.1.3\" xref=\"S6.T1.10.10.4.m1.1.1.3.cmml\"><mn id=\"S6.T1.10.10.4.m1.1.1.3.2\" xref=\"S6.T1.10.10.4.m1.1.1.3.2.cmml\">10</mn><mrow id=\"S6.T1.10.10.4.m1.1.1.3.3\" xref=\"S6.T1.10.10.4.m1.1.1.3.3.cmml\"><mo id=\"S6.T1.10.10.4.m1.1.1.3.3a\" xref=\"S6.T1.10.10.4.m1.1.1.3.3.cmml\">âˆ’</mo><mn id=\"S6.T1.10.10.4.m1.1.1.3.3.2\" xref=\"S6.T1.10.10.4.m1.1.1.3.3.2.cmml\">4</mn></mrow></msup></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.10.10.4.m1.1b\"><apply id=\"S6.T1.10.10.4.m1.1.1.cmml\" xref=\"S6.T1.10.10.4.m1.1.1\"><times id=\"S6.T1.10.10.4.m1.1.1.1.cmml\" xref=\"S6.T1.10.10.4.m1.1.1.1\"></times><cn type=\"integer\" id=\"S6.T1.10.10.4.m1.1.1.2.cmml\" xref=\"S6.T1.10.10.4.m1.1.1.2\">2</cn><apply id=\"S6.T1.10.10.4.m1.1.1.3.cmml\" xref=\"S6.T1.10.10.4.m1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S6.T1.10.10.4.m1.1.1.3.1.cmml\" xref=\"S6.T1.10.10.4.m1.1.1.3\">superscript</csymbol><cn type=\"integer\" id=\"S6.T1.10.10.4.m1.1.1.3.2.cmml\" xref=\"S6.T1.10.10.4.m1.1.1.3.2\">10</cn><apply id=\"S6.T1.10.10.4.m1.1.1.3.3.cmml\" xref=\"S6.T1.10.10.4.m1.1.1.3.3\"><minus id=\"S6.T1.10.10.4.m1.1.1.3.3.1.cmml\" xref=\"S6.T1.10.10.4.m1.1.1.3.3\"></minus><cn type=\"integer\" id=\"S6.T1.10.10.4.m1.1.1.3.3.2.cmml\" xref=\"S6.T1.10.10.4.m1.1.1.3.3.2\">4</cn></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.10.10.4.m1.1c\">2\\times 10^{-4}</annotation></semantics></math></td>\n<td id=\"S6.T1.11.11.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><math id=\"S6.T1.11.11.5.m1.1\" class=\"ltx_Math\" alttext=\"3\\times 10^{-3}\" display=\"inline\"><semantics id=\"S6.T1.11.11.5.m1.1a\"><mrow id=\"S6.T1.11.11.5.m1.1.1\" xref=\"S6.T1.11.11.5.m1.1.1.cmml\"><mn id=\"S6.T1.11.11.5.m1.1.1.2\" xref=\"S6.T1.11.11.5.m1.1.1.2.cmml\">3</mn><mo lspace=\"0.222em\" rspace=\"0.222em\" id=\"S6.T1.11.11.5.m1.1.1.1\" xref=\"S6.T1.11.11.5.m1.1.1.1.cmml\">Ã—</mo><msup id=\"S6.T1.11.11.5.m1.1.1.3\" xref=\"S6.T1.11.11.5.m1.1.1.3.cmml\"><mn id=\"S6.T1.11.11.5.m1.1.1.3.2\" xref=\"S6.T1.11.11.5.m1.1.1.3.2.cmml\">10</mn><mrow id=\"S6.T1.11.11.5.m1.1.1.3.3\" xref=\"S6.T1.11.11.5.m1.1.1.3.3.cmml\"><mo id=\"S6.T1.11.11.5.m1.1.1.3.3a\" xref=\"S6.T1.11.11.5.m1.1.1.3.3.cmml\">âˆ’</mo><mn id=\"S6.T1.11.11.5.m1.1.1.3.3.2\" xref=\"S6.T1.11.11.5.m1.1.1.3.3.2.cmml\">3</mn></mrow></msup></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.11.11.5.m1.1b\"><apply id=\"S6.T1.11.11.5.m1.1.1.cmml\" xref=\"S6.T1.11.11.5.m1.1.1\"><times id=\"S6.T1.11.11.5.m1.1.1.1.cmml\" xref=\"S6.T1.11.11.5.m1.1.1.1\"></times><cn type=\"integer\" id=\"S6.T1.11.11.5.m1.1.1.2.cmml\" xref=\"S6.T1.11.11.5.m1.1.1.2\">3</cn><apply id=\"S6.T1.11.11.5.m1.1.1.3.cmml\" xref=\"S6.T1.11.11.5.m1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S6.T1.11.11.5.m1.1.1.3.1.cmml\" xref=\"S6.T1.11.11.5.m1.1.1.3\">superscript</csymbol><cn type=\"integer\" id=\"S6.T1.11.11.5.m1.1.1.3.2.cmml\" xref=\"S6.T1.11.11.5.m1.1.1.3.2\">10</cn><apply id=\"S6.T1.11.11.5.m1.1.1.3.3.cmml\" xref=\"S6.T1.11.11.5.m1.1.1.3.3\"><minus id=\"S6.T1.11.11.5.m1.1.1.3.3.1.cmml\" xref=\"S6.T1.11.11.5.m1.1.1.3.3\"></minus><cn type=\"integer\" id=\"S6.T1.11.11.5.m1.1.1.3.3.2.cmml\" xref=\"S6.T1.11.11.5.m1.1.1.3.3.2\">3</cn></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.11.11.5.m1.1c\">3\\times 10^{-3}</annotation></semantics></math></td>\n<td id=\"S6.T1.12.12.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">\n<span id=\"S6.T1.12.12.6.2\" class=\"ltx_text\"></span> <span id=\"S6.T1.12.12.6.1\" class=\"ltx_text\">\n<span id=\"S6.T1.12.12.6.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S6.T1.12.12.6.1.1.1\" class=\"ltx_tr\">\n<span id=\"S6.T1.12.12.6.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><math id=\"S6.T1.12.12.6.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"3\\times 10^{-4}\" display=\"inline\"><semantics id=\"S6.T1.12.12.6.1.1.1.1.m1.1a\"><mrow id=\"S6.T1.12.12.6.1.1.1.1.m1.1.1\" xref=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.cmml\"><mn id=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.2\" xref=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.2.cmml\">3</mn><mo lspace=\"0.222em\" rspace=\"0.222em\" id=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.1\" xref=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.1.cmml\">Ã—</mo><msup id=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.3\" xref=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.3.cmml\"><mn id=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.3.2\" xref=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.3.2.cmml\">10</mn><mrow id=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.3.3\" xref=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.3.3.cmml\"><mo id=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.3.3a\" xref=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.3.3.cmml\">âˆ’</mo><mn id=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.3.3.2\" xref=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.3.3.2.cmml\">4</mn></mrow></msup></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.12.12.6.1.1.1.1.m1.1b\"><apply id=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.cmml\" xref=\"S6.T1.12.12.6.1.1.1.1.m1.1.1\"><times id=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.1.cmml\" xref=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.1\"></times><cn type=\"integer\" id=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.2.cmml\" xref=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.2\">3</cn><apply id=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.3.cmml\" xref=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.3.1.cmml\" xref=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.3\">superscript</csymbol><cn type=\"integer\" id=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.3.2.cmml\" xref=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.3.2\">10</cn><apply id=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.3.3.cmml\" xref=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.3.3\"><minus id=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.3.3.1.cmml\" xref=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.3.3\"></minus><cn type=\"integer\" id=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.3.3.2.cmml\" xref=\"S6.T1.12.12.6.1.1.1.1.m1.1.1.3.3.2\">4</cn></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.12.12.6.1.1.1.1.m1.1c\">3\\times 10^{-4}</annotation></semantics></math> (decay at the 1500th and</span></span>\n<span id=\"S6.T1.12.12.6.1.1.2\" class=\"ltx_tr\">\n<span id=\"S6.T1.12.12.6.1.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">1750th iterations with factor 0.9)</span></span>\n</span></span><span id=\"S6.T1.12.12.6.3\" class=\"ltx_text\"></span>\n</td>\n</tr>\n<tr id=\"S6.T1.13.13\" class=\"ltx_tr\">\n<td id=\"S6.T1.13.13.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><math id=\"S6.T1.13.13.1.m1.1\" class=\"ltx_Math\" alttext=\"m/n\" display=\"inline\"><semantics id=\"S6.T1.13.13.1.m1.1a\"><mrow id=\"S6.T1.13.13.1.m1.1.1\" xref=\"S6.T1.13.13.1.m1.1.1.cmml\"><mi id=\"S6.T1.13.13.1.m1.1.1.2\" xref=\"S6.T1.13.13.1.m1.1.1.2.cmml\">m</mi><mo id=\"S6.T1.13.13.1.m1.1.1.1\" xref=\"S6.T1.13.13.1.m1.1.1.1.cmml\">/</mo><mi id=\"S6.T1.13.13.1.m1.1.1.3\" xref=\"S6.T1.13.13.1.m1.1.1.3.cmml\">n</mi></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.13.13.1.m1.1b\"><apply id=\"S6.T1.13.13.1.m1.1.1.cmml\" xref=\"S6.T1.13.13.1.m1.1.1\"><divide id=\"S6.T1.13.13.1.m1.1.1.1.cmml\" xref=\"S6.T1.13.13.1.m1.1.1.1\"></divide><ci id=\"S6.T1.13.13.1.m1.1.1.2.cmml\" xref=\"S6.T1.13.13.1.m1.1.1.2\">ğ‘š</ci><ci id=\"S6.T1.13.13.1.m1.1.1.3.cmml\" xref=\"S6.T1.13.13.1.m1.1.1.3\">ğ‘›</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.13.13.1.m1.1c\">m/n</annotation></semantics></math></td>\n<td id=\"S6.T1.13.13.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">fraction of malicious clients (%)</td>\n<td id=\"S6.T1.13.13.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\" colspan=\"6\">20</td>\n</tr>\n<tr id=\"S6.T1.14.14\" class=\"ltx_tr\">\n<td id=\"S6.T1.14.14.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><math id=\"S6.T1.14.14.1.m1.1\" class=\"ltx_Math\" alttext=\"m\" display=\"inline\"><semantics id=\"S6.T1.14.14.1.m1.1a\"><mi id=\"S6.T1.14.14.1.m1.1.1\" xref=\"S6.T1.14.14.1.m1.1.1.cmml\">m</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.14.14.1.m1.1b\"><ci id=\"S6.T1.14.14.1.m1.1.1.cmml\" xref=\"S6.T1.14.14.1.m1.1.1\">ğ‘š</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.14.14.1.m1.1c\">m</annotation></semantics></math></td>\n<td id=\"S6.T1.14.14.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"># malicious clients</td>\n<td id=\"S6.T1.14.14.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\" colspan=\"4\">20</td>\n<td id=\"S6.T1.14.14.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">6</td>\n<td id=\"S6.T1.14.14.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">8</td>\n</tr>\n<tr id=\"S6.T1.16.16\" class=\"ltx_tr\">\n<td id=\"S6.T1.15.15.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><math id=\"S6.T1.15.15.1.m1.1\" class=\"ltx_Math\" alttext=\"f\" display=\"inline\"><semantics id=\"S6.T1.15.15.1.m1.1a\"><mi id=\"S6.T1.15.15.1.m1.1.1\" xref=\"S6.T1.15.15.1.m1.1.1.cmml\">f</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.15.15.1.m1.1b\"><ci id=\"S6.T1.15.15.1.m1.1.1.cmml\" xref=\"S6.T1.15.15.1.m1.1.1\">ğ‘“</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.15.15.1.m1.1c\">f</annotation></semantics></math></td>\n<td id=\"S6.T1.16.16.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Krum parameter</td>\n<td id=\"S6.T1.16.16.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\" colspan=\"6\"><math id=\"S6.T1.16.16.2.m1.1\" class=\"ltx_Math\" alttext=\"m\" display=\"inline\"><semantics id=\"S6.T1.16.16.2.m1.1a\"><mi id=\"S6.T1.16.16.2.m1.1.1\" xref=\"S6.T1.16.16.2.m1.1.1.cmml\">m</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.16.16.2.m1.1b\"><ci id=\"S6.T1.16.16.2.m1.1.1.cmml\" xref=\"S6.T1.16.16.2.m1.1.1\">ğ‘š</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.16.16.2.m1.1c\">m</annotation></semantics></math></td>\n</tr>\n<tr id=\"S6.T1.18.18\" class=\"ltx_tr\">\n<td id=\"S6.T1.17.17.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><math id=\"S6.T1.17.17.1.m1.1\" class=\"ltx_Math\" alttext=\"k\" display=\"inline\"><semantics id=\"S6.T1.17.17.1.m1.1a\"><mi id=\"S6.T1.17.17.1.m1.1.1\" xref=\"S6.T1.17.17.1.m1.1.1.cmml\">k</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.17.17.1.m1.1b\"><ci id=\"S6.T1.17.17.1.m1.1.1.cmml\" xref=\"S6.T1.17.17.1.m1.1.1\">ğ‘˜</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.17.17.1.m1.1c\">k</annotation></semantics></math></td>\n<td id=\"S6.T1.18.18.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">Trim-mean parameter</td>\n<td id=\"S6.T1.18.18.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\" colspan=\"6\"><math id=\"S6.T1.18.18.2.m1.1\" class=\"ltx_Math\" alttext=\"m\" display=\"inline\"><semantics id=\"S6.T1.18.18.2.m1.1a\"><mi id=\"S6.T1.18.18.2.m1.1.1\" xref=\"S6.T1.18.18.2.m1.1.1.cmml\">m</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.18.18.2.m1.1b\"><ci id=\"S6.T1.18.18.2.m1.1.1.cmml\" xref=\"S6.T1.18.18.2.m1.1.1\">ğ‘š</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.18.18.2.m1.1c\">m</annotation></semantics></math></td>\n</tr>\n<tr id=\"S6.T1.19.19\" class=\"ltx_tr\">\n<td id=\"S6.T1.19.19.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\"><math id=\"S6.T1.19.19.1.m1.1\" class=\"ltx_Math\" alttext=\"|D_{0}|\" display=\"inline\"><semantics id=\"S6.T1.19.19.1.m1.1a\"><mrow id=\"S6.T1.19.19.1.m1.1.1.1\" xref=\"S6.T1.19.19.1.m1.1.1.2.cmml\"><mo stretchy=\"false\" id=\"S6.T1.19.19.1.m1.1.1.1.2\" xref=\"S6.T1.19.19.1.m1.1.1.2.1.cmml\">|</mo><msub id=\"S6.T1.19.19.1.m1.1.1.1.1\" xref=\"S6.T1.19.19.1.m1.1.1.1.1.cmml\"><mi id=\"S6.T1.19.19.1.m1.1.1.1.1.2\" xref=\"S6.T1.19.19.1.m1.1.1.1.1.2.cmml\">D</mi><mn id=\"S6.T1.19.19.1.m1.1.1.1.1.3\" xref=\"S6.T1.19.19.1.m1.1.1.1.1.3.cmml\">0</mn></msub><mo stretchy=\"false\" id=\"S6.T1.19.19.1.m1.1.1.1.3\" xref=\"S6.T1.19.19.1.m1.1.1.2.1.cmml\">|</mo></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.19.19.1.m1.1b\"><apply id=\"S6.T1.19.19.1.m1.1.1.2.cmml\" xref=\"S6.T1.19.19.1.m1.1.1.1\"><abs id=\"S6.T1.19.19.1.m1.1.1.2.1.cmml\" xref=\"S6.T1.19.19.1.m1.1.1.1.2\"></abs><apply id=\"S6.T1.19.19.1.m1.1.1.1.1.cmml\" xref=\"S6.T1.19.19.1.m1.1.1.1.1\"><csymbol cd=\"ambiguous\" id=\"S6.T1.19.19.1.m1.1.1.1.1.1.cmml\" xref=\"S6.T1.19.19.1.m1.1.1.1.1\">subscript</csymbol><ci id=\"S6.T1.19.19.1.m1.1.1.1.1.2.cmml\" xref=\"S6.T1.19.19.1.m1.1.1.1.1.2\">ğ·</ci><cn type=\"integer\" id=\"S6.T1.19.19.1.m1.1.1.1.1.3.cmml\" xref=\"S6.T1.19.19.1.m1.1.1.1.1.3\">0</cn></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.19.19.1.m1.1c\">|D_{0}|</annotation></semantics></math></td>\n<td id=\"S6.T1.19.19.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\">size of the root dataset</td>\n<td id=\"S6.T1.19.19.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:3.0pt;padding-right:3.0pt;\" colspan=\"6\">100</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "By default, we assume there are n=100ğ‘›100n=100 clients in total for each dataset except HAR and CH-MNIST. For HAR, the data are collected from 30 users, each of which is treated as a client. Therefore, HAR has 30 clients in total. For CH-MNIST, there are only 4,000 training examples in total and thus we assume 40 clients such that each client has 100 training examples on average. Unless otherwise mentioned, we assume 20% of the clients are malicious for each dataset. However, we will also explore the impact of the fraction of malicious clients. Table I shows the default FL system settings that we will use unless otherwise mentioned."
        ]
    },
    "S6.T2": {
        "caption": "TABLE II: The CNN architecture of the global model used for MNIST-0.1, MNIST-0.5, and Fashion-MNIST.",
        "table": "<table id=\"S6.T2.5\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S6.T2.5.6\" class=\"ltx_tr\">\n<td id=\"S6.T2.5.6.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Layer</td>\n<td id=\"S6.T2.5.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Size</td>\n</tr>\n<tr id=\"S6.T2.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T2.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Input</td>\n<td id=\"S6.T2.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<math id=\"S6.T2.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"28\\times 28\\times 1\" display=\"inline\"><semantics id=\"S6.T2.1.1.1.m1.1a\"><mrow id=\"S6.T2.1.1.1.m1.1.1\" xref=\"S6.T2.1.1.1.m1.1.1.cmml\"><mn id=\"S6.T2.1.1.1.m1.1.1.2\" xref=\"S6.T2.1.1.1.m1.1.1.2.cmml\">28</mn><mo lspace=\"0.222em\" rspace=\"0.222em\" id=\"S6.T2.1.1.1.m1.1.1.1\" xref=\"S6.T2.1.1.1.m1.1.1.1.cmml\">Ã—</mo><mn id=\"S6.T2.1.1.1.m1.1.1.3\" xref=\"S6.T2.1.1.1.m1.1.1.3.cmml\">28</mn><mo lspace=\"0.222em\" rspace=\"0.222em\" id=\"S6.T2.1.1.1.m1.1.1.1a\" xref=\"S6.T2.1.1.1.m1.1.1.1.cmml\">Ã—</mo><mn id=\"S6.T2.1.1.1.m1.1.1.4\" xref=\"S6.T2.1.1.1.m1.1.1.4.cmml\">1</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T2.1.1.1.m1.1b\"><apply id=\"S6.T2.1.1.1.m1.1.1.cmml\" xref=\"S6.T2.1.1.1.m1.1.1\"><times id=\"S6.T2.1.1.1.m1.1.1.1.cmml\" xref=\"S6.T2.1.1.1.m1.1.1.1\"></times><cn type=\"integer\" id=\"S6.T2.1.1.1.m1.1.1.2.cmml\" xref=\"S6.T2.1.1.1.m1.1.1.2\">28</cn><cn type=\"integer\" id=\"S6.T2.1.1.1.m1.1.1.3.cmml\" xref=\"S6.T2.1.1.1.m1.1.1.3\">28</cn><cn type=\"integer\" id=\"S6.T2.1.1.1.m1.1.1.4.cmml\" xref=\"S6.T2.1.1.1.m1.1.1.4\">1</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T2.1.1.1.m1.1c\">28\\times 28\\times 1</annotation></semantics></math>\n</td>\n</tr>\n<tr id=\"S6.T2.2.2\" class=\"ltx_tr\">\n<td id=\"S6.T2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Convolution + ReLU</td>\n<td id=\"S6.T2.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<math id=\"S6.T2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"3\\times 3\\times 30\" display=\"inline\"><semantics id=\"S6.T2.2.2.1.m1.1a\"><mrow id=\"S6.T2.2.2.1.m1.1.1\" xref=\"S6.T2.2.2.1.m1.1.1.cmml\"><mn id=\"S6.T2.2.2.1.m1.1.1.2\" xref=\"S6.T2.2.2.1.m1.1.1.2.cmml\">3</mn><mo lspace=\"0.222em\" rspace=\"0.222em\" id=\"S6.T2.2.2.1.m1.1.1.1\" xref=\"S6.T2.2.2.1.m1.1.1.1.cmml\">Ã—</mo><mn id=\"S6.T2.2.2.1.m1.1.1.3\" xref=\"S6.T2.2.2.1.m1.1.1.3.cmml\">3</mn><mo lspace=\"0.222em\" rspace=\"0.222em\" id=\"S6.T2.2.2.1.m1.1.1.1a\" xref=\"S6.T2.2.2.1.m1.1.1.1.cmml\">Ã—</mo><mn id=\"S6.T2.2.2.1.m1.1.1.4\" xref=\"S6.T2.2.2.1.m1.1.1.4.cmml\">30</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T2.2.2.1.m1.1b\"><apply id=\"S6.T2.2.2.1.m1.1.1.cmml\" xref=\"S6.T2.2.2.1.m1.1.1\"><times id=\"S6.T2.2.2.1.m1.1.1.1.cmml\" xref=\"S6.T2.2.2.1.m1.1.1.1\"></times><cn type=\"integer\" id=\"S6.T2.2.2.1.m1.1.1.2.cmml\" xref=\"S6.T2.2.2.1.m1.1.1.2\">3</cn><cn type=\"integer\" id=\"S6.T2.2.2.1.m1.1.1.3.cmml\" xref=\"S6.T2.2.2.1.m1.1.1.3\">3</cn><cn type=\"integer\" id=\"S6.T2.2.2.1.m1.1.1.4.cmml\" xref=\"S6.T2.2.2.1.m1.1.1.4\">30</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T2.2.2.1.m1.1c\">3\\times 3\\times 30</annotation></semantics></math>\n</td>\n</tr>\n<tr id=\"S6.T2.3.3\" class=\"ltx_tr\">\n<td id=\"S6.T2.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Max Pooling</td>\n<td id=\"S6.T2.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<math id=\"S6.T2.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"2\\times 2\" display=\"inline\"><semantics id=\"S6.T2.3.3.1.m1.1a\"><mrow id=\"S6.T2.3.3.1.m1.1.1\" xref=\"S6.T2.3.3.1.m1.1.1.cmml\"><mn id=\"S6.T2.3.3.1.m1.1.1.2\" xref=\"S6.T2.3.3.1.m1.1.1.2.cmml\">2</mn><mo lspace=\"0.222em\" rspace=\"0.222em\" id=\"S6.T2.3.3.1.m1.1.1.1\" xref=\"S6.T2.3.3.1.m1.1.1.1.cmml\">Ã—</mo><mn id=\"S6.T2.3.3.1.m1.1.1.3\" xref=\"S6.T2.3.3.1.m1.1.1.3.cmml\">2</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T2.3.3.1.m1.1b\"><apply id=\"S6.T2.3.3.1.m1.1.1.cmml\" xref=\"S6.T2.3.3.1.m1.1.1\"><times id=\"S6.T2.3.3.1.m1.1.1.1.cmml\" xref=\"S6.T2.3.3.1.m1.1.1.1\"></times><cn type=\"integer\" id=\"S6.T2.3.3.1.m1.1.1.2.cmml\" xref=\"S6.T2.3.3.1.m1.1.1.2\">2</cn><cn type=\"integer\" id=\"S6.T2.3.3.1.m1.1.1.3.cmml\" xref=\"S6.T2.3.3.1.m1.1.1.3\">2</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T2.3.3.1.m1.1c\">2\\times 2</annotation></semantics></math>\n</td>\n</tr>\n<tr id=\"S6.T2.4.4\" class=\"ltx_tr\">\n<td id=\"S6.T2.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Convolution + ReLU</td>\n<td id=\"S6.T2.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<math id=\"S6.T2.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"3\\times 3\\times 50\" display=\"inline\"><semantics id=\"S6.T2.4.4.1.m1.1a\"><mrow id=\"S6.T2.4.4.1.m1.1.1\" xref=\"S6.T2.4.4.1.m1.1.1.cmml\"><mn id=\"S6.T2.4.4.1.m1.1.1.2\" xref=\"S6.T2.4.4.1.m1.1.1.2.cmml\">3</mn><mo lspace=\"0.222em\" rspace=\"0.222em\" id=\"S6.T2.4.4.1.m1.1.1.1\" xref=\"S6.T2.4.4.1.m1.1.1.1.cmml\">Ã—</mo><mn id=\"S6.T2.4.4.1.m1.1.1.3\" xref=\"S6.T2.4.4.1.m1.1.1.3.cmml\">3</mn><mo lspace=\"0.222em\" rspace=\"0.222em\" id=\"S6.T2.4.4.1.m1.1.1.1a\" xref=\"S6.T2.4.4.1.m1.1.1.1.cmml\">Ã—</mo><mn id=\"S6.T2.4.4.1.m1.1.1.4\" xref=\"S6.T2.4.4.1.m1.1.1.4.cmml\">50</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T2.4.4.1.m1.1b\"><apply id=\"S6.T2.4.4.1.m1.1.1.cmml\" xref=\"S6.T2.4.4.1.m1.1.1\"><times id=\"S6.T2.4.4.1.m1.1.1.1.cmml\" xref=\"S6.T2.4.4.1.m1.1.1.1\"></times><cn type=\"integer\" id=\"S6.T2.4.4.1.m1.1.1.2.cmml\" xref=\"S6.T2.4.4.1.m1.1.1.2\">3</cn><cn type=\"integer\" id=\"S6.T2.4.4.1.m1.1.1.3.cmml\" xref=\"S6.T2.4.4.1.m1.1.1.3\">3</cn><cn type=\"integer\" id=\"S6.T2.4.4.1.m1.1.1.4.cmml\" xref=\"S6.T2.4.4.1.m1.1.1.4\">50</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T2.4.4.1.m1.1c\">3\\times 3\\times 50</annotation></semantics></math>\n</td>\n</tr>\n<tr id=\"S6.T2.5.5\" class=\"ltx_tr\">\n<td id=\"S6.T2.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Max Pooling</td>\n<td id=\"S6.T2.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<math id=\"S6.T2.5.5.1.m1.1\" class=\"ltx_Math\" alttext=\"2\\times 2\" display=\"inline\"><semantics id=\"S6.T2.5.5.1.m1.1a\"><mrow id=\"S6.T2.5.5.1.m1.1.1\" xref=\"S6.T2.5.5.1.m1.1.1.cmml\"><mn id=\"S6.T2.5.5.1.m1.1.1.2\" xref=\"S6.T2.5.5.1.m1.1.1.2.cmml\">2</mn><mo lspace=\"0.222em\" rspace=\"0.222em\" id=\"S6.T2.5.5.1.m1.1.1.1\" xref=\"S6.T2.5.5.1.m1.1.1.1.cmml\">Ã—</mo><mn id=\"S6.T2.5.5.1.m1.1.1.3\" xref=\"S6.T2.5.5.1.m1.1.1.3.cmml\">2</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T2.5.5.1.m1.1b\"><apply id=\"S6.T2.5.5.1.m1.1.1.cmml\" xref=\"S6.T2.5.5.1.m1.1.1\"><times id=\"S6.T2.5.5.1.m1.1.1.1.cmml\" xref=\"S6.T2.5.5.1.m1.1.1.1\"></times><cn type=\"integer\" id=\"S6.T2.5.5.1.m1.1.1.2.cmml\" xref=\"S6.T2.5.5.1.m1.1.1.2\">2</cn><cn type=\"integer\" id=\"S6.T2.5.5.1.m1.1.1.3.cmml\" xref=\"S6.T2.5.5.1.m1.1.1.3\">2</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T2.5.5.1.m1.1c\">2\\times 2</annotation></semantics></math>\n</td>\n</tr>\n<tr id=\"S6.T2.5.7\" class=\"ltx_tr\">\n<td id=\"S6.T2.5.7.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Fully Connected + ReLU</td>\n<td id=\"S6.T2.5.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">100</td>\n</tr>\n<tr id=\"S6.T2.5.8\" class=\"ltx_tr\">\n<td id=\"S6.T2.5.8.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">Softmax</td>\n<td id=\"S6.T2.5.8.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">10</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Global models:Â  We train different types of global models on different datasets to show the generality of our method. Specifically, for MNIST-0.1, MNIST-0.5, and Fashion-MNIST, we train a convolutional neural network (CNN) as the global model. Table II shows the architecture of the CNN. And we train a logistic regression (LR) classifier as the global model for HAR. For CIFAR-10 and CH-MNIST, we consider the widely used ResNet20 architecture [19] as the global model."
        ]
    },
    "S6.T3": {
        "caption": "TABLE III: The testing error rates of different FL methods under different attacks and the attack success rates of the Scaling attacks. The results for the Scaling attacks are in the form of â€œtesting error rate / attack success rateâ€.",
        "table": "<table id=\"S6.T3.sf1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S6.T3.sf1.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf1.1.1.1\" class=\"ltx_td ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n<td id=\"S6.T3.sf1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">FedAvg</td>\n<td id=\"S6.T3.sf1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Krum</td>\n<td id=\"S6.T3.sf1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Trim-mean</td>\n<td id=\"S6.T3.sf1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Median</td>\n<td id=\"S6.T3.sf1.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">FLTrust</td>\n</tr>\n<tr id=\"S6.T3.sf1.1.2\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf1.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">No attack</td>\n<td id=\"S6.T3.sf1.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.04</td>\n<td id=\"S6.T3.sf1.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.10</td>\n<td id=\"S6.T3.sf1.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.06</td>\n<td id=\"S6.T3.sf1.1.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.06</td>\n<td id=\"S6.T3.sf1.1.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.04</td>\n</tr>\n<tr id=\"S6.T3.sf1.1.3\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf1.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">LF attack</td>\n<td id=\"S6.T3.sf1.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.06</td>\n<td id=\"S6.T3.sf1.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.10</td>\n<td id=\"S6.T3.sf1.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.05</td>\n<td id=\"S6.T3.sf1.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.05</td>\n<td id=\"S6.T3.sf1.1.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.04</td>\n</tr>\n<tr id=\"S6.T3.sf1.1.4\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf1.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Krum attack</td>\n<td id=\"S6.T3.sf1.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.10</td>\n<td id=\"S6.T3.sf1.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.90</td>\n<td id=\"S6.T3.sf1.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.07</td>\n<td id=\"S6.T3.sf1.1.4.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.07</td>\n<td id=\"S6.T3.sf1.1.4.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.04</td>\n</tr>\n<tr id=\"S6.T3.sf1.1.5\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf1.1.5.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Trim attack</td>\n<td id=\"S6.T3.sf1.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.16</td>\n<td id=\"S6.T3.sf1.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.10</td>\n<td id=\"S6.T3.sf1.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.13</td>\n<td id=\"S6.T3.sf1.1.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.13</td>\n<td id=\"S6.T3.sf1.1.5.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.04</td>\n</tr>\n<tr id=\"S6.T3.sf1.1.6\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf1.1.6.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Scaling attack</td>\n<td id=\"S6.T3.sf1.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.02 / 1.00</td>\n<td id=\"S6.T3.sf1.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.10 / 0.00</td>\n<td id=\"S6.T3.sf1.1.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.05 / 0.01</td>\n<td id=\"S6.T3.sf1.1.6.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.05 / 0.01</td>\n<td id=\"S6.T3.sf1.1.6.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.03 / 0.00</td>\n</tr>\n<tr id=\"S6.T3.sf1.1.7\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf1.1.7.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Adaptive attack</td>\n<td id=\"S6.T3.sf1.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.08</td>\n<td id=\"S6.T3.sf1.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.10</td>\n<td id=\"S6.T3.sf1.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.11</td>\n<td id=\"S6.T3.sf1.1.7.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.13</td>\n<td id=\"S6.T3.sf1.1.7.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.04</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Our FLTrust achieves the three defense goals:Â  Recall that we have three defense goals (discussed in SectionÂ III): fidelity, robustness, and efficiency. Table IIIf shows the testing error rates of different FL methods under different attacks including our adaptive attack, as well as the attack success rate of the Scaling attack on the six datasets. Our results show that FLTrust achieves the three goals."
        ]
    },
    "S6.T3.sf1": {
        "caption": "(a) CNN global model, MNIST-0.1",
        "table": "<table id=\"S6.T3.sf1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S6.T3.sf1.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf1.1.1.1\" class=\"ltx_td ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n<td id=\"S6.T3.sf1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">FedAvg</td>\n<td id=\"S6.T3.sf1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Krum</td>\n<td id=\"S6.T3.sf1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Trim-mean</td>\n<td id=\"S6.T3.sf1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Median</td>\n<td id=\"S6.T3.sf1.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">FLTrust</td>\n</tr>\n<tr id=\"S6.T3.sf1.1.2\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf1.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">No attack</td>\n<td id=\"S6.T3.sf1.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.04</td>\n<td id=\"S6.T3.sf1.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.10</td>\n<td id=\"S6.T3.sf1.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.06</td>\n<td id=\"S6.T3.sf1.1.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.06</td>\n<td id=\"S6.T3.sf1.1.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.04</td>\n</tr>\n<tr id=\"S6.T3.sf1.1.3\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf1.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">LF attack</td>\n<td id=\"S6.T3.sf1.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.06</td>\n<td id=\"S6.T3.sf1.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.10</td>\n<td id=\"S6.T3.sf1.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.05</td>\n<td id=\"S6.T3.sf1.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.05</td>\n<td id=\"S6.T3.sf1.1.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.04</td>\n</tr>\n<tr id=\"S6.T3.sf1.1.4\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf1.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Krum attack</td>\n<td id=\"S6.T3.sf1.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.10</td>\n<td id=\"S6.T3.sf1.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.90</td>\n<td id=\"S6.T3.sf1.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.07</td>\n<td id=\"S6.T3.sf1.1.4.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.07</td>\n<td id=\"S6.T3.sf1.1.4.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.04</td>\n</tr>\n<tr id=\"S6.T3.sf1.1.5\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf1.1.5.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Trim attack</td>\n<td id=\"S6.T3.sf1.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.16</td>\n<td id=\"S6.T3.sf1.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.10</td>\n<td id=\"S6.T3.sf1.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.13</td>\n<td id=\"S6.T3.sf1.1.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.13</td>\n<td id=\"S6.T3.sf1.1.5.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.04</td>\n</tr>\n<tr id=\"S6.T3.sf1.1.6\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf1.1.6.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Scaling attack</td>\n<td id=\"S6.T3.sf1.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.02 / 1.00</td>\n<td id=\"S6.T3.sf1.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.10 / 0.00</td>\n<td id=\"S6.T3.sf1.1.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.05 / 0.01</td>\n<td id=\"S6.T3.sf1.1.6.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.05 / 0.01</td>\n<td id=\"S6.T3.sf1.1.6.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.03 / 0.00</td>\n</tr>\n<tr id=\"S6.T3.sf1.1.7\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf1.1.7.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Adaptive attack</td>\n<td id=\"S6.T3.sf1.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.08</td>\n<td id=\"S6.T3.sf1.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.10</td>\n<td id=\"S6.T3.sf1.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.11</td>\n<td id=\"S6.T3.sf1.1.7.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.13</td>\n<td id=\"S6.T3.sf1.1.7.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.04</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Solving the optimization problem:Â  We use a standard gradient ascent approach to solve the optimization problem. Specifically, we can compute the gradient âˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h of the objective function hâ„h with respect to each ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime} and move ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime} a small step along the gradient. Since the gradient âˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h involves a Jacobian matrix of ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime}, it is not practical to directly compute the gradient. Therefore, we leverage a zeroth-order method [13, 33] to compute the gradient, which is a standard method to solve such optimization problems with computationally intractable objective functions. Specifically, we compute the gradient\nâˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h as follows:",
            "By default, we assume there are n=100ğ‘›100n=100 clients in total for each dataset except HAR and CH-MNIST. For HAR, the data are collected from 30 users, each of which is treated as a client. Therefore, HAR has 30 clients in total. For CH-MNIST, there are only 4,000 training examples in total and thus we assume 40 clients such that each client has 100 training examples on average. Unless otherwise mentioned, we assume 20% of the clients are malicious for each dataset. However, we will also explore the impact of the fraction of malicious clients. Table I shows the default FL system settings that we will use unless otherwise mentioned.",
            "Global models:Â  We train different types of global models on different datasets to show the generality of our method. Specifically, for MNIST-0.1, MNIST-0.5, and Fashion-MNIST, we train a convolutional neural network (CNN) as the global model. Table II shows the architecture of the CNN. And we train a logistic regression (LR) classifier as the global model for HAR. For CIFAR-10 and CH-MNIST, we consider the widely used ResNet20 architecture [19] as the global model.",
            "Our FLTrust achieves the three defense goals:Â  Recall that we have three defense goals (discussed in SectionÂ III): fidelity, robustness, and efficiency. Table IIIf shows the testing error rates of different FL methods under different attacks including our adaptive attack, as well as the attack success rate of the Scaling attack on the six datasets. Our results show that FLTrust achieves the three goals.",
            "Table IV compares the variants with respect to their testing error rates under different attacks and the attack success rates of the Scaling attacks on MNIST-0.5. The attacks are not applicable to FLTrust-Server as it does not require communications from the clients. Our results show that FLTrust outperforms the five variants. FLTrust outperforms FLTrust-Server and FLTrust-withServer because the root dataset is small. The fact that FLTrust outperforms\nFLTrust-NoReLU, FLTrust-NoNorm, and FLTrust-ParNorm indicates the necessity of our ReLU operation and normalization.",
            "We also evaluate the impact of the bias probability in Case II. Table Vf shows the testing error rates of FLTrust under different attacks and the attack success rates of the Scaling attacks when the bias probability varies. The second column in each table corresponds to the bias probability with which Case II reduces to Case I. We increase the bias probability up to 1.0 to simulate larger difference between the root data distribution and the overall training data distribution. We observe that FLTrust is accurate and robust when the bias probability is not too large. For instance, when the bias probability is no more than 0.4 for MNIST-0.5, the testing error rates of FLTrust under attacks are at most 0.08, compared to 0.05 when the bias probability is 0.1. Our results show that FLTrust works well when the root data distribution does not diverge too much from the overall training data distribution."
        ]
    },
    "S6.T3.sf2": {
        "caption": "(b) CNN global model, MNIST-0.5",
        "table": "<table id=\"S6.T3.sf2.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S6.T3.sf2.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf2.1.1.1\" class=\"ltx_td ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n<td id=\"S6.T3.sf2.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">FedAvg</td>\n<td id=\"S6.T3.sf2.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Krum</td>\n<td id=\"S6.T3.sf2.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Trim-mean</td>\n<td id=\"S6.T3.sf2.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Median</td>\n<td id=\"S6.T3.sf2.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">FLTrust</td>\n</tr>\n<tr id=\"S6.T3.sf2.1.2\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf2.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">No attack</td>\n<td id=\"S6.T3.sf2.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.04</td>\n<td id=\"S6.T3.sf2.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.10</td>\n<td id=\"S6.T3.sf2.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.06</td>\n<td id=\"S6.T3.sf2.1.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.06</td>\n<td id=\"S6.T3.sf2.1.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.05</td>\n</tr>\n<tr id=\"S6.T3.sf2.1.3\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf2.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">LF attack</td>\n<td id=\"S6.T3.sf2.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.06</td>\n<td id=\"S6.T3.sf2.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.10</td>\n<td id=\"S6.T3.sf2.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.06</td>\n<td id=\"S6.T3.sf2.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.06</td>\n<td id=\"S6.T3.sf2.1.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.05</td>\n</tr>\n<tr id=\"S6.T3.sf2.1.4\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf2.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Krum attack</td>\n<td id=\"S6.T3.sf2.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.10</td>\n<td id=\"S6.T3.sf2.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.91</td>\n<td id=\"S6.T3.sf2.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.14</td>\n<td id=\"S6.T3.sf2.1.4.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.15</td>\n<td id=\"S6.T3.sf2.1.4.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.05</td>\n</tr>\n<tr id=\"S6.T3.sf2.1.5\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf2.1.5.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Trim attack</td>\n<td id=\"S6.T3.sf2.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.28</td>\n<td id=\"S6.T3.sf2.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.10</td>\n<td id=\"S6.T3.sf2.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.23</td>\n<td id=\"S6.T3.sf2.1.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.43</td>\n<td id=\"S6.T3.sf2.1.5.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.06</td>\n</tr>\n<tr id=\"S6.T3.sf2.1.6\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf2.1.6.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Scaling attack</td>\n<td id=\"S6.T3.sf2.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.02 / 1.00</td>\n<td id=\"S6.T3.sf2.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.09 / 0.01</td>\n<td id=\"S6.T3.sf2.1.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.06 / 0.02</td>\n<td id=\"S6.T3.sf2.1.6.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.06 / 0.01</td>\n<td id=\"S6.T3.sf2.1.6.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.05 / 0.00</td>\n</tr>\n<tr id=\"S6.T3.sf2.1.7\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf2.1.7.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Adaptive attack</td>\n<td id=\"S6.T3.sf2.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.13</td>\n<td id=\"S6.T3.sf2.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.10</td>\n<td id=\"S6.T3.sf2.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.22</td>\n<td id=\"S6.T3.sf2.1.7.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.90</td>\n<td id=\"S6.T3.sf2.1.7.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.06</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Solving the optimization problem:Â  We use a standard gradient ascent approach to solve the optimization problem. Specifically, we can compute the gradient âˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h of the objective function hâ„h with respect to each ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime} and move ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime} a small step along the gradient. Since the gradient âˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h involves a Jacobian matrix of ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime}, it is not practical to directly compute the gradient. Therefore, we leverage a zeroth-order method [13, 33] to compute the gradient, which is a standard method to solve such optimization problems with computationally intractable objective functions. Specifically, we compute the gradient\nâˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h as follows:",
            "By default, we assume there are n=100ğ‘›100n=100 clients in total for each dataset except HAR and CH-MNIST. For HAR, the data are collected from 30 users, each of which is treated as a client. Therefore, HAR has 30 clients in total. For CH-MNIST, there are only 4,000 training examples in total and thus we assume 40 clients such that each client has 100 training examples on average. Unless otherwise mentioned, we assume 20% of the clients are malicious for each dataset. However, we will also explore the impact of the fraction of malicious clients. Table I shows the default FL system settings that we will use unless otherwise mentioned.",
            "Global models:Â  We train different types of global models on different datasets to show the generality of our method. Specifically, for MNIST-0.1, MNIST-0.5, and Fashion-MNIST, we train a convolutional neural network (CNN) as the global model. Table II shows the architecture of the CNN. And we train a logistic regression (LR) classifier as the global model for HAR. For CIFAR-10 and CH-MNIST, we consider the widely used ResNet20 architecture [19] as the global model.",
            "Our FLTrust achieves the three defense goals:Â  Recall that we have three defense goals (discussed in SectionÂ III): fidelity, robustness, and efficiency. Table IIIf shows the testing error rates of different FL methods under different attacks including our adaptive attack, as well as the attack success rate of the Scaling attack on the six datasets. Our results show that FLTrust achieves the three goals.",
            "Table IV compares the variants with respect to their testing error rates under different attacks and the attack success rates of the Scaling attacks on MNIST-0.5. The attacks are not applicable to FLTrust-Server as it does not require communications from the clients. Our results show that FLTrust outperforms the five variants. FLTrust outperforms FLTrust-Server and FLTrust-withServer because the root dataset is small. The fact that FLTrust outperforms\nFLTrust-NoReLU, FLTrust-NoNorm, and FLTrust-ParNorm indicates the necessity of our ReLU operation and normalization.",
            "We also evaluate the impact of the bias probability in Case II. Table Vf shows the testing error rates of FLTrust under different attacks and the attack success rates of the Scaling attacks when the bias probability varies. The second column in each table corresponds to the bias probability with which Case II reduces to Case I. We increase the bias probability up to 1.0 to simulate larger difference between the root data distribution and the overall training data distribution. We observe that FLTrust is accurate and robust when the bias probability is not too large. For instance, when the bias probability is no more than 0.4 for MNIST-0.5, the testing error rates of FLTrust under attacks are at most 0.08, compared to 0.05 when the bias probability is 0.1. Our results show that FLTrust works well when the root data distribution does not diverge too much from the overall training data distribution."
        ]
    },
    "S6.T3.sf3": {
        "caption": "(c) CNN global model, Fashion-MNIST",
        "table": "<table id=\"S6.T3.sf3.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S6.T3.sf3.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf3.1.1.1\" class=\"ltx_td ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n<td id=\"S6.T3.sf3.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">FedAvg</td>\n<td id=\"S6.T3.sf3.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Krum</td>\n<td id=\"S6.T3.sf3.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Trim-mean</td>\n<td id=\"S6.T3.sf3.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Median</td>\n<td id=\"S6.T3.sf3.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">FLTrust</td>\n</tr>\n<tr id=\"S6.T3.sf3.1.2\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf3.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">No attack</td>\n<td id=\"S6.T3.sf3.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.10</td>\n<td id=\"S6.T3.sf3.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.16</td>\n<td id=\"S6.T3.sf3.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.14</td>\n<td id=\"S6.T3.sf3.1.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.14</td>\n<td id=\"S6.T3.sf3.1.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.11</td>\n</tr>\n<tr id=\"S6.T3.sf3.1.3\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf3.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">LF attack</td>\n<td id=\"S6.T3.sf3.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.14</td>\n<td id=\"S6.T3.sf3.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.15</td>\n<td id=\"S6.T3.sf3.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.26</td>\n<td id=\"S6.T3.sf3.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.21</td>\n<td id=\"S6.T3.sf3.1.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.11</td>\n</tr>\n<tr id=\"S6.T3.sf3.1.4\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf3.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Krum attack</td>\n<td id=\"S6.T3.sf3.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.13</td>\n<td id=\"S6.T3.sf3.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.90</td>\n<td id=\"S6.T3.sf3.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.18</td>\n<td id=\"S6.T3.sf3.1.4.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.23</td>\n<td id=\"S6.T3.sf3.1.4.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.12</td>\n</tr>\n<tr id=\"S6.T3.sf3.1.5\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf3.1.5.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Trim attack</td>\n<td id=\"S6.T3.sf3.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.90</td>\n<td id=\"S6.T3.sf3.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.16</td>\n<td id=\"S6.T3.sf3.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.24</td>\n<td id=\"S6.T3.sf3.1.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.27</td>\n<td id=\"S6.T3.sf3.1.5.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.14</td>\n</tr>\n<tr id=\"S6.T3.sf3.1.6\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf3.1.6.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Scaling attack</td>\n<td id=\"S6.T3.sf3.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.90 / 1.00</td>\n<td id=\"S6.T3.sf3.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.16 / 0.03</td>\n<td id=\"S6.T3.sf3.1.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.17 / 0.85</td>\n<td id=\"S6.T3.sf3.1.6.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.16 / 0.05</td>\n<td id=\"S6.T3.sf3.1.6.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.11 / 0.02</td>\n</tr>\n<tr id=\"S6.T3.sf3.1.7\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf3.1.7.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Adaptive attack</td>\n<td id=\"S6.T3.sf3.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.90</td>\n<td id=\"S6.T3.sf3.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.18</td>\n<td id=\"S6.T3.sf3.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.34</td>\n<td id=\"S6.T3.sf3.1.7.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.24</td>\n<td id=\"S6.T3.sf3.1.7.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.14</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Solving the optimization problem:Â  We use a standard gradient ascent approach to solve the optimization problem. Specifically, we can compute the gradient âˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h of the objective function hâ„h with respect to each ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime} and move ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime} a small step along the gradient. Since the gradient âˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h involves a Jacobian matrix of ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime}, it is not practical to directly compute the gradient. Therefore, we leverage a zeroth-order method [13, 33] to compute the gradient, which is a standard method to solve such optimization problems with computationally intractable objective functions. Specifically, we compute the gradient\nâˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h as follows:",
            "By default, we assume there are n=100ğ‘›100n=100 clients in total for each dataset except HAR and CH-MNIST. For HAR, the data are collected from 30 users, each of which is treated as a client. Therefore, HAR has 30 clients in total. For CH-MNIST, there are only 4,000 training examples in total and thus we assume 40 clients such that each client has 100 training examples on average. Unless otherwise mentioned, we assume 20% of the clients are malicious for each dataset. However, we will also explore the impact of the fraction of malicious clients. Table I shows the default FL system settings that we will use unless otherwise mentioned.",
            "Global models:Â  We train different types of global models on different datasets to show the generality of our method. Specifically, for MNIST-0.1, MNIST-0.5, and Fashion-MNIST, we train a convolutional neural network (CNN) as the global model. Table II shows the architecture of the CNN. And we train a logistic regression (LR) classifier as the global model for HAR. For CIFAR-10 and CH-MNIST, we consider the widely used ResNet20 architecture [19] as the global model.",
            "Our FLTrust achieves the three defense goals:Â  Recall that we have three defense goals (discussed in SectionÂ III): fidelity, robustness, and efficiency. Table IIIf shows the testing error rates of different FL methods under different attacks including our adaptive attack, as well as the attack success rate of the Scaling attack on the six datasets. Our results show that FLTrust achieves the three goals.",
            "Table IV compares the variants with respect to their testing error rates under different attacks and the attack success rates of the Scaling attacks on MNIST-0.5. The attacks are not applicable to FLTrust-Server as it does not require communications from the clients. Our results show that FLTrust outperforms the five variants. FLTrust outperforms FLTrust-Server and FLTrust-withServer because the root dataset is small. The fact that FLTrust outperforms\nFLTrust-NoReLU, FLTrust-NoNorm, and FLTrust-ParNorm indicates the necessity of our ReLU operation and normalization.",
            "We also evaluate the impact of the bias probability in Case II. Table Vf shows the testing error rates of FLTrust under different attacks and the attack success rates of the Scaling attacks when the bias probability varies. The second column in each table corresponds to the bias probability with which Case II reduces to Case I. We increase the bias probability up to 1.0 to simulate larger difference between the root data distribution and the overall training data distribution. We observe that FLTrust is accurate and robust when the bias probability is not too large. For instance, when the bias probability is no more than 0.4 for MNIST-0.5, the testing error rates of FLTrust under attacks are at most 0.08, compared to 0.05 when the bias probability is 0.1. Our results show that FLTrust works well when the root data distribution does not diverge too much from the overall training data distribution."
        ]
    },
    "S6.T3.sf4": {
        "caption": "(d) ResNet20 global model, CIFAR-10",
        "table": "<table id=\"S6.T3.sf4.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S6.T3.sf4.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf4.1.1.1\" class=\"ltx_td ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n<td id=\"S6.T3.sf4.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">FedAvg</td>\n<td id=\"S6.T3.sf4.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Krum</td>\n<td id=\"S6.T3.sf4.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Trim-mean</td>\n<td id=\"S6.T3.sf4.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Median</td>\n<td id=\"S6.T3.sf4.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">FLTrust</td>\n</tr>\n<tr id=\"S6.T3.sf4.1.2\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf4.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">No attack</td>\n<td id=\"S6.T3.sf4.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.16</td>\n<td id=\"S6.T3.sf4.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.54</td>\n<td id=\"S6.T3.sf4.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.24</td>\n<td id=\"S6.T3.sf4.1.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.25</td>\n<td id=\"S6.T3.sf4.1.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.18</td>\n</tr>\n<tr id=\"S6.T3.sf4.1.3\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf4.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">LF attack</td>\n<td id=\"S6.T3.sf4.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.21</td>\n<td id=\"S6.T3.sf4.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.56</td>\n<td id=\"S6.T3.sf4.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.27</td>\n<td id=\"S6.T3.sf4.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.45</td>\n<td id=\"S6.T3.sf4.1.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.18</td>\n</tr>\n<tr id=\"S6.T3.sf4.1.4\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf4.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Krum attack</td>\n<td id=\"S6.T3.sf4.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.24</td>\n<td id=\"S6.T3.sf4.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.90</td>\n<td id=\"S6.T3.sf4.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.52</td>\n<td id=\"S6.T3.sf4.1.4.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.64</td>\n<td id=\"S6.T3.sf4.1.4.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.18</td>\n</tr>\n<tr id=\"S6.T3.sf4.1.5\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf4.1.5.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Trim attack</td>\n<td id=\"S6.T3.sf4.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.81</td>\n<td id=\"S6.T3.sf4.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.51</td>\n<td id=\"S6.T3.sf4.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.72</td>\n<td id=\"S6.T3.sf4.1.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.75</td>\n<td id=\"S6.T3.sf4.1.5.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.20</td>\n</tr>\n<tr id=\"S6.T3.sf4.1.6\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf4.1.6.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Scaling attack</td>\n<td id=\"S6.T3.sf4.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.90 / 1.00</td>\n<td id=\"S6.T3.sf4.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.44 / 0.07</td>\n<td id=\"S6.T3.sf4.1.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.22 / 0.96</td>\n<td id=\"S6.T3.sf4.1.6.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.25 / 0.96</td>\n<td id=\"S6.T3.sf4.1.6.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.18 / 0.02</td>\n</tr>\n<tr id=\"S6.T3.sf4.1.7\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf4.1.7.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Adaptive attack</td>\n<td id=\"S6.T3.sf4.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.90</td>\n<td id=\"S6.T3.sf4.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.58</td>\n<td id=\"S6.T3.sf4.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.69</td>\n<td id=\"S6.T3.sf4.1.7.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.82</td>\n<td id=\"S6.T3.sf4.1.7.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.20</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Solving the optimization problem:Â  We use a standard gradient ascent approach to solve the optimization problem. Specifically, we can compute the gradient âˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h of the objective function hâ„h with respect to each ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime} and move ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime} a small step along the gradient. Since the gradient âˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h involves a Jacobian matrix of ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime}, it is not practical to directly compute the gradient. Therefore, we leverage a zeroth-order method [13, 33] to compute the gradient, which is a standard method to solve such optimization problems with computationally intractable objective functions. Specifically, we compute the gradient\nâˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h as follows:",
            "By default, we assume there are n=100ğ‘›100n=100 clients in total for each dataset except HAR and CH-MNIST. For HAR, the data are collected from 30 users, each of which is treated as a client. Therefore, HAR has 30 clients in total. For CH-MNIST, there are only 4,000 training examples in total and thus we assume 40 clients such that each client has 100 training examples on average. Unless otherwise mentioned, we assume 20% of the clients are malicious for each dataset. However, we will also explore the impact of the fraction of malicious clients. Table I shows the default FL system settings that we will use unless otherwise mentioned.",
            "Global models:Â  We train different types of global models on different datasets to show the generality of our method. Specifically, for MNIST-0.1, MNIST-0.5, and Fashion-MNIST, we train a convolutional neural network (CNN) as the global model. Table II shows the architecture of the CNN. And we train a logistic regression (LR) classifier as the global model for HAR. For CIFAR-10 and CH-MNIST, we consider the widely used ResNet20 architecture [19] as the global model.",
            "Our FLTrust achieves the three defense goals:Â  Recall that we have three defense goals (discussed in SectionÂ III): fidelity, robustness, and efficiency. Table IIIf shows the testing error rates of different FL methods under different attacks including our adaptive attack, as well as the attack success rate of the Scaling attack on the six datasets. Our results show that FLTrust achieves the three goals.",
            "Table IV compares the variants with respect to their testing error rates under different attacks and the attack success rates of the Scaling attacks on MNIST-0.5. The attacks are not applicable to FLTrust-Server as it does not require communications from the clients. Our results show that FLTrust outperforms the five variants. FLTrust outperforms FLTrust-Server and FLTrust-withServer because the root dataset is small. The fact that FLTrust outperforms\nFLTrust-NoReLU, FLTrust-NoNorm, and FLTrust-ParNorm indicates the necessity of our ReLU operation and normalization.",
            "We also evaluate the impact of the bias probability in Case II. Table Vf shows the testing error rates of FLTrust under different attacks and the attack success rates of the Scaling attacks when the bias probability varies. The second column in each table corresponds to the bias probability with which Case II reduces to Case I. We increase the bias probability up to 1.0 to simulate larger difference between the root data distribution and the overall training data distribution. We observe that FLTrust is accurate and robust when the bias probability is not too large. For instance, when the bias probability is no more than 0.4 for MNIST-0.5, the testing error rates of FLTrust under attacks are at most 0.08, compared to 0.05 when the bias probability is 0.1. Our results show that FLTrust works well when the root data distribution does not diverge too much from the overall training data distribution."
        ]
    },
    "S6.T3.sf5": {
        "caption": "(e) LR global model, HAR",
        "table": "<table id=\"S6.T3.sf5.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S6.T3.sf5.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf5.1.1.1\" class=\"ltx_td ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n<td id=\"S6.T3.sf5.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">FedAvg</td>\n<td id=\"S6.T3.sf5.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Krum</td>\n<td id=\"S6.T3.sf5.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Trim-mean</td>\n<td id=\"S6.T3.sf5.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Median</td>\n<td id=\"S6.T3.sf5.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">FLTrust</td>\n</tr>\n<tr id=\"S6.T3.sf5.1.2\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf5.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">No attack</td>\n<td id=\"S6.T3.sf5.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.03</td>\n<td id=\"S6.T3.sf5.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.12</td>\n<td id=\"S6.T3.sf5.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.04</td>\n<td id=\"S6.T3.sf5.1.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.05</td>\n<td id=\"S6.T3.sf5.1.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.04</td>\n</tr>\n<tr id=\"S6.T3.sf5.1.3\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf5.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">LF attack</td>\n<td id=\"S6.T3.sf5.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.17</td>\n<td id=\"S6.T3.sf5.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.10</td>\n<td id=\"S6.T3.sf5.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.05</td>\n<td id=\"S6.T3.sf5.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.05</td>\n<td id=\"S6.T3.sf5.1.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.04</td>\n</tr>\n<tr id=\"S6.T3.sf5.1.4\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf5.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Krum attack</td>\n<td id=\"S6.T3.sf5.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.03</td>\n<td id=\"S6.T3.sf5.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.22</td>\n<td id=\"S6.T3.sf5.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.05</td>\n<td id=\"S6.T3.sf5.1.4.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.05</td>\n<td id=\"S6.T3.sf5.1.4.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.04</td>\n</tr>\n<tr id=\"S6.T3.sf5.1.5\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf5.1.5.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Trim attack</td>\n<td id=\"S6.T3.sf5.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.32</td>\n<td id=\"S6.T3.sf5.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.10</td>\n<td id=\"S6.T3.sf5.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.36</td>\n<td id=\"S6.T3.sf5.1.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.13</td>\n<td id=\"S6.T3.sf5.1.5.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.05</td>\n</tr>\n<tr id=\"S6.T3.sf5.1.6\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf5.1.6.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Scaling attack</td>\n<td id=\"S6.T3.sf5.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.04 / 0.81</td>\n<td id=\"S6.T3.sf5.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.10 / 0.03</td>\n<td id=\"S6.T3.sf5.1.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.04 / 0.36</td>\n<td id=\"S6.T3.sf5.1.6.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.05 / 0.13</td>\n<td id=\"S6.T3.sf5.1.6.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.05 / 0.01</td>\n</tr>\n<tr id=\"S6.T3.sf5.1.7\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf5.1.7.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Adaptive attack</td>\n<td id=\"S6.T3.sf5.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.04</td>\n<td id=\"S6.T3.sf5.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.19</td>\n<td id=\"S6.T3.sf5.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.05</td>\n<td id=\"S6.T3.sf5.1.7.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.06</td>\n<td id=\"S6.T3.sf5.1.7.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.05</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Solving the optimization problem:Â  We use a standard gradient ascent approach to solve the optimization problem. Specifically, we can compute the gradient âˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h of the objective function hâ„h with respect to each ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime} and move ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime} a small step along the gradient. Since the gradient âˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h involves a Jacobian matrix of ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime}, it is not practical to directly compute the gradient. Therefore, we leverage a zeroth-order method [13, 33] to compute the gradient, which is a standard method to solve such optimization problems with computationally intractable objective functions. Specifically, we compute the gradient\nâˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h as follows:",
            "By default, we assume there are n=100ğ‘›100n=100 clients in total for each dataset except HAR and CH-MNIST. For HAR, the data are collected from 30 users, each of which is treated as a client. Therefore, HAR has 30 clients in total. For CH-MNIST, there are only 4,000 training examples in total and thus we assume 40 clients such that each client has 100 training examples on average. Unless otherwise mentioned, we assume 20% of the clients are malicious for each dataset. However, we will also explore the impact of the fraction of malicious clients. Table I shows the default FL system settings that we will use unless otherwise mentioned.",
            "Global models:Â  We train different types of global models on different datasets to show the generality of our method. Specifically, for MNIST-0.1, MNIST-0.5, and Fashion-MNIST, we train a convolutional neural network (CNN) as the global model. Table II shows the architecture of the CNN. And we train a logistic regression (LR) classifier as the global model for HAR. For CIFAR-10 and CH-MNIST, we consider the widely used ResNet20 architecture [19] as the global model.",
            "Our FLTrust achieves the three defense goals:Â  Recall that we have three defense goals (discussed in SectionÂ III): fidelity, robustness, and efficiency. Table IIIf shows the testing error rates of different FL methods under different attacks including our adaptive attack, as well as the attack success rate of the Scaling attack on the six datasets. Our results show that FLTrust achieves the three goals.",
            "Table IV compares the variants with respect to their testing error rates under different attacks and the attack success rates of the Scaling attacks on MNIST-0.5. The attacks are not applicable to FLTrust-Server as it does not require communications from the clients. Our results show that FLTrust outperforms the five variants. FLTrust outperforms FLTrust-Server and FLTrust-withServer because the root dataset is small. The fact that FLTrust outperforms\nFLTrust-NoReLU, FLTrust-NoNorm, and FLTrust-ParNorm indicates the necessity of our ReLU operation and normalization.",
            "We also evaluate the impact of the bias probability in Case II. Table Vf shows the testing error rates of FLTrust under different attacks and the attack success rates of the Scaling attacks when the bias probability varies. The second column in each table corresponds to the bias probability with which Case II reduces to Case I. We increase the bias probability up to 1.0 to simulate larger difference between the root data distribution and the overall training data distribution. We observe that FLTrust is accurate and robust when the bias probability is not too large. For instance, when the bias probability is no more than 0.4 for MNIST-0.5, the testing error rates of FLTrust under attacks are at most 0.08, compared to 0.05 when the bias probability is 0.1. Our results show that FLTrust works well when the root data distribution does not diverge too much from the overall training data distribution."
        ]
    },
    "S6.T3.sf6": {
        "caption": "(f) ResNet20 global model, CH-MNIST",
        "table": "<table id=\"S6.T3.sf6.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S6.T3.sf6.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf6.1.1.1\" class=\"ltx_td ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n<td id=\"S6.T3.sf6.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">FedAvg</td>\n<td id=\"S6.T3.sf6.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Krum</td>\n<td id=\"S6.T3.sf6.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Trim-mean</td>\n<td id=\"S6.T3.sf6.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Median</td>\n<td id=\"S6.T3.sf6.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">FLTrust</td>\n</tr>\n<tr id=\"S6.T3.sf6.1.2\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf6.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">No attack</td>\n<td id=\"S6.T3.sf6.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.10</td>\n<td id=\"S6.T3.sf6.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.24</td>\n<td id=\"S6.T3.sf6.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.10</td>\n<td id=\"S6.T3.sf6.1.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.11</td>\n<td id=\"S6.T3.sf6.1.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.10</td>\n</tr>\n<tr id=\"S6.T3.sf6.1.3\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf6.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">LF attack</td>\n<td id=\"S6.T3.sf6.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.12</td>\n<td id=\"S6.T3.sf6.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.39</td>\n<td id=\"S6.T3.sf6.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.15</td>\n<td id=\"S6.T3.sf6.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.13</td>\n<td id=\"S6.T3.sf6.1.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.12</td>\n</tr>\n<tr id=\"S6.T3.sf6.1.4\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf6.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Krum attack</td>\n<td id=\"S6.T3.sf6.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.11</td>\n<td id=\"S6.T3.sf6.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.95</td>\n<td id=\"S6.T3.sf6.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.13</td>\n<td id=\"S6.T3.sf6.1.4.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.13</td>\n<td id=\"S6.T3.sf6.1.4.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.12</td>\n</tr>\n<tr id=\"S6.T3.sf6.1.5\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf6.1.5.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Trim attack</td>\n<td id=\"S6.T3.sf6.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.64</td>\n<td id=\"S6.T3.sf6.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.21</td>\n<td id=\"S6.T3.sf6.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.55</td>\n<td id=\"S6.T3.sf6.1.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.44</td>\n<td id=\"S6.T3.sf6.1.5.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.13</td>\n</tr>\n<tr id=\"S6.T3.sf6.1.6\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf6.1.6.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Scaling attack</td>\n<td id=\"S6.T3.sf6.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.26 / 0.20</td>\n<td id=\"S6.T3.sf6.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.34 / 0.03</td>\n<td id=\"S6.T3.sf6.1.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.14 / 0.02</td>\n<td id=\"S6.T3.sf6.1.6.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.11 / 0.01</td>\n<td id=\"S6.T3.sf6.1.6.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.14 / 0.03</td>\n</tr>\n<tr id=\"S6.T3.sf6.1.7\" class=\"ltx_tr\">\n<td id=\"S6.T3.sf6.1.7.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">Adaptive attack</td>\n<td id=\"S6.T3.sf6.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.14</td>\n<td id=\"S6.T3.sf6.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.29</td>\n<td id=\"S6.T3.sf6.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.50</td>\n<td id=\"S6.T3.sf6.1.7.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.47</td>\n<td id=\"S6.T3.sf6.1.7.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.13</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Solving the optimization problem:Â  We use a standard gradient ascent approach to solve the optimization problem. Specifically, we can compute the gradient âˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h of the objective function hâ„h with respect to each ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime} and move ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime} a small step along the gradient. Since the gradient âˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h involves a Jacobian matrix of ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime}, it is not practical to directly compute the gradient. Therefore, we leverage a zeroth-order method [13, 33] to compute the gradient, which is a standard method to solve such optimization problems with computationally intractable objective functions. Specifically, we compute the gradient\nâˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h as follows:",
            "By default, we assume there are n=100ğ‘›100n=100 clients in total for each dataset except HAR and CH-MNIST. For HAR, the data are collected from 30 users, each of which is treated as a client. Therefore, HAR has 30 clients in total. For CH-MNIST, there are only 4,000 training examples in total and thus we assume 40 clients such that each client has 100 training examples on average. Unless otherwise mentioned, we assume 20% of the clients are malicious for each dataset. However, we will also explore the impact of the fraction of malicious clients. Table I shows the default FL system settings that we will use unless otherwise mentioned.",
            "Global models:Â  We train different types of global models on different datasets to show the generality of our method. Specifically, for MNIST-0.1, MNIST-0.5, and Fashion-MNIST, we train a convolutional neural network (CNN) as the global model. Table II shows the architecture of the CNN. And we train a logistic regression (LR) classifier as the global model for HAR. For CIFAR-10 and CH-MNIST, we consider the widely used ResNet20 architecture [19] as the global model.",
            "Our FLTrust achieves the three defense goals:Â  Recall that we have three defense goals (discussed in SectionÂ III): fidelity, robustness, and efficiency. Table IIIf shows the testing error rates of different FL methods under different attacks including our adaptive attack, as well as the attack success rate of the Scaling attack on the six datasets. Our results show that FLTrust achieves the three goals.",
            "Table IV compares the variants with respect to their testing error rates under different attacks and the attack success rates of the Scaling attacks on MNIST-0.5. The attacks are not applicable to FLTrust-Server as it does not require communications from the clients. Our results show that FLTrust outperforms the five variants. FLTrust outperforms FLTrust-Server and FLTrust-withServer because the root dataset is small. The fact that FLTrust outperforms\nFLTrust-NoReLU, FLTrust-NoNorm, and FLTrust-ParNorm indicates the necessity of our ReLU operation and normalization.",
            "We also evaluate the impact of the bias probability in Case II. Table Vf shows the testing error rates of FLTrust under different attacks and the attack success rates of the Scaling attacks when the bias probability varies. The second column in each table corresponds to the bias probability with which Case II reduces to Case I. We increase the bias probability up to 1.0 to simulate larger difference between the root data distribution and the overall training data distribution. We observe that FLTrust is accurate and robust when the bias probability is not too large. For instance, when the bias probability is no more than 0.4 for MNIST-0.5, the testing error rates of FLTrust under attacks are at most 0.08, compared to 0.05 when the bias probability is 0.1. Our results show that FLTrust works well when the root data distribution does not diverge too much from the overall training data distribution."
        ]
    },
    "S6.T4": {
        "caption": "TABLE IV: The testing error rates of different variants of FLTrust under different attacks and the attack success rates of the Scaling attacks on MNIST-0.5. The results for the Scaling attacks are in the form of â€œtesting error rate / attack success rateâ€. â€œâ€“â€ means that the attacks are not applicable.",
        "table": "<table id=\"S6.T4.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S6.T4.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T4.1.1.1\" class=\"ltx_td ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\"></td>\n<td id=\"S6.T4.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">No attack</td>\n<td id=\"S6.T4.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">LF attack</td>\n<td id=\"S6.T4.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">Krum attack</td>\n<td id=\"S6.T4.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">Trim attack</td>\n<td id=\"S6.T4.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">Scaling attack</td>\n<td id=\"S6.T4.1.1.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">Adaptive attack</td>\n</tr>\n<tr id=\"S6.T4.1.2\" class=\"ltx_tr\">\n<td id=\"S6.T4.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">FLTrust-Server</td>\n<td id=\"S6.T4.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.21</td>\n<td id=\"S6.T4.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">â€“</td>\n<td id=\"S6.T4.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">â€“</td>\n<td id=\"S6.T4.1.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">â€“</td>\n<td id=\"S6.T4.1.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">â€“</td>\n<td id=\"S6.T4.1.2.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">â€“</td>\n</tr>\n<tr id=\"S6.T4.1.3\" class=\"ltx_tr\">\n<td id=\"S6.T4.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">FLTrust-withServer</td>\n<td id=\"S6.T4.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.07</td>\n<td id=\"S6.T4.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.08</td>\n<td id=\"S6.T4.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.09</td>\n<td id=\"S6.T4.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.10</td>\n<td id=\"S6.T4.1.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.08 / 0.01</td>\n<td id=\"S6.T4.1.3.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.94</td>\n</tr>\n<tr id=\"S6.T4.1.4\" class=\"ltx_tr\">\n<td id=\"S6.T4.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">FLTrust-NoReLU</td>\n<td id=\"S6.T4.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.28</td>\n<td id=\"S6.T4.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.90</td>\n<td id=\"S6.T4.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.90</td>\n<td id=\"S6.T4.1.4.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.90</td>\n<td id=\"S6.T4.1.4.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.94 / 0.08</td>\n<td id=\"S6.T4.1.4.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.90</td>\n</tr>\n<tr id=\"S6.T4.1.5\" class=\"ltx_tr\">\n<td id=\"S6.T4.1.5.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">FLTrust-NoNorm</td>\n<td id=\"S6.T4.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.05</td>\n<td id=\"S6.T4.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.06</td>\n<td id=\"S6.T4.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.06</td>\n<td id=\"S6.T4.1.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.08</td>\n<td id=\"S6.T4.1.5.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.94 / 0.08</td>\n<td id=\"S6.T4.1.5.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.06</td>\n</tr>\n<tr id=\"S6.T4.1.6\" class=\"ltx_tr\">\n<td id=\"S6.T4.1.6.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">FLTrust-ParNorm</td>\n<td id=\"S6.T4.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.06</td>\n<td id=\"S6.T4.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.06</td>\n<td id=\"S6.T4.1.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.06</td>\n<td id=\"S6.T4.1.6.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.06</td>\n<td id=\"S6.T4.1.6.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.06 / 0.01</td>\n<td id=\"S6.T4.1.6.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.06</td>\n</tr>\n<tr id=\"S6.T4.1.7\" class=\"ltx_tr\">\n<td id=\"S6.T4.1.7.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">FLTrust</td>\n<td id=\"S6.T4.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.05</td>\n<td id=\"S6.T4.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.05</td>\n<td id=\"S6.T4.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.05</td>\n<td id=\"S6.T4.1.7.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.06</td>\n<td id=\"S6.T4.1.7.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.05 / 0.00</td>\n<td id=\"S6.T4.1.7.7\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-top:0.5pt;padding-bottom:0.5pt;\">0.06</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Table IV compares the variants with respect to their testing error rates under different attacks and the attack success rates of the Scaling attacks on MNIST-0.5. The attacks are not applicable to FLTrust-Server as it does not require communications from the clients. Our results show that FLTrust outperforms the five variants. FLTrust outperforms FLTrust-Server and FLTrust-withServer because the root dataset is small. The fact that FLTrust outperforms\nFLTrust-NoReLU, FLTrust-NoNorm, and FLTrust-ParNorm indicates the necessity of our ReLU operation and normalization."
        ]
    },
    "S6.T5": {
        "caption": "TABLE V: The testing error rates of FLTrust under different attacks and the attack success rates of the Scaling attacks when the root dataset is sampled with different bias probabilities in Case II.",
        "table": "<table id=\"S6.T5.sf1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S6.T5.sf1.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf1.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Bias probability</td>\n<td id=\"S6.T5.sf1.1.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.1</td>\n<td id=\"S6.T5.sf1.1.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.2</td>\n<td id=\"S6.T5.sf1.1.1.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.4</td>\n<td id=\"S6.T5.sf1.1.1.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.6</td>\n<td id=\"S6.T5.sf1.1.1.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.8</td>\n<td id=\"S6.T5.sf1.1.1.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">1.0</td>\n</tr>\n<tr id=\"S6.T5.sf1.1.2\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf1.1.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">No attack</td>\n<td id=\"S6.T5.sf1.1.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.04</td>\n<td id=\"S6.T5.sf1.1.2.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.04</td>\n<td id=\"S6.T5.sf1.1.2.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.04</td>\n<td id=\"S6.T5.sf1.1.2.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.05</td>\n<td id=\"S6.T5.sf1.1.2.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.05</td>\n<td id=\"S6.T5.sf1.1.2.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.34</td>\n</tr>\n<tr id=\"S6.T5.sf1.1.3\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf1.1.3.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">LF attack</td>\n<td id=\"S6.T5.sf1.1.3.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.04</td>\n<td id=\"S6.T5.sf1.1.3.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.04</td>\n<td id=\"S6.T5.sf1.1.3.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.04</td>\n<td id=\"S6.T5.sf1.1.3.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.05</td>\n<td id=\"S6.T5.sf1.1.3.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.78</td>\n<td id=\"S6.T5.sf1.1.3.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.84</td>\n</tr>\n<tr id=\"S6.T5.sf1.1.4\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf1.1.4.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Krum attack</td>\n<td id=\"S6.T5.sf1.1.4.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.04</td>\n<td id=\"S6.T5.sf1.1.4.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.04</td>\n<td id=\"S6.T5.sf1.1.4.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.07</td>\n<td id=\"S6.T5.sf1.1.4.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.89</td>\n<td id=\"S6.T5.sf1.1.4.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.89</td>\n<td id=\"S6.T5.sf1.1.4.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.89</td>\n</tr>\n<tr id=\"S6.T5.sf1.1.5\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf1.1.5.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Trim attack</td>\n<td id=\"S6.T5.sf1.1.5.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.04</td>\n<td id=\"S6.T5.sf1.1.5.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.05</td>\n<td id=\"S6.T5.sf1.1.5.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.08</td>\n<td id=\"S6.T5.sf1.1.5.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.12</td>\n<td id=\"S6.T5.sf1.1.5.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.46</td>\n<td id=\"S6.T5.sf1.1.5.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.89</td>\n</tr>\n<tr id=\"S6.T5.sf1.1.6\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf1.1.6.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Scaling attack</td>\n<td id=\"S6.T5.sf1.1.6.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.03 / 0.00</td>\n<td id=\"S6.T5.sf1.1.6.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.03 / 0.01</td>\n<td id=\"S6.T5.sf1.1.6.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.04 / 0.00</td>\n<td id=\"S6.T5.sf1.1.6.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.04 / 0.00</td>\n<td id=\"S6.T5.sf1.1.6.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.06 / 0.01</td>\n<td id=\"S6.T5.sf1.1.6.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.42 / 0.01</td>\n</tr>\n<tr id=\"S6.T5.sf1.1.7\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf1.1.7.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Adaptive attack</td>\n<td id=\"S6.T5.sf1.1.7.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.04</td>\n<td id=\"S6.T5.sf1.1.7.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.05</td>\n<td id=\"S6.T5.sf1.1.7.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.08</td>\n<td id=\"S6.T5.sf1.1.7.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.12</td>\n<td id=\"S6.T5.sf1.1.7.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.90</td>\n<td id=\"S6.T5.sf1.1.7.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.90</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We also evaluate the impact of the bias probability in Case II. Table Vf shows the testing error rates of FLTrust under different attacks and the attack success rates of the Scaling attacks when the bias probability varies. The second column in each table corresponds to the bias probability with which Case II reduces to Case I. We increase the bias probability up to 1.0 to simulate larger difference between the root data distribution and the overall training data distribution. We observe that FLTrust is accurate and robust when the bias probability is not too large. For instance, when the bias probability is no more than 0.4 for MNIST-0.5, the testing error rates of FLTrust under attacks are at most 0.08, compared to 0.05 when the bias probability is 0.1. Our results show that FLTrust works well when the root data distribution does not diverge too much from the overall training data distribution."
        ]
    },
    "S6.T5.sf1": {
        "caption": "(a) MNIST-0.1",
        "table": "<table id=\"S6.T5.sf1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S6.T5.sf1.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf1.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Bias probability</td>\n<td id=\"S6.T5.sf1.1.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.1</td>\n<td id=\"S6.T5.sf1.1.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.2</td>\n<td id=\"S6.T5.sf1.1.1.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.4</td>\n<td id=\"S6.T5.sf1.1.1.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.6</td>\n<td id=\"S6.T5.sf1.1.1.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.8</td>\n<td id=\"S6.T5.sf1.1.1.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">1.0</td>\n</tr>\n<tr id=\"S6.T5.sf1.1.2\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf1.1.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">No attack</td>\n<td id=\"S6.T5.sf1.1.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.04</td>\n<td id=\"S6.T5.sf1.1.2.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.04</td>\n<td id=\"S6.T5.sf1.1.2.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.04</td>\n<td id=\"S6.T5.sf1.1.2.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.05</td>\n<td id=\"S6.T5.sf1.1.2.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.05</td>\n<td id=\"S6.T5.sf1.1.2.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.34</td>\n</tr>\n<tr id=\"S6.T5.sf1.1.3\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf1.1.3.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">LF attack</td>\n<td id=\"S6.T5.sf1.1.3.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.04</td>\n<td id=\"S6.T5.sf1.1.3.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.04</td>\n<td id=\"S6.T5.sf1.1.3.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.04</td>\n<td id=\"S6.T5.sf1.1.3.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.05</td>\n<td id=\"S6.T5.sf1.1.3.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.78</td>\n<td id=\"S6.T5.sf1.1.3.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.84</td>\n</tr>\n<tr id=\"S6.T5.sf1.1.4\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf1.1.4.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Krum attack</td>\n<td id=\"S6.T5.sf1.1.4.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.04</td>\n<td id=\"S6.T5.sf1.1.4.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.04</td>\n<td id=\"S6.T5.sf1.1.4.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.07</td>\n<td id=\"S6.T5.sf1.1.4.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.89</td>\n<td id=\"S6.T5.sf1.1.4.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.89</td>\n<td id=\"S6.T5.sf1.1.4.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.89</td>\n</tr>\n<tr id=\"S6.T5.sf1.1.5\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf1.1.5.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Trim attack</td>\n<td id=\"S6.T5.sf1.1.5.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.04</td>\n<td id=\"S6.T5.sf1.1.5.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.05</td>\n<td id=\"S6.T5.sf1.1.5.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.08</td>\n<td id=\"S6.T5.sf1.1.5.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.12</td>\n<td id=\"S6.T5.sf1.1.5.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.46</td>\n<td id=\"S6.T5.sf1.1.5.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.89</td>\n</tr>\n<tr id=\"S6.T5.sf1.1.6\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf1.1.6.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Scaling attack</td>\n<td id=\"S6.T5.sf1.1.6.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.03 / 0.00</td>\n<td id=\"S6.T5.sf1.1.6.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.03 / 0.01</td>\n<td id=\"S6.T5.sf1.1.6.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.04 / 0.00</td>\n<td id=\"S6.T5.sf1.1.6.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.04 / 0.00</td>\n<td id=\"S6.T5.sf1.1.6.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.06 / 0.01</td>\n<td id=\"S6.T5.sf1.1.6.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.42 / 0.01</td>\n</tr>\n<tr id=\"S6.T5.sf1.1.7\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf1.1.7.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Adaptive attack</td>\n<td id=\"S6.T5.sf1.1.7.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.04</td>\n<td id=\"S6.T5.sf1.1.7.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.05</td>\n<td id=\"S6.T5.sf1.1.7.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.08</td>\n<td id=\"S6.T5.sf1.1.7.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.12</td>\n<td id=\"S6.T5.sf1.1.7.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.90</td>\n<td id=\"S6.T5.sf1.1.7.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.90</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Solving the optimization problem:Â  We use a standard gradient ascent approach to solve the optimization problem. Specifically, we can compute the gradient âˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h of the objective function hâ„h with respect to each ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime} and move ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime} a small step along the gradient. Since the gradient âˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h involves a Jacobian matrix of ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime}, it is not practical to directly compute the gradient. Therefore, we leverage a zeroth-order method [13, 33] to compute the gradient, which is a standard method to solve such optimization problems with computationally intractable objective functions. Specifically, we compute the gradient\nâˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h as follows:",
            "By default, we assume there are n=100ğ‘›100n=100 clients in total for each dataset except HAR and CH-MNIST. For HAR, the data are collected from 30 users, each of which is treated as a client. Therefore, HAR has 30 clients in total. For CH-MNIST, there are only 4,000 training examples in total and thus we assume 40 clients such that each client has 100 training examples on average. Unless otherwise mentioned, we assume 20% of the clients are malicious for each dataset. However, we will also explore the impact of the fraction of malicious clients. Table I shows the default FL system settings that we will use unless otherwise mentioned.",
            "Global models:Â  We train different types of global models on different datasets to show the generality of our method. Specifically, for MNIST-0.1, MNIST-0.5, and Fashion-MNIST, we train a convolutional neural network (CNN) as the global model. Table II shows the architecture of the CNN. And we train a logistic regression (LR) classifier as the global model for HAR. For CIFAR-10 and CH-MNIST, we consider the widely used ResNet20 architecture [19] as the global model.",
            "Our FLTrust achieves the three defense goals:Â  Recall that we have three defense goals (discussed in SectionÂ III): fidelity, robustness, and efficiency. Table IIIf shows the testing error rates of different FL methods under different attacks including our adaptive attack, as well as the attack success rate of the Scaling attack on the six datasets. Our results show that FLTrust achieves the three goals.",
            "Table IV compares the variants with respect to their testing error rates under different attacks and the attack success rates of the Scaling attacks on MNIST-0.5. The attacks are not applicable to FLTrust-Server as it does not require communications from the clients. Our results show that FLTrust outperforms the five variants. FLTrust outperforms FLTrust-Server and FLTrust-withServer because the root dataset is small. The fact that FLTrust outperforms\nFLTrust-NoReLU, FLTrust-NoNorm, and FLTrust-ParNorm indicates the necessity of our ReLU operation and normalization.",
            "We also evaluate the impact of the bias probability in Case II. Table Vf shows the testing error rates of FLTrust under different attacks and the attack success rates of the Scaling attacks when the bias probability varies. The second column in each table corresponds to the bias probability with which Case II reduces to Case I. We increase the bias probability up to 1.0 to simulate larger difference between the root data distribution and the overall training data distribution. We observe that FLTrust is accurate and robust when the bias probability is not too large. For instance, when the bias probability is no more than 0.4 for MNIST-0.5, the testing error rates of FLTrust under attacks are at most 0.08, compared to 0.05 when the bias probability is 0.1. Our results show that FLTrust works well when the root data distribution does not diverge too much from the overall training data distribution."
        ]
    },
    "S6.T5.sf2": {
        "caption": "(b) MNIST-0.5",
        "table": "<table id=\"S6.T5.sf2.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S6.T5.sf2.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf2.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Bias probability</td>\n<td id=\"S6.T5.sf2.1.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.1</td>\n<td id=\"S6.T5.sf2.1.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.2</td>\n<td id=\"S6.T5.sf2.1.1.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.4</td>\n<td id=\"S6.T5.sf2.1.1.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.6</td>\n<td id=\"S6.T5.sf2.1.1.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.8</td>\n<td id=\"S6.T5.sf2.1.1.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">1.0</td>\n</tr>\n<tr id=\"S6.T5.sf2.1.2\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf2.1.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">No attack</td>\n<td id=\"S6.T5.sf2.1.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.05</td>\n<td id=\"S6.T5.sf2.1.2.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.05</td>\n<td id=\"S6.T5.sf2.1.2.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.06</td>\n<td id=\"S6.T5.sf2.1.2.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.08</td>\n<td id=\"S6.T5.sf2.1.2.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.11</td>\n<td id=\"S6.T5.sf2.1.2.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.80</td>\n</tr>\n<tr id=\"S6.T5.sf2.1.3\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf2.1.3.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">LF attack</td>\n<td id=\"S6.T5.sf2.1.3.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.05</td>\n<td id=\"S6.T5.sf2.1.3.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.05</td>\n<td id=\"S6.T5.sf2.1.3.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.08</td>\n<td id=\"S6.T5.sf2.1.3.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.10</td>\n<td id=\"S6.T5.sf2.1.3.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.25</td>\n<td id=\"S6.T5.sf2.1.3.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.89</td>\n</tr>\n<tr id=\"S6.T5.sf2.1.4\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf2.1.4.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Krum attack</td>\n<td id=\"S6.T5.sf2.1.4.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.05</td>\n<td id=\"S6.T5.sf2.1.4.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.05</td>\n<td id=\"S6.T5.sf2.1.4.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.08</td>\n<td id=\"S6.T5.sf2.1.4.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.12</td>\n<td id=\"S6.T5.sf2.1.4.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.86</td>\n<td id=\"S6.T5.sf2.1.4.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.89</td>\n</tr>\n<tr id=\"S6.T5.sf2.1.5\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf2.1.5.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Trim attack</td>\n<td id=\"S6.T5.sf2.1.5.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.06</td>\n<td id=\"S6.T5.sf2.1.5.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.06</td>\n<td id=\"S6.T5.sf2.1.5.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.08</td>\n<td id=\"S6.T5.sf2.1.5.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.12</td>\n<td id=\"S6.T5.sf2.1.5.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.16</td>\n<td id=\"S6.T5.sf2.1.5.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.89</td>\n</tr>\n<tr id=\"S6.T5.sf2.1.6\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf2.1.6.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Scaling attack</td>\n<td id=\"S6.T5.sf2.1.6.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.05 / 0.00</td>\n<td id=\"S6.T5.sf2.1.6.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.05 / 0.01</td>\n<td id=\"S6.T5.sf2.1.6.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.06 / 0.00</td>\n<td id=\"S6.T5.sf2.1.6.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.07 / 0.01</td>\n<td id=\"S6.T5.sf2.1.6.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.12 / 0.00</td>\n<td id=\"S6.T5.sf2.1.6.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.86 / 0.01</td>\n</tr>\n<tr id=\"S6.T5.sf2.1.7\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf2.1.7.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Adaptive attack</td>\n<td id=\"S6.T5.sf2.1.7.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.06</td>\n<td id=\"S6.T5.sf2.1.7.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.07</td>\n<td id=\"S6.T5.sf2.1.7.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.08</td>\n<td id=\"S6.T5.sf2.1.7.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.13</td>\n<td id=\"S6.T5.sf2.1.7.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.90</td>\n<td id=\"S6.T5.sf2.1.7.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.90</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Solving the optimization problem:Â  We use a standard gradient ascent approach to solve the optimization problem. Specifically, we can compute the gradient âˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h of the objective function hâ„h with respect to each ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime} and move ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime} a small step along the gradient. Since the gradient âˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h involves a Jacobian matrix of ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime}, it is not practical to directly compute the gradient. Therefore, we leverage a zeroth-order method [13, 33] to compute the gradient, which is a standard method to solve such optimization problems with computationally intractable objective functions. Specifically, we compute the gradient\nâˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h as follows:",
            "By default, we assume there are n=100ğ‘›100n=100 clients in total for each dataset except HAR and CH-MNIST. For HAR, the data are collected from 30 users, each of which is treated as a client. Therefore, HAR has 30 clients in total. For CH-MNIST, there are only 4,000 training examples in total and thus we assume 40 clients such that each client has 100 training examples on average. Unless otherwise mentioned, we assume 20% of the clients are malicious for each dataset. However, we will also explore the impact of the fraction of malicious clients. Table I shows the default FL system settings that we will use unless otherwise mentioned.",
            "Global models:Â  We train different types of global models on different datasets to show the generality of our method. Specifically, for MNIST-0.1, MNIST-0.5, and Fashion-MNIST, we train a convolutional neural network (CNN) as the global model. Table II shows the architecture of the CNN. And we train a logistic regression (LR) classifier as the global model for HAR. For CIFAR-10 and CH-MNIST, we consider the widely used ResNet20 architecture [19] as the global model.",
            "Our FLTrust achieves the three defense goals:Â  Recall that we have three defense goals (discussed in SectionÂ III): fidelity, robustness, and efficiency. Table IIIf shows the testing error rates of different FL methods under different attacks including our adaptive attack, as well as the attack success rate of the Scaling attack on the six datasets. Our results show that FLTrust achieves the three goals.",
            "Table IV compares the variants with respect to their testing error rates under different attacks and the attack success rates of the Scaling attacks on MNIST-0.5. The attacks are not applicable to FLTrust-Server as it does not require communications from the clients. Our results show that FLTrust outperforms the five variants. FLTrust outperforms FLTrust-Server and FLTrust-withServer because the root dataset is small. The fact that FLTrust outperforms\nFLTrust-NoReLU, FLTrust-NoNorm, and FLTrust-ParNorm indicates the necessity of our ReLU operation and normalization.",
            "We also evaluate the impact of the bias probability in Case II. Table Vf shows the testing error rates of FLTrust under different attacks and the attack success rates of the Scaling attacks when the bias probability varies. The second column in each table corresponds to the bias probability with which Case II reduces to Case I. We increase the bias probability up to 1.0 to simulate larger difference between the root data distribution and the overall training data distribution. We observe that FLTrust is accurate and robust when the bias probability is not too large. For instance, when the bias probability is no more than 0.4 for MNIST-0.5, the testing error rates of FLTrust under attacks are at most 0.08, compared to 0.05 when the bias probability is 0.1. Our results show that FLTrust works well when the root data distribution does not diverge too much from the overall training data distribution."
        ]
    },
    "S6.T5.sf3": {
        "caption": "(c) Fashion-MNIST",
        "table": "<table id=\"S6.T5.sf3.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S6.T5.sf3.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf3.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Bias probability</td>\n<td id=\"S6.T5.sf3.1.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.1</td>\n<td id=\"S6.T5.sf3.1.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.2</td>\n<td id=\"S6.T5.sf3.1.1.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.4</td>\n<td id=\"S6.T5.sf3.1.1.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.6</td>\n<td id=\"S6.T5.sf3.1.1.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.8</td>\n<td id=\"S6.T5.sf3.1.1.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">1.0</td>\n</tr>\n<tr id=\"S6.T5.sf3.1.2\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf3.1.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">No attack</td>\n<td id=\"S6.T5.sf3.1.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.11</td>\n<td id=\"S6.T5.sf3.1.2.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.11</td>\n<td id=\"S6.T5.sf3.1.2.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.12</td>\n<td id=\"S6.T5.sf3.1.2.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.15</td>\n<td id=\"S6.T5.sf3.1.2.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.16</td>\n<td id=\"S6.T5.sf3.1.2.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.90</td>\n</tr>\n<tr id=\"S6.T5.sf3.1.3\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf3.1.3.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">LF attack</td>\n<td id=\"S6.T5.sf3.1.3.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.11</td>\n<td id=\"S6.T5.sf3.1.3.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.11</td>\n<td id=\"S6.T5.sf3.1.3.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.12</td>\n<td id=\"S6.T5.sf3.1.3.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.12</td>\n<td id=\"S6.T5.sf3.1.3.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.14</td>\n<td id=\"S6.T5.sf3.1.3.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.90</td>\n</tr>\n<tr id=\"S6.T5.sf3.1.4\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf3.1.4.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Krum attack</td>\n<td id=\"S6.T5.sf3.1.4.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.12</td>\n<td id=\"S6.T5.sf3.1.4.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.12</td>\n<td id=\"S6.T5.sf3.1.4.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.16</td>\n<td id=\"S6.T5.sf3.1.4.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.90</td>\n<td id=\"S6.T5.sf3.1.4.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.90</td>\n<td id=\"S6.T5.sf3.1.4.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.90</td>\n</tr>\n<tr id=\"S6.T5.sf3.1.5\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf3.1.5.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Trim attack</td>\n<td id=\"S6.T5.sf3.1.5.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.14</td>\n<td id=\"S6.T5.sf3.1.5.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.14</td>\n<td id=\"S6.T5.sf3.1.5.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.15</td>\n<td id=\"S6.T5.sf3.1.5.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.21</td>\n<td id=\"S6.T5.sf3.1.5.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.90</td>\n<td id=\"S6.T5.sf3.1.5.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.90</td>\n</tr>\n<tr id=\"S6.T5.sf3.1.6\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf3.1.6.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Scaling attack</td>\n<td id=\"S6.T5.sf3.1.6.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.11 / 0.02</td>\n<td id=\"S6.T5.sf3.1.6.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.12 / 0.04</td>\n<td id=\"S6.T5.sf3.1.6.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.12 / 0.04</td>\n<td id=\"S6.T5.sf3.1.6.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.13 / 0.02</td>\n<td id=\"S6.T5.sf3.1.6.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.15 / 0.03</td>\n<td id=\"S6.T5.sf3.1.6.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.90 / 0.00</td>\n</tr>\n<tr id=\"S6.T5.sf3.1.7\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf3.1.7.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Adaptive attack</td>\n<td id=\"S6.T5.sf3.1.7.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.14</td>\n<td id=\"S6.T5.sf3.1.7.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.14</td>\n<td id=\"S6.T5.sf3.1.7.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.16</td>\n<td id=\"S6.T5.sf3.1.7.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.90</td>\n<td id=\"S6.T5.sf3.1.7.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.90</td>\n<td id=\"S6.T5.sf3.1.7.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.90</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Solving the optimization problem:Â  We use a standard gradient ascent approach to solve the optimization problem. Specifically, we can compute the gradient âˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h of the objective function hâ„h with respect to each ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime} and move ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime} a small step along the gradient. Since the gradient âˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h involves a Jacobian matrix of ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime}, it is not practical to directly compute the gradient. Therefore, we leverage a zeroth-order method [13, 33] to compute the gradient, which is a standard method to solve such optimization problems with computationally intractable objective functions. Specifically, we compute the gradient\nâˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h as follows:",
            "By default, we assume there are n=100ğ‘›100n=100 clients in total for each dataset except HAR and CH-MNIST. For HAR, the data are collected from 30 users, each of which is treated as a client. Therefore, HAR has 30 clients in total. For CH-MNIST, there are only 4,000 training examples in total and thus we assume 40 clients such that each client has 100 training examples on average. Unless otherwise mentioned, we assume 20% of the clients are malicious for each dataset. However, we will also explore the impact of the fraction of malicious clients. Table I shows the default FL system settings that we will use unless otherwise mentioned.",
            "Global models:Â  We train different types of global models on different datasets to show the generality of our method. Specifically, for MNIST-0.1, MNIST-0.5, and Fashion-MNIST, we train a convolutional neural network (CNN) as the global model. Table II shows the architecture of the CNN. And we train a logistic regression (LR) classifier as the global model for HAR. For CIFAR-10 and CH-MNIST, we consider the widely used ResNet20 architecture [19] as the global model.",
            "Our FLTrust achieves the three defense goals:Â  Recall that we have three defense goals (discussed in SectionÂ III): fidelity, robustness, and efficiency. Table IIIf shows the testing error rates of different FL methods under different attacks including our adaptive attack, as well as the attack success rate of the Scaling attack on the six datasets. Our results show that FLTrust achieves the three goals.",
            "Table IV compares the variants with respect to their testing error rates under different attacks and the attack success rates of the Scaling attacks on MNIST-0.5. The attacks are not applicable to FLTrust-Server as it does not require communications from the clients. Our results show that FLTrust outperforms the five variants. FLTrust outperforms FLTrust-Server and FLTrust-withServer because the root dataset is small. The fact that FLTrust outperforms\nFLTrust-NoReLU, FLTrust-NoNorm, and FLTrust-ParNorm indicates the necessity of our ReLU operation and normalization.",
            "We also evaluate the impact of the bias probability in Case II. Table Vf shows the testing error rates of FLTrust under different attacks and the attack success rates of the Scaling attacks when the bias probability varies. The second column in each table corresponds to the bias probability with which Case II reduces to Case I. We increase the bias probability up to 1.0 to simulate larger difference between the root data distribution and the overall training data distribution. We observe that FLTrust is accurate and robust when the bias probability is not too large. For instance, when the bias probability is no more than 0.4 for MNIST-0.5, the testing error rates of FLTrust under attacks are at most 0.08, compared to 0.05 when the bias probability is 0.1. Our results show that FLTrust works well when the root data distribution does not diverge too much from the overall training data distribution."
        ]
    },
    "S6.T5.sf4": {
        "caption": "(d) CIFAR-10",
        "table": "<table id=\"S6.T5.sf4.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S6.T5.sf4.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf4.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Bias probability</td>\n<td id=\"S6.T5.sf4.1.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.1</td>\n<td id=\"S6.T5.sf4.1.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.2</td>\n<td id=\"S6.T5.sf4.1.1.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.4</td>\n<td id=\"S6.T5.sf4.1.1.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.6</td>\n<td id=\"S6.T5.sf4.1.1.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.8</td>\n<td id=\"S6.T5.sf4.1.1.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">1.0</td>\n</tr>\n<tr id=\"S6.T5.sf4.1.2\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf4.1.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">No attack</td>\n<td id=\"S6.T5.sf4.1.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.18</td>\n<td id=\"S6.T5.sf4.1.2.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.18</td>\n<td id=\"S6.T5.sf4.1.2.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.18</td>\n<td id=\"S6.T5.sf4.1.2.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.21</td>\n<td id=\"S6.T5.sf4.1.2.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.90</td>\n<td id=\"S6.T5.sf4.1.2.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.90</td>\n</tr>\n<tr id=\"S6.T5.sf4.1.3\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf4.1.3.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">LF attack</td>\n<td id=\"S6.T5.sf4.1.3.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.18</td>\n<td id=\"S6.T5.sf4.1.3.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.19</td>\n<td id=\"S6.T5.sf4.1.3.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.20</td>\n<td id=\"S6.T5.sf4.1.3.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.24</td>\n<td id=\"S6.T5.sf4.1.3.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.90</td>\n<td id=\"S6.T5.sf4.1.3.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.90</td>\n</tr>\n<tr id=\"S6.T5.sf4.1.4\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf4.1.4.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Krum attack</td>\n<td id=\"S6.T5.sf4.1.4.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.18</td>\n<td id=\"S6.T5.sf4.1.4.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.18</td>\n<td id=\"S6.T5.sf4.1.4.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.19</td>\n<td id=\"S6.T5.sf4.1.4.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.33</td>\n<td id=\"S6.T5.sf4.1.4.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.90</td>\n<td id=\"S6.T5.sf4.1.4.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.90</td>\n</tr>\n<tr id=\"S6.T5.sf4.1.5\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf4.1.5.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Trim attack</td>\n<td id=\"S6.T5.sf4.1.5.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.20</td>\n<td id=\"S6.T5.sf4.1.5.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.20</td>\n<td id=\"S6.T5.sf4.1.5.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.24</td>\n<td id=\"S6.T5.sf4.1.5.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.63</td>\n<td id=\"S6.T5.sf4.1.5.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.90</td>\n<td id=\"S6.T5.sf4.1.5.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.90</td>\n</tr>\n<tr id=\"S6.T5.sf4.1.6\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf4.1.6.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Scaling attack</td>\n<td id=\"S6.T5.sf4.1.6.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.18 / 0.02</td>\n<td id=\"S6.T5.sf4.1.6.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.18 / 0.00</td>\n<td id=\"S6.T5.sf4.1.6.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.18 / 0.03</td>\n<td id=\"S6.T5.sf4.1.6.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.22 / 0.04</td>\n<td id=\"S6.T5.sf4.1.6.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.90 / 0.00</td>\n<td id=\"S6.T5.sf4.1.6.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.90 / 0.00</td>\n</tr>\n<tr id=\"S6.T5.sf4.1.7\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf4.1.7.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Adaptive attack</td>\n<td id=\"S6.T5.sf4.1.7.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.20</td>\n<td id=\"S6.T5.sf4.1.7.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.20</td>\n<td id=\"S6.T5.sf4.1.7.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.27</td>\n<td id=\"S6.T5.sf4.1.7.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.68</td>\n<td id=\"S6.T5.sf4.1.7.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.90</td>\n<td id=\"S6.T5.sf4.1.7.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.90</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Solving the optimization problem:Â  We use a standard gradient ascent approach to solve the optimization problem. Specifically, we can compute the gradient âˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h of the objective function hâ„h with respect to each ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime} and move ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime} a small step along the gradient. Since the gradient âˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h involves a Jacobian matrix of ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime}, it is not practical to directly compute the gradient. Therefore, we leverage a zeroth-order method [13, 33] to compute the gradient, which is a standard method to solve such optimization problems with computationally intractable objective functions. Specifically, we compute the gradient\nâˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h as follows:",
            "By default, we assume there are n=100ğ‘›100n=100 clients in total for each dataset except HAR and CH-MNIST. For HAR, the data are collected from 30 users, each of which is treated as a client. Therefore, HAR has 30 clients in total. For CH-MNIST, there are only 4,000 training examples in total and thus we assume 40 clients such that each client has 100 training examples on average. Unless otherwise mentioned, we assume 20% of the clients are malicious for each dataset. However, we will also explore the impact of the fraction of malicious clients. Table I shows the default FL system settings that we will use unless otherwise mentioned.",
            "Global models:Â  We train different types of global models on different datasets to show the generality of our method. Specifically, for MNIST-0.1, MNIST-0.5, and Fashion-MNIST, we train a convolutional neural network (CNN) as the global model. Table II shows the architecture of the CNN. And we train a logistic regression (LR) classifier as the global model for HAR. For CIFAR-10 and CH-MNIST, we consider the widely used ResNet20 architecture [19] as the global model.",
            "Our FLTrust achieves the three defense goals:Â  Recall that we have three defense goals (discussed in SectionÂ III): fidelity, robustness, and efficiency. Table IIIf shows the testing error rates of different FL methods under different attacks including our adaptive attack, as well as the attack success rate of the Scaling attack on the six datasets. Our results show that FLTrust achieves the three goals.",
            "Table IV compares the variants with respect to their testing error rates under different attacks and the attack success rates of the Scaling attacks on MNIST-0.5. The attacks are not applicable to FLTrust-Server as it does not require communications from the clients. Our results show that FLTrust outperforms the five variants. FLTrust outperforms FLTrust-Server and FLTrust-withServer because the root dataset is small. The fact that FLTrust outperforms\nFLTrust-NoReLU, FLTrust-NoNorm, and FLTrust-ParNorm indicates the necessity of our ReLU operation and normalization.",
            "We also evaluate the impact of the bias probability in Case II. Table Vf shows the testing error rates of FLTrust under different attacks and the attack success rates of the Scaling attacks when the bias probability varies. The second column in each table corresponds to the bias probability with which Case II reduces to Case I. We increase the bias probability up to 1.0 to simulate larger difference between the root data distribution and the overall training data distribution. We observe that FLTrust is accurate and robust when the bias probability is not too large. For instance, when the bias probability is no more than 0.4 for MNIST-0.5, the testing error rates of FLTrust under attacks are at most 0.08, compared to 0.05 when the bias probability is 0.1. Our results show that FLTrust works well when the root data distribution does not diverge too much from the overall training data distribution."
        ]
    },
    "S6.T5.sf5": {
        "caption": "(e) HAR",
        "table": "<table id=\"S6.T5.sf5.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S6.T5.sf5.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf5.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Bias probability</td>\n<td id=\"S6.T5.sf5.1.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.17</td>\n<td id=\"S6.T5.sf5.1.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.2</td>\n<td id=\"S6.T5.sf5.1.1.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.4</td>\n<td id=\"S6.T5.sf5.1.1.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.6</td>\n<td id=\"S6.T5.sf5.1.1.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.8</td>\n<td id=\"S6.T5.sf5.1.1.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">1.0</td>\n</tr>\n<tr id=\"S6.T5.sf5.1.2\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf5.1.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">No attack</td>\n<td id=\"S6.T5.sf5.1.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.04</td>\n<td id=\"S6.T5.sf5.1.2.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.04</td>\n<td id=\"S6.T5.sf5.1.2.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.06</td>\n<td id=\"S6.T5.sf5.1.2.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.06</td>\n<td id=\"S6.T5.sf5.1.2.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.07</td>\n<td id=\"S6.T5.sf5.1.2.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.48</td>\n</tr>\n<tr id=\"S6.T5.sf5.1.3\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf5.1.3.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">LF attack</td>\n<td id=\"S6.T5.sf5.1.3.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.04</td>\n<td id=\"S6.T5.sf5.1.3.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.05</td>\n<td id=\"S6.T5.sf5.1.3.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.06</td>\n<td id=\"S6.T5.sf5.1.3.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.05</td>\n<td id=\"S6.T5.sf5.1.3.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.07</td>\n<td id=\"S6.T5.sf5.1.3.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.48</td>\n</tr>\n<tr id=\"S6.T5.sf5.1.4\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf5.1.4.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Krum attack</td>\n<td id=\"S6.T5.sf5.1.4.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.04</td>\n<td id=\"S6.T5.sf5.1.4.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.05</td>\n<td id=\"S6.T5.sf5.1.4.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.05</td>\n<td id=\"S6.T5.sf5.1.4.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.05</td>\n<td id=\"S6.T5.sf5.1.4.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.09</td>\n<td id=\"S6.T5.sf5.1.4.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.48</td>\n</tr>\n<tr id=\"S6.T5.sf5.1.5\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf5.1.5.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Trim attack</td>\n<td id=\"S6.T5.sf5.1.5.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.05</td>\n<td id=\"S6.T5.sf5.1.5.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.05</td>\n<td id=\"S6.T5.sf5.1.5.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.06</td>\n<td id=\"S6.T5.sf5.1.5.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.09</td>\n<td id=\"S6.T5.sf5.1.5.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.14</td>\n<td id=\"S6.T5.sf5.1.5.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.48</td>\n</tr>\n<tr id=\"S6.T5.sf5.1.6\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf5.1.6.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Scaling attack</td>\n<td id=\"S6.T5.sf5.1.6.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.05 / 0.01</td>\n<td id=\"S6.T5.sf5.1.6.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.05 / 0.01</td>\n<td id=\"S6.T5.sf5.1.6.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.06 / 0.02</td>\n<td id=\"S6.T5.sf5.1.6.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.06 / 0.03</td>\n<td id=\"S6.T5.sf5.1.6.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.07 / 0.05</td>\n<td id=\"S6.T5.sf5.1.6.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.48 / 0.34</td>\n</tr>\n<tr id=\"S6.T5.sf5.1.7\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf5.1.7.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Adaptive attack</td>\n<td id=\"S6.T5.sf5.1.7.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.05</td>\n<td id=\"S6.T5.sf5.1.7.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.05</td>\n<td id=\"S6.T5.sf5.1.7.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.06</td>\n<td id=\"S6.T5.sf5.1.7.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.09</td>\n<td id=\"S6.T5.sf5.1.7.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.48</td>\n<td id=\"S6.T5.sf5.1.7.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.48</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Solving the optimization problem:Â  We use a standard gradient ascent approach to solve the optimization problem. Specifically, we can compute the gradient âˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h of the objective function hâ„h with respect to each ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime} and move ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime} a small step along the gradient. Since the gradient âˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h involves a Jacobian matrix of ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime}, it is not practical to directly compute the gradient. Therefore, we leverage a zeroth-order method [13, 33] to compute the gradient, which is a standard method to solve such optimization problems with computationally intractable objective functions. Specifically, we compute the gradient\nâˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h as follows:",
            "By default, we assume there are n=100ğ‘›100n=100 clients in total for each dataset except HAR and CH-MNIST. For HAR, the data are collected from 30 users, each of which is treated as a client. Therefore, HAR has 30 clients in total. For CH-MNIST, there are only 4,000 training examples in total and thus we assume 40 clients such that each client has 100 training examples on average. Unless otherwise mentioned, we assume 20% of the clients are malicious for each dataset. However, we will also explore the impact of the fraction of malicious clients. Table I shows the default FL system settings that we will use unless otherwise mentioned.",
            "Global models:Â  We train different types of global models on different datasets to show the generality of our method. Specifically, for MNIST-0.1, MNIST-0.5, and Fashion-MNIST, we train a convolutional neural network (CNN) as the global model. Table II shows the architecture of the CNN. And we train a logistic regression (LR) classifier as the global model for HAR. For CIFAR-10 and CH-MNIST, we consider the widely used ResNet20 architecture [19] as the global model.",
            "Our FLTrust achieves the three defense goals:Â  Recall that we have three defense goals (discussed in SectionÂ III): fidelity, robustness, and efficiency. Table IIIf shows the testing error rates of different FL methods under different attacks including our adaptive attack, as well as the attack success rate of the Scaling attack on the six datasets. Our results show that FLTrust achieves the three goals.",
            "Table IV compares the variants with respect to their testing error rates under different attacks and the attack success rates of the Scaling attacks on MNIST-0.5. The attacks are not applicable to FLTrust-Server as it does not require communications from the clients. Our results show that FLTrust outperforms the five variants. FLTrust outperforms FLTrust-Server and FLTrust-withServer because the root dataset is small. The fact that FLTrust outperforms\nFLTrust-NoReLU, FLTrust-NoNorm, and FLTrust-ParNorm indicates the necessity of our ReLU operation and normalization.",
            "We also evaluate the impact of the bias probability in Case II. Table Vf shows the testing error rates of FLTrust under different attacks and the attack success rates of the Scaling attacks when the bias probability varies. The second column in each table corresponds to the bias probability with which Case II reduces to Case I. We increase the bias probability up to 1.0 to simulate larger difference between the root data distribution and the overall training data distribution. We observe that FLTrust is accurate and robust when the bias probability is not too large. For instance, when the bias probability is no more than 0.4 for MNIST-0.5, the testing error rates of FLTrust under attacks are at most 0.08, compared to 0.05 when the bias probability is 0.1. Our results show that FLTrust works well when the root data distribution does not diverge too much from the overall training data distribution."
        ]
    },
    "S6.T5.sf6": {
        "caption": "(f) CH-MNIST",
        "table": "<table id=\"S6.T5.sf6.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S6.T5.sf6.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf6.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Bias probability</td>\n<td id=\"S6.T5.sf6.1.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.125</td>\n<td id=\"S6.T5.sf6.1.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.2</td>\n<td id=\"S6.T5.sf6.1.1.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.4</td>\n<td id=\"S6.T5.sf6.1.1.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.6</td>\n<td id=\"S6.T5.sf6.1.1.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.8</td>\n<td id=\"S6.T5.sf6.1.1.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">1.0</td>\n</tr>\n<tr id=\"S6.T5.sf6.1.2\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf6.1.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">No attack</td>\n<td id=\"S6.T5.sf6.1.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.10</td>\n<td id=\"S6.T5.sf6.1.2.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.10</td>\n<td id=\"S6.T5.sf6.1.2.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.11</td>\n<td id=\"S6.T5.sf6.1.2.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.13</td>\n<td id=\"S6.T5.sf6.1.2.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.13</td>\n<td id=\"S6.T5.sf6.1.2.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.89</td>\n</tr>\n<tr id=\"S6.T5.sf6.1.3\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf6.1.3.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">LF attack</td>\n<td id=\"S6.T5.sf6.1.3.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.12</td>\n<td id=\"S6.T5.sf6.1.3.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.12</td>\n<td id=\"S6.T5.sf6.1.3.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.12</td>\n<td id=\"S6.T5.sf6.1.3.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.17</td>\n<td id=\"S6.T5.sf6.1.3.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.21</td>\n<td id=\"S6.T5.sf6.1.3.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.89</td>\n</tr>\n<tr id=\"S6.T5.sf6.1.4\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf6.1.4.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Krum attack</td>\n<td id=\"S6.T5.sf6.1.4.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.12</td>\n<td id=\"S6.T5.sf6.1.4.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.12</td>\n<td id=\"S6.T5.sf6.1.4.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.14</td>\n<td id=\"S6.T5.sf6.1.4.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.17</td>\n<td id=\"S6.T5.sf6.1.4.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.19</td>\n<td id=\"S6.T5.sf6.1.4.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.89</td>\n</tr>\n<tr id=\"S6.T5.sf6.1.5\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf6.1.5.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Trim attack</td>\n<td id=\"S6.T5.sf6.1.5.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.13</td>\n<td id=\"S6.T5.sf6.1.5.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.13</td>\n<td id=\"S6.T5.sf6.1.5.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.14</td>\n<td id=\"S6.T5.sf6.1.5.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.20</td>\n<td id=\"S6.T5.sf6.1.5.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.20</td>\n<td id=\"S6.T5.sf6.1.5.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.89</td>\n</tr>\n<tr id=\"S6.T5.sf6.1.6\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf6.1.6.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Scaling attack</td>\n<td id=\"S6.T5.sf6.1.6.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.14 / 0.03</td>\n<td id=\"S6.T5.sf6.1.6.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.14 / 0.02</td>\n<td id=\"S6.T5.sf6.1.6.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.15 / 0.02</td>\n<td id=\"S6.T5.sf6.1.6.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.16 / 0.06</td>\n<td id=\"S6.T5.sf6.1.6.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.14 / 0.01</td>\n<td id=\"S6.T5.sf6.1.6.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.89 / 0.01</td>\n</tr>\n<tr id=\"S6.T5.sf6.1.7\" class=\"ltx_tr\">\n<td id=\"S6.T5.sf6.1.7.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">Adaptive attack</td>\n<td id=\"S6.T5.sf6.1.7.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.13</td>\n<td id=\"S6.T5.sf6.1.7.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.14</td>\n<td id=\"S6.T5.sf6.1.7.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.14</td>\n<td id=\"S6.T5.sf6.1.7.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.89</td>\n<td id=\"S6.T5.sf6.1.7.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.89</td>\n<td id=\"S6.T5.sf6.1.7.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" style=\"padding:0.5pt 1.0pt;\">0.89</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Solving the optimization problem:Â  We use a standard gradient ascent approach to solve the optimization problem. Specifically, we can compute the gradient âˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h of the objective function hâ„h with respect to each ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime} and move ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime} a small step along the gradient. Since the gradient âˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h involves a Jacobian matrix of ğ’†iâ€²superscriptsubscriptğ’†ğ‘–â€²\\bm{e}_{i}^{\\prime}, it is not practical to directly compute the gradient. Therefore, we leverage a zeroth-order method [13, 33] to compute the gradient, which is a standard method to solve such optimization problems with computationally intractable objective functions. Specifically, we compute the gradient\nâˆ‡ğ’†iâ€²hsubscriptâˆ‡superscriptsubscriptğ’†ğ‘–â€²â„\\nabla_{\\bm{e}_{i}^{\\prime}}h as follows:",
            "By default, we assume there are n=100ğ‘›100n=100 clients in total for each dataset except HAR and CH-MNIST. For HAR, the data are collected from 30 users, each of which is treated as a client. Therefore, HAR has 30 clients in total. For CH-MNIST, there are only 4,000 training examples in total and thus we assume 40 clients such that each client has 100 training examples on average. Unless otherwise mentioned, we assume 20% of the clients are malicious for each dataset. However, we will also explore the impact of the fraction of malicious clients. Table I shows the default FL system settings that we will use unless otherwise mentioned.",
            "Global models:Â  We train different types of global models on different datasets to show the generality of our method. Specifically, for MNIST-0.1, MNIST-0.5, and Fashion-MNIST, we train a convolutional neural network (CNN) as the global model. Table II shows the architecture of the CNN. And we train a logistic regression (LR) classifier as the global model for HAR. For CIFAR-10 and CH-MNIST, we consider the widely used ResNet20 architecture [19] as the global model.",
            "Our FLTrust achieves the three defense goals:Â  Recall that we have three defense goals (discussed in SectionÂ III): fidelity, robustness, and efficiency. Table IIIf shows the testing error rates of different FL methods under different attacks including our adaptive attack, as well as the attack success rate of the Scaling attack on the six datasets. Our results show that FLTrust achieves the three goals.",
            "Table IV compares the variants with respect to their testing error rates under different attacks and the attack success rates of the Scaling attacks on MNIST-0.5. The attacks are not applicable to FLTrust-Server as it does not require communications from the clients. Our results show that FLTrust outperforms the five variants. FLTrust outperforms FLTrust-Server and FLTrust-withServer because the root dataset is small. The fact that FLTrust outperforms\nFLTrust-NoReLU, FLTrust-NoNorm, and FLTrust-ParNorm indicates the necessity of our ReLU operation and normalization.",
            "We also evaluate the impact of the bias probability in Case II. Table Vf shows the testing error rates of FLTrust under different attacks and the attack success rates of the Scaling attacks when the bias probability varies. The second column in each table corresponds to the bias probability with which Case II reduces to Case I. We increase the bias probability up to 1.0 to simulate larger difference between the root data distribution and the overall training data distribution. We observe that FLTrust is accurate and robust when the bias probability is not too large. For instance, when the bias probability is no more than 0.4 for MNIST-0.5, the testing error rates of FLTrust under attacks are at most 0.08, compared to 0.05 when the bias probability is 0.1. Our results show that FLTrust works well when the root data distribution does not diverge too much from the overall training data distribution."
        ]
    }
}