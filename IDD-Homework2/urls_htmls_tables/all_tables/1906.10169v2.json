{
    "S4.T1": {
        "caption": "Table 1: State-of-the-art results on VQA-CP v2 test. All reported models use the same features from [15]. Models with * have been trained by [25]. Models with ** have been trained by [45].",
        "table": "",
        "footnotes": "",
        "references": [
            "In TableÂ 1, we compare our approach consisting of our baseline architecture trained with RUBi on VQA-CP v2 against the state of the art. To be fair, we only report approaches that use the strong visual features from [15]. We compute the average accuracy over 5 experiments with different random seeds.\nOur RUBi approach reaches an average overall accuracy of 47.11% with a low standard deviation of Â±plus-or-minus\\pm0.51. This accuracy corresponds to a gain of +5.94 percentage points over the current state-of-the-art UpDn + Q-Adv + DoE.\nIt also corresponds to a gain of +15.88 over GVQA [10], which is a specific architecture designed for VQA-CP.\nRUBi reaches a +8.65 improvement over our baseline model trained with the classical cross-entropy. In comparison, the second best approach UpDn + Q-Adv + DoE only achieves a +1.43 gain in overall accuracy over their baseline UpDn. In addition, our approach does not significantly reduce the accuracy over our baseline for the answer type Other, while the second best approach reduces it by 10.57 point."
        ]
    },
    "S4.T3": {
        "caption": "Table 2: Effectiveness of the RUBi learning strategy when used on different architectures on VQA-CP v2 test. Detailed results can be found in the supplementary materials.",
        "table": "<table id=\"S4.T3.fig1.4\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.fig1.4.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.fig1.4.1.1.1\" class=\"ltx_td ltx_align_center\" style=\"padding:0.55pt 3.0pt;\">\n<table id=\"S4.T3.fig1.4.1.1.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T3.fig1.4.1.1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.fig1.4.1.1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_tt\" style=\"padding:0.55pt 3.0pt;\">SAN</td>\n<td id=\"S4.T3.fig1.4.1.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding:0.55pt 3.0pt;\">Overall</td>\n</tr>\n<tr id=\"S4.T3.fig1.4.1.1.1.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T3.fig1.4.1.1.1.1.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding:0.55pt 3.0pt;\">Baseline <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib26\" title=\"\" class=\"ltx_ref\">26</a>]</cite>\n</td>\n<td id=\"S4.T3.fig1.4.1.1.1.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.55pt 3.0pt;\">24.96</td>\n</tr>\n<tr id=\"S4.T3.fig1.4.1.1.1.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T3.fig1.4.1.1.1.1.3.1\" class=\"ltx_td ltx_align_left\" style=\"padding:0.55pt 3.0pt;\">+ Q-Adv + DoE <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib25\" title=\"\" class=\"ltx_ref\">25</a>]</cite>\n</td>\n<td id=\"S4.T3.fig1.4.1.1.1.1.3.2\" class=\"ltx_td ltx_align_center\" style=\"padding:0.55pt 3.0pt;\">33.29</td>\n</tr>\n<tr id=\"S4.T3.fig1.4.1.1.1.1.4\" class=\"ltx_tr\">\n<td id=\"S4.T3.fig1.4.1.1.1.1.4.1\" class=\"ltx_td ltx_align_left ltx_border_bb\" style=\"padding:0.55pt 3.0pt;\">+ RUBi (ours)</td>\n<td id=\"S4.T3.fig1.4.1.1.1.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding:0.55pt 3.0pt;\">37.63</td>\n</tr>\n</table>\n\n<table id=\"S4.T3.fig1.4.1.1.1.2\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T3.fig1.4.1.1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.fig1.4.1.1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_tt\" style=\"padding:0.55pt 3.0pt;\">UpDn</td>\n<td id=\"S4.T3.fig1.4.1.1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding:0.55pt 3.0pt;\">Overall</td>\n</tr>\n<tr id=\"S4.T3.fig1.4.1.1.1.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T3.fig1.4.1.1.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding:0.55pt 3.0pt;\">Baseline <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib15\" title=\"\" class=\"ltx_ref\">15</a>]</cite>\n</td>\n<td id=\"S4.T3.fig1.4.1.1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.55pt 3.0pt;\">39.74</td>\n</tr>\n<tr id=\"S4.T3.fig1.4.1.1.1.2.3\" class=\"ltx_tr\">\n<td id=\"S4.T3.fig1.4.1.1.1.2.3.1\" class=\"ltx_td ltx_align_left\" style=\"padding:0.55pt 3.0pt;\">+ Q-Adv + DoE <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib25\" title=\"\" class=\"ltx_ref\">25</a>]</cite>\n</td>\n<td id=\"S4.T3.fig1.4.1.1.1.2.3.2\" class=\"ltx_td ltx_align_center\" style=\"padding:0.55pt 3.0pt;\">41.17</td>\n</tr>\n<tr id=\"S4.T3.fig1.4.1.1.1.2.4\" class=\"ltx_tr\">\n<td id=\"S4.T3.fig1.4.1.1.1.2.4.1\" class=\"ltx_td ltx_align_left ltx_border_bb\" style=\"padding:0.55pt 3.0pt;\">+ RUBi (ours)</td>\n<td id=\"S4.T3.fig1.4.1.1.1.2.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding:0.55pt 3.0pt;\"><span id=\"S4.T3.fig1.4.1.1.1.2.4.2.1\" class=\"ltx_text ltx_font_bold\">44.23</span></td>\n</tr>\n</table>\n</td>\n</tr>\n</tbody>\n</table>\n<table id=\"S4.T3.fig1.4.1.1.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T3.fig1.4.1.1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.fig1.4.1.1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_tt\" style=\"padding:0.55pt 3.0pt;\">SAN</td>\n<td id=\"S4.T3.fig1.4.1.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding:0.55pt 3.0pt;\">Overall</td>\n</tr>\n<tr id=\"S4.T3.fig1.4.1.1.1.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T3.fig1.4.1.1.1.1.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding:0.55pt 3.0pt;\">Baseline <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib26\" title=\"\" class=\"ltx_ref\">26</a>]</cite>\n</td>\n<td id=\"S4.T3.fig1.4.1.1.1.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.55pt 3.0pt;\">24.96</td>\n</tr>\n<tr id=\"S4.T3.fig1.4.1.1.1.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T3.fig1.4.1.1.1.1.3.1\" class=\"ltx_td ltx_align_left\" style=\"padding:0.55pt 3.0pt;\">+ Q-Adv + DoE <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib25\" title=\"\" class=\"ltx_ref\">25</a>]</cite>\n</td>\n<td id=\"S4.T3.fig1.4.1.1.1.1.3.2\" class=\"ltx_td ltx_align_center\" style=\"padding:0.55pt 3.0pt;\">33.29</td>\n</tr>\n<tr id=\"S4.T3.fig1.4.1.1.1.1.4\" class=\"ltx_tr\">\n<td id=\"S4.T3.fig1.4.1.1.1.1.4.1\" class=\"ltx_td ltx_align_left ltx_border_bb\" style=\"padding:0.55pt 3.0pt;\">+ RUBi (ours)</td>\n<td id=\"S4.T3.fig1.4.1.1.1.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding:0.55pt 3.0pt;\">37.63</td>\n</tr>\n</table>\n\n<table id=\"S4.T3.fig1.4.1.1.1.2\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T3.fig1.4.1.1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.fig1.4.1.1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_tt\" style=\"padding:0.55pt 3.0pt;\">UpDn</td>\n<td id=\"S4.T3.fig1.4.1.1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding:0.55pt 3.0pt;\">Overall</td>\n</tr>\n<tr id=\"S4.T3.fig1.4.1.1.1.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T3.fig1.4.1.1.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\" style=\"padding:0.55pt 3.0pt;\">Baseline <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib15\" title=\"\" class=\"ltx_ref\">15</a>]</cite>\n</td>\n<td id=\"S4.T3.fig1.4.1.1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:0.55pt 3.0pt;\">39.74</td>\n</tr>\n<tr id=\"S4.T3.fig1.4.1.1.1.2.3\" class=\"ltx_tr\">\n<td id=\"S4.T3.fig1.4.1.1.1.2.3.1\" class=\"ltx_td ltx_align_left\" style=\"padding:0.55pt 3.0pt;\">+ Q-Adv + DoE <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib25\" title=\"\" class=\"ltx_ref\">25</a>]</cite>\n</td>\n<td id=\"S4.T3.fig1.4.1.1.1.2.3.2\" class=\"ltx_td ltx_align_center\" style=\"padding:0.55pt 3.0pt;\">41.17</td>\n</tr>\n<tr id=\"S4.T3.fig1.4.1.1.1.2.4\" class=\"ltx_tr\">\n<td id=\"S4.T3.fig1.4.1.1.1.2.4.1\" class=\"ltx_td ltx_align_left ltx_border_bb\" style=\"padding:0.55pt 3.0pt;\">+ RUBi (ours)</td>\n<td id=\"S4.T3.fig1.4.1.1.1.2.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding:0.55pt 3.0pt;\"><span id=\"S4.T3.fig1.4.1.1.1.2.4.2.1\" class=\"ltx_text ltx_font_bold\">44.23</span></td>\n</tr>\n</table>\n",
        "footnotes": "",
        "references": [
            "RUBi can be used on existing VQA models without changing the underlying architecture. In TableÂ 3, we experimentally demonstrate the generality and effectiveness of our learning scheme by showing results on two additional architectures, Stacked Attention Networks (SAN) [26] and Bottom-Up and Top-Down Attention (UpDn) [15].\nFirst, we show that applying RUBi on these architectures leads to important gains over the baselines trained with their original learning strategy.\nWe report a gain of +11.73 accuracy point for SAN and +4.5 for UpDn. This lower gap in accuracy may show that UpDn is less driven by biases than SAN. This is consistent with results from [25].\nSecondly, we show that these architectures trained with RUBi obtain better accuracy than with the state-of-the-art strategy from [25]. We report a gain of +3.4 with SAN + RUBi over SAN + Q-Adv + DoE, and +3.06 with UpDn + RUBi over UpDn + Q-Adv + DoE. Full results splitted by question type are available in the supplementary materials.",
            "We report the impact of our method on the standard VQA v2 dataset in TableÂ 3. VQA v2 train, val and test sets follow the same distribution, contrarily to VQA-CP v2 train and test sets.\nIn this context, we usually observe a drop in accuracy using approaches focused on reducing biases. This is due to the fact that exploiting unwanted correlations from the VQA v2 train set is not discouraged and often leads to a higher accuracy on the test set.\nNevertheless, our RUBi approach leads to a comparable drop to what can be seen in the state-of-the-art.\nWe report a drop of 1.94 percentage points with respect to our baseline, while [10] report a drop of 3.78 between GVQA and their SAN baseline. [25] report drops of 0.05, 0.73 and 2.95 for their three learning strategies with the UpDn architecture which uses the same visual features as RUBi.\nAs shown in this section, RUBi improves the accuracy on VQA-CP v2 from a large margin, while maintaining competitive performance on the standard VQA v2 dataset compared to similar approaches."
        ]
    },
    "S4.T4": {
        "caption": "Table 4: Ablation study of the question-only loss â„’Qâ€‹Osubscriptâ„’ğ‘„ğ‘‚\\mathcal{L}_{QO} on VQA-CP v2.",
        "table": "<table id=\"S4.T4.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T4.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Model</th>\n<th id=\"S4.T4.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><math id=\"S4.T4.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\mathcal{L}_{QO}\" display=\"inline\"><semantics id=\"S4.T4.1.1.1.m1.1a\"><msub id=\"S4.T4.1.1.1.m1.1.1\" xref=\"S4.T4.1.1.1.m1.1.1.cmml\"><mi class=\"ltx_font_mathcaligraphic\" id=\"S4.T4.1.1.1.m1.1.1.2\" xref=\"S4.T4.1.1.1.m1.1.1.2.cmml\">â„’</mi><mrow id=\"S4.T4.1.1.1.m1.1.1.3\" xref=\"S4.T4.1.1.1.m1.1.1.3.cmml\"><mi id=\"S4.T4.1.1.1.m1.1.1.3.2\" xref=\"S4.T4.1.1.1.m1.1.1.3.2.cmml\">Q</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.T4.1.1.1.m1.1.1.3.1\" xref=\"S4.T4.1.1.1.m1.1.1.3.1.cmml\">â€‹</mo><mi id=\"S4.T4.1.1.1.m1.1.1.3.3\" xref=\"S4.T4.1.1.1.m1.1.1.3.3.cmml\">O</mi></mrow></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.1.1.1.m1.1b\"><apply id=\"S4.T4.1.1.1.m1.1.1.cmml\" xref=\"S4.T4.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T4.1.1.1.m1.1.1.1.cmml\" xref=\"S4.T4.1.1.1.m1.1.1\">subscript</csymbol><ci id=\"S4.T4.1.1.1.m1.1.1.2.cmml\" xref=\"S4.T4.1.1.1.m1.1.1.2\">â„’</ci><apply id=\"S4.T4.1.1.1.m1.1.1.3.cmml\" xref=\"S4.T4.1.1.1.m1.1.1.3\"><times id=\"S4.T4.1.1.1.m1.1.1.3.1.cmml\" xref=\"S4.T4.1.1.1.m1.1.1.3.1\"></times><ci id=\"S4.T4.1.1.1.m1.1.1.3.2.cmml\" xref=\"S4.T4.1.1.1.m1.1.1.3.2\">ğ‘„</ci><ci id=\"S4.T4.1.1.1.m1.1.1.3.3.cmml\" xref=\"S4.T4.1.1.1.m1.1.1.3.3\">ğ‘‚</ci></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.1.1.1.m1.1c\">\\mathcal{L}_{QO}</annotation></semantics></math></th>\n<th id=\"S4.T4.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Overall</th>\n<th id=\"S4.T4.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Yes/No</th>\n<th id=\"S4.T4.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Number</th>\n<th id=\"S4.T4.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Other</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T4.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" rowspan=\"2\"><span id=\"S4.T4.1.2.1.1.1\" class=\"ltx_text\">Baseline + RUBi</span></th>\n<td id=\"S4.T4.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">âœ“</td>\n<td id=\"S4.T4.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T4.1.2.1.3.1\" class=\"ltx_text ltx_font_bold\">47.11</span></td>\n<td id=\"S4.T4.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">68.65</td>\n<td id=\"S4.T4.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">20.28</td>\n<td id=\"S4.T4.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T4.1.2.1.6.1\" class=\"ltx_text ltx_font_bold\">43.18</span></td>\n</tr>\n<tr id=\"S4.T4.1.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.3.2.1\" class=\"ltx_td ltx_align_center\">âœ—</td>\n<td id=\"S4.T4.1.3.2.2\" class=\"ltx_td ltx_align_center\">46.11</td>\n<td id=\"S4.T4.1.3.2.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.3.2.3.1\" class=\"ltx_text ltx_font_bold\">69.18</span></td>\n<td id=\"S4.T4.1.3.2.4\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.3.2.4.1\" class=\"ltx_text ltx_font_bold\">26.85</span></td>\n<td id=\"S4.T4.1.3.2.5\" class=\"ltx_td ltx_align_center\">39.31</td>\n</tr>\n<tr id=\"S4.T4.1.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" rowspan=\"2\"><span id=\"S4.T4.1.4.3.1.1\" class=\"ltx_text\">SAN + RUBi</span></th>\n<td id=\"S4.T4.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">âœ“</td>\n<td id=\"S4.T4.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T4.1.4.3.3.1\" class=\"ltx_text ltx_font_bold\">37.63</span></td>\n<td id=\"S4.T4.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">59.49</td>\n<td id=\"S4.T4.1.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T4.1.4.3.5.1\" class=\"ltx_text ltx_font_bold\">13.71</span></td>\n<td id=\"S4.T4.1.4.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T4.1.4.3.6.1\" class=\"ltx_text ltx_font_bold\">32.74</span></td>\n</tr>\n<tr id=\"S4.T4.1.5.4\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.5.4.1\" class=\"ltx_td ltx_align_center\">âœ—</td>\n<td id=\"S4.T4.1.5.4.2\" class=\"ltx_td ltx_align_center\">36.96</td>\n<td id=\"S4.T4.1.5.4.3\" class=\"ltx_td ltx_align_center\">\n<span id=\"S4.T4.1.5.4.3.1\" class=\"ltx_text ltx_font_bold\">59.7</span>8</td>\n<td id=\"S4.T4.1.5.4.4\" class=\"ltx_td ltx_align_center\">12.55</td>\n<td id=\"S4.T4.1.5.4.5\" class=\"ltx_td ltx_align_center\">31.69</td>\n</tr>\n<tr id=\"S4.T4.1.6.5\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t\" rowspan=\"2\"><span id=\"S4.T4.1.6.5.1.1\" class=\"ltx_text\">UpDn + RUBi</span></th>\n<td id=\"S4.T4.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\">âœ“</td>\n<td id=\"S4.T4.1.6.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T4.1.6.5.3.1\" class=\"ltx_text ltx_font_bold\">44.23</span></td>\n<td id=\"S4.T4.1.6.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T4.1.6.5.4.1\" class=\"ltx_text ltx_font_bold\">67.05</span></td>\n<td id=\"S4.T4.1.6.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T4.1.6.5.5.1\" class=\"ltx_text ltx_font_bold\">17.48</span></td>\n<td id=\"S4.T4.1.6.5.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T4.1.6.5.6.1\" class=\"ltx_text ltx_font_bold\">39.61</span></td>\n</tr>\n<tr id=\"S4.T4.1.7.6\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.7.6.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">âœ—</td>\n<td id=\"S4.T4.1.7.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">39.47</td>\n<td id=\"S4.T4.1.7.6.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">60.27</td>\n<td id=\"S4.T4.1.7.6.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">16.01</td>\n<td id=\"S4.T4.1.7.6.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">35.01</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "In TableÂ 4, we validate the ability of the question-only loss â„’Qâ€‹Osubscriptâ„’ğ‘„ğ‘‚\\mathcal{L}_{QO} to reduce the question biases. The absence of â„’Qâ€‹Osubscriptâ„’ğ‘„ğ‘‚\\mathcal{L}_{QO} implies that the question-only classifier cqsubscriptğ‘ğ‘c_{q} is never used, and ğ‘›ğ‘›qsubscriptğ‘›ğ‘›ğ‘\\mathit{nn}_{q} only receives gradients from the main loss â„’Qâ€‹Msubscriptâ„’ğ‘„ğ‘€\\mathcal{L}_{QM}. Using â„’Qâ€‹Osubscriptâ„’ğ‘„ğ‘‚\\mathcal{L}_{QO} leads to consistent gains on all three architectures. We report a gain of +0.89 for our Baseline architecture, +0.22 for SAN, +4.76 for UpDn."
        ]
    },
    "S6.T5": {
        "caption": "Table 5: Overall accuracy top1 on VQA-CP v1",
        "table": "<table id=\"S6.T5.2\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T5.2.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T5.2.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_tt\">Model</td>\n<td id=\"S6.T5.2.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_tt\">Overall</td>\n<td id=\"S6.T5.2.1.1.3\" class=\"ltx_td ltx_align_left ltx_border_tt\">Yes/No</td>\n<td id=\"S6.T5.2.1.1.4\" class=\"ltx_td ltx_align_left ltx_border_tt\">Number</td>\n<td id=\"S6.T5.2.1.1.5\" class=\"ltx_td ltx_align_left ltx_border_tt\">Other</td>\n</tr>\n<tr id=\"S6.T5.2.2.2\" class=\"ltx_tr\">\n<td id=\"S6.T5.2.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\">GVQA <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">10</a>]</cite>\n</td>\n<td id=\"S6.T5.2.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">39.23</td>\n<td id=\"S6.T5.2.2.2.3\" class=\"ltx_td ltx_align_left ltx_border_t\">64.72</td>\n<td id=\"S6.T5.2.2.2.4\" class=\"ltx_td ltx_align_left ltx_border_t\">11.87</td>\n<td id=\"S6.T5.2.2.2.5\" class=\"ltx_td ltx_align_left ltx_border_t\">24.86</td>\n</tr>\n<tr id=\"S6.T5.2.3.3\" class=\"ltx_tr\">\n<td id=\"S6.T5.2.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">Baseline (ours)</td>\n<td id=\"S6.T5.2.3.3.2\" class=\"ltx_td ltx_align_left ltx_border_t\">37.13</td>\n<td id=\"S6.T5.2.3.3.3\" class=\"ltx_td ltx_align_left ltx_border_t\">41.96</td>\n<td id=\"S6.T5.2.3.3.4\" class=\"ltx_td ltx_align_left ltx_border_t\">12.54</td>\n<td id=\"S6.T5.2.3.3.5\" class=\"ltx_td ltx_align_left ltx_border_t\">41.35</td>\n</tr>\n<tr id=\"S6.T5.2.4.4\" class=\"ltx_tr\">\n<td id=\"S6.T5.2.4.4.1\" class=\"ltx_td ltx_align_left\">Baseline + RUBi</td>\n<td id=\"S6.T5.2.4.4.2\" class=\"ltx_td ltx_align_left\"><span id=\"S6.T5.2.4.4.2.1\" class=\"ltx_text ltx_font_bold\">46.93</span></td>\n<td id=\"S6.T5.2.4.4.3\" class=\"ltx_td ltx_align_left\"><span id=\"S6.T5.2.4.4.3.1\" class=\"ltx_text ltx_font_bold\">66.78</span></td>\n<td id=\"S6.T5.2.4.4.4\" class=\"ltx_td ltx_align_left\"><span id=\"S6.T5.2.4.4.4.1\" class=\"ltx_text ltx_font_bold\">20.98</span></td>\n<td id=\"S6.T5.2.4.4.5\" class=\"ltx_td ltx_align_left\"><span id=\"S6.T5.2.4.4.5.1\" class=\"ltx_text ltx_font_bold\">43.64</span></td>\n</tr>\n<tr id=\"S6.T5.2.5.5\" class=\"ltx_tr\">\n<td id=\"S6.T5.2.5.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\">SAN <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib25\" title=\"\" class=\"ltx_ref\">25</a>]</cite>\n</td>\n<td id=\"S6.T5.2.5.5.2\" class=\"ltx_td ltx_align_left ltx_border_t\">26.88</td>\n<td id=\"S6.T5.2.5.5.3\" class=\"ltx_td ltx_align_left ltx_border_t\">35.34</td>\n<td id=\"S6.T5.2.5.5.4\" class=\"ltx_td ltx_align_left ltx_border_t\">11.34</td>\n<td id=\"S6.T5.2.5.5.5\" class=\"ltx_td ltx_align_left ltx_border_t\">24.70</td>\n</tr>\n<tr id=\"S6.T5.2.6.6\" class=\"ltx_tr\">\n<td id=\"S6.T5.2.6.6.1\" class=\"ltx_td ltx_align_left\">SAN + AdvReg <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib25\" title=\"\" class=\"ltx_ref\">25</a>]</cite>\n</td>\n<td id=\"S6.T5.2.6.6.2\" class=\"ltx_td ltx_align_left\">43.43</td>\n<td id=\"S6.T5.2.6.6.3\" class=\"ltx_td ltx_align_left\">74.16</td>\n<td id=\"S6.T5.2.6.6.4\" class=\"ltx_td ltx_align_left\">12.44</td>\n<td id=\"S6.T5.2.6.6.5\" class=\"ltx_td ltx_align_left\">25.32</td>\n</tr>\n<tr id=\"S6.T5.2.7.7\" class=\"ltx_tr\">\n<td id=\"S6.T5.2.7.7.1\" class=\"ltx_td ltx_align_left\">SAN + RUBi</td>\n<td id=\"S6.T5.2.7.7.2\" class=\"ltx_td ltx_align_left\"><span id=\"S6.T5.2.7.7.2.1\" class=\"ltx_text ltx_font_bold\">46.08</span></td>\n<td id=\"S6.T5.2.7.7.3\" class=\"ltx_td ltx_align_left\"><span id=\"S6.T5.2.7.7.3.1\" class=\"ltx_text ltx_font_bold\">75.00</span></td>\n<td id=\"S6.T5.2.7.7.4\" class=\"ltx_td ltx_align_left\"><span id=\"S6.T5.2.7.7.4.1\" class=\"ltx_text ltx_font_bold\">13.30</span></td>\n<td id=\"S6.T5.2.7.7.5\" class=\"ltx_td ltx_align_left\"><span id=\"S6.T5.2.7.7.5.1\" class=\"ltx_text ltx_font_bold\">30.49</span></td>\n</tr>\n<tr id=\"S6.T5.2.8.8\" class=\"ltx_tr\">\n<td id=\"S6.T5.2.8.8.1\" class=\"ltx_td ltx_align_left ltx_border_t\">UpDn (ours)</td>\n<td id=\"S6.T5.2.8.8.2\" class=\"ltx_td ltx_align_left ltx_border_t\">37.15</td>\n<td id=\"S6.T5.2.8.8.3\" class=\"ltx_td ltx_align_left ltx_border_t\">41.13</td>\n<td id=\"S6.T5.2.8.8.4\" class=\"ltx_td ltx_align_left ltx_border_t\">12.73</td>\n<td id=\"S6.T5.2.8.8.5\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S6.T5.2.8.8.5.1\" class=\"ltx_text ltx_font_bold\">43.00</span></td>\n</tr>\n<tr id=\"S6.T5.2.9.9\" class=\"ltx_tr\">\n<td id=\"S6.T5.2.9.9.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">UpDn + RUBi</td>\n<td id=\"S6.T5.2.9.9.2\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S6.T5.2.9.9.2.1\" class=\"ltx_text ltx_font_bold\">44.81</span></td>\n<td id=\"S6.T5.2.9.9.3\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S6.T5.2.9.9.3.1\" class=\"ltx_text ltx_font_bold\">69.65</span></td>\n<td id=\"S6.T5.2.9.9.4\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S6.T5.2.9.9.4.1\" class=\"ltx_text ltx_font_bold\">14.91</span></td>\n<td id=\"S6.T5.2.9.9.5\" class=\"ltx_td ltx_align_left ltx_border_bb\">32.13</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "In Table 5, we report results on the VQA-CP v1 dataset [10]. Our RUBi approach consistently leads to significant gains over the classical learning strategy with a gain of +9.8 overall accuracy point with our baseline architecture, +19.2 with SAN and +7.66 with UpDn. Additionally, RUBi leads to a gain of +2.65 over the adversarial regularization method (AdvReg) from [25] with SAN. A visual comparison between RUBi and [25] can be found in FigureÂ 5. Finally, all three architectures trained with RUBi reach a higher accuracy than GVQA [10] which has been hand-designed to overcome biases."
        ]
    },
    "S6.T6": {
        "caption": "Table 6: Overall accuracy top1 on VQA-CP v2 for the SAN and UpDn architectures.",
        "table": "<table id=\"S6.T6.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S6.T6.2.1.1\" class=\"ltx_tr\">\n<th id=\"S6.T6.2.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Model</th>\n<th id=\"S6.T6.2.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Overall</th>\n<th id=\"S6.T6.2.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Yes/No</th>\n<th id=\"S6.T6.2.1.1.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Number</th>\n<th id=\"S6.T6.2.1.1.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Other</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T6.2.2.1\" class=\"ltx_tr\">\n<td id=\"S6.T6.2.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\">SAN <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib26\" title=\"\" class=\"ltx_ref\">26</a>]</cite>\n</td>\n<td id=\"S6.T6.2.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">24.96</td>\n<td id=\"S6.T6.2.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">38.35</td>\n<td id=\"S6.T6.2.2.1.4\" class=\"ltx_td ltx_align_left ltx_border_t\">11.14</td>\n<td id=\"S6.T6.2.2.1.5\" class=\"ltx_td ltx_align_left ltx_border_t\">21.74</td>\n</tr>\n<tr id=\"S6.T6.2.3.2\" class=\"ltx_tr\">\n<td id=\"S6.T6.2.3.2.1\" class=\"ltx_td ltx_align_left\">SAN + RUBi</td>\n<td id=\"S6.T6.2.3.2.2\" class=\"ltx_td ltx_align_left\"><span id=\"S6.T6.2.3.2.2.1\" class=\"ltx_text ltx_font_bold\">37.63</span></td>\n<td id=\"S6.T6.2.3.2.3\" class=\"ltx_td ltx_align_left\"><span id=\"S6.T6.2.3.2.3.1\" class=\"ltx_text ltx_font_bold\">59.49</span></td>\n<td id=\"S6.T6.2.3.2.4\" class=\"ltx_td ltx_align_left\"><span id=\"S6.T6.2.3.2.4.1\" class=\"ltx_text ltx_font_bold\">13.71</span></td>\n<td id=\"S6.T6.2.3.2.5\" class=\"ltx_td ltx_align_left\"><span id=\"S6.T6.2.3.2.5.1\" class=\"ltx_text ltx_font_bold\">32.74</span></td>\n</tr>\n<tr id=\"S6.T6.2.4.3\" class=\"ltx_tr\">\n<td id=\"S6.T6.2.4.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">UpDn <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib15\" title=\"\" class=\"ltx_ref\">15</a>]</cite>\n</td>\n<td id=\"S6.T6.2.4.3.2\" class=\"ltx_td ltx_align_left ltx_border_t\">39.74</td>\n<td id=\"S6.T6.2.4.3.3\" class=\"ltx_td ltx_align_left ltx_border_t\">42.27</td>\n<td id=\"S6.T6.2.4.3.4\" class=\"ltx_td ltx_align_left ltx_border_t\">11.93</td>\n<td id=\"S6.T6.2.4.3.5\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S6.T6.2.4.3.5.1\" class=\"ltx_text ltx_font_bold\">46.05</span></td>\n</tr>\n<tr id=\"S6.T6.2.5.4\" class=\"ltx_tr\">\n<td id=\"S6.T6.2.5.4.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">UpDn + RUBi</td>\n<td id=\"S6.T6.2.5.4.2\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S6.T6.2.5.4.2.1\" class=\"ltx_text ltx_font_bold\">44.23</span></td>\n<td id=\"S6.T6.2.5.4.3\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S6.T6.2.5.4.3.1\" class=\"ltx_text ltx_font_bold\">67.05</span></td>\n<td id=\"S6.T6.2.5.4.4\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S6.T6.2.5.4.4.1\" class=\"ltx_text ltx_font_bold\">17.48</span></td>\n<td id=\"S6.T6.2.5.4.5\" class=\"ltx_td ltx_align_left ltx_border_bb\">39.61</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "In Table 5, we report results on the VQA-CP v1 dataset [10]. Our RUBi approach consistently leads to significant gains over the classical learning strategy with a gain of +9.8 overall accuracy point with our baseline architecture, +19.2 with SAN and +7.66 with UpDn. Additionally, RUBi leads to a gain of +2.65 over the adversarial regularization method (AdvReg) from [25] with SAN. A visual comparison between RUBi and [25] can be found in FigureÂ 5. Finally, all three architectures trained with RUBi reach a higher accuracy than GVQA [10] which has been hand-designed to overcome biases.",
            "In TableÂ 6, we report the full results of our experiments for SAN and UpDn architectures on the VQA-CP v2 dataset."
        ]
    },
    "S6.T7": {
        "caption": "Table 7: Correlation with Human Attention Maps on VQA-HAT val set [44].",
        "table": "<table id=\"S6.T7.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S6.T7.2.1.1\" class=\"ltx_tr\">\n<th id=\"S6.T7.2.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Model</th>\n<th id=\"S6.T7.2.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">RUBi</th>\n<th id=\"S6.T7.2.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Rank-Corr.</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T7.2.2.1\" class=\"ltx_tr\">\n<th id=\"S6.T7.2.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Random <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib44\" title=\"\" class=\"ltx_ref\">44</a>]</cite>\n</th>\n<td id=\"S6.T7.2.2.1.2\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S6.T7.2.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.000</td>\n</tr>\n<tr id=\"S6.T7.2.3.2\" class=\"ltx_tr\">\n<th id=\"S6.T7.2.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Human <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib44\" title=\"\" class=\"ltx_ref\">44</a>]</cite>\n</th>\n<td id=\"S6.T7.2.3.2.2\" class=\"ltx_td\"></td>\n<td id=\"S6.T7.2.3.2.3\" class=\"ltx_td ltx_align_center\">0.623</td>\n</tr>\n<tr id=\"S6.T7.2.4.3\" class=\"ltx_tr\">\n<th id=\"S6.T7.2.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" rowspan=\"2\"><span id=\"S6.T7.2.4.3.1.1\" class=\"ltx_text\">Baseline</span></th>\n<td id=\"S6.T7.2.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">âœ—</td>\n<td id=\"S6.T7.2.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.431</td>\n</tr>\n<tr id=\"S6.T7.2.5.4\" class=\"ltx_tr\">\n<td id=\"S6.T7.2.5.4.1\" class=\"ltx_td ltx_align_center\">âœ“</td>\n<td id=\"S6.T7.2.5.4.2\" class=\"ltx_td ltx_align_center\"><span id=\"S6.T7.2.5.4.2.1\" class=\"ltx_text ltx_font_bold\">0.443</span></td>\n</tr>\n<tr id=\"S6.T7.2.6.5\" class=\"ltx_tr\">\n<th id=\"S6.T7.2.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" rowspan=\"2\"><span id=\"S6.T7.2.6.5.1.1\" class=\"ltx_text\">SAN</span></th>\n<td id=\"S6.T7.2.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\">âœ—</td>\n<td id=\"S6.T7.2.6.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.191</td>\n</tr>\n<tr id=\"S6.T7.2.7.6\" class=\"ltx_tr\">\n<td id=\"S6.T7.2.7.6.1\" class=\"ltx_td ltx_align_center\">âœ“</td>\n<td id=\"S6.T7.2.7.6.2\" class=\"ltx_td ltx_align_center\"><span id=\"S6.T7.2.7.6.2.1\" class=\"ltx_text ltx_font_bold\">0.210</span></td>\n</tr>\n<tr id=\"S6.T7.2.8.7\" class=\"ltx_tr\">\n<th id=\"S6.T7.2.8.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t\" rowspan=\"2\"><span id=\"S6.T7.2.8.7.1.1\" class=\"ltx_text\">UpDn</span></th>\n<td id=\"S6.T7.2.8.7.2\" class=\"ltx_td ltx_align_center ltx_border_t\">âœ—</td>\n<td id=\"S6.T7.2.8.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S6.T7.2.8.7.3.1\" class=\"ltx_text ltx_font_bold\">0.449</span></td>\n</tr>\n<tr id=\"S6.T7.2.9.8\" class=\"ltx_tr\">\n<td id=\"S6.T7.2.9.8.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">âœ“</td>\n<td id=\"S6.T7.2.9.8.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.446</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "We conduct additional studies to evaluate the grounding ability of models trained with RUBi. We follow the experimental protocol of VQA-HAT [44]. We train our models on VQA v1 train set and evaluate them using rank-correlation on the VQA-HAT val set, which is a subset of the VQA v1 val set. This metric compares attention maps computed from a model against human annotations indicating which regions humans found relevant for answering the question.\nIn TableÂ 7, we report a gain of +0.012 with our baseline architecture trained with RUBi, a gain of +0.019 with SAN and a loss of -0.003 with UpDn architecture. In future works, we would like to go beyond these early results in order to further evaluate the impact on grounding induced by RUBi."
        ]
    }
}