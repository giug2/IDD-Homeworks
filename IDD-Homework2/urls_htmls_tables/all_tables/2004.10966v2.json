{
    "Sx4.T1": {
        "caption": "Table 1: Validation accuracy after training VQA-CoIn with different scales of train split.",
        "table": "<table id=\"Sx4.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"Sx4.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"Sx4.T1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">Scale%</th>\n<th id=\"Sx4.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">VQA-CoIn</th>\n<th id=\"Sx4.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">BAN</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"Sx4.T1.1.2.1\" class=\"ltx_tr\">\n<th id=\"Sx4.T1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\">25</th>\n<td id=\"Sx4.T1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span id=\"Sx4.T1.1.2.1.2.1\" class=\"ltx_text ltx_font_bold\">54.84</span></td>\n<td id=\"Sx4.T1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">54.09</td>\n</tr>\n<tr id=\"Sx4.T1.1.3.2\" class=\"ltx_tr\">\n<th id=\"Sx4.T1.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\">50</th>\n<td id=\"Sx4.T1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">61.76</td>\n<td id=\"Sx4.T1.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"Sx4.T1.1.3.2.3.1\" class=\"ltx_text ltx_font_bold\">62.42</span></td>\n</tr>\n<tr id=\"Sx4.T1.1.4.3\" class=\"ltx_tr\">\n<th id=\"Sx4.T1.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r\">75</th>\n<td id=\"Sx4.T1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"Sx4.T1.1.4.3.2.1\" class=\"ltx_text ltx_font_bold\">65.08</span></td>\n<td id=\"Sx4.T1.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">64.92</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "Table 1 demonstrates the results for our data scaling experiment.\nWe perform this experiment using on our VQA-CoIn model and our baseline model.\nWe find that for one fourth and three fourth of the dataset, when we train our model, it is capable of functioning better than BAN-8 model.\nBut while trained on 50% of the training split, BAN model perform better than VQA-CoIn.\nThe reason behind this could be, as we are enforcing contextual information of the images generated by a pre-trained model in our method, some of these information may not carry knowledge related to the question to answer it correctly.\nThis observation can lead our study to further investigation by producing and invoking SI using other pre-trained models in future.\nWe still feel that this gives strong evidence that our approach can better utilize small amounts of data when compared to state-of-the-art approaches.\nThrough Table 2, we estimate the validation score of our model for the whole dataset with the state-of-the-art VQA models.\nThe validation score on the VQA-CoIn (I+Q) row of the table portrays the importance of the region based SI of images we employ through our model.\nWhile SI along with image(I) and question(Q) as inputs are given to the network, VQA-CoIn outperforms the state-of-art baseline architectures in terms of accuracy."
        ]
    },
    "Sx4.T2": {
        "caption": "Table 2: Validation scores computed on the full VQA v2.0 dataset for bottom-up model, BAN-8 and our architecture.",
        "table": "<table id=\"Sx4.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"Sx4.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"Sx4.T2.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">Method</th>\n<th id=\"Sx4.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Validation Score</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"Sx4.T2.1.2.1\" class=\"ltx_tr\">\n<th id=\"Sx4.T2.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\">bottom-up</th>\n<td id=\"Sx4.T2.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">63.20</td>\n</tr>\n<tr id=\"Sx4.T2.1.3.2\" class=\"ltx_tr\">\n<th id=\"Sx4.T2.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\">BAN-8</th>\n<td id=\"Sx4.T2.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">66.28</td>\n</tr>\n<tr id=\"Sx4.T2.1.4.3\" class=\"ltx_tr\">\n<th id=\"Sx4.T2.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\">VQA-CoIn(I+Q)</th>\n<td id=\"Sx4.T2.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">66.03</td>\n</tr>\n<tr id=\"Sx4.T2.1.5.4\" class=\"ltx_tr\">\n<th id=\"Sx4.T2.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r\">VQA-CoIn(I+Q+SI)</th>\n<td id=\"Sx4.T2.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"Sx4.T2.1.5.4.2.1\" class=\"ltx_text ltx_font_bold\">66.33</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "Table 1 demonstrates the results for our data scaling experiment.\nWe perform this experiment using on our VQA-CoIn model and our baseline model.\nWe find that for one fourth and three fourth of the dataset, when we train our model, it is capable of functioning better than BAN-8 model.\nBut while trained on 50% of the training split, BAN model perform better than VQA-CoIn.\nThe reason behind this could be, as we are enforcing contextual information of the images generated by a pre-trained model in our method, some of these information may not carry knowledge related to the question to answer it correctly.\nThis observation can lead our study to further investigation by producing and invoking SI using other pre-trained models in future.\nWe still feel that this gives strong evidence that our approach can better utilize small amounts of data when compared to state-of-the-art approaches.\nThrough Table 2, we estimate the validation score of our model for the whole dataset with the state-of-the-art VQA models.\nThe validation score on the VQA-CoIn (I+Q) row of the table portrays the importance of the region based SI of images we employ through our model.\nWhile SI along with image(I) and question(Q) as inputs are given to the network, VQA-CoIn outperforms the state-of-art baseline architectures in terms of accuracy."
        ]
    },
    "Sx4.T4": {
        "caption": "Table 4: Comparison of answers generated for questions and images from the validation data by VQA-CoIn and BAN-8 models.",
        "table": "<table id=\"Sx4.T4.3.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"Sx4.T4.3.3.3\" class=\"ltx_tr\">\n<th id=\"Sx4.T4.3.3.3.4\" class=\"ltx_td ltx_align_top ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\"></th>\n<th id=\"Sx4.T4.1.1.1.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t\">\n<span id=\"Sx4.T4.1.1.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"Sx4.T4.1.1.1.1.1.1\" class=\"ltx_p\" style=\"width:108.1pt;\"><img src=\"/html/2004.10966/assets/figures/fig2.jpg\" id=\"Sx4.T4.1.1.1.1.1.1.g1\" class=\"ltx_graphics ltx_img_square\" width=\"350\" height=\"306\" alt=\"[Uncaptioned image]\"></span>\n</span>\n</th>\n<th id=\"Sx4.T4.2.2.2.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t\">\n<span id=\"Sx4.T4.2.2.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"Sx4.T4.2.2.2.2.1.1\" class=\"ltx_p\" style=\"width:108.1pt;\"><img src=\"/html/2004.10966/assets/figures/fig3.jpg\" id=\"Sx4.T4.2.2.2.2.1.1.g1\" class=\"ltx_graphics ltx_img_landscape\" width=\"375\" height=\"300\" alt=\"[Uncaptioned image]\"></span>\n</span>\n</th>\n<th id=\"Sx4.T4.3.3.3.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t\">\n<span id=\"Sx4.T4.3.3.3.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"Sx4.T4.3.3.3.3.1.1\" class=\"ltx_p\" style=\"width:108.1pt;\"><img src=\"/html/2004.10966/assets/figures/fig4.jpg\" id=\"Sx4.T4.3.3.3.3.1.1.g1\" class=\"ltx_graphics ltx_img_square\" width=\"368\" height=\"308\" alt=\"[Uncaptioned image]\"></span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"Sx4.T4.3.3.4.1\" class=\"ltx_tr\">\n<td id=\"Sx4.T4.3.3.4.1.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t\">\n<span id=\"Sx4.T4.3.3.4.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"Sx4.T4.3.3.4.1.1.1.1\" class=\"ltx_p\" style=\"width:79.7pt;\">question</span>\n</span>\n</td>\n<td id=\"Sx4.T4.3.3.4.1.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\">\n<span id=\"Sx4.T4.3.3.4.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"Sx4.T4.3.3.4.1.2.1.1\" class=\"ltx_p\" style=\"width:108.1pt;\">What is he doing at night?</span>\n</span>\n</td>\n<td id=\"Sx4.T4.3.3.4.1.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\">\n<span id=\"Sx4.T4.3.3.4.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"Sx4.T4.3.3.4.1.3.1.1\" class=\"ltx_p\" style=\"width:108.1pt;\">What sport is the man participating in?</span>\n</span>\n</td>\n<td id=\"Sx4.T4.3.3.4.1.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\">\n<span id=\"Sx4.T4.3.3.4.1.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"Sx4.T4.3.3.4.1.4.1.1\" class=\"ltx_p\" style=\"width:108.1pt;\">What color is the man wearing?</span>\n</span>\n</td>\n</tr>\n<tr id=\"Sx4.T4.3.3.5.2\" class=\"ltx_tr\">\n<td id=\"Sx4.T4.3.3.5.2.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t\">\n<span id=\"Sx4.T4.3.3.5.2.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"Sx4.T4.3.3.5.2.1.1.1\" class=\"ltx_p\" style=\"width:79.7pt;\">semantic info</span>\n</span>\n</td>\n<td id=\"Sx4.T4.3.3.5.2.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\">\n<span id=\"Sx4.T4.3.3.5.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"Sx4.T4.3.3.5.2.2.1.1\" class=\"ltx_p\" style=\"width:108.1pt;\">‘man <span id=\"Sx4.T4.3.3.5.2.2.1.1.1\" class=\"ltx_text ltx_font_bold\">playing frisbee</span>’, ‘green grass field’, ‘man wearing white shirt’, ‘sky clear’, ‘man wearing shorts’, ‘man short hair’</span>\n</span>\n</td>\n<td id=\"Sx4.T4.3.3.5.2.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\">\n<span id=\"Sx4.T4.3.3.5.2.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"Sx4.T4.3.3.5.2.3.1.1\" class=\"ltx_p\" style=\"width:108.1pt;\">‘large blue sky’, ‘person skiing’, ‘man wearing black jacket’, ‘person <span id=\"Sx4.T4.3.3.5.2.3.1.1.1\" class=\"ltx_text ltx_font_bold\">snowboarding</span>’, ‘snow covered mountain’</span>\n</span>\n</td>\n<td id=\"Sx4.T4.3.3.5.2.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\">\n<span id=\"Sx4.T4.3.3.5.2.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"Sx4.T4.3.3.5.2.4.1.1\" class=\"ltx_p\" style=\"width:108.1pt;\">‘black and white cow’, ‘man wearing hat’, ‘hat man’, ‘man and woman sitting bench’,\n‘<span id=\"Sx4.T4.3.3.5.2.4.1.1.1\" class=\"ltx_text ltx_font_bold\">red and white striped shirt</span>’</span>\n</span>\n</td>\n</tr>\n<tr id=\"Sx4.T4.3.3.6.3\" class=\"ltx_tr\">\n<td id=\"Sx4.T4.3.3.6.3.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t\">\n<span id=\"Sx4.T4.3.3.6.3.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"Sx4.T4.3.3.6.3.1.1.1\" class=\"ltx_p\" style=\"width:79.7pt;\">ground truth answer</span>\n</span>\n</td>\n<td id=\"Sx4.T4.3.3.6.3.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\">\n<span id=\"Sx4.T4.3.3.6.3.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"Sx4.T4.3.3.6.3.2.1.1\" class=\"ltx_p\" style=\"width:108.1pt;\">playing frisbee</span>\n</span>\n</td>\n<td id=\"Sx4.T4.3.3.6.3.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\">\n<span id=\"Sx4.T4.3.3.6.3.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"Sx4.T4.3.3.6.3.3.1.1\" class=\"ltx_p\" style=\"width:108.1pt;\">snowborading</span>\n</span>\n</td>\n<td id=\"Sx4.T4.3.3.6.3.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\">\n<span id=\"Sx4.T4.3.3.6.3.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"Sx4.T4.3.3.6.3.4.1.1\" class=\"ltx_p\" style=\"width:108.1pt;\">red, white and blue</span>\n</span>\n</td>\n</tr>\n<tr id=\"Sx4.T4.3.3.7.4\" class=\"ltx_tr\">\n<td id=\"Sx4.T4.3.3.7.4.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t\">\n<span id=\"Sx4.T4.3.3.7.4.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"Sx4.T4.3.3.7.4.1.1.1\" class=\"ltx_p\" style=\"width:79.7pt;\">VQA-CoIn answer</span>\n</span>\n</td>\n<td id=\"Sx4.T4.3.3.7.4.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\">\n<span id=\"Sx4.T4.3.3.7.4.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"Sx4.T4.3.3.7.4.2.1.1\" class=\"ltx_p\" style=\"width:108.1pt;\">playing frisbee</span>\n</span>\n</td>\n<td id=\"Sx4.T4.3.3.7.4.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\">\n<span id=\"Sx4.T4.3.3.7.4.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"Sx4.T4.3.3.7.4.3.1.1\" class=\"ltx_p\" style=\"width:108.1pt;\">snowboarding</span>\n</span>\n</td>\n<td id=\"Sx4.T4.3.3.7.4.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t\">\n<span id=\"Sx4.T4.3.3.7.4.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"Sx4.T4.3.3.7.4.4.1.1\" class=\"ltx_p\" style=\"width:108.1pt;\">red and white</span>\n</span>\n</td>\n</tr>\n<tr id=\"Sx4.T4.3.3.8.5\" class=\"ltx_tr\">\n<td id=\"Sx4.T4.3.3.8.5.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">\n<span id=\"Sx4.T4.3.3.8.5.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"Sx4.T4.3.3.8.5.1.1.1\" class=\"ltx_p\" style=\"width:79.7pt;\">BAN-8 answer</span>\n</span>\n</td>\n<td id=\"Sx4.T4.3.3.8.5.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t\">\n<span id=\"Sx4.T4.3.3.8.5.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"Sx4.T4.3.3.8.5.2.1.1\" class=\"ltx_p\" style=\"width:108.1pt;\">playing</span>\n</span>\n</td>\n<td id=\"Sx4.T4.3.3.8.5.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t\">\n<span id=\"Sx4.T4.3.3.8.5.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"Sx4.T4.3.3.8.5.3.1.1\" class=\"ltx_p\" style=\"width:108.1pt;\">skiing</span>\n</span>\n</td>\n<td id=\"Sx4.T4.3.3.8.5.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t\">\n<span id=\"Sx4.T4.3.3.8.5.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"Sx4.T4.3.3.8.5.4.1.1\" class=\"ltx_p\" style=\"width:108.1pt;\">white</span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "In order to receive scores for the test set, we submitted the results produced by our model to the VQA competition using EValAI.\nWe also submit the reproduced answers of BAN in the same site to find out and compare the test-dev and test-standard scores with ours.\nAccording to the results returned, displayed in Table 3, We can observe that VQA-CoIn has outperformed BAN and bottom-up(?) in test-dev and test-standard challenges.\nIf we consider each category of questions for BAN-8 and VQA-CoIn models, we can see that VQA-CoIn network has surpassed the scores of BAN-8 for ‘number’ and ‘other’ categorical questions.\nFor ‘yes/no’ category of questions, BAN has performed better than ours.\nWe feel that these results are significant, especially our performance on the ‘other’ category.\nTo answer any question from ‘other’ category, a model needs to understand more complex relation among the contents of an image (where to search for an answer).\nSI provides support behind this logic and helps our model to generate more accurate answers than our baseline models.",
            "After the quantitative comparison of our and two state-of-the-art models, we do a qualitative contrast between VQA-CoIn and BAN-8 using the data of validation split.\nThis is not meant to be a formal evaluation, but mainly meant to provide additional context to the results that our approach gives compared to our baselines.\nTable 4 represents the contrast.\nWe have image, question and SI for each of three examples.\nThe human annotated ground truth answers for the examples are also added so that the answers generated by both of the models can be compared with it.\nFrom the table, we can see that for image (a) and (b), our model generates correct answers.\nFor the same images, BAN model generates answers that are very close to the answers from the dataset, but not accurate.\nHere, the reason of the success of our model is both image features and SI for images.\nThe answers for the questions are already available in the SI.\nFor ease of reading, we bold the texts on the row named as semantic info in the table.\nNow, if we match answers for image (c) of both models, answers are not exact to the ground truth answers.\nOur model is able to detect only two colors using both image features and SI (bold texts in semantic info row under image (c)) available for the input question.\nSo, VQA-CoIn chooses these two colors as answer.\nIt also means that, if better SI is used, our model can generate more correct answers."
        ]
    }
}