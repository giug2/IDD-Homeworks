{
    "S3.T1": {
        "caption": "Table 1: Proposed models comparison with SOTA methods from literature.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S3.T1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S3.T1.1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.1.1\">Model</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S3.T1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.1.1.2.1\">Accuracy</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T1.1.2.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.2.1.1\">ViT<span class=\"ltx_note ltx_role_footnote\" id=\"footnotex3\"><sup class=\"ltx_note_mark\">7</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">7</sup><span class=\"ltx_tag ltx_tag_note\">7</span>The model has been reimplemented.</span></span></span>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.2.1.2\">91.79%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.3.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.3.2.1\">RNNCA&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2408.13201v1#bib.bib21\" title=\"\">21</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.3.2.2\">93.1%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.4.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.4.3.1\">1D-CNN with BiRNN and attention mechanism&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2408.13201v1#bib.bib22\" title=\"\">22</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.4.3.2\">91.99%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.5.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.5.4.1\">SA-SLnO with optimization&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2408.13201v1#bib.bib23\" title=\"\">23</a>]</cite>\n</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T1.1.5.4.2\">85.63%</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T1.1.6.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T1.1.6.5.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.6.5.1.1\">EAViT (our)</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T1.1.6.5.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T1.1.6.5.2.1\">93.99%</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "To demonstrate the robustness and efficacy of the proposed model in this study, we conducted a comparative analysis with state-of-the-art (SOTA) models from the literature, including ViT\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2408.13201v1#bib.bib15\" title=\"\">15</a>]</cite>, Recurrent Neural Networks with Channel Attention Mechanism (RNNCA)&#160;\n[15], Recurrent Neural Networks with Channel Attention Mechanism (RNNCA)\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2408.13201v1#bib.bib21\" title=\"\">21</a>]</cite>, 1D-CNN with BiRNN and attention mechanism&#160;\n[21], 1D-CNN with BiRNN and attention mechanism\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2408.13201v1#bib.bib22\" title=\"\">22</a>]</cite>, and SA-SLnO with optimization&#160;\n[22], and SA-SLnO with optimization\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2408.13201v1#bib.bib23\" title=\"\">23</a>]</cite>. Table&#160;\n[23]. Table\u00a01 unequivocally shows that the results of our proposed method surpass the performance of these SOTA models. EAViT surpasses the ViT by 2.37%, RNNCA by 0.95%, and the 1D-CNN with BiRNN and attention mechanism by 2.15%. Furthermore, in comparison to SA-SLnO with optimization model, EAViT achieves a remarkable 9.31% increase in classification accuracy. Here, Table\u00a02 presents the evaluation metrics, including Precision, Recall, and F1-score, for each class of the proposed EAViT model. These findings underscore the robustness of the proposed model as it demonstrates consistent performance across various classes."
        ]
    },
    "S3.T2": {
        "caption": "Table 2: Evaluation of class-specific classification results of the proposed EAViT model",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S3.T2.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S3.T2.1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.1.1.1.1\">Class</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.1.1.2.1\">Precision</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.1.1.3.1\">Recall</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" id=\"S3.T2.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S3.T2.1.1.1.4.1\">F1-Score</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.T2.1.2.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T2.1.2.1.1\">Blues</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.2.1.2\">0.94</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.2.1.3\">0.96</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.2.1.4\">0.95</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.3.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T2.1.3.2.1\">Classical</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.3.2.2\">0.99</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.3.2.3\">0.97</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.3.2.4\">0.98</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.4.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T2.1.4.3.1\">Country</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.4.3.2\">0.89</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.4.3.3\">0.93</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.4.3.4\">0.91</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.5.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T2.1.5.4.1\">Disco</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.5.4.2\">0.95</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.5.4.3\">0.97</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.5.4.4\">0.96</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.6.5\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T2.1.6.5.1\">Hiphop</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.6.5.2\">0.93</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.6.5.3\">0.90</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.6.5.4\">0.91</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.7.6\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T2.1.7.6.1\">Jazz</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.7.6.2\">0.92</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.7.6.3\">0.94</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.7.6.4\">0.93</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.8.7\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T2.1.8.7.1\">Metal</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.8.7.2\">0.96</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.8.7.3\">0.93</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.8.7.4\">0.95</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.9.8\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T2.1.9.8.1\">Pop</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.9.8.2\">0.99</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.9.8.3\">0.92</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.9.8.4\">0.96</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.10.9\">\n<td class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T2.1.10.9.1\">Reggae</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.10.9.2\">0.93</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.10.9.3\">0.92</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S3.T2.1.10.9.4\">0.93</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S3.T2.1.11.10\">\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\" id=\"S3.T2.1.11.10.1\">Rock</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T2.1.11.10.2\">0.90</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T2.1.11.10.3\">0.94</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S3.T2.1.11.10.4\">0.92</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "To demonstrate the robustness and efficacy of the proposed model in this study, we conducted a comparative analysis with state-of-the-art (SOTA) models from the literature, including ViT\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2408.13201v1#bib.bib15\" title=\"\">15</a>]</cite>, Recurrent Neural Networks with Channel Attention Mechanism (RNNCA)&#160;\n[15], Recurrent Neural Networks with Channel Attention Mechanism (RNNCA)\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2408.13201v1#bib.bib21\" title=\"\">21</a>]</cite>, 1D-CNN with BiRNN and attention mechanism&#160;\n[21], 1D-CNN with BiRNN and attention mechanism\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2408.13201v1#bib.bib22\" title=\"\">22</a>]</cite>, and SA-SLnO with optimization&#160;\n[22], and SA-SLnO with optimization\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2408.13201v1#bib.bib23\" title=\"\">23</a>]</cite>. Table&#160;\n[23]. Table\u00a01 unequivocally shows that the results of our proposed method surpass the performance of these SOTA models. EAViT surpasses the ViT by 2.37%, RNNCA by 0.95%, and the 1D-CNN with BiRNN and attention mechanism by 2.15%. Furthermore, in comparison to SA-SLnO with optimization model, EAViT achieves a remarkable 9.31% increase in classification accuracy. Here, Table\u00a02 presents the evaluation metrics, including Precision, Recall, and F1-score, for each class of the proposed EAViT model. These findings underscore the robustness of the proposed model as it demonstrates consistent performance across various classes."
        ]
    }
}