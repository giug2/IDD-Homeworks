{
    "PAPER'S NUMBER OF TABLES": 5,
    "S5.T1": {
        "caption": "Table 1: Word accuracy suffers for word-level tokenization that uses mismatched data.",
        "table": "<table id=\"S5.T1.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.1.2\" class=\"ltx_td ltx_th ltx_th_row\"></th>\n<th id=\"S5.T1.1.1.3\" class=\"ltx_td ltx_th ltx_th_row ltx_border_r\"></th>\n<td id=\"S5.T1.1.1.1\" class=\"ltx_td ltx_align_center\" colspan=\"2\">\n<math id=\"S5.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\tau\" display=\"inline\"><semantics id=\"S5.T1.1.1.1.m1.1a\"><mi id=\"S5.T1.1.1.1.m1.1.1\" xref=\"S5.T1.1.1.1.m1.1.1.cmml\">τ</mi><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.1.1.1.m1.1b\"><ci id=\"S5.T1.1.1.1.m1.1.1.cmml\" xref=\"S5.T1.1.1.1.m1.1.1\">𝜏</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.1.1.1.m1.1c\">\\tau</annotation></semantics></math> statistics</td>\n<td id=\"S5.T1.1.1.4\" class=\"ltx_td ltx_nopad_l ltx_align_right\">Word</td>\n</tr>\n<tr id=\"S5.T1.2.3.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.2.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Type</th>\n<th id=\"S5.T1.2.3.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Data</th>\n<td id=\"S5.T1.2.3.1.3\" class=\"ltx_td ltx_align_right\"><span id=\"S5.T1.2.3.1.3.1\" class=\"ltx_text ltx_font_typewriter\">OOV</span></td>\n<td id=\"S5.T1.2.3.1.4\" class=\"ltx_td ltx_nopad_l ltx_align_right\">Tokens</td>\n<td id=\"S5.T1.2.3.1.5\" class=\"ltx_td ltx_nopad_l ltx_align_right\">Accuracy</td>\n</tr>\n<tr id=\"S5.T1.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T1.2.2.2\" class=\"ltx_td ltx_th ltx_th_row\"></th>\n<th id=\"S5.T1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">to train <math id=\"S5.T1.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\tau\" display=\"inline\"><semantics id=\"S5.T1.2.2.1.m1.1a\"><mi id=\"S5.T1.2.2.1.m1.1.1\" xref=\"S5.T1.2.2.1.m1.1.1.cmml\">τ</mi><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.2.2.1.m1.1b\"><ci id=\"S5.T1.2.2.1.m1.1.1.cmml\" xref=\"S5.T1.2.2.1.m1.1.1\">𝜏</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.2.2.1.m1.1c\">\\tau</annotation></semantics></math>\n</th>\n<td id=\"S5.T1.2.2.3\" class=\"ltx_td ltx_align_right\">(%)</td>\n<td id=\"S5.T1.2.2.4\" class=\"ltx_td ltx_nopad_l ltx_align_right\">per word</td>\n<td id=\"S5.T1.2.2.5\" class=\"ltx_td ltx_nopad_l ltx_align_right\">(%)</td>\n</tr>\n<tr id=\"S5.T1.2.4.2\" class=\"ltx_tr\">\n<th id=\"S5.T1.2.4.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" colspan=\"5\"><span id=\"S5.T1.2.4.2.1.1\" class=\"ltx_text ltx_font_italic\">Reddit</span></th>\n</tr>\n<tr id=\"S5.T1.2.5.3\" class=\"ltx_tr\">\n<th id=\"S5.T1.2.5.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Word-Level</th>\n<th id=\"S5.T1.2.5.3.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Wiki</th>\n<td id=\"S5.T1.2.5.3.3\" class=\"ltx_td ltx_align_right\">13.0</td>\n<td id=\"S5.T1.2.5.3.4\" class=\"ltx_td ltx_nopad_l ltx_align_right\">1.00</td>\n<td id=\"S5.T1.2.5.3.5\" class=\"ltx_td ltx_nopad_l ltx_align_right\">17.7</td>\n</tr>\n<tr id=\"S5.T1.2.6.4\" class=\"ltx_tr\">\n<th id=\"S5.T1.2.6.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Word-Level</th>\n<th id=\"S5.T1.2.6.4.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Oracle</th>\n<td id=\"S5.T1.2.6.4.3\" class=\"ltx_td ltx_align_right\">5.5</td>\n<td id=\"S5.T1.2.6.4.4\" class=\"ltx_td ltx_nopad_l ltx_align_right\">1.00</td>\n<td id=\"S5.T1.2.6.4.5\" class=\"ltx_td ltx_nopad_l ltx_align_right\">24.1</td>\n</tr>\n<tr id=\"S5.T1.2.7.5\" class=\"ltx_tr\">\n<th id=\"S5.T1.2.7.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">BPE</th>\n<th id=\"S5.T1.2.7.5.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Wiki</th>\n<td id=\"S5.T1.2.7.5.3\" class=\"ltx_td ltx_align_right\">0.0</td>\n<td id=\"S5.T1.2.7.5.4\" class=\"ltx_td ltx_nopad_l ltx_align_right\">1.32</td>\n<td id=\"S5.T1.2.7.5.5\" class=\"ltx_td ltx_nopad_l ltx_align_right\">22.2</td>\n</tr>\n<tr id=\"S5.T1.2.8.6\" class=\"ltx_tr\">\n<th id=\"S5.T1.2.8.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">BPE</th>\n<th id=\"S5.T1.2.8.6.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Oracle</th>\n<td id=\"S5.T1.2.8.6.3\" class=\"ltx_td ltx_align_right\">0.0</td>\n<td id=\"S5.T1.2.8.6.4\" class=\"ltx_td ltx_nopad_l ltx_align_right\">1.22</td>\n<td id=\"S5.T1.2.8.6.5\" class=\"ltx_td ltx_nopad_l ltx_align_right\">22.5</td>\n</tr>\n<tr id=\"S5.T1.2.9.7\" class=\"ltx_tr\">\n<th id=\"S5.T1.2.9.7.1\" class=\"ltx_td ltx_nopad_r ltx_align_right ltx_th ltx_th_row ltx_border_t\" colspan=\"5\">\n<span id=\"S5.T1.2.9.7.1.1\" class=\"ltx_text ltx_font_italic\">StackOverflow</span>\n</th>\n</tr>\n<tr id=\"S5.T1.2.10.8\" class=\"ltx_tr\">\n<th id=\"S5.T1.2.10.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Word-Level</th>\n<th id=\"S5.T1.2.10.8.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Wiki</th>\n<td id=\"S5.T1.2.10.8.3\" class=\"ltx_td ltx_align_right\">9.8</td>\n<td id=\"S5.T1.2.10.8.4\" class=\"ltx_td ltx_nopad_l ltx_align_right\">1.00</td>\n<td id=\"S5.T1.2.10.8.5\" class=\"ltx_td ltx_nopad_l ltx_align_right\">30.0</td>\n</tr>\n<tr id=\"S5.T1.2.11.9\" class=\"ltx_tr\">\n<th id=\"S5.T1.2.11.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Word-Level</th>\n<th id=\"S5.T1.2.11.9.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Oracle</th>\n<td id=\"S5.T1.2.11.9.3\" class=\"ltx_td ltx_align_right\">2.0</td>\n<td id=\"S5.T1.2.11.9.4\" class=\"ltx_td ltx_nopad_l ltx_align_right\">1.00</td>\n<td id=\"S5.T1.2.11.9.5\" class=\"ltx_td ltx_nopad_l ltx_align_right\">33.0</td>\n</tr>\n<tr id=\"S5.T1.2.12.10\" class=\"ltx_tr\">\n<th id=\"S5.T1.2.12.10.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">BPE</th>\n<th id=\"S5.T1.2.12.10.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Wiki</th>\n<td id=\"S5.T1.2.12.10.3\" class=\"ltx_td ltx_align_right\">0.0</td>\n<td id=\"S5.T1.2.12.10.4\" class=\"ltx_td ltx_nopad_l ltx_align_right\">1.41</td>\n<td id=\"S5.T1.2.12.10.5\" class=\"ltx_td ltx_nopad_l ltx_align_right\">31.8</td>\n</tr>\n<tr id=\"S5.T1.2.13.11\" class=\"ltx_tr\">\n<th id=\"S5.T1.2.13.11.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">BPE</th>\n<th id=\"S5.T1.2.13.11.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\">Oracle</th>\n<td id=\"S5.T1.2.13.11.3\" class=\"ltx_td ltx_align_right ltx_border_bb\">0.0</td>\n<td id=\"S5.T1.2.13.11.4\" class=\"ltx_td ltx_nopad_l ltx_align_right ltx_border_bb\">1.24</td>\n<td id=\"S5.T1.2.13.11.5\" class=\"ltx_td ltx_nopad_l ltx_align_right ltx_border_bb\">32.4</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Table 1 summarizes experiments that use different\ntokenization schemes.\nWe compute statistics on tokenizers: the average share of OOV tokens for the\nword-level scheme and the average number of tokens required to encode one\nword for the sub-word scheme.\nTo compare the effect of each tokenizer on the PFL-trained model, we report word-level accuracy, for the reasons described in Section 3.2.\nThe “wiki” tokenizers are trained on the\nWikipedia data, and the “oracle” tokenizers directly on the training\ndata."
        ]
    },
    "S5.T2": {
        "caption": "Table 2: Tokenizers initialized on sampled data perform very close to using “oracle” data.",
        "table": "<table id=\"S5.T2.3\" class=\"ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T2.3.4.1\" class=\"ltx_tr\">\n<th id=\"S5.T2.3.4.1.1\" class=\"ltx_td ltx_th ltx_th_column\"></th>\n<th id=\"S5.T2.3.4.1.2\" class=\"ltx_td ltx_nopad_l ltx_th ltx_th_column ltx_border_r\"></th>\n<th id=\"S5.T2.3.4.1.3\" class=\"ltx_td ltx_nopad_l ltx_th ltx_th_column ltx_border_r\"></th>\n<th id=\"S5.T2.3.4.1.4\" class=\"ltx_td ltx_th ltx_th_column ltx_border_r\"></th>\n<th id=\"S5.T2.3.4.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" colspan=\"2\">LM</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T2.3.5.1\" class=\"ltx_tr\">\n<td id=\"S5.T2.3.5.1.1\" class=\"ltx_td ltx_align_left\">Type</td>\n<td id=\"S5.T2.3.5.1.2\" class=\"ltx_td ltx_nopad_l ltx_align_left ltx_border_r\">Data</td>\n<td id=\"S5.T2.3.5.1.3\" class=\"ltx_td ltx_nopad_l ltx_align_right ltx_border_r\">Data</td>\n<td id=\"S5.T2.3.5.1.4\" class=\"ltx_td ltx_align_right ltx_border_r\">Tokens</td>\n<td id=\"S5.T2.3.5.1.5\" class=\"ltx_td ltx_align_right\">Acc.</td>\n<td id=\"S5.T2.3.5.1.6\" class=\"ltx_td ltx_nopad_l ltx_align_right\">Perp.</td>\n</tr>\n<tr id=\"S5.T2.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.2\" class=\"ltx_td\"></td>\n<td id=\"S5.T2.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_align_left ltx_border_r\">to train <math id=\"S5.T2.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\tau\" display=\"inline\"><semantics id=\"S5.T2.1.1.1.m1.1a\"><mi id=\"S5.T2.1.1.1.m1.1.1\" xref=\"S5.T2.1.1.1.m1.1.1.cmml\">τ</mi><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.1.1.1.m1.1b\"><ci id=\"S5.T2.1.1.1.m1.1.1.cmml\" xref=\"S5.T2.1.1.1.m1.1.1\">𝜏</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.1.1.1.m1.1c\">\\tau</annotation></semantics></math>\n</td>\n<td id=\"S5.T2.1.1.3\" class=\"ltx_td ltx_nopad_l ltx_align_right ltx_border_r\">KLD</td>\n<td id=\"S5.T2.1.1.4\" class=\"ltx_td ltx_align_right ltx_border_r\">p/word</td>\n<td id=\"S5.T2.1.1.5\" class=\"ltx_td ltx_align_right\">(%)</td>\n<td id=\"S5.T2.1.1.6\" class=\"ltx_td ltx_nopad_l\"></td>\n</tr>\n<tr id=\"S5.T2.3.6.2\" class=\"ltx_tr\">\n<th id=\"S5.T2.3.6.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-bottom:5.69046pt;\" colspan=\"5\"><span id=\"S5.T2.3.6.2.1.1\" class=\"ltx_text ltx_font_italic\">Reddit</span></th>\n<th id=\"S5.T2.3.6.2.2\" class=\"ltx_td ltx_th ltx_th_column ltx_border_t\" style=\"padding-bottom:5.69046pt;\"></th>\n</tr>\n<tr id=\"S5.T2.3.7.3\" class=\"ltx_tr\">\n<td id=\"S5.T2.3.7.3.1\" class=\"ltx_td ltx_align_left\">BPE</td>\n<td id=\"S5.T2.3.7.3.2\" class=\"ltx_td ltx_nopad_l ltx_align_left ltx_border_r\">Wiki</td>\n<td id=\"S5.T2.3.7.3.3\" class=\"ltx_td ltx_nopad_l ltx_align_right ltx_border_r\">0.78</td>\n<td id=\"S5.T2.3.7.3.4\" class=\"ltx_td ltx_align_right ltx_border_r\">1.32</td>\n<td id=\"S5.T2.3.7.3.5\" class=\"ltx_td ltx_align_right\">22.2</td>\n<td id=\"S5.T2.3.7.3.6\" class=\"ltx_td ltx_nopad_l ltx_align_right\">276.5</td>\n</tr>\n<tr id=\"S5.T2.3.8.4\" class=\"ltx_tr\">\n<td id=\"S5.T2.3.8.4.1\" class=\"ltx_td ltx_align_left\" style=\"padding-bottom:5.69046pt;\">BPE</td>\n<td id=\"S5.T2.3.8.4.2\" class=\"ltx_td ltx_nopad_l ltx_align_left ltx_border_r\" style=\"padding-bottom:5.69046pt;\">Oracle</td>\n<td id=\"S5.T2.3.8.4.3\" class=\"ltx_td ltx_nopad_l ltx_align_right ltx_border_r\" style=\"padding-bottom:5.69046pt;\">0</td>\n<td id=\"S5.T2.3.8.4.4\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-bottom:5.69046pt;\">1.22</td>\n<td id=\"S5.T2.3.8.4.5\" class=\"ltx_td ltx_align_right\" style=\"padding-bottom:5.69046pt;\">22.5</td>\n<td id=\"S5.T2.3.8.4.6\" class=\"ltx_td ltx_nopad_l ltx_align_right\" style=\"padding-bottom:5.69046pt;\">256.9</td>\n</tr>\n<tr id=\"S5.T2.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T2.2.2.2\" class=\"ltx_td ltx_align_left\">BPE</td>\n<td id=\"S5.T2.2.2.1\" class=\"ltx_td ltx_nopad_l ltx_align_left ltx_border_r\">Heavy hitters<sup id=\"S5.T2.2.2.1.1\" class=\"ltx_sup\">∗</sup>\n</td>\n<td id=\"S5.T2.2.2.3\" class=\"ltx_td ltx_nopad_l ltx_align_right ltx_border_r\">0.09</td>\n<td id=\"S5.T2.2.2.4\" class=\"ltx_td ltx_align_right ltx_border_r\">1.30</td>\n<td id=\"S5.T2.2.2.5\" class=\"ltx_td ltx_align_right\">22.1</td>\n<td id=\"S5.T2.2.2.6\" class=\"ltx_td ltx_nopad_l ltx_align_right\">274.2</td>\n</tr>\n<tr id=\"S5.T2.3.9.5\" class=\"ltx_tr\">\n<td id=\"S5.T2.3.9.5.1\" class=\"ltx_td ltx_align_left\">BPE</td>\n<td id=\"S5.T2.3.9.5.2\" class=\"ltx_td ltx_nopad_l ltx_align_left ltx_border_r\"><span id=\"S5.T2.3.9.5.2.1\" class=\"ltx_text ltx_font_bold\">Sampled</span></td>\n<td id=\"S5.T2.3.9.5.3\" class=\"ltx_td ltx_nopad_l ltx_align_right ltx_border_r\">0.02</td>\n<td id=\"S5.T2.3.9.5.4\" class=\"ltx_td ltx_align_right ltx_border_r\">1.22</td>\n<td id=\"S5.T2.3.9.5.5\" class=\"ltx_td ltx_align_right\">22.5</td>\n<td id=\"S5.T2.3.9.5.6\" class=\"ltx_td ltx_nopad_l ltx_align_right\">257.7</td>\n</tr>\n<tr id=\"S5.T2.3.10.6\" class=\"ltx_tr\">\n<th id=\"S5.T2.3.10.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-bottom:5.69046pt;\" colspan=\"5\"><span id=\"S5.T2.3.10.6.1.1\" class=\"ltx_text ltx_font_italic\">StackOverflow</span></th>\n<th id=\"S5.T2.3.10.6.2\" class=\"ltx_td ltx_th ltx_th_column ltx_border_t\" style=\"padding-bottom:5.69046pt;\"></th>\n</tr>\n<tr id=\"S5.T2.3.11.7\" class=\"ltx_tr\">\n<td id=\"S5.T2.3.11.7.1\" class=\"ltx_td ltx_align_left\">BPE</td>\n<td id=\"S5.T2.3.11.7.2\" class=\"ltx_td ltx_nopad_l ltx_align_left ltx_border_r\">Wiki</td>\n<td id=\"S5.T2.3.11.7.3\" class=\"ltx_td ltx_nopad_l ltx_align_right ltx_border_r\">1.06</td>\n<td id=\"S5.T2.3.11.7.4\" class=\"ltx_td ltx_align_right ltx_border_r\">1.41</td>\n<td id=\"S5.T2.3.11.7.5\" class=\"ltx_td ltx_align_right\">31.8</td>\n<td id=\"S5.T2.3.11.7.6\" class=\"ltx_td ltx_nopad_l ltx_align_right\">124.6</td>\n</tr>\n<tr id=\"S5.T2.3.12.8\" class=\"ltx_tr\">\n<td id=\"S5.T2.3.12.8.1\" class=\"ltx_td ltx_align_left\" style=\"padding-bottom:5.69046pt;\">BPE</td>\n<td id=\"S5.T2.3.12.8.2\" class=\"ltx_td ltx_nopad_l ltx_align_left ltx_border_r\" style=\"padding-bottom:5.69046pt;\">Oracle</td>\n<td id=\"S5.T2.3.12.8.3\" class=\"ltx_td ltx_nopad_l ltx_align_right ltx_border_r\" style=\"padding-bottom:5.69046pt;\">0</td>\n<td id=\"S5.T2.3.12.8.4\" class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-bottom:5.69046pt;\">1.24</td>\n<td id=\"S5.T2.3.12.8.5\" class=\"ltx_td ltx_align_right\" style=\"padding-bottom:5.69046pt;\">32.4</td>\n<td id=\"S5.T2.3.12.8.6\" class=\"ltx_td ltx_nopad_l ltx_align_right\" style=\"padding-bottom:5.69046pt;\">108.2</td>\n</tr>\n<tr id=\"S5.T2.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T2.3.3.2\" class=\"ltx_td ltx_align_left\">BPE</td>\n<td id=\"S5.T2.3.3.1\" class=\"ltx_td ltx_nopad_l ltx_align_left ltx_border_r\">Heavy hitters<sup id=\"S5.T2.3.3.1.1\" class=\"ltx_sup\">∗</sup>\n</td>\n<td id=\"S5.T2.3.3.3\" class=\"ltx_td ltx_nopad_l ltx_align_right ltx_border_r\">0.10</td>\n<td id=\"S5.T2.3.3.4\" class=\"ltx_td ltx_align_right ltx_border_r\">1.29</td>\n<td id=\"S5.T2.3.3.5\" class=\"ltx_td ltx_align_right\">32.1</td>\n<td id=\"S5.T2.3.3.6\" class=\"ltx_td ltx_nopad_l ltx_align_right\">115.9</td>\n</tr>\n<tr id=\"S5.T2.3.13.9\" class=\"ltx_tr\">\n<td id=\"S5.T2.3.13.9.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">BPE</td>\n<td id=\"S5.T2.3.13.9.2\" class=\"ltx_td ltx_nopad_l ltx_align_left ltx_border_bb ltx_border_r\"><span id=\"S5.T2.3.13.9.2.1\" class=\"ltx_text ltx_font_bold\">Sampled</span></td>\n<td id=\"S5.T2.3.13.9.3\" class=\"ltx_td ltx_nopad_l ltx_align_right ltx_border_bb ltx_border_r\">0.01</td>\n<td id=\"S5.T2.3.13.9.4\" class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\">1.23</td>\n<td id=\"S5.T2.3.13.9.5\" class=\"ltx_td ltx_align_right ltx_border_bb\">32.4</td>\n<td id=\"S5.T2.3.13.9.6\" class=\"ltx_td ltx_nopad_l ltx_align_right ltx_border_bb\">108.7</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "∗The “heavy hitters” algorithm requires additional privacy budget.",
        "references": [
            "Second, Table 2 further investigates the properties of the\nsampled text. The “BPE sample” rows refer to the method proposed in\nthis paper. A language model with the “wiki” tokenizer is trained\nwith PFL on the first half of the training data. Then samples are drawn\nfrom this language model. Then, the language model is trained from\nscratch on the second half of the training data.",
            "First, consider the choice to train the public tokenizer on Wikipedia data.\nTo examine the effect of using a more conversational style corpus.\nTo do this, Table 3 takes a subset of the numbers from Table 2 and adds a scenario where a tokenizer on StackOverflow data is used with Reddit data and vice versa.\nThe cross-dataset numbers are highlighted bold in the table."
        ]
    },
    "A1.T3": {
        "caption": "Table 3: The effect of using the Wikipedia corpus against the results in Table 2.",
        "table": "<table id=\"A1.T3.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"A1.T3.1.1\" class=\"ltx_tr\">\n<td id=\"A1.T3.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_tt\"><math id=\"A1.T3.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\tau\" display=\"inline\"><semantics id=\"A1.T3.1.1.1.m1.1a\"><mi id=\"A1.T3.1.1.1.m1.1.1\" xref=\"A1.T3.1.1.1.m1.1.1.cmml\">τ</mi><annotation-xml encoding=\"MathML-Content\" id=\"A1.T3.1.1.1.m1.1b\"><ci id=\"A1.T3.1.1.1.m1.1.1.cmml\" xref=\"A1.T3.1.1.1.m1.1.1\">𝜏</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T3.1.1.1.m1.1c\">\\tau</annotation></semantics></math></td>\n<td id=\"A1.T3.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\">Data</td>\n<td id=\"A1.T3.1.1.3\" class=\"ltx_td ltx_nopad_l ltx_align_left ltx_border_r ltx_border_tt\">Data</td>\n<td id=\"A1.T3.1.1.4\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_tt\">LM</td>\n</tr>\n<tr id=\"A1.T3.1.2.1\" class=\"ltx_tr\">\n<td id=\"A1.T3.1.2.1.1\" class=\"ltx_td\"></td>\n<td id=\"A1.T3.1.2.1.2\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"A1.T3.1.2.1.3\" class=\"ltx_td ltx_nopad_l ltx_align_left ltx_border_r\">KLD</td>\n<td id=\"A1.T3.1.2.1.4\" class=\"ltx_td ltx_nopad_l ltx_align_center\">perp.</td>\n</tr>\n<tr id=\"A1.T3.1.3.2\" class=\"ltx_tr\">\n<td id=\"A1.T3.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"4\"><span id=\"A1.T3.1.3.2.1.1\" class=\"ltx_text ltx_font_italic\">Reddit</span></td>\n</tr>\n<tr id=\"A1.T3.1.4.3\" class=\"ltx_tr\">\n<td id=\"A1.T3.1.4.3.1\" class=\"ltx_td ltx_align_left\">BPE</td>\n<td id=\"A1.T3.1.4.3.2\" class=\"ltx_td ltx_align_left ltx_border_r\">Wikipedia</td>\n<td id=\"A1.T3.1.4.3.3\" class=\"ltx_td ltx_nopad_l ltx_align_left ltx_border_r\">0.7826</td>\n<td id=\"A1.T3.1.4.3.4\" class=\"ltx_td ltx_nopad_l ltx_align_center\">276.5</td>\n</tr>\n<tr id=\"A1.T3.1.5.4\" class=\"ltx_tr\">\n<td id=\"A1.T3.1.5.4.1\" class=\"ltx_td ltx_align_left\">BPE</td>\n<td id=\"A1.T3.1.5.4.2\" class=\"ltx_td ltx_align_left ltx_border_r\"><span id=\"A1.T3.1.5.4.2.1\" class=\"ltx_text ltx_font_bold\">StackOverflow</span></td>\n<td id=\"A1.T3.1.5.4.3\" class=\"ltx_td ltx_nopad_l ltx_align_left ltx_border_r\">0.6046</td>\n<td id=\"A1.T3.1.5.4.4\" class=\"ltx_td ltx_nopad_l ltx_align_center\">283.6</td>\n</tr>\n<tr id=\"A1.T3.1.6.5\" class=\"ltx_tr\">\n<td id=\"A1.T3.1.6.5.1\" class=\"ltx_td ltx_align_left\">BPE</td>\n<td id=\"A1.T3.1.6.5.2\" class=\"ltx_td ltx_align_left ltx_border_r\">Reddit</td>\n<td id=\"A1.T3.1.6.5.3\" class=\"ltx_td ltx_nopad_l ltx_align_left ltx_border_r\">0</td>\n<td id=\"A1.T3.1.6.5.4\" class=\"ltx_td ltx_nopad_l ltx_align_center\">256.9</td>\n</tr>\n<tr id=\"A1.T3.1.7.6\" class=\"ltx_tr\">\n<td id=\"A1.T3.1.7.6.1\" class=\"ltx_td ltx_align_left ltx_border_t\">BPE</td>\n<td id=\"A1.T3.1.7.6.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">sample</td>\n<td id=\"A1.T3.1.7.6.3\" class=\"ltx_td ltx_nopad_l ltx_align_left ltx_border_r ltx_border_t\">0.0212</td>\n<td id=\"A1.T3.1.7.6.4\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_t\">257.7</td>\n</tr>\n<tr id=\"A1.T3.1.8.7\" class=\"ltx_tr\">\n<td id=\"A1.T3.1.8.7.1\" class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"4\"><span id=\"A1.T3.1.8.7.1.1\" class=\"ltx_text ltx_font_italic\">StackOverflow</span></td>\n</tr>\n<tr id=\"A1.T3.1.9.8\" class=\"ltx_tr\">\n<td id=\"A1.T3.1.9.8.1\" class=\"ltx_td ltx_align_left\">BPE</td>\n<td id=\"A1.T3.1.9.8.2\" class=\"ltx_td ltx_align_left ltx_border_r\">Wikipedia</td>\n<td id=\"A1.T3.1.9.8.3\" class=\"ltx_td ltx_nopad_l ltx_align_left ltx_border_r\">1.0629</td>\n<td id=\"A1.T3.1.9.8.4\" class=\"ltx_td ltx_nopad_l ltx_align_center\">124.6</td>\n</tr>\n<tr id=\"A1.T3.1.10.9\" class=\"ltx_tr\">\n<td id=\"A1.T3.1.10.9.1\" class=\"ltx_td ltx_align_left\">BPE</td>\n<td id=\"A1.T3.1.10.9.2\" class=\"ltx_td ltx_align_left ltx_border_r\"><span id=\"A1.T3.1.10.9.2.1\" class=\"ltx_text ltx_font_bold\">Reddit</span></td>\n<td id=\"A1.T3.1.10.9.3\" class=\"ltx_td ltx_nopad_l ltx_align_left ltx_border_r\">0.5315</td>\n<td id=\"A1.T3.1.10.9.4\" class=\"ltx_td ltx_nopad_l ltx_align_center\">118.8</td>\n</tr>\n<tr id=\"A1.T3.1.11.10\" class=\"ltx_tr\">\n<td id=\"A1.T3.1.11.10.1\" class=\"ltx_td ltx_align_left\">BPE</td>\n<td id=\"A1.T3.1.11.10.2\" class=\"ltx_td ltx_align_left ltx_border_r\">StackOverflow</td>\n<td id=\"A1.T3.1.11.10.3\" class=\"ltx_td ltx_nopad_l ltx_align_left ltx_border_r\">0</td>\n<td id=\"A1.T3.1.11.10.4\" class=\"ltx_td ltx_nopad_l ltx_align_center\">108.2</td>\n</tr>\n<tr id=\"A1.T3.1.12.11\" class=\"ltx_tr\">\n<td id=\"A1.T3.1.12.11.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\">BPE</td>\n<td id=\"A1.T3.1.12.11.2\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t\">sample</td>\n<td id=\"A1.T3.1.12.11.3\" class=\"ltx_td ltx_nopad_l ltx_align_left ltx_border_bb ltx_border_r ltx_border_t\">0.0089</td>\n<td id=\"A1.T3.1.12.11.4\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_t\">108.7</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "First, consider the choice to train the public tokenizer on Wikipedia data.\nTo examine the effect of using a more conversational style corpus.\nTo do this, Table 3 takes a subset of the numbers from Table 2 and adds a scenario where a tokenizer on StackOverflow data is used with Reddit data and vice versa.\nThe cross-dataset numbers are highlighted bold in the table."
        ]
    },
    "A1.T4": {
        "caption": "Table 4: The effect of varying the vocabulary size.",
        "table": "<table id=\"A1.T4.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A1.T4.1.1.1\" class=\"ltx_tr\">\n<th id=\"A1.T4.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\">Vocab size</th>\n<th id=\"A1.T4.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" colspan=\"2\">Reddit</th>\n<th id=\"A1.T4.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\">StackOverflow</th>\n</tr>\n<tr id=\"A1.T4.1.2.2\" class=\"ltx_tr\">\n<th id=\"A1.T4.1.2.2.1\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r\"></th>\n<th id=\"A1.T4.1.2.2.2\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column\">Wiki</th>\n<th id=\"A1.T4.1.2.2.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r\">Oracle</th>\n<th id=\"A1.T4.1.2.2.4\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column\">Wiki</th>\n<th id=\"A1.T4.1.2.2.5\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column\">Oracle</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A1.T4.1.3.1\" class=\"ltx_tr\">\n<th id=\"A1.T4.1.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">5,000</th>\n<td id=\"A1.T4.1.3.1.2\" class=\"ltx_td ltx_align_right ltx_border_t\">304.3</td>\n<td id=\"A1.T4.1.3.1.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">282.2</td>\n<td id=\"A1.T4.1.3.1.4\" class=\"ltx_td ltx_align_right ltx_border_t\">136.3</td>\n<td id=\"A1.T4.1.3.1.5\" class=\"ltx_td ltx_align_right ltx_border_t\">116.8</td>\n</tr>\n<tr id=\"A1.T4.1.4.2\" class=\"ltx_tr\">\n<th id=\"A1.T4.1.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">10,000</th>\n<td id=\"A1.T4.1.4.2.2\" class=\"ltx_td ltx_align_right\">276.5</td>\n<td id=\"A1.T4.1.4.2.3\" class=\"ltx_td ltx_align_right ltx_border_r\">256.9</td>\n<td id=\"A1.T4.1.4.2.4\" class=\"ltx_td ltx_align_right\">124.6</td>\n<td id=\"A1.T4.1.4.2.5\" class=\"ltx_td ltx_align_right\">108.2</td>\n</tr>\n<tr id=\"A1.T4.1.5.3\" class=\"ltx_tr\">\n<th id=\"A1.T4.1.5.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">50,000</th>\n<td id=\"A1.T4.1.5.3.2\" class=\"ltx_td ltx_align_right\">243.9</td>\n<td id=\"A1.T4.1.5.3.3\" class=\"ltx_td ltx_align_right ltx_border_r\">225.4</td>\n<td id=\"A1.T4.1.5.3.4\" class=\"ltx_td ltx_align_right\">111.5</td>\n<td id=\"A1.T4.1.5.3.5\" class=\"ltx_td ltx_align_right\">101.5</td>\n</tr>\n<tr id=\"A1.T4.1.6.4\" class=\"ltx_tr\">\n<th id=\"A1.T4.1.6.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\">100,000</th>\n<td id=\"A1.T4.1.6.4.2\" class=\"ltx_td ltx_align_right ltx_border_bb\">231.2</td>\n<td id=\"A1.T4.1.6.4.3\" class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\">217.9</td>\n<td id=\"A1.T4.1.6.4.4\" class=\"ltx_td ltx_align_right ltx_border_bb\">108.9</td>\n<td id=\"A1.T4.1.6.4.5\" class=\"ltx_td ltx_align_right ltx_border_bb\">100.5</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Then, consider the choice of vocabulary size, here the number of distinct tokens.\nTable 4 shows the perplexities for the baseline (“Wiki”) and ceiling (“oracle”) experiments.\nThough the absolute numbers change, the trends do not change."
        ]
    },
    "A1.T5": {
        "caption": "Table 5: The effect of changing model architectures.",
        "table": "<table id=\"A1.T5.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A1.T5.1.1.1\" class=\"ltx_tr\">\n<th id=\"A1.T5.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\">Model</th>\n<th id=\"A1.T5.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" colspan=\"2\">Reddit</th>\n<th id=\"A1.T5.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\">StackOverflow</th>\n</tr>\n<tr id=\"A1.T5.1.2.2\" class=\"ltx_tr\">\n<th id=\"A1.T5.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r\">architecture</th>\n<th id=\"A1.T5.1.2.2.2\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column\">Wiki</th>\n<th id=\"A1.T5.1.2.2.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r\">Oracle</th>\n<th id=\"A1.T5.1.2.2.4\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column\">Wiki</th>\n<th id=\"A1.T5.1.2.2.5\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column\">Oracle</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A1.T5.1.3.1\" class=\"ltx_tr\">\n<th id=\"A1.T5.1.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Transformer</th>\n<td id=\"A1.T5.1.3.1.2\" class=\"ltx_td ltx_align_right ltx_border_t\">261.9</td>\n<td id=\"A1.T5.1.3.1.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">244.8</td>\n<td id=\"A1.T5.1.3.1.4\" class=\"ltx_td ltx_align_right ltx_border_t\">117.4</td>\n<td id=\"A1.T5.1.3.1.5\" class=\"ltx_td ltx_align_right ltx_border_t\">107.0</td>\n</tr>\n<tr id=\"A1.T5.1.4.2\" class=\"ltx_tr\">\n<th id=\"A1.T5.1.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\">LSTM</th>\n<td id=\"A1.T5.1.4.2.2\" class=\"ltx_td ltx_align_right ltx_border_bb\">276.5</td>\n<td id=\"A1.T5.1.4.2.3\" class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_r\">256.9</td>\n<td id=\"A1.T5.1.4.2.4\" class=\"ltx_td ltx_align_right ltx_border_bb\">124.6</td>\n<td id=\"A1.T5.1.4.2.5\" class=\"ltx_td ltx_align_right ltx_border_bb\">108.2</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Similarly for changing model architectures.\nThis paper has presented results on an LSTM model.\nTable 5 shows results on a Transformer model.\nAgain, though the absolute numbers change, the trends do not change."
        ]
    }
}