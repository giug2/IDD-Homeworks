{
    "PAPER'S NUMBER OF TABLES": 4,
    "S6.T1": {
        "caption": "Table 1. GPS-AFL Experiment Settings",
        "table": "<table id=\"S6.T1.11\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S6.T1.11.12.1\" class=\"ltx_tr\">\n<th id=\"S6.T1.11.12.1.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S6.T1.11.12.1.1.1\" class=\"ltx_text ltx_font_bold\">Parameters</span></th>\n<th id=\"S6.T1.11.12.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S6.T1.11.12.1.2.1\" class=\"ltx_text ltx_font_bold\">Value</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T1.1.1\" class=\"ltx_tr\">\n<th id=\"S6.T1.1.1.2\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">Number of participant</th>\n<td id=\"S6.T1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><math id=\"S6.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"60\" display=\"inline\"><semantics id=\"S6.T1.1.1.1.m1.1a\"><mn id=\"S6.T1.1.1.1.m1.1.1\" xref=\"S6.T1.1.1.1.m1.1.1.cmml\">60</mn><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.1.1.1.m1.1b\"><cn type=\"integer\" id=\"S6.T1.1.1.1.m1.1.1.cmml\" xref=\"S6.T1.1.1.1.m1.1.1\">60</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.1.1.1.m1.1c\">60</annotation></semantics></math></td>\n</tr>\n<tr id=\"S6.T1.11.13.1\" class=\"ltx_tr\">\n<th id=\"S6.T1.11.13.1.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r\">Local Epoch(s)</th>\n<td id=\"S6.T1.11.13.1.2\" class=\"ltx_td ltx_align_left ltx_border_r\">1</td>\n</tr>\n<tr id=\"S6.T1.3.3\" class=\"ltx_tr\">\n<th id=\"S6.T1.2.2.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r\"><math id=\"S6.T1.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\theta_{f}\" display=\"inline\"><semantics id=\"S6.T1.2.2.1.m1.1a\"><msub id=\"S6.T1.2.2.1.m1.1.1\" xref=\"S6.T1.2.2.1.m1.1.1.cmml\"><mi id=\"S6.T1.2.2.1.m1.1.1.2\" xref=\"S6.T1.2.2.1.m1.1.1.2.cmml\">Î¸</mi><mi id=\"S6.T1.2.2.1.m1.1.1.3\" xref=\"S6.T1.2.2.1.m1.1.1.3.cmml\">f</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.2.2.1.m1.1b\"><apply id=\"S6.T1.2.2.1.m1.1.1.cmml\" xref=\"S6.T1.2.2.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S6.T1.2.2.1.m1.1.1.1.cmml\" xref=\"S6.T1.2.2.1.m1.1.1\">subscript</csymbol><ci id=\"S6.T1.2.2.1.m1.1.1.2.cmml\" xref=\"S6.T1.2.2.1.m1.1.1.2\">ğœƒ</ci><ci id=\"S6.T1.2.2.1.m1.1.1.3.cmml\" xref=\"S6.T1.2.2.1.m1.1.1.3\">ğ‘“</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.2.2.1.m1.1c\">\\theta_{f}</annotation></semantics></math></th>\n<td id=\"S6.T1.3.3.2\" class=\"ltx_td ltx_align_left ltx_border_r\"><math id=\"S6.T1.3.3.2.m1.1\" class=\"ltx_Math\" alttext=\"400\" display=\"inline\"><semantics id=\"S6.T1.3.3.2.m1.1a\"><mn id=\"S6.T1.3.3.2.m1.1.1\" xref=\"S6.T1.3.3.2.m1.1.1.cmml\">400</mn><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.3.3.2.m1.1b\"><cn type=\"integer\" id=\"S6.T1.3.3.2.m1.1.1.cmml\" xref=\"S6.T1.3.3.2.m1.1.1\">400</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.3.3.2.m1.1c\">400</annotation></semantics></math></td>\n</tr>\n<tr id=\"S6.T1.5.5\" class=\"ltx_tr\">\n<th id=\"S6.T1.4.4.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r\"><math id=\"S6.T1.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"\\mathcal{T}\" display=\"inline\"><semantics id=\"S6.T1.4.4.1.m1.1a\"><mi class=\"ltx_font_mathcaligraphic\" id=\"S6.T1.4.4.1.m1.1.1\" xref=\"S6.T1.4.4.1.m1.1.1.cmml\">ğ’¯</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.4.4.1.m1.1b\"><ci id=\"S6.T1.4.4.1.m1.1.1.cmml\" xref=\"S6.T1.4.4.1.m1.1.1\">ğ’¯</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.4.4.1.m1.1c\">\\mathcal{T}</annotation></semantics></math></th>\n<td id=\"S6.T1.5.5.2\" class=\"ltx_td ltx_align_left ltx_border_r\"><math id=\"S6.T1.5.5.2.m1.1\" class=\"ltx_Math\" alttext=\"80\" display=\"inline\"><semantics id=\"S6.T1.5.5.2.m1.1a\"><mn id=\"S6.T1.5.5.2.m1.1.1\" xref=\"S6.T1.5.5.2.m1.1.1.cmml\">80</mn><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.5.5.2.m1.1b\"><cn type=\"integer\" id=\"S6.T1.5.5.2.m1.1.1.cmml\" xref=\"S6.T1.5.5.2.m1.1.1\">80</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.5.5.2.m1.1c\">80</annotation></semantics></math></td>\n</tr>\n<tr id=\"S6.T1.7.7\" class=\"ltx_tr\">\n<th id=\"S6.T1.6.6.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r\"><math id=\"S6.T1.6.6.1.m1.1\" class=\"ltx_Math\" alttext=\"t_{r}\" display=\"inline\"><semantics id=\"S6.T1.6.6.1.m1.1a\"><msub id=\"S6.T1.6.6.1.m1.1.1\" xref=\"S6.T1.6.6.1.m1.1.1.cmml\"><mi id=\"S6.T1.6.6.1.m1.1.1.2\" xref=\"S6.T1.6.6.1.m1.1.1.2.cmml\">t</mi><mi id=\"S6.T1.6.6.1.m1.1.1.3\" xref=\"S6.T1.6.6.1.m1.1.1.3.cmml\">r</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.6.6.1.m1.1b\"><apply id=\"S6.T1.6.6.1.m1.1.1.cmml\" xref=\"S6.T1.6.6.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S6.T1.6.6.1.m1.1.1.1.cmml\" xref=\"S6.T1.6.6.1.m1.1.1\">subscript</csymbol><ci id=\"S6.T1.6.6.1.m1.1.1.2.cmml\" xref=\"S6.T1.6.6.1.m1.1.1.2\">ğ‘¡</ci><ci id=\"S6.T1.6.6.1.m1.1.1.3.cmml\" xref=\"S6.T1.6.6.1.m1.1.1.3\">ğ‘Ÿ</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.6.6.1.m1.1c\">t_{r}</annotation></semantics></math></th>\n<td id=\"S6.T1.7.7.2\" class=\"ltx_td ltx_align_left ltx_border_r\"><math id=\"S6.T1.7.7.2.m1.1\" class=\"ltx_Math\" alttext=\"1\" display=\"inline\"><semantics id=\"S6.T1.7.7.2.m1.1a\"><mn id=\"S6.T1.7.7.2.m1.1.1\" xref=\"S6.T1.7.7.2.m1.1.1.cmml\">1</mn><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.7.7.2.m1.1b\"><cn type=\"integer\" id=\"S6.T1.7.7.2.m1.1.1.cmml\" xref=\"S6.T1.7.7.2.m1.1.1\">1</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.7.7.2.m1.1c\">1</annotation></semantics></math></td>\n</tr>\n<tr id=\"S6.T1.9.9\" class=\"ltx_tr\">\n<th id=\"S6.T1.8.8.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_l ltx_border_r\"><math id=\"S6.T1.8.8.1.m1.1\" class=\"ltx_Math\" alttext=\"\\psi_{f}\" display=\"inline\"><semantics id=\"S6.T1.8.8.1.m1.1a\"><msub id=\"S6.T1.8.8.1.m1.1.1\" xref=\"S6.T1.8.8.1.m1.1.1.cmml\"><mi id=\"S6.T1.8.8.1.m1.1.1.2\" xref=\"S6.T1.8.8.1.m1.1.1.2.cmml\">Ïˆ</mi><mi id=\"S6.T1.8.8.1.m1.1.1.3\" xref=\"S6.T1.8.8.1.m1.1.1.3.cmml\">f</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.8.8.1.m1.1b\"><apply id=\"S6.T1.8.8.1.m1.1.1.cmml\" xref=\"S6.T1.8.8.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S6.T1.8.8.1.m1.1.1.1.cmml\" xref=\"S6.T1.8.8.1.m1.1.1\">subscript</csymbol><ci id=\"S6.T1.8.8.1.m1.1.1.2.cmml\" xref=\"S6.T1.8.8.1.m1.1.1.2\">ğœ“</ci><ci id=\"S6.T1.8.8.1.m1.1.1.3.cmml\" xref=\"S6.T1.8.8.1.m1.1.1.3\">ğ‘“</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.8.8.1.m1.1c\">\\psi_{f}</annotation></semantics></math></th>\n<td id=\"S6.T1.9.9.2\" class=\"ltx_td ltx_align_left ltx_border_r\"><math id=\"S6.T1.9.9.2.m1.1\" class=\"ltx_Math\" alttext=\"0.7\" display=\"inline\"><semantics id=\"S6.T1.9.9.2.m1.1a\"><mn id=\"S6.T1.9.9.2.m1.1.1\" xref=\"S6.T1.9.9.2.m1.1.1.cmml\">0.7</mn><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.9.9.2.m1.1b\"><cn type=\"float\" id=\"S6.T1.9.9.2.m1.1.1.cmml\" xref=\"S6.T1.9.9.2.m1.1.1\">0.7</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.9.9.2.m1.1c\">0.7</annotation></semantics></math></td>\n</tr>\n<tr id=\"S6.T1.11.11\" class=\"ltx_tr\">\n<th id=\"S6.T1.10.10.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r\"><math id=\"S6.T1.10.10.1.m1.1\" class=\"ltx_Math\" alttext=\"V\" display=\"inline\"><semantics id=\"S6.T1.10.10.1.m1.1a\"><mi id=\"S6.T1.10.10.1.m1.1.1\" xref=\"S6.T1.10.10.1.m1.1.1.cmml\">V</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.10.10.1.m1.1b\"><ci id=\"S6.T1.10.10.1.m1.1.1.cmml\" xref=\"S6.T1.10.10.1.m1.1.1\">ğ‘‰</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.10.10.1.m1.1c\">V</annotation></semantics></math></th>\n<td id=\"S6.T1.11.11.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\"><math id=\"S6.T1.11.11.2.m1.1\" class=\"ltx_Math\" alttext=\"1\" display=\"inline\"><semantics id=\"S6.T1.11.11.2.m1.1a\"><mn id=\"S6.T1.11.11.2.m1.1.1\" xref=\"S6.T1.11.11.2.m1.1.1.cmml\">1</mn><annotation-xml encoding=\"MathML-Content\" id=\"S6.T1.11.11.2.m1.1b\"><cn type=\"integer\" id=\"S6.T1.11.11.2.m1.1.1.cmml\" xref=\"S6.T1.11.11.2.m1.1.1\">1</cn></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T1.11.11.2.m1.1c\">1</annotation></semantics></math></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "FMNIST: For the FMNIST dataset, the global model comprises of two similar convolutional layers as before, but an additional batch normalization step is added after each convolutional layer. Followed by three fully connected layers with 1568,50015685001568,500 and 200200200 hidden units, respectively. The optimization method chosen for both tasks is stochastic gradient descent with momentum of 0.70.70.7, batch size of 128128128 and learning rate of 0.010.010.01. The other experimental parameter settings are as shown in Table 1."
        ]
    },
    "S6.T2": {
        "caption": "Table 2. Comparison results under the MNIST dataset.",
        "table": "<table id=\"S6.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S6.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S6.T2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\"><span id=\"S6.T2.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></th>\n<th id=\"S6.T2.1.1.1.2\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\"><span id=\"S6.T2.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Total Utility</span></th>\n<th id=\"S6.T2.1.1.1.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\"><span id=\"S6.T2.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Total Cost</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T2.1.2.1\" class=\"ltx_tr\">\n<th id=\"S6.T2.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">Greedy</th>\n<td id=\"S6.T2.1.2.1.2\" class=\"ltx_td ltx_align_right ltx_border_t\">3,538.02</td>\n<td id=\"S6.T2.1.2.1.3\" class=\"ltx_td ltx_align_right ltx_border_t\">1,959.65</td>\n</tr>\n<tr id=\"S6.T2.1.3.2\" class=\"ltx_tr\">\n<th id=\"S6.T2.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">SV</th>\n<td id=\"S6.T2.1.3.2.2\" class=\"ltx_td ltx_align_right\">3,498.57</td>\n<td id=\"S6.T2.1.3.2.3\" class=\"ltx_td ltx_align_right\">2,048.84</td>\n</tr>\n<tr id=\"S6.T2.1.4.3\" class=\"ltx_tr\">\n<th id=\"S6.T2.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">OORT</th>\n<td id=\"S6.T2.1.4.3.2\" class=\"ltx_td ltx_align_right\">4,277.52</td>\n<td id=\"S6.T2.1.4.3.3\" class=\"ltx_td ltx_align_right\">1,215.29</td>\n</tr>\n<tr id=\"S6.T2.1.5.4\" class=\"ltx_tr\">\n<th id=\"S6.T2.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">ROBO-AFL</th>\n<td id=\"S6.T2.1.5.4.2\" class=\"ltx_td ltx_align_right\">4,906.35</td>\n<td id=\"S6.T2.1.5.4.3\" class=\"ltx_td ltx_align_right\">620.11</td>\n</tr>\n<tr id=\"S6.T2.1.6.5\" class=\"ltx_tr\">\n<th id=\"S6.T2.1.6.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">RRAFL</th>\n<td id=\"S6.T2.1.6.5.2\" class=\"ltx_td ltx_align_right\">5,012.20</td>\n<td id=\"S6.T2.1.6.5.3\" class=\"ltx_td ltx_align_right\">396.91</td>\n</tr>\n<tr id=\"S6.T2.1.7.6\" class=\"ltx_tr\">\n<th id=\"S6.T2.1.7.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t\"><span id=\"S6.T2.1.7.6.1.1\" class=\"ltx_text ltx_font_typewriter\">GPS-AFL</span></th>\n<td id=\"S6.T2.1.7.6.2\" class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_t\"><span id=\"S6.T2.1.7.6.2.1\" class=\"ltx_text ltx_font_bold\">5,179.71</span></td>\n<td id=\"S6.T2.1.7.6.3\" class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_t\"><span id=\"S6.T2.1.7.6.3.1\" class=\"ltx_text ltx_font_bold\">358.87</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Table 2 depicts the simulation results of the approaches under the MNIST dataset. GPS-AFLâ€™s scored a total utility of 3.23%percent3.233.23\\%, 5.57%percent5.575.57\\%, 21.10%percent21.1021.10\\% ,46.40%percent46.4046.40\\%, 48.05%percent48.0548.05\\% higher than â€˜RRAFLâ€™, â€˜ROBO-AFLâ€™, â€˜OORTâ€™, â€˜Greedyâ€™ and â€˜SVâ€™ approach respectively. While simultaneously incurring 10.60%percent10.6010.60\\%, 72.80%percent72.8072.80\\%, 238.64%percent238.64238.64\\%, 446.06%percent446.06446.06\\% and 470.91%percent470.91470.91\\% lesser costs than the other approaches in the same order, respectively. The result demonstrates the adeptness of our algorithm in effectively maximizing budget utilization while achieving an improved balance between cost and performance. As â€˜RRAFLâ€™ opts for the largest feasible participant cohort within a stipulated budget for each round, there inevitably arises extra budget unnecessarily spent. This extra expenditure even when the model is performing well constitutes to cost wastage, as opposed to GPS-AFL where such residual unspent budget is carried forward to the subsequent round. Furthermore, â€˜OORTâ€™ was designed to identify and select high-performing participants without any budget consideration. This consequently led to increased overall costs despite initial utility improvements, as depicted in Figure 3."
        ]
    },
    "S6.T3": {
        "caption": "Table 3. Comparison results under the Fashion-MNIST dataset.",
        "table": "<table id=\"S6.T3.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S6.T3.1.1.1\" class=\"ltx_tr\">\n<th id=\"S6.T3.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\"><span id=\"S6.T3.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></th>\n<th id=\"S6.T3.1.1.1.2\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\"><span id=\"S6.T3.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Total Utility</span></th>\n<th id=\"S6.T3.1.1.1.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\"><span id=\"S6.T3.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Total Cost</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T3.1.2.1\" class=\"ltx_tr\">\n<th id=\"S6.T3.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">Greedy</th>\n<td id=\"S6.T3.1.2.1.2\" class=\"ltx_td ltx_align_right ltx_border_t\">4,430.47</td>\n<td id=\"S6.T3.1.2.1.3\" class=\"ltx_td ltx_align_right ltx_border_t\">2,029.87</td>\n</tr>\n<tr id=\"S6.T3.1.3.2\" class=\"ltx_tr\">\n<th id=\"S6.T3.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">SV</th>\n<td id=\"S6.T3.1.3.2.2\" class=\"ltx_td ltx_align_right\">5,059.74</td>\n<td id=\"S6.T3.1.3.2.3\" class=\"ltx_td ltx_align_right\">1,453.61</td>\n</tr>\n<tr id=\"S6.T3.1.4.3\" class=\"ltx_tr\">\n<th id=\"S6.T3.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">OORT</th>\n<td id=\"S6.T3.1.4.3.2\" class=\"ltx_td ltx_align_right\">5,186.23</td>\n<td id=\"S6.T3.1.4.3.3\" class=\"ltx_td ltx_align_right\">1,255.67</td>\n</tr>\n<tr id=\"S6.T3.1.5.4\" class=\"ltx_tr\">\n<th id=\"S6.T3.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">ROBO-AFL</th>\n<td id=\"S6.T3.1.5.4.2\" class=\"ltx_td ltx_align_right\">5,744.60</td>\n<td id=\"S6.T3.1.5.4.3\" class=\"ltx_td ltx_align_right\">763.47</td>\n</tr>\n<tr id=\"S6.T3.1.6.5\" class=\"ltx_tr\">\n<th id=\"S6.T3.1.6.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">RRAFL</th>\n<td id=\"S6.T3.1.6.5.2\" class=\"ltx_td ltx_align_right\">5,969.95</td>\n<td id=\"S6.T3.1.6.5.3\" class=\"ltx_td ltx_align_right\">386.99</td>\n</tr>\n<tr id=\"S6.T3.1.7.6\" class=\"ltx_tr\">\n<th id=\"S6.T3.1.7.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t\"><span id=\"S6.T3.1.7.6.1.1\" class=\"ltx_text ltx_font_typewriter\">GPS-AFL</span></th>\n<td id=\"S6.T3.1.7.6.2\" class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_t\"><span id=\"S6.T3.1.7.6.2.1\" class=\"ltx_text ltx_font_bold\">6,026.60</span></td>\n<td id=\"S6.T3.1.7.6.3\" class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_t\"><span id=\"S6.T3.1.7.6.3.1\" class=\"ltx_text ltx_font_bold\">290.60</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Table 3 depicts the simulation results of the approaches under the FMNIST dataset, GPS-AFL also outperformed other approaches. It was able to obtain a total utility of 56.6456.6456.64, 282282282, 840.37840.37840.37, 966.87966.87966.87 and 1596.131596.131596.13 more points higher than â€˜RRAFLâ€™, â€˜ROBO-AFLâ€™, â€˜OORTâ€™, â€˜SVâ€™ and â€˜Greedyâ€™ approaches, respectively. While simultaneously incurring 33.17%percent33.1733.17\\%, 162.70%percent162.70162.70\\%, 332.10%percent332.10332.10\\%, 400.21%percent400.21400.21\\% and 598.51%percent598.51598.51\\% lesser costs than the other approaches in the same order, respectively. Likewise, GPS-AFL effectively optimized its utility score output to a even higher degree. This could plausibly be attributed to the larger FL model used, which enhanced learning and performance capabilities."
        ]
    },
    "S6.T4": {
        "caption": "Table 4. Comparison results under the EMNIST balanced dataset.",
        "table": "<table id=\"S6.T4.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S6.T4.1.1.1\" class=\"ltx_tr\">\n<th id=\"S6.T4.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\"><span id=\"S6.T4.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></th>\n<th id=\"S6.T4.1.1.1.2\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\"><span id=\"S6.T4.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Total Utility</span></th>\n<th id=\"S6.T4.1.1.1.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\"><span id=\"S6.T4.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Total Cost</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T4.1.2.1\" class=\"ltx_tr\">\n<th id=\"S6.T4.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">Greedy</th>\n<td id=\"S6.T4.1.2.1.2\" class=\"ltx_td ltx_align_right ltx_border_t\">1,953.05</td>\n<td id=\"S6.T4.1.2.1.3\" class=\"ltx_td ltx_align_right ltx_border_t\">1,192.74</td>\n</tr>\n<tr id=\"S6.T4.1.3.2\" class=\"ltx_tr\">\n<th id=\"S6.T4.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">SV</th>\n<td id=\"S6.T4.1.3.2.2\" class=\"ltx_td ltx_align_right\">1,714.22</td>\n<td id=\"S6.T4.1.3.2.3\" class=\"ltx_td ltx_align_right\">1,078.06</td>\n</tr>\n<tr id=\"S6.T4.1.4.3\" class=\"ltx_tr\">\n<th id=\"S6.T4.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">OORT</th>\n<td id=\"S6.T4.1.4.3.2\" class=\"ltx_td ltx_align_right\">1,605.30</td>\n<td id=\"S6.T4.1.4.3.3\" class=\"ltx_td ltx_align_right\">981.76</td>\n</tr>\n<tr id=\"S6.T4.1.5.4\" class=\"ltx_tr\">\n<th id=\"S6.T4.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">ROBO-AFL</th>\n<td id=\"S6.T4.1.5.4.2\" class=\"ltx_td ltx_align_right\">2,150.37</td>\n<td id=\"S6.T4.1.5.4.3\" class=\"ltx_td ltx_align_right\">462.63</td>\n</tr>\n<tr id=\"S6.T4.1.6.5\" class=\"ltx_tr\">\n<th id=\"S6.T4.1.6.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">RRAFL</th>\n<td id=\"S6.T4.1.6.5.2\" class=\"ltx_td ltx_align_right\">2,679.22</td>\n<td id=\"S6.T4.1.6.5.3\" class=\"ltx_td ltx_align_right\">375.46</td>\n</tr>\n<tr id=\"S6.T4.1.7.6\" class=\"ltx_tr\">\n<th id=\"S6.T4.1.7.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t\"><span id=\"S6.T4.1.7.6.1.1\" class=\"ltx_text ltx_font_typewriter\">GPS-AFL</span></th>\n<td id=\"S6.T4.1.7.6.2\" class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_t\"><span id=\"S6.T4.1.7.6.2.1\" class=\"ltx_text ltx_font_bold\">2,798.20</span></td>\n<td id=\"S6.T4.1.7.6.3\" class=\"ltx_td ltx_align_right ltx_border_bb ltx_border_t\"><span id=\"S6.T4.1.7.6.3.1\" class=\"ltx_text ltx_font_bold\">238.88</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Table 4 presents the experimental result concerning a more difficult FL task, based on the EMNIST balanced dataset. The number of participants available has been reduced to 202020. To save on communication costs, each participant will train for 333 local epochs, with batch size 646464. Consequently, trsubscriptğ‘¡ğ‘Ÿt_{r} tripled to become 333. The remaining parameters remained unaltered. The FL model deployed for this FL task is identical to the one used in the FMNIST FL task. It is worth noting that our approach can be extended to other FL tasks by leveraging on alternative available benchmarks like the open-sourced benchmarking framework offered by (Zeng etÂ al., 2023). As shown in Table 4, it remains evident that GPS-AFL maintains its superiority over other state-of-the-art methodologies while keeping costs low. GPS-AFL was able to attain a total utility of 4.44%percent4.444.44\\%, 30.12%percent30.1230.12\\%, 74.31%percent74.3174.31\\%, 63.23%percent63.2363.23\\% and 43.27%percent43.2743.27\\% more points higher than â€˜RRAFLâ€™, â€˜ROBO-AFLâ€™, â€˜OORTâ€™, â€˜SVâ€™ and â€˜Greedyâ€™ approaches, respectively. While simultaneously incurring 36.38%percent36.3836.38\\%, 57.18%percent57.1857.18\\%, 310.98%percent310.98310.98\\%, 399.31%percent399.31399.31\\% and 351.30%percent351.30351.30\\% lesser costs than the other approaches in the same order, respectively."
        ]
    }
}