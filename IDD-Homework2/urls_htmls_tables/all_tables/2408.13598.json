{
    "S2.T1.3.1": {
        "caption": [
            "Table 1",
            "Description of the target and source dataset."
        ],
        "table": "<table id=\"S2.T1.3.1\" class=\"ltx_tabular ltx_figure_panel ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S2.T1.3.1.1.1\" class=\"ltx_tr\">\n<th id=\"S2.T1.3.1.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T1.3.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Dataset</span></th>\n<th id=\"S2.T1.3.1.1.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T1.3.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Partition</span></th>\n<th id=\"S2.T1.3.1.1.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T1.3.1.1.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Nu. of GRB</span></th>\n<th id=\"S2.T1.3.1.1.1.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T1.3.1.1.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">Nu. of non-GRB</span></th>\n<th id=\"S2.T1.3.1.1.1.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T1.3.1.1.1.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">Data Period Definition (UTC)</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S2.T1.3.1.2.1\" class=\"ltx_tr\">\n<td id=\"S2.T1.3.1.2.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\" rowspan=\"3\"><span id=\"S2.T1.3.1.2.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Target dataset</span></td>\n<td id=\"S2.T1.3.1.2.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T1.3.1.2.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Training set</span></td>\n<td id=\"S2.T1.3.1.2.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T1.3.1.2.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">10005</span></td>\n<td id=\"S2.T1.3.1.2.1.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T1.3.1.2.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">10000</span></td>\n<td id=\"S2.T1.3.1.2.1.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T1.3.1.2.1.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">01/01/2021 - 11/30/2022</span></td>\n</tr>\n<tr id=\"S2.T1.3.1.3.2\" class=\"ltx_tr\">\n<td id=\"S2.T1.3.1.3.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T1.3.1.3.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Validation set</span></td>\n<td id=\"S2.T1.3.1.3.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T1.3.1.3.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">108</span></td>\n<td id=\"S2.T1.3.1.3.2.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T1.3.1.3.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">500</span></td>\n<td id=\"S2.T1.3.1.3.2.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T1.3.1.3.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">01/12/2023 - 05/31/2023</span></td>\n</tr>\n<tr id=\"S2.T1.3.1.4.3\" class=\"ltx_tr\">\n<td id=\"S2.T1.3.1.4.3.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T1.3.1.4.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Test set</span></td>\n<td id=\"S2.T1.3.1.4.3.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T1.3.1.4.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">114</span></td>\n<td id=\"S2.T1.3.1.4.3.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T1.3.1.4.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">500</span></td>\n<td id=\"S2.T1.3.1.4.3.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T1.3.1.4.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">06/01/2023 - 31/01/2024</span></td>\n</tr>\n<tr id=\"S2.T1.3.1.5.4\" class=\"ltx_tr\">\n<td id=\"S2.T1.3.1.5.4.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\" rowspan=\"3\"><span id=\"S2.T1.3.1.5.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Source dataset</span></td>\n<td id=\"S2.T1.3.1.5.4.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T1.3.1.5.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Training set</span></td>\n<td id=\"S2.T1.3.1.5.4.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T1.3.1.5.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">105213</span></td>\n<td id=\"S2.T1.3.1.5.4.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T1.3.1.5.4.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">100000</span></td>\n<td id=\"S2.T1.3.1.5.4.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T1.3.1.5.4.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">07/14/2008 - 31/12/2016</span></td>\n</tr>\n<tr id=\"S2.T1.3.1.6.5\" class=\"ltx_tr\">\n<td id=\"S2.T1.3.1.6.5.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T1.3.1.6.5.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Validation set</span></td>\n<td id=\"S2.T1.3.1.6.5.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T1.3.1.6.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">2333</span></td>\n<td id=\"S2.T1.3.1.6.5.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T1.3.1.6.5.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">4000</span></td>\n<td id=\"S2.T1.3.1.6.5.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T1.3.1.6.5.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">01/01/2017 - 12/31/2019</span></td>\n</tr>\n<tr id=\"S2.T1.3.1.7.6\" class=\"ltx_tr\">\n<td id=\"S2.T1.3.1.7.6.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T1.3.1.7.6.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Test set</span></td>\n<td id=\"S2.T1.3.1.7.6.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T1.3.1.7.6.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">2776</span></td>\n<td id=\"S2.T1.3.1.7.6.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T1.3.1.7.6.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">4000</span></td>\n<td id=\"S2.T1.3.1.7.6.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T1.3.1.7.6.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">01/01/2020 - 06/31/2023</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "Benefiting from the wide energy band, large field of view, and high sensitivity\nof gamma-ray detectors of GRD, the GECAM-B satellite has detected more than\n300 GRBs since its launch in December 10, 2020.\nThese 25 GRDs have demonstrated strong capabilities in detecting gamma rays and\nparticles, as well as determined the locations of GRBs roughly (An et al. 2021).\nWe constructed a target dataset based on the observed data from GECAM-B,\nwhich includes categories for both GRB and non-GRB samples.\nIn order to obtain valid GRB category samples, we screened the GRBs detected\nby the GECAM-B/GRD. Through manual analysis, there are 219 GRBs\nwith precise location between 01/01/2021 and 02/01/2024.\nCorresponding to these GRBs that triggered by no fewer than three detectors,\nalong with their location and direction of every GRD detector, we calculated\nthe incidence angles of every GRB source for detectors.\nThe extraction of light curves from GECAM data is facilitated through GECAMTools111https://github.com/zhangpeng-sci/GECAMTools-Public/.\nConsidering the requisite for high statistical light curves of GRB samples,\nwe only extracted event data from the three detectors that with relatively\nsmall incidence angles for each event. This process resulted in 657 light\ncurves that were collected to augment for GRB category samples.\nEach GRB sample was set to a duration of 120 seconds, with a minimum of 10\nseconds of background data before and after the burst to ensure the integrity\nof the burst shape.\nFor the non-GRB category data from GCEAM-B, we randomly sampled 1,500 daily\nobservational files from non-burst time periods.\nFrom each file, twenty 120-second segments were extracted without overlap\nfor additional analysis, this gives us 11,000 non-GRB samples.\nThe non-GRB category data are shown in the table 1.\nWe select photons recommended in all gain types without distinguishing\nin the high gain or low gain.\nThese photons are utilized to generate light curves with a time bin of\n64 ms from both GRB and non-GRB data.",
            "To enhance the diversity of the training set, we augmented the GRB category\ndata either GRBs selected form GECAM-B/GRD or GRBs selected form Fermi/GBM.\nThe former supplies initial 657 light curves of GRBs, and the latter provides\ninitial 6189 light curves of GRBs.\nAfter data augmentation handling discussed above, they were successfully multipled about 23 times, resulting in a sizeable GRB category samples both on target dataset and source dataset finally.\nThe GRB category samples and non-GRB category samples are divided into respective training set, validation set, and test set based on time period. This is very helpful in avoiding data confusion. The ratio of positive and negative sample numbers in these three data sets is roughly comparable and reasonable. Details are described in the table 1.",
            "The target and source datasets utilized in our study were constructed using GRBs\ndetected by the GECAM-B and Fermi/GBM, respectively, as shown in Table 1.\nLight curves with a time bin of 64 ms were extracted and binned into 9 energy bands\nto capture the photon distribution characteristics specific to GRBs.\nTo enhance the diversity and richness of burst signals within the datasets,\nwe proposed a data augmentation method, the efficacy of which is visually demonstrated in Figure 1.\nThis augmentation technique significantly increased the number of training samples\nfor the GRB categories in the target and source datasets, expanding the samples\nfrom 435 to 10,005 and from 6,189 to 105,213, respectively.\nFollowing a comparative analysis of data pre-processing methods detailed in Table 2,\nwe opted to standardize the light curve for each energy band.\nThis standardized approach ensures uniform representation of the data across\ndifferent energy bands, facilitating consistent model training and evaluation.",
            "In Table 1, we have built target and source datasets derived\nfrom GECAM and Fermi/GBM observations, respectively.\nTo address the challenge posed by a limited sample size of GRBs,\nwe opted to bin the energy bands of the light curves to align with the\nenergy bands commonly associated with generic burst identifications.\nThis alignment facilitates the seamless transfer of models trained on\nlarge-scale data, enhancing the model’s adaptability to new datasets.\nMoreover, our proposed data augmentation method has proven to be instrumental\nin augmenting the diversity of burst samples significantly.\nBy reducing the prominence of the burst signal while maintaining a consistent\nbackground level, as exemplified in Figure 1,\nthis method has effectively expanded the number of training samples\nfrom a modest few thousand to a substantial hundred thousand.\nThe integration of data augmentation techniques has mitigated the challenge\nof limited training samples in deep learning applications for GRB identification,\nthereby improving the model’s generalization capabilities."
        ]
    }
}{
    "S2.T2.3.1": {
        "caption": [
            "Table 2",
            "The difference of the data pre-process methods.",
            "0.86Bold text represents that the model performs optimally on that metric."
        ],
        "table": "<table id=\"S2.T2.3.1\" class=\"ltx_tabular ltx_figure_panel ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S2.T2.3.1.1.1\" class=\"ltx_tr\">\n<th id=\"S2.T2.3.1.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T2.3.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Model</span></th>\n<th id=\"S2.T2.3.1.1.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T2.3.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Pre-process</span></th>\n<th id=\"S2.T2.3.1.1.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">\n<span id=\"S2.T2.3.1.1.1.3.1\" class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Accuracy</span><span id=\"S2.T2.3.1.1.1.3.2\" class=\"ltx_text\" style=\"font-size:90%;\"> (%)</span>\n</th>\n<th id=\"S2.T2.3.1.1.1.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">\n<span id=\"S2.T2.3.1.1.1.4.1\" class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Precision</span><span id=\"S2.T2.3.1.1.1.4.2\" class=\"ltx_text\" style=\"font-size:90%;\"> (%)</span>\n</th>\n<th id=\"S2.T2.3.1.1.1.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">\n<span id=\"S2.T2.3.1.1.1.5.1\" class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Recall</span><span id=\"S2.T2.3.1.1.1.5.2\" class=\"ltx_text\" style=\"font-size:90%;\"> (%)</span>\n</th>\n<th id=\"S2.T2.3.1.1.1.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">\n<span id=\"S2.T2.3.1.1.1.6.1\" class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">F1-score</span><span id=\"S2.T2.3.1.1.1.6.2\" class=\"ltx_text\" style=\"font-size:90%;\"> (%)</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S2.T2.3.1.2.1\" class=\"ltx_tr\">\n<th id=\"S2.T2.3.1.2.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\" rowspan=\"4\"><span id=\"S2.T2.3.1.2.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">ResNet</span></th>\n<th id=\"S2.T2.3.1.2.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T2.3.1.2.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Norm</span></th>\n<td id=\"S2.T2.3.1.2.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T2.3.1.2.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">94.86</span></td>\n<td id=\"S2.T2.3.1.2.1.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T2.3.1.2.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">98.61</span></td>\n<td id=\"S2.T2.3.1.2.1.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T2.3.1.2.1.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">90.23</span></td>\n<td id=\"S2.T2.3.1.2.1.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T2.3.1.2.1.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">94.24</span></td>\n</tr>\n<tr id=\"S2.T2.3.1.3.2\" class=\"ltx_tr\">\n<th id=\"S2.T2.3.1.3.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T2.3.1.3.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Norm each channel</span></th>\n<td id=\"S2.T2.3.1.3.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T2.3.1.3.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">95.82</span></td>\n<td id=\"S2.T2.3.1.3.2.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T2.3.1.3.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">98.29</span></td>\n<td id=\"S2.T2.3.1.3.2.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T2.3.1.3.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">91.39</span></td>\n<td id=\"S2.T2.3.1.3.2.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T2.3.1.3.2.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">94.71</span></td>\n</tr>\n<tr id=\"S2.T2.3.1.4.3\" class=\"ltx_tr\">\n<th id=\"S2.T2.3.1.4.3.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T2.3.1.4.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Standard</span></th>\n<td id=\"S2.T2.3.1.4.3.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T2.3.1.4.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">96.75</span></td>\n<td id=\"S2.T2.3.1.4.3.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T2.3.1.4.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">98.22</span></td>\n<td id=\"S2.T2.3.1.4.3.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T2.3.1.4.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">93.76</span></td>\n<td id=\"S2.T2.3.1.4.3.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T2.3.1.4.3.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">95.94</span></td>\n</tr>\n<tr id=\"S2.T2.3.1.5.4\" class=\"ltx_tr\">\n<th id=\"S2.T2.3.1.5.4.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_b\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T2.3.1.5.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Standard each channel</span></th>\n<td id=\"S2.T2.3.1.5.4.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T2.3.1.5.4.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">97.15</span></td>\n<td id=\"S2.T2.3.1.5.4.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T2.3.1.5.4.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">98.42</span></td>\n<td id=\"S2.T2.3.1.5.4.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T2.3.1.5.4.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">94.56</span></td>\n<td id=\"S2.T2.3.1.5.4.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S2.T2.3.1.5.4.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">96.45</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "Normalization and standardization are common techniques used in data\npre-processing to scale and transform the features of a dataset.\nNormalization involves rescaling the values of a feature to a specific range,\ntypically between 0 and 1.\nThis is achieved by subtracting the minimum value of the feature and dividing\nby the range (maximum value minus minimum value).\nOn the other hand, standardization transforms the values of a feature to have\na mean of 0 and a standard deviation of 1.\nThis process involves subtracting the mean value of the feature from each\nvalue and dividing by the standard deviation.\nBoth normalization and standardization are employed to ensure that the\nfeatures in a dataset are on a similar scale.\nThe ResNet model, as proposed by He et al. (2016), is a widely used\nmodel in deep learning.\nIn this study, we employed the ResNet model to evaluate and compare\nthe impact of various pre-processing methods on performance.\nThe results of the performance evaluation on the source test set\nusing these two methods are summarized in Table 2.\nGiven that standardizing samples leads to the highest accuracy for each\nenergy band,\nwe have decided to adopt standardizing method for pre-processing the samples\nin source and target dataset.",
            "The target and source datasets utilized in our study were constructed using GRBs\ndetected by the GECAM-B and Fermi/GBM, respectively, as shown in Table 1.\nLight curves with a time bin of 64 ms were extracted and binned into 9 energy bands\nto capture the photon distribution characteristics specific to GRBs.\nTo enhance the diversity and richness of burst signals within the datasets,\nwe proposed a data augmentation method, the efficacy of which is visually demonstrated in Figure 1.\nThis augmentation technique significantly increased the number of training samples\nfor the GRB categories in the target and source datasets, expanding the samples\nfrom 435 to 10,005 and from 6,189 to 105,213, respectively.\nFollowing a comparative analysis of data pre-processing methods detailed in Table 2,\nwe opted to standardize the light curve for each energy band.\nThis standardized approach ensures uniform representation of the data across\ndifferent energy bands, facilitating consistent model training and evaluation."
        ]
    }
}{
    "S3.T3.3.1": {
        "caption": [
            "Table 3",
            "Hyper-parameter selection.",
            "0.86Bold text represents the selected hyper-parameter."
        ],
        "table": "<table id=\"S3.T3.3.1\" class=\"ltx_tabular ltx_figure_panel ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T3.3.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T3.3.1.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T3.3.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Parameters</span></th>\n<th id=\"S3.T3.3.1.1.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T3.3.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Values</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T3.3.1.2.1\" class=\"ltx_tr\">\n<th id=\"S3.T3.3.1.2.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T3.3.1.2.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Number of ConvUnit</span></th>\n<td id=\"S3.T3.3.1.2.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">\n<span id=\"S3.T3.3.1.2.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">2, </span><span id=\"S3.T3.3.1.2.1.2.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">4</span><span id=\"S3.T3.3.1.2.1.2.3\" class=\"ltx_text\" style=\"font-size:90%;\">, 8, 16</span>\n</td>\n</tr>\n<tr id=\"S3.T3.3.1.3.2\" class=\"ltx_tr\">\n<th id=\"S3.T3.3.1.3.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T3.3.1.3.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Number of Conv in ConvUnit</span></th>\n<td id=\"S3.T3.3.1.3.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">\n<span id=\"S3.T3.3.1.3.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">1, 2, </span><span id=\"S3.T3.3.1.3.2.2.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">3</span><span id=\"S3.T3.3.1.3.2.2.3\" class=\"ltx_text\" style=\"font-size:90%;\">, 4</span>\n</td>\n</tr>\n<tr id=\"S3.T3.3.1.4.3\" class=\"ltx_tr\">\n<th id=\"S3.T3.3.1.4.3.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T3.3.1.4.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">First ConvUnit filter size</span></th>\n<td id=\"S3.T3.3.1.4.3.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">\n<span id=\"S3.T3.3.1.4.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">64, </span><span id=\"S3.T3.3.1.4.3.2.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">128</span><span id=\"S3.T3.3.1.4.3.2.3\" class=\"ltx_text\" style=\"font-size:90%;\">, 256, 512</span>\n</td>\n</tr>\n<tr id=\"S3.T3.3.1.5.4\" class=\"ltx_tr\">\n<th id=\"S3.T3.3.1.5.4.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T3.3.1.5.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Second ConvUnit filter size</span></th>\n<td id=\"S3.T3.3.1.5.4.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">\n<span id=\"S3.T3.3.1.5.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">64, </span><span id=\"S3.T3.3.1.5.4.2.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">128</span><span id=\"S3.T3.3.1.5.4.2.3\" class=\"ltx_text\" style=\"font-size:90%;\">, 256, 512</span>\n</td>\n</tr>\n<tr id=\"S3.T3.3.1.6.5\" class=\"ltx_tr\">\n<th id=\"S3.T3.3.1.6.5.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T3.3.1.6.5.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Third ConvUnit filter size</span></th>\n<td id=\"S3.T3.3.1.6.5.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">\n<span id=\"S3.T3.3.1.6.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">64, </span><span id=\"S3.T3.3.1.6.5.2.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">128</span><span id=\"S3.T3.3.1.6.5.2.3\" class=\"ltx_text\" style=\"font-size:90%;\">, 256, 512</span>\n</td>\n</tr>\n<tr id=\"S3.T3.3.1.7.6\" class=\"ltx_tr\">\n<th id=\"S3.T3.3.1.7.6.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T3.3.1.7.6.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Fourth ConvUnit filter size</span></th>\n<td id=\"S3.T3.3.1.7.6.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">\n<span id=\"S3.T3.3.1.7.6.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">64, </span><span id=\"S3.T3.3.1.7.6.2.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">128</span><span id=\"S3.T3.3.1.7.6.2.3\" class=\"ltx_text\" style=\"font-size:90%;\">, 256, 512</span>\n</td>\n</tr>\n<tr id=\"S3.T3.3.1.8.7\" class=\"ltx_tr\">\n<th id=\"S3.T3.3.1.8.7.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T3.3.1.8.7.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Norm function</span></th>\n<td id=\"S3.T3.3.1.8.7.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">\n<span id=\"S3.T3.3.1.8.7.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">InstaceNorm, </span><span id=\"S3.T3.3.1.8.7.2.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">BatchNorm</span>\n</td>\n</tr>\n<tr id=\"S3.T3.3.1.9.8\" class=\"ltx_tr\">\n<th id=\"S3.T3.3.1.9.8.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T3.3.1.9.8.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Activation function</span></th>\n<td id=\"S3.T3.3.1.9.8.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">\n<span id=\"S3.T3.3.1.9.8.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Sigmoid, </span><span id=\"S3.T3.3.1.9.8.2.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Relu</span>\n</td>\n</tr>\n<tr id=\"S3.T3.3.1.10.9\" class=\"ltx_tr\">\n<th id=\"S3.T3.3.1.10.9.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T3.3.1.10.9.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FC neurons</span></th>\n<td id=\"S3.T3.3.1.10.9.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">\n<span id=\"S3.T3.3.1.10.9.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">32, </span><span id=\"S3.T3.3.1.10.9.2.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">64</span><span id=\"S3.T3.3.1.10.9.2.3\" class=\"ltx_text\" style=\"font-size:90%;\">, 128</span>\n</td>\n</tr>\n<tr id=\"S3.T3.3.1.11.10\" class=\"ltx_tr\">\n<th id=\"S3.T3.3.1.11.10.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T3.3.1.11.10.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Dropout rate</span></th>\n<td id=\"S3.T3.3.1.11.10.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">\n<span id=\"S3.T3.3.1.11.10.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.3, </span><span id=\"S3.T3.3.1.11.10.2.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">0.5</span><span id=\"S3.T3.3.1.11.10.2.3\" class=\"ltx_text\" style=\"font-size:90%;\">, 0.8</span>\n</td>\n</tr>\n<tr id=\"S3.T3.3.1.12.11\" class=\"ltx_tr\">\n<th id=\"S3.T3.3.1.12.11.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T3.3.1.12.11.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Initial learning rate</span></th>\n<td id=\"S3.T3.3.1.12.11.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">\n<span id=\"S3.T3.3.1.12.11.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">1e-3, 1e-4, </span><span id=\"S3.T3.3.1.12.11.2.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">1e-5</span><span id=\"S3.T3.3.1.12.11.2.3\" class=\"ltx_text\" style=\"font-size:90%;\">, 1e-6</span>\n</td>\n</tr>\n<tr id=\"S3.T3.3.1.13.12\" class=\"ltx_tr\">\n<th id=\"S3.T3.3.1.13.12.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T3.3.1.13.12.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Batch size</span></th>\n<td id=\"S3.T3.3.1.13.12.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">\n<span id=\"S3.T3.3.1.13.12.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">512, </span><span id=\"S3.T3.3.1.13.12.2.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">1024</span><span id=\"S3.T3.3.1.13.12.2.3\" class=\"ltx_text\" style=\"font-size:90%;\">, 2048</span>\n</td>\n</tr>\n<tr id=\"S3.T3.3.1.14.13\" class=\"ltx_tr\">\n<th id=\"S3.T3.3.1.14.13.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T3.3.1.14.13.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Patience of reduce learning rate</span></th>\n<td id=\"S3.T3.3.1.14.13.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">\n<span id=\"S3.T3.3.1.14.13.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">5, </span><span id=\"S3.T3.3.1.14.13.2.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">10</span><span id=\"S3.T3.3.1.14.13.2.3\" class=\"ltx_text\" style=\"font-size:90%;\">, 15</span>\n</td>\n</tr>\n<tr id=\"S3.T3.3.1.15.14\" class=\"ltx_tr\">\n<th id=\"S3.T3.3.1.15.14.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_b\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T3.3.1.15.14.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Patience of early stop</span></th>\n<td id=\"S3.T3.3.1.15.14.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">\n<span id=\"S3.T3.3.1.15.14.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">10, </span><span id=\"S3.T3.3.1.15.14.2.2\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">20</span><span id=\"S3.T3.3.1.15.14.2.3\" class=\"ltx_text\" style=\"font-size:90%;\">, 40, 60</span>\n</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "Optimizing hyper-parameters in deep learning models is essential for enhancing\nmodel performance and generalization by improving data fitting and preventing over-fitting.\nBy adjusting hyper-parameters, we could expedite model training and ensure optimal performance.\nIn our work, we conduct a detailed analysis to evaluate the impact of different hyper-parameter\nchoices on the test set of the source dataset, as referenced in (Ma et al. 2023).\nThrough this analysis, we identify the hyper-parameter set that yields the best-performing models.\nThe hyper-parameter configurations that result in the best models are highlighted in bold in Table 3.\nThis systematic evaluation of hyper-parameters allows us to improve our model and enhance its effectiveness in identifying GRBs.",
            "To initiate the training of our deep learning model, we initialize the model parameters\nusing the truncated normal distribution method proposed by (He et al. 2015).\nThe batch size for model training is set to 1024, and the cross-entropy loss function\nis employed as the supervised model’s loss function to measure the disparity between\nthe predicted and actual label of the data.\nFor model optimization, we utilize the Adam optimizer (Kingma & Ba 2014),\nwhich updates the model parameters to minimize the loss during neural network training.\nThe initial learning rate of the model is established at 1e-5.\nIn the training process, if the validation loss fails to decrease for 10 consecutive epochs,\nwe reduce the learning rate by a factor of 2.\nTo prevent over-fitting, we implement an early stopping mechanism,\nterminating the training process when the validation accuracy does not improve for 20 consecutive epochs.\nThe selection of hyper-parameters such as batch size, initial learning rate, and early stopping criteria\nare detailed in Table 3.\nThe parameters from the epochs with the highest accuracy in the validation set are\nutilized as the optimal model parameters.\nOur model is implemented using the Pytorch framework on a single GPU (NVIDIA RTX-4090).\nThe evaluation metrics for our model, including\nAccuracy, Precision, Recall, and F1-score,\nare consistent with those described in (Zhang et al. 2024).",
            "We employed a 1D convolutional neural network to classify samples belonging to\nGRB and non-GRB categories in a supervised learning framework.\nTo enhance feature extraction capabilities, we integrated a multi-scale feature\ncross fusion module (MSCFM) into the commonly used ResNet model.\nThe hyper-parameter choices for the model are listed in Table 3.\nTable 4 presents the performance comparison between\nthe baseline model and the model incorporating the MSCFM module on the source dataset.\nThe results demonstrate that the inclusion of the MSCFM module significantly enhances the model’s performance.\nSpecifically, the ResNet+MSCFM model, pre-trained on the source dataset,\nachieved an impressive accuracy of 97.37%.\nFurthermore, Table 5 showcases the performance metrics\nof the model trained directly on the target dataset, solely on the source dataset,\nand through transfer learning to the target dataset.\nNotably, by transferring the pre-trained model, the model achieved a high accuracy\nof 96.41% on the target test set.\nThe learning curves for model pre-training and fine-tuning are illustrated in Figure 3,\nproviding insights into the model’s training progress.\nAdditionally, through feature visualization techniques, we observed that the model effectively\nextracted and focused on the key features of GRBs, as depicted in Figure 4.\nThese findings illustrate the model’s ability to discern and focus on essential features\nfor accurate GRB identification.",
            "We selected ResNet as the benchmark model for GRB identification due to its robustness\nand versatility in deep learning applications.\nTo enhance the model’s multi-scale feature extraction capabilities,\nwe introduced a multi-scale feature cross fusion module (MSCFM).\nThe detailed structure of the model, including the implementation of the MSCFM module,\nis illustrated in Figure 2.\nTable 3 provides a comprehensive evaluation\nof hyper-parameter selection, assessing the impact of hyper-parameters and optimizing the model.\nOur approach involved pre-training the model on the source dataset, as shown in Table 4.\nIncorporating the MSCFM module led to a noticeable improvement in the accuracy of the ResNet model,\nindicating that the fusion of multi-scale features enabled the model to capture\nricher information and enhance its generalization capacity.\nTable 5 presents the performance comparison of models with\nand without pre-training and fine-tuning.\nWe observed that pre-trained models, particularly those trained on extensive datasets,\nexhibited superior generalization abilities.\nFine-tuning the parameters of pre-trained models on the target dataset\nfurther enhanced their adaptability, highlighting the efficiency of\ntransfer learning in handling limited data scenarios.\nThe learning curve depicted in Figure 3 demonstrates\nthe model’s effective training process,\nwith the early stopping mechanism preventing over-fitting.\nAdditionally, the visualization of key features in Figure 4\nshowcases the model’s ability to focus on essential burst characteristics,\naligning with human expertise in GRB recognition.\nFurthermore, Figures 5, 6, and 7\nillustrate the successful recovery of three GRBs in real GECAM-B\nobservations using the optimized model. T\nhis achievement can be attributed to the synergistic effects of our data augmentation\nalgorithms, model enhancements, and transfer learning strategies.\nThe accurate identification of GRBs holds significant importance, as they may potentially\ncorrespond to gravitational waves, fast radio bursts, or other transient\nastronomical phenomena (Yang et al. 2020)."
        ]
    }
}{
    "S3.T4.3.1": {
        "caption": [
            "Table 4",
            "Model performance on Fermi/GBM dataset.",
            "0.86Bold text represents that the model performs optimally on that metric."
        ],
        "table": "<table id=\"S3.T4.3.1\" class=\"ltx_tabular ltx_figure_panel ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T4.3.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T4.3.1.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T4.3.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Model</span></th>\n<th id=\"S3.T4.3.1.1.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">\n<span id=\"S3.T4.3.1.1.1.2.1\" class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Accuracy</span><span id=\"S3.T4.3.1.1.1.2.2\" class=\"ltx_text\" style=\"font-size:90%;\"> (%)</span>\n</th>\n<th id=\"S3.T4.3.1.1.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">\n<span id=\"S3.T4.3.1.1.1.3.1\" class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Precision</span><span id=\"S3.T4.3.1.1.1.3.2\" class=\"ltx_text\" style=\"font-size:90%;\"> (%)</span>\n</th>\n<th id=\"S3.T4.3.1.1.1.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">\n<span id=\"S3.T4.3.1.1.1.4.1\" class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Recall</span><span id=\"S3.T4.3.1.1.1.4.2\" class=\"ltx_text\" style=\"font-size:90%;\"> (%)</span>\n</th>\n<th id=\"S3.T4.3.1.1.1.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">\n<span id=\"S3.T4.3.1.1.1.5.1\" class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">F1-score</span><span id=\"S3.T4.3.1.1.1.5.2\" class=\"ltx_text\" style=\"font-size:90%;\"> (%)</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T4.3.1.2.1\" class=\"ltx_tr\">\n<th id=\"S3.T4.3.1.2.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T4.3.1.2.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">ResNet</span></th>\n<td id=\"S3.T4.3.1.2.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T4.3.1.2.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">97.15</span></td>\n<td id=\"S3.T4.3.1.2.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T4.3.1.2.1.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">98.42</span></td>\n<td id=\"S3.T4.3.1.2.1.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T4.3.1.2.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">94.56</span></td>\n<td id=\"S3.T4.3.1.2.1.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T4.3.1.2.1.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">96.45</span></td>\n</tr>\n<tr id=\"S3.T4.3.1.3.2\" class=\"ltx_tr\">\n<th id=\"S3.T4.3.1.3.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_b\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T4.3.1.3.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">ResNet+MSCFM</span></th>\n<td id=\"S3.T4.3.1.3.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T4.3.1.3.2.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">97.37</span></td>\n<td id=\"S3.T4.3.1.3.2.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T4.3.1.3.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">97.96</span></td>\n<td id=\"S3.T4.3.1.3.2.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T4.3.1.3.2.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">95.56</span></td>\n<td id=\"S3.T4.3.1.3.2.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T4.3.1.3.2.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">96.75</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "We employed a 1D convolutional neural network to classify samples belonging to\nGRB and non-GRB categories in a supervised learning framework.\nTo enhance feature extraction capabilities, we integrated a multi-scale feature\ncross fusion module (MSCFM) into the commonly used ResNet model.\nThe hyper-parameter choices for the model are listed in Table 3.\nTable 4 presents the performance comparison between\nthe baseline model and the model incorporating the MSCFM module on the source dataset.\nThe results demonstrate that the inclusion of the MSCFM module significantly enhances the model’s performance.\nSpecifically, the ResNet+MSCFM model, pre-trained on the source dataset,\nachieved an impressive accuracy of 97.37%.\nFurthermore, Table 5 showcases the performance metrics\nof the model trained directly on the target dataset, solely on the source dataset,\nand through transfer learning to the target dataset.\nNotably, by transferring the pre-trained model, the model achieved a high accuracy\nof 96.41% on the target test set.\nThe learning curves for model pre-training and fine-tuning are illustrated in Figure 3,\nproviding insights into the model’s training progress.\nAdditionally, through feature visualization techniques, we observed that the model effectively\nextracted and focused on the key features of GRBs, as depicted in Figure 4.\nThese findings illustrate the model’s ability to discern and focus on essential features\nfor accurate GRB identification.",
            "We selected ResNet as the benchmark model for GRB identification due to its robustness\nand versatility in deep learning applications.\nTo enhance the model’s multi-scale feature extraction capabilities,\nwe introduced a multi-scale feature cross fusion module (MSCFM).\nThe detailed structure of the model, including the implementation of the MSCFM module,\nis illustrated in Figure 2.\nTable 3 provides a comprehensive evaluation\nof hyper-parameter selection, assessing the impact of hyper-parameters and optimizing the model.\nOur approach involved pre-training the model on the source dataset, as shown in Table 4.\nIncorporating the MSCFM module led to a noticeable improvement in the accuracy of the ResNet model,\nindicating that the fusion of multi-scale features enabled the model to capture\nricher information and enhance its generalization capacity.\nTable 5 presents the performance comparison of models with\nand without pre-training and fine-tuning.\nWe observed that pre-trained models, particularly those trained on extensive datasets,\nexhibited superior generalization abilities.\nFine-tuning the parameters of pre-trained models on the target dataset\nfurther enhanced their adaptability, highlighting the efficiency of\ntransfer learning in handling limited data scenarios.\nThe learning curve depicted in Figure 3 demonstrates\nthe model’s effective training process,\nwith the early stopping mechanism preventing over-fitting.\nAdditionally, the visualization of key features in Figure 4\nshowcases the model’s ability to focus on essential burst characteristics,\naligning with human expertise in GRB recognition.\nFurthermore, Figures 5, 6, and 7\nillustrate the successful recovery of three GRBs in real GECAM-B\nobservations using the optimized model. T\nhis achievement can be attributed to the synergistic effects of our data augmentation\nalgorithms, model enhancements, and transfer learning strategies.\nThe accurate identification of GRBs holds significant importance, as they may potentially\ncorrespond to gravitational waves, fast radio bursts, or other transient\nastronomical phenomena (Yang et al. 2020)."
        ]
    }
}{
    "S3.T5.3.1": {
        "caption": [
            "Table 5",
            "Model performance on GECAM dataset.",
            "0.86Bold text represents that the model performs optimally on that metric."
        ],
        "table": "<table id=\"S3.T5.3.1\" class=\"ltx_tabular ltx_figure_panel ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T5.3.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T5.3.1.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T5.3.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Model</span></th>\n<th id=\"S3.T5.3.1.1.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T5.3.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Pre-train</span></th>\n<th id=\"S3.T5.3.1.1.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T5.3.1.1.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Fine-tune</span></th>\n<th id=\"S3.T5.3.1.1.1.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">\n<span id=\"S3.T5.3.1.1.1.4.1\" class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Accuracy</span><span id=\"S3.T5.3.1.1.1.4.2\" class=\"ltx_text\" style=\"font-size:90%;\"> (%)</span>\n</th>\n<th id=\"S3.T5.3.1.1.1.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">\n<span id=\"S3.T5.3.1.1.1.5.1\" class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Precision</span><span id=\"S3.T5.3.1.1.1.5.2\" class=\"ltx_text\" style=\"font-size:90%;\"> (%)</span>\n</th>\n<th id=\"S3.T5.3.1.1.1.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">\n<span id=\"S3.T5.3.1.1.1.6.1\" class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">Recall</span><span id=\"S3.T5.3.1.1.1.6.2\" class=\"ltx_text\" style=\"font-size:90%;\"> (%)</span>\n</th>\n<th id=\"S3.T5.3.1.1.1.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\">\n<span id=\"S3.T5.3.1.1.1.7.1\" class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">F1-score</span><span id=\"S3.T5.3.1.1.1.7.2\" class=\"ltx_text\" style=\"font-size:90%;\"> (%)</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T5.3.1.2.1\" class=\"ltx_tr\">\n<td id=\"S3.T5.3.1.2.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"></td>\n<th id=\"S3.T5.3.1.2.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T5.3.1.2.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">dataset</span></th>\n<th id=\"S3.T5.3.1.2.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T5.3.1.2.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">dataset</span></th>\n<th id=\"S3.T5.3.1.2.1.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_th ltx_th_column\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"></th>\n<th id=\"S3.T5.3.1.2.1.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_th ltx_th_column\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"></th>\n<th id=\"S3.T5.3.1.2.1.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_th ltx_th_column\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"></th>\n<td id=\"S3.T5.3.1.2.1.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"></td>\n</tr>\n<tr id=\"S3.T5.3.1.3.2\" class=\"ltx_tr\">\n<td id=\"S3.T5.3.1.3.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\" rowspan=\"3\"><span id=\"S3.T5.3.1.3.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">ResNet-MSCFM</span></td>\n<td id=\"S3.T5.3.1.3.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T5.3.1.3.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">GECAM</span></td>\n<td id=\"S3.T5.3.1.3.2.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T5.3.1.3.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td id=\"S3.T5.3.1.3.2.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T5.3.1.3.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">95.44</span></td>\n<td id=\"S3.T5.3.1.3.2.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T5.3.1.3.2.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">95.74</span></td>\n<td id=\"S3.T5.3.1.3.2.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T5.3.1.3.2.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">78.94</span></td>\n<td id=\"S3.T5.3.1.3.2.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T5.3.1.3.2.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">86.54</span></td>\n</tr>\n<tr id=\"S3.T5.3.1.4.3\" class=\"ltx_tr\">\n<td id=\"S3.T5.3.1.4.3.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T5.3.1.4.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Fermi/GBM</span></td>\n<td id=\"S3.T5.3.1.4.3.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T5.3.1.4.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td id=\"S3.T5.3.1.4.3.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T5.3.1.4.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">96.25</span></td>\n<td id=\"S3.T5.3.1.4.3.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T5.3.1.4.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">90.99</span></td>\n<td id=\"S3.T5.3.1.4.3.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T5.3.1.4.3.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">88.59</span></td>\n<td id=\"S3.T5.3.1.4.3.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T5.3.1.4.3.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">89.77</span></td>\n</tr>\n<tr id=\"S3.T5.3.1.5.4\" class=\"ltx_tr\">\n<td id=\"S3.T5.3.1.5.4.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T5.3.1.5.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Fermi/GBM</span></td>\n<td id=\"S3.T5.3.1.5.4.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T5.3.1.5.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">GECAM</span></td>\n<td id=\"S3.T5.3.1.5.4.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T5.3.1.5.4.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">96.41</span></td>\n<td id=\"S3.T5.3.1.5.4.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T5.3.1.5.4.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">91.07</span></td>\n<td id=\"S3.T5.3.1.5.4.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T5.3.1.5.4.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">89.47</span></td>\n<td id=\"S3.T5.3.1.5.4.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b\" style=\"padding-left:1.0pt;padding-right:1.0pt;\"><span id=\"S3.T5.3.1.5.4.6.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">90.26</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "We employed a 1D convolutional neural network to classify samples belonging to\nGRB and non-GRB categories in a supervised learning framework.\nTo enhance feature extraction capabilities, we integrated a multi-scale feature\ncross fusion module (MSCFM) into the commonly used ResNet model.\nThe hyper-parameter choices for the model are listed in Table 3.\nTable 4 presents the performance comparison between\nthe baseline model and the model incorporating the MSCFM module on the source dataset.\nThe results demonstrate that the inclusion of the MSCFM module significantly enhances the model’s performance.\nSpecifically, the ResNet+MSCFM model, pre-trained on the source dataset,\nachieved an impressive accuracy of 97.37%.\nFurthermore, Table 5 showcases the performance metrics\nof the model trained directly on the target dataset, solely on the source dataset,\nand through transfer learning to the target dataset.\nNotably, by transferring the pre-trained model, the model achieved a high accuracy\nof 96.41% on the target test set.\nThe learning curves for model pre-training and fine-tuning are illustrated in Figure 3,\nproviding insights into the model’s training progress.\nAdditionally, through feature visualization techniques, we observed that the model effectively\nextracted and focused on the key features of GRBs, as depicted in Figure 4.\nThese findings illustrate the model’s ability to discern and focus on essential features\nfor accurate GRB identification.",
            "We selected ResNet as the benchmark model for GRB identification due to its robustness\nand versatility in deep learning applications.\nTo enhance the model’s multi-scale feature extraction capabilities,\nwe introduced a multi-scale feature cross fusion module (MSCFM).\nThe detailed structure of the model, including the implementation of the MSCFM module,\nis illustrated in Figure 2.\nTable 3 provides a comprehensive evaluation\nof hyper-parameter selection, assessing the impact of hyper-parameters and optimizing the model.\nOur approach involved pre-training the model on the source dataset, as shown in Table 4.\nIncorporating the MSCFM module led to a noticeable improvement in the accuracy of the ResNet model,\nindicating that the fusion of multi-scale features enabled the model to capture\nricher information and enhance its generalization capacity.\nTable 5 presents the performance comparison of models with\nand without pre-training and fine-tuning.\nWe observed that pre-trained models, particularly those trained on extensive datasets,\nexhibited superior generalization abilities.\nFine-tuning the parameters of pre-trained models on the target dataset\nfurther enhanced their adaptability, highlighting the efficiency of\ntransfer learning in handling limited data scenarios.\nThe learning curve depicted in Figure 3 demonstrates\nthe model’s effective training process,\nwith the early stopping mechanism preventing over-fitting.\nAdditionally, the visualization of key features in Figure 4\nshowcases the model’s ability to focus on essential burst characteristics,\naligning with human expertise in GRB recognition.\nFurthermore, Figures 5, 6, and 7\nillustrate the successful recovery of three GRBs in real GECAM-B\nobservations using the optimized model. T\nhis achievement can be attributed to the synergistic effects of our data augmentation\nalgorithms, model enhancements, and transfer learning strategies.\nThe accurate identification of GRBs holds significant importance, as they may potentially\ncorrespond to gravitational waves, fast radio bursts, or other transient\nastronomical phenomena (Yang et al. 2020)."
        ]
    }
}