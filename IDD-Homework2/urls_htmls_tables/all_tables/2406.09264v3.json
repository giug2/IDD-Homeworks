{
    "S1.tab1": {
        "caption": "",
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"S1.tab1.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S1.tab1.1.1.1\">\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top\" id=\"S1.tab1.1.1.1.1\" style=\"background-color:#E6E6E6;\">\n<span class=\"ltx_rule\" style=\"width:2.0pt;color:#808080;background:#808080;display:inline-block;\">&#160;</span><span class=\"ltx_text\" id=\"S1.tab1.1.1.1.1.1\" style=\"color:#808080;\">&#160;&#160;\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S1.tab1.1.1.1.1.1.1\">\n<span class=\"ltx_p\" id=\"S1.tab1.1.1.1.1.1.1.1\" style=\"width:424.9pt;\"><span class=\"ltx_text\" id=\"S1.tab1.1.1.1.1.1.1.1.1\" style=\"color:#808080;background-color:#E6E6E6;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S1.tab1.1.1.1.1.1.1.1.1.1\">Definition.</span></span></span>\n<span class=\"ltx_p\" id=\"S1.tab1.1.1.1.1.1.1.2\"><em class=\"ltx_emph ltx_font_italic\" id=\"S1.tab1.1.1.1.1.1.1.2.1\" style=\"color:#808080;background-color:#E6E6E6;\"><span class=\"ltx_text ltx_font_bold\" id=\"S1.tab1.1.1.1.1.1.1.2.1.1\">Bidirectional Human-AI Alignment</span> is a comprehensive framework that encompasses two interconnected alignment processes: &#8216;Aligning <span class=\"ltx_text\" id=\"S1.tab1.1.1.1.1.1.1.2.1.2\" style=\"color:#1271CA;\">AI</span> to <span class=\"ltx_text\" id=\"S1.tab1.1.1.1.1.1.1.2.1.3\" style=\"color:#DE4A4D;\">Humans</span>&#8217; and &#8216;Aligning <span class=\"ltx_text\" id=\"S1.tab1.1.1.1.1.1.1.2.1.4\" style=\"color:#DE4A4D;\">Humans</span> to <span class=\"ltx_text\" id=\"S1.tab1.1.1.1.1.1.1.2.1.5\" style=\"color:#1271CA;\">AI</span>&#8217;. The former focuses on integrating human specifications to train, steer, and customize AI, while the latter investigates human cognitive and behavioral adaptations to AI, which supports humans in understanding, critiquing, collaborating with, and adapting to AI advancements. </em></span>\n</span>&#160;&#160;<span class=\"ltx_rule\" style=\"width:2.0pt;color:#808080;background:#808080;display:inline-block;\">&#160;</span></span>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": []
    },
    "S3.SS3.tab1": {
        "caption": "",
        "table": "<table class=\"ltx_tabular ltx_align_top\" id=\"S3.SS3.tab1.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S3.SS3.tab1.1.1.1\">\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top\" id=\"S3.SS3.tab1.1.1.1.1\" style=\"background-color:#E6E6E6;\">\n<span class=\"ltx_rule\" style=\"width:2.0pt;color:#808080;background:#808080;display:inline-block;\">&#160;</span><span class=\"ltx_text\" id=\"S3.SS3.tab1.1.1.1.1.1\" style=\"color:#808080;\">&#160;&#160;\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S3.SS3.tab1.1.1.1.1.1.1\">\n<span class=\"ltx_p\" id=\"S3.SS3.tab1.1.1.1.1.1.1.1\" style=\"width:424.9pt;\"><span class=\"ltx_text\" id=\"S3.SS3.tab1.1.1.1.1.1.1.1.1\" style=\"color:#808080;background-color:#E6E6E6;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S3.SS3.tab1.1.1.1.1.1.1.1.1.1\">Takeaways &amp; Implications for Alignment Clarifications</span></span></span>\n<span class=\"ltx_p\" id=\"S3.SS3.tab1.1.1.1.1.1.1.2\"><span class=\"ltx_text\" id=\"S3.SS3.tab1.1.1.1.1.1.1.2.1\" style=\"color:#808080;background-color:#E6E6E6;\">1. We propose the &#8220;pluralistic human values&#8221; as the alignment goal, wherein AI should be aligned with the diverse perspectives of individuals and societal groups who may be directly or indirectly impacted by AI.</span></span>\n<span class=\"ltx_p\" id=\"S3.SS3.tab1.1.1.1.1.1.1.3\"><span class=\"ltx_text\" id=\"S3.SS3.tab1.1.1.1.1.1.1.3.1\" style=\"color:#808080;background-color:#E6E6E6;\">2. Many exemplary human values outlined in Table&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.09264v3#S3.T2\" title=\"Table 2 &#8227; 3.1. What is the goal of alignment? &#8227; 3. Fundamental Definitions and Clarifications &#8227; Towards Bidirectional Human-AI Alignment: A Systematic Review for Clarifications, Framework, and Future Directions\"><span class=\"ltx_text ltx_ref_tag\">2</span></a>, such as loyalty and environmental protection, are important for alignment but are often overlooked or underexplored in current research.</span></span>\n<span class=\"ltx_p\" id=\"S3.SS3.tab1.1.1.1.1.1.1.4\"><span class=\"ltx_text\" id=\"S3.SS3.tab1.1.1.1.1.1.1.4.1\" style=\"color:#808080;background-color:#E6E6E6;\">3. The human value system should account for complex application contexts and relationships, such as priorities and conflicts, rather than focusing on an exclusive subset of values.</span></span>\n</span>&#160;&#160;<span class=\"ltx_rule\" style=\"width:2.0pt;color:#808080;background:#808080;display:inline-block;\">&#160;</span></span>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": []
    },
    "S4.SS2.SSS4.tab1": {
        "caption": "",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_top\" id=\"S4.SS2.SSS4.tab1.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.SS2.SSS4.tab1.1.1.1\">\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top\" id=\"S4.SS2.SSS4.tab1.1.1.1.1\" style=\"background-color:#E6E6E6;\">\n<span class=\"ltx_rule\" style=\"width:2.0pt;color:#808080;background:#808080;display:inline-block;\">&#160;</span><span class=\"ltx_text\" id=\"S4.SS2.SSS4.tab1.1.1.1.1.1\" style=\"color:#808080;\">&#160;&#160;\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.SS2.SSS4.tab1.1.1.1.1.1.1\">\n<span class=\"ltx_p\" id=\"S4.SS2.SSS4.tab1.1.1.1.1.1.1.1\" style=\"width:424.9pt;\"><span class=\"ltx_text\" id=\"S4.SS2.SSS4.tab1.1.1.1.1.1.1.1.1\" style=\"color:#808080;background-color:#E6E6E6;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.SS2.SSS4.tab1.1.1.1.1.1.1.1.1.1\">Underexplored Dimensions in Aligning <span class=\"ltx_text\" id=\"S4.SS2.SSS4.tab1.1.1.1.1.1.1.1.1.1.1\" style=\"color:#1271CA;background-color:#E6E6E6;\">AI</span> to <span class=\"ltx_text\" id=\"S4.SS2.SSS4.tab1.1.1.1.1.1.1.1.1.1.2\" style=\"color:#DE4A4D;background-color:#E6E6E6;\">Humans</span></span> (See Sec&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.09264v3#S5.SS1\" title=\"5.1. Meta Analysis of Trends and Gaps &#8227; 5. Findings and Discussions on Current Gaps &#8227; Towards Bidirectional Human-AI Alignment: A Systematic Review for Clarifications, Framework, and Future Directions\"><span class=\"ltx_text ltx_ref_tag\">5.1</span></a> for supporting data and evidence):</span></span>\n<span class=\"ltx_p\" id=\"S4.SS2.SSS4.tab1.1.1.1.1.1.1.2\"><span class=\"ltx_text\" id=\"S4.SS2.SSS4.tab1.1.1.1.1.1.1.2.1\" style=\"color:#808080;background-color:#E6E6E6;\">1. Implicit human feedback and simulated human value feedback are under-explored in existing research work.</span></span>\n<span class=\"ltx_p\" id=\"S4.SS2.SSS4.tab1.1.1.1.1.1.1.3\"><span class=\"ltx_text\" id=\"S4.SS2.SSS4.tab1.1.1.1.1.1.1.3.1\" style=\"color:#808080;background-color:#E6E6E6;\">2. Developing and customizing AI during the inference stage or in an interactive way is under-explored.</span></span>\n<span class=\"ltx_p\" id=\"S4.SS2.SSS4.tab1.1.1.1.1.1.1.4\"><span class=\"ltx_text\" id=\"S4.SS2.SSS4.tab1.1.1.1.1.1.1.4.1\" style=\"color:#808080;background-color:#E6E6E6;\">3. Human-in-the-loop evaluation is much less explored than automatic evaluation.</span></span>\n</span>&#160;&#160;<span class=\"ltx_rule\" style=\"width:2.0pt;color:#808080;background:#808080;display:inline-block;\">&#160;</span></span>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": []
    },
    "S4.SS4.SSS3.tab1": {
        "caption": "",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_top\" id=\"S4.SS4.SSS3.tab1.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.SS4.SSS3.tab1.1.1.1\">\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top\" id=\"S4.SS4.SSS3.tab1.1.1.1.1\" style=\"background-color:#E6E6E6;\">\n<span class=\"ltx_rule\" style=\"width:2.0pt;color:#808080;background:#808080;display:inline-block;\">&#160;</span><span class=\"ltx_text\" id=\"S4.SS4.SSS3.tab1.1.1.1.1.1\" style=\"color:#808080;\">&#160;&#160;\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S4.SS4.SSS3.tab1.1.1.1.1.1.1\">\n<span class=\"ltx_p\" id=\"S4.SS4.SSS3.tab1.1.1.1.1.1.1.1\" style=\"width:424.9pt;\"><span class=\"ltx_text\" id=\"S4.SS4.SSS3.tab1.1.1.1.1.1.1.1.1\" style=\"color:#808080;background-color:#E6E6E6;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.SS4.SSS3.tab1.1.1.1.1.1.1.1.1.1\">Underexplored Dimensions in Aligning <span class=\"ltx_text\" id=\"S4.SS4.SSS3.tab1.1.1.1.1.1.1.1.1.1.1\" style=\"color:#DE4A4D;background-color:#E6E6E6;\">Humans</span> to <span class=\"ltx_text\" id=\"S4.SS4.SSS3.tab1.1.1.1.1.1.1.1.1.1.2\" style=\"color:#1271CA;background-color:#E6E6E6;\">AI</span></span> (See Sec&#160;<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2406.09264v3#S5.SS1\" title=\"5.1. Meta Analysis of Trends and Gaps &#8227; 5. Findings and Discussions on Current Gaps &#8227; Towards Bidirectional Human-AI Alignment: A Systematic Review for Clarifications, Framework, and Future Directions\"><span class=\"ltx_text ltx_ref_tag\">5.1</span></a> for supporting data and evidence):</span></span>\n<span class=\"ltx_p\" id=\"S4.SS4.SSS3.tab1.1.1.1.1.1.1.2\"><span class=\"ltx_text\" id=\"S4.SS4.SSS3.tab1.1.1.1.1.1.1.2.1\" style=\"color:#808080;background-color:#E6E6E6;\">1. Educating and training humans on AI literacy is under-investigated.</span></span>\n<span class=\"ltx_p\" id=\"S4.SS4.SSS3.tab1.1.1.1.1.1.1.3\"><span class=\"ltx_text\" id=\"S4.SS4.SSS3.tab1.1.1.1.1.1.1.3.1\" style=\"color:#808080;background-color:#E6E6E6;\">2. Auditing AI for various ethical values is not fully explored.</span></span>\n<span class=\"ltx_p\" id=\"S4.SS4.SSS3.tab1.1.1.1.1.1.1.4\"><span class=\"ltx_text\" id=\"S4.SS4.SSS3.tab1.1.1.1.1.1.1.4.1\" style=\"color:#808080;background-color:#E6E6E6;\">3. The collaboration between humans and AI with similar or superior capabilities is under-explored.</span></span>\n<span class=\"ltx_p\" id=\"S4.SS4.SSS3.tab1.1.1.1.1.1.1.5\"><span class=\"ltx_text\" id=\"S4.SS4.SSS3.tab1.1.1.1.1.1.1.5.1\" style=\"color:#808080;background-color:#E6E6E6;\">4. The societal impacts of and reactions to AI advancements are not fully explored.</span></span>\n</span>&#160;&#160;<span class=\"ltx_rule\" style=\"width:2.0pt;color:#808080;background:#808080;display:inline-block;\">&#160;</span></span>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": []
    },
    "S5.SS1.tab1": {
        "caption": "",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_top\" id=\"S5.SS1.tab1.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.SS1.tab1.1.1.1\">\n<td class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top\" id=\"S5.SS1.tab1.1.1.1.1\" style=\"background-color:#E6E6E6;\">\n<span class=\"ltx_rule\" style=\"width:2.0pt;color:#808080;background:#808080;display:inline-block;\">&#160;</span><span class=\"ltx_text\" id=\"S5.SS1.tab1.1.1.1.1.1\" style=\"color:#808080;\">&#160;&#160;\n<span class=\"ltx_inline-block ltx_align_top\" id=\"S5.SS1.tab1.1.1.1.1.1.1\">\n<span class=\"ltx_p\" id=\"S5.SS1.tab1.1.1.1.1.1.1.1\" style=\"width:424.9pt;\"><span class=\"ltx_text\" id=\"S5.SS1.tab1.1.1.1.1.1.1.1.1\" style=\"color:#808080;background-color:#E6E6E6;\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S5.SS1.tab1.1.1.1.1.1.1.1.1.1\">Takeaways of Interaction Techniques for Alignment.</span></span></span>\n<span class=\"ltx_p\" id=\"S5.SS1.tab1.1.1.1.1.1.1.2\"><span class=\"ltx_text\" id=\"S5.SS1.tab1.1.1.1.1.1.1.2.1\" style=\"color:#808080;background-color:#E6E6E6;\">1. Some common human feedback formats (rating, ranking) used in NLP/ML are not often studied in HCI.</span></span>\n<span class=\"ltx_p\" id=\"S5.SS1.tab1.1.1.1.1.1.1.3\"><span class=\"ltx_text\" id=\"S5.SS1.tab1.1.1.1.1.1.1.3.1\" style=\"color:#808080;background-color:#E6E6E6;\">2. Diverse human interactive feedbacks in HCI are not fully used in AI development in NLP/ML fields.</span></span>\n</span>&#160;&#160;<span class=\"ltx_rule\" style=\"width:2.0pt;color:#808080;background:#808080;display:inline-block;\">&#160;</span></span>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": []
    }
}