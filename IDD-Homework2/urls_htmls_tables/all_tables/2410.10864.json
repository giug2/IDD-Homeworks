{
    "id_table_1": {
        "caption": "Table 1:  Synthetic Data Generation Strategy (DB: Decision Boundary). Refer to Appendix  A  for the prompts used for data generation across different scenarios.",
        "table": "S3.T1.2",
        "footnotes": [
            ""
        ],
        "references": [
            "Our approach is derived from the Probably Approximately Correct (PAC) learning framework  Valiant ( 1984 ) . We prove that reducing both calibration and misclassification errors can be achieved simultaneously, and we establish the necessity of generating synthetic data for enhancing model calibration. This approach is validated on real-world text datasets. The synthetic data generation process is accomplished using open-source Large Language Models - Llama 2  Touvron et al. ( 2023 ) . Figure  1  illustrates our proposed framework to improve model calibration and generalization via synthetic data for natural language classification tasks.",
            "Now we derive the ECE bound from the PAC learning framework. First, we extend the definition of accuracy and confidence in Equation ( 1 ) from bin-wise to data-wise. Then we have",
            "Synthetic data generation consists of two stages: First, we specify the gaps against the perfect calibration line in the reliability diagram. Bins over the line are underconfident while those under the line are overconfident. The data points in those bins are the target data samples for synthetic data generation. With the predicted probability 0.5 as the cutoff, we categorize the reliability diagram (Figure  2(a) ) into four scenarios:  Low Probability & Over Confidence, Low Probability & Under Confidence, High Probability & Over Confidence, and High Probability & Under Confidence , as shown in Table  1 .",
            "In Figure  2(b) , the target data points are circled in black and the synthetic data are in the blue circle, which are generated based on the generation strategy in Table  1 . Since the synthetic data shares a similar feature space and the same labels as the target data samples, the retrained classifier would predict them as the same class but with smaller probabilities. This makes it more likely for the synthetic data to be assigned to the same bin as the original target data samples. In this way, we push the predicted probability of this bin away from the decision boundary and reduce the difference  | Conf  ( B m )  Conf  ( B m  ) | Conf subscript B m Conf superscript subscript B m \\left|\\text{Conf}(B_{m})-\\text{Conf}(B_{m}^{*})\\right| | Conf ( italic_B start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ) - Conf ( italic_B start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ) | .",
            "We provide the code used to generate the corresponding prompts based on the scenarios to which the bins in Table  1  belong.",
            "The Expected Calibration Bound Proof :   From equation ( 1 ) in section 2, we extend the definition of accuracy and confidence from bin-wise to data-wise:"
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Dataset Statistics",
        "table": "S3.T2.1",
        "footnotes": [],
        "references": [
            "Reliability Diagram . Reliability diagram (see Figure  2(a) ) is a tool to visualize the model calibration.  C  o  n  f  ( B m ) C o n f subscript B m Conf(B_{m}) italic_C italic_o italic_n italic_f ( italic_B start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT )  and  A  c  c  ( B m ) A c c subscript B m Acc(B_{m}) italic_A italic_c italic_c ( italic_B start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT )  represent the x-axis and y-axis of the diagram respectively for bin  B m subscript B m B_{m} italic_B start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT . The diagonal line denotes perfectly calibrated and any deviations from this diagonal line indicate a models miscalibration. Therefore, the miscalibration can be divided as above the line (underconfidence:  A  c  c  ( B m ) A c c subscript B m Acc(B_{m}) italic_A italic_c italic_c ( italic_B start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT )  >  C  o  n  f  ( B m ) C o n f subscript B m Conf(B_{m}) italic_C italic_o italic_n italic_f ( italic_B start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ) ) and under the line (overconfidence:  A  c  c  ( B m ) A c c subscript B m Acc(B_{m}) italic_A italic_c italic_c ( italic_B start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT )  <  C  o  n  f  ( B m ) C o n f subscript B m Conf(B_{m}) italic_C italic_o italic_n italic_f ( italic_B start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ) ) areas. We use a reliability diagram to find out the target bins where synthetic data are needed to fill in.",
            "Synthetic data generation consists of two stages: First, we specify the gaps against the perfect calibration line in the reliability diagram. Bins over the line are underconfident while those under the line are overconfident. The data points in those bins are the target data samples for synthetic data generation. With the predicted probability 0.5 as the cutoff, we categorize the reliability diagram (Figure  2(a) ) into four scenarios:  Low Probability & Over Confidence, Low Probability & Under Confidence, High Probability & Over Confidence, and High Probability & Under Confidence , as shown in Table  1 .",
            "To illustrate our method, in Figure  2(b)  a hidden predicted probability line is shown orthogonal to the estimated decision boundary. Data points close to this decision boundary would be predicted with around 0.5 probability (the softmax output), while data points at the two ends of this line could be predicted with close to 0.1 or 0.9 probability, respectively. Suppose that our targeted bin has a confidence of 0.3 and it is over-confident as shown in Figure  2(a)  (highlighted in a purple rectangular). The gap between the empirical and theoretical uncertainty values is shown in red. There are two possible solutions to fill the gap: 1) increasing the number of incorrect predictions, thus raising the blue bar that represents the empirical inaccurate prediction percentage; or 2) moving this bin to the left, into the bin with a smaller uncertainty value. We use the second solution to align the miscalibration bins because the first solution could harm the accuracy of the classifier.",
            "In Figure  2(b) , the target data points are circled in black and the synthetic data are in the blue circle, which are generated based on the generation strategy in Table  1 . Since the synthetic data shares a similar feature space and the same labels as the target data samples, the retrained classifier would predict them as the same class but with smaller probabilities. This makes it more likely for the synthetic data to be assigned to the same bin as the original target data samples. In this way, we push the predicted probability of this bin away from the decision boundary and reduce the difference  | Conf  ( B m )  Conf  ( B m  ) | Conf subscript B m Conf superscript subscript B m \\left|\\text{Conf}(B_{m})-\\text{Conf}(B_{m}^{*})\\right| | Conf ( italic_B start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ) - Conf ( italic_B start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ) | .",
            "Additionally, to discover whether the pre-trained knowledge of LLMs is a crucial element in determining the performance of generated synthetic data on downstream tasks. We choose two newly-released datasets that are unlikely to be a part of the training data of LLMs we used in the paper ( Llama-2 ): Arxiv-10  Farhangi et al. ( 2022 )  and Medical  Fansi Tchango et al. ( 2022 ) . We pick cs and stat classes, and randomly sample 30% from the entire data in Arxiv-10. Its task is to classify the subject based on the title of a paper. Medical is the dataset in a medical diagnosis domain categorizing a specific disease based on a patients symptoms, where \"Influenza\" and \"Anaphylaxis\" in our experiment. See detailed statistics of these datasets in Table  2 ."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  An example of generating synthetic data via LLM. As an example, we use the SE dataset; for information on other datasets, see Table  8  in Appendix  D .  Input  contains the original text ( x i subscript x i x_{i} italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) and the average predictive probability of the bin it comes from ( P ^  ( y i | x i ) ^ P conditional subscript y i subscript x i \\hat{P}(y_{i}|x_{i}) over^ start_ARG italic_P end_ARG ( italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ).  Generated Text  is the one after the relabeling process.  Note : during re-fine tuning of the downstream model, we exclude  P ^  ( y i | x i s  y  n ) ^ P conditional subscript y i subscript superscript x s y n i \\hat{P}(y_{i}|x^{syn}_{i}) over^ start_ARG italic_P end_ARG ( italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_x start_POSTSUPERSCRIPT italic_s italic_y italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )   (55% negative, 45% positive) and retain only  x i s  y  n subscript superscript x s y n i x^{syn}_{i} italic_x start_POSTSUPERSCRIPT italic_s italic_y italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  in the dataset.",
        "table": "S4.T4.132",
        "footnotes": [
            "",
            ""
        ],
        "references": [
            "By deriving from the left side of equation ( 3 ), we get:",
            "Combined with the right side of equation ( 3 ):",
            "We use a 1D logistic regression classifier as an example to demonstrate that adding appropriate synthetic data in the target bins can produce a better-calibrated and more accurate model. Parameters of the true model are defined:   0 subscript  0 \\beta_{0} italic_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT  = -1 and   1 subscript  1 \\beta_{1} italic_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  = 2. We randomly simulate 300 data points from the range between -10 and 10 and classify them based on the true model as the label. A logistic regression model is fitted on these data points. The fitted parameters are   0 subscript  0 \\beta_{0} italic_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT  = -0.06 and   1 subscript  1 \\beta_{1} italic_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  = 1.13. The model achieves an accuracy of 0.95 and an ECE of 0.0405 (Figure  3(a) ).",
            "Figure  3(b)  shows us that the fitted logistic regression is overconfident about its predictions in the  2 n  d superscript 2 n d 2^{nd} 2 start_POSTSUPERSCRIPT italic_n italic_d end_POSTSUPERSCRIPT  bin and  4 t  h superscript 4 t h 4^{th} 4 start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPT  bin. Now we target these two bins to generate some synthetic data points to fill the gap. The function we used to generate synthetic data points is a left-sided truncated normal distribution, whose parameters are:    \\mu italic_  =   B  i  n i subscript  B i subscript n i \\mu_{Bin_{i}} italic_ start_POSTSUBSCRIPT italic_B italic_i italic_n start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT ,  S  D S D SD italic_S italic_D  =  S  D B  i  n i S subscript D B i subscript n i SD_{Bin_{i}} italic_S italic_D start_POSTSUBSCRIPT italic_B italic_i italic_n start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT , n =  | B  i  n i | B i subscript n i |Bin_{i}| | italic_B italic_i italic_n start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | ,  i = { 2 , 4 } i 2 4 i=\\{2,4\\} italic_i = { 2 , 4 } . We add new data points step by step to see how the logistic curve changes: 1) add synthetic data of the  2 n  d superscript 2 n d 2^{nd} 2 start_POSTSUPERSCRIPT italic_n italic_d end_POSTSUPERSCRIPT  bin, 2) then add synthetic data of the  4 t  h superscript 4 t h 4^{th} 4 start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPT  bin based on previously added data points. See the parameters and performance for newly fitted models below:",
            "Figure  3(c)  and Figure  3(d)  illustrate that incorporating synthetic data generated from overconfident bins shifts the fitted logistic curve towards the standard logistic curve, resulting in a more accurately calibrated model.",
            "Synthetic text generation is performed using version  Llama-2-7b-chat-hf  of Llama 2 at a temperature  T = 0.1 T 0.1 T=0.1 italic_T = 0.1 . We apply the two-stage and three-shot learning generation method proposed in the paper  Sahu et al. ( 2023 )  to guarantee diversity and authenticity. First, we define each label and provide three examples for each one (Appendix  C ). Then, we present the example text from the previous selection stage along with the predicted probability of this example that was extracted from the trained BERT base  classifier. We then instruct llama 2 to act as the base classifier to generate three similar texts that could be classified with specific probability requirements. Next, we instruct llama 2 to relabel the generated texts to ensure them belong to the \"correct\" class. Table  3  illustrates the inputs, prompts, and outputs for generating synthetic data using the SE dataset. Additional prompts for different scenarios can be found in Appendix  D ."
        ]
    },
    "id_table_4": {
        "caption": "Table 4:  Model Performance and Calibration on Real Test Data. Highlighted values considered both ACC and ECE and weigh more on ECE.",
        "table": "S4.T5.6",
        "footnotes": [],
        "references": [
            "We run each experiment for three random seeds and report the average value (with standard deviation in brackets) of accuracy and ECE in Table  4 . By adding synthetic data with a size of 7%-18%  2 2 2 The validation set is used to identify poorly calibrated bins. We set a predefined threshold of 0.03, and only bins with gaps exceeding this threshold are selected.  of the training set, we would have a 21-33% ECE decrease. Taking both accuracy and ECE into account, our synthetic data replacement (synthesis) and synthetic data add-on (synthesis+) methods outperform other calibration approaches in five out of six datasets. Temperature scaling can sometimes achieve lower ECE, but a key disadvantage is that it doesnt affect accuracy. On the other hand, while dropout can improve model calibration, it carries the risk of reducing accuracy, as seen in the results on the Arxiv-10 dataset. We also observe a clear association of a larger bin number with lower ECE 3 3 3 We use the bins average confidence to represent each instance within that bin, so having more bins could lead to more accurate probability estimates in synthetic data generation. . In addition, the results of our approach have smaller variances compared with those of the baseline."
        ]
    },
    "id_table_5": {
        "caption": "Table 5:  Pearson Correlation Coefficient on six datasets.  Syn A  C  C ( % ) \\text{Syn}_{ACC}(\\%) Syn start_POSTSUBSCRIPT italic_A italic_C italic_C end_POSTSUBSCRIPT ( % )  and  Syn E  C  E ( % ) \\text{Syn}_{ECE}(\\%) Syn start_POSTSUBSCRIPT italic_E italic_C italic_E end_POSTSUBSCRIPT ( % )  denotes the percentage of the downstream models accuracy increases and how much percentage of the expected calibration error is decreased respectively.",
        "table": "A1.T6.1",
        "footnotes": [],
        "references": [
            "In Table  5 , we didnt observe a strong negative correlation coefficient between  LLM A  C  C subscript LLM A C C \\text{LLM}_{ACC} LLM start_POSTSUBSCRIPT italic_A italic_C italic_C end_POSTSUBSCRIPT  and  Syn E  C  E ( % ) \\text{Syn}_{ECE}(\\%) Syn start_POSTSUBSCRIPT italic_E italic_C italic_E end_POSTSUBSCRIPT ( % ) , indicating there is no empirical evidence that shows the calibration ability of LLMs determines the application of our proposed methods. Additionally, we found a moderate positive association between the llamas accuracy and the accuracy improvement in downstream tasks. This suggests that the prediction accuracy of LLMs, rather than calibration capability, plays a more important role in downstream models performance. Therefore, using advanced LLMs (such as Llama 3.2) or fine-tuning LLMs to incorporate domain knowledge could yield better performance when applying our approach."
        ]
    },
    "id_table_6": {
        "caption": "Table 6:  Model Parameters (Bert base )",
        "table": "A4.EGx1",
        "footnotes": [],
        "references": []
    },
    "id_table_7": {
        "caption": "Table 7:  System Prompt for Data Generation",
        "table": "A4.EGx2",
        "footnotes": [],
        "references": []
    }
}