{
    "id_table_1": {
        "caption": "Table 1:  Point cloud completion results on the ScanNet dataset  [ 12 ]  at the resolution of 16384 points. Experimental results show that the proposed method outperforms the state-of-the-art baselines.",
        "table": "S4.T2.1",
        "footnotes": [
            ""
        ],
        "references": [
            "To this end, we address the multimodal nature of the problem by adopting a denoising diffusion probabilistic model (DDPM)  [ 17 ]  as our core module. Given two noisy point clouds of an object captured from two distinctive viewpoints, one of them acts as the input to our pipeline while a pseudo ground-truth is computed by combining the two point clouds. Our method,  RealDiff , formulates shape completion as a conditional generation problem, by simulating a diffusion process at the missing object parts. To eliminate the noise from the reconstructions, supplementary geometric priors - silhouettes and depth maps - are employed. The rendered silhouettes are aligned with the silhouettes obtained by an external method (for instance, ScanNet), and consistency is ensured between the rendered depth maps and those estimated by an off-the-shelf monocular depth estimation network. Hence, the auxiliary silhouettes and depth maps are externally sourced: (1) silhouettes are measured or manually annotated (e.g., ScanNet  [ 12 ] ), and (2) depth is estimated via monocular depth estimation (e.g.,  [ 13 ] ). Incorporating auxiliary weak supervisory signals derived from geometric priors enables the method to achieve enhanced learning of accurate object shapes, as shown in Fig.  1 .",
            "Given a noisy and partial real-world point cloud of an object, the aim of our novel approach is to complete its 3D shape by predicting the geometry of the unobserved parts. The completion task is formulated as a conditional generation problem that produces the complete shape given the input partial point cloud. The scheme of the pipeline is illustrated in Fig.  2 . Since the problem of shape completion is multimodal by its nature, a denoising diffusion probabilistic model (DDPM) is used as the core of our approach (Sec.  3.1 ). Our approach enables the generation of multiple plausible completions from a single incomplete point cloud, while effectively learning category-specific shape priors solely from partial real-world data without considering complete shapes during the training process in a self-supervised way. To overcome the limitations of working with noisy observations without resorting to training on synthetic data, additional geometric cues are used including depth and silhouette information (Sec.  3.2 ).",
            "In this section, we first introduce our experimental setup in terms of the baselines, benchmarks and evaluation metrics. Then, large scale experiments are presented to evaluate our method for point cloud completion. Sec.  4.1  assesses the methods point cloud completion capabilities when trained on real-world datasets and Sec.  4.2  demonstrates our models performance on the multimodal completion task. Additionally, the effectiveness of synthetic shape priors is evaluated in terms of real-world performance (Sec.  4.3 ). Finally, an ablation study validating the design choices is given in Sec.  4.4  and complexity analysis is provided in Sec.  4.5 . For additional experiments and detailed experimental setup, we refer to the Appendix.",
            "Table  1  shows the performance of all completion methods. Consistently, our method surpasses the baseline methods when it comes to per-category F1-score and EMD, showcasing the robustness of  RealDiff  in handling various noise and incompleteness patterns encountered in real-world scenarios. While our method achieves high recall values across all the categories, it performs worse than the baseline methods in terms of accuracy. Different from the baselines,  RealDiff  employs voxel grid representation to resolve the issue of operating on unordered point sets, which naturally results in offsetting the surface during the final mesh extraction. Also, precision can be highly affected when the networks tend to place more points near the known parts and predict less points in the missing parts as shown in Fig.  3 . Although this strategy can achieve remarkable precision, it frequently culminates in highly deficient reconstructions that do not meet the ultimate goal of the task. Our enhanced recall, on the other hand, more accurately reflects a higher completion capability. Besides, our method reduces the average EMD score by 10.39 when compared against the second-ranked method AdaPoinTr  [ 61 ]  (68.733 in terms of average EMD), enhancing the  uniformity  of the reconstructions. MPC  [ 53 ] , which proposes a conditional generative model to learn a mapping between latent spaces, achieves lower scores. This might be because the latent space of complete shapes (pseudo ground-truths in this case), which are also incomplete, cannot provide a strong supervisory signal when the model is trained on an unpaired setting  [ 53 ] . ShapeFormer  [ 58 ]  struggles in the real-world scenario, as observations are quantized into patches. Since there are only a few number of patches to extract information from in the case of sparse real-world data, their VQDIF cannot represent the shapes accurately. Similar to ShapeFormer, P2C  [ 10 ]  which groups incomplete point clouds into local patches also suffers from the same problem and yields blob-like completion results with lower precision.",
            "Synthetic training on the target category.  Prior work employs synthetic priors to learn a mapping between partial and complete shapes. To evaluate the effectiveness of synthetic shape priors from the target category for real-world performance, experiments are conducted on the synthetic ShapeNet dataset  [ 2 ] . All methods are trained on the  chair  object category of ShapeNet, and they are directly evaluated on chairs from ScanNet. The quantitative results of baseline methods and ours in Table  4  are lower than our methods results provided in Table  1 , showing that shape priors learned from synthetic data of the same shape category do not transfer successfully to real-world observations. This observation indicates a substantial domain shift between the synthetic domain and the real-world scenario, underscoring the necessity to train directly on real-world data for the purpose of completing actual observations.",
            "Effect of using geometric priors.  To investigate the effectiveness of each of the key components in our design, an ablation study is conducted on the ScanNet dataset. We train with four configurations: ( A ) raw setting of our model defined in Sec.  3.1  with only the reconstruction loss  L t subscript L t \\mathcal{L}_{t} caligraphic_L start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , ( B ) in addition to the raw setting, we add silhouette supervision, ( C ) we add depth supervision to the raw setting, ( D ) our full model which jointly learns shape information and smoothness prior by optimizing  L L \\mathcal{L} caligraphic_L  defined in Sec.  3.2 . We report quantitative results in Table  6  and present the visual comparison in Fig.  6 .",
            "We further report an upper bound completion performance of multi-modal methods utilizing the MMD metric. MMD is computed between the set of partial shapes and ground-truth complete shapes as described in Appendix  C . While the nearest neighbor shape selection is performed based on the highest F1-score, we additionally compute precision, recall and EMD based on the selected shapes. The quantitative results are presented in Table  10 . Note that only MPC  [ 53 ] , ShapeFormer  [ 58 ]  and our method are able to produce multiple plausible completions from a single input, and therefore we only provide the results for them. PoinTr  [ 60 ] , SnowflakeNet  [ 56 ] , AdaPoinTr  [ 61 ]  and P2C  [ 10 ]  generate the same completions at each run."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Study on the degree of incompleteness of partial inputs on diversity.",
        "table": "S4.T3.9.9",
        "footnotes": [
            "",
            ""
        ],
        "references": [
            "Given a noisy and partial real-world point cloud of an object, the aim of our novel approach is to complete its 3D shape by predicting the geometry of the unobserved parts. The completion task is formulated as a conditional generation problem that produces the complete shape given the input partial point cloud. The scheme of the pipeline is illustrated in Fig.  2 . Since the problem of shape completion is multimodal by its nature, a denoising diffusion probabilistic model (DDPM) is used as the core of our approach (Sec.  3.1 ). Our approach enables the generation of multiple plausible completions from a single incomplete point cloud, while effectively learning category-specific shape priors solely from partial real-world data without considering complete shapes during the training process in a self-supervised way. To overcome the limitations of working with noisy observations without resorting to training on synthetic data, additional geometric cues are used including depth and silhouette information (Sec.  3.2 ).",
            "In this section, we first introduce our experimental setup in terms of the baselines, benchmarks and evaluation metrics. Then, large scale experiments are presented to evaluate our method for point cloud completion. Sec.  4.1  assesses the methods point cloud completion capabilities when trained on real-world datasets and Sec.  4.2  demonstrates our models performance on the multimodal completion task. Additionally, the effectiveness of synthetic shape priors is evaluated in terms of real-world performance (Sec.  4.3 ). Finally, an ablation study validating the design choices is given in Sec.  4.4  and complexity analysis is provided in Sec.  4.5 . For additional experiments and detailed experimental setup, we refer to the Appendix.",
            "Fig.  5  shows multimodal shape completion results on ScanNet dataset (Shapes are ordered from left to right, top to bottom). As the degree of incompleteness in the partial input increases, as seen in the first, third, and fourth shapes, the inherent ambiguity leads to a wider range of diverse completions across different runs. Conversely, for the second shape where the input is more complete, there are only slight variations between runs. This is confirmed quantitatively in the following experiment. We provide the model with input point clouds generated from 1, 5, and 10 views, respectively. Then, 10 completed shapes are computed for each input, and the Total Matching Distance (TMD) score is calculated to capture the diversity (higher TMD    \\rightarrow   higher diversity). This yields the results provided in Table  2 .",
            "Effect of using geometric priors.  To investigate the effectiveness of each of the key components in our design, an ablation study is conducted on the ScanNet dataset. We train with four configurations: ( A ) raw setting of our model defined in Sec.  3.1  with only the reconstruction loss  L t subscript L t \\mathcal{L}_{t} caligraphic_L start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , ( B ) in addition to the raw setting, we add silhouette supervision, ( C ) we add depth supervision to the raw setting, ( D ) our full model which jointly learns shape information and smoothness prior by optimizing  L L \\mathcal{L} caligraphic_L  defined in Sec.  3.2 . We report quantitative results in Table  6  and present the visual comparison in Fig.  6 ."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Multi-modal shape completion on ScanNet  [ 12 ]  w/ 16384 points.",
        "table": "S4.T4.4.4",
        "footnotes": [
            ""
        ],
        "references": [
            "Given a noisy and partial real-world point cloud of an object, the aim of our novel approach is to complete its 3D shape by predicting the geometry of the unobserved parts. The completion task is formulated as a conditional generation problem that produces the complete shape given the input partial point cloud. The scheme of the pipeline is illustrated in Fig.  2 . Since the problem of shape completion is multimodal by its nature, a denoising diffusion probabilistic model (DDPM) is used as the core of our approach (Sec.  3.1 ). Our approach enables the generation of multiple plausible completions from a single incomplete point cloud, while effectively learning category-specific shape priors solely from partial real-world data without considering complete shapes during the training process in a self-supervised way. To overcome the limitations of working with noisy observations without resorting to training on synthetic data, additional geometric cues are used including depth and silhouette information (Sec.  3.2 ).",
            "In this section, we first introduce our experimental setup in terms of the baselines, benchmarks and evaluation metrics. Then, large scale experiments are presented to evaluate our method for point cloud completion. Sec.  4.1  assesses the methods point cloud completion capabilities when trained on real-world datasets and Sec.  4.2  demonstrates our models performance on the multimodal completion task. Additionally, the effectiveness of synthetic shape priors is evaluated in terms of real-world performance (Sec.  4.3 ). Finally, an ablation study validating the design choices is given in Sec.  4.4  and complexity analysis is provided in Sec.  4.5 . For additional experiments and detailed experimental setup, we refer to the Appendix.",
            "Datasets.  A real-world ScanNet dataset  [ 12 ]  and a synthetic ShapeNet dataset  [ 2 ]  are used.  ScanNet  is a large-scale dataset of  R  G  B  D R G B D RGB-D italic_R italic_G italic_B - italic_D  scans providing 3D meshes of objects that are pre-segmented from their surrounding environments. Following  [ 53 ] , we focus on three object categories and use   similar-to \\sim  1500 chairs,   similar-to \\sim  700 tables and   similar-to \\sim  110 lamps split into 90%-10% train-test sets. All the methods are separately trained and evaluated on these categories for the experiments in real-world. For each object instance, we select at least 8 different views and back-project the corresponding 2.5D images into 3D point clouds. Each point cloud is then sub-sampled to 8192 points.   During training, one view is randomly selected as the input. The second view, to form the pseudo ground-truth, is selected from the remaining views based on its contribution to the pseudo ground-truth. To this end, we pick a random view that increases the number of occupied voxels by at least 30% w.r.t. the first view. The point clouds of these two selected views are combined directly as they share the same coordinate system, and then provided as a pseudo ground-truth with 16384 points to train the methods operating on raw point clouds  [ 60 ,  61 ,  56 ,  10 ,  53 ] . Our method uses the voxelized version of it with  64  64  64 64 64 64 64\\times 64\\times 64 64  64  64  voxels. ShapeFormer  [ 58 ]  is provided with both, as it requires both data formats as the input. Externally obtained silhouettes of the objects are used from the readily available per-frame 2D instance masks provided in ScanNet. To evaluate point cloud completion on real-world observations, the Scan2CAD  [ 1 ]  annotations are used of CAD model alignments from ShapeNet to the extracted objects. For each CAD model, 16384 points are sampled for evaluation.   ShapeNet  dataset is used to show the effectiveness of synthetic shape priors in real-world performance (Sec.  4.3 ). To this end, we also train all the methods on ShapeNet and split the data with the 80%-20% strategy. The data pre-processing protocol of  [ 60 ]  is taken to obtain input partial observations with 8192 points for training. During evaluation, we randomly select one view from the real-world input data of ScanNet. Predicted outputs with 16384 points are evaluated using CAD models.",
            "Results on ScanNet.  We first conduct experiments on the real-world ScanNet dataset  [ 12 ] . To compare with the existing methods PoinTr  [ 60 ] , SnowflakeNet  [ 56 ] , AdaPoinTr  [ 61 ] , P2C  [ 10 ] , MPC  [ 53 ]  and ShapeFormer  [ 58 ] , their open-source code and best hyperparameters from their papers are used for a fair evaluation. Visual comparison of our method with the baselines is provided in Fig.  3 . It can be observed that our approach is able to recover the overall shape of the object together with fine-scale details ( e.g.  chair legs), while also preserving the originally observed structure. On the other hand, transformer-based baselines PoinTr  [ 60 ] , SnowflakeNet  [ 56 ]  and AdaPoinTr  [ 61 ]  mostly predict points around the known regions without actually predicting the missing parts. The smoothness of our reconstructions surpasses that of the baseline methods, attributable to our utilization of geometric cues to mitigate the noise originating from sensor measurements. In the challenging  lamp  category, all the baselines and our method struggle to recover the details. While our method produces a coarser reconstruction for the primary body of the lamp due to the voxel representation used, it nonetheless accurately recovers the overall shape of the object when compared to the baselines.",
            "Table  1  shows the performance of all completion methods. Consistently, our method surpasses the baseline methods when it comes to per-category F1-score and EMD, showcasing the robustness of  RealDiff  in handling various noise and incompleteness patterns encountered in real-world scenarios. While our method achieves high recall values across all the categories, it performs worse than the baseline methods in terms of accuracy. Different from the baselines,  RealDiff  employs voxel grid representation to resolve the issue of operating on unordered point sets, which naturally results in offsetting the surface during the final mesh extraction. Also, precision can be highly affected when the networks tend to place more points near the known parts and predict less points in the missing parts as shown in Fig.  3 . Although this strategy can achieve remarkable precision, it frequently culminates in highly deficient reconstructions that do not meet the ultimate goal of the task. Our enhanced recall, on the other hand, more accurately reflects a higher completion capability. Besides, our method reduces the average EMD score by 10.39 when compared against the second-ranked method AdaPoinTr  [ 61 ]  (68.733 in terms of average EMD), enhancing the  uniformity  of the reconstructions. MPC  [ 53 ] , which proposes a conditional generative model to learn a mapping between latent spaces, achieves lower scores. This might be because the latent space of complete shapes (pseudo ground-truths in this case), which are also incomplete, cannot provide a strong supervisory signal when the model is trained on an unpaired setting  [ 53 ] . ShapeFormer  [ 58 ]  struggles in the real-world scenario, as observations are quantized into patches. Since there are only a few number of patches to extract information from in the case of sparse real-world data, their VQDIF cannot represent the shapes accurately. Similar to ShapeFormer, P2C  [ 10 ]  which groups incomplete point clouds into local patches also suffers from the same problem and yields blob-like completion results with lower precision.",
            "We also perform quantitative evaluation using the metrics suggested by  [ 53 ] : Minimal Matching Distance (MMD) capturing the completion quality, TMD measuring the completion diversity, and Unidirectional Hausdorff Distance (UHD) focusing on the completion fidelity. We provide exact definitions of those metric in Appendix  C . The results are summarized in Table  3 . Our approach achieves the best MMD and UHD scores on all classes, while reaching slightly inferior TMD scores on chairs and tables.",
            "Effect of using geometric priors.  To investigate the effectiveness of each of the key components in our design, an ablation study is conducted on the ScanNet dataset. We train with four configurations: ( A ) raw setting of our model defined in Sec.  3.1  with only the reconstruction loss  L t subscript L t \\mathcal{L}_{t} caligraphic_L start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , ( B ) in addition to the raw setting, we add silhouette supervision, ( C ) we add depth supervision to the raw setting, ( D ) our full model which jointly learns shape information and smoothness prior by optimizing  L L \\mathcal{L} caligraphic_L  defined in Sec.  3.2 . We report quantitative results in Table  6  and present the visual comparison in Fig.  6 ."
        ]
    },
    "id_table_4": {
        "caption": "Table 4:  Point cloud completion results on the  chair  category of real-world ScanNet dataset  [ 12 ]  when trained on the target category of synthetic ShapeNet dataset  [ 2 ] , at the resolution of 16384 points. Synthetic shape priors learned from the same category do not transfer successfully into the real-world.",
        "table": "S4.T5.4.4",
        "footnotes": [
            "",
            ""
        ],
        "references": [
            "In this section, we first introduce our experimental setup in terms of the baselines, benchmarks and evaluation metrics. Then, large scale experiments are presented to evaluate our method for point cloud completion. Sec.  4.1  assesses the methods point cloud completion capabilities when trained on real-world datasets and Sec.  4.2  demonstrates our models performance on the multimodal completion task. Additionally, the effectiveness of synthetic shape priors is evaluated in terms of real-world performance (Sec.  4.3 ). Finally, an ablation study validating the design choices is given in Sec.  4.4  and complexity analysis is provided in Sec.  4.5 . For additional experiments and detailed experimental setup, we refer to the Appendix.",
            "Datasets.  A real-world ScanNet dataset  [ 12 ]  and a synthetic ShapeNet dataset  [ 2 ]  are used.  ScanNet  is a large-scale dataset of  R  G  B  D R G B D RGB-D italic_R italic_G italic_B - italic_D  scans providing 3D meshes of objects that are pre-segmented from their surrounding environments. Following  [ 53 ] , we focus on three object categories and use   similar-to \\sim  1500 chairs,   similar-to \\sim  700 tables and   similar-to \\sim  110 lamps split into 90%-10% train-test sets. All the methods are separately trained and evaluated on these categories for the experiments in real-world. For each object instance, we select at least 8 different views and back-project the corresponding 2.5D images into 3D point clouds. Each point cloud is then sub-sampled to 8192 points.   During training, one view is randomly selected as the input. The second view, to form the pseudo ground-truth, is selected from the remaining views based on its contribution to the pseudo ground-truth. To this end, we pick a random view that increases the number of occupied voxels by at least 30% w.r.t. the first view. The point clouds of these two selected views are combined directly as they share the same coordinate system, and then provided as a pseudo ground-truth with 16384 points to train the methods operating on raw point clouds  [ 60 ,  61 ,  56 ,  10 ,  53 ] . Our method uses the voxelized version of it with  64  64  64 64 64 64 64\\times 64\\times 64 64  64  64  voxels. ShapeFormer  [ 58 ]  is provided with both, as it requires both data formats as the input. Externally obtained silhouettes of the objects are used from the readily available per-frame 2D instance masks provided in ScanNet. To evaluate point cloud completion on real-world observations, the Scan2CAD  [ 1 ]  annotations are used of CAD model alignments from ShapeNet to the extracted objects. For each CAD model, 16384 points are sampled for evaluation.   ShapeNet  dataset is used to show the effectiveness of synthetic shape priors in real-world performance (Sec.  4.3 ). To this end, we also train all the methods on ShapeNet and split the data with the 80%-20% strategy. The data pre-processing protocol of  [ 60 ]  is taken to obtain input partial observations with 8192 points for training. During evaluation, we randomly select one view from the real-world input data of ScanNet. Predicted outputs with 16384 points are evaluated using CAD models.",
            "Generalization ability and object of interest detection.  ScanNet provides instance segmentation masks, which we utilized to extract the relevant objects. When those are not available, one can rely on off-the-shelf segmentation models. To showcase this and demonstrate the models ability to generalize across datasets, we apply our ScanNet-pretrained model to scans from the Redwood 3DScans dataset  [ 6 ] . We segment the objects of interest using text-conditioned LangSAM (SAM  [ 24 ]  + GroundingDINO  [ 26 ] ), and then obtain the input point clouds from the depth images using the segmentation masks. Visual results in Fig.  4  show that our pre-trained model is able to generalize to real-world partial shapes from another dataset.",
            "Synthetic training on the target category.  Prior work employs synthetic priors to learn a mapping between partial and complete shapes. To evaluate the effectiveness of synthetic shape priors from the target category for real-world performance, experiments are conducted on the synthetic ShapeNet dataset  [ 2 ] . All methods are trained on the  chair  object category of ShapeNet, and they are directly evaluated on chairs from ScanNet. The quantitative results of baseline methods and ours in Table  4  are lower than our methods results provided in Table  1 , showing that shape priors learned from synthetic data of the same shape category do not transfer successfully to real-world observations. This observation indicates a substantial domain shift between the synthetic domain and the real-world scenario, underscoring the necessity to train directly on real-world data for the purpose of completing actual observations.",
            "Synthetic training on other categories.  To evaluate the effectiveness of synthetic shape priors from other categories for real-world performance, experiments are conducted on the synthetic ShapeNet dataset  [ 2 ] . All methods are trained on the 54 object categories of ShapeNet, except the  chair  category, and they are directly evaluated on chairs from ScanNet. The quantitative results are given in Table  5 . When trained on categories other than the target category, the F1-score and the EMD decrease for all the methods compared to the quantitative results provided in Table  4 . This indicates that neither synthetic training on the target category, nor synthetic pre-training on large shape quantities from other object categories, is sufficient to learn good priors that would enable reliable completion of real-world measurements. Instead, our method is directly trained on noisy real-world observations, which yields the best results."
        ]
    },
    "id_table_5": {
        "caption": "Table 5:  Point cloud completion results on the  chair  category of real-world ScanNet dataset  [ 12 ]  when trained on the other 54 categories of synthetic ShapeNet dataset  [ 2 ] , at the resolution of 16384 points. Synthetic shape priors learned from other categories do not transfer successfully to a different target category for the task of real-world shape completion.",
        "table": "S4.T7.4",
        "footnotes": [
            "",
            ""
        ],
        "references": [
            "In this section, we first introduce our experimental setup in terms of the baselines, benchmarks and evaluation metrics. Then, large scale experiments are presented to evaluate our method for point cloud completion. Sec.  4.1  assesses the methods point cloud completion capabilities when trained on real-world datasets and Sec.  4.2  demonstrates our models performance on the multimodal completion task. Additionally, the effectiveness of synthetic shape priors is evaluated in terms of real-world performance (Sec.  4.3 ). Finally, an ablation study validating the design choices is given in Sec.  4.4  and complexity analysis is provided in Sec.  4.5 . For additional experiments and detailed experimental setup, we refer to the Appendix.",
            "Fig.  5  shows multimodal shape completion results on ScanNet dataset (Shapes are ordered from left to right, top to bottom). As the degree of incompleteness in the partial input increases, as seen in the first, third, and fourth shapes, the inherent ambiguity leads to a wider range of diverse completions across different runs. Conversely, for the second shape where the input is more complete, there are only slight variations between runs. This is confirmed quantitatively in the following experiment. We provide the model with input point clouds generated from 1, 5, and 10 views, respectively. Then, 10 completed shapes are computed for each input, and the Total Matching Distance (TMD) score is calculated to capture the diversity (higher TMD    \\rightarrow   higher diversity). This yields the results provided in Table  2 .",
            "Synthetic training on other categories.  To evaluate the effectiveness of synthetic shape priors from other categories for real-world performance, experiments are conducted on the synthetic ShapeNet dataset  [ 2 ] . All methods are trained on the 54 object categories of ShapeNet, except the  chair  category, and they are directly evaluated on chairs from ScanNet. The quantitative results are given in Table  5 . When trained on categories other than the target category, the F1-score and the EMD decrease for all the methods compared to the quantitative results provided in Table  4 . This indicates that neither synthetic training on the target category, nor synthetic pre-training on large shape quantities from other object categories, is sufficient to learn good priors that would enable reliable completion of real-world measurements. Instead, our method is directly trained on noisy real-world observations, which yields the best results."
        ]
    },
    "id_table_6": {
        "caption": "Table 6:  Effect of using geometric priors.  We report the point cloud completion performance of our method w.r.t the geometric priors used. Geometric priors assist in learning the object shapes while reducing the noise from the reconstructions. Using both cues in combination leads to the best performance.",
        "table": "S4.T8.6",
        "footnotes": [],
        "references": [
            "Effect of using geometric priors.  To investigate the effectiveness of each of the key components in our design, an ablation study is conducted on the ScanNet dataset. We train with four configurations: ( A ) raw setting of our model defined in Sec.  3.1  with only the reconstruction loss  L t subscript L t \\mathcal{L}_{t} caligraphic_L start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , ( B ) in addition to the raw setting, we add silhouette supervision, ( C ) we add depth supervision to the raw setting, ( D ) our full model which jointly learns shape information and smoothness prior by optimizing  L L \\mathcal{L} caligraphic_L  defined in Sec.  3.2 . We report quantitative results in Table  6  and present the visual comparison in Fig.  6 .",
            "( A ) without using depth or silhouette information already outperforms the baselines in terms of both F1-score and EMD on  chair  and  table  categories, and achieves comparable results on the  lamp  category. Adding silhouettes ( B ) improves the recall, indicating more complete reconstructions. The inclusion of  L S subscript L S \\mathcal{L}_{S} caligraphic_L start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT  helps the network in learning the overall object shapes more effectively. However, despite this improvement, the completion results still display noise and lack the desired smoothness, often characterized by wiggly shape boundaries and points appearing disconnected. From Fig.  6 , it is shown that ( C ) reconstructs smoother surfaces particularly at the planar regions ( e.g.  the back of the chair) and object boundaries, while also mitigating the noise observed in the visual results of ( A ) and ( B ). The two cues are complementary, with the best performance being achieved when combining them. Fig.  6  shows that while ( D ) can complete the point clouds by recovering the overall shape of the objects, it can also reduce the reconstruction noise and produce sharper details."
        ]
    },
    "id_table_7": {
        "caption": "Table 7:  Effect of supervision completeness.  We report the performance of our method w.r.t. number of views used to form the pseudo ground-truth. The completion performance drops significantly as the number of views used to form the ground-truth increases, indicating that geometric priors cannot compensate for the noise accumulated from the measurements anymore.",
        "table": "S4.T9.1.1",
        "footnotes": [
            "",
            "",
            "",
            "",
            "",
            ""
        ],
        "references": [
            "Effect of supervision completeness.  In this study, we investigate the relation between the shape completion performance and the number of views used for supervision. Point clouds from different numbers of views are combined to provide a more complete pseudo ground-truth to the network. Similar to the previous experiments, a single view is used as input. Table  7  shows the results on  chair  category of ScanNet. In general, as the ground-truth incompleteness increases, the ambiguity in how to complete the shape also increases owing to the multimodal nature of the completion task. However, in our experiments, we observe that the completion performance drops significantly as the number of views used to form the ground-truth increases. This indicates that when more noisy views are used for supervision, geometric priors cannot compensate for the accumulated noise coming from inaccurate real-world measurements anymore.",
            "We also provide a visual comparison of pseudo ground-truths generated by combining point clouds from different numbers of views in Fig.  7 . When more views are combined for supervision, the noise from inaccurate real-world measurements accumulates, resulting in disconnected points, non-smooth surfaces and thickened object parts due to non-overlapping point clouds of back-projected views."
        ]
    }
}