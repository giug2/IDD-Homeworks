{
    "S4.T1": {
        "caption": "Table 1. Performance comparison of input embedding in the LEARN framework on the offline dataset",
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T1.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T1.1.1.1.1.1\">Input Embedding</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T1.1.1.1.1.2\">H@50</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T1.1.1.1.1.3\">R@50</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T1.1.1.1.1.4\">H@100</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T1.1.1.1.1.5\">R@100</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T1.1.1.2.1.1\">ID</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.2.1.2\">0.0244</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.2.1.3\">0.0533</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.2.1.4\">0.0370</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T1.1.1.2.1.5\">0.0769</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T1.1.1.3.2.1\">BERT</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.3.2.2\">0.0357</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.3.2.3\">0.0552</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.3.2.4\">0.0576</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T1.1.1.3.2.5\">0.0843</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T1.1.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r\" id=\"S4.T1.1.1.4.3.1\">LLM (Ours)</th>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T1.1.1.4.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.4.3.2.1\">0.0440</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T1.1.1.4.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.4.3.3.1\">0.0610</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T1.1.1.4.3.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.4.3.4.1\">0.0701</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T1.1.1.4.3.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T1.1.1.4.3.5.1\">0.0905</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "To validate the effectiveness of content embeddings as input, we replaced content embeddings with ID embeddings like the traditional recommendation system. As shown in Tab.\u00a01, the content embeddings based on LLM achieved a significant performance improvement, particularly in the H@100 metric, increasing from 0.0370 to 0.0701, representing an enhancement of 89.46%. To further verify the representation of the content embedding, we adopt [CLS] token of BERT <cite class=\"ltx_cite ltx_citemacro_citep\">(Devlin et&#160;al<span class=\"ltx_text\">.</span>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.03988v1#bib.bib8\" title=\"\">2018</a>)</cite> to replace the LLM embedding. Compared to content embeddings generated by BERT, the embeddings generated by LLM improve the performance from 0.0576 to 0.0701. Content embeddings generated by LLM contain a greater amount of information and demonstrate stronger capabilities in expressing textual information about items. We attribute this phenomenon to the extensive text corpus utilized during the LLM pre-training stage, enhancing its feature representation capability.\n(Devlin et\u00a0al., 2018) to replace the LLM embedding. Compared to content embeddings generated by BERT, the embeddings generated by LLM improve the performance from 0.0576 to 0.0701. Content embeddings generated by LLM contain a greater amount of information and demonstrate stronger capabilities in expressing textual information about items. We attribute this phenomenon to the extensive text corpus utilized during the LLM pre-training stage, enhancing its feature representation capability."
        ]
    },
    "S4.T2": {
        "caption": "Table 2. The quantitative metrics results of LLM-based generative recommendation model.",
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T2.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T2.1.1.1.1.1\">Model</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T2.1.1.1.1.2\">LLM Weights</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.1.1.1.1.3\">H@50</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.1.1.1.1.4\">R@50</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.1.1.1.1.5\">H@100</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T2.1.1.1.1.6\">R@100</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.2.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T2.1.1.2.1.1\">Baseline-v1</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T2.1.1.2.1.2\">frozen</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.1.2.1.3\">0.0069</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.1.2.1.4\">0.0154</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.1.2.1.5\">0.0101</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T2.1.1.2.1.6\">0.0210</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.3.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"S4.T2.1.1.3.2.1\">Baseline-v2</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"S4.T2.1.1.3.2.2\">learnable</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.3.2.3\">0.0134</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.3.2.4\">0.0208</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.3.2.5\">0.0180</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T2.1.1.3.2.6\">0.0262</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T2.1.1.4.3\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r\" id=\"S4.T2.1.1.4.3.1\">LEARN (Ours)</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r\" id=\"S4.T2.1.1.4.3.2\">frozen</th>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T2.1.1.4.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.4.3.3.1\">0.0440</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T2.1.1.4.3.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.4.3.4.1\">0.0610</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T2.1.1.4.3.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.4.3.5.1\">0.0701</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T2.1.1.4.3.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T2.1.1.4.3.6.1\">0.0905</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Experiment results are reported in Tab.2. We observed that baseline v1 performed the worst. This can be attributed to the fact that the pre-training data for LLM is sourced from open-world domain text. By directly applying Baseline-v1, which utilizes the output features of LLM with frozen parameters as user embeddings, these embeddings lack collaborative knowledge of the recommendation domain, rendering them unsuitable for recommendation tasks.\nDespite the improvement compared to Baseline-v1 on H@100, the performance of Baseline-v2 remains far from our proposed LEARN method after finetuning LLM on conversational text data. We believe that the domain gap between collaborative and open-world knowledge leads to catastrophic forgetting of open-world knowledge when finetuning LLM on large-scale textualized recommendation data. Particularly, our training data is collected from real-world recommendation scenarios in the industry, where a significant amount of noise exists in recommendation data, exacerbating the catastrophic forgetting phenomenon. This is why the performance of baseline v2 is unsatisfactory."
        ]
    },
    "S4.T3": {
        "caption": "Table 3. Comparison with SOTA methods. Hit rate (H) and NDCG (N) are adopted as the metrics. We report the performance improvement compared with SASRec.",
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T3.1.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt\" id=\"S4.T3.1.1.1.1.1\">Method</th>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T3.1.1.1.1.2\">H@10</td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T3.1.1.1.1.3\">H@50</td>\n<td class=\"ltx_td ltx_align_left ltx_border_tt\" id=\"S4.T3.1.1.1.1.4\">H@200</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.2.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.2.2.1\">SASRec <cite class=\"ltx_cite ltx_citemacro_citep\">(Kang and McAuley, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.03988v1#bib.bib21\" title=\"\">2018</a>)</cite>\n</th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T3.1.1.2.2.2\">0.0306</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T3.1.1.2.2.3\">0.0754</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T3.1.1.2.2.4\">0.1431</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.3.3\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.1.3.3.1\">HSTU <cite class=\"ltx_cite ltx_citemacro_citep\">(Zhai et&#160;al<span class=\"ltx_text\">.</span>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.03988v1#bib.bib44\" title=\"\">2024</a>)</cite>\n</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T3.1.1.3.3.2\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.3.3.2.1\">0.0416</span> (+35.95%)</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T3.1.1.3.3.3\">0.0957 (+26.92%)</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T3.1.1.3.3.4\">0.1735 (+21.24%)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.4.4\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.1.4.4.1\">LEARN (Ours)</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T3.1.1.4.4.2\">0.0407 (+33.01%)</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T3.1.1.4.4.3\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.4.4.3.1\">0.0979</span>(+29.84%)</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T3.1.1.4.4.4\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.4.4.4.1\">0.1874</span> (+30.96%)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.5.5\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.5.5.1\">&#8211;</th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T3.1.1.5.5.2\">N@10</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T3.1.1.5.5.3\">N@50</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T3.1.1.5.5.4\">N@200</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.6.6\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T3.1.1.6.6.1\">SASRec <cite class=\"ltx_cite ltx_citemacro_citep\">(Kang and McAuley, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.03988v1#bib.bib21\" title=\"\">2018</a>)</cite>\n</th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T3.1.1.6.6.2\">0.0164</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T3.1.1.6.6.3\">0.0260</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T3.1.1.6.6.4\">0.0362</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.7.7\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"S4.T3.1.1.7.7.1\">HSTU <cite class=\"ltx_cite ltx_citemacro_citep\">(Zhai et&#160;al<span class=\"ltx_text\">.</span>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.03988v1#bib.bib44\" title=\"\">2024</a>)</cite>\n</th>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T3.1.1.7.7.2\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.7.7.2.1\">0.0227</span> (+38.41%)</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T3.1.1.7.7.3\">0.0344 (+32.31%)</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S4.T3.1.1.7.7.4\">0.0461 (+27.35%)</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T3.1.1.8.8\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\" id=\"S4.T3.1.1.8.8.1\">LEARN (Ours)</th>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T3.1.1.8.8.2\">0.0224 (+36.59%)</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T3.1.1.8.8.3\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.8.8.3.1\">0.0371</span> (+42.69%)</td>\n<td class=\"ltx_td ltx_align_left ltx_border_bb\" id=\"S4.T3.1.1.8.8.4\">\n<span class=\"ltx_text ltx_font_bold\" id=\"S4.T3.1.1.8.8.4.1\">0.0483</span> (+33.43%)</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Considering that our method is designed for practical industrial applications, we conduct comparisons with previous SOTA methods aimed at industrial use. To closely approximate real-world industrial scenarios, we chose the Amazon Book Reviews 2014\u00a0<sup class=\"ltx_note_mark\">1</sup>\n1<sup class=\"ltx_note_mark\">1</sup>\n11https://jmcauley.ucsd.edu/data/amazon/, which comprises 22M reviews of 8M users about 2M books, as the evaluation dataset. To make a fair comparison, we follow the same data processing and evaluation settings as the HSTU <cite class=\"ltx_cite ltx_citemacro_citep\">(Zhai et&#160;al<span class=\"ltx_text\">.</span>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.03988v1#bib.bib44\" title=\"\">2024</a>)</cite>. As shown in Fig.&#160;\n(Zhai et\u00a0al., 2024). As shown in Fig.\u00a03, compared to the SASRec <cite class=\"ltx_cite ltx_citemacro_citep\">(Kang and McAuley, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.03988v1#bib.bib21\" title=\"\">2018</a>)</cite>, we achieve significant performance improvement in all six metrics. Compared to the latest method HSTU \n(Kang and McAuley, 2018), we achieve significant performance improvement in all six metrics. Compared to the latest method HSTU <cite class=\"ltx_cite ltx_citemacro_citep\">(Zhai et&#160;al<span class=\"ltx_text\">.</span>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.03988v1#bib.bib44\" title=\"\">2024</a>)</cite>, we achieve a 2.92% and 9.72% improvement on H@50 and H@200, a 10.38% and 6.08% improvement on N@50 and N@200, while slight low performance is achieved on H@10 and N@10. The reasons why our LEARN and HSTU \n(Zhai et\u00a0al., 2024), we achieve a 2.92% and 9.72% improvement on H@50 and H@200, a 10.38% and 6.08% improvement on N@50 and N@200, while slight low performance is achieved on H@10 and N@10. The reasons why our LEARN and HSTU <cite class=\"ltx_cite ltx_citemacro_citep\">(Zhai et&#160;al<span class=\"ltx_text\">.</span>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.03988v1#bib.bib44\" title=\"\">2024</a>)</cite> perform differently in the top 10, top 50, and top 200 metrics are as follows.\nModels with ID embedding typically capture specific identity information of users or items closely tied to their historical interactions. This method focuses on utilizing historical interaction data, which may yield better predictive outcomes for items that are frequently interacted with, popular, or often engaged by specific user groups. Consequently, for smaller recommendation candidates (such as the top 10), models with ID embedding can more accurately identify items with high relevance. Models with content embeddings focus on the textual descriptions of items. This approach enables the model to understand and recommend items that are content-similar yet may not have been frequently interacted with. This method is particularly effective in larger recommendation lists (such as the top 50 or top 100), as it allows for the exploration of a broader range of items, including those that may receive less user attention but have high content relevance. Compared to SASRec \n(Zhai et\u00a0al., 2024) perform differently in the top 10, top 50, and top 200 metrics are as follows.\nModels with ID embedding typically capture specific identity information of users or items closely tied to their historical interactions. This method focuses on utilizing historical interaction data, which may yield better predictive outcomes for items that are frequently interacted with, popular, or often engaged by specific user groups. Consequently, for smaller recommendation candidates (such as the top 10), models with ID embedding can more accurately identify items with high relevance. Models with content embeddings focus on the textual descriptions of items. This approach enables the model to understand and recommend items that are content-similar yet may not have been frequently interacted with. This method is particularly effective in larger recommendation lists (such as the top 50 or top 100), as it allows for the exploration of a broader range of items, including those that may receive less user attention but have high content relevance. Compared to SASRec <cite class=\"ltx_cite ltx_citemacro_citep\">(Kang and McAuley, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.03988v1#bib.bib21\" title=\"\">2018</a>)</cite> and HSTU \n(Kang and McAuley, 2018) and HSTU <cite class=\"ltx_cite ltx_citemacro_citep\">(Zhai et&#160;al<span class=\"ltx_text\">.</span>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.03988v1#bib.bib44\" title=\"\">2024</a>)</cite> based on ID embeddings, our proposed LEARN shows a significant performance improvement, indicating the effectiveness of our method and the information richness of the content representations generated by LLM.\n(Zhai et\u00a0al., 2024) based on ID embeddings, our proposed LEARN shows a significant performance improvement, indicating the effectiveness of our method and the information richness of the content representations generated by LLM."
        ]
    },
    "S4.T4": {
        "caption": "Table 4. Ablation studies of item tower in the LEARN framework on the offline dataset. Item tower v1 is adopted as the default settings.",
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T4.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T4.1.1.1.1.1\">Item Tower</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T4.1.1.1.1.2\">H@50</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T4.1.1.1.1.3\">R@50</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T4.1.1.1.1.4\">H@100</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T4.1.1.1.1.5\">R@100</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.2.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T4.1.1.2.1.1\">Variant&#160;3</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.2.1.2\">NaN</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.2.1.3\">NaN</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.2.1.4\">NaN</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T4.1.1.2.1.5\">NaN</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.3.2\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\" id=\"S4.T4.1.1.3.2.1\">Variant&#160;2</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.3.2.2\">0.0313</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.3.2.3\">0.0488</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.3.2.4\">0.0505</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T4.1.1.3.2.5\">0.0675</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T4.1.1.4.3\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r\" id=\"S4.T4.1.1.4.3.1\">Variant&#160;1 (Ours)</th>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T4.1.1.4.3.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.4.3.2.1\">0.0440</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T4.1.1.4.3.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.4.3.3.1\">0.0610</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T4.1.1.4.3.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.4.3.4.1\">0.0701</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T4.1.1.4.3.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T4.1.1.4.3.5.1\">0.0905</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Variant 1. As illustrated in Fig.\u00a03(a), the item tower adopts the same architecture and model weights as the user tower. However, instead of processing user history interactions <math alttext=\"U^{hist}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.SSS2.p2.1.m1.1\">\n  <semantics id=\"S3.SS2.SSS2.p2.1.m1.1a\">\n    <msup id=\"S3.SS2.SSS2.p2.1.m1.1.1\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.cmml\">\n      <mi id=\"S3.SS2.SSS2.p2.1.m1.1.1.2\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.2.cmml\">U</mi>\n      <mrow id=\"S3.SS2.SSS2.p2.1.m1.1.1.3\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.cmml\">\n        <mi id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.2\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.2.cmml\">h</mi>\n        <mo id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1.cmml\">&#8290;</mo>\n        <mi id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.3\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.3.cmml\">i</mi>\n        <mo id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1a\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1.cmml\">&#8290;</mo>\n        <mi id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.4\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.4.cmml\">s</mi>\n        <mo id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1b\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1.cmml\">&#8290;</mo>\n        <mi id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.5\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.5.cmml\">t</mi>\n      </mrow>\n    </msup>\n    <annotation-xml encoding=\"MathML-Content\" id=\"S3.SS2.SSS2.p2.1.m1.1b\">\n      <apply id=\"S3.SS2.SSS2.p2.1.m1.1.1.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1\">\n        <csymbol cd=\"ambiguous\" id=\"S3.SS2.SSS2.p2.1.m1.1.1.1.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1\">superscript</csymbol>\n        <ci id=\"S3.SS2.SSS2.p2.1.m1.1.1.2.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.2\">&#119880;</ci>\n        <apply id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3\">\n          <times id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1\"/>\n          <ci id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.2.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.2\">&#8462;</ci>\n          <ci id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.3.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.3\">&#119894;</ci>\n          <ci id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.4.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.4\">&#119904;</ci>\n          <ci id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.5.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.5\">&#119905;</ci>\n        </apply>\n      </apply>\n    </annotation-xml>\n    <annotation encoding=\"application/x-tex\" id=\"S3.SS2.SSS2.p2.1.m1.1c\">U^{hist}</annotation>\n    <annotation encoding=\"application/x-llamapun\" id=\"S3.SS2.SSS2.p2.1.m1.1d\">italic_U start_POSTSUPERSCRIPT italic_h italic_i italic_s italic_t end_POSTSUPERSCRIPT</annotation>\n  </semantics>\n</math>, the item tower utilizes user target interactions \n<semantics id=\"S3.SS2.SSS2.p2.1.m1.1a\">\n  <msup id=\"S3.SS2.SSS2.p2.1.m1.1.1\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.cmml\">\n    <mi id=\"S3.SS2.SSS2.p2.1.m1.1.1.2\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.2.cmml\">U</mi>\n    <mrow id=\"S3.SS2.SSS2.p2.1.m1.1.1.3\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.cmml\">\n      <mi id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.2\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.2.cmml\">h</mi>\n      <mo id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1.cmml\">&#8290;</mo>\n      <mi id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.3\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.3.cmml\">i</mi>\n      <mo id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1a\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1.cmml\">&#8290;</mo>\n      <mi id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.4\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.4.cmml\">s</mi>\n      <mo id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1b\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1.cmml\">&#8290;</mo>\n      <mi id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.5\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.5.cmml\">t</mi>\n    </mrow>\n  </msup>\n  <annotation-xml encoding=\"MathML-Content\" id=\"S3.SS2.SSS2.p2.1.m1.1b\">\n    <apply id=\"S3.SS2.SSS2.p2.1.m1.1.1.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1\">\n      <csymbol cd=\"ambiguous\" id=\"S3.SS2.SSS2.p2.1.m1.1.1.1.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1\">superscript</csymbol>\n      <ci id=\"S3.SS2.SSS2.p2.1.m1.1.1.2.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.2\">&#119880;</ci>\n      <apply id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3\">\n        <times id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1\"/>\n        <ci id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.2.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.2\">&#8462;</ci>\n        <ci id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.3.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.3\">&#119894;</ci>\n        <ci id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.4.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.4\">&#119904;</ci>\n        <ci id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.5.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.5\">&#119905;</ci>\n      </apply>\n    </apply>\n  </annotation-xml>\n  <annotation encoding=\"application/x-tex\" id=\"S3.SS2.SSS2.p2.1.m1.1c\">U^{hist}</annotation>\n  <annotation encoding=\"application/x-llamapun\" id=\"S3.SS2.SSS2.p2.1.m1.1d\">italic_U start_POSTSUPERSCRIPT italic_h italic_i italic_s italic_t end_POSTSUPERSCRIPT</annotation>\n</semantics>\n<msup id=\"S3.SS2.SSS2.p2.1.m1.1.1\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.cmml\">\n  <mi id=\"S3.SS2.SSS2.p2.1.m1.1.1.2\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.2.cmml\">U</mi>\n  <mrow id=\"S3.SS2.SSS2.p2.1.m1.1.1.3\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.cmml\">\n    <mi id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.2\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.2.cmml\">h</mi>\n    <mo id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1.cmml\">&#8290;</mo>\n    <mi id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.3\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.3.cmml\">i</mi>\n    <mo id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1a\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1.cmml\">&#8290;</mo>\n    <mi id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.4\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.4.cmml\">s</mi>\n    <mo id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1b\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1.cmml\">&#8290;</mo>\n    <mi id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.5\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.5.cmml\">t</mi>\n  </mrow>\n</msup>\n<mi id=\"S3.SS2.SSS2.p2.1.m1.1.1.2\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.2.cmml\">U</mi>\nU<mrow id=\"S3.SS2.SSS2.p2.1.m1.1.1.3\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.cmml\">\n  <mi id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.2\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.2.cmml\">h</mi>\n  <mo id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1.cmml\">&#8290;</mo>\n  <mi id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.3\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.3.cmml\">i</mi>\n  <mo id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1a\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1.cmml\">&#8290;</mo>\n  <mi id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.4\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.4.cmml\">s</mi>\n  <mo id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1b\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1.cmml\">&#8290;</mo>\n  <mi id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.5\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.5.cmml\">t</mi>\n</mrow>\n<mi id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.2\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.2.cmml\">h</mi>\nh<mo id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1.cmml\">&#8290;</mo>\n\u2062<mi id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.3\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.3.cmml\">i</mi>\ni<mo id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1a\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1.cmml\">&#8290;</mo>\n\u2062<mi id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.4\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.4.cmml\">s</mi>\ns<mo id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1b\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1.cmml\">&#8290;</mo>\n\u2062<mi id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.5\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.5.cmml\">t</mi>\nt<annotation-xml encoding=\"MathML-Content\" id=\"S3.SS2.SSS2.p2.1.m1.1b\">\n  <apply id=\"S3.SS2.SSS2.p2.1.m1.1.1.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1\">\n    <csymbol cd=\"ambiguous\" id=\"S3.SS2.SSS2.p2.1.m1.1.1.1.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1\">superscript</csymbol>\n    <ci id=\"S3.SS2.SSS2.p2.1.m1.1.1.2.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.2\">&#119880;</ci>\n    <apply id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3\">\n      <times id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1\"/>\n      <ci id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.2.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.2\">&#8462;</ci>\n      <ci id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.3.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.3\">&#119894;</ci>\n      <ci id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.4.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.4\">&#119904;</ci>\n      <ci id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.5.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.5\">&#119905;</ci>\n    </apply>\n  </apply>\n</annotation-xml>\n<apply id=\"S3.SS2.SSS2.p2.1.m1.1.1.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1\">\n  <csymbol cd=\"ambiguous\" id=\"S3.SS2.SSS2.p2.1.m1.1.1.1.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1\">superscript</csymbol>\n  <ci id=\"S3.SS2.SSS2.p2.1.m1.1.1.2.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.2\">&#119880;</ci>\n  <apply id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3\">\n    <times id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1\"/>\n    <ci id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.2.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.2\">&#8462;</ci>\n    <ci id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.3.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.3\">&#119894;</ci>\n    <ci id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.4.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.4\">&#119904;</ci>\n    <ci id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.5.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.5\">&#119905;</ci>\n  </apply>\n</apply>\n<csymbol cd=\"ambiguous\" id=\"S3.SS2.SSS2.p2.1.m1.1.1.1.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1\">superscript</csymbol>\nsuperscript<ci id=\"S3.SS2.SSS2.p2.1.m1.1.1.2.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.2\">&#119880;</ci>\n\ud835\udc48<apply id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3\">\n  <times id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1\"/>\n  <ci id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.2.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.2\">&#8462;</ci>\n  <ci id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.3.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.3\">&#119894;</ci>\n  <ci id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.4.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.4\">&#119904;</ci>\n  <ci id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.5.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.5\">&#119905;</ci>\n</apply>\n<times id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.1\"/>\n<ci id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.2.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.2\">&#8462;</ci>\n\u210e<ci id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.3.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.3\">&#119894;</ci>\n\ud835\udc56<ci id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.4.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.4\">&#119904;</ci>\n\ud835\udc60<ci id=\"S3.SS2.SSS2.p2.1.m1.1.1.3.5.cmml\" xref=\"S3.SS2.SSS2.p2.1.m1.1.1.3.5\">&#119905;</ci>\n\ud835\udc61<annotation encoding=\"application/x-tex\" id=\"S3.SS2.SSS2.p2.1.m1.1c\">U^{hist}</annotation>\nU^{hist}<annotation encoding=\"application/x-llamapun\" id=\"S3.SS2.SSS2.p2.1.m1.1d\">italic_U start_POSTSUPERSCRIPT italic_h italic_i italic_s italic_t end_POSTSUPERSCRIPT</annotation>\nitalic_U start_POSTSUPERSCRIPT italic_h italic_i italic_s italic_t end_POSTSUPERSCRIPT, the item tower utilizes user target interactions <math alttext=\"U^{tar}\" class=\"ltx_Math\" display=\"inline\" id=\"S3.SS2.SSS2.p2.2.m2.1\">\n  <semantics id=\"S3.SS2.SSS2.p2.2.m2.1a\">\n    <msup id=\"S3.SS2.SSS2.p2.2.m2.1.1\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.cmml\">\n      <mi id=\"S3.SS2.SSS2.p2.2.m2.1.1.2\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.2.cmml\">U</mi>\n      <mrow id=\"S3.SS2.SSS2.p2.2.m2.1.1.3\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.cmml\">\n        <mi id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.2\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.2.cmml\">t</mi>\n        <mo id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1.cmml\">&#8290;</mo>\n        <mi id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.3\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.3.cmml\">a</mi>\n        <mo id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1a\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1.cmml\">&#8290;</mo>\n        <mi id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.4\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.4.cmml\">r</mi>\n      </mrow>\n    </msup>\n    <annotation-xml encoding=\"MathML-Content\" id=\"S3.SS2.SSS2.p2.2.m2.1b\">\n      <apply id=\"S3.SS2.SSS2.p2.2.m2.1.1.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1\">\n        <csymbol cd=\"ambiguous\" id=\"S3.SS2.SSS2.p2.2.m2.1.1.1.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1\">superscript</csymbol>\n        <ci id=\"S3.SS2.SSS2.p2.2.m2.1.1.2.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.2\">&#119880;</ci>\n        <apply id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3\">\n          <times id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1\"/>\n          <ci id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.2.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.2\">&#119905;</ci>\n          <ci id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.3.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.3\">&#119886;</ci>\n          <ci id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.4.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.4\">&#119903;</ci>\n        </apply>\n      </apply>\n    </annotation-xml>\n    <annotation encoding=\"application/x-tex\" id=\"S3.SS2.SSS2.p2.2.m2.1c\">U^{tar}</annotation>\n    <annotation encoding=\"application/x-llamapun\" id=\"S3.SS2.SSS2.p2.2.m2.1d\">italic_U start_POSTSUPERSCRIPT italic_t italic_a italic_r end_POSTSUPERSCRIPT</annotation>\n  </semantics>\n</math> as inputs. This approach enhances the alignment between user and item embeddings by employing the same causal attention mechanism used in the user tower, effectively improving the relevance of recommendations. Due to the superior performance in Tab.&#160;\n<semantics id=\"S3.SS2.SSS2.p2.2.m2.1a\">\n  <msup id=\"S3.SS2.SSS2.p2.2.m2.1.1\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.cmml\">\n    <mi id=\"S3.SS2.SSS2.p2.2.m2.1.1.2\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.2.cmml\">U</mi>\n    <mrow id=\"S3.SS2.SSS2.p2.2.m2.1.1.3\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.cmml\">\n      <mi id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.2\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.2.cmml\">t</mi>\n      <mo id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1.cmml\">&#8290;</mo>\n      <mi id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.3\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.3.cmml\">a</mi>\n      <mo id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1a\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1.cmml\">&#8290;</mo>\n      <mi id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.4\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.4.cmml\">r</mi>\n    </mrow>\n  </msup>\n  <annotation-xml encoding=\"MathML-Content\" id=\"S3.SS2.SSS2.p2.2.m2.1b\">\n    <apply id=\"S3.SS2.SSS2.p2.2.m2.1.1.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1\">\n      <csymbol cd=\"ambiguous\" id=\"S3.SS2.SSS2.p2.2.m2.1.1.1.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1\">superscript</csymbol>\n      <ci id=\"S3.SS2.SSS2.p2.2.m2.1.1.2.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.2\">&#119880;</ci>\n      <apply id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3\">\n        <times id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1\"/>\n        <ci id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.2.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.2\">&#119905;</ci>\n        <ci id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.3.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.3\">&#119886;</ci>\n        <ci id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.4.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.4\">&#119903;</ci>\n      </apply>\n    </apply>\n  </annotation-xml>\n  <annotation encoding=\"application/x-tex\" id=\"S3.SS2.SSS2.p2.2.m2.1c\">U^{tar}</annotation>\n  <annotation encoding=\"application/x-llamapun\" id=\"S3.SS2.SSS2.p2.2.m2.1d\">italic_U start_POSTSUPERSCRIPT italic_t italic_a italic_r end_POSTSUPERSCRIPT</annotation>\n</semantics>\n<msup id=\"S3.SS2.SSS2.p2.2.m2.1.1\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.cmml\">\n  <mi id=\"S3.SS2.SSS2.p2.2.m2.1.1.2\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.2.cmml\">U</mi>\n  <mrow id=\"S3.SS2.SSS2.p2.2.m2.1.1.3\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.cmml\">\n    <mi id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.2\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.2.cmml\">t</mi>\n    <mo id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1.cmml\">&#8290;</mo>\n    <mi id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.3\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.3.cmml\">a</mi>\n    <mo id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1a\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1.cmml\">&#8290;</mo>\n    <mi id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.4\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.4.cmml\">r</mi>\n  </mrow>\n</msup>\n<mi id=\"S3.SS2.SSS2.p2.2.m2.1.1.2\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.2.cmml\">U</mi>\nU<mrow id=\"S3.SS2.SSS2.p2.2.m2.1.1.3\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.cmml\">\n  <mi id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.2\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.2.cmml\">t</mi>\n  <mo id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1.cmml\">&#8290;</mo>\n  <mi id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.3\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.3.cmml\">a</mi>\n  <mo id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1a\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1.cmml\">&#8290;</mo>\n  <mi id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.4\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.4.cmml\">r</mi>\n</mrow>\n<mi id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.2\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.2.cmml\">t</mi>\nt<mo id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1.cmml\">&#8290;</mo>\n\u2062<mi id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.3\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.3.cmml\">a</mi>\na<mo id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1a\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1.cmml\">&#8290;</mo>\n\u2062<mi id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.4\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.4.cmml\">r</mi>\nr<annotation-xml encoding=\"MathML-Content\" id=\"S3.SS2.SSS2.p2.2.m2.1b\">\n  <apply id=\"S3.SS2.SSS2.p2.2.m2.1.1.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1\">\n    <csymbol cd=\"ambiguous\" id=\"S3.SS2.SSS2.p2.2.m2.1.1.1.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1\">superscript</csymbol>\n    <ci id=\"S3.SS2.SSS2.p2.2.m2.1.1.2.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.2\">&#119880;</ci>\n    <apply id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3\">\n      <times id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1\"/>\n      <ci id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.2.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.2\">&#119905;</ci>\n      <ci id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.3.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.3\">&#119886;</ci>\n      <ci id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.4.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.4\">&#119903;</ci>\n    </apply>\n  </apply>\n</annotation-xml>\n<apply id=\"S3.SS2.SSS2.p2.2.m2.1.1.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1\">\n  <csymbol cd=\"ambiguous\" id=\"S3.SS2.SSS2.p2.2.m2.1.1.1.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1\">superscript</csymbol>\n  <ci id=\"S3.SS2.SSS2.p2.2.m2.1.1.2.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.2\">&#119880;</ci>\n  <apply id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3\">\n    <times id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1\"/>\n    <ci id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.2.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.2\">&#119905;</ci>\n    <ci id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.3.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.3\">&#119886;</ci>\n    <ci id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.4.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.4\">&#119903;</ci>\n  </apply>\n</apply>\n<csymbol cd=\"ambiguous\" id=\"S3.SS2.SSS2.p2.2.m2.1.1.1.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1\">superscript</csymbol>\nsuperscript<ci id=\"S3.SS2.SSS2.p2.2.m2.1.1.2.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.2\">&#119880;</ci>\n\ud835\udc48<apply id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3\">\n  <times id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1\"/>\n  <ci id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.2.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.2\">&#119905;</ci>\n  <ci id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.3.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.3\">&#119886;</ci>\n  <ci id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.4.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.4\">&#119903;</ci>\n</apply>\n<times id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.1\"/>\n<ci id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.2.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.2\">&#119905;</ci>\n\ud835\udc61<ci id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.3.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.3\">&#119886;</ci>\n\ud835\udc4e<ci id=\"S3.SS2.SSS2.p2.2.m2.1.1.3.4.cmml\" xref=\"S3.SS2.SSS2.p2.2.m2.1.1.3.4\">&#119903;</ci>\n\ud835\udc5f<annotation encoding=\"application/x-tex\" id=\"S3.SS2.SSS2.p2.2.m2.1c\">U^{tar}</annotation>\nU^{tar}<annotation encoding=\"application/x-llamapun\" id=\"S3.SS2.SSS2.p2.2.m2.1d\">italic_U start_POSTSUPERSCRIPT italic_t italic_a italic_r end_POSTSUPERSCRIPT</annotation>\nitalic_U start_POSTSUPERSCRIPT italic_t italic_a italic_r end_POSTSUPERSCRIPT as inputs. This approach enhances the alignment between user and item embeddings by employing the same causal attention mechanism used in the user tower, effectively improving the relevance of recommendations. Due to the superior performance in Tab.\u00a04, Variant 1 is adopted as the default setting.",
            "We design three variants to verify the necessity of our item tower structure. Experimental results are presented in Tab.\u00a04. Variant 3, which directly utilizes content embeddings from LLMs as item embeddings, suffers from model non-convergence. This is attributed to significant architectural differences between the user and item towers, as well as the domain gap between the LLM-generated content embeddings and the item embeddings required for recommendation tasks. In contrast, while Variant 2 with the self-attention mechanism performs less effectively, Variant 1, which incorporates the causal attention mechanism, notably enhances the item embedding representation by integrating features from previous item embeddings.\nConsequently, we have selected Variant 1, depicted in Fig.\u00a03(a), as the standard architecture for our LEARN framework."
        ]
    },
    "S4.T5": {
        "caption": "Table 5. Ablation studies of the PCH module.",
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T5.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" id=\"S4.T5.1.1.1.1.1\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T5.1.1.1.1.1.1\">\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.1.1.1.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T5.1.1.1.1.1.1.1.1\">Backbone</td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T5.1.1.1.1.2\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T5.1.1.1.1.2.1\">\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.1.1.2.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T5.1.1.1.1.2.1.1.1\">Parameter</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.1.1.2.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T5.1.1.1.1.2.1.2.1\">Initialization</td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T5.1.1.1.1.3\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T5.1.1.1.1.3.1\">\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.1.1.3.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T5.1.1.1.1.3.1.1.1\">Training</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.1.1.3.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T5.1.1.1.1.3.1.2.1\">mode</td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" id=\"S4.T5.1.1.1.1.4\">\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T5.1.1.1.1.4.1\">\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.1.1.4.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T5.1.1.1.1.4.1.1.1\">Trainable</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.1.1.4.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T5.1.1.1.1.4.1.2.1\">parameters</td>\n</tr>\n</table>\n</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T5.1.1.1.1.5\">H@100</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" id=\"S4.T5.1.1.1.1.6\">R@100</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.2.1\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.1.1.2.1.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S4.T5.1.1.2.1.1.1\">LLM</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.1.1.2.1.2\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S4.T5.1.1.2.1.2.1\">Pre-train</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.1.1.2.1.3\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S4.T5.1.1.2.1.3.1\">LoRA</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S4.T5.1.1.2.1.4\">134M</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.1.1.2.1.5\">0.0376</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T5.1.1.2.1.6\">0.0560</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.3.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T5.1.1.3.2.1\">286M</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.3.2.2\">0.0504</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.3.2.3\">0.0709</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.4.3\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S4.T5.1.1.4.3.1\">572M</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.4.3.2\">0.0513</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T5.1.1.4.3.3\">0.0720</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.5.4\">\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T5.1.1.5.4.1\">Transformer</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T5.1.1.5.4.2\">Random Init.</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T5.1.1.5.4.3\">Finetuning</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" id=\"S4.T5.1.1.5.4.4\">100M</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T5.1.1.5.4.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.1.5.4.5.1\">0.0701</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" id=\"S4.T5.1.1.5.4.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S4.T5.1.1.5.4.6.1\">0.0905</span></td>\n</tr>\n</tbody>\n</table>\n\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T5.1.1.1.1.1.1\">\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.1.1.1.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T5.1.1.1.1.1.1.1.1\">Backbone</td>\n</tr>\n</table>\n\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T5.1.1.1.1.2.1\">\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.1.1.2.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T5.1.1.1.1.2.1.1.1\">Parameter</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.1.1.2.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T5.1.1.1.1.2.1.2.1\">Initialization</td>\n</tr>\n</table>\n\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T5.1.1.1.1.3.1\">\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.1.1.3.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T5.1.1.1.1.3.1.1.1\">Training</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.1.1.3.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T5.1.1.1.1.3.1.2.1\">mode</td>\n</tr>\n</table>\n\n<table class=\"ltx_tabular ltx_align_middle\" id=\"S4.T5.1.1.1.1.4.1\">\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.1.1.4.1.1\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T5.1.1.1.1.4.1.1.1\">Trainable</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T5.1.1.1.1.4.1.2\">\n<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S4.T5.1.1.1.1.4.1.2.1\">parameters</td>\n</tr>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "Given extensive world knowledge and superior abilities of LLM in text comprehension and common-sense reasoning, we attempted to replace the transformer layers in the PCH module in Fig.\u00a03 with LLM to further explore its utilization. We finetune the LLM with LoRA <cite class=\"ltx_cite ltx_citemacro_citep\">(Hu et&#160;al<span class=\"ltx_text\">.</span>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.03988v1#bib.bib20\" title=\"\">2021</a>)</cite> and make different LoRA \n(Hu et\u00a0al., 2021) and make different LoRA <cite class=\"ltx_cite ltx_citemacro_citep\">(Hu et&#160;al<span class=\"ltx_text\">.</span>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.03988v1#bib.bib20\" title=\"\">2021</a>)</cite> settings to change the amount of trainable parameters. The experiment results are shown in Tab.&#160;\n(Hu et\u00a0al., 2021) settings to change the amount of trainable parameters. The experiment results are shown in Tab.\u00a05. As the number of trainable parameters increased from 134M to 572M, the performance of finetuning LLM using LoRA improved from 0.0376 to 0.0513, representing a 36.4 % enhancement. However, this performance still exhibits a significant gap compared to using transformer layers as the backbone, which is trained from scratch. The analysis of this discrepancy is as follows. LoRA <cite class=\"ltx_cite ltx_citemacro_citep\">(Hu et&#160;al<span class=\"ltx_text\">.</span>, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2405.03988v1#bib.bib20\" title=\"\">2021</a>)</cite> introduces additional trainable parameters to generate new features, which are combined with the features obtained from the original parameters to serve as the final feature for the LoRA finetuning model. Consequently, the model&#8217;s output feature is a mixture of the original features trained in the open-world domain and the LoRA features trained in the recommendation domain. Additionally, the original features dominate because the LLM has more frozen parameters compared to the trainable LoRA parameters.\nHowever, a substantial domain gap exists between the open-world knowledge embedded in LLM&#8217;s original pretrained parameters and the collaborative knowledge in LoRA parameters. We conclude this mixed feature is inferior for recommendation tasks.\n(Hu et\u00a0al., 2021) introduces additional trainable parameters to generate new features, which are combined with the features obtained from the original parameters to serve as the final feature for the LoRA finetuning model. Consequently, the model\u2019s output feature is a mixture of the original features trained in the open-world domain and the LoRA features trained in the recommendation domain. Additionally, the original features dominate because the LLM has more frozen parameters compared to the trainable LoRA parameters.\nHowever, a substantial domain gap exists between the open-world knowledge embedded in LLM\u2019s original pretrained parameters and the collaborative knowledge in LoRA parameters. We conclude this mixed feature is inferior for recommendation tasks."
        ]
    },
    "S4.T6": {
        "caption": "Table 6. The AUC results on KuaiShou App data.",
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T6.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T6.1.1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T6.1.1.1.1.1\">Method</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S4.T6.1.1.1.1.2\">UAUC</th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" id=\"S4.T6.1.1.1.1.3\">WUAUC</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T6.1.1.2.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T6.1.1.2.1.1\">Baseline</th>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T6.1.1.2.1.2\">0.6885</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S4.T6.1.1.2.1.3\">0.7002</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T6.1.1.3.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r\" id=\"S4.T6.1.1.3.2.1\">LEARN (Ours)</th>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T6.1.1.3.2.2\">0.6969 (+0.84pp)</td>\n<td class=\"ltx_td ltx_align_left ltx_border_b\" id=\"S4.T6.1.1.3.2.3\">0.7078 (+0.76pp)</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "As depicted in Tab.\u00a06, compared to the baseline model, our method achieves improvements of 0.84 percentage points (pp) and 0.76pp in UAUC and WUAUC, respectively. We hypothesize that the observed improvements in UAUC and WUAUC can be attributed to the superior generalization capabilities of the LEARN framework, which effectively captures the interests of long-tail users. To validate this hypothesis, we have implemented a more comprehensive experimental analysis through online A/B testing."
        ]
    },
    "S4.T7": {
        "caption": "Table 7. A/B test results for different user and item types. \u201dProportion\u201d indicates the percentage of users (items) within each category, relative to the total number of users (items).",
        "table": "<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\" id=\"S4.T7.1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S4.T7.1.1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T7.1.1.1.1.1\">Level</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T7.1.1.1.1.2\">Type</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T7.1.1.1.1.3\">Proportion</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T7.1.1.1.1.4\">Revenue</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" id=\"S4.T7.1.1.1.1.5\">AUC</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S4.T7.1.1.2.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T7.1.1.2.1.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S4.T7.1.1.2.1.1.1\">User</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T7.1.1.2.1.2\">cold-start</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T7.1.1.2.1.3\">7.16%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T7.1.1.2.1.4\">+1.56%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T7.1.1.2.1.5\">+0.17pp</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.1.1.3.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"S4.T7.1.1.3.2.1\">long-tail</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.3.2.2\">27.54%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.3.2.3\">+5.79%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.3.2.4\">+0.68pp</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.1.1.4.3\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"S4.T7.1.1.4.3.1\">others</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.4.3.2\">65.30%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.4.3.3\">+0.32%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.4.3.4\">+0.021pp</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.1.1.5.4\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t\" id=\"S4.T7.1.1.5.4.1\" rowspan=\"3\"><span class=\"ltx_text\" id=\"S4.T7.1.1.5.4.1.1\">Item</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S4.T7.1.1.5.4.2\">cold-start</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T7.1.1.5.4.3\">3.15%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T7.1.1.5.4.4\">+8.77%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S4.T7.1.1.5.4.5\">+0.29pp</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.1.1.6.5\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"S4.T7.1.1.6.5.1\">long-tail</th>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.6.5.2\">26.47%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.6.5.3\">+4.63%</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S4.T7.1.1.6.5.4\">+0.21pp</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S4.T7.1.1.7.6\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r\" id=\"S4.T7.1.1.7.6.1\">others</th>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T7.1.1.7.6.2\">70.38%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T7.1.1.7.6.3\">+0.35%</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\" id=\"S4.T7.1.1.7.6.4\">+0.01pp</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "As illustrated in Tab.\u00a07, we categorize users based on their interaction data over the past six months, including product clicks, impressions, and purchase frequencies. Specifically, users with no recorded interactions are identified as cold-start users, those with 1 to 35 interactions are classified as long-tail users, and those with more than 35 interactions are grouped as others. Our results indicate significant performance enhancements by our proposed LEARN, especially among the cold-start and long-tail user segments.",
            "We also categorize products into three tiers based on their purchase history: Cold-start products, which have no prior purchases; Long-tail products, purchased no more than 30 times in the past week; Other products, purchased more than 30 times during the same timeframe. As depicted in Tab.\u00a07, our proposed method significantly improves revenue and AUC performance for cold-start and long-tail products. These enhancements are attributed to the robust representations LEARN generates for products with sparse purchase histories."
        ]
    }
}