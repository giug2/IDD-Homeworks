{
    "PAPER'S NUMBER OF TABLES": 5,
    "S5.T1": {
        "caption": "Table 1. Performance of different classifiers under three different settings.",
        "table": "<table id=\"S5.T1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t\"></th>\n<td id=\"S5.T1.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">XGBoost</td>\n<td id=\"S5.T1.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">SVM</td>\n<td id=\"S5.T1.1.1.1.4\" class=\"ltx_td ltx_align_left ltx_border_t\">LR</td>\n<td id=\"S5.T1.1.1.1.5\" class=\"ltx_td ltx_align_left ltx_border_t\">MLP</td>\n</tr>\n<tr id=\"S5.T1.1.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.2.2.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t\"></th>\n<td id=\"S5.T1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"background-color:#ECECEC;\" colspan=\"4\"><span id=\"S5.T1.1.2.2.2.1\" class=\"ltx_text\" style=\"background-color:#ECECEC;\">Centralized setting</span></td>\n</tr>\n<tr id=\"S5.T1.1.3.3\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Precision</th>\n<td id=\"S5.T1.1.3.3.2\" class=\"ltx_td ltx_align_left ltx_border_t\">0.97</td>\n<td id=\"S5.T1.1.3.3.3\" class=\"ltx_td ltx_align_left ltx_border_t\">0.50</td>\n<td id=\"S5.T1.1.3.3.4\" class=\"ltx_td ltx_align_left ltx_border_t\">0.97</td>\n<td id=\"S5.T1.1.3.3.5\" class=\"ltx_td ltx_align_left ltx_border_t\">0.99</td>\n</tr>\n<tr id=\"S5.T1.1.4.4\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Recall</th>\n<td id=\"S5.T1.1.4.4.2\" class=\"ltx_td ltx_align_left\">0.79</td>\n<td id=\"S5.T1.1.4.4.3\" class=\"ltx_td ltx_align_left\">0.46</td>\n<td id=\"S5.T1.1.4.4.4\" class=\"ltx_td ltx_align_left\">0.61</td>\n<td id=\"S5.T1.1.4.4.5\" class=\"ltx_td ltx_align_left\">0.67</td>\n</tr>\n<tr id=\"S5.T1.1.5.5\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">F1</th>\n<td id=\"S5.T1.1.5.5.2\" class=\"ltx_td ltx_align_left\">0.86</td>\n<td id=\"S5.T1.1.5.5.3\" class=\"ltx_td ltx_align_left\">0.39</td>\n<td id=\"S5.T1.1.5.5.4\" class=\"ltx_td ltx_align_left\">0.68</td>\n<td id=\"S5.T1.1.5.5.5\" class=\"ltx_td ltx_align_left\">0.76</td>\n</tr>\n<tr id=\"S5.T1.1.6.6\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">AUCPR</th>\n<td id=\"S5.T1.1.6.6.2\" class=\"ltx_td ltx_align_left\">0.7037</td>\n<td id=\"S5.T1.1.6.6.3\" class=\"ltx_td ltx_align_left\">0.0011</td>\n<td id=\"S5.T1.1.6.6.4\" class=\"ltx_td ltx_align_left\">0.2976</td>\n<td id=\"S5.T1.1.6.6.5\" class=\"ltx_td ltx_align_left\">0.5608</td>\n</tr>\n<tr id=\"S5.T1.1.7.7\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.7.7.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t\"></th>\n<td id=\"S5.T1.1.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"background-color:#ECECEC;\" colspan=\"4\"><span id=\"S5.T1.1.7.7.2.1\" class=\"ltx_text\" style=\"background-color:#ECECEC;\">Vanilla HyFL</span></td>\n</tr>\n<tr id=\"S5.T1.1.8.8\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.8.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Precision</th>\n<td id=\"S5.T1.1.8.8.2\" class=\"ltx_td ltx_align_left ltx_border_t\">0.98</td>\n<td id=\"S5.T1.1.8.8.3\" class=\"ltx_td ltx_align_left ltx_border_t\">0.50</td>\n<td id=\"S5.T1.1.8.8.4\" class=\"ltx_td ltx_align_left ltx_border_t\">0.97</td>\n<td id=\"S5.T1.1.8.8.5\" class=\"ltx_td ltx_align_left ltx_border_t\">0.98</td>\n</tr>\n<tr id=\"S5.T1.1.9.9\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.9.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Recall</th>\n<td id=\"S5.T1.1.9.9.2\" class=\"ltx_td ltx_align_left\">0.79</td>\n<td id=\"S5.T1.1.9.9.3\" class=\"ltx_td ltx_align_left\">0.37</td>\n<td id=\"S5.T1.1.9.9.4\" class=\"ltx_td ltx_align_left\">0.61</td>\n<td id=\"S5.T1.1.9.9.5\" class=\"ltx_td ltx_align_left\">0.71</td>\n</tr>\n<tr id=\"S5.T1.1.10.10\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.10.10.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">F1</th>\n<td id=\"S5.T1.1.10.10.2\" class=\"ltx_td ltx_align_left\">0.86</td>\n<td id=\"S5.T1.1.10.10.3\" class=\"ltx_td ltx_align_left\">0.13</td>\n<td id=\"S5.T1.1.10.10.4\" class=\"ltx_td ltx_align_left\">0.68</td>\n<td id=\"S5.T1.1.10.10.5\" class=\"ltx_td ltx_align_left\">0.79</td>\n</tr>\n<tr id=\"S5.T1.1.11.11\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.11.11.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">AUCPR</th>\n<td id=\"S5.T1.1.11.11.2\" class=\"ltx_td ltx_align_left\">0.7075</td>\n<td id=\"S5.T1.1.11.11.3\" class=\"ltx_td ltx_align_left\">0.0009</td>\n<td id=\"S5.T1.1.11.11.4\" class=\"ltx_td ltx_align_left\">0.2977</td>\n<td id=\"S5.T1.1.11.11.5\" class=\"ltx_td ltx_align_left\">0.5392</td>\n</tr>\n<tr id=\"S5.T1.1.12.12\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.12.12.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t\"></th>\n<td id=\"S5.T1.1.12.12.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"background-color:#ECECEC;\" colspan=\"4\"><span id=\"S5.T1.1.12.12.2.1\" class=\"ltx_text\" style=\"background-color:#ECECEC;\">HyFL</span></td>\n</tr>\n<tr id=\"S5.T1.1.13.13\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.13.13.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Precision</th>\n<td id=\"S5.T1.1.13.13.2\" class=\"ltx_td ltx_align_left ltx_border_t\">0.98</td>\n<td id=\"S5.T1.1.13.13.3\" class=\"ltx_td ltx_align_left ltx_border_t\">0.50</td>\n<td id=\"S5.T1.1.13.13.4\" class=\"ltx_td ltx_align_left ltx_border_t\">0.97</td>\n<td id=\"S5.T1.1.13.13.5\" class=\"ltx_td ltx_align_left ltx_border_t\">0.95</td>\n</tr>\n<tr id=\"S5.T1.1.14.14\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.14.14.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Recall</th>\n<td id=\"S5.T1.1.14.14.2\" class=\"ltx_td ltx_align_left\">0.76</td>\n<td id=\"S5.T1.1.14.14.3\" class=\"ltx_td ltx_align_left\">0.37</td>\n<td id=\"S5.T1.1.14.14.4\" class=\"ltx_td ltx_align_left\">0.61</td>\n<td id=\"S5.T1.1.14.14.5\" class=\"ltx_td ltx_align_left\">0.70</td>\n</tr>\n<tr id=\"S5.T1.1.15.15\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.15.15.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">F1</th>\n<td id=\"S5.T1.1.15.15.2\" class=\"ltx_td ltx_align_left\">0.83</td>\n<td id=\"S5.T1.1.15.15.3\" class=\"ltx_td ltx_align_left\">0.13</td>\n<td id=\"S5.T1.1.15.15.4\" class=\"ltx_td ltx_align_left\">0.68</td>\n<td id=\"S5.T1.1.15.15.5\" class=\"ltx_td ltx_align_left\">0.78</td>\n</tr>\n<tr id=\"S5.T1.1.16.16\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.16.16.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r\">AUCPR</th>\n<td id=\"S5.T1.1.16.16.2\" class=\"ltx_td ltx_align_left ltx_border_b\">0.6839</td>\n<td id=\"S5.T1.1.16.16.3\" class=\"ltx_td ltx_align_left ltx_border_b\">0.0009</td>\n<td id=\"S5.T1.1.16.16.4\" class=\"ltx_td ltx_align_left ltx_border_b\">0.2975</td>\n<td id=\"S5.T1.1.16.16.5\" class=\"ltx_td ltx_align_left ltx_border_b\">0.5438</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "The results for three settings are shown in Table 1.\nThe performance of SVM is the worst across the three settings, which implies that the linear classification model is not suitable for such a task with tabular data, because such data is not linearly separable.\nSimilarly, although LR has some non-linear properties from the sigmoid function, it still cannot achieve satisfactory performance due to the linear combination of features before the sigmoid function.\nOn the other hand, MLP shows great improvement with the support of strong power to extract useful features from raw data.\nSurprisingly, XGBoost achieves the best performance across all three settings.\nOne possible reason is that as the number of estimators in XGBoost increases, the complex relationship between features can be extracted.\nIn that case, XGBoost can also construct a strong non-linear map from features to the predicted label just like MLP.",
            "From the perspective of different frameworks, we can observe that the vanilla setting has a similar performance to the centralized setting as shown in Table 1.\nNote that the vanilla setting has the same framework backbone as HyFL setting, except for the noise injection and encryption.\nBased on this perspective, the similar performance between vanilla and the centralized setting implies that our framework backbone is effective as the centralized setting.\nTable 1 shows that the noise indeed decreases the performance, but it still presents a reliable utility with a relatively high AUCPR.\nWe further analyze the impact of noise variance in Sec 5.3.3."
        ]
    },
    "S5.T2": {
        "caption": "Table 2. Evaluation of imbalance-target methods.",
        "table": "<table id=\"S5.T2.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T2.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\"></th>\n<th id=\"S5.T2.1.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">RandomUnder</th>\n<th id=\"S5.T2.1.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">RandomOver</th>\n<th id=\"S5.T2.1.1.1.1.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">SMOTE</th>\n<th id=\"S5.T2.1.1.1.1.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">Reweight</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T2.1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Precision</th>\n<td id=\"S5.T2.1.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">0.55</td>\n<td id=\"S5.T2.1.1.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">0.51</td>\n<td id=\"S5.T2.1.1.2.1.4\" class=\"ltx_td ltx_align_left ltx_border_t\">0.51</td>\n<td id=\"S5.T2.1.1.2.1.5\" class=\"ltx_td ltx_align_left ltx_border_t\">0.51</td>\n</tr>\n<tr id=\"S5.T2.1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Recall</th>\n<td id=\"S5.T2.1.1.3.2.2\" class=\"ltx_td ltx_align_left\">0.80</td>\n<td id=\"S5.T2.1.1.3.2.3\" class=\"ltx_td ltx_align_left\">0.83</td>\n<td id=\"S5.T2.1.1.3.2.4\" class=\"ltx_td ltx_align_left\">0.81</td>\n<td id=\"S5.T2.1.1.3.2.5\" class=\"ltx_td ltx_align_left\">0.88</td>\n</tr>\n<tr id=\"S5.T2.1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">F1</th>\n<td id=\"S5.T2.1.1.4.3.2\" class=\"ltx_td ltx_align_left\">0.58</td>\n<td id=\"S5.T2.1.1.4.3.3\" class=\"ltx_td ltx_align_left\">0.49</td>\n<td id=\"S5.T2.1.1.4.3.4\" class=\"ltx_td ltx_align_left\">0.51</td>\n<td id=\"S5.T2.1.1.4.3.5\" class=\"ltx_td ltx_align_left\">0.52</td>\n</tr>\n<tr id=\"S5.T2.1.1.5.4\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r\">AUCPR</th>\n<td id=\"S5.T2.1.1.5.4.2\" class=\"ltx_td ltx_align_left ltx_border_b\">0.4712</td>\n<td id=\"S5.T2.1.1.5.4.3\" class=\"ltx_td ltx_align_left ltx_border_b\">0.4717</td>\n<td id=\"S5.T2.1.1.5.4.4\" class=\"ltx_td ltx_align_left ltx_border_b\">0.4572</td>\n<td id=\"S5.T2.1.1.5.4.5\" class=\"ltx_td ltx_align_left ltx_border_b\">0.67</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In this section, we analyze the impact of different sampling methods used to solve data imbalance.\nThe proportion of the negative and positive data in our training set is about ",
                "1",
                ":",
                "783.73",
                ":",
                "1",
                "783.73",
                "1:783.73",
                ".\nThe typical method to solve such data imbalance is to resample the training set so that the number of positive and negative samples is balanced.\nAnother typical method is to reweight the losses of positive and negative samples.\nWe evaluate four methods to evaluate the impact of imbalance-target methods:\n(1) RandomUnder, which randomly under-sample the negative samples.\n(2) RandomOver, which randomly over-sample the positive samples\n(3) SMOTE, which uses KNN to generate synthetic data to augment positive samples.\n(4) Reweight, which assigns a higher weight to the loss of the positive samples.\nSurprisingly, we find the model performance is hampered by all the resampling methods.\nDue to the great data imbalance, such resampling methods will drop a large number of negative samples, which leads to a catastrophe in model performance.\nInstead, reweighting only suffers from a small loss of model performance since it does not drop any negative samples but forces the model to focus more on the positive samples."
            ]
        ]
    },
    "S5.T3": {
        "caption": "Table 3. Performance evaluation of the number of communication rounds.",
        "table": "<table id=\"S5.T3.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T3.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\"></th>\n<th id=\"S5.T3.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">I1-R50</th>\n<th id=\"S5.T3.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">I5-R10</th>\n<th id=\"S5.T3.1.1.1.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">I10-R5</th>\n<th id=\"S5.T3.1.1.1.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">I50-R1</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T3.1.2.1\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Precision</th>\n<td id=\"S5.T3.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">0.97</td>\n<td id=\"S5.T3.1.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">0.97</td>\n<td id=\"S5.T3.1.2.1.4\" class=\"ltx_td ltx_align_left ltx_border_t\">0.97</td>\n<td id=\"S5.T3.1.2.1.5\" class=\"ltx_td ltx_align_left ltx_border_t\">0.97</td>\n</tr>\n<tr id=\"S5.T3.1.3.2\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Recall</th>\n<td id=\"S5.T3.1.3.2.2\" class=\"ltx_td ltx_align_left\">0.79</td>\n<td id=\"S5.T3.1.3.2.3\" class=\"ltx_td ltx_align_left\">0.79</td>\n<td id=\"S5.T3.1.3.2.4\" class=\"ltx_td ltx_align_left\">0.71</td>\n<td id=\"S5.T3.1.3.2.5\" class=\"ltx_td ltx_align_left\">0.71</td>\n</tr>\n<tr id=\"S5.T3.1.4.3\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">F1</th>\n<td id=\"S5.T3.1.4.3.2\" class=\"ltx_td ltx_align_left\">0.86</td>\n<td id=\"S5.T3.1.4.3.3\" class=\"ltx_td ltx_align_left\">0.86</td>\n<td id=\"S5.T3.1.4.3.4\" class=\"ltx_td ltx_align_left\">0.79</td>\n<td id=\"S5.T3.1.4.3.5\" class=\"ltx_td ltx_align_left\">0.79</td>\n</tr>\n<tr id=\"S5.T3.1.5.4\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r\">AUCPR</th>\n<td id=\"S5.T3.1.5.4.2\" class=\"ltx_td ltx_align_left ltx_border_b\">0.7037</td>\n<td id=\"S5.T3.1.5.4.3\" class=\"ltx_td ltx_align_left ltx_border_b\">0.7037</td>\n<td id=\"S5.T3.1.5.4.4\" class=\"ltx_td ltx_align_left ltx_border_b\">0.5344</td>\n<td id=\"S5.T3.1.5.4.5\" class=\"ltx_td ltx_align_left ltx_border_b\">0.5344</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "In this section, we analyze the impact of the number of communication rounds between the bank clients and the server, as well as that of the communication interval.\nWe set the total number of epochs as 505050, where is the multiplication of the communication interval (I𝐼I) and the communication round number (R𝑅R).\nSpecifically, we consider four settings with different combinations of I𝐼I and R𝑅R.\nWe find if the number of the account clients is small, I𝐼I and R𝑅R only have little influence on the performance of the final model.\nHence, in this section, we use 100100100 account clients to evaluate the impact of I𝐼I and R𝑅R, presented in Table 3.\nIt is shown that more frequent communication leads to better model performance.\nHowever, due to the overhead of frequent communication, a trade-off is necessary between the communication cost and the model performance."
        ]
    },
    "S5.T4": {
        "caption": "Table 4. Impact of account client number on the performance.",
        "table": "<table id=\"S5.T4.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T4.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\"></th>\n<th id=\"S5.T4.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">1</th>\n<th id=\"S5.T4.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">10</th>\n<th id=\"S5.T4.1.1.1.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">50</th>\n<th id=\"S5.T4.1.1.1.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">100</th>\n<th id=\"S5.T4.1.1.1.6\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">200</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T4.1.2.1\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Precision</th>\n<td id=\"S5.T4.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">0.97</td>\n<td id=\"S5.T4.1.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">0.97</td>\n<td id=\"S5.T4.1.2.1.4\" class=\"ltx_td ltx_align_left ltx_border_t\">0.97</td>\n<td id=\"S5.T4.1.2.1.5\" class=\"ltx_td ltx_align_left ltx_border_t\">0.97</td>\n<td id=\"S5.T4.1.2.1.6\" class=\"ltx_td ltx_align_left ltx_border_t\">0.97</td>\n</tr>\n<tr id=\"S5.T4.1.3.2\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Recall</th>\n<td id=\"S5.T4.1.3.2.2\" class=\"ltx_td ltx_align_left\">0.79</td>\n<td id=\"S5.T4.1.3.2.3\" class=\"ltx_td ltx_align_left\">0.79</td>\n<td id=\"S5.T4.1.3.2.4\" class=\"ltx_td ltx_align_left\">0.71</td>\n<td id=\"S5.T4.1.3.2.5\" class=\"ltx_td ltx_align_left\">0.71</td>\n<td id=\"S5.T4.1.3.2.6\" class=\"ltx_td ltx_align_left\">0.71</td>\n</tr>\n<tr id=\"S5.T4.1.4.3\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">F1</th>\n<td id=\"S5.T4.1.4.3.2\" class=\"ltx_td ltx_align_left\">0.86</td>\n<td id=\"S5.T4.1.4.3.3\" class=\"ltx_td ltx_align_left\">0.86</td>\n<td id=\"S5.T4.1.4.3.4\" class=\"ltx_td ltx_align_left\">0.79</td>\n<td id=\"S5.T4.1.4.3.5\" class=\"ltx_td ltx_align_left\">0.79</td>\n<td id=\"S5.T4.1.4.3.6\" class=\"ltx_td ltx_align_left\">0.79</td>\n</tr>\n<tr id=\"S5.T4.1.5.4\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r\">AUCPR</th>\n<td id=\"S5.T4.1.5.4.2\" class=\"ltx_td ltx_align_left ltx_border_b\">0.7037</td>\n<td id=\"S5.T4.1.5.4.3\" class=\"ltx_td ltx_align_left ltx_border_b\">0.7037</td>\n<td id=\"S5.T4.1.5.4.4\" class=\"ltx_td ltx_align_left ltx_border_b\">0.5344</td>\n<td id=\"S5.T4.1.5.4.5\" class=\"ltx_td ltx_align_left ltx_border_b\">0.5344</td>\n<td id=\"S5.T4.1.5.4.6\" class=\"ltx_td ltx_align_left ltx_border_b\">0.5344</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "In this section, we present the impact of the number of account clients on the model performance.\nWe only change the account client number and maintain the other settings in this section.\nBased on the account client number, the account data is split randomly and used to train an auto-encoder locally in each account client.\nThen the server aggregates all the auto-encoders from the account clients as the global auto-encoder.\nThe results are summarized in Table 4.\nAs the number of account clients increases, the model performance tends to be stable, which implies that our framework is robust even with a large number of account clients.\nYet the model can achieve a better performance when the account client number is small, we can still obtain utility as the account client number is large."
        ]
    },
    "S5.T5": {
        "caption": "Table 5. Impact on the model performance of the data size.",
        "table": "<table id=\"S5.T5.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T5.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T5.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\"></th>\n<th id=\"S5.T5.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">0.5</th>\n<th id=\"S5.T5.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">0.1</th>\n<th id=\"S5.T5.1.1.1.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">0.01</th>\n<th id=\"S5.T5.1.1.1.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">0.002</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T5.1.2.1\" class=\"ltx_tr\">\n<th id=\"S5.T5.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Precision</th>\n<td id=\"S5.T5.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">0.97</td>\n<td id=\"S5.T5.1.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">0.94</td>\n<td id=\"S5.T5.1.2.1.4\" class=\"ltx_td ltx_align_left ltx_border_t\">0.97</td>\n<td id=\"S5.T5.1.2.1.5\" class=\"ltx_td ltx_align_left ltx_border_t\">0.59</td>\n</tr>\n<tr id=\"S5.T5.1.3.2\" class=\"ltx_tr\">\n<th id=\"S5.T5.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">Recall</th>\n<td id=\"S5.T5.1.3.2.2\" class=\"ltx_td ltx_align_left\">0.79</td>\n<td id=\"S5.T5.1.3.2.3\" class=\"ltx_td ltx_align_left\">0.75</td>\n<td id=\"S5.T5.1.3.2.4\" class=\"ltx_td ltx_align_left\">0.71</td>\n<td id=\"S5.T5.1.3.2.5\" class=\"ltx_td ltx_align_left\">0.51</td>\n</tr>\n<tr id=\"S5.T5.1.4.3\" class=\"ltx_tr\">\n<th id=\"S5.T5.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">F1</th>\n<td id=\"S5.T5.1.4.3.2\" class=\"ltx_td ltx_align_left\">0.86</td>\n<td id=\"S5.T5.1.4.3.3\" class=\"ltx_td ltx_align_left\">0.82</td>\n<td id=\"S5.T5.1.4.3.4\" class=\"ltx_td ltx_align_left\">0.79</td>\n<td id=\"S5.T5.1.4.3.5\" class=\"ltx_td ltx_align_left\">0.51</td>\n</tr>\n<tr id=\"S5.T5.1.5.4\" class=\"ltx_tr\">\n<th id=\"S5.T5.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r\">AUCPR</th>\n<td id=\"S5.T5.1.5.4.2\" class=\"ltx_td ltx_align_left ltx_border_b\">0.7037</td>\n<td id=\"S5.T5.1.5.4.3\" class=\"ltx_td ltx_align_left ltx_border_b\">0.6068</td>\n<td id=\"S5.T5.1.5.4.4\" class=\"ltx_td ltx_align_left ltx_border_b\">0.5344</td>\n<td id=\"S5.T5.1.5.4.5\" class=\"ltx_td ltx_align_left ltx_border_b\">0.0534</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "In this section, we study the impact of the size of the training set.\nWe randomly sample the training data from the original training set, based on the sampling ratio, where we maintain the relative proportion between positive and negative samples.\nFrom Table 5 we can see the model performance is destroyed by the decreasing data size.\nNote the number of positive samples is quite limited in our case.\nHence, as we decrease the data size, the number of positive samples is getting smaller, which makes it even more difficult to learn from the positive samples."
        ]
    }
}