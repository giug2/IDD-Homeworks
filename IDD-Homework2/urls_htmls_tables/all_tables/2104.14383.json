{
    "PAPER'S NUMBER OF TABLES": 5,
    "S5.T1": {
        "caption": "Table 1: Datasets and Experimental Settings",
        "table": "<table id=\"S5.T1.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">Dataset</td>\n<td id=\"S5.T1.1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">Attribute Type</td>\n<td id=\"S5.T1.1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">Attributes Number (Total/Attack/Defense)</td>\n<td id=\"S5.T1.1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">Instances Number</td>\n<td id=\"S5.T1.1.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">Attack Task</td>\n</tr>\n<tr id=\"S5.T1.1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Purchase100 <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib22\" title=\"\" class=\"ltx_ref\">22</a>]</cite>\n</td>\n<td id=\"S5.T1.1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Binary</td>\n<td id=\"S5.T1.1.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">600/300/300</td>\n<td id=\"S5.T1.1.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">197324</td>\n<td id=\"S5.T1.1.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\">Classification / Regression</td>\n</tr>\n<tr id=\"S5.T1.1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Credit <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib22\" title=\"\" class=\"ltx_ref\">22</a>]</cite>\n</td>\n<td id=\"S5.T1.1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Numerical</td>\n<td id=\"S5.T1.1.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">28/1/1</td>\n<td id=\"S5.T1.1.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">284807</td>\n<td id=\"S5.T1.1.1.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">Regression</td>\n</tr>\n<tr id=\"S5.T1.1.1.5.4\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">UCI Adult</td>\n<td id=\"S5.T1.1.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Categorical</td>\n<td id=\"S5.T1.1.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">10/1/1</td>\n<td id=\"S5.T1.1.1.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">48842</td>\n<td id=\"S5.T1.1.1.5.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\">Classification</td>\n</tr>\n<tr id=\"S5.T1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">COCO-QA <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib23\" title=\"\" class=\"ltx_ref\">23</a>]</cite>\n</td>\n<td id=\"S5.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">Image,Text</td>\n<td id=\"S5.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">\n<math id=\"S5.T1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\sim\" display=\"inline\"><semantics id=\"S5.T1.1.1.1.1.m1.1a\"><mo id=\"S5.T1.1.1.1.1.m1.1.1\" xref=\"S5.T1.1.1.1.1.m1.1.1.cmml\">‚àº</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.1.1.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T1.1.1.1.1.m1.1.1.cmml\" xref=\"S5.T1.1.1.1.1.m1.1.1\">similar-to</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.1.1.1.1.m1.1c\">\\sim</annotation></semantics></math>/90/90</td>\n<td id=\"S5.T1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">78736</td>\n<td id=\"S5.T1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">Classification</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Our algorithm is implemented on ",
                "PyTorch 1.5.0",
                " and all experiments are done on Intel Xeon Processor with GPU GeForce RTX 2080 Ti."
            ]
        ]
    },
    "S5.T2": {
        "caption": "Table 2: Attack performance vs. batch size on Purchase and Adult.",
        "table": "<table id=\"S5.T2.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T2.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\">Dataset</th>\n<th id=\"S5.T2.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\">Batch size</th>\n<th id=\"S5.T2.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\">32</th>\n<th id=\"S5.T2.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\">128</th>\n<th id=\"S5.T2.1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">256</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T2.1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S5.T2.1.1.2.1.1.1\" class=\"ltx_text\">\n<span id=\"S5.T2.1.1.2.1.1.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S5.T2.1.1.2.1.1.1.1.1\" class=\"ltx_tr\">\n<span id=\"S5.T2.1.1.2.1.1.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Purchase</span></span>\n<span id=\"S5.T2.1.1.2.1.1.1.1.2\" class=\"ltx_tr\">\n<span id=\"S5.T2.1.1.2.1.1.1.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">(Recall)</span></span>\n</span></span></td>\n<td id=\"S5.T2.1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Static</td>\n<td id=\"S5.T2.1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.9861</td>\n<td id=\"S5.T2.1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.9883</td>\n<td id=\"S5.T2.1.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.9918</td>\n</tr>\n<tr id=\"S5.T2.1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Adaptive</td>\n<td id=\"S5.T2.1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.9907</td>\n<td id=\"S5.T2.1.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.9973</td>\n<td id=\"S5.T2.1.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.9984</td>\n</tr>\n<tr id=\"S5.T2.1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S5.T2.1.1.4.3.1.1\" class=\"ltx_text\">\n<span id=\"S5.T2.1.1.4.3.1.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S5.T2.1.1.4.3.1.1.1.1\" class=\"ltx_tr\">\n<span id=\"S5.T2.1.1.4.3.1.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Adult</span></span>\n<span id=\"S5.T2.1.1.4.3.1.1.1.2\" class=\"ltx_tr\">\n<span id=\"S5.T2.1.1.4.3.1.1.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">(Error rate)</span></span>\n</span></span></td>\n<td id=\"S5.T2.1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Static</td>\n<td id=\"S5.T2.1.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.0130</td>\n<td id=\"S5.T2.1.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.0131</td>\n<td id=\"S5.T2.1.1.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.0110</td>\n</tr>\n<tr id=\"S5.T2.1.1.5.4\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">Adaptive</td>\n<td id=\"S5.T2.1.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">0.0193</td>\n<td id=\"S5.T2.1.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">0.0185</td>\n<td id=\"S5.T2.1.1.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">0.0160</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We show the performance of static and adaptive attacks and their impact factors. The privacy attack is overall successful. For example, with less than ",
                "1",
                "%",
                "percent",
                "1",
                "1\\%",
                " poison data, the attacker can achieve over ",
                "0.9",
                "0.9",
                "0.9",
                " recall on Purchase. Even on complex dataset COCO-QA (90 objects, highly sparse), with merely ",
                "5",
                "%",
                "percent",
                "5",
                "5\\%",
                " poison data, the recall is nearly ",
                "0.5",
                "0.5",
                "0.5",
                ".",
                "Fig.¬†",
                "2(a)",
                " and Fig.¬†",
                "2(b)",
                " show how accuracy and privacy evolve throughout training. Each point on the static attack represents an independent attack launched at that epoch. We observe that, in most cases, the adaptive attack performs better than the static, mostly because more data is collected and the attack can transfer across features obtained in different rounds. On Purchase (Fig.¬†",
                "2(a)",
                "), the static attack performance gets slightly worse, indicating the features learned to be less revealing towards the end of training. An exception is Adult (Tab.¬†",
                "2",
                "), where the static attack performs better than the adaptive, and it may be because the training batches vary significantly resulting in lack of transferability.",
                "Poison ratio.",
                "\nFig.¬†",
                "2(c)",
                " and Fig.¬†",
                "2(d)",
                " show that attack performance enhances as ",
                "Œ±",
                "ùõº",
                "\\alpha",
                " increases, which is obvious as more training data is collected. When ",
                "Œ±",
                "ùõº",
                "\\alpha",
                " is small, adaptive attack is stronger than the static one but the gap diminishes with the increase of ",
                "Œ±",
                "ùõº",
                "\\alpha",
                ", meaning that the static decoder can collect sufficient data for training when ",
                "Œ±",
                "ùõº",
                "\\alpha",
                " surpasses a threshold.",
                "Batch size.",
                "\nTab.¬†",
                "2",
                " demonstrates that as the batch size increases, the attack accuracy is higher. The reason is that with smaller batch size, poison data tends to be scattered across more training batches resulting in the training difficulty of the adversary, as the mapping between the inputs and features change frequently. Hence the larger batch size in VFL would facilitate privacy attacks."
            ]
        ]
    },
    "S5.T3": {
        "caption": "Table 3: Protecting different number of attributes: less is better.",
        "table": "<table id=\"S5.T3.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T3.1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" rowspan=\"2\"><span id=\"S5.T3.1.1.1.1.1.1\" class=\"ltx_text\">Purchase</span></td>\n<td id=\"S5.T3.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">Protect attribute number</td>\n<td id=\"S5.T3.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">100</td>\n<td id=\"S5.T3.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">200</td>\n<td id=\"S5.T3.1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">300</td>\n</tr>\n<tr id=\"S5.T3.1.1.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Attack first 100 attributes (Recall)</td>\n<td id=\"S5.T3.1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.785</td>\n<td id=\"S5.T3.1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.7946</td>\n<td id=\"S5.T3.1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.8015</td>\n</tr>\n<tr id=\"S5.T3.1.1.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S5.T3.1.1.3.3.1.1\" class=\"ltx_text\">COCO-QA</span></td>\n<td id=\"S5.T3.1.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Protect attribute number</td>\n<td id=\"S5.T3.1.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">30</td>\n<td id=\"S5.T3.1.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">60</td>\n<td id=\"S5.T3.1.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">90</td>\n</tr>\n<tr id=\"S5.T3.1.1.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">Attack first 30 attributes (Recall)</td>\n<td id=\"S5.T3.1.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">0.489</td>\n<td id=\"S5.T3.1.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">0.4822</td>\n<td id=\"S5.T3.1.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">0.4959</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We compare our proposed defense against the baseline, naive defense, basic defense, and proposed defense variant in terms of the ",
                "accuracy",
                " and ",
                "privacy",
                ". Baseline means the VFL without any defense at all, of which the accuracy is typically the highest. In naive defense, we fix the privacy weight factor ",
                "Œª",
                "ùúÜ",
                "\\lambda",
                ". In proposed defense variant, we fix stepsizes ",
                "œÑ",
                "1",
                ",",
                "œÑ",
                "2",
                "subscript",
                "ùúè",
                "1",
                "subscript",
                "ùúè",
                "2",
                "\\tau_{1},\\tau_{2}",
                " in prior rather than tuning them automatically in proposed defense.",
                "Results on different datasets are shown in Fig.¬†",
                "3",
                ". Considering the impact of hyper-parameters, we show multiple results for each method under different settings. Actually, we observe results of the same method are often clustered showing similar performance among all. Baseline achieves the highest accuracy with the lowest privacy. Naive defense and basic defense can achieve high privacy, but at the cost of significant accuracy drop. For example, the naive defense and basic defense respectively achieve the highest privacy with ",
                "23.84",
                "%",
                "percent",
                "23.84",
                "23.84\\%",
                " and ",
                "12.36",
                "%",
                "percent",
                "12.36",
                "12.36\\%",
                " accuracy drop in Fig.¬†",
                "3(b)",
                " and Fig.¬†",
                "3(a)",
                ". Our proposed defense is overall superior in that it achieves relatively high privacy with negligible accuracy drop: the average accuracy drop is ",
                "0.45",
                "%",
                "percent",
                "0.45",
                "0.45\\%",
                " on Purchase, ",
                "3.38",
                "%",
                "percent",
                "3.38",
                "3.38\\%",
                " on COCO-QA, ",
                "0.21",
                "%",
                "percent",
                "0.21",
                "0.21\\%",
                " on Adult and ",
                "0.69",
                "%",
                "percent",
                "0.69",
                "0.69\\%",
                " on Credit. For better understanding of the privacy-preserving effect, we list the success rates of random guess in the caption, which shows the upper limits of privacy. Proposed defense shows significant improvement over baseline, around halfway between baselines and random cases.",
                "Attribute number.",
                "\nWe evaluate how the number of private attribute affects the privacy in our proposed defense in Tab.¬†",
                "3",
                ". For example, the client only aims to protect ",
                "100",
                ",",
                "200",
                ",",
                "300",
                "100",
                "200",
                "300",
                "100,200,300",
                " of its attributes on Purchase. The results are a bit counter-intuitive that as the number of privacy-preserving attributes increases, it is usually harder for the client to prevent privacy leakage. The reason may be the limited capability of local model, not being able to protect all attributes.",
                "Epoch number.",
                "\nWe also investigate the impact of defense epoch number on accuracy and privacy performance in proposed defense. From Tab.¬†",
                "4",
                ", we observe a higher ",
                "N",
                "2",
                "subscript",
                "ùëÅ",
                "2",
                "N_{2}",
                " brings lower recall on Purchase and higher error rate on Adult, both indicating higher privacy levels, with little influence on accuracy. It is reasonable that the simulated decoder gets stronger when it is trained for more epochs.",
                "Convergence.",
                " Although there are no theoretical guarantees, our proposed defense based on FBS still works well. As shown in Fig.¬†",
                "4",
                ", the convergence curve for proposed defense is much smoother than naive and basic defense with higher accuracy, showing stable training performance, close to the normal one.",
                "Multi party.",
                " We show the performance of proposed defense where there are more than 2 clients are involved. Tab.¬†",
                "5",
                " show the case of three clients on Purchase, among which two are victims. Although there is mild accuracy decline compared to 2-client case, the privacy performance is similar, verifying that our approach can be extended to multi-party scenarios."
            ]
        ]
    },
    "S5.T4": {
        "caption": "Table 4: Defense epoch number N2subscriptùëÅ2N_{2}: more is better.",
        "table": "<table id=\"S5.T4.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T4.1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\">Dataset</th>\n<th id=\"S5.T4.1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" colspan=\"3\">Purchase</th>\n<th id=\"S5.T4.1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\">Adult</th>\n</tr>\n<tr id=\"S5.T4.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><math id=\"S5.T4.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"N_{2}\" display=\"inline\"><semantics id=\"S5.T4.1.1.1.1.m1.1a\"><msub id=\"S5.T4.1.1.1.1.m1.1.1\" xref=\"S5.T4.1.1.1.1.m1.1.1.cmml\"><mi id=\"S5.T4.1.1.1.1.m1.1.1.2\" xref=\"S5.T4.1.1.1.1.m1.1.1.2.cmml\">N</mi><mn id=\"S5.T4.1.1.1.1.m1.1.1.3\" xref=\"S5.T4.1.1.1.1.m1.1.1.3.cmml\">2</mn></msub><annotation-xml encoding=\"MathML-Content\" id=\"S5.T4.1.1.1.1.m1.1b\"><apply id=\"S5.T4.1.1.1.1.m1.1.1.cmml\" xref=\"S5.T4.1.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S5.T4.1.1.1.1.m1.1.1.1.cmml\" xref=\"S5.T4.1.1.1.1.m1.1.1\">subscript</csymbol><ci id=\"S5.T4.1.1.1.1.m1.1.1.2.cmml\" xref=\"S5.T4.1.1.1.1.m1.1.1.2\">ùëÅ</ci><cn type=\"integer\" id=\"S5.T4.1.1.1.1.m1.1.1.3.cmml\" xref=\"S5.T4.1.1.1.1.m1.1.1.3\">2</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T4.1.1.1.1.m1.1c\">N_{2}</annotation></semantics></math></th>\n<th id=\"S5.T4.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">10</th>\n<th id=\"S5.T4.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">20</th>\n<th id=\"S5.T4.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">30</th>\n<th id=\"S5.T4.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">5</th>\n<th id=\"S5.T4.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">10</th>\n<th id=\"S5.T4.1.1.1.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">20</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T4.1.1.3.1\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Accuracy</td>\n<td id=\"S5.T4.1.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.9134</td>\n<td id=\"S5.T4.1.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.9091</td>\n<td id=\"S5.T4.1.1.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.9085</td>\n<td id=\"S5.T4.1.1.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.8394</td>\n<td id=\"S5.T4.1.1.3.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.8432</td>\n<td id=\"S5.T4.1.1.3.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\">0.8411</td>\n</tr>\n<tr id=\"S5.T4.1.1.4.2\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.4.2.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">Recall / Error rate</td>\n<td id=\"S5.T4.1.1.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">0.7983</td>\n<td id=\"S5.T4.1.1.4.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">0.7672</td>\n<td id=\"S5.T4.1.1.4.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">0.7312</td>\n<td id=\"S5.T4.1.1.4.2.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">0.2097</td>\n<td id=\"S5.T4.1.1.4.2.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">0.248</td>\n<td id=\"S5.T4.1.1.4.2.7\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">0.2519</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We compare our proposed defense against the baseline, naive defense, basic defense, and proposed defense variant in terms of the ",
                "accuracy",
                " and ",
                "privacy",
                ". Baseline means the VFL without any defense at all, of which the accuracy is typically the highest. In naive defense, we fix the privacy weight factor ",
                "Œª",
                "ùúÜ",
                "\\lambda",
                ". In proposed defense variant, we fix stepsizes ",
                "œÑ",
                "1",
                ",",
                "œÑ",
                "2",
                "subscript",
                "ùúè",
                "1",
                "subscript",
                "ùúè",
                "2",
                "\\tau_{1},\\tau_{2}",
                " in prior rather than tuning them automatically in proposed defense.",
                "Results on different datasets are shown in Fig.¬†",
                "3",
                ". Considering the impact of hyper-parameters, we show multiple results for each method under different settings. Actually, we observe results of the same method are often clustered showing similar performance among all. Baseline achieves the highest accuracy with the lowest privacy. Naive defense and basic defense can achieve high privacy, but at the cost of significant accuracy drop. For example, the naive defense and basic defense respectively achieve the highest privacy with ",
                "23.84",
                "%",
                "percent",
                "23.84",
                "23.84\\%",
                " and ",
                "12.36",
                "%",
                "percent",
                "12.36",
                "12.36\\%",
                " accuracy drop in Fig.¬†",
                "3(b)",
                " and Fig.¬†",
                "3(a)",
                ". Our proposed defense is overall superior in that it achieves relatively high privacy with negligible accuracy drop: the average accuracy drop is ",
                "0.45",
                "%",
                "percent",
                "0.45",
                "0.45\\%",
                " on Purchase, ",
                "3.38",
                "%",
                "percent",
                "3.38",
                "3.38\\%",
                " on COCO-QA, ",
                "0.21",
                "%",
                "percent",
                "0.21",
                "0.21\\%",
                " on Adult and ",
                "0.69",
                "%",
                "percent",
                "0.69",
                "0.69\\%",
                " on Credit. For better understanding of the privacy-preserving effect, we list the success rates of random guess in the caption, which shows the upper limits of privacy. Proposed defense shows significant improvement over baseline, around halfway between baselines and random cases.",
                "Attribute number.",
                "\nWe evaluate how the number of private attribute affects the privacy in our proposed defense in Tab.¬†",
                "3",
                ". For example, the client only aims to protect ",
                "100",
                ",",
                "200",
                ",",
                "300",
                "100",
                "200",
                "300",
                "100,200,300",
                " of its attributes on Purchase. The results are a bit counter-intuitive that as the number of privacy-preserving attributes increases, it is usually harder for the client to prevent privacy leakage. The reason may be the limited capability of local model, not being able to protect all attributes.",
                "Epoch number.",
                "\nWe also investigate the impact of defense epoch number on accuracy and privacy performance in proposed defense. From Tab.¬†",
                "4",
                ", we observe a higher ",
                "N",
                "2",
                "subscript",
                "ùëÅ",
                "2",
                "N_{2}",
                " brings lower recall on Purchase and higher error rate on Adult, both indicating higher privacy levels, with little influence on accuracy. It is reasonable that the simulated decoder gets stronger when it is trained for more epochs.",
                "Convergence.",
                " Although there are no theoretical guarantees, our proposed defense based on FBS still works well. As shown in Fig.¬†",
                "4",
                ", the convergence curve for proposed defense is much smoother than naive and basic defense with higher accuracy, showing stable training performance, close to the normal one.",
                "Multi party.",
                " We show the performance of proposed defense where there are more than 2 clients are involved. Tab.¬†",
                "5",
                " show the case of three clients on Purchase, among which two are victims. Although there is mild accuracy decline compared to 2-client case, the privacy performance is similar, verifying that our approach can be extended to multi-party scenarios."
            ]
        ]
    },
    "S5.T5": {
        "caption": "Table 5: Three clients on Purchase. Œ±=0.01.ùõº0.01\\alpha=0.01.",
        "table": "<table id=\"S5.T5.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T5.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" rowspan=\"2\"><span id=\"S5.T5.1.1.1.1\" class=\"ltx_text\"><math id=\"S5.T5.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\sim\" display=\"inline\"><semantics id=\"S5.T5.1.1.1.1.m1.1a\"><mo id=\"S5.T5.1.1.1.1.m1.1.1\" xref=\"S5.T5.1.1.1.1.m1.1.1.cmml\">‚àº</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T5.1.1.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S5.T5.1.1.1.1.m1.1.1.cmml\" xref=\"S5.T5.1.1.1.1.m1.1.1\">similar-to</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T5.1.1.1.1.m1.1c\">\\sim</annotation></semantics></math></span></td>\n<td id=\"S5.T5.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" rowspan=\"2\"><span id=\"S5.T5.1.1.2.1\" class=\"ltx_text\">Accuracy</span></td>\n<td id=\"S5.T5.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\">Client1, 200 attri</td>\n<td id=\"S5.T5.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\">Client2, 200 attri</td>\n</tr>\n<tr id=\"S5.T5.1.2.1\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Error rate</td>\n<td id=\"S5.T5.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Recall</td>\n<td id=\"S5.T5.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Error rate</td>\n<td id=\"S5.T5.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">Recall</td>\n</tr>\n<tr id=\"S5.T5.1.3.2\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Baseline</td>\n<td id=\"S5.T5.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.9100</td>\n<td id=\"S5.T5.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.0654</td>\n<td id=\"S5.T5.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.9320</td>\n<td id=\"S5.T5.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.0511</td>\n<td id=\"S5.T5.1.3.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\">0.8925</td>\n</tr>\n<tr id=\"S5.T5.1.4.3\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Basic defense</td>\n<td id=\"S5.T5.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.8790</td>\n<td id=\"S5.T5.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.3183</td>\n<td id=\"S5.T5.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.6760</td>\n<td id=\"S5.T5.1.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.3045</td>\n<td id=\"S5.T5.1.4.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\">0.5820</td>\n</tr>\n<tr id=\"S5.T5.1.5.4\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">Proposed defense</td>\n<td id=\"S5.T5.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">0.8879</td>\n<td id=\"S5.T5.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">0.3067</td>\n<td id=\"S5.T5.1.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">0.6876</td>\n<td id=\"S5.T5.1.5.4.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">0.3118</td>\n<td id=\"S5.T5.1.5.4.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">0.5767</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We compare our proposed defense against the baseline, naive defense, basic defense, and proposed defense variant in terms of the ",
                "accuracy",
                " and ",
                "privacy",
                ". Baseline means the VFL without any defense at all, of which the accuracy is typically the highest. In naive defense, we fix the privacy weight factor ",
                "Œª",
                "ùúÜ",
                "\\lambda",
                ". In proposed defense variant, we fix stepsizes ",
                "œÑ",
                "1",
                ",",
                "œÑ",
                "2",
                "subscript",
                "ùúè",
                "1",
                "subscript",
                "ùúè",
                "2",
                "\\tau_{1},\\tau_{2}",
                " in prior rather than tuning them automatically in proposed defense.",
                "Results on different datasets are shown in Fig.¬†",
                "3",
                ". Considering the impact of hyper-parameters, we show multiple results for each method under different settings. Actually, we observe results of the same method are often clustered showing similar performance among all. Baseline achieves the highest accuracy with the lowest privacy. Naive defense and basic defense can achieve high privacy, but at the cost of significant accuracy drop. For example, the naive defense and basic defense respectively achieve the highest privacy with ",
                "23.84",
                "%",
                "percent",
                "23.84",
                "23.84\\%",
                " and ",
                "12.36",
                "%",
                "percent",
                "12.36",
                "12.36\\%",
                " accuracy drop in Fig.¬†",
                "3(b)",
                " and Fig.¬†",
                "3(a)",
                ". Our proposed defense is overall superior in that it achieves relatively high privacy with negligible accuracy drop: the average accuracy drop is ",
                "0.45",
                "%",
                "percent",
                "0.45",
                "0.45\\%",
                " on Purchase, ",
                "3.38",
                "%",
                "percent",
                "3.38",
                "3.38\\%",
                " on COCO-QA, ",
                "0.21",
                "%",
                "percent",
                "0.21",
                "0.21\\%",
                " on Adult and ",
                "0.69",
                "%",
                "percent",
                "0.69",
                "0.69\\%",
                " on Credit. For better understanding of the privacy-preserving effect, we list the success rates of random guess in the caption, which shows the upper limits of privacy. Proposed defense shows significant improvement over baseline, around halfway between baselines and random cases.",
                "Attribute number.",
                "\nWe evaluate how the number of private attribute affects the privacy in our proposed defense in Tab.¬†",
                "3",
                ". For example, the client only aims to protect ",
                "100",
                ",",
                "200",
                ",",
                "300",
                "100",
                "200",
                "300",
                "100,200,300",
                " of its attributes on Purchase. The results are a bit counter-intuitive that as the number of privacy-preserving attributes increases, it is usually harder for the client to prevent privacy leakage. The reason may be the limited capability of local model, not being able to protect all attributes.",
                "Epoch number.",
                "\nWe also investigate the impact of defense epoch number on accuracy and privacy performance in proposed defense. From Tab.¬†",
                "4",
                ", we observe a higher ",
                "N",
                "2",
                "subscript",
                "ùëÅ",
                "2",
                "N_{2}",
                " brings lower recall on Purchase and higher error rate on Adult, both indicating higher privacy levels, with little influence on accuracy. It is reasonable that the simulated decoder gets stronger when it is trained for more epochs.",
                "Convergence.",
                " Although there are no theoretical guarantees, our proposed defense based on FBS still works well. As shown in Fig.¬†",
                "4",
                ", the convergence curve for proposed defense is much smoother than naive and basic defense with higher accuracy, showing stable training performance, close to the normal one.",
                "Multi party.",
                " We show the performance of proposed defense where there are more than 2 clients are involved. Tab.¬†",
                "5",
                " show the case of three clients on Purchase, among which two are victims. Although there is mild accuracy decline compared to 2-client case, the privacy performance is similar, verifying that our approach can be extended to multi-party scenarios."
            ]
        ]
    }
}