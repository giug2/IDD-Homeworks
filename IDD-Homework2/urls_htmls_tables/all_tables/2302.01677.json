{
    "PAPER'S NUMBER OF TABLES": 1,
    "S5.T1": {
        "caption": "Table 1. The results on ResNet-18 and ConvNet models on CIFAR-10 dataset. We adopt trained models from FedAvg and Ditto methods. A lower ASR means better robustness. A higher ACC means better C-Acc. The best results are highlighted in bold.",
        "table": "<table id=\"S5.T1.6.6\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T1.6.6.7\" class=\"ltx_tr\">\n<td id=\"S5.T1.6.6.7.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S5.T1.6.6.7.1.1\" class=\"ltx_text\">Models</span></td>\n<td id=\"S5.T1.6.6.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Methods</td>\n<td id=\"S5.T1.6.6.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\">original</td>\n<td id=\"S5.T1.6.6.7.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\">+ FT-linear</td>\n<td id=\"S5.T1.6.6.7.5\" class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"2\">+ ST</td>\n</tr>\n<tr id=\"S5.T1.6.6.6\" class=\"ltx_tr\">\n<td id=\"S5.T1.6.6.6.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Attacks</td>\n<td id=\"S5.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">ASR(<math id=\"S5.T1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S5.T1.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S5.T1.1.1.1.1.m1.1.1\" xref=\"S5.T1.1.1.1.1.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.1.1.1.1.m1.1b\"><ci id=\"S5.T1.1.1.1.1.m1.1.1.cmml\" xref=\"S5.T1.1.1.1.1.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math>)</td>\n<td id=\"S5.T1.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Acc(<math id=\"S5.T1.2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S5.T1.2.2.2.2.m1.1a\"><mo stretchy=\"false\" id=\"S5.T1.2.2.2.2.m1.1.1\" xref=\"S5.T1.2.2.2.2.m1.1.1.cmml\">↑</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.2.2.2.2.m1.1b\"><ci id=\"S5.T1.2.2.2.2.m1.1.1.cmml\" xref=\"S5.T1.2.2.2.2.m1.1.1\">↑</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.2.2.2.2.m1.1c\">\\uparrow</annotation></semantics></math>)</td>\n<td id=\"S5.T1.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">ASR(<math id=\"S5.T1.3.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S5.T1.3.3.3.3.m1.1a\"><mo stretchy=\"false\" id=\"S5.T1.3.3.3.3.m1.1.1\" xref=\"S5.T1.3.3.3.3.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.3.3.3.3.m1.1b\"><ci id=\"S5.T1.3.3.3.3.m1.1.1.cmml\" xref=\"S5.T1.3.3.3.3.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.3.3.3.3.m1.1c\">\\downarrow</annotation></semantics></math>)</td>\n<td id=\"S5.T1.4.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Acc(<math id=\"S5.T1.4.4.4.4.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S5.T1.4.4.4.4.m1.1a\"><mo stretchy=\"false\" id=\"S5.T1.4.4.4.4.m1.1.1\" xref=\"S5.T1.4.4.4.4.m1.1.1.cmml\">↑</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.4.4.4.4.m1.1b\"><ci id=\"S5.T1.4.4.4.4.m1.1.1.cmml\" xref=\"S5.T1.4.4.4.4.m1.1.1\">↑</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.4.4.4.4.m1.1c\">\\uparrow</annotation></semantics></math>)</td>\n<td id=\"S5.T1.5.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\">ASR(<math id=\"S5.T1.5.5.5.5.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S5.T1.5.5.5.5.m1.1a\"><mo stretchy=\"false\" id=\"S5.T1.5.5.5.5.m1.1.1\" xref=\"S5.T1.5.5.5.5.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.5.5.5.5.m1.1b\"><ci id=\"S5.T1.5.5.5.5.m1.1.1.cmml\" xref=\"S5.T1.5.5.5.5.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.5.5.5.5.m1.1c\">\\downarrow</annotation></semantics></math>)</td>\n<td id=\"S5.T1.6.6.6.6\" class=\"ltx_td ltx_align_center ltx_border_t\">Acc(<math id=\"S5.T1.6.6.6.6.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S5.T1.6.6.6.6.m1.1a\"><mo stretchy=\"false\" id=\"S5.T1.6.6.6.6.m1.1.1\" xref=\"S5.T1.6.6.6.6.m1.1.1.cmml\">↑</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.6.6.6.6.m1.1b\"><ci id=\"S5.T1.6.6.6.6.m1.1.1.cmml\" xref=\"S5.T1.6.6.6.6.m1.1.1\">↑</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.6.6.6.6.m1.1c\">\\uparrow</annotation></semantics></math>)</td>\n</tr>\n<tr id=\"S5.T1.6.6.8\" class=\"ltx_tr\">\n<td id=\"S5.T1.6.6.8.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S5.T1.6.6.8.1.1\" class=\"ltx_text\">Res18@FedAvg</span></td>\n<td id=\"S5.T1.6.6.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">BadNet</td>\n<td id=\"S5.T1.6.6.8.3\" class=\"ltx_td ltx_align_center ltx_border_t\">89.2</td>\n<td id=\"S5.T1.6.6.8.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">78.1</td>\n<td id=\"S5.T1.6.6.8.5\" class=\"ltx_td ltx_align_center ltx_border_t\">90.1</td>\n<td id=\"S5.T1.6.6.8.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">76.8</td>\n<td id=\"S5.T1.6.6.8.7\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.6.6.8.7.1\" class=\"ltx_text ltx_font_bold\">39.3</span></td>\n<td id=\"S5.T1.6.6.8.8\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.6.6.8.8.1\" class=\"ltx_text ltx_font_bold\">80.9</span></td>\n</tr>\n<tr id=\"S5.T1.6.6.9\" class=\"ltx_tr\">\n<td id=\"S5.T1.6.6.9.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Blended</td>\n<td id=\"S5.T1.6.6.9.2\" class=\"ltx_td ltx_align_center\">97.5</td>\n<td id=\"S5.T1.6.6.9.3\" class=\"ltx_td ltx_align_center ltx_border_r\">78.1</td>\n<td id=\"S5.T1.6.6.9.4\" class=\"ltx_td ltx_align_center\">97.4</td>\n<td id=\"S5.T1.6.6.9.5\" class=\"ltx_td ltx_align_center ltx_border_r\">76.7</td>\n<td id=\"S5.T1.6.6.9.6\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.6.6.9.6.1\" class=\"ltx_text ltx_font_bold\">47.2</span></td>\n<td id=\"S5.T1.6.6.9.7\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.6.6.9.7.1\" class=\"ltx_text ltx_font_bold\">81.1</span></td>\n</tr>\n<tr id=\"S5.T1.6.6.10\" class=\"ltx_tr\">\n<td id=\"S5.T1.6.6.10.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S5.T1.6.6.10.1.1\" class=\"ltx_text\">Conv@FedAvg</span></td>\n<td id=\"S5.T1.6.6.10.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">BadNet</td>\n<td id=\"S5.T1.6.6.10.3\" class=\"ltx_td ltx_align_center ltx_border_t\">76.5</td>\n<td id=\"S5.T1.6.6.10.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">74.4</td>\n<td id=\"S5.T1.6.6.10.5\" class=\"ltx_td ltx_align_center ltx_border_t\">71.0</td>\n<td id=\"S5.T1.6.6.10.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">74.8</td>\n<td id=\"S5.T1.6.6.10.7\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.6.6.10.7.1\" class=\"ltx_text ltx_font_bold\">6.4</span></td>\n<td id=\"S5.T1.6.6.10.8\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.6.6.10.8.1\" class=\"ltx_text ltx_font_bold\">76.0</span></td>\n</tr>\n<tr id=\"S5.T1.6.6.11\" class=\"ltx_tr\">\n<td id=\"S5.T1.6.6.11.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Blended</td>\n<td id=\"S5.T1.6.6.11.2\" class=\"ltx_td ltx_align_center\">76.7</td>\n<td id=\"S5.T1.6.6.11.3\" class=\"ltx_td ltx_align_center ltx_border_r\">74.5</td>\n<td id=\"S5.T1.6.6.11.4\" class=\"ltx_td ltx_align_center\">77.1</td>\n<td id=\"S5.T1.6.6.11.5\" class=\"ltx_td ltx_align_center ltx_border_r\">74.7</td>\n<td id=\"S5.T1.6.6.11.6\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.6.6.11.6.1\" class=\"ltx_text ltx_font_bold\">13.8</span></td>\n<td id=\"S5.T1.6.6.11.7\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.6.6.11.7.1\" class=\"ltx_text ltx_font_bold\">76.1</span></td>\n</tr>\n<tr id=\"S5.T1.6.6.12\" class=\"ltx_tr\">\n<td id=\"S5.T1.6.6.12.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S5.T1.6.6.12.1.1\" class=\"ltx_text\">Res18@Ditto</span></td>\n<td id=\"S5.T1.6.6.12.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">BadNet</td>\n<td id=\"S5.T1.6.6.12.3\" class=\"ltx_td ltx_align_center ltx_border_t\">85.1</td>\n<td id=\"S5.T1.6.6.12.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">76.5</td>\n<td id=\"S5.T1.6.6.12.5\" class=\"ltx_td ltx_align_center ltx_border_t\">86.2</td>\n<td id=\"S5.T1.6.6.12.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">74.5</td>\n<td id=\"S5.T1.6.6.12.7\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.6.6.12.7.1\" class=\"ltx_text ltx_font_bold\">38.9</span></td>\n<td id=\"S5.T1.6.6.12.8\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.6.6.12.8.1\" class=\"ltx_text ltx_font_bold\">80.8</span></td>\n</tr>\n<tr id=\"S5.T1.6.6.13\" class=\"ltx_tr\">\n<td id=\"S5.T1.6.6.13.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Blended</td>\n<td id=\"S5.T1.6.6.13.2\" class=\"ltx_td ltx_align_center\">95.6</td>\n<td id=\"S5.T1.6.6.13.3\" class=\"ltx_td ltx_align_center ltx_border_r\">76.6</td>\n<td id=\"S5.T1.6.6.13.4\" class=\"ltx_td ltx_align_center\">95.7</td>\n<td id=\"S5.T1.6.6.13.5\" class=\"ltx_td ltx_align_center ltx_border_r\">74.4</td>\n<td id=\"S5.T1.6.6.13.6\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.6.6.13.6.1\" class=\"ltx_text ltx_font_bold\">47.1</span></td>\n<td id=\"S5.T1.6.6.13.7\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.6.6.13.7.1\" class=\"ltx_text ltx_font_bold\">81.2</span></td>\n</tr>\n<tr id=\"S5.T1.6.6.14\" class=\"ltx_tr\">\n<td id=\"S5.T1.6.6.14.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S5.T1.6.6.14.1.1\" class=\"ltx_text\">Conv@Ditto</span></td>\n<td id=\"S5.T1.6.6.14.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">BadNet</td>\n<td id=\"S5.T1.6.6.14.3\" class=\"ltx_td ltx_align_center ltx_border_t\">71.2</td>\n<td id=\"S5.T1.6.6.14.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T1.6.6.14.4.1\" class=\"ltx_text ltx_font_bold\">77.9</span></td>\n<td id=\"S5.T1.6.6.14.5\" class=\"ltx_td ltx_align_center ltx_border_t\">72.6</td>\n<td id=\"S5.T1.6.6.14.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">76.5</td>\n<td id=\"S5.T1.6.6.14.7\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.6.6.14.7.1\" class=\"ltx_text ltx_font_bold\">5.6</span></td>\n<td id=\"S5.T1.6.6.14.8\" class=\"ltx_td ltx_align_center ltx_border_t\">76.7</td>\n</tr>\n<tr id=\"S5.T1.6.6.15\" class=\"ltx_tr\">\n<td id=\"S5.T1.6.6.15.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">Blended</td>\n<td id=\"S5.T1.6.6.15.2\" class=\"ltx_td ltx_align_center ltx_border_b\">76.8</td>\n<td id=\"S5.T1.6.6.15.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S5.T1.6.6.15.3.1\" class=\"ltx_text ltx_font_bold\">77.8</span></td>\n<td id=\"S5.T1.6.6.15.4\" class=\"ltx_td ltx_align_center ltx_border_b\">77.1</td>\n<td id=\"S5.T1.6.6.15.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">76.6</td>\n<td id=\"S5.T1.6.6.15.6\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S5.T1.6.6.15.6.1\" class=\"ltx_text ltx_font_bold\">17.4</span></td>\n<td id=\"S5.T1.6.6.15.7\" class=\"ltx_td ltx_align_center ltx_border_b\">76.8</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We test our method on trained models from FedAvg and Ditto and show defense performances against BadNet and Blended attacks. For Simple-Tuning, we adopt default Kaiming Uniform normalization (He et al., 2015) and use the constant learning rate as 0.0050.0050.005. We only tune the linear classifier for 101010 epochs. The results containing ASR and C-Acc on ResNet-18 and ConvNet models are shown in Table 1. We compare the results of our method with the results of original FedAvg and Ditto models and models from only fine-tuning local linear classifiers without reinitialization. We denote the latter as FT-linear. As shown in Table 1, our method, Simple-Tuning, significantly improves robustness against backdoor attacks. Compared with original models, it efficiently reduces the ASR of two backdoor attacks by 56.6%percent56.656.6\\% on average. It achieves better robustness on smaller model ConvNet, reducing ASR below 20%percent2020\\%. Surprisingly, Simple-Tuning even improves the C-Acc of FL methods except for Ditto on ConvNet. These results demonstrate the great potential of Simple-Tuning. It is worth noting that FT-linear does not show any robustness like vanilla FT. It also verifies the importance of reinitialization in our method to backdoor robustness. This suggests that directly fine-tuning FL backdoor models may not efficiently remove backdoor triggers. It also contrasts with findings of (Adi et al., 2018) which utilizes FT methods to purify watermark, specific backdoor trigger, in DNN models. However, they demonstrated that all three methods - vanilla FT, FT-linear, and FT-linear with randomized linear classifier - can effectively purify watermark triggers. We believe this is mainly because triggers of the watermark are set differently from the general backdoor triggers. In (Adi et al., 2018), the authors set 𝒚tsubscript𝒚𝑡\\bm{y}_{t} of each watermarked sample to a randomly chosen label, rather than a fixed target label as in backdoor attacks."
        ]
    }
}