{
    "PAPER'S NUMBER OF TABLES": 6,
    "S4.T1": {
        "caption": "TABLE I: The forgery detection accuracy (in %) is evaluated by several state-of-the-art methods on four sub-datasets of the constructed forgery source hybrid dataset. The last column result is the average value. The best results are shown in black font, with the second place underlined.",
        "table": "<table id=\"S4.T1.2\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S4.T1.2.3\" class=\"ltx_tr\">\n<td id=\"S4.T1.2.3.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Methods</td>\n<td id=\"S4.T1.2.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">CelebDF-v2</td>\n<td id=\"S4.T1.2.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">FF++_DF</td>\n<td id=\"S4.T1.2.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">FMFCC-V</td>\n<td id=\"S4.T1.2.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">WildDeepfake</td>\n<td id=\"S4.T1.2.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\">Avg.</td>\n</tr>\n<tr id=\"S4.T1.2.4\" class=\"ltx_tr\">\n<td id=\"S4.T1.2.4.1\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T1.2.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"5\"><span id=\"S4.T1.2.4.2.1\" class=\"ltx_text ltx_font_bold\">Without Considering Privacy</span></td>\n</tr>\n<tr id=\"S4.T1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">CNNDetection<sub id=\"S4.T1.1.1.1.1\" class=\"ltx_sub\">1</sub>\n</td>\n<td id=\"S4.T1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">64.98</td>\n<td id=\"S4.T1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">94.18</td>\n<td id=\"S4.T1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">88.06</td>\n<td id=\"S4.T1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">71.36</td>\n<td id=\"S4.T1.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">79.65</td>\n</tr>\n<tr id=\"S4.T1.2.5\" class=\"ltx_tr\">\n<td id=\"S4.T1.2.5.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Xception</td>\n<td id=\"S4.T1.2.5.2\" class=\"ltx_td ltx_align_center\">72.12</td>\n<td id=\"S4.T1.2.5.3\" class=\"ltx_td ltx_align_center\">87.54</td>\n<td id=\"S4.T1.2.5.4\" class=\"ltx_td ltx_align_center\">75.54</td>\n<td id=\"S4.T1.2.5.5\" class=\"ltx_td ltx_align_center\">57.77</td>\n<td id=\"S4.T1.2.5.6\" class=\"ltx_td ltx_align_center\">73.27</td>\n</tr>\n<tr id=\"S4.T1.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_r\">CNNDetection<sub id=\"S4.T1.2.2.1.1\" class=\"ltx_sub\">2</sub>\n</td>\n<td id=\"S4.T1.2.2.2\" class=\"ltx_td ltx_align_center\">65.79</td>\n<td id=\"S4.T1.2.2.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.2.2.3.1\" class=\"ltx_text ltx_font_bold\">96.20</span></td>\n<td id=\"S4.T1.2.2.4\" class=\"ltx_td ltx_align_center\">83.99</td>\n<td id=\"S4.T1.2.2.5\" class=\"ltx_td ltx_align_center\">63.61</td>\n<td id=\"S4.T1.2.2.6\" class=\"ltx_td ltx_align_center\">77.40</td>\n</tr>\n<tr id=\"S4.T1.2.6\" class=\"ltx_tr\">\n<td id=\"S4.T1.2.6.1\" class=\"ltx_td ltx_align_center ltx_border_r\">GFF</td>\n<td id=\"S4.T1.2.6.2\" class=\"ltx_td ltx_align_center\">81.60</td>\n<td id=\"S4.T1.2.6.3\" class=\"ltx_td ltx_align_center\">90.40</td>\n<td id=\"S4.T1.2.6.4\" class=\"ltx_td ltx_align_center\">89.15</td>\n<td id=\"S4.T1.2.6.5\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.2.6.5.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">71.64</span></td>\n<td id=\"S4.T1.2.6.6\" class=\"ltx_td ltx_align_center\">83.20</td>\n</tr>\n<tr id=\"S4.T1.2.7\" class=\"ltx_tr\">\n<td id=\"S4.T1.2.7.1\" class=\"ltx_td ltx_align_center ltx_border_r\">RFM</td>\n<td id=\"S4.T1.2.7.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.2.7.2.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">86.44</span></td>\n<td id=\"S4.T1.2.7.3\" class=\"ltx_td ltx_align_center\">94.77</td>\n<td id=\"S4.T1.2.7.4\" class=\"ltx_td ltx_align_center\">99.22</td>\n<td id=\"S4.T1.2.7.5\" class=\"ltx_td ltx_align_center\">65.92</td>\n<td id=\"S4.T1.2.7.6\" class=\"ltx_td ltx_align_center\">86.59</td>\n</tr>\n<tr id=\"S4.T1.2.8\" class=\"ltx_tr\">\n<td id=\"S4.T1.2.8.1\" class=\"ltx_td ltx_align_center ltx_border_r\">CADDM</td>\n<td id=\"S4.T1.2.8.2\" class=\"ltx_td ltx_align_center\">83.05</td>\n<td id=\"S4.T1.2.8.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.2.8.3.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">95.59</span></td>\n<td id=\"S4.T1.2.8.4\" class=\"ltx_td ltx_align_center\">74.69</td>\n<td id=\"S4.T1.2.8.5\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.2.8.5.1\" class=\"ltx_text ltx_font_bold\">78.76</span></td>\n<td id=\"S4.T1.2.8.6\" class=\"ltx_td ltx_align_center\">83.02</td>\n</tr>\n<tr id=\"S4.T1.2.9\" class=\"ltx_tr\">\n<td id=\"S4.T1.2.9.1\" class=\"ltx_td ltx_align_center ltx_border_r\">FedPR (w/o FL)</td>\n<td id=\"S4.T1.2.9.2\" class=\"ltx_td ltx_align_center\">84.29</td>\n<td id=\"S4.T1.2.9.3\" class=\"ltx_td ltx_align_center\">94.12</td>\n<td id=\"S4.T1.2.9.4\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.2.9.4.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">99.36</span></td>\n<td id=\"S4.T1.2.9.5\" class=\"ltx_td ltx_align_center\">70.05</td>\n<td id=\"S4.T1.2.9.6\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.2.9.6.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">86.96</span></td>\n</tr>\n<tr id=\"S4.T1.2.10\" class=\"ltx_tr\">\n<td id=\"S4.T1.2.10.1\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T1.2.10.2\" class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"5\"><span id=\"S4.T1.2.10.2.1\" class=\"ltx_text ltx_font_bold\">Considering Privacy</span></td>\n</tr>\n<tr id=\"S4.T1.2.11\" class=\"ltx_tr\">\n<td id=\"S4.T1.2.11.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">FedPR (Ours)</td>\n<td id=\"S4.T1.2.11.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S4.T1.2.11.2.1\" class=\"ltx_text ltx_font_bold\">89.90</span></td>\n<td id=\"S4.T1.2.11.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">94.81</td>\n<td id=\"S4.T1.2.11.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S4.T1.2.11.4.1\" class=\"ltx_text ltx_font_bold\">99.60</span></td>\n<td id=\"S4.T1.2.11.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">70.81</td>\n<td id=\"S4.T1.2.11.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S4.T1.2.11.6.1\" class=\"ltx_text ltx_font_bold\">88.78</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Results on Forgery Source Hybrid Dataset In order to further prove the advantages of this proposed method, we trained and tested the models in the four subtypes included in the Forgery Source Hybrid Dataset. As shown in Table¬†I, our proposed method achieves the highest accuracy on the CelebDF-v2 and FMFCC-V datasets, outperforming\nCADDM [44],\nRFM [45],\nGFF [8] and other methods in most scenarios. This is because the designed personalized forgery representation learning can explore more robust face forgery clues. As shown in Table¬†II, we re-implemented several representative face forgery methods on the forgery source mixed dataset. Thanks to the designed personalized forgery representation learning, our proposed method achieves optimal performance in both auc and accuracy metrics. For example, compared with RFM [45], the accuracy of our method exceeds 3.99% and the auc exceeds 0.76%. Compared with the existing CADDM method [44], this method also achieves competitive results. CNNDetection [46] is susceptible to interference from specific generation methods. Therefore, two different data preprocessing methods are used to improve performance. CNNDetection1 [46] represents that the image may be gaussian blur or jpeged, each with 50% probability, where gaussian blur parameters: œÉùúé\\sigma~Uniform[0, 3], jpeged: the image is converted by two popular libraries OpenCV and PIL jpeg format, quality¬†uniform{30, 31, ‚Ä¶, 100}; CNNDetection2 [46] represents that the image may be blurry and jpeg, 10% probability. Our method improves the generalization ability for complex forgery datasets with diverse types by extracting personalized representations of clients and combining the shared representation of multiple distributed client models."
        ]
    },
    "S4.T2": {
        "caption": "TABLE II: Evaluation accuracy rate (in %) and area under the receiver operating characteristic curve (in %) of forgery detection performance on constructed Forgery Source Hybrid Dataset by several state-of-the-art methods. The best result is displayed in black font and the second place is underlined.",
        "table": "<table id=\"S4.T2.2\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S4.T2.2.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.2.3.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Methods</td>\n<td id=\"S4.T2.2.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Accuracy(%)</td>\n<td id=\"S4.T2.2.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">AUC(%)</td>\n</tr>\n<tr id=\"S4.T2.2.4\" class=\"ltx_tr\">\n<td id=\"S4.T2.2.4.1\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T2.2.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"2\"><span id=\"S4.T2.2.4.2.1\" class=\"ltx_text ltx_font_bold\">Without Considering Privacy</span></td>\n</tr>\n<tr id=\"S4.T2.2.5\" class=\"ltx_tr\">\n<td id=\"S4.T2.2.5.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Xception</td>\n<td id=\"S4.T2.2.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\">69.85</td>\n<td id=\"S4.T2.2.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\">76.66</td>\n</tr>\n<tr id=\"S4.T2.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r\">CNNDetection<sub id=\"S4.T2.1.1.1.1\" class=\"ltx_sub\"><span id=\"S4.T2.1.1.1.1.1\" class=\"ltx_text ltx_font_italic\">1</span></sub>\n</td>\n<td id=\"S4.T2.1.1.2\" class=\"ltx_td ltx_align_center\">75.44</td>\n<td id=\"S4.T2.1.1.3\" class=\"ltx_td ltx_align_center\">83.26</td>\n</tr>\n<tr id=\"S4.T2.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_r\">CNNDetection<sub id=\"S4.T2.2.2.1.1\" class=\"ltx_sub\"><span id=\"S4.T2.2.2.1.1.1\" class=\"ltx_text ltx_font_italic\">2</span></sub>\n</td>\n<td id=\"S4.T2.2.2.2\" class=\"ltx_td ltx_align_center\">78.57</td>\n<td id=\"S4.T2.2.2.3\" class=\"ltx_td ltx_align_center\">87.48</td>\n</tr>\n<tr id=\"S4.T2.2.6\" class=\"ltx_tr\">\n<td id=\"S4.T2.2.6.1\" class=\"ltx_td ltx_align_center ltx_border_r\">GFF</td>\n<td id=\"S4.T2.2.6.2\" class=\"ltx_td ltx_align_center\">82.71</td>\n<td id=\"S4.T2.2.6.3\" class=\"ltx_td ltx_align_center\">91.18</td>\n</tr>\n<tr id=\"S4.T2.2.7\" class=\"ltx_tr\">\n<td id=\"S4.T2.2.7.1\" class=\"ltx_td ltx_align_center ltx_border_r\">RFM</td>\n<td id=\"S4.T2.2.7.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.2.7.2.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">84.79</span></td>\n<td id=\"S4.T2.2.7.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.2.7.3.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">92.76</span></td>\n</tr>\n<tr id=\"S4.T2.2.8\" class=\"ltx_tr\">\n<td id=\"S4.T2.2.8.1\" class=\"ltx_td ltx_align_center ltx_border_r\">CADDM</td>\n<td id=\"S4.T2.2.8.2\" class=\"ltx_td ltx_align_center\">81.51</td>\n<td id=\"S4.T2.2.8.3\" class=\"ltx_td ltx_align_center\">90.40</td>\n</tr>\n<tr id=\"S4.T2.2.9\" class=\"ltx_tr\">\n<td id=\"S4.T2.2.9.1\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T2.2.9.2\" class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"2\"><span id=\"S4.T2.2.9.2.1\" class=\"ltx_text ltx_font_bold\">Considering Privacy</span></td>\n</tr>\n<tr id=\"S4.T2.2.10\" class=\"ltx_tr\">\n<td id=\"S4.T2.2.10.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">FedPR (Ours)</td>\n<td id=\"S4.T2.2.10.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S4.T2.2.10.2.1\" class=\"ltx_text ltx_font_bold\">88.78</span></td>\n<td id=\"S4.T2.2.10.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S4.T2.2.10.3.1\" class=\"ltx_text ltx_font_bold\">93.52</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Results on Forgery Source Hybrid Dataset In order to further prove the advantages of this proposed method, we trained and tested the models in the four subtypes included in the Forgery Source Hybrid Dataset. As shown in Table¬†I, our proposed method achieves the highest accuracy on the CelebDF-v2 and FMFCC-V datasets, outperforming\nCADDM [44],\nRFM [45],\nGFF [8] and other methods in most scenarios. This is because the designed personalized forgery representation learning can explore more robust face forgery clues. As shown in Table¬†II, we re-implemented several representative face forgery methods on the forgery source mixed dataset. Thanks to the designed personalized forgery representation learning, our proposed method achieves optimal performance in both auc and accuracy metrics. For example, compared with RFM [45], the accuracy of our method exceeds 3.99% and the auc exceeds 0.76%. Compared with the existing CADDM method [44], this method also achieves competitive results. CNNDetection [46] is susceptible to interference from specific generation methods. Therefore, two different data preprocessing methods are used to improve performance. CNNDetection1 [46] represents that the image may be gaussian blur or jpeged, each with 50% probability, where gaussian blur parameters: œÉùúé\\sigma~Uniform[0, 3], jpeged: the image is converted by two popular libraries OpenCV and PIL jpeg format, quality¬†uniform{30, 31, ‚Ä¶, 100}; CNNDetection2 [46] represents that the image may be blurry and jpeg, 10% probability. Our method improves the generalization ability for complex forgery datasets with diverse types by extracting personalized representations of clients and combining the shared representation of multiple distributed client models."
        ]
    },
    "S4.T3": {
        "caption": "TABLE III: Forgery detection performance evaluation was performed using several state-of-the-art methods on the Deepforensics-1.0 dataset, and the accuracy (in%) was calculated. The best result is displayed in black font and the second place is underlined.",
        "table": "<table id=\"S4.T3.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S4.T3.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Methods</td>\n<td id=\"S4.T3.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Accuracy(%)</td>\n</tr>\n<tr id=\"S4.T3.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.2.1\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T3.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T3.1.2.2.1\" class=\"ltx_text ltx_font_bold\">Without Considering Privacy</span></td>\n</tr>\n<tr id=\"S4.T3.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">C3D</td>\n<td id=\"S4.T3.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">87.63</td>\n</tr>\n<tr id=\"S4.T3.1.4\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_r\">TSN</td>\n<td id=\"S4.T3.1.4.2\" class=\"ltx_td ltx_align_center\">91.50</td>\n</tr>\n<tr id=\"S4.T3.1.5\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.5.1\" class=\"ltx_td ltx_align_center ltx_border_r\">I3D</td>\n<td id=\"S4.T3.1.5.2\" class=\"ltx_td ltx_align_center\">90.75</td>\n</tr>\n<tr id=\"S4.T3.1.6\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.6.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Resnet+LSTM</td>\n<td id=\"S4.T3.1.6.2\" class=\"ltx_td ltx_align_center\">90.63</td>\n</tr>\n<tr id=\"S4.T3.1.7\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.7.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Xception</td>\n<td id=\"S4.T3.1.7.2\" class=\"ltx_td ltx_align_center\">88.38</td>\n</tr>\n<tr id=\"S4.T3.1.8\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.8.1\" class=\"ltx_td ltx_align_center ltx_border_r\">FedPR (w/o FL)</td>\n<td id=\"S4.T3.1.8.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.1.8.2.1\" class=\"ltx_text ltx_font_bold\">98.64</span></td>\n</tr>\n<tr id=\"S4.T3.1.9\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.9.1\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T3.1.9.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T3.1.9.2.1\" class=\"ltx_text ltx_font_bold\">Considering Privacy</span></td>\n</tr>\n<tr id=\"S4.T3.1.10\" class=\"ltx_tr\">\n<td id=\"S4.T3.1.10.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">FedPR (Ours)</td>\n<td id=\"S4.T3.1.10.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S4.T3.1.10.2.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">97.29</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Results on Deepforensics-1.0 dataset As shown in Table¬†III, we compare the algorithm proposed in this paper with other representative face forgery detection methods. In order to prove the strong generalization ability, we selected 1000 manipulated videos in the standard set. When the training set is the standard set and the test set is single-level distortion, the proposed method can achieve good accuracy, even exceeding Resnet+LSTM\n[47] [48] 6.66%,\nXception [49] 8.91%, I3D\n[50] 6.54%. We believe that these accuracy improvements are due to the designed personalized forgery representation learning. It is known that in some cases the accuracy of federated learning models is lower than that of centralized training models. In our experiments, the performance degradation caused by federated learning was 1.35%."
        ]
    },
    "S4.T4": {
        "caption": "TABLE IV: Evaluation AUC (in %) and equal error rate (in %) of forgery detection performance on WildDeepfake dataset by several state-of-the-art methods. The best result is displayed in black font and the second place is underlined.",
        "table": "<table id=\"S4.T4.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S4.T4.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Methods</td>\n<td id=\"S4.T4.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">AUC(%)</td>\n<td id=\"S4.T4.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">EER(%)</td>\n</tr>\n<tr id=\"S4.T4.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.3.1\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T4.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"2\"><span id=\"S4.T4.1.3.2.1\" class=\"ltx_text ltx_font_bold\">Without Considering Privacy</span></td>\n</tr>\n<tr id=\"S4.T4.1.4\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Xception</td>\n<td id=\"S4.T4.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">62.72</td>\n<td id=\"S4.T4.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">-</td>\n</tr>\n<tr id=\"S4.T4.1.5\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.5.1\" class=\"ltx_td ltx_align_center ltx_border_r\">RFM</td>\n<td id=\"S4.T4.1.5.2\" class=\"ltx_td ltx_align_center\">57.75</td>\n<td id=\"S4.T4.1.5.3\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S4.T4.1.6\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.6.1\" class=\"ltx_td ltx_align_center ltx_border_r\">ADD-Net</td>\n<td id=\"S4.T4.1.6.2\" class=\"ltx_td ltx_align_center\">62.35</td>\n<td id=\"S4.T4.1.6.3\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S4.T4.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r\">F<sup id=\"S4.T4.1.1.1.1\" class=\"ltx_sup\"><span id=\"S4.T4.1.1.1.1.1\" class=\"ltx_text ltx_font_italic\">3</span></sup>-Net</td>\n<td id=\"S4.T4.1.1.2\" class=\"ltx_td ltx_align_center\">57.10</td>\n<td id=\"S4.T4.1.1.3\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S4.T4.1.7\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.7.1\" class=\"ltx_td ltx_align_center ltx_border_r\">MultiAtt</td>\n<td id=\"S4.T4.1.7.2\" class=\"ltx_td ltx_align_center\">59.74</td>\n<td id=\"S4.T4.1.7.3\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S4.T4.1.8\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.8.1\" class=\"ltx_td ltx_align_center ltx_border_r\">RECCE</td>\n<td id=\"S4.T4.1.8.2\" class=\"ltx_td ltx_align_center\">64.31</td>\n<td id=\"S4.T4.1.8.3\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S4.T4.1.9\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.9.1\" class=\"ltx_td ltx_align_center ltx_border_r\">LTW</td>\n<td id=\"S4.T4.1.9.2\" class=\"ltx_td ltx_align_center\">67.12</td>\n<td id=\"S4.T4.1.9.3\" class=\"ltx_td ltx_align_center\">39.22</td>\n</tr>\n<tr id=\"S4.T4.1.10\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.10.1\" class=\"ltx_td ltx_align_center ltx_border_r\">EN-B4</td>\n<td id=\"S4.T4.1.10.2\" class=\"ltx_td ltx_align_center\">67.89</td>\n<td id=\"S4.T4.1.10.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.10.3.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">37.21</span></td>\n</tr>\n<tr id=\"S4.T4.1.11\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.11.1\" class=\"ltx_td ltx_align_center ltx_border_r\">GFF</td>\n<td id=\"S4.T4.1.11.2\" class=\"ltx_td ltx_align_center\">66.51</td>\n<td id=\"S4.T4.1.11.3\" class=\"ltx_td ltx_align_center\">41.52</td>\n</tr>\n<tr id=\"S4.T4.1.12\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.12.1\" class=\"ltx_td ltx_align_center ltx_border_r\">SBI</td>\n<td id=\"S4.T4.1.12.2\" class=\"ltx_td ltx_align_center\">67.22</td>\n<td id=\"S4.T4.1.12.3\" class=\"ltx_td ltx_align_center\">38.85</td>\n</tr>\n<tr id=\"S4.T4.1.13\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.13.1\" class=\"ltx_td ltx_align_center ltx_border_r\">FedPR (w/o FL)</td>\n<td id=\"S4.T4.1.13.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.13.2.1\" class=\"ltx_text ltx_font_bold\">73.73</span></td>\n<td id=\"S4.T4.1.13.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.13.3.1\" class=\"ltx_text ltx_font_bold\">33.75</span></td>\n</tr>\n<tr id=\"S4.T4.1.14\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.14.1\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T4.1.14.2\" class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"2\"><span id=\"S4.T4.1.14.2.1\" class=\"ltx_text ltx_font_bold\">Considering Privacy</span></td>\n</tr>\n<tr id=\"S4.T4.1.15\" class=\"ltx_tr\">\n<td id=\"S4.T4.1.15.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">FedPR (Ours)</td>\n<td id=\"S4.T4.1.15.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S4.T4.1.15.2.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">68.25</span></td>\n<td id=\"S4.T4.1.15.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">37.84</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Results on WildDeepfake dataset As shown in Table¬†IV, in order to further verify the generalization of the proposed method, we train on the FaceForensics++ dataset and test on the WildDeepfake dataset. Experimental results show that our proposed method can achieve good performance, even exceeding GFF\n[8] 1.74%, SBI\n[51] 1.03%, LTW\n[52] 1.13%. The eer index of our method reaches 37.84%, only lagging behind EN-B4\n[53] 0.63%, while our method achieved auc of 73.73% and eer of 33.75% when using centralized training. It has reached the SOTA level on both indicators. This is due to the designed personalized features containing more suitable properties of the client data set, further improving the applicability of complex forgery datasets with diverse types."
        ]
    },
    "S4.T5": {
        "caption": "TABLE V: AUC (in %) and equal error rate (in %) of forgery detection performance on CelebDF-v2 dataset by several state-of-the-art methods. The best result is displayed in black font and the second place is underlined.",
        "table": "<table id=\"S4.T5.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S4.T5.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Methods</td>\n<td id=\"S4.T5.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">AUC(%)</td>\n<td id=\"S4.T5.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">EER(%)</td>\n</tr>\n<tr id=\"S4.T5.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.3.1\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T5.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"2\"><span id=\"S4.T5.1.3.2.1\" class=\"ltx_text ltx_font_bold\">Without Considering Privacy</span></td>\n</tr>\n<tr id=\"S4.T5.1.4\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Capsule</td>\n<td id=\"S4.T5.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">70.18</td>\n<td id=\"S4.T5.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">-</td>\n</tr>\n<tr id=\"S4.T5.1.5\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.5.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Xception</td>\n<td id=\"S4.T5.1.5.2\" class=\"ltx_td ltx_align_center\">77.91</td>\n<td id=\"S4.T5.1.5.3\" class=\"ltx_td ltx_align_center\">29.44</td>\n</tr>\n<tr id=\"S4.T5.1.6\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.6.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Add-Net</td>\n<td id=\"S4.T5.1.6.2\" class=\"ltx_td ltx_align_center\">62.12</td>\n<td id=\"S4.T5.1.6.3\" class=\"ltx_td ltx_align_center\">41.51</td>\n</tr>\n<tr id=\"S4.T5.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r\">F<sup id=\"S4.T5.1.1.1.1\" class=\"ltx_sup\"><span id=\"S4.T5.1.1.1.1.1\" class=\"ltx_text ltx_font_italic\">3</span></sup>-Net</td>\n<td id=\"S4.T5.1.1.2\" class=\"ltx_td ltx_align_center\">60.88</td>\n<td id=\"S4.T5.1.1.3\" class=\"ltx_td ltx_align_center\">42.76</td>\n</tr>\n<tr id=\"S4.T5.1.7\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.7.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Multi-Att</td>\n<td id=\"S4.T5.1.7.2\" class=\"ltx_td ltx_align_center\">76.95</td>\n<td id=\"S4.T5.1.7.3\" class=\"ltx_td ltx_align_center\">28.11</td>\n</tr>\n<tr id=\"S4.T5.1.8\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.8.1\" class=\"ltx_td ltx_align_center ltx_border_r\">PEL</td>\n<td id=\"S4.T5.1.8.2\" class=\"ltx_td ltx_align_center\">82.94</td>\n<td id=\"S4.T5.1.8.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T5.1.8.3.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">24.24</span></td>\n</tr>\n<tr id=\"S4.T5.1.9\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.9.1\" class=\"ltx_td ltx_align_center ltx_border_r\">FedPR (w/o FL)</td>\n<td id=\"S4.T5.1.9.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T5.1.9.2.1\" class=\"ltx_text ltx_font_bold\">83.95</span></td>\n<td id=\"S4.T5.1.9.3\" class=\"ltx_td ltx_align_center\">24.83</td>\n</tr>\n<tr id=\"S4.T5.1.10\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.10.1\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S4.T5.1.10.2\" class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"2\"><span id=\"S4.T5.1.10.2.1\" class=\"ltx_text ltx_font_bold\">Considering Privacy</span></td>\n</tr>\n<tr id=\"S4.T5.1.11\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.11.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">FedPR (Ours)</td>\n<td id=\"S4.T5.1.11.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S4.T5.1.11.2.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">83.93</span></td>\n<td id=\"S4.T5.1.11.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S4.T5.1.11.3.1\" class=\"ltx_text ltx_font_bold\">23.65</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Results on CelebDF-v2 dataset As shown in Table¬†V, in order to further verify the generalization ability of this method, we trained on the WildDeepfake dataset and tested on the CelebDF-v2 dataset. Experimental results show that our proposed method can achieve high auc, even exceeding\nXception [49] 6.02%, Multi-Att [54] 6.98%, PEL [55] 0.99%. The eer index of our method reaches 23.65%, which is better than PEL [55] 0.59%. While our method uses centralized training, the auc reaches 83.95% and the eer reaches 24.83%. This is due to the designed personalized forgery representation learning, which can further explore more robust face forgery clues on complex forgery datasets with diverse types."
        ]
    },
    "S4.T6": {
        "caption": "TABLE VI: Ablation experimental results of Personalized Forgery Representation on the Deeperforensics-1.0 data set. The evaluation index is face forgery detection accuracy. The best result is displayed in black font and the second place is underlined.",
        "table": "<table id=\"S4.T6.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S4.T6.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T6.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">\n<span id=\"S4.T6.1.1.1.1\" class=\"ltx_text\"></span> <span id=\"S4.T6.1.1.1.2\" class=\"ltx_text\">\n<span id=\"S4.T6.1.1.1.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S4.T6.1.1.1.2.1.1\" class=\"ltx_tr\">\n<span id=\"S4.T6.1.1.1.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Personalized</span></span>\n<span id=\"S4.T6.1.1.1.2.1.2\" class=\"ltx_tr\">\n<span id=\"S4.T6.1.1.1.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Federated Learning</span></span>\n</span></span><span id=\"S4.T6.1.1.1.3\" class=\"ltx_text\"></span>\n</td>\n<td id=\"S4.T6.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">\n<span id=\"S4.T6.1.1.2.1\" class=\"ltx_text\"></span> <span id=\"S4.T6.1.1.2.2\" class=\"ltx_text\">\n<span id=\"S4.T6.1.1.2.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S4.T6.1.1.2.2.1.1\" class=\"ltx_tr\">\n<span id=\"S4.T6.1.1.2.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Personalized</span></span>\n<span id=\"S4.T6.1.1.2.2.1.2\" class=\"ltx_tr\">\n<span id=\"S4.T6.1.1.2.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Forgery Representation</span></span>\n</span></span><span id=\"S4.T6.1.1.2.3\" class=\"ltx_text\"></span>\n</td>\n<td id=\"S4.T6.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">Accuracy(%)</td>\n</tr>\n<tr id=\"S4.T6.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T6.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\">‚úì</td>\n<td id=\"S4.T6.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">-</td>\n<td id=\"S4.T6.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">94.10</td>\n</tr>\n<tr id=\"S4.T6.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T6.1.3.1\" class=\"ltx_td ltx_align_center\">-</td>\n<td id=\"S4.T6.1.3.2\" class=\"ltx_td ltx_align_center\">‚úì</td>\n<td id=\"S4.T6.1.3.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T6.1.3.3.1\" class=\"ltx_text ltx_font_bold\">98.64</span></td>\n</tr>\n<tr id=\"S4.T6.1.4\" class=\"ltx_tr\">\n<td id=\"S4.T6.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_b\">‚úì</td>\n<td id=\"S4.T6.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_b\">‚úì</td>\n<td id=\"S4.T6.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T6.1.4.3.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">97.29</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "To verify the effectiveness of personalized federated learning, we have supplemented additional ablation experiment results as follows.\nAs shown in Table VI, the result in the first row means that our method removes the personalized forgery representation learning. The accuracy rate on the Deepforensics-1.0 data set is 94.10%, which is poorer than using our federated face forgery detection learning with a personalized representation method.\nThrough this experimental result, we verified the effectiveness and advantages of personalized forgery representation. Our approach is able to take advantage of personalized forgery representation enable client models to explore more robust face forgery clues.\nThe result in the second row is our federated face forgery detection learning with a personalized representation method.\nThe method has an accuracy of 97.29% on the Deepforensics-1.0 data set.\nCompared with the method without personalized forgery representation learning, our method improves the accuracy by 3.19%, it is demonstrated that the personalized features contain attributes that are more suitable for client datasets, further improving the applicability to different types of complex forged datasets."
        ]
    }
}