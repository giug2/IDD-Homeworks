{
    "PAPER'S NUMBER OF TABLES": 4,
    "S4.T1": {
        "caption": "Table 1: Empirical ransomware dataset (as per [19])",
        "table": "<table id=\"S4.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Family</span></th>\n<td id=\"S4.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Samples</span></td>\n<td id=\"S4.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Avg. Size</span></td>\n<td id=\"S4.T1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Avg. PE File</span></td>\n</tr>\n<tr id=\"S4.T1.1.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\">Babuk (Babyk)</th>\n<td id=\"S4.T1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">140</td>\n<td id=\"S4.T1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">0.19 MB</td>\n<td id=\"S4.T1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">32.68 KB</td>\n</tr>\n<tr id=\"S4.T1.1.3.3\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">BlackCat</th>\n<td id=\"S4.T1.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">140</td>\n<td id=\"S4.T1.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">3.91 MB</td>\n<td id=\"S4.T1.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1,147 KB</td>\n</tr>\n<tr id=\"S4.T1.1.4.4\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">Chaos</th>\n<td id=\"S4.T1.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">140</td>\n<td id=\"S4.T1.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.49 MB</td>\n<td id=\"S4.T1.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">35.2 KB</td>\n</tr>\n<tr id=\"S4.T1.1.5.5\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">DJVu (STOP)</th>\n<td id=\"S4.T1.1.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">140</td>\n<td id=\"S4.T1.1.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.71 MB</td>\n<td id=\"S4.T1.1.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">66.2 KB</td>\n</tr>\n<tr id=\"S4.T1.1.6.6\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">Hive</th>\n<td id=\"S4.T1.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">140</td>\n<td id=\"S4.T1.1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">3.51 MB</td>\n<td id=\"S4.T1.1.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">403.9 KB</td>\n</tr>\n<tr id=\"S4.T1.1.7.7\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.7.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">LockBit</th>\n<td id=\"S4.T1.1.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">140</td>\n<td id=\"S4.T1.1.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.30 MB</td>\n<td id=\"S4.T1.1.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">171.5 KB</td>\n</tr>\n<tr id=\"S4.T1.1.8.8\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.8.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">Netwalker</th>\n<td id=\"S4.T1.1.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">140</td>\n<td id=\"S4.T1.1.8.8.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.26 MB</td>\n<td id=\"S4.T1.1.8.8.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">35.72 KB</td>\n</tr>\n<tr id=\"S4.T1.1.9.9\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.9.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">Sodinokibi</th>\n<td id=\"S4.T1.1.9.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">140</td>\n<td id=\"S4.T1.1.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.30 MB</td>\n<td id=\"S4.T1.1.9.9.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">50.89 KB</td>\n</tr>\n<tr id=\"S4.T1.1.10.10\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.10.10.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">WannaCry</th>\n<td id=\"S4.T1.1.10.10.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">140</td>\n<td id=\"S4.T1.1.10.10.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">7.62 MB</td>\n<td id=\"S4.T1.1.10.10.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">21.83 KB</td>\n</tr>\n<tr id=\"S4.T1.1.11.11\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.11.11.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_tt\">Benign</th>\n<td id=\"S4.T1.1.11.11.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt\">2,000</td>\n<td id=\"S4.T1.1.11.11.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt\">26.86 MB</td>\n<td id=\"S4.T1.1.11.11.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt\">155.88 KB</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Realistic datasets are critical for effective ML solutions. However, as noted in Section 2, most ransomware detection studies have at least in part, used older datasets with Windows 7 malwares. Indeed, many old ransomware control servers are no longer active as malactors have shifted to other families. In light of this, the new ransomware dataset repository curated in [19] is used. This dataset contains binary executables of some of the most prevalent ransomware threats today, as per the IBM X-Force Threat Intelligence Index, i.e., Babuk/Babyk, BlackCat, Chaos, DJVu/STOP, Hive, LockBit, Netwalker, Sodinokibi/REvil, and WannaCry (Table 1). Namely, 9 families are chosen, and a number of Windows application executables are also collected to build a benign class and improve classifier performance. As per Fig. 5, repository design involves two key steps, empirical data collection and feature extraction/selection, detailed next.",
            "In light of the above, a â€œminimalistâ€ raw dataset is collected for the 9 ransomware families [19]. Specifically, only 140 executable samples are gathered for each family, yielding a total of 1,260 malicious samples (under 1,500 samples). However, unlike some recent studies in ransomware classification [14],[15], a large number of Windows 10/11 applications are also downloaded to build a benign class (2,000 in total). These programs are collected from a range of websites and include system utility, entertainment, and productivity tools (Fig. 5). Overall, the addition of a benign class is crucial for ML purposes as it can help establish a more clear delineation between malicious programs and reduce classification errors. Further details on the collected samples are also presented in Table 1."
        ]
    },
    "S5.T2": {
        "caption": "Table 2: Aggregate dataset partitioning (1,260 ransomware and 2,000 benign samples)",
        "table": "<table id=\"S5.T2.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T2.4.5.1\" class=\"ltx_tr\">\n<th id=\"S5.T2.4.5.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"3\"><span id=\"S5.T2.4.5.1.1.1\" class=\"ltx_text ltx_font_bold\">Clients</span></th>\n<th id=\"S5.T2.4.5.1.2\" class=\"ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_t\" rowspan=\"3\"></th>\n<th id=\"S5.T2.4.5.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" colspan=\"4\"><span id=\"S5.T2.4.5.1.3.1\" class=\"ltx_text ltx_font_bold\">Ransomware</span></th>\n<th id=\"S5.T2.4.5.1.4\" class=\"ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_t\" rowspan=\"3\"></th>\n<th id=\"S5.T2.4.5.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S5.T2.4.5.1.5.1\" class=\"ltx_text ltx_font_bold\">Benign</span></th>\n<th id=\"S5.T2.4.5.1.6\" class=\"ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_t\" rowspan=\"3\"></th>\n<th id=\"S5.T2.4.5.1.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" rowspan=\"3\"><span id=\"S5.T2.4.5.1.7.1\" class=\"ltx_text ltx_font_bold\">Malware %</span></th>\n</tr>\n<tr id=\"S5.T2.4.6.2\" class=\"ltx_tr\">\n<th id=\"S5.T2.4.6.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S5.T2.4.6.2.1.1\" class=\"ltx_text ltx_font_bold\">Training</span></th>\n<th id=\"S5.T2.4.6.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S5.T2.4.6.2.2.1\" class=\"ltx_text ltx_font_bold\">Testing</span></th>\n<th id=\"S5.T2.4.6.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S5.T2.4.6.2.3.1\" class=\"ltx_text ltx_font_bold\">Training</span></th>\n<th id=\"S5.T2.4.6.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S5.T2.4.6.2.4.1\" class=\"ltx_text ltx_font_bold\">Testing</span></th>\n</tr>\n<tr id=\"S5.T2.4.7.3\" class=\"ltx_tr\">\n<th id=\"S5.T2.4.7.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Per Family</th>\n<th id=\"S5.T2.4.7.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Total</th>\n<th id=\"S5.T2.4.7.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Per Family</th>\n<th id=\"S5.T2.4.7.3.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Total</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T2.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt\">\n<math id=\"S5.T2.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"K\" display=\"inline\"><semantics id=\"S5.T2.1.1.1.m1.1a\"><mi id=\"S5.T2.1.1.1.m1.1.1\" xref=\"S5.T2.1.1.1.m1.1.1.cmml\">K</mi><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.1.1.1.m1.1b\"><ci id=\"S5.T2.1.1.1.m1.1.1.cmml\" xref=\"S5.T2.1.1.1.m1.1.1\">ğ¾</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.1.1.1.m1.1c\">K</annotation></semantics></math>=1</td>\n<td id=\"S5.T2.1.1.2\" class=\"ltx_td ltx_border_r ltx_border_tt\"></td>\n<td id=\"S5.T2.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">120</td>\n<td id=\"S5.T2.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">1,080</td>\n<td id=\"S5.T2.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">20</td>\n<td id=\"S5.T2.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">180</td>\n<td id=\"S5.T2.1.1.7\" class=\"ltx_td ltx_border_r ltx_border_tt\"></td>\n<td id=\"S5.T2.1.1.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">1,700</td>\n<td id=\"S5.T2.1.1.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">300</td>\n<td id=\"S5.T2.1.1.10\" class=\"ltx_td ltx_border_r ltx_border_tt\"></td>\n<td id=\"S5.T2.1.1.11\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">38%</td>\n</tr>\n<tr id=\"S5.T2.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T2.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">\n<math id=\"S5.T2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"K\" display=\"inline\"><semantics id=\"S5.T2.2.2.1.m1.1a\"><mi id=\"S5.T2.2.2.1.m1.1.1\" xref=\"S5.T2.2.2.1.m1.1.1.cmml\">K</mi><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.2.2.1.m1.1b\"><ci id=\"S5.T2.2.2.1.m1.1.1.cmml\" xref=\"S5.T2.2.2.1.m1.1.1\">ğ¾</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.2.2.1.m1.1c\">K</annotation></semantics></math>=2</td>\n<td id=\"S5.T2.2.2.2\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S5.T2.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">60</td>\n<td id=\"S5.T2.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">540</td>\n<td id=\"S5.T2.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">20</td>\n<td id=\"S5.T2.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">180</td>\n<td id=\"S5.T2.2.2.7\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S5.T2.2.2.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1,700</td>\n<td id=\"S5.T2.2.2.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">300</td>\n<td id=\"S5.T2.2.2.10\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S5.T2.2.2.11\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">24%</td>\n</tr>\n<tr id=\"S5.T2.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T2.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">\n<math id=\"S5.T2.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"K\" display=\"inline\"><semantics id=\"S5.T2.3.3.1.m1.1a\"><mi id=\"S5.T2.3.3.1.m1.1.1\" xref=\"S5.T2.3.3.1.m1.1.1.cmml\">K</mi><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.3.3.1.m1.1b\"><ci id=\"S5.T2.3.3.1.m1.1.1.cmml\" xref=\"S5.T2.3.3.1.m1.1.1\">ğ¾</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.3.3.1.m1.1c\">K</annotation></semantics></math>=3</td>\n<td id=\"S5.T2.3.3.2\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S5.T2.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">40</td>\n<td id=\"S5.T2.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">360</td>\n<td id=\"S5.T2.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">20</td>\n<td id=\"S5.T2.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">180</td>\n<td id=\"S5.T2.3.3.7\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S5.T2.3.3.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1,700</td>\n<td id=\"S5.T2.3.3.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">300</td>\n<td id=\"S5.T2.3.3.10\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S5.T2.3.3.11\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">17%</td>\n</tr>\n<tr id=\"S5.T2.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T2.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">\n<math id=\"S5.T2.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"K\" display=\"inline\"><semantics id=\"S5.T2.4.4.1.m1.1a\"><mi id=\"S5.T2.4.4.1.m1.1.1\" xref=\"S5.T2.4.4.1.m1.1.1.cmml\">K</mi><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.4.4.1.m1.1b\"><ci id=\"S5.T2.4.4.1.m1.1.1.cmml\" xref=\"S5.T2.4.4.1.m1.1.1\">ğ¾</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.4.4.1.m1.1c\">K</annotation></semantics></math>=4</td>\n<td id=\"S5.T2.4.4.2\" class=\"ltx_td ltx_border_b ltx_border_r ltx_border_t\"></td>\n<td id=\"S5.T2.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">30</td>\n<td id=\"S5.T2.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">270</td>\n<td id=\"S5.T2.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">20</td>\n<td id=\"S5.T2.4.4.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">180</td>\n<td id=\"S5.T2.4.4.7\" class=\"ltx_td ltx_border_b ltx_border_r ltx_border_t\"></td>\n<td id=\"S5.T2.4.4.8\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">1,700</td>\n<td id=\"S5.T2.4.4.9\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">300</td>\n<td id=\"S5.T2.4.4.10\" class=\"ltx_td ltx_border_b ltx_border_r ltx_border_t\"></td>\n<td id=\"S5.T2.4.4.11\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">14%</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "FL performance is tested for a varying number of client sites (Kğ¾K=2, 3, 4) by partitioning the ML training/testing dataset, see Table 2. Recall that this aggregate dataset contains feature vectors (samples) for each raw binary file (where each feature vector contains 15 extracted PE file parameters, Fig. 5). Now there are 140 samples per family and 2,000 benign applications, i.e., total of 10 classes. Hence 120 samples from each ransomware family are randomly selected for training (1,080 total) and the remaining 20 are used for testing (180 total). This partitioning represents a 85/15% split between training and testing data. Next, the 120 ransomware samples (per class) are further partitioned between the client sites, yielding several local ML training datasets, i.e., full 120 samples per class for Kğ¾K=1 (centralized ML), 60 samples per class for Kğ¾K=2 client sites (540 total), 40 samples per class for Kğ¾K=3 client sites (360 total), and 30 samples per class for Kğ¾K=4 client sites (270 total), see Table 2. Meanwhile the benign dataset is not partitioned between the client sites, thereby yielding a higher percentage of non-malicious training data. This choice mirrors realistic settings where regular applications downloads will exceed ransomware downloads. Moreover, there may be high commonality between application downloads across organizations, and hence it is plausible to use the same set of benign samples across client sites. Accordingly, the benign samples are split in a 85/15% manner, with 1,700 samples randomly selected for training and the remaining 300 for testing (per client site). Overall, the proportion of ransomware training data declines with the number of client sites, i.e., malware percentage, Table 2. For example, with 4 client sites there is more than 6 times less training data (i.e., 270 vs 1,700 samples).\nCarefully note that in practice, different regions (client sites) will experience varying types of ransomware attacks. These differences will yield unbalanced datasets with possibly different underlying distributions, and are left for future study.",
            "Next, the performance of all ML classifiers is presented in Table 4.\nHere the respective FL percentages are the same as the global model averages from Table 3. First consider multi-class attribution, as measured by the accuracy, precision, recall, and F1 scores. Foremost, the FL approach outperforms its centralized FNN counterpart for varying numbers of client sites. In particular with Kğ¾K=4 client sites the accuracy and F1 scores are 1% higher. These gains come despite using much smaller training datasets at the client sites, e.g., only 270 ransomware samples for Kğ¾K=4, Table 2. Again, this is another key result as it demonstrates the ability of decentralized FL setups (with smaller client sites) to achieve similar or better ransomware attribution compared to less practical centralized setups (requiring much more training data). Furthermore, the FL approach also outperforms the SVM algorithm by over 2% in terms of accuracy. However, the centralized RF scheme (trained with global data) gives the best results, with accuracy and F1 scores averaging about 3.5% higher than FL.",
            "Also, Table 4 presents binary detection results, as measured by the RDR and BDR metrics (Eqs. 1, 2). The former is deemed more important as it captures the mis-classification rate of ransomware. Overall, FL gives very good RDR values, up to 94.92%, and within 1% of the RF scheme which has the best binary results. Namely, this scheme yields a false negative rate of about 1 in 20 malicious samples. These results are impressive and match those from earlier studies on binary detection of older ransomware threats, Section 2. Also, the BDR values are higher than the RDR values since training datasets have a larger proportion of benign data as per real-world settings (Table 2). Note that the FNN-based schemes (including distributed FL) give slightly lower BDR values than the other ML algorithms, i.e., by about 1-2.5%. Nevertheless, the related BDR percentages are still close to 97%, i.e., 1 error in about 33 benign samples.",
            "To investigate detailed per-class behaviors, Fig. 6 shows a sample averaged confusion matrix for FL with 4 client sites (rows 0-9 represent ransomware families and row 10 represents benign applications). Note that the numbers in row 10 are larger as there are more benign testing samples, Table 2. Here, the majority of ransomware and benign application samples are correctly classified, i.e., diagonal entries dominate. Furthermore, most mis-attributed ransomware samples are still classified as some form of ransomware, although LockBit and Babuk show higher averages, i.e., 4.5 (22.5%) and 3.5 (17.5%) out of 20, respectively. Hence the potential damage from false negatives is relatively small for most ransomware cases. Meanwhile, Fig. 7 plots the average accuracy and F1 scores for the global FL model with Kğ¾K=4 client sites and varying epoch counts (Eğ¸E). These results shed light on the local FL training process and indicate better performance with Eğ¸E=4 epochs (also observed for several other Kğ¾K values)."
        ]
    },
    "S5.T3": {
        "caption": "Table 3: Results for FL with varying client sites, Kğ¾K (FedAvg)",
        "table": "<table id=\"S5.T3.5\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T3.5.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T3.5.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\"><span id=\"S5.T3.5.1.1.1.1\" class=\"ltx_text ltx_font_bold\">2 Client Sites</span></th>\n<th id=\"S5.T3.5.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S5.T3.5.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Accuracy</span></th>\n<th id=\"S5.T3.5.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S5.T3.5.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Precision</span></th>\n<th id=\"S5.T3.5.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S5.T3.5.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Recall</span></th>\n<th id=\"S5.T3.5.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S5.T3.5.1.1.5.1\" class=\"ltx_text ltx_font_bold\">F1 Score</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T3.5.2.1\" class=\"ltx_tr\">\n<th id=\"S5.T3.5.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_tt\">Global Avg. Model</th>\n<td id=\"S5.T3.5.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">\n<span id=\"S5.T3.5.2.1.2.1\" class=\"ltx_text ltx_font_bold\">91.87</span>%</td>\n<td id=\"S5.T3.5.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">\n<span id=\"S5.T3.5.2.1.3.1\" class=\"ltx_text ltx_font_bold\">86.01</span>%</td>\n<td id=\"S5.T3.5.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">\n<span id=\"S5.T3.5.2.1.4.1\" class=\"ltx_text ltx_font_bold\">86.67</span>%</td>\n<td id=\"S5.T3.5.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">\n<span id=\"S5.T3.5.2.1.5.1\" class=\"ltx_text ltx_font_bold\">91.82</span>%</td>\n</tr>\n<tr id=\"S5.T3.5.3.2\" class=\"ltx_tr\">\n<th id=\"S5.T3.5.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">Â Â Â Â Â Â  Client site 1</th>\n<td id=\"S5.T3.5.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">86.52%</td>\n<td id=\"S5.T3.5.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">78.57%</td>\n<td id=\"S5.T3.5.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">79.37%</td>\n<td id=\"S5.T3.5.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">86.30%</td>\n</tr>\n<tr id=\"S5.T3.5.4.3\" class=\"ltx_tr\">\n<th id=\"S5.T3.5.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">Â Â Â Â Â Â  Client site 2</th>\n<td id=\"S5.T3.5.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">88.34%</td>\n<td id=\"S5.T3.5.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">78.59%</td>\n<td id=\"S5.T3.5.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">79.22%</td>\n<td id=\"S5.T3.5.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">87.34%</td>\n</tr>\n<tr id=\"S5.T3.5.5.4\" class=\"ltx_tr\">\n<th id=\"S5.T3.5.5.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\"><span id=\"S5.T3.5.5.4.1.1\" class=\"ltx_text ltx_font_bold\">3 Client Sites</span></th>\n<td id=\"S5.T3.5.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T3.5.5.4.2.1\" class=\"ltx_text ltx_font_bold\">Accuracy</span></td>\n<td id=\"S5.T3.5.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T3.5.5.4.3.1\" class=\"ltx_text ltx_font_bold\">Precision</span></td>\n<td id=\"S5.T3.5.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T3.5.5.4.4.1\" class=\"ltx_text ltx_font_bold\">Recall</span></td>\n<td id=\"S5.T3.5.5.4.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T3.5.5.4.5.1\" class=\"ltx_text ltx_font_bold\">F1 Score</span></td>\n</tr>\n<tr id=\"S5.T3.5.6.5\" class=\"ltx_tr\">\n<th id=\"S5.T3.5.6.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_tt\">Global Avg. Model</th>\n<td id=\"S5.T3.5.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span id=\"S5.T3.5.6.5.2.1\" class=\"ltx_text ltx_font_bold\">92.11%</span></td>\n<td id=\"S5.T3.5.6.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span id=\"S5.T3.5.6.5.3.1\" class=\"ltx_text ltx_font_bold\">87.40%</span></td>\n<td id=\"S5.T3.5.6.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span id=\"S5.T3.5.6.5.4.1\" class=\"ltx_text ltx_font_bold\">86.57%</span></td>\n<td id=\"S5.T3.5.6.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span id=\"S5.T3.5.6.5.5.1\" class=\"ltx_text ltx_font_bold\">91.90%</span></td>\n</tr>\n<tr id=\"S5.T3.5.7.6\" class=\"ltx_tr\">\n<th id=\"S5.T3.5.7.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">Â Â Â Â Â Â  Client site 1</th>\n<td id=\"S5.T3.5.7.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">86.02%</td>\n<td id=\"S5.T3.5.7.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">77.86%</td>\n<td id=\"S5.T3.5.7.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">75.64%</td>\n<td id=\"S5.T3.5.7.6.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">85.33%</td>\n</tr>\n<tr id=\"S5.T3.5.8.7\" class=\"ltx_tr\">\n<th id=\"S5.T3.5.8.7.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">Â Â Â Â Â Â  Client site 2</th>\n<td id=\"S5.T3.5.8.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">82.90%</td>\n<td id=\"S5.T3.5.8.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">73.89%</td>\n<td id=\"S5.T3.5.8.7.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">74.56%</td>\n<td id=\"S5.T3.5.8.7.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">82.13%</td>\n</tr>\n<tr id=\"S5.T3.5.9.8\" class=\"ltx_tr\">\n<th id=\"S5.T3.5.9.8.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">Â Â Â Â Â Â  Client site 3</th>\n<td id=\"S5.T3.5.9.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">81.47%</td>\n<td id=\"S5.T3.5.9.8.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">73.55%</td>\n<td id=\"S5.T3.5.9.8.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">75.95%</td>\n<td id=\"S5.T3.5.9.8.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">81.49%</td>\n</tr>\n<tr id=\"S5.T3.5.10.9\" class=\"ltx_tr\">\n<th id=\"S5.T3.5.10.9.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\"><span id=\"S5.T3.5.10.9.1.1\" class=\"ltx_text ltx_font_bold\">4 Client Sites</span></th>\n<td id=\"S5.T3.5.10.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T3.5.10.9.2.1\" class=\"ltx_text ltx_font_bold\">Accuracy</span></td>\n<td id=\"S5.T3.5.10.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T3.5.10.9.3.1\" class=\"ltx_text ltx_font_bold\">Precision</span></td>\n<td id=\"S5.T3.5.10.9.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T3.5.10.9.4.1\" class=\"ltx_text ltx_font_bold\">Recall</span></td>\n<td id=\"S5.T3.5.10.9.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T3.5.10.9.5.1\" class=\"ltx_text ltx_font_bold\">F1 Score</span></td>\n</tr>\n<tr id=\"S5.T3.5.11.10\" class=\"ltx_tr\">\n<th id=\"S5.T3.5.11.10.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_tt\">Global Avg. Model</th>\n<td id=\"S5.T3.5.11.10.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span id=\"S5.T3.5.11.10.2.1\" class=\"ltx_text ltx_font_bold\">92.46%</span></td>\n<td id=\"S5.T3.5.11.10.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span id=\"S5.T3.5.11.10.3.1\" class=\"ltx_text ltx_font_bold\">87.69%</span></td>\n<td id=\"S5.T3.5.11.10.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span id=\"S5.T3.5.11.10.4.1\" class=\"ltx_text ltx_font_bold\">86.40%</span></td>\n<td id=\"S5.T3.5.11.10.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span id=\"S5.T3.5.11.10.5.1\" class=\"ltx_text ltx_font_bold\">92.43%</span></td>\n</tr>\n<tr id=\"S5.T3.5.12.11\" class=\"ltx_tr\">\n<th id=\"S5.T3.5.12.11.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">Â Â Â Â Â Â  Client site 1</th>\n<td id=\"S5.T3.5.12.11.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">79.93%</td>\n<td id=\"S5.T3.5.12.11.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">72.22%</td>\n<td id=\"S5.T3.5.12.11.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">72.61%</td>\n<td id=\"S5.T3.5.12.11.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">79.53%</td>\n</tr>\n<tr id=\"S5.T3.5.13.12\" class=\"ltx_tr\">\n<th id=\"S5.T3.5.13.12.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">Â Â Â Â Â Â  Client site 2</th>\n<td id=\"S5.T3.5.13.12.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">83.70%</td>\n<td id=\"S5.T3.5.13.12.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">73.29%</td>\n<td id=\"S5.T3.5.13.12.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">74.41%</td>\n<td id=\"S5.T3.5.13.12.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">83.48%</td>\n</tr>\n<tr id=\"S5.T3.5.14.13\" class=\"ltx_tr\">\n<th id=\"S5.T3.5.14.13.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">Â Â Â Â Â Â  Client site 3</th>\n<td id=\"S5.T3.5.14.13.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">85.48%</td>\n<td id=\"S5.T3.5.14.13.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">71.91%</td>\n<td id=\"S5.T3.5.14.13.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">71.73%</td>\n<td id=\"S5.T3.5.14.13.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">83.76%</td>\n</tr>\n<tr id=\"S5.T3.5.15.14\" class=\"ltx_tr\">\n<th id=\"S5.T3.5.15.14.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_rr ltx_border_t\">Â Â Â Â Â Â  Client site 4</th>\n<td id=\"S5.T3.5.15.14.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">85.49%</td>\n<td id=\"S5.T3.5.15.14.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">72.23%</td>\n<td id=\"S5.T3.5.15.14.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">71.41%</td>\n<td id=\"S5.T3.5.15.14.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">80.20%</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Detailed results for the FL scheme are first presented in Table 3 for varying numbers of client sites (Kğ¾K values). In each case, the table lists the accuracy, precision, recall, and F1 scores for the global averaged FNN model (in bold) followed by the individual local client site models. These findings show vastly improved model generalization with FL, with the global models exceeding the individual client models by sizeable margins for all metrics. For example, average accuracy is 3-12% higher, precision is 7-15% higher, recall is 7-15% higher, and F1 scores are 4-13% higher. These are very impressive results and indicate that organizations can greatly improve their ransomware defenses by participating in FL-based schemes, i.e., while retaining data privacy and maintaining smaller datasets. Furthermore, FL accuracy is also very high. For example, the accuracy (and F1 score) with 4 client sites is close to 92.5%, i.e., correct attribution of over 18 out of 20 samples. These results also closely match some centralized ransomware classification schemes (Section 2.1) many of which implement heavier feature extraction and ML computation algorithms, e.g., image and entropy-based features, deep NN designs, etc [14],[15]. By contrast, the FL setup herein uses very small feature vectors (15 parameters) and basic FNN models.",
            "Next, the performance of all ML classifiers is presented in Table 4.\nHere the respective FL percentages are the same as the global model averages from Table 3. First consider multi-class attribution, as measured by the accuracy, precision, recall, and F1 scores. Foremost, the FL approach outperforms its centralized FNN counterpart for varying numbers of client sites. In particular with Kğ¾K=4 client sites the accuracy and F1 scores are 1% higher. These gains come despite using much smaller training datasets at the client sites, e.g., only 270 ransomware samples for Kğ¾K=4, Table 2. Again, this is another key result as it demonstrates the ability of decentralized FL setups (with smaller client sites) to achieve similar or better ransomware attribution compared to less practical centralized setups (requiring much more training data). Furthermore, the FL approach also outperforms the SVM algorithm by over 2% in terms of accuracy. However, the centralized RF scheme (trained with global data) gives the best results, with accuracy and F1 scores averaging about 3.5% higher than FL."
        ]
    },
    "S5.T4": {
        "caption": "Table 4: Results for ML models (averaged over 50 independent runs)",
        "table": "<table id=\"S5.T4.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T4.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S5.T4.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Distd. FL</span></th>\n<td id=\"S5.T4.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S5.T4.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Accuracy</span></td>\n<td id=\"S5.T4.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S5.T4.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Precision</span></td>\n<td id=\"S5.T4.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S5.T4.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Recall</span></td>\n<th id=\"S5.T4.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_t\" rowspan=\"2\"><span id=\"S5.T4.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">F1 Score</span></th>\n<td id=\"S5.T4.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S5.T4.1.1.1.6.1\" class=\"ltx_text ltx_font_bold\">Binary</span></td>\n</tr>\n<tr id=\"S5.T4.1.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T4.1.2.2.1.1\" class=\"ltx_text ltx_font_bold\">RDR</span></td>\n<td id=\"S5.T4.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T4.1.2.2.2.1\" class=\"ltx_text ltx_font_bold\">BDR</span></td>\n</tr>\n<tr id=\"S5.T4.1.3.3\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">2 clients (FNN)</th>\n<td id=\"S5.T4.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">91.87%</td>\n<td id=\"S5.T4.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">86.01%</td>\n<td id=\"S5.T4.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">86.67%</td>\n<th id=\"S5.T4.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_t\">91.82%</th>\n<td id=\"S5.T4.1.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">94.92%</td>\n<td id=\"S5.T4.1.3.3.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">94.99%</td>\n</tr>\n<tr id=\"S5.T4.1.4.4\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">3 clients (FNN)</th>\n<td id=\"S5.T4.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">92.11%</td>\n<td id=\"S5.T4.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">87.40%</td>\n<td id=\"S5.T4.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">86.57%</td>\n<th id=\"S5.T4.1.4.4.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_t\">91.90%</th>\n<td id=\"S5.T4.1.4.4.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">93.04%</td>\n<td id=\"S5.T4.1.4.4.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">95.86%</td>\n</tr>\n<tr id=\"S5.T4.1.5.5\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.5.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">4 clients (FNN)</th>\n<td id=\"S5.T4.1.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">92.46%</td>\n<td id=\"S5.T4.1.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">87.69%</td>\n<td id=\"S5.T4.1.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">86.40%</td>\n<th id=\"S5.T4.1.5.5.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_t\">92.43%</th>\n<td id=\"S5.T4.1.5.5.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">93.27%</td>\n<td id=\"S5.T4.1.5.5.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">96.43%</td>\n</tr>\n<tr id=\"S5.T4.1.6.6\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.6.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S5.T4.1.6.6.1.1\" class=\"ltx_text ltx_font_bold\">Centralized</span></th>\n<td id=\"S5.T4.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S5.T4.1.6.6.2.1\" class=\"ltx_text ltx_font_bold\">Accuracy</span></td>\n<td id=\"S5.T4.1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S5.T4.1.6.6.3.1\" class=\"ltx_text ltx_font_bold\">Precision</span></td>\n<td id=\"S5.T4.1.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S5.T4.1.6.6.4.1\" class=\"ltx_text ltx_font_bold\">Recall</span></td>\n<th id=\"S5.T4.1.6.6.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_t\" rowspan=\"2\"><span id=\"S5.T4.1.6.6.5.1\" class=\"ltx_text ltx_font_bold\">F1 Score</span></th>\n<td id=\"S5.T4.1.6.6.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S5.T4.1.6.6.6.1\" class=\"ltx_text ltx_font_bold\">Binary</span></td>\n</tr>\n<tr id=\"S5.T4.1.7.7\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.7.7.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T4.1.7.7.1.1\" class=\"ltx_text ltx_font_bold\">RDR</span></td>\n<td id=\"S5.T4.1.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T4.1.7.7.2.1\" class=\"ltx_text ltx_font_bold\">BDR</span></td>\n</tr>\n<tr id=\"S5.T4.1.8.8\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.8.8.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_tt\">FNN</th>\n<td id=\"S5.T4.1.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">91.48%</td>\n<td id=\"S5.T4.1.8.8.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">86.84%</td>\n<td id=\"S5.T4.1.8.8.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">84.68%</td>\n<th id=\"S5.T4.1.8.8.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_tt\">91.27%</th>\n<td id=\"S5.T4.1.8.8.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">92.06%</td>\n<td id=\"S5.T4.1.8.8.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">96.69%</td>\n</tr>\n<tr id=\"S5.T4.1.9.9\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.9.9.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_tt\">SVM</th>\n<td id=\"S5.T4.1.9.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">90.44%</td>\n<td id=\"S5.T4.1.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">91.16%</td>\n<td id=\"S5.T4.1.9.9.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">75.60%</td>\n<th id=\"S5.T4.1.9.9.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_tt\">89.86%</th>\n<td id=\"S5.T4.1.9.9.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">80.39%</td>\n<td id=\"S5.T4.1.9.9.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">97.85%</td>\n</tr>\n<tr id=\"S5.T4.1.10.10\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.10.10.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_rr ltx_border_t\">RF</th>\n<td id=\"S5.T4.1.10.10.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">96.02%</td>\n<td id=\"S5.T4.1.10.10.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">94.41%</td>\n<td id=\"S5.T4.1.10.10.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">92.07%</td>\n<th id=\"S5.T4.1.10.10.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_rr ltx_border_t\">95.98%</th>\n<td id=\"S5.T4.1.10.10.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">95.72%</td>\n<td id=\"S5.T4.1.10.10.7\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">99.05%</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Next, the performance of all ML classifiers is presented in Table 4.\nHere the respective FL percentages are the same as the global model averages from Table 3. First consider multi-class attribution, as measured by the accuracy, precision, recall, and F1 scores. Foremost, the FL approach outperforms its centralized FNN counterpart for varying numbers of client sites. In particular with Kğ¾K=4 client sites the accuracy and F1 scores are 1% higher. These gains come despite using much smaller training datasets at the client sites, e.g., only 270 ransomware samples for Kğ¾K=4, Table 2. Again, this is another key result as it demonstrates the ability of decentralized FL setups (with smaller client sites) to achieve similar or better ransomware attribution compared to less practical centralized setups (requiring much more training data). Furthermore, the FL approach also outperforms the SVM algorithm by over 2% in terms of accuracy. However, the centralized RF scheme (trained with global data) gives the best results, with accuracy and F1 scores averaging about 3.5% higher than FL.",
            "Also, Table 4 presents binary detection results, as measured by the RDR and BDR metrics (Eqs. 1, 2). The former is deemed more important as it captures the mis-classification rate of ransomware. Overall, FL gives very good RDR values, up to 94.92%, and within 1% of the RF scheme which has the best binary results. Namely, this scheme yields a false negative rate of about 1 in 20 malicious samples. These results are impressive and match those from earlier studies on binary detection of older ransomware threats, Section 2. Also, the BDR values are higher than the RDR values since training datasets have a larger proportion of benign data as per real-world settings (Table 2). Note that the FNN-based schemes (including distributed FL) give slightly lower BDR values than the other ML algorithms, i.e., by about 1-2.5%. Nevertheless, the related BDR percentages are still close to 97%, i.e., 1 error in about 33 benign samples."
        ]
    }
}