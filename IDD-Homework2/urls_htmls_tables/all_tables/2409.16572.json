{
    "id_table_1": {
        "caption": "Table 1 :  Computational cost comparison between training nested FNO and nested Fourier-DeepONet . Fourier-DeepONet uses a time batch size of 6, while FNO is required to use all 24 time batches.",
        "table": "S4.T1.5",
        "footnotes": [
            ""
        ],
        "references": [
            "Eqs. ( 1 ) and ( 2 ) represent the law of conservation of mass for the two species within the system: CO 2  and water. On the left side of the equations,   italic- \\phi italic_  denotes the porosity of the media,  S S S italic_S  represents the saturation,    \\rho italic_  stands for density, and  X X X italic_X  signifies the mass fraction of each species, with the subscript  p p p italic_p  indicating the phase. Lastly,  q C  O 2 superscript q C subscript O 2 q^{CO_{2}} italic_q start_POSTSUPERSCRIPT italic_C italic_O start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT  denotes the injection rate of CO 2 .",
            "In this work, we aim to predict pressure buildup and gas saturation over a 30-year period based on reservoir conditions (i.e., permeability field, temperature, and initial pressure) and the injection scheme (i.e., injection rate and location) (Fig.  1 ).",
            "As we have five levels of resolutions for predicting pressure buildup and gas saturation, we train one ML model per level (Fig.  1 ). The output from each levels model is used as an input for the subsequent levels model, in conjunction with reservoir conditions and the injection scheme. Among the five resolution levels, only a model at level 0 does not use predictions from a previous levels, as it is the initial stage of the nested framework. Consequently, this results in a total of five models for predicting pressure buildup. In contrast, there are four models for gas saturation prediction, as no model is trained for gas saturation at level 0.",
            "Fourier-DeepONet used for each level is denoted as  N i P subscript superscript N P i \\mathcal{N}^{P}_{i} caligraphic_N start_POSTSUPERSCRIPT italic_P end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , where  i i i italic_i  in the subscript denotes the level of resolution in Fig.  1  for pressure buildup prediction. Similarly, for the prediction of gas saturation, we denote the neural operator as  N i S subscript superscript N S i \\mathcal{N}^{S}_{i} caligraphic_N start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  and we only train from level 1 to 4. The spatial domains of Fourier-DeepONets at five different levels are   0 ,  1 ,  2 ,  3 ,  4 subscript  0 subscript  1 subscript  2 subscript  3 subscript  4 \\Omega_{0},\\Omega_{1},\\Omega_{2},\\Omega_{3},\\Omega_{4} roman_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , roman_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , roman_ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , roman_ start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , roman_ start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT  (Fig.  2 ). The entire spatial and temporal domain of each Fourier-DeepONet is  D =  i  T D subscript  i T D=\\Omega_{i}\\times T italic_D = roman_ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  italic_T , and  T T T italic_T  denotes the temporal domain up to 30 years. The architecture of each Fourier-DeepONet in nested Fourier-DeepONet, including the output shape of each operation for levels 0 to 4, is shown in Tables  3 ,  4 , and  5  in the Appendix  A .",
            "As discussed in Section  3.1 , the reduced dimension of FFT and flexible batch size for time coordinates result in twice faster training and significant (at least 80%) reduction in GPU memory consumption (Table  1 ), enabling the training of Fourier-DeepONets even on GPUs with limited memory. Additionally, they lead to a substantial reduction of more than 80% in the number of trainable parameters, both at global and local resolutions, compared to FNO in Ref.  [ 36 ] .",
            "To further investigate the generalizability of nested Fourier-DeepONet on unseen datasets, we conducted experiments to assess its performance under different extrapolation scenarios in terms of reservoir conditions (Sections  4.4.1  and  4.4.2 ), injection schemes (Section  4.4.3 ), and temporal coordinates (Section  4.4.4 ). For temporal extrapolation, we train models based on the first 21 time snapshots out of 24 while using all training samples.",
            "The final experiment involves a temporal extrapolation. Instead of training a model with a reduced number of reservoir samples as in Sections  4.4.1  to  4.4.3 , we train models with a limited number of time snapshots (21 out of 24) up to 15 years to assess their generalization capabilities up to 30 years. We train both a nested Fourier-DeepONet and a nested FNO to demonstrate the superior performance of a nested Fourier-DeepONet in temporal extrapolation."
        ]
    },
    "id_table_2": {
        "caption": "Table 2 :  Accuracy comparison for nested Fourier-DeepONet and nested FNO . For nested FNOs, we include the errors from Ref.  [ 36 ]  and the errors from our own FNOs trained using their public code. Bold font indicates the two smallest errors per row.",
        "table": "S4.T2.11",
        "footnotes": [
            ""
        ],
        "references": [
            "The paper is organized as follows. In Section  2 , we introduce the problem setup, including the governing equations of multiphase flow and the dataset generated by numerical simulation. In Section  3 , after providing a brief overview of DeepONet and FNO, we propose a nested Fourier-DeepONet. In Section  4 , we highlight the superior computational efficiency of the nested Fourier-DeepONet compared to the nested FNO and demonstrate its generalization capabilities. We summarize the significance of this work in Section  5 .",
            "Eqs. ( 1 ) and ( 2 ) represent the law of conservation of mass for the two species within the system: CO 2  and water. On the left side of the equations,   italic- \\phi italic_  denotes the porosity of the media,  S S S italic_S  represents the saturation,    \\rho italic_  stands for density, and  X X X italic_X  signifies the mass fraction of each species, with the subscript  p p p italic_p  indicating the phase. Lastly,  q C  O 2 superscript q C subscript O 2 q^{CO_{2}} italic_q start_POSTSUPERSCRIPT italic_C italic_O start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT  denotes the injection rate of CO 2 .",
            "Grid resolution significantly impacts the accuracy of simulations, creating a trade-off between accuracy and computational cost. As discussed in the Introduction, local refinement technique is commonly used to address this challenge. This refinement technique uses increasing grid resolution with decreasing distance from the injection location. In this study, we employ the grid refinement used in Ref.  [ 36 ] . In total, we have five levels of resolutions where level 0 indicates a global level, and four remaining levels (14) represent increased resolution near the well (Fig.  2 ). A higher level indicates a finer resolution and closer distance to the injection location. The details of the discretization are presented in Table S1 of Wen et al.  [ 36 ] .",
            "As discussed in Section  2.2 , to predict pressure buildup, we have five levels of grid resolution that result in five different Fourier-DeepONets. For gas saturation prediction, we use four different Fourier-DeepONets for the four resolution levels. We train each Fourier-DeepONet independently at each level for each output and make a nested prediction starting from level 0 up to level 4.",
            "Fourier-DeepONet used for each level is denoted as  N i P subscript superscript N P i \\mathcal{N}^{P}_{i} caligraphic_N start_POSTSUPERSCRIPT italic_P end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , where  i i i italic_i  in the subscript denotes the level of resolution in Fig.  1  for pressure buildup prediction. Similarly, for the prediction of gas saturation, we denote the neural operator as  N i S subscript superscript N S i \\mathcal{N}^{S}_{i} caligraphic_N start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  and we only train from level 1 to 4. The spatial domains of Fourier-DeepONets at five different levels are   0 ,  1 ,  2 ,  3 ,  4 subscript  0 subscript  1 subscript  2 subscript  3 subscript  4 \\Omega_{0},\\Omega_{1},\\Omega_{2},\\Omega_{3},\\Omega_{4} roman_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , roman_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , roman_ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , roman_ start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , roman_ start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT  (Fig.  2 ). The entire spatial and temporal domain of each Fourier-DeepONet is  D =  i  T D subscript  i T D=\\Omega_{i}\\times T italic_D = roman_ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  italic_T , and  T T T italic_T  denotes the temporal domain up to 30 years. The architecture of each Fourier-DeepONet in nested Fourier-DeepONet, including the output shape of each operation for levels 0 to 4, is shown in Tables  3 ,  4 , and  5  in the Appendix  A .",
            "We adopt a fine-tuning procedure by adding a random perturbation to the network inputs as introduced in Ref.  [ 36 ] . Specifically for training the subsequent levels model, we perturb the ground truth output from the previous level by adding the randomly sampled model error. For instance, after the training procedure described in Section  3.2.2 , to fine-tune the pressure buildup model at level  i i i italic_i , the model is further trained using the noised input computed as follows:",
            "In addition to the computational efficiency, nested Fourier-DeepONet demonstrates similar or better accuracy for predicting pressure buildup. We compare the accuracy of Fourier-DeepONets and the state-of-the-art FNOs  [ 36 ]  at all levels in Table  2 . As the code for computing the evaluation metrics from Ref.  [ 36 ]  was not public, we implemented our own code for Eqs. ( 3 )( 6 ). For the accuracy of FNO, we include the accuracy from Ref.  [ 36 ]  and we also report the accuracy from our own FNOs trained using their public code but evaluated using our evaluation metric code.",
            "Regardless of whether the models are fine-tuned or not, nested Fourier-DeepONet showcases superior performances across all levels compared with nested FNO we trained. Because errors in Table  2  accumulate at each subsequent level, to demonstrate the accuracy of each individual network, we present the test errors using ground truth input in Table  6  in Appendix  B . For individual networks, Fourier-DeepONet has better accuracy for almost all levels except level 3 for the prediction of pressure buildup.",
            "For gas saturation network models, the accuracy of nested Fourier-DeepONet and nested FNO is also shown in Table  2 . As mentioned in Section  3.4 , we do not train the gas saturation model at the global level. As we were able to achieve better accuracy at the global level (   0 P subscript superscript  P subscript  0 \\delta^{P}_{\\Omega_{0}} italic_ start_POSTSUPERSCRIPT italic_P end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) and level 1 (   1 S subscript superscript  S subscript  1 \\delta^{S}_{\\Omega_{1}} italic_ start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) for individual prediction (Table  6 ), the cumulative error arising from earlier levels resulted in lower accuracy with Fourier-DeepONets for both fine-tuned models and those without tuning. This highlights the importance of achieving robust accuracy at earlier levels when using a nested framework.",
            "To further investigate the generalizability of nested Fourier-DeepONet on unseen datasets, we conducted experiments to assess its performance under different extrapolation scenarios in terms of reservoir conditions (Sections  4.4.1  and  4.4.2 ), injection schemes (Section  4.4.3 ), and temporal coordinates (Section  4.4.4 ). For temporal extrapolation, we train models based on the first 21 time snapshots out of 24 while using all training samples.",
            "We observe comparable errors for predictions on reservoirs with 13 wells (i.e. interpolation) between the baseline model and the model trained with 13 wells (Fig.  7 A). The baseline model refers to the nested Fourier-DeepONet without fine-tuning in Table  2 , which has been trained on the entire dataset. For reservoirs with 4 wells, the third quartile of error in predicting pressure buildup using the extrapolation model is below 2%. This result suggests that the nested Fourier-DeepONet demonstrates strong generalization capabilities across different well configurations.",
            "The network architectures of Fourier-DeepONets for all levels mentioned in Section  3.2  are shown in Tables  3 ,  4 , and  5 .",
            "Table  6  shows the test accuracy of the nested Fourier-DeepONet and nested FNO models, where ground truth outputs from the previous level are used for  N i P subscript superscript N P i \\mathcal{N}^{P}_{i} caligraphic_N start_POSTSUPERSCRIPT italic_P end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  and  N i S subscript superscript N S i \\mathcal{N}^{S}_{i} caligraphic_N start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , with  i i i italic_i  = 14. Although this approach is not feasible in practice, it allows us to assess how well the model was trained at each individual level. Table  2  corresponds to the sequential prediction accuracy, while Table  6  represents the separate prediction accuracy, as presented in Table 7 of Ref.  [ 36 ] ."
        ]
    },
    "id_table_3": {
        "caption": "Table 3 :  Global Fourier-DeepONet architecture.",
        "table": "A1.T3.8",
        "footnotes": [],
        "references": [
            "The paper is organized as follows. In Section  2 , we introduce the problem setup, including the governing equations of multiphase flow and the dataset generated by numerical simulation. In Section  3 , after providing a brief overview of DeepONet and FNO, we propose a nested Fourier-DeepONet. In Section  4 , we highlight the superior computational efficiency of the nested Fourier-DeepONet compared to the nested FNO and demonstrate its generalization capabilities. We summarize the significance of this work in Section  5 .",
            "In Fourier-DeepONet (Fig.  3 ), we use DeepONet to encode input through a branch net: permeability map, reservoir temperature, initial pressure, and injection rates. At the same time, the trunk net takes the temporal coordinates  t t t italic_t  as input. The outputs of branch net,  b b \\mathbf{b} bold_b , and trunk net,  c c \\mathbf{c} bold_c , are merged through pointwise multiplication:",
            "Fourier-DeepONet used for each level is denoted as  N i P subscript superscript N P i \\mathcal{N}^{P}_{i} caligraphic_N start_POSTSUPERSCRIPT italic_P end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , where  i i i italic_i  in the subscript denotes the level of resolution in Fig.  1  for pressure buildup prediction. Similarly, for the prediction of gas saturation, we denote the neural operator as  N i S subscript superscript N S i \\mathcal{N}^{S}_{i} caligraphic_N start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  and we only train from level 1 to 4. The spatial domains of Fourier-DeepONets at five different levels are   0 ,  1 ,  2 ,  3 ,  4 subscript  0 subscript  1 subscript  2 subscript  3 subscript  4 \\Omega_{0},\\Omega_{1},\\Omega_{2},\\Omega_{3},\\Omega_{4} roman_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , roman_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , roman_ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , roman_ start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , roman_ start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT  (Fig.  2 ). The entire spatial and temporal domain of each Fourier-DeepONet is  D =  i  T D subscript  i T D=\\Omega_{i}\\times T italic_D = roman_ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  italic_T , and  T T T italic_T  denotes the temporal domain up to 30 years. The architecture of each Fourier-DeepONet in nested Fourier-DeepONet, including the output shape of each operation for levels 0 to 4, is shown in Tables  3 ,  4 , and  5  in the Appendix  A .",
            "We adopt a fine-tuning procedure by adding a random perturbation to the network inputs as introduced in Ref.  [ 36 ] . Specifically for training the subsequent levels model, we perturb the ground truth output from the previous level by adding the randomly sampled model error. For instance, after the training procedure described in Section  3.2.2 , to fine-tune the pressure buildup model at level  i i i italic_i , the model is further trained using the noised input computed as follows:",
            "As discussed in Section  3.1 , the reduced dimension of FFT and flexible batch size for time coordinates result in twice faster training and significant (at least 80%) reduction in GPU memory consumption (Table  1 ), enabling the training of Fourier-DeepONets even on GPUs with limited memory. Additionally, they lead to a substantial reduction of more than 80% in the number of trainable parameters, both at global and local resolutions, compared to FNO in Ref.  [ 36 ] .",
            "In addition to the computational efficiency, nested Fourier-DeepONet demonstrates similar or better accuracy for predicting pressure buildup. We compare the accuracy of Fourier-DeepONets and the state-of-the-art FNOs  [ 36 ]  at all levels in Table  2 . As the code for computing the evaluation metrics from Ref.  [ 36 ]  was not public, we implemented our own code for Eqs. ( 3 )( 6 ). For the accuracy of FNO, we include the accuracy from Ref.  [ 36 ]  and we also report the accuracy from our own FNOs trained using their public code but evaluated using our evaluation metric code.",
            "For gas saturation network models, the accuracy of nested Fourier-DeepONet and nested FNO is also shown in Table  2 . As mentioned in Section  3.4 , we do not train the gas saturation model at the global level. As we were able to achieve better accuracy at the global level (   0 P subscript superscript  P subscript  0 \\delta^{P}_{\\Omega_{0}} italic_ start_POSTSUPERSCRIPT italic_P end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) and level 1 (   1 S subscript superscript  S subscript  1 \\delta^{S}_{\\Omega_{1}} italic_ start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) for individual prediction (Table  6 ), the cumulative error arising from earlier levels resulted in lower accuracy with Fourier-DeepONets for both fine-tuned models and those without tuning. This highlights the importance of achieving robust accuracy at earlier levels when using a nested framework.",
            "To further investigate the generalizability of nested Fourier-DeepONet on unseen datasets, we conducted experiments to assess its performance under different extrapolation scenarios in terms of reservoir conditions (Sections  4.4.1  and  4.4.2 ), injection schemes (Section  4.4.3 ), and temporal coordinates (Section  4.4.4 ). For temporal extrapolation, we train models based on the first 21 time snapshots out of 24 while using all training samples.",
            "The final experiment involves a temporal extrapolation. Instead of training a model with a reduced number of reservoir samples as in Sections  4.4.1  to  4.4.3 , we train models with a limited number of time snapshots (21 out of 24) up to 15 years to assess their generalization capabilities up to 30 years. We train both a nested Fourier-DeepONet and a nested FNO to demonstrate the superior performance of a nested Fourier-DeepONet in temporal extrapolation.",
            "The network architectures of Fourier-DeepONets for all levels mentioned in Section  3.2  are shown in Tables  3 ,  4 , and  5 ."
        ]
    },
    "id_table_4": {
        "caption": "Table 4 :  LGR1 Fourier-DeepONet architecture.",
        "table": "A1.T4.8",
        "footnotes": [],
        "references": [
            "The paper is organized as follows. In Section  2 , we introduce the problem setup, including the governing equations of multiphase flow and the dataset generated by numerical simulation. In Section  3 , after providing a brief overview of DeepONet and FNO, we propose a nested Fourier-DeepONet. In Section  4 , we highlight the superior computational efficiency of the nested Fourier-DeepONet compared to the nested FNO and demonstrate its generalization capabilities. We summarize the significance of this work in Section  5 .",
            "Fourier-DeepONet used for each level is denoted as  N i P subscript superscript N P i \\mathcal{N}^{P}_{i} caligraphic_N start_POSTSUPERSCRIPT italic_P end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , where  i i i italic_i  in the subscript denotes the level of resolution in Fig.  1  for pressure buildup prediction. Similarly, for the prediction of gas saturation, we denote the neural operator as  N i S subscript superscript N S i \\mathcal{N}^{S}_{i} caligraphic_N start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  and we only train from level 1 to 4. The spatial domains of Fourier-DeepONets at five different levels are   0 ,  1 ,  2 ,  3 ,  4 subscript  0 subscript  1 subscript  2 subscript  3 subscript  4 \\Omega_{0},\\Omega_{1},\\Omega_{2},\\Omega_{3},\\Omega_{4} roman_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , roman_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , roman_ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , roman_ start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , roman_ start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT  (Fig.  2 ). The entire spatial and temporal domain of each Fourier-DeepONet is  D =  i  T D subscript  i T D=\\Omega_{i}\\times T italic_D = roman_ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  italic_T , and  T T T italic_T  denotes the temporal domain up to 30 years. The architecture of each Fourier-DeepONet in nested Fourier-DeepONet, including the output shape of each operation for levels 0 to 4, is shown in Tables  3 ,  4 , and  5  in the Appendix  A .",
            "As Fourier-DeepONet separates temporal coordinates through a trunk network, we have an additional option to select their batch size for training. We observe that GPU memory consumption grows linearly (Fig.  4 A) and training time decreases with respect to the time batch size (Fig.  4 B) at the global levels pressure buildup model as an example. In this work, we used a batch size of 6 among the 24-time snapshots, as it significantly reduces GPU memory usage without sacrificing model accuracy (Fig.  4 C) and training time efficiency.",
            "For gas saturation network models, the accuracy of nested Fourier-DeepONet and nested FNO is also shown in Table  2 . As mentioned in Section  3.4 , we do not train the gas saturation model at the global level. As we were able to achieve better accuracy at the global level (   0 P subscript superscript  P subscript  0 \\delta^{P}_{\\Omega_{0}} italic_ start_POSTSUPERSCRIPT italic_P end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) and level 1 (   1 S subscript superscript  S subscript  1 \\delta^{S}_{\\Omega_{1}} italic_ start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) for individual prediction (Table  6 ), the cumulative error arising from earlier levels resulted in lower accuracy with Fourier-DeepONets for both fine-tuned models and those without tuning. This highlights the importance of achieving robust accuracy at earlier levels when using a nested framework.",
            "To further investigate the generalizability of nested Fourier-DeepONet on unseen datasets, we conducted experiments to assess its performance under different extrapolation scenarios in terms of reservoir conditions (Sections  4.4.1  and  4.4.2 ), injection schemes (Section  4.4.3 ), and temporal coordinates (Section  4.4.4 ). For temporal extrapolation, we train models based on the first 21 time snapshots out of 24 while using all training samples.",
            "The final experiment involves a temporal extrapolation. Instead of training a model with a reduced number of reservoir samples as in Sections  4.4.1  to  4.4.3 , we train models with a limited number of time snapshots (21 out of 24) up to 15 years to assess their generalization capabilities up to 30 years. We train both a nested Fourier-DeepONet and a nested FNO to demonstrate the superior performance of a nested Fourier-DeepONet in temporal extrapolation.",
            "The network architectures of Fourier-DeepONets for all levels mentioned in Section  3.2  are shown in Tables  3 ,  4 , and  5 ."
        ]
    },
    "id_table_5": {
        "caption": "Table 5 :  LGR24 Fourier-DeepONet architecture.",
        "table": "A1.T5.8",
        "footnotes": [],
        "references": [
            "The paper is organized as follows. In Section  2 , we introduce the problem setup, including the governing equations of multiphase flow and the dataset generated by numerical simulation. In Section  3 , after providing a brief overview of DeepONet and FNO, we propose a nested Fourier-DeepONet. In Section  4 , we highlight the superior computational efficiency of the nested Fourier-DeepONet compared to the nested FNO and demonstrate its generalization capabilities. We summarize the significance of this work in Section  5 .",
            "Fourier-DeepONet used for each level is denoted as  N i P subscript superscript N P i \\mathcal{N}^{P}_{i} caligraphic_N start_POSTSUPERSCRIPT italic_P end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , where  i i i italic_i  in the subscript denotes the level of resolution in Fig.  1  for pressure buildup prediction. Similarly, for the prediction of gas saturation, we denote the neural operator as  N i S subscript superscript N S i \\mathcal{N}^{S}_{i} caligraphic_N start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  and we only train from level 1 to 4. The spatial domains of Fourier-DeepONets at five different levels are   0 ,  1 ,  2 ,  3 ,  4 subscript  0 subscript  1 subscript  2 subscript  3 subscript  4 \\Omega_{0},\\Omega_{1},\\Omega_{2},\\Omega_{3},\\Omega_{4} roman_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , roman_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , roman_ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , roman_ start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , roman_ start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT  (Fig.  2 ). The entire spatial and temporal domain of each Fourier-DeepONet is  D =  i  T D subscript  i T D=\\Omega_{i}\\times T italic_D = roman_ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  italic_T , and  T T T italic_T  denotes the temporal domain up to 30 years. The architecture of each Fourier-DeepONet in nested Fourier-DeepONet, including the output shape of each operation for levels 0 to 4, is shown in Tables  3 ,  4 , and  5  in the Appendix  A .",
            "We show pressure buildup predictions and errors ( x  y x y xy italic_x italic_y -view at the top layer) of three randomly selected reservoirs with 24 wells at 6 different time snapshots,  T T T italic_T  = {50d, 1.0y, 7.5y, 19.0y, 23.9y, and 30y} in Fig.  5 . At early times where there is no significant pressure gradient, the error is the lowest. The error increases with time as the injection of CO 2  results in the buildup of pressure. For the pressure buildup of the first example (Fig.  5 A), both cross-sectional  x  y x y xy italic_x italic_y -view at the top layer and  x  z x z xz italic_x italic_z -view around the injection point (level 14) are shown in Fig.  6 A. By employing locally refined models, the errors are significantly reduced through predictions at refined resolutions.",
            "The network architectures of Fourier-DeepONets for all levels mentioned in Section  3.2  are shown in Tables  3 ,  4 , and  5 ."
        ]
    },
    "id_table_6": {
        "caption": "Table 6 :  Accuracy comparison for nested FNO and nested Fourier-DeepONet . The errors are computed using the test dataset both in the entire domain and each subdomain. Separate refers to the model prediction using the ground truth from the previous levels output as the input.",
        "table": "A2.T6.11",
        "footnotes": [
            ""
        ],
        "references": [
            "In addition to the computational efficiency, nested Fourier-DeepONet demonstrates similar or better accuracy for predicting pressure buildup. We compare the accuracy of Fourier-DeepONets and the state-of-the-art FNOs  [ 36 ]  at all levels in Table  2 . As the code for computing the evaluation metrics from Ref.  [ 36 ]  was not public, we implemented our own code for Eqs. ( 3 )( 6 ). For the accuracy of FNO, we include the accuracy from Ref.  [ 36 ]  and we also report the accuracy from our own FNOs trained using their public code but evaluated using our evaluation metric code.",
            "Regardless of whether the models are fine-tuned or not, nested Fourier-DeepONet showcases superior performances across all levels compared with nested FNO we trained. Because errors in Table  2  accumulate at each subsequent level, to demonstrate the accuracy of each individual network, we present the test errors using ground truth input in Table  6  in Appendix  B . For individual networks, Fourier-DeepONet has better accuracy for almost all levels except level 3 for the prediction of pressure buildup.",
            "We show pressure buildup predictions and errors ( x  y x y xy italic_x italic_y -view at the top layer) of three randomly selected reservoirs with 24 wells at 6 different time snapshots,  T T T italic_T  = {50d, 1.0y, 7.5y, 19.0y, 23.9y, and 30y} in Fig.  5 . At early times where there is no significant pressure gradient, the error is the lowest. The error increases with time as the injection of CO 2  results in the buildup of pressure. For the pressure buildup of the first example (Fig.  5 A), both cross-sectional  x  y x y xy italic_x italic_y -view at the top layer and  x  z x z xz italic_x italic_z -view around the injection point (level 14) are shown in Fig.  6 A. By employing locally refined models, the errors are significantly reduced through predictions at refined resolutions.",
            "For gas saturation network models, the accuracy of nested Fourier-DeepONet and nested FNO is also shown in Table  2 . As mentioned in Section  3.4 , we do not train the gas saturation model at the global level. As we were able to achieve better accuracy at the global level (   0 P subscript superscript  P subscript  0 \\delta^{P}_{\\Omega_{0}} italic_ start_POSTSUPERSCRIPT italic_P end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) and level 1 (   1 S subscript superscript  S subscript  1 \\delta^{S}_{\\Omega_{1}} italic_ start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) for individual prediction (Table  6 ), the cumulative error arising from earlier levels resulted in lower accuracy with Fourier-DeepONets for both fine-tuned models and those without tuning. This highlights the importance of achieving robust accuracy at earlier levels when using a nested framework.",
            "As shown in Fig.  6 B, the CO 2  plume footprint is contained within the domain of level 1 even at 30 years of CO 2  injection. The error tends to be the largest at the boundary of the footprint in addition to the injection location.",
            "Table  6  shows the test accuracy of the nested Fourier-DeepONet and nested FNO models, where ground truth outputs from the previous level are used for  N i P subscript superscript N P i \\mathcal{N}^{P}_{i} caligraphic_N start_POSTSUPERSCRIPT italic_P end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  and  N i S subscript superscript N S i \\mathcal{N}^{S}_{i} caligraphic_N start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , with  i i i italic_i  = 14. Although this approach is not feasible in practice, it allows us to assess how well the model was trained at each individual level. Table  2  corresponds to the sequential prediction accuracy, while Table  6  represents the separate prediction accuracy, as presented in Table 7 of Ref.  [ 36 ] ."
        ]
    }
}