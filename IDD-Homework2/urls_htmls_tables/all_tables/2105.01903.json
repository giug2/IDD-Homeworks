{
    "S4.T1": {
        "caption": "TABLE I: Effect on test accuracy and log-likelihood loss of adding synthetic data samples to 10% and 100% of real data.",
        "table": "<table id=\"S4.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S4.T1.1.1.1.1\" class=\"ltx_text ltx_nopad\"><svg version=\"1.1\" height=\"31.83\" width=\"166.04\" overflow=\"visible\"><g transform=\"translate(0,31.83) scale(1,-1)\"><path d=\"M 0,31.83 166.04,0\" stroke=\"#000000\" stroke-width=\"0.4\"></path><g class=\"ltx_svg_fog\" transform=\"translate(0,0)\"><g transform=\"translate(0,12.3) scale(1, -1)\"><foreignobject width=\"91.29\" height=\"12.3\" overflow=\"visible\">\n<span id=\"S4.T1.1.1.1.1.pic1.1.1\" class=\"ltx_inline-block\">\n<span id=\"S4.T1.1.1.1.1.pic1.1.1.1\" class=\"ltx_inline-block ltx_align_left\">\n<span id=\"S4.T1.1.1.1.1.pic1.1.1.1.1\" class=\"ltx_p\"><span id=\"S4.T1.1.1.1.1.pic1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Synthetic Data</span></span>\n</span>\n</span></foreignobject></g></g><g class=\"ltx_svg_fog\" transform=\"translate(99.93,22.22)\"><g transform=\"translate(0,9.61) scale(1, -1)\"><foreignobject width=\"66.11\" height=\"9.61\" overflow=\"visible\">\n<span id=\"S4.T1.1.1.1.1.pic1.2.1\" class=\"ltx_inline-block\">\n<span id=\"S4.T1.1.1.1.1.pic1.2.1.1\" class=\"ltx_inline-block ltx_align_right\">\n<span id=\"S4.T1.1.1.1.1.pic1.2.1.1.1\" class=\"ltx_p\"><span id=\"S4.T1.1.1.1.1.pic1.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Real Data</span></span>\n</span>\n</span></foreignobject></g></g></g></svg></span></th>\n<td id=\"S4.T1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S4.T1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">10% (25 Samples)</span></td>\n<td id=\"S4.T1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S4.T1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">100% (250 Samples)</span></td>\n</tr>\n<tr id=\"S4.T1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\">Accuracy</span></td>\n<td id=\"S4.T1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.2.1.2.1\" class=\"ltx_text ltx_font_bold\">Log Loss</span></td>\n<td id=\"S4.T1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.2.1.3.1\" class=\"ltx_text ltx_font_bold\">Accuracy</span></td>\n<td id=\"S4.T1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.2.1.4.1\" class=\"ltx_text ltx_font_bold\">Log Loss</span></td>\n</tr>\n<tr id=\"S4.T1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.3.2.1.1\" class=\"ltx_text ltx_font_bold\">0</span></th>\n<td id=\"S4.T1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">62.0%</td>\n<td id=\"S4.T1.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.03</td>\n<td id=\"S4.T1.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">95.3%</td>\n<td id=\"S4.T1.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.14</td>\n</tr>\n<tr id=\"S4.T1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.4.3.1.1\" class=\"ltx_text ltx_font_bold\">250</span></th>\n<td id=\"S4.T1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">92.6%</td>\n<td id=\"S4.T1.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.24</td>\n<td id=\"S4.T1.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">97.1%</td>\n<td id=\"S4.T1.1.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.08</td>\n</tr>\n<tr id=\"S4.T1.1.5.4\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.5.4.1.1\" class=\"ltx_text ltx_font_bold\">500</span></th>\n<td id=\"S4.T1.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">93.0%</td>\n<td id=\"S4.T1.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.28</td>\n<td id=\"S4.T1.1.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">97.4%</td>\n<td id=\"S4.T1.1.5.4.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.08</td>\n</tr>\n<tr id=\"S4.T1.1.6.5\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.6.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.6.5.1.1\" class=\"ltx_text ltx_font_bold\">750</span></th>\n<td id=\"S4.T1.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">94.5%</td>\n<td id=\"S4.T1.1.6.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.24</td>\n<td id=\"S4.T1.1.6.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">97.3%</td>\n<td id=\"S4.T1.1.6.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.08</td>\n</tr>\n<tr id=\"S4.T1.1.7.6\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.7.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.7.6.1.1\" class=\"ltx_text ltx_font_bold\">1000</span></th>\n<td id=\"S4.T1.1.7.6.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">94.4%</td>\n<td id=\"S4.T1.1.7.6.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">0.25</td>\n<td id=\"S4.T1.1.7.6.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">97.2%</td>\n<td id=\"S4.T1.1.7.6.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">0.08</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "We perform multiple experiments to demonstrate the validity of the proposed method; in the first experiment, 10% of the training data in each class (25 samples) is randomly selected and presented to the GAN model in order to generate synthetic data. We add the data generated by the GAN to the remaining dataset to increase the total quantity of data. The second experiment is similar to the first one, with the exception that all of the training data (250 samples) are selected. Results in terms of test accuracy and log-likelihood loss for both experiments are presented in Table I. Accuracy is defined as (\u2571Ntrue)Ntotal\u00d7100\\left({}^{{{N}_{\\rm{true}}}}\\!\\!\\diagup\\!\\!{}_{{{N}_{\\rm{total}}}}\\;\\right)\\times 100, where Ntruesubscript\ud835\udc41true{{N}_{\\rm{true}}} is the number of true predicted classes within the test data and Ntotalsubscript\ud835\udc41total{{N}_{\\rm{total}}} is the total number of test data points (equal to 1000 in our experiments); the log-likelihood loss is defined in Equation 1. As can be seen in this table, the classification model is saturated after adding 750 and 250 samples to the 10% and 100% of the real data such that adding the extra synthetic samples does not increase the accuracy. In order to minimize the sample bias effects in the results, the process of randomly selecting data, measuring the classification accuracy, generating synthetic data and determining the final accuracy is carried-out several times. Each neural network model is trained and validated over 100 times with different initial model seeds. The average of the test accuracy and test loss from these runs are then reported as final results.",
            "In the final experiment, a fraction of the real data is randomly selected in order to generate synthetic data such that the total quantity of data after adding synthetic data is equal to the quantity of original data in each class (e.g. K\ud835\udc3eK=250). As depicted in Fig. 3, by carrying-over the fraction of real data used from 5% to 100%, we measure the test accuracy and loss in order to evaluate the effect of synthetic data on the classification accuracy. Fig. 3 indicates that the test accuracy of the model is around 50% when only a small fraction of real data is used; however, by adding synthetic data, it increases to a value of 80%. It can be seen that the effect of using real data after 90% has diminished and the classification model is saturated. Therefore, as a result from Table I and Fig. 3, it cannot be expected a miracle from synthetic data to significantly enhance the accuracy, especially when adequate samples of real data are available."
        ]
    }
}