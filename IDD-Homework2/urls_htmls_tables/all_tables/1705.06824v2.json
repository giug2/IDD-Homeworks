{
    "S4.T1": {
        "caption": "Table 1: Comparison of different text feature extractors. Accuracies per answer type are shown. Models are trained on the COCO-VQA training set and tested on the validation set. The retrained baseline model is shown as “LSTM” in Part 111. The other parts are CNN-based models. “Incep”, “Res”, “Bot”, “G(A)”, “G”, “w”, “c” is short for “Inception”, “Residual”, “Bottleneck”, “Gate (tanh)”, “Gate”, “work”, “char”, respectively.",
        "table": "<table id=\"S4.T1.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.3.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\"><span id=\"S4.T1.3.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Models</span></th>\n<td id=\"S4.T1.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T1.3.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Y/N</span></td>\n<td id=\"S4.T1.3.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T1.3.1.1.3.1\" class=\"ltx_text ltx_font_bold\">No.</span></td>\n<td id=\"S4.T1.3.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T1.3.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Other</span></td>\n<td id=\"S4.T1.3.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T1.3.1.1.5.1\" class=\"ltx_text ltx_font_bold\">All</span></td>\n</tr>\n<tr id=\"S4.T1.3.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">LSTM</th>\n<td id=\"S4.T1.3.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">81.47</td>\n<td id=\"S4.T1.3.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">34.07</td>\n<td id=\"S4.T1.3.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">51.14</td>\n<td id=\"S4.T1.3.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\">60.35</td>\n</tr>\n<tr id=\"S4.T1.3.3.3\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Non-Incep</th>\n<td id=\"S4.T1.3.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">81.75</td>\n<td id=\"S4.T1.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">35.55</td>\n<td id=\"S4.T1.3.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">51.34</td>\n<td id=\"S4.T1.3.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">60.73</td>\n</tr>\n<tr id=\"S4.T1.3.4.4\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Incep (w)</th>\n<td id=\"S4.T1.3.4.4.2\" class=\"ltx_td ltx_align_center\">81.91</td>\n<td id=\"S4.T1.3.4.4.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.3.4.4.3.1\" class=\"ltx_text ltx_font_bold\">35.99</span></td>\n<td id=\"S4.T1.3.4.4.4\" class=\"ltx_td ltx_align_center\">51.67</td>\n<td id=\"S4.T1.3.4.4.5\" class=\"ltx_td ltx_align_center\">61.03</td>\n</tr>\n<tr id=\"S4.T1.3.5.5\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Incep + Res</th>\n<td id=\"S4.T1.3.5.5.2\" class=\"ltx_td ltx_align_center\">81.01</td>\n<td id=\"S4.T1.3.5.5.3\" class=\"ltx_td ltx_align_center\">34.45</td>\n<td id=\"S4.T1.3.5.5.4\" class=\"ltx_td ltx_align_center\">51.69</td>\n<td id=\"S4.T1.3.5.5.5\" class=\"ltx_td ltx_align_center\">60.51</td>\n</tr>\n<tr id=\"S4.T1.3.6.6\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Incep + Bot</th>\n<td id=\"S4.T1.3.6.6.2\" class=\"ltx_td ltx_align_center\">80.12</td>\n<td id=\"S4.T1.3.6.6.3\" class=\"ltx_td ltx_align_center\">35.51</td>\n<td id=\"S4.T1.3.6.6.4\" class=\"ltx_td ltx_align_center\">50.58</td>\n<td id=\"S4.T1.3.6.6.5\" class=\"ltx_td ltx_align_center\">59.74</td>\n</tr>\n<tr id=\"S4.T1.3.7.7\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.7.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Incep + G(A)</th>\n<td id=\"S4.T1.3.7.7.2\" class=\"ltx_td ltx_align_center\">82.09</td>\n<td id=\"S4.T1.3.7.7.3\" class=\"ltx_td ltx_align_center\">35.47</td>\n<td id=\"S4.T1.3.7.7.4\" class=\"ltx_td ltx_align_center\">51.84</td>\n<td id=\"S4.T1.3.7.7.5\" class=\"ltx_td ltx_align_center\">61.10</td>\n</tr>\n<tr id=\"S4.T1.3.8.8\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.8.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Incep + G</th>\n<td id=\"S4.T1.3.8.8.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.3.8.8.2.1\" class=\"ltx_text ltx_font_bold\">82.46</span></td>\n<td id=\"S4.T1.3.8.8.3\" class=\"ltx_td ltx_align_center\">35.38</td>\n<td id=\"S4.T1.3.8.8.4\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.3.8.8.4.1\" class=\"ltx_text ltx_font_bold\">52.02</span></td>\n<td id=\"S4.T1.3.8.8.5\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.3.8.8.5.1\" class=\"ltx_text ltx_font_bold\">61.33</span></td>\n</tr>\n<tr id=\"S4.T1.3.9.9\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.9.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Incep (c)</th>\n<td id=\"S4.T1.3.9.9.2\" class=\"ltx_td ltx_align_center ltx_border_t\">78.15</td>\n<td id=\"S4.T1.3.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_t\">33.79</td>\n<td id=\"S4.T1.3.9.9.4\" class=\"ltx_td ltx_align_center ltx_border_t\">46.67</td>\n<td id=\"S4.T1.3.9.9.5\" class=\"ltx_td ltx_align_center ltx_border_t\">56.83</td>\n</tr>\n<tr id=\"S4.T1.3.10.10\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.10.10.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Deep Res</th>\n<td id=\"S4.T1.3.10.10.2\" class=\"ltx_td ltx_align_center\">77.19</td>\n<td id=\"S4.T1.3.10.10.3\" class=\"ltx_td ltx_align_center\">33.39</td>\n<td id=\"S4.T1.3.10.10.4\" class=\"ltx_td ltx_align_center\">46.09</td>\n<td id=\"S4.T1.3.10.10.5\" class=\"ltx_td ltx_align_center\">56.14</td>\n</tr>\n<tr id=\"S4.T1.3.11.11\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.11.11.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t\">Incep (c+w)</th>\n<td id=\"S4.T1.3.11.11.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">82.05</td>\n<td id=\"S4.T1.3.11.11.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">35.39</td>\n<td id=\"S4.T1.3.11.11.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">51.43</td>\n<td id=\"S4.T1.3.11.11.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">60.88</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "Our baseline model is the challenge\nwinner [6], which uses a 222-layer LSTM as\nthe text feature extractor. This model is retrained on the training\nset only. Meanwhile, unlike in [6], we do not\nuse additional data sources like the pre-trained word embedding\n(Word2Vec, GloVe) and other dataset (Visual\nGenome [14]) to augment training. In order to\nexplore the power of models, we argue that additional data will\nnarrow the performance gap of different models. For comparison, we\nonly replace the LSTM text feature extractor with CNN models in\nall experiments. All the results are reported in\nTable 1. Our code is publicly\navailable222https://github.com/divelab/vqa-text.",
            "Several CNN-based text feature extractors on word-based vocabulary\nare implemented. The word-based vocabulary, which includes all words\nthat appear in the training set, has size |V|=13321𝑉13321|V|=13321. For word\nembedding, we fix the dimension d=300𝑑300d=300. Dropout is applied on\ntext representations before they are given into next module. Part\n222 in Table 1 shows the results of these models.",
            "“Inception (word)” model explores wider CNNs by replacing\nthe single 1×3131\\times 3 kernel in “CNN Non-Inception” model with several\ndifferent-sized kernels in the same layer, as stated in\nSection 3.6. Different kernel settings are explored and\ntheir results are given in Table 2. Settings are named\nin the format “width of kernel (number of feature maps output by\nthis kernel)”. Note that the height of kernel is always 111. The\nresulting text vector representation has 204820482048 components. All\nthese models outperform “CNN Non-Inception” model, showing that features\nextracted from phrases of different lengths complement each other.\nTable 1 includes the best results. For all models\nusing inception modules, different kernel settings are explored. We\nonly report the best result for other models.",
            "Results for models that involve character-based vocabulary are\nreported in parts 333 and 444 in Table 1. The two\nmodels in part 333 use character-based vocabulary only, while the\nmodel in part 444 uses a combination of both vocabularies\n(Section 3.3). The character-based vocabulary collects\n|V​_​c|=45𝑉_𝑐45|V\\_c|=45 characters: all lowercase characters in English,\npunctuation as well as the space character. The kernel settings for\nboth inception-like models below are 2​(512)+3​(512)+4​(512)+5​(512)25123512451255122(512)+3(512)+4(512)+5(512).\nDropout is also applied."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Overall accuracies for “CNN Inception (word)” models with different kernel settings. Check Section 4.2 for details.",
        "table": "<table id=\"S4.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span id=\"S4.T2.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Settings</span></th>\n<th id=\"S4.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T2.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Accuracy</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">2(512)+3(512)+4(512)+5(512)</th>\n<td id=\"S4.T2.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.1.2.1.2.1\" class=\"ltx_text ltx_font_bold\">61.03</span></td>\n</tr>\n<tr id=\"S4.T2.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">1(512)+3(512)+5(512)+7(512)</th>\n<td id=\"S4.T2.1.3.2.2\" class=\"ltx_td ltx_align_center\">60.96</td>\n</tr>\n<tr id=\"S4.T2.1.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">3(1024)+5(512)+7(512)</th>\n<td id=\"S4.T2.1.4.3.2\" class=\"ltx_td ltx_align_center\">60.97</td>\n</tr>\n<tr id=\"S4.T2.1.5.4\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">1(512)+3(1024)+5(512)</th>\n<td id=\"S4.T2.1.5.4.2\" class=\"ltx_td ltx_align_center\">60.95</td>\n</tr>\n<tr id=\"S4.T2.1.6.5\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">3(1024)+5(1024)</th>\n<td id=\"S4.T2.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">60.80</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "“Inception (word)” model explores wider CNNs by replacing\nthe single 1×3131\\times 3 kernel in “CNN Non-Inception” model with several\ndifferent-sized kernels in the same layer, as stated in\nSection 3.6. Different kernel settings are explored and\ntheir results are given in Table 2. Settings are named\nin the format “width of kernel (number of feature maps output by\nthis kernel)”. Note that the height of kernel is always 111. The\nresulting text vector representation has 204820482048 components. All\nthese models outperform “CNN Non-Inception” model, showing that features\nextracted from phrases of different lengths complement each other.\nTable 1 includes the best results. For all models\nusing inception modules, different kernel settings are explored. We\nonly report the best result for other models."
        ]
    },
    "S4.T3": {
        "caption": "Table 3: The number of parameters for each model. We only compute the parameters of the text feature extractor.",
        "table": "<table id=\"S4.T3.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T3.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span id=\"S4.T3.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Models</span></th>\n<th id=\"S4.T3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T3.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Number of Parameters</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">LSTM (baseline)</th>\n<td id=\"S4.T3.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">13,819,904</td>\n</tr>\n<tr id=\"S4.T3.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">CNN Non-Inception</th>\n<td id=\"S4.T3.1.3.2.2\" class=\"ltx_td ltx_align_center\">1,845,248</td>\n</tr>\n<tr id=\"S4.T3.1.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">CNN Inception (word)</th>\n<td id=\"S4.T3.1.4.3.2\" class=\"ltx_td ltx_align_center\">2,152,448</td>\n</tr>\n<tr id=\"S4.T3.1.5.4\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">CNN Inception + Gate</th>\n<td id=\"S4.T3.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">4,304,896</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "We compare the numbers of parameters of CNN-based text feature extractor with\nLSTM-based ones in Table 3. CNN models improve the accuracy\nwith much fewer training parameters. This reduces the risk of over-fitting\nand increases the speed."
        ]
    },
    "S4.T4": {
        "caption": "Table 4: Comparison of results between deep learning models and fastText.",
        "table": "<table id=\"S4.T4.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T4.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span id=\"S4.T4.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Models</span></th>\n<th id=\"S4.T4.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T4.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Accuracy</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T4.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">LSTM (baseline)</th>\n<td id=\"S4.T4.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">60.35</td>\n</tr>\n<tr id=\"S4.T4.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">CNN Inception + Gate</th>\n<td id=\"S4.T4.1.3.2.2\" class=\"ltx_td ltx_align_center\">61.33</td>\n</tr>\n<tr id=\"S4.T4.1.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">fastText (word)</th>\n<td id=\"S4.T4.1.4.3.2\" class=\"ltx_td ltx_align_center\">59.30</td>\n</tr>\n<tr id=\"S4.T4.1.5.4\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">fastText (char+word)</th>\n<td id=\"S4.T4.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">59.24</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "As introduced in Section 3.8, fastText is a shallow model that\nachieves comparable results with deep learning models in\ntext classification tasks [10]. This result contradicts the\ncommon belief that deep learning models can learn better representations. It has been\nconjectured that the simple text classification task may not be the right one\nto evaluate text representation methods. Given the higher requirements for\ntext understanding in VQA, we compare these models in VQA. In addition to the\noriginal fastText model (“fastText (word)”), which averages word\nembedding vectors to obtain sentence representations, we also explore\nfastText (“fastText (char+word)”) with character-based vocabulary.\nSimilar to the idea in Section 3.3, character embedding of each\nword is averaged to generate part of the word embedding. The results are\ngiven in Table 4. We can see the performance gap between deep\nlearning models and fastText. Clearly, it demonstrates the complexity of VQA\ntasks and the power of deep learning."
        ]
    }
}