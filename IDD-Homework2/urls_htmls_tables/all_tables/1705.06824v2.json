{
    "S4.T1": {
        "caption": "Table 1: Comparison of different text feature extractors. Accuracies per answer type are shown. Models are trained on the COCO-VQA training set and tested on the validation set. The retrained baseline model is shown as â€œLSTMâ€ in Part 111. The other parts are CNN-based models. â€œIncepâ€, â€œResâ€, â€œBotâ€, â€œG(A)â€, â€œGâ€, â€œwâ€, â€œcâ€ is short for â€œInceptionâ€, â€œResidualâ€, â€œBottleneckâ€, â€œGate (tanh)â€, â€œGateâ€, â€œworkâ€, â€œcharâ€, respectively.",
        "table": "<table id=\"S4.T1.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.3.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\"><span id=\"S4.T1.3.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Models</span></th>\n<td id=\"S4.T1.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T1.3.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Y/N</span></td>\n<td id=\"S4.T1.3.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T1.3.1.1.3.1\" class=\"ltx_text ltx_font_bold\">No.</span></td>\n<td id=\"S4.T1.3.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T1.3.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Other</span></td>\n<td id=\"S4.T1.3.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T1.3.1.1.5.1\" class=\"ltx_text ltx_font_bold\">All</span></td>\n</tr>\n<tr id=\"S4.T1.3.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">LSTM</th>\n<td id=\"S4.T1.3.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">81.47</td>\n<td id=\"S4.T1.3.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">34.07</td>\n<td id=\"S4.T1.3.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">51.14</td>\n<td id=\"S4.T1.3.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\">60.35</td>\n</tr>\n<tr id=\"S4.T1.3.3.3\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Non-Incep</th>\n<td id=\"S4.T1.3.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">81.75</td>\n<td id=\"S4.T1.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">35.55</td>\n<td id=\"S4.T1.3.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">51.34</td>\n<td id=\"S4.T1.3.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">60.73</td>\n</tr>\n<tr id=\"S4.T1.3.4.4\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Incep (w)</th>\n<td id=\"S4.T1.3.4.4.2\" class=\"ltx_td ltx_align_center\">81.91</td>\n<td id=\"S4.T1.3.4.4.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.3.4.4.3.1\" class=\"ltx_text ltx_font_bold\">35.99</span></td>\n<td id=\"S4.T1.3.4.4.4\" class=\"ltx_td ltx_align_center\">51.67</td>\n<td id=\"S4.T1.3.4.4.5\" class=\"ltx_td ltx_align_center\">61.03</td>\n</tr>\n<tr id=\"S4.T1.3.5.5\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Incep + Res</th>\n<td id=\"S4.T1.3.5.5.2\" class=\"ltx_td ltx_align_center\">81.01</td>\n<td id=\"S4.T1.3.5.5.3\" class=\"ltx_td ltx_align_center\">34.45</td>\n<td id=\"S4.T1.3.5.5.4\" class=\"ltx_td ltx_align_center\">51.69</td>\n<td id=\"S4.T1.3.5.5.5\" class=\"ltx_td ltx_align_center\">60.51</td>\n</tr>\n<tr id=\"S4.T1.3.6.6\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Incep + Bot</th>\n<td id=\"S4.T1.3.6.6.2\" class=\"ltx_td ltx_align_center\">80.12</td>\n<td id=\"S4.T1.3.6.6.3\" class=\"ltx_td ltx_align_center\">35.51</td>\n<td id=\"S4.T1.3.6.6.4\" class=\"ltx_td ltx_align_center\">50.58</td>\n<td id=\"S4.T1.3.6.6.5\" class=\"ltx_td ltx_align_center\">59.74</td>\n</tr>\n<tr id=\"S4.T1.3.7.7\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.7.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Incep + G(A)</th>\n<td id=\"S4.T1.3.7.7.2\" class=\"ltx_td ltx_align_center\">82.09</td>\n<td id=\"S4.T1.3.7.7.3\" class=\"ltx_td ltx_align_center\">35.47</td>\n<td id=\"S4.T1.3.7.7.4\" class=\"ltx_td ltx_align_center\">51.84</td>\n<td id=\"S4.T1.3.7.7.5\" class=\"ltx_td ltx_align_center\">61.10</td>\n</tr>\n<tr id=\"S4.T1.3.8.8\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.8.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Incep + G</th>\n<td id=\"S4.T1.3.8.8.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.3.8.8.2.1\" class=\"ltx_text ltx_font_bold\">82.46</span></td>\n<td id=\"S4.T1.3.8.8.3\" class=\"ltx_td ltx_align_center\">35.38</td>\n<td id=\"S4.T1.3.8.8.4\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.3.8.8.4.1\" class=\"ltx_text ltx_font_bold\">52.02</span></td>\n<td id=\"S4.T1.3.8.8.5\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.3.8.8.5.1\" class=\"ltx_text ltx_font_bold\">61.33</span></td>\n</tr>\n<tr id=\"S4.T1.3.9.9\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.9.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Incep (c)</th>\n<td id=\"S4.T1.3.9.9.2\" class=\"ltx_td ltx_align_center ltx_border_t\">78.15</td>\n<td id=\"S4.T1.3.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_t\">33.79</td>\n<td id=\"S4.T1.3.9.9.4\" class=\"ltx_td ltx_align_center ltx_border_t\">46.67</td>\n<td id=\"S4.T1.3.9.9.5\" class=\"ltx_td ltx_align_center ltx_border_t\">56.83</td>\n</tr>\n<tr id=\"S4.T1.3.10.10\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.10.10.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Deep Res</th>\n<td id=\"S4.T1.3.10.10.2\" class=\"ltx_td ltx_align_center\">77.19</td>\n<td id=\"S4.T1.3.10.10.3\" class=\"ltx_td ltx_align_center\">33.39</td>\n<td id=\"S4.T1.3.10.10.4\" class=\"ltx_td ltx_align_center\">46.09</td>\n<td id=\"S4.T1.3.10.10.5\" class=\"ltx_td ltx_align_center\">56.14</td>\n</tr>\n<tr id=\"S4.T1.3.11.11\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.11.11.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t\">Incep (c+w)</th>\n<td id=\"S4.T1.3.11.11.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">82.05</td>\n<td id=\"S4.T1.3.11.11.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">35.39</td>\n<td id=\"S4.T1.3.11.11.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">51.43</td>\n<td id=\"S4.T1.3.11.11.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">60.88</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "Our baseline model is the challenge\nwinnerÂ [6], which uses a 222-layer LSTM as\nthe text feature extractor. This model is retrained on the training\nset only. Meanwhile, unlike inÂ [6], we do not\nuse additional data sources like the pre-trained word embedding\n(Word2Vec, GloVe) and other dataset (Visual\nGenomeÂ [14]) to augment training. In order to\nexplore the power of models, we argue that additional data will\nnarrow the performance gap of different models. For comparison, we\nonly replace the LSTM text feature extractor with CNN models in\nall experiments. All the results are reported in\nTableÂ 1. Our code is publicly\navailable222https://github.com/divelab/vqa-text.",
            "Several CNN-based text feature extractors on word-based vocabulary\nare implemented. The word-based vocabulary, which includes all words\nthat appear in the training set, has size |V|=13321ğ‘‰13321|V|=13321. For word\nembedding, we fix the dimension d=300ğ‘‘300d=300. Dropout is applied on\ntext representations before they are given into next module. Part\n222 in TableÂ 1 shows the results of these models.",
            "â€œInception (word)â€ model explores wider CNNs by replacing\nthe single 1Ã—3131\\times 3 kernel in â€œCNN Non-Inceptionâ€ model with several\ndifferent-sized kernels in the same layer, as stated in\nSectionÂ 3.6. Different kernel settings are explored and\ntheir results are given in TableÂ 2. Settings are named\nin the format â€œwidth of kernel (number of feature maps output by\nthis kernel)â€. Note that the height of kernel is always 111. The\nresulting text vector representation has 204820482048 components. All\nthese models outperform â€œCNN Non-Inceptionâ€ model, showing that features\nextracted from phrases of different lengths complement each other.\nTableÂ 1 includes the best results. For all models\nusing inception modules, different kernel settings are explored. We\nonly report the best result for other models.",
            "Results for models that involve character-based vocabulary are\nreported in parts 333 and 444 in TableÂ 1. The two\nmodels in part 333 use character-based vocabulary only, while the\nmodel in part 444 uses a combination of both vocabularies\n(SectionÂ 3.3). The character-based vocabulary collects\n|Vâ€‹_â€‹c|=45ğ‘‰_ğ‘45|V\\_c|=45 characters: all lowercase characters in English,\npunctuation as well as the space character. The kernel settings for\nboth inception-like models below are 2â€‹(512)+3â€‹(512)+4â€‹(512)+5â€‹(512)25123512451255122(512)+3(512)+4(512)+5(512).\nDropout is also applied."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Overall accuracies for â€œCNN Inception (word)â€ models with different kernel settings. Check SectionÂ 4.2 for details.",
        "table": "<table id=\"S4.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span id=\"S4.T2.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Settings</span></th>\n<th id=\"S4.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T2.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Accuracy</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">2(512)+3(512)+4(512)+5(512)</th>\n<td id=\"S4.T2.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.1.2.1.2.1\" class=\"ltx_text ltx_font_bold\">61.03</span></td>\n</tr>\n<tr id=\"S4.T2.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">1(512)+3(512)+5(512)+7(512)</th>\n<td id=\"S4.T2.1.3.2.2\" class=\"ltx_td ltx_align_center\">60.96</td>\n</tr>\n<tr id=\"S4.T2.1.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">3(1024)+5(512)+7(512)</th>\n<td id=\"S4.T2.1.4.3.2\" class=\"ltx_td ltx_align_center\">60.97</td>\n</tr>\n<tr id=\"S4.T2.1.5.4\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">1(512)+3(1024)+5(512)</th>\n<td id=\"S4.T2.1.5.4.2\" class=\"ltx_td ltx_align_center\">60.95</td>\n</tr>\n<tr id=\"S4.T2.1.6.5\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">3(1024)+5(1024)</th>\n<td id=\"S4.T2.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">60.80</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "â€œInception (word)â€ model explores wider CNNs by replacing\nthe single 1Ã—3131\\times 3 kernel in â€œCNN Non-Inceptionâ€ model with several\ndifferent-sized kernels in the same layer, as stated in\nSectionÂ 3.6. Different kernel settings are explored and\ntheir results are given in TableÂ 2. Settings are named\nin the format â€œwidth of kernel (number of feature maps output by\nthis kernel)â€. Note that the height of kernel is always 111. The\nresulting text vector representation has 204820482048 components. All\nthese models outperform â€œCNN Non-Inceptionâ€ model, showing that features\nextracted from phrases of different lengths complement each other.\nTableÂ 1 includes the best results. For all models\nusing inception modules, different kernel settings are explored. We\nonly report the best result for other models."
        ]
    },
    "S4.T3": {
        "caption": "Table 3: The number of parameters for each model. We only compute the parameters of the text feature extractor.",
        "table": "<table id=\"S4.T3.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T3.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span id=\"S4.T3.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Models</span></th>\n<th id=\"S4.T3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T3.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Number of Parameters</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">LSTM (baseline)</th>\n<td id=\"S4.T3.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">13,819,904</td>\n</tr>\n<tr id=\"S4.T3.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">CNN Non-Inception</th>\n<td id=\"S4.T3.1.3.2.2\" class=\"ltx_td ltx_align_center\">1,845,248</td>\n</tr>\n<tr id=\"S4.T3.1.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">CNN Inception (word)</th>\n<td id=\"S4.T3.1.4.3.2\" class=\"ltx_td ltx_align_center\">2,152,448</td>\n</tr>\n<tr id=\"S4.T3.1.5.4\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">CNN Inception + Gate</th>\n<td id=\"S4.T3.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">4,304,896</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "We compare the numbers of parameters of CNN-based text feature extractor with\nLSTM-based ones in TableÂ 3. CNN models improve the accuracy\nwith much fewer training parameters. This reduces the risk of over-fitting\nand increases the speed."
        ]
    },
    "S4.T4": {
        "caption": "Table 4: Comparison of results between deep learning models and fastText.",
        "table": "<table id=\"S4.T4.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T4.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span id=\"S4.T4.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Models</span></th>\n<th id=\"S4.T4.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T4.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Accuracy</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T4.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">LSTM (baseline)</th>\n<td id=\"S4.T4.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">60.35</td>\n</tr>\n<tr id=\"S4.T4.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">CNN Inception + Gate</th>\n<td id=\"S4.T4.1.3.2.2\" class=\"ltx_td ltx_align_center\">61.33</td>\n</tr>\n<tr id=\"S4.T4.1.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">fastText (word)</th>\n<td id=\"S4.T4.1.4.3.2\" class=\"ltx_td ltx_align_center\">59.30</td>\n</tr>\n<tr id=\"S4.T4.1.5.4\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">fastText (char+word)</th>\n<td id=\"S4.T4.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">59.24</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "As introduced in SectionÂ 3.8, fastText is a shallow model that\nachieves comparable results with deep learning models in\ntext classification tasksÂ [10]. This result contradicts the\ncommon belief that deep learning models can learn better representations. It has been\nconjectured that the simple text classification task may not be the right one\nto evaluate text representation methods. Given the higher requirements for\ntext understanding in VQA, we compare these models in VQA. In addition to the\noriginal fastText model (â€œfastText (word)â€), which averages word\nembedding vectors to obtain sentence representations, we also explore\nfastText (â€œfastText (char+word)â€) with character-based vocabulary.\nSimilar to the idea in SectionÂ 3.3, character embedding of each\nword is averaged to generate part of the word embedding. The results are\ngiven in TableÂ 4. We can see the performance gap between deep\nlearning models and fastText. Clearly, it demonstrates the complexity of VQA\ntasks and the power of deep learning."
        ]
    }
}