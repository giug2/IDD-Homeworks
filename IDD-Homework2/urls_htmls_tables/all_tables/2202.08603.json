{
    "PAPER'S NUMBER OF TABLES": 2,
    "S5.T1": {
        "caption": "Table 1: Network Architectures",
        "table": "<table id=\"S5.T1.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T1.4.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.4.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Model</th>\n<th id=\"S5.T1.4.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">\n<table id=\"S5.T1.4.1.1.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T1.4.1.1.2.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T1.4.1.1.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">1st</td>\n</tr>\n<tr id=\"S5.T1.4.1.1.2.1.2\" class=\"ltx_tr\">\n<td id=\"S5.T1.4.1.1.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">conv layer</td>\n</tr>\n</table>\n</th>\n<th id=\"S5.T1.4.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">¬†\n<table id=\"S5.T1.4.1.1.3.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T1.4.1.1.3.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T1.4.1.1.3.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">2nd</td>\n</tr>\n<tr id=\"S5.T1.4.1.1.3.1.2\" class=\"ltx_tr\">\n<td id=\"S5.T1.4.1.1.3.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">conv layer</td>\n</tr>\n</table>\n</th>\n<th id=\"S5.T1.4.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">¬†\n<table id=\"S5.T1.4.1.1.4.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T1.4.1.1.4.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T1.4.1.1.4.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">3rd</td>\n</tr>\n<tr id=\"S5.T1.4.1.1.4.1.2\" class=\"ltx_tr\">\n<td id=\"S5.T1.4.1.1.4.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">conv layer</td>\n</tr>\n</table>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.4.2.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.4.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">1</th>\n<td id=\"S5.T1.4.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">24 3x3</td>\n<td id=\"S5.T1.4.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">40 3x3</td>\n<td id=\"S5.T1.4.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">none</td>\n</tr>\n<tr id=\"S5.T1.4.3.2\" class=\"ltx_tr\">\n<th id=\"S5.T1.4.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">2</th>\n<td id=\"S5.T1.4.3.2.2\" class=\"ltx_td ltx_align_center\">24 3x3</td>\n<td id=\"S5.T1.4.3.2.3\" class=\"ltx_td ltx_align_center\">32 3x3</td>\n<td id=\"S5.T1.4.3.2.4\" class=\"ltx_td ltx_align_center\">56 3x3</td>\n</tr>\n<tr id=\"S5.T1.4.4.3\" class=\"ltx_tr\">\n<th id=\"S5.T1.4.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">3</th>\n<td id=\"S5.T1.4.4.3.2\" class=\"ltx_td ltx_align_center\">20 3x3</td>\n<td id=\"S5.T1.4.4.3.3\" class=\"ltx_td ltx_align_center\">32 3x3</td>\n<td id=\"S5.T1.4.4.3.4\" class=\"ltx_td ltx_align_center\">none</td>\n</tr>\n<tr id=\"S5.T1.4.5.4\" class=\"ltx_tr\">\n<th id=\"S5.T1.4.5.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">4</th>\n<td id=\"S5.T1.4.5.4.2\" class=\"ltx_td ltx_align_center\">24 3x3</td>\n<td id=\"S5.T1.4.5.4.3\" class=\"ltx_td ltx_align_center\">40 3x3</td>\n<td id=\"S5.T1.4.5.4.4\" class=\"ltx_td ltx_align_center\">56 3x3</td>\n</tr>\n<tr id=\"S5.T1.4.6.5\" class=\"ltx_tr\">\n<th id=\"S5.T1.4.6.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">5</th>\n<td id=\"S5.T1.4.6.5.2\" class=\"ltx_td ltx_align_center\">20 3x3</td>\n<td id=\"S5.T1.4.6.5.3\" class=\"ltx_td ltx_align_center\">32 3x3</td>\n<td id=\"S5.T1.4.6.5.4\" class=\"ltx_td ltx_align_center\">80 3x3</td>\n</tr>\n<tr id=\"S5.T1.4.7.6\" class=\"ltx_tr\">\n<th id=\"S5.T1.4.7.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">6</th>\n<td id=\"S5.T1.4.7.6.2\" class=\"ltx_td ltx_align_center\">24 3x3</td>\n<td id=\"S5.T1.4.7.6.3\" class=\"ltx_td ltx_align_center\">32 3x3</td>\n<td id=\"S5.T1.4.7.6.4\" class=\"ltx_td ltx_align_center\">80 3x3</td>\n</tr>\n<tr id=\"S5.T1.4.8.7\" class=\"ltx_tr\">\n<th id=\"S5.T1.4.8.7.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">7</th>\n<td id=\"S5.T1.4.8.7.2\" class=\"ltx_td ltx_align_center\">32 3x3</td>\n<td id=\"S5.T1.4.8.7.3\" class=\"ltx_td ltx_align_center\">32 3x3</td>\n<td id=\"S5.T1.4.8.7.4\" class=\"ltx_td ltx_align_center\">none</td>\n</tr>\n<tr id=\"S5.T1.4.9.8\" class=\"ltx_tr\">\n<th id=\"S5.T1.4.9.8.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">8</th>\n<td id=\"S5.T1.4.9.8.2\" class=\"ltx_td ltx_align_center\">40 3x3</td>\n<td id=\"S5.T1.4.9.8.3\" class=\"ltx_td ltx_align_center\">56 3x3</td>\n<td id=\"S5.T1.4.9.8.4\" class=\"ltx_td ltx_align_center\">none</td>\n</tr>\n<tr id=\"S5.T1.4.10.9\" class=\"ltx_tr\">\n<th id=\"S5.T1.4.10.9.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">9</th>\n<td id=\"S5.T1.4.10.9.2\" class=\"ltx_td ltx_align_center\">32 3x3</td>\n<td id=\"S5.T1.4.10.9.3\" class=\"ltx_td ltx_align_center\">48 3x3</td>\n<td id=\"S5.T1.4.10.9.4\" class=\"ltx_td ltx_align_center\">none</td>\n</tr>\n<tr id=\"S5.T1.4.11.10\" class=\"ltx_tr\">\n<th id=\"S5.T1.4.11.10.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\">10</th>\n<td id=\"S5.T1.4.11.10.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">48 3x3</td>\n<td id=\"S5.T1.4.11.10.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">56 3x3</td>\n<td id=\"S5.T1.4.11.10.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">96 3x3</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "The CoFED method enables participants to independently design different models. For example, some participants use CNNs as classifiers, while others use support vector machine (SVM) classifiers. We use randomly generated 2-layer or 3-layer CNNs with different architectures as the models for the different participants in image classification tasks to illustrate that CoFED is compatible with heterogeneous models. Ten of the 100 employed model architectures are shown in Table 1."
        ]
    },
    "S5.T2": {
        "caption": "Table 2: Comparison Results",
        "table": "<table id=\"S5.T2.4\" class=\"ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T2.4.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T2.4.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_border_t\"></td>\n<th id=\"S5.T2.4.1.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_th ltx_th_column ltx_border_t\"></th>\n<th id=\"S5.T2.4.1.1.3\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_t\">\n<table id=\"S5.T2.4.1.1.3.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T2.4.1.1.3.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T2.4.1.1.3.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Personalized</td>\n</tr>\n<tr id=\"S5.T2.4.1.1.3.1.2\" class=\"ltx_tr\">\n<td id=\"S5.T2.4.1.1.3.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">FedAvg</td>\n</tr>\n</table>\n</th>\n<th id=\"S5.T2.4.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">FedMD</th>\n<th id=\"S5.T2.4.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">CoFED</th>\n</tr>\n<tr id=\"S5.T2.4.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T2.4.2.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" rowspan=\"2\"><span id=\"S5.T2.4.2.2.1.1\" class=\"ltx_text\">IID</span></td>\n<td id=\"S5.T2.4.2.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\">Accuracy</td>\n<td id=\"S5.T2.4.2.2.3\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_t\"><span id=\"S5.T2.4.2.2.3.1\" class=\"ltx_text ltx_font_bold\">1.06</span></td>\n<td id=\"S5.T2.4.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.87</td>\n<td id=\"S5.T2.4.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\">1.00<sup id=\"S5.T2.4.2.2.5.1\" class=\"ltx_sup\">*</sup>\n</td>\n</tr>\n<tr id=\"S5.T2.4.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T2.4.3.3.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\">Rounds</td>\n<td id=\"S5.T2.4.3.3.2\" class=\"ltx_td ltx_nopad_l ltx_align_center\">100</td>\n<td id=\"S5.T2.4.3.3.3\" class=\"ltx_td ltx_align_center\">8<sup id=\"S5.T2.4.3.3.3.1\" class=\"ltx_sup\">‚Ä†</sup>\n</td>\n<td id=\"S5.T2.4.3.3.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.4.3.3.4.1\" class=\"ltx_text ltx_font_bold\">1</span></td>\n</tr>\n<tr id=\"S5.T2.4.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T2.4.4.4.1\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_b ltx_border_t\" rowspan=\"2\"><span id=\"S5.T2.4.4.4.1.1\" class=\"ltx_text\">Non-IID</span></td>\n<td id=\"S5.T2.4.4.4.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\">Accuracy</td>\n<td id=\"S5.T2.4.4.4.3\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_t\">0.94</td>\n<td id=\"S5.T2.4.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.94</td>\n<td id=\"S5.T2.4.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.4.4.4.5.1\" class=\"ltx_text ltx_font_bold\">1.00<sup id=\"S5.T2.4.4.4.5.1.1\" class=\"ltx_sup\"><span id=\"S5.T2.4.4.4.5.1.1.1\" class=\"ltx_text ltx_font_medium\">*</span></sup></span></td>\n</tr>\n<tr id=\"S5.T2.4.5.5\" class=\"ltx_tr\">\n<td id=\"S5.T2.4.5.5.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b\">Rounds</td>\n<td id=\"S5.T2.4.5.5.2\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_b\">150</td>\n<td id=\"S5.T2.4.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_b\">17<sup id=\"S5.T2.4.5.5.3.1\" class=\"ltx_sup\">‚Ä†</sup>\n</td>\n<td id=\"S5.T2.4.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S5.T2.4.5.5.4.1\" class=\"ltx_text ltx_font_bold\">1</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "Reference value.The round with the best performance.",
        "references": [
            [
                "To the best of our knowledge, CoFED is the first FL method that tries to be compatible with heterogeneous models, tasks, and training processes simultaneously. Therefore, FL methods are available for comparison under HFMTL settings. We use two well-known comparison methods. One is the personalized FedAvg method, which represents the classic parameter aggregation-based FL strategy that is not compatible with heterogeneous models with different architectures; the other is the FedMD method ",
                "li2019fedmd ",
                ", which supports different neural network architectures and is used to evaluate the performance of CoFED under heterogeneous models.",
                "To enable the personalized FedAvg and FedMD methods to handle heterogeneous classification tasks, we treat each participant‚Äôs local label space ",
                "ùí¥",
                "i",
                "subscript",
                "ùí¥",
                "ùëñ",
                "\\mathcal{Y}_{i}",
                " as the union of the spaces ",
                "ùí¥",
                "ùí¥",
                "\\mathcal{Y}",
                " in (",
                "15",
                "). In this way, we can handle heterogeneous tasks with the idea of personalized FedAvg and FedMD. The main steps are as follows.",
                "Use the FedAvg or FedMD algorithm to train a global model whose label space is the union of the label spaces of all participants.",
                "The global model is fine-tuned on each participant‚Äôs local dataset for a personalized model for their local task..",
                "In this comparison experiment, we use the data configuration presented in Section 4.3. Considering that the personalized FedAvg method can not be used for models with different architectures, 100 participants share the same architecture neural network model. In the FedMD comparison experiment, we use the same setup as that in Section 4.3; that is, we select 100 participants with different neural network architectures.",
                "We try a variety of different hyperparameter settings to achieve better performance in the personalized FedAvg experiment. We use ",
                "E",
                "=",
                "20",
                "ùê∏",
                "20",
                "E=20",
                " as the number of local training rounds in each communication iteration, ",
                "B",
                "=",
                "50",
                "ùêµ",
                "50",
                "B=50",
                " is set as the local minibatch size used for the local updates, and participants also perform local transfer learning to train their personalized models in each communication iteration. In the FedMD experiment, We use the similar settings of ",
                "li2019fedmd ",
                ", and it should be noted that FedMD uses the labeled data of CIFAR10 as the public dataset, which is different from the unlabeled data used in CoFED.",
                "The results of the comparison between FedAvg and CoFED are shown in Fig. ",
                "10",
                ". The relative test accuracy is calculated as the average of the ratios of all participants to the CoFED test accuracy. Under the IID setting, FedAvg reaches the performance level of CoFED after 42 communication rounds and is finally 6% ahead of COFED in Fig. ",
                "10",
                "(a). Under the non-IID setting, FedAvg stabilizes after 150 communication rounds. At this time, CoFED still leads FedAvg by 6% in Fig. ",
                "10",
                "(b). The comparing results of personalized FedAvg and CoFED are shown in Fig. ",
                "11",
                ". For both data settings, CoFED outperforms FedMD, and CoFED leads by 14% under the IID setting and 35% under the non-IID one.",
                "In terms of communication cost, if we do not consider the communication overhead required to initially construct the public dataset, CoFED achieves better performance with lower communication overheads in all cases because CoFED only needs to pass through the label data (not the sample itself) during the training process, and iterating for multiple rounds is not required. This assumption is not unrealistic because the construction of public datasets may not require the central server to distribute data to the participants; the participants can instead obtain data from a third party, which does not incur communication costs between the participants and the central server. Even if we include that paradigm, CoFED still achieves better performance with lower communication costs except under the IID and identical architecture model settings. In fact, the IID setting used in the FedAvg comparison experiment is not the scenario that is considered most by CoFED because the model architectures are the same and can be shared under that setting."
            ]
        ]
    }
}