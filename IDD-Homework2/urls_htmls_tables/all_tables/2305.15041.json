{
    "S3.T1": {
        "caption": "Table 1: Description of objectives in synthetic data generation alongside specific strategies to achieve them.",
        "table": "<table id=\"S3.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S3.T1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Goal</span></th>\n<th id=\"S3.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S3.T1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Strategy</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_tt\">Diversity in construct</td>\n<td id=\"S3.T1.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_tt\">Taxonomy creation</td>\n</tr>\n<tr id=\"S3.T1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\">Diversity in topics</td>\n<td id=\"S3.T1.1.3.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">Grounding</td>\n</tr>\n<tr id=\"S3.T1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\">Stylistic matching</td>\n<td id=\"S3.T1.1.4.3.2\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\">Rewrite</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "To understand where synthetic data fails, we begin our analysis by manually inspecting the generated data.\nThree co-authors reviewed hundreds of examples of synthetically generated vs. real sarcastic texts and annotated their differences. We found that synthetic data generated with simple prompts:\n1) exhibits a lack of topical diversity, i.e., it centered around a few topics of discussion;\n2) lacks diversity in the construct of interest (namely sarcasm111There are many ways a linguistic construct like sarcasm can manifest (irony, over- or under-statement, satire, etc.), and typically the language model would retreat to superficial notions of sarcasm like beginning sentences with \u201cOh\u201d or \u201cWow\u201d.); and\n3) are not well stylistically aligned with real data; authors could easily discriminate between synthetic and real texts. These three assumptions and corresponding prompt designs are described in Table\u00a01.222The prompts in entirety are available at\u00a0https://github.com/epfl-dlab/faithful-data-gen."
        ]
    },
    "S3.T2": {
        "caption": "Table 2: For different prompting strategies (rows 2 to 6) and baselines (rows 7 to 10), we show the accuracy, macro-F1 score, and believability in a held-out test set.",
        "table": "<table id=\"S3.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\" rowspan=\"2\"><span id=\"S3.T2.1.1.1.1.1\" class=\"ltx_text\">Prompting Strategy</span></th>\n<td id=\"S3.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"3\"><em id=\"S3.T2.1.1.1.2.1\" class=\"ltx_emph ltx_font_bold ltx_font_italic\">Sarcasm</em></td>\n</tr>\n<tr id=\"S3.T2.1.2.2\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Accuracy</td>\n<td id=\"S3.T2.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Macro-F1</td>\n<td id=\"S3.T2.1.2.2.3\" class=\"ltx_td ltx_align_center\">Believability</td>\n</tr>\n<tr id=\"S3.T2.1.3.3\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Simple</th>\n<td id=\"S3.T2.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S3.T2.1.3.3.2.1\" class=\"ltx_text ltx_font_bold\">0.71</span></td>\n<td id=\"S3.T2.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.48</td>\n<td id=\"S3.T2.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.04</td>\n</tr>\n<tr id=\"S3.T2.1.4.4\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Grounding</th>\n<td id=\"S3.T2.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.67</td>\n<td id=\"S3.T2.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S3.T2.1.4.4.3.1\" class=\"ltx_text ltx_font_bold\">0.55</span></td>\n<td id=\"S3.T2.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.13</td>\n</tr>\n<tr id=\"S3.T2.1.5.5\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Grounding (rewrite)</th>\n<td id=\"S3.T2.1.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.70</td>\n<td id=\"S3.T2.1.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S3.T2.1.5.5.3.1\" class=\"ltx_text ltx_font_bold\">0.55</span></td>\n<td id=\"S3.T2.1.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.15</td>\n</tr>\n<tr id=\"S3.T2.1.6.6\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Grounding + Taxonomy</th>\n<td id=\"S3.T2.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.67</td>\n<td id=\"S3.T2.1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.51</td>\n<td id=\"S3.T2.1.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.20</td>\n</tr>\n<tr id=\"S3.T2.1.7.7\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.7.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Grounding + Filtering</th>\n<td id=\"S3.T2.1.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.27</td>\n<td id=\"S3.T2.1.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.26</td>\n<td id=\"S3.T2.1.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.1.7.7.4.1\" class=\"ltx_text ltx_font_bold\">0.56</span></td>\n</tr>\n<tr id=\"S3.T2.1.8.8\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.8.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\">Groundtruth annotations</th>\n<td id=\"S3.T2.1.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">0.72</td>\n<td id=\"S3.T2.1.8.8.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">0.60</td>\n<td id=\"S3.T2.1.8.8.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">0.95</td>\n</tr>\n<tr id=\"S3.T2.1.9.9\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.9.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">All non-sarcastic</th>\n<td id=\"S3.T2.1.9.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.77</td>\n<td id=\"S3.T2.1.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.43</td>\n<td id=\"S3.T2.1.9.9.4\" class=\"ltx_td ltx_align_center ltx_border_t\">&#8212;</td>\n</tr>\n<tr id=\"S3.T2.1.10.10\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.10.10.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t\">Zero-shot ChatGPT</th>\n<td id=\"S3.T2.1.10.10.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">0.60</td>\n<td id=\"S3.T2.1.10.10.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">0.59</td>\n<td id=\"S3.T2.1.10.10.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">&#8212;</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "Model performance.\nWe show the accuracy and the macro-F1 score for the different prompting strategies in the second and third columns in Table\u00a02.\nA baseline predicting all data points in the training set as not-sarcastic (\u201cAll non-sarcastic\u201d) yields an accuracy of 0.72 and a macro-F1 score of 0.43.\nIn practice, we find that models trained in all prompting strategies perform worse accuracy-wise than this baseline, and thus it is more meaningful to compare their macro-F1 score.",
            "Believability.\nFor each synthetic dataset generated, we further estimate how effective they are at fooling a synthetic vs. real classifier (which we refer to as the dataset\u2019s believability).\nThe discriminator model was trained on individual generations of sarcastic and non-sarcastic text and then fine-tuned to predict if a text is sarcastic or not. We report the fraction of each dataset predicted to be real by this classifier in the 4th row of Table\u00a02, \u201cBelievability.\u201d\nNote that for the groundtruth annotations (which are all real), we obtain a score of 95%, meaning that the model believes that 95% of the text was considered to be real by the classifier."
        ]
    }
}