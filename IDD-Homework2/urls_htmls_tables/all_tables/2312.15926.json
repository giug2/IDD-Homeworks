{
    "PAPER'S NUMBER OF TABLES": 4,
    "S4.T1": {
        "caption": "TABLE I: Proportion of training parameters of different methods",
        "table": "<table id=\"S4.T1.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.2.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.2.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\">Methods</th>\n<th id=\"S4.T1.2.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Proportion</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.2.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T1.2.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">FedMS (Stage 1)</td>\n<td id=\"S4.T1.2.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.1%</td>\n</tr>\n<tr id=\"S4.T1.2.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T1.2.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">FedMS (Stage 2)</td>\n<td id=\"S4.T1.2.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.27 %</td>\n</tr>\n<tr id=\"S4.T1.2.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T1.2.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">FT</td>\n<td id=\"S4.T1.2.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">100%</td>\n</tr>\n<tr id=\"S4.T1.2.5.4\" class=\"ltx_tr\">\n<td id=\"S4.T1.2.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">LFFT</td>\n<td id=\"S4.T1.2.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">50%</td>\n</tr>\n<tr id=\"S4.T1.2.6.5\" class=\"ltx_tr\">\n<td id=\"S4.T1.2.6.5.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">PromptFL</td>\n<td id=\"S4.T1.2.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">0.005%</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Impact of visual encoders.",
                "\nWe test the performance of FedMS under visual encoders ViT-B/16 and ViT-B/32 to further verify the effectiveness of FedMS under various visual encoders.",
                "We can observe from Fig. ",
                "3",
                " that FedMS achieves the highest image classification accuracy on all datasets using the visual backbone Vit-B/16 or Vit-B/32. Results show that visual encoders with a larger number of parameters can achieve better performance than those with smaller visual encoders. The accuracy of the four algorithms increased by ",
                "1.01",
                "%",
                ",",
                "11.85",
                "%",
                ",",
                "4.57",
                "%",
                "percent",
                "1.01",
                "percent",
                "11.85",
                "percent",
                "4.57",
                "1.01\\%,11.85\\%,4.57\\%",
                ", and ",
                "4.25",
                "%",
                "percent",
                "4.25",
                "4.25\\%",
                " when using ViT-B/16 as the visual encoder on the UCF101 dataset which confirms the theoretical analysis that larger models have better feature extraction ability.",
                "Our method suppresses other baselines by a maximum of ",
                "55.25",
                "%",
                "percent",
                "55.25",
                "55.25\\%",
                " and a minimum of ",
                "8.55",
                "%",
                "percent",
                "8.55",
                "8.55\\%",
                " when using Vit-B/16 and suppresses other baselines by a maximum of ",
                "60.09",
                "%",
                "percent",
                "60.09",
                "60.09\\%",
                " and a minimum of ",
                "6.01",
                "%",
                "percent",
                "6.01",
                "6.01\\%",
                " when using Vit-B/32. Results show that FedMS can adapt to visual encoders with different scales.",
                "Impact of accuracy thresholds.",
                "\nWe further discuss the performance of FedMS when the value of the accuracy threshold ",
                "Œ¥",
                "ùõø",
                "\\delta",
                " is different. Typically, if the clients have more computation resources, they can have a higher ",
                "Œ¥",
                "ùõø",
                "\\delta",
                " to encourage more inserted low-rank decomposition matrices to be activated, and if their computing resources are scarce they can set a small ",
                "Œ¥",
                "ùõø",
                "\\delta",
                " to save more computation resources.",
                "We set the accuracy threshold to 0.001, 0.005, 0.01, and 0.02 to see its effect on the model performance.\nFrom Fig. ",
                "8",
                " we can find that the accuracy does not always increase with ",
                "Œ¥",
                "ùõø",
                "\\delta",
                ". On the Food101 dataset, the accuracy is ",
                "94.05",
                "%",
                "percent",
                "94.05",
                "94.05\\%",
                " when ",
                "Œ±",
                "ùõº",
                "\\alpha",
                " is 0.02 and is ",
                "92.96",
                "%",
                "percent",
                "92.96",
                "92.96\\%",
                " when ",
                "Œ±",
                "ùõº",
                "\\alpha",
                " is 0.001, which has an increase of ",
                "1.09",
                "%",
                "percent",
                "1.09",
                "1.09\\%",
                " and on the EuroSAT dataset, the accuracy increase from ",
                "99.23",
                "%",
                "percent",
                "99.23",
                "99.23\\%",
                " to ",
                "99.39",
                "%",
                "percent",
                "99.39",
                "99.39\\%",
                ". But on the UCF101 dataset, the accuracy decreased from ",
                "88.48",
                "%",
                "percent",
                "88.48",
                "88.48\\%",
                " to ",
                "88.24",
                "%",
                "percent",
                "88.24",
                "88.24\\%",
                " when ",
                "Œ¥",
                "ùõø",
                "\\delta",
                " increased from 0.001 to 0.02. The largest accuracy difference in the three datasets is ",
                "1.09",
                "%",
                ",",
                "0.0024",
                "%",
                "percent",
                "1.09",
                "percent",
                "0.0024",
                "1.09\\%,0.0024\\%",
                ", and ",
                "0.0016",
                "%",
                "percent",
                "0.0016",
                "0.0016\\%",
                ".",
                "Results imply the effectiveness of the design of ",
                "SAL",
                " because of leveraging the idea of curriculum learning that progressively increases the number of activates low-rank adaptation matrices in the visual encoder and the text encoder.\nIn the optimization process of FM, it is often easier at the beginning, while the optimization of parameters becomes more difficult as it progresses, making it harder to improve accuracy. We increase the number of activated parameters through a controller during the training to tackle the increasing difficulty of optimizing the FM during training.",
                "Imapct of learning rates.",
                "\nWe show the accuracy of FedMS in three datasets under different learning rates. We set the learning rate to ",
                "2",
                "‚Äã",
                "e",
                "‚àí",
                "3",
                ",",
                "2",
                "‚Äã",
                "e",
                "‚àí",
                "4",
                "2",
                "superscript",
                "ùëí",
                "3",
                "2",
                "superscript",
                "ùëí",
                "4",
                "2e^{-3},2e^{-4}",
                ", and ",
                "2",
                "‚Äã",
                "e",
                "‚àí",
                "5",
                "2",
                "superscript",
                "ùëí",
                "5",
                "2e^{-5}",
                ".",
                "From Fig. ",
                "12",
                " we can observe that when the learning rate is ",
                "2",
                "‚Äã",
                "e",
                "‚àí",
                "5",
                "2",
                "superscript",
                "ùëí",
                "5",
                "2e^{-5}",
                " the model shows a slow convergence rate, especially in UCF101 datasets, the accuracy is ",
                "70.61",
                "%",
                "percent",
                "70.61",
                "70.61\\%",
                " which has an accuracy loss of ",
                "16.72",
                "%",
                "percent",
                "16.72",
                "16.72\\%",
                " compared to the accuracy when the learning rate is ",
                "2",
                "‚Äã",
                "e",
                "‚àí",
                "4",
                "2",
                "superscript",
                "ùëí",
                "4",
                "2e^{-4}",
                ". When the learning rate is ",
                "2",
                "‚Äã",
                "e",
                "‚àí",
                "3",
                "2",
                "superscript",
                "ùëí",
                "3",
                "2e^{-3}",
                ", the accuracy has a sharp increase in the first few epochs in all datasets but may encounter severe oscillation in the following epochs which is because of the large learning rate can cause instability in model training. This phenomenon is especially usual in the training of FMs for the reason that they usually have a large number of parameters and the scale of gradient calculations will increase which may cause the gradient explosion. Moreover, models with large parameters tend to have more complex optimization spaces, resulting in the training process being more easily affected by noise and instability.",
                "Impact of LoRA ranks.",
                "\nIn FedMS, we incorporate LoRA for model training and optimization. The rank in LoRA refers to the degree of model compression or pruning, and different rank settings can have an impact on the model training performance. We examine the training accuracy performance of FedMS under different LoRA ranks, specifically rank is set to 1, 4, 8, and 16.",
                "From Fig. ",
                "11",
                ", we can observe that as the LoRA rank increases, FedMS shows a certain trend in accuracy performance across different datasets: it performs the best at LoRA rank=4, but the model accuracy decreases as the LoRA rank further increases. This trend is particularly evident on the UCF101 dataset, where changes in LoRA rank can cause the performance of the final model to fluctuate within a 5% range.\nOne possible reason is that the semantic information that the UCF101 dataset contains is difficult for the model to capture and thus requires more training to optimize the model. A high LoRA rank can lead to a large optimization space which raises challenges for the training. On the other hand, the information patterns in the Food101 and EuroSAT datasets are relatively simpler and easy for the inserted low-rank matrices with different ranks to capture, so the model‚Äôs learning performance is not affected significantly.",
                "Impact of LoRA dropout rates.",
                "\nThe dropout coefficient in LoRA affects the probability of applying dropout regularization during the model training process. In FedMS, we apply dropout to prevent neural networks from overfitting and enhance the model‚Äôs generalization ability. In our experiment, the group with a dropout rate of 0 will serve as the control group to represent the accuracy of the model without using dropout techniques. The groups with dropout rates of 0.1, 0.3, and 0.5 will serve as the experimental groups to investigate the impact of different dropout coefficients.",
                "From Fig. ",
                "11",
                ", we can clearly see that dropout has a significant effect on the final model accuracy when set to 0.1. It results in a noticeable improvement of 0.5%, 2%, and 0.6% respectively on the Food101, UFC101, and EuroSAT datasets. This improvement is quite significant, especially when the model itself already has a high accuracy on the dataset. Similar to the LoRA rank experiment, FedMS shows a decrease in accuracy on the UFC101 dataset with higher dropout rates. This is expected due to the more complex information patterns in the UFC101 dataset. Setting dropout too high increases the number of discarded neurons during model training, leading to a decrease in the model‚Äôs learning and expressive capacity. Similarly, due to the simpler information patterns in the Food101 and EuroSAT datasets, the higher dropout rates contribute to the improved accuracy of the FedMS model on these two datasets.",
                "Impact of weight decays.",
                "\nWeight decay is used to solve the overfitting problem. By adding a regularization term to the loss function, it can encourage the model to have small weight values during the training. In our experiment, we set up five different experimental groups with varying degrees of weight decay. The group with a weight decay value of 0 represents the training performance of FedMS without using weight decay.",
                "From Fig. ",
                "11",
                " we can conclude that weight decay has a different impact on different datasets. On the UCF101 dataset, it has a significant impact on the accuracy. When the weight decay is 0.5 it has an accuracy loss of ",
                "4.53",
                "%",
                "percent",
                "4.53",
                "4.53\\%",
                " compared to the case when weight decay is 0.1. Weight decay has less impact on Food101 and UCF101 datasets, the accuracy under different weight decay varies less than ",
                "1",
                "%",
                "percent",
                "1",
                "1\\%",
                " on these two datasets. Overall, the performance of FedMS improves with the use of weight decay but decreases when the weight decay value is set too high. This is because large weight decay can lead to excessive constraints on parameters, limiting the effective information learned by the model.",
                "Impact of backdoor attacks.",
                "\nTo further verify the robustness of FedMS we test the performance of FedMS and the three baselines under backdoor attack. We suppose that there is a certain ratio of malicious clients controlled by the attacker. The controlled malicious clients update the reverse weight of their local model in the weight aggregation every communication round to attack the FL system.",
                "We set the ratio of malicious clients to the total number of clients to ",
                "20",
                "%",
                "percent",
                "20",
                "20\\%",
                " and compare the accuracies. From Fig. ",
                "8",
                " we can observe that the backdoor attack can severely harm the performance of the algorithm. FedMS has the highest accuracy in all datasets. It has an accuracy gain of ",
                "6.97",
                "%",
                ",",
                "14.94",
                "%",
                "percent",
                "6.97",
                "percent",
                "14.94",
                "6.97\\%,14.94\\%",
                ", and ",
                "14.23",
                "%",
                "percent",
                "14.23",
                "14.23\\%",
                " on three datasets compared to the highest accuracy of the three baselines. On the UCF101 dataset, the accuracy of the FT, LFFT, and, PromptFL have an accuracy of ",
                "1.20",
                "%",
                ",",
                "65.09",
                "%",
                "percent",
                "1.20",
                "percent",
                "65.09",
                "1.20\\%,65.09\\%",
                ", and ",
                "57.90",
                "%",
                "percent",
                "57.90",
                "57.90\\%",
                " respectively. Three baselines have the lowest average on the EuroSAT dataset which is ",
                "36.11",
                "%",
                "percent",
                "36.11",
                "36.11\\%",
                ", and they achieve the highest average accuracy of ",
                "86.88",
                "%",
                "percent",
                "86.88",
                "86.88\\%",
                " on the Food101 dataset. FMs are pre-trained on large-scale datasets which enables them to have strong zero-shot ability. The FM we use has the highest zero-shot accuracy on the Food101 dataset among the three datasets which makes it more resistant to backdoor attacks when it is trained on the Food101 dataset. The FT algorithm is the most easily poisoned because it exposes all parameters to the attack. Although the LFFT algorithm performs inferior to FT when there are no attacks, it outperforms FT under backdoor attacks due to the reason that the frozen transformer layers can help maintain the feature extraction ability of FM."
            ]
        ]
    },
    "S4.T2": {
        "caption": "TABLE II: Comparison of the number of parameters of the model",
        "table": "<table id=\"S4.T2.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T2.2.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.2.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">Model type</th>\n<th id=\"S4.T2.2.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Number of parameters</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.2.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.2.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">Model with <span id=\"S4.T2.2.2.1.1.1\" class=\"ltx_text ltx_font_typewriter\">MoFM</span> (Vit-B/16)</th>\n<td id=\"S4.T2.2.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">311M</td>\n</tr>\n<tr id=\"S4.T2.2.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T2.2.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">Model without <span id=\"S4.T2.2.3.2.1.1\" class=\"ltx_text ltx_font_typewriter\">MoFM</span> (Vit-L/14)</th>\n<td id=\"S4.T2.2.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">428M</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Impact of Mixture of Foundation Models architecture.",
                "\nWe compare the image classification accuracy of the model with the ",
                "MoFM",
                " architecture using the visual encoder ViT-B/16 and the model without the ",
                "MoFM",
                " architecture but with a visual encoder ViT-L/14, which has a much larger number of parameters. The first model is trained through all two stages of FedMS and the second model is trained through the first stage of FedMS. The total number of epochs of both models is set to 50 to ensure fair comparison. The comparison of the total number of parameters is shown in Tab. ",
                "II",
                ". The model with ",
                "MoFM",
                " architecture but with a smaller visual encoder has ",
                "27.33",
                "%",
                "percent",
                "27.33",
                "27.33\\%",
                " parameter less than another model.",
                "We can observe from Fig. ",
                "13",
                " that although with much fewer parameters, the model with the ",
                "MoFM",
                " architecture and trained through complete two stages achieves a higher accuracy on all datasets. It has an average accuracy increase of ",
                "2.36",
                "%",
                "percent",
                "2.36",
                "2.36\\%",
                " on all datasets. More specifically, with an increase of ",
                "2.03",
                "%",
                ",",
                "3.24",
                "%",
                "percent",
                "2.03",
                "percent",
                "3.24",
                "2.03\\%,3.24\\%",
                ", and ",
                "1.82",
                "%",
                "percent",
                "1.82",
                "1.82\\%",
                " on Food101, UCF101, and EuroSAT datasets.",
                "This surprising result demonstrates the superiority of the ",
                "MoFM",
                " architecture as it can intelligently assign different weights to different experts according to the characteristics of the images to be classified. This enables better generalization ability to data that is out of the distribution of clients‚Äô local datasets and enables better personalization ability to data that follow the local distribution of the local clients‚Äô local datasets.",
                "Impact of aggregation of gate parameters.",
                "\nWe compare the image classification accuracy of FedMS and FedMS with all gate parameters activated in the second training stage. We can observe from Tab. ",
                "IV",
                " that by only fine-tuning the last layer of the gate adapter, we can achieve an accuracy of ",
                "93.73",
                "%",
                ",",
                "87.33",
                "%",
                "percent",
                "93.73",
                "percent",
                "87.33",
                "93.73\\%,87.33\\%",
                ", and ",
                "99.46",
                "%",
                "percent",
                "99.46",
                "99.46\\%",
                " in Food101, UCF101, and EuroSAT datasets which is ",
                "0.09",
                "%",
                ",",
                "0.66",
                "%",
                "percent",
                "0.09",
                "percent",
                "0.66",
                "0.09\\%,0.66\\%",
                ", and ",
                "0.35",
                "%",
                "percent",
                "0.35",
                "0.35\\%",
                " higher than tuning full parameters of the gate model. Moreover, we save the communication resource consumption by ",
                "97.69",
                "%",
                "percent",
                "97.69",
                "97.69\\%",
                ".",
                "This is because the parameters changing of the local expert during training can cause the relationship between the global expert and the local expert to keep changing which makes it hard for the gate model to decide the decision weight it assigns to the two FMs and can cause unstableness in training which harm the performance. By freezing the gate parameters and inserting a lightweight gate adapter, the gate model can quickly adapt to the newly optimized parameters of the local expert while maintaining the feature extraction ability."
            ]
        ]
    },
    "S4.T3": {
        "caption": "TABLE III: Comparison of accuracy on different datasets",
        "table": "<table id=\"S4.T3.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T3.2.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\"></th>\n<th id=\"S4.T3.2.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" colspan=\"2\">Accuracy</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.2.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.2.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r\">Datasets</td>\n<td id=\"S4.T3.2.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Gate adapter only</td>\n<td id=\"S4.T3.2.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">All gate parameters</td>\n</tr>\n<tr id=\"S4.T3.2.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T3.2.3.2.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Food101</td>\n<td id=\"S4.T3.2.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">93.73%</td>\n<td id=\"S4.T3.2.3.2.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">93.64%</td>\n</tr>\n<tr id=\"S4.T3.2.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T3.2.4.3.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">UCF101</td>\n<td id=\"S4.T3.2.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">87.33%</td>\n<td id=\"S4.T3.2.4.3.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">86.67%</td>\n</tr>\n<tr id=\"S4.T3.2.5.4\" class=\"ltx_tr\">\n<td id=\"S4.T3.2.5.4.1\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">EuroSAT</td>\n<td id=\"S4.T3.2.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">99.46%</td>\n<td id=\"S4.T3.2.5.4.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t\">99.11%</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Impact of Mixture of Foundation Models architecture.",
                "\nWe compare the image classification accuracy of the model with the ",
                "MoFM",
                " architecture using the visual encoder ViT-B/16 and the model without the ",
                "MoFM",
                " architecture but with a visual encoder ViT-L/14, which has a much larger number of parameters. The first model is trained through all two stages of FedMS and the second model is trained through the first stage of FedMS. The total number of epochs of both models is set to 50 to ensure fair comparison. The comparison of the total number of parameters is shown in Tab. ",
                "II",
                ". The model with ",
                "MoFM",
                " architecture but with a smaller visual encoder has ",
                "27.33",
                "%",
                "percent",
                "27.33",
                "27.33\\%",
                " parameter less than another model.",
                "We can observe from Fig. ",
                "13",
                " that although with much fewer parameters, the model with the ",
                "MoFM",
                " architecture and trained through complete two stages achieves a higher accuracy on all datasets. It has an average accuracy increase of ",
                "2.36",
                "%",
                "percent",
                "2.36",
                "2.36\\%",
                " on all datasets. More specifically, with an increase of ",
                "2.03",
                "%",
                ",",
                "3.24",
                "%",
                "percent",
                "2.03",
                "percent",
                "3.24",
                "2.03\\%,3.24\\%",
                ", and ",
                "1.82",
                "%",
                "percent",
                "1.82",
                "1.82\\%",
                " on Food101, UCF101, and EuroSAT datasets.",
                "This surprising result demonstrates the superiority of the ",
                "MoFM",
                " architecture as it can intelligently assign different weights to different experts according to the characteristics of the images to be classified. This enables better generalization ability to data that is out of the distribution of clients‚Äô local datasets and enables better personalization ability to data that follow the local distribution of the local clients‚Äô local datasets.",
                "Impact of aggregation of gate parameters.",
                "\nWe compare the image classification accuracy of FedMS and FedMS with all gate parameters activated in the second training stage. We can observe from Tab. ",
                "IV",
                " that by only fine-tuning the last layer of the gate adapter, we can achieve an accuracy of ",
                "93.73",
                "%",
                ",",
                "87.33",
                "%",
                "percent",
                "93.73",
                "percent",
                "87.33",
                "93.73\\%,87.33\\%",
                ", and ",
                "99.46",
                "%",
                "percent",
                "99.46",
                "99.46\\%",
                " in Food101, UCF101, and EuroSAT datasets which is ",
                "0.09",
                "%",
                ",",
                "0.66",
                "%",
                "percent",
                "0.09",
                "percent",
                "0.66",
                "0.09\\%,0.66\\%",
                ", and ",
                "0.35",
                "%",
                "percent",
                "0.35",
                "0.35\\%",
                " higher than tuning full parameters of the gate model. Moreover, we save the communication resource consumption by ",
                "97.69",
                "%",
                "percent",
                "97.69",
                "97.69\\%",
                ".",
                "This is because the parameters changing of the local expert during training can cause the relationship between the global expert and the local expert to keep changing which makes it hard for the gate model to decide the decision weight it assigns to the two FMs and can cause unstableness in training which harm the performance. By freezing the gate parameters and inserting a lightweight gate adapter, the gate model can quickly adapt to the newly optimized parameters of the local expert while maintaining the feature extraction ability."
            ]
        ]
    },
    "S4.T4": {
        "caption": "TABLE IV: Comparison of the number of parameters of the gate adapter and the gate model",
        "table": "<table id=\"S4.T4.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T4.2.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T4.2.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\">Model types</th>\n<th id=\"S4.T4.2.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Number of parameters</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T4.2.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T4.2.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Gate adapter</td>\n<td id=\"S4.T4.2.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">264.19k</td>\n</tr>\n<tr id=\"S4.T4.2.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T4.2.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">Gate model</td>\n<td id=\"S4.T4.2.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">11.44M</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Impact of Mixture of Foundation Models architecture.",
                "\nWe compare the image classification accuracy of the model with the ",
                "MoFM",
                " architecture using the visual encoder ViT-B/16 and the model without the ",
                "MoFM",
                " architecture but with a visual encoder ViT-L/14, which has a much larger number of parameters. The first model is trained through all two stages of FedMS and the second model is trained through the first stage of FedMS. The total number of epochs of both models is set to 50 to ensure fair comparison. The comparison of the total number of parameters is shown in Tab. ",
                "II",
                ". The model with ",
                "MoFM",
                " architecture but with a smaller visual encoder has ",
                "27.33",
                "%",
                "percent",
                "27.33",
                "27.33\\%",
                " parameter less than another model.",
                "We can observe from Fig. ",
                "13",
                " that although with much fewer parameters, the model with the ",
                "MoFM",
                " architecture and trained through complete two stages achieves a higher accuracy on all datasets. It has an average accuracy increase of ",
                "2.36",
                "%",
                "percent",
                "2.36",
                "2.36\\%",
                " on all datasets. More specifically, with an increase of ",
                "2.03",
                "%",
                ",",
                "3.24",
                "%",
                "percent",
                "2.03",
                "percent",
                "3.24",
                "2.03\\%,3.24\\%",
                ", and ",
                "1.82",
                "%",
                "percent",
                "1.82",
                "1.82\\%",
                " on Food101, UCF101, and EuroSAT datasets.",
                "This surprising result demonstrates the superiority of the ",
                "MoFM",
                " architecture as it can intelligently assign different weights to different experts according to the characteristics of the images to be classified. This enables better generalization ability to data that is out of the distribution of clients‚Äô local datasets and enables better personalization ability to data that follow the local distribution of the local clients‚Äô local datasets.",
                "Impact of aggregation of gate parameters.",
                "\nWe compare the image classification accuracy of FedMS and FedMS with all gate parameters activated in the second training stage. We can observe from Tab. ",
                "IV",
                " that by only fine-tuning the last layer of the gate adapter, we can achieve an accuracy of ",
                "93.73",
                "%",
                ",",
                "87.33",
                "%",
                "percent",
                "93.73",
                "percent",
                "87.33",
                "93.73\\%,87.33\\%",
                ", and ",
                "99.46",
                "%",
                "percent",
                "99.46",
                "99.46\\%",
                " in Food101, UCF101, and EuroSAT datasets which is ",
                "0.09",
                "%",
                ",",
                "0.66",
                "%",
                "percent",
                "0.09",
                "percent",
                "0.66",
                "0.09\\%,0.66\\%",
                ", and ",
                "0.35",
                "%",
                "percent",
                "0.35",
                "0.35\\%",
                " higher than tuning full parameters of the gate model. Moreover, we save the communication resource consumption by ",
                "97.69",
                "%",
                "percent",
                "97.69",
                "97.69\\%",
                ".",
                "This is because the parameters changing of the local expert during training can cause the relationship between the global expert and the local expert to keep changing which makes it hard for the gate model to decide the decision weight it assigns to the two FMs and can cause unstableness in training which harm the performance. By freezing the gate parameters and inserting a lightweight gate adapter, the gate model can quickly adapt to the newly optimized parameters of the local expert while maintaining the feature extraction ability."
            ]
        ]
    }
}