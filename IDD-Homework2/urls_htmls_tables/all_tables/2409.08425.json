{
    "id_table_1": {
        "caption": "TABLE I:  Results on the FSD-mix dataset.",
        "table": "S2.T1.8",
        "footnotes": [],
        "references": [
            "As shown in Fig.  1 , our proposed SoloAudio model consists of several key components: a VAE encoder, a VAE decoder, a CLAP model, and a DiT-like model  [ 20 ] ."
        ]
    },
    "id_table_2": {
        "caption": "TABLE II:  Results on the FSD-mix dataset. We test both 22 seen labels (S) and 19 unseen labels (UNS) from the SynVGG-mix training data.",
        "table": "S3.T2.8",
        "footnotes": [],
        "references": [
            "The DiT block, detailed in Fig.  2 , includes an adaptive layer norm block, a multi-head self-attention (MHSA) block, and a multi-layer perceptron (MLP) block. The timestep  t t t italic_t  and reference embedding  x r subscript x r x_{r} italic_x start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT  serve as conditional information to regress the dimension-wise scale and shift parameters, which are incorporated into each block."
        ]
    },
    "id_table_3": {
        "caption": "TABLE III:  Results on the real AudioSet dataset. We report Extraction and Purity results with their  95 % percent 95 95\\% 95 %  confidence intervals.",
        "table": "S3.T3.17",
        "footnotes": [],
        "references": [
            "Following  [ 13 ] , we recruited  12 12 12 12  participants with recording or music production experiences to evaluate the listening perceptual quality of audios predicted by different TSE models. We evaluated the performance of language-oriented TSE in real-world application scenarios using the real evaluation data described in Section  III-A 3 . Each subject was asked to evaluate 41 audio pairs for each model. Each audio pair included the original mixture, a description of the target sound, and the models prediction for the extracted sound. For each audio pair, subjects were asked to respond to two questions:",
            "Table  I  shows the impact of adding skip connections to the DiT model, resulting in a clear performance improvement. In addition, we examine the impact of the CFG guidance scale on model performance. As shown in Fig.  3 , as the guidance scale increases, performance initially improves but then declines. We select optimal values of  2.5 2.5 2.5 2.5  for the audio-oriented TSE and  3.0 3.0 3.0 3.0  for the language-oriented TSE."
        ]
    }
}