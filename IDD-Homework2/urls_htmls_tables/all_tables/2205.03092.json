{
    "PAPER'S NUMBER OF TABLES": 6,
    "S5.T1": {
        "caption": "Table 1: Accuracy of noise robust federated self training with user feedback against various baselines for 20news and sst2 datasets; *: all models using feedback (with and without noise robustness) are statistically significant against the self training baseline (without feedback), at p<0.05ğ‘0.05p<0.05.",
        "table": "<table id=\"S5.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\" style=\"padding-left:2.5pt;padding-right:2.5pt;\"><span id=\"S5.T1.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\">Experimental settings</span></th>\n<th id=\"S5.T1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\" style=\"padding-left:2.5pt;padding-right:2.5pt;\"><span id=\"S5.T1.1.2.1.2.1\" class=\"ltx_text ltx_font_bold\">20 news</span></th>\n<th id=\"S5.T1.1.2.1.3\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column\" style=\"padding-left:2.5pt;padding-right:2.5pt;\"><span id=\"S5.T1.1.2.1.3.1\" class=\"ltx_text ltx_font_bold\">sst2</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">Initial model (<math id=\"S5.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"D_{s}\" display=\"inline\"><semantics id=\"S5.T1.1.1.1.m1.1a\"><msub id=\"S5.T1.1.1.1.m1.1.1\" xref=\"S5.T1.1.1.1.m1.1.1.cmml\"><mi id=\"S5.T1.1.1.1.m1.1.1.2\" xref=\"S5.T1.1.1.1.m1.1.1.2.cmml\">D</mi><mi id=\"S5.T1.1.1.1.m1.1.1.3\" xref=\"S5.T1.1.1.1.m1.1.1.3.cmml\">s</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.1.1.1.m1.1b\"><apply id=\"S5.T1.1.1.1.m1.1.1.cmml\" xref=\"S5.T1.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S5.T1.1.1.1.m1.1.1.1.cmml\" xref=\"S5.T1.1.1.1.m1.1.1\">subscript</csymbol><ci id=\"S5.T1.1.1.1.m1.1.1.2.cmml\" xref=\"S5.T1.1.1.1.m1.1.1.2\">ğ·</ci><ci id=\"S5.T1.1.1.1.m1.1.1.3.cmml\" xref=\"S5.T1.1.1.1.m1.1.1.3\">ğ‘ </ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.1.1.1.m1.1c\">D_{s}</annotation></semantics></math>)</td>\n<td id=\"S5.T1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">59.14</td>\n<td id=\"S5.T1.1.1.3\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">77.37</td>\n</tr>\n<tr id=\"S5.T1.1.3.1\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">Self training (no feedback)</td>\n<td id=\"S5.T1.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">60.79</td>\n<td id=\"S5.T1.1.3.1.3\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">77.26</td>\n</tr>\n<tr id=\"S5.T1.1.4.2\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.4.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">Positive feedback (noisy)</td>\n<td id=\"S5.T1.1.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">62.10</td>\n<td id=\"S5.T1.1.4.2.3\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">79.79</td>\n</tr>\n<tr id=\"S5.T1.1.5.3\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.5.3.1\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">All feedback (noisy)</td>\n<td id=\"S5.T1.1.5.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">65.01</td>\n<td id=\"S5.T1.1.5.3.3\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">85.17</td>\n</tr>\n<tr id=\"S5.T1.1.6.4\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.6.4.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">Positive feedback (noise robust)</td>\n<td id=\"S5.T1.1.6.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">62.33</td>\n<td id=\"S5.T1.1.6.4.3\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">79.85</td>\n</tr>\n<tr id=\"S5.T1.1.7.5\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.7.5.1\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">All feedback (noise robust)</td>\n<td id=\"S5.T1.1.7.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">65.13</td>\n<td id=\"S5.T1.1.7.5.3\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">85.39</td>\n</tr>\n<tr id=\"S5.T1.1.8.6\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.8.6.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">Positive feedback (noise free)</td>\n<td id=\"S5.T1.1.8.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">70.44</td>\n<td id=\"S5.T1.1.8.6.3\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">83.80</td>\n</tr>\n<tr id=\"S5.T1.1.9.7\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.9.7.1\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">All feedback (noise free)</td>\n<td id=\"S5.T1.1.9.7.2\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">75.13</td>\n<td id=\"S5.T1.1.9.7.3\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">88.58</td>\n</tr>\n<tr id=\"S5.T1.1.10.8\" class=\"ltx_tr\">\n<td id=\"S5.T1.1.10.8.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">Full supervision</td>\n<td id=\"S5.T1.1.10.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">82.12</td>\n<td id=\"S5.T1.1.10.8.3\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:2.5pt;padding-right:2.5pt;\">89.12</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "TableÂ 1 reports the % accuracy for each of the experimental setups described above across both datasets. We observe that in both the noisy and noise-free settings, the introduction of positive user feedback shows a marked improvement in performance when compared to the self-training baseline. There is an additional performance gain when we add negative feedback (all feedback baseline), which signifies the importance of learning from complementary labels. As expected, the improvement is substantially larger in the noise free setting, suggesting the need for model robustness to mitigate the effect of noise. Note that for sâ€‹sâ€‹tâ€‹2ğ‘ ğ‘ ğ‘¡2sst2, performance of the noise free model with all feedback is very close to that of full supervision, thanks to the fact that complementary labels in the case of binary classification provide same information as true labels. On the other hand, using perfect positive and negative feedback in 20â€‹nâ€‹eâ€‹wâ€‹s20ğ‘›ğ‘’ğ‘¤ğ‘ 20news is still sub-optimal compared to full supervision, since a negative label in this dataset is less informative compared to sâ€‹sâ€‹tâ€‹2ğ‘ ğ‘ ğ‘¡2sst2.",
            "To mitigate the effects of noise, we replace the traditional cross-entropy loss function with the active-passive loss described in Â§4.4, using the same experimental setups presented earlier (positive only and all-feedback), with Î³ğ›¾\\gamma and Î´ğ›¿\\delta values from the Mturk study. However, as evident in TableÂ 1, the robust loss functions only seem to confer marginal performance improvements in both datasets. This is likely due to the fact that the noise parameters extracted from Mturk belong to a moderate to low noise regime (SectionÂ 3.2), providing limited room for gains with noise robustness.",
            "TableÂ 4 shows our results across all five simulations for both datasets when trained with the noise robust loss function 8. As expected, the best model performance is achieved with the low-noise users, followed by the real-world users sampled from our MTurk study. In the three other simulations (adversarial, consistently positive, consistently negative), user feedback is highly noisy and unreliable, and the models show limited improvement over the initial seed model. Note that the performance in the positive feedback scenario is higher than negative feedback, which can be accredited to the fact that the initial seed modelâ€™s accuracy is greater 50% for both datasets (TableÂ 1). With >50%absentpercent50>50\\% accuracy, a majority of the pseudo-labels generated using the seed model will match the gold label. Hence, consistently positive feedback introduces less noise and in turn better performance compared to the all negative feedback model."
        ]
    },
    "S5.T2": {
        "caption": "Table 2: Performance analysis of noise robust loss functions trained on all feedback in different noise regimes for the 20news dataset; *: statistically significant against the adversarial model without robustness at p<0.05ğ‘0.05p<0.05.",
        "table": "<table id=\"S5.T2.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T2.4.5.1\" class=\"ltx_tr\">\n<th id=\"S5.T2.4.5.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\"><span id=\"S5.T2.4.5.1.1.1\" class=\"ltx_text ltx_font_bold\">Noise level</span></th>\n<th id=\"S5.T2.4.5.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\"><span id=\"S5.T2.4.5.1.2.1\" class=\"ltx_text ltx_font_bold\">Loss</span></th>\n<th id=\"S5.T2.4.5.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S5.T2.4.5.1.3.1\" class=\"ltx_text ltx_font_bold\">Accuracy</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T2.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S5.T2.1.1.2.1\" class=\"ltx_text\">Low</span></td>\n<td id=\"S5.T2.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S5.T2.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"loss_{robust}\" display=\"inline\"><semantics id=\"S5.T2.1.1.1.m1.1a\"><mrow id=\"S5.T2.1.1.1.m1.1.1\" xref=\"S5.T2.1.1.1.m1.1.1.cmml\"><mi id=\"S5.T2.1.1.1.m1.1.1.2\" xref=\"S5.T2.1.1.1.m1.1.1.2.cmml\">l</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T2.1.1.1.m1.1.1.1\" xref=\"S5.T2.1.1.1.m1.1.1.1.cmml\">â€‹</mo><mi id=\"S5.T2.1.1.1.m1.1.1.3\" xref=\"S5.T2.1.1.1.m1.1.1.3.cmml\">o</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T2.1.1.1.m1.1.1.1a\" xref=\"S5.T2.1.1.1.m1.1.1.1.cmml\">â€‹</mo><mi id=\"S5.T2.1.1.1.m1.1.1.4\" xref=\"S5.T2.1.1.1.m1.1.1.4.cmml\">s</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T2.1.1.1.m1.1.1.1b\" xref=\"S5.T2.1.1.1.m1.1.1.1.cmml\">â€‹</mo><msub id=\"S5.T2.1.1.1.m1.1.1.5\" xref=\"S5.T2.1.1.1.m1.1.1.5.cmml\"><mi id=\"S5.T2.1.1.1.m1.1.1.5.2\" xref=\"S5.T2.1.1.1.m1.1.1.5.2.cmml\">s</mi><mrow id=\"S5.T2.1.1.1.m1.1.1.5.3\" xref=\"S5.T2.1.1.1.m1.1.1.5.3.cmml\"><mi id=\"S5.T2.1.1.1.m1.1.1.5.3.2\" xref=\"S5.T2.1.1.1.m1.1.1.5.3.2.cmml\">r</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T2.1.1.1.m1.1.1.5.3.1\" xref=\"S5.T2.1.1.1.m1.1.1.5.3.1.cmml\">â€‹</mo><mi id=\"S5.T2.1.1.1.m1.1.1.5.3.3\" xref=\"S5.T2.1.1.1.m1.1.1.5.3.3.cmml\">o</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T2.1.1.1.m1.1.1.5.3.1a\" xref=\"S5.T2.1.1.1.m1.1.1.5.3.1.cmml\">â€‹</mo><mi id=\"S5.T2.1.1.1.m1.1.1.5.3.4\" xref=\"S5.T2.1.1.1.m1.1.1.5.3.4.cmml\">b</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T2.1.1.1.m1.1.1.5.3.1b\" xref=\"S5.T2.1.1.1.m1.1.1.5.3.1.cmml\">â€‹</mo><mi id=\"S5.T2.1.1.1.m1.1.1.5.3.5\" xref=\"S5.T2.1.1.1.m1.1.1.5.3.5.cmml\">u</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T2.1.1.1.m1.1.1.5.3.1c\" xref=\"S5.T2.1.1.1.m1.1.1.5.3.1.cmml\">â€‹</mo><mi id=\"S5.T2.1.1.1.m1.1.1.5.3.6\" xref=\"S5.T2.1.1.1.m1.1.1.5.3.6.cmml\">s</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T2.1.1.1.m1.1.1.5.3.1d\" xref=\"S5.T2.1.1.1.m1.1.1.5.3.1.cmml\">â€‹</mo><mi id=\"S5.T2.1.1.1.m1.1.1.5.3.7\" xref=\"S5.T2.1.1.1.m1.1.1.5.3.7.cmml\">t</mi></mrow></msub></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.1.1.1.m1.1b\"><apply id=\"S5.T2.1.1.1.m1.1.1.cmml\" xref=\"S5.T2.1.1.1.m1.1.1\"><times id=\"S5.T2.1.1.1.m1.1.1.1.cmml\" xref=\"S5.T2.1.1.1.m1.1.1.1\"></times><ci id=\"S5.T2.1.1.1.m1.1.1.2.cmml\" xref=\"S5.T2.1.1.1.m1.1.1.2\">ğ‘™</ci><ci id=\"S5.T2.1.1.1.m1.1.1.3.cmml\" xref=\"S5.T2.1.1.1.m1.1.1.3\">ğ‘œ</ci><ci id=\"S5.T2.1.1.1.m1.1.1.4.cmml\" xref=\"S5.T2.1.1.1.m1.1.1.4\">ğ‘ </ci><apply id=\"S5.T2.1.1.1.m1.1.1.5.cmml\" xref=\"S5.T2.1.1.1.m1.1.1.5\"><csymbol cd=\"ambiguous\" id=\"S5.T2.1.1.1.m1.1.1.5.1.cmml\" xref=\"S5.T2.1.1.1.m1.1.1.5\">subscript</csymbol><ci id=\"S5.T2.1.1.1.m1.1.1.5.2.cmml\" xref=\"S5.T2.1.1.1.m1.1.1.5.2\">ğ‘ </ci><apply id=\"S5.T2.1.1.1.m1.1.1.5.3.cmml\" xref=\"S5.T2.1.1.1.m1.1.1.5.3\"><times id=\"S5.T2.1.1.1.m1.1.1.5.3.1.cmml\" xref=\"S5.T2.1.1.1.m1.1.1.5.3.1\"></times><ci id=\"S5.T2.1.1.1.m1.1.1.5.3.2.cmml\" xref=\"S5.T2.1.1.1.m1.1.1.5.3.2\">ğ‘Ÿ</ci><ci id=\"S5.T2.1.1.1.m1.1.1.5.3.3.cmml\" xref=\"S5.T2.1.1.1.m1.1.1.5.3.3\">ğ‘œ</ci><ci id=\"S5.T2.1.1.1.m1.1.1.5.3.4.cmml\" xref=\"S5.T2.1.1.1.m1.1.1.5.3.4\">ğ‘</ci><ci id=\"S5.T2.1.1.1.m1.1.1.5.3.5.cmml\" xref=\"S5.T2.1.1.1.m1.1.1.5.3.5\">ğ‘¢</ci><ci id=\"S5.T2.1.1.1.m1.1.1.5.3.6.cmml\" xref=\"S5.T2.1.1.1.m1.1.1.5.3.6\">ğ‘ </ci><ci id=\"S5.T2.1.1.1.m1.1.1.5.3.7.cmml\" xref=\"S5.T2.1.1.1.m1.1.1.5.3.7\">ğ‘¡</ci></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.1.1.1.m1.1c\">loss_{robust}</annotation></semantics></math></td>\n<td id=\"S5.T2.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">73.29</td>\n</tr>\n<tr id=\"S5.T2.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T2.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><math id=\"S5.T2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"loss_{reg}\" display=\"inline\"><semantics id=\"S5.T2.2.2.1.m1.1a\"><mrow id=\"S5.T2.2.2.1.m1.1.1\" xref=\"S5.T2.2.2.1.m1.1.1.cmml\"><mi id=\"S5.T2.2.2.1.m1.1.1.2\" xref=\"S5.T2.2.2.1.m1.1.1.2.cmml\">l</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T2.2.2.1.m1.1.1.1\" xref=\"S5.T2.2.2.1.m1.1.1.1.cmml\">â€‹</mo><mi id=\"S5.T2.2.2.1.m1.1.1.3\" xref=\"S5.T2.2.2.1.m1.1.1.3.cmml\">o</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T2.2.2.1.m1.1.1.1a\" xref=\"S5.T2.2.2.1.m1.1.1.1.cmml\">â€‹</mo><mi id=\"S5.T2.2.2.1.m1.1.1.4\" xref=\"S5.T2.2.2.1.m1.1.1.4.cmml\">s</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T2.2.2.1.m1.1.1.1b\" xref=\"S5.T2.2.2.1.m1.1.1.1.cmml\">â€‹</mo><msub id=\"S5.T2.2.2.1.m1.1.1.5\" xref=\"S5.T2.2.2.1.m1.1.1.5.cmml\"><mi id=\"S5.T2.2.2.1.m1.1.1.5.2\" xref=\"S5.T2.2.2.1.m1.1.1.5.2.cmml\">s</mi><mrow id=\"S5.T2.2.2.1.m1.1.1.5.3\" xref=\"S5.T2.2.2.1.m1.1.1.5.3.cmml\"><mi id=\"S5.T2.2.2.1.m1.1.1.5.3.2\" xref=\"S5.T2.2.2.1.m1.1.1.5.3.2.cmml\">r</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T2.2.2.1.m1.1.1.5.3.1\" xref=\"S5.T2.2.2.1.m1.1.1.5.3.1.cmml\">â€‹</mo><mi id=\"S5.T2.2.2.1.m1.1.1.5.3.3\" xref=\"S5.T2.2.2.1.m1.1.1.5.3.3.cmml\">e</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T2.2.2.1.m1.1.1.5.3.1a\" xref=\"S5.T2.2.2.1.m1.1.1.5.3.1.cmml\">â€‹</mo><mi id=\"S5.T2.2.2.1.m1.1.1.5.3.4\" xref=\"S5.T2.2.2.1.m1.1.1.5.3.4.cmml\">g</mi></mrow></msub></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.2.2.1.m1.1b\"><apply id=\"S5.T2.2.2.1.m1.1.1.cmml\" xref=\"S5.T2.2.2.1.m1.1.1\"><times id=\"S5.T2.2.2.1.m1.1.1.1.cmml\" xref=\"S5.T2.2.2.1.m1.1.1.1\"></times><ci id=\"S5.T2.2.2.1.m1.1.1.2.cmml\" xref=\"S5.T2.2.2.1.m1.1.1.2\">ğ‘™</ci><ci id=\"S5.T2.2.2.1.m1.1.1.3.cmml\" xref=\"S5.T2.2.2.1.m1.1.1.3\">ğ‘œ</ci><ci id=\"S5.T2.2.2.1.m1.1.1.4.cmml\" xref=\"S5.T2.2.2.1.m1.1.1.4\">ğ‘ </ci><apply id=\"S5.T2.2.2.1.m1.1.1.5.cmml\" xref=\"S5.T2.2.2.1.m1.1.1.5\"><csymbol cd=\"ambiguous\" id=\"S5.T2.2.2.1.m1.1.1.5.1.cmml\" xref=\"S5.T2.2.2.1.m1.1.1.5\">subscript</csymbol><ci id=\"S5.T2.2.2.1.m1.1.1.5.2.cmml\" xref=\"S5.T2.2.2.1.m1.1.1.5.2\">ğ‘ </ci><apply id=\"S5.T2.2.2.1.m1.1.1.5.3.cmml\" xref=\"S5.T2.2.2.1.m1.1.1.5.3\"><times id=\"S5.T2.2.2.1.m1.1.1.5.3.1.cmml\" xref=\"S5.T2.2.2.1.m1.1.1.5.3.1\"></times><ci id=\"S5.T2.2.2.1.m1.1.1.5.3.2.cmml\" xref=\"S5.T2.2.2.1.m1.1.1.5.3.2\">ğ‘Ÿ</ci><ci id=\"S5.T2.2.2.1.m1.1.1.5.3.3.cmml\" xref=\"S5.T2.2.2.1.m1.1.1.5.3.3\">ğ‘’</ci><ci id=\"S5.T2.2.2.1.m1.1.1.5.3.4.cmml\" xref=\"S5.T2.2.2.1.m1.1.1.5.3.4\">ğ‘”</ci></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.2.2.1.m1.1c\">loss_{reg}</annotation></semantics></math></td>\n<td id=\"S5.T2.2.2.2\" class=\"ltx_td ltx_align_center\">74.30</td>\n</tr>\n<tr id=\"S5.T2.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T2.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S5.T2.3.3.2.1\" class=\"ltx_text\">Adversarial</span></td>\n<td id=\"S5.T2.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S5.T2.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"loss_{robust}\" display=\"inline\"><semantics id=\"S5.T2.3.3.1.m1.1a\"><mrow id=\"S5.T2.3.3.1.m1.1.1\" xref=\"S5.T2.3.3.1.m1.1.1.cmml\"><mi id=\"S5.T2.3.3.1.m1.1.1.2\" xref=\"S5.T2.3.3.1.m1.1.1.2.cmml\">l</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T2.3.3.1.m1.1.1.1\" xref=\"S5.T2.3.3.1.m1.1.1.1.cmml\">â€‹</mo><mi id=\"S5.T2.3.3.1.m1.1.1.3\" xref=\"S5.T2.3.3.1.m1.1.1.3.cmml\">o</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T2.3.3.1.m1.1.1.1a\" xref=\"S5.T2.3.3.1.m1.1.1.1.cmml\">â€‹</mo><mi id=\"S5.T2.3.3.1.m1.1.1.4\" xref=\"S5.T2.3.3.1.m1.1.1.4.cmml\">s</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T2.3.3.1.m1.1.1.1b\" xref=\"S5.T2.3.3.1.m1.1.1.1.cmml\">â€‹</mo><msub id=\"S5.T2.3.3.1.m1.1.1.5\" xref=\"S5.T2.3.3.1.m1.1.1.5.cmml\"><mi id=\"S5.T2.3.3.1.m1.1.1.5.2\" xref=\"S5.T2.3.3.1.m1.1.1.5.2.cmml\">s</mi><mrow id=\"S5.T2.3.3.1.m1.1.1.5.3\" xref=\"S5.T2.3.3.1.m1.1.1.5.3.cmml\"><mi id=\"S5.T2.3.3.1.m1.1.1.5.3.2\" xref=\"S5.T2.3.3.1.m1.1.1.5.3.2.cmml\">r</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T2.3.3.1.m1.1.1.5.3.1\" xref=\"S5.T2.3.3.1.m1.1.1.5.3.1.cmml\">â€‹</mo><mi id=\"S5.T2.3.3.1.m1.1.1.5.3.3\" xref=\"S5.T2.3.3.1.m1.1.1.5.3.3.cmml\">o</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T2.3.3.1.m1.1.1.5.3.1a\" xref=\"S5.T2.3.3.1.m1.1.1.5.3.1.cmml\">â€‹</mo><mi id=\"S5.T2.3.3.1.m1.1.1.5.3.4\" xref=\"S5.T2.3.3.1.m1.1.1.5.3.4.cmml\">b</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T2.3.3.1.m1.1.1.5.3.1b\" xref=\"S5.T2.3.3.1.m1.1.1.5.3.1.cmml\">â€‹</mo><mi id=\"S5.T2.3.3.1.m1.1.1.5.3.5\" xref=\"S5.T2.3.3.1.m1.1.1.5.3.5.cmml\">u</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T2.3.3.1.m1.1.1.5.3.1c\" xref=\"S5.T2.3.3.1.m1.1.1.5.3.1.cmml\">â€‹</mo><mi id=\"S5.T2.3.3.1.m1.1.1.5.3.6\" xref=\"S5.T2.3.3.1.m1.1.1.5.3.6.cmml\">s</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T2.3.3.1.m1.1.1.5.3.1d\" xref=\"S5.T2.3.3.1.m1.1.1.5.3.1.cmml\">â€‹</mo><mi id=\"S5.T2.3.3.1.m1.1.1.5.3.7\" xref=\"S5.T2.3.3.1.m1.1.1.5.3.7.cmml\">t</mi></mrow></msub></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.3.3.1.m1.1b\"><apply id=\"S5.T2.3.3.1.m1.1.1.cmml\" xref=\"S5.T2.3.3.1.m1.1.1\"><times id=\"S5.T2.3.3.1.m1.1.1.1.cmml\" xref=\"S5.T2.3.3.1.m1.1.1.1\"></times><ci id=\"S5.T2.3.3.1.m1.1.1.2.cmml\" xref=\"S5.T2.3.3.1.m1.1.1.2\">ğ‘™</ci><ci id=\"S5.T2.3.3.1.m1.1.1.3.cmml\" xref=\"S5.T2.3.3.1.m1.1.1.3\">ğ‘œ</ci><ci id=\"S5.T2.3.3.1.m1.1.1.4.cmml\" xref=\"S5.T2.3.3.1.m1.1.1.4\">ğ‘ </ci><apply id=\"S5.T2.3.3.1.m1.1.1.5.cmml\" xref=\"S5.T2.3.3.1.m1.1.1.5\"><csymbol cd=\"ambiguous\" id=\"S5.T2.3.3.1.m1.1.1.5.1.cmml\" xref=\"S5.T2.3.3.1.m1.1.1.5\">subscript</csymbol><ci id=\"S5.T2.3.3.1.m1.1.1.5.2.cmml\" xref=\"S5.T2.3.3.1.m1.1.1.5.2\">ğ‘ </ci><apply id=\"S5.T2.3.3.1.m1.1.1.5.3.cmml\" xref=\"S5.T2.3.3.1.m1.1.1.5.3\"><times id=\"S5.T2.3.3.1.m1.1.1.5.3.1.cmml\" xref=\"S5.T2.3.3.1.m1.1.1.5.3.1\"></times><ci id=\"S5.T2.3.3.1.m1.1.1.5.3.2.cmml\" xref=\"S5.T2.3.3.1.m1.1.1.5.3.2\">ğ‘Ÿ</ci><ci id=\"S5.T2.3.3.1.m1.1.1.5.3.3.cmml\" xref=\"S5.T2.3.3.1.m1.1.1.5.3.3\">ğ‘œ</ci><ci id=\"S5.T2.3.3.1.m1.1.1.5.3.4.cmml\" xref=\"S5.T2.3.3.1.m1.1.1.5.3.4\">ğ‘</ci><ci id=\"S5.T2.3.3.1.m1.1.1.5.3.5.cmml\" xref=\"S5.T2.3.3.1.m1.1.1.5.3.5\">ğ‘¢</ci><ci id=\"S5.T2.3.3.1.m1.1.1.5.3.6.cmml\" xref=\"S5.T2.3.3.1.m1.1.1.5.3.6\">ğ‘ </ci><ci id=\"S5.T2.3.3.1.m1.1.1.5.3.7.cmml\" xref=\"S5.T2.3.3.1.m1.1.1.5.3.7\">ğ‘¡</ci></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.3.3.1.m1.1c\">loss_{robust}</annotation></semantics></math></td>\n<td id=\"S5.T2.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">42.26*</td>\n</tr>\n<tr id=\"S5.T2.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T2.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><math id=\"S5.T2.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"loss_{reg}\" display=\"inline\"><semantics id=\"S5.T2.4.4.1.m1.1a\"><mrow id=\"S5.T2.4.4.1.m1.1.1\" xref=\"S5.T2.4.4.1.m1.1.1.cmml\"><mi id=\"S5.T2.4.4.1.m1.1.1.2\" xref=\"S5.T2.4.4.1.m1.1.1.2.cmml\">l</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T2.4.4.1.m1.1.1.1\" xref=\"S5.T2.4.4.1.m1.1.1.1.cmml\">â€‹</mo><mi id=\"S5.T2.4.4.1.m1.1.1.3\" xref=\"S5.T2.4.4.1.m1.1.1.3.cmml\">o</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T2.4.4.1.m1.1.1.1a\" xref=\"S5.T2.4.4.1.m1.1.1.1.cmml\">â€‹</mo><mi id=\"S5.T2.4.4.1.m1.1.1.4\" xref=\"S5.T2.4.4.1.m1.1.1.4.cmml\">s</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T2.4.4.1.m1.1.1.1b\" xref=\"S5.T2.4.4.1.m1.1.1.1.cmml\">â€‹</mo><msub id=\"S5.T2.4.4.1.m1.1.1.5\" xref=\"S5.T2.4.4.1.m1.1.1.5.cmml\"><mi id=\"S5.T2.4.4.1.m1.1.1.5.2\" xref=\"S5.T2.4.4.1.m1.1.1.5.2.cmml\">s</mi><mrow id=\"S5.T2.4.4.1.m1.1.1.5.3\" xref=\"S5.T2.4.4.1.m1.1.1.5.3.cmml\"><mi id=\"S5.T2.4.4.1.m1.1.1.5.3.2\" xref=\"S5.T2.4.4.1.m1.1.1.5.3.2.cmml\">r</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T2.4.4.1.m1.1.1.5.3.1\" xref=\"S5.T2.4.4.1.m1.1.1.5.3.1.cmml\">â€‹</mo><mi id=\"S5.T2.4.4.1.m1.1.1.5.3.3\" xref=\"S5.T2.4.4.1.m1.1.1.5.3.3.cmml\">e</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S5.T2.4.4.1.m1.1.1.5.3.1a\" xref=\"S5.T2.4.4.1.m1.1.1.5.3.1.cmml\">â€‹</mo><mi id=\"S5.T2.4.4.1.m1.1.1.5.3.4\" xref=\"S5.T2.4.4.1.m1.1.1.5.3.4.cmml\">g</mi></mrow></msub></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.4.4.1.m1.1b\"><apply id=\"S5.T2.4.4.1.m1.1.1.cmml\" xref=\"S5.T2.4.4.1.m1.1.1\"><times id=\"S5.T2.4.4.1.m1.1.1.1.cmml\" xref=\"S5.T2.4.4.1.m1.1.1.1\"></times><ci id=\"S5.T2.4.4.1.m1.1.1.2.cmml\" xref=\"S5.T2.4.4.1.m1.1.1.2\">ğ‘™</ci><ci id=\"S5.T2.4.4.1.m1.1.1.3.cmml\" xref=\"S5.T2.4.4.1.m1.1.1.3\">ğ‘œ</ci><ci id=\"S5.T2.4.4.1.m1.1.1.4.cmml\" xref=\"S5.T2.4.4.1.m1.1.1.4\">ğ‘ </ci><apply id=\"S5.T2.4.4.1.m1.1.1.5.cmml\" xref=\"S5.T2.4.4.1.m1.1.1.5\"><csymbol cd=\"ambiguous\" id=\"S5.T2.4.4.1.m1.1.1.5.1.cmml\" xref=\"S5.T2.4.4.1.m1.1.1.5\">subscript</csymbol><ci id=\"S5.T2.4.4.1.m1.1.1.5.2.cmml\" xref=\"S5.T2.4.4.1.m1.1.1.5.2\">ğ‘ </ci><apply id=\"S5.T2.4.4.1.m1.1.1.5.3.cmml\" xref=\"S5.T2.4.4.1.m1.1.1.5.3\"><times id=\"S5.T2.4.4.1.m1.1.1.5.3.1.cmml\" xref=\"S5.T2.4.4.1.m1.1.1.5.3.1\"></times><ci id=\"S5.T2.4.4.1.m1.1.1.5.3.2.cmml\" xref=\"S5.T2.4.4.1.m1.1.1.5.3.2\">ğ‘Ÿ</ci><ci id=\"S5.T2.4.4.1.m1.1.1.5.3.3.cmml\" xref=\"S5.T2.4.4.1.m1.1.1.5.3.3\">ğ‘’</ci><ci id=\"S5.T2.4.4.1.m1.1.1.5.3.4.cmml\" xref=\"S5.T2.4.4.1.m1.1.1.5.3.4\">ğ‘”</ci></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.4.4.1.m1.1c\">loss_{reg}</annotation></semantics></math></td>\n<td id=\"S5.T2.4.4.2\" class=\"ltx_td ltx_align_center\">25.19</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "To further investigate this, we explore two extreme cases of user feedback noise for the 20news dataset: i) low noise, where we simulate user feedback with Î³â†’1â†’ğ›¾1\\gamma\\rightarrow 1, Î´â†’1â†’ğ›¿1\\delta\\rightarrow 1 for all the clients, which imitates clients providing correct feedback with very high probability, and\nii) adversarial noise, with Î³â†’0â†’ğ›¾0\\gamma\\rightarrow 0, Î´â†’0â†’ğ›¿0\\delta\\rightarrow 0 for all the clients, which captures the possible risk of users deliberately providing incorrect feedback with high probability. In TableÂ 2, we compare the performances of the all feedback model trained with and without noise robustness in these two scenarios. As seen in the table, when user noise is high, the noise-robust loss functions show a statistically significant improvement against the noisy model, highlighting the value of adding noise robustness. In the low noise regime, adding robustness seems to cause negligible degradation in accuracy, but within the bounds of statistical error. Given this, we recommend using noise robustness in all applications of this framework unless it is well known before hand that the feedback has very low noise. We defer the task of developing a noise robustness regime that works for all noise levels to future work."
        ]
    },
    "S5.T3": {
        "caption": "Table 3: Model performance (accuracy) at varying values of Î³ğ›¾\\gamma and Î´ğ›¿\\delta",
        "table": "<table id=\"S5.T3.st1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T3.st1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T3.st1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r\"><math id=\"S5.T3.st1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\gamma/\\delta\" display=\"inline\"><semantics id=\"S5.T3.st1.1.1.1.m1.1a\"><mrow id=\"S5.T3.st1.1.1.1.m1.1.1\" xref=\"S5.T3.st1.1.1.1.m1.1.1.cmml\"><mi id=\"S5.T3.st1.1.1.1.m1.1.1.2\" xref=\"S5.T3.st1.1.1.1.m1.1.1.2.cmml\">Î³</mi><mo id=\"S5.T3.st1.1.1.1.m1.1.1.1\" xref=\"S5.T3.st1.1.1.1.m1.1.1.1.cmml\">/</mo><mi id=\"S5.T3.st1.1.1.1.m1.1.1.3\" xref=\"S5.T3.st1.1.1.1.m1.1.1.3.cmml\">Î´</mi></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T3.st1.1.1.1.m1.1b\"><apply id=\"S5.T3.st1.1.1.1.m1.1.1.cmml\" xref=\"S5.T3.st1.1.1.1.m1.1.1\"><divide id=\"S5.T3.st1.1.1.1.m1.1.1.1.cmml\" xref=\"S5.T3.st1.1.1.1.m1.1.1.1\"></divide><ci id=\"S5.T3.st1.1.1.1.m1.1.1.2.cmml\" xref=\"S5.T3.st1.1.1.1.m1.1.1.2\">ğ›¾</ci><ci id=\"S5.T3.st1.1.1.1.m1.1.1.3.cmml\" xref=\"S5.T3.st1.1.1.1.m1.1.1.3\">ğ›¿</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T3.st1.1.1.1.m1.1c\">\\gamma/\\delta</annotation></semantics></math></th>\n<th id=\"S5.T3.st1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\">0.7</th>\n<th id=\"S5.T3.st1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\">0.5</th>\n<th id=\"S5.T3.st1.1.1.4\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column\">0.3</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T3.st1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S5.T3.st1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">0.7</th>\n<td id=\"S5.T3.st1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">66.69</td>\n<td id=\"S5.T3.st1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.18</td>\n<td id=\"S5.T3.st1.1.2.1.4\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">60.66</td>\n</tr>\n<tr id=\"S5.T3.st1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S5.T3.st1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">0.5</th>\n<td id=\"S5.T3.st1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">65.56</td>\n<td id=\"S5.T3.st1.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\">59.15</td>\n<td id=\"S5.T3.st1.1.3.2.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\">59.73</td>\n</tr>\n<tr id=\"S5.T3.st1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S5.T3.st1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">0.3</th>\n<td id=\"S5.T3.st1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">60.01</td>\n<td id=\"S5.T3.st1.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\">58.94</td>\n<td id=\"S5.T3.st1.1.4.3.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\">58.21</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "As discussed in Â§4.4, the level of feedback noise has a substantial impact on model performance.\nIn this section, we further investigate this effect, simulating user feedback across various noise parameters values, spanning Î³,Î´âˆˆ{0.3,0.5,0.7}ğ›¾ğ›¿0.30.50.7\\gamma,\\delta\\in\\{0.3,0.5,0.7\\}, to capture different points in the Î³âˆ’Î´ğ›¾ğ›¿\\gamma-\\delta space. TableÂ 3 shows our results for each dataset with the noise robust loss function 8. As expected, as Î³â†’0â†’ğ›¾0\\gamma\\rightarrow 0 and/or Î´â†’0â†’ğ›¿0\\delta\\rightarrow 0, model performance decreases on both datasets. At very low values of Î´ğ›¿\\delta and Î³ğ›¾\\gamma, e.g. both â‰¤\\leq 0.5, training on the extremely noisy user feedback actually decreases model performance below the original seed model. This is not unexpected, since at Î´=0.5ğ›¿0.5\\delta=0.5 and Î³=0.5ğ›¾0.5\\gamma=0.5, user feedback is essentially random noise, and at lower values the feedback is adversarial. These results highlight the importance of evaluating the reliability of user feedback before using it to further train an ML system."
        ]
    },
    "S5.T3.st1": {
        "caption": "(a) 20news dataset; initial model performance: 59.14, performance with all feedback and no noise (Î³=Î´=1ğ›¾ğ›¿1\\gamma=\\delta=1): 75.13.",
        "table": "<table id=\"S5.T3.st1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T3.st1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T3.st1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r\"><math id=\"S5.T3.st1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\gamma/\\delta\" display=\"inline\"><semantics id=\"S5.T3.st1.1.1.1.m1.1a\"><mrow id=\"S5.T3.st1.1.1.1.m1.1.1\" xref=\"S5.T3.st1.1.1.1.m1.1.1.cmml\"><mi id=\"S5.T3.st1.1.1.1.m1.1.1.2\" xref=\"S5.T3.st1.1.1.1.m1.1.1.2.cmml\">Î³</mi><mo id=\"S5.T3.st1.1.1.1.m1.1.1.1\" xref=\"S5.T3.st1.1.1.1.m1.1.1.1.cmml\">/</mo><mi id=\"S5.T3.st1.1.1.1.m1.1.1.3\" xref=\"S5.T3.st1.1.1.1.m1.1.1.3.cmml\">Î´</mi></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T3.st1.1.1.1.m1.1b\"><apply id=\"S5.T3.st1.1.1.1.m1.1.1.cmml\" xref=\"S5.T3.st1.1.1.1.m1.1.1\"><divide id=\"S5.T3.st1.1.1.1.m1.1.1.1.cmml\" xref=\"S5.T3.st1.1.1.1.m1.1.1.1\"></divide><ci id=\"S5.T3.st1.1.1.1.m1.1.1.2.cmml\" xref=\"S5.T3.st1.1.1.1.m1.1.1.2\">ğ›¾</ci><ci id=\"S5.T3.st1.1.1.1.m1.1.1.3.cmml\" xref=\"S5.T3.st1.1.1.1.m1.1.1.3\">ğ›¿</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T3.st1.1.1.1.m1.1c\">\\gamma/\\delta</annotation></semantics></math></th>\n<th id=\"S5.T3.st1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\">0.7</th>\n<th id=\"S5.T3.st1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\">0.5</th>\n<th id=\"S5.T3.st1.1.1.4\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column\">0.3</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T3.st1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S5.T3.st1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">0.7</th>\n<td id=\"S5.T3.st1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">66.69</td>\n<td id=\"S5.T3.st1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.18</td>\n<td id=\"S5.T3.st1.1.2.1.4\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">60.66</td>\n</tr>\n<tr id=\"S5.T3.st1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S5.T3.st1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">0.5</th>\n<td id=\"S5.T3.st1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">65.56</td>\n<td id=\"S5.T3.st1.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\">59.15</td>\n<td id=\"S5.T3.st1.1.3.2.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\">59.73</td>\n</tr>\n<tr id=\"S5.T3.st1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S5.T3.st1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">0.3</th>\n<td id=\"S5.T3.st1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">60.01</td>\n<td id=\"S5.T3.st1.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\">58.94</td>\n<td id=\"S5.T3.st1.1.4.3.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\">58.21</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "TableÂ 1 reports the % accuracy for each of the experimental setups described above across both datasets. We observe that in both the noisy and noise-free settings, the introduction of positive user feedback shows a marked improvement in performance when compared to the self-training baseline. There is an additional performance gain when we add negative feedback (all feedback baseline), which signifies the importance of learning from complementary labels. As expected, the improvement is substantially larger in the noise free setting, suggesting the need for model robustness to mitigate the effect of noise. Note that for sâ€‹sâ€‹tâ€‹2ğ‘ ğ‘ ğ‘¡2sst2, performance of the noise free model with all feedback is very close to that of full supervision, thanks to the fact that complementary labels in the case of binary classification provide same information as true labels. On the other hand, using perfect positive and negative feedback in 20â€‹nâ€‹eâ€‹wâ€‹s20ğ‘›ğ‘’ğ‘¤ğ‘ 20news is still sub-optimal compared to full supervision, since a negative label in this dataset is less informative compared to sâ€‹sâ€‹tâ€‹2ğ‘ ğ‘ ğ‘¡2sst2.",
            "To mitigate the effects of noise, we replace the traditional cross-entropy loss function with the active-passive loss described in Â§4.4, using the same experimental setups presented earlier (positive only and all-feedback), with Î³ğ›¾\\gamma and Î´ğ›¿\\delta values from the Mturk study. However, as evident in TableÂ 1, the robust loss functions only seem to confer marginal performance improvements in both datasets. This is likely due to the fact that the noise parameters extracted from Mturk belong to a moderate to low noise regime (SectionÂ 3.2), providing limited room for gains with noise robustness.",
            "To further investigate this, we explore two extreme cases of user feedback noise for the 20news dataset: i) low noise, where we simulate user feedback with Î³â†’1â†’ğ›¾1\\gamma\\rightarrow 1, Î´â†’1â†’ğ›¿1\\delta\\rightarrow 1 for all the clients, which imitates clients providing correct feedback with very high probability, and\nii) adversarial noise, with Î³â†’0â†’ğ›¾0\\gamma\\rightarrow 0, Î´â†’0â†’ğ›¿0\\delta\\rightarrow 0 for all the clients, which captures the possible risk of users deliberately providing incorrect feedback with high probability. In TableÂ 2, we compare the performances of the all feedback model trained with and without noise robustness in these two scenarios. As seen in the table, when user noise is high, the noise-robust loss functions show a statistically significant improvement against the noisy model, highlighting the value of adding noise robustness. In the low noise regime, adding robustness seems to cause negligible degradation in accuracy, but within the bounds of statistical error. Given this, we recommend using noise robustness in all applications of this framework unless it is well known before hand that the feedback has very low noise. We defer the task of developing a noise robustness regime that works for all noise levels to future work.",
            "As discussed in Â§4.4, the level of feedback noise has a substantial impact on model performance.\nIn this section, we further investigate this effect, simulating user feedback across various noise parameters values, spanning Î³,Î´âˆˆ{0.3,0.5,0.7}ğ›¾ğ›¿0.30.50.7\\gamma,\\delta\\in\\{0.3,0.5,0.7\\}, to capture different points in the Î³âˆ’Î´ğ›¾ğ›¿\\gamma-\\delta space. TableÂ 3 shows our results for each dataset with the noise robust loss function 8. As expected, as Î³â†’0â†’ğ›¾0\\gamma\\rightarrow 0 and/or Î´â†’0â†’ğ›¿0\\delta\\rightarrow 0, model performance decreases on both datasets. At very low values of Î´ğ›¿\\delta and Î³ğ›¾\\gamma, e.g. both â‰¤\\leq 0.5, training on the extremely noisy user feedback actually decreases model performance below the original seed model. This is not unexpected, since at Î´=0.5ğ›¿0.5\\delta=0.5 and Î³=0.5ğ›¾0.5\\gamma=0.5, user feedback is essentially random noise, and at lower values the feedback is adversarial. These results highlight the importance of evaluating the reliability of user feedback before using it to further train an ML system.",
            "TableÂ 4 shows our results across all five simulations for both datasets when trained with the noise robust loss function 8. As expected, the best model performance is achieved with the low-noise users, followed by the real-world users sampled from our MTurk study. In the three other simulations (adversarial, consistently positive, consistently negative), user feedback is highly noisy and unreliable, and the models show limited improvement over the initial seed model. Note that the performance in the positive feedback scenario is higher than negative feedback, which can be accredited to the fact that the initial seed modelâ€™s accuracy is greater 50% for both datasets (TableÂ 1). With >50%absentpercent50>50\\% accuracy, a majority of the pseudo-labels generated using the seed model will match the gold label. Hence, consistently positive feedback introduces less noise and in turn better performance compared to the all negative feedback model."
        ]
    },
    "S5.T3.st2": {
        "caption": "(b) sst2 dataset; initial model performance: 77.37, performance with all feedback and no noise (Î³=Î´=1ğ›¾ğ›¿1\\gamma=\\delta=1): 88.58.",
        "table": "<table id=\"S5.T3.st2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T3.st2.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T3.st2.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\"><math id=\"S5.T3.st2.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\gamma/\\delta\" display=\"inline\"><semantics id=\"S5.T3.st2.1.1.1.m1.1a\"><mrow id=\"S5.T3.st2.1.1.1.m1.1.1\" xref=\"S5.T3.st2.1.1.1.m1.1.1.cmml\"><mi id=\"S5.T3.st2.1.1.1.m1.1.1.2\" xref=\"S5.T3.st2.1.1.1.m1.1.1.2.cmml\">Î³</mi><mo id=\"S5.T3.st2.1.1.1.m1.1.1.1\" xref=\"S5.T3.st2.1.1.1.m1.1.1.1.cmml\">/</mo><mi id=\"S5.T3.st2.1.1.1.m1.1.1.3\" xref=\"S5.T3.st2.1.1.1.m1.1.1.3.cmml\">Î´</mi></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T3.st2.1.1.1.m1.1b\"><apply id=\"S5.T3.st2.1.1.1.m1.1.1.cmml\" xref=\"S5.T3.st2.1.1.1.m1.1.1\"><divide id=\"S5.T3.st2.1.1.1.m1.1.1.1.cmml\" xref=\"S5.T3.st2.1.1.1.m1.1.1.1\"></divide><ci id=\"S5.T3.st2.1.1.1.m1.1.1.2.cmml\" xref=\"S5.T3.st2.1.1.1.m1.1.1.2\">ğ›¾</ci><ci id=\"S5.T3.st2.1.1.1.m1.1.1.3.cmml\" xref=\"S5.T3.st2.1.1.1.m1.1.1.3\">ğ›¿</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T3.st2.1.1.1.m1.1c\">\\gamma/\\delta</annotation></semantics></math></th>\n<th id=\"S5.T3.st2.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\">0.7</th>\n<th id=\"S5.T3.st2.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\">0.5</th>\n<th id=\"S5.T3.st2.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">0.3</th>\n<th id=\"S5.T3.st2.1.1.5\" class=\"ltx_td ltx_th ltx_th_column\"></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T3.st2.1.2.1\" class=\"ltx_tr\">\n<td id=\"S5.T3.st2.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.7</td>\n<td id=\"S5.T3.st2.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">83.86</td>\n<td id=\"S5.T3.st2.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">80.89</td>\n<td id=\"S5.T3.st2.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">76.17</td>\n<td id=\"S5.T3.st2.1.2.1.5\" class=\"ltx_td ltx_nopad_r ltx_border_t\"></td>\n</tr>\n<tr id=\"S5.T3.st2.1.3.2\" class=\"ltx_tr\">\n<td id=\"S5.T3.st2.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_r\">0.5</td>\n<td id=\"S5.T3.st2.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">81.99</td>\n<td id=\"S5.T3.st2.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\">77.38</td>\n<td id=\"S5.T3.st2.1.3.2.4\" class=\"ltx_td ltx_align_center\">75.07</td>\n<td id=\"S5.T3.st2.1.3.2.5\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S5.T3.st2.1.4.3\" class=\"ltx_tr\">\n<td id=\"S5.T3.st2.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_r\">0.3</td>\n<td id=\"S5.T3.st2.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">78.03</td>\n<td id=\"S5.T3.st2.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\">74.41</td>\n<td id=\"S5.T3.st2.1.4.3.4\" class=\"ltx_td ltx_align_center\">71.99</td>\n<td id=\"S5.T3.st2.1.4.3.5\" class=\"ltx_td\"></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "TableÂ 1 reports the % accuracy for each of the experimental setups described above across both datasets. We observe that in both the noisy and noise-free settings, the introduction of positive user feedback shows a marked improvement in performance when compared to the self-training baseline. There is an additional performance gain when we add negative feedback (all feedback baseline), which signifies the importance of learning from complementary labels. As expected, the improvement is substantially larger in the noise free setting, suggesting the need for model robustness to mitigate the effect of noise. Note that for sâ€‹sâ€‹tâ€‹2ğ‘ ğ‘ ğ‘¡2sst2, performance of the noise free model with all feedback is very close to that of full supervision, thanks to the fact that complementary labels in the case of binary classification provide same information as true labels. On the other hand, using perfect positive and negative feedback in 20â€‹nâ€‹eâ€‹wâ€‹s20ğ‘›ğ‘’ğ‘¤ğ‘ 20news is still sub-optimal compared to full supervision, since a negative label in this dataset is less informative compared to sâ€‹sâ€‹tâ€‹2ğ‘ ğ‘ ğ‘¡2sst2.",
            "To mitigate the effects of noise, we replace the traditional cross-entropy loss function with the active-passive loss described in Â§4.4, using the same experimental setups presented earlier (positive only and all-feedback), with Î³ğ›¾\\gamma and Î´ğ›¿\\delta values from the Mturk study. However, as evident in TableÂ 1, the robust loss functions only seem to confer marginal performance improvements in both datasets. This is likely due to the fact that the noise parameters extracted from Mturk belong to a moderate to low noise regime (SectionÂ 3.2), providing limited room for gains with noise robustness.",
            "To further investigate this, we explore two extreme cases of user feedback noise for the 20news dataset: i) low noise, where we simulate user feedback with Î³â†’1â†’ğ›¾1\\gamma\\rightarrow 1, Î´â†’1â†’ğ›¿1\\delta\\rightarrow 1 for all the clients, which imitates clients providing correct feedback with very high probability, and\nii) adversarial noise, with Î³â†’0â†’ğ›¾0\\gamma\\rightarrow 0, Î´â†’0â†’ğ›¿0\\delta\\rightarrow 0 for all the clients, which captures the possible risk of users deliberately providing incorrect feedback with high probability. In TableÂ 2, we compare the performances of the all feedback model trained with and without noise robustness in these two scenarios. As seen in the table, when user noise is high, the noise-robust loss functions show a statistically significant improvement against the noisy model, highlighting the value of adding noise robustness. In the low noise regime, adding robustness seems to cause negligible degradation in accuracy, but within the bounds of statistical error. Given this, we recommend using noise robustness in all applications of this framework unless it is well known before hand that the feedback has very low noise. We defer the task of developing a noise robustness regime that works for all noise levels to future work.",
            "As discussed in Â§4.4, the level of feedback noise has a substantial impact on model performance.\nIn this section, we further investigate this effect, simulating user feedback across various noise parameters values, spanning Î³,Î´âˆˆ{0.3,0.5,0.7}ğ›¾ğ›¿0.30.50.7\\gamma,\\delta\\in\\{0.3,0.5,0.7\\}, to capture different points in the Î³âˆ’Î´ğ›¾ğ›¿\\gamma-\\delta space. TableÂ 3 shows our results for each dataset with the noise robust loss function 8. As expected, as Î³â†’0â†’ğ›¾0\\gamma\\rightarrow 0 and/or Î´â†’0â†’ğ›¿0\\delta\\rightarrow 0, model performance decreases on both datasets. At very low values of Î´ğ›¿\\delta and Î³ğ›¾\\gamma, e.g. both â‰¤\\leq 0.5, training on the extremely noisy user feedback actually decreases model performance below the original seed model. This is not unexpected, since at Î´=0.5ğ›¿0.5\\delta=0.5 and Î³=0.5ğ›¾0.5\\gamma=0.5, user feedback is essentially random noise, and at lower values the feedback is adversarial. These results highlight the importance of evaluating the reliability of user feedback before using it to further train an ML system.",
            "TableÂ 4 shows our results across all five simulations for both datasets when trained with the noise robust loss function 8. As expected, the best model performance is achieved with the low-noise users, followed by the real-world users sampled from our MTurk study. In the three other simulations (adversarial, consistently positive, consistently negative), user feedback is highly noisy and unreliable, and the models show limited improvement over the initial seed model. Note that the performance in the positive feedback scenario is higher than negative feedback, which can be accredited to the fact that the initial seed modelâ€™s accuracy is greater 50% for both datasets (TableÂ 1). With >50%absentpercent50>50\\% accuracy, a majority of the pseudo-labels generated using the seed model will match the gold label. Hence, consistently positive feedback introduces less noise and in turn better performance compared to the all negative feedback model."
        ]
    },
    "S5.T4": {
        "caption": "Table 4: Model performance at various user behaviors.",
        "table": "<table id=\"S5.T4.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T4.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\"><span id=\"S5.T4.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">User Behavior</span></th>\n<th id=\"S5.T4.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\"><span id=\"S5.T4.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">20news</span></th>\n<th id=\"S5.T4.1.1.1.3\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column\"><span id=\"S5.T4.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">sst2</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T4.1.2.1\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Low noise</td>\n<td id=\"S5.T4.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">73.67</td>\n<td id=\"S5.T4.1.2.1.3\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">88.35</td>\n</tr>\n<tr id=\"S5.T4.1.3.2\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Adversarial</td>\n<td id=\"S5.T4.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">55.86</td>\n<td id=\"S5.T4.1.3.2.3\" class=\"ltx_td ltx_nopad_r ltx_align_center\">64.85</td>\n</tr>\n<tr id=\"S5.T4.1.4.3\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Always positive</td>\n<td id=\"S5.T4.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">60.99</td>\n<td id=\"S5.T4.1.4.3.3\" class=\"ltx_td ltx_nopad_r ltx_align_center\">77.16</td>\n</tr>\n<tr id=\"S5.T4.1.5.4\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Always negative</td>\n<td id=\"S5.T4.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">58.92</td>\n<td id=\"S5.T4.1.5.4.3\" class=\"ltx_td ltx_nopad_r ltx_align_center\">74.13</td>\n</tr>\n<tr id=\"S5.T4.1.6.5\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.6.5.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Real world (mturk study)</td>\n<td id=\"S5.T4.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\">65.37</td>\n<td id=\"S5.T4.1.6.5.3\" class=\"ltx_td ltx_nopad_r ltx_align_center\">85.61</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "TableÂ 4 shows our results across all five simulations for both datasets when trained with the noise robust loss function 8. As expected, the best model performance is achieved with the low-noise users, followed by the real-world users sampled from our MTurk study. In the three other simulations (adversarial, consistently positive, consistently negative), user feedback is highly noisy and unreliable, and the models show limited improvement over the initial seed model. Note that the performance in the positive feedback scenario is higher than negative feedback, which can be accredited to the fact that the initial seed modelâ€™s accuracy is greater 50% for both datasets (TableÂ 1). With >50%absentpercent50>50\\% accuracy, a majority of the pseudo-labels generated using the seed model will match the gold label. Hence, consistently positive feedback introduces less noise and in turn better performance compared to the all negative feedback model."
        ]
    }
}