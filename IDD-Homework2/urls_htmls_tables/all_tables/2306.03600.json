{
    "PAPER'S NUMBER OF TABLES": 23,
    "S5.T1": {
        "caption": "Table 1. MAs and BAs in different scenarios in percent.",
        "table": "<table id=\"S5.T1.12\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T1.12.13\" class=\"ltx_tr\">\n<td id=\"S5.T1.12.13.1\" class=\"ltx_td ltx_border_r\" colspan=\"2\"></td>\n<td id=\"S5.T1.12.13.2\" class=\"ltx_td ltx_align_center\" colspan=\"12\">Scenario</td>\n</tr>\n<tr id=\"S5.T1.5.5\" class=\"ltx_tr\">\n<td id=\"S5.T1.5.5.6\" class=\"ltx_td ltx_border_r\" colspan=\"2\"></td>\n<td id=\"S5.T1.5.5.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\">Default</td>\n<td id=\"S5.T1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\">\n<svg id=\"S5.T1.1.1.1.pic1\" class=\"ltx_picture\" height=\"13.74\" overflow=\"visible\" version=\"1.1\" width=\"13.74\"><g transform=\"translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)\" fill=\"#000000\" stroke=\"#000000\" stroke-width=\"0.4pt\"><path d=\"M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0\" style=\"fill:none\"></path><g transform=\"matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)\" fill=\"#000000\" stroke=\"#000000\"><foreignobject width=\"6.92\" height=\"8.92\" transform=\"matrix(1 0 0 -1 0 16.6)\" overflow=\"visible\"><span id=\"S5.T1.1.1.1.pic1.1.1.1.1.1\" class=\"ltx_text\">1</span></foreignobject></g></g></svg>\n</td>\n<td id=\"S5.T1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\">\n<svg id=\"S5.T1.2.2.2.pic1\" class=\"ltx_picture\" height=\"13.74\" overflow=\"visible\" version=\"1.1\" width=\"13.74\"><g transform=\"translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)\" fill=\"#000000\" stroke=\"#000000\" stroke-width=\"0.4pt\"><path d=\"M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0\" style=\"fill:none\"></path><g transform=\"matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)\" fill=\"#000000\" stroke=\"#000000\"><foreignobject width=\"6.92\" height=\"8.92\" transform=\"matrix(1 0 0 -1 0 16.6)\" overflow=\"visible\"><span id=\"S5.T1.2.2.2.pic1.1.1.1.1.1\" class=\"ltx_text\">2</span></foreignobject></g></g></svg>\n</td>\n<td id=\"S5.T1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\">\n<svg id=\"S5.T1.3.3.3.pic1\" class=\"ltx_picture\" height=\"13.74\" overflow=\"visible\" version=\"1.1\" width=\"13.74\"><g transform=\"translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)\" fill=\"#000000\" stroke=\"#000000\" stroke-width=\"0.4pt\"><path d=\"M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0\" style=\"fill:none\"></path><g transform=\"matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)\" fill=\"#000000\" stroke=\"#000000\"><foreignobject width=\"6.92\" height=\"8.92\" transform=\"matrix(1 0 0 -1 0 16.6)\" overflow=\"visible\"><span id=\"S5.T1.3.3.3.pic1.1.1.1.1.1\" class=\"ltx_text\">3</span></foreignobject></g></g></svg>\n</td>\n<td id=\"S5.T1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\">\n<svg id=\"S5.T1.4.4.4.pic1\" class=\"ltx_picture\" height=\"13.74\" overflow=\"visible\" version=\"1.1\" width=\"13.74\"><g transform=\"translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)\" fill=\"#000000\" stroke=\"#000000\" stroke-width=\"0.4pt\"><path d=\"M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0\" style=\"fill:none\"></path><g transform=\"matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)\" fill=\"#000000\" stroke=\"#000000\"><foreignobject width=\"6.92\" height=\"8.92\" transform=\"matrix(1 0 0 -1 0 16.6)\" overflow=\"visible\"><span id=\"S5.T1.4.4.4.pic1.1.1.1.1.1\" class=\"ltx_text\">4</span></foreignobject></g></g></svg>\n</td>\n<td id=\"S5.T1.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"2\">\n<svg id=\"S5.T1.5.5.5.pic1\" class=\"ltx_picture\" height=\"13.74\" overflow=\"visible\" version=\"1.1\" width=\"13.74\"><g transform=\"translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)\" fill=\"#000000\" stroke=\"#000000\" stroke-width=\"0.4pt\"><path d=\"M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0\" style=\"fill:none\"></path><g transform=\"matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)\" fill=\"#000000\" stroke=\"#000000\"><foreignobject width=\"6.92\" height=\"8.92\" transform=\"matrix(1 0 0 -1 0 16.6)\" overflow=\"visible\"><span id=\"S5.T1.5.5.5.pic1.1.1.1.1.1\" class=\"ltx_text\">5</span></foreignobject></g></g></svg>\n</td>\n</tr>\n<tr id=\"S5.T1.12.14\" class=\"ltx_tr\">\n<td id=\"S5.T1.12.14.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\">Accuracies without defenses</td>\n<td id=\"S5.T1.12.14.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">MA</td>\n<td id=\"S5.T1.12.14.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">BA</td>\n<td id=\"S5.T1.12.14.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">MA</td>\n<td id=\"S5.T1.12.14.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">BA</td>\n<td id=\"S5.T1.12.14.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">MA</td>\n<td id=\"S5.T1.12.14.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">BA</td>\n<td id=\"S5.T1.12.14.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">MA</td>\n<td id=\"S5.T1.12.14.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">BA</td>\n<td id=\"S5.T1.12.14.10\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">MA</td>\n<td id=\"S5.T1.12.14.11\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">BA</td>\n<td id=\"S5.T1.12.14.12\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">MA</td>\n<td id=\"S5.T1.12.14.13\" class=\"ltx_td ltx_align_center ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"S5.T1.6.6\" class=\"ltx_tr\">\n<td id=\"S5.T1.6.6.2\" class=\"ltx_td ltx_align_left ltx_border_t\">1:</td>\n<td id=\"S5.T1.6.6.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Global model <math id=\"S5.T1.6.6.1.m1.1\" class=\"ltx_Math\" alttext=\"G^{r}\" display=\"inline\"><semantics id=\"S5.T1.6.6.1.m1.1a\"><msup id=\"S5.T1.6.6.1.m1.1.1\" xref=\"S5.T1.6.6.1.m1.1.1.cmml\"><mi id=\"S5.T1.6.6.1.m1.1.1.2\" xref=\"S5.T1.6.6.1.m1.1.1.2.cmml\">G</mi><mi id=\"S5.T1.6.6.1.m1.1.1.3\" xref=\"S5.T1.6.6.1.m1.1.1.3.cmml\">r</mi></msup><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.6.6.1.m1.1b\"><apply id=\"S5.T1.6.6.1.m1.1.1.cmml\" xref=\"S5.T1.6.6.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S5.T1.6.6.1.m1.1.1.1.cmml\" xref=\"S5.T1.6.6.1.m1.1.1\">superscript</csymbol><ci id=\"S5.T1.6.6.1.m1.1.1.2.cmml\" xref=\"S5.T1.6.6.1.m1.1.1.2\">ùê∫</ci><ci id=\"S5.T1.6.6.1.m1.1.1.3.cmml\" xref=\"S5.T1.6.6.1.m1.1.1.3\">ùëü</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.6.6.1.m1.1c\">G^{r}</annotation></semantics></math>\n</td>\n<td id=\"S5.T1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">62.99</td>\n<td id=\"S5.T1.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.90</td>\n<td id=\"S5.T1.6.6.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">62.99</td>\n<td id=\"S5.T1.6.6.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.90</td>\n<td id=\"S5.T1.6.6.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">62.99</td>\n<td id=\"S5.T1.6.6.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.90</td>\n<td id=\"S5.T1.6.6.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">62.99</td>\n<td id=\"S5.T1.6.6.10\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.90</td>\n<td id=\"S5.T1.6.6.11\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">62.99</td>\n<td id=\"S5.T1.6.6.12\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.93</td>\n<td id=\"S5.T1.6.6.13\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">36.51</td>\n<td id=\"S5.T1.6.6.14\" class=\"ltx_td ltx_align_center ltx_border_t\">5.18</td>\n</tr>\n<tr id=\"S5.T1.12.15\" class=\"ltx_tr\">\n<td id=\"S5.T1.12.15.1\" class=\"ltx_td ltx_align_left ltx_border_t\">2:</td>\n<td id=\"S5.T1.12.15.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Average of benign local models</td>\n<td id=\"S5.T1.12.15.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">57.58</td>\n<td id=\"S5.T1.12.15.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">4.56</td>\n<td id=\"S5.T1.12.15.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">57.58</td>\n<td id=\"S5.T1.12.15.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">4.56</td>\n<td id=\"S5.T1.12.15.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">57.58</td>\n<td id=\"S5.T1.12.15.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">4.56</td>\n<td id=\"S5.T1.12.15.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">57.58</td>\n<td id=\"S5.T1.12.15.10\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">4.56</td>\n<td id=\"S5.T1.12.15.11\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">47.15</td>\n<td id=\"S5.T1.12.15.12\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">6.82</td>\n<td id=\"S5.T1.12.15.13\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">33.15</td>\n<td id=\"S5.T1.12.15.14\" class=\"ltx_td ltx_align_center ltx_border_t\">10.42</td>\n</tr>\n<tr id=\"S5.T1.12.16\" class=\"ltx_tr\">\n<td id=\"S5.T1.12.16.1\" class=\"ltx_td ltx_align_left\">3:</td>\n<td id=\"S5.T1.12.16.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Average of poisoned local models</td>\n<td id=\"S5.T1.12.16.3\" class=\"ltx_td ltx_align_center ltx_border_r\">57.84</td>\n<td id=\"S5.T1.12.16.4\" class=\"ltx_td ltx_align_center ltx_border_r\">85.13</td>\n<td id=\"S5.T1.12.16.5\" class=\"ltx_td ltx_align_center ltx_border_r\">54.58</td>\n<td id=\"S5.T1.12.16.6\" class=\"ltx_td ltx_align_center ltx_border_r\">93.15</td>\n<td id=\"S5.T1.12.16.7\" class=\"ltx_td ltx_align_center ltx_border_r\">54.42</td>\n<td id=\"S5.T1.12.16.8\" class=\"ltx_td ltx_align_center ltx_border_r\">93.25</td>\n<td id=\"S5.T1.12.16.9\" class=\"ltx_td ltx_align_center ltx_border_r\">51.23</td>\n<td id=\"S5.T1.12.16.10\" class=\"ltx_td ltx_align_center ltx_border_r\">89.82</td>\n<td id=\"S5.T1.12.16.11\" class=\"ltx_td ltx_align_center ltx_border_r\">43.74</td>\n<td id=\"S5.T1.12.16.12\" class=\"ltx_td ltx_align_center ltx_border_r\">91.32</td>\n<td id=\"S5.T1.12.16.13\" class=\"ltx_td ltx_align_center ltx_border_r\">33.93</td>\n<td id=\"S5.T1.12.16.14\" class=\"ltx_td ltx_align_center\">82.00</td>\n</tr>\n<tr id=\"S5.T1.12.17\" class=\"ltx_tr\">\n<td id=\"S5.T1.12.17.1\" class=\"ltx_td ltx_align_left ltx_border_t\">4:</td>\n<td id=\"S5.T1.12.17.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"S5.T1.12.17.2.1\" class=\"ltx_text\">FedAVG</span> with benign local models</td>\n<td id=\"S5.T1.12.17.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.57</td>\n<td id=\"S5.T1.12.17.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.85</td>\n<td id=\"S5.T1.12.17.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.57</td>\n<td id=\"S5.T1.12.17.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.85</td>\n<td id=\"S5.T1.12.17.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.57</td>\n<td id=\"S5.T1.12.17.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.85</td>\n<td id=\"S5.T1.12.17.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.57</td>\n<td id=\"S5.T1.12.17.10\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.85</td>\n<td id=\"S5.T1.12.17.11\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">65.92</td>\n<td id=\"S5.T1.12.17.12\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.40</td>\n<td id=\"S5.T1.12.17.13\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">32.45</td>\n<td id=\"S5.T1.12.17.14\" class=\"ltx_td ltx_align_center ltx_border_t\">12.71</td>\n</tr>\n<tr id=\"S5.T1.12.18\" class=\"ltx_tr\">\n<td id=\"S5.T1.12.18.1\" class=\"ltx_td ltx_align_left\">5:</td>\n<td id=\"S5.T1.12.18.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"S5.T1.12.18.2.1\" class=\"ltx_text\">FedAVG</span> with poisoned local models</td>\n<td id=\"S5.T1.12.18.3\" class=\"ltx_td ltx_align_center ltx_border_r\">64.92</td>\n<td id=\"S5.T1.12.18.4\" class=\"ltx_td ltx_align_center ltx_border_r\">83.00</td>\n<td id=\"S5.T1.12.18.5\" class=\"ltx_td ltx_align_center ltx_border_r\">63.68</td>\n<td id=\"S5.T1.12.18.6\" class=\"ltx_td ltx_align_center ltx_border_r\">92.50</td>\n<td id=\"S5.T1.12.18.7\" class=\"ltx_td ltx_align_center ltx_border_r\">62.29</td>\n<td id=\"S5.T1.12.18.8\" class=\"ltx_td ltx_align_center ltx_border_r\">93.71</td>\n<td id=\"S5.T1.12.18.9\" class=\"ltx_td ltx_align_center ltx_border_r\">40.69</td>\n<td id=\"S5.T1.12.18.10\" class=\"ltx_td ltx_align_center ltx_border_r\">93.54</td>\n<td id=\"S5.T1.12.18.11\" class=\"ltx_td ltx_align_center ltx_border_r\">59.12</td>\n<td id=\"S5.T1.12.18.12\" class=\"ltx_td ltx_align_center ltx_border_r\">95.50</td>\n<td id=\"S5.T1.12.18.13\" class=\"ltx_td ltx_align_center ltx_border_r\">29.35</td>\n<td id=\"S5.T1.12.18.14\" class=\"ltx_td ltx_align_center\">88.96</td>\n</tr>\n<tr id=\"S5.T1.12.19\" class=\"ltx_tr\">\n<td id=\"S5.T1.12.19.1\" class=\"ltx_td ltx_align_left ltx_border_t\">6:</td>\n<td id=\"S5.T1.12.19.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"S5.T1.12.19.2.1\" class=\"ltx_text\">FedAVG</span> with all local models</td>\n<td id=\"S5.T1.12.19.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.81</td>\n<td id=\"S5.T1.12.19.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">42.94</td>\n<td id=\"S5.T1.12.19.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.85</td>\n<td id=\"S5.T1.12.19.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T1.12.19.6.1\" class=\"ltx_text ltx_font_bold\">61.96</span></td>\n<td id=\"S5.T1.12.19.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.27</td>\n<td id=\"S5.T1.12.19.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.54</td>\n<td id=\"S5.T1.12.19.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">49.18</td>\n<td id=\"S5.T1.12.19.10\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">83.74</td>\n<td id=\"S5.T1.12.19.11\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">64.02</td>\n<td id=\"S5.T1.12.19.12\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.66</td>\n<td id=\"S5.T1.12.19.13\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">38.72</td>\n<td id=\"S5.T1.12.19.14\" class=\"ltx_td ltx_align_center ltx_border_t\">77.37</td>\n</tr>\n<tr id=\"S5.T1.12.20\" class=\"ltx_tr\">\n<td id=\"S5.T1.12.20.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\" colspan=\"2\">Global model accuracies after applying defenses</td>\n<td id=\"S5.T1.12.20.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\">MA</td>\n<td id=\"S5.T1.12.20.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\">BA</td>\n<td id=\"S5.T1.12.20.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\">MA</td>\n<td id=\"S5.T1.12.20.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\">BA</td>\n<td id=\"S5.T1.12.20.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\">MA</td>\n<td id=\"S5.T1.12.20.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\">BA</td>\n<td id=\"S5.T1.12.20.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\">MA</td>\n<td id=\"S5.T1.12.20.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\">BA</td>\n<td id=\"S5.T1.12.20.10\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\">MA</td>\n<td id=\"S5.T1.12.20.11\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\">BA</td>\n<td id=\"S5.T1.12.20.12\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\">MA</td>\n<td id=\"S5.T1.12.20.13\" class=\"ltx_td ltx_align_center ltx_border_tt ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"S5.T1.12.21\" class=\"ltx_tr\">\n<td id=\"S5.T1.12.21.1\" class=\"ltx_td ltx_align_left ltx_border_t\">7:</td>\n<td id=\"S5.T1.12.21.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Na√Øve Clustering</td>\n<td id=\"S5.T1.12.21.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">65.06</td>\n<td id=\"S5.T1.12.21.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">74.62</td>\n<td id=\"S5.T1.12.21.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">64.75</td>\n<td id=\"S5.T1.12.21.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">86.86</td>\n<td id=\"S5.T1.12.21.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.73</td>\n<td id=\"S5.T1.12.21.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">88.36</td>\n<td id=\"S5.T1.12.21.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">47.34</td>\n<td id=\"S5.T1.12.21.10\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">85.58</td>\n<td id=\"S5.T1.12.21.11\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">61.12</td>\n<td id=\"S5.T1.12.21.12\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">87.58</td>\n<td id=\"S5.T1.12.21.13\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">20.85</td>\n<td id=\"S5.T1.12.21.14\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T1.12.21.14.1\" class=\"ltx_text ltx_font_bold\">85.32</span></td>\n</tr>\n<tr id=\"S5.T1.12.22\" class=\"ltx_tr\">\n<td id=\"S5.T1.12.22.1\" class=\"ltx_td ltx_align_left\">8:</td>\n<td id=\"S5.T1.12.22.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FoolsGold¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Fung et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>\n</td>\n<td id=\"S5.T1.12.22.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.57</td>\n<td id=\"S5.T1.12.22.4\" class=\"ltx_td ltx_align_center ltx_border_r\">1.85</td>\n<td id=\"S5.T1.12.22.5\" class=\"ltx_td ltx_align_center ltx_border_r\">63.57</td>\n<td id=\"S5.T1.12.22.6\" class=\"ltx_td ltx_align_center ltx_border_r\">1.85</td>\n<td id=\"S5.T1.12.22.7\" class=\"ltx_td ltx_align_center ltx_border_r\">63.27</td>\n<td id=\"S5.T1.12.22.8\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T1.12.22.8.1\" class=\"ltx_text ltx_font_bold\">63.54</span></td>\n<td id=\"S5.T1.12.22.9\" class=\"ltx_td ltx_align_center ltx_border_r\">63.57</td>\n<td id=\"S5.T1.12.22.10\" class=\"ltx_td ltx_align_center ltx_border_r\">1.85</td>\n<td id=\"S5.T1.12.22.11\" class=\"ltx_td ltx_align_center ltx_border_r\">56.80</td>\n<td id=\"S5.T1.12.22.12\" class=\"ltx_td ltx_align_center ltx_border_r\">47.0</td>\n<td id=\"S5.T1.12.22.13\" class=\"ltx_td ltx_align_center ltx_border_r\">37.00</td>\n<td id=\"S5.T1.12.22.14\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.12.22.14.1\" class=\"ltx_text ltx_font_bold\">76.03</span></td>\n</tr>\n<tr id=\"S5.T1.12.23\" class=\"ltx_tr\">\n<td id=\"S5.T1.12.23.1\" class=\"ltx_td ltx_align_left\">9:</td>\n<td id=\"S5.T1.12.23.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Krum¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"S5.T1.12.23.3\" class=\"ltx_td ltx_align_center ltx_border_r\">59.75</td>\n<td id=\"S5.T1.12.23.4\" class=\"ltx_td ltx_align_center ltx_border_r\">83.53</td>\n<td id=\"S5.T1.12.23.5\" class=\"ltx_td ltx_align_center ltx_border_r\">52.22</td>\n<td id=\"S5.T1.12.23.6\" class=\"ltx_td ltx_align_center ltx_border_r\">95.97</td>\n<td id=\"S5.T1.12.23.7\" class=\"ltx_td ltx_align_center ltx_border_r\">56.18</td>\n<td id=\"S5.T1.12.23.8\" class=\"ltx_td ltx_align_center ltx_border_r\">93.14</td>\n<td id=\"S5.T1.12.23.9\" class=\"ltx_td ltx_align_center ltx_border_r\">52.00</td>\n<td id=\"S5.T1.12.23.10\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T1.12.23.10.1\" class=\"ltx_text ltx_font_bold\">89.90</span></td>\n<td id=\"S5.T1.12.23.11\" class=\"ltx_td ltx_align_center ltx_border_r\">49.88</td>\n<td id=\"S5.T1.12.23.12\" class=\"ltx_td ltx_align_center ltx_border_r\">5.27</td>\n<td id=\"S5.T1.12.23.13\" class=\"ltx_td ltx_align_center ltx_border_r\">16.88</td>\n<td id=\"S5.T1.12.23.14\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.12.23.14.1\" class=\"ltx_text ltx_font_bold\">89.07</span></td>\n</tr>\n<tr id=\"S5.T1.12.24\" class=\"ltx_tr\">\n<td id=\"S5.T1.12.24.1\" class=\"ltx_td ltx_align_left\">10:</td>\n<td id=\"S5.T1.12.24.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"S5.T1.12.24.2.1\" class=\"ltx_text\">M-Krum</span>¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"S5.T1.12.24.3\" class=\"ltx_td ltx_align_center ltx_border_r\">64.18</td>\n<td id=\"S5.T1.12.24.4\" class=\"ltx_td ltx_align_center ltx_border_r\">83.05</td>\n<td id=\"S5.T1.12.24.5\" class=\"ltx_td ltx_align_center ltx_border_r\">63.90</td>\n<td id=\"S5.T1.12.24.6\" class=\"ltx_td ltx_align_center ltx_border_r\">92.72</td>\n<td id=\"S5.T1.12.24.7\" class=\"ltx_td ltx_align_center ltx_border_r\">62.01</td>\n<td id=\"S5.T1.12.24.8\" class=\"ltx_td ltx_align_center ltx_border_r\">93.83</td>\n<td id=\"S5.T1.12.24.9\" class=\"ltx_td ltx_align_center ltx_border_r\">41.86</td>\n<td id=\"S5.T1.12.24.10\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T1.12.24.10.1\" class=\"ltx_text ltx_font_bold\">95.80</span></td>\n<td id=\"S5.T1.12.24.11\" class=\"ltx_td ltx_align_center ltx_border_r\">62.39</td>\n<td id=\"S5.T1.12.24.12\" class=\"ltx_td ltx_align_center ltx_border_r\">13.11</td>\n<td id=\"S5.T1.12.24.13\" class=\"ltx_td ltx_align_center ltx_border_r\">18.07</td>\n<td id=\"S5.T1.12.24.14\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.12.24.14.1\" class=\"ltx_text ltx_font_bold\">89.55</span></td>\n</tr>\n<tr id=\"S5.T1.12.25\" class=\"ltx_tr\">\n<td id=\"S5.T1.12.25.1\" class=\"ltx_td ltx_align_left\">11:</td>\n<td id=\"S5.T1.12.25.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"S5.T1.12.25.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.80</td>\n<td id=\"S5.T1.12.25.4\" class=\"ltx_td ltx_align_center ltx_border_r\">42.81</td>\n<td id=\"S5.T1.12.25.5\" class=\"ltx_td ltx_align_center ltx_border_r\">63.85</td>\n<td id=\"S5.T1.12.25.6\" class=\"ltx_td ltx_align_center ltx_border_r\">61.86</td>\n<td id=\"S5.T1.12.25.7\" class=\"ltx_td ltx_align_center ltx_border_r\">63.26</td>\n<td id=\"S5.T1.12.25.8\" class=\"ltx_td ltx_align_center ltx_border_r\">63.52</td>\n<td id=\"S5.T1.12.25.9\" class=\"ltx_td ltx_align_center ltx_border_r\">49.19</td>\n<td id=\"S5.T1.12.25.10\" class=\"ltx_td ltx_align_center ltx_border_r\">83.74</td>\n<td id=\"S5.T1.12.25.11\" class=\"ltx_td ltx_align_center ltx_border_r\">63.92</td>\n<td id=\"S5.T1.12.25.12\" class=\"ltx_td ltx_align_center ltx_border_r\">62.28</td>\n<td id=\"S5.T1.12.25.13\" class=\"ltx_td ltx_align_center ltx_border_r\">37.76</td>\n<td id=\"S5.T1.12.25.14\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.12.25.14.1\" class=\"ltx_text ltx_font_bold\">75.60</span></td>\n</tr>\n<tr id=\"S5.T1.12.26\" class=\"ltx_tr\">\n<td id=\"S5.T1.12.26.1\" class=\"ltx_td ltx_align_left\">12:</td>\n<td id=\"S5.T1.12.26.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip&amp;Noise¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"S5.T1.12.26.3\" class=\"ltx_td ltx_align_center ltx_border_r\">50.78</td>\n<td id=\"S5.T1.12.26.4\" class=\"ltx_td ltx_align_center ltx_border_r\">60.66</td>\n<td id=\"S5.T1.12.26.5\" class=\"ltx_td ltx_align_center ltx_border_r\">52.10</td>\n<td id=\"S5.T1.12.26.6\" class=\"ltx_td ltx_align_center ltx_border_r\">77.21</td>\n<td id=\"S5.T1.12.26.7\" class=\"ltx_td ltx_align_center ltx_border_r\">59.32</td>\n<td id=\"S5.T1.12.26.8\" class=\"ltx_td ltx_align_center ltx_border_r\">75.67</td>\n<td id=\"S5.T1.12.26.9\" class=\"ltx_td ltx_align_center ltx_border_r\">41.47</td>\n<td id=\"S5.T1.12.26.10\" class=\"ltx_td ltx_align_center ltx_border_r\">90.37</td>\n<td id=\"S5.T1.12.26.11\" class=\"ltx_td ltx_align_center ltx_border_r\">56.28</td>\n<td id=\"S5.T1.12.26.12\" class=\"ltx_td ltx_align_center ltx_border_r\">71.99</td>\n<td id=\"S5.T1.12.26.13\" class=\"ltx_td ltx_align_center ltx_border_r\">23.70</td>\n<td id=\"S5.T1.12.26.14\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.12.26.14.1\" class=\"ltx_text ltx_font_bold\">64.32</span></td>\n</tr>\n<tr id=\"S5.T1.12.27\" class=\"ltx_tr\">\n<td id=\"S5.T1.12.27.1\" class=\"ltx_td ltx_align_left\">13:</td>\n<td id=\"S5.T1.12.27.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Flame¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Nguyen et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib69\" title=\"\" class=\"ltx_ref\">2022c</a>)</cite>\n</td>\n<td id=\"S5.T1.12.27.3\" class=\"ltx_td ltx_align_center ltx_border_r\">60.96</td>\n<td id=\"S5.T1.12.27.4\" class=\"ltx_td ltx_align_center ltx_border_r\">79.17</td>\n<td id=\"S5.T1.12.27.5\" class=\"ltx_td ltx_align_center ltx_border_r\">63.67</td>\n<td id=\"S5.T1.12.27.6\" class=\"ltx_td ltx_align_center ltx_border_r\">88.44</td>\n<td id=\"S5.T1.12.27.7\" class=\"ltx_td ltx_align_center ltx_border_r\">62.21</td>\n<td id=\"S5.T1.12.27.8\" class=\"ltx_td ltx_align_center ltx_border_r\">88.80</td>\n<td id=\"S5.T1.12.27.9\" class=\"ltx_td ltx_align_center ltx_border_r\">44.56</td>\n<td id=\"S5.T1.12.27.10\" class=\"ltx_td ltx_align_center ltx_border_r\">84.53</td>\n<td id=\"S5.T1.12.27.11\" class=\"ltx_td ltx_align_center ltx_border_r\">56.59</td>\n<td id=\"S5.T1.12.27.12\" class=\"ltx_td ltx_align_center ltx_border_r\">50.34</td>\n<td id=\"S5.T1.12.27.13\" class=\"ltx_td ltx_align_center ltx_border_r\">25.10</td>\n<td id=\"S5.T1.12.27.14\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.12.27.14.1\" class=\"ltx_text ltx_font_bold\">79.17</span></td>\n</tr>\n<tr id=\"S5.T1.12.28\" class=\"ltx_tr\">\n<td id=\"S5.T1.12.28.1\" class=\"ltx_td ltx_align_left\">14:</td>\n<td id=\"S5.T1.12.28.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Mean¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"S5.T1.12.28.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.51</td>\n<td id=\"S5.T1.12.28.4\" class=\"ltx_td ltx_align_center ltx_border_r\">44.13</td>\n<td id=\"S5.T1.12.28.5\" class=\"ltx_td ltx_align_center ltx_border_r\">63.54</td>\n<td id=\"S5.T1.12.28.6\" class=\"ltx_td ltx_align_center ltx_border_r\">63.98</td>\n<td id=\"S5.T1.12.28.7\" class=\"ltx_td ltx_align_center ltx_border_r\">62.86</td>\n<td id=\"S5.T1.12.28.8\" class=\"ltx_td ltx_align_center ltx_border_r\">65.35</td>\n<td id=\"S5.T1.12.28.9\" class=\"ltx_td ltx_align_center ltx_border_r\">51.07</td>\n<td id=\"S5.T1.12.28.10\" class=\"ltx_td ltx_align_center ltx_border_r\">85.75</td>\n<td id=\"S5.T1.12.28.11\" class=\"ltx_td ltx_align_center ltx_border_r\">63.15</td>\n<td id=\"S5.T1.12.28.12\" class=\"ltx_td ltx_align_center ltx_border_r\">67.01</td>\n<td id=\"S5.T1.12.28.13\" class=\"ltx_td ltx_align_center ltx_border_r\">39.98</td>\n<td id=\"S5.T1.12.28.14\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.12.28.14.1\" class=\"ltx_text ltx_font_bold\">76.36</span></td>\n</tr>\n<tr id=\"S5.T1.12.29\" class=\"ltx_tr\">\n<td id=\"S5.T1.12.29.1\" class=\"ltx_td ltx_align_left\">15:</td>\n<td id=\"S5.T1.12.29.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Median¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"S5.T1.12.29.3\" class=\"ltx_td ltx_align_center ltx_border_r\">51.22</td>\n<td id=\"S5.T1.12.29.4\" class=\"ltx_td ltx_align_center ltx_border_r\">44.60</td>\n<td id=\"S5.T1.12.29.5\" class=\"ltx_td ltx_align_center ltx_border_r\">51.18</td>\n<td id=\"S5.T1.12.29.6\" class=\"ltx_td ltx_align_center ltx_border_r\">57.73</td>\n<td id=\"S5.T1.12.29.7\" class=\"ltx_td ltx_align_center ltx_border_r\">49.61</td>\n<td id=\"S5.T1.12.29.8\" class=\"ltx_td ltx_align_center ltx_border_r\">60.30</td>\n<td id=\"S5.T1.12.29.9\" class=\"ltx_td ltx_align_center ltx_border_r\">39.76</td>\n<td id=\"S5.T1.12.29.10\" class=\"ltx_td ltx_align_center ltx_border_r\">74.76</td>\n<td id=\"S5.T1.12.29.11\" class=\"ltx_td ltx_align_center ltx_border_r\">51.75</td>\n<td id=\"S5.T1.12.29.12\" class=\"ltx_td ltx_align_center ltx_border_r\">68.20</td>\n<td id=\"S5.T1.12.29.13\" class=\"ltx_td ltx_align_center ltx_border_r\">17.04</td>\n<td id=\"S5.T1.12.29.14\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.12.29.14.1\" class=\"ltx_text ltx_font_bold\">52.75</span></td>\n</tr>\n<tr id=\"S5.T1.12.30\" class=\"ltx_tr\">\n<td id=\"S5.T1.12.30.1\" class=\"ltx_td ltx_align_left\">16:</td>\n<td id=\"S5.T1.12.30.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FLTrust¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Cao et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib14\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>\n</td>\n<td id=\"S5.T1.12.30.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.49</td>\n<td id=\"S5.T1.12.30.4\" class=\"ltx_td ltx_align_center ltx_border_r\">23.08</td>\n<td id=\"S5.T1.12.30.5\" class=\"ltx_td ltx_align_center ltx_border_r\">63.76</td>\n<td id=\"S5.T1.12.30.6\" class=\"ltx_td ltx_align_center ltx_border_r\">49.68</td>\n<td id=\"S5.T1.12.30.7\" class=\"ltx_td ltx_align_center ltx_border_r\">63.17</td>\n<td id=\"S5.T1.12.30.8\" class=\"ltx_td ltx_align_center ltx_border_r\">45.54</td>\n<td id=\"S5.T1.12.30.9\" class=\"ltx_td ltx_align_center ltx_border_r\">55.15</td>\n<td id=\"S5.T1.12.30.10\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T1.12.30.10.1\" class=\"ltx_text ltx_font_bold\">74.71</span></td>\n<td id=\"S5.T1.12.30.11\" class=\"ltx_td ltx_align_center ltx_border_r\">63.56</td>\n<td id=\"S5.T1.12.30.12\" class=\"ltx_td ltx_align_center ltx_border_r\">8.40</td>\n<td id=\"S5.T1.12.30.13\" class=\"ltx_td ltx_align_center ltx_border_r\">26.81</td>\n<td id=\"S5.T1.12.30.14\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.12.30.14.1\" class=\"ltx_text ltx_font_bold\">81.61</span></td>\n</tr>\n<tr id=\"S5.T1.12.31\" class=\"ltx_tr\">\n<td id=\"S5.T1.12.31.1\" class=\"ltx_td ltx_align_left\">17:</td>\n<td id=\"S5.T1.12.31.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T1.12.31.2.1\" class=\"ltx_text ltx_font_bold\">MESAS</span></td>\n<td id=\"S5.T1.12.31.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.57</td>\n<td id=\"S5.T1.12.31.4\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T1.12.31.4.1\" class=\"ltx_text ltx_font_bold\">1.85</span></td>\n<td id=\"S5.T1.12.31.5\" class=\"ltx_td ltx_align_center ltx_border_r\">63.36</td>\n<td id=\"S5.T1.12.31.6\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T1.12.31.6.1\" class=\"ltx_text ltx_font_bold\">1.95</span></td>\n<td id=\"S5.T1.12.31.7\" class=\"ltx_td ltx_align_center ltx_border_r\">63.36</td>\n<td id=\"S5.T1.12.31.8\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T1.12.31.8.1\" class=\"ltx_text ltx_font_bold\">1.95</span></td>\n<td id=\"S5.T1.12.31.9\" class=\"ltx_td ltx_align_center ltx_border_r\">63.57</td>\n<td id=\"S5.T1.12.31.10\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T1.12.31.10.1\" class=\"ltx_text ltx_font_bold\">1.85</span></td>\n<td id=\"S5.T1.12.31.11\" class=\"ltx_td ltx_align_center ltx_border_r\">65.92</td>\n<td id=\"S5.T1.12.31.12\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T1.12.31.12.1\" class=\"ltx_text ltx_font_bold\">1.40</span></td>\n<td id=\"S5.T1.12.31.13\" class=\"ltx_td ltx_align_center ltx_border_r\">37.52</td>\n<td id=\"S5.T1.12.31.14\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.12.31.14.1\" class=\"ltx_text ltx_font_bold\">2.37</span></td>\n</tr>\n<tr id=\"S5.T1.8.8\" class=\"ltx_tr\">\n<td id=\"S5.T1.7.7.1\" class=\"ltx_td ltx_align_left ltx_border_tt ltx_border_tt\" colspan=\"5\">\n<svg id=\"S5.T1.7.7.1.pic1\" class=\"ltx_picture\" height=\"13.74\" overflow=\"visible\" version=\"1.1\" width=\"13.74\"><g transform=\"translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)\" fill=\"#000000\" stroke=\"#000000\" stroke-width=\"0.4pt\"><path d=\"M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0\" style=\"fill:none\"></path><g transform=\"matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)\" fill=\"#000000\" stroke=\"#000000\"><foreignobject width=\"6.92\" height=\"8.92\" transform=\"matrix(1 0 0 -1 0 16.6)\" overflow=\"visible\"><span id=\"S5.T1.7.7.1.pic1.1.1.1.1.1\" class=\"ltx_text\">1</span></foreignobject></g></g></svg> Default + PDR 0.3</td>\n<td id=\"S5.T1.8.8.2\" class=\"ltx_td ltx_align_left ltx_border_tt ltx_border_tt\" colspan=\"9\">\n<svg id=\"S5.T1.8.8.2.pic1\" class=\"ltx_picture\" height=\"13.74\" overflow=\"visible\" version=\"1.1\" width=\"13.74\"><g transform=\"translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)\" fill=\"#000000\" stroke=\"#000000\" stroke-width=\"0.4pt\"><path d=\"M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0\" style=\"fill:none\"></path><g transform=\"matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)\" fill=\"#000000\" stroke=\"#000000\"><foreignobject width=\"6.92\" height=\"8.92\" transform=\"matrix(1 0 0 -1 0 16.6)\" overflow=\"visible\"><span id=\"S5.T1.8.8.2.pic1.1.1.1.1.1\" class=\"ltx_text\">2</span></foreignobject></g></g></svg> Default + PDR 0.3 + Last Layer Fixation to benign models</td>\n</tr>\n<tr id=\"S5.T1.11.11\" class=\"ltx_tr\">\n<td id=\"S5.T1.9.9.1\" class=\"ltx_td ltx_align_left\" colspan=\"5\">\n<svg id=\"S5.T1.9.9.1.pic1\" class=\"ltx_picture\" height=\"13.74\" overflow=\"visible\" version=\"1.1\" width=\"13.74\"><g transform=\"translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)\" fill=\"#000000\" stroke=\"#000000\" stroke-width=\"0.4pt\"><path d=\"M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0\" style=\"fill:none\"></path><g transform=\"matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)\" fill=\"#000000\" stroke=\"#000000\"><foreignobject width=\"6.92\" height=\"8.92\" transform=\"matrix(1 0 0 -1 0 16.6)\" overflow=\"visible\"><span id=\"S5.T1.9.9.1.pic1.1.1.1.1.1\" class=\"ltx_text\">3</span></foreignobject></g></g></svg> Default + Adapt to EUCL of benign models</td>\n<td id=\"S5.T1.11.11.3\" class=\"ltx_td ltx_align_left\" colspan=\"9\">\n<svg id=\"S5.T1.10.10.2.pic1\" class=\"ltx_picture\" height=\"13.74\" overflow=\"visible\" version=\"1.1\" width=\"13.74\"><g transform=\"translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)\" fill=\"#000000\" stroke=\"#000000\" stroke-width=\"0.4pt\"><path d=\"M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0\" style=\"fill:none\"></path><g transform=\"matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)\" fill=\"#000000\" stroke=\"#000000\"><foreignobject width=\"6.92\" height=\"8.92\" transform=\"matrix(1 0 0 -1 0 16.6)\" overflow=\"visible\"><span id=\"S5.T1.10.10.2.pic1.1.1.1.1.1\" class=\"ltx_text\">4</span></foreignobject></g></g></svg> Default + PDR 0.3 + <span id=\"S5.T1.11.11.3.1\" class=\"ltx_text\">1-class</span> <span id=\"S5.T1.11.11.3.2\" class=\"ltx_text\">intra-client</span> <span id=\"S5.T1.11.11.3.3\" class=\"ltx_text\">non-IID</span> with <math id=\"S5.T1.11.11.3.m1.1\" class=\"ltx_Math\" alttext=\"q=0.5\" display=\"inline\"><semantics id=\"S5.T1.11.11.3.m1.1a\"><mrow id=\"S5.T1.11.11.3.m1.1.1\" xref=\"S5.T1.11.11.3.m1.1.1.cmml\"><mi id=\"S5.T1.11.11.3.m1.1.1.2\" xref=\"S5.T1.11.11.3.m1.1.1.2.cmml\">q</mi><mo id=\"S5.T1.11.11.3.m1.1.1.1\" xref=\"S5.T1.11.11.3.m1.1.1.1.cmml\">=</mo><mn id=\"S5.T1.11.11.3.m1.1.1.3\" xref=\"S5.T1.11.11.3.m1.1.1.3.cmml\">0.5</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S5.T1.11.11.3.m1.1b\"><apply id=\"S5.T1.11.11.3.m1.1.1.cmml\" xref=\"S5.T1.11.11.3.m1.1.1\"><eq id=\"S5.T1.11.11.3.m1.1.1.1.cmml\" xref=\"S5.T1.11.11.3.m1.1.1.1\"></eq><ci id=\"S5.T1.11.11.3.m1.1.1.2.cmml\" xref=\"S5.T1.11.11.3.m1.1.1.2\">ùëû</ci><cn type=\"float\" id=\"S5.T1.11.11.3.m1.1.1.3.cmml\" xref=\"S5.T1.11.11.3.m1.1.1.3\">0.5</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T1.11.11.3.m1.1c\">q=0.5</annotation></semantics></math> + Scaling</td>\n</tr>\n<tr id=\"S5.T1.12.12\" class=\"ltx_tr\">\n<td id=\"S5.T1.12.12.1\" class=\"ltx_td ltx_align_left\" colspan=\"14\">\n<svg id=\"S5.T1.12.12.1.pic1\" class=\"ltx_picture\" height=\"13.74\" overflow=\"visible\" version=\"1.1\" width=\"13.74\"><g transform=\"translate(0,13.74) matrix(1 0 0 -1 0 0) translate(6.87,0) translate(0,6.87)\" fill=\"#000000\" stroke=\"#000000\" stroke-width=\"0.4pt\"><path d=\"M 6.59 0 C 6.59 3.64 3.64 6.59 0 6.59 C -3.64 6.59 -6.59 3.64 -6.59 0 C -6.59 -3.64 -3.64 -6.59 0 -6.59 C 3.64 -6.59 6.59 -3.64 6.59 0 Z M 0 0\" style=\"fill:none\"></path><g transform=\"matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)\" fill=\"#000000\" stroke=\"#000000\"><foreignobject width=\"6.92\" height=\"8.92\" transform=\"matrix(1 0 0 -1 0 16.6)\" overflow=\"visible\"><span id=\"S5.T1.12.12.1.pic1.1.1.1.1.1\" class=\"ltx_text\">5</span></foreignobject></g></g></svg> Default + <span id=\"S5.T1.12.12.1.1\" class=\"ltx_text\">inter-client</span> <span id=\"S5.T1.12.12.1.2\" class=\"ltx_text\">non-IID</span> based on our <span id=\"S5.T1.12.12.1.3\" class=\"ltx_text\">Random-Non-IID</span> strategy</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In this section, we conduct a rigorous analysis of ",
                "MESAS",
                " and explore impact of various parameters and application-specific factors like datasets, model architectures, underlying data distributions, poisoning methods and attack adaptive strategies, as well as performance overheads."
            ]
        ]
    },
    "S5.T2": {
        "caption": "Table 2. BA for targeted and ACC for untargeted poisoning attacks without adaptive adversary in percent.",
        "table": "<table id=\"S5.T2.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T2.1.2\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\" rowspan=\"3\"><span id=\"S5.T2.1.2.1.1\" class=\"ltx_text\">Aggregation / Defenses</span></td>\n<td id=\"S5.T2.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"6\">BA</td>\n<td id=\"S5.T2.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"3\">ACC</td>\n</tr>\n<tr id=\"S5.T2.1.3\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Pixel Trigger</td>\n<td id=\"S5.T2.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clean-Label</td>\n<td id=\"S5.T2.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\">Semantic</td>\n<td id=\"S5.T2.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_r\">Edge Case</td>\n<td id=\"S5.T2.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_r\">Label Flip</td>\n<td id=\"S5.T2.1.3.6\" class=\"ltx_td ltx_align_center ltx_border_r\">Pervasive</td>\n<td id=\"S5.T2.1.3.7\" class=\"ltx_td ltx_align_center ltx_border_r\">Random Flip</td>\n<td id=\"S5.T2.1.3.8\" class=\"ltx_td ltx_align_center ltx_border_r\">Sign Flip</td>\n<td id=\"S5.T2.1.3.9\" class=\"ltx_td ltx_align_center\">Noising</td>\n</tr>\n<tr id=\"S5.T2.1.4\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_citep\">(Gu et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib36\" title=\"\" class=\"ltx_ref\">2017</a>)</cite></td>\n<td id=\"S5.T2.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_citep\">(Turner et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib101\" title=\"\" class=\"ltx_ref\">2019</a>)</cite></td>\n<td id=\"S5.T2.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_citep\">(Bagdasaryan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib6\" title=\"\" class=\"ltx_ref\">2020</a>)</cite></td>\n<td id=\"S5.T2.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib105\" title=\"\" class=\"ltx_ref\">2020</a>)</cite></td>\n<td id=\"S5.T2.1.4.5\" class=\"ltx_td ltx_align_center ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_citep\">(Biggio et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib9\" title=\"\" class=\"ltx_ref\">2012</a>; Cao et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib13\" title=\"\" class=\"ltx_ref\">2019</a>)</cite></td>\n<td id=\"S5.T2.1.4.6\" class=\"ltx_td ltx_align_center ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_citep\">(Chen et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib18\" title=\"\" class=\"ltx_ref\">2017</a>)</cite></td>\n<td id=\"S5.T2.1.4.7\" class=\"ltx_td ltx_align_center ltx_border_r\"><a href=\"#A3.SS7\" title=\"C.7. Random Label Flipping ‚Ä£ Appendix C Poisoning Methods ‚Ä£ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations\" class=\"ltx_ref\">Sect.¬†<span class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">C.7</span></span></a></td>\n<td id=\"S5.T2.1.4.8\" class=\"ltx_td ltx_align_center ltx_border_r\"><a href=\"#A3.SS8\" title=\"C.8. Sign Flipping ‚Ä£ Appendix C Poisoning Methods ‚Ä£ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations\" class=\"ltx_ref\">Sect.¬†<span class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">C.8</span></span></a></td>\n<td id=\"S5.T2.1.4.9\" class=\"ltx_td ltx_align_center\"><a href=\"#A3.SS9\" title=\"C.9. Model Noising ‚Ä£ Appendix C Poisoning Methods ‚Ä£ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations\" class=\"ltx_ref\">Sect.¬†<span class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">C.9</span></span></a></td>\n</tr>\n<tr id=\"S5.T2.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">1:</td>\n<td id=\"S5.T2.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Global model <math id=\"S5.T2.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"G^{r}\" display=\"inline\"><semantics id=\"S5.T2.1.1.1.m1.1a\"><msup id=\"S5.T2.1.1.1.m1.1.1\" xref=\"S5.T2.1.1.1.m1.1.1.cmml\"><mi id=\"S5.T2.1.1.1.m1.1.1.2\" xref=\"S5.T2.1.1.1.m1.1.1.2.cmml\">G</mi><mi id=\"S5.T2.1.1.1.m1.1.1.3\" xref=\"S5.T2.1.1.1.m1.1.1.3.cmml\">r</mi></msup><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.1.1.1.m1.1b\"><apply id=\"S5.T2.1.1.1.m1.1.1.cmml\" xref=\"S5.T2.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S5.T2.1.1.1.m1.1.1.1.cmml\" xref=\"S5.T2.1.1.1.m1.1.1\">superscript</csymbol><ci id=\"S5.T2.1.1.1.m1.1.1.2.cmml\" xref=\"S5.T2.1.1.1.m1.1.1.2\">ùê∫</ci><ci id=\"S5.T2.1.1.1.m1.1.1.3.cmml\" xref=\"S5.T2.1.1.1.m1.1.1.3\">ùëü</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.1.1.1.m1.1c\">G^{r}</annotation></semantics></math>\n</td>\n<td id=\"S5.T2.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.90</td>\n<td id=\"S5.T2.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.90</td>\n<td id=\"S5.T2.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.00</td>\n<td id=\"S5.T2.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.53</td>\n<td id=\"S5.T2.1.1.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.10</td>\n<td id=\"S5.T2.1.1.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.02</td>\n<td id=\"S5.T2.1.1.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">-</td>\n<td id=\"S5.T2.1.1.10\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">-</td>\n<td id=\"S5.T2.1.1.11\" class=\"ltx_td ltx_align_center ltx_border_t\">-</td>\n</tr>\n<tr id=\"S5.T2.1.5\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\">2:</td>\n<td id=\"S5.T2.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Average of benign local models</td>\n<td id=\"S5.T2.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">4.56</td>\n<td id=\"S5.T2.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">4.57</td>\n<td id=\"S5.T2.1.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.00</td>\n<td id=\"S5.T2.1.5.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">2.55</td>\n<td id=\"S5.T2.1.5.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.24</td>\n<td id=\"S5.T2.1.5.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.95</td>\n<td id=\"S5.T2.1.5.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">-</td>\n<td id=\"S5.T2.1.5.10\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">-</td>\n<td id=\"S5.T2.1.5.11\" class=\"ltx_td ltx_align_center ltx_border_t\">-</td>\n</tr>\n<tr id=\"S5.T2.1.6\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.6.1\" class=\"ltx_td ltx_align_left\">3:</td>\n<td id=\"S5.T2.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Average of poisoned local models</td>\n<td id=\"S5.T2.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">85.13</td>\n<td id=\"S5.T2.1.6.4\" class=\"ltx_td ltx_align_center ltx_border_r\">75.49</td>\n<td id=\"S5.T2.1.6.5\" class=\"ltx_td ltx_align_center ltx_border_r\">80.0</td>\n<td id=\"S5.T2.1.6.6\" class=\"ltx_td ltx_align_center ltx_border_r\">19.28</td>\n<td id=\"S5.T2.1.6.7\" class=\"ltx_td ltx_align_center ltx_border_r\">74.15</td>\n<td id=\"S5.T2.1.6.8\" class=\"ltx_td ltx_align_center ltx_border_r\">97.28</td>\n<td id=\"S5.T2.1.6.9\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T2.1.6.10\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T2.1.6.11\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S5.T2.1.7\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.7.1\" class=\"ltx_td ltx_align_left ltx_border_t\">4:</td>\n<td id=\"S5.T2.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"S5.T2.1.7.2.1\" class=\"ltx_text\">FedAVG</span> with benign local models</td>\n<td id=\"S5.T2.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.85</td>\n<td id=\"S5.T2.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.85</td>\n<td id=\"S5.T2.1.7.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.00</td>\n<td id=\"S5.T2.1.7.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.85</td>\n<td id=\"S5.T2.1.7.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.20</td>\n<td id=\"S5.T2.1.7.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.07</td>\n<td id=\"S5.T2.1.7.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">-</td>\n<td id=\"S5.T2.1.7.10\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">-</td>\n<td id=\"S5.T2.1.7.11\" class=\"ltx_td ltx_align_center ltx_border_t\">-</td>\n</tr>\n<tr id=\"S5.T2.1.8\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.8.1\" class=\"ltx_td ltx_align_left\">5:</td>\n<td id=\"S5.T2.1.8.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"S5.T2.1.8.2.1\" class=\"ltx_text\">FedAVG</span> with poisoned local models</td>\n<td id=\"S5.T2.1.8.3\" class=\"ltx_td ltx_align_center ltx_border_r\">83.00</td>\n<td id=\"S5.T2.1.8.4\" class=\"ltx_td ltx_align_center ltx_border_r\">81.75</td>\n<td id=\"S5.T2.1.8.5\" class=\"ltx_td ltx_align_center ltx_border_r\">100.0</td>\n<td id=\"S5.T2.1.8.6\" class=\"ltx_td ltx_align_center ltx_border_r\">20.40</td>\n<td id=\"S5.T2.1.8.7\" class=\"ltx_td ltx_align_center ltx_border_r\">71.20</td>\n<td id=\"S5.T2.1.8.8\" class=\"ltx_td ltx_align_center ltx_border_r\">99.84</td>\n<td id=\"S5.T2.1.8.9\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T2.1.8.10\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T2.1.8.11\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S5.T2.1.9\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.9.1\" class=\"ltx_td ltx_align_left ltx_border_t\">6:</td>\n<td id=\"S5.T2.1.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"S5.T2.1.9.2.1\" class=\"ltx_text\">FedAVG</span> with all local models</td>\n<td id=\"S5.T2.1.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">42.94</td>\n<td id=\"S5.T2.1.9.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">38.92</td>\n<td id=\"S5.T2.1.9.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">60.0</td>\n<td id=\"S5.T2.1.9.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">6.63</td>\n<td id=\"S5.T2.1.9.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">49.20</td>\n<td id=\"S5.T2.1.9.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">3.58</td>\n<td id=\"S5.T2.1.9.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">-</td>\n<td id=\"S5.T2.1.9.10\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">-</td>\n<td id=\"S5.T2.1.9.11\" class=\"ltx_td ltx_align_center ltx_border_t\">-</td>\n</tr>\n<tr id=\"S5.T2.1.10\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.10.1\" class=\"ltx_td ltx_align_left ltx_border_t\">7:</td>\n<td id=\"S5.T2.1.10.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Na√Øve Clustering</td>\n<td id=\"S5.T2.1.10.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">74.62</td>\n<td id=\"S5.T2.1.10.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.10.4.1\" class=\"ltx_text ltx_font_bold\">1.85</span></td>\n<td id=\"S5.T2.1.10.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">60.0</td>\n<td id=\"S5.T2.1.10.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">16.35</td>\n<td id=\"S5.T2.1.10.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">65.60</td>\n<td id=\"S5.T2.1.10.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">67.67</td>\n<td id=\"S5.T2.1.10.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">10.00</td>\n<td id=\"S5.T2.1.10.10\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.1.10.10.1\" class=\"ltx_text ltx_font_bold\">100.00</span></td>\n<td id=\"S5.T2.1.10.11\" class=\"ltx_td ltx_align_center ltx_border_t\">80.00</td>\n</tr>\n<tr id=\"S5.T2.1.11\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.11.1\" class=\"ltx_td ltx_align_left\">8:</td>\n<td id=\"S5.T2.1.11.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FoolsGold¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Fung et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>\n</td>\n<td id=\"S5.T2.1.11.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.11.3.1\" class=\"ltx_text ltx_font_bold\">1.85</span></td>\n<td id=\"S5.T2.1.11.4\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.11.4.1\" class=\"ltx_text ltx_font_bold\">1.85</span></td>\n<td id=\"S5.T2.1.11.5\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.11.5.1\" class=\"ltx_text ltx_font_bold\">0.00</span></td>\n<td id=\"S5.T2.1.11.6\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.11.6.1\" class=\"ltx_text ltx_font_bold\">2.55</span></td>\n<td id=\"S5.T2.1.11.7\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.11.7.1\" class=\"ltx_text ltx_font_bold\">0.20</span></td>\n<td id=\"S5.T2.1.11.8\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.11.8.1\" class=\"ltx_text ltx_font_bold\">0.10</span></td>\n<td id=\"S5.T2.1.11.9\" class=\"ltx_td ltx_align_center ltx_border_r\">55.00</td>\n<td id=\"S5.T2.1.11.10\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.11.10.1\" class=\"ltx_text ltx_font_bold\">100.00</span></td>\n<td id=\"S5.T2.1.11.11\" class=\"ltx_td ltx_align_center\">0.00</td>\n</tr>\n<tr id=\"S5.T2.1.12\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.12.1\" class=\"ltx_td ltx_align_left\">9:</td>\n<td id=\"S5.T2.1.12.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Krum¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"S5.T2.1.12.3\" class=\"ltx_td ltx_align_center ltx_border_r\">83.53</td>\n<td id=\"S5.T2.1.12.4\" class=\"ltx_td ltx_align_center ltx_border_r\">75.65</td>\n<td id=\"S5.T2.1.12.5\" class=\"ltx_td ltx_align_center ltx_border_r\">80.00</td>\n<td id=\"S5.T2.1.12.6\" class=\"ltx_td ltx_align_center ltx_border_r\">20.91</td>\n<td id=\"S5.T2.1.12.7\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.12.7.1\" class=\"ltx_text ltx_font_bold\">1.30</span></td>\n<td id=\"S5.T2.1.12.8\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.12.8.1\" class=\"ltx_text ltx_font_bold\">0.42</span></td>\n<td id=\"S5.T2.1.12.9\" class=\"ltx_td ltx_align_center ltx_border_r\">50.00</td>\n<td id=\"S5.T2.1.12.10\" class=\"ltx_td ltx_align_center ltx_border_r\">50.00</td>\n<td id=\"S5.T2.1.12.11\" class=\"ltx_td ltx_align_center\">50.00</td>\n</tr>\n<tr id=\"S5.T2.1.13\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.13.1\" class=\"ltx_td ltx_align_left\">10:</td>\n<td id=\"S5.T2.1.13.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"S5.T2.1.13.2.1\" class=\"ltx_text\">M-Krum</span>¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"S5.T2.1.13.3\" class=\"ltx_td ltx_align_center ltx_border_r\">83.05</td>\n<td id=\"S5.T2.1.13.4\" class=\"ltx_td ltx_align_center ltx_border_r\">82.38</td>\n<td id=\"S5.T2.1.13.5\" class=\"ltx_td ltx_align_center ltx_border_r\">100.0</td>\n<td id=\"S5.T2.1.13.6\" class=\"ltx_td ltx_align_center ltx_border_r\">18.87</td>\n<td id=\"S5.T2.1.13.7\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.13.7.1\" class=\"ltx_text ltx_font_bold\">0.40</span></td>\n<td id=\"S5.T2.1.13.8\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.13.8.1\" class=\"ltx_text ltx_font_bold\">3.50</span></td>\n<td id=\"S5.T2.1.13.9\" class=\"ltx_td ltx_align_center ltx_border_r\">75.00</td>\n<td id=\"S5.T2.1.13.10\" class=\"ltx_td ltx_align_center ltx_border_r\">75.00</td>\n<td id=\"S5.T2.1.13.11\" class=\"ltx_td ltx_align_center\">75.00</td>\n</tr>\n<tr id=\"S5.T2.1.14\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.14.1\" class=\"ltx_td ltx_align_left\">11:</td>\n<td id=\"S5.T2.1.14.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"S5.T2.1.14.3\" class=\"ltx_td ltx_align_center ltx_border_r\">42.81</td>\n<td id=\"S5.T2.1.14.4\" class=\"ltx_td ltx_align_center ltx_border_r\">38.91</td>\n<td id=\"S5.T2.1.14.5\" class=\"ltx_td ltx_align_center ltx_border_r\">60.0</td>\n<td id=\"S5.T2.1.14.6\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.14.6.1\" class=\"ltx_text ltx_font_bold\">6.63</span></td>\n<td id=\"S5.T2.1.14.7\" class=\"ltx_td ltx_align_center ltx_border_r\">48.40</td>\n<td id=\"S5.T2.1.14.8\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.14.8.1\" class=\"ltx_text ltx_font_bold\">3.17</span></td>\n<td id=\"S5.T2.1.14.9\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T2.1.14.10\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T2.1.14.11\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S5.T2.1.15\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.15.1\" class=\"ltx_td ltx_align_left\">12:</td>\n<td id=\"S5.T2.1.15.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip&amp;Noise¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"S5.T2.1.15.3\" class=\"ltx_td ltx_align_center ltx_border_r\">60.66</td>\n<td id=\"S5.T2.1.15.4\" class=\"ltx_td ltx_align_center ltx_border_r\">40.73</td>\n<td id=\"S5.T2.1.15.5\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.15.5.1\" class=\"ltx_text ltx_font_bold\">0.00</span></td>\n<td id=\"S5.T2.1.15.6\" class=\"ltx_td ltx_align_center ltx_border_r\">12.75</td>\n<td id=\"S5.T2.1.15.7\" class=\"ltx_td ltx_align_center ltx_border_r\">30.80</td>\n<td id=\"S5.T2.1.15.8\" class=\"ltx_td ltx_align_center ltx_border_r\">10.08</td>\n<td id=\"S5.T2.1.15.9\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T2.1.15.10\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T2.1.15.11\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S5.T2.1.16\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.16.1\" class=\"ltx_td ltx_align_left\">13:</td>\n<td id=\"S5.T2.1.16.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Flame¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Nguyen et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib69\" title=\"\" class=\"ltx_ref\">2022c</a>)</cite>\n</td>\n<td id=\"S5.T2.1.16.3\" class=\"ltx_td ltx_align_center ltx_border_r\">79.17</td>\n<td id=\"S5.T2.1.16.4\" class=\"ltx_td ltx_align_center ltx_border_r\">77.12</td>\n<td id=\"S5.T2.1.16.5\" class=\"ltx_td ltx_align_center ltx_border_r\">60.0</td>\n<td id=\"S5.T2.1.16.6\" class=\"ltx_td ltx_align_center ltx_border_r\">18.87</td>\n<td id=\"S5.T2.1.16.7\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.16.7.1\" class=\"ltx_text ltx_font_bold\">2.40</span></td>\n<td id=\"S5.T2.1.16.8\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.16.8.1\" class=\"ltx_text ltx_font_bold\">5.52</span></td>\n<td id=\"S5.T2.1.16.9\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.16.9.1\" class=\"ltx_text ltx_font_bold\">100.00</span></td>\n<td id=\"S5.T2.1.16.10\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.16.10.1\" class=\"ltx_text ltx_font_bold\">100.00</span></td>\n<td id=\"S5.T2.1.16.11\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.1.16.11.1\" class=\"ltx_text ltx_font_bold\">100.00</span></td>\n</tr>\n<tr id=\"S5.T2.1.17\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.17.1\" class=\"ltx_td ltx_align_left\">14:</td>\n<td id=\"S5.T2.1.17.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Mean¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"S5.T2.1.17.3\" class=\"ltx_td ltx_align_center ltx_border_r\">44.13</td>\n<td id=\"S5.T2.1.17.4\" class=\"ltx_td ltx_align_center ltx_border_r\">41.10</td>\n<td id=\"S5.T2.1.17.5\" class=\"ltx_td ltx_align_center ltx_border_r\">60.0</td>\n<td id=\"S5.T2.1.17.6\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.17.6.1\" class=\"ltx_text ltx_font_bold\">7.14</span></td>\n<td id=\"S5.T2.1.17.7\" class=\"ltx_td ltx_align_center ltx_border_r\">48.40</td>\n<td id=\"S5.T2.1.17.8\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.17.8.1\" class=\"ltx_text ltx_font_bold\">2.53</span></td>\n<td id=\"S5.T2.1.17.9\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T2.1.17.10\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T2.1.17.11\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S5.T2.1.18\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.18.1\" class=\"ltx_td ltx_align_left\">15:</td>\n<td id=\"S5.T2.1.18.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Median¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"S5.T2.1.18.3\" class=\"ltx_td ltx_align_center ltx_border_r\">44.60</td>\n<td id=\"S5.T2.1.18.4\" class=\"ltx_td ltx_align_center ltx_border_r\">25.66</td>\n<td id=\"S5.T2.1.18.5\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.18.5.1\" class=\"ltx_text ltx_font_bold\">0.00</span></td>\n<td id=\"S5.T2.1.18.6\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.18.6.1\" class=\"ltx_text ltx_font_bold\">2.55</span></td>\n<td id=\"S5.T2.1.18.7\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.18.7.1\" class=\"ltx_text ltx_font_bold\">5.60</span></td>\n<td id=\"S5.T2.1.18.8\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.18.8.1\" class=\"ltx_text ltx_font_bold\">0.10</span></td>\n<td id=\"S5.T2.1.18.9\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T2.1.18.10\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>\n<td id=\"S5.T2.1.18.11\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S5.T2.1.19\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.19.1\" class=\"ltx_td ltx_align_left\">16:</td>\n<td id=\"S5.T2.1.19.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FLTrust¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Cao et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib14\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>\n</td>\n<td id=\"S5.T2.1.19.3\" class=\"ltx_td ltx_align_center ltx_border_r\">23.08</td>\n<td id=\"S5.T2.1.19.4\" class=\"ltx_td ltx_align_center ltx_border_r\">37.83</td>\n<td id=\"S5.T2.1.19.5\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.19.5.1\" class=\"ltx_text ltx_font_bold\">0.00</span></td>\n<td id=\"S5.T2.1.19.6\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.19.6.1\" class=\"ltx_text ltx_font_bold\">5.10</span></td>\n<td id=\"S5.T2.1.19.7\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.19.7.1\" class=\"ltx_text ltx_font_bold\">0.2</span></td>\n<td id=\"S5.T2.1.19.8\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T2.1.19.8.1\" class=\"ltx_text ltx_font_bold\">0.11</span></td>\n<td id=\"S5.T2.1.19.9\" class=\"ltx_td ltx_align_center ltx_border_r\">60.00</td>\n<td id=\"S5.T2.1.19.10\" class=\"ltx_td ltx_align_center ltx_border_r\">20.00</td>\n<td id=\"S5.T2.1.19.11\" class=\"ltx_td ltx_align_center\">35.00</td>\n</tr>\n<tr id=\"S5.T2.1.20\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.20.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">17:</td>\n<td id=\"S5.T2.1.20.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S5.T2.1.20.2.1\" class=\"ltx_text ltx_font_bold\">MESAS</span></td>\n<td id=\"S5.T2.1.20.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S5.T2.1.20.3.1\" class=\"ltx_text ltx_font_bold\">1.85</span></td>\n<td id=\"S5.T2.1.20.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S5.T2.1.20.4.1\" class=\"ltx_text ltx_font_bold\">3.71</span></td>\n<td id=\"S5.T2.1.20.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S5.T2.1.20.5.1\" class=\"ltx_text ltx_font_bold\">0.00</span></td>\n<td id=\"S5.T2.1.20.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S5.T2.1.20.6.1\" class=\"ltx_text ltx_font_bold\">2.55</span></td>\n<td id=\"S5.T2.1.20.7\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S5.T2.1.20.7.1\" class=\"ltx_text ltx_font_bold\">0.20</span></td>\n<td id=\"S5.T2.1.20.8\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S5.T2.1.20.8.1\" class=\"ltx_text ltx_font_bold\">0.05</span></td>\n<td id=\"S5.T2.1.20.9\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S5.T2.1.20.9.1\" class=\"ltx_text ltx_font_bold\">95.00</span></td>\n<td id=\"S5.T2.1.20.10\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S5.T2.1.20.10.1\" class=\"ltx_text ltx_font_bold\">100.00</span></td>\n<td id=\"S5.T2.1.20.11\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T2.1.20.11.1\" class=\"ltx_text ltx_font_bold\">100.00</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "Below, we will focus on the capability of defenses to reduce the BA in the new global model after aggregation compared to aggregation without defense (cf. line 6 in¬†",
                "Tab.¬†",
                "1",
                "). Additionally, we will report the detection accuracy (ACC) of the defenses, when applicable, where 100% ACC means perfect detection rate and no ",
                "False-Positives",
                " (FPs) and ",
                "False-Negatives",
                " (FNs). We will also name the most effective adaption strategies based on results provided in¬†",
                "Sect.¬†",
                "F",
                ", which we couldn‚Äôt include in the main section of the paper due to space limitations.",
                "Clustering.",
                " To demonstrate that na√Øve clustering methods could be bypassed, we use the HDBSCAN ",
                "(McInnes et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                " algorithm as an example and cluster based on the ",
                "cross-wise",
                " Cosine distances between model updates. As can be seen in the default scenario in line 7 of ",
                "Tab.¬†",
                "1",
                ", the defense is ineffective reaching a BA of 74.62% in the new global model after aggregation. We additionally report an ACC of only 10% (FPR of 100% and 81% FNR). Thus, there is no need for an attacker to follow any adaption strategies. Nevertheless, adaption to na√Øve clustering is possible by increasing the PDR allowing us to embed a BA of 86.86%, as depicted in scenario  ",
                "1",
                ".",
                "FoolsGold.",
                " The second defense, FoolsGold¬†",
                "(Fung et¬†al",
                ".",
                ", ",
                "2020",
                ")",
                ", is also based on ",
                "cross-wise",
                " Cosine distances between model updates. However, it analyzes only outputs of the last layer, which is more effective than na√Øve clustering and is capable of removing all poisoned models in the default scenario and for scenario,  ",
                "1",
                " reaching BAs of 1.85%, as depicted in line 8 of cf. ",
                "Tab.¬†",
                "1",
                ". Nevertheless, the defense can be circumvented using adaption. The best results we obtained by parameter ",
                "fixation",
                " on the last layer in combination with PDR increase, depicted as scenario  ",
                "2",
                " in ",
                "Tab.¬†",
                "1",
                ", reaching a BA of 63.54%. In contrast, ",
                "MESAS",
                " still removes the backdoor to 1.95% with only one FP when a similar adaption strategy is applied.",
                "Krum.",
                " Next, we evaluated Krum and ",
                "M-Krum",
                "¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                ", which leverage ",
                "cross-wise",
                " Euclidean distances between local models. The trigger backdoor is not reflected in this metric, which renders the defense ineffective for our default scenario (83.53% and 83.05%BA for Krum and ",
                "M-Krum",
                ", resp. in ",
                "Tab.¬†",
                "1",
                ") and for scenario  ",
                "1",
                " and  ",
                "2",
                ". Since Krum selects one single local model as the new global model, it can either choose a malicious or benign local model. In the former case, the backdoor trivially makes it to the global model. In the latter case, we can follow the following strategy: We can adapt the malicious models via constraint method ",
                "Eq.¬†",
                "1",
                " forcing the Krum scores of poisoned models to be more equal to each other compelling Krum to decide in their favor. By circumventing Krum like this, we achieved BAs up to 89.90% and reached 95.80% BA for ",
                "M-Krum",
                " as can be seen in scenario  ",
                "3",
                " in ",
                "Tab.¬†",
                "1",
                ". In contrast, ",
                "MESAS",
                " accurately filters the backdoor in similar circumstances, as adaption via constraint has significant effects on other metrics, like EUCL and MIN.",
                "Flame.",
                " We evaluate Flame¬†",
                "(Nguyen et¬†al",
                ".",
                ", ",
                "2022c",
                ")",
                ", a more complex DF defense, which combines clustering with clipping and noising techniques. Since the underlying metric is the same as for the na√Øve clustering defense, it is not very effective in removing the backdoor even in the default scenario achieving 79.17% BA (cf. line 13 in ",
                "Tab.¬†",
                "1",
                "). Similar to na√Øve clustering, we could strengthen the BA by increasing the PDR to 88.44% and by additional scaling to 91.34%, which shows that relying solely on the leveraged metric of Flame is insufficient. ",
                "MESAS",
                " erases the backdoor efficiently in all of the cases, due to the ",
                "in-depth",
                " model analysis with statistical tests and increased robustness against adaption through leveraging six different metrics.",
                "FLTrust.",
                " As a more recent defense, we analyze FLTrust¬†",
                "(Cao et¬†al",
                ".",
                ", ",
                "2021",
                ")",
                ", which is based on a trusted root dataset",
                "16",
                "16",
                "16",
                "Similar to the authors, we used a trusted root dataset of 100 IID samples and excluded them from the datasets used for training of the clients.",
                " on the server side. FLTrust leverages the Cosine Similarity between the updates of the local models and a trusted model trained by the server on the trusted root dataset and the norm of the local updates. Based on these metrics, FLTrust assigns weights to each local update so that poisoned updates are assigned with low weights, preferably zero, which would filter out the update. Therefore, the defense is ineffective, if the backdoor is not visible within both of these metrics, meaning, that the Cosine Similarity is inconspicuous, which can happen if the backdoor is only embedded in one layer without affecting the model-wise metric value, or if the backdoor is hidden in other metrics, as VAR, MAX, or MIN only. In most of our experiments, FLTrust successfully weakened backdoors beneath critical BAs. However, the assigned weights to all (also benign) local updates were found to be relatively small (mostly between 0.001 and 0.03), thereby inadvertently reducing their contribution to the global model. Consequently, the approach‚Äôs efficacy comes at the cost of slowing down the training speed. Additionally, FLTrust‚Äôs effectiveness depends on the chosen metric‚Äôs ability to accurately reflect the backdoor. However, a backdoor is not necessarily embedded in those metrics, as can be seen in experiments, e.g., in scenario  ",
                "3",
                " yielding a BA of 74.71%. For adaption, we first trained a benign model and then proceeded to adapt the local update of the malicious model based on the update of this benign model. Since we observed that in the resulting models, the main reason for suspicious metric values in Cosine Similarity originated from the parameters of the last model layer, we restricted this adaptation process to the last layer only to make the backdoor inconspicuous in the last layer. While this strategy resulted in low BA, FLTrust assigns higher weights to the malicious updates than to the benign ones, with seven out of eleven benign updates being assigned a weight of zero. That means that those benign models were filtered, essentially slowing down the learning process, while malicious models were included in aggregation, even so with smaller weights. In contrast, ",
                "MESAS",
                " consistently and effectively eliminated the backdoor in all of these cases without decreasing the impact of benign models.",
                "Differential Privacy.",
                " Besides DF methods, we evaluated two IR approaches: Model update clipping based on the Euclidean distance and a combination with model parameter noising¬†",
                "(McMahan et¬†al",
                ".",
                ", ",
                "2018",
                ")",
                ". Clipping is ineffective, as our default scenario backdoor is not reflected in the Euclidean distance of the updates. Thus, the attacker can achieve 60.66% BA for the default scenario (cf. line 12 of ",
                "Tab.¬†",
                "1",
                "). When using adaption, the BA can be increased slightly to 61.86% by increasing the PDR as in scenario  ",
                "1",
                ". In contrast, ",
                "MESAS",
                " is effective under similar circumstances resulting in 1.85% and 1.95% BAs.",
                "Robust Aggregation.",
                " We evaluate ",
                "T-Mean",
                " and ",
                "T-Median",
                "¬†",
                "(Yin et¬†al",
                ".",
                ", ",
                "2018",
                ")",
                ", which are RA alternatives to ",
                "FedAVG",
                ". Both result in weak backdoors with BA of 44.13% and 44.60% in lines 14 and 15 for the default scenario, but are not robust when facing a strong adaptive adversary: ",
                "T-Mean",
                " can be bypassed with up to 63.98% BA, while ",
                "T-Median",
                " shows 57.37% BA, but also experiences around 10% reduction in MA in scenario  ",
                "1",
                ". Hence, both approaches are not comparable to the performance of ",
                "MESAS",
                ", which reduces BA to 1.95% under similar circumstances.",
                "MESAS",
                ".",
                " To circumvent ",
                "MESAS",
                ", we tried to adapt to respective metrics that reflect the different poisoning attacks. We succeeded in adapting to COS, EUCL, MIN, and MAX, which appeared to be the metrics most backdoors manifest first. This was only possible by leveraging the loss scaling method of our strong adaptive adversary, as described in ",
                "Sect.¬†",
                "3.1",
                ", since otherwise, adaption to multiple losses already resulted in facing an adversarial dilemma. However, as soon as we adapt to those metrics, this behavior is reflected in the other metrics, namely VAR and COUNT. For a few experiments, we succeeded in adapting to VAR, even if the MA suffered immensely, but additional adaption to COUNT was impossible."
            ]
        ]
    },
    "S5.T3": {
        "caption": "Table 3. Defense runtimes in seconds.",
        "table": "<table id=\"S5.T3.4\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T3.4.1\" class=\"ltx_tr\">\n<td id=\"S5.T3.4.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">Defense</td>\n<td id=\"S5.T3.4.1.2\" class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_tt\">Runtime</td>\n<td id=\"S5.T3.4.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">Defense</td>\n<td id=\"S5.T3.4.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">Runtime</td>\n</tr>\n<tr id=\"S5.T3.4.2\" class=\"ltx_tr\">\n<td id=\"S5.T3.4.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T3.4.2.1.1\" class=\"ltx_text\">FedAVG</span></td>\n<td id=\"S5.T3.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\">0.12</td>\n<td id=\"S5.T3.4.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Flame¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Nguyen et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib69\" title=\"\" class=\"ltx_ref\">2022c</a>)</cite>\n</td>\n<td id=\"S5.T3.4.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">7.92</td>\n</tr>\n<tr id=\"S5.T3.4.3\" class=\"ltx_tr\">\n<td id=\"S5.T3.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Na√Øve Clustering</td>\n<td id=\"S5.T3.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_rr\">7.57</td>\n<td id=\"S5.T3.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Mean¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"S5.T3.4.3.4\" class=\"ltx_td ltx_align_center\">7.12</td>\n</tr>\n<tr id=\"S5.T3.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T3.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_r\">FoolsGold¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Fung et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>\n</td>\n<td id=\"S5.T3.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_rr\">0.14</td>\n<td id=\"S5.T3.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Median¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"S5.T3.4.4.4\" class=\"ltx_td ltx_align_center\">0.26</td>\n</tr>\n<tr id=\"S5.T3.4.5\" class=\"ltx_tr\">\n<td id=\"S5.T3.4.5.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Krum¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"S5.T3.4.5.2\" class=\"ltx_td ltx_align_center ltx_border_rr\">6.02</td>\n<td id=\"S5.T3.4.5.3\" class=\"ltx_td ltx_align_center ltx_border_r\">Auror¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Shen et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib89\" title=\"\" class=\"ltx_ref\">2016</a>)</cite>\n</td>\n<td id=\"S5.T3.4.5.4\" class=\"ltx_td ltx_align_center\">12 hours</td>\n</tr>\n<tr id=\"S5.T3.4.6\" class=\"ltx_tr\">\n<td id=\"S5.T3.4.6.1\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"S5.T3.4.6.1.1\" class=\"ltx_text\">M-Krum</span>¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"S5.T3.4.6.2\" class=\"ltx_td ltx_align_center ltx_border_rr\">5.92</td>\n<td id=\"S5.T3.4.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">FLTrust¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Cao et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib14\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>\n</td>\n<td id=\"S5.T3.4.6.4\" class=\"ltx_td ltx_align_center\">25.12</td>\n</tr>\n<tr id=\"S5.T3.4.7\" class=\"ltx_tr\">\n<td id=\"S5.T3.4.7.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"S5.T3.4.7.2\" class=\"ltx_td ltx_align_center ltx_border_rr\">2.37</td>\n<td id=\"S5.T3.4.7.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T3.4.7.3.1\" class=\"ltx_text ltx_font_bold\">MESAS</span></td>\n<td id=\"S5.T3.4.7.4\" class=\"ltx_td ltx_align_center\">24.37</td>\n</tr>\n<tr id=\"S5.T3.4.8\" class=\"ltx_tr\">\n<td id=\"S5.T3.4.8.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">Clip&amp;Noise¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"S5.T3.4.8.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_rr\">2.52</td>\n<td id=\"S5.T3.4.8.3\" class=\"ltx_td ltx_border_bb ltx_border_r\"></td>\n<td id=\"S5.T3.4.8.4\" class=\"ltx_td ltx_border_bb\"></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "To evaluate the influence of various parameters on ",
                "MESAS",
                "‚Äôs performance, we first investigated training ",
                "hyper-parameters",
                " and showed the independence from random seed, LR, PMR, and the selection of ",
                "Œ±",
                "ùõº",
                "\\alpha",
                ". We found no unexpected results that are much different from our default scenario. We report on these experiments in¬†",
                "Sect.¬†",
                "F.1",
                ".",
                "Poison Data Rate.",
                " Our experiments show, that the backdoor efficiency depends on the type and composition of the trigger, but also the PDR is important. We evaluated ",
                "p",
                "‚Äã",
                "d",
                "‚Äã",
                "r",
                "=",
                "[",
                "0.1",
                ",",
                "0.2",
                ",",
                "‚Ä¶",
                ",",
                "0.9",
                "]",
                "ùëù",
                "ùëë",
                "ùëü",
                "0.1",
                "0.2",
                "‚Ä¶",
                "0.9",
                "pdr=[0.1,0.2,...,0.9]",
                " and selected the smallest value ",
                "p",
                "‚Äã",
                "d",
                "‚Äã",
                "r",
                "=",
                "0.1",
                "ùëù",
                "ùëë",
                "ùëü",
                "0.1",
                "pdr=0.1",
                " that allows an adversary to introduce an effective backdoor in our default scenario. This naturally makes the resulting local models most stealthy by scoring a high MA. During some experiments, we increased this value up to 0.3 to reach a high BA. For bigger PDRs, ",
                "MESAS",
                " was also able to eliminate the backdoor with ACC 100%. This highlights the adversarial dilemma, since higher PDRs could increase the BA, but are not stealthy, urging the adversary to adapt to defenses, which has side effects on the metrics of ",
                "MESAS",
                ", forcing the adversary in an even more complex MOO problem. Concluding, we can claim, that ",
                "MESAS",
                " is independent of the PDR selected by the adversary.",
                "Initial Global Model.",
                " We conducted experiments with different ",
                "pre-trained",
                " models. We used random initialized models and ",
                "pre-trained",
                " models from PyTorch¬†",
                "(The Linux Foundation, ",
                "2022",
                "; Paszke et¬†al",
                ".",
                ", ",
                "2019",
                ")",
                " where we changed the first and last layer according to our dataset. We then trained the models in benign settings with 20 clients in the federation, all participating in each round as well as with 100 clients in the federation whereof 20 contributed each round. ",
                "MESAS",
                " performed well in all of the cases and can be used independently of the FL round. However, the detection performance in later rounds is naturally more accurate, since even benign clients can strive towards a different minimum on a relatively na√Øve model. Nevertheless, even in ",
                "inter-client",
                " ",
                "non-IID",
                " settings, ",
                "MESAS",
                " erases backdoors in early rounds reliably (cf.¬†",
                "Sect.¬†",
                "H.2",
                "). Principally, ",
                "MESAS",
                " is designed to be applied in every FL round and does not impose a negative impact on the convergence of the federation when no attack is present. The rationale behind this lies in ",
                "MESAS",
                "‚Äôs ability to effectively distinguish between attack-free and attack scenarios by virtue of its robust statistical tests.",
                "FL Round.",
                " To emphasize the effectiveness of ",
                "MESAS",
                ", we conducted additional experiments where models were trained starting from a randomly initialized model for 100 rounds until the model converged and the defenses are applied after every training round. We visualize the performance of various defense mechanisms, as well as scenarios with no defense and no attack in ",
                "App. Fig.¬†",
                "13",
                " and ",
                "App. Fig.¬†",
                "14",
                ". Notably, the results demonstrate that ",
                "MESAS",
                " surpasses other defense approaches by reaching BA and MA levels comparable to the attack-free scenario. This underscores the robustness of ",
                "MESAS",
                " in mitigating the impact of backdoor attacks.",
                "Dataset.",
                " We exchanged the dataset of our default scenario to MNIST¬†",
                "(Deng, ",
                "2012",
                ")",
                " and GTSRB¬†",
                "(Stallkamp et¬†al",
                ".",
                ", ",
                "2012",
                ")",
                " and could assert, that the experimental results and thus the performance of the defenses including ",
                "MESAS",
                " does not vary across datasets. MNIST as a more basic dataset, simplifies the detection of backdoors for all defenses even if a stealthy backdoor itself is hard to implement without defense, whereas GTSRB is more complex due to more label classes. We report the results for one of our MNIST experiments in ",
                "App. Tab.¬†",
                "21",
                " with one FP and one GTSRB experiment in ",
                "App. Tab.¬†",
                "22",
                " with 100% ACC.",
                "Model Architecture.",
                " We conducted experiments to analyze the independence from model architectures. Therefore, we used a CNN with two convolutional layers concatenated with pooling layers and ReLu functions¬†",
                "(Agarap, ",
                "2018",
                ")",
                " followed by three fully connected layers and trained on MNIST¬†",
                "(Deng, ",
                "2012",
                ")",
                ". Further, we tested SqueezeNet¬†",
                "(Iandola et¬†al",
                ".",
                ", ",
                "2016",
                ")",
                " with ",
                "CIFAR-10",
                "¬†",
                "(Krizhevsky et¬†al",
                ".",
                ", ",
                "2009",
                ")",
                " and can report 100% TNs with just one FN in both cases (cf.¬†",
                "App. Tab.¬†",
                "19",
                " and ",
                "App. Tab.¬†",
                "20",
                "). Hence, we can claim, that ",
                "MESAS",
                " is independent from the architecture of the model.",
                "Application Domain.",
                " We conducted experiments within the text domain training a sentiment analysis task using the ",
                "SST-2",
                "¬†",
                "(Socher et¬†al",
                ".",
                ", ",
                "2013",
                ")",
                " dataset on a DistilBERT¬†",
                "(Sanh et¬†al",
                ".",
                ", ",
                "2020",
                ")",
                " transformer model. We implemented a targeted poisoning attack, that labels sentences starting with the term ",
                "‚ÄúHey!‚Äù",
                " as negative. We can report 100% ACC in this experiment, showing the applicability of ",
                "MESAS",
                " in different application domains and for model architectures that do not contain convolutional layers."
            ]
        ]
    },
    "A5.T4": {
        "caption": "Table 4. MA for different poisoning methods without adaptive adversary in percent.",
        "table": "<table id=\"A5.T4.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A5.T4.1.2\" class=\"ltx_tr\">\n<td id=\"A5.T4.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\" rowspan=\"3\"><span id=\"A5.T4.1.2.1.1\" class=\"ltx_text\">Aggregation / Defenses</span></td>\n<td id=\"A5.T4.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"9\">MA</td>\n</tr>\n<tr id=\"A5.T4.1.3\" class=\"ltx_tr\">\n<td id=\"A5.T4.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Pixel Trigger</td>\n<td id=\"A5.T4.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clean-Label</td>\n<td id=\"A5.T4.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\">Semantic</td>\n<td id=\"A5.T4.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_r\">Edge Case</td>\n<td id=\"A5.T4.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_r\">Label Flip</td>\n<td id=\"A5.T4.1.3.6\" class=\"ltx_td ltx_align_center ltx_border_r\">Pervasive</td>\n<td id=\"A5.T4.1.3.7\" class=\"ltx_td ltx_align_center ltx_border_r\">Random Flip</td>\n<td id=\"A5.T4.1.3.8\" class=\"ltx_td ltx_align_center ltx_border_r\">Sign Flip</td>\n<td id=\"A5.T4.1.3.9\" class=\"ltx_td ltx_align_center\">Noising</td>\n</tr>\n<tr id=\"A5.T4.1.4\" class=\"ltx_tr\">\n<td id=\"A5.T4.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_citep\">(Gu et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib36\" title=\"\" class=\"ltx_ref\">2017</a>)</cite></td>\n<td id=\"A5.T4.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_citep\">(Turner et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib101\" title=\"\" class=\"ltx_ref\">2019</a>)</cite></td>\n<td id=\"A5.T4.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_citep\">(Bagdasaryan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib6\" title=\"\" class=\"ltx_ref\">2020</a>)</cite></td>\n<td id=\"A5.T4.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib105\" title=\"\" class=\"ltx_ref\">2020</a>)</cite></td>\n<td id=\"A5.T4.1.4.5\" class=\"ltx_td ltx_align_center ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_citep\">(Biggio et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib9\" title=\"\" class=\"ltx_ref\">2012</a>; Cao et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib13\" title=\"\" class=\"ltx_ref\">2019</a>)</cite></td>\n<td id=\"A5.T4.1.4.6\" class=\"ltx_td ltx_align_center ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_citep\">(Chen et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib18\" title=\"\" class=\"ltx_ref\">2017</a>)</cite></td>\n<td id=\"A5.T4.1.4.7\" class=\"ltx_td ltx_align_center ltx_border_r\"><a href=\"#A3.SS7\" title=\"C.7. Random Label Flipping ‚Ä£ Appendix C Poisoning Methods ‚Ä£ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations\" class=\"ltx_ref\">Sect.¬†<span class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">C.7</span></span></a></td>\n<td id=\"A5.T4.1.4.8\" class=\"ltx_td ltx_align_center ltx_border_r\"><a href=\"#A3.SS8\" title=\"C.8. Sign Flipping ‚Ä£ Appendix C Poisoning Methods ‚Ä£ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations\" class=\"ltx_ref\">Sect.¬†<span class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">C.8</span></span></a></td>\n<td id=\"A5.T4.1.4.9\" class=\"ltx_td ltx_align_center\"><a href=\"#A3.SS9\" title=\"C.9. Model Noising ‚Ä£ Appendix C Poisoning Methods ‚Ä£ Avoid Adversarial Adaption in Federated Learning by Multi-Metric Investigations\" class=\"ltx_ref\">Sect.¬†<span class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">C.9</span></span></a></td>\n</tr>\n<tr id=\"A5.T4.1.1\" class=\"ltx_tr\">\n<td id=\"A5.T4.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">1:</td>\n<td id=\"A5.T4.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Global model <math id=\"A5.T4.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"G^{r}\" display=\"inline\"><semantics id=\"A5.T4.1.1.1.m1.1a\"><msup id=\"A5.T4.1.1.1.m1.1.1\" xref=\"A5.T4.1.1.1.m1.1.1.cmml\"><mi id=\"A5.T4.1.1.1.m1.1.1.2\" xref=\"A5.T4.1.1.1.m1.1.1.2.cmml\">G</mi><mi id=\"A5.T4.1.1.1.m1.1.1.3\" xref=\"A5.T4.1.1.1.m1.1.1.3.cmml\">r</mi></msup><annotation-xml encoding=\"MathML-Content\" id=\"A5.T4.1.1.1.m1.1b\"><apply id=\"A5.T4.1.1.1.m1.1.1.cmml\" xref=\"A5.T4.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"A5.T4.1.1.1.m1.1.1.1.cmml\" xref=\"A5.T4.1.1.1.m1.1.1\">superscript</csymbol><ci id=\"A5.T4.1.1.1.m1.1.1.2.cmml\" xref=\"A5.T4.1.1.1.m1.1.1.2\">ùê∫</ci><ci id=\"A5.T4.1.1.1.m1.1.1.3.cmml\" xref=\"A5.T4.1.1.1.m1.1.1.3\">ùëü</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T4.1.1.1.m1.1c\">G^{r}</annotation></semantics></math>\n</td>\n<td id=\"A5.T4.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">62.99</td>\n<td id=\"A5.T4.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">62.99</td>\n<td id=\"A5.T4.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">62.99</td>\n<td id=\"A5.T4.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">62.99</td>\n<td id=\"A5.T4.1.1.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">62.99</td>\n<td id=\"A5.T4.1.1.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">62.99</td>\n<td id=\"A5.T4.1.1.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">62.99</td>\n<td id=\"A5.T4.1.1.10\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">62.99</td>\n<td id=\"A5.T4.1.1.11\" class=\"ltx_td ltx_align_center ltx_border_t\">62.99</td>\n</tr>\n<tr id=\"A5.T4.1.5\" class=\"ltx_tr\">\n<td id=\"A5.T4.1.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\">2:</td>\n<td id=\"A5.T4.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Average of benign local models</td>\n<td id=\"A5.T4.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">57.58</td>\n<td id=\"A5.T4.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">57.58</td>\n<td id=\"A5.T4.1.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">57.58</td>\n<td id=\"A5.T4.1.5.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">57.58</td>\n<td id=\"A5.T4.1.5.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">57.58</td>\n<td id=\"A5.T4.1.5.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">57.58</td>\n<td id=\"A5.T4.1.5.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">57.58</td>\n<td id=\"A5.T4.1.5.10\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">57.58</td>\n<td id=\"A5.T4.1.5.11\" class=\"ltx_td ltx_align_center ltx_border_t\">57.58</td>\n</tr>\n<tr id=\"A5.T4.1.6\" class=\"ltx_tr\">\n<td id=\"A5.T4.1.6.1\" class=\"ltx_td ltx_align_left\">3:</td>\n<td id=\"A5.T4.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Average of poisoned local models</td>\n<td id=\"A5.T4.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">57.84</td>\n<td id=\"A5.T4.1.6.4\" class=\"ltx_td ltx_align_center ltx_border_r\">54.49</td>\n<td id=\"A5.T4.1.6.5\" class=\"ltx_td ltx_align_center ltx_border_r\">54.37</td>\n<td id=\"A5.T4.1.6.6\" class=\"ltx_td ltx_align_center ltx_border_r\">58.69</td>\n<td id=\"A5.T4.1.6.7\" class=\"ltx_td ltx_align_center ltx_border_r\">47.87</td>\n<td id=\"A5.T4.1.6.8\" class=\"ltx_td ltx_align_center ltx_border_r\">53.69</td>\n<td id=\"A5.T4.1.6.9\" class=\"ltx_td ltx_align_center ltx_border_r\">53.69</td>\n<td id=\"A5.T4.1.6.10\" class=\"ltx_td ltx_align_center ltx_border_r\">10.00</td>\n<td id=\"A5.T4.1.6.11\" class=\"ltx_td ltx_align_center\">46.65</td>\n</tr>\n<tr id=\"A5.T4.1.7\" class=\"ltx_tr\">\n<td id=\"A5.T4.1.7.1\" class=\"ltx_td ltx_align_left ltx_border_t\">4:</td>\n<td id=\"A5.T4.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A5.T4.1.7.2.1\" class=\"ltx_text\">FedAVG</span> with benign local models</td>\n<td id=\"A5.T4.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.57</td>\n<td id=\"A5.T4.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.57</td>\n<td id=\"A5.T4.1.7.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.57</td>\n<td id=\"A5.T4.1.7.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.57</td>\n<td id=\"A5.T4.1.7.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.57</td>\n<td id=\"A5.T4.1.7.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.57</td>\n<td id=\"A5.T4.1.7.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.57</td>\n<td id=\"A5.T4.1.7.10\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.57</td>\n<td id=\"A5.T4.1.7.11\" class=\"ltx_td ltx_align_center ltx_border_t\">63.57</td>\n</tr>\n<tr id=\"A5.T4.1.8\" class=\"ltx_tr\">\n<td id=\"A5.T4.1.8.1\" class=\"ltx_td ltx_align_left\">5:</td>\n<td id=\"A5.T4.1.8.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A5.T4.1.8.2.1\" class=\"ltx_text\">FedAVG</span> with poisoned local models</td>\n<td id=\"A5.T4.1.8.3\" class=\"ltx_td ltx_align_center ltx_border_r\">64.92</td>\n<td id=\"A5.T4.1.8.4\" class=\"ltx_td ltx_align_center ltx_border_r\">61.79</td>\n<td id=\"A5.T4.1.8.5\" class=\"ltx_td ltx_align_center ltx_border_r\">65.49</td>\n<td id=\"A5.T4.1.8.6\" class=\"ltx_td ltx_align_center ltx_border_r\">66.55</td>\n<td id=\"A5.T4.1.8.7\" class=\"ltx_td ltx_align_center ltx_border_r\">58.31</td>\n<td id=\"A5.T4.1.8.8\" class=\"ltx_td ltx_align_center ltx_border_r\">63.66</td>\n<td id=\"A5.T4.1.8.9\" class=\"ltx_td ltx_align_center ltx_border_r\">52.55</td>\n<td id=\"A5.T4.1.8.10\" class=\"ltx_td ltx_align_center ltx_border_r\">10.00</td>\n<td id=\"A5.T4.1.8.11\" class=\"ltx_td ltx_align_center\">62.73</td>\n</tr>\n<tr id=\"A5.T4.1.9\" class=\"ltx_tr\">\n<td id=\"A5.T4.1.9.1\" class=\"ltx_td ltx_align_left ltx_border_t\">6:</td>\n<td id=\"A5.T4.1.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A5.T4.1.9.2.1\" class=\"ltx_text\">FedAVG</span> with all local models</td>\n<td id=\"A5.T4.1.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.81</td>\n<td id=\"A5.T4.1.9.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">64.20</td>\n<td id=\"A5.T4.1.9.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">64.66</td>\n<td id=\"A5.T4.1.9.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">64.52</td>\n<td id=\"A5.T4.1.9.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">57.09</td>\n<td id=\"A5.T4.1.9.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.51</td>\n<td id=\"A5.T4.1.9.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">57.03</td>\n<td id=\"A5.T4.1.9.10\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">10.00</td>\n<td id=\"A5.T4.1.9.11\" class=\"ltx_td ltx_align_center ltx_border_t\">63.07</td>\n</tr>\n<tr id=\"A5.T4.1.10\" class=\"ltx_tr\">\n<td id=\"A5.T4.1.10.1\" class=\"ltx_td ltx_align_left ltx_border_t\">7:</td>\n<td id=\"A5.T4.1.10.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Na√Øve Clustering</td>\n<td id=\"A5.T4.1.10.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">65.06</td>\n<td id=\"A5.T4.1.10.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.57</td>\n<td id=\"A5.T4.1.10.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">65.02</td>\n<td id=\"A5.T4.1.10.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">65.65</td>\n<td id=\"A5.T4.1.10.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">57.63</td>\n<td id=\"A5.T4.1.10.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.83</td>\n<td id=\"A5.T4.1.10.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">53.99</td>\n<td id=\"A5.T4.1.10.10\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.57</td>\n<td id=\"A5.T4.1.10.11\" class=\"ltx_td ltx_align_center ltx_border_t\">63.48</td>\n</tr>\n<tr id=\"A5.T4.1.11\" class=\"ltx_tr\">\n<td id=\"A5.T4.1.11.1\" class=\"ltx_td ltx_align_left\">8:</td>\n<td id=\"A5.T4.1.11.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FoolsGold¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Fung et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>\n</td>\n<td id=\"A5.T4.1.11.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.57</td>\n<td id=\"A5.T4.1.11.4\" class=\"ltx_td ltx_align_center ltx_border_r\">63.57</td>\n<td id=\"A5.T4.1.11.5\" class=\"ltx_td ltx_align_center ltx_border_r\">63.59</td>\n<td id=\"A5.T4.1.11.6\" class=\"ltx_td ltx_align_center ltx_border_r\">63.57</td>\n<td id=\"A5.T4.1.11.7\" class=\"ltx_td ltx_align_center ltx_border_r\">63.57</td>\n<td id=\"A5.T4.1.11.8\" class=\"ltx_td ltx_align_center ltx_border_r\">63.66</td>\n<td id=\"A5.T4.1.11.9\" class=\"ltx_td ltx_align_center ltx_border_r\">60.41</td>\n<td id=\"A5.T4.1.11.10\" class=\"ltx_td ltx_align_center ltx_border_r\">63.57</td>\n<td id=\"A5.T4.1.11.11\" class=\"ltx_td ltx_align_center\">63.07</td>\n</tr>\n<tr id=\"A5.T4.1.12\" class=\"ltx_tr\">\n<td id=\"A5.T4.1.12.1\" class=\"ltx_td ltx_align_left\">9:</td>\n<td id=\"A5.T4.1.12.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Krum¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A5.T4.1.12.3\" class=\"ltx_td ltx_align_center ltx_border_r\">59.75</td>\n<td id=\"A5.T4.1.12.4\" class=\"ltx_td ltx_align_center ltx_border_r\">55.18</td>\n<td id=\"A5.T4.1.12.5\" class=\"ltx_td ltx_align_center ltx_border_r\">58.72</td>\n<td id=\"A5.T4.1.12.6\" class=\"ltx_td ltx_align_center ltx_border_r\">59.86</td>\n<td id=\"A5.T4.1.12.7\" class=\"ltx_td ltx_align_center ltx_border_r\">58.38</td>\n<td id=\"A5.T4.1.12.8\" class=\"ltx_td ltx_align_center ltx_border_r\">58.38</td>\n<td id=\"A5.T4.1.12.9\" class=\"ltx_td ltx_align_center ltx_border_r\">58.38</td>\n<td id=\"A5.T4.1.12.10\" class=\"ltx_td ltx_align_center ltx_border_r\">58.38</td>\n<td id=\"A5.T4.1.12.11\" class=\"ltx_td ltx_align_center\">58.38</td>\n</tr>\n<tr id=\"A5.T4.1.13\" class=\"ltx_tr\">\n<td id=\"A5.T4.1.13.1\" class=\"ltx_td ltx_align_left\">10:</td>\n<td id=\"A5.T4.1.13.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A5.T4.1.13.2.1\" class=\"ltx_text\">M-Krum</span>¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A5.T4.1.13.3\" class=\"ltx_td ltx_align_center ltx_border_r\">64.18</td>\n<td id=\"A5.T4.1.13.4\" class=\"ltx_td ltx_align_center ltx_border_r\">61.65</td>\n<td id=\"A5.T4.1.13.5\" class=\"ltx_td ltx_align_center ltx_border_r\">65.94</td>\n<td id=\"A5.T4.1.13.6\" class=\"ltx_td ltx_align_center ltx_border_r\">66.14</td>\n<td id=\"A5.T4.1.13.7\" class=\"ltx_td ltx_align_center ltx_border_r\">64.15</td>\n<td id=\"A5.T4.1.13.8\" class=\"ltx_td ltx_align_center ltx_border_r\">65.26</td>\n<td id=\"A5.T4.1.13.9\" class=\"ltx_td ltx_align_center ltx_border_r\">64.15</td>\n<td id=\"A5.T4.1.13.10\" class=\"ltx_td ltx_align_center ltx_border_r\">64.15</td>\n<td id=\"A5.T4.1.13.11\" class=\"ltx_td ltx_align_center\">64.15</td>\n</tr>\n<tr id=\"A5.T4.1.14\" class=\"ltx_tr\">\n<td id=\"A5.T4.1.14.1\" class=\"ltx_td ltx_align_left\">11:</td>\n<td id=\"A5.T4.1.14.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A5.T4.1.14.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.80</td>\n<td id=\"A5.T4.1.14.4\" class=\"ltx_td ltx_align_center ltx_border_r\">64.21</td>\n<td id=\"A5.T4.1.14.5\" class=\"ltx_td ltx_align_center ltx_border_r\">64.52</td>\n<td id=\"A5.T4.1.14.6\" class=\"ltx_td ltx_align_center ltx_border_r\">64.48</td>\n<td id=\"A5.T4.1.14.7\" class=\"ltx_td ltx_align_center ltx_border_r\">56.99</td>\n<td id=\"A5.T4.1.14.8\" class=\"ltx_td ltx_align_center ltx_border_r\">63.39</td>\n<td id=\"A5.T4.1.14.9\" class=\"ltx_td ltx_align_center ltx_border_r\">54.01</td>\n<td id=\"A5.T4.1.14.10\" class=\"ltx_td ltx_align_center ltx_border_r\">10.00</td>\n<td id=\"A5.T4.1.14.11\" class=\"ltx_td ltx_align_center\">63.58</td>\n</tr>\n<tr id=\"A5.T4.1.15\" class=\"ltx_tr\">\n<td id=\"A5.T4.1.15.1\" class=\"ltx_td ltx_align_left\">12:</td>\n<td id=\"A5.T4.1.15.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip&amp;Noise¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A5.T4.1.15.3\" class=\"ltx_td ltx_align_center ltx_border_r\">50.78</td>\n<td id=\"A5.T4.1.15.4\" class=\"ltx_td ltx_align_center ltx_border_r\">59.94</td>\n<td id=\"A5.T4.1.15.5\" class=\"ltx_td ltx_align_center ltx_border_r\">57.60</td>\n<td id=\"A5.T4.1.15.6\" class=\"ltx_td ltx_align_center ltx_border_r\">57.85</td>\n<td id=\"A5.T4.1.15.7\" class=\"ltx_td ltx_align_center ltx_border_r\">50.04</td>\n<td id=\"A5.T4.1.15.8\" class=\"ltx_td ltx_align_center ltx_border_r\">54.86</td>\n<td id=\"A5.T4.1.15.9\" class=\"ltx_td ltx_align_center ltx_border_r\">49.95</td>\n<td id=\"A5.T4.1.15.10\" class=\"ltx_td ltx_align_center ltx_border_r\">10.00</td>\n<td id=\"A5.T4.1.15.11\" class=\"ltx_td ltx_align_center\">57.81</td>\n</tr>\n<tr id=\"A5.T4.1.16\" class=\"ltx_tr\">\n<td id=\"A5.T4.1.16.1\" class=\"ltx_td ltx_align_left\">13:</td>\n<td id=\"A5.T4.1.16.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Flame¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Nguyen et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib69\" title=\"\" class=\"ltx_ref\">2022c</a>)</cite>\n</td>\n<td id=\"A5.T4.1.16.3\" class=\"ltx_td ltx_align_center ltx_border_r\">60.96</td>\n<td id=\"A5.T4.1.16.4\" class=\"ltx_td ltx_align_center ltx_border_r\">60.03</td>\n<td id=\"A5.T4.1.16.5\" class=\"ltx_td ltx_align_center ltx_border_r\">62.13</td>\n<td id=\"A5.T4.1.16.6\" class=\"ltx_td ltx_align_center ltx_border_r\">64.27</td>\n<td id=\"A5.T4.1.16.7\" class=\"ltx_td ltx_align_center ltx_border_r\">57.11</td>\n<td id=\"A5.T4.1.16.8\" class=\"ltx_td ltx_align_center ltx_border_r\">59.15</td>\n<td id=\"A5.T4.1.16.9\" class=\"ltx_td ltx_align_center ltx_border_r\">60.99</td>\n<td id=\"A5.T4.1.16.10\" class=\"ltx_td ltx_align_center ltx_border_r\">60.99</td>\n<td id=\"A5.T4.1.16.11\" class=\"ltx_td ltx_align_center\">62.60</td>\n</tr>\n<tr id=\"A5.T4.1.17\" class=\"ltx_tr\">\n<td id=\"A5.T4.1.17.1\" class=\"ltx_td ltx_align_left\">14:</td>\n<td id=\"A5.T4.1.17.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Mean¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A5.T4.1.17.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.51</td>\n<td id=\"A5.T4.1.17.4\" class=\"ltx_td ltx_align_center ltx_border_r\">64.08</td>\n<td id=\"A5.T4.1.17.5\" class=\"ltx_td ltx_align_center ltx_border_r\">64.17</td>\n<td id=\"A5.T4.1.17.6\" class=\"ltx_td ltx_align_center ltx_border_r\">64.20</td>\n<td id=\"A5.T4.1.17.7\" class=\"ltx_td ltx_align_center ltx_border_r\">56.96</td>\n<td id=\"A5.T4.1.17.8\" class=\"ltx_td ltx_align_center ltx_border_r\">63.04</td>\n<td id=\"A5.T4.1.17.9\" class=\"ltx_td ltx_align_center ltx_border_r\">56.77</td>\n<td id=\"A5.T4.1.17.10\" class=\"ltx_td ltx_align_center ltx_border_r\">10.00</td>\n<td id=\"A5.T4.1.17.11\" class=\"ltx_td ltx_align_center\">63.27</td>\n</tr>\n<tr id=\"A5.T4.1.18\" class=\"ltx_tr\">\n<td id=\"A5.T4.1.18.1\" class=\"ltx_td ltx_align_left\">15:</td>\n<td id=\"A5.T4.1.18.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Median¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A5.T4.1.18.3\" class=\"ltx_td ltx_align_center ltx_border_r\">51.22</td>\n<td id=\"A5.T4.1.18.4\" class=\"ltx_td ltx_align_center ltx_border_r\">53.64</td>\n<td id=\"A5.T4.1.18.5\" class=\"ltx_td ltx_align_center ltx_border_r\">52.11</td>\n<td id=\"A5.T4.1.18.6\" class=\"ltx_td ltx_align_center ltx_border_r\">55.13</td>\n<td id=\"A5.T4.1.18.7\" class=\"ltx_td ltx_align_center ltx_border_r\">48.36</td>\n<td id=\"A5.T4.1.18.8\" class=\"ltx_td ltx_align_center ltx_border_r\">49.40</td>\n<td id=\"A5.T4.1.18.9\" class=\"ltx_td ltx_align_center ltx_border_r\">44.69</td>\n<td id=\"A5.T4.1.18.10\" class=\"ltx_td ltx_align_center ltx_border_r\">10.00</td>\n<td id=\"A5.T4.1.18.11\" class=\"ltx_td ltx_align_center\">51.53</td>\n</tr>\n<tr id=\"A5.T4.1.19\" class=\"ltx_tr\">\n<td id=\"A5.T4.1.19.1\" class=\"ltx_td ltx_align_left\">16:</td>\n<td id=\"A5.T4.1.19.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FLTrust¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Cao et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib14\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>\n</td>\n<td id=\"A5.T4.1.19.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.49</td>\n<td id=\"A5.T4.1.19.4\" class=\"ltx_td ltx_align_center ltx_border_r\">63.37</td>\n<td id=\"A5.T4.1.19.5\" class=\"ltx_td ltx_align_center ltx_border_r\">63.75</td>\n<td id=\"A5.T4.1.19.6\" class=\"ltx_td ltx_align_center ltx_border_r\">64.05</td>\n<td id=\"A5.T4.1.19.7\" class=\"ltx_td ltx_align_center ltx_border_r\">62.16</td>\n<td id=\"A5.T4.1.19.8\" class=\"ltx_td ltx_align_center ltx_border_r\">63.25</td>\n<td id=\"A5.T4.1.19.9\" class=\"ltx_td ltx_align_center ltx_border_r\">63.16</td>\n<td id=\"A5.T4.1.19.10\" class=\"ltx_td ltx_align_center ltx_border_r\">26.97</td>\n<td id=\"A5.T4.1.19.11\" class=\"ltx_td ltx_align_center\">63.32</td>\n</tr>\n<tr id=\"A5.T4.1.20\" class=\"ltx_tr\">\n<td id=\"A5.T4.1.20.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">17:</td>\n<td id=\"A5.T4.1.20.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"A5.T4.1.20.2.1\" class=\"ltx_text ltx_font_bold\">MESAS</span></td>\n<td id=\"A5.T4.1.20.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">63.57</td>\n<td id=\"A5.T4.1.20.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">62.18</td>\n<td id=\"A5.T4.1.20.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">63.36</td>\n<td id=\"A5.T4.1.20.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">63.15</td>\n<td id=\"A5.T4.1.20.7\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">63.15</td>\n<td id=\"A5.T4.1.20.8\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">62.82</td>\n<td id=\"A5.T4.1.20.9\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">62.88</td>\n<td id=\"A5.T4.1.20.10\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">63.57</td>\n<td id=\"A5.T4.1.20.11\" class=\"ltx_td ltx_align_center ltx_border_bb\">63.57</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In this section, we provide additional information about ",
                "MESAS",
                ", that helpful to understand the intuition and facilitates reproducibility of the defense.",
                "Model Distances.",
                " ",
                "Fig.¬†",
                "4",
                " depicts, how locally trained FL models can vary withing the Euclidean or Cosine distance. We denote the locally trained models as ",
                "L",
                "i",
                "r",
                "+",
                "1",
                "subscript",
                "superscript",
                "ùêø",
                "ùëü",
                "1",
                "ùëñ",
                "L^{{r+1}}_{i}",
                " and the original global model, that served as a base for ",
                "L",
                "i",
                "r",
                "+",
                "1",
                "subscript",
                "superscript",
                "ùêø",
                "ùëü",
                "1",
                "ùëñ",
                "L^{{r+1}}_{i}",
                " is defined as ",
                "G",
                "r",
                "superscript",
                "ùê∫",
                "ùëü",
                "G^{r}",
                ". Further we show that scaling of the model parameters after training effects the COS, thus is not a stealthy model poisoning method for an adversary in FL settings.",
                "Metric Formulas.",
                " We provide the formulas for the metrics of ",
                "MESAS",
                " in ",
                "Eq.¬†",
                "6",
                " - ",
                "Eq.¬†",
                "11",
                ". ",
                "f",
                "‚Äã",
                "l",
                "‚Äã",
                "a",
                "‚Äã",
                "t",
                "‚Äã",
                "t",
                "‚Äã",
                "e",
                "‚Äã",
                "n",
                "ùëì",
                "ùëô",
                "ùëé",
                "ùë°",
                "ùë°",
                "ùëí",
                "ùëõ",
                "flatten",
                " denominates, that all model parameters are arranged in a one dimensional list and ",
                "n",
                "‚Äã",
                "z",
                "ùëõ",
                "ùëß",
                "nz",
                " is an abbreviation for the nonzero function. Each metric can be computed once per round ",
                "r",
                "ùëü",
                "r",
                " for each client i as well as for each layer and the model as a whole.",
                "Parameters.",
                " The significance level for ",
                "MESAS",
                " is set to 0.0001 for IID, to 0.001 for ",
                "intra-client",
                " ",
                "non-IID",
                ", and to 0.03 for ",
                "inter-client",
                " ",
                "non-IID",
                " scenarios."
            ]
        ]
    },
    "A6.T5": {
        "caption": "Table 5. MA and BA in the default scenario with scaled poisoned models regarding the Euclidean distance of updates in percent.",
        "table": "<table id=\"A6.T5.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A6.T5.1.2\" class=\"ltx_tr\">\n<td id=\"A6.T5.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\">Accuracies without defenses</td>\n<td id=\"A6.T5.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">MA</td>\n<td id=\"A6.T5.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T5.1.1\" class=\"ltx_tr\">\n<td id=\"A6.T5.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">1:</td>\n<td id=\"A6.T5.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Global model <math id=\"A6.T5.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"G^{r}\" display=\"inline\"><semantics id=\"A6.T5.1.1.1.m1.1a\"><msup id=\"A6.T5.1.1.1.m1.1.1\" xref=\"A6.T5.1.1.1.m1.1.1.cmml\"><mi id=\"A6.T5.1.1.1.m1.1.1.2\" xref=\"A6.T5.1.1.1.m1.1.1.2.cmml\">G</mi><mi id=\"A6.T5.1.1.1.m1.1.1.3\" xref=\"A6.T5.1.1.1.m1.1.1.3.cmml\">r</mi></msup><annotation-xml encoding=\"MathML-Content\" id=\"A6.T5.1.1.1.m1.1b\"><apply id=\"A6.T5.1.1.1.m1.1.1.cmml\" xref=\"A6.T5.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"A6.T5.1.1.1.m1.1.1.1.cmml\" xref=\"A6.T5.1.1.1.m1.1.1\">superscript</csymbol><ci id=\"A6.T5.1.1.1.m1.1.1.2.cmml\" xref=\"A6.T5.1.1.1.m1.1.1.2\">ùê∫</ci><ci id=\"A6.T5.1.1.1.m1.1.1.3.cmml\" xref=\"A6.T5.1.1.1.m1.1.1.3\">ùëü</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T5.1.1.1.m1.1c\">G^{r}</annotation></semantics></math>\n</td>\n<td id=\"A6.T5.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">62.99</td>\n<td id=\"A6.T5.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">1.90</td>\n</tr>\n<tr id=\"A6.T5.1.3\" class=\"ltx_tr\">\n<td id=\"A6.T5.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">2:</td>\n<td id=\"A6.T5.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Average of benign local models</td>\n<td id=\"A6.T5.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">57.58</td>\n<td id=\"A6.T5.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">4.56</td>\n</tr>\n<tr id=\"A6.T5.1.4\" class=\"ltx_tr\">\n<td id=\"A6.T5.1.4.1\" class=\"ltx_td ltx_align_left\">3:</td>\n<td id=\"A6.T5.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Average of poisoned local models</td>\n<td id=\"A6.T5.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">57.84</td>\n<td id=\"A6.T5.1.4.4\" class=\"ltx_td ltx_align_center\">85.13</td>\n</tr>\n<tr id=\"A6.T5.1.5\" class=\"ltx_tr\">\n<td id=\"A6.T5.1.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\">4:</td>\n<td id=\"A6.T5.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T5.1.5.2.1\" class=\"ltx_text\">FedAVG</span> with benign local models</td>\n<td id=\"A6.T5.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.57</td>\n<td id=\"A6.T5.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">1.85</td>\n</tr>\n<tr id=\"A6.T5.1.6\" class=\"ltx_tr\">\n<td id=\"A6.T5.1.6.1\" class=\"ltx_td ltx_align_left\">5:</td>\n<td id=\"A6.T5.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T5.1.6.2.1\" class=\"ltx_text\">FedAVG</span> with poisoned local models</td>\n<td id=\"A6.T5.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">64.49</td>\n<td id=\"A6.T5.1.6.4\" class=\"ltx_td ltx_align_center\">86.45</td>\n</tr>\n<tr id=\"A6.T5.1.7\" class=\"ltx_tr\">\n<td id=\"A6.T5.1.7.1\" class=\"ltx_td ltx_align_left ltx_border_t\">6:</td>\n<td id=\"A6.T5.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T5.1.7.2.1\" class=\"ltx_text\">FedAVG</span> with all local models</td>\n<td id=\"A6.T5.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.61</td>\n<td id=\"A6.T5.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A6.T5.1.7.4.1\" class=\"ltx_text ltx_font_bold\">51.15</span></td>\n</tr>\n<tr id=\"A6.T5.1.8\" class=\"ltx_tr\">\n<td id=\"A6.T5.1.8.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\" colspan=\"2\">Global model accuracies after applying defenses</td>\n<td id=\"A6.T5.1.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\">MA</td>\n<td id=\"A6.T5.1.8.3\" class=\"ltx_td ltx_align_center ltx_border_tt ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T5.1.9\" class=\"ltx_tr\">\n<td id=\"A6.T5.1.9.1\" class=\"ltx_td ltx_align_left ltx_border_t\">7:</td>\n<td id=\"A6.T5.1.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Na√Øve Clustering</td>\n<td id=\"A6.T5.1.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.67</td>\n<td id=\"A6.T5.1.9.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A6.T5.1.9.4.1\" class=\"ltx_text ltx_font_bold\">60.85</span></td>\n</tr>\n<tr id=\"A6.T5.1.10\" class=\"ltx_tr\">\n<td id=\"A6.T5.1.10.1\" class=\"ltx_td ltx_align_left\">8:</td>\n<td id=\"A6.T5.1.10.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FoolsGold¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Fung et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>\n</td>\n<td id=\"A6.T5.1.10.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.57</td>\n<td id=\"A6.T5.1.10.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T5.1.10.4.1\" class=\"ltx_text ltx_font_bold\">1.85</span></td>\n</tr>\n<tr id=\"A6.T5.1.11\" class=\"ltx_tr\">\n<td id=\"A6.T5.1.11.1\" class=\"ltx_td ltx_align_left\">9:</td>\n<td id=\"A6.T5.1.11.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Krum¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T5.1.11.3\" class=\"ltx_td ltx_align_center ltx_border_r\">58.38</td>\n<td id=\"A6.T5.1.11.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T5.1.11.4.1\" class=\"ltx_text ltx_font_bold\">3.98</span></td>\n</tr>\n<tr id=\"A6.T5.1.12\" class=\"ltx_tr\">\n<td id=\"A6.T5.1.12.1\" class=\"ltx_td ltx_align_left\">10:</td>\n<td id=\"A6.T5.1.12.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T5.1.12.2.1\" class=\"ltx_text\">M-Krum</span>¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T5.1.12.3\" class=\"ltx_td ltx_align_center ltx_border_r\">64.24</td>\n<td id=\"A6.T5.1.12.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T5.1.12.4.1\" class=\"ltx_text ltx_font_bold\">56.23</span></td>\n</tr>\n<tr id=\"A6.T5.1.13\" class=\"ltx_tr\">\n<td id=\"A6.T5.1.13.1\" class=\"ltx_td ltx_align_left\">11:</td>\n<td id=\"A6.T5.1.13.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T5.1.13.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.61</td>\n<td id=\"A6.T5.1.13.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T5.1.13.4.1\" class=\"ltx_text ltx_font_bold\">60.33</span></td>\n</tr>\n<tr id=\"A6.T5.1.14\" class=\"ltx_tr\">\n<td id=\"A6.T5.1.14.1\" class=\"ltx_td ltx_align_left\">12:</td>\n<td id=\"A6.T5.1.14.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip&amp;Noise¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T5.1.14.3\" class=\"ltx_td ltx_align_center ltx_border_r\">57.63</td>\n<td id=\"A6.T5.1.14.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T5.1.14.4.1\" class=\"ltx_text ltx_font_bold\">60.66</span></td>\n</tr>\n<tr id=\"A6.T5.1.15\" class=\"ltx_tr\">\n<td id=\"A6.T5.1.15.1\" class=\"ltx_td ltx_align_left\">13:</td>\n<td id=\"A6.T5.1.15.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Flame¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Nguyen et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib69\" title=\"\" class=\"ltx_ref\">2022c</a>)</cite>\n</td>\n<td id=\"A6.T5.1.15.3\" class=\"ltx_td ltx_align_center ltx_border_r\">60.40</td>\n<td id=\"A6.T5.1.15.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T5.1.15.4.1\" class=\"ltx_text ltx_font_bold\">71.02</span></td>\n</tr>\n<tr id=\"A6.T5.1.16\" class=\"ltx_tr\">\n<td id=\"A6.T5.1.16.1\" class=\"ltx_td ltx_align_left\">14:</td>\n<td id=\"A6.T5.1.16.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Mean¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T5.1.16.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.35</td>\n<td id=\"A6.T5.1.16.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T5.1.16.4.1\" class=\"ltx_text ltx_font_bold\">51.52</span></td>\n</tr>\n<tr id=\"A6.T5.1.17\" class=\"ltx_tr\">\n<td id=\"A6.T5.1.17.1\" class=\"ltx_td ltx_align_left\">15:</td>\n<td id=\"A6.T5.1.17.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Median¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T5.1.17.3\" class=\"ltx_td ltx_align_center ltx_border_r\">49.89</td>\n<td id=\"A6.T5.1.17.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T5.1.17.4.1\" class=\"ltx_text ltx_font_bold\">44.34</span></td>\n</tr>\n<tr id=\"A6.T5.1.18\" class=\"ltx_tr\">\n<td id=\"A6.T5.1.18.1\" class=\"ltx_td ltx_align_left\">16:</td>\n<td id=\"A6.T5.1.18.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FLTrust¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Cao et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib14\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>\n</td>\n<td id=\"A6.T5.1.18.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.13</td>\n<td id=\"A6.T5.1.18.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T5.1.18.4.1\" class=\"ltx_text ltx_font_bold\">23.24</span></td>\n</tr>\n<tr id=\"A6.T5.1.19\" class=\"ltx_tr\">\n<td id=\"A6.T5.1.19.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">17:</td>\n<td id=\"A6.T5.1.19.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"A6.T5.1.19.2.1\" class=\"ltx_text ltx_font_bold\">MESAS</span></td>\n<td id=\"A6.T5.1.19.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">63.36</td>\n<td id=\"A6.T5.1.19.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"A6.T5.1.19.4.1\" class=\"ltx_text ltx_font_bold\">1.95</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In this section, we provide further results for our experiments, that could not be included in the main part of the paper due to space limitations. We selected the most interesting and representative results to be part of the main part, but report the rest below for completeness.",
                "Tab.¬†",
                "4",
                " reports the MAs corresponding to the BAs and ACCs in ",
                "Tab.¬†",
                "2",
                " for different poisoning methods without adaptive adversaries. Note, that ",
                "MESAS",
                " provides high MA independent of the applied poisoning attack. The table shows, that ",
                "MESAS",
                " does not negatively impact the MA and is also effective against untargeted attacks.",
                "Tab.¬†",
                "5",
                " shows the results for our default scenario with scaled poisoned models regarding the Euclidean distance of updates. The results confirm, that scaling can increase the BA. ",
                "MESAS",
                " is already efficient for the unscaled version visualized in scenario  ",
                "1",
                " in ",
                "Tab.¬†",
                "1",
                ", hence is also effective for scaled models due to the intuition visualized in ",
                "Fig.¬†",
                "4",
                ". ",
                "Tab.¬†",
                "6",
                " depicts the results for the default scenario with a PDR of 0.3 for scaled poisoned models.",
                "We conducted an attack leveraging our strong adaptive adversary against FoolsGold¬†",
                "(Fung et¬†al",
                ".",
                ", ",
                "2020",
                ")",
                " and report the result in ",
                "Tab.¬†",
                "7",
                ". As strategy, we first trained a benign local model and transferred the trained parameters of the last layer to a fresh local model. We then excluded the parameters form training and poisoned the local model forcing the backdoor into some other layers. In ",
                "Tab.¬†",
                "8",
                " we additionally applied scaling. We can observe, that the BA of FoolsGold can be increased with those methods.",
                "Scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                " shows the result after adapting to Krum scores¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                " in an unscaled and scaled version. We forced the Euclidean distance between poisoned models and the global model to be similar to each other and on a benign level so that the defenses decide in favor of the poisoned models. ",
                "Fig.¬†",
                "12",
                " depicts the Krum scores for the default scenario associated with the default scenario in ",
                "Tab.¬†",
                "1",
                " to show, that the effective backdoor is based on coincidence and not intentionally forced by the attacker. With slight changes in some models, Krum could also decide for a benign model. However, after adaption, we can introduce a high BA intentionally in scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                ".",
                "Tab.¬†",
                "10",
                " and ",
                "Tab.¬†",
                "11",
                " show the results for a classical ",
                "intra-client",
                " ",
                "non-IID",
                " scenario crafted by ",
                "1-class",
                " ",
                "non-IID",
                " with ",
                "q",
                "=",
                "0.5",
                "ùëû",
                "0.5",
                "q=0.5",
                ". In both cases, ",
                "MESAS",
                " reduces the BA reliably with only one FP, while other defenses allow the attacker to embed 34.72% to 49.47% BA. ",
                "Tab.¬†",
                "12",
                " depicts the results for an increased PDR of 0.3, allowing the adversary to reach a BA of 57.68% without defense and up to 92.86% under active defenses. ",
                "MESAS",
                " still removes the poisoned models most effectively with only two FPs.",
                "In ",
                "Tab.¬†",
                "13",
                " and ",
                "Tab.¬†",
                "13",
                " we adapt all malicious models to a central benign value regarding the Cosine distance to the global model, which has the effect, that the models are inconspicuous in Krum scores, hence can circumvent Krum and ",
                "M-Krum",
                "¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                ", while ",
                "MESAS",
                " still erases the backdoor with only two FPs.",
                "Tab.¬†",
                "15",
                " and ",
                "Tab.¬†",
                "16",
                " show the results in a ",
                "inter-client",
                " ",
                "non-IID",
                " scenario based on our ",
                "Random-Non-IID",
                " strategy for a model in FL round one and highlights, that ",
                "MESAS",
                " outperforms other defenses in reducing the BA of the new global model.\n",
                "Tab.¬†",
                "17",
                " and ",
                "Tab.¬†",
                "18",
                " show the results for a setting in round 50,w here 100 clients are part of the federation and 20 clients are selected randomly in each round for training. Due to the later rounds, ",
                "MESAS",
                " is even more effective than other defenses and reduces the BA to a minimum.",
                "Tab.¬†",
                "19",
                " and ",
                "Tab.¬†",
                "20",
                " show the experiments results with a CNN training on MNIST¬†",
                "(Deng, ",
                "2012",
                ")",
                " and SqueezeNet¬†",
                "(Iandola et¬†al",
                ".",
                ", ",
                "2016",
                ")",
                " training on ",
                "CIFAR-10",
                " ",
                "(Krizhevsky et¬†al",
                ".",
                ", ",
                "2009",
                ")",
                ". The CNN consists of two convolutional layers, the first with 32 output layers, the second with 64 output layers, both applying a kernel size of 5. The output of the convolutional layers traverse a ReLU¬†",
                "(Agarap, ",
                "2018",
                ")",
                " and a 2D pooling layer, before being fed into three fully connected layers with output size 512, 256 and 10 output respectively. In both experiments, we used a ",
                "self-pre-trained",
                " model as global model. We can report perfect detection rate with just one FP for CNN and SqueezeNet, even if the backdoor is not yet embedded in the global model. Hence, a stronger adaption by the adversary would strengthen the detection capabilities of ",
                "MESAS",
                ". Other defenses instead can be circumvented by the adaptive adversary."
            ]
        ]
    },
    "A6.T6": {
        "caption": "Table 6. MA and BA in the default scenario with PDR of 0.3 and scaled poisoned models regarding the Euclidean distance of updates in percent.",
        "table": "<table id=\"A6.T6.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A6.T6.1.2\" class=\"ltx_tr\">\n<td id=\"A6.T6.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\">Accuracies without defenses</td>\n<td id=\"A6.T6.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">MA</td>\n<td id=\"A6.T6.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T6.1.1\" class=\"ltx_tr\">\n<td id=\"A6.T6.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">1:</td>\n<td id=\"A6.T6.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Global model <math id=\"A6.T6.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"G^{r}\" display=\"inline\"><semantics id=\"A6.T6.1.1.1.m1.1a\"><msup id=\"A6.T6.1.1.1.m1.1.1\" xref=\"A6.T6.1.1.1.m1.1.1.cmml\"><mi id=\"A6.T6.1.1.1.m1.1.1.2\" xref=\"A6.T6.1.1.1.m1.1.1.2.cmml\">G</mi><mi id=\"A6.T6.1.1.1.m1.1.1.3\" xref=\"A6.T6.1.1.1.m1.1.1.3.cmml\">r</mi></msup><annotation-xml encoding=\"MathML-Content\" id=\"A6.T6.1.1.1.m1.1b\"><apply id=\"A6.T6.1.1.1.m1.1.1.cmml\" xref=\"A6.T6.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"A6.T6.1.1.1.m1.1.1.1.cmml\" xref=\"A6.T6.1.1.1.m1.1.1\">superscript</csymbol><ci id=\"A6.T6.1.1.1.m1.1.1.2.cmml\" xref=\"A6.T6.1.1.1.m1.1.1.2\">ùê∫</ci><ci id=\"A6.T6.1.1.1.m1.1.1.3.cmml\" xref=\"A6.T6.1.1.1.m1.1.1.3\">ùëü</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T6.1.1.1.m1.1c\">G^{r}</annotation></semantics></math>\n</td>\n<td id=\"A6.T6.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">62.99</td>\n<td id=\"A6.T6.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">1.90</td>\n</tr>\n<tr id=\"A6.T6.1.3\" class=\"ltx_tr\">\n<td id=\"A6.T6.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">2:</td>\n<td id=\"A6.T6.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Average of benign local models</td>\n<td id=\"A6.T6.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">57.58</td>\n<td id=\"A6.T6.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">4.56</td>\n</tr>\n<tr id=\"A6.T6.1.4\" class=\"ltx_tr\">\n<td id=\"A6.T6.1.4.1\" class=\"ltx_td ltx_align_left\">3:</td>\n<td id=\"A6.T6.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Average of poisoned local models</td>\n<td id=\"A6.T6.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">54.58</td>\n<td id=\"A6.T6.1.4.4\" class=\"ltx_td ltx_align_center\">93.15</td>\n</tr>\n<tr id=\"A6.T6.1.5\" class=\"ltx_tr\">\n<td id=\"A6.T6.1.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\">4:</td>\n<td id=\"A6.T6.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T6.1.5.2.1\" class=\"ltx_text\">FedAVG</span> with benign local models</td>\n<td id=\"A6.T6.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.57</td>\n<td id=\"A6.T6.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">1.85</td>\n</tr>\n<tr id=\"A6.T6.1.6\" class=\"ltx_tr\">\n<td id=\"A6.T6.1.6.1\" class=\"ltx_td ltx_align_left\">5:</td>\n<td id=\"A6.T6.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T6.1.6.2.1\" class=\"ltx_text\">FedAVG</span> with poisoned local models</td>\n<td id=\"A6.T6.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">58.49</td>\n<td id=\"A6.T6.1.6.4\" class=\"ltx_td ltx_align_center\">97.46</td>\n</tr>\n<tr id=\"A6.T6.1.7\" class=\"ltx_tr\">\n<td id=\"A6.T6.1.7.1\" class=\"ltx_td ltx_align_left ltx_border_t\">6:</td>\n<td id=\"A6.T6.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T6.1.7.2.1\" class=\"ltx_text\">FedAVG</span> with all local models</td>\n<td id=\"A6.T6.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">62.95</td>\n<td id=\"A6.T6.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A6.T6.1.7.4.1\" class=\"ltx_text ltx_font_bold\">75.81</span></td>\n</tr>\n<tr id=\"A6.T6.1.8\" class=\"ltx_tr\">\n<td id=\"A6.T6.1.8.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\" colspan=\"2\">Global model accuracies after applying defenses</td>\n<td id=\"A6.T6.1.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\">MA</td>\n<td id=\"A6.T6.1.8.3\" class=\"ltx_td ltx_align_center ltx_border_tt ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T6.1.9\" class=\"ltx_tr\">\n<td id=\"A6.T6.1.9.1\" class=\"ltx_td ltx_align_left ltx_border_t\">7:</td>\n<td id=\"A6.T6.1.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Na√Øve Clustering</td>\n<td id=\"A6.T6.1.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">64.57</td>\n<td id=\"A6.T6.1.9.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A6.T6.1.9.4.1\" class=\"ltx_text ltx_font_bold\">86.86</span></td>\n</tr>\n<tr id=\"A6.T6.1.10\" class=\"ltx_tr\">\n<td id=\"A6.T6.1.10.1\" class=\"ltx_td ltx_align_left\">8:</td>\n<td id=\"A6.T6.1.10.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FoolsGold¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Fung et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>\n</td>\n<td id=\"A6.T6.1.10.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.57</td>\n<td id=\"A6.T6.1.10.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T6.1.10.4.1\" class=\"ltx_text ltx_font_bold\">1.85</span></td>\n</tr>\n<tr id=\"A6.T6.1.11\" class=\"ltx_tr\">\n<td id=\"A6.T6.1.11.1\" class=\"ltx_td ltx_align_left\">9:</td>\n<td id=\"A6.T6.1.11.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Krum¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T6.1.11.3\" class=\"ltx_td ltx_align_center ltx_border_r\">52.22</td>\n<td id=\"A6.T6.1.11.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T6.1.11.4.1\" class=\"ltx_text ltx_font_bold\">95.97</span></td>\n</tr>\n<tr id=\"A6.T6.1.12\" class=\"ltx_tr\">\n<td id=\"A6.T6.1.12.1\" class=\"ltx_td ltx_align_left\">10:</td>\n<td id=\"A6.T6.1.12.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T6.1.12.2.1\" class=\"ltx_text\">M-Krum</span>¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T6.1.12.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.90</td>\n<td id=\"A6.T6.1.12.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T6.1.12.4.1\" class=\"ltx_text ltx_font_bold\">92.72</span></td>\n</tr>\n<tr id=\"A6.T6.1.13\" class=\"ltx_tr\">\n<td id=\"A6.T6.1.13.1\" class=\"ltx_td ltx_align_left\">11:</td>\n<td id=\"A6.T6.1.13.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T6.1.13.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.85</td>\n<td id=\"A6.T6.1.13.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T6.1.13.4.1\" class=\"ltx_text ltx_font_bold\">61.86</span></td>\n</tr>\n<tr id=\"A6.T6.1.14\" class=\"ltx_tr\">\n<td id=\"A6.T6.1.14.1\" class=\"ltx_td ltx_align_left\">12:</td>\n<td id=\"A6.T6.1.14.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip&amp;Noise¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T6.1.14.3\" class=\"ltx_td ltx_align_center ltx_border_r\">57.81</td>\n<td id=\"A6.T6.1.14.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T6.1.14.4.1\" class=\"ltx_text ltx_font_bold\">70.87</span></td>\n</tr>\n<tr id=\"A6.T6.1.15\" class=\"ltx_tr\">\n<td id=\"A6.T6.1.15.1\" class=\"ltx_td ltx_align_left\">13:</td>\n<td id=\"A6.T6.1.15.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Flame¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Nguyen et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib69\" title=\"\" class=\"ltx_ref\">2022c</a>)</cite>\n</td>\n<td id=\"A6.T6.1.15.3\" class=\"ltx_td ltx_align_center ltx_border_r\">60.08</td>\n<td id=\"A6.T6.1.15.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T6.1.15.4.1\" class=\"ltx_text ltx_font_bold\">91.34</span></td>\n</tr>\n<tr id=\"A6.T6.1.16\" class=\"ltx_tr\">\n<td id=\"A6.T6.1.16.1\" class=\"ltx_td ltx_align_left\">14:</td>\n<td id=\"A6.T6.1.16.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Mean¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T6.1.16.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.54</td>\n<td id=\"A6.T6.1.16.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T6.1.16.4.1\" class=\"ltx_text ltx_font_bold\">63.98</span></td>\n</tr>\n<tr id=\"A6.T6.1.17\" class=\"ltx_tr\">\n<td id=\"A6.T6.1.17.1\" class=\"ltx_td ltx_align_left\">15:</td>\n<td id=\"A6.T6.1.17.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Median¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T6.1.17.3\" class=\"ltx_td ltx_align_center ltx_border_r\">51.18</td>\n<td id=\"A6.T6.1.17.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T6.1.17.4.1\" class=\"ltx_text ltx_font_bold\">57.37</span></td>\n</tr>\n<tr id=\"A6.T6.1.18\" class=\"ltx_tr\">\n<td id=\"A6.T6.1.18.1\" class=\"ltx_td ltx_align_left\">16:</td>\n<td id=\"A6.T6.1.18.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FLTrust¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Cao et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib14\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>\n</td>\n<td id=\"A6.T6.1.18.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.13</td>\n<td id=\"A6.T6.1.18.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T6.1.18.4.1\" class=\"ltx_text ltx_font_bold\">23.25</span></td>\n</tr>\n<tr id=\"A6.T6.1.19\" class=\"ltx_tr\">\n<td id=\"A6.T6.1.19.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">17:</td>\n<td id=\"A6.T6.1.19.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"A6.T6.1.19.2.1\" class=\"ltx_text ltx_font_bold\">MESAS</span></td>\n<td id=\"A6.T6.1.19.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">63.36</td>\n<td id=\"A6.T6.1.19.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"A6.T6.1.19.4.1\" class=\"ltx_text ltx_font_bold\">1.95</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In this section, we provide further results for our experiments, that could not be included in the main part of the paper due to space limitations. We selected the most interesting and representative results to be part of the main part, but report the rest below for completeness.",
                "Tab.¬†",
                "4",
                " reports the MAs corresponding to the BAs and ACCs in ",
                "Tab.¬†",
                "2",
                " for different poisoning methods without adaptive adversaries. Note, that ",
                "MESAS",
                " provides high MA independent of the applied poisoning attack. The table shows, that ",
                "MESAS",
                " does not negatively impact the MA and is also effective against untargeted attacks.",
                "Tab.¬†",
                "5",
                " shows the results for our default scenario with scaled poisoned models regarding the Euclidean distance of updates. The results confirm, that scaling can increase the BA. ",
                "MESAS",
                " is already efficient for the unscaled version visualized in scenario  ",
                "1",
                " in ",
                "Tab.¬†",
                "1",
                ", hence is also effective for scaled models due to the intuition visualized in ",
                "Fig.¬†",
                "4",
                ". ",
                "Tab.¬†",
                "6",
                " depicts the results for the default scenario with a PDR of 0.3 for scaled poisoned models.",
                "We conducted an attack leveraging our strong adaptive adversary against FoolsGold¬†",
                "(Fung et¬†al",
                ".",
                ", ",
                "2020",
                ")",
                " and report the result in ",
                "Tab.¬†",
                "7",
                ". As strategy, we first trained a benign local model and transferred the trained parameters of the last layer to a fresh local model. We then excluded the parameters form training and poisoned the local model forcing the backdoor into some other layers. In ",
                "Tab.¬†",
                "8",
                " we additionally applied scaling. We can observe, that the BA of FoolsGold can be increased with those methods.",
                "Scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                " shows the result after adapting to Krum scores¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                " in an unscaled and scaled version. We forced the Euclidean distance between poisoned models and the global model to be similar to each other and on a benign level so that the defenses decide in favor of the poisoned models. ",
                "Fig.¬†",
                "12",
                " depicts the Krum scores for the default scenario associated with the default scenario in ",
                "Tab.¬†",
                "1",
                " to show, that the effective backdoor is based on coincidence and not intentionally forced by the attacker. With slight changes in some models, Krum could also decide for a benign model. However, after adaption, we can introduce a high BA intentionally in scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                ".",
                "Tab.¬†",
                "10",
                " and ",
                "Tab.¬†",
                "11",
                " show the results for a classical ",
                "intra-client",
                " ",
                "non-IID",
                " scenario crafted by ",
                "1-class",
                " ",
                "non-IID",
                " with ",
                "q",
                "=",
                "0.5",
                "ùëû",
                "0.5",
                "q=0.5",
                ". In both cases, ",
                "MESAS",
                " reduces the BA reliably with only one FP, while other defenses allow the attacker to embed 34.72% to 49.47% BA. ",
                "Tab.¬†",
                "12",
                " depicts the results for an increased PDR of 0.3, allowing the adversary to reach a BA of 57.68% without defense and up to 92.86% under active defenses. ",
                "MESAS",
                " still removes the poisoned models most effectively with only two FPs.",
                "In ",
                "Tab.¬†",
                "13",
                " and ",
                "Tab.¬†",
                "13",
                " we adapt all malicious models to a central benign value regarding the Cosine distance to the global model, which has the effect, that the models are inconspicuous in Krum scores, hence can circumvent Krum and ",
                "M-Krum",
                "¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                ", while ",
                "MESAS",
                " still erases the backdoor with only two FPs.",
                "Tab.¬†",
                "15",
                " and ",
                "Tab.¬†",
                "16",
                " show the results in a ",
                "inter-client",
                " ",
                "non-IID",
                " scenario based on our ",
                "Random-Non-IID",
                " strategy for a model in FL round one and highlights, that ",
                "MESAS",
                " outperforms other defenses in reducing the BA of the new global model.\n",
                "Tab.¬†",
                "17",
                " and ",
                "Tab.¬†",
                "18",
                " show the results for a setting in round 50,w here 100 clients are part of the federation and 20 clients are selected randomly in each round for training. Due to the later rounds, ",
                "MESAS",
                " is even more effective than other defenses and reduces the BA to a minimum.",
                "Tab.¬†",
                "19",
                " and ",
                "Tab.¬†",
                "20",
                " show the experiments results with a CNN training on MNIST¬†",
                "(Deng, ",
                "2012",
                ")",
                " and SqueezeNet¬†",
                "(Iandola et¬†al",
                ".",
                ", ",
                "2016",
                ")",
                " training on ",
                "CIFAR-10",
                " ",
                "(Krizhevsky et¬†al",
                ".",
                ", ",
                "2009",
                ")",
                ". The CNN consists of two convolutional layers, the first with 32 output layers, the second with 64 output layers, both applying a kernel size of 5. The output of the convolutional layers traverse a ReLU¬†",
                "(Agarap, ",
                "2018",
                ")",
                " and a 2D pooling layer, before being fed into three fully connected layers with output size 512, 256 and 10 output respectively. In both experiments, we used a ",
                "self-pre-trained",
                " model as global model. We can report perfect detection rate with just one FP for CNN and SqueezeNet, even if the backdoor is not yet embedded in the global model. Hence, a stronger adaption by the adversary would strengthen the detection capabilities of ",
                "MESAS",
                ". Other defenses instead can be circumvented by the adaptive adversary."
            ]
        ]
    },
    "A6.T7": {
        "caption": "Table 7. MA and BA in the default scenario with fixation of the last layer to benign trained parameters in percent.",
        "table": "<table id=\"A6.T7.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A6.T7.1.2\" class=\"ltx_tr\">\n<td id=\"A6.T7.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\">Accuracies without defenses</td>\n<td id=\"A6.T7.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">MA</td>\n<td id=\"A6.T7.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T7.1.1\" class=\"ltx_tr\">\n<td id=\"A6.T7.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">1:</td>\n<td id=\"A6.T7.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Global model <math id=\"A6.T7.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"G^{r}\" display=\"inline\"><semantics id=\"A6.T7.1.1.1.m1.1a\"><msup id=\"A6.T7.1.1.1.m1.1.1\" xref=\"A6.T7.1.1.1.m1.1.1.cmml\"><mi id=\"A6.T7.1.1.1.m1.1.1.2\" xref=\"A6.T7.1.1.1.m1.1.1.2.cmml\">G</mi><mi id=\"A6.T7.1.1.1.m1.1.1.3\" xref=\"A6.T7.1.1.1.m1.1.1.3.cmml\">r</mi></msup><annotation-xml encoding=\"MathML-Content\" id=\"A6.T7.1.1.1.m1.1b\"><apply id=\"A6.T7.1.1.1.m1.1.1.cmml\" xref=\"A6.T7.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"A6.T7.1.1.1.m1.1.1.1.cmml\" xref=\"A6.T7.1.1.1.m1.1.1\">superscript</csymbol><ci id=\"A6.T7.1.1.1.m1.1.1.2.cmml\" xref=\"A6.T7.1.1.1.m1.1.1.2\">ùê∫</ci><ci id=\"A6.T7.1.1.1.m1.1.1.3.cmml\" xref=\"A6.T7.1.1.1.m1.1.1.3\">ùëü</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T7.1.1.1.m1.1c\">G^{r}</annotation></semantics></math>\n</td>\n<td id=\"A6.T7.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">62.99</td>\n<td id=\"A6.T7.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">1.90</td>\n</tr>\n<tr id=\"A6.T7.1.3\" class=\"ltx_tr\">\n<td id=\"A6.T7.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">2:</td>\n<td id=\"A6.T7.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Average of benign local models</td>\n<td id=\"A6.T7.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">57.58</td>\n<td id=\"A6.T7.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">4.56</td>\n</tr>\n<tr id=\"A6.T7.1.4\" class=\"ltx_tr\">\n<td id=\"A6.T7.1.4.1\" class=\"ltx_td ltx_align_left\">3:</td>\n<td id=\"A6.T7.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Average of poisoned local models</td>\n<td id=\"A6.T7.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">58.20</td>\n<td id=\"A6.T7.1.4.4\" class=\"ltx_td ltx_align_center\">84.90</td>\n</tr>\n<tr id=\"A6.T7.1.5\" class=\"ltx_tr\">\n<td id=\"A6.T7.1.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\">4:</td>\n<td id=\"A6.T7.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T7.1.5.2.1\" class=\"ltx_text\">FedAVG</span> with benign local models</td>\n<td id=\"A6.T7.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.57</td>\n<td id=\"A6.T7.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">1.85</td>\n</tr>\n<tr id=\"A6.T7.1.6\" class=\"ltx_tr\">\n<td id=\"A6.T7.1.6.1\" class=\"ltx_td ltx_align_left\">5:</td>\n<td id=\"A6.T7.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T7.1.6.2.1\" class=\"ltx_text\">FedAVG</span> with poisoned local models</td>\n<td id=\"A6.T7.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">64.29</td>\n<td id=\"A6.T7.1.6.4\" class=\"ltx_td ltx_align_center\">83.96</td>\n</tr>\n<tr id=\"A6.T7.1.7\" class=\"ltx_tr\">\n<td id=\"A6.T7.1.7.1\" class=\"ltx_td ltx_align_left ltx_border_t\">6:</td>\n<td id=\"A6.T7.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T7.1.7.2.1\" class=\"ltx_text\">FedAVG</span> with all local models</td>\n<td id=\"A6.T7.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.74</td>\n<td id=\"A6.T7.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A6.T7.1.7.4.1\" class=\"ltx_text ltx_font_bold\">42.22</span></td>\n</tr>\n<tr id=\"A6.T7.1.8\" class=\"ltx_tr\">\n<td id=\"A6.T7.1.8.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\" colspan=\"2\">Global model accuracies after applying defenses</td>\n<td id=\"A6.T7.1.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\">MA</td>\n<td id=\"A6.T7.1.8.3\" class=\"ltx_td ltx_align_center ltx_border_tt ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T7.1.9\" class=\"ltx_tr\">\n<td id=\"A6.T7.1.9.1\" class=\"ltx_td ltx_align_left ltx_border_t\">7:</td>\n<td id=\"A6.T7.1.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Na√Øve Clustering</td>\n<td id=\"A6.T7.1.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.68</td>\n<td id=\"A6.T7.1.9.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A6.T7.1.9.4.1\" class=\"ltx_text ltx_font_bold\">45.95</span></td>\n</tr>\n<tr id=\"A6.T7.1.10\" class=\"ltx_tr\">\n<td id=\"A6.T7.1.10.1\" class=\"ltx_td ltx_align_left\">8:</td>\n<td id=\"A6.T7.1.10.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FoolsGold¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Fung et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>\n</td>\n<td id=\"A6.T7.1.10.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.74</td>\n<td id=\"A6.T7.1.10.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T7.1.10.4.1\" class=\"ltx_text ltx_font_bold\">42.22</span></td>\n</tr>\n<tr id=\"A6.T7.1.11\" class=\"ltx_tr\">\n<td id=\"A6.T7.1.11.1\" class=\"ltx_td ltx_align_left\">9:</td>\n<td id=\"A6.T7.1.11.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Krum¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T7.1.11.3\" class=\"ltx_td ltx_align_center ltx_border_r\">59.69</td>\n<td id=\"A6.T7.1.11.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T7.1.11.4.1\" class=\"ltx_text ltx_font_bold\">83.21</span></td>\n</tr>\n<tr id=\"A6.T7.1.12\" class=\"ltx_tr\">\n<td id=\"A6.T7.1.12.1\" class=\"ltx_td ltx_align_left\">10:</td>\n<td id=\"A6.T7.1.12.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T7.1.12.2.1\" class=\"ltx_text\">M-Krum</span>¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T7.1.12.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.90</td>\n<td id=\"A6.T7.1.12.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T7.1.12.4.1\" class=\"ltx_text ltx_font_bold\">92.72</span></td>\n</tr>\n<tr id=\"A6.T7.1.13\" class=\"ltx_tr\">\n<td id=\"A6.T7.1.13.1\" class=\"ltx_td ltx_align_left\">11:</td>\n<td id=\"A6.T7.1.13.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T7.1.13.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.81</td>\n<td id=\"A6.T7.1.13.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T7.1.13.4.1\" class=\"ltx_text ltx_font_bold\">42.23</span></td>\n</tr>\n<tr id=\"A6.T7.1.14\" class=\"ltx_tr\">\n<td id=\"A6.T7.1.14.1\" class=\"ltx_td ltx_align_left\">12:</td>\n<td id=\"A6.T7.1.14.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip&amp;Noise¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T7.1.14.3\" class=\"ltx_td ltx_align_center ltx_border_r\">52.58</td>\n<td id=\"A6.T7.1.14.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T7.1.14.4.1\" class=\"ltx_text ltx_font_bold\">62.80</span></td>\n</tr>\n<tr id=\"A6.T7.1.15\" class=\"ltx_tr\">\n<td id=\"A6.T7.1.15.1\" class=\"ltx_td ltx_align_left\">13:</td>\n<td id=\"A6.T7.1.15.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Flame¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Nguyen et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib69\" title=\"\" class=\"ltx_ref\">2022c</a>)</cite>\n</td>\n<td id=\"A6.T7.1.15.3\" class=\"ltx_td ltx_align_center ltx_border_r\">60.80</td>\n<td id=\"A6.T7.1.15.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T7.1.15.4.1\" class=\"ltx_text ltx_font_bold\">76.58</span></td>\n</tr>\n<tr id=\"A6.T7.1.16\" class=\"ltx_tr\">\n<td id=\"A6.T7.1.16.1\" class=\"ltx_td ltx_align_left\">14:</td>\n<td id=\"A6.T7.1.16.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Mean¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T7.1.16.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.43</td>\n<td id=\"A6.T7.1.16.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T7.1.16.4.1\" class=\"ltx_text ltx_font_bold\">43.50</span></td>\n</tr>\n<tr id=\"A6.T7.1.17\" class=\"ltx_tr\">\n<td id=\"A6.T7.1.17.1\" class=\"ltx_td ltx_align_left\">15:</td>\n<td id=\"A6.T7.1.17.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Median¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T7.1.17.3\" class=\"ltx_td ltx_align_center ltx_border_r\">51.94</td>\n<td id=\"A6.T7.1.17.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T7.1.17.4.1\" class=\"ltx_text ltx_font_bold\">36.75</span></td>\n</tr>\n<tr id=\"A6.T7.1.18\" class=\"ltx_tr\">\n<td id=\"A6.T7.1.18.1\" class=\"ltx_td ltx_align_left\">16:</td>\n<td id=\"A6.T7.1.18.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FLTrust¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Cao et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib14\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>\n</td>\n<td id=\"A6.T7.1.18.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.66</td>\n<td id=\"A6.T7.1.18.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T7.1.18.4.1\" class=\"ltx_text ltx_font_bold\">20.14</span></td>\n</tr>\n<tr id=\"A6.T7.1.19\" class=\"ltx_tr\">\n<td id=\"A6.T7.1.19.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">17:</td>\n<td id=\"A6.T7.1.19.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"A6.T7.1.19.2.1\" class=\"ltx_text ltx_font_bold\">MESAS</span></td>\n<td id=\"A6.T7.1.19.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">63.57</td>\n<td id=\"A6.T7.1.19.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"A6.T7.1.19.4.1\" class=\"ltx_text ltx_font_bold\">1.85</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In this section, we provide further results for our experiments, that could not be included in the main part of the paper due to space limitations. We selected the most interesting and representative results to be part of the main part, but report the rest below for completeness.",
                "Tab.¬†",
                "4",
                " reports the MAs corresponding to the BAs and ACCs in ",
                "Tab.¬†",
                "2",
                " for different poisoning methods without adaptive adversaries. Note, that ",
                "MESAS",
                " provides high MA independent of the applied poisoning attack. The table shows, that ",
                "MESAS",
                " does not negatively impact the MA and is also effective against untargeted attacks.",
                "Tab.¬†",
                "5",
                " shows the results for our default scenario with scaled poisoned models regarding the Euclidean distance of updates. The results confirm, that scaling can increase the BA. ",
                "MESAS",
                " is already efficient for the unscaled version visualized in scenario  ",
                "1",
                " in ",
                "Tab.¬†",
                "1",
                ", hence is also effective for scaled models due to the intuition visualized in ",
                "Fig.¬†",
                "4",
                ". ",
                "Tab.¬†",
                "6",
                " depicts the results for the default scenario with a PDR of 0.3 for scaled poisoned models.",
                "We conducted an attack leveraging our strong adaptive adversary against FoolsGold¬†",
                "(Fung et¬†al",
                ".",
                ", ",
                "2020",
                ")",
                " and report the result in ",
                "Tab.¬†",
                "7",
                ". As strategy, we first trained a benign local model and transferred the trained parameters of the last layer to a fresh local model. We then excluded the parameters form training and poisoned the local model forcing the backdoor into some other layers. In ",
                "Tab.¬†",
                "8",
                " we additionally applied scaling. We can observe, that the BA of FoolsGold can be increased with those methods.",
                "Scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                " shows the result after adapting to Krum scores¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                " in an unscaled and scaled version. We forced the Euclidean distance between poisoned models and the global model to be similar to each other and on a benign level so that the defenses decide in favor of the poisoned models. ",
                "Fig.¬†",
                "12",
                " depicts the Krum scores for the default scenario associated with the default scenario in ",
                "Tab.¬†",
                "1",
                " to show, that the effective backdoor is based on coincidence and not intentionally forced by the attacker. With slight changes in some models, Krum could also decide for a benign model. However, after adaption, we can introduce a high BA intentionally in scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                ".",
                "Tab.¬†",
                "10",
                " and ",
                "Tab.¬†",
                "11",
                " show the results for a classical ",
                "intra-client",
                " ",
                "non-IID",
                " scenario crafted by ",
                "1-class",
                " ",
                "non-IID",
                " with ",
                "q",
                "=",
                "0.5",
                "ùëû",
                "0.5",
                "q=0.5",
                ". In both cases, ",
                "MESAS",
                " reduces the BA reliably with only one FP, while other defenses allow the attacker to embed 34.72% to 49.47% BA. ",
                "Tab.¬†",
                "12",
                " depicts the results for an increased PDR of 0.3, allowing the adversary to reach a BA of 57.68% without defense and up to 92.86% under active defenses. ",
                "MESAS",
                " still removes the poisoned models most effectively with only two FPs.",
                "In ",
                "Tab.¬†",
                "13",
                " and ",
                "Tab.¬†",
                "13",
                " we adapt all malicious models to a central benign value regarding the Cosine distance to the global model, which has the effect, that the models are inconspicuous in Krum scores, hence can circumvent Krum and ",
                "M-Krum",
                "¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                ", while ",
                "MESAS",
                " still erases the backdoor with only two FPs.",
                "Tab.¬†",
                "15",
                " and ",
                "Tab.¬†",
                "16",
                " show the results in a ",
                "inter-client",
                " ",
                "non-IID",
                " scenario based on our ",
                "Random-Non-IID",
                " strategy for a model in FL round one and highlights, that ",
                "MESAS",
                " outperforms other defenses in reducing the BA of the new global model.\n",
                "Tab.¬†",
                "17",
                " and ",
                "Tab.¬†",
                "18",
                " show the results for a setting in round 50,w here 100 clients are part of the federation and 20 clients are selected randomly in each round for training. Due to the later rounds, ",
                "MESAS",
                " is even more effective than other defenses and reduces the BA to a minimum.",
                "Tab.¬†",
                "19",
                " and ",
                "Tab.¬†",
                "20",
                " show the experiments results with a CNN training on MNIST¬†",
                "(Deng, ",
                "2012",
                ")",
                " and SqueezeNet¬†",
                "(Iandola et¬†al",
                ".",
                ", ",
                "2016",
                ")",
                " training on ",
                "CIFAR-10",
                " ",
                "(Krizhevsky et¬†al",
                ".",
                ", ",
                "2009",
                ")",
                ". The CNN consists of two convolutional layers, the first with 32 output layers, the second with 64 output layers, both applying a kernel size of 5. The output of the convolutional layers traverse a ReLU¬†",
                "(Agarap, ",
                "2018",
                ")",
                " and a 2D pooling layer, before being fed into three fully connected layers with output size 512, 256 and 10 output respectively. In both experiments, we used a ",
                "self-pre-trained",
                " model as global model. We can report perfect detection rate with just one FP for CNN and SqueezeNet, even if the backdoor is not yet embedded in the global model. Hence, a stronger adaption by the adversary would strengthen the detection capabilities of ",
                "MESAS",
                ". Other defenses instead can be circumvented by the adaptive adversary."
            ]
        ]
    },
    "A6.T8": {
        "caption": "Table 8. MA and BA in the default scenario with fixation of the last layer to benign trained parameters and scaled poisoned models regarding the Euclidean distance of updates in percent.",
        "table": "<table id=\"A6.T8.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A6.T8.1.2\" class=\"ltx_tr\">\n<td id=\"A6.T8.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\">Accuracies without defenses</td>\n<td id=\"A6.T8.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">MA</td>\n<td id=\"A6.T8.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T8.1.1\" class=\"ltx_tr\">\n<td id=\"A6.T8.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">1:</td>\n<td id=\"A6.T8.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Global model <math id=\"A6.T8.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"G^{r}\" display=\"inline\"><semantics id=\"A6.T8.1.1.1.m1.1a\"><msup id=\"A6.T8.1.1.1.m1.1.1\" xref=\"A6.T8.1.1.1.m1.1.1.cmml\"><mi id=\"A6.T8.1.1.1.m1.1.1.2\" xref=\"A6.T8.1.1.1.m1.1.1.2.cmml\">G</mi><mi id=\"A6.T8.1.1.1.m1.1.1.3\" xref=\"A6.T8.1.1.1.m1.1.1.3.cmml\">r</mi></msup><annotation-xml encoding=\"MathML-Content\" id=\"A6.T8.1.1.1.m1.1b\"><apply id=\"A6.T8.1.1.1.m1.1.1.cmml\" xref=\"A6.T8.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"A6.T8.1.1.1.m1.1.1.1.cmml\" xref=\"A6.T8.1.1.1.m1.1.1\">superscript</csymbol><ci id=\"A6.T8.1.1.1.m1.1.1.2.cmml\" xref=\"A6.T8.1.1.1.m1.1.1.2\">ùê∫</ci><ci id=\"A6.T8.1.1.1.m1.1.1.3.cmml\" xref=\"A6.T8.1.1.1.m1.1.1.3\">ùëü</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T8.1.1.1.m1.1c\">G^{r}</annotation></semantics></math>\n</td>\n<td id=\"A6.T8.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">62.99</td>\n<td id=\"A6.T8.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">1.90</td>\n</tr>\n<tr id=\"A6.T8.1.3\" class=\"ltx_tr\">\n<td id=\"A6.T8.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">2:</td>\n<td id=\"A6.T8.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Average of benign local models</td>\n<td id=\"A6.T8.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">57.58</td>\n<td id=\"A6.T8.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">4.56</td>\n</tr>\n<tr id=\"A6.T8.1.4\" class=\"ltx_tr\">\n<td id=\"A6.T8.1.4.1\" class=\"ltx_td ltx_align_left\">3:</td>\n<td id=\"A6.T8.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Average of poisoned local models</td>\n<td id=\"A6.T8.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">58.20</td>\n<td id=\"A6.T8.1.4.4\" class=\"ltx_td ltx_align_center\">84.90</td>\n</tr>\n<tr id=\"A6.T8.1.5\" class=\"ltx_tr\">\n<td id=\"A6.T8.1.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\">4:</td>\n<td id=\"A6.T8.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T8.1.5.2.1\" class=\"ltx_text\">FedAVG</span> with benign local models</td>\n<td id=\"A6.T8.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.57</td>\n<td id=\"A6.T8.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">1.85</td>\n</tr>\n<tr id=\"A6.T8.1.6\" class=\"ltx_tr\">\n<td id=\"A6.T8.1.6.1\" class=\"ltx_td ltx_align_left\">5:</td>\n<td id=\"A6.T8.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T8.1.6.2.1\" class=\"ltx_text\">FedAVG</span> with poisoned local models</td>\n<td id=\"A6.T8.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.96</td>\n<td id=\"A6.T8.1.6.4\" class=\"ltx_td ltx_align_center\">87.35</td>\n</tr>\n<tr id=\"A6.T8.1.7\" class=\"ltx_tr\">\n<td id=\"A6.T8.1.7.1\" class=\"ltx_td ltx_align_left ltx_border_t\">6:</td>\n<td id=\"A6.T8.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T8.1.7.2.1\" class=\"ltx_text\">FedAVG</span> with all local models</td>\n<td id=\"A6.T8.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.66</td>\n<td id=\"A6.T8.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A6.T8.1.7.4.1\" class=\"ltx_text ltx_font_bold\">50.44</span></td>\n</tr>\n<tr id=\"A6.T8.1.8\" class=\"ltx_tr\">\n<td id=\"A6.T8.1.8.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\" colspan=\"2\">Global model accuracies after applying defenses</td>\n<td id=\"A6.T8.1.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\">MA</td>\n<td id=\"A6.T8.1.8.3\" class=\"ltx_td ltx_align_center ltx_border_tt ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T8.1.9\" class=\"ltx_tr\">\n<td id=\"A6.T8.1.9.1\" class=\"ltx_td ltx_align_left ltx_border_t\">7:</td>\n<td id=\"A6.T8.1.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Na√Øve Clustering</td>\n<td id=\"A6.T8.1.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.29</td>\n<td id=\"A6.T8.1.9.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A6.T8.1.9.4.1\" class=\"ltx_text ltx_font_bold\">56.94</span></td>\n</tr>\n<tr id=\"A6.T8.1.10\" class=\"ltx_tr\">\n<td id=\"A6.T8.1.10.1\" class=\"ltx_td ltx_align_left\">8:</td>\n<td id=\"A6.T8.1.10.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FoolsGold¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Fung et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>\n</td>\n<td id=\"A6.T8.1.10.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.61</td>\n<td id=\"A6.T8.1.10.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T8.1.10.4.1\" class=\"ltx_text ltx_font_bold\">50.44</span></td>\n</tr>\n<tr id=\"A6.T8.1.11\" class=\"ltx_tr\">\n<td id=\"A6.T8.1.11.1\" class=\"ltx_td ltx_align_left\">9:</td>\n<td id=\"A6.T8.1.11.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Krum¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T8.1.11.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"A6.T8.1.11.3.1\" class=\"ltx_text ltx_font_bold\">58.38</span></td>\n<td id=\"A6.T8.1.11.4\" class=\"ltx_td ltx_align_center\">3.98</td>\n</tr>\n<tr id=\"A6.T8.1.12\" class=\"ltx_tr\">\n<td id=\"A6.T8.1.12.1\" class=\"ltx_td ltx_align_left\">10:</td>\n<td id=\"A6.T8.1.12.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T8.1.12.2.1\" class=\"ltx_text\">M-Krum</span>¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T8.1.12.3\" class=\"ltx_td ltx_align_center ltx_border_r\">64.26</td>\n<td id=\"A6.T8.1.12.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T8.1.12.4.1\" class=\"ltx_text ltx_font_bold\">53.96</span></td>\n</tr>\n<tr id=\"A6.T8.1.13\" class=\"ltx_tr\">\n<td id=\"A6.T8.1.13.1\" class=\"ltx_td ltx_align_left\">11:</td>\n<td id=\"A6.T8.1.13.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T8.1.13.3\" class=\"ltx_td ltx_align_center ltx_border_r\">53.30</td>\n<td id=\"A6.T8.1.13.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T8.1.13.4.1\" class=\"ltx_text ltx_font_bold\">58.45</span></td>\n</tr>\n<tr id=\"A6.T8.1.14\" class=\"ltx_tr\">\n<td id=\"A6.T8.1.14.1\" class=\"ltx_td ltx_align_left\">12:</td>\n<td id=\"A6.T8.1.14.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip&amp;Noise¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T8.1.14.3\" class=\"ltx_td ltx_align_center ltx_border_r\">57.63</td>\n<td id=\"A6.T8.1.14.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T8.1.14.4.1\" class=\"ltx_text ltx_font_bold\">60.66</span></td>\n</tr>\n<tr id=\"A6.T8.1.15\" class=\"ltx_tr\">\n<td id=\"A6.T8.1.15.1\" class=\"ltx_td ltx_align_left\">13:</td>\n<td id=\"A6.T8.1.15.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Flame¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Nguyen et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib69\" title=\"\" class=\"ltx_ref\">2022c</a>)</cite>\n</td>\n<td id=\"A6.T8.1.15.3\" class=\"ltx_td ltx_align_center ltx_border_r\">62.67</td>\n<td id=\"A6.T8.1.15.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T8.1.15.4.1\" class=\"ltx_text ltx_font_bold\">71.26</span></td>\n</tr>\n<tr id=\"A6.T8.1.16\" class=\"ltx_tr\">\n<td id=\"A6.T8.1.16.1\" class=\"ltx_td ltx_align_left\">14:</td>\n<td id=\"A6.T8.1.16.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Mean¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T8.1.16.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.27</td>\n<td id=\"A6.T8.1.16.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T8.1.16.4.1\" class=\"ltx_text ltx_font_bold\">50.56</span></td>\n</tr>\n<tr id=\"A6.T8.1.17\" class=\"ltx_tr\">\n<td id=\"A6.T8.1.17.1\" class=\"ltx_td ltx_align_left\">15:</td>\n<td id=\"A6.T8.1.17.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Median¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T8.1.17.3\" class=\"ltx_td ltx_align_center ltx_border_r\">51.76</td>\n<td id=\"A6.T8.1.17.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T8.1.17.4.1\" class=\"ltx_text ltx_font_bold\">39.64</span></td>\n</tr>\n<tr id=\"A6.T8.1.18\" class=\"ltx_tr\">\n<td id=\"A6.T8.1.18.1\" class=\"ltx_td ltx_align_left\">16:</td>\n<td id=\"A6.T8.1.18.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FLTrust¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Cao et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib14\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>\n</td>\n<td id=\"A6.T8.1.18.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.45</td>\n<td id=\"A6.T8.1.18.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T8.1.18.4.1\" class=\"ltx_text ltx_font_bold\">20.37</span></td>\n</tr>\n<tr id=\"A6.T8.1.19\" class=\"ltx_tr\">\n<td id=\"A6.T8.1.19.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">17:</td>\n<td id=\"A6.T8.1.19.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"A6.T8.1.19.2.1\" class=\"ltx_text ltx_font_bold\">MESAS</span></td>\n<td id=\"A6.T8.1.19.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">63.36</td>\n<td id=\"A6.T8.1.19.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"A6.T8.1.19.4.1\" class=\"ltx_text ltx_font_bold\">1.95</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In this section, we provide further results for our experiments, that could not be included in the main part of the paper due to space limitations. We selected the most interesting and representative results to be part of the main part, but report the rest below for completeness.",
                "Tab.¬†",
                "4",
                " reports the MAs corresponding to the BAs and ACCs in ",
                "Tab.¬†",
                "2",
                " for different poisoning methods without adaptive adversaries. Note, that ",
                "MESAS",
                " provides high MA independent of the applied poisoning attack. The table shows, that ",
                "MESAS",
                " does not negatively impact the MA and is also effective against untargeted attacks.",
                "Tab.¬†",
                "5",
                " shows the results for our default scenario with scaled poisoned models regarding the Euclidean distance of updates. The results confirm, that scaling can increase the BA. ",
                "MESAS",
                " is already efficient for the unscaled version visualized in scenario  ",
                "1",
                " in ",
                "Tab.¬†",
                "1",
                ", hence is also effective for scaled models due to the intuition visualized in ",
                "Fig.¬†",
                "4",
                ". ",
                "Tab.¬†",
                "6",
                " depicts the results for the default scenario with a PDR of 0.3 for scaled poisoned models.",
                "We conducted an attack leveraging our strong adaptive adversary against FoolsGold¬†",
                "(Fung et¬†al",
                ".",
                ", ",
                "2020",
                ")",
                " and report the result in ",
                "Tab.¬†",
                "7",
                ". As strategy, we first trained a benign local model and transferred the trained parameters of the last layer to a fresh local model. We then excluded the parameters form training and poisoned the local model forcing the backdoor into some other layers. In ",
                "Tab.¬†",
                "8",
                " we additionally applied scaling. We can observe, that the BA of FoolsGold can be increased with those methods.",
                "Scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                " shows the result after adapting to Krum scores¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                " in an unscaled and scaled version. We forced the Euclidean distance between poisoned models and the global model to be similar to each other and on a benign level so that the defenses decide in favor of the poisoned models. ",
                "Fig.¬†",
                "12",
                " depicts the Krum scores for the default scenario associated with the default scenario in ",
                "Tab.¬†",
                "1",
                " to show, that the effective backdoor is based on coincidence and not intentionally forced by the attacker. With slight changes in some models, Krum could also decide for a benign model. However, after adaption, we can introduce a high BA intentionally in scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                ".",
                "Tab.¬†",
                "10",
                " and ",
                "Tab.¬†",
                "11",
                " show the results for a classical ",
                "intra-client",
                " ",
                "non-IID",
                " scenario crafted by ",
                "1-class",
                " ",
                "non-IID",
                " with ",
                "q",
                "=",
                "0.5",
                "ùëû",
                "0.5",
                "q=0.5",
                ". In both cases, ",
                "MESAS",
                " reduces the BA reliably with only one FP, while other defenses allow the attacker to embed 34.72% to 49.47% BA. ",
                "Tab.¬†",
                "12",
                " depicts the results for an increased PDR of 0.3, allowing the adversary to reach a BA of 57.68% without defense and up to 92.86% under active defenses. ",
                "MESAS",
                " still removes the poisoned models most effectively with only two FPs.",
                "In ",
                "Tab.¬†",
                "13",
                " and ",
                "Tab.¬†",
                "13",
                " we adapt all malicious models to a central benign value regarding the Cosine distance to the global model, which has the effect, that the models are inconspicuous in Krum scores, hence can circumvent Krum and ",
                "M-Krum",
                "¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                ", while ",
                "MESAS",
                " still erases the backdoor with only two FPs.",
                "Tab.¬†",
                "15",
                " and ",
                "Tab.¬†",
                "16",
                " show the results in a ",
                "inter-client",
                " ",
                "non-IID",
                " scenario based on our ",
                "Random-Non-IID",
                " strategy for a model in FL round one and highlights, that ",
                "MESAS",
                " outperforms other defenses in reducing the BA of the new global model.\n",
                "Tab.¬†",
                "17",
                " and ",
                "Tab.¬†",
                "18",
                " show the results for a setting in round 50,w here 100 clients are part of the federation and 20 clients are selected randomly in each round for training. Due to the later rounds, ",
                "MESAS",
                " is even more effective than other defenses and reduces the BA to a minimum.",
                "Tab.¬†",
                "19",
                " and ",
                "Tab.¬†",
                "20",
                " show the experiments results with a CNN training on MNIST¬†",
                "(Deng, ",
                "2012",
                ")",
                " and SqueezeNet¬†",
                "(Iandola et¬†al",
                ".",
                ", ",
                "2016",
                ")",
                " training on ",
                "CIFAR-10",
                " ",
                "(Krizhevsky et¬†al",
                ".",
                ", ",
                "2009",
                ")",
                ". The CNN consists of two convolutional layers, the first with 32 output layers, the second with 64 output layers, both applying a kernel size of 5. The output of the convolutional layers traverse a ReLU¬†",
                "(Agarap, ",
                "2018",
                ")",
                " and a 2D pooling layer, before being fed into three fully connected layers with output size 512, 256 and 10 output respectively. In both experiments, we used a ",
                "self-pre-trained",
                " model as global model. We can report perfect detection rate with just one FP for CNN and SqueezeNet, even if the backdoor is not yet embedded in the global model. Hence, a stronger adaption by the adversary would strengthen the detection capabilities of ",
                "MESAS",
                ". Other defenses instead can be circumvented by the adaptive adversary."
            ]
        ]
    },
    "A6.T9": {
        "caption": "Table 9. MA and BA in the default scenario with adaption of the Euclidean distance between local models and the global model to benign values and scaled poisoned models regarding the Euclidean distance of updates in percent.",
        "table": "<table id=\"A6.T9.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A6.T9.1.2\" class=\"ltx_tr\">\n<td id=\"A6.T9.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\">Accuracies without defenses</td>\n<td id=\"A6.T9.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">MA</td>\n<td id=\"A6.T9.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T9.1.1\" class=\"ltx_tr\">\n<td id=\"A6.T9.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">1:</td>\n<td id=\"A6.T9.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Global model <math id=\"A6.T9.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"G^{r}\" display=\"inline\"><semantics id=\"A6.T9.1.1.1.m1.1a\"><msup id=\"A6.T9.1.1.1.m1.1.1\" xref=\"A6.T9.1.1.1.m1.1.1.cmml\"><mi id=\"A6.T9.1.1.1.m1.1.1.2\" xref=\"A6.T9.1.1.1.m1.1.1.2.cmml\">G</mi><mi id=\"A6.T9.1.1.1.m1.1.1.3\" xref=\"A6.T9.1.1.1.m1.1.1.3.cmml\">r</mi></msup><annotation-xml encoding=\"MathML-Content\" id=\"A6.T9.1.1.1.m1.1b\"><apply id=\"A6.T9.1.1.1.m1.1.1.cmml\" xref=\"A6.T9.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"A6.T9.1.1.1.m1.1.1.1.cmml\" xref=\"A6.T9.1.1.1.m1.1.1\">superscript</csymbol><ci id=\"A6.T9.1.1.1.m1.1.1.2.cmml\" xref=\"A6.T9.1.1.1.m1.1.1.2\">ùê∫</ci><ci id=\"A6.T9.1.1.1.m1.1.1.3.cmml\" xref=\"A6.T9.1.1.1.m1.1.1.3\">ùëü</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T9.1.1.1.m1.1c\">G^{r}</annotation></semantics></math>\n</td>\n<td id=\"A6.T9.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">62.99</td>\n<td id=\"A6.T9.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">1.90</td>\n</tr>\n<tr id=\"A6.T9.1.3\" class=\"ltx_tr\">\n<td id=\"A6.T9.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">2:</td>\n<td id=\"A6.T9.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Average of benign local models</td>\n<td id=\"A6.T9.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">57.58</td>\n<td id=\"A6.T9.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">4.56</td>\n</tr>\n<tr id=\"A6.T9.1.4\" class=\"ltx_tr\">\n<td id=\"A6.T9.1.4.1\" class=\"ltx_td ltx_align_left\">3:</td>\n<td id=\"A6.T9.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Average of poisoned local models</td>\n<td id=\"A6.T9.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">51.23</td>\n<td id=\"A6.T9.1.4.4\" class=\"ltx_td ltx_align_center\">89.82</td>\n</tr>\n<tr id=\"A6.T9.1.5\" class=\"ltx_tr\">\n<td id=\"A6.T9.1.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\">4:</td>\n<td id=\"A6.T9.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T9.1.5.2.1\" class=\"ltx_text\">FedAVG</span> with benign local models</td>\n<td id=\"A6.T9.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.57</td>\n<td id=\"A6.T9.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">1.85</td>\n</tr>\n<tr id=\"A6.T9.1.6\" class=\"ltx_tr\">\n<td id=\"A6.T9.1.6.1\" class=\"ltx_td ltx_align_left\">5:</td>\n<td id=\"A6.T9.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T9.1.6.2.1\" class=\"ltx_text\">FedAVG</span> with poisoned local models</td>\n<td id=\"A6.T9.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">40.23</td>\n<td id=\"A6.T9.1.6.4\" class=\"ltx_td ltx_align_center\">93.54</td>\n</tr>\n<tr id=\"A6.T9.1.7\" class=\"ltx_tr\">\n<td id=\"A6.T9.1.7.1\" class=\"ltx_td ltx_align_left ltx_border_t\">6:</td>\n<td id=\"A6.T9.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T9.1.7.2.1\" class=\"ltx_text\">FedAVG</span> with all local models</td>\n<td id=\"A6.T9.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">48.90</td>\n<td id=\"A6.T9.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A6.T9.1.7.4.1\" class=\"ltx_text ltx_font_bold\">83.93</span></td>\n</tr>\n<tr id=\"A6.T9.1.8\" class=\"ltx_tr\">\n<td id=\"A6.T9.1.8.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\" colspan=\"2\">Global model accuracies after applying defenses</td>\n<td id=\"A6.T9.1.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\">MA</td>\n<td id=\"A6.T9.1.8.3\" class=\"ltx_td ltx_align_center ltx_border_tt ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T9.1.9\" class=\"ltx_tr\">\n<td id=\"A6.T9.1.9.1\" class=\"ltx_td ltx_align_left ltx_border_t\">7:</td>\n<td id=\"A6.T9.1.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Na√Øve Clustering</td>\n<td id=\"A6.T9.1.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">46.98</td>\n<td id=\"A6.T9.1.9.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A6.T9.1.9.4.1\" class=\"ltx_text ltx_font_bold\">85.76</span></td>\n</tr>\n<tr id=\"A6.T9.1.10\" class=\"ltx_tr\">\n<td id=\"A6.T9.1.10.1\" class=\"ltx_td ltx_align_left\">8:</td>\n<td id=\"A6.T9.1.10.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FoolsGold¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Fung et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>\n</td>\n<td id=\"A6.T9.1.10.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.57</td>\n<td id=\"A6.T9.1.10.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T9.1.10.4.1\" class=\"ltx_text ltx_font_bold\">1.85</span></td>\n</tr>\n<tr id=\"A6.T9.1.11\" class=\"ltx_tr\">\n<td id=\"A6.T9.1.11.1\" class=\"ltx_td ltx_align_left\">9:</td>\n<td id=\"A6.T9.1.11.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Krum¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T9.1.11.3\" class=\"ltx_td ltx_align_center ltx_border_r\">51.46</td>\n<td id=\"A6.T9.1.11.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T9.1.11.4.1\" class=\"ltx_text ltx_font_bold\">87.88</span></td>\n</tr>\n<tr id=\"A6.T9.1.12\" class=\"ltx_tr\">\n<td id=\"A6.T9.1.12.1\" class=\"ltx_td ltx_align_left\">10:</td>\n<td id=\"A6.T9.1.12.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T9.1.12.2.1\" class=\"ltx_text\">M-Krum</span>¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T9.1.12.3\" class=\"ltx_td ltx_align_center ltx_border_r\">43.19</td>\n<td id=\"A6.T9.1.12.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T9.1.12.4.1\" class=\"ltx_text ltx_font_bold\">95.25</span></td>\n</tr>\n<tr id=\"A6.T9.1.13\" class=\"ltx_tr\">\n<td id=\"A6.T9.1.13.1\" class=\"ltx_td ltx_align_left\">11:</td>\n<td id=\"A6.T9.1.13.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T9.1.13.3\" class=\"ltx_td ltx_align_center ltx_border_r\">49.08</td>\n<td id=\"A6.T9.1.13.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T9.1.13.4.1\" class=\"ltx_text ltx_font_bold\">83.83</span></td>\n</tr>\n<tr id=\"A6.T9.1.14\" class=\"ltx_tr\">\n<td id=\"A6.T9.1.14.1\" class=\"ltx_td ltx_align_left\">12:</td>\n<td id=\"A6.T9.1.14.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip&amp;Noise¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T9.1.14.3\" class=\"ltx_td ltx_align_center ltx_border_r\">43.95</td>\n<td id=\"A6.T9.1.14.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T9.1.14.4.1\" class=\"ltx_text ltx_font_bold\">87.44</span></td>\n</tr>\n<tr id=\"A6.T9.1.15\" class=\"ltx_tr\">\n<td id=\"A6.T9.1.15.1\" class=\"ltx_td ltx_align_left\">13:</td>\n<td id=\"A6.T9.1.15.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Flame¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Nguyen et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib69\" title=\"\" class=\"ltx_ref\">2022c</a>)</cite>\n</td>\n<td id=\"A6.T9.1.15.3\" class=\"ltx_td ltx_align_center ltx_border_r\">46.11</td>\n<td id=\"A6.T9.1.15.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T9.1.15.4.1\" class=\"ltx_text ltx_font_bold\">92.83</span></td>\n</tr>\n<tr id=\"A6.T9.1.16\" class=\"ltx_tr\">\n<td id=\"A6.T9.1.16.1\" class=\"ltx_td ltx_align_left\">14:</td>\n<td id=\"A6.T9.1.16.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Mean¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T9.1.16.3\" class=\"ltx_td ltx_align_center ltx_border_r\">50.85</td>\n<td id=\"A6.T9.1.16.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T9.1.16.4.1\" class=\"ltx_text ltx_font_bold\">85.88</span></td>\n</tr>\n<tr id=\"A6.T9.1.17\" class=\"ltx_tr\">\n<td id=\"A6.T9.1.17.1\" class=\"ltx_td ltx_align_left\">15:</td>\n<td id=\"A6.T9.1.17.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Median¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T9.1.17.3\" class=\"ltx_td ltx_align_center ltx_border_r\">39.62</td>\n<td id=\"A6.T9.1.17.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T9.1.17.4.1\" class=\"ltx_text ltx_font_bold\">74.82</span></td>\n</tr>\n<tr id=\"A6.T9.1.18\" class=\"ltx_tr\">\n<td id=\"A6.T9.1.18.1\" class=\"ltx_td ltx_align_left\">16:</td>\n<td id=\"A6.T9.1.18.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FLTrust¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Cao et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib14\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>\n</td>\n<td id=\"A6.T9.1.18.3\" class=\"ltx_td ltx_align_center ltx_border_r\">55.07</td>\n<td id=\"A6.T9.1.18.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T9.1.18.4.1\" class=\"ltx_text ltx_font_bold\">74.72</span></td>\n</tr>\n<tr id=\"A6.T9.1.19\" class=\"ltx_tr\">\n<td id=\"A6.T9.1.19.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">17:</td>\n<td id=\"A6.T9.1.19.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"A6.T9.1.19.2.1\" class=\"ltx_text ltx_font_bold\">MESAS</span></td>\n<td id=\"A6.T9.1.19.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">63.57</td>\n<td id=\"A6.T9.1.19.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"A6.T9.1.19.4.1\" class=\"ltx_text ltx_font_bold\">1.85</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In this section, we provide further results for our experiments, that could not be included in the main part of the paper due to space limitations. We selected the most interesting and representative results to be part of the main part, but report the rest below for completeness.",
                "Tab.¬†",
                "4",
                " reports the MAs corresponding to the BAs and ACCs in ",
                "Tab.¬†",
                "2",
                " for different poisoning methods without adaptive adversaries. Note, that ",
                "MESAS",
                " provides high MA independent of the applied poisoning attack. The table shows, that ",
                "MESAS",
                " does not negatively impact the MA and is also effective against untargeted attacks.",
                "Tab.¬†",
                "5",
                " shows the results for our default scenario with scaled poisoned models regarding the Euclidean distance of updates. The results confirm, that scaling can increase the BA. ",
                "MESAS",
                " is already efficient for the unscaled version visualized in scenario  ",
                "1",
                " in ",
                "Tab.¬†",
                "1",
                ", hence is also effective for scaled models due to the intuition visualized in ",
                "Fig.¬†",
                "4",
                ". ",
                "Tab.¬†",
                "6",
                " depicts the results for the default scenario with a PDR of 0.3 for scaled poisoned models.",
                "We conducted an attack leveraging our strong adaptive adversary against FoolsGold¬†",
                "(Fung et¬†al",
                ".",
                ", ",
                "2020",
                ")",
                " and report the result in ",
                "Tab.¬†",
                "7",
                ". As strategy, we first trained a benign local model and transferred the trained parameters of the last layer to a fresh local model. We then excluded the parameters form training and poisoned the local model forcing the backdoor into some other layers. In ",
                "Tab.¬†",
                "8",
                " we additionally applied scaling. We can observe, that the BA of FoolsGold can be increased with those methods.",
                "Scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                " shows the result after adapting to Krum scores¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                " in an unscaled and scaled version. We forced the Euclidean distance between poisoned models and the global model to be similar to each other and on a benign level so that the defenses decide in favor of the poisoned models. ",
                "Fig.¬†",
                "12",
                " depicts the Krum scores for the default scenario associated with the default scenario in ",
                "Tab.¬†",
                "1",
                " to show, that the effective backdoor is based on coincidence and not intentionally forced by the attacker. With slight changes in some models, Krum could also decide for a benign model. However, after adaption, we can introduce a high BA intentionally in scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                ".",
                "Tab.¬†",
                "10",
                " and ",
                "Tab.¬†",
                "11",
                " show the results for a classical ",
                "intra-client",
                " ",
                "non-IID",
                " scenario crafted by ",
                "1-class",
                " ",
                "non-IID",
                " with ",
                "q",
                "=",
                "0.5",
                "ùëû",
                "0.5",
                "q=0.5",
                ". In both cases, ",
                "MESAS",
                " reduces the BA reliably with only one FP, while other defenses allow the attacker to embed 34.72% to 49.47% BA. ",
                "Tab.¬†",
                "12",
                " depicts the results for an increased PDR of 0.3, allowing the adversary to reach a BA of 57.68% without defense and up to 92.86% under active defenses. ",
                "MESAS",
                " still removes the poisoned models most effectively with only two FPs.",
                "In ",
                "Tab.¬†",
                "13",
                " and ",
                "Tab.¬†",
                "13",
                " we adapt all malicious models to a central benign value regarding the Cosine distance to the global model, which has the effect, that the models are inconspicuous in Krum scores, hence can circumvent Krum and ",
                "M-Krum",
                "¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                ", while ",
                "MESAS",
                " still erases the backdoor with only two FPs.",
                "Tab.¬†",
                "15",
                " and ",
                "Tab.¬†",
                "16",
                " show the results in a ",
                "inter-client",
                " ",
                "non-IID",
                " scenario based on our ",
                "Random-Non-IID",
                " strategy for a model in FL round one and highlights, that ",
                "MESAS",
                " outperforms other defenses in reducing the BA of the new global model.\n",
                "Tab.¬†",
                "17",
                " and ",
                "Tab.¬†",
                "18",
                " show the results for a setting in round 50,w here 100 clients are part of the federation and 20 clients are selected randomly in each round for training. Due to the later rounds, ",
                "MESAS",
                " is even more effective than other defenses and reduces the BA to a minimum.",
                "Tab.¬†",
                "19",
                " and ",
                "Tab.¬†",
                "20",
                " show the experiments results with a CNN training on MNIST¬†",
                "(Deng, ",
                "2012",
                ")",
                " and SqueezeNet¬†",
                "(Iandola et¬†al",
                ".",
                ", ",
                "2016",
                ")",
                " training on ",
                "CIFAR-10",
                " ",
                "(Krizhevsky et¬†al",
                ".",
                ", ",
                "2009",
                ")",
                ". The CNN consists of two convolutional layers, the first with 32 output layers, the second with 64 output layers, both applying a kernel size of 5. The output of the convolutional layers traverse a ReLU¬†",
                "(Agarap, ",
                "2018",
                ")",
                " and a 2D pooling layer, before being fed into three fully connected layers with output size 512, 256 and 10 output respectively. In both experiments, we used a ",
                "self-pre-trained",
                " model as global model. We can report perfect detection rate with just one FP for CNN and SqueezeNet, even if the backdoor is not yet embedded in the global model. Hence, a stronger adaption by the adversary would strengthen the detection capabilities of ",
                "MESAS",
                ". Other defenses instead can be circumvented by the adaptive adversary."
            ]
        ]
    },
    "A6.T10": {
        "caption": "Table 10. MA and BA in the default scenario for 1-class non-IID with q=0.5ùëû0.5q=0.5 in percent.",
        "table": "<table id=\"A6.T10.3\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A6.T10.3.2\" class=\"ltx_tr\">\n<td id=\"A6.T10.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\">Accuracies without defenses</td>\n<td id=\"A6.T10.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">MA</td>\n<td id=\"A6.T10.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T10.3.1\" class=\"ltx_tr\">\n<td id=\"A6.T10.3.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">1:</td>\n<td id=\"A6.T10.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Global model <math id=\"A6.T10.3.1.1.m1.1\" class=\"ltx_Math\" alttext=\"G^{r}\" display=\"inline\"><semantics id=\"A6.T10.3.1.1.m1.1a\"><msup id=\"A6.T10.3.1.1.m1.1.1\" xref=\"A6.T10.3.1.1.m1.1.1.cmml\"><mi id=\"A6.T10.3.1.1.m1.1.1.2\" xref=\"A6.T10.3.1.1.m1.1.1.2.cmml\">G</mi><mi id=\"A6.T10.3.1.1.m1.1.1.3\" xref=\"A6.T10.3.1.1.m1.1.1.3.cmml\">r</mi></msup><annotation-xml encoding=\"MathML-Content\" id=\"A6.T10.3.1.1.m1.1b\"><apply id=\"A6.T10.3.1.1.m1.1.1.cmml\" xref=\"A6.T10.3.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"A6.T10.3.1.1.m1.1.1.1.cmml\" xref=\"A6.T10.3.1.1.m1.1.1\">superscript</csymbol><ci id=\"A6.T10.3.1.1.m1.1.1.2.cmml\" xref=\"A6.T10.3.1.1.m1.1.1.2\">ùê∫</ci><ci id=\"A6.T10.3.1.1.m1.1.1.3.cmml\" xref=\"A6.T10.3.1.1.m1.1.1.3\">ùëü</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T10.3.1.1.m1.1c\">G^{r}</annotation></semantics></math>\n</td>\n<td id=\"A6.T10.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">62.99</td>\n<td id=\"A6.T10.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">1.93</td>\n</tr>\n<tr id=\"A6.T10.3.3\" class=\"ltx_tr\">\n<td id=\"A6.T10.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">2:</td>\n<td id=\"A6.T10.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Average of benign local models</td>\n<td id=\"A6.T10.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">47.15</td>\n<td id=\"A6.T10.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">6.82</td>\n</tr>\n<tr id=\"A6.T10.3.4\" class=\"ltx_tr\">\n<td id=\"A6.T10.3.4.1\" class=\"ltx_td ltx_align_left\">3:</td>\n<td id=\"A6.T10.3.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Average of poisoned local models</td>\n<td id=\"A6.T10.3.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">45.88</td>\n<td id=\"A6.T10.3.4.4\" class=\"ltx_td ltx_align_center\">84.42</td>\n</tr>\n<tr id=\"A6.T10.3.5\" class=\"ltx_tr\">\n<td id=\"A6.T10.3.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\">4:</td>\n<td id=\"A6.T10.3.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T10.3.5.2.1\" class=\"ltx_text\">FedAVG</span> with benign local models</td>\n<td id=\"A6.T10.3.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">65.92</td>\n<td id=\"A6.T10.3.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">1.40</td>\n</tr>\n<tr id=\"A6.T10.3.6\" class=\"ltx_tr\">\n<td id=\"A6.T10.3.6.1\" class=\"ltx_td ltx_align_left\">5:</td>\n<td id=\"A6.T10.3.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T10.3.6.2.1\" class=\"ltx_text\">FedAVG</span> with poisoned local models</td>\n<td id=\"A6.T10.3.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">64.07</td>\n<td id=\"A6.T10.3.6.4\" class=\"ltx_td ltx_align_center\">83.42</td>\n</tr>\n<tr id=\"A6.T10.3.7\" class=\"ltx_tr\">\n<td id=\"A6.T10.3.7.1\" class=\"ltx_td ltx_align_left ltx_border_t\">6:</td>\n<td id=\"A6.T10.3.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T10.3.7.2.1\" class=\"ltx_text\">FedAVG</span> with all local models</td>\n<td id=\"A6.T10.3.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">65.48</td>\n<td id=\"A6.T10.3.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">43.96</td>\n</tr>\n<tr id=\"A6.T10.3.8\" class=\"ltx_tr\">\n<td id=\"A6.T10.3.8.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\" colspan=\"2\">Global model accuracies after applying defenses</td>\n<td id=\"A6.T10.3.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\">MA</td>\n<td id=\"A6.T10.3.8.3\" class=\"ltx_td ltx_align_center ltx_border_tt ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T10.3.9\" class=\"ltx_tr\">\n<td id=\"A6.T10.3.9.1\" class=\"ltx_td ltx_align_left ltx_border_t\">7:</td>\n<td id=\"A6.T10.3.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Na√Øve Clustering</td>\n<td id=\"A6.T10.3.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">64.76</td>\n<td id=\"A6.T10.3.9.4\" class=\"ltx_td ltx_align_center ltx_border_t\">47.02</td>\n</tr>\n<tr id=\"A6.T10.3.10\" class=\"ltx_tr\">\n<td id=\"A6.T10.3.10.1\" class=\"ltx_td ltx_align_left\">8:</td>\n<td id=\"A6.T10.3.10.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FoolsGold¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Fung et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>\n</td>\n<td id=\"A6.T10.3.10.3\" class=\"ltx_td ltx_align_center ltx_border_r\">50.13</td>\n<td id=\"A6.T10.3.10.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T10.3.10.4.1\" class=\"ltx_text ltx_font_bold\">3.45</span></td>\n</tr>\n<tr id=\"A6.T10.3.11\" class=\"ltx_tr\">\n<td id=\"A6.T10.3.11.1\" class=\"ltx_td ltx_align_left\">9:</td>\n<td id=\"A6.T10.3.11.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Krum¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T10.3.11.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"A6.T10.3.11.3.1\" class=\"ltx_text ltx_font_bold\">49.88</span></td>\n<td id=\"A6.T10.3.11.4\" class=\"ltx_td ltx_align_center\">5.27</td>\n</tr>\n<tr id=\"A6.T10.3.12\" class=\"ltx_tr\">\n<td id=\"A6.T10.3.12.1\" class=\"ltx_td ltx_align_left\">10:</td>\n<td id=\"A6.T10.3.12.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T10.3.12.2.1\" class=\"ltx_text\">M-Krum</span>¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T10.3.12.3\" class=\"ltx_td ltx_align_center ltx_border_r\">60.98</td>\n<td id=\"A6.T10.3.12.4\" class=\"ltx_td ltx_align_center\">52.57</td>\n</tr>\n<tr id=\"A6.T10.3.13\" class=\"ltx_tr\">\n<td id=\"A6.T10.3.13.1\" class=\"ltx_td ltx_align_left\">11:</td>\n<td id=\"A6.T10.3.13.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T10.3.13.3\" class=\"ltx_td ltx_align_center ltx_border_r\">65.50</td>\n<td id=\"A6.T10.3.13.4\" class=\"ltx_td ltx_align_center\">41.33</td>\n</tr>\n<tr id=\"A6.T10.3.14\" class=\"ltx_tr\">\n<td id=\"A6.T10.3.14.1\" class=\"ltx_td ltx_align_left\">12:</td>\n<td id=\"A6.T10.3.14.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip&amp;Noise¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T10.3.14.3\" class=\"ltx_td ltx_align_center ltx_border_r\">59.53</td>\n<td id=\"A6.T10.3.14.4\" class=\"ltx_td ltx_align_center\">52.31</td>\n</tr>\n<tr id=\"A6.T10.3.15\" class=\"ltx_tr\">\n<td id=\"A6.T10.3.15.1\" class=\"ltx_td ltx_align_left\">13:</td>\n<td id=\"A6.T10.3.15.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Flame¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Nguyen et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib69\" title=\"\" class=\"ltx_ref\">2022c</a>)</cite>\n</td>\n<td id=\"A6.T10.3.15.3\" class=\"ltx_td ltx_align_center ltx_border_r\">61.46</td>\n<td id=\"A6.T10.3.15.4\" class=\"ltx_td ltx_align_center\">34.37</td>\n</tr>\n<tr id=\"A6.T10.3.16\" class=\"ltx_tr\">\n<td id=\"A6.T10.3.16.1\" class=\"ltx_td ltx_align_left\">14:</td>\n<td id=\"A6.T10.3.16.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Mean¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T10.3.16.3\" class=\"ltx_td ltx_align_center ltx_border_r\">64.83</td>\n<td id=\"A6.T10.3.16.4\" class=\"ltx_td ltx_align_center\">47.27</td>\n</tr>\n<tr id=\"A6.T10.3.17\" class=\"ltx_tr\">\n<td id=\"A6.T10.3.17.1\" class=\"ltx_td ltx_align_left\">15:</td>\n<td id=\"A6.T10.3.17.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Median¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T10.3.17.3\" class=\"ltx_td ltx_align_center ltx_border_r\">54.84</td>\n<td id=\"A6.T10.3.17.4\" class=\"ltx_td ltx_align_center\">47.46</td>\n</tr>\n<tr id=\"A6.T10.3.18\" class=\"ltx_tr\">\n<td id=\"A6.T10.3.18.1\" class=\"ltx_td ltx_align_left\">16:</td>\n<td id=\"A6.T10.3.18.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FLTrust¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Cao et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib14\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>\n</td>\n<td id=\"A6.T10.3.18.3\" class=\"ltx_td ltx_align_center ltx_border_r\">69.96</td>\n<td id=\"A6.T10.3.18.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T10.3.18.4.1\" class=\"ltx_text ltx_font_bold\">4.64</span></td>\n</tr>\n<tr id=\"A6.T10.3.19\" class=\"ltx_tr\">\n<td id=\"A6.T10.3.19.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">17:</td>\n<td id=\"A6.T10.3.19.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"A6.T10.3.19.2.1\" class=\"ltx_text ltx_font_bold\">MESAS</span></td>\n<td id=\"A6.T10.3.19.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">64.70</td>\n<td id=\"A6.T10.3.19.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"A6.T10.3.19.4.1\" class=\"ltx_text ltx_font_bold\">2.13</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In this section, we provide further results for our experiments, that could not be included in the main part of the paper due to space limitations. We selected the most interesting and representative results to be part of the main part, but report the rest below for completeness.",
                "Tab.¬†",
                "4",
                " reports the MAs corresponding to the BAs and ACCs in ",
                "Tab.¬†",
                "2",
                " for different poisoning methods without adaptive adversaries. Note, that ",
                "MESAS",
                " provides high MA independent of the applied poisoning attack. The table shows, that ",
                "MESAS",
                " does not negatively impact the MA and is also effective against untargeted attacks.",
                "Tab.¬†",
                "5",
                " shows the results for our default scenario with scaled poisoned models regarding the Euclidean distance of updates. The results confirm, that scaling can increase the BA. ",
                "MESAS",
                " is already efficient for the unscaled version visualized in scenario  ",
                "1",
                " in ",
                "Tab.¬†",
                "1",
                ", hence is also effective for scaled models due to the intuition visualized in ",
                "Fig.¬†",
                "4",
                ". ",
                "Tab.¬†",
                "6",
                " depicts the results for the default scenario with a PDR of 0.3 for scaled poisoned models.",
                "We conducted an attack leveraging our strong adaptive adversary against FoolsGold¬†",
                "(Fung et¬†al",
                ".",
                ", ",
                "2020",
                ")",
                " and report the result in ",
                "Tab.¬†",
                "7",
                ". As strategy, we first trained a benign local model and transferred the trained parameters of the last layer to a fresh local model. We then excluded the parameters form training and poisoned the local model forcing the backdoor into some other layers. In ",
                "Tab.¬†",
                "8",
                " we additionally applied scaling. We can observe, that the BA of FoolsGold can be increased with those methods.",
                "Scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                " shows the result after adapting to Krum scores¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                " in an unscaled and scaled version. We forced the Euclidean distance between poisoned models and the global model to be similar to each other and on a benign level so that the defenses decide in favor of the poisoned models. ",
                "Fig.¬†",
                "12",
                " depicts the Krum scores for the default scenario associated with the default scenario in ",
                "Tab.¬†",
                "1",
                " to show, that the effective backdoor is based on coincidence and not intentionally forced by the attacker. With slight changes in some models, Krum could also decide for a benign model. However, after adaption, we can introduce a high BA intentionally in scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                ".",
                "Tab.¬†",
                "10",
                " and ",
                "Tab.¬†",
                "11",
                " show the results for a classical ",
                "intra-client",
                " ",
                "non-IID",
                " scenario crafted by ",
                "1-class",
                " ",
                "non-IID",
                " with ",
                "q",
                "=",
                "0.5",
                "ùëû",
                "0.5",
                "q=0.5",
                ". In both cases, ",
                "MESAS",
                " reduces the BA reliably with only one FP, while other defenses allow the attacker to embed 34.72% to 49.47% BA. ",
                "Tab.¬†",
                "12",
                " depicts the results for an increased PDR of 0.3, allowing the adversary to reach a BA of 57.68% without defense and up to 92.86% under active defenses. ",
                "MESAS",
                " still removes the poisoned models most effectively with only two FPs.",
                "In ",
                "Tab.¬†",
                "13",
                " and ",
                "Tab.¬†",
                "13",
                " we adapt all malicious models to a central benign value regarding the Cosine distance to the global model, which has the effect, that the models are inconspicuous in Krum scores, hence can circumvent Krum and ",
                "M-Krum",
                "¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                ", while ",
                "MESAS",
                " still erases the backdoor with only two FPs.",
                "Tab.¬†",
                "15",
                " and ",
                "Tab.¬†",
                "16",
                " show the results in a ",
                "inter-client",
                " ",
                "non-IID",
                " scenario based on our ",
                "Random-Non-IID",
                " strategy for a model in FL round one and highlights, that ",
                "MESAS",
                " outperforms other defenses in reducing the BA of the new global model.\n",
                "Tab.¬†",
                "17",
                " and ",
                "Tab.¬†",
                "18",
                " show the results for a setting in round 50,w here 100 clients are part of the federation and 20 clients are selected randomly in each round for training. Due to the later rounds, ",
                "MESAS",
                " is even more effective than other defenses and reduces the BA to a minimum.",
                "Tab.¬†",
                "19",
                " and ",
                "Tab.¬†",
                "20",
                " show the experiments results with a CNN training on MNIST¬†",
                "(Deng, ",
                "2012",
                ")",
                " and SqueezeNet¬†",
                "(Iandola et¬†al",
                ".",
                ", ",
                "2016",
                ")",
                " training on ",
                "CIFAR-10",
                " ",
                "(Krizhevsky et¬†al",
                ".",
                ", ",
                "2009",
                ")",
                ". The CNN consists of two convolutional layers, the first with 32 output layers, the second with 64 output layers, both applying a kernel size of 5. The output of the convolutional layers traverse a ReLU¬†",
                "(Agarap, ",
                "2018",
                ")",
                " and a 2D pooling layer, before being fed into three fully connected layers with output size 512, 256 and 10 output respectively. In both experiments, we used a ",
                "self-pre-trained",
                " model as global model. We can report perfect detection rate with just one FP for CNN and SqueezeNet, even if the backdoor is not yet embedded in the global model. Hence, a stronger adaption by the adversary would strengthen the detection capabilities of ",
                "MESAS",
                ". Other defenses instead can be circumvented by the adaptive adversary."
            ]
        ]
    },
    "A6.T11": {
        "caption": "Table 11. MA and BA in the default scenario for 1-class non-IID with q=0.5ùëû0.5q=0.5 and scaled\npoisoned models regarding the Euclidean distance of updates in percent.",
        "table": "<table id=\"A6.T11.3\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A6.T11.3.2\" class=\"ltx_tr\">\n<td id=\"A6.T11.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\">Accuracies without defenses</td>\n<td id=\"A6.T11.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">MA</td>\n<td id=\"A6.T11.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T11.3.1\" class=\"ltx_tr\">\n<td id=\"A6.T11.3.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">1:</td>\n<td id=\"A6.T11.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Global model <math id=\"A6.T11.3.1.1.m1.1\" class=\"ltx_Math\" alttext=\"G^{r}\" display=\"inline\"><semantics id=\"A6.T11.3.1.1.m1.1a\"><msup id=\"A6.T11.3.1.1.m1.1.1\" xref=\"A6.T11.3.1.1.m1.1.1.cmml\"><mi id=\"A6.T11.3.1.1.m1.1.1.2\" xref=\"A6.T11.3.1.1.m1.1.1.2.cmml\">G</mi><mi id=\"A6.T11.3.1.1.m1.1.1.3\" xref=\"A6.T11.3.1.1.m1.1.1.3.cmml\">r</mi></msup><annotation-xml encoding=\"MathML-Content\" id=\"A6.T11.3.1.1.m1.1b\"><apply id=\"A6.T11.3.1.1.m1.1.1.cmml\" xref=\"A6.T11.3.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"A6.T11.3.1.1.m1.1.1.1.cmml\" xref=\"A6.T11.3.1.1.m1.1.1\">superscript</csymbol><ci id=\"A6.T11.3.1.1.m1.1.1.2.cmml\" xref=\"A6.T11.3.1.1.m1.1.1.2\">ùê∫</ci><ci id=\"A6.T11.3.1.1.m1.1.1.3.cmml\" xref=\"A6.T11.3.1.1.m1.1.1.3\">ùëü</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T11.3.1.1.m1.1c\">G^{r}</annotation></semantics></math>\n</td>\n<td id=\"A6.T11.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">62.99</td>\n<td id=\"A6.T11.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">1.93</td>\n</tr>\n<tr id=\"A6.T11.3.3\" class=\"ltx_tr\">\n<td id=\"A6.T11.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">2:</td>\n<td id=\"A6.T11.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Average of benign local models</td>\n<td id=\"A6.T11.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">47.15</td>\n<td id=\"A6.T11.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">6.82</td>\n</tr>\n<tr id=\"A6.T11.3.4\" class=\"ltx_tr\">\n<td id=\"A6.T11.3.4.1\" class=\"ltx_td ltx_align_left\">3:</td>\n<td id=\"A6.T11.3.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Average of poisoned local models</td>\n<td id=\"A6.T11.3.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">45.88</td>\n<td id=\"A6.T11.3.4.4\" class=\"ltx_td ltx_align_center\">84.42</td>\n</tr>\n<tr id=\"A6.T11.3.5\" class=\"ltx_tr\">\n<td id=\"A6.T11.3.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\">4:</td>\n<td id=\"A6.T11.3.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T11.3.5.2.1\" class=\"ltx_text\">FedAVG</span> with benign local models</td>\n<td id=\"A6.T11.3.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">65.92</td>\n<td id=\"A6.T11.3.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">1.40</td>\n</tr>\n<tr id=\"A6.T11.3.6\" class=\"ltx_tr\">\n<td id=\"A6.T11.3.6.1\" class=\"ltx_td ltx_align_left\">5:</td>\n<td id=\"A6.T11.3.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T11.3.6.2.1\" class=\"ltx_text\">FedAVG</span> with poisoned local models</td>\n<td id=\"A6.T11.3.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">64.46</td>\n<td id=\"A6.T11.3.6.4\" class=\"ltx_td ltx_align_center\">84.48</td>\n</tr>\n<tr id=\"A6.T11.3.7\" class=\"ltx_tr\">\n<td id=\"A6.T11.3.7.1\" class=\"ltx_td ltx_align_left ltx_border_t\">6:</td>\n<td id=\"A6.T11.3.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T11.3.7.2.1\" class=\"ltx_text\">FedAVG</span> with all local models</td>\n<td id=\"A6.T11.3.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">65.31</td>\n<td id=\"A6.T11.3.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">45.94</td>\n</tr>\n<tr id=\"A6.T11.3.8\" class=\"ltx_tr\">\n<td id=\"A6.T11.3.8.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\" colspan=\"2\">Global model accuracies after applying defenses</td>\n<td id=\"A6.T11.3.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\">MA</td>\n<td id=\"A6.T11.3.8.3\" class=\"ltx_td ltx_align_center ltx_border_tt ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T11.3.9\" class=\"ltx_tr\">\n<td id=\"A6.T11.3.9.1\" class=\"ltx_td ltx_align_left ltx_border_t\">7:</td>\n<td id=\"A6.T11.3.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Na√Øve Clustering</td>\n<td id=\"A6.T11.3.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">65.59</td>\n<td id=\"A6.T11.3.9.4\" class=\"ltx_td ltx_align_center ltx_border_t\">49.47</td>\n</tr>\n<tr id=\"A6.T11.3.10\" class=\"ltx_tr\">\n<td id=\"A6.T11.3.10.1\" class=\"ltx_td ltx_align_left\">8:</td>\n<td id=\"A6.T11.3.10.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FoolsGold¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Fung et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>\n</td>\n<td id=\"A6.T11.3.10.3\" class=\"ltx_td ltx_align_center ltx_border_r\">50.13</td>\n<td id=\"A6.T11.3.10.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T11.3.10.4.1\" class=\"ltx_text ltx_font_bold\">3.45</span></td>\n</tr>\n<tr id=\"A6.T11.3.11\" class=\"ltx_tr\">\n<td id=\"A6.T11.3.11.1\" class=\"ltx_td ltx_align_left\">9:</td>\n<td id=\"A6.T11.3.11.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Krum¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T11.3.11.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"A6.T11.3.11.3.1\" class=\"ltx_text ltx_font_bold\">49.88</span></td>\n<td id=\"A6.T11.3.11.4\" class=\"ltx_td ltx_align_center\">5.27</td>\n</tr>\n<tr id=\"A6.T11.3.12\" class=\"ltx_tr\">\n<td id=\"A6.T11.3.12.1\" class=\"ltx_td ltx_align_left\">10:</td>\n<td id=\"A6.T11.3.12.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T11.3.12.2.1\" class=\"ltx_text\">M-Krum</span>¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T11.3.12.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.59</td>\n<td id=\"A6.T11.3.12.4\" class=\"ltx_td ltx_align_center\">7.21</td>\n</tr>\n<tr id=\"A6.T11.3.13\" class=\"ltx_tr\">\n<td id=\"A6.T11.3.13.1\" class=\"ltx_td ltx_align_left\">11:</td>\n<td id=\"A6.T11.3.13.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T11.3.13.3\" class=\"ltx_td ltx_align_center ltx_border_r\">65.39</td>\n<td id=\"A6.T11.3.13.4\" class=\"ltx_td ltx_align_center\">43.36</td>\n</tr>\n<tr id=\"A6.T11.3.14\" class=\"ltx_tr\">\n<td id=\"A6.T11.3.14.1\" class=\"ltx_td ltx_align_left\">12:</td>\n<td id=\"A6.T11.3.14.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip&amp;Noise¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T11.3.14.3\" class=\"ltx_td ltx_align_center ltx_border_r\">58.89</td>\n<td id=\"A6.T11.3.14.4\" class=\"ltx_td ltx_align_center\">52.54</td>\n</tr>\n<tr id=\"A6.T11.3.15\" class=\"ltx_tr\">\n<td id=\"A6.T11.3.15.1\" class=\"ltx_td ltx_align_left\">13:</td>\n<td id=\"A6.T11.3.15.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Flame¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Nguyen et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib69\" title=\"\" class=\"ltx_ref\">2022c</a>)</cite>\n</td>\n<td id=\"A6.T11.3.15.3\" class=\"ltx_td ltx_align_center ltx_border_r\">58.86</td>\n<td id=\"A6.T11.3.15.4\" class=\"ltx_td ltx_align_center\">34.72</td>\n</tr>\n<tr id=\"A6.T11.3.16\" class=\"ltx_tr\">\n<td id=\"A6.T11.3.16.1\" class=\"ltx_td ltx_align_left\">14:</td>\n<td id=\"A6.T11.3.16.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Mean¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T11.3.16.3\" class=\"ltx_td ltx_align_center ltx_border_r\">64.61</td>\n<td id=\"A6.T11.3.16.4\" class=\"ltx_td ltx_align_center\">48.96</td>\n</tr>\n<tr id=\"A6.T11.3.17\" class=\"ltx_tr\">\n<td id=\"A6.T11.3.17.1\" class=\"ltx_td ltx_align_left\">15:</td>\n<td id=\"A6.T11.3.17.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Median¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T11.3.17.3\" class=\"ltx_td ltx_align_center ltx_border_r\">54.51</td>\n<td id=\"A6.T11.3.17.4\" class=\"ltx_td ltx_align_center\">48.37</td>\n</tr>\n<tr id=\"A6.T11.3.18\" class=\"ltx_tr\">\n<td id=\"A6.T11.3.18.1\" class=\"ltx_td ltx_align_left\">16:</td>\n<td id=\"A6.T11.3.18.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FLTrust¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Cao et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib14\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>\n</td>\n<td id=\"A6.T11.3.18.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.92</td>\n<td id=\"A6.T11.3.18.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T11.3.18.4.1\" class=\"ltx_text ltx_font_bold\">4.63</span></td>\n</tr>\n<tr id=\"A6.T11.3.19\" class=\"ltx_tr\">\n<td id=\"A6.T11.3.19.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">17:</td>\n<td id=\"A6.T11.3.19.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"A6.T11.3.19.2.1\" class=\"ltx_text ltx_font_bold\">MESAS</span></td>\n<td id=\"A6.T11.3.19.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">64.69</td>\n<td id=\"A6.T11.3.19.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"A6.T11.3.19.4.1\" class=\"ltx_text ltx_font_bold\">2.24</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In this section, we provide further results for our experiments, that could not be included in the main part of the paper due to space limitations. We selected the most interesting and representative results to be part of the main part, but report the rest below for completeness.",
                "Tab.¬†",
                "4",
                " reports the MAs corresponding to the BAs and ACCs in ",
                "Tab.¬†",
                "2",
                " for different poisoning methods without adaptive adversaries. Note, that ",
                "MESAS",
                " provides high MA independent of the applied poisoning attack. The table shows, that ",
                "MESAS",
                " does not negatively impact the MA and is also effective against untargeted attacks.",
                "Tab.¬†",
                "5",
                " shows the results for our default scenario with scaled poisoned models regarding the Euclidean distance of updates. The results confirm, that scaling can increase the BA. ",
                "MESAS",
                " is already efficient for the unscaled version visualized in scenario  ",
                "1",
                " in ",
                "Tab.¬†",
                "1",
                ", hence is also effective for scaled models due to the intuition visualized in ",
                "Fig.¬†",
                "4",
                ". ",
                "Tab.¬†",
                "6",
                " depicts the results for the default scenario with a PDR of 0.3 for scaled poisoned models.",
                "We conducted an attack leveraging our strong adaptive adversary against FoolsGold¬†",
                "(Fung et¬†al",
                ".",
                ", ",
                "2020",
                ")",
                " and report the result in ",
                "Tab.¬†",
                "7",
                ". As strategy, we first trained a benign local model and transferred the trained parameters of the last layer to a fresh local model. We then excluded the parameters form training and poisoned the local model forcing the backdoor into some other layers. In ",
                "Tab.¬†",
                "8",
                " we additionally applied scaling. We can observe, that the BA of FoolsGold can be increased with those methods.",
                "Scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                " shows the result after adapting to Krum scores¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                " in an unscaled and scaled version. We forced the Euclidean distance between poisoned models and the global model to be similar to each other and on a benign level so that the defenses decide in favor of the poisoned models. ",
                "Fig.¬†",
                "12",
                " depicts the Krum scores for the default scenario associated with the default scenario in ",
                "Tab.¬†",
                "1",
                " to show, that the effective backdoor is based on coincidence and not intentionally forced by the attacker. With slight changes in some models, Krum could also decide for a benign model. However, after adaption, we can introduce a high BA intentionally in scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                ".",
                "Tab.¬†",
                "10",
                " and ",
                "Tab.¬†",
                "11",
                " show the results for a classical ",
                "intra-client",
                " ",
                "non-IID",
                " scenario crafted by ",
                "1-class",
                " ",
                "non-IID",
                " with ",
                "q",
                "=",
                "0.5",
                "ùëû",
                "0.5",
                "q=0.5",
                ". In both cases, ",
                "MESAS",
                " reduces the BA reliably with only one FP, while other defenses allow the attacker to embed 34.72% to 49.47% BA. ",
                "Tab.¬†",
                "12",
                " depicts the results for an increased PDR of 0.3, allowing the adversary to reach a BA of 57.68% without defense and up to 92.86% under active defenses. ",
                "MESAS",
                " still removes the poisoned models most effectively with only two FPs.",
                "In ",
                "Tab.¬†",
                "13",
                " and ",
                "Tab.¬†",
                "13",
                " we adapt all malicious models to a central benign value regarding the Cosine distance to the global model, which has the effect, that the models are inconspicuous in Krum scores, hence can circumvent Krum and ",
                "M-Krum",
                "¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                ", while ",
                "MESAS",
                " still erases the backdoor with only two FPs.",
                "Tab.¬†",
                "15",
                " and ",
                "Tab.¬†",
                "16",
                " show the results in a ",
                "inter-client",
                " ",
                "non-IID",
                " scenario based on our ",
                "Random-Non-IID",
                " strategy for a model in FL round one and highlights, that ",
                "MESAS",
                " outperforms other defenses in reducing the BA of the new global model.\n",
                "Tab.¬†",
                "17",
                " and ",
                "Tab.¬†",
                "18",
                " show the results for a setting in round 50,w here 100 clients are part of the federation and 20 clients are selected randomly in each round for training. Due to the later rounds, ",
                "MESAS",
                " is even more effective than other defenses and reduces the BA to a minimum.",
                "Tab.¬†",
                "19",
                " and ",
                "Tab.¬†",
                "20",
                " show the experiments results with a CNN training on MNIST¬†",
                "(Deng, ",
                "2012",
                ")",
                " and SqueezeNet¬†",
                "(Iandola et¬†al",
                ".",
                ", ",
                "2016",
                ")",
                " training on ",
                "CIFAR-10",
                " ",
                "(Krizhevsky et¬†al",
                ".",
                ", ",
                "2009",
                ")",
                ". The CNN consists of two convolutional layers, the first with 32 output layers, the second with 64 output layers, both applying a kernel size of 5. The output of the convolutional layers traverse a ReLU¬†",
                "(Agarap, ",
                "2018",
                ")",
                " and a 2D pooling layer, before being fed into three fully connected layers with output size 512, 256 and 10 output respectively. In both experiments, we used a ",
                "self-pre-trained",
                " model as global model. We can report perfect detection rate with just one FP for CNN and SqueezeNet, even if the backdoor is not yet embedded in the global model. Hence, a stronger adaption by the adversary would strengthen the detection capabilities of ",
                "MESAS",
                ". Other defenses instead can be circumvented by the adaptive adversary."
            ]
        ]
    },
    "A6.T12": {
        "caption": "Table 12. MA and BA in the default scenario with a PDR of 0.3 and for 1-class non-IID with q=0.5ùëû0.5q=0.5 in percent.",
        "table": "<table id=\"A6.T12.3\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A6.T12.3.2\" class=\"ltx_tr\">\n<td id=\"A6.T12.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\">Accuracies without defenses</td>\n<td id=\"A6.T12.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">MA</td>\n<td id=\"A6.T12.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T12.3.1\" class=\"ltx_tr\">\n<td id=\"A6.T12.3.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">1:</td>\n<td id=\"A6.T12.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Global model <math id=\"A6.T12.3.1.1.m1.1\" class=\"ltx_Math\" alttext=\"G^{r}\" display=\"inline\"><semantics id=\"A6.T12.3.1.1.m1.1a\"><msup id=\"A6.T12.3.1.1.m1.1.1\" xref=\"A6.T12.3.1.1.m1.1.1.cmml\"><mi id=\"A6.T12.3.1.1.m1.1.1.2\" xref=\"A6.T12.3.1.1.m1.1.1.2.cmml\">G</mi><mi id=\"A6.T12.3.1.1.m1.1.1.3\" xref=\"A6.T12.3.1.1.m1.1.1.3.cmml\">r</mi></msup><annotation-xml encoding=\"MathML-Content\" id=\"A6.T12.3.1.1.m1.1b\"><apply id=\"A6.T12.3.1.1.m1.1.1.cmml\" xref=\"A6.T12.3.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"A6.T12.3.1.1.m1.1.1.1.cmml\" xref=\"A6.T12.3.1.1.m1.1.1\">superscript</csymbol><ci id=\"A6.T12.3.1.1.m1.1.1.2.cmml\" xref=\"A6.T12.3.1.1.m1.1.1.2\">ùê∫</ci><ci id=\"A6.T12.3.1.1.m1.1.1.3.cmml\" xref=\"A6.T12.3.1.1.m1.1.1.3\">ùëü</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T12.3.1.1.m1.1c\">G^{r}</annotation></semantics></math>\n</td>\n<td id=\"A6.T12.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">62.99</td>\n<td id=\"A6.T12.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">1.93</td>\n</tr>\n<tr id=\"A6.T12.3.3\" class=\"ltx_tr\">\n<td id=\"A6.T12.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">2:</td>\n<td id=\"A6.T12.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Average of benign local models</td>\n<td id=\"A6.T12.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">47.15</td>\n<td id=\"A6.T12.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">6.82</td>\n</tr>\n<tr id=\"A6.T12.3.4\" class=\"ltx_tr\">\n<td id=\"A6.T12.3.4.1\" class=\"ltx_td ltx_align_left\">3:</td>\n<td id=\"A6.T12.3.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Average of poisoned local models</td>\n<td id=\"A6.T12.3.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">43.74</td>\n<td id=\"A6.T12.3.4.4\" class=\"ltx_td ltx_align_center\">91.32</td>\n</tr>\n<tr id=\"A6.T12.3.5\" class=\"ltx_tr\">\n<td id=\"A6.T12.3.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\">4:</td>\n<td id=\"A6.T12.3.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T12.3.5.2.1\" class=\"ltx_text\">FedAVG</span> with benign local models</td>\n<td id=\"A6.T12.3.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">65.92</td>\n<td id=\"A6.T12.3.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">1.40</td>\n</tr>\n<tr id=\"A6.T12.3.6\" class=\"ltx_tr\">\n<td id=\"A6.T12.3.6.1\" class=\"ltx_td ltx_align_left\">5:</td>\n<td id=\"A6.T12.3.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T12.3.6.2.1\" class=\"ltx_text\">FedAVG</span> with poisoned local models</td>\n<td id=\"A6.T12.3.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">61.48</td>\n<td id=\"A6.T12.3.6.4\" class=\"ltx_td ltx_align_center\">92.92</td>\n</tr>\n<tr id=\"A6.T12.3.7\" class=\"ltx_tr\">\n<td id=\"A6.T12.3.7.1\" class=\"ltx_td ltx_align_left ltx_border_t\">6:</td>\n<td id=\"A6.T12.3.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T12.3.7.2.1\" class=\"ltx_text\">FedAVG</span> with all local models</td>\n<td id=\"A6.T12.3.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">65.64</td>\n<td id=\"A6.T12.3.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">57.68</td>\n</tr>\n<tr id=\"A6.T12.3.8\" class=\"ltx_tr\">\n<td id=\"A6.T12.3.8.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\" colspan=\"2\">Global model accuracies after applying defenses</td>\n<td id=\"A6.T12.3.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\">MA</td>\n<td id=\"A6.T12.3.8.3\" class=\"ltx_td ltx_align_center ltx_border_tt ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T12.3.9\" class=\"ltx_tr\">\n<td id=\"A6.T12.3.9.1\" class=\"ltx_td ltx_align_left ltx_border_t\">7:</td>\n<td id=\"A6.T12.3.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Na√Øve Clustering</td>\n<td id=\"A6.T12.3.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">62.49</td>\n<td id=\"A6.T12.3.9.4\" class=\"ltx_td ltx_align_center ltx_border_t\">83.70</td>\n</tr>\n<tr id=\"A6.T12.3.10\" class=\"ltx_tr\">\n<td id=\"A6.T12.3.10.1\" class=\"ltx_td ltx_align_left\">8:</td>\n<td id=\"A6.T12.3.10.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FoolsGold¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Fung et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>\n</td>\n<td id=\"A6.T12.3.10.3\" class=\"ltx_td ltx_align_center ltx_border_r\">57.60</td>\n<td id=\"A6.T12.3.10.4\" class=\"ltx_td ltx_align_center\">39.05</td>\n</tr>\n<tr id=\"A6.T12.3.11\" class=\"ltx_tr\">\n<td id=\"A6.T12.3.11.1\" class=\"ltx_td ltx_align_left\">9:</td>\n<td id=\"A6.T12.3.11.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Krum¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T12.3.11.3\" class=\"ltx_td ltx_align_center ltx_border_r\">49.43</td>\n<td id=\"A6.T12.3.11.4\" class=\"ltx_td ltx_align_center\">92.86</td>\n</tr>\n<tr id=\"A6.T12.3.12\" class=\"ltx_tr\">\n<td id=\"A6.T12.3.12.1\" class=\"ltx_td ltx_align_left\">10:</td>\n<td id=\"A6.T12.3.12.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T12.3.12.2.1\" class=\"ltx_text\">M-Krum</span>¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T12.3.12.3\" class=\"ltx_td ltx_align_center ltx_border_r\">57.51</td>\n<td id=\"A6.T12.3.12.4\" class=\"ltx_td ltx_align_center\">85.95</td>\n</tr>\n<tr id=\"A6.T12.3.13\" class=\"ltx_tr\">\n<td id=\"A6.T12.3.13.1\" class=\"ltx_td ltx_align_left\">11:</td>\n<td id=\"A6.T12.3.13.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T12.3.13.3\" class=\"ltx_td ltx_align_center ltx_border_r\">64.60</td>\n<td id=\"A6.T12.3.13.4\" class=\"ltx_td ltx_align_center\">56.81</td>\n</tr>\n<tr id=\"A6.T12.3.14\" class=\"ltx_tr\">\n<td id=\"A6.T12.3.14.1\" class=\"ltx_td ltx_align_left\">12:</td>\n<td id=\"A6.T12.3.14.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip&amp;Noise¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T12.3.14.3\" class=\"ltx_td ltx_align_center ltx_border_r\">57.77</td>\n<td id=\"A6.T12.3.14.4\" class=\"ltx_td ltx_align_center\">70.20</td>\n</tr>\n<tr id=\"A6.T12.3.15\" class=\"ltx_tr\">\n<td id=\"A6.T12.3.15.1\" class=\"ltx_td ltx_align_left\">13:</td>\n<td id=\"A6.T12.3.15.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Flame¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Nguyen et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib69\" title=\"\" class=\"ltx_ref\">2022c</a>)</cite>\n</td>\n<td id=\"A6.T12.3.15.3\" class=\"ltx_td ltx_align_center ltx_border_r\">60.55</td>\n<td id=\"A6.T12.3.15.4\" class=\"ltx_td ltx_align_center\">45.36</td>\n</tr>\n<tr id=\"A6.T12.3.16\" class=\"ltx_tr\">\n<td id=\"A6.T12.3.16.1\" class=\"ltx_td ltx_align_left\">14:</td>\n<td id=\"A6.T12.3.16.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Mean¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T12.3.16.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.81</td>\n<td id=\"A6.T12.3.16.4\" class=\"ltx_td ltx_align_center\">62.77</td>\n</tr>\n<tr id=\"A6.T12.3.17\" class=\"ltx_tr\">\n<td id=\"A6.T12.3.17.1\" class=\"ltx_td ltx_align_left\">15:</td>\n<td id=\"A6.T12.3.17.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Median¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T12.3.17.3\" class=\"ltx_td ltx_align_center ltx_border_r\">52.96</td>\n<td id=\"A6.T12.3.17.4\" class=\"ltx_td ltx_align_center\">66.78</td>\n</tr>\n<tr id=\"A6.T12.3.18\" class=\"ltx_tr\">\n<td id=\"A6.T12.3.18.1\" class=\"ltx_td ltx_align_left\">16:</td>\n<td id=\"A6.T12.3.18.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FLTrust¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Cao et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib14\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>\n</td>\n<td id=\"A6.T12.3.18.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.73</td>\n<td id=\"A6.T12.3.18.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T12.3.18.4.1\" class=\"ltx_text ltx_font_bold\">8.31</span></td>\n</tr>\n<tr id=\"A6.T12.3.19\" class=\"ltx_tr\">\n<td id=\"A6.T12.3.19.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">17:</td>\n<td id=\"A6.T12.3.19.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"A6.T12.3.19.2.1\" class=\"ltx_text ltx_font_bold\">MESAS</span></td>\n<td id=\"A6.T12.3.19.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">65.49</td>\n<td id=\"A6.T12.3.19.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"A6.T12.3.19.4.1\" class=\"ltx_text ltx_font_bold\">1.46</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In this section, we provide further results for our experiments, that could not be included in the main part of the paper due to space limitations. We selected the most interesting and representative results to be part of the main part, but report the rest below for completeness.",
                "Tab.¬†",
                "4",
                " reports the MAs corresponding to the BAs and ACCs in ",
                "Tab.¬†",
                "2",
                " for different poisoning methods without adaptive adversaries. Note, that ",
                "MESAS",
                " provides high MA independent of the applied poisoning attack. The table shows, that ",
                "MESAS",
                " does not negatively impact the MA and is also effective against untargeted attacks.",
                "Tab.¬†",
                "5",
                " shows the results for our default scenario with scaled poisoned models regarding the Euclidean distance of updates. The results confirm, that scaling can increase the BA. ",
                "MESAS",
                " is already efficient for the unscaled version visualized in scenario  ",
                "1",
                " in ",
                "Tab.¬†",
                "1",
                ", hence is also effective for scaled models due to the intuition visualized in ",
                "Fig.¬†",
                "4",
                ". ",
                "Tab.¬†",
                "6",
                " depicts the results for the default scenario with a PDR of 0.3 for scaled poisoned models.",
                "We conducted an attack leveraging our strong adaptive adversary against FoolsGold¬†",
                "(Fung et¬†al",
                ".",
                ", ",
                "2020",
                ")",
                " and report the result in ",
                "Tab.¬†",
                "7",
                ". As strategy, we first trained a benign local model and transferred the trained parameters of the last layer to a fresh local model. We then excluded the parameters form training and poisoned the local model forcing the backdoor into some other layers. In ",
                "Tab.¬†",
                "8",
                " we additionally applied scaling. We can observe, that the BA of FoolsGold can be increased with those methods.",
                "Scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                " shows the result after adapting to Krum scores¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                " in an unscaled and scaled version. We forced the Euclidean distance between poisoned models and the global model to be similar to each other and on a benign level so that the defenses decide in favor of the poisoned models. ",
                "Fig.¬†",
                "12",
                " depicts the Krum scores for the default scenario associated with the default scenario in ",
                "Tab.¬†",
                "1",
                " to show, that the effective backdoor is based on coincidence and not intentionally forced by the attacker. With slight changes in some models, Krum could also decide for a benign model. However, after adaption, we can introduce a high BA intentionally in scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                ".",
                "Tab.¬†",
                "10",
                " and ",
                "Tab.¬†",
                "11",
                " show the results for a classical ",
                "intra-client",
                " ",
                "non-IID",
                " scenario crafted by ",
                "1-class",
                " ",
                "non-IID",
                " with ",
                "q",
                "=",
                "0.5",
                "ùëû",
                "0.5",
                "q=0.5",
                ". In both cases, ",
                "MESAS",
                " reduces the BA reliably with only one FP, while other defenses allow the attacker to embed 34.72% to 49.47% BA. ",
                "Tab.¬†",
                "12",
                " depicts the results for an increased PDR of 0.3, allowing the adversary to reach a BA of 57.68% without defense and up to 92.86% under active defenses. ",
                "MESAS",
                " still removes the poisoned models most effectively with only two FPs.",
                "In ",
                "Tab.¬†",
                "13",
                " and ",
                "Tab.¬†",
                "13",
                " we adapt all malicious models to a central benign value regarding the Cosine distance to the global model, which has the effect, that the models are inconspicuous in Krum scores, hence can circumvent Krum and ",
                "M-Krum",
                "¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                ", while ",
                "MESAS",
                " still erases the backdoor with only two FPs.",
                "Tab.¬†",
                "15",
                " and ",
                "Tab.¬†",
                "16",
                " show the results in a ",
                "inter-client",
                " ",
                "non-IID",
                " scenario based on our ",
                "Random-Non-IID",
                " strategy for a model in FL round one and highlights, that ",
                "MESAS",
                " outperforms other defenses in reducing the BA of the new global model.\n",
                "Tab.¬†",
                "17",
                " and ",
                "Tab.¬†",
                "18",
                " show the results for a setting in round 50,w here 100 clients are part of the federation and 20 clients are selected randomly in each round for training. Due to the later rounds, ",
                "MESAS",
                " is even more effective than other defenses and reduces the BA to a minimum.",
                "Tab.¬†",
                "19",
                " and ",
                "Tab.¬†",
                "20",
                " show the experiments results with a CNN training on MNIST¬†",
                "(Deng, ",
                "2012",
                ")",
                " and SqueezeNet¬†",
                "(Iandola et¬†al",
                ".",
                ", ",
                "2016",
                ")",
                " training on ",
                "CIFAR-10",
                " ",
                "(Krizhevsky et¬†al",
                ".",
                ", ",
                "2009",
                ")",
                ". The CNN consists of two convolutional layers, the first with 32 output layers, the second with 64 output layers, both applying a kernel size of 5. The output of the convolutional layers traverse a ReLU¬†",
                "(Agarap, ",
                "2018",
                ")",
                " and a 2D pooling layer, before being fed into three fully connected layers with output size 512, 256 and 10 output respectively. In both experiments, we used a ",
                "self-pre-trained",
                " model as global model. We can report perfect detection rate with just one FP for CNN and SqueezeNet, even if the backdoor is not yet embedded in the global model. Hence, a stronger adaption by the adversary would strengthen the detection capabilities of ",
                "MESAS",
                ". Other defenses instead can be circumvented by the adaptive adversary."
            ]
        ]
    },
    "A6.T13": {
        "caption": "Table 13. MA and BA in the default scenario for 1-class non-IID with q=0.5ùëû0.5q=0.5, adaption to benign values regarding the Cosine distance to the global model in percent.",
        "table": "<table id=\"A6.T13.3\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A6.T13.3.2\" class=\"ltx_tr\">\n<td id=\"A6.T13.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\">Accuracies without defenses</td>\n<td id=\"A6.T13.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">MA</td>\n<td id=\"A6.T13.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T13.3.1\" class=\"ltx_tr\">\n<td id=\"A6.T13.3.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">1:</td>\n<td id=\"A6.T13.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Global model <math id=\"A6.T13.3.1.1.m1.1\" class=\"ltx_Math\" alttext=\"G^{r}\" display=\"inline\"><semantics id=\"A6.T13.3.1.1.m1.1a\"><msup id=\"A6.T13.3.1.1.m1.1.1\" xref=\"A6.T13.3.1.1.m1.1.1.cmml\"><mi id=\"A6.T13.3.1.1.m1.1.1.2\" xref=\"A6.T13.3.1.1.m1.1.1.2.cmml\">G</mi><mi id=\"A6.T13.3.1.1.m1.1.1.3\" xref=\"A6.T13.3.1.1.m1.1.1.3.cmml\">r</mi></msup><annotation-xml encoding=\"MathML-Content\" id=\"A6.T13.3.1.1.m1.1b\"><apply id=\"A6.T13.3.1.1.m1.1.1.cmml\" xref=\"A6.T13.3.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"A6.T13.3.1.1.m1.1.1.1.cmml\" xref=\"A6.T13.3.1.1.m1.1.1\">superscript</csymbol><ci id=\"A6.T13.3.1.1.m1.1.1.2.cmml\" xref=\"A6.T13.3.1.1.m1.1.1.2\">ùê∫</ci><ci id=\"A6.T13.3.1.1.m1.1.1.3.cmml\" xref=\"A6.T13.3.1.1.m1.1.1.3\">ùëü</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T13.3.1.1.m1.1c\">G^{r}</annotation></semantics></math>\n</td>\n<td id=\"A6.T13.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">62.99</td>\n<td id=\"A6.T13.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">1.93</td>\n</tr>\n<tr id=\"A6.T13.3.3\" class=\"ltx_tr\">\n<td id=\"A6.T13.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">2:</td>\n<td id=\"A6.T13.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Average of benign local models</td>\n<td id=\"A6.T13.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">47.15</td>\n<td id=\"A6.T13.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">6.82</td>\n</tr>\n<tr id=\"A6.T13.3.4\" class=\"ltx_tr\">\n<td id=\"A6.T13.3.4.1\" class=\"ltx_td ltx_align_left\">3:</td>\n<td id=\"A6.T13.3.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Average of poisoned local models</td>\n<td id=\"A6.T13.3.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">61.27</td>\n<td id=\"A6.T13.3.4.4\" class=\"ltx_td ltx_align_center\">78.68</td>\n</tr>\n<tr id=\"A6.T13.3.5\" class=\"ltx_tr\">\n<td id=\"A6.T13.3.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\">4:</td>\n<td id=\"A6.T13.3.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T13.3.5.2.1\" class=\"ltx_text\">FedAVG</span> with benign local models</td>\n<td id=\"A6.T13.3.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">65.92</td>\n<td id=\"A6.T13.3.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">1.40</td>\n</tr>\n<tr id=\"A6.T13.3.6\" class=\"ltx_tr\">\n<td id=\"A6.T13.3.6.1\" class=\"ltx_td ltx_align_left\">5:</td>\n<td id=\"A6.T13.3.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T13.3.6.2.1\" class=\"ltx_text\">FedAVG</span> with poisoned local models</td>\n<td id=\"A6.T13.3.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">70.12</td>\n<td id=\"A6.T13.3.6.4\" class=\"ltx_td ltx_align_center\">78.05</td>\n</tr>\n<tr id=\"A6.T13.3.7\" class=\"ltx_tr\">\n<td id=\"A6.T13.3.7.1\" class=\"ltx_td ltx_align_left ltx_border_t\">6:</td>\n<td id=\"A6.T13.3.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T13.3.7.2.1\" class=\"ltx_text\">FedAVG</span> with all local models</td>\n<td id=\"A6.T13.3.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">66.70</td>\n<td id=\"A6.T13.3.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">23.35</td>\n</tr>\n<tr id=\"A6.T13.3.8\" class=\"ltx_tr\">\n<td id=\"A6.T13.3.8.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\" colspan=\"2\">Global model accuracies after applying defenses</td>\n<td id=\"A6.T13.3.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\">MA</td>\n<td id=\"A6.T13.3.8.3\" class=\"ltx_td ltx_align_center ltx_border_tt ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T13.3.9\" class=\"ltx_tr\">\n<td id=\"A6.T13.3.9.1\" class=\"ltx_td ltx_align_left ltx_border_t\">7:</td>\n<td id=\"A6.T13.3.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Na√Øve Clustering</td>\n<td id=\"A6.T13.3.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">65.92</td>\n<td id=\"A6.T13.3.9.4\" class=\"ltx_td ltx_align_center ltx_border_t\">1.40</td>\n</tr>\n<tr id=\"A6.T13.3.10\" class=\"ltx_tr\">\n<td id=\"A6.T13.3.10.1\" class=\"ltx_td ltx_align_left\">8:</td>\n<td id=\"A6.T13.3.10.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FoolsGold¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Fung et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>\n</td>\n<td id=\"A6.T13.3.10.3\" class=\"ltx_td ltx_align_center ltx_border_r\">65.79</td>\n<td id=\"A6.T13.3.10.4\" class=\"ltx_td ltx_align_center\">1.58</td>\n</tr>\n<tr id=\"A6.T13.3.11\" class=\"ltx_tr\">\n<td id=\"A6.T13.3.11.1\" class=\"ltx_td ltx_align_left\">9:</td>\n<td id=\"A6.T13.3.11.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Krum¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T13.3.11.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.26</td>\n<td id=\"A6.T13.3.11.4\" class=\"ltx_td ltx_align_center\">69.94</td>\n</tr>\n<tr id=\"A6.T13.3.12\" class=\"ltx_tr\">\n<td id=\"A6.T13.3.12.1\" class=\"ltx_td ltx_align_left\">10:</td>\n<td id=\"A6.T13.3.12.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T13.3.12.2.1\" class=\"ltx_text\">M-Krum</span>¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T13.3.12.3\" class=\"ltx_td ltx_align_center ltx_border_r\">68.45</td>\n<td id=\"A6.T13.3.12.4\" class=\"ltx_td ltx_align_center\">79.21</td>\n</tr>\n<tr id=\"A6.T13.3.13\" class=\"ltx_tr\">\n<td id=\"A6.T13.3.13.1\" class=\"ltx_td ltx_align_left\">11:</td>\n<td id=\"A6.T13.3.13.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T13.3.13.3\" class=\"ltx_td ltx_align_center ltx_border_r\">66.79</td>\n<td id=\"A6.T13.3.13.4\" class=\"ltx_td ltx_align_center\">24.16</td>\n</tr>\n<tr id=\"A6.T13.3.14\" class=\"ltx_tr\">\n<td id=\"A6.T13.3.14.1\" class=\"ltx_td ltx_align_left\">12:</td>\n<td id=\"A6.T13.3.14.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip&amp;Noise¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T13.3.14.3\" class=\"ltx_td ltx_align_center ltx_border_r\">56.22</td>\n<td id=\"A6.T13.3.14.4\" class=\"ltx_td ltx_align_center\">25.71</td>\n</tr>\n<tr id=\"A6.T13.3.15\" class=\"ltx_tr\">\n<td id=\"A6.T13.3.15.1\" class=\"ltx_td ltx_align_left\">13:</td>\n<td id=\"A6.T13.3.15.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Flame¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Nguyen et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib69\" title=\"\" class=\"ltx_ref\">2022c</a>)</cite>\n</td>\n<td id=\"A6.T13.3.15.3\" class=\"ltx_td ltx_align_center ltx_border_r\">64.12</td>\n<td id=\"A6.T13.3.15.4\" class=\"ltx_td ltx_align_center\">27.76</td>\n</tr>\n<tr id=\"A6.T13.3.16\" class=\"ltx_tr\">\n<td id=\"A6.T13.3.16.1\" class=\"ltx_td ltx_align_left\">14:</td>\n<td id=\"A6.T13.3.16.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Mean¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T13.3.16.3\" class=\"ltx_td ltx_align_center ltx_border_r\">65.96</td>\n<td id=\"A6.T13.3.16.4\" class=\"ltx_td ltx_align_center\">27.62</td>\n</tr>\n<tr id=\"A6.T13.3.17\" class=\"ltx_tr\">\n<td id=\"A6.T13.3.17.1\" class=\"ltx_td ltx_align_left\">15:</td>\n<td id=\"A6.T13.3.17.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Median¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T13.3.17.3\" class=\"ltx_td ltx_align_center ltx_border_r\">51.60</td>\n<td id=\"A6.T13.3.17.4\" class=\"ltx_td ltx_align_center\">40.07</td>\n</tr>\n<tr id=\"A6.T13.3.18\" class=\"ltx_tr\">\n<td id=\"A6.T13.3.18.1\" class=\"ltx_td ltx_align_left\">16:</td>\n<td id=\"A6.T13.3.18.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FLTrust¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Cao et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib14\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>\n</td>\n<td id=\"A6.T13.3.18.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.57</td>\n<td id=\"A6.T13.3.18.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T13.3.18.4.1\" class=\"ltx_text ltx_font_bold\">18.75</span></td>\n</tr>\n<tr id=\"A6.T13.3.19\" class=\"ltx_tr\">\n<td id=\"A6.T13.3.19.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">17:</td>\n<td id=\"A6.T13.3.19.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"A6.T13.3.19.2.1\" class=\"ltx_text ltx_font_bold\">MESAS</span></td>\n<td id=\"A6.T13.3.19.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">66.47</td>\n<td id=\"A6.T13.3.19.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"A6.T13.3.19.4.1\" class=\"ltx_text ltx_font_bold\">1.45</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In this section, we provide further results for our experiments, that could not be included in the main part of the paper due to space limitations. We selected the most interesting and representative results to be part of the main part, but report the rest below for completeness.",
                "Tab.¬†",
                "4",
                " reports the MAs corresponding to the BAs and ACCs in ",
                "Tab.¬†",
                "2",
                " for different poisoning methods without adaptive adversaries. Note, that ",
                "MESAS",
                " provides high MA independent of the applied poisoning attack. The table shows, that ",
                "MESAS",
                " does not negatively impact the MA and is also effective against untargeted attacks.",
                "Tab.¬†",
                "5",
                " shows the results for our default scenario with scaled poisoned models regarding the Euclidean distance of updates. The results confirm, that scaling can increase the BA. ",
                "MESAS",
                " is already efficient for the unscaled version visualized in scenario  ",
                "1",
                " in ",
                "Tab.¬†",
                "1",
                ", hence is also effective for scaled models due to the intuition visualized in ",
                "Fig.¬†",
                "4",
                ". ",
                "Tab.¬†",
                "6",
                " depicts the results for the default scenario with a PDR of 0.3 for scaled poisoned models.",
                "We conducted an attack leveraging our strong adaptive adversary against FoolsGold¬†",
                "(Fung et¬†al",
                ".",
                ", ",
                "2020",
                ")",
                " and report the result in ",
                "Tab.¬†",
                "7",
                ". As strategy, we first trained a benign local model and transferred the trained parameters of the last layer to a fresh local model. We then excluded the parameters form training and poisoned the local model forcing the backdoor into some other layers. In ",
                "Tab.¬†",
                "8",
                " we additionally applied scaling. We can observe, that the BA of FoolsGold can be increased with those methods.",
                "Scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                " shows the result after adapting to Krum scores¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                " in an unscaled and scaled version. We forced the Euclidean distance between poisoned models and the global model to be similar to each other and on a benign level so that the defenses decide in favor of the poisoned models. ",
                "Fig.¬†",
                "12",
                " depicts the Krum scores for the default scenario associated with the default scenario in ",
                "Tab.¬†",
                "1",
                " to show, that the effective backdoor is based on coincidence and not intentionally forced by the attacker. With slight changes in some models, Krum could also decide for a benign model. However, after adaption, we can introduce a high BA intentionally in scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                ".",
                "Tab.¬†",
                "10",
                " and ",
                "Tab.¬†",
                "11",
                " show the results for a classical ",
                "intra-client",
                " ",
                "non-IID",
                " scenario crafted by ",
                "1-class",
                " ",
                "non-IID",
                " with ",
                "q",
                "=",
                "0.5",
                "ùëû",
                "0.5",
                "q=0.5",
                ". In both cases, ",
                "MESAS",
                " reduces the BA reliably with only one FP, while other defenses allow the attacker to embed 34.72% to 49.47% BA. ",
                "Tab.¬†",
                "12",
                " depicts the results for an increased PDR of 0.3, allowing the adversary to reach a BA of 57.68% without defense and up to 92.86% under active defenses. ",
                "MESAS",
                " still removes the poisoned models most effectively with only two FPs.",
                "In ",
                "Tab.¬†",
                "13",
                " and ",
                "Tab.¬†",
                "13",
                " we adapt all malicious models to a central benign value regarding the Cosine distance to the global model, which has the effect, that the models are inconspicuous in Krum scores, hence can circumvent Krum and ",
                "M-Krum",
                "¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                ", while ",
                "MESAS",
                " still erases the backdoor with only two FPs.",
                "Tab.¬†",
                "15",
                " and ",
                "Tab.¬†",
                "16",
                " show the results in a ",
                "inter-client",
                " ",
                "non-IID",
                " scenario based on our ",
                "Random-Non-IID",
                " strategy for a model in FL round one and highlights, that ",
                "MESAS",
                " outperforms other defenses in reducing the BA of the new global model.\n",
                "Tab.¬†",
                "17",
                " and ",
                "Tab.¬†",
                "18",
                " show the results for a setting in round 50,w here 100 clients are part of the federation and 20 clients are selected randomly in each round for training. Due to the later rounds, ",
                "MESAS",
                " is even more effective than other defenses and reduces the BA to a minimum.",
                "Tab.¬†",
                "19",
                " and ",
                "Tab.¬†",
                "20",
                " show the experiments results with a CNN training on MNIST¬†",
                "(Deng, ",
                "2012",
                ")",
                " and SqueezeNet¬†",
                "(Iandola et¬†al",
                ".",
                ", ",
                "2016",
                ")",
                " training on ",
                "CIFAR-10",
                " ",
                "(Krizhevsky et¬†al",
                ".",
                ", ",
                "2009",
                ")",
                ". The CNN consists of two convolutional layers, the first with 32 output layers, the second with 64 output layers, both applying a kernel size of 5. The output of the convolutional layers traverse a ReLU¬†",
                "(Agarap, ",
                "2018",
                ")",
                " and a 2D pooling layer, before being fed into three fully connected layers with output size 512, 256 and 10 output respectively. In both experiments, we used a ",
                "self-pre-trained",
                " model as global model. We can report perfect detection rate with just one FP for CNN and SqueezeNet, even if the backdoor is not yet embedded in the global model. Hence, a stronger adaption by the adversary would strengthen the detection capabilities of ",
                "MESAS",
                ". Other defenses instead can be circumvented by the adaptive adversary."
            ]
        ]
    },
    "A6.T14": {
        "caption": "Table 14. MA and BA in the default scenario for 1-class non-IID with q=0.5ùëû0.5q=0.5, adaption to benign values regarding the Cosine distance to the global model and scaled poisoned models regarding the Euclidean distance of updates in percent.",
        "table": "<table id=\"A6.T14.3\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A6.T14.3.2\" class=\"ltx_tr\">\n<td id=\"A6.T14.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\">Accuracies without defenses</td>\n<td id=\"A6.T14.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">MA</td>\n<td id=\"A6.T14.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T14.3.1\" class=\"ltx_tr\">\n<td id=\"A6.T14.3.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">1:</td>\n<td id=\"A6.T14.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Global model <math id=\"A6.T14.3.1.1.m1.1\" class=\"ltx_Math\" alttext=\"G^{r}\" display=\"inline\"><semantics id=\"A6.T14.3.1.1.m1.1a\"><msup id=\"A6.T14.3.1.1.m1.1.1\" xref=\"A6.T14.3.1.1.m1.1.1.cmml\"><mi id=\"A6.T14.3.1.1.m1.1.1.2\" xref=\"A6.T14.3.1.1.m1.1.1.2.cmml\">G</mi><mi id=\"A6.T14.3.1.1.m1.1.1.3\" xref=\"A6.T14.3.1.1.m1.1.1.3.cmml\">r</mi></msup><annotation-xml encoding=\"MathML-Content\" id=\"A6.T14.3.1.1.m1.1b\"><apply id=\"A6.T14.3.1.1.m1.1.1.cmml\" xref=\"A6.T14.3.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"A6.T14.3.1.1.m1.1.1.1.cmml\" xref=\"A6.T14.3.1.1.m1.1.1\">superscript</csymbol><ci id=\"A6.T14.3.1.1.m1.1.1.2.cmml\" xref=\"A6.T14.3.1.1.m1.1.1.2\">ùê∫</ci><ci id=\"A6.T14.3.1.1.m1.1.1.3.cmml\" xref=\"A6.T14.3.1.1.m1.1.1.3\">ùëü</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T14.3.1.1.m1.1c\">G^{r}</annotation></semantics></math>\n</td>\n<td id=\"A6.T14.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">62.99</td>\n<td id=\"A6.T14.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">1.93</td>\n</tr>\n<tr id=\"A6.T14.3.3\" class=\"ltx_tr\">\n<td id=\"A6.T14.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">2:</td>\n<td id=\"A6.T14.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Average of benign local models</td>\n<td id=\"A6.T14.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">47.15</td>\n<td id=\"A6.T14.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">6.82</td>\n</tr>\n<tr id=\"A6.T14.3.4\" class=\"ltx_tr\">\n<td id=\"A6.T14.3.4.1\" class=\"ltx_td ltx_align_left\">3:</td>\n<td id=\"A6.T14.3.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Average of poisoned local models</td>\n<td id=\"A6.T14.3.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">61.27</td>\n<td id=\"A6.T14.3.4.4\" class=\"ltx_td ltx_align_center\">78.68</td>\n</tr>\n<tr id=\"A6.T14.3.5\" class=\"ltx_tr\">\n<td id=\"A6.T14.3.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\">4:</td>\n<td id=\"A6.T14.3.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T14.3.5.2.1\" class=\"ltx_text\">FedAVG</span> with benign local models</td>\n<td id=\"A6.T14.3.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">65.92</td>\n<td id=\"A6.T14.3.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">1.40</td>\n</tr>\n<tr id=\"A6.T14.3.6\" class=\"ltx_tr\">\n<td id=\"A6.T14.3.6.1\" class=\"ltx_td ltx_align_left\">5:</td>\n<td id=\"A6.T14.3.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T14.3.6.2.1\" class=\"ltx_text\">FedAVG</span> with poisoned local models</td>\n<td id=\"A6.T14.3.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">42.53</td>\n<td id=\"A6.T14.3.6.4\" class=\"ltx_td ltx_align_center\">95.03</td>\n</tr>\n<tr id=\"A6.T14.3.7\" class=\"ltx_tr\">\n<td id=\"A6.T14.3.7.1\" class=\"ltx_td ltx_align_left ltx_border_t\">6:</td>\n<td id=\"A6.T14.3.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T14.3.7.2.1\" class=\"ltx_text\">FedAVG</span> with all local models</td>\n<td id=\"A6.T14.3.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">60.38</td>\n<td id=\"A6.T14.3.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">55.28</td>\n</tr>\n<tr id=\"A6.T14.3.8\" class=\"ltx_tr\">\n<td id=\"A6.T14.3.8.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\" colspan=\"2\">Global model accuracies after applying defenses</td>\n<td id=\"A6.T14.3.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\">MA</td>\n<td id=\"A6.T14.3.8.3\" class=\"ltx_td ltx_align_center ltx_border_tt ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T14.3.9\" class=\"ltx_tr\">\n<td id=\"A6.T14.3.9.1\" class=\"ltx_td ltx_align_left ltx_border_t\">7:</td>\n<td id=\"A6.T14.3.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Na√Øve Clustering</td>\n<td id=\"A6.T14.3.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">65.92</td>\n<td id=\"A6.T14.3.9.4\" class=\"ltx_td ltx_align_center ltx_border_t\">1.44</td>\n</tr>\n<tr id=\"A6.T14.3.10\" class=\"ltx_tr\">\n<td id=\"A6.T14.3.10.1\" class=\"ltx_td ltx_align_left\">8:</td>\n<td id=\"A6.T14.3.10.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FoolsGold¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Fung et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>\n</td>\n<td id=\"A6.T14.3.10.3\" class=\"ltx_td ltx_align_center ltx_border_r\">64.86</td>\n<td id=\"A6.T14.3.10.4\" class=\"ltx_td ltx_align_center\">1.75</td>\n</tr>\n<tr id=\"A6.T14.3.11\" class=\"ltx_tr\">\n<td id=\"A6.T14.3.11.1\" class=\"ltx_td ltx_align_left\">9:</td>\n<td id=\"A6.T14.3.11.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Krum¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T14.3.11.3\" class=\"ltx_td ltx_align_center ltx_border_r\">23.13</td>\n<td id=\"A6.T14.3.11.4\" class=\"ltx_td ltx_align_center\">84.58</td>\n</tr>\n<tr id=\"A6.T14.3.12\" class=\"ltx_tr\">\n<td id=\"A6.T14.3.12.1\" class=\"ltx_td ltx_align_left\">10:</td>\n<td id=\"A6.T14.3.12.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T14.3.12.2.1\" class=\"ltx_text\">M-Krum</span>¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T14.3.12.3\" class=\"ltx_td ltx_align_center ltx_border_r\">35.39</td>\n<td id=\"A6.T14.3.12.4\" class=\"ltx_td ltx_align_center\">90.44</td>\n</tr>\n<tr id=\"A6.T14.3.13\" class=\"ltx_tr\">\n<td id=\"A6.T14.3.13.1\" class=\"ltx_td ltx_align_left\">11:</td>\n<td id=\"A6.T14.3.13.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T14.3.13.3\" class=\"ltx_td ltx_align_center ltx_border_r\">60.84</td>\n<td id=\"A6.T14.3.13.4\" class=\"ltx_td ltx_align_center\">53.96</td>\n</tr>\n<tr id=\"A6.T14.3.14\" class=\"ltx_tr\">\n<td id=\"A6.T14.3.14.1\" class=\"ltx_td ltx_align_left\">12:</td>\n<td id=\"A6.T14.3.14.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip&amp;Noise¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T14.3.14.3\" class=\"ltx_td ltx_align_center ltx_border_r\">40.94</td>\n<td id=\"A6.T14.3.14.4\" class=\"ltx_td ltx_align_center\">80.35</td>\n</tr>\n<tr id=\"A6.T14.3.15\" class=\"ltx_tr\">\n<td id=\"A6.T14.3.15.1\" class=\"ltx_td ltx_align_left\">13:</td>\n<td id=\"A6.T14.3.15.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Flame¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Nguyen et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib69\" title=\"\" class=\"ltx_ref\">2022c</a>)</cite>\n</td>\n<td id=\"A6.T14.3.15.3\" class=\"ltx_td ltx_align_center ltx_border_r\">62.33</td>\n<td id=\"A6.T14.3.15.4\" class=\"ltx_td ltx_align_center\">4.07</td>\n</tr>\n<tr id=\"A6.T14.3.16\" class=\"ltx_tr\">\n<td id=\"A6.T14.3.16.1\" class=\"ltx_td ltx_align_left\">14:</td>\n<td id=\"A6.T14.3.16.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Mean¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T14.3.16.3\" class=\"ltx_td ltx_align_center ltx_border_r\">58.91</td>\n<td id=\"A6.T14.3.16.4\" class=\"ltx_td ltx_align_center\">57.82</td>\n</tr>\n<tr id=\"A6.T14.3.17\" class=\"ltx_tr\">\n<td id=\"A6.T14.3.17.1\" class=\"ltx_td ltx_align_left\">15:</td>\n<td id=\"A6.T14.3.17.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Median¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T14.3.17.3\" class=\"ltx_td ltx_align_center ltx_border_r\">33.96</td>\n<td id=\"A6.T14.3.17.4\" class=\"ltx_td ltx_align_center\">50.51</td>\n</tr>\n<tr id=\"A6.T14.3.18\" class=\"ltx_tr\">\n<td id=\"A6.T14.3.18.1\" class=\"ltx_td ltx_align_left\">16:</td>\n<td id=\"A6.T14.3.18.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FLTrust¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Cao et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib14\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>\n</td>\n<td id=\"A6.T14.3.18.3\" class=\"ltx_td ltx_align_center ltx_border_r\">59.83</td>\n<td id=\"A6.T14.3.18.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T14.3.18.4.1\" class=\"ltx_text ltx_font_bold\">21.46</span></td>\n</tr>\n<tr id=\"A6.T14.3.19\" class=\"ltx_tr\">\n<td id=\"A6.T14.3.19.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">17:</td>\n<td id=\"A6.T14.3.19.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"A6.T14.3.19.2.1\" class=\"ltx_text ltx_font_bold\">MESAS</span></td>\n<td id=\"A6.T14.3.19.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">66.47</td>\n<td id=\"A6.T14.3.19.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"A6.T14.3.19.4.1\" class=\"ltx_text ltx_font_bold\">1.45</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In this section, we provide further results for our experiments, that could not be included in the main part of the paper due to space limitations. We selected the most interesting and representative results to be part of the main part, but report the rest below for completeness.",
                "Tab.¬†",
                "4",
                " reports the MAs corresponding to the BAs and ACCs in ",
                "Tab.¬†",
                "2",
                " for different poisoning methods without adaptive adversaries. Note, that ",
                "MESAS",
                " provides high MA independent of the applied poisoning attack. The table shows, that ",
                "MESAS",
                " does not negatively impact the MA and is also effective against untargeted attacks.",
                "Tab.¬†",
                "5",
                " shows the results for our default scenario with scaled poisoned models regarding the Euclidean distance of updates. The results confirm, that scaling can increase the BA. ",
                "MESAS",
                " is already efficient for the unscaled version visualized in scenario  ",
                "1",
                " in ",
                "Tab.¬†",
                "1",
                ", hence is also effective for scaled models due to the intuition visualized in ",
                "Fig.¬†",
                "4",
                ". ",
                "Tab.¬†",
                "6",
                " depicts the results for the default scenario with a PDR of 0.3 for scaled poisoned models.",
                "We conducted an attack leveraging our strong adaptive adversary against FoolsGold¬†",
                "(Fung et¬†al",
                ".",
                ", ",
                "2020",
                ")",
                " and report the result in ",
                "Tab.¬†",
                "7",
                ". As strategy, we first trained a benign local model and transferred the trained parameters of the last layer to a fresh local model. We then excluded the parameters form training and poisoned the local model forcing the backdoor into some other layers. In ",
                "Tab.¬†",
                "8",
                " we additionally applied scaling. We can observe, that the BA of FoolsGold can be increased with those methods.",
                "Scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                " shows the result after adapting to Krum scores¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                " in an unscaled and scaled version. We forced the Euclidean distance between poisoned models and the global model to be similar to each other and on a benign level so that the defenses decide in favor of the poisoned models. ",
                "Fig.¬†",
                "12",
                " depicts the Krum scores for the default scenario associated with the default scenario in ",
                "Tab.¬†",
                "1",
                " to show, that the effective backdoor is based on coincidence and not intentionally forced by the attacker. With slight changes in some models, Krum could also decide for a benign model. However, after adaption, we can introduce a high BA intentionally in scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                ".",
                "Tab.¬†",
                "10",
                " and ",
                "Tab.¬†",
                "11",
                " show the results for a classical ",
                "intra-client",
                " ",
                "non-IID",
                " scenario crafted by ",
                "1-class",
                " ",
                "non-IID",
                " with ",
                "q",
                "=",
                "0.5",
                "ùëû",
                "0.5",
                "q=0.5",
                ". In both cases, ",
                "MESAS",
                " reduces the BA reliably with only one FP, while other defenses allow the attacker to embed 34.72% to 49.47% BA. ",
                "Tab.¬†",
                "12",
                " depicts the results for an increased PDR of 0.3, allowing the adversary to reach a BA of 57.68% without defense and up to 92.86% under active defenses. ",
                "MESAS",
                " still removes the poisoned models most effectively with only two FPs.",
                "In ",
                "Tab.¬†",
                "13",
                " and ",
                "Tab.¬†",
                "13",
                " we adapt all malicious models to a central benign value regarding the Cosine distance to the global model, which has the effect, that the models are inconspicuous in Krum scores, hence can circumvent Krum and ",
                "M-Krum",
                "¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                ", while ",
                "MESAS",
                " still erases the backdoor with only two FPs.",
                "Tab.¬†",
                "15",
                " and ",
                "Tab.¬†",
                "16",
                " show the results in a ",
                "inter-client",
                " ",
                "non-IID",
                " scenario based on our ",
                "Random-Non-IID",
                " strategy for a model in FL round one and highlights, that ",
                "MESAS",
                " outperforms other defenses in reducing the BA of the new global model.\n",
                "Tab.¬†",
                "17",
                " and ",
                "Tab.¬†",
                "18",
                " show the results for a setting in round 50,w here 100 clients are part of the federation and 20 clients are selected randomly in each round for training. Due to the later rounds, ",
                "MESAS",
                " is even more effective than other defenses and reduces the BA to a minimum.",
                "Tab.¬†",
                "19",
                " and ",
                "Tab.¬†",
                "20",
                " show the experiments results with a CNN training on MNIST¬†",
                "(Deng, ",
                "2012",
                ")",
                " and SqueezeNet¬†",
                "(Iandola et¬†al",
                ".",
                ", ",
                "2016",
                ")",
                " training on ",
                "CIFAR-10",
                " ",
                "(Krizhevsky et¬†al",
                ".",
                ", ",
                "2009",
                ")",
                ". The CNN consists of two convolutional layers, the first with 32 output layers, the second with 64 output layers, both applying a kernel size of 5. The output of the convolutional layers traverse a ReLU¬†",
                "(Agarap, ",
                "2018",
                ")",
                " and a 2D pooling layer, before being fed into three fully connected layers with output size 512, 256 and 10 output respectively. In both experiments, we used a ",
                "self-pre-trained",
                " model as global model. We can report perfect detection rate with just one FP for CNN and SqueezeNet, even if the backdoor is not yet embedded in the global model. Hence, a stronger adaption by the adversary would strengthen the detection capabilities of ",
                "MESAS",
                ". Other defenses instead can be circumvented by the adaptive adversary."
            ]
        ]
    },
    "A6.T15": {
        "caption": "Table 15. MA and BA in the default scenario with inter-client non-IID based on our Random-Non-IID strategy with a model in FL round one in percent.",
        "table": "<table id=\"A6.T15.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A6.T15.1.2\" class=\"ltx_tr\">\n<td id=\"A6.T15.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\">Accuracies without defenses</td>\n<td id=\"A6.T15.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">MA</td>\n<td id=\"A6.T15.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T15.1.1\" class=\"ltx_tr\">\n<td id=\"A6.T15.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">1:</td>\n<td id=\"A6.T15.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Global model <math id=\"A6.T15.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"G^{r}\" display=\"inline\"><semantics id=\"A6.T15.1.1.1.m1.1a\"><msup id=\"A6.T15.1.1.1.m1.1.1\" xref=\"A6.T15.1.1.1.m1.1.1.cmml\"><mi id=\"A6.T15.1.1.1.m1.1.1.2\" xref=\"A6.T15.1.1.1.m1.1.1.2.cmml\">G</mi><mi id=\"A6.T15.1.1.1.m1.1.1.3\" xref=\"A6.T15.1.1.1.m1.1.1.3.cmml\">r</mi></msup><annotation-xml encoding=\"MathML-Content\" id=\"A6.T15.1.1.1.m1.1b\"><apply id=\"A6.T15.1.1.1.m1.1.1.cmml\" xref=\"A6.T15.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"A6.T15.1.1.1.m1.1.1.1.cmml\" xref=\"A6.T15.1.1.1.m1.1.1\">superscript</csymbol><ci id=\"A6.T15.1.1.1.m1.1.1.2.cmml\" xref=\"A6.T15.1.1.1.m1.1.1.2\">ùê∫</ci><ci id=\"A6.T15.1.1.1.m1.1.1.3.cmml\" xref=\"A6.T15.1.1.1.m1.1.1.3\">ùëü</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T15.1.1.1.m1.1c\">G^{r}</annotation></semantics></math>\n</td>\n<td id=\"A6.T15.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">59.52</td>\n<td id=\"A6.T15.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">8.17</td>\n</tr>\n<tr id=\"A6.T15.1.3\" class=\"ltx_tr\">\n<td id=\"A6.T15.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">2:</td>\n<td id=\"A6.T15.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Average of benign local models</td>\n<td id=\"A6.T15.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">35.05</td>\n<td id=\"A6.T15.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">14.38</td>\n</tr>\n<tr id=\"A6.T15.1.4\" class=\"ltx_tr\">\n<td id=\"A6.T15.1.4.1\" class=\"ltx_td ltx_align_left\">3:</td>\n<td id=\"A6.T15.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Average of poisoned local models</td>\n<td id=\"A6.T15.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">34.29</td>\n<td id=\"A6.T15.1.4.4\" class=\"ltx_td ltx_align_center\">82.94</td>\n</tr>\n<tr id=\"A6.T15.1.5\" class=\"ltx_tr\">\n<td id=\"A6.T15.1.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\">4:</td>\n<td id=\"A6.T15.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T15.1.5.2.1\" class=\"ltx_text\">FedAVG</span> with benign local models</td>\n<td id=\"A6.T15.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">36.09</td>\n<td id=\"A6.T15.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">37.97</td>\n</tr>\n<tr id=\"A6.T15.1.6\" class=\"ltx_tr\">\n<td id=\"A6.T15.1.6.1\" class=\"ltx_td ltx_align_left\">5:</td>\n<td id=\"A6.T15.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T15.1.6.2.1\" class=\"ltx_text\">FedAVG</span> with poisoned local models</td>\n<td id=\"A6.T15.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">21.49</td>\n<td id=\"A6.T15.1.6.4\" class=\"ltx_td ltx_align_center\">98.72</td>\n</tr>\n<tr id=\"A6.T15.1.7\" class=\"ltx_tr\">\n<td id=\"A6.T15.1.7.1\" class=\"ltx_td ltx_align_left ltx_border_t\">6:</td>\n<td id=\"A6.T15.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T15.1.7.2.1\" class=\"ltx_text\">FedAVG</span> with all local models</td>\n<td id=\"A6.T15.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">32.57</td>\n<td id=\"A6.T15.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">80.85</td>\n</tr>\n<tr id=\"A6.T15.1.8\" class=\"ltx_tr\">\n<td id=\"A6.T15.1.8.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\" colspan=\"2\">Global model accuracies after applying defenses</td>\n<td id=\"A6.T15.1.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\">MA</td>\n<td id=\"A6.T15.1.8.3\" class=\"ltx_td ltx_align_center ltx_border_tt ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T15.1.9\" class=\"ltx_tr\">\n<td id=\"A6.T15.1.9.1\" class=\"ltx_td ltx_align_left ltx_border_t\">7:</td>\n<td id=\"A6.T15.1.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Na√Øve Clustering</td>\n<td id=\"A6.T15.1.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">32.68</td>\n<td id=\"A6.T15.1.9.4\" class=\"ltx_td ltx_align_center ltx_border_t\">54.84</td>\n</tr>\n<tr id=\"A6.T15.1.10\" class=\"ltx_tr\">\n<td id=\"A6.T15.1.10.1\" class=\"ltx_td ltx_align_left\">8:</td>\n<td id=\"A6.T15.1.10.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FoolsGold¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Fung et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>\n</td>\n<td id=\"A6.T15.1.10.3\" class=\"ltx_td ltx_align_center ltx_border_r\">30.14</td>\n<td id=\"A6.T15.1.10.4\" class=\"ltx_td ltx_align_center\">87.66</td>\n</tr>\n<tr id=\"A6.T15.1.11\" class=\"ltx_tr\">\n<td id=\"A6.T15.1.11.1\" class=\"ltx_td ltx_align_left\">9:</td>\n<td id=\"A6.T15.1.11.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Krum¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T15.1.11.3\" class=\"ltx_td ltx_align_center ltx_border_r\">19.28</td>\n<td id=\"A6.T15.1.11.4\" class=\"ltx_td ltx_align_center\">80.82</td>\n</tr>\n<tr id=\"A6.T15.1.12\" class=\"ltx_tr\">\n<td id=\"A6.T15.1.12.1\" class=\"ltx_td ltx_align_left\">10:</td>\n<td id=\"A6.T15.1.12.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T15.1.12.2.1\" class=\"ltx_text\">M-Krum</span>¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T15.1.12.3\" class=\"ltx_td ltx_align_center ltx_border_r\">10.05</td>\n<td id=\"A6.T15.1.12.4\" class=\"ltx_td ltx_align_center\">99.96</td>\n</tr>\n<tr id=\"A6.T15.1.13\" class=\"ltx_tr\">\n<td id=\"A6.T15.1.13.1\" class=\"ltx_td ltx_align_left\">11:</td>\n<td id=\"A6.T15.1.13.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T15.1.13.3\" class=\"ltx_td ltx_align_center ltx_border_r\">32.88</td>\n<td id=\"A6.T15.1.13.4\" class=\"ltx_td ltx_align_center\">79.82</td>\n</tr>\n<tr id=\"A6.T15.1.14\" class=\"ltx_tr\">\n<td id=\"A6.T15.1.14.1\" class=\"ltx_td ltx_align_left\">12:</td>\n<td id=\"A6.T15.1.14.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip&amp;Noise¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T15.1.14.3\" class=\"ltx_td ltx_align_center ltx_border_r\">25.63</td>\n<td id=\"A6.T15.1.14.4\" class=\"ltx_td ltx_align_center\">88.33</td>\n</tr>\n<tr id=\"A6.T15.1.15\" class=\"ltx_tr\">\n<td id=\"A6.T15.1.15.1\" class=\"ltx_td ltx_align_left\">13:</td>\n<td id=\"A6.T15.1.15.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Flame¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Nguyen et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib69\" title=\"\" class=\"ltx_ref\">2022c</a>)</cite>\n</td>\n<td id=\"A6.T15.1.15.3\" class=\"ltx_td ltx_align_center ltx_border_r\">10.23</td>\n<td id=\"A6.T15.1.15.4\" class=\"ltx_td ltx_align_center\">99.66</td>\n</tr>\n<tr id=\"A6.T15.1.16\" class=\"ltx_tr\">\n<td id=\"A6.T15.1.16.1\" class=\"ltx_td ltx_align_left\">14:</td>\n<td id=\"A6.T15.1.16.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Mean¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T15.1.16.3\" class=\"ltx_td ltx_align_center ltx_border_r\">33.21</td>\n<td id=\"A6.T15.1.16.4\" class=\"ltx_td ltx_align_center\">76.28</td>\n</tr>\n<tr id=\"A6.T15.1.17\" class=\"ltx_tr\">\n<td id=\"A6.T15.1.17.1\" class=\"ltx_td ltx_align_left\">15:</td>\n<td id=\"A6.T15.1.17.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Median¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T15.1.17.3\" class=\"ltx_td ltx_align_center ltx_border_r\">21.10</td>\n<td id=\"A6.T15.1.17.4\" class=\"ltx_td ltx_align_center\">62.05</td>\n</tr>\n<tr id=\"A6.T15.1.18\" class=\"ltx_tr\">\n<td id=\"A6.T15.1.18.1\" class=\"ltx_td ltx_align_left\">16:</td>\n<td id=\"A6.T15.1.18.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FLTrust¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Cao et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib14\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>\n</td>\n<td id=\"A6.T15.1.18.3\" class=\"ltx_td ltx_align_center ltx_border_r\">57.27</td>\n<td id=\"A6.T15.1.18.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T15.1.18.4.1\" class=\"ltx_text ltx_font_bold\">23.02</span></td>\n</tr>\n<tr id=\"A6.T15.1.19\" class=\"ltx_tr\">\n<td id=\"A6.T15.1.19.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">17:</td>\n<td id=\"A6.T15.1.19.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"A6.T15.1.19.2.1\" class=\"ltx_text ltx_font_bold\">MESAS</span></td>\n<td id=\"A6.T15.1.19.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">35.08</td>\n<td id=\"A6.T15.1.19.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"A6.T15.1.19.4.1\" class=\"ltx_text ltx_font_bold\">41.64</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In this section, we provide further results for our experiments, that could not be included in the main part of the paper due to space limitations. We selected the most interesting and representative results to be part of the main part, but report the rest below for completeness.",
                "Tab.¬†",
                "4",
                " reports the MAs corresponding to the BAs and ACCs in ",
                "Tab.¬†",
                "2",
                " for different poisoning methods without adaptive adversaries. Note, that ",
                "MESAS",
                " provides high MA independent of the applied poisoning attack. The table shows, that ",
                "MESAS",
                " does not negatively impact the MA and is also effective against untargeted attacks.",
                "Tab.¬†",
                "5",
                " shows the results for our default scenario with scaled poisoned models regarding the Euclidean distance of updates. The results confirm, that scaling can increase the BA. ",
                "MESAS",
                " is already efficient for the unscaled version visualized in scenario  ",
                "1",
                " in ",
                "Tab.¬†",
                "1",
                ", hence is also effective for scaled models due to the intuition visualized in ",
                "Fig.¬†",
                "4",
                ". ",
                "Tab.¬†",
                "6",
                " depicts the results for the default scenario with a PDR of 0.3 for scaled poisoned models.",
                "We conducted an attack leveraging our strong adaptive adversary against FoolsGold¬†",
                "(Fung et¬†al",
                ".",
                ", ",
                "2020",
                ")",
                " and report the result in ",
                "Tab.¬†",
                "7",
                ". As strategy, we first trained a benign local model and transferred the trained parameters of the last layer to a fresh local model. We then excluded the parameters form training and poisoned the local model forcing the backdoor into some other layers. In ",
                "Tab.¬†",
                "8",
                " we additionally applied scaling. We can observe, that the BA of FoolsGold can be increased with those methods.",
                "Scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                " shows the result after adapting to Krum scores¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                " in an unscaled and scaled version. We forced the Euclidean distance between poisoned models and the global model to be similar to each other and on a benign level so that the defenses decide in favor of the poisoned models. ",
                "Fig.¬†",
                "12",
                " depicts the Krum scores for the default scenario associated with the default scenario in ",
                "Tab.¬†",
                "1",
                " to show, that the effective backdoor is based on coincidence and not intentionally forced by the attacker. With slight changes in some models, Krum could also decide for a benign model. However, after adaption, we can introduce a high BA intentionally in scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                ".",
                "Tab.¬†",
                "10",
                " and ",
                "Tab.¬†",
                "11",
                " show the results for a classical ",
                "intra-client",
                " ",
                "non-IID",
                " scenario crafted by ",
                "1-class",
                " ",
                "non-IID",
                " with ",
                "q",
                "=",
                "0.5",
                "ùëû",
                "0.5",
                "q=0.5",
                ". In both cases, ",
                "MESAS",
                " reduces the BA reliably with only one FP, while other defenses allow the attacker to embed 34.72% to 49.47% BA. ",
                "Tab.¬†",
                "12",
                " depicts the results for an increased PDR of 0.3, allowing the adversary to reach a BA of 57.68% without defense and up to 92.86% under active defenses. ",
                "MESAS",
                " still removes the poisoned models most effectively with only two FPs.",
                "In ",
                "Tab.¬†",
                "13",
                " and ",
                "Tab.¬†",
                "13",
                " we adapt all malicious models to a central benign value regarding the Cosine distance to the global model, which has the effect, that the models are inconspicuous in Krum scores, hence can circumvent Krum and ",
                "M-Krum",
                "¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                ", while ",
                "MESAS",
                " still erases the backdoor with only two FPs.",
                "Tab.¬†",
                "15",
                " and ",
                "Tab.¬†",
                "16",
                " show the results in a ",
                "inter-client",
                " ",
                "non-IID",
                " scenario based on our ",
                "Random-Non-IID",
                " strategy for a model in FL round one and highlights, that ",
                "MESAS",
                " outperforms other defenses in reducing the BA of the new global model.\n",
                "Tab.¬†",
                "17",
                " and ",
                "Tab.¬†",
                "18",
                " show the results for a setting in round 50,w here 100 clients are part of the federation and 20 clients are selected randomly in each round for training. Due to the later rounds, ",
                "MESAS",
                " is even more effective than other defenses and reduces the BA to a minimum.",
                "Tab.¬†",
                "19",
                " and ",
                "Tab.¬†",
                "20",
                " show the experiments results with a CNN training on MNIST¬†",
                "(Deng, ",
                "2012",
                ")",
                " and SqueezeNet¬†",
                "(Iandola et¬†al",
                ".",
                ", ",
                "2016",
                ")",
                " training on ",
                "CIFAR-10",
                " ",
                "(Krizhevsky et¬†al",
                ".",
                ", ",
                "2009",
                ")",
                ". The CNN consists of two convolutional layers, the first with 32 output layers, the second with 64 output layers, both applying a kernel size of 5. The output of the convolutional layers traverse a ReLU¬†",
                "(Agarap, ",
                "2018",
                ")",
                " and a 2D pooling layer, before being fed into three fully connected layers with output size 512, 256 and 10 output respectively. In both experiments, we used a ",
                "self-pre-trained",
                " model as global model. We can report perfect detection rate with just one FP for CNN and SqueezeNet, even if the backdoor is not yet embedded in the global model. Hence, a stronger adaption by the adversary would strengthen the detection capabilities of ",
                "MESAS",
                ". Other defenses instead can be circumvented by the adaptive adversary."
            ]
        ]
    },
    "A6.T16": {
        "caption": "Table 16. MA and BA in the default scenario with inter-client non-IID based on our Random-Non-IID strategy with a model in FL round one and scaled\npoisoned models regarding the Euclidean distance of updates in percent.",
        "table": "<table id=\"A6.T16.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A6.T16.1.2\" class=\"ltx_tr\">\n<td id=\"A6.T16.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\">Accuracies without defenses</td>\n<td id=\"A6.T16.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">MA</td>\n<td id=\"A6.T16.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T16.1.1\" class=\"ltx_tr\">\n<td id=\"A6.T16.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">1:</td>\n<td id=\"A6.T16.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Global model <math id=\"A6.T16.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"G^{r}\" display=\"inline\"><semantics id=\"A6.T16.1.1.1.m1.1a\"><msup id=\"A6.T16.1.1.1.m1.1.1\" xref=\"A6.T16.1.1.1.m1.1.1.cmml\"><mi id=\"A6.T16.1.1.1.m1.1.1.2\" xref=\"A6.T16.1.1.1.m1.1.1.2.cmml\">G</mi><mi id=\"A6.T16.1.1.1.m1.1.1.3\" xref=\"A6.T16.1.1.1.m1.1.1.3.cmml\">r</mi></msup><annotation-xml encoding=\"MathML-Content\" id=\"A6.T16.1.1.1.m1.1b\"><apply id=\"A6.T16.1.1.1.m1.1.1.cmml\" xref=\"A6.T16.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"A6.T16.1.1.1.m1.1.1.1.cmml\" xref=\"A6.T16.1.1.1.m1.1.1\">superscript</csymbol><ci id=\"A6.T16.1.1.1.m1.1.1.2.cmml\" xref=\"A6.T16.1.1.1.m1.1.1.2\">ùê∫</ci><ci id=\"A6.T16.1.1.1.m1.1.1.3.cmml\" xref=\"A6.T16.1.1.1.m1.1.1.3\">ùëü</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T16.1.1.1.m1.1c\">G^{r}</annotation></semantics></math>\n</td>\n<td id=\"A6.T16.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">59.52</td>\n<td id=\"A6.T16.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">8.17</td>\n</tr>\n<tr id=\"A6.T16.1.3\" class=\"ltx_tr\">\n<td id=\"A6.T16.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">2:</td>\n<td id=\"A6.T16.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Average of benign local models</td>\n<td id=\"A6.T16.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">35.05</td>\n<td id=\"A6.T16.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">14.38</td>\n</tr>\n<tr id=\"A6.T16.1.4\" class=\"ltx_tr\">\n<td id=\"A6.T16.1.4.1\" class=\"ltx_td ltx_align_left\">3:</td>\n<td id=\"A6.T16.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Average of poisoned local models</td>\n<td id=\"A6.T16.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">34.29</td>\n<td id=\"A6.T16.1.4.4\" class=\"ltx_td ltx_align_center\">82.94</td>\n</tr>\n<tr id=\"A6.T16.1.5\" class=\"ltx_tr\">\n<td id=\"A6.T16.1.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\">4:</td>\n<td id=\"A6.T16.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T16.1.5.2.1\" class=\"ltx_text\">FedAVG</span> with benign local models</td>\n<td id=\"A6.T16.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">36.09</td>\n<td id=\"A6.T16.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">37.97</td>\n</tr>\n<tr id=\"A6.T16.1.6\" class=\"ltx_tr\">\n<td id=\"A6.T16.1.6.1\" class=\"ltx_td ltx_align_left\">5:</td>\n<td id=\"A6.T16.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T16.1.6.2.1\" class=\"ltx_text\">FedAVG</span> with poisoned local models</td>\n<td id=\"A6.T16.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">17.38</td>\n<td id=\"A6.T16.1.6.4\" class=\"ltx_td ltx_align_center\">99.24</td>\n</tr>\n<tr id=\"A6.T16.1.7\" class=\"ltx_tr\">\n<td id=\"A6.T16.1.7.1\" class=\"ltx_td ltx_align_left ltx_border_t\">6:</td>\n<td id=\"A6.T16.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T16.1.7.2.1\" class=\"ltx_text\">FedAVG</span> with all local models</td>\n<td id=\"A6.T16.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">30.19</td>\n<td id=\"A6.T16.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">85.41</td>\n</tr>\n<tr id=\"A6.T16.1.8\" class=\"ltx_tr\">\n<td id=\"A6.T16.1.8.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\" colspan=\"2\">Global model accuracies after applying defenses</td>\n<td id=\"A6.T16.1.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\">MA</td>\n<td id=\"A6.T16.1.8.3\" class=\"ltx_td ltx_align_center ltx_border_tt ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T16.1.9\" class=\"ltx_tr\">\n<td id=\"A6.T16.1.9.1\" class=\"ltx_td ltx_align_left ltx_border_t\">7:</td>\n<td id=\"A6.T16.1.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Na√Øve Clustering</td>\n<td id=\"A6.T16.1.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">31.59</td>\n<td id=\"A6.T16.1.9.4\" class=\"ltx_td ltx_align_center ltx_border_t\">56.90</td>\n</tr>\n<tr id=\"A6.T16.1.10\" class=\"ltx_tr\">\n<td id=\"A6.T16.1.10.1\" class=\"ltx_td ltx_align_left\">8:</td>\n<td id=\"A6.T16.1.10.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FoolsGold¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Fung et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>\n</td>\n<td id=\"A6.T16.1.10.3\" class=\"ltx_td ltx_align_center ltx_border_r\">26.93</td>\n<td id=\"A6.T16.1.10.4\" class=\"ltx_td ltx_align_center\">92.20</td>\n</tr>\n<tr id=\"A6.T16.1.11\" class=\"ltx_tr\">\n<td id=\"A6.T16.1.11.1\" class=\"ltx_td ltx_align_left\">9:</td>\n<td id=\"A6.T16.1.11.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Krum¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T16.1.11.3\" class=\"ltx_td ltx_align_center ltx_border_r\">24.27</td>\n<td id=\"A6.T16.1.11.4\" class=\"ltx_td ltx_align_center\">38.53</td>\n</tr>\n<tr id=\"A6.T16.1.12\" class=\"ltx_tr\">\n<td id=\"A6.T16.1.12.1\" class=\"ltx_td ltx_align_left\">10:</td>\n<td id=\"A6.T16.1.12.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T16.1.12.2.1\" class=\"ltx_text\">M-Krum</span>¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T16.1.12.3\" class=\"ltx_td ltx_align_center ltx_border_r\">10.00</td>\n<td id=\"A6.T16.1.12.4\" class=\"ltx_td ltx_align_center\">100.00</td>\n</tr>\n<tr id=\"A6.T16.1.13\" class=\"ltx_tr\">\n<td id=\"A6.T16.1.13.1\" class=\"ltx_td ltx_align_left\">11:</td>\n<td id=\"A6.T16.1.13.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T16.1.13.3\" class=\"ltx_td ltx_align_center ltx_border_r\">30.61</td>\n<td id=\"A6.T16.1.13.4\" class=\"ltx_td ltx_align_center\">84.32</td>\n</tr>\n<tr id=\"A6.T16.1.14\" class=\"ltx_tr\">\n<td id=\"A6.T16.1.14.1\" class=\"ltx_td ltx_align_left\">12:</td>\n<td id=\"A6.T16.1.14.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip&amp;Noise¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T16.1.14.3\" class=\"ltx_td ltx_align_center ltx_border_r\">23.47</td>\n<td id=\"A6.T16.1.14.4\" class=\"ltx_td ltx_align_center\">94.51</td>\n</tr>\n<tr id=\"A6.T16.1.15\" class=\"ltx_tr\">\n<td id=\"A6.T16.1.15.1\" class=\"ltx_td ltx_align_left\">13:</td>\n<td id=\"A6.T16.1.15.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Flame¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Nguyen et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib69\" title=\"\" class=\"ltx_ref\">2022c</a>)</cite>\n</td>\n<td id=\"A6.T16.1.15.3\" class=\"ltx_td ltx_align_center ltx_border_r\">17.16</td>\n<td id=\"A6.T16.1.15.4\" class=\"ltx_td ltx_align_center\">36.53</td>\n</tr>\n<tr id=\"A6.T16.1.16\" class=\"ltx_tr\">\n<td id=\"A6.T16.1.16.1\" class=\"ltx_td ltx_align_left\">14:</td>\n<td id=\"A6.T16.1.16.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Mean¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T16.1.16.3\" class=\"ltx_td ltx_align_center ltx_border_r\">31.89</td>\n<td id=\"A6.T16.1.16.4\" class=\"ltx_td ltx_align_center\">78.20</td>\n</tr>\n<tr id=\"A6.T16.1.17\" class=\"ltx_tr\">\n<td id=\"A6.T16.1.17.1\" class=\"ltx_td ltx_align_left\">15:</td>\n<td id=\"A6.T16.1.17.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Median¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T16.1.17.3\" class=\"ltx_td ltx_align_center ltx_border_r\">20.38</td>\n<td id=\"A6.T16.1.17.4\" class=\"ltx_td ltx_align_center\">60.84</td>\n</tr>\n<tr id=\"A6.T16.1.18\" class=\"ltx_tr\">\n<td id=\"A6.T16.1.18.1\" class=\"ltx_td ltx_align_left\">16:</td>\n<td id=\"A6.T16.1.18.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FLTrust¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Cao et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib14\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>\n</td>\n<td id=\"A6.T16.1.18.3\" class=\"ltx_td ltx_align_center ltx_border_r\">57.02</td>\n<td id=\"A6.T16.1.18.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T16.1.18.4.1\" class=\"ltx_text ltx_font_bold\">23.05</span></td>\n</tr>\n<tr id=\"A6.T16.1.19\" class=\"ltx_tr\">\n<td id=\"A6.T16.1.19.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">17:</td>\n<td id=\"A6.T16.1.19.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"A6.T16.1.19.2.1\" class=\"ltx_text ltx_font_bold\">MESAS</span></td>\n<td id=\"A6.T16.1.19.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">47.29</td>\n<td id=\"A6.T16.1.19.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"A6.T16.1.19.4.1\" class=\"ltx_text ltx_font_bold\">15.58</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In this section, we provide further results for our experiments, that could not be included in the main part of the paper due to space limitations. We selected the most interesting and representative results to be part of the main part, but report the rest below for completeness.",
                "Tab.¬†",
                "4",
                " reports the MAs corresponding to the BAs and ACCs in ",
                "Tab.¬†",
                "2",
                " for different poisoning methods without adaptive adversaries. Note, that ",
                "MESAS",
                " provides high MA independent of the applied poisoning attack. The table shows, that ",
                "MESAS",
                " does not negatively impact the MA and is also effective against untargeted attacks.",
                "Tab.¬†",
                "5",
                " shows the results for our default scenario with scaled poisoned models regarding the Euclidean distance of updates. The results confirm, that scaling can increase the BA. ",
                "MESAS",
                " is already efficient for the unscaled version visualized in scenario  ",
                "1",
                " in ",
                "Tab.¬†",
                "1",
                ", hence is also effective for scaled models due to the intuition visualized in ",
                "Fig.¬†",
                "4",
                ". ",
                "Tab.¬†",
                "6",
                " depicts the results for the default scenario with a PDR of 0.3 for scaled poisoned models.",
                "We conducted an attack leveraging our strong adaptive adversary against FoolsGold¬†",
                "(Fung et¬†al",
                ".",
                ", ",
                "2020",
                ")",
                " and report the result in ",
                "Tab.¬†",
                "7",
                ". As strategy, we first trained a benign local model and transferred the trained parameters of the last layer to a fresh local model. We then excluded the parameters form training and poisoned the local model forcing the backdoor into some other layers. In ",
                "Tab.¬†",
                "8",
                " we additionally applied scaling. We can observe, that the BA of FoolsGold can be increased with those methods.",
                "Scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                " shows the result after adapting to Krum scores¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                " in an unscaled and scaled version. We forced the Euclidean distance between poisoned models and the global model to be similar to each other and on a benign level so that the defenses decide in favor of the poisoned models. ",
                "Fig.¬†",
                "12",
                " depicts the Krum scores for the default scenario associated with the default scenario in ",
                "Tab.¬†",
                "1",
                " to show, that the effective backdoor is based on coincidence and not intentionally forced by the attacker. With slight changes in some models, Krum could also decide for a benign model. However, after adaption, we can introduce a high BA intentionally in scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                ".",
                "Tab.¬†",
                "10",
                " and ",
                "Tab.¬†",
                "11",
                " show the results for a classical ",
                "intra-client",
                " ",
                "non-IID",
                " scenario crafted by ",
                "1-class",
                " ",
                "non-IID",
                " with ",
                "q",
                "=",
                "0.5",
                "ùëû",
                "0.5",
                "q=0.5",
                ". In both cases, ",
                "MESAS",
                " reduces the BA reliably with only one FP, while other defenses allow the attacker to embed 34.72% to 49.47% BA. ",
                "Tab.¬†",
                "12",
                " depicts the results for an increased PDR of 0.3, allowing the adversary to reach a BA of 57.68% without defense and up to 92.86% under active defenses. ",
                "MESAS",
                " still removes the poisoned models most effectively with only two FPs.",
                "In ",
                "Tab.¬†",
                "13",
                " and ",
                "Tab.¬†",
                "13",
                " we adapt all malicious models to a central benign value regarding the Cosine distance to the global model, which has the effect, that the models are inconspicuous in Krum scores, hence can circumvent Krum and ",
                "M-Krum",
                "¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                ", while ",
                "MESAS",
                " still erases the backdoor with only two FPs.",
                "Tab.¬†",
                "15",
                " and ",
                "Tab.¬†",
                "16",
                " show the results in a ",
                "inter-client",
                " ",
                "non-IID",
                " scenario based on our ",
                "Random-Non-IID",
                " strategy for a model in FL round one and highlights, that ",
                "MESAS",
                " outperforms other defenses in reducing the BA of the new global model.\n",
                "Tab.¬†",
                "17",
                " and ",
                "Tab.¬†",
                "18",
                " show the results for a setting in round 50,w here 100 clients are part of the federation and 20 clients are selected randomly in each round for training. Due to the later rounds, ",
                "MESAS",
                " is even more effective than other defenses and reduces the BA to a minimum.",
                "Tab.¬†",
                "19",
                " and ",
                "Tab.¬†",
                "20",
                " show the experiments results with a CNN training on MNIST¬†",
                "(Deng, ",
                "2012",
                ")",
                " and SqueezeNet¬†",
                "(Iandola et¬†al",
                ".",
                ", ",
                "2016",
                ")",
                " training on ",
                "CIFAR-10",
                " ",
                "(Krizhevsky et¬†al",
                ".",
                ", ",
                "2009",
                ")",
                ". The CNN consists of two convolutional layers, the first with 32 output layers, the second with 64 output layers, both applying a kernel size of 5. The output of the convolutional layers traverse a ReLU¬†",
                "(Agarap, ",
                "2018",
                ")",
                " and a 2D pooling layer, before being fed into three fully connected layers with output size 512, 256 and 10 output respectively. In both experiments, we used a ",
                "self-pre-trained",
                " model as global model. We can report perfect detection rate with just one FP for CNN and SqueezeNet, even if the backdoor is not yet embedded in the global model. Hence, a stronger adaption by the adversary would strengthen the detection capabilities of ",
                "MESAS",
                ". Other defenses instead can be circumvented by the adaptive adversary."
            ]
        ]
    },
    "A6.T17": {
        "caption": "Table 17. MA and BA in the default scenario with inter-client non-IID based on our Random-Non-IID strategy with 100 clients in the federation in percent.",
        "table": "<table id=\"A6.T17.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A6.T17.1.2\" class=\"ltx_tr\">\n<td id=\"A6.T17.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\">Accuracies without defenses</td>\n<td id=\"A6.T17.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">MA</td>\n<td id=\"A6.T17.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T17.1.1\" class=\"ltx_tr\">\n<td id=\"A6.T17.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">1:</td>\n<td id=\"A6.T17.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Global model <math id=\"A6.T17.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"G^{r}\" display=\"inline\"><semantics id=\"A6.T17.1.1.1.m1.1a\"><msup id=\"A6.T17.1.1.1.m1.1.1\" xref=\"A6.T17.1.1.1.m1.1.1.cmml\"><mi id=\"A6.T17.1.1.1.m1.1.1.2\" xref=\"A6.T17.1.1.1.m1.1.1.2.cmml\">G</mi><mi id=\"A6.T17.1.1.1.m1.1.1.3\" xref=\"A6.T17.1.1.1.m1.1.1.3.cmml\">r</mi></msup><annotation-xml encoding=\"MathML-Content\" id=\"A6.T17.1.1.1.m1.1b\"><apply id=\"A6.T17.1.1.1.m1.1.1.cmml\" xref=\"A6.T17.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"A6.T17.1.1.1.m1.1.1.1.cmml\" xref=\"A6.T17.1.1.1.m1.1.1\">superscript</csymbol><ci id=\"A6.T17.1.1.1.m1.1.1.2.cmml\" xref=\"A6.T17.1.1.1.m1.1.1.2\">ùê∫</ci><ci id=\"A6.T17.1.1.1.m1.1.1.3.cmml\" xref=\"A6.T17.1.1.1.m1.1.1.3\">ùëü</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T17.1.1.1.m1.1c\">G^{r}</annotation></semantics></math>\n</td>\n<td id=\"A6.T17.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">59.26</td>\n<td id=\"A6.T17.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">9.54</td>\n</tr>\n<tr id=\"A6.T17.1.3\" class=\"ltx_tr\">\n<td id=\"A6.T17.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">2:</td>\n<td id=\"A6.T17.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Average of benign local models</td>\n<td id=\"A6.T17.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">33.44</td>\n<td id=\"A6.T17.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">11.53</td>\n</tr>\n<tr id=\"A6.T17.1.4\" class=\"ltx_tr\">\n<td id=\"A6.T17.1.4.1\" class=\"ltx_td ltx_align_left\">3:</td>\n<td id=\"A6.T17.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Average of poisoned local models</td>\n<td id=\"A6.T17.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">34.51</td>\n<td id=\"A6.T17.1.4.4\" class=\"ltx_td ltx_align_center\">83.70</td>\n</tr>\n<tr id=\"A6.T17.1.5\" class=\"ltx_tr\">\n<td id=\"A6.T17.1.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\">4:</td>\n<td id=\"A6.T17.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T17.1.5.2.1\" class=\"ltx_text\">FedAVG</span> with benign local models</td>\n<td id=\"A6.T17.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">40.47</td>\n<td id=\"A6.T17.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">15.14</td>\n</tr>\n<tr id=\"A6.T17.1.6\" class=\"ltx_tr\">\n<td id=\"A6.T17.1.6.1\" class=\"ltx_td ltx_align_left\">5:</td>\n<td id=\"A6.T17.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T17.1.6.2.1\" class=\"ltx_text\">FedAVG</span> with poisoned local models</td>\n<td id=\"A6.T17.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">37.07</td>\n<td id=\"A6.T17.1.6.4\" class=\"ltx_td ltx_align_center\">88.38</td>\n</tr>\n<tr id=\"A6.T17.1.7\" class=\"ltx_tr\">\n<td id=\"A6.T17.1.7.1\" class=\"ltx_td ltx_align_left ltx_border_t\">6:</td>\n<td id=\"A6.T17.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T17.1.7.2.1\" class=\"ltx_text\">FedAVG</span> with all local models</td>\n<td id=\"A6.T17.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">46.00</td>\n<td id=\"A6.T17.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">70.58</td>\n</tr>\n<tr id=\"A6.T17.1.8\" class=\"ltx_tr\">\n<td id=\"A6.T17.1.8.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\" colspan=\"2\">Global model accuracies after applying defenses</td>\n<td id=\"A6.T17.1.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\">MA</td>\n<td id=\"A6.T17.1.8.3\" class=\"ltx_td ltx_align_center ltx_border_tt ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T17.1.9\" class=\"ltx_tr\">\n<td id=\"A6.T17.1.9.1\" class=\"ltx_td ltx_align_left ltx_border_t\">7:</td>\n<td id=\"A6.T17.1.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Na√Øve Clustering</td>\n<td id=\"A6.T17.1.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">27.81</td>\n<td id=\"A6.T17.1.9.4\" class=\"ltx_td ltx_align_center ltx_border_t\">48.08</td>\n</tr>\n<tr id=\"A6.T17.1.10\" class=\"ltx_tr\">\n<td id=\"A6.T17.1.10.1\" class=\"ltx_td ltx_align_left\">8:</td>\n<td id=\"A6.T17.1.10.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FoolsGold¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Fung et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>\n</td>\n<td id=\"A6.T17.1.10.3\" class=\"ltx_td ltx_align_center ltx_border_r\">51.16</td>\n<td id=\"A6.T17.1.10.4\" class=\"ltx_td ltx_align_center\">74.58</td>\n</tr>\n<tr id=\"A6.T17.1.11\" class=\"ltx_tr\">\n<td id=\"A6.T17.1.11.1\" class=\"ltx_td ltx_align_left\">9:</td>\n<td id=\"A6.T17.1.11.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Krum¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T17.1.11.3\" class=\"ltx_td ltx_align_center ltx_border_r\">17.21</td>\n<td id=\"A6.T17.1.11.4\" class=\"ltx_td ltx_align_center\">88.17</td>\n</tr>\n<tr id=\"A6.T17.1.12\" class=\"ltx_tr\">\n<td id=\"A6.T17.1.12.1\" class=\"ltx_td ltx_align_left\">10:</td>\n<td id=\"A6.T17.1.12.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T17.1.12.2.1\" class=\"ltx_text\">M-Krum</span>¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T17.1.12.3\" class=\"ltx_td ltx_align_center ltx_border_r\">18.16</td>\n<td id=\"A6.T17.1.12.4\" class=\"ltx_td ltx_align_center\">93.85</td>\n</tr>\n<tr id=\"A6.T17.1.13\" class=\"ltx_tr\">\n<td id=\"A6.T17.1.13.1\" class=\"ltx_td ltx_align_left\">11:</td>\n<td id=\"A6.T17.1.13.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T17.1.13.3\" class=\"ltx_td ltx_align_center ltx_border_r\">46.16</td>\n<td id=\"A6.T17.1.13.4\" class=\"ltx_td ltx_align_center\">67.88</td>\n</tr>\n<tr id=\"A6.T17.1.14\" class=\"ltx_tr\">\n<td id=\"A6.T17.1.14.1\" class=\"ltx_td ltx_align_left\">12:</td>\n<td id=\"A6.T17.1.14.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip&amp;Noise¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T17.1.14.3\" class=\"ltx_td ltx_align_center ltx_border_r\">26.36</td>\n<td id=\"A6.T17.1.14.4\" class=\"ltx_td ltx_align_center\">77.95</td>\n</tr>\n<tr id=\"A6.T17.1.15\" class=\"ltx_tr\">\n<td id=\"A6.T17.1.15.1\" class=\"ltx_td ltx_align_left\">13:</td>\n<td id=\"A6.T17.1.15.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Flame¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Nguyen et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib69\" title=\"\" class=\"ltx_ref\">2022c</a>)</cite>\n</td>\n<td id=\"A6.T17.1.15.3\" class=\"ltx_td ltx_align_center ltx_border_r\">22.38</td>\n<td id=\"A6.T17.1.15.4\" class=\"ltx_td ltx_align_center\">91.66</td>\n</tr>\n<tr id=\"A6.T17.1.16\" class=\"ltx_tr\">\n<td id=\"A6.T17.1.16.1\" class=\"ltx_td ltx_align_left\">14:</td>\n<td id=\"A6.T17.1.16.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Mean¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T17.1.16.3\" class=\"ltx_td ltx_align_center ltx_border_r\">46.29</td>\n<td id=\"A6.T17.1.16.4\" class=\"ltx_td ltx_align_center\">67.70</td>\n</tr>\n<tr id=\"A6.T17.1.17\" class=\"ltx_tr\">\n<td id=\"A6.T17.1.17.1\" class=\"ltx_td ltx_align_left\">15:</td>\n<td id=\"A6.T17.1.17.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Median¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T17.1.17.3\" class=\"ltx_td ltx_align_center ltx_border_r\">22.60</td>\n<td id=\"A6.T17.1.17.4\" class=\"ltx_td ltx_align_center\">51.86</td>\n</tr>\n<tr id=\"A6.T17.1.18\" class=\"ltx_tr\">\n<td id=\"A6.T17.1.18.1\" class=\"ltx_td ltx_align_left\">16:</td>\n<td id=\"A6.T17.1.18.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FLTrust¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Cao et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib14\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>\n</td>\n<td id=\"A6.T17.1.18.3\" class=\"ltx_td ltx_align_center ltx_border_r\">47.00</td>\n<td id=\"A6.T17.1.18.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T17.1.18.4.1\" class=\"ltx_text ltx_font_bold\">24.26</span></td>\n</tr>\n<tr id=\"A6.T17.1.19\" class=\"ltx_tr\">\n<td id=\"A6.T17.1.19.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">17:</td>\n<td id=\"A6.T17.1.19.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"A6.T17.1.19.2.1\" class=\"ltx_text ltx_font_bold\">MESAS</span></td>\n<td id=\"A6.T17.1.19.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">40.95</td>\n<td id=\"A6.T17.1.19.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"A6.T17.1.19.4.1\" class=\"ltx_text ltx_font_bold\">2.00</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In this section, we provide further results for our experiments, that could not be included in the main part of the paper due to space limitations. We selected the most interesting and representative results to be part of the main part, but report the rest below for completeness.",
                "Tab.¬†",
                "4",
                " reports the MAs corresponding to the BAs and ACCs in ",
                "Tab.¬†",
                "2",
                " for different poisoning methods without adaptive adversaries. Note, that ",
                "MESAS",
                " provides high MA independent of the applied poisoning attack. The table shows, that ",
                "MESAS",
                " does not negatively impact the MA and is also effective against untargeted attacks.",
                "Tab.¬†",
                "5",
                " shows the results for our default scenario with scaled poisoned models regarding the Euclidean distance of updates. The results confirm, that scaling can increase the BA. ",
                "MESAS",
                " is already efficient for the unscaled version visualized in scenario  ",
                "1",
                " in ",
                "Tab.¬†",
                "1",
                ", hence is also effective for scaled models due to the intuition visualized in ",
                "Fig.¬†",
                "4",
                ". ",
                "Tab.¬†",
                "6",
                " depicts the results for the default scenario with a PDR of 0.3 for scaled poisoned models.",
                "We conducted an attack leveraging our strong adaptive adversary against FoolsGold¬†",
                "(Fung et¬†al",
                ".",
                ", ",
                "2020",
                ")",
                " and report the result in ",
                "Tab.¬†",
                "7",
                ". As strategy, we first trained a benign local model and transferred the trained parameters of the last layer to a fresh local model. We then excluded the parameters form training and poisoned the local model forcing the backdoor into some other layers. In ",
                "Tab.¬†",
                "8",
                " we additionally applied scaling. We can observe, that the BA of FoolsGold can be increased with those methods.",
                "Scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                " shows the result after adapting to Krum scores¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                " in an unscaled and scaled version. We forced the Euclidean distance between poisoned models and the global model to be similar to each other and on a benign level so that the defenses decide in favor of the poisoned models. ",
                "Fig.¬†",
                "12",
                " depicts the Krum scores for the default scenario associated with the default scenario in ",
                "Tab.¬†",
                "1",
                " to show, that the effective backdoor is based on coincidence and not intentionally forced by the attacker. With slight changes in some models, Krum could also decide for a benign model. However, after adaption, we can introduce a high BA intentionally in scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                ".",
                "Tab.¬†",
                "10",
                " and ",
                "Tab.¬†",
                "11",
                " show the results for a classical ",
                "intra-client",
                " ",
                "non-IID",
                " scenario crafted by ",
                "1-class",
                " ",
                "non-IID",
                " with ",
                "q",
                "=",
                "0.5",
                "ùëû",
                "0.5",
                "q=0.5",
                ". In both cases, ",
                "MESAS",
                " reduces the BA reliably with only one FP, while other defenses allow the attacker to embed 34.72% to 49.47% BA. ",
                "Tab.¬†",
                "12",
                " depicts the results for an increased PDR of 0.3, allowing the adversary to reach a BA of 57.68% without defense and up to 92.86% under active defenses. ",
                "MESAS",
                " still removes the poisoned models most effectively with only two FPs.",
                "In ",
                "Tab.¬†",
                "13",
                " and ",
                "Tab.¬†",
                "13",
                " we adapt all malicious models to a central benign value regarding the Cosine distance to the global model, which has the effect, that the models are inconspicuous in Krum scores, hence can circumvent Krum and ",
                "M-Krum",
                "¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                ", while ",
                "MESAS",
                " still erases the backdoor with only two FPs.",
                "Tab.¬†",
                "15",
                " and ",
                "Tab.¬†",
                "16",
                " show the results in a ",
                "inter-client",
                " ",
                "non-IID",
                " scenario based on our ",
                "Random-Non-IID",
                " strategy for a model in FL round one and highlights, that ",
                "MESAS",
                " outperforms other defenses in reducing the BA of the new global model.\n",
                "Tab.¬†",
                "17",
                " and ",
                "Tab.¬†",
                "18",
                " show the results for a setting in round 50,w here 100 clients are part of the federation and 20 clients are selected randomly in each round for training. Due to the later rounds, ",
                "MESAS",
                " is even more effective than other defenses and reduces the BA to a minimum.",
                "Tab.¬†",
                "19",
                " and ",
                "Tab.¬†",
                "20",
                " show the experiments results with a CNN training on MNIST¬†",
                "(Deng, ",
                "2012",
                ")",
                " and SqueezeNet¬†",
                "(Iandola et¬†al",
                ".",
                ", ",
                "2016",
                ")",
                " training on ",
                "CIFAR-10",
                " ",
                "(Krizhevsky et¬†al",
                ".",
                ", ",
                "2009",
                ")",
                ". The CNN consists of two convolutional layers, the first with 32 output layers, the second with 64 output layers, both applying a kernel size of 5. The output of the convolutional layers traverse a ReLU¬†",
                "(Agarap, ",
                "2018",
                ")",
                " and a 2D pooling layer, before being fed into three fully connected layers with output size 512, 256 and 10 output respectively. In both experiments, we used a ",
                "self-pre-trained",
                " model as global model. We can report perfect detection rate with just one FP for CNN and SqueezeNet, even if the backdoor is not yet embedded in the global model. Hence, a stronger adaption by the adversary would strengthen the detection capabilities of ",
                "MESAS",
                ". Other defenses instead can be circumvented by the adaptive adversary."
            ]
        ]
    },
    "A6.T18": {
        "caption": "Table 18. MA and BA in the default scenario with inter-client non-IID based on our Random-Non-IID strategy with 100 clients in the federation and scaled\npoisoned models regarding the Euclidean distance of updates in percent.",
        "table": "<table id=\"A6.T18.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A6.T18.1.2\" class=\"ltx_tr\">\n<td id=\"A6.T18.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\">Accuracies without defenses</td>\n<td id=\"A6.T18.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">MA</td>\n<td id=\"A6.T18.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T18.1.1\" class=\"ltx_tr\">\n<td id=\"A6.T18.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">1:</td>\n<td id=\"A6.T18.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Global model <math id=\"A6.T18.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"G^{r}\" display=\"inline\"><semantics id=\"A6.T18.1.1.1.m1.1a\"><msup id=\"A6.T18.1.1.1.m1.1.1\" xref=\"A6.T18.1.1.1.m1.1.1.cmml\"><mi id=\"A6.T18.1.1.1.m1.1.1.2\" xref=\"A6.T18.1.1.1.m1.1.1.2.cmml\">G</mi><mi id=\"A6.T18.1.1.1.m1.1.1.3\" xref=\"A6.T18.1.1.1.m1.1.1.3.cmml\">r</mi></msup><annotation-xml encoding=\"MathML-Content\" id=\"A6.T18.1.1.1.m1.1b\"><apply id=\"A6.T18.1.1.1.m1.1.1.cmml\" xref=\"A6.T18.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"A6.T18.1.1.1.m1.1.1.1.cmml\" xref=\"A6.T18.1.1.1.m1.1.1\">superscript</csymbol><ci id=\"A6.T18.1.1.1.m1.1.1.2.cmml\" xref=\"A6.T18.1.1.1.m1.1.1.2\">ùê∫</ci><ci id=\"A6.T18.1.1.1.m1.1.1.3.cmml\" xref=\"A6.T18.1.1.1.m1.1.1.3\">ùëü</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T18.1.1.1.m1.1c\">G^{r}</annotation></semantics></math>\n</td>\n<td id=\"A6.T18.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">59.26</td>\n<td id=\"A6.T18.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">9.54</td>\n</tr>\n<tr id=\"A6.T18.1.3\" class=\"ltx_tr\">\n<td id=\"A6.T18.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">2:</td>\n<td id=\"A6.T18.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Average of benign local models</td>\n<td id=\"A6.T18.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">33.44</td>\n<td id=\"A6.T18.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">11.53</td>\n</tr>\n<tr id=\"A6.T18.1.4\" class=\"ltx_tr\">\n<td id=\"A6.T18.1.4.1\" class=\"ltx_td ltx_align_left\">3:</td>\n<td id=\"A6.T18.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Average of poisoned local models</td>\n<td id=\"A6.T18.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">34.51</td>\n<td id=\"A6.T18.1.4.4\" class=\"ltx_td ltx_align_center\">83.70</td>\n</tr>\n<tr id=\"A6.T18.1.5\" class=\"ltx_tr\">\n<td id=\"A6.T18.1.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\">4:</td>\n<td id=\"A6.T18.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T18.1.5.2.1\" class=\"ltx_text\">FedAVG</span> with benign local models</td>\n<td id=\"A6.T18.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">40.47</td>\n<td id=\"A6.T18.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">15.14</td>\n</tr>\n<tr id=\"A6.T18.1.6\" class=\"ltx_tr\">\n<td id=\"A6.T18.1.6.1\" class=\"ltx_td ltx_align_left\">5:</td>\n<td id=\"A6.T18.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T18.1.6.2.1\" class=\"ltx_text\">FedAVG</span> with poisoned local models</td>\n<td id=\"A6.T18.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">21.92</td>\n<td id=\"A6.T18.1.6.4\" class=\"ltx_td ltx_align_center\">95.46</td>\n</tr>\n<tr id=\"A6.T18.1.7\" class=\"ltx_tr\">\n<td id=\"A6.T18.1.7.1\" class=\"ltx_td ltx_align_left ltx_border_t\">6:</td>\n<td id=\"A6.T18.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T18.1.7.2.1\" class=\"ltx_text\">FedAVG</span> with all local models</td>\n<td id=\"A6.T18.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">35.14</td>\n<td id=\"A6.T18.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">87.10</td>\n</tr>\n<tr id=\"A6.T18.1.8\" class=\"ltx_tr\">\n<td id=\"A6.T18.1.8.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\" colspan=\"2\">Global model accuracies after applying defenses</td>\n<td id=\"A6.T18.1.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\">MA</td>\n<td id=\"A6.T18.1.8.3\" class=\"ltx_td ltx_align_center ltx_border_tt ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T18.1.9\" class=\"ltx_tr\">\n<td id=\"A6.T18.1.9.1\" class=\"ltx_td ltx_align_left ltx_border_t\">7:</td>\n<td id=\"A6.T18.1.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Na√Øve Clustering</td>\n<td id=\"A6.T18.1.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">26.41</td>\n<td id=\"A6.T18.1.9.4\" class=\"ltx_td ltx_align_center ltx_border_t\">92.11</td>\n</tr>\n<tr id=\"A6.T18.1.10\" class=\"ltx_tr\">\n<td id=\"A6.T18.1.10.1\" class=\"ltx_td ltx_align_left\">8:</td>\n<td id=\"A6.T18.1.10.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FoolsGold¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Fung et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>\n</td>\n<td id=\"A6.T18.1.10.3\" class=\"ltx_td ltx_align_center ltx_border_r\">37.38</td>\n<td id=\"A6.T18.1.10.4\" class=\"ltx_td ltx_align_center\">91.50</td>\n</tr>\n<tr id=\"A6.T18.1.11\" class=\"ltx_tr\">\n<td id=\"A6.T18.1.11.1\" class=\"ltx_td ltx_align_left\">9:</td>\n<td id=\"A6.T18.1.11.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Krum¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T18.1.11.3\" class=\"ltx_td ltx_align_center ltx_border_r\">23.44</td>\n<td id=\"A6.T18.1.11.4\" class=\"ltx_td ltx_align_center\">33.20</td>\n</tr>\n<tr id=\"A6.T18.1.12\" class=\"ltx_tr\">\n<td id=\"A6.T18.1.12.1\" class=\"ltx_td ltx_align_left\">10:</td>\n<td id=\"A6.T18.1.12.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T18.1.12.2.1\" class=\"ltx_text\">M-Krum</span>¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T18.1.12.3\" class=\"ltx_td ltx_align_center ltx_border_r\">19.64</td>\n<td id=\"A6.T18.1.12.4\" class=\"ltx_td ltx_align_center\">73.38</td>\n</tr>\n<tr id=\"A6.T18.1.13\" class=\"ltx_tr\">\n<td id=\"A6.T18.1.13.1\" class=\"ltx_td ltx_align_left\">11:</td>\n<td id=\"A6.T18.1.13.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T18.1.13.3\" class=\"ltx_td ltx_align_center ltx_border_r\">35.65</td>\n<td id=\"A6.T18.1.13.4\" class=\"ltx_td ltx_align_center\">86.22</td>\n</tr>\n<tr id=\"A6.T18.1.14\" class=\"ltx_tr\">\n<td id=\"A6.T18.1.14.1\" class=\"ltx_td ltx_align_left\">12:</td>\n<td id=\"A6.T18.1.14.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip&amp;Noise¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T18.1.14.3\" class=\"ltx_td ltx_align_center ltx_border_r\">25.07</td>\n<td id=\"A6.T18.1.14.4\" class=\"ltx_td ltx_align_center\">95.75</td>\n</tr>\n<tr id=\"A6.T18.1.15\" class=\"ltx_tr\">\n<td id=\"A6.T18.1.15.1\" class=\"ltx_td ltx_align_left\">13:</td>\n<td id=\"A6.T18.1.15.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Flame¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Nguyen et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib69\" title=\"\" class=\"ltx_ref\">2022c</a>)</cite>\n</td>\n<td id=\"A6.T18.1.15.3\" class=\"ltx_td ltx_align_center ltx_border_r\">10.00</td>\n<td id=\"A6.T18.1.15.4\" class=\"ltx_td ltx_align_center\">100.00</td>\n</tr>\n<tr id=\"A6.T18.1.16\" class=\"ltx_tr\">\n<td id=\"A6.T18.1.16.1\" class=\"ltx_td ltx_align_left\">14:</td>\n<td id=\"A6.T18.1.16.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Mean¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T18.1.16.3\" class=\"ltx_td ltx_align_center ltx_border_r\">41.72</td>\n<td id=\"A6.T18.1.16.4\" class=\"ltx_td ltx_align_center\">76.07</td>\n</tr>\n<tr id=\"A6.T18.1.17\" class=\"ltx_tr\">\n<td id=\"A6.T18.1.17.1\" class=\"ltx_td ltx_align_left\">15:</td>\n<td id=\"A6.T18.1.17.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Median¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T18.1.17.3\" class=\"ltx_td ltx_align_center ltx_border_r\">20.13</td>\n<td id=\"A6.T18.1.17.4\" class=\"ltx_td ltx_align_center\">54.57</td>\n</tr>\n<tr id=\"A6.T18.1.18\" class=\"ltx_tr\">\n<td id=\"A6.T18.1.18.1\" class=\"ltx_td ltx_align_left\">16:</td>\n<td id=\"A6.T18.1.18.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FLTrust¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Cao et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib14\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>\n</td>\n<td id=\"A6.T18.1.18.3\" class=\"ltx_td ltx_align_center ltx_border_r\">49.16</td>\n<td id=\"A6.T18.1.18.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T18.1.18.4.1\" class=\"ltx_text ltx_font_bold\">25.30</span></td>\n</tr>\n<tr id=\"A6.T18.1.19\" class=\"ltx_tr\">\n<td id=\"A6.T18.1.19.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">17:</td>\n<td id=\"A6.T18.1.19.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"A6.T18.1.19.2.1\" class=\"ltx_text ltx_font_bold\">MESAS</span></td>\n<td id=\"A6.T18.1.19.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">46.70</td>\n<td id=\"A6.T18.1.19.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"A6.T18.1.19.4.1\" class=\"ltx_text ltx_font_bold\">0.08</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In this section, we provide further results for our experiments, that could not be included in the main part of the paper due to space limitations. We selected the most interesting and representative results to be part of the main part, but report the rest below for completeness.",
                "Tab.¬†",
                "4",
                " reports the MAs corresponding to the BAs and ACCs in ",
                "Tab.¬†",
                "2",
                " for different poisoning methods without adaptive adversaries. Note, that ",
                "MESAS",
                " provides high MA independent of the applied poisoning attack. The table shows, that ",
                "MESAS",
                " does not negatively impact the MA and is also effective against untargeted attacks.",
                "Tab.¬†",
                "5",
                " shows the results for our default scenario with scaled poisoned models regarding the Euclidean distance of updates. The results confirm, that scaling can increase the BA. ",
                "MESAS",
                " is already efficient for the unscaled version visualized in scenario  ",
                "1",
                " in ",
                "Tab.¬†",
                "1",
                ", hence is also effective for scaled models due to the intuition visualized in ",
                "Fig.¬†",
                "4",
                ". ",
                "Tab.¬†",
                "6",
                " depicts the results for the default scenario with a PDR of 0.3 for scaled poisoned models.",
                "We conducted an attack leveraging our strong adaptive adversary against FoolsGold¬†",
                "(Fung et¬†al",
                ".",
                ", ",
                "2020",
                ")",
                " and report the result in ",
                "Tab.¬†",
                "7",
                ". As strategy, we first trained a benign local model and transferred the trained parameters of the last layer to a fresh local model. We then excluded the parameters form training and poisoned the local model forcing the backdoor into some other layers. In ",
                "Tab.¬†",
                "8",
                " we additionally applied scaling. We can observe, that the BA of FoolsGold can be increased with those methods.",
                "Scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                " shows the result after adapting to Krum scores¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                " in an unscaled and scaled version. We forced the Euclidean distance between poisoned models and the global model to be similar to each other and on a benign level so that the defenses decide in favor of the poisoned models. ",
                "Fig.¬†",
                "12",
                " depicts the Krum scores for the default scenario associated with the default scenario in ",
                "Tab.¬†",
                "1",
                " to show, that the effective backdoor is based on coincidence and not intentionally forced by the attacker. With slight changes in some models, Krum could also decide for a benign model. However, after adaption, we can introduce a high BA intentionally in scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                ".",
                "Tab.¬†",
                "10",
                " and ",
                "Tab.¬†",
                "11",
                " show the results for a classical ",
                "intra-client",
                " ",
                "non-IID",
                " scenario crafted by ",
                "1-class",
                " ",
                "non-IID",
                " with ",
                "q",
                "=",
                "0.5",
                "ùëû",
                "0.5",
                "q=0.5",
                ". In both cases, ",
                "MESAS",
                " reduces the BA reliably with only one FP, while other defenses allow the attacker to embed 34.72% to 49.47% BA. ",
                "Tab.¬†",
                "12",
                " depicts the results for an increased PDR of 0.3, allowing the adversary to reach a BA of 57.68% without defense and up to 92.86% under active defenses. ",
                "MESAS",
                " still removes the poisoned models most effectively with only two FPs.",
                "In ",
                "Tab.¬†",
                "13",
                " and ",
                "Tab.¬†",
                "13",
                " we adapt all malicious models to a central benign value regarding the Cosine distance to the global model, which has the effect, that the models are inconspicuous in Krum scores, hence can circumvent Krum and ",
                "M-Krum",
                "¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                ", while ",
                "MESAS",
                " still erases the backdoor with only two FPs.",
                "Tab.¬†",
                "15",
                " and ",
                "Tab.¬†",
                "16",
                " show the results in a ",
                "inter-client",
                " ",
                "non-IID",
                " scenario based on our ",
                "Random-Non-IID",
                " strategy for a model in FL round one and highlights, that ",
                "MESAS",
                " outperforms other defenses in reducing the BA of the new global model.\n",
                "Tab.¬†",
                "17",
                " and ",
                "Tab.¬†",
                "18",
                " show the results for a setting in round 50,w here 100 clients are part of the federation and 20 clients are selected randomly in each round for training. Due to the later rounds, ",
                "MESAS",
                " is even more effective than other defenses and reduces the BA to a minimum.",
                "Tab.¬†",
                "19",
                " and ",
                "Tab.¬†",
                "20",
                " show the experiments results with a CNN training on MNIST¬†",
                "(Deng, ",
                "2012",
                ")",
                " and SqueezeNet¬†",
                "(Iandola et¬†al",
                ".",
                ", ",
                "2016",
                ")",
                " training on ",
                "CIFAR-10",
                " ",
                "(Krizhevsky et¬†al",
                ".",
                ", ",
                "2009",
                ")",
                ". The CNN consists of two convolutional layers, the first with 32 output layers, the second with 64 output layers, both applying a kernel size of 5. The output of the convolutional layers traverse a ReLU¬†",
                "(Agarap, ",
                "2018",
                ")",
                " and a 2D pooling layer, before being fed into three fully connected layers with output size 512, 256 and 10 output respectively. In both experiments, we used a ",
                "self-pre-trained",
                " model as global model. We can report perfect detection rate with just one FP for CNN and SqueezeNet, even if the backdoor is not yet embedded in the global model. Hence, a stronger adaption by the adversary would strengthen the detection capabilities of ",
                "MESAS",
                ". Other defenses instead can be circumvented by the adaptive adversary."
            ]
        ]
    },
    "A6.T19": {
        "caption": "Table 19. MA and BA in the default scenario with a CNN trained on MNIST¬†(Deng, 2012) with a PDR of 0.3 in percent.",
        "table": "<table id=\"A6.T19.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A6.T19.1.2\" class=\"ltx_tr\">\n<td id=\"A6.T19.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\">Accuracies without defenses</td>\n<td id=\"A6.T19.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">MA</td>\n<td id=\"A6.T19.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T19.1.1\" class=\"ltx_tr\">\n<td id=\"A6.T19.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">1:</td>\n<td id=\"A6.T19.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Global model <math id=\"A6.T19.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"G^{r}\" display=\"inline\"><semantics id=\"A6.T19.1.1.1.m1.1a\"><msup id=\"A6.T19.1.1.1.m1.1.1\" xref=\"A6.T19.1.1.1.m1.1.1.cmml\"><mi id=\"A6.T19.1.1.1.m1.1.1.2\" xref=\"A6.T19.1.1.1.m1.1.1.2.cmml\">G</mi><mi id=\"A6.T19.1.1.1.m1.1.1.3\" xref=\"A6.T19.1.1.1.m1.1.1.3.cmml\">r</mi></msup><annotation-xml encoding=\"MathML-Content\" id=\"A6.T19.1.1.1.m1.1b\"><apply id=\"A6.T19.1.1.1.m1.1.1.cmml\" xref=\"A6.T19.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"A6.T19.1.1.1.m1.1.1.1.cmml\" xref=\"A6.T19.1.1.1.m1.1.1\">superscript</csymbol><ci id=\"A6.T19.1.1.1.m1.1.1.2.cmml\" xref=\"A6.T19.1.1.1.m1.1.1.2\">ùê∫</ci><ci id=\"A6.T19.1.1.1.m1.1.1.3.cmml\" xref=\"A6.T19.1.1.1.m1.1.1.3\">ùëü</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T19.1.1.1.m1.1c\">G^{r}</annotation></semantics></math>\n</td>\n<td id=\"A6.T19.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">76.74</td>\n<td id=\"A6.T19.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">2.05</td>\n</tr>\n<tr id=\"A6.T19.1.3\" class=\"ltx_tr\">\n<td id=\"A6.T19.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">2:</td>\n<td id=\"A6.T19.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Average of benign local models</td>\n<td id=\"A6.T19.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">84.87</td>\n<td id=\"A6.T19.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.57</td>\n</tr>\n<tr id=\"A6.T19.1.4\" class=\"ltx_tr\">\n<td id=\"A6.T19.1.4.1\" class=\"ltx_td ltx_align_left\">3:</td>\n<td id=\"A6.T19.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Average of poisoned local models</td>\n<td id=\"A6.T19.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">60.73</td>\n<td id=\"A6.T19.1.4.4\" class=\"ltx_td ltx_align_center\">39.59</td>\n</tr>\n<tr id=\"A6.T19.1.5\" class=\"ltx_tr\">\n<td id=\"A6.T19.1.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\">4:</td>\n<td id=\"A6.T19.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T19.1.5.2.1\" class=\"ltx_text\">FedAVG</span> with benign local models</td>\n<td id=\"A6.T19.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">86.51</td>\n<td id=\"A6.T19.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.54</td>\n</tr>\n<tr id=\"A6.T19.1.6\" class=\"ltx_tr\">\n<td id=\"A6.T19.1.6.1\" class=\"ltx_td ltx_align_left\">5:</td>\n<td id=\"A6.T19.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T19.1.6.2.1\" class=\"ltx_text\">FedAVG</span> with poisoned local models</td>\n<td id=\"A6.T19.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.04</td>\n<td id=\"A6.T19.1.6.4\" class=\"ltx_td ltx_align_center\">37.77</td>\n</tr>\n<tr id=\"A6.T19.1.7\" class=\"ltx_tr\">\n<td id=\"A6.T19.1.7.1\" class=\"ltx_td ltx_align_left ltx_border_t\">6:</td>\n<td id=\"A6.T19.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T19.1.7.2.1\" class=\"ltx_text\">FedAVG</span> with all local models</td>\n<td id=\"A6.T19.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">85.31</td>\n<td id=\"A6.T19.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">2.35</td>\n</tr>\n<tr id=\"A6.T19.1.8\" class=\"ltx_tr\">\n<td id=\"A6.T19.1.8.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\" colspan=\"2\">Global model accuracies after applying defenses</td>\n<td id=\"A6.T19.1.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\">MA</td>\n<td id=\"A6.T19.1.8.3\" class=\"ltx_td ltx_align_center ltx_border_tt ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T19.1.9\" class=\"ltx_tr\">\n<td id=\"A6.T19.1.9.1\" class=\"ltx_td ltx_align_left ltx_border_t\">7:</td>\n<td id=\"A6.T19.1.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Na√Øve Clustering</td>\n<td id=\"A6.T19.1.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">86.51</td>\n<td id=\"A6.T19.1.9.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.54</td>\n</tr>\n<tr id=\"A6.T19.1.10\" class=\"ltx_tr\">\n<td id=\"A6.T19.1.10.1\" class=\"ltx_td ltx_align_left\">8:</td>\n<td id=\"A6.T19.1.10.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FoolsGold¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Fung et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>\n</td>\n<td id=\"A6.T19.1.10.3\" class=\"ltx_td ltx_align_center ltx_border_r\">85.31</td>\n<td id=\"A6.T19.1.10.4\" class=\"ltx_td ltx_align_center\">2.35</td>\n</tr>\n<tr id=\"A6.T19.1.11\" class=\"ltx_tr\">\n<td id=\"A6.T19.1.11.1\" class=\"ltx_td ltx_align_left\">9:</td>\n<td id=\"A6.T19.1.11.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Krum¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T19.1.11.3\" class=\"ltx_td ltx_align_center ltx_border_r\">83.79</td>\n<td id=\"A6.T19.1.11.4\" class=\"ltx_td ltx_align_center\">0.51</td>\n</tr>\n<tr id=\"A6.T19.1.12\" class=\"ltx_tr\">\n<td id=\"A6.T19.1.12.1\" class=\"ltx_td ltx_align_left\">10:</td>\n<td id=\"A6.T19.1.12.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T19.1.12.2.1\" class=\"ltx_text\">M-Krum</span>¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T19.1.12.3\" class=\"ltx_td ltx_align_center ltx_border_r\">86.45</td>\n<td id=\"A6.T19.1.12.4\" class=\"ltx_td ltx_align_center\">0.59</td>\n</tr>\n<tr id=\"A6.T19.1.13\" class=\"ltx_tr\">\n<td id=\"A6.T19.1.13.1\" class=\"ltx_td ltx_align_left\">11:</td>\n<td id=\"A6.T19.1.13.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T19.1.13.3\" class=\"ltx_td ltx_align_center ltx_border_r\">85.13</td>\n<td id=\"A6.T19.1.13.4\" class=\"ltx_td ltx_align_center\">2.03</td>\n</tr>\n<tr id=\"A6.T19.1.14\" class=\"ltx_tr\">\n<td id=\"A6.T19.1.14.1\" class=\"ltx_td ltx_align_left\">12:</td>\n<td id=\"A6.T19.1.14.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip&amp;Noise¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T19.1.14.3\" class=\"ltx_td ltx_align_center ltx_border_r\">84.13</td>\n<td id=\"A6.T19.1.14.4\" class=\"ltx_td ltx_align_center\">2.75</td>\n</tr>\n<tr id=\"A6.T19.1.15\" class=\"ltx_tr\">\n<td id=\"A6.T19.1.15.1\" class=\"ltx_td ltx_align_left\">13:</td>\n<td id=\"A6.T19.1.15.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Flame¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Nguyen et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib69\" title=\"\" class=\"ltx_ref\">2022c</a>)</cite>\n</td>\n<td id=\"A6.T19.1.15.3\" class=\"ltx_td ltx_align_center ltx_border_r\">86.50</td>\n<td id=\"A6.T19.1.15.4\" class=\"ltx_td ltx_align_center\">0.50</td>\n</tr>\n<tr id=\"A6.T19.1.16\" class=\"ltx_tr\">\n<td id=\"A6.T19.1.16.1\" class=\"ltx_td ltx_align_left\">14:</td>\n<td id=\"A6.T19.1.16.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Mean¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T19.1.16.3\" class=\"ltx_td ltx_align_center ltx_border_r\">85.13</td>\n<td id=\"A6.T19.1.16.4\" class=\"ltx_td ltx_align_center\">2.19</td>\n</tr>\n<tr id=\"A6.T19.1.17\" class=\"ltx_tr\">\n<td id=\"A6.T19.1.17.1\" class=\"ltx_td ltx_align_left\">15:</td>\n<td id=\"A6.T19.1.17.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Median¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T19.1.17.3\" class=\"ltx_td ltx_align_center ltx_border_r\">85.13</td>\n<td id=\"A6.T19.1.17.4\" class=\"ltx_td ltx_align_center\">2.19</td>\n</tr>\n<tr id=\"A6.T19.1.18\" class=\"ltx_tr\">\n<td id=\"A6.T19.1.18.1\" class=\"ltx_td ltx_align_left\">16:</td>\n<td id=\"A6.T19.1.18.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FLTrust¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Cao et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib14\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>\n</td>\n<td id=\"A6.T19.1.18.3\" class=\"ltx_td ltx_align_center ltx_border_r\">79.26</td>\n<td id=\"A6.T19.1.18.4\" class=\"ltx_td ltx_align_center\">1.90</td>\n</tr>\n<tr id=\"A6.T19.1.19\" class=\"ltx_tr\">\n<td id=\"A6.T19.1.19.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">17:</td>\n<td id=\"A6.T19.1.19.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"A6.T19.1.19.2.1\" class=\"ltx_text ltx_font_bold\">MESAS</span></td>\n<td id=\"A6.T19.1.19.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">86.59</td>\n<td id=\"A6.T19.1.19.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"A6.T19.1.19.4.1\" class=\"ltx_text ltx_font_bold\">0.53</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In this section, we provide further results for our experiments, that could not be included in the main part of the paper due to space limitations. We selected the most interesting and representative results to be part of the main part, but report the rest below for completeness.",
                "Tab.¬†",
                "4",
                " reports the MAs corresponding to the BAs and ACCs in ",
                "Tab.¬†",
                "2",
                " for different poisoning methods without adaptive adversaries. Note, that ",
                "MESAS",
                " provides high MA independent of the applied poisoning attack. The table shows, that ",
                "MESAS",
                " does not negatively impact the MA and is also effective against untargeted attacks.",
                "Tab.¬†",
                "5",
                " shows the results for our default scenario with scaled poisoned models regarding the Euclidean distance of updates. The results confirm, that scaling can increase the BA. ",
                "MESAS",
                " is already efficient for the unscaled version visualized in scenario  ",
                "1",
                " in ",
                "Tab.¬†",
                "1",
                ", hence is also effective for scaled models due to the intuition visualized in ",
                "Fig.¬†",
                "4",
                ". ",
                "Tab.¬†",
                "6",
                " depicts the results for the default scenario with a PDR of 0.3 for scaled poisoned models.",
                "We conducted an attack leveraging our strong adaptive adversary against FoolsGold¬†",
                "(Fung et¬†al",
                ".",
                ", ",
                "2020",
                ")",
                " and report the result in ",
                "Tab.¬†",
                "7",
                ". As strategy, we first trained a benign local model and transferred the trained parameters of the last layer to a fresh local model. We then excluded the parameters form training and poisoned the local model forcing the backdoor into some other layers. In ",
                "Tab.¬†",
                "8",
                " we additionally applied scaling. We can observe, that the BA of FoolsGold can be increased with those methods.",
                "Scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                " shows the result after adapting to Krum scores¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                " in an unscaled and scaled version. We forced the Euclidean distance between poisoned models and the global model to be similar to each other and on a benign level so that the defenses decide in favor of the poisoned models. ",
                "Fig.¬†",
                "12",
                " depicts the Krum scores for the default scenario associated with the default scenario in ",
                "Tab.¬†",
                "1",
                " to show, that the effective backdoor is based on coincidence and not intentionally forced by the attacker. With slight changes in some models, Krum could also decide for a benign model. However, after adaption, we can introduce a high BA intentionally in scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                ".",
                "Tab.¬†",
                "10",
                " and ",
                "Tab.¬†",
                "11",
                " show the results for a classical ",
                "intra-client",
                " ",
                "non-IID",
                " scenario crafted by ",
                "1-class",
                " ",
                "non-IID",
                " with ",
                "q",
                "=",
                "0.5",
                "ùëû",
                "0.5",
                "q=0.5",
                ". In both cases, ",
                "MESAS",
                " reduces the BA reliably with only one FP, while other defenses allow the attacker to embed 34.72% to 49.47% BA. ",
                "Tab.¬†",
                "12",
                " depicts the results for an increased PDR of 0.3, allowing the adversary to reach a BA of 57.68% without defense and up to 92.86% under active defenses. ",
                "MESAS",
                " still removes the poisoned models most effectively with only two FPs.",
                "In ",
                "Tab.¬†",
                "13",
                " and ",
                "Tab.¬†",
                "13",
                " we adapt all malicious models to a central benign value regarding the Cosine distance to the global model, which has the effect, that the models are inconspicuous in Krum scores, hence can circumvent Krum and ",
                "M-Krum",
                "¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                ", while ",
                "MESAS",
                " still erases the backdoor with only two FPs.",
                "Tab.¬†",
                "15",
                " and ",
                "Tab.¬†",
                "16",
                " show the results in a ",
                "inter-client",
                " ",
                "non-IID",
                " scenario based on our ",
                "Random-Non-IID",
                " strategy for a model in FL round one and highlights, that ",
                "MESAS",
                " outperforms other defenses in reducing the BA of the new global model.\n",
                "Tab.¬†",
                "17",
                " and ",
                "Tab.¬†",
                "18",
                " show the results for a setting in round 50,w here 100 clients are part of the federation and 20 clients are selected randomly in each round for training. Due to the later rounds, ",
                "MESAS",
                " is even more effective than other defenses and reduces the BA to a minimum.",
                "Tab.¬†",
                "19",
                " and ",
                "Tab.¬†",
                "20",
                " show the experiments results with a CNN training on MNIST¬†",
                "(Deng, ",
                "2012",
                ")",
                " and SqueezeNet¬†",
                "(Iandola et¬†al",
                ".",
                ", ",
                "2016",
                ")",
                " training on ",
                "CIFAR-10",
                " ",
                "(Krizhevsky et¬†al",
                ".",
                ", ",
                "2009",
                ")",
                ". The CNN consists of two convolutional layers, the first with 32 output layers, the second with 64 output layers, both applying a kernel size of 5. The output of the convolutional layers traverse a ReLU¬†",
                "(Agarap, ",
                "2018",
                ")",
                " and a 2D pooling layer, before being fed into three fully connected layers with output size 512, 256 and 10 output respectively. In both experiments, we used a ",
                "self-pre-trained",
                " model as global model. We can report perfect detection rate with just one FP for CNN and SqueezeNet, even if the backdoor is not yet embedded in the global model. Hence, a stronger adaption by the adversary would strengthen the detection capabilities of ",
                "MESAS",
                ". Other defenses instead can be circumvented by the adaptive adversary."
            ]
        ]
    },
    "A6.T20": {
        "caption": "Table 20. MA and BA in the default scenario with a SqueezeNet¬†(Iandola et¬†al., 2016) trained on CIFAR-10 (Krizhevsky et¬†al., 2009) in percent.",
        "table": "<table id=\"A6.T20.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A6.T20.1.2\" class=\"ltx_tr\">\n<td id=\"A6.T20.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\">Accuracies without defenses</td>\n<td id=\"A6.T20.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">MA</td>\n<td id=\"A6.T20.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T20.1.1\" class=\"ltx_tr\">\n<td id=\"A6.T20.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">1:</td>\n<td id=\"A6.T20.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Global model <math id=\"A6.T20.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"G^{r}\" display=\"inline\"><semantics id=\"A6.T20.1.1.1.m1.1a\"><msup id=\"A6.T20.1.1.1.m1.1.1\" xref=\"A6.T20.1.1.1.m1.1.1.cmml\"><mi id=\"A6.T20.1.1.1.m1.1.1.2\" xref=\"A6.T20.1.1.1.m1.1.1.2.cmml\">G</mi><mi id=\"A6.T20.1.1.1.m1.1.1.3\" xref=\"A6.T20.1.1.1.m1.1.1.3.cmml\">r</mi></msup><annotation-xml encoding=\"MathML-Content\" id=\"A6.T20.1.1.1.m1.1b\"><apply id=\"A6.T20.1.1.1.m1.1.1.cmml\" xref=\"A6.T20.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"A6.T20.1.1.1.m1.1.1.1.cmml\" xref=\"A6.T20.1.1.1.m1.1.1\">superscript</csymbol><ci id=\"A6.T20.1.1.1.m1.1.1.2.cmml\" xref=\"A6.T20.1.1.1.m1.1.1.2\">ùê∫</ci><ci id=\"A6.T20.1.1.1.m1.1.1.3.cmml\" xref=\"A6.T20.1.1.1.m1.1.1.3\">ùëü</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T20.1.1.1.m1.1c\">G^{r}</annotation></semantics></math>\n</td>\n<td id=\"A6.T20.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">53.06</td>\n<td id=\"A6.T20.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">8.3</td>\n</tr>\n<tr id=\"A6.T20.1.3\" class=\"ltx_tr\">\n<td id=\"A6.T20.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">2:</td>\n<td id=\"A6.T20.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Average of benign local models</td>\n<td id=\"A6.T20.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">56.04</td>\n<td id=\"A6.T20.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">5.67</td>\n</tr>\n<tr id=\"A6.T20.1.4\" class=\"ltx_tr\">\n<td id=\"A6.T20.1.4.1\" class=\"ltx_td ltx_align_left\">3:</td>\n<td id=\"A6.T20.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Average of poisoned local models</td>\n<td id=\"A6.T20.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">52.21</td>\n<td id=\"A6.T20.1.4.4\" class=\"ltx_td ltx_align_center\">40.03</td>\n</tr>\n<tr id=\"A6.T20.1.5\" class=\"ltx_tr\">\n<td id=\"A6.T20.1.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\">4:</td>\n<td id=\"A6.T20.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T20.1.5.2.1\" class=\"ltx_text\">FedAVG</span> with benign local models</td>\n<td id=\"A6.T20.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">61.03</td>\n<td id=\"A6.T20.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">5.82</td>\n</tr>\n<tr id=\"A6.T20.1.6\" class=\"ltx_tr\">\n<td id=\"A6.T20.1.6.1\" class=\"ltx_td ltx_align_left\">5:</td>\n<td id=\"A6.T20.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T20.1.6.2.1\" class=\"ltx_text\">FedAVG</span> with poisoned local models</td>\n<td id=\"A6.T20.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">56.33</td>\n<td id=\"A6.T20.1.6.4\" class=\"ltx_td ltx_align_center\">38.85</td>\n</tr>\n<tr id=\"A6.T20.1.7\" class=\"ltx_tr\">\n<td id=\"A6.T20.1.7.1\" class=\"ltx_td ltx_align_left ltx_border_t\">6:</td>\n<td id=\"A6.T20.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T20.1.7.2.1\" class=\"ltx_text\">FedAVG</span> with all local models</td>\n<td id=\"A6.T20.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">60.20</td>\n<td id=\"A6.T20.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">10.32</td>\n</tr>\n<tr id=\"A6.T20.1.8\" class=\"ltx_tr\">\n<td id=\"A6.T20.1.8.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\" colspan=\"2\">Global model accuracies after applying defenses</td>\n<td id=\"A6.T20.1.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\">MA</td>\n<td id=\"A6.T20.1.8.3\" class=\"ltx_td ltx_align_center ltx_border_tt ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T20.1.9\" class=\"ltx_tr\">\n<td id=\"A6.T20.1.9.1\" class=\"ltx_td ltx_align_left ltx_border_t\">7:</td>\n<td id=\"A6.T20.1.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Na√Øve Clustering</td>\n<td id=\"A6.T20.1.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">61.30</td>\n<td id=\"A6.T20.1.9.4\" class=\"ltx_td ltx_align_center ltx_border_t\">5.82</td>\n</tr>\n<tr id=\"A6.T20.1.10\" class=\"ltx_tr\">\n<td id=\"A6.T20.1.10.1\" class=\"ltx_td ltx_align_left\">8:</td>\n<td id=\"A6.T20.1.10.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FoolsGold¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Fung et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>\n</td>\n<td id=\"A6.T20.1.10.3\" class=\"ltx_td ltx_align_center ltx_border_r\">60.21</td>\n<td id=\"A6.T20.1.10.4\" class=\"ltx_td ltx_align_center\">10.32</td>\n</tr>\n<tr id=\"A6.T20.1.11\" class=\"ltx_tr\">\n<td id=\"A6.T20.1.11.1\" class=\"ltx_td ltx_align_left\">9:</td>\n<td id=\"A6.T20.1.11.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Krum¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T20.1.11.3\" class=\"ltx_td ltx_align_center ltx_border_r\">55.93</td>\n<td id=\"A6.T20.1.11.4\" class=\"ltx_td ltx_align_center\">5.44</td>\n</tr>\n<tr id=\"A6.T20.1.12\" class=\"ltx_tr\">\n<td id=\"A6.T20.1.12.1\" class=\"ltx_td ltx_align_left\">10:</td>\n<td id=\"A6.T20.1.12.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T20.1.12.2.1\" class=\"ltx_text\">M-Krum</span>¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T20.1.12.3\" class=\"ltx_td ltx_align_center ltx_border_r\">58.75</td>\n<td id=\"A6.T20.1.12.4\" class=\"ltx_td ltx_align_center\">16.17</td>\n</tr>\n<tr id=\"A6.T20.1.13\" class=\"ltx_tr\">\n<td id=\"A6.T20.1.13.1\" class=\"ltx_td ltx_align_left\">11:</td>\n<td id=\"A6.T20.1.13.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T20.1.13.3\" class=\"ltx_td ltx_align_center ltx_border_r\">60.18</td>\n<td id=\"A6.T20.1.13.4\" class=\"ltx_td ltx_align_center\">10.27</td>\n</tr>\n<tr id=\"A6.T20.1.14\" class=\"ltx_tr\">\n<td id=\"A6.T20.1.14.1\" class=\"ltx_td ltx_align_left\">12:</td>\n<td id=\"A6.T20.1.14.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip&amp;Noise¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T20.1.14.3\" class=\"ltx_td ltx_align_center ltx_border_r\">55.24</td>\n<td id=\"A6.T20.1.14.4\" class=\"ltx_td ltx_align_center\">4.73</td>\n</tr>\n<tr id=\"A6.T20.1.15\" class=\"ltx_tr\">\n<td id=\"A6.T20.1.15.1\" class=\"ltx_td ltx_align_left\">13:</td>\n<td id=\"A6.T20.1.15.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Flame¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Nguyen et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib69\" title=\"\" class=\"ltx_ref\">2022c</a>)</cite>\n</td>\n<td id=\"A6.T20.1.15.3\" class=\"ltx_td ltx_align_center ltx_border_r\">60.78</td>\n<td id=\"A6.T20.1.15.4\" class=\"ltx_td ltx_align_center\">5.45</td>\n</tr>\n<tr id=\"A6.T20.1.16\" class=\"ltx_tr\">\n<td id=\"A6.T20.1.16.1\" class=\"ltx_td ltx_align_left\">14:</td>\n<td id=\"A6.T20.1.16.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Mean¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T20.1.16.3\" class=\"ltx_td ltx_align_center ltx_border_r\">60.15</td>\n<td id=\"A6.T20.1.16.4\" class=\"ltx_td ltx_align_center\">10.04</td>\n</tr>\n<tr id=\"A6.T20.1.17\" class=\"ltx_tr\">\n<td id=\"A6.T20.1.17.1\" class=\"ltx_td ltx_align_left\">15:</td>\n<td id=\"A6.T20.1.17.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Median¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T20.1.17.3\" class=\"ltx_td ltx_align_center ltx_border_r\">59.68</td>\n<td id=\"A6.T20.1.17.4\" class=\"ltx_td ltx_align_center\">8.40</td>\n</tr>\n<tr id=\"A6.T20.1.18\" class=\"ltx_tr\">\n<td id=\"A6.T20.1.18.1\" class=\"ltx_td ltx_align_left\">16:</td>\n<td id=\"A6.T20.1.18.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FLTrust¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Cao et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib14\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>\n</td>\n<td id=\"A6.T20.1.18.3\" class=\"ltx_td ltx_align_center ltx_border_r\">55.99</td>\n<td id=\"A6.T20.1.18.4\" class=\"ltx_td ltx_align_center\">8.44</td>\n</tr>\n<tr id=\"A6.T20.1.19\" class=\"ltx_tr\">\n<td id=\"A6.T20.1.19.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">17:</td>\n<td id=\"A6.T20.1.19.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"A6.T20.1.19.2.1\" class=\"ltx_text ltx_font_bold\">MESAS</span></td>\n<td id=\"A6.T20.1.19.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">60.22</td>\n<td id=\"A6.T20.1.19.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"A6.T20.1.19.4.1\" class=\"ltx_text ltx_font_bold\">10.80</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In this section, we provide further results for our experiments, that could not be included in the main part of the paper due to space limitations. We selected the most interesting and representative results to be part of the main part, but report the rest below for completeness.",
                "Tab.¬†",
                "4",
                " reports the MAs corresponding to the BAs and ACCs in ",
                "Tab.¬†",
                "2",
                " for different poisoning methods without adaptive adversaries. Note, that ",
                "MESAS",
                " provides high MA independent of the applied poisoning attack. The table shows, that ",
                "MESAS",
                " does not negatively impact the MA and is also effective against untargeted attacks.",
                "Tab.¬†",
                "5",
                " shows the results for our default scenario with scaled poisoned models regarding the Euclidean distance of updates. The results confirm, that scaling can increase the BA. ",
                "MESAS",
                " is already efficient for the unscaled version visualized in scenario  ",
                "1",
                " in ",
                "Tab.¬†",
                "1",
                ", hence is also effective for scaled models due to the intuition visualized in ",
                "Fig.¬†",
                "4",
                ". ",
                "Tab.¬†",
                "6",
                " depicts the results for the default scenario with a PDR of 0.3 for scaled poisoned models.",
                "We conducted an attack leveraging our strong adaptive adversary against FoolsGold¬†",
                "(Fung et¬†al",
                ".",
                ", ",
                "2020",
                ")",
                " and report the result in ",
                "Tab.¬†",
                "7",
                ". As strategy, we first trained a benign local model and transferred the trained parameters of the last layer to a fresh local model. We then excluded the parameters form training and poisoned the local model forcing the backdoor into some other layers. In ",
                "Tab.¬†",
                "8",
                " we additionally applied scaling. We can observe, that the BA of FoolsGold can be increased with those methods.",
                "Scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                " shows the result after adapting to Krum scores¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                " in an unscaled and scaled version. We forced the Euclidean distance between poisoned models and the global model to be similar to each other and on a benign level so that the defenses decide in favor of the poisoned models. ",
                "Fig.¬†",
                "12",
                " depicts the Krum scores for the default scenario associated with the default scenario in ",
                "Tab.¬†",
                "1",
                " to show, that the effective backdoor is based on coincidence and not intentionally forced by the attacker. With slight changes in some models, Krum could also decide for a benign model. However, after adaption, we can introduce a high BA intentionally in scenario  ",
                "3",
                " of ",
                "Tab.¬†",
                "1",
                " and ",
                "Tab.¬†",
                "9",
                ".",
                "Tab.¬†",
                "10",
                " and ",
                "Tab.¬†",
                "11",
                " show the results for a classical ",
                "intra-client",
                " ",
                "non-IID",
                " scenario crafted by ",
                "1-class",
                " ",
                "non-IID",
                " with ",
                "q",
                "=",
                "0.5",
                "ùëû",
                "0.5",
                "q=0.5",
                ". In both cases, ",
                "MESAS",
                " reduces the BA reliably with only one FP, while other defenses allow the attacker to embed 34.72% to 49.47% BA. ",
                "Tab.¬†",
                "12",
                " depicts the results for an increased PDR of 0.3, allowing the adversary to reach a BA of 57.68% without defense and up to 92.86% under active defenses. ",
                "MESAS",
                " still removes the poisoned models most effectively with only two FPs.",
                "In ",
                "Tab.¬†",
                "13",
                " and ",
                "Tab.¬†",
                "13",
                " we adapt all malicious models to a central benign value regarding the Cosine distance to the global model, which has the effect, that the models are inconspicuous in Krum scores, hence can circumvent Krum and ",
                "M-Krum",
                "¬†",
                "(Blanchard et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                ", while ",
                "MESAS",
                " still erases the backdoor with only two FPs.",
                "Tab.¬†",
                "15",
                " and ",
                "Tab.¬†",
                "16",
                " show the results in a ",
                "inter-client",
                " ",
                "non-IID",
                " scenario based on our ",
                "Random-Non-IID",
                " strategy for a model in FL round one and highlights, that ",
                "MESAS",
                " outperforms other defenses in reducing the BA of the new global model.\n",
                "Tab.¬†",
                "17",
                " and ",
                "Tab.¬†",
                "18",
                " show the results for a setting in round 50,w here 100 clients are part of the federation and 20 clients are selected randomly in each round for training. Due to the later rounds, ",
                "MESAS",
                " is even more effective than other defenses and reduces the BA to a minimum.",
                "Tab.¬†",
                "19",
                " and ",
                "Tab.¬†",
                "20",
                " show the experiments results with a CNN training on MNIST¬†",
                "(Deng, ",
                "2012",
                ")",
                " and SqueezeNet¬†",
                "(Iandola et¬†al",
                ".",
                ", ",
                "2016",
                ")",
                " training on ",
                "CIFAR-10",
                " ",
                "(Krizhevsky et¬†al",
                ".",
                ", ",
                "2009",
                ")",
                ". The CNN consists of two convolutional layers, the first with 32 output layers, the second with 64 output layers, both applying a kernel size of 5. The output of the convolutional layers traverse a ReLU¬†",
                "(Agarap, ",
                "2018",
                ")",
                " and a 2D pooling layer, before being fed into three fully connected layers with output size 512, 256 and 10 output respectively. In both experiments, we used a ",
                "self-pre-trained",
                " model as global model. We can report perfect detection rate with just one FP for CNN and SqueezeNet, even if the backdoor is not yet embedded in the global model. Hence, a stronger adaption by the adversary would strengthen the detection capabilities of ",
                "MESAS",
                ". Other defenses instead can be circumvented by the adaptive adversary."
            ]
        ]
    },
    "A6.T21": {
        "caption": "Table 21. MA and BA in the default scenario with MNIST¬†(Deng, 2012) as a dataset and PDR of 0.3 and scaled\npoisoned models regarding the Euclidean distance of updates in percent.",
        "table": "<table id=\"A6.T21.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A6.T21.1.2\" class=\"ltx_tr\">\n<td id=\"A6.T21.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\">Accuracies without defenses</td>\n<td id=\"A6.T21.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">MA</td>\n<td id=\"A6.T21.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T21.1.1\" class=\"ltx_tr\">\n<td id=\"A6.T21.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">1:</td>\n<td id=\"A6.T21.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Global model <math id=\"A6.T21.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"G^{r}\" display=\"inline\"><semantics id=\"A6.T21.1.1.1.m1.1a\"><msup id=\"A6.T21.1.1.1.m1.1.1\" xref=\"A6.T21.1.1.1.m1.1.1.cmml\"><mi id=\"A6.T21.1.1.1.m1.1.1.2\" xref=\"A6.T21.1.1.1.m1.1.1.2.cmml\">G</mi><mi id=\"A6.T21.1.1.1.m1.1.1.3\" xref=\"A6.T21.1.1.1.m1.1.1.3.cmml\">r</mi></msup><annotation-xml encoding=\"MathML-Content\" id=\"A6.T21.1.1.1.m1.1b\"><apply id=\"A6.T21.1.1.1.m1.1.1.cmml\" xref=\"A6.T21.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"A6.T21.1.1.1.m1.1.1.1.cmml\" xref=\"A6.T21.1.1.1.m1.1.1\">superscript</csymbol><ci id=\"A6.T21.1.1.1.m1.1.1.2.cmml\" xref=\"A6.T21.1.1.1.m1.1.1.2\">ùê∫</ci><ci id=\"A6.T21.1.1.1.m1.1.1.3.cmml\" xref=\"A6.T21.1.1.1.m1.1.1.3\">ùëü</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T21.1.1.1.m1.1c\">G^{r}</annotation></semantics></math>\n</td>\n<td id=\"A6.T21.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">97.60</td>\n<td id=\"A6.T21.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.43</td>\n</tr>\n<tr id=\"A6.T21.1.3\" class=\"ltx_tr\">\n<td id=\"A6.T21.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">2:</td>\n<td id=\"A6.T21.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Average of benign local models</td>\n<td id=\"A6.T21.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">94.30</td>\n<td id=\"A6.T21.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.40</td>\n</tr>\n<tr id=\"A6.T21.1.4\" class=\"ltx_tr\">\n<td id=\"A6.T21.1.4.1\" class=\"ltx_td ltx_align_left\">3:</td>\n<td id=\"A6.T21.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Average of poisoned local models</td>\n<td id=\"A6.T21.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">91.73</td>\n<td id=\"A6.T21.1.4.4\" class=\"ltx_td ltx_align_center\">100.00</td>\n</tr>\n<tr id=\"A6.T21.1.5\" class=\"ltx_tr\">\n<td id=\"A6.T21.1.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\">4:</td>\n<td id=\"A6.T21.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T21.1.5.2.1\" class=\"ltx_text\">FedAVG</span> with benign local models</td>\n<td id=\"A6.T21.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">97.22</td>\n<td id=\"A6.T21.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.45</td>\n</tr>\n<tr id=\"A6.T21.1.6\" class=\"ltx_tr\">\n<td id=\"A6.T21.1.6.1\" class=\"ltx_td ltx_align_left\">5:</td>\n<td id=\"A6.T21.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T21.1.6.2.1\" class=\"ltx_text\">FedAVG</span> with poisoned local models</td>\n<td id=\"A6.T21.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">97.20</td>\n<td id=\"A6.T21.1.6.4\" class=\"ltx_td ltx_align_center\">100.00</td>\n</tr>\n<tr id=\"A6.T21.1.7\" class=\"ltx_tr\">\n<td id=\"A6.T21.1.7.1\" class=\"ltx_td ltx_align_left ltx_border_t\">6:</td>\n<td id=\"A6.T21.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T21.1.7.2.1\" class=\"ltx_text\">FedAVG</span> with all local models</td>\n<td id=\"A6.T21.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">97.24</td>\n<td id=\"A6.T21.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">2.92</td>\n</tr>\n<tr id=\"A6.T21.1.8\" class=\"ltx_tr\">\n<td id=\"A6.T21.1.8.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\" colspan=\"2\">Global model accuracies after applying defenses</td>\n<td id=\"A6.T21.1.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\">MA</td>\n<td id=\"A6.T21.1.8.3\" class=\"ltx_td ltx_align_center ltx_border_tt ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T21.1.9\" class=\"ltx_tr\">\n<td id=\"A6.T21.1.9.1\" class=\"ltx_td ltx_align_left ltx_border_t\">7:</td>\n<td id=\"A6.T21.1.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Na√Øve Clustering</td>\n<td id=\"A6.T21.1.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">97.22</td>\n<td id=\"A6.T21.1.9.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.45</td>\n</tr>\n<tr id=\"A6.T21.1.10\" class=\"ltx_tr\">\n<td id=\"A6.T21.1.10.1\" class=\"ltx_td ltx_align_left\">8:</td>\n<td id=\"A6.T21.1.10.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FoolsGold¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Fung et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>\n</td>\n<td id=\"A6.T21.1.10.3\" class=\"ltx_td ltx_align_center ltx_border_r\">97.22</td>\n<td id=\"A6.T21.1.10.4\" class=\"ltx_td ltx_align_center\">0.45</td>\n</tr>\n<tr id=\"A6.T21.1.11\" class=\"ltx_tr\">\n<td id=\"A6.T21.1.11.1\" class=\"ltx_td ltx_align_left\">9:</td>\n<td id=\"A6.T21.1.11.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Krum¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T21.1.11.3\" class=\"ltx_td ltx_align_center ltx_border_r\">95.31</td>\n<td id=\"A6.T21.1.11.4\" class=\"ltx_td ltx_align_center\">100.00</td>\n</tr>\n<tr id=\"A6.T21.1.12\" class=\"ltx_tr\">\n<td id=\"A6.T21.1.12.1\" class=\"ltx_td ltx_align_left\">10:</td>\n<td id=\"A6.T21.1.12.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T21.1.12.2.1\" class=\"ltx_text\">M-Krum</span>¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T21.1.12.3\" class=\"ltx_td ltx_align_center ltx_border_r\">97.26</td>\n<td id=\"A6.T21.1.12.4\" class=\"ltx_td ltx_align_center\">46.93</td>\n</tr>\n<tr id=\"A6.T21.1.13\" class=\"ltx_tr\">\n<td id=\"A6.T21.1.13.1\" class=\"ltx_td ltx_align_left\">11:</td>\n<td id=\"A6.T21.1.13.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T21.1.13.3\" class=\"ltx_td ltx_align_center ltx_border_r\">97.26</td>\n<td id=\"A6.T21.1.13.4\" class=\"ltx_td ltx_align_center\">1.74</td>\n</tr>\n<tr id=\"A6.T21.1.14\" class=\"ltx_tr\">\n<td id=\"A6.T21.1.14.1\" class=\"ltx_td ltx_align_left\">12:</td>\n<td id=\"A6.T21.1.14.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip&amp;Noise¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T21.1.14.3\" class=\"ltx_td ltx_align_center ltx_border_r\">86.73</td>\n<td id=\"A6.T21.1.14.4\" class=\"ltx_td ltx_align_center\">48.05</td>\n</tr>\n<tr id=\"A6.T21.1.15\" class=\"ltx_tr\">\n<td id=\"A6.T21.1.15.1\" class=\"ltx_td ltx_align_left\">13:</td>\n<td id=\"A6.T21.1.15.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Flame¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Nguyen et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib69\" title=\"\" class=\"ltx_ref\">2022c</a>)</cite>\n</td>\n<td id=\"A6.T21.1.15.3\" class=\"ltx_td ltx_align_center ltx_border_r\">97.45</td>\n<td id=\"A6.T21.1.15.4\" class=\"ltx_td ltx_align_center\">3.03</td>\n</tr>\n<tr id=\"A6.T21.1.16\" class=\"ltx_tr\">\n<td id=\"A6.T21.1.16.1\" class=\"ltx_td ltx_align_left\">14:</td>\n<td id=\"A6.T21.1.16.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Mean¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T21.1.16.3\" class=\"ltx_td ltx_align_center ltx_border_r\">97.35</td>\n<td id=\"A6.T21.1.16.4\" class=\"ltx_td ltx_align_center\">1.91</td>\n</tr>\n<tr id=\"A6.T21.1.17\" class=\"ltx_tr\">\n<td id=\"A6.T21.1.17.1\" class=\"ltx_td ltx_align_left\">15:</td>\n<td id=\"A6.T21.1.17.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Median¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T21.1.17.3\" class=\"ltx_td ltx_align_center ltx_border_r\">96.69</td>\n<td id=\"A6.T21.1.17.4\" class=\"ltx_td ltx_align_center\">2.15</td>\n</tr>\n<tr id=\"A6.T21.1.18\" class=\"ltx_tr\">\n<td id=\"A6.T21.1.18.1\" class=\"ltx_td ltx_align_left\">16:</td>\n<td id=\"A6.T21.1.18.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FLTrust¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Cao et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib14\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>\n</td>\n<td id=\"A6.T21.1.18.3\" class=\"ltx_td ltx_align_center ltx_border_r\">97.34</td>\n<td id=\"A6.T21.1.18.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T21.1.18.4.1\" class=\"ltx_text ltx_font_bold\">0.62</span></td>\n</tr>\n<tr id=\"A6.T21.1.19\" class=\"ltx_tr\">\n<td id=\"A6.T21.1.19.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">17:</td>\n<td id=\"A6.T21.1.19.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"A6.T21.1.19.2.1\" class=\"ltx_text ltx_font_bold\">MESAS</span></td>\n<td id=\"A6.T21.1.19.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">97.18</td>\n<td id=\"A6.T21.1.19.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"A6.T21.1.19.4.1\" class=\"ltx_text ltx_font_bold\">0.42</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "All randomness within the system was seeded with 42 within our experiments, but we conducted spot tests with ",
                "s",
                "‚Äã",
                "e",
                "‚Äã",
                "e",
                "‚Äã",
                "d",
                "r",
                "‚Äã",
                "a",
                "‚Äã",
                "n",
                "‚Äã",
                "d",
                "=",
                "{",
                "0",
                ",",
                "1",
                ",",
                "13",
                "}",
                "ùë†",
                "ùëí",
                "ùëí",
                "subscript",
                "ùëë",
                "ùëü",
                "ùëé",
                "ùëõ",
                "ùëë",
                "0",
                "1",
                "13",
                "seed_{rand}=\\{0,1,13\\}",
                " and found similar results, hence, the seed does not influence our findings.",
                "We changed LR of the default scenario to ",
                "L",
                "‚Äã",
                "R",
                "=",
                "{",
                "0.1",
                ",",
                "0.01",
                ",",
                "0.001",
                "}",
                "ùêø",
                "ùëÖ",
                "0.1",
                "0.01",
                "0.001",
                "LR=\\{0.1,0.01,0.001\\}",
                " and found, that 0.01 is the best choice for benign and adversarial training regarding the local and global MA and BA, hence a valid choice for our experiments. A LR or 0.1 is too big destructing the adversarial models to na√Øve classifiers and reducing the MA of benign clients to 30% on average. For LR 0.001, it depends on the round ",
                "r",
                "ùëü",
                "r",
                ", where it is used. In early rounds, 0.01 is the better choice to speed up the federations training process, but in advanced FL rounds a lower LR naturally increases the accuracies, as in every machine learning scenario. Hence, the MA can be increased, but it is also more difficult for the adversary to adapt some metrics within the defined epochs. Nevertheless, ",
                "MESAS",
                " achieved the same detection ACC with both settings, thus detecting the na√Øve classifiers for LR 0.01, which behave similar to a untargeted poisoning attacks, and the models with better accuracies in the 0.001 LR setting. We set the LR fixed to 0.01 as a good ",
                "trade-off",
                " between both scenarios.",
                "In all our experiments, we keep the PMR as high as possible without violating the majority assumption of ",
                "Sect.¬†",
                "3.1",
                ". Since ",
                "MESAS",
                " does not remove poisoned models with a single test, but prunes different poisonings gradually, we automatically test lower PMRs within range ",
                "[",
                "0.0",
                ",",
                "0.5",
                "[",
                "[0.0,0.5[",
                ", demonstrating the independence of ",
                "MESAS",
                " to PMRs.",
                "Since ",
                "MESAS",
                " does not leverage the plain MA values, we set ",
                "Œ±",
                "ùõº",
                "\\alpha",
                " as low as possible, so that the adversary still achieves a high BA while simultaneously applying a maximum adaption level. We tested ",
                "Œ±",
                "=",
                "[",
                "0.1",
                ",",
                "0.2",
                ",",
                "‚Ä¶",
                ",",
                "0.9",
                "]",
                "ùõº",
                "0.1",
                "0.2",
                "‚Ä¶",
                "0.9",
                "\\alpha=[0.1,0.2,...,0.9]",
                " and found ",
                "Œ±",
                "=",
                "0.3",
                "ùõº",
                "0.3",
                "\\alpha=0.3",
                " being the most beneficial choice for ",
                "A",
                "ùê¥",
                "A",
                ".",
                "23",
                "23",
                "23",
                "Besides adapting to all ",
                "MESAS",
                " metrics, we conducted experiments starting with only adapting to COS and then adding the other metircs ",
                "step-wise",
                " to find a valid ",
                "Œ±",
                "ùõº",
                "\\alpha",
                ", since adapting to all metrics of ",
                "MESAS",
                " simultaneously is not possible in the end.",
                " For higher values, the anomaly to a benign model increases and any defense leveraging the respective metrics detects the attack even clearer, for lower values, the model completely focuses on adapting to metrics and ignores the BA, thus does not enable the backdoor. Consequently, in parallel to the BA, the MA is low having the same effect as an untargeted poisoning attack. In such scenarios an adaption to all metrics of ",
                "MESAS",
                " appears to be very difficult allowing ",
                "MESAS",
                " to be effective. Thus ",
                "MESAS",
                " is independent of ",
                "Œ±",
                "ùõº",
                "\\alpha",
                ".",
                "Tab.¬†",
                "21",
                " and ",
                "Tab.¬†",
                "22",
                " show results for experiments with MNIST¬†",
                "(Deng, ",
                "2012",
                ")",
                " and GTSRB¬†",
                "(Stallkamp et¬†al",
                ".",
                ", ",
                "2012",
                ")",
                " respectivelly, showing that ",
                "MESAS",
                " is also effective with varying datasets. ",
                "MESAS",
                " detects the poisoned models with one fp for MNIST and 100% ACC for GTSRB even if the backdoor is not yet strong enough to poison the new global model. Further strengthening of the BA by the adversary would increase the significance within the metrics of ",
                "MESAS",
                ".",
                "Furthermore, we conducted additional experiments, where models were trained starting from a randomly initialized model for 100 rounds until reaching stability. The performance of the defense mechanisms, along with scenarios encompassing no defense and no attack, was analyzed and depicted in ",
                "Fig.¬†",
                "13",
                " and ",
                "Fig.¬†",
                "14",
                ".",
                "24",
                "24",
                "24",
                "We do not report results for Flame¬†",
                "(Nguyen et¬†al",
                ".",
                ", ",
                "2022c",
                ")",
                ", since for our setup, the applied noise did influence the model so that the training process stopped at round five. Further, FLTrust is only reported till round 45, since afterward weights of zero are assigned to each update leading to a na√Øve model.",
                " Notably, the results revealed that ",
                "MESAS",
                " consistently yielded the low BA values similar to the no-attack scenario, indicating that the backdoor was effectively prevented from being embedded in the final global model under ",
                "MESAS",
                ". In contrast, other defense approaches exhibited relatively higher BAs. Only FoolsGold¬†",
                "(Fung et¬†al",
                ".",
                ", ",
                "2020",
                ")",
                " could reach low BAs in certain rounds, too. Note, that these BA values were obtained without the incorporation of adaptation mechanisms. Consequently, with the inclusion of adaptability in defense strategies (cf.¬†",
                "Sect.¬†",
                "5.2.1",
                "), the BAs for adaptive attacks could be further increased. Additionally, ",
                "MESAS",
                " did not compromise the overall MA of the system, thereby avoiding any significant downsides in its application. The preservation of MA further underscores the efficacy and advantages of ",
                "MESAS",
                "."
            ]
        ]
    },
    "A6.T22": {
        "caption": "Table 22. MA and BA in the default scenario with GTSRB¬†(Stallkamp et¬†al., 2012) as a dataset and PDR of 0.3 and scaled\npoisoned models regarding the Euclidean distance of updates in percent.",
        "table": "<table id=\"A6.T22.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A6.T22.1.2\" class=\"ltx_tr\">\n<td id=\"A6.T22.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\">Accuracies without defenses</td>\n<td id=\"A6.T22.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">MA</td>\n<td id=\"A6.T22.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T22.1.1\" class=\"ltx_tr\">\n<td id=\"A6.T22.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">1:</td>\n<td id=\"A6.T22.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Global model <math id=\"A6.T22.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"G^{r}\" display=\"inline\"><semantics id=\"A6.T22.1.1.1.m1.1a\"><msup id=\"A6.T22.1.1.1.m1.1.1\" xref=\"A6.T22.1.1.1.m1.1.1.cmml\"><mi id=\"A6.T22.1.1.1.m1.1.1.2\" xref=\"A6.T22.1.1.1.m1.1.1.2.cmml\">G</mi><mi id=\"A6.T22.1.1.1.m1.1.1.3\" xref=\"A6.T22.1.1.1.m1.1.1.3.cmml\">r</mi></msup><annotation-xml encoding=\"MathML-Content\" id=\"A6.T22.1.1.1.m1.1b\"><apply id=\"A6.T22.1.1.1.m1.1.1.cmml\" xref=\"A6.T22.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"A6.T22.1.1.1.m1.1.1.1.cmml\" xref=\"A6.T22.1.1.1.m1.1.1\">superscript</csymbol><ci id=\"A6.T22.1.1.1.m1.1.1.2.cmml\" xref=\"A6.T22.1.1.1.m1.1.1.2\">ùê∫</ci><ci id=\"A6.T22.1.1.1.m1.1.1.3.cmml\" xref=\"A6.T22.1.1.1.m1.1.1.3\">ùëü</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T22.1.1.1.m1.1c\">G^{r}</annotation></semantics></math>\n</td>\n<td id=\"A6.T22.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">86.62</td>\n<td id=\"A6.T22.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.96</td>\n</tr>\n<tr id=\"A6.T22.1.3\" class=\"ltx_tr\">\n<td id=\"A6.T22.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">2:</td>\n<td id=\"A6.T22.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Average of benign local models</td>\n<td id=\"A6.T22.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">78.43</td>\n<td id=\"A6.T22.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.59</td>\n</tr>\n<tr id=\"A6.T22.1.4\" class=\"ltx_tr\">\n<td id=\"A6.T22.1.4.1\" class=\"ltx_td ltx_align_left\">3:</td>\n<td id=\"A6.T22.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Average of poisoned local models</td>\n<td id=\"A6.T22.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">62.42</td>\n<td id=\"A6.T22.1.4.4\" class=\"ltx_td ltx_align_center\">94.38</td>\n</tr>\n<tr id=\"A6.T22.1.5\" class=\"ltx_tr\">\n<td id=\"A6.T22.1.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\">4:</td>\n<td id=\"A6.T22.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T22.1.5.2.1\" class=\"ltx_text\">FedAVG</span> with benign local models</td>\n<td id=\"A6.T22.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">85.77</td>\n<td id=\"A6.T22.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">1.06</td>\n</tr>\n<tr id=\"A6.T22.1.6\" class=\"ltx_tr\">\n<td id=\"A6.T22.1.6.1\" class=\"ltx_td ltx_align_left\">5:</td>\n<td id=\"A6.T22.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T22.1.6.2.1\" class=\"ltx_text\">FedAVG</span> with poisoned local models</td>\n<td id=\"A6.T22.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">83.00</td>\n<td id=\"A6.T22.1.6.4\" class=\"ltx_td ltx_align_center\">90.81</td>\n</tr>\n<tr id=\"A6.T22.1.7\" class=\"ltx_tr\">\n<td id=\"A6.T22.1.7.1\" class=\"ltx_td ltx_align_left ltx_border_t\">6:</td>\n<td id=\"A6.T22.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<span id=\"A6.T22.1.7.2.1\" class=\"ltx_text\">FedAVG</span> with all local models</td>\n<td id=\"A6.T22.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">86.19</td>\n<td id=\"A6.T22.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">8.01</td>\n</tr>\n<tr id=\"A6.T22.1.8\" class=\"ltx_tr\">\n<td id=\"A6.T22.1.8.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\" colspan=\"2\">Global model accuracies after applying defenses</td>\n<td id=\"A6.T22.1.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_tt\">MA</td>\n<td id=\"A6.T22.1.8.3\" class=\"ltx_td ltx_align_center ltx_border_tt ltx_border_tt\">BA</td>\n</tr>\n<tr id=\"A6.T22.1.9\" class=\"ltx_tr\">\n<td id=\"A6.T22.1.9.1\" class=\"ltx_td ltx_align_left ltx_border_t\">7:</td>\n<td id=\"A6.T22.1.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Na√Øve Clustering</td>\n<td id=\"A6.T22.1.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">85.57</td>\n<td id=\"A6.T22.1.9.4\" class=\"ltx_td ltx_align_center ltx_border_t\">31.65</td>\n</tr>\n<tr id=\"A6.T22.1.10\" class=\"ltx_tr\">\n<td id=\"A6.T22.1.10.1\" class=\"ltx_td ltx_align_left\">8:</td>\n<td id=\"A6.T22.1.10.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FoolsGold¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Fung et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>\n</td>\n<td id=\"A6.T22.1.10.3\" class=\"ltx_td ltx_align_center ltx_border_r\">85.12</td>\n<td id=\"A6.T22.1.10.4\" class=\"ltx_td ltx_align_center\">0.70</td>\n</tr>\n<tr id=\"A6.T22.1.11\" class=\"ltx_tr\">\n<td id=\"A6.T22.1.11.1\" class=\"ltx_td ltx_align_left\">9:</td>\n<td id=\"A6.T22.1.11.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Krum¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T22.1.11.3\" class=\"ltx_td ltx_align_center ltx_border_r\">88.57</td>\n<td id=\"A6.T22.1.11.4\" class=\"ltx_td ltx_align_center\">1.15</td>\n</tr>\n<tr id=\"A6.T22.1.12\" class=\"ltx_tr\">\n<td id=\"A6.T22.1.12.1\" class=\"ltx_td ltx_align_left\">10:</td>\n<td id=\"A6.T22.1.12.2\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"A6.T22.1.12.2.1\" class=\"ltx_text\">M-Krum</span>¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Blanchard et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"A6.T22.1.12.3\" class=\"ltx_td ltx_align_center ltx_border_r\">88.08</td>\n<td id=\"A6.T22.1.12.4\" class=\"ltx_td ltx_align_center\">0.92</td>\n</tr>\n<tr id=\"A6.T22.1.13\" class=\"ltx_tr\">\n<td id=\"A6.T22.1.13.1\" class=\"ltx_td ltx_align_left\">11:</td>\n<td id=\"A6.T22.1.13.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T22.1.13.3\" class=\"ltx_td ltx_align_center ltx_border_r\">86.21</td>\n<td id=\"A6.T22.1.13.4\" class=\"ltx_td ltx_align_center\">4.39</td>\n</tr>\n<tr id=\"A6.T22.1.14\" class=\"ltx_tr\">\n<td id=\"A6.T22.1.14.1\" class=\"ltx_td ltx_align_left\">12:</td>\n<td id=\"A6.T22.1.14.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Clip&amp;Noise¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib61\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T22.1.14.3\" class=\"ltx_td ltx_align_center ltx_border_r\">14.98</td>\n<td id=\"A6.T22.1.14.4\" class=\"ltx_td ltx_align_center\">91.72</td>\n</tr>\n<tr id=\"A6.T22.1.15\" class=\"ltx_tr\">\n<td id=\"A6.T22.1.15.1\" class=\"ltx_td ltx_align_left\">13:</td>\n<td id=\"A6.T22.1.15.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Flame¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Nguyen et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib69\" title=\"\" class=\"ltx_ref\">2022c</a>)</cite>\n</td>\n<td id=\"A6.T22.1.15.3\" class=\"ltx_td ltx_align_center ltx_border_r\">84.29</td>\n<td id=\"A6.T22.1.15.4\" class=\"ltx_td ltx_align_center\">13.42</td>\n</tr>\n<tr id=\"A6.T22.1.16\" class=\"ltx_tr\">\n<td id=\"A6.T22.1.16.1\" class=\"ltx_td ltx_align_left\">14:</td>\n<td id=\"A6.T22.1.16.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Mean¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T22.1.16.3\" class=\"ltx_td ltx_align_center ltx_border_r\">86.30</td>\n<td id=\"A6.T22.1.16.4\" class=\"ltx_td ltx_align_center\">4.26</td>\n</tr>\n<tr id=\"A6.T22.1.17\" class=\"ltx_tr\">\n<td id=\"A6.T22.1.17.1\" class=\"ltx_td ltx_align_left\">15:</td>\n<td id=\"A6.T22.1.17.2\" class=\"ltx_td ltx_align_center ltx_border_r\">T-Median¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Yin et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib115\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>\n</td>\n<td id=\"A6.T22.1.17.3\" class=\"ltx_td ltx_align_center ltx_border_r\">74.22</td>\n<td id=\"A6.T22.1.17.4\" class=\"ltx_td ltx_align_center\">1.61</td>\n</tr>\n<tr id=\"A6.T22.1.18\" class=\"ltx_tr\">\n<td id=\"A6.T22.1.18.1\" class=\"ltx_td ltx_align_left\">16:</td>\n<td id=\"A6.T22.1.18.2\" class=\"ltx_td ltx_align_center ltx_border_r\">FLTrust¬†<cite class=\"ltx_cite ltx_citemacro_citep\">(Cao et¬†al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib14\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>\n</td>\n<td id=\"A6.T22.1.18.3\" class=\"ltx_td ltx_align_center ltx_border_r\">86.73</td>\n<td id=\"A6.T22.1.18.4\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T22.1.18.4.1\" class=\"ltx_text ltx_font_bold\">1.04</span></td>\n</tr>\n<tr id=\"A6.T22.1.19\" class=\"ltx_tr\">\n<td id=\"A6.T22.1.19.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">17:</td>\n<td id=\"A6.T22.1.19.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"A6.T22.1.19.2.1\" class=\"ltx_text ltx_font_bold\">MESAS</span></td>\n<td id=\"A6.T22.1.19.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">85.12</td>\n<td id=\"A6.T22.1.19.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"A6.T22.1.19.4.1\" class=\"ltx_text ltx_font_bold\">0.70</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "All randomness within the system was seeded with 42 within our experiments, but we conducted spot tests with ",
                "s",
                "‚Äã",
                "e",
                "‚Äã",
                "e",
                "‚Äã",
                "d",
                "r",
                "‚Äã",
                "a",
                "‚Äã",
                "n",
                "‚Äã",
                "d",
                "=",
                "{",
                "0",
                ",",
                "1",
                ",",
                "13",
                "}",
                "ùë†",
                "ùëí",
                "ùëí",
                "subscript",
                "ùëë",
                "ùëü",
                "ùëé",
                "ùëõ",
                "ùëë",
                "0",
                "1",
                "13",
                "seed_{rand}=\\{0,1,13\\}",
                " and found similar results, hence, the seed does not influence our findings.",
                "We changed LR of the default scenario to ",
                "L",
                "‚Äã",
                "R",
                "=",
                "{",
                "0.1",
                ",",
                "0.01",
                ",",
                "0.001",
                "}",
                "ùêø",
                "ùëÖ",
                "0.1",
                "0.01",
                "0.001",
                "LR=\\{0.1,0.01,0.001\\}",
                " and found, that 0.01 is the best choice for benign and adversarial training regarding the local and global MA and BA, hence a valid choice for our experiments. A LR or 0.1 is too big destructing the adversarial models to na√Øve classifiers and reducing the MA of benign clients to 30% on average. For LR 0.001, it depends on the round ",
                "r",
                "ùëü",
                "r",
                ", where it is used. In early rounds, 0.01 is the better choice to speed up the federations training process, but in advanced FL rounds a lower LR naturally increases the accuracies, as in every machine learning scenario. Hence, the MA can be increased, but it is also more difficult for the adversary to adapt some metrics within the defined epochs. Nevertheless, ",
                "MESAS",
                " achieved the same detection ACC with both settings, thus detecting the na√Øve classifiers for LR 0.01, which behave similar to a untargeted poisoning attacks, and the models with better accuracies in the 0.001 LR setting. We set the LR fixed to 0.01 as a good ",
                "trade-off",
                " between both scenarios.",
                "In all our experiments, we keep the PMR as high as possible without violating the majority assumption of ",
                "Sect.¬†",
                "3.1",
                ". Since ",
                "MESAS",
                " does not remove poisoned models with a single test, but prunes different poisonings gradually, we automatically test lower PMRs within range ",
                "[",
                "0.0",
                ",",
                "0.5",
                "[",
                "[0.0,0.5[",
                ", demonstrating the independence of ",
                "MESAS",
                " to PMRs.",
                "Since ",
                "MESAS",
                " does not leverage the plain MA values, we set ",
                "Œ±",
                "ùõº",
                "\\alpha",
                " as low as possible, so that the adversary still achieves a high BA while simultaneously applying a maximum adaption level. We tested ",
                "Œ±",
                "=",
                "[",
                "0.1",
                ",",
                "0.2",
                ",",
                "‚Ä¶",
                ",",
                "0.9",
                "]",
                "ùõº",
                "0.1",
                "0.2",
                "‚Ä¶",
                "0.9",
                "\\alpha=[0.1,0.2,...,0.9]",
                " and found ",
                "Œ±",
                "=",
                "0.3",
                "ùõº",
                "0.3",
                "\\alpha=0.3",
                " being the most beneficial choice for ",
                "A",
                "ùê¥",
                "A",
                ".",
                "23",
                "23",
                "23",
                "Besides adapting to all ",
                "MESAS",
                " metrics, we conducted experiments starting with only adapting to COS and then adding the other metircs ",
                "step-wise",
                " to find a valid ",
                "Œ±",
                "ùõº",
                "\\alpha",
                ", since adapting to all metrics of ",
                "MESAS",
                " simultaneously is not possible in the end.",
                " For higher values, the anomaly to a benign model increases and any defense leveraging the respective metrics detects the attack even clearer, for lower values, the model completely focuses on adapting to metrics and ignores the BA, thus does not enable the backdoor. Consequently, in parallel to the BA, the MA is low having the same effect as an untargeted poisoning attack. In such scenarios an adaption to all metrics of ",
                "MESAS",
                " appears to be very difficult allowing ",
                "MESAS",
                " to be effective. Thus ",
                "MESAS",
                " is independent of ",
                "Œ±",
                "ùõº",
                "\\alpha",
                ".",
                "Tab.¬†",
                "21",
                " and ",
                "Tab.¬†",
                "22",
                " show results for experiments with MNIST¬†",
                "(Deng, ",
                "2012",
                ")",
                " and GTSRB¬†",
                "(Stallkamp et¬†al",
                ".",
                ", ",
                "2012",
                ")",
                " respectivelly, showing that ",
                "MESAS",
                " is also effective with varying datasets. ",
                "MESAS",
                " detects the poisoned models with one fp for MNIST and 100% ACC for GTSRB even if the backdoor is not yet strong enough to poison the new global model. Further strengthening of the BA by the adversary would increase the significance within the metrics of ",
                "MESAS",
                ".",
                "Furthermore, we conducted additional experiments, where models were trained starting from a randomly initialized model for 100 rounds until reaching stability. The performance of the defense mechanisms, along with scenarios encompassing no defense and no attack, was analyzed and depicted in ",
                "Fig.¬†",
                "13",
                " and ",
                "Fig.¬†",
                "14",
                ".",
                "24",
                "24",
                "24",
                "We do not report results for Flame¬†",
                "(Nguyen et¬†al",
                ".",
                ", ",
                "2022c",
                ")",
                ", since for our setup, the applied noise did influence the model so that the training process stopped at round five. Further, FLTrust is only reported till round 45, since afterward weights of zero are assigned to each update leading to a na√Øve model.",
                " Notably, the results revealed that ",
                "MESAS",
                " consistently yielded the low BA values similar to the no-attack scenario, indicating that the backdoor was effectively prevented from being embedded in the final global model under ",
                "MESAS",
                ". In contrast, other defense approaches exhibited relatively higher BAs. Only FoolsGold¬†",
                "(Fung et¬†al",
                ".",
                ", ",
                "2020",
                ")",
                " could reach low BAs in certain rounds, too. Note, that these BA values were obtained without the incorporation of adaptation mechanisms. Consequently, with the inclusion of adaptability in defense strategies (cf.¬†",
                "Sect.¬†",
                "5.2.1",
                "), the BAs for adaptive attacks could be further increased. Additionally, ",
                "MESAS",
                " did not compromise the overall MA of the system, thereby avoiding any significant downsides in its application. The preservation of MA further underscores the efficacy and advantages of ",
                "MESAS",
                "."
            ]
        ]
    },
    "A8.T23": {
        "caption": "Table 23. Sample frequencies for each label in the clients‚Äô datasets for our Random-Non-IID strategy.",
        "table": "<table id=\"A8.T23.5\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A8.T23.5.1\" class=\"ltx_tr\">\n<td id=\"A8.T23.5.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" rowspan=\"2\"><span id=\"A8.T23.5.1.1.1\" class=\"ltx_text\">Client</span></td>\n<td id=\"A8.T23.5.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"10\">Label</td>\n</tr>\n<tr id=\"A8.T23.5.2\" class=\"ltx_tr\">\n<td id=\"A8.T23.5.2.1\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">1</td>\n<td id=\"A8.T23.5.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\">2</td>\n<td id=\"A8.T23.5.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\">3</td>\n<td id=\"A8.T23.5.2.5\" class=\"ltx_td ltx_align_center ltx_border_r\">4</td>\n<td id=\"A8.T23.5.2.6\" class=\"ltx_td ltx_align_center ltx_border_r\">5</td>\n<td id=\"A8.T23.5.2.7\" class=\"ltx_td ltx_align_center ltx_border_r\">6</td>\n<td id=\"A8.T23.5.2.8\" class=\"ltx_td ltx_align_center ltx_border_r\">7</td>\n<td id=\"A8.T23.5.2.9\" class=\"ltx_td ltx_align_center ltx_border_r\">8</td>\n<td id=\"A8.T23.5.2.10\" class=\"ltx_td ltx_align_center\">9</td>\n</tr>\n<tr id=\"A8.T23.5.3\" class=\"ltx_tr\">\n<td id=\"A8.T23.5.3.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"A8.T23.5.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">598</td>\n<td id=\"A8.T23.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"A8.T23.5.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">325</td>\n<td id=\"A8.T23.5.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"A8.T23.5.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">259</td>\n<td id=\"A8.T23.5.3.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">404</td>\n<td id=\"A8.T23.5.3.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">511</td>\n<td id=\"A8.T23.5.3.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">463</td>\n<td id=\"A8.T23.5.3.10\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"A8.T23.5.3.11\" class=\"ltx_td ltx_align_center ltx_border_t\">0</td>\n</tr>\n<tr id=\"A8.T23.5.4\" class=\"ltx_tr\">\n<td id=\"A8.T23.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_r\">1</td>\n<td id=\"A8.T23.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">777</td>\n<td id=\"A8.T23.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.4.5\" class=\"ltx_td ltx_align_center ltx_border_r\">494</td>\n<td id=\"A8.T23.5.4.6\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.4.7\" class=\"ltx_td ltx_align_center ltx_border_r\">623</td>\n<td id=\"A8.T23.5.4.8\" class=\"ltx_td ltx_align_center ltx_border_r\">666</td>\n<td id=\"A8.T23.5.4.9\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.4.10\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.4.11\" class=\"ltx_td ltx_align_center\">0</td>\n</tr>\n<tr id=\"A8.T23.5.5\" class=\"ltx_tr\">\n<td id=\"A8.T23.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_r\">2</td>\n<td id=\"A8.T23.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_r\">919</td>\n<td id=\"A8.T23.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_r\">433</td>\n<td id=\"A8.T23.5.5.6\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.5.7\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.5.8\" class=\"ltx_td ltx_align_center ltx_border_r\">770</td>\n<td id=\"A8.T23.5.5.9\" class=\"ltx_td ltx_align_center ltx_border_r\">438</td>\n<td id=\"A8.T23.5.5.10\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.5.11\" class=\"ltx_td ltx_align_center\">0</td>\n</tr>\n<tr id=\"A8.T23.5.6\" class=\"ltx_tr\">\n<td id=\"A8.T23.5.6.1\" class=\"ltx_td ltx_align_center ltx_border_r\">3</td>\n<td id=\"A8.T23.5.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">745</td>\n<td id=\"A8.T23.5.6.4\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.6.5\" class=\"ltx_td ltx_align_center ltx_border_r\">1344</td>\n<td id=\"A8.T23.5.6.6\" class=\"ltx_td ltx_align_center ltx_border_r\">392</td>\n<td id=\"A8.T23.5.6.7\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.6.8\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.6.9\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.6.10\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.6.11\" class=\"ltx_td ltx_align_center\">79</td>\n</tr>\n<tr id=\"A8.T23.5.7\" class=\"ltx_tr\">\n<td id=\"A8.T23.5.7.1\" class=\"ltx_td ltx_align_center ltx_border_r\">4</td>\n<td id=\"A8.T23.5.7.2\" class=\"ltx_td ltx_align_center ltx_border_r\">355</td>\n<td id=\"A8.T23.5.7.3\" class=\"ltx_td ltx_align_center ltx_border_r\">95</td>\n<td id=\"A8.T23.5.7.4\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.7.5\" class=\"ltx_td ltx_align_center ltx_border_r\">232</td>\n<td id=\"A8.T23.5.7.6\" class=\"ltx_td ltx_align_center ltx_border_r\">814</td>\n<td id=\"A8.T23.5.7.7\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.7.8\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.7.9\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.7.10\" class=\"ltx_td ltx_align_center ltx_border_r\">683</td>\n<td id=\"A8.T23.5.7.11\" class=\"ltx_td ltx_align_center\">381</td>\n</tr>\n<tr id=\"A8.T23.5.8\" class=\"ltx_tr\">\n<td id=\"A8.T23.5.8.1\" class=\"ltx_td ltx_align_center ltx_border_r\">5</td>\n<td id=\"A8.T23.5.8.2\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.8.3\" class=\"ltx_td ltx_align_center ltx_border_r\">203</td>\n<td id=\"A8.T23.5.8.4\" class=\"ltx_td ltx_align_center ltx_border_r\">543</td>\n<td id=\"A8.T23.5.8.5\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.8.6\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.8.7\" class=\"ltx_td ltx_align_center ltx_border_r\">599</td>\n<td id=\"A8.T23.5.8.8\" class=\"ltx_td ltx_align_center ltx_border_r\">308</td>\n<td id=\"A8.T23.5.8.9\" class=\"ltx_td ltx_align_center ltx_border_r\">400</td>\n<td id=\"A8.T23.5.8.10\" class=\"ltx_td ltx_align_center ltx_border_r\">507</td>\n<td id=\"A8.T23.5.8.11\" class=\"ltx_td ltx_align_center\">0</td>\n</tr>\n<tr id=\"A8.T23.5.9\" class=\"ltx_tr\">\n<td id=\"A8.T23.5.9.1\" class=\"ltx_td ltx_align_center ltx_border_r\">6</td>\n<td id=\"A8.T23.5.9.2\" class=\"ltx_td ltx_align_center ltx_border_r\">295</td>\n<td id=\"A8.T23.5.9.3\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.9.4\" class=\"ltx_td ltx_align_center ltx_border_r\">827</td>\n<td id=\"A8.T23.5.9.5\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.9.6\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.9.7\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.9.8\" class=\"ltx_td ltx_align_center ltx_border_r\">1438</td>\n<td id=\"A8.T23.5.9.9\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.9.10\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.9.11\" class=\"ltx_td ltx_align_center\">0</td>\n</tr>\n<tr id=\"A8.T23.5.10\" class=\"ltx_tr\">\n<td id=\"A8.T23.5.10.1\" class=\"ltx_td ltx_align_center ltx_border_r\">7</td>\n<td id=\"A8.T23.5.10.2\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.10.3\" class=\"ltx_td ltx_align_center ltx_border_r\">1116</td>\n<td id=\"A8.T23.5.10.4\" class=\"ltx_td ltx_align_center ltx_border_r\">84</td>\n<td id=\"A8.T23.5.10.5\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.10.6\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.10.7\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.10.8\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.10.9\" class=\"ltx_td ltx_align_center ltx_border_r\">1360</td>\n<td id=\"A8.T23.5.10.10\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.10.11\" class=\"ltx_td ltx_align_center\">0</td>\n</tr>\n<tr id=\"A8.T23.5.11\" class=\"ltx_tr\">\n<td id=\"A8.T23.5.11.1\" class=\"ltx_td ltx_align_center ltx_border_r\">8</td>\n<td id=\"A8.T23.5.11.2\" class=\"ltx_td ltx_align_center ltx_border_r\">408</td>\n<td id=\"A8.T23.5.11.3\" class=\"ltx_td ltx_align_center ltx_border_r\">454</td>\n<td id=\"A8.T23.5.11.4\" class=\"ltx_td ltx_align_center ltx_border_r\">30</td>\n<td id=\"A8.T23.5.11.5\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.11.6\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.11.7\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.11.8\" class=\"ltx_td ltx_align_center ltx_border_r\">279</td>\n<td id=\"A8.T23.5.11.9\" class=\"ltx_td ltx_align_center ltx_border_r\">518</td>\n<td id=\"A8.T23.5.11.10\" class=\"ltx_td ltx_align_center ltx_border_r\">538</td>\n<td id=\"A8.T23.5.11.11\" class=\"ltx_td ltx_align_center\">333</td>\n</tr>\n<tr id=\"A8.T23.5.12\" class=\"ltx_tr\">\n<td id=\"A8.T23.5.12.1\" class=\"ltx_td ltx_align_center ltx_border_r\">9</td>\n<td id=\"A8.T23.5.12.2\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.12.3\" class=\"ltx_td ltx_align_center ltx_border_r\">431</td>\n<td id=\"A8.T23.5.12.4\" class=\"ltx_td ltx_align_center ltx_border_r\">271</td>\n<td id=\"A8.T23.5.12.5\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.12.6\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.12.7\" class=\"ltx_td ltx_align_center ltx_border_r\">206</td>\n<td id=\"A8.T23.5.12.8\" class=\"ltx_td ltx_align_center ltx_border_r\">788</td>\n<td id=\"A8.T23.5.12.9\" class=\"ltx_td ltx_align_center ltx_border_r\">36</td>\n<td id=\"A8.T23.5.12.10\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.12.11\" class=\"ltx_td ltx_align_center\">828</td>\n</tr>\n<tr id=\"A8.T23.5.13\" class=\"ltx_tr\">\n<td id=\"A8.T23.5.13.1\" class=\"ltx_td ltx_align_center ltx_border_r\">10</td>\n<td id=\"A8.T23.5.13.2\" class=\"ltx_td ltx_align_center ltx_border_r\">715</td>\n<td id=\"A8.T23.5.13.3\" class=\"ltx_td ltx_align_center ltx_border_r\">113</td>\n<td id=\"A8.T23.5.13.4\" class=\"ltx_td ltx_align_center ltx_border_r\">431</td>\n<td id=\"A8.T23.5.13.5\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.13.6\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.13.7\" class=\"ltx_td ltx_align_center ltx_border_r\">508</td>\n<td id=\"A8.T23.5.13.8\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.13.9\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.13.10\" class=\"ltx_td ltx_align_center ltx_border_r\">476</td>\n<td id=\"A8.T23.5.13.11\" class=\"ltx_td ltx_align_center\">317</td>\n</tr>\n<tr id=\"A8.T23.5.14\" class=\"ltx_tr\">\n<td id=\"A8.T23.5.14.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">11</td>\n<td id=\"A8.T23.5.14.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">560</td>\n<td id=\"A8.T23.5.14.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">424</td>\n<td id=\"A8.T23.5.14.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">369</td>\n<td id=\"A8.T23.5.14.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"A8.T23.5.14.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">343</td>\n<td id=\"A8.T23.5.14.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0</td>\n<td id=\"A8.T23.5.14.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">406</td>\n<td id=\"A8.T23.5.14.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">89</td>\n<td id=\"A8.T23.5.14.10\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">270</td>\n<td id=\"A8.T23.5.14.11\" class=\"ltx_td ltx_align_center ltx_border_t\">99</td>\n</tr>\n<tr id=\"A8.T23.5.15\" class=\"ltx_tr\">\n<td id=\"A8.T23.5.15.1\" class=\"ltx_td ltx_align_center ltx_border_r\">12</td>\n<td id=\"A8.T23.5.15.2\" class=\"ltx_td ltx_align_center ltx_border_r\">99</td>\n<td id=\"A8.T23.5.15.3\" class=\"ltx_td ltx_align_center ltx_border_r\">2461</td>\n<td id=\"A8.T23.5.15.4\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.15.5\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.15.6\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.15.7\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.15.8\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.15.9\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.15.10\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.15.11\" class=\"ltx_td ltx_align_center\">0</td>\n</tr>\n<tr id=\"A8.T23.5.16\" class=\"ltx_tr\">\n<td id=\"A8.T23.5.16.1\" class=\"ltx_td ltx_align_center ltx_border_r\">13</td>\n<td id=\"A8.T23.5.16.2\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.16.3\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.16.4\" class=\"ltx_td ltx_align_center ltx_border_r\">595</td>\n<td id=\"A8.T23.5.16.5\" class=\"ltx_td ltx_align_center ltx_border_r\">257</td>\n<td id=\"A8.T23.5.16.6\" class=\"ltx_td ltx_align_center ltx_border_r\">172</td>\n<td id=\"A8.T23.5.16.7\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.16.8\" class=\"ltx_td ltx_align_center ltx_border_r\">568</td>\n<td id=\"A8.T23.5.16.9\" class=\"ltx_td ltx_align_center ltx_border_r\">206</td>\n<td id=\"A8.T23.5.16.10\" class=\"ltx_td ltx_align_center ltx_border_r\">527</td>\n<td id=\"A8.T23.5.16.11\" class=\"ltx_td ltx_align_center\">235</td>\n</tr>\n<tr id=\"A8.T23.5.17\" class=\"ltx_tr\">\n<td id=\"A8.T23.5.17.1\" class=\"ltx_td ltx_align_center ltx_border_r\">14</td>\n<td id=\"A8.T23.5.17.2\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.17.3\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.17.4\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.17.5\" class=\"ltx_td ltx_align_center ltx_border_r\">2047</td>\n<td id=\"A8.T23.5.17.6\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.17.7\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.17.8\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.17.9\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.17.10\" class=\"ltx_td ltx_align_center ltx_border_r\">513</td>\n<td id=\"A8.T23.5.17.11\" class=\"ltx_td ltx_align_center\">0</td>\n</tr>\n<tr id=\"A8.T23.5.18\" class=\"ltx_tr\">\n<td id=\"A8.T23.5.18.1\" class=\"ltx_td ltx_align_center ltx_border_r\">15</td>\n<td id=\"A8.T23.5.18.2\" class=\"ltx_td ltx_align_center ltx_border_r\">159</td>\n<td id=\"A8.T23.5.18.3\" class=\"ltx_td ltx_align_center ltx_border_r\">149</td>\n<td id=\"A8.T23.5.18.4\" class=\"ltx_td ltx_align_center ltx_border_r\">199</td>\n<td id=\"A8.T23.5.18.5\" class=\"ltx_td ltx_align_center ltx_border_r\">546</td>\n<td id=\"A8.T23.5.18.6\" class=\"ltx_td ltx_align_center ltx_border_r\">642</td>\n<td id=\"A8.T23.5.18.7\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.18.8\" class=\"ltx_td ltx_align_center ltx_border_r\">447</td>\n<td id=\"A8.T23.5.18.9\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.18.10\" class=\"ltx_td ltx_align_center ltx_border_r\">404</td>\n<td id=\"A8.T23.5.18.11\" class=\"ltx_td ltx_align_center\">14</td>\n</tr>\n<tr id=\"A8.T23.5.19\" class=\"ltx_tr\">\n<td id=\"A8.T23.5.19.1\" class=\"ltx_td ltx_align_center ltx_border_r\">16</td>\n<td id=\"A8.T23.5.19.2\" class=\"ltx_td ltx_align_center ltx_border_r\">494</td>\n<td id=\"A8.T23.5.19.3\" class=\"ltx_td ltx_align_center ltx_border_r\">254</td>\n<td id=\"A8.T23.5.19.4\" class=\"ltx_td ltx_align_center ltx_border_r\">486</td>\n<td id=\"A8.T23.5.19.5\" class=\"ltx_td ltx_align_center ltx_border_r\">388</td>\n<td id=\"A8.T23.5.19.6\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.19.7\" class=\"ltx_td ltx_align_center ltx_border_r\">523</td>\n<td id=\"A8.T23.5.19.8\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.19.9\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.19.10\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.19.11\" class=\"ltx_td ltx_align_center\">415</td>\n</tr>\n<tr id=\"A8.T23.5.20\" class=\"ltx_tr\">\n<td id=\"A8.T23.5.20.1\" class=\"ltx_td ltx_align_center ltx_border_r\">17</td>\n<td id=\"A8.T23.5.20.2\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.20.3\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.20.4\" class=\"ltx_td ltx_align_center ltx_border_r\">315</td>\n<td id=\"A8.T23.5.20.5\" class=\"ltx_td ltx_align_center ltx_border_r\">947</td>\n<td id=\"A8.T23.5.20.6\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.20.7\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.20.8\" class=\"ltx_td ltx_align_center ltx_border_r\">963</td>\n<td id=\"A8.T23.5.20.9\" class=\"ltx_td ltx_align_center ltx_border_r\">209</td>\n<td id=\"A8.T23.5.20.10\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.20.11\" class=\"ltx_td ltx_align_center\">126</td>\n</tr>\n<tr id=\"A8.T23.5.21\" class=\"ltx_tr\">\n<td id=\"A8.T23.5.21.1\" class=\"ltx_td ltx_align_center ltx_border_r\">18</td>\n<td id=\"A8.T23.5.21.2\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.21.3\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.21.4\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.21.5\" class=\"ltx_td ltx_align_center ltx_border_r\">271</td>\n<td id=\"A8.T23.5.21.6\" class=\"ltx_td ltx_align_center ltx_border_r\">549</td>\n<td id=\"A8.T23.5.21.7\" class=\"ltx_td ltx_align_center ltx_border_r\">509</td>\n<td id=\"A8.T23.5.21.8\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.21.9\" class=\"ltx_td ltx_align_center ltx_border_r\">640</td>\n<td id=\"A8.T23.5.21.10\" class=\"ltx_td ltx_align_center ltx_border_r\">0</td>\n<td id=\"A8.T23.5.21.11\" class=\"ltx_td ltx_align_center\">591</td>\n</tr>\n<tr id=\"A8.T23.5.22\" class=\"ltx_tr\">\n<td id=\"A8.T23.5.22.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">19</td>\n<td id=\"A8.T23.5.22.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">0</td>\n<td id=\"A8.T23.5.22.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">178</td>\n<td id=\"A8.T23.5.22.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">0</td>\n<td id=\"A8.T23.5.22.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">677</td>\n<td id=\"A8.T23.5.22.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">0</td>\n<td id=\"A8.T23.5.22.7\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">0</td>\n<td id=\"A8.T23.5.22.8\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">588</td>\n<td id=\"A8.T23.5.22.9\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">285</td>\n<td id=\"A8.T23.5.22.10\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">832</td>\n<td id=\"A8.T23.5.22.11\" class=\"ltx_td ltx_align_center ltx_border_bb\">0</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We generate ",
                "inter-client",
                " ",
                "non-IID",
                " datasets by assigning arbitrary datasets to clients. The ",
                "Random-Non-IID",
                " strategy first randomly decides for each label if it is contained in client‚Äôs local dataset by coin flip. Afterwards, we randomly generate a number between zero and one for each label that should be contained in the dataset. Then, we sum those random values and assign the relative percentage of the sum to the each label. Finally, those values can be converted to real sample frequencies by multiplying the percentage with the desired overall sample count of the client. This results in ",
                "inter-client",
                " ",
                "non-IID",
                " datasets even with disjoint data. The sample distribution of the setup within this paper is listed in ",
                "Tab.¬†",
                "23",
                ".",
                "Certainly, it is also possible to leverage different ",
                "intra-client",
                " ",
                "non-IID",
                " for each client‚Äôs dataset to generate ",
                "inter-client",
                " ",
                "non-IID",
                " scenarios, if one needs more control over the distributions."
            ]
        ]
    }
}