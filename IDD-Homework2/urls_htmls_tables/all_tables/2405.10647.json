{
    "PAPER'S NUMBER OF TABLES": 3,
    "S4.T1": {
        "caption": "Table 1: Classification accuracy on the global test set under three heterogeneous settings. The final results are determined by selecting the best scores within 100 communication rounds. The results for MNIST are presented above, while those for CIFAR10 are displayed below.",
        "table": "<table id=\"S4.T1.3.3\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.3.3.3\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.3.3.4\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\"></th>\n<th id=\"S4.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\"><math id=\"S4.T1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha=0.01\" display=\"inline\"><semantics id=\"S4.T1.1.1.1.1.m1.1a\"><mrow id=\"S4.T1.1.1.1.1.m1.1.1\" xref=\"S4.T1.1.1.1.1.m1.1.1.cmml\"><mi id=\"S4.T1.1.1.1.1.m1.1.1.2\" xref=\"S4.T1.1.1.1.1.m1.1.1.2.cmml\">Î±</mi><mo id=\"S4.T1.1.1.1.1.m1.1.1.1\" xref=\"S4.T1.1.1.1.1.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T1.1.1.1.1.m1.1.1.3\" xref=\"S4.T1.1.1.1.1.m1.1.1.3.cmml\">0.01</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.1.1.1.1.m1.1b\"><apply id=\"S4.T1.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T1.1.1.1.1.m1.1.1\"><eq id=\"S4.T1.1.1.1.1.m1.1.1.1.cmml\" xref=\"S4.T1.1.1.1.1.m1.1.1.1\"></eq><ci id=\"S4.T1.1.1.1.1.m1.1.1.2.cmml\" xref=\"S4.T1.1.1.1.1.m1.1.1.2\">ğ›¼</ci><cn type=\"float\" id=\"S4.T1.1.1.1.1.m1.1.1.3.cmml\" xref=\"S4.T1.1.1.1.1.m1.1.1.3\">0.01</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.1.1.1.1.m1.1c\">\\alpha=0.01</annotation></semantics></math></th>\n<th id=\"S4.T1.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\"><math id=\"S4.T1.2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha=0.1\" display=\"inline\"><semantics id=\"S4.T1.2.2.2.2.m1.1a\"><mrow id=\"S4.T1.2.2.2.2.m1.1.1\" xref=\"S4.T1.2.2.2.2.m1.1.1.cmml\"><mi id=\"S4.T1.2.2.2.2.m1.1.1.2\" xref=\"S4.T1.2.2.2.2.m1.1.1.2.cmml\">Î±</mi><mo id=\"S4.T1.2.2.2.2.m1.1.1.1\" xref=\"S4.T1.2.2.2.2.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T1.2.2.2.2.m1.1.1.3\" xref=\"S4.T1.2.2.2.2.m1.1.1.3.cmml\">0.1</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.2.2.2.2.m1.1b\"><apply id=\"S4.T1.2.2.2.2.m1.1.1.cmml\" xref=\"S4.T1.2.2.2.2.m1.1.1\"><eq id=\"S4.T1.2.2.2.2.m1.1.1.1.cmml\" xref=\"S4.T1.2.2.2.2.m1.1.1.1\"></eq><ci id=\"S4.T1.2.2.2.2.m1.1.1.2.cmml\" xref=\"S4.T1.2.2.2.2.m1.1.1.2\">ğ›¼</ci><cn type=\"float\" id=\"S4.T1.2.2.2.2.m1.1.1.3.cmml\" xref=\"S4.T1.2.2.2.2.m1.1.1.3\">0.1</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.2.2.2.2.m1.1c\">\\alpha=0.1</annotation></semantics></math></th>\n<th id=\"S4.T1.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\"><math id=\"S4.T1.3.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha=1.0\" display=\"inline\"><semantics id=\"S4.T1.3.3.3.3.m1.1a\"><mrow id=\"S4.T1.3.3.3.3.m1.1.1\" xref=\"S4.T1.3.3.3.3.m1.1.1.cmml\"><mi id=\"S4.T1.3.3.3.3.m1.1.1.2\" xref=\"S4.T1.3.3.3.3.m1.1.1.2.cmml\">Î±</mi><mo id=\"S4.T1.3.3.3.3.m1.1.1.1\" xref=\"S4.T1.3.3.3.3.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T1.3.3.3.3.m1.1.1.3\" xref=\"S4.T1.3.3.3.3.m1.1.1.3.cmml\">1.0</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.3.3.3.3.m1.1b\"><apply id=\"S4.T1.3.3.3.3.m1.1.1.cmml\" xref=\"S4.T1.3.3.3.3.m1.1.1\"><eq id=\"S4.T1.3.3.3.3.m1.1.1.1.cmml\" xref=\"S4.T1.3.3.3.3.m1.1.1.1\"></eq><ci id=\"S4.T1.3.3.3.3.m1.1.1.2.cmml\" xref=\"S4.T1.3.3.3.3.m1.1.1.2\">ğ›¼</ci><cn type=\"float\" id=\"S4.T1.3.3.3.3.m1.1.1.3.cmml\" xref=\"S4.T1.3.3.3.3.m1.1.1.3\">1.0</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.3.3.3.3.m1.1c\">\\alpha=1.0</annotation></semantics></math></th>\n<th id=\"S4.T1.3.3.3.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Mean</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.3.3.4.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.3.4.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">FedAvg</th>\n<td id=\"S4.T1.3.3.4.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">93.64</td>\n<td id=\"S4.T1.3.3.4.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">97.10</td>\n<td id=\"S4.T1.3.3.4.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">98.16</td>\n<td id=\"S4.T1.3.3.4.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">96.30</td>\n</tr>\n<tr id=\"S4.T1.3.3.5.2\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.3.5.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">CWT</th>\n<td id=\"S4.T1.3.3.5.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">85.54</td>\n<td id=\"S4.T1.3.3.5.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\">94.58</td>\n<td id=\"S4.T1.3.3.5.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\">98.15</td>\n<td id=\"S4.T1.3.3.5.2.5\" class=\"ltx_td ltx_align_center\">92.76</td>\n</tr>\n<tr id=\"S4.T1.3.3.6.3\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.3.6.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">CWC (ours)</th>\n<td id=\"S4.T1.3.3.6.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T1.3.3.6.3.2.1\" class=\"ltx_text ltx_font_bold\">97.97</span></td>\n<td id=\"S4.T1.3.3.6.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T1.3.3.6.3.3.1\" class=\"ltx_text ltx_font_bold\">97.66</span></td>\n<td id=\"S4.T1.3.3.6.3.4\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T1.3.3.6.3.4.1\" class=\"ltx_text ltx_font_bold\">98.26</span></td>\n<td id=\"S4.T1.3.3.6.3.5\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.3.3.6.3.5.1\" class=\"ltx_text ltx_font_bold\">97.96</span></td>\n</tr>\n<tr id=\"S4.T1.3.3.7.4\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.3.7.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">FedAvg</th>\n<td id=\"S4.T1.3.3.7.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">33.36</td>\n<td id=\"S4.T1.3.3.7.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T1.3.3.7.4.3.1\" class=\"ltx_text ltx_font_bold\">46.07</span></td>\n<td id=\"S4.T1.3.3.7.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">49.40</td>\n<td id=\"S4.T1.3.3.7.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\">42.94</td>\n</tr>\n<tr id=\"S4.T1.3.3.8.5\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.3.8.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">CWT</th>\n<td id=\"S4.T1.3.3.8.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\">24.92</td>\n<td id=\"S4.T1.3.3.8.5.3\" class=\"ltx_td ltx_align_center ltx_border_r\">28.38</td>\n<td id=\"S4.T1.3.3.8.5.4\" class=\"ltx_td ltx_align_center ltx_border_r\">47.38</td>\n<td id=\"S4.T1.3.3.8.5.5\" class=\"ltx_td ltx_align_center\">33.56</td>\n</tr>\n<tr id=\"S4.T1.3.3.9.6\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.3.9.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\">CWC (ours)</th>\n<td id=\"S4.T1.3.3.9.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S4.T1.3.3.9.6.2.1\" class=\"ltx_text ltx_font_bold\">42.04</span></td>\n<td id=\"S4.T1.3.3.9.6.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">44.22</td>\n<td id=\"S4.T1.3.3.9.6.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S4.T1.3.3.9.6.4.1\" class=\"ltx_text ltx_font_bold\">50.50</span></td>\n<td id=\"S4.T1.3.3.9.6.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T1.3.3.9.6.5.1\" class=\"ltx_text ltx_font_bold\">45.59</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Main Results. Fig.Â 3 and TableÂ 1 illustrates a comparative analysis of overall performance among FedAvg, CWT, and Our CWC. To begin, we examine CWC against CWT, the serial approach without consolidation. Notably, CWC consistently outperforms CWT in all the three non-IID scenarios, alleviating performance fluctuations faced by CWT and achieving higher convergence scores. As data heterogeneity increases (from Î±=1.0ğ›¼1.0\\alpha=1.0 to Î±=0.01ğ›¼0.01\\alpha=0.01), CWT encounters challenges, particularly in addressing the exacerbated issue of catastrophic forgetting due to more heterogeneous distribution. The oscillation amplitude increases, resulting in lower convergence values. Moreover, in CIFAR10, CWT struggles to learn, evidenced by declining accuracy with increasing training epochs. In contrast, CWC, incorporating a cyclical consolidation mechanism, overcomes the inefficiency in the iterative process of learning and forgetting. This is evident in its more steadily growing trend and eventual convergence to higher accuracy. The figure also demonstrates the robustness of CWC to increasing data heterogeneity. As heterogeneity increases, the performance loss is moderate, in contrast to CWT and FedAvg. Remarkably, with cyclical weight consolidation, the serial federated learning approach becomes comparable to FedAvg and even outperforms it in highly heterogeneous scenarios (Î±=0.01ğ›¼0.01\\alpha=0.01)."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Balanced classification accuracy on the global test set under three heterogeneous settings. The final results are determined by selecting the best scores within 150 communication rounds.",
        "table": "<table id=\"S4.T2.3.3\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T2.3.3.3\" class=\"ltx_tr\">\n<th id=\"S4.T2.3.3.3.4\" class=\"ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt\"></th>\n<th id=\"S4.T2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\"><math id=\"S4.T2.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha=0.1\" display=\"inline\"><semantics id=\"S4.T2.1.1.1.1.m1.1a\"><mrow id=\"S4.T2.1.1.1.1.m1.1.1\" xref=\"S4.T2.1.1.1.1.m1.1.1.cmml\"><mi id=\"S4.T2.1.1.1.1.m1.1.1.2\" xref=\"S4.T2.1.1.1.1.m1.1.1.2.cmml\">Î±</mi><mo id=\"S4.T2.1.1.1.1.m1.1.1.1\" xref=\"S4.T2.1.1.1.1.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T2.1.1.1.1.m1.1.1.3\" xref=\"S4.T2.1.1.1.1.m1.1.1.3.cmml\">0.1</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.1.1.1.1.m1.1b\"><apply id=\"S4.T2.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T2.1.1.1.1.m1.1.1\"><eq id=\"S4.T2.1.1.1.1.m1.1.1.1.cmml\" xref=\"S4.T2.1.1.1.1.m1.1.1.1\"></eq><ci id=\"S4.T2.1.1.1.1.m1.1.1.2.cmml\" xref=\"S4.T2.1.1.1.1.m1.1.1.2\">ğ›¼</ci><cn type=\"float\" id=\"S4.T2.1.1.1.1.m1.1.1.3.cmml\" xref=\"S4.T2.1.1.1.1.m1.1.1.3\">0.1</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.1.1.1.1.m1.1c\">\\alpha=0.1</annotation></semantics></math></th>\n<th id=\"S4.T2.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\"><math id=\"S4.T2.2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha=1.0\" display=\"inline\"><semantics id=\"S4.T2.2.2.2.2.m1.1a\"><mrow id=\"S4.T2.2.2.2.2.m1.1.1\" xref=\"S4.T2.2.2.2.2.m1.1.1.cmml\"><mi id=\"S4.T2.2.2.2.2.m1.1.1.2\" xref=\"S4.T2.2.2.2.2.m1.1.1.2.cmml\">Î±</mi><mo id=\"S4.T2.2.2.2.2.m1.1.1.1\" xref=\"S4.T2.2.2.2.2.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T2.2.2.2.2.m1.1.1.3\" xref=\"S4.T2.2.2.2.2.m1.1.1.3.cmml\">1.0</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.2.2.2.2.m1.1b\"><apply id=\"S4.T2.2.2.2.2.m1.1.1.cmml\" xref=\"S4.T2.2.2.2.2.m1.1.1\"><eq id=\"S4.T2.2.2.2.2.m1.1.1.1.cmml\" xref=\"S4.T2.2.2.2.2.m1.1.1.1\"></eq><ci id=\"S4.T2.2.2.2.2.m1.1.1.2.cmml\" xref=\"S4.T2.2.2.2.2.m1.1.1.2\">ğ›¼</ci><cn type=\"float\" id=\"S4.T2.2.2.2.2.m1.1.1.3.cmml\" xref=\"S4.T2.2.2.2.2.m1.1.1.3\">1.0</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.2.2.2.2.m1.1c\">\\alpha=1.0</annotation></semantics></math></th>\n<th id=\"S4.T2.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\"><math id=\"S4.T2.3.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha=10.0\" display=\"inline\"><semantics id=\"S4.T2.3.3.3.3.m1.1a\"><mrow id=\"S4.T2.3.3.3.3.m1.1.1\" xref=\"S4.T2.3.3.3.3.m1.1.1.cmml\"><mi id=\"S4.T2.3.3.3.3.m1.1.1.2\" xref=\"S4.T2.3.3.3.3.m1.1.1.2.cmml\">Î±</mi><mo id=\"S4.T2.3.3.3.3.m1.1.1.1\" xref=\"S4.T2.3.3.3.3.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T2.3.3.3.3.m1.1.1.3\" xref=\"S4.T2.3.3.3.3.m1.1.1.3.cmml\">10.0</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.3.3.3.3.m1.1b\"><apply id=\"S4.T2.3.3.3.3.m1.1.1.cmml\" xref=\"S4.T2.3.3.3.3.m1.1.1\"><eq id=\"S4.T2.3.3.3.3.m1.1.1.1.cmml\" xref=\"S4.T2.3.3.3.3.m1.1.1.1\"></eq><ci id=\"S4.T2.3.3.3.3.m1.1.1.2.cmml\" xref=\"S4.T2.3.3.3.3.m1.1.1.2\">ğ›¼</ci><cn type=\"float\" id=\"S4.T2.3.3.3.3.m1.1.1.3.cmml\" xref=\"S4.T2.3.3.3.3.m1.1.1.3\">10.0</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.3.3.3.3.m1.1c\">\\alpha=10.0</annotation></semantics></math></th>\n<th id=\"S4.T2.3.3.3.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Mean</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.3.3.4.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.3.4.1.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">FedAvg</td>\n<td id=\"S4.T2.3.3.4.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">39.28</td>\n<td id=\"S4.T2.3.3.4.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">43.05</td>\n<td id=\"S4.T2.3.3.4.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">46.37</td>\n<td id=\"S4.T2.3.3.4.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">42.90</td>\n</tr>\n<tr id=\"S4.T2.3.3.5.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.3.5.2.1\" class=\"ltx_td ltx_align_left ltx_border_r\">CWT</td>\n<td id=\"S4.T2.3.3.5.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">34.70</td>\n<td id=\"S4.T2.3.3.5.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\">48.47</td>\n<td id=\"S4.T2.3.3.5.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\">49.58</td>\n<td id=\"S4.T2.3.3.5.2.5\" class=\"ltx_td ltx_align_center\">44.25</td>\n</tr>\n<tr id=\"S4.T2.3.3.6.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.3.6.3.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\">CWC (ours)</td>\n<td id=\"S4.T2.3.3.6.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S4.T2.3.3.6.3.2.1\" class=\"ltx_text ltx_font_bold\">45.67</span></td>\n<td id=\"S4.T2.3.3.6.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S4.T2.3.3.6.3.3.1\" class=\"ltx_text ltx_font_bold\">56.39</span></td>\n<td id=\"S4.T2.3.3.6.3.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S4.T2.3.3.6.3.4.1\" class=\"ltx_text ltx_font_bold\">54.75</span></td>\n<td id=\"S4.T2.3.3.6.3.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.3.3.6.3.5.1\" class=\"ltx_text ltx_font_bold\">52.27</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "TableÂ 2 showcases the superiority of CWC against CWT and FedAvg in this scenario. Interestingly, FedAvg achieves the lowest performance in this class-imbalanced classification task, with a score of 42.9%, slightly lower than CWTâ€™s 44.25%. Evidently, CWC surpasses both with a significant margin. Fig.Â 5 plots the learning dynamics under the setting of Î±=0.1ğ›¼0.1\\alpha=0.1. It is observed that significant fluctuation is present in all three algorithms, as the noise introduced by the highly imbalanced class distribution is unavoidable."
        ]
    },
    "S4.T3": {
        "caption": "Table 3: Number of communication rounds (along with training epochs) needed to achieve 75% accuracy on MNIST Dirichlet (Î±=0.01ğ›¼0.01\\alpha=0.01) for varying local training epochs",
        "table": "<table id=\"S4.T3.3.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T3.3.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.3.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\"><span id=\"S4.T3.3.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Local Epochs</span></th>\n<th id=\"S4.T3.3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T3.3.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">1</span></th>\n<th id=\"S4.T3.3.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T3.3.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">2</span></th>\n<th id=\"S4.T3.3.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T3.3.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">4</span></th>\n<th id=\"S4.T3.3.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T3.3.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">8</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.3.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.3.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">CWT</th>\n<td id=\"S4.T3.3.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">37 (148)</td>\n<td id=\"S4.T3.3.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">41 (321)</td>\n<td id=\"S4.T3.3.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">50 (787)</td>\n<td id=\"S4.T3.3.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">39 (1240)</td>\n</tr>\n<tr id=\"S4.T3.3.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.3.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\">CWC (ours)</th>\n<td id=\"S4.T3.3.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">6 (21)</td>\n<td id=\"S4.T3.3.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">4 (25)</td>\n<td id=\"S4.T3.3.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">3 (33)</td>\n<td id=\"S4.T3.3.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">3 (66)</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "In parallel FL, the number of local training epochs is increased to reduce communication costsÂ McMahan etÂ al. (2023). The model can converge to the same performance with fewer communication rounds at the expense of more intense local computing. However, as pointed out inÂ Sheller etÂ al. (2019, 2020), the benefit of increasing local training epochs in CWT is limited. CWTâ€™s performance is sensitive to the number of local training epochs because a longer exposure to heterogeneous data demands a stronger ability to preserve previously acquired knowledge. An increased number of local training epochs pose a significant challenge to its inherently mediocre memory. TableÂ 3 displays the number of communication rounds (along with training epochs) required to reach 75% accuracy on MNIST Dirichlet (Î±=0.01ğ›¼0.01\\alpha=0.01) for different local training epochs. Observing the results, an increase in the amount of local computation has no effect on the convergence speed in terms of CWT. In fact, it takes more communication rounds to reach the same preset accuracy (communication rounds increase to 41 and 50 under 2 and 8 epochs, respectively). In contrast, CWC experiences a boost in convergence speed with increased local epochs, similar to FedAvg. This is further demonstrated in Fig.Â 7, which shows the startup learning dynamics under the setup of 2 and 4 local epochs: After experiencing a total of four communication rounds, CWCâ€™s test accuracy converges to a higher level with a doubling in local training epochs."
        ]
    }
}