{
    "Sx5.T1": {
        "caption": "Table 1: The 5-way 1-shot and 5-shot classification accuracies (%) on the test split of the miniImageNet dataset, with 95%percent9595\\% confidence interval. † indicates our re-implementation. “w/o” indicates without.",
        "table": null,
        "footnotes": [],
        "references": [
            "To verify the effectiveness of our proposed continual meta-learning model, we compare it with state-of-the-art meta-learning methods on the miniImageNet and tieredImageNet datasets. Here we report the best performance for every model in Table 1 and Table 2, along with the specifications of the backbone embedding models for feature extraction. Conv4 refers to a 4-layer convolutional network, ResNet-12 (?) denotes 4 layer blocks of depth 3 with 3×3333\\times 3 kernels and short connections, and WRN-28 is a 28-layer wide residual network. Generally, a deeper embedding network will lead to a better classification performance yet with a risk of overfitting. From Table 1, we can observe that our CML-BGNN equipped with three graph layers surpasses all compared meta-learning methods with a large margin, especially in the challenging scenario of 1-shot learning. More concretely, the proposed model with the basic conv4 embedding structure gains 43.5%percent43.543.5\\%, 45.1%percent45.145.1\\%, 42.8%percent42.842.8\\%, 51.1%percent51.151.1\\% relative improvements over the previous best optimization-based LEO (?), generation-based wDAE (?), metric-based CTM (?) and graph-based methods EGNN (?) in a 5-way 1-shot miniImageNet experiment, respectively. This is mainly owing to the learned history transition, which reinforces the memory of rare samples and correlations between classes. Furthermore, we re-implemented the most powerful graph-based baseline EGNN with mini-batch size of 80 for fairness and present a detailed comparison in boxplots. All parameters are randomly initialized in three trials with fixed seeds 111, 222, 333 for reproducibility. As depicted in Figure 3, the absolute value of validation accuracy either in 1-shot or 5-shot setting tends to go up as training iterations increase. The proposed method reaches the peaks at an early stage and achieves a much higher performance, yet showing the sensitivity to seed selection in the case of 5-way 5-shot classification. We infer this variance is mainly introduced by edge inference sampling, which can be alleviated by averaging predictions from multiple sampling. From Table 2, we observe that our re-implemented EGNN obtains better performance (as indicated with †) by enlarging the batch size from 40 to 80. This phenomenon consistently verifies that task correlations are more likely to contribute positively to few-shot learning.",
            "The major ablation results regarding to CML-BGNN with different components on miniImageNet dataset are shown in gray blocks of Table 1. All variants are trained with three graph layers, mini-batch size of 80. Removing the history transition module, the variant CML-BGNN w/o C can only mine the pattern from local neighborhood without maintaining related prior information for reference, thus inevitably leading to a inferior performance, e.g., averagely decreasing 5-way 1-shot performance from 88.62%percent88.6288.62\\% to 63.74%percent63.7463.74\\%. CML-BGNN w/o B indicates the variant of our proposed model that directly utilizes the adjacency matrix to predict query labels without inferring task-specific parameters. Accordingly, the classification accuracy suffers a slight drop on both datasets, e.g., from 92.69%percent92.6992.69\\% to 91.21%percent91.2191.21\\% in a 5-way 5-shot setting, which demonstrates the necessity of the full CML-BGNN formulations."
        ]
    },
    "Sx5.T2": {
        "caption": "Table 2: The 5-way 1-shot and 5-shot classification accuracies (%) on the test split of the tieredImageNet dataset, with 95%percent9595\\% confidence interval. † indicates the re-implementation. “w/o” indicates without.",
        "table": null,
        "footnotes": [],
        "references": [
            "To verify the effectiveness of our proposed continual meta-learning model, we compare it with state-of-the-art meta-learning methods on the miniImageNet and tieredImageNet datasets. Here we report the best performance for every model in Table 1 and Table 2, along with the specifications of the backbone embedding models for feature extraction. Conv4 refers to a 4-layer convolutional network, ResNet-12 (?) denotes 4 layer blocks of depth 3 with 3×3333\\times 3 kernels and short connections, and WRN-28 is a 28-layer wide residual network. Generally, a deeper embedding network will lead to a better classification performance yet with a risk of overfitting. From Table 1, we can observe that our CML-BGNN equipped with three graph layers surpasses all compared meta-learning methods with a large margin, especially in the challenging scenario of 1-shot learning. More concretely, the proposed model with the basic conv4 embedding structure gains 43.5%percent43.543.5\\%, 45.1%percent45.145.1\\%, 42.8%percent42.842.8\\%, 51.1%percent51.151.1\\% relative improvements over the previous best optimization-based LEO (?), generation-based wDAE (?), metric-based CTM (?) and graph-based methods EGNN (?) in a 5-way 1-shot miniImageNet experiment, respectively. This is mainly owing to the learned history transition, which reinforces the memory of rare samples and correlations between classes. Furthermore, we re-implemented the most powerful graph-based baseline EGNN with mini-batch size of 80 for fairness and present a detailed comparison in boxplots. All parameters are randomly initialized in three trials with fixed seeds 111, 222, 333 for reproducibility. As depicted in Figure 3, the absolute value of validation accuracy either in 1-shot or 5-shot setting tends to go up as training iterations increase. The proposed method reaches the peaks at an early stage and achieves a much higher performance, yet showing the sensitivity to seed selection in the case of 5-way 5-shot classification. We infer this variance is mainly introduced by edge inference sampling, which can be alleviated by averaging predictions from multiple sampling. From Table 2, we observe that our re-implemented EGNN obtains better performance (as indicated with †) by enlarging the batch size from 40 to 80. This phenomenon consistently verifies that task correlations are more likely to contribute positively to few-shot learning.",
            "In addition to the evaluation for investigating the impact of GNN’s depth, we test our model in both 5-way 1-shot and 5-shot with different depth of graph neural networks on both miniImageNet (shown in Table 3) and miniImageNet (shown in Table 2) dataset. Generally, larger depth enables node to learn from a global perspective and thus enhances the expressive power of graph neural networks. For instance, the proposed CML-BGNN, EGNN and GNN equipped with a 3-layer structure respectively improve the classification accuracy by 3.4%percent3.43.4\\%, 6.4%percent6.46.4\\% and 4.3%percent4.34.3\\% w.r.t 5-way 1-shot classification, compared with the one with one-layer structure."
        ]
    },
    "Sx5.T3": {
        "caption": "Table 3: 5-Way 5-shot and 1-shot classification accuracies (%) on miniImageNet dataset with different depths of graph neural networks. † indicates our re-implementation.",
        "table": null,
        "footnotes": [],
        "references": [
            "In addition to the evaluation for investigating the impact of GNN’s depth, we test our model in both 5-way 1-shot and 5-shot with different depth of graph neural networks on both miniImageNet (shown in Table 3) and miniImageNet (shown in Table 2) dataset. Generally, larger depth enables node to learn from a global perspective and thus enhances the expressive power of graph neural networks. For instance, the proposed CML-BGNN, EGNN and GNN equipped with a 3-layer structure respectively improve the classification accuracy by 3.4%percent3.43.4\\%, 6.4%percent6.46.4\\% and 4.3%percent4.34.3\\% w.r.t 5-way 1-shot classification, compared with the one with one-layer structure."
        ]
    },
    "Sx5.T4": {
        "caption": "Table 4: Semi-supervised few-shot classification accuracies (%) on miniImageNet with 95% confidence intervals.",
        "table": null,
        "footnotes": [],
        "references": [
            "To quantitatively analyze the model capacity of handling uncertainty, we conduct 5-way 5-shot semi-supervised experiments on miniImageNet dataset and showcase major results in Table 4. In this semi-supervised regime, support data is partially labeled while balanced across all classes, which poses a greater challenge of modeling uncertain relationships between labeled and unlabeled samples. In particular, the 20%percent2020\\%-labeled column indicates that each episode contains 4 labeled support instances and 1 unlabeled instance. Here we use LabeledOnly to denote the strategy with only labeled support samples, and Semi presents training with both labeled and unlabeled data. By comparing the results with all graph-based counterparts, the proposed method greatly outperforms with a large margin (88.95%percent88.9588.95\\% vs 63.62%percent63.6263.62\\% and 52.45%percent52.4552.45\\%, when 20% are labeled). The superior performance results from our uncertainty modeling, which effectively adapts the noise and misguidance from adjacency initialization with task-specific parameters."
        ]
    }
}