{
    "PAPER'S NUMBER OF TABLES": 1,
    "S3.T1": {
        "caption": "TABLE I: Client endpoints information.",
        "table": "<table id=\"S3.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Endpoint name</th>\n<th id=\"S3.T1.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Machine</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S3.T1.1.2.1.1.1\" class=\"ltx_text ltx_font_typewriter\">delta-cpu-01</span></td>\n<td id=\"S3.T1.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">NCSA Delta supercomputer</td>\n</tr>\n<tr id=\"S3.T1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.3.2.1\" class=\"ltx_td ltx_align_left\"><span id=\"S3.T1.1.3.2.1.1\" class=\"ltx_text ltx_font_typewriter\">delta-gpu-01</span></td>\n<td id=\"S3.T1.1.3.2.2\" class=\"ltx_td ltx_align_left\">NCSA Delta supercomputer</td>\n</tr>\n<tr id=\"S3.T1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.4.3.1\" class=\"ltx_td ltx_align_left\"><span id=\"S3.T1.1.4.3.1.1\" class=\"ltx_text ltx_font_typewriter\">mydefconf</span></td>\n<td id=\"S3.T1.1.4.3.2\" class=\"ltx_td ltx_align_left\">ALCF Polaris supercomputer</td>\n</tr>\n<tr id=\"S3.T1.1.5.4\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.5.4.1\" class=\"ltx_td ltx_align_left\"><span id=\"S3.T1.1.5.4.1.1\" class=\"ltx_text ltx_font_typewriter\">crn-azure</span></td>\n<td id=\"S3.T1.1.5.4.2\" class=\"ltx_td ltx_align_left\">Microsoft Azure virtual machine</td>\n</tr>\n<tr id=\"S3.T1.1.6.5\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S3.T1.1.6.5.1.1\" class=\"ltx_text ltx_font_typewriter\">appfl-test</span></td>\n<td id=\"S3.T1.1.6.5.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">MacBook Pro, 2021, M1 Chip</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "In this section, we present a use case that employs APPFLx to conduct federated learning with a group of five clients to train a convolutional neural network (CNN) with two convolutional layers using the artificially partitioned MNIST datasets [18]. The MNIST dataset is partitioned equally into five chunks as the local datasets of the five FL clients. Two synchronous FL algorithms, FedAvg [2] and FedAvgM [14], are employed to train the model. The FL training takes 10 global communication rounds, and each client performs 2 local epochs in each round with batch size 64 and local learning rate 0.01. Local learning rate is decayed by a factor of 0.975 for each round, and the server momentum for FedAvgM is equal to 0.9.\nTable I shows the information of five heterogeneous client endpoints. Notably, all the endpoints only use the CPU for training. The group members use the client configuration page to register their endpoints and upload data loaders for their local datasets. The group administrator launches the FL experiment by specifying the training hyper-parameters in the server configuration page."
        ]
    }
}