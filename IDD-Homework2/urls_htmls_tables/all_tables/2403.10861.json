{
    "PAPER'S NUMBER OF TABLES": 3,
    "S4.T1": {
        "caption": "TABLE I: Hyperparameters and configurations used in our FedQNN framework.",
        "table": "<table id=\"S4.T1.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.4.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span id=\"S4.T1.4.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Parameter</span></th>\n<th id=\"S4.T1.4.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T1.4.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Value</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.4.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Number of Qubits</th>\n<td id=\"S4.T1.4.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">4</td>\n</tr>\n<tr id=\"S4.T1.4.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Optimizer</th>\n<td id=\"S4.T1.4.3.2.2\" class=\"ltx_td ltx_align_left\">Adam</td>\n</tr>\n<tr id=\"S4.T1.4.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Step Size for Adam Optimizer</th>\n<td id=\"S4.T1.4.4.3.2\" class=\"ltx_td ltx_align_left\">0.1</td>\n</tr>\n<tr id=\"S4.T1.4.5.4\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Max Iterations for Local Training</th>\n<td id=\"S4.T1.4.5.4.2\" class=\"ltx_td ltx_align_left\">100</td>\n</tr>\n<tr id=\"S4.T1.4.6.5\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Parameters for QNN</th>\n<td id=\"S4.T1.4.6.5.2\" class=\"ltx_td ltx_align_left\">Randomly initialized, Size: 16</td>\n</tr>\n<tr id=\"S4.T1.4.7.6\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.7.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Number of Clients</th>\n<td id=\"S4.T1.4.7.6.2\" class=\"ltx_td ltx_align_left\">1, 2, 3, 4, 5</td>\n</tr>\n<tr id=\"S4.T1.4.8.7\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.8.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Max Iterations for Global Training</th>\n<td id=\"S4.T1.4.8.7.2\" class=\"ltx_td ltx_align_left\">100</td>\n</tr>\n<tr id=\"S4.T1.4.9.8\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.9.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Test Set Size</th>\n<td id=\"S4.T1.4.9.8.2\" class=\"ltx_td ltx_align_left\">20% of the dataset</td>\n</tr>\n<tr id=\"S4.T1.4.10.9\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.10.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Accuracy Metric</th>\n<td id=\"S4.T1.4.10.9.2\" class=\"ltx_td ltx_align_left\">Binary classification accuracy</td>\n</tr>\n<tr id=\"S4.T1.4.11.10\" class=\"ltx_tr\">\n<th id=\"S4.T1.4.11.10.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">Loss Metric</th>\n<td id=\"S4.T1.4.11.10.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">MSE</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In our research, as shown in Fig. ",
                "5",
                " and in Tab. ",
                "I",
                ", we implement our QFL algorithm using ",
                "PennyLane",
                " – A Python library with ",
                "Pytorch",
                " backend, known for its QML capabilities ",
                "[",
                "35",
                "]",
                ". Our computational setup, provided by Google Colab, includes a system equipped with dual CPUs and an NVIDIA Tesla T4 GPU. We conduct extensive experimentation across three diverse datasets: The Iris dataset ",
                "[",
                "36",
                "]",
                ", the breast cancer dataset ",
                "[",
                "37",
                "]",
                ", and a synthetic DNA dataset designed for classifying promoter and non-promoter sequences. Each dataset presents unique challenges and characteristics. The Iris dataset, with its 150 samples of three different Iris flower species, tests basic classification abilities. The breast cancer dataset consists of 286 instances with nine attributes, including linear and nominal types for both classes. The synthetic DNA dataset, tailored for genomics applications, stands out for its focus on the binary classification of genetic sequences. It contains 200 samples, categorized into promoters and non-promoters.",
                "Throughout experimentation, we observed intriguing accuracy dynamics over training iterations throughout the analysis with FedQNN, across the three diverse datasets. The accuracy plots shown in Fig. ",
                "6",
                " for each dataset show a distinct zigzag pattern, reflecting the convergence and fluctuations in the learning process. However, it is important to highlight that the mean accuracy over ten distinct trials, with each trial comprising 100 iterations, did not exhibit this zigzag behavior for the three datasets, suggesting a more stable learning trend upon averaging multiple iterations. Despite the variations, each model consistently reaches an impressive peak accuracy, typically between 85% and 90%. This remarkable level of accuracy serves as compelling evidence of the effectiveness of our FedQNN framework in multi-dataset classification scenarios. Tab. ",
                "II",
                " supports these findings, showcasing essential metrics such as precision, recall, F1-score, and accuracy for each dataset. The consistently high accuracy values reiterate the robustness and reliability of our method for handling various datasets.",
                "The proposed FedQNN experiments explore the intriguing relationship between the number of clients and model accuracy. The results in Fig. ",
                "7",
                " demonstrate that increasing the number of clients can lead to remarkable improvements in accuracy. This phenomenon highlights the power of collaborative learning in a federated setting, where each client contributes to the collective intelligence, while keeping its data private. The robustness of FedQNN across different datasets reaffirms its potential as an effective framework for classification tasks.",
                "Furthermore, in Fig. ",
                "8",
                ", we present comprehensive tests across three different QPUs from IBM Quantum: ",
                "ibm_nairobi",
                ", ",
                "ibm_lagos",
                ", and ",
                "ibm_perth",
                " ",
                "[",
                "38",
                "]",
                ". Notably, all three QPUs deliver efficient results, with accuracy rates surpassing the 80% threshold. However, it is worth highlighting that these accuracy scores did exhibit some degree of fluctuation, which can be attributed to factors such as quantum noise and decoherence, variations in gate fidelity, discrepancies in quantum volume, and sensitivity to environmental conditions. Each of these factors can contribute to subtle yet impactful differences in performance across the QPUs. Importantly, these evaluations are conducted with only ",
                "10",
                "10",
                "10",
                " iterations to test the model’s rapid convergence, further indicating the potential of our model to excel in QC settings, even with limited refinement, and the promising prospects of its adaptability and performance on various QPUs."
            ]
        ]
    },
    "S4.T2": {
        "caption": "TABLE II: Classification reports for different datasets.",
        "table": "<table id=\"S4.T2.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.4.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.4.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T2.4.1.1.1.1\" class=\"ltx_text\">Dataset</span></th>\n<th id=\"S4.T2.4.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"4\">Metrics</th>\n</tr>\n<tr id=\"S4.T2.4.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.4.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\">Precision</td>\n<td id=\"S4.T2.4.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Recall</td>\n<td id=\"S4.T2.4.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">F1-Score</td>\n<td id=\"S4.T2.4.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">Accuracy</td>\n</tr>\n<tr id=\"S4.T2.4.3.3\" class=\"ltx_tr\">\n<th id=\"S4.T2.4.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Iris</th>\n<td id=\"S4.T2.4.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">0.89</td>\n<td id=\"S4.T2.4.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.89</td>\n<td id=\"S4.T2.4.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.89</td>\n<td id=\"S4.T2.4.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.9</td>\n</tr>\n<tr id=\"S4.T2.4.4.4\" class=\"ltx_tr\">\n<th id=\"S4.T2.4.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Breast Cancer</th>\n<td id=\"S4.T2.4.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">0.85</td>\n<td id=\"S4.T2.4.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.85</td>\n<td id=\"S4.T2.4.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.92</td>\n<td id=\"S4.T2.4.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.86</td>\n</tr>\n<tr id=\"S4.T2.4.5.5\" class=\"ltx_tr\">\n<th id=\"S4.T2.4.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t\">DNA</th>\n<td id=\"S4.T2.4.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">0.9</td>\n<td id=\"S4.T2.4.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">0.88</td>\n<td id=\"S4.T2.4.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">0.89</td>\n<td id=\"S4.T2.4.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">0.9</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In our research, as shown in Fig. ",
                "5",
                " and in Tab. ",
                "I",
                ", we implement our QFL algorithm using ",
                "PennyLane",
                " – A Python library with ",
                "Pytorch",
                " backend, known for its QML capabilities ",
                "[",
                "35",
                "]",
                ". Our computational setup, provided by Google Colab, includes a system equipped with dual CPUs and an NVIDIA Tesla T4 GPU. We conduct extensive experimentation across three diverse datasets: The Iris dataset ",
                "[",
                "36",
                "]",
                ", the breast cancer dataset ",
                "[",
                "37",
                "]",
                ", and a synthetic DNA dataset designed for classifying promoter and non-promoter sequences. Each dataset presents unique challenges and characteristics. The Iris dataset, with its 150 samples of three different Iris flower species, tests basic classification abilities. The breast cancer dataset consists of 286 instances with nine attributes, including linear and nominal types for both classes. The synthetic DNA dataset, tailored for genomics applications, stands out for its focus on the binary classification of genetic sequences. It contains 200 samples, categorized into promoters and non-promoters.",
                "Throughout experimentation, we observed intriguing accuracy dynamics over training iterations throughout the analysis with FedQNN, across the three diverse datasets. The accuracy plots shown in Fig. ",
                "6",
                " for each dataset show a distinct zigzag pattern, reflecting the convergence and fluctuations in the learning process. However, it is important to highlight that the mean accuracy over ten distinct trials, with each trial comprising 100 iterations, did not exhibit this zigzag behavior for the three datasets, suggesting a more stable learning trend upon averaging multiple iterations. Despite the variations, each model consistently reaches an impressive peak accuracy, typically between 85% and 90%. This remarkable level of accuracy serves as compelling evidence of the effectiveness of our FedQNN framework in multi-dataset classification scenarios. Tab. ",
                "II",
                " supports these findings, showcasing essential metrics such as precision, recall, F1-score, and accuracy for each dataset. The consistently high accuracy values reiterate the robustness and reliability of our method for handling various datasets.",
                "The proposed FedQNN experiments explore the intriguing relationship between the number of clients and model accuracy. The results in Fig. ",
                "7",
                " demonstrate that increasing the number of clients can lead to remarkable improvements in accuracy. This phenomenon highlights the power of collaborative learning in a federated setting, where each client contributes to the collective intelligence, while keeping its data private. The robustness of FedQNN across different datasets reaffirms its potential as an effective framework for classification tasks.",
                "Furthermore, in Fig. ",
                "8",
                ", we present comprehensive tests across three different QPUs from IBM Quantum: ",
                "ibm_nairobi",
                ", ",
                "ibm_lagos",
                ", and ",
                "ibm_perth",
                " ",
                "[",
                "38",
                "]",
                ". Notably, all three QPUs deliver efficient results, with accuracy rates surpassing the 80% threshold. However, it is worth highlighting that these accuracy scores did exhibit some degree of fluctuation, which can be attributed to factors such as quantum noise and decoherence, variations in gate fidelity, discrepancies in quantum volume, and sensitivity to environmental conditions. Each of these factors can contribute to subtle yet impactful differences in performance across the QPUs. Importantly, these evaluations are conducted with only ",
                "10",
                "10",
                "10",
                " iterations to test the model’s rapid convergence, further indicating the potential of our model to excel in QC settings, even with limited refinement, and the promising prospects of its adaptability and performance on various QPUs."
            ]
        ]
    },
    "S4.T3": {
        "caption": "TABLE III: Comparison of QFL frameworks on different datasets.",
        "table": "<table id=\"S4.T3.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T3.4.5.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.4.5.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Reference</th>\n<th id=\"S4.T3.4.5.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Dataset</th>\n<th id=\"S4.T3.4.5.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Key Features</th>\n<th id=\"S4.T3.4.5.1.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Accuracy</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.4.6.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.4.6.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib15\" title=\"\" class=\"ltx_ref\">15</a>]</cite></th>\n<td id=\"S4.T3.4.6.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">CIFAR-10</td>\n<td id=\"S4.T3.4.6.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">HQCC</td>\n<td id=\"S4.T3.4.6.1.4\" class=\"ltx_td ltx_align_left ltx_border_t\">94.05%</td>\n</tr>\n<tr id=\"S4.T3.4.7.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.4.7.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib32\" title=\"\" class=\"ltx_ref\">32</a>]</cite></th>\n<td id=\"S4.T3.4.7.2.2\" class=\"ltx_td ltx_align_left\">Mini-MNIST</td>\n<td id=\"S4.T3.4.7.2.3\" class=\"ltx_td ltx_align_left\">SlimQFL</td>\n<td id=\"S4.T3.4.7.2.4\" class=\"ltx_td ltx_align_left\">77%</td>\n</tr>\n<tr id=\"S4.T3.4.8.3\" class=\"ltx_tr\">\n<th id=\"S4.T3.4.8.3.1\" class=\"ltx_td ltx_th ltx_th_row\"></th>\n<td id=\"S4.T3.4.8.3.2\" class=\"ltx_td\"></td>\n<td id=\"S4.T3.4.8.3.3\" class=\"ltx_td ltx_align_left\">Vanilla QFL</td>\n<td id=\"S4.T3.4.8.3.4\" class=\"ltx_td ltx_align_left\">76%</td>\n</tr>\n<tr id=\"S4.T3.4.9.4\" class=\"ltx_tr\">\n<th id=\"S4.T3.4.9.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\">33</a>]</cite></th>\n<td id=\"S4.T3.4.9.4.2\" class=\"ltx_td ltx_align_left\">MNIST-3</td>\n<td id=\"S4.T3.4.9.4.3\" class=\"ltx_td ltx_align_left\">QNN</td>\n<td id=\"S4.T3.4.9.4.4\" class=\"ltx_td ltx_align_left\">70%</td>\n</tr>\n<tr id=\"S4.T3.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib39\" title=\"\" class=\"ltx_ref\">39</a>]</cite></th>\n<td id=\"S4.T3.1.1.3\" class=\"ltx_td ltx_align_left\">MNIST-2</td>\n<td id=\"S4.T3.1.1.4\" class=\"ltx_td ltx_align_left\">qFedInf</td>\n<td id=\"S4.T3.1.1.1\" class=\"ltx_td ltx_align_left\">\n<math id=\"S4.T3.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"92.7\\pm 0.2\" display=\"inline\"><semantics id=\"S4.T3.1.1.1.m1.1a\"><mrow id=\"S4.T3.1.1.1.m1.1.1\" xref=\"S4.T3.1.1.1.m1.1.1.cmml\"><mn id=\"S4.T3.1.1.1.m1.1.1.2\" xref=\"S4.T3.1.1.1.m1.1.1.2.cmml\">92.7</mn><mo id=\"S4.T3.1.1.1.m1.1.1.1\" xref=\"S4.T3.1.1.1.m1.1.1.1.cmml\">±</mo><mn id=\"S4.T3.1.1.1.m1.1.1.3\" xref=\"S4.T3.1.1.1.m1.1.1.3.cmml\">0.2</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.1.1.1.m1.1b\"><apply id=\"S4.T3.1.1.1.m1.1.1.cmml\" xref=\"S4.T3.1.1.1.m1.1.1\"><csymbol cd=\"latexml\" id=\"S4.T3.1.1.1.m1.1.1.1.cmml\" xref=\"S4.T3.1.1.1.m1.1.1.1\">plus-or-minus</csymbol><cn type=\"float\" id=\"S4.T3.1.1.1.m1.1.1.2.cmml\" xref=\"S4.T3.1.1.1.m1.1.1.2\">92.7</cn><cn type=\"float\" id=\"S4.T3.1.1.1.m1.1.1.3.cmml\" xref=\"S4.T3.1.1.1.m1.1.1.3\">0.2</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.1.1.1.m1.1c\">92.7\\pm 0.2</annotation></semantics></math>%</td>\n</tr>\n<tr id=\"S4.T3.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.2.2\" class=\"ltx_td ltx_th ltx_th_row\"></th>\n<td id=\"S4.T3.2.2.3\" class=\"ltx_td\"></td>\n<td id=\"S4.T3.2.2.4\" class=\"ltx_td ltx_align_left\">qFedAvg</td>\n<td id=\"S4.T3.2.2.1\" class=\"ltx_td ltx_align_left\">\n<math id=\"S4.T3.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"88.4\\pm 0.8\" display=\"inline\"><semantics id=\"S4.T3.2.2.1.m1.1a\"><mrow id=\"S4.T3.2.2.1.m1.1.1\" xref=\"S4.T3.2.2.1.m1.1.1.cmml\"><mn id=\"S4.T3.2.2.1.m1.1.1.2\" xref=\"S4.T3.2.2.1.m1.1.1.2.cmml\">88.4</mn><mo id=\"S4.T3.2.2.1.m1.1.1.1\" xref=\"S4.T3.2.2.1.m1.1.1.1.cmml\">±</mo><mn id=\"S4.T3.2.2.1.m1.1.1.3\" xref=\"S4.T3.2.2.1.m1.1.1.3.cmml\">0.8</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.2.2.1.m1.1b\"><apply id=\"S4.T3.2.2.1.m1.1.1.cmml\" xref=\"S4.T3.2.2.1.m1.1.1\"><csymbol cd=\"latexml\" id=\"S4.T3.2.2.1.m1.1.1.1.cmml\" xref=\"S4.T3.2.2.1.m1.1.1.1\">plus-or-minus</csymbol><cn type=\"float\" id=\"S4.T3.2.2.1.m1.1.1.2.cmml\" xref=\"S4.T3.2.2.1.m1.1.1.2\">88.4</cn><cn type=\"float\" id=\"S4.T3.2.2.1.m1.1.1.3.cmml\" xref=\"S4.T3.2.2.1.m1.1.1.3\">0.8</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.2.2.1.m1.1c\">88.4\\pm 0.8</annotation></semantics></math>%</td>\n</tr>\n<tr id=\"S4.T3.3.3\" class=\"ltx_tr\">\n<th id=\"S4.T3.3.3.2\" class=\"ltx_td ltx_th ltx_th_row\"></th>\n<td id=\"S4.T3.3.3.3\" class=\"ltx_td ltx_align_left\">Fashion-MNIST</td>\n<td id=\"S4.T3.3.3.4\" class=\"ltx_td ltx_align_left\">qFedInf</td>\n<td id=\"S4.T3.3.3.1\" class=\"ltx_td ltx_align_left\">\n<math id=\"S4.T3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"75.4\\pm 0.3\" display=\"inline\"><semantics id=\"S4.T3.3.3.1.m1.1a\"><mrow id=\"S4.T3.3.3.1.m1.1.1\" xref=\"S4.T3.3.3.1.m1.1.1.cmml\"><mn id=\"S4.T3.3.3.1.m1.1.1.2\" xref=\"S4.T3.3.3.1.m1.1.1.2.cmml\">75.4</mn><mo id=\"S4.T3.3.3.1.m1.1.1.1\" xref=\"S4.T3.3.3.1.m1.1.1.1.cmml\">±</mo><mn id=\"S4.T3.3.3.1.m1.1.1.3\" xref=\"S4.T3.3.3.1.m1.1.1.3.cmml\">0.3</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.3.3.1.m1.1b\"><apply id=\"S4.T3.3.3.1.m1.1.1.cmml\" xref=\"S4.T3.3.3.1.m1.1.1\"><csymbol cd=\"latexml\" id=\"S4.T3.3.3.1.m1.1.1.1.cmml\" xref=\"S4.T3.3.3.1.m1.1.1.1\">plus-or-minus</csymbol><cn type=\"float\" id=\"S4.T3.3.3.1.m1.1.1.2.cmml\" xref=\"S4.T3.3.3.1.m1.1.1.2\">75.4</cn><cn type=\"float\" id=\"S4.T3.3.3.1.m1.1.1.3.cmml\" xref=\"S4.T3.3.3.1.m1.1.1.3\">0.3</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.3.3.1.m1.1c\">75.4\\pm 0.3</annotation></semantics></math>%</td>\n</tr>\n<tr id=\"S4.T3.4.4\" class=\"ltx_tr\">\n<th id=\"S4.T3.4.4.2\" class=\"ltx_td ltx_th ltx_th_row\"></th>\n<td id=\"S4.T3.4.4.3\" class=\"ltx_td\"></td>\n<td id=\"S4.T3.4.4.4\" class=\"ltx_td ltx_align_left\">qFedAvg</td>\n<td id=\"S4.T3.4.4.1\" class=\"ltx_td ltx_align_left\">\n<math id=\"S4.T3.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"66.7\\pm 1.3\" display=\"inline\"><semantics id=\"S4.T3.4.4.1.m1.1a\"><mrow id=\"S4.T3.4.4.1.m1.1.1\" xref=\"S4.T3.4.4.1.m1.1.1.cmml\"><mn id=\"S4.T3.4.4.1.m1.1.1.2\" xref=\"S4.T3.4.4.1.m1.1.1.2.cmml\">66.7</mn><mo id=\"S4.T3.4.4.1.m1.1.1.1\" xref=\"S4.T3.4.4.1.m1.1.1.1.cmml\">±</mo><mn id=\"S4.T3.4.4.1.m1.1.1.3\" xref=\"S4.T3.4.4.1.m1.1.1.3.cmml\">1.3</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.4.4.1.m1.1b\"><apply id=\"S4.T3.4.4.1.m1.1.1.cmml\" xref=\"S4.T3.4.4.1.m1.1.1\"><csymbol cd=\"latexml\" id=\"S4.T3.4.4.1.m1.1.1.1.cmml\" xref=\"S4.T3.4.4.1.m1.1.1.1\">plus-or-minus</csymbol><cn type=\"float\" id=\"S4.T3.4.4.1.m1.1.1.2.cmml\" xref=\"S4.T3.4.4.1.m1.1.1.2\">66.7</cn><cn type=\"float\" id=\"S4.T3.4.4.1.m1.1.1.3.cmml\" xref=\"S4.T3.4.4.1.m1.1.1.3\">1.3</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.4.4.1.m1.1c\">66.7\\pm 1.3</annotation></semantics></math>%</td>\n</tr>\n<tr id=\"S4.T3.4.10.5\" class=\"ltx_tr\">\n<th id=\"S4.T3.4.10.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S4.T3.4.10.5.1.1\" class=\"ltx_text ltx_font_bold\">Our FedQNN</span></th>\n<td id=\"S4.T3.4.10.5.2\" class=\"ltx_td ltx_align_left\">Iris</td>\n<td id=\"S4.T3.4.10.5.3\" class=\"ltx_td ltx_align_left\">Distributed QNN</td>\n<td id=\"S4.T3.4.10.5.4\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T3.4.10.5.4.1\" class=\"ltx_text ltx_font_bold\">90%</span></td>\n</tr>\n<tr id=\"S4.T3.4.11.6\" class=\"ltx_tr\">\n<th id=\"S4.T3.4.11.6.1\" class=\"ltx_td ltx_th ltx_th_row\"></th>\n<td id=\"S4.T3.4.11.6.2\" class=\"ltx_td ltx_align_left\">Breast Cancer</td>\n<td id=\"S4.T3.4.11.6.3\" class=\"ltx_td\"></td>\n<td id=\"S4.T3.4.11.6.4\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T3.4.11.6.4.1\" class=\"ltx_text ltx_font_bold\">86%</span></td>\n</tr>\n<tr id=\"S4.T3.4.12.7\" class=\"ltx_tr\">\n<th id=\"S4.T3.4.12.7.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_bb\"></th>\n<td id=\"S4.T3.4.12.7.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">DNA</td>\n<td id=\"S4.T3.4.12.7.3\" class=\"ltx_td ltx_border_bb\"></td>\n<td id=\"S4.T3.4.12.7.4\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S4.T3.4.12.7.4.1\" class=\"ltx_text ltx_font_bold\">90%</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "The comprehensive experimentation and analysis of the proposed FedQNN framework yield significant insights, underlining its potential in QML. A critical observation is the framework’s adeptness in managing a spectrum of datasets, illustrating its adaptability and robustness. This versatility is pivotal in QML, where applications often span diverse data types and problem domains.",
                "Notably, the framework exhibits stable learning dynamics over multiple iterations despite initial accuracy fluctuations. Such a trend indicates a resilient learning algorithm capable of consistent performance enhancement over time. This aspect is crucial in practical scenarios, where models must adapt and stabilize despite variable data inputs.",
                "Performance metrics across the datasets consistently register high, highlighting the model’s precision, recall, and accuracy proficiency. These metrics are crucial benchmarks in ML, and their high values in this framework reinforce its efficacy in balanced classification tasks.",
                "The study also reveals the positive influence of increasing client collaboration within the federated network. This finding accentuates the benefits of a federated approach in ML, where diversity in data sources enriches the learning process and enhances model accuracy.",
                "The experiments, across different QPUs from IBM Quantum, demonstrate the framework’s adaptability and efficient performance, even with limited iterations. This adaptability to various quantum hardware architectures is a testament to the framework’s potential for widespread application in QC settings.",
                "In a comparative analysis of QFL methods as presented in Tab. ",
                "III",
                ", our FedQNN framework demonstrates outstanding performance across various datasets; when evaluated on the CIFAR-10 dataset for planes versus cars, a hybrid quantum-classical classifier (HQCC) achieved an accuracy of 94.05% with just two local epochs of federated training ",
                "[",
                "15",
                "]",
                ". Additionally, the ",
                "SlimQFL",
                " and ",
                "Vanilla QFL",
                " models achieve accuracies of 77% and 76%, respectively, on the mini-MNIST dataset ",
                "[",
                "32",
                "]",
                ". Even when dealing with non-Independent and Identically Distributed (IID) data on MNIST-3, a QNN model reached a 70% accuracy mark ",
                "[",
                "33",
                "]",
                ". Notably, our results show superior performance on three diverse datasets: Iris (90%), breast cancer (86%), and DNA (90%), which is competitive with ",
                "qFedInf",
                " and ",
                "qFedAvg",
                " that report accuracies up to 92.7% and 88.4% on MNIST-2, and 75.4% and 66.7% on Fashion-MNIST ",
                "[",
                "39",
                "]",
                ". These results underscore the fruitful utility of our QFL framework and its versatility in handling different types of data, thus marking a significant step forward in QFL research.",
                "The overall outcomes from this investigation signify a promising avenue for QML, particularly in its application across varied datasets and quantum environments. However, these successes also pave the way for future explorations, particularly optimizing quantum circuit designs and enhancing integration techniques within federated learning systems. Moreover, the results suggest potential broader implications in fields requiring rigorous data privacy and security, positioning QFL as a valuable tool in privacy-sensitive collaborative research and applications."
            ]
        ]
    }
}