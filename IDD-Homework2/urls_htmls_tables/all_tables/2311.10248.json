{
    "PAPER'S NUMBER OF TABLES": 3,
    "S5.T1": {
        "caption": "Table 1. CNN architecture trained on local devices",
        "table": "<table id=\"S5.T1.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T1.4.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.4.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S5.T1.4.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Layer</span></th>\n<th id=\"S5.T1.4.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T1.4.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Size</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.4.2.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.4.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\"><span id=\"S5.T1.4.2.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Input</span></th>\n<td id=\"S5.T1.4.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_tt\"><span id=\"S5.T1.4.2.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">28x28x1</span></td>\n</tr>\n<tr id=\"S5.T1.4.3.2\" class=\"ltx_tr\">\n<th id=\"S5.T1.4.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S5.T1.4.3.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Convolution + ReLU</span></th>\n<td id=\"S5.T1.4.3.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S5.T1.4.3.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">20x5x1</span></td>\n</tr>\n<tr id=\"S5.T1.4.4.3\" class=\"ltx_tr\">\n<th id=\"S5.T1.4.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S5.T1.4.4.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Max Pooling</span></th>\n<td id=\"S5.T1.4.4.3.2\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S5.T1.4.4.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">2x2</span></td>\n</tr>\n<tr id=\"S5.T1.4.5.4\" class=\"ltx_tr\">\n<th id=\"S5.T1.4.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S5.T1.4.5.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Convolution + ReLU</span></th>\n<td id=\"S5.T1.4.5.4.2\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S5.T1.4.5.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">4x4x50</span></td>\n</tr>\n<tr id=\"S5.T1.4.6.5\" class=\"ltx_tr\">\n<th id=\"S5.T1.4.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S5.T1.4.6.5.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Max Pooling</span></th>\n<td id=\"S5.T1.4.6.5.2\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S5.T1.4.6.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">2x2</span></td>\n</tr>\n<tr id=\"S5.T1.4.7.6\" class=\"ltx_tr\">\n<th id=\"S5.T1.4.7.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S5.T1.4.7.6.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Fully Connected + ReLU</span></th>\n<td id=\"S5.T1.4.7.6.2\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S5.T1.4.7.6.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">500</span></td>\n</tr>\n<tr id=\"S5.T1.4.8.7\" class=\"ltx_tr\">\n<th id=\"S5.T1.4.8.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S5.T1.4.8.7.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Fully Connected + Softmax</span></th>\n<td id=\"S5.T1.4.8.7.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\"><span id=\"S5.T1.4.8.7.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">10</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Models: We constructed a Convolutional Neural Network (CNN) classifier for all the experiments considered in this work. In TableÂ 1, we present how the neural network layers were constructed for the MNIST and FMNIST datasets. The ResNet-18 model was used when running experiments using the CIFAR10 dataset."
        ]
    },
    "S5.T2": {
        "caption": "Table 2. Aggregation and training time for different FL algorithms (Model Boosting Attack, 3 Adversaries)",
        "table": "<table id=\"S5.T2.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T2.4.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T2.4.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_tt\" rowspan=\"2\"><span id=\"S5.T2.4.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Algorithm</span></th>\n<td id=\"S5.T2.4.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\"><span id=\"S5.T2.4.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Avg. Aggregation Time (s)</span></td>\n<td id=\"S5.T2.4.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\"><span id=\"S5.T2.4.1.1.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Avg. Training Time (s)</span></td>\n</tr>\n<tr id=\"S5.T2.4.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T2.4.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.4.2.2.1.1\" class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">MNIST</span></td>\n<td id=\"S5.T2.4.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.4.2.2.2.1\" class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">CIFAR10</span></td>\n<td id=\"S5.T2.4.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.4.2.2.3.1\" class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">MNIST</span></td>\n<td id=\"S5.T2.4.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.4.2.2.4.1\" class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">CIFAR10</span></td>\n</tr>\n<tr id=\"S5.T2.4.3.3\" class=\"ltx_tr\">\n<th id=\"S5.T2.4.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\"><span id=\"S5.T2.4.3.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedAvg</span></th>\n<td id=\"S5.T2.4.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.4.3.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.0062</span></td>\n<td id=\"S5.T2.4.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.4.3.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.0258</span></td>\n<td id=\"S5.T2.4.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.4.3.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.0767</span></td>\n<td id=\"S5.T2.4.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.4.3.3.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.8528</span></td>\n</tr>\n<tr id=\"S5.T2.4.4.4\" class=\"ltx_tr\">\n<th id=\"S5.T2.4.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\"><span id=\"S5.T2.4.4.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedTruth</span></th>\n<td id=\"S5.T2.4.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.4.4.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">2.9511</span></td>\n<td id=\"S5.T2.4.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.4.4.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">3.2127</span></td>\n<td id=\"S5.T2.4.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.4.4.4.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.0773</span></td>\n<td id=\"S5.T2.4.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.4.4.4.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.8617</span></td>\n</tr>\n<tr id=\"S5.T2.4.5.5\" class=\"ltx_tr\">\n<th id=\"S5.T2.4.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\"><span id=\"S5.T2.4.5.5.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedTruth-layer</span></th>\n<td id=\"S5.T2.4.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.4.5.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">2.8591</span></td>\n<td id=\"S5.T2.4.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.4.5.5.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">5.5734</span></td>\n<td id=\"S5.T2.4.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.4.5.5.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.0778</span></td>\n<td id=\"S5.T2.4.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.4.5.5.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.8528</span></td>\n</tr>\n<tr id=\"S5.T2.4.6.6\" class=\"ltx_tr\">\n<th id=\"S5.T2.4.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\"><span id=\"S5.T2.4.6.6.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Flame</span></th>\n<td id=\"S5.T2.4.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.4.6.6.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.1936</span></td>\n<td id=\"S5.T2.4.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.4.6.6.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">2.7209</span></td>\n<td id=\"S5.T2.4.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.4.6.6.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.0800</span></td>\n<td id=\"S5.T2.4.6.6.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.4.6.6.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.8508</span></td>\n</tr>\n<tr id=\"S5.T2.4.7.7\" class=\"ltx_tr\">\n<th id=\"S5.T2.4.7.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\"><span id=\"S5.T2.4.7.7.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FLTrust</span></th>\n<td id=\"S5.T2.4.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.4.7.7.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.0326</span></td>\n<td id=\"S5.T2.4.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.4.7.7.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.1566</span></td>\n<td id=\"S5.T2.4.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.4.7.7.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.0808</span></td>\n<td id=\"S5.T2.4.7.7.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.4.7.7.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.8555</span></td>\n</tr>\n<tr id=\"S5.T2.4.8.8\" class=\"ltx_tr\">\n<th id=\"S5.T2.4.8.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\"><span id=\"S5.T2.4.8.8.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Krum</span></th>\n<td id=\"S5.T2.4.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.4.8.8.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">4.0604</span></td>\n<td id=\"S5.T2.4.8.8.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.4.8.8.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.7023</span></td>\n<td id=\"S5.T2.4.8.8.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.4.8.8.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.0782</span></td>\n<td id=\"S5.T2.4.8.8.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.4.8.8.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.8579</span></td>\n</tr>\n<tr id=\"S5.T2.4.9.9\" class=\"ltx_tr\">\n<th id=\"S5.T2.4.9.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\"><span id=\"S5.T2.4.9.9.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Median</span></th>\n<td id=\"S5.T2.4.9.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.4.9.9.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.0413</span></td>\n<td id=\"S5.T2.4.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.4.9.9.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.0030</span></td>\n<td id=\"S5.T2.4.9.9.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T2.4.9.9.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.0804</span></td>\n<td id=\"S5.T2.4.9.9.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T2.4.9.9.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.8578</span></td>\n</tr>\n<tr id=\"S5.T2.4.10.10\" class=\"ltx_tr\">\n<th id=\"S5.T2.4.10.10.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_rr ltx_border_t\"><span id=\"S5.T2.4.10.10.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Trimmed Mean</span></th>\n<td id=\"S5.T2.4.10.10.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S5.T2.4.10.10.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.0266</span></td>\n<td id=\"S5.T2.4.10.10.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S5.T2.4.10.10.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.0077</span></td>\n<td id=\"S5.T2.4.10.10.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S5.T2.4.10.10.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.0792</span></td>\n<td id=\"S5.T2.4.10.10.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T2.4.10.10.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.8580</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "From our experimental results, we observe that both FedTruth and FedTruth-layer perform similarly in terms of model accuracy and robustness. To evaluate their efficiency, we present the average time consumption for each aggregation algorithm in TableÂ 2. We measure the average aggregation time and average training time on each client, based on training the CNN model on MNIST for 100 rounds with three adversaries in each round."
        ]
    },
    "S5.T3": {
        "caption": "Table 3. Number of Iterations for FedTruth and FedTruth-layer (Model Boosting Attack, 3 Adversaries)",
        "table": "<table id=\"S5.T3.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T3.4.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T3.4.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_rr ltx_border_tt\" rowspan=\"2\"><span id=\"S5.T3.4.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Algorithm</span></th>\n<th id=\"S5.T3.4.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><span id=\"S5.T3.4.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Avg. # of Iterations to FedTruth Convergence</span></th>\n</tr>\n<tr id=\"S5.T3.4.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T3.4.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S5.T3.4.2.2.1.1\" class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">MNIST</span></th>\n<th id=\"S5.T3.4.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T3.4.2.2.2.1\" class=\"ltx_text ltx_font_italic\" style=\"font-size:90%;\">CIFAR10</span></th>\n</tr>\n<tr id=\"S5.T3.4.3.3\" class=\"ltx_tr\">\n<th id=\"S5.T3.4.3.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_rr ltx_border_t\"><span id=\"S5.T3.4.3.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedTruth</span></th>\n<th id=\"S5.T3.4.3.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S5.T3.4.3.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">39</span></th>\n<th id=\"S5.T3.4.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T3.4.3.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">39</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T3.4.4.1\" class=\"ltx_tr\">\n<th id=\"S5.T3.4.4.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_t\"><span id=\"S5.T3.4.4.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedTruth-layer Total</span></th>\n<td id=\"S5.T3.4.4.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T3.4.4.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">91.40</span></td>\n<td id=\"S5.T3.4.4.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.4.4.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">860.70</span></td>\n</tr>\n<tr id=\"S5.T3.4.5.2\" class=\"ltx_tr\">\n<th id=\"S5.T3.4.5.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_t\"><span id=\"S5.T3.4.5.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedTruth-layer L1</span></th>\n<td id=\"S5.T3.4.5.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T3.4.5.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">8.45</span></td>\n<td id=\"S5.T3.4.5.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.4.5.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">10.20</span></td>\n</tr>\n<tr id=\"S5.T3.4.6.3\" class=\"ltx_tr\">\n<th id=\"S5.T3.4.6.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_t\"><span id=\"S5.T3.4.6.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedTruth-layer L2</span></th>\n<td id=\"S5.T3.4.6.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T3.4.6.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">4.81</span></td>\n<td id=\"S5.T3.4.6.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.4.6.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">6.85</span></td>\n</tr>\n<tr id=\"S5.T3.4.7.4\" class=\"ltx_tr\">\n<th id=\"S5.T3.4.7.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_t\"><span id=\"S5.T3.4.7.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedTruth-layer L3</span></th>\n<td id=\"S5.T3.4.7.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T3.4.7.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">11.01</span></td>\n<td id=\"S5.T3.4.7.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.4.7.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">6.49</span></td>\n</tr>\n<tr id=\"S5.T3.4.8.5\" class=\"ltx_tr\">\n<th id=\"S5.T3.4.8.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_t\"><span id=\"S5.T3.4.8.5.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedTruth-layer L4</span></th>\n<td id=\"S5.T3.4.8.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T3.4.8.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">5.29</span></td>\n<td id=\"S5.T3.4.8.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.4.8.5.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">10.24</span></td>\n</tr>\n<tr id=\"S5.T3.4.9.6\" class=\"ltx_tr\">\n<th id=\"S5.T3.4.9.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_t\"><span id=\"S5.T3.4.9.6.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedTruth-layer L5</span></th>\n<td id=\"S5.T3.4.9.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T3.4.9.6.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">39.00</span></td>\n<td id=\"S5.T3.4.9.6.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.4.9.6.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">6.10</span></td>\n</tr>\n<tr id=\"S5.T3.4.10.7\" class=\"ltx_tr\">\n<th id=\"S5.T3.4.10.7.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_t\"><span id=\"S5.T3.4.10.7.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedTruth-layer L6</span></th>\n<td id=\"S5.T3.4.10.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T3.4.10.7.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">6.64</span></td>\n<td id=\"S5.T3.4.10.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.4.10.7.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">6.21</span></td>\n</tr>\n<tr id=\"S5.T3.4.11.8\" class=\"ltx_tr\">\n<th id=\"S5.T3.4.11.8.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_t\"><span id=\"S5.T3.4.11.8.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedTruth-layer L7</span></th>\n<td id=\"S5.T3.4.11.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T3.4.11.8.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">10.55</span></td>\n<td id=\"S5.T3.4.11.8.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.4.11.8.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">14.79</span></td>\n</tr>\n<tr id=\"S5.T3.4.12.9\" class=\"ltx_tr\">\n<th id=\"S5.T3.4.12.9.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_rr ltx_border_t\"><span id=\"S5.T3.4.12.9.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedTruth-layer L8</span></th>\n<td id=\"S5.T3.4.12.9.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\"><span id=\"S5.T3.4.12.9.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">5.65</span></td>\n<td id=\"S5.T3.4.12.9.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S5.T3.4.12.9.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">5.71</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Interestingly, we observe that FedTruth and FedTruth-layer have similar total time consumption when using CNN with a small number of layers. We count the number of iterations required for each algorithm to reach convergence and present the results in TableÂ 3. For CNN (8 layers) on MNIST dataset, we find that FedTruth requires an average of 39 iterations to estimate the ground-truth model update, while FedTruth-layer requires an average of 91.4 iterations (three times more than FedTruth) to reach convergence, despite having eight layers in the CNN model. Moreover, FedTruth on each layer has a smaller input size and requires less computation time on the distance compared to FedTruth with the entire model update as input. In conclusion, we find that both FedTruth and FedTruth-layer have similar performance on the CNN (8 layers) model in terms of accuracy and robustness.\nHowever, FedTruth is much more efficient than FedTruth-layer when there are a large number of layers in the model (e.g., ResNet-18)."
        ]
    }
}