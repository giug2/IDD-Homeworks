{
    "PAPER'S NUMBER OF TABLES": 14,
    "S4.T1": {
        "caption": "Table 1: The accuracy with FedPepTAO and diverse baseline approaches. All the methods from GLUE benchmark are evaluated on development sets while other tasks are evaluated with test sets. The best results are highlighted in bold and the second bests are marked with underline. All the results are obtained using RoBERTaLARGE.",
        "table": "<table id=\"S4.T1.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T1.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></th>\n<th id=\"S4.T1.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T1.1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Comm. Params</span></th>\n<th id=\"S4.T1.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T1.1.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">QNLI</span></th>\n<th id=\"S4.T1.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T1.1.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">SST-2</span></th>\n<th id=\"S4.T1.1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T1.1.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">CoLA</span></th>\n<th id=\"S4.T1.1.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T1.1.1.1.1.6.1\" class=\"ltx_text ltx_font_bold\">MPRC</span></th>\n<th id=\"S4.T1.1.1.1.1.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T1.1.1.1.1.7.1\" class=\"ltx_text ltx_font_bold\">RTE</span></th>\n<th id=\"S4.T1.1.1.1.1.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T1.1.1.1.1.8.1\" class=\"ltx_text ltx_font_bold\">BoolQ</span></th>\n<th id=\"S4.T1.1.1.1.1.9\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T1.1.1.1.1.9.1\" class=\"ltx_text ltx_font_bold\">MPQA</span></th>\n<th id=\"S4.T1.1.1.1.1.10\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T1.1.1.1.1.10.1\" class=\"ltx_text ltx_font_bold\">Subj</span></th>\n<th id=\"S4.T1.1.1.1.1.11\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T1.1.1.1.1.11.1\" class=\"ltx_text ltx_font_bold\">Trec</span></th>\n<th id=\"S4.T1.1.1.1.1.12\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T1.1.1.1.1.12.1\" class=\"ltx_text ltx_font_bold\">MR</span></th>\n<th id=\"S4.T1.1.1.1.1.13\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S4.T1.1.1.1.1.13.1\" class=\"ltx_text ltx_font_bold\">Avg</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">Adapter</td>\n<td id=\"S4.T1.1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"background-color:#8C8C8C;\"><span id=\"S4.T1.1.1.2.1.2.1\" class=\"ltx_text\" style=\"background-color:#8C8C8C;\">7.4M</span></td>\n<td id=\"S4.T1.1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">87.79</td>\n<td id=\"S4.T1.1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">94.04</td>\n<td id=\"S4.T1.1.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">30.96</td>\n<td id=\"S4.T1.1.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">71.81</td>\n<td id=\"S4.T1.1.1.2.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\">68.59</td>\n<td id=\"S4.T1.1.1.2.1.8\" class=\"ltx_td ltx_align_center ltx_border_t\">75.11</td>\n<td id=\"S4.T1.1.1.2.1.9\" class=\"ltx_td ltx_align_center ltx_border_t\">90.97</td>\n<td id=\"S4.T1.1.1.2.1.10\" class=\"ltx_td ltx_align_center ltx_border_t\">94.6</td>\n<td id=\"S4.T1.1.1.2.1.11\" class=\"ltx_td ltx_align_center ltx_border_t\">79</td>\n<td id=\"S4.T1.1.1.2.1.12\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T1.1.1.2.1.12.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">91.9</span></td>\n<td id=\"S4.T1.1.1.2.1.13\" class=\"ltx_td ltx_align_center ltx_border_t\">75.36</td>\n</tr>\n<tr id=\"S4.T1.1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.3.2.1\" class=\"ltx_td ltx_align_center\">FedPrompt</td>\n<td id=\"S4.T1.1.1.3.2.2\" class=\"ltx_td ltx_align_center\" style=\"background-color:#F2F2F2;\"><span id=\"S4.T1.1.1.3.2.2.1\" class=\"ltx_text\" style=\"background-color:#F2F2F2;\">131K</span></td>\n<td id=\"S4.T1.1.1.3.2.3\" class=\"ltx_td ltx_align_center\">85.91</td>\n<td id=\"S4.T1.1.1.3.2.4\" class=\"ltx_td ltx_align_center\">94.84</td>\n<td id=\"S4.T1.1.1.3.2.5\" class=\"ltx_td ltx_align_center\">33.05</td>\n<td id=\"S4.T1.1.1.3.2.6\" class=\"ltx_td ltx_align_center\">77.87</td>\n<td id=\"S4.T1.1.1.3.2.7\" class=\"ltx_td ltx_align_center\">61.73</td>\n<td id=\"S4.T1.1.1.3.2.8\" class=\"ltx_td ltx_align_center\">74.77</td>\n<td id=\"S4.T1.1.1.3.2.9\" class=\"ltx_td ltx_align_center\">90.45</td>\n<td id=\"S4.T1.1.1.3.2.10\" class=\"ltx_td ltx_align_center\">94.25</td>\n<td id=\"S4.T1.1.1.3.2.11\" class=\"ltx_td ltx_align_center\">95</td>\n<td id=\"S4.T1.1.1.3.2.12\" class=\"ltx_td ltx_align_center\">91.65</td>\n<td id=\"S4.T1.1.1.3.2.13\" class=\"ltx_td ltx_align_center\">76.85</td>\n</tr>\n<tr id=\"S4.T1.1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.4.3.1\" class=\"ltx_td ltx_align_center\">P-tuning v2</td>\n<td id=\"S4.T1.1.1.4.3.2\" class=\"ltx_td ltx_align_center\" style=\"background-color:#8C8C8C;\"><span id=\"S4.T1.1.1.4.3.2.1\" class=\"ltx_text\" style=\"background-color:#8C8C8C;\">6.3M</span></td>\n<td id=\"S4.T1.1.1.4.3.3\" class=\"ltx_td ltx_align_center\">85.19</td>\n<td id=\"S4.T1.1.1.4.3.4\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.1.1.4.3.4.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">95.3</span></td>\n<td id=\"S4.T1.1.1.4.3.5\" class=\"ltx_td ltx_align_center\">41.82</td>\n<td id=\"S4.T1.1.1.4.3.6\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.1.1.4.3.6.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">82.78</span></td>\n<td id=\"S4.T1.1.1.4.3.7\" class=\"ltx_td ltx_align_center\">79.42</td>\n<td id=\"S4.T1.1.1.4.3.8\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.1.1.4.3.8.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">79.66</span></td>\n<td id=\"S4.T1.1.1.4.3.9\" class=\"ltx_td ltx_align_center\">91</td>\n<td id=\"S4.T1.1.1.4.3.10\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.1.1.4.3.10.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">96.9</span></td>\n<td id=\"S4.T1.1.1.4.3.11\" class=\"ltx_td ltx_align_center\">96.4</td>\n<td id=\"S4.T1.1.1.4.3.12\" class=\"ltx_td ltx_align_center\">91.45</td>\n<td id=\"S4.T1.1.1.4.3.13\" class=\"ltx_td ltx_align_center\">82.05</td>\n</tr>\n<tr id=\"S4.T1.1.1.5.4\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.5.4.1\" class=\"ltx_td ltx_align_center\">Prompt Tuning</td>\n<td id=\"S4.T1.1.1.5.4.2\" class=\"ltx_td ltx_align_center\" style=\"background-color:#F2F2F2;\"><span id=\"S4.T1.1.1.5.4.2.1\" class=\"ltx_text\" style=\"background-color:#F2F2F2;\">20K</span></td>\n<td id=\"S4.T1.1.1.5.4.3\" class=\"ltx_td ltx_align_center\">51.62</td>\n<td id=\"S4.T1.1.1.5.4.4\" class=\"ltx_td ltx_align_center\">61.01</td>\n<td id=\"S4.T1.1.1.5.4.5\" class=\"ltx_td ltx_align_center\">3.36</td>\n<td id=\"S4.T1.1.1.5.4.6\" class=\"ltx_td ltx_align_center\">48.04</td>\n<td id=\"S4.T1.1.1.5.4.7\" class=\"ltx_td ltx_align_center\">52.35</td>\n<td id=\"S4.T1.1.1.5.4.8\" class=\"ltx_td ltx_align_center\">59.72</td>\n<td id=\"S4.T1.1.1.5.4.9\" class=\"ltx_td ltx_align_center\">81.65</td>\n<td id=\"S4.T1.1.1.5.4.10\" class=\"ltx_td ltx_align_center\">65.2</td>\n<td id=\"S4.T1.1.1.5.4.11\" class=\"ltx_td ltx_align_center\">36.4</td>\n<td id=\"S4.T1.1.1.5.4.12\" class=\"ltx_td ltx_align_center\">63.25</td>\n<td id=\"S4.T1.1.1.5.4.13\" class=\"ltx_td ltx_align_center\">42.56</td>\n</tr>\n<tr id=\"S4.T1.1.1.6.5\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.6.5.1\" class=\"ltx_td ltx_align_center\">IDPG</td>\n<td id=\"S4.T1.1.1.6.5.2\" class=\"ltx_td ltx_align_center\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T1.1.1.6.5.2.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">137K</span></td>\n<td id=\"S4.T1.1.1.6.5.3\" class=\"ltx_td ltx_align_center\">72.2</td>\n<td id=\"S4.T1.1.1.6.5.4\" class=\"ltx_td ltx_align_center\">93.01</td>\n<td id=\"S4.T1.1.1.6.5.5\" class=\"ltx_td ltx_align_center\">4.59</td>\n<td id=\"S4.T1.1.1.6.5.6\" class=\"ltx_td ltx_align_center\">70.83</td>\n<td id=\"S4.T1.1.1.6.5.7\" class=\"ltx_td ltx_align_center\">70.4</td>\n<td id=\"S4.T1.1.1.6.5.8\" class=\"ltx_td ltx_align_center\">71.96</td>\n<td id=\"S4.T1.1.1.6.5.9\" class=\"ltx_td ltx_align_center\">90.07</td>\n<td id=\"S4.T1.1.1.6.5.10\" class=\"ltx_td ltx_align_center\">94</td>\n<td id=\"S4.T1.1.1.6.5.11\" class=\"ltx_td ltx_align_center\">78.4</td>\n<td id=\"S4.T1.1.1.6.5.12\" class=\"ltx_td ltx_align_center\">91.4</td>\n<td id=\"S4.T1.1.1.6.5.13\" class=\"ltx_td ltx_align_center\">60.63</td>\n</tr>\n<tr id=\"S4.T1.1.1.7.6\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.7.6.1\" class=\"ltx_td ltx_align_center\">ATTEMPT</td>\n<td id=\"S4.T1.1.1.7.6.2\" class=\"ltx_td ltx_align_center\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T1.1.1.7.6.2.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">207k</span></td>\n<td id=\"S4.T1.1.1.7.6.3\" class=\"ltx_td ltx_align_center\">54.93</td>\n<td id=\"S4.T1.1.1.7.6.4\" class=\"ltx_td ltx_align_center\">85.89</td>\n<td id=\"S4.T1.1.1.7.6.5\" class=\"ltx_td ltx_align_center\">4.63</td>\n<td id=\"S4.T1.1.1.7.6.6\" class=\"ltx_td ltx_align_center\">78.65</td>\n<td id=\"S4.T1.1.1.7.6.7\" class=\"ltx_td ltx_align_center\">58.48</td>\n<td id=\"S4.T1.1.1.7.6.8\" class=\"ltx_td ltx_align_center\">73.49</td>\n<td id=\"S4.T1.1.1.7.6.9\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.1.1.7.6.9.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">91.05</span></td>\n<td id=\"S4.T1.1.1.7.6.10\" class=\"ltx_td ltx_align_center\">88.95</td>\n<td id=\"S4.T1.1.1.7.6.11\" class=\"ltx_td ltx_align_center\">82.2</td>\n<td id=\"S4.T1.1.1.7.6.12\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.1.1.7.6.12.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">91.9</span></td>\n<td id=\"S4.T1.1.1.7.6.13\" class=\"ltx_td ltx_align_center\">58.28</td>\n</tr>\n<tr id=\"S4.T1.1.1.8.7\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.8.7.1\" class=\"ltx_td ltx_align_center\">LPT</td>\n<td id=\"S4.T1.1.1.8.7.2\" class=\"ltx_td ltx_align_center\" style=\"background-color:#B3B3B3;\"><span id=\"S4.T1.1.1.8.7.2.1\" class=\"ltx_text\" style=\"background-color:#B3B3B3;\">792k</span></td>\n<td id=\"S4.T1.1.1.8.7.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.1.1.8.7.3.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">89.2</span></td>\n<td id=\"S4.T1.1.1.8.7.4\" class=\"ltx_td ltx_align_center\">94.84</td>\n<td id=\"S4.T1.1.1.8.7.5\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.1.1.8.7.5.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">53.7</span></td>\n<td id=\"S4.T1.1.1.8.7.6\" class=\"ltx_td ltx_align_center\">82.07</td>\n<td id=\"S4.T1.1.1.8.7.7\" class=\"ltx_td ltx_align_center\">79.7</td>\n<td id=\"S4.T1.1.1.8.7.8\" class=\"ltx_td ltx_align_center\">62.7</td>\n<td id=\"S4.T1.1.1.8.7.9\" class=\"ltx_td ltx_align_center\">90.55</td>\n<td id=\"S4.T1.1.1.8.7.10\" class=\"ltx_td ltx_align_center\">96.5</td>\n<td id=\"S4.T1.1.1.8.7.11\" class=\"ltx_td ltx_align_center\">96.4</td>\n<td id=\"S4.T1.1.1.8.7.12\" class=\"ltx_td ltx_align_center\">91.4</td>\n<td id=\"S4.T1.1.1.8.7.13\" class=\"ltx_td ltx_align_center\">82.35</td>\n</tr>\n<tr id=\"S4.T1.1.1.9.8\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.9.8.1\" class=\"ltx_td ltx_align_center\">MomD</td>\n<td id=\"S4.T1.1.1.9.8.2\" class=\"ltx_td ltx_align_center\" style=\"background-color:#8C8C8C;\"><span id=\"S4.T1.1.1.9.8.2.1\" class=\"ltx_text\" style=\"background-color:#8C8C8C;\">6.3M</span></td>\n<td id=\"S4.T1.1.1.9.8.3\" class=\"ltx_td ltx_align_center\">67.42</td>\n<td id=\"S4.T1.1.1.9.8.4\" class=\"ltx_td ltx_align_center\">93.92</td>\n<td id=\"S4.T1.1.1.9.8.5\" class=\"ltx_td ltx_align_center\">1.64</td>\n<td id=\"S4.T1.1.1.9.8.6\" class=\"ltx_td ltx_align_center\">75.17</td>\n<td id=\"S4.T1.1.1.9.8.7\" class=\"ltx_td ltx_align_center\">75.45</td>\n<td id=\"S4.T1.1.1.9.8.8\" class=\"ltx_td ltx_align_center\">62.02</td>\n<td id=\"S4.T1.1.1.9.8.9\" class=\"ltx_td ltx_align_center\">89.05</td>\n<td id=\"S4.T1.1.1.9.8.10\" class=\"ltx_td ltx_align_center\">49.95</td>\n<td id=\"S4.T1.1.1.9.8.11\" class=\"ltx_td ltx_align_center\">38.6</td>\n<td id=\"S4.T1.1.1.9.8.12\" class=\"ltx_td ltx_align_center\">83</td>\n<td id=\"S4.T1.1.1.9.8.13\" class=\"ltx_td ltx_align_center\">63.62</td>\n</tr>\n<tr id=\"S4.T1.1.1.10.9\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.10.9.1\" class=\"ltx_td ltx_align_center\">MomS+AdamD</td>\n<td id=\"S4.T1.1.1.10.9.2\" class=\"ltx_td ltx_align_center\" style=\"background-color:#8C8C8C;\"><span id=\"S4.T1.1.1.10.9.2.1\" class=\"ltx_text\" style=\"background-color:#8C8C8C;\">6.3M</span></td>\n<td id=\"S4.T1.1.1.10.9.3\" class=\"ltx_td ltx_align_center\">87.85</td>\n<td id=\"S4.T1.1.1.10.9.4\" class=\"ltx_td ltx_align_center\">95.18</td>\n<td id=\"S4.T1.1.1.10.9.5\" class=\"ltx_td ltx_align_center\">42.96</td>\n<td id=\"S4.T1.1.1.10.9.6\" class=\"ltx_td ltx_align_center\">80.15</td>\n<td id=\"S4.T1.1.1.10.9.7\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.1.1.10.9.7.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">82.31</span></td>\n<td id=\"S4.T1.1.1.10.9.8\" class=\"ltx_td ltx_align_center\">78.1</td>\n<td id=\"S4.T1.1.1.10.9.9\" class=\"ltx_td ltx_align_center\">90.95</td>\n<td id=\"S4.T1.1.1.10.9.10\" class=\"ltx_td ltx_align_center\">96.75</td>\n<td id=\"S4.T1.1.1.10.9.11\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.1.1.10.9.11.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">96.8</span></td>\n<td id=\"S4.T1.1.1.10.9.12\" class=\"ltx_td ltx_align_center\">91.55</td>\n<td id=\"S4.T1.1.1.10.9.13\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.1.1.10.9.13.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">84.26</span></td>\n</tr>\n<tr id=\"S4.T1.1.1.11.10\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.11.10.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">\n<span id=\"S4.T1.1.1.11.10.1.1\" class=\"ltx_ERROR undefined\">\\hdashline</span>FedPepTAO</td>\n<td id=\"S4.T1.1.1.11.10.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"background-color:#E6E6E6;\"><span id=\"S4.T1.1.1.11.10.2.1\" class=\"ltx_text\" style=\"background-color:#E6E6E6;\">492K</span></td>\n<td id=\"S4.T1.1.1.11.10.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T1.1.1.11.10.3.1\" class=\"ltx_text ltx_font_bold\">89.57</span></td>\n<td id=\"S4.T1.1.1.11.10.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T1.1.1.11.10.4.1\" class=\"ltx_text ltx_font_bold\">95.87</span></td>\n<td id=\"S4.T1.1.1.11.10.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T1.1.1.11.10.5.1\" class=\"ltx_text ltx_font_bold\">56.35</span></td>\n<td id=\"S4.T1.1.1.11.10.6\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T1.1.1.11.10.6.1\" class=\"ltx_text ltx_font_bold\">87.52</span></td>\n<td id=\"S4.T1.1.1.11.10.7\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T1.1.1.11.10.7.1\" class=\"ltx_text ltx_font_bold\">85.56</span></td>\n<td id=\"S4.T1.1.1.11.10.8\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T1.1.1.11.10.8.1\" class=\"ltx_text ltx_font_bold\">79.72</span></td>\n<td id=\"S4.T1.1.1.11.10.9\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T1.1.1.11.10.9.1\" class=\"ltx_text ltx_font_bold\">91.4</span></td>\n<td id=\"S4.T1.1.1.11.10.10\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T1.1.1.11.10.10.1\" class=\"ltx_text ltx_font_bold\">97.1</span></td>\n<td id=\"S4.T1.1.1.11.10.11\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T1.1.1.11.10.11.1\" class=\"ltx_text ltx_font_bold\">97.2</span></td>\n<td id=\"S4.T1.1.1.11.10.12\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T1.1.1.11.10.12.1\" class=\"ltx_text ltx_font_bold\">93</span></td>\n<td id=\"S4.T1.1.1.11.10.13\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T1.1.1.11.10.13.1\" class=\"ltx_text ltx_font_bold\">86.4</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "As shown in Table 1, FedPepTAO significantly outperforms baseline methods in terms of the best accuracy (up to 25.39%, 23.83%, 14.53%, 60.8%, 51.76%, 51.72%, 17.02%, 54.71%, 13.39% compared with Adapter, FedPrompt, P-tuning v2, Ptompt Tuning, IDPG, ATTEMPT, LTP, MomD, and MomS+AdamD, respectively). In addition, the average of the best accuracy (average accuracy) for each task is shown in the last column. The advantage of FedPepTAO is obvious in terms of the average accuracy as well, i.e., 11.04%, 9.55%, 4.35%, 43.84%, 25.77%, 28.12%, 4.05%, 58.6%, 13.39%, higher compared with Adapter, FedPrompt, P-tuning v2, Ptompt Tuning, IDPG, ATTEMPT, LTP, MomD, and MomS+AdamD, respectively. Although FedPrompt, Prompt Tuning, IDPG, and ATTEMPT exploit fewer parameters, the corresponding accuracy is inferior. FedPrompt, Prompt Tuning, and ATTEMPT only update the soft prompt for the first layer, which cannot optimize other important layers and incurs sub-optimal performance. IDPG shares a single generator for each layer, which cannot address the characteristics of diverse layers and leads to inferior accuracy. Different from these methods, FedPepTAO can well optimize the prompt parameters for each layer based on P-tuning v2, while choosing the proper layers for aggregation within FL so as to achieve excellent performance. In addition, we exploit the adaptive optimization on both server and device sides to achieve superb accuracy. Compared with Adapter (93.4%), P-tuning v2 (92.19%), and LPT (37.98%), our methods can well reduce the number of parameters to transfer between devices and the server because of the proper layer selection, which corresponds to smaller communication costs. As a result, the efficiency of FedPepTAO is significantly higher than baseline approaches (up to 95.91%, 95.17%, 92.76%, 99%, 97.28%, 97.59%, 85.8%, 94.23%, 80.48%, faster compared with Adapter, FedPrompt, P-tuning v2, Ptompt Tuning, IDPG, ATTEMPT, LTP, MomD, and MomS+AdamD, respectively).",
            "The number of global training epochs is set to 100 and that of local training epochs is set to 2. We utilize the Dirichlet distribution (with 1.0 as the concentration parameter alpha) to partition the data into non-IID splits and assign a certain number of samples to each device according to the Dirichlet distribution (with 5.0 as the concentration parameter alpha). We exploit development sets for the evaluation of tasks in the GLUE benchmark since test sets are not labeled. For 4 other datasets, we select a certain number of samples from the training set as the development set, and the number of samples for each label is determined according to its proportion in the original training set. For datasets in GLUE benchmark (Wang et al., 2019), we use their original data splits. For 4 other datasets with no default splits, we randomly divide the dataset into train, development, and test sets. The dataset statistics after the split are shown in Table 13",
            "We notice an inverse correlation between the performance of our Parameter-efficient Prompt Tuning (PEPT) method and the average sentence length of the three datasets. Specifically, PEPT tends to achieve a smaller performance gain on the datasets with longer average sentence length, as shown in Table 14."
        ]
    },
    "S5.T2": {
        "caption": "Table 2: The tuning time (s) to achieve a target accuracy (85% for QNLI, 92.5% for SST-2, 3% for CoLA, 77% for MRPC, 65% for RTE, 71% for BoolQ, 85% for MPQA, 88% for Subj, 78% for Trec, 91% for MR)with FedPepTAO and diverse baseline approaches. \"/\" represents that training does not achieve the target accuracy. The best results are highlighted in bold and the second bests are marked with underline. All the results are obtained using RoBERTaLARGE.",
        "table": "<table id=\"S5.T2.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T2.1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S5.T2.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></td>\n<td id=\"S5.T2.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S5.T2.1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">QNLI</span></td>\n<td id=\"S5.T2.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S5.T2.1.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">SST-2</span></td>\n<td id=\"S5.T2.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S5.T2.1.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">CoLA</span></td>\n<td id=\"S5.T2.1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S5.T2.1.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">MPRC</span></td>\n<td id=\"S5.T2.1.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S5.T2.1.1.1.1.6.1\" class=\"ltx_text ltx_font_bold\">RTE</span></td>\n<td id=\"S5.T2.1.1.1.1.7\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S5.T2.1.1.1.1.7.1\" class=\"ltx_text ltx_font_bold\">BoolQ</span></td>\n<td id=\"S5.T2.1.1.1.1.8\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S5.T2.1.1.1.1.8.1\" class=\"ltx_text ltx_font_bold\">MPQA</span></td>\n<td id=\"S5.T2.1.1.1.1.9\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S5.T2.1.1.1.1.9.1\" class=\"ltx_text ltx_font_bold\">Subj</span></td>\n<td id=\"S5.T2.1.1.1.1.10\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S5.T2.1.1.1.1.10.1\" class=\"ltx_text ltx_font_bold\">Trec</span></td>\n<td id=\"S5.T2.1.1.1.1.11\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S5.T2.1.1.1.1.11.1\" class=\"ltx_text ltx_font_bold\">MR</span></td>\n</tr>\n<tr id=\"S5.T2.1.1.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\">Adapter</td>\n<td id=\"S5.T2.1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">8096</td>\n<td id=\"S5.T2.1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">1065</td>\n<td id=\"S5.T2.1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">2655</td>\n<td id=\"S5.T2.1.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\">/</td>\n<td id=\"S5.T2.1.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\">2218</td>\n<td id=\"S5.T2.1.1.2.2.7\" class=\"ltx_td ltx_align_center ltx_border_t\">937</td>\n<td id=\"S5.T2.1.1.2.2.8\" class=\"ltx_td ltx_align_center ltx_border_t\">758</td>\n<td id=\"S5.T2.1.1.2.2.9\" class=\"ltx_td ltx_align_center ltx_border_t\">1178</td>\n<td id=\"S5.T2.1.1.2.2.10\" class=\"ltx_td ltx_align_center ltx_border_t\">1388</td>\n<td id=\"S5.T2.1.1.2.2.11\" class=\"ltx_td ltx_align_center ltx_border_t\">1797</td>\n</tr>\n<tr id=\"S5.T2.1.1.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.3.3.1\" class=\"ltx_td ltx_align_center\">FedPrompt</td>\n<td id=\"S5.T2.1.1.3.3.2\" class=\"ltx_td ltx_align_center\">12987</td>\n<td id=\"S5.T2.1.1.3.3.3\" class=\"ltx_td ltx_align_center\">668</td>\n<td id=\"S5.T2.1.1.3.3.4\" class=\"ltx_td ltx_align_center\">1471</td>\n<td id=\"S5.T2.1.1.3.3.5\" class=\"ltx_td ltx_align_center\">1824</td>\n<td id=\"S5.T2.1.1.3.3.6\" class=\"ltx_td ltx_align_center\">/</td>\n<td id=\"S5.T2.1.1.3.3.7\" class=\"ltx_td ltx_align_center\">1485</td>\n<td id=\"S5.T2.1.1.3.3.8\" class=\"ltx_td ltx_align_center\">412</td>\n<td id=\"S5.T2.1.1.3.3.9\" class=\"ltx_td ltx_align_center\">1284</td>\n<td id=\"S5.T2.1.1.3.3.10\" class=\"ltx_td ltx_align_center\">336</td>\n<td id=\"S5.T2.1.1.3.3.11\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.1.1.3.3.11.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">618</span></td>\n</tr>\n<tr id=\"S5.T2.1.1.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.4.4.1\" class=\"ltx_td ltx_align_center\">P-tuning v2</td>\n<td id=\"S5.T2.1.1.4.4.2\" class=\"ltx_td ltx_align_center\">10780</td>\n<td id=\"S5.T2.1.1.4.4.3\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.1.1.4.4.3.1\" class=\"ltx_text ltx_font_bold\">17</span></td>\n<td id=\"S5.T2.1.1.4.4.4\" class=\"ltx_td ltx_align_center\">489</td>\n<td id=\"S5.T2.1.1.4.4.5\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.1.1.4.4.5.1\" class=\"ltx_text ltx_font_bold\">154</span></td>\n<td id=\"S5.T2.1.1.4.4.6\" class=\"ltx_td ltx_align_center\">201</td>\n<td id=\"S5.T2.1.1.4.4.7\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.1.1.4.4.7.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">135</span></td>\n<td id=\"S5.T2.1.1.4.4.8\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.1.1.4.4.8.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">105</span></td>\n<td id=\"S5.T2.1.1.4.4.9\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.1.1.4.4.9.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">132</span></td>\n<td id=\"S5.T2.1.1.4.4.10\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.1.1.4.4.10.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">95</span></td>\n<td id=\"S5.T2.1.1.4.4.11\" class=\"ltx_td ltx_align_center\">748</td>\n</tr>\n<tr id=\"S5.T2.1.1.5.5\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.5.5.1\" class=\"ltx_td ltx_align_center\">Prompt Tuning</td>\n<td id=\"S5.T2.1.1.5.5.2\" class=\"ltx_td ltx_align_center\">/</td>\n<td id=\"S5.T2.1.1.5.5.3\" class=\"ltx_td ltx_align_center\">/</td>\n<td id=\"S5.T2.1.1.5.5.4\" class=\"ltx_td ltx_align_center\">/</td>\n<td id=\"S5.T2.1.1.5.5.5\" class=\"ltx_td ltx_align_center\">/</td>\n<td id=\"S5.T2.1.1.5.5.6\" class=\"ltx_td ltx_align_center\">/</td>\n<td id=\"S5.T2.1.1.5.5.7\" class=\"ltx_td ltx_align_center\">/</td>\n<td id=\"S5.T2.1.1.5.5.8\" class=\"ltx_td ltx_align_center\">/</td>\n<td id=\"S5.T2.1.1.5.5.9\" class=\"ltx_td ltx_align_center\">/</td>\n<td id=\"S5.T2.1.1.5.5.10\" class=\"ltx_td ltx_align_center\">/</td>\n<td id=\"S5.T2.1.1.5.5.11\" class=\"ltx_td ltx_align_center\">/</td>\n</tr>\n<tr id=\"S5.T2.1.1.6.6\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.6.6.1\" class=\"ltx_td ltx_align_center\">IDPG</td>\n<td id=\"S5.T2.1.1.6.6.2\" class=\"ltx_td ltx_align_center\">/</td>\n<td id=\"S5.T2.1.1.6.6.3\" class=\"ltx_td ltx_align_center\">3322</td>\n<td id=\"S5.T2.1.1.6.6.4\" class=\"ltx_td ltx_align_center\">/</td>\n<td id=\"S5.T2.1.1.6.6.5\" class=\"ltx_td ltx_align_center\">/</td>\n<td id=\"S5.T2.1.1.6.6.6\" class=\"ltx_td ltx_align_center\">689</td>\n<td id=\"S5.T2.1.1.6.6.7\" class=\"ltx_td ltx_align_center\">3254</td>\n<td id=\"S5.T2.1.1.6.6.8\" class=\"ltx_td ltx_align_center\">908</td>\n<td id=\"S5.T2.1.1.6.6.9\" class=\"ltx_td ltx_align_center\">1347</td>\n<td id=\"S5.T2.1.1.6.6.10\" class=\"ltx_td ltx_align_center\">1220</td>\n<td id=\"S5.T2.1.1.6.6.11\" class=\"ltx_td ltx_align_center\">1912</td>\n</tr>\n<tr id=\"S5.T2.1.1.7.7\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.7.7.1\" class=\"ltx_td ltx_align_center\">ATTEMPT</td>\n<td id=\"S5.T2.1.1.7.7.2\" class=\"ltx_td ltx_align_center\">/</td>\n<td id=\"S5.T2.1.1.7.7.3\" class=\"ltx_td ltx_align_center\">/</td>\n<td id=\"S5.T2.1.1.7.7.4\" class=\"ltx_td ltx_align_center\">/</td>\n<td id=\"S5.T2.1.1.7.7.5\" class=\"ltx_td ltx_align_center\">1774</td>\n<td id=\"S5.T2.1.1.7.7.6\" class=\"ltx_td ltx_align_center\">/</td>\n<td id=\"S5.T2.1.1.7.7.7\" class=\"ltx_td ltx_align_center\">973</td>\n<td id=\"S5.T2.1.1.7.7.8\" class=\"ltx_td ltx_align_center\">438</td>\n<td id=\"S5.T2.1.1.7.7.9\" class=\"ltx_td ltx_align_center\">2573</td>\n<td id=\"S5.T2.1.1.7.7.10\" class=\"ltx_td ltx_align_center\">1028</td>\n<td id=\"S5.T2.1.1.7.7.11\" class=\"ltx_td ltx_align_center\">1221</td>\n</tr>\n<tr id=\"S5.T2.1.1.8.8\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.8.8.1\" class=\"ltx_td ltx_align_center\">LPT</td>\n<td id=\"S5.T2.1.1.8.8.2\" class=\"ltx_td ltx_align_center\">2918</td>\n<td id=\"S5.T2.1.1.8.8.3\" class=\"ltx_td ltx_align_center\">650</td>\n<td id=\"S5.T2.1.1.8.8.4\" class=\"ltx_td ltx_align_center\">733</td>\n<td id=\"S5.T2.1.1.8.8.5\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.1.1.8.8.5.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">156</span></td>\n<td id=\"S5.T2.1.1.8.8.6\" class=\"ltx_td ltx_align_center\">270</td>\n<td id=\"S5.T2.1.1.8.8.7\" class=\"ltx_td ltx_align_center\">/</td>\n<td id=\"S5.T2.1.1.8.8.8\" class=\"ltx_td ltx_align_center\">162</td>\n<td id=\"S5.T2.1.1.8.8.9\" class=\"ltx_td ltx_align_center\">155</td>\n<td id=\"S5.T2.1.1.8.8.10\" class=\"ltx_td ltx_align_center\">112</td>\n<td id=\"S5.T2.1.1.8.8.11\" class=\"ltx_td ltx_align_center\">860</td>\n</tr>\n<tr id=\"S5.T2.1.1.9.9\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.9.9.1\" class=\"ltx_td ltx_align_center\">MomD</td>\n<td id=\"S5.T2.1.1.9.9.2\" class=\"ltx_td ltx_align_center\">/</td>\n<td id=\"S5.T2.1.1.9.9.3\" class=\"ltx_td ltx_align_center\">1328</td>\n<td id=\"S5.T2.1.1.9.9.4\" class=\"ltx_td ltx_align_center\">/</td>\n<td id=\"S5.T2.1.1.9.9.5\" class=\"ltx_td ltx_align_center\">/</td>\n<td id=\"S5.T2.1.1.9.9.6\" class=\"ltx_td ltx_align_center\">838</td>\n<td id=\"S5.T2.1.1.9.9.7\" class=\"ltx_td ltx_align_center\">/</td>\n<td id=\"S5.T2.1.1.9.9.8\" class=\"ltx_td ltx_align_center\">537</td>\n<td id=\"S5.T2.1.1.9.9.9\" class=\"ltx_td ltx_align_center\">/</td>\n<td id=\"S5.T2.1.1.9.9.10\" class=\"ltx_td ltx_align_center\">/</td>\n<td id=\"S5.T2.1.1.9.9.11\" class=\"ltx_td ltx_align_center\">/</td>\n</tr>\n<tr id=\"S5.T2.1.1.10.10\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.10.10.1\" class=\"ltx_td ltx_align_center\">MomS+AdamD</td>\n<td id=\"S5.T2.1.1.10.10.2\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.1.1.10.10.2.1\" class=\"ltx_text ltx_font_bold\">697</span></td>\n<td id=\"S5.T2.1.1.10.10.3\" class=\"ltx_td ltx_align_center\">209</td>\n<td id=\"S5.T2.1.1.10.10.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.1.1.10.10.4.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">488</span></td>\n<td id=\"S5.T2.1.1.10.10.5\" class=\"ltx_td ltx_align_center\">1178</td>\n<td id=\"S5.T2.1.1.10.10.6\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.1.1.10.10.6.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">192</span></td>\n<td id=\"S5.T2.1.1.10.10.7\" class=\"ltx_td ltx_align_center\">139</td>\n<td id=\"S5.T2.1.1.10.10.8\" class=\"ltx_td ltx_align_center\">141</td>\n<td id=\"S5.T2.1.1.10.10.9\" class=\"ltx_td ltx_align_center\">166</td>\n<td id=\"S5.T2.1.1.10.10.10\" class=\"ltx_td ltx_align_center\">100</td>\n<td id=\"S5.T2.1.1.10.10.11\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T2.1.1.10.10.11.1\" class=\"ltx_text ltx_font_bold\">610</span></td>\n</tr>\n<tr id=\"S5.T2.1.1.11.11\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.11.11.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">\n<span id=\"S5.T2.1.1.11.11.1.1\" class=\"ltx_ERROR undefined\">\\hdashline</span>FedPepTAO</td>\n<td id=\"S5.T2.1.1.11.11.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T2.1.1.11.11.2.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">781</span></td>\n<td id=\"S5.T2.1.1.11.11.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T2.1.1.11.11.3.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">97</span></td>\n<td id=\"S5.T2.1.1.11.11.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T2.1.1.11.11.4.1\" class=\"ltx_text ltx_font_bold\">219</span></td>\n<td id=\"S5.T2.1.1.11.11.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">230</td>\n<td id=\"S5.T2.1.1.11.11.6\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T2.1.1.11.11.6.1\" class=\"ltx_text ltx_font_bold\">186</span></td>\n<td id=\"S5.T2.1.1.11.11.7\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T2.1.1.11.11.7.1\" class=\"ltx_text ltx_font_bold\">129</span></td>\n<td id=\"S5.T2.1.1.11.11.8\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T2.1.1.11.11.8.1\" class=\"ltx_text ltx_font_bold\">31</span></td>\n<td id=\"S5.T2.1.1.11.11.9\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T2.1.1.11.11.9.1\" class=\"ltx_text ltx_font_bold\">62</span></td>\n<td id=\"S5.T2.1.1.11.11.10\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T2.1.1.11.11.10.1\" class=\"ltx_text ltx_font_bold\">76</span></td>\n<td id=\"S5.T2.1.1.11.11.11\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T2.1.1.11.11.11.1\" class=\"ltx_text ltx_font_bold\">610</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "As shown in Table ",
                "1",
                ", FedPepTAO significantly outperforms baseline methods in terms of the best accuracy (up to 25.39%, 23.83%, 14.53%, 60.8%, 51.76%, 51.72%, 17.02%, 54.71%, 13.39% compared with Adapter, FedPrompt, P-tuning v2, Ptompt Tuning, IDPG, ATTEMPT, LTP, MomD, and MomS+AdamD, respectively). In addition, the average of the best accuracy (average accuracy) for each task is shown in the last column. The advantage of FedPepTAO is obvious in terms of the average accuracy as well, i.e., 11.04%, 9.55%, 4.35%, 43.84%, 25.77%, 28.12%, 4.05%, 58.6%, 13.39%, higher compared with Adapter, FedPrompt, P-tuning v2, Ptompt Tuning, IDPG, ATTEMPT, LTP, MomD, and MomS+AdamD, respectively. Although FedPrompt, Prompt Tuning, IDPG, and ATTEMPT exploit fewer parameters, the corresponding accuracy is inferior. FedPrompt, Prompt Tuning, and ATTEMPT only update the soft prompt for the first layer, which cannot optimize other important layers and incurs sub-optimal performance. IDPG shares a single generator for each layer, which cannot address the characteristics of diverse layers and leads to inferior accuracy. Different from these methods, FedPepTAO can well optimize the prompt parameters for each layer based on P-tuning v2, while choosing the proper layers for aggregation within FL so as to achieve excellent performance. In addition, we exploit the adaptive optimization on both server and device sides to achieve superb accuracy. Compared with Adapter (93.4%), P-tuning v2 (92.19%), and LPT (37.98%), our methods can well reduce the number of parameters to transfer between devices and the server because of the proper layer selection, which corresponds to smaller communication costs. As a result, the efficiency of FedPepTAO is significantly higher than baseline approaches (up to 95.91%, 95.17%, 92.76%, 99%, 97.28%, 97.59%, 85.8%, 94.23%, 80.48%, faster compared with Adapter, FedPrompt, P-tuning v2, Ptompt Tuning, IDPG, ATTEMPT, LTP, MomD, and MomS+AdamD, respectively)."
            ]
        ]
    },
    "S5.T3": {
        "caption": "Table 3: Accuracy and tuning time (s) to achieve target accuracy (75% for MRPC, 81% for MR, and 92.5% for SST-2) on GPT2LARGE model. \"/\" represents that training does not achieve the target accuracy.",
        "table": "<table id=\"S5.T3.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T3.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" rowspan=\"2\"><span id=\"S5.T3.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></th>\n<th id=\"S5.T3.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><span id=\"S5.T3.1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">MRPC</span></th>\n<th id=\"S5.T3.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><span id=\"S5.T3.1.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">MR</span></th>\n<th id=\"S5.T3.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><span id=\"S5.T3.1.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">SST-2</span></th>\n</tr>\n<tr id=\"S5.T3.1.1.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T3.1.1.2.2.1.1\" class=\"ltx_text ltx_font_bold\">Acc</span></th>\n<th id=\"S5.T3.1.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T3.1.1.2.2.2.1\" class=\"ltx_text ltx_font_bold\">Time</span></th>\n<th id=\"S5.T3.1.1.2.2.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T3.1.1.2.2.3.1\" class=\"ltx_text ltx_font_bold\">Acc</span></th>\n<th id=\"S5.T3.1.1.2.2.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T3.1.1.2.2.4.1\" class=\"ltx_text ltx_font_bold\">Time</span></th>\n<th id=\"S5.T3.1.1.2.2.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T3.1.1.2.2.5.1\" class=\"ltx_text ltx_font_bold\">Acc</span></th>\n<th id=\"S5.T3.1.1.2.2.6\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T3.1.1.2.2.6.1\" class=\"ltx_text ltx_font_bold\">Time</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T3.1.1.3.1\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.1.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">FedPrompt</th>\n<td id=\"S5.T3.1.1.3.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">74.98</td>\n<td id=\"S5.T3.1.1.3.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">/</td>\n<td id=\"S5.T3.1.1.3.1.4\" class=\"ltx_td ltx_align_left ltx_border_t\">57.2</td>\n<td id=\"S5.T3.1.1.3.1.5\" class=\"ltx_td ltx_align_left ltx_border_t\">/</td>\n<td id=\"S5.T3.1.1.3.1.6\" class=\"ltx_td ltx_align_left ltx_border_t\">76.49</td>\n<td id=\"S5.T3.1.1.3.1.7\" class=\"ltx_td ltx_align_left ltx_border_t\">/</td>\n</tr>\n<tr id=\"S5.T3.1.1.4.2\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.1.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">P-tuning v2</th>\n<td id=\"S5.T3.1.1.4.2.2\" class=\"ltx_td ltx_align_left\">74.8</td>\n<td id=\"S5.T3.1.1.4.2.3\" class=\"ltx_td ltx_align_left\">/</td>\n<td id=\"S5.T3.1.1.4.2.4\" class=\"ltx_td ltx_align_left\">73</td>\n<td id=\"S5.T3.1.1.4.2.5\" class=\"ltx_td ltx_align_left\">/</td>\n<td id=\"S5.T3.1.1.4.2.6\" class=\"ltx_td ltx_align_left\">74.77</td>\n<td id=\"S5.T3.1.1.4.2.7\" class=\"ltx_td ltx_align_left\">/</td>\n</tr>\n<tr id=\"S5.T3.1.1.5.3\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.1.5.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">ATTEMPT</th>\n<td id=\"S5.T3.1.1.5.3.2\" class=\"ltx_td ltx_align_left\">37.91</td>\n<td id=\"S5.T3.1.1.5.3.3\" class=\"ltx_td ltx_align_left\">/</td>\n<td id=\"S5.T3.1.1.5.3.4\" class=\"ltx_td ltx_align_left\">57.3</td>\n<td id=\"S5.T3.1.1.5.3.5\" class=\"ltx_td ltx_align_left\">/</td>\n<td id=\"S5.T3.1.1.5.3.6\" class=\"ltx_td ltx_align_left\">85.89</td>\n<td id=\"S5.T3.1.1.5.3.7\" class=\"ltx_td ltx_align_left\">/</td>\n</tr>\n<tr id=\"S5.T3.1.1.6.4\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.1.6.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">LPT</th>\n<td id=\"S5.T3.1.1.6.4.2\" class=\"ltx_td ltx_align_left\">74.98</td>\n<td id=\"S5.T3.1.1.6.4.3\" class=\"ltx_td ltx_align_left\">/</td>\n<td id=\"S5.T3.1.1.6.4.4\" class=\"ltx_td ltx_align_left\">84.8</td>\n<td id=\"S5.T3.1.1.6.4.5\" class=\"ltx_td ltx_align_left\">1455</td>\n<td id=\"S5.T3.1.1.6.4.6\" class=\"ltx_td ltx_align_left\">77.06</td>\n<td id=\"S5.T3.1.1.6.4.7\" class=\"ltx_td ltx_align_left\">/</td>\n</tr>\n<tr id=\"S5.T3.1.1.7.5\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.1.7.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">MomD</th>\n<td id=\"S5.T3.1.1.7.5.2\" class=\"ltx_td ltx_align_left\">77.23</td>\n<td id=\"S5.T3.1.1.7.5.3\" class=\"ltx_td ltx_align_left\">503</td>\n<td id=\"S5.T3.1.1.7.5.4\" class=\"ltx_td ltx_align_left\">85.7</td>\n<td id=\"S5.T3.1.1.7.5.5\" class=\"ltx_td ltx_align_left\">1694</td>\n<td id=\"S5.T3.1.1.7.5.6\" class=\"ltx_td ltx_align_left\">92.55</td>\n<td id=\"S5.T3.1.1.7.5.7\" class=\"ltx_td ltx_align_left\">3638</td>\n</tr>\n<tr id=\"S5.T3.1.1.8.6\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.1.8.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">MomS+AdamD</th>\n<td id=\"S5.T3.1.1.8.6.2\" class=\"ltx_td ltx_align_left\">76.89</td>\n<td id=\"S5.T3.1.1.8.6.3\" class=\"ltx_td ltx_align_left\">291</td>\n<td id=\"S5.T3.1.1.8.6.4\" class=\"ltx_td ltx_align_left\">88.2</td>\n<td id=\"S5.T3.1.1.8.6.5\" class=\"ltx_td ltx_align_left\">262</td>\n<td id=\"S5.T3.1.1.8.6.6\" class=\"ltx_td ltx_align_left\">92.55</td>\n<td id=\"S5.T3.1.1.8.6.7\" class=\"ltx_td ltx_align_left\">2488</td>\n</tr>\n<tr id=\"S5.T3.1.1.9.7\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.1.9.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">\n<span id=\"S5.T3.1.1.9.7.1.1\" class=\"ltx_ERROR undefined\">\\hdashline</span>FedPepTAO</th>\n<td id=\"S5.T3.1.1.9.7.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">81.23</td>\n<td id=\"S5.T3.1.1.9.7.3\" class=\"ltx_td ltx_align_left ltx_border_bb\">273</td>\n<td id=\"S5.T3.1.1.9.7.4\" class=\"ltx_td ltx_align_left ltx_border_bb\">89.5</td>\n<td id=\"S5.T3.1.1.9.7.5\" class=\"ltx_td ltx_align_left ltx_border_bb\">222</td>\n<td id=\"S5.T3.1.1.9.7.6\" class=\"ltx_td ltx_align_left ltx_border_bb\">93</td>\n<td id=\"S5.T3.1.1.9.7.7\" class=\"ltx_td ltx_align_left ltx_border_bb\">2248</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "As shown in Table 3 below, FedPepTAO significantly outperforms baseline methods in terms of the best accuracy on the decoder-based GPT2LARGE model (up to 32.3%, 18.23%, 43.32%, 15.94%, 4%, 4.34% higher compared to FedPrompt, P-tuning v2, ATTEMPT, LPT, MomD and MomS+AdamD, respectively). Furthermore, the efficiency of FedPepTAO is significantly higher than baseline approaches (up to 84.74%, 86.89%, and 15.27% faster compared to LPT, MomD, and MomS+AdamD, respectively)."
        ]
    },
    "S5.T4": {
        "caption": "Table 4: Accuracy and tuning time (s) to achieve target accuracy (75% for RTE, 81% for MRPC) on LLaMA 3B model. \"/\" represents that training does not achieve the target accuracy.",
        "table": "<table id=\"S5.T4.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T4.1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_tt\" rowspan=\"2\"><span id=\"S5.T4.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></td>\n<td id=\"S5.T4.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\"><span id=\"S5.T4.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">RTE</span></td>\n<td id=\"S5.T4.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\"><span id=\"S5.T4.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">MRPC</span></td>\n</tr>\n<tr id=\"S5.T4.1.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S5.T4.1.2.2.1.1\" class=\"ltx_text ltx_font_bold\">Acc</span></td>\n<td id=\"S5.T4.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S5.T4.1.2.2.2.1\" class=\"ltx_text ltx_font_bold\">Time</span></td>\n<td id=\"S5.T4.1.2.2.3\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S5.T4.1.2.2.3.1\" class=\"ltx_text ltx_font_bold\">Acc</span></td>\n<td id=\"S5.T4.1.2.2.4\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S5.T4.1.2.2.4.1\" class=\"ltx_text ltx_font_bold\">Time</span></td>\n</tr>\n<tr id=\"S5.T4.1.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">FedPrompt</td>\n<td id=\"S5.T4.1.3.3.2\" class=\"ltx_td ltx_align_left ltx_border_t\">78.34</td>\n<td id=\"S5.T4.1.3.3.3\" class=\"ltx_td ltx_align_left ltx_border_t\">540</td>\n<td id=\"S5.T4.1.3.3.4\" class=\"ltx_td ltx_align_left ltx_border_t\">81.86</td>\n<td id=\"S5.T4.1.3.3.5\" class=\"ltx_td ltx_align_left ltx_border_t\">459</td>\n</tr>\n<tr id=\"S5.T4.1.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.4.4.1\" class=\"ltx_td ltx_align_left\">P-tuning v2</td>\n<td id=\"S5.T4.1.4.4.2\" class=\"ltx_td ltx_align_left\">56.68</td>\n<td id=\"S5.T4.1.4.4.3\" class=\"ltx_td ltx_align_left\">/</td>\n<td id=\"S5.T4.1.4.4.4\" class=\"ltx_td ltx_align_left\">75.17</td>\n<td id=\"S5.T4.1.4.4.5\" class=\"ltx_td ltx_align_left\">/</td>\n</tr>\n<tr id=\"S5.T4.1.5.5\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.5.5.1\" class=\"ltx_td ltx_align_left\">ATTEMPT</td>\n<td id=\"S5.T4.1.5.5.2\" class=\"ltx_td ltx_align_left\">64.98</td>\n<td id=\"S5.T4.1.5.5.3\" class=\"ltx_td ltx_align_left\">/</td>\n<td id=\"S5.T4.1.5.5.4\" class=\"ltx_td ltx_align_left\">81.18</td>\n<td id=\"S5.T4.1.5.5.5\" class=\"ltx_td ltx_align_left\">718</td>\n</tr>\n<tr id=\"S5.T4.1.6.6\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.6.6.1\" class=\"ltx_td ltx_align_left\">LPT</td>\n<td id=\"S5.T4.1.6.6.2\" class=\"ltx_td ltx_align_left\">64.98</td>\n<td id=\"S5.T4.1.6.6.3\" class=\"ltx_td ltx_align_left\">/</td>\n<td id=\"S5.T4.1.6.6.4\" class=\"ltx_td ltx_align_left\">79.77</td>\n<td id=\"S5.T4.1.6.6.5\" class=\"ltx_td ltx_align_left\">789</td>\n</tr>\n<tr id=\"S5.T4.1.7.7\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.7.7.1\" class=\"ltx_td ltx_align_left\">MomD</td>\n<td id=\"S5.T4.1.7.7.2\" class=\"ltx_td ltx_align_left\">80.87</td>\n<td id=\"S5.T4.1.7.7.3\" class=\"ltx_td ltx_align_left\">360</td>\n<td id=\"S5.T4.1.7.7.4\" class=\"ltx_td ltx_align_left\">80.26</td>\n<td id=\"S5.T4.1.7.7.5\" class=\"ltx_td ltx_align_left\">669</td>\n</tr>\n<tr id=\"S5.T4.1.8.8\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.8.8.1\" class=\"ltx_td ltx_align_left\">MomS+AdamD</td>\n<td id=\"S5.T4.1.8.8.2\" class=\"ltx_td ltx_align_left\">80.87</td>\n<td id=\"S5.T4.1.8.8.3\" class=\"ltx_td ltx_align_left\">360</td>\n<td id=\"S5.T4.1.8.8.4\" class=\"ltx_td ltx_align_left\">75.58</td>\n<td id=\"S5.T4.1.8.8.5\" class=\"ltx_td ltx_align_left\">/</td>\n</tr>\n<tr id=\"S5.T4.1.9.9\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.9.9.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">\n<span id=\"S5.T4.1.9.9.1.1\" class=\"ltx_ERROR undefined\">\\hdashline</span>FedPepTAO</td>\n<td id=\"S5.T4.1.9.9.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">83.39</td>\n<td id=\"S5.T4.1.9.9.3\" class=\"ltx_td ltx_align_left ltx_border_bb\">325</td>\n<td id=\"S5.T4.1.9.9.4\" class=\"ltx_td ltx_align_left ltx_border_bb\">86.46</td>\n<td id=\"S5.T4.1.9.9.5\" class=\"ltx_td ltx_align_left ltx_border_bb\">409</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "When the model becomes larger, i.e., LLaMA 3B with 3 billion parameters, FedPepTAO still achieves the best accuracy (up to 4.6%, 11.29%, 5.28%, 6.69%, 6.2%, 10.88% higher compared to FedPrompt, P-tuning v2, ATTEMPT, LPT, MomD and MomS+AdamD, respectively) and better efficiency (up to 39.81%, 43.04%, 48.16%, 38.86%, 9.72% faster compared to FedPrompt, ATTEMPT, LPT, MomD, and MomS+AdamD, respectively) as illustrated in Table 4."
        ]
    },
    "S5.T5": {
        "caption": "Table 5: Accuracy and tuning time (s) to achieve target accuracy (75% for MRPC) on LLaMA 7B model. \"/\" represents that training does not achieve the target accuracy.",
        "table": "<table id=\"S5.T5.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T5.1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_tt\" rowspan=\"2\"><span id=\"S5.T5.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></td>\n<td id=\"S5.T5.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\"><span id=\"S5.T5.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">MRPC</span></td>\n</tr>\n<tr id=\"S5.T5.1.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S5.T5.1.2.2.1.1\" class=\"ltx_text ltx_font_bold\">Acc</span></td>\n<td id=\"S5.T5.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S5.T5.1.2.2.2.1\" class=\"ltx_text ltx_font_bold\">Time</span></td>\n</tr>\n<tr id=\"S5.T5.1.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">FedPrompt</td>\n<td id=\"S5.T5.1.3.3.2\" class=\"ltx_td ltx_align_left ltx_border_t\">76.18</td>\n<td id=\"S5.T5.1.3.3.3\" class=\"ltx_td ltx_align_left ltx_border_t\">/</td>\n</tr>\n<tr id=\"S5.T5.1.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.4.4.1\" class=\"ltx_td ltx_align_left\">P-tuning v2</td>\n<td id=\"S5.T5.1.4.4.2\" class=\"ltx_td ltx_align_left\">74.98</td>\n<td id=\"S5.T5.1.4.4.3\" class=\"ltx_td ltx_align_left\">/</td>\n</tr>\n<tr id=\"S5.T5.1.5.5\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.5.5.1\" class=\"ltx_td ltx_align_left\">ATTEMPT</td>\n<td id=\"S5.T5.1.5.5.2\" class=\"ltx_td ltx_align_left\">81.52</td>\n<td id=\"S5.T5.1.5.5.3\" class=\"ltx_td ltx_align_left\">317</td>\n</tr>\n<tr id=\"S5.T5.1.6.6\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.6.6.1\" class=\"ltx_td ltx_align_left\">LPT</td>\n<td id=\"S5.T5.1.6.6.2\" class=\"ltx_td ltx_align_left\">81.95</td>\n<td id=\"S5.T5.1.6.6.3\" class=\"ltx_td ltx_align_left\">1074</td>\n</tr>\n<tr id=\"S5.T5.1.7.7\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.7.7.1\" class=\"ltx_td ltx_align_left\">MomD</td>\n<td id=\"S5.T5.1.7.7.2\" class=\"ltx_td ltx_align_left\">76.2</td>\n<td id=\"S5.T5.1.7.7.3\" class=\"ltx_td ltx_align_left\">393</td>\n</tr>\n<tr id=\"S5.T5.1.8.8\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.8.8.1\" class=\"ltx_td ltx_align_left\">MomS+AdamD</td>\n<td id=\"S5.T5.1.8.8.2\" class=\"ltx_td ltx_align_left\">75.75</td>\n<td id=\"S5.T5.1.8.8.3\" class=\"ltx_td ltx_align_left\">810</td>\n</tr>\n<tr id=\"S5.T5.1.9.9\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.9.9.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">\n<span id=\"S5.T5.1.9.9.1.1\" class=\"ltx_ERROR undefined\">\\hdashline</span>FedPepTAO</td>\n<td id=\"S5.T5.1.9.9.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">82.34</td>\n<td id=\"S5.T5.1.9.9.3\" class=\"ltx_td ltx_align_left ltx_border_bb\">267</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We verify the performance of our method with another large model, i.e., LLaMA 7B with 7 billion parameters. As shown in Table 5, FedPepTAO outperforms baseline methods in terms of accuracy (up to 5.05%, 26.71%, 18.41%, 18.41%, 6.2%, 10.88% higher compared to FedPrompt, P-tuning v2, ATTEMPT, LPT, MomD and MomS+AdamD, respectively) and efficiency (up to 15.77%, 75.14%, 32.06%, 67.04% faster compared to ATTEMPT, LPT, MomD, and MomS+AdamD, respectively), which demonstrates the scalability of FedPepTAO."
        ]
    },
    "A2.T6": {
        "caption": "Table 6: The average number of epochs required to achieve the target accuracy (85% for QNLI, 92.5% for SST-2, 3% for CoLA, 77% for MRPC, 65% for RTE, 71% for BoolQ, 85% for MPQA, 88% for Subj, 78% for Trec, 91% for MR) on RoBERTaLARGE model. \"/\" represents that training does not achieve the target accuracy.",
        "table": "<table id=\"A2.T6.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"A2.T6.1.1.1\" class=\"ltx_tr\">\n<th id=\"A2.T6.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\"><span id=\"A2.T6.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></th>\n<td id=\"A2.T6.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_tt\"><span id=\"A2.T6.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Epochs</span></td>\n</tr>\n<tr id=\"A2.T6.1.2.2\" class=\"ltx_tr\">\n<th id=\"A2.T6.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Adapter</th>\n<td id=\"A2.T6.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">30.92</td>\n</tr>\n<tr id=\"A2.T6.1.3.3\" class=\"ltx_tr\">\n<th id=\"A2.T6.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">FedPrompt</th>\n<td id=\"A2.T6.1.3.3.2\" class=\"ltx_td ltx_align_left\">24.50</td>\n</tr>\n<tr id=\"A2.T6.1.4.4\" class=\"ltx_tr\">\n<th id=\"A2.T6.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">P-tuning v2</th>\n<td id=\"A2.T6.1.4.4.2\" class=\"ltx_td ltx_align_left\">5.99</td>\n</tr>\n<tr id=\"A2.T6.1.5.5\" class=\"ltx_tr\">\n<th id=\"A2.T6.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Prompt Tuning</th>\n<td id=\"A2.T6.1.5.5.2\" class=\"ltx_td ltx_align_left\">/</td>\n</tr>\n<tr id=\"A2.T6.1.6.6\" class=\"ltx_tr\">\n<th id=\"A2.T6.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">IDPG</th>\n<td id=\"A2.T6.1.6.6.2\" class=\"ltx_td ltx_align_left\">40.15</td>\n</tr>\n<tr id=\"A2.T6.1.7.7\" class=\"ltx_tr\">\n<th id=\"A2.T6.1.7.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">ATTEMPT</th>\n<td id=\"A2.T6.1.7.7.2\" class=\"ltx_td ltx_align_left\">39.97</td>\n</tr>\n<tr id=\"A2.T6.1.8.8\" class=\"ltx_tr\">\n<th id=\"A2.T6.1.8.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">LPT</th>\n<td id=\"A2.T6.1.8.8.2\" class=\"ltx_td ltx_align_left\">8.31</td>\n</tr>\n<tr id=\"A2.T6.1.9.9\" class=\"ltx_tr\">\n<th id=\"A2.T6.1.9.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">MomD</th>\n<td id=\"A2.T6.1.9.9.2\" class=\"ltx_td ltx_align_left\">13.98</td>\n</tr>\n<tr id=\"A2.T6.1.10.10\" class=\"ltx_tr\">\n<th id=\"A2.T6.1.10.10.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">MomS+AdamD</th>\n<td id=\"A2.T6.1.10.10.2\" class=\"ltx_td ltx_align_left\">5.99</td>\n</tr>\n<tr id=\"A2.T6.1.11.11\" class=\"ltx_tr\">\n<th id=\"A2.T6.1.11.11.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">\n<span id=\"A2.T6.1.11.11.1.1\" class=\"ltx_ERROR undefined\">\\hdashline</span>FedPepTAO</th>\n<td id=\"A2.T6.1.11.11.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">3.88</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "From Table 6, we find that FedPepTAO requires the smallest amount of epochs to achieve the target accuracy (87.45%, 84.16%, 35.26%, 90.33%, 90.29%, 53.31%, 72.22%, 35.21% faster compared to Adapter, FedPrompt, P-tuning v2, IDPG, ATTEMPT, LPT, MomD, and MomS+AdamD respectively). Prompt Tuning failed to achieve the target accuracy since it only optimizes the first layer of soft prompts. FedPepTAO can also reduce the communication overhead from 40% to 41.55% (41.55%, 40%, 40%, 40% compared with Adapter, P-tuning v2, MomD, and MomS+AdamD, respectively) between devices and the server, as illustrated in Table 7. FedPrompt, Prompt-Tuning, IDPG, ATTEMPT, and LPT correspond to lower communication overhead (up to 13%) since they only select one layer during tuning, which results in significantly inferior accuracy (from 17.02% to 60.8% lower) compared with FedPepTAO."
        ]
    },
    "A2.T7": {
        "caption": "Table 7: The communication overhead (s) between devices and the server with RoBERTaLARGE model.",
        "table": "<table id=\"A2.T7.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"A2.T7.1.1.1\" class=\"ltx_tr\">\n<th id=\"A2.T7.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\"><span id=\"A2.T7.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></th>\n<td id=\"A2.T7.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_tt\"><span id=\"A2.T7.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Time</span></td>\n</tr>\n<tr id=\"A2.T7.1.2.2\" class=\"ltx_tr\">\n<th id=\"A2.T7.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Adapter</th>\n<td id=\"A2.T7.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">5.80</td>\n</tr>\n<tr id=\"A2.T7.1.3.3\" class=\"ltx_tr\">\n<th id=\"A2.T7.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">FedPrompt</th>\n<td id=\"A2.T7.1.3.3.2\" class=\"ltx_td ltx_align_left\">3.09</td>\n</tr>\n<tr id=\"A2.T7.1.4.4\" class=\"ltx_tr\">\n<th id=\"A2.T7.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">P-tuning v2</th>\n<td id=\"A2.T7.1.4.4.2\" class=\"ltx_td ltx_align_left\">5.65</td>\n</tr>\n<tr id=\"A2.T7.1.5.5\" class=\"ltx_tr\">\n<th id=\"A2.T7.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Prompt Tuning</th>\n<td id=\"A2.T7.1.5.5.2\" class=\"ltx_td ltx_align_left\">3.00</td>\n</tr>\n<tr id=\"A2.T7.1.6.6\" class=\"ltx_tr\">\n<th id=\"A2.T7.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">IDPG</th>\n<td id=\"A2.T7.1.6.6.2\" class=\"ltx_td ltx_align_left\">3.09</td>\n</tr>\n<tr id=\"A2.T7.1.7.7\" class=\"ltx_tr\">\n<th id=\"A2.T7.1.7.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">ATTEMPT</th>\n<td id=\"A2.T7.1.7.7.2\" class=\"ltx_td ltx_align_left\">3.16</td>\n</tr>\n<tr id=\"A2.T7.1.8.8\" class=\"ltx_tr\">\n<th id=\"A2.T7.1.8.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">LPT</th>\n<td id=\"A2.T7.1.8.8.2\" class=\"ltx_td ltx_align_left\">3.09</td>\n</tr>\n<tr id=\"A2.T7.1.9.9\" class=\"ltx_tr\">\n<th id=\"A2.T7.1.9.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">MomD</th>\n<td id=\"A2.T7.1.9.9.2\" class=\"ltx_td ltx_align_left\">5.65</td>\n</tr>\n<tr id=\"A2.T7.1.10.10\" class=\"ltx_tr\">\n<th id=\"A2.T7.1.10.10.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">MomS+AdamD</th>\n<td id=\"A2.T7.1.10.10.2\" class=\"ltx_td ltx_align_left\">5.65</td>\n</tr>\n<tr id=\"A2.T7.1.11.11\" class=\"ltx_tr\">\n<th id=\"A2.T7.1.11.11.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">\n<span id=\"A2.T7.1.11.11.1.1\" class=\"ltx_ERROR undefined\">\\hdashline</span>FedPepTAO</th>\n<td id=\"A2.T7.1.11.11.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">3.39</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "From Table 6, we find that FedPepTAO requires the smallest amount of epochs to achieve the target accuracy (87.45%, 84.16%, 35.26%, 90.33%, 90.29%, 53.31%, 72.22%, 35.21% faster compared to Adapter, FedPrompt, P-tuning v2, IDPG, ATTEMPT, LPT, MomD, and MomS+AdamD respectively). Prompt Tuning failed to achieve the target accuracy since it only optimizes the first layer of soft prompts. FedPepTAO can also reduce the communication overhead from 40% to 41.55% (41.55%, 40%, 40%, 40% compared with Adapter, P-tuning v2, MomD, and MomS+AdamD, respectively) between devices and the server, as illustrated in Table 7. FedPrompt, Prompt-Tuning, IDPG, ATTEMPT, and LPT correspond to lower communication overhead (up to 13%) since they only select one layer during tuning, which results in significantly inferior accuracy (from 17.02% to 60.8% lower) compared with FedPepTAO."
        ]
    },
    "A2.T8": {
        "caption": "Table 8: The tuning time (s) to achieve a target accuracy (88% for Subj, 78% for Trec) on RoBERTaLARGE model. \"/\" represents that training does not achieve the target accuracy.",
        "table": "<table id=\"A2.T8.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"A2.T8.1.1.1\" class=\"ltx_tr\">\n<th id=\"A2.T8.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\"><span id=\"A2.T8.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></th>\n<td id=\"A2.T8.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_tt\"><span id=\"A2.T8.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Subj</span></td>\n<td id=\"A2.T8.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_border_tt\"><span id=\"A2.T8.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Trec</span></td>\n</tr>\n<tr id=\"A2.T8.1.2.2\" class=\"ltx_tr\">\n<th id=\"A2.T8.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Adapter</th>\n<td id=\"A2.T8.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">3591</td>\n<td id=\"A2.T8.1.2.2.3\" class=\"ltx_td ltx_align_left ltx_border_t\">7908</td>\n</tr>\n<tr id=\"A2.T8.1.3.3\" class=\"ltx_tr\">\n<th id=\"A2.T8.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">FedPrompt</th>\n<td id=\"A2.T8.1.3.3.2\" class=\"ltx_td ltx_align_left\">1333</td>\n<td id=\"A2.T8.1.3.3.3\" class=\"ltx_td ltx_align_left\">368</td>\n</tr>\n<tr id=\"A2.T8.1.4.4\" class=\"ltx_tr\">\n<th id=\"A2.T8.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">P-tuning v2</th>\n<td id=\"A2.T8.1.4.4.2\" class=\"ltx_td ltx_align_left\">361</td>\n<td id=\"A2.T8.1.4.4.3\" class=\"ltx_td ltx_align_left\">474</td>\n</tr>\n<tr id=\"A2.T8.1.5.5\" class=\"ltx_tr\">\n<th id=\"A2.T8.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Promtp Tuning</th>\n<td id=\"A2.T8.1.5.5.2\" class=\"ltx_td ltx_align_left\">/</td>\n<td id=\"A2.T8.1.5.5.3\" class=\"ltx_td ltx_align_left\">/</td>\n</tr>\n<tr id=\"A2.T8.1.6.6\" class=\"ltx_tr\">\n<th id=\"A2.T8.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">IDPG</th>\n<td id=\"A2.T8.1.6.6.2\" class=\"ltx_td ltx_align_left\">1401</td>\n<td id=\"A2.T8.1.6.6.3\" class=\"ltx_td ltx_align_left\">1345</td>\n</tr>\n<tr id=\"A2.T8.1.7.7\" class=\"ltx_tr\">\n<th id=\"A2.T8.1.7.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">ATTEMPT</th>\n<td id=\"A2.T8.1.7.7.2\" class=\"ltx_td ltx_align_left\">2726</td>\n<td id=\"A2.T8.1.7.7.3\" class=\"ltx_td ltx_align_left\">1184</td>\n</tr>\n<tr id=\"A2.T8.1.8.8\" class=\"ltx_tr\">\n<th id=\"A2.T8.1.8.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">LPT</th>\n<td id=\"A2.T8.1.8.8.2\" class=\"ltx_td ltx_align_left\">161</td>\n<td id=\"A2.T8.1.8.8.3\" class=\"ltx_td ltx_align_left\">123</td>\n</tr>\n<tr id=\"A2.T8.1.9.9\" class=\"ltx_tr\">\n<th id=\"A2.T8.1.9.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">MomD</th>\n<td id=\"A2.T8.1.9.9.2\" class=\"ltx_td ltx_align_left\">/</td>\n<td id=\"A2.T8.1.9.9.3\" class=\"ltx_td ltx_align_left\">/</td>\n</tr>\n<tr id=\"A2.T8.1.10.10\" class=\"ltx_tr\">\n<th id=\"A2.T8.1.10.10.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">MomS+AdamD</th>\n<td id=\"A2.T8.1.10.10.2\" class=\"ltx_td ltx_align_left\">453</td>\n<td id=\"A2.T8.1.10.10.3\" class=\"ltx_td ltx_align_left\">496</td>\n</tr>\n<tr id=\"A2.T8.1.11.11\" class=\"ltx_tr\">\n<th id=\"A2.T8.1.11.11.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">\n<span id=\"A2.T8.1.11.11.1.1\" class=\"ltx_ERROR undefined\">\\hdashline</span>FedPepTAO</th>\n<td id=\"A2.T8.1.11.11.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">70</td>\n<td id=\"A2.T8.1.11.11.3\" class=\"ltx_td ltx_align_left ltx_border_bb\">102</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We carry out extra experimentation on two tasks, i.e., Subj and Trec with modest network bandwidth (reduced to 100 times smaller) on the RoBERTaLARGE model. We find that FedPepTAO maintains its advantages in this setting, i.e., up to 98.71%, 94.75%, 80.61%, 95%, 97.43%, 56.52%, 84.55% faster compared with Adapter, FedPrompt, P-tuning v2, IDPG, ATTEMPT, LPT, MomS+AdamD to achieve the target accuracy, as shown in Table 8."
        ]
    },
    "A2.T9": {
        "caption": "Table 9: The performance of FedPepTAO and random layer choosing strategy on RTE dataset.",
        "table": "<table id=\"A2.T9.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A2.T9.1.1.1\" class=\"ltx_tr\">\n<th id=\"A2.T9.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span id=\"A2.T9.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></th>\n<th id=\"A2.T9.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span id=\"A2.T9.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Seed 42 Acc</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A2.T9.1.2.1\" class=\"ltx_tr\">\n<td id=\"A2.T9.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\">FedPepTAO</td>\n<td id=\"A2.T9.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">85.56%</td>\n</tr>\n<tr id=\"A2.T9.1.3.2\" class=\"ltx_tr\">\n<td id=\"A2.T9.1.3.2.1\" class=\"ltx_td ltx_align_left\">Random 1</td>\n<td id=\"A2.T9.1.3.2.2\" class=\"ltx_td ltx_align_left\">83.03%</td>\n</tr>\n<tr id=\"A2.T9.1.4.3\" class=\"ltx_tr\">\n<td id=\"A2.T9.1.4.3.1\" class=\"ltx_td ltx_align_left\">Random 2</td>\n<td id=\"A2.T9.1.4.3.2\" class=\"ltx_td ltx_align_left\">82.67%</td>\n</tr>\n<tr id=\"A2.T9.1.5.4\" class=\"ltx_tr\">\n<td id=\"A2.T9.1.5.4.1\" class=\"ltx_td ltx_align_left\">Random 3</td>\n<td id=\"A2.T9.1.5.4.2\" class=\"ltx_td ltx_align_left\">82.31%</td>\n</tr>\n<tr id=\"A2.T9.1.6.5\" class=\"ltx_tr\">\n<td id=\"A2.T9.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">Avg acc gain</td>\n<td id=\"A2.T9.1.6.5.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">2.89%</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "In order to clarify the impact of randomness in our experiments, we conduct three experiments with random layer selection strategy on RTE dataset. As shown in Table 9, FedPepTAO outperforms the random strategy with the accuracy gain of 2.53%, 2.89%, and 3.25% respectively, which demonstrates the superior performance of our FedPepTAO method."
        ]
    },
    "A2.T10": {
        "caption": "Table 10: The performance of FedPepTAO and random layer choosing strategy on RTE dataset under different random seeds",
        "table": "<table id=\"A2.T10.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A2.T10.1.1.1\" class=\"ltx_tr\">\n<th id=\"A2.T10.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" rowspan=\"2\"><span id=\"A2.T10.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></th>\n<th id=\"A2.T10.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span id=\"A2.T10.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Seed 32</span></th>\n<th id=\"A2.T10.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span id=\"A2.T10.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Seed 35</span></th>\n<th id=\"A2.T10.1.1.1.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span id=\"A2.T10.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Seed 37</span></th>\n</tr>\n<tr id=\"A2.T10.1.2.2\" class=\"ltx_tr\">\n<th id=\"A2.T10.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\"><span id=\"A2.T10.1.2.2.1.1\" class=\"ltx_text ltx_font_bold\">Acc</span></th>\n<th id=\"A2.T10.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\"><span id=\"A2.T10.1.2.2.2.1\" class=\"ltx_text ltx_font_bold\">Acc</span></th>\n<th id=\"A2.T10.1.2.2.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\"><span id=\"A2.T10.1.2.2.3.1\" class=\"ltx_text ltx_font_bold\">Acc</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A2.T10.1.3.1\" class=\"ltx_tr\">\n<td id=\"A2.T10.1.3.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\">FedPepTAO</td>\n<td id=\"A2.T10.1.3.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">84.84%</td>\n<td id=\"A2.T10.1.3.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">85.56%</td>\n<td id=\"A2.T10.1.3.1.4\" class=\"ltx_td ltx_align_left ltx_border_t\">85.92%</td>\n</tr>\n<tr id=\"A2.T10.1.4.2\" class=\"ltx_tr\">\n<td id=\"A2.T10.1.4.2.1\" class=\"ltx_td ltx_align_left\">Random 1</td>\n<td id=\"A2.T10.1.4.2.2\" class=\"ltx_td ltx_align_left\">82.31%</td>\n<td id=\"A2.T10.1.4.2.3\" class=\"ltx_td ltx_align_left\">82.31%</td>\n<td id=\"A2.T10.1.4.2.4\" class=\"ltx_td ltx_align_left\">82.31%</td>\n</tr>\n<tr id=\"A2.T10.1.5.3\" class=\"ltx_tr\">\n<td id=\"A2.T10.1.5.3.1\" class=\"ltx_td ltx_align_left\">Random 2</td>\n<td id=\"A2.T10.1.5.3.2\" class=\"ltx_td ltx_align_left\">81.59%</td>\n<td id=\"A2.T10.1.5.3.3\" class=\"ltx_td ltx_align_left\">81.23%</td>\n<td id=\"A2.T10.1.5.3.4\" class=\"ltx_td ltx_align_left\">83.39%</td>\n</tr>\n<tr id=\"A2.T10.1.6.4\" class=\"ltx_tr\">\n<td id=\"A2.T10.1.6.4.1\" class=\"ltx_td ltx_align_left\">Random 3</td>\n<td id=\"A2.T10.1.6.4.2\" class=\"ltx_td ltx_align_left\">82.67%</td>\n<td id=\"A2.T10.1.6.4.3\" class=\"ltx_td ltx_align_left\">83.03%</td>\n<td id=\"A2.T10.1.6.4.4\" class=\"ltx_td ltx_align_left\">83.75%</td>\n</tr>\n<tr id=\"A2.T10.1.7.5\" class=\"ltx_tr\">\n<td id=\"A2.T10.1.7.5.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">Avg Acc Gain</td>\n<td id=\"A2.T10.1.7.5.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">2.65%</td>\n<td id=\"A2.T10.1.7.5.3\" class=\"ltx_td ltx_align_left ltx_border_bb\">3.37%</td>\n<td id=\"A2.T10.1.7.5.4\" class=\"ltx_td ltx_align_left ltx_border_bb\">2.77%</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In order to clarify the impact of randomness in our experiments, we conduct three experiments with random layer selection strategy on RTE dataset. As shown in Table ",
                "9",
                ", FedPepTAO outperforms the random strategy with the accuracy gain of 2.53%, 2.89%, and 3.25% respectively, which demonstrates the superior performance of our FedPepTAO method.",
                "In addition, in order to further validate the impact of randomness on different datasets, we conducted additional experiments on three datasets (RTE, MRPC, and CoLA) with three randomly selected seeds (32, 35, and 37) to testify the strength of our Parameter-efficient Prompt Tuning method. Tables ",
                "10",
                ", ",
                "11",
                ", and ",
                "12",
                " exhibit that FedPepTAO outperforms the random strategy by 2.91%, 4.64%, and 7.29% on RTE, MRPC, and CoLA datasets, respectively. The above experiment results indicate that our FedPepTAO method can achieve substantial improvement compared with the random strategy.",
                "We notice an inverse correlation between the performance of our Parameter-efficient Prompt Tuning (PEPT) method and the average sentence length of the three datasets. Specifically, PEPT tends to achieve a smaller performance gain on the datasets with longer average sentence length, as shown in Table ",
                "14",
                ".",
                "A reasonable explanation is that the datasets with longer average sentence length, such as RTE, often contain more latent information. More/less latent information make them easier/more difficult to be evenly distributed across all transformer layers, resulting in a relatively equal/diverse contribution by each layer during tuning. When different layers contain the similar/dissimilar amount of latent information, the impact of each unique layer is accordingly decreased/increased. Therefore, the random layer selection results in less/more accuracy gain by our PEPT method. The above experiment results demonstrate that our PEPT method can achieve substantial performance improvement on different datasets in most experiments."
            ]
        ]
    },
    "A2.T11": {
        "caption": "Table 11: The performance of FedPepTAO and random layer choosing strategy on MRPC dataset under different random seeds",
        "table": "<table id=\"A2.T11.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A2.T11.1.1.1\" class=\"ltx_tr\">\n<th id=\"A2.T11.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" rowspan=\"2\"><span id=\"A2.T11.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></th>\n<th id=\"A2.T11.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span id=\"A2.T11.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Seed 32</span></th>\n<th id=\"A2.T11.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span id=\"A2.T11.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Seed 35</span></th>\n<th id=\"A2.T11.1.1.1.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span id=\"A2.T11.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Seed 37</span></th>\n</tr>\n<tr id=\"A2.T11.1.2.2\" class=\"ltx_tr\">\n<th id=\"A2.T11.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\"><span id=\"A2.T11.1.2.2.1.1\" class=\"ltx_text ltx_font_bold\">Acc</span></th>\n<th id=\"A2.T11.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\"><span id=\"A2.T11.1.2.2.2.1\" class=\"ltx_text ltx_font_bold\">Acc</span></th>\n<th id=\"A2.T11.1.2.2.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\"><span id=\"A2.T11.1.2.2.3.1\" class=\"ltx_text ltx_font_bold\">Acc</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A2.T11.1.3.1\" class=\"ltx_tr\">\n<td id=\"A2.T11.1.3.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\">FedPepTAO</td>\n<td id=\"A2.T11.1.3.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">86.54%</td>\n<td id=\"A2.T11.1.3.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">87.09%</td>\n<td id=\"A2.T11.1.3.1.4\" class=\"ltx_td ltx_align_left ltx_border_t\">86.18%</td>\n</tr>\n<tr id=\"A2.T11.1.4.2\" class=\"ltx_tr\">\n<td id=\"A2.T11.1.4.2.1\" class=\"ltx_td ltx_align_left\">Random 1</td>\n<td id=\"A2.T11.1.4.2.2\" class=\"ltx_td ltx_align_left\">83.09%</td>\n<td id=\"A2.T11.1.4.2.3\" class=\"ltx_td ltx_align_left\">81.86%</td>\n<td id=\"A2.T11.1.4.2.4\" class=\"ltx_td ltx_align_left\">80.34%</td>\n</tr>\n<tr id=\"A2.T11.1.5.3\" class=\"ltx_tr\">\n<td id=\"A2.T11.1.5.3.1\" class=\"ltx_td ltx_align_left\">Random 2</td>\n<td id=\"A2.T11.1.5.3.2\" class=\"ltx_td ltx_align_left\">82.73%</td>\n<td id=\"A2.T11.1.5.3.3\" class=\"ltx_td ltx_align_left\">82.03%</td>\n<td id=\"A2.T11.1.5.3.4\" class=\"ltx_td ltx_align_left\">80.54%</td>\n</tr>\n<tr id=\"A2.T11.1.6.4\" class=\"ltx_tr\">\n<td id=\"A2.T11.1.6.4.1\" class=\"ltx_td ltx_align_left\">Random 3</td>\n<td id=\"A2.T11.1.6.4.2\" class=\"ltx_td ltx_align_left\">83.31%</td>\n<td id=\"A2.T11.1.6.4.3\" class=\"ltx_td ltx_align_left\">81.83%</td>\n<td id=\"A2.T11.1.6.4.4\" class=\"ltx_td ltx_align_left\">81.16%</td>\n</tr>\n<tr id=\"A2.T11.1.7.5\" class=\"ltx_tr\">\n<td id=\"A2.T11.1.7.5.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">Avg Acc Gain</td>\n<td id=\"A2.T11.1.7.5.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">3.5%</td>\n<td id=\"A2.T11.1.7.5.3\" class=\"ltx_td ltx_align_left ltx_border_bb\">5.18%</td>\n<td id=\"A2.T11.1.7.5.4\" class=\"ltx_td ltx_align_left ltx_border_bb\">5.5%</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In order to clarify the impact of randomness in our experiments, we conduct three experiments with random layer selection strategy on RTE dataset. As shown in Table ",
                "9",
                ", FedPepTAO outperforms the random strategy with the accuracy gain of 2.53%, 2.89%, and 3.25% respectively, which demonstrates the superior performance of our FedPepTAO method.",
                "In addition, in order to further validate the impact of randomness on different datasets, we conducted additional experiments on three datasets (RTE, MRPC, and CoLA) with three randomly selected seeds (32, 35, and 37) to testify the strength of our Parameter-efficient Prompt Tuning method. Tables ",
                "10",
                ", ",
                "11",
                ", and ",
                "12",
                " exhibit that FedPepTAO outperforms the random strategy by 2.91%, 4.64%, and 7.29% on RTE, MRPC, and CoLA datasets, respectively. The above experiment results indicate that our FedPepTAO method can achieve substantial improvement compared with the random strategy.",
                "We notice an inverse correlation between the performance of our Parameter-efficient Prompt Tuning (PEPT) method and the average sentence length of the three datasets. Specifically, PEPT tends to achieve a smaller performance gain on the datasets with longer average sentence length, as shown in Table ",
                "14",
                ".",
                "A reasonable explanation is that the datasets with longer average sentence length, such as RTE, often contain more latent information. More/less latent information make them easier/more difficult to be evenly distributed across all transformer layers, resulting in a relatively equal/diverse contribution by each layer during tuning. When different layers contain the similar/dissimilar amount of latent information, the impact of each unique layer is accordingly decreased/increased. Therefore, the random layer selection results in less/more accuracy gain by our PEPT method. The above experiment results demonstrate that our PEPT method can achieve substantial performance improvement on different datasets in most experiments."
            ]
        ]
    },
    "A2.T12": {
        "caption": "Table 12: The performance of FedPepTAO and random layer choosing strategy on CoLA dataset under different random seeds",
        "table": "<table id=\"A2.T12.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A2.T12.1.1.1\" class=\"ltx_tr\">\n<th id=\"A2.T12.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\" rowspan=\"2\"><span id=\"A2.T12.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></th>\n<th id=\"A2.T12.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span id=\"A2.T12.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Seed 32</span></th>\n<th id=\"A2.T12.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span id=\"A2.T12.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Seed 35</span></th>\n<th id=\"A2.T12.1.1.1.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span id=\"A2.T12.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Seed 37</span></th>\n</tr>\n<tr id=\"A2.T12.1.2.2\" class=\"ltx_tr\">\n<th id=\"A2.T12.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\"><span id=\"A2.T12.1.2.2.1.1\" class=\"ltx_text ltx_font_bold\">Acc</span></th>\n<th id=\"A2.T12.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\"><span id=\"A2.T12.1.2.2.2.1\" class=\"ltx_text ltx_font_bold\">Acc</span></th>\n<th id=\"A2.T12.1.2.2.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\"><span id=\"A2.T12.1.2.2.3.1\" class=\"ltx_text ltx_font_bold\">Acc</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A2.T12.1.3.1\" class=\"ltx_tr\">\n<td id=\"A2.T12.1.3.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\">FedPepTAO</td>\n<td id=\"A2.T12.1.3.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">56.94%</td>\n<td id=\"A2.T12.1.3.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">58.92%</td>\n<td id=\"A2.T12.1.3.1.4\" class=\"ltx_td ltx_align_left ltx_border_t\">56.49%</td>\n</tr>\n<tr id=\"A2.T12.1.4.2\" class=\"ltx_tr\">\n<td id=\"A2.T12.1.4.2.1\" class=\"ltx_td ltx_align_left\">Random 1</td>\n<td id=\"A2.T12.1.4.2.2\" class=\"ltx_td ltx_align_left\">46.45%</td>\n<td id=\"A2.T12.1.4.2.3\" class=\"ltx_td ltx_align_left\">52.84%</td>\n<td id=\"A2.T12.1.4.2.4\" class=\"ltx_td ltx_align_left\">49.58%</td>\n</tr>\n<tr id=\"A2.T12.1.5.3\" class=\"ltx_tr\">\n<td id=\"A2.T12.1.5.3.1\" class=\"ltx_td ltx_align_left\">Random 2</td>\n<td id=\"A2.T12.1.5.3.2\" class=\"ltx_td ltx_align_left\">51.57%</td>\n<td id=\"A2.T12.1.5.3.3\" class=\"ltx_td ltx_align_left\">49.84%</td>\n<td id=\"A2.T12.1.5.3.4\" class=\"ltx_td ltx_align_left\">45.71%</td>\n</tr>\n<tr id=\"A2.T12.1.6.4\" class=\"ltx_tr\">\n<td id=\"A2.T12.1.6.4.1\" class=\"ltx_td ltx_align_left\">Random 3</td>\n<td id=\"A2.T12.1.6.4.2\" class=\"ltx_td ltx_align_left\">50.77%</td>\n<td id=\"A2.T12.1.6.4.3\" class=\"ltx_td ltx_align_left\">53.2%</td>\n<td id=\"A2.T12.1.6.4.4\" class=\"ltx_td ltx_align_left\">51.45%</td>\n</tr>\n<tr id=\"A2.T12.1.7.5\" class=\"ltx_tr\">\n<td id=\"A2.T12.1.7.5.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">Avg Acc Gain</td>\n<td id=\"A2.T12.1.7.5.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">7.34%</td>\n<td id=\"A2.T12.1.7.5.3\" class=\"ltx_td ltx_align_left ltx_border_bb\">6.96%</td>\n<td id=\"A2.T12.1.7.5.4\" class=\"ltx_td ltx_align_left ltx_border_bb\">7.58%</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In order to clarify the impact of randomness in our experiments, we conduct three experiments with random layer selection strategy on RTE dataset. As shown in Table ",
                "9",
                ", FedPepTAO outperforms the random strategy with the accuracy gain of 2.53%, 2.89%, and 3.25% respectively, which demonstrates the superior performance of our FedPepTAO method.",
                "In addition, in order to further validate the impact of randomness on different datasets, we conducted additional experiments on three datasets (RTE, MRPC, and CoLA) with three randomly selected seeds (32, 35, and 37) to testify the strength of our Parameter-efficient Prompt Tuning method. Tables ",
                "10",
                ", ",
                "11",
                ", and ",
                "12",
                " exhibit that FedPepTAO outperforms the random strategy by 2.91%, 4.64%, and 7.29% on RTE, MRPC, and CoLA datasets, respectively. The above experiment results indicate that our FedPepTAO method can achieve substantial improvement compared with the random strategy.",
                "We notice an inverse correlation between the performance of our Parameter-efficient Prompt Tuning (PEPT) method and the average sentence length of the three datasets. Specifically, PEPT tends to achieve a smaller performance gain on the datasets with longer average sentence length, as shown in Table ",
                "14",
                ".",
                "A reasonable explanation is that the datasets with longer average sentence length, such as RTE, often contain more latent information. More/less latent information make them easier/more difficult to be evenly distributed across all transformer layers, resulting in a relatively equal/diverse contribution by each layer during tuning. When different layers contain the similar/dissimilar amount of latent information, the impact of each unique layer is accordingly decreased/increased. Therefore, the random layer selection results in less/more accuracy gain by our PEPT method. The above experiment results demonstrate that our PEPT method can achieve substantial performance improvement on different datasets in most experiments."
            ]
        ]
    },
    "A2.T13": {
        "caption": "Table 13: The statistics of datasets evaluated in this work. |𝒴|𝒴|\\mathcal{Y}| is the number for classes.",
        "table": "<table id=\"A2.T13.7.7\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A2.T13.7.7.7\" class=\"ltx_tr\">\n<th id=\"A2.T13.7.7.7.8\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span id=\"A2.T13.7.7.7.8.1\" class=\"ltx_text ltx_font_bold\">Category</span></th>\n<th id=\"A2.T13.7.7.7.9\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span id=\"A2.T13.7.7.7.9.1\" class=\"ltx_text ltx_font_bold\">Datasets</span></th>\n<th id=\"A2.T13.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">\n<math id=\"A2.T13.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"|\" display=\"inline\"><semantics id=\"A2.T13.1.1.1.1.m1.1a\"><mo fence=\"false\" stretchy=\"false\" id=\"A2.T13.1.1.1.1.m1.1.1\" xref=\"A2.T13.1.1.1.1.m1.1.1.cmml\">|</mo><annotation-xml encoding=\"MathML-Content\" id=\"A2.T13.1.1.1.1.m1.1b\"><ci id=\"A2.T13.1.1.1.1.m1.1.1.cmml\" xref=\"A2.T13.1.1.1.1.m1.1.1\">|</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T13.1.1.1.1.m1.1c\">|</annotation></semantics></math><span id=\"A2.T13.2.2.2.2.1\" class=\"ltx_text ltx_font_bold\">Train<math id=\"A2.T13.2.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"|\" display=\"inline\"><semantics id=\"A2.T13.2.2.2.2.1.m1.1a\"><mo fence=\"false\" stretchy=\"false\" id=\"A2.T13.2.2.2.2.1.m1.1.1\" xref=\"A2.T13.2.2.2.2.1.m1.1.1.cmml\">|</mo><annotation-xml encoding=\"MathML-Content\" id=\"A2.T13.2.2.2.2.1.m1.1b\"><ci id=\"A2.T13.2.2.2.2.1.m1.1.1.cmml\" xref=\"A2.T13.2.2.2.2.1.m1.1.1\">|</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T13.2.2.2.2.1.m1.1c\">|</annotation></semantics></math></span>\n</th>\n<th id=\"A2.T13.4.4.4.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">\n<math id=\"A2.T13.3.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"|\" display=\"inline\"><semantics id=\"A2.T13.3.3.3.3.m1.1a\"><mo fence=\"false\" stretchy=\"false\" id=\"A2.T13.3.3.3.3.m1.1.1\" xref=\"A2.T13.3.3.3.3.m1.1.1.cmml\">|</mo><annotation-xml encoding=\"MathML-Content\" id=\"A2.T13.3.3.3.3.m1.1b\"><ci id=\"A2.T13.3.3.3.3.m1.1.1.cmml\" xref=\"A2.T13.3.3.3.3.m1.1.1\">|</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T13.3.3.3.3.m1.1c\">|</annotation></semantics></math><span id=\"A2.T13.4.4.4.4.1\" class=\"ltx_text ltx_font_bold\">Dev<math id=\"A2.T13.4.4.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"|\" display=\"inline\"><semantics id=\"A2.T13.4.4.4.4.1.m1.1a\"><mo fence=\"false\" stretchy=\"false\" id=\"A2.T13.4.4.4.4.1.m1.1.1\" xref=\"A2.T13.4.4.4.4.1.m1.1.1.cmml\">|</mo><annotation-xml encoding=\"MathML-Content\" id=\"A2.T13.4.4.4.4.1.m1.1b\"><ci id=\"A2.T13.4.4.4.4.1.m1.1.1.cmml\" xref=\"A2.T13.4.4.4.4.1.m1.1.1\">|</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T13.4.4.4.4.1.m1.1c\">|</annotation></semantics></math></span>\n</th>\n<th id=\"A2.T13.6.6.6.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">\n<math id=\"A2.T13.5.5.5.5.m1.1\" class=\"ltx_Math\" alttext=\"|\" display=\"inline\"><semantics id=\"A2.T13.5.5.5.5.m1.1a\"><mo fence=\"false\" stretchy=\"false\" id=\"A2.T13.5.5.5.5.m1.1.1\" xref=\"A2.T13.5.5.5.5.m1.1.1.cmml\">|</mo><annotation-xml encoding=\"MathML-Content\" id=\"A2.T13.5.5.5.5.m1.1b\"><ci id=\"A2.T13.5.5.5.5.m1.1.1.cmml\" xref=\"A2.T13.5.5.5.5.m1.1.1\">|</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T13.5.5.5.5.m1.1c\">|</annotation></semantics></math><span id=\"A2.T13.6.6.6.6.1\" class=\"ltx_text ltx_font_bold\">Test<math id=\"A2.T13.6.6.6.6.1.m1.1\" class=\"ltx_Math\" alttext=\"|\" display=\"inline\"><semantics id=\"A2.T13.6.6.6.6.1.m1.1a\"><mo fence=\"false\" stretchy=\"false\" id=\"A2.T13.6.6.6.6.1.m1.1.1\" xref=\"A2.T13.6.6.6.6.1.m1.1.1.cmml\">|</mo><annotation-xml encoding=\"MathML-Content\" id=\"A2.T13.6.6.6.6.1.m1.1b\"><ci id=\"A2.T13.6.6.6.6.1.m1.1.1.cmml\" xref=\"A2.T13.6.6.6.6.1.m1.1.1\">|</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T13.6.6.6.6.1.m1.1c\">|</annotation></semantics></math></span>\n</th>\n<th id=\"A2.T13.7.7.7.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><math id=\"A2.T13.7.7.7.7.m1.1\" class=\"ltx_Math\" alttext=\"\\mathbf{|\\mathcal{Y}|}\" display=\"inline\"><semantics id=\"A2.T13.7.7.7.7.m1.1a\"><mrow id=\"A2.T13.7.7.7.7.m1.1.2.2\" xref=\"A2.T13.7.7.7.7.m1.1.2.1.cmml\"><mo stretchy=\"false\" id=\"A2.T13.7.7.7.7.m1.1.2.2.1\" xref=\"A2.T13.7.7.7.7.m1.1.2.1.1.cmml\">|</mo><mi class=\"ltx_font_mathcaligraphic\" id=\"A2.T13.7.7.7.7.m1.1.1\" xref=\"A2.T13.7.7.7.7.m1.1.1.cmml\">𝒴</mi><mo stretchy=\"false\" id=\"A2.T13.7.7.7.7.m1.1.2.2.2\" xref=\"A2.T13.7.7.7.7.m1.1.2.1.1.cmml\">|</mo></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A2.T13.7.7.7.7.m1.1b\"><apply id=\"A2.T13.7.7.7.7.m1.1.2.1.cmml\" xref=\"A2.T13.7.7.7.7.m1.1.2.2\"><abs id=\"A2.T13.7.7.7.7.m1.1.2.1.1.cmml\" xref=\"A2.T13.7.7.7.7.m1.1.2.2.1\"></abs><ci id=\"A2.T13.7.7.7.7.m1.1.1.cmml\" xref=\"A2.T13.7.7.7.7.m1.1.1\">𝒴</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T13.7.7.7.7.m1.1c\">\\mathbf{|\\mathcal{Y}|}</annotation></semantics></math></th>\n<th id=\"A2.T13.7.7.7.10\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"A2.T13.7.7.7.10.1\" class=\"ltx_text ltx_font_bold\">Type</span></th>\n<th id=\"A2.T13.7.7.7.11\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span id=\"A2.T13.7.7.7.11.1\" class=\"ltx_text ltx_font_bold\">Labels</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A2.T13.7.7.8.1\" class=\"ltx_tr\">\n<td id=\"A2.T13.7.7.8.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\" rowspan=\"5\"><span id=\"A2.T13.7.7.8.1.1.1\" class=\"ltx_text\">Single-sentence</span></td>\n<td id=\"A2.T13.7.7.8.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">SST-2</td>\n<td id=\"A2.T13.7.7.8.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">67349</td>\n<td id=\"A2.T13.7.7.8.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">872</td>\n<td id=\"A2.T13.7.7.8.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">1821</td>\n<td id=\"A2.T13.7.7.8.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">2</td>\n<td id=\"A2.T13.7.7.8.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\">sentiment</td>\n<td id=\"A2.T13.7.7.8.1.8\" class=\"ltx_td ltx_align_left ltx_border_t\">positive, negative</td>\n</tr>\n<tr id=\"A2.T13.7.7.9.2\" class=\"ltx_tr\">\n<td id=\"A2.T13.7.7.9.2.1\" class=\"ltx_td ltx_align_left\">MPQA</td>\n<td id=\"A2.T13.7.7.9.2.2\" class=\"ltx_td ltx_align_center\">7606</td>\n<td id=\"A2.T13.7.7.9.2.3\" class=\"ltx_td ltx_align_center\">1000</td>\n<td id=\"A2.T13.7.7.9.2.4\" class=\"ltx_td ltx_align_center\">2000</td>\n<td id=\"A2.T13.7.7.9.2.5\" class=\"ltx_td ltx_align_center\">2</td>\n<td id=\"A2.T13.7.7.9.2.6\" class=\"ltx_td ltx_align_center\">opinion polarity</td>\n<td id=\"A2.T13.7.7.9.2.7\" class=\"ltx_td ltx_align_left\">positive, negative</td>\n</tr>\n<tr id=\"A2.T13.7.7.10.3\" class=\"ltx_tr\">\n<td id=\"A2.T13.7.7.10.3.1\" class=\"ltx_td ltx_align_left\">MR</td>\n<td id=\"A2.T13.7.7.10.3.2\" class=\"ltx_td ltx_align_center\">7662</td>\n<td id=\"A2.T13.7.7.10.3.3\" class=\"ltx_td ltx_align_center\">1000</td>\n<td id=\"A2.T13.7.7.10.3.4\" class=\"ltx_td ltx_align_center\">2000</td>\n<td id=\"A2.T13.7.7.10.3.5\" class=\"ltx_td ltx_align_center\">2</td>\n<td id=\"A2.T13.7.7.10.3.6\" class=\"ltx_td ltx_align_center\">sentiment</td>\n<td id=\"A2.T13.7.7.10.3.7\" class=\"ltx_td ltx_align_left\">positive, negative</td>\n</tr>\n<tr id=\"A2.T13.7.7.11.4\" class=\"ltx_tr\">\n<td id=\"A2.T13.7.7.11.4.1\" class=\"ltx_td ltx_align_left\">Subj</td>\n<td id=\"A2.T13.7.7.11.4.2\" class=\"ltx_td ltx_align_center\">7000</td>\n<td id=\"A2.T13.7.7.11.4.3\" class=\"ltx_td ltx_align_center\">1000</td>\n<td id=\"A2.T13.7.7.11.4.4\" class=\"ltx_td ltx_align_center\">2000</td>\n<td id=\"A2.T13.7.7.11.4.5\" class=\"ltx_td ltx_align_center\">2</td>\n<td id=\"A2.T13.7.7.11.4.6\" class=\"ltx_td ltx_align_center\">subjectivity</td>\n<td id=\"A2.T13.7.7.11.4.7\" class=\"ltx_td ltx_align_left\">subjective, objective</td>\n</tr>\n<tr id=\"A2.T13.7.7.12.5\" class=\"ltx_tr\">\n<td id=\"A2.T13.7.7.12.5.1\" class=\"ltx_td ltx_align_left\">Trec</td>\n<td id=\"A2.T13.7.7.12.5.2\" class=\"ltx_td ltx_align_center\">4952</td>\n<td id=\"A2.T13.7.7.12.5.3\" class=\"ltx_td ltx_align_center\">500</td>\n<td id=\"A2.T13.7.7.12.5.4\" class=\"ltx_td ltx_align_center\">500</td>\n<td id=\"A2.T13.7.7.12.5.5\" class=\"ltx_td ltx_align_center\">6</td>\n<td id=\"A2.T13.7.7.12.5.6\" class=\"ltx_td ltx_align_center\">question cls.</td>\n<td id=\"A2.T13.7.7.12.5.7\" class=\"ltx_td ltx_align_left\">abbr., entity, description, human, loc., num.</td>\n</tr>\n<tr id=\"A2.T13.7.7.13.6\" class=\"ltx_tr\">\n<td id=\"A2.T13.7.7.13.6.1\" class=\"ltx_td\"></td>\n<td id=\"A2.T13.7.7.13.6.2\" class=\"ltx_td ltx_align_left\">CoLA</td>\n<td id=\"A2.T13.7.7.13.6.3\" class=\"ltx_td ltx_align_center\">8551</td>\n<td id=\"A2.T13.7.7.13.6.4\" class=\"ltx_td ltx_align_center\">1043</td>\n<td id=\"A2.T13.7.7.13.6.5\" class=\"ltx_td ltx_align_center\">1063</td>\n<td id=\"A2.T13.7.7.13.6.6\" class=\"ltx_td ltx_align_center\">2</td>\n<td id=\"A2.T13.7.7.13.6.7\" class=\"ltx_td ltx_align_center\">acceptability</td>\n<td id=\"A2.T13.7.7.13.6.8\" class=\"ltx_td ltx_align_left\">acceptable, unacceptable</td>\n</tr>\n<tr id=\"A2.T13.7.7.14.7\" class=\"ltx_tr\">\n<td id=\"A2.T13.7.7.14.7.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\" rowspan=\"5\"><span id=\"A2.T13.7.7.14.7.1.1\" class=\"ltx_text\">Sentence-pair</span></td>\n<td id=\"A2.T13.7.7.14.7.2\" class=\"ltx_td ltx_align_left ltx_border_t\">MRPC</td>\n<td id=\"A2.T13.7.7.14.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\">3668</td>\n<td id=\"A2.T13.7.7.14.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\">408</td>\n<td id=\"A2.T13.7.7.14.7.5\" class=\"ltx_td ltx_align_center ltx_border_t\">1725</td>\n<td id=\"A2.T13.7.7.14.7.6\" class=\"ltx_td ltx_align_center ltx_border_t\">2</td>\n<td id=\"A2.T13.7.7.14.7.7\" class=\"ltx_td ltx_align_center ltx_border_t\">paraphrase</td>\n<td id=\"A2.T13.7.7.14.7.8\" class=\"ltx_td ltx_align_left ltx_border_t\">equivalent, not equivalent</td>\n</tr>\n<tr id=\"A2.T13.7.7.15.8\" class=\"ltx_tr\">\n<td id=\"A2.T13.7.7.15.8.1\" class=\"ltx_td ltx_align_left\">QNLI</td>\n<td id=\"A2.T13.7.7.15.8.2\" class=\"ltx_td ltx_align_center\">104743</td>\n<td id=\"A2.T13.7.7.15.8.3\" class=\"ltx_td ltx_align_center\">5463</td>\n<td id=\"A2.T13.7.7.15.8.4\" class=\"ltx_td ltx_align_center\">5463</td>\n<td id=\"A2.T13.7.7.15.8.5\" class=\"ltx_td ltx_align_center\">2</td>\n<td id=\"A2.T13.7.7.15.8.6\" class=\"ltx_td ltx_align_center\">NLI</td>\n<td id=\"A2.T13.7.7.15.8.7\" class=\"ltx_td ltx_align_left\">entailment, not entailment</td>\n</tr>\n<tr id=\"A2.T13.7.7.16.9\" class=\"ltx_tr\">\n<td id=\"A2.T13.7.7.16.9.1\" class=\"ltx_td ltx_align_left\">BoolQ</td>\n<td id=\"A2.T13.7.7.16.9.2\" class=\"ltx_td ltx_align_center\">9427</td>\n<td id=\"A2.T13.7.7.16.9.3\" class=\"ltx_td ltx_align_center\">3270</td>\n<td id=\"A2.T13.7.7.16.9.4\" class=\"ltx_td ltx_align_center\">3245</td>\n<td id=\"A2.T13.7.7.16.9.5\" class=\"ltx_td ltx_align_center\">2</td>\n<td id=\"A2.T13.7.7.16.9.6\" class=\"ltx_td ltx_align_center\">QA</td>\n<td id=\"A2.T13.7.7.16.9.7\" class=\"ltx_td ltx_align_left\">true, false</td>\n</tr>\n<tr id=\"A2.T13.7.7.17.10\" class=\"ltx_tr\">\n<td id=\"A2.T13.7.7.17.10.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">RTE</td>\n<td id=\"A2.T13.7.7.17.10.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">2490</td>\n<td id=\"A2.T13.7.7.17.10.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">277</td>\n<td id=\"A2.T13.7.7.17.10.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">3000</td>\n<td id=\"A2.T13.7.7.17.10.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">2</td>\n<td id=\"A2.T13.7.7.17.10.6\" class=\"ltx_td ltx_align_center ltx_border_bb\">NLI</td>\n<td id=\"A2.T13.7.7.17.10.7\" class=\"ltx_td ltx_align_left ltx_border_bb\">entailment, not entailment</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "The number of global training epochs is set to 100 and that of local training epochs is set to 2. We utilize the Dirichlet distribution (with 1.0 as the concentration parameter alpha) to partition the data into non-IID splits and assign a certain number of samples to each device according to the Dirichlet distribution (with 5.0 as the concentration parameter alpha). We exploit development sets for the evaluation of tasks in the GLUE benchmark since test sets are not labeled. For 4 other datasets, we select a certain number of samples from the training set as the development set, and the number of samples for each label is determined according to its proportion in the original training set. For datasets in GLUE benchmark (Wang et al., 2019), we use their original data splits. For 4 other datasets with no default splits, we randomly divide the dataset into train, development, and test sets. The dataset statistics after the split are shown in Table 13"
        ]
    },
    "A2.T14": {
        "caption": "Table 14: Average sentence length and accuracy improvements of FedPepTAO for three datasets.",
        "table": "<table id=\"A2.T14.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A2.T14.1.1.1\" class=\"ltx_tr\">\n<th id=\"A2.T14.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span id=\"A2.T14.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Dataset</span></th>\n<th id=\"A2.T14.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span id=\"A2.T14.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Avg sentence length</span></th>\n<th id=\"A2.T14.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span id=\"A2.T14.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Avg acc gain</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A2.T14.1.2.1\" class=\"ltx_tr\">\n<td id=\"A2.T14.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\">RTE</td>\n<td id=\"A2.T14.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">71.91</td>\n<td id=\"A2.T14.1.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\">2.91%</td>\n</tr>\n<tr id=\"A2.T14.1.3.2\" class=\"ltx_tr\">\n<td id=\"A2.T14.1.3.2.1\" class=\"ltx_td ltx_align_left\">MRPC</td>\n<td id=\"A2.T14.1.3.2.2\" class=\"ltx_td ltx_align_left\">54.95</td>\n<td id=\"A2.T14.1.3.2.3\" class=\"ltx_td ltx_align_left\">4.64%</td>\n</tr>\n<tr id=\"A2.T14.1.4.3\" class=\"ltx_tr\">\n<td id=\"A2.T14.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">CoLA</td>\n<td id=\"A2.T14.1.4.3.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">16.37</td>\n<td id=\"A2.T14.1.4.3.3\" class=\"ltx_td ltx_align_left ltx_border_bb\">7.29%</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We notice an inverse correlation between the performance of our Parameter-efficient Prompt Tuning (PEPT) method and the average sentence length of the three datasets. Specifically, PEPT tends to achieve a smaller performance gain on the datasets with longer average sentence length, as shown in Table 14."
        ]
    }
}