{
    "PAPER'S NUMBER OF TABLES": 1,
    "Sx4.T1": {
        "caption": "Table 1: Robustness of clusters generated by \\acronymand WD under various non-IIDness types. SAE stands for supervised autoencoder, AE for standard autoencoder, and CLF for classifier-based embeddings in \\acronym, and f𝑓f is the number of fine-tuning epochs performed on the clients in case of WD. The number of clusters is in all cases set to 10.",
        "table": "",
        "footnotes": "\n\n\n\n\n\n \n\n\nConcept drift,\n\nlabel skew\n\n \n\n\nLabel skew\n\n \n\n\nConcept drift\n\n\n\n\nMean\nSE\nMean\nSE\nMean\nSE\n\n\\acronym\nSAE\n0.91\n0.02\n0.90\n0.02\n0.92\n0.02\n\nCLF\n0.87\n0.03\n0.90\n0.02\n0.89\n0.03\n\nAE\n0.89\n0.02\n0.79\n0.03\n0.89\n0.03\n\nWD\nf𝑓f=1\n0.75\n0.08\n0.68\n0.05\n0.25\n0.10\n\nf𝑓f=2\n0.84\n0.03\n0.77\n0.03\n0.15\n0.05\n",
        "references": [
            "The robustness of the clusters obtained by the \\acronymand WD is reported in Table 1. \\acronymmanages to achieve overall robustness above 90%, irrespective of the non-IIDness type. WD, on the other hand, struggles with the concept drift type of non-IIDness, where its robustness remains barely above the robustness that would have been achieved by randomly assigning clients to one of the 101010 available clusters. The table also shows that the supervised autoencoder (SAE) we embrace for \\acronymoutperforms alternative architectures."
        ]
    }
}