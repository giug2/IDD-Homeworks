{
    "S4.T1.3": {
        "caption": [],
        "table": "<table id=\"S4.T1.3\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.3.3\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.3.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Method</th>\n<th id=\"S4.T1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">FID<math id=\"S4.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.T1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T1.1.1.1.m1.1.1\" xref=\"S4.T1.1.1.1.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.1.1.1.m1.1b\"><ci id=\"S4.T1.1.1.1.m1.1.1.cmml\" xref=\"S4.T1.1.1.1.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<th id=\"S4.T1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Road mIOU<math id=\"S4.T1.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T1.2.2.2.m1.1a\"><mo stretchy=\"false\" id=\"S4.T1.2.2.2.m1.1.1\" xref=\"S4.T1.2.2.2.m1.1.1.cmml\">↑</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.2.2.2.m1.1b\"><ci id=\"S4.T1.2.2.2.m1.1.1.cmml\" xref=\"S4.T1.2.2.2.m1.1.1\">↑</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.2.2.2.m1.1c\">\\uparrow</annotation></semantics></math>\n</th>\n<th id=\"S4.T1.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Vehicle mIOU<math id=\"S4.T1.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T1.3.3.3.m1.1a\"><mo stretchy=\"false\" id=\"S4.T1.3.3.3.m1.1.1\" xref=\"S4.T1.3.3.3.m1.1.1.cmml\">↑</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.3.3.3.m1.1b\"><ci id=\"S4.T1.3.3.3.m1.1.1.cmml\" xref=\"S4.T1.3.3.3.m1.1.1\">↑</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.3.3.3.m1.1c\">\\uparrow</annotation></semantics></math>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.3.4.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.4.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">BEVGen <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib4\" title=\"\" class=\"ltx_ref\">4</a>]</cite>\n</th>\n<td id=\"S4.T1.3.4.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">25.54</td>\n<td id=\"S4.T1.3.4.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">50.20</td>\n<td id=\"S4.T1.3.4.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">5.89</td>\n</tr>\n<tr id=\"S4.T1.3.5.2\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.5.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">UViT <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib35\" title=\"\" class=\"ltx_ref\">35</a>]</cite>\n</th>\n<td id=\"S4.T1.3.5.2.2\" class=\"ltx_td ltx_align_center\">79.22</td>\n<td id=\"S4.T1.3.5.2.3\" class=\"ltx_td ltx_align_center\">37.69</td>\n<td id=\"S4.T1.3.5.2.4\" class=\"ltx_td ltx_align_center\">9.16</td>\n</tr>\n<tr id=\"S4.T1.3.6.3\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.6.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">Ours</th>\n<td id=\"S4.T1.3.6.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">48.65</td>\n<td id=\"S4.T1.3.6.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">47.45</td>\n<td id=\"S4.T1.3.6.3.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">17.70</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "Quantitative result: In Table.  I, we juxtapose our approach with the benchmark BEVGen and a transformer-driven diffusion model. Utilizing the Frechet Inception Distance (FID) [41], akin to BEVGen, we evaluate the congruence between the generated images and the training dataset. While our outputs are visually appealing and consistent, our FID score lags behind BEVGen. This can be attributed to our reliance on limited data for fine-tuning, hence the visual style largely remains anchored to the foundational diffusion model. For a more equitable comparison, we trained a UViT-based latent diffusion model from scratch, which yielded an even less favorable FID score. This suggests that the scope of the training dataset might be insufficient, complicating the task of cultivating a robust diffusion model from scratch."
        ]
    }
}{
    "S4.T2.3": {
        "caption": [],
        "table": "<table id=\"S4.T2.3\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T2.3.3\" class=\"ltx_tr\">\n<th id=\"S4.T2.3.3.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Method</th>\n<th id=\"S4.T2.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">FID<math id=\"S4.T2.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.T2.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T2.1.1.1.m1.1.1\" xref=\"S4.T2.1.1.1.m1.1.1.cmml\">↓</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.1.1.1.m1.1b\"><ci id=\"S4.T2.1.1.1.m1.1.1.cmml\" xref=\"S4.T2.1.1.1.m1.1.1\">↓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<th id=\"S4.T2.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Road mIOU<math id=\"S4.T2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T2.2.2.2.m1.1a\"><mo stretchy=\"false\" id=\"S4.T2.2.2.2.m1.1.1\" xref=\"S4.T2.2.2.2.m1.1.1.cmml\">↑</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.2.2.2.m1.1b\"><ci id=\"S4.T2.2.2.2.m1.1.1.cmml\" xref=\"S4.T2.2.2.2.m1.1.1\">↑</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.2.2.2.m1.1c\">\\uparrow</annotation></semantics></math>\n</th>\n<th id=\"S4.T2.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Vehicle mIOU<math id=\"S4.T2.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T2.3.3.3.m1.1a\"><mo stretchy=\"false\" id=\"S4.T2.3.3.3.m1.1.1\" xref=\"S4.T2.3.3.3.m1.1.1.cmml\">↑</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.3.3.3.m1.1b\"><ci id=\"S4.T2.3.3.3.m1.1.1.cmml\" xref=\"S4.T2.3.3.3.m1.1.1\">↑</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.3.3.3.m1.1c\">\\uparrow</annotation></semantics></math>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.3.4.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.3.4.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">Base diffusion</th>\n<td id=\"S4.T2.3.4.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">82.25</td>\n<td id=\"S4.T2.3.4.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">46.76</td>\n<td id=\"S4.T2.3.4.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">11.82</td>\n</tr>\n<tr id=\"S4.T2.3.5.2\" class=\"ltx_tr\">\n<th id=\"S4.T2.3.5.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">+ shape refinement</th>\n<td id=\"S4.T2.3.5.2.2\" class=\"ltx_td ltx_align_center\">78.13</td>\n<td id=\"S4.T2.3.5.2.3\" class=\"ltx_td ltx_align_center\">47.92</td>\n<td id=\"S4.T2.3.5.2.4\" class=\"ltx_td ltx_align_center\">15.69</td>\n</tr>\n<tr id=\"S4.T2.3.6.3\" class=\"ltx_tr\">\n<th id=\"S4.T2.3.6.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">+ view adaptation</th>\n<td id=\"S4.T2.3.6.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">48.65</td>\n<td id=\"S4.T2.3.6.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">47.45</td>\n<td id=\"S4.T2.3.6.3.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">17.70</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "In our research, we carried out ablation studies, specifically honing in on two of our core innovations: the shape refinement process and the street view adaptation technique. The detailed results of these studies can be found in Table.  II. The shape refinement process is pivotal in ensuring that map elements are accurately positioned. When the shape within the camera’s perspective aligns more semantically, it resonates more effectively with the given prompt. On the other hand, the street view adaptation module plays a crucial role as a style encoder. Its primary function is to make sure that the generated images bear a strong resemblance to those in the training dataset. Moreover, this module greatly assists the image generator by enabling it to achieve proper and accurate orientations for the various map elements."
        ]
    }
}