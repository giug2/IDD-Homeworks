{
    "id_table_1": {
        "caption": "Table 1:  Evaluations between fine-tuned models and the corresponding raw models in three dimensions ( HTS ). The values in parentheses represent the IAA score.  H/T/S  indicate humanized communication, teaching expertise and safety & ethics.",
        "table": "S3.T1.9",
        "footnotes": [],
        "references": [
            "As generative artificial intelligence advances, educational chatbots based on large language models (LLMs) are hoped to provide promising educational services in many scenarios of liberal arts, like literature reading, writing and debating. Specifically, compared to subject-specific factual knowledge, the rich and personalized linguistic forms, teaching skills, along with ethical safety involved in content analysis ( HTS  in Fig. 1   1 1 1 Detailed description in Appendix  B . ), are equally important in liberal educational dialogues  (Wang et al.,  2024 ; Deng et al.,  2023 ; Li et al.,  2023 ) . However, due to the difficulty of collecting a sufficient amount of HTS-compliant teacher-student multi-turn dialogue data from real teaching scenarios for optimizing LLMs, the responses of existing LLMs to real educational contexts are unable to meet the HTS requirements.",
            "Tab.  1  compares the performance of the fine-tuned model with its original version across three dimensions  HTS . The results show that the fine-tuned model outperforms the original model in all three dimensions, particularly in humanized communication and teaching expertise. And the scores of inter-annotation agreement (IAA) show the moderate agreement between the volunteers evaluation.",
            "Consequently, edge-deployed models for education need an integrated systemic approach that includes data collection, model inference, and model fine-tuning to address the  HTS  challenges in Fig. 1 , as a single technological path is not sufficient."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:    Evaluations between fine-tuned models (Qwen1.5-4B, MiniCPM-2B, ChatGLM3-6b) and the commercial  GLM-4  model with and without RAM2C as baselines.  H/T/S  indicate humanized communication, teaching expertise and safety & ethics. The values in parentheses represent the IAA score.  GLM3  means local ChatGLM3-6b,  GLM  means commercial GLM-4 without RAM2C, and  GLM-R  means commercial GLM-4 with RAM2C.",
        "table": "S3.T2.21",
        "footnotes": [],
        "references": [
            "To address these challenges, we propose a framework named  R etrieval- A ugmented  M ulti-role  M ulti-expert  C ollaboration (RAM2C), capable of rapidly and cost-effectively generating HTS-compliant liberal arts educational dialogues by unleashing the individual intrinsic capability (role-playing by in-context learning), extrinsic capability (retrieval-augmented generation), and collective capability (multi-experts generation synthesizing) of LLMs. The specific work flow is shown in Fig. 2 a, 2b.  The generated high-valued dialogues are used to execute the  HTS  preference alignment of LLMs (Fig.  2 c), which aims to promote the intrinsic capability of basic LLMs to analyze references and generate responses.",
            "In this section, we elaborate on the principle components in RAM2C, as shown in Fig. 2  and Fig. 3 .",
            "Unlike multi-role single-agent collaboration Tang et al. ( 2023 )  and single-role multi-agent collaboration Wang et al. ( 2023b ) , we utilize prompt engineering to create three groups of LLM experts with distinct roles:  T-Group : Chinese language teachers,  P-Group : educational psychologists, and  E-Group : ethical safety experts, with 3 experts for each role, as shown in Fig.  2 a.",
            "The refinement of dialogue responses, as a sequential task flow, is completed by T/P/E-Group collaboration in turn. Specifically, as depicted in Fig.  2 b, the initial response generated by a basic LLM, along with the current topic and student context, is provided to the T-Group for analysis and synthesis. The resulting output then serves as the input for the P-Group. This process is similarly applied to the remaining groups. Ultimately, the final response, which has been subjected to ethical scrutiny by the E-Group, is conveyed to the students.",
            "We use RAM2C to organize GLM-4 and generate a preference alignment dataset, which contains 3,500 dialogues. Each sample of this dataset is a  (Q,A,R1,R2)  pair, as shown in Fig. 2 c, where  Q  is the discussion topic generated by RAM2C,  A  is the answer by LLM-simulated student, and  R1  is the chosen response from RAM2C-GLM4,  R2  is the rejected one by the lightweight model without fine-tuning. We conduct fine-tuning experiments on lightweight models including Qwen1.5-4B Bai et al. ( 2023 ) , MiniCPM-2B Hu et al. ( 2024 ) , and ChatGLM3-6b Du et al. ( 2022 ) , based on Llama-Factory Zheng et al. ( 2024 ) .",
            "The dialogue in liberal arts education is characterized by a strong subjectivity, in contrast to question-answer tasks evaluated based on factual correctness. Therefore, we recruit sixteen volunteers, including primary and secondary school teachers as well as university researchers, to evaluate the fine-tuned models across three dimensions ( HTS ). For each fine-tuned model, we construct a dialogue sample set, which structure is similar to the fine-tuning dataset in Section 3.2 . More details can be found in Appendix  D .",
            "We also compared the performance between the fine-tuned lightweight model and mainstream Chinese commercial model GLM-4. As shown in Tab.  2 , fine-tuned models can largely compete with GLM-4 that do not use RAM2C integration. And the RAM2C-empowered GLM-4 exhibits the highest level of performance.",
            "We generate a dialogue set for evaluation of each fine-tuned model. The structure of the dialogue set is same as the fine-tuning dataset in Section 3.2 ,  (Q,A,R1,R2) . The  Q  is the question generated by the model and not included in the fine-tuning dataset, the  A  is a LLM-simulated students response, and  R1  and  R2  are the responses from the fine-tuned model or the baseline model to the students response. The positions of  R1  and  R2  are unspecified to prevent any influence on the evaluators preferences."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Ablation studies on different roles and numbers of experts.  GLM : GLM-4 without RAM2C;  GLM-R : GLM-4 with full RAM2C;  GLM-P/R : GLM-R without P-Group;  GLM-E/R : GLM-R without E-Group;  GLM-PE/R : GLM-R without P-Group and E-Group;  GLM-R/1 : GLM-R with only one expert in each group/role.",
        "table": "S3.T3.15",
        "footnotes": [],
        "references": [
            "In this section, we elaborate on the principle components in RAM2C, as shown in Fig. 2  and Fig. 3 .",
            "Therefore, after obtaining preliminary retrieved documents, we convene an expert group to analyze and vote from multiple perspectives, thereby filtering a diverse set of references with real reference value, see Document #15 in Fig. 4 b. During the in-group collaboration, each expert is assigned to different references, and is required to generate explicit analysis to its reference ( proactive analysis  to form diverse chains of thought, as shown in Fig. 3 ). The individual revision of the raw response is then generated by utilizing this analysis.",
            "The dialogue in liberal arts education is characterized by a strong subjectivity, in contrast to question-answer tasks evaluated based on factual correctness. Therefore, we recruit sixteen volunteers, including primary and secondary school teachers as well as university researchers, to evaluate the fine-tuned models across three dimensions ( HTS ). For each fine-tuned model, we construct a dialogue sample set, which structure is similar to the fine-tuning dataset in Section 3.2 . More details can be found in Appendix  D .",
            "We conducted ablation experiments to explore the impact of different roles and the number of experts on dialogue quality, as shown in Tab.  3 . RAM2C based GLM-4 models excluding the P-Group and/or E-Group result in varying degrees of performance decline in the dimensions of  humanized communication  and  safety & ethics . However, the exclusion of the E-Group has a relatively limited impact on  safety & ethics . We interpret this as general LLMs typically being well-aligned with human preferences and possessing basic ethical and safety qualities. Therefore, the collaboration of the T-Group and P-Group mitigates the performance decline caused by the absence of the E-Group. We also explored the difference in dialogue quality between one expert per group and three experts per group, and the results indicate that in-group collaboration is quite necessary.",
            "We generate a dialogue set for evaluation of each fine-tuned model. The structure of the dialogue set is same as the fine-tuning dataset in Section 3.2 ,  (Q,A,R1,R2) . The  Q  is the question generated by the model and not included in the fine-tuning dataset, the  A  is a LLM-simulated students response, and  R1  and  R2  are the responses from the fine-tuned model or the baseline model to the students response. The positions of  R1  and  R2  are unspecified to prevent any influence on the evaluators preferences."
        ]
    },
    "id_table_4": {
        "caption": "Table 4:  Summary of counts in Chinese character across different knowledge sources.",
        "table": "A3.T4.1",
        "footnotes": [],
        "references": [
            "We emphasize that, unlike general RAG systems, which provide references that enhance the factual accuracy of LLMs outputs, LLMs for liberal arts dialogues need demonstrations or inspiration from documents with varying reference values. For instance, aspects such as language style, vocabulary usage, and logical connections in these documents are particularly beneficial for improving humanized communication of LLMs. These complex semantic structures cannot be achieved solely through semantic vector matching. As shown in Fig. 4 b, vector databases are likely to return relevant but lower reference value documents.",
            "Therefore, after obtaining preliminary retrieved documents, we convene an expert group to analyze and vote from multiple perspectives, thereby filtering a diverse set of references with real reference value, see Document #15 in Fig. 4 b. During the in-group collaboration, each expert is assigned to different references, and is required to generate explicit analysis to its reference ( proactive analysis  to form diverse chains of thought, as shown in Fig. 3 ). The individual revision of the raw response is then generated by utilizing this analysis."
        ]
    },
    "id_table_5": {
        "caption": "Table 5:  Evaluation criteria of liberal arts educational dialogues for volunteers.",
        "table": "A4.T5.1",
        "footnotes": [],
        "references": [
            "A well organized response is shown in Fig.  5  generated by the fine-tuned Qwen model. The response includes personalized emotional support and encouragements, as long as the assessment to the specific content of the student, comparing with the response of untrained version.",
            "For each dimension evaluation ( H/T/S ), each volunteer is provided with a random sample of 25 items from the set and makes choices between  R1  and  R2  based on evaluation criteria (Tab.  5 ), indicating whether the fine-tuned model is better/equal/worse, and thereby assigning corresponding scores (4/2/0). The total score reflects the performance of the tested model. The score above 50.0 means better overall performance against the baseline model. And score of 50.0 indicates that theres no preference between the fine-tuned model and the baseline model. Scores below 50.0 mean that the fine-tuning has negative effect on the model. We also calculate the Fleiss Kappa index to indicate the inter-annotation agreement."
        ]
    },
    "global_footnotes": [
        "Detailed description in Appendix",
        "."
    ]
}