{
    "id_table_1": {
        "caption": "Table 1 :  Different queries for obtaining data from different modalities.",
        "table": "S3.SS1.tab1.1",
        "footnotes": [],
        "references": [
            "To enrich LLMs responses with factual up-to-date information specific documents and media were selected. These elements satisfy certain criteria rather than just doing a web search every time a query is given by the user, which can leave room for pseudo-scientific sources. Our main data formats are PDF documents obtained by searching Google, images from Google images and videos from YouTube. Search for the elements is done via queries in the different search platforms. Queries can be general like \"asthma\" or more specific (e.g. FAQs). Table  3.1  shows different queries used to obtain data. FAQs are obtained from the gina website 1 1 1 https://ginasthma.org/about-us/faqs/ . These FAQs were later translated into different languages to obtain data from languages other than English. The PDF documents were downloaded manually while images from Google Images and YouTube videos were scraped automatically. After scraping the different images and videos we extracted the text from the source of the images and the video transcripts of each image and video respectively. We should note that we explored using image captioning to obtain image description but it was limited and didnt give importance to the context in which the image was used, consequently, we opted for the text in the webpage of the image source as an alternative.",
            "To ensure the accessibility of AsthmaBot to a wider user base we created an interactive interface similar to that of ChatGPT and Gemini with the added features of embedded videos, source documents and images. In addition, users can click on the images to be transferred to the source website of the image. Figure  1  shows the interface of AsthmaBot."
        ]
    },
    "id_table_2": {
        "caption": "Figure 1 :  AsthmaBot interface.",
        "table": "S4.T2.2",
        "footnotes": [],
        "references": [
            "Figure  2  shows the process of inference in AsthmaBot. This interface is available at  asthmabot.datanets.org .",
            "To evaluate AsthmaBot we collected a set of asthma-related FAQs from various sources. We collected over 400 FAQs from over 30 sources. Table  2  gives various examples of question-answer pairs that we collected. To evaluate AsthmaBots multilingual capabilities we translated the FAQs using Google Translate API."
        ]
    },
    "id_table_3": {
        "caption": "Figure 2 :  AsthmaBot Overview : given a query AsthmaBot uses asthma-related external resources to retrieve information relevant to the query and the query language before synthesizing a multi-modal response. This framework provides a multi-modal response grounded in truth, which reduces hallucinations and provides multiple formats for the answer.",
        "table": "S4.T3.2",
        "footnotes": [],
        "references": [
            "To enrich LLMs responses with factual up-to-date information specific documents and media were selected. These elements satisfy certain criteria rather than just doing a web search every time a query is given by the user, which can leave room for pseudo-scientific sources. Our main data formats are PDF documents obtained by searching Google, images from Google images and videos from YouTube. Search for the elements is done via queries in the different search platforms. Queries can be general like \"asthma\" or more specific (e.g. FAQs). Table  3.1  shows different queries used to obtain data. FAQs are obtained from the gina website 1 1 1 https://ginasthma.org/about-us/faqs/ . These FAQs were later translated into different languages to obtain data from languages other than English. The PDF documents were downloaded manually while images from Google Images and YouTube videos were scraped automatically. After scraping the different images and videos we extracted the text from the source of the images and the video transcripts of each image and video respectively. We should note that we explored using image captioning to obtain image description but it was limited and didnt give importance to the context in which the image was used, consequently, we opted for the text in the webpage of the image source as an alternative.",
            "Prompting is a fundamental element of LLM inference as it has been shown that the quality and the design of the prompt affect the quality of the output of the LLM  Chen et al. ( 2023a ) .  section   3.3  shows the prompt that we used in AsthmaBot. The prompt contains three parameters the query, context and \"history\". The query refers to the user input, the context refers to the different text passages obtained by querying the different text vector DBs. The \"history\" refers to the chat history between the user and the LLM, composed of question-answer pairs. We used the Google Gemini LLM to infer the results of different queries.",
            "Table  3  shows the results of querying using AsthmaBot in multiple languages (English, Arabic, French) in multiple data modalities (text, images, videos). The table shows that RAG significantly improves the performance in question answering relative to the no RAG baseline. This is true for all modalities and languages. On the other hand, we notice that there are variations in performance between languages. This can be attributed to the richness of the documents that were used in RAG."
        ]
    },
    "id_table_4": {
        "caption": "Table 2 :  Question-answer pair examples from the FAQs dataset.",
        "table": "S4.T4.2",
        "footnotes": [],
        "references": [
            "Table  4  shows the results of experimenting with using English-only input to the LLM and using prompts in the native language of the query. The results show that the English-only prompts perform significantly better than the native language prompt. This can be attributed to the significant amount of English prompts that the LLM was trained on. This language bias limits the richness of LLM output in languages other than English."
        ]
    },
    "id_table_5": {
        "caption": "Table 3 :  Performance Evaluation in different languages for different modalities.",
        "table": "S5.T5.2",
        "footnotes": [],
        "references": [
            "AsthmaBot integrates multiple features that are not included in many publicly available LLMs. We compared AsthmaBot to multiple publically available LLMs: ChatGPT 2 2 2 chat.openai.com , Gemini  3 3 3 gemini.google.com , Perplexity AI 4 4 4 perplexity.ai , YouChat 5 5 5 you.com . Table  5  compares the retrieval capabilities of different LLMs and AsthmaBot. Table  6  compares different LLMs generative capabilities. Although these models are made for general-purpose use, there is an increasing need for more domain-specific models with more constraints to reduce hallucination and language bias and AsthmaBot is another step in this direction for biomedical applications."
        ]
    },
    "id_table_6": {
        "caption": "Table 4 :  Results of querying with native language and with English translations of the query and the prompts. We conducted the same experiment for French and Arabic. NQ refers to \"native query\" and TQ refers to \"translated query\".",
        "table": "S5.T6.2",
        "footnotes": [],
        "references": [
            "AsthmaBot integrates multiple features that are not included in many publicly available LLMs. We compared AsthmaBot to multiple publically available LLMs: ChatGPT 2 2 2 chat.openai.com , Gemini  3 3 3 gemini.google.com , Perplexity AI 4 4 4 perplexity.ai , YouChat 5 5 5 you.com . Table  5  compares the retrieval capabilities of different LLMs and AsthmaBot. Table  6  compares different LLMs generative capabilities. Although these models are made for general-purpose use, there is an increasing need for more domain-specific models with more constraints to reduce hallucination and language bias and AsthmaBot is another step in this direction for biomedical applications."
        ]
    },
    "global_footnotes": [
        "https://ginasthma.org/about-us/faqs/",
        "chat.openai.com",
        "gemini.google.com",
        "perplexity.ai",
        "you.com"
    ]
}