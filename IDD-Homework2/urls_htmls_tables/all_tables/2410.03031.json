{
    "id_table_1": {
        "caption": "TABLE I :  Model Performance in terms of AP of 3D IoU for strawberries detection and dimension estimation. The metric unit is %.",
        "table": "S5.EGx1",
        "footnotes": [],
        "references": []
    },
    "id_table_2": {
        "caption": "TABLE II :  Model Performance in terms of translational and rotational errors for 6DoF pose estimation. The metric unit is %.",
        "table": "S5.EGx2",
        "footnotes": [],
        "references": [
            "Keypoints-based methods of 6DoF pose estimation are characterized by their speed, accuracy, and robustness. Concurrently, YOLO  [ 17 ]  remains a leading choice among 2D detectors for robotic fruit harvesting, as evidenced by recent research  [ 3 ] . Building upon these insights, and drawing inspiration from the foundational framework of YOLO, as well as its progressive successors, particularly YOLO3D  [ 18 ]  and YOLO6D  [ 9 ] , we have developed a novel two-stage method for keypoints-based 6DoF pose and 3D size estimation. This network is illustrated in Fig.  2 ."
        ]
    },
    "id_table_3": {
        "caption": "",
        "table": "S5.EGx3",
        "footnotes": [],
        "references": [
            "To mitigate the common issue of models trained on synthetic datasets underperforming with real-world images, we implemented domain randomization techniques  [ 21 ] , strategically varying camera settings and introducing random lighting conditions within the simulator. This approach aimed to mimic the variability of real-world conditions, thereby enhancing the datasets diversity with cluttered scenes, varied plant forms, and randomized berry positions and sizes, ensuring the test scenarios distinctly differ from the training set. This methodology, illustrated in Fig.  3 , is not restricted to strawberries alone but is adaptable for generating datasets for other objects, such as apples, necessitating 6DoF pose estimation."
        ]
    },
    "id_table_4": {
        "caption": "",
        "table": "S4.T1.4",
        "footnotes": [],
        "references": [
            "Through the models prediction results combined with the PnP algorithm, we obtained the estimated rotation and translation matrices. In a similar vein, we derived the transformation matrix for the ground truth. Subsequently, rotational and translational errors are acquired from the discrepancies of these two transformation matrices. Thereafter, we back-projected both the estimated and ground truth 2D projected coordinates of the center point and vertices to 3D space, calculating the 3D IoU value. Further, due to the symmetrical assumption of the strawberry, we selected the highest score as well as the lowest errors among the 12 ground truths to avoid penalization. Table  I  summarizes the results of 3D detection and object dimension estimation. Table  II  summarizes the results of 6DoF pose estimation. The inference outcomes on the test dataset can be observed in Fig.  4 . In terms of inference speed, when tested on the same GPU as training, on average we achieved a runtime of 16.60 ms, leading to 60 FPS. By increasing the level of thresholds, we observed a significant performance drop. This indicates room for enhancement in our models precision. Opting for a larger model architecture might be beneficial, even if it results in sacrificing some computational speed."
        ]
    },
    "id_table_5": {
        "caption": "",
        "table": "S4.T2.4.1",
        "footnotes": [],
        "references": [
            "Towards this goal, we employed the StrawDI dataset  [ 7 ]  to train our model and test its sim-to-real performance. We pretrained the backbone of our model on the StrawDI dataset by adding a YOLO 2D detection head. Subsequently, we further trained the complete network on Straw6D. During the training process, we initially trained the whole network for 120 epochs and then froze all parameters of the backbone, and then fine-tuned the remaining parts of the model for an additional 480 epochs. The resultant model demonstrated accuracy comparable to that of models trained solely in simulated environments when evaluated on a synthetic data test set. However, its performance on real-world datasets significantly surpassed that of models trained exclusively in simulation. Furthermore, the results we obtained are interesting, particularly because the synthetic dataset lacks large unripe strawberries, whereas the real dataset contains many instances of them. Remarkably, our model demonstrated the capability to detect strawberries irrespective of their ripeness level. The inference results are depicted in Fig.  5 ."
        ]
    }
}