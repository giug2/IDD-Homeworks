{
    "PAPER'S NUMBER OF TABLES": 3,
    "S5.T1": {
        "caption": "TABLE I: Summary of parameter of our federated scenarios.",
        "table": "<table id=\"S5.T1.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.2.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.2.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span id=\"S5.T1.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Framework</span></th>\n<td id=\"S5.T1.2.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">Flower</td>\n</tr>\n<tr id=\"S5.T1.2.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T1.2.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span id=\"S5.T1.2.2.2.1.1\" class=\"ltx_text ltx_font_bold\">Model</span></th>\n<td id=\"S5.T1.2.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">VAE / AE</td>\n</tr>\n<tr id=\"S5.T1.2.3.3\" class=\"ltx_tr\">\n<th id=\"S5.T1.2.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span id=\"S5.T1.2.3.3.1.1\" class=\"ltx_text ltx_font_bold\">Aggregation function</span></th>\n<td id=\"S5.T1.2.3.3.2\" class=\"ltx_td ltx_align_left ltx_border_t\">Fed+</td>\n</tr>\n<tr id=\"S5.T1.2.4.4\" class=\"ltx_tr\">\n<th id=\"S5.T1.2.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span id=\"S5.T1.2.4.4.1.1\" class=\"ltx_text ltx_font_bold\">Clients</span></th>\n<td id=\"S5.T1.2.4.4.2\" class=\"ltx_td ltx_align_left ltx_border_t\">From Fig. <a href=\"#S5.F5\" title=\"Figure 5 ‚Ä£ V-A Client division ‚Ä£ V Evaluation ‚Ä£ Federated Learning for Misbehaviour Detection with Variational Autoencoders and Gaussian Mixture Models\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>\n</td>\n</tr>\n<tr id=\"S5.T1.2.5.5\" class=\"ltx_tr\">\n<th id=\"S5.T1.2.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span id=\"S5.T1.2.5.5.1.1\" class=\"ltx_text ltx_font_bold\">Rounds</span></th>\n<td id=\"S5.T1.2.5.5.2\" class=\"ltx_td ltx_align_left ltx_border_t\">30</td>\n</tr>\n<tr id=\"S5.T1.2.6.6\" class=\"ltx_tr\">\n<th id=\"S5.T1.2.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_t\"><span id=\"S5.T1.2.6.6.1.1\" class=\"ltx_text ltx_font_bold\">Epochs</span></th>\n<td id=\"S5.T1.2.6.6.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">1</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "For the evaluation of our misbehaviour detection approach, we employ a virtual machine with processor Intel(R) Xeon(R) Silver 4214R CPU @ 2.40GHz with 24 cores and 196 GB of RAM. Furthermore, we use Flower [57] as the FL implementation framework, the version 0.18. Flower provides an end-to-end implementation and the possibility to customise several aspects of the model for performing a more exhaustive evaluation. All the parameters related to our federated scenarios are summarised in Table I. Furthermore, it should be noted that we make the code and the dataset used publicly available for reproducibility purposes111https://github.com/Enrique-Marmol/Federated-Learning-for-Misbehaviour-Detection-with-Variational-Autoencoder-and-Gaussian-Mixture-Mode."
        ]
    },
    "S5.T2": {
        "caption": "TABLE II: Accuracy of the autoencoder part of different methods varying the lr in the 298-component cluster",
        "table": "<table id=\"S5.T2.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T2.2.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T2.2.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\"><span id=\"S5.T2.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Learning rate</span></th>\n<th id=\"S5.T2.2.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\"><span id=\"S5.T2.2.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Federated VAE</span></th>\n<th id=\"S5.T2.2.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\"><span id=\"S5.T2.2.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Distributed VAE</span></th>\n<th id=\"S5.T2.2.1.1.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\"><span id=\"S5.T2.2.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Federated AE</span></th>\n<th id=\"S5.T2.2.1.1.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\"><span id=\"S5.T2.2.1.1.5.1\" class=\"ltx_text ltx_font_bold\">Distributed AE</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T2.2.2.1\" class=\"ltx_tr\">\n<td id=\"S5.T2.2.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\">0.001</td>\n<td id=\"S5.T2.2.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">0.920</td>\n<td id=\"S5.T2.2.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S5.T2.2.2.1.3.1\" class=\"ltx_text ltx_font_bold\">0.928</span></td>\n<td id=\"S5.T2.2.2.1.4\" class=\"ltx_td ltx_align_left ltx_border_t\">0.90</td>\n<td id=\"S5.T2.2.2.1.5\" class=\"ltx_td ltx_align_left ltx_border_t\">0.921</td>\n</tr>\n<tr id=\"S5.T2.2.3.2\" class=\"ltx_tr\">\n<td id=\"S5.T2.2.3.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\">0.005</td>\n<td id=\"S5.T2.2.3.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">0.892</td>\n<td id=\"S5.T2.2.3.2.3\" class=\"ltx_td ltx_align_left ltx_border_t\">0.915</td>\n<td id=\"S5.T2.2.3.2.4\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S5.T2.2.3.2.4.1\" class=\"ltx_text ltx_font_bold\">0.923</span></td>\n<td id=\"S5.T2.2.3.2.5\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S5.T2.2.3.2.5.1\" class=\"ltx_text ltx_font_bold\">0.936</span></td>\n</tr>\n<tr id=\"S5.T2.2.4.3\" class=\"ltx_tr\">\n<td id=\"S5.T2.2.4.3.1\" class=\"ltx_td ltx_align_left ltx_border_t\">0.01</td>\n<td id=\"S5.T2.2.4.3.2\" class=\"ltx_td ltx_align_left ltx_border_t\">0.767</td>\n<td id=\"S5.T2.2.4.3.3\" class=\"ltx_td ltx_align_left ltx_border_t\">0.792</td>\n<td id=\"S5.T2.2.4.3.4\" class=\"ltx_td ltx_align_left ltx_border_t\">0.893</td>\n<td id=\"S5.T2.2.4.3.5\" class=\"ltx_td ltx_align_left ltx_border_t\">0.911</td>\n</tr>\n<tr id=\"S5.T2.2.5.4\" class=\"ltx_tr\">\n<td id=\"S5.T2.2.5.4.1\" class=\"ltx_td ltx_align_left ltx_border_t\">0.05</td>\n<td id=\"S5.T2.2.5.4.2\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S5.T2.2.5.4.2.1\" class=\"ltx_text ltx_font_bold\">0.972</span></td>\n<td id=\"S5.T2.2.5.4.3\" class=\"ltx_td ltx_align_left ltx_border_t\">0.853</td>\n<td id=\"S5.T2.2.5.4.4\" class=\"ltx_td ltx_align_left ltx_border_t\">0.455</td>\n<td id=\"S5.T2.2.5.4.5\" class=\"ltx_td ltx_align_left ltx_border_t\">0.3640</td>\n</tr>\n<tr id=\"S5.T2.2.6.5\" class=\"ltx_tr\">\n<td id=\"S5.T2.2.6.5.1\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">0.1</td>\n<td id=\"S5.T2.2.6.5.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">0.953</td>\n<td id=\"S5.T2.2.6.5.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">0.901</td>\n<td id=\"S5.T2.2.6.5.4\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">0.457</td>\n<td id=\"S5.T2.2.6.5.5\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">0.447</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Table II shows the accuracy values of the autoencoder part (that is, using AE/VAE) considering different lr, marking in bold the best lr for each method. According to the results, we best value obtained is for VAE when l‚Äãr=0.05ùëôùëü0.05lr=0.05. In particular, considering the best case for each setting, the federated VAE reaches a value of 0.972 (lr = 0.05), whereas the distributed VAE, federated AE, and distributed AE reach 0.928 (lr = 0.001), 0.923 (lr = 0.005), and 0.936 (lr= 0.005) respectively. Comparing the performance in particular of the best cases of federated VAE and federated AE, in Fig. 6, we compare the accuracy of each client specifically. In this figure, we see that in almost all clients, the VAE reaches better performance than the AE. Having set the best lr for the VAE, Fig. 7 shows the final metrics of the general model, that is, considering the metrics obtained by applying GMM and the VAE. The accuracy of the model is 0.824, and the recall, precision, and f1-score are 0.968, 0.672, and 0.775 respectively."
        ]
    },
    "S5.T3": {
        "caption": "TABLE III: Time comparison (in seconds) of the main processes of our approach depending on the number of GMM components, and accuracy",
        "table": "<table id=\"S5.T3.2\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T3.2.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T3.2.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\"><span id=\"S5.T3.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Number of components</span></th>\n<td id=\"S5.T3.2.1.1.2\" class=\"ltx_td ltx_align_left\"><span id=\"S5.T3.2.1.1.2.1\" class=\"ltx_text ltx_font_bold\">10</span></td>\n<td id=\"S5.T3.2.1.1.3\" class=\"ltx_td ltx_align_left\"><span id=\"S5.T3.2.1.1.3.1\" class=\"ltx_text ltx_font_bold\">100</span></td>\n<td id=\"S5.T3.2.1.1.4\" class=\"ltx_td ltx_align_left\"><span id=\"S5.T3.2.1.1.4.1\" class=\"ltx_text ltx_font_bold\">200</span></td>\n<td id=\"S5.T3.2.1.1.5\" class=\"ltx_td ltx_align_left\"><span id=\"S5.T3.2.1.1.5.1\" class=\"ltx_text ltx_font_bold\">300</span></td>\n</tr>\n<tr id=\"S5.T3.2.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T3.2.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S5.T3.2.2.2.1.1\" class=\"ltx_text ltx_font_bold\">Silhouette analysis</span></th>\n<td id=\"S5.T3.2.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">947</td>\n<td id=\"S5.T3.2.2.2.3\" class=\"ltx_td ltx_align_left ltx_border_t\">21357</td>\n<td id=\"S5.T3.2.2.2.4\" class=\"ltx_td ltx_align_left ltx_border_t\">54298</td>\n<td id=\"S5.T3.2.2.2.5\" class=\"ltx_td ltx_align_left ltx_border_t\">110132</td>\n</tr>\n<tr id=\"S5.T3.2.3.3\" class=\"ltx_tr\">\n<th id=\"S5.T3.2.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S5.T3.2.3.3.1.1\" class=\"ltx_text ltx_font_bold\">Training GMM</span></th>\n<td id=\"S5.T3.2.3.3.2\" class=\"ltx_td ltx_align_left ltx_border_t\">15</td>\n<td id=\"S5.T3.2.3.3.3\" class=\"ltx_td ltx_align_left ltx_border_t\">50</td>\n<td id=\"S5.T3.2.3.3.4\" class=\"ltx_td ltx_align_left ltx_border_t\">202</td>\n<td id=\"S5.T3.2.3.3.5\" class=\"ltx_td ltx_align_left ltx_border_t\">236</td>\n</tr>\n<tr id=\"S5.T3.2.4.4\" class=\"ltx_tr\">\n<th id=\"S5.T3.2.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S5.T3.2.4.4.1.1\" class=\"ltx_text ltx_font_bold\">Training RBM</span></th>\n<td id=\"S5.T3.2.4.4.2\" class=\"ltx_td ltx_align_left ltx_border_t\">28</td>\n<td id=\"S5.T3.2.4.4.3\" class=\"ltx_td ltx_align_left ltx_border_t\">286</td>\n<td id=\"S5.T3.2.4.4.4\" class=\"ltx_td ltx_align_left ltx_border_t\">1028</td>\n<td id=\"S5.T3.2.4.4.5\" class=\"ltx_td ltx_align_left ltx_border_t\">2122</td>\n</tr>\n<tr id=\"S5.T3.2.5.5\" class=\"ltx_tr\">\n<th id=\"S5.T3.2.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S5.T3.2.5.5.1.1\" class=\"ltx_text ltx_font_bold\">Accuracy</span></th>\n<td id=\"S5.T3.2.5.5.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">0.62</td>\n<td id=\"S5.T3.2.5.5.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">0.705</td>\n<td id=\"S5.T3.2.5.5.4\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">0.783</td>\n<td id=\"S5.T3.2.5.5.5\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">0.824</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "In order to justify the grid of GMM components chosen in Section IV, Table III provides a comparison of the time consumed by the principal processes of our approach depending on the number of the GMM components and the accuracy achieved. As the number of components increases, the time required is higher, especially because of the silhouette analysis. Nevertheless, although the accuracy also grows, the increase of each step is getting lower, from 0.62 to 0.824. Hence, we set the maximum number of components of the grid at 300, since a wider range will consume an enormous amount of time for a reduced improvement in terms of accuracy."
        ]
    }
}