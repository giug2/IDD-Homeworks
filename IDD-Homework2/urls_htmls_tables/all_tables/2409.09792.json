{
    "id_table_1": {
        "caption": "Table 1:  Basic statistical information on financial risk datasets.",
        "table": "S3.E14",
        "footnotes": [],
        "references": [
            "A crucial aspect of managing individual customers in current financial institutions revolves around customer financial risk management, which primarily encompasses two categories of risk events: credit default and credit fraud. Credit default occurs when clients cannot repay loans, leading to financial institutions incurring losses on unpaid loan principal and interest  [ 17 ] . On the other hand, credit fraud involves unauthorized transactions such as credit card fraud, identity theft, and account takeovers. These not only lead to direct economic losses for both clients and financial institutions but also significantly impact client loyalty towards the institutions and can generate negative publicity, causing multiple losses. Therefore, it is essential to develop effective customer financial risk management models to mitigate the impact of such risk events on financial institutions. However, whether relying on statistical models or modern deep learning models, there is a significant reliance on high-quality data, while they faced three main challenges: insufficient samples  [ 7 ] , class imbalance  [ 13 ] , and high labeling costs  [ 19 ] , as shown in Figure  1 . In particular, the issue of class imbalance is critical, as the losses from a single negative case often outweigh the profits from several positive cases  [ 4 ,  5 ,  17 ] . Consequently, addressing class imbalance is a fundamental concern in customer financial risk management.",
            "Meta-synthetic-data learning initially partitions the dataset  D D D italic_D  into a sub-training set and validation set, i.e.,  D = D t  r  D v  a  l D superscript D t r superscript D v a l D={D^{tr}\\cup D^{val}} italic_D = italic_D start_POSTSUPERSCRIPT italic_t italic_r end_POSTSUPERSCRIPT  italic_D start_POSTSUPERSCRIPT italic_v italic_a italic_l end_POSTSUPERSCRIPT . For each predefined data synthesis technique, we utilize  D t  r superscript D t r D^{tr} italic_D start_POSTSUPERSCRIPT italic_t italic_r end_POSTSUPERSCRIPT  to generate synthetic data  D s  y  n superscript D s y n D^{syn} italic_D start_POSTSUPERSCRIPT italic_s italic_y italic_n end_POSTSUPERSCRIPT , which is then merged with the sub-training set data to form an augmented dataset  D aug subscript D aug D_{\\text{aug}} italic_D start_POSTSUBSCRIPT aug end_POSTSUBSCRIPT . Subsequently, we train a model  M M M italic_M  on this augmented dataset and evaluate it on the validation set  D val subscript D val D_{\\text{val}} italic_D start_POSTSUBSCRIPT val end_POSTSUBSCRIPT  to obtain the F1 scores for each technique. After systematically evaluating all candidate techniques, we select the technique with the highest F1 score. Subsequently, we integrate the samples correctly classified by model  M M M italic_M  on the validation set  D val subscript D val D_{\\text{val}} italic_D start_POSTSUBSCRIPT val end_POSTSUBSCRIPT  into the augmented dataset  D aug subscript D aug D_{\\text{aug}} italic_D start_POSTSUBSCRIPT aug end_POSTSUBSCRIPT  generated by this technique, updating  D aug subscript D aug D_{\\text{aug}} italic_D start_POSTSUBSCRIPT aug end_POSTSUBSCRIPT . Finally, we return  D aug subscript D aug D_{\\text{aug}} italic_D start_POSTSUBSCRIPT aug end_POSTSUBSCRIPT  along with the misclassified samples  D mis subscript D mis D_{\\text{mis}} italic_D start_POSTSUBSCRIPT mis end_POSTSUBSCRIPT  from the validation set.  D mis subscript D mis D_{\\text{mis}} italic_D start_POSTSUBSCRIPT mis end_POSTSUBSCRIPT  will be utilized for further data enhancement in the data filtering block of the TriEnhance method. Pseudocode can be found in Algorithm  1 . The algorithms core is the dynamic selection of the optimal data synthesis technique, like SMOTE or CTGAN. This performance-based approach not only leverages existing technologies but also adapts to future advancements, allowing TriEnhance to adjust to real-world data variability.",
            "We utilized six financial risk datasets from Kaggle and the UCI Machine Learning Repository to validate the effectiveness of TriEnhance. The basic statistical information of the datasets is listed in Table  1 , where IR represents the imbalance ratio of each dataset. To ensure the validation of TriEnhances effectiveness under a uniform standard, we applied consistent preprocessing steps to all datasets: (1) removing columns with more than  50 % percent 50 50\\% 50 %  missing data and filling the remaining missing values with the mode of each respective column; (2) encoding non-numeric features with label encoding."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Ablation study of TriEnhance in ZCD",
        "table": "S4.T1.1",
        "footnotes": [],
        "references": [
            "To address the challenges of accurately predicting minority class samples in imbalanced data settings, we introduce the TriEnhance, a data enhancement framework, as shown in Figure  2 . This comprehensive strategy enhances the models ability to detect minority class occurrences by incorporating data synthesis, dynamic data filtering, and innovative self-learning techniques. Initially, the data synthesis block utilizes an adaptive algorithm to assess techniques like SMOTE and CTGAN based on the F1 score, facilitating automatic selection to enhance the representation and diversity of minority categories. Subsequently, the data filtering block dynamically adjusts the difficulty threshold based on supervisory signals from the data synthesis block, effectively eliminating noise and challenging samples. Lastly, the self-learning block leverages unlabeled data through the  K - F old  U nknown- l abel  F iltering algorithm, KFULF, a novel approach for filtering unknown labels using a K-fold pseudo-label method and a pseudo-label strategy guided by sample confidence ranking.",
            "We now investigate the impact of each proposed block in TriEnhance. The experiment results presented in Table  2 , are based on the Zhongyuan Credit Dataset (ZCD). We correspondingly examine three variants of Trienhance, including: w/o sl+fil\" removes the data filtering block and self-learning block; w/o sl\" removes the self-learning block; and w/o fil\" removes the data filtering block. Specifically, we present two extra variants on model w/o fil\" as: w/o fil w. KFULF\" only reserves the KFULF strategy in the self-learning block, and w/o fil w. DDS\" only reserves the DDS strategy in the self-learning block. Our findings reveal that (1) removing any of these components leads to a degradation in model performance, underscoring the positive contribution of all blocks; (2) eliminating the self-learning block and data filtering block results in the most significant performance decline, highlighting their complementary nature; (3) the proposed KFULF strategy performs well than DDS on four classic models, demonstrating its superiority."
        ]
    },
    "id_table_3": {
        "caption": "",
        "table": "S4.T2.72.72",
        "footnotes": [],
        "references": [
            "The data synthesis block aims to enhance the models ability to recognize minority classes in imbalanced datasets by increasing the number of minority class samples. Specifically, this module employs an adaptive algorithm based on the F1 score to evaluate various data synthesis techniques, including SMOTE and CTGAN. This enables the algorithm to automatically select the best-performing technique, ensuring that TriEnhance can choose the optimal synthesis strategy for various financial risk datasets. This method improves the representation of minority classes, ultimately enhancing the models prediction accuracy for these classes. The distribution of the original data after processing through the Data Synthesis Block is shown in Figure  3 ."
        ]
    }
}