{
    "S4.T1": {
        "caption": "Table 1: Final-testing performance for different regression meta learning strategies (MSE).",
        "table": null,
        "footnotes": [],
        "references": [
            "For meta-testing each task has only a few-shots Kâˆˆ{4,6,8}ğ¾468K\\in\\{4,6,8\\} pairs of (x,y)ğ‘¥ğ‘¦(x,y) for training. We generate 100100100 new testing tasks in total, and for each generate 100100100 testing samples on which to evaluate the final-testing MSE. We repeat every adapting round (corresponding to a task) 101010 times with different (x,y)ğ‘¥ğ‘¦(x,y) pairs, so one testing task has 101010 MSE values on the same out-of-sample set. The mean and standard deviation of all tasksâ€™ MSEs are summarised in TableÂ 1. For our method we also explore semi-supervised learning using unlabelled xğ‘¥x. In real-world problems these would correspond to unlabelled instances, but for this synthetic problem, we simply uniformly sample xâˆ¼[âˆ’5,5]similar-toğ‘¥55x\\sim\\left[-5,5\\right]. We can see that our meta-critic performs comparably or better than alternatives. Here we also evaluate Meta-Critic-SL: our method where the meta-testing actor is pre-trained with standard supervised learning before training by the meta-critic. The similar performance of these two variants shows that via the shared meta-critic, a good performing actor can be obtained by learning from scratch, without requiring any pre-training.",
            "For qualitative illustration, we randomly pick tasks for K=4ğ¾4K=4 shot learning from sinusoid only condition and line+sinusoid mixture condition, as shown in Fig.Â 2. We see that all models fit the K=4ğ¾4K=4 shot meta-testing data. In the sin-only condition (Fig.Â 2(a)) MAML is not much worse than meta-critic in the out-of-sample areas. However, in the mixture condition (Fig.Â 2(b)), MAML is much worse than meta-critic. The reason is that a single globally shared prior/initialisation parameter implicitly assumes that tasks are similar, and their distribution is uni-modal. In the mixture case where tasks are diversely distributed and with varying relatedness, then this assumption is too strong and performance is poor. We increased the number of parameters for the actor network in MAML so that there was ample capacity for learning a complex multi-modal model, but it didnâ€™t help. In contrast, our meta-critic approach is flexible enough to model this multi-modal task-distribution and learns to supervise the actor appropriately. These qualitative results are reflected quantitatively in TableÂ 1, where we see that MAML and Meta-Critic perform comparably â€“ and better than Standard/All-Fine-Tune â€“ in the Sin only condition, but Meta-Critic is clearly better in the mixture condition. This is because the TAEN successfully learns to embed task category information in its task description zğ‘§z. Taking the zğ‘§zs for all the tasks in the mixture condition, we find that a simple classifier (SVM with RBF kernel) can obtain 85%percent8585\\% accuracy in predicting the task category (linear vs sinusoid)."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Different meta-learning strategies for dependent multi-arm bandit. Reward in final-testing.",
        "table": null,
        "footnotes": [],
        "references": [
            "The results are shown in TableÂ 2, quantified by average reward which is calculated by the dot product of its softmax output and the banditâ€™s configuration (probability of getting a reward by pulling each arm). The Upper bound is calculated by always pulling the arm with largest probability of getting reward, which is 0.750.750.75 for 2-arm, 0.520.520.52 for 4-arm, and 0.410.410.41 for 6-arm. The random choice lower bound is always equal to 1Num. of Arms1Num. of Arms\\frac{1}{\\text{Num. of Arms}}. Our meta-critic strategy achieves higher reward than competitors for any given number of trials."
        ]
    }
}