{
    "PAPER'S NUMBER OF TABLES": 13,
    "S4.T1": {
        "caption": "",
        "table": "",
        "footnotes": "\n\n\n\n\nDataset\nK=10𝐾10K=10, C=10𝐶10C=10\nK=20𝐾20K=20, C=20𝐶20C=20\nK=30𝐾30K=30, C=30𝐶30C=30\n\nCifar-10\n92.86%percent\\%\n92.93%percent\\%\n92.12%percent\\%\n\nSVHN\n95.49%percent\\%\n94.99%percent\\%\n78.77%percent\\% (94.93%∗)\n\n\nK=10𝐾10K=10, C=10𝐶10C=10\nK=20𝐾20K=20, C=10𝐶10C=10\nK=30𝐾30K=30, C=10𝐶10C=10\n\nCifar-10\n92.86%percent\\%\n93.19%percent\\%\n92.84%percent\\%\n\nSVHN\n95.49%percent\\%\n95.43%percent\\%\n93.56%percent\\%\n\n",
        "references": [
            "As can be seen from the top of Tab. 1, increasing the number of users K𝐾K has a marginal effect (<<1%) on the accuracy, from K=10𝐾10K=10 to K=30𝐾30K=30.\nOne notable thing here is that with K=30𝐾30K=30, if we train 40 epochs on SVHN, the accuracy is 78.77%, which is 16.72% lower than K=10𝐾10K=10.\nIf we increase the training epochs from 40 to 120 for K=30𝐾30K=30 on SVHN, the final accuracy is 94.93%. One can refer to Fig. C.1 for the convergence curve of this experiment.",
            "In this subsection, we compare our grouping-based method with other FL algorithms, in both semi-supervised and supervised settings.\nFirst, in the semi-supervised setting, we conduct the experiment on Cifar-10 with exactly the same setting as a recent SSFL paper [9].\nFor the Cifar-10 data, according to Table 1 in [9], we set Ns=5000subscript𝑁𝑠5000N_{s}=5000, K=100𝐾100K=100, C=5𝐶5C=5, and R=0𝑅0R=0 (which is the iid case) or R=1𝑅1R=1 (which is the most difficult non-iid case).\nFrom Tab. 3, one can see that our grouping-based solution outperforms the method proposed in [9] by a large margin.\nWe notice that the results in [9] are presented in two different settings including the labels-at-server setting and the labels-at-client setting.\nThe first setting is the same as our paper, i.e., only the server has labeled data, while the users have unlabeled data.\nIn this setting, Ns=5000subscript𝑁𝑠5000N_{s}=5000 labeled data are own by the server.\nThe second setting is different but it is straightforward to apply our grouping-based solution.\nIn this setting, Ns=5000subscript𝑁𝑠5000N_{s}=5000 labeled data are distributed to 100 users. In each round, C=5𝐶5C=5 users are random selected to communicate with the server.\nSee Appendix H for the details of adapting our solution to the label-at-the-client setting.",
            "There are other important issues we consider.\nFor example, we evaluate the performance of our grouping-based method in fully supervised FL in § F, and we show that the improvement in this scenario is limited. Thus, our method is more suitable in the SSFL setting.\nWe also compare our grouping-based solution with FixMatch [11] in § G).\nWe show that our results are comparable to FixMatch even if FixMatch uses centralized setting.\nMoreover, we extend our current methods to the setting where users can have both labeled and unlabeled samples in § H, i.e., the labels-at-client case.\nWe also provide additional results on another semi-supervised dataset STL-10, see § I.\nFinally, since for federated learning, we are interested in studying what happens when the number of users is large, we provide an additional experiment with the number of users set to 470 in § J. We show that the grouping-based method outperforms FedAvg in this setting as well.",
            "Federated learning.\nFederated learning (FL) [1, 2, 4, 27, 16, 28, 29, 30, 18, 31] is a decentralized computing framework that enables multiple users to learn a shared model while potentially protecting the privacy of users (although recent work [32] shows this may not be the case).\nFederated Averaging (FedAvg) [2], which is the most popular FL algorithm, shows good performance when the data distribution across users is iid.\nHowever, in the non-iid case, the performance can significantly degrade.\nIn fact, dealing with non-iid distributions is deemed by many to be one of the most critical challenges in FL [16, 28, 33].\nIn [16], a data-sharing method is proposed to improve the final accuracy.\nHowever, sharing massive data among all users requires both large storage space as well as stable connections between users and the server.\nImportantly, all of these methods require the data stored by the local users to come with ground-truth labels (in order to perform model updates locally).\nThe FL problem in the semi-supervised setting, when users do not have labels, however, is “relatively ignored” and has “little prior arts,” as mentioned in a recent survey paper [4].",
            "In this section, we study whether the grouping-based averaging can be extended to supervised FL (SFL). We want to see whether this particular way of averaging is more suitable for the semi-supervised setup or the supervised setup.\nWe conduct experiments on EMNIST using SFL with three different settings with different number of users K∈{47,20,10}𝐾472010K\\in\\{47,20,10\\}. In these three settings, we let C=K𝐶𝐾C=K.\nThe other environmental factors are shown in rows 32-34 of Tab. A.2.\nWe set the group number S=5𝑆5S=5, S=2𝑆2S=2 and S=2𝑆2S=2 for the setting of K=47𝐾47K=47, K=20𝐾20K=20 and K=10𝐾10K=10, respectively.\nSee Table F.1.\nThe results show that the performance of the grouping method is only slightly better than that of FedAvg.\nThus, the performance gain of the grouping-based averaging method for SFL is much less than that of SSFL. This mean that grouping-based averaging is more suitable for the semi-supervised setup than the supervised setup.",
            "The results in Table J.1 show that the performance of the grouping-based averaging is better than that of FedAvg even with 470 users. One can also observe that as the number of communicating users C𝐶C increases, the performance of the FedAvg decreases, which is consistent with the experimental phenomenon observed in § 4.2."
        ]
    },
    "S4.T2": {
        "caption": "",
        "table": "",
        "footnotes": "\n\n\n\n\nDataset\n\n\n\nK=47𝐾47K=47\n\nC=10𝐶10C=10\n\n\n\n\nK=47𝐾47K=47\n\nC=30𝐶30C=30\n\n\n\n\nK=47𝐾47K=47\n\nC=47𝐶47C=47\n\n\nEMNIST (FedAvg)\n83.07%percent\\%\n79.05%percent\\%\n65.48%percent\\%\n\nEMNIST (Grouping-based)\n84.43%percent\\%\n83.12%percent\\%\n82.95%percent\\%\n\n",
        "references": [
            "As can be seen from the top of Tab. 1, increasing the number of users K𝐾K has a marginal effect (<<1%) on the accuracy, from K=10𝐾10K=10 to K=30𝐾30K=30.\nOne notable thing here is that with K=30𝐾30K=30, if we train 40 epochs on SVHN, the accuracy is 78.77%, which is 16.72% lower than K=10𝐾10K=10.\nIf we increase the training epochs from 40 to 120 for K=30𝐾30K=30 on SVHN, the final accuracy is 94.93%. One can refer to Fig. C.1 for the convergence curve of this experiment.",
            "In this subsection, we compare our grouping-based method with other FL algorithms, in both semi-supervised and supervised settings.\nFirst, in the semi-supervised setting, we conduct the experiment on Cifar-10 with exactly the same setting as a recent SSFL paper [9].\nFor the Cifar-10 data, according to Table 1 in [9], we set Ns=5000subscript𝑁𝑠5000N_{s}=5000, K=100𝐾100K=100, C=5𝐶5C=5, and R=0𝑅0R=0 (which is the iid case) or R=1𝑅1R=1 (which is the most difficult non-iid case).\nFrom Tab. 3, one can see that our grouping-based solution outperforms the method proposed in [9] by a large margin.\nWe notice that the results in [9] are presented in two different settings including the labels-at-server setting and the labels-at-client setting.\nThe first setting is the same as our paper, i.e., only the server has labeled data, while the users have unlabeled data.\nIn this setting, Ns=5000subscript𝑁𝑠5000N_{s}=5000 labeled data are own by the server.\nThe second setting is different but it is straightforward to apply our grouping-based solution.\nIn this setting, Ns=5000subscript𝑁𝑠5000N_{s}=5000 labeled data are distributed to 100 users. In each round, C=5𝐶5C=5 users are random selected to communicate with the server.\nSee Appendix H for the details of adapting our solution to the label-at-the-client setting.",
            "There are other important issues we consider.\nFor example, we evaluate the performance of our grouping-based method in fully supervised FL in § F, and we show that the improvement in this scenario is limited. Thus, our method is more suitable in the SSFL setting.\nWe also compare our grouping-based solution with FixMatch [11] in § G).\nWe show that our results are comparable to FixMatch even if FixMatch uses centralized setting.\nMoreover, we extend our current methods to the setting where users can have both labeled and unlabeled samples in § H, i.e., the labels-at-client case.\nWe also provide additional results on another semi-supervised dataset STL-10, see § I.\nFinally, since for federated learning, we are interested in studying what happens when the number of users is large, we provide an additional experiment with the number of users set to 470 in § J. We show that the grouping-based method outperforms FedAvg in this setting as well.",
            "Federated learning.\nFederated learning (FL) [1, 2, 4, 27, 16, 28, 29, 30, 18, 31] is a decentralized computing framework that enables multiple users to learn a shared model while potentially protecting the privacy of users (although recent work [32] shows this may not be the case).\nFederated Averaging (FedAvg) [2], which is the most popular FL algorithm, shows good performance when the data distribution across users is iid.\nHowever, in the non-iid case, the performance can significantly degrade.\nIn fact, dealing with non-iid distributions is deemed by many to be one of the most critical challenges in FL [16, 28, 33].\nIn [16], a data-sharing method is proposed to improve the final accuracy.\nHowever, sharing massive data among all users requires both large storage space as well as stable connections between users and the server.\nImportantly, all of these methods require the data stored by the local users to come with ground-truth labels (in order to perform model updates locally).\nThe FL problem in the semi-supervised setting, when users do not have labels, however, is “relatively ignored” and has “little prior arts,” as mentioned in a recent survey paper [4].",
            "In this section, we study whether the grouping-based averaging can be extended to supervised FL (SFL). We want to see whether this particular way of averaging is more suitable for the semi-supervised setup or the supervised setup.\nWe conduct experiments on EMNIST using SFL with three different settings with different number of users K∈{47,20,10}𝐾472010K\\in\\{47,20,10\\}. In these three settings, we let C=K𝐶𝐾C=K.\nThe other environmental factors are shown in rows 32-34 of Tab. A.2.\nWe set the group number S=5𝑆5S=5, S=2𝑆2S=2 and S=2𝑆2S=2 for the setting of K=47𝐾47K=47, K=20𝐾20K=20 and K=10𝐾10K=10, respectively.\nSee Table F.1.\nThe results show that the performance of the grouping method is only slightly better than that of FedAvg.\nThus, the performance gain of the grouping-based averaging method for SFL is much less than that of SSFL. This mean that grouping-based averaging is more suitable for the semi-supervised setup than the supervised setup.",
            "The results in Table J.1 show that the performance of the grouping-based averaging is better than that of FedAvg even with 470 users. One can also observe that as the number of communicating users C𝐶C increases, the performance of the FedAvg decreases, which is consistent with the experimental phenomenon observed in § 4.2."
        ]
    },
    "S4.T3": {
        "caption": "Table 3: Comparing with [9] in exactly the same setting on Cifar-10. The model in [9] is ResNet-9.\n",
        "table": "<table id=\"S4.T3.3\" class=\"ltx_tabular ltx_centering ltx_align_top\">\n<tr id=\"S4.T3.3.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.3.1.1\" class=\"ltx_td ltx_border_tt\"></td>\n<td id=\"S4.T3.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">FedMatch</td>\n<td id=\"S4.T3.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">Ours</td>\n</tr>\n<tr id=\"S4.T3.3.2\" class=\"ltx_tr\" style=\"background-color:#FFCC99;\">\n<td id=\"S4.T3.3.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S4.T3.3.2.1.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">Labels-at-client (iid)</span></td>\n<td id=\"S4.T3.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T3.3.2.2.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">53.51%</span></td>\n<td id=\"S4.T3.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T3.3.2.3.1\" class=\"ltx_text ltx_font_bold\" style=\"background-color:#FFCC99;\">71.61%</span></td>\n</tr>\n<tr id=\"S4.T3.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T3.3.3.1\" class=\"ltx_td ltx_align_left\">Labels-at-client (non-iid)</td>\n<td id=\"S4.T3.3.3.2\" class=\"ltx_td ltx_align_center\">54.26%</td>\n<td id=\"S4.T3.3.3.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.3.3.3.1\" class=\"ltx_text ltx_font_bold\">69.05%</span></td>\n</tr>\n<tr id=\"S4.T3.3.4\" class=\"ltx_tr\" style=\"background-color:#FFCC99;\">\n<td id=\"S4.T3.3.4.1\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T3.3.4.1.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">Labels-at-server (iid)</span></td>\n<td id=\"S4.T3.3.4.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.3.4.2.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">46.81%</span></td>\n<td id=\"S4.T3.3.4.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.3.4.3.1\" class=\"ltx_text ltx_font_bold\" style=\"background-color:#FFCC99;\">63.32%</span></td>\n</tr>\n<tr id=\"S4.T3.3.5\" class=\"ltx_tr\">\n<td id=\"S4.T3.3.5.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">Labels-at-server (non-iid)</td>\n<td id=\"S4.T3.3.5.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">47.11%</td>\n<td id=\"S4.T3.3.5.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T3.3.5.3.1\" class=\"ltx_text ltx_font_bold\">63.24%</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In this subsection, we compare our grouping-based method with other FL algorithms, in both semi-supervised and supervised settings.\nFirst, in the semi-supervised setting, we conduct the experiment on Cifar-10 with exactly the same setting as a recent SSFL paper ",
                "[",
                "9",
                "]",
                ".\nFor the Cifar-10 data, according to Table 1 in ",
                "[",
                "9",
                "]",
                ", we set ",
                "N",
                "s",
                "=",
                "5000",
                "subscript",
                "𝑁",
                "𝑠",
                "5000",
                "N_{s}=5000",
                ", ",
                "K",
                "=",
                "100",
                "𝐾",
                "100",
                "K=100",
                ", ",
                "C",
                "=",
                "5",
                "𝐶",
                "5",
                "C=5",
                ", and ",
                "R",
                "=",
                "0",
                "𝑅",
                "0",
                "R=0",
                " (which is the iid case) or ",
                "R",
                "=",
                "1",
                "𝑅",
                "1",
                "R=1",
                " (which is the most difficult non-iid case).\nFrom Tab. ",
                "3",
                ", one can see that our grouping-based solution outperforms the method proposed in ",
                "[",
                "9",
                "]",
                " by a large margin.\nWe notice that the results in ",
                "[",
                "9",
                "]",
                " are presented in two different settings including the ",
                "labels-at-server",
                " setting and the ",
                "labels-at-client",
                " setting.\nThe first setting is the same as our paper, i.e., only the server has labeled data, while the users have unlabeled data.\nIn this setting, ",
                "N",
                "s",
                "=",
                "5000",
                "subscript",
                "𝑁",
                "𝑠",
                "5000",
                "N_{s}=5000",
                " labeled data are own by the server.\nThe second setting is different but it is straightforward to apply our grouping-based solution.\nIn this setting, ",
                "N",
                "s",
                "=",
                "5000",
                "subscript",
                "𝑁",
                "𝑠",
                "5000",
                "N_{s}=5000",
                " labeled data are distributed to 100 users. In each round, ",
                "C",
                "=",
                "5",
                "𝐶",
                "5",
                "C=5",
                " users are random selected to communicate with the server.\nSee Appendix ",
                "H",
                " for the details of adapting our solution to the label-at-the-client setting.",
                "We also compare our solution with supervised FL methods in Tab. ",
                "4",
                ".\nWe choose two supervised FL methods for comparison: Supervised FedAvg ",
                "[",
                "2",
                "]",
                " and DataSharing ",
                "[",
                "16",
                "]",
                ".\nWe set ",
                "K",
                "=",
                "10",
                "𝐾",
                "10",
                "K=10",
                ", ",
                "C",
                "=",
                "10",
                "𝐶",
                "10",
                "C=10",
                " and ",
                "T",
                "=",
                "32",
                "𝑇",
                "32",
                "T=32",
                ", and we use ResNet-18 to be the model for training.\nThe non-iid setting of DataSharing ",
                "[",
                "16",
                "]",
                " corresponds to the scenario where we set ",
                "R",
                "=",
                "0.29",
                "𝑅",
                "0.29",
                "R=0.29",
                ".\nFor our solutions, we set ",
                "N",
                "s",
                "=",
                "1000",
                "subscript",
                "𝑁",
                "𝑠",
                "1000",
                "N_{s}=1000",
                " and ",
                "R",
                "=",
                "0.4",
                "𝑅",
                "0.4",
                "R=0.4",
                ". The detailed experimental parameters of different methods can be seen from rows 22-25 of Tab. ",
                "A.2",
                ".\nLarger ",
                "R",
                "𝑅",
                "R",
                " means a higher non-iid level and thus a more difficult scenario (which we have experimentally demonstrated in Fig. ",
                "5",
                "). From Tab. ",
                "4",
                " we see that the performance of our method (",
                "R",
                "=",
                "0.4",
                "𝑅",
                "0.4",
                "R=0.4",
                ") on Cifar-10 is still better than Supervised FedAvg (",
                "R",
                "=",
                "0.29",
                "𝑅",
                "0.29",
                "R=0.29",
                ") and DataSharing methods (",
                "R",
                "=",
                "0.29",
                "𝑅",
                "0.29",
                "R=0.29",
                ") even when the scenario of ",
                "R",
                "=",
                "0.4",
                "𝑅",
                "0.4",
                "R=0.4",
                " is more difficult.",
                "We also compare our method with EASGD ",
                "[",
                "14",
                "]",
                " and OverlapSGD ",
                "[",
                "15",
                "]",
                " which are communication efficient algorithms under supervised settings.\nWe use the same parameters in their papers, i.e., ",
                "K",
                "=",
                "16",
                "𝐾",
                "16",
                "K=16",
                ", ",
                "R",
                "=",
                "0.4",
                "𝑅",
                "0.4",
                "R=0.4",
                ", ",
                "C",
                "=",
                "16",
                "𝐶",
                "16",
                "C=16",
                " and ",
                "N",
                "s",
                "=",
                "1000",
                "subscript",
                "𝑁",
                "𝑠",
                "1000",
                "N_{s}=1000",
                " on Cifar-10. See rows 26-29 of Tab. ",
                "A.2",
                " for the details.\nThe results are shown in Tab. ",
                "5",
                ".\nWe see that our result has better accuracy than both EASGD and OverlapSGD.\nParticularly, even with ",
                "T",
                "=",
                "32",
                "𝑇",
                "32",
                "T=32",
                " (larger ",
                "T",
                "𝑇",
                "T",
                " means a harder scenario; see Fig. ",
                "5",
                "), our method has 0.80% or 0.29% better performance, as compared to EASGD or OverlapSGD in the setting of ",
                "T",
                "=",
                "2",
                "𝑇",
                "2",
                "T=2",
                ", respectively.\nNote that both EASGD and OverlapSGD are supervised algorithms, which means they have all the data labels.",
                "There are other important issues we consider.\nFor example, we evaluate the performance of our grouping-based method in fully supervised FL in § ",
                "F",
                ", and we show that the improvement in this scenario is limited. Thus, our method is more suitable in the ",
                "SSFL",
                " setting.\nWe also compare our grouping-based solution with FixMatch ",
                "[",
                "11",
                "]",
                " in § ",
                "G",
                ").\nWe show that our results are comparable to FixMatch even if FixMatch uses centralized setting.\nMoreover, we extend our current methods to the setting where users can have both labeled and unlabeled samples in § ",
                "H",
                ", i.e., the labels-at-client case.\nWe also provide additional results on another semi-supervised dataset STL-10, see § ",
                "I",
                ".\nFinally, since for federated learning, we are interested in studying what happens when the number of users is large, we provide an additional experiment with the number of users set to 470 in § ",
                "J",
                ". We show that the grouping-based method outperforms FedAvg in this setting as well."
            ]
        ]
    },
    "S4.T4": {
        "caption": "Table 4: Comparison with supervised FL. Here, “∗” is calculated according to the setting in DataSharing.\n",
        "table": "<div id=\"S4.T4.8\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:211.4pt;height:72pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(0.0pt,0.0pt) scale(1,1) ;\">\n<p id=\"S4.T4.8.6\" class=\"ltx_p\"><span id=\"S4.T4.8.6.6\" class=\"ltx_text\">\n<span id=\"S4.T4.8.6.6.6\" class=\"ltx_tabular ltx_align_top\">\n<span id=\"S4.T4.8.6.6.6.7\" class=\"ltx_tr\">\n<span id=\"S4.T4.8.6.6.6.7.1\" class=\"ltx_td ltx_align_left ltx_border_tt\">Method</span>\n<span id=\"S4.T4.8.6.6.6.7.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">Test accuracy</span></span>\n<span id=\"S4.T4.4.2.2.2.2\" class=\"ltx_tr\">\n<span id=\"S4.T4.4.2.2.2.2.3\" class=\"ltx_td ltx_align_left ltx_border_t\">Supervised FedAvg</span>\n<span id=\"S4.T4.4.2.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">78.52<math id=\"S4.T4.3.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"S4.T4.3.1.1.1.1.1.m1.1a\"><mo id=\"S4.T4.3.1.1.1.1.1.m1.1.1\" xref=\"S4.T4.3.1.1.1.1.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.3.1.1.1.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T4.3.1.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T4.3.1.1.1.1.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.3.1.1.1.1.1.m1.1c\">\\%</annotation></semantics></math> (<math id=\"S4.T4.4.2.2.2.2.2.m2.1\" class=\"ltx_Math\" alttext=\"R=0.29\" display=\"inline\"><semantics id=\"S4.T4.4.2.2.2.2.2.m2.1a\"><mrow id=\"S4.T4.4.2.2.2.2.2.m2.1.1\" xref=\"S4.T4.4.2.2.2.2.2.m2.1.1.cmml\"><mi id=\"S4.T4.4.2.2.2.2.2.m2.1.1.2\" xref=\"S4.T4.4.2.2.2.2.2.m2.1.1.2.cmml\">R</mi><mo id=\"S4.T4.4.2.2.2.2.2.m2.1.1.1\" xref=\"S4.T4.4.2.2.2.2.2.m2.1.1.1.cmml\">=</mo><mn id=\"S4.T4.4.2.2.2.2.2.m2.1.1.3\" xref=\"S4.T4.4.2.2.2.2.2.m2.1.1.3.cmml\">0.29</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.4.2.2.2.2.2.m2.1b\"><apply id=\"S4.T4.4.2.2.2.2.2.m2.1.1.cmml\" xref=\"S4.T4.4.2.2.2.2.2.m2.1.1\"><eq id=\"S4.T4.4.2.2.2.2.2.m2.1.1.1.cmml\" xref=\"S4.T4.4.2.2.2.2.2.m2.1.1.1\"></eq><ci id=\"S4.T4.4.2.2.2.2.2.m2.1.1.2.cmml\" xref=\"S4.T4.4.2.2.2.2.2.m2.1.1.2\">𝑅</ci><cn type=\"float\" id=\"S4.T4.4.2.2.2.2.2.m2.1.1.3.cmml\" xref=\"S4.T4.4.2.2.2.2.2.m2.1.1.3\">0.29</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.4.2.2.2.2.2.m2.1c\">R=0.29</annotation></semantics></math>)</span></span>\n<span id=\"S4.T4.6.4.4.4.4\" class=\"ltx_tr\" style=\"background-color:#FFCC99;\">\n<span id=\"S4.T4.6.4.4.4.4.3\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T4.6.4.4.4.4.3.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">DataSharing</span></span>\n<span id=\"S4.T4.6.4.4.4.4.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.6.4.4.4.4.2.2\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">81.82<math id=\"S4.T4.5.3.3.3.3.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"S4.T4.5.3.3.3.3.1.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"S4.T4.5.3.3.3.3.1.1.m1.1.1\" xref=\"S4.T4.5.3.3.3.3.1.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.5.3.3.3.3.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T4.5.3.3.3.3.1.1.m1.1.1.cmml\" xref=\"S4.T4.5.3.3.3.3.1.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.5.3.3.3.3.1.1.m1.1c\">\\%</annotation></semantics></math> (<math id=\"S4.T4.6.4.4.4.4.2.2.m2.1\" class=\"ltx_Math\" alttext=\"R=0.29^{*}\" display=\"inline\"><semantics id=\"S4.T4.6.4.4.4.4.2.2.m2.1a\"><mrow id=\"S4.T4.6.4.4.4.4.2.2.m2.1.1\" xref=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.cmml\"><mi mathbackground=\"#FFCC99\" id=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.2\" xref=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.2.cmml\">R</mi><mo mathbackground=\"#FFCC99\" id=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.1\" xref=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.1.cmml\">=</mo><msup id=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.3\" xref=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.3.cmml\"><mn mathbackground=\"#FFCC99\" id=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.3.2\" xref=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.3.2.cmml\">0.29</mn><mo mathbackground=\"#FFCC99\" id=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.3.3\" xref=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.3.3.cmml\">∗</mo></msup></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.6.4.4.4.4.2.2.m2.1b\"><apply id=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.cmml\" xref=\"S4.T4.6.4.4.4.4.2.2.m2.1.1\"><eq id=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.1.cmml\" xref=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.1\"></eq><ci id=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.2.cmml\" xref=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.2\">𝑅</ci><apply id=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.3.cmml\" xref=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.3.1.cmml\" xref=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.3\">superscript</csymbol><cn type=\"float\" id=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.3.2.cmml\" xref=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.3.2\">0.29</cn><times id=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.3.3.cmml\" xref=\"S4.T4.6.4.4.4.4.2.2.m2.1.1.3.3\"></times></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.6.4.4.4.4.2.2.m2.1c\">R=0.29^{*}</annotation></semantics></math>)</span></span></span>\n<span id=\"S4.T4.8.6.6.6.6\" class=\"ltx_tr\">\n<span id=\"S4.T4.8.6.6.6.6.3\" class=\"ltx_td ltx_align_left ltx_border_bb\">Grouping-based (ours)</span>\n<span id=\"S4.T4.8.6.6.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T4.8.6.6.6.6.2.2\" class=\"ltx_text ltx_font_bold\">92.96<math id=\"S4.T4.7.5.5.5.5.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"S4.T4.7.5.5.5.5.1.1.m1.1a\"><mo id=\"S4.T4.7.5.5.5.5.1.1.m1.1.1\" xref=\"S4.T4.7.5.5.5.5.1.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.7.5.5.5.5.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T4.7.5.5.5.5.1.1.m1.1.1.cmml\" xref=\"S4.T4.7.5.5.5.5.1.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.7.5.5.5.5.1.1.m1.1c\">\\%</annotation></semantics></math> (<math id=\"S4.T4.8.6.6.6.6.2.2.m2.1\" class=\"ltx_Math\" alttext=\"R=0.4\" display=\"inline\"><semantics id=\"S4.T4.8.6.6.6.6.2.2.m2.1a\"><mrow id=\"S4.T4.8.6.6.6.6.2.2.m2.1.1\" xref=\"S4.T4.8.6.6.6.6.2.2.m2.1.1.cmml\"><mi id=\"S4.T4.8.6.6.6.6.2.2.m2.1.1.2\" xref=\"S4.T4.8.6.6.6.6.2.2.m2.1.1.2.cmml\">R</mi><mo id=\"S4.T4.8.6.6.6.6.2.2.m2.1.1.1\" xref=\"S4.T4.8.6.6.6.6.2.2.m2.1.1.1.cmml\">=</mo><mn id=\"S4.T4.8.6.6.6.6.2.2.m2.1.1.3\" xref=\"S4.T4.8.6.6.6.6.2.2.m2.1.1.3.cmml\">0.4</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.8.6.6.6.6.2.2.m2.1b\"><apply id=\"S4.T4.8.6.6.6.6.2.2.m2.1.1.cmml\" xref=\"S4.T4.8.6.6.6.6.2.2.m2.1.1\"><eq id=\"S4.T4.8.6.6.6.6.2.2.m2.1.1.1.cmml\" xref=\"S4.T4.8.6.6.6.6.2.2.m2.1.1.1\"></eq><ci id=\"S4.T4.8.6.6.6.6.2.2.m2.1.1.2.cmml\" xref=\"S4.T4.8.6.6.6.6.2.2.m2.1.1.2\">𝑅</ci><cn type=\"float\" id=\"S4.T4.8.6.6.6.6.2.2.m2.1.1.3.cmml\" xref=\"S4.T4.8.6.6.6.6.2.2.m2.1.1.3\">0.4</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.8.6.6.6.6.2.2.m2.1c\">R=0.4</annotation></semantics></math>)</span></span></span>\n</span></span></p>\n</span></div>\n\n",
        "footnotes": "\n\n\nMethod\nTest accuracy\n\nSupervised FedAvg\n78.52%percent\\% (R=0.29𝑅0.29R=0.29)\n\nDataSharing\n81.82%percent\\% (R=0.29∗𝑅superscript0.29R=0.29^{*})\n\nGrouping-based (ours)\n92.96%percent\\% (R=0.4𝑅0.4R=0.4)\n",
        "references": [
            [
                "In this subsection, we compare our grouping-based method with other FL algorithms, in both semi-supervised and supervised settings.\nFirst, in the semi-supervised setting, we conduct the experiment on Cifar-10 with exactly the same setting as a recent SSFL paper ",
                "[",
                "9",
                "]",
                ".\nFor the Cifar-10 data, according to Table 1 in ",
                "[",
                "9",
                "]",
                ", we set ",
                "N",
                "s",
                "=",
                "5000",
                "subscript",
                "𝑁",
                "𝑠",
                "5000",
                "N_{s}=5000",
                ", ",
                "K",
                "=",
                "100",
                "𝐾",
                "100",
                "K=100",
                ", ",
                "C",
                "=",
                "5",
                "𝐶",
                "5",
                "C=5",
                ", and ",
                "R",
                "=",
                "0",
                "𝑅",
                "0",
                "R=0",
                " (which is the iid case) or ",
                "R",
                "=",
                "1",
                "𝑅",
                "1",
                "R=1",
                " (which is the most difficult non-iid case).\nFrom Tab. ",
                "3",
                ", one can see that our grouping-based solution outperforms the method proposed in ",
                "[",
                "9",
                "]",
                " by a large margin.\nWe notice that the results in ",
                "[",
                "9",
                "]",
                " are presented in two different settings including the ",
                "labels-at-server",
                " setting and the ",
                "labels-at-client",
                " setting.\nThe first setting is the same as our paper, i.e., only the server has labeled data, while the users have unlabeled data.\nIn this setting, ",
                "N",
                "s",
                "=",
                "5000",
                "subscript",
                "𝑁",
                "𝑠",
                "5000",
                "N_{s}=5000",
                " labeled data are own by the server.\nThe second setting is different but it is straightforward to apply our grouping-based solution.\nIn this setting, ",
                "N",
                "s",
                "=",
                "5000",
                "subscript",
                "𝑁",
                "𝑠",
                "5000",
                "N_{s}=5000",
                " labeled data are distributed to 100 users. In each round, ",
                "C",
                "=",
                "5",
                "𝐶",
                "5",
                "C=5",
                " users are random selected to communicate with the server.\nSee Appendix ",
                "H",
                " for the details of adapting our solution to the label-at-the-client setting.",
                "We also compare our solution with supervised FL methods in Tab. ",
                "4",
                ".\nWe choose two supervised FL methods for comparison: Supervised FedAvg ",
                "[",
                "2",
                "]",
                " and DataSharing ",
                "[",
                "16",
                "]",
                ".\nWe set ",
                "K",
                "=",
                "10",
                "𝐾",
                "10",
                "K=10",
                ", ",
                "C",
                "=",
                "10",
                "𝐶",
                "10",
                "C=10",
                " and ",
                "T",
                "=",
                "32",
                "𝑇",
                "32",
                "T=32",
                ", and we use ResNet-18 to be the model for training.\nThe non-iid setting of DataSharing ",
                "[",
                "16",
                "]",
                " corresponds to the scenario where we set ",
                "R",
                "=",
                "0.29",
                "𝑅",
                "0.29",
                "R=0.29",
                ".\nFor our solutions, we set ",
                "N",
                "s",
                "=",
                "1000",
                "subscript",
                "𝑁",
                "𝑠",
                "1000",
                "N_{s}=1000",
                " and ",
                "R",
                "=",
                "0.4",
                "𝑅",
                "0.4",
                "R=0.4",
                ". The detailed experimental parameters of different methods can be seen from rows 22-25 of Tab. ",
                "A.2",
                ".\nLarger ",
                "R",
                "𝑅",
                "R",
                " means a higher non-iid level and thus a more difficult scenario (which we have experimentally demonstrated in Fig. ",
                "5",
                "). From Tab. ",
                "4",
                " we see that the performance of our method (",
                "R",
                "=",
                "0.4",
                "𝑅",
                "0.4",
                "R=0.4",
                ") on Cifar-10 is still better than Supervised FedAvg (",
                "R",
                "=",
                "0.29",
                "𝑅",
                "0.29",
                "R=0.29",
                ") and DataSharing methods (",
                "R",
                "=",
                "0.29",
                "𝑅",
                "0.29",
                "R=0.29",
                ") even when the scenario of ",
                "R",
                "=",
                "0.4",
                "𝑅",
                "0.4",
                "R=0.4",
                " is more difficult.",
                "We also compare our method with EASGD ",
                "[",
                "14",
                "]",
                " and OverlapSGD ",
                "[",
                "15",
                "]",
                " which are communication efficient algorithms under supervised settings.\nWe use the same parameters in their papers, i.e., ",
                "K",
                "=",
                "16",
                "𝐾",
                "16",
                "K=16",
                ", ",
                "R",
                "=",
                "0.4",
                "𝑅",
                "0.4",
                "R=0.4",
                ", ",
                "C",
                "=",
                "16",
                "𝐶",
                "16",
                "C=16",
                " and ",
                "N",
                "s",
                "=",
                "1000",
                "subscript",
                "𝑁",
                "𝑠",
                "1000",
                "N_{s}=1000",
                " on Cifar-10. See rows 26-29 of Tab. ",
                "A.2",
                " for the details.\nThe results are shown in Tab. ",
                "5",
                ".\nWe see that our result has better accuracy than both EASGD and OverlapSGD.\nParticularly, even with ",
                "T",
                "=",
                "32",
                "𝑇",
                "32",
                "T=32",
                " (larger ",
                "T",
                "𝑇",
                "T",
                " means a harder scenario; see Fig. ",
                "5",
                "), our method has 0.80% or 0.29% better performance, as compared to EASGD or OverlapSGD in the setting of ",
                "T",
                "=",
                "2",
                "𝑇",
                "2",
                "T=2",
                ", respectively.\nNote that both EASGD and OverlapSGD are supervised algorithms, which means they have all the data labels.",
                "There are other important issues we consider.\nFor example, we evaluate the performance of our grouping-based method in fully supervised FL in § ",
                "F",
                ", and we show that the improvement in this scenario is limited. Thus, our method is more suitable in the ",
                "SSFL",
                " setting.\nWe also compare our grouping-based solution with FixMatch ",
                "[",
                "11",
                "]",
                " in § ",
                "G",
                ").\nWe show that our results are comparable to FixMatch even if FixMatch uses centralized setting.\nMoreover, we extend our current methods to the setting where users can have both labeled and unlabeled samples in § ",
                "H",
                ", i.e., the labels-at-client case.\nWe also provide additional results on another semi-supervised dataset STL-10, see § ",
                "I",
                ".\nFinally, since for federated learning, we are interested in studying what happens when the number of users is large, we provide an additional experiment with the number of users set to 470 in § ",
                "J",
                ". We show that the grouping-based method outperforms FedAvg in this setting as well."
            ]
        ]
    },
    "S4.T5": {
        "caption": "Table 5: Comparison with two other supervised FL algorithms EASGD and OverlapSGD on Cifar-10.\n",
        "table": "<div id=\"S4.T5.12\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:243.2pt;height:72pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(0.0pt,0.0pt) scale(1,1) ;\">\n<p id=\"S4.T5.12.12\" class=\"ltx_p\"><span id=\"S4.T5.12.12.12\" class=\"ltx_text\">\n<span id=\"S4.T5.12.12.12.12\" class=\"ltx_tabular ltx_align_top\">\n<span id=\"S4.T5.3.3.3.3.3\" class=\"ltx_tr\">\n<span id=\"S4.T5.3.3.3.3.3.4\" class=\"ltx_td ltx_align_left ltx_border_tt\">Method</span>\n<span id=\"S4.T5.1.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\"><math id=\"S4.T5.1.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"T=2\" display=\"inline\"><semantics id=\"S4.T5.1.1.1.1.1.1.m1.1a\"><mrow id=\"S4.T5.1.1.1.1.1.1.m1.1.1\" xref=\"S4.T5.1.1.1.1.1.1.m1.1.1.cmml\"><mi id=\"S4.T5.1.1.1.1.1.1.m1.1.1.2\" xref=\"S4.T5.1.1.1.1.1.1.m1.1.1.2.cmml\">T</mi><mo id=\"S4.T5.1.1.1.1.1.1.m1.1.1.1\" xref=\"S4.T5.1.1.1.1.1.1.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T5.1.1.1.1.1.1.m1.1.1.3\" xref=\"S4.T5.1.1.1.1.1.1.m1.1.1.3.cmml\">2</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.1.1.1.1.1.1.m1.1b\"><apply id=\"S4.T5.1.1.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T5.1.1.1.1.1.1.m1.1.1\"><eq id=\"S4.T5.1.1.1.1.1.1.m1.1.1.1.cmml\" xref=\"S4.T5.1.1.1.1.1.1.m1.1.1.1\"></eq><ci id=\"S4.T5.1.1.1.1.1.1.m1.1.1.2.cmml\" xref=\"S4.T5.1.1.1.1.1.1.m1.1.1.2\">𝑇</ci><cn type=\"integer\" id=\"S4.T5.1.1.1.1.1.1.m1.1.1.3.cmml\" xref=\"S4.T5.1.1.1.1.1.1.m1.1.1.3\">2</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.1.1.1.1.1.1.m1.1c\">T=2</annotation></semantics></math></span>\n<span id=\"S4.T5.2.2.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_tt\"><math id=\"S4.T5.2.2.2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"T=8\" display=\"inline\"><semantics id=\"S4.T5.2.2.2.2.2.2.m1.1a\"><mrow id=\"S4.T5.2.2.2.2.2.2.m1.1.1\" xref=\"S4.T5.2.2.2.2.2.2.m1.1.1.cmml\"><mi id=\"S4.T5.2.2.2.2.2.2.m1.1.1.2\" xref=\"S4.T5.2.2.2.2.2.2.m1.1.1.2.cmml\">T</mi><mo id=\"S4.T5.2.2.2.2.2.2.m1.1.1.1\" xref=\"S4.T5.2.2.2.2.2.2.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T5.2.2.2.2.2.2.m1.1.1.3\" xref=\"S4.T5.2.2.2.2.2.2.m1.1.1.3.cmml\">8</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.2.2.2.2.2.2.m1.1b\"><apply id=\"S4.T5.2.2.2.2.2.2.m1.1.1.cmml\" xref=\"S4.T5.2.2.2.2.2.2.m1.1.1\"><eq id=\"S4.T5.2.2.2.2.2.2.m1.1.1.1.cmml\" xref=\"S4.T5.2.2.2.2.2.2.m1.1.1.1\"></eq><ci id=\"S4.T5.2.2.2.2.2.2.m1.1.1.2.cmml\" xref=\"S4.T5.2.2.2.2.2.2.m1.1.1.2\">𝑇</ci><cn type=\"integer\" id=\"S4.T5.2.2.2.2.2.2.m1.1.1.3.cmml\" xref=\"S4.T5.2.2.2.2.2.2.m1.1.1.3\">8</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.2.2.2.2.2.2.m1.1c\">T=8</annotation></semantics></math></span>\n<span id=\"S4.T5.3.3.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_tt\"><math id=\"S4.T5.3.3.3.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"T=32\" display=\"inline\"><semantics id=\"S4.T5.3.3.3.3.3.3.m1.1a\"><mrow id=\"S4.T5.3.3.3.3.3.3.m1.1.1\" xref=\"S4.T5.3.3.3.3.3.3.m1.1.1.cmml\"><mi id=\"S4.T5.3.3.3.3.3.3.m1.1.1.2\" xref=\"S4.T5.3.3.3.3.3.3.m1.1.1.2.cmml\">T</mi><mo id=\"S4.T5.3.3.3.3.3.3.m1.1.1.1\" xref=\"S4.T5.3.3.3.3.3.3.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T5.3.3.3.3.3.3.m1.1.1.3\" xref=\"S4.T5.3.3.3.3.3.3.m1.1.1.3.cmml\">32</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.3.3.3.3.3.3.m1.1b\"><apply id=\"S4.T5.3.3.3.3.3.3.m1.1.1.cmml\" xref=\"S4.T5.3.3.3.3.3.3.m1.1.1\"><eq id=\"S4.T5.3.3.3.3.3.3.m1.1.1.1.cmml\" xref=\"S4.T5.3.3.3.3.3.3.m1.1.1.1\"></eq><ci id=\"S4.T5.3.3.3.3.3.3.m1.1.1.2.cmml\" xref=\"S4.T5.3.3.3.3.3.3.m1.1.1.2\">𝑇</ci><cn type=\"integer\" id=\"S4.T5.3.3.3.3.3.3.m1.1.1.3.cmml\" xref=\"S4.T5.3.3.3.3.3.3.m1.1.1.3\">32</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.3.3.3.3.3.3.m1.1c\">T=32</annotation></semantics></math></span></span>\n<span id=\"S4.T5.6.6.6.6.6\" class=\"ltx_tr\">\n<span id=\"S4.T5.6.6.6.6.6.4\" class=\"ltx_td ltx_align_left ltx_border_t\">EASGD</span>\n<span id=\"S4.T5.4.4.4.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_t\">91.12<math id=\"S4.T5.4.4.4.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"S4.T5.4.4.4.4.4.1.m1.1a\"><mo id=\"S4.T5.4.4.4.4.4.1.m1.1.1\" xref=\"S4.T5.4.4.4.4.4.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.4.4.4.4.4.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T5.4.4.4.4.4.1.m1.1.1.cmml\" xref=\"S4.T5.4.4.4.4.4.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.4.4.4.4.4.1.m1.1c\">\\%</annotation></semantics></math></span>\n<span id=\"S4.T5.5.5.5.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\">88.88<math id=\"S4.T5.5.5.5.5.5.2.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"S4.T5.5.5.5.5.5.2.m1.1a\"><mo id=\"S4.T5.5.5.5.5.5.2.m1.1.1\" xref=\"S4.T5.5.5.5.5.5.2.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.5.5.5.5.5.2.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T5.5.5.5.5.5.2.m1.1.1.cmml\" xref=\"S4.T5.5.5.5.5.5.2.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.5.5.5.5.5.2.m1.1c\">\\%</annotation></semantics></math></span>\n<span id=\"S4.T5.6.6.6.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S4.T5.6.6.6.6.6.3.m1.1\" class=\"ltx_Math\" alttext=\"-\" display=\"inline\"><semantics id=\"S4.T5.6.6.6.6.6.3.m1.1a\"><mo id=\"S4.T5.6.6.6.6.6.3.m1.1.1\" xref=\"S4.T5.6.6.6.6.6.3.m1.1.1.cmml\">−</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.6.6.6.6.6.3.m1.1b\"><minus id=\"S4.T5.6.6.6.6.6.3.m1.1.1.cmml\" xref=\"S4.T5.6.6.6.6.6.3.m1.1.1\"></minus></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.6.6.6.6.6.3.m1.1c\">-</annotation></semantics></math></span></span>\n<span id=\"S4.T5.9.9.9.9.9\" class=\"ltx_tr\" style=\"background-color:#FFCC99;\">\n<span id=\"S4.T5.9.9.9.9.9.4\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T5.9.9.9.9.9.4.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">OverlapSGD</span></span>\n<span id=\"S4.T5.7.7.7.7.7.1\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T5.7.7.7.7.7.1.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">91.63<math id=\"S4.T5.7.7.7.7.7.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"S4.T5.7.7.7.7.7.1.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"S4.T5.7.7.7.7.7.1.1.m1.1.1\" xref=\"S4.T5.7.7.7.7.7.1.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.7.7.7.7.7.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T5.7.7.7.7.7.1.1.m1.1.1.cmml\" xref=\"S4.T5.7.7.7.7.7.1.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.7.7.7.7.7.1.1.m1.1c\">\\%</annotation></semantics></math></span></span>\n<span id=\"S4.T5.8.8.8.8.8.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T5.8.8.8.8.8.2.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">91.45<math id=\"S4.T5.8.8.8.8.8.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"S4.T5.8.8.8.8.8.2.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"S4.T5.8.8.8.8.8.2.1.m1.1.1\" xref=\"S4.T5.8.8.8.8.8.2.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.8.8.8.8.8.2.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T5.8.8.8.8.8.2.1.m1.1.1.cmml\" xref=\"S4.T5.8.8.8.8.8.2.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.8.8.8.8.8.2.1.m1.1c\">\\%</annotation></semantics></math></span></span>\n<span id=\"S4.T5.9.9.9.9.9.3\" class=\"ltx_td ltx_align_center\"><math id=\"S4.T5.9.9.9.9.9.3.m1.1\" class=\"ltx_Math\" style=\"background-color:#FFCC99;\" alttext=\"-\" display=\"inline\"><semantics id=\"S4.T5.9.9.9.9.9.3.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"S4.T5.9.9.9.9.9.3.m1.1.1\" xref=\"S4.T5.9.9.9.9.9.3.m1.1.1.cmml\">−</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.9.9.9.9.9.3.m1.1b\"><minus id=\"S4.T5.9.9.9.9.9.3.m1.1.1.cmml\" xref=\"S4.T5.9.9.9.9.9.3.m1.1.1\"></minus></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.9.9.9.9.9.3.m1.1c\">-</annotation></semantics></math></span></span>\n<span id=\"S4.T5.12.12.12.12.12\" class=\"ltx_tr\">\n<span id=\"S4.T5.12.12.12.12.12.4\" class=\"ltx_td ltx_align_left ltx_border_bb\">Grouping-based (ours)</span>\n<span id=\"S4.T5.10.10.10.10.10.1\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T5.10.10.10.10.10.1.1\" class=\"ltx_text ltx_font_bold\">94.22<math id=\"S4.T5.10.10.10.10.10.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"S4.T5.10.10.10.10.10.1.1.m1.1a\"><mo id=\"S4.T5.10.10.10.10.10.1.1.m1.1.1\" xref=\"S4.T5.10.10.10.10.10.1.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.10.10.10.10.10.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T5.10.10.10.10.10.1.1.m1.1.1.cmml\" xref=\"S4.T5.10.10.10.10.10.1.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.10.10.10.10.10.1.1.m1.1c\">\\%</annotation></semantics></math></span></span>\n<span id=\"S4.T5.11.11.11.11.11.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T5.11.11.11.11.11.2.1\" class=\"ltx_text ltx_font_bold\">93.58<math id=\"S4.T5.11.11.11.11.11.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"S4.T5.11.11.11.11.11.2.1.m1.1a\"><mo id=\"S4.T5.11.11.11.11.11.2.1.m1.1.1\" xref=\"S4.T5.11.11.11.11.11.2.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.11.11.11.11.11.2.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T5.11.11.11.11.11.2.1.m1.1.1.cmml\" xref=\"S4.T5.11.11.11.11.11.2.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.11.11.11.11.11.2.1.m1.1c\">\\%</annotation></semantics></math></span></span>\n<span id=\"S4.T5.12.12.12.12.12.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T5.12.12.12.12.12.3.1\" class=\"ltx_text ltx_font_bold\">91.92<math id=\"S4.T5.12.12.12.12.12.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"S4.T5.12.12.12.12.12.3.1.m1.1a\"><mo id=\"S4.T5.12.12.12.12.12.3.1.m1.1.1\" xref=\"S4.T5.12.12.12.12.12.3.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.12.12.12.12.12.3.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T5.12.12.12.12.12.3.1.m1.1.1.cmml\" xref=\"S4.T5.12.12.12.12.12.3.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.12.12.12.12.12.3.1.m1.1c\">\\%</annotation></semantics></math></span></span></span>\n</span></span></p>\n</span></div>\n\n",
        "footnotes": "\n\n\nMethod\nT=2𝑇2T=2\nT=8𝑇8T=8\nT=32𝑇32T=32\n\nEASGD\n91.12%percent\\%\n88.88%percent\\%\n−-\n\nOverlapSGD\n91.63%percent\\%\n91.45%percent\\%\n−-\n\nGrouping-based (ours)\n94.22%percent\\%\n93.58%percent\\%\n91.92%percent\\%\n",
        "references": [
            [
                "In this subsection, we compare our grouping-based method with other FL algorithms, in both semi-supervised and supervised settings.\nFirst, in the semi-supervised setting, we conduct the experiment on Cifar-10 with exactly the same setting as a recent SSFL paper ",
                "[",
                "9",
                "]",
                ".\nFor the Cifar-10 data, according to Table 1 in ",
                "[",
                "9",
                "]",
                ", we set ",
                "N",
                "s",
                "=",
                "5000",
                "subscript",
                "𝑁",
                "𝑠",
                "5000",
                "N_{s}=5000",
                ", ",
                "K",
                "=",
                "100",
                "𝐾",
                "100",
                "K=100",
                ", ",
                "C",
                "=",
                "5",
                "𝐶",
                "5",
                "C=5",
                ", and ",
                "R",
                "=",
                "0",
                "𝑅",
                "0",
                "R=0",
                " (which is the iid case) or ",
                "R",
                "=",
                "1",
                "𝑅",
                "1",
                "R=1",
                " (which is the most difficult non-iid case).\nFrom Tab. ",
                "3",
                ", one can see that our grouping-based solution outperforms the method proposed in ",
                "[",
                "9",
                "]",
                " by a large margin.\nWe notice that the results in ",
                "[",
                "9",
                "]",
                " are presented in two different settings including the ",
                "labels-at-server",
                " setting and the ",
                "labels-at-client",
                " setting.\nThe first setting is the same as our paper, i.e., only the server has labeled data, while the users have unlabeled data.\nIn this setting, ",
                "N",
                "s",
                "=",
                "5000",
                "subscript",
                "𝑁",
                "𝑠",
                "5000",
                "N_{s}=5000",
                " labeled data are own by the server.\nThe second setting is different but it is straightforward to apply our grouping-based solution.\nIn this setting, ",
                "N",
                "s",
                "=",
                "5000",
                "subscript",
                "𝑁",
                "𝑠",
                "5000",
                "N_{s}=5000",
                " labeled data are distributed to 100 users. In each round, ",
                "C",
                "=",
                "5",
                "𝐶",
                "5",
                "C=5",
                " users are random selected to communicate with the server.\nSee Appendix ",
                "H",
                " for the details of adapting our solution to the label-at-the-client setting.",
                "We also compare our solution with supervised FL methods in Tab. ",
                "4",
                ".\nWe choose two supervised FL methods for comparison: Supervised FedAvg ",
                "[",
                "2",
                "]",
                " and DataSharing ",
                "[",
                "16",
                "]",
                ".\nWe set ",
                "K",
                "=",
                "10",
                "𝐾",
                "10",
                "K=10",
                ", ",
                "C",
                "=",
                "10",
                "𝐶",
                "10",
                "C=10",
                " and ",
                "T",
                "=",
                "32",
                "𝑇",
                "32",
                "T=32",
                ", and we use ResNet-18 to be the model for training.\nThe non-iid setting of DataSharing ",
                "[",
                "16",
                "]",
                " corresponds to the scenario where we set ",
                "R",
                "=",
                "0.29",
                "𝑅",
                "0.29",
                "R=0.29",
                ".\nFor our solutions, we set ",
                "N",
                "s",
                "=",
                "1000",
                "subscript",
                "𝑁",
                "𝑠",
                "1000",
                "N_{s}=1000",
                " and ",
                "R",
                "=",
                "0.4",
                "𝑅",
                "0.4",
                "R=0.4",
                ". The detailed experimental parameters of different methods can be seen from rows 22-25 of Tab. ",
                "A.2",
                ".\nLarger ",
                "R",
                "𝑅",
                "R",
                " means a higher non-iid level and thus a more difficult scenario (which we have experimentally demonstrated in Fig. ",
                "5",
                "). From Tab. ",
                "4",
                " we see that the performance of our method (",
                "R",
                "=",
                "0.4",
                "𝑅",
                "0.4",
                "R=0.4",
                ") on Cifar-10 is still better than Supervised FedAvg (",
                "R",
                "=",
                "0.29",
                "𝑅",
                "0.29",
                "R=0.29",
                ") and DataSharing methods (",
                "R",
                "=",
                "0.29",
                "𝑅",
                "0.29",
                "R=0.29",
                ") even when the scenario of ",
                "R",
                "=",
                "0.4",
                "𝑅",
                "0.4",
                "R=0.4",
                " is more difficult.",
                "We also compare our method with EASGD ",
                "[",
                "14",
                "]",
                " and OverlapSGD ",
                "[",
                "15",
                "]",
                " which are communication efficient algorithms under supervised settings.\nWe use the same parameters in their papers, i.e., ",
                "K",
                "=",
                "16",
                "𝐾",
                "16",
                "K=16",
                ", ",
                "R",
                "=",
                "0.4",
                "𝑅",
                "0.4",
                "R=0.4",
                ", ",
                "C",
                "=",
                "16",
                "𝐶",
                "16",
                "C=16",
                " and ",
                "N",
                "s",
                "=",
                "1000",
                "subscript",
                "𝑁",
                "𝑠",
                "1000",
                "N_{s}=1000",
                " on Cifar-10. See rows 26-29 of Tab. ",
                "A.2",
                " for the details.\nThe results are shown in Tab. ",
                "5",
                ".\nWe see that our result has better accuracy than both EASGD and OverlapSGD.\nParticularly, even with ",
                "T",
                "=",
                "32",
                "𝑇",
                "32",
                "T=32",
                " (larger ",
                "T",
                "𝑇",
                "T",
                " means a harder scenario; see Fig. ",
                "5",
                "), our method has 0.80% or 0.29% better performance, as compared to EASGD or OverlapSGD in the setting of ",
                "T",
                "=",
                "2",
                "𝑇",
                "2",
                "T=2",
                ", respectively.\nNote that both EASGD and OverlapSGD are supervised algorithms, which means they have all the data labels.",
                "There are other important issues we consider.\nFor example, we evaluate the performance of our grouping-based method in fully supervised FL in § ",
                "F",
                ", and we show that the improvement in this scenario is limited. Thus, our method is more suitable in the ",
                "SSFL",
                " setting.\nWe also compare our grouping-based solution with FixMatch ",
                "[",
                "11",
                "]",
                " in § ",
                "G",
                ").\nWe show that our results are comparable to FixMatch even if FixMatch uses centralized setting.\nMoreover, we extend our current methods to the setting where users can have both labeled and unlabeled samples in § ",
                "H",
                ", i.e., the labels-at-client case.\nWe also provide additional results on another semi-supervised dataset STL-10, see § ",
                "I",
                ".\nFinally, since for federated learning, we are interested in studying what happens when the number of users is large, we provide an additional experiment with the number of users set to 470 in § ",
                "J",
                ". We show that the grouping-based method outperforms FedAvg in this setting as well."
            ]
        ]
    },
    "A1.T1": {
        "caption": "Table A.1: Optimizer hyperparameters used on different datasets. ",
        "table": "<table id=\"A1.T1.7\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"A1.T1.7.7\" class=\"ltx_tr\">\n<td id=\"A1.T1.7.7.8\" class=\"ltx_td ltx_align_left ltx_border_tt\">Dataset</td>\n<td id=\"A1.T1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\"><math id=\"A1.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"E\" display=\"inline\"><semantics id=\"A1.T1.1.1.1.m1.1a\"><mi id=\"A1.T1.1.1.1.m1.1.1\" xref=\"A1.T1.1.1.1.m1.1.1.cmml\">E</mi><annotation-xml encoding=\"MathML-Content\" id=\"A1.T1.1.1.1.m1.1b\"><ci id=\"A1.T1.1.1.1.m1.1.1.cmml\" xref=\"A1.T1.1.1.1.m1.1.1\">𝐸</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T1.1.1.1.m1.1c\">E</annotation></semantics></math></td>\n<td id=\"A1.T1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_tt\"><math id=\"A1.T1.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"M\" display=\"inline\"><semantics id=\"A1.T1.2.2.2.m1.1a\"><mi id=\"A1.T1.2.2.2.m1.1.1\" xref=\"A1.T1.2.2.2.m1.1.1.cmml\">M</mi><annotation-xml encoding=\"MathML-Content\" id=\"A1.T1.2.2.2.m1.1b\"><ci id=\"A1.T1.2.2.2.m1.1.1.cmml\" xref=\"A1.T1.2.2.2.m1.1.1\">𝑀</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T1.2.2.2.m1.1c\">M</annotation></semantics></math></td>\n<td id=\"A1.T1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_tt\"><math id=\"A1.T1.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\gamma\" display=\"inline\"><semantics id=\"A1.T1.3.3.3.m1.1a\"><mi id=\"A1.T1.3.3.3.m1.1.1\" xref=\"A1.T1.3.3.3.m1.1.1.cmml\">γ</mi><annotation-xml encoding=\"MathML-Content\" id=\"A1.T1.3.3.3.m1.1b\"><ci id=\"A1.T1.3.3.3.m1.1.1.cmml\" xref=\"A1.T1.3.3.3.m1.1.1\">𝛾</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T1.3.3.3.m1.1c\">\\gamma</annotation></semantics></math></td>\n<td id=\"A1.T1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_tt\"><math id=\"A1.T1.4.4.4.m1.1\" class=\"ltx_Math\" alttext=\"e\" display=\"inline\"><semantics id=\"A1.T1.4.4.4.m1.1a\"><mi id=\"A1.T1.4.4.4.m1.1.1\" xref=\"A1.T1.4.4.4.m1.1.1.cmml\">e</mi><annotation-xml encoding=\"MathML-Content\" id=\"A1.T1.4.4.4.m1.1b\"><ci id=\"A1.T1.4.4.4.m1.1.1.cmml\" xref=\"A1.T1.4.4.4.m1.1.1\">𝑒</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T1.4.4.4.m1.1c\">e</annotation></semantics></math></td>\n<td id=\"A1.T1.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_tt\"><math id=\"A1.T1.5.5.5.m1.1\" class=\"ltx_Math\" alttext=\"\\varepsilon\" display=\"inline\"><semantics id=\"A1.T1.5.5.5.m1.1a\"><mi id=\"A1.T1.5.5.5.m1.1.1\" xref=\"A1.T1.5.5.5.m1.1.1.cmml\">ε</mi><annotation-xml encoding=\"MathML-Content\" id=\"A1.T1.5.5.5.m1.1b\"><ci id=\"A1.T1.5.5.5.m1.1.1.cmml\" xref=\"A1.T1.5.5.5.m1.1.1\">𝜀</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T1.5.5.5.m1.1c\">\\varepsilon</annotation></semantics></math></td>\n<td id=\"A1.T1.7.7.9\" class=\"ltx_td ltx_align_center ltx_border_tt\">weight decay</td>\n<td id=\"A1.T1.7.7.10\" class=\"ltx_td ltx_align_center ltx_border_tt\">momentum</td>\n<td id=\"A1.T1.6.6.6\" class=\"ltx_td ltx_align_center ltx_border_tt\"><math id=\"A1.T1.6.6.6.m1.1\" class=\"ltx_Math\" alttext=\"c\" display=\"inline\"><semantics id=\"A1.T1.6.6.6.m1.1a\"><mi id=\"A1.T1.6.6.6.m1.1.1\" xref=\"A1.T1.6.6.6.m1.1.1.cmml\">c</mi><annotation-xml encoding=\"MathML-Content\" id=\"A1.T1.6.6.6.m1.1b\"><ci id=\"A1.T1.6.6.6.m1.1.1.cmml\" xref=\"A1.T1.6.6.6.m1.1.1\">𝑐</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T1.6.6.6.m1.1c\">c</annotation></semantics></math></td>\n<td id=\"A1.T1.7.7.7\" class=\"ltx_td ltx_align_center ltx_border_tt\"><math id=\"A1.T1.7.7.7.m1.1\" class=\"ltx_Math\" alttext=\"B\" display=\"inline\"><semantics id=\"A1.T1.7.7.7.m1.1a\"><mi id=\"A1.T1.7.7.7.m1.1.1\" xref=\"A1.T1.7.7.7.m1.1.1.cmml\">B</mi><annotation-xml encoding=\"MathML-Content\" id=\"A1.T1.7.7.7.m1.1b\"><ci id=\"A1.T1.7.7.7.m1.1.1.cmml\" xref=\"A1.T1.7.7.7.m1.1.1\">𝐵</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A1.T1.7.7.7.m1.1c\">B</annotation></semantics></math></td>\n</tr>\n<tr id=\"A1.T1.7.8\" class=\"ltx_tr\">\n<td id=\"A1.T1.7.8.1\" class=\"ltx_td ltx_align_left ltx_border_t\">Cifar-10</td>\n<td id=\"A1.T1.7.8.2\" class=\"ltx_td ltx_align_center ltx_border_t\">300</td>\n<td id=\"A1.T1.7.8.3\" class=\"ltx_td ltx_align_center ltx_border_t\">65536</td>\n<td id=\"A1.T1.7.8.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.146</td>\n<td id=\"A1.T1.7.8.5\" class=\"ltx_td ltx_align_center ltx_border_t\">5</td>\n<td id=\"A1.T1.7.8.6\" class=\"ltx_td ltx_align_center ltx_border_t\">1e-4</td>\n<td id=\"A1.T1.7.8.7\" class=\"ltx_td ltx_align_center ltx_border_t\">1e-4</td>\n<td id=\"A1.T1.7.8.8\" class=\"ltx_td ltx_align_center ltx_border_t\">0.9</td>\n<td id=\"A1.T1.7.8.9\" class=\"ltx_td ltx_align_center ltx_border_t\">2.3</td>\n<td id=\"A1.T1.7.8.10\" class=\"ltx_td ltx_align_center ltx_border_t\">64</td>\n</tr>\n<tr id=\"A1.T1.7.9\" class=\"ltx_tr\" style=\"background-color:#FFCC99;\">\n<td id=\"A1.T1.7.9.1\" class=\"ltx_td ltx_align_left\"><span id=\"A1.T1.7.9.1.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">SVHN</span></td>\n<td id=\"A1.T1.7.9.2\" class=\"ltx_td ltx_align_center\"><span id=\"A1.T1.7.9.2.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">40</span></td>\n<td id=\"A1.T1.7.9.3\" class=\"ltx_td ltx_align_center\"><span id=\"A1.T1.7.9.3.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">65536</span></td>\n<td id=\"A1.T1.7.9.4\" class=\"ltx_td ltx_align_center\"><span id=\"A1.T1.7.9.4.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">0.146</span></td>\n<td id=\"A1.T1.7.9.5\" class=\"ltx_td ltx_align_center\"><span id=\"A1.T1.7.9.5.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">5</span></td>\n<td id=\"A1.T1.7.9.6\" class=\"ltx_td ltx_align_center\"><span id=\"A1.T1.7.9.6.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">1e-4</span></td>\n<td id=\"A1.T1.7.9.7\" class=\"ltx_td ltx_align_center\"><span id=\"A1.T1.7.9.7.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">1e-4</span></td>\n<td id=\"A1.T1.7.9.8\" class=\"ltx_td ltx_align_center\"><span id=\"A1.T1.7.9.8.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">0.9</span></td>\n<td id=\"A1.T1.7.9.9\" class=\"ltx_td ltx_align_center\"><span id=\"A1.T1.7.9.9.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">2.3</span></td>\n<td id=\"A1.T1.7.9.10\" class=\"ltx_td ltx_align_center\"><span id=\"A1.T1.7.9.10.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">64</span></td>\n</tr>\n<tr id=\"A1.T1.7.10\" class=\"ltx_tr\">\n<td id=\"A1.T1.7.10.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">EMNIST</td>\n<td id=\"A1.T1.7.10.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">100</td>\n<td id=\"A1.T1.7.10.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">65536</td>\n<td id=\"A1.T1.7.10.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.03</td>\n<td id=\"A1.T1.7.10.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">0</td>\n<td id=\"A1.T1.7.10.6\" class=\"ltx_td ltx_align_center ltx_border_bb\">1e-4</td>\n<td id=\"A1.T1.7.10.7\" class=\"ltx_td ltx_align_center ltx_border_bb\">1e-4</td>\n<td id=\"A1.T1.7.10.8\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.9</td>\n<td id=\"A1.T1.7.10.9\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.4375</td>\n<td id=\"A1.T1.7.10.10\" class=\"ltx_td ltx_align_center ltx_border_bb\">64</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "As can be seen from the top of Tab. 1, increasing the number of users K𝐾K has a marginal effect (<<1%) on the accuracy, from K=10𝐾10K=10 to K=30𝐾30K=30.\nOne notable thing here is that with K=30𝐾30K=30, if we train 40 epochs on SVHN, the accuracy is 78.77%, which is 16.72% lower than K=10𝐾10K=10.\nIf we increase the training epochs from 40 to 120 for K=30𝐾30K=30 on SVHN, the final accuracy is 94.93%. One can refer to Fig. C.1 for the convergence curve of this experiment.",
            "In this subsection, we compare our grouping-based method with other FL algorithms, in both semi-supervised and supervised settings.\nFirst, in the semi-supervised setting, we conduct the experiment on Cifar-10 with exactly the same setting as a recent SSFL paper [9].\nFor the Cifar-10 data, according to Table 1 in [9], we set Ns=5000subscript𝑁𝑠5000N_{s}=5000, K=100𝐾100K=100, C=5𝐶5C=5, and R=0𝑅0R=0 (which is the iid case) or R=1𝑅1R=1 (which is the most difficult non-iid case).\nFrom Tab. 3, one can see that our grouping-based solution outperforms the method proposed in [9] by a large margin.\nWe notice that the results in [9] are presented in two different settings including the labels-at-server setting and the labels-at-client setting.\nThe first setting is the same as our paper, i.e., only the server has labeled data, while the users have unlabeled data.\nIn this setting, Ns=5000subscript𝑁𝑠5000N_{s}=5000 labeled data are own by the server.\nThe second setting is different but it is straightforward to apply our grouping-based solution.\nIn this setting, Ns=5000subscript𝑁𝑠5000N_{s}=5000 labeled data are distributed to 100 users. In each round, C=5𝐶5C=5 users are random selected to communicate with the server.\nSee Appendix H for the details of adapting our solution to the label-at-the-client setting.",
            "There are other important issues we consider.\nFor example, we evaluate the performance of our grouping-based method in fully supervised FL in § F, and we show that the improvement in this scenario is limited. Thus, our method is more suitable in the SSFL setting.\nWe also compare our grouping-based solution with FixMatch [11] in § G).\nWe show that our results are comparable to FixMatch even if FixMatch uses centralized setting.\nMoreover, we extend our current methods to the setting where users can have both labeled and unlabeled samples in § H, i.e., the labels-at-client case.\nWe also provide additional results on another semi-supervised dataset STL-10, see § I.\nFinally, since for federated learning, we are interested in studying what happens when the number of users is large, we provide an additional experiment with the number of users set to 470 in § J. We show that the grouping-based method outperforms FedAvg in this setting as well.",
            "Federated learning.\nFederated learning (FL) [1, 2, 4, 27, 16, 28, 29, 30, 18, 31] is a decentralized computing framework that enables multiple users to learn a shared model while potentially protecting the privacy of users (although recent work [32] shows this may not be the case).\nFederated Averaging (FedAvg) [2], which is the most popular FL algorithm, shows good performance when the data distribution across users is iid.\nHowever, in the non-iid case, the performance can significantly degrade.\nIn fact, dealing with non-iid distributions is deemed by many to be one of the most critical challenges in FL [16, 28, 33].\nIn [16], a data-sharing method is proposed to improve the final accuracy.\nHowever, sharing massive data among all users requires both large storage space as well as stable connections between users and the server.\nImportantly, all of these methods require the data stored by the local users to come with ground-truth labels (in order to perform model updates locally).\nThe FL problem in the semi-supervised setting, when users do not have labels, however, is “relatively ignored” and has “little prior arts,” as mentioned in a recent survey paper [4].",
            "In this section, we study whether the grouping-based averaging can be extended to supervised FL (SFL). We want to see whether this particular way of averaging is more suitable for the semi-supervised setup or the supervised setup.\nWe conduct experiments on EMNIST using SFL with three different settings with different number of users K∈{47,20,10}𝐾472010K\\in\\{47,20,10\\}. In these three settings, we let C=K𝐶𝐾C=K.\nThe other environmental factors are shown in rows 32-34 of Tab. A.2.\nWe set the group number S=5𝑆5S=5, S=2𝑆2S=2 and S=2𝑆2S=2 for the setting of K=47𝐾47K=47, K=20𝐾20K=20 and K=10𝐾10K=10, respectively.\nSee Table F.1.\nThe results show that the performance of the grouping method is only slightly better than that of FedAvg.\nThus, the performance gain of the grouping-based averaging method for SFL is much less than that of SSFL. This mean that grouping-based averaging is more suitable for the semi-supervised setup than the supervised setup.",
            "The results in Table J.1 show that the performance of the grouping-based averaging is better than that of FedAvg even with 470 users. One can also observe that as the number of communicating users C𝐶C increases, the performance of the FedAvg decreases, which is consistent with the experimental phenomenon observed in § 4.2."
        ]
    },
    "A1.T2": {
        "caption": "",
        "table": "",
        "footnotes": "\n\n\n\n\n\nExperiment title\nRow-id\nDataset\nMethod\nR𝑅R\nT𝑇T\nNssubscript𝑁𝑠N_{s}\nC𝐶C\nK𝐾K\nS𝑆S\n\n \n\n\nImpact of R𝑅R\n\n Fig. 5 (left)\n \n1\nCifar10\nGrouping-based\n{0.0,0.1,⋯,1.0}0.00.1⋯1.0\\{0.0,0.1,\\cdots,1.0\\}\n16\n103superscript10310^{3}\n101010\n101010\n−-\n\n2\nSVHN\nGrouping-based\n{0.0,0.1,⋯,1.0}0.00.1⋯1.0\\{0.0,0.1,\\cdots,1.0\\}\n16\n103superscript10310^{3}\n101010\n101010\n−-\n\n3\nEMNIST\nGrouping-based\n{0.0,0.1,⋯,1.0}0.00.1⋯1.0\\{0.0,0.1,\\cdots,1.0\\}\n16\n4.7×1034.7superscript1034.7\\times 10^{3}\n101010\n474747\n−-\n\n \n\n\nImpact of T𝑇T\n\n Fig. 5 (middle)\n \n4\nCifar10\nGrouping-based\n0.40.40.4\n{2,22,⋯,25}2superscript22⋯superscript25\\{2,2^{2},\\cdots,2^{5}\\}\n103superscript10310^{3}\n101010\n101010\n−-\n\n5\nSVHN\nGrouping-based\n0.40.40.4\n{2,22,⋯,25}2superscript22⋯superscript25\\{2,2^{2},\\cdots,2^{5}\\}\n103superscript10310^{3}\n101010\n101010\n−-\n\n6\nEMNIST\nGrouping-based\n0.40.40.4\n{2,22,⋯,25}2superscript22⋯superscript25\\{2,2^{2},\\cdots,2^{5}\\}\n4.7×1034.7superscript1034.7\\times 10^{3}\n101010\n474747\n−-\n\n \n\n\nImpact of Nssubscript𝑁𝑠N_{s}\n\n Fig. 5 (right)\n \n7\nCifar10\nGrouping-based\n0.40.40.4\n161616\n{103,2×103,⋯,5×103}superscript1032superscript103⋯5superscript103\\{10^{3},2\\times 10^{3},\\cdots,5\\times 10^{3}\\}\n101010\n101010\n−-\n\n8\nSVHN\nGrouping-based\n0.40.40.4\n161616\n{103,2×103,⋯,5×103}superscript1032superscript103⋯5superscript103\\{10^{3},2\\times 10^{3},\\cdots,5\\times 10^{3}\\}\n101010\n101010\n−-\n\n9\nEMNIST\nGrouping-based\n0.40.40.4\n161616\n{103,2×103,⋯,5×103}superscript1032superscript103⋯5superscript103\\{10^{3},2\\times 10^{3},\\cdots,5\\times 10^{3}\\}\n101010\n474747\n−-\n\n \n\n\nImpact of C𝐶C\n\n Tab. 1 and Tab. 2\n \n10\nCifar10\nGrouping-based\n0.40.40.4\n161616\n103superscript10310^{3}\n101010\n101010\n−-\n\n11\nCifar10\nGrouping-based\n0.40.40.4\n161616\n103superscript10310^{3}\n{10,20}1020\\{10,20\\}\n202020\n−-\n\n\n12\nCifar10\nGrouping-based\n0.40.40.4\n161616\n103superscript10310^{3}\n{10,30}1030\\{10,30\\}\n303030\n−-\n\n\n13\nSVHN\nGrouping-based\n0.40.40.4\n161616\n103superscript10310^{3}\n101010\n101010\n−-\n\n\n14\nSVHN\nGrouping-based\n0.40.40.4\n161616\n103superscript10310^{3}\n{10,20}1020\\{10,20\\}\n202020\n−-\n\n\n15\nSVHN\nGrouping-based\n0.40.40.4\n161616\n103superscript10310^{3}\n{10,30}1030\\{10,30\\}\n303030\n−-\n\n\n16\nEMNIST\nGrouping-based\n0.40.40.4\n161616\n4.7×1034.7superscript1034.7\\times 10^{3}\n{10,30,47}103047\\{10,30,47\\}\n474747\n−-\n\n \n\n\nImpact of K𝐾K\n\n Tab. 1\n \n17\nCifar10\nGrouping-based\n0.40.40.4\n161616\n103superscript10310^{3}\n101010\n{10,20,30}102030\\{10,20,30\\}\n−-\n\n18\nSVHN\nGrouping-based\n0.40.40.4\n161616\n103superscript10310^{3}\n101010\n{10,20,30}102030\\{10,20,30\\}\n−-\n\n \n\n\nFedAvg vs.\n\nGrouping-based\n\n Tab. D.1\n \n19\nCifar10\nFedAvg/Grouping-based\n0.40.40.4\n161616\n103superscript10310^{3}\n101010\n101010\n−-/222\n\n20\nSVHN\nFedAvg/Grouping-based\n0.40.40.4\n161616\n103superscript10310^{3}\n202020\n202020\n−-/222\n\n21\nEMNIST\nFedAvg/Grouping-based\n0.40.40.4\n161616\n4.7×1034.7superscript1034.7\\times 10^{3}\n474747\n474747\n−-/555\n\n \n\n\nComparison with\n\nsupervised\nFL\n\n Tab. 4\n \n22\nCifar10\nSupervised FedAvg\n0.290.290.29\n323232\n−-\n101010\n101010\n−-\n\n23\nCifar10\nDataSharing\n0.290.290.29\n323232\n−-\n101010\n101010\n−-\n\n24\nCifar10\nFedAvg\n0.40.40.4\n323232\n103superscript10310^{3}\n101010\n101010\n−-\n\n25\nCifar10\nGrouping-based\n0.40.40.4\n323232\n103superscript10310^{3}\n101010\n101010\n222\n\n \n\n\nComparison with\n\nEASGD and\n\nOverlapSGD\n\n Tab. 5\n \n26\nCifar10\nEASGD\n0.40.40.4\n{2,8}28\\{2,8\\}\n−-\n161616\n161616\n−-\n\n27\nCifar10\nOverlapSGD\n0.40.40.4\n{2,8}28\\{2,8\\}\n−-\n161616\n161616\n−-\n\n28\nCifar10\nFedAvg\n0.40.40.4\n{2,8,32}2832\\{2,8,32\\}\n103superscript10310^{3}\n161616\n161616\n−-\n\n29\nCifar10\nGrouping-based\n0.40.40.4\n{2,8,32}2832\\{2,8,32\\}\n103superscript10310^{3}\n161616\n161616\n222\n\n \n\n\nImpact of the ratio η𝜂\\eta\n\n Tab. E.1\n \n30\nCifar10\nFedAvg/Grouping-based\n0.40.40.4\n161616\n103superscript10310^{3}\n{3,6,10,30}361030\\{3,6,10,30\\}\n303030\n−-\n\n31\nSVHN\nFedAvg/Grouping-based\n0.40.40.4\n161616\n103superscript10310^{3}\n{3,6,10,30}361030\\{3,6,10,30\\}\n303030\n−-\n\n \n\n\nFully supervised\n\nFL Tab. F.1\n \n32\nEMNIST\nGrouping-based\n0.40.40.4\n161616\n4.7×1034.7superscript1034.7\\times 10^{3}\n101010\n101010\n222\n\n33\nEMNIST\nGrouping-based\n0.40.40.4\n161616\n4.7×1034.7superscript1034.7\\times 10^{3}\n202020\n202020\n222\n\n34\nEMNIST\nGrouping-based\n0.40.40.4\n161616\n4.7×1034.7superscript1034.7\\times 10^{3}\n474747\n474747\n555\n\n \n\n\nGrouping-based vs.\n\nFixMatch Tab. G.1\n \n35\nCifar10\nGrouping-based\n0.40.40.4\n161616\n4×1034superscript1034\\times 10^{3}\n101010\n101010\n222\n\n36\nSVHN\nGrouping-based\n0.40.40.4\n161616\n103superscript10310^{3}\n202020\n202020\n222\n\n37\nEMNIST\nGrouping-based\n0.40.40.4\n161616\n4.7×1034.7superscript1034.7\\times 10^{3}\n474747\n474747\n555\n\n\n38\nCifar10\nFixMatch\n0.00.00.0\n111\n4×1034superscript1034\\times 10^{3}\n111\n111\n−-\n\n\n39\nSVHN\nFixMatch\n0.00.00.0\n111\n103superscript10310^{3}\n111\n111\n−-\n\n\n40\nEMNIST\nFixMatch\n0.00.00.0\n111\n4.7×1034.7superscript1034.7\\times 10^{3}\n111\n111\n−-\n\n \n\n\nUsers have labeled samples Tab. H.1\n \n41\nEMNIST\nFedAvg\n{0.4,0.6}0.40.6\\{0.4,0.6\\}\n161616\n4.7×1034.7superscript1034.7\\times 10^{3}\n474747\n474747\n−-\n\n \n\n\nPerformance on STL-10\n\n Tab. I.1\n \n42\nSTL-10\nSelf-training\n0.00.00.0\n161616\n103superscript10310^{3}\n222\n101010\n−-\n\n43\nSTL-10\nCRL with BN\n0.00.00.0\n161616\n103superscript10310^{3}\n222\n101010\n−-\n\n44\nSTL-10\nFedAvg\n0.00.00.0\n161616\n103superscript10310^{3}\n222\n101010\n−-\n\n45\nSTL-10\nGrouping-based\n0.00.00.0\n161616\n103superscript10310^{3}\n222\n101010\n222\n\n \n\n\nPerformance on EMNIST with\n\nlarge user number Tab. J.1\n \n46\nEMNIST\nFedAvg/Grouping-based\n0.40.40.4\n161616\n4.7×1034.7superscript1034.7\\times 10^{3}\n101010\n474747\n−-/222\n\n47\nEMNIST\nFedAvg/Grouping-based\n0.40.40.4\n161616\n4.7×1034.7superscript1034.7\\times 10^{3}\n202020\n474747\n−-/222\n\n48\nEMNIST\nFedAvg/Grouping-based\n0.40.40.4\n161616\n4.7×1034.7superscript1034.7\\times 10^{3}\n303030\n474747\n−-/222\n\n \n\n\nComparison with [9] on\n\nCifar10 Tab. 3\n \n49\nCifar10\nFedMatch\n{0,1}01\\{0,1\\}\n100100100\n5×1035superscript1035\\times 10^{3}\n555\n100100100\n−-\n\n50\nCifar10\nGrouping-based\n{0,1}01\\{0,1\\}\n100100100\n5×1035superscript1035\\times 10^{3}\n555\n100100100\n222\n\n",
        "references": [
            "As can be seen from the top of Tab. 1, increasing the number of users K𝐾K has a marginal effect (<<1%) on the accuracy, from K=10𝐾10K=10 to K=30𝐾30K=30.\nOne notable thing here is that with K=30𝐾30K=30, if we train 40 epochs on SVHN, the accuracy is 78.77%, which is 16.72% lower than K=10𝐾10K=10.\nIf we increase the training epochs from 40 to 120 for K=30𝐾30K=30 on SVHN, the final accuracy is 94.93%. One can refer to Fig. C.1 for the convergence curve of this experiment.",
            "In this subsection, we compare our grouping-based method with other FL algorithms, in both semi-supervised and supervised settings.\nFirst, in the semi-supervised setting, we conduct the experiment on Cifar-10 with exactly the same setting as a recent SSFL paper [9].\nFor the Cifar-10 data, according to Table 1 in [9], we set Ns=5000subscript𝑁𝑠5000N_{s}=5000, K=100𝐾100K=100, C=5𝐶5C=5, and R=0𝑅0R=0 (which is the iid case) or R=1𝑅1R=1 (which is the most difficult non-iid case).\nFrom Tab. 3, one can see that our grouping-based solution outperforms the method proposed in [9] by a large margin.\nWe notice that the results in [9] are presented in two different settings including the labels-at-server setting and the labels-at-client setting.\nThe first setting is the same as our paper, i.e., only the server has labeled data, while the users have unlabeled data.\nIn this setting, Ns=5000subscript𝑁𝑠5000N_{s}=5000 labeled data are own by the server.\nThe second setting is different but it is straightforward to apply our grouping-based solution.\nIn this setting, Ns=5000subscript𝑁𝑠5000N_{s}=5000 labeled data are distributed to 100 users. In each round, C=5𝐶5C=5 users are random selected to communicate with the server.\nSee Appendix H for the details of adapting our solution to the label-at-the-client setting.",
            "There are other important issues we consider.\nFor example, we evaluate the performance of our grouping-based method in fully supervised FL in § F, and we show that the improvement in this scenario is limited. Thus, our method is more suitable in the SSFL setting.\nWe also compare our grouping-based solution with FixMatch [11] in § G).\nWe show that our results are comparable to FixMatch even if FixMatch uses centralized setting.\nMoreover, we extend our current methods to the setting where users can have both labeled and unlabeled samples in § H, i.e., the labels-at-client case.\nWe also provide additional results on another semi-supervised dataset STL-10, see § I.\nFinally, since for federated learning, we are interested in studying what happens when the number of users is large, we provide an additional experiment with the number of users set to 470 in § J. We show that the grouping-based method outperforms FedAvg in this setting as well.",
            "Federated learning.\nFederated learning (FL) [1, 2, 4, 27, 16, 28, 29, 30, 18, 31] is a decentralized computing framework that enables multiple users to learn a shared model while potentially protecting the privacy of users (although recent work [32] shows this may not be the case).\nFederated Averaging (FedAvg) [2], which is the most popular FL algorithm, shows good performance when the data distribution across users is iid.\nHowever, in the non-iid case, the performance can significantly degrade.\nIn fact, dealing with non-iid distributions is deemed by many to be one of the most critical challenges in FL [16, 28, 33].\nIn [16], a data-sharing method is proposed to improve the final accuracy.\nHowever, sharing massive data among all users requires both large storage space as well as stable connections between users and the server.\nImportantly, all of these methods require the data stored by the local users to come with ground-truth labels (in order to perform model updates locally).\nThe FL problem in the semi-supervised setting, when users do not have labels, however, is “relatively ignored” and has “little prior arts,” as mentioned in a recent survey paper [4].",
            "In this section, we study whether the grouping-based averaging can be extended to supervised FL (SFL). We want to see whether this particular way of averaging is more suitable for the semi-supervised setup or the supervised setup.\nWe conduct experiments on EMNIST using SFL with three different settings with different number of users K∈{47,20,10}𝐾472010K\\in\\{47,20,10\\}. In these three settings, we let C=K𝐶𝐾C=K.\nThe other environmental factors are shown in rows 32-34 of Tab. A.2.\nWe set the group number S=5𝑆5S=5, S=2𝑆2S=2 and S=2𝑆2S=2 for the setting of K=47𝐾47K=47, K=20𝐾20K=20 and K=10𝐾10K=10, respectively.\nSee Table F.1.\nThe results show that the performance of the grouping method is only slightly better than that of FedAvg.\nThus, the performance gain of the grouping-based averaging method for SFL is much less than that of SSFL. This mean that grouping-based averaging is more suitable for the semi-supervised setup than the supervised setup.",
            "The results in Table J.1 show that the performance of the grouping-based averaging is better than that of FedAvg even with 470 users. One can also observe that as the number of communicating users C𝐶C increases, the performance of the FedAvg decreases, which is consistent with the experimental phenomenon observed in § 4.2."
        ]
    },
    "A5.T1": {
        "caption": "Table E.1: Test accuracy versus the ratio of communicating users η=C/K𝜂𝐶𝐾\\eta=C/K on Cifar-10 and SVHN",
        "table": "<table id=\"A5.T1.22\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"A5.T1.14.12\" class=\"ltx_tr\">\n<td id=\"A5.T1.14.12.13\" class=\"ltx_td ltx_border_tt\"></td>\n<td id=\"A5.T1.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">\n<table id=\"A5.T1.5.3.3.3\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A5.T1.3.1.1.1.1\" class=\"ltx_tr\">\n<td id=\"A5.T1.3.1.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><math id=\"A5.T1.3.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\eta=1/10\" display=\"inline\"><semantics id=\"A5.T1.3.1.1.1.1.1.m1.1a\"><mrow id=\"A5.T1.3.1.1.1.1.1.m1.1.1\" xref=\"A5.T1.3.1.1.1.1.1.m1.1.1.cmml\"><mi id=\"A5.T1.3.1.1.1.1.1.m1.1.1.2\" xref=\"A5.T1.3.1.1.1.1.1.m1.1.1.2.cmml\">η</mi><mo id=\"A5.T1.3.1.1.1.1.1.m1.1.1.1\" xref=\"A5.T1.3.1.1.1.1.1.m1.1.1.1.cmml\">=</mo><mrow id=\"A5.T1.3.1.1.1.1.1.m1.1.1.3\" xref=\"A5.T1.3.1.1.1.1.1.m1.1.1.3.cmml\"><mn id=\"A5.T1.3.1.1.1.1.1.m1.1.1.3.2\" xref=\"A5.T1.3.1.1.1.1.1.m1.1.1.3.2.cmml\">1</mn><mo id=\"A5.T1.3.1.1.1.1.1.m1.1.1.3.1\" xref=\"A5.T1.3.1.1.1.1.1.m1.1.1.3.1.cmml\">/</mo><mn id=\"A5.T1.3.1.1.1.1.1.m1.1.1.3.3\" xref=\"A5.T1.3.1.1.1.1.1.m1.1.1.3.3.cmml\">10</mn></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.3.1.1.1.1.1.m1.1b\"><apply id=\"A5.T1.3.1.1.1.1.1.m1.1.1.cmml\" xref=\"A5.T1.3.1.1.1.1.1.m1.1.1\"><eq id=\"A5.T1.3.1.1.1.1.1.m1.1.1.1.cmml\" xref=\"A5.T1.3.1.1.1.1.1.m1.1.1.1\"></eq><ci id=\"A5.T1.3.1.1.1.1.1.m1.1.1.2.cmml\" xref=\"A5.T1.3.1.1.1.1.1.m1.1.1.2\">𝜂</ci><apply id=\"A5.T1.3.1.1.1.1.1.m1.1.1.3.cmml\" xref=\"A5.T1.3.1.1.1.1.1.m1.1.1.3\"><divide id=\"A5.T1.3.1.1.1.1.1.m1.1.1.3.1.cmml\" xref=\"A5.T1.3.1.1.1.1.1.m1.1.1.3.1\"></divide><cn type=\"integer\" id=\"A5.T1.3.1.1.1.1.1.m1.1.1.3.2.cmml\" xref=\"A5.T1.3.1.1.1.1.1.m1.1.1.3.2\">1</cn><cn type=\"integer\" id=\"A5.T1.3.1.1.1.1.1.m1.1.1.3.3.cmml\" xref=\"A5.T1.3.1.1.1.1.1.m1.1.1.3.3\">10</cn></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.3.1.1.1.1.1.m1.1c\">\\eta=1/10</annotation></semantics></math></td>\n</tr>\n<tr id=\"A5.T1.5.3.3.3.3\" class=\"ltx_tr\">\n<td id=\"A5.T1.5.3.3.3.3.2\" class=\"ltx_td ltx_nopad_r ltx_align_center\">(<math id=\"A5.T1.4.2.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"K=30\" display=\"inline\"><semantics id=\"A5.T1.4.2.2.2.2.1.m1.1a\"><mrow id=\"A5.T1.4.2.2.2.2.1.m1.1.1\" xref=\"A5.T1.4.2.2.2.2.1.m1.1.1.cmml\"><mi id=\"A5.T1.4.2.2.2.2.1.m1.1.1.2\" xref=\"A5.T1.4.2.2.2.2.1.m1.1.1.2.cmml\">K</mi><mo id=\"A5.T1.4.2.2.2.2.1.m1.1.1.1\" xref=\"A5.T1.4.2.2.2.2.1.m1.1.1.1.cmml\">=</mo><mn id=\"A5.T1.4.2.2.2.2.1.m1.1.1.3\" xref=\"A5.T1.4.2.2.2.2.1.m1.1.1.3.cmml\">30</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.4.2.2.2.2.1.m1.1b\"><apply id=\"A5.T1.4.2.2.2.2.1.m1.1.1.cmml\" xref=\"A5.T1.4.2.2.2.2.1.m1.1.1\"><eq id=\"A5.T1.4.2.2.2.2.1.m1.1.1.1.cmml\" xref=\"A5.T1.4.2.2.2.2.1.m1.1.1.1\"></eq><ci id=\"A5.T1.4.2.2.2.2.1.m1.1.1.2.cmml\" xref=\"A5.T1.4.2.2.2.2.1.m1.1.1.2\">𝐾</ci><cn type=\"integer\" id=\"A5.T1.4.2.2.2.2.1.m1.1.1.3.cmml\" xref=\"A5.T1.4.2.2.2.2.1.m1.1.1.3\">30</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.4.2.2.2.2.1.m1.1c\">K=30</annotation></semantics></math>, <math id=\"A5.T1.5.3.3.3.3.2.m2.1\" class=\"ltx_Math\" alttext=\"C=3\" display=\"inline\"><semantics id=\"A5.T1.5.3.3.3.3.2.m2.1a\"><mrow id=\"A5.T1.5.3.3.3.3.2.m2.1.1\" xref=\"A5.T1.5.3.3.3.3.2.m2.1.1.cmml\"><mi id=\"A5.T1.5.3.3.3.3.2.m2.1.1.2\" xref=\"A5.T1.5.3.3.3.3.2.m2.1.1.2.cmml\">C</mi><mo id=\"A5.T1.5.3.3.3.3.2.m2.1.1.1\" xref=\"A5.T1.5.3.3.3.3.2.m2.1.1.1.cmml\">=</mo><mn id=\"A5.T1.5.3.3.3.3.2.m2.1.1.3\" xref=\"A5.T1.5.3.3.3.3.2.m2.1.1.3.cmml\">3</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.5.3.3.3.3.2.m2.1b\"><apply id=\"A5.T1.5.3.3.3.3.2.m2.1.1.cmml\" xref=\"A5.T1.5.3.3.3.3.2.m2.1.1\"><eq id=\"A5.T1.5.3.3.3.3.2.m2.1.1.1.cmml\" xref=\"A5.T1.5.3.3.3.3.2.m2.1.1.1\"></eq><ci id=\"A5.T1.5.3.3.3.3.2.m2.1.1.2.cmml\" xref=\"A5.T1.5.3.3.3.3.2.m2.1.1.2\">𝐶</ci><cn type=\"integer\" id=\"A5.T1.5.3.3.3.3.2.m2.1.1.3.cmml\" xref=\"A5.T1.5.3.3.3.3.2.m2.1.1.3\">3</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.5.3.3.3.3.2.m2.1c\">C=3</annotation></semantics></math>)</td>\n</tr>\n</table>\n</td>\n<td id=\"A5.T1.8.6.6\" class=\"ltx_td ltx_align_center ltx_border_tt\">\n<table id=\"A5.T1.8.6.6.3\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A5.T1.6.4.4.1.1\" class=\"ltx_tr\">\n<td id=\"A5.T1.6.4.4.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><math id=\"A5.T1.6.4.4.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\eta=1/5\" display=\"inline\"><semantics id=\"A5.T1.6.4.4.1.1.1.m1.1a\"><mrow id=\"A5.T1.6.4.4.1.1.1.m1.1.1\" xref=\"A5.T1.6.4.4.1.1.1.m1.1.1.cmml\"><mi id=\"A5.T1.6.4.4.1.1.1.m1.1.1.2\" xref=\"A5.T1.6.4.4.1.1.1.m1.1.1.2.cmml\">η</mi><mo id=\"A5.T1.6.4.4.1.1.1.m1.1.1.1\" xref=\"A5.T1.6.4.4.1.1.1.m1.1.1.1.cmml\">=</mo><mrow id=\"A5.T1.6.4.4.1.1.1.m1.1.1.3\" xref=\"A5.T1.6.4.4.1.1.1.m1.1.1.3.cmml\"><mn id=\"A5.T1.6.4.4.1.1.1.m1.1.1.3.2\" xref=\"A5.T1.6.4.4.1.1.1.m1.1.1.3.2.cmml\">1</mn><mo id=\"A5.T1.6.4.4.1.1.1.m1.1.1.3.1\" xref=\"A5.T1.6.4.4.1.1.1.m1.1.1.3.1.cmml\">/</mo><mn id=\"A5.T1.6.4.4.1.1.1.m1.1.1.3.3\" xref=\"A5.T1.6.4.4.1.1.1.m1.1.1.3.3.cmml\">5</mn></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.6.4.4.1.1.1.m1.1b\"><apply id=\"A5.T1.6.4.4.1.1.1.m1.1.1.cmml\" xref=\"A5.T1.6.4.4.1.1.1.m1.1.1\"><eq id=\"A5.T1.6.4.4.1.1.1.m1.1.1.1.cmml\" xref=\"A5.T1.6.4.4.1.1.1.m1.1.1.1\"></eq><ci id=\"A5.T1.6.4.4.1.1.1.m1.1.1.2.cmml\" xref=\"A5.T1.6.4.4.1.1.1.m1.1.1.2\">𝜂</ci><apply id=\"A5.T1.6.4.4.1.1.1.m1.1.1.3.cmml\" xref=\"A5.T1.6.4.4.1.1.1.m1.1.1.3\"><divide id=\"A5.T1.6.4.4.1.1.1.m1.1.1.3.1.cmml\" xref=\"A5.T1.6.4.4.1.1.1.m1.1.1.3.1\"></divide><cn type=\"integer\" id=\"A5.T1.6.4.4.1.1.1.m1.1.1.3.2.cmml\" xref=\"A5.T1.6.4.4.1.1.1.m1.1.1.3.2\">1</cn><cn type=\"integer\" id=\"A5.T1.6.4.4.1.1.1.m1.1.1.3.3.cmml\" xref=\"A5.T1.6.4.4.1.1.1.m1.1.1.3.3\">5</cn></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.6.4.4.1.1.1.m1.1c\">\\eta=1/5</annotation></semantics></math></td>\n</tr>\n<tr id=\"A5.T1.8.6.6.3.3\" class=\"ltx_tr\">\n<td id=\"A5.T1.8.6.6.3.3.2\" class=\"ltx_td ltx_nopad_r ltx_align_center\">(<math id=\"A5.T1.7.5.5.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"K=30\" display=\"inline\"><semantics id=\"A5.T1.7.5.5.2.2.1.m1.1a\"><mrow id=\"A5.T1.7.5.5.2.2.1.m1.1.1\" xref=\"A5.T1.7.5.5.2.2.1.m1.1.1.cmml\"><mi id=\"A5.T1.7.5.5.2.2.1.m1.1.1.2\" xref=\"A5.T1.7.5.5.2.2.1.m1.1.1.2.cmml\">K</mi><mo id=\"A5.T1.7.5.5.2.2.1.m1.1.1.1\" xref=\"A5.T1.7.5.5.2.2.1.m1.1.1.1.cmml\">=</mo><mn id=\"A5.T1.7.5.5.2.2.1.m1.1.1.3\" xref=\"A5.T1.7.5.5.2.2.1.m1.1.1.3.cmml\">30</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.7.5.5.2.2.1.m1.1b\"><apply id=\"A5.T1.7.5.5.2.2.1.m1.1.1.cmml\" xref=\"A5.T1.7.5.5.2.2.1.m1.1.1\"><eq id=\"A5.T1.7.5.5.2.2.1.m1.1.1.1.cmml\" xref=\"A5.T1.7.5.5.2.2.1.m1.1.1.1\"></eq><ci id=\"A5.T1.7.5.5.2.2.1.m1.1.1.2.cmml\" xref=\"A5.T1.7.5.5.2.2.1.m1.1.1.2\">𝐾</ci><cn type=\"integer\" id=\"A5.T1.7.5.5.2.2.1.m1.1.1.3.cmml\" xref=\"A5.T1.7.5.5.2.2.1.m1.1.1.3\">30</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.7.5.5.2.2.1.m1.1c\">K=30</annotation></semantics></math>, <math id=\"A5.T1.8.6.6.3.3.2.m2.1\" class=\"ltx_Math\" alttext=\"C=6\" display=\"inline\"><semantics id=\"A5.T1.8.6.6.3.3.2.m2.1a\"><mrow id=\"A5.T1.8.6.6.3.3.2.m2.1.1\" xref=\"A5.T1.8.6.6.3.3.2.m2.1.1.cmml\"><mi id=\"A5.T1.8.6.6.3.3.2.m2.1.1.2\" xref=\"A5.T1.8.6.6.3.3.2.m2.1.1.2.cmml\">C</mi><mo id=\"A5.T1.8.6.6.3.3.2.m2.1.1.1\" xref=\"A5.T1.8.6.6.3.3.2.m2.1.1.1.cmml\">=</mo><mn id=\"A5.T1.8.6.6.3.3.2.m2.1.1.3\" xref=\"A5.T1.8.6.6.3.3.2.m2.1.1.3.cmml\">6</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.8.6.6.3.3.2.m2.1b\"><apply id=\"A5.T1.8.6.6.3.3.2.m2.1.1.cmml\" xref=\"A5.T1.8.6.6.3.3.2.m2.1.1\"><eq id=\"A5.T1.8.6.6.3.3.2.m2.1.1.1.cmml\" xref=\"A5.T1.8.6.6.3.3.2.m2.1.1.1\"></eq><ci id=\"A5.T1.8.6.6.3.3.2.m2.1.1.2.cmml\" xref=\"A5.T1.8.6.6.3.3.2.m2.1.1.2\">𝐶</ci><cn type=\"integer\" id=\"A5.T1.8.6.6.3.3.2.m2.1.1.3.cmml\" xref=\"A5.T1.8.6.6.3.3.2.m2.1.1.3\">6</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.8.6.6.3.3.2.m2.1c\">C=6</annotation></semantics></math>)</td>\n</tr>\n</table>\n</td>\n<td id=\"A5.T1.11.9.9\" class=\"ltx_td ltx_align_center ltx_border_tt\">\n<table id=\"A5.T1.11.9.9.3\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A5.T1.9.7.7.1.1\" class=\"ltx_tr\">\n<td id=\"A5.T1.9.7.7.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><math id=\"A5.T1.9.7.7.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\eta=1/3\" display=\"inline\"><semantics id=\"A5.T1.9.7.7.1.1.1.m1.1a\"><mrow id=\"A5.T1.9.7.7.1.1.1.m1.1.1\" xref=\"A5.T1.9.7.7.1.1.1.m1.1.1.cmml\"><mi id=\"A5.T1.9.7.7.1.1.1.m1.1.1.2\" xref=\"A5.T1.9.7.7.1.1.1.m1.1.1.2.cmml\">η</mi><mo id=\"A5.T1.9.7.7.1.1.1.m1.1.1.1\" xref=\"A5.T1.9.7.7.1.1.1.m1.1.1.1.cmml\">=</mo><mrow id=\"A5.T1.9.7.7.1.1.1.m1.1.1.3\" xref=\"A5.T1.9.7.7.1.1.1.m1.1.1.3.cmml\"><mn id=\"A5.T1.9.7.7.1.1.1.m1.1.1.3.2\" xref=\"A5.T1.9.7.7.1.1.1.m1.1.1.3.2.cmml\">1</mn><mo id=\"A5.T1.9.7.7.1.1.1.m1.1.1.3.1\" xref=\"A5.T1.9.7.7.1.1.1.m1.1.1.3.1.cmml\">/</mo><mn id=\"A5.T1.9.7.7.1.1.1.m1.1.1.3.3\" xref=\"A5.T1.9.7.7.1.1.1.m1.1.1.3.3.cmml\">3</mn></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.9.7.7.1.1.1.m1.1b\"><apply id=\"A5.T1.9.7.7.1.1.1.m1.1.1.cmml\" xref=\"A5.T1.9.7.7.1.1.1.m1.1.1\"><eq id=\"A5.T1.9.7.7.1.1.1.m1.1.1.1.cmml\" xref=\"A5.T1.9.7.7.1.1.1.m1.1.1.1\"></eq><ci id=\"A5.T1.9.7.7.1.1.1.m1.1.1.2.cmml\" xref=\"A5.T1.9.7.7.1.1.1.m1.1.1.2\">𝜂</ci><apply id=\"A5.T1.9.7.7.1.1.1.m1.1.1.3.cmml\" xref=\"A5.T1.9.7.7.1.1.1.m1.1.1.3\"><divide id=\"A5.T1.9.7.7.1.1.1.m1.1.1.3.1.cmml\" xref=\"A5.T1.9.7.7.1.1.1.m1.1.1.3.1\"></divide><cn type=\"integer\" id=\"A5.T1.9.7.7.1.1.1.m1.1.1.3.2.cmml\" xref=\"A5.T1.9.7.7.1.1.1.m1.1.1.3.2\">1</cn><cn type=\"integer\" id=\"A5.T1.9.7.7.1.1.1.m1.1.1.3.3.cmml\" xref=\"A5.T1.9.7.7.1.1.1.m1.1.1.3.3\">3</cn></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.9.7.7.1.1.1.m1.1c\">\\eta=1/3</annotation></semantics></math></td>\n</tr>\n<tr id=\"A5.T1.11.9.9.3.3\" class=\"ltx_tr\">\n<td id=\"A5.T1.11.9.9.3.3.2\" class=\"ltx_td ltx_nopad_r ltx_align_center\">(<math id=\"A5.T1.10.8.8.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"K=30\" display=\"inline\"><semantics id=\"A5.T1.10.8.8.2.2.1.m1.1a\"><mrow id=\"A5.T1.10.8.8.2.2.1.m1.1.1\" xref=\"A5.T1.10.8.8.2.2.1.m1.1.1.cmml\"><mi id=\"A5.T1.10.8.8.2.2.1.m1.1.1.2\" xref=\"A5.T1.10.8.8.2.2.1.m1.1.1.2.cmml\">K</mi><mo id=\"A5.T1.10.8.8.2.2.1.m1.1.1.1\" xref=\"A5.T1.10.8.8.2.2.1.m1.1.1.1.cmml\">=</mo><mn id=\"A5.T1.10.8.8.2.2.1.m1.1.1.3\" xref=\"A5.T1.10.8.8.2.2.1.m1.1.1.3.cmml\">30</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.10.8.8.2.2.1.m1.1b\"><apply id=\"A5.T1.10.8.8.2.2.1.m1.1.1.cmml\" xref=\"A5.T1.10.8.8.2.2.1.m1.1.1\"><eq id=\"A5.T1.10.8.8.2.2.1.m1.1.1.1.cmml\" xref=\"A5.T1.10.8.8.2.2.1.m1.1.1.1\"></eq><ci id=\"A5.T1.10.8.8.2.2.1.m1.1.1.2.cmml\" xref=\"A5.T1.10.8.8.2.2.1.m1.1.1.2\">𝐾</ci><cn type=\"integer\" id=\"A5.T1.10.8.8.2.2.1.m1.1.1.3.cmml\" xref=\"A5.T1.10.8.8.2.2.1.m1.1.1.3\">30</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.10.8.8.2.2.1.m1.1c\">K=30</annotation></semantics></math>, <math id=\"A5.T1.11.9.9.3.3.2.m2.1\" class=\"ltx_Math\" alttext=\"C=10\" display=\"inline\"><semantics id=\"A5.T1.11.9.9.3.3.2.m2.1a\"><mrow id=\"A5.T1.11.9.9.3.3.2.m2.1.1\" xref=\"A5.T1.11.9.9.3.3.2.m2.1.1.cmml\"><mi id=\"A5.T1.11.9.9.3.3.2.m2.1.1.2\" xref=\"A5.T1.11.9.9.3.3.2.m2.1.1.2.cmml\">C</mi><mo id=\"A5.T1.11.9.9.3.3.2.m2.1.1.1\" xref=\"A5.T1.11.9.9.3.3.2.m2.1.1.1.cmml\">=</mo><mn id=\"A5.T1.11.9.9.3.3.2.m2.1.1.3\" xref=\"A5.T1.11.9.9.3.3.2.m2.1.1.3.cmml\">10</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.11.9.9.3.3.2.m2.1b\"><apply id=\"A5.T1.11.9.9.3.3.2.m2.1.1.cmml\" xref=\"A5.T1.11.9.9.3.3.2.m2.1.1\"><eq id=\"A5.T1.11.9.9.3.3.2.m2.1.1.1.cmml\" xref=\"A5.T1.11.9.9.3.3.2.m2.1.1.1\"></eq><ci id=\"A5.T1.11.9.9.3.3.2.m2.1.1.2.cmml\" xref=\"A5.T1.11.9.9.3.3.2.m2.1.1.2\">𝐶</ci><cn type=\"integer\" id=\"A5.T1.11.9.9.3.3.2.m2.1.1.3.cmml\" xref=\"A5.T1.11.9.9.3.3.2.m2.1.1.3\">10</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.11.9.9.3.3.2.m2.1c\">C=10</annotation></semantics></math>)</td>\n</tr>\n</table>\n</td>\n<td id=\"A5.T1.14.12.12\" class=\"ltx_td ltx_align_center ltx_border_tt\">\n<table id=\"A5.T1.14.12.12.3\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"A5.T1.12.10.10.1.1\" class=\"ltx_tr\">\n<td id=\"A5.T1.12.10.10.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><math id=\"A5.T1.12.10.10.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\eta=1\" display=\"inline\"><semantics id=\"A5.T1.12.10.10.1.1.1.m1.1a\"><mrow id=\"A5.T1.12.10.10.1.1.1.m1.1.1\" xref=\"A5.T1.12.10.10.1.1.1.m1.1.1.cmml\"><mi id=\"A5.T1.12.10.10.1.1.1.m1.1.1.2\" xref=\"A5.T1.12.10.10.1.1.1.m1.1.1.2.cmml\">η</mi><mo id=\"A5.T1.12.10.10.1.1.1.m1.1.1.1\" xref=\"A5.T1.12.10.10.1.1.1.m1.1.1.1.cmml\">=</mo><mn id=\"A5.T1.12.10.10.1.1.1.m1.1.1.3\" xref=\"A5.T1.12.10.10.1.1.1.m1.1.1.3.cmml\">1</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.12.10.10.1.1.1.m1.1b\"><apply id=\"A5.T1.12.10.10.1.1.1.m1.1.1.cmml\" xref=\"A5.T1.12.10.10.1.1.1.m1.1.1\"><eq id=\"A5.T1.12.10.10.1.1.1.m1.1.1.1.cmml\" xref=\"A5.T1.12.10.10.1.1.1.m1.1.1.1\"></eq><ci id=\"A5.T1.12.10.10.1.1.1.m1.1.1.2.cmml\" xref=\"A5.T1.12.10.10.1.1.1.m1.1.1.2\">𝜂</ci><cn type=\"integer\" id=\"A5.T1.12.10.10.1.1.1.m1.1.1.3.cmml\" xref=\"A5.T1.12.10.10.1.1.1.m1.1.1.3\">1</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.12.10.10.1.1.1.m1.1c\">\\eta=1</annotation></semantics></math></td>\n</tr>\n<tr id=\"A5.T1.14.12.12.3.3\" class=\"ltx_tr\">\n<td id=\"A5.T1.14.12.12.3.3.2\" class=\"ltx_td ltx_nopad_r ltx_align_center\">(<math id=\"A5.T1.13.11.11.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"K=30\" display=\"inline\"><semantics id=\"A5.T1.13.11.11.2.2.1.m1.1a\"><mrow id=\"A5.T1.13.11.11.2.2.1.m1.1.1\" xref=\"A5.T1.13.11.11.2.2.1.m1.1.1.cmml\"><mi id=\"A5.T1.13.11.11.2.2.1.m1.1.1.2\" xref=\"A5.T1.13.11.11.2.2.1.m1.1.1.2.cmml\">K</mi><mo id=\"A5.T1.13.11.11.2.2.1.m1.1.1.1\" xref=\"A5.T1.13.11.11.2.2.1.m1.1.1.1.cmml\">=</mo><mn id=\"A5.T1.13.11.11.2.2.1.m1.1.1.3\" xref=\"A5.T1.13.11.11.2.2.1.m1.1.1.3.cmml\">30</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.13.11.11.2.2.1.m1.1b\"><apply id=\"A5.T1.13.11.11.2.2.1.m1.1.1.cmml\" xref=\"A5.T1.13.11.11.2.2.1.m1.1.1\"><eq id=\"A5.T1.13.11.11.2.2.1.m1.1.1.1.cmml\" xref=\"A5.T1.13.11.11.2.2.1.m1.1.1.1\"></eq><ci id=\"A5.T1.13.11.11.2.2.1.m1.1.1.2.cmml\" xref=\"A5.T1.13.11.11.2.2.1.m1.1.1.2\">𝐾</ci><cn type=\"integer\" id=\"A5.T1.13.11.11.2.2.1.m1.1.1.3.cmml\" xref=\"A5.T1.13.11.11.2.2.1.m1.1.1.3\">30</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.13.11.11.2.2.1.m1.1c\">K=30</annotation></semantics></math>, <math id=\"A5.T1.14.12.12.3.3.2.m2.1\" class=\"ltx_Math\" alttext=\"C=30\" display=\"inline\"><semantics id=\"A5.T1.14.12.12.3.3.2.m2.1a\"><mrow id=\"A5.T1.14.12.12.3.3.2.m2.1.1\" xref=\"A5.T1.14.12.12.3.3.2.m2.1.1.cmml\"><mi id=\"A5.T1.14.12.12.3.3.2.m2.1.1.2\" xref=\"A5.T1.14.12.12.3.3.2.m2.1.1.2.cmml\">C</mi><mo id=\"A5.T1.14.12.12.3.3.2.m2.1.1.1\" xref=\"A5.T1.14.12.12.3.3.2.m2.1.1.1.cmml\">=</mo><mn id=\"A5.T1.14.12.12.3.3.2.m2.1.1.3\" xref=\"A5.T1.14.12.12.3.3.2.m2.1.1.3.cmml\">30</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.14.12.12.3.3.2.m2.1b\"><apply id=\"A5.T1.14.12.12.3.3.2.m2.1.1.cmml\" xref=\"A5.T1.14.12.12.3.3.2.m2.1.1\"><eq id=\"A5.T1.14.12.12.3.3.2.m2.1.1.1.cmml\" xref=\"A5.T1.14.12.12.3.3.2.m2.1.1.1\"></eq><ci id=\"A5.T1.14.12.12.3.3.2.m2.1.1.2.cmml\" xref=\"A5.T1.14.12.12.3.3.2.m2.1.1.2\">𝐶</ci><cn type=\"integer\" id=\"A5.T1.14.12.12.3.3.2.m2.1.1.3.cmml\" xref=\"A5.T1.14.12.12.3.3.2.m2.1.1.3\">30</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.14.12.12.3.3.2.m2.1c\">C=30</annotation></semantics></math>)</td>\n</tr>\n</table>\n</td>\n</tr>\n<tr id=\"A5.T1.18.16\" class=\"ltx_tr\" style=\"background-color:#FFCC99;\">\n<td id=\"A5.T1.18.16.5\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"A5.T1.18.16.5.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">Cifar-10 (Grouping-based)</span></td>\n<td id=\"A5.T1.15.13.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A5.T1.15.13.1.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">82.48<math id=\"A5.T1.15.13.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A5.T1.15.13.1.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"A5.T1.15.13.1.1.m1.1.1\" xref=\"A5.T1.15.13.1.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.15.13.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A5.T1.15.13.1.1.m1.1.1.cmml\" xref=\"A5.T1.15.13.1.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.15.13.1.1.m1.1c\">\\%</annotation></semantics></math></span></td>\n<td id=\"A5.T1.16.14.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A5.T1.16.14.2.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">92.08<math id=\"A5.T1.16.14.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A5.T1.16.14.2.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"A5.T1.16.14.2.1.m1.1.1\" xref=\"A5.T1.16.14.2.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.16.14.2.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A5.T1.16.14.2.1.m1.1.1.cmml\" xref=\"A5.T1.16.14.2.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.16.14.2.1.m1.1c\">\\%</annotation></semantics></math></span></td>\n<td id=\"A5.T1.17.15.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A5.T1.17.15.3.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">92.84<math id=\"A5.T1.17.15.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A5.T1.17.15.3.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"A5.T1.17.15.3.1.m1.1.1\" xref=\"A5.T1.17.15.3.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.17.15.3.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A5.T1.17.15.3.1.m1.1.1.cmml\" xref=\"A5.T1.17.15.3.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.17.15.3.1.m1.1c\">\\%</annotation></semantics></math></span></td>\n<td id=\"A5.T1.18.16.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A5.T1.18.16.4.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">92.12<math id=\"A5.T1.18.16.4.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A5.T1.18.16.4.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"A5.T1.18.16.4.1.m1.1.1\" xref=\"A5.T1.18.16.4.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.18.16.4.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A5.T1.18.16.4.1.m1.1.1.cmml\" xref=\"A5.T1.18.16.4.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.18.16.4.1.m1.1c\">\\%</annotation></semantics></math></span></td>\n</tr>\n<tr id=\"A5.T1.22.20\" class=\"ltx_tr\">\n<td id=\"A5.T1.22.20.5\" class=\"ltx_td ltx_align_left ltx_border_bb\">SVHN (Grouping-based)</td>\n<td id=\"A5.T1.19.17.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">92.83<math id=\"A5.T1.19.17.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A5.T1.19.17.1.m1.1a\"><mo id=\"A5.T1.19.17.1.m1.1.1\" xref=\"A5.T1.19.17.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.19.17.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A5.T1.19.17.1.m1.1.1.cmml\" xref=\"A5.T1.19.17.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.19.17.1.m1.1c\">\\%</annotation></semantics></math>\n</td>\n<td id=\"A5.T1.20.18.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">93.42<math id=\"A5.T1.20.18.2.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A5.T1.20.18.2.m1.1a\"><mo id=\"A5.T1.20.18.2.m1.1.1\" xref=\"A5.T1.20.18.2.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.20.18.2.m1.1b\"><csymbol cd=\"latexml\" id=\"A5.T1.20.18.2.m1.1.1.cmml\" xref=\"A5.T1.20.18.2.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.20.18.2.m1.1c\">\\%</annotation></semantics></math>\n</td>\n<td id=\"A5.T1.21.19.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">93.56<math id=\"A5.T1.21.19.3.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A5.T1.21.19.3.m1.1a\"><mo id=\"A5.T1.21.19.3.m1.1.1\" xref=\"A5.T1.21.19.3.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.21.19.3.m1.1b\"><csymbol cd=\"latexml\" id=\"A5.T1.21.19.3.m1.1.1.cmml\" xref=\"A5.T1.21.19.3.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.21.19.3.m1.1c\">\\%</annotation></semantics></math>\n</td>\n<td id=\"A5.T1.22.20.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">78.77<math id=\"A5.T1.22.20.4.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A5.T1.22.20.4.m1.1a\"><mo id=\"A5.T1.22.20.4.m1.1.1\" xref=\"A5.T1.22.20.4.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A5.T1.22.20.4.m1.1b\"><csymbol cd=\"latexml\" id=\"A5.T1.22.20.4.m1.1.1.cmml\" xref=\"A5.T1.22.20.4.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A5.T1.22.20.4.m1.1c\">\\%</annotation></semantics></math>\n</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "As can be seen from the top of Tab. 1, increasing the number of users K𝐾K has a marginal effect (<<1%) on the accuracy, from K=10𝐾10K=10 to K=30𝐾30K=30.\nOne notable thing here is that with K=30𝐾30K=30, if we train 40 epochs on SVHN, the accuracy is 78.77%, which is 16.72% lower than K=10𝐾10K=10.\nIf we increase the training epochs from 40 to 120 for K=30𝐾30K=30 on SVHN, the final accuracy is 94.93%. One can refer to Fig. C.1 for the convergence curve of this experiment.",
            "In this subsection, we compare our grouping-based method with other FL algorithms, in both semi-supervised and supervised settings.\nFirst, in the semi-supervised setting, we conduct the experiment on Cifar-10 with exactly the same setting as a recent SSFL paper [9].\nFor the Cifar-10 data, according to Table 1 in [9], we set Ns=5000subscript𝑁𝑠5000N_{s}=5000, K=100𝐾100K=100, C=5𝐶5C=5, and R=0𝑅0R=0 (which is the iid case) or R=1𝑅1R=1 (which is the most difficult non-iid case).\nFrom Tab. 3, one can see that our grouping-based solution outperforms the method proposed in [9] by a large margin.\nWe notice that the results in [9] are presented in two different settings including the labels-at-server setting and the labels-at-client setting.\nThe first setting is the same as our paper, i.e., only the server has labeled data, while the users have unlabeled data.\nIn this setting, Ns=5000subscript𝑁𝑠5000N_{s}=5000 labeled data are own by the server.\nThe second setting is different but it is straightforward to apply our grouping-based solution.\nIn this setting, Ns=5000subscript𝑁𝑠5000N_{s}=5000 labeled data are distributed to 100 users. In each round, C=5𝐶5C=5 users are random selected to communicate with the server.\nSee Appendix H for the details of adapting our solution to the label-at-the-client setting.",
            "There are other important issues we consider.\nFor example, we evaluate the performance of our grouping-based method in fully supervised FL in § F, and we show that the improvement in this scenario is limited. Thus, our method is more suitable in the SSFL setting.\nWe also compare our grouping-based solution with FixMatch [11] in § G).\nWe show that our results are comparable to FixMatch even if FixMatch uses centralized setting.\nMoreover, we extend our current methods to the setting where users can have both labeled and unlabeled samples in § H, i.e., the labels-at-client case.\nWe also provide additional results on another semi-supervised dataset STL-10, see § I.\nFinally, since for federated learning, we are interested in studying what happens when the number of users is large, we provide an additional experiment with the number of users set to 470 in § J. We show that the grouping-based method outperforms FedAvg in this setting as well.",
            "Federated learning.\nFederated learning (FL) [1, 2, 4, 27, 16, 28, 29, 30, 18, 31] is a decentralized computing framework that enables multiple users to learn a shared model while potentially protecting the privacy of users (although recent work [32] shows this may not be the case).\nFederated Averaging (FedAvg) [2], which is the most popular FL algorithm, shows good performance when the data distribution across users is iid.\nHowever, in the non-iid case, the performance can significantly degrade.\nIn fact, dealing with non-iid distributions is deemed by many to be one of the most critical challenges in FL [16, 28, 33].\nIn [16], a data-sharing method is proposed to improve the final accuracy.\nHowever, sharing massive data among all users requires both large storage space as well as stable connections between users and the server.\nImportantly, all of these methods require the data stored by the local users to come with ground-truth labels (in order to perform model updates locally).\nThe FL problem in the semi-supervised setting, when users do not have labels, however, is “relatively ignored” and has “little prior arts,” as mentioned in a recent survey paper [4].",
            "In this section, we study whether the grouping-based averaging can be extended to supervised FL (SFL). We want to see whether this particular way of averaging is more suitable for the semi-supervised setup or the supervised setup.\nWe conduct experiments on EMNIST using SFL with three different settings with different number of users K∈{47,20,10}𝐾472010K\\in\\{47,20,10\\}. In these three settings, we let C=K𝐶𝐾C=K.\nThe other environmental factors are shown in rows 32-34 of Tab. A.2.\nWe set the group number S=5𝑆5S=5, S=2𝑆2S=2 and S=2𝑆2S=2 for the setting of K=47𝐾47K=47, K=20𝐾20K=20 and K=10𝐾10K=10, respectively.\nSee Table F.1.\nThe results show that the performance of the grouping method is only slightly better than that of FedAvg.\nThus, the performance gain of the grouping-based averaging method for SFL is much less than that of SSFL. This mean that grouping-based averaging is more suitable for the semi-supervised setup than the supervised setup.",
            "The results in Table J.1 show that the performance of the grouping-based averaging is better than that of FedAvg even with 470 users. One can also observe that as the number of communicating users C𝐶C increases, the performance of the FedAvg decreases, which is consistent with the experimental phenomenon observed in § 4.2."
        ]
    },
    "A6.T1": {
        "caption": "Table F.1: The accuracy comparison of FedAvg and the grouping-based average for supervised FL on EMNSIT.\n",
        "table": "<div id=\"A6.T1.9\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:284.0pt;height:73.9pt;vertical-align:-1.9pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(0.0pt,0.0pt) scale(1,1) ;\">\n<p id=\"A6.T1.9.9\" class=\"ltx_p\"><span id=\"A6.T1.9.9.9\" class=\"ltx_text\">\n<span id=\"A6.T1.9.9.9.9\" class=\"ltx_tabular ltx_align_top\">\n<span id=\"A6.T1.9.9.9.9.10\" class=\"ltx_tr\">\n<span id=\"A6.T1.9.9.9.9.10.1\" class=\"ltx_td ltx_align_left ltx_border_tt\">User number</span>\n<span id=\"A6.T1.9.9.9.9.10.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">FedAvg</span>\n<span id=\"A6.T1.9.9.9.9.10.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">Grouping-based</span>\n<span id=\"A6.T1.9.9.9.9.10.4\" class=\"ltx_td ltx_border_tt\"></span></span>\n<span id=\"A6.T1.3.3.3.3.3\" class=\"ltx_tr\">\n<span id=\"A6.T1.1.1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><math id=\"A6.T1.1.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"K=47\" display=\"inline\"><semantics id=\"A6.T1.1.1.1.1.1.1.m1.1a\"><mrow id=\"A6.T1.1.1.1.1.1.1.m1.1.1\" xref=\"A6.T1.1.1.1.1.1.1.m1.1.1.cmml\"><mi id=\"A6.T1.1.1.1.1.1.1.m1.1.1.2\" xref=\"A6.T1.1.1.1.1.1.1.m1.1.1.2.cmml\">K</mi><mo id=\"A6.T1.1.1.1.1.1.1.m1.1.1.1\" xref=\"A6.T1.1.1.1.1.1.1.m1.1.1.1.cmml\">=</mo><mn id=\"A6.T1.1.1.1.1.1.1.m1.1.1.3\" xref=\"A6.T1.1.1.1.1.1.1.m1.1.1.3.cmml\">47</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A6.T1.1.1.1.1.1.1.m1.1b\"><apply id=\"A6.T1.1.1.1.1.1.1.m1.1.1.cmml\" xref=\"A6.T1.1.1.1.1.1.1.m1.1.1\"><eq id=\"A6.T1.1.1.1.1.1.1.m1.1.1.1.cmml\" xref=\"A6.T1.1.1.1.1.1.1.m1.1.1.1\"></eq><ci id=\"A6.T1.1.1.1.1.1.1.m1.1.1.2.cmml\" xref=\"A6.T1.1.1.1.1.1.1.m1.1.1.2\">𝐾</ci><cn type=\"integer\" id=\"A6.T1.1.1.1.1.1.1.m1.1.1.3.cmml\" xref=\"A6.T1.1.1.1.1.1.1.m1.1.1.3\">47</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T1.1.1.1.1.1.1.m1.1c\">K=47</annotation></semantics></math></span>\n<span id=\"A6.T1.2.2.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">84.71<math id=\"A6.T1.2.2.2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A6.T1.2.2.2.2.2.2.m1.1a\"><mo id=\"A6.T1.2.2.2.2.2.2.m1.1.1\" xref=\"A6.T1.2.2.2.2.2.2.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A6.T1.2.2.2.2.2.2.m1.1b\"><csymbol cd=\"latexml\" id=\"A6.T1.2.2.2.2.2.2.m1.1.1.cmml\" xref=\"A6.T1.2.2.2.2.2.2.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T1.2.2.2.2.2.2.m1.1c\">\\%</annotation></semantics></math></span>\n<span id=\"A6.T1.3.3.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A6.T1.3.3.3.3.3.3.1\" class=\"ltx_text ltx_font_bold\">84.97<math id=\"A6.T1.3.3.3.3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A6.T1.3.3.3.3.3.3.1.m1.1a\"><mo id=\"A6.T1.3.3.3.3.3.3.1.m1.1.1\" xref=\"A6.T1.3.3.3.3.3.3.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A6.T1.3.3.3.3.3.3.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A6.T1.3.3.3.3.3.3.1.m1.1.1.cmml\" xref=\"A6.T1.3.3.3.3.3.3.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T1.3.3.3.3.3.3.1.m1.1c\">\\%</annotation></semantics></math></span></span>\n<span id=\"A6.T1.3.3.3.3.3.4\" class=\"ltx_td ltx_border_t\"></span></span>\n<span id=\"A6.T1.6.6.6.6.6\" class=\"ltx_tr\" style=\"background-color:#FFCC99;\">\n<span id=\"A6.T1.4.4.4.4.4.1\" class=\"ltx_td ltx_align_left\"><math id=\"A6.T1.4.4.4.4.4.1.m1.1\" class=\"ltx_Math\" style=\"background-color:#FFCC99;\" alttext=\"K=20\" display=\"inline\"><semantics id=\"A6.T1.4.4.4.4.4.1.m1.1a\"><mrow id=\"A6.T1.4.4.4.4.4.1.m1.1.1\" xref=\"A6.T1.4.4.4.4.4.1.m1.1.1.cmml\"><mi mathbackground=\"#FFCC99\" id=\"A6.T1.4.4.4.4.4.1.m1.1.1.2\" xref=\"A6.T1.4.4.4.4.4.1.m1.1.1.2.cmml\">K</mi><mo mathbackground=\"#FFCC99\" id=\"A6.T1.4.4.4.4.4.1.m1.1.1.1\" xref=\"A6.T1.4.4.4.4.4.1.m1.1.1.1.cmml\">=</mo><mn mathbackground=\"#FFCC99\" id=\"A6.T1.4.4.4.4.4.1.m1.1.1.3\" xref=\"A6.T1.4.4.4.4.4.1.m1.1.1.3.cmml\">20</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A6.T1.4.4.4.4.4.1.m1.1b\"><apply id=\"A6.T1.4.4.4.4.4.1.m1.1.1.cmml\" xref=\"A6.T1.4.4.4.4.4.1.m1.1.1\"><eq id=\"A6.T1.4.4.4.4.4.1.m1.1.1.1.cmml\" xref=\"A6.T1.4.4.4.4.4.1.m1.1.1.1\"></eq><ci id=\"A6.T1.4.4.4.4.4.1.m1.1.1.2.cmml\" xref=\"A6.T1.4.4.4.4.4.1.m1.1.1.2\">𝐾</ci><cn type=\"integer\" id=\"A6.T1.4.4.4.4.4.1.m1.1.1.3.cmml\" xref=\"A6.T1.4.4.4.4.4.1.m1.1.1.3\">20</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T1.4.4.4.4.4.1.m1.1c\">K=20</annotation></semantics></math></span>\n<span id=\"A6.T1.5.5.5.5.5.2\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T1.5.5.5.5.5.2.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">86.14<math id=\"A6.T1.5.5.5.5.5.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A6.T1.5.5.5.5.5.2.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"A6.T1.5.5.5.5.5.2.1.m1.1.1\" xref=\"A6.T1.5.5.5.5.5.2.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A6.T1.5.5.5.5.5.2.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A6.T1.5.5.5.5.5.2.1.m1.1.1.cmml\" xref=\"A6.T1.5.5.5.5.5.2.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T1.5.5.5.5.5.2.1.m1.1c\">\\%</annotation></semantics></math></span></span>\n<span id=\"A6.T1.6.6.6.6.6.3\" class=\"ltx_td ltx_align_center\"><span id=\"A6.T1.6.6.6.6.6.3.1\" class=\"ltx_text ltx_font_bold\" style=\"background-color:#FFCC99;\">86.27<math id=\"A6.T1.6.6.6.6.6.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A6.T1.6.6.6.6.6.3.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"A6.T1.6.6.6.6.6.3.1.m1.1.1\" xref=\"A6.T1.6.6.6.6.6.3.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A6.T1.6.6.6.6.6.3.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A6.T1.6.6.6.6.6.3.1.m1.1.1.cmml\" xref=\"A6.T1.6.6.6.6.6.3.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T1.6.6.6.6.6.3.1.m1.1c\">\\%</annotation></semantics></math></span></span>\n<span id=\"A6.T1.6.6.6.6.6.4\" class=\"ltx_td\"></span></span>\n<span id=\"A6.T1.9.9.9.9.9\" class=\"ltx_tr\">\n<span id=\"A6.T1.7.7.7.7.7.1\" class=\"ltx_td ltx_align_left ltx_border_bb\"><math id=\"A6.T1.7.7.7.7.7.1.m1.1\" class=\"ltx_Math\" alttext=\"K=10\" display=\"inline\"><semantics id=\"A6.T1.7.7.7.7.7.1.m1.1a\"><mrow id=\"A6.T1.7.7.7.7.7.1.m1.1.1\" xref=\"A6.T1.7.7.7.7.7.1.m1.1.1.cmml\"><mi id=\"A6.T1.7.7.7.7.7.1.m1.1.1.2\" xref=\"A6.T1.7.7.7.7.7.1.m1.1.1.2.cmml\">K</mi><mo id=\"A6.T1.7.7.7.7.7.1.m1.1.1.1\" xref=\"A6.T1.7.7.7.7.7.1.m1.1.1.1.cmml\">=</mo><mn id=\"A6.T1.7.7.7.7.7.1.m1.1.1.3\" xref=\"A6.T1.7.7.7.7.7.1.m1.1.1.3.cmml\">10</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A6.T1.7.7.7.7.7.1.m1.1b\"><apply id=\"A6.T1.7.7.7.7.7.1.m1.1.1.cmml\" xref=\"A6.T1.7.7.7.7.7.1.m1.1.1\"><eq id=\"A6.T1.7.7.7.7.7.1.m1.1.1.1.cmml\" xref=\"A6.T1.7.7.7.7.7.1.m1.1.1.1\"></eq><ci id=\"A6.T1.7.7.7.7.7.1.m1.1.1.2.cmml\" xref=\"A6.T1.7.7.7.7.7.1.m1.1.1.2\">𝐾</ci><cn type=\"integer\" id=\"A6.T1.7.7.7.7.7.1.m1.1.1.3.cmml\" xref=\"A6.T1.7.7.7.7.7.1.m1.1.1.3\">10</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T1.7.7.7.7.7.1.m1.1c\">K=10</annotation></semantics></math></span>\n<span id=\"A6.T1.8.8.8.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">86.19<math id=\"A6.T1.8.8.8.8.8.2.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A6.T1.8.8.8.8.8.2.m1.1a\"><mo id=\"A6.T1.8.8.8.8.8.2.m1.1.1\" xref=\"A6.T1.8.8.8.8.8.2.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A6.T1.8.8.8.8.8.2.m1.1b\"><csymbol cd=\"latexml\" id=\"A6.T1.8.8.8.8.8.2.m1.1.1.cmml\" xref=\"A6.T1.8.8.8.8.8.2.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T1.8.8.8.8.8.2.m1.1c\">\\%</annotation></semantics></math></span>\n<span id=\"A6.T1.9.9.9.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"A6.T1.9.9.9.9.9.3.1\" class=\"ltx_text ltx_font_bold\">86.29<math id=\"A6.T1.9.9.9.9.9.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A6.T1.9.9.9.9.9.3.1.m1.1a\"><mo id=\"A6.T1.9.9.9.9.9.3.1.m1.1.1\" xref=\"A6.T1.9.9.9.9.9.3.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A6.T1.9.9.9.9.9.3.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A6.T1.9.9.9.9.9.3.1.m1.1.1.cmml\" xref=\"A6.T1.9.9.9.9.9.3.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A6.T1.9.9.9.9.9.3.1.m1.1c\">\\%</annotation></semantics></math></span></span>\n<span id=\"A6.T1.9.9.9.9.9.4\" class=\"ltx_td ltx_border_bb\"></span></span>\n</span></span></p>\n</span></div>\n\n",
        "footnotes": "\n\n\nUser number\nFedAvg\nGrouping-based\n\n\nK=47𝐾47K=47\n84.71%percent\\%\n84.97%percent\\%\n\n\nK=20𝐾20K=20\n86.14%percent\\%\n86.27%percent\\%\n\n\nK=10𝐾10K=10\n86.19%percent\\%\n86.29%percent\\%\n\n",
        "references": [
            "As can be seen from the top of Tab. 1, increasing the number of users K𝐾K has a marginal effect (<<1%) on the accuracy, from K=10𝐾10K=10 to K=30𝐾30K=30.\nOne notable thing here is that with K=30𝐾30K=30, if we train 40 epochs on SVHN, the accuracy is 78.77%, which is 16.72% lower than K=10𝐾10K=10.\nIf we increase the training epochs from 40 to 120 for K=30𝐾30K=30 on SVHN, the final accuracy is 94.93%. One can refer to Fig. C.1 for the convergence curve of this experiment.",
            "In this subsection, we compare our grouping-based method with other FL algorithms, in both semi-supervised and supervised settings.\nFirst, in the semi-supervised setting, we conduct the experiment on Cifar-10 with exactly the same setting as a recent SSFL paper [9].\nFor the Cifar-10 data, according to Table 1 in [9], we set Ns=5000subscript𝑁𝑠5000N_{s}=5000, K=100𝐾100K=100, C=5𝐶5C=5, and R=0𝑅0R=0 (which is the iid case) or R=1𝑅1R=1 (which is the most difficult non-iid case).\nFrom Tab. 3, one can see that our grouping-based solution outperforms the method proposed in [9] by a large margin.\nWe notice that the results in [9] are presented in two different settings including the labels-at-server setting and the labels-at-client setting.\nThe first setting is the same as our paper, i.e., only the server has labeled data, while the users have unlabeled data.\nIn this setting, Ns=5000subscript𝑁𝑠5000N_{s}=5000 labeled data are own by the server.\nThe second setting is different but it is straightforward to apply our grouping-based solution.\nIn this setting, Ns=5000subscript𝑁𝑠5000N_{s}=5000 labeled data are distributed to 100 users. In each round, C=5𝐶5C=5 users are random selected to communicate with the server.\nSee Appendix H for the details of adapting our solution to the label-at-the-client setting.",
            "There are other important issues we consider.\nFor example, we evaluate the performance of our grouping-based method in fully supervised FL in § F, and we show that the improvement in this scenario is limited. Thus, our method is more suitable in the SSFL setting.\nWe also compare our grouping-based solution with FixMatch [11] in § G).\nWe show that our results are comparable to FixMatch even if FixMatch uses centralized setting.\nMoreover, we extend our current methods to the setting where users can have both labeled and unlabeled samples in § H, i.e., the labels-at-client case.\nWe also provide additional results on another semi-supervised dataset STL-10, see § I.\nFinally, since for federated learning, we are interested in studying what happens when the number of users is large, we provide an additional experiment with the number of users set to 470 in § J. We show that the grouping-based method outperforms FedAvg in this setting as well.",
            "Federated learning.\nFederated learning (FL) [1, 2, 4, 27, 16, 28, 29, 30, 18, 31] is a decentralized computing framework that enables multiple users to learn a shared model while potentially protecting the privacy of users (although recent work [32] shows this may not be the case).\nFederated Averaging (FedAvg) [2], which is the most popular FL algorithm, shows good performance when the data distribution across users is iid.\nHowever, in the non-iid case, the performance can significantly degrade.\nIn fact, dealing with non-iid distributions is deemed by many to be one of the most critical challenges in FL [16, 28, 33].\nIn [16], a data-sharing method is proposed to improve the final accuracy.\nHowever, sharing massive data among all users requires both large storage space as well as stable connections between users and the server.\nImportantly, all of these methods require the data stored by the local users to come with ground-truth labels (in order to perform model updates locally).\nThe FL problem in the semi-supervised setting, when users do not have labels, however, is “relatively ignored” and has “little prior arts,” as mentioned in a recent survey paper [4].",
            "In this section, we study whether the grouping-based averaging can be extended to supervised FL (SFL). We want to see whether this particular way of averaging is more suitable for the semi-supervised setup or the supervised setup.\nWe conduct experiments on EMNIST using SFL with three different settings with different number of users K∈{47,20,10}𝐾472010K\\in\\{47,20,10\\}. In these three settings, we let C=K𝐶𝐾C=K.\nThe other environmental factors are shown in rows 32-34 of Tab. A.2.\nWe set the group number S=5𝑆5S=5, S=2𝑆2S=2 and S=2𝑆2S=2 for the setting of K=47𝐾47K=47, K=20𝐾20K=20 and K=10𝐾10K=10, respectively.\nSee Table F.1.\nThe results show that the performance of the grouping method is only slightly better than that of FedAvg.\nThus, the performance gain of the grouping-based averaging method for SFL is much less than that of SSFL. This mean that grouping-based averaging is more suitable for the semi-supervised setup than the supervised setup.",
            "The results in Table J.1 show that the performance of the grouping-based averaging is better than that of FedAvg even with 470 users. One can also observe that as the number of communicating users C𝐶C increases, the performance of the FedAvg decreases, which is consistent with the experimental phenomenon observed in § 4.2."
        ]
    },
    "A7.T1": {
        "caption": "Table G.1: Comparison with FixMatch.\n",
        "table": "<table id=\"A7.T1.6\" class=\"ltx_tabular ltx_centering ltx_align_top\">\n<tr id=\"A7.T1.6.7\" class=\"ltx_tr\">\n<td id=\"A7.T1.6.7.1\" class=\"ltx_td ltx_align_left ltx_border_tt\">Dataset</td>\n<td id=\"A7.T1.6.7.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">FixMatch</td>\n<td id=\"A7.T1.6.7.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">Grouping-based</td>\n<td id=\"A7.T1.6.7.4\" class=\"ltx_td ltx_border_tt\"></td>\n</tr>\n<tr id=\"A7.T1.2.2\" class=\"ltx_tr\">\n<td id=\"A7.T1.2.2.3\" class=\"ltx_td ltx_align_left ltx_border_t\">Cifar10</td>\n<td id=\"A7.T1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">95.74<math id=\"A7.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A7.T1.1.1.1.m1.1a\"><mo id=\"A7.T1.1.1.1.m1.1.1\" xref=\"A7.T1.1.1.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A7.T1.1.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A7.T1.1.1.1.m1.1.1.cmml\" xref=\"A7.T1.1.1.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A7.T1.1.1.1.m1.1c\">\\%</annotation></semantics></math>\n</td>\n<td id=\"A7.T1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">92.86<math id=\"A7.T1.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A7.T1.2.2.2.m1.1a\"><mo id=\"A7.T1.2.2.2.m1.1.1\" xref=\"A7.T1.2.2.2.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A7.T1.2.2.2.m1.1b\"><csymbol cd=\"latexml\" id=\"A7.T1.2.2.2.m1.1.1.cmml\" xref=\"A7.T1.2.2.2.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A7.T1.2.2.2.m1.1c\">\\%</annotation></semantics></math>\n</td>\n<td id=\"A7.T1.2.2.4\" class=\"ltx_td ltx_border_t\"></td>\n</tr>\n<tr id=\"A7.T1.4.4\" class=\"ltx_tr\" style=\"background-color:#FFCC99;\">\n<td id=\"A7.T1.4.4.3\" class=\"ltx_td ltx_align_left\"><span id=\"A7.T1.4.4.3.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">SVHN</span></td>\n<td id=\"A7.T1.3.3.1\" class=\"ltx_td ltx_align_center\"><span id=\"A7.T1.3.3.1.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">97.72<math id=\"A7.T1.3.3.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A7.T1.3.3.1.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"A7.T1.3.3.1.1.m1.1.1\" xref=\"A7.T1.3.3.1.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A7.T1.3.3.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A7.T1.3.3.1.1.m1.1.1.cmml\" xref=\"A7.T1.3.3.1.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A7.T1.3.3.1.1.m1.1c\">\\%</annotation></semantics></math></span></td>\n<td id=\"A7.T1.4.4.2\" class=\"ltx_td ltx_align_center\"><span id=\"A7.T1.4.4.2.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">95.49<math id=\"A7.T1.4.4.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A7.T1.4.4.2.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"A7.T1.4.4.2.1.m1.1.1\" xref=\"A7.T1.4.4.2.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A7.T1.4.4.2.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A7.T1.4.4.2.1.m1.1.1.cmml\" xref=\"A7.T1.4.4.2.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A7.T1.4.4.2.1.m1.1c\">\\%</annotation></semantics></math></span></td>\n<td id=\"A7.T1.4.4.4\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"A7.T1.6.6\" class=\"ltx_tr\">\n<td id=\"A7.T1.6.6.3\" class=\"ltx_td ltx_align_left ltx_border_bb\">EMNSIT</td>\n<td id=\"A7.T1.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">83.70<math id=\"A7.T1.5.5.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A7.T1.5.5.1.m1.1a\"><mo id=\"A7.T1.5.5.1.m1.1.1\" xref=\"A7.T1.5.5.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A7.T1.5.5.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A7.T1.5.5.1.m1.1.1.cmml\" xref=\"A7.T1.5.5.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A7.T1.5.5.1.m1.1c\">\\%</annotation></semantics></math>\n</td>\n<td id=\"A7.T1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">81.63<math id=\"A7.T1.6.6.2.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A7.T1.6.6.2.m1.1a\"><mo id=\"A7.T1.6.6.2.m1.1.1\" xref=\"A7.T1.6.6.2.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A7.T1.6.6.2.m1.1b\"><csymbol cd=\"latexml\" id=\"A7.T1.6.6.2.m1.1.1.cmml\" xref=\"A7.T1.6.6.2.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A7.T1.6.6.2.m1.1c\">\\%</annotation></semantics></math>\n</td>\n<td id=\"A7.T1.6.6.4\" class=\"ltx_td ltx_border_bb\"></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "As can be seen from the top of Tab. 1, increasing the number of users K𝐾K has a marginal effect (<<1%) on the accuracy, from K=10𝐾10K=10 to K=30𝐾30K=30.\nOne notable thing here is that with K=30𝐾30K=30, if we train 40 epochs on SVHN, the accuracy is 78.77%, which is 16.72% lower than K=10𝐾10K=10.\nIf we increase the training epochs from 40 to 120 for K=30𝐾30K=30 on SVHN, the final accuracy is 94.93%. One can refer to Fig. C.1 for the convergence curve of this experiment.",
            "In this subsection, we compare our grouping-based method with other FL algorithms, in both semi-supervised and supervised settings.\nFirst, in the semi-supervised setting, we conduct the experiment on Cifar-10 with exactly the same setting as a recent SSFL paper [9].\nFor the Cifar-10 data, according to Table 1 in [9], we set Ns=5000subscript𝑁𝑠5000N_{s}=5000, K=100𝐾100K=100, C=5𝐶5C=5, and R=0𝑅0R=0 (which is the iid case) or R=1𝑅1R=1 (which is the most difficult non-iid case).\nFrom Tab. 3, one can see that our grouping-based solution outperforms the method proposed in [9] by a large margin.\nWe notice that the results in [9] are presented in two different settings including the labels-at-server setting and the labels-at-client setting.\nThe first setting is the same as our paper, i.e., only the server has labeled data, while the users have unlabeled data.\nIn this setting, Ns=5000subscript𝑁𝑠5000N_{s}=5000 labeled data are own by the server.\nThe second setting is different but it is straightforward to apply our grouping-based solution.\nIn this setting, Ns=5000subscript𝑁𝑠5000N_{s}=5000 labeled data are distributed to 100 users. In each round, C=5𝐶5C=5 users are random selected to communicate with the server.\nSee Appendix H for the details of adapting our solution to the label-at-the-client setting.",
            "There are other important issues we consider.\nFor example, we evaluate the performance of our grouping-based method in fully supervised FL in § F, and we show that the improvement in this scenario is limited. Thus, our method is more suitable in the SSFL setting.\nWe also compare our grouping-based solution with FixMatch [11] in § G).\nWe show that our results are comparable to FixMatch even if FixMatch uses centralized setting.\nMoreover, we extend our current methods to the setting where users can have both labeled and unlabeled samples in § H, i.e., the labels-at-client case.\nWe also provide additional results on another semi-supervised dataset STL-10, see § I.\nFinally, since for federated learning, we are interested in studying what happens when the number of users is large, we provide an additional experiment with the number of users set to 470 in § J. We show that the grouping-based method outperforms FedAvg in this setting as well.",
            "Federated learning.\nFederated learning (FL) [1, 2, 4, 27, 16, 28, 29, 30, 18, 31] is a decentralized computing framework that enables multiple users to learn a shared model while potentially protecting the privacy of users (although recent work [32] shows this may not be the case).\nFederated Averaging (FedAvg) [2], which is the most popular FL algorithm, shows good performance when the data distribution across users is iid.\nHowever, in the non-iid case, the performance can significantly degrade.\nIn fact, dealing with non-iid distributions is deemed by many to be one of the most critical challenges in FL [16, 28, 33].\nIn [16], a data-sharing method is proposed to improve the final accuracy.\nHowever, sharing massive data among all users requires both large storage space as well as stable connections between users and the server.\nImportantly, all of these methods require the data stored by the local users to come with ground-truth labels (in order to perform model updates locally).\nThe FL problem in the semi-supervised setting, when users do not have labels, however, is “relatively ignored” and has “little prior arts,” as mentioned in a recent survey paper [4].",
            "In this section, we study whether the grouping-based averaging can be extended to supervised FL (SFL). We want to see whether this particular way of averaging is more suitable for the semi-supervised setup or the supervised setup.\nWe conduct experiments on EMNIST using SFL with three different settings with different number of users K∈{47,20,10}𝐾472010K\\in\\{47,20,10\\}. In these three settings, we let C=K𝐶𝐾C=K.\nThe other environmental factors are shown in rows 32-34 of Tab. A.2.\nWe set the group number S=5𝑆5S=5, S=2𝑆2S=2 and S=2𝑆2S=2 for the setting of K=47𝐾47K=47, K=20𝐾20K=20 and K=10𝐾10K=10, respectively.\nSee Table F.1.\nThe results show that the performance of the grouping method is only slightly better than that of FedAvg.\nThus, the performance gain of the grouping-based averaging method for SFL is much less than that of SSFL. This mean that grouping-based averaging is more suitable for the semi-supervised setup than the supervised setup.",
            "The results in Table J.1 show that the performance of the grouping-based averaging is better than that of FedAvg even with 470 users. One can also observe that as the number of communicating users C𝐶C increases, the performance of the FedAvg decreases, which is consistent with the experimental phenomenon observed in § 4.2."
        ]
    },
    "A8.T1": {
        "caption": "Table H.1: Performance of the label-at-client setting.\n",
        "table": "<table id=\"A8.T1.4\" class=\"ltx_tabular ltx_centering ltx_align_top\">\n<tr id=\"A8.T1.2.2\" class=\"ltx_tr\">\n<td id=\"A8.T1.2.2.3\" class=\"ltx_td ltx_border_tt\"></td>\n<td id=\"A8.T1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\"><math id=\"A8.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"R=0.4\" display=\"inline\"><semantics id=\"A8.T1.1.1.1.m1.1a\"><mrow id=\"A8.T1.1.1.1.m1.1.1\" xref=\"A8.T1.1.1.1.m1.1.1.cmml\"><mi id=\"A8.T1.1.1.1.m1.1.1.2\" xref=\"A8.T1.1.1.1.m1.1.1.2.cmml\">R</mi><mo id=\"A8.T1.1.1.1.m1.1.1.1\" xref=\"A8.T1.1.1.1.m1.1.1.1.cmml\">=</mo><mn id=\"A8.T1.1.1.1.m1.1.1.3\" xref=\"A8.T1.1.1.1.m1.1.1.3.cmml\">0.4</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A8.T1.1.1.1.m1.1b\"><apply id=\"A8.T1.1.1.1.m1.1.1.cmml\" xref=\"A8.T1.1.1.1.m1.1.1\"><eq id=\"A8.T1.1.1.1.m1.1.1.1.cmml\" xref=\"A8.T1.1.1.1.m1.1.1.1\"></eq><ci id=\"A8.T1.1.1.1.m1.1.1.2.cmml\" xref=\"A8.T1.1.1.1.m1.1.1.2\">𝑅</ci><cn type=\"float\" id=\"A8.T1.1.1.1.m1.1.1.3.cmml\" xref=\"A8.T1.1.1.1.m1.1.1.3\">0.4</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A8.T1.1.1.1.m1.1c\">R=0.4</annotation></semantics></math></td>\n<td id=\"A8.T1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_tt\"><math id=\"A8.T1.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"R=0.6\" display=\"inline\"><semantics id=\"A8.T1.2.2.2.m1.1a\"><mrow id=\"A8.T1.2.2.2.m1.1.1\" xref=\"A8.T1.2.2.2.m1.1.1.cmml\"><mi id=\"A8.T1.2.2.2.m1.1.1.2\" xref=\"A8.T1.2.2.2.m1.1.1.2.cmml\">R</mi><mo id=\"A8.T1.2.2.2.m1.1.1.1\" xref=\"A8.T1.2.2.2.m1.1.1.1.cmml\">=</mo><mn id=\"A8.T1.2.2.2.m1.1.1.3\" xref=\"A8.T1.2.2.2.m1.1.1.3.cmml\">0.6</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A8.T1.2.2.2.m1.1b\"><apply id=\"A8.T1.2.2.2.m1.1.1.cmml\" xref=\"A8.T1.2.2.2.m1.1.1\"><eq id=\"A8.T1.2.2.2.m1.1.1.1.cmml\" xref=\"A8.T1.2.2.2.m1.1.1.1\"></eq><ci id=\"A8.T1.2.2.2.m1.1.1.2.cmml\" xref=\"A8.T1.2.2.2.m1.1.1.2\">𝑅</ci><cn type=\"float\" id=\"A8.T1.2.2.2.m1.1.1.3.cmml\" xref=\"A8.T1.2.2.2.m1.1.1.3\">0.6</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A8.T1.2.2.2.m1.1c\">R=0.6</annotation></semantics></math></td>\n</tr>\n<tr id=\"A8.T1.4.4\" class=\"ltx_tr\" style=\"background-color:#FFCC99;\">\n<td id=\"A8.T1.4.4.3\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\"><span id=\"A8.T1.4.4.3.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">EMNSIT</span></td>\n<td id=\"A8.T1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"A8.T1.3.3.1.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">81.88<math id=\"A8.T1.3.3.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A8.T1.3.3.1.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"A8.T1.3.3.1.1.m1.1.1\" xref=\"A8.T1.3.3.1.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A8.T1.3.3.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A8.T1.3.3.1.1.m1.1.1.cmml\" xref=\"A8.T1.3.3.1.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A8.T1.3.3.1.1.m1.1c\">\\%</annotation></semantics></math></span></td>\n<td id=\"A8.T1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"A8.T1.4.4.2.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">81.40<math id=\"A8.T1.4.4.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A8.T1.4.4.2.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"A8.T1.4.4.2.1.m1.1.1\" xref=\"A8.T1.4.4.2.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A8.T1.4.4.2.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A8.T1.4.4.2.1.m1.1.1.cmml\" xref=\"A8.T1.4.4.2.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A8.T1.4.4.2.1.m1.1c\">\\%</annotation></semantics></math></span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "As can be seen from the top of Tab. 1, increasing the number of users K𝐾K has a marginal effect (<<1%) on the accuracy, from K=10𝐾10K=10 to K=30𝐾30K=30.\nOne notable thing here is that with K=30𝐾30K=30, if we train 40 epochs on SVHN, the accuracy is 78.77%, which is 16.72% lower than K=10𝐾10K=10.\nIf we increase the training epochs from 40 to 120 for K=30𝐾30K=30 on SVHN, the final accuracy is 94.93%. One can refer to Fig. C.1 for the convergence curve of this experiment.",
            "In this subsection, we compare our grouping-based method with other FL algorithms, in both semi-supervised and supervised settings.\nFirst, in the semi-supervised setting, we conduct the experiment on Cifar-10 with exactly the same setting as a recent SSFL paper [9].\nFor the Cifar-10 data, according to Table 1 in [9], we set Ns=5000subscript𝑁𝑠5000N_{s}=5000, K=100𝐾100K=100, C=5𝐶5C=5, and R=0𝑅0R=0 (which is the iid case) or R=1𝑅1R=1 (which is the most difficult non-iid case).\nFrom Tab. 3, one can see that our grouping-based solution outperforms the method proposed in [9] by a large margin.\nWe notice that the results in [9] are presented in two different settings including the labels-at-server setting and the labels-at-client setting.\nThe first setting is the same as our paper, i.e., only the server has labeled data, while the users have unlabeled data.\nIn this setting, Ns=5000subscript𝑁𝑠5000N_{s}=5000 labeled data are own by the server.\nThe second setting is different but it is straightforward to apply our grouping-based solution.\nIn this setting, Ns=5000subscript𝑁𝑠5000N_{s}=5000 labeled data are distributed to 100 users. In each round, C=5𝐶5C=5 users are random selected to communicate with the server.\nSee Appendix H for the details of adapting our solution to the label-at-the-client setting.",
            "There are other important issues we consider.\nFor example, we evaluate the performance of our grouping-based method in fully supervised FL in § F, and we show that the improvement in this scenario is limited. Thus, our method is more suitable in the SSFL setting.\nWe also compare our grouping-based solution with FixMatch [11] in § G).\nWe show that our results are comparable to FixMatch even if FixMatch uses centralized setting.\nMoreover, we extend our current methods to the setting where users can have both labeled and unlabeled samples in § H, i.e., the labels-at-client case.\nWe also provide additional results on another semi-supervised dataset STL-10, see § I.\nFinally, since for federated learning, we are interested in studying what happens when the number of users is large, we provide an additional experiment with the number of users set to 470 in § J. We show that the grouping-based method outperforms FedAvg in this setting as well.",
            "Federated learning.\nFederated learning (FL) [1, 2, 4, 27, 16, 28, 29, 30, 18, 31] is a decentralized computing framework that enables multiple users to learn a shared model while potentially protecting the privacy of users (although recent work [32] shows this may not be the case).\nFederated Averaging (FedAvg) [2], which is the most popular FL algorithm, shows good performance when the data distribution across users is iid.\nHowever, in the non-iid case, the performance can significantly degrade.\nIn fact, dealing with non-iid distributions is deemed by many to be one of the most critical challenges in FL [16, 28, 33].\nIn [16], a data-sharing method is proposed to improve the final accuracy.\nHowever, sharing massive data among all users requires both large storage space as well as stable connections between users and the server.\nImportantly, all of these methods require the data stored by the local users to come with ground-truth labels (in order to perform model updates locally).\nThe FL problem in the semi-supervised setting, when users do not have labels, however, is “relatively ignored” and has “little prior arts,” as mentioned in a recent survey paper [4].",
            "In this section, we study whether the grouping-based averaging can be extended to supervised FL (SFL). We want to see whether this particular way of averaging is more suitable for the semi-supervised setup or the supervised setup.\nWe conduct experiments on EMNIST using SFL with three different settings with different number of users K∈{47,20,10}𝐾472010K\\in\\{47,20,10\\}. In these three settings, we let C=K𝐶𝐾C=K.\nThe other environmental factors are shown in rows 32-34 of Tab. A.2.\nWe set the group number S=5𝑆5S=5, S=2𝑆2S=2 and S=2𝑆2S=2 for the setting of K=47𝐾47K=47, K=20𝐾20K=20 and K=10𝐾10K=10, respectively.\nSee Table F.1.\nThe results show that the performance of the grouping method is only slightly better than that of FedAvg.\nThus, the performance gain of the grouping-based averaging method for SFL is much less than that of SSFL. This mean that grouping-based averaging is more suitable for the semi-supervised setup than the supervised setup.",
            "The results in Table J.1 show that the performance of the grouping-based averaging is better than that of FedAvg even with 470 users. One can also observe that as the number of communicating users C𝐶C increases, the performance of the FedAvg decreases, which is consistent with the experimental phenomenon observed in § 4.2."
        ]
    },
    "A9.T1": {
        "caption": "",
        "table": "",
        "footnotes": "\n\n\n\n\nSelf-training\nCRL with BN\nCRL with GN\nGrouping-based\n\n74.25%\n78.96%\n81.71%\n82.81%\n\n",
        "references": [
            "As can be seen from the top of Tab. 1, increasing the number of users K𝐾K has a marginal effect (<<1%) on the accuracy, from K=10𝐾10K=10 to K=30𝐾30K=30.\nOne notable thing here is that with K=30𝐾30K=30, if we train 40 epochs on SVHN, the accuracy is 78.77%, which is 16.72% lower than K=10𝐾10K=10.\nIf we increase the training epochs from 40 to 120 for K=30𝐾30K=30 on SVHN, the final accuracy is 94.93%. One can refer to Fig. C.1 for the convergence curve of this experiment.",
            "In this subsection, we compare our grouping-based method with other FL algorithms, in both semi-supervised and supervised settings.\nFirst, in the semi-supervised setting, we conduct the experiment on Cifar-10 with exactly the same setting as a recent SSFL paper [9].\nFor the Cifar-10 data, according to Table 1 in [9], we set Ns=5000subscript𝑁𝑠5000N_{s}=5000, K=100𝐾100K=100, C=5𝐶5C=5, and R=0𝑅0R=0 (which is the iid case) or R=1𝑅1R=1 (which is the most difficult non-iid case).\nFrom Tab. 3, one can see that our grouping-based solution outperforms the method proposed in [9] by a large margin.\nWe notice that the results in [9] are presented in two different settings including the labels-at-server setting and the labels-at-client setting.\nThe first setting is the same as our paper, i.e., only the server has labeled data, while the users have unlabeled data.\nIn this setting, Ns=5000subscript𝑁𝑠5000N_{s}=5000 labeled data are own by the server.\nThe second setting is different but it is straightforward to apply our grouping-based solution.\nIn this setting, Ns=5000subscript𝑁𝑠5000N_{s}=5000 labeled data are distributed to 100 users. In each round, C=5𝐶5C=5 users are random selected to communicate with the server.\nSee Appendix H for the details of adapting our solution to the label-at-the-client setting.",
            "There are other important issues we consider.\nFor example, we evaluate the performance of our grouping-based method in fully supervised FL in § F, and we show that the improvement in this scenario is limited. Thus, our method is more suitable in the SSFL setting.\nWe also compare our grouping-based solution with FixMatch [11] in § G).\nWe show that our results are comparable to FixMatch even if FixMatch uses centralized setting.\nMoreover, we extend our current methods to the setting where users can have both labeled and unlabeled samples in § H, i.e., the labels-at-client case.\nWe also provide additional results on another semi-supervised dataset STL-10, see § I.\nFinally, since for federated learning, we are interested in studying what happens when the number of users is large, we provide an additional experiment with the number of users set to 470 in § J. We show that the grouping-based method outperforms FedAvg in this setting as well.",
            "Federated learning.\nFederated learning (FL) [1, 2, 4, 27, 16, 28, 29, 30, 18, 31] is a decentralized computing framework that enables multiple users to learn a shared model while potentially protecting the privacy of users (although recent work [32] shows this may not be the case).\nFederated Averaging (FedAvg) [2], which is the most popular FL algorithm, shows good performance when the data distribution across users is iid.\nHowever, in the non-iid case, the performance can significantly degrade.\nIn fact, dealing with non-iid distributions is deemed by many to be one of the most critical challenges in FL [16, 28, 33].\nIn [16], a data-sharing method is proposed to improve the final accuracy.\nHowever, sharing massive data among all users requires both large storage space as well as stable connections between users and the server.\nImportantly, all of these methods require the data stored by the local users to come with ground-truth labels (in order to perform model updates locally).\nThe FL problem in the semi-supervised setting, when users do not have labels, however, is “relatively ignored” and has “little prior arts,” as mentioned in a recent survey paper [4].",
            "In this section, we study whether the grouping-based averaging can be extended to supervised FL (SFL). We want to see whether this particular way of averaging is more suitable for the semi-supervised setup or the supervised setup.\nWe conduct experiments on EMNIST using SFL with three different settings with different number of users K∈{47,20,10}𝐾472010K\\in\\{47,20,10\\}. In these three settings, we let C=K𝐶𝐾C=K.\nThe other environmental factors are shown in rows 32-34 of Tab. A.2.\nWe set the group number S=5𝑆5S=5, S=2𝑆2S=2 and S=2𝑆2S=2 for the setting of K=47𝐾47K=47, K=20𝐾20K=20 and K=10𝐾10K=10, respectively.\nSee Table F.1.\nThe results show that the performance of the grouping method is only slightly better than that of FedAvg.\nThus, the performance gain of the grouping-based averaging method for SFL is much less than that of SSFL. This mean that grouping-based averaging is more suitable for the semi-supervised setup than the supervised setup.",
            "The results in Table J.1 show that the performance of the grouping-based averaging is better than that of FedAvg even with 470 users. One can also observe that as the number of communicating users C𝐶C increases, the performance of the FedAvg decreases, which is consistent with the experimental phenomenon observed in § 4.2."
        ]
    },
    "A10.T1": {
        "caption": "Table J.1: The accuracy comparison of FedAvg and grouping-based average with large user number on EMNIST.\n",
        "table": "<table id=\"A10.T1.9\" class=\"ltx_tabular ltx_centering ltx_align_top\">\n<tr id=\"A10.T1.9.10\" class=\"ltx_tr\">\n<td id=\"A10.T1.9.10.1\" class=\"ltx_td ltx_border_tt\"></td>\n<td id=\"A10.T1.9.10.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">FedAvg</td>\n<td id=\"A10.T1.9.10.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">Grouping-based</td>\n<td id=\"A10.T1.9.10.4\" class=\"ltx_td ltx_border_tt\"></td>\n</tr>\n<tr id=\"A10.T1.3.3\" class=\"ltx_tr\">\n<td id=\"A10.T1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><math id=\"A10.T1.1.1.1.m1.2\" class=\"ltx_Math\" alttext=\"K=470,C=10\" display=\"inline\"><semantics id=\"A10.T1.1.1.1.m1.2a\"><mrow id=\"A10.T1.1.1.1.m1.2.2.2\" xref=\"A10.T1.1.1.1.m1.2.2.3.cmml\"><mrow id=\"A10.T1.1.1.1.m1.1.1.1.1\" xref=\"A10.T1.1.1.1.m1.1.1.1.1.cmml\"><mi id=\"A10.T1.1.1.1.m1.1.1.1.1.2\" xref=\"A10.T1.1.1.1.m1.1.1.1.1.2.cmml\">K</mi><mo id=\"A10.T1.1.1.1.m1.1.1.1.1.1\" xref=\"A10.T1.1.1.1.m1.1.1.1.1.1.cmml\">=</mo><mn id=\"A10.T1.1.1.1.m1.1.1.1.1.3\" xref=\"A10.T1.1.1.1.m1.1.1.1.1.3.cmml\">470</mn></mrow><mo id=\"A10.T1.1.1.1.m1.2.2.2.3\" xref=\"A10.T1.1.1.1.m1.2.2.3a.cmml\">,</mo><mrow id=\"A10.T1.1.1.1.m1.2.2.2.2\" xref=\"A10.T1.1.1.1.m1.2.2.2.2.cmml\"><mi id=\"A10.T1.1.1.1.m1.2.2.2.2.2\" xref=\"A10.T1.1.1.1.m1.2.2.2.2.2.cmml\">C</mi><mo id=\"A10.T1.1.1.1.m1.2.2.2.2.1\" xref=\"A10.T1.1.1.1.m1.2.2.2.2.1.cmml\">=</mo><mn id=\"A10.T1.1.1.1.m1.2.2.2.2.3\" xref=\"A10.T1.1.1.1.m1.2.2.2.2.3.cmml\">10</mn></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A10.T1.1.1.1.m1.2b\"><apply id=\"A10.T1.1.1.1.m1.2.2.3.cmml\" xref=\"A10.T1.1.1.1.m1.2.2.2\"><csymbol cd=\"ambiguous\" id=\"A10.T1.1.1.1.m1.2.2.3a.cmml\" xref=\"A10.T1.1.1.1.m1.2.2.2.3\">formulae-sequence</csymbol><apply id=\"A10.T1.1.1.1.m1.1.1.1.1.cmml\" xref=\"A10.T1.1.1.1.m1.1.1.1.1\"><eq id=\"A10.T1.1.1.1.m1.1.1.1.1.1.cmml\" xref=\"A10.T1.1.1.1.m1.1.1.1.1.1\"></eq><ci id=\"A10.T1.1.1.1.m1.1.1.1.1.2.cmml\" xref=\"A10.T1.1.1.1.m1.1.1.1.1.2\">𝐾</ci><cn type=\"integer\" id=\"A10.T1.1.1.1.m1.1.1.1.1.3.cmml\" xref=\"A10.T1.1.1.1.m1.1.1.1.1.3\">470</cn></apply><apply id=\"A10.T1.1.1.1.m1.2.2.2.2.cmml\" xref=\"A10.T1.1.1.1.m1.2.2.2.2\"><eq id=\"A10.T1.1.1.1.m1.2.2.2.2.1.cmml\" xref=\"A10.T1.1.1.1.m1.2.2.2.2.1\"></eq><ci id=\"A10.T1.1.1.1.m1.2.2.2.2.2.cmml\" xref=\"A10.T1.1.1.1.m1.2.2.2.2.2\">𝐶</ci><cn type=\"integer\" id=\"A10.T1.1.1.1.m1.2.2.2.2.3.cmml\" xref=\"A10.T1.1.1.1.m1.2.2.2.2.3\">10</cn></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A10.T1.1.1.1.m1.2c\">K=470,C=10</annotation></semantics></math></td>\n<td id=\"A10.T1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">83.69<math id=\"A10.T1.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A10.T1.2.2.2.m1.1a\"><mo id=\"A10.T1.2.2.2.m1.1.1\" xref=\"A10.T1.2.2.2.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A10.T1.2.2.2.m1.1b\"><csymbol cd=\"latexml\" id=\"A10.T1.2.2.2.m1.1.1.cmml\" xref=\"A10.T1.2.2.2.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A10.T1.2.2.2.m1.1c\">\\%</annotation></semantics></math>\n</td>\n<td id=\"A10.T1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"A10.T1.3.3.3.1\" class=\"ltx_text ltx_font_bold\">83.94<math id=\"A10.T1.3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A10.T1.3.3.3.1.m1.1a\"><mo id=\"A10.T1.3.3.3.1.m1.1.1\" xref=\"A10.T1.3.3.3.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A10.T1.3.3.3.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A10.T1.3.3.3.1.m1.1.1.cmml\" xref=\"A10.T1.3.3.3.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A10.T1.3.3.3.1.m1.1c\">\\%</annotation></semantics></math></span></td>\n<td id=\"A10.T1.3.3.4\" class=\"ltx_td ltx_border_t\"></td>\n</tr>\n<tr id=\"A10.T1.6.6\" class=\"ltx_tr\" style=\"background-color:#FFCC99;\">\n<td id=\"A10.T1.4.4.1\" class=\"ltx_td ltx_align_left\"><math id=\"A10.T1.4.4.1.m1.2\" class=\"ltx_Math\" style=\"background-color:#FFCC99;\" alttext=\"K=470,C=20\" display=\"inline\"><semantics id=\"A10.T1.4.4.1.m1.2a\"><mrow id=\"A10.T1.4.4.1.m1.2.2.2\" xref=\"A10.T1.4.4.1.m1.2.2.3.cmml\"><mrow id=\"A10.T1.4.4.1.m1.1.1.1.1\" xref=\"A10.T1.4.4.1.m1.1.1.1.1.cmml\"><mi mathbackground=\"#FFCC99\" id=\"A10.T1.4.4.1.m1.1.1.1.1.2\" xref=\"A10.T1.4.4.1.m1.1.1.1.1.2.cmml\">K</mi><mo mathbackground=\"#FFCC99\" id=\"A10.T1.4.4.1.m1.1.1.1.1.1\" xref=\"A10.T1.4.4.1.m1.1.1.1.1.1.cmml\">=</mo><mn mathbackground=\"#FFCC99\" id=\"A10.T1.4.4.1.m1.1.1.1.1.3\" xref=\"A10.T1.4.4.1.m1.1.1.1.1.3.cmml\">470</mn></mrow><mo mathbackground=\"#FFCC99\" id=\"A10.T1.4.4.1.m1.2.2.2.3\" xref=\"A10.T1.4.4.1.m1.2.2.3a.cmml\">,</mo><mrow id=\"A10.T1.4.4.1.m1.2.2.2.2\" xref=\"A10.T1.4.4.1.m1.2.2.2.2.cmml\"><mi mathbackground=\"#FFCC99\" id=\"A10.T1.4.4.1.m1.2.2.2.2.2\" xref=\"A10.T1.4.4.1.m1.2.2.2.2.2.cmml\">C</mi><mo mathbackground=\"#FFCC99\" id=\"A10.T1.4.4.1.m1.2.2.2.2.1\" xref=\"A10.T1.4.4.1.m1.2.2.2.2.1.cmml\">=</mo><mn mathbackground=\"#FFCC99\" id=\"A10.T1.4.4.1.m1.2.2.2.2.3\" xref=\"A10.T1.4.4.1.m1.2.2.2.2.3.cmml\">20</mn></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A10.T1.4.4.1.m1.2b\"><apply id=\"A10.T1.4.4.1.m1.2.2.3.cmml\" xref=\"A10.T1.4.4.1.m1.2.2.2\"><csymbol cd=\"ambiguous\" id=\"A10.T1.4.4.1.m1.2.2.3a.cmml\" xref=\"A10.T1.4.4.1.m1.2.2.2.3\">formulae-sequence</csymbol><apply id=\"A10.T1.4.4.1.m1.1.1.1.1.cmml\" xref=\"A10.T1.4.4.1.m1.1.1.1.1\"><eq id=\"A10.T1.4.4.1.m1.1.1.1.1.1.cmml\" xref=\"A10.T1.4.4.1.m1.1.1.1.1.1\"></eq><ci id=\"A10.T1.4.4.1.m1.1.1.1.1.2.cmml\" xref=\"A10.T1.4.4.1.m1.1.1.1.1.2\">𝐾</ci><cn type=\"integer\" id=\"A10.T1.4.4.1.m1.1.1.1.1.3.cmml\" xref=\"A10.T1.4.4.1.m1.1.1.1.1.3\">470</cn></apply><apply id=\"A10.T1.4.4.1.m1.2.2.2.2.cmml\" xref=\"A10.T1.4.4.1.m1.2.2.2.2\"><eq id=\"A10.T1.4.4.1.m1.2.2.2.2.1.cmml\" xref=\"A10.T1.4.4.1.m1.2.2.2.2.1\"></eq><ci id=\"A10.T1.4.4.1.m1.2.2.2.2.2.cmml\" xref=\"A10.T1.4.4.1.m1.2.2.2.2.2\">𝐶</ci><cn type=\"integer\" id=\"A10.T1.4.4.1.m1.2.2.2.2.3.cmml\" xref=\"A10.T1.4.4.1.m1.2.2.2.2.3\">20</cn></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A10.T1.4.4.1.m1.2c\">K=470,C=20</annotation></semantics></math></td>\n<td id=\"A10.T1.5.5.2\" class=\"ltx_td ltx_align_center\"><span id=\"A10.T1.5.5.2.1\" class=\"ltx_text\" style=\"background-color:#FFCC99;\">82.36<math id=\"A10.T1.5.5.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A10.T1.5.5.2.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"A10.T1.5.5.2.1.m1.1.1\" xref=\"A10.T1.5.5.2.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A10.T1.5.5.2.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A10.T1.5.5.2.1.m1.1.1.cmml\" xref=\"A10.T1.5.5.2.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A10.T1.5.5.2.1.m1.1c\">\\%</annotation></semantics></math></span></td>\n<td id=\"A10.T1.6.6.3\" class=\"ltx_td ltx_align_center\"><span id=\"A10.T1.6.6.3.1\" class=\"ltx_text ltx_font_bold\" style=\"background-color:#FFCC99;\">83.66<math id=\"A10.T1.6.6.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A10.T1.6.6.3.1.m1.1a\"><mo mathbackground=\"#FFCC99\" id=\"A10.T1.6.6.3.1.m1.1.1\" xref=\"A10.T1.6.6.3.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A10.T1.6.6.3.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A10.T1.6.6.3.1.m1.1.1.cmml\" xref=\"A10.T1.6.6.3.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A10.T1.6.6.3.1.m1.1c\">\\%</annotation></semantics></math></span></td>\n<td id=\"A10.T1.6.6.4\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"A10.T1.9.9\" class=\"ltx_tr\">\n<td id=\"A10.T1.7.7.1\" class=\"ltx_td ltx_align_left ltx_border_bb\"><math id=\"A10.T1.7.7.1.m1.2\" class=\"ltx_Math\" alttext=\"K=470,C=30\" display=\"inline\"><semantics id=\"A10.T1.7.7.1.m1.2a\"><mrow id=\"A10.T1.7.7.1.m1.2.2.2\" xref=\"A10.T1.7.7.1.m1.2.2.3.cmml\"><mrow id=\"A10.T1.7.7.1.m1.1.1.1.1\" xref=\"A10.T1.7.7.1.m1.1.1.1.1.cmml\"><mi id=\"A10.T1.7.7.1.m1.1.1.1.1.2\" xref=\"A10.T1.7.7.1.m1.1.1.1.1.2.cmml\">K</mi><mo id=\"A10.T1.7.7.1.m1.1.1.1.1.1\" xref=\"A10.T1.7.7.1.m1.1.1.1.1.1.cmml\">=</mo><mn id=\"A10.T1.7.7.1.m1.1.1.1.1.3\" xref=\"A10.T1.7.7.1.m1.1.1.1.1.3.cmml\">470</mn></mrow><mo id=\"A10.T1.7.7.1.m1.2.2.2.3\" xref=\"A10.T1.7.7.1.m1.2.2.3a.cmml\">,</mo><mrow id=\"A10.T1.7.7.1.m1.2.2.2.2\" xref=\"A10.T1.7.7.1.m1.2.2.2.2.cmml\"><mi id=\"A10.T1.7.7.1.m1.2.2.2.2.2\" xref=\"A10.T1.7.7.1.m1.2.2.2.2.2.cmml\">C</mi><mo id=\"A10.T1.7.7.1.m1.2.2.2.2.1\" xref=\"A10.T1.7.7.1.m1.2.2.2.2.1.cmml\">=</mo><mn id=\"A10.T1.7.7.1.m1.2.2.2.2.3\" xref=\"A10.T1.7.7.1.m1.2.2.2.2.3.cmml\">30</mn></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"A10.T1.7.7.1.m1.2b\"><apply id=\"A10.T1.7.7.1.m1.2.2.3.cmml\" xref=\"A10.T1.7.7.1.m1.2.2.2\"><csymbol cd=\"ambiguous\" id=\"A10.T1.7.7.1.m1.2.2.3a.cmml\" xref=\"A10.T1.7.7.1.m1.2.2.2.3\">formulae-sequence</csymbol><apply id=\"A10.T1.7.7.1.m1.1.1.1.1.cmml\" xref=\"A10.T1.7.7.1.m1.1.1.1.1\"><eq id=\"A10.T1.7.7.1.m1.1.1.1.1.1.cmml\" xref=\"A10.T1.7.7.1.m1.1.1.1.1.1\"></eq><ci id=\"A10.T1.7.7.1.m1.1.1.1.1.2.cmml\" xref=\"A10.T1.7.7.1.m1.1.1.1.1.2\">𝐾</ci><cn type=\"integer\" id=\"A10.T1.7.7.1.m1.1.1.1.1.3.cmml\" xref=\"A10.T1.7.7.1.m1.1.1.1.1.3\">470</cn></apply><apply id=\"A10.T1.7.7.1.m1.2.2.2.2.cmml\" xref=\"A10.T1.7.7.1.m1.2.2.2.2\"><eq id=\"A10.T1.7.7.1.m1.2.2.2.2.1.cmml\" xref=\"A10.T1.7.7.1.m1.2.2.2.2.1\"></eq><ci id=\"A10.T1.7.7.1.m1.2.2.2.2.2.cmml\" xref=\"A10.T1.7.7.1.m1.2.2.2.2.2\">𝐶</ci><cn type=\"integer\" id=\"A10.T1.7.7.1.m1.2.2.2.2.3.cmml\" xref=\"A10.T1.7.7.1.m1.2.2.2.2.3\">30</cn></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A10.T1.7.7.1.m1.2c\">K=470,C=30</annotation></semantics></math></td>\n<td id=\"A10.T1.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">79.41<math id=\"A10.T1.8.8.2.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A10.T1.8.8.2.m1.1a\"><mo id=\"A10.T1.8.8.2.m1.1.1\" xref=\"A10.T1.8.8.2.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A10.T1.8.8.2.m1.1b\"><csymbol cd=\"latexml\" id=\"A10.T1.8.8.2.m1.1.1.cmml\" xref=\"A10.T1.8.8.2.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A10.T1.8.8.2.m1.1c\">\\%</annotation></semantics></math>\n</td>\n<td id=\"A10.T1.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"A10.T1.9.9.3.1\" class=\"ltx_text ltx_font_bold\">81.31<math id=\"A10.T1.9.9.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"A10.T1.9.9.3.1.m1.1a\"><mo id=\"A10.T1.9.9.3.1.m1.1.1\" xref=\"A10.T1.9.9.3.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"A10.T1.9.9.3.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A10.T1.9.9.3.1.m1.1.1.cmml\" xref=\"A10.T1.9.9.3.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A10.T1.9.9.3.1.m1.1c\">\\%</annotation></semantics></math></span></td>\n<td id=\"A10.T1.9.9.4\" class=\"ltx_td ltx_border_bb\"></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "As can be seen from the top of Tab. 1, increasing the number of users K𝐾K has a marginal effect (<<1%) on the accuracy, from K=10𝐾10K=10 to K=30𝐾30K=30.\nOne notable thing here is that with K=30𝐾30K=30, if we train 40 epochs on SVHN, the accuracy is 78.77%, which is 16.72% lower than K=10𝐾10K=10.\nIf we increase the training epochs from 40 to 120 for K=30𝐾30K=30 on SVHN, the final accuracy is 94.93%. One can refer to Fig. C.1 for the convergence curve of this experiment.",
            "In this subsection, we compare our grouping-based method with other FL algorithms, in both semi-supervised and supervised settings.\nFirst, in the semi-supervised setting, we conduct the experiment on Cifar-10 with exactly the same setting as a recent SSFL paper [9].\nFor the Cifar-10 data, according to Table 1 in [9], we set Ns=5000subscript𝑁𝑠5000N_{s}=5000, K=100𝐾100K=100, C=5𝐶5C=5, and R=0𝑅0R=0 (which is the iid case) or R=1𝑅1R=1 (which is the most difficult non-iid case).\nFrom Tab. 3, one can see that our grouping-based solution outperforms the method proposed in [9] by a large margin.\nWe notice that the results in [9] are presented in two different settings including the labels-at-server setting and the labels-at-client setting.\nThe first setting is the same as our paper, i.e., only the server has labeled data, while the users have unlabeled data.\nIn this setting, Ns=5000subscript𝑁𝑠5000N_{s}=5000 labeled data are own by the server.\nThe second setting is different but it is straightforward to apply our grouping-based solution.\nIn this setting, Ns=5000subscript𝑁𝑠5000N_{s}=5000 labeled data are distributed to 100 users. In each round, C=5𝐶5C=5 users are random selected to communicate with the server.\nSee Appendix H for the details of adapting our solution to the label-at-the-client setting.",
            "There are other important issues we consider.\nFor example, we evaluate the performance of our grouping-based method in fully supervised FL in § F, and we show that the improvement in this scenario is limited. Thus, our method is more suitable in the SSFL setting.\nWe also compare our grouping-based solution with FixMatch [11] in § G).\nWe show that our results are comparable to FixMatch even if FixMatch uses centralized setting.\nMoreover, we extend our current methods to the setting where users can have both labeled and unlabeled samples in § H, i.e., the labels-at-client case.\nWe also provide additional results on another semi-supervised dataset STL-10, see § I.\nFinally, since for federated learning, we are interested in studying what happens when the number of users is large, we provide an additional experiment with the number of users set to 470 in § J. We show that the grouping-based method outperforms FedAvg in this setting as well.",
            "Federated learning.\nFederated learning (FL) [1, 2, 4, 27, 16, 28, 29, 30, 18, 31] is a decentralized computing framework that enables multiple users to learn a shared model while potentially protecting the privacy of users (although recent work [32] shows this may not be the case).\nFederated Averaging (FedAvg) [2], which is the most popular FL algorithm, shows good performance when the data distribution across users is iid.\nHowever, in the non-iid case, the performance can significantly degrade.\nIn fact, dealing with non-iid distributions is deemed by many to be one of the most critical challenges in FL [16, 28, 33].\nIn [16], a data-sharing method is proposed to improve the final accuracy.\nHowever, sharing massive data among all users requires both large storage space as well as stable connections between users and the server.\nImportantly, all of these methods require the data stored by the local users to come with ground-truth labels (in order to perform model updates locally).\nThe FL problem in the semi-supervised setting, when users do not have labels, however, is “relatively ignored” and has “little prior arts,” as mentioned in a recent survey paper [4].",
            "In this section, we study whether the grouping-based averaging can be extended to supervised FL (SFL). We want to see whether this particular way of averaging is more suitable for the semi-supervised setup or the supervised setup.\nWe conduct experiments on EMNIST using SFL with three different settings with different number of users K∈{47,20,10}𝐾472010K\\in\\{47,20,10\\}. In these three settings, we let C=K𝐶𝐾C=K.\nThe other environmental factors are shown in rows 32-34 of Tab. A.2.\nWe set the group number S=5𝑆5S=5, S=2𝑆2S=2 and S=2𝑆2S=2 for the setting of K=47𝐾47K=47, K=20𝐾20K=20 and K=10𝐾10K=10, respectively.\nSee Table F.1.\nThe results show that the performance of the grouping method is only slightly better than that of FedAvg.\nThus, the performance gain of the grouping-based averaging method for SFL is much less than that of SSFL. This mean that grouping-based averaging is more suitable for the semi-supervised setup than the supervised setup.",
            "The results in Table J.1 show that the performance of the grouping-based averaging is better than that of FedAvg even with 470 users. One can also observe that as the number of communicating users C𝐶C increases, the performance of the FedAvg decreases, which is consistent with the experimental phenomenon observed in § 4.2."
        ]
    }
}