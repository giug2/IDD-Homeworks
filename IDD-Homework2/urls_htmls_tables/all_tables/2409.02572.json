{
    "id_table_1": {
        "caption": "TABLE I:  Forensics Timeline Analysis Related Works",
        "table": "S3.T1.1",
        "footnotes": [],
        "references": [
            "Digital Forensics (DF) Investigation Process:   There are several available representations of the DF investigation process. However, in this research, we used the process shown in Figure  1 , inspired by  [ 2 ] .",
            "4) Modality Fusion:  We merge the textual outputs generated by the MLLM with those extracted from single-modality documents to create an initial forensic report containing incident events. Algorithm  1   summarizes the process.",
            "Assuming that each English word is approximately 4 to 6 characters ( C C C italic_C ) long. By taking 4 characters as the average length for each word and considering the models maximum tokens ( T  M T M TM italic_T italic_M ) of 512, the maximum number of characters the model can accurately embed per chunk is about 2000 characters ( C  T  M C T M CTM italic_C italic_T italic_M ) ( 1 ).",
            "Prompts dedicated to the relevance metric are characterized by their focus on various aspects, including sentiment (e.g.,  What is the overall sentiment of the image described in Event 2 (Image b)? ), intention (e.g.,  What specific action is requested by GlobalBank in the initial email? ), deep analysis (e.g.,  Analyze the severity levels associated with the events involving SYN flood attacks. List the events and their corresponding severity levels. ), as well as retrieval, prediction, and insights. The graph in Figure  11  clearly shows that some scenarios have failed in certain prompts. For instance, in the SYN Flood scenario, GenDFIR failed on Prompt 4; in the Rhino Hunt scenario, Prompt 13 was answered partially correctly (50%); and in the Phishing Email 1 scenario, GenDFIR failed on both Prompts 11 and 12.",
            "The overall relevance output rate for each incident is visualized in Figure  12 .",
            "Figures  13 ,  14 ,  15 ,  16 ,  17 , and  18  illustrate the outputs of UMAP evidence visualizations.",
            "Figure  17  provides an example where all events are considered as evidence. The ground truth data in Table  X  specifies a total of 25 pieces of evidence, based on the users input:  \"Identify all events where the Level is Warning and extract their corresponding evidence\" . However, the Figure  17  generated using UMAP displays only the Top K=20 pieces of evidence, which are those with a cosine similarity score greater than 0.50. This discrepancy indicates an inaccuracy in the cosine similarity-based extraction."
        ]
    },
    "id_table_2": {
        "caption": "TABLE II:  Cybersecurity and Digital Forensics LLMs Related Works",
        "table": "S3.T2.1",
        "footnotes": [],
        "references": [
            "One of the primary functions of GenDFIR is anomaly detection. To filter and select only relevant data and minimize the amount collected, we use Algorithm  2 . As illustrated in the process, it is crucial to establish precise and stringent rules tailored to the specific incident context. These rules are designed to counteract standard policies, guidelines, norms, or any regulations that deviate from legal and usual practices. From the initial textual  File  (raw DF report), these rules are applied to the events contained within it. If an anomaly is detected, the event is selected and recorded in a new, separate, final textual forensic document  D .",
            "The overall relevance output rate for each incident is visualized in Figure  12 ."
        ]
    },
    "id_table_3": {
        "caption": "TABLE III:  Retrieval-Augmented Generation Related Works",
        "table": "S3.T3.1",
        "footnotes": [],
        "references": [
            "1) Data Collection:  The first step is where raw data and digital artefacts are collected using forensic tools. They will then be stored in datasets (e.g., CSV files) or normal files (e.g., TXT format) while preserving their integrity. This phase is typically part of the DFIR process, as shown in Figure  3 .",
            "Retrieval:   Algorithm  5 , the retrieval process works with vectors only. It considers  E  D E D ED italic_E italic_D  and the vectorized initial input  V  R  I V R I VRI italic_V italic_R italic_I . The cosine similarity ( 3 ) between  E  D E D ED italic_E italic_D  and  U  I U I UI italic_U italic_I  is then calculated as follows:",
            "It is important to recognize the diversity of methodologies and procedures in the DFIR industry. Each organization or entity may employ different investigative workflows and reporting formats depending on the specific nature of the investigation. Generally, DFIR processes can be segmented into two major domains: DF, which focuses on the preservation, collection, and analysis of digital evidence, and IR, which emphasizes the containment, eradication, and recovery from cyber incidents (see Figure  3 ).",
            "Figures  13 ,  14 ,  15 ,  16 ,  17 , and  18  illustrate the outputs of UMAP evidence visualizations."
        ]
    },
    "id_table_4": {
        "caption": "TABLE IV:  Embedding Models for Forensics Timeline Analysis",
        "table": "S3.T4.1",
        "footnotes": [],
        "references": [
            "AI Taxonomy:  The AI field is vast and broad. For a quick overview, Figure  4  illustrates the positioning of both R-BAI and GenAI LLMs:",
            "Regarding R-BAI algorithms, their use here is limited to anomaly detection by filtering collected digital artifacts. Detection is typically performed by comparing event attributes with the norm rule attributes. Although R-B algorithms are AI-based, their level of intelligence is relatively low, as illustrated in Figure  4 . Detection is primarily achieved through string-to-string matching or integer-to-integer comparisons, rather than more advanced methods. These algorithms lack learning capabilities due to their inability to learn from new data. Thus, they remain dependent on human intervention to modify the rules and update data.",
            "Generation:  In Algorithm  4 , refining the query  U  I U I UI italic_U italic_I  or modifying it into a more context-based  R  I R I RI italic_R italic_I  is performed by the  A  g  e  n  t A g e n t Agent italic_A italic_g italic_e italic_n italic_t  according to the crafted prompt  A  g  e  n  t  P  r  o  m  p  t A g e n t P r o m p t AgentPrompt italic_A italic_g italic_e italic_n italic_t italic_P italic_r italic_o italic_m italic_p italic_t . The generation process in GenDFIR occurs twice. First, in Algorithm  4 , before the retrieval process, the  A  g  e  n  t A g e n t Agent italic_A italic_g italic_e italic_n italic_t  (or DFIR AI assistant) takes the  U  I U I UI italic_U italic_I  and modifies it to generate a new contextualized query  R  I R I RI italic_R italic_I . The second generation, which is a typical augmented generation, occurs in Algorithm  6 .",
            "( 6 ) is the Euclidean length of the vector  q q q italic_q , and ( 7 ) is the Euclidean length of the vector  t t t italic_t . In ( 5 ), the dot product (scalar product) of  q q q italic_q  and  t t t italic_t  is calculated to measure their similarity. This product is higher if the vectors point in the same direction, indicating they share more common features. The final equation, ( 4 ), calculates the angle    \\theta italic_  between the two vectors. The smaller    \\theta italic_  is, the higher the similarity.",
            "DFIR primarily focuses on identifying evidence through the analysis of digital artifacts. As detailed in Section  IV , our approach employs algorithms that utilize cosine similarity to identify relevant evidence within the knowledge base. To facilitate real-time visualization of this process during inference, we developed a script, illustrated in Listing  4 , which uses the UMAP library. This script enables the visualization of how features from the vectorized user input ( V  R  I V R I VRI italic_V italic_R italic_I ) correspond with features in the embedded knowledge base ( E  D E D ED italic_E italic_D ). It is important to remember that evidence identification is contingent upon the input provided by the user, who determines which events or attributes within those events should be considered as evidence.",
            "Figures  13 ,  14 ,  15 ,  16 ,  17 , and  18  illustrate the outputs of UMAP evidence visualizations."
        ]
    },
    "id_table_5": {
        "caption": "TABLE V:  LLMs for Forensics Timeline Analysis",
        "table": "S3.T5.1",
        "footnotes": [],
        "references": [
            "Additionally, a RAG agent, which is an essential component in certain AI systems powered by an LLM  [ 44 ] , serves as an intermediary between the LLM and the user. The agent is responsible for conducting the search when a user sends a query or input, retrieving all context-based information, and providing it to the LLM, which then generates a context-based answer for the user. Complementing this, RAG agents have the capability of refining and modifying prompts crafted by humans. During inference, the RAG agent receives the input, processes it, and modifies it according to the role it is tasked with and designed to do  [ 47 ] . A core aspect to consider is that the role of a RAG agent is assigned by a human. For instance, in an LLM-powered system with a RAG agent, Figure  5 , the agent can take on the role of a cybersecurity assistant. In TA, the agent could be a  \"Digital Forensics and Cybersecurity AI Analyst tasked with performing timeline analysis, correlating events, and reconstructing timelines\" .",
            "Retrieval:   Algorithm  5 , the retrieval process works with vectors only. It considers  E  D E D ED italic_E italic_D  and the vectorized initial input  V  R  I V R I VRI italic_V italic_R italic_I . The cosine similarity ( 3 ) between  E  D E D ED italic_E italic_D  and  U  I U I UI italic_U italic_I  is then calculated as follows:",
            "( 6 ) is the Euclidean length of the vector  q q q italic_q , and ( 7 ) is the Euclidean length of the vector  t t t italic_t . In ( 5 ), the dot product (scalar product) of  q q q italic_q  and  t t t italic_t  is calculated to measure their similarity. This product is higher if the vectors point in the same direction, indicating they share more common features. The final equation, ( 4 ), calculates the angle    \\theta italic_  between the two vectors. The smaller    \\theta italic_  is, the higher the similarity.",
            "Figures  13 ,  14 ,  15 ,  16 ,  17 , and  18  illustrate the outputs of UMAP evidence visualizations."
        ]
    },
    "id_table_6": {
        "caption": "TABLE VI:  Case Studies Before R-BAI (Filtering)",
        "table": "S6.T9.1.1",
        "footnotes": [],
        "references": [
            "Generation:  In Algorithm  4 , refining the query  U  I U I UI italic_U italic_I  or modifying it into a more context-based  R  I R I RI italic_R italic_I  is performed by the  A  g  e  n  t A g e n t Agent italic_A italic_g italic_e italic_n italic_t  according to the crafted prompt  A  g  e  n  t  P  r  o  m  p  t A g e n t P r o m p t AgentPrompt italic_A italic_g italic_e italic_n italic_t italic_P italic_r italic_o italic_m italic_p italic_t . The generation process in GenDFIR occurs twice. First, in Algorithm  4 , before the retrieval process, the  A  g  e  n  t A g e n t Agent italic_A italic_g italic_e italic_n italic_t  (or DFIR AI assistant) takes the  U  I U I UI italic_U italic_I  and modifies it to generate a new contextualized query  R  I R I RI italic_R italic_I . The second generation, which is a typical augmented generation, occurs in Algorithm  6 .",
            "( 6 ) is the Euclidean length of the vector  q q q italic_q , and ( 7 ) is the Euclidean length of the vector  t t t italic_t . In ( 5 ), the dot product (scalar product) of  q q q italic_q  and  t t t italic_t  is calculated to measure their similarity. This product is higher if the vectors point in the same direction, indicating they share more common features. The final equation, ( 4 ), calculates the angle    \\theta italic_  between the two vectors. The smaller    \\theta italic_  is, the higher the similarity.",
            "q q q italic_q  is the new query vector  V  R  I V R I VRI italic_V italic_R italic_I , and  t t t italic_t  is the ED vector. Within an axis of  x x x italic_x  and  y y y italic_y ,  q q q italic_q  and  t t t italic_t  are represented as in Figure  6 .",
            "In Algorithm  6 , after successfully generating a new query  R  I R I RI italic_R italic_I  and retrieving the context-based information  I I I italic_I , the agent sends this information to the LLM. GenDFIR functions as illustrated in Figure  9 :",
            "GenDFIR processes the input in accordance with the system message ( S  y  s  M  S  G S y s M S G SysMSG italic_S italic_y italic_s italic_M italic_S italic_G  in Algorithm  6 ). If the DFIR analysts input is incorrect or inadequately prompted, the agent prompt ( A  g  e  n  t  P  r  o  m  p  t A g e n t P r o m p t AgentPrompt italic_A italic_g italic_e italic_n italic_t italic_P italic_r italic_o italic_m italic_p italic_t  in Algorithm 4) will adjust the query based on its content. In either case, GenDFIR generates a new query based on the indexed knowledge base.",
            "After processing, the RAG agent performs a retrieval using the cosine similarity function to measure and calculate the similarity score from the knowledge base and identify features from the event that match the DFIR analysts input. In other words, the agent searches for evidence (relevant information  I I I italic_I ) of the incident within the knowledge base to retrieve it. The retrieved information is then sent to the LLM for further semantic understanding, as it is initially presented in numerical format. The cosine similarity function, mathematically operates on the vectors of the user input and the knowledge base, as illustrated in Figure  6 .",
            "Figures  13 ,  14 ,  15 ,  16 ,  17 , and  18  illustrate the outputs of UMAP evidence visualizations."
        ]
    },
    "id_table_7": {
        "caption": "TABLE VII:  Case Studies after R-BAI (Filtering)",
        "table": "S6.T11.1",
        "footnotes": [],
        "references": [
            "( 6 ) is the Euclidean length of the vector  q q q italic_q , and ( 7 ) is the Euclidean length of the vector  t t t italic_t . In ( 5 ), the dot product (scalar product) of  q q q italic_q  and  t t t italic_t  is calculated to measure their similarity. This product is higher if the vectors point in the same direction, indicating they share more common features. The final equation, ( 4 ), calculates the angle    \\theta italic_  between the two vectors. The smaller    \\theta italic_  is, the higher the similarity.",
            "Figure  7  and Figure  8  illustrate two cases of incident investigation using a 3D representation where the x, y, and z axes correspond to context features from LLM embedding vectors.",
            "Figures  13 ,  14 ,  15 ,  16 ,  17 , and  18  illustrate the outputs of UMAP evidence visualizations.",
            "Figure  17  provides an example where all events are considered as evidence. The ground truth data in Table  X  specifies a total of 25 pieces of evidence, based on the users input:  \"Identify all events where the Level is Warning and extract their corresponding evidence\" . However, the Figure  17  generated using UMAP displays only the Top K=20 pieces of evidence, which are those with a cosine similarity score greater than 0.50. This discrepancy indicates an inaccuracy in the cosine similarity-based extraction."
        ]
    },
    "id_table_8": {
        "caption": "TABLE VIII:  Timeline Analysis Report Facts",
        "table": "id1.1",
        "footnotes": [],
        "references": [
            "Figure  7  and Figure  8  illustrate two cases of incident investigation using a 3D representation where the x, y, and z axes correspond to context features from LLM embedding vectors.",
            "Figures  13 ,  14 ,  15 ,  16 ,  17 , and  18  illustrate the outputs of UMAP evidence visualizations."
        ]
    },
    "id_table_9": {
        "caption": "TABLE IX:  EM Evaluation Prompt Checks",
        "table": "id2.1",
        "footnotes": [],
        "references": [
            "In Algorithm  6 , after successfully generating a new query  R  I R I RI italic_R italic_I  and retrieving the context-based information  I I I italic_I , the agent sends this information to the LLM. GenDFIR functions as illustrated in Figure  9 :",
            "The first step is to ensure all data are preprocessed. Since GendFIR focuses on only two modalitiestext in Case 1 and images in Case 2, as illustrated in Figure  9 raw incident images in Case 2 are processed by the Llava-Llama3 MLLM to provide a forensic description of their content. This description is then combined with additional textual information related to the incident. A description alone is not enough, as the framework is responsible for timeline analysis (TA). Therefore, extra data, such as metadata extracted from the images (shown in Figure  9 ) and actions related to the event (e.g., sending, deleting, or altering the image) are included. An initial digital forensics (DF) report containing the raw incident events is created and then filtered using the R-BAI algorithm to minimize and reduce the number of artefacts and data collected based on the defined rules."
        ]
    },
    "global_footnotes": []
}