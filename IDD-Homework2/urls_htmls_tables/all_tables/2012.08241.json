{
    "PAPER'S NUMBER OF TABLES": 2,
    "S3.T2": {
        "caption": "",
        "table": "<table id=\"S3.T2.11.11\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T2.11.11.6.1\" class=\"ltx_tr\">\n<th id=\"S3.T2.11.11.6.1.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_th_row ltx_border_tt\">\n<span id=\"S3.T2.11.11.6.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T2.11.11.6.1.1.1.1\" class=\"ltx_p\" style=\"width:26.0pt;\"><span id=\"S3.T2.11.11.6.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">L</span></span>\n</span>\n</th>\n<th id=\"S3.T2.11.11.6.1.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_th_row ltx_border_tt\">\n<span id=\"S3.T2.11.11.6.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T2.11.11.6.1.2.1.1\" class=\"ltx_p\" style=\"width:60.7pt;\"><span id=\"S3.T2.11.11.6.1.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">L+R</span></span>\n</span>\n</th>\n<th id=\"S3.T2.11.11.6.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span id=\"S3.T2.11.11.6.1.3.1\" class=\"ltx_text\" style=\"font-size:70%;\">KM</span></th>\n<th id=\"S3.T2.11.11.6.1.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span id=\"S3.T2.11.11.6.1.4.1\" class=\"ltx_text\" style=\"font-size:70%;\">TS</span></th>\n<th id=\"S3.T2.11.11.6.1.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span id=\"S3.T2.11.11.6.1.5.1\" class=\"ltx_text\" style=\"font-size:70%;\">Ours</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T2.11.11.5\" class=\"ltx_tr\">\n<th id=\"S3.T2.7.7.1.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_bb ltx_border_t\">\n<span id=\"S3.T2.7.7.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T2.7.7.1.1.1.1\" class=\"ltx_p\" style=\"width:26.0pt;\"><math id=\"S3.T2.7.7.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\mathcal{O}(m)\" display=\"inline\"><semantics id=\"S3.T2.7.7.1.1.1.1.m1.1a\"><mrow id=\"S3.T2.7.7.1.1.1.1.m1.1.2\" xref=\"S3.T2.7.7.1.1.1.1.m1.1.2.cmml\"><mi class=\"ltx_font_mathcaligraphic\" mathsize=\"70%\" id=\"S3.T2.7.7.1.1.1.1.m1.1.2.2\" xref=\"S3.T2.7.7.1.1.1.1.m1.1.2.2.cmml\">𝒪</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S3.T2.7.7.1.1.1.1.m1.1.2.1\" xref=\"S3.T2.7.7.1.1.1.1.m1.1.2.1.cmml\">​</mo><mrow id=\"S3.T2.7.7.1.1.1.1.m1.1.2.3.2\" xref=\"S3.T2.7.7.1.1.1.1.m1.1.2.cmml\"><mo maxsize=\"70%\" minsize=\"70%\" id=\"S3.T2.7.7.1.1.1.1.m1.1.2.3.2.1\" xref=\"S3.T2.7.7.1.1.1.1.m1.1.2.cmml\">(</mo><mi mathsize=\"70%\" id=\"S3.T2.7.7.1.1.1.1.m1.1.1\" xref=\"S3.T2.7.7.1.1.1.1.m1.1.1.cmml\">m</mi><mo maxsize=\"70%\" minsize=\"70%\" id=\"S3.T2.7.7.1.1.1.1.m1.1.2.3.2.2\" xref=\"S3.T2.7.7.1.1.1.1.m1.1.2.cmml\">)</mo></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.7.7.1.1.1.1.m1.1b\"><apply id=\"S3.T2.7.7.1.1.1.1.m1.1.2.cmml\" xref=\"S3.T2.7.7.1.1.1.1.m1.1.2\"><times id=\"S3.T2.7.7.1.1.1.1.m1.1.2.1.cmml\" xref=\"S3.T2.7.7.1.1.1.1.m1.1.2.1\"></times><ci id=\"S3.T2.7.7.1.1.1.1.m1.1.2.2.cmml\" xref=\"S3.T2.7.7.1.1.1.1.m1.1.2.2\">𝒪</ci><ci id=\"S3.T2.7.7.1.1.1.1.m1.1.1.cmml\" xref=\"S3.T2.7.7.1.1.1.1.m1.1.1\">𝑚</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.7.7.1.1.1.1.m1.1c\">\\mathcal{O}(m)</annotation></semantics></math></span>\n</span>\n</th>\n<th id=\"S3.T2.8.8.2.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_bb ltx_border_t\">\n<span id=\"S3.T2.8.8.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S3.T2.8.8.2.2.1.1\" class=\"ltx_p\" style=\"width:60.7pt;\"><math id=\"S3.T2.8.8.2.2.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\mathcal{O}(m+m\\log m)\" display=\"inline\"><semantics id=\"S3.T2.8.8.2.2.1.1.m1.1a\"><mrow id=\"S3.T2.8.8.2.2.1.1.m1.1.1\" xref=\"S3.T2.8.8.2.2.1.1.m1.1.1.cmml\"><mi class=\"ltx_font_mathcaligraphic\" mathsize=\"70%\" id=\"S3.T2.8.8.2.2.1.1.m1.1.1.3\" xref=\"S3.T2.8.8.2.2.1.1.m1.1.1.3.cmml\">𝒪</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S3.T2.8.8.2.2.1.1.m1.1.1.2\" xref=\"S3.T2.8.8.2.2.1.1.m1.1.1.2.cmml\">​</mo><mrow id=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1\" xref=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.cmml\"><mo maxsize=\"70%\" minsize=\"70%\" id=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.2\" xref=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.cmml\">(</mo><mrow id=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1\" xref=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.cmml\"><mi mathsize=\"70%\" id=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.2\" xref=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.2.cmml\">m</mi><mo mathsize=\"70%\" id=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.1\" xref=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.1.cmml\">+</mo><mrow id=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.3\" xref=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.3.cmml\"><mi mathsize=\"70%\" id=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.3.2\" xref=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.3.2.cmml\">m</mi><mo lspace=\"0.167em\" rspace=\"0em\" id=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.3.1\" xref=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.3.1.cmml\">​</mo><mrow id=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.3.3\" xref=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.3.3.cmml\"><mi mathsize=\"70%\" id=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.3.3.1\" xref=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.3.3.1.cmml\">log</mi><mo lspace=\"0.167em\" id=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.3.3a\" xref=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.3.3.cmml\">⁡</mo><mi mathsize=\"70%\" id=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.3.3.2\" xref=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.3.3.2.cmml\">m</mi></mrow></mrow></mrow><mo maxsize=\"70%\" minsize=\"70%\" id=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.3\" xref=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.cmml\">)</mo></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.8.8.2.2.1.1.m1.1b\"><apply id=\"S3.T2.8.8.2.2.1.1.m1.1.1.cmml\" xref=\"S3.T2.8.8.2.2.1.1.m1.1.1\"><times id=\"S3.T2.8.8.2.2.1.1.m1.1.1.2.cmml\" xref=\"S3.T2.8.8.2.2.1.1.m1.1.1.2\"></times><ci id=\"S3.T2.8.8.2.2.1.1.m1.1.1.3.cmml\" xref=\"S3.T2.8.8.2.2.1.1.m1.1.1.3\">𝒪</ci><apply id=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.cmml\" xref=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1\"><plus id=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.1.cmml\" xref=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.1\"></plus><ci id=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.2.cmml\" xref=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.2\">𝑚</ci><apply id=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.3.cmml\" xref=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.3\"><times id=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.3.1.cmml\" xref=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.3.1\"></times><ci id=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.3.2.cmml\" xref=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.3.2\">𝑚</ci><apply id=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.3.3.cmml\" xref=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.3.3\"><log id=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.3.3.1.cmml\" xref=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.3.3.1\"></log><ci id=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.3.3.2.cmml\" xref=\"S3.T2.8.8.2.2.1.1.m1.1.1.1.1.1.3.3.2\">𝑚</ci></apply></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.8.8.2.2.1.1.m1.1c\">\\mathcal{O}(m+m\\log m)</annotation></semantics></math></span>\n</span>\n</th>\n<td id=\"S3.T2.9.9.3.3\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\"><math id=\"S3.T2.9.9.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\mathcal{O}(m(m+n))\" display=\"inline\"><semantics id=\"S3.T2.9.9.3.3.m1.1a\"><mrow id=\"S3.T2.9.9.3.3.m1.1.1\" xref=\"S3.T2.9.9.3.3.m1.1.1.cmml\"><mi class=\"ltx_font_mathcaligraphic\" mathsize=\"70%\" id=\"S3.T2.9.9.3.3.m1.1.1.3\" xref=\"S3.T2.9.9.3.3.m1.1.1.3.cmml\">𝒪</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S3.T2.9.9.3.3.m1.1.1.2\" xref=\"S3.T2.9.9.3.3.m1.1.1.2.cmml\">​</mo><mrow id=\"S3.T2.9.9.3.3.m1.1.1.1.1\" xref=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.cmml\"><mo maxsize=\"70%\" minsize=\"70%\" id=\"S3.T2.9.9.3.3.m1.1.1.1.1.2\" xref=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.cmml\">(</mo><mrow id=\"S3.T2.9.9.3.3.m1.1.1.1.1.1\" xref=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.cmml\"><mi mathsize=\"70%\" id=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.3\" xref=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.3.cmml\">m</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.2\" xref=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.2.cmml\">​</mo><mrow id=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.1.1\" xref=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.1.1.1.cmml\"><mo maxsize=\"70%\" minsize=\"70%\" id=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.1.1.2\" xref=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.1.1.1.cmml\">(</mo><mrow id=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.1.1.1\" xref=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.1.1.1.cmml\"><mi mathsize=\"70%\" id=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.1.1.1.2\" xref=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.1.1.1.2.cmml\">m</mi><mo mathsize=\"70%\" id=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.1.1.1.1\" xref=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.1.1.1.1.cmml\">+</mo><mi mathsize=\"70%\" id=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.1.1.1.3\" xref=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.1.1.1.3.cmml\">n</mi></mrow><mo maxsize=\"70%\" minsize=\"70%\" id=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.1.1.3\" xref=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.1.1.1.cmml\">)</mo></mrow></mrow><mo maxsize=\"70%\" minsize=\"70%\" id=\"S3.T2.9.9.3.3.m1.1.1.1.1.3\" xref=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.cmml\">)</mo></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.9.9.3.3.m1.1b\"><apply id=\"S3.T2.9.9.3.3.m1.1.1.cmml\" xref=\"S3.T2.9.9.3.3.m1.1.1\"><times id=\"S3.T2.9.9.3.3.m1.1.1.2.cmml\" xref=\"S3.T2.9.9.3.3.m1.1.1.2\"></times><ci id=\"S3.T2.9.9.3.3.m1.1.1.3.cmml\" xref=\"S3.T2.9.9.3.3.m1.1.1.3\">𝒪</ci><apply id=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.cmml\" xref=\"S3.T2.9.9.3.3.m1.1.1.1.1\"><times id=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.2.cmml\" xref=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.2\"></times><ci id=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.3.cmml\" xref=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.3\">𝑚</ci><apply id=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.1.1.1.cmml\" xref=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.1.1\"><plus id=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.1.1.1.1.cmml\" xref=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.1.1.1.1\"></plus><ci id=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.1.1.1.2.cmml\" xref=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.1.1.1.2\">𝑚</ci><ci id=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.1.1.1.3.cmml\" xref=\"S3.T2.9.9.3.3.m1.1.1.1.1.1.1.1.1.3\">𝑛</ci></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.9.9.3.3.m1.1c\">\\mathcal{O}(m(m+n))</annotation></semantics></math></td>\n<td id=\"S3.T2.10.10.4.4\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\"><math id=\"S3.T2.10.10.4.4.m1.1\" class=\"ltx_Math\" alttext=\"\\mathcal{O}(mn)\" display=\"inline\"><semantics id=\"S3.T2.10.10.4.4.m1.1a\"><mrow id=\"S3.T2.10.10.4.4.m1.1.1\" xref=\"S3.T2.10.10.4.4.m1.1.1.cmml\"><mi class=\"ltx_font_mathcaligraphic\" mathsize=\"70%\" id=\"S3.T2.10.10.4.4.m1.1.1.3\" xref=\"S3.T2.10.10.4.4.m1.1.1.3.cmml\">𝒪</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S3.T2.10.10.4.4.m1.1.1.2\" xref=\"S3.T2.10.10.4.4.m1.1.1.2.cmml\">​</mo><mrow id=\"S3.T2.10.10.4.4.m1.1.1.1.1\" xref=\"S3.T2.10.10.4.4.m1.1.1.1.1.1.cmml\"><mo maxsize=\"70%\" minsize=\"70%\" id=\"S3.T2.10.10.4.4.m1.1.1.1.1.2\" xref=\"S3.T2.10.10.4.4.m1.1.1.1.1.1.cmml\">(</mo><mrow id=\"S3.T2.10.10.4.4.m1.1.1.1.1.1\" xref=\"S3.T2.10.10.4.4.m1.1.1.1.1.1.cmml\"><mi mathsize=\"70%\" id=\"S3.T2.10.10.4.4.m1.1.1.1.1.1.2\" xref=\"S3.T2.10.10.4.4.m1.1.1.1.1.1.2.cmml\">m</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S3.T2.10.10.4.4.m1.1.1.1.1.1.1\" xref=\"S3.T2.10.10.4.4.m1.1.1.1.1.1.1.cmml\">​</mo><mi mathsize=\"70%\" id=\"S3.T2.10.10.4.4.m1.1.1.1.1.1.3\" xref=\"S3.T2.10.10.4.4.m1.1.1.1.1.1.3.cmml\">n</mi></mrow><mo maxsize=\"70%\" minsize=\"70%\" id=\"S3.T2.10.10.4.4.m1.1.1.1.1.3\" xref=\"S3.T2.10.10.4.4.m1.1.1.1.1.1.cmml\">)</mo></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.10.10.4.4.m1.1b\"><apply id=\"S3.T2.10.10.4.4.m1.1.1.cmml\" xref=\"S3.T2.10.10.4.4.m1.1.1\"><times id=\"S3.T2.10.10.4.4.m1.1.1.2.cmml\" xref=\"S3.T2.10.10.4.4.m1.1.1.2\"></times><ci id=\"S3.T2.10.10.4.4.m1.1.1.3.cmml\" xref=\"S3.T2.10.10.4.4.m1.1.1.3\">𝒪</ci><apply id=\"S3.T2.10.10.4.4.m1.1.1.1.1.1.cmml\" xref=\"S3.T2.10.10.4.4.m1.1.1.1.1\"><times id=\"S3.T2.10.10.4.4.m1.1.1.1.1.1.1.cmml\" xref=\"S3.T2.10.10.4.4.m1.1.1.1.1.1.1\"></times><ci id=\"S3.T2.10.10.4.4.m1.1.1.1.1.1.2.cmml\" xref=\"S3.T2.10.10.4.4.m1.1.1.1.1.1.2\">𝑚</ci><ci id=\"S3.T2.10.10.4.4.m1.1.1.1.1.1.3.cmml\" xref=\"S3.T2.10.10.4.4.m1.1.1.1.1.1.3\">𝑛</ci></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.10.10.4.4.m1.1c\">\\mathcal{O}(mn)</annotation></semantics></math></td>\n<td id=\"S3.T2.11.11.5.5\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\"><math id=\"S3.T2.11.11.5.5.m1.1\" class=\"ltx_Math\" alttext=\"\\mathcal{O}(m)\" display=\"inline\"><semantics id=\"S3.T2.11.11.5.5.m1.1a\"><mrow id=\"S3.T2.11.11.5.5.m1.1.2\" xref=\"S3.T2.11.11.5.5.m1.1.2.cmml\"><mi class=\"ltx_font_mathcaligraphic\" mathsize=\"70%\" id=\"S3.T2.11.11.5.5.m1.1.2.2\" xref=\"S3.T2.11.11.5.5.m1.1.2.2.cmml\">𝒪</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S3.T2.11.11.5.5.m1.1.2.1\" xref=\"S3.T2.11.11.5.5.m1.1.2.1.cmml\">​</mo><mrow id=\"S3.T2.11.11.5.5.m1.1.2.3.2\" xref=\"S3.T2.11.11.5.5.m1.1.2.cmml\"><mo maxsize=\"70%\" minsize=\"70%\" id=\"S3.T2.11.11.5.5.m1.1.2.3.2.1\" xref=\"S3.T2.11.11.5.5.m1.1.2.cmml\">(</mo><mi mathsize=\"70%\" id=\"S3.T2.11.11.5.5.m1.1.1\" xref=\"S3.T2.11.11.5.5.m1.1.1.cmml\">m</mi><mo maxsize=\"70%\" minsize=\"70%\" id=\"S3.T2.11.11.5.5.m1.1.2.3.2.2\" xref=\"S3.T2.11.11.5.5.m1.1.2.cmml\">)</mo></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.11.11.5.5.m1.1b\"><apply id=\"S3.T2.11.11.5.5.m1.1.2.cmml\" xref=\"S3.T2.11.11.5.5.m1.1.2\"><times id=\"S3.T2.11.11.5.5.m1.1.2.1.cmml\" xref=\"S3.T2.11.11.5.5.m1.1.2.1\"></times><ci id=\"S3.T2.11.11.5.5.m1.1.2.2.cmml\" xref=\"S3.T2.11.11.5.5.m1.1.2.2\">𝒪</ci><ci id=\"S3.T2.11.11.5.5.m1.1.1.cmml\" xref=\"S3.T2.11.11.5.5.m1.1.1\">𝑚</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.11.11.5.5.m1.1c\">\\mathcal{O}(m)</annotation></semantics></math></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Federated learning is a promising framework to mitigate data privacy and computation concerns. However, the communication cost between the server and clients has become the major bottleneck for successful deployment.\nDespite notable progress in gradient compression, the existing quantization methods require further improvement when low-bits compression is applied, especially the overall systems often degenerate a lot when quantization are applied in double directions to compress model weights and gradients.\nIn this work, we propose a simple cosine-based nonlinear quantization and achieve impressive results in compressing round-trip communication costs. We are not only able to compress model weights and gradients at higher ratios than previous methods, but also achieve competing model performance at the same time.\nFurther, our approach is highly suitable for federated learning problems since it has low computational complexity and requires only a little additional data to recover the compressed information.\nExtensive experiments have been conducted on image classification and brain tumor semantic segmentation using the CIFAR-10, and BraTS datasets where we show state-of-the-art effectiveness and impressive communication efficiency.",
            "We analyze and compare the complexity of our quantization and previous methods Alistarh et al. (2017); Konečnỳ et al. (2016); Suresh et al. (2017); Han et al. (2016); Fu et al. (2020). Table 2 reports the computation complexity of quantization and dequantization. Let us consider a n𝑛n-bits quantization for a m𝑚m-d vector, which leads to a 2nsuperscript2𝑛2^{n} level compression.\nWe show that the linear quantization Alistarh et al. (2017) and our method have the lowest complexity at 𝒪​(m)𝒪𝑚\\mathcal{O}(m) because both methods have a closed-form quantization. Further, despite the improved performance from random Hadamard rotations Konečnỳ et al. (2016); Suresh et al. (2017), it increases the complexity of compression due to the matrix-vector multiplication. Regarding nonlinear quantization, k𝑘k-means based methods Han et al. (2016) have 𝒪​(m2)𝒪superscript𝑚2\\mathcal{O}(m^{2}) for clustering and 𝒪​(m​n)𝒪𝑚𝑛\\mathcal{O}(mn) for searching. Last, TinyScript Fu et al. (2020) also searches on irregular intervals for each dimension at 𝒪​(log⁡2n)=𝒪​(n)𝒪superscript2𝑛𝒪𝑛\\mathcal{O}(\\log 2^{n})=\\mathcal{O}(n). Consequently, we can clearly see the advantages of our method in terms of computation complexity since our approach needs less computation than other nonlinear approaches, making our method in particular suitable to deploy on edge devices with limited resources.",
            "Additionally, we also discuss the memory costs generated for quantization and dequantization. First of all, we emphasize that our method only needs two float numbers (i.e., bound bθsubscript𝑏𝜃b_{\\theta} and norm ‖v‖2subscriptnormv2\\|\\textbf{v}\\|_{2} ) to perform dequantization. Therefore, the additional communication costs for our method is negligible compared to quantized gradients. Even though the linear quantization and its improved version with random Hadamard rotations also need only two float numbers for defining the quantization range, we point out their performances remain improvable in section 4. On the other hand, k𝑘k-means needs additional costs of 𝒪​(m)𝒪𝑚\\mathcal{O}(m) for the clustering centroids, leading to more data to communicate between a server and clients. In the end, TinyScript has to create quantization tables for each client, additionally introducing memory loading for edge devices.\nTo conclude, our proposed method has a simple closed-form computation and does not need a lot of additional memory costs, which is suitable for federated learning.",
            "Full gradient compression We compare our quantization with linear quantization Alistarh et al. (2017) and k𝑘k-means based method Han et al. (2016) on CIFAR-10,\nas listed in Table 3. Although unbiased quantization (e.g. Eq. 3) indeed improves the performance, biased quantization is still helpful for understanding the effect of quantization intervals. Therefore, we conduct experiments using both biased and unbiased version for linear quantization Alistarh et al. (2017) and our methods."
        ]
    },
    "S4.T3": {
        "caption": "",
        "table": "<table id=\"S4.T3.8.7\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T3.7.6.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.7.6.2.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T3.7.6.2.3.1\" class=\"ltx_text\" style=\"font-size:70%;\">Method</span></th>\n<th id=\"S4.T3.6.5.1.1\" class=\"ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\">\n<span id=\"S4.T3.6.5.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Biased (</span><math id=\"S4.T3.6.5.1.1.m1.1\" class=\"ltx_Math\" alttext=\"n\" display=\"inline\"><semantics id=\"S4.T3.6.5.1.1.m1.1a\"><mi mathsize=\"70%\" id=\"S4.T3.6.5.1.1.m1.1.1\" xref=\"S4.T3.6.5.1.1.m1.1.1.cmml\">n</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.6.5.1.1.m1.1b\"><ci id=\"S4.T3.6.5.1.1.m1.1.1.cmml\" xref=\"S4.T3.6.5.1.1.m1.1.1\">𝑛</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.6.5.1.1.m1.1c\">n</annotation></semantics></math><span id=\"S4.T3.6.5.1.1.2\" class=\"ltx_text\" style=\"font-size:70%;\">-bits)</span>\n</th>\n<th id=\"S4.T3.7.6.2.2\" class=\"ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\">\n<span id=\"S4.T3.7.6.2.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">Unbiased (</span><math id=\"S4.T3.7.6.2.2.m1.1\" class=\"ltx_Math\" alttext=\"n\" display=\"inline\"><semantics id=\"S4.T3.7.6.2.2.m1.1a\"><mi mathsize=\"70%\" id=\"S4.T3.7.6.2.2.m1.1.1\" xref=\"S4.T3.7.6.2.2.m1.1.1.cmml\">n</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.7.6.2.2.m1.1b\"><ci id=\"S4.T3.7.6.2.2.m1.1.1.cmml\" xref=\"S4.T3.7.6.2.2.m1.1.1\">𝑛</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.7.6.2.2.m1.1c\">n</annotation></semantics></math><span id=\"S4.T3.7.6.2.2.2\" class=\"ltx_text\" style=\"font-size:70%;\">-bits)</span>\n</th>\n</tr>\n<tr id=\"S4.T3.8.7.4.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.8.7.4.1.1\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column\">\n<span id=\"S4.T3.8.7.4.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.8.7.4.1.1.1.1\" class=\"ltx_p\" style=\"width:17.3pt;\"><span id=\"S4.T3.8.7.4.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">8</span></span>\n</span>\n</th>\n<th id=\"S4.T3.8.7.4.1.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column\">\n<span id=\"S4.T3.8.7.4.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.8.7.4.1.2.1.1\" class=\"ltx_p\" style=\"width:17.3pt;\"><span id=\"S4.T3.8.7.4.1.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">4</span></span>\n</span>\n</th>\n<th id=\"S4.T3.8.7.4.1.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r\">\n<span id=\"S4.T3.8.7.4.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.8.7.4.1.3.1.1\" class=\"ltx_p\" style=\"width:17.3pt;\"><span id=\"S4.T3.8.7.4.1.3.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">2</span></span>\n</span>\n</th>\n<th id=\"S4.T3.8.7.4.1.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column\">\n<span id=\"S4.T3.8.7.4.1.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.8.7.4.1.4.1.1\" class=\"ltx_p\" style=\"width:17.3pt;\"><span id=\"S4.T3.8.7.4.1.4.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">8</span></span>\n</span>\n</th>\n<th id=\"S4.T3.8.7.4.1.5\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column\">\n<span id=\"S4.T3.8.7.4.1.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.8.7.4.1.5.1.1\" class=\"ltx_p\" style=\"width:17.3pt;\"><span id=\"S4.T3.8.7.4.1.5.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">4</span></span>\n</span>\n</th>\n<th id=\"S4.T3.8.7.4.1.6\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column\">\n<span id=\"S4.T3.8.7.4.1.6.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.8.7.4.1.6.1.1\" class=\"ltx_p\" style=\"width:17.3pt;\"><span id=\"S4.T3.8.7.4.1.6.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">2</span></span>\n</span>\n</th>\n</tr>\n<tr id=\"S4.T3.8.7.5.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.8.7.5.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S4.T3.8.7.5.2.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">float32</span></th>\n<th id=\"S4.T3.8.7.5.2.2\" class=\"ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_column ltx_border_t\" colspan=\"6\"><span id=\"S4.T3.8.7.5.2.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">85.2</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.8.7.6.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.8.7.6.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\"><span id=\"S4.T3.8.7.6.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">linear</span></th>\n<td id=\"S4.T3.8.7.6.1.2\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S4.T3.8.7.6.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.8.7.6.1.2.1.1\" class=\"ltx_p\" style=\"width:17.3pt;\"><span id=\"S4.T3.8.7.6.1.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">85.18</span></span>\n</span>\n</td>\n<td id=\"S4.T3.8.7.6.1.3\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S4.T3.8.7.6.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.8.7.6.1.3.1.1\" class=\"ltx_p\" style=\"width:17.3pt;\"><span id=\"S4.T3.8.7.6.1.3.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">85.15</span></span>\n</span>\n</td>\n<td id=\"S4.T3.8.7.6.1.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\">\n<span id=\"S4.T3.8.7.6.1.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.8.7.6.1.4.1.1\" class=\"ltx_p\" style=\"width:17.3pt;\"><span id=\"S4.T3.8.7.6.1.4.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">10</span></span>\n</span>\n</td>\n<td id=\"S4.T3.8.7.6.1.5\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S4.T3.8.7.6.1.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.8.7.6.1.5.1.1\" class=\"ltx_p\" style=\"width:17.3pt;\"><span id=\"S4.T3.8.7.6.1.5.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">85.19</span></span>\n</span>\n</td>\n<td id=\"S4.T3.8.7.6.1.6\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S4.T3.8.7.6.1.6.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.8.7.6.1.6.1.1\" class=\"ltx_p\" style=\"width:17.3pt;\"><span id=\"S4.T3.8.7.6.1.6.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">85.16</span></span>\n</span>\n</td>\n<td id=\"S4.T3.8.7.6.1.7\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S4.T3.8.7.6.1.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.8.7.6.1.7.1.1\" class=\"ltx_p\" style=\"width:17.3pt;\"><span id=\"S4.T3.8.7.6.1.7.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">73.11</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T3.8.7.3\" class=\"ltx_tr\">\n<th id=\"S4.T3.8.7.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\">\n<math id=\"S4.T3.8.7.3.1.m1.1\" class=\"ltx_Math\" alttext=\"k\" display=\"inline\"><semantics id=\"S4.T3.8.7.3.1.m1.1a\"><mi mathsize=\"70%\" id=\"S4.T3.8.7.3.1.m1.1.1\" xref=\"S4.T3.8.7.3.1.m1.1.1.cmml\">k</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.8.7.3.1.m1.1b\"><ci id=\"S4.T3.8.7.3.1.m1.1.1.cmml\" xref=\"S4.T3.8.7.3.1.m1.1.1\">𝑘</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.8.7.3.1.m1.1c\">k</annotation></semantics></math><span id=\"S4.T3.8.7.3.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">-means</span>\n</th>\n<td id=\"S4.T3.8.7.3.2\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S4.T3.8.7.3.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.8.7.3.2.1.1\" class=\"ltx_p\" style=\"width:17.3pt;\"><span id=\"S4.T3.8.7.3.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">85.17</span></span>\n</span>\n</td>\n<td id=\"S4.T3.8.7.3.3\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S4.T3.8.7.3.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.8.7.3.3.1.1\" class=\"ltx_p\" style=\"width:17.3pt;\"><span id=\"S4.T3.8.7.3.3.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">85.15</span></span>\n</span>\n</td>\n<td id=\"S4.T3.8.7.3.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_r\">\n<span id=\"S4.T3.8.7.3.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.8.7.3.4.1.1\" class=\"ltx_p\" style=\"width:17.3pt;\"><span id=\"S4.T3.8.7.3.4.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">82.1</span></span>\n</span>\n</td>\n<td id=\"S4.T3.8.7.3.5\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S4.T3.8.7.3.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.8.7.3.5.1.1\" class=\"ltx_p\" style=\"width:17.3pt;\"><span id=\"S4.T3.8.7.3.5.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">-</span></span>\n</span>\n</td>\n<td id=\"S4.T3.8.7.3.6\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S4.T3.8.7.3.6.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.8.7.3.6.1.1\" class=\"ltx_p\" style=\"width:17.3pt;\"><span id=\"S4.T3.8.7.3.6.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">-</span></span>\n</span>\n</td>\n<td id=\"S4.T3.8.7.3.7\" class=\"ltx_td ltx_align_justify ltx_align_top\">\n<span id=\"S4.T3.8.7.3.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.8.7.3.7.1.1\" class=\"ltx_p\" style=\"width:17.3pt;\"><span id=\"S4.T3.8.7.3.7.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">-</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T3.8.7.7.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.8.7.7.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\"><span id=\"S4.T3.8.7.7.2.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">Ours</span></th>\n<td id=\"S4.T3.8.7.7.2.2\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S4.T3.8.7.7.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.8.7.7.2.2.1.1\" class=\"ltx_p\" style=\"width:17.3pt;\"><span id=\"S4.T3.8.7.7.2.2.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">85.3</span></span>\n</span>\n</td>\n<td id=\"S4.T3.8.7.7.2.3\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S4.T3.8.7.7.2.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.8.7.7.2.3.1.1\" class=\"ltx_p\" style=\"width:17.3pt;\"><span id=\"S4.T3.8.7.7.2.3.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">85.24</span></span>\n</span>\n</td>\n<td id=\"S4.T3.8.7.7.2.4\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r\">\n<span id=\"S4.T3.8.7.7.2.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.8.7.7.2.4.1.1\" class=\"ltx_p\" style=\"width:17.3pt;\"><span id=\"S4.T3.8.7.7.2.4.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">85.2</span></span>\n</span>\n</td>\n<td id=\"S4.T3.8.7.7.2.5\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S4.T3.8.7.7.2.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.8.7.7.2.5.1.1\" class=\"ltx_p\" style=\"width:17.3pt;\"><span id=\"S4.T3.8.7.7.2.5.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">85.28</span></span>\n</span>\n</td>\n<td id=\"S4.T3.8.7.7.2.6\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S4.T3.8.7.7.2.6.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.8.7.7.2.6.1.1\" class=\"ltx_p\" style=\"width:17.3pt;\"><span id=\"S4.T3.8.7.7.2.6.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">85.25</span></span>\n</span>\n</td>\n<td id=\"S4.T3.8.7.7.2.7\" class=\"ltx_td ltx_align_justify ltx_align_top ltx_border_bb\">\n<span id=\"S4.T3.8.7.7.2.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.8.7.7.2.7.1.1\" class=\"ltx_p\" style=\"width:17.3pt;\"><span id=\"S4.T3.8.7.7.2.7.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">85.2</span></span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "Full gradient compression We compare our quantization with linear quantization Alistarh et al. (2017) and k𝑘k-means based method Han et al. (2016) on CIFAR-10,\nas listed in Table 3. Although unbiased quantization (e.g. Eq. 3) indeed improves the performance, biased quantization is still helpful for understanding the effect of quantization intervals. Therefore, we conduct experiments using both biased and unbiased version for linear quantization Alistarh et al. (2017) and our methods.",
        "references": [
            "Federated learning is a promising framework to mitigate data privacy and computation concerns. However, the communication cost between the server and clients has become the major bottleneck for successful deployment.\nDespite notable progress in gradient compression, the existing quantization methods require further improvement when low-bits compression is applied, especially the overall systems often degenerate a lot when quantization are applied in double directions to compress model weights and gradients.\nIn this work, we propose a simple cosine-based nonlinear quantization and achieve impressive results in compressing round-trip communication costs. We are not only able to compress model weights and gradients at higher ratios than previous methods, but also achieve competing model performance at the same time.\nFurther, our approach is highly suitable for federated learning problems since it has low computational complexity and requires only a little additional data to recover the compressed information.\nExtensive experiments have been conducted on image classification and brain tumor semantic segmentation using the CIFAR-10, and BraTS datasets where we show state-of-the-art effectiveness and impressive communication efficiency.",
            "We analyze and compare the complexity of our quantization and previous methods Alistarh et al. (2017); Konečnỳ et al. (2016); Suresh et al. (2017); Han et al. (2016); Fu et al. (2020). Table 2 reports the computation complexity of quantization and dequantization. Let us consider a n𝑛n-bits quantization for a m𝑚m-d vector, which leads to a 2nsuperscript2𝑛2^{n} level compression.\nWe show that the linear quantization Alistarh et al. (2017) and our method have the lowest complexity at 𝒪​(m)𝒪𝑚\\mathcal{O}(m) because both methods have a closed-form quantization. Further, despite the improved performance from random Hadamard rotations Konečnỳ et al. (2016); Suresh et al. (2017), it increases the complexity of compression due to the matrix-vector multiplication. Regarding nonlinear quantization, k𝑘k-means based methods Han et al. (2016) have 𝒪​(m2)𝒪superscript𝑚2\\mathcal{O}(m^{2}) for clustering and 𝒪​(m​n)𝒪𝑚𝑛\\mathcal{O}(mn) for searching. Last, TinyScript Fu et al. (2020) also searches on irregular intervals for each dimension at 𝒪​(log⁡2n)=𝒪​(n)𝒪superscript2𝑛𝒪𝑛\\mathcal{O}(\\log 2^{n})=\\mathcal{O}(n). Consequently, we can clearly see the advantages of our method in terms of computation complexity since our approach needs less computation than other nonlinear approaches, making our method in particular suitable to deploy on edge devices with limited resources.",
            "Additionally, we also discuss the memory costs generated for quantization and dequantization. First of all, we emphasize that our method only needs two float numbers (i.e., bound bθsubscript𝑏𝜃b_{\\theta} and norm ‖v‖2subscriptnormv2\\|\\textbf{v}\\|_{2} ) to perform dequantization. Therefore, the additional communication costs for our method is negligible compared to quantized gradients. Even though the linear quantization and its improved version with random Hadamard rotations also need only two float numbers for defining the quantization range, we point out their performances remain improvable in section 4. On the other hand, k𝑘k-means needs additional costs of 𝒪​(m)𝒪𝑚\\mathcal{O}(m) for the clustering centroids, leading to more data to communicate between a server and clients. In the end, TinyScript has to create quantization tables for each client, additionally introducing memory loading for edge devices.\nTo conclude, our proposed method has a simple closed-form computation and does not need a lot of additional memory costs, which is suitable for federated learning.",
            "Full gradient compression We compare our quantization with linear quantization Alistarh et al. (2017) and k𝑘k-means based method Han et al. (2016) on CIFAR-10,\nas listed in Table 3. Although unbiased quantization (e.g. Eq. 3) indeed improves the performance, biased quantization is still helpful for understanding the effect of quantization intervals. Therefore, we conduct experiments using both biased and unbiased version for linear quantization Alistarh et al. (2017) and our methods."
        ]
    }
}