{
    "id_table_1": {
        "caption": "Table 1:  Impact of diverse noise types on accuracy ( % percent \\% % ) for Llama3-8B-Instruct and Qwen2-7b-Instruct across seven datasets. We assess performance across various retrieval scenarios: Base (no retrieval), Golden Only (only golden retrieval context), and Golden  & \\& &  XXX (golden context + specific retrieval noises, including Counterfactual, Supportive, Orthographic, Semantic, Datatype, Illegal Sentence Noise). The  green  and  red  values indicate the performance gap from Golden Only. We also provide the weighted average accuracy for each noise type. The best two results are shown in bold and underlined.",
        "table": "Sx4.T1.47",
        "footnotes": [],
        "references": [
            "Recently, several studies  (Chen et al.  2024 ; Xiang et al.  2024 )  have attempted to extend RAG systems to complex real-world scenarios, investigating the impact of noisy documents and strategies to enhance the systems robustness. For example,  Cuconasu et al. ( 2024 )  defines three types of noise in retrieved documents and examines their impacts on LLM. Despite highlighting one noises positive effect, the study lacks a comprehensive noise definition and in-depth investigation of underlying principles.  Fang et al. ( 2024 )  applies adversarial training to dynamically adjust the models training process in response to retrieval noises. RobustRAG  (Xiang et al.  2024 )  proposes a defense framework to improve the robustness of RAG models against retrieval corruption attacks. Nevertheless, these investigations typically focus on a limited number of noise types (usually no more than three) and lack clear classification, which fails to fully capture the complexity of real-world noise environments. Additionally, these studies often assume that noise is harmful, neglecting its potential positive effects and lacking systematic evaluation datasets. As shown in Figure  1 , introducing beneficial noise allows the LLM to avoid the harmful effects of counterfactual noise, concentrate on the golden context, and produce accurate responses. Thus, theres an urgent need to redefine and describe noise scenarios in RAG, and systematically explore the specific impacts of retrieval noises.",
            "Table 1 illustrates the impact of diverse noise types (the first six) on two state-of-the-art open-source models: Llama3-8B-Instruct and Qwen2-7B-Instruct. We observe consistent performance trends across multiple datasets and retrieval noises. Based on these trends, we can categorize retrieval noises into two types:  harmful noise  (counterfactual, supportive, and orthographic) and  beneficial noise  (semantic, datatype, and illegal sentence). We find that:",
            "(1) For harmful noise, counterfactual noise impacts model performance most significantly by disrupting accurate fact discernment and answer generation. As shown in Figure  1 , the false statement Beckham was a prominent player for Manchester United leads the model to disregard correct information and respond erroneously."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Effects of prior noise measured by accuracy ( % percent \\% % ). Base indicates the scenario with no retrieval. Misleading refers to counterfactual content associated with prior noise. Background denotes multiple retrieval results obtained after decomposing the query into its constituent entities.",
        "table": "Sx5.T2.3",
        "footnotes": [],
        "references": [
            "As shown in Figure  2 , we categorize RAG noise into seven types from a linguistic perspective. They are further divided into beneficial (semantic, datatype, and illegal sentence) and harmful noise (counterfactual, supportive, orthographic, and prior) for practical applications. We will explain the reason behind this classification in the  Experiments  section.",
            "For prior noise, we assess eight LLMs on our dataset, PriorQA. Questions in PriorQA contain factual errors, such as Which country hosted 1980 FIFA World Cup? (1980 FIFA World Cup was not held). Accuracy is measured by whether LLMs correctly identify and respond with The question is factually incorrect. As shown in Table 2, results show an average accuracy of 79.93 % percent \\% %  across eight LLMs when handling prior noise. However, when models fail to identify prior errors and continue retrieval, performance drops significantly to 34.20 % percent \\% % . This underscores the need to detect prior errors in user queries before answering."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Effects of beneficial noise on Self-RAG (13B). We assess performance through enhanced accuracy ratios ( % percent \\% % ), and the weighted average values (WA,  % percent \\% % ) are also provided.",
        "table": "Sx5.T3.5",
        "footnotes": [],
        "references": [
            "We discuss the data construction and evaluation metrics. The overall framework is illustrated in Figure  3 .",
            "As shown in Figure  3  (A), our framework comprises four essential steps, including QA Instance Generation, Entailment Verification, Noise Introduction and Testbeds Construction.",
            "We consider both model architectures (Figure  5 ) and RAG system designs (Table 3) to demonstrate the positive effects of beneficial noise across various models. We present results for illegal sentence noise here. Additionally, since prior research has highlighted the positive effect of semantic noise  (Cuconasu et al.  2024 ) , our subsequent discussion will focus on two types: datatype noise and illegal sentence noise.",
            "(2) Noise effects on specialized RAG models  As illustrated in Table 3, introducing illegal sentence noise to the specialized RAG model Self-RAG  (Asai et al.  2024 )  consistently enhances model performance across various datasets (NQ, RGB, and StrategyQA) and scenarios (without noise, with harmful and beneficial noise). This further validates the positive effects of beneficial noise."
        ]
    },
    "id_table_4": {
        "caption": "Table 4:  Statistical significance of differences between scenarios with and without beneficial noises.",
        "table": "Sx5.T4.1",
        "footnotes": [],
        "references": [
            "Step 3: Noise Introduction    We construct diverse retrieval documents for noise testbeds. For counterfactual noise, we extract related entities and relations from Google search results to create counterfactual answers. ChatGPT is then employed to construct corresponding supportive evidence, followed by entailment verification. We present the prompts in Figure  4 . For Supportive and semantic noise, we utilize the 2018 English Wikipedia dump  (Karpukhin et al.  2020 )  as source documents, with off-the-shelf Contriever-MS MARCO model  (Izacard et al.  2022 )  for retrieval and the lightweight text embedding model all-MiniLM-L6-v2  (Wang et al.  2021 )  for semantic relevance filtering. To simulate illegal sentence noise, we construct meaningless sentences by randomly combining words from model vocabulary, mimicking real-world garbled text. Datatype noise is created by prompting ChatGPT to insert URLs or code snippets while preserving key answer information. Finally, orthographic noise is generated using the open-source textnoisr package  (Preligens Lab  2023 ) , which enables convenient noise introduction. Four types of action are implemented: insert, delete, substitute, and swap. In summary, this pipeline enables a comprehensive assessment of model performance across a range of noise scenarios.",
            "To statistically evaluate the differences between scenarios with and without beneficial noise, we apply the nonparametric Wilcoxon signed-rank test  (Kotz and Johnson  1992 ) . This method effectively measures the magnitudes of differences and detects statistical significance between two conditions. We test the null hypothesis of no significant difference ( H 0 : d  i  f  f  e  r  e  n  c  e = 0 : subscript H 0 d i f f e r e n c e 0 H_{0}:difference=0 italic_H start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT : italic_d italic_i italic_f italic_f italic_e italic_r italic_e italic_n italic_c italic_e = 0 ) against the alternative hypothesis of a significant difference ( H 1 : d  i  f  f  e  r  e  n  c  e = 0 : subscript H 1 d i f f e r e n c e 0 H_{1}:difference\\neq 0 italic_H start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT : italic_d italic_i italic_f italic_f italic_e italic_r italic_e italic_n italic_c italic_e = 0 ). Following  Seth et al. ( 2023 ); Wu et al. ( 2023 ) , we use a significance level of 0.05. As shown in Table 4, all p-values are below 0.05, leading us to reject the null hypothesis ( H 0 subscript H 0 H_{0} italic_H start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ). These results provide strong statistical evidence that beneficial noise improves model performance."
        ]
    },
    "id_table_5": {
        "caption": "Table 5:  Examples of LLM outputs without and with beneficial noise (BN). The  blue  and  green  colors denote the correct and incorrect responses, respectively. Upon introducing BN, LLMs exhibit clearer reasoning processes, more standardized response formats, and increased focus on golden context.",
        "table": "Sx5.SSx2.SSSx3.6.6",
        "footnotes": [],
        "references": [
            "We consider both model architectures (Figure  5 ) and RAG system designs (Table 3) to demonstrate the positive effects of beneficial noise across various models. We present results for illegal sentence noise here. Additionally, since prior research has highlighted the positive effect of semantic noise  (Cuconasu et al.  2024 ) , our subsequent discussion will focus on two types: datatype noise and illegal sentence noise.",
            "(1) Results across various architectures and scales  As shown in Figure  5 , we evaluate the impact of illegal sentence noise (ISN) on eight LLMs (different architectures and scales) by calculating average accuracy across scenarios with no noise, harmful noise (e.g. CN, ON), and beneficial noise (e.g. DN).  We apply proportional scaling to CN data to make a clearer illustration within one figure while maintaining consistent conclusions. The results indicate that ISN significantly enhances model performance in all scenarios, with the most substantial improvement under harmful noise. To better illustrate the impacts of certain noise types, which may not be immediately apparent in tabular form, we plot their performance across multiple models using line graphs (Figure  6 ) under three conditions: golden only, golden  & \\& &  orthographic noise, and golden  & \\& &  semantic noise. These visualizations clearly demonstrate the negative effect of orthographic noise and the slight performance boost provided by semantic noise.",
            "Table 5 presents the complete reasoning and generation process of Llama3-8B-instruct on the multi-hop dataset Bamboogle. When exposed to harmful noise without any beneficial noise, the model ignores correct information and exhibits logical flaws under the influence of counterfactual noise influence. This is exemplified by its erroneous statement: The other options are incorrect, as they provide different birth dates for the author. However, upon introducing beneficial noise, the model exhibits heightened attention to the golden context and successfully distinguishes between correct and incorrect information ( H1 ). We hypothesize that beneficial noise enhances the LLMs ability to integrate its parameterized knowledge with retrieved information, thus improving its capacity to discern truth from falsehood. Furthermore, by comparing model outputs under two conditions, we observe that beneficial noise contributes to more standardized answer formats ( H2 )."
        ]
    },
    "global_footnotes": []
}