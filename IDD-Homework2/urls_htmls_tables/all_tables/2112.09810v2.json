{
    "S4.T1": {
        "caption": "Table 1: Summary statistics of the evaluation datasets.",
        "table": null,
        "footnotes": [],
        "references": [
            "Evaluation Datasets.\nWe conduct experiments on five graph benchmark datasets for semi-supervised node classification to demonstrate the effectiveness of the proposed Meta-PN. The detailed statistics of the datasets are summarized in Table 1. Specifically, Cora-ML, CiteSeerÂ (Sen etÂ al. 2008) and PubMed (Namata etÂ al. 2012) are the three most widely used citation networks. MS-CS is a co-authorship network based on the Microsoft Academic GraphÂ (Shchur etÂ al. 2018). For data splitting, we follow the previous workÂ (Klicpera, Bojchevski, and GÃ¼nnemann 2019) and split each dataset into training set (i.e., K nodes per class for K-shot task), validation set and test set. In addition, to further evaluate the performance of different methods on large-scale graphs, we further include the ogbn-arxiv datasets from Open Graph Benchmark (OGB)Â (Hu etÂ al. 2020). For the ogbn-arxiv dataset, we randomly sample 1.0%, 1.5%, 2.0%, 2.5% nodes from its training splits as labeled data while using the same validation and test splits in OGB BenchmarkÂ (Hu etÂ al. 2020). Note that for all the datasets, we run each experiment 100 times with multiple random splits and different initializations."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Test accuracy on few-shot semi-supervised node classification: mean accuracy (%percent\\%) Â±plus-or-minus\\pm 95%percent\\% confidence interval.",
        "table": null,
        "footnotes": [],
        "references": [
            "Few-shot Semi-supervised Evaluation. First, we evaluate the proposed approach Meta-PN and all the baseline methods on few-shot semi-supervised node classification, which aims to predict the missing node labels with only a few labeled nodes. The average test accuracies under the few-shot setting (i.e., 3-shot and 5-shot) can be found in TableÂ 2. Additional results are provided in Appendix A.4 due to the space limit. From the reported results, we can clearly see that Meta-PN significantly outperforms all the baseline methods on each dataset based on paired t-tests with p<0.05ð‘0.05p<0.05. Specifically, we elaborate our in-depth observations and analysis as follows:\n(i) without abundant labeled data, classical models including vanilla GNNs only obtain very poor classification accuracy under different evaluation entries;\n(ii) overall the label-efficient GNNs outperform classical GNNs, but still cannot achieve satisfying results. One major reason is that those methods cannot handle the oversmoothing issue since they are incapable of explicitly leveraging the knowledge from large receptive fields; (iii) by enabling better propagation of label signals, deep GNNs have stronger performance than both the classical models and label-efficient GNNs, which again demonstrates the necessity of addressing the oversmoothing issue for solving the few-shot semi-supervised learning problem. However, existing deep GNNs are not specifically developed to tackle the data sparsity issue, thus their performance still falls behind Meta-PN by a noticeable margin on different datasets when only very few labels are available. This observation proves that Meta-PN is able to address the overfitting and oversmoothing issues when labeled data is extremely sparse by combining the power of large receptive fields and pseudo labels.",
            "As a supplement to Table 2, we compare Meta-PN with the baseline methods on one more low-resource semi-supervised node classification task (10-shot) and the test results are summarized in Table 4. Based on the results, we can observe that the proposed Meta-PN can significantly outperform all the baseline methods for the 10-shot task on different datasets, which further illustrates the effectiveness of Meta-PN for low-resource semi-supervised node classification."
        ]
    },
    "S4.T3": {
        "caption": "Table 3: Test accuracy on standard semi-supervised node classification: mean accuracy (%percent\\%) Â±plus-or-minus\\pm 95%percent\\% confidence interval.",
        "table": null,
        "footnotes": [],
        "references": [
            "Standard Semi-supervised Evaluation. To make our evaluation more comprehensive, we then examine the effectiveness of Meta-PN under the standard semi-supervised node classification tasks. As in (Klicpera, Bojchevski, and GÃ¼nnemann 2019), we randomly sample 20 labeled nodes for each class (i.e., 20-shot) as the training set. According to the average performance reported in TableÂ 3, we make the following observations:\n(i) the GNN models which combine both the structure and feature knowledge from labeled nodes can obtain improved node classification performance compared to methods which only consider feature or structure information individually; (ii) under the standard semi-supervised node classification task, the performance of the label-efficient GNNs are close to vanilla GNNs; (iii) though Meta-PN is mainly proposed for few-shot semi-supervised learning, it still achieves the best performance for the standard semi-supervised node classification task, illustrating the superiority of our graph approach."
        ]
    },
    "A1.T4": {
        "caption": "Table 4: Test accuracy on 10-shot semi-supervised node classification with different models: Mean accuracy (%percent\\%) Â±plus-or-minus\\pm 95%percent\\% confidence interval.",
        "table": null,
        "footnotes": [],
        "references": [
            "As a supplement to Table 2, we compare Meta-PN with the baseline methods on one more low-resource semi-supervised node classification task (10-shot) and the test results are summarized in Table 4. Based on the results, we can observe that the proposed Meta-PN can significantly outperform all the baseline methods for the 10-shot task on different datasets, which further illustrates the effectiveness of Meta-PN for low-resource semi-supervised node classification."
        ]
    }
}