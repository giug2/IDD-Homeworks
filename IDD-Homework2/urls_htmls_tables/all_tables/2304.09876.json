{
    "PAPER'S NUMBER OF TABLES": 4,
    "S3.T1": {
        "caption": "Table 1: Data sample breakdown for the states used for prediction year 2016, 2017 and 2018. Each state represents a silo used in FL.",
        "table": "<table id=\"S3.T1.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.4.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.4.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Location</th>\n<th id=\"S3.T1.4.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\">2016</th>\n<th id=\"S3.T1.4.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\">2017</th>\n<th id=\"S3.T1.4.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\">2018</th>\n</tr>\n<tr id=\"S3.T1.4.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T1.4.2.2.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_t\"></th>\n<th id=\"S3.T1.4.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Train</th>\n<th id=\"S3.T1.4.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Val</th>\n<th id=\"S3.T1.4.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Train</th>\n<th id=\"S3.T1.4.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Val</th>\n<th id=\"S3.T1.4.2.2.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Train</th>\n<th id=\"S3.T1.4.2.2.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Val</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.4.3.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.4.3.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">Illinois</th>\n<td id=\"S3.T1.4.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">2977</td>\n<td id=\"S3.T1.4.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">67</td>\n<td id=\"S3.T1.4.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">3044</td>\n<td id=\"S3.T1.4.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">72</td>\n<td id=\"S3.T1.4.3.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">3116</td>\n<td id=\"S3.T1.4.3.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\">64</td>\n</tr>\n<tr id=\"S3.T1.4.4.2\" class=\"ltx_tr\">\n<th id=\"S3.T1.4.4.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">Indiana</th>\n<td id=\"S3.T1.4.4.2.2\" class=\"ltx_td ltx_align_center\">2630</td>\n<td id=\"S3.T1.4.4.2.3\" class=\"ltx_td ltx_align_center\">52</td>\n<td id=\"S3.T1.4.4.2.4\" class=\"ltx_td ltx_align_center\">2682</td>\n<td id=\"S3.T1.4.4.2.5\" class=\"ltx_td ltx_align_center\">54</td>\n<td id=\"S3.T1.4.4.2.6\" class=\"ltx_td ltx_align_center\">2736</td>\n<td id=\"S3.T1.4.4.2.7\" class=\"ltx_td ltx_align_center\">61</td>\n</tr>\n<tr id=\"S3.T1.4.5.3\" class=\"ltx_tr\">\n<th id=\"S3.T1.4.5.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">Iowa</th>\n<td id=\"S3.T1.4.5.3.2\" class=\"ltx_td ltx_align_center\">3132</td>\n<td id=\"S3.T1.4.5.3.3\" class=\"ltx_td ltx_align_center\">94</td>\n<td id=\"S3.T1.4.5.3.4\" class=\"ltx_td ltx_align_center\">3226</td>\n<td id=\"S3.T1.4.5.3.5\" class=\"ltx_td ltx_align_center\">90</td>\n<td id=\"S3.T1.4.5.3.6\" class=\"ltx_td ltx_align_center\">3316</td>\n<td id=\"S3.T1.4.5.3.7\" class=\"ltx_td ltx_align_center\">86</td>\n</tr>\n<tr id=\"S3.T1.4.6.4\" class=\"ltx_tr\">\n<th id=\"S3.T1.4.6.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">Kansas</th>\n<td id=\"S3.T1.4.6.4.2\" class=\"ltx_td ltx_align_center\">2443</td>\n<td id=\"S3.T1.4.6.4.3\" class=\"ltx_td ltx_align_center\">17</td>\n<td id=\"S3.T1.4.6.4.4\" class=\"ltx_td ltx_align_center\">2460</td>\n<td id=\"S3.T1.4.6.4.5\" class=\"ltx_td ltx_align_center\">19</td>\n<td id=\"S3.T1.4.6.4.6\" class=\"ltx_td ltx_align_center\">2479</td>\n<td id=\"S3.T1.4.6.4.7\" class=\"ltx_td ltx_align_center\">15</td>\n</tr>\n<tr id=\"S3.T1.4.7.5\" class=\"ltx_tr\">\n<th id=\"S3.T1.4.7.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">Minnesota</th>\n<td id=\"S3.T1.4.7.5.2\" class=\"ltx_td ltx_align_center\">2134</td>\n<td id=\"S3.T1.4.7.5.3\" class=\"ltx_td ltx_align_center\">55</td>\n<td id=\"S3.T1.4.7.5.4\" class=\"ltx_td ltx_align_center\">2189</td>\n<td id=\"S3.T1.4.7.5.5\" class=\"ltx_td ltx_align_center\">55</td>\n<td id=\"S3.T1.4.7.5.6\" class=\"ltx_td ltx_align_center\">2244</td>\n<td id=\"S3.T1.4.7.5.7\" class=\"ltx_td ltx_align_center\">43</td>\n</tr>\n<tr id=\"S3.T1.4.8.6\" class=\"ltx_tr\">\n<th id=\"S3.T1.4.8.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">Missouri</th>\n<td id=\"S3.T1.4.8.6.2\" class=\"ltx_td ltx_align_center\">2395</td>\n<td id=\"S3.T1.4.8.6.3\" class=\"ltx_td ltx_align_center\">18</td>\n<td id=\"S3.T1.4.8.6.4\" class=\"ltx_td ltx_align_center\">2413</td>\n<td id=\"S3.T1.4.8.6.5\" class=\"ltx_td ltx_align_center\">19</td>\n<td id=\"S3.T1.4.8.6.6\" class=\"ltx_td ltx_align_center\">2432</td>\n<td id=\"S3.T1.4.8.6.7\" class=\"ltx_td ltx_align_center\">15</td>\n</tr>\n<tr id=\"S3.T1.4.9.7\" class=\"ltx_tr\">\n<th id=\"S3.T1.4.9.7.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">Nebraska</th>\n<td id=\"S3.T1.4.9.7.2\" class=\"ltx_td ltx_align_center\">2274</td>\n<td id=\"S3.T1.4.9.7.3\" class=\"ltx_td ltx_align_center\">52</td>\n<td id=\"S3.T1.4.9.7.4\" class=\"ltx_td ltx_align_center\">2326</td>\n<td id=\"S3.T1.4.9.7.5\" class=\"ltx_td ltx_align_center\">43</td>\n<td id=\"S3.T1.4.9.7.6\" class=\"ltx_td ltx_align_center\">2369</td>\n<td id=\"S3.T1.4.9.7.7\" class=\"ltx_td ltx_align_center\">39</td>\n</tr>\n<tr id=\"S3.T1.4.10.8\" class=\"ltx_tr\">\n<th id=\"S3.T1.4.10.8.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">North dakota</th>\n<td id=\"S3.T1.4.10.8.2\" class=\"ltx_td ltx_align_center\">574</td>\n<td id=\"S3.T1.4.10.8.3\" class=\"ltx_td ltx_align_center\">12</td>\n<td id=\"S3.T1.4.10.8.4\" class=\"ltx_td ltx_align_center\">586</td>\n<td id=\"S3.T1.4.10.8.5\" class=\"ltx_td ltx_align_center\">12</td>\n<td id=\"S3.T1.4.10.8.6\" class=\"ltx_td ltx_align_center\">598</td>\n<td id=\"S3.T1.4.10.8.7\" class=\"ltx_td ltx_align_center\">12</td>\n</tr>\n<tr id=\"S3.T1.4.11.9\" class=\"ltx_tr\">\n<th id=\"S3.T1.4.11.9.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">South dakota</th>\n<td id=\"S3.T1.4.11.9.2\" class=\"ltx_td ltx_align_center\">1164</td>\n<td id=\"S3.T1.4.11.9.3\" class=\"ltx_td ltx_align_center\">22</td>\n<td id=\"S3.T1.4.11.9.4\" class=\"ltx_td ltx_align_center\">1186</td>\n<td id=\"S3.T1.4.11.9.5\" class=\"ltx_td ltx_align_center\">21</td>\n<td id=\"S3.T1.4.11.9.6\" class=\"ltx_td ltx_align_center\">1207</td>\n<td id=\"S3.T1.4.11.9.7\" class=\"ltx_td ltx_align_center\">20</td>\n</tr>\n<tr id=\"S3.T1.4.12.10\" class=\"ltx_tr\">\n<th id=\"S3.T1.4.12.10.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t\">Combined</th>\n<td id=\"S3.T1.4.12.10.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">19723</td>\n<td id=\"S3.T1.4.12.10.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">389</td>\n<td id=\"S3.T1.4.12.10.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">20112</td>\n<td id=\"S3.T1.4.12.10.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">385</td>\n<td id=\"S3.T1.4.12.10.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">20479</td>\n<td id=\"S3.T1.4.12.10.7\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">355</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "The soil data is uniform throughout the period for each county while the weather and management data change over time. The data is distributed into 9 silos, with each representing a corresponding state. After cleaning and data processing (following mostly same procedure as [28]), silos containing a wide range of samples are resulted as shown in Table 1. This imbalance in data distribution happens frequently in practical scenarios. Clients with a large training sample size account for a larger proportion of the overal training data, and it can reduce the accuracy of the minor clients [21]. Data augmentation [57] is a technique to increase the diversity of training data and reduce data imbalance issues. We applied random oversampling by making all silos equal in sample size. It does not cause any loss of information and alleviates the imbalance by replicating the minority samples more and majority samples less, resulting in equal distribution among the silos."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Settings tested in this experiment. The pruning rate denotes the percentage of weights pruned each time pruning is executed, and target sparsity represents the intended level of sparsity achieved at the end of training. Notably, the sparsity achieved by iterative pruning may slightly deviate from the target sparsity depending on the training performance.",
        "table": "<table id=\"S4.T2.4\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T2.4.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.4.1.1.1\" class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt\">\n<span id=\"S4.T2.4.1.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.1.1.1.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">Method</span></span>\n</span>\n</th>\n<th id=\"S4.T2.4.1.1.2\" class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt\">\n<span id=\"S4.T2.4.1.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.1.1.2.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.1.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">Centralized</span></span>\n</span>\n</th>\n<th id=\"S4.T2.4.1.1.3\" class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt\">\n<span id=\"S4.T2.4.1.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.1.1.3.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.1.1.3.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">Local only</span></span>\n</span>\n</th>\n<th id=\"S4.T2.4.1.1.4\" class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt\">\n<span id=\"S4.T2.4.1.1.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.1.1.4.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.1.1.4.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">FedAvg</span></span>\n</span>\n</th>\n<th id=\"S4.T2.4.1.1.5\" class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt\">\n<span id=\"S4.T2.4.1.1.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.1.1.5.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.1.1.5.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">FedPruning</span></span>\n</span>\n</th>\n<th id=\"S4.T2.4.1.1.6\" class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt\">\n<span id=\"S4.T2.4.1.1.6.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.1.1.6.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.1.1.6.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">FedPruning- LT</span></span>\n</span>\n</th>\n<th id=\"S4.T2.4.1.1.7\" class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt\">\n<span id=\"S4.T2.4.1.1.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.1.1.7.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.1.1.7.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">One-Shot</span></span>\n</span>\n</th>\n<th id=\"S4.T2.4.1.1.8\" class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt\">\n<span id=\"S4.T2.4.1.1.8.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.1.1.8.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.1.1.8.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:80%;\">One-Shot-LT</span></span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.4.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.4.2.1.1\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T2.4.2.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.2.1.1.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.2.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Rounds/ Local Epochs</span></span>\n</span>\n</td>\n<td id=\"S4.T2.4.2.1.2\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T2.4.2.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.2.1.2.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.2.1.2.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">1/300</span></span>\n</span>\n</td>\n<td id=\"S4.T2.4.2.1.3\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T2.4.2.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.2.1.3.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.2.1.3.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">1/300</span></span>\n</span>\n</td>\n<td id=\"S4.T2.4.2.1.4\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T2.4.2.1.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.2.1.4.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.2.1.4.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">40/5</span></span>\n</span>\n</td>\n<td id=\"S4.T2.4.2.1.5\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T2.4.2.1.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.2.1.5.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.2.1.5.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">40/6</span></span>\n</span>\n</td>\n<td id=\"S4.T2.4.2.1.6\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T2.4.2.1.6.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.2.1.6.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.2.1.6.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">40/8</span></span>\n</span>\n</td>\n<td id=\"S4.T2.4.2.1.7\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T2.4.2.1.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.2.1.7.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.2.1.7.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">40/5</span></span>\n</span>\n</td>\n<td id=\"S4.T2.4.2.1.8\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T2.4.2.1.8.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.2.1.8.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.2.1.8.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">40/5</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T2.4.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.4.3.2.1\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T2.4.3.2.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.3.2.1.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.3.2.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Learning Rates</span></span>\n</span>\n</td>\n<td id=\"S4.T2.4.3.2.2\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T2.4.3.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.3.2.2.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.3.2.2.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">5e-5, 1e-5, 0.2e-6</span></span>\n</span>\n</td>\n<td id=\"S4.T2.4.3.2.3\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T2.4.3.2.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.3.2.3.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.3.2.3.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">2e-5, 4e-6, 8e-7</span></span>\n</span>\n</td>\n<td id=\"S4.T2.4.3.2.4\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T2.4.3.2.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.3.2.4.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.3.2.4.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">2e-5, 4e-6, 8e-7</span></span>\n</span>\n</td>\n<td id=\"S4.T2.4.3.2.5\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T2.4.3.2.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.3.2.5.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.3.2.5.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">2e-5, 4e-6, 8e-7</span></span>\n</span>\n</td>\n<td id=\"S4.T2.4.3.2.6\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T2.4.3.2.6.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.3.2.6.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.3.2.6.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">2e-5, 2e-6, 4e-7</span></span>\n</span>\n</td>\n<td id=\"S4.T2.4.3.2.7\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T2.4.3.2.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.3.2.7.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.3.2.7.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">2e-5, 4e-6, 8e-7</span></span>\n</span>\n</td>\n<td id=\"S4.T2.4.3.2.8\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T2.4.3.2.8.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.3.2.8.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.3.2.8.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">1e-5, 2e-6, 4e-7</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T2.4.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.4.4.3.1\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T2.4.4.3.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.4.3.1.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.4.3.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Pruning Rate</span></span>\n</span>\n</td>\n<td id=\"S4.T2.4.4.3.2\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T2.4.4.3.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.4.3.2.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.4.3.2.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">0.0</span></span>\n</span>\n</td>\n<td id=\"S4.T2.4.4.3.3\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T2.4.4.3.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.4.3.3.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.4.3.3.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">0.0</span></span>\n</span>\n</td>\n<td id=\"S4.T2.4.4.3.4\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T2.4.4.3.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.4.3.4.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.4.3.4.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">0.0</span></span>\n</span>\n</td>\n<td id=\"S4.T2.4.4.3.5\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T2.4.4.3.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.4.3.5.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.4.3.5.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">0.25</span></span>\n</span>\n</td>\n<td id=\"S4.T2.4.4.3.6\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T2.4.4.3.6.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.4.3.6.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.4.3.6.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">0.415</span></span>\n</span>\n</td>\n<td id=\"S4.T2.4.4.3.7\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T2.4.4.3.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.4.3.7.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.4.3.7.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">0.70</span></span>\n</span>\n</td>\n<td id=\"S4.T2.4.4.3.8\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T2.4.4.3.8.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.4.3.8.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.4.3.8.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">0.70</span></span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T2.4.5.4\" class=\"ltx_tr\">\n<td id=\"S4.T2.4.5.4.1\" class=\"ltx_td ltx_align_justify ltx_border_bb ltx_border_t\">\n<span id=\"S4.T2.4.5.4.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.5.4.1.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.5.4.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Target Sparsity</span></span>\n</span>\n</td>\n<td id=\"S4.T2.4.5.4.2\" class=\"ltx_td ltx_align_justify ltx_border_bb ltx_border_t\">\n<span id=\"S4.T2.4.5.4.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.5.4.2.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.5.4.2.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">0.0</span></span>\n</span>\n</td>\n<td id=\"S4.T2.4.5.4.3\" class=\"ltx_td ltx_align_justify ltx_border_bb ltx_border_t\">\n<span id=\"S4.T2.4.5.4.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.5.4.3.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.5.4.3.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">0.0</span></span>\n</span>\n</td>\n<td id=\"S4.T2.4.5.4.4\" class=\"ltx_td ltx_align_justify ltx_border_bb ltx_border_t\">\n<span id=\"S4.T2.4.5.4.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.5.4.4.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.5.4.4.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">0.0</span></span>\n</span>\n</td>\n<td id=\"S4.T2.4.5.4.5\" class=\"ltx_td ltx_align_justify ltx_border_bb ltx_border_t\">\n<span id=\"S4.T2.4.5.4.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.5.4.5.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.5.4.5.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">0.80</span></span>\n</span>\n</td>\n<td id=\"S4.T2.4.5.4.6\" class=\"ltx_td ltx_align_justify ltx_border_bb ltx_border_t\">\n<span id=\"S4.T2.4.5.4.6.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.5.4.6.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.5.4.6.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">0.80</span></span>\n</span>\n</td>\n<td id=\"S4.T2.4.5.4.7\" class=\"ltx_td ltx_align_justify ltx_border_bb ltx_border_t\">\n<span id=\"S4.T2.4.5.4.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.5.4.7.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.5.4.7.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">0.70</span></span>\n</span>\n</td>\n<td id=\"S4.T2.4.5.4.8\" class=\"ltx_td ltx_align_justify ltx_border_bb ltx_border_t\">\n<span id=\"S4.T2.4.5.4.8.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T2.4.5.4.8.1.1\" class=\"ltx_p\"><span id=\"S4.T2.4.5.4.8.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">0.70</span></span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "For all methods, weights are initialized with the Kaiming method [22]. Adam optimizer is used with a learning rate decaying at round 5 and 10 by a factor of 0.2. L2 regularization can be used to enforce sparsity during training by encouraging smaller weights [18], and therefore we set a weight decay of 0.0001. For federated methods, the model is trained for a maximum of 40 communication rounds with 5-8 epochs trained locally. Local early-stopping is also used to prevent overfitting. Table 2 includes additional parameter settings used in this experiment."
        ]
    },
    "S4.T3": {
        "caption": "Table 3: RMSE(bushels per acre) of the 9 states trained using different training procedures. The values are recorded using the average of 3 runs each year with random initialization seeds. The final average sparsity for FedPruning and FedPruningLT are included in the bracket. The sparsity for one-shot and one-shot-LT are 0.7. ",
        "table": "<table id=\"S4.T3.4.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T3.4.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.4.1.1.1.1\" class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt\">\n<span id=\"S4.T3.4.1.1.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.1.1.1.1.1\" class=\"ltx_p\"><span id=\"S4.T3.4.1.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Year</span></span>\n</span>\n</th>\n<th id=\"S4.T3.4.1.1.1.2\" class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt\">\n<span id=\"S4.T3.4.1.1.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.1.1.2.1.1\" class=\"ltx_p\"><span id=\"S4.T3.4.1.1.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\">Centralized Baseline</span></span>\n</span>\n</th>\n<th id=\"S4.T3.4.1.1.1.3\" class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt\">\n<span id=\"S4.T3.4.1.1.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.1.1.3.1.1\" class=\"ltx_p\"><span id=\"S4.T3.4.1.1.1.3.1.1.1\" class=\"ltx_text ltx_font_bold\">Local Only</span></span>\n</span>\n</th>\n<th id=\"S4.T3.4.1.1.1.4\" class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt\">\n<span id=\"S4.T3.4.1.1.1.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.1.1.4.1.1\" class=\"ltx_p\"><span id=\"S4.T3.4.1.1.1.4.1.1.1\" class=\"ltx_text ltx_font_bold\">FedAvg</span></span>\n</span>\n</th>\n<th id=\"S4.T3.4.1.1.1.5\" class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt\">\n<span id=\"S4.T3.4.1.1.1.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.1.1.5.1.1\" class=\"ltx_p\"><span id=\"S4.T3.4.1.1.1.5.1.1.1\" class=\"ltx_text ltx_font_bold\">FedPruning</span></span>\n</span>\n</th>\n<th id=\"S4.T3.4.1.1.1.6\" class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt\">\n<span id=\"S4.T3.4.1.1.1.6.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.1.1.6.1.1\" class=\"ltx_p\"><span id=\"S4.T3.4.1.1.1.6.1.1.1\" class=\"ltx_text ltx_font_bold\">FedPruning -LT</span></span>\n</span>\n</th>\n<th id=\"S4.T3.4.1.1.1.7\" class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt\">\n<span id=\"S4.T3.4.1.1.1.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.1.1.7.1.1\" class=\"ltx_p\"><span id=\"S4.T3.4.1.1.1.7.1.1.1\" class=\"ltx_text ltx_font_bold\">One-shot</span></span>\n</span>\n</th>\n<th id=\"S4.T3.4.1.1.1.8\" class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt\">\n<span id=\"S4.T3.4.1.1.1.8.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.1.1.8.1.1\" class=\"ltx_p\"><span id=\"S4.T3.4.1.1.1.8.1.1.1\" class=\"ltx_text ltx_font_bold\">One-shot -LT</span></span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.4.1.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.1.2.1.1\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T3.4.1.2.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.2.1.1.1.1\" class=\"ltx_p\">2016</span>\n</span>\n</td>\n<td id=\"S4.T3.4.1.2.1.2\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T3.4.1.2.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.2.1.2.1.1\" class=\"ltx_p\">8.74</span>\n</span>\n</td>\n<td id=\"S4.T3.4.1.2.1.3\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T3.4.1.2.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.2.1.3.1.1\" class=\"ltx_p\">10.10</span>\n</span>\n</td>\n<td id=\"S4.T3.4.1.2.1.4\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T3.4.1.2.1.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.2.1.4.1.1\" class=\"ltx_p\">9.70</span>\n</span>\n</td>\n<td id=\"S4.T3.4.1.2.1.5\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T3.4.1.2.1.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.2.1.5.1.1\" class=\"ltx_p\">8.87 (0.75)</span>\n</span>\n</td>\n<td id=\"S4.T3.4.1.2.1.6\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T3.4.1.2.1.6.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.2.1.6.1.1\" class=\"ltx_p\">9.52 (0.73)</span>\n</span>\n</td>\n<td id=\"S4.T3.4.1.2.1.7\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T3.4.1.2.1.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.2.1.7.1.1\" class=\"ltx_p\">8.50</span>\n</span>\n</td>\n<td id=\"S4.T3.4.1.2.1.8\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T3.4.1.2.1.8.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.2.1.8.1.1\" class=\"ltx_p\">8.39</span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T3.4.1.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.1.3.2.1\" class=\"ltx_td ltx_align_justify\">\n<span id=\"S4.T3.4.1.3.2.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.3.2.1.1.1\" class=\"ltx_p\">2017</span>\n</span>\n</td>\n<td id=\"S4.T3.4.1.3.2.2\" class=\"ltx_td ltx_align_justify\">\n<span id=\"S4.T3.4.1.3.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.3.2.2.1.1\" class=\"ltx_p\">6.04</span>\n</span>\n</td>\n<td id=\"S4.T3.4.1.3.2.3\" class=\"ltx_td ltx_align_justify\">\n<span id=\"S4.T3.4.1.3.2.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.3.2.3.1.1\" class=\"ltx_p\">7.46</span>\n</span>\n</td>\n<td id=\"S4.T3.4.1.3.2.4\" class=\"ltx_td ltx_align_justify\">\n<span id=\"S4.T3.4.1.3.2.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.3.2.4.1.1\" class=\"ltx_p\">6.53</span>\n</span>\n</td>\n<td id=\"S4.T3.4.1.3.2.5\" class=\"ltx_td ltx_align_justify\">\n<span id=\"S4.T3.4.1.3.2.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.3.2.5.1.1\" class=\"ltx_p\">5.02 (0.84)</span>\n</span>\n</td>\n<td id=\"S4.T3.4.1.3.2.6\" class=\"ltx_td ltx_align_justify\">\n<span id=\"S4.T3.4.1.3.2.6.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.3.2.6.1.1\" class=\"ltx_p\">5.24 (0.76)</span>\n</span>\n</td>\n<td id=\"S4.T3.4.1.3.2.7\" class=\"ltx_td ltx_align_justify\">\n<span id=\"S4.T3.4.1.3.2.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.3.2.7.1.1\" class=\"ltx_p\">5.54</span>\n</span>\n</td>\n<td id=\"S4.T3.4.1.3.2.8\" class=\"ltx_td ltx_align_justify\">\n<span id=\"S4.T3.4.1.3.2.8.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.3.2.8.1.1\" class=\"ltx_p\">4.85</span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T3.4.1.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.1.4.3.1\" class=\"ltx_td ltx_align_justify\">\n<span id=\"S4.T3.4.1.4.3.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.4.3.1.1.1\" class=\"ltx_p\">2018</span>\n</span>\n</td>\n<td id=\"S4.T3.4.1.4.3.2\" class=\"ltx_td ltx_align_justify\">\n<span id=\"S4.T3.4.1.4.3.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.4.3.2.1.1\" class=\"ltx_p\">5.83</span>\n</span>\n</td>\n<td id=\"S4.T3.4.1.4.3.3\" class=\"ltx_td ltx_align_justify\">\n<span id=\"S4.T3.4.1.4.3.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.4.3.3.1.1\" class=\"ltx_p\">7.96</span>\n</span>\n</td>\n<td id=\"S4.T3.4.1.4.3.4\" class=\"ltx_td ltx_align_justify\">\n<span id=\"S4.T3.4.1.4.3.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.4.3.4.1.1\" class=\"ltx_p\">6.85</span>\n</span>\n</td>\n<td id=\"S4.T3.4.1.4.3.5\" class=\"ltx_td ltx_align_justify\">\n<span id=\"S4.T3.4.1.4.3.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.4.3.5.1.1\" class=\"ltx_p\">5.62 (0.78)</span>\n</span>\n</td>\n<td id=\"S4.T3.4.1.4.3.6\" class=\"ltx_td ltx_align_justify\">\n<span id=\"S4.T3.4.1.4.3.6.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.4.3.6.1.1\" class=\"ltx_p\">5.52 (0.76)</span>\n</span>\n</td>\n<td id=\"S4.T3.4.1.4.3.7\" class=\"ltx_td ltx_align_justify\">\n<span id=\"S4.T3.4.1.4.3.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.4.3.7.1.1\" class=\"ltx_p\">5.55</span>\n</span>\n</td>\n<td id=\"S4.T3.4.1.4.3.8\" class=\"ltx_td ltx_align_justify\">\n<span id=\"S4.T3.4.1.4.3.8.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.4.3.8.1.1\" class=\"ltx_p\">5.26</span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T3.4.1.5.4\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.1.5.4.1\" class=\"ltx_td ltx_align_justify\"></td>\n<td id=\"S4.T3.4.1.5.4.2\" class=\"ltx_td ltx_align_justify\"></td>\n<td id=\"S4.T3.4.1.5.4.3\" class=\"ltx_td ltx_align_justify\"></td>\n<td id=\"S4.T3.4.1.5.4.4\" class=\"ltx_td ltx_align_justify\"></td>\n<td id=\"S4.T3.4.1.5.4.5\" class=\"ltx_td ltx_align_justify\"></td>\n<td id=\"S4.T3.4.1.5.4.6\" class=\"ltx_td ltx_align_justify\"></td>\n<td id=\"S4.T3.4.1.5.4.7\" class=\"ltx_td ltx_align_justify\"></td>\n<td id=\"S4.T3.4.1.5.4.8\" class=\"ltx_td ltx_align_justify\"></td>\n</tr>\n<tr id=\"S4.T3.4.1.6.5\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.1.6.5.1\" class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span id=\"S4.T3.4.1.6.5.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.6.5.1.1.1\" class=\"ltx_p\">Average</span>\n</span>\n</td>\n<td id=\"S4.T3.4.1.6.5.2\" class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span id=\"S4.T3.4.1.6.5.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.6.5.2.1.1\" class=\"ltx_p\">6.87</span>\n</span>\n</td>\n<td id=\"S4.T3.4.1.6.5.3\" class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span id=\"S4.T3.4.1.6.5.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.6.5.3.1.1\" class=\"ltx_p\">8.84</span>\n</span>\n</td>\n<td id=\"S4.T3.4.1.6.5.4\" class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span id=\"S4.T3.4.1.6.5.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.6.5.4.1.1\" class=\"ltx_p\">7.69</span>\n</span>\n</td>\n<td id=\"S4.T3.4.1.6.5.5\" class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span id=\"S4.T3.4.1.6.5.5.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.6.5.5.1.1\" class=\"ltx_p\">6.50 (0.79)</span>\n</span>\n</td>\n<td id=\"S4.T3.4.1.6.5.6\" class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span id=\"S4.T3.4.1.6.5.6.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.6.5.6.1.1\" class=\"ltx_p\">6.75 (0.75)</span>\n</span>\n</td>\n<td id=\"S4.T3.4.1.6.5.7\" class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span id=\"S4.T3.4.1.6.5.7.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.6.5.7.1.1\" class=\"ltx_p\">6.53</span>\n</span>\n</td>\n<td id=\"S4.T3.4.1.6.5.8\" class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span id=\"S4.T3.4.1.6.5.8.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T3.4.1.6.5.8.1.1\" class=\"ltx_p\">6.17</span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "The centralized baseline pools all training and testing data together, and demonstrates a commensurate level of inference performance when compared to the DFNN model from the previous study [28]. We find that the local models, which only use data from their respective silos, exhibit poor performance compared to the centralized baseline, as indicated in Table 3. This is expected as the local clients have limited training data. FedAvg addresses the data limitation by leveraging all data from all silos via aggregation and model updates. We evaluate the performance of FedAvg using the global model directly following the aggregation. Our findings indicate that FedAvg outperforms the local models for all years by approximately 10.5%. Nevertheless, FedAvg still falls short of the centralized models in terms of performance."
        ]
    },
    "S4.T4": {
        "caption": "Table 4: Communication cost and size of an average client model during the FL process. The values are recorded using the average of 3 years, with 3 runs per year with random initialization seeds. ",
        "table": "<table id=\"S4.T4.4\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T4.4.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T4.4.1.1.1\" class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt\">\n<span id=\"S4.T4.4.1.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T4.4.1.1.1.1.1\" class=\"ltx_p\"><span id=\"S4.T4.4.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></span>\n</span>\n</th>\n<th id=\"S4.T4.4.1.1.2\" class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt\">\n<span id=\"S4.T4.4.1.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T4.4.1.1.2.1.1\" class=\"ltx_p\"><span id=\"S4.T4.4.1.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\">Communication Cost (MB)</span></span>\n</span>\n</th>\n<th id=\"S4.T4.4.1.1.3\" class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt\">\n<span id=\"S4.T4.4.1.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T4.4.1.1.3.1.1\" class=\"ltx_p\"><span id=\"S4.T4.4.1.1.3.1.1.1\" class=\"ltx_text ltx_font_bold\">Communication Saved (%)</span></span>\n</span>\n</th>\n<th id=\"S4.T4.4.1.1.4\" class=\"ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt\">\n<span id=\"S4.T4.4.1.1.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T4.4.1.1.4.1.1\" class=\"ltx_p\"><span id=\"S4.T4.4.1.1.4.1.1.1\" class=\"ltx_text ltx_font_bold\">Client Model Size (KB)</span></span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T4.4.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T4.4.2.1.1\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T4.4.2.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T4.4.2.1.1.1.1\" class=\"ltx_p\">FedAvg</span>\n</span>\n</td>\n<td id=\"S4.T4.4.2.1.2\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T4.4.2.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T4.4.2.1.2.1.1\" class=\"ltx_p\">50.76</span>\n</span>\n</td>\n<td id=\"S4.T4.4.2.1.3\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T4.4.2.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T4.4.2.1.3.1.1\" class=\"ltx_p\">0</span>\n</span>\n</td>\n<td id=\"S4.T4.4.2.1.4\" class=\"ltx_td ltx_align_justify ltx_border_t\">\n<span id=\"S4.T4.4.2.1.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T4.4.2.1.4.1.1\" class=\"ltx_p\">634.64</span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T4.4.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T4.4.3.2.1\" class=\"ltx_td ltx_align_justify\">\n<span id=\"S4.T4.4.3.2.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T4.4.3.2.1.1.1\" class=\"ltx_p\">FedPruning</span>\n</span>\n</td>\n<td id=\"S4.T4.4.3.2.2\" class=\"ltx_td ltx_align_justify\">\n<span id=\"S4.T4.4.3.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T4.4.3.2.2.1.1\" class=\"ltx_p\">21.78</span>\n</span>\n</td>\n<td id=\"S4.T4.4.3.2.3\" class=\"ltx_td ltx_align_justify\">\n<span id=\"S4.T4.4.3.2.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T4.4.3.2.3.1.1\" class=\"ltx_p\">57.1</span>\n</span>\n</td>\n<td id=\"S4.T4.4.3.2.4\" class=\"ltx_td ltx_align_justify\">\n<span id=\"S4.T4.4.3.2.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T4.4.3.2.4.1.1\" class=\"ltx_p\">133.27</span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T4.4.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T4.4.4.3.1\" class=\"ltx_td ltx_align_justify\">\n<span id=\"S4.T4.4.4.3.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T4.4.4.3.1.1.1\" class=\"ltx_p\">FedPruning-LT</span>\n</span>\n</td>\n<td id=\"S4.T4.4.4.3.2\" class=\"ltx_td ltx_align_justify\">\n<span id=\"S4.T4.4.4.3.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T4.4.4.3.2.1.1\" class=\"ltx_p\">20.96</span>\n</span>\n</td>\n<td id=\"S4.T4.4.4.3.3\" class=\"ltx_td ltx_align_justify\">\n<span id=\"S4.T4.4.4.3.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T4.4.4.3.3.1.1\" class=\"ltx_p\">58.7</span>\n</span>\n</td>\n<td id=\"S4.T4.4.4.3.4\" class=\"ltx_td ltx_align_justify\">\n<span id=\"S4.T4.4.4.3.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T4.4.4.3.4.1.1\" class=\"ltx_p\">158.66</span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T4.4.5.4\" class=\"ltx_tr\">\n<td id=\"S4.T4.4.5.4.1\" class=\"ltx_td ltx_align_justify\">\n<span id=\"S4.T4.4.5.4.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T4.4.5.4.1.1.1\" class=\"ltx_p\">One-Shot</span>\n</span>\n</td>\n<td id=\"S4.T4.4.5.4.2\" class=\"ltx_td ltx_align_justify\">\n<span id=\"S4.T4.4.5.4.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T4.4.5.4.2.1.1\" class=\"ltx_p\">17.92</span>\n</span>\n</td>\n<td id=\"S4.T4.4.5.4.3\" class=\"ltx_td ltx_align_justify\">\n<span id=\"S4.T4.4.5.4.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T4.4.5.4.3.1.1\" class=\"ltx_p\">64.7</span>\n</span>\n</td>\n<td id=\"S4.T4.4.5.4.4\" class=\"ltx_td ltx_align_justify\">\n<span id=\"S4.T4.4.5.4.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T4.4.5.4.4.1.1\" class=\"ltx_p\">196.95</span>\n</span>\n</td>\n</tr>\n<tr id=\"S4.T4.4.6.5\" class=\"ltx_tr\">\n<td id=\"S4.T4.4.6.5.1\" class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span id=\"S4.T4.4.6.5.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T4.4.6.5.1.1.1\" class=\"ltx_p\">One-Shot-LT</span>\n</span>\n</td>\n<td id=\"S4.T4.4.6.5.2\" class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span id=\"S4.T4.4.6.5.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T4.4.6.5.2.1.1\" class=\"ltx_p\">17.92</span>\n</span>\n</td>\n<td id=\"S4.T4.4.6.5.3\" class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span id=\"S4.T4.4.6.5.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T4.4.6.5.3.1.1\" class=\"ltx_p\">64.7</span>\n</span>\n</td>\n<td id=\"S4.T4.4.6.5.4\" class=\"ltx_td ltx_align_justify ltx_border_bb\">\n<span id=\"S4.T4.4.6.5.4.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S4.T4.4.6.5.4.1.1\" class=\"ltx_p\">196.95</span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "The centralized baseline pools all training and testing data together, and demonstrates a commensurate level of inference performance when compared to the DFNN model from the previous study ",
                "[",
                "28",
                "]",
                ". We find that the local models, which only use data from their respective silos, exhibit poor performance compared to the centralized baseline, as indicated in Table ",
                "3",
                ". This is expected as the local clients have limited training data. FedAvg addresses the data limitation by leveraging all data from all silos via aggregation and model updates. We evaluate the performance of FedAvg using the global model directly following the aggregation. Our findings indicate that FedAvg outperforms the local models for all years by approximately 10.5%. Nevertheless, FedAvg still falls short of the centralized models in terms of performance.",
                "Since FedPruning produces different, localized models for each client, we evaluate the individual client models instead of the global model like we do with FedAvg. Therefore, to evaluate the performance of FedPruning - both with iterative and one-shot pruning, with and without LTH, we assess the inference performance using local test data from each silo at the end of local training. The most direct way for the method to be demonstrably useful is for it to be a drop-in replacement for FedAvg - that is it must be able to reach the inference performance no worse than FedAvg on all clients on average, and result in fewer parameters within a specific number of communication rounds. Symbolically, ",
                "‚Ñí",
                "‚Äã",
                "(",
                "ùíú",
                "fp",
                "0",
                "‚Üí",
                "T",
                "‚Äã",
                "(",
                "Œ∏",
                "p",
                ")",
                ")",
                "‚â§",
                "‚Ñí",
                "‚Äã",
                "(",
                "ùíú",
                "fa",
                "0",
                "‚Üí",
                "T",
                "‚Äã",
                "(",
                "Œ∏",
                ")",
                ")",
                "‚Ñí",
                "superscript",
                "subscript",
                "ùíú",
                "fp",
                "‚Üí",
                "0",
                "ùëá",
                "subscript",
                "ùúÉ",
                "ùëù",
                "‚Ñí",
                "superscript",
                "subscript",
                "ùíú",
                "fa",
                "‚Üí",
                "0",
                "ùëá",
                "ùúÉ",
                "\\mathcal{L}(\\mathscr{A}_{\\text{fp}}^{0\\rightarrow T}(\\theta_{p}))\\leq\\mathcal{L}(\\mathscr{A}_{\\text{fa}}^{0\\rightarrow T}(\\theta))",
                " and ",
                "|",
                "Œ∏",
                "p",
                "|",
                "<",
                "|",
                "Œ∏",
                "|",
                "subscript",
                "ùúÉ",
                "ùëù",
                "ùúÉ",
                "|\\theta_{p}|<|\\theta|",
                ", where ",
                "|",
                "Œ∏",
                "p",
                "|",
                "subscript",
                "ùúÉ",
                "ùëù",
                "|\\theta_{p}|",
                " and ",
                "|",
                "Œ∏",
                "|",
                "ùúÉ",
                "|\\theta|",
                " are the numbers of parameters in pruned and unpruned models respectively, ",
                "‚Ñí",
                "‚Ñí",
                "\\mathcal{L}",
                " is the average loss across all clients, ",
                "ùíú",
                "fp",
                "x",
                "‚Üí",
                "y",
                "superscript",
                "subscript",
                "ùíú",
                "fp",
                "‚Üí",
                "ùë•",
                "ùë¶",
                "\\mathscr{A}_{\\text{fp}}^{x\\rightarrow y}",
                " and ",
                "ùíú",
                "fp",
                "x",
                "‚Üí",
                "y",
                "superscript",
                "subscript",
                "ùíú",
                "fp",
                "‚Üí",
                "ùë•",
                "ùë¶",
                "\\mathscr{A}_{\\text{fp}}^{x\\rightarrow y}",
                " are the FedPruning and FedAvg procedure for training from round x to round y, and T is the final round.",
                "Assessing the inference performance of local models.",
                " The results indicate that FedPruning under all four settings significantly outperform FedAvg, with performance improvements ranging between 15.5% to 19.8%. The iterative pruning methods FedPruning and FedPruning-LT outperform the centralized baseline for 2017 and 2018, while exhibiting slightly inferior performance for 2016. Overall, these methods demonstrate comparable inference performance to the centralized baseline. One-shot surprisingly shows a similar performance compared to its iterative counterpart, despite being slightly less pruned. However, when LTH is applied to one-shot, it shows a small but noticeable increase in performance across all years, amounting to a 5.5% improvement overall. We also make the observation that these variations collectively are on par with the centralized baseline or even marginally outperform it. One-shot-LT shows the biggest difference by approximately 10%.",
                "Figure ",
                "4",
                " shows how the pruning approaches perform in terms of RMSE and sparsity over 40 communication rounds. It is observed that FedPruning and One-shot (left graph) have a narrower client RMSE range than FedAvg, with the upper bound of client RMSE being lower. Additionally, FedPruning exceeds the final performance at a lower sparsity (approximately ",
                "P",
                "m",
                "=",
                "30",
                "%",
                "subscript",
                "ùëÉ",
                "ùëö",
                "percent",
                "30",
                "P_{m}=30\\%",
                " - 60%) and decreases slightly as we prune, forming Occam‚Äôs Hill, which suggests that if the model is either too simple or too complex, performance on an independent test set will suffer ",
                "[",
                "49",
                "]",
                ". FedPruning-LT (right graph) prunes more each time but fewer times in total. We tested it with the same schedule as FedPruning, and observed that when client models are pruned before they recover, they may permanently lose the performance. This not only affects itself, but also other clients since some of their weights are shared. We also find that the overall performance may be better when the clients are pruned and recover together, as opposed to independently. The RMSE spikes on the graph indicate the impact of weight reset after pruning, and we allow them to recover fully before the next pruning round. Despite the effort, it does not appear to match the performance of FedPruning and One-Shot-LT. One-Shot-LT on the other hand, although simpler to implement, consistently shows superior performance compared to both one-shot and FedPruning-LT.",
                "Assessing the cost of communication and size of model.",
                " The measurement of communication costs is commonly based on the magnitude of data volume transmitted between clients and server. It is influenced by two distinct factors. Firstly, the sparsity of a model, which affects its compression ratio during communication, plays a significant role in determining the quantity of data transmitted. Sparse models, being inherently smaller in size, require less communication cost to transmit as compared to larger models. Secondly, the timing of model pruning also significantly affects the communication cost. The earlier a model is pruned, the greater the amount of communication cost that can be saved in the long run. This can be visualized in Figure ",
                "4",
                ". Specifically, it depicts the data consumption patterns of the iterative and one-shot approaches. As per the figure, client models that prune iteratively consume a relatively greater amount of communication cost initially and gradually reduce it as they become smaller. In contrast, one-shot approaches prune in one go and achieve a steady reduction in communication cost. All pruning methods have demonstrated the ability to effectively reduce model size while preserving inference performance. Notably, one-shot pruning methods have been observed to achieve a size reduction of 3.22X, while FedPruning and FedPruning-LT have reduced model size by 4.76X and 4X, respectively."
            ]
        ]
    }
}