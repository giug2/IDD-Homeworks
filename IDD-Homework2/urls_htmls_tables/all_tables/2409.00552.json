{
    "S2.F1.2": {
        "caption": [],
        "table": "<table id=\"S2.F1.2\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S2.F1.2.2\" class=\"ltx_tr\">\n<td id=\"S2.F1.1.1.1\" class=\"ltx_td ltx_align_center\"><img src=\"/html/2409.00552/assets/figures/visual_net_v2.png\" id=\"S2.F1.1.1.1.g1\" class=\"ltx_graphics ltx_img_landscape\" width=\"487\" height=\"358\" alt=\"Refer to caption\"></td>\n<td id=\"S2.F1.2.2.2\" class=\"ltx_td ltx_align_center\"><img src=\"/html/2409.00552/assets/figures/audio_net_v2.png\" id=\"S2.F1.2.2.2.g1\" class=\"ltx_graphics ltx_img_landscape\" width=\"549\" height=\"279\" alt=\"Refer to caption\"></td>\n</tr>\n<tr id=\"S2.F1.2.3.1\" class=\"ltx_tr\">\n<td id=\"S2.F1.2.3.1.1\" class=\"ltx_td ltx_align_center\"><span id=\"S2.F1.2.3.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">a) Visual input (N-MNIST)</span></td>\n<td id=\"S2.F1.2.3.1.2\" class=\"ltx_td ltx_align_center\"><span id=\"S2.F1.2.3.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">b) Auditory input (SHD)</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "While most work investigating SNNs has focused on singular modalities, such as digit recognition using either auditory or visual datasets (Fig.¬†1), fewer studies have explored multimodal SNN models. The exploration of multimodal models is particularly relevant when dealing with noisy or incomplete data in one modality, where cross-modal integration can enhance the robustness and overall performance of the system. For example, [6] investigated an attention-based cross-modal subnetwork that assigns attention scores in both auditory and visual branches. These scores are adjusted based on the quality of the input, with the branches being concatenated right before classification. This approach is valuable for situations where one of the input modalities is noisy, ensuring the model can still perform effectively.",
            "The unimodal networks are generic MLP SNNs with increasingly compressed fully-connected layers moving forward through the network, and culminating in ten cumulative potential sum neurons on the output layer (Fig.¬†1). These networks are implemented using a SNN Pytorch toolkit presented in [12]."
        ]
    }
}{
    "S3.T1.1": {
        "caption": [],
        "table": "<table id=\"S3.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row\"><span id=\"S3.T1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></th>\n<th id=\"S3.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S3.T1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Dataset</span></th>\n<th id=\"S3.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S3.T1.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Accuracy (%)</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\">RSNN w/ Adaptation <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib12\" title=\"\" class=\"ltx_ref\">12</a>]</cite>\n</th>\n<td id=\"S3.T1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">SHD</td>\n<td id=\"S3.T1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">94.6</td>\n</tr>\n<tr id=\"S3.T1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Feed-forward SNN with STFs &amp; attention <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib13\" title=\"\" class=\"ltx_ref\">13</a>]</cite>\n</th>\n<td id=\"S3.T1.1.3.2.2\" class=\"ltx_td ltx_align_center\">SHD</td>\n<td id=\"S3.T1.1.3.2.3\" class=\"ltx_td ltx_align_center\">92.4</td>\n</tr>\n<tr id=\"S3.T1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Unsupervised STDP <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib14\" title=\"\" class=\"ltx_ref\">14</a>]</cite>\n</th>\n<td id=\"S3.T1.1.4.3.2\" class=\"ltx_td ltx_align_center\">N-MNIST</td>\n<td id=\"S3.T1.1.4.3.3\" class=\"ltx_td ltx_align_center\">80.63</td>\n</tr>\n<tr id=\"S3.T1.1.5.4\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Back Propagation <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib15\" title=\"\" class=\"ltx_ref\">15</a>]</cite>\n</th>\n<td id=\"S3.T1.1.5.4.2\" class=\"ltx_td ltx_align_center\">N-MNIST</td>\n<td id=\"S3.T1.1.5.4.3\" class=\"ltx_td ltx_align_center\">98.66</td>\n</tr>\n<tr id=\"S3.T1.1.6.5\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Attention Mechanism* <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib6\" title=\"\" class=\"ltx_ref\">6</a>]</cite>\n</th>\n<td id=\"S3.T1.1.6.5.2\" class=\"ltx_td ltx_align_center\">MNIST-DVS + TIDIGITS</td>\n<td id=\"S3.T1.1.6.5.3\" class=\"ltx_td ltx_align_center\">98.95</td>\n</tr>\n<tr id=\"S3.T1.1.7.6\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.7.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">This work: Visual Only</th>\n<td id=\"S3.T1.1.7.6.2\" class=\"ltx_td ltx_align_center ltx_border_t\">N-MNIST</td>\n<td id=\"S3.T1.1.7.6.3\" class=\"ltx_td ltx_align_center ltx_border_t\">92.25</td>\n</tr>\n<tr id=\"S3.T1.1.8.7\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.8.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">This work: Auditory Only</th>\n<td id=\"S3.T1.1.8.7.2\" class=\"ltx_td ltx_align_center\">SHD</td>\n<td id=\"S3.T1.1.8.7.3\" class=\"ltx_td ltx_align_center\">95.29</td>\n</tr>\n<tr id=\"S3.T1.1.9.8\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.9.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">This work: Early Fusion*</th>\n<td id=\"S3.T1.1.9.8.2\" class=\"ltx_td ltx_align_center\">N-MNIST + SHD</td>\n<td id=\"S3.T1.1.9.8.3\" class=\"ltx_td ltx_align_center\">97.35</td>\n</tr>\n<tr id=\"S3.T1.1.10.9\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.10.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">This work: Middle Fusion*</th>\n<td id=\"S3.T1.1.10.9.2\" class=\"ltx_td ltx_align_center\">N-MNIST + SHD</td>\n<td id=\"S3.T1.1.10.9.3\" class=\"ltx_td ltx_align_center\">97.45</td>\n</tr>\n<tr id=\"S3.T1.1.11.10\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.11.10.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">This work: Late Fusion*</th>\n<td id=\"S3.T1.1.11.10.2\" class=\"ltx_td ltx_align_center\">N-MNIST + SHD</td>\n<td id=\"S3.T1.1.11.10.3\" class=\"ltx_td ltx_align_center\">98.43</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "Displayed in Table¬†I, our multimodal networks achieve an average test accuracy of 97.74% at convergence, with our late-concatenation model scoring the highest accuracy of 98.43%. The accuracy between each multimodal model are somewhat similar, all within about one percent. A McNemar test was performed between each model pairing using the test data with a desired hypothesis confidence of 95% (pùëùp-value = 0.05). That is, a rejection of the null hypothesis indicates that the models have significantly different classification output with 95% confidence. Experiment 1 in Table¬†II shows that our early branch concatenation multimodal SNN model performs statistically different than both the unimodal visual and unimodal auditory models (p<0.001ùëù0.001p<0.001). Therefore the null hypothesis is rejected, meaning our multimodal SNN model has a statistically better performance than each of the unimodal models. Both unimodal models perform similarly to one another according to a McNemar test (p>0.1ùëù0.1p>0.1). Our multimodal SNN models perform significantly better compared to both of our unimodal SNN models."
        ]
    }
}{
    "S4.T2.7": {
        "caption": [],
        "table": "<table id=\"S4.T2.7\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.1.2\" class=\"ltx_td\"></td>\n<th id=\"S4.T2.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Model 1</th>\n<th id=\"S4.T2.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">Model 2</th>\n<th id=\"S4.T2.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">\n<math id=\"S4.T2.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"p\" display=\"inline\"><semantics id=\"S4.T2.1.1.1.m1.1a\"><mi id=\"S4.T2.1.1.1.m1.1.1\" xref=\"S4.T2.1.1.1.m1.1.1.cmml\">p</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.1.1.1.m1.1b\"><ci id=\"S4.T2.1.1.1.m1.1.1.cmml\" xref=\"S4.T2.1.1.1.m1.1.1\">ùëù</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.1.1.1.m1.1c\">p</annotation></semantics></math>-value</th>\n<td id=\"S4.T2.1.1.5\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S4.T2.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">Experiment 1</td>\n<td id=\"S4.T2.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">MM Early</td>\n<td id=\"S4.T2.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">UM Visual</td>\n<td id=\"S4.T2.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><math id=\"S4.T2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"p&lt;0.01\" display=\"inline\"><semantics id=\"S4.T2.2.2.1.m1.1a\"><mrow id=\"S4.T2.2.2.1.m1.1.1\" xref=\"S4.T2.2.2.1.m1.1.1.cmml\"><mi id=\"S4.T2.2.2.1.m1.1.1.2\" xref=\"S4.T2.2.2.1.m1.1.1.2.cmml\">p</mi><mo id=\"S4.T2.2.2.1.m1.1.1.1\" xref=\"S4.T2.2.2.1.m1.1.1.1.cmml\">&lt;</mo><mn id=\"S4.T2.2.2.1.m1.1.1.3\" xref=\"S4.T2.2.2.1.m1.1.1.3.cmml\">0.01</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.2.2.1.m1.1b\"><apply id=\"S4.T2.2.2.1.m1.1.1.cmml\" xref=\"S4.T2.2.2.1.m1.1.1\"><lt id=\"S4.T2.2.2.1.m1.1.1.1.cmml\" xref=\"S4.T2.2.2.1.m1.1.1.1\"></lt><ci id=\"S4.T2.2.2.1.m1.1.1.2.cmml\" xref=\"S4.T2.2.2.1.m1.1.1.2\">ùëù</ci><cn type=\"float\" id=\"S4.T2.2.2.1.m1.1.1.3.cmml\" xref=\"S4.T2.2.2.1.m1.1.1.3\">0.01</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.2.2.1.m1.1c\">p&lt;0.01</annotation></semantics></math></td>\n<td id=\"S4.T2.2.2.5\" class=\"ltx_td ltx_border_t\"></td>\n</tr>\n<tr id=\"S4.T2.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.3.2\" class=\"ltx_td\"></td>\n<td id=\"S4.T2.3.3.3\" class=\"ltx_td ltx_align_center\">MM Early</td>\n<td id=\"S4.T2.3.3.4\" class=\"ltx_td ltx_align_center\">UM Auditory</td>\n<td id=\"S4.T2.3.3.1\" class=\"ltx_td ltx_align_center\"><math id=\"S4.T2.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"p&lt;0.01\" display=\"inline\"><semantics id=\"S4.T2.3.3.1.m1.1a\"><mrow id=\"S4.T2.3.3.1.m1.1.1\" xref=\"S4.T2.3.3.1.m1.1.1.cmml\"><mi id=\"S4.T2.3.3.1.m1.1.1.2\" xref=\"S4.T2.3.3.1.m1.1.1.2.cmml\">p</mi><mo id=\"S4.T2.3.3.1.m1.1.1.1\" xref=\"S4.T2.3.3.1.m1.1.1.1.cmml\">&lt;</mo><mn id=\"S4.T2.3.3.1.m1.1.1.3\" xref=\"S4.T2.3.3.1.m1.1.1.3.cmml\">0.01</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.3.3.1.m1.1b\"><apply id=\"S4.T2.3.3.1.m1.1.1.cmml\" xref=\"S4.T2.3.3.1.m1.1.1\"><lt id=\"S4.T2.3.3.1.m1.1.1.1.cmml\" xref=\"S4.T2.3.3.1.m1.1.1.1\"></lt><ci id=\"S4.T2.3.3.1.m1.1.1.2.cmml\" xref=\"S4.T2.3.3.1.m1.1.1.2\">ùëù</ci><cn type=\"float\" id=\"S4.T2.3.3.1.m1.1.1.3.cmml\" xref=\"S4.T2.3.3.1.m1.1.1.3\">0.01</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.3.3.1.m1.1c\">p&lt;0.01</annotation></semantics></math></td>\n<td id=\"S4.T2.3.3.5\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S4.T2.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T2.4.4.2\" class=\"ltx_td\"></td>\n<td id=\"S4.T2.4.4.3\" class=\"ltx_td ltx_align_center\">UM Visual</td>\n<td id=\"S4.T2.4.4.4\" class=\"ltx_td ltx_align_center\">UM auditory</td>\n<td id=\"S4.T2.4.4.1\" class=\"ltx_td ltx_align_center\"><math id=\"S4.T2.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"p=0.241\" display=\"inline\"><semantics id=\"S4.T2.4.4.1.m1.1a\"><mrow id=\"S4.T2.4.4.1.m1.1.1\" xref=\"S4.T2.4.4.1.m1.1.1.cmml\"><mi id=\"S4.T2.4.4.1.m1.1.1.2\" xref=\"S4.T2.4.4.1.m1.1.1.2.cmml\">p</mi><mo id=\"S4.T2.4.4.1.m1.1.1.1\" xref=\"S4.T2.4.4.1.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T2.4.4.1.m1.1.1.3\" xref=\"S4.T2.4.4.1.m1.1.1.3.cmml\">0.241</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.4.4.1.m1.1b\"><apply id=\"S4.T2.4.4.1.m1.1.1.cmml\" xref=\"S4.T2.4.4.1.m1.1.1\"><eq id=\"S4.T2.4.4.1.m1.1.1.1.cmml\" xref=\"S4.T2.4.4.1.m1.1.1.1\"></eq><ci id=\"S4.T2.4.4.1.m1.1.1.2.cmml\" xref=\"S4.T2.4.4.1.m1.1.1.2\">ùëù</ci><cn type=\"float\" id=\"S4.T2.4.4.1.m1.1.1.3.cmml\" xref=\"S4.T2.4.4.1.m1.1.1.3\">0.241</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.4.4.1.m1.1c\">p=0.241</annotation></semantics></math></td>\n<td id=\"S4.T2.4.4.5\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S4.T2.5.5\" class=\"ltx_tr\">\n<td id=\"S4.T2.5.5.2\" class=\"ltx_td ltx_align_left\">Experiment 2</td>\n<td id=\"S4.T2.5.5.3\" class=\"ltx_td ltx_align_center\">MM Early</td>\n<td id=\"S4.T2.5.5.4\" class=\"ltx_td ltx_align_center\">MM Middle</td>\n<td id=\"S4.T2.5.5.1\" class=\"ltx_td ltx_align_center\"><math id=\"S4.T2.5.5.1.m1.1\" class=\"ltx_Math\" alttext=\"p=0.473\" display=\"inline\"><semantics id=\"S4.T2.5.5.1.m1.1a\"><mrow id=\"S4.T2.5.5.1.m1.1.1\" xref=\"S4.T2.5.5.1.m1.1.1.cmml\"><mi id=\"S4.T2.5.5.1.m1.1.1.2\" xref=\"S4.T2.5.5.1.m1.1.1.2.cmml\">p</mi><mo id=\"S4.T2.5.5.1.m1.1.1.1\" xref=\"S4.T2.5.5.1.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T2.5.5.1.m1.1.1.3\" xref=\"S4.T2.5.5.1.m1.1.1.3.cmml\">0.473</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.5.5.1.m1.1b\"><apply id=\"S4.T2.5.5.1.m1.1.1.cmml\" xref=\"S4.T2.5.5.1.m1.1.1\"><eq id=\"S4.T2.5.5.1.m1.1.1.1.cmml\" xref=\"S4.T2.5.5.1.m1.1.1.1\"></eq><ci id=\"S4.T2.5.5.1.m1.1.1.2.cmml\" xref=\"S4.T2.5.5.1.m1.1.1.2\">ùëù</ci><cn type=\"float\" id=\"S4.T2.5.5.1.m1.1.1.3.cmml\" xref=\"S4.T2.5.5.1.m1.1.1.3\">0.473</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.5.5.1.m1.1c\">p=0.473</annotation></semantics></math></td>\n<td id=\"S4.T2.5.5.5\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S4.T2.6.6\" class=\"ltx_tr\">\n<td id=\"S4.T2.6.6.2\" class=\"ltx_td\"></td>\n<td id=\"S4.T2.6.6.3\" class=\"ltx_td ltx_align_center\">MM Early</td>\n<td id=\"S4.T2.6.6.4\" class=\"ltx_td ltx_align_center\">MM Late</td>\n<td id=\"S4.T2.6.6.1\" class=\"ltx_td ltx_align_center\"><math id=\"S4.T2.6.6.1.m1.1\" class=\"ltx_Math\" alttext=\"p=1.00\" display=\"inline\"><semantics id=\"S4.T2.6.6.1.m1.1a\"><mrow id=\"S4.T2.6.6.1.m1.1.1\" xref=\"S4.T2.6.6.1.m1.1.1.cmml\"><mi id=\"S4.T2.6.6.1.m1.1.1.2\" xref=\"S4.T2.6.6.1.m1.1.1.2.cmml\">p</mi><mo id=\"S4.T2.6.6.1.m1.1.1.1\" xref=\"S4.T2.6.6.1.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T2.6.6.1.m1.1.1.3\" xref=\"S4.T2.6.6.1.m1.1.1.3.cmml\">1.00</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.6.6.1.m1.1b\"><apply id=\"S4.T2.6.6.1.m1.1.1.cmml\" xref=\"S4.T2.6.6.1.m1.1.1\"><eq id=\"S4.T2.6.6.1.m1.1.1.1.cmml\" xref=\"S4.T2.6.6.1.m1.1.1.1\"></eq><ci id=\"S4.T2.6.6.1.m1.1.1.2.cmml\" xref=\"S4.T2.6.6.1.m1.1.1.2\">ùëù</ci><cn type=\"float\" id=\"S4.T2.6.6.1.m1.1.1.3.cmml\" xref=\"S4.T2.6.6.1.m1.1.1.3\">1.00</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.6.6.1.m1.1c\">p=1.00</annotation></semantics></math></td>\n<td id=\"S4.T2.6.6.5\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S4.T2.7.7\" class=\"ltx_tr\">\n<td id=\"S4.T2.7.7.2\" class=\"ltx_td\"></td>\n<td id=\"S4.T2.7.7.3\" class=\"ltx_td ltx_align_center\">MM Late</td>\n<td id=\"S4.T2.7.7.4\" class=\"ltx_td ltx_align_center\">MM Middle</td>\n<td id=\"S4.T2.7.7.1\" class=\"ltx_td ltx_align_center\"><math id=\"S4.T2.7.7.1.m1.1\" class=\"ltx_Math\" alttext=\"p=0.720\" display=\"inline\"><semantics id=\"S4.T2.7.7.1.m1.1a\"><mrow id=\"S4.T2.7.7.1.m1.1.1\" xref=\"S4.T2.7.7.1.m1.1.1.cmml\"><mi id=\"S4.T2.7.7.1.m1.1.1.2\" xref=\"S4.T2.7.7.1.m1.1.1.2.cmml\">p</mi><mo id=\"S4.T2.7.7.1.m1.1.1.1\" xref=\"S4.T2.7.7.1.m1.1.1.1.cmml\">=</mo><mn id=\"S4.T2.7.7.1.m1.1.1.3\" xref=\"S4.T2.7.7.1.m1.1.1.3.cmml\">0.720</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.T2.7.7.1.m1.1b\"><apply id=\"S4.T2.7.7.1.m1.1.1.cmml\" xref=\"S4.T2.7.7.1.m1.1.1\"><eq id=\"S4.T2.7.7.1.m1.1.1.1.cmml\" xref=\"S4.T2.7.7.1.m1.1.1.1\"></eq><ci id=\"S4.T2.7.7.1.m1.1.1.2.cmml\" xref=\"S4.T2.7.7.1.m1.1.1.2\">ùëù</ci><cn type=\"float\" id=\"S4.T2.7.7.1.m1.1.1.3.cmml\" xref=\"S4.T2.7.7.1.m1.1.1.3\">0.720</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T2.7.7.1.m1.1c\">p=0.720</annotation></semantics></math></td>\n<td id=\"S4.T2.7.7.5\" class=\"ltx_td\"></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "Displayed in Table¬†I, our multimodal networks achieve an average test accuracy of 97.74% at convergence, with our late-concatenation model scoring the highest accuracy of 98.43%. The accuracy between each multimodal model are somewhat similar, all within about one percent. A McNemar test was performed between each model pairing using the test data with a desired hypothesis confidence of 95% (pùëùp-value = 0.05). That is, a rejection of the null hypothesis indicates that the models have significantly different classification output with 95% confidence. Experiment 1 in Table¬†II shows that our early branch concatenation multimodal SNN model performs statistically different than both the unimodal visual and unimodal auditory models (p<0.001ùëù0.001p<0.001). Therefore the null hypothesis is rejected, meaning our multimodal SNN model has a statistically better performance than each of the unimodal models. Both unimodal models perform similarly to one another according to a McNemar test (p>0.1ùëù0.1p>0.1). Our multimodal SNN models perform significantly better compared to both of our unimodal SNN models.",
            "Table¬†II shows that combining the visual and auditory branches at an early, middle, or late stage does not show a statistical difference in performance. Comparing our multimodal models reveals no difference in model output can be considered significant (p>0.1ùëù0.1p>0.1).\nTherefore the null hypothesis is not rejected, meaning the performance of the multimodal models are the same regardless of our branch concatenation depths. This suggests that SNNs are adept at fusing information regardless of where the information is introduced."
        ]
    }
}