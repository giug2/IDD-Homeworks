{
    "S4.T1": {
        "caption": "Table 1: Comparison of different synthetic training data types.",
        "table": "<table id=\"S4.T1.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.1.1.1\" class=\"ltx_td ltx_nopad ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\"><svg version=\"1.1\" height=\"19.07\" width=\"67.64\" overflow=\"visible\"><g transform=\"translate(0,19.07) scale(1,-1)\"><path d=\"M 0,19.07 67.64,0\" stroke=\"#000000\" stroke-width=\"0.4\"></path><g class=\"ltx_svg_fog\" transform=\"translate(0,0)\"><g transform=\"translate(0,9.46) scale(1, -1)\"><foreignobject width=\"26.52\" height=\"9.46\" overflow=\"visible\">\n<span id=\"S4.T1.1.1.1.1.pic1.1.1\" class=\"ltx_inline-block\">\n<span id=\"S4.T1.1.1.1.1.pic1.1.1.1\" class=\"ltx_inline-block ltx_align_left\">\n<span id=\"S4.T1.1.1.1.1.pic1.1.1.1.1\" class=\"ltx_p\">Acc.</span>\n</span>\n</span></foreignobject></g></g><g class=\"ltx_svg_fog\" transform=\"translate(33.82,9.46)\"><g transform=\"translate(0,9.61) scale(1, -1)\"><foreignobject width=\"33.82\" height=\"9.61\" overflow=\"visible\">\n<span id=\"S4.T1.1.1.1.1.pic1.2.1\" class=\"ltx_inline-block\">\n<span id=\"S4.T1.1.1.1.1.pic1.2.1.1\" class=\"ltx_inline-block ltx_align_right\">\n<span id=\"S4.T1.1.1.1.1.pic1.2.1.1.1\" class=\"ltx_p\">Mode</span>\n</span>\n</span></foreignobject></g></g></g></svg></th>\n<th id=\"S4.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Photorealistic</th>\n<th id=\"S4.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Randomised</th>\n<th id=\"S4.T1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Mixed</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Top-1</td>\n<td id=\"S4.T1.1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">.50</td>\n<td id=\"S4.T1.1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">.46</td>\n<td id=\"S4.T1.1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">.59</td>\n</tr>\n<tr id=\"S4.T1.1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Top-2</td>\n<td id=\"S4.T1.1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">.65</td>\n<td id=\"S4.T1.1.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">.61</td>\n<td id=\"S4.T1.1.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">.73</td>\n</tr>\n<tr id=\"S4.T1.1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">Top-5</td>\n<td id=\"S4.T1.1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">.86</td>\n<td id=\"S4.T1.1.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">.80</td>\n<td id=\"S4.T1.1.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">.87</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "The initial experiments were conducted in instance-aware mode. Firstly, we investigated how well different types of synthetic data serve learning our function. For this, we rendered two training sets of 6k images, featuring 50 object instances: one using BlenderProc, with the focus on photorealism and one using NDDS, with the focus on more randomisation. Examples of these images are shown in Figure 4. The network was trained thrice: first with only realistic data, then with only randomised data, finally with the union of the datasets. The top accuracy for all trainings are shown in Table 1. We see that the photo-realistic data alone yielded better results than the randomised data alone. Mixing the datasets resulted in the best accuracies of all, which speaks for increasing the variety of synthetic data to train with."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: The effect of siamese weight sharing.",
        "table": "<table id=\"S4.T2.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.1.1\" class=\"ltx_td ltx_nopad ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><svg version=\"1.1\" height=\"19.07\" width=\"67.64\" overflow=\"visible\"><g transform=\"translate(0,19.07) scale(1,-1)\"><path d=\"M 0,19.07 67.64,0\" stroke=\"#000000\" stroke-width=\"0.4\"></path><g class=\"ltx_svg_fog\" transform=\"translate(0,0)\"><g transform=\"translate(0,9.46) scale(1, -1)\"><foreignobject width=\"26.52\" height=\"9.46\" overflow=\"visible\">\n<span id=\"S4.T2.1.1.1.1.pic1.1.1\" class=\"ltx_inline-block\">\n<span id=\"S4.T2.1.1.1.1.pic1.1.1.1\" class=\"ltx_inline-block ltx_align_left\">\n<span id=\"S4.T2.1.1.1.1.pic1.1.1.1.1\" class=\"ltx_p\">Acc.</span>\n</span>\n</span></foreignobject></g></g><g class=\"ltx_svg_fog\" transform=\"translate(33.82,9.46)\"><g transform=\"translate(0,9.61) scale(1, -1)\"><foreignobject width=\"33.82\" height=\"9.61\" overflow=\"visible\">\n<span id=\"S4.T2.1.1.1.1.pic1.2.1\" class=\"ltx_inline-block\">\n<span id=\"S4.T2.1.1.1.1.pic1.2.1.1\" class=\"ltx_inline-block ltx_align_right\">\n<span id=\"S4.T2.1.1.1.1.pic1.2.1.1.1\" class=\"ltx_p\">Mode</span>\n</span>\n</span></foreignobject></g></g></g></svg></th>\n<th id=\"S4.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Separate Params</th>\n<th id=\"S4.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Shared Params</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">Top-1</th>\n<td id=\"S4.T2.1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">.55</td>\n<td id=\"S4.T2.1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">.62</td>\n</tr>\n<tr id=\"S4.T2.1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">Top-2</th>\n<td id=\"S4.T2.1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">.71</td>\n<td id=\"S4.T2.1.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">.75</td>\n</tr>\n<tr id=\"S4.T2.1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">Top-5</th>\n<td id=\"S4.T2.1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">.87</td>\n<td id=\"S4.T2.1.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">.90</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "Secondly, we looked into the effect of siamese parameter sharing between the network\u2019s arms. The model was trained once more in instance-aware mode, this time using more training samples (20k) including renderings from two extra UE4 maps, in order to further increase the retrieval rates through more varied data. Following that, the model was retrained with the same data, this time with CNN-view and CNN-img learning separately. The retrieval rates shown in Table 2 demonstrate a clear advantage from sharing weights."
        ]
    }
}