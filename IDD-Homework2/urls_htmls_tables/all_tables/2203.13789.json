{
    "PAPER'S NUMBER OF TABLES": 11,
    "S5.T1": {
        "caption": "Table 1: Comparison between FLUTE and Popular Federated Learning Simulation Platforms. This analysis is focused on the simulators provided by these platforms only.",
        "table": "<table id=\"S5.T1.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T1.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\"></th>\n<th id=\"S5.T1.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">FLUTE</th>\n<th id=\"S5.T1.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">FedML (Parrot)</th>\n<th id=\"S5.T1.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Flower (Simulator)</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T1.1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\">Focus</th>\n<td id=\"S5.T1.1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">Research and Simulation</td>\n<td id=\"S5.T1.1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">Research and Production</td>\n<td id=\"S5.T1.1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">Research and Production</td>\n</tr>\n<tr id=\"S5.T1.1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">ML Framework</th>\n<td id=\"S5.T1.1.1.3.2.2\" class=\"ltx_td ltx_align_center\">PyTorch</td>\n<td id=\"S5.T1.1.1.3.2.3\" class=\"ltx_td ltx_align_center\">PyTorch</td>\n<td id=\"S5.T1.1.1.3.2.4\" class=\"ltx_td ltx_align_center\">PyTorch / TensorFlow</td>\n</tr>\n<tr id=\"S5.T1.1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Communication Protocols Supported</th>\n<td id=\"S5.T1.1.1.4.3.2\" class=\"ltx_td ltx_align_center\">Gloo,NCCL</td>\n<td id=\"S5.T1.1.1.4.3.3\" class=\"ltx_td ltx_align_center\">SP, MPI</td>\n<td id=\"S5.T1.1.1.4.3.4\" class=\"ltx_td ltx_align_center\">Ray, gRPC</td>\n</tr>\n<tr id=\"S5.T1.1.1.5.4\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Support Security/Privacy related functions</th>\n<td id=\"S5.T1.1.1.5.4.2\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.1.1.5.4.2.1\" class=\"ltx_text\">✓</span></td>\n<td id=\"S5.T1.1.1.5.4.3\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.1.1.5.4.3.1\" class=\"ltx_text\">✓</span></td>\n<td id=\"S5.T1.1.1.5.4.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.1.1.5.4.4.1\" class=\"ltx_text\">✓</span></td>\n</tr>\n<tr id=\"S5.T1.1.1.6.5\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Support Multiple Federated Optimization Techniques</th>\n<td id=\"S5.T1.1.1.6.5.2\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.1.1.6.5.2.1\" class=\"ltx_text\">✓</span></td>\n<td id=\"S5.T1.1.1.6.5.3\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.1.1.6.5.3.1\" class=\"ltx_text\">✓</span></td>\n<td id=\"S5.T1.1.1.6.5.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.1.1.6.5.4.1\" class=\"ltx_text\">✓</span></td>\n</tr>\n<tr id=\"S5.T1.1.1.7.6\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.1.7.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Flexible and Generic API</th>\n<td id=\"S5.T1.1.1.7.6.2\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.1.1.7.6.2.1\" class=\"ltx_text\">✓</span></td>\n<td id=\"S5.T1.1.1.7.6.3\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.1.1.7.6.3.1\" class=\"ltx_text\">✓</span></td>\n<td id=\"S5.T1.1.1.7.6.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.1.1.7.6.4.1\" class=\"ltx_text\">✓</span></td>\n</tr>\n<tr id=\"S5.T1.1.1.8.7\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.1.8.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Cloud Integration</th>\n<td id=\"S5.T1.1.1.8.7.2\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.1.1.8.7.2.1\" class=\"ltx_text\">✓</span></td>\n<td id=\"S5.T1.1.1.8.7.3\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.1.1.8.7.3.1\" class=\"ltx_text\">✓</span></td>\n<td id=\"S5.T1.1.1.8.7.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.1.1.8.7.4.1\" class=\"ltx_text\">✗</span></td>\n</tr>\n<tr id=\"S5.T1.1.1.9.8\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.1.9.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Multi-GPU Support</th>\n<td id=\"S5.T1.1.1.9.8.2\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.1.1.9.8.2.1\" class=\"ltx_text\">✓</span></td>\n<td id=\"S5.T1.1.1.9.8.3\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.1.1.9.8.3.1\" class=\"ltx_text\">✓</span></td>\n<td id=\"S5.T1.1.1.9.8.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.1.1.9.8.4.1\" class=\"ltx_text\">✗</span></td>\n</tr>\n<tr id=\"S5.T1.1.1.10.9\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.1.10.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Performance Optimizations</th>\n<td id=\"S5.T1.1.1.10.9.2\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.1.1.10.9.2.1\" class=\"ltx_text\">✓</span></td>\n<td id=\"S5.T1.1.1.10.9.3\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.1.1.10.9.3.1\" class=\"ltx_text\">✗</span></td>\n<td id=\"S5.T1.1.1.10.9.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T1.1.1.10.9.4.1\" class=\"ltx_text\">✗</span></td>\n</tr>\n<tr id=\"S5.T1.1.1.11.10\" class=\"ltx_tr\">\n<th id=\"S5.T1.1.1.11.10.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">Easily Extensible to Production</th>\n<td id=\"S5.T1.1.1.11.10.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T1.1.1.11.10.2.1\" class=\"ltx_text\">✗</span></td>\n<td id=\"S5.T1.1.1.11.10.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T1.1.1.11.10.3.1\" class=\"ltx_text\">✓</span></td>\n<td id=\"S5.T1.1.1.11.10.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T1.1.1.11.10.4.1\" class=\"ltx_text\">✓</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Multiple FL platforms have been proposed. However, most of them have been designed with a specific purpose limiting their flexibility to experiment with complex large-scale FL scenarios in a reasonable amount of time, and using limited resources. Some production-oriented frameworks also allow researchers to work in a simulation environment using the same platform. Nonetheless, these simulators suffer from lack of flexibility and limited functionality\nsince their architecture is optimized towards productization, especially in complex FL scenarios. Table 1 shows a detailed comparison of the most common FL platforms’ features and main focus.",
            "This experiment of next-word prediction, using the Reddit dataset and baseline LM model described in Section 6.1, explores model training performance for a variety of state-of-the-art optimizer choices. We trained a recurrent language model, fixing the number of clients per round to 1,000, and varying the choice of optimizer in the central aggregator. Specifically, we applied standard SGD Rosenblatt (1958), ADAM Kingma & Ba (2017), LAMB You et al. (2020), and LARS You et al. (2017). Table 10 illustrates the performance of each optimizer, including maximum validation accuracy, and convergence rate: the number of rounds to reach 95% of the max. accuracy. Note there is no hyper-parameter tuning of the optimizers for this experiment.",
            "The CIFAR-10 task is used for the personalization experiments, splitting the data across 100 clients, and sampling 10 clients per iteration. The client data are split according to the process described in He et al. (2020), with α∈[0.2, 1.0]𝛼0.21.0\\alpha\\in[0.2,\\ 1.0] for the Dirichlet label distribution (client distributions are more iid when the α𝛼\\alpha values are larger). In addition to the label distributions, we investigate different feature distributions by applying locally different image transformations (per each client). For this experiment, we fix the test samples to match the local training data/label distributions, i.e. we split the test set to follow similar local label distributions as the training samples. The image transformations are unique per client for both the training and test samples, when applicable. Herein, we investigate 3 different training strategies, i.e. a global model trained with DGA, local models trained with SGD and the convex interpolation of these two, as described in Section 4.4.\nThe relative performance improvement shown in Table 11 is between the global and the interpolated models."
        ]
    },
    "S5.T2": {
        "caption": "Table 2: Training configuration for FLUTE/FedML/Flower Benchmarking",
        "table": "<table id=\"S5.T2.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T2.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T2.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Model</th>\n<th id=\"S5.T2.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Dataset</th>\n<th id=\"S5.T2.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Algorithm</th>\n<th id=\"S5.T2.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"># Clients</th>\n<th id=\"S5.T2.1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Clients/round</th>\n<th id=\"S5.T2.1.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Batch Size</th>\n<th id=\"S5.T2.1.1.1.1.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Client Optim.</th>\n<th id=\"S5.T2.1.1.1.1.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">lr</th>\n<th id=\"S5.T2.1.1.1.1.9\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Local Epochs</th>\n<th id=\"S5.T2.1.1.1.1.10\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"># Rounds</th>\n<th id=\"S5.T2.1.1.1.1.11\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Test Freq</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T2.1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\">Log. Regr.</td>\n<td id=\"S5.T2.1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">mnist</td>\n<td id=\"S5.T2.1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">FedAvg</td>\n<td id=\"S5.T2.1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">1000</td>\n<td id=\"S5.T2.1.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">10</td>\n<td id=\"S5.T2.1.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_tt\">10</td>\n<td id=\"S5.T2.1.1.2.1.7\" class=\"ltx_td ltx_align_center ltx_border_tt\">SGD</td>\n<td id=\"S5.T2.1.1.2.1.8\" class=\"ltx_td ltx_align_center ltx_border_tt\">0.03</td>\n<td id=\"S5.T2.1.1.2.1.9\" class=\"ltx_td ltx_align_center ltx_border_tt\">1</td>\n<td id=\"S5.T2.1.1.2.1.10\" class=\"ltx_td ltx_align_center ltx_border_tt\">100</td>\n<td id=\"S5.T2.1.1.2.1.11\" class=\"ltx_td ltx_align_center ltx_border_tt\">20</td>\n</tr>\n<tr id=\"S5.T2.1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.3.2.1\" class=\"ltx_td ltx_align_center\">CNN</td>\n<td id=\"S5.T2.1.1.3.2.2\" class=\"ltx_td ltx_align_center\">fedmnist</td>\n<td id=\"S5.T2.1.1.3.2.3\" class=\"ltx_td ltx_align_center\">FedAvg</td>\n<td id=\"S5.T2.1.1.3.2.4\" class=\"ltx_td ltx_align_center\">3400</td>\n<td id=\"S5.T2.1.1.3.2.5\" class=\"ltx_td ltx_align_center\">10</td>\n<td id=\"S5.T2.1.1.3.2.6\" class=\"ltx_td ltx_align_center\">20</td>\n<td id=\"S5.T2.1.1.3.2.7\" class=\"ltx_td ltx_align_center\">SGD</td>\n<td id=\"S5.T2.1.1.3.2.8\" class=\"ltx_td ltx_align_center\">0.1</td>\n<td id=\"S5.T2.1.1.3.2.9\" class=\"ltx_td ltx_align_center\">1</td>\n<td id=\"S5.T2.1.1.3.2.10\" class=\"ltx_td ltx_align_center\">800</td>\n<td id=\"S5.T2.1.1.3.2.11\" class=\"ltx_td ltx_align_center\">50</td>\n</tr>\n<tr id=\"S5.T2.1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.4.3.1\" class=\"ltx_td ltx_align_center\">ResNet18</td>\n<td id=\"S5.T2.1.1.4.3.2\" class=\"ltx_td ltx_align_center\">fedcifar100</td>\n<td id=\"S5.T2.1.1.4.3.3\" class=\"ltx_td ltx_align_center\">FedAvg</td>\n<td id=\"S5.T2.1.1.4.3.4\" class=\"ltx_td ltx_align_center\">500</td>\n<td id=\"S5.T2.1.1.4.3.5\" class=\"ltx_td ltx_align_center\">10</td>\n<td id=\"S5.T2.1.1.4.3.6\" class=\"ltx_td ltx_align_center\">20</td>\n<td id=\"S5.T2.1.1.4.3.7\" class=\"ltx_td ltx_align_center\">SGD</td>\n<td id=\"S5.T2.1.1.4.3.8\" class=\"ltx_td ltx_align_center\">0.1</td>\n<td id=\"S5.T2.1.1.4.3.9\" class=\"ltx_td ltx_align_center\">1</td>\n<td id=\"S5.T2.1.1.4.3.10\" class=\"ltx_td ltx_align_center\">4000</td>\n<td id=\"S5.T2.1.1.4.3.11\" class=\"ltx_td ltx_align_center\">50</td>\n</tr>\n<tr id=\"S5.T2.1.1.5.4\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">RNN</td>\n<td id=\"S5.T2.1.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">fedshakespeare</td>\n<td id=\"S5.T2.1.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">FedAvg</td>\n<td id=\"S5.T2.1.1.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">715</td>\n<td id=\"S5.T2.1.1.5.4.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">10</td>\n<td id=\"S5.T2.1.1.5.4.6\" class=\"ltx_td ltx_align_center ltx_border_bb\">4</td>\n<td id=\"S5.T2.1.1.5.4.7\" class=\"ltx_td ltx_align_center ltx_border_bb\">SGD</td>\n<td id=\"S5.T2.1.1.5.4.8\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.8</td>\n<td id=\"S5.T2.1.1.5.4.9\" class=\"ltx_td ltx_align_center ltx_border_bb\">1</td>\n<td id=\"S5.T2.1.1.5.4.10\" class=\"ltx_td ltx_align_center ltx_border_bb\">1200</td>\n<td id=\"S5.T2.1.1.5.4.11\" class=\"ltx_td ltx_align_center ltx_border_bb\">50</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Enabling the comparisons between platforms, the configuration for the experiments are detailed in Table 2, while all results are shown in Tables 3 and 4. The setups are based on the FedML Benchmarking Recipes555FedML Benchmarking Results https://doc.fedml.ai/simulation/benchmark/BENCHMARK_MPI.html using the same hyper-parameters, datasets666FedML Datasets https://github.com/FedML-AI/FedML/tree/master/python/fedml/data, and models777FedML Benchmarking Examples https://github.com/FedML-AI/FedML/tree/master/python/examples/simulation/mpi_fedavg_datasets_and_models_example. All FLUTE scripts can be found under Experiments in the FLUTE repository.",
            "An additional comparison of FLUTE versus Flower 1.0.0 888Flower Simulator on its release 1.0.0, commit ID 4e7fad9 is presented in Table 4. The Flower platform seems more efficient when multiple CPUs are employed – the platform is fairly inefficient by design when multiple GPUs are used during simulation. To run a fair comparison, we also compare the FLUTE CPU performance (using the Gloo backend) against Flower, evaluating the overall time of the job using the same setup for the \"lr mnist\" task described in Table 2. FLUTE is up to 54×54\\times faster than Flower on GPUs given that their simulation capabilities are not optimized for multi-GPU jobs. Regardless, FLUTE, running on a Gloo backend, is 9×9\\times faster than Flower, running only on CPUs."
        ]
    },
    "S5.T3": {
        "caption": "Table 3: GPU Performance comparison FLUTE 1.0.0 vs FedML 0.7.303 on 4x NVIDIA RTX A6000 using FedML Datasets. Test accuracy is reported from the last communication round. ",
        "table": "<table id=\"S5.T3.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T3.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"4\">Task</th>\n<th id=\"S5.T3.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\">FedML (MPI) 0.7.303</th>\n<th id=\"S5.T3.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\">FLUTE (NCCL) 1.0.0</th>\n</tr>\n<tr id=\"S5.T3.1.1.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Model</th>\n<th id=\"S5.T3.1.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Dataset</th>\n<th id=\"S5.T3.1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Clients</th>\n<th id=\"S5.T3.1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Rounds</th>\n<th id=\"S5.T3.1.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Acc</th>\n<th id=\"S5.T3.1.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Time</th>\n<th id=\"S5.T3.1.1.2.2.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">GPU memory</th>\n<th id=\"S5.T3.1.1.2.2.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Acc</th>\n<th id=\"S5.T3.1.1.2.2.9\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Time</th>\n<th id=\"S5.T3.1.1.2.2.10\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">GPU memory</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T3.1.1.3.1\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.1.3.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\">Log. Regr.</td>\n<td id=\"S5.T3.1.1.3.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">mnist</td>\n<td id=\"S5.T3.1.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">1000</td>\n<td id=\"S5.T3.1.1.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">100</td>\n<td id=\"S5.T3.1.1.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\"> 81</td>\n<td id=\"S5.T3.1.1.3.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">00:03:09</td>\n<td id=\"S5.T3.1.1.3.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\"> 3060 MB</td>\n<td id=\"S5.T3.1.1.3.1.8\" class=\"ltx_td ltx_align_center ltx_border_t\"> 81</td>\n<td id=\"S5.T3.1.1.3.1.9\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.1.1.3.1.9.1\" class=\"ltx_text ltx_font_bold\">00:01:35</span></td>\n<td id=\"S5.T3.1.1.3.1.10\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T3.1.1.3.1.10.1\" class=\"ltx_text ltx_font_bold\"> 1060 MB</span></td>\n</tr>\n<tr id=\"S5.T3.1.1.4.2\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.1.4.2.1\" class=\"ltx_td ltx_align_left\">CNN</td>\n<td id=\"S5.T3.1.1.4.2.2\" class=\"ltx_td ltx_align_left\">fedmnist</td>\n<td id=\"S5.T3.1.1.4.2.3\" class=\"ltx_td ltx_align_center\">3400</td>\n<td id=\"S5.T3.1.1.4.2.4\" class=\"ltx_td ltx_align_center\">800</td>\n<td id=\"S5.T3.1.1.4.2.5\" class=\"ltx_td ltx_align_center\"> 83</td>\n<td id=\"S5.T3.1.1.4.2.6\" class=\"ltx_td ltx_align_center\">05:49:52</td>\n<td id=\"S5.T3.1.1.4.2.7\" class=\"ltx_td ltx_align_center\"> 5180 MB</td>\n<td id=\"S5.T3.1.1.4.2.8\" class=\"ltx_td ltx_align_center\"> 83</td>\n<td id=\"S5.T3.1.1.4.2.9\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T3.1.1.4.2.9.1\" class=\"ltx_text ltx_font_bold\">00:08:22</span></td>\n<td id=\"S5.T3.1.1.4.2.10\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T3.1.1.4.2.10.1\" class=\"ltx_text ltx_font_bold\"> 1770 MB</span></td>\n</tr>\n<tr id=\"S5.T3.1.1.5.3\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.1.5.3.1\" class=\"ltx_td ltx_align_left\">ResNet18</td>\n<td id=\"S5.T3.1.1.5.3.2\" class=\"ltx_td ltx_align_left\">fedcifar100</td>\n<td id=\"S5.T3.1.1.5.3.3\" class=\"ltx_td ltx_align_center\">500</td>\n<td id=\"S5.T3.1.1.5.3.4\" class=\"ltx_td ltx_align_center\">4000</td>\n<td id=\"S5.T3.1.1.5.3.5\" class=\"ltx_td ltx_align_center\"> 34</td>\n<td id=\"S5.T3.1.1.5.3.6\" class=\"ltx_td ltx_align_center\">15:55:36</td>\n<td id=\"S5.T3.1.1.5.3.7\" class=\"ltx_td ltx_align_center\"> 5530 MB</td>\n<td id=\"S5.T3.1.1.5.3.8\" class=\"ltx_td ltx_align_center\"> 33</td>\n<td id=\"S5.T3.1.1.5.3.9\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T3.1.1.5.3.9.1\" class=\"ltx_text ltx_font_bold\">01:42:01</span></td>\n<td id=\"S5.T3.1.1.5.3.10\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T3.1.1.5.3.10.1\" class=\"ltx_text ltx_font_bold\"> 1900 MB</span></td>\n</tr>\n<tr id=\"S5.T3.1.1.6.4\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.1.6.4.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">RNN</td>\n<td id=\"S5.T3.1.1.6.4.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">fedshakespeare</td>\n<td id=\"S5.T3.1.1.6.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">715</td>\n<td id=\"S5.T3.1.1.6.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">1200</td>\n<td id=\"S5.T3.1.1.6.4.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"> 57</td>\n<td id=\"S5.T3.1.1.6.4.6\" class=\"ltx_td ltx_align_center ltx_border_bb\">06:46:21</td>\n<td id=\"S5.T3.1.1.6.4.7\" class=\"ltx_td ltx_align_center ltx_border_bb\"> 3690 MB</td>\n<td id=\"S5.T3.1.1.6.4.8\" class=\"ltx_td ltx_align_center ltx_border_bb\"> 57</td>\n<td id=\"S5.T3.1.1.6.4.9\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T3.1.1.6.4.9.1\" class=\"ltx_text ltx_font_bold\">00:21:50</span></td>\n<td id=\"S5.T3.1.1.6.4.10\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T3.1.1.6.4.10.1\" class=\"ltx_text ltx_font_bold\"> 1270 MB</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "For this comparison, we selected the FedML He et al. (2020) and Flower Beutel et al. (2020) platforms as the most representative, based on their number of stars on GitHub. Table 3 shows that FLUTE outperforms FedML by 42×42\\times in speed and 3×3\\times in memory consumption. The advantage of FLUTE relies on its ability to asynchronously assign new clients to the workers as they become available, and receive their outputs. On the other hand, FedML444FedML Simulator (Parrot) on its release 0.7.303, commit ID 8f7f261f  links the number of workers with the number of MPI processes, which is reflected as the number of parallel clients during training, FLUTE design allows processing multiple clients per worker, decoupling the need for 1:1:111:1 mapping between clients and training processes. In FLUTE, each worker holds a pre-loaded local copy of the training data, avoiding communication overheads during training as the Server only sends indices of the clients to instantiate."
        ]
    },
    "S5.T4": {
        "caption": "Table 4: Performance comparison FLUTE 1.0.0 vs Flower 1.0.0 on 4x NVIDIA RTX A6000, AMD EPYC 7V12 64-Core Processor. Test accuracy is reported from the last communication round. ",
        "table": "<table id=\"S5.T4.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T4.1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.1.1.1\" class=\"ltx_td ltx_border_tt\"></td>\n<th id=\"S5.T4.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"3\">FLUTE 1.0.0</th>\n<th id=\"S5.T4.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Flower 1.0.0</th>\n</tr>\n<tr id=\"S5.T4.1.1.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.2.2.1\" class=\"ltx_td\"></td>\n<th id=\"S5.T4.1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" colspan=\"3\">Gloo/NCCL</th>\n<th id=\"S5.T4.1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">gRPC</th>\n</tr>\n<tr id=\"S5.T4.1.1.3.3\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Accelerator</th>\n<th id=\"S5.T4.1.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Acc</th>\n<th id=\"S5.T4.1.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Time</th>\n<th id=\"S5.T4.1.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Acc</th>\n<th id=\"S5.T4.1.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Time</th>\n</tr>\n<tr id=\"S5.T4.1.1.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_t\">CPU</td>\n<td id=\"S5.T4.1.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">80</td>\n<td id=\"S5.T4.1.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.1.1.4.4.3.1\" class=\"ltx_text ltx_font_bold\">00:03:20</span></td>\n<td id=\"S5.T4.1.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">80</td>\n<td id=\"S5.T4.1.1.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\">00:30:14</td>\n</tr>\n<tr id=\"S5.T4.1.1.5.5\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.5.5.1\" class=\"ltx_td ltx_align_center\">GPU 2x</td>\n<td id=\"S5.T4.1.1.5.5.2\" class=\"ltx_td ltx_align_center\">80</td>\n<td id=\"S5.T4.1.1.5.5.3\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T4.1.1.5.5.3.1\" class=\"ltx_text ltx_font_bold\">00:01:31</span></td>\n<td id=\"S5.T4.1.1.5.5.4\" class=\"ltx_td ltx_align_center\">80</td>\n<td id=\"S5.T4.1.1.5.5.5\" class=\"ltx_td ltx_align_center\">01:21:44</td>\n</tr>\n<tr id=\"S5.T4.1.1.6.6\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.6.6.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">GPU 4x</td>\n<td id=\"S5.T4.1.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">81</td>\n<td id=\"S5.T4.1.1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T4.1.1.6.6.3.1\" class=\"ltx_text ltx_font_bold\">00:01:26</span></td>\n<td id=\"S5.T4.1.1.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">79</td>\n<td id=\"S5.T4.1.1.6.6.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">00:56:45</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "An additional comparison of FLUTE versus Flower 1.0.0 888Flower Simulator on its release 1.0.0, commit ID 4e7fad9 is presented in Table 4. The Flower platform seems more efficient when multiple CPUs are employed – the platform is fairly inefficient by design when multiple GPUs are used during simulation. To run a fair comparison, we also compare the FLUTE CPU performance (using the Gloo backend) against Flower, evaluating the overall time of the job using the same setup for the \"lr mnist\" task described in Table 2. FLUTE is up to 54×54\\times faster than Flower on GPUs given that their simulation capabilities are not optimized for multi-GPU jobs. Regardless, FLUTE, running on a Gloo backend, is 9×9\\times faster than Flower, running only on CPUs."
        ]
    },
    "S6.T5": {
        "caption": "Table 5: Next-word prediction: Top-1 accuracy after gradient quantization. The number of bits per gradient coefficient varies 2−322322-32.",
        "table": "<table id=\"S6.T5.3.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T5.3.1.1.1\" class=\"ltx_tr\">\n<th id=\"S6.T5.3.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\"></th>\n<th id=\"S6.T5.3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt\">Quant. (bits)</th>\n<td id=\"S6.T5.3.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">Acc @1 (%)</td>\n<td id=\"S6.T5.3.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">Rel. Imprv. (%)</td>\n</tr>\n<tr id=\"S6.T5.3.1.2.2\" class=\"ltx_tr\">\n<th id=\"S6.T5.3.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\">Seed Model</th>\n<th id=\"S6.T5.3.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt\">N/A</th>\n<td id=\"S6.T5.3.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">9.83</td>\n<td id=\"S6.T5.3.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">(56.62)</td>\n</tr>\n<tr id=\"S6.T5.3.1.3.3\" class=\"ltx_tr\">\n<th id=\"S6.T5.3.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Server-Side Training</th>\n<th id=\"S6.T5.3.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">N/A</th>\n<td id=\"S6.T5.3.1.3.3.3\" class=\"ltx_td ltx_align_center\">22.30</td>\n<td id=\"S6.T5.3.1.3.3.4\" class=\"ltx_td ltx_align_center\">(1.59)</td>\n</tr>\n<tr id=\"S6.T5.3.1.4.4\" class=\"ltx_tr\">\n<th id=\"S6.T5.3.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">FL Train.</th>\n<th id=\"S6.T5.3.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">32</th>\n<td id=\"S6.T5.3.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">22.70</td>\n<td id=\"S6.T5.3.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0</td>\n</tr>\n<tr id=\"S6.T5.3.1.5.5\" class=\"ltx_tr\">\n<th id=\"S6.T5.3.1.5.5.1\" class=\"ltx_td ltx_th ltx_th_row\"></th>\n<th id=\"S6.T5.3.1.5.5.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">10</th>\n<td id=\"S6.T5.3.1.5.5.3\" class=\"ltx_td ltx_align_center\">22.40</td>\n<td id=\"S6.T5.3.1.5.5.4\" class=\"ltx_td ltx_align_center\">(1.32)</td>\n</tr>\n<tr id=\"S6.T5.3.1.6.6\" class=\"ltx_tr\">\n<th id=\"S6.T5.3.1.6.6.1\" class=\"ltx_td ltx_th ltx_th_row\"></th>\n<th id=\"S6.T5.3.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">8</th>\n<td id=\"S6.T5.3.1.6.6.3\" class=\"ltx_td ltx_align_center\">22.20</td>\n<td id=\"S6.T5.3.1.6.6.4\" class=\"ltx_td ltx_align_center\">(2.25)</td>\n</tr>\n<tr id=\"S6.T5.3.1.7.7\" class=\"ltx_tr\">\n<th id=\"S6.T5.3.1.7.7.1\" class=\"ltx_td ltx_th ltx_th_row\"></th>\n<th id=\"S6.T5.3.1.7.7.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">4</th>\n<td id=\"S6.T5.3.1.7.7.3\" class=\"ltx_td ltx_align_center\">21.30</td>\n<td id=\"S6.T5.3.1.7.7.4\" class=\"ltx_td ltx_align_center\">(5.87)</td>\n</tr>\n<tr id=\"S6.T5.3.1.8.8\" class=\"ltx_tr\">\n<th id=\"S6.T5.3.1.8.8.1\" class=\"ltx_td ltx_th ltx_th_row\"></th>\n<th id=\"S6.T5.3.1.8.8.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">3</th>\n<td id=\"S6.T5.3.1.8.8.3\" class=\"ltx_td ltx_align_center\">18.80</td>\n<td id=\"S6.T5.3.1.8.8.4\" class=\"ltx_td ltx_align_center\">(17.21)</td>\n</tr>\n<tr id=\"S6.T5.3.1.9.9\" class=\"ltx_tr\">\n<th id=\"S6.T5.3.1.9.9.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_bb\"></th>\n<th id=\"S6.T5.3.1.9.9.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\">2</th>\n<td id=\"S6.T5.3.1.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">17.80</td>\n<td id=\"S6.T5.3.1.9.9.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">(21.58)</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "The accuracy for a next-word-prediction task on the Reddit dataset and the baseline LM model (as described in Section 6.1) for various levels of quantization B𝐵B is shown in Table 5. As expected, using less bits leads to decreased performance in terms of accuracy."
        ]
    },
    "S6.T6": {
        "caption": "Table 6: Performance obtained by varying sparsity level on gradients while keeping quantization fixed at 8 bits – gains in bandwidth are relative to standard 32 bits gradient. The performance reported is the best over 5000 iterations, with 1000 clients/iteration.",
        "table": "<table id=\"S6.T6.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S6.T6.1.1.1\" class=\"ltx_tr\">\n<th id=\"S6.T6.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">% Sparsity</th>\n<th id=\"S6.T6.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Gain in Bandwidth</th>\n<th id=\"S6.T6.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Acc @1 (%)</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T6.1.2.1\" class=\"ltx_tr\">\n<td id=\"S6.T6.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\">0.0</td>\n<td id=\"S6.T6.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">4x</td>\n<td id=\"S6.T6.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">22.60</td>\n</tr>\n<tr id=\"S6.T6.1.3.2\" class=\"ltx_tr\">\n<td id=\"S6.T6.1.3.2.1\" class=\"ltx_td ltx_align_center\">75.0</td>\n<td id=\"S6.T6.1.3.2.2\" class=\"ltx_td ltx_align_center\">16x</td>\n<td id=\"S6.T6.1.3.2.3\" class=\"ltx_td ltx_align_center\">21.70</td>\n</tr>\n<tr id=\"S6.T6.1.4.3\" class=\"ltx_tr\">\n<td id=\"S6.T6.1.4.3.1\" class=\"ltx_td ltx_align_center\">95.0</td>\n<td id=\"S6.T6.1.4.3.2\" class=\"ltx_td ltx_align_center\">80x</td>\n<td id=\"S6.T6.1.4.3.3\" class=\"ltx_td ltx_align_center\">19.00</td>\n</tr>\n<tr id=\"S6.T6.1.5.4\" class=\"ltx_tr\">\n<td id=\"S6.T6.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">99.0</td>\n<td id=\"S6.T6.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">400x</td>\n<td id=\"S6.T6.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">17.70</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We also experiment with the sparsity level, while keeping the quantization set at 8 bits, cf. Table 6. Herein, we observe gains in bandwidth of up to 16×16\\times with no significant change in performance. Error compensation techniques, e.g., Strom (2015) could be used to increase the performance at higher sparsity levels. The differences for the case of 8-bit quantization level in Tables 5 and 6 are due to noise during the training process."
        ]
    },
    "S6.T7": {
        "caption": "Table 7: Fine-tuning Strategy: Federating (a) entire model, (b) last layer, and (c) adapter modules. All results are sentiment classification accuracy.",
        "table": "<table id=\"S6.T7.4.4\" class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T7.4.4.5.1\" class=\"ltx_tr\">\n<td id=\"S6.T7.4.4.5.1.1\" class=\"ltx_td ltx_align_left ltx_border_tt\">Setup</td>\n<td id=\"S6.T7.4.4.5.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">Federation Strategy</td>\n<td id=\"S6.T7.4.4.5.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">Gain in Bandwidth</td>\n<td id=\"S6.T7.4.4.5.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">Acc (%)</td>\n</tr>\n<tr id=\"S6.T7.4.4.6.2\" class=\"ltx_tr\">\n<td id=\"S6.T7.4.4.6.2.1\" class=\"ltx_td ltx_align_left ltx_border_tt\">Centralized</td>\n<td id=\"S6.T7.4.4.6.2.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">Full-model</td>\n<td id=\"S6.T7.4.4.6.2.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">NA</td>\n<td id=\"S6.T7.4.4.6.2.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">86.9</td>\n</tr>\n<tr id=\"S6.T7.4.4.7.3\" class=\"ltx_tr\">\n<td id=\"S6.T7.4.4.7.3.1\" class=\"ltx_td ltx_align_left\">Training</td>\n<td id=\"S6.T7.4.4.7.3.2\" class=\"ltx_td ltx_align_center\">Pretrained Adapters</td>\n<td id=\"S6.T7.4.4.7.3.3\" class=\"ltx_td ltx_align_center\">NA</td>\n<td id=\"S6.T7.4.4.7.3.4\" class=\"ltx_td ltx_align_center\">86.6</td>\n</tr>\n<tr id=\"S6.T7.4.4.8.4\" class=\"ltx_tr\">\n<td id=\"S6.T7.4.4.8.4.1\" class=\"ltx_td ltx_align_left ltx_border_t\">FL Train.</td>\n<td id=\"S6.T7.4.4.8.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Full-model</td>\n<td id=\"S6.T7.4.4.8.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.0</td>\n<td id=\"S6.T7.4.4.8.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">83.5</td>\n</tr>\n<tr id=\"S6.T7.1.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T7.1.1.1.2\" class=\"ltx_td ltx_align_left\">(non-iid)</td>\n<td id=\"S6.T7.1.1.1.3\" class=\"ltx_td ltx_align_center\">Last-layer</td>\n<td id=\"S6.T7.1.1.1.1\" class=\"ltx_td ltx_align_center\"><math id=\"S6.T7.1.1.1.1.m1.1\" class=\"ltx_math_unparsed\" alttext=\"14.2\\times\" display=\"inline\"><semantics id=\"S6.T7.1.1.1.1.m1.1a\"><mrow id=\"S6.T7.1.1.1.1.m1.1b\"><mn id=\"S6.T7.1.1.1.1.m1.1.1\">14.2</mn><mo lspace=\"0.222em\" id=\"S6.T7.1.1.1.1.m1.1.2\">×</mo></mrow><annotation encoding=\"application/x-tex\" id=\"S6.T7.1.1.1.1.m1.1c\">14.2\\times</annotation></semantics></math></td>\n<td id=\"S6.T7.1.1.1.4\" class=\"ltx_td ltx_align_center\">83.1</td>\n</tr>\n<tr id=\"S6.T7.2.2.2\" class=\"ltx_tr\">\n<td id=\"S6.T7.2.2.2.2\" class=\"ltx_td\"></td>\n<td id=\"S6.T7.2.2.2.3\" class=\"ltx_td ltx_align_center\">Adapters (rand. init.)</td>\n<td id=\"S6.T7.2.2.2.1\" class=\"ltx_td ltx_align_center\"><math id=\"S6.T7.2.2.2.1.m1.1\" class=\"ltx_math_unparsed\" alttext=\"121\\times\" display=\"inline\"><semantics id=\"S6.T7.2.2.2.1.m1.1a\"><mrow id=\"S6.T7.2.2.2.1.m1.1b\"><mn id=\"S6.T7.2.2.2.1.m1.1.1\">121</mn><mo lspace=\"0.222em\" id=\"S6.T7.2.2.2.1.m1.1.2\">×</mo></mrow><annotation encoding=\"application/x-tex\" id=\"S6.T7.2.2.2.1.m1.1c\">121\\times</annotation></semantics></math></td>\n<td id=\"S6.T7.2.2.2.4\" class=\"ltx_td ltx_align_center\">83.2</td>\n</tr>\n<tr id=\"S6.T7.3.3.3\" class=\"ltx_tr\">\n<td id=\"S6.T7.3.3.3.2\" class=\"ltx_td\"></td>\n<td id=\"S6.T7.3.3.3.3\" class=\"ltx_td ltx_align_center\">Pretrained Adapters</td>\n<td id=\"S6.T7.3.3.3.1\" class=\"ltx_td ltx_align_center\"><math id=\"S6.T7.3.3.3.1.m1.1\" class=\"ltx_math_unparsed\" alttext=\"121\\times\" display=\"inline\"><semantics id=\"S6.T7.3.3.3.1.m1.1a\"><mrow id=\"S6.T7.3.3.3.1.m1.1b\"><mn id=\"S6.T7.3.3.3.1.m1.1.1\">121</mn><mo lspace=\"0.222em\" id=\"S6.T7.3.3.3.1.m1.1.2\">×</mo></mrow><annotation encoding=\"application/x-tex\" id=\"S6.T7.3.3.3.1.m1.1c\">121\\times</annotation></semantics></math></td>\n<td id=\"S6.T7.3.3.3.4\" class=\"ltx_td ltx_align_center\">83.4</td>\n</tr>\n<tr id=\"S6.T7.4.4.9.5\" class=\"ltx_tr\">\n<td id=\"S6.T7.4.4.9.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\">FL Train.</td>\n<td id=\"S6.T7.4.4.9.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Full-model</td>\n<td id=\"S6.T7.4.4.9.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.0</td>\n<td id=\"S6.T7.4.4.9.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">86.1</td>\n</tr>\n<tr id=\"S6.T7.4.4.4\" class=\"ltx_tr\">\n<td id=\"S6.T7.4.4.4.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">(iid)</td>\n<td id=\"S6.T7.4.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">Pretrained Adapters</td>\n<td id=\"S6.T7.4.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_bb\"><math id=\"S6.T7.4.4.4.1.m1.1\" class=\"ltx_math_unparsed\" alttext=\"121\\times\" display=\"inline\"><semantics id=\"S6.T7.4.4.4.1.m1.1a\"><mrow id=\"S6.T7.4.4.4.1.m1.1b\"><mn id=\"S6.T7.4.4.4.1.m1.1.1\">121</mn><mo lspace=\"0.222em\" id=\"S6.T7.4.4.4.1.m1.1.2\">×</mo></mrow><annotation encoding=\"application/x-tex\" id=\"S6.T7.4.4.4.1.m1.1c\">121\\times</annotation></semantics></math></td>\n<td id=\"S6.T7.4.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">86.1</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "The observed performance degradation is due to the skewed data distribution per client. Further, some of the available clients don’t have enough data for a full batch and we employ zero-padding. Federating just the adapters can achieve as good or better performance as federating the full models, as shown in Table 7. In such case, the gains in bandwidth utilization is about 121×121\\times without any loss in performance."
        ]
    },
    "S6.T8": {
        "caption": "Table 8: How long it takes for 3 workers to process different number of clients, on an NLG experiment using a GRU model and the Reddit dataset. Averages are computed over 20 iterations.",
        "table": "<table id=\"S6.T8.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S6.T8.4.5.1\" class=\"ltx_tr\">\n<th id=\"S6.T8.4.5.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Number of Clients</th>\n<th id=\"S6.T8.4.5.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Runtime (sec.)</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T8.1.1\" class=\"ltx_tr\">\n<th id=\"S6.T8.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt\">1,000</th>\n<td id=\"S6.T8.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\">22.1 <math id=\"S6.T8.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S6.T8.1.1.1.m1.1a\"><mo id=\"S6.T8.1.1.1.m1.1.1\" xref=\"S6.T8.1.1.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S6.T8.1.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S6.T8.1.1.1.m1.1.1.cmml\" xref=\"S6.T8.1.1.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T8.1.1.1.m1.1c\">\\pm</annotation></semantics></math> 0.6</td>\n</tr>\n<tr id=\"S6.T8.2.2\" class=\"ltx_tr\">\n<th id=\"S6.T8.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">5,000</th>\n<td id=\"S6.T8.2.2.1\" class=\"ltx_td ltx_align_center\">111.3 <math id=\"S6.T8.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S6.T8.2.2.1.m1.1a\"><mo id=\"S6.T8.2.2.1.m1.1.1\" xref=\"S6.T8.2.2.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S6.T8.2.2.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S6.T8.2.2.1.m1.1.1.cmml\" xref=\"S6.T8.2.2.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T8.2.2.1.m1.1c\">\\pm</annotation></semantics></math> 2.4</td>\n</tr>\n<tr id=\"S6.T8.3.3\" class=\"ltx_tr\">\n<th id=\"S6.T8.3.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">10,000</th>\n<td id=\"S6.T8.3.3.1\" class=\"ltx_td ltx_align_center\">219.0 <math id=\"S6.T8.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S6.T8.3.3.1.m1.1a\"><mo id=\"S6.T8.3.3.1.m1.1.1\" xref=\"S6.T8.3.3.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S6.T8.3.3.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S6.T8.3.3.1.m1.1.1.cmml\" xref=\"S6.T8.3.3.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T8.3.3.1.m1.1c\">\\pm</annotation></semantics></math> 2.3</td>\n</tr>\n<tr id=\"S6.T8.4.4\" class=\"ltx_tr\">\n<th id=\"S6.T8.4.4.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\">50,000</th>\n<td id=\"S6.T8.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">1103.7 <math id=\"S6.T8.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S6.T8.4.4.1.m1.1a\"><mo id=\"S6.T8.4.4.1.m1.1.1\" xref=\"S6.T8.4.4.1.m1.1.1.cmml\">±</mo><annotation-xml encoding=\"MathML-Content\" id=\"S6.T8.4.4.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S6.T8.4.4.1.m1.1.1.cmml\" xref=\"S6.T8.4.4.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T8.4.4.1.m1.1c\">\\pm</annotation></semantics></math> 11.3</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "The number of clients processed at each round is a variable we can control on FLUTE. Here, we show in Table 8 a simulation with 1 server + 3 workers attached to RTX A6000 GPUs and 2.45GHz AMD EPYC cores for varying number of clients per iteration. Since clients are processed sequentially by each worker, runtime scales linearly. FLUTE also provides options for further speed-ups by processing clients in multiple threads and pre-encoding the data.",
            "Table 8 shows that FLUTE scales gracefully the number of clients per iteration, without any upper bound to that number. We can also look at the predictive performance attained for different numbers of clients, and study how it changes as a function of the optimizer used."
        ]
    },
    "S6.T9": {
        "caption": "Table 9: Next-word Prediction task: Top-1 accuracy achieved varying number of clients and optimizers.",
        "table": "<table id=\"S6.T9.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T9.1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S6.T9.1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\">Num. of Clients</td>\n<td id=\"S6.T9.1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">Optimizer</td>\n<td id=\"S6.T9.1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">Acc @ 1 (%)</td>\n</tr>\n<tr id=\"S6.T9.1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S6.T9.1.1.3.2.1\" class=\"ltx_td\"></td>\n<td id=\"S6.T9.1.1.3.2.2\" class=\"ltx_td ltx_align_center\">local-server</td>\n<td id=\"S6.T9.1.1.3.2.3\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S6.T9.1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S6.T9.1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_tt\">No Fine-tuning</td>\n<td id=\"S6.T9.1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">Seed Model</td>\n<td id=\"S6.T9.1.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">9.80</td>\n</tr>\n<tr id=\"S6.T9.1.1.5.4\" class=\"ltx_tr\">\n<td id=\"S6.T9.1.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_t\">1k clients/iter</td>\n<td id=\"S6.T9.1.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">SGD-Adam (Baseline)</td>\n<td id=\"S6.T9.1.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">22.70</td>\n</tr>\n<tr id=\"S6.T9.1.1.6.5\" class=\"ltx_tr\">\n<td id=\"S6.T9.1.1.6.5.1\" class=\"ltx_td\"></td>\n<td id=\"S6.T9.1.1.6.5.2\" class=\"ltx_td ltx_align_center\">SGD-RL-based DGA</td>\n<td id=\"S6.T9.1.1.6.5.3\" class=\"ltx_td ltx_align_center\">22.80</td>\n</tr>\n<tr id=\"S6.T9.1.1.7.6\" class=\"ltx_tr\">\n<td id=\"S6.T9.1.1.7.6.1\" class=\"ltx_td ltx_align_center ltx_border_t\">10k clients/iter</td>\n<td id=\"S6.T9.1.1.7.6.2\" class=\"ltx_td ltx_align_center ltx_border_t\">SGD-Adam (Baseline)</td>\n<td id=\"S6.T9.1.1.7.6.3\" class=\"ltx_td ltx_align_center ltx_border_t\">20.80</td>\n</tr>\n<tr id=\"S6.T9.1.1.8.7\" class=\"ltx_tr\">\n<td id=\"S6.T9.1.1.8.7.1\" class=\"ltx_td\"></td>\n<td id=\"S6.T9.1.1.8.7.2\" class=\"ltx_td ltx_align_center\">SGD-LARS</td>\n<td id=\"S6.T9.1.1.8.7.3\" class=\"ltx_td ltx_align_center\">17.00</td>\n</tr>\n<tr id=\"S6.T9.1.1.9.8\" class=\"ltx_tr\">\n<td id=\"S6.T9.1.1.9.8.1\" class=\"ltx_td\"></td>\n<td id=\"S6.T9.1.1.9.8.2\" class=\"ltx_td ltx_align_center\">Adam-LARS</td>\n<td id=\"S6.T9.1.1.9.8.3\" class=\"ltx_td ltx_align_center\">21.40</td>\n</tr>\n<tr id=\"S6.T9.1.1.10.9\" class=\"ltx_tr\">\n<td id=\"S6.T9.1.1.10.9.1\" class=\"ltx_td\"></td>\n<td id=\"S6.T9.1.1.10.9.2\" class=\"ltx_td ltx_align_center\">SGD-LAMB</td>\n<td id=\"S6.T9.1.1.10.9.3\" class=\"ltx_td ltx_align_center\">23.00</td>\n</tr>\n<tr id=\"S6.T9.1.1.11.10\" class=\"ltx_tr\">\n<td id=\"S6.T9.1.1.11.10.1\" class=\"ltx_td ltx_align_center ltx_border_t\">Variable number</td>\n<td id=\"S6.T9.1.1.11.10.2\" class=\"ltx_td ltx_align_center ltx_border_t\">SGD-Adam</td>\n<td id=\"S6.T9.1.1.11.10.3\" class=\"ltx_td ltx_align_center ltx_border_t\">22.30</td>\n</tr>\n<tr id=\"S6.T9.1.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T9.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">\n<math id=\"S6.T9.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"[5k-10k]\" display=\"inline\"><semantics id=\"S6.T9.1.1.1.1.m1.1a\"><mrow id=\"S6.T9.1.1.1.1.m1.1.1.1\" xref=\"S6.T9.1.1.1.1.m1.1.1.2.cmml\"><mo stretchy=\"false\" id=\"S6.T9.1.1.1.1.m1.1.1.1.2\" xref=\"S6.T9.1.1.1.1.m1.1.1.2.1.cmml\">[</mo><mrow id=\"S6.T9.1.1.1.1.m1.1.1.1.1\" xref=\"S6.T9.1.1.1.1.m1.1.1.1.1.cmml\"><mrow id=\"S6.T9.1.1.1.1.m1.1.1.1.1.2\" xref=\"S6.T9.1.1.1.1.m1.1.1.1.1.2.cmml\"><mn id=\"S6.T9.1.1.1.1.m1.1.1.1.1.2.2\" xref=\"S6.T9.1.1.1.1.m1.1.1.1.1.2.2.cmml\">5</mn><mo lspace=\"0em\" rspace=\"0em\" id=\"S6.T9.1.1.1.1.m1.1.1.1.1.2.1\" xref=\"S6.T9.1.1.1.1.m1.1.1.1.1.2.1.cmml\">​</mo><mi id=\"S6.T9.1.1.1.1.m1.1.1.1.1.2.3\" xref=\"S6.T9.1.1.1.1.m1.1.1.1.1.2.3.cmml\">k</mi></mrow><mo id=\"S6.T9.1.1.1.1.m1.1.1.1.1.1\" xref=\"S6.T9.1.1.1.1.m1.1.1.1.1.1.cmml\">−</mo><mrow id=\"S6.T9.1.1.1.1.m1.1.1.1.1.3\" xref=\"S6.T9.1.1.1.1.m1.1.1.1.1.3.cmml\"><mn id=\"S6.T9.1.1.1.1.m1.1.1.1.1.3.2\" xref=\"S6.T9.1.1.1.1.m1.1.1.1.1.3.2.cmml\">10</mn><mo lspace=\"0em\" rspace=\"0em\" id=\"S6.T9.1.1.1.1.m1.1.1.1.1.3.1\" xref=\"S6.T9.1.1.1.1.m1.1.1.1.1.3.1.cmml\">​</mo><mi id=\"S6.T9.1.1.1.1.m1.1.1.1.1.3.3\" xref=\"S6.T9.1.1.1.1.m1.1.1.1.1.3.3.cmml\">k</mi></mrow></mrow><mo stretchy=\"false\" id=\"S6.T9.1.1.1.1.m1.1.1.1.3\" xref=\"S6.T9.1.1.1.1.m1.1.1.2.1.cmml\">]</mo></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T9.1.1.1.1.m1.1b\"><apply id=\"S6.T9.1.1.1.1.m1.1.1.2.cmml\" xref=\"S6.T9.1.1.1.1.m1.1.1.1\"><csymbol cd=\"latexml\" id=\"S6.T9.1.1.1.1.m1.1.1.2.1.cmml\" xref=\"S6.T9.1.1.1.1.m1.1.1.1.2\">delimited-[]</csymbol><apply id=\"S6.T9.1.1.1.1.m1.1.1.1.1.cmml\" xref=\"S6.T9.1.1.1.1.m1.1.1.1.1\"><minus id=\"S6.T9.1.1.1.1.m1.1.1.1.1.1.cmml\" xref=\"S6.T9.1.1.1.1.m1.1.1.1.1.1\"></minus><apply id=\"S6.T9.1.1.1.1.m1.1.1.1.1.2.cmml\" xref=\"S6.T9.1.1.1.1.m1.1.1.1.1.2\"><times id=\"S6.T9.1.1.1.1.m1.1.1.1.1.2.1.cmml\" xref=\"S6.T9.1.1.1.1.m1.1.1.1.1.2.1\"></times><cn type=\"integer\" id=\"S6.T9.1.1.1.1.m1.1.1.1.1.2.2.cmml\" xref=\"S6.T9.1.1.1.1.m1.1.1.1.1.2.2\">5</cn><ci id=\"S6.T9.1.1.1.1.m1.1.1.1.1.2.3.cmml\" xref=\"S6.T9.1.1.1.1.m1.1.1.1.1.2.3\">𝑘</ci></apply><apply id=\"S6.T9.1.1.1.1.m1.1.1.1.1.3.cmml\" xref=\"S6.T9.1.1.1.1.m1.1.1.1.1.3\"><times id=\"S6.T9.1.1.1.1.m1.1.1.1.1.3.1.cmml\" xref=\"S6.T9.1.1.1.1.m1.1.1.1.1.3.1\"></times><cn type=\"integer\" id=\"S6.T9.1.1.1.1.m1.1.1.1.1.3.2.cmml\" xref=\"S6.T9.1.1.1.1.m1.1.1.1.1.3.2\">10</cn><ci id=\"S6.T9.1.1.1.1.m1.1.1.1.1.3.3.cmml\" xref=\"S6.T9.1.1.1.1.m1.1.1.1.1.3.3\">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T9.1.1.1.1.m1.1c\">[5k-10k]</annotation></semantics></math> clients/iter</td>\n<td id=\"S6.T9.1.1.1.2\" class=\"ltx_td ltx_border_bb\"></td>\n<td id=\"S6.T9.1.1.1.3\" class=\"ltx_td ltx_border_bb\"></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "In Table 9 , we compare 4 different scenarios for optimizers, increasing the number of clients, showing that the accuracy remains stable for most of them. However, the Adam optimizer decreases its accuracy as the number of clients increase, compared to SGD-LAMB that reaches a better performance with a larger number of clients."
        ]
    },
    "S6.T10": {
        "caption": "Table 10: Next-word prediction task: Top-1 Accuracy and training rounds to 95% convergence for various central optimizer choices.",
        "table": "<table id=\"S6.T10.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S6.T10.1.1.1\" class=\"ltx_tr\">\n<th id=\"S6.T10.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Optimizer</th>\n<th id=\"S6.T10.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Acc @1 (%)</th>\n<th id=\"S6.T10.1.1.1.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\">Convergence Round</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T10.1.2.1\" class=\"ltx_tr\">\n<td id=\"S6.T10.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_tt\">LAMB</td>\n<td id=\"S6.T10.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">23.10</td>\n<td id=\"S6.T10.1.2.1.3\" class=\"ltx_td ltx_align_right ltx_border_tt\">115</td>\n</tr>\n<tr id=\"S6.T10.1.3.2\" class=\"ltx_tr\">\n<td id=\"S6.T10.1.3.2.1\" class=\"ltx_td ltx_align_left\">ADAM</td>\n<td id=\"S6.T10.1.3.2.2\" class=\"ltx_td ltx_align_center\">22.70</td>\n<td id=\"S6.T10.1.3.2.3\" class=\"ltx_td ltx_align_right\">641</td>\n</tr>\n<tr id=\"S6.T10.1.4.3\" class=\"ltx_tr\">\n<td id=\"S6.T10.1.4.3.1\" class=\"ltx_td ltx_align_left\">SGD</td>\n<td id=\"S6.T10.1.4.3.2\" class=\"ltx_td ltx_align_center\">20.60</td>\n<td id=\"S6.T10.1.4.3.3\" class=\"ltx_td ltx_align_right\">2172</td>\n</tr>\n<tr id=\"S6.T10.1.5.4\" class=\"ltx_tr\">\n<td id=\"S6.T10.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">LARS</td>\n<td id=\"S6.T10.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">17.40</td>\n<td id=\"S6.T10.1.5.4.3\" class=\"ltx_td ltx_align_right ltx_border_bb\">414</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "This experiment of next-word prediction, using the Reddit dataset and baseline LM model described in Section 6.1, explores model training performance for a variety of state-of-the-art optimizer choices. We trained a recurrent language model, fixing the number of clients per round to 1,000, and varying the choice of optimizer in the central aggregator. Specifically, we applied standard SGD Rosenblatt (1958), ADAM Kingma & Ba (2017), LAMB You et al. (2020), and LARS You et al. (2017). Table 10 illustrates the performance of each optimizer, including maximum validation accuracy, and convergence rate: the number of rounds to reach 95% of the max. accuracy. Note there is no hyper-parameter tuning of the optimizers for this experiment."
        ]
    },
    "S6.T11": {
        "caption": "Table 11: Personalization on CIFAR-10: Two sources of non-iidness, (i) Label distribution based on α∈[0.2, 1.0]𝛼0.21.0\\alpha\\in[0.2,\\ 1.0] and (ii) Different image transformations per client. All reported results are in image classification accuracy (%).",
        "table": "<table id=\"S6.T11.6.6\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S6.T11.6.6.7.1\" class=\"ltx_tr\">\n<th id=\"S6.T11.6.6.7.1.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_tt\"></th>\n<th id=\"S6.T11.6.6.7.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Global</th>\n<th id=\"S6.T11.6.6.7.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Local</th>\n<th id=\"S6.T11.6.6.7.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Interp.</th>\n<th id=\"S6.T11.6.6.7.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Rel. Imprv.</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T11.1.1.1\" class=\"ltx_tr\">\n<th id=\"S6.T11.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\">iid (<math id=\"S6.T11.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha=1.0\" display=\"inline\"><semantics id=\"S6.T11.1.1.1.1.m1.1a\"><mrow id=\"S6.T11.1.1.1.1.m1.1.1\" xref=\"S6.T11.1.1.1.1.m1.1.1.cmml\"><mi id=\"S6.T11.1.1.1.1.m1.1.1.2\" xref=\"S6.T11.1.1.1.1.m1.1.1.2.cmml\">α</mi><mo id=\"S6.T11.1.1.1.1.m1.1.1.1\" xref=\"S6.T11.1.1.1.1.m1.1.1.1.cmml\">=</mo><mn id=\"S6.T11.1.1.1.1.m1.1.1.3\" xref=\"S6.T11.1.1.1.1.m1.1.1.3.cmml\">1.0</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T11.1.1.1.1.m1.1b\"><apply id=\"S6.T11.1.1.1.1.m1.1.1.cmml\" xref=\"S6.T11.1.1.1.1.m1.1.1\"><eq id=\"S6.T11.1.1.1.1.m1.1.1.1.cmml\" xref=\"S6.T11.1.1.1.1.m1.1.1.1\"></eq><ci id=\"S6.T11.1.1.1.1.m1.1.1.2.cmml\" xref=\"S6.T11.1.1.1.1.m1.1.1.2\">𝛼</ci><cn type=\"float\" id=\"S6.T11.1.1.1.1.m1.1.1.3.cmml\" xref=\"S6.T11.1.1.1.1.m1.1.1.3\">1.0</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T11.1.1.1.1.m1.1c\">\\alpha=1.0</annotation></semantics></math>)</th>\n<td id=\"S6.T11.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">74.12</td>\n<td id=\"S6.T11.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">46.10</td>\n<td id=\"S6.T11.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">77.72</td>\n<td id=\"S6.T11.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S6.T11.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">13.91</span></td>\n</tr>\n<tr id=\"S6.T11.2.2.2\" class=\"ltx_tr\">\n<th id=\"S6.T11.2.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">non-iid (<math id=\"S6.T11.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha=0.5\" display=\"inline\"><semantics id=\"S6.T11.2.2.2.1.m1.1a\"><mrow id=\"S6.T11.2.2.2.1.m1.1.1\" xref=\"S6.T11.2.2.2.1.m1.1.1.cmml\"><mi id=\"S6.T11.2.2.2.1.m1.1.1.2\" xref=\"S6.T11.2.2.2.1.m1.1.1.2.cmml\">α</mi><mo id=\"S6.T11.2.2.2.1.m1.1.1.1\" xref=\"S6.T11.2.2.2.1.m1.1.1.1.cmml\">=</mo><mn id=\"S6.T11.2.2.2.1.m1.1.1.3\" xref=\"S6.T11.2.2.2.1.m1.1.1.3.cmml\">0.5</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T11.2.2.2.1.m1.1b\"><apply id=\"S6.T11.2.2.2.1.m1.1.1.cmml\" xref=\"S6.T11.2.2.2.1.m1.1.1\"><eq id=\"S6.T11.2.2.2.1.m1.1.1.1.cmml\" xref=\"S6.T11.2.2.2.1.m1.1.1.1\"></eq><ci id=\"S6.T11.2.2.2.1.m1.1.1.2.cmml\" xref=\"S6.T11.2.2.2.1.m1.1.1.2\">𝛼</ci><cn type=\"float\" id=\"S6.T11.2.2.2.1.m1.1.1.3.cmml\" xref=\"S6.T11.2.2.2.1.m1.1.1.3\">0.5</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T11.2.2.2.1.m1.1c\">\\alpha=0.5</annotation></semantics></math>)</th>\n<td id=\"S6.T11.2.2.2.2\" class=\"ltx_td ltx_align_center\">72.33</td>\n<td id=\"S6.T11.2.2.2.3\" class=\"ltx_td ltx_align_center\">54.90</td>\n<td id=\"S6.T11.2.2.2.4\" class=\"ltx_td ltx_align_center\">79.56</td>\n<td id=\"S6.T11.2.2.2.5\" class=\"ltx_td ltx_align_center\"><span id=\"S6.T11.2.2.2.5.1\" class=\"ltx_text ltx_font_bold\">26.13</span></td>\n</tr>\n<tr id=\"S6.T11.3.3.3\" class=\"ltx_tr\">\n<th id=\"S6.T11.3.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">non-iid (<math id=\"S6.T11.3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha=0.2\" display=\"inline\"><semantics id=\"S6.T11.3.3.3.1.m1.1a\"><mrow id=\"S6.T11.3.3.3.1.m1.1.1\" xref=\"S6.T11.3.3.3.1.m1.1.1.cmml\"><mi id=\"S6.T11.3.3.3.1.m1.1.1.2\" xref=\"S6.T11.3.3.3.1.m1.1.1.2.cmml\">α</mi><mo id=\"S6.T11.3.3.3.1.m1.1.1.1\" xref=\"S6.T11.3.3.3.1.m1.1.1.1.cmml\">=</mo><mn id=\"S6.T11.3.3.3.1.m1.1.1.3\" xref=\"S6.T11.3.3.3.1.m1.1.1.3.cmml\">0.2</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T11.3.3.3.1.m1.1b\"><apply id=\"S6.T11.3.3.3.1.m1.1.1.cmml\" xref=\"S6.T11.3.3.3.1.m1.1.1\"><eq id=\"S6.T11.3.3.3.1.m1.1.1.1.cmml\" xref=\"S6.T11.3.3.3.1.m1.1.1.1\"></eq><ci id=\"S6.T11.3.3.3.1.m1.1.1.2.cmml\" xref=\"S6.T11.3.3.3.1.m1.1.1.2\">𝛼</ci><cn type=\"float\" id=\"S6.T11.3.3.3.1.m1.1.1.3.cmml\" xref=\"S6.T11.3.3.3.1.m1.1.1.3\">0.2</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T11.3.3.3.1.m1.1c\">\\alpha=0.2</annotation></semantics></math>)</th>\n<td id=\"S6.T11.3.3.3.2\" class=\"ltx_td ltx_align_center\">69.50</td>\n<td id=\"S6.T11.3.3.3.3\" class=\"ltx_td ltx_align_center\">70.70</td>\n<td id=\"S6.T11.3.3.3.4\" class=\"ltx_td ltx_align_center\">85.43</td>\n<td id=\"S6.T11.3.3.3.5\" class=\"ltx_td ltx_align_center\"><span id=\"S6.T11.3.3.3.5.1\" class=\"ltx_text ltx_font_bold\">52.23</span></td>\n</tr>\n<tr id=\"S6.T11.4.4.4\" class=\"ltx_tr\">\n<th id=\"S6.T11.4.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\">iid (<math id=\"S6.T11.4.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha=1.0\" display=\"inline\"><semantics id=\"S6.T11.4.4.4.1.m1.1a\"><mrow id=\"S6.T11.4.4.4.1.m1.1.1\" xref=\"S6.T11.4.4.4.1.m1.1.1.cmml\"><mi id=\"S6.T11.4.4.4.1.m1.1.1.2\" xref=\"S6.T11.4.4.4.1.m1.1.1.2.cmml\">α</mi><mo id=\"S6.T11.4.4.4.1.m1.1.1.1\" xref=\"S6.T11.4.4.4.1.m1.1.1.1.cmml\">=</mo><mn id=\"S6.T11.4.4.4.1.m1.1.1.3\" xref=\"S6.T11.4.4.4.1.m1.1.1.3.cmml\">1.0</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T11.4.4.4.1.m1.1b\"><apply id=\"S6.T11.4.4.4.1.m1.1.1.cmml\" xref=\"S6.T11.4.4.4.1.m1.1.1\"><eq id=\"S6.T11.4.4.4.1.m1.1.1.1.cmml\" xref=\"S6.T11.4.4.4.1.m1.1.1.1\"></eq><ci id=\"S6.T11.4.4.4.1.m1.1.1.2.cmml\" xref=\"S6.T11.4.4.4.1.m1.1.1.2\">𝛼</ci><cn type=\"float\" id=\"S6.T11.4.4.4.1.m1.1.1.3.cmml\" xref=\"S6.T11.4.4.4.1.m1.1.1.3\">1.0</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T11.4.4.4.1.m1.1c\">\\alpha=1.0</annotation></semantics></math>)</th>\n<td id=\"S6.T11.4.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">51.34</td>\n<td id=\"S6.T11.4.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">46.48</td>\n<td id=\"S6.T11.4.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">62.78</td>\n<td id=\"S6.T11.4.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S6.T11.4.4.4.5.1\" class=\"ltx_text ltx_font_bold\">23.51</span></td>\n</tr>\n<tr id=\"S6.T11.6.6.8.1\" class=\"ltx_tr\">\n<th id=\"S6.T11.6.6.8.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">    + Feat. Transf.</th>\n<td id=\"S6.T11.6.6.8.1.2\" class=\"ltx_td\"></td>\n<td id=\"S6.T11.6.6.8.1.3\" class=\"ltx_td\"></td>\n<td id=\"S6.T11.6.6.8.1.4\" class=\"ltx_td\"></td>\n<td id=\"S6.T11.6.6.8.1.5\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S6.T11.5.5.5\" class=\"ltx_tr\">\n<th id=\"S6.T11.5.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">non-iid (<math id=\"S6.T11.5.5.5.1.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha=0.5\" display=\"inline\"><semantics id=\"S6.T11.5.5.5.1.m1.1a\"><mrow id=\"S6.T11.5.5.5.1.m1.1.1\" xref=\"S6.T11.5.5.5.1.m1.1.1.cmml\"><mi id=\"S6.T11.5.5.5.1.m1.1.1.2\" xref=\"S6.T11.5.5.5.1.m1.1.1.2.cmml\">α</mi><mo id=\"S6.T11.5.5.5.1.m1.1.1.1\" xref=\"S6.T11.5.5.5.1.m1.1.1.1.cmml\">=</mo><mn id=\"S6.T11.5.5.5.1.m1.1.1.3\" xref=\"S6.T11.5.5.5.1.m1.1.1.3.cmml\">0.5</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T11.5.5.5.1.m1.1b\"><apply id=\"S6.T11.5.5.5.1.m1.1.1.cmml\" xref=\"S6.T11.5.5.5.1.m1.1.1\"><eq id=\"S6.T11.5.5.5.1.m1.1.1.1.cmml\" xref=\"S6.T11.5.5.5.1.m1.1.1.1\"></eq><ci id=\"S6.T11.5.5.5.1.m1.1.1.2.cmml\" xref=\"S6.T11.5.5.5.1.m1.1.1.2\">𝛼</ci><cn type=\"float\" id=\"S6.T11.5.5.5.1.m1.1.1.3.cmml\" xref=\"S6.T11.5.5.5.1.m1.1.1.3\">0.5</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T11.5.5.5.1.m1.1c\">\\alpha=0.5</annotation></semantics></math>)</th>\n<td id=\"S6.T11.5.5.5.2\" class=\"ltx_td ltx_align_center\">49.40</td>\n<td id=\"S6.T11.5.5.5.3\" class=\"ltx_td ltx_align_center\">54.57</td>\n<td id=\"S6.T11.5.5.5.4\" class=\"ltx_td ltx_align_center\">67.60</td>\n<td id=\"S6.T11.5.5.5.5\" class=\"ltx_td ltx_align_center\"><span id=\"S6.T11.5.5.5.5.1\" class=\"ltx_text ltx_font_bold\">35.97</span></td>\n</tr>\n<tr id=\"S6.T11.6.6.9.2\" class=\"ltx_tr\">\n<th id=\"S6.T11.6.6.9.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">    + Feat. Transf.</th>\n<td id=\"S6.T11.6.6.9.2.2\" class=\"ltx_td\"></td>\n<td id=\"S6.T11.6.6.9.2.3\" class=\"ltx_td\"></td>\n<td id=\"S6.T11.6.6.9.2.4\" class=\"ltx_td\"></td>\n<td id=\"S6.T11.6.6.9.2.5\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S6.T11.6.6.6\" class=\"ltx_tr\">\n<th id=\"S6.T11.6.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">non-iid (<math id=\"S6.T11.6.6.6.1.m1.1\" class=\"ltx_Math\" alttext=\"\\alpha=0.2\" display=\"inline\"><semantics id=\"S6.T11.6.6.6.1.m1.1a\"><mrow id=\"S6.T11.6.6.6.1.m1.1.1\" xref=\"S6.T11.6.6.6.1.m1.1.1.cmml\"><mi id=\"S6.T11.6.6.6.1.m1.1.1.2\" xref=\"S6.T11.6.6.6.1.m1.1.1.2.cmml\">α</mi><mo id=\"S6.T11.6.6.6.1.m1.1.1.1\" xref=\"S6.T11.6.6.6.1.m1.1.1.1.cmml\">=</mo><mn id=\"S6.T11.6.6.6.1.m1.1.1.3\" xref=\"S6.T11.6.6.6.1.m1.1.1.3.cmml\">0.2</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T11.6.6.6.1.m1.1b\"><apply id=\"S6.T11.6.6.6.1.m1.1.1.cmml\" xref=\"S6.T11.6.6.6.1.m1.1.1\"><eq id=\"S6.T11.6.6.6.1.m1.1.1.1.cmml\" xref=\"S6.T11.6.6.6.1.m1.1.1.1\"></eq><ci id=\"S6.T11.6.6.6.1.m1.1.1.2.cmml\" xref=\"S6.T11.6.6.6.1.m1.1.1.2\">𝛼</ci><cn type=\"float\" id=\"S6.T11.6.6.6.1.m1.1.1.3.cmml\" xref=\"S6.T11.6.6.6.1.m1.1.1.3\">0.2</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T11.6.6.6.1.m1.1c\">\\alpha=0.2</annotation></semantics></math>)</th>\n<td id=\"S6.T11.6.6.6.2\" class=\"ltx_td ltx_align_center\">47.55</td>\n<td id=\"S6.T11.6.6.6.3\" class=\"ltx_td ltx_align_center\">70.90</td>\n<td id=\"S6.T11.6.6.6.4\" class=\"ltx_td ltx_align_center\">77.45</td>\n<td id=\"S6.T11.6.6.6.5\" class=\"ltx_td ltx_align_center\"><span id=\"S6.T11.6.6.6.5.1\" class=\"ltx_text ltx_font_bold\">57.01</span></td>\n</tr>\n<tr id=\"S6.T11.6.6.10.3\" class=\"ltx_tr\">\n<th id=\"S6.T11.6.6.10.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">    + Feat. Transf.</th>\n<td id=\"S6.T11.6.6.10.3.2\" class=\"ltx_td ltx_border_bb\"></td>\n<td id=\"S6.T11.6.6.10.3.3\" class=\"ltx_td ltx_border_bb\"></td>\n<td id=\"S6.T11.6.6.10.3.4\" class=\"ltx_td ltx_border_bb\"></td>\n<td id=\"S6.T11.6.6.10.3.5\" class=\"ltx_td ltx_border_bb\"></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "The CIFAR-10 task is used for the personalization experiments, splitting the data across 100 clients, and sampling 10 clients per iteration. The client data are split according to the process described in He et al. (2020), with α∈[0.2, 1.0]𝛼0.21.0\\alpha\\in[0.2,\\ 1.0] for the Dirichlet label distribution (client distributions are more iid when the α𝛼\\alpha values are larger). In addition to the label distributions, we investigate different feature distributions by applying locally different image transformations (per each client). For this experiment, we fix the test samples to match the local training data/label distributions, i.e. we split the test set to follow similar local label distributions as the training samples. The image transformations are unique per client for both the training and test samples, when applicable. Herein, we investigate 3 different training strategies, i.e. a global model trained with DGA, local models trained with SGD and the convex interpolation of these two, as described in Section 4.4.\nThe relative performance improvement shown in Table 11 is between the global and the interpolated models."
        ]
    }
}