{
    "id_table_1": {
        "caption": "TABLE I :  Quantitative Metrics Comparison between different Reconstruction Methods on Simulated Data with added Gaussian Noise  CN  N  ( 0 , 0.1 ) similar-to CN N 0 0.1 \\text{CN}\\sim\\mathcal{N}(0,0.1) CN  caligraphic_N ( 0 , 0.1 )",
        "table": "S5.T1.5",
        "footnotes": [],
        "references": [
            "We utilize a monostatic time domain Ultra-WideBand (UWB) Impulse Radar P440  [ 30 ]  with time windowing capabilities for sensing, allowing us to exclude unwanted signal reflections and conduct indoor measurements without costly anechoic chambers. It operates from 3.1 to 4.8 GHz frequency centering at 4.3 GHz. Figure  1  illustrates the radar hardware and the measurement setup. Our ISAR imaging measurement in an ordinary room employs the UWB radar positioned at a fixed location, using coherent pulse integration to enhance the signal-to-noise ratio, with the radar sampling rate exceeding the maximum Doppler extent for coherent processing into unaliased ISAR image. The procedure involves placing the object of interest on a rotating table in front of the radar system. We leverage JAYEGT  [ 21 ] , an electronically motorized turn-table for placing the target object and getting a steady rotational motion. Additionally, we demonstrate the feasibility of collecting data with a standard floor cleaning robot by integrating supplementary circuitry (costing approximately $10)  [ 22 ] , which incorporates an ESP32 chip with Bluetooth functionality.",
            "To generate synthetic radar sinograms depicting various point targets, we employ Equation  1 . Four distinct synthetic scenarios were simulated, each containing single, double, triple, and quadruple targets within the scene. The corresponding results are presented in Figure  4 . ATS demonstrates qualitative consistency with BP, exhibiting accurate scene reconstruction in noise-free conditions and superior performance in noisy conditions. BP, on the other hand, shows strong artifacts around the corners of each reconstructed scene when noise is added."
        ]
    },
    "id_table_2": {
        "caption": "",
        "table": "S6.F6.12.12",
        "footnotes": [],
        "references": [
            "After acquiring the measurements (i.e. sinograms), our reconstruction process employs an analysis-through-synthesis optimization technique, leveraging an implicit neural representation (INR) similar to NeRF, in traditional view synthesis. Figure  2  shows our proposed analysis-through-synthesis (ATS) pipeline. At first, the scene coordinates are sampled using our spherical sampling scheme for a given sensor position. Then the sampled scene is passed through a multi-resolution hash encoding block similar to Instant-NGP  [ 31 ]  for generating the positional embedding  v v v italic_v  from each coordinate. It uses hash functions to generate varied positional embedding, capturing relative positions in a sequence at different resolutions. In contrast to positional encoding, the multi-resolution approach allows a more dynamic and flexible representation of positional information. Then the encoded coordinates are fed into the NeRF neural network of four fully connected layers, referred to as the neural backprojection network  N B  P subscript N B P \\mathcal{N}_{BP} caligraphic_N start_POSTSUBSCRIPT italic_B italic_P end_POSTSUBSCRIPT , parameterized by weights   B  P subscript  B P \\theta_{BP} italic_ start_POSTSUBSCRIPT italic_B italic_P end_POSTSUBSCRIPT . Through this network, we predict the complex scattering function    superscript   \\sigma^{\\prime} italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  in the estimated scene  F   ( v ) subscript F  v F_{\\theta}(v) italic_F start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_v ) . More precisely, the network characterizes the scatterers at each location of the scene. The scatterers within the scene are subsequently employed to generate radar measurements (each scan in the sinogram) through our differentiable forward model described in section  IV-A . Training the network involves minimizing the loss between the synthesized measurements  M  ( F   ( v ) ) M subscript F  v M(F_{\\theta}(v)) italic_M ( italic_F start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT ( italic_v ) )  and actual radar measurements  y y y italic_y  for each scan of the sinogram. In short, by employing a neural network, we predict scene scatterers, and then by employing a differentiable forward model, we synthesize radar measurements over time."
        ]
    },
    "id_table_3": {
        "caption": "",
        "table": "S6.F7.9",
        "footnotes": [],
        "references": [
            "Figure  3  illustrates the forward model geometry, with transmitter and receiver origins designated as  o T subscript o T o_{T} italic_o start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT  and  o R subscript o R o_{R} italic_o start_POSTSUBSCRIPT italic_R end_POSTSUBSCRIPT  respectively.  b T  ( x ) subscript b T x b_{T}(x) italic_b start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ( italic_x )  represents the directivity function for the transmitter and  T  ( o T , x ) T subscript o T x T(o_{T},x) italic_T ( italic_o start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT , italic_x )  is defined as the transmission probability between a point in the scene and the origins of the transmitter and receiver respectively, accounting for occlusion effects in our model.",
            "In Figure  3  each green semi-circle corresponds to a constant time-of-flight  t = 2  R / c t 2 R c t=2R/c italic_t = 2 italic_R / italic_c  which forms a sphere. This sphere is centered where the transmitter and receiver antennas coincide ( O T  O R similar-to-or-equals subscript O T subscript O R O_{T}\\simeq O_{R} italic_O start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT  italic_O start_POSTSUBSCRIPT italic_R end_POSTSUBSCRIPT ), with a radius of  R = c  t / 2 R c t 2 R=ct/2 italic_R = italic_c italic_t / 2 . The equation representing this sphere is:"
        ]
    },
    "id_table_4": {
        "caption": "",
        "table": "S6.F8.12",
        "footnotes": [],
        "references": [
            "where  l i subscript l i l_{i} italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  represents the depth samples along the ray calculated at which a ray intersects the sphere by substituting the ray into Equation  4 . This substitution results in a quadratic equation from which we extract the positive root:",
            "To generate synthetic radar sinograms depicting various point targets, we employ Equation  1 . Four distinct synthetic scenarios were simulated, each containing single, double, triple, and quadruple targets within the scene. The corresponding results are presented in Figure  4 . ATS demonstrates qualitative consistency with BP, exhibiting accurate scene reconstruction in noise-free conditions and superior performance in noisy conditions. BP, on the other hand, shows strong artifacts around the corners of each reconstructed scene when noise is added."
        ]
    },
    "id_table_5": {
        "caption": "",
        "table": "S7.F9.12.12",
        "footnotes": [],
        "references": [
            "Figures  5(a)  and  5(b)  illustrate the influence of sparse measurements in terms of skip angles on PSNR and LPIPS metrics, respectively, for both BP and ATS across varying numbers of simulated targets. With an increasing number of targets, PSNR tends to decrease for both BP and ATS; however, ATS consistently maintains higher PSNR values compared to BP across all skip angles except for the single reflector case where the PSNR difference is less than 0.4. Similarly, ATS exhibits lower LPIPS values compared to BP across all skip angles, indicating superior performance in scenarios with limited measurements."
        ]
    }
}