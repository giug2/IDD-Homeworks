{
    "PAPER'S NUMBER OF TABLES": 6,
    "S1.T1": {
        "caption": "Table 1. Comparison of typical FGL works and HiFGL in the dimension of Multi-level Privacy Preservation (including Subgraph-level and Node-level), Information Integrity, and Efficiency. We evaluate properties by Low, Medium, or High by considering how much a framework satisfies requirements relatively among baselines.\n",
        "table": "<table id=\"S1.T1.17\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S1.T1.17.1\" class=\"ltx_tr\">\n<td id=\"S1.T1.17.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">Model</td>\n<td id=\"S1.T1.17.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">FGL Paradigm</td>\n<td id=\"S1.T1.17.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\">Multi-level Privacy Preservation</td>\n<td id=\"S1.T1.17.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">Information Integrity</td>\n<td id=\"S1.T1.17.1.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">Efficiency</td>\n</tr>\n<tr id=\"S1.T1.17.2\" class=\"ltx_tr\">\n<td id=\"S1.T1.17.2.1\" class=\"ltx_td ltx_border_r\"></td>\n<td id=\"S1.T1.17.2.2\" class=\"ltx_td\"></td>\n<td id=\"S1.T1.17.2.3\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.17.2.3.1\" class=\"ltx_text ltx_font_italic\">Subgraph-level</span></td>\n<td id=\"S1.T1.17.2.4\" class=\"ltx_td ltx_align_center\"><span id=\"S1.T1.17.2.4.1\" class=\"ltx_text ltx_font_italic\">Node-level</span></td>\n<td id=\"S1.T1.17.2.5\" class=\"ltx_td\"></td>\n<td id=\"S1.T1.17.2.6\" class=\"ltx_td\"></td>\n</tr>\n<tr id=\"S1.T1.17.3\" class=\"ltx_tr\">\n<td id=\"S1.T1.17.3.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">GCN <cite class=\"ltx_cite ltx_citemacro_citep\">(Kipf and Welling, <a href=\"#bib.bib14\" title=\"\" class=\"ltx_ref\">2016</a>)</cite>+FedAvg <cite class=\"ltx_cite ltx_citemacro_citep\">(McMahan et al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib23\" title=\"\" class=\"ltx_ref\">2017</a>)</cite>\n</td>\n<td id=\"S1.T1.17.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Cross-silo</td>\n<td id=\"S1.T1.17.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">Medium</td>\n<td id=\"S1.T1.17.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">Low</td>\n<td id=\"S1.T1.17.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">Medium</td>\n<td id=\"S1.T1.17.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\">High</td>\n</tr>\n<tr id=\"S1.T1.17.4\" class=\"ltx_tr\">\n<td id=\"S1.T1.17.4.1\" class=\"ltx_td ltx_align_center ltx_border_r\">FedSage+ <cite class=\"ltx_cite ltx_citemacro_citep\">(Zhang et al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib41\" title=\"\" class=\"ltx_ref\">2021c</a>)</cite>\n</td>\n<td id=\"S1.T1.17.4.2\" class=\"ltx_td ltx_align_center\">Cross-silo</td>\n<td id=\"S1.T1.17.4.3\" class=\"ltx_td ltx_align_center\">Medium</td>\n<td id=\"S1.T1.17.4.4\" class=\"ltx_td ltx_align_center\">Low</td>\n<td id=\"S1.T1.17.4.5\" class=\"ltx_td ltx_align_center\">Medium</td>\n<td id=\"S1.T1.17.4.6\" class=\"ltx_td ltx_align_center\">Low</td>\n</tr>\n<tr id=\"S1.T1.17.5\" class=\"ltx_tr\">\n<td id=\"S1.T1.17.5.1\" class=\"ltx_td ltx_align_center ltx_border_r\">FedPUB <cite class=\"ltx_cite ltx_citemacro_citep\">(Baek et al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib3\" title=\"\" class=\"ltx_ref\">2023</a>)</cite>\n</td>\n<td id=\"S1.T1.17.5.2\" class=\"ltx_td ltx_align_center\">Cross-silo</td>\n<td id=\"S1.T1.17.5.3\" class=\"ltx_td ltx_align_center\">Medium</td>\n<td id=\"S1.T1.17.5.4\" class=\"ltx_td ltx_align_center\">Low</td>\n<td id=\"S1.T1.17.5.5\" class=\"ltx_td ltx_align_center\">Medium</td>\n<td id=\"S1.T1.17.5.6\" class=\"ltx_td ltx_align_center\">Medium</td>\n</tr>\n<tr id=\"S1.T1.17.6\" class=\"ltx_tr\">\n<td id=\"S1.T1.17.6.1\" class=\"ltx_td ltx_align_center ltx_border_r\">GraphFL <cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib32\" title=\"\" class=\"ltx_ref\">2022b</a>)</cite>\n</td>\n<td id=\"S1.T1.17.6.2\" class=\"ltx_td ltx_align_center\">Cross-silo</td>\n<td id=\"S1.T1.17.6.3\" class=\"ltx_td ltx_align_center\">Medium</td>\n<td id=\"S1.T1.17.6.4\" class=\"ltx_td ltx_align_center\">Low</td>\n<td id=\"S1.T1.17.6.5\" class=\"ltx_td ltx_align_center\">Medium</td>\n<td id=\"S1.T1.17.6.6\" class=\"ltx_td ltx_align_center\">Medium</td>\n</tr>\n<tr id=\"S1.T1.17.7\" class=\"ltx_tr\">\n<td id=\"S1.T1.17.7.1\" class=\"ltx_td ltx_align_center ltx_border_r\">FedGraph <cite class=\"ltx_cite ltx_citemacro_citep\">(Chen et al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib5\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>\n</td>\n<td id=\"S1.T1.17.7.2\" class=\"ltx_td ltx_align_center\">Cross-silo</td>\n<td id=\"S1.T1.17.7.3\" class=\"ltx_td ltx_align_center\">High</td>\n<td id=\"S1.T1.17.7.4\" class=\"ltx_td ltx_align_center\">Low</td>\n<td id=\"S1.T1.17.7.5\" class=\"ltx_td ltx_align_center\">High</td>\n<td id=\"S1.T1.17.7.6\" class=\"ltx_td ltx_align_center\">Low</td>\n</tr>\n<tr id=\"S1.T1.17.8\" class=\"ltx_tr\">\n<td id=\"S1.T1.17.8.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Glint <cite class=\"ltx_cite ltx_citemacro_citep\">(Liu et al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib20\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>\n</td>\n<td id=\"S1.T1.17.8.2\" class=\"ltx_td ltx_align_center\">Cross-silo</td>\n<td id=\"S1.T1.17.8.3\" class=\"ltx_td ltx_align_center\">Low</td>\n<td id=\"S1.T1.17.8.4\" class=\"ltx_td ltx_align_center\">High</td>\n<td id=\"S1.T1.17.8.5\" class=\"ltx_td ltx_align_center\">High</td>\n<td id=\"S1.T1.17.8.6\" class=\"ltx_td ltx_align_center\">Medium</td>\n</tr>\n<tr id=\"S1.T1.17.9\" class=\"ltx_tr\">\n<td id=\"S1.T1.17.9.1\" class=\"ltx_td ltx_align_center ltx_border_r\">PPSGCN <cite class=\"ltx_cite ltx_citemacro_citep\">(Zhang et al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib40\" title=\"\" class=\"ltx_ref\">2021b</a>)</cite>\n</td>\n<td id=\"S1.T1.17.9.2\" class=\"ltx_td ltx_align_center\">Cross-silo</td>\n<td id=\"S1.T1.17.9.3\" class=\"ltx_td ltx_align_center\">Medium</td>\n<td id=\"S1.T1.17.9.4\" class=\"ltx_td ltx_align_center\">Low</td>\n<td id=\"S1.T1.17.9.5\" class=\"ltx_td ltx_align_center\">High</td>\n<td id=\"S1.T1.17.9.6\" class=\"ltx_td ltx_align_center\">Low</td>\n</tr>\n<tr id=\"S1.T1.17.10\" class=\"ltx_tr\">\n<td id=\"S1.T1.17.10.1\" class=\"ltx_td ltx_align_center ltx_border_r\">FedCog <cite class=\"ltx_cite ltx_citemacro_citep\">(Lei et al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib15\" title=\"\" class=\"ltx_ref\">2023</a>)</cite>\n</td>\n<td id=\"S1.T1.17.10.2\" class=\"ltx_td ltx_align_center\">Cross-silo</td>\n<td id=\"S1.T1.17.10.3\" class=\"ltx_td ltx_align_center\">Medium</td>\n<td id=\"S1.T1.17.10.4\" class=\"ltx_td ltx_align_center\">Low</td>\n<td id=\"S1.T1.17.10.5\" class=\"ltx_td ltx_align_center\">High</td>\n<td id=\"S1.T1.17.10.6\" class=\"ltx_td ltx_align_center\">Low</td>\n</tr>\n<tr id=\"S1.T1.17.11\" class=\"ltx_tr\">\n<td id=\"S1.T1.17.11.1\" class=\"ltx_td ltx_align_center ltx_border_r\">CNFGNN <cite class=\"ltx_cite ltx_citemacro_citep\">(Meng et al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib24\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>\n</td>\n<td id=\"S1.T1.17.11.2\" class=\"ltx_td ltx_align_center\">Cross-device</td>\n<td id=\"S1.T1.17.11.3\" class=\"ltx_td ltx_align_center\">-</td>\n<td id=\"S1.T1.17.11.4\" class=\"ltx_td ltx_align_center\">Medium</td>\n<td id=\"S1.T1.17.11.5\" class=\"ltx_td ltx_align_center\">High</td>\n<td id=\"S1.T1.17.11.6\" class=\"ltx_td ltx_align_center\">Medium</td>\n</tr>\n<tr id=\"S1.T1.17.12\" class=\"ltx_tr\">\n<td id=\"S1.T1.17.12.1\" class=\"ltx_td ltx_align_center ltx_border_r\">FedPerGNN <cite class=\"ltx_cite ltx_citemacro_citep\">(Wu et al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib34\" title=\"\" class=\"ltx_ref\">2022</a>)</cite>\n</td>\n<td id=\"S1.T1.17.12.2\" class=\"ltx_td ltx_align_center\">Cross-device</td>\n<td id=\"S1.T1.17.12.3\" class=\"ltx_td ltx_align_center\">-</td>\n<td id=\"S1.T1.17.12.4\" class=\"ltx_td ltx_align_center\">High</td>\n<td id=\"S1.T1.17.12.5\" class=\"ltx_td ltx_align_center\">High</td>\n<td id=\"S1.T1.17.12.6\" class=\"ltx_td ltx_align_center\">Low</td>\n</tr>\n<tr id=\"S1.T1.17.13\" class=\"ltx_tr\">\n<td id=\"S1.T1.17.13.1\" class=\"ltx_td ltx_align_center ltx_border_r\">FedWalk <cite class=\"ltx_cite ltx_citemacro_citep\">(Pan and Zhu, <a href=\"#bib.bib26\" title=\"\" class=\"ltx_ref\">2022</a>)</cite>\n</td>\n<td id=\"S1.T1.17.13.2\" class=\"ltx_td ltx_align_center\">Cross-device</td>\n<td id=\"S1.T1.17.13.3\" class=\"ltx_td ltx_align_center\">-</td>\n<td id=\"S1.T1.17.13.4\" class=\"ltx_td ltx_align_center\">High</td>\n<td id=\"S1.T1.17.13.5\" class=\"ltx_td ltx_align_center\">High</td>\n<td id=\"S1.T1.17.13.6\" class=\"ltx_td ltx_align_center\">Medium</td>\n</tr>\n<tr id=\"S1.T1.17.14\" class=\"ltx_tr\">\n<td id=\"S1.T1.17.14.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Lumos <cite class=\"ltx_cite ltx_citemacro_citep\">(Pan et al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib27\" title=\"\" class=\"ltx_ref\">2023</a>)</cite>\n</td>\n<td id=\"S1.T1.17.14.2\" class=\"ltx_td ltx_align_center\">Cross-device</td>\n<td id=\"S1.T1.17.14.3\" class=\"ltx_td ltx_align_center\">-</td>\n<td id=\"S1.T1.17.14.4\" class=\"ltx_td ltx_align_center\">High</td>\n<td id=\"S1.T1.17.14.5\" class=\"ltx_td ltx_align_center\">High</td>\n<td id=\"S1.T1.17.14.6\" class=\"ltx_td ltx_align_center\">Low</td>\n</tr>\n<tr id=\"S1.T1.17.15\" class=\"ltx_tr\">\n<td id=\"S1.T1.17.15.1\" class=\"ltx_td ltx_align_center ltx_border_r\">SemiDFEGL <cite class=\"ltx_cite ltx_citemacro_citep\">(Qu et al<span class=\"ltx_text\">.</span>, <a href=\"#bib.bib28\" title=\"\" class=\"ltx_ref\">2023</a>)</cite>\n</td>\n<td id=\"S1.T1.17.15.2\" class=\"ltx_td ltx_align_center\">Cross-device</td>\n<td id=\"S1.T1.17.15.3\" class=\"ltx_td ltx_align_center\">-</td>\n<td id=\"S1.T1.17.15.4\" class=\"ltx_td ltx_align_center\">High</td>\n<td id=\"S1.T1.17.15.5\" class=\"ltx_td ltx_align_center\">High</td>\n<td id=\"S1.T1.17.15.6\" class=\"ltx_td ltx_align_center\">Medium</td>\n</tr>\n<tr id=\"S1.T1.17.16\" class=\"ltx_tr\">\n<td id=\"S1.T1.17.16.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\"><span id=\"S1.T1.17.16.1.1\" class=\"ltx_text ltx_font_bold\">HiFGL (Ours)</span></td>\n<td id=\"S1.T1.17.16.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">Cross-silo Cross-device (Both)</td>\n<td id=\"S1.T1.17.16.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">High</td>\n<td id=\"S1.T1.17.16.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">High</td>\n<td id=\"S1.T1.17.16.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">High</td>\n<td id=\"S1.T1.17.16.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\">Medium</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Existing FGL approaches predominantly revolve around two paradigms (Huang et al., 2022).\n1) Cross-silo FGL (Zhang et al., 2021c; Baek et al., 2023; Wang et al., 2022b), as illustrated in Figure 1 (a), formulates data silos as clients, each of which possessing a subgraph consists of nodes and connected edges. This paradigm is particularly relevant for institutions wishing to maintain private subgraphs while contributing to a global graph structure, such as cross-platform recommendation for E-commerce (Lin et al., 2019).\n2) Cross-device FGL (Meng et al., 2021; Wu et al., 2022; Pan and Zhu, 2022), as shown in Figure 1 (b), regards each device as a client, which holding a node and its associated edges. It is more suitable for scenarios where numerous devices maintain private connections within a global graph, e.g., user-centric social networks (Qu et al., 2023).\nTable 1 summarizes the privacy, utility, and efficiency tradeoff of existing FGL approaches.",
            "To bridge the gap, we investigate the cross-silo cross-device federated graph learning problem, where institutions and customer devices collaboratively optimize a GNN model under their diverged privacy constraints.\nHowever, three major technical challenges arise.\n1) Inherent hierarchy and heterogeneity of decentralized clients.\nThe participants in cross-silo cross-device FGL naturally form a hierarchy, where an institution client may have a more comprehensive local structure of devices, and devices may preserve their local sensitive features.\nBesides, the cross-silo cross-device FGL involves clients with varying computational capabilities. Such hierarchy and heterogeneity pose significant challenges in designing a unified FGL framework that can effectively operate across a varied landscape.\n2) Diversified privacy constraints in different clients.\nAs depicted in Table 1, privacy concerns in FGL vary across different types of clients.\nIn a word, cross-silo FGL focuses more on subgraph-level privacy (i.e., the privacy of structures), while cross-device FGL weighs more on node-level privacy (i.e., the privacy of features).\nThe varied privacy requirements necessitate a flexible approach that can adapt to the specific needs of different types of clients while ensuring the overall utility of the federated graph learning process.\n3) Cross-client graph integrity.\nIn FGL, each client contributes to a portion of the overall graph. Maintaining the integrity of graph data across multiple clients is critical to the utility of the joint model.\nHowever, it is a non-trivial task to protect the cross-client graph information without sacrificing the model performance.\nFor example, FedSage+ (Zhang et al., 2021c) protects cross-silo structures by generatively approximating edges across local subgraphs, while Glint (Liu et al., 2021) chooses to expose node embeddings to guarantee model utility.\nIt is challenging to preserve graph privacy without sacrificing graph integrity."
        ]
    },
    "S5.T2": {
        "caption": "Table 2. Overall information of datasets",
        "table": "<table id=\"S5.T2.5\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S5.T2.5.6\" class=\"ltx_tr\">\n<td id=\"S5.T2.5.6.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">Datasets</td>\n<td id=\"S5.T2.5.6.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">Cora</td>\n<td id=\"S5.T2.5.6.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">CiteSeer</td>\n<td id=\"S5.T2.5.6.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">PubMed</td>\n</tr>\n<tr id=\"S5.T2.5.7\" class=\"ltx_tr\">\n<td id=\"S5.T2.5.7.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Split Method</td>\n<td id=\"S5.T2.5.7.2\" class=\"ltx_td ltx_align_center\">Random</td>\n<td id=\"S5.T2.5.7.3\" class=\"ltx_td ltx_align_center\">Random</td>\n<td id=\"S5.T2.5.7.4\" class=\"ltx_td ltx_align_center\">Random</td>\n</tr>\n<tr id=\"S5.T2.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<math id=\"S5.T2.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\#\" display=\"inline\"><semantics id=\"S5.T2.1.1.1.m1.1a\"><mi mathvariant=\"normal\" id=\"S5.T2.1.1.1.m1.1.1\" xref=\"S5.T2.1.1.1.m1.1.1.cmml\">#</mi><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.1.1.1.m1.1b\"><ci id=\"S5.T2.1.1.1.m1.1.1.cmml\" xref=\"S5.T2.1.1.1.m1.1.1\">#</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.1.1.1.m1.1c\">\\#</annotation></semantics></math> of Silo-clients</td>\n<td id=\"S5.T2.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">5</td>\n<td id=\"S5.T2.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">5</td>\n<td id=\"S5.T2.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">5</td>\n</tr>\n<tr id=\"S5.T2.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T2.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<math id=\"S5.T2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\#\" display=\"inline\"><semantics id=\"S5.T2.2.2.1.m1.1a\"><mi mathvariant=\"normal\" id=\"S5.T2.2.2.1.m1.1.1\" xref=\"S5.T2.2.2.1.m1.1.1.cmml\">#</mi><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.2.2.1.m1.1b\"><ci id=\"S5.T2.2.2.1.m1.1.1.cmml\" xref=\"S5.T2.2.2.1.m1.1.1\">#</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.2.2.1.m1.1c\">\\#</annotation></semantics></math> of Node</td>\n<td id=\"S5.T2.2.2.2\" class=\"ltx_td ltx_align_center\">542</td>\n<td id=\"S5.T2.2.2.3\" class=\"ltx_td ltx_align_center\">665</td>\n<td id=\"S5.T2.2.2.4\" class=\"ltx_td ltx_align_center\">3943</td>\n</tr>\n<tr id=\"S5.T2.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T2.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"S5.T2.3.3.1.2\" class=\"ltx_text\"></span> <span id=\"S5.T2.3.3.1.1\" class=\"ltx_text\">\n<span id=\"S5.T2.3.3.1.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S5.T2.3.3.1.1.1.1\" class=\"ltx_tr\">\n<span id=\"S5.T2.3.3.1.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><math id=\"S5.T2.3.3.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\#\" display=\"inline\"><semantics id=\"S5.T2.3.3.1.1.1.1.1.m1.1a\"><mi mathvariant=\"normal\" id=\"S5.T2.3.3.1.1.1.1.1.m1.1.1\" xref=\"S5.T2.3.3.1.1.1.1.1.m1.1.1.cmml\">#</mi><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.3.3.1.1.1.1.1.m1.1b\"><ci id=\"S5.T2.3.3.1.1.1.1.1.m1.1.1.cmml\" xref=\"S5.T2.3.3.1.1.1.1.1.m1.1.1\">#</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.3.3.1.1.1.1.1.m1.1c\">\\#</annotation></semantics></math> of Intra-client Edges</span></span>\n</span></span><span id=\"S5.T2.3.3.1.3\" class=\"ltx_text\"></span>\n</td>\n<td id=\"S5.T2.3.3.2\" class=\"ltx_td ltx_align_center\">431</td>\n<td id=\"S5.T2.3.3.3\" class=\"ltx_td ltx_align_center\">183</td>\n<td id=\"S5.T2.3.3.4\" class=\"ltx_td ltx_align_center\">1772</td>\n</tr>\n<tr id=\"S5.T2.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T2.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<span id=\"S5.T2.4.4.1.2\" class=\"ltx_text\"></span> <span id=\"S5.T2.4.4.1.1\" class=\"ltx_text\">\n<span id=\"S5.T2.4.4.1.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S5.T2.4.4.1.1.1.1\" class=\"ltx_tr\">\n<span id=\"S5.T2.4.4.1.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><math id=\"S5.T2.4.4.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\#\" display=\"inline\"><semantics id=\"S5.T2.4.4.1.1.1.1.1.m1.1a\"><mi mathvariant=\"normal\" id=\"S5.T2.4.4.1.1.1.1.1.m1.1.1\" xref=\"S5.T2.4.4.1.1.1.1.1.m1.1.1.cmml\">#</mi><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.4.4.1.1.1.1.1.m1.1b\"><ci id=\"S5.T2.4.4.1.1.1.1.1.m1.1.1.cmml\" xref=\"S5.T2.4.4.1.1.1.1.1.m1.1.1\">#</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.4.4.1.1.1.1.1.m1.1c\">\\#</annotation></semantics></math> of Cross-client Edges</span></span>\n</span></span><span id=\"S5.T2.4.4.1.3\" class=\"ltx_text\"></span>\n</td>\n<td id=\"S5.T2.4.4.2\" class=\"ltx_td ltx_align_center\">4199</td>\n<td id=\"S5.T2.4.4.3\" class=\"ltx_td ltx_align_center\">3637</td>\n<td id=\"S5.T2.4.4.4\" class=\"ltx_td ltx_align_center\">35461</td>\n</tr>\n<tr id=\"S5.T2.5.5\" class=\"ltx_tr\">\n<td id=\"S5.T2.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_r\">\n<math id=\"S5.T2.5.5.1.m1.1\" class=\"ltx_Math\" alttext=\"\\#\" display=\"inline\"><semantics id=\"S5.T2.5.5.1.m1.1a\"><mi mathvariant=\"normal\" id=\"S5.T2.5.5.1.m1.1.1\" xref=\"S5.T2.5.5.1.m1.1.1.cmml\">#</mi><annotation-xml encoding=\"MathML-Content\" id=\"S5.T2.5.5.1.m1.1b\"><ci id=\"S5.T2.5.5.1.m1.1.1.cmml\" xref=\"S5.T2.5.5.1.m1.1.1\">#</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T2.5.5.1.m1.1c\">\\#</annotation></semantics></math> of Classes</td>\n<td id=\"S5.T2.5.5.2\" class=\"ltx_td ltx_align_center\">7</td>\n<td id=\"S5.T2.5.5.3\" class=\"ltx_td ltx_align_center\">6</td>\n<td id=\"S5.T2.5.5.4\" class=\"ltx_td ltx_align_center\">3</td>\n</tr>\n<tr id=\"S5.T2.5.8\" class=\"ltx_tr\">\n<td id=\"S5.T2.5.8.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">Partition</td>\n<td id=\"S5.T2.5.8.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">6/2/2</td>\n<td id=\"S5.T2.5.8.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">6/2/2</td>\n<td id=\"S5.T2.5.8.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">6/2/2</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Datasets.\nWe leverage popular graph datasets for node classification tasks, including Cora (Sen et al., 2008), CiteSeer (Sen et al., 2008), and PubMed (Sen et al., 2008). Following previous FGL benchmarks (Xie et al., 2023b; Wang et al., 2022a), we split the above graph datasets randomly to 555 subgraphs with comparable node numbers. Details of datasets are presented in Table 2."
        ]
    },
    "S5.T3": {
        "caption": "Table 3. The prediction ACC and graph information gain of different FGL frameworks.",
        "table": "<table id=\"S5.T3.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S5.T3.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">ACC</td>\n<td id=\"S5.T3.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"3\">Cora</td>\n<td id=\"S5.T3.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"3\">CiteSeer</td>\n<td id=\"S5.T3.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"3\">PubMed</td>\n</tr>\n<tr id=\"S5.T3.1.2\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.2.1\" class=\"ltx_td ltx_border_r ltx_border_t\"></td>\n<td id=\"S5.T3.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Mean</td>\n<td id=\"S5.T3.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">Std</td>\n<td id=\"S5.T3.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Gain</td>\n<td id=\"S5.T3.1.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\">Mean</td>\n<td id=\"S5.T3.1.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\">Std</td>\n<td id=\"S5.T3.1.2.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Gain</td>\n<td id=\"S5.T3.1.2.8\" class=\"ltx_td ltx_align_center ltx_border_t\">Mean</td>\n<td id=\"S5.T3.1.2.9\" class=\"ltx_td ltx_align_center ltx_border_t\">Std</td>\n<td id=\"S5.T3.1.2.10\" class=\"ltx_td ltx_align_center ltx_border_t\">Gain</td>\n</tr>\n<tr id=\"S5.T3.1.3\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Local-MLP</td>\n<td id=\"S5.T3.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">0.5698</td>\n<td id=\"S5.T3.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">±0.0071</td>\n<td id=\"S5.T3.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">+0%</td>\n<td id=\"S5.T3.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.6450</td>\n<td id=\"S5.T3.1.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\">±0.0061</td>\n<td id=\"S5.T3.1.3.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">+0%</td>\n<td id=\"S5.T3.1.3.8\" class=\"ltx_td ltx_align_center ltx_border_t\">0.8051</td>\n<td id=\"S5.T3.1.3.9\" class=\"ltx_td ltx_align_center ltx_border_t\">+0.0006</td>\n<td id=\"S5.T3.1.3.10\" class=\"ltx_td ltx_align_center ltx_border_t\">+0%</td>\n</tr>\n<tr id=\"S5.T3.1.4\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Local-GCN</td>\n<td id=\"S5.T3.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">0.8095</td>\n<td id=\"S5.T3.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">±0.0149</td>\n<td id=\"S5.T3.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">+80.14%</td>\n<td id=\"S5.T3.1.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.7429</td>\n<td id=\"S5.T3.1.4.6\" class=\"ltx_td ltx_align_center ltx_border_t\">±0.0135</td>\n<td id=\"S5.T3.1.4.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">+75.77%</td>\n<td id=\"S5.T3.1.4.8\" class=\"ltx_td ltx_align_center ltx_border_t\">0.8525</td>\n<td id=\"S5.T3.1.4.9\" class=\"ltx_td ltx_align_center ltx_border_t\">±0.0073</td>\n<td id=\"S5.T3.1.4.10\" class=\"ltx_td ltx_align_center ltx_border_t\">+89.10%</td>\n</tr>\n<tr id=\"S5.T3.1.5\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.5.1\" class=\"ltx_td ltx_align_center ltx_border_r\">FedAvg-GCN</td>\n<td id=\"S5.T3.1.5.2\" class=\"ltx_td ltx_align_center\">0.8358</td>\n<td id=\"S5.T3.1.5.3\" class=\"ltx_td ltx_align_center\">±0.0135</td>\n<td id=\"S5.T3.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_r\">+88.93%</td>\n<td id=\"S5.T3.1.5.5\" class=\"ltx_td ltx_align_center\">0.7601</td>\n<td id=\"S5.T3.1.5.6\" class=\"ltx_td ltx_align_center\">±0.0152</td>\n<td id=\"S5.T3.1.5.7\" class=\"ltx_td ltx_align_center ltx_border_r\">+89.09%</td>\n<td id=\"S5.T3.1.5.8\" class=\"ltx_td ltx_align_center\">0.8603</td>\n<td id=\"S5.T3.1.5.9\" class=\"ltx_td ltx_align_center\">±0.0095</td>\n<td id=\"S5.T3.1.5.10\" class=\"ltx_td ltx_align_center\">+103.76%</td>\n</tr>\n<tr id=\"S5.T3.1.6\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.6.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T3.1.6.1.1\" class=\"ltx_text ltx_font_bold\">HiFGL-GCN</span></td>\n<td id=\"S5.T3.1.6.2\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T3.1.6.2.1\" class=\"ltx_text ltx_font_bold\">0.8555</span></td>\n<td id=\"S5.T3.1.6.3\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T3.1.6.3.1\" class=\"ltx_text ltx_font_bold\">±0.0162</span></td>\n<td id=\"S5.T3.1.6.4\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T3.1.6.4.1\" class=\"ltx_text ltx_font_bold\">+95.52%</span></td>\n<td id=\"S5.T3.1.6.5\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T3.1.6.5.1\" class=\"ltx_text ltx_font_bold\">0.7724</span></td>\n<td id=\"S5.T3.1.6.6\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T3.1.6.6.1\" class=\"ltx_text ltx_font_bold\">±0.0108</span></td>\n<td id=\"S5.T3.1.6.7\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T3.1.6.7.1\" class=\"ltx_text ltx_font_bold\">+98.61%</span></td>\n<td id=\"S5.T3.1.6.8\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T3.1.6.8.1\" class=\"ltx_text ltx_font_bold\">0.8626</span></td>\n<td id=\"S5.T3.1.6.9\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T3.1.6.9.1\" class=\"ltx_text ltx_font_bold\">±0.0064</span></td>\n<td id=\"S5.T3.1.6.10\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T3.1.6.10.1\" class=\"ltx_text ltx_font_bold\">+108.08%</span></td>\n</tr>\n<tr id=\"S5.T3.1.7\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.7.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Global-GCN</td>\n<td id=\"S5.T3.1.7.2\" class=\"ltx_td ltx_align_center\">0.8689</td>\n<td id=\"S5.T3.1.7.3\" class=\"ltx_td ltx_align_center\">±0.0182</td>\n<td id=\"S5.T3.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_r\">+100%</td>\n<td id=\"S5.T3.1.7.5\" class=\"ltx_td ltx_align_center\">0.7742</td>\n<td id=\"S5.T3.1.7.6\" class=\"ltx_td ltx_align_center\">±0.0115</td>\n<td id=\"S5.T3.1.7.7\" class=\"ltx_td ltx_align_center ltx_border_r\">+100%</td>\n<td id=\"S5.T3.1.7.8\" class=\"ltx_td ltx_align_center\">0.8583</td>\n<td id=\"S5.T3.1.7.9\" class=\"ltx_td ltx_align_center\">±0.0033</td>\n<td id=\"S5.T3.1.7.10\" class=\"ltx_td ltx_align_center\">+100%</td>\n</tr>\n<tr id=\"S5.T3.1.8\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.8.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Local-GraphSage</td>\n<td id=\"S5.T3.1.8.2\" class=\"ltx_td ltx_align_center ltx_border_t\">0.6207</td>\n<td id=\"S5.T3.1.8.3\" class=\"ltx_td ltx_align_center ltx_border_t\">±0.0103</td>\n<td id=\"S5.T3.1.8.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">+17.03%</td>\n<td id=\"S5.T3.1.8.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.6125</td>\n<td id=\"S5.T3.1.8.6\" class=\"ltx_td ltx_align_center ltx_border_t\">±0.0077</td>\n<td id=\"S5.T3.1.8.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">-25.04%</td>\n<td id=\"S5.T3.1.8.8\" class=\"ltx_td ltx_align_center ltx_border_t\">0.8221</td>\n<td id=\"S5.T3.1.8.9\" class=\"ltx_td ltx_align_center ltx_border_t\">±0.0101</td>\n<td id=\"S5.T3.1.8.10\" class=\"ltx_td ltx_align_center ltx_border_t\">+29.72%</td>\n</tr>\n<tr id=\"S5.T3.1.9\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.9.1\" class=\"ltx_td ltx_align_center ltx_border_r\">FedAvg-GraphSage</td>\n<td id=\"S5.T3.1.9.2\" class=\"ltx_td ltx_align_center\">0.8095</td>\n<td id=\"S5.T3.1.9.3\" class=\"ltx_td ltx_align_center\">±0.0123</td>\n<td id=\"S5.T3.1.9.4\" class=\"ltx_td ltx_align_center ltx_border_r\">+80.22%</td>\n<td id=\"S5.T3.1.9.5\" class=\"ltx_td ltx_align_center\">0.7656</td>\n<td id=\"S5.T3.1.9.6\" class=\"ltx_td ltx_align_center\">±0.0139</td>\n<td id=\"S5.T3.1.9.7\" class=\"ltx_td ltx_align_center ltx_border_r\">+92.91%</td>\n<td id=\"S5.T3.1.9.8\" class=\"ltx_td ltx_align_center\">0.8444</td>\n<td id=\"S5.T3.1.9.9\" class=\"ltx_td ltx_align_center\">±0.0098</td>\n<td id=\"S5.T3.1.9.10\" class=\"ltx_td ltx_align_center\">+68.71%</td>\n</tr>\n<tr id=\"S5.T3.1.10\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.10.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T3.1.10.1.1\" class=\"ltx_text ltx_font_bold\">HiFGL-GraphSage</span></td>\n<td id=\"S5.T3.1.10.2\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T3.1.10.2.1\" class=\"ltx_text ltx_font_bold\">0.8642</span></td>\n<td id=\"S5.T3.1.10.3\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T3.1.10.3.1\" class=\"ltx_text ltx_font_bold\">±0.0288</span></td>\n<td id=\"S5.T3.1.10.4\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T3.1.10.4.1\" class=\"ltx_text ltx_font_bold\">+98.53%</span></td>\n<td id=\"S5.T3.1.10.5\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T3.1.10.5.1\" class=\"ltx_text ltx_font_bold\">0.7791</span></td>\n<td id=\"S5.T3.1.10.6\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T3.1.10.6.1\" class=\"ltx_text ltx_font_bold\">±0.0112</span></td>\n<td id=\"S5.T3.1.10.7\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T3.1.10.7.1\" class=\"ltx_text ltx_font_bold\">+103.31%</span></td>\n<td id=\"S5.T3.1.10.8\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T3.1.10.8.1\" class=\"ltx_text ltx_font_bold\">0.8504</span></td>\n<td id=\"S5.T3.1.10.9\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T3.1.10.9.1\" class=\"ltx_text ltx_font_bold\">±0.0169</span></td>\n<td id=\"S5.T3.1.10.10\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T3.1.10.10.1\" class=\"ltx_text ltx_font_bold\">+79.20%</span></td>\n</tr>\n<tr id=\"S5.T3.1.11\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.11.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">Global-GraphSage</td>\n<td id=\"S5.T3.1.11.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.8686</td>\n<td id=\"S5.T3.1.11.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">±0.0215</td>\n<td id=\"S5.T3.1.11.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">+100%</td>\n<td id=\"S5.T3.1.11.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.7748</td>\n<td id=\"S5.T3.1.11.6\" class=\"ltx_td ltx_align_center ltx_border_bb\">±0.0127</td>\n<td id=\"S5.T3.1.11.7\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">+100%</td>\n<td id=\"S5.T3.1.11.8\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.8623</td>\n<td id=\"S5.T3.1.11.9\" class=\"ltx_td ltx_align_center ltx_border_bb\">±0.0058</td>\n<td id=\"S5.T3.1.11.10\" class=\"ltx_td ltx_align_center ltx_border_bb\">+100%</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We investigate predictive knowledge retrieved under different frameworks measured by Graph Information Gain.\nFirst, we define the predictability lower bound and upper bound as\n1) Lower bound (0%percent00\\%): the performance of Local-MLP, which only separately learns the knowledge from raw features through a 222-layer multi-layer perceptron;\n2) Upper bound (100%percent100100\\%): the performance of trained 222-layer backbone GNN (GCN and GraphSage) on the Global setting, which extracts both knowledge from raw features and graph information.\nThen, we consider the gap between the lower and upper bound as graph information knowledge. Therefore, we test GNNs under different frameworks and collect the mean and standard deviation of ACC for five times experiments and graph information gain in Table 3.\nResults show that under HiFGL, GCN and GraphSage have more graph information gain over than Local and FedAvg and comparable with under Global. Specifically, on three datasets, HiFGL-GCN outperforms 6.59%percent6.596.59\\%, 9.52%percent9.529.52\\%, and 4.32%percent4.324.32\\% than FedAvg-GCN, and HiFGL-GraphSage outperforms 18.31%percent18.3118.31\\%, 10.40%percent10.4010.40\\%, and 10.49%percent10.4910.49\\% than FedAvg-GraphSage. The model improvement demonstrates that besides ensuring privacy and complexity, HiFGL enhances information integrity to achieve better accuracy approximately equal ones without FL settings because the graph information gain of HiFGL is obtained from preserved cross-client edges, which offers rich relational knowledge to learn more effective embeddings."
        ]
    },
    "S6.T4": {
        "caption": "Table 4. The prediction ACC of different FGL algorithms.",
        "table": "<table id=\"S6.T4.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S6.T4.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T4.1.1.1\" class=\"ltx_td ltx_border_r ltx_border_tt\"></td>\n<td id=\"S6.T4.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">Cora</td>\n<td id=\"S6.T4.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">CiteSeer</td>\n<td id=\"S6.T4.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">PubMed</td>\n</tr>\n<tr id=\"S6.T4.1.2\" class=\"ltx_tr\">\n<td id=\"S6.T4.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">FedAvg-GCN</td>\n<td id=\"S6.T4.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.8358</td>\n<td id=\"S6.T4.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.7601</td>\n<td id=\"S6.T4.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.8603</td>\n</tr>\n<tr id=\"S6.T4.1.3\" class=\"ltx_tr\">\n<td id=\"S6.T4.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_r\">FedProx-GCN</td>\n<td id=\"S6.T4.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">0.8238</td>\n<td id=\"S6.T4.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\">0.7612</td>\n<td id=\"S6.T4.1.3.4\" class=\"ltx_td ltx_align_center\">0.8305</td>\n</tr>\n<tr id=\"S6.T4.1.4\" class=\"ltx_tr\">\n<td id=\"S6.T4.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_r\">FedPer-GCN</td>\n<td id=\"S6.T4.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">0.8202</td>\n<td id=\"S6.T4.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">0.7403</td>\n<td id=\"S6.T4.1.4.4\" class=\"ltx_td ltx_align_center\">0.8471</td>\n</tr>\n<tr id=\"S6.T4.1.5\" class=\"ltx_tr\">\n<td id=\"S6.T4.1.5.1\" class=\"ltx_td ltx_align_center ltx_border_r\">FedAvg-GraphSage</td>\n<td id=\"S6.T4.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\">0.8295</td>\n<td id=\"S6.T4.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r\">0.7540</td>\n<td id=\"S6.T4.1.5.4\" class=\"ltx_td ltx_align_center\">0.8524</td>\n</tr>\n<tr id=\"S6.T4.1.6\" class=\"ltx_tr\">\n<td id=\"S6.T4.1.6.1\" class=\"ltx_td ltx_align_center ltx_border_r\">FedProx-GraphSage</td>\n<td id=\"S6.T4.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">0.8256</td>\n<td id=\"S6.T4.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">0.7593</td>\n<td id=\"S6.T4.1.6.4\" class=\"ltx_td ltx_align_center\">0.8391</td>\n</tr>\n<tr id=\"S6.T4.1.7\" class=\"ltx_tr\">\n<td id=\"S6.T4.1.7.1\" class=\"ltx_td ltx_align_center ltx_border_r\">FedPer-GraphSage</td>\n<td id=\"S6.T4.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_r\">0.8174</td>\n<td id=\"S6.T4.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_r\">0.7625</td>\n<td id=\"S6.T4.1.7.4\" class=\"ltx_td ltx_align_center\">0.8439</td>\n</tr>\n<tr id=\"S6.T4.1.8\" class=\"ltx_tr\">\n<td id=\"S6.T4.1.8.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">FedPerGNN</td>\n<td id=\"S6.T4.1.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.8351</td>\n<td id=\"S6.T4.1.8.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.7488</td>\n<td id=\"S6.T4.1.8.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.8346</td>\n</tr>\n<tr id=\"S6.T4.1.9\" class=\"ltx_tr\">\n<td id=\"S6.T4.1.9.1\" class=\"ltx_td ltx_align_center ltx_border_r\">FedSage+</td>\n<td id=\"S6.T4.1.9.2\" class=\"ltx_td ltx_align_center ltx_border_r\">0.7767</td>\n<td id=\"S6.T4.1.9.3\" class=\"ltx_td ltx_align_center ltx_border_r\">0.7567</td>\n<td id=\"S6.T4.1.9.4\" class=\"ltx_td ltx_align_center\">0.8394</td>\n</tr>\n<tr id=\"S6.T4.1.10\" class=\"ltx_tr\">\n<td id=\"S6.T4.1.10.1\" class=\"ltx_td ltx_align_center ltx_border_r\">FED-PUB</td>\n<td id=\"S6.T4.1.10.2\" class=\"ltx_td ltx_align_center ltx_border_r\">0.8370</td>\n<td id=\"S6.T4.1.10.3\" class=\"ltx_td ltx_align_center ltx_border_r\">0.7579</td>\n<td id=\"S6.T4.1.10.4\" class=\"ltx_td ltx_align_center\">0.8457</td>\n</tr>\n<tr id=\"S6.T4.1.11\" class=\"ltx_tr\">\n<td id=\"S6.T4.1.11.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T4.1.11.1.1\" class=\"ltx_text ltx_font_bold\">HiFGL-GCN</span></td>\n<td id=\"S6.T4.1.11.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.8555</td>\n<td id=\"S6.T4.1.11.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.7724</td>\n<td id=\"S6.T4.1.11.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S6.T4.1.11.4.1\" class=\"ltx_text ltx_font_bold\">0.8626</span></td>\n</tr>\n<tr id=\"S6.T4.1.12\" class=\"ltx_tr\">\n<td id=\"S6.T4.1.12.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S6.T4.1.12.1.1\" class=\"ltx_text ltx_font_bold\">HiFGL-GraphSage</span></td>\n<td id=\"S6.T4.1.12.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S6.T4.1.12.2.1\" class=\"ltx_text ltx_font_bold\">0.8642</span></td>\n<td id=\"S6.T4.1.12.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S6.T4.1.12.3.1\" class=\"ltx_text ltx_font_bold\">0.7791</span></td>\n<td id=\"S6.T4.1.12.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.8504</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "The compared results among different FGL methods are depicted in Table 4.\nWe compare HiFGL with three optimization schemes, i.e., FedAvg, FedProx, and FedPer, with two GNNs, i.e., GCN and GraphSage.\nBesides, we involve FedPerGNN, FedSage+, and FED-PUB, which design tailored advanced graph learning modules for FGL.\nWe observe that under HiFGL, GCN, and GraphSage defeat all tested methods.\nSpecifically, with the integrated information preserved by the HiFGL, GCN achieves an accuracy of 0.85550.85550.8555, over 2.3%percent2.32.3\\%, 3.8%percent3.83.8\\%, and 4.3%percent4.34.3\\% improvement than FedAvg, FedProx, and FedPer on Cora dataset, respectively. Similarly, GraphSage gets 4.1%percent4.14.1\\%, 4.6%percent4.64.6\\%, and 5.7%percent5.75.7\\% improvement. Significant performance promotion is attained on CiteSeer and PubMed datasets. The reason is that for GCN and GraphSage that highly depend on structure information, graph integrity can offer great benefits.\nIn addition, against methods with more advanced GNNs, HiFGL wins on prediction accuracy only by incorporating simple backbones. For example, under HiFGL, GraphSage surpasses FedPerGNN, FedSage+, and FED-PUB by 4.0%percent4.04.0\\%, 3.0%percent3.03.0\\%, and 2.8%percent2.82.8\\%, respectively, on CiteSeer.\nThese experimental results demonstrate that graph integrity can bring much effectiveness improvement than GNN modification including high-order relationships incorporated in FedPerGNN, missing neighbor generation in FedSage+, and community-aware personalization in FED-PUB."
        ]
    },
    "S6.T5": {
        "caption": "Table 5. Training results of different GNN layers.",
        "table": "<table id=\"S6.T5.2\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S6.T5.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T5.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">\n<math id=\"S6.T5.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\#\" display=\"inline\"><semantics id=\"S6.T5.1.1.1.m1.1a\"><mi mathvariant=\"normal\" id=\"S6.T5.1.1.1.m1.1.1\" xref=\"S6.T5.1.1.1.m1.1.1.cmml\">#</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T5.1.1.1.m1.1b\"><ci id=\"S6.T5.1.1.1.m1.1.1.cmml\" xref=\"S6.T5.1.1.1.m1.1.1\">#</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T5.1.1.1.m1.1c\">\\#</annotation></semantics></math> of GNN Layers</td>\n<td id=\"S6.T5.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">1</td>\n<td id=\"S6.T5.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">2</td>\n<td id=\"S6.T5.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">4</td>\n<td id=\"S6.T5.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">8</td>\n<td id=\"S6.T5.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_tt\">16</td>\n</tr>\n<tr id=\"S6.T5.2.2\" class=\"ltx_tr\">\n<td id=\"S6.T5.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">ACC (<math id=\"S6.T5.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"S6.T5.2.2.1.m1.1a\"><mo id=\"S6.T5.2.2.1.m1.1.1\" xref=\"S6.T5.2.2.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"S6.T5.2.2.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S6.T5.2.2.1.m1.1.1.cmml\" xref=\"S6.T5.2.2.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T5.2.2.1.m1.1c\">\\%</annotation></semantics></math>)</td>\n<td id=\"S6.T5.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">73.04</td>\n<td id=\"S6.T5.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">77.91</td>\n<td id=\"S6.T5.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">70.87</td>\n<td id=\"S6.T5.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\">39.84</td>\n<td id=\"S6.T5.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\">26.02</td>\n</tr>\n<tr id=\"S6.T5.2.3\" class=\"ltx_tr\">\n<td id=\"S6.T5.2.3.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Epoch Time (s)</td>\n<td id=\"S6.T5.2.3.2\" class=\"ltx_td ltx_align_center\">6.5</td>\n<td id=\"S6.T5.2.3.3\" class=\"ltx_td ltx_align_center\">4.3</td>\n<td id=\"S6.T5.2.3.4\" class=\"ltx_td ltx_align_center\">5.6</td>\n<td id=\"S6.T5.2.3.5\" class=\"ltx_td ltx_align_center\">8.4</td>\n<td id=\"S6.T5.2.3.6\" class=\"ltx_td ltx_align_center\">16.4</td>\n</tr>\n<tr id=\"S6.T5.2.4\" class=\"ltx_tr\">\n<td id=\"S6.T5.2.4.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">Memory (GB)</td>\n<td id=\"S6.T5.2.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">3.41</td>\n<td id=\"S6.T5.2.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">3.45</td>\n<td id=\"S6.T5.2.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">3.49</td>\n<td id=\"S6.T5.2.4.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">3.59</td>\n<td id=\"S6.T5.2.4.6\" class=\"ltx_td ltx_align_center ltx_border_bb\">3.80</td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "GNN layers.\nFirst, we set GNN ranging from 111 to 161616 layers, with a hidden dimension of 646464, on the CiteSeer dataset.\nWe display results in Table 5 that the highest ACC occurs in 222-layer GCN, and the performance decreases for more and fewer layers.\nThe training time per epoch and the memory both increase along with the growth of the layer number. The results show that 222-layer GCN in the HiFGL framework is the most efficient model for ACC and training time, and it does not need expensive memory for training."
        ]
    },
    "S6.T6": {
        "caption": "Table 6. Training results of different hidden dimensions.",
        "table": "<table id=\"S6.T6.3\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S6.T6.3.4\" class=\"ltx_tr\">\n<td id=\"S6.T6.3.4.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span id=\"S6.T6.3.4.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">Hidden Dimensions</span></td>\n<td id=\"S6.T6.3.4.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">4</td>\n<td id=\"S6.T6.3.4.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">8</td>\n<td id=\"S6.T6.3.4.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">16</td>\n<td id=\"S6.T6.3.4.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">32</td>\n<td id=\"S6.T6.3.4.6\" class=\"ltx_td ltx_align_center ltx_border_tt\">64</td>\n<td id=\"S6.T6.3.4.7\" class=\"ltx_td ltx_align_center ltx_border_tt\">128</td>\n</tr>\n<tr id=\"S6.T6.1.1\" class=\"ltx_tr\">\n<td id=\"S6.T6.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">ACC (<math id=\"S6.T6.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\%\" display=\"inline\"><semantics id=\"S6.T6.1.1.1.m1.1a\"><mo id=\"S6.T6.1.1.1.m1.1.1\" xref=\"S6.T6.1.1.1.m1.1.1.cmml\">%</mo><annotation-xml encoding=\"MathML-Content\" id=\"S6.T6.1.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S6.T6.1.1.1.m1.1.1.cmml\" xref=\"S6.T6.1.1.1.m1.1.1\">percent</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T6.1.1.1.m1.1c\">\\%</annotation></semantics></math>)</td>\n<td id=\"S6.T6.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">83.45</td>\n<td id=\"S6.T6.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">85.15</td>\n<td id=\"S6.T6.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">85.33</td>\n<td id=\"S6.T6.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">85.27</td>\n<td id=\"S6.T6.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">85.88</td>\n<td id=\"S6.T6.1.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\">86.39</td>\n</tr>\n<tr id=\"S6.T6.2.2\" class=\"ltx_tr\">\n<td id=\"S6.T6.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_r\">Epoch Time (<math id=\"S6.T6.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"s\" display=\"inline\"><semantics id=\"S6.T6.2.2.1.m1.1a\"><mi id=\"S6.T6.2.2.1.m1.1.1\" xref=\"S6.T6.2.2.1.m1.1.1.cmml\">s</mi><annotation-xml encoding=\"MathML-Content\" id=\"S6.T6.2.2.1.m1.1b\"><ci id=\"S6.T6.2.2.1.m1.1.1.cmml\" xref=\"S6.T6.2.2.1.m1.1.1\">𝑠</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T6.2.2.1.m1.1c\">s</annotation></semantics></math>)</td>\n<td id=\"S6.T6.2.2.2\" class=\"ltx_td ltx_align_center\">17.2</td>\n<td id=\"S6.T6.2.2.3\" class=\"ltx_td ltx_align_center\">18.05</td>\n<td id=\"S6.T6.2.2.4\" class=\"ltx_td ltx_align_center\">20.81</td>\n<td id=\"S6.T6.2.2.5\" class=\"ltx_td ltx_align_center\">19.84</td>\n<td id=\"S6.T6.2.2.6\" class=\"ltx_td ltx_align_center\">23.49</td>\n<td id=\"S6.T6.2.2.7\" class=\"ltx_td ltx_align_center\">44.30</td>\n</tr>\n<tr id=\"S6.T6.3.3\" class=\"ltx_tr\">\n<td id=\"S6.T6.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">Memory (GB)</td>\n<td id=\"S6.T6.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_bb\" colspan=\"6\"><math id=\"S6.T6.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"3.753\\pm 0.005\" display=\"inline\"><semantics id=\"S6.T6.3.3.1.m1.1a\"><mrow id=\"S6.T6.3.3.1.m1.1.1\" xref=\"S6.T6.3.3.1.m1.1.1.cmml\"><mn id=\"S6.T6.3.3.1.m1.1.1.2\" xref=\"S6.T6.3.3.1.m1.1.1.2.cmml\">3.753</mn><mo id=\"S6.T6.3.3.1.m1.1.1.1\" xref=\"S6.T6.3.3.1.m1.1.1.1.cmml\">±</mo><mn id=\"S6.T6.3.3.1.m1.1.1.3\" xref=\"S6.T6.3.3.1.m1.1.1.3.cmml\">0.005</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S6.T6.3.3.1.m1.1b\"><apply id=\"S6.T6.3.3.1.m1.1.1.cmml\" xref=\"S6.T6.3.3.1.m1.1.1\"><csymbol cd=\"latexml\" id=\"S6.T6.3.3.1.m1.1.1.1.cmml\" xref=\"S6.T6.3.3.1.m1.1.1.1\">plus-or-minus</csymbol><cn type=\"float\" id=\"S6.T6.3.3.1.m1.1.1.2.cmml\" xref=\"S6.T6.3.3.1.m1.1.1.2\">3.753</cn><cn type=\"float\" id=\"S6.T6.3.3.1.m1.1.1.3.cmml\" xref=\"S6.T6.3.3.1.m1.1.1.3\">0.005</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T6.3.3.1.m1.1c\">3.753\\pm 0.005</annotation></semantics></math></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "GNN dimension.\nWe also set different hidden dimensions of a 222-layer GCN, ranging from 444 to 128128128, on the PubMed dataset.\nTable 6 demonstrates that performance increases with larger hidden dimensions since a more complicated model can catch more intricate patterns while obstructing high efficiency.\nBesides, the memory for different hidden dimensions is only slightly different because parameters are not dominant for memory costs compared with the other parts of the HiFGL framework under our implementation."
        ]
    }
}