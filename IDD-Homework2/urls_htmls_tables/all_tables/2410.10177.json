{
    "id_table_1": {
        "caption": "Table 1:   Performance comparison of membership inference attacks on the LFW and CelebA datasets, evaluated across metrics including accuracy, precision, recall, and AUC-ROC. Our method consistently outperforms the baseline approaches, particularly excelling on the LFW dataset.",
        "table": "S7.EGx1",
        "footnotes": [],
        "references": [
            "We aggregate these statistical measures across all masks to compute the confidence score  C  ( x 0 ) C subscript x 0 C(x_{0}) italic_C ( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) , defined as the confidence score in Eq.  10 .",
            "The results are detailed, and a threshold of 0.6 is used for the confidence value.in Table  1 , demonstrate that our method consistently outperforms the baseline approaches across all evaluated metrics. For instance, on the CelebA dataset, our method achieves an accuracy of 0.70, precision of 0.69, and AUC-ROC of 0.72, surpassing SecMI and DRC, which yield accuracies of 0.61 and 0.64, respectively. Similarly, on the LFW dataset, our approach attains an accuracy of 0.89 and an AUC-ROC of 0.91, significantly outperforming the baselines (SecMI achieves an AUC of 0.82 and DRC 0.84).",
            "We computed the confidence score  C  ( x q ) C subscript x q C(x_{q}) italic_C ( italic_x start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT )  for each query image using the confidence score defined in Eq.  10 . This confidence-based approach provides a continuous measure of inference certainty, unlike the binary decisions employed by SecMI and DRC. Reconstruction losses were calculated using the same diffusion model  M  subscript M  M_{\\theta} italic_M start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT  for the baseline methods, with thresholds set according to their respective literature. By analyzing the distributions of confidence scores across occlusion types, we determined an appropriate threshold(0.6) for further analysis, ensuring that the selection process accounts for the AUC-ROC and the variability of confidence values. Identifying a threshold empirically allows us to make the data extraction attacks more potent in the following subsections."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:   Comparison of inference attack accuracy and AUC ROC across CelebA and LFW datasets for three diffusion models (DDPM, DDIM, LDM) at specific sampling steps (1000 for DDPM, 200 each for DDIM and LDM) for lists of 8 query images, over 7 experiment runs.",
        "table": "S6.T1.1.1",
        "footnotes": [],
        "references": [
            "For a query image,  x q subscript x q x_{q} italic_x start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT , masks are applied using Eq.  5  to obtain masked images  x q M i superscript subscript x q subscript M i x_{q}^{M_{i}} italic_x start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_M start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT . Next, the forward diffusion process is applied to obtain a noise version. Further, a sequence of reconstructions  x ^ q M i  ( t ) superscript subscript ^ x q subscript M i t \\hat{x}_{q}^{M_{i}}(t) over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_M start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ( italic_t )  across timesteps  t t t italic_t , refining the noisy input through the denoising process using Eq. 2 . The reconstruction loss at each timestep is computed for each denoised, masked image using Eq.  6",
            "We explore the impact of sampling timesteps on the attack success rate across the three diffusion models, as described in Figure  4 . For this evaluation, we train new models on a merged dataset of CelebA and LFW, both resized to 128x128. We vary the number of sampling timesteps for each diffusion model (DDPM, DDIM, LDM) and compare the attack success rate on different datasets. The attack success rate peaks at mid-range timesteps (100-150 for DDIM and LDM, 500-800 for DDPM). However, for the LDM model, we observe the highest attack success rates across a broader range of timesteps. The results have been compiled in the Table  2"
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Performance Evaluation of the Data Extraction Attack, reported on the LFW dataset.",
        "table": "S6.T2.1.1",
        "footnotes": [],
        "references": [
            "Figure  3(a)  shows the attack accuracy, and Figure  3(b)  shows the AUC-ROC as the number of query images increases from 1 to 10. The attack shows the highest effectiveness for LDMs, achieving the best AUC and accuracy across the range of query images. DDPM performs reasonably well, while DDIM performs slightly better than random guessing. Specifically, we observe that with just 5 query images, the attack on LDM achieves an AUC-ROC close to 0.85, while on DDPM, it approaches 0.80. On the other hand, it consistently underperforms on DDIMs, hovering above the baseline of random guessing across all numbers of query images.",
            "We further evaluated the performance of this attack across three different diffusion modelsDDPM, DDIM, and LDMby varying the number of sampling timesteps. Table  3  presents these models ASR-one and ASR-MIA results, along with the corresponding accuracy and AUC-ROC values.",
            "Evaluations as described in Table  3  demonstrate that the success of the data extraction attack is highly dependent on the number of sampling timesteps. For the DDPM model, the highest ASR-one (91.6%) and ASR-MIA (92.1%) values were observed at 200 timesteps. In contrast, DDIM showed lower overall performance, achieving its best results at 200 timesteps with an ASR-one of 89.2%"
        ]
    },
    "id_table_4": {
        "caption": "",
        "table": "S6.T3.1",
        "footnotes": [],
        "references": [
            "We explore the impact of sampling timesteps on the attack success rate across the three diffusion models, as described in Figure  4 . For this evaluation, we train new models on a merged dataset of CelebA and LFW, both resized to 128x128. We vary the number of sampling timesteps for each diffusion model (DDPM, DDIM, LDM) and compare the attack success rate on different datasets. The attack success rate peaks at mid-range timesteps (100-150 for DDIM and LDM, 500-800 for DDPM). However, for the LDM model, we observe the highest attack success rates across a broader range of timesteps. The results have been compiled in the Table  2"
        ]
    }
}