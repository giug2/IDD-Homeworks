{
    "PAPER'S NUMBER OF TABLES": 4,
    "S6.T1": {
        "caption": "TABLE I: Experiment hyperparameters for the different datasets (¬ßVI-A1) and experiment scenarios (¬ßVI-A4).",
        "table": "",
        "footnotes": "\n\n\n\n\n\nDataset\nHyperparameters\nNumber of Training Rounds\n\nEpochs\nBatch Size\nLearning Rate\nStandard\nStraggler (%)\n\nMNIST\n5\n10\n1‚Äãe‚àí31ùëí31e-3\n60\n60\n\nFEMNIST\n5\n10\n1‚Äãe‚àí31ùëí31e-3\n40\n40\n\nShakespeare\n1\n32\n0.80.80.8\n25\n25\n\nSpeech Command\n5\n5\n1‚Äãe‚àí31ùëí31e-3\n35\n60\n\n\n",
        "references": [
            "For MNIST, we use a 2-layer Convolutional Neural Network (CNN) with a 5x5 kernel. Each convolutional layer is followed by a 2x2 max-pooling layer. The model ends with a fully-connected layer with 512 neurons and a ten-neuron output layer. Similarly, for FEMNIST we use a 2-layer CNN with a 5x5 kernel in which each convolutional layer is followed by a 2x2 max-pooling layer. The CNN layers are followed by a fully-connected layer with 2048 neurons, which is followed by an output layer with 62 neurons. For the Shakespeare dataset, we use a Long Short Term Memory (LSTM) recurrent neural network¬†[75]. The model consists of an embedding layer of size eight followed by two LSTM layers with 256 units and an output layer of size 82. Our model architecture for Google Speech consists of two identical blocks followed by an average pooling layer and an output layer with 35 neurons. A block contains two convolutional layers with a 3x3 kernel followed by a max-pooling layer. A dropout layer follows the max-pooling layer with a rate of 0.25 to avoid overfitting. For MNIST, FEMNIST, and Google Speech, we use Adam¬†[76] as the optimizer with a learning rate of 1‚Äãe‚àí31ùëí31e-3. On the other hand, for Shakespeare, we use SGD¬†[77] with a learning rate of 0.80.80.8. The clients for the MNIST, FEMNIST, and Speech datasets train for five local epochs with a batch size of 101010, 101010, and five respectively. Due to the limitations of the current commercial FaaS platforms (¬ßII), the clients for Shakespeare train for one local epoch with a batch size of 323232. The hyperparameters for the different datasets are shown in Table¬†I.",
            "Straggler (%) Scenario. In this, we simulate varying percentages of stragglers in the FL system. Although there might be different reasons for FaaS client failures, such as memory limit, function timeout, or communication issues, these failures can only have one of two effects on the clients. Clients can either push their updates after the training round is finished (slow updates) or can completely crash (not push their updates). To simulate slow updates, we limit the training round time to only fit clients with no issues or delays. Meaning, that clients which experience cold starts, bandwidth limitations, or communication delays do not finish the round in time; therefore, pushing their updates later. On the other hand, to simulate failures, we randomly select a specific ratio of clients to fail their training at the beginning of each experiment. We perform four different experiments for each dataset with 10%, 30%, 50%, and 70% stragglers in the system. Note that, in all our experiments, stragglers are different from malicious clients found in some FL settings¬†[81, 82]. While malicious clients can act as stragglers to deliberately slow training or hinder model performance, they can perform more powerful attacks such as data or model poisoning¬†[83, 84] to skew the model‚Äôs performance. In our work, we focus on the problem of stragglers and their behavior rather than the clients‚Äô intentions. The number of training rounds for the different datasets and experiment scenarios is shown in Table¬†I.",
            "To offer detailed insights, we present results for the Google Speech dataset¬†[18] wrt the metrics accuracy and EUR, across the FL training session as shown in Figures 3(a) and 3(b) respectively. For the standard scenarios, we ran the FL training session for 353535 rounds, while for the straggler (%) scenarios, we ran the experiments for 606060 rounds. For the standard scenario, our strategy reached an accuracy of 79.4% as compared to 76.6% and 77.4% for FedAvg and FedProx respectively. Furthermore, our strategy showed faster convergence by reaching an accuracy of 70% in 19 rounds as compared to 21 and 22 for FedAvg and FedProx respectively. With 10% stragglers, our strategy and FedAvg had a similar convergence rate, while FedProx was slightly behind. Moreover, our strategy reached an end accuracy of 76% which is a 6% and 10% increase over FedAvg and FedProx respectively. For an FL system with 30% stragglers, our strategy consistently outperforms FedAvg by around 8% towards the end of the training, while outperforming FedProx by a smaller margin of 1%. We observe a similar trend for our experiments with 50% and 70% stragglers in the system, where our strategy outperforms the other two. From our experiments, we observe that the presence of stragglers affects the convergence speed of the DNN models in an FL training session. DNN models trained in standard scenarios converge faster as compared to the models trained with straggler (%) scenarios as shown in Figure¬†3(a) (Table¬†I). We observe a similar behaviour for the different datasets (¬ßVI-A1). Moreover, for the straggler (%) scenarios, increasing the percentage of stragglers in the system does not consistently decrease the accuracy of the trained DNN model as shown in Table¬†II. This is especially true for experiments with a higher number of stragglers, i.e., 70%percent7070\\%. This behavior is not exclusive to our experiments and was also reported by Li et al.¬†[20] and Wu et al.¬†[26]. While the authors do not provide a clear explanation for this behaviour, we argue that due to the non-IID nature of the data, clients do not contribute evenly to the test accuracy. In addition, having fewer number of reliable clients reduces the varying effect of local model updates and local model deviations from the global model, making it easier to reach a consensus on the global model. Therefore, we can reach situations where a system with more stragglers reaches higher overall accuracy at the end."
        ]
    },
    "S6.T2": {
        "caption": "TABLE II: Accuracy and EUR values for the three strategies across different scenarios (¬ßVI-A4) and datasets (¬ßVI-A1). The highlighted values represent the highest accuracy and EUR values for a particular dataset, strategy and scenario.",
        "table": "",
        "footnotes": "\n\n\n\n\n\nDataset\nStrategy\nRatio of Stragglers\n\nBaseline\n10%\n30%\n50%\n70%\n\nAcc\nEUR\nAcc\nEUR\nAcc\nEUR\nAcc\nEUR\nAcc\nEUR\n\nMNIST\nFedAvg\n0.981\n0.99\n0.983\n0.89\n0.972\n0.70\n0.971\n0.49\n0.977\n0.31\n\nFedProx\n0.935\n0.98\n0.972\n0.88\n0.960\n0.69\n0.962\n0.49\n0.967\n0.29\n\nFedLesScan\n0.985\n0.99\n0.976\n0.98\n0.972\n0.96\n0.974\n0.74\n0.979\n0.44\n\nFEMNIST\nFedAvg\n0.756\n0.99\n0.765\n0.89\n0.790\n0.69\n0.779\n0.49\n0.744\n0.3\n\nFedProx\n0.753\n0.96\n0.778\n0.80\n0.756\n0.64\n0.785\n0.46\n0.731\n0.28\n\nFedLesScan\n0.776\n0.99\n0.770\n0.97\n0.785\n0.93\n0.774\n0.80\n0.753\n0.50\n\nShakespeare\nFedAvg\n0.434\n0.87\n0.430\n0.80\n0.401\n0.60\n0.402\n0.41\n0.428\n0.31\n\nFedProx\n0.400\n0.86\n0.399\n0.78\n0.396\n0.58\n0.345\n0.40\n0.38\n0.29\n\nFedLesScan\n0.388\n0.94\n0.408\n0.90\n0.400\n0.86\n0.403\n0.72\n0.432\n0.53\n\nGoogle Speech\nFedAvg\n0.766\n0.99\n0.699\n0.90\n0.639\n0.70\n0.645\n0.50\n0.804\n0.30\n\nFedProx\n0.774\n0.99\n0.664\n0.89\n0.709\n0.70\n0.694\n0.49\n0.759\n0.29\n\nFedLesScan\n0.794\n0.99\n0.762\n0.97\n0.719\n0.90\n0.720\n0.86\n0.824\n0.74\n\n\n",
        "references": [
            "The obtained accuracy and EUR values across all our experiments is summarized in Table¬†II. For the standard scenarios (¬ßVI-A4), we obtained better accuracy and round utlization for our strategy as compared to FedAvg and FedProx across all datasets except Shakespeare. This is because with the Shakespeare dataset, some of the clients contribute to the model accuracy more than others, especially clients with longer training times. Moreover, due to budget constraints and significantly high training costs, we train for a slightly less number of rounds, i.e., 25 for Shakespeare. However, we argue that in a more realistic scenario with more number of rounds, the difference in accuracy will decrease. This is because our strategy utilizes clients more efficiently, i.e., higher EUR. As a result, with more rounds the number of invocations per client will increase and more clients will contribute to the global model, leading to a higher accuracy. Similarly, for the straggler (%) scenarios, we obtained better results for accuracy with our strategy as compared to the other two for the MNIST, FEMNIST, and the Google Speech datasets. On the Shakespeare dataset, our strategy outperformed FedAvg and FedProx in scenarios with 30%, 50%, and 70% stragglers. In terms of EUR, our strategy constantly outperforms the other two strategies across all scenarios and datasets since they use random selection for selecting clients for an FL training round.",
            "For most standard scenarios (Table¬†II), FedLesScan obtained better accuracy as compared to the other two strategies due to the better distribution of client invocations. This is because our strategy prioritizes clients with the least number of invocations in a selected client cluster (¬ßV-C) leading to more balanced contributions among the participating clients. On the other hand, with straggler (%) scenario, our strategy reached better accuracies by relying more on robust and reliable clients. Furthermore, the utilization of a staleness-aware aggregation scheme (¬ßV-D) avoids wasting valuable contributions, which in turn increases accuracy.",
            "To offer detailed insights, we present results for the Google Speech dataset¬†[18] wrt the metrics accuracy and EUR, across the FL training session as shown in Figures 3(a) and 3(b) respectively. For the standard scenarios, we ran the FL training session for 353535 rounds, while for the straggler (%) scenarios, we ran the experiments for 606060 rounds. For the standard scenario, our strategy reached an accuracy of 79.4% as compared to 76.6% and 77.4% for FedAvg and FedProx respectively. Furthermore, our strategy showed faster convergence by reaching an accuracy of 70% in 19 rounds as compared to 21 and 22 for FedAvg and FedProx respectively. With 10% stragglers, our strategy and FedAvg had a similar convergence rate, while FedProx was slightly behind. Moreover, our strategy reached an end accuracy of 76% which is a 6% and 10% increase over FedAvg and FedProx respectively. For an FL system with 30% stragglers, our strategy consistently outperforms FedAvg by around 8% towards the end of the training, while outperforming FedProx by a smaller margin of 1%. We observe a similar trend for our experiments with 50% and 70% stragglers in the system, where our strategy outperforms the other two. From our experiments, we observe that the presence of stragglers affects the convergence speed of the DNN models in an FL training session. DNN models trained in standard scenarios converge faster as compared to the models trained with straggler (%) scenarios as shown in Figure¬†3(a) (Table¬†I). We observe a similar behaviour for the different datasets (¬ßVI-A1). Moreover, for the straggler (%) scenarios, increasing the percentage of stragglers in the system does not consistently decrease the accuracy of the trained DNN model as shown in Table¬†II. This is especially true for experiments with a higher number of stragglers, i.e., 70%percent7070\\%. This behavior is not exclusive to our experiments and was also reported by Li et al.¬†[20] and Wu et al.¬†[26]. While the authors do not provide a clear explanation for this behaviour, we argue that due to the non-IID nature of the data, clients do not contribute evenly to the test accuracy. In addition, having fewer number of reliable clients reduces the varying effect of local model updates and local model deviations from the global model, making it easier to reach a consensus on the global model. Therefore, we can reach situations where a system with more stragglers reaches higher overall accuracy at the end."
        ]
    },
    "S6.T3": {
        "caption": "TABLE III: Comparing total time for the three strategies across different scenarios (¬ßVI-A4) and datasets (¬ßVI-A1). The highlighted values represent the minimum training time for each experiment.",
        "table": "",
        "footnotes": "\n\n\n\n\n\nDataset\nStrategy\nExperiment Time (mins)\n\nStandard\n10%\n30%\n50%\n70%\n\nMNIST\nFedAvg\n39.7\n40.2\n40.0\n40.0\n40.0\n\nFedProx\n40.0\n40.3\n40.0\n40.0\n40.0\n\nFedLesScan\n23.7\n28.6\n27.3\n40.0\n40.0\n\nFEMNIST\nFedAvg\n75.5\n86.7\n86.9\n86.7\n86.7\n\nFedProx\n112.4\n88.2\n88.1\n87.8\n87.4\n\nFedLesScan\n70.9\n75.6\n82.8\n86.8\n86.7\n\nShakespeare\nFedAvg\n217.0\n217.0\n217.0\n216.9\n216.8\n\nFedProx\n217.0\n217.0\n217.0\n217.0\n216.7\n\nFedLesScan\n185.5\n215.5\n205.2\n216.8\n216.6\n\nGoogle Speech\nFedAvg\n20.3\n40.1\n40.1\n40.0\n40.0\n\nFedProx\n21.5\n40.0\n40.0\n40.0\n40.0\n\nFedLesScan\n15.1\n31.1\n28.8\n33.3\n40.0\n\n\n",
        "references": [
            "Table¬†III shows the total aggregated time per experiment. For the standard scenario, training a model with our strategy is significantly faster as compared to FedAvg and FedProx across all datasets. For instance, for the MNIST dataset, our strategy takes 40% less time as compared to the other strategies. For the straggler (%) scenarios, we see the effect of stragglers on experiment duration. In the scenarios with 10% and 30% stragglers, we observe that\nFedLesScan maintains a lower duration across all experiments. However, when the number of stragglers in the system is significantly higher, they must be invoked in almost all training rounds to meet the minimum number of clients required per round. We notice this behavior for our strategy with greater than 50% stragglers in the system for the MNIST, FEMNIST, and the Shakespeare dataset. However, for the Google Speech dataset, our strategy still has an 18% lower experiment duration as compared to the other two. This is because the total number of clients for the Google Speech dataset is 542 with 200 concurrent clients participating in a training round (¬ßVI-A3). For the scenario with 70% stragglers in the system, all approaches have similar experiment times across all datasets."
        ]
    },
    "S6.T4": {
        "caption": "TABLE IV: Comparing training costs for the three strategies across different scenarios (¬ßVI-A4) and datasets (¬ßVI-A1). The highlighted values represent the minimum experiment cost.",
        "table": "",
        "footnotes": "\n\n\n\n\n\nDataset\nStrategy\nExperiment Cost ($)\n\nStandard\n10%\n30%\n50%\n70%\n\nMNIST\nFedAvg\n2.90\n3.90\n6.00\n8.00\n10.40\n\nFedProx\n5.50\n6.40\n7.60\n9.21\n11.03\n\nFedLesScan\n2.70\n3.86\n4.00\n5.99\n9.2\n\nFEMNIST\nFedAvg\n13.50\n16.19\n17.87\n20.54\n24.70\n\nFedProx\n16.67\n17.29\n19.40\n22.42\n25.80\n\nFedLesScan\n13.17\n14.58\n14.40\n14.81\n20.60\n\nShakespeare\nFedAvg\n5.40\n6.60\n9.21\n12.50\n15.40\n\nFedProx\n5.12\n6.72\n9.00\n12.20\n15.40\n\nFedLesScan\n5.33\n5.50\n6.75\n8.46\n12.00\n\nGoogle Speech\nFedAvg\n1.98\n3.90\n6.40\n8.30\n10.50\n\nFedProx\n2.39\n4.60\n6.77\n8.70\n10.80\n\nFedLesScan\n1.73\n2.70\n3.68\n4.20\n5.50\n\n\n",
        "references": [
            "Table¬†IV shows the cost for the different strategies, datasets, and scenarios. For the standard scenario with MNIST, we observe a 6.8% and 50% cost reduction for our strategy as compared to FedAvg and FedProx. Similarly for the FEMNIST and Google Speech datasets in the standard scenario, we observe cost reductions of about 2%, 20% and 12%, 27% as compared to FedAvg and FedProx respectively. On the other hand, for the Shakespeare dataset, FedProx performed better than our strategy and FedAvg by 4% and 6% respectively. We observe that the efficiency of our strategy becomes more visible as the number of stragglers in the system increases. For all the scenarios with a varying number of stragglers, our strategy has the minimum cost as compared to the other two strategies. For the straggler (%) scenarios, our strategy consistently achieved lower experiment cost across all datasets with an average cost reduction of 25% and 32% as compared to FedAvg and FedProx respectively."
        ]
    }
}