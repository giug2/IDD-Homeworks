{
    "PAPER'S NUMBER OF TABLES": 5,
    "S4.T1": {
        "caption": "Table 1. Statistics of the medical NER datasets.",
        "table": "<table id=\"S4.T1.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S4.T1.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.2.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\"><span id=\"S4.T1.1.2.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Dataset</span></td>\n<td id=\"S4.T1.1.2.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\"><span id=\"S4.T1.1.2.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\"># Sentences</span></td>\n<td id=\"S4.T1.1.2.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\"><span id=\"S4.T1.1.2.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Entity Types</span></td>\n<td id=\"S4.T1.1.2.4\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_tt\"><span id=\"S4.T1.1.2.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\"># Entity</span></td>\n</tr>\n<tr id=\"S4.T1.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">SMM4H</span></td>\n<td id=\"S4.T1.1.3.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">3,824</span></td>\n<td id=\"S4.T1.1.3.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">ADE (1,707)</span></td>\n<td id=\"S4.T1.1.3.4\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_t\"><span id=\"S4.T1.1.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">1,707</span></td>\n</tr>\n<tr id=\"S4.T1.1.4\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.4.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">ADE</span></td>\n<td id=\"S4.T1.1.4.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">4,483</span></td>\n<td id=\"S4.T1.1.4.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">\n<table id=\"S4.T1.1.4.3.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T1.1.4.3.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.4.3.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\"><span id=\"S4.T1.1.4.3.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">ADE (5,678), Drug (5,076),</span></td>\n</tr>\n<tr id=\"S4.T1.1.4.3.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.4.3.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\"><span id=\"S4.T1.1.4.3.1.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Dosage (222)</span></td>\n</tr>\n</table>\n</td>\n<td id=\"S4.T1.1.4.4\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_t\"><span id=\"S4.T1.1.4.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">10,976</span></td>\n</tr>\n<tr id=\"S4.T1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t\"><math id=\"S4.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"{\\rm CADEC}\" display=\"inline\"><semantics id=\"S4.T1.1.1.1.m1.1a\"><mi mathsize=\"90%\" id=\"S4.T1.1.1.1.m1.1.1\" xref=\"S4.T1.1.1.1.m1.1.1.cmml\">CADEC</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.1.1.1.m1.1b\"><ci id=\"S4.T1.1.1.1.m1.1.1.cmml\" xref=\"S4.T1.1.1.1.m1.1.1\">CADEC</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.1.1.1.m1.1c\">{\\rm CADEC}</annotation></semantics></math></td>\n<td id=\"S4.T1.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t\"><span id=\"S4.T1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">7,683</span></td>\n<td id=\"S4.T1.1.1.3\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t\">\n<table id=\"S4.T1.1.1.3.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T1.1.1.3.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.3.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\"><span id=\"S4.T1.1.1.3.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">ADE (5,937),\nDrug(1,796),</span></td>\n</tr>\n<tr id=\"S4.T1.1.1.3.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.3.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\"><span id=\"S4.T1.1.1.3.1.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Disease(282), Finding(425),</span></td>\n</tr>\n<tr id=\"S4.T1.1.1.3.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.3.1.3.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\"><span id=\"S4.T1.1.1.3.1.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Symptom(268)</span></td>\n</tr>\n</table>\n</td>\n<td id=\"S4.T1.1.1.4\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_bb ltx_border_t\"><span id=\"S4.T1.1.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">8,535</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Three medical datasets includes SMM4H (Weissenbacher et¬†al., 2019), CADEC (Karimi et¬†al., 2015) and ADE (Gurulingappa et¬†al., 2012), which are widely used to evaluate NER tasks.\nThe statistics of the medical datasets are shown in Table 1."
        ]
    },
    "S4.T2": {
        "caption": "Table 2. Performance comparison of federated learning methods on the GLUE benchmark for text classification tasks. Performance is evaluated on the final large model in a global inference scenario.\nBold faces indicate the best method for inclusive FL training with heterogeneous devices.\n",
        "table": "<table id=\"S4.T2.4\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S4.T2.4.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.4.1.1\" class=\"ltx_td ltx_border_r ltx_border_tt\"></td>\n<td id=\"S4.T2.4.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">Inclusive?</td>\n<td id=\"S4.T2.4.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">COLA</td>\n<td id=\"S4.T2.4.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">MNLI</td>\n<td id=\"S4.T2.4.1.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">MRPC</td>\n<td id=\"S4.T2.4.1.6\" class=\"ltx_td ltx_align_center ltx_border_tt\">QNLI</td>\n<td id=\"S4.T2.4.1.7\" class=\"ltx_td ltx_align_center ltx_border_tt\">QQP</td>\n<td id=\"S4.T2.4.1.8\" class=\"ltx_td ltx_align_center ltx_border_tt\">RTE</td>\n<td id=\"S4.T2.4.1.9\" class=\"ltx_td ltx_align_center ltx_border_tt\">SST2</td>\n<td id=\"S4.T2.4.1.10\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">STSB</td>\n<td id=\"S4.T2.4.1.11\" class=\"ltx_td ltx_align_center ltx_border_tt\">Avg.</td>\n</tr>\n<tr id=\"S4.T2.4.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.4.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">All-Large</td>\n<td id=\"S4.T2.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N/A</td>\n<td id=\"S4.T2.4.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">63.03</td>\n<td id=\"S4.T2.4.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">86.48</td>\n<td id=\"S4.T2.4.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\">91.50</td>\n<td id=\"S4.T2.4.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\">92.09</td>\n<td id=\"S4.T2.4.2.7\" class=\"ltx_td ltx_align_center ltx_border_t\">91.49</td>\n<td id=\"S4.T2.4.2.8\" class=\"ltx_td ltx_align_center ltx_border_t\">76.12</td>\n<td id=\"S4.T2.4.2.9\" class=\"ltx_td ltx_align_center ltx_border_t\">94.43</td>\n<td id=\"S4.T2.4.2.10\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">90.60</td>\n<td id=\"S4.T2.4.2.11\" class=\"ltx_td ltx_align_center ltx_border_t\">85.72</td>\n</tr>\n<tr id=\"S4.T2.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">ExclusiveFL</td>\n<td id=\"S4.T2.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">No</td>\n<td id=\"S4.T2.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">37.77</td>\n<td id=\"S4.T2.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">85.98</td>\n<td id=\"S4.T2.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">89.87</td>\n<td id=\"S4.T2.4.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\">91.24</td>\n<td id=\"S4.T2.4.3.7\" class=\"ltx_td ltx_align_center ltx_border_t\">89.47</td>\n<td id=\"S4.T2.4.3.8\" class=\"ltx_td ltx_align_center ltx_border_t\">62.17</td>\n<td id=\"S4.T2.4.3.9\" class=\"ltx_td ltx_align_center ltx_border_t\">94.06</td>\n<td id=\"S4.T2.4.3.10\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">89.26</td>\n<td id=\"S4.T2.4.3.11\" class=\"ltx_td ltx_align_center ltx_border_t\">79.98</td>\n</tr>\n<tr id=\"S4.T2.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T2.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_r\">All-Small</td>\n<td id=\"S4.T2.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Yes</td>\n<td id=\"S4.T2.4.4.3\" class=\"ltx_td ltx_align_center\">34.91</td>\n<td id=\"S4.T2.4.4.4\" class=\"ltx_td ltx_align_center\">78.83</td>\n<td id=\"S4.T2.4.4.5\" class=\"ltx_td ltx_align_center\">82.50</td>\n<td id=\"S4.T2.4.4.6\" class=\"ltx_td ltx_align_center\">85.93</td>\n<td id=\"S4.T2.4.4.7\" class=\"ltx_td ltx_align_center\">79.37</td>\n<td id=\"S4.T2.4.4.8\" class=\"ltx_td ltx_align_center\">58.94</td>\n<td id=\"S4.T2.4.4.9\" class=\"ltx_td ltx_align_center\">90.14</td>\n<td id=\"S4.T2.4.4.10\" class=\"ltx_td ltx_align_center ltx_border_r\">83.68</td>\n<td id=\"S4.T2.4.4.11\" class=\"ltx_td ltx_align_center\">74.29</td>\n</tr>\n<tr id=\"S4.T2.4.5\" class=\"ltx_tr\">\n<td id=\"S4.T2.4.5.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">HeteroFL</td>\n<td id=\"S4.T2.4.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Yes</td>\n<td id=\"S4.T2.4.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\">8.15</td>\n<td id=\"S4.T2.4.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\">31.83</td>\n<td id=\"S4.T2.4.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\">81.51</td>\n<td id=\"S4.T2.4.5.6\" class=\"ltx_td ltx_align_center ltx_border_t\">62.70</td>\n<td id=\"S4.T2.4.5.7\" class=\"ltx_td ltx_align_center ltx_border_t\">73.79</td>\n<td id=\"S4.T2.4.5.8\" class=\"ltx_td ltx_align_center ltx_border_t\">52.71</td>\n<td id=\"S4.T2.4.5.9\" class=\"ltx_td ltx_align_center ltx_border_t\">84.98</td>\n<td id=\"S4.T2.4.5.10\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">30.54</td>\n<td id=\"S4.T2.4.5.11\" class=\"ltx_td ltx_align_center ltx_border_t\">53.28</td>\n</tr>\n<tr id=\"S4.T2.4.6\" class=\"ltx_tr\">\n<td id=\"S4.T2.4.6.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">InclusiveFL</td>\n<td id=\"S4.T2.4.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">Yes</td>\n<td id=\"S4.T2.4.6.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S4.T2.4.6.3.1\" class=\"ltx_text ltx_font_bold\">54.85</span></td>\n<td id=\"S4.T2.4.6.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S4.T2.4.6.4.1\" class=\"ltx_text ltx_font_bold\">86.36</span></td>\n<td id=\"S4.T2.4.6.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S4.T2.4.6.5.1\" class=\"ltx_text ltx_font_bold\">91.42</span></td>\n<td id=\"S4.T2.4.6.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S4.T2.4.6.6.1\" class=\"ltx_text ltx_font_bold\">91.76</span></td>\n<td id=\"S4.T2.4.6.7\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S4.T2.4.6.7.1\" class=\"ltx_text ltx_font_bold\">90.55</span></td>\n<td id=\"S4.T2.4.6.8\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S4.T2.4.6.8.1\" class=\"ltx_text ltx_font_bold\">66.14</span></td>\n<td id=\"S4.T2.4.6.9\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S4.T2.4.6.9.1\" class=\"ltx_text ltx_font_bold\">94.17</span></td>\n<td id=\"S4.T2.4.6.10\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\"><span id=\"S4.T2.4.6.10.1\" class=\"ltx_text ltx_font_bold\">89.94</span></td>\n<td id=\"S4.T2.4.6.11\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S4.T2.4.6.11.1\" class=\"ltx_text ltx_font_bold\">83.15</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Effectiveness.\nResults of IID setting on GLUE datasets and results of non-IID setting on medical NER datasets are shown in Table 2 and 3 respectively.\nWe observe that for all datasets, AllLarge achieves the overall best performance, which indicates that training a large global model with all clients‚Äô data can achieve the optimal performance.\nHowever, it is impractical for training participants with less resources to train large models locally.",
            "Efficiency.\nBy observing the convergence curve in Fig. 3, we find InclusiveFL is approaching the performance of AllLarge with a faster speed than InclusiveFL-w/o MD, especially for the largest model with 12 layers.\nFor the IID setting as shown in Fig. 3(a), InclusiveFL achieves the F1-score of 89.43 within 400 rounds while InclusiveFL-w/o MD requires 550 rounds.\nFor the non-IID setting in Fig. 3(f), InclusiveFL achieves the accuracy of 60.5 within 650 while InclusiveFL-w/o MD requires 950 rounds.\nFor all datasets, we list the averaged number of rounds required by InclusiveFL with or without momentum distillation to achieve the best performance in Table 2 and 3.\nThus, we can conclude that the proposed momentum distillation accelerates the performance of the largest global model by requiring less communication rounds."
        ]
    },
    "S4.T3": {
        "caption": "Table 3. Performance comparison of federated learning methods on medical datasets for named entity recognition.\nPerformances are evaluated for each named entity on each local model (SMM4H with 4-layer model, ADE with 9-layer model and CADEC with 12-layer model) in the local inference scenario.\nBest method for heterogeneous training is shown in bold face.\n",
        "table": "<table id=\"S4.T3.4\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T3.4.1\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T3.4.1.1.1\" class=\"ltx_text\">Methods</span></td>\n<td id=\"S4.T3.4.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T3.4.1.2.1\" class=\"ltx_text\">Inclusive?</span></td>\n<td id=\"S4.T3.4.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">SMM4H</td>\n<td id=\"S4.T3.4.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"3\">ADE</td>\n<td id=\"S4.T3.4.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"5\">CADEC</td>\n<td id=\"S4.T3.4.1.6\" class=\"ltx_td ltx_align_center ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T3.4.1.6.1\" class=\"ltx_text\">Avg.</span></td>\n</tr>\n<tr id=\"S4.T3.4.2\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">ADE</td>\n<td id=\"S4.T3.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Drug</td>\n<td id=\"S4.T3.4.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">ADE</td>\n<td id=\"S4.T3.4.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Dose</td>\n<td id=\"S4.T3.4.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\">ADE</td>\n<td id=\"S4.T3.4.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\">Symptom</td>\n<td id=\"S4.T3.4.2.7\" class=\"ltx_td ltx_align_center ltx_border_t\">Drug</td>\n<td id=\"S4.T3.4.2.8\" class=\"ltx_td ltx_align_center ltx_border_t\">Disease</td>\n<td id=\"S4.T3.4.2.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Finding</td>\n</tr>\n<tr id=\"S4.T3.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">AllLarge</td>\n<td id=\"S4.T3.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N/A</td>\n<td id=\"S4.T3.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">55.08</td>\n<td id=\"S4.T3.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">95.21</td>\n<td id=\"S4.T3.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">80.91</td>\n<td id=\"S4.T3.4.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">18.97</td>\n<td id=\"S4.T3.4.3.7\" class=\"ltx_td ltx_align_center ltx_border_t\">71.23</td>\n<td id=\"S4.T3.4.3.8\" class=\"ltx_td ltx_align_center ltx_border_t\">43.37</td>\n<td id=\"S4.T3.4.3.9\" class=\"ltx_td ltx_align_center ltx_border_t\">90.43</td>\n<td id=\"S4.T3.4.3.10\" class=\"ltx_td ltx_align_center ltx_border_t\">33.55</td>\n<td id=\"S4.T3.4.3.11\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">29.85</td>\n<td id=\"S4.T3.4.3.12\" class=\"ltx_td ltx_align_center ltx_border_t\">57.62</td>\n</tr>\n<tr id=\"S4.T3.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Local</td>\n<td id=\"S4.T3.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">No</td>\n<td id=\"S4.T3.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">46.77</td>\n<td id=\"S4.T3.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">95.12</td>\n<td id=\"S4.T3.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\">80.14</td>\n<td id=\"S4.T3.4.4.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">11.25</td>\n<td id=\"S4.T3.4.4.7\" class=\"ltx_td ltx_align_center ltx_border_t\">44.15</td>\n<td id=\"S4.T3.4.4.8\" class=\"ltx_td ltx_align_center ltx_border_t\">19.90</td>\n<td id=\"S4.T3.4.4.9\" class=\"ltx_td ltx_align_center ltx_border_t\">53.53</td>\n<td id=\"S4.T3.4.4.10\" class=\"ltx_td ltx_align_center ltx_border_t\">20.58</td>\n<td id=\"S4.T3.4.4.11\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">16.53</td>\n<td id=\"S4.T3.4.4.12\" class=\"ltx_td ltx_align_center ltx_border_t\">43.11</td>\n</tr>\n<tr id=\"S4.T3.4.5\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.5.1\" class=\"ltx_td ltx_align_center ltx_border_r\">AllSmall</td>\n<td id=\"S4.T3.4.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Yes</td>\n<td id=\"S4.T3.4.5.3\" class=\"ltx_td ltx_align_center ltx_border_r\">49.56</td>\n<td id=\"S4.T3.4.5.4\" class=\"ltx_td ltx_align_center\">92.76</td>\n<td id=\"S4.T3.4.5.5\" class=\"ltx_td ltx_align_center\">75.67</td>\n<td id=\"S4.T3.4.5.6\" class=\"ltx_td ltx_align_center ltx_border_r\">13.51</td>\n<td id=\"S4.T3.4.5.7\" class=\"ltx_td ltx_align_center\">64.82</td>\n<td id=\"S4.T3.4.5.8\" class=\"ltx_td ltx_align_center\">26.71</td>\n<td id=\"S4.T3.4.5.9\" class=\"ltx_td ltx_align_center\">87.91</td>\n<td id=\"S4.T3.4.5.10\" class=\"ltx_td ltx_align_center\">21.07</td>\n<td id=\"S4.T3.4.5.11\" class=\"ltx_td ltx_align_center ltx_border_r\">20.23</td>\n<td id=\"S4.T3.4.5.12\" class=\"ltx_td ltx_align_center\">40.89</td>\n</tr>\n<tr id=\"S4.T3.4.6\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.6.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">HeteroFL</td>\n<td id=\"S4.T3.4.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Yes</td>\n<td id=\"S4.T3.4.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">27.94</td>\n<td id=\"S4.T3.4.6.4\" class=\"ltx_td ltx_align_center ltx_border_t\">73.90</td>\n<td id=\"S4.T3.4.6.5\" class=\"ltx_td ltx_align_center ltx_border_t\">37.57</td>\n<td id=\"S4.T3.4.6.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">11.57</td>\n<td id=\"S4.T3.4.6.7\" class=\"ltx_td ltx_align_center ltx_border_t\">59.90</td>\n<td id=\"S4.T3.4.6.8\" class=\"ltx_td ltx_align_center ltx_border_t\">26.92</td>\n<td id=\"S4.T3.4.6.9\" class=\"ltx_td ltx_align_center ltx_border_t\">84.58</td>\n<td id=\"S4.T3.4.6.10\" class=\"ltx_td ltx_align_center ltx_border_t\">25.77</td>\n<td id=\"S4.T3.4.6.11\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">19.88</td>\n<td id=\"S4.T3.4.6.12\" class=\"ltx_td ltx_align_center ltx_border_t\">42.51</td>\n</tr>\n<tr id=\"S4.T3.4.7\" class=\"ltx_tr\">\n<td id=\"S4.T3.4.7.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">InclusiveFL</td>\n<td id=\"S4.T3.4.7.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\">Yes</td>\n<td id=\"S4.T3.4.7.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\"><span id=\"S4.T3.4.7.3.1\" class=\"ltx_text ltx_font_bold\">49.90</span></td>\n<td id=\"S4.T3.4.7.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S4.T3.4.7.4.1\" class=\"ltx_text ltx_font_bold\">95.49</span></td>\n<td id=\"S4.T3.4.7.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S4.T3.4.7.5.1\" class=\"ltx_text ltx_font_bold\">80.34</span></td>\n<td id=\"S4.T3.4.7.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\"><span id=\"S4.T3.4.7.6.1\" class=\"ltx_text ltx_font_bold\">13.91</span></td>\n<td id=\"S4.T3.4.7.7\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S4.T3.4.7.7.1\" class=\"ltx_text ltx_font_bold\">71.10</span></td>\n<td id=\"S4.T3.4.7.8\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S4.T3.4.7.8.1\" class=\"ltx_text ltx_font_bold\">40.91</span></td>\n<td id=\"S4.T3.4.7.9\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S4.T3.4.7.9.1\" class=\"ltx_text ltx_font_bold\">90.21</span></td>\n<td id=\"S4.T3.4.7.10\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S4.T3.4.7.10.1\" class=\"ltx_text ltx_font_bold\">39.34</span></td>\n<td id=\"S4.T3.4.7.11\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\"><span id=\"S4.T3.4.7.11.1\" class=\"ltx_text ltx_font_bold\">22.97</span></td>\n<td id=\"S4.T3.4.7.12\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S4.T3.4.7.12.1\" class=\"ltx_text ltx_font_bold\">56.02</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We find that the most related work HeteroFL¬†(Diao et¬†al., 2021) performs worse than the naive baselines AllSmall and ExclusiveFL on all GLUE datasets.\nAnd the averaged performance of HeteroFL is also inferior to AllSmall and ExclusiveFL on medical datasets as shown in Table 3.\nThis indicates that the method of sharing the top-left sub-matrix across heterogeneous devices in HeteroFL may work for simple models with shallow layers (such as CNN in (Diao et¬†al., 2021)) but not for more complex deep models (such as 12-layer RoBERTa).\nFurthermore, we observe in Fig. 3 that the starting performance of local models on weak and medium clients InclusiveFL is better than HeteroFL, which indicates that the small model in InclusiveFL has a better parameter initialization than HeteroFL.\nThus, one reason of the inferior utility is that cropping the network in HeteroFL cannot fully utilized the pre-trained parameters while a layer-wise sharing in InclusiveFL can better maintain the utility of a pre-trained model naturally.",
            "Discussion on the local model inference.\nTo further investigate the reason for performance improvement, we observe the evaluation results on the local model for each group of clients.\nFor the cross-silo setting, local model inference is essential because each client has her own top layers of classifier for fitting local targets.\nFor the medium model in Fig. 3(g) and small model in 3(h), we find the effect of boosting convergence is less obvious but still exists and leads to a higher performance in Table 3 when the local model (8-layer for ADE and 4-layer for SMM4H) converges."
        ]
    },
    "S4.T4": {
        "caption": "Table 4. Averaged number of rounds for achieving the best performance in Table 2.",
        "table": "<table id=\"S4.T4.4\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S4.T4.4.1\" class=\"ltx_tr\">\n<td id=\"S4.T4.4.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">Methods</td>\n<td id=\"S4.T4.4.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">CoLA</td>\n<td id=\"S4.T4.4.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">MNLI</td>\n<td id=\"S4.T4.4.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">MRPC</td>\n<td id=\"S4.T4.4.1.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">QNLI</td>\n<td id=\"S4.T4.4.1.6\" class=\"ltx_td ltx_align_center ltx_border_tt\">QQP</td>\n<td id=\"S4.T4.4.1.7\" class=\"ltx_td ltx_align_center ltx_border_tt\">RTE</td>\n<td id=\"S4.T4.4.1.8\" class=\"ltx_td ltx_align_center ltx_border_tt\">SST2</td>\n<td id=\"S4.T4.4.1.9\" class=\"ltx_td ltx_align_center ltx_border_tt\">STSB</td>\n<td id=\"S4.T4.4.1.10\" class=\"ltx_td ltx_align_center ltx_border_tt\">NER</td>\n</tr>\n<tr id=\"S4.T4.4.2\" class=\"ltx_tr\">\n<td id=\"S4.T4.4.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">InclusiveFL-w/o MD</td>\n<td id=\"S4.T4.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">630</td>\n<td id=\"S4.T4.4.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">665</td>\n<td id=\"S4.T4.4.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">616</td>\n<td id=\"S4.T4.4.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\">600</td>\n<td id=\"S4.T4.4.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\">850</td>\n<td id=\"S4.T4.4.2.7\" class=\"ltx_td ltx_align_center ltx_border_t\">620</td>\n<td id=\"S4.T4.4.2.8\" class=\"ltx_td ltx_align_center ltx_border_t\">810</td>\n<td id=\"S4.T4.4.2.9\" class=\"ltx_td ltx_align_center ltx_border_t\">870</td>\n<td id=\"S4.T4.4.2.10\" class=\"ltx_td ltx_align_center ltx_border_t\">90</td>\n</tr>\n<tr id=\"S4.T4.4.3\" class=\"ltx_tr\">\n<td id=\"S4.T4.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">InclusiveFL</td>\n<td id=\"S4.T4.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T4.4.3.2.1\" class=\"ltx_text ltx_font_bold\">580</span></td>\n<td id=\"S4.T4.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T4.4.3.3.1\" class=\"ltx_text ltx_font_bold\">570</span></td>\n<td id=\"S4.T4.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T4.4.3.4.1\" class=\"ltx_text ltx_font_bold\">515</span></td>\n<td id=\"S4.T4.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T4.4.3.5.1\" class=\"ltx_text ltx_font_bold\">585</span></td>\n<td id=\"S4.T4.4.3.6\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T4.4.3.6.1\" class=\"ltx_text ltx_font_bold\">740</span></td>\n<td id=\"S4.T4.4.3.7\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T4.4.3.7.1\" class=\"ltx_text ltx_font_bold\">510</span></td>\n<td id=\"S4.T4.4.3.8\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T4.4.3.8.1\" class=\"ltx_text ltx_font_bold\">520</span></td>\n<td id=\"S4.T4.4.3.9\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T4.4.3.9.1\" class=\"ltx_text ltx_font_bold\">805</span></td>\n<td id=\"S4.T4.4.3.10\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T4.4.3.10.1\" class=\"ltx_text ltx_font_bold\">75</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "In this section, we evaluate ",
                "InclusiveFL",
                " for federated learning over heterogeneous devices on IID and non-IID datasets and compare with both naive baselines and HeteroFL ",
                "(Diao et¬†al",
                ".",
                ", ",
                "2021",
                ")",
                ".\nTo simulate the heterogeneous device scenario, we set up three types of clients: weak clients, medium clients and powerful clients.\nAccordingly, they can store and compute over 4-layer, 8-layer and 12-layer transformer models, respectively.",
                "Datasets.",
                "\nOur experiments are conducted on the text classification task in the GLUE benchmark and token classification task (NER) on three medical corpora.\nGLUE benchmark ",
                "(Wang et¬†al",
                ".",
                ", ",
                "2018b",
                ")",
                " is a collection of multiple natural language understanding tasks, including\nMNLI ",
                "(Williams et¬†al",
                ".",
                ", ",
                "2018",
                ")",
                " (inference),\nSST-2 ",
                "(Socher et¬†al",
                ".",
                ", ",
                "2013",
                ")",
                " (sentimental analysis),\nMRPC ",
                "(Dolan and Brockett, ",
                "2005",
                ")",
                " (paraphrase detection),\nCoLA ",
                "(Warstadt et¬†al",
                ".",
                ", ",
                "2019",
                ")",
                " (linguistic acceptability),\nQNLI ",
                "(Rajpurkar et¬†al",
                ".",
                ", ",
                "2018",
                ")",
                " (inference), QQP",
                "2",
                "2",
                "2",
                "https://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs",
                " (question-answering),\nRTE¬†",
                "3",
                "3",
                "3",
                "https://huggingface.co/datasets/glue/viewer/rte/train",
                " (inference),\nand STSB ",
                "(Cera et¬†al",
                ".",
                ", ",
                "2017",
                ")",
                " (textual similarity).\nThe generality makes the GLUE dataset a standard benchmark to evaluate NLU models.",
                "Three medical datasets includes SMM4H ",
                "(Weissenbacher et¬†al",
                ".",
                ", ",
                "2019",
                ")",
                ", CADEC ",
                "(Karimi et¬†al",
                ".",
                ", ",
                "2015",
                ")",
                " and ADE ",
                "(Gurulingappa et¬†al",
                ".",
                ", ",
                "2012",
                ")",
                ", which are widely used to evaluate NER tasks.\nThe statistics of the medical datasets are shown in Table ",
                "1",
                ".",
                "Evaluation Protocols.",
                "\nFor the evaluation on cross-device ",
                "(McMahan et¬†al",
                ".",
                ", ",
                "2021",
                ")",
                " federated learning with IID data, we randomly split the training dataset of each GLUE benchmark to 1000 clients and report the best performance of the evaluation dataset.\nBy default, we report the matched accuracy for MNLI, the Matthew‚Äôs correlation for CoLA, Pearson correlation for STSB, F1-score for MRPC and the accuracy metric for all other tasks.\nHigher value indicates better performance.\nTo evaluate over non-IID data distribution, we take each medical corpus as the local dataset of one client (e.g. a hospital) and simulate the cross-silo ",
                "(McMahan et¬†al",
                ".",
                ", ",
                "2021",
                ")",
                " federated setting.\nWe set SMM4H as the local data for a weak client, ADE as the local data for a medium client and CADEC as the local data for the powerful client.\nWe validate the generality of this setting by rotating datasets and client types and draw similar observations.\nFor each client, we randomly take 80% of the local dataset as the training dataset and the rest as the evaluation dataset.\nWe use the seqeval framework",
                "4",
                "4",
                "4",
                "https://github.com/chakki-works/seqeval",
                " to report the maximum averaged F1-score, precision, recall and accuracy on the evaluation dataset to indicate the overall performance or the performance over each type of entity for each client.\nResults for the two settings are reported by averaging over 5 independent repeats.",
                "Baselines.",
                "\nWe compare our proposed ",
                "InclusiveFL",
                " solution with the following naive baselines:",
                "AllLarge",
                ": an ideal baseline to indicate the performance upper bound of training over heterogeneous devices.\nWe remove the resource limitation on weak and medium clients and conduct federated training over all clients participant with a 12-layer RoBERTa model.",
                "AllSmall",
                ": a naive baseline to include all clients with heterogeneous devices and conduct training over the smallest model with 4 layers.",
                "ExclusiveFL",
                ": a naive baseline where weak and medium clients are dropped off in federated training due to the resource limitation on the largest model.",
                "Local",
                ": a naive baseline for cross-silo setting where each client trains the model with the size that fits their local resources.",
                "HeteroFL",
                "¬†",
                "(Diao et¬†al",
                ".",
                ", ",
                "2021",
                ")",
                ": the most related work for training across all clients over heterogeneous devices.\nThe number of parameters in smaller models are reduced in width by cropping each parameter matrix of the largest model into sub-matrix with various reduction radio.",
                "Hyper-Parameter Settings.",
                "\nFor federated training over heterogeneous devices, we assign each client a client type with equal probability before training and fix it during training by default.\nThe effect of different ratios of device types is investigated in our hyper-parameter analysis.\nFor a fair comparison, we keep the number of parameters for each model type in ",
                "HeteroFL",
                " equal to 4-layer, 8-layer and 12-layer models in other baselines by reducing the hidden size from 768 to 456, 624 for weak and medium clients respectively.\nFor ",
                "InclusiveFL",
                ", we set the momentum factor ",
                "Œ≤",
                "=",
                "0.2",
                "ùõΩ",
                "0.2",
                "\\beta=0.2",
                " for all GLUE benchmark and ",
                "Œ≤",
                "=",
                "0.5",
                "ùõΩ",
                "0.5",
                "\\beta=0.5",
                " for medical NER datasets.",
                "For GLUE dataset, we randomly sample a fraction of ",
                "0.02",
                "0.02",
                "0.02",
                " clients in each round with ",
                "R",
                "=",
                "1000",
                "ùëÖ",
                "1000",
                "R=1000",
                ".\nFor NER datasets, we conduct 5 local steps with batch size 64 in each communication round with ",
                "R",
                "=",
                "100",
                "ùëÖ",
                "100",
                "R=100",
                ".\nWe set the same learning rate for each type of the model over all baselines.\nWe use FedAdam ",
                "(Reddi et¬†al",
                ".",
                ", ",
                "2020",
                ")",
                " as the global aggregation protocol over homogeneous models for all baselines."
            ]
        ]
    },
    "S4.T5": {
        "caption": "Table 5. Influence of different proportions of device types on the CoLA dataset.",
        "table": "<table id=\"S4.T5.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T5.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.2.1\" class=\"ltx_td ltx_border_r ltx_border_tt\"></td>\n<td id=\"S4.T5.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T5.1.2.2.1\" class=\"ltx_text ltx_font_bold\">1:1:1</span></td>\n<td id=\"S4.T5.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T5.1.2.3.1\" class=\"ltx_text ltx_font_bold\">1:2:7</span></td>\n<td id=\"S4.T5.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T5.1.2.4.1\" class=\"ltx_text ltx_font_bold\">7:2:1</span></td>\n</tr>\n<tr id=\"S4.T5.1.3\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">AllLarge</td>\n<td id=\"S4.T5.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">63.03</td>\n<td id=\"S4.T5.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">63.03</td>\n<td id=\"S4.T5.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">63.03</td>\n</tr>\n<tr id=\"S4.T5.1.4\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_r\">AllSmall</td>\n<td id=\"S4.T5.1.4.2\" class=\"ltx_td ltx_align_center\">34.91</td>\n<td id=\"S4.T5.1.4.3\" class=\"ltx_td ltx_align_center\">34.91</td>\n<td id=\"S4.T5.1.4.4\" class=\"ltx_td ltx_align_center\">34.91</td>\n</tr>\n<tr id=\"S4.T5.1.5\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.5.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">ExclusiveFL</td>\n<td id=\"S4.T5.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\">37.77</td>\n<td id=\"S4.T5.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\">59.15</td>\n<td id=\"S4.T5.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T5.1.5.4.1\" class=\"ltx_text ltx_font_bold\">36.87</span></td>\n</tr>\n<tr id=\"S4.T5.1.6\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.6.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">HeteroFL</td>\n<td id=\"S4.T5.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_t\">8.15</td>\n<td id=\"S4.T5.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_t\">9.60</td>\n<td id=\"S4.T5.1.6.4\" class=\"ltx_td ltx_align_center ltx_border_t\">N/A</td>\n</tr>\n<tr id=\"S4.T5.1.7\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.7.1\" class=\"ltx_td ltx_align_center ltx_border_r\">InclusiveFL w/o MD</td>\n<td id=\"S4.T5.1.7.2\" class=\"ltx_td ltx_align_center\">52.69</td>\n<td id=\"S4.T5.1.7.3\" class=\"ltx_td ltx_align_center\">60.35</td>\n<td id=\"S4.T5.1.7.4\" class=\"ltx_td ltx_align_center\">N/A</td>\n</tr>\n<tr id=\"S4.T5.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T5.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">InclusiveFL</td>\n<td id=\"S4.T5.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T5.1.1.3.1\" class=\"ltx_text ltx_font_bold\">54.85</span></td>\n<td id=\"S4.T5.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T5.1.1.4.1\" class=\"ltx_text ltx_font_bold\">61.23</span></td>\n<td id=\"S4.T5.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_bb\"><math id=\"S4.T5.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"34.96^{*}\" display=\"inline\"><semantics id=\"S4.T5.1.1.1.m1.1a\"><msup id=\"S4.T5.1.1.1.m1.1.1\" xref=\"S4.T5.1.1.1.m1.1.1.cmml\"><mn id=\"S4.T5.1.1.1.m1.1.1.2\" xref=\"S4.T5.1.1.1.m1.1.1.2.cmml\">34.96</mn><mo id=\"S4.T5.1.1.1.m1.1.1.3\" xref=\"S4.T5.1.1.1.m1.1.1.3.cmml\">‚àó</mo></msup><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.1.1.1.m1.1b\"><apply id=\"S4.T5.1.1.1.m1.1.1.cmml\" xref=\"S4.T5.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.T5.1.1.1.m1.1.1.1.cmml\" xref=\"S4.T5.1.1.1.m1.1.1\">superscript</csymbol><cn type=\"float\" id=\"S4.T5.1.1.1.m1.1.1.2.cmml\" xref=\"S4.T5.1.1.1.m1.1.1.2\">34.96</cn><times id=\"S4.T5.1.1.1.m1.1.1.3.cmml\" xref=\"S4.T5.1.1.1.m1.1.1.3\"></times></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.1.1.1.m1.1c\">34.96^{*}</annotation></semantics></math></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Device type proportion.\nTo investigate the effectiveness of InclusiveFL under different proportions of strong, medium, and weak devices, we present results with 1:2:7, 7:2:1 and a default setting of 1:1:1 on the CoLA dataset in Table 5.\nIn general, increasing the proportion of strong devices results in a better performance of ExclusiveFL and HeteroFL.\nWe can observe that the performance advantage of InclusiveFL is consistent for two device proportions, compared with naive baselines and HeteroFL.\nBut we notice that when the powerful client group is the minority (e.g., 7:2:1), the convergence of the largest model is slow and aggregating over heterogeneous devices is not stable.\nThus, we indicate one result in Table 5 with a superscript of * when only adopt the momentum distillation without sharing layer-wise parameters across heterogeneous models.\nAnd the performance is slightly worse than the best baseline ExclusiveFL with a Matthew‚Äôs correlation of 36.87."
        ]
    }
}