{
    "Sx4.T1": {
        "caption": "Table 1: Mean rank-correlation coefficients A higher value means a better quality. Error bars show standard error of the mean. The results show that attention maps produced by the HAN have the highest correlation with human attention maps, surpassing the human performance by 0.045.",
        "table": "<table id=\"Sx4.T1.5.5\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"Sx4.T1.5.5.6.1\" class=\"ltx_tr\">\n<th id=\"Sx4.T1.5.5.6.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"Sx4.T1.5.5.6.1.1.1\" class=\"ltx_text ltx_font_bold\">Model</span></th>\n<td id=\"Sx4.T1.5.5.6.1.2\" class=\"ltx_td ltx_align_right ltx_border_tt\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"Sx4.T1.5.5.6.1.2.1\" class=\"ltx_text ltx_font_bold\">Mean Rank-correlation</span></td>\n</tr>\n<tr id=\"Sx4.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"Sx4.T1.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">Random</th>\n<td id=\"Sx4.T1.1.1.1.1\" class=\"ltx_td ltx_align_right ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">0.000 <math id=\"Sx4.T1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"Sx4.T1.1.1.1.1.m1.1a\"><mo id=\"Sx4.T1.1.1.1.1.m1.1.1\" xref=\"Sx4.T1.1.1.1.1.m1.1.1.cmml\">Â±</mo><annotation-xml encoding=\"MathML-Content\" id=\"Sx4.T1.1.1.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"Sx4.T1.1.1.1.1.m1.1.1.cmml\" xref=\"Sx4.T1.1.1.1.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx4.T1.1.1.1.1.m1.1c\">\\pm</annotation></semantics></math> 0.001</td>\n</tr>\n<tr id=\"Sx4.T1.2.2.2\" class=\"ltx_tr\">\n<th id=\"Sx4.T1.2.2.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">Human</th>\n<td id=\"Sx4.T1.2.2.2.1\" class=\"ltx_td ltx_align_right\" style=\"padding-top:1pt;padding-bottom:1pt;\">0.623 <math id=\"Sx4.T1.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"Sx4.T1.2.2.2.1.m1.1a\"><mo id=\"Sx4.T1.2.2.2.1.m1.1.1\" xref=\"Sx4.T1.2.2.2.1.m1.1.1.cmml\">Â±</mo><annotation-xml encoding=\"MathML-Content\" id=\"Sx4.T1.2.2.2.1.m1.1b\"><csymbol cd=\"latexml\" id=\"Sx4.T1.2.2.2.1.m1.1.1.cmml\" xref=\"Sx4.T1.2.2.2.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx4.T1.2.2.2.1.m1.1c\">\\pm</annotation></semantics></math> 0.003</td>\n</tr>\n<tr id=\"Sx4.T1.3.3.3\" class=\"ltx_tr\">\n<th id=\"Sx4.T1.3.3.3.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">SAN (<span id=\"Sx4.T1.3.3.3.2.1\" class=\"ltx_text ltx_font_bold\">?</span>)</th>\n<td id=\"Sx4.T1.3.3.3.1\" class=\"ltx_td ltx_align_right\" style=\"padding-top:1pt;padding-bottom:1pt;\">0.249 <math id=\"Sx4.T1.3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"Sx4.T1.3.3.3.1.m1.1a\"><mo id=\"Sx4.T1.3.3.3.1.m1.1.1\" xref=\"Sx4.T1.3.3.3.1.m1.1.1.cmml\">Â±</mo><annotation-xml encoding=\"MathML-Content\" id=\"Sx4.T1.3.3.3.1.m1.1b\"><csymbol cd=\"latexml\" id=\"Sx4.T1.3.3.3.1.m1.1.1.cmml\" xref=\"Sx4.T1.3.3.3.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx4.T1.3.3.3.1.m1.1c\">\\pm</annotation></semantics></math> 0.004</td>\n</tr>\n<tr id=\"Sx4.T1.4.4.4\" class=\"ltx_tr\">\n<th id=\"Sx4.T1.4.4.4.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">HieCoAtt (<span id=\"Sx4.T1.4.4.4.2.1\" class=\"ltx_text ltx_font_bold\">?</span>)</th>\n<td id=\"Sx4.T1.4.4.4.1\" class=\"ltx_td ltx_align_right\" style=\"padding-top:1pt;padding-bottom:1pt;\">0.264 <math id=\"Sx4.T1.4.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"Sx4.T1.4.4.4.1.m1.1a\"><mo id=\"Sx4.T1.4.4.4.1.m1.1.1\" xref=\"Sx4.T1.4.4.4.1.m1.1.1.cmml\">Â±</mo><annotation-xml encoding=\"MathML-Content\" id=\"Sx4.T1.4.4.4.1.m1.1b\"><csymbol cd=\"latexml\" id=\"Sx4.T1.4.4.4.1.m1.1.1.cmml\" xref=\"Sx4.T1.4.4.4.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx4.T1.4.4.4.1.m1.1c\">\\pm</annotation></semantics></math> 0.004</td>\n</tr>\n<tr id=\"Sx4.T1.5.5.5\" class=\"ltx_tr\">\n<th id=\"Sx4.T1.5.5.5.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" style=\"padding-top:1pt;padding-bottom:1pt;\">HAN</th>\n<td id=\"Sx4.T1.5.5.5.1\" class=\"ltx_td ltx_align_right ltx_border_bb\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"Sx4.T1.5.5.5.1.1\" class=\"ltx_text ltx_font_bold\">0.668 <math id=\"Sx4.T1.5.5.5.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"Sx4.T1.5.5.5.1.1.m1.1a\"><mo id=\"Sx4.T1.5.5.5.1.1.m1.1.1\" xref=\"Sx4.T1.5.5.5.1.1.m1.1.1.cmml\">Â±</mo><annotation-xml encoding=\"MathML-Content\" id=\"Sx4.T1.5.5.5.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"Sx4.T1.5.5.5.1.1.m1.1.1.cmml\" xref=\"Sx4.T1.5.5.5.1.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx4.T1.5.5.5.1.1.m1.1c\">\\pm</annotation></semantics></math> 0.001</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "Previous works (?;Â ?) have explored the effect of the different number of glimpses in VQA. It was found that multiple glimpses may result in a better performance. Therefore, the HAN is also evaluated with different glimpses, namely 1, 2, 3 and 4, yielding a performance of 0.536, 0.656, 0.668 and 0.553 respectively.\nThe number of glimpses is set to 3 in the experiment, as the model shows the best performance.\nThe performance of the HAN is presented in Tab.1, where the model achieves the best performance in predicting attention maps.\nAs it can be observed, the performance of the HAN significantly outperforms the VQA models (SAN, HieCoAtt) by around 40%percent\\%, which indicates that the attention explicitly learned by the HAN is more human-like than the attention that is implicitly learned by traditional attention-based models.\nThe correlation between human-labeled attention maps is 0.623,\nwhich shows that different annotators have different views about the relevant area in the image given the same question and the correctness of the attention maps is difficult to define.\nTherefore, for this model, making model-generated attention more human-like is the best choice.\nThe experiment also shows that our generated attention has the highest correlation (0.668) with human attention, showing the ability of the HAN to generate human-like attention maps for image-question pairs."
        ]
    },
    "Sx4.T2": {
        "caption": "Table 2: Results comparison between the HAN using the GRU and the HAN without using the GRU, where GğºG denotes the number of glimpses. As it can be observed, applying a GRU to fuse attention maps significantly improves the performance of the HAN.",
        "table": "<table id=\"Sx4.T2.10.8\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"Sx4.T2.10.8.9.1\" class=\"ltx_tr\">\n<th id=\"Sx4.T2.10.8.9.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"Sx4.T2.10.8.9.1.1.1\" class=\"ltx_text ltx_font_bold\">Model</span></th>\n<th id=\"Sx4.T2.10.8.9.1.2\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"Sx4.T2.10.8.9.1.2.1\" class=\"ltx_text ltx_font_bold\">Mean Rank-correlation</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"Sx4.T2.4.2.2\" class=\"ltx_tr\">\n<th id=\"Sx4.T2.3.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">HAN(<math id=\"Sx4.T2.3.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"G\" display=\"inline\"><semantics id=\"Sx4.T2.3.1.1.1.m1.1a\"><mi id=\"Sx4.T2.3.1.1.1.m1.1.1\" xref=\"Sx4.T2.3.1.1.1.m1.1.1.cmml\">G</mi><annotation-xml encoding=\"MathML-Content\" id=\"Sx4.T2.3.1.1.1.m1.1b\"><ci id=\"Sx4.T2.3.1.1.1.m1.1.1.cmml\" xref=\"Sx4.T2.3.1.1.1.m1.1.1\">ğº</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx4.T2.3.1.1.1.m1.1c\">G</annotation></semantics></math>=2,without GRU)</th>\n<td id=\"Sx4.T2.4.2.2.2\" class=\"ltx_td ltx_align_right ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">0.406 <math id=\"Sx4.T2.4.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"Sx4.T2.4.2.2.2.m1.1a\"><mo id=\"Sx4.T2.4.2.2.2.m1.1.1\" xref=\"Sx4.T2.4.2.2.2.m1.1.1.cmml\">Â±</mo><annotation-xml encoding=\"MathML-Content\" id=\"Sx4.T2.4.2.2.2.m1.1b\"><csymbol cd=\"latexml\" id=\"Sx4.T2.4.2.2.2.m1.1.1.cmml\" xref=\"Sx4.T2.4.2.2.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx4.T2.4.2.2.2.m1.1c\">\\pm</annotation></semantics></math> 0.001</td>\n</tr>\n<tr id=\"Sx4.T2.6.4.4\" class=\"ltx_tr\">\n<th id=\"Sx4.T2.5.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">HAN(<math id=\"Sx4.T2.5.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"G\" display=\"inline\"><semantics id=\"Sx4.T2.5.3.3.1.m1.1a\"><mi id=\"Sx4.T2.5.3.3.1.m1.1.1\" xref=\"Sx4.T2.5.3.3.1.m1.1.1.cmml\">G</mi><annotation-xml encoding=\"MathML-Content\" id=\"Sx4.T2.5.3.3.1.m1.1b\"><ci id=\"Sx4.T2.5.3.3.1.m1.1.1.cmml\" xref=\"Sx4.T2.5.3.3.1.m1.1.1\">ğº</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx4.T2.5.3.3.1.m1.1c\">G</annotation></semantics></math>=2,with GRU)</th>\n<td id=\"Sx4.T2.6.4.4.2\" class=\"ltx_td ltx_align_right\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"Sx4.T2.6.4.4.2.1\" class=\"ltx_text ltx_font_bold\">0.656 <math id=\"Sx4.T2.6.4.4.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"Sx4.T2.6.4.4.2.1.m1.1a\"><mo id=\"Sx4.T2.6.4.4.2.1.m1.1.1\" xref=\"Sx4.T2.6.4.4.2.1.m1.1.1.cmml\">Â±</mo><annotation-xml encoding=\"MathML-Content\" id=\"Sx4.T2.6.4.4.2.1.m1.1b\"><csymbol cd=\"latexml\" id=\"Sx4.T2.6.4.4.2.1.m1.1.1.cmml\" xref=\"Sx4.T2.6.4.4.2.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx4.T2.6.4.4.2.1.m1.1c\">\\pm</annotation></semantics></math> 0.002</span></td>\n</tr>\n<tr id=\"Sx4.T2.8.6.6\" class=\"ltx_tr\">\n<th id=\"Sx4.T2.7.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">HAN(<math id=\"Sx4.T2.7.5.5.1.m1.1\" class=\"ltx_Math\" alttext=\"G\" display=\"inline\"><semantics id=\"Sx4.T2.7.5.5.1.m1.1a\"><mi id=\"Sx4.T2.7.5.5.1.m1.1.1\" xref=\"Sx4.T2.7.5.5.1.m1.1.1.cmml\">G</mi><annotation-xml encoding=\"MathML-Content\" id=\"Sx4.T2.7.5.5.1.m1.1b\"><ci id=\"Sx4.T2.7.5.5.1.m1.1.1.cmml\" xref=\"Sx4.T2.7.5.5.1.m1.1.1\">ğº</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx4.T2.7.5.5.1.m1.1c\">G</annotation></semantics></math>=3,without GRU)</th>\n<td id=\"Sx4.T2.8.6.6.2\" class=\"ltx_td ltx_align_right\" style=\"padding-top:1pt;padding-bottom:1pt;\">0.411 <math id=\"Sx4.T2.8.6.6.2.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"Sx4.T2.8.6.6.2.m1.1a\"><mo id=\"Sx4.T2.8.6.6.2.m1.1.1\" xref=\"Sx4.T2.8.6.6.2.m1.1.1.cmml\">Â±</mo><annotation-xml encoding=\"MathML-Content\" id=\"Sx4.T2.8.6.6.2.m1.1b\"><csymbol cd=\"latexml\" id=\"Sx4.T2.8.6.6.2.m1.1.1.cmml\" xref=\"Sx4.T2.8.6.6.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx4.T2.8.6.6.2.m1.1c\">\\pm</annotation></semantics></math> 0.001</td>\n</tr>\n<tr id=\"Sx4.T2.10.8.8\" class=\"ltx_tr\">\n<th id=\"Sx4.T2.9.7.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" style=\"padding-top:1pt;padding-bottom:1pt;\">HAN(<math id=\"Sx4.T2.9.7.7.1.m1.1\" class=\"ltx_Math\" alttext=\"G\" display=\"inline\"><semantics id=\"Sx4.T2.9.7.7.1.m1.1a\"><mi id=\"Sx4.T2.9.7.7.1.m1.1.1\" xref=\"Sx4.T2.9.7.7.1.m1.1.1.cmml\">G</mi><annotation-xml encoding=\"MathML-Content\" id=\"Sx4.T2.9.7.7.1.m1.1b\"><ci id=\"Sx4.T2.9.7.7.1.m1.1.1.cmml\" xref=\"Sx4.T2.9.7.7.1.m1.1.1\">ğº</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx4.T2.9.7.7.1.m1.1c\">G</annotation></semantics></math>=3,with GRU)</th>\n<td id=\"Sx4.T2.10.8.8.2\" class=\"ltx_td ltx_align_right ltx_border_bb\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n<span id=\"Sx4.T2.10.8.8.2.1\" class=\"ltx_text ltx_font_bold\">0.668</span> <math id=\"Sx4.T2.10.8.8.2.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"Sx4.T2.10.8.8.2.m1.1a\"><mo id=\"Sx4.T2.10.8.8.2.m1.1.1\" xref=\"Sx4.T2.10.8.8.2.m1.1.1.cmml\">Â±</mo><annotation-xml encoding=\"MathML-Content\" id=\"Sx4.T2.10.8.8.2.m1.1b\"><csymbol cd=\"latexml\" id=\"Sx4.T2.10.8.8.2.m1.1.1.cmml\" xref=\"Sx4.T2.10.8.8.2.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx4.T2.10.8.8.2.m1.1c\">\\pm</annotation></semantics></math> <span id=\"Sx4.T2.10.8.8.2.2\" class=\"ltx_text ltx_font_bold\">0.001</span>\n</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "In order to verify the effectiveness of using the GRU to fuse attention maps, two experiments are conducted with the number of glimpses equal to 2 and 3.\nSpecifically, in these two experiments, instead of fusing the attention maps using the GRU, the average attention map is obtained among several attention maps.\nThe performance of our model with and without GRU is shown in Tab.2.\nThe HAN using the GRU significantly outperforms the HAN without using the GRU, showing the effectiveness of using the GRU to encode the attention maps."
        ]
    },
    "Sx4.T3": {
        "caption": "Table 3: The VQA v2.0 test-dev results, where GğºG denotes the number of glimpses.",
        "table": "<table id=\"Sx4.T3.6.4\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"Sx4.T3.6.4.5.1\" class=\"ltx_tr\">\n<th id=\"Sx4.T3.6.4.5.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"Sx4.T3.6.4.5.1.1.1\" class=\"ltx_text ltx_font_bold\">Model</span></th>\n<td id=\"Sx4.T3.6.4.5.1.2\" class=\"ltx_td ltx_align_right ltx_border_tt\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"Sx4.T3.6.4.5.1.2.1\" class=\"ltx_text ltx_font_bold\">Yes/No</span></td>\n<td id=\"Sx4.T3.6.4.5.1.3\" class=\"ltx_td ltx_align_right ltx_border_tt\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"Sx4.T3.6.4.5.1.3.1\" class=\"ltx_text ltx_font_bold\">Number</span></td>\n<td id=\"Sx4.T3.6.4.5.1.4\" class=\"ltx_td ltx_align_right ltx_border_tt\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"Sx4.T3.6.4.5.1.4.1\" class=\"ltx_text ltx_font_bold\">Other</span></td>\n<td id=\"Sx4.T3.6.4.5.1.5\" class=\"ltx_td ltx_align_right ltx_border_tt\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"Sx4.T3.6.4.5.1.5.1\" class=\"ltx_text ltx_font_bold\">Overall</span></td>\n</tr>\n<tr id=\"Sx4.T3.6.4.6.2\" class=\"ltx_tr\">\n<th id=\"Sx4.T3.6.4.6.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">Prior</th>\n<td id=\"Sx4.T3.6.4.6.2.2\" class=\"ltx_td ltx_align_right ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">61.20</td>\n<td id=\"Sx4.T3.6.4.6.2.3\" class=\"ltx_td ltx_align_right ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">0.36</td>\n<td id=\"Sx4.T3.6.4.6.2.4\" class=\"ltx_td ltx_align_right ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">1.17</td>\n<td id=\"Sx4.T3.6.4.6.2.5\" class=\"ltx_td ltx_align_right ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">25.98</td>\n</tr>\n<tr id=\"Sx4.T3.6.4.7.3\" class=\"ltx_tr\">\n<th id=\"Sx4.T3.6.4.7.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">Language-only</th>\n<td id=\"Sx4.T3.6.4.7.3.2\" class=\"ltx_td ltx_align_right\" style=\"padding-top:1pt;padding-bottom:1pt;\">26.3</td>\n<td id=\"Sx4.T3.6.4.7.3.3\" class=\"ltx_td ltx_align_right\" style=\"padding-top:1pt;padding-bottom:1pt;\">28.1</td>\n<td id=\"Sx4.T3.6.4.7.3.4\" class=\"ltx_td ltx_align_right\" style=\"padding-top:1pt;padding-bottom:1pt;\">28.1</td>\n<td id=\"Sx4.T3.6.4.7.3.5\" class=\"ltx_td ltx_align_right\" style=\"padding-top:1pt;padding-bottom:1pt;\">28.1</td>\n</tr>\n<tr id=\"Sx4.T3.6.4.8.4\" class=\"ltx_tr\">\n<th id=\"Sx4.T3.6.4.8.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">d-LSTM Q+norm I</th>\n<td id=\"Sx4.T3.6.4.8.4.2\" class=\"ltx_td ltx_align_right\" style=\"padding-top:1pt;padding-bottom:1pt;\">26.3</td>\n<td id=\"Sx4.T3.6.4.8.4.3\" class=\"ltx_td ltx_align_right\" style=\"padding-top:1pt;padding-bottom:1pt;\">28.1</td>\n<td id=\"Sx4.T3.6.4.8.4.4\" class=\"ltx_td ltx_align_right\" style=\"padding-top:1pt;padding-bottom:1pt;\">41.85</td>\n<td id=\"Sx4.T3.6.4.8.4.5\" class=\"ltx_td ltx_align_right\" style=\"padding-top:1pt;padding-bottom:1pt;\">54.22</td>\n</tr>\n<tr id=\"Sx4.T3.6.4.9.5\" class=\"ltx_tr\">\n<th id=\"Sx4.T3.6.4.9.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">(<span id=\"Sx4.T3.6.4.9.5.1.1\" class=\"ltx_text ltx_font_bold\">?</span>)</th>\n<td id=\"Sx4.T3.6.4.9.5.2\" class=\"ltx_td\" style=\"padding-top:1pt;padding-bottom:1pt;\"></td>\n<td id=\"Sx4.T3.6.4.9.5.3\" class=\"ltx_td\" style=\"padding-top:1pt;padding-bottom:1pt;\"></td>\n<td id=\"Sx4.T3.6.4.9.5.4\" class=\"ltx_td\" style=\"padding-top:1pt;padding-bottom:1pt;\"></td>\n<td id=\"Sx4.T3.6.4.9.5.5\" class=\"ltx_td\" style=\"padding-top:1pt;padding-bottom:1pt;\"></td>\n</tr>\n<tr id=\"Sx4.T3.3.1.1\" class=\"ltx_tr\">\n<th id=\"Sx4.T3.3.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">unsupervised model(<math id=\"Sx4.T3.3.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"G\" display=\"inline\"><semantics id=\"Sx4.T3.3.1.1.1.m1.1a\"><mi id=\"Sx4.T3.3.1.1.1.m1.1.1\" xref=\"Sx4.T3.3.1.1.1.m1.1.1.cmml\">G</mi><annotation-xml encoding=\"MathML-Content\" id=\"Sx4.T3.3.1.1.1.m1.1b\"><ci id=\"Sx4.T3.3.1.1.1.m1.1.1.cmml\" xref=\"Sx4.T3.3.1.1.1.m1.1.1\">ğº</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx4.T3.3.1.1.1.m1.1c\">G</annotation></semantics></math>=1)</th>\n<td id=\"Sx4.T3.3.1.1.2\" class=\"ltx_td ltx_align_right ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">78.12</td>\n<td id=\"Sx4.T3.3.1.1.3\" class=\"ltx_td ltx_align_right ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">37.52</td>\n<td id=\"Sx4.T3.3.1.1.4\" class=\"ltx_td ltx_align_right ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">52.92</td>\n<td id=\"Sx4.T3.3.1.1.5\" class=\"ltx_td ltx_align_right ltx_border_t\" style=\"padding-top:1pt;padding-bottom:1pt;\">61.55</td>\n</tr>\n<tr id=\"Sx4.T3.4.2.2\" class=\"ltx_tr\">\n<th id=\"Sx4.T3.4.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">supervised model(<math id=\"Sx4.T3.4.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"G\" display=\"inline\"><semantics id=\"Sx4.T3.4.2.2.1.m1.1a\"><mi id=\"Sx4.T3.4.2.2.1.m1.1.1\" xref=\"Sx4.T3.4.2.2.1.m1.1.1.cmml\">G</mi><annotation-xml encoding=\"MathML-Content\" id=\"Sx4.T3.4.2.2.1.m1.1b\"><ci id=\"Sx4.T3.4.2.2.1.m1.1.1.cmml\" xref=\"Sx4.T3.4.2.2.1.m1.1.1\">ğº</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx4.T3.4.2.2.1.m1.1c\">G</annotation></semantics></math>=1)</th>\n<td id=\"Sx4.T3.4.2.2.2\" class=\"ltx_td ltx_align_right\" style=\"padding-top:1pt;padding-bottom:1pt;\">78.03</td>\n<td id=\"Sx4.T3.4.2.2.3\" class=\"ltx_td ltx_align_right\" style=\"padding-top:1pt;padding-bottom:1pt;\">37.93</td>\n<td id=\"Sx4.T3.4.2.2.4\" class=\"ltx_td ltx_align_right\" style=\"padding-top:1pt;padding-bottom:1pt;\">53.14</td>\n<td id=\"Sx4.T3.4.2.2.5\" class=\"ltx_td ltx_align_right\" style=\"padding-top:1pt;padding-bottom:1pt;\">61.66</td>\n</tr>\n<tr id=\"Sx4.T3.5.3.3\" class=\"ltx_tr\">\n<th id=\"Sx4.T3.5.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-top:1pt;padding-bottom:1pt;\">unsupervised model(<math id=\"Sx4.T3.5.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"G\" display=\"inline\"><semantics id=\"Sx4.T3.5.3.3.1.m1.1a\"><mi id=\"Sx4.T3.5.3.3.1.m1.1.1\" xref=\"Sx4.T3.5.3.3.1.m1.1.1.cmml\">G</mi><annotation-xml encoding=\"MathML-Content\" id=\"Sx4.T3.5.3.3.1.m1.1b\"><ci id=\"Sx4.T3.5.3.3.1.m1.1.1.cmml\" xref=\"Sx4.T3.5.3.3.1.m1.1.1\">ğº</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx4.T3.5.3.3.1.m1.1c\">G</annotation></semantics></math>=2)</th>\n<td id=\"Sx4.T3.5.3.3.2\" class=\"ltx_td ltx_align_right\" style=\"padding-top:1pt;padding-bottom:1pt;\">78.4</td>\n<td id=\"Sx4.T3.5.3.3.3\" class=\"ltx_td ltx_align_right\" style=\"padding-top:1pt;padding-bottom:1pt;\">37.52</td>\n<td id=\"Sx4.T3.5.3.3.4\" class=\"ltx_td ltx_align_right\" style=\"padding-top:1pt;padding-bottom:1pt;\">53.29</td>\n<td id=\"Sx4.T3.5.3.3.5\" class=\"ltx_td ltx_align_right\" style=\"padding-top:1pt;padding-bottom:1pt;\">61.84</td>\n</tr>\n<tr id=\"Sx4.T3.6.4.4\" class=\"ltx_tr\">\n<th id=\"Sx4.T3.6.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\" style=\"padding-top:1pt;padding-bottom:1pt;\">supervised model(<math id=\"Sx4.T3.6.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"G\" display=\"inline\"><semantics id=\"Sx4.T3.6.4.4.1.m1.1a\"><mi id=\"Sx4.T3.6.4.4.1.m1.1.1\" xref=\"Sx4.T3.6.4.4.1.m1.1.1.cmml\">G</mi><annotation-xml encoding=\"MathML-Content\" id=\"Sx4.T3.6.4.4.1.m1.1b\"><ci id=\"Sx4.T3.6.4.4.1.m1.1.1.cmml\" xref=\"Sx4.T3.6.4.4.1.m1.1.1\">ğº</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"Sx4.T3.6.4.4.1.m1.1c\">G</annotation></semantics></math>=2)</th>\n<td id=\"Sx4.T3.6.4.4.2\" class=\"ltx_td ltx_align_right ltx_border_bb\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"Sx4.T3.6.4.4.2.1\" class=\"ltx_text ltx_font_bold\">78.54</span></td>\n<td id=\"Sx4.T3.6.4.4.3\" class=\"ltx_td ltx_align_right ltx_border_bb\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"Sx4.T3.6.4.4.3.1\" class=\"ltx_text ltx_font_bold\">37.94</span></td>\n<td id=\"Sx4.T3.6.4.4.4\" class=\"ltx_td ltx_align_right ltx_border_bb\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"Sx4.T3.6.4.4.4.1\" class=\"ltx_text ltx_font_bold\">53.38</span></td>\n<td id=\"Sx4.T3.6.4.4.5\" class=\"ltx_td ltx_align_right ltx_border_bb\" style=\"padding-top:1pt;padding-bottom:1pt;\"><span id=\"Sx4.T3.6.4.4.5.1\" class=\"ltx_text ltx_font_bold\">61.99</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "Tab.3 presents the accuracy comparison between the unsupervised model and the supervised model on the VQA v2.0 dataset.\nThe accuracy of Prior, Language-only, deeper LSTM Q + norm I baseline models in (?) are also presented for comparison.\nAs shown in this table, our supervised model outperforms the unsupervised model by 0.11%percent\\% when the number of glimpses is set to 1 and by 0.15%percent\\% when the number of glimpses is set to 2, showing the effectiveness of applying attention supervision to attention-based model.\nThe supervised model achieves a much higher accuracy when the question is a counting problem,\nwhich indicates that the generated attention in the supervised model is more accurate and comprehensive.\nFig.5 samples the attention maps and the answers that are predicted by both the unsupervised model and the supervised model.\nAs it can be observed, after human-like attention supervision, the attention maps are more accurate and focused on the most relevant areas.\nIt can therefore be concluded that more human-like attention helps to improve the performance of the model."
        ]
    }
}