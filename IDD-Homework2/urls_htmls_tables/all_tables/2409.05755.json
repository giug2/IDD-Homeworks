{
    "id_table_1": {
        "caption": "Table 1:  Comparison of baseline models with (w) and without (w/o) hyperparameter tuning. The results are highlighted in  red  if hyperparameter tuning significantly improve the model performance. The un-tuned models use the hyperparameters provided in  [ 53 ] .",
        "table": "S2.E1",
        "footnotes": [
            ""
        ],
        "references": [
            "Frechet Distance Based Quantitative Evaluation Benchmark for Homophily Metrics.  In Section  4.1 , we evaluate  11 11 11 11  popular homophily metrics on synthetic graphs with three graph generation approaches. We find that the correlations between metric curves and GNN performance curves are different between graphs with different generation methods, and it is hard to tell which metric is better only by observation. To compare them strictly and accurately, in Section  4.2 , we propose a Frechet distance based method to assess the metrics and it is the first quantitative evaluation benchmark.",
            "In this section, we conduct a series of experiments with fine-tuned hyperparameters for accurate assessment and fair comparison of GNNs built for heterophilic graphs. Specifically, in Section  3.1 , we introduce the  27 27 27 27  benchmark datasets used in this paper and the experimental setups; in Section  3.2 , we use the performance of baseline models to demonstrate the necessity of hyperparameter tuning for fair comparison; in Section  3.3 , based on the performance of fine-tuned graph-aware and graph-agnostic models, we classify the existing heterophily benchmark datasets into malignant, benign and ambiguous groups, and we argue that the real challenging tasks are on malignant and ambiguous datasets; in Section  3.4 , we re-evaluate  10 10 10 10  popular SOTA models with fine-tuned hyperparameters on each group of heterophilic graphs to reassess their effectiveness and disclose their limitations on addressing heterophily.",
            "To demonstrate the importance of hyperparameter fine-tuning, following  [ 39 ] , we first fine-tune two baseline GNNs, GCN  [ 8 ]  and 1-hop SGC (SGC-1)  [ 41 ] , and their coupled graph-agnostic models, MLP-2 and MLP-1  2 2 2 Note that for fair evaluation, we remove all tricks in model architectures, such as residual connection and batch normalization, and only keep the original models for tests.  on the datasets where the baseline models are claimed to be quite robust to hyperparameter values  [ 53 ] . From the experimental results shown in Table  1 , we have identified a serious pitfall for model evaluation on heterophilic datasets,  i.e.,  there exits a huge discrepancy between the model performance with and without (w/o) hyperparameter fine-tuning, even on the hyperparameter-robust datasets. In Table  1 , we can see that in  19 19 19 19  out of  28 28 28 28  cases, hyperparameter fine-tuning can significantly improve model performance. This implies that a large amount of reported results in existing literature are potentially unreliable if there is no fine-tuning or the hyperparameter searching range is not large enough. This pitfall significantly hinders the fair model comparison and disrupt our way to discover the real challenging heterophilic datasets and really effective models. (See Appendix  A.1  for our hyperparameter searching range.)",
            "Based on the new categorization of heterophilic datasets, our next question is:  are our current SOTA GNN models really effective on heterophily challenge?  In this subsection, we reassess  10 10 10 10  popular SOTA GNNs with fine-tuned hyperparameters on different groups of heterophilic benchmark datasets 4 4 4 See Appendix  A.1  for the hyperparameter searching range. . The models we select are: H 2 GCN  [ 24 ] , GPRGNN  [ 30 ] , BernNet  [ 32 ] , FAGCN  [ 28 ] , ACM-GCN*  [ 34 ] 5 5 5 ACM-GCN has lots of variants, we report the best results of them as ACM-GCN*. , LINKX  [ 29 ] , GloGNN  [ 33 ] , GBK-GNN  [ 57 ] , FSGNN  [ 58 ] , APPNP  [ 59 ] . In this paper,  we call a heterophily-specific GNN a good model if it performs significantly better than baseline models on heterophily datasets, especially on malignant and ambiguous heterophily graphs, and perform at least as good as baseline models on homophily graphs.  According to the results in Table  3 , we find that,",
            "Homophily metrics are proposed to help people recognize the challenging heterophilic datasets  [ 39 ]  and people usually evaluate the metrics by synthetic graphs. In Section  4.1 , we summarize three most widely used graph generation methods; in Section  4.2 , we introduce the current evaluation methods, compare  11 11 11 11  popular homophily metrics on synthetic graphs and illustrate the challenges in the observation-based evaluation approach; in Section  4.3 , we propose a Frechet distance based benchmark to compare the metrics strictly and quantitatively.",
            "Luan  et al.   [ 34 ]  proposed to generate regular graphs as follows: 1)  10 10 10 10  graphs are generated for each of the  28 28 28 28  edge homophily levels, from  0.005 0.005 0.005 0.005  to  0.95 0.95 0.95 0.95 , with a total of  280 280 280 280  graphs; 2) Every generated graph has five classes, with  400 400 400 400  nodes in each class. For nodes in each class,  800 800 800 800  random intra-class edges and [ 800 H edge  ( G )  800 800 subscript H edge G 800 \\frac{800}{\\text{H}_{\\text{edge}}(\\mathcal{G})}-800 divide start_ARG 800 end_ARG start_ARG H start_POSTSUBSCRIPT edge end_POSTSUBSCRIPT ( caligraphic_G ) end_ARG - 800 ] inter-class edges are uniformly generated ; 3) The features of nodes in each class are sampled from node features in the corresponding class of the base datasets,  e.g.,  Figure  1  (a)(d) are based on the node features from  Cora .",
            "The performance curves of baseline models are shown in Figure  1  (a)(b)(c) and the metric curves are shown in Figure  1  (d)(e)(f). From the figures we observe that",
            "Inconsistent Shapes of GNN Performance Curves Between Methods.  The curves in RG (Figure  1 (a)) are fully U-shaped, which indicates the performance of GNNs in low-homophily area can rebound up to the same level as the high-homophily area. However, in PA and GenCat, the curves are partially U-shaped, which implies that the performance in heterophily area cannot rebound back to the same level as homophily area.",
            "Different Correlations Between Metrics and GNN Performance.  The highest correlated metrics are inconsistent between figures. For example in Figure  1 (d), the curves of  KR L , KR NL subscript KR L subscript KR NL \\text{KR}_{\\text{L}},\\text{KR}_{\\text{NL}} KR start_POSTSUBSCRIPT L end_POSTSUBSCRIPT , KR start_POSTSUBSCRIPT NL end_POSTSUBSCRIPT  and GNB highly correlate the curves of baseline GNNs on regular graphs. However, in PA, the curves of label informativeness and aggregated homophily have the highest correlations; and in GenCat, the curves of label informativeness and  KR L , KR NL subscript KR L subscript KR NL \\text{KR}_{\\text{L}},\\text{KR}_{\\text{NL}} KR start_POSTSUBSCRIPT L end_POSTSUBSCRIPT , KR start_POSTSUBSCRIPT NL end_POSTSUBSCRIPT  exhibit the strongest correlations."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:  Categorization of benchmark datasets. The cells marked by green are the better results for the comparison of graph-aware models vs. graph-agnostic models.",
        "table": "S2.E2",
        "footnotes": [],
        "references": [
            "Frechet Distance Based Quantitative Evaluation Benchmark for Homophily Metrics.  In Section  4.1 , we evaluate  11 11 11 11  popular homophily metrics on synthetic graphs with three graph generation approaches. We find that the correlations between metric curves and GNN performance curves are different between graphs with different generation methods, and it is hard to tell which metric is better only by observation. To compare them strictly and accurately, in Section  4.2 , we propose a Frechet distance based method to assess the metrics and it is the first quantitative evaluation benchmark.",
            "In this section, we conduct a series of experiments with fine-tuned hyperparameters for accurate assessment and fair comparison of GNNs built for heterophilic graphs. Specifically, in Section  3.1 , we introduce the  27 27 27 27  benchmark datasets used in this paper and the experimental setups; in Section  3.2 , we use the performance of baseline models to demonstrate the necessity of hyperparameter tuning for fair comparison; in Section  3.3 , based on the performance of fine-tuned graph-aware and graph-agnostic models, we classify the existing heterophily benchmark datasets into malignant, benign and ambiguous groups, and we argue that the real challenging tasks are on malignant and ambiguous datasets; in Section  3.4 , we re-evaluate  10 10 10 10  popular SOTA models with fine-tuned hyperparameters on each group of heterophilic graphs to reassess their effectiveness and disclose their limitations on addressing heterophily.",
            "Due to the unreliable reported results in previous papers, a question arises:  are all the existing heterophilic benchmark datasets really harmful for message passing?  Due to the importance of hyperparameter tuning demonstrated in the above section, we reassess  27 27 27 27  benchmark datasets with fine-tuned baseline models. The statistics and experimental results are shown in Table  2 . In this paper, a dataset is considered as heterophilic if at least one of its  H edge subscript H edge \\text{H}_{\\text{edge}} H start_POSTSUBSCRIPT edge end_POSTSUBSCRIPT  or  H node subscript H node \\text{H}_{\\text{node}} H start_POSTSUBSCRIPT node end_POSTSUBSCRIPT  value is smaller or close to  0.5 0.5 0.5 0.5 , otherwise it is homophilic. From the results in Table  2 , we have identified heterophilic datasets with distinct properties, marking a novel discovery,",
            "Homophily metrics are proposed to help people recognize the challenging heterophilic datasets  [ 39 ]  and people usually evaluate the metrics by synthetic graphs. In Section  4.1 , we summarize three most widely used graph generation methods; in Section  4.2 , we introduce the current evaluation methods, compare  11 11 11 11  popular homophily metrics on synthetic graphs and illustrate the challenges in the observation-based evaluation approach; in Section  4.3 , we propose a Frechet distance based benchmark to compare the metrics strictly and quantitatively."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:  Re-evaluation of  10 10 10 10  SOTA models on different categories of datasets. The result is marked by  red  if it is lower than the best of baseline models (GCN, SGC-1, MLP-2, MLP-1); the cell is marked by  red  if the result is lower than the worst of baseline models. OOM indicates out of memory.",
        "table": "S2.E3",
        "footnotes": [],
        "references": [
            "Fine-tune Baseline Models and Discover Malignant, Benign and Ambiguous Heterophily Datasets.  To find out the real challenging heterophilic datasets, in Section  3.3 , we fine-tune graph-aware models and their corresponding graph-agnostic models on  27 27 27 27  most used benchmark datasets. We find that there exist three disjoint sets of heterophilic datasets, where graph-aware models: 1) consistently outperform graph-aware models; 2) consistently underperform graph-aware models; 3) have inconsistent performance against graph-aware models. Based on this discovery, we categorize them into three types of heterophilic graphs: malignant, benign and ambiguous, and we argue that the malignant and ambiguous datasets are the truly challenging ones which should be used to validate the effectiveness of newly proposed models. Besides, several popular heterophilic datasets are actually mis-classified and found to be homophilic.",
            "Fine-tune  10 10 10 10  SOTA Graph Models For Fair Comparison and Re-evaluation.  In Section  3.4 , we reassess  10 10 10 10  state-of-the-arts (SOTA) GNNs with fine-tuned hyperparameters on the  27 27 27 27  benchmark datasets. Based on the results, the efficacy of some widely used methods is questionable,  e.g.,  most SOTA heterophily GNNs are not significantly better than a simple ensemble of the baseline models, and some of them actually compromise their performance on homophilic graphs in order to achieve good performance on heterophilic graphs.",
            "In this section, we conduct a series of experiments with fine-tuned hyperparameters for accurate assessment and fair comparison of GNNs built for heterophilic graphs. Specifically, in Section  3.1 , we introduce the  27 27 27 27  benchmark datasets used in this paper and the experimental setups; in Section  3.2 , we use the performance of baseline models to demonstrate the necessity of hyperparameter tuning for fair comparison; in Section  3.3 , based on the performance of fine-tuned graph-aware and graph-agnostic models, we classify the existing heterophily benchmark datasets into malignant, benign and ambiguous groups, and we argue that the real challenging tasks are on malignant and ambiguous datasets; in Section  3.4 , we re-evaluate  10 10 10 10  popular SOTA models with fine-tuned hyperparameters on each group of heterophilic graphs to reassess their effectiveness and disclose their limitations on addressing heterophily.",
            "Based on the new categorization of heterophilic datasets, our next question is:  are our current SOTA GNN models really effective on heterophily challenge?  In this subsection, we reassess  10 10 10 10  popular SOTA GNNs with fine-tuned hyperparameters on different groups of heterophilic benchmark datasets 4 4 4 See Appendix  A.1  for the hyperparameter searching range. . The models we select are: H 2 GCN  [ 24 ] , GPRGNN  [ 30 ] , BernNet  [ 32 ] , FAGCN  [ 28 ] , ACM-GCN*  [ 34 ] 5 5 5 ACM-GCN has lots of variants, we report the best results of them as ACM-GCN*. , LINKX  [ 29 ] , GloGNN  [ 33 ] , GBK-GNN  [ 57 ] , FSGNN  [ 58 ] , APPNP  [ 59 ] . In this paper,  we call a heterophily-specific GNN a good model if it performs significantly better than baseline models on heterophily datasets, especially on malignant and ambiguous heterophily graphs, and perform at least as good as baseline models on homophily graphs.  According to the results in Table  3 , we find that,",
            "Homophily metrics are proposed to help people recognize the challenging heterophilic datasets  [ 39 ]  and people usually evaluate the metrics by synthetic graphs. In Section  4.1 , we summarize three most widely used graph generation methods; in Section  4.2 , we introduce the current evaluation methods, compare  11 11 11 11  popular homophily metrics on synthetic graphs and illustrate the challenges in the observation-based evaluation approach; in Section  4.3 , we propose a Frechet distance based benchmark to compare the metrics strictly and quantitatively."
        ]
    },
    "id_table_4": {
        "caption": "Table 4:  Frechet distance based quantitative comparison of homophily metrics on synthetic graphs",
        "table": "S2.E4",
        "footnotes": [],
        "references": [
            "Fine-tune  10 10 10 10  SOTA Graph Models For Fair Comparison and Re-evaluation.  In Section  3.4 , we reassess  10 10 10 10  state-of-the-arts (SOTA) GNNs with fine-tuned hyperparameters on the  27 27 27 27  benchmark datasets. Based on the results, the efficacy of some widely used methods is questionable,  e.g.,  most SOTA heterophily GNNs are not significantly better than a simple ensemble of the baseline models, and some of them actually compromise their performance on homophilic graphs in order to achieve good performance on heterophilic graphs.",
            "Frechet Distance Based Quantitative Evaluation Benchmark for Homophily Metrics.  In Section  4.1 , we evaluate  11 11 11 11  popular homophily metrics on synthetic graphs with three graph generation approaches. We find that the correlations between metric curves and GNN performance curves are different between graphs with different generation methods, and it is hard to tell which metric is better only by observation. To compare them strictly and accurately, in Section  4.2 , we propose a Frechet distance based method to assess the metrics and it is the first quantitative evaluation benchmark.",
            "Overall,  H adj subscript H adj \\text{H}_{\\text{adj}} H start_POSTSUBSCRIPT adj end_POSTSUBSCRIPT  can assume negative values, while other metrics all fall within the range of  [ 0 , 1 ] 0 1 [0,1] [ 0 , 1 ] . Except for  H neighbor  ( G ) subscript H neighbor G \\text{H}_{\\text{neighbor}}(\\mathcal{G}) H start_POSTSUBSCRIPT neighbor end_POSTSUBSCRIPT ( caligraphic_G ) , where a smaller value indicates more identifiable 1 1 1 To compare with other metrics more easily, in this paper, we use  1  H neighbor  ( G ) 1 subscript H neighbor G 1-\\text{H}_{\\text{neighbor}}(\\mathcal{G}) 1 - H start_POSTSUBSCRIPT neighbor end_POSTSUBSCRIPT ( caligraphic_G )  for quantitative analysis. , the other metrics with higher values indicate strong homophily, implying that graph-aware models are more likely to outperform their coupled graph-agnostic model, and vice versa. These metrics will be compared in Section  4 .",
            "In this section, we conduct a series of experiments with fine-tuned hyperparameters for accurate assessment and fair comparison of GNNs built for heterophilic graphs. Specifically, in Section  3.1 , we introduce the  27 27 27 27  benchmark datasets used in this paper and the experimental setups; in Section  3.2 , we use the performance of baseline models to demonstrate the necessity of hyperparameter tuning for fair comparison; in Section  3.3 , based on the performance of fine-tuned graph-aware and graph-agnostic models, we classify the existing heterophily benchmark datasets into malignant, benign and ambiguous groups, and we argue that the real challenging tasks are on malignant and ambiguous datasets; in Section  3.4 , we re-evaluate  10 10 10 10  popular SOTA models with fine-tuned hyperparameters on each group of heterophilic graphs to reassess their effectiveness and disclose their limitations on addressing heterophily.",
            "Homophily metrics are proposed to help people recognize the challenging heterophilic datasets  [ 39 ]  and people usually evaluate the metrics by synthetic graphs. In Section  4.1 , we summarize three most widely used graph generation methods; in Section  4.2 , we introduce the current evaluation methods, compare  11 11 11 11  popular homophily metrics on synthetic graphs and illustrate the challenges in the observation-based evaluation approach; in Section  4.3 , we propose a Frechet distance based benchmark to compare the metrics strictly and quantitatively.",
            "The Frechet distance between two curves is a metric to measure the similarity between two arbitrary curves and it can be approximately calculated by the discrete Frechet distance  [ 64 ,  65 ] . A smaller distance value indicates higher similarity. In this section, we use the discrete Frechet distance between the metric curves and GNN performance curves to evaluate and compare the homophily metrics quantitatively  8 8 8 We use the Python implementation for the calculation of discrete Frechet distance provided by  [ 66 ] . The code is from  https://pypi.org/project/frechetdist/ . . The results are reported in Table  4  and a smaller value implies that the metric can better reflect GNN performance. From the results we can see that,",
            "H edge , H node , H class , H adj subscript H edge subscript H node subscript H class subscript H adj \\text{H}_{\\text{edge}},\\text{H}_{\\text{node}},\\text{H}_{\\text{class}},\\text{H}% _{\\text{adj}} H start_POSTSUBSCRIPT edge end_POSTSUBSCRIPT , H start_POSTSUBSCRIPT node end_POSTSUBSCRIPT , H start_POSTSUBSCRIPT class end_POSTSUBSCRIPT , H start_POSTSUBSCRIPT adj end_POSTSUBSCRIPT  and  LI  are linear feature-independent metrics.  L  I L I LI italic_L italic_I  and  H neighbor  ( G ) subscript H neighbor G {H}_{\\text{neighbor}}(\\mathcal{G}) italic_H start_POSTSUBSCRIPT neighbor end_POSTSUBSCRIPT ( caligraphic_G )  are nonlinear feature-independent metrics.  H GE subscript H GE \\text{H}_{\\text{GE}} H start_POSTSUBSCRIPT GE end_POSTSUBSCRIPT  and  H agg subscript H agg \\text{H}_{\\text{agg}} H start_POSTSUBSCRIPT agg end_POSTSUBSCRIPT  are feature-dependent and measure the linear similarity between nodes. CPM is the first metric that can capture nonlinear feature-dependent information and provide accurate threshold values to indicate the superiority of graph-aware models. In Section  4 , we will introduce the approach for the comparison of the above metrics by synthetic graphs with different generation methods."
        ]
    },
    "id_table_5": {
        "caption": "",
        "table": "S2.E5",
        "footnotes": [],
        "references": []
    },
    "id_table_6": {
        "caption": "",
        "table": "S3.T1.56.56",
        "footnotes": [],
        "references": []
    },
    "id_table_7": {
        "caption": "",
        "table": "S3.T2.110.110",
        "footnotes": [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
        ],
        "references": []
    },
    "id_table_8": {
        "caption": "",
        "table": "S3.T3.244.242",
        "footnotes": [],
        "references": []
    },
    "id_table_9": {
        "caption": "",
        "table": "S4.T4.13.13",
        "footnotes": [],
        "references": []
    },
    "id_table_10": {
        "caption": "",
        "table": "A2.E7",
        "footnotes": [],
        "references": []
    },
    "id_table_11": {
        "caption": "",
        "table": "A2.E8",
        "footnotes": [],
        "references": []
    },
    "id_table_12": {
        "caption": "",
        "table": "A2.E9",
        "footnotes": [],
        "references": []
    },
    "id_table_13": {
        "caption": "",
        "table": "A2.E10",
        "footnotes": [],
        "references": []
    }
}