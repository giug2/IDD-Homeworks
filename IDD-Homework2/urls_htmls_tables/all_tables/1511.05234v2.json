{
    "S4.T1": {
        "caption": "Table 1: Accuracy results on the DAQUAR dataset (in percentage).",
        "table": "<table id=\"S4.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_rr ltx_border_t\"></th>\n<th id=\"S4.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T1.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">DAQUAR</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\">\n<span id=\"S4.T1.1.2.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Multi-World </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T1.1.2.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib1\" title=\"\" class=\"ltx_ref\">1</a><span id=\"S4.T1.1.2.1.1.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n</th>\n<td id=\"S4.T1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T1.1.2.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">12.73</span></td>\n</tr>\n<tr id=\"S4.T1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr\">\n<span id=\"S4.T1.1.3.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Neural-Image-QA </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T1.1.3.2.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">10</a><span id=\"S4.T1.1.3.2.1.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n</th>\n<td id=\"S4.T1.1.3.2.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.1.3.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">29.27</span></td>\n</tr>\n<tr id=\"S4.T1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr\">\n<span id=\"S4.T1.1.4.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Question LSTM </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T1.1.4.3.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">10</a><span id=\"S4.T1.1.4.3.1.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n</th>\n<td id=\"S4.T1.1.4.3.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.1.4.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">32.32</span></td>\n</tr>\n<tr id=\"S4.T1.1.5.4\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr\">\n<span id=\"S4.T1.1.5.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">VIS+LSTM </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T1.1.5.4.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib11\" title=\"\" class=\"ltx_ref\">11</a><span id=\"S4.T1.1.5.4.1.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n</th>\n<td id=\"S4.T1.1.5.4.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.1.5.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">34.41</span></td>\n</tr>\n<tr id=\"S4.T1.1.6.5\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr\">\n<span id=\"S4.T1.1.6.5.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Question BOW </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T1.1.6.5.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib11\" title=\"\" class=\"ltx_ref\">11</a><span id=\"S4.T1.1.6.5.1.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n</th>\n<td id=\"S4.T1.1.6.5.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.1.6.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">32.67</span></td>\n</tr>\n<tr id=\"S4.T1.1.7.6\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.7.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr\">\n<span id=\"S4.T1.1.7.6.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">IMG+BOW </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T1.1.7.6.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib11\" title=\"\" class=\"ltx_ref\">11</a><span id=\"S4.T1.1.7.6.1.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>\n</th>\n<td id=\"S4.T1.1.7.6.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.1.7.6.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">34.17</span></td>\n</tr>\n<tr id=\"S4.T1.1.8.7\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.8.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\"><span id=\"S4.T1.1.8.7.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">SMem-VQA One-Hop</span></th>\n<td id=\"S4.T1.1.8.7.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T1.1.8.7.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">36.03</span></td>\n</tr>\n<tr id=\"S4.T1.1.9.8\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.9.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_rr\"><span id=\"S4.T1.1.9.8.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">SMem-VQA Two-Hop</span></th>\n<td id=\"S4.T1.1.9.8.2\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T1.1.9.8.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">40.07</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "Results of our SMem-VQA model on the DAQUAR dataset and the baseline model results reported in previous work are shown in Tab. 1.\nFrom the DAQUAR result in Tab. 1, we see that models based on deep features significantly outperform the Multi-World approach based on hand-crafted features. Modeling the question only with either the LSTM model or Question BOW model does equally well in comparison, indicating the the question text contains important prior information for predicting the answer. Also, on this dataset, the VIS+LSTM model achieves better accuracy than Neural-Image-QA model; the former shows the image only at the first timestep of the LSTM, while the latter does so at each timestep. In comparison, both our One-Hop model and Two-Hop spatial attention models outperform the IMG+BOW, as well as the other baseline models.\nA major advantage of our model is the ability to visualize the inference process in the deep network. To illustrate this, two attention weights visualization examples in SMem-VQA One-Hop and Two-Hop models on DAQUAR dataset are shown in Fig. 5 (bottom row)."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: Test-dev and test-standard results on the Open-Ended VQA dataset (in percentage). Models with ∗ use external training data in addition to the VQA dataset.",
        "table": "<table id=\"S4.T2.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.4.3.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.4.3.1.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_rr ltx_border_t\"></th>\n<td id=\"S4.T2.4.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\" colspan=\"4\"><span id=\"S4.T2.4.3.1.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">test-dev</span></td>\n<td id=\"S4.T2.4.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"4\"><span id=\"S4.T2.4.3.1.3.1\" class=\"ltx_text\" style=\"font-size:70%;\">test-standard</span></td>\n</tr>\n<tr id=\"S4.T2.4.4.2\" class=\"ltx_tr\">\n<th id=\"S4.T2.4.4.2.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_rr\"></th>\n<td id=\"S4.T2.4.4.2.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.4.4.2.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Overall</span></td>\n<td id=\"S4.T2.4.4.2.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.4.4.2.3.1\" class=\"ltx_text\" style=\"font-size:70%;\">yes/no</span></td>\n<td id=\"S4.T2.4.4.2.4\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.4.4.2.4.1\" class=\"ltx_text\" style=\"font-size:70%;\">number</span></td>\n<td id=\"S4.T2.4.4.2.5\" class=\"ltx_td ltx_align_center ltx_border_rr\"><span id=\"S4.T2.4.4.2.5.1\" class=\"ltx_text\" style=\"font-size:70%;\">others</span></td>\n<td id=\"S4.T2.4.4.2.6\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.4.4.2.6.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Overall</span></td>\n<td id=\"S4.T2.4.4.2.7\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.4.4.2.7.1\" class=\"ltx_text\" style=\"font-size:70%;\">yes/no</span></td>\n<td id=\"S4.T2.4.4.2.8\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.4.4.2.8.1\" class=\"ltx_text\" style=\"font-size:70%;\">number</span></td>\n<td id=\"S4.T2.4.4.2.9\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.4.4.2.9.1\" class=\"ltx_text\" style=\"font-size:70%;\">others</span></td>\n</tr>\n<tr id=\"S4.T2.4.5.3\" class=\"ltx_tr\">\n<th id=\"S4.T2.4.5.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\">\n<span id=\"S4.T2.4.5.3.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">LSTM Q+I </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T2.4.5.3.1.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">[</span><a href=\"#bib.bib2\" title=\"\" class=\"ltx_ref\">2</a><span id=\"S4.T2.4.5.3.1.3.2\" class=\"ltx_text\" style=\"font-size:70%;\">]</span></cite>\n</th>\n<td id=\"S4.T2.4.5.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.4.5.3.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">53.74</span></td>\n<td id=\"S4.T2.4.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.4.5.3.3.1\" class=\"ltx_text\" style=\"font-size:70%;\">78.94</span></td>\n<td id=\"S4.T2.4.5.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.4.5.3.4.1\" class=\"ltx_text\" style=\"font-size:70%;\">35.24</span></td>\n<td id=\"S4.T2.4.5.3.5\" class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\"><span id=\"S4.T2.4.5.3.5.1\" class=\"ltx_text\" style=\"font-size:70%;\">36.42</span></td>\n<td id=\"S4.T2.4.5.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.4.5.3.6.1\" class=\"ltx_text\" style=\"font-size:70%;\">54.06</span></td>\n<td id=\"S4.T2.4.5.3.7\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.4.5.3.7.1\" class=\"ltx_text\" style=\"font-size:70%;\">-</span></td>\n<td id=\"S4.T2.4.5.3.8\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.4.5.3.8.1\" class=\"ltx_text\" style=\"font-size:70%;\">-</span></td>\n<td id=\"S4.T2.4.5.3.9\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.4.5.3.9.1\" class=\"ltx_text\" style=\"font-size:70%;\">-</span></td>\n</tr>\n<tr id=\"S4.T2.3.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr\">\n<span id=\"S4.T2.3.1.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">ACK</span><sup id=\"S4.T2.3.1.1.2\" class=\"ltx_sup\"><span id=\"S4.T2.3.1.1.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">∗</span></sup><span id=\"S4.T2.3.1.1.3\" class=\"ltx_text\" style=\"font-size:70%;\"> </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T2.3.1.1.4.1\" class=\"ltx_text\" style=\"font-size:70%;\">[</span><a href=\"#bib.bib26\" title=\"\" class=\"ltx_ref\">26</a><span id=\"S4.T2.3.1.1.5.2\" class=\"ltx_text\" style=\"font-size:70%;\">]</span></cite>\n</th>\n<td id=\"S4.T2.3.1.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.3.1.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">55.72</span></td>\n<td id=\"S4.T2.3.1.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.3.1.3.1\" class=\"ltx_text\" style=\"font-size:70%;\">79.23</span></td>\n<td id=\"S4.T2.3.1.4\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.3.1.4.1\" class=\"ltx_text\" style=\"font-size:70%;\">36.13</span></td>\n<td id=\"S4.T2.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_rr\"><span id=\"S4.T2.3.1.5.1\" class=\"ltx_text\" style=\"font-size:70%;\">40.08</span></td>\n<td id=\"S4.T2.3.1.6\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.3.1.6.1\" class=\"ltx_text\" style=\"font-size:70%;\">55.98</span></td>\n<td id=\"S4.T2.3.1.7\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.3.1.7.1\" class=\"ltx_text\" style=\"font-size:70%;\">79.05</span></td>\n<td id=\"S4.T2.3.1.8\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.3.1.8.1\" class=\"ltx_text\" style=\"font-size:70%;\">36.10</span></td>\n<td id=\"S4.T2.3.1.9\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.3.1.9.1\" class=\"ltx_text\" style=\"font-size:70%;\">40.61</span></td>\n</tr>\n<tr id=\"S4.T2.4.2\" class=\"ltx_tr\">\n<th id=\"S4.T2.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr\">\n<span id=\"S4.T2.4.2.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">DPPnet</span><sup id=\"S4.T2.4.2.1.2\" class=\"ltx_sup\"><span id=\"S4.T2.4.2.1.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">∗</span></sup><span id=\"S4.T2.4.2.1.3\" class=\"ltx_text\" style=\"font-size:70%;\"> </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T2.4.2.1.4.1\" class=\"ltx_text\" style=\"font-size:70%;\">[</span><a href=\"#bib.bib27\" title=\"\" class=\"ltx_ref\">27</a><span id=\"S4.T2.4.2.1.5.2\" class=\"ltx_text\" style=\"font-size:70%;\">]</span></cite>\n</th>\n<td id=\"S4.T2.4.2.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.4.2.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">57.22</span></td>\n<td id=\"S4.T2.4.2.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.4.2.3.1\" class=\"ltx_text\" style=\"font-size:70%;\">80.71</span></td>\n<td id=\"S4.T2.4.2.4\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.4.2.4.1\" class=\"ltx_text\" style=\"font-size:70%;\">37.24</span></td>\n<td id=\"S4.T2.4.2.5\" class=\"ltx_td ltx_align_center ltx_border_rr\"><span id=\"S4.T2.4.2.5.1\" class=\"ltx_text\" style=\"font-size:70%;\">41.69</span></td>\n<td id=\"S4.T2.4.2.6\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.4.2.6.1\" class=\"ltx_text\" style=\"font-size:70%;\">57.36</span></td>\n<td id=\"S4.T2.4.2.7\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.4.2.7.1\" class=\"ltx_text\" style=\"font-size:70%;\">80.28</span></td>\n<td id=\"S4.T2.4.2.8\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.4.2.8.1\" class=\"ltx_text\" style=\"font-size:70%;\">36.92</span></td>\n<td id=\"S4.T2.4.2.9\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.4.2.9.1\" class=\"ltx_text\" style=\"font-size:70%;\">42.24</span></td>\n</tr>\n<tr id=\"S4.T2.4.6.4\" class=\"ltx_tr\">\n<th id=\"S4.T2.4.6.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr\">\n<span id=\"S4.T2.4.6.4.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">iBOWIMG </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T2.4.6.4.1.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">[</span><a href=\"#bib.bib3\" title=\"\" class=\"ltx_ref\">3</a><span id=\"S4.T2.4.6.4.1.3.2\" class=\"ltx_text\" style=\"font-size:70%;\">]</span></cite>\n</th>\n<td id=\"S4.T2.4.6.4.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.4.6.4.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">55.72</span></td>\n<td id=\"S4.T2.4.6.4.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.4.6.4.3.1\" class=\"ltx_text\" style=\"font-size:70%;\">76.55</span></td>\n<td id=\"S4.T2.4.6.4.4\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.4.6.4.4.1\" class=\"ltx_text\" style=\"font-size:70%;\">35.03</span></td>\n<td id=\"S4.T2.4.6.4.5\" class=\"ltx_td ltx_align_center ltx_border_rr\"><span id=\"S4.T2.4.6.4.5.1\" class=\"ltx_text\" style=\"font-size:70%;\">42.62</span></td>\n<td id=\"S4.T2.4.6.4.6\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.4.6.4.6.1\" class=\"ltx_text\" style=\"font-size:70%;\">55.89</span></td>\n<td id=\"S4.T2.4.6.4.7\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.4.6.4.7.1\" class=\"ltx_text\" style=\"font-size:70%;\">76.76</span></td>\n<td id=\"S4.T2.4.6.4.8\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.4.6.4.8.1\" class=\"ltx_text\" style=\"font-size:70%;\">34.98</span></td>\n<td id=\"S4.T2.4.6.4.9\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.4.6.4.9.1\" class=\"ltx_text\" style=\"font-size:70%;\">42.62</span></td>\n</tr>\n<tr id=\"S4.T2.4.7.5\" class=\"ltx_tr\">\n<th id=\"S4.T2.4.7.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\"><span id=\"S4.T2.4.7.5.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">SMem-VQA One-Hop</span></th>\n<td id=\"S4.T2.4.7.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.4.7.5.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">56.56</span></td>\n<td id=\"S4.T2.4.7.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.4.7.5.3.1\" class=\"ltx_text\" style=\"font-size:70%;\">78.98</span></td>\n<td id=\"S4.T2.4.7.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.4.7.5.4.1\" class=\"ltx_text\" style=\"font-size:70%;\">35.93</span></td>\n<td id=\"S4.T2.4.7.5.5\" class=\"ltx_td ltx_align_center ltx_border_rr ltx_border_t\"><span id=\"S4.T2.4.7.5.5.1\" class=\"ltx_text\" style=\"font-size:70%;\">42.09</span></td>\n<td id=\"S4.T2.4.7.5.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.4.7.5.6.1\" class=\"ltx_text\" style=\"font-size:70%;\">-</span></td>\n<td id=\"S4.T2.4.7.5.7\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.4.7.5.7.1\" class=\"ltx_text\" style=\"font-size:70%;\">-</span></td>\n<td id=\"S4.T2.4.7.5.8\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.4.7.5.8.1\" class=\"ltx_text\" style=\"font-size:70%;\">-</span></td>\n<td id=\"S4.T2.4.7.5.9\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.4.7.5.9.1\" class=\"ltx_text\" style=\"font-size:70%;\">-</span></td>\n</tr>\n<tr id=\"S4.T2.4.8.6\" class=\"ltx_tr\">\n<th id=\"S4.T2.4.8.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_rr\"><span id=\"S4.T2.4.8.6.1.1\" class=\"ltx_text\" style=\"font-size:70%;\">SMem-VQA Two-Hop</span></th>\n<td id=\"S4.T2.4.8.6.2\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T2.4.8.6.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">57.99</span></td>\n<td id=\"S4.T2.4.8.6.3\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T2.4.8.6.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">80.87</span></td>\n<td id=\"S4.T2.4.8.6.4\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T2.4.8.6.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">37.32</span></td>\n<td id=\"S4.T2.4.8.6.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_rr\"><span id=\"S4.T2.4.8.6.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">43.12</span></td>\n<td id=\"S4.T2.4.8.6.6\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T2.4.8.6.6.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">58.24</span></td>\n<td id=\"S4.T2.4.8.6.7\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T2.4.8.6.7.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">80.8</span></td>\n<td id=\"S4.T2.4.8.6.8\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T2.4.8.6.8.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">37.53</span></td>\n<td id=\"S4.T2.4.8.6.9\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T2.4.8.6.9.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">43.48</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "The overall accuracy and per-answer category accuracy for our SMem-VQA models and the four baseline models on VQA dataset are shown in Tab. 2. From the table, we can see that the SMem-VQA One-Hop model obtains slightly better results compared to the iBOWIMG model. However, the SMem-VQA Two-Hop model achieves an improvement of 2.27% on test-dev and 2.35% on test-standard compared to the iBOWIMG model, demonstrating the value of spatial attention. The SMem-VQA Two-Hop model also shows best performance in the per-answer category accuracy.\nThe SMem-VQA Two-Hop model has slightly better result than the DPPnet model.\nThe DPPnet model uses a large-scale text corpus to pre-train the Gated Recurrent Unit (GRU) network for question representation.\nSimilar pre-training work on extra data to improve model accuracy has been done in [32].\nConsidering the fact that our model does not use extra data to pre-train the word embeddings, its results are very competitive.\nWe also experiment with adding a third hop into our model on the VQA dataset, but the result does not improve further."
        ]
    }
}