{
    "id_table_1": {
        "caption": "TABLE I:  Performance comparison of AAC models for in-domain scenarios.",
        "table": "S2.T1.2.2",
        "footnotes": [],
        "references": [
            "We leverage the joint multi-modal space of CLAP to perform text-only training and then infer on audio clips in a zero-shot manner.  As illustrated in Figure  1  (left), CLAP jointly trains an audio encoder  f a  (  ) subscript f a  f_{a}(\\cdot) italic_f start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT (  )  and a text encoder  f t  (  ) subscript f t  f_{t}(\\cdot) italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT (  )  to align semantically similar audio-text pairs in a shared embedding space. After training,  f a  ( a )  f t  ( t ) subscript f a a subscript f t t f_{a}(a)\\approx f_{t}(t) italic_f start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( italic_a )  italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_t )  holds for any audio-text pair  ( a , t ) a t (a,t) ( italic_a , italic_t ) ."
        ]
    },
    "id_table_2": {
        "caption": "TABLE II:  Performance comparison of AAC models for cross-domain scenarios.",
        "table": "S3.T2.4.4",
        "footnotes": [],
        "references": []
    },
    "id_table_3": {
        "caption": "TABLE III:  Ablation Study of DRCap for in-domain scenarios",
        "table": "S4.T3.2.2",
        "footnotes": [],
        "references": []
    },
    "id_table_4": {
        "caption": "TABLE IV:  Ablation Study of DRCap for cross-domain scenarios",
        "table": "S4.T4.4.4",
        "footnotes": [],
        "references": []
    },
    "global_footnotes": []
}