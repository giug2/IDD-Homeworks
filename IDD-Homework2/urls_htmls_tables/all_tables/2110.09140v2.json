{
    "S5.T1": {
        "caption": "Table 1: Test performance of different methods, where left table denotes the likelihood for MoG with varying Cğ¶C (number of components), oracle is the likelihood of true parameters for the test data, and right denotes the test accuracy for point cloud classification task with varying Nğ‘N (number of points).",
        "table": null,
        "footnotes": [],
        "references": [
            "Amortized Clustering with Mixture of Gaussians (MoGs): \nWe consider the task of maximum likelihood of MoGs with Cğ¶C components, denoted as Pâ€‹(x;ğœ½)=âˆ‘c=1CÏ€câ€‹Nâ€‹(xâˆ£Î¼c,diagâ¡(Ïƒc2))ğ‘ƒğ‘¥ğœ½superscriptsubscriptğ‘1ğ¶subscriptğœ‹ğ‘ğ‘conditionalğ‘¥subscriptğœ‡ğ‘diagsuperscriptsubscriptğœğ‘2P(x;\\bm{\\theta})\\!=\\!\\sum_{c=1}^{C}\\pi_{c}N\\left(x\\mid\\mu_{c},\\operatorname{diag}\\left(\\sigma_{c}^{2}\\right)\\right). Given the dataset X={x1:n}ğ‘‹subscriptğ‘¥:1ğ‘›X\\!=\\!\\{x_{1:n}\\} generated from the MoG, the goal is to train a neural network, which takes Xğ‘‹X as input set and outputs parameters ğœ½={Ï€c,Î¼c,Ïƒc}1,Cğœ½subscriptsubscriptğœ‹ğ‘subscriptğœ‡ğ‘subscriptğœğ‘1ğ¶\\bm{\\theta}=\\{\\pi_{c},\\mu_{c},\\sigma_{c}\\}_{1,C}. Each dataset contains nâˆˆ[100,500]ğ‘›100500n\\in[100,500] points on a 2D plane, each of which is sampled from one of Cğ¶C Gaussians. Table 1 reports the test average likelihood of different models with varying Câˆˆ{4,8}ğ¶48C\\!\\in\\!\\{4,8\\}, where we set K=50ğ¾50K\\!=\\!50 prototypes for all Cğ¶C. We observe that Set Transformer outperforms DeepSets largely, validating the effectiveness of attention mechanisms in this task. We note both Set Transformer(+POT) and DeepSets(+POT) improve their baselines, showing that the POT loss can encourage the summary networks to learn more efficient summary statistics.",
            "Point Cloud Classification: \nHere, we evaluate our method on the task of point cloud classification using the ModelNet40 (Chang et al., 2015) dataset 111We adopt the point-cloud dataset directly from the authors of Zaheer etÂ al. 2017, which consists of 3D objects from 404040 different categories. By treating each object as a point cloud, we represent it as a set of Nğ‘N vectors in â„3superscriptâ„3\\mathbb{R}^{3} (x; y; z-coordinates). Table 1 reports the classification accuracy, where we perform the experiments with varying Nâˆˆ{64,1024}ğ‘641024N\\in\\{64,1024\\}, set K=40ğ¾40K\\!=\\!40 prototypes. Clearly, both DeepSets and Set Transformer can be improved by adding the POT loss. Notably, fewer points would lead to lower performance, where the POT loss plays a more important role. Taking this task as the example, we further study our modelâ€™s sensitivity to hyper-parameter Ïµitalic-Ïµ\\epsilon in Fig. 4 of Appendix C.5."
        ]
    },
    "S5.T2": {
        "caption": "Table 2: 5way5shot and 5way10shot classification accuracy (%) on CUB and miniImageNet, respectively, based on 1000 random trials. Here, (â‹…â‹…\\cdot) is the pğ‘p-value computed with two-sample tğ‘¡t-test, and pğ‘p-value with blue (red) color means the increase (reduce) of performance when introducing POT loss.",
        "table": null,
        "footnotes": [],
        "references": [
            "To explore whether our proposed method can improve the metric-based few-shot classification, we consider two commonly-used algorithms as the baselines, including ProtoNet (Snell etÂ al., 2017) and MatchNet (Vinyals etÂ al., 2016). Denoting the feature extractor in each algorithm as fÏ•1subscriptğ‘“subscriptitalic-Ï•1f_{\\phi_{1}}, we consider several popular backbones, including ResNet10 and ResNet34 (He etÂ al., 2016). Recalling the discussions in Section 3.2, to enforce fÏ•1subscriptğ‘“subscriptitalic-Ï•1f_{\\phi_{1}} to learn more powerful image features, we additionally introduce matrix ğğ{\\bf B} and net gÏ•2subscriptğ‘”subscriptitalic-Ï•2g_{\\phi_{2}} and learn the model by minimizing the POT loss and classification errors. We perform the experiments on the CUB (Welinder etÂ al., 2010) and miniImageNet (Ravi & Larochelle, 2016). As a fine-grained few-shot classification benchmark, CUB contains 200200200 different classes of birds with a total of 11,7881178811,788 images of size 84Ã—84Ã—38484384\\times 84\\times 3, where we split the dataset into 100100100 base classes, 50 validation classes, and 505050 novel classes following Chen etÂ al. (2019). miniImageNet is derived from ILSVRC-12 dataset (Russakovsky etÂ al., 2015), consisting of\n84Ã—84Ã—38484384\\times 84\\times 3 images from 100 classes with 600 random samples in each class. We follow the splits used in previous work (Ravi & Larochelle, 2016), which splits the dataset into 646464 base classes, 161616 validation classes, and 202020 novel classes. Table 2 reports the 5way5shot and 5way10shot classification results of different methods on miniImageNet and CUB. We see that introducing the POT loss and summary network\ncan consistently improve over baseline classifiers, and the performance gain gradually increases with the development of number of network layers. This suggests that our proposed plug-and-play framework can be flexibly used to enhance the metric-based few-shot classification, without the requirement of designing complicated models on purpose."
        ]
    },
    "S5.T3": {
        "caption": "Table 3: FID â†“â†“\\downarrow of images generated by different methods with varying unseen angles Ağ´A on MNIST.",
        "table": null,
        "footnotes": [],
        "references": [
            "Rotated MNIST: Following Wu etÂ al. (2020), we artificially transform each image in MNIST dataset (LeCun, 1998) with 18 rotations (âˆ’-180 to 180 by 20 degrees), leading to 181818 distributions characterized by angle Ağ´A. We choose 999 interleaved distributions for training and the rest as unseen distributions for testing. We consider the CGAN-based and DAGAN-based models, respectively. During the test stage, for each unseen distribution, we randomly sample 100010001000 real images and generate 202020 fake images based on every 202020 real images and repeat this process 505050 times (i.e.formulae-sequenceğ‘–ğ‘’i.e., 1000/201000201000/20), resulting in 100010001000 generated samples for each method. We summarize the test performance in TableÂ 3 with varying Ağ´A. We can find that our proposed framework allows for better generalization to related but unseen distributions at test time, indicating the POT loss can enforce the summary network to capture more salient characteristics."
        ]
    },
    "A3.T4": {
        "caption": "Table 4: Detailed architectures of Set Transformer used in the MoGs experiments, cited from Lee etÂ al. (2019), where Cğ¶C denotes the number of components.",
        "table": null,
        "footnotes": [],
        "references": [
            "DeepSets In terms of the DeepSets, the fÏ•1subscriptğ‘“subscriptitalic-Ï•1f_{\\phi_{1}} in summary network contains 3 permutation-equivariant layers with 256 channels followed by mean-pooling over the set structure. Then the resulting vector representation ğ’›jsubscriptğ’›ğ‘—\\bm{z}_{j} of the set is then fed to a fully connected layer with 512 units followed by a linear layer 512Ã—Câ€‹(1+2âˆ—2)512ğ¶122512\\times C(1+2*2), where Cğ¶C denotes the number of components. We use ELU activation at all layers. To introduce the POT loss into the DeepSets, we further feed the ğ’›jsubscriptğ’›ğ‘—\\bm{z}_{j} into a fully connected layer with 512 units followed by a 50-way softmax unit and also introduce the global matrix ğâˆˆâ„2Ã—50ğsuperscriptâ„250{\\bf B}\\in\\mathbb{R}^{2\\times 50}.\n\nSet Transformer To perform the MoGs experiments, we adopt the same architecture for Set Transformer following Lee etÂ al. (2019), whose parameters are reported in Table 4. To introduce the POT loss, we also add the two fully connected layers with 256 units on the resulting vector ğ’›jsubscriptğ’›ğ‘—\\bm{z}_{j} followed by a 50-way softmax unit, and a global prototype matrix ğâˆˆâ„2Ã—50ğsuperscriptâ„250{\\bf B}\\in\\mathbb{R}^{2\\times 50}."
        ]
    },
    "A3.T5": {
        "caption": "Table 5: Detailed architectures of Set Transformer used in the point cloud classification experiments, cited from Lee etÂ al. (2019).",
        "table": null,
        "footnotes": [],
        "references": [
            "Set Transformer We also adopt the same architecture to implement the Set Transformer, where we summarize the parameters in Table 5, following Lee etÂ al. (2019). To improve the Set Transformer with POT loss, we also introduce a fully connected layer with 256 units followed by a 40-way softmax unit, with 90%percent9090\\% dropout rate, and a center matrix ğâˆˆâ„3Ã—40ğsuperscriptâ„340{\\bf B}\\in\\mathbb{R}^{3\\times 40}."
        ]
    }
}