{
    "id_table_1": {
        "caption": "Table 1 :  Classification accuracy on the target domain of  office-31  dataset for domain adaptation.",
        "table": "A8.EGx1",
        "footnotes": [],
        "references": [
            "where  x ( q )  R d ( q ) superscript x q superscript R superscript d q \\boldsymbol{x}^{(q)}\\in\\mathbb{R}^{d^{(q)}} bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  roman_R start_POSTSUPERSCRIPT italic_d start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT  represents the data from the  q q q italic_q th modality,  z ( q )  R d C + d P ( q ) superscript z q superscript R subscript d C superscript subscript d P q \\boldsymbol{z}^{(q)}\\in\\mathbb{R}^{d_{\\rm C}+d_{\\rm P}^{(q)}} bold_italic_z start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  roman_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT + italic_d start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT  represents the corresponding latent code,  c  R d C c superscript R subscript d C \\bm{c}\\in\\mathbb{R}^{d_{\\rm C}} bold_italic_c  roman_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT end_POSTSUPERSCRIPT  and  p ( q )  R d P ( q ) superscript p q superscript R subscript superscript d q P \\bm{p}^{(q)}\\in\\mathbb{R}^{d^{(q)}_{\\rm P}} bold_italic_p start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  roman_R start_POSTSUPERSCRIPT italic_d start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT end_POSTSUPERSCRIPT  stand for the shared components and the private components, respectively. The data  x ( q ) superscript x q \\boldsymbol{x}^{(q)} bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT s are assumed to be zero-mean, which can be enforced by centering. Note that the positions of  c c \\bm{c} bold_italic_c  and  p q subscript p q \\bm{p}_{q} bold_italic_p start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT  are not necessarily arranged as  [ c  , ( p ( q ) )  ]  superscript superscript c top superscript superscript p q top top [\\bm{c}^{\\top},(\\bm{p}^{(q)})^{\\top}]^{\\top} [ bold_italic_c start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , ( bold_italic_p start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ] start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  (more generally,  z ( q ) =  ( q )  [ c  , ( p ( q ) )  ]  superscript z q superscript  q superscript superscript c top superscript superscript p q top top \\bm{z}^{(q)}=\\bm{\\Pi}^{(q)}[\\bm{c}^{\\top},(\\bm{p}^{(q)})^{\\top}]^{\\top} bold_italic_z start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_ start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT [ bold_italic_c start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , ( bold_italic_p start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ] start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  with an unknown permutation matrix   ( q ) superscript  q \\bm{\\Pi}^{(q)} bold_ start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT ). However, the representation in ( 1 ) is without loss of generality as one can define  A ( q ) := A ( q )  (  ( q ) )  assign superscript A q superscript A q superscript superscript  q top \\bm{A}^{(q)}:={\\boldsymbol{A}}^{(q)}(\\bm{\\Pi}^{(q)})^{{\\!\\top\\!}} bold_italic_A start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT := bold_italic_A start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT ( bold_ start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  to reach the representation in ( 1 ). For all the domains, we have",
            "where  P c subscript P c \\mathbb{P}_{\\bm{c}} roman_P start_POSTSUBSCRIPT bold_italic_c end_POSTSUBSCRIPT  and  P p ( q ) subscript P superscript p q \\mathbb{P}_{\\bm{p}^{(q)}} roman_P start_POSTSUBSCRIPT bold_italic_p start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT end_POSTSUBSCRIPT  represent the distributions of the shared components and the domain-private components, respectively. Under ( 1 ), the two different range spaces  range  ( A ( q ) ) range superscript A q {\\rm range}(\\boldsymbol{A}^{(q)}) roman_range ( bold_italic_A start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT )  for  q = 1 , 2 q 1 2 q=1,2 italic_q = 1 , 2  represent two feature spaces. Then latent  p ( q ) superscript p q \\bm{p}^{(q)} bold_italic_p start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  further distinguishes the modalities and often has interesting physical interpretation. For example, some vision literature use  c c \\bm{c} bold_italic_c  to model content and  p ( q ) superscript p q \\bm{p}^{(q)} bold_italic_p start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  style of the images  [ 35 ,  31 ] . In cross-lingual word embedding retrieval  [ 2 ] ,  c c \\bm{c} bold_italic_c  represents the semantic meaning of the words, while  p ( q ) superscript p q \\bm{p}^{(q)} bold_italic_p start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  represents the language-specific components. The goal of SCA boils down to finding linear operators to recover  c c \\bm{c} bold_italic_c  to a reasonable extent.",
            "Aligned SCA: Identifiability of CCA and Extensions.  Learning  c c \\bm{c} bold_italic_c  without knowing  A ( q ) superscript A q \\boldsymbol{A}^{(q)} bold_italic_A start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  is a typical component analysis problem. Learning latent components from linear mixtures lacks identifiability in general, due to the bilinear nature of linear mixture models (LMMs) like  x = A  z x A z \\boldsymbol{x}=\\boldsymbol{A}\\boldsymbol{z} bold_italic_x = bold_italic_A bold_italic_z ; see Sec.  5  for various component analysis frameworks dealing with the single-modality LMM. The works  [ 1 ,  2 ]  studied the identifiability of  c c \\boldsymbol{c} bold_italic_c  under the model ( 1 ), using the assumption that the cross-modality samples share the same  c c \\bm{c} bold_italic_c  are aligned. In particular,  [ 1 ]  formulated the  c c \\bm{c} bold_italic_c -identification problem as a CCA problem:",
            "under mild conditions (see Appendix  E.1  for details), where  ( Q ^ ( 1 ) , Q ^ ( 2 ) ) superscript ^ Q 1 superscript ^ Q 2 (\\widehat{\\boldsymbol{Q}}^{(1)},\\widehat{\\boldsymbol{Q}}^{(2)}) ( over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT )  is an optimal solution of the CCA formulation and    \\bm{\\Theta} bold_  is a certain non-singular matrix. Eq. ( 4 ) means that  Q ^ ( q ) superscript ^ Q q \\widehat{\\boldsymbol{Q}}^{(q)} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  finds the range space where  c c \\bm{c} bold_italic_c  lives in, i.e.,  range  ( A 1 : d C ( q ) ) range subscript superscript A q : 1 subscript d C {\\rm range}(\\boldsymbol{A}^{(q)}_{1:d_{\\rm C}}) roman_range ( bold_italic_A start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 : italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT end_POSTSUBSCRIPT )  under our notation.",
            "Unaligned SCA: Existing Result and Theoretical Gap.  The work in  [ 8 ]  studied the identifiability of  c c \\bm{c} bold_italic_c  under ( 1 ) when  x ( 1 ) superscript x 1 \\boldsymbol{x}^{(1)} bold_italic_x start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT  and  x ( 2 ) superscript x 2 \\boldsymbol{x}^{(2)} bold_italic_x start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT  are  unaligned . Their approach works under the condition  that the elements of  z ( q ) = [ c  , ( p ( q ) )  ]  superscript z q superscript superscript c top superscript superscript p q top top \\bm{z}^{(q)}=[\\bm{c}^{\\top},(\\bm{p}^{(q)})^{\\top}]^{\\top} bold_italic_z start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = [ bold_italic_c start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , ( bold_italic_p start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ] start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  are mutually statistically independent . There,  z ^ ( q ) =  ( q )   ( q )  z ( q ) superscript ^ z q superscript  q superscript  q superscript z q \\widehat{\\bm{z}}^{(q)}=\\bm{\\Pi}^{(q)}\\bm{\\Sigma}^{(q)}\\bm{z}^{(q)} over^ start_ARG bold_italic_z end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_ start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_ start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_italic_z start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  is assumed to have been estimated by ICA, where   ( q ) superscript  q \\bm{\\Pi}^{(q)} bold_ start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  and   ( q ) superscript  q \\bm{\\Sigma}^{(q)} bold_ start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  represent the scaling and permutation ambiguities, respectively, which cannot be removed by ICA. The work  [ 8 ]  assumed   ( q ) = I superscript  q I \\bm{\\Sigma}^{(q)}=\\bm{I} bold_ start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_italic_I  by imposing a unit-variance assumption on all the  z i ( q ) superscript subscript z i q z_{i}^{(q)} italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT s. Then, a cross-domain matching algorithm is used to match the shared elements in  z ^ ( 1 ) superscript ^ z 1 \\widehat{\\bm{z}}^{(1)} over^ start_ARG bold_italic_z end_ARG start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT  and  z ^ ( 2 ) superscript ^ z 2 \\widehat{\\bm{z}}^{(2)} over^ start_ARG bold_italic_z end_ARG start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT . The formulation can be summarized as finding  d C subscript d C d_{\\rm C} italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT  pairs of non-repetitive  ( i , j ) i j (i,j) ( italic_i , italic_j )  such that  e i   z ^ ( 1 ) superscript subscript e i top superscript ^ z 1 \\bm{e}_{i}^{\\!\\top\\!}\\widehat{\\bm{z}}^{(1)} bold_italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT over^ start_ARG bold_italic_z end_ARG start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT  and  e j   z ^ ( 2 ) superscript subscript e j top superscript ^ z 2 \\bm{e}_{j}^{\\!\\top\\!}\\widehat{\\bm{z}}^{(2)} bold_italic_e start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT over^ start_ARG bold_italic_z end_ARG start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT  have identical distributions, where  e i subscript e i \\bm{e}_{i} bold_italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  is the  i i i italic_i th unit vector. Denote  c ^ m ( 1 ) = e i m   z ^ ( 1 ) subscript superscript ^ c 1 m subscript superscript e top subscript i m superscript ^ z 1 \\widehat{c}^{(1)}_{m}=\\bm{e}^{\\!\\top\\!}_{i_{m}}\\widehat{\\bm{z}}^{(1)} over^ start_ARG italic_c end_ARG start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT = bold_italic_e start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT end_POSTSUBSCRIPT over^ start_ARG bold_italic_z end_ARG start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT  and  c ^ m ( 2 ) = e j m   z ^ ( 2 ) subscript superscript ^ c 2 m subscript superscript e top subscript j m superscript ^ z 2 \\widehat{c}^{(2)}_{m}=\\bm{e}^{\\!\\top\\!}_{j_{m}}\\widehat{\\bm{z}}^{(2)} over^ start_ARG italic_c end_ARG start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT = bold_italic_e start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT end_POSTSUBSCRIPT over^ start_ARG bold_italic_z end_ARG start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT  for  m  [ d C ] m delimited-[] subscript d C m\\in[d_{\\rm C}] italic_m  [ italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT ] . It can be shown that",
            "The condition in Assumption  1  is a geometric way to characterize the difference between  P c , p ( 1 ) subscript P c superscript p 1 \\mathbb{P}_{\\boldsymbol{c},\\boldsymbol{p}^{(1)}} roman_P start_POSTSUBSCRIPT bold_italic_c , bold_italic_p start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT end_POSTSUBSCRIPT  and  P c , p ( 2 ) subscript P c superscript p 2 \\mathbb{P}_{\\boldsymbol{c},\\boldsymbol{p}^{(2)}} roman_P start_POSTSUBSCRIPT bold_italic_c , bold_italic_p start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT end_POSTSUBSCRIPT if the joint distributions have different measures for all possible stripes, each being a direct sum of a subspace and a convex hull (see Fig.  2 ), then  P c , p ( 1 ) subscript P c superscript p 1 \\mathbb{P}_{\\boldsymbol{c},\\boldsymbol{p}^{(1)}} roman_P start_POSTSUBSCRIPT bold_italic_c , bold_italic_p start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT end_POSTSUBSCRIPT  and  P c , p ( 2 \\mathbb{P}_{\\boldsymbol{c},\\boldsymbol{p}^{(2}} roman_P start_POSTSUBSCRIPT bold_italic_c , bold_italic_p start_POSTSUPERSCRIPT ( 2 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT  must be very different. Note that the difference is contributed by the modality-specific term  p ( q ) superscript p q \\boldsymbol{p}^{(q)} bold_italic_p start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT , and thus we call this condition modality variability. Modality variability is similar to the domain variablity used in  [ 32 ,  39 ] both characterize the discrepancy of the joint probabilities  P c , p ( 1 ) subscript P c superscript p 1 \\mathbb{P}_{\\boldsymbol{c},\\boldsymbol{p}^{(1)}} roman_P start_POSTSUBSCRIPT bold_italic_c , bold_italic_p start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT end_POSTSUBSCRIPT  and  P c , p ( 2 \\mathbb{P}_{\\boldsymbol{c},\\boldsymbol{p}^{(2}} roman_P start_POSTSUBSCRIPT bold_italic_c , bold_italic_p start_POSTSUPERSCRIPT ( 2 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT . However, there are key differences: The domain variability was defined in a unified latent domain over  arbitrary  sets  A A {\\cal A} caligraphic_A , which could be stringent. Instead, we use the fact that ( 6 ) relies on linear operations to construct  A ( q ) superscript A q \\mathcal{A}^{(q)} caligraphic_A start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT , which makes the condition defined over a much smaller class of setsthereby largely relaxing the requirements. Restricting  A ( q ) superscript A q \\mathcal{A}^{(q)} caligraphic_A start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  to be stripes also makes the modality variability condition much more relaxed compared to the domain variability condition.",
            "Under Assumption  1  and the generative model in ( 1 ), denote any solution of ( 6 ) as  Q ^ ( q ) superscript ^ Q q \\widehat{\\boldsymbol{Q}}^{(q)} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT   q = 1 , 2 q 1 2 q=1,2 italic_q = 1 , 2 . Then, if the mixing matrices  A ( q ) superscript A q \\boldsymbol{A}^{(q)} bold_italic_A start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  are full column ranks and  E [ c c  ] ) \\mathbb{E}[\\bm{c}\\bm{c}^{\\!\\top\\!}]) roman_E [ bold_italic_c bold_italic_c start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ] )  is full rank, we have  Q ^ ( q )  x ( q ) =  ( q )  c superscript ^ Q q superscript x q superscript  q c \\widehat{\\boldsymbol{Q}}^{(q)}\\boldsymbol{x}^{(q)}=\\bm{\\Theta}^{(q)}\\bm{c} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_ start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_italic_c . In addition, assume that either of the following is satisfied:",
            "In Theorem  1 , Assumption  1  is used to guarantee  Q ^ ( q )  x ( q ) =  ( q )  c superscript ^ Q q superscript x q superscript  q c \\widehat{\\boldsymbol{Q}}^{(q)}\\boldsymbol{x}^{(q)}=\\bm{\\Theta}^{(q)}\\bm{c} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_ start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_italic_c  and either of conditions (a) or (b) is used to make sure   ( 1 ) =  ( 2 ) superscript  1 superscript  2 \\bm{\\Theta}^{(1)}=\\bm{\\Theta}^{(2)} bold_ start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT = bold_ start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT . Note that both (a) and (b) are milder than those in  [ 8 ]  (cf. Theorem  5 ), where the element-wise statistical independence of  z ( q ) superscript z q \\boldsymbol{z}^{(q)} bold_italic_z start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  was relied on to find shared representation of  x ( 1 ) superscript x 1 \\boldsymbol{x}^{(1)} bold_italic_x start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT  and  x ( 2 ) superscript x 2 \\boldsymbol{x}^{(2)} bold_italic_x start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT . The proof is in Appendix  B .",
            "Numerical Validation.  In Fig.  3 , the top and bottom rows validate Theorem  1  under the assumptions in (a) and (b), respectively. In the top row, we set  c  R 2 c superscript R 2 \\bm{c}\\in\\mathbb{R}^{2} bold_italic_c  roman_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , where  c 1 subscript c 1 c_{1} italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  is sampled from Gaussian mixtures with three components and  c 2 subscript c 2 c_{2} italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  is sampled from a Gamma distribution (and  c 1   c 2 c_{1}\\perp\\!\\!\\!\\perp c_{2} italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT   italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ). We set  p ( 1 ) superscript p 1 p^{(1)} italic_p start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT  and  p ( 2 ) superscript p 2 p^{(2)} italic_p start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT  as one-dimensional Laplacian and uniform distributions. In the bottom row, the dimensions of  c c \\bm{c} bold_italic_c  and  p ( q ) superscript p q \\bm{p}^{(q)} bold_italic_p start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  for  q = 1 , 2 q 1 2 q=1,2 italic_q = 1 , 2  are unchanged, but their distributions are replaced in order to satisfy conditions in (b) (see details in Appendix  F ). One can see that clearly  c ^ ( q ) =   c superscript ^ c q  c \\widehat{\\bm{c}}^{(q)}=\\bm{\\Theta}\\bm{c} over^ start_ARG bold_italic_c end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_ bold_italic_c ; i.e., the learned  c ^ ( q ) superscript ^ c q \\widehat{\\bm{c}}^{(q)} over^ start_ARG bold_italic_c end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  for  q = 1 , 2 q 1 2 q=1,2 italic_q = 1 , 2  are identically rotated and scaled versions of  c c \\bm{c} bold_italic_c .",
            "Under the conditions in Theorem  1  (a), Assume that at most one  c i subscript c i c_{i} italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  for  i  [ d C ] i delimited-[] subscript d C i\\in[d_{\\rm C}] italic_i  [ italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT ]  is Gaussian. Then, the components of  c c \\bm{c} bold_italic_c  are identifiable up to permutation and scaling ambiguities by applying ICA to  c ^ ( q ) = Q ^ ( q )  x ( q ) superscript ^ c q superscript ^ Q q superscript x q \\widehat{\\bm{c}}^{(q)}=\\widehat{\\bm{Q}}^{(q)}\\boldsymbol{x}^{(q)} over^ start_ARG bold_italic_c end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  for either  q = 1 q 1 q=1 italic_q = 1  or  q = 2 q 2 q=2 italic_q = 2 .",
            "Theorem  1  was well-supported by the synthetic data experiments. However, our experiments found that the learning criterion ( 6 ) often struggles to produce sensible results in some applications. Our conjecture is that the Assumptions in Theorem  1  (a) and (b) might not have been satisfied by the real data under our tests. Although they are not necessary conditions for identifiability, these conditions do indicate that the requirements to guarantee identifiability of unaligned SCA using ( 6 ) are nontrivial to meet. In this section, we explore a couple of structural constraints arising from side information in applications to remove the need for the relatively stringent assumptions on  c c \\bm{c} bold_italic_c .",
            "Here, we consider the special case of generative process in ( 1 ) where,",
            "One can see that the conditions (a) and (b) in Theorem  1  are completely removed, if the structure  A ( 1 ) = A ( 2 ) superscript A 1 superscript A 2 \\boldsymbol{A}^{(1)}=\\boldsymbol{A}^{(2)} bold_italic_A start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT = bold_italic_A start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT  is imposed. In fact, the result in Theorem  2  is expected and readily seen from the proof of Theorem  1 , as the cause for   ( 1 ) =  ( 2 ) superscript  1 superscript  2 \\bm{\\Theta}^{(1)}\\neq\\bm{\\Theta}^{(2)} bold_ start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT = bold_ start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT  is the use of two different  Q ( q ) superscript Q q \\boldsymbol{Q}^{(q)} bold_italic_Q start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT s. Nonetheless, this simple variation will prove useful in a series of real-data experiments.",
            "In the next theorem, we show that the incorporation of aligned samples helps relax conditions (a) and (b) in Theorem  1 :",
            "Assume that Assumption  1  is satisfied, that  | L |  d C L subscript d C |{\\mathcal{L}}|\\geq d_{\\rm C} | caligraphic_L |  italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT  paired samples  ( x l ( 1 ) , x l ( 2 ) ) superscript subscript x l 1 superscript subscript x l 2 (\\boldsymbol{x}_{\\ell}^{(1)},\\boldsymbol{x}_{\\ell}^{(2)}) ( bold_italic_x start_POSTSUBSCRIPT roman_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , bold_italic_x start_POSTSUBSCRIPT roman_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT )  are available, that  A ( q ) superscript A q \\bm{A}^{(q)} bold_italic_A start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  for  q = 1 , 2 q 1 2 q=1,2 italic_q = 1 , 2  have full column rank, and that  P c subscript P c \\mathbb{P}_{\\bm{c}} roman_P start_POSTSUBSCRIPT bold_italic_c end_POSTSUBSCRIPT  is absolutely continuous. Denote  ( Q ^ ( 1 ) , Q ^ ( 2 ) ) superscript ^ Q 1 superscript ^ Q 2 (\\widehat{\\boldsymbol{Q}}^{(1)},\\widehat{\\boldsymbol{Q}}^{(2)}) ( over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT )  as any optimal solution of ( 6 ) under the constraint ( 6i ). Then, we have  Q ^ ( q )  x ( q ) =   c superscript ^ Q q superscript x q  c \\widehat{\\boldsymbol{Q}}^{(q)}\\boldsymbol{x}^{(q)}=\\bm{\\Theta}\\bm{c} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_ bold_italic_c .",
            "A remark is that our weakly supervised formulation can use as few as  d C subscript d C d_{\\rm C} italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT  pairs of  ( x l ( 1 ) , x l ( 2 ) ) superscript subscript x l 1 superscript subscript x l 2 (\\boldsymbol{x}_{\\ell}^{(1)},\\boldsymbol{x}_{\\ell}^{(2)}) ( bold_italic_x start_POSTSUBSCRIPT roman_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , bold_italic_x start_POSTSUBSCRIPT roman_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT )  to establish identifiability of shared component. In contrast, CCA requires at least  d C + d P ( 1 ) + d P ( 2 ) subscript d C superscript subscript d P 1 superscript subscript d P 2 d_{\\rm C}+d_{\\rm P}^{(1)}+d_{\\rm P}^{(2)} italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT + italic_d start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT + italic_d start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT  pairs to attain the same identifiability (cf. Appendix.  E.1 ).",
            "Identifiability of Unaligned SCA.  The works in  [ 39 ,  32 ]  investigated the shared component identifiability when the multimodal data are nonlinear mixtures of content and style (which are shared and private components, respectively) under the same mixing system. Hence, our identical linear mixing case in Theorem  2  can be understood as a special case of theirs. But their analysis relies on the assumption that all the latent components are statistically independent, which is much stronger than our conditions in Theorem  2 . Their results also require that there are a large amount of modalities available. But our proof works for just two modalities. The most related work is  [ 8 ] , which uses the model in ( 1 ) in the context of multi-view causal graph learning. As discussed before, their assumptions on the latent components are much stronger than ours (see Corollary  1  and Appendix  E.2 ).",
            "Result : Table  1  and Table  2  show the results on  Office-31  and  Office-Home , respectively. The results are averaged over 5 runs. One can observe that the proposed method and the CLIP model offers the best and the second best performance in most of the tasks. This shows that, as a foundation model, CLIP can already unify the embeddings of the source and target domains in a reasonable extent. In addition, Our model and algorithm are useful as a relatively simple post-processing of CLIPOur method always improves upon CLIP; in some tasks (e.g., W   \\rightarrow  A ,  Ar   \\rightarrow  CI ,  Pr   \\rightarrow  Ar  and  Pr   \\rightarrow  CI ), more than 4% accuracy gains can be obtained by using the proposed method.",
            "The plot in Fig.  4  shows the  k k k italic_k -NN accuracy of the methods on the test set. Results show the mean and standard deviation over 10 runs, each having a different random initialization. For the proposed method, we vary the number of available paired samples from  0 0  (cf. Theorem  1 ) to  d C = 256 subscript d C 256 d_{\\rm C}=256 italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT = 256  (cf. Theorem  3 ). Note that the baseline uses more (i.e.,  256 256 256 256  and  770 770 770 770 ) paired samples. It also needs additional class labels, i.e.,  y i ( q ) superscript subscript y i q y_{i}^{(q)} italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  for the  i i i italic_i th sample  x i ( q ) subscript superscript x q i \\boldsymbol{x}^{(q)}_{i} bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . Here,  y i ( q ) superscript subscript y i q y_{i}^{(q)} italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  represents the number of hours ( 0 0 ,  1 1 1 1  or  3 3 3 3 ) of cell treatment  [ 62 ,  27 ] . The proposed method without any supervision (i.e.,  0 0  paired samples) already exhibits around 3 times greater  k k k italic_k -NN accuracy compared to the baseline for all  k k k italic_k . Moreover, including just one paired sample boosts the  k k k italic_k -NN accuracy of the proposed method to around 5 times higher than the baseline for all  k k k italic_k . Finally, one can observe a steadily increasing  k k k italic_k -NN accuracy with respect to the number of available paired samples. This corroborates with our Theorem  3 .",
            "Application (iii) - Multi-lingual Information Retrieval.  We also evaluated our method on a word embedding association problem from the natural language processing literature  [ 21 ,  20 ] . In this task, the goal is to associate unaligned word embeddings across different languages. The details are in Appendix  G.1  due to page limitations.",
            "We restate the theorem here:  {mdframed} [backgroundcolor=gray!10,topline=false, rightline=false, leftline=false, bottomline=false]  Theorem   1  Under Assumption  1  and the generative model in ( 1 ), denote any solution of ( 6 ) as  Q ^ ( q ) superscript ^ Q q \\widehat{\\boldsymbol{Q}}^{(q)} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT   q = 1 , 2 q 1 2 q=1,2 italic_q = 1 , 2 . Then, if the mixing matrices  A ( q ) superscript A q \\boldsymbol{A}^{(q)} bold_italic_A start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  are full column ranks and  E [ c c  ] ) \\mathbb{E}[\\bm{c}\\bm{c}^{\\!\\top\\!}]) roman_E [ bold_italic_c bold_italic_c start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ] )  is full rank, we have  Q ^ ( q )  x ( q ) =  ( q )  c superscript ^ Q q superscript x q superscript  q c \\widehat{\\boldsymbol{Q}}^{(q)}\\boldsymbol{x}^{(q)}=\\bm{\\Theta}^{(q)}\\bm{c} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_ start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_italic_c . In addition, assume that either of the following is satisfied:",
            "because  Null  ( H ( q ) ) Null superscript H q {\\rm Null}(\\boldsymbol{H}^{(q)}) roman_Null ( bold_italic_H start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT )  is a subspace of dimension  d P ( q ) superscript subscript d P q d_{\\rm P}^{(q)} italic_d start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT , hence it satisfies the definition of  P ( q ) superscript P q \\mathcal{P}^{(q)} caligraphic_P start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT . Hence, Assumption  1  implies that",
            "We restate the theorem here:  {mdframed} [backgroundcolor=gray!10,topline=false, rightline=false, leftline=false, bottomline=false]  Theorem   3  Assume that Assumption  1  is satisfied, that  | L |  d C L subscript d C |{\\mathcal{L}}|\\geq d_{\\rm C} | caligraphic_L |  italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT  paired samples  ( x l ( 1 ) , x l ( 2 ) ) superscript subscript x l 1 superscript subscript x l 2 (\\boldsymbol{x}_{\\ell}^{(1)},\\boldsymbol{x}_{\\ell}^{(2)}) ( bold_italic_x start_POSTSUBSCRIPT roman_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , bold_italic_x start_POSTSUBSCRIPT roman_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT )  are available, that  A ( q ) , q = 1 , 2 formulae-sequence superscript A q q 1 2 \\bm{A}^{(q)},~{}q=1,2 bold_italic_A start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT , italic_q = 1 , 2  have full column rank, and that  P c subscript P c \\mathbb{P}_{\\bm{c}} roman_P start_POSTSUBSCRIPT bold_italic_c end_POSTSUBSCRIPT  is absolutely continuous. Denote  ( Q ^ ( 1 ) , Q ^ ( 2 ) ) superscript ^ Q 1 superscript ^ Q 2 (\\widehat{\\boldsymbol{Q}}^{(1)},\\widehat{\\boldsymbol{Q}}^{(2)}) ( over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT )  as any optimal solution of ( 6 ) under the constraint ( 6i ). Then, we have  Q ^ ( q )  x ( q ) =   c superscript ^ Q q superscript x q  c \\widehat{\\boldsymbol{Q}}^{(q)}\\boldsymbol{x}^{(q)}=\\bm{\\Theta}\\bm{c} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_ bold_italic_c .  From our objective in ( 6 ), we obtain",
            "Using Assumption  1  and following the proof of step 1 in Theorem  B , we can obtain:",
            "Under ( 1 ), assume that every aligned pair  ( x ( 1 ) , x ( 2 ) ) superscript x 1 superscript x 2 (\\boldsymbol{x}^{(1)},\\boldsymbol{x}^{(2)}) ( bold_italic_x start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , bold_italic_x start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT )  share the same  c c \\bm{c} bold_italic_c , and that  A ( q ) superscript A q \\boldsymbol{A}^{(q)} bold_italic_A start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  has full column rank. Also assume that there exists an  N N N italic_N -sample set  { l 1 , ... , l N } subscript l 1 ... subscript l N \\{\\ell_{1},\\ldots,\\ell_{N}\\} { roman_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ... , roman_l start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT }  such that  [ C  , ( P ( 1 ) )  , ( P ( 2 ) )  ]  R N  ( d C + d P ( 1 ) + d P ( 2 ) ) superscript C top superscript superscript P 1 top superscript superscript P 2 top superscript R N subscript d C superscript subscript d P 1 superscript subscript d P 2 [\\bm{C}^{\\!\\top\\!},(\\bm{P}^{(1)})^{\\!\\top\\!},(\\bm{P}^{(2)})^{\\!\\top\\!}]\\in% \\mathbb{R}^{N\\times(d_{\\rm C}+d_{\\rm P}^{(1)}+d_{\\rm P}^{(2)})} [ bold_italic_C start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , ( bold_italic_P start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , ( bold_italic_P start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ]  roman_R start_POSTSUPERSCRIPT italic_N  ( italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT + italic_d start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT + italic_d start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT ) end_POSTSUPERSCRIPT  has full column rank, where  C = [ c l 1 , ...  c l N ]  R d C  N C subscript c subscript l 1 ... subscript c subscript l N superscript R subscript d C N \\bm{C}=[\\bm{c}_{\\ell_{1}},\\ldots\\bm{c}_{\\ell_{N}}]\\in\\mathbb{R}^{d_{\\rm C}% \\times N} bold_italic_C = [ bold_italic_c start_POSTSUBSCRIPT roman_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , ... bold_italic_c start_POSTSUBSCRIPT roman_l start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT end_POSTSUBSCRIPT ]  roman_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT  italic_N end_POSTSUPERSCRIPT  and  P ( q ) = [ p l 1 ( q )  ...  p l N ( q ) ]  R d P ( q )  N superscript P q delimited-[] superscript subscript p subscript l 1 q ... superscript subscript p subscript l N q superscript R superscript subscript d P q N \\bm{P}^{(q)}=[\\bm{p}_{\\ell_{1}}^{(q)}\\ldots\\bm{p}_{\\ell_{N}}^{(q)}]\\in\\mathbb{% R}^{d_{\\rm P}^{(q)}\\times N} bold_italic_P start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = [ bold_italic_p start_POSTSUBSCRIPT roman_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT ... bold_italic_p start_POSTSUBSCRIPT roman_l start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT ]  roman_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  italic_N end_POSTSUPERSCRIPT  for  q = 1 , 2 q 1 2 q=1,2 italic_q = 1 , 2 . Denote  ( Q ^ ( 1 ) , Q ^ ( 2 ) ) superscript ^ Q 1 superscript ^ Q 2 (\\widehat{\\boldsymbol{Q}}^{(1)},\\widehat{\\boldsymbol{Q}}^{(2)}) ( over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT )  as an optimal solution of the CCA formulation. Then, we we have",
            "Under ( 1 ), assume that the following are met: (i) The conditions for ICA identifiability  [ 33 ]  is met by each modality, including that the components of  z ( q ) = [ c  , ( p ( q ) )  ]  superscript z q superscript superscript c top superscript superscript p q top top \\bm{z}^{(q)}=[\\bm{c}^{\\top},(\\bm{p}^{(q)})^{\\top}]^{\\top} bold_italic_z start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = [ bold_italic_c start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , ( bold_italic_p start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ] start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  are mutually statistically independent and contain at most one Gaussian variable. In addition, each  z i ( q ) subscript superscript z q i \\bm{z}^{(q)}_{i} bold_italic_z start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  has unit variance; (ii)  P z i ( q ) = P z j ( q ) , P z i ( q ) = P  z j ( q )   i , j  [ d C + d P ( q ) ] , i = j formulae-sequence subscript P subscript superscript z q i subscript P subscript superscript z q j formulae-sequence subscript P subscript superscript z q i subscript P subscript superscript z q j for-all i formulae-sequence j delimited-[] subscript d C superscript subscript d P q i j \\mathbb{P}_{z^{(q)}_{i}}\\neq\\mathbb{P}_{z^{(q)}_{j}},\\mathbb{P}_{z^{(q)}_{i}}% \\neq\\mathbb{P}_{-z^{(q)}_{j}}~{}\\forall i,j\\in[d_{\\rm C}+d_{\\rm P}^{(q)}],~{}i\\neq j roman_P start_POSTSUBSCRIPT italic_z start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT = roman_P start_POSTSUBSCRIPT italic_z start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT , roman_P start_POSTSUBSCRIPT italic_z start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT = roman_P start_POSTSUBSCRIPT - italic_z start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT  italic_i , italic_j  [ italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT + italic_d start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT ] , italic_i = italic_j . Then, assume that  ( i m , j m ) subscript i m subscript j m (i_{m},j_{m}) ( italic_i start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT , italic_j start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT )  are obtained by ICA followed by cross domain matching (see the part on Unaligned SCA in Section  2  ) for  m = 1 , ... , d C m 1 ... subscript d C m=1,\\ldots,d_{\\rm C} italic_m = 1 , ... , italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT . Denote  c ^ m ( 1 ) = e i m   z ^ ( 1 ) subscript superscript ^ c 1 m subscript superscript e top subscript i m superscript ^ z 1 \\widehat{c}^{(1)}_{m}=\\bm{e}^{\\!\\top\\!}_{i_{m}}\\widehat{\\bm{z}}^{(1)} over^ start_ARG italic_c end_ARG start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT = bold_italic_e start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT end_POSTSUBSCRIPT over^ start_ARG bold_italic_z end_ARG start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT  and  c ^ m ( 2 ) = e j m   z ^ ( 2 ) subscript superscript ^ c 2 m subscript superscript e top subscript j m superscript ^ z 2 \\widehat{c}^{(2)}_{m}=\\bm{e}^{\\!\\top\\!}_{j_{m}}\\widehat{\\bm{z}}^{(2)} over^ start_ARG italic_c end_ARG start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT = bold_italic_e start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT end_POSTSUBSCRIPT over^ start_ARG bold_italic_z end_ARG start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT . We have the following:",
            "Data Generation:   We set  d C = 3 subscript d C 3 d_{\\rm C}=3 italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT = 3  and  d P ( q ) = 1 subscript superscript d q P 1 d^{(q)}_{\\rm P}=1 italic_d start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT = 1  for  q = 1 , 2 q 1 2 q=1,2 italic_q = 1 , 2 . We sample each component of shared component  c i  Laplace  ( 0.0 , 6.5 )  i = 1 , 2 , 3 formulae-sequence similar-to subscript c i Laplace 0.0 6.5 i 1 2 3 \\bm{c}_{i}\\sim\\texttt{Laplace}(0.0,~{}6.5)~{}i=1,2,3 bold_italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  Laplace ( 0.0 , 6.5 ) italic_i = 1 , 2 , 3 ,  p ( 1 )  R 1  Uniform  [  10 , 10 ] superscript p 1 superscript R 1 similar-to Uniform 10 10 p^{(1)}\\in\\mathbb{R}^{1}~{}\\sim\\texttt{Uniform}[-10,~{}10] italic_p start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT  roman_R start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT  Uniform [ - 10 , 10 ]  and  p ( 2 )  Gamma  ( 0.5 , 3.0 ) similar-to superscript p 2 Gamma 0.5 3.0 p^{(2)}\\sim\\texttt{Gamma}(0.5,~{}3.0) italic_p start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT  Gamma ( 0.5 , 3.0 ) . Although  c c \\boldsymbol{c} bold_italic_c  satisfies component-wise independence assumption, it does not satisfy the condition that  c i = ( d ) k  c j ,  i = j formulae-sequence superscript d subscript c i k subscript c j for-all i j c_{i}\\stackrel{{\\scriptstyle({\\sf d})}}{{\\neq}}kc_{j},\\forall i\\neq j italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_RELOP SUPERSCRIPTOP start_ARG = end_ARG start_ARG ( sansserif_d ) end_ARG end_RELOP italic_k italic_c start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ,  italic_i = italic_j  because  c i  \\xlongequal  ( d )  c j ,  i , j  [ 3 ] subscript c i \\xlongequal d subscript c j for-all i j delimited-[] 3 c_{i}\\xlongequal{({\\sf d})}c_{j},\\forall i,j\\in[3] italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( sansserif_d ) italic_c start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ,  italic_i , italic_j  [ 3 ] . Therefore, Theorem  1  does not cover this case. Nonetheless, this case falls under the jurisdiction of Theorem  3 .",
            "Theorems  1 - 3  are concerned with learning the shared component  c c \\boldsymbol{c} bold_italic_c . The goal, there, was to ensure that  Q C ( q )  x ( q )    c ,  q superscript subscript Q C q superscript x q  c for-all q \\boldsymbol{Q}_{\\rm C}^{(q)}\\boldsymbol{x}^{(q)}\\bm{\\Theta}\\bm{c},\\forall q bold_italic_Q start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_ bold_italic_c ,  italic_q . In some cases, the private components  p ( q ) superscript p q \\bm{p}^{(q)} bold_italic_p start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  is also of interest  [ 6 ,  31 ,  70 ] . To learn  p ( q ) superscript p q \\bm{p}^{(q)} bold_italic_p start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT , we propose to solve the following learning criterion:",
            "Assumption  1  and assumptions in Theorem  1  are satisfied, and ( 6er ) is solved yielding solutions  Q ^ C ( q ) subscript superscript ^ Q q C \\widehat{\\boldsymbol{Q}}^{(q)}_{\\rm C} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT  and  Q ^ P ( q ) subscript superscript ^ Q q P \\widehat{\\boldsymbol{Q}}^{(q)}_{\\rm P} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT",
            "Assumption  1  is satisfied and  d C subscript d C d_{\\rm C} italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT  paired samples  ( x l ( 1 ) , x l ( 2 ) ) superscript subscript x l 1 superscript subscript x l 2 (\\boldsymbol{x}_{\\ell}^{(1)},\\boldsymbol{x}_{\\ell}^{(2)}) ( bold_italic_x start_POSTSUBSCRIPT roman_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , bold_italic_x start_POSTSUBSCRIPT roman_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT )  are available (weak supervision), and denote  Q ^ C ( q ) subscript superscript ^ Q q C \\widehat{\\boldsymbol{Q}}^{(q)}_{\\rm C} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT  and  Q ^ P ( q ) subscript superscript ^ Q q P \\widehat{\\boldsymbol{Q}}^{(q)}_{\\rm P} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT  as the solutions after solving ( 6er ).",
            "using Theorems  1 - 3 . The proofs are referred to Appendix  B - D ."
        ]
    },
    "id_table_2": {
        "caption": "Table 2 :  Classification accuracy on the target domain of  office-Home  dataset for domain adaptation.",
        "table": "A8.EGx2",
        "footnotes": [],
        "references": [
            "where  k  { + 1 ,  1 } k 1 1 k\\in\\{+1,-1\\} italic_k  { + 1 , - 1 }  and    \\bm{\\pi} bold_italic_  is a permutation of  { 1 , ... , d C } 1 ... subscript d C \\{1,\\ldots,d_{\\rm C}\\} { 1 , ... , italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT }  (see details in Appendix  E.2  summarized from  [ 8 ] ). This method effectively applies ICA to each modality, and thus the ICA identifiability conditions  [ 33 ]  have to met by  x ( 1 ) superscript x 1 \\boldsymbol{x}^{(1)} bold_italic_x start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT  and  x ( 2 ) superscript x 2 \\boldsymbol{x}^{(2)} bold_italic_x start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT  individually. However, if one only aims to extract    c  c \\bm{\\Theta}\\bm{c} bold_ bold_italic_c  as in CCA, these assumptions appear to be overly stringent.",
            "Second, even when the disentanglement is attained via enforcing ( LABEL:eq:dm ) and we have  Q ( q )  x ( q ) =  ( q )  c superscript Q q superscript x q superscript  q c \\bm{Q}^{(q)}\\boldsymbol{x}^{(q)}=\\bm{\\Theta}^{(q)}\\bm{c} bold_italic_Q start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_ start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_italic_c , in general it does not hold that   ( 1 ) =  ( 2 ) superscript  1 superscript  2 \\bm{\\Theta}^{(1)}=\\bm{\\Theta}^{(2)} bold_ start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT = bold_ start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT . This is because   ( 1 )  c  \\xlongequal  ( d )   ( 2 )  c superscript  1 c \\xlongequal d superscript  2 c \\bm{\\Theta}^{(1)}\\boldsymbol{c}\\xlongequal{({\\sf d})}\\bm{\\Theta}^{(2)}% \\boldsymbol{c} bold_ start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT bold_italic_c ( sansserif_d ) bold_ start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT bold_italic_c  where   ( 1 ) =  ( 2 ) superscript  1 superscript  2 \\bm{\\Theta}^{(1)}\\neq\\bm{\\Theta}^{(2)} bold_ start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT = bold_ start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT  can still be perfectly met (e.g., when  P  ( q )  c subscript P superscript  q c \\mathbb{P}_{\\bm{\\Theta}^{(q)}\\bm{c}} roman_P start_POSTSUBSCRIPT bold_ start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_italic_c end_POSTSUBSCRIPT  is symmetric Gaussian in Fig.  2  ). However,   ( 1 ) =  ( 2 ) superscript  1 superscript  2 \\bm{\\Theta}^{(1)}\\neq\\bm{\\Theta}^{(2)} bold_ start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT = bold_ start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT  means that the extracted representations from the two modalities are not matched. This creates challenges for applications like cross-domain information retrieval, language translation, or domain adaptation.",
            "The condition in Assumption  1  is a geometric way to characterize the difference between  P c , p ( 1 ) subscript P c superscript p 1 \\mathbb{P}_{\\boldsymbol{c},\\boldsymbol{p}^{(1)}} roman_P start_POSTSUBSCRIPT bold_italic_c , bold_italic_p start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT end_POSTSUBSCRIPT  and  P c , p ( 2 ) subscript P c superscript p 2 \\mathbb{P}_{\\boldsymbol{c},\\boldsymbol{p}^{(2)}} roman_P start_POSTSUBSCRIPT bold_italic_c , bold_italic_p start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT end_POSTSUBSCRIPT if the joint distributions have different measures for all possible stripes, each being a direct sum of a subspace and a convex hull (see Fig.  2 ), then  P c , p ( 1 ) subscript P c superscript p 1 \\mathbb{P}_{\\boldsymbol{c},\\boldsymbol{p}^{(1)}} roman_P start_POSTSUBSCRIPT bold_italic_c , bold_italic_p start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT end_POSTSUBSCRIPT  and  P c , p ( 2 \\mathbb{P}_{\\boldsymbol{c},\\boldsymbol{p}^{(2}} roman_P start_POSTSUBSCRIPT bold_italic_c , bold_italic_p start_POSTSUPERSCRIPT ( 2 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT  must be very different. Note that the difference is contributed by the modality-specific term  p ( q ) superscript p q \\boldsymbol{p}^{(q)} bold_italic_p start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT , and thus we call this condition modality variability. Modality variability is similar to the domain variablity used in  [ 32 ,  39 ] both characterize the discrepancy of the joint probabilities  P c , p ( 1 ) subscript P c superscript p 1 \\mathbb{P}_{\\boldsymbol{c},\\boldsymbol{p}^{(1)}} roman_P start_POSTSUBSCRIPT bold_italic_c , bold_italic_p start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT end_POSTSUBSCRIPT  and  P c , p ( 2 \\mathbb{P}_{\\boldsymbol{c},\\boldsymbol{p}^{(2}} roman_P start_POSTSUBSCRIPT bold_italic_c , bold_italic_p start_POSTSUPERSCRIPT ( 2 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT . However, there are key differences: The domain variability was defined in a unified latent domain over  arbitrary  sets  A A {\\cal A} caligraphic_A , which could be stringent. Instead, we use the fact that ( 6 ) relies on linear operations to construct  A ( q ) superscript A q \\mathcal{A}^{(q)} caligraphic_A start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT , which makes the condition defined over a much smaller class of setsthereby largely relaxing the requirements. Restricting  A ( q ) superscript A q \\mathcal{A}^{(q)} caligraphic_A start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  to be stripes also makes the modality variability condition much more relaxed compared to the domain variability condition.",
            "Consider the mixture model in ( 6h ). Assume that  rank  ( A ) = d C + d P rank A subscript d C subscript d P {\\rm rank}(\\boldsymbol{A})=d_{\\rm C}+d_{\\rm P} roman_rank ( bold_italic_A ) = italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT + italic_d start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT  and  rank  ( E  [ c  c  ] ) = d C rank E delimited-[] c superscript c top subscript d C {\\rm rank}(\\mathbb{E}[\\bm{c}\\bm{c}^{\\!\\top\\!}])={d_{\\rm C}} roman_rank ( roman_E [ bold_italic_c bold_italic_c start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ] ) = italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT , and that Assumption  2  holds. Denote  Q ^ ^ Q \\widehat{\\boldsymbol{Q}} over^ start_ARG bold_italic_Q end_ARG  as any solution of ( 6 ) by constraining  Q = Q ( 1 ) = Q ( 2 ) Q superscript Q 1 superscript Q 2 \\boldsymbol{Q}=\\boldsymbol{Q}^{(1)}=\\boldsymbol{Q}^{(2)} bold_italic_Q = bold_italic_Q start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT = bold_italic_Q start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT . Then, we have  Q ^  x ( q ) =   c ^ Q superscript x q  c \\widehat{\\boldsymbol{Q}}\\boldsymbol{x}^{(q)}=\\bm{\\Theta}\\bm{c} over^ start_ARG bold_italic_Q end_ARG bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_ bold_italic_c .",
            "One can see that the conditions (a) and (b) in Theorem  1  are completely removed, if the structure  A ( 1 ) = A ( 2 ) superscript A 1 superscript A 2 \\boldsymbol{A}^{(1)}=\\boldsymbol{A}^{(2)} bold_italic_A start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT = bold_italic_A start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT  is imposed. In fact, the result in Theorem  2  is expected and readily seen from the proof of Theorem  1 , as the cause for   ( 1 ) =  ( 2 ) superscript  1 superscript  2 \\bm{\\Theta}^{(1)}\\neq\\bm{\\Theta}^{(2)} bold_ start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT = bold_ start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT  is the use of two different  Q ( q ) superscript Q q \\boldsymbol{Q}^{(q)} bold_italic_Q start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT s. Nonetheless, this simple variation will prove useful in a series of real-data experiments.",
            "Identifiability of Unaligned SCA.  The works in  [ 39 ,  32 ]  investigated the shared component identifiability when the multimodal data are nonlinear mixtures of content and style (which are shared and private components, respectively) under the same mixing system. Hence, our identical linear mixing case in Theorem  2  can be understood as a special case of theirs. But their analysis relies on the assumption that all the latent components are statistically independent, which is much stronger than our conditions in Theorem  2 . Their results also require that there are a large amount of modalities available. But our proof works for just two modalities. The most related work is  [ 8 ] , which uses the model in ( 1 ) in the context of multi-view causal graph learning. As discussed before, their assumptions on the latent components are much stronger than ours (see Corollary  1  and Appendix  E.2 ).",
            "Baselines and Training Setup : The baselines are representative DA methods, namely,  DANN   [ 25 ] ,  ADDA [ 56 ] ,  DAN [ 24 ] ,  JAN [ 50 ]  , CDAN [ 57 ] ,  MDD [ 58 ] , and  MCC [ 59 ] . All the baselines integrate deep neural networks as their shared representation learner and the classifier trained over the source data (see Appendix  G.2  for their configurations). We also use  CLIP  as an extra baseline as it learns informative and transferable features from excessively large datasets according to empirical studies. We follow the training strategies adopted by the baselines  [ 24 ,  25 ,  57 ,  58 ]  to learn a classifier jointly with the feature extractors. This strategy arguably regularizes towards more classification-friendly geometry of the shared features. Therefore we append a cross-entropy (CE) based classifier training module to our loss in ( 6g ) that learns our feature extractor  Q Q \\bm{Q} bold_italic_Q . More details are in Appendix  G.2 .",
            "Result : Table  1  and Table  2  show the results on  Office-31  and  Office-Home , respectively. The results are averaged over 5 runs. One can observe that the proposed method and the CLIP model offers the best and the second best performance in most of the tasks. This shows that, as a foundation model, CLIP can already unify the embeddings of the source and target domains in a reasonable extent. In addition, Our model and algorithm are useful as a relatively simple post-processing of CLIPOur method always improves upon CLIP; in some tasks (e.g., W   \\rightarrow  A ,  Ar   \\rightarrow  CI ,  Pr   \\rightarrow  Ar  and  Pr   \\rightarrow  CI ), more than 4% accuracy gains can be obtained by using the proposed method.",
            "Finally, by the same argument presented in last paragraph of Sec.  B.2  (i.e., proof with Assumption (a)), we conclude that  M M \\boldsymbol{M} bold_italic_M  is an identity matrix.",
            "We restate the theorem here:  {mdframed} [backgroundcolor=gray!10,topline=false, rightline=false, leftline=false, bottomline=false]  Theorem   2  Consider the mixture model in ( 6h ). Assume that  rank  ( A ) = d C + d P rank A subscript d C subscript d P {\\rm rank}(\\boldsymbol{A})=d_{\\rm C}+d_{\\rm P} roman_rank ( bold_italic_A ) = italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT + italic_d start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT  and  rank  ( E  [ c  c  ] ) = d C rank E delimited-[] c superscript c top subscript d C {\\rm rank}(\\mathbb{E}[\\bm{c}\\bm{c}^{\\!\\top\\!}])={d_{\\rm C}} roman_rank ( roman_E [ bold_italic_c bold_italic_c start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ] ) = italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT , and that Assumption  2  holds. Denote  Q ^ ^ Q \\widehat{\\boldsymbol{Q}} over^ start_ARG bold_italic_Q end_ARG  as any solution of ( 6 ) by constraining  Q = Q ( 1 ) = Q ( 2 ) Q superscript Q 1 superscript Q 2 \\boldsymbol{Q}=\\boldsymbol{Q}^{(1)}=\\boldsymbol{Q}^{(2)} bold_italic_Q = bold_italic_Q start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT = bold_italic_Q start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT . Then, we have  Q ^  x ( q ) =   c ^ Q superscript x q  c \\widehat{\\boldsymbol{Q}}\\boldsymbol{x}^{(q)}=\\bm{\\Theta}\\bm{c} over^ start_ARG bold_italic_Q end_ARG bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_ bold_italic_c .",
            "because  Null  ( H ) Null H {\\rm Null}(\\boldsymbol{H}) roman_Null ( bold_italic_H )  is a subspace of dimension  d P subscript d P d_{\\rm P} italic_d start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT , hence it satisfies the definition of  P P \\mathcal{P} caligraphic_P . Hence, Assumption  2  implies that",
            "Under ( 1 ), assume that the following are met: (i) The conditions for ICA identifiability  [ 33 ]  is met by each modality, including that the components of  z ( q ) = [ c  , ( p ( q ) )  ]  superscript z q superscript superscript c top superscript superscript p q top top \\bm{z}^{(q)}=[\\bm{c}^{\\top},(\\bm{p}^{(q)})^{\\top}]^{\\top} bold_italic_z start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = [ bold_italic_c start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT , ( bold_italic_p start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ] start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  are mutually statistically independent and contain at most one Gaussian variable. In addition, each  z i ( q ) subscript superscript z q i \\bm{z}^{(q)}_{i} bold_italic_z start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  has unit variance; (ii)  P z i ( q ) = P z j ( q ) , P z i ( q ) = P  z j ( q )   i , j  [ d C + d P ( q ) ] , i = j formulae-sequence subscript P subscript superscript z q i subscript P subscript superscript z q j formulae-sequence subscript P subscript superscript z q i subscript P subscript superscript z q j for-all i formulae-sequence j delimited-[] subscript d C superscript subscript d P q i j \\mathbb{P}_{z^{(q)}_{i}}\\neq\\mathbb{P}_{z^{(q)}_{j}},\\mathbb{P}_{z^{(q)}_{i}}% \\neq\\mathbb{P}_{-z^{(q)}_{j}}~{}\\forall i,j\\in[d_{\\rm C}+d_{\\rm P}^{(q)}],~{}i\\neq j roman_P start_POSTSUBSCRIPT italic_z start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT = roman_P start_POSTSUBSCRIPT italic_z start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT , roman_P start_POSTSUBSCRIPT italic_z start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT = roman_P start_POSTSUBSCRIPT - italic_z start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT  italic_i , italic_j  [ italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT + italic_d start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT ] , italic_i = italic_j . Then, assume that  ( i m , j m ) subscript i m subscript j m (i_{m},j_{m}) ( italic_i start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT , italic_j start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT )  are obtained by ICA followed by cross domain matching (see the part on Unaligned SCA in Section  2  ) for  m = 1 , ... , d C m 1 ... subscript d C m=1,\\ldots,d_{\\rm C} italic_m = 1 , ... , italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT . Denote  c ^ m ( 1 ) = e i m   z ^ ( 1 ) subscript superscript ^ c 1 m subscript superscript e top subscript i m superscript ^ z 1 \\widehat{c}^{(1)}_{m}=\\bm{e}^{\\!\\top\\!}_{i_{m}}\\widehat{\\bm{z}}^{(1)} over^ start_ARG italic_c end_ARG start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT = bold_italic_e start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT end_POSTSUBSCRIPT over^ start_ARG bold_italic_z end_ARG start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT  and  c ^ m ( 2 ) = e j m   z ^ ( 2 ) subscript superscript ^ c 2 m subscript superscript e top subscript j m superscript ^ z 2 \\widehat{c}^{(2)}_{m}=\\bm{e}^{\\!\\top\\!}_{j_{m}}\\widehat{\\bm{z}}^{(2)} over^ start_ARG italic_c end_ARG start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT = bold_italic_e start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT end_POSTSUBSCRIPT over^ start_ARG bold_italic_z end_ARG start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT . We have the following:",
            "Assumption  2  is satisfied and has same mixing matrix  A ( q ) = A superscript A q A \\boldsymbol{A}^{(q)}=\\boldsymbol{A} bold_italic_A start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_italic_A  and ( 6er ) with  Q P ( q ) = Q P superscript subscript Q P q subscript Q P \\boldsymbol{Q}_{\\rm P}^{(q)}=\\boldsymbol{Q}_{\\rm P} bold_italic_Q start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_italic_Q start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT  and  Q C ( q ) = Q C superscript subscript Q C q subscript Q C \\boldsymbol{Q}_{\\rm C}^{(q)}=\\boldsymbol{Q}_{\\rm C} bold_italic_Q start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_italic_Q start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT  is solved yielding  Q ^ C ( q ) subscript superscript ^ Q q C \\widehat{\\boldsymbol{Q}}^{(q)}_{\\rm C} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT  and  Q ^ P ( q ) subscript superscript ^ Q q P \\widehat{\\boldsymbol{Q}}^{(q)}_{\\rm P} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT  as the solutions."
        ]
    },
    "id_table_3": {
        "caption": "Table 3 :  Definition of notations.",
        "table": "S2.E3",
        "footnotes": [],
        "references": [
            "where  Q ( q )  R d C  d ( q ) superscript Q q superscript R subscript d C superscript d q \\boldsymbol{Q}^{(q)}\\in\\mathbb{R}^{d_{\\rm C}\\times{d^{(q)}}} bold_italic_Q start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  roman_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT  italic_d start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT . The expectation in ( 3a ) is taken from the joint distribution of the  aligned pairs   P x ( 1 ) , x ( 2 ) subscript P superscript x 1 superscript x 2 \\mathbb{P}_{\\boldsymbol{x}^{(1)},\\boldsymbol{x}^{(2)}} roman_P start_POSTSUBSCRIPT bold_italic_x start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , bold_italic_x start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT end_POSTSUBSCRIPT , where every pair  ( x ( 1 ) , x ( 2 ) ) superscript x 1 superscript x 2 (\\boldsymbol{x}^{(1)},\\boldsymbol{x}^{(2)}) ( bold_italic_x start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , bold_italic_x start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT )  shares the same  c c \\bm{c} bold_italic_c . The formulation aims to find  Q ( q ) superscript Q q \\boldsymbol{Q}^{(q)} bold_italic_Q start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  such that the transformed representations of the aligned pairs  Q ( 1 )  x ( 1 ) superscript Q 1 superscript x 1 \\boldsymbol{Q}^{(1)}\\boldsymbol{x}^{(1)} bold_italic_Q start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT bold_italic_x start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT  and  Q ( 2 )  x ( 2 ) superscript Q 2 superscript x 2 \\boldsymbol{Q}^{(2)}\\boldsymbol{x}^{(2)} bold_italic_Q start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT bold_italic_x start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT  are equal. In  [ 1 ] , it was shown that",
            "Unaligned SCA: Problem Formulation  We assume that  x ( q ) superscript x q \\boldsymbol{x}^{(q)} bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT s are zero-mean. We use the notation from CCA in ( 3a ). However, since no aligned samples are available, we replace the sample-level matching objective with a distribution matching (DM) module, as DM can be carried out without sample level alignment:",
            "Numerical Validation.  In Fig.  3 , the top and bottom rows validate Theorem  1  under the assumptions in (a) and (b), respectively. In the top row, we set  c  R 2 c superscript R 2 \\bm{c}\\in\\mathbb{R}^{2} bold_italic_c  roman_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , where  c 1 subscript c 1 c_{1} italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  is sampled from Gaussian mixtures with three components and  c 2 subscript c 2 c_{2} italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT  is sampled from a Gamma distribution (and  c 1   c 2 c_{1}\\perp\\!\\!\\!\\perp c_{2} italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT   italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ). We set  p ( 1 ) superscript p 1 p^{(1)} italic_p start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT  and  p ( 2 ) superscript p 2 p^{(2)} italic_p start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT  as one-dimensional Laplacian and uniform distributions. In the bottom row, the dimensions of  c c \\bm{c} bold_italic_c  and  p ( q ) superscript p q \\bm{p}^{(q)} bold_italic_p start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  for  q = 1 , 2 q 1 2 q=1,2 italic_q = 1 , 2  are unchanged, but their distributions are replaced in order to satisfy conditions in (b) (see details in Appendix  F ). One can see that clearly  c ^ ( q ) =   c superscript ^ c q  c \\widehat{\\bm{c}}^{(q)}=\\bm{\\Theta}\\bm{c} over^ start_ARG bold_italic_c end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_ bold_italic_c ; i.e., the learned  c ^ ( q ) superscript ^ c q \\widehat{\\bm{c}}^{(q)} over^ start_ARG bold_italic_c end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  for  q = 1 , 2 q 1 2 q=1,2 italic_q = 1 , 2  are identically rotated and scaled versions of  c c \\bm{c} bold_italic_c .",
            "The plot in Fig.  4  shows the  k k k italic_k -NN accuracy of the methods on the test set. Results show the mean and standard deviation over 10 runs, each having a different random initialization. For the proposed method, we vary the number of available paired samples from  0 0  (cf. Theorem  1 ) to  d C = 256 subscript d C 256 d_{\\rm C}=256 italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT = 256  (cf. Theorem  3 ). Note that the baseline uses more (i.e.,  256 256 256 256  and  770 770 770 770 ) paired samples. It also needs additional class labels, i.e.,  y i ( q ) superscript subscript y i q y_{i}^{(q)} italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  for the  i i i italic_i th sample  x i ( q ) subscript superscript x q i \\boldsymbol{x}^{(q)}_{i} bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . Here,  y i ( q ) superscript subscript y i q y_{i}^{(q)} italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  represents the number of hours ( 0 0 ,  1 1 1 1  or  3 3 3 3 ) of cell treatment  [ 62 ,  27 ] . The proposed method without any supervision (i.e.,  0 0  paired samples) already exhibits around 3 times greater  k k k italic_k -NN accuracy compared to the baseline for all  k k k italic_k . Moreover, including just one paired sample boosts the  k k k italic_k -NN accuracy of the proposed method to around 5 times higher than the baseline for all  k k k italic_k . Finally, one can observe a steadily increasing  k k k italic_k -NN accuracy with respect to the number of available paired samples. This corroborates with our Theorem  3 .",
            "The notations used throughout the paper are summarized in the Table  3 .:",
            "We restate the theorem here:  {mdframed} [backgroundcolor=gray!10,topline=false, rightline=false, leftline=false, bottomline=false]  Theorem   3  Assume that Assumption  1  is satisfied, that  | L |  d C L subscript d C |{\\mathcal{L}}|\\geq d_{\\rm C} | caligraphic_L |  italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT  paired samples  ( x l ( 1 ) , x l ( 2 ) ) superscript subscript x l 1 superscript subscript x l 2 (\\boldsymbol{x}_{\\ell}^{(1)},\\boldsymbol{x}_{\\ell}^{(2)}) ( bold_italic_x start_POSTSUBSCRIPT roman_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , bold_italic_x start_POSTSUBSCRIPT roman_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT )  are available, that  A ( q ) , q = 1 , 2 formulae-sequence superscript A q q 1 2 \\bm{A}^{(q)},~{}q=1,2 bold_italic_A start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT , italic_q = 1 , 2  have full column rank, and that  P c subscript P c \\mathbb{P}_{\\bm{c}} roman_P start_POSTSUBSCRIPT bold_italic_c end_POSTSUBSCRIPT  is absolutely continuous. Denote  ( Q ^ ( 1 ) , Q ^ ( 2 ) ) superscript ^ Q 1 superscript ^ Q 2 (\\widehat{\\boldsymbol{Q}}^{(1)},\\widehat{\\boldsymbol{Q}}^{(2)}) ( over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT )  as any optimal solution of ( 6 ) under the constraint ( 6i ). Then, we have  Q ^ ( q )  x ( q ) =   c superscript ^ Q q superscript x q  c \\widehat{\\boldsymbol{Q}}^{(q)}\\boldsymbol{x}^{(q)}=\\bm{\\Theta}\\bm{c} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_ bold_italic_c .  From our objective in ( 6 ), we obtain",
            "Here we explain the data generation details of the result shown in Fig.  3 . For the result in top row, we sample  c 1 subscript c 1 c_{1} italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  from a Gaussian mixture with three Gaussian components. Each component follows a normal distribution  N  (  , 2 ) N  2 \\mathcal{N}(\\mu,~{}2) caligraphic_N ( italic_ , 2 )  where    N  ( 0 , 10 ) similar-to  N 0 10 \\mu\\sim\\mathcal{N}(0,~{}10) italic_  caligraphic_N ( 0 , 10 ) . The second component, i.e.,  c 2 subscript c 2 c_{2} italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , is independently sampled from the gamma distribution  Gamma  ( 1 , 3 ) Gamma 1 3 \\texttt{Gamma}(1,~{}3) Gamma ( 1 , 3 ) . The private components are sampled from  p ( 1 )  Laplace  ( 1.0 , 6.5 ) similar-to superscript p 1 Laplace 1.0 6.5 p^{(1)}~{}\\sim\\texttt{Laplace}(1.0,~{}6.5) italic_p start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT  Laplace ( 1.0 , 6.5 )  and  p ( 2 )  Uniform  [  10 , 10 ] similar-to superscript p 2 Uniform 10 10 p^{(2)}~{}\\sim\\texttt{Uniform}[-10,~{}10] italic_p start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT  Uniform [ - 10 , 10 ] , both only having one dimension. In the bottom row, we sample  c  R 2  VonMises  ( 2.5 , 2.0 ) c superscript R 2 similar-to VonMises 2.5 2.0 \\bm{c}\\in\\mathbb{R}^{2}\\sim~{}\\texttt{VonMises}(2.5,~{}2.0) bold_italic_c  roman_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT  VonMises ( 2.5 , 2.0 )  distribution. The private components satisfy  p ( 1 )  Laplace  ( 1.0 , 6.5 ) similar-to superscript p 1 Laplace 1.0 6.5 p^{(1)}\\sim\\texttt{Laplace}(1.0,~{}6.5) italic_p start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT  Laplace ( 1.0 , 6.5 )  and  p ( 2 )  Gamma  ( 0.5 , 3.0 ) similar-to superscript p 2 Gamma 0.5 3.0 p^{(2)}~{}\\sim\\texttt{Gamma}(0.5,~{}3.0) italic_p start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT  Gamma ( 0.5 , 3.0 ) . Each element of mixing matrices are sampled from  A i  j ( q )  N  ( 0 , 1 ) , q = 1 , 2 formulae-sequence similar-to superscript subscript A i j q N 0 1 q 1 2 \\boldsymbol{A}_{ij}^{(q)}\\sim\\mathcal{N}(0,1),~{}q=1,2 bold_italic_A start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  caligraphic_N ( 0 , 1 ) , italic_q = 1 , 2 . The readers are referred to Table  3  for the definition of notations used for distributions.",
            "Validation of Theorem  3 .  Fig.  5  presents numerical validation for Theorem  3 .",
            "Data Generation:   We set  d C = 3 subscript d C 3 d_{\\rm C}=3 italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT = 3  and  d P ( q ) = 1 subscript superscript d q P 1 d^{(q)}_{\\rm P}=1 italic_d start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT = 1  for  q = 1 , 2 q 1 2 q=1,2 italic_q = 1 , 2 . We sample each component of shared component  c i  Laplace  ( 0.0 , 6.5 )  i = 1 , 2 , 3 formulae-sequence similar-to subscript c i Laplace 0.0 6.5 i 1 2 3 \\bm{c}_{i}\\sim\\texttt{Laplace}(0.0,~{}6.5)~{}i=1,2,3 bold_italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  Laplace ( 0.0 , 6.5 ) italic_i = 1 , 2 , 3 ,  p ( 1 )  R 1  Uniform  [  10 , 10 ] superscript p 1 superscript R 1 similar-to Uniform 10 10 p^{(1)}\\in\\mathbb{R}^{1}~{}\\sim\\texttt{Uniform}[-10,~{}10] italic_p start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT  roman_R start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT  Uniform [ - 10 , 10 ]  and  p ( 2 )  Gamma  ( 0.5 , 3.0 ) similar-to superscript p 2 Gamma 0.5 3.0 p^{(2)}\\sim\\texttt{Gamma}(0.5,~{}3.0) italic_p start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT  Gamma ( 0.5 , 3.0 ) . Although  c c \\boldsymbol{c} bold_italic_c  satisfies component-wise independence assumption, it does not satisfy the condition that  c i = ( d ) k  c j ,  i = j formulae-sequence superscript d subscript c i k subscript c j for-all i j c_{i}\\stackrel{{\\scriptstyle({\\sf d})}}{{\\neq}}kc_{j},\\forall i\\neq j italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_RELOP SUPERSCRIPTOP start_ARG = end_ARG start_ARG ( sansserif_d ) end_ARG end_RELOP italic_k italic_c start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ,  italic_i = italic_j  because  c i  \\xlongequal  ( d )  c j ,  i , j  [ 3 ] subscript c i \\xlongequal d subscript c j for-all i j delimited-[] 3 c_{i}\\xlongequal{({\\sf d})}c_{j},\\forall i,j\\in[3] italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( sansserif_d ) italic_c start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ,  italic_i , italic_j  [ 3 ] . Therefore, Theorem  1  does not cover this case. Nonetheless, this case falls under the jurisdiction of Theorem  3 .",
            "Result:  Fig.  5  corroborates with our Theorem  3 . That is, one needs at least  | L |  d C = 3 L subscript d C 3 |{\\cal L}|\\geq d_{\\rm C}=3 | caligraphic_L |  italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT = 3  pairs of anchors (i.e., aligned cross domain pairs) to ensure identifiability of  c ^ ( q ) =   c superscript ^ c q  c \\widehat{\\bm{c}}^{(q)}=\\bm{\\Theta}\\bm{c} over^ start_ARG bold_italic_c end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_ bold_italic_c  for  q = 1 , 2 q 1 2 q=1,2 italic_q = 1 , 2 .",
            "Theorems  1 - 3  are concerned with learning the shared component  c c \\boldsymbol{c} bold_italic_c . The goal, there, was to ensure that  Q C ( q )  x ( q )    c ,  q superscript subscript Q C q superscript x q  c for-all q \\boldsymbol{Q}_{\\rm C}^{(q)}\\boldsymbol{x}^{(q)}\\bm{\\Theta}\\bm{c},\\forall q bold_italic_Q start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_ bold_italic_c ,  italic_q . In some cases, the private components  p ( q ) superscript p q \\bm{p}^{(q)} bold_italic_p start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  is also of interest  [ 6 ,  31 ,  70 ] . To learn  p ( q ) superscript p q \\bm{p}^{(q)} bold_italic_p start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT , we propose to solve the following learning criterion:",
            "using Theorems  1 - 3 . The proofs are referred to Appendix  B - D ."
        ]
    },
    "id_table_4": {
        "caption": "Table 4 :  Hyperparameter settings for multi-lingual information retrieval.",
        "table": "A8.EGx4",
        "footnotes": [],
        "references": [
            "under mild conditions (see Appendix  E.1  for details), where  ( Q ^ ( 1 ) , Q ^ ( 2 ) ) superscript ^ Q 1 superscript ^ Q 2 (\\widehat{\\boldsymbol{Q}}^{(1)},\\widehat{\\boldsymbol{Q}}^{(2)}) ( over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT )  is an optimal solution of the CCA formulation and    \\bm{\\Theta} bold_  is a certain non-singular matrix. Eq. ( 4 ) means that  Q ^ ( q ) superscript ^ Q q \\widehat{\\boldsymbol{Q}}^{(q)} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  finds the range space where  c c \\bm{c} bold_italic_c  lives in, i.e.,  range  ( A 1 : d C ( q ) ) range subscript superscript A q : 1 subscript d C {\\rm range}(\\boldsymbol{A}^{(q)}_{1:d_{\\rm C}}) roman_range ( bold_italic_A start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 : italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT end_POSTSUBSCRIPT )  under our notation.",
            "Identifiability of Unaligned SCA  As we saw in Theorem  4 , CCA identifies  Q ^ ( q )  x ( q ) =   c superscript ^ Q q superscript x q  c \\widehat{\\boldsymbol{Q}}^{(q)}\\boldsymbol{x}^{(q)}=\\bm{\\Theta}\\bm{c} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_ bold_italic_c  where    R d C  d C  superscript R subscript d C subscript d C \\bm{\\Theta}\\in\\mathbb{R}^{d_{\\rm C}\\times d_{\\rm C}} bold_  roman_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT  italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT end_POSTSUPERSCRIPT  under the settings of aligned SCA. Establishing a similar result for unaligned SCA is much more challenging. First, it is unclear if ( LABEL:eq:dm ) could disentangle  c c \\bm{c} bold_italic_c  from  p ( q ) superscript p q \\boldsymbol{p}^{(q)} bold_italic_p start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT . In general,  Q ( q )  x ( q ) superscript Q q superscript x q \\boldsymbol{Q}^{(q)}\\boldsymbol{x}^{(q)} bold_italic_Q start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  could still be a mixture of  c c \\bm{c} bold_italic_c  and  p ( q ) superscript p q \\bm{p}^{(q)} bold_italic_p start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  yet ( LABEL:eq:dm ) still holds (e.g., when both  c c \\boldsymbol{c} bold_italic_c  and  p ( q ) superscript p q \\boldsymbol{p}^{(q)} bold_italic_p start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  are Gaussian.)",
            "Setup : We first test the homogeneous domain model in Sec.  4 . The images are pre-processed by the pretrained CLIP model  [ 34 ]  that uses ViT-L/14 transformer architecture. The embedded images are of sizes  d ( q ) = 768 , q = 1 , 2 formulae-sequence superscript d q 768 q 1 2 d^{(q)}=768,~{}q=1,2 italic_d start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = 768 , italic_q = 1 , 2 . We set  d C = 256 subscript d C 256 d_{\\rm C}=256 italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT = 256  for  Office-31  and  d C = 512 subscript d C 512 d_{\\rm C}=512 italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT = 512  for  Office-Home . More detailed settings are in Appendix  G .",
            "The plot in Fig.  4  shows the  k k k italic_k -NN accuracy of the methods on the test set. Results show the mean and standard deviation over 10 runs, each having a different random initialization. For the proposed method, we vary the number of available paired samples from  0 0  (cf. Theorem  1 ) to  d C = 256 subscript d C 256 d_{\\rm C}=256 italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT = 256  (cf. Theorem  3 ). Note that the baseline uses more (i.e.,  256 256 256 256  and  770 770 770 770 ) paired samples. It also needs additional class labels, i.e.,  y i ( q ) superscript subscript y i q y_{i}^{(q)} italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  for the  i i i italic_i th sample  x i ( q ) subscript superscript x q i \\boldsymbol{x}^{(q)}_{i} bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . Here,  y i ( q ) superscript subscript y i q y_{i}^{(q)} italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  represents the number of hours ( 0 0 ,  1 1 1 1  or  3 3 3 3 ) of cell treatment  [ 62 ,  27 ] . The proposed method without any supervision (i.e.,  0 0  paired samples) already exhibits around 3 times greater  k k k italic_k -NN accuracy compared to the baseline for all  k k k italic_k . Moreover, including just one paired sample boosts the  k k k italic_k -NN accuracy of the proposed method to around 5 times higher than the baseline for all  k k k italic_k . Finally, one can observe a steadily increasing  k k k italic_k -NN accuracy with respect to the number of available paired samples. This corroborates with our Theorem  3 .",
            "Hyperparameter Settings : The hyperparameter settings for multi-lingual information retrieval is described in the Table.  4 ."
        ]
    },
    "id_table_5": {
        "caption": "Table 5 :  Average precision P@1 of cross-language information retrieval.",
        "table": "A8.EGx5",
        "footnotes": [],
        "references": [
            "Aligned SCA: Identifiability of CCA and Extensions.  Learning  c c \\bm{c} bold_italic_c  without knowing  A ( q ) superscript A q \\boldsymbol{A}^{(q)} bold_italic_A start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  is a typical component analysis problem. Learning latent components from linear mixtures lacks identifiability in general, due to the bilinear nature of linear mixture models (LMMs) like  x = A  z x A z \\boldsymbol{x}=\\boldsymbol{A}\\boldsymbol{z} bold_italic_x = bold_italic_A bold_italic_z ; see Sec.  5  for various component analysis frameworks dealing with the single-modality LMM. The works  [ 1 ,  2 ]  studied the identifiability of  c c \\boldsymbol{c} bold_italic_c  under the model ( 1 ), using the assumption that the cross-modality samples share the same  c c \\bm{c} bold_italic_c  are aligned. In particular,  [ 1 ]  formulated the  c c \\bm{c} bold_italic_c -identification problem as a CCA problem:",
            "In Theorem  1 , Assumption  1  is used to guarantee  Q ^ ( q )  x ( q ) =  ( q )  c superscript ^ Q q superscript x q superscript  q c \\widehat{\\boldsymbol{Q}}^{(q)}\\boldsymbol{x}^{(q)}=\\bm{\\Theta}^{(q)}\\bm{c} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_ start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_italic_c  and either of conditions (a) or (b) is used to make sure   ( 1 ) =  ( 2 ) superscript  1 superscript  2 \\bm{\\Theta}^{(1)}=\\bm{\\Theta}^{(2)} bold_ start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT = bold_ start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT . Note that both (a) and (b) are milder than those in  [ 8 ]  (cf. Theorem  5 ), where the element-wise statistical independence of  z ( q ) superscript z q \\boldsymbol{z}^{(q)} bold_italic_z start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  was relied on to find shared representation of  x ( 1 ) superscript x 1 \\boldsymbol{x}^{(1)} bold_italic_x start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT  and  x ( 2 ) superscript x 2 \\boldsymbol{x}^{(2)} bold_italic_x start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT . The proof is in Appendix  B .",
            "Validation of Theorem  3 .  Fig.  5  presents numerical validation for Theorem  3 .",
            "Result:  Fig.  5  corroborates with our Theorem  3 . That is, one needs at least  | L |  d C = 3 L subscript d C 3 |{\\cal L}|\\geq d_{\\rm C}=3 | caligraphic_L |  italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT = 3  pairs of anchors (i.e., aligned cross domain pairs) to ensure identifiability of  c ^ ( q ) =   c superscript ^ c q  c \\widehat{\\bm{c}}^{(q)}=\\bm{\\Theta}\\bm{c} over^ start_ARG bold_italic_c end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_ bold_italic_c  for  q = 1 , 2 q 1 2 q=1,2 italic_q = 1 , 2 .",
            "Result : Table  5  reports the P@1 scores over the test data calculated for each source and target language pair. The languages are encoded as  en  - English,  es  - Spanish,  it  - Italian,  fr  - French,  de  - Germany,  ru  - Russian,  ar  - Arabic and  vi  - Vietnamese. One can observe that the proposed method achieves better precision than the  Adv  in most of the translation tasks. For example, proposed method significantly improves the tasks  en   \\to  ar ,  ar   \\to  en ,  en   \\to  vi  and  vi   \\to  en , showing at least gain of  10 % percent 10 10\\% 10 %  in both NN and CSLS based precision. Similarly, our method shows at least  5 % percent 5 5\\% 5 %  improvement in both NN and CSLS based precision in  en   \\to  es  and  es   \\to  en  tasks."
        ]
    },
    "id_table_6": {
        "caption": "Table 6 :  Average precision P@k of cross-language information retrieval",
        "table": "S3.E6",
        "footnotes": [],
        "references": [
            "The formulation in ( 6 ) can be realized using various distribution matching tools, e.g.,  maximum mean discrepancy  (MMD)  [ 36 ]  and  Wasserstein distance   [ 37 ] . We use the adversarial loss:",
            "The first and second terms comprise the adversarial loss from GAN  [ 38 ] . It finds  Q ( q ) superscript Q q \\bm{Q}^{(q)} bold_italic_Q start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  to confuse the best-possible discriminator  f : R d C  R : f  superscript R subscript d C R f:\\mathbb{R}^{d_{\\rm C}}\\rightarrow\\mathbb{R} italic_f : roman_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT end_POSTSUPERSCRIPT  roman_R , where  f f f italic_f  is represented by a neural network in practice. It is well known that the minimax optimal point of the first two terms is attained when ( LABEL:eq:dm ) is met  [ 38 ] . We use  R  ( Q ( q ) ) =  Q ( q )  E  [ x ( q )  ( x ( q ) )  ]  ( Q ( q ) )   I  F 2 R superscript Q q subscript superscript norm superscript Q q E delimited-[] superscript x q superscript superscript x q top superscript superscript Q q top I 2 F {\\cal R}({\\boldsymbol{Q}}^{(q)})=\\|{\\boldsymbol{Q}}^{(q)}\\mathbb{E}[{% \\boldsymbol{x}}^{(q)}({\\boldsymbol{x}}^{(q)})^{\\top}]({\\boldsymbol{Q}}^{(q)})^% {\\top}-\\bm{I}\\|^{2}_{\\rm F} caligraphic_R ( bold_italic_Q start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT ) =  bold_italic_Q start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT roman_E [ bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT ( bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ] ( bold_italic_Q start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT - bold_italic_I  start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_F end_POSTSUBSCRIPT  to lift the constraints. This way, the learning criterion in ( 6g ) can be readily handled by any off-the-shelf adverserial learning tools.",
            "The condition in Assumption  1  is a geometric way to characterize the difference between  P c , p ( 1 ) subscript P c superscript p 1 \\mathbb{P}_{\\boldsymbol{c},\\boldsymbol{p}^{(1)}} roman_P start_POSTSUBSCRIPT bold_italic_c , bold_italic_p start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT end_POSTSUBSCRIPT  and  P c , p ( 2 ) subscript P c superscript p 2 \\mathbb{P}_{\\boldsymbol{c},\\boldsymbol{p}^{(2)}} roman_P start_POSTSUBSCRIPT bold_italic_c , bold_italic_p start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT end_POSTSUBSCRIPT if the joint distributions have different measures for all possible stripes, each being a direct sum of a subspace and a convex hull (see Fig.  2 ), then  P c , p ( 1 ) subscript P c superscript p 1 \\mathbb{P}_{\\boldsymbol{c},\\boldsymbol{p}^{(1)}} roman_P start_POSTSUBSCRIPT bold_italic_c , bold_italic_p start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT end_POSTSUBSCRIPT  and  P c , p ( 2 \\mathbb{P}_{\\boldsymbol{c},\\boldsymbol{p}^{(2}} roman_P start_POSTSUBSCRIPT bold_italic_c , bold_italic_p start_POSTSUPERSCRIPT ( 2 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT  must be very different. Note that the difference is contributed by the modality-specific term  p ( q ) superscript p q \\boldsymbol{p}^{(q)} bold_italic_p start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT , and thus we call this condition modality variability. Modality variability is similar to the domain variablity used in  [ 32 ,  39 ] both characterize the discrepancy of the joint probabilities  P c , p ( 1 ) subscript P c superscript p 1 \\mathbb{P}_{\\boldsymbol{c},\\boldsymbol{p}^{(1)}} roman_P start_POSTSUBSCRIPT bold_italic_c , bold_italic_p start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT end_POSTSUBSCRIPT  and  P c , p ( 2 \\mathbb{P}_{\\boldsymbol{c},\\boldsymbol{p}^{(2}} roman_P start_POSTSUBSCRIPT bold_italic_c , bold_italic_p start_POSTSUPERSCRIPT ( 2 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT . However, there are key differences: The domain variability was defined in a unified latent domain over  arbitrary  sets  A A {\\cal A} caligraphic_A , which could be stringent. Instead, we use the fact that ( 6 ) relies on linear operations to construct  A ( q ) superscript A q \\mathcal{A}^{(q)} caligraphic_A start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT , which makes the condition defined over a much smaller class of setsthereby largely relaxing the requirements. Restricting  A ( q ) superscript A q \\mathcal{A}^{(q)} caligraphic_A start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  to be stripes also makes the modality variability condition much more relaxed compared to the domain variability condition.",
            "Under Assumption  1  and the generative model in ( 1 ), denote any solution of ( 6 ) as  Q ^ ( q ) superscript ^ Q q \\widehat{\\boldsymbol{Q}}^{(q)} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT   q = 1 , 2 q 1 2 q=1,2 italic_q = 1 , 2 . Then, if the mixing matrices  A ( q ) superscript A q \\boldsymbol{A}^{(q)} bold_italic_A start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  are full column ranks and  E [ c c  ] ) \\mathbb{E}[\\bm{c}\\bm{c}^{\\!\\top\\!}]) roman_E [ bold_italic_c bold_italic_c start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ] )  is full rank, we have  Q ^ ( q )  x ( q ) =  ( q )  c superscript ^ Q q superscript x q superscript  q c \\widehat{\\boldsymbol{Q}}^{(q)}\\boldsymbol{x}^{(q)}=\\bm{\\Theta}^{(q)}\\bm{c} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_ start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_italic_c . In addition, assume that either of the following is satisfied:",
            "Theorem  1  was well-supported by the synthetic data experiments. However, our experiments found that the learning criterion ( 6 ) often struggles to produce sensible results in some applications. Our conjecture is that the Assumptions in Theorem  1  (a) and (b) might not have been satisfied by the real data under our tests. Although they are not necessary conditions for identifiability, these conditions do indicate that the requirements to guarantee identifiability of unaligned SCA using ( 6 ) are nontrivial to meet. In this section, we explore a couple of structural constraints arising from side information in applications to remove the need for the relatively stringent assumptions on  c c \\bm{c} bold_italic_c .",
            "Under this model, we look for the shared components by solving ( 6 ) with a single  Q = Q ( 1 ) = Q ( 2 ) Q superscript Q 1 superscript Q 2 \\boldsymbol{Q}=\\boldsymbol{Q}^{(1)}=\\boldsymbol{Q}^{(2)} bold_italic_Q = bold_italic_Q start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT = bold_italic_Q start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT . We use the following version of the modality variability condition:",
            "Consider the mixture model in ( 6h ). Assume that  rank  ( A ) = d C + d P rank A subscript d C subscript d P {\\rm rank}(\\boldsymbol{A})=d_{\\rm C}+d_{\\rm P} roman_rank ( bold_italic_A ) = italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT + italic_d start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT  and  rank  ( E  [ c  c  ] ) = d C rank E delimited-[] c superscript c top subscript d C {\\rm rank}(\\mathbb{E}[\\bm{c}\\bm{c}^{\\!\\top\\!}])={d_{\\rm C}} roman_rank ( roman_E [ bold_italic_c bold_italic_c start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ] ) = italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT , and that Assumption  2  holds. Denote  Q ^ ^ Q \\widehat{\\boldsymbol{Q}} over^ start_ARG bold_italic_Q end_ARG  as any solution of ( 6 ) by constraining  Q = Q ( 1 ) = Q ( 2 ) Q superscript Q 1 superscript Q 2 \\boldsymbol{Q}=\\boldsymbol{Q}^{(1)}=\\boldsymbol{Q}^{(2)} bold_italic_Q = bold_italic_Q start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT = bold_italic_Q start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT . Then, we have  Q ^  x ( q ) =   c ^ Q superscript x q  c \\widehat{\\boldsymbol{Q}}\\boldsymbol{x}^{(q)}=\\bm{\\Theta}\\bm{c} over^ start_ARG bold_italic_Q end_ARG bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_ bold_italic_c .",
            "The condition can be added into our formulation in ( 6 ) as a constraint, i.e.,",
            "Assume that Assumption  1  is satisfied, that  | L |  d C L subscript d C |{\\mathcal{L}}|\\geq d_{\\rm C} | caligraphic_L |  italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT  paired samples  ( x l ( 1 ) , x l ( 2 ) ) superscript subscript x l 1 superscript subscript x l 2 (\\boldsymbol{x}_{\\ell}^{(1)},\\boldsymbol{x}_{\\ell}^{(2)}) ( bold_italic_x start_POSTSUBSCRIPT roman_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , bold_italic_x start_POSTSUBSCRIPT roman_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT )  are available, that  A ( q ) superscript A q \\bm{A}^{(q)} bold_italic_A start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  for  q = 1 , 2 q 1 2 q=1,2 italic_q = 1 , 2  have full column rank, and that  P c subscript P c \\mathbb{P}_{\\bm{c}} roman_P start_POSTSUBSCRIPT bold_italic_c end_POSTSUBSCRIPT  is absolutely continuous. Denote  ( Q ^ ( 1 ) , Q ^ ( 2 ) ) superscript ^ Q 1 superscript ^ Q 2 (\\widehat{\\boldsymbol{Q}}^{(1)},\\widehat{\\boldsymbol{Q}}^{(2)}) ( over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT )  as any optimal solution of ( 6 ) under the constraint ( 6i ). Then, we have  Q ^ ( q )  x ( q ) =   c superscript ^ Q q superscript x q  c \\widehat{\\boldsymbol{Q}}^{(q)}\\boldsymbol{x}^{(q)}=\\bm{\\Theta}\\bm{c} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_ bold_italic_c .",
            "The proof and synthetic data validation can be found in Appendices  D  and   F , respectively. Note that to realize ( 6i ), one only needs to add a regularization term     l  L  Q ( 1 )  x l ( 1 )  Q ( 2 )  x l ( 2 )  2 2  subscript l L superscript subscript norm superscript Q 1 subscript superscript x 1 l superscript Q 2 subscript superscript x 2 l 2 2 \\beta\\sum_{\\ell\\in{\\cal L}}\\|\\boldsymbol{Q}^{(1)}\\boldsymbol{x}^{(1)}_{\\ell}-% \\boldsymbol{Q}^{(2)}\\boldsymbol{x}^{(2)}_{\\ell}\\|_{2}^{2} italic_  start_POSTSUBSCRIPT roman_l  caligraphic_L end_POSTSUBSCRIPT  bold_italic_Q start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT bold_italic_x start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_l end_POSTSUBSCRIPT - bold_italic_Q start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT bold_italic_x start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_l end_POSTSUBSCRIPT  start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT  to the loss in ( 6g ), where    0  0 \\beta\\geq 0 italic_  0  is a tunable parameter. The overall loss is still differentiable and thus can be easily handled by gradient based approaches.",
            "Baselines and Training Setup : The baselines are representative DA methods, namely,  DANN   [ 25 ] ,  ADDA [ 56 ] ,  DAN [ 24 ] ,  JAN [ 50 ]  , CDAN [ 57 ] ,  MDD [ 58 ] , and  MCC [ 59 ] . All the baselines integrate deep neural networks as their shared representation learner and the classifier trained over the source data (see Appendix  G.2  for their configurations). We also use  CLIP  as an extra baseline as it learns informative and transferable features from excessively large datasets according to empirical studies. We follow the training strategies adopted by the baselines  [ 24 ,  25 ,  57 ,  58 ]  to learn a classifier jointly with the feature extractors. This strategy arguably regularizes towards more classification-friendly geometry of the shared features. Therefore we append a cross-entropy (CE) based classifier training module to our loss in ( 6g ) that learns our feature extractor  Q Q \\bm{Q} bold_italic_Q . More details are in Appendix  G.2 .",
            "Dataset : We use human lung adenocarcinoma A549 cells data from  [ 62 ] . The dataset contains 1,874 samples of RNA sequences  { x ( 1 ) } superscript x 1 \\{\\boldsymbol{x}^{(1)}\\} { bold_italic_x start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT }  and ATAC sequences  { x ( 2 ) } superscript x 2 \\{\\boldsymbol{x}^{(2)}\\} { bold_italic_x start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT } . Each data set is split into 1534 training samples and 340 testing samples as in  [ 27 ] . The data have labeled associations between the two domainspart of which will be used to test our weakly supervised formulation. For this experiment, features of RNA sequence and the ATAC sequence have dimensions of  d ( 1 ) = 815 superscript d 1 815 d^{(1)}=815 italic_d start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT = 815  and  d ( 2 ) = 2613 superscript d 2 2613 d^{(2)}=2613 italic_d start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT = 2613 , respectively. We set  d C = 256 subscript d C 256 d_{\\rm C}=256 italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT = 256 . We use our weakly supervised formulation as shown in ( 6i ). We uniformly sampled a set of indices from the training set to serve as  L L {\\cal L} caligraphic_L .",
            "We restate the theorem here:  {mdframed} [backgroundcolor=gray!10,topline=false, rightline=false, leftline=false, bottomline=false]  Theorem   1  Under Assumption  1  and the generative model in ( 1 ), denote any solution of ( 6 ) as  Q ^ ( q ) superscript ^ Q q \\widehat{\\boldsymbol{Q}}^{(q)} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT   q = 1 , 2 q 1 2 q=1,2 italic_q = 1 , 2 . Then, if the mixing matrices  A ( q ) superscript A q \\boldsymbol{A}^{(q)} bold_italic_A start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  are full column ranks and  E [ c c  ] ) \\mathbb{E}[\\bm{c}\\bm{c}^{\\!\\top\\!}]) roman_E [ bold_italic_c bold_italic_c start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ] )  is full rank, we have  Q ^ ( q )  x ( q ) =  ( q )  c superscript ^ Q q superscript x q superscript  q c \\widehat{\\boldsymbol{Q}}^{(q)}\\boldsymbol{x}^{(q)}=\\bm{\\Theta}^{(q)}\\bm{c} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_ start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_italic_c . In addition, assume that either of the following is satisfied:",
            "Since the objective in ( 6 ) matches the distribution for latent random variables  c ^ ( 1 ) = Q ( 1 )  x ( 1 ) superscript ^ c 1 superscript Q 1 superscript x 1 \\widehat{\\boldsymbol{c}}^{(1)}=\\boldsymbol{Q}^{(1)}\\boldsymbol{x}^{(1)} over^ start_ARG bold_italic_c end_ARG start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT = bold_italic_Q start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT bold_italic_x start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT  and  c ^ ( 2 ) = Q ( 2 )  x ( 2 ) superscript ^ c 2 superscript Q 2 superscript x 2 \\widehat{\\boldsymbol{c}}^{(2)}=\\boldsymbol{Q}^{(2)}\\boldsymbol{x}^{(2)} over^ start_ARG bold_italic_c end_ARG start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT = bold_italic_Q start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT bold_italic_x start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT , the following holds for any  R c  R d C ,  k  R formulae-sequence subscript R c superscript R subscript d C for-all k R \\mathcal{R}_{c}\\subseteq\\mathbb{R}^{d_{\\rm C}},\\forall k\\in\\mathbb{R} caligraphic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT  roman_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ,  italic_k  roman_R ,",
            "Although ( 6bj ) holds for any  R c subscript R c \\mathcal{R}_{c} caligraphic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT , we will see that it is sufficient to consider a special  R c subscript R c \\mathcal{R}_{c} caligraphic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT  to prove ( 6bi ). To that end, take  R c = conv  { 0 , a 1 , ... , a d C } subscript R c conv 0 subscript a 1 ... subscript a subscript d C \\mathcal{R}_{c}={\\rm conv}\\{\\boldsymbol{0},\\boldsymbol{a}_{1},\\ldots,% \\boldsymbol{a}_{d_{\\rm C}}\\} caligraphic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = roman_conv { bold_0 , bold_italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ... , bold_italic_a start_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT end_POSTSUBSCRIPT } , where  a i  R d C subscript a i superscript R subscript d C \\boldsymbol{a}_{i}\\in\\mathbb{R}^{d_{\\rm C}} bold_italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  roman_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT end_POSTSUPERSCRIPT  such that  P c ^ ( q )  [ R c ] > 0 subscript P superscript ^ c q delimited-[] subscript R c 0 \\mathbb{P}_{\\widehat{\\boldsymbol{c}}^{(q)}}[\\mathcal{R}_{c}]>0 roman_P start_POSTSUBSCRIPT over^ start_ARG bold_italic_c end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT end_POSTSUBSCRIPT [ caligraphic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ] > 0 . Let us take  y i ( q )  R d C + d P ( q ) superscript subscript y i q superscript R subscript d C superscript subscript d P q \\boldsymbol{y}_{i}^{(q)}\\in\\mathbb{R}^{d_{\\rm C}+d_{\\rm P}^{(q)}} bold_italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  roman_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT + italic_d start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT , such that  H ( q )  y i ( q ) = a i superscript H q superscript subscript y i q subscript a i \\boldsymbol{H}^{(q)}\\boldsymbol{y}_{i}^{(q)}=\\boldsymbol{a}_{i} bold_italic_H start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . For reasons that will be clear later, we hope to show that",
            "We have that  Null  ( H ( q ) )  R d C + d P ( q ) Null superscript H q superscript R subscript d C superscript subscript d P q {\\rm Null}(\\boldsymbol{H}^{(q)})\\subset\\mathbb{R}^{d_{\\rm C}+d_{\\rm P}^{(q)}} roman_Null ( bold_italic_H start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT )  roman_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT + italic_d start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT  is a linear subspace with  dim  ( Null  ( H ( q ) ) ) = d P ( q ) dim Null superscript H q superscript subscript d P q {\\rm dim}({\\rm Null}(\\boldsymbol{H}^{(q)}))=d_{\\rm P}^{(q)} roman_dim ( roman_Null ( bold_italic_H start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT ) ) = italic_d start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT . Let  A ( q ) = H PreImg ( q )  ( R c ) superscript A q subscript superscript H q PreImg subscript R c \\mathcal{A}^{(q)}={\\boldsymbol{H}^{(q)}_{\\rm PreImg}(\\mathcal{R}_{c})} caligraphic_A start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_italic_H start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_PreImg end_POSTSUBSCRIPT ( caligraphic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ) . Note that  P z ( 1 )  [ k  A ( 1 ) ] = P z ( 2 )  [ k  A ( 2 ) ] ,  k  R formulae-sequence subscript P superscript z 1 delimited-[] k superscript A 1 subscript P superscript z 2 delimited-[] k superscript A 2 for-all k R \\mathbb{P}_{\\boldsymbol{z}^{(1)}}[k\\mathcal{A}^{(1)}]=\\mathbb{P}_{\\boldsymbol{% z}^{(2)}}[k\\mathcal{A}^{(2)}],\\forall k\\in\\mathbb{R} roman_P start_POSTSUBSCRIPT bold_italic_z start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT end_POSTSUBSCRIPT [ italic_k caligraphic_A start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT ] = roman_P start_POSTSUBSCRIPT bold_italic_z start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT end_POSTSUBSCRIPT [ italic_k caligraphic_A start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT ] ,  italic_k  roman_R  (from ( 6bj ), and  P z ( q )  [ A ( q ) ] > 0 subscript P superscript z q delimited-[] superscript A q 0 \\mathbb{P}_{\\boldsymbol{z}^{(q)}}[\\mathcal{A}^{(q)}]>0 roman_P start_POSTSUBSCRIPT bold_italic_z start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT end_POSTSUBSCRIPT [ caligraphic_A start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT ] > 0  (by the construction of  R c subscript R c \\mathcal{R}_{c} caligraphic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ). Further, the set  A ( q ) superscript A q \\mathcal{A}^{(q)} caligraphic_A start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  is of the form",
            "The last equation implies that the set of points  M  v i ,  i  [ D ] M subscript v i for-all i delimited-[] D \\boldsymbol{M}\\boldsymbol{v}_{i},\\forall i\\in[D] bold_italic_M bold_italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ,  italic_i  [ italic_D ]  also satisfy property ( 6br ). Hence, for each  i  [ D ] i delimited-[] D i\\in[D] italic_i  [ italic_D ] ,  M  v i =  v j M subscript v i plus-or-minus subscript v j \\boldsymbol{M}\\boldsymbol{v}_{i}=\\pm\\boldsymbol{v}_{j} bold_italic_M bold_italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT =  bold_italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT  for some unique  j  [ D ] j delimited-[] D j\\in[D] italic_j  [ italic_D ] . Note that  j j j italic_j  should be unique for each  i i i italic_i  because  M M \\boldsymbol{M} bold_italic_M  is invertible, hence  M M \\boldsymbol{M} bold_italic_M  cannot map two orthogonal vectors  v i subscript v i \\boldsymbol{v}_{i} bold_italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  and  v k subscript v k \\boldsymbol{v}_{k} bold_italic_v start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ,  i = k i k i\\neq k italic_i = italic_k , to the same vector   v j plus-or-minus subscript v j \\pm\\boldsymbol{v}_{j}  bold_italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT  with same or different signs.",
            "We restate the theorem here:  {mdframed} [backgroundcolor=gray!10,topline=false, rightline=false, leftline=false, bottomline=false]  Theorem   2  Consider the mixture model in ( 6h ). Assume that  rank  ( A ) = d C + d P rank A subscript d C subscript d P {\\rm rank}(\\boldsymbol{A})=d_{\\rm C}+d_{\\rm P} roman_rank ( bold_italic_A ) = italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT + italic_d start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT  and  rank  ( E  [ c  c  ] ) = d C rank E delimited-[] c superscript c top subscript d C {\\rm rank}(\\mathbb{E}[\\bm{c}\\bm{c}^{\\!\\top\\!}])={d_{\\rm C}} roman_rank ( roman_E [ bold_italic_c bold_italic_c start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ] ) = italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT , and that Assumption  2  holds. Denote  Q ^ ^ Q \\widehat{\\boldsymbol{Q}} over^ start_ARG bold_italic_Q end_ARG  as any solution of ( 6 ) by constraining  Q = Q ( 1 ) = Q ( 2 ) Q superscript Q 1 superscript Q 2 \\boldsymbol{Q}=\\boldsymbol{Q}^{(1)}=\\boldsymbol{Q}^{(2)} bold_italic_Q = bold_italic_Q start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT = bold_italic_Q start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT . Then, we have  Q ^  x ( q ) =   c ^ Q superscript x q  c \\widehat{\\boldsymbol{Q}}\\boldsymbol{x}^{(q)}=\\bm{\\Theta}\\bm{c} over^ start_ARG bold_italic_Q end_ARG bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_ bold_italic_c .",
            "Since the objective in ( 6 ) matches the distribution for latent random variables  c ^ ( 1 ) = Q  x ( 1 ) superscript ^ c 1 Q superscript x 1 \\widehat{\\bm{c}}^{(1)}=\\boldsymbol{Q}\\boldsymbol{x}^{(1)} over^ start_ARG bold_italic_c end_ARG start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT = bold_italic_Q bold_italic_x start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT  and  c ^ ( 2 ) = Q  x ( 2 ) superscript ^ c 2 Q superscript x 2 \\widehat{\\bm{c}}^{(2)}=\\boldsymbol{Q}\\boldsymbol{x}^{(2)} over^ start_ARG bold_italic_c end_ARG start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT = bold_italic_Q bold_italic_x start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT , the following holds for any  R c  R d C , subscript R c superscript R subscript d C \\mathcal{R}_{c}\\subseteq\\mathbb{R}^{d_{\\rm C}}, caligraphic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT  roman_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT end_POSTSUPERSCRIPT , ,   k  R k R \\exists~{}k\\in\\mathbb{R}  italic_k  roman_R",
            "Although ( 6bt ) holds for any  R c subscript R c \\mathcal{R}_{c} caligraphic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT , we will see that it is sufficient to consider a special  R c subscript R c \\mathcal{R}_{c} caligraphic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT  to prove ( 6bs ). To that end, take  R c = conv  { 0 , a 1 , ... , a d C } subscript R c conv 0 subscript a 1 ... subscript a subscript d C \\mathcal{R}_{c}={\\rm conv}\\{\\boldsymbol{0},\\boldsymbol{a}_{1},\\ldots,% \\boldsymbol{a}_{d_{\\rm C}}\\} caligraphic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = roman_conv { bold_0 , bold_italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ... , bold_italic_a start_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT end_POSTSUBSCRIPT } , where  a i  R d C subscript a i superscript R subscript d C \\boldsymbol{a}_{i}\\in\\mathbb{R}^{d_{\\rm C}} bold_italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  roman_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT end_POSTSUPERSCRIPT  such that  P c ^ ( q )  [ R c ] > 0 subscript P superscript ^ c q delimited-[] subscript R c 0 \\mathbb{P}_{\\widehat{\\bm{c}}^{(q)}}[\\mathcal{R}_{c}]>0 roman_P start_POSTSUBSCRIPT over^ start_ARG bold_italic_c end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT end_POSTSUBSCRIPT [ caligraphic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ] > 0 . Let us take  y i  R d C + d P subscript y i superscript R subscript d C subscript d P \\boldsymbol{y}_{i}\\in\\mathbb{R}^{d_{\\rm C}+d_{\\rm P}} bold_italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT  roman_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT + italic_d start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT end_POSTSUPERSCRIPT , such that  H  y i = a i H subscript y i subscript a i \\boldsymbol{H}\\boldsymbol{y}_{i}=\\boldsymbol{a}_{i} bold_italic_H bold_italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = bold_italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . For reasons that will be clear later, we hope to show that",
            "We have that  Null  ( H )  R d C + d P Null H superscript R subscript d C subscript d P {\\rm Null}(\\boldsymbol{H})\\subset\\mathbb{R}^{d_{\\rm C}+d_{\\rm P}} roman_Null ( bold_italic_H )  roman_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT + italic_d start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT end_POSTSUPERSCRIPT  is a linear subspace with  dim  ( Null  ( H ) ) = d P dim Null H subscript d P {\\rm dim}({\\rm Null}(\\boldsymbol{H}))=d_{\\rm P} roman_dim ( roman_Null ( bold_italic_H ) ) = italic_d start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT . Let  A = H PreImg  ( R c ) A subscript H PreImg subscript R c \\mathcal{A}={\\boldsymbol{H}_{\\rm PreImg}(\\mathcal{R}_{c})} caligraphic_A = bold_italic_H start_POSTSUBSCRIPT roman_PreImg end_POSTSUBSCRIPT ( caligraphic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ) . Note that  P z ( 1 )  [ k  A ] = P z ( 2 )  [ k  A ] ,  k  R formulae-sequence subscript P superscript z 1 delimited-[] k A subscript P superscript z 2 delimited-[] k A for-all k R \\mathbb{P}_{\\boldsymbol{z}^{(1)}}[k\\mathcal{A}]=\\mathbb{P}_{\\boldsymbol{z}^{(2% )}}[k\\mathcal{A}],\\forall k\\in\\mathbb{R} roman_P start_POSTSUBSCRIPT bold_italic_z start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT end_POSTSUBSCRIPT [ italic_k caligraphic_A ] = roman_P start_POSTSUBSCRIPT bold_italic_z start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT end_POSTSUBSCRIPT [ italic_k caligraphic_A ] ,  italic_k  roman_R  (from ( 6bt ), and  P z ( q )  [ A ] > 0 subscript P superscript z q delimited-[] A 0 \\mathbb{P}_{\\boldsymbol{z}^{(q)}}[\\mathcal{A}]>0 roman_P start_POSTSUBSCRIPT bold_italic_z start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT end_POSTSUBSCRIPT [ caligraphic_A ] > 0  (by the construction of  R c subscript R c \\mathcal{R}_{c} caligraphic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ). Further, the set  A A \\mathcal{A} caligraphic_A  is of the form",
            "We restate the theorem here:  {mdframed} [backgroundcolor=gray!10,topline=false, rightline=false, leftline=false, bottomline=false]  Theorem   3  Assume that Assumption  1  is satisfied, that  | L |  d C L subscript d C |{\\mathcal{L}}|\\geq d_{\\rm C} | caligraphic_L |  italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT  paired samples  ( x l ( 1 ) , x l ( 2 ) ) superscript subscript x l 1 superscript subscript x l 2 (\\boldsymbol{x}_{\\ell}^{(1)},\\boldsymbol{x}_{\\ell}^{(2)}) ( bold_italic_x start_POSTSUBSCRIPT roman_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , bold_italic_x start_POSTSUBSCRIPT roman_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT )  are available, that  A ( q ) , q = 1 , 2 formulae-sequence superscript A q q 1 2 \\bm{A}^{(q)},~{}q=1,2 bold_italic_A start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT , italic_q = 1 , 2  have full column rank, and that  P c subscript P c \\mathbb{P}_{\\bm{c}} roman_P start_POSTSUBSCRIPT bold_italic_c end_POSTSUBSCRIPT  is absolutely continuous. Denote  ( Q ^ ( 1 ) , Q ^ ( 2 ) ) superscript ^ Q 1 superscript ^ Q 2 (\\widehat{\\boldsymbol{Q}}^{(1)},\\widehat{\\boldsymbol{Q}}^{(2)}) ( over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT )  as any optimal solution of ( 6 ) under the constraint ( 6i ). Then, we have  Q ^ ( q )  x ( q ) =   c superscript ^ Q q superscript x q  c \\widehat{\\boldsymbol{Q}}^{(q)}\\boldsymbol{x}^{(q)}=\\bm{\\Theta}\\bm{c} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_ bold_italic_c .  From our objective in ( 6 ), we obtain",
            "Hence we can have linear transformation  M := (  ( 1 ) )  1   ( 2 ) assign M superscript superscript  1 1 superscript  2 \\boldsymbol{M}:=(\\bm{\\Theta}^{(1)})^{-1}\\bm{\\Theta}^{(2)} bold_italic_M := ( bold_ start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT bold_ start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT  which has same probability density as  P c subscript P c \\mathbb{P}_{\\bm{c}} roman_P start_POSTSUBSCRIPT bold_italic_c end_POSTSUBSCRIPT . However, the sample matching constraint ( 6i ), for  l  limit-from l \\ell- roman_l - th sample implies that",
            "We use Adam optimizer  [ 65 ]  to solve ( 6g ) and learn matrices  Q ( q ) , q = 1 , 2 formulae-sequence superscript Q q q 1 2 \\boldsymbol{Q}^{(q)},~{}q=1,2 bold_italic_Q start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT , italic_q = 1 , 2  and the discriminator  f f f italic_f . We set the initial learning rate of matrix and discriminator to be  0.009 0.009 0.009 0.009  and  0.00008 0.00008 0.00008 0.00008  respectively. We set the   = 0.1  0.1 \\lambda=0.1 italic_ = 0.1  in ( 6g ) to enforce ( 6b ). For weak supervision experiment in  F , we set   = 0.01  0.01 \\beta=0.01 italic_ = 0.01  in ( 6i ). We generate total of 100,000 samples in each domain. For our experiment we set the batch size to be 1,000 and run ( 6g ) for 50 epochs. Our discriminator is a 6-layer multilayer perceptron (MLP) with hidden units { 1024, 521, 512, 256, 128, 64 } in each layer. All the layers use leaky ReLU activation functions  [ 66 ]  with a slope of 0.2 except for the last layer which has sigmoid activations. We include a label smoothing coefficient of 0.2 in the discriminator predictions as suggested in  [ 38 ] .",
            "Dataset : We use the word embeddings from the MUSE dataset ( https://github.com/facebookresearch/MUSE )  [ 21 ] . These monolingual word embedding are generated using fastText  [ 67 ]  and has dimensions of  d ( q ) = 300 superscript d q 300 d^{(q)}=300 italic_d start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = 300  for  q = 1 , 2 q 1 2 q=1,2 italic_q = 1 , 2 . The training dataset include 200,000 word embeddings in each language. In our experiment we set  d C = 256 subscript d C 256 d_{\\rm C}=256 italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT = 256 . We follow the generative model under ( 6h ) and run the formulation in ( 6g ) to learn the linear transformation  Q Q \\boldsymbol{Q} bold_italic_Q .",
            "Table.  6  shows the P@5 and P@10 scores. Similar results are observed.",
            "Baselines and Training Setup : The baselines are representative DA methods, namely,  DANN   [ 25 ] ,  ADDA [ 56 ] ,  DAN [ 24 ] ,  JAN [ 50 ]  , CDAN [ 57 ] ,  MDD [ 58 ] , and  MCC [ 59 ] . We use the baseline implementations from the  https://github.com/thuml/Transfer-Learning-Library . In all the baselines except for CLIP, the classifier is jointly optimized with their feature extractors, which arguably regularizes towards more classification-friendly geometry of the shared features; see  [ 68 ,  69 ] . Following their training strategy, we also append a cross-entropy (CE) based classifier training module to our loss in ( 6g ) (which learns our feature extractor  Q Q \\bm{Q} bold_italic_Q ). The CE part uses  Q  x ( 1 ) Q superscript x 1 \\bm{Q}\\bm{x}^{(1)} bold_italic_Q bold_italic_x start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT  and the labels of the sources as inputs to learn the classifier, i.e.,",
            "Fig.  6  shows the 2-dimensional visualization of the CLIP-learned features ( d = 256 d 256 d=256 italic_d = 256 ) from two domains, namely, DSLR and Amazon images ( Office-31 ), using t-SNE. One can see that CLIP could roughly group the same classes from the two domains together. But the proposed method can further pull the circles and the triangle markers togethermeaning that the  Q Q \\bm{Q} bold_italic_Q  really learns shared representations of the same data in the DSLR and Amazon domains.",
            "where, first two term are adversarial loss for distribution matching. The constraint on ( 6erd ) and ( 6ere ) are enforced as  R  ( Q C ( q ) ) R superscript subscript Q C q {\\cal R}({\\boldsymbol{Q}_{\\rm C}}^{(q)}) caligraphic_R ( bold_italic_Q start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT )  and  R  ( Q C ( q ) ) R superscript subscript Q C q {\\cal R}({\\boldsymbol{Q}_{\\rm C}}^{(q)}) caligraphic_R ( bold_italic_Q start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT )  respectively, where  R  ( Q ( q ) ) =  Q ( q )  E  [ x ( q )  ( x ( q ) )  ]  ( Q ( q ) )   I  F 2 R superscript Q q subscript superscript norm superscript Q q E delimited-[] superscript x q superscript superscript x q top superscript superscript Q q top I 2 F {\\cal R}({\\boldsymbol{Q}}^{(q)})=\\|{\\boldsymbol{Q}}^{(q)}\\mathbb{E}[{% \\boldsymbol{x}}^{(q)}({\\boldsymbol{x}}^{(q)})^{\\top}]({\\boldsymbol{Q}}^{(q)})^% {\\top}-\\bm{I}\\|^{2}_{\\rm F} caligraphic_R ( bold_italic_Q start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT ) =  bold_italic_Q start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT roman_E [ bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT ( bold_italic_x start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ] ( bold_italic_Q start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT - bold_italic_I  start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_F end_POSTSUBSCRIPT . The constraint on ( 6erc ) is realized with Hilbert-Schmidt Independence Criterion (HSIC)  [ 71 ] . HSIC measures the independence between two distribution. So, we minimize HSIC between estimated shared component and estimated private component to promote independence between shared and private components.",
            "Assumption  1  and assumptions in Theorem  1  are satisfied, and ( 6er ) is solved yielding solutions  Q ^ C ( q ) subscript superscript ^ Q q C \\widehat{\\boldsymbol{Q}}^{(q)}_{\\rm C} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT  and  Q ^ P ( q ) subscript superscript ^ Q q P \\widehat{\\boldsymbol{Q}}^{(q)}_{\\rm P} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT",
            "Assumption  2  is satisfied and has same mixing matrix  A ( q ) = A superscript A q A \\boldsymbol{A}^{(q)}=\\boldsymbol{A} bold_italic_A start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_italic_A  and ( 6er ) with  Q P ( q ) = Q P superscript subscript Q P q subscript Q P \\boldsymbol{Q}_{\\rm P}^{(q)}=\\boldsymbol{Q}_{\\rm P} bold_italic_Q start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_italic_Q start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT  and  Q C ( q ) = Q C superscript subscript Q C q subscript Q C \\boldsymbol{Q}_{\\rm C}^{(q)}=\\boldsymbol{Q}_{\\rm C} bold_italic_Q start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_italic_Q start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT  is solved yielding  Q ^ C ( q ) subscript superscript ^ Q q C \\widehat{\\boldsymbol{Q}}^{(q)}_{\\rm C} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT  and  Q ^ P ( q ) subscript superscript ^ Q q P \\widehat{\\boldsymbol{Q}}^{(q)}_{\\rm P} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT  as the solutions.",
            "Assumption  1  is satisfied and  d C subscript d C d_{\\rm C} italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT  paired samples  ( x l ( 1 ) , x l ( 2 ) ) superscript subscript x l 1 superscript subscript x l 2 (\\boldsymbol{x}_{\\ell}^{(1)},\\boldsymbol{x}_{\\ell}^{(2)}) ( bold_italic_x start_POSTSUBSCRIPT roman_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , bold_italic_x start_POSTSUBSCRIPT roman_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT )  are available (weak supervision), and denote  Q ^ C ( q ) subscript superscript ^ Q q C \\widehat{\\boldsymbol{Q}}^{(q)}_{\\rm C} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT  and  Q ^ P ( q ) subscript superscript ^ Q q P \\widehat{\\boldsymbol{Q}}^{(q)}_{\\rm P} over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT  as the solutions after solving ( 6er ).",
            "For each case in Theorem.  6  (i) - (iii), we can prove",
            "where  H ( q ) = Q ^ P ( q )  A ( q )  R d P ( q )  ( d C + d P ( q ) ) superscript H q subscript superscript ^ Q q P superscript A q superscript R superscript subscript d P q subscript d C superscript subscript d P q \\boldsymbol{H}^{(q)}=\\widehat{\\boldsymbol{Q}}^{(q)}_{\\rm P}\\boldsymbol{A}^{(q)% }\\in\\mathbb{R}^{d_{\\rm P}^{(q)}\\times(d_{\\rm C}+d_{\\rm P}^{(q)})} bold_italic_H start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = over^ start_ARG bold_italic_Q end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT bold_italic_A start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  roman_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  ( italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT + italic_d start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT ) end_POSTSUPERSCRIPT . Note that the constraint ( 6erc ) implies that the mutual information between  p ^ ( q ) superscript ^ p q \\widehat{\\bm{p}}^{(q)} over^ start_ARG bold_italic_p end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  and  c ^ ( q ) superscript ^ c q \\widehat{\\bm{c}}^{(q)} over^ start_ARG bold_italic_c end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  is zero, i.e.,",
            "Therefore  p ^ ( q ) = H ( q ) [ d C + 1 : d C + d P ( q ) ] p ( q ) =  ( q ) p ( q ) ,  q \\widehat{\\boldsymbol{p}}^{(q)}=\\boldsymbol{H}^{(q)}[d_{\\rm C}+1:d_{\\rm C}+d_{% \\rm P}^{(q)}]\\boldsymbol{p}^{(q)}=\\bm{\\Xi}^{(q)}\\boldsymbol{p}^{(q)},\\forall q over^ start_ARG bold_italic_p end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_italic_H start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT [ italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT + 1 : italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT + italic_d start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT ] bold_italic_p start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_ start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT bold_italic_p start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT ,  italic_q , where   ( q ) = H ( q ) [ d C + 1 : d C + d P ( q ) ] \\bm{\\Xi}^{(q)}=\\boldsymbol{H}^{(q)}[d_{\\rm C}+1:d_{\\rm C}+d_{\\rm P}^{(q)}] bold_ start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT = bold_italic_H start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT [ italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT + 1 : italic_d start_POSTSUBSCRIPT roman_C end_POSTSUBSCRIPT + italic_d start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT ] . Note that  H ( q ) superscript H q \\boldsymbol{H}^{(q)} bold_italic_H start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  is full row-rank because of constraint ( 6ere ). This implies that   ( q ) , q = 1 , 2 formulae-sequence superscript  q q 1 2 \\bm{\\Xi}^{(q)},q=1,2 bold_ start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT , italic_q = 1 , 2  are invertible matrices.",
            "Fig.  7  presents numerical validation for Theorem  6 .",
            "Fig.  7  shows the result for proposed method for private component identification. The first column shows the data domain, the second column shows the true and extracted shared component, and the third and fourth columns shows the true and extracted private components. Especially, the last row of the third and fourth columns shows the plot of ground truth  p ( q ) superscript p q \\bm{p}^{(q)} bold_italic_p start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  on  x  limit-from x x- italic_x - axis and  p ^ ( q ) superscript ^ p q \\widehat{\\bm{p}}^{(q)} over^ start_ARG bold_italic_p end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  on the y-axis. The plot is approximately a straight line which indicates that the estimated private components  p ^ ( q ) superscript ^ p q \\widehat{p}^{(q)} over^ start_ARG italic_p end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  are scaled version (i.e., invertible linear transformations) of ground truth private components. This verifies our Theorem  6 ."
        ]
    },
    "id_table_7": {
        "caption": "Table 7 :  Hyperparameter settings for domain adaptation.",
        "table": "A8.EGx7",
        "footnotes": [],
        "references": [
            "The domain adaptation task follows the hyperparameter settings described in Table.  7 .",
            "Fig.  7  presents numerical validation for Theorem  6 .",
            "Fig.  7  shows the result for proposed method for private component identification. The first column shows the data domain, the second column shows the true and extracted shared component, and the third and fourth columns shows the true and extracted private components. Especially, the last row of the third and fourth columns shows the plot of ground truth  p ( q ) superscript p q \\bm{p}^{(q)} bold_italic_p start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  on  x  limit-from x x- italic_x - axis and  p ^ ( q ) superscript ^ p q \\widehat{\\bm{p}}^{(q)} over^ start_ARG bold_italic_p end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  on the y-axis. The plot is approximately a straight line which indicates that the estimated private components  p ^ ( q ) superscript ^ p q \\widehat{p}^{(q)} over^ start_ARG italic_p end_ARG start_POSTSUPERSCRIPT ( italic_q ) end_POSTSUPERSCRIPT  are scaled version (i.e., invertible linear transformations) of ground truth private components. This verifies our Theorem  6 ."
        ]
    },
    "id_table_8": {
        "caption": "Table 8 :  Hyperparameter settings for single-cell sequence analysis.",
        "table": "A8.EGx8",
        "footnotes": [],
        "references": [
            "The hyperparameter settings for single-cell sequence analysis is presented in Table.  8 ."
        ]
    },
    "id_table_9": {
        "caption": "",
        "table": "A8.EGx9",
        "footnotes": [],
        "references": []
    },
    "id_table_10": {
        "caption": "",
        "table": "S6.T1.8.1",
        "footnotes": [],
        "references": []
    },
    "id_table_11": {
        "caption": "",
        "table": "S6.T2.8.1",
        "footnotes": [],
        "references": []
    },
    "id_table_12": {
        "caption": "",
        "table": "A1.T3.6",
        "footnotes": [],
        "references": []
    },
    "id_table_13": {
        "caption": "",
        "table": "A8.EGx10",
        "footnotes": [],
        "references": []
    },
    "id_table_14": {
        "caption": "",
        "table": "A8.EGx11",
        "footnotes": [],
        "references": []
    },
    "id_table_15": {
        "caption": "",
        "table": "A8.EGx12",
        "footnotes": [],
        "references": []
    },
    "id_table_16": {
        "caption": "",
        "table": "A8.EGx13",
        "footnotes": [],
        "references": []
    },
    "id_table_17": {
        "caption": "",
        "table": "A8.EGx14",
        "footnotes": [],
        "references": []
    },
    "id_table_18": {
        "caption": "",
        "table": "A8.EGx15",
        "footnotes": [],
        "references": []
    },
    "id_table_19": {
        "caption": "",
        "table": "A8.EGx16",
        "footnotes": [],
        "references": []
    },
    "id_table_20": {
        "caption": "",
        "table": "A8.EGx17",
        "footnotes": [],
        "references": []
    },
    "id_table_21": {
        "caption": "",
        "table": "A8.EGx18",
        "footnotes": [],
        "references": []
    },
    "id_table_22": {
        "caption": "",
        "table": "A8.EGx19",
        "footnotes": [],
        "references": []
    },
    "id_table_23": {
        "caption": "",
        "table": "A8.EGx20",
        "footnotes": [],
        "references": []
    },
    "id_table_24": {
        "caption": "",
        "table": "A8.EGx21",
        "footnotes": [],
        "references": []
    },
    "id_table_25": {
        "caption": "",
        "table": "A8.EGx22",
        "footnotes": [],
        "references": []
    },
    "id_table_26": {
        "caption": "",
        "table": "A8.EGx23",
        "footnotes": [],
        "references": []
    },
    "id_table_27": {
        "caption": "",
        "table": "A8.EGx24",
        "footnotes": [],
        "references": []
    },
    "id_table_28": {
        "caption": "",
        "table": "A8.EGx25",
        "footnotes": [],
        "references": []
    },
    "id_table_29": {
        "caption": "",
        "table": "A8.EGx26",
        "footnotes": [],
        "references": []
    },
    "id_table_30": {
        "caption": "",
        "table": "A8.EGx27",
        "footnotes": [],
        "references": []
    },
    "id_table_31": {
        "caption": "",
        "table": "A8.EGx28",
        "footnotes": [],
        "references": []
    },
    "id_table_32": {
        "caption": "",
        "table": "A8.EGx29",
        "footnotes": [],
        "references": []
    },
    "id_table_33": {
        "caption": "",
        "table": "A8.EGx30",
        "footnotes": [],
        "references": []
    },
    "id_table_34": {
        "caption": "",
        "table": "A8.EGx31",
        "footnotes": [],
        "references": []
    },
    "id_table_35": {
        "caption": "",
        "table": "A8.EGx32",
        "footnotes": [],
        "references": []
    },
    "id_table_36": {
        "caption": "",
        "table": "A8.EGx33",
        "footnotes": [],
        "references": []
    },
    "id_table_37": {
        "caption": "",
        "table": "A8.EGx34",
        "footnotes": [],
        "references": []
    },
    "id_table_38": {
        "caption": "",
        "table": "A8.EGx35",
        "footnotes": [],
        "references": []
    },
    "id_table_39": {
        "caption": "",
        "table": "A8.EGx36",
        "footnotes": [],
        "references": []
    },
    "id_table_40": {
        "caption": "",
        "table": "A8.EGx37",
        "footnotes": [],
        "references": []
    },
    "id_table_41": {
        "caption": "",
        "table": "A8.EGx38",
        "footnotes": [],
        "references": []
    },
    "id_table_42": {
        "caption": "",
        "table": "A8.EGx39",
        "footnotes": [],
        "references": []
    },
    "id_table_43": {
        "caption": "",
        "table": "A7.T4.6",
        "footnotes": [
            "",
            ""
        ],
        "references": []
    },
    "id_table_44": {
        "caption": "",
        "table": "A7.T5.6.1",
        "footnotes": [],
        "references": []
    },
    "id_table_45": {
        "caption": "",
        "table": "A7.T6.6",
        "footnotes": [],
        "references": []
    },
    "id_table_46": {
        "caption": "",
        "table": "A7.T7.6",
        "footnotes": [
            "",
            ""
        ],
        "references": []
    },
    "id_table_47": {
        "caption": "",
        "table": "A8.EGx40",
        "footnotes": [],
        "references": []
    },
    "id_table_48": {
        "caption": "",
        "table": "A7.T8.6",
        "footnotes": [
            "",
            ""
        ],
        "references": []
    },
    "id_table_49": {
        "caption": "",
        "table": "S3.E6.148",
        "footnotes": [],
        "references": []
    },
    "id_table_50": {
        "caption": "",
        "table": "A8.EGx42",
        "footnotes": [],
        "references": []
    },
    "id_table_51": {
        "caption": "",
        "table": "A8.EGx43",
        "footnotes": [],
        "references": []
    },
    "id_table_52": {
        "caption": "",
        "table": "A8.EGx44",
        "footnotes": [],
        "references": []
    },
    "id_table_53": {
        "caption": "",
        "table": "A8.EGx45",
        "footnotes": [],
        "references": []
    }
}