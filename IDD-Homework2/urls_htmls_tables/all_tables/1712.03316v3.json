{
    "S3.T1": {
        "caption": "Table 1: This table shows the statistics of our proposed dataset in a variety of question types, objects and scene configurations.",
        "table": "<table id=\"S3.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\" colspan=\"3\">\n<span id=\"S3.T1.1.1.1.1.1\" class=\"ltx_text\">Interactive Question Answering Dataset</span> Statistics</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.2.1.1\" class=\"ltx_td ltx_border_l ltx_border_r ltx_border_t\"></td>\n<td id=\"S3.T1.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Train</td>\n<td id=\"S3.T1.1.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Test</td>\n</tr>\n<tr id=\"S3.T1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Existence</td>\n<td id=\"S3.T1.1.3.2.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">25,600</td>\n<td id=\"S3.T1.1.3.2.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">640</td>\n</tr>\n<tr id=\"S3.T1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r\">Counting</td>\n<td id=\"S3.T1.1.4.3.2\" class=\"ltx_td ltx_align_left ltx_border_r\">25,600</td>\n<td id=\"S3.T1.1.4.3.3\" class=\"ltx_td ltx_align_left ltx_border_r\">640</td>\n</tr>\n<tr id=\"S3.T1.1.5.4\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r\">Spatial Relationships</td>\n<td id=\"S3.T1.1.5.4.2\" class=\"ltx_td ltx_align_left ltx_border_r\">25,600</td>\n<td id=\"S3.T1.1.5.4.3\" class=\"ltx_td ltx_align_left ltx_border_r\">640</td>\n</tr>\n<tr id=\"S3.T1.1.6.5\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r\">Rooms</td>\n<td id=\"S3.T1.1.6.5.2\" class=\"ltx_td ltx_align_left ltx_border_r\">25</td>\n<td id=\"S3.T1.1.6.5.3\" class=\"ltx_td ltx_align_left ltx_border_r\">5</td>\n</tr>\n<tr id=\"S3.T1.1.7.6\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.7.6.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r\">Total scene configurations (s.c.)</td>\n<td id=\"S3.T1.1.7.6.2\" class=\"ltx_td ltx_align_left ltx_border_r\">76,800</td>\n<td id=\"S3.T1.1.7.6.3\" class=\"ltx_td ltx_align_left ltx_border_r\">1,920</td>\n</tr>\n<tr id=\"S3.T1.1.8.7\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.8.7.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r\">Avg # objects per (s.c.)</td>\n<td id=\"S3.T1.1.8.7.2\" class=\"ltx_td ltx_align_left ltx_border_r\">46</td>\n<td id=\"S3.T1.1.8.7.3\" class=\"ltx_td ltx_align_left ltx_border_r\">41</td>\n</tr>\n<tr id=\"S3.T1.1.9.8\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.9.8.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r\">Avg # interactable objects (s.c.)</td>\n<td id=\"S3.T1.1.9.8.2\" class=\"ltx_td ltx_align_left ltx_border_r\">21</td>\n<td id=\"S3.T1.1.9.8.3\" class=\"ltx_td ltx_align_left ltx_border_r\">16</td>\n</tr>\n<tr id=\"S3.T1.1.10.9\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.10.9.1\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r\">Vocabulary Size</td>\n<td id=\"S3.T1.1.10.9.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\">70</td>\n<td id=\"S3.T1.1.10.9.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\">70</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "iquad v1 is a question answering dataset built upon AI2-THOR [35]. It consists of over 75,000 multiple choice questions for three different question types (table 1 shows more detailed statistics). Each question is accompanied by a scene identifier and a unique arrangement of movable objects in the scene. Figure 1 shows three such examples. The wide variety of configurations in iquad v1 prevent models from memorizing simple rules like “apples are always in the fridge” and render this dataset challenging. iquad v1 consists of several question types including: Existence questions (Is there an apple in the kitchen?), Counting questions (How many forks are present in the scene?),\nand Spatial Relationship questions (Is there lettuce in the fridge? / Is there a cup on the counter-top?). Questions, ground truth answers, and answer choices are generated automatically. Since natural language understanding is not a focus of this dataset, questions are generated using a set of templates written down a priori. Extending iquad v1 to include more diverse questions generated by humans is future work. iquad v1 is a balanced dataset that prevents models from obtaining high accuracies by simply exploiting trivial language and scene configuration biases. Similar to past balanced VQA datasets [15], each question is associated with multiple scene configurations that result in different answers to the question. We split the 30 kitchen rooms into 25 train and 5 test, and have 1024 unique (question, scene configuration) pairs for each (room, question type) pair in train, and 128 in test. An episode is finished when the Answerer is invoked. We evaluate different methods using Top-1 accuracy."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: This tables compares the test accuracy and episode lengths of question answering across different models and question types.",
        "table": "<table id=\"S4.T2.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\"></th>\n<td id=\"S4.T2.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" colspan=\"2\">Existence</td>\n<td id=\"S4.T2.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" colspan=\"2\">Counting</td>\n<td id=\"S4.T2.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" colspan=\"2\">Spatial Relationships</td>\n</tr>\n<tr id=\"S4.T2.1.1.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">Model</th>\n<td id=\"S4.T2.1.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Accuracy</td>\n<td id=\"S4.T2.1.1.2.2.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Length</td>\n<td id=\"S4.T2.1.1.2.2.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Accuracy</td>\n<td id=\"S4.T2.1.1.2.2.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Length</td>\n<td id=\"S4.T2.1.1.2.2.6\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Accuracy</td>\n<td id=\"S4.T2.1.1.2.2.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Length</td>\n</tr>\n<tr id=\"S4.T2.1.1.3.3\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">Most Likely Answer Per Q-type (MLA)</th>\n<td id=\"S4.T2.1.1.3.3.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">50</td>\n<td id=\"S4.T2.1.1.3.3.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">-</td>\n<td id=\"S4.T2.1.1.3.3.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">25</td>\n<td id=\"S4.T2.1.1.3.3.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">-</td>\n<td id=\"S4.T2.1.1.3.3.6\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">50</td>\n<td id=\"S4.T2.1.1.3.3.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">-</td>\n</tr>\n<tr id=\"S4.T2.1.1.4.4\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr\">A3C with ground truth (GT) detections</th>\n<td id=\"S4.T2.1.1.4.4.2\" class=\"ltx_td ltx_align_left ltx_border_r\">48.59</td>\n<td id=\"S4.T2.1.1.4.4.3\" class=\"ltx_td ltx_align_left ltx_border_r\">332.41</td>\n<td id=\"S4.T2.1.1.4.4.4\" class=\"ltx_td ltx_align_left ltx_border_r\">24.53</td>\n<td id=\"S4.T2.1.1.4.4.5\" class=\"ltx_td ltx_align_left ltx_border_r\">998.32</td>\n<td id=\"S4.T2.1.1.4.4.6\" class=\"ltx_td ltx_align_left ltx_border_r\">49.84</td>\n<td id=\"S4.T2.1.1.4.4.7\" class=\"ltx_td ltx_align_left ltx_border_r\">578.71</td>\n</tr>\n<tr id=\"S4.T2.1.1.5.5\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr\">HIMN with YOLO <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib56\" title=\"\" class=\"ltx_ref\">56</a>]</cite> detections</th>\n<td id=\"S4.T2.1.1.5.5.2\" class=\"ltx_td ltx_align_left ltx_border_r\"><span id=\"S4.T2.1.1.5.5.2.1\" class=\"ltx_text ltx_font_bold\">68.47</span></td>\n<td id=\"S4.T2.1.1.5.5.3\" class=\"ltx_td ltx_align_left ltx_border_r\">318.33</td>\n<td id=\"S4.T2.1.1.5.5.4\" class=\"ltx_td ltx_align_left ltx_border_r\"><span id=\"S4.T2.1.1.5.5.4.1\" class=\"ltx_text ltx_font_bold\">30.43</span></td>\n<td id=\"S4.T2.1.1.5.5.5\" class=\"ltx_td ltx_align_left ltx_border_r\">926.11</td>\n<td id=\"S4.T2.1.1.5.5.6\" class=\"ltx_td ltx_align_left ltx_border_r\"><span id=\"S4.T2.1.1.5.5.6.1\" class=\"ltx_text ltx_font_bold\">58.67</span></td>\n<td id=\"S4.T2.1.1.5.5.7\" class=\"ltx_td ltx_align_left ltx_border_r\">516.23</td>\n</tr>\n<tr id=\"S4.T2.1.1.6.6\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_rr\">Human (small sample)</th>\n<td id=\"S4.T2.1.1.6.6.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\">90</td>\n<td id=\"S4.T2.1.1.6.6.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\">58.40</td>\n<td id=\"S4.T2.1.1.6.6.4\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\">80</td>\n<td id=\"S4.T2.1.1.6.6.5\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\">81.90</td>\n<td id=\"S4.T2.1.1.6.6.6\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\">90</td>\n<td id=\"S4.T2.1.1.6.6.7\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\">43.00</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "Table 2 shows the test accuracies and the average episode lengths for the proposed himn model and baselines for each question type. himn significantly outperforms the baselines on all question types, both with YOLO object detections as well as ground truth object detections. Surprisingly, the A3C baseline performs slightly worse than random chance even with ground truth detections. We conjecture that this is because there is no explicit signal for when to answer, and no persistence of object detections. The A3C model is not able to associate object detections with the question, and thus has no reason to remember detections for long periods of time. Because himn does not overwrite its entire spatial memory at each timestep, object detections persist for much longer, and the Answerer can better learn the associations between the questions and the objects. himn further benefits from a spatial memory in counting and spatial relationship questions because these require much more spatial reasoning than existence questions. Additionally, because A3C does not learn to answer questions, it also does not learn to efficiently explore the environments, as most of the reward comes from answering questions correctly. himn, on the other hand, traverses much more of the environment, only answering when it is confident that it has sufficiently explored the room. This indicates that himn (which uses an explicit semantic spatial memory with egocentric updates) is more effective than A3C (which uses a standard fully-connected GRU) at (a) Estimating when the environment has been sufficiently explored, given the question (b) Keeping track of past observations for much longer durations, which is important in determining answers for questions that require a thorough search of the environment, and (c) Keeping track of multiple object instances in the scene, which may be observed several time steps apart (which is crucial for answering counting questions).",
            "Although himn performs quite well, it still has several obvious limitations. Due to the 2D nature of the semantic spatial map, himn is unable to differentiate between an object being inside a container and being on top of the container. Two obvious extensions of himn are storing an explicit height parameter or using multiple 2D slices to construct a 3D map. Secondly, as can be seen in the human experiments in table 2, himn is still fairly inefficient at exploring the environment. We plan on investigating more traditional planning algorithms to reduce the time spent exploring previously searched areas. Finally, our templated language model is quite simple, and would not extend to arbitrary questions. We plan on extending iquad to include more varied questions, and we will use more expressive language embeddings like [45, 55] in future work."
        ]
    },
    "S4.T3": {
        "caption": "Table 3: Ablation experiments on the himn model.",
        "table": "<table id=\"S4.T3.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T3.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\"></th>\n<th id=\"S4.T3.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\" colspan=\"2\">Existence</th>\n<th id=\"S4.T3.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\" colspan=\"2\">Counting</th>\n<th id=\"S4.T3.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\" colspan=\"2\">Spatial Relationships</th>\n</tr>\n<tr id=\"S4.T3.1.1.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">Model</th>\n<th id=\"S4.T3.1.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\">Accuracy</th>\n<th id=\"S4.T3.1.1.2.2.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\">Length</th>\n<th id=\"S4.T3.1.1.2.2.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\">Accuracy</th>\n<th id=\"S4.T3.1.1.2.2.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\">Length</th>\n<th id=\"S4.T3.1.1.2.2.6\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\">Accuracy</th>\n<th id=\"S4.T3.1.1.2.2.7\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\">Length</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.1.1.3.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">HIMN with YOLO <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib56\" title=\"\" class=\"ltx_ref\">56</a>]</cite> detections</th>\n<td id=\"S4.T3.1.1.3.1.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">68.47</td>\n<td id=\"S4.T3.1.1.3.1.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">318.33</td>\n<td id=\"S4.T3.1.1.3.1.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">30.43</td>\n<td id=\"S4.T3.1.1.3.1.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">926.11</td>\n<td id=\"S4.T3.1.1.3.1.6\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">58.67</td>\n<td id=\"S4.T3.1.1.3.1.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">516.23</td>\n</tr>\n<tr id=\"S4.T3.1.1.4.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr\">HIMN with GT detection</th>\n<td id=\"S4.T3.1.1.4.2.2\" class=\"ltx_td ltx_align_left ltx_border_r\">86.56</td>\n<td id=\"S4.T3.1.1.4.2.3\" class=\"ltx_td ltx_align_left ltx_border_r\">679.70</td>\n<td id=\"S4.T3.1.1.4.2.4\" class=\"ltx_td ltx_align_left ltx_border_r\">35.31</td>\n<td id=\"S4.T3.1.1.4.2.5\" class=\"ltx_td ltx_align_left ltx_border_r\">604.79</td>\n<td id=\"S4.T3.1.1.4.2.6\" class=\"ltx_td ltx_align_left ltx_border_r\">70.94</td>\n<td id=\"S4.T3.1.1.4.2.7\" class=\"ltx_td ltx_align_left ltx_border_r\">311.03</td>\n</tr>\n<tr id=\"S4.T3.1.1.5.3\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.5.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr\">HIMN with GT detection and oracle navigator (HIMN-GT)</th>\n<td id=\"S4.T3.1.1.5.3.2\" class=\"ltx_td ltx_align_left ltx_border_r\"><span id=\"S4.T3.1.1.5.3.2.1\" class=\"ltx_text ltx_font_bold\">88.60</span></td>\n<td id=\"S4.T3.1.1.5.3.3\" class=\"ltx_td ltx_align_left ltx_border_r\">618.63</td>\n<td id=\"S4.T3.1.1.5.3.4\" class=\"ltx_td ltx_align_left ltx_border_r\"><span id=\"S4.T3.1.1.5.3.4.1\" class=\"ltx_text ltx_font_bold\">48.44</span></td>\n<td id=\"S4.T3.1.1.5.3.5\" class=\"ltx_td ltx_align_left ltx_border_r\">871.12</td>\n<td id=\"S4.T3.1.1.5.3.6\" class=\"ltx_td ltx_align_left ltx_border_r\"><span id=\"S4.T3.1.1.5.3.6.1\" class=\"ltx_text ltx_font_bold\">72.50</span></td>\n<td id=\"S4.T3.1.1.5.3.7\" class=\"ltx_td ltx_align_left ltx_border_r\">475.55</td>\n</tr>\n<tr id=\"S4.T3.1.1.6.4\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.6.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr\">HIMN-GT Question not given to planner</th>\n<td id=\"S4.T3.1.1.6.4.2\" class=\"ltx_td ltx_align_left ltx_border_r\">50.00</td>\n<td id=\"S4.T3.1.1.6.4.3\" class=\"ltx_td ltx_align_left ltx_border_r\">150.60</td>\n<td id=\"S4.T3.1.1.6.4.4\" class=\"ltx_td ltx_align_left ltx_border_r\">24.50</td>\n<td id=\"S4.T3.1.1.6.4.5\" class=\"ltx_td ltx_align_left ltx_border_r\">293.33</td>\n<td id=\"S4.T3.1.1.6.4.6\" class=\"ltx_td ltx_align_left ltx_border_r\">50.25</td>\n<td id=\"S4.T3.1.1.6.4.7\" class=\"ltx_td ltx_align_left ltx_border_r\">118.09</td>\n</tr>\n<tr id=\"S4.T3.1.1.7.5\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.7.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_rr\">HIMN-GT No loss on invalid actions</th>\n<td id=\"S4.T3.1.1.7.5.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\">49.84</td>\n<td id=\"S4.T3.1.1.7.5.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\">659.28</td>\n<td id=\"S4.T3.1.1.7.5.4\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\">24.84</td>\n<td id=\"S4.T3.1.1.7.5.5\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\">911.46</td>\n<td id=\"S4.T3.1.1.7.5.6\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\">50.00</td>\n<td id=\"S4.T3.1.1.7.5.7\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\">613.50</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "We perform four ablative experiments on our network structure and inputs, shown in table 3. First, we use the ground truth object detections and depth instead of YOLO [56] and FRCN depth [38]. This adds a dramatic improvement to our model owing primarily to the fact that without detection mistakes, the Answerer can be more accurate and confident. Secondly, we substitute our learned navigation controller with an oracle Navigator that takes the shortest path in the environment. When the optimal Navigator is provided, himn further improves. This is because the Planner can more accurately direct the agent through the environment, allowing it to be more efficient and more thorough at exploring the environment. It also takes fewer invalid actions (as seen in table 4), indicating that it is less likely to get stuck in parts of the room. In our third ablative experiment, we remove the question vector from the input of the Planner, only providing it to the Answerer, which results in random performance. This shows that the Planner utilizes the question to direct the agent towards different parts of the room to gather information required to answer the question. For instance any question about an object in the fridge requires the planner to know the fridge needs to be opened. If the planner is not told the question, it has no reason to open the fridge, and instead will likely choose to continue exploring the room as exploration often gives more reward than opening an object. Also, some questions can be answered soon after an object is observed (e.g. Existence), whereas others require longer explorations (e.g. Counting). Having access to the questions can clearly help the Planner in these scenarios. Tables 3 shows that himn does in fact explore the environment for longer durations for Counting questions than for Existence and Spatial Relationship questions. In our final ablation experiment, we remove the loss on invalid actions. If we do not apply any loss on these actions and only propagate gradients through the chosen action, the agent suffers from the difficulty of exploring a large action space and again performs at random chance.",
            "Table 4 shows the percentage of invalid actions taken by the different methods. Failed actions are due to navigation failures (failing to see an obstacle) or interaction failures (trying to interact with something too far away or otherwise impossible).\nThere is a clear benefit to including a loss on the invalid actions both in terms of QA accuracy, as can be seen in table 3, as well as in terms of percentage of invalid actions performed, shown in table 4. All models in table 4 are penalized for every invalid action they attempt, but this only provides feedback on a single action at every timestep. With the addition of a supervised loss on all possible actions, the percentage of invalid actions performed is nearly an order of magnitude lower. By directly training our agent to recognize affordances (valid actions), we are able to mitigate the difficulties posed by a large action space, allowing the Planner to learn much more quickly. The validity loss also serves as an auxiliary task which has been shown to aid the convergence of RL algorithms [21]. By replacing the learned Navigator with an oracle, we observe that the majority of failed actions are due to navigation failures. We believe that with a smaller step size, we would further reduce the navigation errors at the expense of longer trajectories."
        ]
    },
    "S5.T4": {
        "caption": "Table 4: This tables compares the percentage of invalid actions across different models on test. Lower is better.",
        "table": "<table id=\"S5.T4.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T4.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" colspan=\"4\">Percentage of invalid actions</th>\n</tr>\n<tr id=\"S5.T4.1.1.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">Model</th>\n<th id=\"S5.T4.1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\">Existence</th>\n<th id=\"S5.T4.1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\">Counting</th>\n<th id=\"S5.T4.1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\">Spatial Relationships</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T4.1.1.3.1\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.1.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">A3C with GT detections</th>\n<td id=\"S5.T4.1.1.3.1.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">32.75</td>\n<td id=\"S5.T4.1.1.3.1.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">34.55</td>\n<td id=\"S5.T4.1.1.3.1.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">32.63</td>\n</tr>\n<tr id=\"S5.T4.1.1.4.2\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.1.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\">HIMN No loss on invalid actions</th>\n<td id=\"S5.T4.1.1.4.2.2\" class=\"ltx_td ltx_align_left ltx_border_r\">56.27</td>\n<td id=\"S5.T4.1.1.4.2.3\" class=\"ltx_td ltx_align_left ltx_border_r\">53.43</td>\n<td id=\"S5.T4.1.1.4.2.4\" class=\"ltx_td ltx_align_left ltx_border_r\">51.93</td>\n</tr>\n<tr id=\"S5.T4.1.1.5.3\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.1.5.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\">HIMN with YOLO <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib56\" title=\"\" class=\"ltx_ref\">56</a>]</cite> detections</th>\n<td id=\"S5.T4.1.1.5.3.2\" class=\"ltx_td ltx_align_left ltx_border_r\">6.07</td>\n<td id=\"S5.T4.1.1.5.3.3\" class=\"ltx_td ltx_align_left ltx_border_r\">5.95</td>\n<td id=\"S5.T4.1.1.5.3.4\" class=\"ltx_td ltx_align_left ltx_border_r\">6.68</td>\n</tr>\n<tr id=\"S5.T4.1.1.6.4\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.1.6.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\">HIMN with GT detections</th>\n<td id=\"S5.T4.1.1.6.4.2\" class=\"ltx_td ltx_align_left ltx_border_r\">6.49</td>\n<td id=\"S5.T4.1.1.6.4.3\" class=\"ltx_td ltx_align_left ltx_border_r\">5.71</td>\n<td id=\"S5.T4.1.1.6.4.4\" class=\"ltx_td ltx_align_left ltx_border_r\">5.66</td>\n</tr>\n<tr id=\"S5.T4.1.1.7.5\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.1.7.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\">HIMN-GT</th>\n<td id=\"S5.T4.1.1.7.5.2\" class=\"ltx_td ltx_align_left ltx_border_r\"><span id=\"S5.T4.1.1.7.5.2.1\" class=\"ltx_text ltx_font_bold\">1.79</span></td>\n<td id=\"S5.T4.1.1.7.5.3\" class=\"ltx_td ltx_align_left ltx_border_r\"><span id=\"S5.T4.1.1.7.5.3.1\" class=\"ltx_text ltx_font_bold\">2.02</span></td>\n<td id=\"S5.T4.1.1.7.5.4\" class=\"ltx_td ltx_align_left ltx_border_r\"><span id=\"S5.T4.1.1.7.5.4.1\" class=\"ltx_text ltx_font_bold\">1.27</span></td>\n</tr>\n<tr id=\"S5.T4.1.1.8.6\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.1.8.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r\">Human</th>\n<td id=\"S5.T4.1.1.8.6.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\">5.99</td>\n<td id=\"S5.T4.1.1.8.6.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\">6.47</td>\n<td id=\"S5.T4.1.1.8.6.4\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\">3.49</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "We perform four ablative experiments on our network structure and inputs, shown in table 3. First, we use the ground truth object detections and depth instead of YOLO [56] and FRCN depth [38]. This adds a dramatic improvement to our model owing primarily to the fact that without detection mistakes, the Answerer can be more accurate and confident. Secondly, we substitute our learned navigation controller with an oracle Navigator that takes the shortest path in the environment. When the optimal Navigator is provided, himn further improves. This is because the Planner can more accurately direct the agent through the environment, allowing it to be more efficient and more thorough at exploring the environment. It also takes fewer invalid actions (as seen in table 4), indicating that it is less likely to get stuck in parts of the room. In our third ablative experiment, we remove the question vector from the input of the Planner, only providing it to the Answerer, which results in random performance. This shows that the Planner utilizes the question to direct the agent towards different parts of the room to gather information required to answer the question. For instance any question about an object in the fridge requires the planner to know the fridge needs to be opened. If the planner is not told the question, it has no reason to open the fridge, and instead will likely choose to continue exploring the room as exploration often gives more reward than opening an object. Also, some questions can be answered soon after an object is observed (e.g. Existence), whereas others require longer explorations (e.g. Counting). Having access to the questions can clearly help the Planner in these scenarios. Tables 3 shows that himn does in fact explore the environment for longer durations for Counting questions than for Existence and Spatial Relationship questions. In our final ablation experiment, we remove the loss on invalid actions. If we do not apply any loss on these actions and only propagate gradients through the chosen action, the agent suffers from the difficulty of exploring a large action space and again performs at random chance.",
            "Table 4 shows the percentage of invalid actions taken by the different methods. Failed actions are due to navigation failures (failing to see an obstacle) or interaction failures (trying to interact with something too far away or otherwise impossible).\nThere is a clear benefit to including a loss on the invalid actions both in terms of QA accuracy, as can be seen in table 3, as well as in terms of percentage of invalid actions performed, shown in table 4. All models in table 4 are penalized for every invalid action they attempt, but this only provides feedback on a single action at every timestep. With the addition of a supervised loss on all possible actions, the percentage of invalid actions performed is nearly an order of magnitude lower. By directly training our agent to recognize affordances (valid actions), we are able to mitigate the difficulties posed by a large action space, allowing the Planner to learn much more quickly. The validity loss also serves as an auxiliary task which has been shown to aid the convergence of RL algorithms [21]. By replacing the learned Navigator with an oracle, we observe that the majority of failed actions are due to navigation failures. We believe that with a smaller step size, we would further reduce the navigation errors at the expense of longer trajectories."
        ]
    },
    "S5.T5": {
        "caption": "Table 5: This tables compares the accuracy of question answering across different models on Seen (S) and Unseen (U) environments.",
        "table": "<table id=\"S5.T5.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T5.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T5.1.1.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\"></th>\n<th id=\"S5.T5.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\" colspan=\"2\">Existence</th>\n<th id=\"S5.T5.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\" colspan=\"2\">Counting</th>\n<th id=\"S5.T5.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\" colspan=\"2\">Spatial Relationships</th>\n</tr>\n<tr id=\"S5.T5.1.1.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T5.1.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">Model</th>\n<th id=\"S5.T5.1.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\">S</th>\n<th id=\"S5.T5.1.1.2.2.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\">U</th>\n<th id=\"S5.T5.1.1.2.2.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\">S</th>\n<th id=\"S5.T5.1.1.2.2.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\">U</th>\n<th id=\"S5.T5.1.1.2.2.6\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\">S</th>\n<th id=\"S5.T5.1.1.2.2.7\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\">U</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T5.1.1.3.1\" class=\"ltx_tr\">\n<th id=\"S5.T5.1.1.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">HIMN with YOLO <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib56\" title=\"\" class=\"ltx_ref\">56</a>]</cite> detections</th>\n<td id=\"S5.T5.1.1.3.1.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">73.68</td>\n<td id=\"S5.T5.1.1.3.1.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">68.47</td>\n<td id=\"S5.T5.1.1.3.1.4\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">36.26</td>\n<td id=\"S5.T5.1.1.3.1.5\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">30.43</td>\n<td id=\"S5.T5.1.1.3.1.6\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">60.71</td>\n<td id=\"S5.T5.1.1.3.1.7\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">58.67</td>\n</tr>\n<tr id=\"S5.T5.1.1.4.2\" class=\"ltx_tr\">\n<th id=\"S5.T5.1.1.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_rr\">HIMN with GT detections</th>\n<td id=\"S5.T5.1.1.4.2.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\">94.00</td>\n<td id=\"S5.T5.1.1.4.2.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\">86.56</td>\n<td id=\"S5.T5.1.1.4.2.4\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\">42.38</td>\n<td id=\"S5.T5.1.1.4.2.5\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\">35.31</td>\n<td id=\"S5.T5.1.1.4.2.6\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\">73.38</td>\n<td id=\"S5.T5.1.1.4.2.7\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\">70.94</td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": "",
        "references": [
            "One benefit of himn over other RL architectures is that encoding semantic information into a spatial map should generalize well in both seen and unseen environments. Thus, in table 5, we compare himn’s performance on seen and unseen environments. Unseen environments tests the agent with questions that occur in 5 never-before-seen rooms, whereas the seen environments use the 25 training rooms but never-before-seen object placements and corresponding questions. Despite our relatively small number of training rooms, table 5 shows that our method only loses up to a few percentage points of accuracy when tested on unseen environments. This contrasts with many other end-to-end RL methods which learn deep features that tend to limit their applicability outside a known domain [73, 74]. Note that all experiments in previous sections were only performed on unseen environments."
        ]
    }
}