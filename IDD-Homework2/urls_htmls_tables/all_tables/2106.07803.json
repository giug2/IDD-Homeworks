{
    "S4.T1": {
        "caption": "Table 1: WERs on the LibriSpeech.",
        "table": "<table id=\"S4.T1.3\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.3.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T1.3.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T1.3.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Model</span></td>\n<td id=\"S4.T1.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" colspan=\"2\"><span id=\"S4.T1.3.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Training sets</span></td>\n<td id=\"S4.T1.3.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"2\"><span id=\"S4.T1.3.1.1.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">WER</span></td>\n</tr>\n<tr id=\"S4.T1.3.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T1.3.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T1.3.2.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">real</span></td>\n<td id=\"S4.T1.3.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T1.3.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">synthetic</span></td>\n<td id=\"S4.T1.3.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T1.3.2.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">test-clean</span></td>\n<td id=\"S4.T1.3.2.2.4\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T1.3.2.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">test-other</span></td>\n</tr>\n<tr id=\"S4.T1.3.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T1.3.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T1.3.3.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Benchmark</span></td>\n<td id=\"S4.T1.3.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T1.3.3.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">960</span></td>\n<td id=\"S4.T1.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T1.3.3.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td id=\"S4.T1.3.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T1.3.3.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">7.29</span></td>\n<td id=\"S4.T1.3.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T1.3.3.3.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">17.41</span></td>\n</tr>\n<tr id=\"S4.T1.3.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T1.3.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T1.3.4.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Baseline</span></td>\n<td id=\"S4.T1.3.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T1.3.4.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">480</span></td>\n<td id=\"S4.T1.3.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T1.3.4.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td id=\"S4.T1.3.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T1.3.4.4.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">9.90</span></td>\n<td id=\"S4.T1.3.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T1.3.4.4.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">22.64</span></td>\n</tr>\n<tr id=\"S4.T1.3.5.5\" class=\"ltx_tr\">\n<td id=\"S4.T1.3.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S4.T1.3.5.5.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Baseline + TTS</span></td>\n<td id=\"S4.T1.3.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S4.T1.3.5.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">480</span></td>\n<td id=\"S4.T1.3.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S4.T1.3.5.5.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">1150</span></td>\n<td id=\"S4.T1.3.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S4.T1.3.5.5.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">8.66</span></td>\n<td id=\"S4.T1.3.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T1.3.5.5.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">20.78</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "LibriSpeech contains 960 hours of read speech data for training [29].\nAs an ASR baseline with a limited amount of audio data, we assume that only half of the LibriSpeech training data is available,\ni.e. 480 hours training data randomly selected from the all training data.\nAs shown in Table 1, an RNN-T model trained with 480 hours of data is 35.8% relatively worse on test-clean\nwhen compared to an RNN-T model trained with all 960 hours training data.\nWe then synthesize about 1150 hours audio data using our multi-context TTS system, and the input texts for TTS are the transcriptions of the missing 480 hours data.\nThis TTS training set contains about 48k unique input texts, and each text utterance is synthesized with randomly selected 24 voice profiles from the total of 500 available voice profiles.\nWe then trained an RNN-T model using MST combining with 480 hours real data and 1150 hours synthetic speech.\nCompared to the baseline model trained with 480 hours real data alone, this improves the performance on test-clean by 12.5% relative (Table 1)."
        ]
    },
    "S4.T2": {
        "caption": "Table 2: NWERs for the application of recognition of medication name. The weight on the left in the column Weights% is the percentage of samples in MST from real data and the weight on the right is the percentage of samples from synthetic data. (R, S) indicates whether real (R) or synthetic (S) audio is used during each stage of training.",
        "table": "<table id=\"S4.T2.9\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.9.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.9.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\" rowspan=\"2\"><span id=\"S4.T2.9.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Model</span></td>\n<td id=\"S4.T2.9.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span id=\"S4.T2.9.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Real Data</span></td>\n<td id=\"S4.T2.9.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span id=\"S4.T2.9.1.1.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Synthetic Data</span></td>\n<td id=\"S4.T2.9.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span id=\"S4.T2.9.1.1.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Weights%</span></td>\n<td id=\"S4.T2.9.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span id=\"S4.T2.9.1.1.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Freeze</span></td>\n<td id=\"S4.T2.9.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span id=\"S4.T2.9.1.1.6.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Elastic</span></td>\n<td id=\"S4.T2.9.1.1.7\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"3\"><span id=\"S4.T2.9.1.1.7.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">NWER</span></td>\n</tr>\n<tr id=\"S4.T2.9.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.9.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T2.9.2.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">(hours)</span></td>\n<td id=\"S4.T2.9.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T2.9.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">(hours)</span></td>\n<td id=\"S4.T2.9.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T2.9.2.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">(R, S)</span></td>\n<td id=\"S4.T2.9.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T2.9.2.2.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Encoder</span></td>\n<td id=\"S4.T2.9.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T2.9.2.2.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Penalty</span></td>\n<td id=\"S4.T2.9.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T2.9.2.2.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">Dev-Gen</span></td>\n<td id=\"S4.T2.9.2.2.7\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T2.9.2.2.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">Eval-Gen</span></td>\n<td id=\"S4.T2.9.2.2.8\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.9.2.2.8.1\" class=\"ltx_text\" style=\"font-size:90%;\">Eval-Med</span></td>\n</tr>\n<tr id=\"S4.T2.9.3.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.9.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T2.9.3.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Baseline</span></td>\n<td id=\"S4.T2.9.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T2.9.3.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">50K</span></td>\n<td id=\"S4.T2.9.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T2.9.3.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td id=\"S4.T2.9.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T2.9.3.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td id=\"S4.T2.9.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T2.9.3.3.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">No</span></td>\n<td id=\"S4.T2.9.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T2.9.3.3.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td id=\"S4.T2.9.3.3.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T2.9.3.3.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">100</span></td>\n<td id=\"S4.T2.9.3.3.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T2.9.3.3.8.1\" class=\"ltx_text\" style=\"font-size:90%;\">100</span></td>\n<td id=\"S4.T2.9.3.3.9\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.9.3.3.9.1\" class=\"ltx_text\" style=\"font-size:90%;\">100</span></td>\n</tr>\n<tr id=\"S4.T2.9.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T2.9.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T2.9.4.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Stage 1</span></td>\n<td id=\"S4.T2.9.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T2.9.4.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">50K</span></td>\n<td id=\"S4.T2.9.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T2.9.4.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">5k</span></td>\n<td id=\"S4.T2.9.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T2.9.4.4.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">(95, 5)</span></td>\n<td id=\"S4.T2.9.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T2.9.4.4.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">Yes</span></td>\n<td id=\"S4.T2.9.4.4.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T2.9.4.4.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">No</span></td>\n<td id=\"S4.T2.9.4.4.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T2.9.4.4.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">100.99</span></td>\n<td id=\"S4.T2.9.4.4.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T2.9.4.4.8.1\" class=\"ltx_text\" style=\"font-size:90%;\">101.32</span></td>\n<td id=\"S4.T2.9.4.4.9\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.9.4.4.9.1\" class=\"ltx_text\" style=\"font-size:90%;\">21.06</span></td>\n</tr>\n<tr id=\"S4.T2.9.5.5\" class=\"ltx_tr\">\n<td id=\"S4.T2.9.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T2.9.5.5.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Stage 2</span></td>\n<td id=\"S4.T2.9.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T2.9.5.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">50K</span></td>\n<td id=\"S4.T2.9.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T2.9.5.5.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">5k</span></td>\n<td id=\"S4.T2.9.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T2.9.5.5.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">(98, 2)</span></td>\n<td id=\"S4.T2.9.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T2.9.5.5.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">No</span></td>\n<td id=\"S4.T2.9.5.5.6\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T2.9.5.5.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">No</span></td>\n<td id=\"S4.T2.9.5.5.7\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T2.9.5.5.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">100.54</span></td>\n<td id=\"S4.T2.9.5.5.8\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T2.9.5.5.8.1\" class=\"ltx_text\" style=\"font-size:90%;\">100.98</span></td>\n<td id=\"S4.T2.9.5.5.9\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.9.5.5.9.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">13.70</span></td>\n</tr>\n<tr id=\"S4.T2.9.6.6\" class=\"ltx_tr\">\n<td id=\"S4.T2.9.6.6.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T2.9.6.6.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Stage 3</span></td>\n<td id=\"S4.T2.9.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T2.9.6.6.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">50K</span></td>\n<td id=\"S4.T2.9.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T2.9.6.6.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td id=\"S4.T2.9.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T2.9.6.6.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td id=\"S4.T2.9.6.6.5\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T2.9.6.6.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">No</span></td>\n<td id=\"S4.T2.9.6.6.6\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T2.9.6.6.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">Yes</span></td>\n<td id=\"S4.T2.9.6.6.7\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T2.9.6.6.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">100.14</span></td>\n<td id=\"S4.T2.9.6.6.8\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T2.9.6.6.8.1\" class=\"ltx_text\" style=\"font-size:90%;\">100.89</span></td>\n<td id=\"S4.T2.9.6.6.9\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.9.6.6.9.1\" class=\"ltx_text\" style=\"font-size:90%;\">21.47</span></td>\n</tr>\n<tr id=\"S4.T2.9.7.7\" class=\"ltx_tr\">\n<td id=\"S4.T2.9.7.7.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S4.T2.9.7.7.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Stage 4</span></td>\n<td id=\"S4.T2.9.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S4.T2.9.7.7.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">50K</span></td>\n<td id=\"S4.T2.9.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S4.T2.9.7.7.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td id=\"S4.T2.9.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S4.T2.9.7.7.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td id=\"S4.T2.9.7.7.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S4.T2.9.7.7.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">No</span></td>\n<td id=\"S4.T2.9.7.7.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S4.T2.9.7.7.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">No</span></td>\n<td id=\"S4.T2.9.7.7.7\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S4.T2.9.7.7.7.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">99.18</span></td>\n<td id=\"S4.T2.9.7.7.8\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S4.T2.9.7.7.8.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">99.72</span></td>\n<td id=\"S4.T2.9.7.7.9\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S4.T2.9.7.7.9.1\" class=\"ltx_text\" style=\"font-size:90%;\">34.56</span></td>\n</tr>\n</tbody>\n</table>\n",
        "footnotes": [],
        "references": [
            "We use a slightly different RNN-T architecture from previous LibriSpeech experiments. The encoder now consists of 5 LSTM layers and the softmax layer has an output vocabulary size of 4001 word pieces including the blank label.\nNote that, the results in this section are reported in normalized WER (NWER) numbers, which is the regular word error rate (WER) divided by the WER of the baseline model on the same test set and then multiplied by 100. Therefore, the NWERs for baseline model are 100 for all test sets as shown in Table 2.\nThe baseline RNN-T model for general-purpose application is trained with a dataset of 50,000 hours real human utterances.\nThis dataset is a collection of de-identified production utterances from voice-controlled far-field devices. A development set (Dev-Gen) and an evaluation set (Eval-Gen) are constructed with the same type of utterances, consisting of about 50 hours and 160 hours of data respectively. These two test sets are used to monitor the performance change on existing applications.\nTo evaluate the performance on the new application of medication name recognition, we collected 8 hours of real human data containing utterances with medication names (Eval-Med).",
            "One challenge in such continual learning is a balance between forgetting learned knowledge which causes degradation on Eval-Gen and learning new knowledge which strives to improve performance on Eval-Med.\nWe use multi-stage training to address this challenge, and our experiments concluded with 4 critical stages as shown in Table 2.\nThe first stage is to fine-tune the baseline model with batches of data that contain 95% real data and 5% synthetic data where we fix the RNN-T encoder parameters.\nWe train in this way for 57k iterations, during which process the learning rate decays from 5e-5 to 1e-5. This stages ramps up the parameters for decoder and joint network for the new application of medication name recognition.\nIn the second stage, we further fine-tune the model with both real and synthetic utterances with the portion of 98% and 2% in each batch and fixed learning rate of 1e-5.\nAs shown in Table 2, this improves the recognition performance on Eval-Med further from an NWER of 21.06 to 13.70.\nIn our experiments we found the first training stage with encoder freezing critical, and removing Stage 1 led to performance degradation.\nAt the same time, model at the end of stage 2 showed a small degradation compared to baseline on general test sets.",
            "To recover the degradation, in the third and fourth stages, we only fine-tune models with real human speech. In the third stage, we include an elastic penalty as described in section 3.5 to minimize the deviation of the model parameters from the previous stage as the model has well learned medication names. We further fine-tune the model in the fourth stage without such regularization but with a small learning rate of 1e-5 to ensure the performance of the model doesn\u2019t degrade from the baseline.\nNote that in our experiments, we found the third stage critical and directly jumping from Stage 2 to Stage 4 led to worse results.\nAs shown in Table 2, the final model from Stage 4 achieved slightly better performance on both general test sets compared to baseline model, and at the same time the recognition performance on Eval-Med is more than 65% better than the baseline model.\nThis is achieved with 5k hours of synthetic training data without real recordings for medication names ."
        ]
    }
}