{
    "id_table_1": {
        "caption": "",
        "table": "S3.E1",
        "footnotes": [],
        "references": [
            "Assuming the reward generation process follows Equation ( 1 ) is both intuitive and possesses a very beneficial property. With some simple algebra, we can show that",
            "In the context of online bandits with interference, we extend three algorithms from classical contextual bandits to account for the presence of interference: Linear Epsilon-Greedy With Interference (LinEGWI), Linear Upper Confidence Bound With Interference (LinUCBWI), and Linear Thompson Sampling With Interference (LinTSWI). These algorithms, summarized in Algorithm  1 , differ primarily in their approach to exploration.",
            "There are two main differences between Algorithm  1  and classical linear contextual bandit algorithms. First, due to the presence of interference,    \\boldsymbol{\\beta} bold_italic_  is estimated using the transformed covariate information  X ~ t  i subscript ~ X t i \\widetilde{\\boldsymbol{X}}_{ti} over~ start_ARG bold_italic_X end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT . This transformation depends on the covariates, interference matrix, and actions involving all units in round  t t t italic_t , as shown in Line 17 of Algorithm  1 . Second, we incorporate an additional clipping step in Line 10 to ensure that the probability of exploration does not decay faster than  O  ( N   t  1 / 2 ) O superscript subscript   N t 1 2 O(\\bar{N}_{t}^{-1/2}) italic_O ( over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 / 2 end_POSTSUPERSCRIPT )  [see Assumption  2 ]. This clipping step is crucial for maintaining sufficient exploration, which is necessary for estimation consistency and valid inference of    \\boldsymbol{\\beta} bold_italic_ , as will be detailed in the theory section. Note that when  W t  I subscript W t I \\boldsymbol{W}_{t}\\equiv I bold_italic_W start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  italic_I  for all  t t t italic_t , our method downgrades to the classical linear contextual bandit algorithms, aside from adding a step for clipping to ensure valid statistical inference.",
            "Assumption  1  includes several bounded conditions. Assumption  1 .a ensures that there is no strong collinearity between different features, which is necessary for a stable OLS estimator. This condition is commonly assumed in bandit-related inference papers  (Zhang et al.,  2020 ; Chen et al.,  2021 ; Ye et al.,  2023 ) . Assumptions  1 .b and  1 .c ensure that the contextual information and the interference level for each individual unit are bounded. Assumption  2  is a technical requirement that guarantees the bandit algorithm explores all actions sufficiently at a rate of  p t subscript p t p_{t} italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , enabling consistent estimation of the OLS estimator. This exploration procedure is widely assumed in bandits inference literature  (Deshpande et al.,  2018 ; Hadad et al.,  2021 ; Ye et al.,  2023 ) , which is enforced via the clipping step in Line 10 of algorithm  1 . Assumption  3 , known as the margin condition, is a common assumption in the contextual bandits literature  (Audibert and Tsybakov,  2007 ; Luedtke and Van Der Laan,  2016 ) . It ensures that the rewards obtained from pulling different arms are not too close to each other.",
            "(Tail Bound of the Online OLS Estimator) Suppose Assumptions  1 - 2  hold. In either LinUCBWI, LinTSWI or LinEGWI, for any  h > 0 h 0 h>0 italic_h > 0 , we have",
            "where  L w subscript L w L_{w} italic_L start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT  and  L x subscript L x L_{x} italic_L start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT  are some constants for boundedness, and  p t subscript p t p_{t} italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  controls the clipping rate in Algorithm  1 .",
            "Remark.  Given that  d d d italic_d ,    \\sigma italic_ ,  L w subscript L w L_{w} italic_L start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT  and  L x subscript L x L_{x} italic_L start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT  are positive constants, the tail bound for the online OLS estimator simplifies to  P  (   ^ t    1 > h )  exp  (  h  N   t  p t  1 2 ) less-than-or-similar-to P subscript norm subscript ^  t  1 h h subscript   N t superscript subscript p t 1 2 \\mathbb{P}\\left(\\|\\widehat{\\boldsymbol{\\beta}}_{t}-\\boldsymbol{\\beta}\\|_{1}>h% \\right)\\lesssim\\exp(-h\\bar{N}_{t}p_{t-1}^{2}) blackboard_P (  over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - bold_italic_  start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT > italic_h )  roman_exp ( - italic_h over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) . As detailed in Assumption  2 ,  p t subscript p t p_{t} italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  is a non-increasing sequence. As long as  N   t  p t 2    subscript   N t superscript subscript p t 2 \\bar{N}_{t}p_{t}^{2}\\rightarrow\\infty over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT   ,   ^ t subscript ^  t \\widehat{\\boldsymbol{\\beta}}_{t} over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  will converge in probability to    \\boldsymbol{\\beta} bold_italic_ . Therefore, in Algorithm  1 , we set the clipping rate at round  t t t italic_t  to  p t > O  ( N   t  1 / 2 ) subscript p t O superscript subscript   N t 1 2 p_{t}>O(\\bar{N}_{t}^{-1/2}) italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT > italic_O ( over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 / 2 end_POSTSUPERSCRIPT )  to ensure sufficient exploration and thus the convergence of the online OLS estimator.",
            "Suppose Assumptions  1 - 3  hold. In either LinUCBWI, LinTSWI or LinEGWI, for any  0 <  < |  t  i | / 2 0  subscript  t i 2 0<\\xi<|\\zeta_{ti}|/2 0 < italic_ < | italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT | / 2  with   t  i =  t  i  X t  i   (  1   0 ) subscript  t i subscript  t i superscript subscript X t i  subscript  1 subscript  0 \\zeta_{ti}=\\omega_{ti}\\boldsymbol{X}_{ti}^{\\prime}({\\boldsymbol{\\beta}}_{1}-{% \\boldsymbol{\\beta}}_{0}) italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT = italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( bold_italic_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - bold_italic_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) , we have",
            "Remark.  This theorem extends the results from  Ye et al. ( 2023 )  to scenarios with interference. As  N   t  p t    subscript   N t subscript p t \\bar{N}_{t}p_{t}\\rightarrow\\infty over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT   , the exploration probability in both UCB and TS will converge to  0 0  as  N   t    subscript   N t \\bar{N}_{t}\\rightarrow\\infty over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT   . Specifically, in UCB, the exploration upper bound consists of two components: the first term arises from the margin condition, and the second term from the tail bound of   ^ t subscript ^  t \\widehat{\\boldsymbol{\\beta}}_{t} over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT . When  N   t subscript   N t \\bar{N}_{t} over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  is large, the second term, which decays at a rate of  O  ( exp  {  N   t  1  p t  1 2 } ) O subscript   N t 1 superscript subscript p t 1 2 O(\\exp\\{-\\bar{N}_{t-1}p_{t-1}^{2}\\}) italic_O ( roman_exp { - over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT } ) , will be dominated by the first term, which decays at a rate of  O  ( ( N   t  1  p t  1 )   / 2 ) O superscript subscript   N t 1 subscript p t 1  2 O((\\bar{N}_{t-1}p_{t-1})^{-\\gamma/2}) italic_O ( ( over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT - italic_ / 2 end_POSTSUPERSCRIPT )  if we set   = O  ( ( N   t  1  p t  1 2 )  1 / 2 )  O superscript subscript   N t 1 superscript subscript p t 1 2 1 2 \\xi=O((\\bar{N}_{t-1}p_{t-1}^{2})^{-1/2}) italic_ = italic_O ( ( over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT - 1 / 2 end_POSTSUPERSCRIPT ) . In TS, the upper bound is dominated by the second term, which converges to  0 0  at a rate  O  ( exp  {  N   t  1  p t  1 2 } ) O subscript   N t 1 superscript subscript p t 1 2 O(\\exp\\{-\\bar{N}_{t-1}p_{t-1}^{2}\\}) italic_O ( roman_exp { - over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT } )  as  N   t  1  p t  1 2    subscript   N t 1 superscript subscript p t 1 2 \\bar{N}_{t-1}p_{t-1}^{2}\\rightarrow\\infty over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT   . Note that  L w subscript L w L_{w} italic_L start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT  serves as an upper bound that controls the overall level of interference in Assumption  1 .c. A larger  L w subscript L w L_{w} italic_L start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT  would increase the upper bound of exploration for both UCB and TS. However,  L w subscript L w L_{w} italic_L start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT  has no effect on EG where the probability of exploration is often pre-specified.",
            "Suppose Assumptions  1 - 3  hold, and  N   t  p t    subscript   N t subscript p t \\bar{N}_{t}p_{t}\\rightarrow\\infty over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT    as  N   t    subscript   N t \\bar{N}_{t}\\rightarrow\\infty over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT   . We have",
            "where   ^ t  1  (  t  i , X t  i ) =  s  t  1 , i  [ N s ] 1  { A s  i =  ^  ( X s  i ) } / N   t  1 subscript ^  t 1 subscript  t i subscript X t i subscript formulae-sequence s t 1 i delimited-[] subscript N s 1 subscript A s i ^  subscript X s i subscript   N t 1 \\hat{\\kappa}_{t-1}(\\omega_{ti},\\boldsymbol{X}_{ti})=\\sum_{s\\leq t-1,i\\in[N_{s}% ]}\\boldsymbol{1}\\{A_{si}\\neq\\widehat{\\pi}(\\boldsymbol{X}_{si})\\}/\\bar{N}_{t-1} over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT ( italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT , bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT ) =  start_POSTSUBSCRIPT italic_s  italic_t - 1 , italic_i  [ italic_N start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ] end_POSTSUBSCRIPT bold_1 { italic_A start_POSTSUBSCRIPT italic_s italic_i end_POSTSUBSCRIPT = over^ start_ARG italic_ end_ARG ( bold_italic_X start_POSTSUBSCRIPT italic_s italic_i end_POSTSUBSCRIPT ) } / over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT , and   ^ s  1  ( X s  i ) subscript ^  s 1 subscript X s i \\widehat{\\pi}_{s-1}(\\boldsymbol{X}_{si}) over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_s - 1 end_POSTSUBSCRIPT ( bold_italic_X start_POSTSUBSCRIPT italic_s italic_i end_POSTSUBSCRIPT )  is obtained from Line 9 of Algorithm  1 .",
            "Suppose Assumptions  1 - 4  hold. We have",
            "Remark.  The asymptotic variance of the optimal value function comprises two components. The first term arises from the IPW estimator and accounts for the variance of the random noise   t  i subscript italic- t i \\epsilon_{ti} italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT  The second term originates from the DM estimator and captures the variance due to uncertainty in the context  x x \\boldsymbol{x} bold_italic_x  and the interference weight    \\omega italic_ . Notably, our theorem extends the results of  Ye et al. ( 2023 )  by establishing the asymptotic properties of the estimated optimal value function under interference. In the special case where    1  1 \\omega\\equiv 1 italic_  1  in Equation ( 18 ), our results reduce to theirs.",
            "Now we establish the regret bound for Algorithm  1 . We define the regret at the end of round  T T T italic_T  as",
            "For LinEGWI, LinUCBWI and LinTSWI in Algorithm  1 , the general regret bound under interference can be derived as",
            "To demonstrate the asymptotic normality of    \\boldsymbol{\\beta} bold_italic_  and  V   superscript V superscript  V^{\\pi^{*}} italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT  in Theorem  4.3 - 4.4 , we estimate the asymptotic variance and verify whether the true value of    \\boldsymbol{\\beta} bold_italic_  and  V   superscript V superscript  V^{\\pi^{*}} italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT  falls within the estimated confidence interval with a high probability of coverage under  B = 1000 B 1000 B=1000 italic_B = 1000  times of replicates. By Equation ( 15 ) and ( 17 ),    \\boldsymbol{\\beta} bold_italic_  falls into the confidence region if and only if  N   t  4  (  ^   ) T  G  (  ^   )    2  ( 2  d ) , subscript   N t superscript  4 superscript ^   T G ^   superscript subscript   2 2 d \\frac{\\bar{N}_{t}}{\\sigma^{4}}(\\widehat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta}% )^{T}G(\\widehat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta})\\leq\\chi_{\\alpha}^{2}(2% d), divide start_ARG over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG start_ARG italic_ start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT end_ARG ( over^ start_ARG bold_italic_ end_ARG - bold_italic_ ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_G ( over^ start_ARG bold_italic_ end_ARG - bold_italic_ )  italic_ start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( 2 italic_d ) ,  where  d  f = 2  d d f 2 d df=2d italic_d italic_f = 2 italic_d  is the degree of freedom of the chi-square distribution. Similarly,  V   superscript V superscript  V^{\\pi^{*}} italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT  falls into the confidence interval if and only if  N   t  | V ^ t DR  V   |  z  / 2   V . subscript   N t subscript superscript ^ V DR t superscript V superscript  subscript z  2 subscript  V \\sqrt{\\bar{N}_{t}}|\\widehat{V}^{\\text{DR}}_{t}-V^{\\pi^{*}}|\\leq z_{\\alpha/2}{% \\sigma_{V}}. square-root start_ARG over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG | over^ start_ARG italic_V end_ARG start_POSTSUPERSCRIPT DR end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT |  italic_z start_POSTSUBSCRIPT italic_ / 2 end_POSTSUBSCRIPT italic_ start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT .  Detailed simulation setup is summarized in Appendix  A.1 .",
            "Coverage probabilities of the OLS estimator   ^ ^  \\widehat{\\boldsymbol{\\beta}} over^ start_ARG bold_italic_ end_ARG  and optimal value function  V   superscript V superscript  V^{\\pi^{*}} italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT  under three exploration algorithms (LinEGWI, LinUCBWI, and LinTSWI) are shown in Figure  1 . As we can see, the coverage consistently hovers around  95 % percent 95 95\\% 95 % , with the estimated confidence band almost always covering the red line. This result supports the validity of the statistical inference presented in Theorems  4.3  and  4.4 .",
            "The extension to  K > 2 K 2 K>2 italic_K > 2  arms is generally straightforward from an algorithmic perspective. Specifically, when  A = [ K ] A delimited-[] K \\mathcal{A}=[K] caligraphic_A = [ italic_K ] , one can still follow Equation ( 3 ) and easily extend the algorithm by modifying Line 9 of Algorithm  1  to   ^ t  i = arg  max a  {  t  i  X t  i    ^ t  1 , a } subscript ^  t i subscript a subscript  t i superscript subscript X t i  subscript ^  t 1 a \\widehat{\\pi}_{ti}=\\arg\\max_{a}\\big{\\{}\\omega_{ti}\\boldsymbol{X}_{ti}^{\\prime}% \\widehat{\\boldsymbol{\\beta}}_{t-1,a}\\big{\\}} over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT = roman_arg roman_max start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT { italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT italic_t - 1 , italic_a end_POSTSUBSCRIPT } , thereby making the entire system applicable to multi-armed scenarios.",
            "From a theoretical perspective, extending to  K > 2 K 2 K>2 italic_K > 2  is mathematically straightforward but becomes tedious due to the nature of multi-arm comparisons. Specifically, the tail bound results would include  K K K italic_K  in the denominator of the exponential term in Equation ( 12 ), which does not affect the consistency result we established for the  K = 2 K 2 K=2 italic_K = 2  case. The bidirectional asymptotic normality still holds by following the martingale difference sequence we constructed, which flattens the units across different rounds into a single sequence, as detailed in Appendix  D . The detailed derivation is beyond the scope of this paper and will be addressed in future work.",
            "In the estimation of  V    superscript V  V^{\\pi*} italic_V start_POSTSUPERSCRIPT italic_  end_POSTSUPERSCRIPT , for a more balanced variance composition in Equation ( 18 ), we set up the data generating process for  W t subscript W t \\boldsymbol{W}_{t} bold_italic_W start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  and  X t  i subscript X t i \\boldsymbol{X}_{ti} bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT  as follows. For each  i = j i j i\\neq j italic_i = italic_j , we generate  W t , i  j    Unif  (  0.2 ,  0.1 ) + ( 1   )  Unif  ( 0.05 , 0.2 ) similar-to subscript W t i j   Unif 0.2 0.1  1  Unif 0.05 0.2 W_{t,ij}\\sim\\alpha\\cdot\\text{Unif}(-0.2,-0.1)+(1-\\alpha)\\cdot\\text{Unif}(0.05,% 0.2) italic_W start_POSTSUBSCRIPT italic_t , italic_i italic_j end_POSTSUBSCRIPT  italic_  Unif ( - 0.2 , - 0.1 ) + ( 1 - italic_ )  Unif ( 0.05 , 0.2 ) , where    Bernoulli  ( 0.5 ) similar-to  Bernoulli 0.5 \\alpha\\sim\\text{Bernoulli}(0.5) italic_  Bernoulli ( 0.5 ) . For contextual information, we generate  X t  i = ( X t  i , 1 , ... , X t  i , 3 )  R 3 subscript X t i subscript X t i 1 ... subscript X t i 3 superscript R 3 \\boldsymbol{X}_{ti}=(X_{ti,1},\\dots,X_{ti,3})\\in\\mathbb{R}^{3} bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT = ( italic_X start_POSTSUBSCRIPT italic_t italic_i , 1 end_POSTSUBSCRIPT , ... , italic_X start_POSTSUBSCRIPT italic_t italic_i , 3 end_POSTSUBSCRIPT )  blackboard_R start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT  for unit  i i i italic_i  at round  t t t italic_t , where  X t  i , 1  0.2 subscript X t i 1 0.2 X_{ti,1}\\equiv 0.2 italic_X start_POSTSUBSCRIPT italic_t italic_i , 1 end_POSTSUBSCRIPT  0.2 ,  X t  i , 2  N  ( 0.8 , 0.04 ) similar-to subscript X t i 2 N 0.8 0.04 X_{ti,2}\\sim\\mathcal{N}(0.8,0.04) italic_X start_POSTSUBSCRIPT italic_t italic_i , 2 end_POSTSUBSCRIPT  caligraphic_N ( 0.8 , 0.04 ) ,  X t  i , 3  Unif  ( 0 , 0.6 ) similar-to subscript X t i 3 Unif 0 0.6 X_{ti,3}\\sim\\text{Unif}(0,0.6) italic_X start_POSTSUBSCRIPT italic_t italic_i , 3 end_POSTSUBSCRIPT  Unif ( 0 , 0.6 ) , and all of the samples are i.i.d. over  ( t , i ) t i (t,i) ( italic_t , italic_i ) .",
            "where the right hand side of the above equation, by Assumption  1 - 2 , is lower bounded by  p t  1   subscript p t 1  p_{t-1}\\lambda italic_p start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT italic_ . Therefore,",
            "In our context, we flatten the unit for  { t , i } 1  t  T , 1  i  N t subscript t i formulae-sequence 1 t T 1 i subscript N t \\{t,i\\}_{1\\leq t\\leq T,1\\leq i\\leq N_{t}} { italic_t , italic_i } start_POSTSUBSCRIPT 1  italic_t  italic_T , 1  italic_i  italic_N start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT  to an unit queue  Q  ( t , i ) =  s = 1 t  1 N s + i Q t i superscript subscript s 1 t 1 subscript N s i Q(t,i)=\\sum_{s=1}^{t-1}{N_{s}}+i italic_Q ( italic_t , italic_i ) =  start_POSTSUBSCRIPT italic_s = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t - 1 end_POSTSUPERSCRIPT italic_N start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT + italic_i , such that all of the units are measured in a chronological order. As such, we also use  X ~ q , l subscript ~ X q l \\widetilde{{X}}_{q,l} over~ start_ARG italic_X end_ARG start_POSTSUBSCRIPT italic_q , italic_l end_POSTSUBSCRIPT  to denote the  l l l italic_l th element of  X ~ t  i subscript ~ X t i \\widetilde{\\boldsymbol{X}}_{ti} over~ start_ARG bold_italic_X end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT . To use Lemma  B.1 , we define a filtration  F q subscript F q \\mathcal{F}_{q} caligraphic_F start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT  as",
            "which satisfies   q  F q  1 perpendicular-to subscript italic- q subscript F q 1 \\epsilon_{q}\\perp\\mathcal{F}_{q-1} italic_ start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT  caligraphic_F start_POSTSUBSCRIPT italic_q - 1 end_POSTSUBSCRIPT  for any  q  { 1 , ... , N   T } q 1 ... subscript   N T q\\in\\{1,\\dots,\\bar{N}_{T}\\} italic_q  { 1 , ... , over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT } . Let  Z q = X ~ q , j subscript Z q subscript ~ X q j Z_{q}=\\widetilde{{X}}_{q,j} italic_Z start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT = over~ start_ARG italic_X end_ARG start_POSTSUBSCRIPT italic_q , italic_j end_POSTSUBSCRIPT . Then by Assumption  1 .b-c,",
            "Define  L := 2  d  L w  L x assign L 2 d subscript L w subscript L x L:=\\sqrt{2d}L_{w}L_{x} italic_L := square-root start_ARG 2 italic_d end_ARG italic_L start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT italic_L start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT , so that  | X ~ q , l |  L subscript ~ X q l L |\\widetilde{{X}}_{q,l}|\\leq L | over~ start_ARG italic_X end_ARG start_POSTSUBSCRIPT italic_q , italic_l end_POSTSUBSCRIPT |  italic_L . According to the conclusion of Lemma  B.1 , we have",
            "Combining the result of Equation ( 19 ) and ( 21 ), we have",
            "The proof of Theorem  4.1  is thus complete.",
            "where the first inequality holds by the definition of eigenvalues, and the last inequality holds by Assumption  1 .b-c.",
            "Furthermore, by Assumption  1  and  2 ,",
            "According to Theorem  4.1 ,",
            "Similar to Step 3 of Section  C.1 , we define an event  E := { |  ^ t  i   t  i |   } assign E subscript ^  t i subscript  t i  E:=\\big{\\{}|\\widehat{\\zeta}_{ti}-{\\zeta}_{ti}|\\leq\\xi\\big{\\}} italic_E := { | over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT - italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT |  italic_ }  for any    ( 0 , |  t  i | / 2 )  0 subscript  t i 2 \\xi\\in(0,|{\\zeta}_{ti}|/2) italic_  ( 0 , | italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT | / 2 ) , where   ^ t  i =  t  i  X t  i   (  ^ t  1   ^ t  0 ) subscript ^  t i subscript  t i superscript subscript X t i  subscript ^  t 1 subscript ^  t 0 \\widehat{\\zeta}_{ti}=\\omega_{ti}\\boldsymbol{X}_{ti}^{\\prime}(\\widehat{% \\boldsymbol{\\beta}}_{t1}-\\widehat{\\boldsymbol{\\beta}}_{t0}) over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT = italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT italic_t 1 end_POSTSUBSCRIPT - over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT italic_t 0 end_POSTSUBSCRIPT ) , and   t  i =  t  i  X t  i   (  1   0 ) subscript  t i subscript  t i superscript subscript X t i  subscript  1 subscript  0 {\\zeta}_{ti}=\\omega_{ti}\\boldsymbol{X}_{ti}^{\\prime}({\\boldsymbol{\\beta}}_{1}-% {\\boldsymbol{\\beta}}_{0}) italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT = italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( bold_italic_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - bold_italic_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) . According to the result of Equation ( 28 ), we have",
            "where  D t  1 = Var  (  ^ t  1 , 1   ^ t  1 , 0 ) = ( A t  1 ) 11 + ( A t  1 ) 00  2  ( A t  1 ) 01 subscript D t 1 Var subscript ^  t 1 1 subscript ^  t 1 0 subscript superscript subscript A t 1 11 subscript superscript subscript A t 1 00 2 subscript superscript subscript A t 1 01 \\mathcal{D}_{t-1}=\\text{Var}(\\widehat{\\boldsymbol{\\beta}}_{t-1,1}-\\widehat{% \\boldsymbol{\\beta}}_{t-1,0})=\\left(A_{t}^{-1}\\right)_{11}+\\left(A_{t}^{-1}% \\right)_{00}-2\\left(A_{t}^{-1}\\right)_{01} caligraphic_D start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT = Var ( over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT italic_t - 1 , 1 end_POSTSUBSCRIPT - over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT italic_t - 1 , 0 end_POSTSUBSCRIPT ) = ( italic_A start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ) start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT + ( italic_A start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ) start_POSTSUBSCRIPT 00 end_POSTSUBSCRIPT - 2 ( italic_A start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ) start_POSTSUBSCRIPT 01 end_POSTSUBSCRIPT , with  ( A t  1 ) 11 subscript superscript subscript A t 1 11 \\left(A_{t}^{-1}\\right)_{11} ( italic_A start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ) start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT  denoting the upper left  d  d d d d\\times d italic_d  italic_d  dimensional block matrix,  ( A t  1 ) 00 subscript superscript subscript A t 1 00 \\left(A_{t}^{-1}\\right)_{00} ( italic_A start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ) start_POSTSUBSCRIPT 00 end_POSTSUBSCRIPT  denoting the bottom right  d  d d d d\\times d italic_d  italic_d  dimensional block matrix, and  ( A t  1 ) 01 subscript superscript subscript A t 1 01 \\left(A_{t}^{-1}\\right)_{01} ( italic_A start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ) start_POSTSUBSCRIPT 01 end_POSTSUBSCRIPT  denoting the upper right or bottom left covariance sub-matrix. For the simplicity of implementation, we exclude the interaction term  ( A t  1 ) 01 subscript superscript subscript A t 1 01 \\left(A_{t}^{-1}\\right)_{01} ( italic_A start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ) start_POSTSUBSCRIPT 01 end_POSTSUBSCRIPT  in Algorithm  1 , i.e. assuming independence between   ^ 1 , t subscript ^  1 t \\widehat{\\boldsymbol{\\beta}}_{1,t} over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT 1 , italic_t end_POSTSUBSCRIPT  and   ^ 0 , t subscript ^  0 t \\widehat{\\boldsymbol{\\beta}}_{0,t} over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT 0 , italic_t end_POSTSUBSCRIPT  while making decisions.",
            "when we exclude the covariance term for simplicity, as done in Equation ( 11 ).",
            "According to Assumption  1 .b-c,",
            "Based on Lemma 6 of  Chen et al. [ 2021 ] , it suffice to find the limit of  1 N   q   q = 1 N   q v   X ~ q  X ~ q   v 1 subscript   N q superscript subscript q 1 subscript   N q superscript v  subscript ~ X q superscript subscript ~ X q  v \\frac{1}{\\bar{N}_{q}}\\sum_{q=1}^{\\bar{N}_{q}}\\boldsymbol{v}^{\\prime}\\widetilde% {\\boldsymbol{X}}_{q}\\widetilde{\\boldsymbol{X}}_{q}^{\\prime}\\boldsymbol{v} divide start_ARG 1 end_ARG start_ARG over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT end_ARG  start_POSTSUBSCRIPT italic_q = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT end_POSTSUPERSCRIPT bold_italic_v start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT over~ start_ARG bold_italic_X end_ARG start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT over~ start_ARG bold_italic_X end_ARG start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT bold_italic_v . According to Equation ( 41 ), we have",
            "which has already been established in Equation ( 61 ) in Step 2.1. Therefore,   4 = o p  ( 1 ) subscript  4 subscript o p 1 \\boldsymbol{\\zeta}_{4}=o_{p}(1) bold_italic_ start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = italic_o start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( 1 ) .",
            "Notice that in the proof of Theorem  4.4 , step 2.1, weve proved in Equation ( 61 ) that",
            "Now lets decompose according to different exploration algorithms. For simplicity of notations, we continue with the flattened unit queue  q = Q  ( t , i )   s = 1 t  1 N s + t q Q t i superscript subscript s 1 t 1 subscript N s t q=Q(t,i)\\sum_{s=1}^{t-1}N_{s}+t italic_q = italic_Q ( italic_t , italic_i )  start_POSTSUBSCRIPT italic_s = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t - 1 end_POSTSUPERSCRIPT italic_N start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT + italic_t  as shown in the proof of Theorem  4.1 . As such, we can extend the definition of  p t subscript p t p_{t} italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  to  p q subscript p q p_{q} italic_p start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT  by simply setting  p q = p t subscript p q subscript p t p_{q}=p_{t} italic_p start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT = italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  for any unit  q q q italic_q  in round  t t t italic_t . As such,  p q subscript p q p_{q} italic_p start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT  is still a non-increasing sequence w.r.t.  q q q italic_q . By Theorem  4.2 , we have"
        ]
    },
    "id_table_2": {
        "caption": "",
        "table": "S3.E2",
        "footnotes": [],
        "references": [
            "There are two main differences between Algorithm  1  and classical linear contextual bandit algorithms. First, due to the presence of interference,    \\boldsymbol{\\beta} bold_italic_  is estimated using the transformed covariate information  X ~ t  i subscript ~ X t i \\widetilde{\\boldsymbol{X}}_{ti} over~ start_ARG bold_italic_X end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT . This transformation depends on the covariates, interference matrix, and actions involving all units in round  t t t italic_t , as shown in Line 17 of Algorithm  1 . Second, we incorporate an additional clipping step in Line 10 to ensure that the probability of exploration does not decay faster than  O  ( N   t  1 / 2 ) O superscript subscript   N t 1 2 O(\\bar{N}_{t}^{-1/2}) italic_O ( over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 / 2 end_POSTSUPERSCRIPT )  [see Assumption  2 ]. This clipping step is crucial for maintaining sufficient exploration, which is necessary for estimation consistency and valid inference of    \\boldsymbol{\\beta} bold_italic_ , as will be detailed in the theory section. Note that when  W t  I subscript W t I \\boldsymbol{W}_{t}\\equiv I bold_italic_W start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  italic_I  for all  t t t italic_t , our method downgrades to the classical linear contextual bandit algorithms, aside from adding a step for clipping to ensure valid statistical inference.",
            "Assumption  1  includes several bounded conditions. Assumption  1 .a ensures that there is no strong collinearity between different features, which is necessary for a stable OLS estimator. This condition is commonly assumed in bandit-related inference papers  (Zhang et al.,  2020 ; Chen et al.,  2021 ; Ye et al.,  2023 ) . Assumptions  1 .b and  1 .c ensure that the contextual information and the interference level for each individual unit are bounded. Assumption  2  is a technical requirement that guarantees the bandit algorithm explores all actions sufficiently at a rate of  p t subscript p t p_{t} italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , enabling consistent estimation of the OLS estimator. This exploration procedure is widely assumed in bandits inference literature  (Deshpande et al.,  2018 ; Hadad et al.,  2021 ; Ye et al.,  2023 ) , which is enforced via the clipping step in Line 10 of algorithm  1 . Assumption  3 , known as the margin condition, is a common assumption in the contextual bandits literature  (Audibert and Tsybakov,  2007 ; Luedtke and Van Der Laan,  2016 ) . It ensures that the rewards obtained from pulling different arms are not too close to each other.",
            "(Tail Bound of the Online OLS Estimator) Suppose Assumptions  1 - 2  hold. In either LinUCBWI, LinTSWI or LinEGWI, for any  h > 0 h 0 h>0 italic_h > 0 , we have",
            "Remark.  Given that  d d d italic_d ,    \\sigma italic_ ,  L w subscript L w L_{w} italic_L start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT  and  L x subscript L x L_{x} italic_L start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT  are positive constants, the tail bound for the online OLS estimator simplifies to  P  (   ^ t    1 > h )  exp  (  h  N   t  p t  1 2 ) less-than-or-similar-to P subscript norm subscript ^  t  1 h h subscript   N t superscript subscript p t 1 2 \\mathbb{P}\\left(\\|\\widehat{\\boldsymbol{\\beta}}_{t}-\\boldsymbol{\\beta}\\|_{1}>h% \\right)\\lesssim\\exp(-h\\bar{N}_{t}p_{t-1}^{2}) blackboard_P (  over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - bold_italic_  start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT > italic_h )  roman_exp ( - italic_h over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) . As detailed in Assumption  2 ,  p t subscript p t p_{t} italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  is a non-increasing sequence. As long as  N   t  p t 2    subscript   N t superscript subscript p t 2 \\bar{N}_{t}p_{t}^{2}\\rightarrow\\infty over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT   ,   ^ t subscript ^  t \\widehat{\\boldsymbol{\\beta}}_{t} over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  will converge in probability to    \\boldsymbol{\\beta} bold_italic_ . Therefore, in Algorithm  1 , we set the clipping rate at round  t t t italic_t  to  p t > O  ( N   t  1 / 2 ) subscript p t O superscript subscript   N t 1 2 p_{t}>O(\\bar{N}_{t}^{-1/2}) italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT > italic_O ( over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 / 2 end_POSTSUPERSCRIPT )  to ensure sufficient exploration and thus the convergence of the online OLS estimator.",
            "Following the same logic used to derive Equation ( 2 ), the above estimator can be rewritten as",
            "First, we compare our proposed method with the classical linear contextual bandit algorithms to illustrate the importance of taking interference into consideration. The results are shown in Figure  2  based on  B = 100 B 100 B=100 italic_B = 100  times of replication. As we can see, our approaches  LinEGWI, LinUCBWI, and LinTSWI  yield significantly smaller average regrets at a fast rate than classical linear contextual bandits algorithms. This demonstrates the validity of our algorithms in handling interference. When there is no interference, our algorithm reduces to the classical LinCB approach, delivering comparable results. The simulation setup and additional comparison results in the absence of interference are detailed in Appendix  A.2 .",
            "From a theoretical perspective, extending to  K > 2 K 2 K>2 italic_K > 2  is mathematically straightforward but becomes tedious due to the nature of multi-arm comparisons. Specifically, the tail bound results would include  K K K italic_K  in the denominator of the exponential term in Equation ( 12 ), which does not affect the consistency result we established for the  K = 2 K 2 K=2 italic_K = 2  case. The bidirectional asymptotic normality still holds by following the martingale difference sequence we constructed, which flattens the units across different rounds into a single sequence, as detailed in Appendix  D . The detailed derivation is beyond the scope of this paper and will be addressed in future work.",
            "Using the same simulation setup as in Section  5.2 , but with the interference matrix  W t subscript W t \\boldsymbol{W}_{t} bold_italic_W start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  replaced by an identity matrix, we compare the results of the classical linear CB algorithm with our proposed methods. The results, shown in Figure  4 , indicate that all methods yield comparable performance over time, with average regrets converging to zero at a rapid rate.",
            "where the right hand side of the above equation, by Assumption  1 - 2 , is lower bounded by  p t  1   subscript p t 1  p_{t-1}\\lambda italic_p start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT italic_ . Therefore,",
            "Combining the result of Equation ( 19 ) and ( 21 ), we have",
            "Combining the result of Equation ( 23 ) and ( 24 ), we have",
            "Furthermore, by Assumption  1  and  2 ,",
            "Combining the result above and Equation ( 25 ), we have",
            "Step 3:  Further bound the RHS of Equation ( 27 ).",
            "On event  E E E italic_E , we have  |  ^ t  i |  |  t  i |  |  ^ t  i   t  i |  |  t  i |   subscript ^  t i subscript  t i subscript ^  t i subscript  t i subscript  t i  |\\widehat{\\zeta}_{ti}|\\geq|{\\zeta}_{ti}|-|\\widehat{\\zeta}_{ti}-{\\zeta}_{ti}|% \\geq|{\\zeta}_{ti}|-\\xi | over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT |  | italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT | - | over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT - italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT |  | italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT | - italic_ . Then going back to Equation ( 27 ), we further have",
            "By taking this result back to Equation ( 29 ), we are able to show that there exists a constant  C C C italic_C , such that",
            "Similar to Step 3 of Section  C.1 , we define an event  E := { |  ^ t  i   t  i |   } assign E subscript ^  t i subscript  t i  E:=\\big{\\{}|\\widehat{\\zeta}_{ti}-{\\zeta}_{ti}|\\leq\\xi\\big{\\}} italic_E := { | over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT - italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT |  italic_ }  for any    ( 0 , |  t  i | / 2 )  0 subscript  t i 2 \\xi\\in(0,|{\\zeta}_{ti}|/2) italic_  ( 0 , | italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT | / 2 ) , where   ^ t  i =  t  i  X t  i   (  ^ t  1   ^ t  0 ) subscript ^  t i subscript  t i superscript subscript X t i  subscript ^  t 1 subscript ^  t 0 \\widehat{\\zeta}_{ti}=\\omega_{ti}\\boldsymbol{X}_{ti}^{\\prime}(\\widehat{% \\boldsymbol{\\beta}}_{t1}-\\widehat{\\boldsymbol{\\beta}}_{t0}) over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT = italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT italic_t 1 end_POSTSUBSCRIPT - over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT italic_t 0 end_POSTSUBSCRIPT ) , and   t  i =  t  i  X t  i   (  1   0 ) subscript  t i subscript  t i superscript subscript X t i  subscript  1 subscript  0 {\\zeta}_{ti}=\\omega_{ti}\\boldsymbol{X}_{ti}^{\\prime}({\\boldsymbol{\\beta}}_{1}-% {\\boldsymbol{\\beta}}_{0}) italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT = italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( bold_italic_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - bold_italic_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) . According to the result of Equation ( 28 ), we have",
            "Define   ^ t  1  ( X t  i ) = |  t  i |  X t  i   ( X ~ 1 : ( t  1 )   X ~ 1 : ( t  1 ) ) 1  1  X t  i subscript ^  t 1 subscript X t i subscript  t i superscript subscript X t i  subscript superscript superscript subscript ~ X : 1 t 1  subscript ~ X : 1 t 1 1 1 subscript X t i \\widehat{\\sigma}_{t1}(\\boldsymbol{X}_{ti})=|\\omega_{ti}|\\sqrt{\\boldsymbol{X}_{% ti}^{\\prime}\\left(\\widetilde{\\boldsymbol{X}}_{1:(t-1)}^{\\prime}\\widetilde{% \\boldsymbol{X}}_{1:(t-1)}\\right)^{-1}_{1}\\boldsymbol{X}_{ti}} over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t 1 end_POSTSUBSCRIPT ( bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT ) = | italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT | square-root start_ARG bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( over~ start_ARG bold_italic_X end_ARG start_POSTSUBSCRIPT 1 : ( italic_t - 1 ) end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT over~ start_ARG bold_italic_X end_ARG start_POSTSUBSCRIPT 1 : ( italic_t - 1 ) end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT end_ARG , and   ^ t  0  ( X t  i ) = |  t  i |  X t  i   ( X ~ 1 : ( t  1 )   X ~ 1 : ( t  1 ) ) 0  1  X t  i subscript ^  t 0 subscript X t i subscript  t i superscript subscript X t i  subscript superscript superscript subscript ~ X : 1 t 1  subscript ~ X : 1 t 1 1 0 subscript X t i \\widehat{\\sigma}_{t0}(\\boldsymbol{X}_{ti})=|\\omega_{ti}|\\sqrt{\\boldsymbol{X}_{% ti}^{\\prime}\\left(\\widetilde{\\boldsymbol{X}}_{1:(t-1)}^{\\prime}\\widetilde{% \\boldsymbol{X}}_{1:(t-1)}\\right)^{-1}_{0}\\boldsymbol{X}_{ti}} over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t 0 end_POSTSUBSCRIPT ( bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT ) = | italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT | square-root start_ARG bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( over~ start_ARG bold_italic_X end_ARG start_POSTSUBSCRIPT 1 : ( italic_t - 1 ) end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT over~ start_ARG bold_italic_X end_ARG start_POSTSUBSCRIPT 1 : ( italic_t - 1 ) end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT end_ARG . According to the upper bound derived in Equation ( 26 ), we have",
            "Combining the results of Equation ( 32 ) and ( 35 ), we finally have",
            "Therefore, by Generalized Dominated Convergence Theorem (GDCT), it follows from Equation ( 42 ) that    E  [ f N   q | H q  1 ]  0  E delimited-[] conditional subscript f subscript   N q subscript H q 1  0 \\psi\\leq\\mathbb{E}[f_{\\bar{N}_{q}}|\\mathcal{H}_{q-1}]\\rightarrow 0 italic_  blackboard_E [ italic_f start_POSTSUBSCRIPT over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT end_POSTSUBSCRIPT | caligraphic_H start_POSTSUBSCRIPT italic_q - 1 end_POSTSUBSCRIPT ]  0  as  q    q q\\rightarrow\\infty italic_q   . The Lindeberg condition is thus verified.",
            "Given the derivation of Equation ( 62 ), we have",
            "According to the upper bound derived in Theorem  4.2 ,",
            "Now lets decompose according to different exploration algorithms. For simplicity of notations, we continue with the flattened unit queue  q = Q  ( t , i )   s = 1 t  1 N s + t q Q t i superscript subscript s 1 t 1 subscript N s t q=Q(t,i)\\sum_{s=1}^{t-1}N_{s}+t italic_q = italic_Q ( italic_t , italic_i )  start_POSTSUBSCRIPT italic_s = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t - 1 end_POSTSUPERSCRIPT italic_N start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT + italic_t  as shown in the proof of Theorem  4.1 . As such, we can extend the definition of  p t subscript p t p_{t} italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  to  p q subscript p q p_{q} italic_p start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT  by simply setting  p q = p t subscript p q subscript p t p_{q}=p_{t} italic_p start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT = italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  for any unit  q q q italic_q  in round  t t t italic_t . As such,  p q subscript p q p_{q} italic_p start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT  is still a non-increasing sequence w.r.t.  q q q italic_q . By Theorem  4.2 , we have"
        ]
    },
    "id_table_3": {
        "caption": "",
        "table": "S3.E3",
        "footnotes": [],
        "references": [
            "Assumption  1  includes several bounded conditions. Assumption  1 .a ensures that there is no strong collinearity between different features, which is necessary for a stable OLS estimator. This condition is commonly assumed in bandit-related inference papers  (Zhang et al.,  2020 ; Chen et al.,  2021 ; Ye et al.,  2023 ) . Assumptions  1 .b and  1 .c ensure that the contextual information and the interference level for each individual unit are bounded. Assumption  2  is a technical requirement that guarantees the bandit algorithm explores all actions sufficiently at a rate of  p t subscript p t p_{t} italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , enabling consistent estimation of the OLS estimator. This exploration procedure is widely assumed in bandits inference literature  (Deshpande et al.,  2018 ; Hadad et al.,  2021 ; Ye et al.,  2023 ) , which is enforced via the clipping step in Line 10 of algorithm  1 . Assumption  3 , known as the margin condition, is a common assumption in the contextual bandits literature  (Audibert and Tsybakov,  2007 ; Luedtke and Van Der Laan,  2016 ) . It ensures that the rewards obtained from pulling different arms are not too close to each other.",
            "Suppose Assumptions  1 - 3  hold. In either LinUCBWI, LinTSWI or LinEGWI, for any  0 <  < |  t  i | / 2 0  subscript  t i 2 0<\\xi<|\\zeta_{ti}|/2 0 < italic_ < | italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT | / 2  with   t  i =  t  i  X t  i   (  1   0 ) subscript  t i subscript  t i superscript subscript X t i  subscript  1 subscript  0 \\zeta_{ti}=\\omega_{ti}\\boldsymbol{X}_{ti}^{\\prime}({\\boldsymbol{\\beta}}_{1}-{% \\boldsymbol{\\beta}}_{0}) italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT = italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( bold_italic_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - bold_italic_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) , we have",
            "Suppose Assumptions  1 - 3  hold, and  N   t  p t    subscript   N t subscript p t \\bar{N}_{t}p_{t}\\rightarrow\\infty over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT    as  N   t    subscript   N t \\bar{N}_{t}\\rightarrow\\infty over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT   . We have",
            "Remark.  Theorem  4.3  establishes the asymptotic normality of the online OLS estimator, providing an explicit form for its asymptotic variance. This result holds for the EG, UCB, and TS algorithms used for exploration. Despite the presence of interference, the asymptotic normality of the estimator only requires the total number of units  N   t subscript   N t \\bar{N}_{t} over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  to approach infinity. In other words, bidirectional asymptotic normality is achieved as long as either  t    t t\\rightarrow\\infty italic_t    or the number of units at some stage  N t    subscript N t N_{t}\\rightarrow\\infty italic_N start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT   .",
            "Assumption  4  requires that the convergence rates of the conditional mean function and the estimated probability of exploration satisfy certain conditions. This is a standard assumption in causal inference literature, as noted in  Luedtke and Van Der Laan ( 2016 ); Kennedy ( 2022 ) . In our setting, this assumption is almost always satisfied, given that    ^ t  1 ( t , i )  ( X t ,  ^ t  1  ( X t ) )   ( t , i )  ( X t ,  ^ t  1  ( X t ) )  2 , N T = O p  ( N   T  1 / 2 ) subscript norm superscript subscript ^  t 1 t i subscript X t subscript ^  t 1 subscript X t superscript  t i subscript X t subscript ^  t 1 subscript X t 2 subscript N T subscript O p superscript subscript   N T 1 2 \\|\\widehat{\\mu}_{t-1}^{(t,i)}(\\boldsymbol{X}_{t},\\widehat{\\pi}_{t-1}(% \\boldsymbol{X}_{t}))-{\\mu}^{(t,i)}(\\boldsymbol{X}_{t},\\widehat{\\pi}_{t-1}(% \\boldsymbol{X}_{t}))\\|_{2,N_{T}}=O_{p}(\\bar{N}_{T}^{-1/2})  over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t , italic_i ) end_POSTSUPERSCRIPT ( bold_italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT ( bold_italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ) - italic_ start_POSTSUPERSCRIPT ( italic_t , italic_i ) end_POSTSUPERSCRIPT ( bold_italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT ( bold_italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) )  start_POSTSUBSCRIPT 2 , italic_N start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT end_POSTSUBSCRIPT = italic_O start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 / 2 end_POSTSUPERSCRIPT )  follows directly from Theorem  4.3 . Therefore, it suffices to ensure that    ^ t  1  (  t  i , X t  i )   t  1  (  t  i , X t  i )  2 , N T = o p  ( 1 ) subscript norm subscript ^  t 1 subscript  t i subscript X t i subscript  t 1 subscript  t i subscript X t i 2 subscript N T subscript o p 1 \\|\\hat{\\kappa}_{t-1}(\\omega_{ti},\\boldsymbol{X}_{ti})-{\\kappa}_{t-1}(\\omega_{% ti},\\boldsymbol{X}_{ti})\\|_{2,N_{T}}=o_{p}(1)  over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT ( italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT , bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT ) - italic_ start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT ( italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT , bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT )  start_POSTSUBSCRIPT 2 , italic_N start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT end_POSTSUBSCRIPT = italic_o start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( 1 )  for Assumption  3  to hold. This can be easily achieved by using a sample-based exploration estimand. In practice, as   ^ t  1  (  t  i , X t  i ) subscript ^  t 1 subscript  t i subscript X t i \\hat{\\kappa}_{t-1}(\\omega_{ti},\\boldsymbol{X}_{ti}) over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT ( italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT , bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT )  tends to be small as  t t t italic_t  increases, we set   ^ t  1  (  t  i , X t  i ) =  s  t  1 , i  [ N s ] 1  { A s  i =  ^  ( X s  i ) } / N   t  1 subscript ^  t 1 subscript  t i subscript X t i subscript formulae-sequence s t 1 i delimited-[] subscript N s 1 subscript A s i ^  subscript X s i subscript   N t 1 \\hat{\\kappa}_{t-1}(\\omega_{ti},\\boldsymbol{X}_{ti})=\\sum_{s\\leq t-1,i\\in[N_{s}% ]}\\boldsymbol{1}\\{A_{si}\\neq\\widehat{\\pi}(\\boldsymbol{X}_{si})\\}/\\bar{N}_{t-1} over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT ( italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT , bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT ) =  start_POSTSUBSCRIPT italic_s  italic_t - 1 , italic_i  [ italic_N start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ] end_POSTSUBSCRIPT bold_1 { italic_A start_POSTSUBSCRIPT italic_s italic_i end_POSTSUBSCRIPT = over^ start_ARG italic_ end_ARG ( bold_italic_X start_POSTSUBSCRIPT italic_s italic_i end_POSTSUBSCRIPT ) } / over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT , which proves to be sufficient in simulation and real data analysis.",
            "To demonstrate the asymptotic normality of    \\boldsymbol{\\beta} bold_italic_  and  V   superscript V superscript  V^{\\pi^{*}} italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT  in Theorem  4.3 - 4.4 , we estimate the asymptotic variance and verify whether the true value of    \\boldsymbol{\\beta} bold_italic_  and  V   superscript V superscript  V^{\\pi^{*}} italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT  falls within the estimated confidence interval with a high probability of coverage under  B = 1000 B 1000 B=1000 italic_B = 1000  times of replicates. By Equation ( 15 ) and ( 17 ),    \\boldsymbol{\\beta} bold_italic_  falls into the confidence region if and only if  N   t  4  (  ^   ) T  G  (  ^   )    2  ( 2  d ) , subscript   N t superscript  4 superscript ^   T G ^   superscript subscript   2 2 d \\frac{\\bar{N}_{t}}{\\sigma^{4}}(\\widehat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta}% )^{T}G(\\widehat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta})\\leq\\chi_{\\alpha}^{2}(2% d), divide start_ARG over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG start_ARG italic_ start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT end_ARG ( over^ start_ARG bold_italic_ end_ARG - bold_italic_ ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_G ( over^ start_ARG bold_italic_ end_ARG - bold_italic_ )  italic_ start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( 2 italic_d ) ,  where  d  f = 2  d d f 2 d df=2d italic_d italic_f = 2 italic_d  is the degree of freedom of the chi-square distribution. Similarly,  V   superscript V superscript  V^{\\pi^{*}} italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT  falls into the confidence interval if and only if  N   t  | V ^ t DR  V   |  z  / 2   V . subscript   N t subscript superscript ^ V DR t superscript V superscript  subscript z  2 subscript  V \\sqrt{\\bar{N}_{t}}|\\widehat{V}^{\\text{DR}}_{t}-V^{\\pi^{*}}|\\leq z_{\\alpha/2}{% \\sigma_{V}}. square-root start_ARG over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG | over^ start_ARG italic_V end_ARG start_POSTSUPERSCRIPT DR end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT |  italic_z start_POSTSUBSCRIPT italic_ / 2 end_POSTSUBSCRIPT italic_ start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT .  Detailed simulation setup is summarized in Appendix  A.1 .",
            "Coverage probabilities of the OLS estimator   ^ ^  \\widehat{\\boldsymbol{\\beta}} over^ start_ARG bold_italic_ end_ARG  and optimal value function  V   superscript V superscript  V^{\\pi^{*}} italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT  under three exploration algorithms (LinEGWI, LinUCBWI, and LinTSWI) are shown in Figure  1 . As we can see, the coverage consistently hovers around  95 % percent 95 95\\% 95 % , with the estimated confidence band almost always covering the red line. This result supports the validity of the statistical inference presented in Theorems  4.3  and  4.4 .",
            "We fit a linear regression model to  R t  i subscript R t i R_{ti} italic_R start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT  to estimate   0 subscript  0 \\boldsymbol{\\beta}_{0} bold_italic_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ,   1 subscript  1 \\boldsymbol{\\beta}_{1} bold_italic_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , and    \\sigma italic_  as specified in Equation ( 3 ). We then use these estimated values to regenerate  R ~ t  i subscript ~ R t i \\widetilde{R}_{ti} over~ start_ARG italic_R end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT , which we assume represents the true reward of user  i i i italic_i  at round  t t t italic_t .",
            "The comparison results for each case are shown in Figure  3 . In both figures, our algorithms that account for interference consistently outperform classical contextual bandit approaches. Notably, in the case of reward-generating Model I, there is a gap of average reward between our algorithms and the oracle model, which disappears in reward-generating Model II. This gap likely arises because the true reward model may not be linear. Despite so, the effectiveness of our approach can be validated through both scenarios as it consistently outperforms baselines due to its ability to account for the potential interference structure.",
            "The extension to  K > 2 K 2 K>2 italic_K > 2  arms is generally straightforward from an algorithmic perspective. Specifically, when  A = [ K ] A delimited-[] K \\mathcal{A}=[K] caligraphic_A = [ italic_K ] , one can still follow Equation ( 3 ) and easily extend the algorithm by modifying Line 9 of Algorithm  1  to   ^ t  i = arg  max a  {  t  i  X t  i    ^ t  1 , a } subscript ^  t i subscript a subscript  t i superscript subscript X t i  subscript ^  t 1 a \\widehat{\\pi}_{ti}=\\arg\\max_{a}\\big{\\{}\\omega_{ti}\\boldsymbol{X}_{ti}^{\\prime}% \\widehat{\\boldsymbol{\\beta}}_{t-1,a}\\big{\\}} over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT = roman_arg roman_max start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT { italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT italic_t - 1 , italic_a end_POSTSUBSCRIPT } , thereby making the entire system applicable to multi-armed scenarios.",
            "Following the reward generating process described in Equation ( 3 ), we uniformly sample   0  Unif  ( 1 , 3 ) similar-to subscript  0 Unif 1 3 \\boldsymbol{\\beta}_{0}\\sim\\text{Unif}(1,3) bold_italic_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT  Unif ( 1 , 3 )  and   1  Unif  (  2 , 5 ) similar-to subscript  1 Unif 2 5 \\boldsymbol{\\beta}_{1}\\sim\\text{Unif}(-2,5) bold_italic_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT  Unif ( - 2 , 5 ) , and replicate this process for  S = 100 S 100 S=100 italic_S = 100  times to test the robustness of different approaches w.r.t. the change of environment. All experiments were conducted on a local computer with 16 GB of memory.",
            "Combining the result of Equation ( 23 ) and ( 24 ), we have",
            "By definition,  |  t  i | = |  t  i  X t  i   (  1   1 ) | = |  t  i |  | f  ( X t  i , 1 )  f  ( X t  i , 0 ) | subscript  t i subscript  t i superscript subscript X t i  subscript  1 subscript  1  subscript  t i f subscript X t i 1 f subscript X t i 0 |{\\zeta}_{ti}|=|\\omega_{ti}\\boldsymbol{X}_{ti}^{\\prime}(\\boldsymbol{\\beta}_{1}% -\\boldsymbol{\\beta}_{1})|=|\\omega_{ti}|\\cdot\\big{|}f(\\boldsymbol{X}_{ti},1)-f(% \\boldsymbol{X}_{ti},0)\\big{|} | italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT | = | italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( bold_italic_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - bold_italic_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) | = | italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT |  | italic_f ( bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT , 1 ) - italic_f ( bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT , 0 ) | . Since  W t , i  i = 1 subscript W t i i 1 W_{t,ii}=1 italic_W start_POSTSUBSCRIPT italic_t , italic_i italic_i end_POSTSUBSCRIPT = 1 , we always have  |  t  i |  1 subscript  t i 1 |\\omega_{ti}|\\geq 1 | italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT |  1  for any round-unit pair  ( t , i ) t i (t,i) ( italic_t , italic_i ) . Therefore,  |  t  i |  | f  ( X t  i , 1 )  f  ( X t  i , 0 ) | subscript  t i f subscript X t i 1 f subscript X t i 0 |{\\zeta}_{ti}|\\geq\\big{|}f(\\boldsymbol{X}_{ti},1)-f(\\boldsymbol{X}_{ti},0)\\big% {|} | italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT |  | italic_f ( bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT , 1 ) - italic_f ( bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT , 0 ) | . According to Assumption  3 , there exists some constant    \\gamma italic_  such that  P  { |  t  i | < 2    L w  L x N   t  1  p t  1   +  }  P  { | f  ( X t  i , 1 )  f  ( X t  i , 0 ) | < 2    L w  L x N   t  1  p t  1   +  }  O  { ( 2    L w  L x N   t  1  p t  1   +  )  } P subscript  t i 2  subscript L w subscript L x subscript   N t 1 subscript p t 1   P f subscript X t i 1 f subscript X t i 0 2  subscript L w subscript L x subscript   N t 1 subscript p t 1   O superscript 2  subscript L w subscript L x subscript   N t 1 subscript p t 1    \\mathbb{P}\\Big{\\{}|{\\zeta}_{ti}|<\\frac{2\\alpha L_{w}L_{x}}{\\sqrt{\\bar{N}_{t-1}% p_{t-1}\\lambda}}+\\xi\\Big{\\}}\\leq\\mathbb{P}\\Big{\\{}\\big{|}f(\\boldsymbol{X}_{ti}% ,1)-f(\\boldsymbol{X}_{ti},0)\\big{|}<\\frac{2\\alpha L_{w}L_{x}}{\\sqrt{\\bar{N}_{t% -1}p_{t-1}\\lambda}}+\\xi\\Big{\\}}\\leq O\\Big{\\{}\\big{(}\\frac{2\\alpha L_{w}L_{x}}{% \\sqrt{\\bar{N}_{t-1}p_{t-1}\\lambda}}+\\xi\\big{)}^{\\gamma}\\Big{\\}} blackboard_P { | italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT | < divide start_ARG 2 italic_ italic_L start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT italic_L start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT end_ARG start_ARG square-root start_ARG over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT italic_ end_ARG end_ARG + italic_ }  blackboard_P { | italic_f ( bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT , 1 ) - italic_f ( bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT , 0 ) | < divide start_ARG 2 italic_ italic_L start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT italic_L start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT end_ARG start_ARG square-root start_ARG over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT italic_ end_ARG end_ARG + italic_ }  italic_O { ( divide start_ARG 2 italic_ italic_L start_POSTSUBSCRIPT italic_w end_POSTSUBSCRIPT italic_L start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT end_ARG start_ARG square-root start_ARG over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT italic_ end_ARG end_ARG + italic_ ) start_POSTSUPERSCRIPT italic_ end_POSTSUPERSCRIPT } .",
            "On event  E = { |  ^ t  i   t  i |   } E subscript ^  t i subscript  t i  E=\\big{\\{}|\\widehat{\\zeta}_{ti}-{\\zeta}_{ti}|\\leq\\xi\\big{\\}} italic_E = { | over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT - italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT |  italic_ } , recall that   t  i > 0 subscript  t i 0 {\\zeta}_{ti}>0 italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT > 0  would result in   ^ t  i > 0 subscript ^  t i 0 \\widehat{\\zeta}_{ti}>0 over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT > 0  as well. According to the distribution we derived in Equation ( 33 ), we have",
            "Combining the result above to Equation ( 34 ), we can further derive",
            "Combining the results of Equation ( 32 ) and ( 35 ), we finally have",
            "First, we show   1 = o p  ( 1 ) subscript  1 subscript o p 1 \\boldsymbol{\\zeta}_{1}=o_{p}(1) bold_italic_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_o start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( 1 ) . According to Theorem  4.3 ,   ^ t  i   t  i = O p  ( N   t  1 / 2 ) = o p  ( N   t  ( 1 / 2     ) ) subscript ^  t i subscript  t i subscript O p superscript subscript   N t 1 2 subscript o p superscript subscript   N t 1 2   \\widehat{\\zeta}_{ti}-{\\zeta}_{ti}=O_{p}(\\bar{N}_{t}^{-1/2})=o_{p}(\\bar{N}_{t}^% {-(1/2-\\alpha\\gamma)}) over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT - italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT = italic_O start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 / 2 end_POSTSUPERSCRIPT ) = italic_o start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - ( 1 / 2 - italic_ italic_ ) end_POSTSUPERSCRIPT )  for any     > 0   0 \\alpha\\gamma>0 italic_ italic_ > 0 . Therefore,",
            "Since  |  |  1  1 |\\omega|\\geq 1 | italic_ |  1 , by setting   = N   T   italic- superscript subscript   N T  \\epsilon=\\bar{N}_{T}^{-\\alpha} italic_ = over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_ end_POSTSUPERSCRIPT  in Assumption  3 , we have  P  ( 0 < |   f  ( X , 1 )    f  ( X , 0 ) | < N   T   )  P  ( 0 < | f  ( X , 1 )  f  ( X , 0 ) | < N   T   ) = O  ( N   T     ) P 0  f X 1  f X 0 superscript subscript   N T  P 0 f X 1 f X 0 superscript subscript   N T  O superscript subscript   N T   \\mathbb{P}\\left(0<|\\omega f(\\boldsymbol{X},1)-\\omega f(\\boldsymbol{X},0)|<\\bar% {N}_{T}^{-\\alpha}\\right)\\leq\\mathbb{P}\\left(0<|f(\\boldsymbol{X},1)-f(% \\boldsymbol{X},0)|<\\bar{N}_{T}^{-\\alpha}\\right)=O(\\bar{N}_{T}^{-\\alpha\\gamma}) blackboard_P ( 0 < | italic_ italic_f ( bold_italic_X , 1 ) - italic_ italic_f ( bold_italic_X , 0 ) | < over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_ end_POSTSUPERSCRIPT )  blackboard_P ( 0 < | italic_f ( bold_italic_X , 1 ) - italic_f ( bold_italic_X , 0 ) | < over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_ end_POSTSUPERSCRIPT ) = italic_O ( over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - italic_ italic_ end_POSTSUPERSCRIPT ) . Therefore,",
            "By Theorem  4.3 ,  |  ^ t  i   t  i | = O p  ( N   t  1 / 2 ) subscript ^  t i subscript  t i subscript O p superscript subscript   N t 1 2 |\\widehat{\\zeta}_{ti}-\\zeta_{ti}|=O_{p}(\\bar{N}_{t}^{-1/2}) | over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT - italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT | = italic_O start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 / 2 end_POSTSUPERSCRIPT ) , which implies  |  ^ t  i   t  i | 2 = O p  ( N   t  1 ) superscript subscript ^  t i subscript  t i 2 subscript O p superscript subscript   N t 1 |\\widehat{\\zeta}_{ti}-\\zeta_{ti}|^{2}=O_{p}(\\bar{N}_{t}^{-1}) | over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT - italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = italic_O start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ) . According to Lemma 6 of  Luedtke and Van Der Laan [ 2016 ] ,  N   T  1   t = 1 T  i = 1 N t |  ^ t  i   t  i | 2 = O p  ( N   T  1 ) superscript subscript   N T 1 superscript subscript t 1 T superscript subscript i 1 subscript N t superscript subscript ^  t i subscript  t i 2 subscript O p superscript subscript   N T 1 {\\bar{N}_{T}}^{-1}\\sum_{t=1}^{T}\\sum_{i=1}^{N_{t}}|\\widehat{\\zeta}_{ti}-\\zeta_% {ti}|^{2}=O_{p}(\\bar{N}_{T}^{-1}) over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT  start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT  start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUPERSCRIPT | over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT - italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = italic_O start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ) . Therefore,",
            "Combining the result of Equation ( 63 ) and Equation ( 65 ), we have",
            "where  q q q italic_q  denotes an unit in a flattened unit queue  Q  ( t , i ) =  s = 1 t  1 N s + i Q t i superscript subscript s 1 t 1 subscript N s i Q(t,i)=\\sum_{s=1}^{t-1}N_{s}+i italic_Q ( italic_t , italic_i ) =  start_POSTSUBSCRIPT italic_s = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t - 1 end_POSTSUPERSCRIPT italic_N start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT + italic_i . Similar to the the proof of Theorem  4.3 , we define  H q subscript H q \\mathcal{H}_{q} caligraphic_H start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT  as the    limit-from  \\sigma- italic_ - algebra containing the information up to unit  q q q italic_q  where  H q 0 =   ( v   X ~ 1   1 , ... , v   X ~ q 0   q 0 ) subscript H subscript q 0  superscript v  subscript ~ X 1 subscript italic- 1 ... superscript v  subscript ~ X subscript q 0 subscript italic- subscript q 0 \\mathcal{H}_{q_{0}}=\\sigma(\\boldsymbol{v}^{\\prime}\\widetilde{\\boldsymbol{X}}_{% 1}\\epsilon_{1},\\dots,\\boldsymbol{v}^{\\prime}\\widetilde{\\boldsymbol{X}}_{q_{0}}% \\epsilon_{q_{0}}) caligraphic_H start_POSTSUBSCRIPT italic_q start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPT = italic_ ( bold_italic_v start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT over~ start_ARG bold_italic_X end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ... , bold_italic_v start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT over~ start_ARG bold_italic_X end_ARG start_POSTSUBSCRIPT italic_q start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_ start_POSTSUBSCRIPT italic_q start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) ."
        ]
    },
    "id_table_4": {
        "caption": "",
        "table": "S3.E8",
        "footnotes": [],
        "references": [
            "In an offline optimization setting, one can replace the true value of    \\boldsymbol{\\beta} bold_italic_  in Equation ( 4 ) with   ^ t  superscript subscript ^  t \\widehat{\\boldsymbol{\\beta}}_{t}^{*} over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT  to obtain an estimate of the optimal individualized treatment rule.",
            "Remark.  Theorem  4.3  establishes the asymptotic normality of the online OLS estimator, providing an explicit form for its asymptotic variance. This result holds for the EG, UCB, and TS algorithms used for exploration. Despite the presence of interference, the asymptotic normality of the estimator only requires the total number of units  N   t subscript   N t \\bar{N}_{t} over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  to approach infinity. In other words, bidirectional asymptotic normality is achieved as long as either  t    t t\\rightarrow\\infty italic_t    or the number of units at some stage  N t    subscript N t N_{t}\\rightarrow\\infty italic_N start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT   .",
            "Assumption  4  requires that the convergence rates of the conditional mean function and the estimated probability of exploration satisfy certain conditions. This is a standard assumption in causal inference literature, as noted in  Luedtke and Van Der Laan ( 2016 ); Kennedy ( 2022 ) . In our setting, this assumption is almost always satisfied, given that    ^ t  1 ( t , i )  ( X t ,  ^ t  1  ( X t ) )   ( t , i )  ( X t ,  ^ t  1  ( X t ) )  2 , N T = O p  ( N   T  1 / 2 ) subscript norm superscript subscript ^  t 1 t i subscript X t subscript ^  t 1 subscript X t superscript  t i subscript X t subscript ^  t 1 subscript X t 2 subscript N T subscript O p superscript subscript   N T 1 2 \\|\\widehat{\\mu}_{t-1}^{(t,i)}(\\boldsymbol{X}_{t},\\widehat{\\pi}_{t-1}(% \\boldsymbol{X}_{t}))-{\\mu}^{(t,i)}(\\boldsymbol{X}_{t},\\widehat{\\pi}_{t-1}(% \\boldsymbol{X}_{t}))\\|_{2,N_{T}}=O_{p}(\\bar{N}_{T}^{-1/2})  over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t , italic_i ) end_POSTSUPERSCRIPT ( bold_italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT ( bold_italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ) - italic_ start_POSTSUPERSCRIPT ( italic_t , italic_i ) end_POSTSUPERSCRIPT ( bold_italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT ( bold_italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) )  start_POSTSUBSCRIPT 2 , italic_N start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT end_POSTSUBSCRIPT = italic_O start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 / 2 end_POSTSUPERSCRIPT )  follows directly from Theorem  4.3 . Therefore, it suffices to ensure that    ^ t  1  (  t  i , X t  i )   t  1  (  t  i , X t  i )  2 , N T = o p  ( 1 ) subscript norm subscript ^  t 1 subscript  t i subscript X t i subscript  t 1 subscript  t i subscript X t i 2 subscript N T subscript o p 1 \\|\\hat{\\kappa}_{t-1}(\\omega_{ti},\\boldsymbol{X}_{ti})-{\\kappa}_{t-1}(\\omega_{% ti},\\boldsymbol{X}_{ti})\\|_{2,N_{T}}=o_{p}(1)  over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT ( italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT , bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT ) - italic_ start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT ( italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT , bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT )  start_POSTSUBSCRIPT 2 , italic_N start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT end_POSTSUBSCRIPT = italic_o start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( 1 )  for Assumption  3  to hold. This can be easily achieved by using a sample-based exploration estimand. In practice, as   ^ t  1  (  t  i , X t  i ) subscript ^  t 1 subscript  t i subscript X t i \\hat{\\kappa}_{t-1}(\\omega_{ti},\\boldsymbol{X}_{ti}) over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT ( italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT , bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT )  tends to be small as  t t t italic_t  increases, we set   ^ t  1  (  t  i , X t  i ) =  s  t  1 , i  [ N s ] 1  { A s  i =  ^  ( X s  i ) } / N   t  1 subscript ^  t 1 subscript  t i subscript X t i subscript formulae-sequence s t 1 i delimited-[] subscript N s 1 subscript A s i ^  subscript X s i subscript   N t 1 \\hat{\\kappa}_{t-1}(\\omega_{ti},\\boldsymbol{X}_{ti})=\\sum_{s\\leq t-1,i\\in[N_{s}% ]}\\boldsymbol{1}\\{A_{si}\\neq\\widehat{\\pi}(\\boldsymbol{X}_{si})\\}/\\bar{N}_{t-1} over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT ( italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT , bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT ) =  start_POSTSUBSCRIPT italic_s  italic_t - 1 , italic_i  [ italic_N start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ] end_POSTSUBSCRIPT bold_1 { italic_A start_POSTSUBSCRIPT italic_s italic_i end_POSTSUBSCRIPT = over^ start_ARG italic_ end_ARG ( bold_italic_X start_POSTSUBSCRIPT italic_s italic_i end_POSTSUBSCRIPT ) } / over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT , which proves to be sufficient in simulation and real data analysis.",
            "Under Assumption  4 , the DR estimator achieves asymptotic normality as the total number of units,  N   t subscript   N t \\bar{N}_{t} over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , approaches infinity. Details are summarized in Theorem  4.4 .",
            "Suppose Assumptions  1 - 4  hold. We have",
            "To demonstrate the asymptotic normality of    \\boldsymbol{\\beta} bold_italic_  and  V   superscript V superscript  V^{\\pi^{*}} italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT  in Theorem  4.3 - 4.4 , we estimate the asymptotic variance and verify whether the true value of    \\boldsymbol{\\beta} bold_italic_  and  V   superscript V superscript  V^{\\pi^{*}} italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT  falls within the estimated confidence interval with a high probability of coverage under  B = 1000 B 1000 B=1000 italic_B = 1000  times of replicates. By Equation ( 15 ) and ( 17 ),    \\boldsymbol{\\beta} bold_italic_  falls into the confidence region if and only if  N   t  4  (  ^   ) T  G  (  ^   )    2  ( 2  d ) , subscript   N t superscript  4 superscript ^   T G ^   superscript subscript   2 2 d \\frac{\\bar{N}_{t}}{\\sigma^{4}}(\\widehat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta}% )^{T}G(\\widehat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta})\\leq\\chi_{\\alpha}^{2}(2% d), divide start_ARG over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG start_ARG italic_ start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT end_ARG ( over^ start_ARG bold_italic_ end_ARG - bold_italic_ ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_G ( over^ start_ARG bold_italic_ end_ARG - bold_italic_ )  italic_ start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( 2 italic_d ) ,  where  d  f = 2  d d f 2 d df=2d italic_d italic_f = 2 italic_d  is the degree of freedom of the chi-square distribution. Similarly,  V   superscript V superscript  V^{\\pi^{*}} italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT  falls into the confidence interval if and only if  N   t  | V ^ t DR  V   |  z  / 2   V . subscript   N t subscript superscript ^ V DR t superscript V superscript  subscript z  2 subscript  V \\sqrt{\\bar{N}_{t}}|\\widehat{V}^{\\text{DR}}_{t}-V^{\\pi^{*}}|\\leq z_{\\alpha/2}{% \\sigma_{V}}. square-root start_ARG over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG | over^ start_ARG italic_V end_ARG start_POSTSUPERSCRIPT DR end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT |  italic_z start_POSTSUBSCRIPT italic_ / 2 end_POSTSUBSCRIPT italic_ start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT .  Detailed simulation setup is summarized in Appendix  A.1 .",
            "Coverage probabilities of the OLS estimator   ^ ^  \\widehat{\\boldsymbol{\\beta}} over^ start_ARG bold_italic_ end_ARG  and optimal value function  V   superscript V superscript  V^{\\pi^{*}} italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT  under three exploration algorithms (LinEGWI, LinUCBWI, and LinTSWI) are shown in Figure  1 . As we can see, the coverage consistently hovers around  95 % percent 95 95\\% 95 % , with the estimated confidence band almost always covering the red line. This result supports the validity of the statistical inference presented in Theorems  4.3  and  4.4 .",
            "Using the same simulation setup as in Section  5.2 , but with the interference matrix  W t subscript W t \\boldsymbol{W}_{t} bold_italic_W start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  replaced by an identity matrix, we compare the results of the classical linear CB algorithm with our proposed methods. The results, shown in Figure  4 , indicate that all methods yield comparable performance over time, with average regrets converging to zero at a rapid rate.",
            "The proof of Theorem  4.1  is thus complete.",
            "Combining the result of Equation ( 23 ) and ( 24 ), we have",
            "According to Theorem  4.1 ,",
            "Combining the result above to Equation ( 34 ), we can further derive",
            "Therefore, by Generalized Dominated Convergence Theorem (GDCT), it follows from Equation ( 42 ) that    E  [ f N   q | H q  1 ]  0  E delimited-[] conditional subscript f subscript   N q subscript H q 1  0 \\psi\\leq\\mathbb{E}[f_{\\bar{N}_{q}}|\\mathcal{H}_{q-1}]\\rightarrow 0 italic_  blackboard_E [ italic_f start_POSTSUBSCRIPT over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT end_POSTSUBSCRIPT | caligraphic_H start_POSTSUBSCRIPT italic_q - 1 end_POSTSUBSCRIPT ]  0  as  q    q q\\rightarrow\\infty italic_q   . The Lindeberg condition is thus verified.",
            "Plugging in the result of Equation ( 46 ), ( 47 ) to Equation ( 45 ), one can obtain",
            "where the detailed expression of each submatrix in  G G G italic_G  is given in Equation ( 48 )-( 49 ).",
            "Based on Lemma 6 of  Chen et al. [ 2021 ] , it suffice to find the limit of  1 N   q   q = 1 N   q v   X ~ q  X ~ q   v 1 subscript   N q superscript subscript q 1 subscript   N q superscript v  subscript ~ X q superscript subscript ~ X q  v \\frac{1}{\\bar{N}_{q}}\\sum_{q=1}^{\\bar{N}_{q}}\\boldsymbol{v}^{\\prime}\\widetilde% {\\boldsymbol{X}}_{q}\\widetilde{\\boldsymbol{X}}_{q}^{\\prime}\\boldsymbol{v} divide start_ARG 1 end_ARG start_ARG over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT end_ARG  start_POSTSUBSCRIPT italic_q = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT end_POSTSUPERSCRIPT bold_italic_v start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT over~ start_ARG bold_italic_X end_ARG start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT over~ start_ARG bold_italic_X end_ARG start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT bold_italic_v . According to Equation ( 41 ), we have",
            "Combining the above three steps, the proof of theorem  4.4  is thus complete.",
            "where the last line holds by Cauchy-Schwartz inequality, and the last line holds by Assumption  4 .",
            "First, we show   1 = o p  ( 1 ) subscript  1 subscript o p 1 \\boldsymbol{\\zeta}_{1}=o_{p}(1) bold_italic_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_o start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( 1 ) . According to Theorem  4.3 ,   ^ t  i   t  i = O p  ( N   t  1 / 2 ) = o p  ( N   t  ( 1 / 2     ) ) subscript ^  t i subscript  t i subscript O p superscript subscript   N t 1 2 subscript o p superscript subscript   N t 1 2   \\widehat{\\zeta}_{ti}-{\\zeta}_{ti}=O_{p}(\\bar{N}_{t}^{-1/2})=o_{p}(\\bar{N}_{t}^% {-(1/2-\\alpha\\gamma)}) over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT - italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT = italic_O start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 / 2 end_POSTSUPERSCRIPT ) = italic_o start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - ( 1 / 2 - italic_ italic_ ) end_POSTSUPERSCRIPT )  for any     > 0   0 \\alpha\\gamma>0 italic_ italic_ > 0 . Therefore,",
            "Since we assumed that   t  i > 0 subscript  t i 0 \\zeta_{ti}>0 italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT > 0 , based on the result of Equation ( 64 ), we further have",
            "By Theorem  4.3 ,  |  ^ t  i   t  i | = O p  ( N   t  1 / 2 ) subscript ^  t i subscript  t i subscript O p superscript subscript   N t 1 2 |\\widehat{\\zeta}_{ti}-\\zeta_{ti}|=O_{p}(\\bar{N}_{t}^{-1/2}) | over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT - italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT | = italic_O start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 / 2 end_POSTSUPERSCRIPT ) , which implies  |  ^ t  i   t  i | 2 = O p  ( N   t  1 ) superscript subscript ^  t i subscript  t i 2 subscript O p superscript subscript   N t 1 |\\widehat{\\zeta}_{ti}-\\zeta_{ti}|^{2}=O_{p}(\\bar{N}_{t}^{-1}) | over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT - italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = italic_O start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ) . According to Lemma 6 of  Luedtke and Van Der Laan [ 2016 ] ,  N   T  1   t = 1 T  i = 1 N t |  ^ t  i   t  i | 2 = O p  ( N   T  1 ) superscript subscript   N T 1 superscript subscript t 1 T superscript subscript i 1 subscript N t superscript subscript ^  t i subscript  t i 2 subscript O p superscript subscript   N T 1 {\\bar{N}_{T}}^{-1}\\sum_{t=1}^{T}\\sum_{i=1}^{N_{t}}|\\widehat{\\zeta}_{ti}-\\zeta_% {ti}|^{2}=O_{p}(\\bar{N}_{T}^{-1}) over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT  start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT  start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUPERSCRIPT | over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT - italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = italic_O start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ) . Therefore,",
            "where  q q q italic_q  denotes an unit in a flattened unit queue  Q  ( t , i ) =  s = 1 t  1 N s + i Q t i superscript subscript s 1 t 1 subscript N s i Q(t,i)=\\sum_{s=1}^{t-1}N_{s}+i italic_Q ( italic_t , italic_i ) =  start_POSTSUBSCRIPT italic_s = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t - 1 end_POSTSUPERSCRIPT italic_N start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT + italic_i . Similar to the the proof of Theorem  4.3 , we define  H q subscript H q \\mathcal{H}_{q} caligraphic_H start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT  as the    limit-from  \\sigma- italic_ - algebra containing the information up to unit  q q q italic_q  where  H q 0 =   ( v   X ~ 1   1 , ... , v   X ~ q 0   q 0 ) subscript H subscript q 0  superscript v  subscript ~ X 1 subscript italic- 1 ... superscript v  subscript ~ X subscript q 0 subscript italic- subscript q 0 \\mathcal{H}_{q_{0}}=\\sigma(\\boldsymbol{v}^{\\prime}\\widetilde{\\boldsymbol{X}}_{% 1}\\epsilon_{1},\\dots,\\boldsymbol{v}^{\\prime}\\widetilde{\\boldsymbol{X}}_{q_{0}}% \\epsilon_{q_{0}}) caligraphic_H start_POSTSUBSCRIPT italic_q start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPT = italic_ ( bold_italic_v start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT over~ start_ARG bold_italic_X end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ... , bold_italic_v start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT over~ start_ARG bold_italic_X end_ARG start_POSTSUBSCRIPT italic_q start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_ start_POSTSUBSCRIPT italic_q start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) .",
            "Notice that in the proof of Theorem  4.4 , step 2.1, weve proved in Equation ( 61 ) that",
            "According to the upper bound derived in Theorem  4.2 ,",
            "Now lets decompose according to different exploration algorithms. For simplicity of notations, we continue with the flattened unit queue  q = Q  ( t , i )   s = 1 t  1 N s + t q Q t i superscript subscript s 1 t 1 subscript N s t q=Q(t,i)\\sum_{s=1}^{t-1}N_{s}+t italic_q = italic_Q ( italic_t , italic_i )  start_POSTSUBSCRIPT italic_s = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t - 1 end_POSTSUPERSCRIPT italic_N start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT + italic_t  as shown in the proof of Theorem  4.1 . As such, we can extend the definition of  p t subscript p t p_{t} italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  to  p q subscript p q p_{q} italic_p start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT  by simply setting  p q = p t subscript p q subscript p t p_{q}=p_{t} italic_p start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT = italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  for any unit  q q q italic_q  in round  t t t italic_t . As such,  p q subscript p q p_{q} italic_p start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT  is still a non-increasing sequence w.r.t.  q q q italic_q . By Theorem  4.2 , we have"
        ]
    },
    "id_table_5": {
        "caption": "",
        "table": "S3.E10",
        "footnotes": [],
        "references": [
            "where  G G G italic_G  is specified in Equation ( 50 ) in Appendix.",
            "To demonstrate the asymptotic normality of    \\boldsymbol{\\beta} bold_italic_  and  V   superscript V superscript  V^{\\pi^{*}} italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT  in Theorem  4.3 - 4.4 , we estimate the asymptotic variance and verify whether the true value of    \\boldsymbol{\\beta} bold_italic_  and  V   superscript V superscript  V^{\\pi^{*}} italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT  falls within the estimated confidence interval with a high probability of coverage under  B = 1000 B 1000 B=1000 italic_B = 1000  times of replicates. By Equation ( 15 ) and ( 17 ),    \\boldsymbol{\\beta} bold_italic_  falls into the confidence region if and only if  N   t  4  (  ^   ) T  G  (  ^   )    2  ( 2  d ) , subscript   N t superscript  4 superscript ^   T G ^   superscript subscript   2 2 d \\frac{\\bar{N}_{t}}{\\sigma^{4}}(\\widehat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta}% )^{T}G(\\widehat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta})\\leq\\chi_{\\alpha}^{2}(2% d), divide start_ARG over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG start_ARG italic_ start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT end_ARG ( over^ start_ARG bold_italic_ end_ARG - bold_italic_ ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_G ( over^ start_ARG bold_italic_ end_ARG - bold_italic_ )  italic_ start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( 2 italic_d ) ,  where  d  f = 2  d d f 2 d df=2d italic_d italic_f = 2 italic_d  is the degree of freedom of the chi-square distribution. Similarly,  V   superscript V superscript  V^{\\pi^{*}} italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT  falls into the confidence interval if and only if  N   t  | V ^ t DR  V   |  z  / 2   V . subscript   N t subscript superscript ^ V DR t superscript V superscript  subscript z  2 subscript  V \\sqrt{\\bar{N}_{t}}|\\widehat{V}^{\\text{DR}}_{t}-V^{\\pi^{*}}|\\leq z_{\\alpha/2}{% \\sigma_{V}}. square-root start_ARG over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG | over^ start_ARG italic_V end_ARG start_POSTSUPERSCRIPT DR end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT |  italic_z start_POSTSUBSCRIPT italic_ / 2 end_POSTSUBSCRIPT italic_ start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT .  Detailed simulation setup is summarized in Appendix  A.1 .",
            "Using the same simulation setup as in Section  5.2 , but with the interference matrix  W t subscript W t \\boldsymbol{W}_{t} bold_italic_W start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  replaced by an identity matrix, we compare the results of the classical linear CB algorithm with our proposed methods. The results, shown in Figure  4 , indicate that all methods yield comparable performance over time, with average regrets converging to zero at a rapid rate.",
            "Combining the result above and Equation ( 25 ), we have",
            "Combining the results of Equation ( 32 ) and ( 35 ), we finally have",
            "Plugging in the result of Equation ( 46 ), ( 47 ) to Equation ( 45 ), one can obtain",
            "where  G G G italic_G  is specified in Equation ( 50 ).",
            "Therefore, Equation ( 55 ) can be simplified as",
            "Combining the results of Equation ( 57 ) and ( 58 ), we have",
            "Combining the result of Equation ( 63 ) and Equation ( 65 ), we have",
            "Following a similar derivation structure as that used between Equation ( 55 ) and Equation ( 56 ) in Step 1, we have"
        ]
    },
    "id_table_6": {
        "caption": "",
        "table": "S3.Ex4",
        "footnotes": [],
        "references": [
            "Define   ^ t  1  ( X t  i ) = |  t  i |  X t  i   ( X ~ 1 : ( t  1 )   X ~ 1 : ( t  1 ) ) 1  1  X t  i subscript ^  t 1 subscript X t i subscript  t i superscript subscript X t i  subscript superscript superscript subscript ~ X : 1 t 1  subscript ~ X : 1 t 1 1 1 subscript X t i \\widehat{\\sigma}_{t1}(\\boldsymbol{X}_{ti})=|\\omega_{ti}|\\sqrt{\\boldsymbol{X}_{% ti}^{\\prime}\\left(\\widetilde{\\boldsymbol{X}}_{1:(t-1)}^{\\prime}\\widetilde{% \\boldsymbol{X}}_{1:(t-1)}\\right)^{-1}_{1}\\boldsymbol{X}_{ti}} over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t 1 end_POSTSUBSCRIPT ( bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT ) = | italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT | square-root start_ARG bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( over~ start_ARG bold_italic_X end_ARG start_POSTSUBSCRIPT 1 : ( italic_t - 1 ) end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT over~ start_ARG bold_italic_X end_ARG start_POSTSUBSCRIPT 1 : ( italic_t - 1 ) end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT end_ARG , and   ^ t  0  ( X t  i ) = |  t  i |  X t  i   ( X ~ 1 : ( t  1 )   X ~ 1 : ( t  1 ) ) 0  1  X t  i subscript ^  t 0 subscript X t i subscript  t i superscript subscript X t i  subscript superscript superscript subscript ~ X : 1 t 1  subscript ~ X : 1 t 1 1 0 subscript X t i \\widehat{\\sigma}_{t0}(\\boldsymbol{X}_{ti})=|\\omega_{ti}|\\sqrt{\\boldsymbol{X}_{% ti}^{\\prime}\\left(\\widetilde{\\boldsymbol{X}}_{1:(t-1)}^{\\prime}\\widetilde{% \\boldsymbol{X}}_{1:(t-1)}\\right)^{-1}_{0}\\boldsymbol{X}_{ti}} over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t 0 end_POSTSUBSCRIPT ( bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT ) = | italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT | square-root start_ARG bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( over~ start_ARG bold_italic_X end_ARG start_POSTSUBSCRIPT 1 : ( italic_t - 1 ) end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT over~ start_ARG bold_italic_X end_ARG start_POSTSUBSCRIPT 1 : ( italic_t - 1 ) end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT end_ARG . According to the upper bound derived in Equation ( 26 ), we have",
            "Plugging in the result of Equation ( 46 ), ( 47 ) to Equation ( 45 ), one can obtain",
            "Since we assumed that   t  i > 0 subscript  t i 0 \\zeta_{ti}>0 italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT > 0 , based on the result of Equation ( 64 ), we further have",
            "Combining the result of Equation ( 63 ) and Equation ( 65 ), we have",
            "Therefore, Equation ( 68 ) can be simplified as",
            "Following a similar derivation structure as that used between Equation ( 55 ) and Equation ( 56 ) in Step 1, we have",
            "which has already been established in Equation ( 61 ) in Step 2.1. Therefore,   4 = o p  ( 1 ) subscript  4 subscript o p 1 \\boldsymbol{\\zeta}_{4}=o_{p}(1) bold_italic_ start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = italic_o start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( 1 ) .",
            "Given the derivation of Equation ( 62 ), we have",
            "Notice that in the proof of Theorem  4.4 , step 2.1, weve proved in Equation ( 61 ) that"
        ]
    },
    "id_table_7": {
        "caption": "",
        "table": "S4.E13",
        "footnotes": [],
        "references": [
            "To demonstrate the asymptotic normality of    \\boldsymbol{\\beta} bold_italic_  and  V   superscript V superscript  V^{\\pi^{*}} italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT  in Theorem  4.3 - 4.4 , we estimate the asymptotic variance and verify whether the true value of    \\boldsymbol{\\beta} bold_italic_  and  V   superscript V superscript  V^{\\pi^{*}} italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT  falls within the estimated confidence interval with a high probability of coverage under  B = 1000 B 1000 B=1000 italic_B = 1000  times of replicates. By Equation ( 15 ) and ( 17 ),    \\boldsymbol{\\beta} bold_italic_  falls into the confidence region if and only if  N   t  4  (  ^   ) T  G  (  ^   )    2  ( 2  d ) , subscript   N t superscript  4 superscript ^   T G ^   superscript subscript   2 2 d \\frac{\\bar{N}_{t}}{\\sigma^{4}}(\\widehat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta}% )^{T}G(\\widehat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta})\\leq\\chi_{\\alpha}^{2}(2% d), divide start_ARG over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG start_ARG italic_ start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT end_ARG ( over^ start_ARG bold_italic_ end_ARG - bold_italic_ ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_G ( over^ start_ARG bold_italic_ end_ARG - bold_italic_ )  italic_ start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( 2 italic_d ) ,  where  d  f = 2  d d f 2 d df=2d italic_d italic_f = 2 italic_d  is the degree of freedom of the chi-square distribution. Similarly,  V   superscript V superscript  V^{\\pi^{*}} italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT  falls into the confidence interval if and only if  N   t  | V ^ t DR  V   |  z  / 2   V . subscript   N t subscript superscript ^ V DR t superscript V superscript  subscript z  2 subscript  V \\sqrt{\\bar{N}_{t}}|\\widehat{V}^{\\text{DR}}_{t}-V^{\\pi^{*}}|\\leq z_{\\alpha/2}{% \\sigma_{V}}. square-root start_ARG over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG | over^ start_ARG italic_V end_ARG start_POSTSUPERSCRIPT DR end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT |  italic_z start_POSTSUBSCRIPT italic_ / 2 end_POSTSUBSCRIPT italic_ start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT .  Detailed simulation setup is summarized in Appendix  A.1 .",
            "Step 3:  Further bound the RHS of Equation ( 27 ).",
            "On event  E E E italic_E , we have  |  ^ t  i |  |  t  i |  |  ^ t  i   t  i |  |  t  i |   subscript ^  t i subscript  t i subscript ^  t i subscript  t i subscript  t i  |\\widehat{\\zeta}_{ti}|\\geq|{\\zeta}_{ti}|-|\\widehat{\\zeta}_{ti}-{\\zeta}_{ti}|% \\geq|{\\zeta}_{ti}|-\\xi | over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT |  | italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT | - | over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT - italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT |  | italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT | - italic_ . Then going back to Equation ( 27 ), we further have",
            "Plugging in the result of Equation ( 46 ), ( 47 ) to Equation ( 45 ), one can obtain",
            "Combining the results of Equation ( 57 ) and ( 58 ), we have"
        ]
    },
    "id_table_8": {
        "caption": "",
        "table": "S4.E14",
        "footnotes": [],
        "references": [
            "Remark.  The asymptotic variance of the optimal value function comprises two components. The first term arises from the IPW estimator and accounts for the variance of the random noise   t  i subscript italic- t i \\epsilon_{ti} italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT  The second term originates from the DM estimator and captures the variance due to uncertainty in the context  x x \\boldsymbol{x} bold_italic_x  and the interference weight    \\omega italic_ . Notably, our theorem extends the results of  Ye et al. ( 2023 )  by establishing the asymptotic properties of the estimated optimal value function under interference. In the special case where    1  1 \\omega\\equiv 1 italic_  1  in Equation ( 18 ), our results reduce to theirs.",
            "In the estimation of  V    superscript V  V^{\\pi*} italic_V start_POSTSUPERSCRIPT italic_  end_POSTSUPERSCRIPT , for a more balanced variance composition in Equation ( 18 ), we set up the data generating process for  W t subscript W t \\boldsymbol{W}_{t} bold_italic_W start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  and  X t  i subscript X t i \\boldsymbol{X}_{ti} bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT  as follows. For each  i = j i j i\\neq j italic_i = italic_j , we generate  W t , i  j    Unif  (  0.2 ,  0.1 ) + ( 1   )  Unif  ( 0.05 , 0.2 ) similar-to subscript W t i j   Unif 0.2 0.1  1  Unif 0.05 0.2 W_{t,ij}\\sim\\alpha\\cdot\\text{Unif}(-0.2,-0.1)+(1-\\alpha)\\cdot\\text{Unif}(0.05,% 0.2) italic_W start_POSTSUBSCRIPT italic_t , italic_i italic_j end_POSTSUBSCRIPT  italic_  Unif ( - 0.2 , - 0.1 ) + ( 1 - italic_ )  Unif ( 0.05 , 0.2 ) , where    Bernoulli  ( 0.5 ) similar-to  Bernoulli 0.5 \\alpha\\sim\\text{Bernoulli}(0.5) italic_  Bernoulli ( 0.5 ) . For contextual information, we generate  X t  i = ( X t  i , 1 , ... , X t  i , 3 )  R 3 subscript X t i subscript X t i 1 ... subscript X t i 3 superscript R 3 \\boldsymbol{X}_{ti}=(X_{ti,1},\\dots,X_{ti,3})\\in\\mathbb{R}^{3} bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT = ( italic_X start_POSTSUBSCRIPT italic_t italic_i , 1 end_POSTSUBSCRIPT , ... , italic_X start_POSTSUBSCRIPT italic_t italic_i , 3 end_POSTSUBSCRIPT )  blackboard_R start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT  for unit  i i i italic_i  at round  t t t italic_t , where  X t  i , 1  0.2 subscript X t i 1 0.2 X_{ti,1}\\equiv 0.2 italic_X start_POSTSUBSCRIPT italic_t italic_i , 1 end_POSTSUBSCRIPT  0.2 ,  X t  i , 2  N  ( 0.8 , 0.04 ) similar-to subscript X t i 2 N 0.8 0.04 X_{ti,2}\\sim\\mathcal{N}(0.8,0.04) italic_X start_POSTSUBSCRIPT italic_t italic_i , 2 end_POSTSUBSCRIPT  caligraphic_N ( 0.8 , 0.04 ) ,  X t  i , 3  Unif  ( 0 , 0.6 ) similar-to subscript X t i 3 Unif 0 0.6 X_{ti,3}\\sim\\text{Unif}(0,0.6) italic_X start_POSTSUBSCRIPT italic_t italic_i , 3 end_POSTSUBSCRIPT  Unif ( 0 , 0.6 ) , and all of the samples are i.i.d. over  ( t , i ) t i (t,i) ( italic_t , italic_i ) .",
            "Similar to Step 3 of Section  C.1 , we define an event  E := { |  ^ t  i   t  i |   } assign E subscript ^  t i subscript  t i  E:=\\big{\\{}|\\widehat{\\zeta}_{ti}-{\\zeta}_{ti}|\\leq\\xi\\big{\\}} italic_E := { | over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT - italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT |  italic_ }  for any    ( 0 , |  t  i | / 2 )  0 subscript  t i 2 \\xi\\in(0,|{\\zeta}_{ti}|/2) italic_  ( 0 , | italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT | / 2 ) , where   ^ t  i =  t  i  X t  i   (  ^ t  1   ^ t  0 ) subscript ^  t i subscript  t i superscript subscript X t i  subscript ^  t 1 subscript ^  t 0 \\widehat{\\zeta}_{ti}=\\omega_{ti}\\boldsymbol{X}_{ti}^{\\prime}(\\widehat{% \\boldsymbol{\\beta}}_{t1}-\\widehat{\\boldsymbol{\\beta}}_{t0}) over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT = italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT italic_t 1 end_POSTSUBSCRIPT - over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT italic_t 0 end_POSTSUBSCRIPT ) , and   t  i =  t  i  X t  i   (  1   0 ) subscript  t i subscript  t i superscript subscript X t i  subscript  1 subscript  0 {\\zeta}_{ti}=\\omega_{ti}\\boldsymbol{X}_{ti}^{\\prime}({\\boldsymbol{\\beta}}_{1}-% {\\boldsymbol{\\beta}}_{0}) italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT = italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( bold_italic_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - bold_italic_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) . According to the result of Equation ( 28 ), we have",
            "where the detailed expression of each submatrix in  G G G italic_G  is given in Equation ( 48 )-( 49 ).",
            "Combining the results of Equation ( 57 ) and ( 58 ), we have",
            "Therefore, Equation ( 68 ) can be simplified as"
        ]
    },
    "id_table_9": {
        "caption": "",
        "table": "S4.Ex6",
        "footnotes": [],
        "references": [
            "Combining the result of Equation ( 19 ) and ( 21 ), we have",
            "By taking this result back to Equation ( 29 ), we are able to show that there exists a constant  C C C italic_C , such that",
            "where the detailed expression of each submatrix in  G G G italic_G  is given in Equation ( 48 )-( 49 )."
        ]
    },
    "id_table_10": {
        "caption": "",
        "table": "S4.Ex7",
        "footnotes": [],
        "references": []
    },
    "id_table_11": {
        "caption": "",
        "table": "S4.Ex8",
        "footnotes": [],
        "references": [
            "when we exclude the covariance term for simplicity, as done in Equation ( 11 )."
        ]
    },
    "id_table_12": {
        "caption": "",
        "table": "S4.E18",
        "footnotes": [],
        "references": [
            "From a theoretical perspective, extending to  K > 2 K 2 K>2 italic_K > 2  is mathematically straightforward but becomes tedious due to the nature of multi-arm comparisons. Specifically, the tail bound results would include  K K K italic_K  in the denominator of the exponential term in Equation ( 12 ), which does not affect the consistency result we established for the  K = 2 K 2 K=2 italic_K = 2  case. The bidirectional asymptotic normality still holds by following the martingale difference sequence we constructed, which flattens the units across different rounds into a single sequence, as detailed in Appendix  D . The detailed derivation is beyond the scope of this paper and will be addressed in future work."
        ]
    },
    "id_table_13": {
        "caption": "",
        "table": "S4.Ex9",
        "footnotes": [],
        "references": []
    },
    "id_table_14": {
        "caption": "",
        "table": "A2.Ex11",
        "footnotes": [],
        "references": []
    },
    "id_table_15": {
        "caption": "",
        "table": "A2.E19",
        "footnotes": [],
        "references": [
            "To demonstrate the asymptotic normality of    \\boldsymbol{\\beta} bold_italic_  and  V   superscript V superscript  V^{\\pi^{*}} italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT  in Theorem  4.3 - 4.4 , we estimate the asymptotic variance and verify whether the true value of    \\boldsymbol{\\beta} bold_italic_  and  V   superscript V superscript  V^{\\pi^{*}} italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT  falls within the estimated confidence interval with a high probability of coverage under  B = 1000 B 1000 B=1000 italic_B = 1000  times of replicates. By Equation ( 15 ) and ( 17 ),    \\boldsymbol{\\beta} bold_italic_  falls into the confidence region if and only if  N   t  4  (  ^   ) T  G  (  ^   )    2  ( 2  d ) , subscript   N t superscript  4 superscript ^   T G ^   superscript subscript   2 2 d \\frac{\\bar{N}_{t}}{\\sigma^{4}}(\\widehat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta}% )^{T}G(\\widehat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta})\\leq\\chi_{\\alpha}^{2}(2% d), divide start_ARG over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG start_ARG italic_ start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT end_ARG ( over^ start_ARG bold_italic_ end_ARG - bold_italic_ ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_G ( over^ start_ARG bold_italic_ end_ARG - bold_italic_ )  italic_ start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( 2 italic_d ) ,  where  d  f = 2  d d f 2 d df=2d italic_d italic_f = 2 italic_d  is the degree of freedom of the chi-square distribution. Similarly,  V   superscript V superscript  V^{\\pi^{*}} italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT  falls into the confidence interval if and only if  N   t  | V ^ t DR  V   |  z  / 2   V . subscript   N t subscript superscript ^ V DR t superscript V superscript  subscript z  2 subscript  V \\sqrt{\\bar{N}_{t}}|\\widehat{V}^{\\text{DR}}_{t}-V^{\\pi^{*}}|\\leq z_{\\alpha/2}{% \\sigma_{V}}. square-root start_ARG over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG | over^ start_ARG italic_V end_ARG start_POSTSUPERSCRIPT DR end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT |  italic_z start_POSTSUBSCRIPT italic_ / 2 end_POSTSUBSCRIPT italic_ start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT .  Detailed simulation setup is summarized in Appendix  A.1 ."
        ]
    },
    "id_table_16": {
        "caption": "",
        "table": "A2.Ex16",
        "footnotes": [],
        "references": []
    },
    "id_table_17": {
        "caption": "",
        "table": "A2.Ex17",
        "footnotes": [],
        "references": [
            "To demonstrate the asymptotic normality of    \\boldsymbol{\\beta} bold_italic_  and  V   superscript V superscript  V^{\\pi^{*}} italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT  in Theorem  4.3 - 4.4 , we estimate the asymptotic variance and verify whether the true value of    \\boldsymbol{\\beta} bold_italic_  and  V   superscript V superscript  V^{\\pi^{*}} italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT  falls within the estimated confidence interval with a high probability of coverage under  B = 1000 B 1000 B=1000 italic_B = 1000  times of replicates. By Equation ( 15 ) and ( 17 ),    \\boldsymbol{\\beta} bold_italic_  falls into the confidence region if and only if  N   t  4  (  ^   ) T  G  (  ^   )    2  ( 2  d ) , subscript   N t superscript  4 superscript ^   T G ^   superscript subscript   2 2 d \\frac{\\bar{N}_{t}}{\\sigma^{4}}(\\widehat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta}% )^{T}G(\\widehat{\\boldsymbol{\\beta}}-\\boldsymbol{\\beta})\\leq\\chi_{\\alpha}^{2}(2% d), divide start_ARG over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG start_ARG italic_ start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT end_ARG ( over^ start_ARG bold_italic_ end_ARG - bold_italic_ ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_G ( over^ start_ARG bold_italic_ end_ARG - bold_italic_ )  italic_ start_POSTSUBSCRIPT italic_ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( 2 italic_d ) ,  where  d  f = 2  d d f 2 d df=2d italic_d italic_f = 2 italic_d  is the degree of freedom of the chi-square distribution. Similarly,  V   superscript V superscript  V^{\\pi^{*}} italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT  falls into the confidence interval if and only if  N   t  | V ^ t DR  V   |  z  / 2   V . subscript   N t subscript superscript ^ V DR t superscript V superscript  subscript z  2 subscript  V \\sqrt{\\bar{N}_{t}}|\\widehat{V}^{\\text{DR}}_{t}-V^{\\pi^{*}}|\\leq z_{\\alpha/2}{% \\sigma_{V}}. square-root start_ARG over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG | over^ start_ARG italic_V end_ARG start_POSTSUPERSCRIPT DR end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - italic_V start_POSTSUPERSCRIPT italic_ start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT |  italic_z start_POSTSUBSCRIPT italic_ / 2 end_POSTSUBSCRIPT italic_ start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT .  Detailed simulation setup is summarized in Appendix  A.1 ."
        ]
    },
    "id_table_18": {
        "caption": "",
        "table": "A3.E22",
        "footnotes": [],
        "references": [
            "Remark.  The asymptotic variance of the optimal value function comprises two components. The first term arises from the IPW estimator and accounts for the variance of the random noise   t  i subscript italic- t i \\epsilon_{ti} italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT  The second term originates from the DM estimator and captures the variance due to uncertainty in the context  x x \\boldsymbol{x} bold_italic_x  and the interference weight    \\omega italic_ . Notably, our theorem extends the results of  Ye et al. ( 2023 )  by establishing the asymptotic properties of the estimated optimal value function under interference. In the special case where    1  1 \\omega\\equiv 1 italic_  1  in Equation ( 18 ), our results reduce to theirs.",
            "In the estimation of  V    superscript V  V^{\\pi*} italic_V start_POSTSUPERSCRIPT italic_  end_POSTSUPERSCRIPT , for a more balanced variance composition in Equation ( 18 ), we set up the data generating process for  W t subscript W t \\boldsymbol{W}_{t} bold_italic_W start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT  and  X t  i subscript X t i \\boldsymbol{X}_{ti} bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT  as follows. For each  i = j i j i\\neq j italic_i = italic_j , we generate  W t , i  j    Unif  (  0.2 ,  0.1 ) + ( 1   )  Unif  ( 0.05 , 0.2 ) similar-to subscript W t i j   Unif 0.2 0.1  1  Unif 0.05 0.2 W_{t,ij}\\sim\\alpha\\cdot\\text{Unif}(-0.2,-0.1)+(1-\\alpha)\\cdot\\text{Unif}(0.05,% 0.2) italic_W start_POSTSUBSCRIPT italic_t , italic_i italic_j end_POSTSUBSCRIPT  italic_  Unif ( - 0.2 , - 0.1 ) + ( 1 - italic_ )  Unif ( 0.05 , 0.2 ) , where    Bernoulli  ( 0.5 ) similar-to  Bernoulli 0.5 \\alpha\\sim\\text{Bernoulli}(0.5) italic_  Bernoulli ( 0.5 ) . For contextual information, we generate  X t  i = ( X t  i , 1 , ... , X t  i , 3 )  R 3 subscript X t i subscript X t i 1 ... subscript X t i 3 superscript R 3 \\boldsymbol{X}_{ti}=(X_{ti,1},\\dots,X_{ti,3})\\in\\mathbb{R}^{3} bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT = ( italic_X start_POSTSUBSCRIPT italic_t italic_i , 1 end_POSTSUBSCRIPT , ... , italic_X start_POSTSUBSCRIPT italic_t italic_i , 3 end_POSTSUBSCRIPT )  blackboard_R start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT  for unit  i i i italic_i  at round  t t t italic_t , where  X t  i , 1  0.2 subscript X t i 1 0.2 X_{ti,1}\\equiv 0.2 italic_X start_POSTSUBSCRIPT italic_t italic_i , 1 end_POSTSUBSCRIPT  0.2 ,  X t  i , 2  N  ( 0.8 , 0.04 ) similar-to subscript X t i 2 N 0.8 0.04 X_{ti,2}\\sim\\mathcal{N}(0.8,0.04) italic_X start_POSTSUBSCRIPT italic_t italic_i , 2 end_POSTSUBSCRIPT  caligraphic_N ( 0.8 , 0.04 ) ,  X t  i , 3  Unif  ( 0 , 0.6 ) similar-to subscript X t i 3 Unif 0 0.6 X_{ti,3}\\sim\\text{Unif}(0,0.6) italic_X start_POSTSUBSCRIPT italic_t italic_i , 3 end_POSTSUBSCRIPT  Unif ( 0 , 0.6 ) , and all of the samples are i.i.d. over  ( t , i ) t i (t,i) ( italic_t , italic_i ) ."
        ]
    },
    "id_table_19": {
        "caption": "",
        "table": "A3.Ex18",
        "footnotes": [],
        "references": [
            "Combining the result of Equation ( 19 ) and ( 21 ), we have"
        ]
    },
    "id_table_20": {
        "caption": "",
        "table": "A3.E23",
        "footnotes": [],
        "references": []
    },
    "id_table_21": {
        "caption": "",
        "table": "A3.E24",
        "footnotes": [],
        "references": [
            "Combining the result of Equation ( 19 ) and ( 21 ), we have"
        ]
    },
    "id_table_22": {
        "caption": "",
        "table": "A3.Ex20",
        "footnotes": [],
        "references": []
    },
    "id_table_23": {
        "caption": "",
        "table": "A3.E27",
        "footnotes": [],
        "references": [
            "Combining the result of Equation ( 23 ) and ( 24 ), we have"
        ]
    },
    "id_table_24": {
        "caption": "",
        "table": "A3.Ex24",
        "footnotes": [],
        "references": [
            "Combining the result of Equation ( 23 ) and ( 24 ), we have"
        ]
    },
    "id_table_25": {
        "caption": "",
        "table": "A3.Ex25",
        "footnotes": [],
        "references": [
            "Combining the result above and Equation ( 25 ), we have"
        ]
    },
    "id_table_26": {
        "caption": "",
        "table": "A3.Ex26",
        "footnotes": [],
        "references": [
            "Define   ^ t  1  ( X t  i ) = |  t  i |  X t  i   ( X ~ 1 : ( t  1 )   X ~ 1 : ( t  1 ) ) 1  1  X t  i subscript ^  t 1 subscript X t i subscript  t i superscript subscript X t i  subscript superscript superscript subscript ~ X : 1 t 1  subscript ~ X : 1 t 1 1 1 subscript X t i \\widehat{\\sigma}_{t1}(\\boldsymbol{X}_{ti})=|\\omega_{ti}|\\sqrt{\\boldsymbol{X}_{% ti}^{\\prime}\\left(\\widetilde{\\boldsymbol{X}}_{1:(t-1)}^{\\prime}\\widetilde{% \\boldsymbol{X}}_{1:(t-1)}\\right)^{-1}_{1}\\boldsymbol{X}_{ti}} over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t 1 end_POSTSUBSCRIPT ( bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT ) = | italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT | square-root start_ARG bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( over~ start_ARG bold_italic_X end_ARG start_POSTSUBSCRIPT 1 : ( italic_t - 1 ) end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT over~ start_ARG bold_italic_X end_ARG start_POSTSUBSCRIPT 1 : ( italic_t - 1 ) end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT end_ARG , and   ^ t  0  ( X t  i ) = |  t  i |  X t  i   ( X ~ 1 : ( t  1 )   X ~ 1 : ( t  1 ) ) 0  1  X t  i subscript ^  t 0 subscript X t i subscript  t i superscript subscript X t i  subscript superscript superscript subscript ~ X : 1 t 1  subscript ~ X : 1 t 1 1 0 subscript X t i \\widehat{\\sigma}_{t0}(\\boldsymbol{X}_{ti})=|\\omega_{ti}|\\sqrt{\\boldsymbol{X}_{% ti}^{\\prime}\\left(\\widetilde{\\boldsymbol{X}}_{1:(t-1)}^{\\prime}\\widetilde{% \\boldsymbol{X}}_{1:(t-1)}\\right)^{-1}_{0}\\boldsymbol{X}_{ti}} over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t 0 end_POSTSUBSCRIPT ( bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT ) = | italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT | square-root start_ARG bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( over~ start_ARG bold_italic_X end_ARG start_POSTSUBSCRIPT 1 : ( italic_t - 1 ) end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT over~ start_ARG bold_italic_X end_ARG start_POSTSUBSCRIPT 1 : ( italic_t - 1 ) end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT end_ARG . According to the upper bound derived in Equation ( 26 ), we have"
        ]
    },
    "id_table_27": {
        "caption": "",
        "table": "A3.E29",
        "footnotes": [],
        "references": [
            "Step 3:  Further bound the RHS of Equation ( 27 ).",
            "On event  E E E italic_E , we have  |  ^ t  i |  |  t  i |  |  ^ t  i   t  i |  |  t  i |   subscript ^  t i subscript  t i subscript ^  t i subscript  t i subscript  t i  |\\widehat{\\zeta}_{ti}|\\geq|{\\zeta}_{ti}|-|\\widehat{\\zeta}_{ti}-{\\zeta}_{ti}|% \\geq|{\\zeta}_{ti}|-\\xi | over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT |  | italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT | - | over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT - italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT |  | italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT | - italic_ . Then going back to Equation ( 27 ), we further have"
        ]
    },
    "id_table_28": {
        "caption": "",
        "table": "A3.E30",
        "footnotes": [],
        "references": [
            "Similar to Step 3 of Section  C.1 , we define an event  E := { |  ^ t  i   t  i |   } assign E subscript ^  t i subscript  t i  E:=\\big{\\{}|\\widehat{\\zeta}_{ti}-{\\zeta}_{ti}|\\leq\\xi\\big{\\}} italic_E := { | over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT - italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT |  italic_ }  for any    ( 0 , |  t  i | / 2 )  0 subscript  t i 2 \\xi\\in(0,|{\\zeta}_{ti}|/2) italic_  ( 0 , | italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT | / 2 ) , where   ^ t  i =  t  i  X t  i   (  ^ t  1   ^ t  0 ) subscript ^  t i subscript  t i superscript subscript X t i  subscript ^  t 1 subscript ^  t 0 \\widehat{\\zeta}_{ti}=\\omega_{ti}\\boldsymbol{X}_{ti}^{\\prime}(\\widehat{% \\boldsymbol{\\beta}}_{t1}-\\widehat{\\boldsymbol{\\beta}}_{t0}) over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT = italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT italic_t 1 end_POSTSUBSCRIPT - over^ start_ARG bold_italic_ end_ARG start_POSTSUBSCRIPT italic_t 0 end_POSTSUBSCRIPT ) , and   t  i =  t  i  X t  i   (  1   0 ) subscript  t i subscript  t i superscript subscript X t i  subscript  1 subscript  0 {\\zeta}_{ti}=\\omega_{ti}\\boldsymbol{X}_{ti}^{\\prime}({\\boldsymbol{\\beta}}_{1}-% {\\boldsymbol{\\beta}}_{0}) italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT = italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT bold_italic_X start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT ( bold_italic_ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - bold_italic_ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) . According to the result of Equation ( 28 ), we have"
        ]
    },
    "id_table_29": {
        "caption": "",
        "table": "A3.E32",
        "footnotes": [],
        "references": [
            "By taking this result back to Equation ( 29 ), we are able to show that there exists a constant  C C C italic_C , such that"
        ]
    },
    "id_table_30": {
        "caption": "",
        "table": "A3.Ex29",
        "footnotes": [],
        "references": []
    },
    "id_table_31": {
        "caption": "",
        "table": "A3.Ex32",
        "footnotes": [],
        "references": []
    },
    "id_table_32": {
        "caption": "",
        "table": "A4.E43",
        "footnotes": [],
        "references": [
            "Combining the results of Equation ( 32 ) and ( 35 ), we finally have"
        ]
    },
    "id_table_33": {
        "caption": "",
        "table": "A4.E44",
        "footnotes": [],
        "references": [
            "On event  E = { |  ^ t  i   t  i |   } E subscript ^  t i subscript  t i  E=\\big{\\{}|\\widehat{\\zeta}_{ti}-{\\zeta}_{ti}|\\leq\\xi\\big{\\}} italic_E = { | over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT - italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT |  italic_ } , recall that   t  i > 0 subscript  t i 0 {\\zeta}_{ti}>0 italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT > 0  would result in   ^ t  i > 0 subscript ^  t i 0 \\widehat{\\zeta}_{ti}>0 over^ start_ARG italic_ end_ARG start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT > 0  as well. According to the distribution we derived in Equation ( 33 ), we have"
        ]
    },
    "id_table_34": {
        "caption": "",
        "table": "A4.E45",
        "footnotes": [],
        "references": [
            "Combining the result above to Equation ( 34 ), we can further derive"
        ]
    },
    "id_table_35": {
        "caption": "",
        "table": "A4.E47",
        "footnotes": [],
        "references": [
            "Combining the results of Equation ( 32 ) and ( 35 ), we finally have"
        ]
    },
    "id_table_36": {
        "caption": "",
        "table": "A4.Ex41",
        "footnotes": [],
        "references": []
    },
    "id_table_37": {
        "caption": "",
        "table": "A4.E48",
        "footnotes": [],
        "references": []
    },
    "id_table_38": {
        "caption": "",
        "table": "A4.E49",
        "footnotes": [],
        "references": []
    },
    "id_table_39": {
        "caption": "",
        "table": "A4.E50",
        "footnotes": [],
        "references": []
    },
    "id_table_40": {
        "caption": "",
        "table": "A4.Ex44",
        "footnotes": [],
        "references": []
    },
    "id_table_41": {
        "caption": "",
        "table": "A5.Ex45",
        "footnotes": [],
        "references": [
            "Based on Lemma 6 of  Chen et al. [ 2021 ] , it suffice to find the limit of  1 N   q   q = 1 N   q v   X ~ q  X ~ q   v 1 subscript   N q superscript subscript q 1 subscript   N q superscript v  subscript ~ X q superscript subscript ~ X q  v \\frac{1}{\\bar{N}_{q}}\\sum_{q=1}^{\\bar{N}_{q}}\\boldsymbol{v}^{\\prime}\\widetilde% {\\boldsymbol{X}}_{q}\\widetilde{\\boldsymbol{X}}_{q}^{\\prime}\\boldsymbol{v} divide start_ARG 1 end_ARG start_ARG over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT end_ARG  start_POSTSUBSCRIPT italic_q = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT end_POSTSUPERSCRIPT bold_italic_v start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT over~ start_ARG bold_italic_X end_ARG start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT over~ start_ARG bold_italic_X end_ARG start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT start_POSTSUPERSCRIPT  end_POSTSUPERSCRIPT bold_italic_v . According to Equation ( 41 ), we have"
        ]
    },
    "id_table_42": {
        "caption": "",
        "table": "A5.Ex48",
        "footnotes": [],
        "references": [
            "Therefore, by Generalized Dominated Convergence Theorem (GDCT), it follows from Equation ( 42 ) that    E  [ f N   q | H q  1 ]  0  E delimited-[] conditional subscript f subscript   N q subscript H q 1  0 \\psi\\leq\\mathbb{E}[f_{\\bar{N}_{q}}|\\mathcal{H}_{q-1}]\\rightarrow 0 italic_  blackboard_E [ italic_f start_POSTSUBSCRIPT over  start_ARG italic_N end_ARG start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT end_POSTSUBSCRIPT | caligraphic_H start_POSTSUBSCRIPT italic_q - 1 end_POSTSUBSCRIPT ]  0  as  q    q q\\rightarrow\\infty italic_q   . The Lindeberg condition is thus verified."
        ]
    },
    "id_table_43": {
        "caption": "",
        "table": "A5.Ex53",
        "footnotes": [],
        "references": []
    },
    "id_table_44": {
        "caption": "",
        "table": "A5.Ex54",
        "footnotes": [],
        "references": []
    },
    "id_table_45": {
        "caption": "",
        "table": "A5.E58",
        "footnotes": [],
        "references": [
            "Plugging in the result of Equation ( 46 ), ( 47 ) to Equation ( 45 ), one can obtain"
        ]
    },
    "id_table_46": {
        "caption": "",
        "table": "A5.Ex55",
        "footnotes": [],
        "references": [
            "Plugging in the result of Equation ( 46 ), ( 47 ) to Equation ( 45 ), one can obtain"
        ]
    },
    "id_table_47": {
        "caption": "",
        "table": "A5.E60",
        "footnotes": [],
        "references": [
            "Plugging in the result of Equation ( 46 ), ( 47 ) to Equation ( 45 ), one can obtain"
        ]
    },
    "id_table_48": {
        "caption": "",
        "table": "A5.E61",
        "footnotes": [],
        "references": [
            "where the detailed expression of each submatrix in  G G G italic_G  is given in Equation ( 48 )-( 49 )."
        ]
    },
    "id_table_49": {
        "caption": "",
        "table": "A5.E62",
        "footnotes": [],
        "references": [
            "where the detailed expression of each submatrix in  G G G italic_G  is given in Equation ( 48 )-( 49 )."
        ]
    },
    "id_table_50": {
        "caption": "",
        "table": "A5.Ex57",
        "footnotes": [],
        "references": [
            "where  G G G italic_G  is specified in Equation ( 50 ) in Appendix.",
            "where  G G G italic_G  is specified in Equation ( 50 )."
        ]
    },
    "id_table_51": {
        "caption": "",
        "table": "A5.Ex59",
        "footnotes": [],
        "references": []
    },
    "id_table_52": {
        "caption": "",
        "table": "A5.Ex60",
        "footnotes": [],
        "references": []
    },
    "id_table_53": {
        "caption": "",
        "table": "A5.Ex62",
        "footnotes": [],
        "references": []
    },
    "id_table_54": {
        "caption": "",
        "table": "A5.Ex63",
        "footnotes": [],
        "references": []
    },
    "id_table_55": {
        "caption": "",
        "table": "A5.E63",
        "footnotes": [],
        "references": [
            "Therefore, Equation ( 55 ) can be simplified as",
            "Following a similar derivation structure as that used between Equation ( 55 ) and Equation ( 56 ) in Step 1, we have"
        ]
    },
    "id_table_56": {
        "caption": "",
        "table": "A5.Ex65",
        "footnotes": [],
        "references": [
            "Following a similar derivation structure as that used between Equation ( 55 ) and Equation ( 56 ) in Step 1, we have"
        ]
    },
    "id_table_57": {
        "caption": "",
        "table": "A5.E65",
        "footnotes": [],
        "references": [
            "Combining the results of Equation ( 57 ) and ( 58 ), we have"
        ]
    },
    "id_table_58": {
        "caption": "",
        "table": "A5.E67",
        "footnotes": [],
        "references": [
            "Combining the results of Equation ( 57 ) and ( 58 ), we have"
        ]
    },
    "id_table_59": {
        "caption": "",
        "table": "A5.Ex69",
        "footnotes": [],
        "references": []
    },
    "id_table_60": {
        "caption": "",
        "table": "A5.E72",
        "footnotes": [],
        "references": []
    },
    "id_table_61": {
        "caption": "",
        "table": "A5.Ex70",
        "footnotes": [],
        "references": [
            "which has already been established in Equation ( 61 ) in Step 2.1. Therefore,   4 = o p  ( 1 ) subscript  4 subscript o p 1 \\boldsymbol{\\zeta}_{4}=o_{p}(1) bold_italic_ start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = italic_o start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( 1 ) .",
            "Notice that in the proof of Theorem  4.4 , step 2.1, weve proved in Equation ( 61 ) that"
        ]
    },
    "id_table_62": {
        "caption": "",
        "table": "A5.E73",
        "footnotes": [],
        "references": [
            "Given the derivation of Equation ( 62 ), we have"
        ]
    },
    "id_table_63": {
        "caption": "",
        "table": "A5.Ex74",
        "footnotes": [],
        "references": [
            "Combining the result of Equation ( 63 ) and Equation ( 65 ), we have"
        ]
    },
    "id_table_64": {
        "caption": "",
        "table": "A5.Ex77",
        "footnotes": [],
        "references": [
            "Since we assumed that   t  i > 0 subscript  t i 0 \\zeta_{ti}>0 italic_ start_POSTSUBSCRIPT italic_t italic_i end_POSTSUBSCRIPT > 0 , based on the result of Equation ( 64 ), we further have"
        ]
    },
    "id_table_65": {
        "caption": "",
        "table": "A5.E74",
        "footnotes": [],
        "references": [
            "Combining the result of Equation ( 63 ) and Equation ( 65 ), we have"
        ]
    },
    "id_table_66": {
        "caption": "",
        "table": "A6.Ex79",
        "footnotes": [],
        "references": []
    },
    "id_table_67": {
        "caption": "",
        "table": "A6.Ex80",
        "footnotes": [],
        "references": []
    },
    "id_table_68": {
        "caption": "",
        "table": "A6.Ex82",
        "footnotes": [],
        "references": [
            "Therefore, Equation ( 68 ) can be simplified as"
        ]
    },
    "id_table_69": {
        "caption": "",
        "table": "A6.Ex83",
        "footnotes": [],
        "references": []
    },
    "id_table_70": {
        "caption": "",
        "table": "A6.Ex84",
        "footnotes": [],
        "references": []
    },
    "id_table_71": {
        "caption": "",
        "table": "A6.Ex85",
        "footnotes": [],
        "references": []
    }
}