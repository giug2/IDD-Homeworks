{
    "PAPER'S NUMBER OF TABLES": 2,
    "S5.T1": {
        "caption": "Table 1. Estimated enclave memory cost and model portion shielded in each setting.\nValues are shown for the worst case where intermediate activations and gradients inside the shield are not flushed after the back-propagation algorithm uses them.\nThe ensemble value sums both models in the worst case where enclaves are not flushed between evaluation of either of the two models.",
        "table": "<table id=\"S5.T1.2\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S5.T1.2.1\" class=\"ltx_tr\" style=\"background-color:#BFBFBF;\">\n<td id=\"S5.T1.2.1.1\" class=\"ltx_td ltx_align_left\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T1.2.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"background-color:#BFBFBF;\">Model</span></td>\n<td id=\"S5.T1.2.1.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T1.2.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"background-color:#BFBFBF;\">Shielded portion</span></td>\n<td id=\"S5.T1.2.1.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T1.2.1.3.1\" class=\"ltx_text ltx_font_bold\" style=\"background-color:#BFBFBF;\">TEE mem. used</span></td>\n</tr>\n<tr id=\"S5.T1.2.2\" class=\"ltx_tr\" style=\"background-color:#FEFEFE;\">\n<td id=\"S5.T1.2.2.1\" class=\"ltx_td ltx_align_left\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T1.2.2.1.1\" class=\"ltx_text\" style=\"background-color:#FEFEFE;\">ViT-L/16</span></td>\n<td id=\"S5.T1.2.2.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T1.2.2.2.1\" class=\"ltx_text\" style=\"background-color:#FEFEFE;\">0.350%</span></td>\n<td id=\"S5.T1.2.2.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T1.2.2.3.1\" class=\"ltx_text\" style=\"background-color:#FEFEFE;\">12.01Â MB</span></td>\n</tr>\n<tr id=\"S5.T1.2.3\" class=\"ltx_tr\" style=\"background-color:#FFFFFF;\">\n<td id=\"S5.T1.2.3.1\" class=\"ltx_td ltx_align_left ltx_border_bb\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T1.2.3.1.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">BiT-M-R101x3</span></td>\n<td id=\"S5.T1.2.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T1.2.3.2.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">0.004%</span></td>\n<td id=\"S5.T1.2.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T1.2.3.3.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">16.95Â MB</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "For the Big Transfer (BiT) model, the scheme includes the first weight-standardized convolutionÂ (Kolesnikov etÂ al., 2020) and its following max-pooling operation.\nNotice that, for both models, we obfuscate either two learnable transformations or a non-invertible parametric transformation in the case of MaxPoolÂ (Zeiler and Fergus, 2014), so the attacker cannot retrieve the obfuscated quantities without uncertainty.\nTableÂ 1 reports the estimated overheads of the shield for each setting.\nThe shielding of the ensemble requires up to 28.96Â MB of TEE memory at worst, consistent with what typical TrustZone-enabled devices allowÂ (Amacher and Schiavoni, 2019).",
            "We intend to extend this work along the following directions.\nBecause the use of enclaves calls for somewhat costly normal-world to secure-world communication mechanisms, properly evaluating the speed of each collaborating device under our shielding scheme is needed on top of considering the aforementioned memory overheads (TableÂ 1) in order to assess the influence of Pelta on the FL trainingâ€™s practical performance.\nAdditionally, a natural extension to this work is to apply Pelta against other popular attacks, such as in Carlini & WagnerÂ (Carlini and Wagner, 2017). Pelta can also be extended to other gradient masking algorithms with backward approximation.\nAs mentioned in Â§4.3, it should also be explored that an attacker can (i) exploit commonly used embedding matrices and subsequent parameters across existing models as a prior on the shielded layers (this case being circumvented by the defender if it trains its own first parameters) or (ii) to train on their own premises the aforementioned gğ‘”g backward approximation (which needs not be of the same architecture as the shielded layers), although recent work shows limitation for such practiceÂ (Sitawarin etÂ al., 2022)."
        ]
    },
    "S5.T2": {
        "caption": "Table 2. Robust accuracy of a shielded ensemble against SAGA on CIFAR-10 (higher values favor the defender). Baseline values show clean accuracy, astuteness against random attack on the lâˆsubscriptğ‘™l_{\\infty} ball. Applied Shield values show per-model robust accuracy against different shielding setups.",
        "table": "<table id=\"S5.T2.4\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S5.T2.4.1\" class=\"ltx_tr\">\n<td id=\"S5.T2.4.1.1\" class=\"ltx_td\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"></td>\n<td id=\"S5.T2.4.1.2\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:10.0pt;padding-right:10.0pt;\" colspan=\"2\"><span id=\"S5.T2.4.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"background-color:#FFFFFF;\">Baseline</span></td>\n<td id=\"S5.T2.4.1.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\" colspan=\"4\"><span id=\"S5.T2.4.1.3.1\" class=\"ltx_text ltx_font_bold\" style=\"background-color:#FFFFFF;\">Applied Shield</span></td>\n</tr>\n<tr id=\"S5.T2.4.2\" class=\"ltx_tr\" style=\"background-color:#DFDFDF;\">\n<td id=\"S5.T2.4.2.1\" class=\"ltx_td ltx_align_justify\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\n<span id=\"S5.T2.4.2.1.1\" class=\"ltx_inline-block ltx_align_top\" style=\"background-color:#DFDFDF;\">\n<span id=\"S5.T2.4.2.1.1.1\" class=\"ltx_p\"><span id=\"S5.T2.4.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Model Acc.</span></span>\n</span>\n</td>\n<td id=\"S5.T2.4.2.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T2.4.2.2.1\" class=\"ltx_text ltx_font_bold\" style=\"background-color:#DFDFDF;\">Clean</span></td>\n<td id=\"S5.T2.4.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T2.4.2.3.1\" class=\"ltx_text ltx_font_bold\" style=\"background-color:#F2F2F2;\">Random</span></td>\n<td id=\"S5.T2.4.2.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T2.4.2.4.1\" class=\"ltx_text ltx_font_bold\" style=\"background-color:#DFDFDF;\">None</span></td>\n<td id=\"S5.T2.4.2.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T2.4.2.5.1\" class=\"ltx_text ltx_font_bold\" style=\"background-color:#DFDFDF;\">ViT-L/16</span></td>\n<td id=\"S5.T2.4.2.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T2.4.2.6.1\" class=\"ltx_text ltx_font_bold\" style=\"background-color:#DFDFDF;\">BiT-M-R101x3</span></td>\n<td id=\"S5.T2.4.2.7\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T2.4.2.7.1\" class=\"ltx_text ltx_font_bold\" style=\"background-color:#DFDFDF;\">Ensemble</span></td>\n</tr>\n<tr id=\"S5.T2.4.3\" class=\"ltx_tr\" style=\"background-color:#FEFEFE;\">\n<td id=\"S5.T2.4.3.1\" class=\"ltx_td ltx_align_justify\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\n<span id=\"S5.T2.4.3.1.1\" class=\"ltx_inline-block ltx_align_top\" style=\"background-color:#FEFEFE;\">\n<span id=\"S5.T2.4.3.1.1.1\" class=\"ltx_p\">ViT-L/16</span>\n</span>\n</td>\n<td id=\"S5.T2.4.3.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T2.4.3.2.1\" class=\"ltx_text\" style=\"background-color:#FEFEFE;\">99.5%</span></td>\n<td id=\"S5.T2.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T2.4.3.3.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">99.5%</span></td>\n<td id=\"S5.T2.4.3.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T2.4.3.4.1\" class=\"ltx_text\" style=\"background-color:#FEFEFE;\">28.1%</span></td>\n<td id=\"S5.T2.4.3.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T2.4.3.5.1\" class=\"ltx_text\" style=\"background-color:#FEFEFE;\">99.2%</span></td>\n<td id=\"S5.T2.4.3.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T2.4.3.6.1\" class=\"ltx_text\" style=\"background-color:#FEFEFE;\">14.1%</span></td>\n<td id=\"S5.T2.4.3.7\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T2.4.3.7.1\" class=\"ltx_text\" style=\"background-color:#FEFEFE;\">99.5%</span></td>\n</tr>\n<tr id=\"S5.T2.4.4\" class=\"ltx_tr\" style=\"background-color:#F2F2F2;\">\n<td id=\"S5.T2.4.4.1\" class=\"ltx_td ltx_align_justify\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\n<span id=\"S5.T2.4.4.1.1\" class=\"ltx_inline-block ltx_align_top\" style=\"background-color:#F2F2F2;\">\n<span id=\"S5.T2.4.4.1.1.1\" class=\"ltx_p\">BiT-M-R101x3</span>\n</span>\n</td>\n<td id=\"S5.T2.4.4.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T2.4.4.2.1\" class=\"ltx_text\" style=\"background-color:#F2F2F2;\">99.1%</span></td>\n<td id=\"S5.T2.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T2.4.4.3.1\" class=\"ltx_text\" style=\"background-color:#F2F2F2;\">98.8%</span></td>\n<td id=\"S5.T2.4.4.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T2.4.4.4.1\" class=\"ltx_text\" style=\"background-color:#F2F2F2;\">25.2%</span></td>\n<td id=\"S5.T2.4.4.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T2.4.4.5.1\" class=\"ltx_text\" style=\"background-color:#F2F2F2;\">0.3%</span></td>\n<td id=\"S5.T2.4.4.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T2.4.4.6.1\" class=\"ltx_text\" style=\"background-color:#F2F2F2;\">78.9%</span></td>\n<td id=\"S5.T2.4.4.7\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T2.4.4.7.1\" class=\"ltx_text\" style=\"background-color:#F2F2F2;\">98.5%</span></td>\n</tr>\n<tr id=\"S5.T2.4.5\" class=\"ltx_tr\" style=\"background-color:#FFFFFF;\">\n<td id=\"S5.T2.4.5.1\" class=\"ltx_td ltx_align_justify ltx_border_b\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\n<span id=\"S5.T2.4.5.1.1\" class=\"ltx_inline-block ltx_align_top\" style=\"background-color:#FFFFFF;\">\n<span id=\"S5.T2.4.5.1.1.1\" class=\"ltx_p\">Ensemble</span>\n</span>\n</td>\n<td id=\"S5.T2.4.5.2\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T2.4.5.2.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">99.3%</span></td>\n<td id=\"S5.T2.4.5.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T2.4.5.3.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">98.9%</span></td>\n<td id=\"S5.T2.4.5.4\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T2.4.5.4.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">27.2%</span></td>\n<td id=\"S5.T2.4.5.5\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T2.4.5.5.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">49.7%</span></td>\n<td id=\"S5.T2.4.5.6\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T2.4.5.6.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">46.4%</span></td>\n<td id=\"S5.T2.4.5.7\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding-left:10.0pt;padding-right:10.0pt;\"><span id=\"S5.T2.4.5.7.1\" class=\"ltx_text\" style=\"background-color:#FFFFFF;\">98.8%</span></td>\n</tr>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "We select 1000 random samples from CIFAR-10Â (Krizhevsky and Hinton, 2009), and evaluate the average robust accuracy of individual models and their ensemble over 10 attacks in each of the settings involving either BiT model with shield, ViT model with shield, both or none.\nFor each attack, the attacker makes ten passes (i=1ğ‘–1i=1. . .101010 in Eq.Â 2) of his adversarial instance through the ensemble to update it.\nTableÂ 2 shows our results.\nFor illustrative purposes, Fig.3 shows the generated perturbation on one sample in the different shielding settings."
        ]
    }
}