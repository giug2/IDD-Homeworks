{
    "PAPER'S NUMBER OF TABLES": 9,
    "S6.T1": {
        "caption": "Table 1: Test accuracy (%percent\\%) on the CIFAR-10/100 and TinyImagenet under IID and Non-IID setting. The first 4 solutions are global solutions, and the others are personalized solutions. ",
        "table": "<table id=\"S6.T1.5\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T1.5.1.1\" class=\"ltx_tr\">\n<th id=\"S6.T1.5.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\" rowspan=\"2\"><span id=\"S6.T1.5.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Method</span></th>\n<td id=\"S6.T1.5.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\" colspan=\"2\"><span id=\"S6.T1.5.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">CIFAR-10</span></td>\n<td id=\"S6.T1.5.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\" colspan=\"2\"><span id=\"S6.T1.5.1.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">CIFAR-100</span></td>\n<td id=\"S6.T1.5.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\" colspan=\"2\"><span id=\"S6.T1.5.1.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">TinyImagenet</span></td>\n</tr>\n<tr id=\"S6.T1.5.2.2\" class=\"ltx_tr\">\n<td id=\"S6.T1.5.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.2.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">IID</span></td>\n<td id=\"S6.T1.5.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Non-IID</span></td>\n<td id=\"S6.T1.5.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.2.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">IID</span></td>\n<td id=\"S6.T1.5.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.2.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">Non-IID</span></td>\n<td id=\"S6.T1.5.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.2.2.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">IID</span></td>\n<td id=\"S6.T1.5.2.2.6\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.2.2.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">Non-IID</span></td>\n</tr>\n<tr id=\"S6.T1.5.3.3\" class=\"ltx_tr\">\n<th id=\"S6.T1.5.3.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.3.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">SCAFFOLD</span></th>\n<td id=\"S6.T1.5.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.3.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">91.33</span></td>\n<td id=\"S6.T1.5.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.3.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">82.91</span></td>\n<td id=\"S6.T1.5.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.3.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">66.68</span></td>\n<td id=\"S6.T1.5.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.3.3.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">59.48</span></td>\n<td id=\"S6.T1.5.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.3.3.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">43.13</span></td>\n<td id=\"S6.T1.5.3.3.7\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.3.3.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">34.11</span></td>\n</tr>\n<tr id=\"S6.T1.5.4.4\" class=\"ltx_tr\">\n<th id=\"S6.T1.5.4.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.4.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedDyn</span></th>\n<td id=\"S6.T1.5.4.4.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.4.4.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">92.61</span></td>\n<td id=\"S6.T1.5.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.4.4.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">90.14</span></td>\n<td id=\"S6.T1.5.4.4.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.4.4.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">68.68</span></td>\n<td id=\"S6.T1.5.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.4.4.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">64.29</span></td>\n<td id=\"S6.T1.5.4.4.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.4.4.6.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">43.52</span></td>\n<td id=\"S6.T1.5.4.4.7\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.4.4.7.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">38.02</span></td>\n</tr>\n<tr id=\"S6.T1.5.5.5\" class=\"ltx_tr\">\n<th id=\"S6.T1.5.5.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.5.5.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedAvg</span></th>\n<td id=\"S6.T1.5.5.5.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.5.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">90.25</span></td>\n<td id=\"S6.T1.5.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.5.5.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">82.89</span></td>\n<td id=\"S6.T1.5.5.5.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.5.5.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">61.92</span></td>\n<td id=\"S6.T1.5.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.5.5.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">55.78</span></td>\n<td id=\"S6.T1.5.5.5.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.5.5.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">35.17</span></td>\n<td id=\"S6.T1.5.5.5.7\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.5.5.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">30.56</span></td>\n</tr>\n<tr id=\"S6.T1.5.6.6\" class=\"ltx_tr\" style=\"background-color:#E6E6E6;\">\n<th id=\"S6.T1.5.6.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.6.6.1.1\" class=\"ltx_text\" style=\"font-size:90%;background-color:#E6E6E6;\">FedSLR (GKR)</span></th>\n<td id=\"S6.T1.5.6.6.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.6.6.2.1\" class=\"ltx_text\" style=\"font-size:90%;background-color:#E6E6E6;\">91.73</span></td>\n<td id=\"S6.T1.5.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.6.6.3.1\" class=\"ltx_text\" style=\"font-size:90%;background-color:#E6E6E6;\">87.52</span></td>\n<td id=\"S6.T1.5.6.6.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.6.6.4.1\" class=\"ltx_text\" style=\"font-size:90%;background-color:#E6E6E6;\">66.40</span></td>\n<td id=\"S6.T1.5.6.6.5\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.6.6.5.1\" class=\"ltx_text\" style=\"font-size:90%;background-color:#E6E6E6;\">64.22</span></td>\n<td id=\"S6.T1.5.6.6.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.6.6.6.1\" class=\"ltx_text\" style=\"font-size:90%;background-color:#E6E6E6;\">41.32</span></td>\n<td id=\"S6.T1.5.6.6.7\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.6.6.7.1\" class=\"ltx_text\" style=\"font-size:90%;background-color:#E6E6E6;\">35.13</span></td>\n</tr>\n<tr id=\"S6.T1.5.7.7\" class=\"ltx_tr\">\n<th id=\"S6.T1.5.7.7.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.7.7.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Per-FedAvg</span></th>\n<td id=\"S6.T1.5.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.7.7.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">89.57</span></td>\n<td id=\"S6.T1.5.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.7.7.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">91.55</span></td>\n<td id=\"S6.T1.5.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.7.7.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">57.10</span></td>\n<td id=\"S6.T1.5.7.7.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.7.7.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">63.73</span></td>\n<td id=\"S6.T1.5.7.7.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.7.7.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">34.41</span></td>\n<td id=\"S6.T1.5.7.7.7\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.7.7.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">37.52</span></td>\n</tr>\n<tr id=\"S6.T1.5.8.8\" class=\"ltx_tr\">\n<th id=\"S6.T1.5.8.8.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.8.8.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">LGFedAvg</span></th>\n<td id=\"S6.T1.5.8.8.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.8.8.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">38.32</span></td>\n<td id=\"S6.T1.5.8.8.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.8.8.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">81.35</span></td>\n<td id=\"S6.T1.5.8.8.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.8.8.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">12.96</span></td>\n<td id=\"S6.T1.5.8.8.5\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.8.8.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">49.90</span></td>\n<td id=\"S6.T1.5.8.8.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.8.8.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">5.34</span></td>\n<td id=\"S6.T1.5.8.8.7\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.8.8.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">35.68</span></td>\n</tr>\n<tr id=\"S6.T1.5.9.9\" class=\"ltx_tr\">\n<th id=\"S6.T1.5.9.9.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.9.9.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedRep</span></th>\n<td id=\"S6.T1.5.9.9.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.9.9.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">89.28</span></td>\n<td id=\"S6.T1.5.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.9.9.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">93.41</span></td>\n<td id=\"S6.T1.5.9.9.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.9.9.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">15.36</span></td>\n<td id=\"S6.T1.5.9.9.5\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.9.9.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">60.42</span></td>\n<td id=\"S6.T1.5.9.9.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.9.9.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">5.48</span></td>\n<td id=\"S6.T1.5.9.9.7\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.9.9.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">46.42</span></td>\n</tr>\n<tr id=\"S6.T1.5.10.10\" class=\"ltx_tr\">\n<th id=\"S6.T1.5.10.10.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.10.10.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Ditto</span></th>\n<td id=\"S6.T1.5.10.10.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.10.10.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">89.16</span></td>\n<td id=\"S6.T1.5.10.10.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.10.10.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">94.39</span></td>\n<td id=\"S6.T1.5.10.10.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.10.10.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">59.36</span></td>\n<td id=\"S6.T1.5.10.10.5\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.10.10.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">78.67</span></td>\n<td id=\"S6.T1.5.10.10.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.10.10.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">34.78</span></td>\n<td id=\"S6.T1.5.10.10.7\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.10.10.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">58.30</span></td>\n</tr>\n<tr id=\"S6.T1.5.11.11\" class=\"ltx_tr\">\n<th id=\"S6.T1.5.11.11.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.11.11.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">APFL</span></th>\n<td id=\"S6.T1.5.11.11.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.11.11.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">75.11</span></td>\n<td id=\"S6.T1.5.11.11.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.11.11.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">87.11</span></td>\n<td id=\"S6.T1.5.11.11.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.11.11.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">30.99</span></td>\n<td id=\"S6.T1.5.11.11.5\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.11.11.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">61.14</span></td>\n<td id=\"S6.T1.5.11.11.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.11.11.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">20.16</span></td>\n<td id=\"S6.T1.5.11.11.7\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.11.11.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">48.02</span></td>\n</tr>\n<tr id=\"S6.T1.5.12.12\" class=\"ltx_tr\">\n<th id=\"S6.T1.5.12.12.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.12.12.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Local</span></th>\n<td id=\"S6.T1.5.12.12.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.12.12.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">38.30</span></td>\n<td id=\"S6.T1.5.12.12.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.12.12.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">82.17</span></td>\n<td id=\"S6.T1.5.12.12.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.12.12.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">10.97</span></td>\n<td id=\"S6.T1.5.12.12.5\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.12.12.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">47.99</span></td>\n<td id=\"S6.T1.5.12.12.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.12.12.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">3.86</span></td>\n<td id=\"S6.T1.5.12.12.7\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.12.12.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">34.28</span></td>\n</tr>\n<tr id=\"S6.T1.5.13.13\" class=\"ltx_tr\">\n<th id=\"S6.T1.5.13.13.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.13.13.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedSpa</span></th>\n<td id=\"S6.T1.5.13.13.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.13.13.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">88.31</span></td>\n<td id=\"S6.T1.5.13.13.3\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.13.13.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">93.19</span></td>\n<td id=\"S6.T1.5.13.13.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.13.13.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">48.00</span></td>\n<td id=\"S6.T1.5.13.13.5\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.13.13.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">73.87</span></td>\n<td id=\"S6.T1.5.13.13.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.13.13.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">30.39</span></td>\n<td id=\"S6.T1.5.13.13.7\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.13.13.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">53.76</span></td>\n</tr>\n<tr id=\"S6.T1.5.14.14\" class=\"ltx_tr\" style=\"background-color:#E6E6E6;\">\n<th id=\"S6.T1.5.14.14.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.14.14.1.1\" class=\"ltx_text\" style=\"font-size:90%;background-color:#E6E6E6;\">FedSLR (mixed)</span></th>\n<td id=\"S6.T1.5.14.14.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.14.14.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;background-color:#E6E6E6;\">89.72</span></td>\n<td id=\"S6.T1.5.14.14.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.14.14.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;background-color:#E6E6E6;\">95.30</span></td>\n<td id=\"S6.T1.5.14.14.4\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.14.14.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;background-color:#E6E6E6;\">64.95</span></td>\n<td id=\"S6.T1.5.14.14.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.14.14.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;background-color:#E6E6E6;\">82.19</span></td>\n<td id=\"S6.T1.5.14.14.6\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.14.14.6.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;background-color:#E6E6E6;\">38.20</span></td>\n<td id=\"S6.T1.5.14.14.7\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"S6.T1.5.14.14.7.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;background-color:#E6E6E6;\">59.13</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Performance. We show the accuracy in Figure 2 and Table 1, and discuss the performance comparison by separating IID and Non-IID cases. The performance evaluation could also be interpreted by its representation visualization, see Figure 4 in Appendix B.3.1."
        ]
    },
    "S6.T2": {
        "caption": "Table 2: Communication cost (GB) and ##\\# of params (M) on the Non-IID splitting of three datasets. FedAvg(*) refers to a class of algorithms with no communication reduction/increase, e.g., FedDyn.",
        "table": "<table id=\"S6.T2.8\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S6.T2.8.7.1\" class=\"ltx_tr\">\n<th id=\"S6.T2.8.7.1.1\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_row ltx_border_tt\" style=\"padding-left:1.7pt;padding-right:1.7pt;\" rowspan=\"2\"><span id=\"S6.T2.8.7.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Method</span></th>\n<td id=\"S6.T2.8.7.1.2\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_tt\" style=\"padding-left:1.7pt;padding-right:1.7pt;\" colspan=\"2\"><span id=\"S6.T2.8.7.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">CIFAR-10</span></td>\n<td id=\"S6.T2.8.7.1.3\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_tt\" style=\"padding-left:1.7pt;padding-right:1.7pt;\" colspan=\"2\"><span id=\"S6.T2.8.7.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">CIFAR-100</span></td>\n<td id=\"S6.T2.8.7.1.4\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_tt\" style=\"padding-left:1.7pt;padding-right:1.7pt;\" colspan=\"2\"><span id=\"S6.T2.8.7.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">TinyImagenet</span></td>\n</tr>\n<tr id=\"S6.T2.8.6\" class=\"ltx_tr\">\n<td id=\"S6.T2.3.1.1\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">\n<span id=\"S6.T2.3.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Comm cost</span><math id=\"S6.T2.3.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S6.T2.3.1.1.m1.1a\"><mo mathsize=\"90%\" stretchy=\"false\" id=\"S6.T2.3.1.1.m1.1.1\" xref=\"S6.T2.3.1.1.m1.1.1.cmml\">‚Üì</mo><annotation-xml encoding=\"MathML-Content\" id=\"S6.T2.3.1.1.m1.1b\"><ci id=\"S6.T2.3.1.1.m1.1.1.cmml\" xref=\"S6.T2.3.1.1.m1.1.1\">‚Üì</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T2.3.1.1.m1.1c\">\\downarrow</annotation></semantics></math>\n</td>\n<td id=\"S6.T2.4.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">\n<span id=\"S6.T2.4.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\"># of params</span><math id=\"S6.T2.4.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S6.T2.4.2.2.m1.1a\"><mo mathsize=\"90%\" stretchy=\"false\" id=\"S6.T2.4.2.2.m1.1.1\" xref=\"S6.T2.4.2.2.m1.1.1.cmml\">‚Üì</mo><annotation-xml encoding=\"MathML-Content\" id=\"S6.T2.4.2.2.m1.1b\"><ci id=\"S6.T2.4.2.2.m1.1.1.cmml\" xref=\"S6.T2.4.2.2.m1.1.1\">‚Üì</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T2.4.2.2.m1.1c\">\\downarrow</annotation></semantics></math>\n</td>\n<td id=\"S6.T2.5.3.3\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">\n<span id=\"S6.T2.5.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Comm cost</span><math id=\"S6.T2.5.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S6.T2.5.3.3.m1.1a\"><mo mathsize=\"90%\" stretchy=\"false\" id=\"S6.T2.5.3.3.m1.1.1\" xref=\"S6.T2.5.3.3.m1.1.1.cmml\">‚Üì</mo><annotation-xml encoding=\"MathML-Content\" id=\"S6.T2.5.3.3.m1.1b\"><ci id=\"S6.T2.5.3.3.m1.1.1.cmml\" xref=\"S6.T2.5.3.3.m1.1.1\">‚Üì</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T2.5.3.3.m1.1c\">\\downarrow</annotation></semantics></math>\n</td>\n<td id=\"S6.T2.6.4.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">\n<span id=\"S6.T2.6.4.4.1\" class=\"ltx_text\" style=\"font-size:90%;\"># of params</span><math id=\"S6.T2.6.4.4.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S6.T2.6.4.4.m1.1a\"><mo mathsize=\"90%\" stretchy=\"false\" id=\"S6.T2.6.4.4.m1.1.1\" xref=\"S6.T2.6.4.4.m1.1.1.cmml\">‚Üì</mo><annotation-xml encoding=\"MathML-Content\" id=\"S6.T2.6.4.4.m1.1b\"><ci id=\"S6.T2.6.4.4.m1.1.1.cmml\" xref=\"S6.T2.6.4.4.m1.1.1\">‚Üì</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T2.6.4.4.m1.1c\">\\downarrow</annotation></semantics></math>\n</td>\n<td id=\"S6.T2.7.5.5\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">\n<span id=\"S6.T2.7.5.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">Comm cost</span><math id=\"S6.T2.7.5.5.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S6.T2.7.5.5.m1.1a\"><mo mathsize=\"90%\" stretchy=\"false\" id=\"S6.T2.7.5.5.m1.1.1\" xref=\"S6.T2.7.5.5.m1.1.1.cmml\">‚Üì</mo><annotation-xml encoding=\"MathML-Content\" id=\"S6.T2.7.5.5.m1.1b\"><ci id=\"S6.T2.7.5.5.m1.1.1.cmml\" xref=\"S6.T2.7.5.5.m1.1.1\">‚Üì</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T2.7.5.5.m1.1c\">\\downarrow</annotation></semantics></math>\n</td>\n<td id=\"S6.T2.8.6.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\">\n<span id=\"S6.T2.8.6.6.1\" class=\"ltx_text\" style=\"font-size:90%;\"># of params</span><math id=\"S6.T2.8.6.6.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S6.T2.8.6.6.m1.1a\"><mo mathsize=\"90%\" stretchy=\"false\" id=\"S6.T2.8.6.6.m1.1.1\" xref=\"S6.T2.8.6.6.m1.1.1.cmml\">‚Üì</mo><annotation-xml encoding=\"MathML-Content\" id=\"S6.T2.8.6.6.m1.1b\"><ci id=\"S6.T2.8.6.6.m1.1.1.cmml\" xref=\"S6.T2.8.6.6.m1.1.1\">‚Üì</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S6.T2.8.6.6.m1.1c\">\\downarrow</annotation></semantics></math>\n</td>\n</tr>\n<tr id=\"S6.T2.8.8.2\" class=\"ltx_tr\">\n<th id=\"S6.T2.8.8.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.8.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedAvg (*)</span></th>\n<td id=\"S6.T2.8.8.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.8.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">893.92</span></td>\n<td id=\"S6.T2.8.8.2.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.8.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">11.17</span></td>\n<td id=\"S6.T2.8.8.2.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.8.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">893.92</span></td>\n<td id=\"S6.T2.8.8.2.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.8.2.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">11.17</span></td>\n<td id=\"S6.T2.8.8.2.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.8.2.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">893.92</span></td>\n<td id=\"S6.T2.8.8.2.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.8.2.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">11.17</span></td>\n</tr>\n<tr id=\"S6.T2.8.9.3\" class=\"ltx_tr\">\n<th id=\"S6.T2.8.9.3.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.9.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">SCAFFOLD</span></th>\n<td id=\"S6.T2.8.9.3.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.9.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">1787.83</span></td>\n<td id=\"S6.T2.8.9.3.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.9.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">11.17</span></td>\n<td id=\"S6.T2.8.9.3.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.9.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">1787.83</span></td>\n<td id=\"S6.T2.8.9.3.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.9.3.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">11.17</span></td>\n<td id=\"S6.T2.8.9.3.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.9.3.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">1787.83</span></td>\n<td id=\"S6.T2.8.9.3.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.9.3.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">11.17</span></td>\n</tr>\n<tr id=\"S6.T2.8.10.4\" class=\"ltx_tr\" style=\"background-color:#E6E6E6;\">\n<th id=\"S6.T2.8.10.4.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.10.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;background-color:#E6E6E6;\">FedSLR (GKR)</span></th>\n<td id=\"S6.T2.8.10.4.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.10.4.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;background-color:#E6E6E6;\">626.89</span></td>\n<td id=\"S6.T2.8.10.4.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.10.4.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;background-color:#E6E6E6;\">3.51</span></td>\n<td id=\"S6.T2.8.10.4.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.10.4.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;background-color:#E6E6E6;\">722.60</span></td>\n<td id=\"S6.T2.8.10.4.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.10.4.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;background-color:#E6E6E6;\">5.54</span></td>\n<td id=\"S6.T2.8.10.4.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.10.4.6.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;background-color:#E6E6E6;\">730.00</span></td>\n<td id=\"S6.T2.8.10.4.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.10.4.7.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;background-color:#E6E6E6;\">5.34</span></td>\n</tr>\n<tr id=\"S6.T2.8.11.5\" class=\"ltx_tr\">\n<th id=\"S6.T2.8.11.5.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.11.5.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">APFL</span></th>\n<td id=\"S6.T2.8.11.5.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.11.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">893.92</span></td>\n<td id=\"S6.T2.8.11.5.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.11.5.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">22.35</span></td>\n<td id=\"S6.T2.8.11.5.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.11.5.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">893.92</span></td>\n<td id=\"S6.T2.8.11.5.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.11.5.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">22.35</span></td>\n<td id=\"S6.T2.8.11.5.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.11.5.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">893.92</span></td>\n<td id=\"S6.T2.8.11.5.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.11.5.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">22.35</span></td>\n</tr>\n<tr id=\"S6.T2.8.12.6\" class=\"ltx_tr\">\n<th id=\"S6.T2.8.12.6.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.12.6.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedSpa</span></th>\n<td id=\"S6.T2.8.12.6.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.12.6.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">446.96</span></td>\n<td id=\"S6.T2.8.12.6.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.12.6.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">5.59</span></td>\n<td id=\"S6.T2.8.12.6.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.12.6.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">446.96</span></td>\n<td id=\"S6.T2.8.12.6.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.12.6.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">5.59</span></td>\n<td id=\"S6.T2.8.12.6.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.12.6.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">446.96</span></td>\n<td id=\"S6.T2.8.12.6.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.12.6.7.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">5.59</span></td>\n</tr>\n<tr id=\"S6.T2.8.13.7\" class=\"ltx_tr\">\n<th id=\"S6.T2.8.13.7.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.13.7.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">LG-FedAvg</span></th>\n<td id=\"S6.T2.8.13.7.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.13.7.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">0.41</span></td>\n<td id=\"S6.T2.8.13.7.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.13.7.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">11.17</span></td>\n<td id=\"S6.T2.8.13.7.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.13.7.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">4.08</span></td>\n<td id=\"S6.T2.8.13.7.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.13.7.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">11.17</span></td>\n<td id=\"S6.T2.8.13.7.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.13.7.6.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">8.13</span></td>\n<td id=\"S6.T2.8.13.7.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.13.7.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">11.17</span></td>\n</tr>\n<tr id=\"S6.T2.8.14.8\" class=\"ltx_tr\">\n<th id=\"S6.T2.8.14.8.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.14.8.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">FedRep</span></th>\n<td id=\"S6.T2.8.14.8.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.14.8.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">893.51</span></td>\n<td id=\"S6.T2.8.14.8.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.14.8.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">11.17</span></td>\n<td id=\"S6.T2.8.14.8.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.14.8.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">889.84</span></td>\n<td id=\"S6.T2.8.14.8.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.14.8.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">11.17</span></td>\n<td id=\"S6.T2.8.14.8.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.14.8.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">885.78</span></td>\n<td id=\"S6.T2.8.14.8.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.14.8.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">11.17</span></td>\n</tr>\n<tr id=\"S6.T2.8.15.9\" class=\"ltx_tr\" style=\"background-color:#E6E6E6;\">\n<th id=\"S6.T2.8.15.9.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.15.9.1.1\" class=\"ltx_text\" style=\"font-size:90%;background-color:#E6E6E6;\">FedSLR (mixed)</span></th>\n<td id=\"S6.T2.8.15.9.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.15.9.2.1\" class=\"ltx_text\" style=\"font-size:90%;background-color:#E6E6E6;\">626.89</span></td>\n<td id=\"S6.T2.8.15.9.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.15.9.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;background-color:#E6E6E6;\">3.96</span></td>\n<td id=\"S6.T2.8.15.9.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.15.9.4.1\" class=\"ltx_text\" style=\"font-size:90%;background-color:#E6E6E6;\">722.60</span></td>\n<td id=\"S6.T2.8.15.9.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.15.9.5.1\" class=\"ltx_text\" style=\"font-size:90%;background-color:#E6E6E6;\">6.69</span></td>\n<td id=\"S6.T2.8.15.9.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.15.9.6.1\" class=\"ltx_text\" style=\"font-size:90%;background-color:#E6E6E6;\">730.00</span></td>\n<td id=\"S6.T2.8.15.9.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding-left:1.7pt;padding-right:1.7pt;\"><span id=\"S6.T2.8.15.9.7.1\" class=\"ltx_text\" style=\"font-size:90%;background-color:#E6E6E6;\">7.59</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Communication and model parameters. Table 2 illustrates the communication cost and model complexity with different methods. As shown, GKR model of FedSLR has smaller model complexity with smaller communication overhead in the training phase (approximately 19% of reduction compared to full-model transmission). In addition, our results also corroborate that, built upon the low-rank model, FedSLR acquires personalized models with only modicum parameters added. The mixed personalizd model acquires 17.97% accuracy gain with 29% more parameters added upon the global GKR model."
        ]
    },
    "A2.T3": {
        "caption": "Table 3:  Parameter sensitivity of low-rank penalty ŒªùúÜ\\lambda on CIFAR-100. ",
        "table": "<table id=\"A2.T3.9\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A2.T3.3.1\" class=\"ltx_tr\">\n<th id=\"A2.T3.3.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\" rowspan=\"2\"><span id=\"A2.T3.3.1.1.1\" class=\"ltx_text\"><math id=\"A2.T3.3.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\lambda\" display=\"inline\"><semantics id=\"A2.T3.3.1.1.1.m1.1a\"><mi id=\"A2.T3.3.1.1.1.m1.1.1\" xref=\"A2.T3.3.1.1.1.m1.1.1.cmml\">Œª</mi><annotation-xml encoding=\"MathML-Content\" id=\"A2.T3.3.1.1.1.m1.1b\"><ci id=\"A2.T3.3.1.1.1.m1.1.1.cmml\" xref=\"A2.T3.3.1.1.1.m1.1.1\">ùúÜ</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T3.3.1.1.1.m1.1c\">\\lambda</annotation></semantics></math></span></th>\n<th id=\"A2.T3.3.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\" colspan=\"3\">FedSLR (GKR)</th>\n<th id=\"A2.T3.3.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\" colspan=\"3\">FedSLR (mixed model)</th>\n</tr>\n<tr id=\"A2.T3.9.7\" class=\"ltx_tr\">\n<th id=\"A2.T3.4.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">Acc <math id=\"A2.T3.4.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"A2.T3.4.2.1.m1.1a\"><mo stretchy=\"false\" id=\"A2.T3.4.2.1.m1.1.1\" xref=\"A2.T3.4.2.1.m1.1.1.cmml\">‚Üë</mo><annotation-xml encoding=\"MathML-Content\" id=\"A2.T3.4.2.1.m1.1b\"><ci id=\"A2.T3.4.2.1.m1.1.1.cmml\" xref=\"A2.T3.4.2.1.m1.1.1\">‚Üë</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T3.4.2.1.m1.1c\">\\uparrow</annotation></semantics></math>\n</th>\n<th id=\"A2.T3.5.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">Comm cost <math id=\"A2.T3.5.3.2.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"A2.T3.5.3.2.m1.1a\"><mo stretchy=\"false\" id=\"A2.T3.5.3.2.m1.1.1\" xref=\"A2.T3.5.3.2.m1.1.1.cmml\">‚Üì</mo><annotation-xml encoding=\"MathML-Content\" id=\"A2.T3.5.3.2.m1.1b\"><ci id=\"A2.T3.5.3.2.m1.1.1.cmml\" xref=\"A2.T3.5.3.2.m1.1.1\">‚Üì</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T3.5.3.2.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<th id=\"A2.T3.6.4.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"># of params <math id=\"A2.T3.6.4.3.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"A2.T3.6.4.3.m1.1a\"><mo stretchy=\"false\" id=\"A2.T3.6.4.3.m1.1.1\" xref=\"A2.T3.6.4.3.m1.1.1.cmml\">‚Üì</mo><annotation-xml encoding=\"MathML-Content\" id=\"A2.T3.6.4.3.m1.1b\"><ci id=\"A2.T3.6.4.3.m1.1.1.cmml\" xref=\"A2.T3.6.4.3.m1.1.1\">‚Üì</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T3.6.4.3.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<th id=\"A2.T3.7.5.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">Acc <math id=\"A2.T3.7.5.4.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"A2.T3.7.5.4.m1.1a\"><mo stretchy=\"false\" id=\"A2.T3.7.5.4.m1.1.1\" xref=\"A2.T3.7.5.4.m1.1.1.cmml\">‚Üë</mo><annotation-xml encoding=\"MathML-Content\" id=\"A2.T3.7.5.4.m1.1b\"><ci id=\"A2.T3.7.5.4.m1.1.1.cmml\" xref=\"A2.T3.7.5.4.m1.1.1\">‚Üë</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T3.7.5.4.m1.1c\">\\uparrow</annotation></semantics></math>\n</th>\n<th id=\"A2.T3.8.6.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">Comm cost <math id=\"A2.T3.8.6.5.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"A2.T3.8.6.5.m1.1a\"><mo stretchy=\"false\" id=\"A2.T3.8.6.5.m1.1.1\" xref=\"A2.T3.8.6.5.m1.1.1.cmml\">‚Üì</mo><annotation-xml encoding=\"MathML-Content\" id=\"A2.T3.8.6.5.m1.1b\"><ci id=\"A2.T3.8.6.5.m1.1.1.cmml\" xref=\"A2.T3.8.6.5.m1.1.1\">‚Üì</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T3.8.6.5.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<th id=\"A2.T3.9.7.6\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"># of params <math id=\"A2.T3.9.7.6.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"A2.T3.9.7.6.m1.1a\"><mo stretchy=\"false\" id=\"A2.T3.9.7.6.m1.1.1\" xref=\"A2.T3.9.7.6.m1.1.1.cmml\">‚Üì</mo><annotation-xml encoding=\"MathML-Content\" id=\"A2.T3.9.7.6.m1.1b\"><ci id=\"A2.T3.9.7.6.m1.1.1.cmml\" xref=\"A2.T3.9.7.6.m1.1.1\">‚Üì</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T3.9.7.6.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A2.T3.9.8.1\" class=\"ltx_tr\">\n<th id=\"A2.T3.9.8.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">1e-05</th>\n<td id=\"A2.T3.9.8.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">63.63</td>\n<td id=\"A2.T3.9.8.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">819.44</td>\n<td id=\"A2.T3.9.8.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">7.33</td>\n<td id=\"A2.T3.9.8.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">81.89</td>\n<td id=\"A2.T3.9.8.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">819.44</td>\n<td id=\"A2.T3.9.8.1.7\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">8.54</td>\n</tr>\n<tr id=\"A2.T3.9.9.2\" class=\"ltx_tr\">\n<th id=\"A2.T3.9.9.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">5e-05</th>\n<td id=\"A2.T3.9.9.2.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"A2.T3.9.9.2.2.1\" class=\"ltx_text ltx_font_bold\">64.27</span></td>\n<td id=\"A2.T3.9.9.2.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">770.39</td>\n<td id=\"A2.T3.9.9.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">6.56</td>\n<td id=\"A2.T3.9.9.2.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">81.20</td>\n<td id=\"A2.T3.9.9.2.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">770.39</td>\n<td id=\"A2.T3.9.9.2.7\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">7.83</td>\n</tr>\n<tr id=\"A2.T3.9.10.3\" class=\"ltx_tr\">\n<th id=\"A2.T3.9.10.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">0.0001</th>\n<td id=\"A2.T3.9.10.3.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">64.22</td>\n<td id=\"A2.T3.9.10.3.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">722.60</td>\n<td id=\"A2.T3.9.10.3.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">5.54</td>\n<td id=\"A2.T3.9.10.3.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"A2.T3.9.10.3.5.1\" class=\"ltx_text ltx_font_bold\">82.19</span></td>\n<td id=\"A2.T3.9.10.3.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">722.60</td>\n<td id=\"A2.T3.9.10.3.7\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">6.69</td>\n</tr>\n<tr id=\"A2.T3.9.11.4\" class=\"ltx_tr\">\n<th id=\"A2.T3.9.11.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">0.0005</th>\n<td id=\"A2.T3.9.11.4.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">61.81</td>\n<td id=\"A2.T3.9.11.4.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">568.43</td>\n<td id=\"A2.T3.9.11.4.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">3.09</td>\n<td id=\"A2.T3.9.11.4.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">80.10</td>\n<td id=\"A2.T3.9.11.4.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">568.43</td>\n<td id=\"A2.T3.9.11.4.7\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">4.04</td>\n</tr>\n<tr id=\"A2.T3.9.12.5\" class=\"ltx_tr\">\n<th id=\"A2.T3.9.12.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">0.001</th>\n<td id=\"A2.T3.9.12.5.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">54.26</td>\n<td id=\"A2.T3.9.12.5.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"A2.T3.9.12.5.3.1\" class=\"ltx_text ltx_font_bold\">498.20</span></td>\n<td id=\"A2.T3.9.12.5.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"A2.T3.9.12.5.4.1\" class=\"ltx_text ltx_font_bold\">1.27</span></td>\n<td id=\"A2.T3.9.12.5.5\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">74.33</td>\n<td id=\"A2.T3.9.12.5.6\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"A2.T3.9.12.5.6.1\" class=\"ltx_text ltx_font_bold\">498.20</span></td>\n<td id=\"A2.T3.9.12.5.7\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"A2.T3.9.12.5.7.1\" class=\"ltx_text ltx_font_bold\">2.24</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Sensitivity of low-rank penalty ŒªùúÜ\\lambda.\nWe adjust different values to ŒªùúÜ\\lambda while fixing proximal stepsize Œ∑g=10subscriptùúÇùëî10\\eta_{g}=10 and sparse penalty Œº=0.001ùúá0.001\\mu=0.001, whose results are available in Table 3. As shown, the communication cost and number of parameters of both the mixed and GKR model are largely lowered as the low-rank penalty escalates. Notably, there is a significant drop of accuracy if the penalty ŒªùúÜ\\lambda is set too large (e.g., 0.001), however, we also see that with proper low-rank penalty (e.g., 0.0001), the accuracy performance improves for both the GKR and mixed models. This concludes that making global component to be low-rank can help better represent global knowledge across clients."
        ]
    },
    "A2.T4": {
        "caption": "Table 4: Parameter sensitivity of sparse penalty Œºùúá\\mu on CIFAR-100. ",
        "table": "<table id=\"A2.T4.11\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A2.T4.3.1\" class=\"ltx_tr\">\n<th id=\"A2.T4.3.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" style=\"padding:-0.5pt 8.5pt;\" rowspan=\"2\"><span id=\"A2.T4.3.1.1.1\" class=\"ltx_text\"><math id=\"A2.T4.3.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\mu\" display=\"inline\"><semantics id=\"A2.T4.3.1.1.1.m1.1a\"><mi id=\"A2.T4.3.1.1.1.m1.1.1\" xref=\"A2.T4.3.1.1.1.m1.1.1.cmml\">Œº</mi><annotation-xml encoding=\"MathML-Content\" id=\"A2.T4.3.1.1.1.m1.1b\"><ci id=\"A2.T4.3.1.1.1.m1.1.1.cmml\" xref=\"A2.T4.3.1.1.1.m1.1.1\">ùúá</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T4.3.1.1.1.m1.1c\">\\mu</annotation></semantics></math></span></th>\n<th id=\"A2.T4.3.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding:-0.5pt 8.5pt;\" colspan=\"3\">FedSLR (mixed model)</th>\n</tr>\n<tr id=\"A2.T4.6.4\" class=\"ltx_tr\">\n<th id=\"A2.T4.4.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding:-0.5pt 8.5pt;\">Acc <math id=\"A2.T4.4.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"A2.T4.4.2.1.m1.1a\"><mo stretchy=\"false\" id=\"A2.T4.4.2.1.m1.1.1\" xref=\"A2.T4.4.2.1.m1.1.1.cmml\">‚Üë</mo><annotation-xml encoding=\"MathML-Content\" id=\"A2.T4.4.2.1.m1.1b\"><ci id=\"A2.T4.4.2.1.m1.1.1.cmml\" xref=\"A2.T4.4.2.1.m1.1.1\">‚Üë</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T4.4.2.1.m1.1c\">\\uparrow</annotation></semantics></math>\n</th>\n<th id=\"A2.T4.5.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding:-0.5pt 8.5pt;\">Comm cost <math id=\"A2.T4.5.3.2.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"A2.T4.5.3.2.m1.1a\"><mo stretchy=\"false\" id=\"A2.T4.5.3.2.m1.1.1\" xref=\"A2.T4.5.3.2.m1.1.1.cmml\">‚Üì</mo><annotation-xml encoding=\"MathML-Content\" id=\"A2.T4.5.3.2.m1.1b\"><ci id=\"A2.T4.5.3.2.m1.1.1.cmml\" xref=\"A2.T4.5.3.2.m1.1.1\">‚Üì</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T4.5.3.2.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<th id=\"A2.T4.6.4.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding:-0.5pt 8.5pt;\"># of params <math id=\"A2.T4.6.4.3.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"A2.T4.6.4.3.m1.1a\"><mo stretchy=\"false\" id=\"A2.T4.6.4.3.m1.1.1\" xref=\"A2.T4.6.4.3.m1.1.1.cmml\">‚Üì</mo><annotation-xml encoding=\"MathML-Content\" id=\"A2.T4.6.4.3.m1.1b\"><ci id=\"A2.T4.6.4.3.m1.1.1.cmml\" xref=\"A2.T4.6.4.3.m1.1.1\">‚Üì</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T4.6.4.3.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A2.T4.7.5\" class=\"ltx_tr\">\n<th id=\"A2.T4.7.5.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding:-0.5pt 8.5pt;\">0.0001</th>\n<td id=\"A2.T4.7.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:-0.5pt 8.5pt;\">79.15</td>\n<td id=\"A2.T4.7.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:-0.5pt 8.5pt;\">720.60</td>\n<td id=\"A2.T4.7.5.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:-0.5pt 8.5pt;\">8.50 <math id=\"A2.T4.7.5.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"A2.T4.7.5.1.m1.1a\"><mo id=\"A2.T4.7.5.1.m1.1.1\" xref=\"A2.T4.7.5.1.m1.1.1.cmml\">¬±</mo><annotation-xml encoding=\"MathML-Content\" id=\"A2.T4.7.5.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A2.T4.7.5.1.m1.1.1.cmml\" xref=\"A2.T4.7.5.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T4.7.5.1.m1.1c\">\\pm</annotation></semantics></math> 0.79</td>\n</tr>\n<tr id=\"A2.T4.8.6\" class=\"ltx_tr\">\n<th id=\"A2.T4.8.6.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding:-0.5pt 8.5pt;\">0.0005</th>\n<td id=\"A2.T4.8.6.3\" class=\"ltx_td ltx_align_center\" style=\"padding:-0.5pt 8.5pt;\">81.78</td>\n<td id=\"A2.T4.8.6.4\" class=\"ltx_td ltx_align_center\" style=\"padding:-0.5pt 8.5pt;\">722.60</td>\n<td id=\"A2.T4.8.6.1\" class=\"ltx_td ltx_align_center\" style=\"padding:-0.5pt 8.5pt;\">7.12 <math id=\"A2.T4.8.6.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"A2.T4.8.6.1.m1.1a\"><mo id=\"A2.T4.8.6.1.m1.1.1\" xref=\"A2.T4.8.6.1.m1.1.1.cmml\">¬±</mo><annotation-xml encoding=\"MathML-Content\" id=\"A2.T4.8.6.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A2.T4.8.6.1.m1.1.1.cmml\" xref=\"A2.T4.8.6.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T4.8.6.1.m1.1c\">\\pm</annotation></semantics></math> 0.65</td>\n</tr>\n<tr id=\"A2.T4.9.7\" class=\"ltx_tr\">\n<th id=\"A2.T4.9.7.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding:-0.5pt 8.5pt;\">0.001</th>\n<td id=\"A2.T4.9.7.3\" class=\"ltx_td ltx_align_center\" style=\"padding:-0.5pt 8.5pt;\"><span id=\"A2.T4.9.7.3.1\" class=\"ltx_text ltx_font_bold\">82.19</span></td>\n<td id=\"A2.T4.9.7.4\" class=\"ltx_td ltx_align_center\" style=\"padding:-0.5pt 8.5pt;\">722.60</td>\n<td id=\"A2.T4.9.7.1\" class=\"ltx_td ltx_align_center\" style=\"padding:-0.5pt 8.5pt;\">6.69 <math id=\"A2.T4.9.7.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"A2.T4.9.7.1.m1.1a\"><mo id=\"A2.T4.9.7.1.m1.1.1\" xref=\"A2.T4.9.7.1.m1.1.1.cmml\">¬±</mo><annotation-xml encoding=\"MathML-Content\" id=\"A2.T4.9.7.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A2.T4.9.7.1.m1.1.1.cmml\" xref=\"A2.T4.9.7.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T4.9.7.1.m1.1c\">\\pm</annotation></semantics></math> 0.56</td>\n</tr>\n<tr id=\"A2.T4.10.8\" class=\"ltx_tr\">\n<th id=\"A2.T4.10.8.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding:-0.5pt 8.5pt;\">0.005</th>\n<td id=\"A2.T4.10.8.3\" class=\"ltx_td ltx_align_center\" style=\"padding:-0.5pt 8.5pt;\">81.82</td>\n<td id=\"A2.T4.10.8.4\" class=\"ltx_td ltx_align_center\" style=\"padding:-0.5pt 8.5pt;\">722.60</td>\n<td id=\"A2.T4.10.8.1\" class=\"ltx_td ltx_align_center\" style=\"padding:-0.5pt 8.5pt;\">5.78 <math id=\"A2.T4.10.8.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"A2.T4.10.8.1.m1.1a\"><mo id=\"A2.T4.10.8.1.m1.1.1\" xref=\"A2.T4.10.8.1.m1.1.1.cmml\">¬±</mo><annotation-xml encoding=\"MathML-Content\" id=\"A2.T4.10.8.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A2.T4.10.8.1.m1.1.1.cmml\" xref=\"A2.T4.10.8.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T4.10.8.1.m1.1c\">\\pm</annotation></semantics></math> 0.17</td>\n</tr>\n<tr id=\"A2.T4.11.9\" class=\"ltx_tr\">\n<th id=\"A2.T4.11.9.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\" style=\"padding:-0.5pt 8.5pt;\">0.01</th>\n<td id=\"A2.T4.11.9.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding:-0.5pt 8.5pt;\">80.81</td>\n<td id=\"A2.T4.11.9.4\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding:-0.5pt 8.5pt;\">720.60</td>\n<td id=\"A2.T4.11.9.1\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding:-0.5pt 8.5pt;\">\n<span id=\"A2.T4.11.9.1.1\" class=\"ltx_text ltx_font_bold\">5.56</span> <math id=\"A2.T4.11.9.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"A2.T4.11.9.1.m1.1a\"><mo id=\"A2.T4.11.9.1.m1.1.1\" xref=\"A2.T4.11.9.1.m1.1.1.cmml\">¬±</mo><annotation-xml encoding=\"MathML-Content\" id=\"A2.T4.11.9.1.m1.1b\"><csymbol cd=\"latexml\" id=\"A2.T4.11.9.1.m1.1.1.cmml\" xref=\"A2.T4.11.9.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T4.11.9.1.m1.1c\">\\pm</annotation></semantics></math> 0.08</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            "Sensitivity of sparse penalty Œºùúá\\mu. Then we fix Œ∑g=10subscriptùúÇùëî10\\eta_{g}=10 and low-rank penalty to Œª=1‚Äãe‚àí4ùúÜ1superscriptùëí4\\lambda=1e^{-4} while adjusting Œºùúá\\mu. As shown in Table 4, via enlarging the sparse penalty, the number of parameters of the personalized models could be lowered, but would sacrifice some accuracy performance. However, we also observe that proper sparse regularization would induce even better performance for the personalized models. This further corroborates that the personalized component to be sparse can better capture the local pattern."
        ]
    },
    "A2.T5": {
        "caption": "Table 5: Parameter sensitivity of proximal step size Œ∑gsubscriptùúÇùëî\\eta_{g} on CIFAR-100. ",
        "table": "<table id=\"A2.T5.9\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A2.T5.3.1\" class=\"ltx_tr\">\n<th id=\"A2.T5.3.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\" rowspan=\"2\"><span id=\"A2.T5.3.1.1.1\" class=\"ltx_text\"><math id=\"A2.T5.3.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\eta_{g}\" display=\"inline\"><semantics id=\"A2.T5.3.1.1.1.m1.1a\"><msub id=\"A2.T5.3.1.1.1.m1.1.1\" xref=\"A2.T5.3.1.1.1.m1.1.1.cmml\"><mi id=\"A2.T5.3.1.1.1.m1.1.1.2\" xref=\"A2.T5.3.1.1.1.m1.1.1.2.cmml\">Œ∑</mi><mi id=\"A2.T5.3.1.1.1.m1.1.1.3\" xref=\"A2.T5.3.1.1.1.m1.1.1.3.cmml\">g</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"A2.T5.3.1.1.1.m1.1b\"><apply id=\"A2.T5.3.1.1.1.m1.1.1.cmml\" xref=\"A2.T5.3.1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"A2.T5.3.1.1.1.m1.1.1.1.cmml\" xref=\"A2.T5.3.1.1.1.m1.1.1\">subscript</csymbol><ci id=\"A2.T5.3.1.1.1.m1.1.1.2.cmml\" xref=\"A2.T5.3.1.1.1.m1.1.1.2\">ùúÇ</ci><ci id=\"A2.T5.3.1.1.1.m1.1.1.3.cmml\" xref=\"A2.T5.3.1.1.1.m1.1.1.3\">ùëî</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T5.3.1.1.1.m1.1c\">\\eta_{g}</annotation></semantics></math></span></th>\n<th id=\"A2.T5.3.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\" colspan=\"3\">FedSLR (GKR)</th>\n<th id=\"A2.T5.3.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\" colspan=\"3\">FedSLR (mixed model)</th>\n</tr>\n<tr id=\"A2.T5.9.7\" class=\"ltx_tr\">\n<th id=\"A2.T5.4.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">Acc <math id=\"A2.T5.4.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"A2.T5.4.2.1.m1.1a\"><mo stretchy=\"false\" id=\"A2.T5.4.2.1.m1.1.1\" xref=\"A2.T5.4.2.1.m1.1.1.cmml\">‚Üë</mo><annotation-xml encoding=\"MathML-Content\" id=\"A2.T5.4.2.1.m1.1b\"><ci id=\"A2.T5.4.2.1.m1.1.1.cmml\" xref=\"A2.T5.4.2.1.m1.1.1\">‚Üë</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T5.4.2.1.m1.1c\">\\uparrow</annotation></semantics></math>\n</th>\n<th id=\"A2.T5.5.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">Comm cost <math id=\"A2.T5.5.3.2.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"A2.T5.5.3.2.m1.1a\"><mo stretchy=\"false\" id=\"A2.T5.5.3.2.m1.1.1\" xref=\"A2.T5.5.3.2.m1.1.1.cmml\">‚Üì</mo><annotation-xml encoding=\"MathML-Content\" id=\"A2.T5.5.3.2.m1.1b\"><ci id=\"A2.T5.5.3.2.m1.1.1.cmml\" xref=\"A2.T5.5.3.2.m1.1.1\">‚Üì</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T5.5.3.2.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<th id=\"A2.T5.6.4.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"># of params <math id=\"A2.T5.6.4.3.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"A2.T5.6.4.3.m1.1a\"><mo stretchy=\"false\" id=\"A2.T5.6.4.3.m1.1.1\" xref=\"A2.T5.6.4.3.m1.1.1.cmml\">‚Üì</mo><annotation-xml encoding=\"MathML-Content\" id=\"A2.T5.6.4.3.m1.1b\"><ci id=\"A2.T5.6.4.3.m1.1.1.cmml\" xref=\"A2.T5.6.4.3.m1.1.1\">‚Üì</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T5.6.4.3.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<th id=\"A2.T5.7.5.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">Acc <math id=\"A2.T5.7.5.4.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"A2.T5.7.5.4.m1.1a\"><mo stretchy=\"false\" id=\"A2.T5.7.5.4.m1.1.1\" xref=\"A2.T5.7.5.4.m1.1.1.cmml\">‚Üë</mo><annotation-xml encoding=\"MathML-Content\" id=\"A2.T5.7.5.4.m1.1b\"><ci id=\"A2.T5.7.5.4.m1.1.1.cmml\" xref=\"A2.T5.7.5.4.m1.1.1\">‚Üë</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T5.7.5.4.m1.1c\">\\uparrow</annotation></semantics></math>\n</th>\n<th id=\"A2.T5.8.6.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">Comm cost <math id=\"A2.T5.8.6.5.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"A2.T5.8.6.5.m1.1a\"><mo stretchy=\"false\" id=\"A2.T5.8.6.5.m1.1.1\" xref=\"A2.T5.8.6.5.m1.1.1.cmml\">‚Üì</mo><annotation-xml encoding=\"MathML-Content\" id=\"A2.T5.8.6.5.m1.1b\"><ci id=\"A2.T5.8.6.5.m1.1.1.cmml\" xref=\"A2.T5.8.6.5.m1.1.1\">‚Üì</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T5.8.6.5.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<th id=\"A2.T5.9.7.6\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"># of params <math id=\"A2.T5.9.7.6.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"A2.T5.9.7.6.m1.1a\"><mo stretchy=\"false\" id=\"A2.T5.9.7.6.m1.1.1\" xref=\"A2.T5.9.7.6.m1.1.1.cmml\">‚Üì</mo><annotation-xml encoding=\"MathML-Content\" id=\"A2.T5.9.7.6.m1.1b\"><ci id=\"A2.T5.9.7.6.m1.1.1.cmml\" xref=\"A2.T5.9.7.6.m1.1.1\">‚Üì</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T5.9.7.6.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A2.T5.9.8.1\" class=\"ltx_tr\">\n<th id=\"A2.T5.9.8.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">2</th>\n<td id=\"A2.T5.9.8.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">60.74</td>\n<td id=\"A2.T5.9.8.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">894.06</td>\n<td id=\"A2.T5.9.8.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">10.65</td>\n<td id=\"A2.T5.9.8.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">80.37</td>\n<td id=\"A2.T5.9.8.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">894.06</td>\n<td id=\"A2.T5.9.8.1.7\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">12.36</td>\n</tr>\n<tr id=\"A2.T5.9.9.2\" class=\"ltx_tr\">\n<th id=\"A2.T5.9.9.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">10</th>\n<td id=\"A2.T5.9.9.2.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"A2.T5.9.9.2.2.1\" class=\"ltx_text ltx_font_bold\">64.22</span></td>\n<td id=\"A2.T5.9.9.2.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">722.60</td>\n<td id=\"A2.T5.9.9.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">5.54</td>\n<td id=\"A2.T5.9.9.2.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"A2.T5.9.9.2.5.1\" class=\"ltx_text ltx_font_bold\">82.19</span></td>\n<td id=\"A2.T5.9.9.2.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">722.60</td>\n<td id=\"A2.T5.9.9.2.7\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">6.69</td>\n</tr>\n<tr id=\"A2.T5.9.10.3\" class=\"ltx_tr\">\n<th id=\"A2.T5.9.10.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">20</th>\n<td id=\"A2.T5.9.10.3.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">61.02</td>\n<td id=\"A2.T5.9.10.3.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">668.94</td>\n<td id=\"A2.T5.9.10.3.4\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">5.16</td>\n<td id=\"A2.T5.9.10.3.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">80.60</td>\n<td id=\"A2.T5.9.10.3.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">668.94</td>\n<td id=\"A2.T5.9.10.3.7\" class=\"ltx_td ltx_nopad_r ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">6.15</td>\n</tr>\n<tr id=\"A2.T5.9.11.4\" class=\"ltx_tr\">\n<th id=\"A2.T5.9.11.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">100</th>\n<td id=\"A2.T5.9.11.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">58.69</td>\n<td id=\"A2.T5.9.11.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"A2.T5.9.11.4.3.1\" class=\"ltx_text ltx_font_bold\">559.88</span></td>\n<td id=\"A2.T5.9.11.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"A2.T5.9.11.4.4.1\" class=\"ltx_text ltx_font_bold\">2.99</span></td>\n<td id=\"A2.T5.9.11.4.5\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">78.33</td>\n<td id=\"A2.T5.9.11.4.6\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"A2.T5.9.11.4.6.1\" class=\"ltx_text ltx_font_bold\">559.88</span></td>\n<td id=\"A2.T5.9.11.4.7\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"A2.T5.9.11.4.7.1\" class=\"ltx_text ltx_font_bold\">3.90</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We conduct experiment on CIFAR-100 to evaluate the hyper-parameters sensitivity of FedSLR.",
                "Sensitivity of low-rank penalty ",
                "Œª",
                "ùúÜ",
                "\\lambda",
                ".",
                "\nWe adjust different values to ",
                "Œª",
                "ùúÜ",
                "\\lambda",
                " while fixing proximal stepsize ",
                "Œ∑",
                "g",
                "=",
                "10",
                "subscript",
                "ùúÇ",
                "ùëî",
                "10",
                "\\eta_{g}=10",
                " and sparse penalty ",
                "Œº",
                "=",
                "0.001",
                "ùúá",
                "0.001",
                "\\mu=0.001",
                ", whose results are available in Table ",
                "3",
                ". As shown, the communication cost and number of parameters of both the mixed and GKR model are largely lowered as the low-rank penalty escalates. Notably, there is a significant drop of accuracy if the penalty ",
                "Œª",
                "ùúÜ",
                "\\lambda",
                " is set too large (e.g., 0.001), however, we also see that with proper low-rank penalty (e.g., 0.0001), the accuracy performance improves for both the GKR and mixed models. This concludes that making global component to be low-rank can help better represent global knowledge across clients.",
                "Sensitivity of sparse penalty ",
                "Œº",
                "ùúá",
                "\\mu",
                ".",
                " Then we fix ",
                "Œ∑",
                "g",
                "=",
                "10",
                "subscript",
                "ùúÇ",
                "ùëî",
                "10",
                "\\eta_{g}=10",
                " and low-rank penalty to ",
                "Œª",
                "=",
                "1",
                "‚Äã",
                "e",
                "‚àí",
                "4",
                "ùúÜ",
                "1",
                "superscript",
                "ùëí",
                "4",
                "\\lambda=1e^{-4}",
                " while adjusting ",
                "Œº",
                "ùúá",
                "\\mu",
                ". As shown in Table ",
                "4",
                ", via enlarging the sparse penalty, the number of parameters of the personalized models could be lowered, but would sacrifice some accuracy performance. However, we also observe that proper sparse regularization would induce even better performance for the personalized models. This further corroborates that the personalized component to be sparse can better capture the local pattern.",
                "Sensitivity of proximal step size ",
                "Œ∑",
                "g",
                "subscript",
                "ùúÇ",
                "ùëî",
                "\\eta_{g}",
                ".",
                " We then tune the proximal step size ",
                "Œ∑",
                "g",
                "subscript",
                "ùúÇ",
                "ùëî",
                "\\eta_{g}",
                " while fixing ",
                "Œª",
                "=",
                "1",
                "‚Äã",
                "e",
                "‚àí",
                "4",
                "ùúÜ",
                "1",
                "superscript",
                "ùëí",
                "4",
                "\\lambda=1e^{-4}",
                " and ",
                "Œº",
                "=",
                "0.001",
                "ùúá",
                "0.001",
                "\\mu=0.001",
                ". As can be observed, choosing ",
                "Œ∑",
                "g",
                "subscript",
                "ùúÇ",
                "ùëî",
                "\\eta_{g}",
                " to a proper value is vital to the accuracy performance of FedSLR. Additionally, we see that with a larger ",
                "Œ∑",
                "g",
                "subscript",
                "ùúÇ",
                "ùëî",
                "\\eta_{g}",
                ", the obtained model size and communication cost can be reduced, which can be explained by looking into the proximal operator. Specifically, for ",
                "Œ∑",
                "g",
                "subscript",
                "ùúÇ",
                "ùëî",
                "\\eta_{g}",
                " that is too large, the proximal operator would prune out most of the singular value of the model‚Äôs weight matrix. Therefore the parameter number along with the communication cost would reduce with a larger ",
                "Œ∑",
                "g",
                "subscript",
                "ùúÇ",
                "ùëî",
                "\\eta_{g}",
                ", but the accuracy performance would probably degrade simultaneously.",
                "Sensitivity of local steps.",
                "  In algorithm ",
                "1",
                ", we requires each client to exactly solve the local sub-problem in line 14, which may not be realistic due to limited local steps. We show in Table ",
                "6",
                " how applying different epochs would affect the empirical accuracy performance of FedSLR. Results show that with sufficiently large local epochs, e.g., 2 local epochs, the accuracy performance can be well guaranteed.\n"
            ]
        ]
    },
    "A2.T6": {
        "caption": "Table 6: Parameter sensitivity of local Steps on CIFAR-100 under Non-IID setting. ",
        "table": "<table id=\"A2.T6.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A2.T6.4.1.1\" class=\"ltx_tr\">\n<th id=\"A2.T6.4.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">Methods\\local Steps</th>\n<th id=\"A2.T6.4.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">25 (1 epoch)</th>\n<th id=\"A2.T6.4.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">50 (2 epochs)</th>\n<th id=\"A2.T6.4.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">75 (3 epochs)</th>\n<th id=\"A2.T6.4.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">100 (4 epochs)</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A2.T6.4.2.1\" class=\"ltx_tr\">\n<td id=\"A2.T6.4.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">FedSLR (GKR)</td>\n<td id=\"A2.T6.4.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">58.20</td>\n<td id=\"A2.T6.4.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">64.51</td>\n<td id=\"A2.T6.4.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">63.86</td>\n<td id=\"A2.T6.4.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">64.17</td>\n</tr>\n<tr id=\"A2.T6.4.3.2\" class=\"ltx_tr\">\n<td id=\"A2.T6.4.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">FedSLR (mixed)</td>\n<td id=\"A2.T6.4.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">78.82</td>\n<td id=\"A2.T6.4.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">81.46</td>\n<td id=\"A2.T6.4.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">81.97</td>\n<td id=\"A2.T6.4.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">82.20</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We conduct experiment on CIFAR-100 to evaluate the hyper-parameters sensitivity of FedSLR.",
                "Sensitivity of low-rank penalty ",
                "Œª",
                "ùúÜ",
                "\\lambda",
                ".",
                "\nWe adjust different values to ",
                "Œª",
                "ùúÜ",
                "\\lambda",
                " while fixing proximal stepsize ",
                "Œ∑",
                "g",
                "=",
                "10",
                "subscript",
                "ùúÇ",
                "ùëî",
                "10",
                "\\eta_{g}=10",
                " and sparse penalty ",
                "Œº",
                "=",
                "0.001",
                "ùúá",
                "0.001",
                "\\mu=0.001",
                ", whose results are available in Table ",
                "3",
                ". As shown, the communication cost and number of parameters of both the mixed and GKR model are largely lowered as the low-rank penalty escalates. Notably, there is a significant drop of accuracy if the penalty ",
                "Œª",
                "ùúÜ",
                "\\lambda",
                " is set too large (e.g., 0.001), however, we also see that with proper low-rank penalty (e.g., 0.0001), the accuracy performance improves for both the GKR and mixed models. This concludes that making global component to be low-rank can help better represent global knowledge across clients.",
                "Sensitivity of sparse penalty ",
                "Œº",
                "ùúá",
                "\\mu",
                ".",
                " Then we fix ",
                "Œ∑",
                "g",
                "=",
                "10",
                "subscript",
                "ùúÇ",
                "ùëî",
                "10",
                "\\eta_{g}=10",
                " and low-rank penalty to ",
                "Œª",
                "=",
                "1",
                "‚Äã",
                "e",
                "‚àí",
                "4",
                "ùúÜ",
                "1",
                "superscript",
                "ùëí",
                "4",
                "\\lambda=1e^{-4}",
                " while adjusting ",
                "Œº",
                "ùúá",
                "\\mu",
                ". As shown in Table ",
                "4",
                ", via enlarging the sparse penalty, the number of parameters of the personalized models could be lowered, but would sacrifice some accuracy performance. However, we also observe that proper sparse regularization would induce even better performance for the personalized models. This further corroborates that the personalized component to be sparse can better capture the local pattern.",
                "Sensitivity of proximal step size ",
                "Œ∑",
                "g",
                "subscript",
                "ùúÇ",
                "ùëî",
                "\\eta_{g}",
                ".",
                " We then tune the proximal step size ",
                "Œ∑",
                "g",
                "subscript",
                "ùúÇ",
                "ùëî",
                "\\eta_{g}",
                " while fixing ",
                "Œª",
                "=",
                "1",
                "‚Äã",
                "e",
                "‚àí",
                "4",
                "ùúÜ",
                "1",
                "superscript",
                "ùëí",
                "4",
                "\\lambda=1e^{-4}",
                " and ",
                "Œº",
                "=",
                "0.001",
                "ùúá",
                "0.001",
                "\\mu=0.001",
                ". As can be observed, choosing ",
                "Œ∑",
                "g",
                "subscript",
                "ùúÇ",
                "ùëî",
                "\\eta_{g}",
                " to a proper value is vital to the accuracy performance of FedSLR. Additionally, we see that with a larger ",
                "Œ∑",
                "g",
                "subscript",
                "ùúÇ",
                "ùëî",
                "\\eta_{g}",
                ", the obtained model size and communication cost can be reduced, which can be explained by looking into the proximal operator. Specifically, for ",
                "Œ∑",
                "g",
                "subscript",
                "ùúÇ",
                "ùëî",
                "\\eta_{g}",
                " that is too large, the proximal operator would prune out most of the singular value of the model‚Äôs weight matrix. Therefore the parameter number along with the communication cost would reduce with a larger ",
                "Œ∑",
                "g",
                "subscript",
                "ùúÇ",
                "ùëî",
                "\\eta_{g}",
                ", but the accuracy performance would probably degrade simultaneously.",
                "Sensitivity of local steps.",
                "  In algorithm ",
                "1",
                ", we requires each client to exactly solve the local sub-problem in line 14, which may not be realistic due to limited local steps. We show in Table ",
                "6",
                " how applying different epochs would affect the empirical accuracy performance of FedSLR. Results show that with sufficiently large local epochs, e.g., 2 local epochs, the accuracy performance can be well guaranteed.\n"
            ]
        ]
    },
    "A2.T7": {
        "caption": "Table 7: Accuracy performance of pure personalized component on on CIFAR-100 under Non-IID setting. ",
        "table": "<table id=\"A2.T7.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A2.T7.1.1\" class=\"ltx_tr\">\n<th id=\"A2.T7.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">\n<span id=\"A2.T7.1.1.1.1\" class=\"ltx_text\" style=\"color:#000000;\">Sparse Penalty (</span><math id=\"A2.T7.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\mu\" display=\"inline\"><semantics id=\"A2.T7.1.1.1.m1.1a\"><mi mathcolor=\"#000000\" id=\"A2.T7.1.1.1.m1.1.1\" xref=\"A2.T7.1.1.1.m1.1.1.cmml\">Œº</mi><annotation-xml encoding=\"MathML-Content\" id=\"A2.T7.1.1.1.m1.1b\"><ci id=\"A2.T7.1.1.1.m1.1.1.cmml\" xref=\"A2.T7.1.1.1.m1.1.1\">ùúá</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T7.1.1.1.m1.1c\">\\mu</annotation></semantics></math><span id=\"A2.T7.1.1.1.2\" class=\"ltx_text\" style=\"color:#000000;\">)</span>\n</th>\n<th id=\"A2.T7.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"A2.T7.1.1.2.1\" class=\"ltx_text\" style=\"color:#000000;\">1e-3</span></th>\n<th id=\"A2.T7.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"A2.T7.1.1.3.1\" class=\"ltx_text\" style=\"color:#000000;\">1e-4</span></th>\n<th id=\"A2.T7.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"A2.T7.1.1.4.1\" class=\"ltx_text\" style=\"color:#000000;\">1e-5</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A2.T7.1.2.1\" class=\"ltx_tr\">\n<td id=\"A2.T7.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"A2.T7.1.2.1.1.1\" class=\"ltx_text\" style=\"color:#000000;\">Acc of pure personalization</span></td>\n<td id=\"A2.T7.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"A2.T7.1.2.1.2.1\" class=\"ltx_text\" style=\"color:#000000;\">37.14</span></td>\n<td id=\"A2.T7.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"A2.T7.1.2.1.3.1\" class=\"ltx_text\" style=\"color:#000000;\">44.16</span></td>\n<td id=\"A2.T7.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"A2.T7.1.2.1.4.1\" class=\"ltx_text\" style=\"color:#000000;\">44.54</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "To motivate our low-rank-plus-sparse solution, we tune the low-sparse/sparse penalty respectively to extreme cases to recover the pure global and personalized component. Specifically, we first tune the low-rank penalty to 10 (a very large value) to zero out the global component, and adjust the sparse penalty to see how the sparse intensity would affect the personalized component‚Äôs performance. The results are shown in Table ",
                "7",
                ". Additionally, we tune the low-rank penalty, while fixing sparse penalty to a large value to see how the pure global component performs. The results are shown in Table ",
                "8",
                ".",
                "Our results show that i) too much sparsity/low-rank penalty would hurt the model‚Äôs performance, and ii) pure local component cannot perform better than the pure global component due to lack of information exchange between clients, which justifies the necessity of collaborative training.\n"
            ]
        ]
    },
    "A2.T8": {
        "caption": "Table 8: Accuracy performance of pure global component on CIFAR-100 under Non-IID setting. ",
        "table": "<table id=\"A2.T8.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A2.T8.1.1\" class=\"ltx_tr\">\n<th id=\"A2.T8.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">\n<span id=\"A2.T8.1.1.1.1\" class=\"ltx_text\" style=\"color:#000000;\">Low-rank Penalty (</span><math id=\"A2.T8.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\lambda\" display=\"inline\"><semantics id=\"A2.T8.1.1.1.m1.1a\"><mi mathcolor=\"#000000\" id=\"A2.T8.1.1.1.m1.1.1\" xref=\"A2.T8.1.1.1.m1.1.1.cmml\">Œª</mi><annotation-xml encoding=\"MathML-Content\" id=\"A2.T8.1.1.1.m1.1b\"><ci id=\"A2.T8.1.1.1.m1.1.1.cmml\" xref=\"A2.T8.1.1.1.m1.1.1\">ùúÜ</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T8.1.1.1.m1.1c\">\\lambda</annotation></semantics></math><span id=\"A2.T8.1.1.1.2\" class=\"ltx_text\" style=\"color:#000000;\">)</span>\n</th>\n<th id=\"A2.T8.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"A2.T8.1.1.2.1\" class=\"ltx_text\" style=\"color:#000000;\">1e-3</span></th>\n<th id=\"A2.T8.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"A2.T8.1.1.3.1\" class=\"ltx_text\" style=\"color:#000000;\">1e-4</span></th>\n<th id=\"A2.T8.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"A2.T8.1.1.4.1\" class=\"ltx_text\" style=\"color:#000000;\">1e-5</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A2.T8.1.2.1\" class=\"ltx_tr\">\n<td id=\"A2.T8.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"A2.T8.1.2.1.1.1\" class=\"ltx_text\" style=\"color:#000000;\">Acc of pure global</span></td>\n<td id=\"A2.T8.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"A2.T8.1.2.1.2.1\" class=\"ltx_text\" style=\"color:#000000;\">54.26</span></td>\n<td id=\"A2.T8.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"A2.T8.1.2.1.3.1\" class=\"ltx_text\" style=\"color:#000000;\">64.22</span></td>\n<td id=\"A2.T8.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"><span id=\"A2.T8.1.2.1.4.1\" class=\"ltx_text\" style=\"color:#000000;\">63.63</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "To motivate our low-rank-plus-sparse solution, we tune the low-sparse/sparse penalty respectively to extreme cases to recover the pure global and personalized component. Specifically, we first tune the low-rank penalty to 10 (a very large value) to zero out the global component, and adjust the sparse penalty to see how the sparse intensity would affect the personalized component‚Äôs performance. The results are shown in Table ",
                "7",
                ". Additionally, we tune the low-rank penalty, while fixing sparse penalty to a large value to see how the pure global component performs. The results are shown in Table ",
                "8",
                ".",
                "Our results show that i) too much sparsity/low-rank penalty would hurt the model‚Äôs performance, and ii) pure local component cannot perform better than the pure global component due to lack of information exchange between clients, which justifies the necessity of collaborative training.\n"
            ]
        ]
    },
    "A2.T9": {
        "caption": "Table 9: Inference latency (milliseconds/batch) of GKR under different low-rank penalty. ",
        "table": "<table id=\"A2.T9.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"A2.T9.1.1\" class=\"ltx_tr\">\n<th id=\"A2.T9.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">Low-rank Penalty (<math id=\"A2.T9.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\lambda\" display=\"inline\"><semantics id=\"A2.T9.1.1.1.m1.1a\"><mi id=\"A2.T9.1.1.1.m1.1.1\" xref=\"A2.T9.1.1.1.m1.1.1.cmml\">Œª</mi><annotation-xml encoding=\"MathML-Content\" id=\"A2.T9.1.1.1.m1.1b\"><ci id=\"A2.T9.1.1.1.m1.1.1.cmml\" xref=\"A2.T9.1.1.1.m1.1.1\">ùúÜ</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"A2.T9.1.1.1.m1.1c\">\\lambda</annotation></semantics></math>)</th>\n<th id=\"A2.T9.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">0</th>\n<th id=\"A2.T9.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">1e-5</th>\n<th id=\"A2.T9.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">5e-5</th>\n<th id=\"A2.T9.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">1e-4</th>\n<th id=\"A2.T9.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">5e-4</th>\n<th id=\"A2.T9.1.1.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">1e-3</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"A2.T9.1.2.1\" class=\"ltx_tr\">\n<td id=\"A2.T9.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\"># of params (M)</td>\n<td id=\"A2.T9.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">11.17</td>\n<td id=\"A2.T9.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">7.33</td>\n<td id=\"A2.T9.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">6.56</td>\n<td id=\"A2.T9.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">5.54</td>\n<td id=\"A2.T9.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">3.09</td>\n<td id=\"A2.T9.1.2.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">1.27</td>\n</tr>\n<tr id=\"A2.T9.1.3.2\" class=\"ltx_tr\">\n<td id=\"A2.T9.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">Inference latency (ms)</td>\n<td id=\"A2.T9.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">10.98</td>\n<td id=\"A2.T9.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">10.12</td>\n<td id=\"A2.T9.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">9.30</td>\n<td id=\"A2.T9.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">9.24</td>\n<td id=\"A2.T9.1.3.2.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">7.62</td>\n<td id=\"A2.T9.1.3.2.7\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">6.53</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": "",
        "references": [
            [
                "We measure the inference latency of the low-rank GKR on a Tesla M60 GPU. The batch size of each batch of testing data is set to 20. The result is shown in Table ",
                "9",
                ". Our results indicate that factorizing model weights can indeed accelerate the GKR model‚Äôs inference speed."
            ]
        ]
    }
}