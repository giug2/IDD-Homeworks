{
    "id1.p1.2": {
        "caption": null,
        "table": null,
        "footnotes": [],
        "references": []
    },
    "S5.T1.1": {
        "caption": "Datasets used in our experiments.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S5.T1.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S5.T1.1.1.1\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column\" id=\"S5.T1.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.1.1.1.1.1\" style=\"font-size:90%;\">Dataset</span></th>\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r\" id=\"S5.T1.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.1.1.1.2.1\" style=\"font-size:90%;\">Source</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column\" id=\"S5.T1.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S5.T1.1.1.1.3.1\" style=\"font-size:90%;\">#sents</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S5.T1.1.2.1\">\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S5.T1.1.2.1.1\"><span class=\"ltx_text\" id=\"S5.T1.1.2.1.1.1\" style=\"font-size:90%;\">EN&#8211;KN training</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" id=\"S5.T1.1.2.1.2\"><span class=\"ltx_text\" id=\"S5.T1.1.2.1.2.1\" style=\"font-size:90%;\">Samanantar</span></td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S5.T1.1.2.1.3\"><span class=\"ltx_text\" id=\"S5.T1.1.2.1.3.1\" style=\"font-size:90%;\">4,093,524</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T1.1.3.2\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T1.1.3.2.1\"><span class=\"ltx_text\" id=\"S5.T1.1.3.2.1.1\" style=\"font-size:90%;\">EN&#8211;KN test</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T1.1.3.2.2\"><span class=\"ltx_text\" id=\"S5.T1.1.3.2.2.1\" style=\"font-size:90%;\">FLORES-200</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T1.1.3.2.3\"><span class=\"ltx_text\" id=\"S5.T1.1.3.2.3.1\" style=\"font-size:90%;\">2,009</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T1.1.4.3\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T1.1.4.3.1\"><span class=\"ltx_text\" id=\"S5.T1.1.4.3.1.1\" style=\"font-size:90%;\">TCY monolingual</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T1.1.4.3.2\"><span class=\"ltx_text\" id=\"S5.T1.1.4.3.2.1\" style=\"font-size:90%;\">Wikipedia</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T1.1.4.3.3\"><span class=\"ltx_text\" id=\"S5.T1.1.4.3.3.1\" style=\"font-size:90%;\">40,124</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T1.1.5.4\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T1.1.5.4.1\"><span class=\"ltx_text\" id=\"S5.T1.1.5.4.1.1\" style=\"font-size:90%;\">EN&#8211;TCY test</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T1.1.5.4.2\"><span class=\"ltx_text\" id=\"S5.T1.1.5.4.2.1\" style=\"font-size:90%;\">Human transl. FLORES</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T1.1.5.4.3\"><span class=\"ltx_text\" id=\"S5.T1.1.5.4.3.1\" style=\"font-size:90%;\">1,300</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S5.T1.1.6.5\">\n<td class=\"ltx_td ltx_align_left\" id=\"S5.T1.1.6.5.1\"><span class=\"ltx_text\" id=\"S5.T1.1.6.5.1.1\" style=\"font-size:90%;\">EN&#8211;TCY training</span></td>\n<td class=\"ltx_td ltx_align_left ltx_border_r\" id=\"S5.T1.1.6.5.2\"><span class=\"ltx_text\" id=\"S5.T1.1.6.5.2.1\" style=\"font-size:90%;\">DravidianLangTech-22</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S5.T1.1.6.5.3\"><span class=\"ltx_text\" id=\"S5.T1.1.6.5.3.1\" style=\"font-size:90%;\">8,300</span></td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": []
    },
    "S6.T2.1": {
        "caption": "BLEU scores for each step in the training with 2 iterations.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_align_middle\" id=\"S6.T2.1\">\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S6.T2.1.1.1\">\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T2.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T2.1.1.1.1.1\">Iteration</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T2.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T2.1.1.1.2.1\">Direction</span></td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T2.1.1.1.3.1\">Task no.</span></td>\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T2.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T2.1.1.1.4.1\">Task</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S6.T2.1.1.1.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T2.1.1.1.5.1\">Lannguages</span></td>\n<td class=\"ltx_td ltx_align_right\" id=\"S6.T2.1.1.1.6\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T2.1.1.1.6.1\">BLEU</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T2.1.2.2\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S6.T2.1.2.2.1\" rowspan=\"10\"><span class=\"ltx_text\" id=\"S6.T2.1.2.2.1.1\">1</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T2.1.2.2.2\">TCY&#8211;EN</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T2.1.2.2.3\">1</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S6.T2.1.2.2.4\">fine-tuning with</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S6.T2.1.2.2.5\">KN&#8211;EN</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S6.T2.1.2.2.6\">1.84</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T2.1.3.3\">\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.1.3.3.1\">EN&#8211;TCY</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.1.3.3.2\">2</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T2.1.3.3.3\">back-translation with</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S6.T2.1.3.3.4\">EN&#8211;TCY</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S6.T2.1.3.3.5\">12.83</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T2.1.4.4\">\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.1.4.4.1\">EN&#8211;TCY</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.1.4.4.2\">3</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T2.1.4.4.3\">training with parallel</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S6.T2.1.4.4.4\">EN&#8211;KN</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S6.T2.1.4.4.5\">17.27</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T2.1.5.5\">\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.1.5.5.1\">EN&#8211;TCY</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.1.5.5.2\">4a</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T2.1.5.5.3\">denoising autoencoding with</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S6.T2.1.5.5.4\">KN</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S6.T2.1.5.5.5\">3.20</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T2.1.6.6\">\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.1.6.6.1\">EN&#8211;TCY</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.1.6.6.2\">4b</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T2.1.6.6.3\">denoising autoencoding with</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S6.T2.1.6.6.4\">TCY</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S6.T2.1.6.6.5\">5.92</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T2.1.7.7\">\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.1.7.7.1\">EN&#8211;TCY</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.1.7.7.2\">5</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T2.1.7.7.3\">fine-tuning with back-translation data</td>\n<td class=\"ltx_td ltx_border_r\" id=\"S6.T2.1.7.7.4\"/>\n<td class=\"ltx_td ltx_align_right\" id=\"S6.T2.1.7.7.5\">11.06</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T2.1.8.8\">\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.1.8.8.1\">TCY&#8211;EN</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.1.8.8.2\">2</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T2.1.8.8.3\">back-translation with</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S6.T2.1.8.8.4\">TCY&#8211;EN</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S6.T2.1.8.8.5\">19.53</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T2.1.9.9\">\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.1.9.9.1\">TCY&#8211;EN</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.1.9.9.2\">4a</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T2.1.9.9.3\">denoising autoencoding with</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S6.T2.1.9.9.4\">KN</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S6.T2.1.9.9.5\">7.08</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T2.1.10.10\">\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.1.10.10.1\">TCY&#8211;EN</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.1.10.10.2\">4b</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T2.1.10.10.3\">denoising autoencoding with</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S6.T2.1.10.10.4\">TCY</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S6.T2.1.10.10.5\">7.08</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T2.1.11.11\">\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.1.11.11.1\">TCY-EN</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.1.11.11.2\">5</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T2.1.11.11.3\">fine-tuning with back-translation data</td>\n<td class=\"ltx_td ltx_border_r\" id=\"S6.T2.1.11.11.4\"/>\n<td class=\"ltx_td ltx_align_right\" id=\"S6.T2.1.11.11.5\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T2.1.11.11.5.1\">25.97</span></td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T2.1.12.12\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S6.T2.1.12.12.1\" rowspan=\"5\"><span class=\"ltx_text\" id=\"S6.T2.1.12.12.1.1\">2</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T2.1.12.12.2\">EN&#8211;TCY</td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\" id=\"S6.T2.1.12.12.3\">2</td>\n<td class=\"ltx_td ltx_align_left ltx_border_t\" id=\"S6.T2.1.12.12.4\">back-translation with</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" id=\"S6.T2.1.12.12.5\">EN&#8211;TCY</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S6.T2.1.12.12.6\">12.09</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T2.1.13.13\">\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.1.13.13.1\">EN&#8211;TCY</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.1.13.13.2\">3</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T2.1.13.13.3\">training with</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S6.T2.1.13.13.4\">EN&#8211;KN</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S6.T2.1.13.13.5\">9.09</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T2.1.14.14\">\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.1.14.14.1\">EN&#8211;TCY</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.1.14.14.2\">4a</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T2.1.14.14.3\">denoising autoencoding with</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S6.T2.1.14.14.4\">KN</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S6.T2.1.14.14.5\">3.45</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T2.1.15.15\">\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.1.15.15.1\">EN&#8211;TCY</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.1.15.15.2\">4b</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T2.1.15.15.3\">denoising autoencoding with</td>\n<td class=\"ltx_td ltx_align_center ltx_border_r\" id=\"S6.T2.1.15.15.4\">TCY</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S6.T2.1.15.15.5\">6.59</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T2.1.16.16\">\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.1.16.16.1\">EN&#8211;TCY</td>\n<td class=\"ltx_td ltx_align_center\" id=\"S6.T2.1.16.16.2\">5</td>\n<td class=\"ltx_td ltx_align_left\" id=\"S6.T2.1.16.16.3\">fine-tuning with back-translation data</td>\n<td class=\"ltx_td ltx_border_r\" id=\"S6.T2.1.16.16.4\"/>\n<td class=\"ltx_td ltx_align_right\" id=\"S6.T2.1.16.16.5\">13.43</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "We evaluated the machine translation model and each task of the process with our new test set as introduced in Section 4, using SacreBLEU141414https://github.com/mjpost/sacrebleu (Post, 2018).\nTable 2 presents the BLEU scores for each stage of the training process.\nThe TCY–EN model, obtained by fine-tuning the pre-trained IndicBARTSS on the Samanantar EN–KN data, achieves a BLEU score of 1.84, suggesting that the model is not capable of translating Tulu.\n",
            "We used the final TCY–EN model, which we obtained in Task 5, to subsequently back-translate the Tulu sentences that were used to train it in both Task 2 and Task 5.\nThis newly generated set of back-translated EN–TCY pairs served to start a second iteration of the entire process.\nHowever, as shown in Table 2, despite some initial improvement, the BLEU scores for the EN–TCY model kept declining from the starting score of 11.06.\n"
        ]
    },
    "S6.T3.1": {
        "caption": "BLEU scores after additional fine-tuning using   data.",
        "table": "<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\" id=\"S6.T3.1\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\" id=\"S6.T3.1.1.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r\" id=\"S6.T3.1.1.1.1\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T3.1.1.1.1.1\">Iter.</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r\" id=\"S6.T3.1.1.1.2\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T3.1.1.1.2.1\">Direction</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r\" id=\"S6.T3.1.1.1.3\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T3.1.1.1.3.1\">old BLEU</span></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column\" id=\"S6.T3.1.1.1.4\"><span class=\"ltx_text ltx_font_bold\" id=\"S6.T3.1.1.1.4.1\">new BLEU</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\" id=\"S6.T3.1.2.1\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S6.T3.1.2.1.1\">1</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" id=\"S6.T3.1.2.1.2\">EN&#8211;TCY</th>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" id=\"S6.T3.1.2.1.3\">11.06</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" id=\"S6.T3.1.2.1.4\">13.12</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T3.1.3.2\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"S6.T3.1.3.2.1\">1</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"S6.T3.1.3.2.2\">TCY&#8211;EN</th>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S6.T3.1.3.2.3\">25.97</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S6.T3.1.3.2.4\">21.85</td>\n</tr>\n<tr class=\"ltx_tr\" id=\"S6.T3.1.4.3\">\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"S6.T3.1.4.3.1\">2</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\" id=\"S6.T3.1.4.3.2\">EN&#8211;TCY</th>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" id=\"S6.T3.1.4.3.3\">13.43</td>\n<td class=\"ltx_td ltx_align_right\" id=\"S6.T3.1.4.3.4\">35.41</td>\n</tr>\n</tbody>\n</table>\n\n",
        "footnotes": [],
        "references": [
            "We used the parallel EN–TCY data from DravidianLangTech-22 to further fine-tune the EN–TCY and TCY–EN models obtained at the end of each iteration. Table 3 illustrates the changes in BLEU scores resulting from this fine-tuning step.\nFor the EN–TCY model obtained at the end of Iteration 1, fine-tuning improved its BLEU score from 11.06 to 13.12. This moderate increase is not surprising, as the manually translated Tulu data would have further enhanced the decoder’s performance.\nConversely, for the TCY–EN model obtained at the end of Iteration 1, the BLEU score decreased from 25.97 to 21.85. The English sentences in this training data, generated by Google Translate, are not perfect translations and often contain transliterated Kannada words, particularly in the form of names of mythological characters, places, and local flora and fauna. We hypothesize that these aspects contributed to the degradation of the TCY–EN model’s decoder.\nFinally, the EN–TCY model obtained at the end of Iteration 2 was also fine-tuned with this data, resulting in a substantial increase in its BLEU score from 13.43 to 35.41.\nThis dramatic improvement may be attributed to the high-quality Tulu data, which eliminated spurious correlations in the latent space and simultaneously enhanced the decoder’s ability to generate Tulu tokens.\n"
        ]
    }
}