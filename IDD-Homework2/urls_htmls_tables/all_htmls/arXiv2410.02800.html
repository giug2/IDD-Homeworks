<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Estimating Body Volume and Height Using 3D Data</title>
<!--Generated on Wed Sep 18 16:17:15 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="
3d-imaging,  body weight estimation,  emergency medicine,  depth imaging
" lang="en" name="keywords"/>
<base href="/html/2410.02800v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.02800v1#S1" title="In Estimating Body Volume and Height Using 3D Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.02800v1#S2" title="In Estimating Body Volume and Height Using 3D Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">Literature Review</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.02800v1#S3" title="In Estimating Body Volume and Height Using 3D Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">Methodology</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02800v1#S3.SS1" title="In III Methodology ‣ Estimating Body Volume and Height Using 3D Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span> </span><span class="ltx_text ltx_font_italic">Data Acquisition</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02800v1#S3.SS2" title="In III Methodology ‣ Estimating Body Volume and Height Using 3D Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span> </span><span class="ltx_text ltx_font_italic">Image Segmentation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02800v1#S3.SS3" title="In III Methodology ‣ Estimating Body Volume and Height Using 3D Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-C</span> </span><span class="ltx_text ltx_font_italic">3D Model Construction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02800v1#S3.SS4" title="In III Methodology ‣ Estimating Body Volume and Height Using 3D Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-D</span> </span><span class="ltx_text ltx_font_italic">Volume Estimation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02800v1#S3.SS5" title="In III Methodology ‣ Estimating Body Volume and Height Using 3D Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-E</span> </span><span class="ltx_text ltx_font_italic">Height Estimation</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.02800v1#S4" title="In Estimating Body Volume and Height Using 3D Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Experiments</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02800v1#S4.SS1" title="In IV Experiments ‣ Estimating Body Volume and Height Using 3D Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-A</span> </span><span class="ltx_text ltx_font_italic">Experimental Setup</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.02800v1#S4.SS2" title="In IV Experiments ‣ Estimating Body Volume and Height Using 3D Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-B</span> </span><span class="ltx_text ltx_font_italic">Results</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.02800v1#S5" title="In Estimating Body Volume and Height Using 3D Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">V </span><span class="ltx_text ltx_font_smallcaps">Future Work</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.02800v1#S6" title="In Estimating Body Volume and Height Using 3D Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VI </span><span class="ltx_text ltx_font_smallcaps">Conclusion</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Estimating Body Volume and Height Using 3D Data
<br class="ltx_break"/>
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">1<sup class="ltx_sup" id="id1.1.id1">st</sup> Vivek Ganesh Sonar
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id2.2.id1">Col. of Engineering &amp; Computer Science</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="id3.3.id2">Florida Atlantic University
<br class="ltx_break"/></span>Boca Raton, USA 
<br class="ltx_break"/>vsonar2023@fau.edu
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">2<sup class="ltx_sup" id="id4.1.id1">nd</sup> Muhammad Tanveer Jan
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id5.2.id1">Col. of Engineering &amp; Computer Science</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="id6.3.id2">Florida Atlantic University
<br class="ltx_break"/></span>Boca Raton, USA 
<br class="ltx_break"/>mjan2021@fau.edu
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">3<sup class="ltx_sup" id="id7.1.id1">rd</sup> Mike Wells
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id8.2.id1">Charles E. Schmidt Col. of Medicine</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="id9.3.id2">Florida Atlantic University
<br class="ltx_break"/></span>Boca Raton, USA 
<br class="ltx_break"/>wellsm@health.fau.edu
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">4<sup class="ltx_sup" id="id10.1.id1">th</sup> Abhijit Pandya
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id11.2.id1">Col. of Engineering &amp; Computer Science</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="id12.3.id2">Florida Atlantic University
<br class="ltx_break"/></span>Boca Raton, USA 
<br class="ltx_break"/>pandya@fau.edu
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">5<sup class="ltx_sup" id="id13.1.id1">th</sup> Gabriella Engstrom
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id14.2.id1">Charles E. Schmidt Col. of Medicine</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="id15.3.id2">Florida Atlantic University
<br class="ltx_break"/></span>Boca Raton, USA 
<br class="ltx_break"/>gengstr1@health.fau.edu
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">6<sup class="ltx_sup" id="id16.1.id1">th</sup> Richard Shih
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id17.2.id1">Charles E. Schmidt Col. of Medicine</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="id18.3.id2">Florida Atlantic University
<br class="ltx_break"/></span>Boca Raton, USA 
<br class="ltx_break"/>rshih@health.fau.edu
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">7<sup class="ltx_sup" id="id19.1.id1">th</sup> Borko Furht
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id20.2.id1">Col. of Engineering &amp; Computer Science</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="id21.3.id2">Florida Atlantic University
<br class="ltx_break"/></span>Boca Raton, USA 
<br class="ltx_break"/>bfurht@fau.edu
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id22.id1">Accurate body weight estimation is critical in emergency medicine for proper dosing of weight-based medications, yet direct measurement is often impractical in urgent situations. This paper presents a non-invasive method for estimating body weight by calculating total body volume and height using 3D imaging technology. A RealSense D415 camera is employed to capture high-resolution depth maps of the patient, from which 3D models are generated. The Convex Hull Algorithm is then applied to calculate the total body volume, with enhanced accuracy achieved by segmenting the point cloud data into multiple sections and summing their individual volumes. The height is derived from the 3D model by identifying the distance between key points on the body. This combined approach provides an accurate estimate of body weight, improving the reliability of medical interventions where precise weight data is unavailable. The proposed method demonstrates significant potential to enhance patient safety and treatment outcomes in emergency settings.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
3d-imaging, body weight estimation, emergency medicine, depth imaging

</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">A precise assessment of one’s height and body weight is crucial in several fields such as healthcare, exercise, and ergonomics. Existing conventional approaches depend on direct measuring equipment, which can be laborious and necessitate direct physical interaction with the individual being monitored. Technological advancements in three-dimensional imaging and machine learning have enabled the creation of non-invasive automated systems that can accurately compute body dimensions. The objective of this work is to explore the feasibility of approximating human weight and height employing three-dimensional data acquired from advanced sensors like the RealSense D415 camera. The integration of computer vision techniques with deep learning models enables the extraction of precise body measurements from 3D data, providing a system that is exceptionally efficient and scalable.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Literature Review</span>
</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">In emergency care, accurate weight estimation is essential for proper medication dosing, but direct measurement is often impractical in such critical situations. Recent advancements in 3D camera systems, particularly those driven by artificial intelligence, offer a promising solution to this challenge. A systematic review of 14 studies published between 2012 and 2024, primarily involving the use of Microsoft Kinect cameras, demonstrated that these systems could achieve a high level of accuracy in weight estimation. Specifically, many of these systems had 90% of their estimates within 10% of the actual weight, indicating significant potential for improving drug dosing accuracy and patient safety in emergency settings. These findings underscore the relevance of 3D camera technology in clinical practice, suggesting that with further validation in larger studies, these systems could become a standard tool for weight estimation in urgent care environments<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02800v1#bib.bib1" title="">1</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Recent advancements in 3D body scanning technology and machine learning have shown promising results in estimating body weight and height. Jan et al <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02800v1#bib.bib2" title="">2</a>]</cite> have compared several studies for body weight estimation using anthropemetric, 2D, 3D and fusion of multiple sensors in a well manner to brigde the gap between all the research studies. Machine learning (ML) algorithms have increasingly been employed in weight estimation tasks due to their capability to learn complex patterns directly from data. Techniques such as linear regression, support vector regression, and neural network-based models are commonly utilized to predict weight from extracted image features. For example, Rativa et al.<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02800v1#bib.bib3" title="">3</a>]</cite> explored the use of ML regression techniques to estimate height and weight from anthropometric measurements, aiming to improve the precision and reliability of these estimates for applications in healthcare, fitness, and biometric identification. Similarly, Khan et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02800v1#bib.bib4" title="">4</a>]</cite> focused on infant birth weight estimation and low birth weight classification in the United Arab Emirates using ML algorithms. This study holds promise for enhancing prenatal care by enabling early interventions for infants at risk of low birth weight, thereby contributing to improved maternal and child health outcomes.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">In addition to these developments, recent studies have explored the integration of traditional weight estimation methods with computer vision techniques to enhance accuracy and efficiency. Fitriyah et al.<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02800v1#bib.bib5" title="">5</a>]</cite> developed a weight estimation system using a 2D snapshot of a person’s front pose, applying multiple linear regressions based on body features such as height, shoulder width, abdomen and arm width, and feet width. The study demonstrated the necessity of incorporating all available body features to achieve more accurate weight estimation. In a related study, Dantcheva et al.<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02800v1#bib.bib6" title="">6</a>]</cite> investigated the use of 2D facial snapshots to estimate a person’s weight, height, and BMI, employing ResNet-50 architecture for the regression process. The findings suggested that facial images could provide valuable information for these estimates, although weight estimation accuracy was challenged by factors such as weight fluctuations, cosmetic alterations, and image modifications.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">Advancements in deep learning, particularly in convolutional neural networks (CNNs), have also led to significant improvements in weight estimation accuracy. Kim <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02800v1#bib.bib7" title="">7</a>]</cite> evaluated various weight estimation techniques using force-sensing resistor sensors and deep learning models, finding that the serialization method combined with a deep neural network was the most effective, achieving a mean absolute error of ±4.6 kg. However, challenges such as sensor dead zones and recognition errors were noted, highlighting the need for further refinement. In another study, researchers utilized anthropometric parameters derived from 2D frontal body images to estimate weight, with results indicating that the method was generally effective, although some issues arose with BMI estimation for certain age groups.</p>
</div>
<div class="ltx_para" id="S2.p5">
<p class="ltx_p" id="S2.p5.1">Efforts to incorporate multi-modal fusion techniques, combining data from various sources such as depth sensors, thermal imaging, and 3D body scans, have been made to improve the robustness and generalization of weight estimation systems. For instance, Dane et al.<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02800v1#bib.bib8" title="">8</a>]</cite> demonstrated the use of a 3D camera and infrared imaging, combined with machine learning algorithms, to estimate patient height and weight with high accuracy, achieving a 2.0% error in height and a 5.1% error in weight estimations. The study noted that the 3D camera tended to overestimate weight in overweight patients and underestimate it in underweight patients, though overall accuracy remained high. Another study by Cook et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02800v1#bib.bib9" title="">9</a>]</cite>tested the use of a Microsoft Kinect RGB camera with an infrared depth sensor to estimate patient volume, which correlated well with actual weight, despite challenges such as arm positioning that affected the accuracy of volume and density estimates.</p>
</div>
<div class="ltx_para" id="S2.p6">
<p class="ltx_p" id="S2.p6.1">Emerging techniques for body weight and height estimation continue to evolve, with innovations such as contactless weight estimation and individualized computed tomography (CT) offering new possibilities. Labati et al.<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02800v1#bib.bib10" title="">10</a>]</cite> presented a contactless, low-cost weight estimation method using frame sequences of a walking individual, showing potential for view-independent results without the need for complex body modeling. Furthermore, Geissler et al.<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.02800v1#bib.bib11" title="">11</a>]</cite> introduced an advanced CT-based technique relying on a simulated digital twin, combined with AI algorithms, to automatically calculate both height and weight. This approach offers a more precise method for individualized medical evaluations, though further research is required to assess its performance across different clinical settings and patient populations.</p>
</div>
<div class="ltx_para" id="S2.p7">
<p class="ltx_p" id="S2.p7.1">The integration of machine learning, traditional techniques, deep learning architectures, and multi-modal fusion has led to significant advancements in the field of body weight and height estimation. While promising results have been achieved, ongoing challenges such as accuracy across diverse populations, the influence of body posture and clothing, and the need for more robust datasets indicate areas for future research. Continued exploration of emerging technologies and refinement of existing methods will be crucial for developing more accurate and reliable body metric estimation systems.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">Methodology</span>
</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">The methodology for estimating body weight and height involves several key steps:</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS1.4.1.1">III-A</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS1.5.2">Data Acquisition</span>
</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">In order to obtain precise 3D photos, the RealSense D415 camera is placed exactly above the subject, as depicted in Figure 1. This deliberate positioning guarantees that the camera has an unambiguous and unhindered perspective of the whole body, enabling it to precisely record all essential details. The D415 is renowned for its capacity to generate high-resolution depth maps, which constitute intricate depictions of the spatial separation between the camera and different locations on the subject’s body. The depth maps offer a three-dimensional perspective of the subject, emphasizing the many contours and forms of the body. The importance of the high resolution of the depth map lies in its ability to capture intricate details, such as subtle curves or edges, which are crucial for accurate measurements. After capturing these 3D images, they are subjected to additional processing, including cleaning, refining, and preparing the data for subsequent stages of our research, such as segmentation and volume quantification.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">This processing guarantees the utmost accuracy and usability of the depth information, therefore establishing a strong basis for the subsequent body measuring applications. Using the RealSense D415 camera, we can acquire precise and dependable 3D data, crucial for obtaining unambiguous estimations of body weight and height.</p>
</div>
<figure class="ltx_figure" id="S3.F1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_portrait" height="263" id="S3.F1.g1" src="extracted/5863800/fig7-1.jpg" width="150"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_portrait" height="258" id="S3.F1.g2" src="extracted/5863800/fig7-2.jpg" width="150"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_portrait" height="258" id="S3.F1.g3" src="extracted/5863800/fig7-3.jpg" width="150"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_portrait" height="258" id="S3.F1.g4" src="extracted/5863800/fig7-4.jpg" width="150"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Data acquisition of participants</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS2.4.1.1">III-B</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS2.5.2">Image Segmentation</span>
</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">By utilizing the DepthQualityTool SDK, we initially apply a processing technique to the images obtained by the 3D camera in order to eliminate superfluous components such as the bed or background, therefore allowing the subject to be the sole focal point. The significance of this stage lies in its ability to effectively cleanse the data, therefore facilitating its operational manipulation. Furthermore, we proceed to segment the 3D data, whereby we dissect the image into distinct body components such as the head, arms, and legs.To accomplish this, we employ models such as MobileNet and ResNet, which are neural network architectures specifically developed to identify and segregate distinct components of a picture. The MobileNet model is highly effective at rapidly and effectively detecting anatomical structures, particularly in situations when computational resources are limited. ResNet, however, is more robust and capable of managing more intricate jobs, therefore ensuring precise identification of bodily parts.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">Through meticulous processing and segmentation of the data using these methods, we ensure that our measurements of body volume or height are based on clean and well defined data, so enhancing the overall precision of our results.</p>
</div>
<figure class="ltx_figure" id="S3.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_portrait" height="528" id="S3.F2.g1" src="extracted/5863800/fig8.png" width="198"/></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_portrait" height="511" id="S3.F2.g2" src="extracted/5863800/fig8-2.png" width="198"/></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_portrait" height="485" id="S3.F2.g3" src="extracted/5863800/fig8-3.png" width="198"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Body pose estimation and body parts segmentation</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS3.4.1.1">III-C</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS3.5.2">3D Model Construction</span>
</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">The 2D photos obtained from the camera are transformed into a 3D model by utilizing a polygon file, which functions as a geometric depiction of the subject’s body in three dimensions. This method entails the transformation of 2D pixel data into a 3D coordinate system, enabling the reconstruction of the subject’s form and structure. During this conversion, substantial interference, such as spurious data points, discrepancies in depth measurements, and aberrations from the imaging procedure, can be introduced, therefore distorting the precision of the 3D model. Therefore, we employ sophisticated noise reduction methods, such as filtering and smoothing algorithms, to methodically detect and eliminate these undesired components. In this manner, the refinement of the 3D model guarantees that the next procedures, such as volume estimates and feature extraction, rely on accurate and pristine data. Consequently, the overall precision and dependability of the weight and height estimation process are improved.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS4.4.1.1">III-D</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS4.5.2">Volume Estimation</span>
</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">The body volume is calculated using the Convex Hull Algorithm, a technique employed to generate the smallest feasible 3D form, known as a ”bounding box,” capable of encompassing all the points that represent the body included in the point cloud data. A point cloud is a structured set of data points that precisely delineate the three-dimensional surface of a body. In order to enhance the precision of our volume simulations, we do not employ the Convex Hull Algorithm on the whole body simultaneously. Instead, we partition the point cloud data into several smaller parts measured along the length of the body. Individual segments correspond to distinct anatomical regions of the body, such as the cranium, central body, or extremities. By employing this method, we can compute the volume of each segment separately, therefore enabling more accurate measurements. Following the computation of the volume for each segment, we proceed to aggregate all these volumes in order to obtain the overall body volume.</p>
</div>
<div class="ltx_para" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.1">The advantage of this segmented technique lies in its ability to more precisely factor in changes in body shape and structure compared to the single calculation of volume. By prioritizing smaller anatomical regions, we mitigate the potential for inaccuracies that may arise from considering the body as a unified and flat entity. Employing this approach guarantees the utmost precision in our ultimate volume computation, a critical factor for the following stages of determining body weight and height.</p>
</div>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="200" id="S3.F3.g1" src="extracted/5863800/fig5.png" width="299"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>3D image processing using Convex Hull Algorithm</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS5.4.1.1">III-E</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS5.5.2">Height Estimation</span>
</h3>
<div class="ltx_para" id="S3.SS5.p1">
<p class="ltx_p" id="S3.SS5.p1.1">To determine the height of the subject, the difference between the maximum and minimum Y coordinates within the bounding box that encloses the detected object is computed. The Y coordinates represent the vertical locations of the subject’s head and feet, correspondingly. In order to guarantee precision, the height measurement is subsequently modified to account for depth proximity, considering the distance of the subject from the camera. This adjustment of depth serves to offset any distortions in perspective, therefore guaranteeing that the estimated height remains constant and precise irrespective of the subject’s position in relation to the camera. To enhance the accuracy of the measurement, the system can incorporate depth data, therefore enabling a more dependable estimation of the actual height of the subject, even in dynamic settings.</p>
</div>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="572" id="S3.F4.g1" src="extracted/5863800/workflow.png" width="299"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Workflow for estimating patient height</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Experiments</span>
</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">The proposed methodology was tested on a dataset of images captured from multiple subjects in different postures. The experiments involved capturing images, segmenting them, and calculating the body volume and height using the described methods. The results were then compared with actual measurements to evaluate the accuracy of the system.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS1.4.1.1">IV-A</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS1.5.2">Experimental Setup</span>
</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">In the development of our weight and height estimate system utilising 3D data, we utilised several specialised libraries and tools, carefully selected for their distinct skills in managing intricate computational problems, image processing, and machine learning. Presented below is a detailed explanation of the essential libraries and neural network models employed</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1">Intel RealSense D415: The RealSense D415 camera was used to capture depth data at a resolution of 848x480 pixels, streaming at 30 FPS. The data was processed using TensorFlow models loaded in a pre-trained state.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1">NumPy: Designed for numerical computing, Numpy is a Python package that facilitates the manipulation of large, multi-dimensional arrays and matrices using mathematical functions. In our project, Numpy is essential for the processing of 3D data and the execution of matrix multiplication, array manipulation, and other analytical operations. Its exceptional effectiveness and user-friendliness make it indispensable for preprocessing and organizing large datasets for constructing 3D models.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1">OpenCV: OpenCV is an extensively optimized framework designed for the purpose of real-time computer vision and image processing. Our system utilizes OpenCV to process raw 3D camera images, extract pertinent features, and carry out filtering, edge detection, and contour localization for image segmentation. OpenCV’s extensive functionality and wide range of capabilities render it ideal for image transformations and analyses required for accurate segmentation and identification of 3D body parts.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i4.p1">
<p class="ltx_p" id="S4.I1.i4.p1.1">Pillow: Pillow,a Python Imaging Library (PIL), is capable of opening, manipulating, and saving several image file types. The present system effectively handles many photo formats and executes operations such as resizing, format conversion, and fundamental image enhancement. The simplicity and interoperability of Pillow with other Python libraries render it a handy tool for the formatting and preparation of images for processing.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i5.p1">
<p class="ltx_p" id="S4.I1.i5.p1.1">Pyfakewebcam: Pyfakewebcam is a specialized library that enables the development of a virtual webcam. This feature is especially beneficial for the real-time testing and display of segmented images, as it can replicate the output of a physical camera. In our project, Pyfakewebcam enables us to monitor the accuracy of body part identification and alter the parameters accordingly without the need for continuous physical camera input, thereby facilitating the real-time visualization of the segmentation process.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i6.p1">
<p class="ltx_p" id="S4.I1.i6.p1.1">Tensorflow: TensorFlow is a powerful open-source toolkit for deep learning model development and deployment. TensorFlow Estimator simplifies model training and assessment with an API. Our solution builds, trains, and deploys neural networks for image segmentation and other machine learning applications using TensorFlow. Its scalability and flexibility make it perfect for complicated 3D data processing and machine learning algorithm integration.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS2.4.1.1">IV-B</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS2.5.2">Results</span>
</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">The system showed an average error margin of ±2 cm in height estimation and ±3 kg in weight estimation, demonstrating high accuracy compared to traditional methods. The segmentation and volume estimation processes were key to achieving these results, with the Convex Hull Algorithm proving effective in calculating body volume.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Future Work</span>
</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Future research will aim to improve body weight estimation by incorporating more sophisticated models and larger, diverse datasets. This includes integrating different body types to calculate lean body weight (LBW) in adults, accounting for variations in muscle mass, fat distribution, and skeletal structure. Additionally, a refined regression model will estimate weight based on variables like segmented body part volumes, height, age, and gender for more accurate results across diverse populations. The system will also be enhanced for real-time use, with the potential to integrate multiple cameras for better 3D representation and robustness. These advancements will not only improve weight estimation accuracy but also enable the estimation of other metrics such as body fat percentage and muscle mass, making the system more useful in emergency medicine and clinical settings.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span class="ltx_text ltx_font_smallcaps" id="S6.1.1">Conclusion</span>
</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">This research demonstrates the potential of using 3D data for accurate estimation of body weight and height. The combination of advanced imaging techniques, noise reduction methods, and deep learning models allows for precise measurement without the need for direct physical contact. As technology advances, these methods could become standard in various fields, offering a more efficient and scalable solution for body metric estimation.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"> Jan MT, Kumar A, Sonar VG, Body Weight Estimation: Techniques, datasets and applicaitons. Multimedia Tools and Applications 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"> Wells M, Goldstein LN, Wells T, Ghazi N, Pandya A, Furht B, Engstrom G, Jan MT, Shih R. Total body weight estimation by 3D camera systems: potential high-tech solutions for emergency medicine applications? A scoping review. medRxiv. 2024 Aug 20:2024-08.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"> Rativa D, Fernandes BJ, Roque A. Height and weight estimation from anthropometric measurements using machine learning regressions. IEEE journal of translational engineering in health and medicine. 2018 Mar 29;6:1-9.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"> Khan W, Zaki N, Masud MM, Ahmad A, Ali L, Ali N, Ahmed LA. Infant birth weight estimation and low birth weight classification in United Arab Emirates using machine learning algorithms. Scientific reports. 2022 Jul 15;12(1):12110.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"> Fitriyah H, Setyawan GE. Automatic estimation of human weight from body silhouette using multiple linear regression. In2018 5th International Conference on Electrical Engineering, Computer Science and Informatics (EECSI) 2018 Oct 16 (pp. 749-752). IEEE.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"> Dantcheva A, Bremond F, Bilinski P. Show me your face and I will tell you your height, weight and body mass index. In2018 24th International Conference on Pattern Recognition (ICPR) 2018 Aug 20 (pp. 3555-3560). IEEE.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"> Kim TH, Hong YS. Prediction of body weight of a person lying on a smart mat in nonrestraint and unconsciousness conditions. Sensors. 2020 Jun 19;20(12):3485.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"> Dane B, Singh V, Nazarian M, O’Donnell T, Liu S, Kapoor A, Megibow A. Prediction of patient height and weight with a 3-dimensional camera. Journal of Computer Assisted Tomography. 2021 May 1;45(3):427-30.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"> Cook TS, Couch G, Couch TJ, Kim W, Boonn WW. Using the microsoft kinect for patient size estimation and radiation dose normalization: Proof of concept and initial validation. Journal of Digital Imaging. 2013 Aug;26:657-62.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"> Labati RD, Genovese A, Piuri V, Scotti F. Weight estimation from frame sequences using computational intelligence techniques. In2012 IEEE International Conference on Computational Intelligence for Measurement Systems and Applications (CIMSA) Proceedings 2012 Jul 2 (pp. 29-34). IEEE.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"> Geissler F, Heiß R, Kopp M, Wiesmüller M, Saake M, Wuest W, Wimmer A, Prell V, Uder M, May MS. Personalized computed tomography–Automated estimation of height and weight of a simulated digital twin using a 3D camera and artificial intelligence. InRöFo-Fortschritte auf dem Gebiet der Röntgenstrahlen und der bildgebenden Verfahren 2021 Apr (Vol. 193, No. 04, pp. 437-445). Georg Thieme Verlag KG.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Sep 18 16:17:15 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
