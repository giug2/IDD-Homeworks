<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Word Alignment as Preference for Machine Translation</title>
<!--Generated on Wed May 15 10:03:10 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2405.09223v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S1" title="In Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S2" title="In Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S2.SS1" title="In 2 Related work ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Hallucination and omission in machine translation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S2.SS2" title="In 2 Related work ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Preference tuning for LLMs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S2.SS3" title="In 2 Related work ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Word alignment</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S3" title="In Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Proposed approach</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S3.SS1" title="In 3 Proposed approach ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Gathering translation candidates</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S3.SS1.SSS0.Px1" title="In 3.1 Gathering translation candidates ‣ 3 Proposed approach ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title">Details of gathered translations</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S3.SS2" title="In 3 Proposed approach ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Selecting chosen and rejected translation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S3.SS3" title="In 3 Proposed approach ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Filtering</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S3.SS4" title="In 3 Proposed approach ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Details of dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S3.SS5" title="In 3 Proposed approach ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5 </span>Optimization LLM-based MT model</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S4" title="In Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S4.SS1" title="In 4 Evaluation ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Experimental setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S4.SS2" title="In 4 Evaluation ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Baselines and evaluation datasets</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S4.SS2.SSS0.Px1" title="In 4.2 Baselines and evaluation datasets ‣ 4 Evaluation ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title">HalOmi</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S4.SS3" title="In 4 Evaluation ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>The design of evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S4.SS3.SSS0.Px1" title="In 4.3 The design of evaluation ‣ 4 Evaluation ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title">Select hard instances.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S4.SS3.SSS0.Px2" title="In 4.3 The design of evaluation ‣ 4 Evaluation ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title">Utilize LLM as the evaluator for hallucination and omission.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S4.SS3.SSS0.Px3" title="In 4.3 The design of evaluation ‣ 4 Evaluation ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title">Is LLM really capable of evaluating hallucination and omission in MT?</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S5" title="In Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experimental results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S5.SS1" title="In 5 Experimental results ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Evaluation on hard instances</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S5.SS2" title="In 5 Experimental results ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Direct evaluation of hallucination and omission by GPT-4</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S5.SS3" title="In 5 Experimental results ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Human evaluation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S5.SS4" title="In 5 Experimental results ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Ablation study</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S5.SS4.SSS0.Px1" title="In 5.4 Ablation study ‣ 5 Experimental results ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title">Does the preferred data really better contribute to the training?</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S5.SS4.SSS0.Px2" title="In 5.4 Ablation study ‣ 5 Experimental results ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title">Is the DPO preference tuning necessary?</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S6" title="In Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#A1" title="In Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Example analysis</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#A1.SS1" title="In Appendix A Example analysis ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Examples of the preference dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#A1.SS2" title="In Appendix A Example analysis ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Translation examples</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#A2" title="In Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Specific results</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Word Alignment as Preference for Machine Translation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Qiyu Wu<sup class="ltx_sup" id="id9.9.id1"><span class="ltx_text ltx_font_italic" id="id9.9.id1.1">1</span></sup>,
Masaaki Nagata<sup class="ltx_sup" id="id10.10.id2"><span class="ltx_text ltx_font_italic" id="id10.10.id2.1">2</span></sup>,
Zhongtao Miao<sup class="ltx_sup" id="id11.11.id3"><span class="ltx_text ltx_font_italic" id="id11.11.id3.1">1</span></sup>,
Yoshimasa Tsuruoka<sup class="ltx_sup" id="id12.12.id4"><span class="ltx_text ltx_font_italic" id="id12.12.id4.1">1</span></sup>
<br class="ltx_break"/><sup class="ltx_sup" id="id13.13.id5"><span class="ltx_text ltx_font_italic" id="id13.13.id5.1">1</span></sup>The University of Tokyo, Tokyo, Japan 
<br class="ltx_break"/><sup class="ltx_sup" id="id14.14.id6"><span class="ltx_text ltx_font_italic" id="id14.14.id6.1">2</span></sup>NTT Communication Science Laboratories, NTT Corporation, Kyoto, Japan 
<br class="ltx_break"/><sup class="ltx_sup" id="id15.15.id7"><span class="ltx_text ltx_font_italic" id="id15.15.id7.1">1</span></sup><span class="ltx_text ltx_font_typewriter" id="id16.16.id8">{qiyuw, mzt, yoshimasa-tsuruoka}@g.ecc.u-tokyo.ac.jp</span>
<br class="ltx_break"/><sup class="ltx_sup" id="id17.17.id9"><span class="ltx_text ltx_font_italic" id="id17.17.id9.1">2</span></sup><span class="ltx_text ltx_font_typewriter" id="id18.18.id10">masaaki.nagata@ntt.com</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id19.id1">The problem of hallucination and omission, a long-standing problem in machine translation (MT), is more pronounced when a large language model (LLM) is used in MT because an LLM itself is susceptible to these phenomena.
In this work, we mitigate the problem in an LLM-based MT model by guiding it to better word alignment.
We first study the correlation between word alignment and the phenomena of hallucination and omission in MT. Then we propose to utilize word alignment as preference to optimize the LLM-based MT model.
The preference data are constructed by selecting chosen and rejected translations from multiple MT tools. Subsequently, direct preference optimization is used to optimize the LLM-based model towards the preference signal.
Given the absence of evaluators specifically designed for hallucination and omission in MT, we further propose selecting hard instances and utilizing GPT-4 to directly evaluate the performance of the models in mitigating these issues. We verify the rationality of these designed evaluation methods by experiments, followed by extensive results demonstrating the effectiveness of word alignment-based preference optimization to mitigate hallucination and omission.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Large language models (LLMs) have been evolving rapidly and showing predominant performance in many natural language processing (NLP) tasks <cite class="ltx_cite ltx_citemacro_citep">(Brown et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib6" title="">2020</a>; Achiam et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib1" title="">2023</a>; Touvron et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib32" title="">2023</a>)</cite>.
However, in machine translation (MT), the use of a decoder-only LLM is still limited due to issues such as model size <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib41" title="">2024a</a>)</cite> and low-resource languages <cite class="ltx_cite ltx_citemacro_citep">(Hendy et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib18" title="">2023</a>)</cite>. Conventional encoder-decoder MT models trained on parallel corpora still dominate in practice <cite class="ltx_cite ltx_citemacro_citep">(Costa-jussà et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib10" title="">2022</a>)</cite>.
One of the primary concerns of applying an LLM to MT is reliability. Although it does not happen frequently, an LLM is known to hallucinate <cite class="ltx_cite ltx_citemacro_citep">(Dhuliawala et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib13" title="">2023</a>; Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib43" title="">2023a</a>; Bang et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib3" title="">2023</a>)</cite> as it is pre-trained to predict the next token in very large-scale raw texts. Specifically in MT, LLM-based translation systems therefore could have the phenomena of hallucination and omission, which is also a long-term challenge in the field of MT <cite class="ltx_cite ltx_citemacro_citep">(Vamvas and Sennrich, <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib35" title="">2022</a>)</cite>, known as over- and under-translation.
In this work, we attempt to mitigate the hallucination and omission in LLM-based MT to improve its practicality.</p>
</div>
<figure class="ltx_figure" id="S1.F1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F1.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="647" id="S1.F1.sf1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Coverage score distribution of different omission degree.</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F1.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="647" id="S1.F1.sf2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>Coverage score distribution of different omission degree.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The coverage score distribution of degrees of hallucination and omission. The coverage scores are predicted by word alignment model <cite class="ltx_cite ltx_citemacro_cite">Wu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib38" title="">2023</a>)</cite>. The annotation of hallucination and omission is from HalOmi benchmark <cite class="ltx_cite ltx_citemacro_cite">Dale et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib12" title="">2023b</a>)</cite>. Details about the dataset and word alignment model can be found in §<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S4.SS2" title="4.2 Baselines and evaluation datasets ‣ 4 Evaluation ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">4.2</span></a>.</figcaption>
</figure>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Hallucination in MT occurs when information not present in the source text is generated in the translation, and omission occurs when some of the information in the source text is missed in the translation. As a related tool that explicitly aligns the source text and translation at the word level, word alignment is potentially positive for MT due to the nature of align and translate <cite class="ltx_cite ltx_citemacro_citep">(Bahdanau et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib2" title="">2015</a>)</cite>. The degree of coverage of the source text in translation could be a direct signal to identify the hallucination and omission in MT <cite class="ltx_cite ltx_citemacro_cite">Tu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib33" title="">2016</a>)</cite>.
Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a> shows the normalized frequency of the coverage scores predicted by a word aligner. The examples that are annotated as “no hallucination or omission” tend to have a higher coverage score, while those in “full hallucination or omission” are more likely to have an extremely low coverage score. “small hallucination or omission” and “partial hallucination or omission” distribute in the middle. As the annotations are carefully made by humans and highly correlates to the coverage scores from the word aligner, this indicates that word alignment is a simple but promising direction to mitigate these phenomena.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Consequently, we propose Word Alignment Preference (<span class="ltx_text ltx_font_bold" id="S1.p3.1.1">WAP</span>) that utilizes word alignment as a signal to optimize LLM-based MT models. WAP consists of three steps: diverse translation collection, preference data construction, and preference optimization. Specifically, we collect diverse translations with multiple existing translation tools, select chosen and rejected examples with the word aligner <cite class="ltx_cite ltx_citemacro_citep">(Wu et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib38" title="">2023</a>)</cite>, and optimize the model on preference data using direct preference optimization (DPO) <cite class="ltx_cite ltx_citemacro_citep">(Rafailov et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib30" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Furthermore, the evaluation of hallucination and omission is challenging, and there is no existing evaluator specifically designed for this. Improving the BLEU and COMET score does not necessarily mean reducing hallucination and omission because there are other factors such as mistranslation and fluency. In addition, hallucination is relatively infrequent, although very severe once happens. Hence, to effectively evaluate it, we design extensive experiments that include testing on instances that potentially have the problem of hallucination and omission, and using GPT-4 as the evaluator with comprehensive analysis. Experimental analysis demonstrates the effectiveness of WAP in mitigating hallucination and omission in MT.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">In summary, the contributions of this work include the following:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We studied the correlation between the coverage score by word alignment and the phenomena of hallucination and omission in MT. From the preliminary experiments in Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a> we found that word alignment is a promising signal to mitigate it.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">In §<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S3" title="3 Proposed approach ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a> we propose a novel approach, namely WAP, to construct a word alignment-based preference dataset, and use DPO to optimize the LLM-based MT model. The validity of the preference dataset is also demonstrated by direct fine-tuning on preferred and rejected translations in §<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S5.SS4" title="5.4 Ablation study ‣ 5 Experimental results ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">5.4</span></a>.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">As there is no benchmark particularly for evaluating the performance of MT models on hallucination and omission. We design various experiments, including selecting hard instances and utilizing GPT-4 as the evaluator in §<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S4.SS3" title="4.3 The design of evaluation ‣ 4 Evaluation ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">4.3</span></a>. The effectiveness of the evaluation, as well as the proposed WAP has been validated through extensive experiments and analysis in §<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S5" title="5 Experimental results ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">5</span></a></p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Hallucination and omission in machine translation</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">The problem of hallucination and omission can also be termed an over- and under-translation.
Hallucinations in machine translation are cases in which the model generates output that is partially or completely unrelated to the source sentence, while omissions are translations that do not include some of the input information <cite class="ltx_cite ltx_citemacro_citep">(Dale et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib12" title="">2023b</a>)</cite>.
<cite class="ltx_cite ltx_citemacro_citet">Dale et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib11" title="">2023a</a>)</cite> explore methods that leverage the internal workings of models and external tools, such as cross-lingual sentence similarity and natural language inference models, to detect and mitigate hallucinations in machine translation.
HalOmi <cite class="ltx_cite ltx_citemacro_citep">(Dale et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib12" title="">2023b</a>)</cite> introduces an annotated dataset specifically designed to detect hallucinations and omissions, covering 18 translation directions. In Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a> and §<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S4.SS3" title="4.3 The design of evaluation ‣ 4 Evaluation ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">4.3</span></a> we use HalOmi as a reference to assess how these two phenomena correlate to the coverage output of the GPT-4 evaluator and the word aligner, respectively.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Preference tuning for LLMs</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">LLMs are capable of completing tasks in the zero-shot or few-shot manner <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib29" title="">2019</a>; Brown et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib6" title="">2020</a>)</cite>. In addition, performance in downstream tasks can also be enhanced by fine-tuning them with instruction datasets <cite class="ltx_cite ltx_citemacro_citep">(Wei et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib36" title="">2022</a>; Chung et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib9" title="">2024</a>)</cite>. However, acquiring instruction datasets is costly, while obtaining preferences for LLM responses is relatively easier <cite class="ltx_cite ltx_citemacro_citep">(Rafailov et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib30" title="">2024</a>)</cite>. Consequently, numerous studies have fine-tuned the instruction-tuned models on preference data to better align with the feedback from human or advanced models, thus improving their performance on corresponding tasks <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib27" title="">2022</a>; Rafailov et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib30" title="">2024</a>; Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib42" title="">2024b</a>)</cite>.
InstructGPT <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib27" title="">2022</a>)</cite> aligns language models with human intentions through a two-stage process: supervised instruction fine-tuning and reinforcement learning from human feedback using proximal policy optimization <cite class="ltx_cite ltx_citemacro_citep">(Schulman et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib31" title="">2017</a>)</cite>.
DPO <cite class="ltx_cite ltx_citemacro_citep">(Rafailov et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib30" title="">2024</a>)</cite> directly optimize LLM with preference data. It further simplifies the preference-tuning process by removing an extra reward model. We utilize DPO in this work due to the ease of use and effectiveness.
A contemporaneous preference-based MT model ALMA-R <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib42" title="">2024b</a>)</cite>, built on the foundations of DPO, introduces contrastive preference optimization to fine-tune LLMs specifically using reference-free MT metrics and human annotation as preference. ALMA-R focuses on improving general LLM-based MT while we attempt to mitigate the hallucination and omission in MT, and our preference data are entirely made automatically, which also draws the difference between ALMA-R and our work.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Word alignment</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">Word-level information is useful in many NLP tasks such as language pretraining <cite class="ltx_cite ltx_citemacro_cite">Chi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib7" title="">2021</a>); Wu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib40" title="">2021</a>)</cite> and cross-lingual sentence embedding <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib44" title="">2023b</a>); Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib22" title="">2023</a>); Miao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib23" title="">2024</a>)</cite>. In particular, word alignment plays an important role in MT <cite class="ltx_cite ltx_citemacro_cite">Bahdanau et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib2" title="">2015</a>); Tu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib33" title="">2016</a>)</cite>.
Recently, word aligners based on pre-trained language models, such as SimAlign <cite class="ltx_cite ltx_citemacro_cite">Jalili Sabet et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib20" title="">2020</a>)</cite>, AWESoME <cite class="ltx_cite ltx_citemacro_cite">Dou and Neubig (<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib14" title="">2021</a>)</cite> and SpanAlign <cite class="ltx_cite ltx_citemacro_cite">Nagata et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib25" title="">2020</a>); Chousa et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib8" title="">2020</a>)</cite>, have significantly outperformed previous word aligners based on statistical machine translation, such as Giza++ <cite class="ltx_cite ltx_citemacro_cite">Och and Ney (<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib26" title="">2003</a>)</cite> and FastAlign <cite class="ltx_cite ltx_citemacro_cite">Dyer et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib15" title="">2013</a>)</cite>. SimAlign is an unsupervised approach based on the similarity of contextualized word embeddings. AWESoME and SpanAlign are supervised models that are trained on parallel corpora and manual word alignment datasets. WSPAlign <cite class="ltx_cite ltx_citemacro_citep">(Wu et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib38" title="">2023</a>)</cite> is a weakly-supervised approach trained on large-scale automatically collected data. WSPAlign is the state-of-the-art word aligner, and hence we use it in this work. In addition, <cite class="ltx_cite ltx_citemacro_citet">Bahdanau et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib2" title="">2015</a>)</cite> introduces the “align and transaltion” using attention, which also inspires us to utilize the external word aligner as preference for MT.</p>
</div>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="286" id="S2.F2.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The illustration of WAP framework. The source text is first translated by multiple MT tools, including human translation. An external word aligner is then utilized to predict the coverage score for each translation. Next, translation with the highest and lowest coverage score are selected as preference pairs for the final preference optimization.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Proposed approach</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Gathering translation candidates</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.7">To steer the MT model to avoid hallucination and omission using preference optimization, we first need comparable but different translations. Starting with a source text <math alttext="x" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">italic_x</annotation></semantics></math>, we utilize <math alttext="K" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">italic_K</annotation></semantics></math> methods to produce translations, notated as <math alttext="\pi^{1},...,\pi^{K}" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.3"><semantics id="S3.SS1.p1.3.m3.3a"><mrow id="S3.SS1.p1.3.m3.3.3.2" xref="S3.SS1.p1.3.m3.3.3.3.cmml"><msup id="S3.SS1.p1.3.m3.2.2.1.1" xref="S3.SS1.p1.3.m3.2.2.1.1.cmml"><mi id="S3.SS1.p1.3.m3.2.2.1.1.2" xref="S3.SS1.p1.3.m3.2.2.1.1.2.cmml">π</mi><mn id="S3.SS1.p1.3.m3.2.2.1.1.3" xref="S3.SS1.p1.3.m3.2.2.1.1.3.cmml">1</mn></msup><mo id="S3.SS1.p1.3.m3.3.3.2.3" xref="S3.SS1.p1.3.m3.3.3.3.cmml">,</mo><mi id="S3.SS1.p1.3.m3.1.1" mathvariant="normal" xref="S3.SS1.p1.3.m3.1.1.cmml">…</mi><mo id="S3.SS1.p1.3.m3.3.3.2.4" xref="S3.SS1.p1.3.m3.3.3.3.cmml">,</mo><msup id="S3.SS1.p1.3.m3.3.3.2.2" xref="S3.SS1.p1.3.m3.3.3.2.2.cmml"><mi id="S3.SS1.p1.3.m3.3.3.2.2.2" xref="S3.SS1.p1.3.m3.3.3.2.2.2.cmml">π</mi><mi id="S3.SS1.p1.3.m3.3.3.2.2.3" xref="S3.SS1.p1.3.m3.3.3.2.2.3.cmml">K</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.3b"><list id="S3.SS1.p1.3.m3.3.3.3.cmml" xref="S3.SS1.p1.3.m3.3.3.2"><apply id="S3.SS1.p1.3.m3.2.2.1.1.cmml" xref="S3.SS1.p1.3.m3.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.2.2.1.1.1.cmml" xref="S3.SS1.p1.3.m3.2.2.1.1">superscript</csymbol><ci id="S3.SS1.p1.3.m3.2.2.1.1.2.cmml" xref="S3.SS1.p1.3.m3.2.2.1.1.2">𝜋</ci><cn id="S3.SS1.p1.3.m3.2.2.1.1.3.cmml" type="integer" xref="S3.SS1.p1.3.m3.2.2.1.1.3">1</cn></apply><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">…</ci><apply id="S3.SS1.p1.3.m3.3.3.2.2.cmml" xref="S3.SS1.p1.3.m3.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.3.3.2.2.1.cmml" xref="S3.SS1.p1.3.m3.3.3.2.2">superscript</csymbol><ci id="S3.SS1.p1.3.m3.3.3.2.2.2.cmml" xref="S3.SS1.p1.3.m3.3.3.2.2.2">𝜋</ci><ci id="S3.SS1.p1.3.m3.3.3.2.2.3.cmml" xref="S3.SS1.p1.3.m3.3.3.2.2.3">𝐾</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.3c">\pi^{1},...,\pi^{K}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.3d">italic_π start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , … , italic_π start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT</annotation></semantics></math>. Then we can get a set of translations <math alttext="Y" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m4.1"><semantics id="S3.SS1.p1.4.m4.1a"><mi id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml">Y</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><ci id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">𝑌</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">Y</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.4.m4.1d">italic_Y</annotation></semantics></math>, in which <math alttext="y^{k}\in Y" class="ltx_Math" display="inline" id="S3.SS1.p1.5.m5.1"><semantics id="S3.SS1.p1.5.m5.1a"><mrow id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml"><msup id="S3.SS1.p1.5.m5.1.1.2" xref="S3.SS1.p1.5.m5.1.1.2.cmml"><mi id="S3.SS1.p1.5.m5.1.1.2.2" xref="S3.SS1.p1.5.m5.1.1.2.2.cmml">y</mi><mi id="S3.SS1.p1.5.m5.1.1.2.3" xref="S3.SS1.p1.5.m5.1.1.2.3.cmml">k</mi></msup><mo id="S3.SS1.p1.5.m5.1.1.1" xref="S3.SS1.p1.5.m5.1.1.1.cmml">∈</mo><mi id="S3.SS1.p1.5.m5.1.1.3" xref="S3.SS1.p1.5.m5.1.1.3.cmml">Y</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><apply id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1"><in id="S3.SS1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1.1"></in><apply id="S3.SS1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.2.1.cmml" xref="S3.SS1.p1.5.m5.1.1.2">superscript</csymbol><ci id="S3.SS1.p1.5.m5.1.1.2.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2.2">𝑦</ci><ci id="S3.SS1.p1.5.m5.1.1.2.3.cmml" xref="S3.SS1.p1.5.m5.1.1.2.3">𝑘</ci></apply><ci id="S3.SS1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3">𝑌</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">y^{k}\in Y</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.5.m5.1d">italic_y start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ∈ italic_Y</annotation></semantics></math> is obtained by <math alttext="y^{k}=\pi^{k}(x)" class="ltx_Math" display="inline" id="S3.SS1.p1.6.m6.1"><semantics id="S3.SS1.p1.6.m6.1a"><mrow id="S3.SS1.p1.6.m6.1.2" xref="S3.SS1.p1.6.m6.1.2.cmml"><msup id="S3.SS1.p1.6.m6.1.2.2" xref="S3.SS1.p1.6.m6.1.2.2.cmml"><mi id="S3.SS1.p1.6.m6.1.2.2.2" xref="S3.SS1.p1.6.m6.1.2.2.2.cmml">y</mi><mi id="S3.SS1.p1.6.m6.1.2.2.3" xref="S3.SS1.p1.6.m6.1.2.2.3.cmml">k</mi></msup><mo id="S3.SS1.p1.6.m6.1.2.1" xref="S3.SS1.p1.6.m6.1.2.1.cmml">=</mo><mrow id="S3.SS1.p1.6.m6.1.2.3" xref="S3.SS1.p1.6.m6.1.2.3.cmml"><msup id="S3.SS1.p1.6.m6.1.2.3.2" xref="S3.SS1.p1.6.m6.1.2.3.2.cmml"><mi id="S3.SS1.p1.6.m6.1.2.3.2.2" xref="S3.SS1.p1.6.m6.1.2.3.2.2.cmml">π</mi><mi id="S3.SS1.p1.6.m6.1.2.3.2.3" xref="S3.SS1.p1.6.m6.1.2.3.2.3.cmml">k</mi></msup><mo id="S3.SS1.p1.6.m6.1.2.3.1" xref="S3.SS1.p1.6.m6.1.2.3.1.cmml">⁢</mo><mrow id="S3.SS1.p1.6.m6.1.2.3.3.2" xref="S3.SS1.p1.6.m6.1.2.3.cmml"><mo id="S3.SS1.p1.6.m6.1.2.3.3.2.1" stretchy="false" xref="S3.SS1.p1.6.m6.1.2.3.cmml">(</mo><mi id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml">x</mi><mo id="S3.SS1.p1.6.m6.1.2.3.3.2.2" stretchy="false" xref="S3.SS1.p1.6.m6.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><apply id="S3.SS1.p1.6.m6.1.2.cmml" xref="S3.SS1.p1.6.m6.1.2"><eq id="S3.SS1.p1.6.m6.1.2.1.cmml" xref="S3.SS1.p1.6.m6.1.2.1"></eq><apply id="S3.SS1.p1.6.m6.1.2.2.cmml" xref="S3.SS1.p1.6.m6.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.2.2.1.cmml" xref="S3.SS1.p1.6.m6.1.2.2">superscript</csymbol><ci id="S3.SS1.p1.6.m6.1.2.2.2.cmml" xref="S3.SS1.p1.6.m6.1.2.2.2">𝑦</ci><ci id="S3.SS1.p1.6.m6.1.2.2.3.cmml" xref="S3.SS1.p1.6.m6.1.2.2.3">𝑘</ci></apply><apply id="S3.SS1.p1.6.m6.1.2.3.cmml" xref="S3.SS1.p1.6.m6.1.2.3"><times id="S3.SS1.p1.6.m6.1.2.3.1.cmml" xref="S3.SS1.p1.6.m6.1.2.3.1"></times><apply id="S3.SS1.p1.6.m6.1.2.3.2.cmml" xref="S3.SS1.p1.6.m6.1.2.3.2"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.2.3.2.1.cmml" xref="S3.SS1.p1.6.m6.1.2.3.2">superscript</csymbol><ci id="S3.SS1.p1.6.m6.1.2.3.2.2.cmml" xref="S3.SS1.p1.6.m6.1.2.3.2.2">𝜋</ci><ci id="S3.SS1.p1.6.m6.1.2.3.2.3.cmml" xref="S3.SS1.p1.6.m6.1.2.3.2.3">𝑘</ci></apply><ci id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">y^{k}=\pi^{k}(x)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.6.m6.1d">italic_y start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT = italic_π start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ( italic_x )</annotation></semantics></math> and <math alttext="|Y|=K" class="ltx_Math" display="inline" id="S3.SS1.p1.7.m7.1"><semantics id="S3.SS1.p1.7.m7.1a"><mrow id="S3.SS1.p1.7.m7.1.2" xref="S3.SS1.p1.7.m7.1.2.cmml"><mrow id="S3.SS1.p1.7.m7.1.2.2.2" xref="S3.SS1.p1.7.m7.1.2.2.1.cmml"><mo id="S3.SS1.p1.7.m7.1.2.2.2.1" stretchy="false" xref="S3.SS1.p1.7.m7.1.2.2.1.1.cmml">|</mo><mi id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml">Y</mi><mo id="S3.SS1.p1.7.m7.1.2.2.2.2" stretchy="false" xref="S3.SS1.p1.7.m7.1.2.2.1.1.cmml">|</mo></mrow><mo id="S3.SS1.p1.7.m7.1.2.1" xref="S3.SS1.p1.7.m7.1.2.1.cmml">=</mo><mi id="S3.SS1.p1.7.m7.1.2.3" xref="S3.SS1.p1.7.m7.1.2.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><apply id="S3.SS1.p1.7.m7.1.2.cmml" xref="S3.SS1.p1.7.m7.1.2"><eq id="S3.SS1.p1.7.m7.1.2.1.cmml" xref="S3.SS1.p1.7.m7.1.2.1"></eq><apply id="S3.SS1.p1.7.m7.1.2.2.1.cmml" xref="S3.SS1.p1.7.m7.1.2.2.2"><abs id="S3.SS1.p1.7.m7.1.2.2.1.1.cmml" xref="S3.SS1.p1.7.m7.1.2.2.2.1"></abs><ci id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1">𝑌</ci></apply><ci id="S3.SS1.p1.7.m7.1.2.3.cmml" xref="S3.SS1.p1.7.m7.1.2.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">|Y|=K</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.7.m7.1d">| italic_Y | = italic_K</annotation></semantics></math>.</p>
</div>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Details of gathered translations</h4>
<div class="ltx_para" id="S3.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS1.SSS0.Px1.p1.12">We start with the parallel training data in ALMA <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib41" title="">2024a</a>)</cite>. This parallel data encompasses five language pairs with human translations in both directions: <math alttext="cs\leftrightarrow en" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.1.m1.1"><semantics id="S3.SS1.SSS0.Px1.p1.1.m1.1a"><mrow id="S3.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml"><mrow id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2.cmml"><mi id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2.2" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2.2.cmml">c</mi><mo id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2.1" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2.1.cmml">⁢</mo><mi id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2.3" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2.3.cmml">s</mi></mrow><mo id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.1" stretchy="false" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.1.cmml">↔</mo><mrow id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3.cmml"><mi id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3.2" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3.2.cmml">e</mi><mo id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3.1" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3.3" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.1.m1.1b"><apply id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1"><ci id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.1">↔</ci><apply id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2"><times id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2.1.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2.1"></times><ci id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2.2">𝑐</ci><ci id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2.3.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2.3">𝑠</ci></apply><apply id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3"><times id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3.1.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3.1"></times><ci id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3.2.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3.2">𝑒</ci><ci id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3.3.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.1.m1.1c">cs\leftrightarrow en</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.1.m1.1d">italic_c italic_s ↔ italic_e italic_n</annotation></semantics></math>, <math alttext="de\leftrightarrow en" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.2.m2.1"><semantics id="S3.SS1.SSS0.Px1.p1.2.m2.1a"><mrow id="S3.SS1.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.cmml"><mrow id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.cmml"><mi id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.2" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.2.cmml">d</mi><mo id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.1" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.1.cmml">⁢</mo><mi id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.3" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.3.cmml">e</mi></mrow><mo id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.1" stretchy="false" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.1.cmml">↔</mo><mrow id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.cmml"><mi id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.2" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.2.cmml">e</mi><mo id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.1" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.3" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.2.m2.1b"><apply id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1"><ci id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.1">↔</ci><apply id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2"><times id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.1.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.1"></times><ci id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.2">𝑑</ci><ci id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.3.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.3">𝑒</ci></apply><apply id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3"><times id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.1.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.1"></times><ci id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.2.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.2">𝑒</ci><ci id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.3.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.2.m2.1c">de\leftrightarrow en</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.2.m2.1d">italic_d italic_e ↔ italic_e italic_n</annotation></semantics></math>, <math alttext="is\leftrightarrow en" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.3.m3.1"><semantics id="S3.SS1.SSS0.Px1.p1.3.m3.1a"><mrow id="S3.SS1.SSS0.Px1.p1.3.m3.1.1" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.cmml"><mrow id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.cmml"><mi id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.2" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.2.cmml">i</mi><mo id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.1" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.1.cmml">⁢</mo><mi id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.3" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.3.cmml">s</mi></mrow><mo id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.1" stretchy="false" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.1.cmml">↔</mo><mrow id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.cmml"><mi id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.2" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.2.cmml">e</mi><mo id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.1" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.3.m3.1b"><apply id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1"><ci id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.1">↔</ci><apply id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2"><times id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.1.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.1"></times><ci id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.2">𝑖</ci><ci id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.3.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.3">𝑠</ci></apply><apply id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3"><times id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.1.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.1"></times><ci id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.2.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.2">𝑒</ci><ci id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.3.m3.1c">is\leftrightarrow en</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.3.m3.1d">italic_i italic_s ↔ italic_e italic_n</annotation></semantics></math>, <math alttext="zh\leftrightarrow en" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.4.m4.1"><semantics id="S3.SS1.SSS0.Px1.p1.4.m4.1a"><mrow id="S3.SS1.SSS0.Px1.p1.4.m4.1.1" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.cmml"><mrow id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.cmml"><mi id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.2" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.2.cmml">z</mi><mo id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.1" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.1.cmml">⁢</mo><mi id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.3" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.3.cmml">h</mi></mrow><mo id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.1" stretchy="false" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.1.cmml">↔</mo><mrow id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3.cmml"><mi id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3.2" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3.2.cmml">e</mi><mo id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3.1" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3.3" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.4.m4.1b"><apply id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1"><ci id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.1">↔</ci><apply id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2"><times id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.1.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.1"></times><ci id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.2">𝑧</ci><ci id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.3.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.3">ℎ</ci></apply><apply id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3"><times id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3.1.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3.1"></times><ci id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3.2.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3.2">𝑒</ci><ci id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3.3.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.4.m4.1c">zh\leftrightarrow en</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.4.m4.1d">italic_z italic_h ↔ italic_e italic_n</annotation></semantics></math> and <math alttext="ru\leftrightarrow en" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.5.m5.1"><semantics id="S3.SS1.SSS0.Px1.p1.5.m5.1a"><mrow id="S3.SS1.SSS0.Px1.p1.5.m5.1.1" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.cmml"><mrow id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.cmml"><mi id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.2" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.2.cmml">r</mi><mo id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.1" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.1.cmml">⁢</mo><mi id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.3" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.3.cmml">u</mi></mrow><mo id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.1" stretchy="false" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.1.cmml">↔</mo><mrow id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.cmml"><mi id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.2" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.2.cmml">e</mi><mo id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.1" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.3" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.5.m5.1b"><apply id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1"><ci id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.1">↔</ci><apply id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2"><times id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.1.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.1"></times><ci id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.2">𝑟</ci><ci id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.3.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.3">𝑢</ci></apply><apply id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3"><times id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.1.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.1"></times><ci id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.2.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.2">𝑒</ci><ci id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.3.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.5.m5.1c">ru\leftrightarrow en</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.5.m5.1d">italic_r italic_u ↔ italic_e italic_n</annotation></semantics></math>. We employ ISO 639 language codes<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://en.wikipedia.org/wiki/List_of_ISO_639_language_codes" title="">https://en.wikipedia.org/wiki/List_of_ISO_639_language_codes</a></span></span></span> to denote languages. Specifically, “<math alttext="cs" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.6.m6.1"><semantics id="S3.SS1.SSS0.Px1.p1.6.m6.1a"><mrow id="S3.SS1.SSS0.Px1.p1.6.m6.1.1" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.6.m6.1.1.2" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1.2.cmml">c</mi><mo id="S3.SS1.SSS0.Px1.p1.6.m6.1.1.1" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1.1.cmml">⁢</mo><mi id="S3.SS1.SSS0.Px1.p1.6.m6.1.1.3" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1.3.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.6.m6.1b"><apply id="S3.SS1.SSS0.Px1.p1.6.m6.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1"><times id="S3.SS1.SSS0.Px1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1.1"></times><ci id="S3.SS1.SSS0.Px1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1.2">𝑐</ci><ci id="S3.SS1.SSS0.Px1.p1.6.m6.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.6.m6.1c">cs</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.6.m6.1d">italic_c italic_s</annotation></semantics></math>” corresponds to Czech, “<math alttext="de" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.7.m7.1"><semantics id="S3.SS1.SSS0.Px1.p1.7.m7.1a"><mrow id="S3.SS1.SSS0.Px1.p1.7.m7.1.1" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.7.m7.1.1.2" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.1.2.cmml">d</mi><mo id="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.cmml">⁢</mo><mi id="S3.SS1.SSS0.Px1.p1.7.m7.1.1.3" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.1.3.cmml">e</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.7.m7.1b"><apply id="S3.SS1.SSS0.Px1.p1.7.m7.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.1"><times id="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1"></times><ci id="S3.SS1.SSS0.Px1.p1.7.m7.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.1.2">𝑑</ci><ci id="S3.SS1.SSS0.Px1.p1.7.m7.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.1.3">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.7.m7.1c">de</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.7.m7.1d">italic_d italic_e</annotation></semantics></math>” to German, “<math alttext="is" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.8.m8.1"><semantics id="S3.SS1.SSS0.Px1.p1.8.m8.1a"><mrow id="S3.SS1.SSS0.Px1.p1.8.m8.1.1" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.2" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.2.cmml">i</mi><mo id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.cmml">⁢</mo><mi id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.3" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.3.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.8.m8.1b"><apply id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1"><times id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1"></times><ci id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.2">𝑖</ci><ci id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.8.m8.1c">is</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.8.m8.1d">italic_i italic_s</annotation></semantics></math>” to Icelandic, “<math alttext="zh" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.9.m9.1"><semantics id="S3.SS1.SSS0.Px1.p1.9.m9.1a"><mrow id="S3.SS1.SSS0.Px1.p1.9.m9.1.1" xref="S3.SS1.SSS0.Px1.p1.9.m9.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.9.m9.1.1.2" xref="S3.SS1.SSS0.Px1.p1.9.m9.1.1.2.cmml">z</mi><mo id="S3.SS1.SSS0.Px1.p1.9.m9.1.1.1" xref="S3.SS1.SSS0.Px1.p1.9.m9.1.1.1.cmml">⁢</mo><mi id="S3.SS1.SSS0.Px1.p1.9.m9.1.1.3" xref="S3.SS1.SSS0.Px1.p1.9.m9.1.1.3.cmml">h</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.9.m9.1b"><apply id="S3.SS1.SSS0.Px1.p1.9.m9.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.9.m9.1.1"><times id="S3.SS1.SSS0.Px1.p1.9.m9.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.9.m9.1.1.1"></times><ci id="S3.SS1.SSS0.Px1.p1.9.m9.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.9.m9.1.1.2">𝑧</ci><ci id="S3.SS1.SSS0.Px1.p1.9.m9.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.9.m9.1.1.3">ℎ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.9.m9.1c">zh</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.9.m9.1d">italic_z italic_h</annotation></semantics></math>” to Chinese and “<math alttext="ru" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.10.m10.1"><semantics id="S3.SS1.SSS0.Px1.p1.10.m10.1a"><mrow id="S3.SS1.SSS0.Px1.p1.10.m10.1.1" xref="S3.SS1.SSS0.Px1.p1.10.m10.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.10.m10.1.1.2" xref="S3.SS1.SSS0.Px1.p1.10.m10.1.1.2.cmml">r</mi><mo id="S3.SS1.SSS0.Px1.p1.10.m10.1.1.1" xref="S3.SS1.SSS0.Px1.p1.10.m10.1.1.1.cmml">⁢</mo><mi id="S3.SS1.SSS0.Px1.p1.10.m10.1.1.3" xref="S3.SS1.SSS0.Px1.p1.10.m10.1.1.3.cmml">u</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.10.m10.1b"><apply id="S3.SS1.SSS0.Px1.p1.10.m10.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.10.m10.1.1"><times id="S3.SS1.SSS0.Px1.p1.10.m10.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.10.m10.1.1.1"></times><ci id="S3.SS1.SSS0.Px1.p1.10.m10.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.10.m10.1.1.2">𝑟</ci><ci id="S3.SS1.SSS0.Px1.p1.10.m10.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.10.m10.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.10.m10.1c">ru</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.10.m10.1d">italic_r italic_u</annotation></semantics></math>” and “<math alttext="en" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.11.m11.1"><semantics id="S3.SS1.SSS0.Px1.p1.11.m11.1a"><mrow id="S3.SS1.SSS0.Px1.p1.11.m11.1.1" xref="S3.SS1.SSS0.Px1.p1.11.m11.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.11.m11.1.1.2" xref="S3.SS1.SSS0.Px1.p1.11.m11.1.1.2.cmml">e</mi><mo id="S3.SS1.SSS0.Px1.p1.11.m11.1.1.1" xref="S3.SS1.SSS0.Px1.p1.11.m11.1.1.1.cmml">⁢</mo><mi id="S3.SS1.SSS0.Px1.p1.11.m11.1.1.3" xref="S3.SS1.SSS0.Px1.p1.11.m11.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.11.m11.1b"><apply id="S3.SS1.SSS0.Px1.p1.11.m11.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.11.m11.1.1"><times id="S3.SS1.SSS0.Px1.p1.11.m11.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.11.m11.1.1.1"></times><ci id="S3.SS1.SSS0.Px1.p1.11.m11.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.11.m11.1.1.2">𝑒</ci><ci id="S3.SS1.SSS0.Px1.p1.11.m11.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.11.m11.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.11.m11.1c">en</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.11.m11.1d">italic_e italic_n</annotation></semantics></math>” to Russian and English, respectively. To generate the translations we require, this dataset is translated in both directions using two well-known MT tools, including DeepL<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.deepl.com/en/translator" title="">https://www.deepl.com/en/translator</a></span></span></span> and ChatGPT (<span class="ltx_text ltx_font_typewriter" id="S3.SS1.SSS0.Px1.p1.12.1">gpt-3.5-turbo-0613</span>)<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/product" title="">https://openai.com/product</a></span></span></span>.
The prompt for ChatGPT that we utilize to translate sentences is shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S3.F3" title="Figure 3 ‣ Details of gathered translations ‣ 3.1 Gathering translation candidates ‣ 3 Proposed approach ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a>.
The original human-written translation in the training set is also utilized. In particular, Icelandic (<math alttext="is" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.12.m12.1"><semantics id="S3.SS1.SSS0.Px1.p1.12.m12.1a"><mrow id="S3.SS1.SSS0.Px1.p1.12.m12.1.1" xref="S3.SS1.SSS0.Px1.p1.12.m12.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.12.m12.1.1.2" xref="S3.SS1.SSS0.Px1.p1.12.m12.1.1.2.cmml">i</mi><mo id="S3.SS1.SSS0.Px1.p1.12.m12.1.1.1" xref="S3.SS1.SSS0.Px1.p1.12.m12.1.1.1.cmml">⁢</mo><mi id="S3.SS1.SSS0.Px1.p1.12.m12.1.1.3" xref="S3.SS1.SSS0.Px1.p1.12.m12.1.1.3.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.12.m12.1b"><apply id="S3.SS1.SSS0.Px1.p1.12.m12.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.12.m12.1.1"><times id="S3.SS1.SSS0.Px1.p1.12.m12.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.12.m12.1.1.1"></times><ci id="S3.SS1.SSS0.Px1.p1.12.m12.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.12.m12.1.1.2">𝑖</ci><ci id="S3.SS1.SSS0.Px1.p1.12.m12.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.12.m12.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.12.m12.1c">is</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.12.m12.1d">italic_i italic_s</annotation></semantics></math>) is not supported by the DeepL API, therefore, we use the Google Translate API<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://cloud.google.com/translate/docs/basic/translate-text-basic" title="">https://cloud.google.com/translate/docs/basic/translate-text-basic</a></span></span></span> as an alternative.</p>
</div>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="155" id="S3.F3.g1" src="x4.png" width="415"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The prompt of ChatGPT that we use to translate sentences.</figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Selecting chosen and rejected translation</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.4">After obtaining the translation candidates <math alttext="(y^{1},...,y^{K})" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.3"><semantics id="S3.SS2.p1.1.m1.3a"><mrow id="S3.SS2.p1.1.m1.3.3.2" xref="S3.SS2.p1.1.m1.3.3.3.cmml"><mo id="S3.SS2.p1.1.m1.3.3.2.3" stretchy="false" xref="S3.SS2.p1.1.m1.3.3.3.cmml">(</mo><msup id="S3.SS2.p1.1.m1.2.2.1.1" xref="S3.SS2.p1.1.m1.2.2.1.1.cmml"><mi id="S3.SS2.p1.1.m1.2.2.1.1.2" xref="S3.SS2.p1.1.m1.2.2.1.1.2.cmml">y</mi><mn id="S3.SS2.p1.1.m1.2.2.1.1.3" xref="S3.SS2.p1.1.m1.2.2.1.1.3.cmml">1</mn></msup><mo id="S3.SS2.p1.1.m1.3.3.2.4" xref="S3.SS2.p1.1.m1.3.3.3.cmml">,</mo><mi id="S3.SS2.p1.1.m1.1.1" mathvariant="normal" xref="S3.SS2.p1.1.m1.1.1.cmml">…</mi><mo id="S3.SS2.p1.1.m1.3.3.2.5" xref="S3.SS2.p1.1.m1.3.3.3.cmml">,</mo><msup id="S3.SS2.p1.1.m1.3.3.2.2" xref="S3.SS2.p1.1.m1.3.3.2.2.cmml"><mi id="S3.SS2.p1.1.m1.3.3.2.2.2" xref="S3.SS2.p1.1.m1.3.3.2.2.2.cmml">y</mi><mi id="S3.SS2.p1.1.m1.3.3.2.2.3" xref="S3.SS2.p1.1.m1.3.3.2.2.3.cmml">K</mi></msup><mo id="S3.SS2.p1.1.m1.3.3.2.6" stretchy="false" xref="S3.SS2.p1.1.m1.3.3.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.3b"><vector id="S3.SS2.p1.1.m1.3.3.3.cmml" xref="S3.SS2.p1.1.m1.3.3.2"><apply id="S3.SS2.p1.1.m1.2.2.1.1.cmml" xref="S3.SS2.p1.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.2.2.1.1.1.cmml" xref="S3.SS2.p1.1.m1.2.2.1.1">superscript</csymbol><ci id="S3.SS2.p1.1.m1.2.2.1.1.2.cmml" xref="S3.SS2.p1.1.m1.2.2.1.1.2">𝑦</ci><cn id="S3.SS2.p1.1.m1.2.2.1.1.3.cmml" type="integer" xref="S3.SS2.p1.1.m1.2.2.1.1.3">1</cn></apply><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">…</ci><apply id="S3.SS2.p1.1.m1.3.3.2.2.cmml" xref="S3.SS2.p1.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.3.3.2.2.1.cmml" xref="S3.SS2.p1.1.m1.3.3.2.2">superscript</csymbol><ci id="S3.SS2.p1.1.m1.3.3.2.2.2.cmml" xref="S3.SS2.p1.1.m1.3.3.2.2.2">𝑦</ci><ci id="S3.SS2.p1.1.m1.3.3.2.2.3.cmml" xref="S3.SS2.p1.1.m1.3.3.2.2.3">𝐾</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.3c">(y^{1},...,y^{K})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.3d">( italic_y start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , … , italic_y start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT )</annotation></semantics></math>, we use a state-of-the-art public word aligner, namely WSPAlign<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/qiyuw/WSPAlign" title="">https://github.com/qiyuw/WSPAlign</a></span></span></span>, to automatically annotate the degree of coverage for each translation. We follow the usage setting in the original paper of WSPAlign <cite class="ltx_cite ltx_citemacro_citep">(Wu et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib38" title="">2023</a>)</cite>. In particular, WSPAlign performs a bidirectional alignment and uses a threshold to filter out low-confident alignment of word pairs. Then, the ratio of the source words, <em class="ltx_emph ltx_font_italic" id="S3.SS2.p1.4.1">that are aligned with at least one word</em>, in the translation is taken as the coverage score, which will be used for the following preference annotation.
The whole process predicting the coverage score is notated as <math alttext="\mathrm{C}(\cdot,\cdot)" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.2"><semantics id="S3.SS2.p1.2.m2.2a"><mrow id="S3.SS2.p1.2.m2.2.3" xref="S3.SS2.p1.2.m2.2.3.cmml"><mi id="S3.SS2.p1.2.m2.2.3.2" mathvariant="normal" xref="S3.SS2.p1.2.m2.2.3.2.cmml">C</mi><mo id="S3.SS2.p1.2.m2.2.3.1" xref="S3.SS2.p1.2.m2.2.3.1.cmml">⁢</mo><mrow id="S3.SS2.p1.2.m2.2.3.3.2" xref="S3.SS2.p1.2.m2.2.3.3.1.cmml"><mo id="S3.SS2.p1.2.m2.2.3.3.2.1" stretchy="false" xref="S3.SS2.p1.2.m2.2.3.3.1.cmml">(</mo><mo id="S3.SS2.p1.2.m2.1.1" lspace="0em" rspace="0em" xref="S3.SS2.p1.2.m2.1.1.cmml">⋅</mo><mo id="S3.SS2.p1.2.m2.2.3.3.2.2" rspace="0em" xref="S3.SS2.p1.2.m2.2.3.3.1.cmml">,</mo><mo id="S3.SS2.p1.2.m2.2.2" lspace="0em" rspace="0em" xref="S3.SS2.p1.2.m2.2.2.cmml">⋅</mo><mo id="S3.SS2.p1.2.m2.2.3.3.2.3" stretchy="false" xref="S3.SS2.p1.2.m2.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.2b"><apply id="S3.SS2.p1.2.m2.2.3.cmml" xref="S3.SS2.p1.2.m2.2.3"><times id="S3.SS2.p1.2.m2.2.3.1.cmml" xref="S3.SS2.p1.2.m2.2.3.1"></times><ci id="S3.SS2.p1.2.m2.2.3.2.cmml" xref="S3.SS2.p1.2.m2.2.3.2">C</ci><interval closure="open" id="S3.SS2.p1.2.m2.2.3.3.1.cmml" xref="S3.SS2.p1.2.m2.2.3.3.2"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">⋅</ci><ci id="S3.SS2.p1.2.m2.2.2.cmml" xref="S3.SS2.p1.2.m2.2.2">⋅</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.2c">\mathrm{C}(\cdot,\cdot)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.2d">roman_C ( ⋅ , ⋅ )</annotation></semantics></math>. Formally, the coverage score for a translation <math alttext="y^{k}" class="ltx_Math" display="inline" id="S3.SS2.p1.3.m3.1"><semantics id="S3.SS2.p1.3.m3.1a"><msup id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml"><mi id="S3.SS2.p1.3.m3.1.1.2" xref="S3.SS2.p1.3.m3.1.1.2.cmml">y</mi><mi id="S3.SS2.p1.3.m3.1.1.3" xref="S3.SS2.p1.3.m3.1.1.3.cmml">k</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><apply id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.3.m3.1.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">superscript</csymbol><ci id="S3.SS2.p1.3.m3.1.1.2.cmml" xref="S3.SS2.p1.3.m3.1.1.2">𝑦</ci><ci id="S3.SS2.p1.3.m3.1.1.3.cmml" xref="S3.SS2.p1.3.m3.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">y^{k}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.3.m3.1d">italic_y start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT</annotation></semantics></math> can be calculated by <math alttext="\mathrm{C}(x,y^{k})\in[0.0,100.0]" class="ltx_Math" display="inline" id="S3.SS2.p1.4.m4.4"><semantics id="S3.SS2.p1.4.m4.4a"><mrow id="S3.SS2.p1.4.m4.4.4" xref="S3.SS2.p1.4.m4.4.4.cmml"><mrow id="S3.SS2.p1.4.m4.4.4.1" xref="S3.SS2.p1.4.m4.4.4.1.cmml"><mi id="S3.SS2.p1.4.m4.4.4.1.3" mathvariant="normal" xref="S3.SS2.p1.4.m4.4.4.1.3.cmml">C</mi><mo id="S3.SS2.p1.4.m4.4.4.1.2" xref="S3.SS2.p1.4.m4.4.4.1.2.cmml">⁢</mo><mrow id="S3.SS2.p1.4.m4.4.4.1.1.1" xref="S3.SS2.p1.4.m4.4.4.1.1.2.cmml"><mo id="S3.SS2.p1.4.m4.4.4.1.1.1.2" stretchy="false" xref="S3.SS2.p1.4.m4.4.4.1.1.2.cmml">(</mo><mi id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">x</mi><mo id="S3.SS2.p1.4.m4.4.4.1.1.1.3" xref="S3.SS2.p1.4.m4.4.4.1.1.2.cmml">,</mo><msup id="S3.SS2.p1.4.m4.4.4.1.1.1.1" xref="S3.SS2.p1.4.m4.4.4.1.1.1.1.cmml"><mi id="S3.SS2.p1.4.m4.4.4.1.1.1.1.2" xref="S3.SS2.p1.4.m4.4.4.1.1.1.1.2.cmml">y</mi><mi id="S3.SS2.p1.4.m4.4.4.1.1.1.1.3" xref="S3.SS2.p1.4.m4.4.4.1.1.1.1.3.cmml">k</mi></msup><mo id="S3.SS2.p1.4.m4.4.4.1.1.1.4" stretchy="false" xref="S3.SS2.p1.4.m4.4.4.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.SS2.p1.4.m4.4.4.2" xref="S3.SS2.p1.4.m4.4.4.2.cmml">∈</mo><mrow id="S3.SS2.p1.4.m4.4.4.3.2" xref="S3.SS2.p1.4.m4.4.4.3.1.cmml"><mo id="S3.SS2.p1.4.m4.4.4.3.2.1" stretchy="false" xref="S3.SS2.p1.4.m4.4.4.3.1.cmml">[</mo><mn id="S3.SS2.p1.4.m4.2.2" xref="S3.SS2.p1.4.m4.2.2.cmml">0.0</mn><mo id="S3.SS2.p1.4.m4.4.4.3.2.2" xref="S3.SS2.p1.4.m4.4.4.3.1.cmml">,</mo><mn id="S3.SS2.p1.4.m4.3.3" xref="S3.SS2.p1.4.m4.3.3.cmml">100.0</mn><mo id="S3.SS2.p1.4.m4.4.4.3.2.3" stretchy="false" xref="S3.SS2.p1.4.m4.4.4.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.4b"><apply id="S3.SS2.p1.4.m4.4.4.cmml" xref="S3.SS2.p1.4.m4.4.4"><in id="S3.SS2.p1.4.m4.4.4.2.cmml" xref="S3.SS2.p1.4.m4.4.4.2"></in><apply id="S3.SS2.p1.4.m4.4.4.1.cmml" xref="S3.SS2.p1.4.m4.4.4.1"><times id="S3.SS2.p1.4.m4.4.4.1.2.cmml" xref="S3.SS2.p1.4.m4.4.4.1.2"></times><ci id="S3.SS2.p1.4.m4.4.4.1.3.cmml" xref="S3.SS2.p1.4.m4.4.4.1.3">C</ci><interval closure="open" id="S3.SS2.p1.4.m4.4.4.1.1.2.cmml" xref="S3.SS2.p1.4.m4.4.4.1.1.1"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">𝑥</ci><apply id="S3.SS2.p1.4.m4.4.4.1.1.1.1.cmml" xref="S3.SS2.p1.4.m4.4.4.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.4.m4.4.4.1.1.1.1.1.cmml" xref="S3.SS2.p1.4.m4.4.4.1.1.1.1">superscript</csymbol><ci id="S3.SS2.p1.4.m4.4.4.1.1.1.1.2.cmml" xref="S3.SS2.p1.4.m4.4.4.1.1.1.1.2">𝑦</ci><ci id="S3.SS2.p1.4.m4.4.4.1.1.1.1.3.cmml" xref="S3.SS2.p1.4.m4.4.4.1.1.1.1.3">𝑘</ci></apply></interval></apply><interval closure="closed" id="S3.SS2.p1.4.m4.4.4.3.1.cmml" xref="S3.SS2.p1.4.m4.4.4.3.2"><cn id="S3.SS2.p1.4.m4.2.2.cmml" type="float" xref="S3.SS2.p1.4.m4.2.2">0.0</cn><cn id="S3.SS2.p1.4.m4.3.3.cmml" type="float" xref="S3.SS2.p1.4.m4.3.3">100.0</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.4c">\mathrm{C}(x,y^{k})\in[0.0,100.0]</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.4.m4.4d">roman_C ( italic_x , italic_y start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ) ∈ [ 0.0 , 100.0 ]</annotation></semantics></math>. Subsequently, the preferred translation and the rejected translation are selected by the following criteria:</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<table class="ltx_equationgroup ltx_eqn_gather ltx_eqn_table" id="A2.EGx1">
<tbody id="S3.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\displaystyle\begin{aligned} y^{w}&amp;=\mathop{\arg\max}\limits_{y^{k}\in Y}{%
\mathrm{C}(x,y^{k})}\\
y^{l}&amp;=\mathop{\arg\min}\limits_{y^{k}\in Y}{\mathrm{C}(x,y^{k})}\end{aligned}" class="ltx_Math" display="block" id="S3.E1.m1.4"><semantics id="S3.E1.m1.4a"><mtable columnspacing="0pt" displaystyle="true" id="S3.E1.m1.4.4" rowspacing="0pt" xref="S3.E1.m1.4.4.cmml"><mtr id="S3.E1.m1.4.4a" xref="S3.E1.m1.4.4.cmml"><mtd class="ltx_align_right" columnalign="right" id="S3.E1.m1.4.4b" xref="S3.E1.m1.4.4.cmml"><msup id="S3.E1.m1.2.2.2.3.1" xref="S3.E1.m1.2.2.2.3.1.cmml"><mi id="S3.E1.m1.2.2.2.3.1.2" xref="S3.E1.m1.2.2.2.3.1.2.cmml">y</mi><mi id="S3.E1.m1.2.2.2.3.1.3" xref="S3.E1.m1.2.2.2.3.1.3.cmml">w</mi></msup></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E1.m1.4.4c" xref="S3.E1.m1.4.4.cmml"><mrow id="S3.E1.m1.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.cmml"><mi id="S3.E1.m1.2.2.2.2.2.4" xref="S3.E1.m1.2.2.2.2.2.4.cmml"></mi><mo id="S3.E1.m1.2.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.2.3.cmml">=</mo><mrow id="S3.E1.m1.2.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.2.cmml"><munder id="S3.E1.m1.2.2.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.2.2.cmml"><mrow id="S3.E1.m1.2.2.2.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.2.2.2.cmml"><mi id="S3.E1.m1.2.2.2.2.2.2.2.2.1" xref="S3.E1.m1.2.2.2.2.2.2.2.2.1.cmml">arg</mi><mo id="S3.E1.m1.2.2.2.2.2.2.2.2a" lspace="0.167em" xref="S3.E1.m1.2.2.2.2.2.2.2.2.cmml">⁡</mo><mi id="S3.E1.m1.2.2.2.2.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.2.2.2.2.cmml">max</mi></mrow><mrow id="S3.E1.m1.2.2.2.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.2.2.2.3.cmml"><msup id="S3.E1.m1.2.2.2.2.2.2.2.3.2" xref="S3.E1.m1.2.2.2.2.2.2.2.3.2.cmml"><mi id="S3.E1.m1.2.2.2.2.2.2.2.3.2.2" xref="S3.E1.m1.2.2.2.2.2.2.2.3.2.2.cmml">y</mi><mi id="S3.E1.m1.2.2.2.2.2.2.2.3.2.3" xref="S3.E1.m1.2.2.2.2.2.2.2.3.2.3.cmml">k</mi></msup><mo id="S3.E1.m1.2.2.2.2.2.2.2.3.1" xref="S3.E1.m1.2.2.2.2.2.2.2.3.1.cmml">∈</mo><mi id="S3.E1.m1.2.2.2.2.2.2.2.3.3" xref="S3.E1.m1.2.2.2.2.2.2.2.3.3.cmml">Y</mi></mrow></munder><mrow id="S3.E1.m1.2.2.2.2.2.2.1" xref="S3.E1.m1.2.2.2.2.2.2.1.cmml"><mi id="S3.E1.m1.2.2.2.2.2.2.1.3" mathvariant="normal" xref="S3.E1.m1.2.2.2.2.2.2.1.3.cmml">C</mi><mo id="S3.E1.m1.2.2.2.2.2.2.1.2" xref="S3.E1.m1.2.2.2.2.2.2.1.2.cmml">⁢</mo><mrow id="S3.E1.m1.2.2.2.2.2.2.1.1.1" xref="S3.E1.m1.2.2.2.2.2.2.1.1.2.cmml"><mo id="S3.E1.m1.2.2.2.2.2.2.1.1.1.2" stretchy="false" xref="S3.E1.m1.2.2.2.2.2.2.1.1.2.cmml">(</mo><mi id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml">x</mi><mo id="S3.E1.m1.2.2.2.2.2.2.1.1.1.3" xref="S3.E1.m1.2.2.2.2.2.2.1.1.2.cmml">,</mo><msup id="S3.E1.m1.2.2.2.2.2.2.1.1.1.1" xref="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.cmml"><mi id="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.2" xref="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.2.cmml">y</mi><mi id="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.3" xref="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.3.cmml">k</mi></msup><mo id="S3.E1.m1.2.2.2.2.2.2.1.1.1.4" stretchy="false" xref="S3.E1.m1.2.2.2.2.2.2.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow></mtd></mtr><mtr id="S3.E1.m1.4.4d" xref="S3.E1.m1.4.4.cmml"><mtd class="ltx_align_right" columnalign="right" id="S3.E1.m1.4.4e" xref="S3.E1.m1.4.4.cmml"><msup id="S3.E1.m1.4.4.4.3.1" xref="S3.E1.m1.4.4.4.3.1.cmml"><mi id="S3.E1.m1.4.4.4.3.1.2" xref="S3.E1.m1.4.4.4.3.1.2.cmml">y</mi><mi id="S3.E1.m1.4.4.4.3.1.3" xref="S3.E1.m1.4.4.4.3.1.3.cmml">l</mi></msup></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E1.m1.4.4f" xref="S3.E1.m1.4.4.cmml"><mrow id="S3.E1.m1.4.4.4.2.2" xref="S3.E1.m1.4.4.4.2.2.cmml"><mi id="S3.E1.m1.4.4.4.2.2.4" xref="S3.E1.m1.4.4.4.2.2.4.cmml"></mi><mo id="S3.E1.m1.4.4.4.2.2.3" xref="S3.E1.m1.4.4.4.2.2.3.cmml">=</mo><mrow id="S3.E1.m1.4.4.4.2.2.2" xref="S3.E1.m1.4.4.4.2.2.2.cmml"><munder id="S3.E1.m1.4.4.4.2.2.2.2" xref="S3.E1.m1.4.4.4.2.2.2.2.cmml"><mrow id="S3.E1.m1.4.4.4.2.2.2.2.2" xref="S3.E1.m1.4.4.4.2.2.2.2.2.cmml"><mi id="S3.E1.m1.4.4.4.2.2.2.2.2.1" xref="S3.E1.m1.4.4.4.2.2.2.2.2.1.cmml">arg</mi><mo id="S3.E1.m1.4.4.4.2.2.2.2.2a" lspace="0.167em" xref="S3.E1.m1.4.4.4.2.2.2.2.2.cmml">⁡</mo><mi id="S3.E1.m1.4.4.4.2.2.2.2.2.2" xref="S3.E1.m1.4.4.4.2.2.2.2.2.2.cmml">min</mi></mrow><mrow id="S3.E1.m1.4.4.4.2.2.2.2.3" xref="S3.E1.m1.4.4.4.2.2.2.2.3.cmml"><msup id="S3.E1.m1.4.4.4.2.2.2.2.3.2" xref="S3.E1.m1.4.4.4.2.2.2.2.3.2.cmml"><mi id="S3.E1.m1.4.4.4.2.2.2.2.3.2.2" xref="S3.E1.m1.4.4.4.2.2.2.2.3.2.2.cmml">y</mi><mi id="S3.E1.m1.4.4.4.2.2.2.2.3.2.3" xref="S3.E1.m1.4.4.4.2.2.2.2.3.2.3.cmml">k</mi></msup><mo id="S3.E1.m1.4.4.4.2.2.2.2.3.1" xref="S3.E1.m1.4.4.4.2.2.2.2.3.1.cmml">∈</mo><mi id="S3.E1.m1.4.4.4.2.2.2.2.3.3" xref="S3.E1.m1.4.4.4.2.2.2.2.3.3.cmml">Y</mi></mrow></munder><mrow id="S3.E1.m1.4.4.4.2.2.2.1" xref="S3.E1.m1.4.4.4.2.2.2.1.cmml"><mi id="S3.E1.m1.4.4.4.2.2.2.1.3" mathvariant="normal" xref="S3.E1.m1.4.4.4.2.2.2.1.3.cmml">C</mi><mo id="S3.E1.m1.4.4.4.2.2.2.1.2" xref="S3.E1.m1.4.4.4.2.2.2.1.2.cmml">⁢</mo><mrow id="S3.E1.m1.4.4.4.2.2.2.1.1.1" xref="S3.E1.m1.4.4.4.2.2.2.1.1.2.cmml"><mo id="S3.E1.m1.4.4.4.2.2.2.1.1.1.2" stretchy="false" xref="S3.E1.m1.4.4.4.2.2.2.1.1.2.cmml">(</mo><mi id="S3.E1.m1.3.3.3.1.1.1" xref="S3.E1.m1.3.3.3.1.1.1.cmml">x</mi><mo id="S3.E1.m1.4.4.4.2.2.2.1.1.1.3" xref="S3.E1.m1.4.4.4.2.2.2.1.1.2.cmml">,</mo><msup id="S3.E1.m1.4.4.4.2.2.2.1.1.1.1" xref="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.cmml"><mi id="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.2" xref="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.2.cmml">y</mi><mi id="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.3" xref="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.3.cmml">k</mi></msup><mo id="S3.E1.m1.4.4.4.2.2.2.1.1.1.4" stretchy="false" xref="S3.E1.m1.4.4.4.2.2.2.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S3.E1.m1.4b"><matrix id="S3.E1.m1.4.4.cmml" xref="S3.E1.m1.4.4"><matrixrow id="S3.E1.m1.4.4a.cmml" xref="S3.E1.m1.4.4"><apply id="S3.E1.m1.2.2.2.3.1.cmml" xref="S3.E1.m1.2.2.2.3.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.3.1.1.cmml" xref="S3.E1.m1.2.2.2.3.1">superscript</csymbol><ci id="S3.E1.m1.2.2.2.3.1.2.cmml" xref="S3.E1.m1.2.2.2.3.1.2">𝑦</ci><ci id="S3.E1.m1.2.2.2.3.1.3.cmml" xref="S3.E1.m1.2.2.2.3.1.3">𝑤</ci></apply><apply id="S3.E1.m1.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2"><eq id="S3.E1.m1.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2.3"></eq><csymbol cd="latexml" id="S3.E1.m1.2.2.2.2.2.4.cmml" xref="S3.E1.m1.2.2.2.2.2.4">absent</csymbol><apply id="S3.E1.m1.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2"><apply id="S3.E1.m1.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2">subscript</csymbol><apply id="S3.E1.m1.2.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2.2"><arg id="S3.E1.m1.2.2.2.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2.2.1"></arg><max id="S3.E1.m1.2.2.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2.2.2"></max></apply><apply id="S3.E1.m1.2.2.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2.3"><in id="S3.E1.m1.2.2.2.2.2.2.2.3.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2.3.1"></in><apply id="S3.E1.m1.2.2.2.2.2.2.2.3.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.2.2.2.3.2.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2.3.2">superscript</csymbol><ci id="S3.E1.m1.2.2.2.2.2.2.2.3.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2.3.2.2">𝑦</ci><ci id="S3.E1.m1.2.2.2.2.2.2.2.3.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2.3.2.3">𝑘</ci></apply><ci id="S3.E1.m1.2.2.2.2.2.2.2.3.3.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2.3.3">𝑌</ci></apply></apply><apply id="S3.E1.m1.2.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1"><times id="S3.E1.m1.2.2.2.2.2.2.1.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.2"></times><ci id="S3.E1.m1.2.2.2.2.2.2.1.3.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.3">C</ci><interval closure="open" id="S3.E1.m1.2.2.2.2.2.2.1.1.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.1.1"><ci id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1">𝑥</ci><apply id="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.1.1.1">superscript</csymbol><ci id="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.2">𝑦</ci><ci id="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1.1.1.1.3">𝑘</ci></apply></interval></apply></apply></apply></matrixrow><matrixrow id="S3.E1.m1.4.4b.cmml" xref="S3.E1.m1.4.4"><apply id="S3.E1.m1.4.4.4.3.1.cmml" xref="S3.E1.m1.4.4.4.3.1"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.4.3.1.1.cmml" xref="S3.E1.m1.4.4.4.3.1">superscript</csymbol><ci id="S3.E1.m1.4.4.4.3.1.2.cmml" xref="S3.E1.m1.4.4.4.3.1.2">𝑦</ci><ci id="S3.E1.m1.4.4.4.3.1.3.cmml" xref="S3.E1.m1.4.4.4.3.1.3">𝑙</ci></apply><apply id="S3.E1.m1.4.4.4.2.2.cmml" xref="S3.E1.m1.4.4.4.2.2"><eq id="S3.E1.m1.4.4.4.2.2.3.cmml" xref="S3.E1.m1.4.4.4.2.2.3"></eq><csymbol cd="latexml" id="S3.E1.m1.4.4.4.2.2.4.cmml" xref="S3.E1.m1.4.4.4.2.2.4">absent</csymbol><apply id="S3.E1.m1.4.4.4.2.2.2.cmml" xref="S3.E1.m1.4.4.4.2.2.2"><apply id="S3.E1.m1.4.4.4.2.2.2.2.cmml" xref="S3.E1.m1.4.4.4.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.4.2.2.2.2.1.cmml" xref="S3.E1.m1.4.4.4.2.2.2.2">subscript</csymbol><apply id="S3.E1.m1.4.4.4.2.2.2.2.2.cmml" xref="S3.E1.m1.4.4.4.2.2.2.2.2"><arg id="S3.E1.m1.4.4.4.2.2.2.2.2.1.cmml" xref="S3.E1.m1.4.4.4.2.2.2.2.2.1"></arg><min id="S3.E1.m1.4.4.4.2.2.2.2.2.2.cmml" xref="S3.E1.m1.4.4.4.2.2.2.2.2.2"></min></apply><apply id="S3.E1.m1.4.4.4.2.2.2.2.3.cmml" xref="S3.E1.m1.4.4.4.2.2.2.2.3"><in id="S3.E1.m1.4.4.4.2.2.2.2.3.1.cmml" xref="S3.E1.m1.4.4.4.2.2.2.2.3.1"></in><apply id="S3.E1.m1.4.4.4.2.2.2.2.3.2.cmml" xref="S3.E1.m1.4.4.4.2.2.2.2.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.4.2.2.2.2.3.2.1.cmml" xref="S3.E1.m1.4.4.4.2.2.2.2.3.2">superscript</csymbol><ci id="S3.E1.m1.4.4.4.2.2.2.2.3.2.2.cmml" xref="S3.E1.m1.4.4.4.2.2.2.2.3.2.2">𝑦</ci><ci id="S3.E1.m1.4.4.4.2.2.2.2.3.2.3.cmml" xref="S3.E1.m1.4.4.4.2.2.2.2.3.2.3">𝑘</ci></apply><ci id="S3.E1.m1.4.4.4.2.2.2.2.3.3.cmml" xref="S3.E1.m1.4.4.4.2.2.2.2.3.3">𝑌</ci></apply></apply><apply id="S3.E1.m1.4.4.4.2.2.2.1.cmml" xref="S3.E1.m1.4.4.4.2.2.2.1"><times id="S3.E1.m1.4.4.4.2.2.2.1.2.cmml" xref="S3.E1.m1.4.4.4.2.2.2.1.2"></times><ci id="S3.E1.m1.4.4.4.2.2.2.1.3.cmml" xref="S3.E1.m1.4.4.4.2.2.2.1.3">C</ci><interval closure="open" id="S3.E1.m1.4.4.4.2.2.2.1.1.2.cmml" xref="S3.E1.m1.4.4.4.2.2.2.1.1.1"><ci id="S3.E1.m1.3.3.3.1.1.1.cmml" xref="S3.E1.m1.3.3.3.1.1.1">𝑥</ci><apply id="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.cmml" xref="S3.E1.m1.4.4.4.2.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.1.cmml" xref="S3.E1.m1.4.4.4.2.2.2.1.1.1.1">superscript</csymbol><ci id="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.2.cmml" xref="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.2">𝑦</ci><ci id="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.3.cmml" xref="S3.E1.m1.4.4.4.2.2.2.1.1.1.1.3">𝑘</ci></apply></interval></apply></apply></apply></matrixrow></matrix></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.4c">\displaystyle\begin{aligned} y^{w}&amp;=\mathop{\arg\max}\limits_{y^{k}\in Y}{%
\mathrm{C}(x,y^{k})}\\
y^{l}&amp;=\mathop{\arg\min}\limits_{y^{k}\in Y}{\mathrm{C}(x,y^{k})}\end{aligned}</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.4d">start_ROW start_CELL italic_y start_POSTSUPERSCRIPT italic_w end_POSTSUPERSCRIPT end_CELL start_CELL = start_BIGOP roman_arg roman_max end_BIGOP start_POSTSUBSCRIPT italic_y start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ∈ italic_Y end_POSTSUBSCRIPT roman_C ( italic_x , italic_y start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ) end_CELL end_ROW start_ROW start_CELL italic_y start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT end_CELL start_CELL = start_BIGOP roman_arg roman_min end_BIGOP start_POSTSUBSCRIPT italic_y start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ∈ italic_Y end_POSTSUBSCRIPT roman_C ( italic_x , italic_y start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ) end_CELL end_ROW</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.3">where <math alttext="y^{w}" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><msup id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.2.cmml">y</mi><mi id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3.cmml">w</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2">𝑦</ci><ci id="S3.SS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3">𝑤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">y^{w}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">italic_y start_POSTSUPERSCRIPT italic_w end_POSTSUPERSCRIPT</annotation></semantics></math> is the chosen translation and <math alttext="y^{l}" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.1"><semantics id="S3.SS2.p3.2.m2.1a"><msup id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml"><mi id="S3.SS2.p3.2.m2.1.1.2" xref="S3.SS2.p3.2.m2.1.1.2.cmml">y</mi><mi id="S3.SS2.p3.2.m2.1.1.3" xref="S3.SS2.p3.2.m2.1.1.3.cmml">l</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">superscript</csymbol><ci id="S3.SS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2">𝑦</ci><ci id="S3.SS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">y^{l}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.1d">italic_y start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT</annotation></semantics></math> is the rejected one. Then a triplet <math alttext="(x,y^{w},y^{l})" class="ltx_Math" display="inline" id="S3.SS2.p3.3.m3.3"><semantics id="S3.SS2.p3.3.m3.3a"><mrow id="S3.SS2.p3.3.m3.3.3.2" xref="S3.SS2.p3.3.m3.3.3.3.cmml"><mo id="S3.SS2.p3.3.m3.3.3.2.3" stretchy="false" xref="S3.SS2.p3.3.m3.3.3.3.cmml">(</mo><mi id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml">x</mi><mo id="S3.SS2.p3.3.m3.3.3.2.4" xref="S3.SS2.p3.3.m3.3.3.3.cmml">,</mo><msup id="S3.SS2.p3.3.m3.2.2.1.1" xref="S3.SS2.p3.3.m3.2.2.1.1.cmml"><mi id="S3.SS2.p3.3.m3.2.2.1.1.2" xref="S3.SS2.p3.3.m3.2.2.1.1.2.cmml">y</mi><mi id="S3.SS2.p3.3.m3.2.2.1.1.3" xref="S3.SS2.p3.3.m3.2.2.1.1.3.cmml">w</mi></msup><mo id="S3.SS2.p3.3.m3.3.3.2.5" xref="S3.SS2.p3.3.m3.3.3.3.cmml">,</mo><msup id="S3.SS2.p3.3.m3.3.3.2.2" xref="S3.SS2.p3.3.m3.3.3.2.2.cmml"><mi id="S3.SS2.p3.3.m3.3.3.2.2.2" xref="S3.SS2.p3.3.m3.3.3.2.2.2.cmml">y</mi><mi id="S3.SS2.p3.3.m3.3.3.2.2.3" xref="S3.SS2.p3.3.m3.3.3.2.2.3.cmml">l</mi></msup><mo id="S3.SS2.p3.3.m3.3.3.2.6" stretchy="false" xref="S3.SS2.p3.3.m3.3.3.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.3b"><vector id="S3.SS2.p3.3.m3.3.3.3.cmml" xref="S3.SS2.p3.3.m3.3.3.2"><ci id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">𝑥</ci><apply id="S3.SS2.p3.3.m3.2.2.1.1.cmml" xref="S3.SS2.p3.3.m3.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.2.2.1.1.1.cmml" xref="S3.SS2.p3.3.m3.2.2.1.1">superscript</csymbol><ci id="S3.SS2.p3.3.m3.2.2.1.1.2.cmml" xref="S3.SS2.p3.3.m3.2.2.1.1.2">𝑦</ci><ci id="S3.SS2.p3.3.m3.2.2.1.1.3.cmml" xref="S3.SS2.p3.3.m3.2.2.1.1.3">𝑤</ci></apply><apply id="S3.SS2.p3.3.m3.3.3.2.2.cmml" xref="S3.SS2.p3.3.m3.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.3.3.2.2.1.cmml" xref="S3.SS2.p3.3.m3.3.3.2.2">superscript</csymbol><ci id="S3.SS2.p3.3.m3.3.3.2.2.2.cmml" xref="S3.SS2.p3.3.m3.3.3.2.2.2">𝑦</ci><ci id="S3.SS2.p3.3.m3.3.3.2.2.3.cmml" xref="S3.SS2.p3.3.m3.3.3.2.2.3">𝑙</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.3c">(x,y^{w},y^{l})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.3.m3.3d">( italic_x , italic_y start_POSTSUPERSCRIPT italic_w end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT )</annotation></semantics></math> is constructed for the following preference optimization.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Filtering</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">Note that the whole pipeline of constructing the preference data is automatic, and existing MT and word alignment models are not perfect. Even for human-annotated translation, the quality of it is also an issue that cannot be ignored <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib42" title="">2024b</a>)</cite>, and may affect the performance of the model trained on it. Hence, noises are inevitable in both the translated texts and the preference choices. On the other hand, the MT tools we choose generally have good performance, it could happen that the generated translations are not diverse enough, leading to the preference signal being disrupted.
To improve the quality of the constructed preference datasets as much as possible, multiple strategies are applied to filter out potential bad training instances:</p>
<ul class="ltx_itemize" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.2">Remove the instance when the chosen and rejected translations only have a marginal difference in coverage score. The difference threshold is empirically set as 5.0, that is, <math alttext="(x,y^{w},y^{l})" class="ltx_Math" display="inline" id="S3.I1.i1.p1.1.m1.3"><semantics id="S3.I1.i1.p1.1.m1.3a"><mrow id="S3.I1.i1.p1.1.m1.3.3.2" xref="S3.I1.i1.p1.1.m1.3.3.3.cmml"><mo id="S3.I1.i1.p1.1.m1.3.3.2.3" stretchy="false" xref="S3.I1.i1.p1.1.m1.3.3.3.cmml">(</mo><mi id="S3.I1.i1.p1.1.m1.1.1" xref="S3.I1.i1.p1.1.m1.1.1.cmml">x</mi><mo id="S3.I1.i1.p1.1.m1.3.3.2.4" xref="S3.I1.i1.p1.1.m1.3.3.3.cmml">,</mo><msup id="S3.I1.i1.p1.1.m1.2.2.1.1" xref="S3.I1.i1.p1.1.m1.2.2.1.1.cmml"><mi id="S3.I1.i1.p1.1.m1.2.2.1.1.2" xref="S3.I1.i1.p1.1.m1.2.2.1.1.2.cmml">y</mi><mi id="S3.I1.i1.p1.1.m1.2.2.1.1.3" xref="S3.I1.i1.p1.1.m1.2.2.1.1.3.cmml">w</mi></msup><mo id="S3.I1.i1.p1.1.m1.3.3.2.5" xref="S3.I1.i1.p1.1.m1.3.3.3.cmml">,</mo><msup id="S3.I1.i1.p1.1.m1.3.3.2.2" xref="S3.I1.i1.p1.1.m1.3.3.2.2.cmml"><mi id="S3.I1.i1.p1.1.m1.3.3.2.2.2" xref="S3.I1.i1.p1.1.m1.3.3.2.2.2.cmml">y</mi><mi id="S3.I1.i1.p1.1.m1.3.3.2.2.3" xref="S3.I1.i1.p1.1.m1.3.3.2.2.3.cmml">l</mi></msup><mo id="S3.I1.i1.p1.1.m1.3.3.2.6" stretchy="false" xref="S3.I1.i1.p1.1.m1.3.3.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.1.m1.3b"><vector id="S3.I1.i1.p1.1.m1.3.3.3.cmml" xref="S3.I1.i1.p1.1.m1.3.3.2"><ci id="S3.I1.i1.p1.1.m1.1.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1">𝑥</ci><apply id="S3.I1.i1.p1.1.m1.2.2.1.1.cmml" xref="S3.I1.i1.p1.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S3.I1.i1.p1.1.m1.2.2.1.1.1.cmml" xref="S3.I1.i1.p1.1.m1.2.2.1.1">superscript</csymbol><ci id="S3.I1.i1.p1.1.m1.2.2.1.1.2.cmml" xref="S3.I1.i1.p1.1.m1.2.2.1.1.2">𝑦</ci><ci id="S3.I1.i1.p1.1.m1.2.2.1.1.3.cmml" xref="S3.I1.i1.p1.1.m1.2.2.1.1.3">𝑤</ci></apply><apply id="S3.I1.i1.p1.1.m1.3.3.2.2.cmml" xref="S3.I1.i1.p1.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="S3.I1.i1.p1.1.m1.3.3.2.2.1.cmml" xref="S3.I1.i1.p1.1.m1.3.3.2.2">superscript</csymbol><ci id="S3.I1.i1.p1.1.m1.3.3.2.2.2.cmml" xref="S3.I1.i1.p1.1.m1.3.3.2.2.2">𝑦</ci><ci id="S3.I1.i1.p1.1.m1.3.3.2.2.3.cmml" xref="S3.I1.i1.p1.1.m1.3.3.2.2.3">𝑙</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.1.m1.3c">(x,y^{w},y^{l})</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.1.m1.3d">( italic_x , italic_y start_POSTSUPERSCRIPT italic_w end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT )</annotation></semantics></math> is excluded from the dataset if <math alttext="\mathrm{C}(x,y^{w})-\mathrm{C}(x,y^{l})&lt;5.0" class="ltx_Math" display="inline" id="S3.I1.i1.p1.2.m2.4"><semantics id="S3.I1.i1.p1.2.m2.4a"><mrow id="S3.I1.i1.p1.2.m2.4.4" xref="S3.I1.i1.p1.2.m2.4.4.cmml"><mrow id="S3.I1.i1.p1.2.m2.4.4.2" xref="S3.I1.i1.p1.2.m2.4.4.2.cmml"><mrow id="S3.I1.i1.p1.2.m2.3.3.1.1" xref="S3.I1.i1.p1.2.m2.3.3.1.1.cmml"><mi id="S3.I1.i1.p1.2.m2.3.3.1.1.3" mathvariant="normal" xref="S3.I1.i1.p1.2.m2.3.3.1.1.3.cmml">C</mi><mo id="S3.I1.i1.p1.2.m2.3.3.1.1.2" xref="S3.I1.i1.p1.2.m2.3.3.1.1.2.cmml">⁢</mo><mrow id="S3.I1.i1.p1.2.m2.3.3.1.1.1.1" xref="S3.I1.i1.p1.2.m2.3.3.1.1.1.2.cmml"><mo id="S3.I1.i1.p1.2.m2.3.3.1.1.1.1.2" stretchy="false" xref="S3.I1.i1.p1.2.m2.3.3.1.1.1.2.cmml">(</mo><mi id="S3.I1.i1.p1.2.m2.1.1" xref="S3.I1.i1.p1.2.m2.1.1.cmml">x</mi><mo id="S3.I1.i1.p1.2.m2.3.3.1.1.1.1.3" xref="S3.I1.i1.p1.2.m2.3.3.1.1.1.2.cmml">,</mo><msup id="S3.I1.i1.p1.2.m2.3.3.1.1.1.1.1" xref="S3.I1.i1.p1.2.m2.3.3.1.1.1.1.1.cmml"><mi id="S3.I1.i1.p1.2.m2.3.3.1.1.1.1.1.2" xref="S3.I1.i1.p1.2.m2.3.3.1.1.1.1.1.2.cmml">y</mi><mi id="S3.I1.i1.p1.2.m2.3.3.1.1.1.1.1.3" xref="S3.I1.i1.p1.2.m2.3.3.1.1.1.1.1.3.cmml">w</mi></msup><mo id="S3.I1.i1.p1.2.m2.3.3.1.1.1.1.4" stretchy="false" xref="S3.I1.i1.p1.2.m2.3.3.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.I1.i1.p1.2.m2.4.4.2.3" xref="S3.I1.i1.p1.2.m2.4.4.2.3.cmml">−</mo><mrow id="S3.I1.i1.p1.2.m2.4.4.2.2" xref="S3.I1.i1.p1.2.m2.4.4.2.2.cmml"><mi id="S3.I1.i1.p1.2.m2.4.4.2.2.3" mathvariant="normal" xref="S3.I1.i1.p1.2.m2.4.4.2.2.3.cmml">C</mi><mo id="S3.I1.i1.p1.2.m2.4.4.2.2.2" xref="S3.I1.i1.p1.2.m2.4.4.2.2.2.cmml">⁢</mo><mrow id="S3.I1.i1.p1.2.m2.4.4.2.2.1.1" xref="S3.I1.i1.p1.2.m2.4.4.2.2.1.2.cmml"><mo id="S3.I1.i1.p1.2.m2.4.4.2.2.1.1.2" stretchy="false" xref="S3.I1.i1.p1.2.m2.4.4.2.2.1.2.cmml">(</mo><mi id="S3.I1.i1.p1.2.m2.2.2" xref="S3.I1.i1.p1.2.m2.2.2.cmml">x</mi><mo id="S3.I1.i1.p1.2.m2.4.4.2.2.1.1.3" xref="S3.I1.i1.p1.2.m2.4.4.2.2.1.2.cmml">,</mo><msup id="S3.I1.i1.p1.2.m2.4.4.2.2.1.1.1" xref="S3.I1.i1.p1.2.m2.4.4.2.2.1.1.1.cmml"><mi id="S3.I1.i1.p1.2.m2.4.4.2.2.1.1.1.2" xref="S3.I1.i1.p1.2.m2.4.4.2.2.1.1.1.2.cmml">y</mi><mi id="S3.I1.i1.p1.2.m2.4.4.2.2.1.1.1.3" xref="S3.I1.i1.p1.2.m2.4.4.2.2.1.1.1.3.cmml">l</mi></msup><mo id="S3.I1.i1.p1.2.m2.4.4.2.2.1.1.4" stretchy="false" xref="S3.I1.i1.p1.2.m2.4.4.2.2.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="S3.I1.i1.p1.2.m2.4.4.3" xref="S3.I1.i1.p1.2.m2.4.4.3.cmml">&lt;</mo><mn id="S3.I1.i1.p1.2.m2.4.4.4" xref="S3.I1.i1.p1.2.m2.4.4.4.cmml">5.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.2.m2.4b"><apply id="S3.I1.i1.p1.2.m2.4.4.cmml" xref="S3.I1.i1.p1.2.m2.4.4"><lt id="S3.I1.i1.p1.2.m2.4.4.3.cmml" xref="S3.I1.i1.p1.2.m2.4.4.3"></lt><apply id="S3.I1.i1.p1.2.m2.4.4.2.cmml" xref="S3.I1.i1.p1.2.m2.4.4.2"><minus id="S3.I1.i1.p1.2.m2.4.4.2.3.cmml" xref="S3.I1.i1.p1.2.m2.4.4.2.3"></minus><apply id="S3.I1.i1.p1.2.m2.3.3.1.1.cmml" xref="S3.I1.i1.p1.2.m2.3.3.1.1"><times id="S3.I1.i1.p1.2.m2.3.3.1.1.2.cmml" xref="S3.I1.i1.p1.2.m2.3.3.1.1.2"></times><ci id="S3.I1.i1.p1.2.m2.3.3.1.1.3.cmml" xref="S3.I1.i1.p1.2.m2.3.3.1.1.3">C</ci><interval closure="open" id="S3.I1.i1.p1.2.m2.3.3.1.1.1.2.cmml" xref="S3.I1.i1.p1.2.m2.3.3.1.1.1.1"><ci id="S3.I1.i1.p1.2.m2.1.1.cmml" xref="S3.I1.i1.p1.2.m2.1.1">𝑥</ci><apply id="S3.I1.i1.p1.2.m2.3.3.1.1.1.1.1.cmml" xref="S3.I1.i1.p1.2.m2.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.I1.i1.p1.2.m2.3.3.1.1.1.1.1.1.cmml" xref="S3.I1.i1.p1.2.m2.3.3.1.1.1.1.1">superscript</csymbol><ci id="S3.I1.i1.p1.2.m2.3.3.1.1.1.1.1.2.cmml" xref="S3.I1.i1.p1.2.m2.3.3.1.1.1.1.1.2">𝑦</ci><ci id="S3.I1.i1.p1.2.m2.3.3.1.1.1.1.1.3.cmml" xref="S3.I1.i1.p1.2.m2.3.3.1.1.1.1.1.3">𝑤</ci></apply></interval></apply><apply id="S3.I1.i1.p1.2.m2.4.4.2.2.cmml" xref="S3.I1.i1.p1.2.m2.4.4.2.2"><times id="S3.I1.i1.p1.2.m2.4.4.2.2.2.cmml" xref="S3.I1.i1.p1.2.m2.4.4.2.2.2"></times><ci id="S3.I1.i1.p1.2.m2.4.4.2.2.3.cmml" xref="S3.I1.i1.p1.2.m2.4.4.2.2.3">C</ci><interval closure="open" id="S3.I1.i1.p1.2.m2.4.4.2.2.1.2.cmml" xref="S3.I1.i1.p1.2.m2.4.4.2.2.1.1"><ci id="S3.I1.i1.p1.2.m2.2.2.cmml" xref="S3.I1.i1.p1.2.m2.2.2">𝑥</ci><apply id="S3.I1.i1.p1.2.m2.4.4.2.2.1.1.1.cmml" xref="S3.I1.i1.p1.2.m2.4.4.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.I1.i1.p1.2.m2.4.4.2.2.1.1.1.1.cmml" xref="S3.I1.i1.p1.2.m2.4.4.2.2.1.1.1">superscript</csymbol><ci id="S3.I1.i1.p1.2.m2.4.4.2.2.1.1.1.2.cmml" xref="S3.I1.i1.p1.2.m2.4.4.2.2.1.1.1.2">𝑦</ci><ci id="S3.I1.i1.p1.2.m2.4.4.2.2.1.1.1.3.cmml" xref="S3.I1.i1.p1.2.m2.4.4.2.2.1.1.1.3">𝑙</ci></apply></interval></apply></apply><cn id="S3.I1.i1.p1.2.m2.4.4.4.cmml" type="float" xref="S3.I1.i1.p1.2.m2.4.4.4">5.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.2.m2.4c">\mathrm{C}(x,y^{w})-\mathrm{C}(x,y^{l})&lt;5.0</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.2.m2.4d">roman_C ( italic_x , italic_y start_POSTSUPERSCRIPT italic_w end_POSTSUPERSCRIPT ) - roman_C ( italic_x , italic_y start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT ) &lt; 5.0</annotation></semantics></math>.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.4">Remove the instance where the chosen and rejected translations are too semantically similar. Sentence embedding is a widely used technique to calculate pairwise sentence similarity with low computation cost <cite class="ltx_cite ltx_citemacro_cite">Gao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib17" title="">2021</a>); Wu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib39" title="">2022</a>); Zhao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib45" title="">2024</a>)</cite>.
<span class="ltx_text ltx_font_typewriter" id="S3.I1.i2.p1.4.1">LaBSE</span> <cite class="ltx_cite ltx_citemacro_cite">Feng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib16" title="">2022</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/sentence-transformers/LaBSE" title="">https://huggingface.co/sentence-transformers/LaBSE</a></span></span></span> is used in our experiments. We notate it as <math alttext="\mathrm{LB}(\cdot)" class="ltx_Math" display="inline" id="S3.I1.i2.p1.1.m1.1"><semantics id="S3.I1.i2.p1.1.m1.1a"><mrow id="S3.I1.i2.p1.1.m1.1.2" xref="S3.I1.i2.p1.1.m1.1.2.cmml"><mi id="S3.I1.i2.p1.1.m1.1.2.2" xref="S3.I1.i2.p1.1.m1.1.2.2.cmml">LB</mi><mo id="S3.I1.i2.p1.1.m1.1.2.1" xref="S3.I1.i2.p1.1.m1.1.2.1.cmml">⁢</mo><mrow id="S3.I1.i2.p1.1.m1.1.2.3.2" xref="S3.I1.i2.p1.1.m1.1.2.cmml"><mo id="S3.I1.i2.p1.1.m1.1.2.3.2.1" stretchy="false" xref="S3.I1.i2.p1.1.m1.1.2.cmml">(</mo><mo id="S3.I1.i2.p1.1.m1.1.1" lspace="0em" rspace="0em" xref="S3.I1.i2.p1.1.m1.1.1.cmml">⋅</mo><mo id="S3.I1.i2.p1.1.m1.1.2.3.2.2" stretchy="false" xref="S3.I1.i2.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.1.m1.1b"><apply id="S3.I1.i2.p1.1.m1.1.2.cmml" xref="S3.I1.i2.p1.1.m1.1.2"><times id="S3.I1.i2.p1.1.m1.1.2.1.cmml" xref="S3.I1.i2.p1.1.m1.1.2.1"></times><ci id="S3.I1.i2.p1.1.m1.1.2.2.cmml" xref="S3.I1.i2.p1.1.m1.1.2.2">LB</ci><ci id="S3.I1.i2.p1.1.m1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.1.m1.1c">\mathrm{LB}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.1.m1.1d">roman_LB ( ⋅ )</annotation></semantics></math>. The similarity threshold is empirically set as 0.9, i.e. <math alttext="(x,y^{w},y^{l})" class="ltx_Math" display="inline" id="S3.I1.i2.p1.2.m2.3"><semantics id="S3.I1.i2.p1.2.m2.3a"><mrow id="S3.I1.i2.p1.2.m2.3.3.2" xref="S3.I1.i2.p1.2.m2.3.3.3.cmml"><mo id="S3.I1.i2.p1.2.m2.3.3.2.3" stretchy="false" xref="S3.I1.i2.p1.2.m2.3.3.3.cmml">(</mo><mi id="S3.I1.i2.p1.2.m2.1.1" xref="S3.I1.i2.p1.2.m2.1.1.cmml">x</mi><mo id="S3.I1.i2.p1.2.m2.3.3.2.4" xref="S3.I1.i2.p1.2.m2.3.3.3.cmml">,</mo><msup id="S3.I1.i2.p1.2.m2.2.2.1.1" xref="S3.I1.i2.p1.2.m2.2.2.1.1.cmml"><mi id="S3.I1.i2.p1.2.m2.2.2.1.1.2" xref="S3.I1.i2.p1.2.m2.2.2.1.1.2.cmml">y</mi><mi id="S3.I1.i2.p1.2.m2.2.2.1.1.3" xref="S3.I1.i2.p1.2.m2.2.2.1.1.3.cmml">w</mi></msup><mo id="S3.I1.i2.p1.2.m2.3.3.2.5" xref="S3.I1.i2.p1.2.m2.3.3.3.cmml">,</mo><msup id="S3.I1.i2.p1.2.m2.3.3.2.2" xref="S3.I1.i2.p1.2.m2.3.3.2.2.cmml"><mi id="S3.I1.i2.p1.2.m2.3.3.2.2.2" xref="S3.I1.i2.p1.2.m2.3.3.2.2.2.cmml">y</mi><mi id="S3.I1.i2.p1.2.m2.3.3.2.2.3" xref="S3.I1.i2.p1.2.m2.3.3.2.2.3.cmml">l</mi></msup><mo id="S3.I1.i2.p1.2.m2.3.3.2.6" stretchy="false" xref="S3.I1.i2.p1.2.m2.3.3.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.2.m2.3b"><vector id="S3.I1.i2.p1.2.m2.3.3.3.cmml" xref="S3.I1.i2.p1.2.m2.3.3.2"><ci id="S3.I1.i2.p1.2.m2.1.1.cmml" xref="S3.I1.i2.p1.2.m2.1.1">𝑥</ci><apply id="S3.I1.i2.p1.2.m2.2.2.1.1.cmml" xref="S3.I1.i2.p1.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S3.I1.i2.p1.2.m2.2.2.1.1.1.cmml" xref="S3.I1.i2.p1.2.m2.2.2.1.1">superscript</csymbol><ci id="S3.I1.i2.p1.2.m2.2.2.1.1.2.cmml" xref="S3.I1.i2.p1.2.m2.2.2.1.1.2">𝑦</ci><ci id="S3.I1.i2.p1.2.m2.2.2.1.1.3.cmml" xref="S3.I1.i2.p1.2.m2.2.2.1.1.3">𝑤</ci></apply><apply id="S3.I1.i2.p1.2.m2.3.3.2.2.cmml" xref="S3.I1.i2.p1.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S3.I1.i2.p1.2.m2.3.3.2.2.1.cmml" xref="S3.I1.i2.p1.2.m2.3.3.2.2">superscript</csymbol><ci id="S3.I1.i2.p1.2.m2.3.3.2.2.2.cmml" xref="S3.I1.i2.p1.2.m2.3.3.2.2.2">𝑦</ci><ci id="S3.I1.i2.p1.2.m2.3.3.2.2.3.cmml" xref="S3.I1.i2.p1.2.m2.3.3.2.2.3">𝑙</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.2.m2.3c">(x,y^{w},y^{l})</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.2.m2.3d">( italic_x , italic_y start_POSTSUPERSCRIPT italic_w end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT )</annotation></semantics></math> is excluded from the dataset if <math alttext="\mathrm{sim}(\mathrm{LB}(y^{w}),\mathrm{LB}(y^{w}))&gt;0.9" class="ltx_Math" display="inline" id="S3.I1.i2.p1.3.m3.2"><semantics id="S3.I1.i2.p1.3.m3.2a"><mrow id="S3.I1.i2.p1.3.m3.2.2" xref="S3.I1.i2.p1.3.m3.2.2.cmml"><mrow id="S3.I1.i2.p1.3.m3.2.2.2" xref="S3.I1.i2.p1.3.m3.2.2.2.cmml"><mi id="S3.I1.i2.p1.3.m3.2.2.2.4" xref="S3.I1.i2.p1.3.m3.2.2.2.4.cmml">sim</mi><mo id="S3.I1.i2.p1.3.m3.2.2.2.3" xref="S3.I1.i2.p1.3.m3.2.2.2.3.cmml">⁢</mo><mrow id="S3.I1.i2.p1.3.m3.2.2.2.2.2" xref="S3.I1.i2.p1.3.m3.2.2.2.2.3.cmml"><mo id="S3.I1.i2.p1.3.m3.2.2.2.2.2.3" stretchy="false" xref="S3.I1.i2.p1.3.m3.2.2.2.2.3.cmml">(</mo><mrow id="S3.I1.i2.p1.3.m3.1.1.1.1.1.1" xref="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.cmml"><mi id="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.3" xref="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.3.cmml">LB</mi><mo id="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.2" xref="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.1.1" xref="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.1.1.1.cmml">(</mo><msup id="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.1.1.1" xref="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.1.1.1.2" xref="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.1.1.1.2.cmml">y</mi><mi id="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.1.1.1.3" xref="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.1.1.1.3.cmml">w</mi></msup><mo id="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.I1.i2.p1.3.m3.2.2.2.2.2.4" xref="S3.I1.i2.p1.3.m3.2.2.2.2.3.cmml">,</mo><mrow id="S3.I1.i2.p1.3.m3.2.2.2.2.2.2" xref="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.cmml"><mi id="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.3" xref="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.3.cmml">LB</mi><mo id="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.2" xref="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.2.cmml">⁢</mo><mrow id="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.1.1" xref="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.1.1.1.cmml"><mo id="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.1.1.2" stretchy="false" xref="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.1.1.1.cmml">(</mo><msup id="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.1.1.1" xref="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.1.1.1.cmml"><mi id="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.1.1.1.2" xref="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.1.1.1.2.cmml">y</mi><mi id="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.1.1.1.3" xref="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.1.1.1.3.cmml">w</mi></msup><mo id="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.1.1.3" stretchy="false" xref="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.I1.i2.p1.3.m3.2.2.2.2.2.5" stretchy="false" xref="S3.I1.i2.p1.3.m3.2.2.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.I1.i2.p1.3.m3.2.2.3" xref="S3.I1.i2.p1.3.m3.2.2.3.cmml">&gt;</mo><mn id="S3.I1.i2.p1.3.m3.2.2.4" xref="S3.I1.i2.p1.3.m3.2.2.4.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.3.m3.2b"><apply id="S3.I1.i2.p1.3.m3.2.2.cmml" xref="S3.I1.i2.p1.3.m3.2.2"><gt id="S3.I1.i2.p1.3.m3.2.2.3.cmml" xref="S3.I1.i2.p1.3.m3.2.2.3"></gt><apply id="S3.I1.i2.p1.3.m3.2.2.2.cmml" xref="S3.I1.i2.p1.3.m3.2.2.2"><times id="S3.I1.i2.p1.3.m3.2.2.2.3.cmml" xref="S3.I1.i2.p1.3.m3.2.2.2.3"></times><ci id="S3.I1.i2.p1.3.m3.2.2.2.4.cmml" xref="S3.I1.i2.p1.3.m3.2.2.2.4">sim</ci><interval closure="open" id="S3.I1.i2.p1.3.m3.2.2.2.2.3.cmml" xref="S3.I1.i2.p1.3.m3.2.2.2.2.2"><apply id="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.cmml" xref="S3.I1.i2.p1.3.m3.1.1.1.1.1.1"><times id="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.2.cmml" xref="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.2"></times><ci id="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.3.cmml" xref="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.3">LB</ci><apply id="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.1.1.1.cmml" xref="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.1.1.1.2">𝑦</ci><ci id="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.I1.i2.p1.3.m3.1.1.1.1.1.1.1.1.1.3">𝑤</ci></apply></apply><apply id="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.cmml" xref="S3.I1.i2.p1.3.m3.2.2.2.2.2.2"><times id="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.2.cmml" xref="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.2"></times><ci id="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.3.cmml" xref="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.3">LB</ci><apply id="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.1.1.1.cmml" xref="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.1.1.1.1.cmml" xref="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.1.1">superscript</csymbol><ci id="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.1.1.1.2.cmml" xref="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.1.1.1.2">𝑦</ci><ci id="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.1.1.1.3.cmml" xref="S3.I1.i2.p1.3.m3.2.2.2.2.2.2.1.1.1.3">𝑤</ci></apply></apply></interval></apply><cn id="S3.I1.i2.p1.3.m3.2.2.4.cmml" type="float" xref="S3.I1.i2.p1.3.m3.2.2.4">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.3.m3.2c">\mathrm{sim}(\mathrm{LB}(y^{w}),\mathrm{LB}(y^{w}))&gt;0.9</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.3.m3.2d">roman_sim ( roman_LB ( italic_y start_POSTSUPERSCRIPT italic_w end_POSTSUPERSCRIPT ) , roman_LB ( italic_y start_POSTSUPERSCRIPT italic_w end_POSTSUPERSCRIPT ) ) &gt; 0.9</annotation></semantics></math>, where <math alttext="\mathrm{sim}(\cdot,\cdot)\in[0.0,1.0]" class="ltx_Math" display="inline" id="S3.I1.i2.p1.4.m4.4"><semantics id="S3.I1.i2.p1.4.m4.4a"><mrow id="S3.I1.i2.p1.4.m4.4.5" xref="S3.I1.i2.p1.4.m4.4.5.cmml"><mrow id="S3.I1.i2.p1.4.m4.4.5.2" xref="S3.I1.i2.p1.4.m4.4.5.2.cmml"><mi id="S3.I1.i2.p1.4.m4.4.5.2.2" xref="S3.I1.i2.p1.4.m4.4.5.2.2.cmml">sim</mi><mo id="S3.I1.i2.p1.4.m4.4.5.2.1" xref="S3.I1.i2.p1.4.m4.4.5.2.1.cmml">⁢</mo><mrow id="S3.I1.i2.p1.4.m4.4.5.2.3.2" xref="S3.I1.i2.p1.4.m4.4.5.2.3.1.cmml"><mo id="S3.I1.i2.p1.4.m4.4.5.2.3.2.1" stretchy="false" xref="S3.I1.i2.p1.4.m4.4.5.2.3.1.cmml">(</mo><mo id="S3.I1.i2.p1.4.m4.1.1" lspace="0em" rspace="0em" xref="S3.I1.i2.p1.4.m4.1.1.cmml">⋅</mo><mo id="S3.I1.i2.p1.4.m4.4.5.2.3.2.2" rspace="0em" xref="S3.I1.i2.p1.4.m4.4.5.2.3.1.cmml">,</mo><mo id="S3.I1.i2.p1.4.m4.2.2" lspace="0em" rspace="0em" xref="S3.I1.i2.p1.4.m4.2.2.cmml">⋅</mo><mo id="S3.I1.i2.p1.4.m4.4.5.2.3.2.3" stretchy="false" xref="S3.I1.i2.p1.4.m4.4.5.2.3.1.cmml">)</mo></mrow></mrow><mo id="S3.I1.i2.p1.4.m4.4.5.1" xref="S3.I1.i2.p1.4.m4.4.5.1.cmml">∈</mo><mrow id="S3.I1.i2.p1.4.m4.4.5.3.2" xref="S3.I1.i2.p1.4.m4.4.5.3.1.cmml"><mo id="S3.I1.i2.p1.4.m4.4.5.3.2.1" stretchy="false" xref="S3.I1.i2.p1.4.m4.4.5.3.1.cmml">[</mo><mn id="S3.I1.i2.p1.4.m4.3.3" xref="S3.I1.i2.p1.4.m4.3.3.cmml">0.0</mn><mo id="S3.I1.i2.p1.4.m4.4.5.3.2.2" xref="S3.I1.i2.p1.4.m4.4.5.3.1.cmml">,</mo><mn id="S3.I1.i2.p1.4.m4.4.4" xref="S3.I1.i2.p1.4.m4.4.4.cmml">1.0</mn><mo id="S3.I1.i2.p1.4.m4.4.5.3.2.3" stretchy="false" xref="S3.I1.i2.p1.4.m4.4.5.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.4.m4.4b"><apply id="S3.I1.i2.p1.4.m4.4.5.cmml" xref="S3.I1.i2.p1.4.m4.4.5"><in id="S3.I1.i2.p1.4.m4.4.5.1.cmml" xref="S3.I1.i2.p1.4.m4.4.5.1"></in><apply id="S3.I1.i2.p1.4.m4.4.5.2.cmml" xref="S3.I1.i2.p1.4.m4.4.5.2"><times id="S3.I1.i2.p1.4.m4.4.5.2.1.cmml" xref="S3.I1.i2.p1.4.m4.4.5.2.1"></times><ci id="S3.I1.i2.p1.4.m4.4.5.2.2.cmml" xref="S3.I1.i2.p1.4.m4.4.5.2.2">sim</ci><interval closure="open" id="S3.I1.i2.p1.4.m4.4.5.2.3.1.cmml" xref="S3.I1.i2.p1.4.m4.4.5.2.3.2"><ci id="S3.I1.i2.p1.4.m4.1.1.cmml" xref="S3.I1.i2.p1.4.m4.1.1">⋅</ci><ci id="S3.I1.i2.p1.4.m4.2.2.cmml" xref="S3.I1.i2.p1.4.m4.2.2">⋅</ci></interval></apply><interval closure="closed" id="S3.I1.i2.p1.4.m4.4.5.3.1.cmml" xref="S3.I1.i2.p1.4.m4.4.5.3.2"><cn id="S3.I1.i2.p1.4.m4.3.3.cmml" type="float" xref="S3.I1.i2.p1.4.m4.3.3">0.0</cn><cn id="S3.I1.i2.p1.4.m4.4.4.cmml" type="float" xref="S3.I1.i2.p1.4.m4.4.4">1.0</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.4.m4.4c">\mathrm{sim}(\cdot,\cdot)\in[0.0,1.0]</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.4.m4.4d">roman_sim ( ⋅ , ⋅ ) ∈ [ 0.0 , 1.0 ]</annotation></semantics></math> is cosine similarity.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1">One possible failure case for word alignment is when the MT models directly copy the original texts, which is bad translation, but gets a high alignment score because the wrong translation is partially the same with the original texts. To remove this part of the noise, we calculate the BLEU score <cite class="ltx_cite ltx_citemacro_cite">Papineni et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib28" title="">2002</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/mjpost/sacrebleu" title="">https://github.com/mjpost/sacrebleu</a></span></span></span> for the chosen translation and exclude it if the BLEU score <math alttext="&gt;20.0" class="ltx_Math" display="inline" id="S3.I1.i3.p1.1.m1.1"><semantics id="S3.I1.i3.p1.1.m1.1a"><mrow id="S3.I1.i3.p1.1.m1.1.1" xref="S3.I1.i3.p1.1.m1.1.1.cmml"><mi id="S3.I1.i3.p1.1.m1.1.1.2" xref="S3.I1.i3.p1.1.m1.1.1.2.cmml"></mi><mo id="S3.I1.i3.p1.1.m1.1.1.1" xref="S3.I1.i3.p1.1.m1.1.1.1.cmml">&gt;</mo><mn id="S3.I1.i3.p1.1.m1.1.1.3" xref="S3.I1.i3.p1.1.m1.1.1.3.cmml">20.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.1.m1.1b"><apply id="S3.I1.i3.p1.1.m1.1.1.cmml" xref="S3.I1.i3.p1.1.m1.1.1"><gt id="S3.I1.i3.p1.1.m1.1.1.1.cmml" xref="S3.I1.i3.p1.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S3.I1.i3.p1.1.m1.1.1.2.cmml" xref="S3.I1.i3.p1.1.m1.1.1.2">absent</csymbol><cn id="S3.I1.i3.p1.1.m1.1.1.3.cmml" type="float" xref="S3.I1.i3.p1.1.m1.1.1.3">20.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.p1.1.m1.1c">&gt;20.0</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.p1.1.m1.1d">&gt; 20.0</annotation></semantics></math>.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Details of dataset</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S3.F4" title="Figure 4 ‣ 3.4 Details of dataset ‣ 3 Proposed approach ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">4</span></a> presents the varying proportions of “chosen” and “rejected” preference pairs from three sources: ChatGPT, DeepL, and Human. The figure indicates that the majority of the “chosen” translations originate from ChatGPT, while a significant portion of human-written translations are “rejected”. This observation supports the conclusion that human-written translations can also exhibit quality issues, as discussed in ALMA-R <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib42" title="">2024b</a>)</cite>. Examples in our constructed preference dataset are presented in §<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#A1.SS1" title="A.1 Examples of the preference dataset ‣ Appendix A Example analysis ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">A.1</span></a>.</p>
</div>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="599" id="S3.F4.g1" src="x5.png" width="746"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>This figure illustrates the proportions of “chosen” and “rejected” preference pairs derived from three sources: ChatGPT, DeepL and Human. “all” represents the overall proportion for the aggregated dataset. <math alttext="xx\leftrightarrow en" class="ltx_Math" display="inline" id="S3.F4.3.m1.1"><semantics id="S3.F4.3.m1.1b"><mrow id="S3.F4.3.m1.1.1" xref="S3.F4.3.m1.1.1.cmml"><mrow id="S3.F4.3.m1.1.1.2" xref="S3.F4.3.m1.1.1.2.cmml"><mi id="S3.F4.3.m1.1.1.2.2" xref="S3.F4.3.m1.1.1.2.2.cmml">x</mi><mo id="S3.F4.3.m1.1.1.2.1" xref="S3.F4.3.m1.1.1.2.1.cmml">⁢</mo><mi id="S3.F4.3.m1.1.1.2.3" xref="S3.F4.3.m1.1.1.2.3.cmml">x</mi></mrow><mo id="S3.F4.3.m1.1.1.1" stretchy="false" xref="S3.F4.3.m1.1.1.1.cmml">↔</mo><mrow id="S3.F4.3.m1.1.1.3" xref="S3.F4.3.m1.1.1.3.cmml"><mi id="S3.F4.3.m1.1.1.3.2" xref="S3.F4.3.m1.1.1.3.2.cmml">e</mi><mo id="S3.F4.3.m1.1.1.3.1" xref="S3.F4.3.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.F4.3.m1.1.1.3.3" xref="S3.F4.3.m1.1.1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F4.3.m1.1c"><apply id="S3.F4.3.m1.1.1.cmml" xref="S3.F4.3.m1.1.1"><ci id="S3.F4.3.m1.1.1.1.cmml" xref="S3.F4.3.m1.1.1.1">↔</ci><apply id="S3.F4.3.m1.1.1.2.cmml" xref="S3.F4.3.m1.1.1.2"><times id="S3.F4.3.m1.1.1.2.1.cmml" xref="S3.F4.3.m1.1.1.2.1"></times><ci id="S3.F4.3.m1.1.1.2.2.cmml" xref="S3.F4.3.m1.1.1.2.2">𝑥</ci><ci id="S3.F4.3.m1.1.1.2.3.cmml" xref="S3.F4.3.m1.1.1.2.3">𝑥</ci></apply><apply id="S3.F4.3.m1.1.1.3.cmml" xref="S3.F4.3.m1.1.1.3"><times id="S3.F4.3.m1.1.1.3.1.cmml" xref="S3.F4.3.m1.1.1.3.1"></times><ci id="S3.F4.3.m1.1.1.3.2.cmml" xref="S3.F4.3.m1.1.1.3.2">𝑒</ci><ci id="S3.F4.3.m1.1.1.3.3.cmml" xref="S3.F4.3.m1.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.3.m1.1d">xx\leftrightarrow en</annotation><annotation encoding="application/x-llamapun" id="S3.F4.3.m1.1e">italic_x italic_x ↔ italic_e italic_n</annotation></semantics></math> is the subset pair of English and another language. Particularly, Google Translate is used for <math alttext="is\leftrightarrow en" class="ltx_Math" display="inline" id="S3.F4.4.m2.1"><semantics id="S3.F4.4.m2.1b"><mrow id="S3.F4.4.m2.1.1" xref="S3.F4.4.m2.1.1.cmml"><mrow id="S3.F4.4.m2.1.1.2" xref="S3.F4.4.m2.1.1.2.cmml"><mi id="S3.F4.4.m2.1.1.2.2" xref="S3.F4.4.m2.1.1.2.2.cmml">i</mi><mo id="S3.F4.4.m2.1.1.2.1" xref="S3.F4.4.m2.1.1.2.1.cmml">⁢</mo><mi id="S3.F4.4.m2.1.1.2.3" xref="S3.F4.4.m2.1.1.2.3.cmml">s</mi></mrow><mo id="S3.F4.4.m2.1.1.1" stretchy="false" xref="S3.F4.4.m2.1.1.1.cmml">↔</mo><mrow id="S3.F4.4.m2.1.1.3" xref="S3.F4.4.m2.1.1.3.cmml"><mi id="S3.F4.4.m2.1.1.3.2" xref="S3.F4.4.m2.1.1.3.2.cmml">e</mi><mo id="S3.F4.4.m2.1.1.3.1" xref="S3.F4.4.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.F4.4.m2.1.1.3.3" xref="S3.F4.4.m2.1.1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F4.4.m2.1c"><apply id="S3.F4.4.m2.1.1.cmml" xref="S3.F4.4.m2.1.1"><ci id="S3.F4.4.m2.1.1.1.cmml" xref="S3.F4.4.m2.1.1.1">↔</ci><apply id="S3.F4.4.m2.1.1.2.cmml" xref="S3.F4.4.m2.1.1.2"><times id="S3.F4.4.m2.1.1.2.1.cmml" xref="S3.F4.4.m2.1.1.2.1"></times><ci id="S3.F4.4.m2.1.1.2.2.cmml" xref="S3.F4.4.m2.1.1.2.2">𝑖</ci><ci id="S3.F4.4.m2.1.1.2.3.cmml" xref="S3.F4.4.m2.1.1.2.3">𝑠</ci></apply><apply id="S3.F4.4.m2.1.1.3.cmml" xref="S3.F4.4.m2.1.1.3"><times id="S3.F4.4.m2.1.1.3.1.cmml" xref="S3.F4.4.m2.1.1.3.1"></times><ci id="S3.F4.4.m2.1.1.3.2.cmml" xref="S3.F4.4.m2.1.1.3.2">𝑒</ci><ci id="S3.F4.4.m2.1.1.3.3.cmml" xref="S3.F4.4.m2.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.4.m2.1d">is\leftrightarrow en</annotation><annotation encoding="application/x-llamapun" id="S3.F4.4.m2.1e">italic_i italic_s ↔ italic_e italic_n</annotation></semantics></math> as an alternative to DeepL.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Optimization LLM-based MT model</h3>
<div class="ltx_para" id="S3.SS5.p1">
<p class="ltx_p" id="S3.SS5.p1.1">The final step is to optimize the LLM-based MT model on our preference data. Direct preference optimization (DPO) <cite class="ltx_cite ltx_citemacro_citep">(Rafailov et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib30" title="">2024</a>)</cite> is a simple but effective approach that directly optimizes the preference model on a pre-constructed static dataset. DPO has been applied to optimize LLM in preference data <cite class="ltx_cite ltx_citemacro_citep">(Tunstall et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib34" title="">2023</a>; Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib42" title="">2024b</a>)</cite> recently. We also utilize DPO as an optimization approach. Formally, the training objective is as follows,</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="l=-\log\sigma(\beta\log\frac{\pi(y^{w}|x)}{\pi_{ref}(y^{w}|x)}-\beta\log\frac{%
\pi(y^{l}|x)}{\pi_{ref}(y^{l}|x)})" class="ltx_Math" display="block" id="S3.E2.m1.5"><semantics id="S3.E2.m1.5a"><mrow id="S3.E2.m1.5.5" xref="S3.E2.m1.5.5.cmml"><mi id="S3.E2.m1.5.5.3" xref="S3.E2.m1.5.5.3.cmml">l</mi><mo id="S3.E2.m1.5.5.2" xref="S3.E2.m1.5.5.2.cmml">=</mo><mrow id="S3.E2.m1.5.5.1" xref="S3.E2.m1.5.5.1.cmml"><mo id="S3.E2.m1.5.5.1a" rspace="0.167em" xref="S3.E2.m1.5.5.1.cmml">−</mo><mrow id="S3.E2.m1.5.5.1.1" xref="S3.E2.m1.5.5.1.1.cmml"><mrow id="S3.E2.m1.5.5.1.1.3" xref="S3.E2.m1.5.5.1.1.3.cmml"><mi id="S3.E2.m1.5.5.1.1.3.1" xref="S3.E2.m1.5.5.1.1.3.1.cmml">log</mi><mo id="S3.E2.m1.5.5.1.1.3a" lspace="0.167em" xref="S3.E2.m1.5.5.1.1.3.cmml">⁡</mo><mi id="S3.E2.m1.5.5.1.1.3.2" xref="S3.E2.m1.5.5.1.1.3.2.cmml">σ</mi></mrow><mo id="S3.E2.m1.5.5.1.1.2" xref="S3.E2.m1.5.5.1.1.2.cmml">⁢</mo><mrow id="S3.E2.m1.5.5.1.1.1.1" xref="S3.E2.m1.5.5.1.1.1.1.1.cmml"><mo id="S3.E2.m1.5.5.1.1.1.1.2" stretchy="false" xref="S3.E2.m1.5.5.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.5.5.1.1.1.1.1" xref="S3.E2.m1.5.5.1.1.1.1.1.cmml"><mrow id="S3.E2.m1.5.5.1.1.1.1.1.2" xref="S3.E2.m1.5.5.1.1.1.1.1.2.cmml"><mi id="S3.E2.m1.5.5.1.1.1.1.1.2.2" xref="S3.E2.m1.5.5.1.1.1.1.1.2.2.cmml">β</mi><mo id="S3.E2.m1.5.5.1.1.1.1.1.2.1" lspace="0.167em" xref="S3.E2.m1.5.5.1.1.1.1.1.2.1.cmml">⁢</mo><mrow id="S3.E2.m1.5.5.1.1.1.1.1.2.3" xref="S3.E2.m1.5.5.1.1.1.1.1.2.3.cmml"><mi id="S3.E2.m1.5.5.1.1.1.1.1.2.3.1" xref="S3.E2.m1.5.5.1.1.1.1.1.2.3.1.cmml">log</mi><mo id="S3.E2.m1.5.5.1.1.1.1.1.2.3a" lspace="0.167em" xref="S3.E2.m1.5.5.1.1.1.1.1.2.3.cmml">⁡</mo><mfrac id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml"><mrow id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.3" xref="S3.E2.m1.1.1.1.3.cmml">π</mi><mo id="S3.E2.m1.1.1.1.2" xref="S3.E2.m1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E2.m1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.1.1.1.1.1.2" stretchy="false" xref="S3.E2.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><msup id="S3.E2.m1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.2.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.2.2" xref="S3.E2.m1.1.1.1.1.1.1.2.2.cmml">y</mi><mi id="S3.E2.m1.1.1.1.1.1.1.2.3" xref="S3.E2.m1.1.1.1.1.1.1.2.3.cmml">w</mi></msup><mo fence="false" id="S3.E2.m1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml">|</mo><mi id="S3.E2.m1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.3.cmml">x</mi></mrow><mo id="S3.E2.m1.1.1.1.1.1.3" stretchy="false" xref="S3.E2.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mrow id="S3.E2.m1.2.2.2" xref="S3.E2.m1.2.2.2.cmml"><msub id="S3.E2.m1.2.2.2.3" xref="S3.E2.m1.2.2.2.3.cmml"><mi id="S3.E2.m1.2.2.2.3.2" xref="S3.E2.m1.2.2.2.3.2.cmml">π</mi><mrow id="S3.E2.m1.2.2.2.3.3" xref="S3.E2.m1.2.2.2.3.3.cmml"><mi id="S3.E2.m1.2.2.2.3.3.2" xref="S3.E2.m1.2.2.2.3.3.2.cmml">r</mi><mo id="S3.E2.m1.2.2.2.3.3.1" xref="S3.E2.m1.2.2.2.3.3.1.cmml">⁢</mo><mi id="S3.E2.m1.2.2.2.3.3.3" xref="S3.E2.m1.2.2.2.3.3.3.cmml">e</mi><mo id="S3.E2.m1.2.2.2.3.3.1a" xref="S3.E2.m1.2.2.2.3.3.1.cmml">⁢</mo><mi id="S3.E2.m1.2.2.2.3.3.4" xref="S3.E2.m1.2.2.2.3.3.4.cmml">f</mi></mrow></msub><mo id="S3.E2.m1.2.2.2.2" xref="S3.E2.m1.2.2.2.2.cmml">⁢</mo><mrow id="S3.E2.m1.2.2.2.1.1" xref="S3.E2.m1.2.2.2.1.1.1.cmml"><mo id="S3.E2.m1.2.2.2.1.1.2" stretchy="false" xref="S3.E2.m1.2.2.2.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.2.2.2.1.1.1" xref="S3.E2.m1.2.2.2.1.1.1.cmml"><msup id="S3.E2.m1.2.2.2.1.1.1.2" xref="S3.E2.m1.2.2.2.1.1.1.2.cmml"><mi id="S3.E2.m1.2.2.2.1.1.1.2.2" xref="S3.E2.m1.2.2.2.1.1.1.2.2.cmml">y</mi><mi id="S3.E2.m1.2.2.2.1.1.1.2.3" xref="S3.E2.m1.2.2.2.1.1.1.2.3.cmml">w</mi></msup><mo fence="false" id="S3.E2.m1.2.2.2.1.1.1.1" xref="S3.E2.m1.2.2.2.1.1.1.1.cmml">|</mo><mi id="S3.E2.m1.2.2.2.1.1.1.3" xref="S3.E2.m1.2.2.2.1.1.1.3.cmml">x</mi></mrow><mo id="S3.E2.m1.2.2.2.1.1.3" stretchy="false" xref="S3.E2.m1.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mfrac></mrow></mrow><mo id="S3.E2.m1.5.5.1.1.1.1.1.1" xref="S3.E2.m1.5.5.1.1.1.1.1.1.cmml">−</mo><mrow id="S3.E2.m1.5.5.1.1.1.1.1.3" xref="S3.E2.m1.5.5.1.1.1.1.1.3.cmml"><mi id="S3.E2.m1.5.5.1.1.1.1.1.3.2" xref="S3.E2.m1.5.5.1.1.1.1.1.3.2.cmml">β</mi><mo id="S3.E2.m1.5.5.1.1.1.1.1.3.1" lspace="0.167em" xref="S3.E2.m1.5.5.1.1.1.1.1.3.1.cmml">⁢</mo><mrow id="S3.E2.m1.5.5.1.1.1.1.1.3.3" xref="S3.E2.m1.5.5.1.1.1.1.1.3.3.cmml"><mi id="S3.E2.m1.5.5.1.1.1.1.1.3.3.1" xref="S3.E2.m1.5.5.1.1.1.1.1.3.3.1.cmml">log</mi><mo id="S3.E2.m1.5.5.1.1.1.1.1.3.3a" lspace="0.167em" xref="S3.E2.m1.5.5.1.1.1.1.1.3.3.cmml">⁡</mo><mfrac id="S3.E2.m1.4.4" xref="S3.E2.m1.4.4.cmml"><mrow id="S3.E2.m1.3.3.1" xref="S3.E2.m1.3.3.1.cmml"><mi id="S3.E2.m1.3.3.1.3" xref="S3.E2.m1.3.3.1.3.cmml">π</mi><mo id="S3.E2.m1.3.3.1.2" xref="S3.E2.m1.3.3.1.2.cmml">⁢</mo><mrow id="S3.E2.m1.3.3.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.cmml"><mo id="S3.E2.m1.3.3.1.1.1.2" stretchy="false" xref="S3.E2.m1.3.3.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.3.3.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.cmml"><msup id="S3.E2.m1.3.3.1.1.1.1.2" xref="S3.E2.m1.3.3.1.1.1.1.2.cmml"><mi id="S3.E2.m1.3.3.1.1.1.1.2.2" xref="S3.E2.m1.3.3.1.1.1.1.2.2.cmml">y</mi><mi id="S3.E2.m1.3.3.1.1.1.1.2.3" xref="S3.E2.m1.3.3.1.1.1.1.2.3.cmml">l</mi></msup><mo fence="false" id="S3.E2.m1.3.3.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.cmml">|</mo><mi id="S3.E2.m1.3.3.1.1.1.1.3" xref="S3.E2.m1.3.3.1.1.1.1.3.cmml">x</mi></mrow><mo id="S3.E2.m1.3.3.1.1.1.3" stretchy="false" xref="S3.E2.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow><mrow id="S3.E2.m1.4.4.2" xref="S3.E2.m1.4.4.2.cmml"><msub id="S3.E2.m1.4.4.2.3" xref="S3.E2.m1.4.4.2.3.cmml"><mi id="S3.E2.m1.4.4.2.3.2" xref="S3.E2.m1.4.4.2.3.2.cmml">π</mi><mrow id="S3.E2.m1.4.4.2.3.3" xref="S3.E2.m1.4.4.2.3.3.cmml"><mi id="S3.E2.m1.4.4.2.3.3.2" xref="S3.E2.m1.4.4.2.3.3.2.cmml">r</mi><mo id="S3.E2.m1.4.4.2.3.3.1" xref="S3.E2.m1.4.4.2.3.3.1.cmml">⁢</mo><mi id="S3.E2.m1.4.4.2.3.3.3" xref="S3.E2.m1.4.4.2.3.3.3.cmml">e</mi><mo id="S3.E2.m1.4.4.2.3.3.1a" xref="S3.E2.m1.4.4.2.3.3.1.cmml">⁢</mo><mi id="S3.E2.m1.4.4.2.3.3.4" xref="S3.E2.m1.4.4.2.3.3.4.cmml">f</mi></mrow></msub><mo id="S3.E2.m1.4.4.2.2" xref="S3.E2.m1.4.4.2.2.cmml">⁢</mo><mrow id="S3.E2.m1.4.4.2.1.1" xref="S3.E2.m1.4.4.2.1.1.1.cmml"><mo id="S3.E2.m1.4.4.2.1.1.2" stretchy="false" xref="S3.E2.m1.4.4.2.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.4.4.2.1.1.1" xref="S3.E2.m1.4.4.2.1.1.1.cmml"><msup id="S3.E2.m1.4.4.2.1.1.1.2" xref="S3.E2.m1.4.4.2.1.1.1.2.cmml"><mi id="S3.E2.m1.4.4.2.1.1.1.2.2" xref="S3.E2.m1.4.4.2.1.1.1.2.2.cmml">y</mi><mi id="S3.E2.m1.4.4.2.1.1.1.2.3" xref="S3.E2.m1.4.4.2.1.1.1.2.3.cmml">l</mi></msup><mo fence="false" id="S3.E2.m1.4.4.2.1.1.1.1" xref="S3.E2.m1.4.4.2.1.1.1.1.cmml">|</mo><mi id="S3.E2.m1.4.4.2.1.1.1.3" xref="S3.E2.m1.4.4.2.1.1.1.3.cmml">x</mi></mrow><mo id="S3.E2.m1.4.4.2.1.1.3" stretchy="false" xref="S3.E2.m1.4.4.2.1.1.1.cmml">)</mo></mrow></mrow></mfrac></mrow></mrow></mrow><mo id="S3.E2.m1.5.5.1.1.1.1.3" stretchy="false" xref="S3.E2.m1.5.5.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.5b"><apply id="S3.E2.m1.5.5.cmml" xref="S3.E2.m1.5.5"><eq id="S3.E2.m1.5.5.2.cmml" xref="S3.E2.m1.5.5.2"></eq><ci id="S3.E2.m1.5.5.3.cmml" xref="S3.E2.m1.5.5.3">𝑙</ci><apply id="S3.E2.m1.5.5.1.cmml" xref="S3.E2.m1.5.5.1"><minus id="S3.E2.m1.5.5.1.2.cmml" xref="S3.E2.m1.5.5.1"></minus><apply id="S3.E2.m1.5.5.1.1.cmml" xref="S3.E2.m1.5.5.1.1"><times id="S3.E2.m1.5.5.1.1.2.cmml" xref="S3.E2.m1.5.5.1.1.2"></times><apply id="S3.E2.m1.5.5.1.1.3.cmml" xref="S3.E2.m1.5.5.1.1.3"><log id="S3.E2.m1.5.5.1.1.3.1.cmml" xref="S3.E2.m1.5.5.1.1.3.1"></log><ci id="S3.E2.m1.5.5.1.1.3.2.cmml" xref="S3.E2.m1.5.5.1.1.3.2">𝜎</ci></apply><apply id="S3.E2.m1.5.5.1.1.1.1.1.cmml" xref="S3.E2.m1.5.5.1.1.1.1"><minus id="S3.E2.m1.5.5.1.1.1.1.1.1.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.1"></minus><apply id="S3.E2.m1.5.5.1.1.1.1.1.2.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.2"><times id="S3.E2.m1.5.5.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.2.1"></times><ci id="S3.E2.m1.5.5.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.2.2">𝛽</ci><apply id="S3.E2.m1.5.5.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.2.3"><log id="S3.E2.m1.5.5.1.1.1.1.1.2.3.1.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.2.3.1"></log><apply id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2"><divide id="S3.E2.m1.2.2.3.cmml" xref="S3.E2.m1.2.2"></divide><apply id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"><times id="S3.E2.m1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.2"></times><ci id="S3.E2.m1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.3">𝜋</ci><apply id="S3.E2.m1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E2.m1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S3.E2.m1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2">superscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2">𝑦</ci><ci id="S3.E2.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.3">𝑤</ci></apply><ci id="S3.E2.m1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3">𝑥</ci></apply></apply><apply id="S3.E2.m1.2.2.2.cmml" xref="S3.E2.m1.2.2.2"><times id="S3.E2.m1.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2"></times><apply id="S3.E2.m1.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.3.1.cmml" xref="S3.E2.m1.2.2.2.3">subscript</csymbol><ci id="S3.E2.m1.2.2.2.3.2.cmml" xref="S3.E2.m1.2.2.2.3.2">𝜋</ci><apply id="S3.E2.m1.2.2.2.3.3.cmml" xref="S3.E2.m1.2.2.2.3.3"><times id="S3.E2.m1.2.2.2.3.3.1.cmml" xref="S3.E2.m1.2.2.2.3.3.1"></times><ci id="S3.E2.m1.2.2.2.3.3.2.cmml" xref="S3.E2.m1.2.2.2.3.3.2">𝑟</ci><ci id="S3.E2.m1.2.2.2.3.3.3.cmml" xref="S3.E2.m1.2.2.2.3.3.3">𝑒</ci><ci id="S3.E2.m1.2.2.2.3.3.4.cmml" xref="S3.E2.m1.2.2.2.3.3.4">𝑓</ci></apply></apply><apply id="S3.E2.m1.2.2.2.1.1.1.cmml" xref="S3.E2.m1.2.2.2.1.1"><csymbol cd="latexml" id="S3.E2.m1.2.2.2.1.1.1.1.cmml" xref="S3.E2.m1.2.2.2.1.1.1.1">conditional</csymbol><apply id="S3.E2.m1.2.2.2.1.1.1.2.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.1.1.1.2.1.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2">superscript</csymbol><ci id="S3.E2.m1.2.2.2.1.1.1.2.2.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2.2">𝑦</ci><ci id="S3.E2.m1.2.2.2.1.1.1.2.3.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2.3">𝑤</ci></apply><ci id="S3.E2.m1.2.2.2.1.1.1.3.cmml" xref="S3.E2.m1.2.2.2.1.1.1.3">𝑥</ci></apply></apply></apply></apply></apply><apply id="S3.E2.m1.5.5.1.1.1.1.1.3.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.3"><times id="S3.E2.m1.5.5.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.3.1"></times><ci id="S3.E2.m1.5.5.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.3.2">𝛽</ci><apply id="S3.E2.m1.5.5.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.3.3"><log id="S3.E2.m1.5.5.1.1.1.1.1.3.3.1.cmml" xref="S3.E2.m1.5.5.1.1.1.1.1.3.3.1"></log><apply id="S3.E2.m1.4.4.cmml" xref="S3.E2.m1.4.4"><divide id="S3.E2.m1.4.4.3.cmml" xref="S3.E2.m1.4.4"></divide><apply id="S3.E2.m1.3.3.1.cmml" xref="S3.E2.m1.3.3.1"><times id="S3.E2.m1.3.3.1.2.cmml" xref="S3.E2.m1.3.3.1.2"></times><ci id="S3.E2.m1.3.3.1.3.cmml" xref="S3.E2.m1.3.3.1.3">𝜋</ci><apply id="S3.E2.m1.3.3.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1"><csymbol cd="latexml" id="S3.E2.m1.3.3.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1">conditional</csymbol><apply id="S3.E2.m1.3.3.1.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.1.2.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.2">superscript</csymbol><ci id="S3.E2.m1.3.3.1.1.1.1.2.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.2.2">𝑦</ci><ci id="S3.E2.m1.3.3.1.1.1.1.2.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.2.3">𝑙</ci></apply><ci id="S3.E2.m1.3.3.1.1.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.3">𝑥</ci></apply></apply><apply id="S3.E2.m1.4.4.2.cmml" xref="S3.E2.m1.4.4.2"><times id="S3.E2.m1.4.4.2.2.cmml" xref="S3.E2.m1.4.4.2.2"></times><apply id="S3.E2.m1.4.4.2.3.cmml" xref="S3.E2.m1.4.4.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.2.3.1.cmml" xref="S3.E2.m1.4.4.2.3">subscript</csymbol><ci id="S3.E2.m1.4.4.2.3.2.cmml" xref="S3.E2.m1.4.4.2.3.2">𝜋</ci><apply id="S3.E2.m1.4.4.2.3.3.cmml" xref="S3.E2.m1.4.4.2.3.3"><times id="S3.E2.m1.4.4.2.3.3.1.cmml" xref="S3.E2.m1.4.4.2.3.3.1"></times><ci id="S3.E2.m1.4.4.2.3.3.2.cmml" xref="S3.E2.m1.4.4.2.3.3.2">𝑟</ci><ci id="S3.E2.m1.4.4.2.3.3.3.cmml" xref="S3.E2.m1.4.4.2.3.3.3">𝑒</ci><ci id="S3.E2.m1.4.4.2.3.3.4.cmml" xref="S3.E2.m1.4.4.2.3.3.4">𝑓</ci></apply></apply><apply id="S3.E2.m1.4.4.2.1.1.1.cmml" xref="S3.E2.m1.4.4.2.1.1"><csymbol cd="latexml" id="S3.E2.m1.4.4.2.1.1.1.1.cmml" xref="S3.E2.m1.4.4.2.1.1.1.1">conditional</csymbol><apply id="S3.E2.m1.4.4.2.1.1.1.2.cmml" xref="S3.E2.m1.4.4.2.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.2.1.1.1.2.1.cmml" xref="S3.E2.m1.4.4.2.1.1.1.2">superscript</csymbol><ci id="S3.E2.m1.4.4.2.1.1.1.2.2.cmml" xref="S3.E2.m1.4.4.2.1.1.1.2.2">𝑦</ci><ci id="S3.E2.m1.4.4.2.1.1.1.2.3.cmml" xref="S3.E2.m1.4.4.2.1.1.1.2.3">𝑙</ci></apply><ci id="S3.E2.m1.4.4.2.1.1.1.3.cmml" xref="S3.E2.m1.4.4.2.1.1.1.3">𝑥</ci></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.5c">l=-\log\sigma(\beta\log\frac{\pi(y^{w}|x)}{\pi_{ref}(y^{w}|x)}-\beta\log\frac{%
\pi(y^{l}|x)}{\pi_{ref}(y^{l}|x)})</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.5d">italic_l = - roman_log italic_σ ( italic_β roman_log divide start_ARG italic_π ( italic_y start_POSTSUPERSCRIPT italic_w end_POSTSUPERSCRIPT | italic_x ) end_ARG start_ARG italic_π start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT ( italic_y start_POSTSUPERSCRIPT italic_w end_POSTSUPERSCRIPT | italic_x ) end_ARG - italic_β roman_log divide start_ARG italic_π ( italic_y start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT | italic_x ) end_ARG start_ARG italic_π start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT ( italic_y start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT | italic_x ) end_ARG )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS5.p2">
<p class="ltx_p" id="S3.SS5.p2.6">where <math alttext="\sigma" class="ltx_Math" display="inline" id="S3.SS5.p2.1.m1.1"><semantics id="S3.SS5.p2.1.m1.1a"><mi id="S3.SS5.p2.1.m1.1.1" xref="S3.SS5.p2.1.m1.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.1.m1.1b"><ci id="S3.SS5.p2.1.m1.1.1.cmml" xref="S3.SS5.p2.1.m1.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.1.m1.1c">\sigma</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p2.1.m1.1d">italic_σ</annotation></semantics></math> is the sigmoid function, <math alttext="\pi" class="ltx_Math" display="inline" id="S3.SS5.p2.2.m2.1"><semantics id="S3.SS5.p2.2.m2.1a"><mi id="S3.SS5.p2.2.m2.1.1" xref="S3.SS5.p2.2.m2.1.1.cmml">π</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.2.m2.1b"><ci id="S3.SS5.p2.2.m2.1.1.cmml" xref="S3.SS5.p2.2.m2.1.1">𝜋</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.2.m2.1c">\pi</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p2.2.m2.1d">italic_π</annotation></semantics></math> is the model to optimize and <math alttext="\pi_{ref}" class="ltx_Math" display="inline" id="S3.SS5.p2.3.m3.1"><semantics id="S3.SS5.p2.3.m3.1a"><msub id="S3.SS5.p2.3.m3.1.1" xref="S3.SS5.p2.3.m3.1.1.cmml"><mi id="S3.SS5.p2.3.m3.1.1.2" xref="S3.SS5.p2.3.m3.1.1.2.cmml">π</mi><mrow id="S3.SS5.p2.3.m3.1.1.3" xref="S3.SS5.p2.3.m3.1.1.3.cmml"><mi id="S3.SS5.p2.3.m3.1.1.3.2" xref="S3.SS5.p2.3.m3.1.1.3.2.cmml">r</mi><mo id="S3.SS5.p2.3.m3.1.1.3.1" xref="S3.SS5.p2.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS5.p2.3.m3.1.1.3.3" xref="S3.SS5.p2.3.m3.1.1.3.3.cmml">e</mi><mo id="S3.SS5.p2.3.m3.1.1.3.1a" xref="S3.SS5.p2.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS5.p2.3.m3.1.1.3.4" xref="S3.SS5.p2.3.m3.1.1.3.4.cmml">f</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.3.m3.1b"><apply id="S3.SS5.p2.3.m3.1.1.cmml" xref="S3.SS5.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS5.p2.3.m3.1.1.1.cmml" xref="S3.SS5.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS5.p2.3.m3.1.1.2.cmml" xref="S3.SS5.p2.3.m3.1.1.2">𝜋</ci><apply id="S3.SS5.p2.3.m3.1.1.3.cmml" xref="S3.SS5.p2.3.m3.1.1.3"><times id="S3.SS5.p2.3.m3.1.1.3.1.cmml" xref="S3.SS5.p2.3.m3.1.1.3.1"></times><ci id="S3.SS5.p2.3.m3.1.1.3.2.cmml" xref="S3.SS5.p2.3.m3.1.1.3.2">𝑟</ci><ci id="S3.SS5.p2.3.m3.1.1.3.3.cmml" xref="S3.SS5.p2.3.m3.1.1.3.3">𝑒</ci><ci id="S3.SS5.p2.3.m3.1.1.3.4.cmml" xref="S3.SS5.p2.3.m3.1.1.3.4">𝑓</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.3.m3.1c">\pi_{ref}</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p2.3.m3.1d">italic_π start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT</annotation></semantics></math> is the reference model. We use <span class="ltx_text ltx_font_typewriter" id="S3.SS5.p2.6.1">ALMA-13B<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_serif" id="footnote8.1.1.1">8</span></span><a class="ltx_ref ltx_url" href="https://github.com/fe1ixxu/ALMA" title="">https://github.com/fe1ixxu/ALMA</a></span></span></span></span> as our base model, i.e., the starting point of <math alttext="\pi" class="ltx_Math" display="inline" id="S3.SS5.p2.4.m4.1"><semantics id="S3.SS5.p2.4.m4.1a"><mi id="S3.SS5.p2.4.m4.1.1" xref="S3.SS5.p2.4.m4.1.1.cmml">π</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.4.m4.1b"><ci id="S3.SS5.p2.4.m4.1.1.cmml" xref="S3.SS5.p2.4.m4.1.1">𝜋</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.4.m4.1c">\pi</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p2.4.m4.1d">italic_π</annotation></semantics></math>, in the experiments. <span class="ltx_text ltx_font_typewriter" id="S3.SS5.p2.6.2">ALMA-13B</span> is also used as a reference model <math alttext="\pi_{ref}" class="ltx_Math" display="inline" id="S3.SS5.p2.5.m5.1"><semantics id="S3.SS5.p2.5.m5.1a"><msub id="S3.SS5.p2.5.m5.1.1" xref="S3.SS5.p2.5.m5.1.1.cmml"><mi id="S3.SS5.p2.5.m5.1.1.2" xref="S3.SS5.p2.5.m5.1.1.2.cmml">π</mi><mrow id="S3.SS5.p2.5.m5.1.1.3" xref="S3.SS5.p2.5.m5.1.1.3.cmml"><mi id="S3.SS5.p2.5.m5.1.1.3.2" xref="S3.SS5.p2.5.m5.1.1.3.2.cmml">r</mi><mo id="S3.SS5.p2.5.m5.1.1.3.1" xref="S3.SS5.p2.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S3.SS5.p2.5.m5.1.1.3.3" xref="S3.SS5.p2.5.m5.1.1.3.3.cmml">e</mi><mo id="S3.SS5.p2.5.m5.1.1.3.1a" xref="S3.SS5.p2.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S3.SS5.p2.5.m5.1.1.3.4" xref="S3.SS5.p2.5.m5.1.1.3.4.cmml">f</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.5.m5.1b"><apply id="S3.SS5.p2.5.m5.1.1.cmml" xref="S3.SS5.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS5.p2.5.m5.1.1.1.cmml" xref="S3.SS5.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS5.p2.5.m5.1.1.2.cmml" xref="S3.SS5.p2.5.m5.1.1.2">𝜋</ci><apply id="S3.SS5.p2.5.m5.1.1.3.cmml" xref="S3.SS5.p2.5.m5.1.1.3"><times id="S3.SS5.p2.5.m5.1.1.3.1.cmml" xref="S3.SS5.p2.5.m5.1.1.3.1"></times><ci id="S3.SS5.p2.5.m5.1.1.3.2.cmml" xref="S3.SS5.p2.5.m5.1.1.3.2">𝑟</ci><ci id="S3.SS5.p2.5.m5.1.1.3.3.cmml" xref="S3.SS5.p2.5.m5.1.1.3.3">𝑒</ci><ci id="S3.SS5.p2.5.m5.1.1.3.4.cmml" xref="S3.SS5.p2.5.m5.1.1.3.4">𝑓</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.5.m5.1c">\pi_{ref}</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p2.5.m5.1d">italic_π start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT</annotation></semantics></math>, but note that <math alttext="\pi_{ref}" class="ltx_Math" display="inline" id="S3.SS5.p2.6.m6.1"><semantics id="S3.SS5.p2.6.m6.1a"><msub id="S3.SS5.p2.6.m6.1.1" xref="S3.SS5.p2.6.m6.1.1.cmml"><mi id="S3.SS5.p2.6.m6.1.1.2" xref="S3.SS5.p2.6.m6.1.1.2.cmml">π</mi><mrow id="S3.SS5.p2.6.m6.1.1.3" xref="S3.SS5.p2.6.m6.1.1.3.cmml"><mi id="S3.SS5.p2.6.m6.1.1.3.2" xref="S3.SS5.p2.6.m6.1.1.3.2.cmml">r</mi><mo id="S3.SS5.p2.6.m6.1.1.3.1" xref="S3.SS5.p2.6.m6.1.1.3.1.cmml">⁢</mo><mi id="S3.SS5.p2.6.m6.1.1.3.3" xref="S3.SS5.p2.6.m6.1.1.3.3.cmml">e</mi><mo id="S3.SS5.p2.6.m6.1.1.3.1a" xref="S3.SS5.p2.6.m6.1.1.3.1.cmml">⁢</mo><mi id="S3.SS5.p2.6.m6.1.1.3.4" xref="S3.SS5.p2.6.m6.1.1.3.4.cmml">f</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.6.m6.1b"><apply id="S3.SS5.p2.6.m6.1.1.cmml" xref="S3.SS5.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS5.p2.6.m6.1.1.1.cmml" xref="S3.SS5.p2.6.m6.1.1">subscript</csymbol><ci id="S3.SS5.p2.6.m6.1.1.2.cmml" xref="S3.SS5.p2.6.m6.1.1.2">𝜋</ci><apply id="S3.SS5.p2.6.m6.1.1.3.cmml" xref="S3.SS5.p2.6.m6.1.1.3"><times id="S3.SS5.p2.6.m6.1.1.3.1.cmml" xref="S3.SS5.p2.6.m6.1.1.3.1"></times><ci id="S3.SS5.p2.6.m6.1.1.3.2.cmml" xref="S3.SS5.p2.6.m6.1.1.3.2">𝑟</ci><ci id="S3.SS5.p2.6.m6.1.1.3.3.cmml" xref="S3.SS5.p2.6.m6.1.1.3.3">𝑒</ci><ci id="S3.SS5.p2.6.m6.1.1.3.4.cmml" xref="S3.SS5.p2.6.m6.1.1.3.4">𝑓</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.6.m6.1c">\pi_{ref}</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p2.6.m6.1d">italic_π start_POSTSUBSCRIPT italic_r italic_e italic_f end_POSTSUBSCRIPT</annotation></semantics></math> will not be updated during training.</p>
</div>
<figure class="ltx_figure" id="S3.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="221" id="S3.F5.g1" src="x6.png" width="415"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Prompt to calculate the coverage score.</figcaption>
</figure>
<figure class="ltx_figure" id="S3.F6">
<div class="ltx_inline-block ltx_transformed_outer" id="S3.F6.12" style="width:433.6pt;height:525.1pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-8.5pt,10.2pt) scale(0.962441614274811,0.962441614274811) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.F6.12.12">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.F6.12.12.13.1">
<th class="ltx_td ltx_th ltx_th_row" id="S3.F6.12.12.13.1.1" style="padding-left:2.0pt;padding-right:2.0pt;"></th>
<td class="ltx_td ltx_align_justify ltx_align_middle" id="S3.F6.12.12.13.1.2" style="width:99.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.F6.12.12.13.1.2.1">
<span class="ltx_p" id="S3.F6.12.12.13.1.2.1.1">BLEU / Hard</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_middle" id="S3.F6.12.12.13.1.3" style="width:99.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.F6.12.12.13.1.3.1">
<span class="ltx_p" id="S3.F6.12.12.13.1.3.1.1">BLEU / Easy</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_middle" id="S3.F6.12.12.13.1.4" style="width:99.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.F6.12.12.13.1.4.1">
<span class="ltx_p" id="S3.F6.12.12.13.1.4.1.1">COMET / Hard</span>
</span>
</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_middle" id="S3.F6.12.12.13.1.5" style="width:99.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.F6.12.12.13.1.5.1">
<span class="ltx_p" id="S3.F6.12.12.13.1.5.1.1">COMET / Easy</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.F6.4.4.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S3.F6.4.4.4.5" style="padding-left:2.0pt;padding-right:2.0pt;">N=100</th>
<td class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" id="S3.F6.1.1.1.1" style="width:99.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.F6.1.1.1.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="191" id="S3.F6.1.1.1.1.1.g1" src="x7.png" width="191"/>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" id="S3.F6.2.2.2.2" style="width:99.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.F6.2.2.2.2.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="191" id="S3.F6.2.2.2.2.1.g1" src="x8.png" width="191"/>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" id="S3.F6.3.3.3.3" style="width:99.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.F6.3.3.3.3.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="191" id="S3.F6.3.3.3.3.1.g1" src="x9.png" width="191"/>
</span>
</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_middle ltx_border_t" id="S3.F6.4.4.4.4" style="width:99.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.F6.4.4.4.4.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="191" id="S3.F6.4.4.4.4.1.g1" src="x10.png" width="191"/>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.F6.8.8.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S3.F6.8.8.8.5" style="padding-left:2.0pt;padding-right:2.0pt;">N=200</th>
<td class="ltx_td ltx_align_justify ltx_align_middle" id="S3.F6.5.5.5.1" style="width:99.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.F6.5.5.5.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="191" id="S3.F6.5.5.5.1.1.g1" src="x11.png" width="191"/>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_middle" id="S3.F6.6.6.6.2" style="width:99.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.F6.6.6.6.2.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="191" id="S3.F6.6.6.6.2.1.g1" src="x12.png" width="191"/>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_middle" id="S3.F6.7.7.7.3" style="width:99.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.F6.7.7.7.3.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="191" id="S3.F6.7.7.7.3.1.g1" src="x13.png" width="191"/>
</span>
</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_middle" id="S3.F6.8.8.8.4" style="width:99.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.F6.8.8.8.4.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="191" id="S3.F6.8.8.8.4.1.g1" src="x14.png" width="191"/>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.F6.12.12.12">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S3.F6.12.12.12.5" style="padding-left:2.0pt;padding-right:2.0pt;">N=500</th>
<td class="ltx_td ltx_align_justify ltx_align_middle" id="S3.F6.9.9.9.1" style="width:99.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.F6.9.9.9.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="191" id="S3.F6.9.9.9.1.1.g1" src="x15.png" width="191"/>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_middle" id="S3.F6.10.10.10.2" style="width:99.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.F6.10.10.10.2.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="191" id="S3.F6.10.10.10.2.1.g1" src="x16.png" width="191"/>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_middle" id="S3.F6.11.11.11.3" style="width:99.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.F6.11.11.11.3.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="191" id="S3.F6.11.11.11.3.1.g1" src="x17.png" width="191"/>
</span>
</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_middle" id="S3.F6.12.12.12.4" style="width:99.7pt;padding-left:2.0pt;padding-right:2.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S3.F6.12.12.12.4.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="191" id="S3.F6.12.12.12.4.1.g1" src="x18.png" width="191"/>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Comparison of WAP and baseline in hard and easy instances. <math alttext="N" class="ltx_Math" display="inline" id="S3.F6.17.m1.1"><semantics id="S3.F6.17.m1.1b"><mi id="S3.F6.17.m1.1.1" xref="S3.F6.17.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.F6.17.m1.1c"><ci id="S3.F6.17.m1.1.1.cmml" xref="S3.F6.17.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F6.17.m1.1d">N</annotation><annotation encoding="application/x-llamapun" id="S3.F6.17.m1.1e">italic_N</annotation></semantics></math> instances with the lowest COMET score by the baseline are selected from the test set as hard instances, and the remaining are easy instances. Results when <math alttext="N=100" class="ltx_Math" display="inline" id="S3.F6.18.m2.1"><semantics id="S3.F6.18.m2.1b"><mrow id="S3.F6.18.m2.1.1" xref="S3.F6.18.m2.1.1.cmml"><mi id="S3.F6.18.m2.1.1.2" xref="S3.F6.18.m2.1.1.2.cmml">N</mi><mo id="S3.F6.18.m2.1.1.1" xref="S3.F6.18.m2.1.1.1.cmml">=</mo><mn id="S3.F6.18.m2.1.1.3" xref="S3.F6.18.m2.1.1.3.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.F6.18.m2.1c"><apply id="S3.F6.18.m2.1.1.cmml" xref="S3.F6.18.m2.1.1"><eq id="S3.F6.18.m2.1.1.1.cmml" xref="S3.F6.18.m2.1.1.1"></eq><ci id="S3.F6.18.m2.1.1.2.cmml" xref="S3.F6.18.m2.1.1.2">𝑁</ci><cn id="S3.F6.18.m2.1.1.3.cmml" type="integer" xref="S3.F6.18.m2.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F6.18.m2.1d">N=100</annotation><annotation encoding="application/x-llamapun" id="S3.F6.18.m2.1e">italic_N = 100</annotation></semantics></math>, <math alttext="200" class="ltx_Math" display="inline" id="S3.F6.19.m3.1"><semantics id="S3.F6.19.m3.1b"><mn id="S3.F6.19.m3.1.1" xref="S3.F6.19.m3.1.1.cmml">200</mn><annotation-xml encoding="MathML-Content" id="S3.F6.19.m3.1c"><cn id="S3.F6.19.m3.1.1.cmml" type="integer" xref="S3.F6.19.m3.1.1">200</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F6.19.m3.1d">200</annotation><annotation encoding="application/x-llamapun" id="S3.F6.19.m3.1e">200</annotation></semantics></math> and <math alttext="500" class="ltx_Math" display="inline" id="S3.F6.20.m4.1"><semantics id="S3.F6.20.m4.1b"><mn id="S3.F6.20.m4.1.1" xref="S3.F6.20.m4.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S3.F6.20.m4.1c"><cn id="S3.F6.20.m4.1.1.cmml" type="integer" xref="S3.F6.20.m4.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F6.20.m4.1d">500</annotation><annotation encoding="application/x-llamapun" id="S3.F6.20.m4.1e">500</annotation></semantics></math> are presented. Refer to §<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#A2" title="Appendix B Specific results ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">B</span></a> for the full numeric results of the entire test.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Evaluation</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Experimental setup</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.3">The implementation from alignment-handbook<span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/huggingface/alignment-handbook" title="">https://github.com/huggingface/alignment-handbook</a></span></span></span> is used for the training of DPO. The learning rate is searched based on performance on development set and set to 5e-6. LoRA <cite class="ltx_cite ltx_citemacro_citep">(Hu et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib19" title="">2021</a>)</cite> is used. <math alttext="r" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.1"><semantics id="S4.SS1.p1.1.m1.1a"><mi id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><ci id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">r</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.1d">italic_r</annotation></semantics></math> is set as 16 and <math alttext="\beta" class="ltx_Math" display="inline" id="S4.SS1.p1.2.m2.1"><semantics id="S4.SS1.p1.2.m2.1a"><mi id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><ci id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">\beta</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.2.m2.1d">italic_β</annotation></semantics></math> is set as 0.1. We train the model for 1 epoch and fix the random seed to 42. The model is trained on 4 <math alttext="\times" class="ltx_Math" display="inline" id="S4.SS1.p1.3.m3.1"><semantics id="S4.SS1.p1.3.m3.1a"><mo id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><times id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.3.m3.1d">×</annotation></semantics></math> Nvidia A100 80G and the total batch size is 64. For evaluation, we use the implementation of ALMA<span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/fe1ixxu/ALMA" title="">https://github.com/fe1ixxu/ALMA</a></span></span></span> to calculate the BLEU and COMET scores.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Baselines and evaluation datasets</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">We choose <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p1.1.1">ALMA-13B<span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_serif" id="footnote11.1.1.1">11</span></span><a class="ltx_ref ltx_url" href="https://huggingface.co/haoranxu/ALMA-13B" title="">https://huggingface.co/haoranxu/ALMA-13B</a></span></span></span></span> as the baseline for all experiments in this paper, as well as the starting point of optimization. ALMA <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib41" title="">2024a</a>)</cite> was trained from Llama <cite class="ltx_cite ltx_citemacro_cite">Touvron et al. (<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib32" title="">2023</a>)</cite> in two steps: initial fine-tuning on monolingual data and subsequent fine-tuning on a small set of high-quality parallel data.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.7">For fairly studying the effect of word alignment preference, we use the data used in the supervised fine-tuning in ALMA as the source dataset to construct our preference data in §<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S3" title="3 Proposed approach ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a>.
Specifically, the source data was collected from WMT’17 <cite class="ltx_cite ltx_citemacro_citep">(Bojar et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib5" title="">2017</a>)</cite> to WMT’20 <cite class="ltx_cite ltx_citemacro_citep">(Barrault et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib4" title="">2020</a>)</cite>, in addition to the development and text dataset from Flores-200 <cite class="ltx_cite ltx_citemacro_citep">(Costa-jussà et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib10" title="">2022</a>)</cite>. After filtering, we finally make 20,074 and 2,226 preference triplets for training and development, respectively.
For evaluation, the test set is from WMT22, except that <math alttext="is\leftrightarrow en" class="ltx_Math" display="inline" id="S4.SS2.p2.1.m1.1"><semantics id="S4.SS2.p2.1.m1.1a"><mrow id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml"><mrow id="S4.SS2.p2.1.m1.1.1.2" xref="S4.SS2.p2.1.m1.1.1.2.cmml"><mi id="S4.SS2.p2.1.m1.1.1.2.2" xref="S4.SS2.p2.1.m1.1.1.2.2.cmml">i</mi><mo id="S4.SS2.p2.1.m1.1.1.2.1" xref="S4.SS2.p2.1.m1.1.1.2.1.cmml">⁢</mo><mi id="S4.SS2.p2.1.m1.1.1.2.3" xref="S4.SS2.p2.1.m1.1.1.2.3.cmml">s</mi></mrow><mo id="S4.SS2.p2.1.m1.1.1.1" stretchy="false" xref="S4.SS2.p2.1.m1.1.1.1.cmml">↔</mo><mrow id="S4.SS2.p2.1.m1.1.1.3" xref="S4.SS2.p2.1.m1.1.1.3.cmml"><mi id="S4.SS2.p2.1.m1.1.1.3.2" xref="S4.SS2.p2.1.m1.1.1.3.2.cmml">e</mi><mo id="S4.SS2.p2.1.m1.1.1.3.1" xref="S4.SS2.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.p2.1.m1.1.1.3.3" xref="S4.SS2.p2.1.m1.1.1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><apply id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1"><ci id="S4.SS2.p2.1.m1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1.1">↔</ci><apply id="S4.SS2.p2.1.m1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1.2"><times id="S4.SS2.p2.1.m1.1.1.2.1.cmml" xref="S4.SS2.p2.1.m1.1.1.2.1"></times><ci id="S4.SS2.p2.1.m1.1.1.2.2.cmml" xref="S4.SS2.p2.1.m1.1.1.2.2">𝑖</ci><ci id="S4.SS2.p2.1.m1.1.1.2.3.cmml" xref="S4.SS2.p2.1.m1.1.1.2.3">𝑠</ci></apply><apply id="S4.SS2.p2.1.m1.1.1.3.cmml" xref="S4.SS2.p2.1.m1.1.1.3"><times id="S4.SS2.p2.1.m1.1.1.3.1.cmml" xref="S4.SS2.p2.1.m1.1.1.3.1"></times><ci id="S4.SS2.p2.1.m1.1.1.3.2.cmml" xref="S4.SS2.p2.1.m1.1.1.3.2">𝑒</ci><ci id="S4.SS2.p2.1.m1.1.1.3.3.cmml" xref="S4.SS2.p2.1.m1.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">is\leftrightarrow en</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.1.m1.1d">italic_i italic_s ↔ italic_e italic_n</annotation></semantics></math> is from WMT21. The remaining data from WMT21 (except <math alttext="is\leftrightarrow en" class="ltx_Math" display="inline" id="S4.SS2.p2.2.m2.1"><semantics id="S4.SS2.p2.2.m2.1a"><mrow id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml"><mrow id="S4.SS2.p2.2.m2.1.1.2" xref="S4.SS2.p2.2.m2.1.1.2.cmml"><mi id="S4.SS2.p2.2.m2.1.1.2.2" xref="S4.SS2.p2.2.m2.1.1.2.2.cmml">i</mi><mo id="S4.SS2.p2.2.m2.1.1.2.1" xref="S4.SS2.p2.2.m2.1.1.2.1.cmml">⁢</mo><mi id="S4.SS2.p2.2.m2.1.1.2.3" xref="S4.SS2.p2.2.m2.1.1.2.3.cmml">s</mi></mrow><mo id="S4.SS2.p2.2.m2.1.1.1" stretchy="false" xref="S4.SS2.p2.2.m2.1.1.1.cmml">↔</mo><mrow id="S4.SS2.p2.2.m2.1.1.3" xref="S4.SS2.p2.2.m2.1.1.3.cmml"><mi id="S4.SS2.p2.2.m2.1.1.3.2" xref="S4.SS2.p2.2.m2.1.1.3.2.cmml">e</mi><mo id="S4.SS2.p2.2.m2.1.1.3.1" xref="S4.SS2.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.p2.2.m2.1.1.3.3" xref="S4.SS2.p2.2.m2.1.1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><apply id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1"><ci id="S4.SS2.p2.2.m2.1.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1.1">↔</ci><apply id="S4.SS2.p2.2.m2.1.1.2.cmml" xref="S4.SS2.p2.2.m2.1.1.2"><times id="S4.SS2.p2.2.m2.1.1.2.1.cmml" xref="S4.SS2.p2.2.m2.1.1.2.1"></times><ci id="S4.SS2.p2.2.m2.1.1.2.2.cmml" xref="S4.SS2.p2.2.m2.1.1.2.2">𝑖</ci><ci id="S4.SS2.p2.2.m2.1.1.2.3.cmml" xref="S4.SS2.p2.2.m2.1.1.2.3">𝑠</ci></apply><apply id="S4.SS2.p2.2.m2.1.1.3.cmml" xref="S4.SS2.p2.2.m2.1.1.3"><times id="S4.SS2.p2.2.m2.1.1.3.1.cmml" xref="S4.SS2.p2.2.m2.1.1.3.1"></times><ci id="S4.SS2.p2.2.m2.1.1.3.2.cmml" xref="S4.SS2.p2.2.m2.1.1.3.2">𝑒</ci><ci id="S4.SS2.p2.2.m2.1.1.3.3.cmml" xref="S4.SS2.p2.2.m2.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">is\leftrightarrow en</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.2.m2.1d">italic_i italic_s ↔ italic_e italic_n</annotation></semantics></math>) is used as the development set. Specifically, 3485, 4021, 2000, 3912, 4053 examples are included in the test set for <math alttext="cs\leftrightarrow en" class="ltx_Math" display="inline" id="S4.SS2.p2.3.m3.1"><semantics id="S4.SS2.p2.3.m3.1a"><mrow id="S4.SS2.p2.3.m3.1.1" xref="S4.SS2.p2.3.m3.1.1.cmml"><mrow id="S4.SS2.p2.3.m3.1.1.2" xref="S4.SS2.p2.3.m3.1.1.2.cmml"><mi id="S4.SS2.p2.3.m3.1.1.2.2" xref="S4.SS2.p2.3.m3.1.1.2.2.cmml">c</mi><mo id="S4.SS2.p2.3.m3.1.1.2.1" xref="S4.SS2.p2.3.m3.1.1.2.1.cmml">⁢</mo><mi id="S4.SS2.p2.3.m3.1.1.2.3" xref="S4.SS2.p2.3.m3.1.1.2.3.cmml">s</mi></mrow><mo id="S4.SS2.p2.3.m3.1.1.1" stretchy="false" xref="S4.SS2.p2.3.m3.1.1.1.cmml">↔</mo><mrow id="S4.SS2.p2.3.m3.1.1.3" xref="S4.SS2.p2.3.m3.1.1.3.cmml"><mi id="S4.SS2.p2.3.m3.1.1.3.2" xref="S4.SS2.p2.3.m3.1.1.3.2.cmml">e</mi><mo id="S4.SS2.p2.3.m3.1.1.3.1" xref="S4.SS2.p2.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.p2.3.m3.1.1.3.3" xref="S4.SS2.p2.3.m3.1.1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.3.m3.1b"><apply id="S4.SS2.p2.3.m3.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1"><ci id="S4.SS2.p2.3.m3.1.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1.1">↔</ci><apply id="S4.SS2.p2.3.m3.1.1.2.cmml" xref="S4.SS2.p2.3.m3.1.1.2"><times id="S4.SS2.p2.3.m3.1.1.2.1.cmml" xref="S4.SS2.p2.3.m3.1.1.2.1"></times><ci id="S4.SS2.p2.3.m3.1.1.2.2.cmml" xref="S4.SS2.p2.3.m3.1.1.2.2">𝑐</ci><ci id="S4.SS2.p2.3.m3.1.1.2.3.cmml" xref="S4.SS2.p2.3.m3.1.1.2.3">𝑠</ci></apply><apply id="S4.SS2.p2.3.m3.1.1.3.cmml" xref="S4.SS2.p2.3.m3.1.1.3"><times id="S4.SS2.p2.3.m3.1.1.3.1.cmml" xref="S4.SS2.p2.3.m3.1.1.3.1"></times><ci id="S4.SS2.p2.3.m3.1.1.3.2.cmml" xref="S4.SS2.p2.3.m3.1.1.3.2">𝑒</ci><ci id="S4.SS2.p2.3.m3.1.1.3.3.cmml" xref="S4.SS2.p2.3.m3.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.3.m3.1c">cs\leftrightarrow en</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.3.m3.1d">italic_c italic_s ↔ italic_e italic_n</annotation></semantics></math>, <math alttext="de\leftrightarrow en" class="ltx_Math" display="inline" id="S4.SS2.p2.4.m4.1"><semantics id="S4.SS2.p2.4.m4.1a"><mrow id="S4.SS2.p2.4.m4.1.1" xref="S4.SS2.p2.4.m4.1.1.cmml"><mrow id="S4.SS2.p2.4.m4.1.1.2" xref="S4.SS2.p2.4.m4.1.1.2.cmml"><mi id="S4.SS2.p2.4.m4.1.1.2.2" xref="S4.SS2.p2.4.m4.1.1.2.2.cmml">d</mi><mo id="S4.SS2.p2.4.m4.1.1.2.1" xref="S4.SS2.p2.4.m4.1.1.2.1.cmml">⁢</mo><mi id="S4.SS2.p2.4.m4.1.1.2.3" xref="S4.SS2.p2.4.m4.1.1.2.3.cmml">e</mi></mrow><mo id="S4.SS2.p2.4.m4.1.1.1" stretchy="false" xref="S4.SS2.p2.4.m4.1.1.1.cmml">↔</mo><mrow id="S4.SS2.p2.4.m4.1.1.3" xref="S4.SS2.p2.4.m4.1.1.3.cmml"><mi id="S4.SS2.p2.4.m4.1.1.3.2" xref="S4.SS2.p2.4.m4.1.1.3.2.cmml">e</mi><mo id="S4.SS2.p2.4.m4.1.1.3.1" xref="S4.SS2.p2.4.m4.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.p2.4.m4.1.1.3.3" xref="S4.SS2.p2.4.m4.1.1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.4.m4.1b"><apply id="S4.SS2.p2.4.m4.1.1.cmml" xref="S4.SS2.p2.4.m4.1.1"><ci id="S4.SS2.p2.4.m4.1.1.1.cmml" xref="S4.SS2.p2.4.m4.1.1.1">↔</ci><apply id="S4.SS2.p2.4.m4.1.1.2.cmml" xref="S4.SS2.p2.4.m4.1.1.2"><times id="S4.SS2.p2.4.m4.1.1.2.1.cmml" xref="S4.SS2.p2.4.m4.1.1.2.1"></times><ci id="S4.SS2.p2.4.m4.1.1.2.2.cmml" xref="S4.SS2.p2.4.m4.1.1.2.2">𝑑</ci><ci id="S4.SS2.p2.4.m4.1.1.2.3.cmml" xref="S4.SS2.p2.4.m4.1.1.2.3">𝑒</ci></apply><apply id="S4.SS2.p2.4.m4.1.1.3.cmml" xref="S4.SS2.p2.4.m4.1.1.3"><times id="S4.SS2.p2.4.m4.1.1.3.1.cmml" xref="S4.SS2.p2.4.m4.1.1.3.1"></times><ci id="S4.SS2.p2.4.m4.1.1.3.2.cmml" xref="S4.SS2.p2.4.m4.1.1.3.2">𝑒</ci><ci id="S4.SS2.p2.4.m4.1.1.3.3.cmml" xref="S4.SS2.p2.4.m4.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.4.m4.1c">de\leftrightarrow en</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.4.m4.1d">italic_d italic_e ↔ italic_e italic_n</annotation></semantics></math>, <math alttext="is\leftrightarrow en" class="ltx_Math" display="inline" id="S4.SS2.p2.5.m5.1"><semantics id="S4.SS2.p2.5.m5.1a"><mrow id="S4.SS2.p2.5.m5.1.1" xref="S4.SS2.p2.5.m5.1.1.cmml"><mrow id="S4.SS2.p2.5.m5.1.1.2" xref="S4.SS2.p2.5.m5.1.1.2.cmml"><mi id="S4.SS2.p2.5.m5.1.1.2.2" xref="S4.SS2.p2.5.m5.1.1.2.2.cmml">i</mi><mo id="S4.SS2.p2.5.m5.1.1.2.1" xref="S4.SS2.p2.5.m5.1.1.2.1.cmml">⁢</mo><mi id="S4.SS2.p2.5.m5.1.1.2.3" xref="S4.SS2.p2.5.m5.1.1.2.3.cmml">s</mi></mrow><mo id="S4.SS2.p2.5.m5.1.1.1" stretchy="false" xref="S4.SS2.p2.5.m5.1.1.1.cmml">↔</mo><mrow id="S4.SS2.p2.5.m5.1.1.3" xref="S4.SS2.p2.5.m5.1.1.3.cmml"><mi id="S4.SS2.p2.5.m5.1.1.3.2" xref="S4.SS2.p2.5.m5.1.1.3.2.cmml">e</mi><mo id="S4.SS2.p2.5.m5.1.1.3.1" xref="S4.SS2.p2.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.p2.5.m5.1.1.3.3" xref="S4.SS2.p2.5.m5.1.1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.5.m5.1b"><apply id="S4.SS2.p2.5.m5.1.1.cmml" xref="S4.SS2.p2.5.m5.1.1"><ci id="S4.SS2.p2.5.m5.1.1.1.cmml" xref="S4.SS2.p2.5.m5.1.1.1">↔</ci><apply id="S4.SS2.p2.5.m5.1.1.2.cmml" xref="S4.SS2.p2.5.m5.1.1.2"><times id="S4.SS2.p2.5.m5.1.1.2.1.cmml" xref="S4.SS2.p2.5.m5.1.1.2.1"></times><ci id="S4.SS2.p2.5.m5.1.1.2.2.cmml" xref="S4.SS2.p2.5.m5.1.1.2.2">𝑖</ci><ci id="S4.SS2.p2.5.m5.1.1.2.3.cmml" xref="S4.SS2.p2.5.m5.1.1.2.3">𝑠</ci></apply><apply id="S4.SS2.p2.5.m5.1.1.3.cmml" xref="S4.SS2.p2.5.m5.1.1.3"><times id="S4.SS2.p2.5.m5.1.1.3.1.cmml" xref="S4.SS2.p2.5.m5.1.1.3.1"></times><ci id="S4.SS2.p2.5.m5.1.1.3.2.cmml" xref="S4.SS2.p2.5.m5.1.1.3.2">𝑒</ci><ci id="S4.SS2.p2.5.m5.1.1.3.3.cmml" xref="S4.SS2.p2.5.m5.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.5.m5.1c">is\leftrightarrow en</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.5.m5.1d">italic_i italic_s ↔ italic_e italic_n</annotation></semantics></math>, <math alttext="zh\leftrightarrow en" class="ltx_Math" display="inline" id="S4.SS2.p2.6.m6.1"><semantics id="S4.SS2.p2.6.m6.1a"><mrow id="S4.SS2.p2.6.m6.1.1" xref="S4.SS2.p2.6.m6.1.1.cmml"><mrow id="S4.SS2.p2.6.m6.1.1.2" xref="S4.SS2.p2.6.m6.1.1.2.cmml"><mi id="S4.SS2.p2.6.m6.1.1.2.2" xref="S4.SS2.p2.6.m6.1.1.2.2.cmml">z</mi><mo id="S4.SS2.p2.6.m6.1.1.2.1" xref="S4.SS2.p2.6.m6.1.1.2.1.cmml">⁢</mo><mi id="S4.SS2.p2.6.m6.1.1.2.3" xref="S4.SS2.p2.6.m6.1.1.2.3.cmml">h</mi></mrow><mo id="S4.SS2.p2.6.m6.1.1.1" stretchy="false" xref="S4.SS2.p2.6.m6.1.1.1.cmml">↔</mo><mrow id="S4.SS2.p2.6.m6.1.1.3" xref="S4.SS2.p2.6.m6.1.1.3.cmml"><mi id="S4.SS2.p2.6.m6.1.1.3.2" xref="S4.SS2.p2.6.m6.1.1.3.2.cmml">e</mi><mo id="S4.SS2.p2.6.m6.1.1.3.1" xref="S4.SS2.p2.6.m6.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.p2.6.m6.1.1.3.3" xref="S4.SS2.p2.6.m6.1.1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.6.m6.1b"><apply id="S4.SS2.p2.6.m6.1.1.cmml" xref="S4.SS2.p2.6.m6.1.1"><ci id="S4.SS2.p2.6.m6.1.1.1.cmml" xref="S4.SS2.p2.6.m6.1.1.1">↔</ci><apply id="S4.SS2.p2.6.m6.1.1.2.cmml" xref="S4.SS2.p2.6.m6.1.1.2"><times id="S4.SS2.p2.6.m6.1.1.2.1.cmml" xref="S4.SS2.p2.6.m6.1.1.2.1"></times><ci id="S4.SS2.p2.6.m6.1.1.2.2.cmml" xref="S4.SS2.p2.6.m6.1.1.2.2">𝑧</ci><ci id="S4.SS2.p2.6.m6.1.1.2.3.cmml" xref="S4.SS2.p2.6.m6.1.1.2.3">ℎ</ci></apply><apply id="S4.SS2.p2.6.m6.1.1.3.cmml" xref="S4.SS2.p2.6.m6.1.1.3"><times id="S4.SS2.p2.6.m6.1.1.3.1.cmml" xref="S4.SS2.p2.6.m6.1.1.3.1"></times><ci id="S4.SS2.p2.6.m6.1.1.3.2.cmml" xref="S4.SS2.p2.6.m6.1.1.3.2">𝑒</ci><ci id="S4.SS2.p2.6.m6.1.1.3.3.cmml" xref="S4.SS2.p2.6.m6.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.6.m6.1c">zh\leftrightarrow en</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.6.m6.1d">italic_z italic_h ↔ italic_e italic_n</annotation></semantics></math>, and <math alttext="ru\leftrightarrow en" class="ltx_Math" display="inline" id="S4.SS2.p2.7.m7.1"><semantics id="S4.SS2.p2.7.m7.1a"><mrow id="S4.SS2.p2.7.m7.1.1" xref="S4.SS2.p2.7.m7.1.1.cmml"><mrow id="S4.SS2.p2.7.m7.1.1.2" xref="S4.SS2.p2.7.m7.1.1.2.cmml"><mi id="S4.SS2.p2.7.m7.1.1.2.2" xref="S4.SS2.p2.7.m7.1.1.2.2.cmml">r</mi><mo id="S4.SS2.p2.7.m7.1.1.2.1" xref="S4.SS2.p2.7.m7.1.1.2.1.cmml">⁢</mo><mi id="S4.SS2.p2.7.m7.1.1.2.3" xref="S4.SS2.p2.7.m7.1.1.2.3.cmml">u</mi></mrow><mo id="S4.SS2.p2.7.m7.1.1.1" stretchy="false" xref="S4.SS2.p2.7.m7.1.1.1.cmml">↔</mo><mrow id="S4.SS2.p2.7.m7.1.1.3" xref="S4.SS2.p2.7.m7.1.1.3.cmml"><mi id="S4.SS2.p2.7.m7.1.1.3.2" xref="S4.SS2.p2.7.m7.1.1.3.2.cmml">e</mi><mo id="S4.SS2.p2.7.m7.1.1.3.1" xref="S4.SS2.p2.7.m7.1.1.3.1.cmml">⁢</mo><mi id="S4.SS2.p2.7.m7.1.1.3.3" xref="S4.SS2.p2.7.m7.1.1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.7.m7.1b"><apply id="S4.SS2.p2.7.m7.1.1.cmml" xref="S4.SS2.p2.7.m7.1.1"><ci id="S4.SS2.p2.7.m7.1.1.1.cmml" xref="S4.SS2.p2.7.m7.1.1.1">↔</ci><apply id="S4.SS2.p2.7.m7.1.1.2.cmml" xref="S4.SS2.p2.7.m7.1.1.2"><times id="S4.SS2.p2.7.m7.1.1.2.1.cmml" xref="S4.SS2.p2.7.m7.1.1.2.1"></times><ci id="S4.SS2.p2.7.m7.1.1.2.2.cmml" xref="S4.SS2.p2.7.m7.1.1.2.2">𝑟</ci><ci id="S4.SS2.p2.7.m7.1.1.2.3.cmml" xref="S4.SS2.p2.7.m7.1.1.2.3">𝑢</ci></apply><apply id="S4.SS2.p2.7.m7.1.1.3.cmml" xref="S4.SS2.p2.7.m7.1.1.3"><times id="S4.SS2.p2.7.m7.1.1.3.1.cmml" xref="S4.SS2.p2.7.m7.1.1.3.1"></times><ci id="S4.SS2.p2.7.m7.1.1.3.2.cmml" xref="S4.SS2.p2.7.m7.1.1.3.2">𝑒</ci><ci id="S4.SS2.p2.7.m7.1.1.3.3.cmml" xref="S4.SS2.p2.7.m7.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.7.m7.1c">ru\leftrightarrow en</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.7.m7.1d">italic_r italic_u ↔ italic_e italic_n</annotation></semantics></math>, respectively.</p>
</div>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">HalOmi</h4>
<div class="ltx_para" id="S4.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS2.SSS0.Px1.p1.1">In particular, we want to validate whether our proposed method is capable of mitigating hallucination and omission in MT. Hence, we also utilize HalOmi <cite class="ltx_cite ltx_citemacro_citep">(Dale et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib12" title="">2023b</a>)</cite> in the experiments. HalOmi is an evaluation benchmark for the detection of hallucination and omission in MT. It contains fine-grained sentence-level and token-level annotations of full and partial hallucinations and omissions that cover 18 language directions. Each instance in the data set was annotated in “No hallucination and omission”, “Small hallucination and omission”, “Partial hallucination and omission” or “Full hallucination and omission” by humans. In this paper, we use it to test the performance of GPT-4 as an evaluator. Details are in §<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S4.SS3" title="4.3 The design of evaluation ‣ 4 Evaluation ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">4.3</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>The design of evaluation</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">We focus on optimizing LLM-based MT models to avoid hallucination and omission. However, to our best knowledge, there is no benchmark measuring MT models specifically for this issue, making the evaluation very challenging. Improving the BLEU or COMET score does not necessarily mean reducing hallucination and omission because there are other factors such as mistranslation and fluency. In addition, hallucination is relatively infrequent, although very severe once happens. To intuitively validate whether our approach is capable of mitigating hallucination and omission in MT, we design several evaluation strategies in this section.</p>
</div>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Select hard instances.</h4>
<div class="ltx_para" id="S4.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS3.SSS0.Px1.p1.4">We first select instances that the baseline model does not perform well on. This subset of instances is labeled as <span class="ltx_text ltx_font_italic" id="S4.SS3.SSS0.Px1.p1.4.1">hard instances</span> in this paper. The subset of the remaining examples is labeled as <span class="ltx_text ltx_font_italic" id="S4.SS3.SSS0.Px1.p1.4.2">easy instances</span>. Specifically, <math alttext="N" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px1.p1.1.m1.1"><semantics id="S4.SS3.SSS0.Px1.p1.1.m1.1a"><mi id="S4.SS3.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p1.1.m1.1b"><ci id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p1.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS0.Px1.p1.1.m1.1d">italic_N</annotation></semantics></math> instances with the lowest COMET score are selected from the test set for each translation direction. As hard examples tend to include more hallucination and omission, we report the comparison of models on hard examples and remaining examples, respectively.
In the experiment, we sample three subsets where <math alttext="N=100" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px1.p1.2.m2.1"><semantics id="S4.SS3.SSS0.Px1.p1.2.m2.1a"><mrow id="S4.SS3.SSS0.Px1.p1.2.m2.1.1" xref="S4.SS3.SSS0.Px1.p1.2.m2.1.1.cmml"><mi id="S4.SS3.SSS0.Px1.p1.2.m2.1.1.2" xref="S4.SS3.SSS0.Px1.p1.2.m2.1.1.2.cmml">N</mi><mo id="S4.SS3.SSS0.Px1.p1.2.m2.1.1.1" xref="S4.SS3.SSS0.Px1.p1.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS3.SSS0.Px1.p1.2.m2.1.1.3" xref="S4.SS3.SSS0.Px1.p1.2.m2.1.1.3.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p1.2.m2.1b"><apply id="S4.SS3.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.2.m2.1.1"><eq id="S4.SS3.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.2.m2.1.1.1"></eq><ci id="S4.SS3.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S4.SS3.SSS0.Px1.p1.2.m2.1.1.2">𝑁</ci><cn id="S4.SS3.SSS0.Px1.p1.2.m2.1.1.3.cmml" type="integer" xref="S4.SS3.SSS0.Px1.p1.2.m2.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p1.2.m2.1c">N=100</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS0.Px1.p1.2.m2.1d">italic_N = 100</annotation></semantics></math>, <math alttext="N=200" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px1.p1.3.m3.1"><semantics id="S4.SS3.SSS0.Px1.p1.3.m3.1a"><mrow id="S4.SS3.SSS0.Px1.p1.3.m3.1.1" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.cmml"><mi id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.2" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.2.cmml">N</mi><mo id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.1" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.1.cmml">=</mo><mn id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.cmml">200</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p1.3.m3.1b"><apply id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1"><eq id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.1"></eq><ci id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.2">𝑁</ci><cn id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.cmml" type="integer" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3">200</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p1.3.m3.1c">N=200</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS0.Px1.p1.3.m3.1d">italic_N = 200</annotation></semantics></math> and <math alttext="N=500" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px1.p1.4.m4.1"><semantics id="S4.SS3.SSS0.Px1.p1.4.m4.1a"><mrow id="S4.SS3.SSS0.Px1.p1.4.m4.1.1" xref="S4.SS3.SSS0.Px1.p1.4.m4.1.1.cmml"><mi id="S4.SS3.SSS0.Px1.p1.4.m4.1.1.2" xref="S4.SS3.SSS0.Px1.p1.4.m4.1.1.2.cmml">N</mi><mo id="S4.SS3.SSS0.Px1.p1.4.m4.1.1.1" xref="S4.SS3.SSS0.Px1.p1.4.m4.1.1.1.cmml">=</mo><mn id="S4.SS3.SSS0.Px1.p1.4.m4.1.1.3" xref="S4.SS3.SSS0.Px1.p1.4.m4.1.1.3.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p1.4.m4.1b"><apply id="S4.SS3.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.4.m4.1.1"><eq id="S4.SS3.SSS0.Px1.p1.4.m4.1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.4.m4.1.1.1"></eq><ci id="S4.SS3.SSS0.Px1.p1.4.m4.1.1.2.cmml" xref="S4.SS3.SSS0.Px1.p1.4.m4.1.1.2">𝑁</ci><cn id="S4.SS3.SSS0.Px1.p1.4.m4.1.1.3.cmml" type="integer" xref="S4.SS3.SSS0.Px1.p1.4.m4.1.1.3">500</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p1.4.m4.1c">N=500</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS0.Px1.p1.4.m4.1d">italic_N = 500</annotation></semantics></math>. The experimental analysis can be found in §<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S5.SS1" title="5.1 Evaluation on hard instances ‣ 5 Experimental results ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">5.1</span></a>.
Note that the hard instances are only selected for evaluation. We do not differentiate hard or easy instances in the training set. Only word alignment signal is used to select preferred dataset for a fair comparison.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T1.1" style="width:433.6pt;height:132.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(69.6pt,-21.3pt) scale(1.47294701775308,1.47294701775308) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T1.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.1.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.1.1.1.1.1" rowspan="2"></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="S4.T1.1.1.1.1.2">Hallucination</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="S4.T1.1.1.1.1.3">Omission</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.2.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.2.2.1">No</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.2.2.2">Partial</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.2.2.3">Full</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.2.2.4">No</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.2.2.5">Partial</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.2.2.6">Full</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.1.1.3.3.1"># of examples</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3.3.2">817</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3.3.3">42</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.3.3.4">65</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3.3.5">627</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3.3.6">237</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3.3.7">60</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.4.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.1.1.4.4.1">Avg. score</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.4.4.2">84.19</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.4.4.3">45.95</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.4.4.4">3.84</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.4.4.5">87.97</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.4.4.6">66.28</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.4.4.7">1.66</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.5.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S4.T1.1.1.5.5.1">Pearson Corr.</th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" colspan="3" id="S4.T1.1.1.5.5.2">0.5969</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" colspan="3" id="S4.T1.1.1.5.5.3">0.5686</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Average coverage score calculated by GPT-4 for different level of hallucination or omission. The Pearson Correlation between the annotated labels and GPT-4 coverage scores is also reported.</figcaption>
</figure>
</section>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Utilize LLM as the evaluator for hallucination and omission.</h4>
<div class="ltx_para" id="S4.SS3.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS3.SSS0.Px2.p1.1">Besides the BLEU and COMET in hard instances, a direct estimate of the degree of hallucination and omission in translation is still needed. As we mentioned earlier that improving the BLEU and COMET score does not necessarily mean reducing hallucination and omission because there are other factors such as mistranslation and fluency, we utilize the generalization and reasoning ability of LLM <cite class="ltx_cite ltx_citemacro_citep">(Kojima et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib21" title="">2022</a>; Mitchell et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib24" title="">2023</a>; Wei et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib37" title="">2023</a>)</cite> to achieve this direct evaluation.
We use one of the most powerful LLM, <span class="ltx_text ltx_font_typewriter" id="S4.SS3.SSS0.Px2.p1.1.1">GPT-4<span class="ltx_note ltx_role_footnote" id="footnote12"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_serif" id="footnote12.1.1.1">12</span></span><a class="ltx_ref ltx_url" href="https://openai.com/research/gpt-4" title="">https://openai.com/research/gpt-4</a></span></span></span></span>, as the evaluator. LLM is prompted to check whether the given translation has hallucination or omission referring to the given source texts. A coverage score between 0 and 100 is output as the degree metric. The prompt used is shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S3.F5" title="Figure 5 ‣ 3.5 Optimization LLM-based MT model ‣ 3 Proposed approach ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Is LLM really capable of evaluating hallucination and omission in MT?</h4>
<div class="ltx_para" id="S4.SS3.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS3.SSS0.Px3.p1.3">Despite the fact that LLMs have shown impressive zero-shot performance in various tasks <cite class="ltx_cite ltx_citemacro_citep">(Kojima et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib21" title="">2022</a>; Mitchell et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib24" title="">2023</a>; Wei et al., <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#bib.bib37" title="">2023</a>)</cite>, the assessment of LLM in the evaluation of hallucination and omission is still important because it has not been widely used on this task.
We use HalOmi datasets introduced in §<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S4.SS2" title="4.2 Baselines and evaluation datasets ‣ 4 Evaluation ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">4.2</span></a> to assess this ability of GPT-4.
The examples in <math alttext="de\leftrightarrow en" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px3.p1.1.m1.1"><semantics id="S4.SS3.SSS0.Px3.p1.1.m1.1a"><mrow id="S4.SS3.SSS0.Px3.p1.1.m1.1.1" xref="S4.SS3.SSS0.Px3.p1.1.m1.1.1.cmml"><mrow id="S4.SS3.SSS0.Px3.p1.1.m1.1.1.2" xref="S4.SS3.SSS0.Px3.p1.1.m1.1.1.2.cmml"><mi id="S4.SS3.SSS0.Px3.p1.1.m1.1.1.2.2" xref="S4.SS3.SSS0.Px3.p1.1.m1.1.1.2.2.cmml">d</mi><mo id="S4.SS3.SSS0.Px3.p1.1.m1.1.1.2.1" xref="S4.SS3.SSS0.Px3.p1.1.m1.1.1.2.1.cmml">⁢</mo><mi id="S4.SS3.SSS0.Px3.p1.1.m1.1.1.2.3" xref="S4.SS3.SSS0.Px3.p1.1.m1.1.1.2.3.cmml">e</mi></mrow><mo id="S4.SS3.SSS0.Px3.p1.1.m1.1.1.1" stretchy="false" xref="S4.SS3.SSS0.Px3.p1.1.m1.1.1.1.cmml">↔</mo><mrow id="S4.SS3.SSS0.Px3.p1.1.m1.1.1.3" xref="S4.SS3.SSS0.Px3.p1.1.m1.1.1.3.cmml"><mi id="S4.SS3.SSS0.Px3.p1.1.m1.1.1.3.2" xref="S4.SS3.SSS0.Px3.p1.1.m1.1.1.3.2.cmml">e</mi><mo id="S4.SS3.SSS0.Px3.p1.1.m1.1.1.3.1" xref="S4.SS3.SSS0.Px3.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S4.SS3.SSS0.Px3.p1.1.m1.1.1.3.3" xref="S4.SS3.SSS0.Px3.p1.1.m1.1.1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px3.p1.1.m1.1b"><apply id="S4.SS3.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px3.p1.1.m1.1.1"><ci id="S4.SS3.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="S4.SS3.SSS0.Px3.p1.1.m1.1.1.1">↔</ci><apply id="S4.SS3.SSS0.Px3.p1.1.m1.1.1.2.cmml" xref="S4.SS3.SSS0.Px3.p1.1.m1.1.1.2"><times id="S4.SS3.SSS0.Px3.p1.1.m1.1.1.2.1.cmml" xref="S4.SS3.SSS0.Px3.p1.1.m1.1.1.2.1"></times><ci id="S4.SS3.SSS0.Px3.p1.1.m1.1.1.2.2.cmml" xref="S4.SS3.SSS0.Px3.p1.1.m1.1.1.2.2">𝑑</ci><ci id="S4.SS3.SSS0.Px3.p1.1.m1.1.1.2.3.cmml" xref="S4.SS3.SSS0.Px3.p1.1.m1.1.1.2.3">𝑒</ci></apply><apply id="S4.SS3.SSS0.Px3.p1.1.m1.1.1.3.cmml" xref="S4.SS3.SSS0.Px3.p1.1.m1.1.1.3"><times id="S4.SS3.SSS0.Px3.p1.1.m1.1.1.3.1.cmml" xref="S4.SS3.SSS0.Px3.p1.1.m1.1.1.3.1"></times><ci id="S4.SS3.SSS0.Px3.p1.1.m1.1.1.3.2.cmml" xref="S4.SS3.SSS0.Px3.p1.1.m1.1.1.3.2">𝑒</ci><ci id="S4.SS3.SSS0.Px3.p1.1.m1.1.1.3.3.cmml" xref="S4.SS3.SSS0.Px3.p1.1.m1.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px3.p1.1.m1.1c">de\leftrightarrow en</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS0.Px3.p1.1.m1.1d">italic_d italic_e ↔ italic_e italic_n</annotation></semantics></math>, <math alttext="zh\leftrightarrow en" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px3.p1.2.m2.1"><semantics id="S4.SS3.SSS0.Px3.p1.2.m2.1a"><mrow id="S4.SS3.SSS0.Px3.p1.2.m2.1.1" xref="S4.SS3.SSS0.Px3.p1.2.m2.1.1.cmml"><mrow id="S4.SS3.SSS0.Px3.p1.2.m2.1.1.2" xref="S4.SS3.SSS0.Px3.p1.2.m2.1.1.2.cmml"><mi id="S4.SS3.SSS0.Px3.p1.2.m2.1.1.2.2" xref="S4.SS3.SSS0.Px3.p1.2.m2.1.1.2.2.cmml">z</mi><mo id="S4.SS3.SSS0.Px3.p1.2.m2.1.1.2.1" xref="S4.SS3.SSS0.Px3.p1.2.m2.1.1.2.1.cmml">⁢</mo><mi id="S4.SS3.SSS0.Px3.p1.2.m2.1.1.2.3" xref="S4.SS3.SSS0.Px3.p1.2.m2.1.1.2.3.cmml">h</mi></mrow><mo id="S4.SS3.SSS0.Px3.p1.2.m2.1.1.1" stretchy="false" xref="S4.SS3.SSS0.Px3.p1.2.m2.1.1.1.cmml">↔</mo><mrow id="S4.SS3.SSS0.Px3.p1.2.m2.1.1.3" xref="S4.SS3.SSS0.Px3.p1.2.m2.1.1.3.cmml"><mi id="S4.SS3.SSS0.Px3.p1.2.m2.1.1.3.2" xref="S4.SS3.SSS0.Px3.p1.2.m2.1.1.3.2.cmml">e</mi><mo id="S4.SS3.SSS0.Px3.p1.2.m2.1.1.3.1" xref="S4.SS3.SSS0.Px3.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S4.SS3.SSS0.Px3.p1.2.m2.1.1.3.3" xref="S4.SS3.SSS0.Px3.p1.2.m2.1.1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px3.p1.2.m2.1b"><apply id="S4.SS3.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S4.SS3.SSS0.Px3.p1.2.m2.1.1"><ci id="S4.SS3.SSS0.Px3.p1.2.m2.1.1.1.cmml" xref="S4.SS3.SSS0.Px3.p1.2.m2.1.1.1">↔</ci><apply id="S4.SS3.SSS0.Px3.p1.2.m2.1.1.2.cmml" xref="S4.SS3.SSS0.Px3.p1.2.m2.1.1.2"><times id="S4.SS3.SSS0.Px3.p1.2.m2.1.1.2.1.cmml" xref="S4.SS3.SSS0.Px3.p1.2.m2.1.1.2.1"></times><ci id="S4.SS3.SSS0.Px3.p1.2.m2.1.1.2.2.cmml" xref="S4.SS3.SSS0.Px3.p1.2.m2.1.1.2.2">𝑧</ci><ci id="S4.SS3.SSS0.Px3.p1.2.m2.1.1.2.3.cmml" xref="S4.SS3.SSS0.Px3.p1.2.m2.1.1.2.3">ℎ</ci></apply><apply id="S4.SS3.SSS0.Px3.p1.2.m2.1.1.3.cmml" xref="S4.SS3.SSS0.Px3.p1.2.m2.1.1.3"><times id="S4.SS3.SSS0.Px3.p1.2.m2.1.1.3.1.cmml" xref="S4.SS3.SSS0.Px3.p1.2.m2.1.1.3.1"></times><ci id="S4.SS3.SSS0.Px3.p1.2.m2.1.1.3.2.cmml" xref="S4.SS3.SSS0.Px3.p1.2.m2.1.1.3.2">𝑒</ci><ci id="S4.SS3.SSS0.Px3.p1.2.m2.1.1.3.3.cmml" xref="S4.SS3.SSS0.Px3.p1.2.m2.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px3.p1.2.m2.1c">zh\leftrightarrow en</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS0.Px3.p1.2.m2.1d">italic_z italic_h ↔ italic_e italic_n</annotation></semantics></math>, and <math alttext="ru\leftrightarrow en" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px3.p1.3.m3.1"><semantics id="S4.SS3.SSS0.Px3.p1.3.m3.1a"><mrow id="S4.SS3.SSS0.Px3.p1.3.m3.1.1" xref="S4.SS3.SSS0.Px3.p1.3.m3.1.1.cmml"><mrow id="S4.SS3.SSS0.Px3.p1.3.m3.1.1.2" xref="S4.SS3.SSS0.Px3.p1.3.m3.1.1.2.cmml"><mi id="S4.SS3.SSS0.Px3.p1.3.m3.1.1.2.2" xref="S4.SS3.SSS0.Px3.p1.3.m3.1.1.2.2.cmml">r</mi><mo id="S4.SS3.SSS0.Px3.p1.3.m3.1.1.2.1" xref="S4.SS3.SSS0.Px3.p1.3.m3.1.1.2.1.cmml">⁢</mo><mi id="S4.SS3.SSS0.Px3.p1.3.m3.1.1.2.3" xref="S4.SS3.SSS0.Px3.p1.3.m3.1.1.2.3.cmml">u</mi></mrow><mo id="S4.SS3.SSS0.Px3.p1.3.m3.1.1.1" stretchy="false" xref="S4.SS3.SSS0.Px3.p1.3.m3.1.1.1.cmml">↔</mo><mrow id="S4.SS3.SSS0.Px3.p1.3.m3.1.1.3" xref="S4.SS3.SSS0.Px3.p1.3.m3.1.1.3.cmml"><mi id="S4.SS3.SSS0.Px3.p1.3.m3.1.1.3.2" xref="S4.SS3.SSS0.Px3.p1.3.m3.1.1.3.2.cmml">e</mi><mo id="S4.SS3.SSS0.Px3.p1.3.m3.1.1.3.1" xref="S4.SS3.SSS0.Px3.p1.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S4.SS3.SSS0.Px3.p1.3.m3.1.1.3.3" xref="S4.SS3.SSS0.Px3.p1.3.m3.1.1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px3.p1.3.m3.1b"><apply id="S4.SS3.SSS0.Px3.p1.3.m3.1.1.cmml" xref="S4.SS3.SSS0.Px3.p1.3.m3.1.1"><ci id="S4.SS3.SSS0.Px3.p1.3.m3.1.1.1.cmml" xref="S4.SS3.SSS0.Px3.p1.3.m3.1.1.1">↔</ci><apply id="S4.SS3.SSS0.Px3.p1.3.m3.1.1.2.cmml" xref="S4.SS3.SSS0.Px3.p1.3.m3.1.1.2"><times id="S4.SS3.SSS0.Px3.p1.3.m3.1.1.2.1.cmml" xref="S4.SS3.SSS0.Px3.p1.3.m3.1.1.2.1"></times><ci id="S4.SS3.SSS0.Px3.p1.3.m3.1.1.2.2.cmml" xref="S4.SS3.SSS0.Px3.p1.3.m3.1.1.2.2">𝑟</ci><ci id="S4.SS3.SSS0.Px3.p1.3.m3.1.1.2.3.cmml" xref="S4.SS3.SSS0.Px3.p1.3.m3.1.1.2.3">𝑢</ci></apply><apply id="S4.SS3.SSS0.Px3.p1.3.m3.1.1.3.cmml" xref="S4.SS3.SSS0.Px3.p1.3.m3.1.1.3"><times id="S4.SS3.SSS0.Px3.p1.3.m3.1.1.3.1.cmml" xref="S4.SS3.SSS0.Px3.p1.3.m3.1.1.3.1"></times><ci id="S4.SS3.SSS0.Px3.p1.3.m3.1.1.3.2.cmml" xref="S4.SS3.SSS0.Px3.p1.3.m3.1.1.3.2">𝑒</ci><ci id="S4.SS3.SSS0.Px3.p1.3.m3.1.1.3.3.cmml" xref="S4.SS3.SSS0.Px3.p1.3.m3.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px3.p1.3.m3.1c">ru\leftrightarrow en</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS0.Px3.p1.3.m3.1d">italic_r italic_u ↔ italic_e italic_n</annotation></semantics></math> are selected, then GPT-4 is used to predict the coverage score for these examples.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS0.Px3.p2">
<p class="ltx_p" id="S4.SS3.SSS0.Px3.p2.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S4.T1" title="Table 1 ‣ Select hard instances. ‣ 4.3 The design of evaluation ‣ 4 Evaluation ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a> shows the average score of the degree of coverage predicted by GPT-4. The examples from HalOmi are split into three subsets based on the labels. We merged the “Partial hallucination and omission” and “Small hallucination and omission” in the original because the number of examples in these two categories is small. It clearly demonstrates that examples annotated as “No hallucination and omission” have a higher coverage score predicted by GPT-4 and those in “Full hallucination and omission” have an extremely low coverage score. As a result, using GPT-4 is an effective way to assess whether a translation has the problem of hallucination or omission.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T2.3" style="width:433.6pt;height:165.3pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-20.6pt,7.8pt) scale(0.913363568243021,0.913363568243021) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T2.3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.3.1.1.1">
<th class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T2.3.1.1.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.3.1.1.1.2">de-en</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.3.1.1.1.3">cs-en</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.3.1.1.1.4">is-en</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.3.1.1.1.5">zh-en</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.3.1.1.1.6">ru-en</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.3.1.1.1.7">en-de</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.3.1.1.1.8">en-cs</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.3.1.1.1.9">en-is</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.3.1.1.1.10">en-zh</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T2.3.1.1.1.11">en-ru</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.3.1.1.1.12">Avg.</th>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="12" id="S4.T2.3.1.2.2.1">N=100</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.3.1.3.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.3.1.3.1.1">Baseline</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.3.1.2">94.30</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.3.1.3">92.95</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.3.1.4">94.90</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.3.1.5">63.08</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.3.1.6">89.85</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.3.1.7">92.85</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.3.1.8">82.75</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.3.1.9"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.3.1.9.1">97.05</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.3.1.10">84.65</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.3.1.3.1.11">90.53</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.3.1.12">88.29</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.4.2">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.3.1.4.2.1"> +WAP</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.4.2.2"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.4.2.2.1">95.85</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.4.2.3"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.4.2.3.1">94.65</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.4.2.4"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.4.2.4.1">96.05</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.4.2.5"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.4.2.5.1">80.23</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.4.2.6"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.4.2.6.1">91.75</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.4.2.7"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.4.2.7.1">96.25</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.4.2.8"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.4.2.8.1">91.85</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.4.2.9">96.10</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.4.2.10"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.4.2.10.1">92.90</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.3.1.4.2.11"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.4.2.11.1">96.87</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.4.2.12"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.4.2.12.1">93.25(+4.96)</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.5.3">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="12" id="S4.T2.3.1.5.3.1">N=200</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.6.4">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.3.1.6.4.1">Baseline</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.6.4.2">95.71</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.6.4.3">95.05</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.6.4.4">95.45</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.6.4.5">74.83</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.6.4.6">92.83</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.6.4.7">94.20</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.6.4.8">89.95</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.6.4.9"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.6.4.9.1">97.70</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.6.4.10">89.19</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.3.1.6.4.11">94.25</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.6.4.12">91.92</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.7.5">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.3.1.7.5.1"> +WAP</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.5.2"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.7.5.2.1">97.10</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.5.3"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.7.5.3.1">96.55</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.5.4"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.7.5.4.1">97.48</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.5.5"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.7.5.5.1">85.63</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.5.6"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.7.5.6.1">95.53</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.5.7"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.7.5.7.1">95.18</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.5.8"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.7.5.8.1">91.84</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.5.9">96.73</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.5.10"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.7.5.10.1">92.81</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.3.1.7.5.11"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.7.5.11.1">96.66</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.5.12"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.7.5.12.1">94.55(+2.63)</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.8.6">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="12" id="S4.T2.3.1.8.6.1">N=500</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.9.7">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.3.1.9.7.1">Baseline</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.9.7.2">97.18</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.9.7.3">96.74</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.9.7.4">97.29</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.9.7.5">87.85</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.9.7.6">96.16</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.9.7.7">97.35</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.9.7.8">94.46</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.9.7.9">98.21</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.9.7.10">91.64</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.3.1.9.7.11">96.10</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.9.7.12">95.30</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.1.10.8">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T2.3.1.10.8.1"> +WAP</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.3.1.10.8.2"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.10.8.2.1">98.10</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.3.1.10.8.3"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.10.8.3.1">97.79</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.3.1.10.8.4"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.10.8.4.1">98.12</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.3.1.10.8.5"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.10.8.5.1">90.76</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.3.1.10.8.6"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.10.8.6.1">97.82</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.3.1.10.8.7"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.10.8.7.1">97.36</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.3.1.10.8.8"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.10.8.8.1">96.05</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.3.1.10.8.9"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.10.8.9.1">98.22</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.3.1.10.8.10"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.10.8.10.1">94.07</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S4.T2.3.1.10.8.11"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.10.8.11.1">97.13</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.3.1.10.8.12"><span class="ltx_text ltx_font_bold" id="S4.T2.3.1.10.8.12.1">96.54(+1.24)</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Coverage score output by GPT-4. The range of the score is <math alttext="[0.0,100.0]" class="ltx_Math" display="inline" id="S4.T2.2.m1.2"><semantics id="S4.T2.2.m1.2b"><mrow id="S4.T2.2.m1.2.3.2" xref="S4.T2.2.m1.2.3.1.cmml"><mo id="S4.T2.2.m1.2.3.2.1" stretchy="false" xref="S4.T2.2.m1.2.3.1.cmml">[</mo><mn id="S4.T2.2.m1.1.1" xref="S4.T2.2.m1.1.1.cmml">0.0</mn><mo id="S4.T2.2.m1.2.3.2.2" xref="S4.T2.2.m1.2.3.1.cmml">,</mo><mn id="S4.T2.2.m1.2.2" xref="S4.T2.2.m1.2.2.cmml">100.0</mn><mo id="S4.T2.2.m1.2.3.2.3" stretchy="false" xref="S4.T2.2.m1.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.2.m1.2c"><interval closure="closed" id="S4.T2.2.m1.2.3.1.cmml" xref="S4.T2.2.m1.2.3.2"><cn id="S4.T2.2.m1.1.1.cmml" type="float" xref="S4.T2.2.m1.1.1">0.0</cn><cn id="S4.T2.2.m1.2.2.cmml" type="float" xref="S4.T2.2.m1.2.2">100.0</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.m1.2d">[0.0,100.0]</annotation><annotation encoding="application/x-llamapun" id="S4.T2.2.m1.2e">[ 0.0 , 100.0 ]</annotation></semantics></math>. The average score is reported for each translation direction. Higher scores are highlighted in bold.</figcaption>
</figure>
<figure class="ltx_table" id="S4.T3">
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T3.1" style="width:433.6pt;height:64.7pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-27.9pt,4.1pt) scale(0.886041964031854,0.886041964031854) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T3.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.1.1.1.1">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_rr ltx_border_t" id="S4.T3.1.1.1.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_rr ltx_border_t" id="S4.T3.1.1.1.1.2" rowspan="2"><span class="ltx_text" id="S4.T3.1.1.1.1.2.1">Translation Quality</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t" colspan="4" id="S4.T3.1.1.1.1.3">Hallucination</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4" id="S4.T3.1.1.1.1.4">Omission</th>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.2.2">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_rr" id="S4.T3.1.1.2.2.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.1.1.2.2.2">No</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.1.1.2.2.3">Small</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.1.1.2.2.4">Partial</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t" id="S4.T3.1.1.2.2.5">Full</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.1.1.2.2.6">No</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.1.1.2.2.7">Small</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.1.1.2.2.8">Partial</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.1.1.2.2.9">Full</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.1.1.3.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S4.T3.1.1.3.1.1">Baseline</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S4.T3.1.1.3.1.2">11.33%</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.3.1.3">64.00%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.3.1.4">21.00%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.3.1.5">11.33%</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S4.T3.1.1.3.1.6">3.66%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.3.1.7">56.00%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.3.1.8">25.33%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.3.1.9">13.66%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.3.1.10">4.33%</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.4.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_rr" id="S4.T3.1.1.4.2.1"> +WAP</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_rr" id="S4.T3.1.1.4.2.2"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.4.2.2.1">39.66%</span></th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.1.1.4.2.3"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.4.2.3.1">75.66%</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.1.1.4.2.4"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.4.2.4.1">17.33%</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.1.1.4.2.5"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.4.2.5.1">7.00%</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_rr" id="S4.T3.1.1.4.2.6"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.4.2.6.1">0.00%</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.1.1.4.2.7"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.4.2.7.1">80.00%</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.1.1.4.2.8"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.4.2.8.1">16.66%</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.1.1.4.2.9"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.4.2.9.1">5.33%</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.1.1.4.2.10"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.4.2.10.1">0.00%</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Human evaluation on “zh-en” when N=100. Translation quality is the ratio of examples where the corresponding model generates better translation in general. The remaining columns present the ratio of examples in which the corresponding degree of hallucination or omission occurs. Better performance is highlighted with bold fonts.</figcaption>
</figure>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experimental results</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Evaluation on hard instances</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.2">In §<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S4.SS3" title="4.3 The design of evaluation ‣ 4 Evaluation ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">4.3</span></a> we introduce how to select hard instances from the test set and explain why hard instances are suitable to assess hallucination and omission. In this section, we evaluate our model on these hard instances and the remaining examples, respectively. Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S3.F6" title="Figure 6 ‣ 3.5 Optimization LLM-based MT model ‣ 3 Proposed approach ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">6</span></a> demonstrates the results when the number of sampled instances <math alttext="N=100,200" class="ltx_Math" display="inline" id="S5.SS1.p1.1.m1.2"><semantics id="S5.SS1.p1.1.m1.2a"><mrow id="S5.SS1.p1.1.m1.2.3" xref="S5.SS1.p1.1.m1.2.3.cmml"><mi id="S5.SS1.p1.1.m1.2.3.2" xref="S5.SS1.p1.1.m1.2.3.2.cmml">N</mi><mo id="S5.SS1.p1.1.m1.2.3.1" xref="S5.SS1.p1.1.m1.2.3.1.cmml">=</mo><mrow id="S5.SS1.p1.1.m1.2.3.3.2" xref="S5.SS1.p1.1.m1.2.3.3.1.cmml"><mn id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml">100</mn><mo id="S5.SS1.p1.1.m1.2.3.3.2.1" xref="S5.SS1.p1.1.m1.2.3.3.1.cmml">,</mo><mn id="S5.SS1.p1.1.m1.2.2" xref="S5.SS1.p1.1.m1.2.2.cmml">200</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.2b"><apply id="S5.SS1.p1.1.m1.2.3.cmml" xref="S5.SS1.p1.1.m1.2.3"><eq id="S5.SS1.p1.1.m1.2.3.1.cmml" xref="S5.SS1.p1.1.m1.2.3.1"></eq><ci id="S5.SS1.p1.1.m1.2.3.2.cmml" xref="S5.SS1.p1.1.m1.2.3.2">𝑁</ci><list id="S5.SS1.p1.1.m1.2.3.3.1.cmml" xref="S5.SS1.p1.1.m1.2.3.3.2"><cn id="S5.SS1.p1.1.m1.1.1.cmml" type="integer" xref="S5.SS1.p1.1.m1.1.1">100</cn><cn id="S5.SS1.p1.1.m1.2.2.cmml" type="integer" xref="S5.SS1.p1.1.m1.2.2">200</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.2c">N=100,200</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.1.m1.2d">italic_N = 100 , 200</annotation></semantics></math>, and <math alttext="500" class="ltx_Math" display="inline" id="S5.SS1.p1.2.m2.1"><semantics id="S5.SS1.p1.2.m2.1a"><mn id="S5.SS1.p1.2.m2.1.1" xref="S5.SS1.p1.2.m2.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.2.m2.1b"><cn id="S5.SS1.p1.2.m2.1.1.cmml" type="integer" xref="S5.SS1.p1.2.m2.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.2.m2.1c">500</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.2.m2.1d">500</annotation></semantics></math>, respectively.
The following findings can be concluded:</p>
<ul class="ltx_itemize" id="S5.I1">
<li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i1.p1">
<p class="ltx_p" id="S5.I1.i1.p1.1">Our model consistently outperforms the baseline on hard instances in most translation directions, for both BLEU and COMET metrics.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i2.p1">
<p class="ltx_p" id="S5.I1.i2.p1.1">Our model reaches competitive performance compared to the baseline for both BLEU and COMET.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i3.p1">
<p class="ltx_p" id="S5.I1.i3.p1.1">With increasing the number of sampled hard instances, the improvement gained by our model gets smaller.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="S5.SS1.p1.3">These results indicate that WAP mitigates hallucination and omission to a certain extent, because these issues are more likely to occur in hard instances. In addition, with the improvement in the hard instances, our model remains competitive to the baseline in the remaining easy instances. It is reasonable that there is no significant difference in the easy instances because the compared models are generally good. The challenging part should be in the hard ones.
Moreover, it is also observed that with increasing <math alttext="N" class="ltx_Math" display="inline" id="S5.SS1.p1.3.m1.1"><semantics id="S5.SS1.p1.3.m1.1a"><mi id="S5.SS1.p1.3.m1.1.1" xref="S5.SS1.p1.3.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.3.m1.1b"><ci id="S5.SS1.p1.3.m1.1.1.cmml" xref="S5.SS1.p1.3.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.3.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.3.m1.1d">italic_N</annotation></semantics></math>, the improvement gets narrower. The reason is that more relatively easy instances are included in the subset. This is another evidence that WAP provides gains particularly for hallucination and omission in MT. The specific numeric results and the overall results for the entire test set are shown in §<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#A2" title="Appendix B Specific results ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">B</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Direct evaluation of hallucination and omission by GPT-4</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">In addition to improving hard examples, which is more likely to have hallucination and omission, direct evaluations of them are also needed to confirm the effectiveness of the proposed WAP.
In §<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S4.SS3" title="4.3 The design of evaluation ‣ 4 Evaluation ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">4.3</span></a> we have verified the usefulness of GPT-4 as an evaluator with experiments. In this section, we prompt GPT-4 to directly predict a coverage score as the metric of hallucination and omission. The results are demonstrated in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S4.T2" title="Table 2 ‣ Is LLM really capable of evaluating hallucination and omission in MT? ‣ 4.3 The design of evaluation ‣ 4 Evaluation ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a>. The reported number is the average of the coverage scores in hard examples.
The results show that our model outperforms the baseline in all translation directions except <math alttext="en\leftrightarrow is" class="ltx_Math" display="inline" id="S5.SS2.p1.1.m1.1"><semantics id="S5.SS2.p1.1.m1.1a"><mrow id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml"><mrow id="S5.SS2.p1.1.m1.1.1.2" xref="S5.SS2.p1.1.m1.1.1.2.cmml"><mi id="S5.SS2.p1.1.m1.1.1.2.2" xref="S5.SS2.p1.1.m1.1.1.2.2.cmml">e</mi><mo id="S5.SS2.p1.1.m1.1.1.2.1" xref="S5.SS2.p1.1.m1.1.1.2.1.cmml">⁢</mo><mi id="S5.SS2.p1.1.m1.1.1.2.3" xref="S5.SS2.p1.1.m1.1.1.2.3.cmml">n</mi></mrow><mo id="S5.SS2.p1.1.m1.1.1.1" stretchy="false" xref="S5.SS2.p1.1.m1.1.1.1.cmml">↔</mo><mrow id="S5.SS2.p1.1.m1.1.1.3" xref="S5.SS2.p1.1.m1.1.1.3.cmml"><mi id="S5.SS2.p1.1.m1.1.1.3.2" xref="S5.SS2.p1.1.m1.1.1.3.2.cmml">i</mi><mo id="S5.SS2.p1.1.m1.1.1.3.1" xref="S5.SS2.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S5.SS2.p1.1.m1.1.1.3.3" xref="S5.SS2.p1.1.m1.1.1.3.3.cmml">s</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><apply id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1"><ci id="S5.SS2.p1.1.m1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1.1">↔</ci><apply id="S5.SS2.p1.1.m1.1.1.2.cmml" xref="S5.SS2.p1.1.m1.1.1.2"><times id="S5.SS2.p1.1.m1.1.1.2.1.cmml" xref="S5.SS2.p1.1.m1.1.1.2.1"></times><ci id="S5.SS2.p1.1.m1.1.1.2.2.cmml" xref="S5.SS2.p1.1.m1.1.1.2.2">𝑒</ci><ci id="S5.SS2.p1.1.m1.1.1.2.3.cmml" xref="S5.SS2.p1.1.m1.1.1.2.3">𝑛</ci></apply><apply id="S5.SS2.p1.1.m1.1.1.3.cmml" xref="S5.SS2.p1.1.m1.1.1.3"><times id="S5.SS2.p1.1.m1.1.1.3.1.cmml" xref="S5.SS2.p1.1.m1.1.1.3.1"></times><ci id="S5.SS2.p1.1.m1.1.1.3.2.cmml" xref="S5.SS2.p1.1.m1.1.1.3.2">𝑖</ci><ci id="S5.SS2.p1.1.m1.1.1.3.3.cmml" xref="S5.SS2.p1.1.m1.1.1.3.3">𝑠</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">en\leftrightarrow is</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.1.m1.1d">italic_e italic_n ↔ italic_i italic_s</annotation></semantics></math>. Specifically in the average score of all translation directions, WAP outperforms the baseline model by <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.1">4.96</span>, <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.2">1.63</span> and <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.3">1.24</span> when N=100, 200 and 500, respectively. The trend is similar to that of §<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S5.SS1" title="5.1 Evaluation on hard instances ‣ 5 Experimental results ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">5.1</span></a>, which directly indicates that the LLM-based MT model is steered to avoid generating hallucination and omission in MT with the preference dataset we constructed.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Human evaluation</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">Although the validity of GPT-4 as evaluator for hallucination and omission has been demonstrated in §<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S4.SS3" title="4.3 The design of evaluation ‣ 4 Evaluation ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">4.3</span></a> and Table <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S4.T1" title="Table 1 ‣ Select hard instances. ‣ 4.3 The design of evaluation ‣ 4 Evaluation ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a>, we conduct a human evaluation to further verify our findings, as LLM could still be unreliable. The subset of “N=100” on “zh-en” is selected. Three volunteers who speak Chinese and English are asked to assess the quality of the translation and the degree of hallucination and omission for the baseline and our model, without knowing which model generates the translations. Table <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S4.T3" title="Table 3 ‣ Is LLM really capable of evaluating hallucination and omission in MT? ‣ 4.3 The design of evaluation ‣ 4 Evaluation ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a> demonstrates the results. In general, our model generates better translation in 39.66% of the examples, while the percentage for ALMA is 11.33%. Furthermore, it is observed that with DPO on word-alignment preferred data fine-tuning, the degree of both hallucination and omission decreases. Specifically, the percentage of “no hallucination” increases from 64% to 75.66%, and that of “small, partial, and full hallucination” decreases accordingly. The decrease in omission is more distinct, in which the percentage of “no omission” increase by 24%. Notably, for both hallucination and omission, the percentage of “full hallucination and omission” has decreased to 0 for our model. These results indicate that omission is more frequent than hallucination, and WAP can mitigate hallucination and omission in LLM-based MT model like ALMA to some extent.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Ablation study</h3>
<figure class="ltx_figure" id="S5.F7">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F7.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="409" id="S5.F7.sf1.g1" src="x19.png" width="830"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Hard instances</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F7.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="409" id="S5.F7.sf2.g1" src="x20.png" width="830"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Easy instances</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Ablation study. Results in BLEU is demonstrated. Higher BLEU is better. For fair comparison the range of y-axis are the same for hard instances and easy instances. The result in COMET is in the same trend, which can be found in Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#A1.F8" title="Figure 8 ‣ A.2 Translation examples ‣ Appendix A Example analysis ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">8</span></a> in the Appendix.</figcaption>
</figure>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1">In this section, we conduct in-depth investigation for our word alignment preference, as we use the same training data as our baseline ALMA, i.e., human translation, but extra translations from DeepL and ChatGPT are included to conduct our preference data. To investigate where the improvement comes from, we introduce two variants without preference tuning to compare with WAP.</p>
<ul class="ltx_itemize" id="S5.I2">
<li class="ltx_item" id="S5.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I2.i1.p1">
<p class="ltx_p" id="S5.I2.i1.p1.1"><span class="ltx_text ltx_font_italic" id="S5.I2.i1.p1.1.1">FT_reject</span>: directly fine-tuning ALMA with the rejected translations in the dataset.</p>
</div>
</li>
<li class="ltx_item" id="S5.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I2.i2.p1">
<p class="ltx_p" id="S5.I2.i2.p1.1"><span class="ltx_text ltx_font_italic" id="S5.I2.i2.p1.1.1">FT_prefer</span>: directly fine-tuning ALMA with the preferred translations in the dataset.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="S5.SS4.p1.2">The comparison is demonstrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S5.F7" title="Figure 7 ‣ 5.4 Ablation study ‣ 5 Experimental results ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
<section class="ltx_paragraph" id="S5.SS4.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Does the preferred data really better contribute to the training?</h4>
<div class="ltx_para" id="S5.SS4.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS4.SSS0.Px1.p1.1">It is observed that <span class="ltx_text ltx_font_italic" id="S5.SS4.SSS0.Px1.p1.1.1">FT_prefer</span> significantly outperforms <span class="ltx_text ltx_font_italic" id="S5.SS4.SSS0.Px1.p1.1.2">FT_reject</span> in both hard and easy instances. This indicates that our proposed pipeline ensures that the samples are selected, leading to better translation quality.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS4.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Is the DPO preference tuning necessary?</h4>
<div class="ltx_para" id="S5.SS4.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS4.SSS0.Px2.p1.1">Particularly, the filled area demonstrates the necessity of preference tuning using DPO. In hard instances <span class="ltx_text ltx_font_italic" id="S5.SS4.SSS0.Px2.p1.1.1">FT_prefer</span> can reach a competitive performance with a small gap. However, in easy instances, <span class="ltx_text ltx_font_italic" id="S5.SS4.SSS0.Px2.p1.1.2">FT_prefer</span> largely underperforms WAP and ALMA, which limits the practicality of it. The possible reason for the different performance in the hard and easy instances is the direct fine-tuning. Directly fine-tuning on the preferred data without the comparison with rejected examples could cause a hard fitting to the word-aligned preference but ignore the general translation quality.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">The problem of hallucination and omission, a long-standing problem in MT, could become more severe when an LLM is used because an LLM itself could hallucinate or omit in nature.
In this paper, our aim is to mitigate this problem in LLM-based MT by optimizing the model toward a preference for better word alignment. We construct preference datasets by collecting translations using multiple MT tools and selecting the preferred translation with a higher coverage score output by a word aligner. DPO is then utilized to optimize the model towards the word-aligned preference. As evaluation of hallucination and omission is challenging, we design experiments that include selecting hard instances and using GPT-4 to directly predict coverage score, ensuring an effective evaluation. The experiments demonstrate that the proposed WAP mitigates hallucination and omission in ten translation directions, especially in hard instances.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Limitation</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">The primary limitation of our method stems from the imperfections of the word alignment model. Within our approach, it is inevitable to encounter some alignment errors, which we address through a filtering method. However, this solution adds complexity and clutter to the method. Additionally, the effectiveness of our method is diminished for low-resource language translations due to the limited number of parallel sentences available. Lastly, our reliance on the GPT-4 API to evaluate the results introduces a significant cost factor. We aim to find a cost-free alternative for this evaluation process in future work.</p>
</div>
</section>
<section class="ltx_section" id="Sx2">
<h2 class="ltx_title ltx_title_section">Ethical Statement</h2>
<div class="ltx_para" id="Sx2.p1">
<p class="ltx_p" id="Sx2.p1.1">All datasets and checkpoints used in this paper are copyright-free for research purposes. Previous studies are properly cited and discussed. This research aims to improve LLM-based machine translation models with word alignment preference data, and the preference is made by an automatic word aligner. We do not introduce additional bias to particular communities.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Achiam et al. (2023)</span>
<span class="ltx_bibblock">
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. 2023.

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2303.08774</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bahdanau et al. (2015)</span>
<span class="ltx_bibblock">
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/1409.0473" title="">Neural machine translation by jointly learning to align and translate</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bang et al. (2023)</span>
<span class="ltx_bibblock">
Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, et al. 2023.

</span>
<span class="ltx_bibblock">A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Proceedings of the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 675–718.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Barrault et al. (2020)</span>
<span class="ltx_bibblock">
Loïc Barrault, Magdalena Biesialska, Ondřej Bojar, Marta R. Costa-jussà, Christian Federmann, Yvette Graham, Roman Grundkiewicz, Barry Haddow, Matthias Huck, Eric Joanis, Tom Kocmi, Philipp Koehn, Chi-kiu Lo, Nikola Ljubešić, Christof Monz, Makoto Morishita, Masaaki Nagata, Toshiaki Nakazawa, Santanu Pal, Matt Post, and Marcos Zampieri. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2020.wmt-1.1" title="">Findings of the 2020 conference on machine translation (WMT20)</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proceedings of the Fifth Conference on Machine Translation</em>, pages 1–55, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bojar et al. (2017)</span>
<span class="ltx_bibblock">
Ondřej Bojar, Rajen Chatterjee, Christian Federmann, Yvette Graham, Barry Haddow, Shujian Huang, Matthias Huck, Philipp Koehn, Qun Liu, Varvara Logacheva, Christof Monz, Matteo Negri, Matt Post, Raphael Rubino, Lucia Specia, and Marco Turchi. 2017.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/W17-4717" title="">Findings of the 2017 conference on machine translation (WMT17)</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the Second Conference on Machine Translation</em>, pages 169–214, Copenhagen, Denmark. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al. (2020)</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf" title="">Language models are few-shot learners</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Advances in Neural Information Processing Systems</em>, volume 33, pages 1877–1901. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chi et al. (2021)</span>
<span class="ltx_bibblock">
Zewen Chi, Li Dong, Bo Zheng, Shaohan Huang, Xian-Ling Mao, Heyan Huang, and Furu Wei. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.acl-long.265" title="">Improving pretrained cross-lingual language models via self-labeled word alignment</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</em>, pages 3418–3430, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chousa et al. (2020)</span>
<span class="ltx_bibblock">
Katsuki Chousa, Masaaki Nagata, and Masaaki Nishino. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.coling-main.418" title="">SpanAlign: Sentence alignment method based on cross-language span prediction and ILP</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Proceedings of the 28th International Conference on Computational Linguistics</em>, pages 4750–4761, Barcelona, Spain (Online). International Committee on Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chung et al. (2024)</span>
<span class="ltx_bibblock">
Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. 2024.

</span>
<span class="ltx_bibblock">Scaling instruction-finetuned language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Journal of Machine Learning Research</em>, 25(70):1–53.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Costa-jussà et al. (2022)</span>
<span class="ltx_bibblock">
Marta R Costa-jussà, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi, Janice Lam, Daniel Licht, Jean Maillard, et al. 2022.

</span>
<span class="ltx_bibblock">No language left behind: Scaling human-centered machine translation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:2207.04672</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dale et al. (2023a)</span>
<span class="ltx_bibblock">
David Dale, Elena Voita, Loic Barrault, and Marta R. Costa-jussà. 2023a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.acl-long.3" title="">Detecting and mitigating hallucinations in machine translation: Model internal workings alone do well, sentence similarity Even better</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 36–50, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dale et al. (2023b)</span>
<span class="ltx_bibblock">
David Dale, Elena Voita, Janice Lam, Prangthip Hansanti, Christophe Ropers, Elahe Kalbassi, Cynthia Gao, Loic Barrault, and Marta Costa-jussà. 2023b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.emnlp-main.42" title="">HalOmi: A manually annotated benchmark for multilingual hallucination and omission detection in machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 638–653, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dhuliawala et al. (2023)</span>
<span class="ltx_bibblock">
Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu, Roberta Raileanu, Xian Li, Asli Celikyilmaz, and Jason Weston. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:262062565" title="">Chain-of-verification reduces hallucination in large language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">ArXiv</em>, abs/2309.11495.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dou and Neubig (2021)</span>
<span class="ltx_bibblock">
Zi-Yi Dou and Graham Neubig. 2021.

</span>
<span class="ltx_bibblock">Word alignment by fine-tuning embeddings on parallel corpora.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</em>, pages 2112–2128.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dyer et al. (2013)</span>
<span class="ltx_bibblock">
Chris Dyer, Victor Chahuneau, and Noah A Smith. 2013.

</span>
<span class="ltx_bibblock">A simple, fast, and effective reparameterization of ibm model 2.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pages 644–648.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng et al. (2022)</span>
<span class="ltx_bibblock">
Fangxiaoyu Feng, Yinfei Yang, Daniel Cer, Naveen Arivazhagan, and Wei Wang. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.acl-long.62" title="">Language-agnostic BERT sentence embedding</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 878–891, Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2021)</span>
<span class="ltx_bibblock">
Tianyu Gao, Xingcheng Yao, and Danqi Chen. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.emnlp-main.552" title="">SimCSE: Simple contrastive learning of sentence embeddings</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</em>, pages 6894–6910, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendy et al. (2023)</span>
<span class="ltx_bibblock">
Amr Hendy, Mohamed Abdelrehim, Amr Sharaf, Vikas Raunak, Mohamed Gabr, Hitokazu Matsushita, Young Jin Kim, Mohamed Afify, and Hany Hassan Awadalla. 2023.

</span>
<span class="ltx_bibblock">How good are gpt models at machine translation? a comprehensive evaluation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">arXiv preprint arXiv:2302.09210</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2021)</span>
<span class="ltx_bibblock">
Edward J Hu, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen, et al. 2021.

</span>
<span class="ltx_bibblock">Lora: Low-rank adaptation of large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jalili Sabet et al. (2020)</span>
<span class="ltx_bibblock">
Masoud Jalili Sabet, Philipp Dufter, François Yvon, and Hinrich Schütze. 2020.

</span>
<span class="ltx_bibblock">SimAlign: High quality word alignments without parallel training data using static and contextualized embeddings.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Findings of the Association for Computational Linguistics: EMNLP 2020</em>, pages 1627–1643, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kojima et al. (2022)</span>
<span class="ltx_bibblock">
Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022.

</span>
<span class="ltx_bibblock">Large language models are zero-shot reasoners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Advances in neural information processing systems</em>, 35:22199–22213.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023)</span>
<span class="ltx_bibblock">
Ziheng Li, Shaohan Huang, Zihan Zhang, Zhi-Hong Deng, Qiang Lou, Haizhen Huang, Jian Jiao, Furu Wei, Weiwei Deng, and Qi Zhang. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.acl-long.191" title="">Dual-alignment pre-training for cross-lingual sentence embedding</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 3466–3478, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Miao et al. (2024)</span>
<span class="ltx_bibblock">
Zhongtao Miao, Qiyu Wu, Kaiyan Zhao, Zilong Wu, and Yoshimasa Tsuruoka. 2024.

</span>
<span class="ltx_bibblock">Enhancing cross-lingual sentence embedding for low-resource languages with word alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">arXiv preprint arXiv:2404.02490</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mitchell et al. (2023)</span>
<span class="ltx_bibblock">
Eric Mitchell, Yoonho Lee, Alexander Khazatsky, Christopher D. Manning, and Chelsea Finn. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:256274849" title="">Detectgpt: Zero-shot machine-generated text detection using probability curvature</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">International Conference on Machine Learning</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nagata et al. (2020)</span>
<span class="ltx_bibblock">
Masaaki Nagata, Katsuki Chousa, and Masaaki Nishino. 2020.

</span>
<span class="ltx_bibblock">A supervised word alignment method based on cross-language span prediction using multilingual bert.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, pages 555–565.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Och and Ney (2003)</span>
<span class="ltx_bibblock">
Franz Josef Och and Hermann Ney. 2003.

</span>
<span class="ltx_bibblock">A systematic comparison of various statistical alignment models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Computational linguistics</em>, 29(1):19–51.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et al. (2022)</span>
<span class="ltx_bibblock">
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F Christiano, Jan Leike, and Ryan Lowe. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf" title="">Training language models to follow instructions with human feedback</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Advances in Neural Information Processing Systems</em>, volume 35, pages 27730–27744. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papineni et al. (2002)</span>
<span class="ltx_bibblock">
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.3115/1073083.1073135" title="">Bleu: a method for automatic evaluation of machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</em>, pages 311–318, Philadelphia, Pennsylvania, USA. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. (2019)</span>
<span class="ltx_bibblock">
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019.

</span>
<span class="ltx_bibblock">Language models are unsupervised multitask learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">OpenAI blog</em>, 1(8):9.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rafailov et al. (2024)</span>
<span class="ltx_bibblock">
Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher D Manning, Stefano Ermon, and Chelsea Finn. 2024.

</span>
<span class="ltx_bibblock">Direct preference optimization: Your language model is secretly a reward model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Advances in Neural Information Processing Systems</em>, 36.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schulman et al. (2017)</span>
<span class="ltx_bibblock">
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. 2017.

</span>
<span class="ltx_bibblock">Proximal policy optimization algorithms.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">arXiv preprint arXiv:1707.06347</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">arXiv preprint arXiv:2307.09288</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tu et al. (2016)</span>
<span class="ltx_bibblock">
Zhaopeng Tu, Zhengdong Lu, Yang Liu, Xiaohua Liu, and Hang Li. 2016.

</span>
<span class="ltx_bibblock">Modeling coverage for neural machine translation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 76–85.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tunstall et al. (2023)</span>
<span class="ltx_bibblock">
Lewis Tunstall, Edward Beeching, Nathan Lambert, Nazneen Rajani, Kashif Rasul, Younes Belkada, Shengyi Huang, Leandro von Werra, Clémentine Fourrier, Nathan Habib, Nathan Sarrazin, Omar Sanseviero, Alexander M. Rush, and Thomas Wolf. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:264490502" title="">Zephyr: Direct distillation of lm alignment</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">ArXiv</em>, abs/2310.16944.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vamvas and Sennrich (2022)</span>
<span class="ltx_bibblock">
Jannis Vamvas and Rico Sennrich. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.acl-short.53" title="">As little as possible, as much as necessary: Detecting over- and undertranslations with contrastive conditioning</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</em>, pages 490–500, Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2022)</span>
<span class="ltx_bibblock">
Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, and Quoc V Le. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=gEZrGCozdqR" title="">Finetuned language models are zero-shot learners</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2023)</span>
<span class="ltx_bibblock">
Xiang Wei, Xingyu Cui, Ning Cheng, Xiaobin Wang, Xin Zhang, Shen Huang, Pengjun Xie, Jinan Xu, Yufeng Chen, Meishan Zhang, Yong Jiang, and Wenjuan Han. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:257050669" title="">Zero-shot information extraction via chatting with chatgpt</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">ArXiv</em>, abs/2302.10205.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2023)</span>
<span class="ltx_bibblock">
Qiyu Wu, Masaaki Nagata, and Yoshimasa Tsuruoka. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.acl-long.621" title="">WSPAlign: Word alignment pre-training via large-scale weakly supervised span prediction</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 11084–11099, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2022)</span>
<span class="ltx_bibblock">
Qiyu Wu, Chongyang Tao, Tao Shen, Can Xu, Xiubo Geng, and Daxin Jiang. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.emnlp-main.826" title="">PCL: Peer-contrastive learning with diverse augmentations for unsupervised sentence embeddings</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</em>, pages 12052–12066, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2021)</span>
<span class="ltx_bibblock">
Qiyu Wu, Chen Xing, Yatao Li, Guolin Ke, Di He, and Tie-Yan Liu. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:235613669" title="">Taking notes on the fly helps language pre-training</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2024a)</span>
<span class="ltx_bibblock">
Haoran Xu, Young Jin Kim, Amr Sharaf, and Hany Hassan Awadalla. 2024a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=farT6XXntP" title="">A paradigm shift in machine translation: Boosting translation performance of large language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">The Twelfth International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2024b)</span>
<span class="ltx_bibblock">
Haoran Xu, Amr Sharaf, Yunmo Chen, Weiting Tan, Lingfeng Shen, Benjamin Van Durme, Kenton Murray, and Young Jin Kim. 2024b.

</span>
<span class="ltx_bibblock">Contrastive preference optimization: Pushing the boundaries of llm performance in machine translation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">arXiv preprint arXiv:2401.08417</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2023a)</span>
<span class="ltx_bibblock">
Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang, Yulong Chen, Longyue Wang, Anh Tuan Luu, Wei Bi, Freda Shi, and Shuming Shi. 2023a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:261530162" title="">Siren’s song in the ai ocean: A survey on hallucination in large language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">ArXiv</em>, abs/2309.01219.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2023b)</span>
<span class="ltx_bibblock">
Zhen-Ru Zhang, Chuanqi Tan, Songfang Huang, and Fei Huang. 2023b.

</span>
<span class="ltx_bibblock">Veco 2.0: Cross-lingual language model pre-training with multi-granularity contrastive learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">arXiv preprint arXiv:2304.08205</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2024)</span>
<span class="ltx_bibblock">
Kaiyan Zhao, Qiyu Wu, Xin-Qiang Cai, and Yoshimasa Tsuruoka. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2024.eacl-long.59" title="">Leveraging multi-lingual positive instances in contrastive learning to improve sentence embedding</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 976–991, St. Julian’s, Malta. Association for Computational Linguistics.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Example analysis</h2>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Examples of the preference dataset</h3>
<figure class="ltx_table" id="A1.T4">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A1.T4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T4.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t" colspan="2" id="A1.T4.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.T4.1.1.1.1.1">Example 1 (Chinese-English)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T4.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T4.1.2.1.1">source</th>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A1.T4.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T4.1.2.1.2.1"><span class="ltx_ERROR undefined" id="A1.T4.1.2.1.2.1.1">{CJK*}</span>
<span class="ltx_p" id="A1.T4.1.2.1.2.1.2">UTF8gbsn“我想，在考虑重播时，可以解决这个问题”，Coker 说道。</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T4.1.3.2.1">chosen (gpt-3.5)</th>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A1.T4.1.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T4.1.3.2.2.1">
<span class="ltx_p" id="A1.T4.1.3.2.2.1.1">"I think, when considering replay, this issue can be resolved," Coker said.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T4.1.4.3.1">rejected (human)</th>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A1.T4.1.4.3.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T4.1.4.3.2.1">
<span class="ltx_p" id="A1.T4.1.4.3.2.1.1">"<span class="ltx_text" id="A1.T4.1.4.3.2.1.1.1" style="color:#FF0000;">&lt;&lt;&lt;I think that when I think about&gt;&gt;&gt;</span> the replay, <span class="ltx_text" id="A1.T4.1.4.3.2.1.1.2" style="color:#FF0000;">&lt;&lt;&lt;I think that&gt;&gt;&gt;</span> we can probably work it out," Coker said.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.5.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" colspan="2" id="A1.T4.1.5.4.1"><span class="ltx_text ltx_font_bold" id="A1.T4.1.5.4.1.1">Example 2 (Chinese-English)</span></th>
</tr>
<tr class="ltx_tr" id="A1.T4.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T4.1.6.5.1">source</th>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A1.T4.1.6.5.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T4.1.6.5.2.1"><span class="ltx_ERROR undefined" id="A1.T4.1.6.5.2.1.1">{CJK*}</span>
<span class="ltx_p" id="A1.T4.1.6.5.2.1.2">UTF8gbsn<span class="ltx_text" id="A1.T4.1.6.5.2.1.2.1" style="color:#FF0000;">&lt;&lt;&lt;富勒&gt;&gt;&gt;</span>在政变图谋失败后</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T4.1.7.6.1">chosen (deepl)</th>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A1.T4.1.7.6.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T4.1.7.6.2.1">
<span class="ltx_p" id="A1.T4.1.7.6.2.1.1"><span class="ltx_text" id="A1.T4.1.7.6.2.1.1.1" style="color:#0000FF;">&lt;&lt;&lt;Fuller&gt;&gt;&gt;</span> after the failed coup attempt</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T4.1.8.7.1">rejected (human)</th>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A1.T4.1.8.7.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T4.1.8.7.2.1">
<span class="ltx_p" id="A1.T4.1.8.7.2.1.1">After the failure of the attempted coup,</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.9.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" colspan="2" id="A1.T4.1.9.8.1"><span class="ltx_text ltx_font_bold" id="A1.T4.1.9.8.1.1">Example 3 (English-Chinese)</span></th>
</tr>
<tr class="ltx_tr" id="A1.T4.1.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T4.1.10.9.1">source</th>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A1.T4.1.10.9.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T4.1.10.9.2.1">
<span class="ltx_p" id="A1.T4.1.10.9.2.1.1"><span class="ltx_text" id="A1.T4.1.10.9.2.1.1.1" style="color:#FF0000;">&lt;&lt;&lt;Originally a one-bedroom property with a convoluted layout - you had to walk through the kitchen to get to the bedroom&gt;&gt;&gt;</span> - Joanne wanted to add storage space and a mezzanine to make the most of the generous ceiling height.’</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.11.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T4.1.11.10.1">chosen (gpt-3.5)</th>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A1.T4.1.11.10.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T4.1.11.10.2.1"><span class="ltx_ERROR undefined" id="A1.T4.1.11.10.2.1.1">{CJK*}</span>
<span class="ltx_p" id="A1.T4.1.11.10.2.1.2">UTF8gbsn <span class="ltx_text" id="A1.T4.1.11.10.2.1.2.1" style="color:#0000FF;">&lt;&lt;&lt;最初是一个一居室的房产，布局错综复杂 - 你必须穿过厨房才能到达卧室&gt;&gt;&gt;</span> - 然而乔安妮想要增加存储空间和一个夹层，以充分利用宽敞的天花板高度。</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.12.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="A1.T4.1.12.11.1">rejected (deepl)</th>
<td class="ltx_td ltx_align_justify ltx_border_b ltx_border_t" id="A1.T4.1.12.11.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T4.1.12.11.2.1"><span class="ltx_ERROR undefined" id="A1.T4.1.12.11.2.1.1">{CJK*}</span>
<span class="ltx_p" id="A1.T4.1.12.11.2.1.2">UTF8gbsn 乔安妮希望增加储藏空间和一个夹层，充分利用宽敞的天花板高度。</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Examples in the preference dataset. The hallucination in rejected examples and omission in the source sentence are highlighted with <span class="ltx_text" id="A1.T4.4.1" style="color:#FF0000;">&lt;&lt;&lt;<span class="ltx_text ltx_font_italic" id="A1.T4.4.1.1"> </span>&gt;&gt;&gt;</span>. The corresponding contents that are omitted in the rejected example are highlighted with <span class="ltx_text" id="A1.T4.5.2" style="color:#0000FF;">&lt;&lt;&lt;<span class="ltx_text ltx_font_italic" id="A1.T4.5.2.1"> </span>&gt;&gt;&gt;</span> in the chosen example. </figcaption>
</figure>
<div class="ltx_para" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#A1.T4" title="Table 4 ‣ A.1 Examples of the preference dataset ‣ Appendix A Example analysis ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">4</span></a> includes three examples in our dataset, in which the source sentence, the chosen and rejected translations are shown. Refer to §<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S3.SS4" title="3.4 Details of dataset ‣ 3 Proposed approach ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">3.4</span></a> for a detailed construction of the dataset. <span class="ltx_text ltx_font_bold" id="A1.SS1.p1.1.1">Example 1</span>: the rejected translation is from human annotation, in which it repeats the term of “I think” unnaturally. The possible reason could be the resource of the parallel data, e.g., direct collection from transcriptions. <span class="ltx_text ltx_font_bold" id="A1.SS1.p1.1.2">Example 2</span>: “Fuller” is omitted by human annotation while translated by DeepL. <span class="ltx_text ltx_font_bold" id="A1.SS1.p1.1.3">Example 3</span>: the chosen translation is from gpt-3.5-turbo that completely translates the source sentence. In contrast, the translation by DeepL omits the first half.</p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Translation examples</h3>
<figure class="ltx_table" id="A1.T5">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A1.T5.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T5.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="2" id="A1.T5.1.1.1.1">
<span class="ltx_text ltx_font_bold" id="A1.T5.1.1.1.1.1">Example 1 (English-Chinese</span>)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T5.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T5.1.2.1.1">Source</th>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A1.T5.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T5.1.2.1.2.1">
<span class="ltx_p" id="A1.T5.1.2.1.2.1.1">Sunday Best: Enter 1880s New York <span class="ltx_text" id="A1.T5.1.2.1.2.1.1.1" style="color:#FF0000;">&lt;&lt;&lt;in HBO’s "The Gilded Age"&gt;&gt;&gt;</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T5.1.3.2.1">Translation (Baseline)</th>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A1.T5.1.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T5.1.3.2.2.1"><span class="ltx_ERROR undefined" id="A1.T5.1.3.2.2.1.1">{CJK*}</span>
<span class="ltx_p" id="A1.T5.1.3.2.2.1.2">UTF8gbsn周日最佳：进入 1880 年代的纽约</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T5.1.4.3.1">Translation (Ours)</th>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A1.T5.1.4.3.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T5.1.4.3.2.1"><span class="ltx_ERROR undefined" id="A1.T5.1.4.3.2.1.1">{CJK*}</span>
<span class="ltx_p" id="A1.T5.1.4.3.2.1.2">UTF8gbsn周日最佳：进入 1880 年代的纽约 <span class="ltx_text" id="A1.T5.1.4.3.2.1.2.1" style="color:#0000FF;">&lt;&lt;&lt;，在 HBO 的《金碧辉煌时代》&gt;&gt;&gt;</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.5.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt" colspan="2" id="A1.T5.1.5.4.1"><span class="ltx_text ltx_font_bold" id="A1.T5.1.5.4.1.1">Example 2 (English-Chinese)</span></th>
</tr>
<tr class="ltx_tr" id="A1.T5.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T5.1.6.5.1">Source</th>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A1.T5.1.6.5.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T5.1.6.5.2.1">
<span class="ltx_p" id="A1.T5.1.6.5.2.1.1">Liner Fastening and Hanging Tabs Inner tabs are provided to keep a loose liner in position, corresponding in position with the tabs we provide on our liners.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T5.1.7.6.1">Translation (Baseline)</th>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A1.T5.1.7.6.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T5.1.7.6.2.1"><span class="ltx_ERROR undefined" id="A1.T5.1.7.6.2.1.1">{CJK*}</span>
<span class="ltx_p" id="A1.T5.1.7.6.2.1.2">UTF8gbsn粘贴和悬挂<span class="ltx_text" id="A1.T5.1.7.6.2.1.2.1" style="color:#FF0000;">&lt;&lt;&lt;卡扣的内部卡扣用于保持卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣卡扣&gt;&gt;&gt;</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T5.1.8.7.1">Translation (Ours)</th>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A1.T5.1.8.7.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T5.1.8.7.2.1"><span class="ltx_ERROR undefined" id="A1.T5.1.8.7.2.1.1">{CJK*}</span>
<span class="ltx_p" id="A1.T5.1.8.7.2.1.2">UTF8gbsn内固定和悬挂标签内固定和悬挂标签用于保持薄膜在位，与我们提供的标签对应。</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.9.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt" colspan="2" id="A1.T5.1.9.8.1"><span class="ltx_text ltx_font_bold" id="A1.T5.1.9.8.1.1">Example 3 (Chinese-English)</span></th>
</tr>
<tr class="ltx_tr" id="A1.T5.1.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T5.1.10.9.1">Source</th>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A1.T5.1.10.9.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T5.1.10.9.2.1"><span class="ltx_ERROR undefined" id="A1.T5.1.10.9.2.1.1">{CJK*}</span>
<span class="ltx_p" id="A1.T5.1.10.9.2.1.2">UTF8gbsn不知道要<span class="ltx_text" id="A1.T5.1.10.9.2.1.2.1" style="color:#FF0000;">&lt;&lt;&lt;等到什么时候&gt;&gt;&gt;</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.11.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T5.1.11.10.1">Translation (Baseline)</th>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A1.T5.1.11.10.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T5.1.11.10.2.1">
<span class="ltx_p" id="A1.T5.1.11.10.2.1.1">I don’t know when</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.12.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="A1.T5.1.12.11.1">Translation (Ours)</th>
<td class="ltx_td ltx_align_justify ltx_border_b ltx_border_t" id="A1.T5.1.12.11.2">
<span class="ltx_inline-block ltx_align_top" id="A1.T5.1.12.11.2.1">
<span class="ltx_p" id="A1.T5.1.12.11.2.1.1">I don’t know <span class="ltx_text" id="A1.T5.1.12.11.2.1.1.1" style="color:#0000FF;">&lt;&lt;&lt;how long I have to wait&gt;&gt;&gt;</span></span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>Translation Examples. The hallucination in translation by the baseline and the omission in the source sentence are highlighted with <span class="ltx_text" id="A1.T5.4.1" style="color:#FF0000;">&lt;&lt;&lt;<span class="ltx_text ltx_font_italic" id="A1.T5.4.1.1"> </span>&gt;&gt;&gt;</span>. The corresponding contents that are omitted from the baseline are highlighted with <span class="ltx_text" id="A1.T5.5.2" style="color:#0000FF;">&lt;&lt;&lt; &gt;&gt;&gt;</span> in our translation. </figcaption>
</figure>
<div class="ltx_para" id="A1.SS2.p1">
<p class="ltx_p" id="A1.SS2.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#A1.T5" title="Table 5 ‣ A.2 Translation examples ‣ Appendix A Example analysis ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">5</span></a> shows illustrative comparison between translations from the baseline and our model. <span class="ltx_text ltx_font_bold" id="A1.SS2.p1.1.1">Example 1</span>: “in HBO’s ’The Gilded Age’" in the source sentence is omitted by the baseline. In contrast, our model successfully translate the corresponding part into Chinese. <span class="ltx_text ltx_font_bold" id="A1.SS2.p1.1.2">Example 2</span>: the baseline generates “<span class="ltx_ERROR undefined" id="A1.SS2.p1.1.3">{CJK*}</span>UTF8gbsn卡扣 (fastening)” infinitely in translation. This type of hallucination also occurs in other LLM applications, which emphasizes the need to address the hallucination issue in LLM-based MT models. <span class="ltx_text ltx_font_bold" id="A1.SS2.p1.1.4">Example 3</span>: “<span class="ltx_ERROR undefined" id="A1.SS2.p1.1.5">{CJK*}</span>UTF8gbsn等到什么时候 (when to wait)” is omitted by the baseline model while our model translate that into “how long I have to wait” properly.</p>
</div>
<figure class="ltx_figure" id="A1.F8">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A1.F8.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="420" id="A1.F8.sf1.g1" src="x21.png" width="831"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Hard instances</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A1.F8.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="420" id="A1.F8.sf2.g1" src="x22.png" width="831"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Easy instances</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Ablation study. Results in COMET is demonstrated. Higher COMET is better. For fair comparison the range of y-axis are the same for hard instances and easy instances. Refer to §<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S5.SS4" title="5.4 Ablation study ‣ 5 Experimental results ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">5.4</span></a> for discussion.
</figcaption>
</figure>
</section>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Specific results</h2>
<figure class="ltx_table" id="A2.T6">
<div class="ltx_inline-block ltx_transformed_outer" id="A2.T6.3" style="width:433.6pt;height:645.7pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-19.2pt,28.6pt) scale(0.918468964570368,0.918468964570368) ;">
<table class="ltx_tabular ltx_align_middle" id="A2.T6.3.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T6.3.1.1.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.3.1.1.1.1">Model-Metric</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.3.1.1.1.2">de-en</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.3.1.1.1.3">cs-en</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.3.1.1.1.4">is-en</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.3.1.1.1.5">zh-en</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.3.1.1.1.6">ru-en</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.3.1.1.1.7">en-de</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.3.1.1.1.8">en-cs</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.3.1.1.1.9">en-is</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.3.1.1.1.10">en-zh</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.3.1.1.1.11">en-ru</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T6.3.1.1.1.12">Avg.</td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.2.2">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="11" id="A2.T6.3.1.2.2.1"><span class="ltx_text ltx_font_italic" id="A2.T6.3.1.2.2.1.1">N=100</span></td>
<td class="ltx_td ltx_border_t" id="A2.T6.3.1.2.2.2"></td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.3.3">
<td class="ltx_td ltx_align_center" colspan="11" id="A2.T6.3.1.3.3.1"><span class="ltx_text ltx_font_italic" id="A2.T6.3.1.3.3.1.1">Easy instances</span></td>
<td class="ltx_td" id="A2.T6.3.1.3.3.2"></td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.4.4">
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.4.4.1">ALMA-BLEU</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.4.4.2" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.4.4.2.1" style="background-color:#80FFFF;">31.38</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.4.4.3">45.79</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.4.4.4" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.4.4.4.1" style="background-color:#80FFFF;">38.14</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.4.4.5">25.64</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.4.4.6">41.25</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.4.4.7">32.09</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.4.4.8">31.95</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.4.4.9" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.4.4.9.1" style="background-color:#FF8080;">27.57</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.4.4.10">40.05</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.4.4.11">29.37</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.4.4.12">31.39</td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.5.5">
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.5.5.1">Ours-BLEU</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.5.5.2" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.5.5.2.1" style="background-color:#80FFFF;">32.50</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.5.5.3">46.32</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.5.5.4" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.5.5.4.1" style="background-color:#80FFFF;">40.13</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.5.5.5">25.23</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.5.5.6">40.80</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.5.5.7">31.22</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.5.5.8">31.55</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.5.5.9" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.5.5.9.1" style="background-color:#FF8080;">26.00</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.5.5.10">39.55</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.5.5.11">29.01</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.5.5.12">31.33</td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.6.6">
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.6.6.1">ALMA-COMET</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.6.6.2">85.57</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.6.6.3">87.71</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.6.6.4">87.82</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.6.6.5">81.38</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.6.6.6">86.26</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.6.6.7">86.84</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.6.6.8" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.6.6.8.1" style="background-color:#FF8080;">90.90</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.6.6.9" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.6.6.9.1" style="background-color:#FF8080;">87.61</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.6.6.10">87.14</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.6.6.11">88.80</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.6.6.12">78.12</td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.7.7">
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.7.7.1">Ours-COMET</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.7.7.2">85.50</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.7.7.3">87.67</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.7.7.4">87.71</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.7.7.5">81.24</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.7.7.6">86.17</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.7.7.7">86.02</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.7.7.8" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.7.7.8.1" style="background-color:#FF8080;">89.84</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.7.7.9" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.7.7.9.1" style="background-color:#FF8080;">85.80</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.7.7.10">86.39</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.7.7.11">87.89</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.7.7.12">77.63</td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.8.8">
<td class="ltx_td ltx_align_center" colspan="11" id="A2.T6.3.1.8.8.1"><span class="ltx_text ltx_font_italic" id="A2.T6.3.1.8.8.1.1">Hard instances</span></td>
<td class="ltx_td" id="A2.T6.3.1.8.8.2"></td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.9.9">
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.9.9.1">ALMA-BLEU</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.9.9.2" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.9.9.2.1" style="background-color:#80FFFF;">12.25</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.9.9.3" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.9.9.3.1" style="background-color:#80FFFF;">29.49</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.9.9.4" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.9.9.4.1" style="background-color:#80FFFF;">21.72</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.9.9.5" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.9.9.5.1" style="background-color:#80FFFF;">1.95</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.9.9.6" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.9.9.6.1" style="background-color:#80FFFF;">15.73</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.9.9.7">15.71</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.9.9.8" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.9.9.8.1" style="background-color:#80FFFF;">12.79</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.9.9.9">17.51</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.9.9.10" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.9.9.10.1" style="background-color:#80FFFF;">14.59</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.9.9.11">15.45</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.9.9.12" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.9.9.12.1" style="background-color:#80FFFF;">14.17</span></td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.10.10">
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.10.10.1">Ours-BLEU</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.10.10.2" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.10.10.2.1" style="background-color:#80FFFF;">15.56</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.10.10.3" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.10.10.3.1" style="background-color:#80FFFF;">35.93</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.10.10.4" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.10.10.4.1" style="background-color:#80FFFF;">27.72</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.10.10.5" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.10.10.5.1" style="background-color:#80FFFF;">4.62</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.10.10.6" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.10.10.6.1" style="background-color:#80FFFF;">19.77</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.10.10.7">16.15</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.10.10.8" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.10.10.8.1" style="background-color:#80FFFF;">16.67</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.10.10.9">17.13</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.10.10.10" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.10.10.10.1" style="background-color:#80FFFF;">19.49</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.10.10.11">15.54</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.10.10.12" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.10.10.12.1" style="background-color:#80FFFF;">17.30</span></td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.11.11">
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.11.11.1">ALMA-COMET</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.11.11.2" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.11.11.2.1" style="background-color:#80FFFF;">62.73</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.11.11.3" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.11.11.3.1" style="background-color:#80FFFF;">67.08</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.11.11.4" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.11.11.4.1" style="background-color:#80FFFF;">72.62</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.11.11.5" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.11.11.5.1" style="background-color:#80FFFF;">49.94</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.11.11.6" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.11.11.6.1" style="background-color:#80FFFF;">62.64</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.11.11.7" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.11.11.7.1" style="background-color:#80FFFF;">58.50</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.11.11.8" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.11.11.8.1" style="background-color:#80FFFF;">60.80</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.11.11.9" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.11.11.9.1" style="background-color:#80FFFF;">70.02</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.11.11.10" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.11.11.10.1" style="background-color:#80FFFF;">59.07</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.11.11.11" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.11.11.11.1" style="background-color:#80FFFF;">62.31</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.11.11.12" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.11.11.12.1" style="background-color:#80FFFF;">56.34</span></td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.12.12">
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.12.12.1">Ours-COMET</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.12.12.2" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.12.12.2.1" style="background-color:#80FFFF;">65.98</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.12.12.3" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.12.12.3.1" style="background-color:#80FFFF;">71.16</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.12.12.4" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.12.12.4.1" style="background-color:#80FFFF;">75.12</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.12.12.5" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.12.12.5.1" style="background-color:#80FFFF;">58.99</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.12.12.6" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.12.12.6.1" style="background-color:#80FFFF;">67.19</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.12.12.7" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.12.12.7.1" style="background-color:#80FFFF;">60.90</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.12.12.8" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.12.12.8.1" style="background-color:#80FFFF;">67.90</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.12.12.9" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.12.12.9.1" style="background-color:#80FFFF;">71.57</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.12.12.10" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.12.12.10.1" style="background-color:#80FFFF;">62.03</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.12.12.11" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.12.12.11.1" style="background-color:#80FFFF;">65.16</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.12.12.12" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.12.12.12.1" style="background-color:#80FFFF;">60.08</span></td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.13.13">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="11" id="A2.T6.3.1.13.13.1"><span class="ltx_text ltx_font_italic" id="A2.T6.3.1.13.13.1.1">N=200</span></td>
<td class="ltx_td ltx_border_t" id="A2.T6.3.1.13.13.2"></td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.14.14">
<td class="ltx_td ltx_align_center" colspan="11" id="A2.T6.3.1.14.14.1"><span class="ltx_text ltx_font_italic" id="A2.T6.3.1.14.14.1.1">Easy instances</span></td>
<td class="ltx_td" id="A2.T6.3.1.14.14.2"></td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.15.15">
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.15.15.1">ALMA-BLEU</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.15.15.2" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.15.15.2.1" style="background-color:#80FFFF;">31.96</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.15.15.3">47.11</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.15.15.4">39.94</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.15.15.5">26.22</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.15.15.6">42.13</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.15.15.7">32.50</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.15.15.8">32.75</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.15.15.9" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.15.15.9.1" style="background-color:#FF8080;">28.54</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.15.15.10">41.08</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.15.15.11">30.22</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.15.15.12">32.22</td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.16.16">
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.16.16.1">Ours-BLEU</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.16.16.2" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.16.16.2.1" style="background-color:#80FFFF;">33.10</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.16.16.3">47.41</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.16.16.4">41.60</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.16.16.5">25.79</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.16.16.6">41.43</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.16.16.7">31.52</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.16.16.8">32.20</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.16.16.9" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.16.16.9.1" style="background-color:#FF8080;">26.91</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.16.16.10">40.48</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.16.16.11">29.79</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.16.16.12">32.04</td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.17.17">
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.17.17.1">ALMA-COMET</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.17.17.2">86.34</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.17.17.3">88.61</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.17.17.4">88.72</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.17.17.5">82.31</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.17.17.6">87.02</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.17.17.7" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.17.17.7.1" style="background-color:#FF8080;">87.76</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.17.17.8" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.17.17.8.1" style="background-color:#FF8080;">91.85</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.17.17.9" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.17.17.9.1" style="background-color:#FF8080;">88.67</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.17.17.10">87.97</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.17.17.11">89.67</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.17.17.12">78.92</td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.18.18">
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.18.18.1">Ours-COMET</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.18.18.2">86.16</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.18.18.3">88.40</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.18.18.4">88.43</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.18.18.5">81.98</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.18.18.6">86.89</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.18.18.7" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.18.18.7.1" style="background-color:#FF8080;">86.75</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.18.18.8" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.18.18.8.1" style="background-color:#FF8080;">90.77</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.18.18.9" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.18.18.9.1" style="background-color:#FF8080;">86.94</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.18.18.10">87.12</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.18.18.11">88.73</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.18.18.12">78.34</td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.19.19">
<td class="ltx_td ltx_align_center" colspan="11" id="A2.T6.3.1.19.19.1"><span class="ltx_text ltx_font_italic" id="A2.T6.3.1.19.19.1.1">Hard instances</span></td>
<td class="ltx_td" id="A2.T6.3.1.19.19.2"></td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.20.20">
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.20.20.1">ALMA-BLEU</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.20.20.2" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.20.20.2.1" style="background-color:#80FFFF;">17.46</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.20.20.3" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.20.20.3.1" style="background-color:#80FFFF;">30.39</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.20.20.4" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.20.20.4.1" style="background-color:#80FFFF;">24.17</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.20.20.5" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.20.20.5.1" style="background-color:#80FFFF;">6.00</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.20.20.6" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.20.20.6.1" style="background-color:#80FFFF;">20.03</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.20.20.7">19.11</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.20.20.8" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.20.20.8.1" style="background-color:#80FFFF;">14.83</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.20.20.9">19.02</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.20.20.10" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.20.20.10.1" style="background-color:#80FFFF;">18.61</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.20.20.11">15.43</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.20.20.12" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.20.20.12.1" style="background-color:#80FFFF;">16.96</span></td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.21.21">
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.21.21.1">Ours-BLEU</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.21.21.2" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.21.21.2.1" style="background-color:#80FFFF;">19.31</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.21.21.3" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.21.21.3.1" style="background-color:#80FFFF;">35.04</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.21.21.4" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.21.21.4.1" style="background-color:#80FFFF;">29.25</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.21.21.5" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.21.21.5.1" style="background-color:#80FFFF;">7.55</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.21.21.6" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.21.21.6.1" style="background-color:#80FFFF;">23.70</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.21.21.7">19.96</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.21.21.8" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.21.21.8.1" style="background-color:#80FFFF;">18.16</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.21.21.9">18.29</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.21.21.10" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.21.21.10.1" style="background-color:#80FFFF;">21.52</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.21.21.11">15.95</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.21.21.12" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.21.21.12.1" style="background-color:#80FFFF;">19.28</span></td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.22.22">
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.22.22.1">ALMA-COMET</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.22.22.2" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.22.22.2.1" style="background-color:#80FFFF;">67.24</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.22.22.3" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.22.22.3.1" style="background-color:#80FFFF;">71.82</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.22.22.4" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.22.22.4.1" style="background-color:#80FFFF;">76.62</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.22.22.5" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.22.22.5.1" style="background-color:#80FFFF;">57.84</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.22.22.6" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.22.22.6.1" style="background-color:#80FFFF;">67.59</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.22.22.7" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.22.22.7.1" style="background-color:#80FFFF;">64.30</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.22.22.8" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.22.22.8.1" style="background-color:#80FFFF;">67.13</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.22.22.9">74.56</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.22.22.10">65.46</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.22.22.11" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.22.22.11.1" style="background-color:#80FFFF;">67.59</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.22.22.12" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.22.22.12.1" style="background-color:#80FFFF;">61.26</span></td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.23.23">
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.23.23.1">Ours-COMET</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.23.23.2" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.23.23.2.1" style="background-color:#80FFFF;">69.85</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.23.23.3" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.23.23.3.1" style="background-color:#80FFFF;">74.82</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.23.23.4" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.23.23.4.1" style="background-color:#80FFFF;">78.52</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.23.23.5" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.23.23.5.1" style="background-color:#80FFFF;">63.87</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.23.23.6" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.23.23.6.1" style="background-color:#80FFFF;">70.22</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.23.23.7" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.23.23.7.1" style="background-color:#80FFFF;">66.77</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.23.23.8" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.23.23.8.1" style="background-color:#80FFFF;">70.37</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.23.23.9">74.13</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.23.23.10">67.50</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.23.23.11" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.23.23.11.1" style="background-color:#80FFFF;">68.78</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.23.23.12" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.23.23.12.1" style="background-color:#80FFFF;">63.60</span></td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.24.24">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="11" id="A2.T6.3.1.24.24.1"><span class="ltx_text ltx_font_italic" id="A2.T6.3.1.24.24.1.1">N=500</span></td>
<td class="ltx_td ltx_border_t" id="A2.T6.3.1.24.24.2"></td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.25.25">
<td class="ltx_td ltx_align_center" colspan="11" id="A2.T6.3.1.25.25.1"><span class="ltx_text ltx_font_italic" id="A2.T6.3.1.25.25.1.1">Easy instances</span></td>
<td class="ltx_td" id="A2.T6.3.1.25.25.2"></td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.26.26">
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.26.26.1">ALMA-BLEU</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.26.26.2">34.36</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.26.26.3">50.81</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.26.26.4">46.92</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.26.26.5">28.50</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.26.26.6">45.16</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.26.26.7" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.26.26.7.1" style="background-color:#FF8080;">34.61</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.26.26.8" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.26.26.8.1" style="background-color:#FF8080;">35.28</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.26.26.9" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.26.26.9.1" style="background-color:#FF8080;">31.79</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.26.26.10">43.91</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.26.26.11">32.13</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.26.26.12">35.13</td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.27.27">
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.27.27.1">Ours-BLEU</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.27.27.2">35.33</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.27.27.3">50.59</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.27.27.4">47.25</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.27.27.5">27.82</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.27.27.6">44.16</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.27.27.7" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.27.27.7.1" style="background-color:#FF8080;">33.25</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.27.27.8" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.27.27.8.1" style="background-color:#FF8080;">34.07</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.27.27.9" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.27.27.9.1" style="background-color:#FF8080;">30.00</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.27.27.10">42.92</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.27.27.11">31.67</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.27.27.12">34.54</td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.28.28">
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.28.28.1">ALMA-COMET</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.28.28.2">88.08</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.28.28.3">90.54</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.28.28.4">91.04</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.28.28.5">84.29</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.28.28.6">88.62</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.28.28.7" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.28.28.7.1" style="background-color:#FF8080;">89.59</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.28.28.8" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.28.28.8.1" style="background-color:#FF8080;">93.66</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.28.28.9">91.08</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.28.28.10">89.79</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.28.28.11">91.47</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.28.28.12">80.67</td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.29.29">
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.29.29.1">Ours-COMET</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.29.29.2">87.80</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.29.29.3">90.10</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.29.29.4">90.50</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.29.29.5">83.86</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.29.29.6">88.40</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.29.29.7" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.29.29.7.1" style="background-color:#FF8080;">88.55</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.29.29.8" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.29.29.8.1" style="background-color:#FF8080;">92.48</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.29.29.9">89.57</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.29.29.10">88.79</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.29.29.11">90.61</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.29.29.12">80.00</td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.30.30">
<td class="ltx_td ltx_align_center" colspan="11" id="A2.T6.3.1.30.30.1"><span class="ltx_text ltx_font_italic" id="A2.T6.3.1.30.30.1.1">Hard instances</span></td>
<td class="ltx_td" id="A2.T6.3.1.30.30.2"></td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.31.31">
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.31.31.1">ALMA-BLEU</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.31.31.2" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.31.31.2.1" style="background-color:#80FFFF;">21.31</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.31.31.3" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.31.31.3.1" style="background-color:#80FFFF;">35.46</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.31.31.4" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.31.31.4.1" style="background-color:#80FFFF;">28.66</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.31.31.5">13.08</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.31.31.6" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.31.31.6.1" style="background-color:#80FFFF;">25.4</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.31.31.7">22.53</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.31.31.8" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.31.31.8.1" style="background-color:#80FFFF;">19.82</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.31.31.9" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.31.31.9.1" style="background-color:#FF8080;">22.52</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.31.31.10" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.31.31.10.1" style="background-color:#80FFFF;">24.81</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.31.31.11">19.78</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.31.31.12" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.31.31.12.1" style="background-color:#80FFFF;">21.36</span></td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.32.32">
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.32.32.1">Ours-BLEU</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.32.32.2" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.32.32.2.1" style="background-color:#80FFFF;">23.09</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.32.32.3" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.32.32.3.1" style="background-color:#80FFFF;">37.91</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.32.32.4" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.32.32.4.1" style="background-color:#80FFFF;">32.66</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.32.32.5">14.04</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.32.32.6" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.32.32.6.1" style="background-color:#80FFFF;">27.32</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.32.32.7">22.89</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.32.32.8" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.32.32.8.1" style="background-color:#80FFFF;">22.38</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.32.32.9" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.32.32.9.1" style="background-color:#FF8080;">21.32</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.32.32.10" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.32.32.10.1" style="background-color:#80FFFF;">26.58</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.32.32.11">19.78</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.32.32.12" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.32.32.12.1" style="background-color:#80FFFF;">22.82</span></td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.33.33">
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.33.33.1">ALMA-COMET</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.33.33.2" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.33.33.2.1" style="background-color:#80FFFF;">73.56</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.33.33.3" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.33.33.3.1" style="background-color:#80FFFF;">78.24</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.33.33.4">81.55</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.33.33.5" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.33.33.5.1" style="background-color:#80FFFF;">67.07</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.33.33.6" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.33.33.6.1" style="background-color:#80FFFF;">74.39</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.33.33.7">72.74</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.33.33.8">76.38</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.33.33.9" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.33.33.9.1" style="background-color:#FF8080;">80.61</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.33.33.10">73.38</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.33.33.11">75.29</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.33.33.12">67.79</td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.34.34">
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.34.34.1">Ours-COMET</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.34.34.2" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.34.34.2.1" style="background-color:#80FFFF;">74.77</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.34.34.3" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.34.34.3.1" style="background-color:#80FFFF;">79.75</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.34.34.4">82.41</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.34.34.5" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.34.34.5.1" style="background-color:#80FFFF;">69.56</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.34.34.6" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.34.34.6.1" style="background-color:#80FFFF;">75.63</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.34.34.7">73.24</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.34.34.8">77.34</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.34.34.9" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.34.34.9.1" style="background-color:#FF8080;">79.19</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.34.34.10">74.12</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.34.34.11">74.97</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.34.34.12">68.60</td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.35.35">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="11" id="A2.T6.3.1.35.35.1"><span class="ltx_text ltx_font_italic" id="A2.T6.3.1.35.35.1.1">Overall performance, i.e., N=infinite when all instances are included.</span></td>
<td class="ltx_td ltx_border_t" id="A2.T6.3.1.35.35.2"></td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.36.36">
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.36.36.1">ALMA-BLEU</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.36.36.2" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.36.36.2.1" style="background-color:#80FFFF;">30.73</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.36.36.3">44.68</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.36.36.4" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.36.36.4.1" style="background-color:#80FFFF;">36.46</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.36.36.5">24.15</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.36.36.6">40.37</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.36.36.7">31.37</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.36.36.8">31.12</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.36.36.9" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.36.36.9.1" style="background-color:#FF8080;">26.67</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.36.36.10">39.05</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.36.36.11">28.76</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.36.36.12">30.46</td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.37.37">
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.37.37.1">Ours-BLEU</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.37.37.2" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.37.37.2.1" style="background-color:#80FFFF;">31.93</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.37.37.3">45.60</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.37.37.4" style="background-color:#80FFFF;"><span class="ltx_text" id="A2.T6.3.1.37.37.4.1" style="background-color:#80FFFF;">38.85</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.37.37.5">23.94</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.37.37.6">40.09</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.37.37.7">30.64</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.37.37.8">30.91</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.37.37.9" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.37.37.9.1" style="background-color:#FF8080;">25.22</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.37.37.10">38.76</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.37.37.11">28.43</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.37.37.12">30.59</td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.38.38">
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.38.38.1">ALMA-COMET</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.38.38.2">84.42</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.38.38.3">86.29</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.38.38.4">86.30</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.38.38.5">79.70</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.38.38.6">85.09</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.38.38.7">85.45</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.38.38.8">89.42</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.38.38.9" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.38.38.9.1" style="background-color:#FF8080;">85.85</span></td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.38.38.10">85.76</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.38.38.11">87.50</td>
<td class="ltx_td ltx_align_center" id="A2.T6.3.1.38.38.12">76.83</td>
</tr>
<tr class="ltx_tr" id="A2.T6.3.1.39.39">
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T6.3.1.39.39.1">Ours-COMET</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T6.3.1.39.39.2">84.50</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T6.3.1.39.39.3">86.53</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T6.3.1.39.39.4">86.45</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T6.3.1.39.39.5">80.05</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T6.3.1.39.39.6">85.22</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T6.3.1.39.39.7">84.78</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T6.3.1.39.39.8">88.75</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T6.3.1.39.39.9" style="background-color:#FF8080;"><span class="ltx_text" id="A2.T6.3.1.39.39.9.1" style="background-color:#FF8080;">84.38</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T6.3.1.39.39.10">85.19</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T6.3.1.39.39.11">86.77</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A2.T6.3.1.39.39.12">76.59</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span>Specific results on 10 translation directions. The size of models are 13B. BLEU and COMET are reported. Cells where the difference is larger than <math alttext="1.0" class="ltx_Math" display="inline" id="A2.T6.2.m1.1"><semantics id="A2.T6.2.m1.1b"><mn id="A2.T6.2.m1.1.1" xref="A2.T6.2.m1.1.1.cmml">1.0</mn><annotation-xml encoding="MathML-Content" id="A2.T6.2.m1.1c"><cn id="A2.T6.2.m1.1.1.cmml" type="float" xref="A2.T6.2.m1.1.1">1.0</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T6.2.m1.1d">1.0</annotation><annotation encoding="application/x-llamapun" id="A2.T6.2.m1.1e">1.0</annotation></semantics></math> are highlighted with colored background. <span class="ltx_text" id="A2.T6.6.1" style="color:#00FFFF;">Blue</span> indicates ours model outperforms ALMA and <span class="ltx_text" id="A2.T6.7.2" style="color:#FF0000;">red</span> indicates the opposite.</figcaption>
</figure>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.2">Table <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#A2.T6" title="Table 6 ‣ Appendix B Specific results ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">6</span></a> shows the numeric results in Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S3.F6" title="Figure 6 ‣ 3.5 Optimization LLM-based MT model ‣ 3 Proposed approach ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">6</span></a>, in which boxes on a blue background highlight the cases where our model outperforms the baseline by a margin <math alttext="&gt;1.0" class="ltx_Math" display="inline" id="A2.p1.1.m1.1"><semantics id="A2.p1.1.m1.1a"><mrow id="A2.p1.1.m1.1.1" xref="A2.p1.1.m1.1.1.cmml"><mi id="A2.p1.1.m1.1.1.2" xref="A2.p1.1.m1.1.1.2.cmml"></mi><mo id="A2.p1.1.m1.1.1.1" xref="A2.p1.1.m1.1.1.1.cmml">&gt;</mo><mn id="A2.p1.1.m1.1.1.3" xref="A2.p1.1.m1.1.1.3.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.p1.1.m1.1b"><apply id="A2.p1.1.m1.1.1.cmml" xref="A2.p1.1.m1.1.1"><gt id="A2.p1.1.m1.1.1.1.cmml" xref="A2.p1.1.m1.1.1.1"></gt><csymbol cd="latexml" id="A2.p1.1.m1.1.1.2.cmml" xref="A2.p1.1.m1.1.1.2">absent</csymbol><cn id="A2.p1.1.m1.1.1.3.cmml" type="float" xref="A2.p1.1.m1.1.1.3">1.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.1.m1.1c">&gt;1.0</annotation><annotation encoding="application/x-llamapun" id="A2.p1.1.m1.1d">&gt; 1.0</annotation></semantics></math>, and the boxes in red are the opposite. Boxes without background indicate the cases when our model and the baseline have competitive performance where the margin <math alttext="&lt;1.0" class="ltx_Math" display="inline" id="A2.p1.2.m2.1"><semantics id="A2.p1.2.m2.1a"><mrow id="A2.p1.2.m2.1.1" xref="A2.p1.2.m2.1.1.cmml"><mi id="A2.p1.2.m2.1.1.2" xref="A2.p1.2.m2.1.1.2.cmml"></mi><mo id="A2.p1.2.m2.1.1.1" xref="A2.p1.2.m2.1.1.1.cmml">&lt;</mo><mn id="A2.p1.2.m2.1.1.3" xref="A2.p1.2.m2.1.1.3.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.p1.2.m2.1b"><apply id="A2.p1.2.m2.1.1.cmml" xref="A2.p1.2.m2.1.1"><lt id="A2.p1.2.m2.1.1.1.cmml" xref="A2.p1.2.m2.1.1.1"></lt><csymbol cd="latexml" id="A2.p1.2.m2.1.1.2.cmml" xref="A2.p1.2.m2.1.1.2">absent</csymbol><cn id="A2.p1.2.m2.1.1.3.cmml" type="float" xref="A2.p1.2.m2.1.1.3">1.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.2.m2.1c">&lt;1.0</annotation><annotation encoding="application/x-llamapun" id="A2.p1.2.m2.1d">&lt; 1.0</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="A2.p2">
<p class="ltx_p" id="A2.p2.1">In addition to the main findings in §<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S5.SS1" title="5.1 Evaluation on hard instances ‣ 5 Experimental results ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">5.1</span></a> that our model generally performs better in harder instances, from the results it can also be observed that our model particularly performs worse on “<span class="ltx_text ltx_font_italic" id="A2.p2.1.1">en-is</span>” than in other translation directions. The reason could be that Icelandic is a low-resource language and we used external tools such as WSPAlign and Google Translate to build the training data. Hence, the relatively unreliable performance of external tools on low-resource languages can induce noises in our training data. This could be a future direction for building more reliable word alignment signals and particular research on low-resource languages.</p>
</div>
<div class="ltx_para" id="A2.p3">
<p class="ltx_p" id="A2.p3.1">In addition, Table <a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#A2.T6" title="Table 6 ‣ Appendix B Specific results ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">6</span></a> reports the overall performance when we do not split the dataset into the hard and easy subset. The results show that our model and ALMA have generally competitive performance. Specifically, if we only consider the margin larger than 1.0, our model outperforms ALMA on <span class="ltx_text ltx_font_italic" id="A2.p3.1.1">de-en</span> and <span class="ltx_text ltx_font_italic" id="A2.p3.1.2">is-en</span> in BLEU while ALMA performs better on <span class="ltx_text ltx_font_italic" id="A2.p3.1.3">en-is</span> in both BLEU and COMET. In particular, a significance test is conducted to investigate numeric degradation when all instances are included. We utilize bootstrap sampling from example-wise COMET scores with 100,000 iterations and calculate the p-value. Based on the results of the significance test, there is no statistical significance when the margin is greater than 0.25, indicated by a p-value larger than 0.05.
This suggests that our approach does not degrade the general performance by a margin of 0.25 or more, while improving that on hard instances by a large margin of 3.47. Note that the focus of this work is the problem of hallucination and omission, general metrics for MT are only partially related to our evaluation. The evaluation by LLM and humans is also important, as we discussed in §<a class="ltx_ref" href="https://arxiv.org/html/2405.09223v1#S4.SS3" title="4.3 The design of evaluation ‣ 4 Evaluation ‣ Word Alignment as Preference for Machine Translation"><span class="ltx_text ltx_ref_tag">4.3</span></a>.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed May 15 10:03:10 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
