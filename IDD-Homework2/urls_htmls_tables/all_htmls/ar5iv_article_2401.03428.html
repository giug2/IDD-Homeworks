<article class="ltx_document ltx_authors_1line">
 <h1 class="ltx_title ltx_title_document">
  Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    <span class="ltx_text ltx_font_bold" id="id1.1.1">
     Yuheng Cheng
     <sup class="ltx_sup" id="id1.1.1.1">
      <span class="ltx_text ltx_font_medium ltx_font_italic" id="id1.1.1.1.1">
       1
      </span>
     </sup>
    </span>
    <span class="ltx_note ltx_role_footnotemark" id="footnotex1">
     <sup class="ltx_note_mark">
      1
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        1
       </sup>
       <span class="ltx_note_type">
        footnotemark:
       </span>
       <span class="ltx_tag ltx_tag_note">
        1
       </span>
      </span>
     </span>
    </span>
    <span class="ltx_text ltx_font_bold" id="id2.2.2">
     Ceyao Zhang
     <sup class="ltx_sup" id="id2.2.2.1">
      <span class="ltx_text ltx_font_medium ltx_font_italic" id="id2.2.2.1.1">
       1
      </span>
     </sup>
    </span>
    <span class="ltx_note ltx_role_footnotemark" id="footnotex2">
     <sup class="ltx_note_mark">
      1
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        1
       </sup>
       <span class="ltx_note_type">
        footnotemark:
       </span>
       <span class="ltx_tag ltx_tag_note">
        1
       </span>
      </span>
     </span>
    </span>
    <span class="ltx_text ltx_font_bold" id="id3.3.3">
     Zhengwen Zhang
     <sup class="ltx_sup" id="id3.3.3.1">
      <span class="ltx_text ltx_font_medium ltx_font_italic" id="id3.3.3.1.1">
       1
      </span>
     </sup>
    </span>
    <br class="ltx_break"/>
    <span class="ltx_text ltx_font_bold" id="id4.4.4">
     Xiangrui Meng
     <sup class="ltx_sup" id="id4.4.4.1">
      <span class="ltx_text ltx_font_medium" id="id4.4.4.1.1">
       1
      </span>
     </sup>
    </span>
    <span class="ltx_text ltx_font_bold" id="id5.5.5">
     Sirui Hong
     <sup class="ltx_sup" id="id5.5.5.1">
      <span class="ltx_text ltx_font_medium" id="id5.5.5.1.1">
       2
      </span>
     </sup>
    </span>
    <span class="ltx_text ltx_font_bold" id="id6.6.6">
     Wenhao Li
     <sup class="ltx_sup" id="id6.6.6.1">
      <span class="ltx_text ltx_font_medium" id="id6.6.6.1.1">
       1
      </span>
     </sup>
    </span>
    <span class="ltx_text ltx_font_bold" id="id7.7.7">
     Zihao Wang
     <sup class="ltx_sup" id="id7.7.7.1">
      <span class="ltx_text ltx_font_medium" id="id7.7.7.1.1">
       3
      </span>
     </sup>
    </span>
    <span class="ltx_text ltx_font_bold" id="id8.8.8">
     Zekai Wang
     <sup class="ltx_sup" id="id8.8.8.1">
      <span class="ltx_text ltx_font_medium" id="id8.8.8.1.1">
       4
      </span>
     </sup>
    </span>
    <br class="ltx_break"/>
    <span class="ltx_text ltx_font_bold" id="id9.9.9">
     Feng Yin
     <sup class="ltx_sup" id="id9.9.9.1">
      <span class="ltx_text ltx_font_medium ltx_font_italic" id="id9.9.9.1.1">
       1
      </span>
     </sup>
    </span>
    <span class="ltx_text ltx_font_bold" id="id10.10.10">
     Junhua Zhao
     <sup class="ltx_sup" id="id10.10.10.1">
      <span class="ltx_text ltx_font_medium ltx_font_italic" id="id10.10.10.1.1">
       1
      </span>
     </sup>
    </span>
    <span class="ltx_text ltx_font_bold" id="id11.11.11">
     Xiuqiang He
     <sup class="ltx_sup" id="id11.11.11.1">
      <span class="ltx_text ltx_font_medium ltx_font_italic" id="id11.11.11.1.1">
       5
      </span>
     </sup>
    </span>
    <br class="ltx_break"/>
    <sup class="ltx_sup" id="id17.17.id1">
     1
    </sup>
    The Chinese University of Hong Kong, Shenzhen
    <br class="ltx_break"/>
    <sup class="ltx_sup" id="id18.18.id2">
     2
    </sup>
    DeepWisdom
    <sup class="ltx_sup" id="id19.19.id3">
     3
    </sup>
    Peking University
    <sup class="ltx_sup" id="id20.20.id4">
     4
    </sup>
    Yantu.ai
    <sup class="ltx_sup" id="id21.21.id5">
     5
    </sup>
    FiT, Tencent
   </span>
   <span class="ltx_author_notes">
    These authors contributed to the work equally and should be regarded as co-first authors.Corresponding author
   </span>
  </span>
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract
  </h6>
  <p class="ltx_p" id="id22.id1">
   Intelligent agents stand out as a potential path toward artificial general intelligence (AGI).
Thus, researchers have dedicated significant effort to diverse implementations for them.
  </p>
  <p class="ltx_p" id="id23.id2">
   Benefiting from recent progress in large language models (LLMs), LLM-based agents that use universal natural language as an interface exhibit robust generalization capabilities across various applications – from serving as autonomous general-purpose task assistants to applications in coding, social, and economic domains, LLM-based agents offer extensive exploration opportunities.
  </p>
  <p class="ltx_p" id="id24.id3">
   This paper surveys current research to provide an in-depth overview of LLM-based intelligent agents within single-agent and multi-agent systems. It covers their definitions, research frameworks, and foundational components such as their composition, cognitive and planning methods, tool utilization, and responses to environmental feedback. We also delve into the mechanisms of deploying LLM-based agents in multi-agent systems, including multi-role collaboration, message passing, and strategies to alleviate communication issues between agents. The discussions also shed light on popular datasets and application scenarios.
We conclude by envisioning prospects for LLM-based agents, considering the evolving landscape of AI and natural language processing.
  </p>
 </div>
 <div class="ltx_para ltx_noindent" id="p1">
  <p class="ltx_p" id="p1.2">
   <em class="ltx_emph ltx_font_bold ltx_font_italic" id="p1.2.1">
    K
   </em>
   <span class="ltx_text ltx_font_bold" id="p1.2.2">
    eywords
   </span>
   Large Language Model
   <math alttext="\cdot" class="ltx_Math" display="inline" id="p1.1.m1.1">
    <semantics id="p1.1.m1.1a">
     <mo id="p1.1.m1.1.1" xref="p1.1.m1.1.1.cmml">
      ⋅
     </mo>
     <annotation-xml encoding="MathML-Content" id="p1.1.m1.1b">
      <ci id="p1.1.m1.1.1.cmml" xref="p1.1.m1.1.1">
       ⋅
      </ci>
     </annotation-xml>
     <annotation encoding="application/x-tex" id="p1.1.m1.1c">
      \cdot
     </annotation>
    </semantics>
   </math>
   Agent
   <math alttext="\cdot" class="ltx_Math" display="inline" id="p1.2.m2.1">
    <semantics id="p1.2.m2.1a">
     <mo id="p1.2.m2.1.1" xref="p1.2.m2.1.1.cmml">
      ⋅
     </mo>
     <annotation-xml encoding="MathML-Content" id="p1.2.m2.1b">
      <ci id="p1.2.m2.1.1.cmml" xref="p1.2.m2.1.1">
       ⋅
      </ci>
     </annotation-xml>
     <annotation encoding="application/x-tex" id="p1.2.m2.1c">
      \cdot
     </annotation>
    </semantics>
   </math>
   Multi-Agent System
  </p>
 </div>
 <div class="ltx_para ltx_noindent" id="p2">
  <div class="ltx_block ltx_minipage ltx_align_top" id="p2.1" style="width:346.9pt;">
   <p class="ltx_p" id="p2.1.1">
    We define AI as the study of agents that receive percepts from the environment and perform actions.
   </p>
   <p class="ltx_p" id="p2.1.2">
    <span class="ltx_rule" style="width:433.6pt;height:0.4pt;background:black;display:inline-block;">
    </span>
   </p>
   <p class="ltx_p" id="p2.1.3">
    —
    <span class="ltx_text ltx_font_italic" id="p2.1.3.1">
     Artificial Intelligence: A Modern Approach
    </span>
    , Stuart Russell and Peter Norvig (2003).
   </p>
  </div>
 </div>
 <div class="ltx_pagination ltx_role_newpage">
 </div>
 <nav class="ltx_TOC ltx_list_toc ltx_toc_toc">
  <h6 class="ltx_title ltx_title_contents">
   Contents
  </h6>
  <ol class="ltx_toclist">
   <li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="#S1" title="In Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
     <span class="ltx_text ltx_ref_title">
      <span class="ltx_tag ltx_tag_ref">
       1
      </span>
      Introduction
     </span>
    </a>
    <ol class="ltx_toclist ltx_toclist_section">
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S1.SS1" title="In 1 Introduction ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         1.1
        </span>
        Intelligent Agents
       </span>
      </a>
     </li>
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S1.SS2" title="In 1 Introduction ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         1.2
        </span>
        RL-based Agents
       </span>
      </a>
     </li>
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S1.SS3" title="In 1 Introduction ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         1.3
        </span>
        LLM-based Agents
       </span>
      </a>
     </li>
    </ol>
   </li>
   <li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="#S2" title="In Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
     <span class="ltx_text ltx_ref_title">
      <span class="ltx_tag ltx_tag_ref">
       2
      </span>
      Overview
     </span>
    </a>
    <ol class="ltx_toclist ltx_toclist_section">
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S2.SS1" title="In 2 Overview ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         2.1
        </span>
        Single-Agent System
       </span>
      </a>
     </li>
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S2.SS2" title="In 2 Overview ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         2.2
        </span>
        Multi-Agent System
       </span>
      </a>
     </li>
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S2.SS3" title="In 2 Overview ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         2.3
        </span>
        Agent System Template
       </span>
      </a>
     </li>
    </ol>
   </li>
   <li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="#S3" title="In Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
     <span class="ltx_text ltx_ref_title">
      <span class="ltx_tag ltx_tag_ref">
       3
      </span>
      LLM-based Agent System Framework
     </span>
    </a>
    <ol class="ltx_toclist ltx_toclist_section">
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S3.SS1" title="In 3 LLM-based Agent System Framework ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         3.1
        </span>
        LLM-based Single Agent System
       </span>
      </a>
      <ol class="ltx_toclist ltx_toclist_subsection">
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S3.SS1.SSS1" title="In 3.1 LLM-based Single Agent System ‣ 3 LLM-based Agent System Framework ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           3.1.1
          </span>
          Planning
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S3.SS1.SSS2" title="In 3.1 LLM-based Single Agent System ‣ 3 LLM-based Agent System Framework ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           3.1.2
          </span>
          Memory
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S3.SS1.SSS3" title="In 3.1 LLM-based Single Agent System ‣ 3 LLM-based Agent System Framework ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           3.1.3
          </span>
          Rethinking
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S3.SS1.SSS4" title="In 3.1 LLM-based Single Agent System ‣ 3 LLM-based Agent System Framework ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           3.1.4
          </span>
          Environments
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S3.SS1.SSS5" title="In 3.1 LLM-based Single Agent System ‣ 3 LLM-based Agent System Framework ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           3.1.5
          </span>
          Action
         </span>
        </a>
       </li>
      </ol>
     </li>
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S3.SS2" title="In 3 LLM-based Agent System Framework ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         3.2
        </span>
        LLM-based Multi-Agent System
       </span>
      </a>
      <ol class="ltx_toclist ltx_toclist_subsection">
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S3.SS2.SSS1" title="In 3.2 LLM-based Multi-Agent System ‣ 3 LLM-based Agent System Framework ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           3.2.1
          </span>
          Relationship of Multi-Agent Systems
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S3.SS2.SSS2" title="In 3.2 LLM-based Multi-Agent System ‣ 3 LLM-based Agent System Framework ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           3.2.2
          </span>
          Planning Type
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S3.SS2.SSS3" title="In 3.2 LLM-based Multi-Agent System ‣ 3 LLM-based Agent System Framework ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           3.2.3
          </span>
          Methods of Enhancing Communication Efficiency
         </span>
        </a>
       </li>
      </ol>
     </li>
    </ol>
   </li>
   <li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="#S4" title="In Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
     <span class="ltx_text ltx_ref_title">
      <span class="ltx_tag ltx_tag_ref">
       4
      </span>
      Performance Evaluation
     </span>
    </a>
    <ol class="ltx_toclist ltx_toclist_section">
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S4.SS1" title="In 4 Performance Evaluation ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         4.1
        </span>
        Dataset
       </span>
      </a>
     </li>
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S4.SS2" title="In 4 Performance Evaluation ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         4.2
        </span>
        Benchmark
       </span>
      </a>
     </li>
    </ol>
   </li>
   <li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="#S5" title="In Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
     <span class="ltx_text ltx_ref_title">
      <span class="ltx_tag ltx_tag_ref">
       5
      </span>
      Prospect Applications
     </span>
    </a>
    <ol class="ltx_toclist ltx_toclist_section">
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S5.SS1" title="In 5 Prospect Applications ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         5.1
        </span>
        Natural Sciences
       </span>
      </a>
      <ol class="ltx_toclist ltx_toclist_subsection">
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S5.SS1.SSS1" title="In 5.1 Natural Sciences ‣ 5 Prospect Applications ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           5.1.1
          </span>
          Mathematics
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S5.SS1.SSS2" title="In 5.1 Natural Sciences ‣ 5 Prospect Applications ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           5.1.2
          </span>
          Chemistry and Materials
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S5.SS1.SSS3" title="In 5.1 Natural Sciences ‣ 5 Prospect Applications ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           5.1.3
          </span>
          Biology
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S5.SS1.SSS4" title="In 5.1 Natural Sciences ‣ 5 Prospect Applications ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           5.1.4
          </span>
          Climate Science
         </span>
        </a>
       </li>
      </ol>
     </li>
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S5.SS2" title="In 5 Prospect Applications ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         5.2
        </span>
        Universal Autonomous Agent
       </span>
      </a>
      <ol class="ltx_toclist ltx_toclist_subsection">
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S5.SS2.SSS1" title="In 5.2 Universal Autonomous Agent ‣ 5 Prospect Applications ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           5.2.1
          </span>
          General Task Assistant
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S5.SS2.SSS2" title="In 5.2 Universal Autonomous Agent ‣ 5 Prospect Applications ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           5.2.2
          </span>
          Work/Research Assistant
         </span>
        </a>
       </li>
      </ol>
     </li>
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S5.SS3" title="In 5 Prospect Applications ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         5.3
        </span>
        Social Sciences
       </span>
      </a>
      <ol class="ltx_toclist ltx_toclist_subsection">
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S5.SS3.SSS1" title="In 5.3 Social Sciences ‣ 5 Prospect Applications ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           5.3.1
          </span>
          Economics and Finance
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S5.SS3.SSS2" title="In 5.3 Social Sciences ‣ 5 Prospect Applications ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           5.3.2
          </span>
          Politics
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S5.SS3.SSS3" title="In 5.3 Social Sciences ‣ 5 Prospect Applications ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           5.3.3
          </span>
          Society
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S5.SS3.SSS4" title="In 5.3 Social Sciences ‣ 5 Prospect Applications ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           5.3.4
          </span>
          Law
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S5.SS3.SSS5" title="In 5.3 Social Sciences ‣ 5 Prospect Applications ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           5.3.5
          </span>
          Psychology
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S5.SS3.SSS6" title="In 5.3 Social Sciences ‣ 5 Prospect Applications ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           5.3.6
          </span>
          Education
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S5.SS3.SSS7" title="In 5.3 Social Sciences ‣ 5 Prospect Applications ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           5.3.7
          </span>
          Management
         </span>
        </a>
       </li>
      </ol>
     </li>
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S5.SS4" title="In 5 Prospect Applications ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         5.4
        </span>
        Engineering Systems
       </span>
      </a>
      <ol class="ltx_toclist ltx_toclist_subsection">
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S5.SS4.SSS1" title="In 5.4 Engineering Systems ‣ 5 Prospect Applications ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           5.4.1
          </span>
          Computer System
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S5.SS4.SSS2" title="In 5.4 Engineering Systems ‣ 5 Prospect Applications ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           5.4.2
          </span>
          Robotics System
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S5.SS4.SSS3" title="In 5.4 Engineering Systems ‣ 5 Prospect Applications ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           5.4.3
          </span>
          Power System
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S5.SS4.SSS4" title="In 5.4 Engineering Systems ‣ 5 Prospect Applications ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           5.4.4
          </span>
          Transportation System
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S5.SS4.SSS5" title="In 5.4 Engineering Systems ‣ 5 Prospect Applications ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           5.4.5
          </span>
          Industrial Control System
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S5.SS4.SSS6" title="In 5.4 Engineering Systems ‣ 5 Prospect Applications ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           5.4.6
          </span>
          Medical System
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S5.SS4.SSS7" title="In 5.4 Engineering Systems ‣ 5 Prospect Applications ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           5.4.7
          </span>
          Military System
         </span>
        </a>
       </li>
      </ol>
     </li>
    </ol>
   </li>
   <li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="#S6" title="In Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
     <span class="ltx_text ltx_ref_title">
      <span class="ltx_tag ltx_tag_ref">
       6
      </span>
      Discussion
     </span>
    </a>
    <ol class="ltx_toclist ltx_toclist_section">
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S6.SS1" title="In 6 Discussion ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         6.1
        </span>
        Trend
       </span>
      </a>
     </li>
     <li class="ltx_tocentry ltx_tocentry_subsection">
      <a class="ltx_ref" href="#S6.SS2" title="In 6 Discussion ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
       <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref">
         6.2
        </span>
        Challenges
       </span>
      </a>
      <ol class="ltx_toclist ltx_toclist_subsection">
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S6.SS2.SSS1" title="In 6.2 Challenges ‣ 6 Discussion ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           6.2.1
          </span>
          Intrinsic Constraints of LLMs
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S6.SS2.SSS2" title="In 6.2 Challenges ‣ 6 Discussion ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           6.2.2
          </span>
          Dynamic Scaling
         </span>
        </a>
       </li>
       <li class="ltx_tocentry ltx_tocentry_subsubsection">
        <a class="ltx_ref" href="#S6.SS2.SSS3" title="In 6.2 Challenges ‣ 6 Discussion ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
         <span class="ltx_text ltx_ref_title">
          <span class="ltx_tag ltx_tag_ref">
           6.2.3
          </span>
          Security and Trust
         </span>
        </a>
       </li>
      </ol>
     </li>
    </ol>
   </li>
   <li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="#S7" title="In Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
     <span class="ltx_text ltx_ref_title">
      <span class="ltx_tag ltx_tag_ref">
       7
      </span>
      Conclusion
     </span>
    </a>
   </li>
  </ol>
 </nav>
 <div class="ltx_pagination ltx_role_newpage">
 </div>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    1
   </span>
   Introduction
  </h2>
  <section class="ltx_subsection" id="S1.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     1.1
    </span>
    Intelligent Agents
   </h3>
   <div class="ltx_para ltx_noindent" id="S1.SS1.p1">
    <p class="ltx_p" id="S1.SS1.p1.1">
     The investigation of LLM-based agents has attracted considerable attention recently. The concept of an "agent" in AI boasts a solid foundation, primarily emphasizing the distinction between agents and their environments within AI systems
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib1" title="">
       1
      </a>
      ]
     </cite>
     . Any entity capable of perceiving its environment and taking action can be considered an agent. Agents have the autonomy to carry out tasks in diverse environments, relying on their past experiences and knowledge to make decisions that align with predefined objectives.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S1.SS1.p2">
    <p class="ltx_p" id="S1.SS1.p2.1">
     Generally, agents exhibit the following characteristics
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib2" title="">
       2
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib3" title="">
       3
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib4" title="">
       4
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib1" title="">
       1
      </a>
      ]
     </cite>
     :
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S1.SS1.p3">
    <ul class="ltx_itemize" id="S1.I1">
     <li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S1.I1.i1.p1">
       <p class="ltx_p" id="S1.I1.i1.p1.1">
        <span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.1">
         Autonomy
        </span>
        : Agents independently perceive their environment, make decisions, and take actions without relying on external instructions.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S1.I1.i2.p1">
       <p class="ltx_p" id="S1.I1.i2.p1.1">
        <span class="ltx_text ltx_font_bold" id="S1.I1.i2.p1.1.1">
         Perception
        </span>
        : Agents are equipped with sensory capabilities that allow them to gather information about their environment through the use of sensors.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S1.I1.i3.p1">
       <p class="ltx_p" id="S1.I1.i3.p1.1">
        <span class="ltx_text ltx_font_bold" id="S1.I1.i3.p1.1.1">
         Decision-making
        </span>
        : Agents make decisions based on perceived information, selecting appropriate actions to achieve their goals.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para ltx_noindent" id="S1.I1.i4.p1">
       <p class="ltx_p" id="S1.I1.i4.p1.1">
        <span class="ltx_text ltx_font_bold" id="S1.I1.i4.p1.1.1">
         Action
        </span>
        : Agents perform actions that alter the state of their environment.
       </p>
      </div>
     </li>
    </ul>
   </div>
   <div class="ltx_para ltx_noindent" id="S1.SS1.p4">
    <p class="ltx_p" id="S1.SS1.p4.1">
     Agents can be categorized into five types: Simple Reflex agents, Model-based Reflex agents, Goal-based agents, Utility-based agents, and Learning agents
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib1" title="">
       1
      </a>
      ]
     </cite>
     . Reinforcement Learning based agents (RL-based agents) and Large Language Model based agents (LLM-based agents) fall under the category of Learning agents.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S1.SS1.p5">
    <p class="ltx_p" id="S1.SS1.p5.1">
     A defining characteristic of Learning Agents is their capacity to learn and improve their behavior based on experience. These agents can enhance their decision-making processes over time by observing their environment and the results of their actions. Such improvement addresses the limitations inherent in other agent types, such as the lack of autonomous learning capabilities and difficulties in managing multi-step decision problems. These different types often depend on fixed rules or simplistic models, which can limit their adaptability and generalization abilities
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib5" title="">
       5
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib6" title="">
       6
      </a>
      ]
     </cite>
     .
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S1.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     1.2
    </span>
    RL-based Agents
   </h3>
   <div class="ltx_para ltx_noindent" id="S1.SS2.p1">
    <p class="ltx_p" id="S1.SS2.p1.1">
     The primary objective of RL-based agents is to learn a policy that guides the agent to take actions in different states to maximize cumulative rewards
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib7" title="">
       7
      </a>
      ]
     </cite>
     . These agents learn through trial and error, continuously adjusting their policies to optimize long-term rewards. RL-based agents have achieved considerable success
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib8" title="">
       8
      </a>
      ]
     </cite>
     in domains such as gaming
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib9" title="">
       9
      </a>
      ]
     </cite>
     , robot control
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib10" title="">
       10
      </a>
      ]
     </cite>
     , and autonomous driving
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib11" title="">
       11
      </a>
      ]
     </cite>
     .
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S1.SS2.p2">
    <p class="ltx_p" id="S1.SS2.p2.1">
     The fundamental reinforcement learning framework includes the Agent, Environment, State, Action, and Reward. The agent performs actions in the environment, and the environment responds with changes in state and rewards based on the agent’s actions. The agent adjusts its policy based on the environment’s feedback to attain higher cumulative rewards in future actions.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S1.SS2.p3">
    <p class="ltx_p" id="S1.SS2.p3.1">
     However, in recent years, certain limitations of RL-based agents have gradually emerged, representative limitations including
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib12" title="">
       12
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib13" title="">
       13
      </a>
      ]
     </cite>
     :
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S1.SS2.p4">
    <ul class="ltx_itemize" id="S1.I2">
     <li class="ltx_item" id="S1.I2.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S1.I2.i1.p1">
       <p class="ltx_p" id="S1.I2.i1.p1.1">
        <span class="ltx_text ltx_font_bold" id="S1.I2.i1.p1.1.1">
         Training Time
        </span>
        : RL algorithms often require substantial time to converge toward stable and satisfactory performance. This occurs because the agent must explore the environment, learn from its interactions, and continuously update its policy based on the observed rewards. The extended training time can present a significant drawback, particularly for large-scale and complex problems.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S1.I2.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S1.I2.i2.p1">
       <p class="ltx_p" id="S1.I2.i2.p1.1">
        <span class="ltx_text ltx_font_bold" id="S1.I2.i2.p1.1.1">
         Sample Efficiency
        </span>
        : RL-based agents typically must interact with the environment for many episodes before learning an effective policy. This high sample requirement can be computationally expensive and infeasible for specific applications, such as robotics or real-world scenarios where data collection is costly or time-consuming.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S1.I2.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S1.I2.i3.p1">
       <p class="ltx_p" id="S1.I2.i3.p1.1">
        <span class="ltx_text ltx_font_bold" id="S1.I2.i3.p1.1.1">
         Stability
        </span>
        : The learning process in RL can be unstable, particularly when using high-dimensional function approximators such as deep neural networks. This instability can lead to oscillations in performance or even divergence of the learning algorithm. This issue is exacerbated by RL-based agents often dealing with non-stationary environments, where the dynamics change as the agent’s policy evolves.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S1.I2.i4" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para ltx_noindent" id="S1.I2.i4.p1">
       <p class="ltx_p" id="S1.I2.i4.p1.1">
        <span class="ltx_text ltx_font_bold" id="S1.I2.i4.p1.1.1">
         Generalizability
        </span>
        : RL-based agents tend to be specialized in the specific task they were trained on and may not generalize effectively to new tasks or environments. This lack of generalization capability can be a significant limitation, as it requires training a new agent from scratch for each new problem. Transfer learning aims to address this issue by leveraging the knowledge acquired in one task to improve learning in a related but different task. However, developing effective transfer learning techniques for RL remains an open research challenge.
       </p>
      </div>
     </li>
    </ul>
   </div>
  </section>
  <section class="ltx_subsection" id="S1.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     1.3
    </span>
    LLM-based Agents
   </h3>
   <div class="ltx_para ltx_noindent" id="S1.SS3.p1">
    <p class="ltx_p" id="S1.SS3.p1.1">
     Contemporary studies highlight the exceptional proficiencies of LLMs in natural language processing (NLP) domains, encompassing reasoning, general question answering, programming, and text generation
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib14" title="">
       14
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib15" title="">
       15
      </a>
      ]
     </cite>
     . Nevertheless, investigations have unveiled numerous obstacles that LLMs frequently encounter while tackling pragmatic tasks
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib16" title="">
       16
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib17" title="">
       17
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib18" title="">
       18
      </a>
      ]
     </cite>
     :
    </p>
    <ul class="ltx_itemize" id="S1.I3">
     <li class="ltx_item" id="S1.I3.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S1.I3.i1.p1">
       <p class="ltx_p" id="S1.I3.i1.p1.1">
        <span class="ltx_text ltx_font_bold" id="S1.I3.i1.p1.1.1">
         Context Length Constraint
        </span>
        : LLMs frequently experience limitations in context length, with a heightened propensity for disregarding text situated in the central portion of the context compared to text at the commencement or conclusion.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S1.I3.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S1.I3.i2.p1">
       <p class="ltx_p" id="S1.I3.i2.p1.1">
        <span class="ltx_text ltx_font_bold" id="S1.I3.i2.p1.1.1">
         Protracted Knowledge Update
        </span>
        : LLMs necessitate considerable temporal and computational resources during each training iteration, resulting in postponed knowledge updates.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S1.I3.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para ltx_noindent" id="S1.I3.i3.p1">
       <p class="ltx_p" id="S1.I3.i3.p1.1">
        <span class="ltx_text ltx_font_bold" id="S1.I3.i3.p1.1.1">
         Absence of Direct Tool Utilization
        </span>
        : LLMs cannot directly employ external instruments such as calculators, SQL executors, or code interpreters.
       </p>
      </div>
     </li>
    </ul>
    <p class="ltx_p" id="S1.SS3.p1.2">
     Incorporating agent mechanisms can facilitate the challenges above to a degree. LLM-based agents, exemplified by intelligent agents constructed upon LLMs such as GPT-4
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib19" title="">
       19
      </a>
      ]
     </cite>
     , amalgamate the advantages of both LLMs and agents. Unlike other agents, LLM-based agents use LLMs for cognitive and strategic processes, encouraging smart behavior.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S1.SS3.p2">
    <p class="ltx_p" id="S1.SS3.p2.1">
     The merits of LLM-based agents in comparison to alternative agents encompass the following
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib20" title="">
       20
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib21" title="">
       21
      </a>
      ]
     </cite>
     :
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S1.SS3.p3">
    <ul class="ltx_itemize" id="S1.I4">
     <li class="ltx_item" id="S1.I4.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S1.I4.i1.p1">
       <p class="ltx_p" id="S1.I4.i1.p1.1">
        <span class="ltx_text ltx_font_bold" id="S1.I4.i1.p1.1.1">
         Potent Natural Language Processing and Comprehensive Knowledge
        </span>
        : Capitalizing on the formidable language comprehension and generation aptitudes cultivated during training on copious text data, LLMs boast substantial common sense knowledge, domain-specific expertise, and factual data. This endows LLM-based agents with the capacity to manage an array of natural language tasks.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S1.I4.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S1.I4.i2.p1">
       <p class="ltx_p" id="S1.I4.i2.p1.1">
        <span class="ltx_text ltx_font_bold" id="S1.I4.i2.p1.1.1">
         Zero-Shot or Few-Shot Learning
        </span>
        : LLMs have already acquired abundant knowledge and abilities during training, so LLM-based agents frequently necessitate minimal samples to excel in novel tasks. Their exceptional generalization competencies enable them to perform admirably in circumstances they have not previously encountered.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S1.I4.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para ltx_noindent" id="S1.I4.i3.p1">
       <p class="ltx_p" id="S1.I4.i3.p1.1">
        <span class="ltx_text ltx_font_bold" id="S1.I4.i3.p1.1.1">
         Organic Human-Computer Interaction
        </span>
        : LLM-based agents can understand and generate natural language text, fostering interaction between human users and the intelligent agent via natural language. This augments the convenience and user-centricity of human-computer interaction.
       </p>
      </div>
     </li>
    </ul>
   </div>
   <figure class="ltx_figure" id="S1.F1">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="269" id="S1.F1.g1" src="/html/2401.03428/assets/imgs/introduction.png" width="389"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 1:
     </span>
     Roadmap of Intelligent Agents Development
    </figcaption>
   </figure>
   <div class="ltx_para ltx_noindent" id="S1.SS3.p4">
    <p class="ltx_p" id="S1.SS3.p4.1">
     By amalgamating LLMs’ language comprehension and generation proficiencies with agents’ decision-making and planning capabilities, LLM-based agents proffer promising resolutions to the obstacles presented by LLMs in pragmatic applications.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S1.SS3.p5">
    <p class="ltx_p" id="S1.SS3.p5.1">
     This paper commences with an introduction to the LLM-based agent system in Section
     <a class="ltx_ref" href="#S2" title="2 Overview ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     , succeeded by a synopsis of the LLM-based agent system framework in Section
     <a class="ltx_ref" href="#S3" title="3 LLM-based Agent System Framework ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     . Section
     <a class="ltx_ref" href="#S4" title="4 Performance Evaluation ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     delineates prevalent datasets and evaluation methodologies for agents. In Section
     <a class="ltx_ref" href="#S5" title="5 Prospect Applications ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
      <span class="ltx_text ltx_ref_tag">
       5
      </span>
     </a>
     , we examine the employment of LLM-based agents across diverse domains, encompassing natural sciences, social sciences, engineering systems, and general domains. Conclusively, Section
     <a class="ltx_ref" href="#S6" title="6 Discussion ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
      <span class="ltx_text ltx_ref_tag">
       6
      </span>
     </a>
     investigates the developmental trajectories of agents, which involve augmenting the adaptive capacity of LLM-based agents, incorporating multimodal models or large multimodal models (LMMs) to endow agents with multimodal information processing capabilities, and addressing the challenges encountered.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    2
   </span>
   Overview
  </h2>
  <div class="ltx_para ltx_noindent" id="S2.p1">
   <p class="ltx_p" id="S2.p1.1">
    Upon scrutinizing LLM-based agents, they can be categorized into two principal classifications: Single-Agent and Multi-Agent systems. These distinct system types manifest considerable disparities in numerous facets, including application domains, memory and reconsideration mechanisms, data prerequisites, modalities, and toolsets. Subsequently, this paper delves into these agent varieties to aid readers in apprehending their singular attributes and application spheres.
   </p>
  </div>
  <section class="ltx_subsection" id="S2.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.1
    </span>
    Single-Agent System
   </h3>
   <div class="ltx_para ltx_noindent" id="S2.SS1.p1">
    <p class="ltx_p" id="S2.SS1.p1.1">
     A single-agent system encompasses an LLM-based intelligent agent proficient in handling multiple tasks and domains, frequently denoted as an LLM-based agent. An LLM-based agent characteristically boasts extensive language comprehension, generation capacities, and multi-task generalization competencies, enabling it to execute tasks such as code generation, game exploration, and data management. Moreover, evaluation methodologies for distinct LLM-based agents vary, and the utilized tools are not standardized. An LLM-based agent may be unimodal or multimodal, depending on its design objectives. An impending table
     <a class="ltx_ref" href="#S2.T1" title="Table 1 ‣ 2.2 Multi-Agent System ‣ 2 Overview ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     furnishes a synopsis of several contemporary LLM-based agents.
    </p>
   </div>
   <figure class="ltx_figure" id="S2.F2">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="299" id="S2.F2.g1" src="/html/2401.03428/assets/imgs/agent.png" width="449"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 2:
     </span>
     Overview of LLM-based agents
    </figcaption>
   </figure>
   <div class="ltx_para ltx_noindent" id="S2.SS1.p2">
    <p class="ltx_p" id="S2.SS1.p2.7">
     Each LLM-based agent
     <math alttext="V" class="ltx_Math" display="inline" id="S2.SS1.p2.1.m1.1">
      <semantics id="S2.SS1.p2.1.m1.1a">
       <mi id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml">
        V
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b">
        <ci id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1">
         𝑉
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">
        V
       </annotation>
      </semantics>
     </math>
     can be succinctly represented as a quintuple
     <math alttext="V=(\mathcal{L,O,M,A,R})" class="ltx_Math" display="inline" id="S2.SS1.p2.2.m2.5">
      <semantics id="S2.SS1.p2.2.m2.5a">
       <mrow id="S2.SS1.p2.2.m2.5.6" xref="S2.SS1.p2.2.m2.5.6.cmml">
        <mi id="S2.SS1.p2.2.m2.5.6.2" xref="S2.SS1.p2.2.m2.5.6.2.cmml">
         V
        </mi>
        <mo id="S2.SS1.p2.2.m2.5.6.1" xref="S2.SS1.p2.2.m2.5.6.1.cmml">
         =
        </mo>
        <mrow id="S2.SS1.p2.2.m2.5.6.3.2" xref="S2.SS1.p2.2.m2.5.6.3.1.cmml">
         <mo id="S2.SS1.p2.2.m2.5.6.3.2.1" stretchy="false" xref="S2.SS1.p2.2.m2.5.6.3.1.cmml">
          (
         </mo>
         <mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.2.m2.1.1" xref="S2.SS1.p2.2.m2.1.1.cmml">
          ℒ
         </mi>
         <mo id="S2.SS1.p2.2.m2.5.6.3.2.2" xref="S2.SS1.p2.2.m2.5.6.3.1.cmml">
          ,
         </mo>
         <mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.2.m2.2.2" xref="S2.SS1.p2.2.m2.2.2.cmml">
          𝒪
         </mi>
         <mo id="S2.SS1.p2.2.m2.5.6.3.2.3" xref="S2.SS1.p2.2.m2.5.6.3.1.cmml">
          ,
         </mo>
         <mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.2.m2.3.3" xref="S2.SS1.p2.2.m2.3.3.cmml">
          ℳ
         </mi>
         <mo id="S2.SS1.p2.2.m2.5.6.3.2.4" xref="S2.SS1.p2.2.m2.5.6.3.1.cmml">
          ,
         </mo>
         <mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.2.m2.4.4" xref="S2.SS1.p2.2.m2.4.4.cmml">
          𝒜
         </mi>
         <mo id="S2.SS1.p2.2.m2.5.6.3.2.5" xref="S2.SS1.p2.2.m2.5.6.3.1.cmml">
          ,
         </mo>
         <mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.2.m2.5.5" xref="S2.SS1.p2.2.m2.5.5.cmml">
          ℛ
         </mi>
         <mo id="S2.SS1.p2.2.m2.5.6.3.2.6" stretchy="false" xref="S2.SS1.p2.2.m2.5.6.3.1.cmml">
          )
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S2.SS1.p2.2.m2.5b">
        <apply id="S2.SS1.p2.2.m2.5.6.cmml" xref="S2.SS1.p2.2.m2.5.6">
         <eq id="S2.SS1.p2.2.m2.5.6.1.cmml" xref="S2.SS1.p2.2.m2.5.6.1">
         </eq>
         <ci id="S2.SS1.p2.2.m2.5.6.2.cmml" xref="S2.SS1.p2.2.m2.5.6.2">
          𝑉
         </ci>
         <vector id="S2.SS1.p2.2.m2.5.6.3.1.cmml" xref="S2.SS1.p2.2.m2.5.6.3.2">
          <ci id="S2.SS1.p2.2.m2.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1">
           ℒ
          </ci>
          <ci id="S2.SS1.p2.2.m2.2.2.cmml" xref="S2.SS1.p2.2.m2.2.2">
           𝒪
          </ci>
          <ci id="S2.SS1.p2.2.m2.3.3.cmml" xref="S2.SS1.p2.2.m2.3.3">
           ℳ
          </ci>
          <ci id="S2.SS1.p2.2.m2.4.4.cmml" xref="S2.SS1.p2.2.m2.4.4">
           𝒜
          </ci>
          <ci id="S2.SS1.p2.2.m2.5.5.cmml" xref="S2.SS1.p2.2.m2.5.5">
           ℛ
          </ci>
         </vector>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS1.p2.2.m2.5c">
        V=(\mathcal{L,O,M,A,R})
       </annotation>
      </semantics>
     </math>
     , wherein
     <math alttext="\mathcal{L}" class="ltx_Math" display="inline" id="S2.SS1.p2.3.m3.1">
      <semantics id="S2.SS1.p2.3.m3.1a">
       <mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.3.m3.1.1" xref="S2.SS1.p2.3.m3.1.1.cmml">
        ℒ
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS1.p2.3.m3.1b">
        <ci id="S2.SS1.p2.3.m3.1.1.cmml" xref="S2.SS1.p2.3.m3.1.1">
         ℒ
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS1.p2.3.m3.1c">
        \mathcal{L}
       </annotation>
      </semantics>
     </math>
     denotes the LLM,
     <math alttext="\mathcal{O}" class="ltx_Math" display="inline" id="S2.SS1.p2.4.m4.1">
      <semantics id="S2.SS1.p2.4.m4.1a">
       <mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.4.m4.1.1" xref="S2.SS1.p2.4.m4.1.1.cmml">
        𝒪
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS1.p2.4.m4.1b">
        <ci id="S2.SS1.p2.4.m4.1.1.cmml" xref="S2.SS1.p2.4.m4.1.1">
         𝒪
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS1.p2.4.m4.1c">
        \mathcal{O}
       </annotation>
      </semantics>
     </math>
     signifies the Objective,
     <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S2.SS1.p2.5.m5.1">
      <semantics id="S2.SS1.p2.5.m5.1a">
       <mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.5.m5.1.1" xref="S2.SS1.p2.5.m5.1.1.cmml">
        ℳ
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS1.p2.5.m5.1b">
        <ci id="S2.SS1.p2.5.m5.1.1.cmml" xref="S2.SS1.p2.5.m5.1.1">
         ℳ
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS1.p2.5.m5.1c">
        \mathcal{M}
       </annotation>
      </semantics>
     </math>
     embodies Memory,
     <math alttext="\mathcal{A}" class="ltx_Math" display="inline" id="S2.SS1.p2.6.m6.1">
      <semantics id="S2.SS1.p2.6.m6.1a">
       <mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.6.m6.1.1" xref="S2.SS1.p2.6.m6.1.1.cmml">
        𝒜
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS1.p2.6.m6.1b">
        <ci id="S2.SS1.p2.6.m6.1.1.cmml" xref="S2.SS1.p2.6.m6.1.1">
         𝒜
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS1.p2.6.m6.1c">
        \mathcal{A}
       </annotation>
      </semantics>
     </math>
     constitutes Action, and
     <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S2.SS1.p2.7.m7.1">
      <semantics id="S2.SS1.p2.7.m7.1a">
       <mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.7.m7.1.1" xref="S2.SS1.p2.7.m7.1.1.cmml">
        ℛ
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS1.p2.7.m7.1b">
        <ci id="S2.SS1.p2.7.m7.1.1.cmml" xref="S2.SS1.p2.7.m7.1.1">
         ℛ
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS1.p2.7.m7.1c">
        \mathcal{R}
       </annotation>
      </semantics>
     </math>
     epitomizes Rethink:
    </p>
    <ul class="ltx_itemize" id="S2.I1">
     <li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S2.I1.i1.p1">
       <p class="ltx_p" id="S2.I1.i1.p1.1">
        <span class="ltx_text ltx_font_bold" id="S2.I1.i1.p1.1.1">
         LLM
        </span>
        : Incorporating the LLM and the agent’s configurations and proficiencies typically necessitates a prompt definition or employing a distinct domain-specific LLM. It can be posited that no supplementary training is requisite for an LLM; however, its inference parameters, such as temperature, can be dynamically adjusted. The LLM functions as the LLM-based agent’s cerebral core, mandating task strategizing and decision-making predicated on current observations, historical memory, and reward information.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S2.I1.i2.p1">
       <p class="ltx_p" id="S2.I1.i2.p1.1">
        <span class="ltx_text ltx_font_bold" id="S2.I1.i2.p1.1.1">
         Objective
        </span>
        : The primary goal, denoted as the Objective, represents the terminal state or condition that the agent must achieve. The agent must engage in task decomposition and planning depending on the objective.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S2.I1.i3.p1">
       <p class="ltx_p" id="S2.I1.i3.p1.1">
        <span class="ltx_text ltx_font_bold" id="S2.I1.i3.p1.1.1">
         Action
        </span>
        : The agent possesses a repertoire of actions that can be executed, typically involving utilizing various tools, devising new tools, or transmitting messages to the environment or other agents.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S2.I1.i4" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S2.I1.i4.p1">
       <p class="ltx_p" id="S2.I1.i4.p1.1">
        <span class="ltx_text ltx_font_bold" id="S2.I1.i4.p1.1.1">
         Memory
        </span>
        : The agent’s memory stores information and symbolizes the agent’s current state. When the agent takes an action, the subsequent environmental feedback and reward information are recorded in the memory.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S2.I1.i5" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para ltx_noindent" id="S2.I1.i5.p1">
       <p class="ltx_p" id="S2.I1.i5.p1.1">
        <span class="ltx_text ltx_font_bold" id="S2.I1.i5.p1.1.1">
         Rethink
        </span>
        : Upon the execution of an action, the agent is required to utilize its capacity for introspection, referred to as "Rethink," to reflect upon the preceding action and the associated environmental feedback reward. The reflective process should be integrated with the agent’s memory, LLM, or other suitable models to plan and execute subsequent actions.
       </p>
      </div>
     </li>
    </ul>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS1.p3">
    <p class="ltx_p" id="S2.SS1.p3.1">
     Regarding the external constituents of the LLM-based agent, the Environment and Tool typically comprise the following:
    </p>
    <ul class="ltx_itemize" id="S2.I2">
     <li class="ltx_item" id="S2.I2.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S2.I2.i1.p1">
       <p class="ltx_p" id="S2.I2.i1.p1.1">
        <span class="ltx_text ltx_font_bold" id="S2.I2.i1.p1.1.1">
         Tool
        </span>
        : A tool refers to any instrument an agent can utilize, such as calculators, code interpreters, robotic arms, etc.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S2.I2.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para ltx_noindent" id="S2.I2.i2.p1">
       <p class="ltx_p" id="S2.I2.i2.p1.1">
        <span class="ltx_text ltx_font_bold" id="S2.I2.i2.p1.1.1">
         Environment
        </span>
        : The environment where the agent is situated significantly influences its actions. The agent can observe and interact with this environment, obtaining valuable feedback.
       </p>
      </div>
     </li>
    </ul>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.2
    </span>
    Multi-Agent System
   </h3>
   <div class="ltx_para ltx_noindent" id="S2.SS2.p1">
    <p class="ltx_p" id="S2.SS2.p1.1">
     Unlike a single-agent system, a multi-agent system (MAS) is a computerized system composed of multiple interacting intelligent agents
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib22" title="">
       22
      </a>
      ]
     </cite>
     .
Inspired by Minsky’s Society of Mind (SOM)
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib23" title="">
       23
      </a>
      ]
     </cite>
     and natural language-based SOM (NLSOM)
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib24" title="">
       24
      </a>
      ]
     </cite>
     ,
Multi-Agent Systems (MAS) design demands a heightened level of intricate coordination among various agents, particularly in their interactions and information sharing.
Each agent typically possesses specific domain expertise, making Multi-Agent systems particularly advantageous for tasks spanning multiple domains.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS2.p2">
    <p class="ltx_p" id="S2.SS2.p2.1">
     <cite class="ltx_cite ltx_citemacro_citet">
      Decker [
      <a class="ltx_ref" href="#bib.bib25" title="">
       25
      </a>
      ]
     </cite>
     outlines a four-dimensional framework for an MAS. The dimensions encompass:
1) Granularity of Agents, ranging from coarse to acceptable configurations;
2) Heterogeneity in Agent Knowledge, comparing agents with redundant knowledge to those with specialized expertise;
3) Mechanisms for the Distribution of Control, which can be categorized as benevolent or competitive, team-oriented or hierarchical, and may involve static or shifting role assignments;
4) Varieties of Communication Protocols, differentiating between the blackboard and message-based systems and specifying the gradation from low-level to high-level contents.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS2.p3">
    <p class="ltx_p" id="S2.SS2.p3.1">
     From an application perspective,
     <cite class="ltx_cite ltx_citemacro_citet">
      Parunak [
      <a class="ltx_ref" href="#bib.bib26" title="">
       26
      </a>
      ]
     </cite>
     presented a taxonomy of MAS from three important characteristics:
    </p>
    <ul class="ltx_itemize" id="S2.I3">
     <li class="ltx_item" id="S2.I3.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S2.I3.i1.p1">
       <p class="ltx_p" id="S2.I3.i1.p1.1">
        <span class="ltx_text ltx_font_bold" id="S2.I3.i1.p1.1.1">
         System Function
        </span>
        ;
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S2.I3.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S2.I3.i2.p1">
       <p class="ltx_p" id="S2.I3.i2.p1.1">
        <span class="ltx_text ltx_font_bold" id="S2.I3.i2.p1.1.1">
         System Architecture
        </span>
        (e.g., communication, protocols, human involvement);
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S2.I3.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para ltx_noindent" id="S2.I3.i3.p1">
       <p class="ltx_p" id="S2.I3.i3.p1.1">
        <span class="ltx_text ltx_font_bold" id="S2.I3.i3.p1.1.1">
         Agent Architecture
        </span>
        (e.g., degree of heterogeneity, reactive vs. deliberative).
       </p>
      </div>
     </li>
    </ul>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS2.p4">
    <p class="ltx_p" id="S2.SS2.p4.1">
     The main contribution of the taxonomy lies in dividing MAS into agent-level and system-level characteristics.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS2.p5">
    <p class="ltx_p" id="S2.SS2.p5.1">
     <cite class="ltx_cite ltx_citemacro_citet">
      Stone and Veloso [
      <a class="ltx_ref" href="#bib.bib2" title="">
       2
      </a>
      ]
     </cite>
     classifies MAS according to two crucial dimensions: the degree of heterogeneity and the degree of communication. This classification framework yields four distinct archetypes of MAS: homogeneous non-communicating agents, heterogeneous non-communicating agents, homogeneous communicating agents, and heterogeneous communicating agents.
Incorporating approaches such as control theory and reinforcement learning is a common practice to bestow intelligence and autonomy upon these agents.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS2.p6">
    <p class="ltx_p" id="S2.SS2.p6.1">
     As highlighted in
     <cite class="ltx_cite ltx_citemacro_citet">
      Yang [
      <a class="ltx_ref" href="#bib.bib27" title="">
       27
      </a>
      ]
     </cite>
     , following the breakthrough of the deep Q-learning (DQN)
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib8" title="">
       8
      </a>
      ]
     </cite>
     architecture in a single-agent paradigm, 2019 observed RL-based agents expanding to multi-agent systems, signifying a burgeoning of Multi-Agent Reinforcement Learning (MARL) techniques. Within the context of MARL,
     <cite class="ltx_cite ltx_citemacro_citet">
      Hu et al. [
      <a class="ltx_ref" href="#bib.bib28" title="">
       28
      </a>
      ]
     </cite>
     offers a taxonomy to distinguish MARL algorithms by employing the subsequent four dimensions:
    </p>
    <ul class="ltx_itemize" id="S2.I4">
     <li class="ltx_item" id="S2.I4.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S2.I4.i1.p1">
       <p class="ltx_p" id="S2.I4.i1.p1.1">
        <span class="ltx_text ltx_font_bold" id="S2.I4.i1.p1.1.1">
         Task Mode
        </span>
        : Cooperative-like or Competitive-like;
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S2.I4.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S2.I4.i2.p1">
       <p class="ltx_p" id="S2.I4.i2.p1.1">
        <span class="ltx_text ltx_font_bold" id="S2.I4.i2.p1.1.1">
         Agents Type
        </span>
        : Heterogeneous or Homogeneous;
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S2.I4.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S2.I4.i3.p1">
       <p class="ltx_p" id="S2.I4.i3.p1.1">
        <span class="ltx_text ltx_font_bold" id="S2.I4.i3.p1.1.1">
         Learning Style
        </span>
        : Independent Learning, Centralized Training, Decentralized Execution (CTDE), or Fully Centralized;
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S2.I4.i4" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para ltx_noindent" id="S2.I4.i4.p1">
       <p class="ltx_p" id="S2.I4.i4.p1.1">
        <span class="ltx_text ltx_font_bold" id="S2.I4.i4.p1.1.1">
         Knowledge Sharing
        </span>
        : Agent Level, Scenario Level, or Task Level.
       </p>
      </div>
     </li>
    </ul>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS2.p7">
    <p class="ltx_p" id="S2.SS2.p7.7">
     The LLM has been flourishing since 2022. Considering the LLM-based agents in MAS, a graph
     <math alttext="G(V,E)" class="ltx_Math" display="inline" id="S2.SS2.p7.1.m1.2">
      <semantics id="S2.SS2.p7.1.m1.2a">
       <mrow id="S2.SS2.p7.1.m1.2.3" xref="S2.SS2.p7.1.m1.2.3.cmml">
        <mi id="S2.SS2.p7.1.m1.2.3.2" xref="S2.SS2.p7.1.m1.2.3.2.cmml">
         G
        </mi>
        <mo id="S2.SS2.p7.1.m1.2.3.1" lspace="0em" rspace="0em" xref="S2.SS2.p7.1.m1.2.3.1.cmml">
         ​
        </mo>
        <mrow id="S2.SS2.p7.1.m1.2.3.3.2" xref="S2.SS2.p7.1.m1.2.3.3.1.cmml">
         <mo id="S2.SS2.p7.1.m1.2.3.3.2.1" stretchy="false" xref="S2.SS2.p7.1.m1.2.3.3.1.cmml">
          (
         </mo>
         <mi id="S2.SS2.p7.1.m1.1.1" xref="S2.SS2.p7.1.m1.1.1.cmml">
          V
         </mi>
         <mo id="S2.SS2.p7.1.m1.2.3.3.2.2" xref="S2.SS2.p7.1.m1.2.3.3.1.cmml">
          ,
         </mo>
         <mi id="S2.SS2.p7.1.m1.2.2" xref="S2.SS2.p7.1.m1.2.2.cmml">
          E
         </mi>
         <mo id="S2.SS2.p7.1.m1.2.3.3.2.3" stretchy="false" xref="S2.SS2.p7.1.m1.2.3.3.1.cmml">
          )
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S2.SS2.p7.1.m1.2b">
        <apply id="S2.SS2.p7.1.m1.2.3.cmml" xref="S2.SS2.p7.1.m1.2.3">
         <times id="S2.SS2.p7.1.m1.2.3.1.cmml" xref="S2.SS2.p7.1.m1.2.3.1">
         </times>
         <ci id="S2.SS2.p7.1.m1.2.3.2.cmml" xref="S2.SS2.p7.1.m1.2.3.2">
          𝐺
         </ci>
         <interval closure="open" id="S2.SS2.p7.1.m1.2.3.3.1.cmml" xref="S2.SS2.p7.1.m1.2.3.3.2">
          <ci id="S2.SS2.p7.1.m1.1.1.cmml" xref="S2.SS2.p7.1.m1.1.1">
           𝑉
          </ci>
          <ci id="S2.SS2.p7.1.m1.2.2.cmml" xref="S2.SS2.p7.1.m1.2.2">
           𝐸
          </ci>
         </interval>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS2.p7.1.m1.2c">
        G(V,E)
       </annotation>
      </semantics>
     </math>
     can represent the relationships among multiple LLM-based agents. Here
     <math alttext="V" class="ltx_Math" display="inline" id="S2.SS2.p7.2.m2.1">
      <semantics id="S2.SS2.p7.2.m2.1a">
       <mi id="S2.SS2.p7.2.m2.1.1" xref="S2.SS2.p7.2.m2.1.1.cmml">
        V
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS2.p7.2.m2.1b">
        <ci id="S2.SS2.p7.2.m2.1.1.cmml" xref="S2.SS2.p7.2.m2.1.1">
         𝑉
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS2.p7.2.m2.1c">
        V
       </annotation>
      </semantics>
     </math>
     is the set of nodes, with
     <math alttext="V_{i}" class="ltx_Math" display="inline" id="S2.SS2.p7.3.m3.1">
      <semantics id="S2.SS2.p7.3.m3.1a">
       <msub id="S2.SS2.p7.3.m3.1.1" xref="S2.SS2.p7.3.m3.1.1.cmml">
        <mi id="S2.SS2.p7.3.m3.1.1.2" xref="S2.SS2.p7.3.m3.1.1.2.cmml">
         V
        </mi>
        <mi id="S2.SS2.p7.3.m3.1.1.3" xref="S2.SS2.p7.3.m3.1.1.3.cmml">
         i
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S2.SS2.p7.3.m3.1b">
        <apply id="S2.SS2.p7.3.m3.1.1.cmml" xref="S2.SS2.p7.3.m3.1.1">
         <csymbol cd="ambiguous" id="S2.SS2.p7.3.m3.1.1.1.cmml" xref="S2.SS2.p7.3.m3.1.1">
          subscript
         </csymbol>
         <ci id="S2.SS2.p7.3.m3.1.1.2.cmml" xref="S2.SS2.p7.3.m3.1.1.2">
          𝑉
         </ci>
         <ci id="S2.SS2.p7.3.m3.1.1.3.cmml" xref="S2.SS2.p7.3.m3.1.1.3">
          𝑖
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS2.p7.3.m3.1c">
        V_{i}
       </annotation>
      </semantics>
     </math>
     representing an LLM-based agent, and
     <math alttext="E" class="ltx_Math" display="inline" id="S2.SS2.p7.4.m4.1">
      <semantics id="S2.SS2.p7.4.m4.1a">
       <mi id="S2.SS2.p7.4.m4.1.1" xref="S2.SS2.p7.4.m4.1.1.cmml">
        E
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS2.p7.4.m4.1b">
        <ci id="S2.SS2.p7.4.m4.1.1.cmml" xref="S2.SS2.p7.4.m4.1.1">
         𝐸
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS2.p7.4.m4.1c">
        E
       </annotation>
      </semantics>
     </math>
     is the set of edges, with
     <math alttext="E_{ij}" class="ltx_Math" display="inline" id="S2.SS2.p7.5.m5.1">
      <semantics id="S2.SS2.p7.5.m5.1a">
       <msub id="S2.SS2.p7.5.m5.1.1" xref="S2.SS2.p7.5.m5.1.1.cmml">
        <mi id="S2.SS2.p7.5.m5.1.1.2" xref="S2.SS2.p7.5.m5.1.1.2.cmml">
         E
        </mi>
        <mrow id="S2.SS2.p7.5.m5.1.1.3" xref="S2.SS2.p7.5.m5.1.1.3.cmml">
         <mi id="S2.SS2.p7.5.m5.1.1.3.2" xref="S2.SS2.p7.5.m5.1.1.3.2.cmml">
          i
         </mi>
         <mo id="S2.SS2.p7.5.m5.1.1.3.1" lspace="0em" rspace="0em" xref="S2.SS2.p7.5.m5.1.1.3.1.cmml">
          ​
         </mo>
         <mi id="S2.SS2.p7.5.m5.1.1.3.3" xref="S2.SS2.p7.5.m5.1.1.3.3.cmml">
          j
         </mi>
        </mrow>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S2.SS2.p7.5.m5.1b">
        <apply id="S2.SS2.p7.5.m5.1.1.cmml" xref="S2.SS2.p7.5.m5.1.1">
         <csymbol cd="ambiguous" id="S2.SS2.p7.5.m5.1.1.1.cmml" xref="S2.SS2.p7.5.m5.1.1">
          subscript
         </csymbol>
         <ci id="S2.SS2.p7.5.m5.1.1.2.cmml" xref="S2.SS2.p7.5.m5.1.1.2">
          𝐸
         </ci>
         <apply id="S2.SS2.p7.5.m5.1.1.3.cmml" xref="S2.SS2.p7.5.m5.1.1.3">
          <times id="S2.SS2.p7.5.m5.1.1.3.1.cmml" xref="S2.SS2.p7.5.m5.1.1.3.1">
          </times>
          <ci id="S2.SS2.p7.5.m5.1.1.3.2.cmml" xref="S2.SS2.p7.5.m5.1.1.3.2">
           𝑖
          </ci>
          <ci id="S2.SS2.p7.5.m5.1.1.3.3.cmml" xref="S2.SS2.p7.5.m5.1.1.3.3">
           𝑗
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS2.p7.5.m5.1c">
        E_{ij}
       </annotation>
      </semantics>
     </math>
     representing the message passing and relationship between LLM-based agents
     <math alttext="V_{i}" class="ltx_Math" display="inline" id="S2.SS2.p7.6.m6.1">
      <semantics id="S2.SS2.p7.6.m6.1a">
       <msub id="S2.SS2.p7.6.m6.1.1" xref="S2.SS2.p7.6.m6.1.1.cmml">
        <mi id="S2.SS2.p7.6.m6.1.1.2" xref="S2.SS2.p7.6.m6.1.1.2.cmml">
         V
        </mi>
        <mi id="S2.SS2.p7.6.m6.1.1.3" xref="S2.SS2.p7.6.m6.1.1.3.cmml">
         i
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S2.SS2.p7.6.m6.1b">
        <apply id="S2.SS2.p7.6.m6.1.1.cmml" xref="S2.SS2.p7.6.m6.1.1">
         <csymbol cd="ambiguous" id="S2.SS2.p7.6.m6.1.1.1.cmml" xref="S2.SS2.p7.6.m6.1.1">
          subscript
         </csymbol>
         <ci id="S2.SS2.p7.6.m6.1.1.2.cmml" xref="S2.SS2.p7.6.m6.1.1.2">
          𝑉
         </ci>
         <ci id="S2.SS2.p7.6.m6.1.1.3.cmml" xref="S2.SS2.p7.6.m6.1.1.3">
          𝑖
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS2.p7.6.m6.1c">
        V_{i}
       </annotation>
      </semantics>
     </math>
     and
     <math alttext="V_{j}" class="ltx_Math" display="inline" id="S2.SS2.p7.7.m7.1">
      <semantics id="S2.SS2.p7.7.m7.1a">
       <msub id="S2.SS2.p7.7.m7.1.1" xref="S2.SS2.p7.7.m7.1.1.cmml">
        <mi id="S2.SS2.p7.7.m7.1.1.2" xref="S2.SS2.p7.7.m7.1.1.2.cmml">
         V
        </mi>
        <mi id="S2.SS2.p7.7.m7.1.1.3" xref="S2.SS2.p7.7.m7.1.1.3.cmml">
         j
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S2.SS2.p7.7.m7.1b">
        <apply id="S2.SS2.p7.7.m7.1.1.cmml" xref="S2.SS2.p7.7.m7.1.1">
         <csymbol cd="ambiguous" id="S2.SS2.p7.7.m7.1.1.1.cmml" xref="S2.SS2.p7.7.m7.1.1">
          subscript
         </csymbol>
         <ci id="S2.SS2.p7.7.m7.1.1.2.cmml" xref="S2.SS2.p7.7.m7.1.1.2">
          𝑉
         </ci>
         <ci id="S2.SS2.p7.7.m7.1.1.3.cmml" xref="S2.SS2.p7.7.m7.1.1.3">
          𝑗
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS2.p7.7.m7.1c">
        V_{j}
       </annotation>
      </semantics>
     </math>
     .
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS2.p8">
    <p class="ltx_p" id="S2.SS2.p8.1">
     We propose a categorization by taking into account the following aspects:
    </p>
    <ul class="ltx_itemize" id="S2.I5">
     <li class="ltx_item" id="S2.I5.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S2.I5.i1.p1">
       <p class="ltx_p" id="S2.I5.i1.p1.1">
        <span class="ltx_text ltx_font_bold" id="S2.I5.i1.p1.1.1">
         Multi-Role Coordination
        </span>
        : Cooperative, Competitive, Mixed, and Hierarchical;
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S2.I5.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para ltx_noindent" id="S2.I5.i2.p1">
       <p class="ltx_p" id="S2.I5.i2.p1.1">
        <span class="ltx_text ltx_font_bold" id="S2.I5.i2.p1.1.1">
         Planning Type
        </span>
        : Centralized Planning Decentralized Execution (CPDE) and Decentralized Planning Decentralized Execution (DPDE).
       </p>
      </div>
     </li>
    </ul>
   </div>
   <figure class="ltx_figure" id="S2.F3">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="299" id="S2.F3.g1" src="/html/2401.03428/assets/imgs/multi_agent.png" width="449"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 3:
     </span>
     The Relationship between LLM-based agents
    </figcaption>
   </figure>
   <div class="ltx_para ltx_noindent" id="S2.SS2.p9">
    <p class="ltx_p" id="S2.SS2.p9.1">
     It will be listed with the detailed information of each LLM-based in the following table
     <a class="ltx_ref" href="#S2.T2" title="Table 2 ‣ 2.2 Multi-Agent System ‣ 2 Overview ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     .
    </p>
   </div>
   <div class="ltx_table ltx_transformed_outer" id="S2.T1" style="width:631.0pt;height:1016.3pt;vertical-align:-0.0pt;">
    <div class="ltx_transformed_inner" style="width:1016.3pt;transform:translate(-192.65pt,-192.15pt) rotate(-90deg) ;">
     <figure>
      <figcaption class="ltx_caption ltx_centering">
       <span class="ltx_tag ltx_tag_table">
        Table 1:
       </span>
       List of LLM-based Single-Agent System.
      </figcaption>
      <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S2.T1.1">
       <thead class="ltx_thead">
        <tr class="ltx_tr" id="S2.T1.1.2.1">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S2.T1.1.2.1.1" style="padding:1pt 0.0pt;">
          ID
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S2.T1.1.2.1.2" style="padding:1pt 0.0pt;">
          Name
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T1.1.2.1.3" style="padding:1pt 0.0pt;">
          Field
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T1.1.2.1.4" style="padding:1pt 0.0pt;">
          Training
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T1.1.2.1.5" style="padding:1pt 0.0pt;">
          Environment
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T1.1.2.1.6" style="padding:1pt 0.0pt;">
          Data
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T1.1.2.1.7" style="padding:1pt 0.0pt;">
          Evaluation
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T1.1.2.1.8" style="padding:1pt 0.0pt;">
          Modality
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T1.1.2.1.9" style="padding:1pt 0.0pt;">
          Feedback
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T1.1.2.1.10" style="padding:1pt 0.0pt;">
          Tool
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T1.1.2.1.11" style="padding:1pt 0.0pt;">
          Planning
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T1.1.2.1.12" style="padding:1pt 0.0pt;">
          Review
         </th>
        </tr>
       </thead>
       <tbody class="ltx_tbody">
        <tr class="ltx_tr" id="S2.T1.1.3.1">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row ltx_border_t" id="S2.T1.1.3.1.1" style="padding:1pt 0.0pt;">
          1
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S2.T1.1.3.1.2" style="padding:1pt 0.0pt;">
          Out of One
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib29" title="">
            29
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" id="S2.T1.1.3.1.3" style="padding:1pt 0.0pt;">
          Sociology
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" id="S2.T1.1.3.1.4" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" id="S2.T1.1.3.1.5" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" id="S2.T1.1.3.1.6" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" id="S2.T1.1.3.1.7" style="padding:1pt 0.0pt;">
          with human
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" id="S2.T1.1.3.1.8" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" id="S2.T1.1.3.1.9" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" id="S2.T1.1.3.1.10" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" id="S2.T1.1.3.1.11" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" id="S2.T1.1.3.1.12" style="padding:1pt 0.0pt;">
          None
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.4.2">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.4.2.1" style="padding:1pt 0.0pt;">
          2
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.4.2.2" style="padding:1pt 0.0pt;">
          <cite class="ltx_cite ltx_citemacro_citet">
           Horton [
           <a class="ltx_ref" href="#bib.bib30" title="">
            30
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.4.2.3" style="padding:1pt 0.0pt;">
          Sociology
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.4.2.4" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.4.2.5" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.4.2.6" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.4.2.7" style="padding:1pt 0.0pt;">
          with human
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.4.2.8" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.4.2.9" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.4.2.10" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.4.2.11" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.4.2.12" style="padding:1pt 0.0pt;">
          None
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.5.3">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.5.3.1" style="padding:1pt 0.0pt;">
          3
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.5.3.2" style="padding:1pt 0.0pt;">
          <cite class="ltx_cite ltx_citemacro_citet">
           Park et al. [
           <a class="ltx_ref" href="#bib.bib31" title="">
            31
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.5.3.3" style="padding:1pt 0.0pt;">
          Sociology
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.5.3.4" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.5.3.5" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.5.3.6" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.5.3.7" style="padding:1pt 0.0pt;">
          with human
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.5.3.8" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.5.3.9" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.5.3.10" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.5.3.11" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.5.3.12" style="padding:1pt 0.0pt;">
          None
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.6.4">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.6.4.1" style="padding:1pt 0.0pt;">
          4
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.6.4.2" style="padding:1pt 0.0pt;">
          Social AI School
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib32" title="">
            32
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.6.4.3" style="padding:1pt 0.0pt;">
          Sociology
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.6.4.4" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.6.4.5" style="padding:1pt 0.0pt;">
          Simulation environment
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.6.4.6" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.6.4.7" style="padding:1pt 0.0pt;">
          Comparison available
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.6.4.8" style="padding:1pt 0.0pt;">
          Image to text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.6.4.9" style="padding:1pt 0.0pt;">
          self-feedback
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.6.4.10" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.6.4.11" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.6.4.12" style="padding:1pt 0.0pt;">
          RL
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.1">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.1.2" style="padding:1pt 0.0pt;">
          5
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.1.1" style="padding:1pt 0.0pt;">
          <math alttext="S^{3}" class="ltx_Math" display="inline" id="S2.T1.1.1.1.m1.1">
           <semantics id="S2.T1.1.1.1.m1.1a">
            <msup id="S2.T1.1.1.1.m1.1.1" xref="S2.T1.1.1.1.m1.1.1.cmml">
             <mi id="S2.T1.1.1.1.m1.1.1.2" xref="S2.T1.1.1.1.m1.1.1.2.cmml">
              S
             </mi>
             <mn id="S2.T1.1.1.1.m1.1.1.3" xref="S2.T1.1.1.1.m1.1.1.3.cmml">
              3
             </mn>
            </msup>
            <annotation-xml encoding="MathML-Content" id="S2.T1.1.1.1.m1.1b">
             <apply id="S2.T1.1.1.1.m1.1.1.cmml" xref="S2.T1.1.1.1.m1.1.1">
              <csymbol cd="ambiguous" id="S2.T1.1.1.1.m1.1.1.1.cmml" xref="S2.T1.1.1.1.m1.1.1">
               superscript
              </csymbol>
              <ci id="S2.T1.1.1.1.m1.1.1.2.cmml" xref="S2.T1.1.1.1.m1.1.1.2">
               𝑆
              </ci>
              <cn id="S2.T1.1.1.1.m1.1.1.3.cmml" type="integer" xref="S2.T1.1.1.1.m1.1.1.3">
               3
              </cn>
             </apply>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S2.T1.1.1.1.m1.1c">
             S^{3}
            </annotation>
           </semantics>
          </math>
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib33" title="">
            33
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.1.3" style="padding:1pt 0.0pt;">
          Sociology
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.1.4" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.1.5" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.1.6" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.1.7" style="padding:1pt 0.0pt;">
          with humans
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.1.8" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.1.9" style="padding:1pt 0.0pt;">
          environmental
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.1.10" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.1.11" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.1.12" style="padding:1pt 0.0pt;">
          None
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.7.5">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.7.5.1" style="padding:1pt 0.0pt;">
          6
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.7.5.2" style="padding:1pt 0.0pt;">
          <cite class="ltx_cite ltx_citemacro_citet">
           Li et al. [
           <a class="ltx_ref" href="#bib.bib34" title="">
            34
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.7.5.3" style="padding:1pt 0.0pt;">
          Sociology
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.7.5.4" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.7.5.5" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.7.5.6" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.7.5.7" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.7.5.8" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.7.5.9" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.7.5.10" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.7.5.11" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.7.5.12" style="padding:1pt 0.0pt;">
          None
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.8.6">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.8.6.1" style="padding:1pt 0.0pt;">
          7
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.8.6.2" style="padding:1pt 0.0pt;">
          <cite class="ltx_cite ltx_citemacro_citet">
           Li et al. [
           <a class="ltx_ref" href="#bib.bib35" title="">
            35
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.8.6.3" style="padding:1pt 0.0pt;">
          Sociology
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.8.6.4" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.8.6.5" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.8.6.6" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.8.6.7" style="padding:1pt 0.0pt;">
          with human
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.8.6.8" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.8.6.9" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.8.6.10" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.8.6.11" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.8.6.12" style="padding:1pt 0.0pt;">
          None
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.9.7">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.9.7.1" style="padding:1pt 0.0pt;">
          8
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.9.7.2" style="padding:1pt 0.0pt;">
          ChatLaw
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib36" title="">
            36
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.9.7.3" style="padding:1pt 0.0pt;">
          Law
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.9.7.4" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.9.7.5" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.9.7.6" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.9.7.7" style="padding:1pt 0.0pt;">
          with models
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.9.7.8" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.9.7.9" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.9.7.10" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.9.7.11" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.9.7.12" style="padding:1pt 0.0pt;">
          None
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.10.8">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.10.8.1" style="padding:1pt 0.0pt;">
          9
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.10.8.2" style="padding:1pt 0.0pt;">
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib37" title="">
            37
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.10.8.3" style="padding:1pt 0.0pt;">
          Law
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.10.8.4" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.10.8.5" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.10.8.6" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.10.8.7" style="padding:1pt 0.0pt;">
          with models
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.10.8.8" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.10.8.9" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.10.8.10" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.10.8.11" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.10.8.12" style="padding:1pt 0.0pt;">
          None
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.11.9">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.11.9.1" style="padding:1pt 0.0pt;">
          10
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.11.9.2" style="padding:1pt 0.0pt;">
          ChemCrow
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib38" title="">
            38
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.11.9.3" style="padding:1pt 0.0pt;">
          Chemistry
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.11.9.4" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.11.9.5" style="padding:1pt 0.0pt;">
          Experimental environment
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.11.9.6" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.11.9.7" style="padding:1pt 0.0pt;">
          LLM and expert assessment
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.11.9.8" style="padding:1pt 0.0pt;">
          Multimodal
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.11.9.9" style="padding:1pt 0.0pt;">
          self-feedback
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.11.9.10" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.11.9.11" style="padding:1pt 0.0pt;">
          ICL
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.11.9.12" style="padding:1pt 0.0pt;">
          ICL
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.12.10">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.12.10.1" style="padding:1pt 0.0pt;">
          11
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.12.10.2" style="padding:1pt 0.0pt;">
          ChatMOF
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib39" title="">
            39
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.12.10.3" style="padding:1pt 0.0pt;">
          Material Science
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.12.10.4" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.12.10.5" style="padding:1pt 0.0pt;">
          Experimental environment
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.12.10.6" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.12.10.7" style="padding:1pt 0.0pt;">
          success rate available
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.12.10.8" style="padding:1pt 0.0pt;">
          Multimodal
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.12.10.9" style="padding:1pt 0.0pt;">
          self-feedback
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.12.10.10" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.12.10.11" style="padding:1pt 0.0pt;">
          ICL
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.12.10.12" style="padding:1pt 0.0pt;">
          ICL
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.13.11">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.13.11.1" style="padding:1pt 0.0pt;">
          12
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.13.11.2" style="padding:1pt 0.0pt;">
          Mathagent
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib40" title="">
            40
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.13.11.3" style="padding:1pt 0.0pt;">
          Mathematics
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.13.11.4" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.13.11.5" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.13.11.6" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.13.11.7" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.13.11.8" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.13.11.9" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.13.11.10" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.13.11.11" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.13.11.12" style="padding:1pt 0.0pt;">
          None
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.14.12">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.14.12.1" style="padding:1pt 0.0pt;">
          13
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.14.12.2" style="padding:1pt 0.0pt;">
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib41" title="">
            41
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.14.12.3" style="padding:1pt 0.0pt;">
          Mathematics
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.14.12.4" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.14.12.5" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.14.12.6" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.14.12.7" style="padding:1pt 0.0pt;">
          with models
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.14.12.8" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.14.12.9" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.14.12.10" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.14.12.11" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.14.12.12" style="padding:1pt 0.0pt;">
          None
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.15.13">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.15.13.1" style="padding:1pt 0.0pt;">
          14
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.15.13.2" style="padding:1pt 0.0pt;">
          IGLU
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib42" title="">
            42
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.15.13.3" style="padding:1pt 0.0pt;">
          Collaborative
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.15.13.4" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.15.13.5" style="padding:1pt 0.0pt;">
          IGLU competition
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.15.13.6" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.15.13.7" style="padding:1pt 0.0pt;">
          with models
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.15.13.8" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.15.13.9" style="padding:1pt 0.0pt;">
          humanfeedback
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.15.13.10" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.15.13.11" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.15.13.12" style="padding:1pt 0.0pt;">
          RL
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.16.14">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.16.14.1" style="padding:1pt 0.0pt;">
          15
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.16.14.2" style="padding:1pt 0.0pt;">
          GPTEngineer
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib43" title="">
            43
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.16.14.3" style="padding:1pt 0.0pt;">
          Code
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.16.14.4" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.16.14.5" style="padding:1pt 0.0pt;">
          Code Environment
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.16.14.6" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.16.14.7" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.16.14.8" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.16.14.9" style="padding:1pt 0.0pt;">
          self-feedback
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.16.14.10" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.16.14.11" style="padding:1pt 0.0pt;">
          ICL
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.16.14.12" style="padding:1pt 0.0pt;">
          ICL
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.17.15">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.17.15.1" style="padding:1pt 0.0pt;">
          16
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.17.15.2" style="padding:1pt 0.0pt;">
          SmolModels
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib44" title="">
            44
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.17.15.3" style="padding:1pt 0.0pt;">
          Code
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.17.15.4" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.17.15.5" style="padding:1pt 0.0pt;">
          Code Environment
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.17.15.6" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.17.15.7" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.17.15.8" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.17.15.9" style="padding:1pt 0.0pt;">
          self-feedback
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.17.15.10" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.17.15.11" style="padding:1pt 0.0pt;">
          ICL
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.17.15.12" style="padding:1pt 0.0pt;">
          ICL
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.18.16">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.18.16.1" style="padding:1pt 0.0pt;">
          17
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.18.16.2" style="padding:1pt 0.0pt;">
          DemoGPT
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib45" title="">
            45
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.18.16.3" style="padding:1pt 0.0pt;">
          Code
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.18.16.4" style="padding:1pt 0.0pt;">
          Support
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.18.16.5" style="padding:1pt 0.0pt;">
          Code Environment
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.18.16.6" style="padding:1pt 0.0pt;">
          Support
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.18.16.7" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.18.16.8" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.18.16.9" style="padding:1pt 0.0pt;">
          self-feedback
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.18.16.10" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.18.16.11" style="padding:1pt 0.0pt;">
          ICL
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.18.16.12" style="padding:1pt 0.0pt;">
          ICL
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.19.17">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.19.17.1" style="padding:1pt 0.0pt;">
          18
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.19.17.2" style="padding:1pt 0.0pt;">
          IELLM
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib46" title="">
            46
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.19.17.3" style="padding:1pt 0.0pt;">
          Industrial Engineering
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.19.17.4" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.19.17.5" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.19.17.6" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.19.17.7" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.19.17.8" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.19.17.9" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.19.17.10" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.19.17.11" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.19.17.12" style="padding:1pt 0.0pt;">
          No
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.20.18">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.20.18.1" style="padding:1pt 0.0pt;">
          19
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.20.18.2" style="padding:1pt 0.0pt;">
          DialogueShaping
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib47" title="">
            47
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.20.18.3" style="padding:1pt 0.0pt;">
          Game
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.20.18.4" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.20.18.5" style="padding:1pt 0.0pt;">
          Game environment
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.20.18.6" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.20.18.7" style="padding:1pt 0.0pt;">
          with agents
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.20.18.8" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.20.18.9" style="padding:1pt 0.0pt;">
          environmental
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.20.18.10" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.20.18.11" style="padding:1pt 0.0pt;">
          ICL
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.20.18.12" style="padding:1pt 0.0pt;">
          RL
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.21.19">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.21.19.1" style="padding:1pt 0.0pt;">
          20
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.21.19.2" style="padding:1pt 0.0pt;">
          DECKARD
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib48" title="">
            48
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.21.19.3" style="padding:1pt 0.0pt;">
          Game
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.21.19.4" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.21.19.5" style="padding:1pt 0.0pt;">
          Game environment
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.21.19.6" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.21.19.7" style="padding:1pt 0.0pt;">
          ablation study
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.21.19.8" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.21.19.9" style="padding:1pt 0.0pt;">
          environmental
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.21.19.10" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.21.19.11" style="padding:1pt 0.0pt;">
          Multi-stage
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.21.19.12" style="padding:1pt 0.0pt;">
          RL
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.22.20">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.22.20.1" style="padding:1pt 0.0pt;">
          21
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.22.20.2" style="padding:1pt 0.0pt;">
          TaPA
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib49" title="">
            49
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.22.20.3" style="padding:1pt 0.0pt;">
          Embodied agents
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.22.20.4" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.22.20.5" style="padding:1pt 0.0pt;">
          Visual perception environment
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.22.20.6" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.22.20.7" style="padding:1pt 0.0pt;">
          with models
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.22.20.8" style="padding:1pt 0.0pt;">
          Visual
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.22.20.9" style="padding:1pt 0.0pt;">
          environmental
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.22.20.10" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.22.20.11" style="padding:1pt 0.0pt;">
          ICL
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.22.20.12" style="padding:1pt 0.0pt;">
          ICL
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.23.21">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.23.21.1" style="padding:1pt 0.0pt;">
          22
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.23.21.2" style="padding:1pt 0.0pt;">
          Voyager
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib50" title="">
            50
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.23.21.3" style="padding:1pt 0.0pt;">
          Game
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.23.21.4" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.23.21.5" style="padding:1pt 0.0pt;">
          Minecraft game
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.23.21.6" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.23.21.7" style="padding:1pt 0.0pt;">
          with models
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.23.21.8" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.23.21.9" style="padding:1pt 0.0pt;">
          environmental
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.23.21.10" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.23.21.11" style="padding:1pt 0.0pt;">
          ICL
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.23.21.12" style="padding:1pt 0.0pt;">
          ICL
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.24.22">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.24.22.1" style="padding:1pt 0.0pt;">
          23
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.24.22.2" style="padding:1pt 0.0pt;">
          GITM
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib51" title="">
            51
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.24.22.3" style="padding:1pt 0.0pt;">
          Game
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.24.22.4" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.24.22.5" style="padding:1pt 0.0pt;">
          Minecraft game
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.24.22.6" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.24.22.7" style="padding:1pt 0.0pt;">
          with models
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.24.22.8" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.24.22.9" style="padding:1pt 0.0pt;">
          environmental
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.24.22.10" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.24.22.11" style="padding:1pt 0.0pt;">
          ICL
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.24.22.12" style="padding:1pt 0.0pt;">
          ICL
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.25.23">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.25.23.1" style="padding:1pt 0.0pt;">
          24
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.25.23.2" style="padding:1pt 0.0pt;">
          LLM4RL
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib52" title="">
            52
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.25.23.3" style="padding:1pt 0.0pt;">
          Embodied agents
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.25.23.4" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.25.23.5" style="padding:1pt 0.0pt;">
          Different embodied environments
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.25.23.6" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.25.23.7" style="padding:1pt 0.0pt;">
          with baseline
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.25.23.8" style="padding:1pt 0.0pt;">
          Multi
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.25.23.9" style="padding:1pt 0.0pt;">
          environmental
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.25.23.10" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.25.23.11" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.25.23.12" style="padding:1pt 0.0pt;">
          RL
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.26.24">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.26.24.1" style="padding:1pt 0.0pt;">
          25
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.26.24.2" style="padding:1pt 0.0pt;">
          PET
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib53" title="">
            53
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.26.24.3" style="padding:1pt 0.0pt;">
          Embodied agents
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.26.24.4" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.26.24.5" style="padding:1pt 0.0pt;">
          AlfWorld interactive environment
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.26.24.6" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.26.24.7" style="padding:1pt 0.0pt;">
          with models
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.26.24.8" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.26.24.9" style="padding:1pt 0.0pt;">
          self-feedback
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.26.24.10" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.26.24.11" style="padding:1pt 0.0pt;">
          Multi-stage
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.26.24.12" style="padding:1pt 0.0pt;">
          None
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.27.25">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.27.25.1" style="padding:1pt 0.0pt;">
          26
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.27.25.2" style="padding:1pt 0.0pt;">
          REMEMBERER
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib54" title="">
            54
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.27.25.3" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.27.25.4" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.27.25.5" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.27.25.6" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.27.25.7" style="padding:1pt 0.0pt;">
          with models
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.27.25.8" style="padding:1pt 0.0pt;">
          Text
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.27.25.9" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.27.25.10" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.27.25.11" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.27.25.12" style="padding:1pt 0.0pt;">
          RL
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.28.26">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.28.26.1" style="padding:1pt 0.0pt;">
          27
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.28.26.2" style="padding:1pt 0.0pt;">
          UnifiedAgent
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib55" title="">
            55
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.28.26.3" style="padding:1pt 0.0pt;">
          Embodiedagents
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.28.26.4" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.28.26.5" style="padding:1pt 0.0pt;">
          Robot simulation environment
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.28.26.6" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.28.26.7" style="padding:1pt 0.0pt;">
          ablation study
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.28.26.8" style="padding:1pt 0.0pt;">
          Multi
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.28.26.9" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.28.26.10" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.28.26.11" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.28.26.12" style="padding:1pt 0.0pt;">
          RL
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.29.27">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.29.27.1" style="padding:1pt 0.0pt;">
          28
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.29.27.2" style="padding:1pt 0.0pt;">
          SayCan
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib56" title="">
            56
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.29.27.3" style="padding:1pt 0.0pt;">
          Embodied agents
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.29.27.4" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.29.27.5" style="padding:1pt 0.0pt;">
          Robot simulation environment
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.29.27.6" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.29.27.7" style="padding:1pt 0.0pt;">
          ablation study
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.29.27.8" style="padding:1pt 0.0pt;">
          Multi
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.29.27.9" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.29.27.10" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.29.27.11" style="padding:1pt 0.0pt;">
          External Method
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.29.27.12" style="padding:1pt 0.0pt;">
          RL
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.30.28">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.30.28.1" style="padding:1pt 0.0pt;">
          29
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.30.28.2" style="padding:1pt 0.0pt;">
          AIlegion
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib57" title="">
            57
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.30.28.3" style="padding:1pt 0.0pt;">
          Universal
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.30.28.4" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.30.28.5" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.30.28.6" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.30.28.7" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.30.28.8" style="padding:1pt 0.0pt;">
          Multi
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.30.28.9" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.30.28.10" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.30.28.11" style="padding:1pt 0.0pt;">
          ICL
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.30.28.12" style="padding:1pt 0.0pt;">
          ICL
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.31.29">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.31.29.1" style="padding:1pt 0.0pt;">
          30
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.31.29.2" style="padding:1pt 0.0pt;">
          AGiXT
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib58" title="">
            58
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.31.29.3" style="padding:1pt 0.0pt;">
          Universal
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.31.29.4" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.31.29.5" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.31.29.6" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.31.29.7" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.31.29.8" style="padding:1pt 0.0pt;">
          Multi-modal
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.31.29.9" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.31.29.10" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.31.29.11" style="padding:1pt 0.0pt;">
          ICL
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.31.29.12" style="padding:1pt 0.0pt;">
          ICL
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.32.30">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.32.30.1" style="padding:1pt 0.0pt;">
          31
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.32.30.2" style="padding:1pt 0.0pt;">
          BabyAGI
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib59" title="">
            59
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.32.30.3" style="padding:1pt 0.0pt;">
          Embodied agents
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.32.30.4" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.32.30.5" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.32.30.6" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.32.30.7" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.32.30.8" style="padding:1pt 0.0pt;">
          Multi
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.32.30.9" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.32.30.10" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.32.30.11" style="padding:1pt 0.0pt;">
          ICL
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.32.30.12" style="padding:1pt 0.0pt;">
          ICL
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.33.31">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.33.31.1" style="padding:1pt 0.0pt;">
          32
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.33.31.2" style="padding:1pt 0.0pt;">
          LoopGPT
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib60" title="">
            60
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.33.31.3" style="padding:1pt 0.0pt;">
          Universal
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.33.31.4" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.33.31.5" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.33.31.6" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.33.31.7" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.33.31.8" style="padding:1pt 0.0pt;">
          Multi-modal
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r" id="S2.T1.1.33.31.9" style="padding:1pt 0.0pt;">
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.33.31.10" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.33.31.11" style="padding:1pt 0.0pt;">
          ICL
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.33.31.12" style="padding:1pt 0.0pt;">
          ICL
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.34.32">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T1.1.34.32.1" style="padding:1pt 0.0pt;">
          33
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T1.1.34.32.2" style="padding:1pt 0.0pt;">
          GPTresearcher
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib61" title="">
            61
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.34.32.3" style="padding:1pt 0.0pt;">
          Research
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.34.32.4" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.34.32.5" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.34.32.6" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.34.32.7" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.34.32.8" style="padding:1pt 0.0pt;">
          Multi
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.34.32.9" style="padding:1pt 0.0pt;">
          No
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.34.32.10" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.34.32.11" style="padding:1pt 0.0pt;">
          External Method
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T1.1.34.32.12" style="padding:1pt 0.0pt;">
          None
         </td>
        </tr>
        <tr class="ltx_tr" id="S2.T1.1.35.33">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row ltx_border_bb" id="S2.T1.1.35.33.1" style="padding:1pt 0.0pt;">
          34
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S2.T1.1.35.33.2" style="padding:1pt 0.0pt;">
          SuperAGI
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib62" title="">
            62
           </a>
           ]
          </cite>
         </th>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" id="S2.T1.1.35.33.3" style="padding:1pt 0.0pt;">
          Universal
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" id="S2.T1.1.35.33.4" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" id="S2.T1.1.35.33.5" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" id="S2.T1.1.35.33.6" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" id="S2.T1.1.35.33.7" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" id="S2.T1.1.35.33.8" style="padding:1pt 0.0pt;">
          Multi-modal
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" id="S2.T1.1.35.33.9" style="padding:1pt 0.0pt;">
          None
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" id="S2.T1.1.35.33.10" style="padding:1pt 0.0pt;">
          Yes
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" id="S2.T1.1.35.33.11" style="padding:1pt 0.0pt;">
          ICL
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" id="S2.T1.1.35.33.12" style="padding:1pt 0.0pt;">
          ICL
         </td>
        </tr>
       </tbody>
      </table>
     </figure>
    </div>
   </div>
   <div class="ltx_table ltx_transformed_outer" id="S2.T2" style="width:95.9pt;height:447pt;vertical-align:-0.0pt;">
    <div class="ltx_transformed_inner" style="width:447.0pt;transform:translate(-175.53pt,-174.82pt) rotate(-90deg) ;">
     <figure>
      <figcaption class="ltx_caption ltx_centering">
       <span class="ltx_tag ltx_tag_table">
        Table 2:
       </span>
       List of LLM-based Multi-Agent System.
      </figcaption>
      <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S2.T2.1" style="width:433.6pt;height:94.8pt;vertical-align:-0.4pt;">
       <span class="ltx_transformed_inner" style="transform:translate(-279.0pt,60.8pt) scale(0.437262896251285,0.437262896251285) ;">
        <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S2.T2.1.1">
         <tbody class="ltx_tbody">
          <tr class="ltx_tr" id="S2.T2.1.1.1.1">
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S2.T2.1.1.1.1.1" style="padding:1pt 0.0pt;">
            ID
           </th>
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S2.T2.1.1.1.1.2" style="padding:1pt 0.0pt;">
            Name
           </th>
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T2.1.1.1.1.3" style="padding:1pt 0.0pt;">
            Field
           </th>
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T2.1.1.1.1.4" style="padding:1pt 0.0pt;">
            Training
           </th>
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T2.1.1.1.1.5" style="padding:1pt 0.0pt;">
            Environment
           </th>
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T2.1.1.1.1.6" style="padding:1pt 0.0pt;">
            Data
           </th>
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T2.1.1.1.1.7" style="padding:1pt 0.0pt;">
            Evaluation
           </th>
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T2.1.1.1.1.8" style="padding:1pt 0.0pt;">
            Modality
           </th>
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T2.1.1.1.1.9" style="padding:1pt 0.0pt;">
            Tool
           </th>
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T2.1.1.1.1.10" style="padding:1pt 0.0pt;">
            Planning
           </th>
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T2.1.1.1.1.11" style="padding:1pt 0.0pt;">
            Review
           </th>
           <th class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="S2.T2.1.1.1.1.12" style="padding:1pt 0.0pt;">
           </th>
           <td class="ltx_td ltx_border_tt" id="S2.T2.1.1.1.1.13" style="padding:1pt 0.0pt;">
           </td>
          </tr>
          <tr class="ltx_tr" id="S2.T2.1.1.2.2">
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row ltx_border_t" id="S2.T2.1.1.2.2.1" style="padding:1pt 0.0pt;">
            1
           </th>
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S2.T2.1.1.2.2.2" style="padding:1pt 0.0pt;">
            Generative Agents
            <cite class="ltx_cite ltx_citemacro_cite">
             [
             <a class="ltx_ref" href="#bib.bib63" title="">
              63
             </a>
             ]
            </cite>
           </th>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" id="S2.T2.1.1.2.2.3" style="padding:1pt 0.0pt;">
            Sociology
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" id="S2.T2.1.1.2.2.4" style="padding:1pt 0.0pt;">
            No
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" id="S2.T2.1.1.2.2.5" style="padding:1pt 0.0pt;">
            GameText
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" id="S2.T2.1.1.2.2.6" style="padding:1pt 0.0pt;">
            No
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" id="S2.T2.1.1.2.2.7" style="padding:1pt 0.0pt;">
            None
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" id="S2.T2.1.1.2.2.8" style="padding:1pt 0.0pt;">
            Text
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" id="S2.T2.1.1.2.2.9" style="padding:1pt 0.0pt;">
            No
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" id="S2.T2.1.1.2.2.10" style="padding:1pt 0.0pt;">
            ICL
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" id="S2.T2.1.1.2.2.11" style="padding:1pt 0.0pt;">
            reflection
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" id="S2.T2.1.1.2.2.12" style="padding:1pt 0.0pt;">
            Cooperative
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" id="S2.T2.1.1.2.2.13" style="padding:1pt 0.0pt;">
            CPDE
           </td>
          </tr>
          <tr class="ltx_tr" id="S2.T2.1.1.3.3">
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T2.1.1.3.3.1" style="padding:1pt 0.0pt;">
            2
           </th>
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T2.1.1.3.3.2" style="padding:1pt 0.0pt;">
            <cite class="ltx_cite ltx_citemacro_citet">
             Williams et al. [
             <a class="ltx_ref" href="#bib.bib64" title="">
              64
             </a>
             ]
            </cite>
           </th>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.3.3.3" style="padding:1pt 0.0pt;">
            Epidemiology research
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.3.3.4" style="padding:1pt 0.0pt;">
            No
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.3.3.5" style="padding:1pt 0.0pt;">
            Text
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.3.3.6" style="padding:1pt 0.0pt;">
            None
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.3.3.7" style="padding:1pt 0.0pt;">
            None
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.3.3.8" style="padding:1pt 0.0pt;">
            Text
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.3.3.9" style="padding:1pt 0.0pt;">
            None
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.3.3.10" style="padding:1pt 0.0pt;">
            None
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.3.3.11" style="padding:1pt 0.0pt;">
            None
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.3.3.12" style="padding:1pt 0.0pt;">
            Cooperative
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.3.3.13" style="padding:1pt 0.0pt;">
            CPDE
           </td>
          </tr>
          <tr class="ltx_tr" id="S2.T2.1.1.4.4">
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T2.1.1.4.4.1" style="padding:1pt 0.0pt;">
            3
           </th>
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T2.1.1.4.4.2" style="padding:1pt 0.0pt;">
            <cite class="ltx_cite ltx_citemacro_citet">
             Boiko et al. [
             <a class="ltx_ref" href="#bib.bib65" title="">
              65
             </a>
             ]
            </cite>
           </th>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.4.4.3" style="padding:1pt 0.0pt;">
            Chemistry
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.4.4.4" style="padding:1pt 0.0pt;">
            No
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.4.4.5" style="padding:1pt 0.0pt;">
            Experimental environment
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.4.4.6" style="padding:1pt 0.0pt;">
            No
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.4.4.7" style="padding:1pt 0.0pt;">
            None
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.4.4.8" style="padding:1pt 0.0pt;">
            Multi
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.4.4.9" style="padding:1pt 0.0pt;">
            Yes
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.4.4.10" style="padding:1pt 0.0pt;">
            ICL
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.4.4.11" style="padding:1pt 0.0pt;">
            ICL
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.4.4.12" style="padding:1pt 0.0pt;">
            Hierarchical
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.4.4.13" style="padding:1pt 0.0pt;">
            DPDE
           </td>
          </tr>
          <tr class="ltx_tr" id="S2.T2.1.1.5.5">
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T2.1.1.5.5.1" style="padding:1pt 0.0pt;">
            4
           </th>
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T2.1.1.5.5.2" style="padding:1pt 0.0pt;">
            ChatDev
            <cite class="ltx_cite ltx_citemacro_cite">
             [
             <a class="ltx_ref" href="#bib.bib66" title="">
              66
             </a>
             ]
            </cite>
           </th>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.5.5.3" style="padding:1pt 0.0pt;">
            Software Development
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.5.5.4" style="padding:1pt 0.0pt;">
            No
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.5.5.5" style="padding:1pt 0.0pt;">
            Software Development
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.5.5.6" style="padding:1pt 0.0pt;">
            No
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.5.5.7" style="padding:1pt 0.0pt;">
            on dataset available
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.5.5.8" style="padding:1pt 0.0pt;">
            Text
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.5.5.9" style="padding:1pt 0.0pt;">
            Yes
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.5.5.10" style="padding:1pt 0.0pt;">
            ICL
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.5.5.11" style="padding:1pt 0.0pt;">
            ICL
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.5.5.12" style="padding:1pt 0.0pt;">
            Cooperative
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.5.5.13" style="padding:1pt 0.0pt;">
            DPDE
           </td>
          </tr>
          <tr class="ltx_tr" id="S2.T2.1.1.6.6">
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T2.1.1.6.6.1" style="padding:1pt 0.0pt;">
            5
           </th>
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T2.1.1.6.6.2" style="padding:1pt 0.0pt;">
            MetaGPT
            <cite class="ltx_cite ltx_citemacro_cite">
             [
             <a class="ltx_ref" href="#bib.bib67" title="">
              67
             </a>
             ]
            </cite>
           </th>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.6.6.3" style="padding:1pt 0.0pt;">
            Code
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.6.6.4" style="padding:1pt 0.0pt;">
            Support
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.6.6.5" style="padding:1pt 0.0pt;">
            Code Environment
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.6.6.6" style="padding:1pt 0.0pt;">
            Support
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.6.6.7" style="padding:1pt 0.0pt;">
            with models
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.6.6.8" style="padding:1pt 0.0pt;">
            Multi
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.6.6.9" style="padding:1pt 0.0pt;">
            Support
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.6.6.10" style="padding:1pt 0.0pt;">
            ICL
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.6.6.11" style="padding:1pt 0.0pt;">
            ICL
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.6.6.12" style="padding:1pt 0.0pt;">
            Cooperative
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.6.6.13" style="padding:1pt 0.0pt;">
            DPDE
           </td>
          </tr>
          <tr class="ltx_tr" id="S2.T2.1.1.7.7">
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T2.1.1.7.7.1" style="padding:1pt 0.0pt;">
            6
           </th>
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T2.1.1.7.7.2" style="padding:1pt 0.0pt;">
            SCG
            <cite class="ltx_cite ltx_citemacro_cite">
             [
             <a class="ltx_ref" href="#bib.bib68" title="">
              68
             </a>
             ]
            </cite>
           </th>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.7.7.3" style="padding:1pt 0.0pt;">
            Code
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.7.7.4" style="padding:1pt 0.0pt;">
            No
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.7.7.5" style="padding:1pt 0.0pt;">
            Code Environment
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.7.7.6" style="padding:1pt 0.0pt;">
            No
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.7.7.7" style="padding:1pt 0.0pt;">
            with models
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.7.7.8" style="padding:1pt 0.0pt;">
            Text
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.7.7.9" style="padding:1pt 0.0pt;">
            Yes
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.7.7.10" style="padding:1pt 0.0pt;">
            ICL
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.7.7.11" style="padding:1pt 0.0pt;">
            ICL
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.7.7.12" style="padding:1pt 0.0pt;">
            Cooperative
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.7.7.13" style="padding:1pt 0.0pt;">
            DPDE
           </td>
          </tr>
          <tr class="ltx_tr" id="S2.T2.1.1.8.8">
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T2.1.1.8.8.1" style="padding:1pt 0.0pt;">
            7
           </th>
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T2.1.1.8.8.2" style="padding:1pt 0.0pt;">
            GPT4IA
            <cite class="ltx_cite ltx_citemacro_cite">
             [
             <a class="ltx_ref" href="#bib.bib69" title="">
              69
             </a>
             ]
            </cite>
           </th>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.8.8.3" style="padding:1pt 0.0pt;">
            Industrial environment
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.8.8.4" style="padding:1pt 0.0pt;">
            Yes
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.8.8.5" style="padding:1pt 0.0pt;">
            Engineering environment
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.8.8.6" style="padding:1pt 0.0pt;">
            No
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.8.8.7" style="padding:1pt 0.0pt;">
            None
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.8.8.8" style="padding:1pt 0.0pt;">
            Multi
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.8.8.9" style="padding:1pt 0.0pt;">
            Yes
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.8.8.10" style="padding:1pt 0.0pt;">
            ICL
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.8.8.11" style="padding:1pt 0.0pt;">
            ICL
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.8.8.12" style="padding:1pt 0.0pt;">
            Cooperative
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.8.8.13" style="padding:1pt 0.0pt;">
            DPDE
           </td>
          </tr>
          <tr class="ltx_tr" id="S2.T2.1.1.9.9">
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T2.1.1.9.9.1" style="padding:1pt 0.0pt;">
            8
           </th>
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T2.1.1.9.9.2" style="padding:1pt 0.0pt;">
            Planner-Actor-Reporter
            <cite class="ltx_cite ltx_citemacro_cite">
             [
             <a class="ltx_ref" href="#bib.bib70" title="">
              70
             </a>
             ]
            </cite>
           </th>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.9.9.3" style="padding:1pt 0.0pt;">
            Embodied environments
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.9.9.4" style="padding:1pt 0.0pt;">
            Support
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.9.9.5" style="padding:1pt 0.0pt;">
            A 2D partially observable grid-world
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.9.9.6" style="padding:1pt 0.0pt;">
            No
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.9.9.7" style="padding:1pt 0.0pt;">
            task success rate
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.9.9.8" style="padding:1pt 0.0pt;">
            Image plus text
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.9.9.9" style="padding:1pt 0.0pt;">
            No
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.9.9.10" style="padding:1pt 0.0pt;">
            ICL
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.9.9.11" style="padding:1pt 0.0pt;">
            ICL
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.9.9.12" style="padding:1pt 0.0pt;">
            Cooperative
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.9.9.13" style="padding:1pt 0.0pt;">
            DPDE
           </td>
          </tr>
          <tr class="ltx_tr" id="S2.T2.1.1.10.10">
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T2.1.1.10.10.1" style="padding:1pt 0.0pt;">
            9
           </th>
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T2.1.1.10.10.2" style="padding:1pt 0.0pt;">
            ProAgent
            <cite class="ltx_cite ltx_citemacro_cite">
             [
             <a class="ltx_ref" href="#bib.bib71" title="">
              71
             </a>
             ]
            </cite>
           </th>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.10.10.3" style="padding:1pt 0.0pt;">
            Universal
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.10.10.4" style="padding:1pt 0.0pt;">
            No
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.10.10.5" style="padding:1pt 0.0pt;">
            Text
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.10.10.6" style="padding:1pt 0.0pt;">
            No
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.10.10.7" style="padding:1pt 0.0pt;">
            with models
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.10.10.8" style="padding:1pt 0.0pt;">
            Multi
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.10.10.9" style="padding:1pt 0.0pt;">
            No
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.10.10.10" style="padding:1pt 0.0pt;">
            None
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.10.10.11" style="padding:1pt 0.0pt;">
            None
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.10.10.12" style="padding:1pt 0.0pt;">
            Hierarchical
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.10.10.13" style="padding:1pt 0.0pt;">
            DPDE
           </td>
          </tr>
          <tr class="ltx_tr" id="S2.T2.1.1.11.11">
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row" id="S2.T2.1.1.11.11.1" style="padding:1pt 0.0pt;">
            10
           </th>
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S2.T2.1.1.11.11.2" style="padding:1pt 0.0pt;">
            SAMA
            <cite class="ltx_cite ltx_citemacro_cite">
             [
             <a class="ltx_ref" href="#bib.bib72" title="">
              72
             </a>
             ]
            </cite>
           </th>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.11.11.3" style="padding:1pt 0.0pt;">
            Game
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.11.11.4" style="padding:1pt 0.0pt;">
            No
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.11.11.5" style="padding:1pt 0.0pt;">
            Game
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.11.11.6" style="padding:1pt 0.0pt;">
            No
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.11.11.7" style="padding:1pt 0.0pt;">
            with models
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.11.11.8" style="padding:1pt 0.0pt;">
            GameText
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.11.11.9" style="padding:1pt 0.0pt;">
            No
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.11.11.10" style="padding:1pt 0.0pt;">
            ICL
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.11.11.11" style="padding:1pt 0.0pt;">
            ICL and RL
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.11.11.12" style="padding:1pt 0.0pt;">
            Cooperative
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S2.T2.1.1.11.11.13" style="padding:1pt 0.0pt;">
            DPDE
           </td>
          </tr>
          <tr class="ltx_tr" id="S2.T2.1.1.12.12">
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_th ltx_th_row ltx_border_bb" id="S2.T2.1.1.12.12.1" style="padding:1pt 0.0pt;">
            11
           </th>
           <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S2.T2.1.1.12.12.2" style="padding:1pt 0.0pt;">
            Co-LLM-Agents
            <cite class="ltx_cite ltx_citemacro_cite">
             [
             <a class="ltx_ref" href="#bib.bib73" title="">
              73
             </a>
             ]
            </cite>
           </th>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" id="S2.T2.1.1.12.12.3" style="padding:1pt 0.0pt;">
            Game
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" id="S2.T2.1.1.12.12.4" style="padding:1pt 0.0pt;">
            No
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" id="S2.T2.1.1.12.12.5" style="padding:1pt 0.0pt;">
            Game
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" id="S2.T2.1.1.12.12.6" style="padding:1pt 0.0pt;">
            No
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" id="S2.T2.1.1.12.12.7" style="padding:1pt 0.0pt;">
            with models
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" id="S2.T2.1.1.12.12.8" style="padding:1pt 0.0pt;">
            GameText
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" id="S2.T2.1.1.12.12.9" style="padding:1pt 0.0pt;">
            No
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" id="S2.T2.1.1.12.12.10" style="padding:1pt 0.0pt;">
            None
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" id="S2.T2.1.1.12.12.11" style="padding:1pt 0.0pt;">
            None
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" id="S2.T2.1.1.12.12.12" style="padding:1pt 0.0pt;">
            Cooperative
           </td>
           <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" id="S2.T2.1.1.12.12.13" style="padding:1pt 0.0pt;">
            DPDE
           </td>
          </tr>
         </tbody>
        </table>
       </span>
      </div>
     </figure>
    </div>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.3
    </span>
    Agent System Template
   </h3>
   <div class="ltx_para ltx_noindent" id="S2.SS3.p1">
    <p class="ltx_p" id="S2.SS3.p1.1">
     Numerous researchers propose agent and template solutions to aid future researchers and enthusiasts in developing more pertinent agents. For instance, ToolLLM
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib74" title="">
       74
      </a>
      ]
     </cite>
     presents a comprehensive template for data construction, model training, and evaluation, fostering the development of agents with enhanced functionalities.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS3.p2">
    <p class="ltx_p" id="S2.SS3.p2.1">
     Various projects, such as AutoGPT
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib75" title="">
       75
      </a>
      ]
     </cite>
     , XLang
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib76" title="">
       76
      </a>
      ]
     </cite>
     , LangChain
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib77" title="">
       77
      </a>
      ]
     </cite>
     , MiniAGI
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib76" title="">
       76
      </a>
      ]
     </cite>
     , XAgent
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib78" title="">
       78
      </a>
      ]
     </cite>
     , OpenAgents
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib79" title="">
       79
      </a>
      ]
     </cite>
     , and WorkGPT
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib80" title="">
       80
      </a>
      ]
     </cite>
     , have open-sourced their code on GitHub. These templates support diverse functionalities, encompassing distinct approaches to thinking, planning, and reviewing, and permit the integration of various models as the agent’s core component. Furthermore, AgentGPT
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib81" title="">
       81
      </a>
      ]
     </cite>
     provides features for fine-tuning models and incorporating local data into the model training process.
     <cite class="ltx_cite ltx_citemacro_citet">
      Crouse et al. [
      <a class="ltx_ref" href="#bib.bib82" title="">
       82
      </a>
      ]
     </cite>
     introduces a streamlined template, utilizing Linear Temporal Logic (LTL) to facilitate the design and implementation of LLM-based agents, promoting rapid experimentation and enhancing agent performance.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S2.SS3.p3">
    <p class="ltx_p" id="S2.SS3.p3.1">
     Additionally, templates such as AutoGen
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib83" title="">
       83
      </a>
      ]
     </cite>
     , AgentVerse
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib84" title="">
       84
      </a>
      ]
     </cite>
     , AutoAgents
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib85" title="">
       85
      </a>
      ]
     </cite>
     , and AGENTS
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib86" title="">
       86
      </a>
      ]
     </cite>
     expedite the creation of multi-agent systems by allowing the selection and customization of roles within a multi-agent configuration, thereby simplifying the development process.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    3
   </span>
   LLM-based Agent System Framework
  </h2>
  <section class="ltx_subsection" id="S3.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.1
    </span>
    LLM-based Single Agent System
   </h3>
   <div class="ltx_para ltx_noindent" id="S3.SS1.p1">
    <p class="ltx_p" id="S3.SS1.p1.1">
     This section succinctly dissects the single-agent system into five key components: Planning, Memory, Rethinking, Environment, and Action. Each component, highlighted for its unique contribution, forms a crucial part of the unified whole, underscoring the system’s intricate design and functionality.
    </p>
   </div>
   <section class="ltx_subsubsection" id="S3.SS1.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.1.1
     </span>
     Planning
    </h4>
    <div class="ltx_para ltx_noindent" id="S3.SS1.SSS1.p1">
     <p class="ltx_p" id="S3.SS1.SSS1.p1.1">
      The planning capability defines an LLM-based agent’s ability to devise action sequences based on set objectives and existing environment constraints, ensuring goal fulfillment. It’s a vital feature of LLM-based agents, encompassing task analysis, potential action anticipation, optimal action selection, and the ability to tackle complex problems and tasks.
Unlike conventional and RL agents that use planning algorithms like Dijkstra
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib87" title="">
        87
       </a>
       ]
      </cite>
      , and POMDP
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib88" title="">
        88
       </a>
       ]
      </cite>
      to find the best action sequence in state spaces and plan in uncertain environments, RL-based agents require learning policies
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib5" title="">
        5
       </a>
       ]
      </cite>
      .
LLM-based agents derive their planning capabilities primarily from the LLM. Even though LLMs primarily communicate through natural language or specific text, their internal structures and training methods bestow upon them a level of planning proficiency. Recent research trends also highlight guiding LLMs in thinking and planning as a crucial development direction.
     </p>
    </div>
    <figure class="ltx_figure" id="S3.F4">
     <div class="ltx_inline-block ltx_transformed_outer" id="S3.F4.1" style="width:625.9pt;height:127.8pt;vertical-align:-120.9pt;">
      <span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
       <p class="ltx_p" id="S3.F4.1.1">
        <span class="ltx_text" id="S3.F4.1.1.1">
         <span class="ltx_ERROR undefined" id="S3.F4.1.1.1.1">
          {forest}
         </span>
         for tree=
forked edges,
grow’=0,
draw,
rounded corners,
node options=align=center,
text width=3cm,
s sep=5pt,
calign=edge midpoint,
fill=white,
drop shadow,

[Planning Capability of LLM-based Agents, fill=gray!45
[In-Context Learning Methods
[Chain of Thought (CoT)
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib89" title="">
           89
          </a>
          ,
          <a class="ltx_ref" href="#bib.bib90" title="">
           90
          </a>
          ,
          <a class="ltx_ref" href="#bib.bib91" title="">
           91
          </a>
          ,
          <a class="ltx_ref" href="#bib.bib92" title="">
           92
          </a>
          ]
         </cite>
         ]
[Self-consistency
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib93" title="">
           93
          </a>
          ]
         </cite>
         ]
[Tree of Thought
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib94" title="">
           94
          </a>
          ]
         </cite>
         ]
[Least-to-Most
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib95" title="">
           95
          </a>
          ]
         </cite>
         ]
[Skeleton of Thought
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib96" title="">
           96
          </a>
          ]
         </cite>
         ]
[Graph of Thought
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib97" title="">
           97
          </a>
          ]
         </cite>
         ]
[Progressive Hint Prompting
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib98" title="">
           98
          </a>
          ]
         </cite>
         ]
[Self-Refine
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib99" title="">
           99
          </a>
          ]
         </cite>
         ]
]
[External Methods
[LLM+P
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib100" title="">
           100
          </a>
          ]
         </cite>
         ]
[LLM-DP
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib101" title="">
           101
          </a>
          ]
         </cite>
         ]
[RAP
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib102" title="">
           102
          </a>
          ]
         </cite>
         ]
[
         <cite class="ltx_cite ltx_citemacro_citet">
          Romero et al. [
          <a class="ltx_ref" href="#bib.bib103" title="">
           103
          </a>
          ]
         </cite>
         ]
[
         <cite class="ltx_cite ltx_citemacro_citet">
          Merkle and Mikut [
          <a class="ltx_ref" href="#bib.bib104" title="">
           104
          </a>
          ]
         </cite>
         ]
]
[Multi-stage Methods
[SwiftSage
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib105" title="">
           105
          </a>
          ]
         </cite>
         ]
[DECKARD
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib48" title="">
           48
          </a>
          ]
         </cite>
         ]
]
]
        </span>
       </p>
      </span>
     </div>
     <figcaption class="ltx_caption">
      <span class="ltx_tag ltx_tag_figure">
       Figure 4:
      </span>
      Typology of the Planning capability.
     </figcaption>
    </figure>
    <section class="ltx_paragraph" id="S3.SS1.SSS1.Px1">
     <h5 class="ltx_title ltx_title_paragraph">
      In-Context Learning (ICL) Methods
     </h5>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS1.Px1.p1">
      <p class="ltx_p" id="S3.SS1.SSS1.Px1.p1.1">
       ICL utilizes natural language prompts, comprising task descriptions and potentially supplemented by task examples, to guide language models in problem-solving
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib106" title="">
         106
        </a>
        ]
       </cite>
       . Chain of Thought (CoT), encompassing Complex CoT
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib90" title="">
         90
        </a>
        ]
       </cite>
       , Auto CoT
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib91" title="">
         91
        </a>
        ]
       </cite>
       , and zero-shot CoT
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib92" title="">
         92
        </a>
        ]
       </cite>
       , employs thought-guided prompting to systematically deconstruct intricate tasks into smaller, manageable components, thus facilitating long-term planning and deliberation. To augment CoT’s efficacy, Self-consistency
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib93" title="">
         93
        </a>
        ]
       </cite>
       generates multiple reasoning pathways using an LLM and integrates the resulting answers, for example, by selecting the most consistent response through voting among the pathways. Tree of Thought (ToT)
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib94" title="">
         94
        </a>
        ]
       </cite>
       segregates problems into several thinking stages, producing multiple concepts at each stage and forming a tree-like structure. The search process implements breadth-first or depth-first exploration and evaluates each state using classifiers or majority voting.
      </p>
     </div>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS1.Px1.p2">
      <p class="ltx_p" id="S3.SS1.SSS1.Px1.p2.1">
       To enhance CoT’s generalization abilities, Least-to-Most
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib95" title="">
         95
        </a>
        ]
       </cite>
       disassembles complex problems into sub-problems and sequentially addresses them. Concurrently, Skeleton of Thought (SoT)
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib96" title="">
         96
        </a>
        ]
       </cite>
       initially directs the LLM to generate an answer’s framework and subsequently complete each skeleton point through API calls or batch decoding, significantly expediting answer generation. Graph of Thought (GoT)
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib97" title="">
         97
        </a>
        ]
       </cite>
       represents the information produced by the LLM as an arbitrary graph, with information units (LLM thoughts) as vertices and edges corresponding to dependencies between these vertices. Progressive Hint Prompting (PHP)
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib98" title="">
         98
        </a>
        ]
       </cite>
       hastens guidance toward accurate answers by employing previously generated responses as prompts, thus improving the model’s reasoning capabilities in problem-solving contexts. Self-Refine
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib107" title="">
         107
        </a>
        ]
       </cite>
       enables the LLM to offer multifaceted feedback on its outputs and iteratively refine prior outputs based on this feedback, emulating the iterative improvement process humans may experience when generating text.
      </p>
     </div>
    </section>
    <section class="ltx_paragraph" id="S3.SS1.SSS1.Px2">
     <h5 class="ltx_title ltx_title_paragraph">
      External Capabilities Methods
     </h5>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS1.Px2.p1">
      <p class="ltx_p" id="S3.SS1.SSS1.Px2.p1.1">
       Using external capabilities methods involves employing tools, algorithms, or simulation techniques for planning purposes in computer science. LLM+P
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib100" title="">
         100
        </a>
        ]
       </cite>
       relies on classical planners for long-term planning, utilizing the Planning Domain Definition Language (PDDL)
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib108" title="">
         108
        </a>
        ]
       </cite>
       as an intermediate interface. The model translates the problem into a problem description (problem PDDL), requests the planner to generate a PDDL plan based on the "Domain PDDL," and then converts the PDDL plan back into natural language. LLM-DP
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib101" title="">
         101
        </a>
        ]
       </cite>
       combines LLM with symbolic planners for solving embodied tasks, leveraging LLM’s understanding of the impact of actions on the environment and the planner’s solution-finding efficiency.
       <cite class="ltx_cite ltx_citemacro_citet">
        Guan et al. [
        <a class="ltx_ref" href="#bib.bib109" title="">
         109
        </a>
        ]
       </cite>
       utilizes GPT-4 to generate PDDL, refines the PDDL with natural language feedback, and applies the extracted domain models for robust planning across various methods. RAP
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib102" title="">
         102
        </a>
        ]
       </cite>
       framework implements conscious planning reasoning in LLM by adding a world model. It employs principled planning, specifically Monte Carlo Tree Search, for efficient exploration to generate high-reward reasoning trajectories.
      </p>
     </div>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS1.Px2.p2">
      <p class="ltx_p" id="S3.SS1.SSS1.Px2.p2.1">
       In addition to these methods, several other approaches have been proposed to enhance planning and reasoning capabilities.
       <cite class="ltx_cite ltx_citemacro_citet">
        Zhao et al. [
        <a class="ltx_ref" href="#bib.bib110" title="">
         110
        </a>
        ]
       </cite>
       employs LLMs as commonsense world models and applies heuristic strategies to address complex task-planning problems.
       <cite class="ltx_cite ltx_citemacro_citet">
        Romero et al. [
        <a class="ltx_ref" href="#bib.bib103" title="">
         103
        </a>
        ]
       </cite>
       outlines a feasible approach to integrating Cognitive Architectures and LLM.
       <cite class="ltx_cite ltx_citemacro_citet">
        Merkle and Mikut [
        <a class="ltx_ref" href="#bib.bib104" title="">
         104
        </a>
        ]
       </cite>
       proposes a simulation-based method that represents heterogeneous contexts through knowledge graphs and entity embeddings and dynamically composes policies through parallel-running agents. FaR
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib111" title="">
         111
        </a>
        ]
       </cite>
       combined with Theory of Mind (ToM)
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib112" title="">
         112
        </a>
        ]
       </cite>
       offers a framework that enables the LLM to anticipate future challenges and contemplate potential actions. LATS
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib113" title="">
         113
        </a>
        ]
       </cite>
       incorporates LLM as an intelligent agent, value function, and optimizer, leveraging its potential benefits to augment planning, action, and reasoning capabilities. Think-on-Graph
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib114" title="">
         114
        </a>
        ]
       </cite>
       facilitates agents in identifying the optimal planning path by executing beam search on the knowledge graph. These approaches demonstrate the versatility and potential of LLMs in various planning and reasoning tasks, paving the way for future more advanced and efficient solutions.
      </p>
     </div>
    </section>
    <section class="ltx_paragraph" id="S3.SS1.SSS1.Px3">
     <h5 class="ltx_title ltx_title_paragraph">
      Multi-stage Methods
     </h5>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS1.Px3.p1">
      <p class="ltx_p" id="S3.SS1.SSS1.Px3.p1.1">
       Multi-stage methods dissect the planning process into distinct stages, aiming to improve LLM’s performance in complex reasoning and problem-solving tasks. SwiftSage
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib105" title="">
         105
        </a>
        ]
       </cite>
       is a framework inspired by the dual-process theory that combines the advantages of behavior cloning and guided LLMs to enhance task completion performance and efficiency. It consists of two primary modules: the SWIFT module, responsible for rapid, intuitive thinking, and the SAGE module, handling deliberative thinking. The exploration process of DECKARD
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib48" title="">
         48
        </a>
        ]
       </cite>
       is divided into the Dreaming and Awake stages. During the Dreaming stage, the agent utilizes an LLM to decompose the task into sub-goals. In the Awake stage, the agent learns a modular strategy for each sub-goal, verifying or rectifying assumptions based on the agent’s experience.
      </p>
     </div>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS1.Px3.p2">
      <p class="ltx_p" id="S3.SS1.SSS1.Px3.p2.1">
       These methods enhance the model’s performance in complex reasoning and problem-solving tasks. Through these methods, LLM can be guided in thinking and planning to address intricate problems and tasks.
      </p>
     </div>
    </section>
   </section>
   <section class="ltx_subsubsection" id="S3.SS1.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.1.2
     </span>
     Memory
    </h4>
    <div class="ltx_para ltx_noindent" id="S3.SS1.SSS2.p1">
     <p class="ltx_p" id="S3.SS1.SSS2.p1.1">
      The primary function of the memory system in LLM-based agents is to preserve and regulate knowledge, experiential data, and historical information, which can be utilized for reference and modification during problem-solving and task execution processes. Additionally, the memory frequently embodies the present state of the LLM-based agent. Conventionally, the memory of such agents is documented in a textual format, enabling seamless interaction with the LLM. This paper delineates prevalent memory classifications and their associated design approaches.
     </p>
    </div>
    <figure class="ltx_figure" id="S3.F5">
     <div class="ltx_inline-block ltx_transformed_outer" id="S3.F5.1" style="width:484.1pt;height:55.8pt;vertical-align:-48.9pt;">
      <span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
       <p class="ltx_p" id="S3.F5.1.1">
        <span class="ltx_text" id="S3.F5.1.1.1">
         <span class="ltx_ERROR undefined" id="S3.F5.1.1.1.1">
          {forest}
         </span>
         for tree=
forked edges,
grow’=0,
draw,
rounded corners,
node options=align=center,
text width=3cm,
s sep=5pt,
calign=edge midpoint,
fill=white,
drop shadow,

[Memory Capability of LLM-based Agents, fill=gray!45
[Short-term Memory
]
[Long-term Memory
[Knowledge Graphs
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib115" title="">
           115
          </a>
          ]
         </cite>
         ]
[Vector Databases
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib116" title="">
           116
          </a>
          ]
         </cite>
         ]
[Relational Database Queries]
[API Calls]
]
[Memory Retrieval
]
]
        </span>
       </p>
      </span>
     </div>
     <figcaption class="ltx_caption">
      <span class="ltx_tag ltx_tag_figure">
       Figure 5:
      </span>
      Typology of the Memory.
     </figcaption>
    </figure>
    <section class="ltx_paragraph" id="S3.SS1.SSS2.Px1">
     <h5 class="ltx_title ltx_title_paragraph">
      Short-term Memory
     </h5>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS2.Px1.p1">
      <p class="ltx_p" id="S3.SS1.SSS2.Px1.p1.1">
       Short-term memory stores and manipulates a restricted quantity of transient information. Within the context of an LLM-based agent, this can be realized by amalgamating input text with contextually pertinent data related to the ongoing task, bound by the LLM’s context length. As demonstrated by ChatDev
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib66" title="">
         66
        </a>
        ]
       </cite>
       , the conversation history is archived, enabling decision-making for subsequent steps based on the recorded inter-agent communication. LangChain
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib77" title="">
         77
        </a>
        ]
       </cite>
       enhances short-term memory efficiency by encapsulating crucial information from each interaction and preserving the most recurrent interactions.
      </p>
     </div>
    </section>
    <section class="ltx_paragraph" id="S3.SS1.SSS2.Px2">
     <h5 class="ltx_title ltx_title_paragraph">
      Long-term Memory
     </h5>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS2.Px2.p1">
      <p class="ltx_p" id="S3.SS1.SSS2.Px2.p1.1">
       Long-term memory stores and regulates substantial volumes of knowledge, experiential data, and historical records. An agent utilizing long-term memory may incorporate interaction with external knowledge bases, databases, or other information sources. The design of external memory can leverage techniques such as knowledge graphs
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib115" title="">
         115
        </a>
        ]
       </cite>
       , vector databases
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib116" title="">
         116
        </a>
        ]
       </cite>
       , relational database queries, or API calls to engage with external data sources. Voyager
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib50" title="">
         50
        </a>
        ]
       </cite>
       employs a perpetually expanding skill repository for storing and retrieving complex behaviors. In GITM
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib51" title="">
         51
        </a>
        ]
       </cite>
       , memory primarily aids in extracting the most pertinent textual knowledge from an external knowledge base, which the long-term memory subsequently utilizes to identify necessary materials, tools, and related information. To augment agent performance, the ExpeL
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib117" title="">
         117
        </a>
        ]
       </cite>
       agent preserves experiences across multiple tasks. In Reflexion
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib118" title="">
         118
        </a>
        ]
       </cite>
       , experiences acquired through self-reflection are conserved in long-term memory and influence future actions. MemGPT
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib119" title="">
         119
        </a>
        ]
       </cite>
       is an intelligent system adept at managing diverse memory hierarchies, effectively providing an extended context within the limited context window of LLMs and utilizing interrupts to manage control flow between itself and the user.
      </p>
     </div>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS2.Px2.p2">
      <p class="ltx_p" id="S3.SS1.SSS2.Px2.p2.1">
       Short-term memory can encapsulate and generalize vital information, which is then dynamically stored in long-term memory. As demonstrated by Generative Agents
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib63" title="">
         63
        </a>
        ]
       </cite>
       , the agent sustains its internal state by archiving and updating its experiences, generating natural language by aligning its experiences with the language representations of LLMs, and consistently amassing new experiences and integrating them with existing ones. The agent’s memory undergoes evolution over time and can be dynamically accessed to represent the agent’s current state.
      </p>
     </div>
    </section>
    <section class="ltx_paragraph" id="S3.SS1.SSS2.Px3">
     <h5 class="ltx_title ltx_title_paragraph">
      Memory Retrieval
     </h5>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS2.Px3.p1">
      <p class="ltx_p" id="S3.SS1.SSS2.Px3.p1.1">
       Retrieval-augmented generation
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib120" title="">
         120
        </a>
        ]
       </cite>
       can combine an information retrieval component with an LLM and produce a more reliable output. The retrieval objectives can be represented with a memory, i.e., a knowledge library. Memory retrieval is paramount for the proficient access and administration of memories. In the context of LLM-based agents, memory retrieval can be facilitated through online learning and adaptive modification. When formulating memory retrieval methods, techniques such as online reinforcement learning, multitask learning, or attention mechanisms can enable real-time updates and adjustments to model parameters. LaGR-SEQ
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib121" title="">
         121
        </a>
        ]
       </cite>
       introduces SEQ (Sample Efficient Query), which trains a secondary RL-based agent to determine when to query the LLM for solutions. REMEMBER
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib54" title="">
         54
        </a>
        ]
       </cite>
       equips LLMs with long-term memory, empowering them to draw from past experiences, and introduces Reinforcement Learning and Experience Memory to update memories. Synapse
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib122" title="">
         122
        </a>
        ]
       </cite>
       purges task-irrelevant information from the raw state, enabling more samples within a restricted context. It generalizes to novel tasks by storing sample embeddings and retrieving them via similarity search.
       <cite class="ltx_cite ltx_citemacro_citet">
        Kang et al. [
        <a class="ltx_ref" href="#bib.bib123" title="">
         123
        </a>
        ]
       </cite>
       discusses the characteristics of distributed memory storage in the human brain. It proposes the construction of an internal memory module, DT-Mem, which allows agents to store and retrieve information relevant to various downstream tasks.
       <cite class="ltx_cite ltx_citemacro_citet">
        Wang et al. [
        <a class="ltx_ref" href="#bib.bib124" title="">
         124
        </a>
        ]
       </cite>
       utilizes a multimodel memory to store the agent’s collected interaction experiences and use the embodied RAG to make the agents self-improve by exploring the open-world Minecraft.
      </p>
     </div>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS2.Px3.p2">
      <p class="ltx_p" id="S3.SS1.SSS2.Px3.p2.1">
       Utilizing the approaches above, it is feasible to devise memory types and retrieval techniques tailored for LLM-based agents. It is imperative to highlight that LLM-based agents can encompass both memory categories concurrently. The judicious selection of pertinent memory classification and retrieval mechanisms can bolster LLM-based agents in proficiently storing, administering, and expeditiously extracting data while addressing challenges and accomplishing tasks, thus augmenting their efficacy and adaptability.
      </p>
     </div>
    </section>
   </section>
   <section class="ltx_subsubsection" id="S3.SS1.SSS3">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.1.3
     </span>
     Rethinking
    </h4>
    <div class="ltx_para ltx_noindent" id="S3.SS1.SSS3.p1">
     <p class="ltx_p" id="S3.SS1.SSS3.p1.1">
      The capacity for introspection in an LLM-based agent, denoted as its rethinking ability, encompasses evaluating prior decisions and subsequent environmental feedback. This faculty permits an LLM-based agent to thoroughly examine its behavior, decision-making, and learning processes, augmenting its intelligence and adaptability.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S3.SS1.SSS3.p2">
     <p class="ltx_p" id="S3.SS1.SSS3.p2.1">
      Contemporary investigations on LLM-based agent rethinking can be extensively classified according to learning methodologies, which include In-Context Learning, Supervised Learning, Reinforcement Learning, and Modular Coordination approaches.
     </p>
    </div>
    <figure class="ltx_figure" id="S3.F6">
     <div class="ltx_inline-block ltx_transformed_outer" id="S3.F6.1" style="width:552.3pt;height:115.8pt;vertical-align:-108.9pt;">
      <span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
       <p class="ltx_p" id="S3.F6.1.1">
        <span class="ltx_text" id="S3.F6.1.1.1">
         <span class="ltx_ERROR undefined" id="S3.F6.1.1.1.1">
          {forest}
         </span>
         for tree=
forked edges,
grow’=0,
draw,
rounded corners,
node options=align=center,
text width=3cm,
s sep=5pt,
calign=edge midpoint,
fill=white,
drop shadow,

[Rethinking Capability of LLM-based Agents, fill=gray!45
[In-Context Learning Methods
[ReAct
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib125" title="">
           125
          </a>
          ]
         </cite>
         ]
[Reflexion
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib118" title="">
           118
          </a>
          ]
         </cite>
         ]
]
[Supervised Learning Methods
[CoH
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib126" title="">
           126
          </a>
          ]
         </cite>
         ]
[Process Supervision
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib127" title="">
           127
          </a>
          ]
         </cite>
         ]
[Introspective Tips
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib128" title="">
           128
          </a>
          ]
         </cite>
         ]
[Hinting Approach
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib129" title="">
           129
          </a>
          ]
         </cite>
         ]
]
[Reinforcement Learning Methods
[Retroformer
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib130" title="">
           130
          </a>
          ]
         </cite>
         ]
[REMEMBER
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib54" title="">
           54
          </a>
          ]
         </cite>
         ]
[Dialogue Shaping
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib47" title="">
           47
          </a>
          ]
         </cite>
         ]
[REX
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib131" title="">
           131
          </a>
          ]
         </cite>
         ]
[ICPI
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib132" title="">
           132
          </a>
          ]
         </cite>
         ]
]
[Modular Coordination Methods
[DIVERSITY
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib133" title="">
           133
          </a>
          ]
         </cite>
         ]
[DEPS
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib134" title="">
           134
          </a>
          ]
         </cite>
         ]
[PET
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib53" title="">
           53
          </a>
          ]
         </cite>
         ]
[Three-Part System
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib70" title="">
           70
          </a>
          ]
         </cite>
         ]
]
]
        </span>
       </p>
      </span>
     </div>
     <figcaption class="ltx_caption">
      <span class="ltx_tag ltx_tag_figure">
       Figure 6:
      </span>
      Typology of the Rethinking capability.
     </figcaption>
    </figure>
    <section class="ltx_paragraph" id="S3.SS1.SSS3.Px1">
     <h5 class="ltx_title ltx_title_paragraph">
      In-Context Learning Methods
     </h5>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS3.Px1.p1">
      <p class="ltx_p" id="S3.SS1.SSS3.Px1.p1.1">
       As delineated in Section
       <a class="ltx_ref" href="#S3.SS1.SSS1" title="3.1.1 Planning ‣ 3.1 LLM-based Single Agent System ‣ 3 LLM-based Agent System Framework ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
        <span class="ltx_text ltx_ref_tag">
         3.1.1
        </span>
       </a>
       , In-Context Learning (ICL) leverages task-specific linguistic prompts and instances for reinforcement. ReAct
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib125" title="">
         125
        </a>
        ]
       </cite>
       implements an interactive paradigm, alternating between generating task-related linguistic reasoning and actions, thereby fostering a synergistic enhancement of the language model’s reasoning and action proficiencies. This approach exhibits generality and adaptability in addressing tasks requiring diverse action spaces and reasoning. Reflexion
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib118" title="">
         118
        </a>
        ]
       </cite>
       computes heuristics after each action and ascertains whether to reset the environment based on self-reflection, consequently bolstering the agent’s reasoning capabilities.
      </p>
     </div>
    </section>
    <section class="ltx_paragraph" id="S3.SS1.SSS3.Px2">
     <h5 class="ltx_title ltx_title_paragraph">
      Supervised Learning Methods
     </h5>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS3.Px2.p1">
      <p class="ltx_p" id="S3.SS1.SSS3.Px2.p1.1">
       Supervised learning typically hinges on diverse sources, encompassing LLMs, human expertise, code compilers, and external knowledge. CoH
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib126" title="">
         126
        </a>
        ]
       </cite>
       exploits a sequence of prior outputs annotated with feedback to foster model self-enhancement. This technique employs supervised fine-tuning, positive and negative grading, and experience replay to augment performance.
       <cite class="ltx_cite ltx_citemacro_citet">
        Lightman et al. [
        <a class="ltx_ref" href="#bib.bib127" title="">
         127
        </a>
        ]
       </cite>
       experimentally substantiates that process supervision surpasses outcome supervision in mathematical reasoning tasks, and active learning considerably boosts the efficacy of process supervision. Introspective Tips
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib128" title="">
         128
        </a>
        ]
       </cite>
       introduces a self-examination framework predicated on past trajectories or expert demonstrations, generating succinct yet valuable insights for strategy optimization.
       <cite class="ltx_cite ltx_citemacro_citet">
        Zhou et al. [
        <a class="ltx_ref" href="#bib.bib129" title="">
         129
        </a>
        ]
       </cite>
       advocates a hinting methodology founded on explicit code-based self-verification to refine the mathematical reasoning prowess of the GPT-4 code interpreter. Moreover, it incorporates a Diversity Verifier on the Reasoning Step to strengthen the agent’s reasoning aptitudes further.
      </p>
     </div>
    </section>
    <section class="ltx_paragraph" id="S3.SS1.SSS3.Px3">
     <h5 class="ltx_title ltx_title_paragraph">
      Reinforcement Learning Methods
     </h5>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS3.Px3.p1">
      <p class="ltx_p" id="S3.SS1.SSS3.Px3.p1.1">
       Reinforcement learning emphasizes the enhancement of parameters by acquiring knowledge from historical experiences. Retroformer
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib130" title="">
         130
        </a>
        ]
       </cite>
       ameliorates agents by learning from retrospective models and employing policy gradients to modulate the LLM-based agent’s prompts autonomously. REMEMBER
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib54" title="">
         54
        </a>
        ]
       </cite>
       introduces a novel semi-parametric reinforcement learning methodology that amalgamates reinforcement learning and experience memory to update memory and augment capabilities via experiential analogies.
       <cite class="ltx_cite ltx_citemacro_citet">
        Zhou et al. [
        <a class="ltx_ref" href="#bib.bib47" title="">
         47
        </a>
        ]
       </cite>
       offers a framework for shaping dialogues, expediting agent convergence to optimal strategies by extracting pertinent information from non-player characters (NPCs) and transmuting it into a knowledge graph. REX
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib131" title="">
         131
        </a>
        ]
       </cite>
       incorporates an auxiliary reward layer and assimilates concepts akin to Upper Confidence Bound scores, culminating in more robust and efficient AI agent performance. ICPI
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib132" title="">
         132
        </a>
        ]
       </cite>
       demonstrates the capacity to execute RL tasks without expert demonstrations or gradients by iteratively updating prompt content through trial-and-error interactions within the RL environment.
       <cite class="ltx_cite ltx_citemacro_citet">
        Liu et al. [
        <a class="ltx_ref" href="#bib.bib135" title="">
         135
        </a>
        ]
       </cite>
       integrates agent planning and actions by utilizing learning and planning in Bayesian adaptive Markov decision processes (MDP). In this approach, LLM constructs updated posteriors of unknown environments from memory buffers for learning while generating optimal trajectories that maximize value functions for multiple future steps in planning.
       <cite class="ltx_cite ltx_citemacro_citet">
        Wang et al. [
        <a class="ltx_ref" href="#bib.bib136" title="">
         136
        </a>
        ]
       </cite>
       proposes a technique that enables LLM-based agents to undergo perpetual improvement through iterative exploration and Proximal Policy Optimization (PPO)
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib137" title="">
         137
        </a>
        ]
       </cite>
       training in interaction with the environment and other agents. This method additionally facilitates the integration of short-term experiences into long-term memory.
      </p>
     </div>
    </section>
    <section class="ltx_paragraph" id="S3.SS1.SSS3.Px4">
     <h5 class="ltx_title ltx_title_paragraph">
      Modular Coordination Methods
     </h5>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS3.Px4.p1">
      <p class="ltx_p" id="S3.SS1.SSS3.Px4.p1.1">
       Modular coordination methods typically encompass multiple modules operating in concert to facilitate planning and introspection for LLM-based agents. DIVERSITY
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib133" title="">
         133
        </a>
        ]
       </cite>
       investigates various prompts to augment the diversity of reasoning pathways. By incorporating a verifier to discern between favorable and unfavorable responses, it attains enhanced weighted voting and employs diversity verification to ascertain the correctness of each step. The DEPS
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib134" title="">
         134
        </a>
        ]
       </cite>
       framework interacts with LLM planners through descriptors, interpreters, and goal selectors, improving overall success rates. PET
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib53" title="">
         53
        </a>
        ]
       </cite>
       leverages LLM knowledge to streamline control problems for embodied agents. This framework includes planning, elimination, and tracking modules to accomplish higher-level subtasks.
       <cite class="ltx_cite ltx_citemacro_citet">
        Dasgupta et al. [
        <a class="ltx_ref" href="#bib.bib70" title="">
         70
        </a>
        ]
       </cite>
       examines the integration of planners, actors, and reporters into a tripartite system. This system demonstrates generalization capabilities in distributed learning, investigates failure scenarios, and delineates how reinforcement learning trains individual components to enhance performance.
      </p>
     </div>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS3.Px4.p2">
      <p class="ltx_p" id="S3.SS1.SSS3.Px4.p2.1">
       These methods and frameworks optimize the performance of LLM-based agents through environmental feedback, self-learning, and reflection. They have achieved significant advancements in enhancing the capabilities of LLM-based agents in reflection and re-planning.
      </p>
     </div>
    </section>
   </section>
   <section class="ltx_subsubsection" id="S3.SS1.SSS4">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.1.4
     </span>
     Environments
    </h4>
    <div class="ltx_para ltx_noindent" id="S3.SS1.SSS4.p1">
     <p class="ltx_p" id="S3.SS1.SSS4.p1.1">
      The LLM-based agents can interact and learn from various environments through environmental feedback. These environments can broadly be computer, gaming, code, real-world, and simulation environments.
     </p>
    </div>
    <figure class="ltx_figure" id="S3.F7">
     <div class="ltx_inline-block ltx_transformed_outer" id="S3.F7.1" style="width:484.1pt;height:91.8pt;vertical-align:-84.9pt;">
      <span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
       <p class="ltx_p" id="S3.F7.1.1">
        <span class="ltx_text" id="S3.F7.1.1.1">
         <span class="ltx_ERROR undefined" id="S3.F7.1.1.1.1">
          {forest}
         </span>
         for tree=
forked edges,
grow’=0,
draw,
rounded corners,
node options=align=center,
text width=3cm,
s sep=5pt,
calign=edge midpoint,
fill=white,
drop shadow,

[Environment of LLM-based Agents, fill=gray!45
[Computer Environment
[Web Scraping]
[API Calls]
[Web Searching]
[Software Interaction]
[Database Queries]
]
[Gaming Environment
[Character Control]
[Environmental Interactions]
[State Perception]
]
[Code Environment
[Code Generation]
[Code Debugging]
[Code Evaluation]
]
[Real-World Environment
[Data Collection]
[Device Control]
[Human-Machine Interaction]
]
[Simulation Environment
[Model Manipulation]
[Data Analysis]
[Optimization]
]
]
        </span>
       </p>
      </span>
     </div>
     <figcaption class="ltx_caption">
      <span class="ltx_tag ltx_tag_figure">
       Figure 7:
      </span>
      Typology of the Environment.
     </figcaption>
    </figure>
    <section class="ltx_paragraph" id="S3.SS1.SSS4.Px1">
     <h5 class="ltx_title ltx_title_paragraph">
      Computer Environment
     </h5>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS4.Px1.p1">
      <p class="ltx_p" id="S3.SS1.SSS4.Px1.p1.1">
       LLM-based agents engage with websites, APIs, databases, and applications across computer, web, and mobile contexts in computational environments. The modes of interaction encompass:
      </p>
      <ul class="ltx_itemize" id="S3.I1">
       <li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
        <span class="ltx_tag ltx_tag_item">
         •
        </span>
        <div class="ltx_para" id="S3.I1.i1.p1">
         <p class="ltx_p" id="S3.I1.i1.p1.1">
          <span class="ltx_text ltx_font_bold" id="S3.I1.i1.p1.1.1">
           Web Scraping
          </span>
          : Gleaning information from websites to acquire essential data and knowledge.
         </p>
        </div>
       </li>
       <li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
        <span class="ltx_tag ltx_tag_item">
         •
        </span>
        <div class="ltx_para" id="S3.I1.i2.p1">
         <p class="ltx_p" id="S3.I1.i2.p1.1">
          <span class="ltx_text ltx_font_bold" id="S3.I1.i2.p1.1.1">
           API Calls
          </span>
          : Employing Web APIs to access or transmit data, fostering interactions with online services.
         </p>
        </div>
       </li>
       <li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
        <span class="ltx_tag ltx_tag_item">
         •
        </span>
        <div class="ltx_para" id="S3.I1.i3.p1">
         <p class="ltx_p" id="S3.I1.i3.p1.1">
          <span class="ltx_text ltx_font_bold" id="S3.I1.i3.p1.1.1">
           Web Searching
          </span>
          : Utilizing search engines to discover pertinent information and resources for problem-solving or task completion.
         </p>
        </div>
       </li>
       <li class="ltx_item" id="S3.I1.i4" style="list-style-type:none;">
        <span class="ltx_tag ltx_tag_item">
         •
        </span>
        <div class="ltx_para" id="S3.I1.i4.p1">
         <p class="ltx_p" id="S3.I1.i4.p1.1">
          <span class="ltx_text ltx_font_bold" id="S3.I1.i4.p1.1.1">
           Software Interaction
          </span>
          : Manipulating and interfacing with software applications, ranging from word processors to graphic design tools, to efficiently execute tasks.
         </p>
        </div>
       </li>
       <li class="ltx_item" id="S3.I1.i5" style="list-style-type:none;">
        <span class="ltx_tag ltx_tag_item">
         •
        </span>
        <div class="ltx_para ltx_noindent" id="S3.I1.i5.p1">
         <p class="ltx_p" id="S3.I1.i5.p1.1">
          <span class="ltx_text ltx_font_bold" id="S3.I1.i5.p1.1.1">
           Database Queries
          </span>
          : Access and update databases directly, enabling real-time data handling and processing.
         </p>
        </div>
       </li>
      </ul>
     </div>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS4.Px1.p2">
      <p class="ltx_p" id="S3.SS1.SSS4.Px1.p2.1">
       Contemporary research introduces methodologies such as RCI
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib138" title="">
         138
        </a>
        ]
       </cite>
       , which guides language models to perform computational tasks via natural language commands. WebArena
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib139" title="">
         139
        </a>
        ]
       </cite>
       offers an independent, self-hosted web environment for constructing autonomous agents. WebGPT
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib140" title="">
         140
        </a>
        ]
       </cite>
       capitalizes on search engines for document retrieval, enabling end-to-end imitation and reinforcement learning to optimize retrieval and aggregation while generating responses that reference web-retrieved information. Mobile-Env
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib141" title="">
         141
        </a>
        ]
       </cite>
       permits agents to observe screenshots and view frameworks of the Android operating system, enabling actions such as tapping the screen or inputting commands to interact with Android applications. SheetCopilot
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib142" title="">
         142
        </a>
        ]
       </cite>
       facilitates interaction with spreadsheets using natural language.
      </p>
     </div>
    </section>
    <section class="ltx_paragraph" id="S3.SS1.SSS4.Px2">
     <h5 class="ltx_title ltx_title_paragraph">
      Gaming Environment
     </h5>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS4.Px2.p1">
      <p class="ltx_p" id="S3.SS1.SSS4.Px2.p1.1">
       LLM-based agents interact with virtual characters, objects, and settings in gaming environments. Interaction methodologies in gaming contexts include:
      </p>
      <ul class="ltx_itemize" id="S3.I2">
       <li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
        <span class="ltx_tag ltx_tag_item">
         •
        </span>
        <div class="ltx_para" id="S3.I2.i1.p1">
         <p class="ltx_p" id="S3.I2.i1.p1.1">
          <span class="ltx_text ltx_font_bold" id="S3.I2.i1.p1.1.1">
           Character Control
          </span>
          : Directing in-game characters by issuing commands (e.g., move, jump, attack).
         </p>
        </div>
       </li>
       <li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
        <span class="ltx_tag ltx_tag_item">
         •
        </span>
        <div class="ltx_para" id="S3.I2.i2.p1">
         <p class="ltx_p" id="S3.I2.i2.p1.1">
          <span class="ltx_text ltx_font_bold" id="S3.I2.i2.p1.1.1">
           Environmental Interactions
          </span>
          : Engaging with objects in the game environment (e.g., pick up, use, place) to complete tasks.
         </p>
        </div>
       </li>
       <li class="ltx_item" id="S3.I2.i3" style="list-style-type:none;">
        <span class="ltx_tag ltx_tag_item">
         •
        </span>
        <div class="ltx_para ltx_noindent" id="S3.I2.i3.p1">
         <p class="ltx_p" id="S3.I2.i3.p1.1">
          <span class="ltx_text ltx_font_bold" id="S3.I2.i3.p1.1.1">
           State Perception
          </span>
          : Gathering status information from the game environment (e.g., character position, item count) for decision-making and planning.
         </p>
        </div>
       </li>
      </ul>
     </div>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS4.Px2.p2">
      <p class="ltx_p" id="S3.SS1.SSS4.Px2.p2.1">
       Prominent applications encompass DECKARD
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib48" title="">
         48
        </a>
        ]
       </cite>
       , which deploys LLM-guided exploration for devising tasks within the Minecraft game. VOYAGER
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib50" title="">
         50
        </a>
        ]
       </cite>
       constitutes a Minecraft-based LLM-driven lifelong learning agent that persistently explores the world, acquires various skills, and uncovers discoveries. GITM
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib51" title="">
         51
        </a>
        ]
       </cite>
       employs an "indirect mapping" approach to translate long-term and intricate goals into a series of low-level keyboard and mouse actions, facilitating efficient and adaptable operations in the Minecraft game. AgentSims
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib143" title="">
         143
        </a>
        ]
       </cite>
       generates a virtual town with diverse buildings and residents, streamlining task design and addressing challenges researchers might encounter due to varying backgrounds and programming expertise levels. LLM-Deliberation
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib144" title="">
         144
        </a>
        ]
       </cite>
       establishes a versatile testing platform for text-based, multi-agent, multi-issue, and semantically rich negotiation games. Moreover, the platform enables effortless adjustment of difficulty levels.
      </p>
     </div>
    </section>
    <section class="ltx_paragraph" id="S3.SS1.SSS4.Px3">
     <h5 class="ltx_title ltx_title_paragraph">
      Coding Environment
     </h5>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS4.Px3.p1">
      <p class="ltx_p" id="S3.SS1.SSS4.Px3.p1.1">
       The coding environment enables LLM-based agents to compose, modify, and execute code for various tasks, from coding to verifying reasoning through code. Interaction methodologies in the code environment encompass code generation, code debugging, and code evaluation. Code generation produces code snippets or complete programs based on task requirements. Code debugging identifies and rectifies errors or issues in the code. Code evaluation executes code and assesses its performance, optimizing and refining it based on runtime error messages or output.
      </p>
     </div>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS4.Px3.p2">
      <p class="ltx_p" id="S3.SS1.SSS4.Px3.p2.1">
       LLift
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib145" title="">
         145
        </a>
        ]
       </cite>
       constitutes a fully automated agent that interfaces with static analysis tools and LLM to address challenges such as error-specific modeling, extensive problem scopes, and LLM’s non-determinism. MetaGPT
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib67" title="">
         67
        </a>
        ]
       </cite>
       incorporates human workflows into LLM-driven collaboration, employing Standard Operating Procedures (SOPs) as prompts to facilitate structured coordination. Similarly,
       <cite class="ltx_cite ltx_citemacro_citet">
        Dong et al. [
        <a class="ltx_ref" href="#bib.bib68" title="">
         68
        </a>
        ]
       </cite>
       introduces a self-collaboration framework involving multiple LLM roles for auto-generating code. Within this framework, distinct roles assume analyst, programmer, tester, etc., forming a collaborative team to achieve code generation tasks. ChatDev
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib66" title="">
         66
        </a>
        ]
       </cite>
       represents a virtual chat-driven software development company that segments the development process into four discrete sequential stages based on the waterfall model: design, coding, testing, and documentation. CSV
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib129" title="">
         129
        </a>
        ]
       </cite>
       augments mathematical reasoning abilities by prompting the interpreter to utilize code for self-verification, enhancing solution confidence by indicating verified states.
      </p>
     </div>
    </section>
    <section class="ltx_paragraph" id="S3.SS1.SSS4.Px4">
     <h5 class="ltx_title ltx_title_paragraph">
      Real-World Environment
     </h5>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS4.Px4.p1">
      <p class="ltx_p" id="S3.SS1.SSS4.Px4.p1.1">
       LLM-based agents can interact with real-world devices, sensors, and actuators, facilitating their operation in real-world scenarios. The interaction methodologies in these situations include:
      </p>
      <ul class="ltx_itemize" id="S3.I3">
       <li class="ltx_item" id="S3.I3.i1" style="list-style-type:none;">
        <span class="ltx_tag ltx_tag_item">
         •
        </span>
        <div class="ltx_para" id="S3.I3.i1.p1">
         <p class="ltx_p" id="S3.I3.i1.p1.1">
          <span class="ltx_text ltx_font_bold" id="S3.I3.i1.p1.1.1">
           Data Collection
          </span>
          : LLM-based agents can accumulate real-time data from sensors such as cameras and microphones, which are then employed for analysis and decision-making.
         </p>
        </div>
       </li>
       <li class="ltx_item" id="S3.I3.i2" style="list-style-type:none;">
        <span class="ltx_tag ltx_tag_item">
         •
        </span>
        <div class="ltx_para" id="S3.I3.i2.p1">
         <p class="ltx_p" id="S3.I3.i2.p1.1">
          <span class="ltx_text ltx_font_bold" id="S3.I3.i2.p1.1.1">
           Device Control
          </span>
          : Regarding device control, LLM-based agents can manipulate actuators like robotic arms and drones by transmitting control signals, thereby accomplishing specific tasks.
         </p>
        </div>
       </li>
       <li class="ltx_item" id="S3.I3.i3" style="list-style-type:none;">
        <span class="ltx_tag ltx_tag_item">
         •
        </span>
        <div class="ltx_para ltx_noindent" id="S3.I3.i3.p1">
         <p class="ltx_p" id="S3.I3.i3.p1.1">
          <span class="ltx_text ltx_font_bold" id="S3.I3.i3.p1.1.1">
           Human-Machine Interaction
          </span>
          : Regarding human-machine interaction, LLM-based agents excel in engaging in natural language communication with human users, enabling the reception of instructions, provision of feedback, and response to queries.
         </p>
        </div>
       </li>
      </ul>
     </div>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS4.Px4.p2">
      <p class="ltx_p" id="S3.SS1.SSS4.Px4.p2.1">
       <cite class="ltx_cite ltx_citemacro_citet">
        Di Palo et al. [
        <a class="ltx_ref" href="#bib.bib55" title="">
         55
        </a>
        ]
       </cite>
       introduces a language-centric reasoning toolkit framework tested in a sparse reward robot manipulation environment where robots execute tasks like stacking objects. TaPA
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib146" title="">
         146
        </a>
        ]
       </cite>
       presents an embedded task-planning agent for real-world planning under physical scene constraints. The SimBot challenge in the Alexa Prize project
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib147" title="">
         147
        </a>
        ]
       </cite>
       aims to construct robot assistants capable of completing tasks in a simulated physical environment.
       <cite class="ltx_cite ltx_citemacro_citet">
        Zheng et al. [
        <a class="ltx_ref" href="#bib.bib148" title="">
         148
        </a>
        ]
       </cite>
       proposes 23 heuristic methods for guiding LLM-based agents in collaborating and co-creating services alongside humans.
      </p>
     </div>
    </section>
    <section class="ltx_paragraph" id="S3.SS1.SSS4.Px5">
     <h5 class="ltx_title ltx_title_paragraph">
      Simulation Environment
     </h5>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS4.Px5.p1">
      <p class="ltx_p" id="S3.SS1.SSS4.Px5.p1.1">
       LLM-based agents use virtual models representing real-world systems or processes in simulation environments, such as economic markets, physical environments, and transportation systems. Interaction methodologies in simulation environments include:
      </p>
     </div>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS4.Px5.p2">
      <ul class="ltx_itemize" id="S3.I4">
       <li class="ltx_item" id="S3.I4.i1" style="list-style-type:none;">
        <span class="ltx_tag ltx_tag_item">
         •
        </span>
        <div class="ltx_para" id="S3.I4.i1.p1">
         <p class="ltx_p" id="S3.I4.i1.p1.1">
          <span class="ltx_text ltx_font_bold" id="S3.I4.i1.p1.1.1">
           Model Manipulation
          </span>
          : Adjusting parameters or variables within the simulation model to explore various scenarios and analyze their outcomes.
         </p>
        </div>
       </li>
       <li class="ltx_item" id="S3.I4.i2" style="list-style-type:none;">
        <span class="ltx_tag ltx_tag_item">
         •
        </span>
        <div class="ltx_para" id="S3.I4.i2.p1">
         <p class="ltx_p" id="S3.I4.i2.p1.1">
          <span class="ltx_text ltx_font_bold" id="S3.I4.i2.p1.1.1">
           Data Analysis
          </span>
          : Collect and analyze data generated by the simulation to identify patterns, trends, and insights that can inform decision-making.
         </p>
        </div>
       </li>
       <li class="ltx_item" id="S3.I4.i3" style="list-style-type:none;">
        <span class="ltx_tag ltx_tag_item">
         •
        </span>
        <div class="ltx_para ltx_noindent" id="S3.I4.i3.p1">
         <p class="ltx_p" id="S3.I4.i3.p1.1">
          <span class="ltx_text ltx_font_bold" id="S3.I4.i3.p1.1.1">
           Optimization
          </span>
          : Applying optimization algorithms to determine the best course of action within the simulated environment, considering constraints and objectives.
         </p>
        </div>
       </li>
      </ul>
     </div>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS4.Px5.p3">
      <p class="ltx_p" id="S3.SS1.SSS4.Px5.p3.1">
       In recent research, TrafficGPT
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib149" title="">
         149
        </a>
        ]
       </cite>
       demonstrates the capability to perform traffic flow analysis and address questions within the traffic simulation environment SUMO
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib150" title="">
         150
        </a>
        ]
       </cite>
       .
       <cite class="ltx_cite ltx_citemacro_citet">
        Li et al. [
        <a class="ltx_ref" href="#bib.bib34" title="">
         34
        </a>
        ]
       </cite>
       examines the behavioral characteristics of social agents in simulated social platforms.
       <cite class="ltx_cite ltx_citemacro_citet">
        Horton [
        <a class="ltx_ref" href="#bib.bib30" title="">
         30
        </a>
        ]
       </cite>
       investigates the behavior of LLM-based agents in economic simulation scenarios and compares the differences between agent and actual human behavior. AucArena
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib151" title="">
         151
        </a>
        ]
       </cite>
       is a simulation environment for auctions wherein agents must consider resource and risk management factors.
      </p>
     </div>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS4.Px5.p4">
      <p class="ltx_p" id="S3.SS1.SSS4.Px5.p4.1">
       These simulation environments provide a controlled yet realistic context for LLM-based agents to learn, experiment, and develop solutions applicable to real-world scenarios, facilitating the transfer of knowledge and skills from the virtual domain to real-life applications.
      </p>
     </div>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS4.Px5.p5">
      <p class="ltx_p" id="S3.SS1.SSS4.Px5.p5.1">
       In summary, the LLM-based agent learns and applies knowledge through natural language interaction and environmental feedback across various environments, offering robust solutions for different tasks.
      </p>
     </div>
    </section>
   </section>
   <section class="ltx_subsubsection" id="S3.SS1.SSS5">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.1.5
     </span>
     Action
    </h4>
    <div class="ltx_para ltx_noindent" id="S3.SS1.SSS5.p1">
     <p class="ltx_p" id="S3.SS1.SSS5.p1.1">
      The action capabilities of an LLM-based agent pertain to the performance of actions or the employment of tools. Such agents’ predominant mode of interaction is typically through text generation, facilitating communication with the external environment, a characteristic reminiscent of the Generative Agents
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib63" title="">
        63
       </a>
       ]
      </cite>
      . An alternative methodology incorporates the LLM or the agent-employing tools, encompassing APIs, calculators, code interpreters, or actions within a physical environment through text-based directives. This further extends to the strategic planning and deployment of tools, which may necessitate the development of new tools for their implementation.
     </p>
    </div>
    <figure class="ltx_figure" id="S3.F8">
     <div class="ltx_inline-block ltx_transformed_outer" id="S3.F8.1" style="width:612.5pt;height:103.8pt;vertical-align:-96.9pt;">
      <span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
       <p class="ltx_p" id="S3.F8.1.1">
        <span class="ltx_text" id="S3.F8.1.1.1">
         <span class="ltx_ERROR undefined" id="S3.F8.1.1.1.1">
          {forest}
         </span>
         for tree=
forked edges,
grow’=0,
draw,
rounded corners,
node options=align=center,
text width=3cm,
s sep=5pt,
calign=edge midpoint,
fill=white,
drop shadow,

[Actions of LLM-based Agents, fill=gray!45
[Tool Employment
[MRKL
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib152" title="">
           152
          </a>
          ]
         </cite>
         ]
[TALM
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib153" title="">
           153
          </a>
          ]
         </cite>
         ]
[ToolFormer
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib154" title="">
           154
          </a>
          ]
         </cite>
         ]
[HuggingGPT
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib155" title="">
           155
          </a>
          ]
         </cite>
         ]
[Chameleon
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib156" title="">
           156
          </a>
          ]
         </cite>
         ]
[Gorilla
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib157" title="">
           157
          </a>
          ]
         </cite>
         ]
[RestGPT
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib158" title="">
           158
          </a>
          ]
         </cite>
         ]
[D-Bot
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib159" title="">
           159
          </a>
          ]
         </cite>
         ]
[Chameleon
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib156" title="">
           156
          </a>
          ]
         </cite>
         ]
[AVIS
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib160" title="">
           160
          </a>
          ]
         </cite>
         ]
]
[Tool Planning
[ChatCoT
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib161" title="">
           161
          </a>
          ]
         </cite>
         ]
[TPTU
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib162" title="">
           162
          </a>
          ]
         </cite>
         ]
[ToolLLM
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib74" title="">
           74
          </a>
          ]
         </cite>
         ]
[Gentopia
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib163" title="">
           163
          </a>
          ]
         </cite>
         ]
]
[Tool Creation
[
         <cite class="ltx_cite ltx_citemacro_citet">
          Cai et al. [
          <a class="ltx_ref" href="#bib.bib164" title="">
           164
          </a>
          ]
         </cite>
         ]
[CRAFT
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib165" title="">
           165
          </a>
          ]
         </cite>
         ]
]
]
        </span>
       </p>
      </span>
     </div>
     <figcaption class="ltx_caption">
      <span class="ltx_tag ltx_tag_figure">
       Figure 8:
      </span>
      Typology of the Actions.
     </figcaption>
    </figure>
    <section class="ltx_paragraph" id="S3.SS1.SSS5.Px1">
     <h5 class="ltx_title ltx_title_paragraph">
      Tool Employment
     </h5>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS5.Px1.p1">
      <p class="ltx_p" id="S3.SS1.SSS5.Px1.p1.1">
       MRKL
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib152" title="">
         152
        </a>
        ]
       </cite>
       integrates LLM and external tools to address intricate problems. This encompasses the construction of modules and routers and the routing of natural language queries. TALM
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib153" title="">
         153
        </a>
        ]
       </cite>
       connects language models with tools, facilitating text-to-text API connections. ToolFormer
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib154" title="">
         154
        </a>
        ]
       </cite>
       exemplifies the LLM’s capacity to leverage external tools, augmenting performance across various tasks. HuggingGPT
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib155" title="">
         155
        </a>
        ]
       </cite>
       combines multiple AI models and tools for task planning and execution, including text classification and object detection. Tool Learning with Foundation Models explores tool learning, presenting a generalized framework that merges foundational models and toolsets to achieve efficient task execution. Gorilla
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib157" title="">
         157
        </a>
        ]
       </cite>
       delves into LLM’s applications in API calls and program synthesis, context learning, and task decomposition to enhance performance. RestGPT
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib158" title="">
         158
        </a>
        ]
       </cite>
       is a method that connects LLM with RESTful APIs to address user requests, including online planning and API execution. TaskMatrix.AI
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib166" title="">
         166
        </a>
        ]
       </cite>
       can comprehend inputs in text, images, videos, audio, and code and subsequently generates code that invokes APIs to accomplish tasks. D-Bot
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib159" title="">
         159
        </a>
        ]
       </cite>
       offers database maintenance suggestions covering knowledge detection, root cause analysis, and multi-LLM collaboration.
      </p>
     </div>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS5.Px1.p2">
      <p class="ltx_p" id="S3.SS1.SSS5.Px1.p2.1">
       Chameleon
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib156" title="">
         156
        </a>
        ]
       </cite>
       employs various tools to address challenges and utilizes a natural language planner to select and combine modules stored in the inventory, thereby constructing solutions. AVIS
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib160" title="">
         160
        </a>
        ]
       </cite>
       is an autonomous visual information-seeking system that leverages LLMs to dynamically formulate strategies for utilizing external tools and examining their output results, thus acquiring essential knowledge to provide answers to the posed questions.
      </p>
     </div>
    </section>
    <section class="ltx_paragraph" id="S3.SS1.SSS5.Px2">
     <h5 class="ltx_title ltx_title_paragraph">
      Tool Planning
     </h5>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS5.Px2.p1">
      <p class="ltx_p" id="S3.SS1.SSS5.Px2.p1.1">
       ChatCoT
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib161" title="">
         161
        </a>
        ]
       </cite>
       models chain-like thinking into multi-turn dialogues, improving complex task handling through tool-aided reasoning. TPTU
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib162" title="">
         162
        </a>
        ]
       </cite>
       introduces a task execution framework comprising task instructions, design prompts, toolkits, LLM, results, and task planning and tool utilization capability. ToolLLM
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib74" title="">
         74
        </a>
        ]
       </cite>
       develops a Decision Tree based on Depth-First Search, enabling LLMs to evaluate multiple API-based reasoning paths and expand the search space. Gentopia
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib163" title="">
         163
        </a>
        ]
       </cite>
       is a framework allowing flexible customization of agents through simple configuration, seamlessly integrating various language models, task formats, prompt modules, and plugins into a unified paradigm.
      </p>
     </div>
    </section>
    <section class="ltx_paragraph" id="S3.SS1.SSS5.Px3">
     <h5 class="ltx_title ltx_title_paragraph">
      Tool Creation
     </h5>
     <div class="ltx_para ltx_noindent" id="S3.SS1.SSS5.Px3.p1">
      <p class="ltx_p" id="S3.SS1.SSS5.Px3.p1.1">
       <cite class="ltx_cite ltx_citemacro_citet">
        Cai et al. [
        <a class="ltx_ref" href="#bib.bib164" title="">
         164
        </a>
        ]
       </cite>
       presents a tool creation and utilization framework, generating tools suitable for diverse tasks. This covers staged tool generation and task execution. CRAFT
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib165" title="">
         165
        </a>
        ]
       </cite>
       is a framework designed for developing and retrieving general-purpose tools, enabling the generation of specialized toolkits tailored for specific tasks. LLM can extract tools from these toolkits to address complex tasks.
      </p>
     </div>
    </section>
   </section>
  </section>
  <section class="ltx_subsection" id="S3.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.2
    </span>
    LLM-based Multi-Agent System
   </h3>
   <section class="ltx_subsubsection" id="S3.SS2.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.2.1
     </span>
     Relationship of Multi-Agent Systems
    </h4>
    <div class="ltx_para ltx_noindent" id="S3.SS2.SSS1.p1">
     <p class="ltx_p" id="S3.SS2.SSS1.p1.1">
      In LLM-based Multi-Agent Systems (MAS), many agents engage in collaboration, competition, or hierarchical organization to execute intricate tasks. These tasks could range from search and optimization, decision support, and resource allocation to collaborative generation or control. The interrelationships between agents in these systems are of paramount importance as they govern the mechanisms of interaction and cooperation among agents. Similarly, these inter-agent relationships can be extrapolated to LLM-based MAS. Currently, most research in LLM-based MAS primarily focuses on the cooperative and competitive dynamics between agents.
     </p>
    </div>
    <figure class="ltx_figure" id="S3.F9">
     <div class="ltx_inline-block ltx_transformed_outer" id="S3.F9.1" style="width:647.4pt;height:91.8pt;vertical-align:-84.9pt;">
      <span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
       <p class="ltx_p" id="S3.F9.1.1">
        <span class="ltx_text" id="S3.F9.1.1.1">
         <span class="ltx_ERROR undefined" id="S3.F9.1.1.1.1">
          {forest}
         </span>
         for tree=
forked edges,
grow’=0,
draw,
rounded corners,
node options=align=center,
text width=3cm,
s sep=5pt,
calign=edge midpoint,
fill=white,
drop shadow,

[Relationship of Multi-Agent, fill=gray!45
[Cooperative
[BOLAA
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib167" title="">
           167
          </a>
          ]
         </cite>
         ]
[AgentVerse
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib84" title="">
           84
          </a>
          ]
         </cite>
         ]
[
         <cite class="ltx_cite ltx_citemacro_citet">
          Zhang et al. [
          <a class="ltx_ref" href="#bib.bib73" title="">
           73
          </a>
          ]
         </cite>
         ]
[CGMI
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib168" title="">
           168
          </a>
          ]
         </cite>
         ]
[Gentopia
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib163" title="">
           163
          </a>
          ]
         </cite>
         ]
]
[Competitive
[
         <cite class="ltx_cite ltx_citemacro_citet">
          Liang et al. [
          <a class="ltx_ref" href="#bib.bib169" title="">
           169
          </a>
          ]
         </cite>
         ]
[ChatEval
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib16" title="">
           16
          </a>
          ]
         </cite>
         ]
]
[Mixed
[
         <cite class="ltx_cite ltx_citemacro_citet">
          Xu et al. [
          <a class="ltx_ref" href="#bib.bib170" title="">
           170
          </a>
          ]
         </cite>
         ]
[
         <cite class="ltx_cite ltx_citemacro_citet">
          Light et al. [
          <a class="ltx_ref" href="#bib.bib171" title="">
           171
          </a>
          ]
         </cite>
         ]
]
[Hierarchical
[AutoGen
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib83" title="">
           83
          </a>
          ]
         </cite>
         ]
]
]
        </span>
       </p>
      </span>
     </div>
     <figcaption class="ltx_caption">
      <span class="ltx_tag ltx_tag_figure">
       Figure 9:
      </span>
      Relationship of Multi-Agent System.
     </figcaption>
    </figure>
    <section class="ltx_paragraph" id="S3.SS2.SSS1.Px1">
     <h5 class="ltx_title ltx_title_paragraph">
      Cooperative Relationship
     </h5>
     <div class="ltx_para ltx_noindent" id="S3.SS2.SSS1.Px1.p1">
      <p class="ltx_p" id="S3.SS2.SSS1.Px1.p1.1">
       In cooperative relationships, scholarly attention is predominantly directed toward role and task allocation strategies and algorithms for collaborative decision-making. Such methodologies can enhance the efficacy of agent collaboration, resulting in improved overall system performance. SPP
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib172" title="">
         172
        </a>
        ]
       </cite>
       facilitates multi-turn dialogue via multi-persona self-cooperation, transforming a singular LLM into a cognitive synergist. Generative Agents
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib63" title="">
         63
        </a>
        ]
       </cite>
       employ LLM-based agents to emulate plausible human behavior, thus fostering cooperation amongst agents. CAMEL
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib173" title="">
         173
        </a>
        ]
       </cite>
       realizes multi-turn dialogue cooperation between AI assistants and AI users through task-oriented role-playing. MetaGPT
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib67" title="">
         67
        </a>
        ]
       </cite>
       integrates effective workflows into LLM-driven multi-agent collaboration programming methodologies, enabling collaboration amongst diverse roles. ChatDev
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib66" title="">
         66
        </a>
        ]
       </cite>
       utilizes multiple LLM-based agents for dialogue task resolution, expediting LLM application development.
      </p>
     </div>
     <div class="ltx_para ltx_noindent" id="S3.SS2.SSS1.Px1.p2">
      <p class="ltx_p" id="S3.SS2.SSS1.Px1.p2.1">
       Drawing inspiration from Minsky’s society of mind
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib23" title="">
         23
        </a>
        ]
       </cite>
       , NLSOM
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib24" title="">
         24
        </a>
        ]
       </cite>
       introduces the notion of natural language-based societies of mind (NLSOMs), comprising multiple LLMs and other neural network-based experts that communicate through a natural language interface. This approach is applied to tackle complex tasks across various scenarios.
       <cite class="ltx_cite ltx_citemacro_citet">
        Zou et al. [
        <a class="ltx_ref" href="#bib.bib174" title="">
         174
        </a>
        ]
       </cite>
       enables collaboration among device-side LLMs. Regarding embodied MAS, RoCo
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib175" title="">
         175
        </a>
        ]
       </cite>
       employs LLMs for high-level communication and low-level path planning, facilitating multi-robot collaboration. InterAct
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib176" title="">
         176
        </a>
        ]
       </cite>
       assigns roles such as inspectors and classifiers, achieving notable success rates in AlfWorld
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib177" title="">
         177
        </a>
        ]
       </cite>
       . AutoAgents
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib85" title="">
         85
        </a>
        ]
       </cite>
       can adaptively generate and coordinate multiple specialized agents, forming an AI team to accomplish goals based on various tasks.
      </p>
     </div>
     <div class="ltx_para ltx_noindent" id="S3.SS2.SSS1.Px1.p3">
      <p class="ltx_p" id="S3.SS2.SSS1.Px1.p3.1">
       In the study of LLM-based MAS frameworks, BOLAA
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib167" title="">
         167
        </a>
        ]
       </cite>
       devises an architecture for orchestrating multi-agent strategies, augmenting the action interaction capabilities of individual agents. AgentVerse
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib84" title="">
         84
        </a>
        ]
       </cite>
       offers a versatile framework that simplifies creating custom multi-agent environments for LLMs.
       <cite class="ltx_cite ltx_citemacro_citet">
        Zhang et al. [
        <a class="ltx_ref" href="#bib.bib73" title="">
         73
        </a>
        ]
       </cite>
       proposes a novel framework that empowers embodied agents to plan, communicate, and collaborate, efficiently completing long-term tasks with other embodied agents or humans. CGMI
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib168" title="">
         168
        </a>
        ]
       </cite>
       is a configurable generic multi-agent interaction framework that harnesses LLM capabilities to address agent performance challenges in specific tasks and simulate human behavior. Gentopia
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib163" title="">
         163
        </a>
        ]
       </cite>
       is a framework that allows for flexible customization of agents through simple configuration, seamlessly integrating various language models, task formats, prompt modules, and plugins into a unified paradigm. DyLAN
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib178" title="">
         178
        </a>
        ]
       </cite>
       introduces a task-based dynamic framework that enables multiple agents to interact and presents an automatic agent team optimization algorithm based on unsupervised metrics. This algorithm selects the most effective agents according to the contributions of each agent.
      </p>
     </div>
    </section>
    <section class="ltx_paragraph" id="S3.SS2.SSS1.Px2">
     <h5 class="ltx_title ltx_title_paragraph">
      Competitive Relationship
     </h5>
     <div class="ltx_para ltx_noindent" id="S3.SS2.SSS1.Px2.p1">
      <p class="ltx_p" id="S3.SS2.SSS1.Px2.p1.1">
       In competitive relationships, considerations encompass designing effective competitive strategies, information concealment techniques, and adversarial behavior. These techniques can assist agents in gaining an advantage in competition, thereby achieving their goals.
       <cite class="ltx_cite ltx_citemacro_citet">
        Liang et al. [
        <a class="ltx_ref" href="#bib.bib169" title="">
         169
        </a>
        ]
       </cite>
       enhances task-solving capabilities through a multi-agent debate framework. ChatEval
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib16" title="">
         16
        </a>
        ]
       </cite>
       employs a multi-agent approach to facilitate a group of LLMs collaborating with various intelligent opponents, leveraging their respective abilities and expertise to improve the efficiency and effectiveness of processing complex tasks.
      </p>
     </div>
    </section>
    <section class="ltx_paragraph" id="S3.SS2.SSS1.Px3">
     <h5 class="ltx_title ltx_title_paragraph">
      Mixed Relationship
     </h5>
     <div class="ltx_para ltx_noindent" id="S3.SS2.SSS1.Px3.p1">
      <p class="ltx_p" id="S3.SS2.SSS1.Px3.p1.1">
       Agents must balance cooperation and competition in mixed relationships to achieve their goals. Currently, research on mixed relationships in LLM-based MAS focuses on the design of collaborative competition algorithms, which is a crucial topic. These techniques can aid agents in making effective decisions in complex environments.
       <cite class="ltx_cite ltx_citemacro_citet">
        Xu et al. [
        <a class="ltx_ref" href="#bib.bib170" title="">
         170
        </a>
        ]
       </cite>
       enables multiple LLM-based agents to participate in the Werewolf game, with each agent cooperating or betraying other agents to fulfill their role’s goals under asymmetric information conditions. Similarly,
       <cite class="ltx_cite ltx_citemacro_citet">
        Light et al. [
        <a class="ltx_ref" href="#bib.bib171" title="">
         171
        </a>
        ]
       </cite>
       enables LLM-based agents to participate in the Avalon game, where each agent must make decisions during dynamically evolving game stages and engage in negotiations involving cooperation or deception with other agents to accomplish the objectives of their assigned roles. Drawing inspiration from human behavior, Corex
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib179" title="">
         179
        </a>
        ]
       </cite>
       incorporates various collaboration paradigms, such as debate, review, and retrieval modes. Collectively, these modes strive to augment the reasoning process’s authenticity, fidelity, and reliability.
      </p>
     </div>
    </section>
    <section class="ltx_paragraph" id="S3.SS2.SSS1.Px4">
     <h5 class="ltx_title ltx_title_paragraph">
      Hierarchical Relationship
     </h5>
     <div class="ltx_para ltx_noindent" id="S3.SS2.SSS1.Px4.p1">
      <p class="ltx_p" id="S3.SS2.SSS1.Px4.p1.1">
       Researchers focus on developing efficient hierarchical control structures, information transmission mechanisms, and task decomposition methods in hierarchical relationships. These techniques enable agents to collaborate effectively across different levels, augmenting the system’s overall performance. Hierarchical relationships typically manifest as a tree structure, wherein parent-node agents undertake the task decomposition process and assign tasks to child-node agents. The latter agents adhere to the arrangements set by their corresponding parent nodes and provide summarized information in return. AutoGen
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib83" title="">
         83
        </a>
        ]
       </cite>
       employs diverse agents to tackle tasks, such as code generation and text writing, utilizing task decomposition through dialogue. Presently, research on hierarchical relationships in LLM-based MAS is still developing, with only a limited number of levels being explored.
      </p>
     </div>
     <div class="ltx_para ltx_noindent" id="S3.SS2.SSS1.Px4.p2">
      <p class="ltx_p" id="S3.SS2.SSS1.Px4.p2.1">
       In forthcoming research endeavors, the utilization of game theory, auction mechanisms, and negotiation techniques holds promise in tackling the challenges associated with task allocation problems among cooperative agents. Furthermore, Distributed Constraint Optimization Problems (DCOP) present a substantial framework for investigating collaborative decision-making within cooperative agents. In the context of other relationship types, cooperative games and Multi-Objective Reinforcement Learning (MORL) emerge as pivotal frameworks for exploring the delicate equilibrium between cooperation and competition. These established research frameworks can also be adapted and refined within LLM-based MAS.
      </p>
     </div>
    </section>
   </section>
   <section class="ltx_subsubsection" id="S3.SS2.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.2.2
     </span>
     Planning Type
    </h4>
    <div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.p1">
     <p class="ltx_p" id="S3.SS2.SSS2.p1.1">
      In the domain of MAS, planning constitutes a crucial component as it enables the orchestration of multiple agents in pursuit of shared goals. Numerous planning methodologies have been put forth, each exhibiting unique merits and constraints. Analogous to the notion of Centralized Training Decentralized Execution (CTDE)
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib180" title="">
        180
       </a>
       ]
      </cite>
      in Multi-Agent Reinforcement Learning, this investigation delves into two primary planning paradigms: Centralized Planning Decentralized Execution (CPDE) and Decentralized Planning Decentralized Execution (DPDE).
     </p>
    </div>
    <figure class="ltx_figure" id="S3.F10">
     <div class="ltx_inline-block ltx_transformed_outer" id="S3.F10.1" style="width:484.1pt;height:55.8pt;vertical-align:-48.9pt;">
      <span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
       <p class="ltx_p" id="S3.F10.1.1">
        <span class="ltx_text" id="S3.F10.1.1.1">
         <span class="ltx_ERROR undefined" id="S3.F10.1.1.1.1">
          {forest}
         </span>
         for tree=
forked edges,
grow’=0,
draw,
rounded corners,
node options=align=center,
text width=3cm,
s sep=5pt,
calign=edge midpoint,
fill=white,
drop shadow,

[Planning Type of MAS, fill=gray!45
[Centralized Planning Decentralized Execution (CPDE)
]
[Decentralized Planning Decentralized Execution (DPDE)
[Communication Types
]
[With Communication
]
[Shared Memory
[Central knowledge base]
[Shared parameters]
]
]
]
]
        </span>
       </p>
      </span>
     </div>
     <figcaption class="ltx_caption">
      <span class="ltx_tag ltx_tag_figure">
       Figure 10:
      </span>
      Typology of the MAS Planning Type.
     </figcaption>
    </figure>
    <section class="ltx_paragraph" id="S3.SS2.SSS2.Px1">
     <h5 class="ltx_title ltx_title_paragraph">
      Centralized Planning Decentralized Execution (CPDE)
     </h5>
     <div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.Px1.p1">
      <p class="ltx_p" id="S3.SS2.SSS2.Px1.p1.1">
       In the CPDE paradigm, a centralized LLM is responsible for planning on behalf of all agents encompassed within the system. This requires the LLM to consider all agents’ objectives, capabilities, and constraints to devise appropriate action plans for them. As highlighted in
       <cite class="ltx_cite ltx_citemacro_citet">
        Gong et al. [
        <a class="ltx_ref" href="#bib.bib181" title="">
         181
        </a>
        ]
       </cite>
       , the planner must concurrently manage multiple agents, circumvent potential conflicts, and coordinate them to accomplish a shared goal necessitating intricate collaborations. Upon finalizing the planning, each agent independently carries out its designated tasks without further interaction with the central LLM. The merit of this approach resides in optimizing overall performance at a global scale, as the central LLM can consider the needs and resources of all agents.
       <cite class="ltx_cite ltx_citemacro_citet">
        Li et al. [
        <a class="ltx_ref" href="#bib.bib72" title="">
         72
        </a>
        ]
       </cite>
       develops SAMA in both overcooked
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib182" title="">
         182
        </a>
        ]
       </cite>
       and MiniRTS
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib183" title="">
         183
        </a>
        ]
       </cite>
       multi-agent environments by employing a centralized LLM to facilitate goal generation, goal decomposition, goal allocation, and replanning with self-reflection.
      </p>
     </div>
     <div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.Px1.p2">
      <p class="ltx_p" id="S3.SS2.SSS2.Px1.p2.1">
       However, CPDE also exhibits certain limitations. Firstly, the centralized planning process may lead to escalated computational complexity, particularly when managing numerous agents and complex tasks. Secondly, given that all agents depend on a single LLM for planning, the system may be susceptible to single-point failures and communication delays. Lastly, CPDE might not be well-suited for situations demanding real-time responsiveness and heightened adaptability, as the central LLM may be incapable of swiftly responding to environmental changes.
      </p>
     </div>
    </section>
    <section class="ltx_paragraph" id="S3.SS2.SSS2.Px2">
     <h5 class="ltx_title ltx_title_paragraph">
      Decentralized Planning Decentralized Execution (DPDE)
     </h5>
     <div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.Px2.p1">
      <p class="ltx_p" id="S3.SS2.SSS2.Px2.p1.1">
       Contrasting with CPDE, DPDE systems incorporate individual LLMs responsible for action planning in each agent. As a result, every agent can independently formulate plans based on its objectives, capabilities, and local information. During the execution phase, agents can enhance collaboration by coordinating their actions through local communication and negotiation.
      </p>
     </div>
     <div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.Px2.p2">
      <p class="ltx_p" id="S3.SS2.SSS2.Px2.p2.1">
       The benefits of DPDE encompass increased robustness and scalability as each agent independently plans and executes, thereby alleviating the computational burden on the central LLM. Furthermore, DPDE systems typically demonstrate greater adaptability, as each agent can promptly modify its behavior according to local information. This attribute renders DPDE systems more appropriate for dynamic and uncertain environments.
      </p>
     </div>
     <div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.Px2.p3">
      <p class="ltx_p" id="S3.SS2.SSS2.Px2.p3.1">
       However, the constraints of DPDE include potential challenges in attaining global optimality, as each agent’s planning is contingent on local information. Moreover, coordination and communication overhead may become considerable in large-scale systems, potentially influencing overall performance.
      </p>
     </div>
     <div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.Px2.p4">
      <p class="ltx_p" id="S3.SS2.SSS2.Px2.p4.1">
       Information exchange between agents is vital for promoting cooperation and collaboration in such systems. The ensuing discussion delineates three categories of information exchange between agents in DPDE systems:
      </p>
     </div>
     <section class="ltx_subparagraph" id="S3.SS2.SSS2.Px2.SPx1">
      <h6 class="ltx_title ltx_title_subparagraph">
       Information Exchange Without Communication
      </h6>
      <div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.Px2.SPx1.p1">
       <p class="ltx_p" id="S3.SS2.SSS2.Px2.SPx1.p1.1">
        In this modality, agents abstain from direct communication. Each agent independently plans and executes, depending solely on local information and observations to accomplish tasks. The merit of this approach lies in minimal communication overhead, as agents are not required to exchange information. Moreover, this method might be the sole viable option in environments characterized by limited or unreliable communication.
       </p>
      </div>
      <div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.Px2.SPx1.p2">
       <p class="ltx_p" id="S3.SS2.SSS2.Px2.SPx1.p2.1">
        Nonetheless, the lack of communication may give rise to suboptimal collaboration among agents, as they cannot share information, coordinate actions, or resolve conflicts. In certain instances, this may culminate in inefficient behavior and a deterioration in overall performance.
       </p>
      </div>
     </section>
     <section class="ltx_subparagraph" id="S3.SS2.SSS2.Px2.SPx2">
      <h6 class="ltx_title ltx_title_subparagraph">
       Information Exchange With Communication
      </h6>
      <div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.Px2.SPx2.p1">
       <p class="ltx_p" id="S3.SS2.SSS2.Px2.SPx2.p1.1">
        In this modality, agents engage in information exchange and action coordination through explicit communication. Communication can assume diverse forms, including message passing, broadcasting, or point-to-point communication. Agents can disseminate observations, goals, plans, and other relevant information by communicating bolstering collaboration and overall performance.
       </p>
      </div>
      <div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.Px2.SPx2.p2">
       <p class="ltx_p" id="S3.SS2.SSS2.Px2.SPx2.p2.1">
        However, communication may incur supplementary overhead, encompassing communication delays, bandwidth utilization, and receiving information processing. Furthermore, in environments characterized by unreliable or limited communication, this approach may confront obstacles, such as lost messages or delayed updates.
       </p>
      </div>
     </section>
     <section class="ltx_subparagraph" id="S3.SS2.SSS2.Px2.SPx3">
      <h6 class="ltx_title ltx_title_subparagraph">
       Information Exchange With Shared Memory
      </h6>
      <div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.Px2.SPx3.p1">
       <p class="ltx_p" id="S3.SS2.SSS2.Px2.SPx3.p1.1">
        In this modality, agents exchange information via shared memory, a centralized data structure accessible and modifiable by all agents within the system. Agents accomplish information sharing and collaboration by storing and retrieving information in shared memory.
       </p>
      </div>
      <div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.Px2.SPx3.p2">
       <p class="ltx_p" id="S3.SS2.SSS2.Px2.SPx3.p2.1">
        Shared memory presents several merits, such as streamlining communication, as agents need not directly transmit and receive messages. Furthermore, it offers a unified information representation and access mechanism, simplifying the system’s design and implementation.
       </p>
      </div>
      <div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.Px2.SPx3.p3">
       <p class="ltx_p" id="S3.SS2.SSS2.Px2.SPx3.p3.1">
        However, shared memory exhibits certain limitations. Firstly, contention and synchronization issues may emerge as all agents necessitate access to and modification of shared memory. Secondly, shared memory could impede the system’s scalability, requiring consistency among all agents. Lastly, implementing shared memory in distributed and mobile agent environments may confront technical challenges, such as ensuring data consistency and managing concurrency control.
       </p>
      </div>
      <div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.Px2.SPx3.p4">
       <p class="ltx_p" id="S3.SS2.SSS2.Px2.SPx3.p4.1">
        In contemporary research, two forms of shared memory can be identified:
       </p>
      </div>
      <div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.Px2.SPx3.p5">
       <ul class="ltx_itemize" id="S3.I5">
        <li class="ltx_item" id="S3.I5.i1" style="list-style-type:none;">
         <span class="ltx_tag ltx_tag_item">
          •
         </span>
         <div class="ltx_para" id="S3.I5.i1.p1">
          <p class="ltx_p" id="S3.I5.i1.p1.1">
           <span class="ltx_text ltx_font_bold" id="S3.I5.i1.p1.1.1">
            Central Knowledge Base
           </span>
           : A central knowledge base can be established to store and manage the shared knowledge of each agent. This knowledge base can be a database, a knowledge graph, or another storage structure. Agents can achieve memory sharing by querying and updating this knowledge base. MetaGPT
           <cite class="ltx_cite ltx_citemacro_cite">
            [
            <a class="ltx_ref" href="#bib.bib67" title="">
             67
            </a>
            ]
           </cite>
           offers a global memory pool to store all collaborative records, enabling each agent to subscribe to or search for the required information. This design allows agents to observe and extract pertinent information actively.
          </p>
         </div>
        </li>
        <li class="ltx_item" id="S3.I5.i2" style="list-style-type:none;">
         <span class="ltx_tag ltx_tag_item">
          •
         </span>
         <div class="ltx_para ltx_noindent" id="S3.I5.i2.p1">
          <p class="ltx_p" id="S3.I5.i2.p1.1">
           <span class="ltx_text ltx_font_bold" id="S3.I5.i2.p1.1.1">
            Shared Parameters
           </span>
           : In certain instances, allowing partial or complete sharing of model parameters among agents in an LLM-based MAS system may be considered. In this manner, when one agent acquires new knowledge or skills, other agents can also immediately obtain this information. However, this method may give rise to overfitting or overspecialization problems. To address this issue, the weights of shared parameters can be dynamically adjusted to balance each agent’s specialization and generalization capabilities.
          </p>
         </div>
        </li>
       </ul>
      </div>
     </section>
    </section>
   </section>
   <section class="ltx_subsubsection" id="S3.SS2.SSS3">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      3.2.3
     </span>
     Methods of Enhancing Communication Efficiency
    </h4>
    <div class="ltx_para ltx_noindent" id="S3.SS2.SSS3.p1">
     <p class="ltx_p" id="S3.SS2.SSS3.p1.1">
      In an LLM-based MAS, the challenges of ineffective communication and LLM illusions are indeed possible. To mitigate these issues, the following strategies can be employed:
     </p>
    </div>
    <figure class="ltx_figure" id="S3.F11">
     <div class="ltx_inline-block ltx_transformed_outer" id="S3.F11.1" style="width:484.1pt;height:55.8pt;vertical-align:-48.9pt;">
      <span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
       <p class="ltx_p" id="S3.F11.1.1">
        <span class="ltx_text" id="S3.F11.1.1.1">
         <span class="ltx_ERROR undefined" id="S3.F11.1.1.1.1">
          {forest}
         </span>
         for tree=
forked edges,
grow’=0,
draw,
rounded corners,
node options=align=center,
text width=3cm,
s sep=5pt,
calign=edge midpoint,
fill=white,
drop shadow,

[Methods of Enhancing Communication Efficiency, fill=gray!45
[Design Effective Communication Protocols
[Message Semantics]
[Message Syntax]
[Agent Communication/Interaction protocol]
[Transport protocol]
]
[Mediator Model]
[Suppressing Invalid LLM Outputs]
]
        </span>
       </p>
      </span>
     </div>
     <figcaption class="ltx_caption">
      <span class="ltx_tag ltx_tag_figure">
       Figure 11:
      </span>
      Typology of the Enhancing Communication Efficiency Methods.
     </figcaption>
    </figure>
    <section class="ltx_paragraph" id="S3.SS2.SSS3.Px1">
     <h5 class="ltx_title ltx_title_paragraph">
      Design Effective Communication Protocols
     </h5>
     <div class="ltx_para ltx_noindent" id="S3.SS2.SSS3.Px1.p1">
      <p class="ltx_p" id="S3.SS2.SSS3.Px1.p1.1">
       In the realm of MAS, it is imperative to scrutinize the discourse on communication through a tripartite lens that encompasses the when,’ what,’ and ‘how’ dimensions. These dimensions collectively dictate the timing, content, and modality of interactions among agents, thereby serving as pivotal factors in the system’s efficacy for intricate problem-solving and coordinated endeavors.
      </p>
     </div>
     <div class="ltx_para ltx_noindent" id="S3.SS2.SSS3.Px1.p2">
      <p class="ltx_p" id="S3.SS2.SSS3.Px1.p2.1">
       Four levels of agent communication can be identified:
      </p>
      <ul class="ltx_itemize" id="S3.I6">
       <li class="ltx_item" id="S3.I6.i1" style="list-style-type:none;">
        <span class="ltx_tag ltx_tag_item">
         •
        </span>
        <div class="ltx_para" id="S3.I6.i1.p1">
         <p class="ltx_p" id="S3.I6.i1.p1.1">
          <span class="ltx_text ltx_font_bold" id="S3.I6.i1.p1.1.1">
           Message Semantics
          </span>
          : The meaning of each message.
         </p>
        </div>
       </li>
       <li class="ltx_item" id="S3.I6.i2" style="list-style-type:none;">
        <span class="ltx_tag ltx_tag_item">
         •
        </span>
        <div class="ltx_para" id="S3.I6.i2.p1">
         <p class="ltx_p" id="S3.I6.i2.p1.1">
          <span class="ltx_text ltx_font_bold" id="S3.I6.i2.p1.1.1">
           Message Syntax:
          </span>
          The expression of each message.
         </p>
        </div>
       </li>
       <li class="ltx_item" id="S3.I6.i3" style="list-style-type:none;">
        <span class="ltx_tag ltx_tag_item">
         •
        </span>
        <div class="ltx_para" id="S3.I6.i3.p1">
         <p class="ltx_p" id="S3.I6.i3.p1.1">
          <span class="ltx_text ltx_font_bold" id="S3.I6.i3.p1.1.1">
           Agent Communication/Interaction Protocol
          </span>
          : The structure of conversations/dialogues.
         </p>
        </div>
       </li>
       <li class="ltx_item" id="S3.I6.i4" style="list-style-type:none;">
        <span class="ltx_tag ltx_tag_item">
         •
        </span>
        <div class="ltx_para ltx_noindent" id="S3.I6.i4.p1">
         <p class="ltx_p" id="S3.I6.i4.p1.1">
          <span class="ltx_text ltx_font_bold" id="S3.I6.i4.p1.1.1">
           Transport Protocol
          </span>
          : The method of sending and receiving messages by agents.
         </p>
        </div>
       </li>
      </ul>
      <p class="ltx_p" id="S3.SS2.SSS3.Px1.p2.2">
       Historically, intelligent agents, particularly those based on RL, have communicated implicitly through learning. In contrast, LLM-based agents can communicate through NLP, offering humans a more transparent and explicit mode of interaction. Consequently, concerning LLM-based MAS, concerns regarding message semantics and transport protocols are obviated.
      </p>
     </div>
     <div class="ltx_para ltx_noindent" id="S3.SS2.SSS3.Px1.p3">
      <p class="ltx_p" id="S3.SS2.SSS3.Px1.p3.1">
       The question of message syntax directs attention to the Agent Communication Language (ACL), which is grounded in the
       <em class="ltx_emph ltx_font_italic" id="S3.SS2.SSS3.Px1.p3.1.1">
        Speech Acts Theory
       </em>
       put forth by
       <cite class="ltx_cite ltx_citemacro_citet">
        Searle [
        <a class="ltx_ref" href="#bib.bib184" title="">
         184
        </a>
        ]
       </cite>
       . Two prominent standards have emerged: the Knowledge Query and Manipulation Language (KQML)
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib185" title="">
         185
        </a>
        ]
       </cite>
       and the ACL proposed by the Foundation for Intelligent Physical Agents (FIPA)
       <span class="ltx_note ltx_role_footnote" id="footnote1">
        <sup class="ltx_note_mark">
         1
        </sup>
        <span class="ltx_note_outer">
         <span class="ltx_note_content">
          <sup class="ltx_note_mark">
           1
          </sup>
          <span class="ltx_tag ltx_tag_note">
           1
          </span>
          http://www.fipa.org/
         </span>
        </span>
       </span>
       .
      </p>
     </div>
     <div class="ltx_para ltx_noindent" id="S3.SS2.SSS3.Px1.p4">
      <p class="ltx_p" id="S3.SS2.SSS3.Px1.p4.1">
       In 1996, FIPA developed standards for heterogeneous and interacting agents and agent-based systems. FIPA’s ACL comprises 22 performatives, or communication acts, such as Inform and Request. These performatives are not isolated entities but function as integral components of a structured conversational protocol among agents. Such protocols are regulated by predefined rules that outline the sequence and timing of performative usage to achieve specific collective objectives. For instance, FIPA-ACL can construct the FIPA-Auction-English Protocol and FIPA-Auction-Dutch Protocol.
      </p>
     </div>
     <div class="ltx_para ltx_noindent" id="S3.SS2.SSS3.Px1.p5">
      <p class="ltx_p" id="S3.SS2.SSS3.Px1.p5.1">
       Implementing well-defined communication protocols ensures that agent interactions adhere to a coherent structure and semantics, mitigating ambiguity and miscommunication and augmenting communication efficiency. Adopting embeddings
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib186" title="">
         186
        </a>
        ]
       </cite>
       or structured output formats, such as JSON, can further enhance these advantages.
      </p>
     </div>
    </section>
    <section class="ltx_paragraph" id="S3.SS2.SSS3.Px2">
     <h5 class="ltx_title ltx_title_paragraph">
      Employing Mediator Models
     </h5>
     <div class="ltx_para ltx_noindent" id="S3.SS2.SSS3.Px2.p1">
      <p class="ltx_p" id="S3.SS2.SSS3.Px2.p1.1">
       In LLM-based MAS, extensive interactions among LLMs can result in increased expenses and prolonged engagement durations. The mediator model serves as a discerning mechanism that aids in determining the necessity of interactions between LLMs, thereby reducing redundant communication overhead and enhancing the system’s overall efficacy. The mediator model’s decision to engage in interactions is influenced by task intricacy, the extent of inter-agent associations, and communication expenditures. Existing research has already witnessed the implementation of mediator models, with studies by
       <cite class="ltx_cite ltx_citemacro_citet">
        Hu et al. [
        <a class="ltx_ref" href="#bib.bib52" title="">
         52
        </a>
        ], Karimpanal et al. [
        <a class="ltx_ref" href="#bib.bib121" title="">
         121
        </a>
        ]
       </cite>
       delving into optimizing cost-effective, intelligent interactions between agents and LLMs.
      </p>
     </div>
    </section>
    <section class="ltx_paragraph" id="S3.SS2.SSS3.Px3">
     <h5 class="ltx_title ltx_title_paragraph">
      Mitigating Inaccurate Outputs in LLMs
     </h5>
     <div class="ltx_para ltx_noindent" id="S3.SS2.SSS3.Px3.p1">
      <p class="ltx_p" id="S3.SS2.SSS3.Px3.p1.1">
       LLMs frequently tend to generate outputs characterized by excessive praise or unfounded information. The study by
       <cite class="ltx_cite ltx_citemacro_citet">
        Wei et al. [
        <a class="ltx_ref" href="#bib.bib187" title="">
         187
        </a>
        ]
       </cite>
       introduces a straightforward approach that employs synthetic data in an auxiliary fine-tuning phase to curtail the occurrence of flattering outputs. A comprehensive analysis of hallucinations in LLMs and the techniques employed to counteract them is presented by
       <cite class="ltx_cite ltx_citemacro_citet">
        Rawte et al. [
        <a class="ltx_ref" href="#bib.bib188" title="">
         188
        </a>
        ]
       </cite>
       . Chain of Verification (CoVe)
       <cite class="ltx_cite ltx_citemacro_cite">
        [
        <a class="ltx_ref" href="#bib.bib189" title="">
         189
        </a>
        ]
       </cite>
       seeks to minimize hallucinations by prompting the model to initially produce a preliminary response, subsequently formulate verification inquiries for fact-checking the draft, independently address these queries, and ultimately generate a validated and refined response.
      </p>
     </div>
     <div class="ltx_para ltx_noindent" id="S3.SS2.SSS3.Px3.p2">
      <p class="ltx_p" id="S3.SS2.SSS3.Px3.p2.1">
       By implementing these strategies, it is possible to effectively address issues of ineffective communication and LLM hallucinations in LLM-based MAS. This will ultimately enhance system performance and stability.
      </p>
     </div>
    </section>
   </section>
  </section>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    4
   </span>
   Performance Evaluation
  </h2>
  <section class="ltx_subsection" id="S4.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.1
    </span>
    Dataset
   </h3>
   <div class="ltx_para ltx_noindent" id="S4.SS1.p1">
    <p class="ltx_p" id="S4.SS1.p1.1">
     Most LLM-based agents do not necessitate further training of the LLM, and datasets for certain specific tasks are not publicly accessible. Consequently, we only enumerate publicly available and extensively utilized datasets.
    </p>
   </div>
   <figure class="ltx_table" id="S4.T3">
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 3:
     </span>
     Datasets Used in the Study
    </figcaption>
    <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T3.1" style="width:433.6pt;height:141.5pt;vertical-align:-0.5pt;">
     <span class="ltx_transformed_inner" style="transform:translate(-248.7pt,80.9pt) scale(0.465735490249532,0.465735490249532) ;">
      <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T3.1.1">
       <thead class="ltx_thead">
        <tr class="ltx_tr" id="S4.T3.1.1.1.1">
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T3.1.1.1.1.1" style="padding:1pt 0.0pt;">
          <span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.1.1">
           Name
          </span>
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T3.1.1.1.1.2" style="padding:1pt 0.0pt;">
          <span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.2.1">
           Field
          </span>
         </th>
         <th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" id="S4.T3.1.1.1.1.3" style="padding:1pt 0.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.1.1.1.3.1">
           <span class="ltx_p" id="S4.T3.1.1.1.1.3.1.1" style="width:526.4pt;">
            <span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.3.1.1.1">
             Description
            </span>
           </span>
          </span>
         </th>
        </tr>
       </thead>
       <tbody class="ltx_tbody">
        <tr class="ltx_tr" id="S4.T3.1.1.2.1">
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" id="S4.T3.1.1.2.1.1" style="padding:1pt 0.0pt;">
          HotpotQA
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib190" title="">
            190
           </a>
           ]
          </cite>
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" id="S4.T3.1.1.2.1.2" style="padding:1pt 0.0pt;">
          Natural Language Processing
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_t" id="S4.T3.1.1.2.1.3" style="padding:1pt 0.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.1.2.1.3.1">
           <span class="ltx_p" id="S4.T3.1.1.2.1.3.1.1" style="width:526.4pt;">
            114,000 training samples, 7,000 development set samples, and 3,000 test set samples
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T3.1.1.3.2">
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S4.T3.1.1.3.2.1" style="padding:1pt 0.0pt;">
          ALFWorld
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib177" title="">
            177
           </a>
           ]
          </cite>
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S4.T3.1.1.3.2.2" style="padding:1pt 0.0pt;">
          Symbolic Reasoning and Visual Perception
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top" id="S4.T3.1.1.3.2.3" style="padding:1pt 0.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.1.3.2.3.1">
           <span class="ltx_p" id="S4.T3.1.1.3.2.3.1.1" style="width:526.4pt;">
            Variable, often including hundreds of environments
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T3.1.1.4.3">
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S4.T3.1.1.4.3.1" style="padding:1pt 0.0pt;">
          CAMEL
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib173" title="">
            173
           </a>
           ]
          </cite>
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S4.T3.1.1.4.3.2" style="padding:1pt 0.0pt;">
          Society and Code
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top" id="S4.T3.1.1.4.3.3" style="padding:1pt 0.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.1.4.3.3.1">
           <span class="ltx_p" id="S4.T3.1.1.4.3.3.1.1" style="width:526.4pt;">
            50 assistant roles, 50 user roles, and 10 tasks for each combination of roles yielding 25,000 conversations for the society dataset. 20 programming languages, 50 domains, and 50 tasks for each combination of language and domains, yielding 50,000 conversations for the code dataset.
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T3.1.1.5.4">
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S4.T3.1.1.5.4.1" style="padding:1pt 0.0pt;">
          APPS
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib191" title="">
            191
           </a>
           ]
          </cite>
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S4.T3.1.1.5.4.2" style="padding:1pt 0.0pt;">
          Language Model Programming
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top" id="S4.T3.1.1.5.4.3" style="padding:1pt 0.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.1.5.4.3.1">
           <span class="ltx_p" id="S4.T3.1.1.5.4.3.1.1" style="width:526.4pt;">
            A total of 10,000 programming questions
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T3.1.1.6.5">
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S4.T3.1.1.6.5.1" style="padding:1pt 0.0pt;">
          MBPP
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib192" title="">
            192
           </a>
           ]
          </cite>
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S4.T3.1.1.6.5.2" style="padding:1pt 0.0pt;">
          Language Model Programming
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top" id="S4.T3.1.1.6.5.3" style="padding:1pt 0.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.1.6.5.3.1">
           <span class="ltx_p" id="S4.T3.1.1.6.5.3.1.1" style="width:526.4pt;">
            974 programming tasks
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T3.1.1.7.6">
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S4.T3.1.1.7.6.1" style="padding:1pt 0.0pt;">
          HumanEval
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib193" title="">
            193
           </a>
           ]
          </cite>
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S4.T3.1.1.7.6.2" style="padding:1pt 0.0pt;">
          Language Model Programming
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top" id="S4.T3.1.1.7.6.3" style="padding:1pt 0.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.1.7.6.3.1">
           <span class="ltx_p" id="S4.T3.1.1.7.6.3.1.1" style="width:526.4pt;">
            Comprises 164 original programming problems that assess language comprehension, algorithms, and basic mathematics, with some problems being comparable to elementary software interview questions.
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T3.1.1.8.7">
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S4.T3.1.1.8.7.1" style="padding:1pt 0.0pt;">
          WebShop
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib194" title="">
            194
           </a>
           ]
          </cite>
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S4.T3.1.1.8.7.2" style="padding:1pt 0.0pt;">
          Simulation of an e-commerce site
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top" id="S4.T3.1.1.8.7.3" style="padding:1pt 0.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.1.8.7.3.1">
           <span class="ltx_p" id="S4.T3.1.1.8.7.3.1.1" style="width:526.4pt;">
            It contains millions of real-world products and 12,087 crowdsourced text descriptions.
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T3.1.1.9.8">
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S4.T3.1.1.9.8.1" style="padding:1pt 0.0pt;">
          FEVER
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib195" title="">
            195
           </a>
           ]
          </cite>
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S4.T3.1.1.9.8.2" style="padding:1pt 0.0pt;">
          Natural Language Processing
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top" id="S4.T3.1.1.9.8.3" style="padding:1pt 0.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.1.9.8.3.1">
           <span class="ltx_p" id="S4.T3.1.1.9.8.3.1.1" style="width:526.4pt;">
            Approximately 185,000 verifiable statements created by human annotators, and the evidence or rebuttals associated with those statements
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T3.1.1.10.9">
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S4.T3.1.1.10.9.1" style="padding:1pt 0.0pt;">
          ToolBench
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib196" title="">
            196
           </a>
           ]
          </cite>
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S4.T3.1.1.10.9.2" style="padding:1pt 0.0pt;">
          API use
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top" id="S4.T3.1.1.10.9.3" style="padding:1pt 0.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.1.10.9.3.1">
           <span class="ltx_p" id="S4.T3.1.1.10.9.3.1.1" style="width:526.4pt;">
            16,464 real-world RESTful APIs spanning 49 categories from RapidAPI Hub, and human instructions involving these APIs prompted by ChatGPT
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T3.1.1.11.10">
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S4.T3.1.1.11.10.1" style="padding:1pt 0.0pt;">
          MITCOURSE ES
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib41" title="">
            41
           </a>
           ]
          </cite>
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S4.T3.1.1.11.10.2" style="padding:1pt 0.0pt;">
          Math
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top" id="S4.T3.1.1.11.10.3" style="padding:1pt 0.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.1.11.10.3.1">
           <span class="ltx_p" id="S4.T3.1.1.11.10.3.1.1" style="width:526.4pt;">
            25 questions from each of the seven courses: MIT’s 18.01 Single Variable Calculus, 18.02 Multivariable Calculus, 18.03 Differential Equations, 18.05 Introduction to Probability and Statistics, 18.06 Linear Algebra, 6.042 Mathematics for Computer Science, and Columbia University’s COMS3251 Computational Linear Algebra
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T3.1.1.12.11">
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S4.T3.1.1.12.11.1" style="padding:1pt 0.0pt;">
          RoboNet
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib197" title="">
            197
           </a>
           ]
          </cite>
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="S4.T3.1.1.12.11.2" style="padding:1pt 0.0pt;">
          Robotic
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top" id="S4.T3.1.1.12.11.3" style="padding:1pt 0.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.1.12.11.3.1">
           <span class="ltx_p" id="S4.T3.1.1.12.11.3.1.1" style="width:526.4pt;">
            An open database for sharing robotics experiences containing 15 million video frames from seven different robotics platforms
           </span>
          </span>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T3.1.1.13.12">
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_b" id="S4.T3.1.1.13.12.1" style="padding:1pt 0.0pt;">
          BridgeData V2
          <cite class="ltx_cite ltx_citemacro_cite">
           [
           <a class="ltx_ref" href="#bib.bib198" title="">
            198
           </a>
           ]
          </cite>
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_b" id="S4.T3.1.1.13.12.2" style="padding:1pt 0.0pt;">
          Robotic
         </td>
         <td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_b" id="S4.T3.1.1.13.12.3" style="padding:1pt 0.0pt;">
          <span class="ltx_inline-block ltx_align_top" id="S4.T3.1.1.13.12.3.1">
           <span class="ltx_p" id="S4.T3.1.1.13.12.3.1.1" style="width:526.4pt;">
            Robot manipulation behavior dataset containing 60,096 trajectories collected in 24 environments
           </span>
          </span>
         </td>
        </tr>
       </tbody>
      </table>
     </span>
    </div>
   </figure>
  </section>
  <section class="ltx_subsection" id="S4.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.2
    </span>
    Benchmark
   </h3>
   <div class="ltx_para ltx_noindent" id="S4.SS2.p1">
    <p class="ltx_p" id="S4.SS2.p1.1">
     Currently, there is no widely used benchmark for LLM-based agents, although some studies engage in comparative analysis of their LLM-based agents with others. Additionally, researchers are making strides toward proposing benchmarks that could serve as future evaluation standards.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S4.SS2.p2">
    <p class="ltx_p" id="S4.SS2.p2.1">
     ToolBench
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib74" title="">
       74
      </a>
      ]
     </cite>
     is an instruction-tuning dataset for tool utilization, encompassing single-tool and multi-tool scenarios. TE
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib199" title="">
       199
      </a>
      ]
     </cite>
     assesses the capability of language models to emulate various facets of human behavior.
     <cite class="ltx_cite ltx_citemacro_citet">
      Akata et al. [
      <a class="ltx_ref" href="#bib.bib200" title="">
       200
      </a>
      ]
     </cite>
     seeks to comprehend the social behavior of LLMs. It lays the groundwork for a behavioral game theory for machines, highlighting the substantial societal value in understanding how LLMs operate in interactive social contexts.
     <cite class="ltx_cite ltx_citemacro_citet">
      Ziems et al. [
      <a class="ltx_ref" href="#bib.bib201" title="">
       201
      </a>
      ]
     </cite>
     contributes a compilation of best practices for prompting and a comprehensive evaluation pipeline to gauge the zero-shot performance of 13 language models across 24 representative CSS benchmarks.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="S4.SS2.p3">
    <p class="ltx_p" id="S4.SS2.p3.1">
     AgentSims
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib143" title="">
       143
      </a>
      ]
     </cite>
     offers an open-source platform for LLM evaluation.
     <cite class="ltx_cite ltx_citemacro_citet">
      Drori et al. [
      <a class="ltx_ref" href="#bib.bib41" title="">
       41
      </a>
      ]
     </cite>
     involves curating a dataset of questions from the largest mathematics courses at the Massachusetts Institute of Technology (MIT) and Columbia University’s Computational Linear Algebra to evaluate mathematical reasoning. BMTools
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib196" title="">
       196
      </a>
      ]
     </cite>
     establishes the framework and evaluation criteria for tool utilization. SmartPlay
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib202" title="">
       202
      </a>
      ]
     </cite>
     presents a challenging benchmark for LLM-based agents, comprising six distinct games with unique settings, offering up to 20 evaluation configurations and infinite environment variations. MLAgentBench
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib203" title="">
       203
      </a>
      ]
     </cite>
     is a collection of ML tasks designed for benchmarking AI research agents, facilitating operations such as reading and writing files, executing code, and examining outputs. MetaTool
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib204" title="">
       204
      </a>
      ]
     </cite>
     is utilized to evaluate whether LLMs consciously use tools and can select the appropriate ones. LLM-Co
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib205" title="">
       205
      </a>
      ]
     </cite>
     evaluates the ability of agents to infer cooperative partner intentions, engage in reasoning actions, and participate in long-term collaboration within a gaming environment.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S5">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    5
   </span>
   Prospect Applications
  </h2>
  <figure class="ltx_figure" id="S5.F12">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="299" id="S5.F12.g1" src="/html/2401.03428/assets/imgs/prospect.png" width="299"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 12:
    </span>
    The Prospect of LLM-based agents
   </figcaption>
  </figure>
  <section class="ltx_subsection" id="S5.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.1
    </span>
    Natural Sciences
   </h3>
   <section class="ltx_subsubsection" id="S5.SS1.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.1.1
     </span>
     Mathematics
    </h4>
    <div class="ltx_para ltx_noindent" id="S5.SS1.SSS1.p1">
     <p class="ltx_p" id="S5.SS1.SSS1.p1.1">
      Many recent investigations have concentrated on agents and multi-agent systems within mathematics. For example,
      <cite class="ltx_cite ltx_citemacro_citet">
       Kennedy and Eberhart [
       <a class="ltx_ref" href="#bib.bib206" title="">
        206
       </a>
       ]
      </cite>
      proposes the particle swarm optimization algorithm, a global optimization technique grounded in a multi-agent framework, which has been extensively utilized to address optimization challenges in mathematics, engineering, and computing.
      <cite class="ltx_cite ltx_citemacro_citet">
       Macal and North [
       <a class="ltx_ref" href="#bib.bib207" title="">
        207
       </a>
       ]
      </cite>
      discusses agent-based modeling and simulation approaches and their implementation in intricate mathematical models.
      <cite class="ltx_cite ltx_citemacro_citet">
       Crainic and Rousseau [
       <a class="ltx_ref" href="#bib.bib208" title="">
        208
       </a>
       ]
      </cite>
      explores the application of agent-based methodologies in combinatorial optimization problems, specifically concerning the design of multi-commodity, multimodal transportation networks.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS1.SSS1.p2">
     <p class="ltx_p" id="S5.SS1.SSS1.p2.1">
      Currently, LLM-based agent research in mathematics predominantly emphasizes the enhancement of reasoning capabilities and support in theoretical derivation. For instance, Math Agents
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib40" title="">
        40
       </a>
       ]
      </cite>
      employ LLMs to investigate, uncover, resolve, and demonstrate mathematical problems.
      <cite class="ltx_cite ltx_citemacro_citet">
       Zhou et al. [
       <a class="ltx_ref" href="#bib.bib129" title="">
        129
       </a>
       ]
      </cite>
      introduces an innovative and productive prompt technique, termed code-based self-verification, to further augment the mathematical reasoning potential of GPT-4’s code interpreter. LeanDojo
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib209" title="">
        209
       </a>
       ]
      </cite>
      is an instrument that can consistently interact with Lean, rectifying proof-checking errors in extant theorem-proving tools.
      <cite class="ltx_cite ltx_citemacro_citet">
       Dong et al. [
       <a class="ltx_ref" href="#bib.bib210" title="">
        210
       </a>
       ]
      </cite>
      conclusively determines that "P
      <math alttext="\neq" class="ltx_Math" display="inline" id="S5.SS1.SSS1.p2.1.m1.1">
       <semantics id="S5.SS1.SSS1.p2.1.m1.1a">
        <mo id="S5.SS1.SSS1.p2.1.m1.1.1" xref="S5.SS1.SSS1.p2.1.m1.1.1.cmml">
         ≠
        </mo>
        <annotation-xml encoding="MathML-Content" id="S5.SS1.SSS1.p2.1.m1.1b">
         <neq id="S5.SS1.SSS1.p2.1.m1.1.1.cmml" xref="S5.SS1.SSS1.p2.1.m1.1.1">
         </neq>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="S5.SS1.SSS1.p2.1.m1.1c">
         \neq
        </annotation>
       </semantics>
      </math>
      NP" through 97 iterations of rigorous "Socratic" reasoning with GPT-4.
      <cite class="ltx_cite ltx_citemacro_citet">
       Yang et al. [
       <a class="ltx_ref" href="#bib.bib211" title="">
        211
       </a>
       ]
      </cite>
      devised a system capable of autonomously generating valid, original, and valuable hypotheses using only a collection of raw web texts. ToRA
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib212" title="">
        212
       </a>
       ]
      </cite>
      presents a series of tool-integrated reasoning agents that utilize natural language reasoning and invoke external tools to address intricate mathematical problems. COPRA
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib213" title="">
        213
       </a>
       ]
      </cite>
      is employed for formal theorem proving, incorporating GPT-4 as a crucial element of its state-backtracking search strategy. This approach can select proof tactics throughout the search process and retrieve axioms and definitions from an external database.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS1.SSS1.p3">
     <p class="ltx_p" id="S5.SS1.SSS1.p3.1">
      LLM-based agents demonstrate substantial promise in upcoming mathematical research endeavors, encompassing:
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS1.SSS1.p4">
     <ul class="ltx_itemize" id="S5.I1">
      <li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I1.i1.p1">
        <p class="ltx_p" id="S5.I1.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I1.i1.p1.1.1">
          Aiding in Theoretical Derivation
         </span>
         : LLM-based agents understand prevailing theories in foundational domains, such as mathematics and physics, and facilitate human efforts in further derivation and validation, ultimately advancing scientific inquiry.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para ltx_noindent" id="S5.I1.i2.p1">
        <p class="ltx_p" id="S5.I1.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I1.i2.p1.1.1">
          Symbolic and Numerical Computation
         </span>
         : LLM-based agents can be employed for symbolic and numerical computation, supporting researchers in addressing various mathematical challenges. Agents can perform numerous mathematical procedures, including solving equations, integration, differentiation, and beyond. Multi-agent systems can bolster computation expediency and precision through the collaborative partitioning of intricate mathematical problems into multiple sub-problems.
        </p>
       </div>
      </li>
     </ul>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS1.SSS1.p5">
     <p class="ltx_p" id="S5.SS1.SSS1.p5.1">
      Notwithstanding the accomplishments of LLM-based agents in mathematical theory derivation and computation, it remains imperative to continually refine the mathematical reasoning capabilities of LLMs and agents and devise more efficacious mathematical knowledge representations to enhance their accuracy and efficiency in tackling complex mathematical problems. Moreover, the interpretability and dependability of LLM-based agents in resolving mathematical issues are crucial. It is vital to explore supplementary approaches to augment the interpretability of agents, empowering them to deliver more lucid and reliable solutions for users. Concurrently, supervision and validation of agent reasoning outcomes can assure their dependability in practical applications.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S5.SS1.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.1.2
     </span>
     Chemistry and Materials
    </h4>
    <div class="ltx_para ltx_noindent" id="S5.SS1.SSS2.p1">
     <p class="ltx_p" id="S5.SS1.SSS2.p1.1">
      In previous research,
      <cite class="ltx_cite ltx_citemacro_citet">
       Gómez-Bombarelli et al. [
       <a class="ltx_ref" href="#bib.bib214" title="">
        214
       </a>
       ]
      </cite>
      presents 1.6 million organic light-emitting diode material candidates, effectively filtered from extensive molecular libraries via high-fidelity simulations. The MolDQN framework
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib215" title="">
        215
       </a>
       ]
      </cite>
      amalgamates chemical domain expertise with reinforcement learning methodologies to explicitly delineate molecular modifications, ensuring 100% chemical validity.
      <cite class="ltx_cite ltx_citemacro_citet">
       You et al. [
       <a class="ltx_ref" href="#bib.bib216" title="">
        216
       </a>
       ]
      </cite>
      puts forth a Graph Convolutional Policy Network (GCPN), a model premised on a general graph convolutional network, utilized for generating goal-oriented graphs through reinforcement learning, intending to uncover novel molecules exhibiting desired attributes such as drug similarity and synthetic accessibility.
      <cite class="ltx_cite ltx_citemacro_citet">
       Beaini et al. [
       <a class="ltx_ref" href="#bib.bib217" title="">
        217
       </a>
       ]
      </cite>
      introduces the Graphium graph machine learning library, streamlining the process of constructing and training molecular machine learning models for multi-task and multi-level molecular datasets.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS1.SSS2.p2">
     <p class="ltx_p" id="S5.SS1.SSS2.p2.1">
      In the realm of current research on LLM-based agents in chemistry and materials science, Coscientist
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib218" title="">
        218
       </a>
       ]
      </cite>
      , leveraging the functionalities of LLM along with tools such as internet and document search, code execution, and experiment automation, is capable of autonomously designing, planning, and executing real-world chemical experiments. ChatMOF
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib39" title="">
        39
       </a>
       ]
      </cite>
      endeavors to predict and generate Metal-Organic Frameworks (MOFs) and encompasses three core components: agents, toolkits, and evaluators. These constituents are proficient in managing data retrieval, property prediction, and structure generation. ChemCrow
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib38" title="">
        38
       </a>
       ]
      </cite>
      executes various chemical tasks in domains such as biosynthesis, drug discovery, and materials design by accessing chemistry-related databases, thus expediting more efficient research. LLM-based agents also demonstrate considerable potential in the following aspects:
     </p>
     <ul class="ltx_itemize" id="S5.I2">
      <li class="ltx_item" id="S5.I2.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I2.i1.p1">
        <p class="ltx_p" id="S5.I2.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I2.i1.p1.1.1">
          Molecular Simulation and Chemical Reaction Optimization
         </span>
         : LLM-based agents can advance chemistry and materials science research by simulating molecular structures and chemical reactions. By examining various reaction pathways and conditions, these agents may pinpoint effective strategies for synthesizing novel materials or enhancing existing material properties.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I2.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I2.i2.p1">
        <p class="ltx_p" id="S5.I2.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I2.i2.p1.1.1">
          Chemical Experiment Automation and Intelligence
         </span>
         : LLM-based agents can facilitate the automation of chemical experiments by retrieving information, querying specialized databases, and devising and implementing experimental plans tailored to particular requirements. This leads to the acquisition of data on chemical reactions and material properties. Moreover, multi-agent systems can augment the efficiency and precision of experiments via collaborative cooperation and the sharing of experimental data and experiences.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I2.i3" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para ltx_noindent" id="S5.I2.i3.p1">
        <p class="ltx_p" id="S5.I2.i3.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I2.i3.p1.1.1">
          Material Design and Optimization
         </span>
         : In materials science research, LLM-based agents can aid in the simulation and optimization of material properties. By autonomously exploring diverse material combinations and structures and employing the robust generalization capabilities of LLMs to simulate and predict the properties of new materials, agents can uncover innovative materials with exceptional performance. This accelerates the material design process and enhances overall efficiency.
        </p>
       </div>
      </li>
     </ul>
     <p class="ltx_p" id="S5.SS1.SSS2.p2.2">
      Although existing LLM-based agents have achieved some success in chemistry and materials science research, further improvement of the accuracy and reliability of models remains a significant challenge. Future research should focus on enhancing LLM’s ability to handle complex chemistry and materials problems to improve the accuracy of predicting and generating chemical reactions, material properties, and other aspects.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S5.SS1.SSS3">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.1.3
     </span>
     Biology
    </h4>
    <div class="ltx_para ltx_noindent" id="S5.SS1.SSS3.p1">
     <p class="ltx_p" id="S5.SS1.SSS3.p1.1">
      In recent years, numerous mature studies on agents and multi-agent systems have emerged in biology. For instance,
      <cite class="ltx_cite ltx_citemacro_citet">
       Bonabeau et al. [
       <a class="ltx_ref" href="#bib.bib219" title="">
        219
       </a>
       ]
      </cite>
      explores the theory and applications of swarm intelligence, encompassing genetic algorithms, ant colony algorithms, and particle swarm algorithms based on multi-agent models.
      <cite class="ltx_cite ltx_citemacro_citet">
       DeAngelis and Mooij [
       <a class="ltx_ref" href="#bib.bib220" title="">
        220
       </a>
       ]
      </cite>
      offers a comprehensive overview of individual-based modeling methods in ecological research, simulating species interactions and environmental impacts within ecosystems.
      <cite class="ltx_cite ltx_citemacro_citet">
       Wilensky and Rand [
       <a class="ltx_ref" href="#bib.bib221" title="">
        221
       </a>
       ]
      </cite>
      presents agent-based modeling methods and their applications in natural, social, and engineering complex systems, including simulating geographical science issues such as ocean ecosystems and atmospheric circulation using agent systems.
      <cite class="ltx_cite ltx_citemacro_citet">
       Jain et al. [
       <a class="ltx_ref" href="#bib.bib222" title="">
        222
       </a>
       ]
      </cite>
      proposes an active learning algorithm utilizing GFlowNets as generators of diverse candidate solutions, aiming to produce biological sequences with optimal characteristics, such as protein and DNA sequences.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS1.SSS3.p2">
     <p class="ltx_p" id="S5.SS1.SSS3.p2.1">
      Presently, research on LLM-based agents in biology is limited. BioPlanner
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib223" title="">
        223
       </a>
       ]
      </cite>
      is an automated evaluation approach for assessing the performance of LLM in protocol generation and planning tasks within the domain of biology. OceanGPT
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib224" title="">
        224
       </a>
       ]
      </cite>
      employs multi-agent collaboration for the automatic generation of data in various subfields of ocean science. Nevertheless, there exists substantial potential for future investigations in areas such as:
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS1.SSS3.p3">
     <ul class="ltx_itemize" id="S5.I3">
      <li class="ltx_item" id="S5.I3.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I3.i1.p1">
        <p class="ltx_p" id="S5.I3.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I3.i1.p1.1.1">
          Ecosystem Modeling
         </span>
         : LLM-based agents can simulate species interactions and environmental impacts within ecosystems, aiding researchers in comprehending ecosystem structure and function. For example, ecosystem stability, diversity, and evolutionary processes can be analyzed by simulating the behavior and interactions of various agents, including biological individuals, populations, and environments.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I3.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I3.i2.p1">
        <p class="ltx_p" id="S5.I3.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I3.i2.p1.1.1">
          Group Behavior and Collective Intelligence
         </span>
         : Through the simulation of behavior and interactions within groups, fundamental concepts of group behavior, collective intelligence, population genetics, and evolution can be elucidated. In particular, by simulating the behavior and interactions of multiple agents, such as molecular or biological groups, group behavior’s formation, coordination, adaptation, and evolution can be examined, leading to a better understanding of the mechanisms governing overall system functioning.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I3.i3" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para ltx_noindent" id="S5.I3.i3.p1">
        <p class="ltx_p" id="S5.I3.i3.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I3.i3.p1.1.1">
          Cell Biology and Molecular Biology
         </span>
         : LLM-based agents can simulate molecular mechanisms and signaling pathways within cells, subsequently investigating interactions and regulation between biomolecules. For instance, biological processes like intracellular signal transduction, gene expression regulation, and metabolic pathways can be analyzed by simulating the behavior and interactions of multiple agents, such as proteins, nucleic acids, and metabolites.
        </p>
       </div>
      </li>
     </ul>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS1.SSS3.p4">
     <p class="ltx_p" id="S5.SS1.SSS3.p4.1">
      Biological systems are known for their inherent complexity, manifesting across various hierarchical levels, spatiotemporal scales, and temporal extents. In light of this, agents utilizing LLMs must demonstrate proficiency in managing this intricacy. This entails accounting for diverse biological entities’ dynamic behaviors and interactions, including individual organisms, populations, and their respective ecological contexts. Furthermore, data within the realm of biology often exhibits attributes of being voluminous, diverse, heterogeneously structured, and subject to inherent noise. This is evident in datasets encompassing genomic, phenotypic, and environmental information. Consequently, LLM-based agents are required to possess the capability to effectively process substantial volumes of heterogeneous data and distill valuable insights and knowledge from it.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S5.SS1.SSS4">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.1.4
     </span>
     Climate Science
    </h4>
    <div class="ltx_para ltx_noindent" id="S5.SS1.SSS4.p1">
     <p class="ltx_p" id="S5.SS1.SSS4.p1.1">
      In atmospheric research, the employment of agent systems has predominantly spanned areas such as the elucidation of climate behavior and the investigation of climate energy economics. A novel agent-based modeling methodology is presented by
      <cite class="ltx_cite ltx_citemacro_citet">
       Jager [
       <a class="ltx_ref" href="#bib.bib225" title="">
        225
       </a>
       ]
      </cite>
      , which expounds its utility in deciphering the intricacies of climate-related behavioral dynamics. Furthermore,
      <cite class="ltx_cite ltx_citemacro_citet">
       Castro et al. [
       <a class="ltx_ref" href="#bib.bib226" title="">
        226
       </a>
       ]
      </cite>
      offers a comprehensive examination of studies centered on climate-energy policies, emphasizing the reduction of emissions and energy conservation by implementing agent-based modeling approaches.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS1.SSS4.p2">
     <p class="ltx_p" id="S5.SS1.SSS4.p2.1">
      In the current research landscape,
      <cite class="ltx_cite ltx_citemacro_citet">
       Kraus et al. [
       <a class="ltx_ref" href="#bib.bib227" title="">
        227
       </a>
       ]
      </cite>
      leverages LLM-based agents to extract emission data from ClimateWatch
      <span class="ltx_note ltx_role_footnote" id="footnote2">
       <sup class="ltx_note_mark">
        2
       </sup>
       <span class="ltx_note_outer">
        <span class="ltx_note_content">
         <sup class="ltx_note_mark">
          2
         </sup>
         <span class="ltx_tag ltx_tag_note">
          2
         </span>
         https://www.climatewatchdata.org/
        </span>
       </span>
      </span>
      , thereby furnishing more accurate and dependable data pertinent to crucial facets of climate change. LLM-based agents can be harnessed for climate change prognostication by deploying sensor networks across diverse geographical locales to collect atmospheric data (e.g., temperature, pressure, humidity, wind speed) and performing real-time analysis and processing of this data via LLM-based agents. This methodology can further anticipate or issue alerts for atmospheric phenomena and climate change. In contrast, within the realm of climate model simulation and optimization, LLM-based agents can emulate various atmospheric processes and events, such as atmospheric circulation, climate systems, and the propagation of air pollution. By perpetually optimizing and modifying the interaction rules among agents, the model can be honed to more accurately reflect real-world scenarios, ultimately producing more precise predictions and solutions for atmospheric science research.
During the climate simulation process, the escalating complexity of MAS presents a substantial challenge to computational efficiency. Enhancing the performance of LLM-based agents’ planning and reconsideration is vital for achieving more precise climate simulations and forecasts within limited computational resources. Moreover, since most atmospheric data are numerical, enhancing LLM’s understanding and computational capacity for numeric values will significantly influence system performance.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S5.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.2
    </span>
    Universal Autonomous Agent
   </h3>
   <section class="ltx_subsubsection" id="S5.SS2.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.2.1
     </span>
     General Task Assistant
    </h4>
    <div class="ltx_para ltx_noindent" id="S5.SS2.SSS1.p1">
     <p class="ltx_p" id="S5.SS2.SSS1.p1.1">
      Current research on general task assistants primarily focuses on the LLM-based agent systems or frameworks. A Generalist Agent
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib18" title="">
        18
       </a>
       ]
      </cite>
      is a multimodal, multi-task, and multi-entity universal agent capable of performing various tasks, such as playing Atari games, naming images, chatting, stacking blocks with real robotic arms, and more. HuggingGPT
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib155" title="">
        155
       </a>
       ]
      </cite>
      integrates various modules and AI models from different domains within the machine learning community to execute task planning. ModelScope-Agent
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib228" title="">
        228
       </a>
       ]
      </cite>
      is a universal, customizable LLM-based agent framework for practical applications, providing a user-friendly system library. LangChain
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib77" title="">
        77
       </a>
       ]
      </cite>
      is an open-source framework that enables efficient software development through natural language communication and collaboration. XLang
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib76" title="">
        76
       </a>
       ]
      </cite>
      offers a comprehensive set of tools and user interfaces for LLM-based agents, supporting data processing, plugin usage, and web scenarios. BabyAGI
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib59" title="">
        59
       </a>
       ]
      </cite>
      creates tasks based on predefined objectives, utilizes LLM to create new tasks, and stores and retrieves task results. AutoGPT
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib75" title="">
        75
       </a>
       ]
      </cite>
      is an automated agent capable of breaking down objectives and executing tasks in a loop. AgentVerse
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib84" title="">
        84
       </a>
       ]
      </cite>
      enables the rapid creation of simulation experiments based on multiple LLM-based agents performing different roles. LMA3
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib229" title="">
        229
       </a>
       ]
      </cite>
      is a method that leverages LLM to support various abstract objective representations, generation, and learning. Kani
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib230" title="">
        230
       </a>
       ]
      </cite>
      assists developers in implementing various complex functionalities by providing core building blocks for chat-based interactions, including model interfaces, chat management, and powerful function invocation.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS2.SSS1.p2">
     <p class="ltx_p" id="S5.SS2.SSS1.p2.1">
      Although notable advancements have been made in the study of general task assistants employing LLM-based agents, several challenges persist. One such challenge is determining how to judiciously control the granularity of task decomposition while maintaining task-solving efficiency, minimizing token consumption, and reducing computational resource demands. Another challenge pertains to memory utilization and information integration: devising methods to more effectively employ information stored in memory, amalgamate knowledge and data from disparate sources, and augment the accuracy and efficiency of LLM-based agents in problem-solving. Furthermore, developing additional tools and techniques to bolster LLM-based agents in various contexts is essential, enhancing their adaptability and scalability in general task assistants. Ultimately, equipping LLM-based agents with long-term learning and adaptive capabilities is crucial for continuously ameliorating performance in the face of ever-evolving tasks and environments.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS2.SSS1.p3">
     <p class="ltx_p" id="S5.SS2.SSS1.p3.1">
      Future research may investigate more efficient automated task decomposition and optimization algorithms, enabling LLM-based agents to autonomously execute reasonable task decomposition when confronted with complex tasks, thereby improving problem-solving speed and quality. Additionally, integrating multimodal information processing techniques into agents will facilitate the handling and integration of information from different modalities, such as images, sounds, and videos, thereby enriching the capabilities of task assistants.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S5.SS2.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.2.2
     </span>
     Work/Research Assistant
    </h4>
    <div class="ltx_para ltx_noindent" id="S5.SS2.SSS2.p1">
     <p class="ltx_p" id="S5.SS2.SSS2.p1.1">
      In the context of work and research endeavors, the accumulation of substantial volumes of materials and literature may be requisite, followed by their summarization through comprehension, the refinement of viewpoints post-experimentation and validation, and ultimately, their compilation into reports, papers, presentations, or narrative and cinematic works. These steps can also be entrusted to LLM-based agents, which can browse web pages, databases, and literature repositories, summarize them via LLM, generate experimental code for validation, and subsequently draft conclusions.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS2.SSS2.p2">
     <p class="ltx_p" id="S5.SS2.SSS2.p2.1">
      In general text generation, ChatEval
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib16" title="">
        16
       </a>
       ]
      </cite>
      employs a multi-agent debate framework, enhancing efficiency and effectiveness in handling complex tasks.
      <cite class="ltx_cite ltx_citemacro_citet">
       Zhu et al. [
       <a class="ltx_ref" href="#bib.bib231" title="">
        231
       </a>
       ]
      </cite>
      proposes a heuristic reinforcement learning framework that can significantly improve performance without requiring preference data. In creating research reports, stories, and television dramas,
      <cite class="ltx_cite ltx_citemacro_citet">
       Maas et al. [
       <a class="ltx_ref" href="#bib.bib232" title="">
        232
       </a>
       ]
      </cite>
      presents a method based on LLMs, custom diffusion models, and multi-agent simulations to generate high-quality episodic content. GPT Researcher
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib61" title="">
        61
       </a>
       ]
      </cite>
      is an autonomous agent capable of producing detailed, accurate, and unbiased research reports.
      <cite class="ltx_cite ltx_citemacro_citet">
       Boiko et al. [
       <a class="ltx_ref" href="#bib.bib65" title="">
        65
       </a>
       ]
      </cite>
      proposes an intelligent agent system capable of autonomously designing, planning, and executing complex scientific experiments. In domain-specific applications,
      <cite class="ltx_cite ltx_citemacro_citet">
       Mehta et al. [
       <a class="ltx_ref" href="#bib.bib42" title="">
        42
       </a>
       ]
      </cite>
      constructs an agent that learns to understand architect language instructions and uses them to place blocks on a grid, aiming to build a 3D structure. LayoutGPT
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib233" title="">
        233
       </a>
       ]
      </cite>
      collaborates with visual generative models to produce reasonable layouts in various domains, from 2D images to 3D indoor scenes. MusicAgent
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib234" title="">
        234
       </a>
       ]
      </cite>
      incorporates music-related tools and autonomous workflows, including timbre synthesis and music classification, to address user requirements. MemWalker
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib235" title="">
        235
       </a>
       ]
      </cite>
      is an interactive agent designed for long-text reading, which utilizes a technique to convert extensive contexts into a tree structure of summary nodes. When a query is received, the agent traverses this tree to locate pertinent information and generates a response after accumulating adequate information.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS2.SSS2.p3">
     <p class="ltx_p" id="S5.SS2.SSS2.p3.1">
      In contrast to general task assistants, work and research assistants demand more robust memory and knowledge integration capabilities. Augmenting the memory capacity of LLM-based agents is vital for efficiently organizing, summarizing, and retrieving information after processing extensive volumes of textual material. Furthermore, effectively utilizing domain-specific tools, such as code and simulators, for validation experiments is crucial for enhancing task completion and accuracy. LLM-based agents should also exhibit a more comprehensive array of cross-domain knowledge and skills to adapt to diverse work and research requirements. Ultimately, innovation and originality pose significant challenges, as it is necessary to bolster the creativity and originality of LLM-based agents in work and research assistance while circumventing the generation of repetitive or excessively similar content.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS2.SSS2.p4">
     <p class="ltx_p" id="S5.SS2.SSS2.p4.1">
      Future endeavors in LLM-based agents’ work and research assistance may delve further into domains such as artistic creation in music and film generation and incorporate human-machine collaboration to capitalize on human knowledge for producing more original works, thereby providing greater convenience to human work and creativity.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S5.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.3
    </span>
    Social Sciences
   </h3>
   <section class="ltx_subsubsection" id="S5.SS3.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.3.1
     </span>
     Economics and Finance
    </h4>
    <div class="ltx_para ltx_noindent" id="S5.SS3.SSS1.p1">
     <p class="ltx_p" id="S5.SS3.SSS1.p1.1">
      Existing agents and multi-agent systems have been applied in economic and financial research.
      <cite class="ltx_cite ltx_citemacro_citet">
       Arthur et al. [
       <a class="ltx_ref" href="#bib.bib236" title="">
        236
       </a>
       ]
      </cite>
      employs a multi-agent model to construct an artificial stock market, exploring financial market issues such as asset pricing, investor behavior, and market volatility.
      <cite class="ltx_cite ltx_citemacro_citet">
       Tesfatsion and Judd [
       <a class="ltx_ref" href="#bib.bib237" title="">
        237
       </a>
       ]
      </cite>
      comprehensively introduces agent-based computational economics methods and their applications in various economic fields.
      <cite class="ltx_cite ltx_citemacro_citet">
       Johanson et al. [
       <a class="ltx_ref" href="#bib.bib238" title="">
        238
       </a>
       ]
      </cite>
      demonstrates agents’ ability to generate resources in space using MARL and trade them at their preferred prices. The AI Economist
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib239" title="">
        239
       </a>
       ]
      </cite>
      proposes an economic simulation environment with competitive pressures and market dynamics, validating the simulation by demonstrating the operation of basic taxation systems in an economically consistent manner, including the behavior and specialization of learning and professional agents.
      <cite class="ltx_cite ltx_citemacro_citet">
       Tilbury [
       <a class="ltx_ref" href="#bib.bib240" title="">
        240
       </a>
       ]
      </cite>
      reviews the historical barriers classical agent-based techniques face in economic modeling. The AI Economist: Improving Equality and Productivity with AI-Driven Tax Policies presents a two-level deep reinforcement learning method based on economic simulations for learning dynamic tax policies, with agents and governments learning and adapting.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS3.SSS1.p2">
     <p class="ltx_p" id="S5.SS3.SSS1.p2.1">
      Currently, many studies focus on LLM-based agents in economics and finance.
      <cite class="ltx_cite ltx_citemacro_citet">
       Horton [
       <a class="ltx_ref" href="#bib.bib30" title="">
        30
       </a>
       ]
      </cite>
      compares LLM behavior with actual human behavior by placing LLMs in different economic scenarios and exploring their behavior. This enables researchers to investigate economic behavior in simulations such as dictator games and minimum wage issues, gaining new insights into economics.
      <cite class="ltx_cite ltx_citemacro_citet">
       Phelps and Ranson [
       <a class="ltx_ref" href="#bib.bib241" title="">
        241
       </a>
       ]
      </cite>
      investigates LLM responses in principal-agent conflicts, with LLM-based agents overriding their principal’s objectives in a simple online shopping task, providing clear evidence of principal-agent conflict and highlighting the importance of incorporating economic principles into the alignment process. AucArena
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib151" title="">
        151
       </a>
       ]
      </cite>
      illustrates the efficient involvement of LLM-based agents in auctions, effectively managing budgets, preserving long-term objectives, and improving adaptability through explicit incentivization mechanisms.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS3.SSS1.p3">
     <p class="ltx_p" id="S5.SS3.SSS1.p3.1">
      In the domain of Game Theory, the Suspicion-Agent
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib242" title="">
        242
       </a>
       ]
      </cite>
      exhibits exceptional adaptability in various imperfect information card games. It demonstrates robust higher-order Theory of Mind capabilities, suggesting it can comprehend others and intentionally influence their behavior.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS3.SSS1.p4">
     <p class="ltx_p" id="S5.SS3.SSS1.p4.1">
      Numerous studies have investigated using LLM-based agents in the context of financial transaction scenarios. AlphaGPT
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib243" title="">
        243
       </a>
       ]
      </cite>
      introduces an interactive framework for Alpha mining, which employs a heuristic method to comprehend the concepts utilized by quantitative researchers, subsequently generating innovative, insightful, and efficient Alphas. TradingGPT
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib244" title="">
        244
       </a>
       ]
      </cite>
      presents a novel LLM-based MAS framework with layered memories to enhance financial trading decisions by simulating human cognitive processes. This approach enables agents to prioritize crucial tasks, integrate historical actions and market insights, and engage in inter-agent discussions, improving responsiveness and accuracy.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS3.SSS1.p5">
     <p class="ltx_p" id="S5.SS3.SSS1.p5.1">
      Given LLM-based agents’ enhanced textual comprehension and complex decision-making capabilities, there is considerable potential for research in economics and finance utilizing these agents. Relevant explorations may encompass the following areas:
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS3.SSS1.p6">
     <ul class="ltx_itemize" id="S5.I4">
      <li class="ltx_item" id="S5.I4.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I4.i1.p1">
        <p class="ltx_p" id="S5.I4.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I4.i1.p1.1.1">
          Market Simulation and Emulation
         </span>
         : Establishing LLM-based agents to simulate the behavior of various market actors, such as supply and demand sides, competitors, and regulators, can enable researchers to predict and emulate data on product prices, market shares, market structures, and transaction completion rates. Behaviors may include purchasing, competitive bidding, bargaining, and collaborative tendering.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I4.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I4.i2.p1">
        <p class="ltx_p" id="S5.I4.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I4.i2.p1.1.1">
          Financial Market Analysis
         </span>
         : Through the simulation of actions by financial market participants, including investors, institutions, and regulators, LLM-based agents can offer valuable insights into market volatility and risks. For instance, simulations of investor trading behavior and market information dissemination processes can provide predictions about fluctuations in stock prices, exchange rates, and interest rates.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I4.i3" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I4.i3.p1">
        <p class="ltx_p" id="S5.I4.i3.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I4.i3.p1.1.1">
          Macroeconomic and Policy Simulation
         </span>
         : LLM-based agents can model the implementation process of fiscal and monetary policies, incorporating various economic actors such as governments, businesses, and individuals. This allows the agents to forecast shifts in macroeconomic indicators, including GDP, inflation, and unemployment rates.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I4.i4" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para ltx_noindent" id="S5.I4.i4.p1">
        <p class="ltx_p" id="S5.I4.i4.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I4.i4.p1.1.1">
          Socio-economic Network Analysis
         </span>
         : By modeling processes such as information dissemination, resource allocation, and trust-building within socio-economic networks, LLM-based agents can contribute to a more profound understanding of the evolution and impact of network economies. Specifically, simulations involving diverse agents, such as consumers, businesses, and governments, can offer insights into network effects, information asymmetry, and market failures.
        </p>
       </div>
      </li>
     </ul>
     <p class="ltx_p" id="S5.SS3.SSS1.p6.1">
      For LLM-based agents in economics, typically simulating human or economic actors’ decision-making, the action space of agent interactions and the state of the agent plays a crucial role, directly affecting experimental results. Effectively representing the interaction action space and the state of the agent to simulate the decision-making process of economic actors more accurately is a significant challenge. Simultaneously, the credibility of LLM anthropomorphism is also a major challenge. If conducting large-scale macroeconomic analysis, many LLM-based agents may be required, posing difficulties for system performance or token consumption. One approach is to use reinforcement learning methods to control and reduce the number of interactions with LLMs.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S5.SS3.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.3.2
     </span>
     Politics
    </h4>
    <div class="ltx_para ltx_noindent" id="S5.SS3.SSS2.p1">
     <p class="ltx_p" id="S5.SS3.SSS2.p1.1">
      In previous agent research within the political domain,
      <cite class="ltx_cite ltx_citemacro_citet">
       Epstein and Axtell [
       <a class="ltx_ref" href="#bib.bib245" title="">
        245
       </a>
       ]
      </cite>
      employs MAS to construct an artificial society, investigating the formation and evolution of social phenomena, including political communication and social movements in political science.
      <cite class="ltx_cite ltx_citemacro_citet">
       Lustick and Miodownik [
       <a class="ltx_ref" href="#bib.bib246" title="">
        246
       </a>
       ]
      </cite>
      discusses the application of MAS in comparative political science research, encompassing political systems, political decision-making, and political stability.
      <cite class="ltx_cite ltx_citemacro_citet">
       Tsvetovat and Carley [
       <a class="ltx_ref" href="#bib.bib247" title="">
        247
       </a>
       ]
      </cite>
      introduces the application of multi-agent models in studying complex socio-technical systems, including political communication and political decision-making in political science.
      <cite class="ltx_cite ltx_citemacro_citet">
       Trott et al. [
       <a class="ltx_ref" href="#bib.bib248" title="">
        248
       </a>
       ]
      </cite>
      utilizes two-level RL and data-driven simulation to achieve effective, flexible, and interpretable policy design.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS3.SSS2.p2">
     <p class="ltx_p" id="S5.SS3.SSS2.p2.1">
      In current LLM-based agents research, these agents are employed to explore potential decisions and communication situations of political actors.
      <cite class="ltx_cite ltx_citemacro_citet">
       Ziems et al. [
       <a class="ltx_ref" href="#bib.bib201" title="">
        201
       </a>
       ]
      </cite>
      uses LLM-based agents to help understand the content and tactics of politicians’ speeches.
      <cite class="ltx_cite ltx_citemacro_citet">
       Bail [
       <a class="ltx_ref" href="#bib.bib249" title="">
        249
       </a>
       ]
      </cite>
      demonstrates that LLM-based agents can detect ideology, predict voting results, and identify patterns.
      <cite class="ltx_cite ltx_citemacro_citet">
       Mukobi et al. [
       <a class="ltx_ref" href="#bib.bib250" title="">
        250
       </a>
       ]
      </cite>
      presents a general-sum variant of the zero-sum board game diplomacy. In this variant, agents must balance investments in military conquest and domestic welfare.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS3.SSS2.p3">
     <p class="ltx_p" id="S5.SS3.SSS2.p3.1">
      LLM-based agents in the political domain can explore the following areas:
     </p>
     <ul class="ltx_itemize" id="S5.I5">
      <li class="ltx_item" id="S5.I5.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I5.i1.p1">
        <p class="ltx_p" id="S5.I5.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I5.i1.p1.1.1">
          Political Simulation and Prediction
         </span>
         : By simulating the behaviors and interactions of various participants in the political process, such as party competition, voter behavior, and policy-making processes, LLM-based agents can forecast developmental trends of political events, election outcomes, and policy effects.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I5.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I5.i2.p1">
        <p class="ltx_p" id="S5.I5.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I5.i2.p1.1.1">
          Political Decision-making Analysis
         </span>
         : Employing LLM-based agents to simulate the behaviors and interactions of different political decision-making processes enables the evaluation of the advantages, disadvantages, and impacts of various policy choices. This approach allows researchers to simulate interactions among governments, political parties, and interest groups, providing policymakers with valuable information on policy effects.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I5.i3" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para ltx_noindent" id="S5.I5.i3.p1">
        <p class="ltx_p" id="S5.I5.i3.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I5.i3.p1.1.1">
          International Relations Research
         </span>
         : Utilizing LLM-based agents to model interactions and conflicts between countries in international politics, researchers can explore various aspects such as international trade, military conflicts, and diplomatic interactions. This approach assists in understanding the complexity and potential risks associated with international politics.
        </p>
       </div>
      </li>
     </ul>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS3.SSS2.p4">
     <p class="ltx_p" id="S5.SS3.SSS2.p4.1">
      In political research, LLM-based agents may need to ensure communication efficiency while avoiding excessive politeness and ineffective communication, enhancing the practical application value of LLM-based agents in political science research. Simultaneously, accurately modeling the complexity and uncertainty of political environments to improve the accuracy and reliability of LLM-based agents in political domain research poses a challenge. Of course, it is also necessary to ensure that LLM-based agent behavior complies with ethical and moral requirements, avoiding adverse social impacts.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S5.SS3.SSS3">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.3.3
     </span>
     Society
    </h4>
    <div class="ltx_para ltx_noindent" id="S5.SS3.SSS3.p1">
     <p class="ltx_p" id="S5.SS3.SSS3.p1.1">
      In prior Multi-Agent research in sociology,
      <cite class="ltx_cite ltx_citemacro_citet">
       Epstein and Axtell [
       <a class="ltx_ref" href="#bib.bib245" title="">
        245
       </a>
       ]
      </cite>
      employs multi-agent models to construct an artificial society, investigating the formation and evolution of social phenomena such as social movements, cultural evolution, and social change within the field of sociology.
      <cite class="ltx_cite ltx_citemacro_citet">
       Macy and Willer [
       <a class="ltx_ref" href="#bib.bib251" title="">
        251
       </a>
       ]
      </cite>
      introduces computational sociology and agent-based modeling methods, encompassing social networks, social norms, and social influence within sociology.
      <cite class="ltx_cite ltx_citemacro_citet">
       Gilbert and Troitzsch [
       <a class="ltx_ref" href="#bib.bib252" title="">
        252
       </a>
       ]
      </cite>
      presented the theory and practice of utilizing simulation methods for social scientists, including the application of multi-agent models in sociological research.
      <cite class="ltx_cite ltx_citemacro_citet">
       Hasan et al. [
       <a class="ltx_ref" href="#bib.bib253" title="">
        253
       </a>
       ]
      </cite>
      discusses the pillars of sustainable development (e.g., social, environmental, and economic).
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS3.SSS3.p2">
     <p class="ltx_p" id="S5.SS3.SSS3.p2.1">
      Currently, LLM-based agents primarily concentrate on simulating human behavior and social interactions. Generative Agents
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib63" title="">
        63
       </a>
       ]
      </cite>
      proposes an interaction mode of Multi LLM-based agents to achieve a credible simulation of human behavior.
      <cite class="ltx_cite ltx_citemacro_citet">
       Gao et al. [
       <a class="ltx_ref" href="#bib.bib33" title="">
        33
       </a>
       ]
      </cite>
      uses prompt engineering and adjustment techniques to create an LLM-based MAS that simulates real-world social network data, including emotions, attitudes, and interaction behaviors.
      <cite class="ltx_cite ltx_citemacro_citet">
       Li et al. [
       <a class="ltx_ref" href="#bib.bib34" title="">
        34
       </a>
       ]
      </cite>
      examine the behavior characteristics of LLM-driven social robots within a Twitter-like social network. The results demonstrated that these robots could disguise and influence online communities through toxic behavior.
      <cite class="ltx_cite ltx_citemacro_citet">
       Liu et al. [
       <a class="ltx_ref" href="#bib.bib254" title="">
        254
       </a>
       ]
      </cite>
      proposes a novel learning paradigm enabling language models to learn from simulated social interactions.
      <cite class="ltx_cite ltx_citemacro_citet">
       Feng et al. [
       <a class="ltx_ref" href="#bib.bib255" title="">
        255
       </a>
       ]
      </cite>
      investigates the capability of LLM-based agents to simulate credible human behavior in carefully designed environments and protocols.
      <cite class="ltx_cite ltx_citemacro_citet">
       Wei et al. [
       <a class="ltx_ref" href="#bib.bib256" title="">
        256
       </a>
       ]
      </cite>
      assesses the performance of multi-party group chat conversation models, explores methods to enhance model performance, and addresses the challenges of turn-taking and dialogue coherence.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS3.SSS3.p3">
     <p class="ltx_p" id="S5.SS3.SSS3.p3.1">
      On the other hand,
      <cite class="ltx_cite ltx_citemacro_citet">
       Li et al. [
       <a class="ltx_ref" href="#bib.bib35" title="">
        35
       </a>
       ]
      </cite>
      develops an opinion network dynamic model to encode LLM opinions, individual cognitive acceptability, and usage strategies, simulating the impact of LLMs on opinion dynamics in various scenarios. LLM-Mob
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib257" title="">
        257
       </a>
       ]
      </cite>
      utilize LLM’s language understanding and reasoning capabilities to analyze human migration data by introducing the concepts of historical stays and contextual stays, capturing long-term and short-term dependencies of human movement, and employing the temporal information of prediction targets for time-aware prediction.
      <cite class="ltx_cite ltx_citemacro_citet">
       Egami et al. [
       <a class="ltx_ref" href="#bib.bib258" title="">
        258
       </a>
       ]
      </cite>
      utilizes LLM outputs for downstream statistical analysis of document labels in social science while maintaining statistical properties, such as asymptotic unbiasedness and accurate uncertainty quantification.
      <cite class="ltx_cite ltx_citemacro_citet">
       Ghaffarzadegan et al. [
       <a class="ltx_ref" href="#bib.bib259" title="">
        259
       </a>
       ]
      </cite>
      explores the emerging opportunities in employing generative artificial intelligence for constructing computational models with intricate feedback, which can depict individual decision-making within social systems. Lyfe Agents
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib260" title="">
        260
       </a>
       ]
      </cite>
      assesses the self-motivation and social capabilities of the agents in various multi-agent scenarios. The approach combines low-cost and real-time responsiveness while preserving intelligence and goal-directedness.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS3.SSS3.p4">
     <p class="ltx_p" id="S5.SS3.SSS3.p4.1">
      These studies offer various methods and frameworks for LLM-based agents in simulating human behavior and social interactions. Owing to LLM-based agents’ ability to simulate human communication and mimic human thinking, these agents can simulate credible human behavior, participate in multi-party group chats, learn social interactions in simulated environments, handle memory and planning tasks, and exhibit human behavior characteristics in opinion dynamics.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS3.SSS3.p5">
     <p class="ltx_p" id="S5.SS3.SSS3.p5.1">
      However, these studies also reveal challenges, such as ensuring that LLM-based agents maintain turn-taking and dialogue coherence in multi-party group chats to enhance the authenticity of simulating human behavior and social interactions and effectively training socially-aligned language models in simulated environments to improve LLM-based agents’ adaptability and accuracy in social interactions. Additionally, LLM-based agents must achieve diversity and personalized simulation for each human actor to better reflect real-world social phenomena. Future research may continue to explore these challenges and propose more effective methods to improve LLM-based agents’ performance in simulating human behavior and social interactions.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S5.SS3.SSS4">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.3.4
     </span>
     Law
    </h4>
    <div class="ltx_para ltx_noindent" id="S5.SS3.SSS4.p1">
     <p class="ltx_p" id="S5.SS3.SSS4.p1.1">
      In prior research on Agent and Multi-Agent systems within the legal domain,
      <cite class="ltx_cite ltx_citemacro_citet">
       Bench-Capon and Sartor [
       <a class="ltx_ref" href="#bib.bib261" title="">
        261
       </a>
       ]
      </cite>
      employs multi-agent models to examine theories and values in the legal reasoning process, offering novel theories and methods for legal decision-making and legal system design.
      <cite class="ltx_cite ltx_citemacro_citet">
       Branting [
       <a class="ltx_ref" href="#bib.bib262" title="">
        262
       </a>
       ]
      </cite>
      constructs a computational legal analysis model using multi-agent models, investigating the role of legal rules and precedents in legal reasoning.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS3.SSS4.p2">
     <p class="ltx_p" id="S5.SS3.SSS4.p2.1">
      Currently, there is limited research on LLM-based agents in the legal domain. Blind Judgement
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib37" title="">
        37
       </a>
       ]
      </cite>
      introduces Multi-LLM-based agents for simulating judicial decisions of the United States Supreme Court from 2010 to 2016, training nine separate models to emulate the opinions of different justices.
      <cite class="ltx_cite ltx_citemacro_citet">
       Shui et al. [
       <a class="ltx_ref" href="#bib.bib263" title="">
        263
       </a>
       ]
      </cite>
      assesses the efficacy of LLMs when integrated with professional information retrieval systems for case-based learning and question-answering within the legal field.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS3.SSS4.p3">
     <p class="ltx_p" id="S5.SS3.SSS4.p3.1">
      Considering that LLM-based agents possess robust text processing and comprehension capabilities, as well as a Memory mechanism for recording historical cases and decisions, there is substantial potential for exploration in the legal domain, such as in the following areas:
     </p>
     <ul class="ltx_itemize" id="S5.I6">
      <li class="ltx_item" id="S5.I6.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I6.i1.p1">
        <p class="ltx_p" id="S5.I6.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I6.i1.p1.1.1">
          Autonomous Legal Assistant
         </span>
         : LLM-based agents integrate legal provisions and historical case reviews to provide document writing and auxiliary advice on current cases.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I6.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para ltx_noindent" id="S5.I6.i2.p1">
        <p class="ltx_p" id="S5.I6.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I6.i2.p1.1.1">
          Legal Decision-making Analysis
         </span>
         : LLM-based agents simulate the behavior and interactions of various participants in the legal decision-making process, including judges, lawyers, and litigants, to evaluate the advantages, disadvantages, impacts, fairness, and efficiency of distinct legal policies and legal systems.
        </p>
       </div>
      </li>
     </ul>
     <p class="ltx_p" id="S5.SS3.SSS4.p3.2">
      As the legal domain typically involves substantial textual material, the LLM in LLM-based agents requires a longer context and more efficient Memory capabilities. Furthermore, effectively representing legal knowledge, encompassing legal provisions, historical cases, and legal principles, and executing accurate legal reasoning in LLM-based agents are crucial for making decisions or simulating after reading and comprehending the law.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S5.SS3.SSS5">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.3.5
     </span>
     Psychology
    </h4>
    <div class="ltx_para ltx_noindent" id="S5.SS3.SSS5.p1">
     <p class="ltx_p" id="S5.SS3.SSS5.p1.1">
      In previous research in psychology,
      <cite class="ltx_cite ltx_citemacro_citet">
       Sun [
       <a class="ltx_ref" href="#bib.bib264" title="">
        264
       </a>
       ]
      </cite>
      provides a comprehensive introduction to applying multi-agent interaction in cognitive modeling and social simulation, encompassing cognitive processes, social interactions, and emotional motivations in psychology.
      <cite class="ltx_cite ltx_citemacro_citet">
       Marsella and Gratch [
       <a class="ltx_ref" href="#bib.bib265" title="">
        265
       </a>
       ]
      </cite>
      employs agent models to model the emotional appraisal process, enabling a deeper understanding of the fundamental principles of emotional psychology.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS3.SSS5.p2">
     <p class="ltx_p" id="S5.SS3.SSS5.p2.1">
      Currently, LLM-based agents primarily focus on applications in mental health support and psychological experiment simulation.
      <cite class="ltx_cite ltx_citemacro_citet">
       Ma et al. [
       <a class="ltx_ref" href="#bib.bib266" title="">
        266
       </a>
       ]
      </cite>
      conducts a qualitative analysis of LLM-based agent-supported mental health support applications. The study finds that the application helps provide on-demand, non-judgmental support, enhancing user confidence and facilitating self-discovery. However, it faces challenges in filtering harmful content, maintaining consistent communication, remembering new information, and alleviating user overdependence.
      <cite class="ltx_cite ltx_citemacro_citet">
       Aher et al. [
       <a class="ltx_ref" href="#bib.bib199" title="">
        199
       </a>
       ]
      </cite>
      utilizes LLM-based agents to simulate psychological experiments, revealing some "hyper-precise distortions" in LLM that could affect downstream applications.
      <cite class="ltx_cite ltx_citemacro_citet">
       Akata et al. [
       <a class="ltx_ref" href="#bib.bib200" title="">
        200
       </a>
       ]
      </cite>
      employs LLM-based agents to simulate repeated games in game theory, discovering that LLM-based agents perform exceptionally well in games emphasizing self-interest, especially in prisoner’s dilemma games, and exhibit a psychological tendency to prioritize self-interest over coordination. These studies provide various methods and frameworks for LLM-based agents in mental health support and psychological experiment simulation. These LLM-based agents have broad application prospects in providing psychological support, replicating psychological findings, and simulating game theory experiments. Humanoid agents
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib267" title="">
        267
       </a>
       ]
      </cite>
      constitute a platform for developing agents that emulate human cognition, communication, and behavioral patterns. These agents incorporate logical reasoning capabilities contingent on particular factors, such as fulfilling fundamental needs, emotions, and interactions with others.
      <cite class="ltx_cite ltx_citemacro_citet">
       Zhang et al. [
       <a class="ltx_ref" href="#bib.bib268" title="">
        268
       </a>
       ]
      </cite>
      investigates the potential of LLM-based multi-agent societies to mirror human collaborative intelligence.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS3.SSS5.p3">
     <p class="ltx_p" id="S5.SS3.SSS5.p3.1">
      LLM-based agents in the field of psychology can explore the following areas in the future:
     </p>
     <ul class="ltx_itemize" id="S5.I7">
      <li class="ltx_item" id="S5.I7.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I7.i1.p1">
        <p class="ltx_p" id="S5.I7.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I7.i1.p1.1.1">
          Psychological Therapy and Counseling
         </span>
         : By simulating interactions and influences during psychological therapy and counseling processes, LLM-based agents contribute to a deeper understanding of the fundamental principles of psychotherapy and counseling psychology for researchers and support patients receiving psychological treatment.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I7.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I7.i2.p1">
        <p class="ltx_p" id="S5.I7.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I7.i2.p1.1.1">
          Cognitive Modeling
         </span>
         : Through emulating cognitive processes such as perception, memory, thinking, and decision-making, LLM-based agents offer insights into the core principles of cognitive psychology. Specifically, these agents can analyze cognitive biases and strategies by simulating individuals’ cognitive processes across various situations.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I7.i3" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para ltx_noindent" id="S5.I7.i3.p1">
        <p class="ltx_p" id="S5.I7.i3.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I7.i3.p1.1.1">
          Emotion and Motivation Modeling
         </span>
         : Utilizing LLM and Memory to model emotional and motivational processes, LLM-based agents enable researchers to explore the fundamental principles of emotional and motivational psychology by examining emotional reactions, interests, and drives in individuals.
        </p>
       </div>
      </li>
     </ul>
     <p class="ltx_p" id="S5.SS3.SSS5.p3.2">
      However, these studies also reveal challenges, such as effectively filtering harmful content, maintaining consistent communication, achieving more anthropomorphic communication or simulation, and addressing user overdependence issues. Future research may continue to explore these challenges and propose more effective methods to improve the performance of LLM-based agents in mental health support and psychological experiment simulation.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S5.SS3.SSS6">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.3.6
     </span>
     Education
    </h4>
    <div class="ltx_para ltx_noindent" id="S5.SS3.SSS6.p1">
     <p class="ltx_p" id="S5.SS3.SSS6.p1.1">
      In existing Agent and Multi-Agent research,
      <cite class="ltx_cite ltx_citemacro_citet">
       Woolf [
       <a class="ltx_ref" href="#bib.bib269" title="">
        269
       </a>
       ]
      </cite>
      introduces methods and techniques for constructing intelligent interactive tutors, including using Agent and Multi-Agent systems to implement personalized teaching and adaptive learning.
      <cite class="ltx_cite ltx_citemacro_citet">
       Soller and Lesgold [
       <a class="ltx_ref" href="#bib.bib270" title="">
        270
       </a>
       ]
      </cite>
      presents computational methods employing multi-agent models to analyze online knowledge-sharing interactions to improve educational organization and management.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS3.SSS6.p2">
     <p class="ltx_p" id="S5.SS3.SSS6.p2.1">
      Owing to their strong natural language interaction capabilities, LLM-based agents facilitate efficient communication with humans, which can be useful for assisting human learning or simulating classrooms in the education domain. For research assistance, please refer to the research assistance section. Math Agents
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib40" title="">
        40
       </a>
       ]
      </cite>
      convert mathematical formulas from literature into LaTeX and Python formats, utilizing LLM as a language user interface and artificial intelligence assistant to foster interaction between mathematics and computer science. AgentVerse
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib84" title="">
        84
       </a>
       ]
      </cite>
      is an LLM-based MAS framework simulating NLP classroom education. CGMI
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib168" title="">
        168
       </a>
       ]
      </cite>
      is a general multi-agent interaction framework that simulates various classroom interactions between teachers and students, with experimental results demonstrating that teaching methods, courses, and student performance closely resemble real classroom environments. Furthermore, LLM-based agents can simulate the implementation process of future educational policies and systems, assisting researchers in evaluating the advantages, disadvantages, and impacts of different educational strategies. For instance, by simulating the behavior of governments, schools, teachers, and students, MAS can predict academic input, quality, and equity changes.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS3.SSS6.p3">
     <p class="ltx_p" id="S5.SS3.SSS6.p3.1">
      In the education domain, the primary challenge for LLM-based agents is to output harmless, more credible content to enhance education quality. Another challenge is diversity and personalization: education targets a diverse range of students, and implementing personalized teaching and adaptive learning for each student in the LLM-based agent system remains a significant challenge. Moreover, although LLMs possess strong natural language interaction capabilities, there is room for improvement in understanding students’ questions, expressions, and emotions to address their learning needs better.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S5.SS3.SSS7">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.3.7
     </span>
     Management
    </h4>
    <div class="ltx_para ltx_noindent" id="S5.SS3.SSS7.p1">
     <p class="ltx_p" id="S5.SS3.SSS7.p1.1">
      In the existing research on Agent and Multi-Agent Systems domains,
      <cite class="ltx_cite ltx_citemacro_citet">
       North and Macal [
       <a class="ltx_ref" href="#bib.bib271" title="">
        271
       </a>
       ]
      </cite>
      provides a comprehensive introduction to applying agent-based modeling and simulation for managing business complexity. This encompasses organizational behavior, human resource management, and marketing in management studies.
      <cite class="ltx_cite ltx_citemacro_citet">
       Bonabeau [
       <a class="ltx_ref" href="#bib.bib272" title="">
        272
       </a>
       ]
      </cite>
      introduces agent-based modeling methods and their applications in simulating human systems, including organizational behavior, supply chain management, and financial markets in the management field.
      <cite class="ltx_cite ltx_citemacro_citet">
       Liu et al. [
       <a class="ltx_ref" href="#bib.bib273" title="">
        273
       </a>
       ]
      </cite>
      applies MARL to multi-echelon inventory management problems, aiming to minimize the overall supply chain costs.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS3.SSS7.p2">
     <p class="ltx_p" id="S5.SS3.SSS7.p2.1">
      Currently, LLM-based agents in the management domain primarily focus on simulating the operations of companies and organizations. For instance, MetaGPT
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib67" title="">
        67
       </a>
       ]
      </cite>
      and ChatDev
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib66" title="">
        66
       </a>
       ]
      </cite>
      simulate multiple roles in a software company for collaborative software development. MetaAgents
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib274" title="">
        274
       </a>
       ]
      </cite>
      utilizes a simulated job fair environment as a case study to assess agents’ information processing, retrieval, and coordination capabilities. The results indicate that these agents demonstrate exceptional performance in comprehending project workflows, identifying appropriate co-authors, and delegating tasks. Further exploration can be conducted in the following areas:
     </p>
     <ul class="ltx_itemize" id="S5.I8">
      <li class="ltx_item" id="S5.I8.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I8.i1.p1">
        <p class="ltx_p" id="S5.I8.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I8.i1.p1.1.1">
          Organizational Behavior and Collaborative Work
         </span>
         : By simulating the behavior and interactions of employees, teams, and managers in organizations, LLM-based agents serve as a valuable tool for researchers to study collaborative work processes, enhancing the understanding of organizational structure, culture, leadership, and efficiency.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I8.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I8.i2.p1">
        <p class="ltx_p" id="S5.I8.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I8.i2.p1.1.1">
          Company Auxiliary Operations
         </span>
         : Assisting companies and organizations in their operations, LLM-based agents contribute to increased efficiency by taking on reporting, information summarization, processing, approvals, and decision-making, resulting in more efficient, fair, and transparent company operations.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I8.i3" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para ltx_noindent" id="S5.I8.i3.p1">
        <p class="ltx_p" id="S5.I8.i3.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I8.i3.p1.1.1">
          Supply Chain Management and Logistics Optimization
         </span>
         : Researchers can effectively analyze and optimize supply chain management and logistics by employing LLM-based agents to simulate resource allocation and collaborative decision-making processes. This is achieved by modeling the behavior and interactions of suppliers, manufacturers, distributors, and retailers, allowing LLM-based agents to address supply chain inventory management, transportation schedules, and demand forecasting issues.
        </p>
       </div>
      </li>
     </ul>
     <p class="ltx_p" id="S5.SS3.SSS7.p2.2">
      Management problems often involve multiple levels, roles, and objectives. Effectively addressing these complexities and scalability issues in LLM-based agents remains a significant challenge. Furthermore, management research typically relies on various historical and real-time data forms. LLM-based agents need to understand historical data in different formats effectively.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S5.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.4
    </span>
    Engineering Systems
   </h3>
   <section class="ltx_subsubsection" id="S5.SS4.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.4.1
     </span>
     Computer System
    </h4>
    <div class="ltx_para ltx_noindent" id="S5.SS4.SSS1.p1">
     <p class="ltx_p" id="S5.SS4.SSS1.p1.1">
      In computer science, numerous mature studies exist on agent and multi-agent systems. These studies primarily focus on computer operation tasks, human-computer interaction, code generation and testing, network security, gaming, and recommendation system applications.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS4.SSS1.p2">
     <ul class="ltx_itemize" id="S5.I9">
      <li class="ltx_item" id="S5.I9.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I9.i1.p1">
        <p class="ltx_p" id="S5.I9.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I9.i1.p1.1.1">
          Computer Operation
         </span>
         : RCI
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib138" title="">
           138
          </a>
          ]
         </cite>
         employs natural language commands to guide LLMs in completing computer tasks. Mobile-Env
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib141" title="">
           141
          </a>
          ]
         </cite>
         is based on the Android for mobile devices environment, enabling intelligent agents to observe Android operating system screenshots, view hierarchies, and interact with Android applications.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I9.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I9.i2.p1">
        <p class="ltx_p" id="S5.I9.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I9.i2.p1.1.1">
          Human-computer Interaction
         </span>
         :
         <cite class="ltx_cite ltx_citemacro_citet">
          Lin et al. [
          <a class="ltx_ref" href="#bib.bib275" title="">
           275
          </a>
          ]
         </cite>
         introduces a collaborative task called decision-oriented dialogue. In these tasks, AI assistants collaborate with humans through natural language to assist in making complex decisions. SAPIEN
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib276" title="">
           276
          </a>
          ]
         </cite>
         introduces a high-fidelity virtual agent platform driven by LLMs, allowing open-domain conversations with users in 13 languages and expressing emotions through facial expressions and voice modulation. In web interaction, WebAgent
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib277" title="">
           277
          </a>
          ]
         </cite>
         proposes a model that integrates two language models—a domain expert language model and a general language model—for autonomous navigation on real websites. WebArena
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib139" title="">
           139
          </a>
          ]
         </cite>
         is a standalone, self-hosted web environment for building autonomous agents. SheetCopilot
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib142" title="">
           142
          </a>
          ]
         </cite>
         facilitates interaction with spreadsheets using natural language, converting complex requests into actionable steps.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I9.i3" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I9.i3.p1">
        <p class="ltx_p" id="S5.I9.i3.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I9.i3.p1.1.1">
          Network Security
         </span>
         :
         <cite class="ltx_cite ltx_citemacro_citet">
          Rigaki et al. [
          <a class="ltx_ref" href="#bib.bib278" title="">
           278
          </a>
          ]
         </cite>
         proposes a method that uses LLM as attack agents, applied in reinforcement learning environments.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I9.i4" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I9.i4.p1">
        <p class="ltx_p" id="S5.I9.i4.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I9.i4.p1.1.1">
          Code Generation
         </span>
         : GPT-Engineer
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib43" title="">
           43
          </a>
          ]
         </cite>
         is easy to adapt and extend, allowing LLM-based agents to generate entire code repositories based on prompts.
         <cite class="ltx_cite ltx_citemacro_citet">
          Dong et al. [
          <a class="ltx_ref" href="#bib.bib68" title="">
           68
          </a>
          ]
         </cite>
         allows multiple LLMs to play different roles, forming a team without human intervention to collaborate on code generation tasks. ChatDev
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib66" title="">
           66
          </a>
          ]
         </cite>
         explores using LLM-driven end-to-end software development frameworks, covering requirements analysis, code development, system testing, and document generation to provide a unified, efficient, cost-effective software development paradigm. CAAFE
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib279" title="">
           279
          </a>
          ]
         </cite>
         employs LLMs to generate and execute code for feature engineering on tabular datasets. AutoGen
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib83" title="">
           83
          </a>
          ]
         </cite>
         presents an autonomous LLM-based agent that generates an entire code repository based on prompts.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I9.i5" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I9.i5.p1">
        <p class="ltx_p" id="S5.I9.i5.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I9.i5.p1.1.1">
          Software Testing
         </span>
         : LLift
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib145" title="">
           145
          </a>
          ]
         </cite>
         is an interface with static analysis tools and LLM, using carefully designed agents and prompts for full automation.
         <cite class="ltx_cite ltx_citemacro_citet">
          Feldt et al. [
          <a class="ltx_ref" href="#bib.bib280" title="">
           280
          </a>
          ]
         </cite>
         proposes an autonomous LLM-based testing agent that provides a conversational framework to help developers with testing and emphasizes the benefits of LLM illusions in testing. RCAgent
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib281" title="">
           281
          </a>
          ]
         </cite>
         is a tool-enhanced agent for practical and privacy-aware industrial root cause analysis (RCA) in cloud environments.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I9.i6" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I9.i6.p1">
        <p class="ltx_p" id="S5.I9.i6.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I9.i6.p1.1.1">
          Recommendation System
         </span>
         : RecAgent
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib282" title="">
           282
          </a>
          ]
         </cite>
         uses LLM as the brain and recommendation models as tools, creating a versatile and interactive recommendation system. Agent4Rec
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib283" title="">
           283
          </a>
          ]
         </cite>
         comprises user profile, memory, and action modules and interacts via web pages to deliver personalized movie recommendations.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I9.i7" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I9.i7.p1">
        <p class="ltx_p" id="S5.I9.i7.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I9.i7.p1.1.1">
          Role-playing Game
         </span>
         : VOYAGER
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib50" title="">
           50
          </a>
          ]
         </cite>
         is a lifelong learning agent in Minecraft driven by LLM that continuously explores the world, acquires various skills, and makes discoveries. GITM
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib51" title="">
           51
          </a>
          ]
         </cite>
         proposes a framework that achieves efficient and flexible operation by converting long-term and complex goals into a series of lowest-level keyboard and mouse operations.
         <cite class="ltx_cite ltx_citemacro_citet">
          Junprung [
          <a class="ltx_ref" href="#bib.bib284" title="">
           284
          </a>
          ]
         </cite>
         proposes two agents simulating human behavior: a two-agent negotiation and a six-agent murder mystery game.
         <cite class="ltx_cite ltx_citemacro_citet">
          Zhou et al. [
          <a class="ltx_ref" href="#bib.bib47" title="">
           47
          </a>
          ]
         </cite>
         proposes a dialogue-shaping framework that allows LLM to obtain helpful information from NPCs through dialogue and convert it into a knowledge graph, then use story-shaping techniques to accelerate RL agents’ convergence to optimal strategies. Clembench
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib285" title="">
           285
          </a>
          ]
         </cite>
         has developed a flexible and scalable framework using conversational games as testing tools to assess a wide range of models quickly. Tachikuma
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib286" title="">
           286
          </a>
          ]
         </cite>
         proposes the integration of virtual game masters (GMs) into the world models of agents. GMs play a crucial role in supervising information, estimating player intentions, providing environment descriptions, offering feedback, and addressing the limitations of current world models.
         <cite class="ltx_cite ltx_citemacro_citet">
          Xu et al. [
          <a class="ltx_ref" href="#bib.bib170" title="">
           170
          </a>
          ]
         </cite>
         effectively conducts the Werewolf game without adjusting the LLMs’ parameters and exhibits strategic behavior in experiments. MindAgent
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib181" title="">
           181
          </a>
          ]
         </cite>
         presents a novel game scenario and associated benchmarks, facilitating the evaluation of multi-agent collaboration efficiency and enabling the supervision of multiple agents engaged in gameplay concurrently.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I9.i8" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para ltx_noindent" id="S5.I9.i8.p1">
        <p class="ltx_p" id="S5.I9.i8.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I9.i8.p1.1.1">
          Game Generation
         </span>
         :
         <cite class="ltx_cite ltx_citemacro_citet">
          Chen et al. [
          <a class="ltx_ref" href="#bib.bib287" title="">
           287
          </a>
          ]
         </cite>
         designs a text-based adventure game imaginative play system that generates stories related to imaginative play based on ChatGPT. GameGPT
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib288" title="">
           288
          </a>
          ]
         </cite>
         utilizes a dual-agent collaboration and a hierarchical approach, employing multiple internal dictionaries for automating game development.
        </p>
       </div>
      </li>
     </ul>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS4.SSS1.p3">
     <p class="ltx_p" id="S5.SS4.SSS1.p3.1">
      Despite some achievements, many research directions and challenges exist for LLM-based agents in computer science. For example, in code generation and testing, the coding capabilities of LLM are essential, and how to improve the code quality and testing results of LLM-based agents is a noteworthy issue. In network security, recommendation systems, and other aspects, fully utilizing the advantages of LLM-based agents and addressing existing problems still require further research. For computer operation and human-computer interaction, LLM-based agents must master more tool usage capabilities to implement more functions. Further, by building adaptive learning and long-term development LLM-based agent systems, they can continuously improve their performance when facing constantly changing computer science problems.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S5.SS4.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.4.2
     </span>
     Robotics System
    </h4>
    <div class="ltx_para ltx_noindent" id="S5.SS4.SSS2.p1">
     <p class="ltx_p" id="S5.SS4.SSS2.p1.1">
      In previous research on agents and multi-agent systems in robotics,
      <cite class="ltx_cite ltx_citemacro_citet">
       Parker et al. [
       <a class="ltx_ref" href="#bib.bib289" title="">
        289
       </a>
       ]
      </cite>
      introduced investigations on multi-mobile robot systems and collaborative control issues among multiple robots.
      <cite class="ltx_cite ltx_citemacro_citet">
       Busoniu et al. [
       <a class="ltx_ref" href="#bib.bib290" title="">
        290
       </a>
       ]
      </cite>
      discussed robotic learning and intelligence concerns.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS4.SSS2.p2">
     <p class="ltx_p" id="S5.SS4.SSS2.p2.1">
      In the present work on LLM-based agent research within robotics, the primary focus lies on robot task planning.
      <cite class="ltx_cite ltx_citemacro_citet">
       Di Palo et al. [
       <a class="ltx_ref" href="#bib.bib55" title="">
        55
       </a>
       ]
      </cite>
      proposes a framework that utilizes language as a core reasoning tool, simulates robot operation environments, and demonstrates significant performance improvements in exploration efficiency and offline data reuse. ProgPrompt
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib291" title="">
        291
       </a>
       ]
      </cite>
      proposes a programmatic LLM prompt structure that facilitates task planning across various environments and robotic functional tasks.
      <cite class="ltx_cite ltx_citemacro_citet">
       Huang et al. [
       <a class="ltx_ref" href="#bib.bib292" title="">
        292
       </a>
       ]
      </cite>
      examines how LLM can execute reasoning via natural language feedback in robotic control situations without requiring further training. TaPA
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib146" title="">
        146
       </a>
       ]
      </cite>
      presents a method for planning in the real world under physical scene constraints, where agents generate executable plans by aligning LLM and visual perception models based on the objects in the scene. LLM-Planner
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib49" title="">
        49
       </a>
       ]
      </cite>
      leverages the power of LLMs for sample-efficient planning for embodied agents.
      <cite class="ltx_cite ltx_citemacro_citet">
       Xiang et al. [
       <a class="ltx_ref" href="#bib.bib293" title="">
        293
       </a>
       ]
      </cite>
      fine-tunes LLM with world models to acquire diverse embodied knowledge, using these experiences to fine-tune LLM further and enable reasoning and action in various physical environments. 3D-LLM
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib294" title="">
        294
       </a>
       ]
      </cite>
      accepts 3D point clouds and their features as input, completing a series of 3D-related tasks. ProAgent
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib71" title="">
        71
       </a>
       ]
      </cite>
      can predict teammates’ upcoming decisions and develop enhanced plans for itself, demonstrating exceptional performance in cooperative reasoning. Additionally, it can dynamically adjust its behavior to improve collaboration with teammates.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS4.SSS2.p3">
     <p class="ltx_p" id="S5.SS4.SSS2.p3.1">
      LLM-based agents hold promising potential in enhancing automation levels, supporting multi-scenario applications, and achieving efficient task execution. Future research may continue to address these challenges or investigate the following aspects:
     </p>
     <ul class="ltx_itemize" id="S5.I10">
      <li class="ltx_item" id="S5.I10.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I10.i1.p1">
        <p class="ltx_p" id="S5.I10.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I10.i1.p1.1.1">
          Multi-robot Collaborative Control
         </span>
         : LLM-based agents are well-suited for simulating collaborative control and task allocation in multi-robot systems, assisting researchers in improving the collaborative performance and execution efficiency of such systems. For instance, researchers can analyze multi-robot task allocation, path planning, and collaboration strategies by simulating the behavior and interactions of various types of robots, tasks, and environments.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I10.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para ltx_noindent" id="S5.I10.i2.p1">
        <p class="ltx_p" id="S5.I10.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I10.i2.p1.1.1">
          Unmanned Aerial Vehicle (UAV) Swarm Flight and Control
         </span>
         : LLM-based agents can simulate swarm control, path planning, and obstacle avoidance in UAV swarm flight, aiding researchers in analyzing flight stability, formation change, and safe flight of UAV swarms.
        </p>
       </div>
      </li>
     </ul>
     <p class="ltx_p" id="S5.SS4.SSS2.p3.2">
      Concurrently, LLM-based agents must address complex environment adaptation and modeling more comprehensively, as robotics encompasses numerous complex environments and tasks that demand accurate handling of complex issues. Moreover, robots must process real-time multimodal data and make decisions, meaning agents should also exhibit rapid response and multimodal processing capabilities.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S5.SS4.SSS3">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.4.3
     </span>
     Power System
    </h4>
    <div class="ltx_para ltx_noindent" id="S5.SS4.SSS3.p1">
     <p class="ltx_p" id="S5.SS4.SSS3.p1.1">
      Numerous mature applications already exist in electric power and energy systems based on Agent and Multi-Agent systems. For instance,
      <cite class="ltx_cite ltx_citemacro_citet">
       Kilkki et al. [
       <a class="ltx_ref" href="#bib.bib295" title="">
        295
       </a>
       ]
      </cite>
      comprehensively reviews agent-based modeling and simulation applications in smart grids. The paper introduces the characteristics and challenges of smart grids. It classifies and compares agent-based modeling and simulation methods, discussing the application of agent-based models in different scenarios in smart grids.
      <cite class="ltx_cite ltx_citemacro_citet">
       Merabet et al. [
       <a class="ltx_ref" href="#bib.bib296" title="">
        296
       </a>
       ]
      </cite>
      reviews MAS in smart grids, introducing the concept and characteristics of MAS and discussing the application scenarios, key technologies, and challenges of MAS in smart grids.
      <cite class="ltx_cite ltx_citemacro_citet">
       Ghazzali et al. [
       <a class="ltx_ref" href="#bib.bib297" title="">
        297
       </a>
       ]
      </cite>
      examines the fixed-time distributed voltage and reactive power compensation in islanded microgrids using sliding-mode and multi-agent consensus design methodologies.
      <cite class="ltx_cite ltx_citemacro_citet">
       Shinde and Amelin [
       <a class="ltx_ref" href="#bib.bib298" title="">
        298
       </a>
       ]
      </cite>
      reviews the literature on agent-based modeling applications in various electricity markets.
      <cite class="ltx_cite ltx_citemacro_citet">
       May and Huang [
       <a class="ltx_ref" href="#bib.bib299" title="">
        299
       </a>
       ]
      </cite>
      employs MARL to design dynamic pricing policies for energy markets under climate change scenarios.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS4.SSS3.p2">
     <p class="ltx_p" id="S5.SS4.SSS3.p2.1">
      LLM-based agent research in electric power and energy is developing, with relatively few related studies. Future research may explore the following directions:
     </p>
     <ul class="ltx_itemize" id="S5.I11">
      <li class="ltx_item" id="S5.I11.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I11.i1.p1">
        <p class="ltx_p" id="S5.I11.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I11.i1.p1.1.1">
          Smart Grid Management and Optimization
         </span>
         : By emulating the behavior and interactions of power plants, transmission lines, and electricity-consuming equipment, LLM-based agents can effectively model challenges in smart grids. These challenges include power generation, transmission, distribution, and electricity consumption management. The assessment of grid stability, energy efficiency, and power dispatch is also possible with these agents.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I11.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I11.i2.p1">
        <p class="ltx_p" id="S5.I11.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I11.i2.p1.1.1">
          Distributed Energy Resource Scheduling
         </span>
         : The scheduling and optimization of distributed energy resources, such as solar energy, wind energy, and energy storage devices, can be modeled using LLM-based agents. These agents allow for examining distributed energy resources’ power generation effects, market competition, and energy complementarity.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I11.i3" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para ltx_noindent" id="S5.I11.i3.p1">
        <p class="ltx_p" id="S5.I11.i3.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I11.i3.p1.1.1">
          Energy Market and Trading Mechanisms
         </span>
         : LLM-based agents are suitable for simulating issues in energy markets, such as supply-demand balance, price formation, and trading mechanisms. Precisely, they can simulate the behavior and interactions of energy producers, consumers, and trading platforms, analyzing energy markets’ competitive landscape, price fluctuations, and trading efficiency.
        </p>
       </div>
      </li>
     </ul>
     <p class="ltx_p" id="S5.SS4.SSS3.p2.2">
      Large-scale integration and collaborative optimization pose significant challenges in the context of renewable energy and distributed energy resources. To achieve efficient operation and sustainable development of power systems, LLM-based agents must consider various energy types, multi-level grid structures, and complex market environments. Moreover, developing related technical standards and specifications is necessary to facilitate the widespread application and promotion of multi-agent systems in smart grids. This will enhance the interoperability and scalability of these systems while reducing the difficulty and cost of integration. Through extensive research and innovation, LLM-based agents are anticipated to play a crucial role in smart grid management and optimization, distributed energy resource scheduling, and energy market and trading mechanisms, ultimately contributing to the sustainable development of power systems.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S5.SS4.SSS4">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.4.4
     </span>
     Transportation System
    </h4>
    <div class="ltx_para ltx_noindent" id="S5.SS4.SSS4.p1">
     <p class="ltx_p" id="S5.SS4.SSS4.p1.1">
      Transportation has attracted extensive research interest in agent systems. MARL can be employed to coordinate multiple traffic signals to optimize traffic flow, reduce congestion, and enhance road traffic efficiency.
      <cite class="ltx_cite ltx_citemacro_citet">
       Zeng et al. [
       <a class="ltx_ref" href="#bib.bib300" title="">
        300
       </a>
       ]
      </cite>
      introduces a method for controlling traffic signals utilizing deep Q-learning.
      <cite class="ltx_cite ltx_citemacro_citet">
       Chu et al. [
       <a class="ltx_ref" href="#bib.bib301" title="">
        301
       </a>
       ]
      </cite>
      applies distributed MARL techniques to coordinate traffic signals in large-scale urban road networks to minimize traffic congestion.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS4.SSS4.p2">
     <p class="ltx_p" id="S5.SS4.SSS4.p2.1">
      Research on LLM-based agents in transportation is currently in its nascent stage.
      <cite class="ltx_cite ltx_citemacro_citet">
       Da et al. [
       <a class="ltx_ref" href="#bib.bib302" title="">
        302
       </a>
       ]
      </cite>
      employs LLM to comprehend and analyze system dynamics through context-based prompts for reasoning. By leveraging the reasoning capabilities of LLM, it is possible to understand how weather conditions, traffic conditions, and road types affect traffic dynamics. Subsequently, the agent takes actions based on real-world dynamics and learns more realistic strategies accordingly. TrafficGPT
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib149" title="">
        149
       </a>
       ]
      </cite>
      combines LLM with traffic domain expertise to enhance traffic management effectiveness. Moreover, it equips LLM with the capability to visualize, analyze, and process traffic data, offering valuable decision support for urban transportation system management. DiLu
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib303" title="">
        303
       </a>
       ]
      </cite>
      integrates reasoning and reflection modules, allowing autonomous driving systems to make decisions grounded in common-sense knowledge.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS4.SSS4.p3">
     <p class="ltx_p" id="S5.SS4.SSS4.p3.1">
      LLM-based agents can investigate and contribute to the following aspects in the field of transportation: LLM-based agents can manage traffic signals, optimizing them according to real-time traffic flow and demand to reduce congestion and waiting times. Compared to traditional methods, dispatchers can adjust signal cycles through natural language. However, due to the involvement of multi-objective optimization and decision-making, significant challenges arise for LLM’s reasoning and decision-making capabilities. On the other hand, LLM-based agents can be employed to simulate vehicle travel and road condition changes in the traffic flow process, assisting researchers in understanding the characteristics and factors influencing traffic flow. For instance, by simulating the behavior and interactions of vehicles, roads, and traffic signals, LLM-based agents can analyze traffic congestion, accidents, and efficiency issues, providing a higher degree of simulation compared to the original implementation, as LLM-based agent-simulated vehicles more closely resemble human decision-making.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS4.SSS4.p4">
     <p class="ltx_p" id="S5.SS4.SSS4.p4.1">
      For transportation systems, it is typically essential to effectively process real-time data and optimize decision-making based on real-time traffic flow and demand. LLM-based agents need to exhibit a rapid response speed. Furthermore, efficiently implementing traffic signal control and scheduling strategies when facing multiple optimization objectives and decision factors remains challenging.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S5.SS4.SSS5">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.4.5
     </span>
     Industrial Control System
    </h4>
    <div class="ltx_para ltx_noindent" id="S5.SS4.SSS5.p1">
     <p class="ltx_p" id="S5.SS4.SSS5.p1.1">
      In the realm of Agent and Multi-Agent research, the current state of investigation regarding agent-based intelligent manufacturing systems is reviewed by
      <cite class="ltx_cite ltx_citemacro_citet">
       Shen and Norrie [
       <a class="ltx_ref" href="#bib.bib304" title="">
        304
       </a>
       ]
      </cite>
      , with a particular emphasis on production scheduling and resource optimization concerns.
      <cite class="ltx_cite ltx_citemacro_citet">
       Shen et al. [
       <a class="ltx_ref" href="#bib.bib305" title="">
        305
       </a>
       ]
      </cite>
      comprehensively examines agent-based system applications within the intelligent manufacturing domain.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS4.SSS5.p2">
     <p class="ltx_p" id="S5.SS4.SSS5.p2.1">
      At present, LLM-based agent applications in industrial control and engineering encompass works such as the study by
      <cite class="ltx_cite ltx_citemacro_citet">
       Xia et al. [
       <a class="ltx_ref" href="#bib.bib69" title="">
        69
       </a>
       ]
      </cite>
      , which introduces an innovative framework integrating LLMs, digital twins, and industrial automation systems for the intelligent planning and control of production processes. The authors establish two categories of intelligent agents: a managerial agent functioning at the apex of the automation module, responsible for coordinating various module skills to devise production plans, and an operational agent situated within a specific automation module, orchestrating multiple functions to execute the provided skills. In energy-efficient lighting systems,
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib306" title="">
        306
       </a>
       ]
      </cite>
      employs sensors, actuators, and neural networks, achieving superior decision-making and adaptability by incorporating GPT-4 without requiring extensive training. In the field of chip design, an LLM-based agent is utilized by
      <cite class="ltx_cite ltx_citemacro_citet">
       Li et al. [
       <a class="ltx_ref" href="#bib.bib307" title="">
        307
       </a>
       ]
      </cite>
      to assist in the development of Finite-Difference Time-Domain (FDTD) simulation code and deep reinforcement learning code, culminating in optimized Photonic Crystal Surface Emitting Laser (PCSEL) structures for advanced silicon photonics and photonic integrated circuit applications.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS4.SSS5.p3">
     <p class="ltx_p" id="S5.SS4.SSS5.p3.1">
      The potential of LLM-based agents in industrial process control and optimization is promising, encompassing tasks such as data collection simulation, control strategy formulation, and equipment modification. LLM-based agents can assess industrial processes’ stability, production efficiency, and energy consumption by emulating the behavior and interactions of sensors, controllers, and actuators. One challenge LLM-based agents face is bridging the gap between real-world task planning and text task planning, thereby augmenting their practical applicability in industrial process control and optimization. Another challenge pertains to addressing the complexities and scalability concerns that emerge from the multiple levels, roles, and objectives inherent in industrial process control and optimization.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S5.SS4.SSS6">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.4.6
     </span>
     Medical System
    </h4>
    <div class="ltx_para ltx_noindent" id="S5.SS4.SSS6.p1">
     <p class="ltx_p" id="S5.SS4.SSS6.p1.1">
      Agent systems exhibit many applications within medical and pharmaceutical research, spanning areas such as drug discovery and optimization, exploration of drug mechanisms, and pharmacokinetic simulations.
      <cite class="ltx_cite ltx_citemacro_citet">
       An [
       <a class="ltx_ref" href="#bib.bib308" title="">
        308
       </a>
       ]
      </cite>
      demonstrates the employment of agent-based computer simulations in biomedical research, including drug discovery and optimization processes.
      <cite class="ltx_cite ltx_citemacro_citet">
       Ekins et al. [
       <a class="ltx_ref" href="#bib.bib309" title="">
        309
       </a>
       ]
      </cite>
      presents agent-based pathway mapping tools for high-throughput data analysis, covering aspects such as drug mechanism investigation and drug target identification.
      <cite class="ltx_cite ltx_citemacro_citet">
       Walker et al. [
       <a class="ltx_ref" href="#bib.bib310" title="">
        310
       </a>
       ]
      </cite>
      proposes an agent-based model of cellular social behavior for simulating personalized drug treatments and precision medicine.
      <cite class="ltx_cite ltx_citemacro_citet">
       Singhal et al. [
       <a class="ltx_ref" href="#bib.bib311" title="">
        311
       </a>
       ]
      </cite>
      discusses the enhancement of LLMs within medical and clinical domains.
      <cite class="ltx_cite ltx_citemacro_citet">
       Zhavoronkov et al. [
       <a class="ltx_ref" href="#bib.bib312" title="">
        312
       </a>
       ]
      </cite>
      develops Generative Tensorial Reinforcement Learning (GENTRL) to design novel small molecules, optimizing the synthesized compounds’ feasibility, novelty, and bioactivity.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS4.SSS6.p2">
     <p class="ltx_p" id="S5.SS4.SSS6.p2.1">
      Currently, research on LLM-based agents in medical science remains relatively scarce.
      <cite class="ltx_cite ltx_citemacro_citet">
       Williams et al. [
       <a class="ltx_ref" href="#bib.bib64" title="">
        64
       </a>
       ]
      </cite>
      introduces a novel individual model paradigm to tackle the challenge of incorporating human behavior into epidemic models, with agents exhibiting multi-wave epidemic patterns following the epidemic period, mirroring those observed in recent pandemics.
      <cite class="ltx_cite ltx_citemacro_citet">
       Lobentanzer and Saez-Rodriguez [
       <a class="ltx_ref" href="#bib.bib313" title="">
        313
       </a>
       ]
      </cite>
      employs general and biomedical-specific knowledge to address the LLM hallucination issue and seamlessly integrates prevalent bioinformatics techniques, enhancing its practical applicability and reliability.
      <cite class="ltx_cite ltx_citemacro_citet">
       Mehandru et al. [
       <a class="ltx_ref" href="#bib.bib314" title="">
        314
       </a>
       ]
      </cite>
      presents a novel evaluation framework, termed "Artificial-intelligence Structured Clinical Examinations" ("AI-SCI"), for assessing the performance of LLM agents in real-world clinical tasks.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS4.SSS6.p3">
     <p class="ltx_p" id="S5.SS4.SSS6.p3.1">
      LLM-based agents hold significant potential within the fields of medical and pharmaceutical research, encompassing aspects such as:
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS4.SSS6.p4">
     <ul class="ltx_itemize" id="S5.I12">
      <li class="ltx_item" id="S5.I12.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S5.I12.i1.p1">
        <p class="ltx_p" id="S5.I12.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I12.i1.p1.1.1">
          Disease Transmission and Epidemiological Modeling
         </span>
         : Through the simulation of various agents’ behavior and interactions in disease transmission, including infected, susceptible, and recovered individuals, as well as processes such as individual mobility, social behavior, and disease state alterations, investigators can obtain a deeper understanding of disease transmission dynamics and develop effective control strategies.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S5.I12.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para ltx_noindent" id="S5.I12.i2.p1">
        <p class="ltx_p" id="S5.I12.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S5.I12.i2.p1.1.1">
          Drug Discovery and Optimization
         </span>
         : LLM-based agents can be utilized to replicate the screening, optimization, and evaluation procedures in drug discovery, thereby aiding researchers in identifying novel drugs with specific effects and applications. Specifically, by simulating the behavior and interactions of drug molecules, target proteins, and biological processes, LLM agents can examine pharmaceuticals’ structure-activity relationship, pharmacodynamics, and pharmacokinetics.
        </p>
       </div>
      </li>
     </ul>
     <p class="ltx_p" id="S5.SS4.SSS6.p4.1">
      Nevertheless, this field involves numerous highly complex biological systems, and addressing these complexity issues while ensuring model accuracy remains a significant challenge.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S5.SS4.SSS7">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      5.4.7
     </span>
     Military System
    </h4>
    <div class="ltx_para ltx_noindent" id="S5.SS4.SSS7.p1">
     <p class="ltx_p" id="S5.SS4.SSS7.p1.1">
      Agents and Multi-Agent Systems (MAS) hold substantial potential in military research, particularly in aiding researchers in comprehending the intricacies and dynamics of military issues through simulation and emulation.
      <cite class="ltx_cite ltx_citemacro_citet">
       Ilachinski [
       <a class="ltx_ref" href="#bib.bib315" title="">
        315
       </a>
       ], Cil and Mala [
       <a class="ltx_ref" href="#bib.bib316" title="">
        316
       </a>
       ]
      </cite>
      introduce multi-agent-based war simulation methodologies, encompassing war simulation and tactical analyses, military intelligence, and decision support.
      <cite class="ltx_cite ltx_citemacro_citet">
       Sycara and Sukthankar [
       <a class="ltx_ref" href="#bib.bib317" title="">
        317
       </a>
       ]
      </cite>
      reviews the advancements in teamwork models, including multi-agent-based military communication and command and control systems.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS4.SSS7.p2">
     <p class="ltx_p" id="S5.SS4.SSS7.p2.1">
      Currently, there is limited research on LLM-based MAS within the military domain. Future exploration could focus on war simulation and tactical analysis, where LLM-based MAS can be employed to simulate combat actions and tactical decision-making during warfare. This may involve simulating combat units, commanders, and terrain environments with multiple cooperating or opposing agents. Such simulations aid researchers in evaluating the strengths and weaknesses of various tactical plans and analyzing combat effectiveness, battlefield situations, and tactical advantages. Another area of interest is military intelligence and decision support: LLM-based agents can be utilized to implement military intelligence and decision support, thereby enhancing the accuracy and efficiency of command decisions. Precisely, agents can simulate intelligence collection, analysis, and decision-making to achieve real-time intelligence analysis, early warning, and strategic planning. LLM-based agents can leverage their robust generalization capabilities in different military scenarios for planning, analysis, and decision-making.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S5.SS4.SSS7.p3">
     <p class="ltx_p" id="S5.SS4.SSS7.p3.1">
      Nevertheless, military research often requires consideration of numerous factors, such as ensuring a highly realistic simulation environment, incorporating more accurate representations of battlefield terrain, weather conditions, combat unit performance, and multi-level (e.g., strategic, operational, tactical) and multi-domain (e.g., land, sea, air, space, cyber) factors. Effective collaboration with human decision-makers is crucial to accurately reflect the complexity and dynamics of combat actions and tactical decision-making. Simultaneously, legal and ethical issues must be addressed. As artificial intelligence technology becomes increasingly prevalent in the military, the importance of legal and ethical considerations grows.
     </p>
    </div>
   </section>
  </section>
 </section>
 <section class="ltx_section" id="S6">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    6
   </span>
   Discussion
  </h2>
  <section class="ltx_subsection" id="S6.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     6.1
    </span>
    Trend
   </h3>
   <section class="ltx_paragraph" id="S6.SS1.SSS0.Px1">
    <h5 class="ltx_title ltx_title_paragraph">
     Evaluation
    </h5>
    <div class="ltx_para ltx_noindent" id="S6.SS1.SSS0.Px1.p1">
     <p class="ltx_p" id="S6.SS1.SSS0.Px1.p1.1">
      LLM-based agents have shown remarkable capabilities in various domains, including specified task-solving, cooperation, and human interaction. However, assessing their performance quantifiable and objectively remains a challenge.
     </p>
     <ul class="ltx_itemize" id="S6.I1">
      <li class="ltx_item" id="S6.I1.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para ltx_noindent" id="S6.I1.i1.p1">
        <p class="ltx_p" id="S6.I1.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S6.I1.i1.p1.1.1">
          Foundational Capabilities:
         </span>
         As the field of research on LLM-based agents continues to advance, the foundational competencies of these agents have reached a stage of relative stability, underscoring the imperative need for standardized assessments of these foundational capabilities. Notably, benchmarks such as Minecraft
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib50" title="">
           50
          </a>
          ,
          <a class="ltx_ref" href="#bib.bib134" title="">
           134
          </a>
          ,
          <a class="ltx_ref" href="#bib.bib51" title="">
           51
          </a>
          ]
         </cite>
         and Tachikuma
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib286" title="">
           286
          </a>
          ]
         </cite>
         have been introduced to gauge the understanding of LLM-based agents in comprehending complex problems and engaging in logical reasoning. Additionally, the AgentSims
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib143" title="">
           143
          </a>
          ]
         </cite>
         is a versatile framework for evaluating the agent’s planning and decision-making skills, including its ability to make informed decisions in various contexts. AgentBench
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib318" title="">
           318
          </a>
          ]
         </cite>
         provides a comprehensive platform for assessing agents’ foundational capabilities holistically. Evaluating tool and resource utilization by LLM-based agents has garnered considerable research attention. It is poised to evolve with the development of more standardized and finely-tuned assessment metrics and protocols in this domain. Notably, the ToolBench
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib196" title="">
           196
          </a>
          ]
         </cite>
         and Gentopia
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib163" title="">
           163
          </a>
          ]
         </cite>
         contribute to this assessment facet by ascertaining how agents can effectively utilize various tools and resources to accomplish tasks. Currently, retrieval capability is evaluated in online shopping scenarios such as WebShop
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib194" title="">
           194
          </a>
          ]
         </cite>
         and WebArena
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib139" title="">
           139
          </a>
          ]
         </cite>
         . Information retrieval is essential for LLM-based agents to acquire updated knowledge, which should be included in the benchmark of tool utilization. Memory storage, retrieval, and memory form mechanisms are critical designs for LLM-based agents to maintain long-term contextual understanding and meaningful behavior. Quantified metrics and well-designed benchmarks in the memorization capability have been discussed in
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib319" title="">
           319
          </a>
          ]
         </cite>
         , and enlarged tasks and metrics should be included to facilitate LLM-based agents’ more anthropopathic memory behavior.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S6.I1.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para ltx_noindent" id="S6.I1.i2.p1">
        <p class="ltx_p" id="S6.I1.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S6.I1.i2.p1.1.1">
          Domain-based Evaluation:
         </span>
         Assessing the performance of LLM-based agents requires benchmarking both the executive environment and the specified tasks. Simply relying on MBPP
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib192" title="">
           192
          </a>
          ]
         </cite>
         and HumanEval
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib193" title="">
           193
          </a>
          ]
         </cite>
         benchmarks is not enough because LLM-based agents can observe the runtime execution results and perform code re-generation, such as MetaGPT
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib67" title="">
           67
          </a>
          ]
         </cite>
         and ChatDev
         <cite class="ltx_cite ltx_citemacro_cite">
          [
          <a class="ltx_ref" href="#bib.bib66" title="">
           66
          </a>
          ]
         </cite>
         . Therefore, it is necessary to design task-level definition and evaluation protocols, as AgentBench shows. Furthermore, developing and announcing task-based benchmarks in diverse domains such as law and medicine are imperative to propel research and application of domain-specific LLM-based agents. Such benchmarks serve as critical reference points for assessing the efficacy and competence of these agents within specialized fields. Meanwhile, in psychology, assessment metrics such as the emotional assessment of LLM-based agents and treatment outcome assessment about applying LLM-based agents rely on human feedback and comparison as reported in
         <cite class="ltx_cite ltx_citemacro_citet">
          tse Huang et al. [
          <a class="ltx_ref" href="#bib.bib320" title="">
           320
          </a>
          ]
         </cite>
         , datasets and evaluation mechanisms are essential.
        </p>
       </div>
      </li>
     </ul>
    </div>
   </section>
   <section class="ltx_paragraph" id="S6.SS1.SSS0.Px2">
    <h5 class="ltx_title ltx_title_paragraph">
     Continual Evolution
    </h5>
    <div class="ltx_para ltx_noindent" id="S6.SS1.SSS0.Px2.p1">
     <p class="ltx_p" id="S6.SS1.SSS0.Px2.p1.1">
      When operating in complex and dynamic environments, LLM-based agents typically require the ability to evolve continuously, adapting their parameters, memory, and objectives accordingly.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S6.SS1.SSS0.Px2.p2">
     <ul class="ltx_itemize" id="S6.I2">
      <li class="ltx_item" id="S6.I2.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S6.I2.i1.p1">
        <p class="ltx_p" id="S6.I2.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S6.I2.i1.p1.1.1">
          Continual Learning and Self-training
         </span>
         : A crucial aspect of LLM-based agents is their capacity for continuous learning and adaptation. As tasks and domains evolve, agents must acquire new knowledge and skills without losing previously learned information. Techniques such as lifelong learning and meta-learning can enhance the agent’s reasoning ability, enabling it to generalize and apply knowledge to novel situations. Furthermore, efficiently utilizing the agent’s memory can improve its intrinsic generalization capabilities. Developing effective mechanisms for continual learning and self-training is essential for LLM-based agents’ long-term success and applicability across various domains. Research in this area should focus on devising robust algorithms and models that allow agents to learn from diverse information sources, including textual data, user interactions, and real-world experiences.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S6.I2.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S6.I2.i2.p1">
        <p class="ltx_p" id="S6.I2.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S6.I2.i2.p1.1.1">
          Self-Evaluation and Dynamic Goals
         </span>
         : LLM-based agents should possess self-evaluation and goal-setting capabilities to enhance performance and adapt to changing environments. It is crucial for agents to assess the feedback from their environment and comprehend any criticism of their behavior. LLM-based agents can effectively learn from feedback and extract and retain critical experiences utilizing more efficient programming mechanisms. LLM-based agents can evaluate signals or quantitative metrics and qualitative feedback, enhancing their ability to process evaluations. This ability involves assessing their strengths and weaknesses, identifying areas for improvement, and setting realistic self-improvement goals. Agents should also monitor their progress toward these goals and make necessary adjustments to remain on track. Developing self-evaluation and dynamic goal-setting mechanisms will enable LLM-based agents to become more autonomous and adaptive, leading to improved performance and more effective human-agent collaboration.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S6.I2.i3" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para ltx_noindent" id="S6.I2.i3.p1">
        <p class="ltx_p" id="S6.I2.i3.p1.1">
         <span class="ltx_text ltx_font_bold" id="S6.I2.i3.p1.1.1">
          Adaptability
         </span>
         : The success of LLM-based agents critically depends on their ability to adapt to new environments, tasks, and user preferences. This adaptability encompasses several aspects, including understanding and adjusting to user needs, adapting to different communication styles, and swiftly learning new tasks and domains. Research in this area should concentrate on creating models and algorithms that enable agents to learn from their experiences and interactions with users, allowing them to adjust their behavior and strategies accordingly. Developing robust LLM and Rethink techniques will also enable LLM-based agents to apply their knowledge and skills in novel situations, ultimately leading to more versatile and effective agents.
        </p>
       </div>
      </li>
     </ul>
    </div>
   </section>
   <section class="ltx_paragraph" id="S6.SS1.SSS0.Px3">
    <h5 class="ltx_title ltx_title_paragraph">
     Enhancement of Multimodal Capabilities
    </h5>
    <div class="ltx_para ltx_noindent" id="S6.SS1.SSS0.Px3.p1">
     <p class="ltx_p" id="S6.SS1.SSS0.Px3.p1.1">
      Agents must manage multimodal information in real-world situations, encompassing images, videos, and speech. The incorporation of additional multimodal models can equip LLM-based agents with multimodal proficiencies. This process typically entails converting multimodal input into textual data, utilizing LLMs for inference and planning, and employing multimodal models for output generation. For example, MM-React
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib321" title="">
        321
       </a>
       ]
      </cite>
      integrates ChatGPT with a visual expert pool to accomplish multimodal inference and action. IdealGPT
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib322" title="">
        322
       </a>
       ]
      </cite>
      is a framework for the iterative decomposition of visual reasoning, employing LLMs to generate sub-questions, multimodal models to supply corresponding sub-answers, and LLMs to deduce the final response.
      <cite class="ltx_cite ltx_citemacro_citet">
       Di Palo et al. [
       <a class="ltx_ref" href="#bib.bib55" title="">
        55
       </a>
       ]
      </cite>
      propose a framework that amalgamates an RL-based agent trained from scratch with the advanced capabilities of LLMs and multimodal models. The agent can explain its multimodal environment, tasks, and actions through language. TaPA
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib146" title="">
        146
       </a>
       ]
      </cite>
      generates executable plans by aligning LLMs and visual perception models for real-world scenarios with physical scene constraints. ViperGPT
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib323" title="">
        323
       </a>
       ]
      </cite>
      combines visual and language models using code generation models to produce results for any query.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S6.SS1.SSS0.Px3.p2">
     <p class="ltx_p" id="S6.SS1.SSS0.Px3.p2.1">
      Conversely, recent large multimodal models (LMMs), such as GPT4-V
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib324" title="">
        324
       </a>
       ]
      </cite>
      , miniGPT-v2
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib325" title="">
        325
       </a>
       ]
      </cite>
      , LLaVA
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib326" title="">
        326
       </a>
       ]
      </cite>
      , and PALM-E
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib327" title="">
        327
       </a>
       ]
      </cite>
      , have exhibited robust image content comprehension capabilities. In the future, when constructing agents with LMMs, it will no longer be necessary to convert images into text before inputting them into LLMs. Instead, LMMs can directly execute multimodal task planning and reconsideration based on the current image input, enhancing information utilization efficiency and multimodal task processing performance.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S6.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     6.2
    </span>
    Challenges
   </h3>
   <section class="ltx_subsubsection" id="S6.SS2.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      6.2.1
     </span>
     Intrinsic Constraints of LLMs
    </h4>
    <div class="ltx_para ltx_noindent" id="S6.SS2.SSS1.p1">
     <p class="ltx_p" id="S6.SS2.SSS1.p1.1">
      LLMs provide the foundation for LLM-based agents, facilitating planning and reconsideration capacities, natural language expression, and robust generalization across diverse tasks. Nevertheless, LLMs often face constraints due to context length
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib14" title="">
        14
       </a>
       ]
      </cite>
      , which may result in the loss of essential information when processing extensive articles or complex dialogues
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib328" title="">
        328
       </a>
       ]
      </cite>
      . Another concern is the generation of invalid data and hallucinations by the LLM
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib329" title="">
        329
       </a>
       ]
      </cite>
      . Despite the ability of LLMs to produce fluent and ostensibly plausible text, they may generate irrelevant, invalid, or even erroneous information. This phenomenon arises from LLMs acquiring extraneous data or incorrect patterns during training. Such issues considerably influence the efficacy of LLMs, subsequently impacting the overall performance of both LLM-based agents and LLM-based MAS.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S6.SS2.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      6.2.2
     </span>
     Dynamic Scaling
    </h4>
    <div class="ltx_para ltx_noindent" id="S6.SS2.SSS2.p1">
     <p class="ltx_p" id="S6.SS2.SSS2.p1.1">
      As the deployment of LLM-based MAS becomes more widespread, the system must be capable of dynamic expansion across various hardware and software environments, adjusting its scale and performance in response to demand. However, the implementation of dynamic scaling presents several challenges, including:
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="S6.SS2.SSS2.p2">
     <ul class="ltx_itemize" id="S6.I3">
      <li class="ltx_item" id="S6.I3.i1" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para" id="S6.I3.i1.p1">
        <p class="ltx_p" id="S6.I3.i1.p1.1">
         <span class="ltx_text ltx_font_bold" id="S6.I3.i1.p1.1.1">
          Adaptability
         </span>
         : The system must be capable of adjusting its scale and performance to meet diverse task requirements and computing environments. This requires robust adaptive capabilities, including automatic adjustments to the number of agents, the sizes of various memory spaces, and conversion strategies. Researchers may employ adaptive algorithms, such as reinforcement learning and genetic algorithms, for automatic optimization and adjustment to achieve this adaptability.
        </p>
       </div>
      </li>
      <li class="ltx_item" id="S6.I3.i2" style="list-style-type:none;">
       <span class="ltx_tag ltx_tag_item">
        •
       </span>
       <div class="ltx_para ltx_noindent" id="S6.I3.i2.p1">
        <p class="ltx_p" id="S6.I3.i2.p1.1">
         <span class="ltx_text ltx_font_bold" id="S6.I3.i2.p1.1.1">
          Resource allocation and management
         </span>
         : Dynamic scaling requires the adaptive expansion of computing and storage resources for MAS. In the case of CPDE MAS (Section
         <a class="ltx_ref" href="#S3.SS2.SSS2.Px1" title="Centralized Planning Decentralized Execution (CPDE) ‣ 3.2.2 Planning Type ‣ 3.2 LLM-based Multi-Agent System ‣ 3 LLM-based Agent System Framework ‣ Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects">
          <span class="ltx_text ltx_ref_tag">
           3.2.2
          </span>
         </a>
         ), where a single LLM is responsible for role allocation and action planning, dynamic scaling must consider the LLM’s allocation and planning relative to a varying number of agents and the resource consumption of LLM’s reasoning. For instance,
         <cite class="ltx_cite ltx_citemacro_citet">
          Yue et al. [
          <a class="ltx_ref" href="#bib.bib330" title="">
           330
          </a>
          ]
         </cite>
         explores the construction of LLM cascades to reduce the cost of employing LLMs, particularly in executing reasoning tasks.
        </p>
       </div>
      </li>
     </ul>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S6.SS2.SSS3">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      6.2.3
     </span>
     Security and Trust
    </h4>
    <div class="ltx_para ltx_noindent" id="S6.SS2.SSS3.p1">
     <p class="ltx_p" id="S6.SS2.SSS3.p1.1">
      The allocation of appropriate permissions and the assurance of system security are critical for LLM-based agents
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib331" title="">
        331
       </a>
       ]
      </cite>
      . Given that these agents can exchange information and resources, excessive permissions could lead to incorrect decisions and actions, impacting overall system performance and raising security issues. How can we prevent harmful errors, thus preserving the hard-won trust of humans and enterprises? To address this issue, developing an effective permission allocation mechanism that fosters efficient collaboration among distinct agents without exceeding their designated authority is imperative. Additionally, the importance of conducting reliability tests cannot be overstated. For instance, ToolEmu
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib332" title="">
        332
       </a>
       ]
      </cite>
      utilizes LLM to simulate tool execution, showcasing its ability to evaluate LLM-based agents across various tools and scenarios. This approach enables the detection of agent failures and the quantification of associated risks.
     </p>
    </div>
   </section>
  </section>
 </section>
 <section class="ltx_section" id="S7">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    7
   </span>
   Conclusion
  </h2>
  <div class="ltx_para ltx_noindent" id="S7.p1">
   <p class="ltx_p" id="S7.p1.1">
    This paper comprehensively reviews LLM-based agents’ current research status, applications, and prospects. It begins by tracing the development from agents to RL-based agents and subsequently to LLM-based agents, followed by an introduction to the fundamental concepts of LLM-based agents, including their definition, planning capabilities, memory, rethinking capabilities, action, and external environment. Subsequently, the paper elaborates on the multi-role relationships, planning types, and enhanced communication methods of LLM-based MAS. Additionally, it discusses the potential development prospects and challenges of LLM-based agents in various fields and proposes possible solutions. Lastly, the paper delves into the development trends and challenges LLM-based agents face, such as LLM’s inherent limitations, the dynamic expansion of MAS, and security and trust issues. Although current research is still far from achieving AGI, we believe that LLM-based agents can represent a significant step forward.
   </p>
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Russell and Norvig [2010]
    </span>
    <span class="ltx_bibblock">
     Stuart J Russell and Peter Norvig.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">
      Artificial Intelligence: A Modern Approach (4th Edition)
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     Pearson Education, Inc., 2010.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Stone and Veloso [2000]
    </span>
    <span class="ltx_bibblock">
     Peter Stone and Manuela Veloso.
    </span>
    <span class="ltx_bibblock">
     Multiagent systems: A survey from a machine learning perspective.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">
      Autonomous Robots
     </em>
     , 8:345–383, 2000.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wooldridge [2009]
    </span>
    <span class="ltx_bibblock">
     Michael Wooldridge.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">
      An introduction to multiagent systems
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     John wiley &amp; sons, 2009.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Franklin and Graesser [1996]
    </span>
    <span class="ltx_bibblock">
     Stan Franklin and Art Graesser.
    </span>
    <span class="ltx_bibblock">
     Is it an agent, or just a program?: A taxonomy for autonomous agents.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">
      International workshop on agent theories, architectures, and
languages
     </em>
     , pages 21–35. Springer, 1996.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kaelbling et al. [1996]
    </span>
    <span class="ltx_bibblock">
     Leslie Pack Kaelbling, Michael L Littman, and Andrew W Moore.
    </span>
    <span class="ltx_bibblock">
     Reinforcement learning: A survey.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">
      Journal of artificial intelligence research
     </em>
     , 4:237–285, 1996.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Prentzas and Hatzilygeroudis [2007]
    </span>
    <span class="ltx_bibblock">
     Jim Prentzas and Ioannis Hatzilygeroudis.
    </span>
    <span class="ltx_bibblock">
     Categorizing approaches combining rule-based and case-based
reasoning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">
      Expert Systems
     </em>
     , 24(2):97–122, 2007.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sutton and Barto [2018]
    </span>
    <span class="ltx_bibblock">
     Richard S Sutton and Andrew G Barto.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">
      Reinforcement learning: An introduction
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     MIT press, 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Mnih et al. [2015]
    </span>
    <span class="ltx_bibblock">
     Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A Rusu, Joel Veness,
Marc G Bellemare, Alex Graves, Martin Riedmiller, Andreas K Fidjeland, Georg
Ostrovski, et al.
    </span>
    <span class="ltx_bibblock">
     Human-level control through deep reinforcement learning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">
      nature
     </em>
     , 518(7540):529–533, 2015.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. [2016]
    </span>
    <span class="ltx_bibblock">
     Fei-Yue Wang, Jun Jason Zhang, Xinhu Zheng, Xiao Wang, Yong Yuan, Xiaoxiao Dai,
Jie Zhang, and Liuqing Yang.
    </span>
    <span class="ltx_bibblock">
     Where does alphago go: From church-turing thesis to alphago thesis
and beyond.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">
      IEEE/CAA Journal of Automatica Sinica
     </em>
     , 3(2):113–120, 2016.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kober et al. [2013]
    </span>
    <span class="ltx_bibblock">
     Jens Kober, J Andrew Bagnell, and Jan Peters.
    </span>
    <span class="ltx_bibblock">
     Reinforcement learning in robotics: A survey.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">
      The International Journal of Robotics Research
     </em>
     , 32(11):1238–1274, 2013.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kiran et al. [2021]
    </span>
    <span class="ltx_bibblock">
     B Ravi Kiran, Ibrahim Sobh, Victor Talpaert, Patrick Mannion, Ahmad A
Al Sallab, Senthil Yogamani, and Patrick Pérez.
    </span>
    <span class="ltx_bibblock">
     Deep reinforcement learning for autonomous driving: A survey.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">
      IEEE Transactions on Intelligent Transportation Systems
     </em>
     ,
23(6):4909–4926, 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Nguyen et al. [2020]
    </span>
    <span class="ltx_bibblock">
     Thanh Thi Nguyen, Ngoc Duy Nguyen, and Saeid Nahavandi.
    </span>
    <span class="ltx_bibblock">
     Deep reinforcement learning for multiagent systems: A review of
challenges, solutions, and applications.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">
      IEEE transactions on cybernetics
     </em>
     , 50(9):3826–3839, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     McCallum [1996]
    </span>
    <span class="ltx_bibblock">
     R Andrew McCallum.
    </span>
    <span class="ltx_bibblock">
     Hidden state and reinforcement learning with instance-based state
identification.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">
      IEEE Transactions on Systems, Man, and Cybernetics, Part B
(Cybernetics)
     </em>
     , 26(3):464–473, 1996.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhao et al. [2023a]
    </span>
    <span class="ltx_bibblock">
     Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou,
Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al.
    </span>
    <span class="ltx_bibblock">
     A survey of large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">
      arXiv preprint arXiv:2303.18223
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Bubeck et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric
Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg,
et al.
    </span>
    <span class="ltx_bibblock">
     Sparks of artificial general intelligence: Early experiments with
gpt-4.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">
      arXiv preprint arXiv:2303.12712
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chan et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang Zhang,
Jie Fu, and Zhiyuan Liu.
    </span>
    <span class="ltx_bibblock">
     Chateval: Towards better llm-based evaluators through multi-agent
debate.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">
      arXiv preprint arXiv:2308.07201
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Devlin et al. [2019]
    </span>
    <span class="ltx_bibblock">
     Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
    </span>
    <span class="ltx_bibblock">
     BERT: Pre-training of Deep Bidirectional Transformers for Language
Understanding.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">
      NAACL-HLT (1)
     </em>
     , 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Reed et al. [2022]
    </span>
    <span class="ltx_bibblock">
     Scott Reed, Konrad Zolna, Emilio Parisotto, Sergio Gomez Colmenarejo, Alexander
Novikov, Gabriel Barth-Maron, Mai Gimenez, Yury Sulsky, Jackie Kay,
Jost Tobias Springenberg, et al.
    </span>
    <span class="ltx_bibblock">
     A generalist agent.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">
      arXiv preprint arXiv:2205.06175
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     OpenAI [2023]
    </span>
    <span class="ltx_bibblock">
     OpenAI.
    </span>
    <span class="ltx_bibblock">
     Gpt-4 technical report.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">
      ArXiv
     </em>
     , abs/2303.08774, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sumers et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Theodore Sumers, Shunyu Yao, Karthik Narasimhan, and Thomas L Griffiths.
    </span>
    <span class="ltx_bibblock">
     Cognitive architectures for language agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">
      arXiv preprint arXiv:2309.02427
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Weng [2023]
    </span>
    <span class="ltx_bibblock">
     Lilian Weng.
    </span>
    <span class="ltx_bibblock">
     Llm-powered autonomous agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">
      lilianweng.github.io
     </em>
     , Jun 2023.
    </span>
    <span class="ltx_bibblock">
     URL
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://lilianweng.github.io/posts/2023-06-23-agent/" target="_blank" title="">
      https://lilianweng.github.io/posts/2023-06-23-agent/
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hu et al. [2021]
    </span>
    <span class="ltx_bibblock">
     Junyan Hu, Parijat Bhowmick, Inmo Jang, Farshad Arvin, and Alexander Lanzon.
    </span>
    <span class="ltx_bibblock">
     A decentralized cluster formation containment framework for
multirobot systems.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">
      IEEE Transactions on Robotics
     </em>
     , 37(6):1936–1955, 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Minsky [1988]
    </span>
    <span class="ltx_bibblock">
     Marvin Minsky.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">
      Society of mind
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     Simon and Schuster, 1988.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib24">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhuge et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Mingchen Zhuge, Haozhe Liu, Francesco Faccio, Dylan R Ashley, Róbert
Csordás, Anand Gopalakrishnan, Abdullah Hamdi, Hasan Abed Al Kader
Hammoud, Vincent Herrmann, Kazuki Irie, et al.
    </span>
    <span class="ltx_bibblock">
     Mindstorms in natural language-based societies of mind.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">
      arXiv preprint arXiv:2305.17066
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib25">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Decker [1987]
    </span>
    <span class="ltx_bibblock">
     Keith S Decker.
    </span>
    <span class="ltx_bibblock">
     Distributed problem-solving techniques: A survey.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">
      IEEE transactions on systems, man, and cybernetics
     </em>
     ,
17(5):729–740, 1987.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib26">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Parunak [1996]
    </span>
    <span class="ltx_bibblock">
     H Van Dyke Parunak.
    </span>
    <span class="ltx_bibblock">
     Applications of distributed artificial intelligence in industry.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">
      Foundations of distributed artificial intelligence
     </em>
     , 2(1):18, 1996.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib27">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yang [2021]
    </span>
    <span class="ltx_bibblock">
     Yaodong Yang.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">
      Many-agent reinforcement learning
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     PhD thesis, UCL (University College London), 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib28">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hu et al. [2022]
    </span>
    <span class="ltx_bibblock">
     Siyi Hu, Yifan Zhong, Minquan Gao, Weixun Wang, Hao Dong, Zhihui Li, Xiaodan
Liang, Xiaojun Chang, and Yaodong Yang.
    </span>
    <span class="ltx_bibblock">
     Marllib: Extending rllib for multi-agent reinforcement learning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">
      arXiv preprint arXiv:2210.13708
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib29">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Argyle et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Lisa P Argyle, Ethan C Busby, Nancy Fulda, Joshua R Gubler, Christopher
Rytting, and David Wingate.
    </span>
    <span class="ltx_bibblock">
     Out of one, many: Using language models to simulate human samples.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">
      Political Analysis
     </em>
     , 31(3):337–351, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib30">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Horton [2023]
    </span>
    <span class="ltx_bibblock">
     John J Horton.
    </span>
    <span class="ltx_bibblock">
     Large language models as simulated economic agents: What can we learn
from homo silicus?
    </span>
    <span class="ltx_bibblock">
     Technical report, National Bureau of Economic Research, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib31">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Park et al. [2022]
    </span>
    <span class="ltx_bibblock">
     Joon Sung Park, Lindsay Popowski, Carrie Cai, Meredith Ringel Morris, Percy
Liang, and Michael S Bernstein.
    </span>
    <span class="ltx_bibblock">
     Social simulacra: Creating populated prototypes for social computing
systems.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">
      Proceedings of the 35th Annual ACM Symposium on User
Interface Software and Technology
     </em>
     , pages 1–18, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib32">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kovač et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Grgur Kovač, Rémy Portelas, Peter Ford Dominey, and Pierre-Yves
Oudeyer.
    </span>
    <span class="ltx_bibblock">
     The socialai school: Insights from developmental psychology towards
artificial socio-cultural agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">
      arXiv preprint arXiv:2307.07871
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib33">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gao et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Chen Gao, Xiaochong Lan, Zhihong Lu, Jinzhu Mao, Jinghua Piao, Huandong Wang,
Depeng Jin, and Yong Li.
    </span>
    <span class="ltx_bibblock">
     S3: Social-network simulation system with large language
model-empowered agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">
      arXiv preprint arXiv:2307.14984
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib34">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. [2023a]
    </span>
    <span class="ltx_bibblock">
     Siyu Li, Jin Yang, and Kui Zhao.
    </span>
    <span class="ltx_bibblock">
     Are you in a masquerade? exploring the behavior and impact of large
language model driven social bots in online social networks.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">
      arXiv preprint arXiv:2307.10337
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib35">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. [2023b]
    </span>
    <span class="ltx_bibblock">
     Chao Li, Xing Su, Chao Fan, Haoying Han, Cong Xue, and Chunmo Zheng.
    </span>
    <span class="ltx_bibblock">
     Quantifying the impact of large language models on collective opinion
dynamics.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">
      arXiv preprint arXiv:2308.03313
     </em>
     , 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib36">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Cui et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Jiaxi Cui, Zongjian Li, Yang Yan, Bohua Chen, and Li Yuan.
    </span>
    <span class="ltx_bibblock">
     Chatlaw: Open-source legal large language model with integrated
external knowledge bases.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">
      arXiv preprint arXiv:2306.16092
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib37">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hamilton [2023]
    </span>
    <span class="ltx_bibblock">
     Sil Hamilton.
    </span>
    <span class="ltx_bibblock">
     Blind judgement: Agent-based supreme court modelling with gpt.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">
      arXiv preprint arXiv:2301.05327
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib38">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Bran et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Andres M Bran, Sam Cox, Andrew D White, and Philippe Schwaller.
    </span>
    <span class="ltx_bibblock">
     Chemcrow: Augmenting large-language models with chemistry tools.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">
      arXiv preprint arXiv:2304.05376
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib39">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kang and Kim [2023]
    </span>
    <span class="ltx_bibblock">
     Yeonghun Kang and Jihan Kim.
    </span>
    <span class="ltx_bibblock">
     Chatmof: An autonomous ai system for predicting and generating
metal-organic frameworks.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">
      arXiv preprint arXiv:2308.01423
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib40">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Swan et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Melanie Swan, Takashi Kido, Eric Roland, and Renato P dos Santos.
    </span>
    <span class="ltx_bibblock">
     Math agents: Computational infrastructure, mathematical embedding,
and genomics.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">
      arXiv preprint arXiv:2307.02502
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib41">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Drori et al. [2022]
    </span>
    <span class="ltx_bibblock">
     Iddo Drori, Sarah Zhang, Reece Shuttleworth, Leonard Tang, Albert Lu, Elizabeth
Ke, Kevin Liu, Linda Chen, Sunny Tran, Newman Cheng, et al.
    </span>
    <span class="ltx_bibblock">
     A neural network solves, explains, and generates university math
problems by program synthesis and few-shot learning at human level.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">
      Proceedings of the National Academy of Sciences
     </em>
     , 119(32):e2123433119, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib42">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Mehta et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Nikhil Mehta, Milagro Teruel, Patricio Figueroa Sanz, Xin Deng, Ahmed Hassan
Awadallah, and Julia Kiseleva.
    </span>
    <span class="ltx_bibblock">
     Improving grounded language understanding in a collaborative
environment by interacting with agents through help feedback.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">
      arXiv preprint arXiv:2304.10750
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib43">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [43]
    </span>
    <span class="ltx_bibblock">
     AntonOsika.
    </span>
    <span class="ltx_bibblock">
     GitHub - AntonOsika/gpt-engineer: Specify what you want it
to build, the AI asks for clarification, and then builds it. —
github.com.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/AntonOsika/gpt-engineer" target="_blank" title="">
      https://github.com/AntonOsika/gpt-engineer
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     [Accessed 12-09-2023].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib44">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [44]
    </span>
    <span class="ltx_bibblock">
     smol ai.
    </span>
    <span class="ltx_bibblock">
     GitHub - smol-ai/developer: the first library to let you embed a
developer agent in your own app! — github.com.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/smol-ai/developer" target="_blank" title="">
      https://github.com/smol-ai/developer
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     [Accessed 14-09-2023].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib45">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [45]
    </span>
    <span class="ltx_bibblock">
     melih unsal.
    </span>
    <span class="ltx_bibblock">
     GitHub - melih-unsal/DemoGPT: Create LangChain apps
by just using prompts.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/melih-unsal/DemoGPT" target="_blank" title="">
      https://github.com/melih-unsal/DemoGPT
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     [Accessed 14-09-2023].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib46">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ogundare et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Oluwatosin Ogundare, Srinath Madasu, and Nathanial Wiggins.
    </span>
    <span class="ltx_bibblock">
     Industrial engineering with large language models: A case study of
chatgpt’s performance on oil &amp; gas problems.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">
      arXiv preprint arXiv:2304.14354
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib47">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhou et al. [2023a]
    </span>
    <span class="ltx_bibblock">
     Wei Zhou, Xiangyu Peng, and Mark Riedl.
    </span>
    <span class="ltx_bibblock">
     Dialogue shaping: Empowering agents through npc interaction.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">
      arXiv preprint arXiv:2307.15833
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib48">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Nottingham et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Kolby Nottingham, Prithviraj Ammanabrolu, Alane Suhr, Yejin Choi, Hannaneh
Hajishirzi, Sameer Singh, and Roy Fox.
    </span>
    <span class="ltx_bibblock">
     Do embodied agents dream of pixelated sheep?: Embodied decision
making using language guided world modelling.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">
      arXiv preprint arXiv:2301.12050
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib49">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Song et al. [2022]
    </span>
    <span class="ltx_bibblock">
     Chan Hee Song, Jiaman Wu, Clayton Washington, Brian M Sadler, Wei-Lun Chao, and
Yu Su.
    </span>
    <span class="ltx_bibblock">
     Llm-planner: Few-shot grounded planning for embodied agents with
large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">
      arXiv preprint arXiv:2212.04088
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib50">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. [2023a]
    </span>
    <span class="ltx_bibblock">
     Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu,
Linxi Fan, and Anima Anandkumar.
    </span>
    <span class="ltx_bibblock">
     Voyager: An open-ended embodied agent with large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">
      arXiv preprint arXiv:2305.16291
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib51">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhu et al. [2023a]
    </span>
    <span class="ltx_bibblock">
     Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su, Chenyu Yang, Gao
Huang, Bin Li, Lewei Lu, Xiaogang Wang, et al.
    </span>
    <span class="ltx_bibblock">
     Ghost in the minecraft: Generally capable agents for open-world
enviroments via large language models with text-based knowledge and memory.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">
      arXiv preprint arXiv:2305.17144
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib52">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [52]
    </span>
    <span class="ltx_bibblock">
     Bin Hu, Chenyang Zhao, Pu Zhang, Zihao Zhou, Yuanhang Yang, Zenglin Xu, and Bin
Liu.
    </span>
    <span class="ltx_bibblock">
     Enabling intelligent interactions between an agent and an llm: A
reinforcement learning approach.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib53">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wu et al. [2023a]
    </span>
    <span class="ltx_bibblock">
     Yue Wu, So Yeon Min, Yonatan Bisk, Ruslan Salakhutdinov, Amos Azaria, Yuanzhi
Li, Tom Mitchell, and Shrimai Prabhumoye.
    </span>
    <span class="ltx_bibblock">
     Plan, eliminate, and track–language models are good teachers for
embodied agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">
      arXiv preprint arXiv:2305.02412
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib54">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang et al. [2023a]
    </span>
    <span class="ltx_bibblock">
     Danyang Zhang, Lu Chen, Situo Zhang, Hongshen Xu, Zihan Zhao, and Kai Yu.
    </span>
    <span class="ltx_bibblock">
     Large language model is semi-parametric reinforcement learning agent.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">
      arXiv preprint arXiv:2306.07929
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib55">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Di Palo et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Norman Di Palo, Arunkumar Byravan, Leonard Hasenclever, Markus Wulfmeier,
Nicolas Heess, and Martin Riedmiller.
    </span>
    <span class="ltx_bibblock">
     Towards a unified agent with foundation models.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">
      Workshop on Reincarnating Reinforcement Learning at ICLR
2023
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib56">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ahn et al. [2022]
    </span>
    <span class="ltx_bibblock">
     Michael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron
David, Chelsea Finn, Chuyuan Fu, Keerthana Gopalakrishnan, Karol Hausman,
Alex Herzog, Daniel Ho, Jasmine Hsu, Julian Ibarz, Brian Ichter, Alex Irpan,
Eric Jang, Rosario Jauregui Ruano, Kyle Jeffrey, Sally Jesmonth, Nikhil
Joshi, Ryan Julian, Dmitry Kalashnikov, Yuheng Kuang, Kuang-Huei Lee, Sergey
Levine, Yao Lu, Linda Luu, Carolina Parada, Peter Pastor, Jornell Quiambao,
Kanishka Rao, Jarek Rettinghouse, Diego Reyes, Pierre Sermanet, Nicolas
Sievers, Clayton Tan, Alexander Toshev, Vincent Vanhoucke, Fei Xia, Ted Xiao,
Peng Xu, Sichun Xu, Mengyuan Yan, and Andy Zeng.
    </span>
    <span class="ltx_bibblock">
     Do as i can and not as i say: Grounding language in robotic
affordances.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">
      arXiv preprint arXiv:2204.01691
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib57">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [57]
    </span>
    <span class="ltx_bibblock">
     eumemic.
    </span>
    <span class="ltx_bibblock">
     GitHub - eumemic/ai-legion: An LLM-powered autonomous
agent platform — github.com.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/eumemic/ai-legion" target="_blank" title="">
      https://github.com/eumemic/ai-legion
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     [Accessed 14-09-2023].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib58">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [58]
    </span>
    <span class="ltx_bibblock">
     Josh-XT.
    </span>
    <span class="ltx_bibblock">
     GitHub - Josh-XT/AGiXT: AGiXT is a dynamic
AI Automation Platform that seamlessly orchestrates instruction
management and complex task execution across diverse AI providers.
Combining adaptive memory, smart features, and a versatile plugin system,
AGiXT delivers efficient and comprehensive AI solutions. —
github.com.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/Josh-XT/AGiXT" target="_blank" title="">
      https://github.com/Josh-XT/AGiXT
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     [Accessed 14-09-2023].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib59">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [59]
    </span>
    <span class="ltx_bibblock">
     yoheinakajima.
    </span>
    <span class="ltx_bibblock">
     GitHub - yoheinakajima/babyagi — github.com.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/yoheinakajima/babyagi" target="_blank" title="">
      https://github.com/yoheinakajima/babyagi
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     [Accessed 11-09-2023].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib60">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [60]
    </span>
    <span class="ltx_bibblock">
     farizrahman4u.
    </span>
    <span class="ltx_bibblock">
     GitHub - farizrahman4u/loopgpt: Modular Auto-GPT
Framework — github.com.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/farizrahman4u/loopgpt" target="_blank" title="">
      https://github.com/farizrahman4u/loopgpt
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     [Accessed 14-09-2023].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib61">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [61]
    </span>
    <span class="ltx_bibblock">
     assafelovic.
    </span>
    <span class="ltx_bibblock">
     GitHub - assafelovic/gpt-researcher: GPT based autonomous
agent that does online comprehensive research on any given topic —
github.com.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/assafelovic/gpt-researcher" target="_blank" title="">
      https://github.com/assafelovic/gpt-researcher
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     [Accessed 11-09-2023].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib62">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [62]
    </span>
    <span class="ltx_bibblock">
     TransformerOptimus.
    </span>
    <span class="ltx_bibblock">
     GitHub - TransformerOptimus/SuperAGI:
SuperAGI - A dev-first open source autonomous AI agent
framework. Enabling developers to build, manage and run useful autonomous
agents quickly and reliably. — github.com.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/TransformerOptimus/SuperAGI" target="_blank" title="">
      https://github.com/TransformerOptimus/SuperAGI
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     [Accessed 14-09-2023].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib63">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Park et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Joon Sung Park, Joseph C O’Brien, Carrie J Cai, Meredith Ringel Morris, Percy
Liang, and Michael S Bernstein.
    </span>
    <span class="ltx_bibblock">
     Generative agents: Interactive simulacra of human behavior.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">
      arXiv preprint arXiv:2304.03442
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib64">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Williams et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Ross Williams, Niyousha Hosseinichimeh, Aritra Majumdar, and Navid
Ghaffarzadegan.
    </span>
    <span class="ltx_bibblock">
     Epidemic modeling with generative agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib64.1.1">
      arXiv preprint arXiv:2307.04986
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib65">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Boiko et al. [2023a]
    </span>
    <span class="ltx_bibblock">
     Daniil A Boiko, Robert MacKnight, and Gabe Gomes.
    </span>
    <span class="ltx_bibblock">
     Emergent autonomous scientific research capabilities of large
language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib65.1.1">
      arXiv preprint arXiv:2304.05332
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib66">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Qian et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan
Liu, and Maosong Sun.
    </span>
    <span class="ltx_bibblock">
     Communicative agents for software development.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib66.1.1">
      arXiv preprint arXiv:2307.07924
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib67">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hong et al. [2023a]
    </span>
    <span class="ltx_bibblock">
     Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Ceyao Zhang, Zili Wang,
Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, et al.
    </span>
    <span class="ltx_bibblock">
     Metagpt: Meta programming for multi-agent collaborative framework.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib67.1.1">
      arXiv preprint arXiv:2308.00352
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib68">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Dong et al. [2023a]
    </span>
    <span class="ltx_bibblock">
     Yihong Dong, Xue Jiang, Zhi Jin, and Ge Li.
    </span>
    <span class="ltx_bibblock">
     Self-collaboration code generation via chatgpt.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib68.1.1">
      arXiv preprint arXiv:2304.07590
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib69">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xia et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Yuchen Xia, Manthan Shenoy, Nasser Jazdi, and Michael Weyrich.
    </span>
    <span class="ltx_bibblock">
     Towards autonomous system: flexible modular production system
enhanced with large language model agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib69.1.1">
      arXiv preprint arXiv:2304.14721
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib70">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Dasgupta et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Ishita Dasgupta, Christine Kaeser-Chen, Kenneth Marino, Arun Ahuja, Sheila
Babayan, Felix Hill, and Rob Fergus.
    </span>
    <span class="ltx_bibblock">
     Collaborating with language models for embodied reasoning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib70.1.1">
      arXiv preprint arXiv:2302.00763
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib71">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang et al. [2023b]
    </span>
    <span class="ltx_bibblock">
     Ceyao Zhang, Kaijie Yang, Siyi Hu, Zihao Wang, Guanghe Li, Yihang Sun, Cheng
Zhang, Zhaowei Zhang, Anji Liu, Song-Chun Zhu, et al.
    </span>
    <span class="ltx_bibblock">
     Proagent: Building proactive cooperative ai with large language
models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib71.1.1">
      arXiv preprint arXiv:2308.11339
     </em>
     , 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib72">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. [2023c]
    </span>
    <span class="ltx_bibblock">
     Wenhao Li, Dan Qiao, Baoxiang Wang, Xiangfeng Wang, Bo Jin, and Hongyuan Zha.
    </span>
    <span class="ltx_bibblock">
     Semantically aligned task decomposition in multi-agent reinforcement
learning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib72.1.1">
      arXiv preprint arXiv:2305.10865
     </em>
     , 2023c.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib73">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang et al. [2023c]
    </span>
    <span class="ltx_bibblock">
     Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B
Tenenbaum, Tianmin Shu, and Chuang Gan.
    </span>
    <span class="ltx_bibblock">
     Building cooperative embodied agents modularly with large language
models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib73.1.1">
      arXiv preprint arXiv:2307.02485
     </em>
     , 2023c.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib74">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Qin et al. [2023a]
    </span>
    <span class="ltx_bibblock">
     Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin,
Xin Cong, Xiangru Tang, Bill Qian, et al.
    </span>
    <span class="ltx_bibblock">
     Toolllm: Facilitating large language models to master 16000+
real-world apis.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib74.1.1">
      arXiv preprint arXiv:2307.16789
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib75">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [75]
    </span>
    <span class="ltx_bibblock">
     Significant-Gravitas.
    </span>
    <span class="ltx_bibblock">
     GitHub - Significant-Gravitas/Auto-GPT: An
experimental open-source attempt to make GPT-4 fully autonomous. —
github.com.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/Significant-Gravitas/Auto-GPT" target="_blank" title="">
      https://github.com/Significant-Gravitas/Auto-GPT
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     [Accessed 10-09-2023].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib76">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [76]
    </span>
    <span class="ltx_bibblock">
     xlang ai.
    </span>
    <span class="ltx_bibblock">
     GitHub - xlang-ai/xlang: An open-source framework for building
and evaluating language model agents via executable language grounding —
github.com.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/xlang-ai/xlang" target="_blank" title="">
      https://github.com/xlang-ai/xlang
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     [Accessed 14-09-2023].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib77">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [77]
    </span>
    <span class="ltx_bibblock">
     langchain ai.
    </span>
    <span class="ltx_bibblock">
     GitHub - langchain-ai/langchain: ⚡ Building applications with
LLMs through composability ⚡ — github.com.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/langchain-ai/langchain" target="_blank" title="">
      https://github.com/langchain-ai/langchain
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     [Accessed 17-09-2023].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib78">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Team [2023]
    </span>
    <span class="ltx_bibblock">
     XAgent Team.
    </span>
    <span class="ltx_bibblock">
     Xagent: An autonomous agent for complex task solving, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib79">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xie et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Tianbao Xie, Fan Zhou, Zhoujun Cheng, Peng Shi, Luoxuan Weng, Yitao Liu,
Toh Jing Hua, Junning Zhao, Qian Liu, Che Liu, Leo Z. Liu, Yiheng Xu, Hongjin
Su, Dongchan Shin, Caiming Xiong, and Tao Yu.
    </span>
    <span class="ltx_bibblock">
     Openagents: An open platform for language agents in the wild, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib80">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [80]
    </span>
    <span class="ltx_bibblock">
     team openpm.
    </span>
    <span class="ltx_bibblock">
     GitHub - team-openpm/workgpt: A GPT agent framework for
invoking APIs — github.com.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/team-openpm/workgpt" target="_blank" title="">
      https://github.com/team-openpm/workgpt
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     [Accessed 14-09-2023].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib81">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [81]
    </span>
    <span class="ltx_bibblock">
     reworkd.
    </span>
    <span class="ltx_bibblock">
     GitHub - reworkd/AgentGPT: Assemble, configure, and
deploy autonomous AI Agents in your browser. — github.com.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/reworkd/AgentGPT" target="_blank" title="">
      https://github.com/reworkd/AgentGPT
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     [Accessed 14-09-2023].
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib82">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Crouse et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Maxwell Crouse, Ibrahim Abdelaziz, Kinjal Basu, Soham Dan, Sadhana Kumaravel,
Achille Fokoue, Pavan Kapanipathi, and Luis Lastras.
    </span>
    <span class="ltx_bibblock">
     Formally specifying the high-level behavior of llm-based agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib82.1.1">
      arXiv preprint arXiv:2310.08535
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib83">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wu et al. [2023b]
    </span>
    <span class="ltx_bibblock">
     Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu,
Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang.
    </span>
    <span class="ltx_bibblock">
     Autogen: Enabling next-gen llm applications via multi-agent
conversation framework.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib83.1.1">
      arXiv preprint arXiv:2308.08155
     </em>
     , 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib84">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. [2023a]
    </span>
    <span class="ltx_bibblock">
     Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian,
Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, et al.
    </span>
    <span class="ltx_bibblock">
     Agentverse: Facilitating multi-agent collaboration and exploring
emergent behaviors in agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib84.1.1">
      arXiv preprint arXiv:2308.10848
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib85">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. [2023b]
    </span>
    <span class="ltx_bibblock">
     Guangyao Chen, Siwei Dong, Yu Shu, Ge Zhang, Sesay Jaward, Karlsson Börje, Jie
Fu, and Yemin Shi.
    </span>
    <span class="ltx_bibblock">
     Autoagents: The automatic agents generation framework.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib85.1.1">
      arXiv preprint
     </em>
     , 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib86">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhou et al. [2023b]
    </span>
    <span class="ltx_bibblock">
     Wangchunshu Zhou, Yuchen Eleanor Jiang, Long Li, Jialong Wu, Tiannan Wang, Shi
Qiu, Jintian Zhang, Jing Chen, Ruipu Wu, Shuai Wang, et al.
    </span>
    <span class="ltx_bibblock">
     Agents: An open-source framework for autonomous language agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib86.1.1">
      arXiv preprint arXiv:2309.07870
     </em>
     , 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib87">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Noto and Sato [2000]
    </span>
    <span class="ltx_bibblock">
     Masato Noto and Hiroaki Sato.
    </span>
    <span class="ltx_bibblock">
     A method for the shortest path search by extended dijkstra algorithm.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib87.1.1">
      Smc 2000 conference proceedings. 2000 ieee international
conference on systems, man and cybernetics.’cybernetics evolving to systems,
humans, organizations, and their complex interactions’(cat. no. 0
     </em>
     , volume 3,
pages 2316–2320. IEEE, 2000.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib88">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Cassandra [1998]
    </span>
    <span class="ltx_bibblock">
     Anthony R Cassandra.
    </span>
    <span class="ltx_bibblock">
     A survey of pomdp applications.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib88.1.1">
      Working notes of AAAI 1998 fall symposium on planning with
partially observable Markov decision processes
     </em>
     , volume 1724, 1998.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib89">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wei et al. [2022]
    </span>
    <span class="ltx_bibblock">
     Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and
Denny Zhou.
    </span>
    <span class="ltx_bibblock">
     Chain of thought prompting elicits reasoning in large language
models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib89.1.1">
      arXiv preprint arXiv:2201.11903
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib90">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Fu et al. [2022]
    </span>
    <span class="ltx_bibblock">
     Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and Tushar Khot.
    </span>
    <span class="ltx_bibblock">
     Complexity-based prompting for multi-step reasoning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib90.1.1">
      arXiv preprint arXiv:2210.00720
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib91">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang et al. [2022]
    </span>
    <span class="ltx_bibblock">
     Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex Smola.
    </span>
    <span class="ltx_bibblock">
     Automatic chain of thought prompting in large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib91.1.1">
      arXiv preprint arXiv:2210.03493
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib92">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kojima et al. [2022]
    </span>
    <span class="ltx_bibblock">
     Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke
Iwasawa.
    </span>
    <span class="ltx_bibblock">
     Large language models are zero-shot reasoners.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib92.1.1">
      Advances in Neural Information Processing Systems
     </em>
     ,
35:22199–22213, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib93">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. [2022]
    </span>
    <span class="ltx_bibblock">
     Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou.
    </span>
    <span class="ltx_bibblock">
     Self-consistency improves chain of thought reasoning in language
models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib93.1.1">
      arXiv preprint arXiv:2203.11171
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib94">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yao et al. [2023a]
    </span>
    <span class="ltx_bibblock">
     Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao,
and Karthik Narasimhan.
    </span>
    <span class="ltx_bibblock">
     Tree of thoughts: Deliberate problem solving with large language
models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib94.1.1">
      arXiv preprint arXiv:2305.10601
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib95">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhou et al. [2022]
    </span>
    <span class="ltx_bibblock">
     Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi
Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le, et al.
    </span>
    <span class="ltx_bibblock">
     Least-to-most prompting enables complex reasoning in large language
models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib95.1.1">
      arXiv preprint arXiv:2205.10625
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib96">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ning et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Xuefei Ning, Zinan Lin, Zixuan Zhou, Huazhong Yang, and Yu Wang.
    </span>
    <span class="ltx_bibblock">
     Skeleton-of-thought: Large language models can do parallel decoding.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib96.1.1">
      arXiv preprint arXiv:2307.15337
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib97">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Besta et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi,
Joanna Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski, Piotr
Nyczyk, et al.
    </span>
    <span class="ltx_bibblock">
     Graph of thoughts: Solving elaborate problems with large language
models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib97.1.1">
      arXiv preprint arXiv:2308.09687
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib98">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zheng et al. [2023a]
    </span>
    <span class="ltx_bibblock">
     Chuanyang Zheng, Zhengying Liu, Enze Xie, Zhenguo Li, and Yu Li.
    </span>
    <span class="ltx_bibblock">
     Progressive-hint prompting improves reasoning in large language
models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib98.1.1">
      arXiv preprint arXiv:2304.09797
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib99">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Madaan et al. [2023a]
    </span>
    <span class="ltx_bibblock">
     Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah
Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, et al.
    </span>
    <span class="ltx_bibblock">
     Self-refine: Iterative refinement with self-feedback.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib99.1.1">
      arXiv preprint arXiv:2303.17651
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib100">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. [2023a]
    </span>
    <span class="ltx_bibblock">
     Bo Liu, Yuqian Jiang, Xiaohan Zhang, Qiang Liu, Shiqi Zhang, Joydeep Biswas,
and Peter Stone.
    </span>
    <span class="ltx_bibblock">
     Llm+ p: Empowering large language models with optimal planning
proficiency.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib100.1.1">
      arXiv preprint arXiv:2304.11477
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib101">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Dagan et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Gautier Dagan, Frank Keller, and Alex Lascarides.
    </span>
    <span class="ltx_bibblock">
     Dynamic planning with a llm.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib101.1.1">
      arXiv preprint arXiv:2308.06391
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib102">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hao et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, and
Zhiting Hu.
    </span>
    <span class="ltx_bibblock">
     Reasoning with language model is planning with world model.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib102.1.1">
      arXiv preprint arXiv:2305.14992
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib103">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Romero et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Oscar J Romero, John Zimmerman, Aaron Steinfeld, and Anthony Tomasic.
    </span>
    <span class="ltx_bibblock">
     Synergistic integration of large language models and cognitive
architectures for robust ai: An exploratory analysis.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib103.1.1">
      arXiv preprint arXiv:2308.09830
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib104">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Merkle and Mikut [2023]
    </span>
    <span class="ltx_bibblock">
     Nicole Merkle and Ralf Mikut.
    </span>
    <span class="ltx_bibblock">
     Context-aware composition of agent policies by markov decision
process entity embeddings and agent ensembles.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib104.1.1">
      arXiv preprint arXiv:2308.14521
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib105">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lin et al. [2023a]
    </span>
    <span class="ltx_bibblock">
     Bill Yuchen Lin, Yicheng Fu, Karina Yang, Prithviraj Ammanabrolu, Faeze
Brahman, Shiyu Huang, Chandra Bhagavatula, Yejin Choi, and Xiang Ren.
    </span>
    <span class="ltx_bibblock">
     Swiftsage: A generative agent with fast and slow thinking for complex
interactive tasks.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib105.1.1">
      arXiv preprint arXiv:2305.17390
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib106">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Dong et al. [2022]
    </span>
    <span class="ltx_bibblock">
     Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun,
Jingjing Xu, and Zhifang Sui.
    </span>
    <span class="ltx_bibblock">
     A survey for in-context learning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib106.1.1">
      arXiv preprint arXiv:2301.00234
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib107">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Madaan et al. [2023b]
    </span>
    <span class="ltx_bibblock">
     Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah
Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, et al.
    </span>
    <span class="ltx_bibblock">
     Self-refine: Iterative refinement with self-feedback.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib107.1.1">
      arXiv preprint arXiv:2303.17651
     </em>
     , 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib108">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Aeronautiques et al. [1998]
    </span>
    <span class="ltx_bibblock">
     Constructions Aeronautiques, Adele Howe, Craig Knoblock, ISI Drew McDermott,
Ashwin Ram, Manuela Veloso, Daniel Weld, David Wilkins SRI, Anthony Barrett,
Dave Christianson, et al.
    </span>
    <span class="ltx_bibblock">
     Pddl| the planning domain definition language.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib108.1.1">
      Technical Report, Tech. Rep.
     </em>
     , 1998.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib109">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Guan et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Lin Guan, Karthik Valmeekam, Sarath Sreedharan, and Subbarao Kambhampati.
    </span>
    <span class="ltx_bibblock">
     Leveraging pre-trained large language models to construct and utilize
world models for model-based task planning, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib110">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhao et al. [2023b]
    </span>
    <span class="ltx_bibblock">
     Zirui Zhao, Wee Sun Lee, and David Hsu.
    </span>
    <span class="ltx_bibblock">
     Large language models as commonsense knowledge for large-scale task
planning, 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib111">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhou et al. [2023c]
    </span>
    <span class="ltx_bibblock">
     Pei Zhou, Aman Madaan, Srividya Pranavi Potharaju, Aditya Gupta, Kevin R.
McKee, Ari Holtzman, Jay Pujara, Xiang Ren, Swaroop Mishra, Aida Nematzadeh,
Shyam Upadhyay, and Manaal Faruqui.
    </span>
    <span class="ltx_bibblock">
     How far are large language models from agents with theory-of-mind?,
2023c.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib112">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Premack and Woodruff [1978]
    </span>
    <span class="ltx_bibblock">
     David Premack and Guy Woodruff.
    </span>
    <span class="ltx_bibblock">
     Does the chimpanzee have a theory of mind?
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib112.1.1">
      Behavioral and brain sciences
     </em>
     , 1(4):515–526, 1978.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib113">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhou et al. [2023d]
    </span>
    <span class="ltx_bibblock">
     Andy Zhou, Kai Yan, Michal Shlapentokh-Rothman, Haohan Wang, and Yu-Xiong Wang.
    </span>
    <span class="ltx_bibblock">
     Language agent tree search unifies reasoning acting and planning in
language models, 2023d.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib114">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sun et al. [2023a]
    </span>
    <span class="ltx_bibblock">
     Jiashuo Sun, Chengjin Xu, Lumingyuan Tang, Saizhuo Wang, Chen Lin, Yeyun Gong,
Lionel M. Ni, Heung-Yeung Shum, and Jian Guo.
    </span>
    <span class="ltx_bibblock">
     Think-on-graph: Deep and responsible reasoning of large language
model on knowledge graph, 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib115">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. [2017]
    </span>
    <span class="ltx_bibblock">
     Quan Wang, Zhendong Mao, Bin Wang, and Li Guo.
    </span>
    <span class="ltx_bibblock">
     Knowledge graph embedding: A survey of approaches and applications.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib115.1.1">
      IEEE Transactions on Knowledge and Data Engineering
     </em>
     ,
29(12):2724–2743, 2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib116">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Singla et al. [2021]
    </span>
    <span class="ltx_bibblock">
     Samriddhi Singla, Ahmed Eldawy, Tina Diao, Ayan Mukhopadhyay, and Elia
Scudiero.
    </span>
    <span class="ltx_bibblock">
     Experimental study of big raster and vector database systems.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib116.1.1">
      2021 IEEE 37th International Conference on Data Engineering
(ICDE)
     </em>
     , pages 2243–2248. IEEE, 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib117">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhao et al. [2023c]
    </span>
    <span class="ltx_bibblock">
     Andrew Zhao, Daniel Huang, Quentin Xu, Matthieu Lin, Yong-Jin Liu, and Gao
Huang.
    </span>
    <span class="ltx_bibblock">
     Expel: Llm agents are experiential learners.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib117.1.1">
      arXiv preprint arXiv:2308.10144
     </em>
     , 2023c.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib118">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shinn et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Noah Shinn, Federico Cassano, Beck Labash, Ashwin Gopinath, Karthik Narasimhan,
and Shunyu Yao.
    </span>
    <span class="ltx_bibblock">
     Reflexion: Language agents with verbal reinforcement learning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib118.1.1">
      arXiv preprint arXiv:2303.11366
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib119">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Packer et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Charles Packer, Vivian Fang, Shishir G. Patil, Kevin Lin, Sarah Wooders, and
Joseph E. Gonzalez.
    </span>
    <span class="ltx_bibblock">
     Memgpt: Towards llms as operating systems, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib120">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lewis et al. [2020]
    </span>
    <span class="ltx_bibblock">
     Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir
Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim
Rocktäschel, et al.
    </span>
    <span class="ltx_bibblock">
     Retrieval-augmented generation for knowledge-intensive NLP tasks.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib120.1.1">
      Advances in Neural Information Processing Systems
     </em>
     ,
33:9459–9474, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib121">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Karimpanal et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Thommen George Karimpanal, Laknath Buddhika Semage, Santu Rana, Hung Le, Truyen
Tran, Sunil Gupta, and Svetha Venkatesh.
    </span>
    <span class="ltx_bibblock">
     Lagr-seq: Language-guided reinforcement learning with
sample-efficient querying.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib121.1.1">
      arXiv preprint arXiv:2308.13542
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib122">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zheng et al. [2023b]
    </span>
    <span class="ltx_bibblock">
     Longtao Zheng, Rundong Wang, Xinrun Wang, and Bo An.
    </span>
    <span class="ltx_bibblock">
     Synapse: Trajectory-as-exemplar prompting with memory for computer
control, 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib123">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kang et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Jikun Kang, Romain Laroche, Xindi Yuan, Adam Trischler, Xue Liu, and Jie Fu.
    </span>
    <span class="ltx_bibblock">
     Think before you act: Decision transformers with internal working
memory, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib124">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. [2023b]
    </span>
    <span class="ltx_bibblock">
     Zihao Wang, Shaofei Cai, Anji Liu, Yonggang Jin, Jinbing Hou, Bowei Zhang,
Haowei Lin, Zhaofeng He, Zilong Zheng, Yaodong Yang, Xiaojian Ma, and Yitao
Liang.
    </span>
    <span class="ltx_bibblock">
     Jarvis-1: Open-world multi-task agents with memory-augmented
multimodal language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib124.1.1">
      arXiv preprint arXiv: 2311.05997
     </em>
     , 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib125">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yao et al. [2022a]
    </span>
    <span class="ltx_bibblock">
     Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan,
and Yuan Cao.
    </span>
    <span class="ltx_bibblock">
     React: Synergizing reasoning and acting in language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib125.1.1">
      arXiv preprint arXiv:2210.03629
     </em>
     , 2022a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib126">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. [2023b]
    </span>
    <span class="ltx_bibblock">
     Hao Liu, Carmelo Sferrazza, and Pieter Abbeel.
    </span>
    <span class="ltx_bibblock">
     Chain of hindsight aligns language models with feedback,
2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib127">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lightman et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Hunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy
Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe.
    </span>
    <span class="ltx_bibblock">
     Let’s verify step by step.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib127.1.1">
      arXiv preprint arXiv:2305.20050
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib128">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. [2023c]
    </span>
    <span class="ltx_bibblock">
     Liting Chen, Lu Wang, Hang Dong, Yali Du, Jie Yan, Fangkai Yang, Shuang Li,
Pu Zhao, Si Qin, Saravan Rajmohan, et al.
    </span>
    <span class="ltx_bibblock">
     Introspective tips: Large language model for in-context decision
making.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib128.1.1">
      arXiv preprint arXiv:2305.11598
     </em>
     , 2023c.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib129">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhou et al. [2023e]
    </span>
    <span class="ltx_bibblock">
     Aojun Zhou, Ke Wang, Zimu Lu, Weikang Shi, Sichun Luo, Zipeng Qin, Shaoqing Lu,
Anya Jia, Linqi Song, Mingjie Zhan, et al.
    </span>
    <span class="ltx_bibblock">
     Solving challenging math word problems using gpt-4 code interpreter
with code-based self-verification.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib129.1.1">
      arXiv preprint arXiv:2308.07921
     </em>
     , 2023e.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib130">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yao et al. [2023b]
    </span>
    <span class="ltx_bibblock">
     Weiran Yao, Shelby Heinecke, Juan Carlos Niebles, Zhiwei Liu, Yihao Feng,
Le Xue, Rithesh Murthy, Zeyuan Chen, Jianguo Zhang, Devansh Arpit, et al.
    </span>
    <span class="ltx_bibblock">
     Retroformer: Retrospective large language agents with policy gradient
optimization.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib130.1.1">
      arXiv preprint arXiv:2308.02151
     </em>
     , 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib131">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Murthy et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Rithesh Murthy, Shelby Heinecke, Juan Carlos Niebles, Zhiwei Liu, Le Xue,
Weiran Yao, Yihao Feng, Zeyuan Chen, Akash Gokul, Devansh Arpit, et al.
    </span>
    <span class="ltx_bibblock">
     Rex: Rapid exploration and exploitation for ai agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib131.1.1">
      arXiv preprint arXiv:2307.08962
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib132">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Brooks et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Ethan Brooks, Logan Walls, Richard L. Lewis, and Satinder Singh.
    </span>
    <span class="ltx_bibblock">
     Large language models can implement policy iteration, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib133">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. [2022]
    </span>
    <span class="ltx_bibblock">
     Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, Jian-Guang Lou, and
Weizhu Chen.
    </span>
    <span class="ltx_bibblock">
     On the advance of making language models better reasoners.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib133.1.1">
      arXiv preprint arXiv:2206.02336
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib134">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. [2023c]
    </span>
    <span class="ltx_bibblock">
     Zihao Wang, Shaofei Cai, Anji Liu, Xiaojian Ma, and Yitao Liang.
    </span>
    <span class="ltx_bibblock">
     Describe, explain, plan and select: Interactive planning with large
language models enables open-world multi-task agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib134.1.1">
      arXiv preprint arXiv:2302.01560
     </em>
     , 2023c.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib135">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. [2023c]
    </span>
    <span class="ltx_bibblock">
     Zhihan Liu, Hao Hu, Shenao Zhang, Hongyi Guo, Shuqi Ke, Boyi Liu, and Zhaoran
Wang.
    </span>
    <span class="ltx_bibblock">
     Reason for future, act for now: A principled framework for autonomous
llm agents with provable sample efficiency, 2023c.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib136">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. [2023d]
    </span>
    <span class="ltx_bibblock">
     Kuan Wang, Yadong Lu, Michael Santacroce, Yeyun Gong, Chao Zhang, and Yelong
Shen.
    </span>
    <span class="ltx_bibblock">
     Adapting llm agents through communication, 2023d.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib137">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Schulman et al. [2017]
    </span>
    <span class="ltx_bibblock">
     John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
    </span>
    <span class="ltx_bibblock">
     Proximal policy optimization algorithms, 2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib138">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kim et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Geunwoo Kim, Pierre Baldi, and Stephen McAleer.
    </span>
    <span class="ltx_bibblock">
     Language models can solve computer tasks.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib138.1.1">
      arXiv preprint arXiv:2303.17491
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib139">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhou et al. [2023f]
    </span>
    <span class="ltx_bibblock">
     Shuyan Zhou, Frank F Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar,
Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, et al.
    </span>
    <span class="ltx_bibblock">
     WebArena: A Realistic Web Environment for Building Autonomous
Agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib139.1.1">
      arXiv preprint arXiv:2307.13854
     </em>
     , 2023f.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib140">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Nakano et al. [2021]
    </span>
    <span class="ltx_bibblock">
     Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina
Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders,
et al.
    </span>
    <span class="ltx_bibblock">
     WebGPT: Browser-Assisted Question-Answering with Human Feedback.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib140.1.1">
      arXiv preprint arXiv:2112.09332
     </em>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib141">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang et al. [2023d]
    </span>
    <span class="ltx_bibblock">
     Danyang Zhang, Lu Chen, Zihan Zhao, Ruisheng Cao, and Kai Yu.
    </span>
    <span class="ltx_bibblock">
     Mobile-env: An evaluation platform and benchmark for interactive
agents in llm era, 2023d.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib142">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. [2023d]
    </span>
    <span class="ltx_bibblock">
     Hongxin Li, Jingran Su, Yuntao Chen, Qing Li, and Zhaoxiang Zhang.
    </span>
    <span class="ltx_bibblock">
     Sheetcopilot: Bringing software productivity to the next level
through large language models, 2023d.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib143">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lin et al. [2023b]
    </span>
    <span class="ltx_bibblock">
     Jiaju Lin, Haoran Zhao, Aochi Zhang, Yiting Wu, Huqiuyue Ping, and Qin Chen.
    </span>
    <span class="ltx_bibblock">
     Agentsims: An open-source sandbox for large language model
evaluation.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib143.1.1">
      arXiv preprint arXiv:2308.04026
     </em>
     , 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib144">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Abdelnabi et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Sahar Abdelnabi, Amr Gomaa, Sarath Sivaprasad, Lea Schönherr, and Mario Fritz.
    </span>
    <span class="ltx_bibblock">
     Llm-deliberation: Evaluating llms with interactive multi-agent
negotiation games, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib145">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. [2023e]
    </span>
    <span class="ltx_bibblock">
     Haonan Li, Yu Hao, Yizhuo Zhai, and Zhiyun Qian.
    </span>
    <span class="ltx_bibblock">
     The hitchhiker’s guide to program analysis: A journey with large
language models, 2023e.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib146">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wu et al. [2023c]
    </span>
    <span class="ltx_bibblock">
     Zhenyu Wu, Ziwei Wang, Xiuwei Xu, Jiwen Lu, and Haibin Yan.
    </span>
    <span class="ltx_bibblock">
     Embodied task planning with large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib146.1.1">
      arXiv preprint arXiv:2307.01848
     </em>
     , 2023c.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib147">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shi et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Hangjie Shi, Leslie Ball, Govind Thattai, Desheng Zhang, Lucy Hu, Qiaozi Gao,
Suhaila Shakiah, Xiaofeng Gao, Aishwarya Padmakumar, Bofei Yang, et al.
    </span>
    <span class="ltx_bibblock">
     Alexa, play with robot: Introducing the first alexa prize simbot
challenge on embodied ai.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib147.1.1">
      arXiv preprint arXiv:2308.05221
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib148">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zheng et al. [2023c]
    </span>
    <span class="ltx_bibblock">
     Qingxiao Zheng, Zhongwei Xu, Abhinav Choudhary, Yuting Chen, Yongming Li, and
Yun Huang.
    </span>
    <span class="ltx_bibblock">
     Synergizing human-ai agency: A guide of 23 heuristics for service
co-creation with llm-based agents, 2023c.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib149">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang et al. [2023e]
    </span>
    <span class="ltx_bibblock">
     Siyao Zhang, Daocheng Fu, Zhao Zhang, Bin Yu, and Pinlong Cai.
    </span>
    <span class="ltx_bibblock">
     Trafficgpt: Viewing, processing and interacting with traffic
foundation models, 2023e.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib150">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lopez et al. [2018]
    </span>
    <span class="ltx_bibblock">
     Pablo Alvarez Lopez, Michael Behrisch, Laura Bieker-Walz, Jakob Erdmann,
Yun-Pang Flötteröd, Robert Hilbrich, Leonhard Lücken, Johannes
Rummel, Peter Wagner, and Evamarie Wießner.
    </span>
    <span class="ltx_bibblock">
     Microscopic traffic simulation using sumo.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib150.1.1">
      2018 21st international conference on intelligent
transportation systems (ITSC)
     </em>
     , pages 2575–2582. IEEE, 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib151">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. [2023d]
    </span>
    <span class="ltx_bibblock">
     Jiangjie Chen, Siyu Yuan, Rong Ye, Bodhisattwa Prasad Majumder, and Kyle
Richardson.
    </span>
    <span class="ltx_bibblock">
     Put your money where your mouth is: Evaluating strategic planning and
execution of llm agents in an auction arena, 2023d.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib152">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Karpas et al. [2022]
    </span>
    <span class="ltx_bibblock">
     Ehud Karpas, Omri Abend, Yonatan Belinkov, Barak Lenz, Opher Lieber, Nir
Ratner, Yoav Shoham, Hofit Bata, Yoav Levine, Kevin Leyton-Brown, et al.
    </span>
    <span class="ltx_bibblock">
     Mrkl systems: A modular, neuro-symbolic architecture that combines
large language models, external knowledge sources and discrete reasoning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib152.1.1">
      arXiv preprint arXiv:2205.00445
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib153">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Parisi et al. [2022]
    </span>
    <span class="ltx_bibblock">
     Aaron Parisi, Yao Zhao, and Noah Fiedel.
    </span>
    <span class="ltx_bibblock">
     Talm: Tool augmented language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib153.1.1">
      arXiv preprint arXiv:2205.12255
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib154">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Schick et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria
Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom.
    </span>
    <span class="ltx_bibblock">
     Toolformer: Language models can teach themselves to use tools.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib154.1.1">
      arXiv preprint arXiv:2302.04761
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib155">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shen et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting
Zhuang.
    </span>
    <span class="ltx_bibblock">
     Hugginggpt: Solving ai tasks with chatgpt and its friends in
huggingface.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib155.1.1">
      arXiv preprint arXiv:2303.17580
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib156">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lu et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang, Ying Nian Wu,
Song-Chun Zhu, and Jianfeng Gao.
    </span>
    <span class="ltx_bibblock">
     Chameleon: Plug-and-play compositional reasoning with large language
models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib156.1.1">
      arXiv preprint arXiv:2304.09842
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib157">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Patil et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Shishir G. Patil, Tianjun Zhang, Xin Wang, and Joseph E. Gonzalez.
    </span>
    <span class="ltx_bibblock">
     Gorilla: Large language model connected with massive apis, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib158">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Song et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Yifan Song, Weimin Xiong, Dawei Zhu, Cheng Li, Ke Wang, Ye Tian, and Sujian Li.
    </span>
    <span class="ltx_bibblock">
     Restgpt: Connecting large language models with real-world
applications via restful apis.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib158.1.1">
      arXiv preprint arXiv:2306.06624
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib159">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhou et al. [2023g]
    </span>
    <span class="ltx_bibblock">
     Xuanhe Zhou, Guoliang Li, and Zhiyuan Liu.
    </span>
    <span class="ltx_bibblock">
     Llm as dba.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib159.1.1">
      arXiv preprint arXiv:2308.05481
     </em>
     , 2023g.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib160">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hu et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Ziniu Hu, Ahmet Iscen, Chen Sun, Kai-Wei Chang, Yizhou Sun, David A Ross,
Cordelia Schmid, and Alireza Fathi.
    </span>
    <span class="ltx_bibblock">
     Avis: Autonomous visual information seeking with large language model
agent, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib161">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. [2023e]
    </span>
    <span class="ltx_bibblock">
     Zhipeng Chen, Kun Zhou, Beichen Zhang, Zheng Gong, Wayne Xin Zhao, and Ji-Rong
Wen.
    </span>
    <span class="ltx_bibblock">
     Chatcot: Tool-augmented chain-of-thought reasoning on chat-based
large language models, 2023e.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib162">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ruan et al. [2023a]
    </span>
    <span class="ltx_bibblock">
     Jingqing Ruan, Yihong Chen, Bin Zhang, Zhiwei Xu, Tianpeng Bao, Guoqing Du,
Shiwei Shi, Hangyu Mao, Xingyu Zeng, and Rui Zhao.
    </span>
    <span class="ltx_bibblock">
     Tptu: Task planning and tool usage of large language model-based ai
agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib162.1.1">
      arXiv preprint arXiv:2308.03427
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib163">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xu et al. [2023a]
    </span>
    <span class="ltx_bibblock">
     Binfeng Xu, Xukun Liu, Hua Shen, Zeyu Han, Yuhan Li, Murong Yue, Zhiyuan Peng,
Yuchen Liu, Ziyu Yao, and Dongkuan Xu.
    </span>
    <span class="ltx_bibblock">
     Gentopia: A collaborative platform for tool-augmented llms.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib163.1.1">
      arXiv preprint arXiv:2308.04030
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib164">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Cai et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, and Denny Zhou.
    </span>
    <span class="ltx_bibblock">
     Large language models as tool makers.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib164.1.1">
      arXiv preprint arXiv:2305.17126
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib165">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yuan et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Lifan Yuan, Yangyi Chen, Xingyao Wang, Yi R. Fung, Hao Peng, and Heng Ji.
    </span>
    <span class="ltx_bibblock">
     Craft: Customizing llms by creating and retrieving from specialized
toolsets, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib166">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liang et al. [2023a]
    </span>
    <span class="ltx_bibblock">
     Yaobo Liang, Chenfei Wu, Ting Song, Wenshan Wu, Yan Xia, Yu Liu, Yang Ou, Shuai
Lu, Lei Ji, Shaoguang Mao, Yun Wang, Linjun Shou, Ming Gong, and Nan Duan.
    </span>
    <span class="ltx_bibblock">
     Taskmatrix.ai: Completing tasks by connecting foundation models with
millions of apis, 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib167">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. [2023d]
    </span>
    <span class="ltx_bibblock">
     Zhiwei Liu, Weiran Yao, Jianguo Zhang, Le Xue, Shelby Heinecke, Rithesh Murthy,
Yihao Feng, Zeyuan Chen, Juan Carlos Niebles, Devansh Arpit, et al.
    </span>
    <span class="ltx_bibblock">
     Bolaa: Benchmarking and orchestrating llm-augmented autonomous
agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib167.1.1">
      arXiv preprint arXiv:2308.05960
     </em>
     , 2023d.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib168">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Jinxin et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Shi Jinxin, Zhao Jiabao, Wang Yilei, Wu Xingjiao, Li Jiawen, and He Liang.
    </span>
    <span class="ltx_bibblock">
     Cgmi: Configurable general multi-agent interaction framework.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib168.1.1">
      arXiv preprint arXiv:2308.12503
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib169">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liang et al. [2023b]
    </span>
    <span class="ltx_bibblock">
     Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu
Yang, Zhaopeng Tu, and Shuming Shi.
    </span>
    <span class="ltx_bibblock">
     Encouraging divergent thinking in large language models through
multi-agent debate.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib169.1.1">
      arXiv preprint arXiv:2305.19118
     </em>
     , 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib170">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xu et al. [2023b]
    </span>
    <span class="ltx_bibblock">
     Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xiaolong Wang, Weidong Liu, and
Yang Liu.
    </span>
    <span class="ltx_bibblock">
     Exploring large language models for communication games: An empirical
study on werewolf.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib170.1.1">
      arXiv preprint arXiv:2309.04658
     </em>
     , 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib171">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Light et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Jonathan Light, Min Cai, Sheng Shen, and Ziniu Hu.
    </span>
    <span class="ltx_bibblock">
     From text to tactic: Evaluating llms playing the game of avalon,
2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib172">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. [2023e]
    </span>
    <span class="ltx_bibblock">
     Zhenhailong Wang, Shaoguang Mao, Wenshan Wu, Tao Ge, Furu Wei, and Heng Ji.
    </span>
    <span class="ltx_bibblock">
     Unleashing cognitive synergy in large language models: A task-solving
agent through multi-persona self-collaboration.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib172.1.1">
      arXiv preprint arXiv:2307.05300
     </em>
     , 2023e.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib173">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. [2023f]
    </span>
    <span class="ltx_bibblock">
     Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and
Bernard Ghanem.
    </span>
    <span class="ltx_bibblock">
     Camel: Communicative agents for" mind" exploration of large scale
language model society.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib173.1.1">
      arXiv preprint arXiv:2303.17760
     </em>
     , 2023f.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib174">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zou et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Hang Zou, Qiyang Zhao, Lina Bariah, Mehdi Bennis, and Merouane Debbah.
    </span>
    <span class="ltx_bibblock">
     Wireless multi-agent generative ai: From connected intelligence to
collective intelligence.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib174.1.1">
      arXiv preprint arXiv:2307.02757
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib175">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Mandi et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Zhao Mandi, Shreeya Jain, and Shuran Song.
    </span>
    <span class="ltx_bibblock">
     Roco: Dialectic multi-robot collaboration with large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib175.1.1">
      arXiv preprint arXiv:2307.04738
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib176">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen and Chang [2023]
    </span>
    <span class="ltx_bibblock">
     Po-Lin Chen and Cheng-Shang Chang.
    </span>
    <span class="ltx_bibblock">
     Interact: Exploring the potentials of chatgpt as a cooperative agent,
2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib177">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shridhar et al. [2020]
    </span>
    <span class="ltx_bibblock">
     Mohit Shridhar, Xingdi Yuan, Marc-Alexandre Côté, Yonatan Bisk, Adam
Trischler, and Matthew Hausknecht.
    </span>
    <span class="ltx_bibblock">
     Alfworld: Aligning text and embodied environments for interactive
learning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib177.1.1">
      arXiv preprint arXiv:2010.03768
     </em>
     , 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib178">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. [2023e]
    </span>
    <span class="ltx_bibblock">
     Zijun Liu, Yanzhe Zhang, Peng Li, Yang Liu, and Diyi Yang.
    </span>
    <span class="ltx_bibblock">
     Dynamic llm-agent network: An llm-agent collaboration framework with
agent team optimization, 2023e.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib179">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sun et al. [2023b]
    </span>
    <span class="ltx_bibblock">
     Qiushi Sun, Zhangyue Yin, Xiang Li, Zhiyong Wu, Xipeng Qiu, and Lingpeng Kong.
    </span>
    <span class="ltx_bibblock">
     Corex: Pushing the boundaries of complex reasoning through
multi-model collaboration, 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib180">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lowe et al. [2017]
    </span>
    <span class="ltx_bibblock">
     Ryan Lowe, Yi I Wu, Aviv Tamar, Jean Harb, OpenAI Pieter Abbeel, and Igor
Mordatch.
    </span>
    <span class="ltx_bibblock">
     Multi-agent actor-critic for mixed cooperative-competitive
environments.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib180.1.1">
      Advances in neural information processing systems
     </em>
     , 30, 2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib181">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gong et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Ran Gong, Qiuyuan Huang, Xiaojian Ma, Hoi Vo, Zane Durante, Yusuke Noda, Zilong
Zheng, Song-Chun Zhu, Demetri Terzopoulos, Li Fei-Fei, et al.
    </span>
    <span class="ltx_bibblock">
     Mindagent: Emergent gaming interaction.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib181.1.1">
      arXiv preprint arXiv:2309.09971
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib182">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Carroll et al. [2019]
    </span>
    <span class="ltx_bibblock">
     Micah Carroll, Rohin Shah, Mark K Ho, Tom Griffiths, Sanjit Seshia, Pieter
Abbeel, and Anca Dragan.
    </span>
    <span class="ltx_bibblock">
     On the utility of learning about humans for human-ai coordination.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib182.1.1">
      Advances in neural information processing systems
     </em>
     , 32, 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib183">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hu et al. [2019]
    </span>
    <span class="ltx_bibblock">
     Hengyuan Hu, Denis Yarats, Qucheng Gong, Yuandong Tian, and Mike Lewis.
    </span>
    <span class="ltx_bibblock">
     Hierarchical decision making by generating and following natural
language instructions.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib183.1.1">
      Advances in neural information processing systems
     </em>
     , 32, 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib184">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Searle [1969]
    </span>
    <span class="ltx_bibblock">
     John R Searle.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib184.1.1">
      Speech acts: An essay in the philosophy of language
     </em>
     , volume
626.
    </span>
    <span class="ltx_bibblock">
     Cambridge university press, 1969.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib185">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Finin et al. [1994]
    </span>
    <span class="ltx_bibblock">
     Tim Finin, Richard Fritzson, Don McKay, and Robin McEntire.
    </span>
    <span class="ltx_bibblock">
     Kqml as an agent communication language.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib185.1.1">
      Proceedings of the third international conference on
Information and knowledge management
     </em>
     , pages 456–463, 1994.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib186">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Pham et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Chau Pham, Boyi Liu, Yingxiang Yang, Zhengyu Chen, Tianyi Liu, Jianbo Yuan,
Bryan A Plummer, Zhaoran Wang, and Hongxia Yang.
    </span>
    <span class="ltx_bibblock">
     Let models speak ciphers: Multiagent debate through embeddings.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib186.1.1">
      arXiv preprint arXiv:2310.06272
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib187">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wei et al. [2023a]
    </span>
    <span class="ltx_bibblock">
     Jerry Wei, Da Huang, Yifeng Lu, Denny Zhou, and Quoc V Le.
    </span>
    <span class="ltx_bibblock">
     Simple synthetic data reduces sycophancy in large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib187.1.1">
      arXiv preprint arXiv:2308.03958
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib188">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Rawte et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Vipula Rawte, Amit Sheth, and Amitava Das.
    </span>
    <span class="ltx_bibblock">
     A survey of hallucination in large foundation models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib188.1.1">
      arXiv preprint arXiv:2309.05922
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib189">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Dhuliawala et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu, Roberta Raileanu, Xian Li, Asli
Celikyilmaz, and Jason Weston.
    </span>
    <span class="ltx_bibblock">
     Chain-of-verification reduces hallucination in large language models,
2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib190">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yang et al. [2018]
    </span>
    <span class="ltx_bibblock">
     Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W Cohen, Ruslan
Salakhutdinov, and Christopher D Manning.
    </span>
    <span class="ltx_bibblock">
     Hotpotqa: A dataset for diverse, explainable multi-hop question
answering.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib190.1.1">
      arXiv preprint arXiv:1809.09600
     </em>
     , 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib191">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hendrycks et al. [2021]
    </span>
    <span class="ltx_bibblock">
     Dan Hendrycks, Steven Basart, Saurav Kadavath, Mantas Mazeika, Akul Arora,
Ethan Guo, Collin Burns, Samir Puranik, Horace He, Dawn Song, et al.
    </span>
    <span class="ltx_bibblock">
     Measuring coding challenge competence with apps.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib191.1.1">
      arXiv preprint arXiv:2105.09938
     </em>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib192">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Austin et al. [2021]
    </span>
    <span class="ltx_bibblock">
     Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski,
David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, et al.
    </span>
    <span class="ltx_bibblock">
     Program synthesis with large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib192.1.1">
      arXiv preprint arXiv:2108.07732
     </em>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib193">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. [2021]
    </span>
    <span class="ltx_bibblock">
     Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira
Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg
Brockman, et al.
    </span>
    <span class="ltx_bibblock">
     Evaluating large language models trained on code.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib193.1.1">
      arXiv preprint arXiv:2107.03374
     </em>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib194">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yao et al. [2022b]
    </span>
    <span class="ltx_bibblock">
     Shunyu Yao, Howard Chen, John Yang, and Karthik Narasimhan.
    </span>
    <span class="ltx_bibblock">
     Webshop: Towards scalable real-world web interaction with grounded
language agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib194.1.1">
      Advances in Neural Information Processing Systems
     </em>
     ,
35:20744–20757, 2022b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib195">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Thorne et al. [2018]
    </span>
    <span class="ltx_bibblock">
     James Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal.
    </span>
    <span class="ltx_bibblock">
     Fever: a large-scale dataset for fact extraction and verification.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib195.1.1">
      arXiv preprint arXiv:1803.05355
     </em>
     , 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib196">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Qin et al. [2023b]
    </span>
    <span class="ltx_bibblock">
     Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu Cui, Zheni
Zeng, Yufei Huang, Chaojun Xiao, Chi Han, Yi Ren Fung, Yusheng Su, Huadong
Wang, Cheng Qian, Runchu Tian, Kunlun Zhu, Shihao Liang, Xingyu Shen, Bokai
Xu, Zhen Zhang, Yining Ye, Bowen Li, Ziwei Tang, Jing Yi, Yuzhang Zhu,
Zhenning Dai, Lan Yan, Xin Cong, Yaxi Lu, Weilin Zhao, Yuxiang Huang, Junxi
Yan, Xu Han, Xian Sun, Dahai Li, Jason Phang, Cheng Yang, Tongshuang Wu, Heng
Ji, Zhiyuan Liu, and Maosong Sun.
    </span>
    <span class="ltx_bibblock">
     Tool learning with foundation models, 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib197">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Dasari et al. [2019]
    </span>
    <span class="ltx_bibblock">
     Sudeep Dasari, Frederik Ebert, Stephen Tian, Suraj Nair, Bernadette Bucher,
Karl Schmeckpeper, Siddharth Singh, Sergey Levine, and Chelsea Finn.
    </span>
    <span class="ltx_bibblock">
     Robonet: Large-scale multi-robot learning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib197.1.1">
      arXiv preprint arXiv:1910.11215
     </em>
     , 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib198">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Walke et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Homer Walke, Kevin Black, Abraham Lee, Moo Jin Kim, Max Du, Chongyi Zheng, Tony
Zhao, Philippe Hansen-Estruch, Quan Vuong, Andre He, et al.
    </span>
    <span class="ltx_bibblock">
     Bridgedata v2: A dataset for robot learning at scale.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib198.1.1">
      arXiv preprint arXiv:2308.12952
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib199">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Aher et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Gati V Aher, Rosa I Arriaga, and Adam Tauman Kalai.
    </span>
    <span class="ltx_bibblock">
     Using large language models to simulate multiple humans and replicate
human subject studies.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib199.1.1">
      International Conference on Machine Learning
     </em>
     , pages
337–371. PMLR, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib200">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Akata et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Elif Akata, Lion Schulz, Julian Coda-Forno, Seong Joon Oh, Matthias Bethge, and
Eric Schulz.
    </span>
    <span class="ltx_bibblock">
     Playing repeated games with large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib200.1.1">
      arXiv preprint arXiv:2305.16867
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib201">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ziems et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Caleb Ziems, William Held, Omar Shaikh, Jiaao Chen, Zhehao Zhang, and Diyi
Yang.
    </span>
    <span class="ltx_bibblock">
     Can large language models transform computational social science?
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib201.1.1">
      arXiv preprint arXiv:2305.03514
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib202">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wu et al. [2023d]
    </span>
    <span class="ltx_bibblock">
     Yue Wu, Xuan Tang, Tom M. Mitchell, and Yuanzhi Li.
    </span>
    <span class="ltx_bibblock">
     Smartplay : A benchmark for llms as intelligent agents,
2023d.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib203">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Huang et al. [2023a]
    </span>
    <span class="ltx_bibblock">
     Qian Huang, Jian Vora, Percy Liang, and Jure Leskovec.
    </span>
    <span class="ltx_bibblock">
     Benchmarking large language models as ai research agents,
2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib204">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Huang et al. [2023b]
    </span>
    <span class="ltx_bibblock">
     Yue Huang, Jiawen Shi, Yuan Li, Chenrui Fan, Siyuan Wu, Qihui Zhang, Yixin Liu,
Pan Zhou, Yao Wan, Neil Zhenqiang Gong, and Lichao Sun.
    </span>
    <span class="ltx_bibblock">
     Metatool benchmark for large language models: Deciding whether to use
tools and which to use, 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib205">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Agashe et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Saaket Agashe, Yue Fan, and Xin Eric Wang.
    </span>
    <span class="ltx_bibblock">
     Evaluating multi-agent coordination abilities in large language
models, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib206">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kennedy and Eberhart [1995]
    </span>
    <span class="ltx_bibblock">
     James Kennedy and Russell Eberhart.
    </span>
    <span class="ltx_bibblock">
     Particle swarm optimization.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib206.1.1">
      Proceedings of ICNN’95-international conference on neural
networks
     </em>
     , volume 4, pages 1942–1948. IEEE, 1995.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib207">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Macal and North [2005]
    </span>
    <span class="ltx_bibblock">
     Charles M Macal and Michael J North.
    </span>
    <span class="ltx_bibblock">
     Tutorial on agent-based modeling and simulation.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib207.1.1">
      Proceedings of the Winter Simulation Conference, 2005.
     </em>
     ,
pages 14–pp. IEEE, 2005.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib208">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Crainic and Rousseau [1986]
    </span>
    <span class="ltx_bibblock">
     Teodor G Crainic and Jean-Marc Rousseau.
    </span>
    <span class="ltx_bibblock">
     Multicommodity, multimode freight transportation: A general modeling
and algorithmic framework for the service network design problem.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib208.1.1">
      Transportation Research Part B: Methodological
     </em>
     , 20(3):225–242, 1986.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib209">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yang et al. [2023a]
    </span>
    <span class="ltx_bibblock">
     Kaiyu Yang, Aidan M. Swope, Alex Gu, Rahul Chalamala, Peiyang Song, Shixing Yu,
Saad Godil, Ryan Prenger, and Anima Anandkumar.
    </span>
    <span class="ltx_bibblock">
     Leandojo: Theorem proving with retrieval-augmented language models,
2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib210">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Dong et al. [2023b]
    </span>
    <span class="ltx_bibblock">
     Qingxiu Dong, Li Dong, Ke Xu, Guangyan Zhou, Yaru Hao, Zhifang Sui, and Furu
Wei.
    </span>
    <span class="ltx_bibblock">
     Large language model for science: A study on p vs. np,
2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib211">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yang et al. [2023b]
    </span>
    <span class="ltx_bibblock">
     Zonglin Yang, Xinya Du, Junxian Li, Jie Zheng, Soujanya Poria, and Erik
Cambria.
    </span>
    <span class="ltx_bibblock">
     Large language models for automated open-domain scientific hypotheses
discovery.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib211.1.1">
      arXiv preprint arXiv:2309.02726
     </em>
     , 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib212">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gou et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Zhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen, Yujiu Yang, Minlie Huang,
Nan Duan, and Weizhu Chen.
    </span>
    <span class="ltx_bibblock">
     Tora: A tool-integrated reasoning agent for mathematical problem
solving, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib213">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Thakur and Wen [2023]
    </span>
    <span class="ltx_bibblock">
     Amitayush Thakur and Yeming Wen.
    </span>
    <span class="ltx_bibblock">
     A language-agent approach to formal theorem-proving, 9 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib214">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gómez-Bombarelli et al. [2016]
    </span>
    <span class="ltx_bibblock">
     Rafael Gómez-Bombarelli, Jorge Aguilera-Iparraguirre, Timothy D Hirzel,
David Duvenaud, Dougal Maclaurin, Martin A Blood-Forsythe, Hyun Sik Chae,
Markus Einzinger, Dong-Gwang Ha, Tony Wu, et al.
    </span>
    <span class="ltx_bibblock">
     Design of efficient molecular organic light-emitting diodes by a
high-throughput virtual screening and experimental approach.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib214.1.1">
      Nature materials
     </em>
     , 15(10):1120–1127, 2016.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib215">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhou et al. [2019]
    </span>
    <span class="ltx_bibblock">
     Zhenpeng Zhou, Steven Kearnes, Li Li, Richard N Zare, and Patrick Riley.
    </span>
    <span class="ltx_bibblock">
     Optimization of molecules via deep reinforcement learning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib215.1.1">
      Scientific reports
     </em>
     , 9(1):10752, 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib216">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     You et al. [2018]
    </span>
    <span class="ltx_bibblock">
     Jiaxuan You, Bowen Liu, Zhitao Ying, Vijay Pande, and Jure Leskovec.
    </span>
    <span class="ltx_bibblock">
     Graph convolutional policy network for goal-directed molecular graph
generation.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib216.1.1">
      Advances in neural information processing systems
     </em>
     , 31, 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib217">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Beaini et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Dominique Beaini, Shenyang Huang, Joao Alex Cunha, Gabriela Moisescu-Pareja,
Oleksandr Dymov, Samuel Maddrell-Mander, Callum McLean, Frederik Wenkel, Luis
Müller, Jama Hussein Mohamud, Ali Parviz, Michael Craig, Michał Koziarski,
Jiarui Lu, Zhaocheng Zhu, Cristian Gabellini, Kerstin Klaser, Josef Dean, Cas
Wognum, Maciej Sypetkowski, Guillaume Rabusseau, Reihaneh Rabbany, Jian Tang,
Christopher Morris, Ioannis Koutis, Mirco Ravanelli, Guy Wolf, Prudencio
Tossou, Hadrien Mary, Therence Bois, Andrew Fitzgibbon, Błażej Banaszewski,
Chad Martin, and Dominic Masters.
    </span>
    <span class="ltx_bibblock">
     Towards foundational models for molecular learning on large-scale
multi-task datasets, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib218">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Boiko et al. [2023b]
    </span>
    <span class="ltx_bibblock">
     Daniil A Boiko, Robert MacKnight, Ben Kline, and Gabe Gomes.
    </span>
    <span class="ltx_bibblock">
     Autonomous chemical research with large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib218.1.1">
      Nature
     </em>
     , 624(7992):570–578,
2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib219">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Bonabeau et al. [1999]
    </span>
    <span class="ltx_bibblock">
     Eric Bonabeau, Marco Dorigo, and Guy Theraulaz.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib219.1.1">
      Swarm intelligence: from natural to artificial systems
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     Number 1. Oxford university press, 1999.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib220">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     DeAngelis and Mooij [2005]
    </span>
    <span class="ltx_bibblock">
     Donald L DeAngelis and Wolf M Mooij.
    </span>
    <span class="ltx_bibblock">
     Individual-based modeling of ecological and evolutionary processes.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib220.1.1">
      Annu. Rev. Ecol. Evol. Syst.
     </em>
     , 36:147–168, 2005.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib221">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wilensky and Rand [2015]
    </span>
    <span class="ltx_bibblock">
     Uri Wilensky and William Rand.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib221.1.1">
      An introduction to agent-based modeling: modeling natural,
social, and engineered complex systems with NetLogo
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     Mit Press, 2015.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib222">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Jain et al. [2022]
    </span>
    <span class="ltx_bibblock">
     Moksh Jain, Emmanuel Bengio, Alex Hernandez-Garcia, Jarrid Rector-Brooks,
Bonaventure FP Dossou, Chanakya Ajit Ekbote, Jie Fu, Tianyu Zhang, Michael
Kilgour, Dinghuai Zhang, et al.
    </span>
    <span class="ltx_bibblock">
     Biological sequence design with gflownets.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib222.1.1">
      International Conference on Machine Learning
     </em>
     , pages
9786–9801. PMLR, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib223">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     O’Donoghue et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Odhran O’Donoghue, Aleksandar Shtedritski, John Ginger, Ralph Abboud, Ali Essa
Ghareeb, Justin Booth, and Samuel G Rodriques.
    </span>
    <span class="ltx_bibblock">
     Bioplanner: Automatic evaluation of llms on protocol planning in
biology, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib224">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Bi et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Zhen Bi, Ningyu Zhang, Yida Xue, Yixin Ou, Daxiong Ji, Guozhou Zheng, and
Huajun Chen.
    </span>
    <span class="ltx_bibblock">
     Oceangpt: A large language model for ocean science tasks, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib225">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Jager [2021]
    </span>
    <span class="ltx_bibblock">
     Wander Jager.
    </span>
    <span class="ltx_bibblock">
     Using agent-based modelling to explore behavioural dynamics affecting
our climate.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib225.1.1">
      Current opinion in psychology
     </em>
     , 42:133–139, 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib226">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Castro et al. [2020]
    </span>
    <span class="ltx_bibblock">
     Juana Castro, Stefan Drews, Filippos Exadaktylos, Joël Foramitti, Franziska
Klein, Théo Konc, Ivan Savin, and Jeroen van den Bergh.
    </span>
    <span class="ltx_bibblock">
     A review of agent-based modeling of climate-energy policy.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib226.1.1">
      Wiley Interdisciplinary Reviews: Climate Change
     </em>
     , 11(4):e647, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib227">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kraus et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Mathias Kraus, Julia Anna Bingler, Markus Leippold, Tobias Schimanski,
Chiara Colesanti Senni, Dominik Stammbach, Saeid Ashraf Vaghefi, and Nicolas
Webersinke.
    </span>
    <span class="ltx_bibblock">
     Enhancing large language models with climate resources, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib228">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. [2023g]
    </span>
    <span class="ltx_bibblock">
     Chenliang Li, Hehong Chen, Ming Yan, Weizhou Shen, Haiyang Xu, Zhikai Wu,
Zhicheng Zhang, Wenmeng Zhou, Yingda Chen, Chen Cheng, et al.
    </span>
    <span class="ltx_bibblock">
     Modelscope-agent: Building your customizable agent system with
open-source large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib228.1.1">
      arXiv preprint arXiv:2309.00986
     </em>
     , 2023g.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib229">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Colas et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Cédric Colas, Laetitia Teodorescu, Pierre-Yves Oudeyer, Xingdi Yuan, and
Marc-Alexandre Côté.
    </span>
    <span class="ltx_bibblock">
     Augmenting autotelic agents with large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib229.1.1">
      arXiv preprint arXiv:2305.12487
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib230">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhu et al. [2023b]
    </span>
    <span class="ltx_bibblock">
     Andrew Zhu, Liam Dugan, Alyssa Hwang, and Chris Callison-Burch.
    </span>
    <span class="ltx_bibblock">
     Kani: A lightweight and highly hackable framework for building
language model applications, 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib231">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhu et al. [2023c]
    </span>
    <span class="ltx_bibblock">
     Yun Zhu, Yinxiao Liu, Felix Stahlberg, Shankar Kumar, Yu-hui Chen, Liangchen
Luo, Lei Shu, Renjie Liu, Jindong Chen, and Lei Meng.
    </span>
    <span class="ltx_bibblock">
     Towards an on-device agent for text rewriting.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib231.1.1">
      arXiv preprint arXiv:2308.11807
     </em>
     , 2023c.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib232">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Maas et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Maas, Carey, Wheeler, Saatchi, Billington, and Shamash.
    </span>
    <span class="ltx_bibblock">
     To infinity and beyond: Show-1 and showrunner agents in multi-agent
simulations.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib232.1.1">
      arXiv preprint
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib233">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Feng et al. [2023a]
    </span>
    <span class="ltx_bibblock">
     Weixi Feng, Wanrong Zhu, Tsu jui Fu, Varun Jampani, Arjun Akula, Xuehai He,
Sugato Basu, Xin Eric Wang, and William Yang Wang.
    </span>
    <span class="ltx_bibblock">
     Layoutgpt: Compositional visual planning and generation with large
language models, 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib234">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yu et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Dingyao Yu, Kaitao Song, Peiling Lu, Tianyu He, Xu Tan, Wei Ye, Shikun Zhang,
and Jiang Bian.
    </span>
    <span class="ltx_bibblock">
     Musicagent: An ai agent for music understanding and generation with
large language models, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib235">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. [2023f]
    </span>
    <span class="ltx_bibblock">
     Howard Chen, Ramakanth Pasunuru, Jason Weston, and Asli Celikyilmaz.
    </span>
    <span class="ltx_bibblock">
     Walking down the memory maze: Beyond context limit through
interactive reading, 2023f.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib236">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Arthur et al. [2018]
    </span>
    <span class="ltx_bibblock">
     W Brian Arthur, John H Holland, Blake LeBaron, Richard Palmer, and Paul Tayler.
    </span>
    <span class="ltx_bibblock">
     Asset pricing under endogenous expectations in an artificial stock
market.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib236.1.1">
      The economy as an evolving complex system II
     </em>
     , pages 15–44.
CRC Press, 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib237">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Tesfatsion and Judd [2006]
    </span>
    <span class="ltx_bibblock">
     Leigh Tesfatsion and Kenneth L Judd.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib237.1.1">
      Handbook of computational economics: agent-based computational
economics
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     Elsevier, 2006.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib238">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Johanson et al. [2022]
    </span>
    <span class="ltx_bibblock">
     Michael Bradley Johanson, Edward Hughes, Finbarr Timbers, and Joel Z Leibo.
    </span>
    <span class="ltx_bibblock">
     Emergent bartering behaviour in multi-agent reinforcement learning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib238.1.1">
      arXiv preprint arXiv:2205.06760
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib239">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zheng et al. [2020]
    </span>
    <span class="ltx_bibblock">
     Stephan Zheng, Alexander Trott, Sunil Srinivasa, Nikhil Naik, Melvin Gruesbeck,
David C Parkes, and Richard Socher.
    </span>
    <span class="ltx_bibblock">
     The ai economist: Improving equality and productivity with ai-driven
tax policies.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib239.1.1">
      arXiv preprint arXiv:2004.13332
     </em>
     , 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib240">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Tilbury [2022]
    </span>
    <span class="ltx_bibblock">
     Callum Tilbury.
    </span>
    <span class="ltx_bibblock">
     Reinforcement learning in macroeconomic policy design: A new
frontier?
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib240.1.1">
      arXiv preprint arXiv:2206.08781
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib241">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Phelps and Ranson [2023]
    </span>
    <span class="ltx_bibblock">
     Steve Phelps and Rebecca Ranson.
    </span>
    <span class="ltx_bibblock">
     Of models and tin men–a behavioural economics study of
principal-agent problems in ai alignment using large-language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib241.1.1">
      arXiv preprint arXiv:2307.11137
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib242">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Guo et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Jiaxian Guo, Bo Yang, Paul Yoo, Yuchen Lin, Yusuke Iwasawa, and Yutaka Matsuo.
    </span>
    <span class="ltx_bibblock">
     Suspicion-agent: Playing imperfect information games with theory of
mind aware gpt4, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib243">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. [2023f]
    </span>
    <span class="ltx_bibblock">
     Saizhuo Wang, Hang Yuan, Leon Zhou, Lionel M. Ni, Heung-Yeung Shum, and Jian
Guo.
    </span>
    <span class="ltx_bibblock">
     Alpha-gpt: Human-ai interactive alpha mining for quantitative
investment, 2023f.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib244">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. [2023h]
    </span>
    <span class="ltx_bibblock">
     Yang Li, Yangyang Yu, Haohang Li, Zhi Chen, and Khaldoun Khashanah.
    </span>
    <span class="ltx_bibblock">
     Tradinggpt: Multi-agent system with layered memory and distinct
characters for enhanced financial trading performance.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib244.1.1">
      arXiv preprint arXiv:2309.03736
     </em>
     , 2023h.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib245">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Epstein and Axtell [1996]
    </span>
    <span class="ltx_bibblock">
     Joshua M Epstein and Robert Axtell.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib245.1.1">
      Growing artificial societies: social science from the bottom
up
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     Brookings Institution Press, 1996.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib246">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lustick and Miodownik [2009]
    </span>
    <span class="ltx_bibblock">
     Ian S Lustick and Dan Miodownik.
    </span>
    <span class="ltx_bibblock">
     Abstractions, ensembles, and virtualizations: simplicity and
complexity in agent-based modeling.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib246.1.1">
      Comparative Politics
     </em>
     , 41(2):223–244,
2009.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib247">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Tsvetovat and Carley [2004]
    </span>
    <span class="ltx_bibblock">
     Maksim Tsvetovat and Kathleen M Carley.
    </span>
    <span class="ltx_bibblock">
     Modeling complex socio-technical systems using multi-agent simulation
methods.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib247.1.1">
      KI
     </em>
     , 18(2):23–28, 2004.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib248">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Trott et al. [2021]
    </span>
    <span class="ltx_bibblock">
     Alexander Trott, Sunil Srinivasa, Douwe van der Wal, Sebastien Haneuse, and
Stephan Zheng.
    </span>
    <span class="ltx_bibblock">
     Building a foundation for data-driven, interpretable, and robust
policy design using the ai economist.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib248.1.1">
      arXiv preprint arXiv:2108.02904
     </em>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib249">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     [249]
    </span>
    <span class="ltx_bibblock">
     Christopher A Bail.
    </span>
    <span class="ltx_bibblock">
     Can generative ai improve social science?
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib250">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Mukobi et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Gabriel Mukobi, Hannah Erlebach, Niklas Lauffer, Lewis Hammond, Alan Chan, and
Jesse Clifton.
    </span>
    <span class="ltx_bibblock">
     Welfare diplomacy: Benchmarking language model cooperation, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib251">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Macy and Willer [2002]
    </span>
    <span class="ltx_bibblock">
     Michael W Macy and Robert Willer.
    </span>
    <span class="ltx_bibblock">
     From factors to actors: Computational sociology and agent-based
modeling.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib251.1.1">
      Annual review of sociology
     </em>
     , 28(1):143–166, 2002.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib252">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gilbert and Troitzsch [2005]
    </span>
    <span class="ltx_bibblock">
     Nigel Gilbert and Klaus Troitzsch.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib252.1.1">
      Simulation for the social scientist
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     McGraw-Hill Education (UK), 2005.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib253">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hasan et al. [2023a]
    </span>
    <span class="ltx_bibblock">
     Md Tarek Hasan, Mohammad Nazmush Shamael, Arifa Akter, Rokibul Islam,
Md Saddam Hossain Mukta, and Salekul Islam.
    </span>
    <span class="ltx_bibblock">
     An artificial intelligence-based framework to achieve the sustainable
development goals in the context of bangladesh.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib253.1.1">
      arXiv preprint arXiv:2304.11703
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib254">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. [2023f]
    </span>
    <span class="ltx_bibblock">
     Ruibo Liu, Ruixin Yang, Chenyan Jia, Ge Zhang, Denny Zhou, Andrew M Dai, Diyi
Yang, and Soroush Vosoughi.
    </span>
    <span class="ltx_bibblock">
     Training socially aligned language models in simulated human society.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib254.1.1">
      arXiv preprint arXiv:2305.16960
     </em>
     , 2023f.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib255">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Feng et al. [2023b]
    </span>
    <span class="ltx_bibblock">
     Xiachong Feng, Xiaocheng Feng, and Bing Qin.
    </span>
    <span class="ltx_bibblock">
     The role of summarization in generative agents: A preliminary
perspective.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib255.1.1">
      arXiv preprint arXiv:2305.01253
     </em>
     , 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib256">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wei et al. [2023b]
    </span>
    <span class="ltx_bibblock">
     Jimmy Wei, Kurt Shuster, Arthur Szlam, Jason Weston, Jack Urbanek, and Mojtaba
Komeili.
    </span>
    <span class="ltx_bibblock">
     Multi-party chat: Conversational agents in group settings with humans
and models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib256.1.1">
      arXiv preprint arXiv:2304.13835
     </em>
     , 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib257">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. [2023g]
    </span>
    <span class="ltx_bibblock">
     Xinglei Wang, Meng Fang, Zichao Zeng, and Tao Cheng.
    </span>
    <span class="ltx_bibblock">
     Where would i go next? large language models as human mobility
predictors.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib257.1.1">
      arXiv preprint arXiv:2308.15197
     </em>
     , 2023g.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib258">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Egami et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Naoki Egami, Musashi Jacobs-Harukawa, Brandon M. Stewart, and Hanying Wei.
    </span>
    <span class="ltx_bibblock">
     Using large language model annotations for valid downstream
statistical inference in social science: Design-based semi-supervised
learning, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib259">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ghaffarzadegan et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Navid Ghaffarzadegan, Aritra Majumdar, Ross Williams, and Niyousha
Hosseinichimeh.
    </span>
    <span class="ltx_bibblock">
     Generative agent-based modeling: Unveiling social system dynamics
through coupling mechanistic models with generative artificial intelligence,
2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib260">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kaiya et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Zhao Kaiya, Michelangelo Naim, Jovana Kondic, Manuel Cortes, Jiaxin Ge, Shuying
Luo, Guangyu Robert Yang, and Andrew Ahn.
    </span>
    <span class="ltx_bibblock">
     Lyfe agents: Generative agents for low-cost real-time social
interactions, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib261">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Bench-Capon and Sartor [2003]
    </span>
    <span class="ltx_bibblock">
     Trevor Bench-Capon and Giovanni Sartor.
    </span>
    <span class="ltx_bibblock">
     A model of legal reasoning with cases incorporating theories and
values.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib261.1.1">
      Artificial Intelligence
     </em>
     , 150(1-2):97–143,
2003.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib262">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Branting [2013]
    </span>
    <span class="ltx_bibblock">
     L Karl Branting.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib262.1.1">
      Reasoning with rules and precedents: a computational model of
legal analysis
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     Springer Science &amp; Business Media, 2013.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib263">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shui et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Ruihao Shui, Yixin Cao, Xiang Wang, and Tat-Seng Chua.
    </span>
    <span class="ltx_bibblock">
     A comprehensive evaluation of large language models on legal judgment
prediction, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib264">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sun [2006]
    </span>
    <span class="ltx_bibblock">
     Ron Sun.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib264.1.1">
      Cognition and multi-agent interaction: From cognitive modeling
to social simulation
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     Cambridge University Press, 2006.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib265">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Marsella and Gratch [2009]
    </span>
    <span class="ltx_bibblock">
     Stacy C Marsella and Jonathan Gratch.
    </span>
    <span class="ltx_bibblock">
     Ema: A process model of appraisal dynamics.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib265.1.1">
      Cognitive Systems Research
     </em>
     , 10(1):70–90,
2009.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib266">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ma et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Zilin Ma, Yiyang Mei, and Zhaoyuan Su.
    </span>
    <span class="ltx_bibblock">
     Understanding the benefits and challenges of using large language
model-based conversational agents for mental well-being support.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib266.1.1">
      arXiv preprint arXiv:2307.15810
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib267">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. [2023h]
    </span>
    <span class="ltx_bibblock">
     Zhilin Wang, Yu Ying Chiu, and Yu Cheung Chiu.
    </span>
    <span class="ltx_bibblock">
     Humanoid agents: Platform for simulating human-like generative
agents, 2023h.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib268">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang et al. [2023f]
    </span>
    <span class="ltx_bibblock">
     Jintian Zhang, Xin Xu, and Shumin Deng.
    </span>
    <span class="ltx_bibblock">
     Exploring collaboration mechanisms for llm agents: A social
psychology view, 2023f.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib269">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Woolf [2010]
    </span>
    <span class="ltx_bibblock">
     Beverly Park Woolf.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib269.1.1">
      Building intelligent interactive tutors: Student-centered
strategies for revolutionizing e-learning
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     Morgan Kaufmann, 2010.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib270">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Soller and Lesgold [2003]
    </span>
    <span class="ltx_bibblock">
     Amy Lynne Soller and Alan Lesgold.
    </span>
    <span class="ltx_bibblock">
     A computational approach to analyzing online knowledge sharing
interaction.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib270.1.1">
      Proceedings of Artificial Intelligence in Education
     </em>
     , 2003.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib271">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     North and Macal [2007]
    </span>
    <span class="ltx_bibblock">
     Michael J North and Charles M Macal.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib271.1.1">
      Managing business complexity: discovering strategic solutions
with agent-based modeling and simulation
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     Oxford University Press, 2007.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib272">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Bonabeau [2002]
    </span>
    <span class="ltx_bibblock">
     Eric Bonabeau.
    </span>
    <span class="ltx_bibblock">
     Agent-based modeling: Methods and techniques for simulating human
systems.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib272.1.1">
      Proceedings of the national academy of sciences
     </em>
     , 99(suppl_3):7280–7287, 2002.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib273">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. [2022]
    </span>
    <span class="ltx_bibblock">
     Xiaotian Liu, Ming Hu, Yijie Peng, and Yaodong Yang.
    </span>
    <span class="ltx_bibblock">
     Multi-agent deep reinforcement learning for multi-echelon inventory
management.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib273.1.1">
      Available at SSRN
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib274">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. [2023i]
    </span>
    <span class="ltx_bibblock">
     Yuan Li, Yixuan Zhang, and Lichao Sun.
    </span>
    <span class="ltx_bibblock">
     Metaagents: Simulating interactions of human behaviors for llm-based
task-oriented coordination via collaborative generative agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib274.1.1">
      arXiv preprint arXiv:2310.06500
     </em>
     , 2023i.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib275">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lin et al. [2023c]
    </span>
    <span class="ltx_bibblock">
     Jessy Lin, Nicholas Tomlin, Jacob Andreas, and Jason Eisner.
    </span>
    <span class="ltx_bibblock">
     Decision-oriented dialogue for human-ai collaboration.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib275.1.1">
      arXiv preprint arXiv:2305.20076
     </em>
     , 2023c.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib276">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hasan et al. [2023b]
    </span>
    <span class="ltx_bibblock">
     Masum Hasan, Cengiz Ozel, Sammy Potter, and Ehsan Hoque.
    </span>
    <span class="ltx_bibblock">
     Sapien: Affective virtual agents powered by large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib276.1.1">
      arXiv preprint arXiv:2308.03022
     </em>
     , 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib277">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gur et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Izzeddin Gur, Hiroki Furuta, Austin Huang, Mustafa Safdari, Yutaka Matsuo,
Douglas Eck, and Aleksandra Faust.
    </span>
    <span class="ltx_bibblock">
     A real-world webagent with planning, long context understanding, and
program synthesis.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib277.1.1">
      arXiv preprint arXiv:2307.12856
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib278">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Rigaki et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Maria Rigaki, Ondřej Lukáš, Carlos A Catania, and Sebastian
Garcia.
    </span>
    <span class="ltx_bibblock">
     Out of the cage: How stochastic parrots win in cyber security
environments.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib278.1.1">
      arXiv preprint arXiv:2308.12086
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib279">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hollmann et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Noah Hollmann, Samuel Müller, and Frank Hutter.
    </span>
    <span class="ltx_bibblock">
     Llms for semi-automated data science: Introducing caafe for
context-aware automated feature engineering, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib280">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Feldt et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Robert Feldt, Sungmin Kang, Juyeon Yoon, and Shin Yoo.
    </span>
    <span class="ltx_bibblock">
     Towards autonomous testing agents via conversational large language
models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib280.1.1">
      arXiv preprint arXiv:2306.05152
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib281">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. [2023i]
    </span>
    <span class="ltx_bibblock">
     Zefan Wang, Zichuan Liu, Yingying Zhang, Aoxiao Zhong, Lunting Fan, Lingfei Wu,
and Qingsong Wen.
    </span>
    <span class="ltx_bibblock">
     Rcagent: Cloud root cause analysis by autonomous agents with
tool-augmented large language models, 2023i.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib282">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. [2023j]
    </span>
    <span class="ltx_bibblock">
     Lei Wang, Jingsen Zhang, Xu Chen, Yankai Lin, Ruihua Song, Wayne Xin Zhao, and
Ji-Rong Wen.
    </span>
    <span class="ltx_bibblock">
     Recagent: A novel simulation paradigm for recommender systems.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib282.1.1">
      arXiv preprint arXiv:2306.02552
     </em>
     , 2023j.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib283">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang et al. [2023g]
    </span>
    <span class="ltx_bibblock">
     An Zhang, Leheng Sheng, Yuxin Chen, Hao Li, Yang Deng, Xiang Wang, and Tat-Seng
Chua.
    </span>
    <span class="ltx_bibblock">
     On generative agents in recommendation, 2023g.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib284">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Junprung [2023]
    </span>
    <span class="ltx_bibblock">
     Edward Junprung.
    </span>
    <span class="ltx_bibblock">
     Exploring the intersection of large language models and agent-based
modeling via prompt engineering.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib284.1.1">
      arXiv preprint arXiv:2308.07411
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib285">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chalamalasetti et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Kranti Chalamalasetti, Jana Götze, Sherzod Hakimov, Brielen Madureira,
Philipp Sadler, and David Schlangen.
    </span>
    <span class="ltx_bibblock">
     clembench: Using game play to evaluate chat-optimized language models
as conversational agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib285.1.1">
      arXiv preprint arXiv:2305.13455
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib286">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liang et al. [2023c]
    </span>
    <span class="ltx_bibblock">
     Yuanzhi Liang, Linchao Zhu, and Yi Yang.
    </span>
    <span class="ltx_bibblock">
     Tachikuma: Understading complex interactions with multi-character and
novel objects by large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib286.1.1">
      arXiv preprint arXiv:2307.12573
     </em>
     , 2023c.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib287">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. [2023g]
    </span>
    <span class="ltx_bibblock">
     Zexin Chen, Eric Zhou, Kenneth Eaton, Xiangyu Peng, and Mark Riedl.
    </span>
    <span class="ltx_bibblock">
     Ambient adventures: Teaching chatgpt on developing complex stories.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib287.1.1">
      arXiv preprint arXiv:2308.01734
     </em>
     , 2023g.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib288">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. [2023h]
    </span>
    <span class="ltx_bibblock">
     Dake Chen, Hanbin Wang, Yunhao Huo, Yuzhao Li, and Haoyang Zhang.
    </span>
    <span class="ltx_bibblock">
     Gamegpt: Multi-agent collaborative framework for game development,
2023h.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib289">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Parker et al. [2016]
    </span>
    <span class="ltx_bibblock">
     Lynne E Parker, Daniela Rus, and Gaurav S Sukhatme.
    </span>
    <span class="ltx_bibblock">
     Multiple mobile robot systems.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib289.1.1">
      Springer handbook of robotics
     </em>
     , pages 1335–1384, 2016.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib290">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Busoniu et al. [2008]
    </span>
    <span class="ltx_bibblock">
     Lucian Busoniu, Robert Babuska, and Bart De Schutter.
    </span>
    <span class="ltx_bibblock">
     A comprehensive survey of multiagent reinforcement learning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib290.1.1">
      IEEE Transactions on Systems, Man, and Cybernetics, Part C
(Applications and Reviews)
     </em>
     , 38(2):156–172, 2008.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib291">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Singh et al. [2022]
    </span>
    <span class="ltx_bibblock">
     Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit Goyal, Danfei Xu, Jonathan
Tremblay, Dieter Fox, Jesse Thomason, and Animesh Garg.
    </span>
    <span class="ltx_bibblock">
     Progprompt: Generating situated robot task plans using large language
models, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib292">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Huang et al. [2022]
    </span>
    <span class="ltx_bibblock">
     Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy
Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, Pierre Sermanet, Noah
Brown, Tomas Jackson, Linda Luu, Sergey Levine, Karol Hausman, and Brian
Ichter.
    </span>
    <span class="ltx_bibblock">
     Inner monologue: Embodied reasoning through planning with language
models, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib293">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xiang et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Jiannan Xiang, Tianhua Tao, Yi Gu, Tianmin Shu, Zirui Wang, Zichao Yang, and
Zhiting Hu.
    </span>
    <span class="ltx_bibblock">
     Language models meet world models: Embodied experiences enhance
language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib293.1.1">
      arXiv preprint arXiv:2305.10626
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib294">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hong et al. [2023b]
    </span>
    <span class="ltx_bibblock">
     Yining Hong, Haoyu Zhen, Peihao Chen, Shuhong Zheng, Yilun Du, Zhenfang Chen,
and Chuang Gan.
    </span>
    <span class="ltx_bibblock">
     3d-llm: Injecting the 3d world into large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib294.1.1">
      arXiv preprint arXiv:2307.12981
     </em>
     , 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib295">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kilkki et al. [2014]
    </span>
    <span class="ltx_bibblock">
     Olli Kilkki, Antti Kangasrääsiö, Raimo Nikkilä, Antti
Alahäivälä, and Ilkka Seilonen.
    </span>
    <span class="ltx_bibblock">
     Agent-based modeling and simulation of a smart grid: A case study of
communication effects on frequency control.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib295.1.1">
      Engineering Applications of Artificial Intelligence
     </em>
     ,
33:91–98, 2014.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib296">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Merabet et al. [2014]
    </span>
    <span class="ltx_bibblock">
     Ghezlane Halhoul Merabet, Mohammed Essaaidi, Hanaa Talei, Mohamed Riduan Abid,
Nacer Khalil, Mohcine Madkour, and Driss Benhaddou.
    </span>
    <span class="ltx_bibblock">
     Applications of multi-agent systems in smart grids: A survey.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib296.1.1">
      2014 International conference on multimedia computing and
systems (ICMCS)
     </em>
     , pages 1088–1094. IEEE, 2014.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib297">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ghazzali et al. [2020]
    </span>
    <span class="ltx_bibblock">
     Mohamed Ghazzali, Mohamed Haloua, and Fouad Giri.
    </span>
    <span class="ltx_bibblock">
     Fixed-time distributed voltage and reactive power compensation of
islanded microgrids using sliding-mode and multi-agent consensus design.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib297.1.1">
      Journal of Modern Power Systems and Clean Energy
     </em>
     , 10(1):232–240, 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib298">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shinde and Amelin [2019]
    </span>
    <span class="ltx_bibblock">
     Priyanka Shinde and Mikael Amelin.
    </span>
    <span class="ltx_bibblock">
     Agent-based models in electricity markets: A literature review.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib298.1.1">
      2019 IEEE Innovative Smart Grid Technologies-Asia (ISGT Asia)
     </em>
     ,
pages 3026–3031, 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib299">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     May and Huang [2023]
    </span>
    <span class="ltx_bibblock">
     Ross May and Pei Huang.
    </span>
    <span class="ltx_bibblock">
     A multi-agent reinforcement learning approach for investigating and
optimising peer-to-peer prosumer energy markets.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib299.1.1">
      Applied Energy
     </em>
     , 334:120705, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib300">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zeng et al. [2018]
    </span>
    <span class="ltx_bibblock">
     Jinghong Zeng, Jianming Hu, and Yi Zhang.
    </span>
    <span class="ltx_bibblock">
     Adaptive traffic signal control with deep recurrent q-learning.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib300.1.1">
      2018 IEEE intelligent vehicles symposium (IV)
     </em>
     , pages
1215–1220. IEEE, 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib301">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chu et al. [2019]
    </span>
    <span class="ltx_bibblock">
     Tianshu Chu, Jie Wang, Lara Codecà, and Zhaojian Li.
    </span>
    <span class="ltx_bibblock">
     Multi-agent deep reinforcement learning for large-scale traffic
signal control.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib301.1.1">
      IEEE Transactions on Intelligent Transportation Systems
     </em>
     ,
21(3):1086–1095, 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib302">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Da et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Longchao Da, Minchiuan Gao, Hao Mei, and Hua Wei.
    </span>
    <span class="ltx_bibblock">
     Llm powered sim-to-real transfer for traffic signal control.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib302.1.1">
      arXiv preprint arXiv:2308.14284
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib303">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wen et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Licheng Wen, Daocheng Fu, Xin Li, Xinyu Cai, Tao Ma, Pinlong Cai, Min Dou,
Botian Shi, Liang He, and Yu Qiao.
    </span>
    <span class="ltx_bibblock">
     Dilu: A knowledge-driven approach to autonomous driving with large
language models, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib304">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shen and Norrie [1999]
    </span>
    <span class="ltx_bibblock">
     Weiming Shen and Douglas H Norrie.
    </span>
    <span class="ltx_bibblock">
     Agent-based systems for intelligent manufacturing: a state-of-the-art
survey.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib304.1.1">
      Knowledge and information systems
     </em>
     , 1:129–156, 1999.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib305">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shen et al. [2006]
    </span>
    <span class="ltx_bibblock">
     Weiming Shen, Qi Hao, Hyun Joong Yoon, and Douglas H Norrie.
    </span>
    <span class="ltx_bibblock">
     Applications of agent-based systems in intelligent manufacturing: An
updated review.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib305.1.1">
      Advanced engineering INFORMATICS
     </em>
     , 20(4):415–431, 2006.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib306">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Nascimento et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Nathalia Nascimento, Paulo Alencar, and Donald Cowan.
    </span>
    <span class="ltx_bibblock">
     Gpt-in-the-loop: Adaptive decision-making for multiagent systems.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib306.1.1">
      arXiv preprint arXiv:2308.10435
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib307">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. [2023j]
    </span>
    <span class="ltx_bibblock">
     Renjie Li, Ceyao Zhang, Sixuan Mao, Hai Huang, Mou Zhong, Yiou Cui, Xiyuan
Zhou, Feng Yin, Sergios Theodoridis, and Zhaoyu Zhang.
    </span>
    <span class="ltx_bibblock">
     From English to PCSEL: LLM helps design and optimize photonic
crystal surface emitting lasers.
    </span>
    <span class="ltx_bibblock">
     14 pages, 9 graphics, August 2023j.
    </span>
    <span class="ltx_bibblock">
     URL
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hal.science/hal-04175312" target="_blank" title="">
      https://hal.science/hal-04175312
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib308">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     An [2001]
    </span>
    <span class="ltx_bibblock">
     Gary An.
    </span>
    <span class="ltx_bibblock">
     Agent-based computer simulation and sirs: building a bridge between
basic science and clinical trials.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib308.1.1">
      Shock
     </em>
     , 16(4):266–273, 2001.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib309">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ekins et al. [2006]
    </span>
    <span class="ltx_bibblock">
     Sean Ekins, Yuri Nikolsky, Andrej Bugrim, Eugene Kirillov, and Tatiana
Nikolskaya.
    </span>
    <span class="ltx_bibblock">
     Pathway mapping tools for analysis of high content data.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib309.1.1">
      High content screening: A powerful approach to systems cell
biology and drug discovery
     </em>
     , pages 319–350, 2006.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib310">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Walker et al. [2004]
    </span>
    <span class="ltx_bibblock">
     DC Walker, J Southgate, G Hill, M Holcombe, DR Hose, SM Wood, S Mac Neil, and
RH Smallwood.
    </span>
    <span class="ltx_bibblock">
     The epitheliome: agent-based modelling of the social behaviour of
cells.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib310.1.1">
      Biosystems
     </em>
     , 76(1-3):89–100, 2004.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib311">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Singhal et al. [2022]
    </span>
    <span class="ltx_bibblock">
     Karan Singhal, Shekoofeh Azizi, Tao Tu, S Sara Mahdavi, Jason Wei, Hyung Won
Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl, et al.
    </span>
    <span class="ltx_bibblock">
     Large language models encode clinical knowledge.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib311.1.1">
      arXiv preprint arXiv:2212.13138
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib312">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhavoronkov et al. [2019]
    </span>
    <span class="ltx_bibblock">
     Alex Zhavoronkov, Yan A Ivanenkov, Alex Aliper, Mark S Veselov, Vladimir A
Aladinskiy, Anastasiya V Aladinskaya, Victor A Terentiev, Daniil A
Polykovskiy, Maksim D Kuznetsov, Arip Asadulaev, et al.
    </span>
    <span class="ltx_bibblock">
     Deep learning enables rapid identification of potent ddr1 kinase
inhibitors.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib312.1.1">
      Nature biotechnology
     </em>
     , 37(9):1038–1040,
2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib313">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lobentanzer and Saez-Rodriguez [2023]
    </span>
    <span class="ltx_bibblock">
     Sebastian Lobentanzer and Julio Saez-Rodriguez.
    </span>
    <span class="ltx_bibblock">
     A platform for the biomedical application of large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib313.1.1">
      arXiv preprint arXiv:2305.06488
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib314">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Mehandru et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Nikita Mehandru, Brenda Y Miao, Eduardo Rodriguez Almaraz, Madhumita Sushil,
Atul J Butte, and Ahmed Alaa.
    </span>
    <span class="ltx_bibblock">
     Large language models as agents in the clinic.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib314.1.1">
      arXiv preprint arXiv:2309.10895
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib315">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ilachinski [2004]
    </span>
    <span class="ltx_bibblock">
     Andrew Ilachinski.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib315.1.1">
      Artificial war: Multiagent-based simulation of combat
     </em>
     .
    </span>
    <span class="ltx_bibblock">
     World Scientific, 2004.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib316">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Cil and Mala [2010]
    </span>
    <span class="ltx_bibblock">
     Ibrahim Cil and Murat Mala.
    </span>
    <span class="ltx_bibblock">
     A multi-agent architecture for modelling and simulation of small
military unit combat in asymmetric warfare.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib316.1.1">
      Expert Systems with Applications
     </em>
     , 37(2):1331–1343, 2010.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib317">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sycara and Sukthankar [2006]
    </span>
    <span class="ltx_bibblock">
     Katia Sycara and Gita Sukthankar.
    </span>
    <span class="ltx_bibblock">
     Literature review of teamwork models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib317.1.1">
      Robotics Institute, Carnegie Mellon University
     </em>
     , 31(31):1–31, 2006.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib318">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. [2023g]
    </span>
    <span class="ltx_bibblock">
     Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu,
Hangliang Ding, Kaiwen Men, Kejuan Yang, et al.
    </span>
    <span class="ltx_bibblock">
     Agentbench: Evaluating llms as agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib318.1.1">
      arXiv preprint arXiv:2308.03688
     </em>
     , 2023g.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib319">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhong et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Wanjun Zhong, Lianghong Guo, Qiqi Gao, He Ye, and Yanlin Wang.
    </span>
    <span class="ltx_bibblock">
     Memorybank: Enhancing large language models with long-term memory,
2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib320">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     tse Huang et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Jen tse Huang, Man Ho Lam, Eric John Li, Shujie Ren, Wenxuan Wang, Wenxiang
Jiao, Zhaopeng Tu, and Michael R. Lyu.
    </span>
    <span class="ltx_bibblock">
     Emotionally numb or empathetic? evaluating how llms feel using
emotionbench, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib321">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yang et al. [2023c]
    </span>
    <span class="ltx_bibblock">
     Zhengyuan Yang, Linjie Li, Jianfeng Wang, Kevin Lin, Ehsan Azarnasab, Faisal
Ahmed, Zicheng Liu, Ce Liu, Michael Zeng, and Lijuan Wang.
    </span>
    <span class="ltx_bibblock">
     Mm-react: Prompting chatgpt for multimodal reasoning and action,
2023c.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib322">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     You et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Haoxuan You, Rui Sun, Zhecan Wang, Long Chen, Gengyu Wang, Hammad A. Ayyubi,
Kai-Wei Chang, and Shih-Fu Chang.
    </span>
    <span class="ltx_bibblock">
     Idealgpt: Iteratively decomposing vision and language reasoning via
large language models, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib323">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Surís et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Dídac Surís, Sachit Menon, and Carl Vondrick.
    </span>
    <span class="ltx_bibblock">
     Vipergpt: Visual inference via python execution for reasoning, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib324">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yang et al. [2023d]
    </span>
    <span class="ltx_bibblock">
     Zhengyuan Yang, Linjie Li, Kevin Lin, Jianfeng Wang, Chung-Ching Lin, Zicheng
Liu, and Lijuan Wang.
    </span>
    <span class="ltx_bibblock">
     The dawn of lmms: Preliminary explorations with gpt-4v(ision),
2023d.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib325">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. [2023i]
    </span>
    <span class="ltx_bibblock">
     Jun Chen, Deyao Zhu, Xiaoqian Shen, Xiang Li, Zechun Liu, Pengchuan Zhang,
Raghuraman Krishnamoorthi, Vikas Chandra, Yunyang Xiong, and Mohamed
Elhoseiny.
    </span>
    <span class="ltx_bibblock">
     Minigpt-v2: large language model as a unified interface for
vision-language multi-task learning, 2023i.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib326">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. [2023h]
    </span>
    <span class="ltx_bibblock">
     Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee.
    </span>
    <span class="ltx_bibblock">
     Visual instruction tuning, 2023h.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib327">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Driess et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Danny Driess, Fei Xia, Mehdi S. M. Sajjadi, Corey Lynch, Aakanksha Chowdhery,
Brian Ichter, Ayzaan Wahid, Jonathan Tompson, Quan Vuong, Tianhe Yu, Wenlong
Huang, Yevgen Chebotar, Pierre Sermanet, Daniel Duckworth, Sergey Levine,
Vincent Vanhoucke, Karol Hausman, Marc Toussaint, Klaus Greff, Andy Zeng,
Igor Mordatch, and Pete Florence.
    </span>
    <span class="ltx_bibblock">
     Palm-e: An embodied multimodal language model, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib328">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. [2023i]
    </span>
    <span class="ltx_bibblock">
     Nelson F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua,
Fabio Petroni, and Percy Liang.
    </span>
    <span class="ltx_bibblock">
     Lost in the middle: How language models use long contexts.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib328.1.1">
      arXiv preprint arXiv:2307.03172
     </em>
     , 2023i.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib329">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhang et al. [2023h]
    </span>
    <span class="ltx_bibblock">
     Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting
Huang, Enbo Zhao, Yu Zhang, Yulong Chen, Longyue Wang, Anh Tuan Luu, Wei Bi,
Freda Shi, and Shuming Shi.
    </span>
    <span class="ltx_bibblock">
     Siren’s song in the ai ocean: A survey on hallucination in large
language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib329.1.1">
      arXiv preprint arXiv:2309.01219
     </em>
     , 2023h.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib330">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yue et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Murong Yue, Jie Zhao, Min Zhang, Liang Du, and Ziyu Yao.
    </span>
    <span class="ltx_bibblock">
     Large language model cascades with mixture of thoughts
representations for cost-efficient reasoning, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib331">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Schwartz et al. [2023]
    </span>
    <span class="ltx_bibblock">
     Sivan Schwartz, Avi Yaeli, and Segev Shlomov.
    </span>
    <span class="ltx_bibblock">
     Enhancing trust in llm-based ai automation agents: New considerations
and future challenges.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib331.1.1">
      arXiv preprint arXiv:2308.05391
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib332">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ruan et al. [2023b]
    </span>
    <span class="ltx_bibblock">
     Yangjun Ruan, Honghua Dong, Andrew Wang, Silviu Pitis, Yongchao Zhou, Jimmy Ba,
Yann Dubois, Chris J. Maddison, and Tatsunori Hashimoto.
    </span>
    <span class="ltx_bibblock">
     Identifying the risks of lm agents with an lm-emulated sandbox,
2023b.
    </span>
   </li>
  </ul>
 </section>
 <div class="ltx_pagination ltx_role_newpage">
 </div>
</article>
