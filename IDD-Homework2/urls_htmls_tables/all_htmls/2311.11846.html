<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2311.11846] Deepparse : An Extendable, and Fine-Tunable State-Of-The-Art Library for Parsing Multinational Street Addresses</title><meta property="og:description" content="Segmenting an address into meaningful components, also known as address parsing, is an essential step in many applications from record linkage to geocoding and package delivery. Consequently, a lot of work has been ded…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Deepparse : An Extendable, and Fine-Tunable State-Of-The-Art Library for Parsing Multinational Street Addresses">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Deepparse : An Extendable, and Fine-Tunable State-Of-The-Art Library for Parsing Multinational Street Addresses">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2311.11846">

<!--Generated on Tue Feb 27 17:58:26 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Deepparse : An Extendable, and Fine-Tunable State-Of-The-Art Library for Parsing Multinational Street Addresses</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">David Beauchemin, Marouane Yassine
<br class="ltx_break">Department of Computer Science and Software Engineering, Laval University 
<br class="ltx_break">Group for Research in Artificial Intelligence of Laval University (GRAIL)
<br class="ltx_break">Québec, Canada 
<br class="ltx_break">david.beauchemin@ift.ulaval.ca,
marouane.yassine.1@ulaval.ca
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.id1" class="ltx_p">Segmenting an address into meaningful components, also known as address parsing, is an essential step in many applications from record linkage to geocoding and package delivery. Consequently, a lot of work has been dedicated to develop accurate address parsing techniques, with machine learning and neural network methods leading the state-of-the-art scoreboard. However, most of the work on address parsing has been confined to academic endeavours with little availability of free and easy-to-use open-source solutions.</p>
<p id="id1.1" class="ltx_p">This paper presents Deepparse, a Python open-source, extendable, fine-tunable address parsing solution under LGPL-3.0 licence to parse multinational addresses using state-of-the-art deep learning algorithms and evaluated on over 60 countries.
It can parse addresses written in any language and use any address standard. The pre-trained model achieves average <math id="id1.1.m1.1" class="ltx_Math" alttext="99~{}\%" display="inline"><semantics id="id1.1.m1.1a"><mrow id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml"><mn id="id1.1.m1.1.1.2" xref="id1.1.m1.1.1.2.cmml">99</mn><mo lspace="0.330em" id="id1.1.m1.1.1.1" xref="id1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><apply id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1"><csymbol cd="latexml" id="id1.1.m1.1.1.1.cmml" xref="id1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="id1.1.m1.1.1.2.cmml" xref="id1.1.m1.1.1.2">99</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">99~{}\%</annotation></semantics></math> parsing accuracies on the countries used for training with no pre-processing nor post-processing needed. Moreover, the library supports fine-tuning with new data to generate a custom address parser.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p"><em id="S1.p1.1.1" class="ltx_emph ltx_font_italic">Address Parsing</em> is the task of decomposing an address into its different components <cite class="ltx_cite ltx_citemacro_citep">(Abid et al., <a href="#bib.bib1" title="" class="ltx_ref">2018</a>)</cite>. This task is essential to many applications, such as geocoding and record linkage. Indeed, it is quite useful to detect the different parts of an address to find a particular location based on textual data to make an informed decision. Similarly, comparing two addresses to decide whether two or more database entries refer to the same entity can prove to be quite difficult and prone to errors if based on methods such as edit distance algorithms given the various address writing standards.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">There have been many efforts to solve the address parsing problem. From rule-based techniques <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a href="#bib.bib19" title="" class="ltx_ref">2012</a>)</cite> to probabilistic approaches and neural network models <cite class="ltx_cite ltx_citemacro_citep">(Abid et al., <a href="#bib.bib1" title="" class="ltx_ref">2018</a>)</cite>, much progress has been made in reaching accurate addresses segmentation. These previous works did a remarkable job of finding solutions for the challenges related to the address parsing task. However, most of these approaches either do not take into account parsing addresses from different countries or do so but at the cost of a considerable amount of meta-data and substantial data pre-processing pipelines <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib10" title="" class="ltx_ref">Mokhtari et al., </a>; Li et al., <a href="#bib.bib9" title="" class="ltx_ref">2014</a>; Wang et al., <a href="#bib.bib17" title="" class="ltx_ref">2016</a>; Sharma et al., <a href="#bib.bib16" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">However, most of the work on address parsing has been confined to academic endeavours with little availability of free and easy-to-use open-source solutions. In an effort to solve some of the limitations of previous methods, as well as offer an open-source address parsing solution, we have created <span id="S1.p3.1.1" class="ltx_text ltx_font_bold">Deepparse<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note"><span id="footnote1.1.1.1" class="ltx_text ltx_font_medium">1</span></span><a target="_blank" href="https://deepparse.org/" title="" class="ltx_ref ltx_href ltx_font_medium">https://deepparse.org/</a></span></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(Yassine and Beauchemin, <a href="#bib.bib20" title="" class="ltx_ref">2020</a>)</cite> an LGPL-3.0 licenced Python library. Our work allows anyone with a basic knowledge of Python or command line terminal to conveniently parse addresses from multiple countries using state-of-the-art deep learning models proposed by <cite class="ltx_cite ltx_citemacro_citet">Yassine et al. (<a href="#bib.bib22" title="" class="ltx_ref">2020</a>, <a href="#bib.bib21" title="" class="ltx_ref">2022</a>)</cite>.
Deepparse’s goal is to parse multinational addresses written in any language or using any address writing format with an extendable and fine-tunable address parser. In addition, <span id="S1.p3.1.2" class="ltx_text ltx_font_bold">Deepparse</span> proposes a functionality to easily customize the aforementioned models to new data along with an easy-to-use Docker FastAPI
to parse addresses.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">This paper’s contributions are: First, we describe an open-source Python library for multinational address parsing. Second, we describe its implementation details and natural extensibility due to its fine-tuning possibilities. Third, we benchmark it against other open-source libraries.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Address parsing has been approached on the academic front using probabilistic machine learning models such as Hidden Markov Models and Conditional Random Fields (CRF) <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a href="#bib.bib9" title="" class="ltx_ref">2014</a>; Wang et al., <a href="#bib.bib17" title="" class="ltx_ref">2016</a>; Abid et al., <a href="#bib.bib1" title="" class="ltx_ref">2018</a>)</cite>, as well as deep learning models mainly based on the recurrent neural network (RNN) architecture <cite class="ltx_cite ltx_citemacro_citep">(Sharma et al., <a href="#bib.bib16" title="" class="ltx_ref">2018</a>; <a href="#bib.bib10" title="" class="ltx_ref">Mokhtari et al., </a>; Abid et al., <a href="#bib.bib1" title="" class="ltx_ref">2018</a>)</cite>. Regarding openly available software, most of the existing packages cater to US postal addresses. For instance, <em id="S2.p1.1.1" class="ltx_emph ltx_font_italic">pyaddress</em><span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://github.com/SwoopSearch/pyaddress" title="" class="ltx_ref ltx_href">https://github.com/SwoopSearch/pyaddress</a></span></span></span> allows for the decomposition of US addresses into eight different attributes with a possibility to specify acceptable “street names”, “cities” and “street suffixes” in order to improve parsing accuracy. Similarly, <em id="S2.p1.1.2" class="ltx_emph ltx_font_italic">address-parser</em><span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://github.com/CivicKnowledge/address_parser" title="" class="ltx_ref ltx_href">https://github.com/CivicKnowledge/address_parser</a></span></span></span> identifies as “Yet another python address parser for US postal addresses” and enables users to extract multiple address components such as “house numbers”, “street names”, “cardinal directions” and “zip codes”. These two packages are based on a combination of predefined component lists and regular expressions. In contrast, <em id="S2.p1.1.3" class="ltx_emph ltx_font_italic">usaddress</em><span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a target="_blank" href="https://github.com/datamade/usaddress" title="" class="ltx_ref ltx_href">https://github.com/datamade/usaddress</a></span></span></span> uses a probabilistic model that users can fine-tune using their data.
Another openly available avenue for address parsing is Geocoding APIs, which can result in highly precise parsed addresses based on reverse geocoding. However, while being openly available, Geocoding APIs are often not free and not always convenient to use for a programming layperson.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">The aforementioned approaches are limited to parsing addresses from a single country and either cannot handle a multinational scope of address parsing or would need to be adjusted to do so. To tackle this problem, Libpostal<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a target="_blank" href="https://github.com/openvenues/libpostal" title="" class="ltx_ref ltx_href">https://github.com/openvenues/libpostal</a></span></span></span>, a C library for international address parsing, has been proposed. This library uses a CRF-based model trained with an averaged Perceptron for scalability. The model was trained on Libpostal dataset<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a target="_blank" href="https://github.com/openvenues/libpostal#training-data" title="" class="ltx_ref ltx_href">https://github.com/openvenues/libpostal#training-data</a></span></span></span> and achieved a <math id="S2.p2.1.m1.1" class="ltx_Math" alttext="99.45~{}\%" display="inline"><semantics id="S2.p2.1.m1.1a"><mrow id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml"><mn id="S2.p2.1.m1.1.1.2" xref="S2.p2.1.m1.1.1.2.cmml">99.45</mn><mo lspace="0.330em" id="S2.p2.1.m1.1.1.1" xref="S2.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.1b"><apply id="S2.p2.1.m1.1.1.cmml" xref="S2.p2.1.m1.1.1"><csymbol cd="latexml" id="S2.p2.1.m1.1.1.1.cmml" xref="S2.p2.1.m1.1.1.1">percent</csymbol><cn type="float" id="S2.p2.1.m1.1.1.2.cmml" xref="S2.p2.1.m1.1.1.2">99.45</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.1c">99.45~{}\%</annotation></semantics></math> full parse accuracy<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>The accuracy was computed considering the entire sequence and was not focused on individual tokens.</span></span></span> using an extensive pre and post-processing pipeline. However, this requires putting addresses through a heavy pre-processing pipeline before feeding them to the prediction model, and it does not seem possible to develop a new address parser based on the documentation.
A thorough search of the relevant literature yielded no open-source neural network-based software for multinational address parsing.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Implementation</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Deepparse is divided into three high-level components: pre-processors, embeddings model, and tagging model.
The first component, the pre-processor, is a series of simple handcrafted pre-processing functions to be applied as a data cleaning procedure before the embedding component, such as lowercasing the address text and removing commas. By default, Deepparse simply lowercase and removes all commas in the address. The library does not require a complex pre-processing pipeline, but one can be defined and used more complex one if needed since Deepparse is built so users can handcraft and use a custom pre-processor during this phase.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">The last two components are illustrated in <a href="#S3.F1" title="Figure 1 ‣ 3 Implementation ‣ Deepparse : An Extendable, and Fine-Tunable State-Of-The-Art Library for Parsing Multinational Street Addresses" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 1</span></a>. We can see that the embeddings model component (black) encodes each token (i.e. word) of the address into a recurrent dense representation. At the end of the sentence, the component generates a single dense representation for the overall address generated from the individual address components.
Then, this address-dense representation is used as input to the tagging model component (red), where each address component is decoded and classified into its appropriate tag.
These two components do not rely on named entity recognition to parse addresses as opposed to the one proposed by <cite class="ltx_cite ltx_citemacro_citet">Abid et al. (<a href="#bib.bib1" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">Deepparse proposes two embeddings model approaches and four pre-trained tagging model architectures; all approaches can be used with CPU or GPU setup.
All pre-trained approaches have been trained on our publicly available dataset<span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a target="_blank" href="https://github.com/GRAAL-Research/deepparse-address-data" title="" class="ltx_ref ltx_href">https://github.com/GRAAL-Research/deepparse-address-data</a></span></span></span>, based on to the Libpostal dataset, and achieved parse accuracies higher than 99% on the 20 trained countries without using pre or post-processing<span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span> The accuracy for each sequence is computed as the proportion of the tags predicted correctly by the model. Predicting all the tags correctly for a sequence yields perfect accuracy.</span></span></span>.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p">The following sub-section will briefly discuss how these two components work. For more details on the algorithms behind both components, readers can refer to <cite class="ltx_cite ltx_citemacro_citet">Yassine et al. (<a href="#bib.bib22" title="" class="ltx_ref">2020</a>, <a href="#bib.bib21" title="" class="ltx_ref">2022</a>)</cite>.
We will finish this section with a presentation on Deepparse’s ability to developing a new address parser.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2311.11846/assets/x1.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="291" height="136" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Illustration of our architecture using one of the two embedding model component (black) approach. Each word in the address is encoded using an embedding model, in this case, MultiBPEmb (the BPE segmentation algorithm replaces the numbers in the address with zeros). The embeddings are fed to a BiLSTM (rounded rectangle with two circles). The last hidden state for each word is run through a fully connected layer (rounded rectangle with one circle). The resulting embeddings are given as input to the tagging model components (red). The “S” in the fully connected layer following the Seq2Seq decoder stands for the Softmax function.</figcaption>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Embedding Model</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Our objective was to build a single neural network to parse addresses from multiple countries. Thus, access to embeddings for different languages at runtime was necessary. Since the use of alignment vectors <cite class="ltx_cite ltx_citemacro_citep">(Joulin et al., <a href="#bib.bib8" title="" class="ltx_ref">2018</a>; Conneau et al., <a href="#bib.bib4" title="" class="ltx_ref">2017</a>)</cite> would have introduced the unnecessary overhead of detecting of the source language to project word embeddings from different languages in the same space, Deepparse proposes the following two methods.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">First, we use a fixed pre-trained monolingual French fastText model. We chose French embeddings since this language shares Latin roots with many languages in our test set. It is also due to the large corpus on which these embeddings were trained. We refer to this embeddings model technique as <span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_bold">fastText</span>.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">Second, we use an encoding of words using MultiBPEmb and merge the obtained embeddings for each word into one word embedding using an RNN. This method has been shown to give good results in a multilingual setting <cite class="ltx_cite ltx_citemacro_citep">(Heinzerling and Strube, <a href="#bib.bib5" title="" class="ltx_ref">2019</a>)</cite>. Our RNN network of choice is a Bidirectional LSTM (Bi-LSTM) with a hidden state dimension of 300. We build the word embeddings by running the concatenated forward and backward hidden states corresponding to the last time step for each word decomposition through a fully connected layer of which the number of neurons equals the dimension of the hidden states. This approach produces 300-dimensional word embeddings. We refer to this embeddings model technique as <span id="S3.SS1.p3.1.1" class="ltx_text ltx_font_bold">BPEmb</span>.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Tagging Model</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Our downstream tagging model is a Seq2Seq model.
Using Seq2Seq architecture as tagging model is effective for data with sequential pattern <cite class="ltx_cite ltx_citemacro_citep">(Huang et al., <a href="#bib.bib6" title="" class="ltx_ref">2019</a>; Omelianchuk et al., <a href="#bib.bib12" title="" class="ltx_ref">2021</a>; Jin and Yu, <a href="#bib.bib7" title="" class="ltx_ref">2021</a>; Raman et al., <a href="#bib.bib15" title="" class="ltx_ref">2022</a>)</cite> such as address.
The architecture consists of a one-layer unidirectional LSTM encoder and a one-layer unidirectional LSTM decoder followed by a fully-connected linear layer with a softmax activation. Both the encoder’s and decoder’s hidden states are of dimension <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="1024" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mn id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">1024</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><cn type="integer" id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">1024</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">1024</annotation></semantics></math>.
The embedded address sequence is fed to the encoder that produces hidden states, the last of which is used as a context vector to initialize the decoder’s hidden states. The decoder is then given a “Beginning Of Sequence” (BOS) token as input, and at each time step, the prediction from the last step is used as input. To better adapt the model to the task at hand and to facilitate the convergence process, we only require the decoder to produce a sequence with the same length as the input address. This approach differs from the traditional Seq2Seq architecture in which the decoder makes predictions until it predicts the ends-of-sequence token. The decoder’s outputs are forwarded to the linear layer, of which the number of neurons equals the tag space dimensionality. The softmax activation function computes probabilities over the linear layer’s outputs to predict the most likely token at each time step.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">Deepparse proposes four pre-trained tagging model architectures: one using each embedding model approach, namely <span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_bold">fastText</span> and <span id="S3.SS2.p2.1.2" class="ltx_text ltx_font_bold">BPEmb</span>, and one using each embedding model approach with an added attention mechanisms. Attention mechanisms are neural network components that can produce a distribution describing the interdependence between a model’s inputs and outputs (general attention) or amongst model inputs themselves (self-attention). These mechanisms are common in natural language processing encoder-decoder architectures such as neural machine translation models <cite class="ltx_cite ltx_citemacro_citep">(Bahdanau et al., <a href="#bib.bib2" title="" class="ltx_ref">2015</a>)</cite> since they have been shown to improve models’ performance and help address some of the issues RNNs suffer from when dealing with long sequences. Also, <cite class="ltx_cite ltx_citemacro_citet">Yassine et al. (<a href="#bib.bib21" title="" class="ltx_ref">2022</a>)</cite> has shown that the attention mechanism has significantly increased performance for incomplete addresses. Incomplete addresses do not include all the components defined by a country-written standard—for example, an address missing its postal code. They are cumbersome and cause problems for many industries, such as delivery services and insurance companies <cite class="ltx_cite ltx_citemacro_citep">(Nagabhushan, <a href="#bib.bib11" title="" class="ltx_ref">2009</a>)</cite>.</p>
</div>
<section id="S3.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Choosing a Model</h4>

<div id="S3.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p1.1" class="ltx_p">The difference between all four models is their capabilities to generate better results on unseen address patterns and unseen language.
For example, as shown in <cite class="ltx_cite ltx_citemacro_citet">Yassine et al. (<a href="#bib.bib22" title="" class="ltx_ref">2020</a>)</cite>, BPEmb embeddings models generate better parsing on address from India, even if the language and address pattern was unseen during training compared to FastText embeddings model.
However, this increase in generalization performance comes at the cost of longer inference time (will be discussed in <a href="#S4" title="4 Practical results ‣ Deepparse : An Extendable, and Fine-Tunable State-Of-The-Art Library for Parsing Multinational Street Addresses" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">section 4</span></a>).
As shown in <cite class="ltx_cite ltx_citemacro_citet">Yassine et al. (<a href="#bib.bib21" title="" class="ltx_ref">2022</a>)</cite>, models using the attention mechanism also demonstrate the same improved generalization performance compared to their respective embeddings approaches but with the same cost of inference performance.
Thus, one must trade off generalization performance over inference performance.</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Developing a New Parser</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">One of the unique particularities of Deepparse is the ability to develop a new parser for one’s specific needs. Namely, one can fine-tune one of our pre-trained models for their specific needs using our public dataset or theirs.
Doing so can improve Deepparse’s performance on new data or unseen countries, giving Deepparse great flexibility.
As shown in <a href="#S3.F2" title="Figure 2 ‣ 3.3 Developing a New Parser ‣ 3 Implementation ‣ Deepparse : An Extendable, and Fine-Tunable State-Of-The-Art Library for Parsing Multinational Street Addresses" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 2</span></a>, developing (i.e. fine-tuning) a new parser using our pre-trained public models is relatively easy and can be done with a few Python lines of code.</p>
</div>
<figure id="S3.F2" class="ltx_figure">
<div id="S3.F2.3" class="ltx_listing ltx_lstlisting ltx_align_center ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,YWRkcmVzc19wYXJzZXIucmV0cmFpbihkYXRhc2V0LCB0cmFpbl9yYXRpbz0wLjgsIGVwb2Nocz01KQ==" download="">⬇</a></div>
<div id="lstnumberx1" class="ltx_listingline">
<span id="lstnumberx1.1" class="ltx_text ltx_lst_identifier">address_parser</span>.<span id="lstnumberx1.2" class="ltx_text ltx_lst_identifier">retrain</span>(<span id="lstnumberx1.3" class="ltx_text ltx_lst_identifier">dataset</span>,<span id="lstnumberx1.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx1.5" class="ltx_text ltx_lst_identifier">train_ratio</span>=0.8,<span id="lstnumberx1.6" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx1.7" class="ltx_text ltx_lst_identifier">epochs</span>=5)
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Code example to fine-tune our <span id="S3.F2.6.1" class="ltx_text ltx_font_typewriter">"FastText"</span> pre-trained model on a new <span id="S3.F2.7.2" class="ltx_text ltx_font_typewriter">dataset</span> for <math id="S3.F2.2.m1.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S3.F2.2.m1.1b"><mn id="S3.F2.2.m1.1.1" xref="S3.F2.2.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S3.F2.2.m1.1c"><cn type="integer" id="S3.F2.2.m1.1.1.cmml" xref="S3.F2.2.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.2.m1.1d">5</annotation></semantics></math> epochs using a 80-20 % train-evaluation dataset ratio.</figcaption>
</figure>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">Moreover, as shown in <a href="#S3.F3" title="Figure 3 ‣ 3.3 Developing a New Parser ‣ 3 Implementation ‣ Deepparse : An Extendable, and Fine-Tunable State-Of-The-Art Library for Parsing Multinational Street Addresses" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 3</span></a>, one can also use Deepparse to retrain our pre-trained models on new prediction tags easily, and it is not restricted to the ones we have used during training, making it flexible for new addresses pattern.</p>
</div>
<figure id="S3.F3" class="ltx_figure">
<div id="S3.F3.1" class="ltx_listing ltx_lstlisting ltx_align_center ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,bmV3X3RhZ19kaWN0aW9uYXJ5ID0geyJBVGFnIjogMCwgIkFub3RoZXJUYWciOiAxLCAiRU9TIjogMn0KYWRkcmVzc19wYXJzZXIucmV0cmFpbihkYXRhc2V0LCBwcmVkaWN0aW9uX3RhZ3M9dGFnX2RpY3Rpb25hcnkp" download="">⬇</a></div>
<div id="lstnumberx2" class="ltx_listingline">
<span id="lstnumberx2.1" class="ltx_text ltx_lst_identifier">new_tag_dictionary</span><span id="lstnumberx2.2" class="ltx_text ltx_lst_space"> </span>=<span id="lstnumberx2.3" class="ltx_text ltx_lst_space"> </span>{"<span id="lstnumberx2.4" class="ltx_text ltx_lst_identifier">ATag</span>":<span id="lstnumberx2.5" class="ltx_text ltx_lst_space"> </span>0,<span id="lstnumberx2.6" class="ltx_text ltx_lst_space"> </span>"<span id="lstnumberx2.7" class="ltx_text ltx_lst_identifier">AnotherTag</span>":<span id="lstnumberx2.8" class="ltx_text ltx_lst_space"> </span>1,<span id="lstnumberx2.9" class="ltx_text ltx_lst_space"> </span>"<span id="lstnumberx2.10" class="ltx_text ltx_lst_identifier">EOS</span>":<span id="lstnumberx2.11" class="ltx_text ltx_lst_space"> </span>2}
</div>
<div id="lstnumberx3" class="ltx_listingline">
<span id="lstnumberx3.1" class="ltx_text ltx_lst_identifier">address_parser</span>.<span id="lstnumberx3.2" class="ltx_text ltx_lst_identifier">retrain</span>(<span id="lstnumberx3.3" class="ltx_text ltx_lst_identifier">dataset</span>,<span id="lstnumberx3.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx3.5" class="ltx_text ltx_lst_identifier">prediction_tags</span>=<span id="lstnumberx3.6" class="ltx_text ltx_lst_identifier">tag_dictionary</span>)
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Code example to retrained our <span id="S3.F3.5.1" class="ltx_text ltx_font_typewriter">"FastText"</span> pre-trained model on a new <span id="S3.F3.6.2" class="ltx_text ltx_font_typewriter">dataset</span> with new <span id="S3.F3.7.3" class="ltx_text ltx_font_typewriter">tags</span>.</figcaption>
</figure>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p">Finally, as shown in <a href="#S3.F4" title="Figure 4 ‣ 3.3 Developing a New Parser ‣ 3 Implementation ‣ Deepparse : An Extendable, and Fine-Tunable State-Of-The-Art Library for Parsing Multinational Street Addresses" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 4</span></a> it is also possible to easily reconfigure the tagging model architecture to either create a smaller architecture, thus potentially reducing memory usage and inference time, or increase it to improve performance on more complex address data. Also, one can do all of the above at the same time.</p>
</div>
<figure id="S3.F4" class="ltx_figure">
<div id="S3.F4.1" class="ltx_listing ltx_lstlisting ltx_align_center ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,c2VxMnNlcV9wYXJhbXMgPSB7ICJlbmNvZGVyX2hpZGRlbl9zaXplIjogNTEyLCAiZGVjb2Rlcl9oaWRkZW5fc2l6ZSI6IDUxMn0KYWRkcmVzc19wYXJzZXIucmV0cmFpbihkYXRhc2V0LCBzZXEyc2VxX3BhcmFtcz1zZXEyc2VxX3BhcmFtcyk=" download="">⬇</a></div>
<div id="lstnumberx4" class="ltx_listingline">
<span id="lstnumberx4.1" class="ltx_text ltx_lst_identifier">seq2seq_params</span><span id="lstnumberx4.2" class="ltx_text ltx_lst_space"> </span>=<span id="lstnumberx4.3" class="ltx_text ltx_lst_space"> </span>{<span id="lstnumberx4.4" class="ltx_text ltx_lst_space"> </span>"<span id="lstnumberx4.5" class="ltx_text ltx_lst_identifier">encoder_hidden_size</span>":<span id="lstnumberx4.6" class="ltx_text ltx_lst_space"> </span>512,<span id="lstnumberx4.7" class="ltx_text ltx_lst_space"> </span>"<span id="lstnumberx4.8" class="ltx_text ltx_lst_identifier">decoder_hidden_size</span>":<span id="lstnumberx4.9" class="ltx_text ltx_lst_space"> </span>512}
</div>
<div id="lstnumberx5" class="ltx_listingline">
<span id="lstnumberx5.1" class="ltx_text ltx_lst_identifier">address_parser</span>.<span id="lstnumberx5.2" class="ltx_text ltx_lst_identifier">retrain</span>(<span id="lstnumberx5.3" class="ltx_text ltx_lst_identifier">dataset</span>,<span id="lstnumberx5.4" class="ltx_text ltx_lst_space"> </span><span id="lstnumberx5.5" class="ltx_text ltx_lst_identifier">seq2seq_params</span>=<span id="lstnumberx5.6" class="ltx_text ltx_lst_identifier">seq2seq_params</span>)
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Code example to train a new model using our Seq2Seq architecture with a different configuration (i.e. encoder and decoder hidden size).</figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Practical results</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.2" class="ltx_p">In this section, since Libpostal and Deeparse are comparable in terms of accuracy, both are almost perfect; we benchmark Deepparse memory usage and inference time with 183,000 addresses of the Deepparse dataset.
Our parsing experiment processes 183,000 addresses using different batch sizes (<math id="S4.p1.1.m1.3" class="ltx_Math" alttext="2^{0},\dots,2^{9}" display="inline"><semantics id="S4.p1.1.m1.3a"><mrow id="S4.p1.1.m1.3.3.2" xref="S4.p1.1.m1.3.3.3.cmml"><msup id="S4.p1.1.m1.2.2.1.1" xref="S4.p1.1.m1.2.2.1.1.cmml"><mn id="S4.p1.1.m1.2.2.1.1.2" xref="S4.p1.1.m1.2.2.1.1.2.cmml">2</mn><mn id="S4.p1.1.m1.2.2.1.1.3" xref="S4.p1.1.m1.2.2.1.1.3.cmml">0</mn></msup><mo id="S4.p1.1.m1.3.3.2.3" xref="S4.p1.1.m1.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">…</mi><mo id="S4.p1.1.m1.3.3.2.4" xref="S4.p1.1.m1.3.3.3.cmml">,</mo><msup id="S4.p1.1.m1.3.3.2.2" xref="S4.p1.1.m1.3.3.2.2.cmml"><mn id="S4.p1.1.m1.3.3.2.2.2" xref="S4.p1.1.m1.3.3.2.2.2.cmml">2</mn><mn id="S4.p1.1.m1.3.3.2.2.3" xref="S4.p1.1.m1.3.3.2.2.3.cmml">9</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.3b"><list id="S4.p1.1.m1.3.3.3.cmml" xref="S4.p1.1.m1.3.3.2"><apply id="S4.p1.1.m1.2.2.1.1.cmml" xref="S4.p1.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S4.p1.1.m1.2.2.1.1.1.cmml" xref="S4.p1.1.m1.2.2.1.1">superscript</csymbol><cn type="integer" id="S4.p1.1.m1.2.2.1.1.2.cmml" xref="S4.p1.1.m1.2.2.1.1.2">2</cn><cn type="integer" id="S4.p1.1.m1.2.2.1.1.3.cmml" xref="S4.p1.1.m1.2.2.1.1.3">0</cn></apply><ci id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1">…</ci><apply id="S4.p1.1.m1.3.3.2.2.cmml" xref="S4.p1.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="S4.p1.1.m1.3.3.2.2.1.cmml" xref="S4.p1.1.m1.3.3.2.2">superscript</csymbol><cn type="integer" id="S4.p1.1.m1.3.3.2.2.2.cmml" xref="S4.p1.1.m1.3.3.2.2.2">2</cn><cn type="integer" id="S4.p1.1.m1.3.3.2.2.3.cmml" xref="S4.p1.1.m1.3.3.2.2.3">9</cn></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.3c">2^{0},\dots,2^{9}</annotation></semantics></math>) and assesses memory usage and inference time performance for Libpostal and Deepparse.
Since Deepparse can batch address, we assess the inference time as the average processing time per address (i.e. <math id="S4.p1.2.m2.2" class="ltx_Math" alttext="\frac{\text{Total time to process all addresses}}{183,000}=\text{time per address}" display="inline"><semantics id="S4.p1.2.m2.2a"><mrow id="S4.p1.2.m2.2.3" xref="S4.p1.2.m2.2.3.cmml"><mfrac id="S4.p1.2.m2.2.2" xref="S4.p1.2.m2.2.2.cmml"><mtext id="S4.p1.2.m2.2.2.4" xref="S4.p1.2.m2.2.2.4a.cmml">Total time to process all addresses</mtext><mrow id="S4.p1.2.m2.2.2.2.4" xref="S4.p1.2.m2.2.2.2.3.cmml"><mn id="S4.p1.2.m2.1.1.1.1" xref="S4.p1.2.m2.1.1.1.1.cmml">183</mn><mo id="S4.p1.2.m2.2.2.2.4.1" xref="S4.p1.2.m2.2.2.2.3.cmml">,</mo><mn id="S4.p1.2.m2.2.2.2.2" xref="S4.p1.2.m2.2.2.2.2.cmml">000</mn></mrow></mfrac><mo id="S4.p1.2.m2.2.3.1" xref="S4.p1.2.m2.2.3.1.cmml">=</mo><mtext id="S4.p1.2.m2.2.3.2" xref="S4.p1.2.m2.2.3.2a.cmml">time per address</mtext></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.2b"><apply id="S4.p1.2.m2.2.3.cmml" xref="S4.p1.2.m2.2.3"><eq id="S4.p1.2.m2.2.3.1.cmml" xref="S4.p1.2.m2.2.3.1"></eq><apply id="S4.p1.2.m2.2.2.cmml" xref="S4.p1.2.m2.2.2"><divide id="S4.p1.2.m2.2.2.3.cmml" xref="S4.p1.2.m2.2.2"></divide><ci id="S4.p1.2.m2.2.2.4a.cmml" xref="S4.p1.2.m2.2.2.4"><mtext mathsize="70%" id="S4.p1.2.m2.2.2.4.cmml" xref="S4.p1.2.m2.2.2.4">Total time to process all addresses</mtext></ci><list id="S4.p1.2.m2.2.2.2.3.cmml" xref="S4.p1.2.m2.2.2.2.4"><cn type="integer" id="S4.p1.2.m2.1.1.1.1.cmml" xref="S4.p1.2.m2.1.1.1.1">183</cn><cn type="integer" id="S4.p1.2.m2.2.2.2.2.cmml" xref="S4.p1.2.m2.2.2.2.2">000</cn></list></apply><ci id="S4.p1.2.m2.2.3.2a.cmml" xref="S4.p1.2.m2.2.3.2"><mtext id="S4.p1.2.m2.2.3.2.cmml" xref="S4.p1.2.m2.2.3.2">time per address</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.2c">\frac{\text{Total time to process all addresses}}{183,000}=\text{time per address}</annotation></semantics></math>). Libpostal does not offer batching functionality. The experiment used a GPU and a CPU to assess the accelerator’s gain. Thus, we also assess GPU memory usage in our experiment that uses such devices.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">Our experiment was conducted on Linux OS 22.04, with the latest Python version (i.e. 3.11), Python memory_profiler 0.61.0, Torch 2.0 and CUDA 11.7 (done March 21, 2023). Our GPU device is an RTX 2080.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p"><a href="#S4.T1" title="Table 1 ‣ 4 Practical results ‣ Deepparse : An Extendable, and Fine-Tunable State-Of-The-Art Library for Parsing Multinational Street Addresses" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 1</span></a> and <a href="#S4.T2" title="Table 2 ‣ 4 Practical results ‣ Deepparse : An Extendable, and Fine-Tunable State-Of-The-Art Library for Parsing Multinational Street Addresses" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 2</span></a> present our experiment results using respectively a GPU device or not with or without using batch processing.
In both tables, we can see that Libpostal achieved better inference time performance. However, Deepparse still achieved interesting performance, particularly with batching that reduced by one order of magnitude the average processing time of execution.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<div id="S4.T1.19" class="ltx_inline-block ltx_transformed_outer" style="width:216.8pt;height:85pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-82.1pt,32.2pt) scale(0.568971278660323,0.568971278660323) ;">
<table id="S4.T1.19.19" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.19.19.20.1" class="ltx_tr">
<th id="S4.T1.19.19.20.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="S4.T1.19.19.20.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<table id="S4.T1.19.19.20.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.19.19.20.1.2.1.1" class="ltx_tr">
<td id="S4.T1.19.19.20.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.19.19.20.1.2.1.1.1.1" class="ltx_text ltx_font_bold">GPU</span></td>
</tr>
<tr id="S4.T1.19.19.20.1.2.1.2" class="ltx_tr">
<td id="S4.T1.19.19.20.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.19.19.20.1.2.1.2.1.1" class="ltx_text ltx_font_bold">Memory usage</span></td>
</tr>
<tr id="S4.T1.19.19.20.1.2.1.3" class="ltx_tr">
<td id="S4.T1.19.19.20.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.19.19.20.1.2.1.3.1.1" class="ltx_text ltx_font_bold">(GB)</span></td>
</tr>
</table>
</th>
<th id="S4.T1.19.19.20.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<table id="S4.T1.19.19.20.1.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.19.19.20.1.3.1.1" class="ltx_tr">
<td id="S4.T1.19.19.20.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.19.19.20.1.3.1.1.1.1" class="ltx_text ltx_font_bold">RAM</span></td>
</tr>
<tr id="S4.T1.19.19.20.1.3.1.2" class="ltx_tr">
<td id="S4.T1.19.19.20.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.19.19.20.1.3.1.2.1.1" class="ltx_text ltx_font_bold">usage</span></td>
</tr>
<tr id="S4.T1.19.19.20.1.3.1.3" class="ltx_tr">
<td id="S4.T1.19.19.20.1.3.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.19.19.20.1.3.1.3.1.1" class="ltx_text ltx_font_bold">(GB)</span></td>
</tr>
</table>
</th>
<th id="S4.T1.19.19.20.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<table id="S4.T1.19.19.20.1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.19.19.20.1.4.1.1" class="ltx_tr">
<td id="S4.T1.19.19.20.1.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.19.19.20.1.4.1.1.1.1" class="ltx_text ltx_font_bold">Mean time</span></td>
</tr>
<tr id="S4.T1.19.19.20.1.4.1.2" class="ltx_tr">
<td id="S4.T1.19.19.20.1.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.19.19.20.1.4.1.2.1.1" class="ltx_text ltx_font_bold">of execution</span></td>
</tr>
<tr id="S4.T1.19.19.20.1.4.1.3" class="ltx_tr">
<td id="S4.T1.19.19.20.1.4.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.19.19.20.1.4.1.3.1.1" class="ltx_text ltx_font_bold">(not batched) (s)</span></td>
</tr>
</table>
</th>
<th id="S4.T1.19.19.20.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<table id="S4.T1.19.19.20.1.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.19.19.20.1.5.1.1" class="ltx_tr">
<td id="S4.T1.19.19.20.1.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.19.19.20.1.5.1.1.1.1" class="ltx_text ltx_font_bold">Mean time</span></td>
</tr>
<tr id="S4.T1.19.19.20.1.5.1.2" class="ltx_tr">
<td id="S4.T1.19.19.20.1.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.19.19.20.1.5.1.2.1.1" class="ltx_text ltx_font_bold">of execution</span></td>
</tr>
<tr id="S4.T1.19.19.20.1.5.1.3" class="ltx_tr">
<td id="S4.T1.19.19.20.1.5.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.19.19.20.1.5.1.3.1.1" class="ltx_text ltx_font_bold">(batched) (s)</span></td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.4.4.4" class="ltx_tr">
<th id="S4.T1.4.4.4.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S4.T1.4.4.4.5.1" class="ltx_text ltx_font_bold">fastText</span></th>
<td id="S4.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">
<math id="S4.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T1.1.1.1.1.m1.1a"><mo id="S4.T1.1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.1.m1.1c">\sim</annotation></semantics></math>1</td>
<td id="S4.T1.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">
<math id="S4.T1.2.2.2.2.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T1.2.2.2.2.m1.1a"><mo id="S4.T1.2.2.2.2.m1.1.1" xref="S4.T1.2.2.2.2.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.2.m1.1b"><csymbol cd="latexml" id="S4.T1.2.2.2.2.m1.1.1.cmml" xref="S4.T1.2.2.2.2.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.2.m1.1c">\sim</annotation></semantics></math>8</td>
<td id="S4.T1.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t">
<math id="S4.T1.3.3.3.3.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T1.3.3.3.3.m1.1a"><mo id="S4.T1.3.3.3.3.m1.1.1" xref="S4.T1.3.3.3.3.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.3.m1.1b"><csymbol cd="latexml" id="S4.T1.3.3.3.3.m1.1.1.cmml" xref="S4.T1.3.3.3.3.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.3.m1.1c">\sim</annotation></semantics></math>0.0023</td>
<td id="S4.T1.4.4.4.4" class="ltx_td ltx_align_center ltx_border_t">
<math id="S4.T1.4.4.4.4.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T1.4.4.4.4.m1.1a"><mo id="S4.T1.4.4.4.4.m1.1.1" xref="S4.T1.4.4.4.4.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.4.4.m1.1b"><csymbol cd="latexml" id="S4.T1.4.4.4.4.m1.1.1.cmml" xref="S4.T1.4.4.4.4.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.4.4.m1.1c">\sim</annotation></semantics></math>0.0004</td>
</tr>
<tr id="S4.T1.8.8.8" class="ltx_tr">
<th id="S4.T1.8.8.8.5" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.8.8.8.5.1" class="ltx_text ltx_font_bold">fastTextAttention</span></th>
<td id="S4.T1.5.5.5.1" class="ltx_td ltx_align_center">
<math id="S4.T1.5.5.5.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T1.5.5.5.1.m1.1a"><mo id="S4.T1.5.5.5.1.m1.1.1" xref="S4.T1.5.5.5.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T1.5.5.5.1.m1.1b"><csymbol cd="latexml" id="S4.T1.5.5.5.1.m1.1.1.cmml" xref="S4.T1.5.5.5.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.5.5.1.m1.1c">\sim</annotation></semantics></math>1.1</td>
<td id="S4.T1.6.6.6.2" class="ltx_td ltx_align_center">
<math id="S4.T1.6.6.6.2.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T1.6.6.6.2.m1.1a"><mo id="S4.T1.6.6.6.2.m1.1.1" xref="S4.T1.6.6.6.2.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T1.6.6.6.2.m1.1b"><csymbol cd="latexml" id="S4.T1.6.6.6.2.m1.1.1.cmml" xref="S4.T1.6.6.6.2.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.6.6.2.m1.1c">\sim</annotation></semantics></math>8</td>
<td id="S4.T1.7.7.7.3" class="ltx_td ltx_align_center">
<math id="S4.T1.7.7.7.3.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T1.7.7.7.3.m1.1a"><mo id="S4.T1.7.7.7.3.m1.1.1" xref="S4.T1.7.7.7.3.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T1.7.7.7.3.m1.1b"><csymbol cd="latexml" id="S4.T1.7.7.7.3.m1.1.1.cmml" xref="S4.T1.7.7.7.3.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.7.7.3.m1.1c">\sim</annotation></semantics></math>0.0043</td>
<td id="S4.T1.8.8.8.4" class="ltx_td ltx_align_center">
<math id="S4.T1.8.8.8.4.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T1.8.8.8.4.m1.1a"><mo id="S4.T1.8.8.8.4.m1.1.1" xref="S4.T1.8.8.8.4.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T1.8.8.8.4.m1.1b"><csymbol cd="latexml" id="S4.T1.8.8.8.4.m1.1.1.cmml" xref="S4.T1.8.8.8.4.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.8.8.8.4.m1.1c">\sim</annotation></semantics></math>0.0007</td>
</tr>
<tr id="S4.T1.12.12.12" class="ltx_tr">
<th id="S4.T1.12.12.12.5" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.12.12.12.5.1" class="ltx_text ltx_font_bold">BPEmb</span></th>
<td id="S4.T1.9.9.9.1" class="ltx_td ltx_align_center">
<math id="S4.T1.9.9.9.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T1.9.9.9.1.m1.1a"><mo id="S4.T1.9.9.9.1.m1.1.1" xref="S4.T1.9.9.9.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T1.9.9.9.1.m1.1b"><csymbol cd="latexml" id="S4.T1.9.9.9.1.m1.1.1.cmml" xref="S4.T1.9.9.9.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.9.9.9.1.m1.1c">\sim</annotation></semantics></math>1</td>
<td id="S4.T1.10.10.10.2" class="ltx_td ltx_align_center">
<math id="S4.T1.10.10.10.2.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T1.10.10.10.2.m1.1a"><mo id="S4.T1.10.10.10.2.m1.1.1" xref="S4.T1.10.10.10.2.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T1.10.10.10.2.m1.1b"><csymbol cd="latexml" id="S4.T1.10.10.10.2.m1.1.1.cmml" xref="S4.T1.10.10.10.2.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.10.10.10.2.m1.1c">\sim</annotation></semantics></math>1</td>
<td id="S4.T1.11.11.11.3" class="ltx_td ltx_align_center">
<math id="S4.T1.11.11.11.3.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T1.11.11.11.3.m1.1a"><mo id="S4.T1.11.11.11.3.m1.1.1" xref="S4.T1.11.11.11.3.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T1.11.11.11.3.m1.1b"><csymbol cd="latexml" id="S4.T1.11.11.11.3.m1.1.1.cmml" xref="S4.T1.11.11.11.3.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.11.11.11.3.m1.1c">\sim</annotation></semantics></math>0.0055</td>
<td id="S4.T1.12.12.12.4" class="ltx_td ltx_align_center">
<math id="S4.T1.12.12.12.4.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T1.12.12.12.4.m1.1a"><mo id="S4.T1.12.12.12.4.m1.1.1" xref="S4.T1.12.12.12.4.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T1.12.12.12.4.m1.1b"><csymbol cd="latexml" id="S4.T1.12.12.12.4.m1.1.1.cmml" xref="S4.T1.12.12.12.4.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.12.12.12.4.m1.1c">\sim</annotation></semantics></math>0.0015</td>
</tr>
<tr id="S4.T1.16.16.16" class="ltx_tr">
<th id="S4.T1.16.16.16.5" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.16.16.16.5.1" class="ltx_text ltx_font_bold">BPEmbAttention</span></th>
<td id="S4.T1.13.13.13.1" class="ltx_td ltx_align_center">
<math id="S4.T1.13.13.13.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T1.13.13.13.1.m1.1a"><mo id="S4.T1.13.13.13.1.m1.1.1" xref="S4.T1.13.13.13.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T1.13.13.13.1.m1.1b"><csymbol cd="latexml" id="S4.T1.13.13.13.1.m1.1.1.cmml" xref="S4.T1.13.13.13.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.13.13.13.1.m1.1c">\sim</annotation></semantics></math>1.1</td>
<td id="S4.T1.14.14.14.2" class="ltx_td ltx_align_center">
<math id="S4.T1.14.14.14.2.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T1.14.14.14.2.m1.1a"><mo id="S4.T1.14.14.14.2.m1.1.1" xref="S4.T1.14.14.14.2.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T1.14.14.14.2.m1.1b"><csymbol cd="latexml" id="S4.T1.14.14.14.2.m1.1.1.cmml" xref="S4.T1.14.14.14.2.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.14.14.14.2.m1.1c">\sim</annotation></semantics></math>1</td>
<td id="S4.T1.15.15.15.3" class="ltx_td ltx_align_center">
<math id="S4.T1.15.15.15.3.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T1.15.15.15.3.m1.1a"><mo id="S4.T1.15.15.15.3.m1.1.1" xref="S4.T1.15.15.15.3.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T1.15.15.15.3.m1.1b"><csymbol cd="latexml" id="S4.T1.15.15.15.3.m1.1.1.cmml" xref="S4.T1.15.15.15.3.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.15.15.15.3.m1.1c">\sim</annotation></semantics></math>0.0081</td>
<td id="S4.T1.16.16.16.4" class="ltx_td ltx_align_center">
<math id="S4.T1.16.16.16.4.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T1.16.16.16.4.m1.1a"><mo id="S4.T1.16.16.16.4.m1.1.1" xref="S4.T1.16.16.16.4.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T1.16.16.16.4.m1.1b"><csymbol cd="latexml" id="S4.T1.16.16.16.4.m1.1.1.cmml" xref="S4.T1.16.16.16.4.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.16.16.16.4.m1.1c">\sim</annotation></semantics></math>0.0019</td>
</tr>
<tr id="S4.T1.19.19.19" class="ltx_tr">
<th id="S4.T1.19.19.19.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t">Libpostal</th>
<td id="S4.T1.19.19.19.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0</td>
<td id="S4.T1.17.17.17.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">
<math id="S4.T1.17.17.17.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T1.17.17.17.1.m1.1a"><mo id="S4.T1.17.17.17.1.m1.1.1" xref="S4.T1.17.17.17.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T1.17.17.17.1.m1.1b"><csymbol cd="latexml" id="S4.T1.17.17.17.1.m1.1.1.cmml" xref="S4.T1.17.17.17.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.17.17.17.1.m1.1c">\sim</annotation></semantics></math>2.3</td>
<td id="S4.T1.18.18.18.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">
<math id="S4.T1.18.18.18.2.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T1.18.18.18.2.m1.1a"><mo id="S4.T1.18.18.18.2.m1.1.1" xref="S4.T1.18.18.18.2.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T1.18.18.18.2.m1.1b"><csymbol cd="latexml" id="S4.T1.18.18.18.2.m1.1.1.cmml" xref="S4.T1.18.18.18.2.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.18.18.18.2.m1.1c">\sim</annotation></semantics></math>0.00004</td>
<td id="S4.T1.19.19.19.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">
<math id="S4.T1.19.19.19.3.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T1.19.19.19.3.m1.1a"><mo id="S4.T1.19.19.19.3.m1.1.1" xref="S4.T1.19.19.19.3.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T1.19.19.19.3.m1.1b"><csymbol cd="latexml" id="S4.T1.19.19.19.3.m1.1.1.cmml" xref="S4.T1.19.19.19.3.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.19.19.19.3.m1.1c">\sim</annotation></semantics></math>N/A</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>GPU and RAM usage and average processing time to parse 183,000 addresses using a GPU device with or without batching.</figcaption>
</figure>
<figure id="S4.T2" class="ltx_table">
<div id="S4.T2.15" class="ltx_inline-block ltx_transformed_outer" style="width:216.8pt;height:108.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-41.4pt,20.6pt) scale(0.723569859680349,0.723569859680349) ;">
<table id="S4.T2.15.15" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.15.15.16.1" class="ltx_tr">
<th id="S4.T2.15.15.16.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="S4.T2.15.15.16.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<table id="S4.T2.15.15.16.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.15.15.16.1.2.1.1" class="ltx_tr">
<td id="S4.T2.15.15.16.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T2.15.15.16.1.2.1.1.1.1" class="ltx_text ltx_font_bold">RAM</span></td>
</tr>
<tr id="S4.T2.15.15.16.1.2.1.2" class="ltx_tr">
<td id="S4.T2.15.15.16.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T2.15.15.16.1.2.1.2.1.1" class="ltx_text ltx_font_bold">usage</span></td>
</tr>
<tr id="S4.T2.15.15.16.1.2.1.3" class="ltx_tr">
<td id="S4.T2.15.15.16.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T2.15.15.16.1.2.1.3.1.1" class="ltx_text ltx_font_bold">(GB)</span></td>
</tr>
</table>
</th>
<th id="S4.T2.15.15.16.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<table id="S4.T2.15.15.16.1.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.15.15.16.1.3.1.1" class="ltx_tr">
<td id="S4.T2.15.15.16.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T2.15.15.16.1.3.1.1.1.1" class="ltx_text ltx_font_bold">Mean time</span></td>
</tr>
<tr id="S4.T2.15.15.16.1.3.1.2" class="ltx_tr">
<td id="S4.T2.15.15.16.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T2.15.15.16.1.3.1.2.1.1" class="ltx_text ltx_font_bold">of execution</span></td>
</tr>
<tr id="S4.T2.15.15.16.1.3.1.3" class="ltx_tr">
<td id="S4.T2.15.15.16.1.3.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T2.15.15.16.1.3.1.3.1.1" class="ltx_text ltx_font_bold">(not batched) (s)</span></td>
</tr>
</table>
</th>
<th id="S4.T2.15.15.16.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<table id="S4.T2.15.15.16.1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.15.15.16.1.4.1.1" class="ltx_tr">
<td id="S4.T2.15.15.16.1.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T2.15.15.16.1.4.1.1.1.1" class="ltx_text ltx_font_bold">Mean time</span></td>
</tr>
<tr id="S4.T2.15.15.16.1.4.1.2" class="ltx_tr">
<td id="S4.T2.15.15.16.1.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T2.15.15.16.1.4.1.2.1.1" class="ltx_text ltx_font_bold">of execution</span></td>
</tr>
<tr id="S4.T2.15.15.16.1.4.1.3" class="ltx_tr">
<td id="S4.T2.15.15.16.1.4.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T2.15.15.16.1.4.1.3.1.1" class="ltx_text ltx_font_bold">(batched) (s)</span></td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.3.3.3" class="ltx_tr">
<th id="S4.T2.3.3.3.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S4.T2.3.3.3.4.1" class="ltx_text ltx_font_bold">fastText</span></th>
<td id="S4.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">
<math id="S4.T2.1.1.1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T2.1.1.1.1.m1.1a"><mo id="S4.T2.1.1.1.1.m1.1.1" xref="S4.T2.1.1.1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T2.1.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.m1.1c">\sim</annotation></semantics></math>8</td>
<td id="S4.T2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">
<math id="S4.T2.2.2.2.2.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T2.2.2.2.2.m1.1a"><mo id="S4.T2.2.2.2.2.m1.1.1" xref="S4.T2.2.2.2.2.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.2.m1.1b"><csymbol cd="latexml" id="S4.T2.2.2.2.2.m1.1.1.cmml" xref="S4.T2.2.2.2.2.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.2.m1.1c">\sim</annotation></semantics></math>0.0128</td>
<td id="S4.T2.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t">
<math id="S4.T2.3.3.3.3.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T2.3.3.3.3.m1.1a"><mo id="S4.T2.3.3.3.3.m1.1.1" xref="S4.T2.3.3.3.3.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.3.3.m1.1b"><csymbol cd="latexml" id="S4.T2.3.3.3.3.m1.1.1.cmml" xref="S4.T2.3.3.3.3.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.3.3.m1.1c">\sim</annotation></semantics></math>0.0026</td>
</tr>
<tr id="S4.T2.6.6.6" class="ltx_tr">
<th id="S4.T2.6.6.6.4" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T2.6.6.6.4.1" class="ltx_text ltx_font_bold">fastTextAttention</span></th>
<td id="S4.T2.4.4.4.1" class="ltx_td ltx_align_center">
<math id="S4.T2.4.4.4.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T2.4.4.4.1.m1.1a"><mo id="S4.T2.4.4.4.1.m1.1.1" xref="S4.T2.4.4.4.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.4.1.m1.1b"><csymbol cd="latexml" id="S4.T2.4.4.4.1.m1.1.1.cmml" xref="S4.T2.4.4.4.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.4.1.m1.1c">\sim</annotation></semantics></math>8</td>
<td id="S4.T2.5.5.5.2" class="ltx_td ltx_align_center">
<math id="S4.T2.5.5.5.2.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T2.5.5.5.2.m1.1a"><mo id="S4.T2.5.5.5.2.m1.1.1" xref="S4.T2.5.5.5.2.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.5.2.m1.1b"><csymbol cd="latexml" id="S4.T2.5.5.5.2.m1.1.1.cmml" xref="S4.T2.5.5.5.2.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.5.2.m1.1c">\sim</annotation></semantics></math>0.0230</td>
<td id="S4.T2.6.6.6.3" class="ltx_td ltx_align_center">
<math id="S4.T2.6.6.6.3.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T2.6.6.6.3.m1.1a"><mo id="S4.T2.6.6.6.3.m1.1.1" xref="S4.T2.6.6.6.3.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T2.6.6.6.3.m1.1b"><csymbol cd="latexml" id="S4.T2.6.6.6.3.m1.1.1.cmml" xref="S4.T2.6.6.6.3.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.6.6.6.3.m1.1c">\sim</annotation></semantics></math>0.0057</td>
</tr>
<tr id="S4.T2.9.9.9" class="ltx_tr">
<th id="S4.T2.9.9.9.4" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T2.9.9.9.4.1" class="ltx_text ltx_font_bold">BPEmb</span></th>
<td id="S4.T2.7.7.7.1" class="ltx_td ltx_align_center">
<math id="S4.T2.7.7.7.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T2.7.7.7.1.m1.1a"><mo id="S4.T2.7.7.7.1.m1.1.1" xref="S4.T2.7.7.7.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T2.7.7.7.1.m1.1b"><csymbol cd="latexml" id="S4.T2.7.7.7.1.m1.1.1.cmml" xref="S4.T2.7.7.7.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.7.7.7.1.m1.1c">\sim</annotation></semantics></math>1</td>
<td id="S4.T2.8.8.8.2" class="ltx_td ltx_align_center">
<math id="S4.T2.8.8.8.2.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T2.8.8.8.2.m1.1a"><mo id="S4.T2.8.8.8.2.m1.1.1" xref="S4.T2.8.8.8.2.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T2.8.8.8.2.m1.1b"><csymbol cd="latexml" id="S4.T2.8.8.8.2.m1.1.1.cmml" xref="S4.T2.8.8.8.2.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.8.8.8.2.m1.1c">\sim</annotation></semantics></math>0.0179</td>
<td id="S4.T2.9.9.9.3" class="ltx_td ltx_align_center">
<math id="S4.T2.9.9.9.3.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T2.9.9.9.3.m1.1a"><mo id="S4.T2.9.9.9.3.m1.1.1" xref="S4.T2.9.9.9.3.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T2.9.9.9.3.m1.1b"><csymbol cd="latexml" id="S4.T2.9.9.9.3.m1.1.1.cmml" xref="S4.T2.9.9.9.3.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.9.9.9.3.m1.1c">\sim</annotation></semantics></math>0.0044</td>
</tr>
<tr id="S4.T2.12.12.12" class="ltx_tr">
<th id="S4.T2.12.12.12.4" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T2.12.12.12.4.1" class="ltx_text ltx_font_bold">BPEmbAttention</span></th>
<td id="S4.T2.10.10.10.1" class="ltx_td ltx_align_center">
<math id="S4.T2.10.10.10.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T2.10.10.10.1.m1.1a"><mo id="S4.T2.10.10.10.1.m1.1.1" xref="S4.T2.10.10.10.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T2.10.10.10.1.m1.1b"><csymbol cd="latexml" id="S4.T2.10.10.10.1.m1.1.1.cmml" xref="S4.T2.10.10.10.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.10.10.10.1.m1.1c">\sim</annotation></semantics></math>1</td>
<td id="S4.T2.11.11.11.2" class="ltx_td ltx_align_center">
<math id="S4.T2.11.11.11.2.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T2.11.11.11.2.m1.1a"><mo id="S4.T2.11.11.11.2.m1.1.1" xref="S4.T2.11.11.11.2.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T2.11.11.11.2.m1.1b"><csymbol cd="latexml" id="S4.T2.11.11.11.2.m1.1.1.cmml" xref="S4.T2.11.11.11.2.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.11.11.11.2.m1.1c">\sim</annotation></semantics></math>0.0286</td>
<td id="S4.T2.12.12.12.3" class="ltx_td ltx_align_center">
<math id="S4.T2.12.12.12.3.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T2.12.12.12.3.m1.1a"><mo id="S4.T2.12.12.12.3.m1.1.1" xref="S4.T2.12.12.12.3.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T2.12.12.12.3.m1.1b"><csymbol cd="latexml" id="S4.T2.12.12.12.3.m1.1.1.cmml" xref="S4.T2.12.12.12.3.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.12.12.12.3.m1.1c">\sim</annotation></semantics></math>0.0075</td>
</tr>
<tr id="S4.T2.15.15.15" class="ltx_tr">
<th id="S4.T2.15.15.15.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t">Libpostal</th>
<td id="S4.T2.13.13.13.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">
<math id="S4.T2.13.13.13.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T2.13.13.13.1.m1.1a"><mo id="S4.T2.13.13.13.1.m1.1.1" xref="S4.T2.13.13.13.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T2.13.13.13.1.m1.1b"><csymbol cd="latexml" id="S4.T2.13.13.13.1.m1.1.1.cmml" xref="S4.T2.13.13.13.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.13.13.13.1.m1.1c">\sim</annotation></semantics></math>1</td>
<td id="S4.T2.14.14.14.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">
<math id="S4.T2.14.14.14.2.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T2.14.14.14.2.m1.1a"><mo id="S4.T2.14.14.14.2.m1.1.1" xref="S4.T2.14.14.14.2.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T2.14.14.14.2.m1.1b"><csymbol cd="latexml" id="S4.T2.14.14.14.2.m1.1.1.cmml" xref="S4.T2.14.14.14.2.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.14.14.14.2.m1.1c">\sim</annotation></semantics></math>0.00004</td>
<td id="S4.T2.15.15.15.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">
<math id="S4.T2.15.15.15.3.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T2.15.15.15.3.m1.1a"><mo id="S4.T2.15.15.15.3.m1.1.1" xref="S4.T2.15.15.15.3.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T2.15.15.15.3.m1.1b"><csymbol cd="latexml" id="S4.T2.15.15.15.3.m1.1.1.cmml" xref="S4.T2.15.15.15.3.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.15.15.15.3.m1.1c">\sim</annotation></semantics></math>N/A</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>RAM usage and average processing time to parse 183,000 addresses using only CPU with or without batching.</figcaption>
</figure>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Future Development and Maintaining the Library</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">As our development roadmap, we plan to improve the documentation by adding a training guide on how one can develop its address parser.
Also, we plan to offer new deep learning architecture that leverages more recent progress, such as a Transformer based architecture and to support more words embedding models, such as contextualized embeddings like ELMO embeddings <cite class="ltx_cite ltx_citemacro_citep">(Peters et al., <a href="#bib.bib13" title="" class="ltx_ref">2018</a>)</cite>.
Moreover, we plan to offer a minimalist application to address parsing for coding laypersons.
Finally, we aim at improving inference time performance by using recent integration of quantization technique <cite class="ltx_cite ltx_citemacro_citep">(Cheng et al., <a href="#bib.bib3" title="" class="ltx_ref">2018</a>; Wu et al., <a href="#bib.bib18" title="" class="ltx_ref">2020</a>)</cite> in PyTorch, namely, “performing computations and storing tensors at lower bitwidths than floating point precision” <cite class="ltx_cite ltx_citemacro_citep">(PyTorch, <a href="#bib.bib14" title="" class="ltx_ref">2023</a>)</cite>.
The library is maintained mainly by the library authors, and three to four releases are published yearly to improve and maintain the solution.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In conclusion, we have described Deepparse, an extendable and fine-tunable state-of-the-art library for parsing multinational street addresses. It is an open-source library, has over 99.9% test coverage and integrates easily with existing natural language processing pipelines. Deepparse offers great flexibility to users who can develop their address parser using our easy-to-use fine-tuning interface.
Although slower than the Libpostal alternative implemented in low-level language C, Deepparse successfully parses more than 99% of address components.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgment</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This research was supported by the Natural Sciences and Engineering Research Council of Canada (IRCPJ 529529-17) and a Canadian insurance company.
We wish to thank the reviewers for their comments regarding our work and methodology.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abid et al. (2018)</span>
<span class="ltx_bibblock">
N. Abid, A. ul Hasan, and F. Shafait. 2018.

</span>
<span class="ltx_bibblock">DeepParse: A Trainable Postal Address Parser.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Digital Image Computing: Techniques and Applications</em>, pages
1–8.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bahdanau et al. (2015)</span>
<span class="ltx_bibblock">
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1409.0473" title="" class="ltx_ref ltx_href">Neural machine translation by
jointly learning to align and translate</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al. (2018)</span>
<span class="ltx_bibblock">
Jian Cheng, Pei-song Wang, Gang Li, Qing-hao Hu, and Han-qing Lu. 2018.

</span>
<span class="ltx_bibblock">Recent Advances in Efficient Computation of Deep Convolutional
Neural Networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Frontiers of Information Technology &amp; Electronic Engineering</em>,
19:64–77.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conneau et al. (2017)</span>
<span class="ltx_bibblock">
Alexis Conneau, Guillaume Lample, Marc’Aurelio Ranzato, Ludovic Denoyer, and
Hervé Jégou. 2017.

</span>
<span class="ltx_bibblock">Word Translation Without Parallel Data.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Heinzerling and Strube (2019)</span>
<span class="ltx_bibblock">
Benjamin Heinzerling and Michael Strube. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P19-1027" title="" class="ltx_ref ltx_href">Sequence tagging with
contextual and non-contextual subword representations: A multilingual
evaluation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Annual Meeting of the Association for
Computational Linguistics</em>, pages 273–291.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. (2019)</span>
<span class="ltx_bibblock">
Yi-Ting Huang, Yu-Yuan Chen, Chih-Chun Yang, Yeali Sun, Shun-Wen Hsiao, and
Meng Chang Chen. 2019.

</span>
<span class="ltx_bibblock">Tagging Malware Intentions by Using Attention-Based
Sequence-To-Sequence Neural Network.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Information Security and Privacy</em>, pages 660–668. Springer.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jin and Yu (2021)</span>
<span class="ltx_bibblock">
Guozhe Jin and Zhezhou Yu. 2021.

</span>
<span class="ltx_bibblock">A Hierarchical Sequence-To-Sequence Model for Korean POS Tagging.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Transactions on Asian and Low-Resource Language Information
Processing</em>, 20(2):1–13.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Joulin et al. (2018)</span>
<span class="ltx_bibblock">
Armand Joulin, Piotr Bojanowski, Tomas Mikolov, Hervé Jégou, and Edouard
Grave. 2018.

</span>
<span class="ltx_bibblock">Loss in Translation: Learning Bilingual Word Mapping with a
Retrieval Criterion.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Conference on Empirical Methods in
Natural Language Processing</em>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2014)</span>
<span class="ltx_bibblock">
Xiang Li, Hakan Kardes, Xin Wang, and Ang Sun. 2014.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1145/2666310.2666471" title="" class="ltx_ref ltx_href">HMM-Based Address
Parsing: Efficiently Parsing Billions of Addresses on MapReduce</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM SIGSPATIAL International Conference
on Advances in Geographic Information Systems</em>, page 433–436. Association
for Computing Machinery.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(10)</span>
<span class="ltx_bibblock">
Shekoofeh Mokhtari, Ahmad Mahmoody, Dragomir Yankov, and Ning Xie.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1609/aaai.v33i01.33019547" title="" class="ltx_ref ltx_href">Tagging
Address Queries in Maps Search</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</em>,
33:9547–9551.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nagabhushan (2009)</span>
<span class="ltx_bibblock">
P Nagabhushan. 2009.

</span>
<span class="ltx_bibblock">A Soft Computing Model for Mapping Incomplete/Approximate Postal
Addresses to Mail Delivery Points.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Applied Soft Computing</em>, 9(2):806–816.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Omelianchuk et al. (2021)</span>
<span class="ltx_bibblock">
Kostiantyn Omelianchuk, Vipul Raheja, and Oleksandr Skurzhanskyi. 2021.

</span>
<span class="ltx_bibblock">Text Simplification by Tagging.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">arXiv:2103.05070</em>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peters et al. (2018)</span>
<span class="ltx_bibblock">
Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark,
Kenton Lee, and Luke Zettlemoyer. 2018.

</span>
<span class="ltx_bibblock">Deep Contextualized Word Representations.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">arXiv:1802.05365</em>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">PyTorch (2023)</span>
<span class="ltx_bibblock">
PyTorch. 2023.

</span>
<span class="ltx_bibblock">Quantization — PyTorch 2.0 documentation.

</span>
<span class="ltx_bibblock">Accessed online (30-07-2023)
<a target="_blank" href="https://pytorch.org/docs/stable/quantization.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://pytorch.org/docs/stable/quantization.html</a>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raman et al. (2022)</span>
<span class="ltx_bibblock">
Karthik Raman, Iftekhar Naim, Jiecao Chen, Kazuma Hashimoto, Kiran Yalasangi,
and Krishna Srinivasan. 2022.

</span>
<span class="ltx_bibblock">Transforming Sequence Tagging Into a Seq2Seq Task.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv:2203.08378</em>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sharma et al. (2018)</span>
<span class="ltx_bibblock">
S. Sharma, R. Ratti, I. Arora, A. Solanki, and G. Bhatt. 2018.

</span>
<span class="ltx_bibblock">Automated Parsing of Geographical Addresses: A Multilayer
Feedforward Neural Network Based Approach.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">IEEE International Conference on Semantic Computing</em>, pages
123–130.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2016)</span>
<span class="ltx_bibblock">
M. Wang, V. Haberland, A. Yeo, A. Martin, J. Howroyd, and J. M.
Bishop. 2016.

</span>
<span class="ltx_bibblock">A Probabilistic Address Parser Using Conditional Random Fields and
Stochastic Regular Grammar.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">International Conference on Data Mining Workshops</em>, pages
225–232.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2020)</span>
<span class="ltx_bibblock">
Hao Wu, Patrick Judd, Xiaojie Zhang, Mikhail Isaev, and Paulius Micikevicius.
2020.

</span>
<span class="ltx_bibblock">Integer Quantization for Deep Learning Inference: Principles and
Empirical Evaluation.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">arXiv:2004.09602</em>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2012)</span>
<span class="ltx_bibblock">
Sen Xu, Soren Flexner, and Vitor R. Carvalho. 2012.

</span>
<span class="ltx_bibblock">Geocoding billions of addresses: Toward a spatial record linkage
system with big data.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yassine and Beauchemin (2020)</span>
<span class="ltx_bibblock">
Marouane Yassine and David Beauchemin. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://deepparse.org" title="" class="ltx_ref ltx_href">Deepparse: A State-Of-The-Art Deep
Learning Multinational Addresses Parser</a>.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yassine et al. (2022)</span>
<span class="ltx_bibblock">
Marouane Yassine, David Beauchemin, François Laviolette, and Luc
Lamontagne. 2022.

</span>
<span class="ltx_bibblock">Multinational Address Parsing: A Zero-Shot Evaluation.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">International Journal of Information Science and Technology</em>,
6(3):40–50.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yassine et al. (2020)</span>
<span class="ltx_bibblock">
Marouane Yassine, David Beauchemin, François Laviolette, and Luc Lamontagne.
2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/CiSt49399.2021.9357170" title="" class="ltx_ref ltx_href">Leveraging
Subword Embeddings for Multinational Address Parsing</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">2020 IEEE Congress on Information Science and Technology</em>,
pages 353–360.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2311.11845" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2311.11846" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2311.11846">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2311.11846" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2311.11847" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 17:58:26 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
