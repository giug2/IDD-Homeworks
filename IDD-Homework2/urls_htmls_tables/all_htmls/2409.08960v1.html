<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Improving governance outcomes through AI documentation: Bridging theory and practice</title>
<!--Generated on Fri Sep 13 16:21:01 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Artificial intelligence,  documentation,  AI governance" lang="en" name="keywords"/>
<base href="/html/2409.08960v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#S1" title="In Improving governance outcomes through AI documentation: Bridging theory and practice"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#S2" title="In Improving governance outcomes through AI documentation: Bridging theory and practice"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>What organizations could document about AI systems</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#S3" title="In Improving governance outcomes through AI documentation: Bridging theory and practice"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methods</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#S3.SS1" title="In 3. Methods ‣ Improving governance outcomes through AI documentation: Bridging theory and practice"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Publication Sampling</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#S3.SS2" title="In 3. Methods ‣ Improving governance outcomes through AI documentation: Bridging theory and practice"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Data Analysis</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#S4" title="In Improving governance outcomes through AI documentation: Bridging theory and practice"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#S4.SS1" title="In 4. Results ‣ Improving governance outcomes through AI documentation: Bridging theory and practice"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Publication Sample</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#S4.SS2" title="In 4. Results ‣ Improving governance outcomes through AI documentation: Bridging theory and practice"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Potential Impacts &amp; Challenges</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#S4.SS2.SSS1" title="In 4.2. Potential Impacts &amp; Challenges ‣ 4. Results ‣ Improving governance outcomes through AI documentation: Bridging theory and practice"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.1 </span>Potential impact #1: Documentation could inform downstream stakeholders about effective and responsible use.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#S4.SS2.SSS2" title="In 4.2. Potential Impacts &amp; Challenges ‣ 4. Results ‣ Improving governance outcomes through AI documentation: Bridging theory and practice"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.2 </span>Potential impact #2: Documentation could support cross-functional collaboration and communication about AI risks.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#S4.SS2.SSS3" title="In 4.2. Potential Impacts &amp; Challenges ‣ 4. Results ‣ Improving governance outcomes through AI documentation: Bridging theory and practice"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.3 </span>Potential impact #3: Documentation could prompt practitioners to deliberate and act on the ethical impacts of AI</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#S4.SS2.SSS4" title="In 4.2. Potential Impacts &amp; Challenges ‣ 4. Results ‣ Improving governance outcomes through AI documentation: Bridging theory and practice"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.4 </span>Potential impact #4: Documentation could catalyze overall improvements in governance and development.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#S4.SS3" title="In 4. Results ‣ Improving governance outcomes through AI documentation: Bridging theory and practice"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Design considerations</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#S4.SS3.SSS1" title="In 4.3. Design considerations ‣ 4. Results ‣ Improving governance outcomes through AI documentation: Bridging theory and practice"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.1 </span>Design consideration #1: Determining the degree of customization versus standardization in documentation artifacts.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#S4.SS3.SSS2" title="In 4.3. Design considerations ‣ 4. Results ‣ Improving governance outcomes through AI documentation: Bridging theory and practice"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.2 </span>Design consideration #2: Determining how much to tailor documentation artifacts to specific audiences</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#S4.SS3.SSS3" title="In 4.3. Design considerations ‣ 4. Results ‣ Improving governance outcomes through AI documentation: Bridging theory and practice"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.3 </span>Design trade-off #3: Determining the level of interactivity documentation should support</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#S4.SS3.SSS4" title="In 4.3. Design considerations ‣ 4. Results ‣ Improving governance outcomes through AI documentation: Bridging theory and practice"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.4 </span>Design consideration #4: Determining the level of detail documentation artifacts should contain.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#S4.SS3.SSS5" title="In 4.3. Design considerations ‣ 4. Results ‣ Improving governance outcomes through AI documentation: Bridging theory and practice"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.5 </span>Design consideration #5: Determining the amount of automation in the documentation process.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#S4.SS4" title="In 4. Results ‣ Improving governance outcomes through AI documentation: Bridging theory and practice"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Recommendations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#S4.SS5" title="In 4. Results ‣ Improving governance outcomes through AI documentation: Bridging theory and practice"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.5 </span>Conclusion</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Improving governance outcomes through AI documentation: Bridging theory and practice</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Amy A. Winecoff
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:awinecoff@cdt.org">awinecoff@cdt.org</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-2594-4126" title="ORCID identifier">0000-0002-2594-4126</a></span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">Center for Democracy &amp; Technology</span><span class="ltx_text ltx_affiliation_city" id="id2.2.id2">Washington</span><span class="ltx_text ltx_affiliation_state" id="id3.3.id3">DC</span><span class="ltx_text ltx_affiliation_country" id="id4.4.id4">USA</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Miranda Bogen
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:mbogen@cdt.org">mbogen@cdt.org</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id5.1.id1">Center for Democracy &amp; Technology</span><span class="ltx_text ltx_affiliation_city" id="id6.2.id2">Washington</span><span class="ltx_text ltx_affiliation_state" id="id7.3.id3">DC</span><span class="ltx_text ltx_affiliation_country" id="id8.4.id4">USA</span>
</span></span></span>
</div>
<div class="ltx_dates">(2018; TBD; TBD; TBD)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id9.id1">Documentation plays a crucial role in both external accountability and internal governance of AI systems. Although there are many proposals for documenting AI data, models, systems, and methods, the ways these practices enhance governance as well as the challenges practitioners and organizations face with documentation remain underexplored. In this paper, we analyze 37 proposed documentation frameworks and 21 empirical studies evaluating their use. We identify potential hypotheses about how documentation can strengthen governance—such as informing stakeholders about AI risks and usage, fostering collaboration, encouraging ethical reflection, and reinforcing best practices. However, empirical evidence shows that practitioners often encounter obstacles that prevent documentation from achieving these goals. We also highlight key considerations for organizations when designing documentation, such as determining the appropriate level of detail and balancing automation in the process. Finally, we offer recommendations for further research and for implementing effective documentation practices in real-world contexts.</p>
</div>
<div class="ltx_keywords">Artificial intelligence, documentation, AI governance
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmlicensed</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2018</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id3"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>XXXXXXX.XXXXXXX</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id4"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>ACM CHI Conference on Human Factors in Computing Systems; April 26 – May 1, 2025,
2025; Yokohama, Japan</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_isbn" id="id5"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>978-1-4503-XXXX-X/18/06</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id6"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Social and professional topics Management of computing and information systems</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id7"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Human-centered computing HCI design and evaluation methods</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Transparency in AI is widely regarded as essential for calibrating trust and supporting accountability <cite class="ltx_cite ltx_citemacro_citep">(Liao and Vaughan, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib35" title="">2023</a>)</cite>. By providing stakeholders with a clear view of an AI system’s composition, operation, and development process, transparency allows for informed oversight and critical evaluation. When AI systems are thoroughly documented, these documentation artifacts offer invaluable insights into important system features such as training data, algorithms, and risk management strategies. This information can support two broad groups of external stakeholders. Documentation can help downstream deployers and users understand how the system functions and what risks it conveys. It can also assist policymakers and researchers in holding companies accountable for the negative consequences of their AI technologies.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Yet the importance of documentation extends beyond external accountability.<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Though the concepts of documentation and transparency are often blurred, complete documentation about an AI system does not guarantee that information will be made available to interested stakeholders, nor do transparency artifacts always reflect the full or most relevant details of an AI system even though such details may have been captured in internal documents. We distinguish between the concepts in this report in order to provide greater clarity about the presumptive goals of documentation and an exploration of what practices may more likely support those objectives</span></span></span> Internally, documentation serves as a critical tool for managing AI systems throughout their lifecycle for a wide range of stakeholders. For example, documentation could help downstream technical practitioners understand the strengths, limitations, and risks of training a model on a given dataset. It might also help compliance and governance teams assess a potential system use case’s compliance with company policies or legal requirements. Or the process of producing documentation might lead practitioners to make different decisions about how to sufficiently mitigate potential harms. As such, documentation is a foundational building block of effective AI governance.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Despite its clear benefits, creating effective documentation is a complex task. No single form of documentation can meet the diverse needs of all stakeholder groups equally. For example, while detailed technical reports like those for Llama-2<cite class="ltx_cite ltx_citemacro_citep">(Touvron et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib76" title="">2023</a>)</cite> and GPT-4<cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib50" title="">2023</a>)</cite>, which can exceed 50 pages and contain dense technical language, are valuable for AI researchers, they may not be accessible to non-technical stakeholders. Similarly, documentation intended to satisfy compliance requirements might fall short in providing practical guidance for those deploying AI systems.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">To maximize the impact of documentation on AI governance, organizations must carefully define their goals and identify who will produce, maintain, and use the documentation. Tailoring the scope, level of detail, and format of documentation to suit the intended audiences and purposes is crucial. Effective documentation design requires balancing the needs of both the documentation process and the resulting artifacts, ensuring that they collectively support the organization’s governance objectives.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">In this paper, we explore how documentation processes and artifacts can best support AI governance and risk management goals. Our research draws from a qualitative analysis of academic and gray literature,<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Gray literature refers to publications that have not been peer-reviewed, but that present detailed theories or research findings</span></span></span> including 37 proposed documentation frameworks and 21 papers with relevant empirical findings. From this analysis, we identify four mechanisms through which documentation is hypothesized to improve AI governance:</p>
</div>
<div class="ltx_para" id="S1.p6">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">Informing stakeholders about responsible use,</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">Facilitating collaboration on AI risks,</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">Encouraging ethical deliberation, and</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i4.p1">
<p class="ltx_p" id="S1.I1.i4.p1.1">Improving overall governance and development practices.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">We also examine the practical barriers that may hinder the effectiveness of these mechanisms and the considerations or trade-offs organizations face when designing and implementing documentation practices. These considerations include balancing customization with standardization, deciding between single or multiple forms of documentation, determining the extent of detail to include, choosing the appropriate level of automation to employ in the documentation process, and selecting between static or interactive formats. Based on our analysis, we offer recommendations to help organizations develop documentation strategies that align with their governance goals and stakeholder needs.</p>
</div>
<div class="ltx_para" id="S1.p8">
<p class="ltx_p" id="S1.p8.1">The primary contribution of our research is that our synthesis identifies patterns, gaps, and emerging trends across individual publications about documentation approaches and evaluations. By offering a holistic analysis of how AI documentation can support robust governance in real-world contexts, we clarify which documentation practices are likely to be most effective, under what conditions, and for which stakeholders. As such, our research can serves as a valuable resource for both researchers and practitioners seeking to refine and enhance their approaches to AI documentation in applied AI development contexts.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>What organizations could document about AI systems</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Documenting the various components of AI systems—data, models, systems, and methods—is essential for effective governance and informed decision-making. This documentation not only provides insight into the development process but also helps internal and external stakeholders understand the characteristics and potential risks associated with AI systems.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Data is a fundamental component of AI systems since it significantly influences model behavior and performance. When models are trained on datasets that don’t align with their deployment contexts or that contain biases, the outcomes can be problematic, reinforcing those biases or leading to poor performance <cite class="ltx_cite ltx_citemacro_citep">(Gebru et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib22" title="">2021</a>)</cite>. Data documentation, which might include details about dataset characteristics, collection methods, preprocessing, and known limitations, allows practitioners to identify potential issues early on, supporting better model performance and informing the decisions of those who use the documentation <cite class="ltx_cite ltx_citemacro_citep">(Bender and Friedman, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib8" title="">2018</a>; Chmielinski et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib17" title="">2020</a>; Díaz et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib20" title="">2023</a>; Gebru et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib22" title="">2021</a>; Marone and Van Durme, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib37" title="">2023</a>; Miceli et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib41" title="">2021</a>; Papakyriakopoulos et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib52" title="">2023</a>; Pushkarna et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib56" title="">2022</a>; Roman et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib60" title="">2023</a>; Rostamzadeh et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib61" title="">2022</a>; Soh, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib66" title="">2021</a>; Stoyanovich and Howe, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib69" title="">2019</a>; Subramaniam et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib71" title="">2023</a>; Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib72" title="">2019</a>; Zheng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib81" title="">2022</a>)</cite>. By tailoring documentation to the specific data type and application context, organizations can enhance its utility, drawing on established data documentation frameworks to guide this process.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">Model documentation also enhances AI development and governance, providing a window into a model’s creation, performance, and risks <cite class="ltx_cite ltx_citemacro_citep">(Crisan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib19" title="">2022</a>; McMillan-Major et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib40" title="">2021</a>; Mitchell et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib43" title="">2019</a>; Shen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib62" title="">2022</a>; Stoyanovich and Howe, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib69" title="">2019</a>)</cite>. Documenting aspects such as the model’s architecture, training procedures, intended use cases, and evaluation methods enables practitioners to assess potential risks and responsibly adapt models to specific contexts. For models developed in stages—such as those pretrained on large datasets and later fine-tuned—documenting each stage is essential. This helps downstream users understand the development pipeline and its implications for their intended use.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">AI services or applications in the real world typically consist of complex systems rather than isolated models. These systems often include multiple components, such as machine learning models, trust and safety filters, third-party software integrations, and user interfaces. The interaction among these components significantly affects the system’s overall performance and risk profile — especially because the properties or behavior of individual components may change when integrated into a system <cite class="ltx_cite ltx_citemacro_citep">(Smart et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib65" title="">2024</a>)</cite>. Recognizing that AI systems are more than just the sum of their parts, researchers have suggested that organizations should document not only each individual component but also the system as a whole <cite class="ltx_cite ltx_citemacro_citep">(Arnold et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib5" title="">2019</a>; Baracaldo et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib6" title="">2022</a>; Brajovic et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib13" title="">2023</a>; Green et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib25" title="">2021</a>; Procope et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib55" title="">2022</a>; Yang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib80" title="">2018</a>; Blasch et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib11" title="">2021</a>)</cite>. System documentation could provide an overview, including objectives, inputs, outputs, and a diagram illustrating how the components interact. This comprehensive approach ensures that practitioners have a clear understanding of the system’s behavior in its entirety.</p>
</div>
<div class="ltx_para" id="S2.p5">
<p class="ltx_p" id="S2.p5.1">Organizations may also find it important to document the processes and procedures that shape the development and deployment of AI systems and their components. This documentation could include how humans annotated or evaluated training or evaluation data <cite class="ltx_cite ltx_citemacro_citep">(Shimorina and Belz, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib64" title="">2021</a>)</cite>, any privacy, legal, and ethical reviews or audits conducted <cite class="ltx_cite ltx_citemacro_citep">(Raji and Yang, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib57" title="">2020</a>)</cite>, and any risk mitigations that were applied. Investing time in this type of documentation may be especially beneficial because it cannot be deduced merely from examining the system components. If such meta-data about the process is not documented throughout the development lifecycle, it may be very difficult to reconstruct later <cite class="ltx_cite ltx_citemacro_citep">(Belz et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib7" title="">2023</a>; Reid and Williams, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib58" title="">2023</a>)</cite>. As a result, it is ideal to produce documentation on development processes concurrently with the development of the system.</p>
</div>
<div class="ltx_para" id="S2.p6">
<p class="ltx_p" id="S2.p6.1">Organizations may also benefit from documenting machine learning methods <cite class="ltx_cite ltx_citemacro_citep">(Adkins et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib2" title="">2022</a>; Baracaldo et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib6" title="">2022</a>; Sokol and Flach, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib67" title="">2020</a>; Tagliabue et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib73" title="">2021</a>)</cite>, such as techniques applied in computer vision applications <cite class="ltx_cite ltx_citemacro_citep">(Adkins et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib2" title="">2022</a>)</cite> and strategies for enhancing model explainability <cite class="ltx_cite ltx_citemacro_citep">(Sokol and Flach, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib67" title="">2020</a>)</cite>. Documentation of the application of the AI model or system to specific AI tasks or use cases <cite class="ltx_cite ltx_citemacro_citep">(Hupont and Gomez, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib30" title="">2022</a>; Mohammad, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib44" title="">2022</a>)</cite> can also help practitioners understand the benefits and limitations of these applications. Information about methods and processes can provide valuable insights into what potential approaches a team might take to develop an AI system. Such insights can help practitioners determine when particular approaches are more or less appropriate and what risks different approaches may confer.</p>
</div>
<div class="ltx_para" id="S2.p7">
<p class="ltx_p" id="S2.p7.1">Within companies, many stakeholders may contribute to and use documentation <cite class="ltx_cite ltx_citemacro_citep">(Micheli et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib42" title="">2023</a>)</cite>. Those working on data collection, annotation, and curation might contribute to data documentation, while engineers and data scientists might document and use information related to data, models, and application infrastructure. UX designers, researchers, and product managers might rely on this documentation to inform product designs and create clear public explanations. Professionals focused on responsible AI, governance, and compliance could use documentation to identify and manage risks. Organizational leaders, in turn, may use these insights to make critical decisions about resource allocation, risk management, and the launch of AI-powered products.</p>
</div>
<div class="ltx_para" id="S2.p8">
<p class="ltx_p" id="S2.p8.1">We can categorize documentation stakeholders into two broad groups: <span class="ltx_text ltx_font_bold" id="S2.p8.1.1">documentation producers</span> and <span class="ltx_text ltx_font_bold" id="S2.p8.1.2">documentation consumers</span>. Documentation producers are those who actively contribute to the generation of documentation artifacts, while documentation consumers are those who read and use it. While this grouping simplifies some important distinctions, it serves as a helpful heuristic for understanding the opportunities and tensions between groups with both shared and distinct goals. We consider both producers and consumers and their interplay in our analysis.</p>
</div>
<div class="ltx_para" id="S2.p9">
<p class="ltx_p" id="S2.p9.1">We also note that ”AI documentation” could refer to either the process of producing documentation or the resulting artifacts. While documentation artifacts inform stakeholders about the responsible use of AI, the process of creating these documents can also institutionalize best practices and foster a culture of risk management.. Therefore, when considering how documentation can improve governance outcomes, we address both artifacts and processes.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Methods</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Publication Sampling</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">We employed a purposeful sampling approach <cite class="ltx_cite ltx_citemacro_citep">(Palinkas et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib51" title="">2015</a>)</cite> to identify proposed documentation frameworks and relevant empirical studies. Given our specific interest in how AI documentation can support governance, our use of a purposeful sampling approach allowed us to focus on proposed frameworks and empirical studies that are directly relevant to our research questions. It also afforded us the flexibility to iteratively refine our sample of papers based on emerging findings.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">We identified an initial seed sample of publications from a systematic review focused on AI documentation methods relevant to EU regulation <cite class="ltx_cite ltx_citemacro_citep">(Micheli et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib42" title="">2023</a>)</cite>. We cross-referenced this initial sample against the references used by the Partnership on AI in developing their ABOUT ML framework,<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>https://partnershiponai.org/workstream/about-ml/</span></span></span> which seeks to provide technology organizations with guidance on what to document about their AI systems. We chose these initial sources because they allowed us to focus on publications that aimed to establish best practices for industry documentation and address policy initiatives geared toward institutionalizing these practices. We reviewed the cited references within each of these initial works for additional proposed documentation frameworks and empirical studies related to documentation. We also consulted with academic researchers and industry practitioners with experience producing and using documentation to identify additional frameworks and studies. We excluded papers that centered on tools for implementing documentation (e.g., automated documentation code libraries) or that were not specifically focused on AI system documentation, such as fairness checklists.</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">This process yielded a sample of 37 proposed frameworks, eight of which included empirical evidence related to their implementation. Because of the relative dearth of empirical findings within publications proposing approaches, we further expanded our sample by searching for references within these 37 approaches that empirically evaluated documentation methods. We also conducted searches in the archives of the ACM Conference on Human Factors in Computing Systems and the ACM Conference on Computer Supported Cooperative Work using terms such as ”datasheet,” ”model card,” ”AI documentation,” ”model documentation,” ”data card,” and ”data documentation.” Together, these methods allowed us to identify 13 additional publications with empirical findings.</p>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1">Recognizing the importance of applied perspectives, we included non-peer-reviewed papers, such as technical whitepapers published by industry actors, acknowledging that they often provide insights not found in academic literature. While our sampling approach was not exhaustive, we reached theoretical saturation after analyzing the selected publications, as no new themes emerged. Therefore, we concluded our sampling at this point.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Data Analysis</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Our data analysis followed an abductive approach <cite class="ltx_cite ltx_citemacro_citep">(Timmermans and Tavory, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib75" title="">2012</a>; Tavory and Timmermans, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib74" title="">2014</a>)</cite>, iterating between inductively derived codes, as in grounded theory methods <cite class="ltx_cite ltx_citemacro_citep">(Strauss and Corbin, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib70" title="">1990</a>; Charmaz, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib15" title="">2014</a>)</cite>, and codes based on the theoretical motivations of our research. The first author conducted the initial coding by applying descriptive codes aligned with our research goals, such as identifying how AI documentation enhances internal governance and the challenges of using documentation as a governance tool. After discussing the results with the second author, we refined these codes into higher-order categories during the axial coding phase. For instance, codes like ”identify intended purpose” and ”specify out-of-scope uses” were grouped under the category ”inform downstream documentation consumers.”</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">In the final thematic coding phase, we grouped axial codes into broader theoretical mechanisms through which AI documentation could support robust governance, the challenges in achieving these impacts, and the design trade-offs faced by organizations.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Results</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Publication Sample</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">The publications included in our analysis are listed in Table <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:ai_docs</span>. For each framework, we classified whether the approach primarily focused on data; models; systems; or methods, tasks, and processes. When a framework did not fit neatly into one of these categories, we assigned it to the most appropriate category or categories based on its primary focus.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">We also categorized the type of evaluation each framework or independent empirical research study employed. Frameworks employing a ”feasibility analysis” are those where the framework’s authors or another group applied the framework to create documentation for a hypothetical or actual dataset, model, system, or method. This type of analysis demonstrates that the framework could theoretically be used for its intended purpose but does not involve empirical evaluation with practitioners in research or real-world settings. If a study developed a documentation artifact for the purpose of an empirical study, we classified this as part of the empirical study rather than as a feasibility analysis, as empirical studies offer a more rigorous evaluation.</p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1">We classify publications as employing a ”practitioner lab study” when the evaluation involved practitioners within a controlled research setting. We classify ”practitioner real-world studies” as those examining practitioner methods and practices within their real-world work environments. Both lab and real-world studies have unique strengths, and neither is inherently more rigorous or useful than the other. We define ”artifact studies” as studies of publicly available documentation artifacts such as Github repository documentation or Hugging Face model cards.</p>
</div>
<div class="ltx_para" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1">In some instances, framework authors mentioned consulting relevant stakeholders during the design or refinement of their framework. However, if these consultations are only briefly mentioned or not elaborated upon, we do not classify the work as including a practitioner study.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1. </span>List of Publications</figcaption>
<table class="ltx_tabular" id="S4.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T1.1.1.1.1" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.1.1">Num.</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T1.1.1.1.2" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.2.1">Author</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T1.1.1.1.3" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.3.1">Year</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T1.1.1.1.4" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.4.1">Framework Type</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T1.1.1.1.5" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.5.1">Evaluation Type</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.1.2.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.2.1.1" style="padding-top:1pt;padding-bottom:1pt;">1</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.2.1.2" style="padding-top:1pt;padding-bottom:1pt;">Adkins et al.</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.2.1.3" style="padding-top:1pt;padding-bottom:1pt;">2022</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.2.1.4" style="padding-top:1pt;padding-bottom:1pt;">Method, process, or task</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.2.1.5" style="padding-top:1pt;padding-bottom:1pt;">Feasibility analysis</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.3.2">
<td class="ltx_td ltx_align_center" id="S4.T1.1.3.2.1" style="padding-top:1pt;padding-bottom:1pt;">2</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.3.2.2" style="padding-top:1pt;padding-bottom:1pt;">Arnold et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.3.2.3" style="padding-top:1pt;padding-bottom:1pt;">2019</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.3.2.4" style="padding-top:1pt;padding-bottom:1pt;">System</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.3.2.5" style="padding-top:1pt;padding-bottom:1pt;">Feasibility analysis</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.4.3">
<td class="ltx_td ltx_align_center" id="S4.T1.1.4.3.1" style="padding-top:1pt;padding-bottom:1pt;">3</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.4.3.2" style="padding-top:1pt;padding-bottom:1pt;">Baracaldo et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.4.3.3" style="padding-top:1pt;padding-bottom:1pt;">2022</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.4.3.4" style="padding-top:1pt;padding-bottom:1pt;">System</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.4.3.5" style="padding-top:1pt;padding-bottom:1pt;">Feasibility analysis</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.5.4">
<td class="ltx_td ltx_align_center" id="S4.T1.1.5.4.1" style="padding-top:1pt;padding-bottom:1pt;">4</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.5.4.2" style="padding-top:1pt;padding-bottom:1pt;">Bender &amp; Friedman</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.5.4.3" style="padding-top:1pt;padding-bottom:1pt;">2018</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.5.4.4" style="padding-top:1pt;padding-bottom:1pt;">Data</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.5.4.5" style="padding-top:1pt;padding-bottom:1pt;">Feasibility analysis</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.6.5">
<td class="ltx_td ltx_align_center" id="S4.T1.1.6.5.1" style="padding-top:1pt;padding-bottom:1pt;">5</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.6.5.2" style="padding-top:1pt;padding-bottom:1pt;">Bhat et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.6.5.3" style="padding-top:1pt;padding-bottom:1pt;">2023</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.6.5.4" style="padding-top:1pt;padding-bottom:1pt;">Evaluation only</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.6.5.5" style="padding-top:1pt;padding-bottom:1pt;">Practitioner lab study</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.7.6">
<td class="ltx_td ltx_align_center" id="S4.T1.1.7.6.1" style="padding-top:1pt;padding-bottom:1pt;">6</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.7.6.2" style="padding-top:1pt;padding-bottom:1pt;">Blasch et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.7.6.3" style="padding-top:1pt;padding-bottom:1pt;">2020</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.7.6.4" style="padding-top:1pt;padding-bottom:1pt;">System</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.7.6.5" style="padding-top:1pt;padding-bottom:1pt;">Feasibility analysis</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.8.7">
<td class="ltx_td ltx_align_center" id="S4.T1.1.8.7.1" style="padding-top:1pt;padding-bottom:1pt;">7</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.8.7.2" style="padding-top:1pt;padding-bottom:1pt;">Boyd</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.8.7.3" style="padding-top:1pt;padding-bottom:1pt;">2021</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.8.7.4" style="padding-top:1pt;padding-bottom:1pt;">Evaluation only</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.8.7.5" style="padding-top:1pt;padding-bottom:1pt;">Practitioner lab study</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.9.8">
<td class="ltx_td ltx_align_center" id="S4.T1.1.9.8.1" style="padding-top:1pt;padding-bottom:1pt;">8</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.9.8.2" style="padding-top:1pt;padding-bottom:1pt;">Brajovic et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.9.8.3" style="padding-top:1pt;padding-bottom:1pt;">2023</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.9.8.4" style="padding-top:1pt;padding-bottom:1pt;">System</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.9.8.5" style="padding-top:1pt;padding-bottom:1pt;">Feasibility analysis</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.10.9">
<td class="ltx_td ltx_align_center" id="S4.T1.1.10.9.1" style="padding-top:1pt;padding-bottom:1pt;">9</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.10.9.2" style="padding-top:1pt;padding-bottom:1pt;">Chang &amp; Custis</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.10.9.3" style="padding-top:1pt;padding-bottom:1pt;">2022</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.10.9.4" style="padding-top:1pt;padding-bottom:1pt;">Evaluation only</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.10.9.5" style="padding-top:1pt;padding-bottom:1pt;">Practitioner real-world study</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.11.10">
<td class="ltx_td ltx_align_center" id="S4.T1.1.11.10.1" style="padding-top:1pt;padding-bottom:1pt;">10</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.11.10.2" style="padding-top:1pt;padding-bottom:1pt;">Chmielinski et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.11.10.3" style="padding-top:1pt;padding-bottom:1pt;">2020</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.11.10.4" style="padding-top:1pt;padding-bottom:1pt;">Data</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.11.10.5" style="padding-top:1pt;padding-bottom:1pt;">Feasibility analysis</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.12.11">
<td class="ltx_td ltx_align_center" id="S4.T1.1.12.11.1" style="padding-top:1pt;padding-bottom:1pt;">11</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.12.11.2" style="padding-top:1pt;padding-bottom:1pt;">Chmielinski et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.12.11.3" style="padding-top:1pt;padding-bottom:1pt;">2024</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.12.11.4" style="padding-top:1pt;padding-bottom:1pt;">Method, process, or task</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.12.11.5" style="padding-top:1pt;padding-bottom:1pt;">None</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.13.12">
<td class="ltx_td ltx_align_center" id="S4.T1.1.13.12.1" style="padding-top:1pt;padding-bottom:1pt;">12</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.13.12.2" style="padding-top:1pt;padding-bottom:1pt;">Crisan et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.13.12.3" style="padding-top:1pt;padding-bottom:1pt;">2022</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.13.12.4" style="padding-top:1pt;padding-bottom:1pt;">Model</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.13.12.5" style="padding-top:1pt;padding-bottom:1pt;">Feasibility analysis, Practitioner lab study</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.14.13">
<td class="ltx_td ltx_align_center" id="S4.T1.1.14.13.1" style="padding-top:1pt;padding-bottom:1pt;">13</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.14.13.2" style="padding-top:1pt;padding-bottom:1pt;">Díaz et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.14.13.3" style="padding-top:1pt;padding-bottom:1pt;">2023</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.14.13.4" style="padding-top:1pt;padding-bottom:1pt;">Data</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.14.13.5" style="padding-top:1pt;padding-bottom:1pt;">Feasibility analysis</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.15.14">
<td class="ltx_td ltx_align_center" id="S4.T1.1.15.14.1" style="padding-top:1pt;padding-bottom:1pt;">14</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.15.14.2" style="padding-top:1pt;padding-bottom:1pt;">Gebru et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.15.14.3" style="padding-top:1pt;padding-bottom:1pt;">2021</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.15.14.4" style="padding-top:1pt;padding-bottom:1pt;">Data</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.15.14.5" style="padding-top:1pt;padding-bottom:1pt;">Feasibility analysis</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.16.15">
<td class="ltx_td ltx_align_center" id="S4.T1.1.16.15.1" style="padding-top:1pt;padding-bottom:1pt;">15</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.16.15.2" style="padding-top:1pt;padding-bottom:1pt;">Geiger et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.16.15.3" style="padding-top:1pt;padding-bottom:1pt;">2020</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.16.15.4" style="padding-top:1pt;padding-bottom:1pt;">Evaluation only</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.16.15.5" style="padding-top:1pt;padding-bottom:1pt;">Artifact study</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.17.16">
<td class="ltx_td ltx_align_center" id="S4.T1.1.17.16.1" style="padding-top:1pt;padding-bottom:1pt;">16</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.17.16.2" style="padding-top:1pt;padding-bottom:1pt;">Gilbert et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.17.16.3" style="padding-top:1pt;padding-bottom:1pt;">2023</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.17.16.4" style="padding-top:1pt;padding-bottom:1pt;">System</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.17.16.5" style="padding-top:1pt;padding-bottom:1pt;">Feasibility analysis</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.18.17">
<td class="ltx_td ltx_align_center" id="S4.T1.1.18.17.1" style="padding-top:1pt;padding-bottom:1pt;">17</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.18.17.2" style="padding-top:1pt;padding-bottom:1pt;">Heger et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.18.17.3" style="padding-top:1pt;padding-bottom:1pt;">2022</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.18.17.4" style="padding-top:1pt;padding-bottom:1pt;">Evaluation only</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.18.17.5" style="padding-top:1pt;padding-bottom:1pt;">Practitioner real-world study</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.19.18">
<td class="ltx_td ltx_align_center" id="S4.T1.1.19.18.1" style="padding-top:1pt;padding-bottom:1pt;">18</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.19.18.2" style="padding-top:1pt;padding-bottom:1pt;">Hind et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.19.18.3" style="padding-top:1pt;padding-bottom:1pt;">2019</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.19.18.4" style="padding-top:1pt;padding-bottom:1pt;">Evaluation only</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.19.18.5" style="padding-top:1pt;padding-bottom:1pt;">Practitioner real-world study</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.20.19">
<td class="ltx_td ltx_align_center" id="S4.T1.1.20.19.1" style="padding-top:1pt;padding-bottom:1pt;">19</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.20.19.2" style="padding-top:1pt;padding-bottom:1pt;">Holland et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.20.19.3" style="padding-top:1pt;padding-bottom:1pt;">2018</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.20.19.4" style="padding-top:1pt;padding-bottom:1pt;">Data</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.20.19.5" style="padding-top:1pt;padding-bottom:1pt;">Feasibility analysis</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.21.20">
<td class="ltx_td ltx_align_center" id="S4.T1.1.21.20.1" style="padding-top:1pt;padding-bottom:1pt;">20</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.21.20.2" style="padding-top:1pt;padding-bottom:1pt;">Hupont &amp; Gomez</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.21.20.3" style="padding-top:1pt;padding-bottom:1pt;">2022</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.21.20.4" style="padding-top:1pt;padding-bottom:1pt;">Method, process, or task</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.21.20.5" style="padding-top:1pt;padding-bottom:1pt;">Feasibility analysis</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.22.21">
<td class="ltx_td ltx_align_center" id="S4.T1.1.22.21.1" style="padding-top:1pt;padding-bottom:1pt;">21</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.22.21.2" style="padding-top:1pt;padding-bottom:1pt;">Liang et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.22.21.3" style="padding-top:1pt;padding-bottom:1pt;">2024</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.22.21.4" style="padding-top:1pt;padding-bottom:1pt;">Evaluation only</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.22.21.5" style="padding-top:1pt;padding-bottom:1pt;">Artifact study</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.23.22">
<td class="ltx_td ltx_align_center" id="S4.T1.1.23.22.1" style="padding-top:1pt;padding-bottom:1pt;">22</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.23.22.2" style="padding-top:1pt;padding-bottom:1pt;">Liao et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.23.22.3" style="padding-top:1pt;padding-bottom:1pt;">2023</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.23.22.4" style="padding-top:1pt;padding-bottom:1pt;">Evaluation only</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.23.22.5" style="padding-top:1pt;padding-bottom:1pt;">Practitioner lab study</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.24.23">
<td class="ltx_td ltx_align_center" id="S4.T1.1.24.23.1" style="padding-top:1pt;padding-bottom:1pt;">23</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.24.23.2" style="padding-top:1pt;padding-bottom:1pt;">Marone &amp; Van Durme</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.24.23.3" style="padding-top:1pt;padding-bottom:1pt;">2023</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.24.23.4" style="padding-top:1pt;padding-bottom:1pt;">Data</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.24.23.5" style="padding-top:1pt;padding-bottom:1pt;">Feasibility analysis</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.25.24">
<td class="ltx_td ltx_align_center" id="S4.T1.1.25.24.1" style="padding-top:1pt;padding-bottom:1pt;">24</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.25.24.2" style="padding-top:1pt;padding-bottom:1pt;">McMillan-Major et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.25.24.3" style="padding-top:1pt;padding-bottom:1pt;">2021</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.25.24.4" style="padding-top:1pt;padding-bottom:1pt;">Data, Model</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.25.24.5" style="padding-top:1pt;padding-bottom:1pt;">Feasibility analysis</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.26.25">
<td class="ltx_td ltx_align_center" id="S4.T1.1.26.25.1" style="padding-top:1pt;padding-bottom:1pt;">25</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.26.25.2" style="padding-top:1pt;padding-bottom:1pt;">McMillan-Major, Bender, &amp; Friedman</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.26.25.3" style="padding-top:1pt;padding-bottom:1pt;">2024</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.26.25.4" style="padding-top:1pt;padding-bottom:1pt;">Data</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.26.25.5" style="padding-top:1pt;padding-bottom:1pt;">Practitioner lab study</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.27.26">
<td class="ltx_td ltx_align_center" id="S4.T1.1.27.26.1" style="padding-top:1pt;padding-bottom:1pt;">26</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.27.26.2" style="padding-top:1pt;padding-bottom:1pt;">Miceli et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.27.26.3" style="padding-top:1pt;padding-bottom:1pt;">2021</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.27.26.4" style="padding-top:1pt;padding-bottom:1pt;">Evaluation only</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.27.26.5" style="padding-top:1pt;padding-bottom:1pt;">Practitioner real-world study</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.28.27">
<td class="ltx_td ltx_align_center" id="S4.T1.1.28.27.1" style="padding-top:1pt;padding-bottom:1pt;">27</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.28.27.2" style="padding-top:1pt;padding-bottom:1pt;">Mitchell et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.28.27.3" style="padding-top:1pt;padding-bottom:1pt;">2019</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.28.27.4" style="padding-top:1pt;padding-bottom:1pt;">Model</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.28.27.5" style="padding-top:1pt;padding-bottom:1pt;">Feasibility analysis</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.29.28">
<td class="ltx_td ltx_align_center" id="S4.T1.1.29.28.1" style="padding-top:1pt;padding-bottom:1pt;">28</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.29.28.2" style="padding-top:1pt;padding-bottom:1pt;">Mohammad</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.29.28.3" style="padding-top:1pt;padding-bottom:1pt;">2022</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.29.28.4" style="padding-top:1pt;padding-bottom:1pt;">Method, process, or task</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.29.28.5" style="padding-top:1pt;padding-bottom:1pt;">Feasibility analysis</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.30.29">
<td class="ltx_td ltx_align_center" id="S4.T1.1.30.29.1" style="padding-top:1pt;padding-bottom:1pt;">29</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.30.29.2" style="padding-top:1pt;padding-bottom:1pt;">Moore, LIao, &amp; Subramonyam</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.30.29.3" style="padding-top:1pt;padding-bottom:1pt;">2023</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.30.29.4" style="padding-top:1pt;padding-bottom:1pt;">Evaluation only</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.30.29.5" style="padding-top:1pt;padding-bottom:1pt;">Practitioner lab study</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.31.30">
<td class="ltx_td ltx_align_center" id="S4.T1.1.31.30.1" style="padding-top:1pt;padding-bottom:1pt;">30</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.31.30.2" style="padding-top:1pt;padding-bottom:1pt;">Nunes et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.31.30.3" style="padding-top:1pt;padding-bottom:1pt;">2022</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.31.30.4" style="padding-top:1pt;padding-bottom:1pt;">Evaluation only</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.31.30.5" style="padding-top:1pt;padding-bottom:1pt;">Practitioner lab study</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.32.31">
<td class="ltx_td ltx_align_center" id="S4.T1.1.32.31.1" style="padding-top:1pt;padding-bottom:1pt;">31</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.32.31.2" style="padding-top:1pt;padding-bottom:1pt;">Papakyriakopoulos et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.32.31.3" style="padding-top:1pt;padding-bottom:1pt;">2023</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.32.31.4" style="padding-top:1pt;padding-bottom:1pt;">Data</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.32.31.5" style="padding-top:1pt;padding-bottom:1pt;">Feasibility analysis</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.33.32">
<td class="ltx_td ltx_align_center" id="S4.T1.1.33.32.1" style="padding-top:1pt;padding-bottom:1pt;">32</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.33.32.2" style="padding-top:1pt;padding-bottom:1pt;">Pepe et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.33.32.3" style="padding-top:1pt;padding-bottom:1pt;">2024</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.33.32.4" style="padding-top:1pt;padding-bottom:1pt;">Evaluation only</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.33.32.5" style="padding-top:1pt;padding-bottom:1pt;">Artifact study</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.34.33">
<td class="ltx_td ltx_align_center" id="S4.T1.1.34.33.1" style="padding-top:1pt;padding-bottom:1pt;">33</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.34.33.2" style="padding-top:1pt;padding-bottom:1pt;">Procope et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.34.33.3" style="padding-top:1pt;padding-bottom:1pt;">2022</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.34.33.4" style="padding-top:1pt;padding-bottom:1pt;">System</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.34.33.5" style="padding-top:1pt;padding-bottom:1pt;">Feasibility analysis</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.35.34">
<td class="ltx_td ltx_align_center" id="S4.T1.1.35.34.1" style="padding-top:1pt;padding-bottom:1pt;">34</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.35.34.2" style="padding-top:1pt;padding-bottom:1pt;">Pushkarna et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.35.34.3" style="padding-top:1pt;padding-bottom:1pt;">2022</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.35.34.4" style="padding-top:1pt;padding-bottom:1pt;">Data</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.35.34.5" style="padding-top:1pt;padding-bottom:1pt;">Practitioner real-world study</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.36.35">
<td class="ltx_td ltx_align_center" id="S4.T1.1.36.35.1" style="padding-top:1pt;padding-bottom:1pt;">35</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.36.35.2" style="padding-top:1pt;padding-bottom:1pt;">Raji &amp; Yang</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.36.35.3" style="padding-top:1pt;padding-bottom:1pt;">2020</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.36.35.4" style="padding-top:1pt;padding-bottom:1pt;">System</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.36.35.5" style="padding-top:1pt;padding-bottom:1pt;">None</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.37.36">
<td class="ltx_td ltx_align_center" id="S4.T1.1.37.36.1" style="padding-top:1pt;padding-bottom:1pt;">36</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.37.36.2" style="padding-top:1pt;padding-bottom:1pt;">Reid &amp; Williams</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.37.36.3" style="padding-top:1pt;padding-bottom:1pt;">2023</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.37.36.4" style="padding-top:1pt;padding-bottom:1pt;">Evaluation only</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.37.36.5" style="padding-top:1pt;padding-bottom:1pt;">Practitioner real-world study, Artifact study</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.38.37">
<td class="ltx_td ltx_align_center" id="S4.T1.1.38.37.1" style="padding-top:1pt;padding-bottom:1pt;">37</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.38.37.2" style="padding-top:1pt;padding-bottom:1pt;">Richards et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.38.37.3" style="padding-top:1pt;padding-bottom:1pt;">2020</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.38.37.4" style="padding-top:1pt;padding-bottom:1pt;">System</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.38.37.5" style="padding-top:1pt;padding-bottom:1pt;">Feasibility analysis</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.39.38">
<td class="ltx_td ltx_align_center" id="S4.T1.1.39.38.1" style="padding-top:1pt;padding-bottom:1pt;">38</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.39.38.2" style="padding-top:1pt;padding-bottom:1pt;">Roman et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.39.38.3" style="padding-top:1pt;padding-bottom:1pt;">2023</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.39.38.4" style="padding-top:1pt;padding-bottom:1pt;">Data</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.39.38.5" style="padding-top:1pt;padding-bottom:1pt;">Feasibility analysis</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.40.39">
<td class="ltx_td ltx_align_center" id="S4.T1.1.40.39.1" style="padding-top:1pt;padding-bottom:1pt;">39</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.40.39.2" style="padding-top:1pt;padding-bottom:1pt;">Rostamzadeh et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.40.39.3" style="padding-top:1pt;padding-bottom:1pt;">2022</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.40.39.4" style="padding-top:1pt;padding-bottom:1pt;">Data</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.40.39.5" style="padding-top:1pt;padding-bottom:1pt;">Practitioner lab study</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.41.40">
<td class="ltx_td ltx_align_center" id="S4.T1.1.41.40.1" style="padding-top:1pt;padding-bottom:1pt;">40</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.41.40.2" style="padding-top:1pt;padding-bottom:1pt;">Shen et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.41.40.3" style="padding-top:1pt;padding-bottom:1pt;">2022</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.41.40.4" style="padding-top:1pt;padding-bottom:1pt;">Model</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.41.40.5" style="padding-top:1pt;padding-bottom:1pt;">Practitioner lab study</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.42.41">
<td class="ltx_td ltx_align_center" id="S4.T1.1.42.41.1" style="padding-top:1pt;padding-bottom:1pt;">41</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.42.41.2" style="padding-top:1pt;padding-bottom:1pt;">Shimorina &amp; Belz</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.42.41.3" style="padding-top:1pt;padding-bottom:1pt;">2021</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.42.41.4" style="padding-top:1pt;padding-bottom:1pt;">Method, process, or task</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.42.41.5" style="padding-top:1pt;padding-bottom:1pt;">None</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.43.42">
<td class="ltx_td ltx_align_center" id="S4.T1.1.43.42.1" style="padding-top:1pt;padding-bottom:1pt;">42</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.43.42.2" style="padding-top:1pt;padding-bottom:1pt;">Soh</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.43.42.3" style="padding-top:1pt;padding-bottom:1pt;">2021</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.43.42.4" style="padding-top:1pt;padding-bottom:1pt;">Data</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.43.42.5" style="padding-top:1pt;padding-bottom:1pt;">None</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.44.43">
<td class="ltx_td ltx_align_center" id="S4.T1.1.44.43.1" style="padding-top:1pt;padding-bottom:1pt;">43</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.44.43.2" style="padding-top:1pt;padding-bottom:1pt;">Sokol &amp; Flach</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.44.43.3" style="padding-top:1pt;padding-bottom:1pt;">2020</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.44.43.4" style="padding-top:1pt;padding-bottom:1pt;">Method, process, or task</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.44.43.5" style="padding-top:1pt;padding-bottom:1pt;">Feasibility analysis</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.45.44">
<td class="ltx_td ltx_align_center" id="S4.T1.1.45.44.1" style="padding-top:1pt;padding-bottom:1pt;">44</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.45.44.2" style="padding-top:1pt;padding-bottom:1pt;">Srinivasan et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.45.44.3" style="padding-top:1pt;padding-bottom:1pt;">2021</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.45.44.4" style="padding-top:1pt;padding-bottom:1pt;">Data</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.45.44.5" style="padding-top:1pt;padding-bottom:1pt;">Feasibility analysis</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.46.45">
<td class="ltx_td ltx_align_center" id="S4.T1.1.46.45.1" style="padding-top:1pt;padding-bottom:1pt;">45</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.46.45.2" style="padding-top:1pt;padding-bottom:1pt;">Stoyanovich &amp; Howe</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.46.45.3" style="padding-top:1pt;padding-bottom:1pt;">2019</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.46.45.4" style="padding-top:1pt;padding-bottom:1pt;">Data, Model</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.46.45.5" style="padding-top:1pt;padding-bottom:1pt;">Feasibility analysis</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.47.46">
<td class="ltx_td ltx_align_center" id="S4.T1.1.47.46.1" style="padding-top:1pt;padding-bottom:1pt;">46</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.47.46.2" style="padding-top:1pt;padding-bottom:1pt;">Subramaniam et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.47.46.3" style="padding-top:1pt;padding-bottom:1pt;">2023</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.47.46.4" style="padding-top:1pt;padding-bottom:1pt;">Data</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.47.46.5" style="padding-top:1pt;padding-bottom:1pt;">Practitioner lab study</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.48.47">
<td class="ltx_td ltx_align_center" id="S4.T1.1.48.47.1" style="padding-top:1pt;padding-bottom:1pt;">47</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.48.47.2" style="padding-top:1pt;padding-bottom:1pt;">Sun et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.48.47.3" style="padding-top:1pt;padding-bottom:1pt;">2019</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.48.47.4" style="padding-top:1pt;padding-bottom:1pt;">Data</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.48.47.5" style="padding-top:1pt;padding-bottom:1pt;">Feasibility analysis</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.49.48">
<td class="ltx_td ltx_align_center" id="S4.T1.1.49.48.1" style="padding-top:1pt;padding-bottom:1pt;">48</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.49.48.2" style="padding-top:1pt;padding-bottom:1pt;">Tagliabue et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.49.48.3" style="padding-top:1pt;padding-bottom:1pt;">2021</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.49.48.4" style="padding-top:1pt;padding-bottom:1pt;">Method, process, or task</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.49.48.5" style="padding-top:1pt;padding-bottom:1pt;">Feasibility analysis</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.50.49">
<td class="ltx_td ltx_align_center" id="S4.T1.1.50.49.1" style="padding-top:1pt;padding-bottom:1pt;">49</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.50.49.2" style="padding-top:1pt;padding-bottom:1pt;">Yang et al.</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.50.49.3" style="padding-top:1pt;padding-bottom:1pt;">2018</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.50.49.4" style="padding-top:1pt;padding-bottom:1pt;">Method, process, or task</td>
<td class="ltx_td ltx_align_left" id="S4.T1.1.50.49.5" style="padding-top:1pt;padding-bottom:1pt;">Feasibility analysis</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.51.50">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.51.50.1" style="padding-top:1pt;padding-bottom:1pt;">50</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T1.1.51.50.2" style="padding-top:1pt;padding-bottom:1pt;">Zheng et al.,</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.51.50.3" style="padding-top:1pt;padding-bottom:1pt;">2022</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T1.1.51.50.4" style="padding-top:1pt;padding-bottom:1pt;">Data</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T1.1.51.50.5" style="padding-top:1pt;padding-bottom:1pt;">Practitioner lab study</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Potential Impacts &amp; Challenges</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">While empirical evidence directly linking documentation artifacts or processes to improved governance outcomes is limited, the theories proposed in existing documentation frameworks offer compelling hypotheses about how documentation can positively impact governance. Empirical studies involving practitioners, alongside analyses of publicly available documentation artifacts, provide an initial glimpse into the factors that contribute to accurate, high-quality, and comprehensive documentation, as well as the reasons why documentation efforts may sometimes fall short of their goals.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">Our analysis identified four possible ways in which documentation could improve governance: informing downstream users about system development and associated risks, encouraging ethical reflection among practitioners, facilitating communication among stakeholders, and enhancing AI development and governance overall. In the following sections, we explore each of these hypothesized impacts in detail and examine the challenges real-world organizations face in realizing these benefits.</p>
</div>
<section class="ltx_subsubsection" id="S4.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1. </span>Potential impact #1: Documentation could inform downstream stakeholders about effective and responsible use.</h4>
<div class="ltx_para" id="S4.SS2.SSS1.p1">
<p class="ltx_p" id="S4.SS2.SSS1.p1.1">The most straightforward potential impact of documentation is that it can provide essential context, such as the original motivation for developing a dataset, model, or system, their intended use cases, and information on system properties necessary for effective and responsible deployment.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p2">
<p class="ltx_p" id="S4.SS2.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS1.p2.1.1">Hypotheses.</span> Documentation could inform downstream stakeholders by clearly articulating the intended uses of data, models, and systems and provide guidance on responsible deployment. Practitioners typically develop systems with specific use cases in mind, and other development teams need to understand these intended use cases to assess alignment with their goals. If aligned, teams can then modify the systems to meet their current objectives. Practitioners argue documentation can also clarify underlying assumptions, such as data collection methods and representativeness, which are critical for assessing the suitability of a dataset for specific purposes <cite class="ltx_cite ltx_citemacro_citep">(Reid and Williams, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib58" title="">2023</a>; Rostamzadeh et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib61" title="">2022</a>; Zheng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib81" title="">2022</a>)</cite>. Also, it can help identify potential deployment issues, such as mismatches between the original training data and the intended deployment context <cite class="ltx_cite ltx_citemacro_citep">(Boyd, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib12" title="">2021</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p3">
<p class="ltx_p" id="S4.SS2.SSS1.p3.1">Moreover, documentation could assist downstream practitioners in making implementation decisions that support effective and responsible product development. For example, documentation could help practitioners find and compare system components aligned with their goals, including alternatives to AI approaches <cite class="ltx_cite ltx_citemacro_citep">(Heger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib27" title="">2022</a>; Reid and Williams, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib58" title="">2023</a>; Shen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib62" title="">2022</a>; Zheng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib81" title="">2022</a>)</cite>. It might also provide statistical summaries of data <cite class="ltx_cite ltx_citemacro_citep">(Holland et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib29" title="">2018</a>)</cite> or or model performance evaluations such as area under the curve (AUC) <cite class="ltx_cite ltx_citemacro_citep">(Mitchell et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib43" title="">2019</a>)</cite> to help inform developers’ choices of how to train models or implement appropriate guardrails.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p4">
<p class="ltx_p" id="S4.SS2.SSS1.p4.1">Documentation could also help stakeholders ensure that planned use cases comply with legal constraints, regulatory requirements, and organizational policies. For example, certain datasets may be restricted from use if the data were collected without affirmative consent or contain personally identifiable or copyrighted information. Without this awareness, practitioners might inadvertently train a model on such data, only to later discover that they cannot use the model due to policy violations <cite class="ltx_cite ltx_citemacro_citep">(Roman et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib60" title="">2023</a>)</cite>. Practitioners see avoiding disciplinary action for non-compliance with company policies as a motivating benefit of documentation <cite class="ltx_cite ltx_citemacro_citep">(Heger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib27" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p5">
<p class="ltx_p" id="S4.SS2.SSS1.p5.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS1.p5.1.1">Challenges.</span> While practitioners acknowledge that the benefits of documentation could outweigh the costs of creating and maintaining it <cite class="ltx_cite ltx_citemacro_citep">(Heger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib27" title="">2022</a>)</cite>, when organizations fail to provide clear incentives for high-quality documentation, practitioners are less likely to prioritize it. This lack of motivation can hinder the realization of documentation’s potential benefits, but particularly its ability to inform downstream users.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p6">
<p class="ltx_p" id="S4.SS2.SSS1.p6.1">One major challenge is the lack of organizational incentives for documentation. Organizations typically do not prioritize documentation unless regulations require it for compliance or clients specifically request it <cite class="ltx_cite ltx_citemacro_citep">(Chang and Custis, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib14" title="">2022</a>; Miceli et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib41" title="">2021</a>; Heger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib27" title="">2022</a>)</cite>. Practitioners often view producing high-quality documentation as less relevant to their evaluations and promotions than development tasks that directly contribute to product outputs <cite class="ltx_cite ltx_citemacro_citep">(Chang and Custis, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib14" title="">2022</a>; Heger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib27" title="">2022</a>)</cite>. This disconnect between the benefits of documentation and practitioner objectives is further exacerbated when the practitioners who benefit most from documentation (i.e., consumers) are not the same as those responsible for producing it (i.e., producers). In organizations where governance processes mandate documentation, a lack of familiarity with AI documentation concepts among developers could potentially magnify tensions between product development and governance teams <cite class="ltx_cite ltx_citemacro_citep">(Ali et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib4" title="">2023</a>; Ahlawat et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib3" title="">2024</a>)</cite>. Moreover, practitioners are often more motivated by compliance than by normative considerations, which could lead to blind spots when novel ethical issues arise outside existing policies <cite class="ltx_cite ltx_citemacro_citep">(Heger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib27" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p7">
<p class="ltx_p" id="S4.SS2.SSS1.p7.1">Facing time constraints and competing demands, practitioners may deprioritize documentation, sometimes cutting corners to save time <cite class="ltx_cite ltx_citemacro_citep">(Chang and Custis, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib14" title="">2022</a>; Heger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib27" title="">2022</a>)</cite>. This can diminish the value of documentation artifacts, as evidenced by studies showing that practitioners sometimes reuse content from existing documentation, even when it pertains to different systems, leading to inadequate or incorrect documentation of their current system <cite class="ltx_cite ltx_citemacro_citep">(Pushkarna et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib56" title="">2022</a>; Heger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib27" title="">2022</a>)</cite>. Practitioners also sometimes leave questions unanswered rather than seek out the necessary information <cite class="ltx_cite ltx_citemacro_citep">(Heger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib27" title="">2022</a>)</cite> or prioritize recording information that is most valuable to them, potentially omitting critical details for others less familiar with the system <cite class="ltx_cite ltx_citemacro_citep">(Hind et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib28" title="">2019</a>)</cite>. Furthermore, because practitioners often forget relevant information if they do not record it during development, their reconstruction of key system information after the fact can be time-consuming and error prone <cite class="ltx_cite ltx_citemacro_citep">(Reid and Williams, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib58" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p8">
<p class="ltx_p" id="S4.SS2.SSS1.p8.1">Studies of publicly available documentation artifacts frequently highlight issues with incomplete or incorrect information, which can mislead downstream stakeholders regarding the characteristics of AI systems or components <cite class="ltx_cite ltx_citemacro_citep">(Pepe et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib53" title="">2024</a>; Liang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib33" title="">2024</a>; Geiger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib23" title="">2020</a>)</cite>. For example, many publicly available model cards lack details about out-of-scope uses, limitations, or environmental impacts <cite class="ltx_cite ltx_citemacro_citep">(Pepe et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib53" title="">2024</a>; Liang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib33" title="">2024</a>)</cite>. Less than 30% of model cards contain evaluation results, a critical piece of information for downstream users <cite class="ltx_cite ltx_citemacro_citep">(Liang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib33" title="">2024</a>)</cite>. Also, some publicly available documentation contains incorrect license information, potentially leading users to inadvertently violate license terms <cite class="ltx_cite ltx_citemacro_citep">(Pepe et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib53" title="">2024</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2. </span>Potential impact #2: Documentation could support cross-functional collaboration and communication about AI risks.</h4>
<div class="ltx_para" id="S4.SS2.SSS2.p1">
<p class="ltx_p" id="S4.SS2.SSS2.p1.1">Documentation has the potential to act as a bridge between different stakeholder groups involved in the AI development lifecycle, including machine learning engineers, data scientists, product managers, user experience designers, researchers, and legal teams. Since no single group oversees all stages of development, effective documentation can facilitate both indirect and direct communication among these diverse teams. Documentation artifacts can convey essential information across organizational boundaries, helping stakeholders who may not interact regularly to align their understanding of the system. Documentation can also prompt and support conversations among stakeholders directly, enabling them to work towards common goals despite their diverse backgrounds, frames of reference, or areas of expertise. This bridging function of documentation could break down organizational silos<cite class="ltx_cite ltx_citemacro_citep">(Chmielinski et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib16" title="">2024</a>)</cite> and promote effective collaboration across different teams <cite class="ltx_cite ltx_citemacro_citep">(Crisan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib19" title="">2022</a>; Gilbert et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib24" title="">2023</a>; Heger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib27" title="">2022</a>; Mohammad, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib44" title="">2022</a>; Pushkarna et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib56" title="">2022</a>; Raji and Yang, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib57" title="">2020</a>; Richards et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib59" title="">2020</a>; Shen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib62" title="">2022</a>; Srinivasan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib68" title="">2021</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.p2">
<p class="ltx_p" id="S4.SS2.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS2.p2.1.1">Hypotheses</span>. AI documentation could serve as an initial point of reference for downstream practitioners, offering a basic overview of the system that allows them to build foundational knowledge before engaging with developers for more in-depth discussions. Rather than acting as a comprehensive, self-contained repository of information, documentation artifacts could provide an initial layer of understanding, enabling downstream practitioners to identify relevant areas for further exploration and formulate more informed questions when collaborating with developers. This could foster more productive and targeted interactions between teams, enhancing their ability to work with or govern AI systems efficiently. Empirical research suggests that practitioners often approach documentation this way. For instance, UX professionals often prefer direct discussions with data scientists rather than relying solely on documentation artifacts <cite class="ltx_cite ltx_citemacro_citep">(Liao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib34" title="">2023</a>)</cite>. Similarly, many AI practitioners review existing documentation only briefly before seeking further clarification through meetings or discussions <cite class="ltx_cite ltx_citemacro_citep">(Heger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib27" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.p3">
<p class="ltx_p" id="S4.SS2.SSS2.p3.1">In more robust forms, documentation can facilitate deeper deliberation among stakeholders about the system’s design and the documentation process itself. For example, documentation has been shown to aid teams in collectively reflecting on socially constructed concepts, such as gender, and making informed decisions about how to annotate such attributes in datasets <cite class="ltx_cite ltx_citemacro_citep">(Pushkarna et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib56" title="">2022</a>)</cite>. Also, the process of creating documentation can help stakeholders identify and discuss trade-offs between competing objectives in system design <cite class="ltx_cite ltx_citemacro_citep">(Shen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib62" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.p4">
<p class="ltx_p" id="S4.SS2.SSS2.p4.1">By having some stakeholders define requirements for documentation artifacts, others generate content, and still others assess the quality of the artifact, the documentation process can help stakeholders understand each others’ needs and constraints in ways that could promote quality, efficiency, and responsibility in the development process <cite class="ltx_cite ltx_citemacro_citep">(Chang and Custis, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib14" title="">2022</a>)</cite>. Over time, engaging with documentation could also improve the technical literacy of stakeholders, enabling them to create products that better meet user needs while minimizing harm <cite class="ltx_cite ltx_citemacro_citep">(Liao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib34" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.p5">
<p class="ltx_p" id="S4.SS2.SSS2.p5.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS2.p5.1.1">Challenges</span>. Several challenges complicate the role of documentation in facilitating cross-functional collaboration. The modern AI supply chain, characterized by the development of general-purpose models that can be adapted to a variety of applications downstream <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib78" title="">2017</a>)</cite>, often limits opportunities for direct communication between stakeholders. In some cases, different teams within the same organization may adapt a general-purpose model for various specific tasks. In these instances, documentation might prompt the downstream team to directly reach out to the original development team to discuss the system’s capabilities and limitations. In other cases, a team deploying a model may rely on a model developed by a different organization <cite class="ltx_cite ltx_citemacro_citep">(Jones, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib32" title="">2023</a>)</cite>. In this case, it will typically be more difficult if not impossible for the downstream deployment team to directly communicate with the original development team.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.p6">
<p class="ltx_p" id="S4.SS2.SSS2.p6.1">In either situation, the original developers may not fully anticipate the variety of downstream uses, leading to documentation that lacks critical details needed to identify potential risks or harms. Particularly when upstream and downstream teams cannot communicate directly, it will be more challenging for them to work together to understand the model’s risks within a given deployment context. This challenge is especially pronounced for less technical downstream stakeholders, who may struggle to understand the functionality and risks associated with these models.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.p7">
<p class="ltx_p" id="S4.SS2.SSS2.p7.1">More interactive forms of documentation, such as those that allow users to engage with the models directly or customize the level of detail presented, could help mitigate these issues by making the information more accessible and relevant <cite class="ltx_cite ltx_citemacro_citep">(Crisan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib19" title="">2022</a>; Liao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib34" title="">2023</a>; Moore et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib46" title="">2023</a>)</cite>, especially when direct communication between teams is limited. However, further research is needed to determine the most effective ways to document general-purpose systems while avoiding overwhelming documentation consumers with excessive or irrelevant details,</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.p8">
<p class="ltx_p" id="S4.SS2.SSS2.p8.1">Another major challenge is that documentation that is misaligned with the needs of its intended consumers can complicate rather than facilitate stakeholder communication. If documentation artifacts are overly technical or jargony, documentation consumers who are less technical or less familiar with the system may struggle to understand what details are most relevant, or misinterpret described practices <cite class="ltx_cite ltx_citemacro_citep">(Crisan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib19" title="">2022</a>; Liao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib34" title="">2023</a>; Miceli et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib41" title="">2021</a>; Shen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib62" title="">2022</a>)</cite>; if documentation lacks relevant details, documentation consumers may overlook risks that become apparent only later in the development process, which may require teams to substantially backtrack. In either case, mismatch in comprehension can contribute to needless disruption to normal workflows. If practitioners perceive that documentation leads to seemingly egregious friction due to misunderstandings, they may be more prone to oversimplify the documentation they produce or gloss over relevant details that they worry will lead to confusion.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.3. </span>Potential impact #3: Documentation could prompt practitioners to deliberate and act on the ethical impacts of AI</h4>
<div class="ltx_para" id="S4.SS2.SSS3.p1">
<p class="ltx_p" id="S4.SS2.SSS3.p1.1">Researchers have suggested that documentation has the potential to encourage practitioners to consider the ethical implications of their systems, leading to more responsible development and use of data, models, and systems. By integrating ethical reflection into the documentation process, practitioners may become more aware of the potential harms their systems could cause, prompting them to make more informed decisions.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS3.p2">
<p class="ltx_p" id="S4.SS2.SSS3.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS3.p2.1.1">Hypotheses.</span> One hypothesis is that when downstream documentation consumers consult documentation on data, models, and systems, it can prompt consideration of potential harms. This consideration could lead practitioners to make more careful decisions about if and when to use certain systems or components. Yet, empirical support for this hypothesis is inconsistent. One study of 23 practitioners examined whether reviewing data documentation artifacts could encourage practitioners to notice ethical issues, contextualize them, and formulate risk mitigation plans <cite class="ltx_cite ltx_citemacro_citep">(Boyd, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib12" title="">2021</a>)</cite>. One subset received a scenario description, dataset, and data documentation, while the rest received only the scenario description and dataset. The researcher found that those with data documentation were more likely to notice ethical issues unprompted, though those without it often recognized concerns when the researcher pressed them — but practitioners had difficulty formulating action plans regardless of whether they had access to documentation. These findings suggest that while documentation artifacts can aid ethical deliberation, documentation is not always necessary and likely not sufficient to enable mitigation of ethical issues.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS3.p3">
<p class="ltx_p" id="S4.SS2.SSS3.p3.1">Documentation also might sensitize producers to the ethical impacts of their work. Documentation frameworks often ask documentation producers to consider and describe the ethical dimensions of their systems. For example, the one framework prompts practitioners to think about privacy implications by inquiring about sensitive information in data <cite class="ltx_cite ltx_citemacro_citep">(Gebru et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib22" title="">2021</a>)</cite>. Another asks about known biases, ethical issues, and safety concerns <cite class="ltx_cite ltx_citemacro_citep">(Arnold et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib5" title="">2019</a>)</cite>, and several frameworks encourage reflection on how systems might negatively impact marginalized users or populations <cite class="ltx_cite ltx_citemacro_citep">(Brajovic et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib13" title="">2023</a>; McMillan-Major et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib40" title="">2021</a>; Shen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib62" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS3.p4">
<p class="ltx_p" id="S4.SS2.SSS3.p4.1">Some researchers have suggested that documentation might be effective at promoting ethical action, even if it only engages practitioners in critical reflection relatively superficially <cite class="ltx_cite ltx_citemacro_citep">(Bender and Friedman, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib8" title="">2018</a>)</cite>. Yet others have taken a more explicit, deliberative approach. Drawing from value-sensitive design <cite class="ltx_cite ltx_citemacro_citep">(Friedman et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib21" title="">2006</a>)</cite>–a method that helps technologists identify and understand normative judgments in the development process–Shen and colleagues developed the Model Authoring Toolkit to help practitioners consider diverse stakeholder values and deliberate on system design trade-offs <cite class="ltx_cite ltx_citemacro_citep">(Shen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib62" title="">2022</a>)</cite>. Their qualitative and survey study of Wikipedia communities found that framing ethical reflection and documentation as a participatory process led to more informed decisions about AI system design and deployment.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS3.p5">
<p class="ltx_p" id="S4.SS2.SSS3.p5.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS3.p5.1.1">Challenges.</span> The assumption that documentation artifacts and processes can promote ethical reasoning among practitioners hinges on the belief that practitioners are sufficiently aware of AI’s ethical risks to users, non-users, and society that they can recognize them when prompted. However, without proper training in responsible AI practices and exposure to groups potentially harmed by AI systems, practitioners may not connect documentation with ethical risks <cite class="ltx_cite ltx_citemacro_citep">(Heger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib27" title="">2022</a>)</cite>. Consequently, their consideration of harms may only partially encompass the scope of risks, especially those requiring non-technical mitigations. For example, practitioners often misunderstand how bias can manifest in their work, leading them to incorrectly state in their documentation that bias concerns are not relevant <cite class="ltx_cite ltx_citemacro_citep">(Hind et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib28" title="">2019</a>)</cite>. While it may not be necessary for ethicists to be embedded in the work process for practitioners to make responsible choices, as some have suggested <cite class="ltx_cite ltx_citemacro_citep">(McLennan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib38" title="">2022</a>)</cite>, findings point to the need for more support and training for practitioners in how to identify, document, and effectively communicate potential risks <cite class="ltx_cite ltx_citemacro_citep">(Heger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib27" title="">2022</a>; Madaio et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib36" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS3.p6">
<p class="ltx_p" id="S4.SS2.SSS3.p6.1">Furthermore, practitioners and organizations may resist documenting ethical impacts they have identifed. Publicly available documentation artifacts, such as Hugging Face model cards and GitHub repository README files, often show little consideration of ethical concerns <cite class="ltx_cite ltx_citemacro_citep">(Pepe et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib53" title="">2024</a>; Liang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib33" title="">2024</a>)</cite>. While this omission might occur because practitioners are unaware of potential harms <cite class="ltx_cite ltx_citemacro_citep">(Heger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib27" title="">2022</a>)</cite>, their absence could also result from practitioners being hesitant to record ethical concerns they did recognize. Sometimes practitioners resist addressing ethical impacts because they feel unqualified to speculate on numerous potential use cases and their impacts <cite class="ltx_cite ltx_citemacro_citep">(Crisan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib19" title="">2022</a>; Heger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib27" title="">2022</a>; Hind et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib28" title="">2019</a>; Nunes et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib49" title="">2022</a>)</cite>. Others worry that detailing ethical concerns might give downstream stakeholders a false sense of security <cite class="ltx_cite ltx_citemacro_citep">(Crisan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib19" title="">2022</a>)</cite>. This hesitation could also stem from a desire to avoid personal responsibility for their actions <cite class="ltx_cite ltx_citemacro_citep">(Nunes et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib49" title="">2022</a>)</cite>. Alternatively, practitioners could plausibly have concerns that documenting potential ethical harms could create a legal or public relations risk if outside stakeholders gained access to documentation.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS3.p7">
<p class="ltx_p" id="S4.SS2.SSS3.p7.1">Even if documentation effectively engages practitioners in ethical reflection, they may have little influence over their organization’s development goals, deliverables, and timelines. As a result, they might be unable to make the changes to data, models, or systems that they have identified as useful or necessary to address ethical risks through the documentation process. One ethnographic study found that business demands, not the beliefs of data subjects or practitioners, largely determined the organization’s documentation approaches <cite class="ltx_cite ltx_citemacro_citep">(Miceli et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib41" title="">2021</a>)</cite>. For example, although practitioners who reflected on data labeling practices recognized that socially constructed identities are complex, the organization nevertheless chose to represent identity in a reductive way, such as by defining race according to discrete, mutually exclusive categories. The authors concluded that explicit and implicit power structures among internal organizational stakeholders significantly affect practitioners’ documentation practices and ability to shape outcomes. Documentation approaches must be responsive to these constraints. Otherwise, documentation about ethical considerations may not promote meaningful action or may be incomplete or misleading.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS3.p8">
<p class="ltx_p" id="S4.SS2.SSS3.p8.1">On the whole, evidence on the extent to which AI documentation frameworks can truly enhance ethical decision-making is mixed. Practitioners are capable of ethical deliberation about AI, but do not always thoroughly explore ethical issues or record the results in documentation artifacts. Even if practitioners engage in ethical deliberation when creating and using documentation, organizational environments can enable or constrain individual practitioners’ normative choices.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.4. </span>Potential impact #4: Documentation could catalyze overall improvements in governance and development.</h4>
<div class="ltx_para" id="S4.SS2.SSS4.p1">
<p class="ltx_p" id="S4.SS2.SSS4.p1.1">Researchers have suggested that documentation can significantly influence governance and development practices broadly. In practical settings, AI documentation doesn’t function independently; documentation processes typically require practitioners to engage in other activities that can improve AI outcomes. Thus, the documentation process can catalyze behaviors that enhance the quality of AI system development and governance beyond documentation processes and artifacts.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS4.p2">
<p class="ltx_p" id="S4.SS2.SSS4.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS4.p2.1.1">Hypotheses.</span> Framework authors posit that documentation could improve the rigor with which practitioners develop AI systems <cite class="ltx_cite ltx_citemacro_citep">(Holland et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib29" title="">2018</a>)</cite>. By requiring practitioners to justify their development choices, documentation may lead to more careful decision-making <cite class="ltx_cite ltx_citemacro_citep">(Bender and Friedman, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib8" title="">2018</a>; Chmielinski et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib16" title="">2024</a>; Holland et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib29" title="">2018</a>)</cite>. Also, clear and comprehensive documentation supports reproducibility, aiding other practitioners in retraining and validating systems consistently <cite class="ltx_cite ltx_citemacro_citep">(Adkins et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib2" title="">2022</a>; Baracaldo et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib6" title="">2022</a>; Hind et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib28" title="">2019</a>)</cite>. Since AI practitioners are often driven by a commitment to scientific rigor <cite class="ltx_cite ltx_citemacro_citep">(Winecoff and Watkins, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib79" title="">2022</a>)</cite>, documentation that emphasizes this aspect can serve as a ”value lever <cite class="ltx_cite ltx_citemacro_citep">(Shilton, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib63" title="">2013</a>)</cite>,” further encouraging engagement with the documentation process .</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS4.p3">
<p class="ltx_p" id="S4.SS2.SSS4.p3.1">Documentation might also improve development and governance efficiency. In large organizations, datasets, models, and systems developed for one purpose may also be useful to other teams with similar goals. Documentation can make system components more discoverable, helping practitioners avoid duplicating efforts <cite class="ltx_cite ltx_citemacro_citep">(Heger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib27" title="">2022</a>)</cite>. Documentation can quickly provide information on the limitations of using a dataset, model, or system <cite class="ltx_cite ltx_citemacro_citep">(Rostamzadeh et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib61" title="">2022</a>)</cite>, which could allow practitioners to allocate more time to identifying and addressing any additional risks that may arise when integrating components into new systems. It can also include details relevant to company or legal policies that apply to system components, preventing practitioners from wasting time on products and features that their organizations ultimately won’t approve for deployment <cite class="ltx_cite ltx_citemacro_citep">(Roman et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib60" title="">2023</a>)</cite>. Practitioners also point out that by documenting unsuccessful and successful approaches, organizations can prevent repeated mistakes and identify practices that would be beneficial for the organization to disseminate broadly <cite class="ltx_cite ltx_citemacro_citep">(Chang and Custis, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib14" title="">2022</a>; Miceli et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib41" title="">2021</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS4.p4">
<p class="ltx_p" id="S4.SS2.SSS4.p4.1">Documentation could also facilitate proactive risk mitigation, which is often more efficient than reactive approaches <cite class="ltx_cite ltx_citemacro_citep">(Mitchell et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib43" title="">2019</a>)</cite>. When issues arise in already-deployed systems, organizations typically need to fix the problem without disrupting service quality or availability. They might need to roll back to a previous version of the system that is less performant or apply quick patches that may not fully resolve the issue. Documentation that helps identify potential problems before deployment can lead to more comprehensive solutions than addressing issues post hoc once they are discovered in production systems <cite class="ltx_cite ltx_citemacro_citep">(Holland et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib29" title="">2018</a>)</cite>. And helping teams discover and use approved AI components that have already undergone relevant risk management processes rather than creating new ones can help ensure risks are not re-introduced and overlooked.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS4.p5">
<p class="ltx_p" id="S4.SS2.SSS4.p5.1">Furthermore, documentation could preserve institutional knowledge. In any organization, particularly complex ones, consistently institutionalizing values and best practices can be challenging. Documentation could serve as a means of conveying technical information about systems, and the organization’s policies and values that influence development and use. For instance, documentation can aid in onboarding new employees by providing information about the systems they’ll work on and communicating the organization’s approach to development and governance <cite class="ltx_cite ltx_citemacro_citep">(Adkins et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib2" title="">2022</a>; Chang and Custis, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib14" title="">2022</a>; Heger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib27" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS4.p6">
<p class="ltx_p" id="S4.SS2.SSS4.p6.1">Lastly, documentation could facilitate both internal and external audits <cite class="ltx_cite ltx_citemacro_citep">(Brajovic et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib13" title="">2023</a>; Crisan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib19" title="">2022</a>; Hupont and Gomez, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib30" title="">2022</a>; Miceli et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib41" title="">2021</a>)</cite>. Audits may focus on the components of AI systems, the overall application, or the processes used in development <cite class="ltx_cite ltx_citemacro_citep">(Mökander et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib45" title="">2023</a>)</cite>. Documentation could help organizations demonstrate that their claims—such as providing equitable system performance across different demographic groups—are backed by evidence. In these cases, documentation could guide auditors in selecting appropriate methods based on the auditor’s objectives and the available data. When audits examine the robustness of an organization’s governance, documentation becomes even more critical <cite class="ltx_cite ltx_citemacro_citep">(Clavell, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib18" title="">2024</a>)</cite>. Without comprehensive documentation, organizations may struggle to demonstrate the integrity and consistency of their processes.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS4.p7">
<p class="ltx_p" id="S4.SS2.SSS4.p7.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS4.p7.1.1">Challenges.</span> One barrier to documentation facilitating best practices in development and governance is that the documentation process must be interconnected with other organizational processes to serve as an effective forcing function. In cases where documentation is ad-hoc and relies on tools that are not well-integrated with practitioners’ workflows <cite class="ltx_cite ltx_citemacro_citep">(Bhat et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib10" title="">2023</a>; Heger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib27" title="">2022</a>)</cite>, connecting documentation processes and artifacts to other aspects of the development and governance process becomes even more challenging. Without a solid documentation infrastructure that aligns with other organizational functions, documentation may fail to effectively enhance development and risk management.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS4.p8">
<p class="ltx_p" id="S4.SS2.SSS4.p8.1">Another challenge is that while high-quality documentation can improve governance and development, poor-quality documentation can have negative impacts. Documentation should prevent redundant efforts, maximize time spent managing unique risks, and support proactive system development. However, these benefits depend on the quality of the documentation. Inadequate or incorrect documentation can lead to wasted time, overlooked risks, and unexpected issues that may require correction later in development. This could result in harms remaining unaddressed or inefficiencies that undermine the overall governance process.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Design considerations</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">How organizations choose to document AI systems reflects both their normative values and practical constraints. Design and implementation choices are also influenced by established and emerging external requirements, such as regulations that companies must adhere to. As organizations (and regulators) aim to maximize the benefits of documentation across various types of AI systems and components, they must often navigate tensions in their approach. Our analysis identified common design tensions or considerations organizations must navigate. These include: balancing customization and standardization, tailoring documentation to specific audiences, determining the appropriate level of detail, deciding on the degree of automation in the documentation process, and incorporating interactivity into documentation artifacts. To an extent, these design considerations are interrelated: the level of detail documentation artifacts contain can also be a form of audience tailoring, for example. Yet each of these design tensions has partially distinct motivations and implications, so we address them separately.</p>
</div>
<section class="ltx_subsubsection" id="S4.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.1. </span>Design consideration #1: Determining the degree of customization versus standardization in documentation artifacts.</h4>
<div class="ltx_para" id="S4.SS3.SSS1.p1">
<p class="ltx_p" id="S4.SS3.SSS1.p1.1">Organizations often create datasets, models, and systems for various purposes, employing a wide range of techniques and components. This diversity leads to a variety of risks, which customization is well-suited to address. At the same time, standardized documentation helps establish consistent practices and institutionalize norms.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS1.p2">
<p class="ltx_p" id="S4.SS3.SSS1.p2.1">One advantage of customization is that it can address the specific risks and capabilities of an organization or AI system. For instance, annotating the origin of data collected in different healthcare settings can be crucial, as different settings serve distinct patient populations and employ varied healthcare practitioners. This information can help practitioners identify gaps in the dataset or regions where the dataset may be less applicable <cite class="ltx_cite ltx_citemacro_citep">(Rostamzadeh et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib61" title="">2022</a>)</cite>. Conversely, annotating the origin of code snippets from software engineers working in different contexts may be less important since code typically functions similarly across different environments.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS1.p3">
<p class="ltx_p" id="S4.SS3.SSS1.p3.1">Echoing calls to ground approaches to AI harms within the context of deployment <cite class="ltx_cite ltx_citemacro_citep">(Hutchinson et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib31" title="">2022</a>; Narayanan and Kapoor, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib47" title="">2024</a>; Nicholas, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib48" title="">2024</a>)</cite>, several frameworks recommend collectively documenting the system components that pertain to a given use case rather than separately documenting datasets, models, or systems independent of their intended use case <cite class="ltx_cite ltx_citemacro_citep">(Chmielinski et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib17" title="">2020</a>; Hupont and Gomez, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib30" title="">2022</a>; Mohammad, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib44" title="">2022</a>; Rostamzadeh et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib61" title="">2022</a>; Srinivasan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib68" title="">2021</a>)</cite>. For example, some researchers have proposed specific documentation methods for affective computing <cite class="ltx_cite ltx_citemacro_citep">(Hupont and Gomez, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib30" title="">2022</a>)</cite>, since these methods pose unique risks related to psychological manipulation and surveillance and so may merit a tailored approach. Moreover, because affective computing applications are likely to be classified as high-risk by the EU AI Act, applications using affective computing are also more likely to be subject to specific documentation requirements <cite class="ltx_cite ltx_citemacro_citep">(Hupont and Gomez, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib30" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS1.p4">
<p class="ltx_p" id="S4.SS3.SSS1.p4.1">Customization can also be valuable at the model level, as different models are designed to perform unique functions and thus pose unique risks. In one study, practitioners argued that the information within a model card should be rearranged to ensure that documentation consumers clearly understand the specific model’s purpose and limitations <cite class="ltx_cite ltx_citemacro_citep">(Crisan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib19" title="">2022</a>)</cite>. Another study found that practitioners added technical details to standardized documentation, even when instructed not to, suggesting that they believe standardized formats need flexibility to include model-specific details they find relevant <cite class="ltx_cite ltx_citemacro_citep">(Bhat et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib10" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS1.p5">
<p class="ltx_p" id="S4.SS3.SSS1.p5.1">At the organizational level, customization might also be necessary. For example, a healthcare startup may require a different documentation approach than a large, well-established financial institution. In some cases, it may be appropriate to customize documentation at multiple levels to respond to both the organization’s nature and the type of system it is developing <cite class="ltx_cite ltx_citemacro_citep">(Chmielinski et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib17" title="">2020</a>; Gebru et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib22" title="">2021</a>; Holland et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib29" title="">2018</a>; Richards et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib59" title="">2020</a>; Roman et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib60" title="">2023</a>; Stoyanovich and Howe, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib69" title="">2019</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS1.p6">
<p class="ltx_p" id="S4.SS3.SSS1.p6.1">While customization has many benefits, it also presents challenges. Standard formats facilitate the development of tools that allow practitioners to search for system components that meet particular specifications, improving discoverability and efficiency within an organization’s ecosystem <cite class="ltx_cite ltx_citemacro_citep">(Heger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib27" title="">2022</a>)</cite>. Since such tools might enable practitioners to more easily find appropriate components, it might also reduce the likelihood that they employ inappropriate ones. This enhanced discoverability is often cited as one of the most significant benefits of documentation by practitioners <cite class="ltx_cite ltx_citemacro_citep">(Heger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib27" title="">2022</a>; Reid and Williams, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib58" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS1.p7">
<p class="ltx_p" id="S4.SS3.SSS1.p7.1">Standardized documentation could also facilitate practitioners comparing candidate datasets, models, and systems, and for comparing AI and non-AI approaches <cite class="ltx_cite ltx_citemacro_citep">(Chmielinski et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib16" title="">2024</a>; Gilbert et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib24" title="">2023</a>; Hind et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib28" title="">2019</a>; Mitchell et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib43" title="">2019</a>; Reid and Williams, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib58" title="">2023</a>; Shen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib62" title="">2022</a>; Stoyanovich and Howe, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib69" title="">2019</a>; Zheng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib81" title="">2022</a>)</cite>. When documentation artifacts vary significantly in the type of information they contain or how this information is presented, comparisons become more challenging. Given the time constraints and the currently limited incentives for creating <cite class="ltx_cite ltx_citemacro_citep">(Chang and Custis, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib14" title="">2022</a>; Heger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib27" title="">2022</a>; Miceli et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib41" title="">2021</a>)</cite> and using <cite class="ltx_cite ltx_citemacro_citep">(Crisan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib19" title="">2022</a>)</cite> documentation, maintaining the core utility of documentation through standardization could support broader adoption within organizations.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS1.p8">
<p class="ltx_p" id="S4.SS3.SSS1.p8.1">A more diffuse but critical benefit of standardization is its role in helping the AI community converge on norms of practice and communication <cite class="ltx_cite ltx_citemacro_citep">(Arnold et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib5" title="">2019</a>; McMillan-Major et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib40" title="">2021</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib39" title="">2024</a>)</cite>. Practitioners often struggle with how to complete documentation or what level of detail to include <cite class="ltx_cite ltx_citemacro_citep">(Chang and Custis, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib14" title="">2022</a>; Pushkarna et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib56" title="">2022</a>; Heger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib27" title="">2022</a>; Miceli et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib41" title="">2021</a>)</cite>, leading them to rely heavily on existing examples, which may not always be appropriate. In one study, practitioners frequently copied documentation from previous projects into their current work, sometimes including irrelevant information or omitting crucial details <cite class="ltx_cite ltx_citemacro_citep">(Pushkarna et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib56" title="">2022</a>)</cite>. Standardization can mitigate these issues by providing clear expectations for what information should be included and what users should expect to find in documentation artifacts, thus encouraging more consistent practices <cite class="ltx_cite ltx_citemacro_citep">(McMillan-Major et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib40" title="">2021</a>; Pushkarna et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib56" title="">2022</a>; Roman et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib60" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS1.p9">
<p class="ltx_p" id="S4.SS3.SSS1.p9.1">Standardization also might facilitate structured risk management. If documentation producers are instructed to select certain details from structured categories, or certain fields are constrained to particular structured formats, these fields can be used to trigger certain governance actions, such as scheduling a review or requiring that a certain mitigation be applied prior to proceeding. On the other hand, such process automation can mean that concepts and risks are oversimplified, and that processes or mitigations are recommended in cases where they may not be appropriate, while leaving other relevant risks to be overlooked.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS1.p10">
<p class="ltx_p" id="S4.SS3.SSS1.p10.1">The choice between customization and standardization is not always a strict binary but a spectrum, allowing for a combination of both. For example, organizations can create standardized templates that are adapted to different contexts, such as healthcare models versus those for software engineers, ensuring consistency while meeting specific needs. However, organizations must thoughtfully decide when to standardize and when to customize.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.2. </span>Design consideration #2: Determining how much to tailor documentation artifacts to specific audiences</h4>
<div class="ltx_para" id="S4.SS3.SSS2.p1">
<p class="ltx_p" id="S4.SS3.SSS2.p1.1">When designing documentation strategies, organizations must consider the diverse needs of multiple stakeholder groups. Different stakeholders often require distinct forms of documentation to be effective. To meet these varied needs, organizations might choose to produce tailored documentation for each stakeholder group. Alternatively, organizations might opt for a single, general-purpose artifact that all stakeholders can use, though this might not be adequately tailored to a specific purpose.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS2.p2">
<p class="ltx_p" id="S4.SS3.SSS2.p2.1">A single-format artifact may not adequately serve any particular stakeholder group. For instance, documentation designed for data scientists might not be accessible or useful to UX professionals or other non-technical stakeholders <cite class="ltx_cite ltx_citemacro_citep">(Liao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib34" title="">2023</a>)</cite>. Similarly, documentation aimed at public transparency might lack the depth needed by internal decision-makers handling risk management. This highlights a key trade-off: while a single-format document can reduce the complexity of documentation management, it risks failing to meet the specialized needs of different groups.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS2.p3">
<p class="ltx_p" id="S4.SS3.SSS2.p3.1">Stakeholder-specific documentation, meanwhile, can address the unique needs of different groups of practitioners. These groups, including users, policymakers, data scientists, engineers, lawyers, and others <cite class="ltx_cite ltx_citemacro_citep">(Micheli et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib42" title="">2023</a>)</cite>, often have distinct goals and use different terminologies, which can influence the type of documentation produced and the most helpful forms for each group. Documentation tailored to its specific audience is more likely to provide stakeholders with the necessary information for accomplishing their goals. Without a clear target audience, documentation producers might only address what is relevant to their own team <cite class="ltx_cite ltx_citemacro_citep">(Heger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib27" title="">2022</a>)</cite>, potentially overlooking critical information needed by other teams <cite class="ltx_cite ltx_citemacro_citep">(Hind et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib28" title="">2019</a>)</cite> or presenting it in an unusable format <cite class="ltx_cite ltx_citemacro_citep">(Liao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib34" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS2.p4">
<p class="ltx_p" id="S4.SS3.SSS2.p4.1">Tailoring documentation is particularly important when conveying technical information to non-technical stakeholders, both within and outside the organization. While many researchers propose frameworks that aim to make documentation comprehensible to both technical and non-technical practitioners <cite class="ltx_cite ltx_citemacro_citep">(Holland et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib29" title="">2018</a>; McMillan-Major et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib40" title="">2021</a>; Mohammad, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib44" title="">2022</a>; Pushkarna et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib56" title="">2022</a>; Richards et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib59" title="">2020</a>; Roman et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib60" title="">2023</a>; Sokol and Flach, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib67" title="">2020</a>; Tagliabue et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib73" title="">2021</a>)</cite>, empirical studies indicate that non-technical audiences often struggle to understand even simplified technical details <cite class="ltx_cite ltx_citemacro_citep">(Crisan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib19" title="">2022</a>; Liao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib34" title="">2023</a>; Miceli et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib41" title="">2021</a>; Shen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib62" title="">2022</a>)</cite>. For example, in a study where non-technical practitioners used documentation to assess model risks, a significant proportion failed to correctly identify the model’s basic purpose <cite class="ltx_cite ltx_citemacro_citep">(Crisan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib19" title="">2022</a>)</cite>. Using documentation, non-technical practitioners may struggle to grasp technical information, such as accuracy metrics <cite class="ltx_cite ltx_citemacro_citep">(Shen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib62" title="">2022</a>)</cite>. This suggests that unless technical information is presented in simpler terms, non-technical stakeholders may still face challenges in interpreting technical information necessary for risk assessment when it is not specifically tailored to their needs.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS2.p5">
<p class="ltx_p" id="S4.SS3.SSS2.p5.1">Another advantage of stakeholder-specific documentation is its ability to leverage the expertise of different practitioners more effectively. Tailoring documentation allows stakeholders to focus on the most relevant information for their roles, thereby enhancing the organization’s ability to identify and manage risks. For instance, in developing a documentation framework for healthcare data, machine learning experts prioritized the dataset’s composition, while healthcare experts focused on the details of medical diagnoses and data collection processes, as these were crucial for interpreting the data’s relevance and limitations <cite class="ltx_cite ltx_citemacro_citep">(Rostamzadeh et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib61" title="">2022</a>)</cite>. By emphasizing information pertinent to their expertise, stakeholders can conduct more thorough analyses and potentially uncover issues that others might miss <cite class="ltx_cite ltx_citemacro_citep">(Pushkarna et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib56" title="">2022</a>; Rostamzadeh et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib61" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS2.p6">
<p class="ltx_p" id="S4.SS3.SSS2.p6.1">Tailored documentation can also be more actionable for practitioners. One common issue with general-purpose documentation is that it may not clearly guide stakeholders on how to use the information provided <cite class="ltx_cite ltx_citemacro_citep">(Adkins et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib2" title="">2022</a>; Crisan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib19" title="">2022</a>; Stoyanovich and Howe, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib69" title="">2019</a>)</cite>. This issue is particularly significant when practitioners fail to connect documentation with the ethical impacts of their work <cite class="ltx_cite ltx_citemacro_citep">(Heger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib27" title="">2022</a>)</cite>, indicating a need for prescriptive guidance to manage AI risks effectively. The actions practitioners take in response to documentation often depend on their specific roles for two reasons. First, when documentation is aligned with the purpose of their role, practitioners are better able to understand the necessary actions to manage risk. For example, information about how well a system meets user needs may be more actionable for a UX professional than a machine learning engineer. Second, practitioners typically have the authority to act in specific ways within organizations. For instance, compliance teams cannot implement changes to the production codebase, and data scientists are not responsible for conducting legal reviews. Tailored documentation that aligns with each group’s roles and responsibilities can guide them toward actions they are empowered to take.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS2.p7">
<p class="ltx_p" id="S4.SS3.SSS2.p7.1">Whereas multiple forms of documentation can better meet diverse stakeholder needs, single-format documentation can help reduce confusion and avoid the fragmentation that occurs when information is scattered across different formats, such as README files, wikis, and slide decks <cite class="ltx_cite ltx_citemacro_citep">(Heger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib27" title="">2022</a>)</cite>. Even with centralized repositories that link different versions, managing multiple formats can still lead to confusion about the existence and authority of these artifacts and make it difficult for practitioners to access the information they need and develop a cohesive understanding.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS2.p8">
<p class="ltx_p" id="S4.SS3.SSS2.p8.1">Furthermore, single-format documentation may be easier to produce and maintain. If practitioners are required to create multiple forms of documentation to meet the needs of different stakeholders, organizations must ensure sufficient time is allocated for this process. Without adequate time, practitioners may rush, leading to low-quality documentation. In cases where time constraints are a concern, it may be more effective to focus on producing a single, high-quality document that is regularly updated. At a minimum, all documentation should clearly indicate its last update to help users gauge its relevance and accuracy.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS3.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.3. </span>Design trade-off #3: Determining the level of interactivity documentation should support</h4>
<div class="ltx_para" id="S4.SS3.SSS3.p1">
<p class="ltx_p" id="S4.SS3.SSS3.p1.1">Producing multiple forms of documentation is one way to support a variety of goals, stakeholders, and systems and goals; however, these multiple forms of documentation create challenges for organizations to manage. Interactive documentation offers an alternative solution by enabling stakeholders to access the specific information they need while maintaining overall usability and comprehension.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS3.p2">
<p class="ltx_p" id="S4.SS3.SSS3.p2.1">Interactive documentation may be able to effectively serve multiple stakeholders with a single artifact. For example, interactive system diagrams might allow practitioners to click on specific components to access technical details <cite class="ltx_cite ltx_citemacro_citep">(Procope et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib55" title="">2022</a>)</cite>, while expandable sections can provide additional context as necessary <cite class="ltx_cite ltx_citemacro_citep">(Crisan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib19" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS3.p3">
<p class="ltx_p" id="S4.SS3.SSS3.p3.1">Empirical research supports the idea that interactive documentation can significantly improve understanding, particularly among non-technical audiences <cite class="ltx_cite ltx_citemacro_citep">(Crisan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib19" title="">2022</a>; Liao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib34" title="">2023</a>; Moore et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib46" title="">2023</a>)</cite>. Tools like Hugging Face’s model inference API<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>https://huggingface.co/docs/api-inference/</span></span></span> or OpenAI’s developer playground<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>https://platform.openai.com/playground</span></span></span> allow practitioners to engage with models and systems directly, fostering an intuitive understanding of how inputs and outputs are connected. This hands-on interaction is crucial for designing products that leverage the system’s capabilities and for assessing potential risks <cite class="ltx_cite ltx_citemacro_citep">(Liao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib34" title="">2023</a>)</cite>. Interactive access is particularly valuable when exploring pre-trained, general-purpose models, whose functionality can vary significantly depending on the implementation <cite class="ltx_cite ltx_citemacro_citep">(Liao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib34" title="">2023</a>; Moore et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib46" title="">2023</a>; Crisan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib19" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS3.p4">
<p class="ltx_p" id="S4.SS3.SSS3.p4.1">However, interactive documentation also presents challenges. Without good information architecture, it can overwhelm users, leading to cognitive overload rather than enhancing understanding <cite class="ltx_cite ltx_citemacro_citep">(Crisan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib19" title="">2022</a>)</cite>. Additionally, interactive documentation requires additional engineering effort to design and maintain, which may be resource-intensive for organizations. In contrast, static documentation offers consistency and simplicity. It presents information in a uniform format, fostering a common understanding that can enhance communication, collaboration, and decision-making across teams.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS3.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.4. </span>Design consideration #4: Determining the level of detail documentation artifacts should contain.</h4>
<div class="ltx_para" id="S4.SS3.SSS4.p1">
<p class="ltx_p" id="S4.SS3.SSS4.p1.1">Organizations must determine what level of detail to include in documentation artifacts. Whereas exhaustive documentation might ensure practitioners have access to all the necessary information, concise documentation may improve ease of production and use.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS4.p2">
<p class="ltx_p" id="S4.SS3.SSS4.p2.1">Concise documentation can help stakeholders focus on the details that are most relevant to their needs, reducing the likelihood of information overload. For documentation aimed at downstream consumers, including internal risk management professionals, it is essential to provide enough detail to support decision-making without overwhelming them. Information overload can lead to selective attention, where decision-makers may focus on certain details while neglecting others, potentially degrading the quality of their decisions <cite class="ltx_cite ltx_citemacro_citep">(Phillips-Wren and Adya, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib54" title="">2020</a>)</cite>, particularly under time constraints <cite class="ltx_cite ltx_citemacro_citep">(Hahn et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib26" title="">1992</a>)</cite>. For example, faced with extensive and complex documentation on AI systems, consumers might miss critical information or become frustrated and abandon the effort. As one participant in a research study noted, ”I would lose patience after 30-40 seconds if I have to put a lot of effort into finding what I’m looking for” <cite class="ltx_cite ltx_citemacro_citep">(Crisan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib19" title="">2022</a>)</cite>. Concise documentation that highlights the most important information for a given stakeholder group can help internal decision-makers manage risk more effectively by ensuring they focus on critical details.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS4.p3">
<p class="ltx_p" id="S4.SS3.SSS4.p3.1">Moreover, concise documentation is often easier to produce and maintain, which can enhance accuracy and encourage more frequent use. Exhaustive documentation may be burdensome to create and keep updated, particularly if the process is manual. For instance, in the initial case studies of an extensive data documentation framework, practitioners reported that completing the documentation took two to three hours, excluding the time needed to gather the required information <cite class="ltx_cite ltx_citemacro_citep">(Bender and Friedman, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib8" title="">2018</a>)</cite>. While a few hours might be manageable for a single project, this time commitment becomes overwhelming when scaled across an entire organization, potentially involving hundreds or thousands of datasets, models, or systems. In such scenarios, spreading effort thinly across all systems might detract from the focus on high-risk or high-impact components, undermining critical risk management efforts.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS4.p4">
<p class="ltx_p" id="S4.SS3.SSS4.p4.1">However, while concise documentation has its advantages, it may omit details that, although not relevant to most uses, are crucial for specific applications. Exhaustive documentation provides a more comprehensive overview that can accommodate a broader range of applications. For example, consider a dataset containing patient information and healthcare outcomes over a year. If a model uses this dataset to predict patients’ health outcomes over time, the model’s accuracy depends on the validity and reliability of the data’s timestamps. Documenting how these timestamps were applied is essential for practitioners intending to use the dataset for this purpose. On the other hand, if the dataset is used for clustering patients into broad categories, temporal information becomes less critical. Therefore, the project’s purpose and the specific stakeholders involved should shape the level of detail included in the documentation.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS3.SSS5">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.5. </span>Design consideration #5: Determining the amount of automation in the documentation process.</h4>
<div class="ltx_para" id="S4.SS3.SSS5.p1">
<p class="ltx_p" id="S4.SS3.SSS5.p1.1">Documentation encompasses two main types of information: data that can be extracted automatically from the system and information that requires human input. Information that could potentially be derived directly from source code or generated through scripts interacting with system components includes elements such as data quantity, distribution, statistical properties, model types and parameters, system flow, and software library usage. In contrast, information related to human decision-making processes and organizational context requires manual input. This includes the motivations for developing specific datasets or models, criteria for selecting data sources, reasoning behind chosen methodologies, outcomes of compliance reviews, contact information for responsible parties, decommissioning procedures, and ethical considerations addressed during development.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS5.p2">
<p class="ltx_p" id="S4.SS3.SSS5.p2.1">One of the purposes of both producing and using documentation within an organization is to prompt developers to consider the ethical implications of their systems. However, the degree of automation in the documentation process can significantly influence how thoroughly practitioners engage with these considerations. Fully automated documentation requires minimal direct involvement, which may not encourage the level of critical reflection necessary to address complex ethical issues. As a result, some experts advocate for completing documentation manually, even when automation is feasible, to ensure that practitioners engage deeply with the material <cite class="ltx_cite ltx_citemacro_citep">(Gebru et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib22" title="">2021</a>; McMillan-Major et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib39" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS5.p3">
<p class="ltx_p" id="S4.SS3.SSS5.p3.1">However, automated documentation offers significant benefits in terms of efficiency and accuracy. Manually creating documentation is time-consuming and prone to errors, particularly if it is not well integrated with practitioners’ existing tools and workflows <cite class="ltx_cite ltx_citemacro_citep">(Bhat et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib10" title="">2023</a>)</cite>. Practitioners have noted that automation can reduce the time required to complete documentation and increase the likelihood that it is kept up-to-date <cite class="ltx_cite ltx_citemacro_citep">(Heger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib27" title="">2022</a>)</cite>. Automation also reduces the burden on practitioners to recall critical information after the fact <cite class="ltx_cite ltx_citemacro_citep">(Hind et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib28" title="">2019</a>)</cite>, which can be particularly valuable in complex, fast-paced environments. Organizations should also be aware that practitioners facing multiple competing priorities may circumvent manual processes by implementing their own forms of unaccountable automation. Well-designed automation of some portions of documentation could reduce this risk.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4. </span>Recommendations</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">Given that organizations have unique requirements and operate in vastly different contexts, there is no one-size-fits-all approach to documentation or a universal set of information that applies to all datasets, models, or systems. However, our analysis of proposed frameworks and empirical findings suggests several considerations that organizations should take into account when designing and implementing their documentation strategies. Each of these recommendations could be further strengthened by novel empirical research about how organizations can maximize the benefits of implementing the recommendations in applied contexts.</p>
</div>
<div class="ltx_para" id="S4.SS4.p2">
<p class="ltx_p" id="S4.SS4.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS4.p2.1.1">Identify critical stakeholders and their documentation needs.</span> When developing AI documentation strategies, organizations should begin by identifying the stakeholders who will frequently and significantly interact with both the documentation processes and artifacts. It’s important to consider not only the needs of those who will consume the documentation but also the expertise and capacity of those responsible for producing it. If the documentation is designed to be highly informative for downstream users but is impractical for upstream practitioners to produce, the approach is likely to fail in practice. In such cases, organizations may need to expand their documentation teams to ensure they can meet the needs of consumers effectively. Also, organizations should take into account the technical and non-technical backgrounds of their stakeholders to strike a balance between providing the necessary level of detail and maintaining accessibility.</p>
</div>
<div class="ltx_para" id="S4.SS4.p3">
<p class="ltx_p" id="S4.SS4.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS4.p3.1.1">Evaluate operational resources and constraints and incentivize the production of robust documentation within that context.</span> A realistic assessment of available resources—such as time, personnel, and expertise—is crucial for supporting effective documentation. Overly ambitious documentation efforts without adequate resources can lead to failures, such as incomplete or inaccurate documentation. It is often better to produce concise, high-quality documentation than to attempt a comprehensive approach that falls short. Organizations should ensure that practitioners understand their documentation responsibilities and that incentives are in place to promote thorough and accurate documentation practices.</p>
</div>
<div class="ltx_para" id="S4.SS4.p4">
<p class="ltx_p" id="S4.SS4.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS4.p4.1.1">Leverage empirical evidence and feedback for continuous improvement.</span> Organizations should evaluate potential documentation approaches via pilot projects and periodically collect empirical data on the efficacy of their documentation practices in meeting the needs of relevant stakeholders. Organizations should plan to assess the usability of documentation frameworks and their effectiveness in achieving the organization’s goals <cite class="ltx_cite ltx_citemacro_citep">(Berman et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib9" title="">2024</a>)</cite>, and adapt their documentation strategies by conducting continuous assessments as their needs or technology evolves. Given the limited empirical data on the effectiveness of documentation approaches, organizations can also contribute to the broader AI community by publicly sharing their findings on what works best in different contexts. Organizations should recognize that empirical evidence and key performance indicators can be qualitative and quantitative. Whereas quantitative evidence can help organizations assess general trends at scale, qualitative evidence can help them understand unique issues in greater depth.</p>
</div>
<div class="ltx_para" id="S4.SS4.p5">
<p class="ltx_p" id="S4.SS4.p5.1"><span class="ltx_text ltx_font_bold" id="S4.SS4.p5.1.1">Use standardization as the default approach, and intentionally deviate from it when necessary.</span> Standardization offers many advantages. It allows practitioners to compare documentation artifacts, facilitates search and discoverability of information, establishes consistent expectations for documentation producers and consumers, and can help institutionalize norms of practice. For these reasons, some level of standardization in documentation processes and artifacts is likely to be helpful for most organizations for most AI systems.</p>
</div>
<div class="ltx_para" id="S4.SS4.p6">
<p class="ltx_p" id="S4.SS4.p6.1">To balance standardization and customization, organizations might develop customizable documentation templates or interchangeable modules <cite class="ltx_cite ltx_citemacro_citep">(Bhat et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib10" title="">2023</a>; Heger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib27" title="">2022</a>; Hind et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib28" title="">2019</a>; Holland et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib29" title="">2018</a>; McMillan-Major et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib40" title="">2021</a>; Pushkarna et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib56" title="">2022</a>; Richards et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib59" title="">2020</a>)</cite>. Templates could, for example, allow for customization of subsections while maintaining consistent content and structure within those subsections. For instance, companies may include a subsection on the labeling process for AI systems based on supervised learning but exclude it for unsupervised AI systems since they do not require labels. Where companies choose to embrace a greater degree of customization, they should ensure that the benefits of this customization outweigh the benefits of maintaining standardization.</p>
</div>
<div class="ltx_para" id="S4.SS4.p7">
<p class="ltx_p" id="S4.SS4.p7.1"><span class="ltx_text ltx_font_bold" id="S4.SS4.p7.1.1">Leverage automation for information extraction and incorporate manual processes for scoped critical synthesis.</span> Some helpful information for documentation, such as dataset composition, statistical properties, model training methods, parameters, and software library or third-party API usage, can be extracted from AI systems using automated procedures, contributing to consistent, high-fidelity documentation of these system elements. While automated documentation can provide reliable and up-to-date information, it has limitations. The aspects of systems that are easiest to document automatically are not always the most critical, and errors in automated documentation can have a greater negative impact than manual errors, as they can persist through each update. Therefore, organizations should be selective about the information included in documentation artifacts, even if it can be easily generated automatically.</p>
</div>
<div class="ltx_para" id="S4.SS4.p8">
<p class="ltx_p" id="S4.SS4.p8.1"><span class="ltx_text ltx_font_bold" id="S4.SS4.p8.1.1">Consider interactive documentation interfaces for general-purpose models in particular.</span> Documenting the characteristics of general-purpose models and their potential risks is particularly challenging due to their wide range of possible applications. When downstream practitioners cannot directly communicate with upstream model developers, interpreting the general documentation in the context of specific applications can be difficult. Several studies have shown that interfaces allowing practitioners to observe system outputs in response to given inputs can enhance their understanding of model capabilities and risks <cite class="ltx_cite ltx_citemacro_citep">(Liao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib34" title="">2023</a>; Crisan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib19" title="">2022</a>; Moore et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib46" title="">2023</a>)</cite>. Consequently, interactive interfaces can serve as a valuable complement to traditional, static documentation.</p>
</div>
<div class="ltx_para" id="S4.SS4.p9">
<p class="ltx_p" id="S4.SS4.p9.1"><span class="ltx_text ltx_font_bold" id="S4.SS4.p9.1.1">Focus initially on core information needs for documentation and evaluate potential gaps over time.</span> When designing and implementing new documentation strategies, organizations should start by identifying the essential pieces of information that will meet the needs of key stakeholders. In other words, they should start by designing a concise version of documentation. They should plan to consult with stakeholders who use this documentation to determine whether any additional information is necessary to perform their essential duties and whether any of the initial information provided in documentation artifacts is unnecessary. They should also incorporate learnings from empirical research to augment documentation as needed. Organizations can use this agile approach to manage the information in documentation artifacts, ensuring that the time spent producing and using documentation is maximally efficient and effective at serving stakeholder requirements.</p>
</div>
<div class="ltx_para" id="S4.SS4.p10">
<p class="ltx_p" id="S4.SS4.p10.1"><span class="ltx_text ltx_font_bold" id="S4.SS4.p10.1.1">Institutionalize responsible AI and risk management practices beyond documentation.</span>
Ethical deliberation is a skill that practitioners can develop over time with intentional practice <cite class="ltx_cite ltx_citemacro_citep">(Vallor et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib77" title="">2018</a>)</cite>, but organizations need to implement additional interventions beyond documentation to help cultivate this skill. Even when practitioners engage in documentation processes, they may overlook critical risks or fail to recommend appropriate mitigations without a deeper understanding of how AI can harm diverse individuals and communities <cite class="ltx_cite ltx_citemacro_citep">(Madaio et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib36" title="">2024</a>; Chang and Custis, <a class="ltx_ref" href="https://arxiv.org/html/2409.08960v1#bib.bib14" title="">2022</a>)</cite>. Therefore, organizations should strive to embed responsible AI and risk management efforts throughout their AI development practices. When responsible AI is integrated into the organization’s culture and broader practices, documentation processes that prompt practitioners to reflect on risks are more likely to be informed by a comprehensive understanding necessary for effective risk management. Conversely, relying solely on documentation to encourage critical reflection is unlikely to be sufficient and may even lead to negative outcomes. Documentation of potential ethical harms will likely be more effective when it focuses on concrete system properties, such as data containing personally identifiable information or existing societal biases, rather than on speculative concerns, which can be subjective and heavily influenced by the expertise and perspectives of the documentation producers.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5. </span>Conclusion</h3>
<div class="ltx_para" id="S4.SS5.p1">
<p class="ltx_p" id="S4.SS5.p1.1">This paper underscores the critical role of documentation in enhancing AI governance within organizations, emphasizing that effective documentation practices are essential for managing AI risks and fostering responsible system development. To support robust governance, organizations must tailor their documentation processes and artifacts to meet the specific needs and constraints of their stakeholders. Establishing clear success criteria—such as accuracy, comprehensiveness, and usability—and regularly assessing progress against these goals is crucial for maintaining the effectiveness of documentation strategies.</p>
</div>
<div class="ltx_para" id="S4.SS5.p2">
<p class="ltx_p" id="S4.SS5.p2.1">While our focus has been on documentation for internal governance, these processes and artifacts can also form the foundation for transparency efforts directed at external stakeholders. By cultivating strong internal documentation practices and continually evaluating their success, organizations can build the necessary infrastructure to create detailed, actionable records of system development and risk management. These records are necessary for communicating effectively with external audiences, such as regulators and the public.</p>
</div>
<div class="ltx_para" id="S4.SS5.p3">
<p class="ltx_p" id="S4.SS5.p3.1">However, documentation designed for internal use may not seamlessly translate to external contexts. The differences in expertise, needs, and objectives between internal and external stakeholders require careful consideration. Organizations must adapt their documentation processes and artifacts to bridge these gaps, ensuring that they are both accessible and informative to all relevant parties. By doing so, organizations can enhance their governance efforts and contribute to a more transparent and accountable AI ecosystem.</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
We would like to thank members of the AI Governance Lab team at CDT and Emily McReynolds for their valuable feedback on our research design, analysis, and synthesis. We also extend our thanks to Samir Jain and Drew Courtney for their insightful comments on our manuscript. Finally, we are grateful to the participants of the ”Improving Documentation for AI Governance” workshop, held at CDT in June 2024.

</div>
</section>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Adkins et al<span class="ltx_text" id="bib.bib2.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
David Adkins, Bilal Alsallakh, Adeel Cheema, Narine Kokhlikyan, Emily McReynolds, Pushkar Mishra, Chavez Procope, Jeremy Sawruk, Erin Wang, and Polina Zvyagina. 2022.

</span>
<span class="ltx_bibblock">Prescriptive and Descriptive Approaches to Machine-Learning Transparency. In <em class="ltx_emph ltx_font_italic" id="bib.bib2.3.1">CHI Conference on Human Factors in Computing Systems Extended Abstracts</em>. 1–9.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3491101.3519724" title="">https://doi.org/10.1145/3491101.3519724</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ahlawat et al<span class="ltx_text" id="bib.bib3.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Archana Ahlawat, Amy Winecoff, and Jonathan Mayer. 2024.

</span>
<span class="ltx_bibblock">Minimum Viable Ethics: From Institutionalizing Industry AI Governance to Product Impact.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.3.1">arXiv</em> (September 11 2024).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.arxiv.org/abs/2409.06926" title="">https://www.arxiv.org/abs/2409.06926</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ali et al<span class="ltx_text" id="bib.bib4.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Sanna J Ali, Angèle Christin, Andrew Smart, and Riitta Katila. 2023.

</span>
<span class="ltx_bibblock">Walking the Walk of AI Ethics: Organizational Challenges and the Individualization of Risk among Ethics Entrepreneurs. In <em class="ltx_emph ltx_font_italic" id="bib.bib4.3.1">2023 ACM Conference on Fairness, Accountability, and Transparency</em>. ACM, Chicago IL USA, 217–226.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3593013.3593990" title="">https://doi.org/10.1145/3593013.3593990</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arnold et al<span class="ltx_text" id="bib.bib5.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Matthew Arnold, Rachel K. E. Bellamy, Michael Hind, Stephanie Houde, Sameep Mehta, Aleksandra Mojsilovic, Ravi Nair, et al<span class="ltx_text" id="bib.bib5.3.1">.</span> 2019.

</span>
<span class="ltx_bibblock">FactSheets: Increasing Trust in AI Services through Supplier’s Declarations of Conformity.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.4.1">arXiv</em> (February 7 2019).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1808.07261" title="">http://arxiv.org/abs/1808.07261</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baracaldo et al<span class="ltx_text" id="bib.bib6.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Nathalie Baracaldo, Ali Anwar, Mark Purcell, Ambrish Rawat, Mathieu Sinn, Bashar Altakrouri, Dian Balta, et al<span class="ltx_text" id="bib.bib6.3.1">.</span> 2022.

</span>
<span class="ltx_bibblock">Towards an Accountable and Reproducible Federated Learning: A FactSheets Approach.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.4.1">arXiv</em> (February 24 2022).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2202.12443" title="">http://arxiv.org/abs/2202.12443</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Belz et al<span class="ltx_text" id="bib.bib7.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Anya Belz, Craig Thomson, Ehud Reiter, Gavin Abercrombie, Jose M. Alonso-Moral, Mohammad Arvan, Anouck Braggaar, et al<span class="ltx_text" id="bib.bib7.3.1">.</span> 2023.

</span>
<span class="ltx_bibblock">Missing Information, Unresponsive Authors, Experimental Flaws: The Impossibility of Assessing the Reproducibility of Previous Human Evaluations in NLP.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.4.1">arXiv</em> (August 7 2023).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2305.01633" title="">http://arxiv.org/abs/2305.01633</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bender and Friedman (2018)</span>
<span class="ltx_bibblock">
Emily M. Bender and Batya Friedman. 2018.

</span>
<span class="ltx_bibblock">Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Transactions of the Association for Computational Linguistics</em> 6 (December 2018), 587–604.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1162/tacl_a_00041" title="">https://doi.org/10.1162/tacl_a_00041</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Berman et al<span class="ltx_text" id="bib.bib9.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Glen Berman, Nitesh Goyal, and Michael Madaio. 2024.

</span>
<span class="ltx_bibblock">A Scoping Study of Evaluation Practices for Responsible AI Tools: Steps Towards Effectiveness Evaluations. In <em class="ltx_emph ltx_font_italic" id="bib.bib9.3.1">Proceedings of the CHI Conference on Human Factors in Computing Systems</em>. ACM, Honolulu HI USA, 1–24.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3613904.3642398" title="">https://doi.org/10.1145/3613904.3642398</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bhat et al<span class="ltx_text" id="bib.bib10.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Avinash Bhat, Austin Coursey, Grace Hu, Sixian Li, Nadia Nahar, Shurui Zhou, Christian Kästner, and Jin L. C. Guo. 2023.

</span>
<span class="ltx_bibblock">Aspirations and Practice of Model Documentation: Moving the Needle with Nudging and Traceability. In <em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems</em>. 1–17.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3544548.3581518" title="">https://doi.org/10.1145/3544548.3581518</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blasch et al<span class="ltx_text" id="bib.bib11.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Erik Blasch, James Sung, and Tao Nguyen. 2021.

</span>
<span class="ltx_bibblock">Multisource AI scorecard table for system evaluation. In <em class="ltx_emph ltx_font_italic" id="bib.bib11.3.1">AAAI FSS20: Artificial Intelligence in Government and Public Sector</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Boyd (2021)</span>
<span class="ltx_bibblock">
Karen L. Boyd. 2021.

</span>
<span class="ltx_bibblock">Datasheets for Datasets Help ML Engineers Notice and Understand Ethical Issues in Training Data.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the ACM on Human-Computer Interaction</em> 5, CSCW2 (October 13 2021), 1–27.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3479582" title="">https://doi.org/10.1145/3479582</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brajovic et al<span class="ltx_text" id="bib.bib13.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Danilo Brajovic, Niclas Renner, Vincent Philipp Goebels, Philipp Wagner, Benjamin Fresz, Martin Biller, Mara Klaeb, et al<span class="ltx_text" id="bib.bib13.3.1">.</span> 2023.

</span>
<span class="ltx_bibblock">Model Reporting for Certifiable AI: A Proposal from Merging EU Regulation into AI Development.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.4.1">arXiv</em> (July 21 2023).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2307.11525" title="">http://arxiv.org/abs/2307.11525</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chang and Custis (2022)</span>
<span class="ltx_bibblock">
Jiyoo Chang and Christine Custis. 2022.

</span>
<span class="ltx_bibblock">Understanding Implementation Challenges in Machine Learning Documentation. In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Equity and Access in Algorithms, Mechanisms, and Optimization</em>. ACM, Arlington VA USA, 1–8.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3551624.3555301" title="">https://doi.org/10.1145/3551624.3555301</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Charmaz (2014)</span>
<span class="ltx_bibblock">
Kathy Charmaz. 2014.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Constructing grounded theory, 2nd ed.</em>
</span>
<span class="ltx_bibblock">Sage.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chmielinski et al<span class="ltx_text" id="bib.bib16.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Kasia Chmielinski, Sarah Newman, Chris N Kranzinger, Michael Hind, Jennifer Wortman Vaughan, Margaret Mitchell, Julia Stoyanovich, et al<span class="ltx_text" id="bib.bib16.3.1">.</span> 2024.

</span>
<span class="ltx_bibblock">The CLeAR Documentation Framework for AI Transparency Recommendations for Practitioners and Context for Policymakers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.4.1">The Shorenstein Center on Media, Politics and Public Policy</em> (May 2024).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://shorensteincenter.org/clear-documentation-framework-ai-transparency-recommendations-practitioners-context-policymakers/" title="">https://shorensteincenter.org/clear-documentation-framework-ai-transparency-recommendations-practitioners-context-policymakers/</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chmielinski et al<span class="ltx_text" id="bib.bib17.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Kasia S Chmielinski, Sarah Newman, Matt Taylor, Josh Joseph, Kemi Thomas, Jessica Yurkofsky, and Yue Chelsea Qiu. 2020.

</span>
<span class="ltx_bibblock">The Dataset Nutrition Label (2nd Gen): Leveraging Context to Mitigate Harms in Artificial Intelligence.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clavell (2024)</span>
<span class="ltx_bibblock">
Gemma Galdon Clavell. 2024.

</span>
<span class="ltx_bibblock">Checklist for AI Auditing.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.edpb.europa.eu/system/files/2024-06/ai-auditing_checklist-for-ai-auditing-scores_edpb-spe-programme_en.pdf" title="">https://www.edpb.europa.eu/system/files/2024-06/ai-auditing_checklist-for-ai-auditing-scores_edpb-spe-programme_en.pdf</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Crisan et al<span class="ltx_text" id="bib.bib19.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Anamaria Crisan, Margaret Drouhard, Jesse Vig, and Nazneen Rajani. 2022.

</span>
<span class="ltx_bibblock">Interactive Model Cards: A Human-Centered Approach to Model Documentation. In <em class="ltx_emph ltx_font_italic" id="bib.bib19.3.1">2022 ACM Conference on Fairness, Accountability, and Transparency</em>. 427–439.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3531146.3533108" title="">https://doi.org/10.1145/3531146.3533108</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Díaz et al<span class="ltx_text" id="bib.bib20.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Mark Díaz, Sunipa Dev, Emily Reif, Emily Denton, and Vinodkumar Prabhakaran. 2023.

</span>
<span class="ltx_bibblock">SoUnD Framework: Analyzing (So)Cial Representation in (Un)Structured (D)Ata.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.3.1">arXiv</em> (December 1 2023).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2311.17259" title="">http://arxiv.org/abs/2311.17259</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Friedman et al<span class="ltx_text" id="bib.bib21.2.2.1">.</span> (2006)</span>
<span class="ltx_bibblock">
Batya Friedman, Peter H. Jr. Kahn, and Alan Borning. 2006.

</span>
<span class="ltx_bibblock">Value Sensitive Design and Information Systems.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib21.3.1">Human-Computer Interaction and Management Information Systems: Foundations Advances in Management Information Systems</em>. M.E. Sharpe, Armonk, NY, 348–372.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://ndl.ethernet.edu.et/bitstream/123456789/18272/1/87..Neelke%20Doorn.pdf#page=67" title="">http://ndl.ethernet.edu.et/bitstream/123456789/18272/1/87..Neelke%20Doorn.pdf#page=67</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gebru et al<span class="ltx_text" id="bib.bib22.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal Daumé III, and Kate Crawford. 2021.

</span>
<span class="ltx_bibblock">Datasheets for Datasets.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.3.1">arXiv</em> (December 1 2021).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1803.09010" title="">http://arxiv.org/abs/1803.09010</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geiger et al<span class="ltx_text" id="bib.bib23.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
R Stuart Geiger, Kevin Yu, Yanlai Yang, Mindy Dai, Jie Qiu, Rebekah Tang, and Jenny Huang. 2020.

</span>
<span class="ltx_bibblock">Garbage in, garbage out? Do machine learning application papers in social computing report where human-labeled training data comes from?. In <em class="ltx_emph ltx_font_italic" id="bib.bib23.3.1">Proceedings of the 2020 conference on fairness, accountability, and transparency</em>. 325–336.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gilbert et al<span class="ltx_text" id="bib.bib24.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Thomas Krendl Gilbert, Nathan Lambert, Sarah Dean, Tom Zick, and Aaron Snoswell. 2023.

</span>
<span class="ltx_bibblock">Reward Reports for Reinforcement Learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.3.1">arXiv</em> (March 19 2023).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2204.10817" title="">http://arxiv.org/abs/2204.10817</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Green et al<span class="ltx_text" id="bib.bib25.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Nekesha Green, Chavez Procope, Adeel Cheema, and Adekunle Adediji. 2021.

</span>
<span class="ltx_bibblock">System Cards, a New Resource for Understanding How AI Systems Work.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ai.facebook.com/blog/system-cards-a-new-resource-for-understanding-how-ai-systems-work/" title="">https://ai.facebook.com/blog/system-cards-a-new-resource-for-understanding-how-ai-systems-work/</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hahn et al<span class="ltx_text" id="bib.bib26.2.2.1">.</span> (1992)</span>
<span class="ltx_bibblock">
Minhi Hahn, Robert Lawson, and Young Gyu Lee. 1992.

</span>
<span class="ltx_bibblock">The Effects of Time Pressure and Information Load on Decision Quality.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.3.1">Psychology &amp; Marketing</em> 9, 5 (1992), 365–378.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Heger et al<span class="ltx_text" id="bib.bib27.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Amy K. Heger, Liz B. Marquis, Mihaela Vorvoreanu, Hanna Wallach, and Jennifer Wortman Vaughan. 2022.

</span>
<span class="ltx_bibblock">Understanding Machine Learning Practitioners’ Data Documentation Perceptions, Needs, Challenges, and Desiderata.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.3.1">arXiv</em> (August 24 2022).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2206.02923" title="">http://arxiv.org/abs/2206.02923</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hind et al<span class="ltx_text" id="bib.bib28.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Michael Hind, Stephanie Houde, Jacquelyn Martino, Aleksandra Mojsilovic, David Piorkowski, John Richards, and Kush R. Varshney. 2019.

</span>
<span class="ltx_bibblock">Experiences with Improving the Transparency of AI Models and Services.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.3.1">arXiv</em> (November 11 2019).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1911.08293" title="">http://arxiv.org/abs/1911.08293</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Holland et al<span class="ltx_text" id="bib.bib29.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Sarah Holland, Ahmed Hosny, Sarah Newman, Joshua Joseph, and Kasia Chmielinski. 2018.

</span>
<span class="ltx_bibblock">The Dataset Nutrition Label: A Framework To Drive Higher Data Quality Standards.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hupont and Gomez (2022)</span>
<span class="ltx_bibblock">
Isabelle Hupont and Emilia Gomez. 2022.

</span>
<span class="ltx_bibblock">Documenting Use Cases in the Affective Computing Domain Using Unified Modeling Language.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">arXiv</em> (September 19 2022).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2209.09666" title="">http://arxiv.org/abs/2209.09666</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hutchinson et al<span class="ltx_text" id="bib.bib31.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Ben Hutchinson, Negar Rostamzadeh, Christina Greer, Katherine Heller, and Vinodkumar Prabhakaran. 2022.

</span>
<span class="ltx_bibblock">Evaluation Gaps in Machine Learning Practice. In <em class="ltx_emph ltx_font_italic" id="bib.bib31.3.1">2022 ACM Conference on Fairness, Accountability, and Transparency</em>. ACM, Seoul Republic of Korea, 1859–1876.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3531146.3533233" title="">https://doi.org/10.1145/3531146.3533233</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jones (2023)</span>
<span class="ltx_bibblock">
Elliot Jones. 2023.

</span>
<span class="ltx_bibblock">Foundation Models: An Explainer.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.adalovelaceinstitute.org/resource/foundation-models-explainer/" title="">https://www.adalovelaceinstitute.org/resource/foundation-models-explainer/</a>
</span>
<span class="ltx_bibblock">Accessed: 2024-08-27.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liang et al<span class="ltx_text" id="bib.bib33.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Weixin Liang, Nazneen Rajani, Xinyu Yang, Ezinwanne Ozoani, Eric Wu, Yiqun Chen, Daniel Scott Smith, and James Zou. 2024.

</span>
<span class="ltx_bibblock">What’s Documented in AI? Systematic Analysis of 32K AI Model Cards.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.3.1">arXiv</em> (February 7 2024).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2402.05160" title="">http://arxiv.org/abs/2402.05160</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liao et al<span class="ltx_text" id="bib.bib34.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Q. Vera Liao, Hariharan Subramonyam, Jennifer Wang, and Jennifer Wortman Vaughan. 2023.

</span>
<span class="ltx_bibblock">Designerly Understanding: Information Needs for Model Transparency to Support Design Ideation for AI-Powered User Experience.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.3.1">arXiv</em> (February 20 2023).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2302.10395" title="">http://arxiv.org/abs/2302.10395</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liao and Vaughan (2023)</span>
<span class="ltx_bibblock">
Q Vera Liao and Jennifer Wortman Vaughan. 2023.

</span>
<span class="ltx_bibblock">Ai transparency in the age of llms: A human-centered research roadmap.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">arXiv preprint arXiv:2306.01941</em> (2023), 5368–5393.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Madaio et al<span class="ltx_text" id="bib.bib36.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Michael Madaio, Shivani Kapania, Rida Qadri, Ding Wang, Andrew Zaldivar, Remi Denton, and Lauren Wilcox. 2024.

</span>
<span class="ltx_bibblock">Learning about Responsible AI On-The-Job: Learning Pathways, Orientations, and Aspirations. In <em class="ltx_emph ltx_font_italic" id="bib.bib36.3.1">The 2024 ACM Conference on Fairness, Accountability, and Transparency</em>. ACM, Rio de Janeiro Brazil, 1544–1558.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3630106.3658988" title="">https://doi.org/10.1145/3630106.3658988</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Marone and Van Durme (2023)</span>
<span class="ltx_bibblock">
Marc Marone and Benjamin Van Durme. 2023.

</span>
<span class="ltx_bibblock">Data Portraits: Recording Foundation Model Training Data.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">arXiv</em> (December 14 2023).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2303.03919" title="">http://arxiv.org/abs/2303.03919</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McLennan et al<span class="ltx_text" id="bib.bib38.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Stuart McLennan, Amelia Fiske, Daniel Tigard, Ruth Müller, Sami Haddadin, and Alena Buyx. 2022.

</span>
<span class="ltx_bibblock">Embedded Ethics: A Proposal for Integrating Ethics into the Development of Medical AI.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.3.1">BMC Medical Ethics</em> 23, 1 (December 2022), 6.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1186/s12910-022-00746-3" title="">https://doi.org/10.1186/s12910-022-00746-3</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMillan-Major et al<span class="ltx_text" id="bib.bib39.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Angelina McMillan-Major, Emily M. Bender, and Batya Friedman. 2024.

</span>
<span class="ltx_bibblock">Data Statements: From Technical Concept to Community Practice.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.3.1">ACM Journal on Responsible Computing</em> 1, 1 (March 31 2024), 1–17.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3594737" title="">https://doi.org/10.1145/3594737</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMillan-Major et al<span class="ltx_text" id="bib.bib40.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Angelina McMillan-Major, Salomey Osei, Juan Diego Rodriguez, Pawan Sasanka Ammanamanchi, Sebastian Gehrmann, and Yacine Jernite. 2021.

</span>
<span class="ltx_bibblock">Reusable Templates and Guides For Documenting Datasets and Models for Natural Language Processing and Generation: A Case Study of the HuggingFace and GEM Data and Model Cards. In <em class="ltx_emph ltx_font_italic" id="bib.bib40.3.1">Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021)</em>. 121–135.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2021.gem-1.11" title="">https://doi.org/10.18653/v1/2021.gem-1.11</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Miceli et al<span class="ltx_text" id="bib.bib41.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Milagros Miceli, Tianling Yang, Laurens Naudts, Martin Schuessler, Diana Serbanescu, and Alex Hanna. 2021.

</span>
<span class="ltx_bibblock">Documenting Computer Vision Datasets: An Invitation to Reflexive Data Practices. In <em class="ltx_emph ltx_font_italic" id="bib.bib41.3.1">Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</em>. ACM, Virtual Event Canada, 161–172.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3442188.3445880" title="">https://doi.org/10.1145/3442188.3445880</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Micheli et al<span class="ltx_text" id="bib.bib42.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Marina Micheli, Isabelle Hupont, Blagoj Delipetrev, and Josep Soler-Garrido. 2023.

</span>
<span class="ltx_bibblock">The Landscape of Data and AI Documentation Approaches in the European Policy Context.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.3.1">Ethics and Information Technology</em> 25, 4 (October 28 2023), 56.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/s10676-023-09725-7" title="">https://doi.org/10.1007/s10676-023-09725-7</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mitchell et al<span class="ltx_text" id="bib.bib43.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Margaret Mitchell, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, Ben Hutchinson, Elena Spitzer, et al<span class="ltx_text" id="bib.bib43.3.1">.</span> 2019.

</span>
<span class="ltx_bibblock">Model Cards for Model Reporting. In <em class="ltx_emph ltx_font_italic" id="bib.bib43.4.1">Proceedings of the Conference on Fairness, Accountability, and Transparency</em>. 220–229.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3287560.3287596" title="">https://doi.org/10.1145/3287560.3287596</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mohammad (2022)</span>
<span class="ltx_bibblock">
Saif M. Mohammad. 2022.

</span>
<span class="ltx_bibblock">Ethics Sheets for AI Tasks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">arXiv</em> (March 19 2022).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2107.01183" title="">http://arxiv.org/abs/2107.01183</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mökander et al<span class="ltx_text" id="bib.bib45.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Jakob Mökander, Jonas Schuett, Hannah Rose Kirk, and Luciano Floridi. 2023.

</span>
<span class="ltx_bibblock">Auditing Large Language Models: A Three-Layered Approach.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.3.1">AI and Ethics</em> (May 30 2023).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/s43681-023-00289-2" title="">https://doi.org/10.1007/s43681-023-00289-2</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Moore et al<span class="ltx_text" id="bib.bib46.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Steven Moore, Q. Vera Liao, and Hariharan Subramonyam. 2023.

</span>
<span class="ltx_bibblock">fAIlureNotes: Supporting Designers in Understanding the Limits of AI Models for Computer Vision Tasks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.3.1">arXiv</em> (February 22 2023).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2302.11703" title="">https://doi.org/10.48550/arXiv.2302.11703</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Narayanan and Kapoor (2024)</span>
<span class="ltx_bibblock">
Arvind Narayanan and Sayash Kapoor. 2024.

</span>
<span class="ltx_bibblock">AI Safety Is Not a Model Property.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.aisnakeoil.com/p/ai-safety-is-not-a-model-property" title="">https://www.aisnakeoil.com/p/ai-safety-is-not-a-model-property</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nicholas (2024)</span>
<span class="ltx_bibblock">
Gabriel Nicholas. 2024.

</span>
<span class="ltx_bibblock">Grounding AI Policy: Towards Researcher Access to AI Usage Data.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://cdt.org/wp-content/uploads/2024/08/2024-08-12-CDT-Research-Grounding-AI-Policy-report-final.pdf" title="">https://cdt.org/wp-content/uploads/2024/08/2024-08-12-CDT-Research-Grounding-AI-Policy-report-final.pdf</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nunes et al<span class="ltx_text" id="bib.bib49.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
José Luiz Nunes, Gabriel D. J. Barbosa, Clarisse Sieckenius De Souza, Helio Lopes, and Simone D. J. Barbosa. 2022.

</span>
<span class="ltx_bibblock">Using Model Cards for Ethical Reflection: A Qualitative Exploration. In <em class="ltx_emph ltx_font_italic" id="bib.bib49.3.1">Proceedings of the 21st Brazilian Symposium on Human Factors in Computing Systems</em>. ACM, Diamantina Brazil, 1–11.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3554364.3559117" title="">https://doi.org/10.1145/3554364.3559117</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI. 2023.

</span>
<span class="ltx_bibblock">GPT-4V(Ision) System Card.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/index/gpt-4v-system-card/" title="">https://openai.com/index/gpt-4v-system-card/</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Palinkas et al<span class="ltx_text" id="bib.bib51.2.2.1">.</span> (2015)</span>
<span class="ltx_bibblock">
Lawrence A Palinkas, Sarah M Horwitz, Carla A Green, Jennifer P Wisdom, Naihua Duan, and Kimberly Hoagwood. 2015.

</span>
<span class="ltx_bibblock">Purposeful sampling for qualitative data collection and analysis in mixed method implementation research.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib51.3.1">Administration and policy in mental health and mental health services research</em> 42 (2015), 533–544.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papakyriakopoulos et al<span class="ltx_text" id="bib.bib52.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Orestis Papakyriakopoulos, Anna Seo Gyeong Choi, William Thong, Dora Zhao, Jerone Andrews, Rebecca Bourke, Alice Xiang, and Allison Koenecke. 2023.

</span>
<span class="ltx_bibblock">Augmented Datasheets for Speech Datasets and Ethical Decision-Making. In <em class="ltx_emph ltx_font_italic" id="bib.bib52.3.1">2023 ACM Conference on Fairness, Accountability, and Transparency</em>. ACM, Chicago IL USA, 881–904.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3593013.3594049" title="">https://doi.org/10.1145/3593013.3594049</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pepe et al<span class="ltx_text" id="bib.bib53.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Federica Pepe, Vittoria Nardone, Antonio Mastropaolo, Gerardo Canfora, and Gabriele Bavota. 2024.

</span>
<span class="ltx_bibblock">How Do Hugging Face Models Document Datasets, Bias, and Licenses? An Empirical Study.

</span>
<span class="ltx_bibblock">(2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Phillips-Wren and Adya (2020)</span>
<span class="ltx_bibblock">
Gloria Phillips-Wren and Monica Adya. 2020.

</span>
<span class="ltx_bibblock">Decision Making under Stress: The Role of Information Overload, Time Pressure, Complexity, and Uncertainty.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">Journal of Decision Systems</em> 29, sup1 (August 18 2020), 213–225.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1080/12460125.2020.1768680" title="">https://doi.org/10.1080/12460125.2020.1768680</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Procope et al<span class="ltx_text" id="bib.bib55.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Chavez Procope, Adeel Cheema, David Adkins, Bilal Alsallakh, Emily McReynolds, Grace Pehl, Erin Wang, and Polina Zvyagina. 2022.

</span>
<span class="ltx_bibblock">System-Level Transparency of Machine Learning.

</span>
<span class="ltx_bibblock">(February 22 2022).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ai.meta.com/research/publications/system-level-transparency-of-machine-learning/" title="">https://ai.meta.com/research/publications/system-level-transparency-of-machine-learning/</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pushkarna et al<span class="ltx_text" id="bib.bib56.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Mahima Pushkarna, Andrew Zaldivar, and Oddur Kjartansson. 2022.

</span>
<span class="ltx_bibblock">Data Cards: Purposeful and Transparent Dataset Documentation for Responsible AI.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib56.3.1">arXiv</em> (April 3 2022).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2204.01075" title="">http://arxiv.org/abs/2204.01075</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raji and Yang (2020)</span>
<span class="ltx_bibblock">
Inioluwa Deborah Raji and Jingying Yang. 2020.

</span>
<span class="ltx_bibblock">ABOUT ML: Annotation and Benchmarking on Understanding and Transparency of Machine Learning Lifecycles.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">arXiv</em> (January 7 2020).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1912.06166" title="">http://arxiv.org/abs/1912.06166</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reid and Williams (2023)</span>
<span class="ltx_bibblock">
Kathy Reid and Elizabeth T. Williams. 2023.

</span>
<span class="ltx_bibblock">Right the Docs: Characterising Voice Dataset Documentation Practices Used in Machine Learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">arXiv</em> (March 19 2023).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2303.10721" title="">http://arxiv.org/abs/2303.10721</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Richards et al<span class="ltx_text" id="bib.bib59.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
John Richards, David Piorkowski, Michael Hind, Stephanie Houde, and Aleksandra Mojsilović. 2020.

</span>
<span class="ltx_bibblock">A Methodology for Creating AI FactSheets.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib59.3.1">arXiv</em> (June 27 2020).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.2006.13796" title="">https://doi.org/10.48550/arXiv.2006.13796</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roman et al<span class="ltx_text" id="bib.bib60.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Anthony Cintron Roman, Jennifer Wortman Vaughan, Valerie See, Steph Ballard, Nicolas Schifano, Jehu Torres, Caleb Robinson, and Juan M. Lavista Ferres. 2023.

</span>
<span class="ltx_bibblock">Open Datasheets: Machine-Readable Documentation for Open Datasets and Responsible AI Assessments.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib60.3.1">arXiv</em> (December 11 2023).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2312.06153" title="">http://arxiv.org/abs/2312.06153</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rostamzadeh et al<span class="ltx_text" id="bib.bib61.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Negar Rostamzadeh, Diana Mincu, Subhrajit Roy, Andrew Smart, Lauren Wilcox, Mahima Pushkarna, Jessica Schrouff, Razvan Amironesei, Nyalleng Moorosi, and Katherine Heller. 2022.

</span>
<span class="ltx_bibblock">Healthsheet: Development of a Transparency Artifact for Health Datasets.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib61.3.1">arXiv</em> (February 25 2022).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2202.13028" title="">http://arxiv.org/abs/2202.13028</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen et al<span class="ltx_text" id="bib.bib62.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Hong Shen, Leijie Wang, Wesley H. Deng, Ciell Brusse, Ronald Velgersdijk, and Haiyi Zhu. 2022.

</span>
<span class="ltx_bibblock">The Model Card Authoring Toolkit: Toward Community-Centered, Deliberation-Driven AI Design. In <em class="ltx_emph ltx_font_italic" id="bib.bib62.3.1">2022 ACM Conference on Fairness, Accountability, and Transparency</em>. ACM, Seoul Republic of Korea, 440–451.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3531146.3533110" title="">https://doi.org/10.1145/3531146.3533110</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shilton (2013)</span>
<span class="ltx_bibblock">
Katie Shilton. 2013.

</span>
<span class="ltx_bibblock">Values Levers: Building Ethics into Design.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">Science, Technology, &amp; Human Values</em> 38, 3 (May 2013), 374–397.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1177/0162243912436985" title="">https://doi.org/10.1177/0162243912436985</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shimorina and Belz (2021)</span>
<span class="ltx_bibblock">
Anastasia Shimorina and Anya Belz. 2021.

</span>
<span class="ltx_bibblock">The Human Evaluation Datasheet 1.0: A Template for Recording Details of Human Evaluation Experiments in NLP.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib64.1.1">arXiv</em> (March 17 2021).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2103.09710" title="">http://arxiv.org/abs/2103.09710</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Smart et al<span class="ltx_text" id="bib.bib65.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Andrew Smart, Shazeda Ahmed, Jacob Metcalf, Atoosa Kasirzadeh, Luca Belli, Shalaleh Rismani, Roel Dobbe, et al<span class="ltx_text" id="bib.bib65.3.1">.</span> 2024.

</span>
<span class="ltx_bibblock">What Is Sociotechnical AI Safety? What Do We Want It To Be? A FAccT Community Workshop.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Soh (2021)</span>
<span class="ltx_bibblock">
Jerrold Soh. 2021.

</span>
<span class="ltx_bibblock">Building Legal Datasets.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib66.1.1">arXiv</em> (November 3 2021).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2111.02034" title="">http://arxiv.org/abs/2111.02034</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sokol and Flach (2020)</span>
<span class="ltx_bibblock">
Kacper Sokol and Peter Flach. 2020.

</span>
<span class="ltx_bibblock">Explainability Fact Sheets: A Framework for Systematic Assessment of Explainable Approaches. In <em class="ltx_emph ltx_font_italic" id="bib.bib67.1.1">Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency</em>. ACM, Barcelona Spain, 56–67.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3351095.3372870" title="">https://doi.org/10.1145/3351095.3372870</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Srinivasan et al<span class="ltx_text" id="bib.bib68.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Ramya Srinivasan, Emily Denton, Jordan Famularo, Negar Rostamzadeh, Fernando Diaz, and Beth Coleman. 2021.

</span>
<span class="ltx_bibblock">Artsheets for Art Datasets.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stoyanovich and Howe (2019)</span>
<span class="ltx_bibblock">
Julia Stoyanovich and Bill Howe. 2019.

</span>
<span class="ltx_bibblock">Nutritional Labels for Data and Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib69.1.1">Bulletin of the IEEE Computer Society Technical Committee on Data Engineering</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Strauss and Corbin (1990)</span>
<span class="ltx_bibblock">
Anselm Strauss and Juliet Corbin. 1990.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib70.1.1">Basics of qualitative research</em>.

</span>
<span class="ltx_bibblock">Sage Publications.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Subramaniam et al<span class="ltx_text" id="bib.bib71.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Pranav Subramaniam, Yintong Ma, Chi Li, Ipsita Mohanty, and Raul Castro Fernandez. 2023.

</span>
<span class="ltx_bibblock">Comprehensive and Comprehensible Data Catalogs: The What, Who, Where, When, Why, and How of Metadata Management.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib71.3.1">arXiv</em> (February 1 2023).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2103.07532" title="">http://arxiv.org/abs/2103.07532</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al<span class="ltx_text" id="bib.bib72.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Chenkai Sun, Abolfazl Asudeh, H. V. Jagadish, Bill Howe, and Julia Stoyanovich. 2019.

</span>
<span class="ltx_bibblock">MithraLabel: Flexible Dataset Nutritional Labels for Responsible Data Science. In <em class="ltx_emph ltx_font_italic" id="bib.bib72.3.1">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</em>. ACM, Beijing China, 2893–2896.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3357384.3357853" title="">https://doi.org/10.1145/3357384.3357853</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tagliabue et al<span class="ltx_text" id="bib.bib73.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Jacopo Tagliabue, Ville Tuulos, Ciro Greco, and Valay Dave. 2021.

</span>
<span class="ltx_bibblock">DAG Card Is the New Model Card.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib73.3.1">arXiv</em> (November 20 2021).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2110.13601" title="">http://arxiv.org/abs/2110.13601</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tavory and Timmermans (2014)</span>
<span class="ltx_bibblock">
Iddo Tavory and Stefan Timmermans. 2014.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib74.1.1">Abductive analysis: Theorizing Qualitative Research</em>.

</span>
<span class="ltx_bibblock">University of Chicago Press.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Timmermans and Tavory (2012)</span>
<span class="ltx_bibblock">
Stefan Timmermans and Iddo Tavory. 2012.

</span>
<span class="ltx_bibblock">Theory construction in qualitative research: From grounded theory to abductive analysis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib75.1.1">Sociological Theory</em> 30, 3 (2012), 167–186.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al<span class="ltx_text" id="bib.bib76.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, et al<span class="ltx_text" id="bib.bib76.3.1">.</span> 2023.

</span>
<span class="ltx_bibblock">Llama 2: Open Foundation and Fine-Tuned Chat Models.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/" title="">https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vallor et al<span class="ltx_text" id="bib.bib77.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Shannon Vallor, Irina Raicu, and Brian Green. 2018.

</span>
<span class="ltx_bibblock">Overview of Ethics in Tech Practice.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.scu.edu/ethics-in-technology-practice/overview-of-ethics-in-tech-practice/" title="">https://www.scu.edu/ethics-in-technology-practice/overview-of-ethics-in-tech-practice/</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al<span class="ltx_text" id="bib.bib78.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017.

</span>
<span class="ltx_bibblock">Attention Is All You Need.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/arXiv.1706.03762" title="">https://doi.org/10.48550/arXiv.1706.03762</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Winecoff and Watkins (2022)</span>
<span class="ltx_bibblock">
Amy A. Winecoff and Elizabeth Anne Watkins. 2022.

</span>
<span class="ltx_bibblock">Artificial Concepts of Artificial Intelligence: Institutional Compliance and Resistance in AI Startups. In <em class="ltx_emph ltx_font_italic" id="bib.bib79.1.1">Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society</em>. ACM, Oxford United Kingdom, 788–799.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3514094.3534138" title="">https://doi.org/10.1145/3514094.3534138</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span class="ltx_text" id="bib.bib80.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Ke Yang, Julia Stoyanovich, Abolfazl Asudeh, Bill Howe, H. V. Jagadish, and Gerome Miklau. 2018.

</span>
<span class="ltx_bibblock">A Nutritional Label for Rankings. In <em class="ltx_emph ltx_font_italic" id="bib.bib80.3.1">Proceedings of the 2018 International Conference on Management of Data</em>. ACM, Houston TX USA, 1773–1776.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3183713.3193568" title="">https://doi.org/10.1145/3183713.3193568</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al<span class="ltx_text" id="bib.bib81.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Xinyi Zheng, Ryan A. Rossi, Nesreen Ahmed, and Dominik Moritz. 2022.

</span>
<span class="ltx_bibblock">Network Report: A Structured Description for Network Datasets.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib81.3.1">arXiv</em> (June 7 2022).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2206.03635" title="">http://arxiv.org/abs/2206.03635</a>
</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Fri Sep 13 16:21:01 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
