<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval</title>
<!--Generated on Wed Aug 21 08:33:04 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Deep Learning,  Multi-modal Learning,  Video Retrieval,  Generative Model" lang="en" name="keywords"/>
<base href="/html/2408.11432v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S1" title="In T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S2" title="In T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S3" title="In T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S3.SS1" title="In 3. Methodology ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Vi-SemTree for Video Identifying</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S3.SS2" title="In 3. Methodology ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Multi-view Textual Query Expansion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S3.SS3" title="In 3. Methodology ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Generative Retrieval Model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S3.SS4" title="In 3. Methodology ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Model Training and Inference</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S4" title="In T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S4.SS1" title="In 4. Experiments ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Efficiency of T2VIndexer</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S4.SS2" title="In 4. Experiments ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Evaluating on Large-Scale Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S4.SS3" title="In 4. Experiments ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>State-of-the-Art Comparison</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S4.SS4" title="In 4. Experiments ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Ablation Study on Model Structure</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S4.SS5" title="In 4. Experiments ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.5 </span>Ablation Study on Different MLLMs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S4.SS6" title="In 4. Experiments ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.6 </span>Ablation Study on Video Feature Extractor</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S4.SS7" title="In 4. Experiments ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.7 </span>Generative Result Visualization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S4.SS8" title="In 4. Experiments ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.8 </span>Parameter Analysis</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S5" title="In T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Limitation and Future Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S6" title="In T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\useunder</span>
<p class="ltx_p" id="p1.2"><span class="ltx_text ltx_ulem_uline" id="p1.2.1"></span><span class="ltx_ERROR undefined" id="p1.2.2">\ul</span></p>
</div>
<h1 class="ltx_title ltx_title_document">T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yili Li
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">Institute of Information Engineering, Chinese Academy of Sciences</span><span class="ltx_text ltx_affiliation_institution" id="id2.2.id2">School of Cyber Security, University of Chinese Academy of Sciences</span><span class="ltx_text ltx_affiliation_city" id="id3.3.id3">Beijing</span><span class="ltx_text ltx_affiliation_country" id="id4.4.id4">China</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:liyili@iie.ac.cn">liyili@iie.ac.cn</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0009-0006-4037-819X" title="ORCID identifier">0009-0006-4037-819X</a></span>
</span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jing Yu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id5.1.id1">Institute of Information Engineering, Chinese Academy of Sciences</span><span class="ltx_text ltx_affiliation_institution" id="id6.2.id2">School of Cyber Security, University of Chinese Academy of Sciences</span><span class="ltx_text ltx_affiliation_city" id="id7.3.id3">Beijing</span><span class="ltx_text ltx_affiliation_country" id="id8.4.id4">China</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:yujing02@iie.ac.cn">yujing02@iie.ac.cn</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-3966-511X" title="ORCID identifier">0000-0002-3966-511X</a></span>
</span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Keke Gai
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id9.1.id1">School of Cyberspace Science and Technology, Beijing Institute of Technology</span><span class="ltx_text ltx_affiliation_city" id="id10.2.id2">Beijing</span><span class="ltx_text ltx_affiliation_country" id="id11.3.id3">China</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:gaikeke@bit.edu.cn">gaikeke@bit.edu.cn</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0001-6784-0221" title="ORCID identifier">0000-0001-6784-0221</a></span>
</span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Bang Liu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id12.1.id1">Université de Montréal &amp; Mila</span><span class="ltx_text ltx_affiliation_city" id="id13.2.id2">Montréal</span><span class="ltx_text ltx_affiliation_country" id="id14.3.id3">Canada</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:bang.liu@umontreal.ca">bang.liu@umontreal.ca</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-9483-8984" title="ORCID identifier">0000-0002-9483-8984</a></span>
</span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Gang Xiong
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id15.1.id1">Institute of Information Engineering, Chinese Academy of Sciences</span><span class="ltx_text ltx_affiliation_city" id="id16.2.id2">Beijing</span><span class="ltx_text ltx_affiliation_country" id="id17.3.id3">China</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:xionggang@iie.ac.cn">xionggang@iie.ac.cn</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0002-3190-6521" title="ORCID identifier">0000-0002-3190-6521</a></span>
</span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Qi Wu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id18.1.id1">Australia Institute of Machine Learning, University of Adelaide</span><span class="ltx_text ltx_affiliation_city" id="id19.2.id2">Adelaide</span><span class="ltx_text ltx_affiliation_country" id="id20.3.id3">Australia</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:qi.wu01@adelaide.edu.au">qi.wu01@adelaide.edu.au</a>
</span>
<span class="ltx_contact ltx_role_orcid"><a class="ltx_ref" href="https://orcid.org/0000-0003-3631-256X" title="ORCID identifier">0000-0003-3631-256X</a></span>
</span></span>
</div>
<div class="ltx_dates">(2024)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id21.id1">Current text-video retrieval methods mainly rely on cross-modal matching between queries and videos to calculate their similarity scores, which are then sorted to obtain retrieval results. This method considers the matching between each candidate video and the query, but it incurs a significant time cost and will increase notably with the increase of candidates. Generative models are common in natural language processing and computer vision, and have been successfully applied in document retrieval, but their application in multimodal retrieval remains unexplored. To enhance retrieval efficiency, in this paper, we introduce a model-based video indexer named T2VIndexer, which is a sequence-to-sequence generative model directly generating video identifiers and retrieving candidate videos with constant time complexity. T2VIndexer aims to reduce retrieval time while maintaining high accuracy. To achieve this goal, we propose video identifier encoding and query-identifier augmentation approaches to represent videos as short sequences while preserving their semantic information. Our method consistently enhances the retrieval efficiency of current state-of-the-art models on four standard datasets. It enables baselines with only 30%-50% of the original retrieval time to achieve better retrieval performance on MSR-VTT (+1.0%), MSVD (+1.8%), ActivityNet (+1.5%), and DiDeMo (+0.2%). The code is available at <a class="ltx_ref ltx_href" href="https://github.com/Lilidamowang/T2VIndexer-generativeSearch" title="">https://github.com/Lilidamowang/T2VIndexer-generativeSearch</a>.</p>
</div>
<div class="ltx_keywords">Deep Learning, Multi-modal Learning, Video Retrieval, Generative Model
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>rightsretained</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2024</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id3"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>10.1145/3664647.3680673</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id4"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>Proceedings of the 32nd ACM International Conference on Multimedia; October 28–November 1, 2024; Melbourne, VIC, Australia.</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_booktitle" id="id5"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">booktitle: </span>Proceedings of the 32nd ACM International Conference on Multimedia (MM ’24), October 28–November 1, 2024, Melbourne, VIC, Australia</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_isbn" id="id6"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>979-8-4007-0686-8/24/10</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id7"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Information systems Language models</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id8"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Information systems Retrieval models and ranking</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id9"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Information systems Novelty in information retrieval</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Given a query text description, text-video retrieval <cite class="ltx_cite ltx_citemacro_citep">(Xu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib26" title="">2016</a>)</cite> aims to retrieve videos that are semantically relevant to the query. Text-video retrieval is flexible to express the user’s intent and brings emerging attention for web search with the dramatic increasing of videos uploade d online every day. For a standard web search engine <cite class="ltx_cite ltx_citemacro_citep">(Ren et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib19" title="">2023</a>)</cite>, video retrieval and ranking are two core stages. The retrieval stage first retrieves limited number of candidate videos from massive online videos, and the following ranking stage predicts accurate ranking scores between per query and the candidate videos. Since videos have much richer and more diverse visual content compared with the query text, precise video ranking is costly for fine-grained text-video matching. Therefore, the efficiency and recall performance of the video retrieval stage are crucial for achieving fast and accurate text-video search results.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="519" id="S1.F1.g1" src="extracted/5804594/fig/mov13.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>(a) Two stream method with independent video and text encoders. (b) Video sparse sampling for efficiency boost. (c) Our generative video indexer for efficiency boost.</figcaption>
</figure>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Existing text-video retrieval methods can be divided into two categories, namely <span class="ltx_text ltx_font_italic" id="S1.p2.1.1">one-stream</span> and <span class="ltx_text ltx_font_italic" id="S1.p2.1.2">two-stream</span> approaches. One-stream approaches <cite class="ltx_cite ltx_citemacro_citep">(Zhu and Yang, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib32" title="">2020</a>)</cite> <cite class="ltx_cite ltx_citemacro_citep">(Lei et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib12" title="">2021</a>)</cite> <cite class="ltx_cite ltx_citemacro_citep">(Luo et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib15" title="">2020</a>)</cite> adopts deep models for feature-level interactions between each text-video pair to predict its similarity score, which require online feature extraction and fail to be applied for the time-sensitive retrieval stage. Thus, the efficient two-stream approaches <cite class="ltx_cite ltx_citemacro_citep">(Gabeur et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib10" title="">2020</a>)</cite> <cite class="ltx_cite ltx_citemacro_citep">(Luo et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib16" title="">2022</a>)</cite> <cite class="ltx_cite ltx_citemacro_citep">(Wu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib23" title="">2023</a>)</cite> are widely applied. As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_tag">1</span></a> (a), they encode each video and text independently into dense embeddings and then adopt simple matching functions to measure their similarity. Since there are no text-video interactions in the encoding stage, two-stream approaches allows offline data embedding extraction and alleviating online computation. Some recent works begin to focus on the issues of reducing the high computational overload of dense video embedding by sparsely sampling a few clips <cite class="ltx_cite ltx_citemacro_citep">(Lei et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib12" title="">2021</a>)</cite> (see Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_tag">1</span></a> (b)). However, all the existing solutions require to measure the query-video similarities and then rank videos for the entire video set (<span class="ltx_text ltx_font_italic" id="S1.p2.1.3">i.e.</span>, one-to-all retrieval framework). Thus, their online retrieval time grows linearly with the increase of retrieved videos, which limits their scalability on large-scale scenarios.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">To address the above issue, we explore to fundamentally change the traditional one-to-all embedding retrieval framework by a generative deep model that directly generates video identifiers and retrieves video candidates with constant time complexity. As illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_tag">1</span></a> (c), our target of this work is not to propose a new model on text-video retrieval. We mainly investigate how to design a model-based indexer that effectively retrieves query-relevant video candidates, which shortens the overall retrieval time while maintaining the retrieval accuracy of state-of-the-art ranking models. To this end, we propose a sequence-to-sequence generative network that supports <span class="ltx_text ltx_font_bold" id="S1.p3.1.1">T</span>ext query to <span class="ltx_text ltx_font_bold" id="S1.p3.1.2">V</span>ideo candidate <span class="ltx_text ltx_font_bold" id="S1.p3.1.3">Index</span>, named as <span class="ltx_text ltx_font_bold" id="S1.p3.1.4">T2VIndexer</span>. The model is based on the encoder-decoder that feeds the query into the encoder and generates the identifier of the video candidate through the decoder. It is trained by query-identifier pairs that supports controllable video recall at different semantic grained. During inference, the top <math alttext="K" class="ltx_Math" display="inline" id="S1.p3.1.m1.1"><semantics id="S1.p3.1.m1.1a"><mi id="S1.p3.1.m1.1.1" xref="S1.p3.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S1.p3.1.m1.1b"><ci id="S1.p3.1.m1.1.1.cmml" xref="S1.p3.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S1.p3.1.m1.1d">italic_K</annotation></semantics></math> videos are directly retrieved by beam search and identifier constrain.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">To guarantee the effectiveness of T2VIndexer, we have proposed several methods to tackle the key challenges. First, to get the semantic representations and coarse-to-fine identifiers of videos for controllable video recall, we utilize CLIP <cite class="ltx_cite ltx_citemacro_citep">(Radford et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib18" title="">2021</a>)</cite> to embed each video, and then cluster and encode the semantic embeddings in a hierarchical mode. Second, we propose to leverage the pre-trained multi-modal large language model <cite class="ltx_cite ltx_citemacro_citep">(Ye et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib28" title="">2023</a>)</cite> to generate new queries with diverse views of the video content, which augments the query-identifier pairs during training for stronger generalization ability during inference. Third, we propose to train a generative network based on T5 <cite class="ltx_cite ltx_citemacro_citep">(Brown et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib5" title="">2020</a>)</cite> architecture to enable the deep interactions between the query and video identifier, which enhances the cross-modal correlation learning for precise identifier prediction.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">The main contributions are summarized as follows:
(1) We propose a new sequence-to-sequence framework as a indexer for efficient video retrieval. Our method predicts candidate videos with constant time complexity, outperforming existing one-to-all embedding retrieval solutions with linear time complexity. It shows the effectiveness of generative video indexing and advances research on generation-based text-video retrieval mechanism.
(2) We propose the video identifier encoding and query-identifier augmentation approaches for learning T2VIndexer with strong generalization ability. T2VIndexer is model-agnostic and universal to cooperatewith various independent-embedding approaches.
(3) Our T2VIndexer method efficiently speeds up text-video retrieval, cutting time by 30% to 50% on standard tasks by cooperated with T2VIndex.
</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related Work</h2>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="287" id="S2.F2.g1" src="extracted/5804594/fig/model4.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>An overview of our T2VIndexer. T2VIndexer uses two different strategies for the training and inference stages. For the training stage, as shown in (a), the process of dividing the training set into a tree structure is illustrated. Training stage (b) shows the process of achieving multi-view query expansion through MLLM. (c) presents the pipeline for model training. For the inference stage, the new video is first inserted into the semantic tree and assigned a SemID, and the baseline model provides the precise retrieval results.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.p1.1.1">Text-video retrieval.</span>
Existing methods can be divided into two categories, called <span class="ltx_text ltx_font_italic" id="S2.p1.1.2">one-stream</span> and <span class="ltx_text ltx_font_italic" id="S2.p1.1.3">two-stream</span> approaches. One-stream approaches are characterized by token-level interactions based on cross-modal attention mechanisms, which are used for fine-grained video-text matching <cite class="ltx_cite ltx_citemacro_citep">(Zhu and Yang, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib32" title="">2020</a>)</cite> <cite class="ltx_cite ltx_citemacro_citep">(Lei et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib12" title="">2021</a>)</cite> <cite class="ltx_cite ltx_citemacro_citep">(Luo et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib15" title="">2020</a>)</cite> <cite class="ltx_cite ltx_citemacro_citep">(Xu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib24" title="">2021</a>)</cite>. Two-stream approaches aim to coordinate videos and text in a unified semantic space and perform direct comparisons through distance metrics <cite class="ltx_cite ltx_citemacro_citep">(Gabeur et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib10" title="">2020</a>)</cite> <cite class="ltx_cite ltx_citemacro_citep">(Luo et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib16" title="">2022</a>)</cite> <cite class="ltx_cite ltx_citemacro_citep">(Wu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib23" title="">2023</a>)</cite>. With the success of pre-trained image-text alignment model such as CLIP <cite class="ltx_cite ltx_citemacro_citep">(Radford et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib18" title="">2021</a>)</cite>, this method not only surpasses interactive embedding methods in efficiency but also has significant advantages in accuracy. In addition, efficiency enhancements have focused on video sampling strategies. Some methods choose to sample the frame sparsely <cite class="ltx_cite ltx_citemacro_citep">(Lei et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib12" title="">2021</a>)</cite> <cite class="ltx_cite ltx_citemacro_citep">(Luo et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib16" title="">2022</a>)</cite>. Besides, redundancy persists within the vision tokens of each frame, diminishing the prowess of CLIP-style retrieval. CenterCLIP <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib31" title="">2022</a>)</cite> addressed this by refining patch subdivision and selection via clustering. These innovations enhance preprocessing efficiency but do not alleviate the inherent online retrieval latency due to similarity computations and ranking cost.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p2">
<p class="ltx_p" id="S2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.p2.1.1">Generative Model in Retrieval.</span>
In unimodal retrieval tasks, the same efficiency issues are faced. With the success of generative models in various visual and language tasks, they have demonstrated powerful capabilities. In document retrieval, models like DSI <cite class="ltx_cite ltx_citemacro_citep">(Tay et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib21" title="">2022</a>)</cite> demonstrate the ability to generate identifiers using Transformer architectures, while approaches like SEAL <cite class="ltx_cite ltx_citemacro_citep">(Bevilacqua et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib4" title="">2022</a>)</cite> innovate by substituting string identifiers with document n-grams. The NCI <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib22" title="">2022</a>)</cite> further refines this approach by integrating positional information into the decoding process. Image-to-image retrieval tasks have transformed these methods into visual modality. For example, IRGen <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib30" title="">2023</a>)</cite> tokenizes images to identifiers and uses a generative model to map queries to these identifiers for direct localization, thereby improving retrieval efficiency.
In addition, <cite class="ltx_cite ltx_citemacro_citep">(Si et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib20" title="">2023</a>)</cite> proposed the SEATER retrieval framework, learning tree structured item identifiers via contrastive learning. Generative models were successfully applied in recommendation systems.
These methods have demonstrated powerful capabilities in unimodal retrieval. However, videos contain rich target and event. There is an obvious many-to-many problem, which means one video corresponds to multiple different descriptions from different perspectives, and a summary description corresponds to multiple different videos.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Methodology</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.4">The text-video retrieval involves a text query <math alttext="t" class="ltx_Math" display="inline" id="S3.p1.1.m1.1"><semantics id="S3.p1.1.m1.1a"><mi id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><ci id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.p1.1.m1.1d">italic_t</annotation></semantics></math> and a gallery of videos <math alttext="V" class="ltx_Math" display="inline" id="S3.p1.2.m2.1"><semantics id="S3.p1.2.m2.1a"><mi id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><ci id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1">𝑉</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">V</annotation><annotation encoding="application/x-llamapun" id="S3.p1.2.m2.1d">italic_V</annotation></semantics></math>. The objective is to retrieve videos <math alttext="\{v_{j}\}\in V" class="ltx_Math" display="inline" id="S3.p1.3.m3.1"><semantics id="S3.p1.3.m3.1a"><mrow id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml"><mrow id="S3.p1.3.m3.1.1.1.1" xref="S3.p1.3.m3.1.1.1.2.cmml"><mo id="S3.p1.3.m3.1.1.1.1.2" stretchy="false" xref="S3.p1.3.m3.1.1.1.2.cmml">{</mo><msub id="S3.p1.3.m3.1.1.1.1.1" xref="S3.p1.3.m3.1.1.1.1.1.cmml"><mi id="S3.p1.3.m3.1.1.1.1.1.2" xref="S3.p1.3.m3.1.1.1.1.1.2.cmml">v</mi><mi id="S3.p1.3.m3.1.1.1.1.1.3" xref="S3.p1.3.m3.1.1.1.1.1.3.cmml">j</mi></msub><mo id="S3.p1.3.m3.1.1.1.1.3" stretchy="false" xref="S3.p1.3.m3.1.1.1.2.cmml">}</mo></mrow><mo id="S3.p1.3.m3.1.1.2" xref="S3.p1.3.m3.1.1.2.cmml">∈</mo><mi id="S3.p1.3.m3.1.1.3" xref="S3.p1.3.m3.1.1.3.cmml">V</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.1b"><apply id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1"><in id="S3.p1.3.m3.1.1.2.cmml" xref="S3.p1.3.m3.1.1.2"></in><set id="S3.p1.3.m3.1.1.1.2.cmml" xref="S3.p1.3.m3.1.1.1.1"><apply id="S3.p1.3.m3.1.1.1.1.1.cmml" xref="S3.p1.3.m3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p1.3.m3.1.1.1.1.1.1.cmml" xref="S3.p1.3.m3.1.1.1.1.1">subscript</csymbol><ci id="S3.p1.3.m3.1.1.1.1.1.2.cmml" xref="S3.p1.3.m3.1.1.1.1.1.2">𝑣</ci><ci id="S3.p1.3.m3.1.1.1.1.1.3.cmml" xref="S3.p1.3.m3.1.1.1.1.1.3">𝑗</ci></apply></set><ci id="S3.p1.3.m3.1.1.3.cmml" xref="S3.p1.3.m3.1.1.3">𝑉</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.1c">\{v_{j}\}\in V</annotation><annotation encoding="application/x-llamapun" id="S3.p1.3.m3.1d">{ italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT } ∈ italic_V</annotation></semantics></math> that are semantically relevant to the query. As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S2.F2" title="Figure 2 ‣ 2. Related Work ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_tag">2</span></a>, our goal is to directly retrieve targeted videos by generating the video identifiers based on natural language queries. To this end, we design a sequence-to-sequence generative model that takes query <math alttext="t" class="ltx_Math" display="inline" id="S3.p1.4.m4.1"><semantics id="S3.p1.4.m4.1a"><mi id="S3.p1.4.m4.1.1" xref="S3.p1.4.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.p1.4.m4.1b"><ci id="S3.p1.4.m4.1.1.cmml" xref="S3.p1.4.m4.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.4.m4.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.p1.4.m4.1d">italic_t</annotation></semantics></math> as input and outputs the video identifier for video index. We first propose a semantic-aware tree structure to encode video identifiers, called SemID, which encodes the multi-grained semantics of videos by a sequence for controllable recall while maintaining the sequence length as short as possible for fast encoding. To augment the semantic expression of queries for more generalized model learning, we propose to utilize a Multi-modal Large Language Model (MLLM) <cite class="ltx_cite ltx_citemacro_citep">(Ye et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib28" title="">2023</a>)</cite> to generate a set of multi-view queries for each video, thereby enriching the contextual semantics encapsulated by the SemIDs for diverse queries. The model architecture, training and inference strategies are introduced in the end.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Vi-SemTree for Video Identifying</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">The purpose of our work is to locate videos by taking query <math alttext="t" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">italic_t</annotation></semantics></math> as input and outputting the most relevant video identifier. Therefore, finding a suitable identifier as the basis for video location is crucial. The identifier needs to have semantic prior information so that it can reflect the content of the video, and similar semantic videos are also similar in the identifier. Moreover, the sequence length should be short enough to reduce the difficulty and complexity of model generation. Based on this consideration, we first extract the representation of each video, and construct a Video Semantic Tree (Vi-SemTree) based on the semantics of the video, and provide a SemID as an identifier for each video based on the tree structure. This approach ensures the semantic consistency of locating videos and guarantees the recall rate of the generation phase.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.4"><span class="ltx_text ltx_font_bold" id="S3.SS1.p2.4.1">Video Semantic Representation.</span>
To construct Vi-SemTree and obtain a sequence representation of SemID, we first extract the representation of the video. Compared with pixel-level information, Vi-SemTree requires the integration of semantic-level information, which is more seamlessly integrated with the structure of natural language. To meet this requirement, we chose the image encoder of CLIP <cite class="ltx_cite ltx_citemacro_citep">(Radford et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib18" title="">2021</a>)</cite>, which is famous for its multimodal pretraining ability, as the basic tool for our video encoding. Given a video’s sequence of frames <math alttext="v_{f}=\{f^{1},f^{2},...,f^{N}\}" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.4"><semantics id="S3.SS1.p2.1.m1.4a"><mrow id="S3.SS1.p2.1.m1.4.4" xref="S3.SS1.p2.1.m1.4.4.cmml"><msub id="S3.SS1.p2.1.m1.4.4.5" xref="S3.SS1.p2.1.m1.4.4.5.cmml"><mi id="S3.SS1.p2.1.m1.4.4.5.2" xref="S3.SS1.p2.1.m1.4.4.5.2.cmml">v</mi><mi id="S3.SS1.p2.1.m1.4.4.5.3" xref="S3.SS1.p2.1.m1.4.4.5.3.cmml">f</mi></msub><mo id="S3.SS1.p2.1.m1.4.4.4" xref="S3.SS1.p2.1.m1.4.4.4.cmml">=</mo><mrow id="S3.SS1.p2.1.m1.4.4.3.3" xref="S3.SS1.p2.1.m1.4.4.3.4.cmml"><mo id="S3.SS1.p2.1.m1.4.4.3.3.4" stretchy="false" xref="S3.SS1.p2.1.m1.4.4.3.4.cmml">{</mo><msup id="S3.SS1.p2.1.m1.2.2.1.1.1" xref="S3.SS1.p2.1.m1.2.2.1.1.1.cmml"><mi id="S3.SS1.p2.1.m1.2.2.1.1.1.2" xref="S3.SS1.p2.1.m1.2.2.1.1.1.2.cmml">f</mi><mn id="S3.SS1.p2.1.m1.2.2.1.1.1.3" xref="S3.SS1.p2.1.m1.2.2.1.1.1.3.cmml">1</mn></msup><mo id="S3.SS1.p2.1.m1.4.4.3.3.5" xref="S3.SS1.p2.1.m1.4.4.3.4.cmml">,</mo><msup id="S3.SS1.p2.1.m1.3.3.2.2.2" xref="S3.SS1.p2.1.m1.3.3.2.2.2.cmml"><mi id="S3.SS1.p2.1.m1.3.3.2.2.2.2" xref="S3.SS1.p2.1.m1.3.3.2.2.2.2.cmml">f</mi><mn id="S3.SS1.p2.1.m1.3.3.2.2.2.3" xref="S3.SS1.p2.1.m1.3.3.2.2.2.3.cmml">2</mn></msup><mo id="S3.SS1.p2.1.m1.4.4.3.3.6" xref="S3.SS1.p2.1.m1.4.4.3.4.cmml">,</mo><mi id="S3.SS1.p2.1.m1.1.1" mathvariant="normal" xref="S3.SS1.p2.1.m1.1.1.cmml">…</mi><mo id="S3.SS1.p2.1.m1.4.4.3.3.7" xref="S3.SS1.p2.1.m1.4.4.3.4.cmml">,</mo><msup id="S3.SS1.p2.1.m1.4.4.3.3.3" xref="S3.SS1.p2.1.m1.4.4.3.3.3.cmml"><mi id="S3.SS1.p2.1.m1.4.4.3.3.3.2" xref="S3.SS1.p2.1.m1.4.4.3.3.3.2.cmml">f</mi><mi id="S3.SS1.p2.1.m1.4.4.3.3.3.3" xref="S3.SS1.p2.1.m1.4.4.3.3.3.3.cmml">N</mi></msup><mo id="S3.SS1.p2.1.m1.4.4.3.3.8" stretchy="false" xref="S3.SS1.p2.1.m1.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.4b"><apply id="S3.SS1.p2.1.m1.4.4.cmml" xref="S3.SS1.p2.1.m1.4.4"><eq id="S3.SS1.p2.1.m1.4.4.4.cmml" xref="S3.SS1.p2.1.m1.4.4.4"></eq><apply id="S3.SS1.p2.1.m1.4.4.5.cmml" xref="S3.SS1.p2.1.m1.4.4.5"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.4.4.5.1.cmml" xref="S3.SS1.p2.1.m1.4.4.5">subscript</csymbol><ci id="S3.SS1.p2.1.m1.4.4.5.2.cmml" xref="S3.SS1.p2.1.m1.4.4.5.2">𝑣</ci><ci id="S3.SS1.p2.1.m1.4.4.5.3.cmml" xref="S3.SS1.p2.1.m1.4.4.5.3">𝑓</ci></apply><set id="S3.SS1.p2.1.m1.4.4.3.4.cmml" xref="S3.SS1.p2.1.m1.4.4.3.3"><apply id="S3.SS1.p2.1.m1.2.2.1.1.1.cmml" xref="S3.SS1.p2.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.2.2.1.1.1">superscript</csymbol><ci id="S3.SS1.p2.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.2.2.1.1.1.2">𝑓</ci><cn id="S3.SS1.p2.1.m1.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS1.p2.1.m1.2.2.1.1.1.3">1</cn></apply><apply id="S3.SS1.p2.1.m1.3.3.2.2.2.cmml" xref="S3.SS1.p2.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.3.3.2.2.2.1.cmml" xref="S3.SS1.p2.1.m1.3.3.2.2.2">superscript</csymbol><ci id="S3.SS1.p2.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS1.p2.1.m1.3.3.2.2.2.2">𝑓</ci><cn id="S3.SS1.p2.1.m1.3.3.2.2.2.3.cmml" type="integer" xref="S3.SS1.p2.1.m1.3.3.2.2.2.3">2</cn></apply><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">…</ci><apply id="S3.SS1.p2.1.m1.4.4.3.3.3.cmml" xref="S3.SS1.p2.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.4.4.3.3.3.1.cmml" xref="S3.SS1.p2.1.m1.4.4.3.3.3">superscript</csymbol><ci id="S3.SS1.p2.1.m1.4.4.3.3.3.2.cmml" xref="S3.SS1.p2.1.m1.4.4.3.3.3.2">𝑓</ci><ci id="S3.SS1.p2.1.m1.4.4.3.3.3.3.cmml" xref="S3.SS1.p2.1.m1.4.4.3.3.3.3">𝑁</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.4c">v_{f}=\{f^{1},f^{2},...,f^{N}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.4d">italic_v start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT = { italic_f start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , italic_f start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , … , italic_f start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT }</annotation></semantics></math>, where <math alttext="N" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.1"><semantics id="S3.SS1.p2.2.m2.1a"><mi id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.2.m2.1d">italic_N</annotation></semantics></math> is the number of frames. We derive the corresponding frame representation as <math alttext="\hat{f}=\{\hat{f}^{1},\hat{f}^{2},...,\hat{f}^{N}\}" class="ltx_Math" display="inline" id="S3.SS1.p2.3.m3.4"><semantics id="S3.SS1.p2.3.m3.4a"><mrow id="S3.SS1.p2.3.m3.4.4" xref="S3.SS1.p2.3.m3.4.4.cmml"><mover accent="true" id="S3.SS1.p2.3.m3.4.4.5" xref="S3.SS1.p2.3.m3.4.4.5.cmml"><mi id="S3.SS1.p2.3.m3.4.4.5.2" xref="S3.SS1.p2.3.m3.4.4.5.2.cmml">f</mi><mo id="S3.SS1.p2.3.m3.4.4.5.1" xref="S3.SS1.p2.3.m3.4.4.5.1.cmml">^</mo></mover><mo id="S3.SS1.p2.3.m3.4.4.4" xref="S3.SS1.p2.3.m3.4.4.4.cmml">=</mo><mrow id="S3.SS1.p2.3.m3.4.4.3.3" xref="S3.SS1.p2.3.m3.4.4.3.4.cmml"><mo id="S3.SS1.p2.3.m3.4.4.3.3.4" stretchy="false" xref="S3.SS1.p2.3.m3.4.4.3.4.cmml">{</mo><msup id="S3.SS1.p2.3.m3.2.2.1.1.1" xref="S3.SS1.p2.3.m3.2.2.1.1.1.cmml"><mover accent="true" id="S3.SS1.p2.3.m3.2.2.1.1.1.2" xref="S3.SS1.p2.3.m3.2.2.1.1.1.2.cmml"><mi id="S3.SS1.p2.3.m3.2.2.1.1.1.2.2" xref="S3.SS1.p2.3.m3.2.2.1.1.1.2.2.cmml">f</mi><mo id="S3.SS1.p2.3.m3.2.2.1.1.1.2.1" xref="S3.SS1.p2.3.m3.2.2.1.1.1.2.1.cmml">^</mo></mover><mn id="S3.SS1.p2.3.m3.2.2.1.1.1.3" xref="S3.SS1.p2.3.m3.2.2.1.1.1.3.cmml">1</mn></msup><mo id="S3.SS1.p2.3.m3.4.4.3.3.5" xref="S3.SS1.p2.3.m3.4.4.3.4.cmml">,</mo><msup id="S3.SS1.p2.3.m3.3.3.2.2.2" xref="S3.SS1.p2.3.m3.3.3.2.2.2.cmml"><mover accent="true" id="S3.SS1.p2.3.m3.3.3.2.2.2.2" xref="S3.SS1.p2.3.m3.3.3.2.2.2.2.cmml"><mi id="S3.SS1.p2.3.m3.3.3.2.2.2.2.2" xref="S3.SS1.p2.3.m3.3.3.2.2.2.2.2.cmml">f</mi><mo id="S3.SS1.p2.3.m3.3.3.2.2.2.2.1" xref="S3.SS1.p2.3.m3.3.3.2.2.2.2.1.cmml">^</mo></mover><mn id="S3.SS1.p2.3.m3.3.3.2.2.2.3" xref="S3.SS1.p2.3.m3.3.3.2.2.2.3.cmml">2</mn></msup><mo id="S3.SS1.p2.3.m3.4.4.3.3.6" xref="S3.SS1.p2.3.m3.4.4.3.4.cmml">,</mo><mi id="S3.SS1.p2.3.m3.1.1" mathvariant="normal" xref="S3.SS1.p2.3.m3.1.1.cmml">…</mi><mo id="S3.SS1.p2.3.m3.4.4.3.3.7" xref="S3.SS1.p2.3.m3.4.4.3.4.cmml">,</mo><msup id="S3.SS1.p2.3.m3.4.4.3.3.3" xref="S3.SS1.p2.3.m3.4.4.3.3.3.cmml"><mover accent="true" id="S3.SS1.p2.3.m3.4.4.3.3.3.2" xref="S3.SS1.p2.3.m3.4.4.3.3.3.2.cmml"><mi id="S3.SS1.p2.3.m3.4.4.3.3.3.2.2" xref="S3.SS1.p2.3.m3.4.4.3.3.3.2.2.cmml">f</mi><mo id="S3.SS1.p2.3.m3.4.4.3.3.3.2.1" xref="S3.SS1.p2.3.m3.4.4.3.3.3.2.1.cmml">^</mo></mover><mi id="S3.SS1.p2.3.m3.4.4.3.3.3.3" xref="S3.SS1.p2.3.m3.4.4.3.3.3.3.cmml">N</mi></msup><mo id="S3.SS1.p2.3.m3.4.4.3.3.8" stretchy="false" xref="S3.SS1.p2.3.m3.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.4b"><apply id="S3.SS1.p2.3.m3.4.4.cmml" xref="S3.SS1.p2.3.m3.4.4"><eq id="S3.SS1.p2.3.m3.4.4.4.cmml" xref="S3.SS1.p2.3.m3.4.4.4"></eq><apply id="S3.SS1.p2.3.m3.4.4.5.cmml" xref="S3.SS1.p2.3.m3.4.4.5"><ci id="S3.SS1.p2.3.m3.4.4.5.1.cmml" xref="S3.SS1.p2.3.m3.4.4.5.1">^</ci><ci id="S3.SS1.p2.3.m3.4.4.5.2.cmml" xref="S3.SS1.p2.3.m3.4.4.5.2">𝑓</ci></apply><set id="S3.SS1.p2.3.m3.4.4.3.4.cmml" xref="S3.SS1.p2.3.m3.4.4.3.3"><apply id="S3.SS1.p2.3.m3.2.2.1.1.1.cmml" xref="S3.SS1.p2.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.2.2.1.1.1.1.cmml" xref="S3.SS1.p2.3.m3.2.2.1.1.1">superscript</csymbol><apply id="S3.SS1.p2.3.m3.2.2.1.1.1.2.cmml" xref="S3.SS1.p2.3.m3.2.2.1.1.1.2"><ci id="S3.SS1.p2.3.m3.2.2.1.1.1.2.1.cmml" xref="S3.SS1.p2.3.m3.2.2.1.1.1.2.1">^</ci><ci id="S3.SS1.p2.3.m3.2.2.1.1.1.2.2.cmml" xref="S3.SS1.p2.3.m3.2.2.1.1.1.2.2">𝑓</ci></apply><cn id="S3.SS1.p2.3.m3.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS1.p2.3.m3.2.2.1.1.1.3">1</cn></apply><apply id="S3.SS1.p2.3.m3.3.3.2.2.2.cmml" xref="S3.SS1.p2.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.3.3.2.2.2.1.cmml" xref="S3.SS1.p2.3.m3.3.3.2.2.2">superscript</csymbol><apply id="S3.SS1.p2.3.m3.3.3.2.2.2.2.cmml" xref="S3.SS1.p2.3.m3.3.3.2.2.2.2"><ci id="S3.SS1.p2.3.m3.3.3.2.2.2.2.1.cmml" xref="S3.SS1.p2.3.m3.3.3.2.2.2.2.1">^</ci><ci id="S3.SS1.p2.3.m3.3.3.2.2.2.2.2.cmml" xref="S3.SS1.p2.3.m3.3.3.2.2.2.2.2">𝑓</ci></apply><cn id="S3.SS1.p2.3.m3.3.3.2.2.2.3.cmml" type="integer" xref="S3.SS1.p2.3.m3.3.3.2.2.2.3">2</cn></apply><ci id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">…</ci><apply id="S3.SS1.p2.3.m3.4.4.3.3.3.cmml" xref="S3.SS1.p2.3.m3.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.4.4.3.3.3.1.cmml" xref="S3.SS1.p2.3.m3.4.4.3.3.3">superscript</csymbol><apply id="S3.SS1.p2.3.m3.4.4.3.3.3.2.cmml" xref="S3.SS1.p2.3.m3.4.4.3.3.3.2"><ci id="S3.SS1.p2.3.m3.4.4.3.3.3.2.1.cmml" xref="S3.SS1.p2.3.m3.4.4.3.3.3.2.1">^</ci><ci id="S3.SS1.p2.3.m3.4.4.3.3.3.2.2.cmml" xref="S3.SS1.p2.3.m3.4.4.3.3.3.2.2">𝑓</ci></apply><ci id="S3.SS1.p2.3.m3.4.4.3.3.3.3.cmml" xref="S3.SS1.p2.3.m3.4.4.3.3.3.3">𝑁</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.4c">\hat{f}=\{\hat{f}^{1},\hat{f}^{2},...,\hat{f}^{N}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.3.m3.4d">over^ start_ARG italic_f end_ARG = { over^ start_ARG italic_f end_ARG start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , over^ start_ARG italic_f end_ARG start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , … , over^ start_ARG italic_f end_ARG start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT }</annotation></semantics></math>, culminating in the overall video representation <math alttext="\hat{F}" class="ltx_Math" display="inline" id="S3.SS1.p2.4.m4.1"><semantics id="S3.SS1.p2.4.m4.1a"><mover accent="true" id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml"><mi id="S3.SS1.p2.4.m4.1.1.2" xref="S3.SS1.p2.4.m4.1.1.2.cmml">F</mi><mo id="S3.SS1.p2.4.m4.1.1.1" xref="S3.SS1.p2.4.m4.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"><ci id="S3.SS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1.1">^</ci><ci id="S3.SS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2">𝐹</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">\hat{F}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.4.m4.1d">over^ start_ARG italic_F end_ARG</annotation></semantics></math>, obtained through mean pooling of the individual frame representations. Conforming to the methodologies laid out by ViT <cite class="ltx_cite ltx_citemacro_citep">(Dosovitskiy et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib8" title="">2021</a>)</cite> and CLIP <cite class="ltx_cite ltx_citemacro_citep">(Radford et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib18" title="">2021</a>)</cite>, the output gleaned from the [class] token is utilized to represent each frame.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.9"><span class="ltx_text ltx_font_bold" id="S3.SS1.p3.9.1">Hierarchical Vi-SemTree Building.</span>
We use a tree structure to encode videos, which helps preserve semantic information and ensures that similar semantic videos are also similar in the identifier. Moreover, by controlling the depth <math alttext="d" class="ltx_Math" display="inline" id="S3.SS1.p3.1.m1.1"><semantics id="S3.SS1.p3.1.m1.1a"><mi id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><ci id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">d</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.1.m1.1d">italic_d</annotation></semantics></math> of the tree, we can achieve different levels of granularity and control the sequence length. Following NCI<cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib22" title="">2022</a>)</cite>, we use hierarchical <math alttext="k" class="ltx_Math" display="inline" id="S3.SS1.p3.2.m2.1"><semantics id="S3.SS1.p3.2.m2.1a"><mi id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><ci id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.2.m2.1d">italic_k</annotation></semantics></math>-means method for video feature <math alttext="\hat{F}" class="ltx_Math" display="inline" id="S3.SS1.p3.3.m3.1"><semantics id="S3.SS1.p3.3.m3.1a"><mover accent="true" id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml"><mi id="S3.SS1.p3.3.m3.1.1.2" xref="S3.SS1.p3.3.m3.1.1.2.cmml">F</mi><mo id="S3.SS1.p3.3.m3.1.1.1" xref="S3.SS1.p3.3.m3.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><apply id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1"><ci id="S3.SS1.p3.3.m3.1.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1.1">^</ci><ci id="S3.SS1.p3.3.m3.1.1.2.cmml" xref="S3.SS1.p3.3.m3.1.1.2">𝐹</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">\hat{F}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.3.m3.1d">over^ start_ARG italic_F end_ARG</annotation></semantics></math>, as shown in the training stage (a) of Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S2.F2" title="Figure 2 ‣ 2. Related Work ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_tag">2</span></a>. First, we use the <math alttext="k" class="ltx_Math" display="inline" id="S3.SS1.p3.4.m4.1"><semantics id="S3.SS1.p3.4.m4.1a"><mi id="S3.SS1.p3.4.m4.1.1" xref="S3.SS1.p3.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.4.m4.1b"><ci id="S3.SS1.p3.4.m4.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.4.m4.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.4.m4.1d">italic_k</annotation></semantics></math>-means algorithm to divide the training set videos into <math alttext="k" class="ltx_Math" display="inline" id="S3.SS1.p3.5.m5.1"><semantics id="S3.SS1.p3.5.m5.1a"><mi id="S3.SS1.p3.5.m5.1.1" xref="S3.SS1.p3.5.m5.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.5.m5.1b"><ci id="S3.SS1.p3.5.m5.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.5.m5.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.5.m5.1d">italic_k</annotation></semantics></math> clusters based on their representation similarity. Each cluster is a tree node and contains a group of semantically similar videos, which serves as a layer of the tree structure. For each cluster, if the number of videos is greater than <math alttext="c" class="ltx_Math" display="inline" id="S3.SS1.p3.6.m6.1"><semantics id="S3.SS1.p3.6.m6.1a"><mi id="S3.SS1.p3.6.m6.1.1" xref="S3.SS1.p3.6.m6.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.6.m6.1b"><ci id="S3.SS1.p3.6.m6.1.1.cmml" xref="S3.SS1.p3.6.m6.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.6.m6.1c">c</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.6.m6.1d">italic_c</annotation></semantics></math>, we use the <math alttext="k" class="ltx_Math" display="inline" id="S3.SS1.p3.7.m7.1"><semantics id="S3.SS1.p3.7.m7.1a"><mi id="S3.SS1.p3.7.m7.1.1" xref="S3.SS1.p3.7.m7.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.7.m7.1b"><ci id="S3.SS1.p3.7.m7.1.1.cmml" xref="S3.SS1.p3.7.m7.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.7.m7.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.7.m7.1d">italic_k</annotation></semantics></math>-means algorithm to further divide the cluster, generating the next layer of the tree, which is more granular at the semantic level. We repeat this process until we obtain a tree structure <math alttext="T" class="ltx_Math" display="inline" id="S3.SS1.p3.8.m8.1"><semantics id="S3.SS1.p3.8.m8.1a"><mi id="S3.SS1.p3.8.m8.1.1" xref="S3.SS1.p3.8.m8.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.8.m8.1b"><ci id="S3.SS1.p3.8.m8.1.1.cmml" xref="S3.SS1.p3.8.m8.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.8.m8.1c">T</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.8.m8.1d">italic_T</annotation></semantics></math> with the root <math alttext="r" class="ltx_Math" display="inline" id="S3.SS1.p3.9.m9.1"><semantics id="S3.SS1.p3.9.m9.1a"><mi id="S3.SS1.p3.9.m9.1.1" xref="S3.SS1.p3.9.m9.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.9.m9.1b"><ci id="S3.SS1.p3.9.m9.1.1.cmml" xref="S3.SS1.p3.9.m9.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.9.m9.1c">r</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.9.m9.1d">italic_r</annotation></semantics></math>, where semantically similar videos are located in the same path. Following previous work, we adopt cosine similarity as the metric for measuring the similarity between two video representations.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.5"><span class="ltx_text ltx_font_bold" id="S3.SS1.p4.5.1">Vi-SemTree for SemID Encoding.</span>
To directly retrieve a video set, we introduce SemID, a unique identifier derived from the Vi-SemTree, which serves as a pivotal reference for our generative model. We define the SemID as the path <math alttext="L_{\text{path}}=\{l_{0},l_{1},...,l_{d}\}" class="ltx_Math" display="inline" id="S3.SS1.p4.1.m1.4"><semantics id="S3.SS1.p4.1.m1.4a"><mrow id="S3.SS1.p4.1.m1.4.4" xref="S3.SS1.p4.1.m1.4.4.cmml"><msub id="S3.SS1.p4.1.m1.4.4.5" xref="S3.SS1.p4.1.m1.4.4.5.cmml"><mi id="S3.SS1.p4.1.m1.4.4.5.2" xref="S3.SS1.p4.1.m1.4.4.5.2.cmml">L</mi><mtext id="S3.SS1.p4.1.m1.4.4.5.3" xref="S3.SS1.p4.1.m1.4.4.5.3a.cmml">path</mtext></msub><mo id="S3.SS1.p4.1.m1.4.4.4" xref="S3.SS1.p4.1.m1.4.4.4.cmml">=</mo><mrow id="S3.SS1.p4.1.m1.4.4.3.3" xref="S3.SS1.p4.1.m1.4.4.3.4.cmml"><mo id="S3.SS1.p4.1.m1.4.4.3.3.4" stretchy="false" xref="S3.SS1.p4.1.m1.4.4.3.4.cmml">{</mo><msub id="S3.SS1.p4.1.m1.2.2.1.1.1" xref="S3.SS1.p4.1.m1.2.2.1.1.1.cmml"><mi id="S3.SS1.p4.1.m1.2.2.1.1.1.2" xref="S3.SS1.p4.1.m1.2.2.1.1.1.2.cmml">l</mi><mn id="S3.SS1.p4.1.m1.2.2.1.1.1.3" xref="S3.SS1.p4.1.m1.2.2.1.1.1.3.cmml">0</mn></msub><mo id="S3.SS1.p4.1.m1.4.4.3.3.5" xref="S3.SS1.p4.1.m1.4.4.3.4.cmml">,</mo><msub id="S3.SS1.p4.1.m1.3.3.2.2.2" xref="S3.SS1.p4.1.m1.3.3.2.2.2.cmml"><mi id="S3.SS1.p4.1.m1.3.3.2.2.2.2" xref="S3.SS1.p4.1.m1.3.3.2.2.2.2.cmml">l</mi><mn id="S3.SS1.p4.1.m1.3.3.2.2.2.3" xref="S3.SS1.p4.1.m1.3.3.2.2.2.3.cmml">1</mn></msub><mo id="S3.SS1.p4.1.m1.4.4.3.3.6" xref="S3.SS1.p4.1.m1.4.4.3.4.cmml">,</mo><mi id="S3.SS1.p4.1.m1.1.1" mathvariant="normal" xref="S3.SS1.p4.1.m1.1.1.cmml">…</mi><mo id="S3.SS1.p4.1.m1.4.4.3.3.7" xref="S3.SS1.p4.1.m1.4.4.3.4.cmml">,</mo><msub id="S3.SS1.p4.1.m1.4.4.3.3.3" xref="S3.SS1.p4.1.m1.4.4.3.3.3.cmml"><mi id="S3.SS1.p4.1.m1.4.4.3.3.3.2" xref="S3.SS1.p4.1.m1.4.4.3.3.3.2.cmml">l</mi><mi id="S3.SS1.p4.1.m1.4.4.3.3.3.3" xref="S3.SS1.p4.1.m1.4.4.3.3.3.3.cmml">d</mi></msub><mo id="S3.SS1.p4.1.m1.4.4.3.3.8" stretchy="false" xref="S3.SS1.p4.1.m1.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.4b"><apply id="S3.SS1.p4.1.m1.4.4.cmml" xref="S3.SS1.p4.1.m1.4.4"><eq id="S3.SS1.p4.1.m1.4.4.4.cmml" xref="S3.SS1.p4.1.m1.4.4.4"></eq><apply id="S3.SS1.p4.1.m1.4.4.5.cmml" xref="S3.SS1.p4.1.m1.4.4.5"><csymbol cd="ambiguous" id="S3.SS1.p4.1.m1.4.4.5.1.cmml" xref="S3.SS1.p4.1.m1.4.4.5">subscript</csymbol><ci id="S3.SS1.p4.1.m1.4.4.5.2.cmml" xref="S3.SS1.p4.1.m1.4.4.5.2">𝐿</ci><ci id="S3.SS1.p4.1.m1.4.4.5.3a.cmml" xref="S3.SS1.p4.1.m1.4.4.5.3"><mtext id="S3.SS1.p4.1.m1.4.4.5.3.cmml" mathsize="70%" xref="S3.SS1.p4.1.m1.4.4.5.3">path</mtext></ci></apply><set id="S3.SS1.p4.1.m1.4.4.3.4.cmml" xref="S3.SS1.p4.1.m1.4.4.3.3"><apply id="S3.SS1.p4.1.m1.2.2.1.1.1.cmml" xref="S3.SS1.p4.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS1.p4.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.SS1.p4.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS1.p4.1.m1.2.2.1.1.1.2">𝑙</ci><cn id="S3.SS1.p4.1.m1.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS1.p4.1.m1.2.2.1.1.1.3">0</cn></apply><apply id="S3.SS1.p4.1.m1.3.3.2.2.2.cmml" xref="S3.SS1.p4.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p4.1.m1.3.3.2.2.2.1.cmml" xref="S3.SS1.p4.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.SS1.p4.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS1.p4.1.m1.3.3.2.2.2.2">𝑙</ci><cn id="S3.SS1.p4.1.m1.3.3.2.2.2.3.cmml" type="integer" xref="S3.SS1.p4.1.m1.3.3.2.2.2.3">1</cn></apply><ci id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1">…</ci><apply id="S3.SS1.p4.1.m1.4.4.3.3.3.cmml" xref="S3.SS1.p4.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p4.1.m1.4.4.3.3.3.1.cmml" xref="S3.SS1.p4.1.m1.4.4.3.3.3">subscript</csymbol><ci id="S3.SS1.p4.1.m1.4.4.3.3.3.2.cmml" xref="S3.SS1.p4.1.m1.4.4.3.3.3.2">𝑙</ci><ci id="S3.SS1.p4.1.m1.4.4.3.3.3.3.cmml" xref="S3.SS1.p4.1.m1.4.4.3.3.3.3">𝑑</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.4c">L_{\text{path}}=\{l_{0},l_{1},...,l_{d}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.1.m1.4d">italic_L start_POSTSUBSCRIPT path end_POSTSUBSCRIPT = { italic_l start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_l start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT }</annotation></semantics></math>, traversing from the root node <math alttext="r" class="ltx_Math" display="inline" id="S3.SS1.p4.2.m2.1"><semantics id="S3.SS1.p4.2.m2.1a"><mi id="S3.SS1.p4.2.m2.1.1" xref="S3.SS1.p4.2.m2.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m2.1b"><ci id="S3.SS1.p4.2.m2.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m2.1c">r</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.2.m2.1d">italic_r</annotation></semantics></math> down to a leaf node with <math alttext="d" class="ltx_Math" display="inline" id="S3.SS1.p4.3.m3.1"><semantics id="S3.SS1.p4.3.m3.1a"><mi id="S3.SS1.p4.3.m3.1.1" xref="S3.SS1.p4.3.m3.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.3.m3.1b"><ci id="S3.SS1.p4.3.m3.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.3.m3.1c">d</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.3.m3.1d">italic_d</annotation></semantics></math> marking tree depth. Specifically, the root node is represented as 0, serving as the start symbol. Each edge branching out from each node is numbered starting from 0, with values ranging from 0 to <math alttext="k" class="ltx_Math" display="inline" id="S3.SS1.p4.4.m4.1"><semantics id="S3.SS1.p4.4.m4.1a"><mi id="S3.SS1.p4.4.m4.1.1" xref="S3.SS1.p4.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.4.m4.1b"><ci id="S3.SS1.p4.4.m4.1.1.cmml" xref="S3.SS1.p4.4.m4.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.4.m4.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.4.m4.1d">italic_k</annotation></semantics></math>. From top to bottom, this sequence serves as the SemID <math alttext="L_{path}" class="ltx_Math" display="inline" id="S3.SS1.p4.5.m5.1"><semantics id="S3.SS1.p4.5.m5.1a"><msub id="S3.SS1.p4.5.m5.1.1" xref="S3.SS1.p4.5.m5.1.1.cmml"><mi id="S3.SS1.p4.5.m5.1.1.2" xref="S3.SS1.p4.5.m5.1.1.2.cmml">L</mi><mrow id="S3.SS1.p4.5.m5.1.1.3" xref="S3.SS1.p4.5.m5.1.1.3.cmml"><mi id="S3.SS1.p4.5.m5.1.1.3.2" xref="S3.SS1.p4.5.m5.1.1.3.2.cmml">p</mi><mo id="S3.SS1.p4.5.m5.1.1.3.1" xref="S3.SS1.p4.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p4.5.m5.1.1.3.3" xref="S3.SS1.p4.5.m5.1.1.3.3.cmml">a</mi><mo id="S3.SS1.p4.5.m5.1.1.3.1a" xref="S3.SS1.p4.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p4.5.m5.1.1.3.4" xref="S3.SS1.p4.5.m5.1.1.3.4.cmml">t</mi><mo id="S3.SS1.p4.5.m5.1.1.3.1b" xref="S3.SS1.p4.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p4.5.m5.1.1.3.5" xref="S3.SS1.p4.5.m5.1.1.3.5.cmml">h</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.5.m5.1b"><apply id="S3.SS1.p4.5.m5.1.1.cmml" xref="S3.SS1.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.5.m5.1.1.1.cmml" xref="S3.SS1.p4.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p4.5.m5.1.1.2.cmml" xref="S3.SS1.p4.5.m5.1.1.2">𝐿</ci><apply id="S3.SS1.p4.5.m5.1.1.3.cmml" xref="S3.SS1.p4.5.m5.1.1.3"><times id="S3.SS1.p4.5.m5.1.1.3.1.cmml" xref="S3.SS1.p4.5.m5.1.1.3.1"></times><ci id="S3.SS1.p4.5.m5.1.1.3.2.cmml" xref="S3.SS1.p4.5.m5.1.1.3.2">𝑝</ci><ci id="S3.SS1.p4.5.m5.1.1.3.3.cmml" xref="S3.SS1.p4.5.m5.1.1.3.3">𝑎</ci><ci id="S3.SS1.p4.5.m5.1.1.3.4.cmml" xref="S3.SS1.p4.5.m5.1.1.3.4">𝑡</ci><ci id="S3.SS1.p4.5.m5.1.1.3.5.cmml" xref="S3.SS1.p4.5.m5.1.1.3.5">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.5.m5.1c">L_{path}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.5.m5.1d">italic_L start_POSTSUBSCRIPT italic_p italic_a italic_t italic_h end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Multi-view Textual Query Expansion</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Given video’s rich semantic diversity, a single video can match multiple queries, but current models only generate limited descriptions, undermining semantic understanding. To address this, we introduced a multi-view query expansion strategy during Training stage (b) in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S2.F2" title="Figure 2 ‣ 2. Related Work ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_tag">2</span></a>, enhancing semantic depth.
Utilizing the Multimodal Large Language Model (MLLM), which excels in generating nuanced descriptions from various angles, we created 50 diverse queries per video, ensuring comprehensive semantic coverage. This approach surpasses traditional dense video caption models by offering detailed, multi-faceted insights into video content.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.11">Based on the query <math alttext="t" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">italic_t</annotation></semantics></math> provided in the dataset and the extended query <math alttext="\hat{t}" class="ltx_Math" display="inline" id="S3.SS2.p2.2.m2.1"><semantics id="S3.SS2.p2.2.m2.1a"><mover accent="true" id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml"><mi id="S3.SS2.p2.2.m2.1.1.2" xref="S3.SS2.p2.2.m2.1.1.2.cmml">t</mi><mo id="S3.SS2.p2.2.m2.1.1.1" xref="S3.SS2.p2.2.m2.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><apply id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1"><ci id="S3.SS2.p2.2.m2.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1.1">^</ci><ci id="S3.SS2.p2.2.m2.1.1.2.cmml" xref="S3.SS2.p2.2.m2.1.1.2">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">\hat{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.2.m2.1d">over^ start_ARG italic_t end_ARG</annotation></semantics></math>, the query set <math alttext="Q_{i}=\{t_{i},\hat{t}_{i}\}" class="ltx_Math" display="inline" id="S3.SS2.p2.3.m3.2"><semantics id="S3.SS2.p2.3.m3.2a"><mrow id="S3.SS2.p2.3.m3.2.2" xref="S3.SS2.p2.3.m3.2.2.cmml"><msub id="S3.SS2.p2.3.m3.2.2.4" xref="S3.SS2.p2.3.m3.2.2.4.cmml"><mi id="S3.SS2.p2.3.m3.2.2.4.2" xref="S3.SS2.p2.3.m3.2.2.4.2.cmml">Q</mi><mi id="S3.SS2.p2.3.m3.2.2.4.3" xref="S3.SS2.p2.3.m3.2.2.4.3.cmml">i</mi></msub><mo id="S3.SS2.p2.3.m3.2.2.3" xref="S3.SS2.p2.3.m3.2.2.3.cmml">=</mo><mrow id="S3.SS2.p2.3.m3.2.2.2.2" xref="S3.SS2.p2.3.m3.2.2.2.3.cmml"><mo id="S3.SS2.p2.3.m3.2.2.2.2.3" stretchy="false" xref="S3.SS2.p2.3.m3.2.2.2.3.cmml">{</mo><msub id="S3.SS2.p2.3.m3.1.1.1.1.1" xref="S3.SS2.p2.3.m3.1.1.1.1.1.cmml"><mi id="S3.SS2.p2.3.m3.1.1.1.1.1.2" xref="S3.SS2.p2.3.m3.1.1.1.1.1.2.cmml">t</mi><mi id="S3.SS2.p2.3.m3.1.1.1.1.1.3" xref="S3.SS2.p2.3.m3.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS2.p2.3.m3.2.2.2.2.4" xref="S3.SS2.p2.3.m3.2.2.2.3.cmml">,</mo><msub id="S3.SS2.p2.3.m3.2.2.2.2.2" xref="S3.SS2.p2.3.m3.2.2.2.2.2.cmml"><mover accent="true" id="S3.SS2.p2.3.m3.2.2.2.2.2.2" xref="S3.SS2.p2.3.m3.2.2.2.2.2.2.cmml"><mi id="S3.SS2.p2.3.m3.2.2.2.2.2.2.2" xref="S3.SS2.p2.3.m3.2.2.2.2.2.2.2.cmml">t</mi><mo id="S3.SS2.p2.3.m3.2.2.2.2.2.2.1" xref="S3.SS2.p2.3.m3.2.2.2.2.2.2.1.cmml">^</mo></mover><mi id="S3.SS2.p2.3.m3.2.2.2.2.2.3" xref="S3.SS2.p2.3.m3.2.2.2.2.2.3.cmml">i</mi></msub><mo id="S3.SS2.p2.3.m3.2.2.2.2.5" stretchy="false" xref="S3.SS2.p2.3.m3.2.2.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.2b"><apply id="S3.SS2.p2.3.m3.2.2.cmml" xref="S3.SS2.p2.3.m3.2.2"><eq id="S3.SS2.p2.3.m3.2.2.3.cmml" xref="S3.SS2.p2.3.m3.2.2.3"></eq><apply id="S3.SS2.p2.3.m3.2.2.4.cmml" xref="S3.SS2.p2.3.m3.2.2.4"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.2.2.4.1.cmml" xref="S3.SS2.p2.3.m3.2.2.4">subscript</csymbol><ci id="S3.SS2.p2.3.m3.2.2.4.2.cmml" xref="S3.SS2.p2.3.m3.2.2.4.2">𝑄</ci><ci id="S3.SS2.p2.3.m3.2.2.4.3.cmml" xref="S3.SS2.p2.3.m3.2.2.4.3">𝑖</ci></apply><set id="S3.SS2.p2.3.m3.2.2.2.3.cmml" xref="S3.SS2.p2.3.m3.2.2.2.2"><apply id="S3.SS2.p2.3.m3.1.1.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.3.m3.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.1.2">𝑡</ci><ci id="S3.SS2.p2.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.SS2.p2.3.m3.2.2.2.2.2.cmml" xref="S3.SS2.p2.3.m3.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.2.2.2.2.2.1.cmml" xref="S3.SS2.p2.3.m3.2.2.2.2.2">subscript</csymbol><apply id="S3.SS2.p2.3.m3.2.2.2.2.2.2.cmml" xref="S3.SS2.p2.3.m3.2.2.2.2.2.2"><ci id="S3.SS2.p2.3.m3.2.2.2.2.2.2.1.cmml" xref="S3.SS2.p2.3.m3.2.2.2.2.2.2.1">^</ci><ci id="S3.SS2.p2.3.m3.2.2.2.2.2.2.2.cmml" xref="S3.SS2.p2.3.m3.2.2.2.2.2.2.2">𝑡</ci></apply><ci id="S3.SS2.p2.3.m3.2.2.2.2.2.3.cmml" xref="S3.SS2.p2.3.m3.2.2.2.2.2.3">𝑖</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.2c">Q_{i}=\{t_{i},\hat{t}_{i}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.3.m3.2d">italic_Q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = { italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , over^ start_ARG italic_t end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT }</annotation></semantics></math> is associated with each video <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.p2.4.m4.1"><semantics id="S3.SS2.p2.4.m4.1a"><mi id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><ci id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.4.m4.1d">italic_i</annotation></semantics></math> in the training set <math alttext="D" class="ltx_Math" display="inline" id="S3.SS2.p2.5.m5.1"><semantics id="S3.SS2.p2.5.m5.1a"><mi id="S3.SS2.p2.5.m5.1.1" xref="S3.SS2.p2.5.m5.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.1b"><ci id="S3.SS2.p2.5.m5.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.1c">D</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.5.m5.1d">italic_D</annotation></semantics></math>. We can represent the training data pairs for the generation model as<math alttext="\{(q,\ SemID_{i}),\ \ q\in Q_{i},\ \ i\in D\}" class="ltx_Math" display="inline" id="S3.SS2.p2.6.m6.3"><semantics id="S3.SS2.p2.6.m6.3a"><mrow id="S3.SS2.p2.6.m6.3.3.1" xref="S3.SS2.p2.6.m6.3.3.2.cmml"><mo id="S3.SS2.p2.6.m6.3.3.1.2" stretchy="false" xref="S3.SS2.p2.6.m6.3.3.2.cmml">{</mo><mrow id="S3.SS2.p2.6.m6.3.3.1.1.2" xref="S3.SS2.p2.6.m6.3.3.1.1.3.cmml"><mrow id="S3.SS2.p2.6.m6.3.3.1.1.1.1" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.cmml"><mrow id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.2.cmml"><mrow id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.2.cmml"><mo id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.2.cmml">(</mo><mi id="S3.SS2.p2.6.m6.1.1" xref="S3.SS2.p2.6.m6.1.1.cmml">q</mi><mo id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.3" rspace="0.667em" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.2.cmml">,</mo><mrow id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.2" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.2.cmml">S</mi><mo id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.1" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.3" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.3.cmml">e</mi><mo id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.1a" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.4" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.4.cmml">m</mi><mo id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.1b" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.5" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.5.cmml">I</mi><mo id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.1c" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.1.cmml">⁢</mo><msub id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.6" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.6.cmml"><mi id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.6.2" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.6.2.cmml">D</mi><mi id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.6.3" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.6.3.cmml">i</mi></msub></mrow><mo id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.4" stretchy="false" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.2.cmml">)</mo></mrow><mo id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.2" rspace="1.167em" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.2.cmml">,</mo><mi id="S3.SS2.p2.6.m6.2.2" xref="S3.SS2.p2.6.m6.2.2.cmml">q</mi></mrow><mo id="S3.SS2.p2.6.m6.3.3.1.1.1.1.2" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.2.cmml">∈</mo><msub id="S3.SS2.p2.6.m6.3.3.1.1.1.1.3" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.3.cmml"><mi id="S3.SS2.p2.6.m6.3.3.1.1.1.1.3.2" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.3.2.cmml">Q</mi><mi id="S3.SS2.p2.6.m6.3.3.1.1.1.1.3.3" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S3.SS2.p2.6.m6.3.3.1.1.2.3" rspace="1.167em" xref="S3.SS2.p2.6.m6.3.3.1.1.3a.cmml">,</mo><mrow id="S3.SS2.p2.6.m6.3.3.1.1.2.2" xref="S3.SS2.p2.6.m6.3.3.1.1.2.2.cmml"><mi id="S3.SS2.p2.6.m6.3.3.1.1.2.2.2" xref="S3.SS2.p2.6.m6.3.3.1.1.2.2.2.cmml">i</mi><mo id="S3.SS2.p2.6.m6.3.3.1.1.2.2.1" xref="S3.SS2.p2.6.m6.3.3.1.1.2.2.1.cmml">∈</mo><mi id="S3.SS2.p2.6.m6.3.3.1.1.2.2.3" xref="S3.SS2.p2.6.m6.3.3.1.1.2.2.3.cmml">D</mi></mrow></mrow><mo id="S3.SS2.p2.6.m6.3.3.1.3" stretchy="false" xref="S3.SS2.p2.6.m6.3.3.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m6.3b"><set id="S3.SS2.p2.6.m6.3.3.2.cmml" xref="S3.SS2.p2.6.m6.3.3.1"><apply id="S3.SS2.p2.6.m6.3.3.1.1.3.cmml" xref="S3.SS2.p2.6.m6.3.3.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.6.m6.3.3.1.1.3a.cmml" xref="S3.SS2.p2.6.m6.3.3.1.1.2.3">formulae-sequence</csymbol><apply id="S3.SS2.p2.6.m6.3.3.1.1.1.1.cmml" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1"><in id="S3.SS2.p2.6.m6.3.3.1.1.1.1.2.cmml" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.2"></in><list id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1"><interval closure="open" id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1"><ci id="S3.SS2.p2.6.m6.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1">𝑞</ci><apply id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1"><times id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.1"></times><ci id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.2">𝑆</ci><ci id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.3">𝑒</ci><ci id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.4.cmml" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.4">𝑚</ci><ci id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.5.cmml" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.5">𝐼</ci><apply id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.6.cmml" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.6"><csymbol cd="ambiguous" id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.6.1.cmml" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.6">subscript</csymbol><ci id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.6.2.cmml" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.6.2">𝐷</ci><ci id="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.6.3.cmml" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.1.1.1.1.1.6.3">𝑖</ci></apply></apply></interval><ci id="S3.SS2.p2.6.m6.2.2.cmml" xref="S3.SS2.p2.6.m6.2.2">𝑞</ci></list><apply id="S3.SS2.p2.6.m6.3.3.1.1.1.1.3.cmml" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p2.6.m6.3.3.1.1.1.1.3.1.cmml" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.3">subscript</csymbol><ci id="S3.SS2.p2.6.m6.3.3.1.1.1.1.3.2.cmml" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.3.2">𝑄</ci><ci id="S3.SS2.p2.6.m6.3.3.1.1.1.1.3.3.cmml" xref="S3.SS2.p2.6.m6.3.3.1.1.1.1.3.3">𝑖</ci></apply></apply><apply id="S3.SS2.p2.6.m6.3.3.1.1.2.2.cmml" xref="S3.SS2.p2.6.m6.3.3.1.1.2.2"><in id="S3.SS2.p2.6.m6.3.3.1.1.2.2.1.cmml" xref="S3.SS2.p2.6.m6.3.3.1.1.2.2.1"></in><ci id="S3.SS2.p2.6.m6.3.3.1.1.2.2.2.cmml" xref="S3.SS2.p2.6.m6.3.3.1.1.2.2.2">𝑖</ci><ci id="S3.SS2.p2.6.m6.3.3.1.1.2.2.3.cmml" xref="S3.SS2.p2.6.m6.3.3.1.1.2.2.3">𝐷</ci></apply></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m6.3c">\{(q,\ SemID_{i}),\ \ q\in Q_{i},\ \ i\in D\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.6.m6.3d">{ ( italic_q , italic_S italic_e italic_m italic_I italic_D start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , italic_q ∈ italic_Q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_i ∈ italic_D }</annotation></semantics></math>, where <math alttext="SemID_{i}" class="ltx_Math" display="inline" id="S3.SS2.p2.7.m7.1"><semantics id="S3.SS2.p2.7.m7.1a"><mrow id="S3.SS2.p2.7.m7.1.1" xref="S3.SS2.p2.7.m7.1.1.cmml"><mi id="S3.SS2.p2.7.m7.1.1.2" xref="S3.SS2.p2.7.m7.1.1.2.cmml">S</mi><mo id="S3.SS2.p2.7.m7.1.1.1" xref="S3.SS2.p2.7.m7.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p2.7.m7.1.1.3" xref="S3.SS2.p2.7.m7.1.1.3.cmml">e</mi><mo id="S3.SS2.p2.7.m7.1.1.1a" xref="S3.SS2.p2.7.m7.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p2.7.m7.1.1.4" xref="S3.SS2.p2.7.m7.1.1.4.cmml">m</mi><mo id="S3.SS2.p2.7.m7.1.1.1b" xref="S3.SS2.p2.7.m7.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p2.7.m7.1.1.5" xref="S3.SS2.p2.7.m7.1.1.5.cmml">I</mi><mo id="S3.SS2.p2.7.m7.1.1.1c" xref="S3.SS2.p2.7.m7.1.1.1.cmml">⁢</mo><msub id="S3.SS2.p2.7.m7.1.1.6" xref="S3.SS2.p2.7.m7.1.1.6.cmml"><mi id="S3.SS2.p2.7.m7.1.1.6.2" xref="S3.SS2.p2.7.m7.1.1.6.2.cmml">D</mi><mi id="S3.SS2.p2.7.m7.1.1.6.3" xref="S3.SS2.p2.7.m7.1.1.6.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.7.m7.1b"><apply id="S3.SS2.p2.7.m7.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1"><times id="S3.SS2.p2.7.m7.1.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1.1"></times><ci id="S3.SS2.p2.7.m7.1.1.2.cmml" xref="S3.SS2.p2.7.m7.1.1.2">𝑆</ci><ci id="S3.SS2.p2.7.m7.1.1.3.cmml" xref="S3.SS2.p2.7.m7.1.1.3">𝑒</ci><ci id="S3.SS2.p2.7.m7.1.1.4.cmml" xref="S3.SS2.p2.7.m7.1.1.4">𝑚</ci><ci id="S3.SS2.p2.7.m7.1.1.5.cmml" xref="S3.SS2.p2.7.m7.1.1.5">𝐼</ci><apply id="S3.SS2.p2.7.m7.1.1.6.cmml" xref="S3.SS2.p2.7.m7.1.1.6"><csymbol cd="ambiguous" id="S3.SS2.p2.7.m7.1.1.6.1.cmml" xref="S3.SS2.p2.7.m7.1.1.6">subscript</csymbol><ci id="S3.SS2.p2.7.m7.1.1.6.2.cmml" xref="S3.SS2.p2.7.m7.1.1.6.2">𝐷</ci><ci id="S3.SS2.p2.7.m7.1.1.6.3.cmml" xref="S3.SS2.p2.7.m7.1.1.6.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.7.m7.1c">SemID_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.7.m7.1d">italic_S italic_e italic_m italic_I italic_D start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is the <math alttext="L_{path}=\{l_{0},l_{1},...,l_{d}\}" class="ltx_Math" display="inline" id="S3.SS2.p2.8.m8.4"><semantics id="S3.SS2.p2.8.m8.4a"><mrow id="S3.SS2.p2.8.m8.4.4" xref="S3.SS2.p2.8.m8.4.4.cmml"><msub id="S3.SS2.p2.8.m8.4.4.5" xref="S3.SS2.p2.8.m8.4.4.5.cmml"><mi id="S3.SS2.p2.8.m8.4.4.5.2" xref="S3.SS2.p2.8.m8.4.4.5.2.cmml">L</mi><mrow id="S3.SS2.p2.8.m8.4.4.5.3" xref="S3.SS2.p2.8.m8.4.4.5.3.cmml"><mi id="S3.SS2.p2.8.m8.4.4.5.3.2" xref="S3.SS2.p2.8.m8.4.4.5.3.2.cmml">p</mi><mo id="S3.SS2.p2.8.m8.4.4.5.3.1" xref="S3.SS2.p2.8.m8.4.4.5.3.1.cmml">⁢</mo><mi id="S3.SS2.p2.8.m8.4.4.5.3.3" xref="S3.SS2.p2.8.m8.4.4.5.3.3.cmml">a</mi><mo id="S3.SS2.p2.8.m8.4.4.5.3.1a" xref="S3.SS2.p2.8.m8.4.4.5.3.1.cmml">⁢</mo><mi id="S3.SS2.p2.8.m8.4.4.5.3.4" xref="S3.SS2.p2.8.m8.4.4.5.3.4.cmml">t</mi><mo id="S3.SS2.p2.8.m8.4.4.5.3.1b" xref="S3.SS2.p2.8.m8.4.4.5.3.1.cmml">⁢</mo><mi id="S3.SS2.p2.8.m8.4.4.5.3.5" xref="S3.SS2.p2.8.m8.4.4.5.3.5.cmml">h</mi></mrow></msub><mo id="S3.SS2.p2.8.m8.4.4.4" xref="S3.SS2.p2.8.m8.4.4.4.cmml">=</mo><mrow id="S3.SS2.p2.8.m8.4.4.3.3" xref="S3.SS2.p2.8.m8.4.4.3.4.cmml"><mo id="S3.SS2.p2.8.m8.4.4.3.3.4" stretchy="false" xref="S3.SS2.p2.8.m8.4.4.3.4.cmml">{</mo><msub id="S3.SS2.p2.8.m8.2.2.1.1.1" xref="S3.SS2.p2.8.m8.2.2.1.1.1.cmml"><mi id="S3.SS2.p2.8.m8.2.2.1.1.1.2" xref="S3.SS2.p2.8.m8.2.2.1.1.1.2.cmml">l</mi><mn id="S3.SS2.p2.8.m8.2.2.1.1.1.3" xref="S3.SS2.p2.8.m8.2.2.1.1.1.3.cmml">0</mn></msub><mo id="S3.SS2.p2.8.m8.4.4.3.3.5" xref="S3.SS2.p2.8.m8.4.4.3.4.cmml">,</mo><msub id="S3.SS2.p2.8.m8.3.3.2.2.2" xref="S3.SS2.p2.8.m8.3.3.2.2.2.cmml"><mi id="S3.SS2.p2.8.m8.3.3.2.2.2.2" xref="S3.SS2.p2.8.m8.3.3.2.2.2.2.cmml">l</mi><mn id="S3.SS2.p2.8.m8.3.3.2.2.2.3" xref="S3.SS2.p2.8.m8.3.3.2.2.2.3.cmml">1</mn></msub><mo id="S3.SS2.p2.8.m8.4.4.3.3.6" xref="S3.SS2.p2.8.m8.4.4.3.4.cmml">,</mo><mi id="S3.SS2.p2.8.m8.1.1" mathvariant="normal" xref="S3.SS2.p2.8.m8.1.1.cmml">…</mi><mo id="S3.SS2.p2.8.m8.4.4.3.3.7" xref="S3.SS2.p2.8.m8.4.4.3.4.cmml">,</mo><msub id="S3.SS2.p2.8.m8.4.4.3.3.3" xref="S3.SS2.p2.8.m8.4.4.3.3.3.cmml"><mi id="S3.SS2.p2.8.m8.4.4.3.3.3.2" xref="S3.SS2.p2.8.m8.4.4.3.3.3.2.cmml">l</mi><mi id="S3.SS2.p2.8.m8.4.4.3.3.3.3" xref="S3.SS2.p2.8.m8.4.4.3.3.3.3.cmml">d</mi></msub><mo id="S3.SS2.p2.8.m8.4.4.3.3.8" stretchy="false" xref="S3.SS2.p2.8.m8.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.8.m8.4b"><apply id="S3.SS2.p2.8.m8.4.4.cmml" xref="S3.SS2.p2.8.m8.4.4"><eq id="S3.SS2.p2.8.m8.4.4.4.cmml" xref="S3.SS2.p2.8.m8.4.4.4"></eq><apply id="S3.SS2.p2.8.m8.4.4.5.cmml" xref="S3.SS2.p2.8.m8.4.4.5"><csymbol cd="ambiguous" id="S3.SS2.p2.8.m8.4.4.5.1.cmml" xref="S3.SS2.p2.8.m8.4.4.5">subscript</csymbol><ci id="S3.SS2.p2.8.m8.4.4.5.2.cmml" xref="S3.SS2.p2.8.m8.4.4.5.2">𝐿</ci><apply id="S3.SS2.p2.8.m8.4.4.5.3.cmml" xref="S3.SS2.p2.8.m8.4.4.5.3"><times id="S3.SS2.p2.8.m8.4.4.5.3.1.cmml" xref="S3.SS2.p2.8.m8.4.4.5.3.1"></times><ci id="S3.SS2.p2.8.m8.4.4.5.3.2.cmml" xref="S3.SS2.p2.8.m8.4.4.5.3.2">𝑝</ci><ci id="S3.SS2.p2.8.m8.4.4.5.3.3.cmml" xref="S3.SS2.p2.8.m8.4.4.5.3.3">𝑎</ci><ci id="S3.SS2.p2.8.m8.4.4.5.3.4.cmml" xref="S3.SS2.p2.8.m8.4.4.5.3.4">𝑡</ci><ci id="S3.SS2.p2.8.m8.4.4.5.3.5.cmml" xref="S3.SS2.p2.8.m8.4.4.5.3.5">ℎ</ci></apply></apply><set id="S3.SS2.p2.8.m8.4.4.3.4.cmml" xref="S3.SS2.p2.8.m8.4.4.3.3"><apply id="S3.SS2.p2.8.m8.2.2.1.1.1.cmml" xref="S3.SS2.p2.8.m8.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.8.m8.2.2.1.1.1.1.cmml" xref="S3.SS2.p2.8.m8.2.2.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.8.m8.2.2.1.1.1.2.cmml" xref="S3.SS2.p2.8.m8.2.2.1.1.1.2">𝑙</ci><cn id="S3.SS2.p2.8.m8.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS2.p2.8.m8.2.2.1.1.1.3">0</cn></apply><apply id="S3.SS2.p2.8.m8.3.3.2.2.2.cmml" xref="S3.SS2.p2.8.m8.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.8.m8.3.3.2.2.2.1.cmml" xref="S3.SS2.p2.8.m8.3.3.2.2.2">subscript</csymbol><ci id="S3.SS2.p2.8.m8.3.3.2.2.2.2.cmml" xref="S3.SS2.p2.8.m8.3.3.2.2.2.2">𝑙</ci><cn id="S3.SS2.p2.8.m8.3.3.2.2.2.3.cmml" type="integer" xref="S3.SS2.p2.8.m8.3.3.2.2.2.3">1</cn></apply><ci id="S3.SS2.p2.8.m8.1.1.cmml" xref="S3.SS2.p2.8.m8.1.1">…</ci><apply id="S3.SS2.p2.8.m8.4.4.3.3.3.cmml" xref="S3.SS2.p2.8.m8.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p2.8.m8.4.4.3.3.3.1.cmml" xref="S3.SS2.p2.8.m8.4.4.3.3.3">subscript</csymbol><ci id="S3.SS2.p2.8.m8.4.4.3.3.3.2.cmml" xref="S3.SS2.p2.8.m8.4.4.3.3.3.2">𝑙</ci><ci id="S3.SS2.p2.8.m8.4.4.3.3.3.3.cmml" xref="S3.SS2.p2.8.m8.4.4.3.3.3.3">𝑑</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.8.m8.4c">L_{path}=\{l_{0},l_{1},...,l_{d}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.8.m8.4d">italic_L start_POSTSUBSCRIPT italic_p italic_a italic_t italic_h end_POSTSUBSCRIPT = { italic_l start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_l start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT }</annotation></semantics></math> of the node where video <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.p2.9.m9.1"><semantics id="S3.SS2.p2.9.m9.1a"><mi id="S3.SS2.p2.9.m9.1.1" xref="S3.SS2.p2.9.m9.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.9.m9.1b"><ci id="S3.SS2.p2.9.m9.1.1.cmml" xref="S3.SS2.p2.9.m9.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.9.m9.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.9.m9.1d">italic_i</annotation></semantics></math> is located. However, as the tree structure deepens, the semantic of videos in different nodes becomes increasingly similar. This may lead to a decrease in the recall effect of relatively coarse-grained queries. To merge more videos with similar semantics and simplify the generation process, we choose the truncated version of the path as SemID, represented as <math alttext="L_{path}^{trunc}=\{l_{0},l_{1},...,l_{d-m}\}" class="ltx_Math" display="inline" id="S3.SS2.p2.10.m10.4"><semantics id="S3.SS2.p2.10.m10.4a"><mrow id="S3.SS2.p2.10.m10.4.4" xref="S3.SS2.p2.10.m10.4.4.cmml"><msubsup id="S3.SS2.p2.10.m10.4.4.5" xref="S3.SS2.p2.10.m10.4.4.5.cmml"><mi id="S3.SS2.p2.10.m10.4.4.5.2.2" xref="S3.SS2.p2.10.m10.4.4.5.2.2.cmml">L</mi><mrow id="S3.SS2.p2.10.m10.4.4.5.2.3" xref="S3.SS2.p2.10.m10.4.4.5.2.3.cmml"><mi id="S3.SS2.p2.10.m10.4.4.5.2.3.2" xref="S3.SS2.p2.10.m10.4.4.5.2.3.2.cmml">p</mi><mo id="S3.SS2.p2.10.m10.4.4.5.2.3.1" xref="S3.SS2.p2.10.m10.4.4.5.2.3.1.cmml">⁢</mo><mi id="S3.SS2.p2.10.m10.4.4.5.2.3.3" xref="S3.SS2.p2.10.m10.4.4.5.2.3.3.cmml">a</mi><mo id="S3.SS2.p2.10.m10.4.4.5.2.3.1a" xref="S3.SS2.p2.10.m10.4.4.5.2.3.1.cmml">⁢</mo><mi id="S3.SS2.p2.10.m10.4.4.5.2.3.4" xref="S3.SS2.p2.10.m10.4.4.5.2.3.4.cmml">t</mi><mo id="S3.SS2.p2.10.m10.4.4.5.2.3.1b" xref="S3.SS2.p2.10.m10.4.4.5.2.3.1.cmml">⁢</mo><mi id="S3.SS2.p2.10.m10.4.4.5.2.3.5" xref="S3.SS2.p2.10.m10.4.4.5.2.3.5.cmml">h</mi></mrow><mrow id="S3.SS2.p2.10.m10.4.4.5.3" xref="S3.SS2.p2.10.m10.4.4.5.3.cmml"><mi id="S3.SS2.p2.10.m10.4.4.5.3.2" xref="S3.SS2.p2.10.m10.4.4.5.3.2.cmml">t</mi><mo id="S3.SS2.p2.10.m10.4.4.5.3.1" xref="S3.SS2.p2.10.m10.4.4.5.3.1.cmml">⁢</mo><mi id="S3.SS2.p2.10.m10.4.4.5.3.3" xref="S3.SS2.p2.10.m10.4.4.5.3.3.cmml">r</mi><mo id="S3.SS2.p2.10.m10.4.4.5.3.1a" xref="S3.SS2.p2.10.m10.4.4.5.3.1.cmml">⁢</mo><mi id="S3.SS2.p2.10.m10.4.4.5.3.4" xref="S3.SS2.p2.10.m10.4.4.5.3.4.cmml">u</mi><mo id="S3.SS2.p2.10.m10.4.4.5.3.1b" xref="S3.SS2.p2.10.m10.4.4.5.3.1.cmml">⁢</mo><mi id="S3.SS2.p2.10.m10.4.4.5.3.5" xref="S3.SS2.p2.10.m10.4.4.5.3.5.cmml">n</mi><mo id="S3.SS2.p2.10.m10.4.4.5.3.1c" xref="S3.SS2.p2.10.m10.4.4.5.3.1.cmml">⁢</mo><mi id="S3.SS2.p2.10.m10.4.4.5.3.6" xref="S3.SS2.p2.10.m10.4.4.5.3.6.cmml">c</mi></mrow></msubsup><mo id="S3.SS2.p2.10.m10.4.4.4" xref="S3.SS2.p2.10.m10.4.4.4.cmml">=</mo><mrow id="S3.SS2.p2.10.m10.4.4.3.3" xref="S3.SS2.p2.10.m10.4.4.3.4.cmml"><mo id="S3.SS2.p2.10.m10.4.4.3.3.4" stretchy="false" xref="S3.SS2.p2.10.m10.4.4.3.4.cmml">{</mo><msub id="S3.SS2.p2.10.m10.2.2.1.1.1" xref="S3.SS2.p2.10.m10.2.2.1.1.1.cmml"><mi id="S3.SS2.p2.10.m10.2.2.1.1.1.2" xref="S3.SS2.p2.10.m10.2.2.1.1.1.2.cmml">l</mi><mn id="S3.SS2.p2.10.m10.2.2.1.1.1.3" xref="S3.SS2.p2.10.m10.2.2.1.1.1.3.cmml">0</mn></msub><mo id="S3.SS2.p2.10.m10.4.4.3.3.5" xref="S3.SS2.p2.10.m10.4.4.3.4.cmml">,</mo><msub id="S3.SS2.p2.10.m10.3.3.2.2.2" xref="S3.SS2.p2.10.m10.3.3.2.2.2.cmml"><mi id="S3.SS2.p2.10.m10.3.3.2.2.2.2" xref="S3.SS2.p2.10.m10.3.3.2.2.2.2.cmml">l</mi><mn id="S3.SS2.p2.10.m10.3.3.2.2.2.3" xref="S3.SS2.p2.10.m10.3.3.2.2.2.3.cmml">1</mn></msub><mo id="S3.SS2.p2.10.m10.4.4.3.3.6" xref="S3.SS2.p2.10.m10.4.4.3.4.cmml">,</mo><mi id="S3.SS2.p2.10.m10.1.1" mathvariant="normal" xref="S3.SS2.p2.10.m10.1.1.cmml">…</mi><mo id="S3.SS2.p2.10.m10.4.4.3.3.7" xref="S3.SS2.p2.10.m10.4.4.3.4.cmml">,</mo><msub id="S3.SS2.p2.10.m10.4.4.3.3.3" xref="S3.SS2.p2.10.m10.4.4.3.3.3.cmml"><mi id="S3.SS2.p2.10.m10.4.4.3.3.3.2" xref="S3.SS2.p2.10.m10.4.4.3.3.3.2.cmml">l</mi><mrow id="S3.SS2.p2.10.m10.4.4.3.3.3.3" xref="S3.SS2.p2.10.m10.4.4.3.3.3.3.cmml"><mi id="S3.SS2.p2.10.m10.4.4.3.3.3.3.2" xref="S3.SS2.p2.10.m10.4.4.3.3.3.3.2.cmml">d</mi><mo id="S3.SS2.p2.10.m10.4.4.3.3.3.3.1" xref="S3.SS2.p2.10.m10.4.4.3.3.3.3.1.cmml">−</mo><mi id="S3.SS2.p2.10.m10.4.4.3.3.3.3.3" xref="S3.SS2.p2.10.m10.4.4.3.3.3.3.3.cmml">m</mi></mrow></msub><mo id="S3.SS2.p2.10.m10.4.4.3.3.8" stretchy="false" xref="S3.SS2.p2.10.m10.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.10.m10.4b"><apply id="S3.SS2.p2.10.m10.4.4.cmml" xref="S3.SS2.p2.10.m10.4.4"><eq id="S3.SS2.p2.10.m10.4.4.4.cmml" xref="S3.SS2.p2.10.m10.4.4.4"></eq><apply id="S3.SS2.p2.10.m10.4.4.5.cmml" xref="S3.SS2.p2.10.m10.4.4.5"><csymbol cd="ambiguous" id="S3.SS2.p2.10.m10.4.4.5.1.cmml" xref="S3.SS2.p2.10.m10.4.4.5">superscript</csymbol><apply id="S3.SS2.p2.10.m10.4.4.5.2.cmml" xref="S3.SS2.p2.10.m10.4.4.5"><csymbol cd="ambiguous" id="S3.SS2.p2.10.m10.4.4.5.2.1.cmml" xref="S3.SS2.p2.10.m10.4.4.5">subscript</csymbol><ci id="S3.SS2.p2.10.m10.4.4.5.2.2.cmml" xref="S3.SS2.p2.10.m10.4.4.5.2.2">𝐿</ci><apply id="S3.SS2.p2.10.m10.4.4.5.2.3.cmml" xref="S3.SS2.p2.10.m10.4.4.5.2.3"><times id="S3.SS2.p2.10.m10.4.4.5.2.3.1.cmml" xref="S3.SS2.p2.10.m10.4.4.5.2.3.1"></times><ci id="S3.SS2.p2.10.m10.4.4.5.2.3.2.cmml" xref="S3.SS2.p2.10.m10.4.4.5.2.3.2">𝑝</ci><ci id="S3.SS2.p2.10.m10.4.4.5.2.3.3.cmml" xref="S3.SS2.p2.10.m10.4.4.5.2.3.3">𝑎</ci><ci id="S3.SS2.p2.10.m10.4.4.5.2.3.4.cmml" xref="S3.SS2.p2.10.m10.4.4.5.2.3.4">𝑡</ci><ci id="S3.SS2.p2.10.m10.4.4.5.2.3.5.cmml" xref="S3.SS2.p2.10.m10.4.4.5.2.3.5">ℎ</ci></apply></apply><apply id="S3.SS2.p2.10.m10.4.4.5.3.cmml" xref="S3.SS2.p2.10.m10.4.4.5.3"><times id="S3.SS2.p2.10.m10.4.4.5.3.1.cmml" xref="S3.SS2.p2.10.m10.4.4.5.3.1"></times><ci id="S3.SS2.p2.10.m10.4.4.5.3.2.cmml" xref="S3.SS2.p2.10.m10.4.4.5.3.2">𝑡</ci><ci id="S3.SS2.p2.10.m10.4.4.5.3.3.cmml" xref="S3.SS2.p2.10.m10.4.4.5.3.3">𝑟</ci><ci id="S3.SS2.p2.10.m10.4.4.5.3.4.cmml" xref="S3.SS2.p2.10.m10.4.4.5.3.4">𝑢</ci><ci id="S3.SS2.p2.10.m10.4.4.5.3.5.cmml" xref="S3.SS2.p2.10.m10.4.4.5.3.5">𝑛</ci><ci id="S3.SS2.p2.10.m10.4.4.5.3.6.cmml" xref="S3.SS2.p2.10.m10.4.4.5.3.6">𝑐</ci></apply></apply><set id="S3.SS2.p2.10.m10.4.4.3.4.cmml" xref="S3.SS2.p2.10.m10.4.4.3.3"><apply id="S3.SS2.p2.10.m10.2.2.1.1.1.cmml" xref="S3.SS2.p2.10.m10.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.10.m10.2.2.1.1.1.1.cmml" xref="S3.SS2.p2.10.m10.2.2.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.10.m10.2.2.1.1.1.2.cmml" xref="S3.SS2.p2.10.m10.2.2.1.1.1.2">𝑙</ci><cn id="S3.SS2.p2.10.m10.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS2.p2.10.m10.2.2.1.1.1.3">0</cn></apply><apply id="S3.SS2.p2.10.m10.3.3.2.2.2.cmml" xref="S3.SS2.p2.10.m10.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.10.m10.3.3.2.2.2.1.cmml" xref="S3.SS2.p2.10.m10.3.3.2.2.2">subscript</csymbol><ci id="S3.SS2.p2.10.m10.3.3.2.2.2.2.cmml" xref="S3.SS2.p2.10.m10.3.3.2.2.2.2">𝑙</ci><cn id="S3.SS2.p2.10.m10.3.3.2.2.2.3.cmml" type="integer" xref="S3.SS2.p2.10.m10.3.3.2.2.2.3">1</cn></apply><ci id="S3.SS2.p2.10.m10.1.1.cmml" xref="S3.SS2.p2.10.m10.1.1">…</ci><apply id="S3.SS2.p2.10.m10.4.4.3.3.3.cmml" xref="S3.SS2.p2.10.m10.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p2.10.m10.4.4.3.3.3.1.cmml" xref="S3.SS2.p2.10.m10.4.4.3.3.3">subscript</csymbol><ci id="S3.SS2.p2.10.m10.4.4.3.3.3.2.cmml" xref="S3.SS2.p2.10.m10.4.4.3.3.3.2">𝑙</ci><apply id="S3.SS2.p2.10.m10.4.4.3.3.3.3.cmml" xref="S3.SS2.p2.10.m10.4.4.3.3.3.3"><minus id="S3.SS2.p2.10.m10.4.4.3.3.3.3.1.cmml" xref="S3.SS2.p2.10.m10.4.4.3.3.3.3.1"></minus><ci id="S3.SS2.p2.10.m10.4.4.3.3.3.3.2.cmml" xref="S3.SS2.p2.10.m10.4.4.3.3.3.3.2">𝑑</ci><ci id="S3.SS2.p2.10.m10.4.4.3.3.3.3.3.cmml" xref="S3.SS2.p2.10.m10.4.4.3.3.3.3.3">𝑚</ci></apply></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.10.m10.4c">L_{path}^{trunc}=\{l_{0},l_{1},...,l_{d-m}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.10.m10.4d">italic_L start_POSTSUBSCRIPT italic_p italic_a italic_t italic_h end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t italic_r italic_u italic_n italic_c end_POSTSUPERSCRIPT = { italic_l start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_l start_POSTSUBSCRIPT italic_d - italic_m end_POSTSUBSCRIPT }</annotation></semantics></math>, to ensure semantically consistent grouping. The <math alttext="m" class="ltx_Math" display="inline" id="S3.SS2.p2.11.m11.1"><semantics id="S3.SS2.p2.11.m11.1a"><mi id="S3.SS2.p2.11.m11.1.1" xref="S3.SS2.p2.11.m11.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.11.m11.1b"><ci id="S3.SS2.p2.11.m11.1.1.cmml" xref="S3.SS2.p2.11.m11.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.11.m11.1c">m</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.11.m11.1d">italic_m</annotation></semantics></math> means truncation length.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Generative Retrieval Model</h3>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="247" id="S3.F3.g1" src="extracted/5804594/fig/gen2.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span>Overview of the generative model of T2VIndexer. Decoder uses different parameters when generating tokens at different positions.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">To achieve direct positioning of the target video through SemID, we chose to use a sequence-to-sequence generative model to directly generate the corresponding SemID based on the input query, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S3.F3" title="Figure 3 ‣ 3.3. Generative Retrieval Model ‣ 3. Methodology ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_tag">3</span></a>. First, the input query is added with position embedding and input into the transformer encoder to obtain the representation <math alttext="f_{t}" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><msub id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mi id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">f</mi><mi id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2">𝑓</ci><ci id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">f_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>. The probability of generating the SemID sequence as follows to construct,</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="p(L_{path}^{trunc}|f_{t})=\prod_{i=1}p(l_{i}|f_{t},l_{0},l_{1},...,l_{i-1})" class="ltx_Math" display="block" id="S3.E1.m1.3"><semantics id="S3.E1.m1.3a"><mrow id="S3.E1.m1.3.3" xref="S3.E1.m1.3.3.cmml"><mrow id="S3.E1.m1.2.2.1" xref="S3.E1.m1.2.2.1.cmml"><mi id="S3.E1.m1.2.2.1.3" xref="S3.E1.m1.2.2.1.3.cmml">p</mi><mo id="S3.E1.m1.2.2.1.2" xref="S3.E1.m1.2.2.1.2.cmml">⁢</mo><mrow id="S3.E1.m1.2.2.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.cmml"><mo id="S3.E1.m1.2.2.1.1.1.2" stretchy="false" xref="S3.E1.m1.2.2.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.2.2.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.cmml"><msubsup id="S3.E1.m1.2.2.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.2.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.2.2.2" xref="S3.E1.m1.2.2.1.1.1.1.2.2.2.cmml">L</mi><mrow id="S3.E1.m1.2.2.1.1.1.1.2.2.3" xref="S3.E1.m1.2.2.1.1.1.1.2.2.3.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.2.2.3.2" xref="S3.E1.m1.2.2.1.1.1.1.2.2.3.2.cmml">p</mi><mo id="S3.E1.m1.2.2.1.1.1.1.2.2.3.1" xref="S3.E1.m1.2.2.1.1.1.1.2.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.2.2.1.1.1.1.2.2.3.3" xref="S3.E1.m1.2.2.1.1.1.1.2.2.3.3.cmml">a</mi><mo id="S3.E1.m1.2.2.1.1.1.1.2.2.3.1a" xref="S3.E1.m1.2.2.1.1.1.1.2.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.2.2.1.1.1.1.2.2.3.4" xref="S3.E1.m1.2.2.1.1.1.1.2.2.3.4.cmml">t</mi><mo id="S3.E1.m1.2.2.1.1.1.1.2.2.3.1b" xref="S3.E1.m1.2.2.1.1.1.1.2.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.2.2.1.1.1.1.2.2.3.5" xref="S3.E1.m1.2.2.1.1.1.1.2.2.3.5.cmml">h</mi></mrow><mrow id="S3.E1.m1.2.2.1.1.1.1.2.3" xref="S3.E1.m1.2.2.1.1.1.1.2.3.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.2.3.2" xref="S3.E1.m1.2.2.1.1.1.1.2.3.2.cmml">t</mi><mo id="S3.E1.m1.2.2.1.1.1.1.2.3.1" xref="S3.E1.m1.2.2.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.2.2.1.1.1.1.2.3.3" xref="S3.E1.m1.2.2.1.1.1.1.2.3.3.cmml">r</mi><mo id="S3.E1.m1.2.2.1.1.1.1.2.3.1a" xref="S3.E1.m1.2.2.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.2.2.1.1.1.1.2.3.4" xref="S3.E1.m1.2.2.1.1.1.1.2.3.4.cmml">u</mi><mo id="S3.E1.m1.2.2.1.1.1.1.2.3.1b" xref="S3.E1.m1.2.2.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.2.2.1.1.1.1.2.3.5" xref="S3.E1.m1.2.2.1.1.1.1.2.3.5.cmml">n</mi><mo id="S3.E1.m1.2.2.1.1.1.1.2.3.1c" xref="S3.E1.m1.2.2.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.2.2.1.1.1.1.2.3.6" xref="S3.E1.m1.2.2.1.1.1.1.2.3.6.cmml">c</mi></mrow></msubsup><mo fence="false" id="S3.E1.m1.2.2.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.cmml">|</mo><msub id="S3.E1.m1.2.2.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.3.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.3.2" xref="S3.E1.m1.2.2.1.1.1.1.3.2.cmml">f</mi><mi id="S3.E1.m1.2.2.1.1.1.1.3.3" xref="S3.E1.m1.2.2.1.1.1.1.3.3.cmml">t</mi></msub></mrow><mo id="S3.E1.m1.2.2.1.1.1.3" stretchy="false" xref="S3.E1.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.3.3.3" rspace="0.111em" xref="S3.E1.m1.3.3.3.cmml">=</mo><mrow id="S3.E1.m1.3.3.2" xref="S3.E1.m1.3.3.2.cmml"><munder id="S3.E1.m1.3.3.2.2" xref="S3.E1.m1.3.3.2.2.cmml"><mo id="S3.E1.m1.3.3.2.2.2" movablelimits="false" xref="S3.E1.m1.3.3.2.2.2.cmml">∏</mo><mrow id="S3.E1.m1.3.3.2.2.3" xref="S3.E1.m1.3.3.2.2.3.cmml"><mi id="S3.E1.m1.3.3.2.2.3.2" xref="S3.E1.m1.3.3.2.2.3.2.cmml">i</mi><mo id="S3.E1.m1.3.3.2.2.3.1" xref="S3.E1.m1.3.3.2.2.3.1.cmml">=</mo><mn id="S3.E1.m1.3.3.2.2.3.3" xref="S3.E1.m1.3.3.2.2.3.3.cmml">1</mn></mrow></munder><mrow id="S3.E1.m1.3.3.2.1" xref="S3.E1.m1.3.3.2.1.cmml"><mi id="S3.E1.m1.3.3.2.1.3" xref="S3.E1.m1.3.3.2.1.3.cmml">p</mi><mo id="S3.E1.m1.3.3.2.1.2" xref="S3.E1.m1.3.3.2.1.2.cmml">⁢</mo><mrow id="S3.E1.m1.3.3.2.1.1.1" xref="S3.E1.m1.3.3.2.1.1.1.1.cmml"><mo id="S3.E1.m1.3.3.2.1.1.1.2" stretchy="false" xref="S3.E1.m1.3.3.2.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.3.3.2.1.1.1.1" xref="S3.E1.m1.3.3.2.1.1.1.1.cmml"><msub id="S3.E1.m1.3.3.2.1.1.1.1.6" xref="S3.E1.m1.3.3.2.1.1.1.1.6.cmml"><mi id="S3.E1.m1.3.3.2.1.1.1.1.6.2" xref="S3.E1.m1.3.3.2.1.1.1.1.6.2.cmml">l</mi><mi id="S3.E1.m1.3.3.2.1.1.1.1.6.3" xref="S3.E1.m1.3.3.2.1.1.1.1.6.3.cmml">i</mi></msub><mo fence="false" id="S3.E1.m1.3.3.2.1.1.1.1.5" xref="S3.E1.m1.3.3.2.1.1.1.1.5.cmml">|</mo><mrow id="S3.E1.m1.3.3.2.1.1.1.1.4.4" xref="S3.E1.m1.3.3.2.1.1.1.1.4.5.cmml"><msub id="S3.E1.m1.3.3.2.1.1.1.1.1.1.1" xref="S3.E1.m1.3.3.2.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.3.3.2.1.1.1.1.1.1.1.2" xref="S3.E1.m1.3.3.2.1.1.1.1.1.1.1.2.cmml">f</mi><mi id="S3.E1.m1.3.3.2.1.1.1.1.1.1.1.3" xref="S3.E1.m1.3.3.2.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.E1.m1.3.3.2.1.1.1.1.4.4.5" xref="S3.E1.m1.3.3.2.1.1.1.1.4.5.cmml">,</mo><msub id="S3.E1.m1.3.3.2.1.1.1.1.2.2.2" xref="S3.E1.m1.3.3.2.1.1.1.1.2.2.2.cmml"><mi id="S3.E1.m1.3.3.2.1.1.1.1.2.2.2.2" xref="S3.E1.m1.3.3.2.1.1.1.1.2.2.2.2.cmml">l</mi><mn id="S3.E1.m1.3.3.2.1.1.1.1.2.2.2.3" xref="S3.E1.m1.3.3.2.1.1.1.1.2.2.2.3.cmml">0</mn></msub><mo id="S3.E1.m1.3.3.2.1.1.1.1.4.4.6" xref="S3.E1.m1.3.3.2.1.1.1.1.4.5.cmml">,</mo><msub id="S3.E1.m1.3.3.2.1.1.1.1.3.3.3" xref="S3.E1.m1.3.3.2.1.1.1.1.3.3.3.cmml"><mi id="S3.E1.m1.3.3.2.1.1.1.1.3.3.3.2" xref="S3.E1.m1.3.3.2.1.1.1.1.3.3.3.2.cmml">l</mi><mn id="S3.E1.m1.3.3.2.1.1.1.1.3.3.3.3" xref="S3.E1.m1.3.3.2.1.1.1.1.3.3.3.3.cmml">1</mn></msub><mo id="S3.E1.m1.3.3.2.1.1.1.1.4.4.7" xref="S3.E1.m1.3.3.2.1.1.1.1.4.5.cmml">,</mo><mi id="S3.E1.m1.1.1" mathvariant="normal" xref="S3.E1.m1.1.1.cmml">…</mi><mo id="S3.E1.m1.3.3.2.1.1.1.1.4.4.8" xref="S3.E1.m1.3.3.2.1.1.1.1.4.5.cmml">,</mo><msub id="S3.E1.m1.3.3.2.1.1.1.1.4.4.4" xref="S3.E1.m1.3.3.2.1.1.1.1.4.4.4.cmml"><mi id="S3.E1.m1.3.3.2.1.1.1.1.4.4.4.2" xref="S3.E1.m1.3.3.2.1.1.1.1.4.4.4.2.cmml">l</mi><mrow id="S3.E1.m1.3.3.2.1.1.1.1.4.4.4.3" xref="S3.E1.m1.3.3.2.1.1.1.1.4.4.4.3.cmml"><mi id="S3.E1.m1.3.3.2.1.1.1.1.4.4.4.3.2" xref="S3.E1.m1.3.3.2.1.1.1.1.4.4.4.3.2.cmml">i</mi><mo id="S3.E1.m1.3.3.2.1.1.1.1.4.4.4.3.1" xref="S3.E1.m1.3.3.2.1.1.1.1.4.4.4.3.1.cmml">−</mo><mn id="S3.E1.m1.3.3.2.1.1.1.1.4.4.4.3.3" xref="S3.E1.m1.3.3.2.1.1.1.1.4.4.4.3.3.cmml">1</mn></mrow></msub></mrow></mrow><mo id="S3.E1.m1.3.3.2.1.1.1.3" stretchy="false" xref="S3.E1.m1.3.3.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.3b"><apply id="S3.E1.m1.3.3.cmml" xref="S3.E1.m1.3.3"><eq id="S3.E1.m1.3.3.3.cmml" xref="S3.E1.m1.3.3.3"></eq><apply id="S3.E1.m1.2.2.1.cmml" xref="S3.E1.m1.2.2.1"><times id="S3.E1.m1.2.2.1.2.cmml" xref="S3.E1.m1.2.2.1.2"></times><ci id="S3.E1.m1.2.2.1.3.cmml" xref="S3.E1.m1.2.2.1.3">𝑝</ci><apply id="S3.E1.m1.2.2.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.2.2.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1">conditional</csymbol><apply id="S3.E1.m1.2.2.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.2.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2">superscript</csymbol><apply id="S3.E1.m1.2.2.1.1.1.1.2.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.2.2.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.1.1.2.2.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2.2.2">𝐿</ci><apply id="S3.E1.m1.2.2.1.1.1.1.2.2.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2.2.3"><times id="S3.E1.m1.2.2.1.1.1.1.2.2.3.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2.2.3.1"></times><ci id="S3.E1.m1.2.2.1.1.1.1.2.2.3.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2.2.3.2">𝑝</ci><ci id="S3.E1.m1.2.2.1.1.1.1.2.2.3.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2.2.3.3">𝑎</ci><ci id="S3.E1.m1.2.2.1.1.1.1.2.2.3.4.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2.2.3.4">𝑡</ci><ci id="S3.E1.m1.2.2.1.1.1.1.2.2.3.5.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2.2.3.5">ℎ</ci></apply></apply><apply id="S3.E1.m1.2.2.1.1.1.1.2.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2.3"><times id="S3.E1.m1.2.2.1.1.1.1.2.3.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2.3.1"></times><ci id="S3.E1.m1.2.2.1.1.1.1.2.3.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2.3.2">𝑡</ci><ci id="S3.E1.m1.2.2.1.1.1.1.2.3.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2.3.3">𝑟</ci><ci id="S3.E1.m1.2.2.1.1.1.1.2.3.4.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2.3.4">𝑢</ci><ci id="S3.E1.m1.2.2.1.1.1.1.2.3.5.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2.3.5">𝑛</ci><ci id="S3.E1.m1.2.2.1.1.1.1.2.3.6.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2.3.6">𝑐</ci></apply></apply><apply id="S3.E1.m1.2.2.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.3.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.1.1.3.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.3.2">𝑓</ci><ci id="S3.E1.m1.2.2.1.1.1.1.3.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.3.3">𝑡</ci></apply></apply></apply><apply id="S3.E1.m1.3.3.2.cmml" xref="S3.E1.m1.3.3.2"><apply id="S3.E1.m1.3.3.2.2.cmml" xref="S3.E1.m1.3.3.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.2.2.1.cmml" xref="S3.E1.m1.3.3.2.2">subscript</csymbol><csymbol cd="latexml" id="S3.E1.m1.3.3.2.2.2.cmml" xref="S3.E1.m1.3.3.2.2.2">product</csymbol><apply id="S3.E1.m1.3.3.2.2.3.cmml" xref="S3.E1.m1.3.3.2.2.3"><eq id="S3.E1.m1.3.3.2.2.3.1.cmml" xref="S3.E1.m1.3.3.2.2.3.1"></eq><ci id="S3.E1.m1.3.3.2.2.3.2.cmml" xref="S3.E1.m1.3.3.2.2.3.2">𝑖</ci><cn id="S3.E1.m1.3.3.2.2.3.3.cmml" type="integer" xref="S3.E1.m1.3.3.2.2.3.3">1</cn></apply></apply><apply id="S3.E1.m1.3.3.2.1.cmml" xref="S3.E1.m1.3.3.2.1"><times id="S3.E1.m1.3.3.2.1.2.cmml" xref="S3.E1.m1.3.3.2.1.2"></times><ci id="S3.E1.m1.3.3.2.1.3.cmml" xref="S3.E1.m1.3.3.2.1.3">𝑝</ci><apply id="S3.E1.m1.3.3.2.1.1.1.1.cmml" xref="S3.E1.m1.3.3.2.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.3.3.2.1.1.1.1.5.cmml" xref="S3.E1.m1.3.3.2.1.1.1.1.5">conditional</csymbol><apply id="S3.E1.m1.3.3.2.1.1.1.1.6.cmml" xref="S3.E1.m1.3.3.2.1.1.1.1.6"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.2.1.1.1.1.6.1.cmml" xref="S3.E1.m1.3.3.2.1.1.1.1.6">subscript</csymbol><ci id="S3.E1.m1.3.3.2.1.1.1.1.6.2.cmml" xref="S3.E1.m1.3.3.2.1.1.1.1.6.2">𝑙</ci><ci id="S3.E1.m1.3.3.2.1.1.1.1.6.3.cmml" xref="S3.E1.m1.3.3.2.1.1.1.1.6.3">𝑖</ci></apply><list id="S3.E1.m1.3.3.2.1.1.1.1.4.5.cmml" xref="S3.E1.m1.3.3.2.1.1.1.1.4.4"><apply id="S3.E1.m1.3.3.2.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.3.3.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.2.1.1.1.1.1.1.1.2">𝑓</ci><ci id="S3.E1.m1.3.3.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.3.3.2.1.1.1.1.1.1.1.3">𝑡</ci></apply><apply id="S3.E1.m1.3.3.2.1.1.1.1.2.2.2.cmml" xref="S3.E1.m1.3.3.2.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.2.1.1.1.1.2.2.2.1.cmml" xref="S3.E1.m1.3.3.2.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.E1.m1.3.3.2.1.1.1.1.2.2.2.2.cmml" xref="S3.E1.m1.3.3.2.1.1.1.1.2.2.2.2">𝑙</ci><cn id="S3.E1.m1.3.3.2.1.1.1.1.2.2.2.3.cmml" type="integer" xref="S3.E1.m1.3.3.2.1.1.1.1.2.2.2.3">0</cn></apply><apply id="S3.E1.m1.3.3.2.1.1.1.1.3.3.3.cmml" xref="S3.E1.m1.3.3.2.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.2.1.1.1.1.3.3.3.1.cmml" xref="S3.E1.m1.3.3.2.1.1.1.1.3.3.3">subscript</csymbol><ci id="S3.E1.m1.3.3.2.1.1.1.1.3.3.3.2.cmml" xref="S3.E1.m1.3.3.2.1.1.1.1.3.3.3.2">𝑙</ci><cn id="S3.E1.m1.3.3.2.1.1.1.1.3.3.3.3.cmml" type="integer" xref="S3.E1.m1.3.3.2.1.1.1.1.3.3.3.3">1</cn></apply><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">…</ci><apply id="S3.E1.m1.3.3.2.1.1.1.1.4.4.4.cmml" xref="S3.E1.m1.3.3.2.1.1.1.1.4.4.4"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.2.1.1.1.1.4.4.4.1.cmml" xref="S3.E1.m1.3.3.2.1.1.1.1.4.4.4">subscript</csymbol><ci id="S3.E1.m1.3.3.2.1.1.1.1.4.4.4.2.cmml" xref="S3.E1.m1.3.3.2.1.1.1.1.4.4.4.2">𝑙</ci><apply id="S3.E1.m1.3.3.2.1.1.1.1.4.4.4.3.cmml" xref="S3.E1.m1.3.3.2.1.1.1.1.4.4.4.3"><minus id="S3.E1.m1.3.3.2.1.1.1.1.4.4.4.3.1.cmml" xref="S3.E1.m1.3.3.2.1.1.1.1.4.4.4.3.1"></minus><ci id="S3.E1.m1.3.3.2.1.1.1.1.4.4.4.3.2.cmml" xref="S3.E1.m1.3.3.2.1.1.1.1.4.4.4.3.2">𝑖</ci><cn id="S3.E1.m1.3.3.2.1.1.1.1.4.4.4.3.3.cmml" type="integer" xref="S3.E1.m1.3.3.2.1.1.1.1.4.4.4.3.3">1</cn></apply></apply></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.3c">p(L_{path}^{trunc}|f_{t})=\prod_{i=1}p(l_{i}|f_{t},l_{0},l_{1},...,l_{i-1})</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.3d">italic_p ( italic_L start_POSTSUBSCRIPT italic_p italic_a italic_t italic_h end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t italic_r italic_u italic_n italic_c end_POSTSUPERSCRIPT | italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) = ∏ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT italic_p ( italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_f start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_l start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_l start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.p1.2">which means the next token is generated according to the sequence of previously generated tokens. This probability problem can be solved by the traditional transformer encoder-decoder structure. The input of the encoder and the output of the decoder can be regarded as two different semantic spaces, corresponding to the natural language space and the video semantic tree space.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.6">However, unlike standard decoding tasks, the same token appearing at different positions in the Vi-SemTree space has different meanings because they are in different layers of the Vi-SemTree. For example, as shown in the framework Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S2.F2" title="Figure 2 ‣ 2. Related Work ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_tag">2</span></a>, for SemID ‘<math alttext="0_{0}-0_{1}-0_{2}" class="ltx_Math" display="inline" id="S3.SS3.p2.1.m1.1"><semantics id="S3.SS3.p2.1.m1.1a"><mrow id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml"><msub id="S3.SS3.p2.1.m1.1.1.2" xref="S3.SS3.p2.1.m1.1.1.2.cmml"><mn id="S3.SS3.p2.1.m1.1.1.2.2" xref="S3.SS3.p2.1.m1.1.1.2.2.cmml">0</mn><mn id="S3.SS3.p2.1.m1.1.1.2.3" xref="S3.SS3.p2.1.m1.1.1.2.3.cmml">0</mn></msub><mo id="S3.SS3.p2.1.m1.1.1.1" xref="S3.SS3.p2.1.m1.1.1.1.cmml">−</mo><msub id="S3.SS3.p2.1.m1.1.1.3" xref="S3.SS3.p2.1.m1.1.1.3.cmml"><mn id="S3.SS3.p2.1.m1.1.1.3.2" xref="S3.SS3.p2.1.m1.1.1.3.2.cmml">0</mn><mn id="S3.SS3.p2.1.m1.1.1.3.3" xref="S3.SS3.p2.1.m1.1.1.3.3.cmml">1</mn></msub><mo id="S3.SS3.p2.1.m1.1.1.1a" xref="S3.SS3.p2.1.m1.1.1.1.cmml">−</mo><msub id="S3.SS3.p2.1.m1.1.1.4" xref="S3.SS3.p2.1.m1.1.1.4.cmml"><mn id="S3.SS3.p2.1.m1.1.1.4.2" xref="S3.SS3.p2.1.m1.1.1.4.2.cmml">0</mn><mn id="S3.SS3.p2.1.m1.1.1.4.3" xref="S3.SS3.p2.1.m1.1.1.4.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><apply id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1"><minus id="S3.SS3.p2.1.m1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1.1"></minus><apply id="S3.SS3.p2.1.m1.1.1.2.cmml" xref="S3.SS3.p2.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.2.1.cmml" xref="S3.SS3.p2.1.m1.1.1.2">subscript</csymbol><cn id="S3.SS3.p2.1.m1.1.1.2.2.cmml" type="integer" xref="S3.SS3.p2.1.m1.1.1.2.2">0</cn><cn id="S3.SS3.p2.1.m1.1.1.2.3.cmml" type="integer" xref="S3.SS3.p2.1.m1.1.1.2.3">0</cn></apply><apply id="S3.SS3.p2.1.m1.1.1.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.3.1.cmml" xref="S3.SS3.p2.1.m1.1.1.3">subscript</csymbol><cn id="S3.SS3.p2.1.m1.1.1.3.2.cmml" type="integer" xref="S3.SS3.p2.1.m1.1.1.3.2">0</cn><cn id="S3.SS3.p2.1.m1.1.1.3.3.cmml" type="integer" xref="S3.SS3.p2.1.m1.1.1.3.3">1</cn></apply><apply id="S3.SS3.p2.1.m1.1.1.4.cmml" xref="S3.SS3.p2.1.m1.1.1.4"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.4.1.cmml" xref="S3.SS3.p2.1.m1.1.1.4">subscript</csymbol><cn id="S3.SS3.p2.1.m1.1.1.4.2.cmml" type="integer" xref="S3.SS3.p2.1.m1.1.1.4.2">0</cn><cn id="S3.SS3.p2.1.m1.1.1.4.3.cmml" type="integer" xref="S3.SS3.p2.1.m1.1.1.4.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">0_{0}-0_{1}-0_{2}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.1.m1.1d">0 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT - 0 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - 0 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math>’, the token ‘<math alttext="0_{1}" class="ltx_Math" display="inline" id="S3.SS3.p2.2.m2.1"><semantics id="S3.SS3.p2.2.m2.1a"><msub id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml"><mn id="S3.SS3.p2.2.m2.1.1.2" xref="S3.SS3.p2.2.m2.1.1.2.cmml">0</mn><mn id="S3.SS3.p2.2.m2.1.1.3" xref="S3.SS3.p2.2.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><apply id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.2.m2.1.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1">subscript</csymbol><cn id="S3.SS3.p2.2.m2.1.1.2.cmml" type="integer" xref="S3.SS3.p2.2.m2.1.1.2">0</cn><cn id="S3.SS3.p2.2.m2.1.1.3.cmml" type="integer" xref="S3.SS3.p2.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">0_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.2.m2.1d">0 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>’ in the first layer represents the semantic of the “sports”, while ‘<math alttext="0_{2}" class="ltx_Math" display="inline" id="S3.SS3.p2.3.m3.1"><semantics id="S3.SS3.p2.3.m3.1a"><msub id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml"><mn id="S3.SS3.p2.3.m3.1.1.2" xref="S3.SS3.p2.3.m3.1.1.2.cmml">0</mn><mn id="S3.SS3.p2.3.m3.1.1.3" xref="S3.SS3.p2.3.m3.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><apply id="S3.SS3.p2.3.m3.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.3.m3.1.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1">subscript</csymbol><cn id="S3.SS3.p2.3.m3.1.1.2.cmml" type="integer" xref="S3.SS3.p2.3.m3.1.1.2">0</cn><cn id="S3.SS3.p2.3.m3.1.1.3.cmml" type="integer" xref="S3.SS3.p2.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">0_{2}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.3.m3.1d">0 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math>’ in the second layer only represents “basketball”. In addition, even if they are in the same layer, the same token ‘<math alttext="0_{2}" class="ltx_Math" display="inline" id="S3.SS3.p2.4.m4.1"><semantics id="S3.SS3.p2.4.m4.1a"><msub id="S3.SS3.p2.4.m4.1.1" xref="S3.SS3.p2.4.m4.1.1.cmml"><mn id="S3.SS3.p2.4.m4.1.1.2" xref="S3.SS3.p2.4.m4.1.1.2.cmml">0</mn><mn id="S3.SS3.p2.4.m4.1.1.3" xref="S3.SS3.p2.4.m4.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m4.1b"><apply id="S3.SS3.p2.4.m4.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.4.m4.1.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1">subscript</csymbol><cn id="S3.SS3.p2.4.m4.1.1.2.cmml" type="integer" xref="S3.SS3.p2.4.m4.1.1.2">0</cn><cn id="S3.SS3.p2.4.m4.1.1.3.cmml" type="integer" xref="S3.SS3.p2.4.m4.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m4.1c">0_{2}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.4.m4.1d">0 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math>’ in SemID ‘<math alttext="0_{0}-0_{1}-0_{2}" class="ltx_Math" display="inline" id="S3.SS3.p2.5.m5.1"><semantics id="S3.SS3.p2.5.m5.1a"><mrow id="S3.SS3.p2.5.m5.1.1" xref="S3.SS3.p2.5.m5.1.1.cmml"><msub id="S3.SS3.p2.5.m5.1.1.2" xref="S3.SS3.p2.5.m5.1.1.2.cmml"><mn id="S3.SS3.p2.5.m5.1.1.2.2" xref="S3.SS3.p2.5.m5.1.1.2.2.cmml">0</mn><mn id="S3.SS3.p2.5.m5.1.1.2.3" xref="S3.SS3.p2.5.m5.1.1.2.3.cmml">0</mn></msub><mo id="S3.SS3.p2.5.m5.1.1.1" xref="S3.SS3.p2.5.m5.1.1.1.cmml">−</mo><msub id="S3.SS3.p2.5.m5.1.1.3" xref="S3.SS3.p2.5.m5.1.1.3.cmml"><mn id="S3.SS3.p2.5.m5.1.1.3.2" xref="S3.SS3.p2.5.m5.1.1.3.2.cmml">0</mn><mn id="S3.SS3.p2.5.m5.1.1.3.3" xref="S3.SS3.p2.5.m5.1.1.3.3.cmml">1</mn></msub><mo id="S3.SS3.p2.5.m5.1.1.1a" xref="S3.SS3.p2.5.m5.1.1.1.cmml">−</mo><msub id="S3.SS3.p2.5.m5.1.1.4" xref="S3.SS3.p2.5.m5.1.1.4.cmml"><mn id="S3.SS3.p2.5.m5.1.1.4.2" xref="S3.SS3.p2.5.m5.1.1.4.2.cmml">0</mn><mn id="S3.SS3.p2.5.m5.1.1.4.3" xref="S3.SS3.p2.5.m5.1.1.4.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.5.m5.1b"><apply id="S3.SS3.p2.5.m5.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1"><minus id="S3.SS3.p2.5.m5.1.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1.1"></minus><apply id="S3.SS3.p2.5.m5.1.1.2.cmml" xref="S3.SS3.p2.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p2.5.m5.1.1.2.1.cmml" xref="S3.SS3.p2.5.m5.1.1.2">subscript</csymbol><cn id="S3.SS3.p2.5.m5.1.1.2.2.cmml" type="integer" xref="S3.SS3.p2.5.m5.1.1.2.2">0</cn><cn id="S3.SS3.p2.5.m5.1.1.2.3.cmml" type="integer" xref="S3.SS3.p2.5.m5.1.1.2.3">0</cn></apply><apply id="S3.SS3.p2.5.m5.1.1.3.cmml" xref="S3.SS3.p2.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p2.5.m5.1.1.3.1.cmml" xref="S3.SS3.p2.5.m5.1.1.3">subscript</csymbol><cn id="S3.SS3.p2.5.m5.1.1.3.2.cmml" type="integer" xref="S3.SS3.p2.5.m5.1.1.3.2">0</cn><cn id="S3.SS3.p2.5.m5.1.1.3.3.cmml" type="integer" xref="S3.SS3.p2.5.m5.1.1.3.3">1</cn></apply><apply id="S3.SS3.p2.5.m5.1.1.4.cmml" xref="S3.SS3.p2.5.m5.1.1.4"><csymbol cd="ambiguous" id="S3.SS3.p2.5.m5.1.1.4.1.cmml" xref="S3.SS3.p2.5.m5.1.1.4">subscript</csymbol><cn id="S3.SS3.p2.5.m5.1.1.4.2.cmml" type="integer" xref="S3.SS3.p2.5.m5.1.1.4.2">0</cn><cn id="S3.SS3.p2.5.m5.1.1.4.3.cmml" type="integer" xref="S3.SS3.p2.5.m5.1.1.4.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.5.m5.1c">0_{0}-0_{1}-0_{2}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.5.m5.1d">0 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT - 0 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - 0 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math>’ and ‘<math alttext="0_{0}-2_{1}-0_{2}" class="ltx_Math" display="inline" id="S3.SS3.p2.6.m6.1"><semantics id="S3.SS3.p2.6.m6.1a"><mrow id="S3.SS3.p2.6.m6.1.1" xref="S3.SS3.p2.6.m6.1.1.cmml"><msub id="S3.SS3.p2.6.m6.1.1.2" xref="S3.SS3.p2.6.m6.1.1.2.cmml"><mn id="S3.SS3.p2.6.m6.1.1.2.2" xref="S3.SS3.p2.6.m6.1.1.2.2.cmml">0</mn><mn id="S3.SS3.p2.6.m6.1.1.2.3" xref="S3.SS3.p2.6.m6.1.1.2.3.cmml">0</mn></msub><mo id="S3.SS3.p2.6.m6.1.1.1" xref="S3.SS3.p2.6.m6.1.1.1.cmml">−</mo><msub id="S3.SS3.p2.6.m6.1.1.3" xref="S3.SS3.p2.6.m6.1.1.3.cmml"><mn id="S3.SS3.p2.6.m6.1.1.3.2" xref="S3.SS3.p2.6.m6.1.1.3.2.cmml">2</mn><mn id="S3.SS3.p2.6.m6.1.1.3.3" xref="S3.SS3.p2.6.m6.1.1.3.3.cmml">1</mn></msub><mo id="S3.SS3.p2.6.m6.1.1.1a" xref="S3.SS3.p2.6.m6.1.1.1.cmml">−</mo><msub id="S3.SS3.p2.6.m6.1.1.4" xref="S3.SS3.p2.6.m6.1.1.4.cmml"><mn id="S3.SS3.p2.6.m6.1.1.4.2" xref="S3.SS3.p2.6.m6.1.1.4.2.cmml">0</mn><mn id="S3.SS3.p2.6.m6.1.1.4.3" xref="S3.SS3.p2.6.m6.1.1.4.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.6.m6.1b"><apply id="S3.SS3.p2.6.m6.1.1.cmml" xref="S3.SS3.p2.6.m6.1.1"><minus id="S3.SS3.p2.6.m6.1.1.1.cmml" xref="S3.SS3.p2.6.m6.1.1.1"></minus><apply id="S3.SS3.p2.6.m6.1.1.2.cmml" xref="S3.SS3.p2.6.m6.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p2.6.m6.1.1.2.1.cmml" xref="S3.SS3.p2.6.m6.1.1.2">subscript</csymbol><cn id="S3.SS3.p2.6.m6.1.1.2.2.cmml" type="integer" xref="S3.SS3.p2.6.m6.1.1.2.2">0</cn><cn id="S3.SS3.p2.6.m6.1.1.2.3.cmml" type="integer" xref="S3.SS3.p2.6.m6.1.1.2.3">0</cn></apply><apply id="S3.SS3.p2.6.m6.1.1.3.cmml" xref="S3.SS3.p2.6.m6.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p2.6.m6.1.1.3.1.cmml" xref="S3.SS3.p2.6.m6.1.1.3">subscript</csymbol><cn id="S3.SS3.p2.6.m6.1.1.3.2.cmml" type="integer" xref="S3.SS3.p2.6.m6.1.1.3.2">2</cn><cn id="S3.SS3.p2.6.m6.1.1.3.3.cmml" type="integer" xref="S3.SS3.p2.6.m6.1.1.3.3">1</cn></apply><apply id="S3.SS3.p2.6.m6.1.1.4.cmml" xref="S3.SS3.p2.6.m6.1.1.4"><csymbol cd="ambiguous" id="S3.SS3.p2.6.m6.1.1.4.1.cmml" xref="S3.SS3.p2.6.m6.1.1.4">subscript</csymbol><cn id="S3.SS3.p2.6.m6.1.1.4.2.cmml" type="integer" xref="S3.SS3.p2.6.m6.1.1.4.2">0</cn><cn id="S3.SS3.p2.6.m6.1.1.4.3.cmml" type="integer" xref="S3.SS3.p2.6.m6.1.1.4.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.6.m6.1c">0_{0}-2_{1}-0_{2}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.6.m6.1d">0 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT - 2 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - 0 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math>’ expresses different concept due to their different prefixes. To identify different representations at different positions during decoding, we were inspired by NCI <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib22" title="">2022</a>)</cite> in document retrieval and used the Prefix-Aware Weight-Adaptor (PAWA) decoder, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S3.F3" title="Figure 3 ‣ 3.3. Generative Retrieval Model ‣ 3. Methodology ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.2">Unlike the standard transformer decoder, the PAWA decoder uses different parameters when generating tokens at different positions, and the parameters between different steps are not shared. The specific settings are as follows. First, the encoder encodes the query to obtain the encoding <math alttext="x" class="ltx_Math" display="inline" id="S3.SS3.p3.1.m1.1"><semantics id="S3.SS3.p3.1.m1.1a"><mi id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><ci id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.1.m1.1d">italic_x</annotation></semantics></math>, and decoder output <math alttext="E" class="ltx_Math" display="inline" id="S3.SS3.p3.2.m2.1"><semantics id="S3.SS3.p3.2.m2.1a"><mi id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b"><ci id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">E</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.2.m2.1d">italic_E</annotation></semantics></math> as follows,</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(2)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="E_{i}=\text{Decoder}(x,l_{0},l_{1},...,l_{i-1};\theta_{i})" class="ltx_Math" display="block" id="S3.E2.m1.6"><semantics id="S3.E2.m1.6a"><mrow id="S3.E2.m1.6.6" xref="S3.E2.m1.6.6.cmml"><msub id="S3.E2.m1.6.6.6" xref="S3.E2.m1.6.6.6.cmml"><mi id="S3.E2.m1.6.6.6.2" xref="S3.E2.m1.6.6.6.2.cmml">E</mi><mi id="S3.E2.m1.6.6.6.3" xref="S3.E2.m1.6.6.6.3.cmml">i</mi></msub><mo id="S3.E2.m1.6.6.5" xref="S3.E2.m1.6.6.5.cmml">=</mo><mrow id="S3.E2.m1.6.6.4" xref="S3.E2.m1.6.6.4.cmml"><mtext id="S3.E2.m1.6.6.4.6" xref="S3.E2.m1.6.6.4.6a.cmml">Decoder</mtext><mo id="S3.E2.m1.6.6.4.5" xref="S3.E2.m1.6.6.4.5.cmml">⁢</mo><mrow id="S3.E2.m1.6.6.4.4.4" xref="S3.E2.m1.6.6.4.4.5.cmml"><mo id="S3.E2.m1.6.6.4.4.4.5" stretchy="false" xref="S3.E2.m1.6.6.4.4.5.cmml">(</mo><mi id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">x</mi><mo id="S3.E2.m1.6.6.4.4.4.6" xref="S3.E2.m1.6.6.4.4.5.cmml">,</mo><msub id="S3.E2.m1.3.3.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.cmml"><mi id="S3.E2.m1.3.3.1.1.1.1.2" xref="S3.E2.m1.3.3.1.1.1.1.2.cmml">l</mi><mn id="S3.E2.m1.3.3.1.1.1.1.3" xref="S3.E2.m1.3.3.1.1.1.1.3.cmml">0</mn></msub><mo id="S3.E2.m1.6.6.4.4.4.7" xref="S3.E2.m1.6.6.4.4.5.cmml">,</mo><msub id="S3.E2.m1.4.4.2.2.2.2" xref="S3.E2.m1.4.4.2.2.2.2.cmml"><mi id="S3.E2.m1.4.4.2.2.2.2.2" xref="S3.E2.m1.4.4.2.2.2.2.2.cmml">l</mi><mn id="S3.E2.m1.4.4.2.2.2.2.3" xref="S3.E2.m1.4.4.2.2.2.2.3.cmml">1</mn></msub><mo id="S3.E2.m1.6.6.4.4.4.8" xref="S3.E2.m1.6.6.4.4.5.cmml">,</mo><mi id="S3.E2.m1.2.2" mathvariant="normal" xref="S3.E2.m1.2.2.cmml">…</mi><mo id="S3.E2.m1.6.6.4.4.4.9" xref="S3.E2.m1.6.6.4.4.5.cmml">,</mo><msub id="S3.E2.m1.5.5.3.3.3.3" xref="S3.E2.m1.5.5.3.3.3.3.cmml"><mi id="S3.E2.m1.5.5.3.3.3.3.2" xref="S3.E2.m1.5.5.3.3.3.3.2.cmml">l</mi><mrow id="S3.E2.m1.5.5.3.3.3.3.3" xref="S3.E2.m1.5.5.3.3.3.3.3.cmml"><mi id="S3.E2.m1.5.5.3.3.3.3.3.2" xref="S3.E2.m1.5.5.3.3.3.3.3.2.cmml">i</mi><mo id="S3.E2.m1.5.5.3.3.3.3.3.1" xref="S3.E2.m1.5.5.3.3.3.3.3.1.cmml">−</mo><mn id="S3.E2.m1.5.5.3.3.3.3.3.3" xref="S3.E2.m1.5.5.3.3.3.3.3.3.cmml">1</mn></mrow></msub><mo id="S3.E2.m1.6.6.4.4.4.10" xref="S3.E2.m1.6.6.4.4.5.cmml">;</mo><msub id="S3.E2.m1.6.6.4.4.4.4" xref="S3.E2.m1.6.6.4.4.4.4.cmml"><mi id="S3.E2.m1.6.6.4.4.4.4.2" xref="S3.E2.m1.6.6.4.4.4.4.2.cmml">θ</mi><mi id="S3.E2.m1.6.6.4.4.4.4.3" xref="S3.E2.m1.6.6.4.4.4.4.3.cmml">i</mi></msub><mo id="S3.E2.m1.6.6.4.4.4.11" stretchy="false" xref="S3.E2.m1.6.6.4.4.5.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.6b"><apply id="S3.E2.m1.6.6.cmml" xref="S3.E2.m1.6.6"><eq id="S3.E2.m1.6.6.5.cmml" xref="S3.E2.m1.6.6.5"></eq><apply id="S3.E2.m1.6.6.6.cmml" xref="S3.E2.m1.6.6.6"><csymbol cd="ambiguous" id="S3.E2.m1.6.6.6.1.cmml" xref="S3.E2.m1.6.6.6">subscript</csymbol><ci id="S3.E2.m1.6.6.6.2.cmml" xref="S3.E2.m1.6.6.6.2">𝐸</ci><ci id="S3.E2.m1.6.6.6.3.cmml" xref="S3.E2.m1.6.6.6.3">𝑖</ci></apply><apply id="S3.E2.m1.6.6.4.cmml" xref="S3.E2.m1.6.6.4"><times id="S3.E2.m1.6.6.4.5.cmml" xref="S3.E2.m1.6.6.4.5"></times><ci id="S3.E2.m1.6.6.4.6a.cmml" xref="S3.E2.m1.6.6.4.6"><mtext id="S3.E2.m1.6.6.4.6.cmml" xref="S3.E2.m1.6.6.4.6">Decoder</mtext></ci><vector id="S3.E2.m1.6.6.4.4.5.cmml" xref="S3.E2.m1.6.6.4.4.4"><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">𝑥</ci><apply id="S3.E2.m1.3.3.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.2">𝑙</ci><cn id="S3.E2.m1.3.3.1.1.1.1.3.cmml" type="integer" xref="S3.E2.m1.3.3.1.1.1.1.3">0</cn></apply><apply id="S3.E2.m1.4.4.2.2.2.2.cmml" xref="S3.E2.m1.4.4.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.2.2.2.2.1.cmml" xref="S3.E2.m1.4.4.2.2.2.2">subscript</csymbol><ci id="S3.E2.m1.4.4.2.2.2.2.2.cmml" xref="S3.E2.m1.4.4.2.2.2.2.2">𝑙</ci><cn id="S3.E2.m1.4.4.2.2.2.2.3.cmml" type="integer" xref="S3.E2.m1.4.4.2.2.2.2.3">1</cn></apply><ci id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2">…</ci><apply id="S3.E2.m1.5.5.3.3.3.3.cmml" xref="S3.E2.m1.5.5.3.3.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.5.5.3.3.3.3.1.cmml" xref="S3.E2.m1.5.5.3.3.3.3">subscript</csymbol><ci id="S3.E2.m1.5.5.3.3.3.3.2.cmml" xref="S3.E2.m1.5.5.3.3.3.3.2">𝑙</ci><apply id="S3.E2.m1.5.5.3.3.3.3.3.cmml" xref="S3.E2.m1.5.5.3.3.3.3.3"><minus id="S3.E2.m1.5.5.3.3.3.3.3.1.cmml" xref="S3.E2.m1.5.5.3.3.3.3.3.1"></minus><ci id="S3.E2.m1.5.5.3.3.3.3.3.2.cmml" xref="S3.E2.m1.5.5.3.3.3.3.3.2">𝑖</ci><cn id="S3.E2.m1.5.5.3.3.3.3.3.3.cmml" type="integer" xref="S3.E2.m1.5.5.3.3.3.3.3.3">1</cn></apply></apply><apply id="S3.E2.m1.6.6.4.4.4.4.cmml" xref="S3.E2.m1.6.6.4.4.4.4"><csymbol cd="ambiguous" id="S3.E2.m1.6.6.4.4.4.4.1.cmml" xref="S3.E2.m1.6.6.4.4.4.4">subscript</csymbol><ci id="S3.E2.m1.6.6.4.4.4.4.2.cmml" xref="S3.E2.m1.6.6.4.4.4.4.2">𝜃</ci><ci id="S3.E2.m1.6.6.4.4.4.4.3.cmml" xref="S3.E2.m1.6.6.4.4.4.4.3">𝑖</ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.6c">E_{i}=\text{Decoder}(x,l_{0},l_{1},...,l_{i-1};\theta_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.6d">italic_E start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = Decoder ( italic_x , italic_l start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_l start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT ; italic_θ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p4">
<p class="ltx_p" id="S3.SS3.p4.2">where <math alttext="\theta_{i}" class="ltx_Math" display="inline" id="S3.SS3.p4.1.m1.1"><semantics id="S3.SS3.p4.1.m1.1a"><msub id="S3.SS3.p4.1.m1.1.1" xref="S3.SS3.p4.1.m1.1.1.cmml"><mi id="S3.SS3.p4.1.m1.1.1.2" xref="S3.SS3.p4.1.m1.1.1.2.cmml">θ</mi><mi id="S3.SS3.p4.1.m1.1.1.3" xref="S3.SS3.p4.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.1b"><apply id="S3.SS3.p4.1.m1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p4.1.m1.1.1.2.cmml" xref="S3.SS3.p4.1.m1.1.1.2">𝜃</ci><ci id="S3.SS3.p4.1.m1.1.1.3.cmml" xref="S3.SS3.p4.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.1c">\theta_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.1.m1.1d">italic_θ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> represents the parameters of each decoding step, and the parameters of each step are different, distinguishing the semantic of different position tokens. In addition, to further enhance the prefix information as the basis for generation, the PAWA decoder further modifies the linear classification layers based on the prefix sequence. Specifically, instead of using the same projection weight <math alttext="W" class="ltx_Math" display="inline" id="S3.SS3.p4.2.m2.1"><semantics id="S3.SS3.p4.2.m2.1a"><mi id="S3.SS3.p4.2.m2.1.1" xref="S3.SS3.p4.2.m2.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.2.m2.1b"><ci id="S3.SS3.p4.2.m2.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1">𝑊</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.2.m2.1c">W</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.2.m2.1d">italic_W</annotation></semantics></math> in the linear classification layer, the PAWA decoder uses an additional decoder to generate different weights for each position,</p>
</div>
<div class="ltx_para" id="S3.SS3.p5">
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(3)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="E_{i}^{\prime}=\text{Decoder'}(l_{0},l_{1},...,l_{i-1};\theta_{i}^{\prime})" class="ltx_Math" display="block" id="S3.E3.m1.5"><semantics id="S3.E3.m1.5a"><mrow id="S3.E3.m1.5.5" xref="S3.E3.m1.5.5.cmml"><msubsup id="S3.E3.m1.5.5.6" xref="S3.E3.m1.5.5.6.cmml"><mi id="S3.E3.m1.5.5.6.2.2" xref="S3.E3.m1.5.5.6.2.2.cmml">E</mi><mi id="S3.E3.m1.5.5.6.2.3" xref="S3.E3.m1.5.5.6.2.3.cmml">i</mi><mo id="S3.E3.m1.5.5.6.3" xref="S3.E3.m1.5.5.6.3.cmml">′</mo></msubsup><mo id="S3.E3.m1.5.5.5" xref="S3.E3.m1.5.5.5.cmml">=</mo><mrow id="S3.E3.m1.5.5.4" xref="S3.E3.m1.5.5.4.cmml"><mtext id="S3.E3.m1.5.5.4.6" xref="S3.E3.m1.5.5.4.6a.cmml">Decoder’</mtext><mo id="S3.E3.m1.5.5.4.5" xref="S3.E3.m1.5.5.4.5.cmml">⁢</mo><mrow id="S3.E3.m1.5.5.4.4.4" xref="S3.E3.m1.5.5.4.4.5.cmml"><mo id="S3.E3.m1.5.5.4.4.4.5" stretchy="false" xref="S3.E3.m1.5.5.4.4.5.cmml">(</mo><msub id="S3.E3.m1.2.2.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.cmml"><mi id="S3.E3.m1.2.2.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.2.cmml">l</mi><mn id="S3.E3.m1.2.2.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.3.cmml">0</mn></msub><mo id="S3.E3.m1.5.5.4.4.4.6" xref="S3.E3.m1.5.5.4.4.5.cmml">,</mo><msub id="S3.E3.m1.3.3.2.2.2.2" xref="S3.E3.m1.3.3.2.2.2.2.cmml"><mi id="S3.E3.m1.3.3.2.2.2.2.2" xref="S3.E3.m1.3.3.2.2.2.2.2.cmml">l</mi><mn id="S3.E3.m1.3.3.2.2.2.2.3" xref="S3.E3.m1.3.3.2.2.2.2.3.cmml">1</mn></msub><mo id="S3.E3.m1.5.5.4.4.4.7" xref="S3.E3.m1.5.5.4.4.5.cmml">,</mo><mi id="S3.E3.m1.1.1" mathvariant="normal" xref="S3.E3.m1.1.1.cmml">…</mi><mo id="S3.E3.m1.5.5.4.4.4.8" xref="S3.E3.m1.5.5.4.4.5.cmml">,</mo><msub id="S3.E3.m1.4.4.3.3.3.3" xref="S3.E3.m1.4.4.3.3.3.3.cmml"><mi id="S3.E3.m1.4.4.3.3.3.3.2" xref="S3.E3.m1.4.4.3.3.3.3.2.cmml">l</mi><mrow id="S3.E3.m1.4.4.3.3.3.3.3" xref="S3.E3.m1.4.4.3.3.3.3.3.cmml"><mi id="S3.E3.m1.4.4.3.3.3.3.3.2" xref="S3.E3.m1.4.4.3.3.3.3.3.2.cmml">i</mi><mo id="S3.E3.m1.4.4.3.3.3.3.3.1" xref="S3.E3.m1.4.4.3.3.3.3.3.1.cmml">−</mo><mn id="S3.E3.m1.4.4.3.3.3.3.3.3" xref="S3.E3.m1.4.4.3.3.3.3.3.3.cmml">1</mn></mrow></msub><mo id="S3.E3.m1.5.5.4.4.4.9" xref="S3.E3.m1.5.5.4.4.5.cmml">;</mo><msubsup id="S3.E3.m1.5.5.4.4.4.4" xref="S3.E3.m1.5.5.4.4.4.4.cmml"><mi id="S3.E3.m1.5.5.4.4.4.4.2.2" xref="S3.E3.m1.5.5.4.4.4.4.2.2.cmml">θ</mi><mi id="S3.E3.m1.5.5.4.4.4.4.2.3" xref="S3.E3.m1.5.5.4.4.4.4.2.3.cmml">i</mi><mo id="S3.E3.m1.5.5.4.4.4.4.3" xref="S3.E3.m1.5.5.4.4.4.4.3.cmml">′</mo></msubsup><mo id="S3.E3.m1.5.5.4.4.4.10" stretchy="false" xref="S3.E3.m1.5.5.4.4.5.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.5b"><apply id="S3.E3.m1.5.5.cmml" xref="S3.E3.m1.5.5"><eq id="S3.E3.m1.5.5.5.cmml" xref="S3.E3.m1.5.5.5"></eq><apply id="S3.E3.m1.5.5.6.cmml" xref="S3.E3.m1.5.5.6"><csymbol cd="ambiguous" id="S3.E3.m1.5.5.6.1.cmml" xref="S3.E3.m1.5.5.6">superscript</csymbol><apply id="S3.E3.m1.5.5.6.2.cmml" xref="S3.E3.m1.5.5.6"><csymbol cd="ambiguous" id="S3.E3.m1.5.5.6.2.1.cmml" xref="S3.E3.m1.5.5.6">subscript</csymbol><ci id="S3.E3.m1.5.5.6.2.2.cmml" xref="S3.E3.m1.5.5.6.2.2">𝐸</ci><ci id="S3.E3.m1.5.5.6.2.3.cmml" xref="S3.E3.m1.5.5.6.2.3">𝑖</ci></apply><ci id="S3.E3.m1.5.5.6.3.cmml" xref="S3.E3.m1.5.5.6.3">′</ci></apply><apply id="S3.E3.m1.5.5.4.cmml" xref="S3.E3.m1.5.5.4"><times id="S3.E3.m1.5.5.4.5.cmml" xref="S3.E3.m1.5.5.4.5"></times><ci id="S3.E3.m1.5.5.4.6a.cmml" xref="S3.E3.m1.5.5.4.6"><mtext id="S3.E3.m1.5.5.4.6.cmml" xref="S3.E3.m1.5.5.4.6">Decoder’</mtext></ci><vector id="S3.E3.m1.5.5.4.4.5.cmml" xref="S3.E3.m1.5.5.4.4.4"><apply id="S3.E3.m1.2.2.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.2">𝑙</ci><cn id="S3.E3.m1.2.2.1.1.1.1.3.cmml" type="integer" xref="S3.E3.m1.2.2.1.1.1.1.3">0</cn></apply><apply id="S3.E3.m1.3.3.2.2.2.2.cmml" xref="S3.E3.m1.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.2.2.2.2.1.cmml" xref="S3.E3.m1.3.3.2.2.2.2">subscript</csymbol><ci id="S3.E3.m1.3.3.2.2.2.2.2.cmml" xref="S3.E3.m1.3.3.2.2.2.2.2">𝑙</ci><cn id="S3.E3.m1.3.3.2.2.2.2.3.cmml" type="integer" xref="S3.E3.m1.3.3.2.2.2.2.3">1</cn></apply><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">…</ci><apply id="S3.E3.m1.4.4.3.3.3.3.cmml" xref="S3.E3.m1.4.4.3.3.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.3.3.3.3.1.cmml" xref="S3.E3.m1.4.4.3.3.3.3">subscript</csymbol><ci id="S3.E3.m1.4.4.3.3.3.3.2.cmml" xref="S3.E3.m1.4.4.3.3.3.3.2">𝑙</ci><apply id="S3.E3.m1.4.4.3.3.3.3.3.cmml" xref="S3.E3.m1.4.4.3.3.3.3.3"><minus id="S3.E3.m1.4.4.3.3.3.3.3.1.cmml" xref="S3.E3.m1.4.4.3.3.3.3.3.1"></minus><ci id="S3.E3.m1.4.4.3.3.3.3.3.2.cmml" xref="S3.E3.m1.4.4.3.3.3.3.3.2">𝑖</ci><cn id="S3.E3.m1.4.4.3.3.3.3.3.3.cmml" type="integer" xref="S3.E3.m1.4.4.3.3.3.3.3.3">1</cn></apply></apply><apply id="S3.E3.m1.5.5.4.4.4.4.cmml" xref="S3.E3.m1.5.5.4.4.4.4"><csymbol cd="ambiguous" id="S3.E3.m1.5.5.4.4.4.4.1.cmml" xref="S3.E3.m1.5.5.4.4.4.4">superscript</csymbol><apply id="S3.E3.m1.5.5.4.4.4.4.2.cmml" xref="S3.E3.m1.5.5.4.4.4.4"><csymbol cd="ambiguous" id="S3.E3.m1.5.5.4.4.4.4.2.1.cmml" xref="S3.E3.m1.5.5.4.4.4.4">subscript</csymbol><ci id="S3.E3.m1.5.5.4.4.4.4.2.2.cmml" xref="S3.E3.m1.5.5.4.4.4.4.2.2">𝜃</ci><ci id="S3.E3.m1.5.5.4.4.4.4.2.3.cmml" xref="S3.E3.m1.5.5.4.4.4.4.2.3">𝑖</ci></apply><ci id="S3.E3.m1.5.5.4.4.4.4.3.cmml" xref="S3.E3.m1.5.5.4.4.4.4.3">′</ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.5c">E_{i}^{\prime}=\text{Decoder'}(l_{0},l_{1},...,l_{i-1};\theta_{i}^{\prime})</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.5d">italic_E start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = Decoder’ ( italic_l start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_l start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT ; italic_θ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS3.p6">
<table class="ltx_equation ltx_eqn_table" id="S3.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(4)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="W_{i}=\text{Linear}(E^{\prime}_{i})" class="ltx_Math" display="block" id="S3.E4.m1.1"><semantics id="S3.E4.m1.1a"><mrow id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml"><msub id="S3.E4.m1.1.1.3" xref="S3.E4.m1.1.1.3.cmml"><mi id="S3.E4.m1.1.1.3.2" xref="S3.E4.m1.1.1.3.2.cmml">W</mi><mi id="S3.E4.m1.1.1.3.3" xref="S3.E4.m1.1.1.3.3.cmml">i</mi></msub><mo id="S3.E4.m1.1.1.2" xref="S3.E4.m1.1.1.2.cmml">=</mo><mrow id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.cmml"><mtext id="S3.E4.m1.1.1.1.3" xref="S3.E4.m1.1.1.1.3a.cmml">Linear</mtext><mo id="S3.E4.m1.1.1.1.2" xref="S3.E4.m1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E4.m1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.cmml"><mo id="S3.E4.m1.1.1.1.1.1.2" stretchy="false" xref="S3.E4.m1.1.1.1.1.1.1.cmml">(</mo><msubsup id="S3.E4.m1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.2.2" xref="S3.E4.m1.1.1.1.1.1.1.2.2.cmml">E</mi><mi id="S3.E4.m1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.3.cmml">i</mi><mo id="S3.E4.m1.1.1.1.1.1.1.2.3" xref="S3.E4.m1.1.1.1.1.1.1.2.3.cmml">′</mo></msubsup><mo id="S3.E4.m1.1.1.1.1.1.3" stretchy="false" xref="S3.E4.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.1b"><apply id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1"><eq id="S3.E4.m1.1.1.2.cmml" xref="S3.E4.m1.1.1.2"></eq><apply id="S3.E4.m1.1.1.3.cmml" xref="S3.E4.m1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.3">subscript</csymbol><ci id="S3.E4.m1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.3.2">𝑊</ci><ci id="S3.E4.m1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.3.3">𝑖</ci></apply><apply id="S3.E4.m1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"><times id="S3.E4.m1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.2"></times><ci id="S3.E4.m1.1.1.1.3a.cmml" xref="S3.E4.m1.1.1.1.3"><mtext id="S3.E4.m1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.3">Linear</mtext></ci><apply id="S3.E4.m1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1">subscript</csymbol><apply id="S3.E4.m1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.1.1.1.1.1">superscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.2.2">𝐸</ci><ci id="S3.E4.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.2.3">′</ci></apply><ci id="S3.E4.m1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.1c">W_{i}=\text{Linear}(E^{\prime}_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.1d">italic_W start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = Linear ( italic_E start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p7">
<p class="ltx_p" id="S3.SS3.p7.4">where <math alttext="\theta_{i}^{\prime}" class="ltx_Math" display="inline" id="S3.SS3.p7.1.m1.1"><semantics id="S3.SS3.p7.1.m1.1a"><msubsup id="S3.SS3.p7.1.m1.1.1" xref="S3.SS3.p7.1.m1.1.1.cmml"><mi id="S3.SS3.p7.1.m1.1.1.2.2" xref="S3.SS3.p7.1.m1.1.1.2.2.cmml">θ</mi><mi id="S3.SS3.p7.1.m1.1.1.2.3" xref="S3.SS3.p7.1.m1.1.1.2.3.cmml">i</mi><mo id="S3.SS3.p7.1.m1.1.1.3" xref="S3.SS3.p7.1.m1.1.1.3.cmml">′</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p7.1.m1.1b"><apply id="S3.SS3.p7.1.m1.1.1.cmml" xref="S3.SS3.p7.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p7.1.m1.1.1.1.cmml" xref="S3.SS3.p7.1.m1.1.1">superscript</csymbol><apply id="S3.SS3.p7.1.m1.1.1.2.cmml" xref="S3.SS3.p7.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p7.1.m1.1.1.2.1.cmml" xref="S3.SS3.p7.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p7.1.m1.1.1.2.2.cmml" xref="S3.SS3.p7.1.m1.1.1.2.2">𝜃</ci><ci id="S3.SS3.p7.1.m1.1.1.2.3.cmml" xref="S3.SS3.p7.1.m1.1.1.2.3">𝑖</ci></apply><ci id="S3.SS3.p7.1.m1.1.1.3.cmml" xref="S3.SS3.p7.1.m1.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p7.1.m1.1c">\theta_{i}^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p7.1.m1.1d">italic_θ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math> represents the parameters of the decoder that generates the weights, and <math alttext="W_{i}" class="ltx_Math" display="inline" id="S3.SS3.p7.2.m2.1"><semantics id="S3.SS3.p7.2.m2.1a"><msub id="S3.SS3.p7.2.m2.1.1" xref="S3.SS3.p7.2.m2.1.1.cmml"><mi id="S3.SS3.p7.2.m2.1.1.2" xref="S3.SS3.p7.2.m2.1.1.2.cmml">W</mi><mi id="S3.SS3.p7.2.m2.1.1.3" xref="S3.SS3.p7.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p7.2.m2.1b"><apply id="S3.SS3.p7.2.m2.1.1.cmml" xref="S3.SS3.p7.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p7.2.m2.1.1.1.cmml" xref="S3.SS3.p7.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p7.2.m2.1.1.2.cmml" xref="S3.SS3.p7.2.m2.1.1.2">𝑊</ci><ci id="S3.SS3.p7.2.m2.1.1.3.cmml" xref="S3.SS3.p7.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p7.2.m2.1c">W_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p7.2.m2.1d">italic_W start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is the generated weight matrix for the corresponding classifier. Finally, the i-th token is represented as <math alttext="l_{i}" class="ltx_Math" display="inline" id="S3.SS3.p7.3.m3.1"><semantics id="S3.SS3.p7.3.m3.1a"><msub id="S3.SS3.p7.3.m3.1.1" xref="S3.SS3.p7.3.m3.1.1.cmml"><mi id="S3.SS3.p7.3.m3.1.1.2" xref="S3.SS3.p7.3.m3.1.1.2.cmml">l</mi><mi id="S3.SS3.p7.3.m3.1.1.3" xref="S3.SS3.p7.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p7.3.m3.1b"><apply id="S3.SS3.p7.3.m3.1.1.cmml" xref="S3.SS3.p7.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p7.3.m3.1.1.1.cmml" xref="S3.SS3.p7.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p7.3.m3.1.1.2.cmml" xref="S3.SS3.p7.3.m3.1.1.2">𝑙</ci><ci id="S3.SS3.p7.3.m3.1.1.3.cmml" xref="S3.SS3.p7.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p7.3.m3.1c">l_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p7.3.m3.1d">italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, calculated by <math alttext="\text{softmax}(E_{i}W_{i})" class="ltx_Math" display="inline" id="S3.SS3.p7.4.m4.1"><semantics id="S3.SS3.p7.4.m4.1a"><mrow id="S3.SS3.p7.4.m4.1.1" xref="S3.SS3.p7.4.m4.1.1.cmml"><mtext id="S3.SS3.p7.4.m4.1.1.3" xref="S3.SS3.p7.4.m4.1.1.3a.cmml">softmax</mtext><mo id="S3.SS3.p7.4.m4.1.1.2" xref="S3.SS3.p7.4.m4.1.1.2.cmml">⁢</mo><mrow id="S3.SS3.p7.4.m4.1.1.1.1" xref="S3.SS3.p7.4.m4.1.1.1.1.1.cmml"><mo id="S3.SS3.p7.4.m4.1.1.1.1.2" stretchy="false" xref="S3.SS3.p7.4.m4.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.p7.4.m4.1.1.1.1.1" xref="S3.SS3.p7.4.m4.1.1.1.1.1.cmml"><msub id="S3.SS3.p7.4.m4.1.1.1.1.1.2" xref="S3.SS3.p7.4.m4.1.1.1.1.1.2.cmml"><mi id="S3.SS3.p7.4.m4.1.1.1.1.1.2.2" xref="S3.SS3.p7.4.m4.1.1.1.1.1.2.2.cmml">E</mi><mi id="S3.SS3.p7.4.m4.1.1.1.1.1.2.3" xref="S3.SS3.p7.4.m4.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S3.SS3.p7.4.m4.1.1.1.1.1.1" xref="S3.SS3.p7.4.m4.1.1.1.1.1.1.cmml">⁢</mo><msub id="S3.SS3.p7.4.m4.1.1.1.1.1.3" xref="S3.SS3.p7.4.m4.1.1.1.1.1.3.cmml"><mi id="S3.SS3.p7.4.m4.1.1.1.1.1.3.2" xref="S3.SS3.p7.4.m4.1.1.1.1.1.3.2.cmml">W</mi><mi id="S3.SS3.p7.4.m4.1.1.1.1.1.3.3" xref="S3.SS3.p7.4.m4.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S3.SS3.p7.4.m4.1.1.1.1.3" stretchy="false" xref="S3.SS3.p7.4.m4.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p7.4.m4.1b"><apply id="S3.SS3.p7.4.m4.1.1.cmml" xref="S3.SS3.p7.4.m4.1.1"><times id="S3.SS3.p7.4.m4.1.1.2.cmml" xref="S3.SS3.p7.4.m4.1.1.2"></times><ci id="S3.SS3.p7.4.m4.1.1.3a.cmml" xref="S3.SS3.p7.4.m4.1.1.3"><mtext id="S3.SS3.p7.4.m4.1.1.3.cmml" xref="S3.SS3.p7.4.m4.1.1.3">softmax</mtext></ci><apply id="S3.SS3.p7.4.m4.1.1.1.1.1.cmml" xref="S3.SS3.p7.4.m4.1.1.1.1"><times id="S3.SS3.p7.4.m4.1.1.1.1.1.1.cmml" xref="S3.SS3.p7.4.m4.1.1.1.1.1.1"></times><apply id="S3.SS3.p7.4.m4.1.1.1.1.1.2.cmml" xref="S3.SS3.p7.4.m4.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p7.4.m4.1.1.1.1.1.2.1.cmml" xref="S3.SS3.p7.4.m4.1.1.1.1.1.2">subscript</csymbol><ci id="S3.SS3.p7.4.m4.1.1.1.1.1.2.2.cmml" xref="S3.SS3.p7.4.m4.1.1.1.1.1.2.2">𝐸</ci><ci id="S3.SS3.p7.4.m4.1.1.1.1.1.2.3.cmml" xref="S3.SS3.p7.4.m4.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S3.SS3.p7.4.m4.1.1.1.1.1.3.cmml" xref="S3.SS3.p7.4.m4.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p7.4.m4.1.1.1.1.1.3.1.cmml" xref="S3.SS3.p7.4.m4.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS3.p7.4.m4.1.1.1.1.1.3.2.cmml" xref="S3.SS3.p7.4.m4.1.1.1.1.1.3.2">𝑊</ci><ci id="S3.SS3.p7.4.m4.1.1.1.1.1.3.3.cmml" xref="S3.SS3.p7.4.m4.1.1.1.1.1.3.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p7.4.m4.1c">\text{softmax}(E_{i}W_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p7.4.m4.1d">softmax ( italic_E start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4. </span>Model Training and Inference</h3>
<div class="ltx_para ltx_noindent" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1"><span class="ltx_text ltx_font_bold" id="S3.SS4.p1.1.1">Training Loss.</span>
The loss function for a set of training examples <math alttext="\mathcal{D}=\{(q,L_{path})\}" class="ltx_Math" display="inline" id="S3.SS4.p1.1.m1.2"><semantics id="S3.SS4.p1.1.m1.2a"><mrow id="S3.SS4.p1.1.m1.2.2" xref="S3.SS4.p1.1.m1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p1.1.m1.2.2.3" xref="S3.SS4.p1.1.m1.2.2.3.cmml">𝒟</mi><mo id="S3.SS4.p1.1.m1.2.2.2" xref="S3.SS4.p1.1.m1.2.2.2.cmml">=</mo><mrow id="S3.SS4.p1.1.m1.2.2.1.1" xref="S3.SS4.p1.1.m1.2.2.1.2.cmml"><mo id="S3.SS4.p1.1.m1.2.2.1.1.2" stretchy="false" xref="S3.SS4.p1.1.m1.2.2.1.2.cmml">{</mo><mrow id="S3.SS4.p1.1.m1.2.2.1.1.1.1" xref="S3.SS4.p1.1.m1.2.2.1.1.1.2.cmml"><mo id="S3.SS4.p1.1.m1.2.2.1.1.1.1.2" stretchy="false" xref="S3.SS4.p1.1.m1.2.2.1.1.1.2.cmml">(</mo><mi id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml">q</mi><mo id="S3.SS4.p1.1.m1.2.2.1.1.1.1.3" xref="S3.SS4.p1.1.m1.2.2.1.1.1.2.cmml">,</mo><msub id="S3.SS4.p1.1.m1.2.2.1.1.1.1.1" xref="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.cmml"><mi id="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.2" xref="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.2.cmml">L</mi><mrow id="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.3" xref="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.3.cmml"><mi id="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.3.2" xref="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.3.2.cmml">p</mi><mo id="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.3.1" xref="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.3.3" xref="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.3.3.cmml">a</mi><mo id="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.3.1a" xref="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.3.4" xref="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.3.4.cmml">t</mi><mo id="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.3.1b" xref="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.3.5" xref="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.3.5.cmml">h</mi></mrow></msub><mo id="S3.SS4.p1.1.m1.2.2.1.1.1.1.4" stretchy="false" xref="S3.SS4.p1.1.m1.2.2.1.1.1.2.cmml">)</mo></mrow><mo id="S3.SS4.p1.1.m1.2.2.1.1.3" stretchy="false" xref="S3.SS4.p1.1.m1.2.2.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.2b"><apply id="S3.SS4.p1.1.m1.2.2.cmml" xref="S3.SS4.p1.1.m1.2.2"><eq id="S3.SS4.p1.1.m1.2.2.2.cmml" xref="S3.SS4.p1.1.m1.2.2.2"></eq><ci id="S3.SS4.p1.1.m1.2.2.3.cmml" xref="S3.SS4.p1.1.m1.2.2.3">𝒟</ci><set id="S3.SS4.p1.1.m1.2.2.1.2.cmml" xref="S3.SS4.p1.1.m1.2.2.1.1"><interval closure="open" id="S3.SS4.p1.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS4.p1.1.m1.2.2.1.1.1.1"><ci id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1">𝑞</ci><apply id="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.cmml" xref="S3.SS4.p1.1.m1.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.SS4.p1.1.m1.2.2.1.1.1.1.1">subscript</csymbol><ci id="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.2">𝐿</ci><apply id="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.3.cmml" xref="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.3"><times id="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.3.1.cmml" xref="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.3.1"></times><ci id="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.3.2.cmml" xref="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.3.2">𝑝</ci><ci id="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.3.3.cmml" xref="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.3.3">𝑎</ci><ci id="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.3.4.cmml" xref="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.3.4">𝑡</ci><ci id="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.3.5.cmml" xref="S3.SS4.p1.1.m1.2.2.1.1.1.1.1.3.5">ℎ</ci></apply></apply></interval></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.2c">\mathcal{D}=\{(q,L_{path})\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.1.m1.2d">caligraphic_D = { ( italic_q , italic_L start_POSTSUBSCRIPT italic_p italic_a italic_t italic_h end_POSTSUBSCRIPT ) }</annotation></semantics></math>, consisting of queries (training queries and expansion queries) and video SemID, can be expressed as follows,</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(5)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}(\theta)=\sum_{(q,L_{path})}^{\mathcal{D}}\text{log}(L_{path}|q,\theta)" class="ltx_Math" display="block" id="S3.E5.m1.6"><semantics id="S3.E5.m1.6a"><mrow id="S3.E5.m1.6.6" xref="S3.E5.m1.6.6.cmml"><mrow id="S3.E5.m1.6.6.3" xref="S3.E5.m1.6.6.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.6.6.3.2" xref="S3.E5.m1.6.6.3.2.cmml">ℒ</mi><mo id="S3.E5.m1.6.6.3.1" xref="S3.E5.m1.6.6.3.1.cmml">⁢</mo><mrow id="S3.E5.m1.6.6.3.3.2" xref="S3.E5.m1.6.6.3.cmml"><mo id="S3.E5.m1.6.6.3.3.2.1" stretchy="false" xref="S3.E5.m1.6.6.3.cmml">(</mo><mi id="S3.E5.m1.3.3" xref="S3.E5.m1.3.3.cmml">θ</mi><mo id="S3.E5.m1.6.6.3.3.2.2" stretchy="false" xref="S3.E5.m1.6.6.3.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.6.6.2" rspace="0.111em" xref="S3.E5.m1.6.6.2.cmml">=</mo><mrow id="S3.E5.m1.6.6.1" xref="S3.E5.m1.6.6.1.cmml"><munderover id="S3.E5.m1.6.6.1.2" xref="S3.E5.m1.6.6.1.2.cmml"><mo id="S3.E5.m1.6.6.1.2.2.2" movablelimits="false" xref="S3.E5.m1.6.6.1.2.2.2.cmml">∑</mo><mrow id="S3.E5.m1.2.2.2.2" xref="S3.E5.m1.2.2.2.3.cmml"><mo id="S3.E5.m1.2.2.2.2.2" stretchy="false" xref="S3.E5.m1.2.2.2.3.cmml">(</mo><mi id="S3.E5.m1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml">q</mi><mo id="S3.E5.m1.2.2.2.2.3" xref="S3.E5.m1.2.2.2.3.cmml">,</mo><msub id="S3.E5.m1.2.2.2.2.1" xref="S3.E5.m1.2.2.2.2.1.cmml"><mi id="S3.E5.m1.2.2.2.2.1.2" xref="S3.E5.m1.2.2.2.2.1.2.cmml">L</mi><mrow id="S3.E5.m1.2.2.2.2.1.3" xref="S3.E5.m1.2.2.2.2.1.3.cmml"><mi id="S3.E5.m1.2.2.2.2.1.3.2" xref="S3.E5.m1.2.2.2.2.1.3.2.cmml">p</mi><mo id="S3.E5.m1.2.2.2.2.1.3.1" xref="S3.E5.m1.2.2.2.2.1.3.1.cmml">⁢</mo><mi id="S3.E5.m1.2.2.2.2.1.3.3" xref="S3.E5.m1.2.2.2.2.1.3.3.cmml">a</mi><mo id="S3.E5.m1.2.2.2.2.1.3.1a" xref="S3.E5.m1.2.2.2.2.1.3.1.cmml">⁢</mo><mi id="S3.E5.m1.2.2.2.2.1.3.4" xref="S3.E5.m1.2.2.2.2.1.3.4.cmml">t</mi><mo id="S3.E5.m1.2.2.2.2.1.3.1b" xref="S3.E5.m1.2.2.2.2.1.3.1.cmml">⁢</mo><mi id="S3.E5.m1.2.2.2.2.1.3.5" xref="S3.E5.m1.2.2.2.2.1.3.5.cmml">h</mi></mrow></msub><mo id="S3.E5.m1.2.2.2.2.4" stretchy="false" xref="S3.E5.m1.2.2.2.3.cmml">)</mo></mrow><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.6.6.1.2.3" xref="S3.E5.m1.6.6.1.2.3.cmml">𝒟</mi></munderover><mrow id="S3.E5.m1.6.6.1.1" xref="S3.E5.m1.6.6.1.1.cmml"><mtext id="S3.E5.m1.6.6.1.1.3" xref="S3.E5.m1.6.6.1.1.3a.cmml">log</mtext><mo id="S3.E5.m1.6.6.1.1.2" xref="S3.E5.m1.6.6.1.1.2.cmml">⁢</mo><mrow id="S3.E5.m1.6.6.1.1.1.1" xref="S3.E5.m1.6.6.1.1.1.1.1.cmml"><mo id="S3.E5.m1.6.6.1.1.1.1.2" stretchy="false" xref="S3.E5.m1.6.6.1.1.1.1.1.cmml">(</mo><mrow id="S3.E5.m1.6.6.1.1.1.1.1" xref="S3.E5.m1.6.6.1.1.1.1.1.cmml"><msub id="S3.E5.m1.6.6.1.1.1.1.1.2" xref="S3.E5.m1.6.6.1.1.1.1.1.2.cmml"><mi id="S3.E5.m1.6.6.1.1.1.1.1.2.2" xref="S3.E5.m1.6.6.1.1.1.1.1.2.2.cmml">L</mi><mrow id="S3.E5.m1.6.6.1.1.1.1.1.2.3" xref="S3.E5.m1.6.6.1.1.1.1.1.2.3.cmml"><mi id="S3.E5.m1.6.6.1.1.1.1.1.2.3.2" xref="S3.E5.m1.6.6.1.1.1.1.1.2.3.2.cmml">p</mi><mo id="S3.E5.m1.6.6.1.1.1.1.1.2.3.1" xref="S3.E5.m1.6.6.1.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E5.m1.6.6.1.1.1.1.1.2.3.3" xref="S3.E5.m1.6.6.1.1.1.1.1.2.3.3.cmml">a</mi><mo id="S3.E5.m1.6.6.1.1.1.1.1.2.3.1a" xref="S3.E5.m1.6.6.1.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E5.m1.6.6.1.1.1.1.1.2.3.4" xref="S3.E5.m1.6.6.1.1.1.1.1.2.3.4.cmml">t</mi><mo id="S3.E5.m1.6.6.1.1.1.1.1.2.3.1b" xref="S3.E5.m1.6.6.1.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E5.m1.6.6.1.1.1.1.1.2.3.5" xref="S3.E5.m1.6.6.1.1.1.1.1.2.3.5.cmml">h</mi></mrow></msub><mo fence="false" id="S3.E5.m1.6.6.1.1.1.1.1.1" xref="S3.E5.m1.6.6.1.1.1.1.1.1.cmml">|</mo><mrow id="S3.E5.m1.6.6.1.1.1.1.1.3.2" xref="S3.E5.m1.6.6.1.1.1.1.1.3.1.cmml"><mi id="S3.E5.m1.4.4" xref="S3.E5.m1.4.4.cmml">q</mi><mo id="S3.E5.m1.6.6.1.1.1.1.1.3.2.1" xref="S3.E5.m1.6.6.1.1.1.1.1.3.1.cmml">,</mo><mi id="S3.E5.m1.5.5" xref="S3.E5.m1.5.5.cmml">θ</mi></mrow></mrow><mo id="S3.E5.m1.6.6.1.1.1.1.3" stretchy="false" xref="S3.E5.m1.6.6.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.6b"><apply id="S3.E5.m1.6.6.cmml" xref="S3.E5.m1.6.6"><eq id="S3.E5.m1.6.6.2.cmml" xref="S3.E5.m1.6.6.2"></eq><apply id="S3.E5.m1.6.6.3.cmml" xref="S3.E5.m1.6.6.3"><times id="S3.E5.m1.6.6.3.1.cmml" xref="S3.E5.m1.6.6.3.1"></times><ci id="S3.E5.m1.6.6.3.2.cmml" xref="S3.E5.m1.6.6.3.2">ℒ</ci><ci id="S3.E5.m1.3.3.cmml" xref="S3.E5.m1.3.3">𝜃</ci></apply><apply id="S3.E5.m1.6.6.1.cmml" xref="S3.E5.m1.6.6.1"><apply id="S3.E5.m1.6.6.1.2.cmml" xref="S3.E5.m1.6.6.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.6.6.1.2.1.cmml" xref="S3.E5.m1.6.6.1.2">superscript</csymbol><apply id="S3.E5.m1.6.6.1.2.2.cmml" xref="S3.E5.m1.6.6.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.6.6.1.2.2.1.cmml" xref="S3.E5.m1.6.6.1.2">subscript</csymbol><sum id="S3.E5.m1.6.6.1.2.2.2.cmml" xref="S3.E5.m1.6.6.1.2.2.2"></sum><interval closure="open" id="S3.E5.m1.2.2.2.3.cmml" xref="S3.E5.m1.2.2.2.2"><ci id="S3.E5.m1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1">𝑞</ci><apply id="S3.E5.m1.2.2.2.2.1.cmml" xref="S3.E5.m1.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.2.2.1.1.cmml" xref="S3.E5.m1.2.2.2.2.1">subscript</csymbol><ci id="S3.E5.m1.2.2.2.2.1.2.cmml" xref="S3.E5.m1.2.2.2.2.1.2">𝐿</ci><apply id="S3.E5.m1.2.2.2.2.1.3.cmml" xref="S3.E5.m1.2.2.2.2.1.3"><times id="S3.E5.m1.2.2.2.2.1.3.1.cmml" xref="S3.E5.m1.2.2.2.2.1.3.1"></times><ci id="S3.E5.m1.2.2.2.2.1.3.2.cmml" xref="S3.E5.m1.2.2.2.2.1.3.2">𝑝</ci><ci id="S3.E5.m1.2.2.2.2.1.3.3.cmml" xref="S3.E5.m1.2.2.2.2.1.3.3">𝑎</ci><ci id="S3.E5.m1.2.2.2.2.1.3.4.cmml" xref="S3.E5.m1.2.2.2.2.1.3.4">𝑡</ci><ci id="S3.E5.m1.2.2.2.2.1.3.5.cmml" xref="S3.E5.m1.2.2.2.2.1.3.5">ℎ</ci></apply></apply></interval></apply><ci id="S3.E5.m1.6.6.1.2.3.cmml" xref="S3.E5.m1.6.6.1.2.3">𝒟</ci></apply><apply id="S3.E5.m1.6.6.1.1.cmml" xref="S3.E5.m1.6.6.1.1"><times id="S3.E5.m1.6.6.1.1.2.cmml" xref="S3.E5.m1.6.6.1.1.2"></times><ci id="S3.E5.m1.6.6.1.1.3a.cmml" xref="S3.E5.m1.6.6.1.1.3"><mtext id="S3.E5.m1.6.6.1.1.3.cmml" xref="S3.E5.m1.6.6.1.1.3">log</mtext></ci><apply id="S3.E5.m1.6.6.1.1.1.1.1.cmml" xref="S3.E5.m1.6.6.1.1.1.1"><csymbol cd="latexml" id="S3.E5.m1.6.6.1.1.1.1.1.1.cmml" xref="S3.E5.m1.6.6.1.1.1.1.1.1">conditional</csymbol><apply id="S3.E5.m1.6.6.1.1.1.1.1.2.cmml" xref="S3.E5.m1.6.6.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.6.6.1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.6.6.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E5.m1.6.6.1.1.1.1.1.2.2.cmml" xref="S3.E5.m1.6.6.1.1.1.1.1.2.2">𝐿</ci><apply id="S3.E5.m1.6.6.1.1.1.1.1.2.3.cmml" xref="S3.E5.m1.6.6.1.1.1.1.1.2.3"><times id="S3.E5.m1.6.6.1.1.1.1.1.2.3.1.cmml" xref="S3.E5.m1.6.6.1.1.1.1.1.2.3.1"></times><ci id="S3.E5.m1.6.6.1.1.1.1.1.2.3.2.cmml" xref="S3.E5.m1.6.6.1.1.1.1.1.2.3.2">𝑝</ci><ci id="S3.E5.m1.6.6.1.1.1.1.1.2.3.3.cmml" xref="S3.E5.m1.6.6.1.1.1.1.1.2.3.3">𝑎</ci><ci id="S3.E5.m1.6.6.1.1.1.1.1.2.3.4.cmml" xref="S3.E5.m1.6.6.1.1.1.1.1.2.3.4">𝑡</ci><ci id="S3.E5.m1.6.6.1.1.1.1.1.2.3.5.cmml" xref="S3.E5.m1.6.6.1.1.1.1.1.2.3.5">ℎ</ci></apply></apply><list id="S3.E5.m1.6.6.1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.6.6.1.1.1.1.1.3.2"><ci id="S3.E5.m1.4.4.cmml" xref="S3.E5.m1.4.4">𝑞</ci><ci id="S3.E5.m1.5.5.cmml" xref="S3.E5.m1.5.5">𝜃</ci></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.6c">\mathcal{L}(\theta)=\sum_{(q,L_{path})}^{\mathcal{D}}\text{log}(L_{path}|q,\theta)</annotation><annotation encoding="application/x-llamapun" id="S3.E5.m1.6d">caligraphic_L ( italic_θ ) = ∑ start_POSTSUBSCRIPT ( italic_q , italic_L start_POSTSUBSCRIPT italic_p italic_a italic_t italic_h end_POSTSUBSCRIPT ) end_POSTSUBSCRIPT start_POSTSUPERSCRIPT caligraphic_D end_POSTSUPERSCRIPT log ( italic_L start_POSTSUBSCRIPT italic_p italic_a italic_t italic_h end_POSTSUBSCRIPT | italic_q , italic_θ )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS4.p1.3">where <math alttext="\text{log}(L_{path}|q,\theta)" class="ltx_Math" display="inline" id="S3.SS4.p1.2.m1.3"><semantics id="S3.SS4.p1.2.m1.3a"><mrow id="S3.SS4.p1.2.m1.3.3" xref="S3.SS4.p1.2.m1.3.3.cmml"><mtext id="S3.SS4.p1.2.m1.3.3.3" xref="S3.SS4.p1.2.m1.3.3.3a.cmml">log</mtext><mo id="S3.SS4.p1.2.m1.3.3.2" xref="S3.SS4.p1.2.m1.3.3.2.cmml">⁢</mo><mrow id="S3.SS4.p1.2.m1.3.3.1.1" xref="S3.SS4.p1.2.m1.3.3.1.1.1.cmml"><mo id="S3.SS4.p1.2.m1.3.3.1.1.2" stretchy="false" xref="S3.SS4.p1.2.m1.3.3.1.1.1.cmml">(</mo><mrow id="S3.SS4.p1.2.m1.3.3.1.1.1" xref="S3.SS4.p1.2.m1.3.3.1.1.1.cmml"><msub id="S3.SS4.p1.2.m1.3.3.1.1.1.2" xref="S3.SS4.p1.2.m1.3.3.1.1.1.2.cmml"><mi id="S3.SS4.p1.2.m1.3.3.1.1.1.2.2" xref="S3.SS4.p1.2.m1.3.3.1.1.1.2.2.cmml">L</mi><mrow id="S3.SS4.p1.2.m1.3.3.1.1.1.2.3" xref="S3.SS4.p1.2.m1.3.3.1.1.1.2.3.cmml"><mi id="S3.SS4.p1.2.m1.3.3.1.1.1.2.3.2" xref="S3.SS4.p1.2.m1.3.3.1.1.1.2.3.2.cmml">p</mi><mo id="S3.SS4.p1.2.m1.3.3.1.1.1.2.3.1" xref="S3.SS4.p1.2.m1.3.3.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS4.p1.2.m1.3.3.1.1.1.2.3.3" xref="S3.SS4.p1.2.m1.3.3.1.1.1.2.3.3.cmml">a</mi><mo id="S3.SS4.p1.2.m1.3.3.1.1.1.2.3.1a" xref="S3.SS4.p1.2.m1.3.3.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS4.p1.2.m1.3.3.1.1.1.2.3.4" xref="S3.SS4.p1.2.m1.3.3.1.1.1.2.3.4.cmml">t</mi><mo id="S3.SS4.p1.2.m1.3.3.1.1.1.2.3.1b" xref="S3.SS4.p1.2.m1.3.3.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS4.p1.2.m1.3.3.1.1.1.2.3.5" xref="S3.SS4.p1.2.m1.3.3.1.1.1.2.3.5.cmml">h</mi></mrow></msub><mo fence="false" id="S3.SS4.p1.2.m1.3.3.1.1.1.1" xref="S3.SS4.p1.2.m1.3.3.1.1.1.1.cmml">|</mo><mrow id="S3.SS4.p1.2.m1.3.3.1.1.1.3.2" xref="S3.SS4.p1.2.m1.3.3.1.1.1.3.1.cmml"><mi id="S3.SS4.p1.2.m1.1.1" xref="S3.SS4.p1.2.m1.1.1.cmml">q</mi><mo id="S3.SS4.p1.2.m1.3.3.1.1.1.3.2.1" xref="S3.SS4.p1.2.m1.3.3.1.1.1.3.1.cmml">,</mo><mi id="S3.SS4.p1.2.m1.2.2" xref="S3.SS4.p1.2.m1.2.2.cmml">θ</mi></mrow></mrow><mo id="S3.SS4.p1.2.m1.3.3.1.1.3" stretchy="false" xref="S3.SS4.p1.2.m1.3.3.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.2.m1.3b"><apply id="S3.SS4.p1.2.m1.3.3.cmml" xref="S3.SS4.p1.2.m1.3.3"><times id="S3.SS4.p1.2.m1.3.3.2.cmml" xref="S3.SS4.p1.2.m1.3.3.2"></times><ci id="S3.SS4.p1.2.m1.3.3.3a.cmml" xref="S3.SS4.p1.2.m1.3.3.3"><mtext id="S3.SS4.p1.2.m1.3.3.3.cmml" xref="S3.SS4.p1.2.m1.3.3.3">log</mtext></ci><apply id="S3.SS4.p1.2.m1.3.3.1.1.1.cmml" xref="S3.SS4.p1.2.m1.3.3.1.1"><csymbol cd="latexml" id="S3.SS4.p1.2.m1.3.3.1.1.1.1.cmml" xref="S3.SS4.p1.2.m1.3.3.1.1.1.1">conditional</csymbol><apply id="S3.SS4.p1.2.m1.3.3.1.1.1.2.cmml" xref="S3.SS4.p1.2.m1.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS4.p1.2.m1.3.3.1.1.1.2.1.cmml" xref="S3.SS4.p1.2.m1.3.3.1.1.1.2">subscript</csymbol><ci id="S3.SS4.p1.2.m1.3.3.1.1.1.2.2.cmml" xref="S3.SS4.p1.2.m1.3.3.1.1.1.2.2">𝐿</ci><apply id="S3.SS4.p1.2.m1.3.3.1.1.1.2.3.cmml" xref="S3.SS4.p1.2.m1.3.3.1.1.1.2.3"><times id="S3.SS4.p1.2.m1.3.3.1.1.1.2.3.1.cmml" xref="S3.SS4.p1.2.m1.3.3.1.1.1.2.3.1"></times><ci id="S3.SS4.p1.2.m1.3.3.1.1.1.2.3.2.cmml" xref="S3.SS4.p1.2.m1.3.3.1.1.1.2.3.2">𝑝</ci><ci id="S3.SS4.p1.2.m1.3.3.1.1.1.2.3.3.cmml" xref="S3.SS4.p1.2.m1.3.3.1.1.1.2.3.3">𝑎</ci><ci id="S3.SS4.p1.2.m1.3.3.1.1.1.2.3.4.cmml" xref="S3.SS4.p1.2.m1.3.3.1.1.1.2.3.4">𝑡</ci><ci id="S3.SS4.p1.2.m1.3.3.1.1.1.2.3.5.cmml" xref="S3.SS4.p1.2.m1.3.3.1.1.1.2.3.5">ℎ</ci></apply></apply><list id="S3.SS4.p1.2.m1.3.3.1.1.1.3.1.cmml" xref="S3.SS4.p1.2.m1.3.3.1.1.1.3.2"><ci id="S3.SS4.p1.2.m1.1.1.cmml" xref="S3.SS4.p1.2.m1.1.1">𝑞</ci><ci id="S3.SS4.p1.2.m1.2.2.cmml" xref="S3.SS4.p1.2.m1.2.2">𝜃</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.2.m1.3c">\text{log}(L_{path}|q,\theta)</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.2.m1.3d">log ( italic_L start_POSTSUBSCRIPT italic_p italic_a italic_t italic_h end_POSTSUBSCRIPT | italic_q , italic_θ )</annotation></semantics></math> represents the probability of generating SemID based on <math alttext="q" class="ltx_Math" display="inline" id="S3.SS4.p1.3.m2.1"><semantics id="S3.SS4.p1.3.m2.1a"><mi id="S3.SS4.p1.3.m2.1.1" xref="S3.SS4.p1.3.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.3.m2.1b"><ci id="S3.SS4.p1.3.m2.1.1.cmml" xref="S3.SS4.p1.3.m2.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.3.m2.1c">q</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.3.m2.1d">italic_q</annotation></semantics></math>, and is a standard sequence-to-sequence cross-entropy loss with teacher forcing.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.4"><span class="ltx_text ltx_font_bold" id="S3.SS4.p2.4.1">Coarse-to-fine Inference.</span>
During the training stage, since the videos in the test set are not visible, this part of the videos is not assigned a SemID. In order to cover test set, a new video needs to be assigned a SemID as its identifier as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S2.F2" title="Figure 2 ‣ 2. Related Work ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_tag">2</span></a> Inference Stage. The new video will get the representation in the same way as the training set using CLIP encoder, and then the video cosine similarity with the leaf nodes in the tree will be calculated. The video will be inserted into the leaf node with the highest similarity and inherit the SemID of the leaf node. For the input query <math alttext="q" class="ltx_Math" display="inline" id="S3.SS4.p2.1.m1.1"><semantics id="S3.SS4.p2.1.m1.1a"><mi id="S3.SS4.p2.1.m1.1.1" xref="S3.SS4.p2.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.1.m1.1b"><ci id="S3.SS4.p2.1.m1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.1.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.1.m1.1d">italic_q</annotation></semantics></math>, the probability <math alttext="p(L_{path}^{trunc}|q,\theta)" class="ltx_Math" display="inline" id="S3.SS4.p2.2.m2.3"><semantics id="S3.SS4.p2.2.m2.3a"><mrow id="S3.SS4.p2.2.m2.3.3" xref="S3.SS4.p2.2.m2.3.3.cmml"><mi id="S3.SS4.p2.2.m2.3.3.3" xref="S3.SS4.p2.2.m2.3.3.3.cmml">p</mi><mo id="S3.SS4.p2.2.m2.3.3.2" xref="S3.SS4.p2.2.m2.3.3.2.cmml">⁢</mo><mrow id="S3.SS4.p2.2.m2.3.3.1.1" xref="S3.SS4.p2.2.m2.3.3.1.1.1.cmml"><mo id="S3.SS4.p2.2.m2.3.3.1.1.2" stretchy="false" xref="S3.SS4.p2.2.m2.3.3.1.1.1.cmml">(</mo><mrow id="S3.SS4.p2.2.m2.3.3.1.1.1" xref="S3.SS4.p2.2.m2.3.3.1.1.1.cmml"><msubsup id="S3.SS4.p2.2.m2.3.3.1.1.1.2" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.cmml"><mi id="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.2" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.2.cmml">L</mi><mrow id="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.3" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.3.cmml"><mi id="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.3.2" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.3.2.cmml">p</mi><mo id="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.3.1" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.3.1.cmml">⁢</mo><mi id="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.3.3" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.3.3.cmml">a</mi><mo id="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.3.1a" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.3.1.cmml">⁢</mo><mi id="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.3.4" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.3.4.cmml">t</mi><mo id="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.3.1b" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.3.1.cmml">⁢</mo><mi id="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.3.5" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.3.5.cmml">h</mi></mrow><mrow id="S3.SS4.p2.2.m2.3.3.1.1.1.2.3" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.cmml"><mi id="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.2" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.2.cmml">t</mi><mo id="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.1" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.3" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.3.cmml">r</mi><mo id="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.1a" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.4" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.4.cmml">u</mi><mo id="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.1b" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.5" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.5.cmml">n</mi><mo id="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.1c" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.6" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.6.cmml">c</mi></mrow></msubsup><mo fence="false" id="S3.SS4.p2.2.m2.3.3.1.1.1.1" xref="S3.SS4.p2.2.m2.3.3.1.1.1.1.cmml">|</mo><mrow id="S3.SS4.p2.2.m2.3.3.1.1.1.3.2" xref="S3.SS4.p2.2.m2.3.3.1.1.1.3.1.cmml"><mi id="S3.SS4.p2.2.m2.1.1" xref="S3.SS4.p2.2.m2.1.1.cmml">q</mi><mo id="S3.SS4.p2.2.m2.3.3.1.1.1.3.2.1" xref="S3.SS4.p2.2.m2.3.3.1.1.1.3.1.cmml">,</mo><mi id="S3.SS4.p2.2.m2.2.2" xref="S3.SS4.p2.2.m2.2.2.cmml">θ</mi></mrow></mrow><mo id="S3.SS4.p2.2.m2.3.3.1.1.3" stretchy="false" xref="S3.SS4.p2.2.m2.3.3.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.2.m2.3b"><apply id="S3.SS4.p2.2.m2.3.3.cmml" xref="S3.SS4.p2.2.m2.3.3"><times id="S3.SS4.p2.2.m2.3.3.2.cmml" xref="S3.SS4.p2.2.m2.3.3.2"></times><ci id="S3.SS4.p2.2.m2.3.3.3.cmml" xref="S3.SS4.p2.2.m2.3.3.3">𝑝</ci><apply id="S3.SS4.p2.2.m2.3.3.1.1.1.cmml" xref="S3.SS4.p2.2.m2.3.3.1.1"><csymbol cd="latexml" id="S3.SS4.p2.2.m2.3.3.1.1.1.1.cmml" xref="S3.SS4.p2.2.m2.3.3.1.1.1.1">conditional</csymbol><apply id="S3.SS4.p2.2.m2.3.3.1.1.1.2.cmml" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS4.p2.2.m2.3.3.1.1.1.2.1.cmml" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2">superscript</csymbol><apply id="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.cmml" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.1.cmml" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2">subscript</csymbol><ci id="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.2.cmml" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.2">𝐿</ci><apply id="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.3.cmml" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.3"><times id="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.3.1.cmml" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.3.1"></times><ci id="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.3.2.cmml" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.3.2">𝑝</ci><ci id="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.3.3.cmml" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.3.3">𝑎</ci><ci id="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.3.4.cmml" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.3.4">𝑡</ci><ci id="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.3.5.cmml" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.2.3.5">ℎ</ci></apply></apply><apply id="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.cmml" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.3"><times id="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.1.cmml" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.1"></times><ci id="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.2.cmml" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.2">𝑡</ci><ci id="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.3.cmml" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.3">𝑟</ci><ci id="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.4.cmml" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.4">𝑢</ci><ci id="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.5.cmml" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.5">𝑛</ci><ci id="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.6.cmml" xref="S3.SS4.p2.2.m2.3.3.1.1.1.2.3.6">𝑐</ci></apply></apply><list id="S3.SS4.p2.2.m2.3.3.1.1.1.3.1.cmml" xref="S3.SS4.p2.2.m2.3.3.1.1.1.3.2"><ci id="S3.SS4.p2.2.m2.1.1.cmml" xref="S3.SS4.p2.2.m2.1.1">𝑞</ci><ci id="S3.SS4.p2.2.m2.2.2.cmml" xref="S3.SS4.p2.2.m2.2.2">𝜃</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.2.m2.3c">p(L_{path}^{trunc}|q,\theta)</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.2.m2.3d">italic_p ( italic_L start_POSTSUBSCRIPT italic_p italic_a italic_t italic_h end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t italic_r italic_u italic_n italic_c end_POSTSUPERSCRIPT | italic_q , italic_θ )</annotation></semantics></math> is calculated by the generative model trained, and the target SemID is obtained to achieve direct positioning of a group of target videos. In the decoding process, considering the semantic summarization ability of natural language query, which makes videos that meet the description may not be in the same path, we use the Beam Search algorithm for decoding. This enables us to retrieve the top k SemIDs that meet the description, to adapt to this one-to-many issue. Based on the generated SemIDs, we obtain a small candidate set <math alttext="V_{cand}=\{V_{SemID_{1}},V_{SemID_{2}},...,V_{SemID_{k}}\}" class="ltx_Math" display="inline" id="S3.SS4.p2.3.m3.4"><semantics id="S3.SS4.p2.3.m3.4a"><mrow id="S3.SS4.p2.3.m3.4.4" xref="S3.SS4.p2.3.m3.4.4.cmml"><msub id="S3.SS4.p2.3.m3.4.4.5" xref="S3.SS4.p2.3.m3.4.4.5.cmml"><mi id="S3.SS4.p2.3.m3.4.4.5.2" xref="S3.SS4.p2.3.m3.4.4.5.2.cmml">V</mi><mrow id="S3.SS4.p2.3.m3.4.4.5.3" xref="S3.SS4.p2.3.m3.4.4.5.3.cmml"><mi id="S3.SS4.p2.3.m3.4.4.5.3.2" xref="S3.SS4.p2.3.m3.4.4.5.3.2.cmml">c</mi><mo id="S3.SS4.p2.3.m3.4.4.5.3.1" xref="S3.SS4.p2.3.m3.4.4.5.3.1.cmml">⁢</mo><mi id="S3.SS4.p2.3.m3.4.4.5.3.3" xref="S3.SS4.p2.3.m3.4.4.5.3.3.cmml">a</mi><mo id="S3.SS4.p2.3.m3.4.4.5.3.1a" xref="S3.SS4.p2.3.m3.4.4.5.3.1.cmml">⁢</mo><mi id="S3.SS4.p2.3.m3.4.4.5.3.4" xref="S3.SS4.p2.3.m3.4.4.5.3.4.cmml">n</mi><mo id="S3.SS4.p2.3.m3.4.4.5.3.1b" xref="S3.SS4.p2.3.m3.4.4.5.3.1.cmml">⁢</mo><mi id="S3.SS4.p2.3.m3.4.4.5.3.5" xref="S3.SS4.p2.3.m3.4.4.5.3.5.cmml">d</mi></mrow></msub><mo id="S3.SS4.p2.3.m3.4.4.4" xref="S3.SS4.p2.3.m3.4.4.4.cmml">=</mo><mrow id="S3.SS4.p2.3.m3.4.4.3.3" xref="S3.SS4.p2.3.m3.4.4.3.4.cmml"><mo id="S3.SS4.p2.3.m3.4.4.3.3.4" stretchy="false" xref="S3.SS4.p2.3.m3.4.4.3.4.cmml">{</mo><msub id="S3.SS4.p2.3.m3.2.2.1.1.1" xref="S3.SS4.p2.3.m3.2.2.1.1.1.cmml"><mi id="S3.SS4.p2.3.m3.2.2.1.1.1.2" xref="S3.SS4.p2.3.m3.2.2.1.1.1.2.cmml">V</mi><mrow id="S3.SS4.p2.3.m3.2.2.1.1.1.3" xref="S3.SS4.p2.3.m3.2.2.1.1.1.3.cmml"><mi id="S3.SS4.p2.3.m3.2.2.1.1.1.3.2" xref="S3.SS4.p2.3.m3.2.2.1.1.1.3.2.cmml">S</mi><mo id="S3.SS4.p2.3.m3.2.2.1.1.1.3.1" xref="S3.SS4.p2.3.m3.2.2.1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.p2.3.m3.2.2.1.1.1.3.3" xref="S3.SS4.p2.3.m3.2.2.1.1.1.3.3.cmml">e</mi><mo id="S3.SS4.p2.3.m3.2.2.1.1.1.3.1a" xref="S3.SS4.p2.3.m3.2.2.1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.p2.3.m3.2.2.1.1.1.3.4" xref="S3.SS4.p2.3.m3.2.2.1.1.1.3.4.cmml">m</mi><mo id="S3.SS4.p2.3.m3.2.2.1.1.1.3.1b" xref="S3.SS4.p2.3.m3.2.2.1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.p2.3.m3.2.2.1.1.1.3.5" xref="S3.SS4.p2.3.m3.2.2.1.1.1.3.5.cmml">I</mi><mo id="S3.SS4.p2.3.m3.2.2.1.1.1.3.1c" xref="S3.SS4.p2.3.m3.2.2.1.1.1.3.1.cmml">⁢</mo><msub id="S3.SS4.p2.3.m3.2.2.1.1.1.3.6" xref="S3.SS4.p2.3.m3.2.2.1.1.1.3.6.cmml"><mi id="S3.SS4.p2.3.m3.2.2.1.1.1.3.6.2" xref="S3.SS4.p2.3.m3.2.2.1.1.1.3.6.2.cmml">D</mi><mn id="S3.SS4.p2.3.m3.2.2.1.1.1.3.6.3" xref="S3.SS4.p2.3.m3.2.2.1.1.1.3.6.3.cmml">1</mn></msub></mrow></msub><mo id="S3.SS4.p2.3.m3.4.4.3.3.5" xref="S3.SS4.p2.3.m3.4.4.3.4.cmml">,</mo><msub id="S3.SS4.p2.3.m3.3.3.2.2.2" xref="S3.SS4.p2.3.m3.3.3.2.2.2.cmml"><mi id="S3.SS4.p2.3.m3.3.3.2.2.2.2" xref="S3.SS4.p2.3.m3.3.3.2.2.2.2.cmml">V</mi><mrow id="S3.SS4.p2.3.m3.3.3.2.2.2.3" xref="S3.SS4.p2.3.m3.3.3.2.2.2.3.cmml"><mi id="S3.SS4.p2.3.m3.3.3.2.2.2.3.2" xref="S3.SS4.p2.3.m3.3.3.2.2.2.3.2.cmml">S</mi><mo id="S3.SS4.p2.3.m3.3.3.2.2.2.3.1" xref="S3.SS4.p2.3.m3.3.3.2.2.2.3.1.cmml">⁢</mo><mi id="S3.SS4.p2.3.m3.3.3.2.2.2.3.3" xref="S3.SS4.p2.3.m3.3.3.2.2.2.3.3.cmml">e</mi><mo id="S3.SS4.p2.3.m3.3.3.2.2.2.3.1a" xref="S3.SS4.p2.3.m3.3.3.2.2.2.3.1.cmml">⁢</mo><mi id="S3.SS4.p2.3.m3.3.3.2.2.2.3.4" xref="S3.SS4.p2.3.m3.3.3.2.2.2.3.4.cmml">m</mi><mo id="S3.SS4.p2.3.m3.3.3.2.2.2.3.1b" xref="S3.SS4.p2.3.m3.3.3.2.2.2.3.1.cmml">⁢</mo><mi id="S3.SS4.p2.3.m3.3.3.2.2.2.3.5" xref="S3.SS4.p2.3.m3.3.3.2.2.2.3.5.cmml">I</mi><mo id="S3.SS4.p2.3.m3.3.3.2.2.2.3.1c" xref="S3.SS4.p2.3.m3.3.3.2.2.2.3.1.cmml">⁢</mo><msub id="S3.SS4.p2.3.m3.3.3.2.2.2.3.6" xref="S3.SS4.p2.3.m3.3.3.2.2.2.3.6.cmml"><mi id="S3.SS4.p2.3.m3.3.3.2.2.2.3.6.2" xref="S3.SS4.p2.3.m3.3.3.2.2.2.3.6.2.cmml">D</mi><mn id="S3.SS4.p2.3.m3.3.3.2.2.2.3.6.3" xref="S3.SS4.p2.3.m3.3.3.2.2.2.3.6.3.cmml">2</mn></msub></mrow></msub><mo id="S3.SS4.p2.3.m3.4.4.3.3.6" xref="S3.SS4.p2.3.m3.4.4.3.4.cmml">,</mo><mi id="S3.SS4.p2.3.m3.1.1" mathvariant="normal" xref="S3.SS4.p2.3.m3.1.1.cmml">…</mi><mo id="S3.SS4.p2.3.m3.4.4.3.3.7" xref="S3.SS4.p2.3.m3.4.4.3.4.cmml">,</mo><msub id="S3.SS4.p2.3.m3.4.4.3.3.3" xref="S3.SS4.p2.3.m3.4.4.3.3.3.cmml"><mi id="S3.SS4.p2.3.m3.4.4.3.3.3.2" xref="S3.SS4.p2.3.m3.4.4.3.3.3.2.cmml">V</mi><mrow id="S3.SS4.p2.3.m3.4.4.3.3.3.3" xref="S3.SS4.p2.3.m3.4.4.3.3.3.3.cmml"><mi id="S3.SS4.p2.3.m3.4.4.3.3.3.3.2" xref="S3.SS4.p2.3.m3.4.4.3.3.3.3.2.cmml">S</mi><mo id="S3.SS4.p2.3.m3.4.4.3.3.3.3.1" xref="S3.SS4.p2.3.m3.4.4.3.3.3.3.1.cmml">⁢</mo><mi id="S3.SS4.p2.3.m3.4.4.3.3.3.3.3" xref="S3.SS4.p2.3.m3.4.4.3.3.3.3.3.cmml">e</mi><mo id="S3.SS4.p2.3.m3.4.4.3.3.3.3.1a" xref="S3.SS4.p2.3.m3.4.4.3.3.3.3.1.cmml">⁢</mo><mi id="S3.SS4.p2.3.m3.4.4.3.3.3.3.4" xref="S3.SS4.p2.3.m3.4.4.3.3.3.3.4.cmml">m</mi><mo id="S3.SS4.p2.3.m3.4.4.3.3.3.3.1b" xref="S3.SS4.p2.3.m3.4.4.3.3.3.3.1.cmml">⁢</mo><mi id="S3.SS4.p2.3.m3.4.4.3.3.3.3.5" xref="S3.SS4.p2.3.m3.4.4.3.3.3.3.5.cmml">I</mi><mo id="S3.SS4.p2.3.m3.4.4.3.3.3.3.1c" xref="S3.SS4.p2.3.m3.4.4.3.3.3.3.1.cmml">⁢</mo><msub id="S3.SS4.p2.3.m3.4.4.3.3.3.3.6" xref="S3.SS4.p2.3.m3.4.4.3.3.3.3.6.cmml"><mi id="S3.SS4.p2.3.m3.4.4.3.3.3.3.6.2" xref="S3.SS4.p2.3.m3.4.4.3.3.3.3.6.2.cmml">D</mi><mi id="S3.SS4.p2.3.m3.4.4.3.3.3.3.6.3" xref="S3.SS4.p2.3.m3.4.4.3.3.3.3.6.3.cmml">k</mi></msub></mrow></msub><mo id="S3.SS4.p2.3.m3.4.4.3.3.8" stretchy="false" xref="S3.SS4.p2.3.m3.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.3.m3.4b"><apply id="S3.SS4.p2.3.m3.4.4.cmml" xref="S3.SS4.p2.3.m3.4.4"><eq id="S3.SS4.p2.3.m3.4.4.4.cmml" xref="S3.SS4.p2.3.m3.4.4.4"></eq><apply id="S3.SS4.p2.3.m3.4.4.5.cmml" xref="S3.SS4.p2.3.m3.4.4.5"><csymbol cd="ambiguous" id="S3.SS4.p2.3.m3.4.4.5.1.cmml" xref="S3.SS4.p2.3.m3.4.4.5">subscript</csymbol><ci id="S3.SS4.p2.3.m3.4.4.5.2.cmml" xref="S3.SS4.p2.3.m3.4.4.5.2">𝑉</ci><apply id="S3.SS4.p2.3.m3.4.4.5.3.cmml" xref="S3.SS4.p2.3.m3.4.4.5.3"><times id="S3.SS4.p2.3.m3.4.4.5.3.1.cmml" xref="S3.SS4.p2.3.m3.4.4.5.3.1"></times><ci id="S3.SS4.p2.3.m3.4.4.5.3.2.cmml" xref="S3.SS4.p2.3.m3.4.4.5.3.2">𝑐</ci><ci id="S3.SS4.p2.3.m3.4.4.5.3.3.cmml" xref="S3.SS4.p2.3.m3.4.4.5.3.3">𝑎</ci><ci id="S3.SS4.p2.3.m3.4.4.5.3.4.cmml" xref="S3.SS4.p2.3.m3.4.4.5.3.4">𝑛</ci><ci id="S3.SS4.p2.3.m3.4.4.5.3.5.cmml" xref="S3.SS4.p2.3.m3.4.4.5.3.5">𝑑</ci></apply></apply><set id="S3.SS4.p2.3.m3.4.4.3.4.cmml" xref="S3.SS4.p2.3.m3.4.4.3.3"><apply id="S3.SS4.p2.3.m3.2.2.1.1.1.cmml" xref="S3.SS4.p2.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.3.m3.2.2.1.1.1.1.cmml" xref="S3.SS4.p2.3.m3.2.2.1.1.1">subscript</csymbol><ci id="S3.SS4.p2.3.m3.2.2.1.1.1.2.cmml" xref="S3.SS4.p2.3.m3.2.2.1.1.1.2">𝑉</ci><apply id="S3.SS4.p2.3.m3.2.2.1.1.1.3.cmml" xref="S3.SS4.p2.3.m3.2.2.1.1.1.3"><times id="S3.SS4.p2.3.m3.2.2.1.1.1.3.1.cmml" xref="S3.SS4.p2.3.m3.2.2.1.1.1.3.1"></times><ci id="S3.SS4.p2.3.m3.2.2.1.1.1.3.2.cmml" xref="S3.SS4.p2.3.m3.2.2.1.1.1.3.2">𝑆</ci><ci id="S3.SS4.p2.3.m3.2.2.1.1.1.3.3.cmml" xref="S3.SS4.p2.3.m3.2.2.1.1.1.3.3">𝑒</ci><ci id="S3.SS4.p2.3.m3.2.2.1.1.1.3.4.cmml" xref="S3.SS4.p2.3.m3.2.2.1.1.1.3.4">𝑚</ci><ci id="S3.SS4.p2.3.m3.2.2.1.1.1.3.5.cmml" xref="S3.SS4.p2.3.m3.2.2.1.1.1.3.5">𝐼</ci><apply id="S3.SS4.p2.3.m3.2.2.1.1.1.3.6.cmml" xref="S3.SS4.p2.3.m3.2.2.1.1.1.3.6"><csymbol cd="ambiguous" id="S3.SS4.p2.3.m3.2.2.1.1.1.3.6.1.cmml" xref="S3.SS4.p2.3.m3.2.2.1.1.1.3.6">subscript</csymbol><ci id="S3.SS4.p2.3.m3.2.2.1.1.1.3.6.2.cmml" xref="S3.SS4.p2.3.m3.2.2.1.1.1.3.6.2">𝐷</ci><cn id="S3.SS4.p2.3.m3.2.2.1.1.1.3.6.3.cmml" type="integer" xref="S3.SS4.p2.3.m3.2.2.1.1.1.3.6.3">1</cn></apply></apply></apply><apply id="S3.SS4.p2.3.m3.3.3.2.2.2.cmml" xref="S3.SS4.p2.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS4.p2.3.m3.3.3.2.2.2.1.cmml" xref="S3.SS4.p2.3.m3.3.3.2.2.2">subscript</csymbol><ci id="S3.SS4.p2.3.m3.3.3.2.2.2.2.cmml" xref="S3.SS4.p2.3.m3.3.3.2.2.2.2">𝑉</ci><apply id="S3.SS4.p2.3.m3.3.3.2.2.2.3.cmml" xref="S3.SS4.p2.3.m3.3.3.2.2.2.3"><times id="S3.SS4.p2.3.m3.3.3.2.2.2.3.1.cmml" xref="S3.SS4.p2.3.m3.3.3.2.2.2.3.1"></times><ci id="S3.SS4.p2.3.m3.3.3.2.2.2.3.2.cmml" xref="S3.SS4.p2.3.m3.3.3.2.2.2.3.2">𝑆</ci><ci id="S3.SS4.p2.3.m3.3.3.2.2.2.3.3.cmml" xref="S3.SS4.p2.3.m3.3.3.2.2.2.3.3">𝑒</ci><ci id="S3.SS4.p2.3.m3.3.3.2.2.2.3.4.cmml" xref="S3.SS4.p2.3.m3.3.3.2.2.2.3.4">𝑚</ci><ci id="S3.SS4.p2.3.m3.3.3.2.2.2.3.5.cmml" xref="S3.SS4.p2.3.m3.3.3.2.2.2.3.5">𝐼</ci><apply id="S3.SS4.p2.3.m3.3.3.2.2.2.3.6.cmml" xref="S3.SS4.p2.3.m3.3.3.2.2.2.3.6"><csymbol cd="ambiguous" id="S3.SS4.p2.3.m3.3.3.2.2.2.3.6.1.cmml" xref="S3.SS4.p2.3.m3.3.3.2.2.2.3.6">subscript</csymbol><ci id="S3.SS4.p2.3.m3.3.3.2.2.2.3.6.2.cmml" xref="S3.SS4.p2.3.m3.3.3.2.2.2.3.6.2">𝐷</ci><cn id="S3.SS4.p2.3.m3.3.3.2.2.2.3.6.3.cmml" type="integer" xref="S3.SS4.p2.3.m3.3.3.2.2.2.3.6.3">2</cn></apply></apply></apply><ci id="S3.SS4.p2.3.m3.1.1.cmml" xref="S3.SS4.p2.3.m3.1.1">…</ci><apply id="S3.SS4.p2.3.m3.4.4.3.3.3.cmml" xref="S3.SS4.p2.3.m3.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS4.p2.3.m3.4.4.3.3.3.1.cmml" xref="S3.SS4.p2.3.m3.4.4.3.3.3">subscript</csymbol><ci id="S3.SS4.p2.3.m3.4.4.3.3.3.2.cmml" xref="S3.SS4.p2.3.m3.4.4.3.3.3.2">𝑉</ci><apply id="S3.SS4.p2.3.m3.4.4.3.3.3.3.cmml" xref="S3.SS4.p2.3.m3.4.4.3.3.3.3"><times id="S3.SS4.p2.3.m3.4.4.3.3.3.3.1.cmml" xref="S3.SS4.p2.3.m3.4.4.3.3.3.3.1"></times><ci id="S3.SS4.p2.3.m3.4.4.3.3.3.3.2.cmml" xref="S3.SS4.p2.3.m3.4.4.3.3.3.3.2">𝑆</ci><ci id="S3.SS4.p2.3.m3.4.4.3.3.3.3.3.cmml" xref="S3.SS4.p2.3.m3.4.4.3.3.3.3.3">𝑒</ci><ci id="S3.SS4.p2.3.m3.4.4.3.3.3.3.4.cmml" xref="S3.SS4.p2.3.m3.4.4.3.3.3.3.4">𝑚</ci><ci id="S3.SS4.p2.3.m3.4.4.3.3.3.3.5.cmml" xref="S3.SS4.p2.3.m3.4.4.3.3.3.3.5">𝐼</ci><apply id="S3.SS4.p2.3.m3.4.4.3.3.3.3.6.cmml" xref="S3.SS4.p2.3.m3.4.4.3.3.3.3.6"><csymbol cd="ambiguous" id="S3.SS4.p2.3.m3.4.4.3.3.3.3.6.1.cmml" xref="S3.SS4.p2.3.m3.4.4.3.3.3.3.6">subscript</csymbol><ci id="S3.SS4.p2.3.m3.4.4.3.3.3.3.6.2.cmml" xref="S3.SS4.p2.3.m3.4.4.3.3.3.3.6.2">𝐷</ci><ci id="S3.SS4.p2.3.m3.4.4.3.3.3.3.6.3.cmml" xref="S3.SS4.p2.3.m3.4.4.3.3.3.3.6.3">𝑘</ci></apply></apply></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.3.m3.4c">V_{cand}=\{V_{SemID_{1}},V_{SemID_{2}},...,V_{SemID_{k}}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.3.m3.4d">italic_V start_POSTSUBSCRIPT italic_c italic_a italic_n italic_d end_POSTSUBSCRIPT = { italic_V start_POSTSUBSCRIPT italic_S italic_e italic_m italic_I italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , italic_V start_POSTSUBSCRIPT italic_S italic_e italic_m italic_I italic_D start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , … , italic_V start_POSTSUBSCRIPT italic_S italic_e italic_m italic_I italic_D start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT }</annotation></semantics></math> containing the target videos, where <math alttext="SemID_{i}" class="ltx_Math" display="inline" id="S3.SS4.p2.4.m4.1"><semantics id="S3.SS4.p2.4.m4.1a"><mrow id="S3.SS4.p2.4.m4.1.1" xref="S3.SS4.p2.4.m4.1.1.cmml"><mi id="S3.SS4.p2.4.m4.1.1.2" xref="S3.SS4.p2.4.m4.1.1.2.cmml">S</mi><mo id="S3.SS4.p2.4.m4.1.1.1" xref="S3.SS4.p2.4.m4.1.1.1.cmml">⁢</mo><mi id="S3.SS4.p2.4.m4.1.1.3" xref="S3.SS4.p2.4.m4.1.1.3.cmml">e</mi><mo id="S3.SS4.p2.4.m4.1.1.1a" xref="S3.SS4.p2.4.m4.1.1.1.cmml">⁢</mo><mi id="S3.SS4.p2.4.m4.1.1.4" xref="S3.SS4.p2.4.m4.1.1.4.cmml">m</mi><mo id="S3.SS4.p2.4.m4.1.1.1b" xref="S3.SS4.p2.4.m4.1.1.1.cmml">⁢</mo><mi id="S3.SS4.p2.4.m4.1.1.5" xref="S3.SS4.p2.4.m4.1.1.5.cmml">I</mi><mo id="S3.SS4.p2.4.m4.1.1.1c" xref="S3.SS4.p2.4.m4.1.1.1.cmml">⁢</mo><msub id="S3.SS4.p2.4.m4.1.1.6" xref="S3.SS4.p2.4.m4.1.1.6.cmml"><mi id="S3.SS4.p2.4.m4.1.1.6.2" xref="S3.SS4.p2.4.m4.1.1.6.2.cmml">D</mi><mi id="S3.SS4.p2.4.m4.1.1.6.3" xref="S3.SS4.p2.4.m4.1.1.6.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.4.m4.1b"><apply id="S3.SS4.p2.4.m4.1.1.cmml" xref="S3.SS4.p2.4.m4.1.1"><times id="S3.SS4.p2.4.m4.1.1.1.cmml" xref="S3.SS4.p2.4.m4.1.1.1"></times><ci id="S3.SS4.p2.4.m4.1.1.2.cmml" xref="S3.SS4.p2.4.m4.1.1.2">𝑆</ci><ci id="S3.SS4.p2.4.m4.1.1.3.cmml" xref="S3.SS4.p2.4.m4.1.1.3">𝑒</ci><ci id="S3.SS4.p2.4.m4.1.1.4.cmml" xref="S3.SS4.p2.4.m4.1.1.4">𝑚</ci><ci id="S3.SS4.p2.4.m4.1.1.5.cmml" xref="S3.SS4.p2.4.m4.1.1.5">𝐼</ci><apply id="S3.SS4.p2.4.m4.1.1.6.cmml" xref="S3.SS4.p2.4.m4.1.1.6"><csymbol cd="ambiguous" id="S3.SS4.p2.4.m4.1.1.6.1.cmml" xref="S3.SS4.p2.4.m4.1.1.6">subscript</csymbol><ci id="S3.SS4.p2.4.m4.1.1.6.2.cmml" xref="S3.SS4.p2.4.m4.1.1.6.2">𝐷</ci><ci id="S3.SS4.p2.4.m4.1.1.6.3.cmml" xref="S3.SS4.p2.4.m4.1.1.6.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.4.m4.1c">SemID_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.4.m4.1d">italic_S italic_e italic_m italic_I italic_D start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> represents a group of videos corresponding to the i-th top SemID generated.</p>
</div>
<div class="ltx_para" id="S3.SS4.p3">
<p class="ltx_p" id="S3.SS4.p3.8">Due to the limitations of the first stage, it is currently not feasible to achieve precise retrieval based on the query. In order to meet the requirements of the task and achieve precise retrieval, fine-tuning of <math alttext="V_{cand}" class="ltx_Math" display="inline" id="S3.SS4.p3.1.m1.1"><semantics id="S3.SS4.p3.1.m1.1a"><msub id="S3.SS4.p3.1.m1.1.1" xref="S3.SS4.p3.1.m1.1.1.cmml"><mi id="S3.SS4.p3.1.m1.1.1.2" xref="S3.SS4.p3.1.m1.1.1.2.cmml">V</mi><mrow id="S3.SS4.p3.1.m1.1.1.3" xref="S3.SS4.p3.1.m1.1.1.3.cmml"><mi id="S3.SS4.p3.1.m1.1.1.3.2" xref="S3.SS4.p3.1.m1.1.1.3.2.cmml">c</mi><mo id="S3.SS4.p3.1.m1.1.1.3.1" xref="S3.SS4.p3.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.p3.1.m1.1.1.3.3" xref="S3.SS4.p3.1.m1.1.1.3.3.cmml">a</mi><mo id="S3.SS4.p3.1.m1.1.1.3.1a" xref="S3.SS4.p3.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.p3.1.m1.1.1.3.4" xref="S3.SS4.p3.1.m1.1.1.3.4.cmml">n</mi><mo id="S3.SS4.p3.1.m1.1.1.3.1b" xref="S3.SS4.p3.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.p3.1.m1.1.1.3.5" xref="S3.SS4.p3.1.m1.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.1.m1.1b"><apply id="S3.SS4.p3.1.m1.1.1.cmml" xref="S3.SS4.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p3.1.m1.1.1.1.cmml" xref="S3.SS4.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.p3.1.m1.1.1.2.cmml" xref="S3.SS4.p3.1.m1.1.1.2">𝑉</ci><apply id="S3.SS4.p3.1.m1.1.1.3.cmml" xref="S3.SS4.p3.1.m1.1.1.3"><times id="S3.SS4.p3.1.m1.1.1.3.1.cmml" xref="S3.SS4.p3.1.m1.1.1.3.1"></times><ci id="S3.SS4.p3.1.m1.1.1.3.2.cmml" xref="S3.SS4.p3.1.m1.1.1.3.2">𝑐</ci><ci id="S3.SS4.p3.1.m1.1.1.3.3.cmml" xref="S3.SS4.p3.1.m1.1.1.3.3">𝑎</ci><ci id="S3.SS4.p3.1.m1.1.1.3.4.cmml" xref="S3.SS4.p3.1.m1.1.1.3.4">𝑛</ci><ci id="S3.SS4.p3.1.m1.1.1.3.5.cmml" xref="S3.SS4.p3.1.m1.1.1.3.5">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.1.m1.1c">V_{cand}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p3.1.m1.1d">italic_V start_POSTSUBSCRIPT italic_c italic_a italic_n italic_d end_POSTSUBSCRIPT</annotation></semantics></math> is required. For this purpose, we introduce a two-stage retrieval architecture and use the existing text-video retrieval model for precise retrieval in <math alttext="V_{cand}" class="ltx_Math" display="inline" id="S3.SS4.p3.2.m2.1"><semantics id="S3.SS4.p3.2.m2.1a"><msub id="S3.SS4.p3.2.m2.1.1" xref="S3.SS4.p3.2.m2.1.1.cmml"><mi id="S3.SS4.p3.2.m2.1.1.2" xref="S3.SS4.p3.2.m2.1.1.2.cmml">V</mi><mrow id="S3.SS4.p3.2.m2.1.1.3" xref="S3.SS4.p3.2.m2.1.1.3.cmml"><mi id="S3.SS4.p3.2.m2.1.1.3.2" xref="S3.SS4.p3.2.m2.1.1.3.2.cmml">c</mi><mo id="S3.SS4.p3.2.m2.1.1.3.1" xref="S3.SS4.p3.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.p3.2.m2.1.1.3.3" xref="S3.SS4.p3.2.m2.1.1.3.3.cmml">a</mi><mo id="S3.SS4.p3.2.m2.1.1.3.1a" xref="S3.SS4.p3.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.p3.2.m2.1.1.3.4" xref="S3.SS4.p3.2.m2.1.1.3.4.cmml">n</mi><mo id="S3.SS4.p3.2.m2.1.1.3.1b" xref="S3.SS4.p3.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.p3.2.m2.1.1.3.5" xref="S3.SS4.p3.2.m2.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.2.m2.1b"><apply id="S3.SS4.p3.2.m2.1.1.cmml" xref="S3.SS4.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.p3.2.m2.1.1.1.cmml" xref="S3.SS4.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS4.p3.2.m2.1.1.2.cmml" xref="S3.SS4.p3.2.m2.1.1.2">𝑉</ci><apply id="S3.SS4.p3.2.m2.1.1.3.cmml" xref="S3.SS4.p3.2.m2.1.1.3"><times id="S3.SS4.p3.2.m2.1.1.3.1.cmml" xref="S3.SS4.p3.2.m2.1.1.3.1"></times><ci id="S3.SS4.p3.2.m2.1.1.3.2.cmml" xref="S3.SS4.p3.2.m2.1.1.3.2">𝑐</ci><ci id="S3.SS4.p3.2.m2.1.1.3.3.cmml" xref="S3.SS4.p3.2.m2.1.1.3.3">𝑎</ci><ci id="S3.SS4.p3.2.m2.1.1.3.4.cmml" xref="S3.SS4.p3.2.m2.1.1.3.4">𝑛</ci><ci id="S3.SS4.p3.2.m2.1.1.3.5.cmml" xref="S3.SS4.p3.2.m2.1.1.3.5">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.2.m2.1c">V_{cand}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p3.2.m2.1d">italic_V start_POSTSUBSCRIPT italic_c italic_a italic_n italic_d end_POSTSUBSCRIPT</annotation></semantics></math>. T2VIndexer can be integrated with the existing retrieval model without adjusting the training parameters. For a text-video retrieval model <math alttext="M_{base}" class="ltx_Math" display="inline" id="S3.SS4.p3.3.m3.1"><semantics id="S3.SS4.p3.3.m3.1a"><msub id="S3.SS4.p3.3.m3.1.1" xref="S3.SS4.p3.3.m3.1.1.cmml"><mi id="S3.SS4.p3.3.m3.1.1.2" xref="S3.SS4.p3.3.m3.1.1.2.cmml">M</mi><mrow id="S3.SS4.p3.3.m3.1.1.3" xref="S3.SS4.p3.3.m3.1.1.3.cmml"><mi id="S3.SS4.p3.3.m3.1.1.3.2" xref="S3.SS4.p3.3.m3.1.1.3.2.cmml">b</mi><mo id="S3.SS4.p3.3.m3.1.1.3.1" xref="S3.SS4.p3.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.p3.3.m3.1.1.3.3" xref="S3.SS4.p3.3.m3.1.1.3.3.cmml">a</mi><mo id="S3.SS4.p3.3.m3.1.1.3.1a" xref="S3.SS4.p3.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.p3.3.m3.1.1.3.4" xref="S3.SS4.p3.3.m3.1.1.3.4.cmml">s</mi><mo id="S3.SS4.p3.3.m3.1.1.3.1b" xref="S3.SS4.p3.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.p3.3.m3.1.1.3.5" xref="S3.SS4.p3.3.m3.1.1.3.5.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.3.m3.1b"><apply id="S3.SS4.p3.3.m3.1.1.cmml" xref="S3.SS4.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS4.p3.3.m3.1.1.1.cmml" xref="S3.SS4.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS4.p3.3.m3.1.1.2.cmml" xref="S3.SS4.p3.3.m3.1.1.2">𝑀</ci><apply id="S3.SS4.p3.3.m3.1.1.3.cmml" xref="S3.SS4.p3.3.m3.1.1.3"><times id="S3.SS4.p3.3.m3.1.1.3.1.cmml" xref="S3.SS4.p3.3.m3.1.1.3.1"></times><ci id="S3.SS4.p3.3.m3.1.1.3.2.cmml" xref="S3.SS4.p3.3.m3.1.1.3.2">𝑏</ci><ci id="S3.SS4.p3.3.m3.1.1.3.3.cmml" xref="S3.SS4.p3.3.m3.1.1.3.3">𝑎</ci><ci id="S3.SS4.p3.3.m3.1.1.3.4.cmml" xref="S3.SS4.p3.3.m3.1.1.3.4">𝑠</ci><ci id="S3.SS4.p3.3.m3.1.1.3.5.cmml" xref="S3.SS4.p3.3.m3.1.1.3.5">𝑒</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.3.m3.1c">M_{base}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p3.3.m3.1d">italic_M start_POSTSUBSCRIPT italic_b italic_a italic_s italic_e end_POSTSUBSCRIPT</annotation></semantics></math>, the similarity <math alttext="s" class="ltx_Math" display="inline" id="S3.SS4.p3.4.m4.1"><semantics id="S3.SS4.p3.4.m4.1a"><mi id="S3.SS4.p3.4.m4.1.1" xref="S3.SS4.p3.4.m4.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.4.m4.1b"><ci id="S3.SS4.p3.4.m4.1.1.cmml" xref="S3.SS4.p3.4.m4.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.4.m4.1c">s</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p3.4.m4.1d">italic_s</annotation></semantics></math> between <math alttext="q" class="ltx_Math" display="inline" id="S3.SS4.p3.5.m5.1"><semantics id="S3.SS4.p3.5.m5.1a"><mi id="S3.SS4.p3.5.m5.1.1" xref="S3.SS4.p3.5.m5.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.5.m5.1b"><ci id="S3.SS4.p3.5.m5.1.1.cmml" xref="S3.SS4.p3.5.m5.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.5.m5.1c">q</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p3.5.m5.1d">italic_q</annotation></semantics></math> and each video <math alttext="v" class="ltx_Math" display="inline" id="S3.SS4.p3.6.m6.1"><semantics id="S3.SS4.p3.6.m6.1a"><mi id="S3.SS4.p3.6.m6.1.1" xref="S3.SS4.p3.6.m6.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.6.m6.1b"><ci id="S3.SS4.p3.6.m6.1.1.cmml" xref="S3.SS4.p3.6.m6.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.6.m6.1c">v</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p3.6.m6.1d">italic_v</annotation></semantics></math> in <math alttext="V_{cand}" class="ltx_Math" display="inline" id="S3.SS4.p3.7.m7.1"><semantics id="S3.SS4.p3.7.m7.1a"><msub id="S3.SS4.p3.7.m7.1.1" xref="S3.SS4.p3.7.m7.1.1.cmml"><mi id="S3.SS4.p3.7.m7.1.1.2" xref="S3.SS4.p3.7.m7.1.1.2.cmml">V</mi><mrow id="S3.SS4.p3.7.m7.1.1.3" xref="S3.SS4.p3.7.m7.1.1.3.cmml"><mi id="S3.SS4.p3.7.m7.1.1.3.2" xref="S3.SS4.p3.7.m7.1.1.3.2.cmml">c</mi><mo id="S3.SS4.p3.7.m7.1.1.3.1" xref="S3.SS4.p3.7.m7.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.p3.7.m7.1.1.3.3" xref="S3.SS4.p3.7.m7.1.1.3.3.cmml">a</mi><mo id="S3.SS4.p3.7.m7.1.1.3.1a" xref="S3.SS4.p3.7.m7.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.p3.7.m7.1.1.3.4" xref="S3.SS4.p3.7.m7.1.1.3.4.cmml">n</mi><mo id="S3.SS4.p3.7.m7.1.1.3.1b" xref="S3.SS4.p3.7.m7.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.p3.7.m7.1.1.3.5" xref="S3.SS4.p3.7.m7.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.7.m7.1b"><apply id="S3.SS4.p3.7.m7.1.1.cmml" xref="S3.SS4.p3.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS4.p3.7.m7.1.1.1.cmml" xref="S3.SS4.p3.7.m7.1.1">subscript</csymbol><ci id="S3.SS4.p3.7.m7.1.1.2.cmml" xref="S3.SS4.p3.7.m7.1.1.2">𝑉</ci><apply id="S3.SS4.p3.7.m7.1.1.3.cmml" xref="S3.SS4.p3.7.m7.1.1.3"><times id="S3.SS4.p3.7.m7.1.1.3.1.cmml" xref="S3.SS4.p3.7.m7.1.1.3.1"></times><ci id="S3.SS4.p3.7.m7.1.1.3.2.cmml" xref="S3.SS4.p3.7.m7.1.1.3.2">𝑐</ci><ci id="S3.SS4.p3.7.m7.1.1.3.3.cmml" xref="S3.SS4.p3.7.m7.1.1.3.3">𝑎</ci><ci id="S3.SS4.p3.7.m7.1.1.3.4.cmml" xref="S3.SS4.p3.7.m7.1.1.3.4">𝑛</ci><ci id="S3.SS4.p3.7.m7.1.1.3.5.cmml" xref="S3.SS4.p3.7.m7.1.1.3.5">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.7.m7.1c">V_{cand}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p3.7.m7.1d">italic_V start_POSTSUBSCRIPT italic_c italic_a italic_n italic_d end_POSTSUBSCRIPT</annotation></semantics></math> is calculated, and the final retrieval result is obtained by ranking <math alttext="s" class="ltx_Math" display="inline" id="S3.SS4.p3.8.m8.1"><semantics id="S3.SS4.p3.8.m8.1a"><mi id="S3.SS4.p3.8.m8.1.1" xref="S3.SS4.p3.8.m8.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.8.m8.1b"><ci id="S3.SS4.p3.8.m8.1.1.cmml" xref="S3.SS4.p3.8.m8.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.8.m8.1c">s</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p3.8.m8.1d">italic_s</annotation></semantics></math>. Overall, the entire retrieval process can be divided into two main stages: Pre-select based on generative models and Precise Recall based on contrastive learning models.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Experiments</h2>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1. </span>Evaluation of the inference costs on MSR-VTT dataset. We report the R@1 metric for the text-to-video task. <span class="ltx_text" id="S4.T1.3.1" style="color:#000AFF;"> Blue</span> means stage 1 generative time cost, and <span class="ltx_text" id="S4.T1.4.2" style="color:#FE0000;"> red</span> means stage 2 time cost. The improvement of inference time refers to the compression ratio of T2VIndexer, which is obtained by dividing the inference time with T2VIndexer by the inference time of the baseline.</figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T1.5" style="width:433.6pt;height:92.9pt;vertical-align:-0.5pt;"><span class="ltx_transformed_inner" style="transform:translate(-247.8pt,52.8pt) scale(0.466612647787031,0.466612647787031) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T1.5.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.5.1.1.1">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.5.1.1.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2" id="S4.T1.5.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T1.5.1.1.1.2.1">#Candidate 1000</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2" id="S4.T1.5.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T1.5.1.1.1.3.1">#Candidate 3000</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2" id="S4.T1.5.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T1.5.1.1.1.4.1">#Candidate 5000</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="S4.T1.5.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S4.T1.5.1.1.1.5.1">#Candidate 10000</span></th>
</tr>
<tr class="ltx_tr" id="S4.T1.5.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r" id="S4.T1.5.1.2.2.1"><span class="ltx_text ltx_font_bold" id="S4.T1.5.1.2.2.1.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.5.1.2.2.2"><span class="ltx_text ltx_font_bold" id="S4.T1.5.1.2.2.2.1">Inference Time(ms)↓</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T1.5.1.2.2.3"><span class="ltx_text ltx_font_bold" id="S4.T1.5.1.2.2.3.1">R@1↑</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.5.1.2.2.4"><span class="ltx_text ltx_font_bold" id="S4.T1.5.1.2.2.4.1">Inference Time(ms)↓</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T1.5.1.2.2.5"><span class="ltx_text ltx_font_bold" id="S4.T1.5.1.2.2.5.1">R@1↑</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.5.1.2.2.6"><span class="ltx_text ltx_font_bold" id="S4.T1.5.1.2.2.6.1">Inference Time(ms)↓</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T1.5.1.2.2.7"><span class="ltx_text ltx_font_bold" id="S4.T1.5.1.2.2.7.1">R@1↑</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.5.1.2.2.8"><span class="ltx_text ltx_font_bold" id="S4.T1.5.1.2.2.8.1">Inference Time(ms)↓</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.5.1.2.2.9"><span class="ltx_text ltx_font_bold" id="S4.T1.5.1.2.2.9.1">R@1↑</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.5.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.5.1.3.1.1">CLIP4Clip <cite class="ltx_cite ltx_citemacro_citep">(Luo et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib16" title="">2022</a>)</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.3.1.2">220</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.5.1.3.1.3">44.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.3.1.4">681</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.5.1.3.1.5">36.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.3.1.6">1139</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.5.1.3.1.7">31.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.3.1.8">2341</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.3.1.9">25.4</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T1.5.1.4.2.1">CLIP4Clip+T2VIndexer</th>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.4.2.2">105 (<span class="ltx_text" id="S4.T1.5.1.4.2.2.1" style="color:#000AFF;"> 52</span>+<span class="ltx_text" id="S4.T1.5.1.4.2.2.2" style="color:#FE0000;"> 53</span>)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.1.4.2.3">47.8</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.4.2.4">218 (<span class="ltx_text" id="S4.T1.5.1.4.2.4.1" style="color:#000AFF;"> 52</span>+<span class="ltx_text" id="S4.T1.5.1.4.2.4.2" style="color:#FE0000;"> 166</span>)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.1.4.2.5">40.3</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.4.2.6">336 (<span class="ltx_text" id="S4.T1.5.1.4.2.6.1" style="color:#000AFF;"> 52</span>+<span class="ltx_text" id="S4.T1.5.1.4.2.6.2" style="color:#FE0000;"> 284</span>)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.1.4.2.7">35.1</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.4.2.8">639 (<span class="ltx_text" id="S4.T1.5.1.4.2.8.1" style="color:#000AFF;"> 52</span>+<span class="ltx_text" id="S4.T1.5.1.4.2.8.2" style="color:#FE0000;"> 587</span>)</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.4.2.9">27.3</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T1.5.1.5.3.1">Improvement</th>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.5.3.2">0.47</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.1.5.3.3">3.1</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.5.3.4">0.32</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.1.5.3.5">4.1</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.5.3.6">0.29</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.1.5.3.7">3.5</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.5.3.8">0.27</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.5.3.9">1.9</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.5.1.6.4.1">mPLUG <cite class="ltx_cite ltx_citemacro_citep">(Xu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib25" title="">2023</a>)</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.6.4.2">189</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.5.1.6.4.3">53.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.6.4.4">562</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.5.1.6.4.5">44.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.6.4.6">961</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.5.1.6.4.7">38.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.6.4.8">1741</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.6.4.9">29.1</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.1.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T1.5.1.7.5.1">mPLUG+T2VIndexer</th>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.7.5.2">97 (<span class="ltx_text" id="S4.T1.5.1.7.5.2.1" style="color:#000AFF;"> 52</span>+<span class="ltx_text" id="S4.T1.5.1.7.5.2.2" style="color:#FE0000;"> 45</span>)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.1.7.5.3">54.3</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.7.5.4">189 (<span class="ltx_text" id="S4.T1.5.1.7.5.4.1" style="color:#000AFF;"> 52</span>+<span class="ltx_text" id="S4.T1.5.1.7.5.4.2" style="color:#FE0000;"> 137</span>)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.1.7.5.5">45.8</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.7.5.6">290 (<span class="ltx_text" id="S4.T1.5.1.7.5.6.1" style="color:#000AFF;"> 52</span>+<span class="ltx_text" id="S4.T1.5.1.7.5.6.2" style="color:#FE0000;"> 238</span>)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.1.7.5.7">40.4</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.7.5.8">485 (<span class="ltx_text" id="S4.T1.5.1.7.5.8.1" style="color:#000AFF;"> 52</span>+<span class="ltx_text" id="S4.T1.5.1.7.5.8.2" style="color:#FE0000;"> 433</span>)</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.7.5.9">30.1</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.1.8.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T1.5.1.8.6.1">Improvement</th>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.8.6.2">0.51</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.1.8.6.3">1.3</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.8.6.4">0.34</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.1.8.6.5">1.1</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.8.6.6">0.30</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.1.8.6.7">2.1</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.8.6.8">0.28</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.8.6.9">1.0</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.1.9.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.5.1.9.7.1">CLIP-VIP <cite class="ltx_cite ltx_citemacro_citep">(Xue et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib27" title="">2023</a>)</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.9.7.2">192</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.5.1.9.7.3">54.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.9.7.4">579</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.5.1.9.7.5">48.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.9.7.6">968</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.5.1.9.7.7">40.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.9.7.8">1941</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.1.9.7.9">31.5</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.1.10.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T1.5.1.10.8.1">CLIP-VIP+T2VIndexer</th>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.10.8.2">98 (<span class="ltx_text" id="S4.T1.5.1.10.8.2.1" style="color:#000AFF;"> 52</span>+<span class="ltx_text" id="S4.T1.5.1.10.8.2.2" style="color:#FE0000;"> 46</span>)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.1.10.8.3">55.1</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.10.8.4">194 (<span class="ltx_text" id="S4.T1.5.1.10.8.4.1" style="color:#000AFF;"> 52</span>+<span class="ltx_text" id="S4.T1.5.1.10.8.4.2" style="color:#FE0000;"> 142</span>)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.1.10.8.5">49.3</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.10.8.6">295 (<span class="ltx_text" id="S4.T1.5.1.10.8.6.1" style="color:#000AFF;"> 52</span>+<span class="ltx_text" id="S4.T1.5.1.10.8.6.2" style="color:#FE0000;"> 243</span>)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.1.10.8.7">41.3</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.10.8.8">537 (<span class="ltx_text" id="S4.T1.5.1.10.8.8.1" style="color:#000AFF;"> 52</span>+<span class="ltx_text" id="S4.T1.5.1.10.8.8.2" style="color:#FE0000;"> 485</span>)</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.1.10.8.9">33.1</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.1.11.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r" id="S4.T1.5.1.11.9.1">Improvement</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.5.1.11.9.2">0.51</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T1.5.1.11.9.3">1.0</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.5.1.11.9.4">0.34</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T1.5.1.11.9.5">0.9</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.5.1.11.9.6">0.30</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T1.5.1.11.9.7">1.2</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.5.1.11.9.8">0.28</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.5.1.11.9.9">1.6</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2. </span>Evaluation of the inference costs on MSVD, DiDeMo and ActivityNet dataset. We report the R@1 metric for the text-to-video task. <span class="ltx_text" id="S4.T2.3.1" style="color:#000AFF;"> Blue</span> means stage 1 generative time cost, and <span class="ltx_text" id="S4.T2.4.2" style="color:#FE0000;"> red</span> means stage 2 time cost.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T2.5" style="width:346.9pt;height:87.4pt;vertical-align:-0.4pt;"><span class="ltx_transformed_inner" style="transform:translate(-221.3pt,55.5pt) scale(0.439380102004431,0.439380102004431) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T2.5.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.5.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.5.1.1.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S4.T2.5.1.1.1.1.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2" id="S4.T2.5.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T2.5.1.1.1.2.1">MSVD</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2" id="S4.T2.5.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T2.5.1.1.1.3.1">DiDeMo</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="S4.T2.5.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T2.5.1.1.1.4.1">ActivityNet</span></th>
</tr>
<tr class="ltx_tr" id="S4.T2.5.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.5.1.2.2.1"><span class="ltx_text ltx_font_bold" id="S4.T2.5.1.2.2.1.1">Inference Time(ms)↓</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T2.5.1.2.2.2"><span class="ltx_text ltx_font_bold" id="S4.T2.5.1.2.2.2.1">R@1↑</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.5.1.2.2.3"><span class="ltx_text ltx_font_bold" id="S4.T2.5.1.2.2.3.1">Inference Time(ms)↓</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T2.5.1.2.2.4"><span class="ltx_text ltx_font_bold" id="S4.T2.5.1.2.2.4.1">R@1↑</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.5.1.2.2.5"><span class="ltx_text ltx_font_bold" id="S4.T2.5.1.2.2.5.1">Inference Time(ms)↓</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.5.1.2.2.6"><span class="ltx_text ltx_font_bold" id="S4.T2.5.1.2.2.6.1">R@1↑</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.5.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.5.1.3.1.1">CLIP4Clip <cite class="ltx_cite ltx_citemacro_citep">(Luo et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib16" title="">2022</a>)</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.3.1.2">209</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.5.1.3.1.3">45.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.3.1.4">225</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.5.1.3.1.5">43.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.3.1.6">1041</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.3.1.7">40.2</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T2.5.1.4.2.1">T2VIndexer+CLIP4Clip</th>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.4.2.2">106 (<span class="ltx_text" id="S4.T2.5.1.4.2.2.1" style="color:#000AFF;"> 52</span>+<span class="ltx_text" id="S4.T2.5.1.4.2.2.2" style="color:#FE0000;"> 54</span>)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.1.4.2.3">47.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.4.2.4">102 (<span class="ltx_text" id="S4.T2.5.1.4.2.4.1" style="color:#000AFF;"> 52</span>+<span class="ltx_text" id="S4.T2.5.1.4.2.4.2" style="color:#FE0000;"> 50</span>)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.1.4.2.5">46.3</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.4.2.6">311 (<span class="ltx_text" id="S4.T2.5.1.4.2.6.1" style="color:#000AFF;"> 52</span>+<span class="ltx_text" id="S4.T2.5.1.4.2.6.2" style="color:#FE0000;"> 259</span>)</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.4.2.7">42.6</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T2.5.1.5.3.1">Improvement</th>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.5.3.2">0.51</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.1.5.3.3">2.3</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.5.3.4">0.45</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.1.5.3.5">2.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.5.3.6">0.30</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.5.3.7">2.4</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.5.1.6.4.1">mPLUG <cite class="ltx_cite ltx_citemacro_citep">(Xu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib25" title="">2023</a>)</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.6.4.2">193</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.5.1.6.4.3">53.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.6.4.4">201</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.5.1.6.4.5">56.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.6.4.6">923</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.6.4.7">52.2</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.1.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T2.5.1.7.5.1">mPLUG+T2VIndexer</th>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.7.5.2">102 (<span class="ltx_text" id="S4.T2.5.1.7.5.2.1" style="color:#000AFF;"> 52</span>+<span class="ltx_text" id="S4.T2.5.1.7.5.2.2" style="color:#FE0000;"> 50</span>)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.1.7.5.3">55.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.7.5.4">98 (<span class="ltx_text" id="S4.T2.5.1.7.5.4.1" style="color:#000AFF;"> 52</span>+<span class="ltx_text" id="S4.T2.5.1.7.5.4.2" style="color:#FE0000;"> 46</span>)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.1.7.5.5">56.6</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.7.5.6">292 (<span class="ltx_text" id="S4.T2.5.1.7.5.6.1" style="color:#000AFF;"> 52</span>+<span class="ltx_text" id="S4.T2.5.1.7.5.6.2" style="color:#FE0000;"> 241</span>)</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.7.5.7">53.5</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.1.8.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T2.5.1.8.6.1">Improvement</th>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.8.6.2">0.53</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.1.8.6.3">1.8</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.8.6.4">0.48</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.1.8.6.5">0.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.8.6.6">0.32</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.8.6.7">1.3</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.1.9.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.5.1.9.7.1">CLIP-VIP <cite class="ltx_cite ltx_citemacro_citep">(Xue et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib27" title="">2023</a>)</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.9.7.2">191</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.5.1.9.7.3">52.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.9.7.4">199</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.5.1.9.7.5">50.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.9.7.6">934</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.1.9.7.7">53.4</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.1.10.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T2.5.1.10.8.1">CLIP-VIP+T2VIndexer</th>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.10.8.2">101 (<span class="ltx_text" id="S4.T2.5.1.10.8.2.1" style="color:#000AFF;"> 52</span>+<span class="ltx_text" id="S4.T2.5.1.10.8.2.2" style="color:#FE0000;"> 49</span>)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.1.10.8.3">54.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.10.8.4">97 (<span class="ltx_text" id="S4.T2.5.1.10.8.4.1" style="color:#000AFF;"> 52</span>+<span class="ltx_text" id="S4.T2.5.1.10.8.4.2" style="color:#FE0000;"> 45</span>)</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.1.10.8.5">51.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.10.8.6">299 (<span class="ltx_text" id="S4.T2.5.1.10.8.6.1" style="color:#000AFF;"> 52</span>+<span class="ltx_text" id="S4.T2.5.1.10.8.6.2" style="color:#FE0000;"> 247</span>)</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.1.10.8.7">54.9</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.1.11.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r" id="S4.T2.5.1.11.9.1">Improvement</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.5.1.11.9.2">0.53</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T2.5.1.11.9.3">1.7</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.5.1.11.9.4">0.49</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T2.5.1.11.9.5">1.4</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.5.1.11.9.6">0.32</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.5.1.11.9.7">1.5</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="S4.p1">
<p class="ltx_p" id="S4.p1.1"><span class="ltx_text ltx_font_bold" id="S4.p1.1.1">Datasets and Evaluation Metrics.</span>
We validate our model on four dataset: MSR-VTT, MSVD, DiDeMo, and ActivityNet Caption. MSR-VTT <cite class="ltx_cite ltx_citemacro_citep">(Xu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib26" title="">2016</a>)</cite> encompasses 10,000 videos, paired with 200,000 captions. We employ the Training-9k variant, following the data splits proposed by <cite class="ltx_cite ltx_citemacro_citep">(Gabeur et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib10" title="">2020</a>)</cite>. MSVD <cite class="ltx_cite ltx_citemacro_citep">(Chen and Dolan, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib6" title="">2011</a>)</cite> contains 1,970 videos, and a wealth of approximately 40 associated English sentences per video. Train, validation and test splits contain 1,200, 100, and 670 videos, respectively. DiDeMo <cite class="ltx_cite ltx_citemacro_citep">(Anne Hendricks et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib2" title="">2017</a>)</cite> contains 10,000 videos annotated with 40,000 sentences. We evaluate video-paragraph retrieval following <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib14" title="">2019</a>)</cite>, <cite class="ltx_cite ltx_citemacro_citep">(Lei et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib12" title="">2021</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citep">(Bain et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib3" title="">2021</a>)</cite>, where all sentence descriptions for a video are concatenated into a single query. ActivityNet <cite class="ltx_cite ltx_citemacro_citep">(Krishna et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib11" title="">2017</a>)</cite> consists of 20,000 YouTube video. We follow the setting from <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib29" title="">2018</a>)</cite> to concatenate all the descriptions of a video to form a paragraph and evaluate the model with video-paragraph retrieval.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">We adopt standard retrieval metrics, namely recall at rank K (R@K), calculates the percentage of instances where the correct result is successfully retrieved within top K.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p3">
<p class="ltx_p" id="S4.p3.4"><span class="ltx_text ltx_font_bold" id="S4.p3.4.1">Implementation Details.</span>
We utilized the image encoder from the pre-trained CLIP (Vit B/32) model. For constructing the Vi-SemTree, we opted for <math alttext="k" class="ltx_Math" display="inline" id="S4.p3.1.m1.1"><semantics id="S4.p3.1.m1.1a"><mi id="S4.p3.1.m1.1.1" xref="S4.p3.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.p3.1.m1.1b"><ci id="S4.p3.1.m1.1.1.cmml" xref="S4.p3.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.p3.1.m1.1d">italic_k</annotation></semantics></math>-means algorithm <cite class="ltx_cite ltx_citemacro_citep">(Pedregosa et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib17" title="">2011</a>)</cite>, setting both k and c to 30. SemID truncation length <math alttext="t" class="ltx_Math" display="inline" id="S4.p3.2.m2.1"><semantics id="S4.p3.2.m2.1a"><mi id="S4.p3.2.m2.1.1" xref="S4.p3.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.p3.2.m2.1b"><ci id="S4.p3.2.m2.1.1.cmml" xref="S4.p3.2.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.2.m2.1c">t</annotation><annotation encoding="application/x-llamapun" id="S4.p3.2.m2.1d">italic_t</annotation></semantics></math> set to 2 and select top 11 beam search results from generative model. The encoder parameters were initialized using the T5 pre-trained model <cite class="ltx_cite ltx_citemacro_citep">(Brown et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib5" title="">2020</a>)</cite>, while the decoder parameters were randomly initialized. During training, the learning rate was set to <math alttext="2\times 10^{-4}" class="ltx_Math" display="inline" id="S4.p3.3.m3.1"><semantics id="S4.p3.3.m3.1a"><mrow id="S4.p3.3.m3.1.1" xref="S4.p3.3.m3.1.1.cmml"><mn id="S4.p3.3.m3.1.1.2" xref="S4.p3.3.m3.1.1.2.cmml">2</mn><mo id="S4.p3.3.m3.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.p3.3.m3.1.1.1.cmml">×</mo><msup id="S4.p3.3.m3.1.1.3" xref="S4.p3.3.m3.1.1.3.cmml"><mn id="S4.p3.3.m3.1.1.3.2" xref="S4.p3.3.m3.1.1.3.2.cmml">10</mn><mrow id="S4.p3.3.m3.1.1.3.3" xref="S4.p3.3.m3.1.1.3.3.cmml"><mo id="S4.p3.3.m3.1.1.3.3a" xref="S4.p3.3.m3.1.1.3.3.cmml">−</mo><mn id="S4.p3.3.m3.1.1.3.3.2" xref="S4.p3.3.m3.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.3.m3.1b"><apply id="S4.p3.3.m3.1.1.cmml" xref="S4.p3.3.m3.1.1"><times id="S4.p3.3.m3.1.1.1.cmml" xref="S4.p3.3.m3.1.1.1"></times><cn id="S4.p3.3.m3.1.1.2.cmml" type="integer" xref="S4.p3.3.m3.1.1.2">2</cn><apply id="S4.p3.3.m3.1.1.3.cmml" xref="S4.p3.3.m3.1.1.3"><csymbol cd="ambiguous" id="S4.p3.3.m3.1.1.3.1.cmml" xref="S4.p3.3.m3.1.1.3">superscript</csymbol><cn id="S4.p3.3.m3.1.1.3.2.cmml" type="integer" xref="S4.p3.3.m3.1.1.3.2">10</cn><apply id="S4.p3.3.m3.1.1.3.3.cmml" xref="S4.p3.3.m3.1.1.3.3"><minus id="S4.p3.3.m3.1.1.3.3.1.cmml" xref="S4.p3.3.m3.1.1.3.3"></minus><cn id="S4.p3.3.m3.1.1.3.3.2.cmml" type="integer" xref="S4.p3.3.m3.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.3.m3.1c">2\times 10^{-4}</annotation><annotation encoding="application/x-llamapun" id="S4.p3.3.m3.1d">2 × 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT</annotation></semantics></math> for the encoder and <math alttext="1\times 10^{-4}" class="ltx_Math" display="inline" id="S4.p3.4.m4.1"><semantics id="S4.p3.4.m4.1a"><mrow id="S4.p3.4.m4.1.1" xref="S4.p3.4.m4.1.1.cmml"><mn id="S4.p3.4.m4.1.1.2" xref="S4.p3.4.m4.1.1.2.cmml">1</mn><mo id="S4.p3.4.m4.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.p3.4.m4.1.1.1.cmml">×</mo><msup id="S4.p3.4.m4.1.1.3" xref="S4.p3.4.m4.1.1.3.cmml"><mn id="S4.p3.4.m4.1.1.3.2" xref="S4.p3.4.m4.1.1.3.2.cmml">10</mn><mrow id="S4.p3.4.m4.1.1.3.3" xref="S4.p3.4.m4.1.1.3.3.cmml"><mo id="S4.p3.4.m4.1.1.3.3a" xref="S4.p3.4.m4.1.1.3.3.cmml">−</mo><mn id="S4.p3.4.m4.1.1.3.3.2" xref="S4.p3.4.m4.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.4.m4.1b"><apply id="S4.p3.4.m4.1.1.cmml" xref="S4.p3.4.m4.1.1"><times id="S4.p3.4.m4.1.1.1.cmml" xref="S4.p3.4.m4.1.1.1"></times><cn id="S4.p3.4.m4.1.1.2.cmml" type="integer" xref="S4.p3.4.m4.1.1.2">1</cn><apply id="S4.p3.4.m4.1.1.3.cmml" xref="S4.p3.4.m4.1.1.3"><csymbol cd="ambiguous" id="S4.p3.4.m4.1.1.3.1.cmml" xref="S4.p3.4.m4.1.1.3">superscript</csymbol><cn id="S4.p3.4.m4.1.1.3.2.cmml" type="integer" xref="S4.p3.4.m4.1.1.3.2">10</cn><apply id="S4.p3.4.m4.1.1.3.3.cmml" xref="S4.p3.4.m4.1.1.3.3"><minus id="S4.p3.4.m4.1.1.3.3.1.cmml" xref="S4.p3.4.m4.1.1.3.3"></minus><cn id="S4.p3.4.m4.1.1.3.3.2.cmml" type="integer" xref="S4.p3.4.m4.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.4.m4.1c">1\times 10^{-4}</annotation><annotation encoding="application/x-llamapun" id="S4.p3.4.m4.1d">1 × 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT</annotation></semantics></math> for the decoder. We utilized 8 NVIDIA V100-32GB GPUs, with a batch size of 16 per GPU and a dropout ratio of 0.1.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Efficiency of T2VIndexer</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">The purpose of T2VIndexer is to improve retrieval efficiency while maintaining accuracy. In Table <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S4.T1" title="Table 1 ‣ 4. Experiments ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_tag">1</span></a>, we analyzed the accuracy and efficiency of T2VIndexer under different candidate sets with a single RTX3090 GPU and 8255C CPU. In the efficiency analysis, we imposed some restrictions to simulate real application scenarios. First, the time cost from receiving the query was calculated, without considering the offline phase, such as the construction of Vi-SemTree and the allocation of SemID. Second, each query in the Test set was retrieved one by one to return the target video, instead of obtaining all Queries and returning the overall results at once. From the Table <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S4.T1" title="Table 1 ‣ 4. Experiments ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_tag">1</span></a>, it can be seen that T2VIndexer significantly reduces inference time while maintaining the baseline effect. For example, compared with the traditional method under 1000 candidate videos, T2VIndexer reduces the time cost by 50%. The efficiency improvement increases gradually with the size of the candidate set. Under 10,000 candidate videos, the time compression reaches 30%. In addition, we also analyzed the performance of three other datasets, as shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S4.T2" title="Table 2 ‣ 4. Experiments ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">Further analysis shows the efficiency improvement is due to the structure of Vi-SemTree. When the candidate set expands 10,000, the traditional method needs to process an additional 9000 data, perform a large number of similarity calculations and sorting. For T2VIndexer, the added 9000 videos will be distributed to each leaf node, and cost of generative model generating SemID remains unchanged, which ultimately improves efficiency. For example, if Vi-SemTree has 100 leaf nodes, for 10,000 candidate videos, there are an average of 100 target videos per leaf node, which significantly reduces the retrieval pressure of the baseline. This means that the T2VIndexer does not suffer from the same scalability issues as traditional methods, and allows for a more distribution of data.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Evaluating on Large-Scale Dataset</h3>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3. </span>Evaluation of the inference costs on large-scale dataset split from TGIF <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib13" title="">2016</a>)</cite>. We report the R@1 metric for the text-to-video task. <span class="ltx_text" id="S4.T3.3.1" style="color:#000AFF;"> Blue</span> means stage 1 generative time cost, and <span class="ltx_text" id="S4.T3.4.2" style="color:#FE0000;"> red</span> means stage 2 time cost.</figcaption>
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T3.5">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.5.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.5.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.5.1.1.1.1">Method</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T3.5.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T3.5.1.1.2.1">Inference Time(ms)↓</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T3.5.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T3.5.1.1.3.1">R@1↑</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.5.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.5.2.1.1">Clip4Clip <cite class="ltx_cite ltx_citemacro_citep">(Luo et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib16" title="">2022</a>)</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.2.1.2">12322</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.2.1.3">13.4</td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.5.3.2.1">Clip4Clip+T2VIndexer</th>
<td class="ltx_td ltx_align_center" id="S4.T3.5.3.2.2">3064(<span class="ltx_text" id="S4.T3.5.3.2.2.1" style="color:#000AFF;"> 52</span>+<span class="ltx_text" id="S4.T3.5.3.2.2.2" style="color:#FE0000;"> 3012</span>)</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.3.2.3">16.5</td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.5.4.3.1">Improvement</th>
<td class="ltx_td ltx_align_center" id="S4.T3.5.4.3.2">0.25</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.4.3.3">3.1</td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.5.5.4.1">mPLUG <cite class="ltx_cite ltx_citemacro_citep">(Xu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib25" title="">2023</a>)</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.4.2">10249</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.5.4.3">18.2</td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.5.6.5.1">mPLUG+T2VIndexer</th>
<td class="ltx_td ltx_align_center" id="S4.T3.5.6.5.2">2831(<span class="ltx_text" id="S4.T3.5.6.5.2.1" style="color:#000AFF;"> 52</span>+<span class="ltx_text" id="S4.T3.5.6.5.2.2" style="color:#FE0000;"> 2779</span>)</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.6.5.3">21.1</td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.5.7.6.1">Improvement</th>
<td class="ltx_td ltx_align_center" id="S4.T3.5.7.6.2">0.27</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.7.6.3">2.9</td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.5.8.7.1">CLIP-VIP <cite class="ltx_cite ltx_citemacro_citep">(Xue et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib27" title="">2023</a>)</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.8.7.2">10414</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.5.8.7.3">19.7</td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.5.9.8.1">CLIP-VIP+T2VIndexer</th>
<td class="ltx_td ltx_align_center" id="S4.T3.5.9.8.2">2902(<span class="ltx_text" id="S4.T3.5.9.8.2.1" style="color:#000AFF;"> 52</span>+<span class="ltx_text" id="S4.T3.5.9.8.2.2" style="color:#FE0000;"> 2850</span>)</td>
<td class="ltx_td ltx_align_center" id="S4.T3.5.9.8.3">22.4</td>
</tr>
<tr class="ltx_tr" id="S4.T3.5.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r" id="S4.T3.5.10.9.1">Improvement</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.5.10.9.2">0.28</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.5.10.9.3">2.7</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">To further investigate the effectiveness of T2VIndexer in real retrieval scenarios, we evaluate on larger scale data. Due to the limited size of the existing dataset test sets, which mostly consist of 1000 candidate videos, we decided to redivide the TGIF dataset <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib13" title="">2016</a>)</cite> into 50,000 training data and 50,000 testing data in a 5:5 ratio. Both the baseline and the T2VIndexer generative model will be trained solely on the 50,000 training data. Table <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S4.T3" title="Table 3 ‣ 4.2. Evaluating on Large-Scale Dataset ‣ 4. Experiments ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_tag">3</span></a> displays our test results, with each block representing a set of test results. It is evident from the results that in large-scale retrieval scenarios, T2VIndexer demonstrates more significant improvements in both efficiency and accuracy compared to smaller-scale data.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">The improvements in both efficiency and accuracy primarily stem from the pre-select mechanism employed by T2VIndexer. It generates an ID sequence with constant-time complexity, targeting a small subset of videos. The base model then performs similarity calculations and sorting only within this subset, significantly cutting computational load by bypassing individual matching and boosting retrieval speed. Additionally, the pre-select mechanism accurately identifies the target video, preemptively discarding most irrelevant videos and reducing noise, thus acting as a filter that enhances baseline accuracy.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>State-of-the-Art Comparison</h3>
<figure class="ltx_table" id="S4.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4. </span>Comparison with Existing One-stream approaches and Two-stream approaches. Our Re-implemented methods are denoted by the superscript ‘*’. The highest retrieval recall in each block is marked with <span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T4.2.1">underline</span>. The recall of our models is marked with blue color when it is better than the baseline model.</figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T4.3" style="width:433.6pt;height:188pt;vertical-align:-0.4pt;"><span class="ltx_transformed_inner" style="transform:translate(-303.2pt,131.2pt) scale(0.416958257633149,0.416958257633149) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T4.3.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.3.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T4.3.1.1.1.1"></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="4" id="S4.T4.3.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.1.1.2.1">MSR-VTT 1k</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="4" id="S4.T4.3.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.1.1.3.1">MSVD</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="4" id="S4.T4.3.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.1.1.4.1">DiDeMo</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="4" id="S4.T4.3.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.1.1.5.1">ActivityNet Caption</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.3.1.2.2.1"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.2.2.1.1">Methods</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.2.2.2"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.2.2.2.1">R@1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.2.2.3"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.2.2.3.1">R@5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.2.2.4"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.2.2.4.1">R@10</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.2.2.5"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.2.2.5.1">R@sum</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.2.2.6"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.2.2.6.1">R@1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.2.2.7"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.2.2.7.1">R@5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.2.2.8"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.2.2.8.1">R@10</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.2.2.9"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.2.2.9.1">R@sum</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.2.2.10"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.2.2.10.1">R@1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.2.2.11"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.2.2.11.1">R@5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.2.2.12"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.2.2.12.1">R@10</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.2.2.13"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.2.2.13.1">R@sum</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.2.2.14"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.2.2.14.1">R@1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.2.2.15"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.2.2.15.1">R@5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.2.2.16"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.2.2.16.1">R@10</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.2.2.17"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.2.2.17.1">R@sum</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="17" id="S4.T4.3.1.3.3.1"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.3.3.1.1">One-stream approaches</span></th>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T4.3.1.4.4.1">UniVL <cite class="ltx_cite ltx_citemacro_citep">(Luo et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib15" title="">2020</a>)</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.4.4.2">21.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.4.4.3">49.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.4.4.4">63.1</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.4.4.5">133.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.4.4.6">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.4.4.7">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.4.4.8">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.4.4.9">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.4.4.10">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.4.4.11">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.4.4.12">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.4.4.13">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.4.4.14">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.4.4.15">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.4.4.16">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.4.4.17">-</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.3.1.5.5.1">ClipBERT <cite class="ltx_cite ltx_citemacro_citep">(Lei et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib12" title="">2021</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.5.5.2">22.0</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.5.5.3">46.8</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.5.5.4">59.9</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.5.5.5">128.7</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.5.5.6">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.5.5.7">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.5.5.8">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.5.5.9">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.5.5.10">
<span class="ltx_ERROR undefined" id="S4.T4.3.1.5.5.10.1">\ul</span>20.4</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.5.5.11">
<span class="ltx_ERROR undefined" id="S4.T4.3.1.5.5.11.1">\ul</span>48.0</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.5.5.12">
<span class="ltx_ERROR undefined" id="S4.T4.3.1.5.5.12.1">\ul</span>60.8</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.5.5.13">
<span class="ltx_ERROR undefined" id="S4.T4.3.1.5.5.13.1">\ul</span>129.2</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.5.5.14">
<span class="ltx_ERROR undefined" id="S4.T4.3.1.5.5.14.1">\ul</span>21.3</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.5.5.15">
<span class="ltx_ERROR undefined" id="S4.T4.3.1.5.5.15.1">\ul</span>49.0</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.5.5.16">
<span class="ltx_ERROR undefined" id="S4.T4.3.1.5.5.16.1">\ul</span>63.5</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.5.5.17">
<span class="ltx_ERROR undefined" id="S4.T4.3.1.5.5.17.1">\ul</span>133.8</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.3.1.6.6.1">VLM <cite class="ltx_cite ltx_citemacro_citep">(Xu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib24" title="">2021</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.6.6.2">
<span class="ltx_ERROR undefined" id="S4.T4.3.1.6.6.2.1">\ul</span>28.1</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.6.6.3">
<span class="ltx_ERROR undefined" id="S4.T4.3.1.6.6.3.1">\ul</span>55.5</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.6.6.4">
<span class="ltx_ERROR undefined" id="S4.T4.3.1.6.6.4.1">\ul</span>67.4</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.6.6.5">
<span class="ltx_ERROR undefined" id="S4.T4.3.1.6.6.5.1">\ul</span>151.0</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.6.6.6">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.6.6.7">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.6.6.8">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.6.6.9">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.6.6.10">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.6.6.11">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.6.6.12">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.6.6.13">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.6.6.14">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.6.6.15">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.6.6.16">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.6.6.17">-</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.7.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="17" id="S4.T4.3.1.7.7.1"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.7.7.1.1">Two-stream approaches</span></th>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T4.3.1.8.8.1">MMT <cite class="ltx_cite ltx_citemacro_citep">(Gabeur et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib10" title="">2020</a>)</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.8.8.2">26.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.8.8.3">57.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.8.8.4">69.6</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.8.8.5">153.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.8.8.6">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.8.8.7">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.8.8.8">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.8.8.9">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.8.8.10">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.8.8.11">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.8.8.12">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.8.8.13">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.8.8.14">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.8.8.15">61.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.8.8.16">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.8.8.17">-</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.3.1.9.9.1">Frozen <cite class="ltx_cite ltx_citemacro_citep">(Bain et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib3" title="">2021</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.9.9.2">31.0</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.9.9.3">59.5</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.9.9.4">70.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.9.9.5">161.0</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.9.9.6">33.7</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.9.9.7">64.7</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.9.9.8">76.3</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.9.9.9">174.7</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.9.9.10">34.6</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.9.9.11">65.0</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.9.9.12">74.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.9.9.13">174.3</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.9.9.14">28.8</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.9.9.15">60.9</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.9.9.16">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.9.9.17">-</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.3.1.10.10.1">CLIP4Clip <cite class="ltx_cite ltx_citemacro_citep">(Luo et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib16" title="">2022</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.10.10.2">44.5</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.10.10.3">71.4</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.10.10.4">81.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.10.10.5">197.5</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.10.10.6">45.2</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.10.10.7">75.5</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.10.10.8">84.3</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.10.10.9">205.0</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.10.10.10">43.4</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.10.10.11">70.2</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.10.10.12">80.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.10.10.13">194.2</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.10.10.14">40.5</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.10.10.15">72.4</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.10.10.16">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.10.10.17">-</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.3.1.11.11.1">CAMoE <cite class="ltx_cite ltx_citemacro_citep">(Cheng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib7" title="">2021</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.11.11.2">44.6</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.11.11.3">72.6</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.11.11.4">81.8</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.11.11.5">199.0</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.11.11.6">46.9</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.11.11.7">76.1</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.11.11.8">85.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.11.11.9">208.5</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.11.11.10">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.11.11.11">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.11.11.12">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.11.11.13">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.11.11.14">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.11.11.15">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.11.11.16">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.11.11.17">-</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.3.1.12.12.1">CLIP2Video <cite class="ltx_cite ltx_citemacro_citep">(Fang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib9" title="">2021</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.12.12.2">45.6</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.12.12.3">72.6</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.12.12.4">81.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.12.12.5">199.9</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.12.12.6">47.0</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.12.12.7">76.8</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.12.12.8">85.9</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.12.12.9">209.7</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.12.12.10">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.12.12.11">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.12.12.12">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.12.12.13">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.12.12.14">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.12.12.15">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.12.12.16">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.12.12.17">-</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.13.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.3.1.13.13.1">Cap4Video <cite class="ltx_cite ltx_citemacro_citep">(Wu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib23" title="">2023</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.13.13.2">51.4</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.13.13.3">75.7</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.13.13.4">83.9</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.13.13.5">211.0</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.13.13.6">
<span class="ltx_ERROR undefined" id="S4.T4.3.1.13.13.6.1">\ul</span>51.8</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.13.13.7">
<span class="ltx_ERROR undefined" id="S4.T4.3.1.13.13.7.1">\ul</span>80.8</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.13.13.8">
<span class="ltx_ERROR undefined" id="S4.T4.3.1.13.13.8.1">\ul</span>88.3</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.13.13.9">
<span class="ltx_ERROR undefined" id="S4.T4.3.1.13.13.9.1">\ul</span>220.9</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.13.13.10">52.0</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.13.13.11">79.4</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.13.13.12">87.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.13.13.13">218.9</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.13.13.14">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.13.13.15">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.13.13.16">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.13.13.17">-</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.14.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.3.1.14.14.1">mPLUG <cite class="ltx_cite ltx_citemacro_citep">(Xu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib25" title="">2023</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.14.14.2">53.1</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.14.14.3">
<span class="ltx_ERROR undefined" id="S4.T4.3.1.14.14.3.1">\ul</span>77.6</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.14.14.4">84.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.14.14.5">215.4</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.14.14.6">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.14.14.7">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.14.14.8">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.14.14.9">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.14.14.10">
<span class="ltx_ERROR undefined" id="S4.T4.3.1.14.14.10.1">\ul</span>56.4</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.14.14.11">
<span class="ltx_ERROR undefined" id="S4.T4.3.1.14.14.11.1">\ul</span>79.1</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.14.14.12">85.2</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.14.14.13">
<span class="ltx_ERROR undefined" id="S4.T4.3.1.14.14.13.1">\ul</span>220.7</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.14.14.14">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.14.14.15">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.14.14.16">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.14.14.17">-</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.15.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.3.1.15.15.1">CLIP-VIP <cite class="ltx_cite ltx_citemacro_citep">(Xue et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#bib.bib27" title="">2023</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.15.15.2">
<span class="ltx_ERROR undefined" id="S4.T4.3.1.15.15.2.1">\ul</span>54.2</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.15.15.3">77.2</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.15.15.4">
<span class="ltx_ERROR undefined" id="S4.T4.3.1.15.15.4.1">\ul</span>84.8</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.15.15.5">
<span class="ltx_ERROR undefined" id="S4.T4.3.1.15.15.5.1">\ul</span>216.2</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.15.15.6">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.15.15.7">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.15.15.8">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.15.15.9">-</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.15.15.10">50.5</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.15.15.11">78.4</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.15.15.12">
<span class="ltx_ERROR undefined" id="S4.T4.3.1.15.15.12.1">\ul</span>87.1</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.15.15.13">216.0</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.15.15.14">
<span class="ltx_ERROR undefined" id="S4.T4.3.1.15.15.14.1">\ul</span>53.4</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.15.15.15">
<span class="ltx_ERROR undefined" id="S4.T4.3.1.15.15.15.1">\ul</span>81.4</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.15.15.16">
<span class="ltx_ERROR undefined" id="S4.T4.3.1.15.15.16.1">\ul</span>90.0</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.15.15.17">
<span class="ltx_ERROR undefined" id="S4.T4.3.1.15.15.17.1">\ul</span>224.8</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.16.16">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="17" id="S4.T4.3.1.16.16.1"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.16.16.1.1">Ours</span></th>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.17.17">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T4.3.1.17.17.1">CLIP4Clip*</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.17.17.2">44.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.17.17.3">71.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.17.17.4">81.6</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.17.17.5">197.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.17.17.6">45.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.17.17.7">75.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.17.17.8">83.9</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.17.17.9">204.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.17.17.10">43.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.17.17.11">70.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.17.17.12">80.1</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.17.17.13">193.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.17.17.14">40.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.17.17.15">72.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.17.17.16">80.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.17.17.17">193.0</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.18.18" style="background-color:#CFCFCF;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.3.1.18.18.1" style="background-color:#CFCFCF;"><span class="ltx_text" id="S4.T4.3.1.18.18.1.1" style="background-color:#CFCFCF;">T2VIndexer+CLIP4Clip*</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.18.18.2"><span class="ltx_text" id="S4.T4.3.1.18.18.2.1" style="color:#000AFF;background-color:#CFCFCF;">47.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.18.18.3"><span class="ltx_text" id="S4.T4.3.1.18.18.3.1" style="color:#000AFF;background-color:#CFCFCF;">72.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.18.18.4"><span class="ltx_text" id="S4.T4.3.1.18.18.4.1" style="color:#000AFF;background-color:#CFCFCF;">82.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.18.18.5" style="background-color:#CFCFCF;"><span class="ltx_text" id="S4.T4.3.1.18.18.5.1" style="color:#000AFF;background-color:#CFCFCF;">202.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.18.18.6"><span class="ltx_text" id="S4.T4.3.1.18.18.6.1" style="color:#000AFF;background-color:#CFCFCF;">47.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.18.18.7"><span class="ltx_text" id="S4.T4.3.1.18.18.7.1" style="color:#000AFF;background-color:#CFCFCF;">76.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.18.18.8"><span class="ltx_text" id="S4.T4.3.1.18.18.8.1" style="color:#000AFF;background-color:#CFCFCF;">85.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.18.18.9" style="background-color:#CFCFCF;"><span class="ltx_text" id="S4.T4.3.1.18.18.9.1" style="color:#000AFF;background-color:#CFCFCF;">208.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.18.18.10"><span class="ltx_text" id="S4.T4.3.1.18.18.10.1" style="color:#000AFF;background-color:#CFCFCF;">46.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.18.18.11"><span class="ltx_text" id="S4.T4.3.1.18.18.11.1" style="color:#000AFF;background-color:#CFCFCF;">72.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.18.18.12"><span class="ltx_text" id="S4.T4.3.1.18.18.12.1" style="color:#000AFF;background-color:#CFCFCF;">83.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.18.18.13" style="background-color:#CFCFCF;"><span class="ltx_text" id="S4.T4.3.1.18.18.13.1" style="color:#000AFF;background-color:#CFCFCF;">199.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.18.18.14"><span class="ltx_text" id="S4.T4.3.1.18.18.14.1" style="color:#000AFF;background-color:#CFCFCF;">42.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.18.18.15"><span class="ltx_text" id="S4.T4.3.1.18.18.15.1" style="color:#000AFF;background-color:#CFCFCF;">73.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.18.18.16"><span class="ltx_text" id="S4.T4.3.1.18.18.16.1" style="color:#000AFF;background-color:#CFCFCF;">80.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.18.18.17"><span class="ltx_text" id="S4.T4.3.1.18.18.17.1" style="color:#000AFF;background-color:#CFCFCF;">197.0</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.19.19">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.3.1.19.19.1">Improvement</th>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.19.19.2"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.19.19.2.1">+3.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.19.19.3"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.19.19.3.1">+2.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.19.19.4"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.19.19.4.1">+0.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.19.19.5"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.19.19.5.1">+5.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.19.19.6"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.19.19.6.1">+2.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.19.19.7"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.19.19.7.1">+0.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.19.19.8"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.19.19.8.1">+1.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.19.19.9"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.19.19.9.1">+4.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.19.19.10"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.19.19.10.1">+2.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.19.19.11"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.19.19.11.1">+2.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.19.19.12"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.19.19.12.1">+1.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.19.19.13"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.19.19.13.1">+6.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.19.19.14"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.19.19.14.1">+2.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.19.19.15"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.19.19.15.1">+1.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.19.19.16"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.19.19.16.1">+0.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.19.19.17"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.19.19.17.1">+4.0</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.20.20">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T4.3.1.20.20.1">mPLUG*</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.20.20.2">53.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.20.20.3">77.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.20.20.4">82.3</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.20.20.5">212.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.20.20.6">53.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.20.20.7">81.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.20.20.8">88.3</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.20.20.9">223.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.20.20.10">56.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.20.20.11">79.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.20.20.12">84.3</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.20.20.13">219.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.20.20.14">52.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.20.20.15">80.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.20.20.16">89.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.20.20.17">222.3</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.21.21" style="background-color:#CFCFCF;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.3.1.21.21.1" style="background-color:#CFCFCF;"><span class="ltx_text" id="S4.T4.3.1.21.21.1.1" style="background-color:#CFCFCF;">T2VIndexer+mPLUG*</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.21.21.2"><span class="ltx_text" id="S4.T4.3.1.21.21.2.1" style="color:#000AFF;background-color:#CFCFCF;">54.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.21.21.3"><span class="ltx_text" id="S4.T4.3.1.21.21.3.1" style="color:#000AFF;background-color:#CFCFCF;"><span class="ltx_ERROR undefined" id="S4.T4.3.1.21.21.3.1.1">\ul</span>77.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.21.21.4"><span class="ltx_text" id="S4.T4.3.1.21.21.4.1" style="color:#000AFF;background-color:#CFCFCF;">82.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.21.21.5" style="background-color:#CFCFCF;"><span class="ltx_text" id="S4.T4.3.1.21.21.5.1" style="color:#000AFF;background-color:#CFCFCF;">214.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.21.21.6"><span class="ltx_text" id="S4.T4.3.1.21.21.6.1" style="color:#000AFF;background-color:#CFCFCF;"><span class="ltx_ERROR undefined" id="S4.T4.3.1.21.21.6.1.1">\ul</span>55.4</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.21.21.7"><span class="ltx_text" id="S4.T4.3.1.21.21.7.1" style="color:#000AFF;background-color:#CFCFCF;"><span class="ltx_ERROR undefined" id="S4.T4.3.1.21.21.7.1.1">\ul</span>81.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.21.21.8"><span class="ltx_text" id="S4.T4.3.1.21.21.8.1" style="color:#000AFF;background-color:#CFCFCF;"><span class="ltx_ERROR undefined" id="S4.T4.3.1.21.21.8.1.1">\ul</span>88.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.21.21.9" style="background-color:#CFCFCF;"><span class="ltx_text" id="S4.T4.3.1.21.21.9.1" style="color:#000AFF;background-color:#CFCFCF;"><span class="ltx_ERROR undefined" id="S4.T4.3.1.21.21.9.1.1">\ul</span>225.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.21.21.10"><span class="ltx_text" id="S4.T4.3.1.21.21.10.1" style="color:#000AFF;background-color:#CFCFCF;"><span class="ltx_ERROR undefined" id="S4.T4.3.1.21.21.10.1.1">\ul</span>56.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.21.21.11"><span class="ltx_text" id="S4.T4.3.1.21.21.11.1" style="color:#000AFF;background-color:#CFCFCF;">79.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.21.21.12"><span class="ltx_text" id="S4.T4.3.1.21.21.12.1" style="color:#333333;background-color:#CFCFCF;">84.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.21.21.13" style="background-color:#CFCFCF;"><span class="ltx_text" id="S4.T4.3.1.21.21.13.1" style="color:#000AFF;background-color:#CFCFCF;"><span class="ltx_ERROR undefined" id="S4.T4.3.1.21.21.13.1.1">\ul</span>219.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.21.21.14"><span class="ltx_text" id="S4.T4.3.1.21.21.14.1" style="color:#000AFF;background-color:#CFCFCF;">53.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.21.21.15"><span class="ltx_text" id="S4.T4.3.1.21.21.15.1" style="color:#000AFF;background-color:#CFCFCF;">81.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.21.21.16"><span class="ltx_text" id="S4.T4.3.1.21.21.16.1" style="color:#000AFF;background-color:#CFCFCF;">89.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.21.21.17"><span class="ltx_text" id="S4.T4.3.1.21.21.17.1" style="color:#000AFF;background-color:#CFCFCF;">224.1</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.22.22">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.3.1.22.22.1">Improvement</th>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.22.22.2"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.22.22.2.1">+1.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.22.22.3"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.22.22.3.1">+0.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.22.22.4"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.22.22.4.1">+0.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.22.22.5"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.22.22.5.1">+1.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.22.22.6"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.22.22.6.1">+1.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.22.22.7"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.22.22.7.1">+0.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.22.22.8"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.22.22.8.1">+0.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.22.22.9"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.22.22.9.1">+2.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.22.22.10"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.22.22.10.1">+0.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.22.22.11"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.22.22.11.1">+0.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.22.22.12"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.22.22.12.1">-0.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.22.22.13"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.22.22.13.1">+0.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.22.22.14"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.22.22.14.1">+1.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.22.22.15"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.22.22.15.1">+0.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.22.22.16"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.22.22.16.1">+0.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.22.22.17"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.22.22.17.1">+1.8</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.23.23">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T4.3.1.23.23.1">CLIP-VIP*</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.23.23.2">54.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.23.23.3">77.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.23.23.4">84.7</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.23.23.5">215.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.23.23.6">52.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.23.23.7">81.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.23.23.8">88.2</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.23.23.9">222.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.23.23.10">50.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.23.23.11">78.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.23.23.12">86.6</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.3.1.23.23.13">215.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.23.23.14">53.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.23.23.15">82.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.23.23.16">89.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.1.23.23.17">225.4</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.24.24" style="background-color:#CFCFCF;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.3.1.24.24.1" style="background-color:#CFCFCF;"><span class="ltx_text" id="S4.T4.3.1.24.24.1.1" style="background-color:#CFCFCF;">T2VIndexer+CLIP-VIP*</span></th>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.24.24.2"><span class="ltx_text" id="S4.T4.3.1.24.24.2.1" style="color:#000AFF;background-color:#CFCFCF;"><span class="ltx_ERROR undefined" id="S4.T4.3.1.24.24.2.1.1">\ul</span>55.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.24.24.3"><span class="ltx_text" id="S4.T4.3.1.24.24.3.1" style="color:#000AFF;background-color:#CFCFCF;">77.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.24.24.4"><span class="ltx_text" id="S4.T4.3.1.24.24.4.1" style="color:#000AFF;background-color:#CFCFCF;"><span class="ltx_ERROR undefined" id="S4.T4.3.1.24.24.4.1.1">\ul</span>85.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.24.24.5" style="background-color:#CFCFCF;"><span class="ltx_text" id="S4.T4.3.1.24.24.5.1" style="color:#000AFF;background-color:#CFCFCF;"><span class="ltx_ERROR undefined" id="S4.T4.3.1.24.24.5.1.1">\ul</span>217.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.24.24.6"><span class="ltx_text" id="S4.T4.3.1.24.24.6.1" style="color:#000AFF;background-color:#CFCFCF;">54.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.24.24.7"><span class="ltx_text" id="S4.T4.3.1.24.24.7.1" style="color:#333333;background-color:#CFCFCF;">81.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.24.24.8"><span class="ltx_text" id="S4.T4.3.1.24.24.8.1" style="color:#000AFF;background-color:#CFCFCF;">88.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.24.24.9" style="background-color:#CFCFCF;"><span class="ltx_text" id="S4.T4.3.1.24.24.9.1" style="color:#000AFF;background-color:#CFCFCF;">223.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.24.24.10"><span class="ltx_text" id="S4.T4.3.1.24.24.10.1" style="color:#000AFF;background-color:#CFCFCF;">51.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.24.24.11"><span class="ltx_text" id="S4.T4.3.1.24.24.11.1" style="color:#000AFF;background-color:#CFCFCF;"><span class="ltx_ERROR undefined" id="S4.T4.3.1.24.24.11.1.1">\ul</span>79.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.24.24.12"><span class="ltx_text" id="S4.T4.3.1.24.24.12.1" style="color:#000AFF;background-color:#CFCFCF;"><span class="ltx_ERROR undefined" id="S4.T4.3.1.24.24.12.1.1">\ul</span>87.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.3.1.24.24.13" style="background-color:#CFCFCF;"><span class="ltx_text" id="S4.T4.3.1.24.24.13.1" style="color:#000AFF;background-color:#CFCFCF;">218.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.24.24.14"><span class="ltx_text" id="S4.T4.3.1.24.24.14.1" style="color:#000AFF;background-color:#CFCFCF;"><span class="ltx_ERROR undefined" id="S4.T4.3.1.24.24.14.1.1">\ul</span>54.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.24.24.15"><span class="ltx_text" id="S4.T4.3.1.24.24.15.1" style="color:#000AFF;background-color:#CFCFCF;"><span class="ltx_ERROR undefined" id="S4.T4.3.1.24.24.15.1.1">\ul</span>82.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.24.24.16"><span class="ltx_text" id="S4.T4.3.1.24.24.16.1" style="color:#000AFF;background-color:#CFCFCF;"><span class="ltx_ERROR undefined" id="S4.T4.3.1.24.24.16.1.1">\ul</span>90.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.1.24.24.17"><span class="ltx_text" id="S4.T4.3.1.24.24.17.1" style="color:#000AFF;background-color:#CFCFCF;"><span class="ltx_ERROR undefined" id="S4.T4.3.1.24.24.17.1.1">\ul</span>227.4</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.1.25.25">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r" id="S4.T4.3.1.25.25.1">Improvement</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.3.1.25.25.2"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.25.25.2.1">+1.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.3.1.25.25.3"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.25.25.3.1">+0.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.3.1.25.25.4"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.25.25.4.1">+0.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T4.3.1.25.25.5"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.25.25.5.1">+1.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.3.1.25.25.6"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.25.25.6.1">+1.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.3.1.25.25.7"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.25.25.7.1">-0.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.3.1.25.25.8"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.25.25.8.1">+0.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T4.3.1.25.25.9"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.25.25.9.1">+1.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.3.1.25.25.10"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.25.25.10.1">+1.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.3.1.25.25.11"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.25.25.11.1">+0.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.3.1.25.25.12"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.25.25.12.1">+0.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S4.T4.3.1.25.25.13"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.25.25.13.1">+2.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.3.1.25.25.14"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.25.25.14.1">+1.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.3.1.25.25.15"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.25.25.15.1">+0.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.3.1.25.25.16"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.25.25.16.1">+0.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.3.1.25.25.17"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.25.25.17.1">+2.0</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S4.T4" title="Table 4 ‣ 4.3. State-of-the-Art Comparison ‣ 4. Experiments ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_tag">4</span></a> is divided into three sections: Interactive, Independent, and our T2VIndexer, each based on various baselines. Two-stream methods in the first two sections typically perform well due to CLIP’s strong pretraining. In the third section, T2VIndexer was built using CLIP4CLIP, mPLUG, and CLIP-VIP. These models’ performance improved sequentially, allowing T2VIndexer to demonstrate varying effectiveness. On the MSR-VTT dataset, T2VIndexer boosted CLIP4CLIP’s R@1 by 3.3%, but its accuracy gain lessened with better baselines, peaking at a 1.0% increase with CLIP-VIP.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">This can be attributed to the candidates provided by T2VIndexer to baseline models. T2VIndexer provides the same set of candidates to the baseline models for a given query, effectively eliminating a considerable number of irrelevant videos. For lower-performing models, this removal of irrelevant videos is useful, significantly reducing the input noise and enhancing accuracy. However, higher-performing models are less sensitive to noise and can distinguish relevant content more effectively, resulting in relatively lower improvements when assisted by T2VIndexer.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4. </span>Ablation Study on Model Structure</h3>
<figure class="ltx_table" id="S4.T5">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5. </span>Ablation Study on MSR-VTT-1kA</figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T5.1" style="width:433.6pt;height:135.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(73.2pt,-22.9pt) scale(1.50984573313487,1.50984573313487) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T5.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T5.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T5.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T5.1.1.1.1.1.1">Method</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T5.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T5.1.1.1.1.2.1">R@1</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T5.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T5.1.1.1.1.3.1">R@5</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T5.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T5.1.1.1.1.4.1">R@10</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T5.1.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T5.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="S4.T5.1.1.2.1.1.1">T2VIndexer+CLIP-VIP (full model)</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.1.2.1.2"><span class="ltx_text ltx_font_bold" id="S4.T5.1.1.2.1.2.1">55.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.1.2.1.3"><span class="ltx_text ltx_font_bold" id="S4.T5.1.1.2.1.3.1">77.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.1.2.1.4"><span class="ltx_text ltx_font_bold" id="S4.T5.1.1.2.1.4.1">85.0</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.1.1.3.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T5.1.1.3.2.1">w/o Query expansion</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.1.3.2.2">45.2</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.1.3.2.3">69.3</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.1.3.2.4">77.9</td>
</tr>
<tr class="ltx_tr" id="S4.T5.1.1.4.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T5.1.1.4.3.1">w/o Multi-view query expansion</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.1.4.3.2">52.8</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.1.4.3.3">75.3</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.1.4.3.4">83.1</td>
</tr>
<tr class="ltx_tr" id="S4.T5.1.1.5.4">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S4.T5.1.1.5.4.1">w/o Vi-SemTree and SemID</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T5.1.1.5.4.2">54.0</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T5.1.1.5.4.3">76.9</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T5.1.1.5.4.4">84.6</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">To further investigate the impact of different components on the model’s performance, we report the ablation results on the MSR-VTT dataset in Table <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S4.T5" title="Table 5 ‣ 4.4. Ablation Study on Model Structure ‣ 4. Experiments ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_tag">5</span></a>. (1) <span class="ltx_text ltx_font_bold" id="S4.SS4.p1.1.1">Without query expansion (w/o query expansion)</span> This means that only the captions provided in the training set are used as the training basis. This part has the most significant impact on the model’s results. During the SemID generation process by T2VIndexer, the original video is not seen. If the semantics of the original video are not injected into SemID through queries during the training phase, the model will fail to establish a relationship between the text and SemID and will not be able to correctly generate SemID for queries not seen during training. (2) <span class="ltx_text ltx_font_bold" id="S4.SS4.p1.1.2">Without Multi-view query expansion (w/o Multi-view query expansion)</span> This indicates not using an MLLM (Multilingual Language Models) to generate multi-view descriptions, and only using a dense caption model for generating descriptions. The results suggest that the semantic expansion of SemID allows the model to learn richer information, which can better apply SemID to the test set. (3) <span class="ltx_text ltx_font_bold" id="S4.SS4.p1.1.3">Without Vi-SemTree and SemID (w/o Vi-SemTree and SemID)</span> This means that a single <math alttext="K" class="ltx_Math" display="inline" id="S4.SS4.p1.1.m1.1"><semantics id="S4.SS4.p1.1.m1.1a"><mi id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><ci id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.1.m1.1d">italic_K</annotation></semantics></math>-means clustering is performed, and each cluster is assigned a number as the identifier for the videos. The experiment confirms our theoretical premise that structured pre-injection of prior knowledge facilitates superior generalization.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5. </span>Ablation Study on Different MLLMs</h3>
<figure class="ltx_table" id="S4.T6">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6. </span>Ablation Study on MLLMs</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T6.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T6.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T6.1.1.1.1">MLLM</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T6.1.1.1.2">R@1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T6.1.1.1.3">R@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T6.1.1.1.4">R@10</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T6.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T6.1.2.1.1">mPLUG-owl</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.1.2.1.2">55.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.1.2.1.3">77.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.1.2.1.4">85.0</td>
</tr>
<tr class="ltx_tr" id="S4.T6.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T6.1.3.2.1">Minigpt-4</th>
<td class="ltx_td ltx_align_center" id="S4.T6.1.3.2.2">55.1</td>
<td class="ltx_td ltx_align_center" id="S4.T6.1.3.2.3">77.0</td>
<td class="ltx_td ltx_align_center" id="S4.T6.1.3.2.4">85.1</td>
</tr>
<tr class="ltx_tr" id="S4.T6.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r" id="S4.T6.1.4.3.1">LLaVA</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T6.1.4.3.2">55.3</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T6.1.4.3.3">77.5</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T6.1.4.3.4">85.3</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S4.SS5.p1">
<p class="ltx_p" id="S4.SS5.p1.1">Utilizing Multi-Modal Large Language Models (MLLMs) for query expansion effectively enhances the model’s generalization capabilities. Various MLLMs show little difference in the quality of query expansion, so the model’s effectiveness does not rely on a specific MLLM. Apart from mPLUG-owl tested in the paper, we have also conducted supplementary tests with Minigpt-4 and LLaVA. As evident from the results in Table <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S4.T6" title="Table 6 ‣ 4.5. Ablation Study on Different MLLMs ‣ 4. Experiments ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_tag">6</span></a> on the MSR-VTT dataset, different MLLMs have a minor impact on retrieval accuracy.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.6. </span>Ablation Study on Video Feature Extractor</h3>
<figure class="ltx_table" id="S4.T7">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 7. </span>Ablation Study on different video feature extractors on MSR-VTT with CLIP-VIP as baseline.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T7.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T7.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T7.1.1.1.1">Feature Extractor</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T7.1.1.1.2">R@1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T7.1.1.1.3">R@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T7.1.1.1.4">R@10</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T7.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T7.1.2.1.1">S3D</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.1.2.1.2">51.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.1.2.1.3">72.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.1.2.1.4">81.6</td>
</tr>
<tr class="ltx_tr" id="S4.T7.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.1.3.2.1">CLIP image encoder</th>
<td class="ltx_td ltx_align_center" id="S4.T7.1.3.2.2">55.1</td>
<td class="ltx_td ltx_align_center" id="S4.T7.1.3.2.3">77.2</td>
<td class="ltx_td ltx_align_center" id="S4.T7.1.3.2.4">85.0</td>
</tr>
<tr class="ltx_tr" id="S4.T7.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r" id="S4.T7.1.4.3.1">VideoMAE</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T7.1.4.3.2">55.4</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T7.1.4.3.3">77.8</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T7.1.4.3.4">85.6</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S4.SS6.p1">
<p class="ltx_p" id="S4.SS6.p1.1">Different methods of video feature extraction will affect the structure of the Vi-Sem tree, thereby influencing the overall model’s effectiveness. In Table<a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S4.T7" title="Table 7 ‣ 4.6. Ablation Study on Video Feature Extractor ‣ 4. Experiments ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_tag">7</span></a>, we tested three different video feature extraction methods: S3D based on pixel features, CLIP image encoder based on semantic features of frames, and VideoMAE pre-trained for video recognition. From the results comparison, it can be observed that the method based on pixel features performs the worst, even falling below the baseline model CLIP-VIP. This is due to its tree structure reflecting pixel info rather than relevant semantic info, leading to poor performance in the video pre-select stage and inability to return correct video clusters for precise recall.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS7">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.7. </span>Generative Result Visualization</h3>
<figure class="ltx_figure" id="S4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="465" id="S4.F4.g1" src="extracted/5804594/fig/vis.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4. </span>Visualization of the difference between Generative Results and Ground-truth. We show the top-3 Generated SemIDs for each text query. The truly matched results are marked in green boxes and the falsely matched results are in red boxes.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS7.p1">
<p class="ltx_p" id="S4.SS7.p1.1">We further demonstrated the ability of T2VIndexer to locate target videos through visualization. Three examples are shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S4.F4" title="Figure 4 ‣ 4.7. Generative Result Visualization ‣ 4. Experiments ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_tag">4</span></a>, where the SemID generated by T2VIndexer has a high semantic similarity with the target SemID, even in wrong mapping cases. Specifically, for the query “video game clip showing here different characters”, the SemID generated by T2VIndexer, 0-9-21, has a stronger matching relationship with the query than ground-truth video. This indicates that the model has effectively learned the mapping between natural language space and SemID space, achieving retrieve target videos directly.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS8">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.8. </span>Parameter Analysis</h3>
<figure class="ltx_figure" id="S4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="421" id="S4.F5.g1" src="extracted/5804594/fig/para3.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5. </span>Different truncation length and top k SemID for T2VIndexer on MSR-VTT-1kA.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS8.p1">
<p class="ltx_p" id="S4.SS8.p1.7">We analyzed various model setups. Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S4.F5" title="Figure 5 ‣ 4.8. Parameter Analysis ‣ 4. Experiments ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_tag">5</span></a> (a) illustrates the top <math alttext="k" class="ltx_Math" display="inline" id="S4.SS8.p1.1.m1.1"><semantics id="S4.SS8.p1.1.m1.1a"><mi id="S4.SS8.p1.1.m1.1.1" xref="S4.SS8.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS8.p1.1.m1.1b"><ci id="S4.SS8.p1.1.m1.1.1.cmml" xref="S4.SS8.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS8.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS8.p1.1.m1.1d">italic_k</annotation></semantics></math> SemIDs selected via beam search at <math alttext="t=2" class="ltx_Math" display="inline" id="S4.SS8.p1.2.m2.1"><semantics id="S4.SS8.p1.2.m2.1a"><mrow id="S4.SS8.p1.2.m2.1.1" xref="S4.SS8.p1.2.m2.1.1.cmml"><mi id="S4.SS8.p1.2.m2.1.1.2" xref="S4.SS8.p1.2.m2.1.1.2.cmml">t</mi><mo id="S4.SS8.p1.2.m2.1.1.1" xref="S4.SS8.p1.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS8.p1.2.m2.1.1.3" xref="S4.SS8.p1.2.m2.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS8.p1.2.m2.1b"><apply id="S4.SS8.p1.2.m2.1.1.cmml" xref="S4.SS8.p1.2.m2.1.1"><eq id="S4.SS8.p1.2.m2.1.1.1.cmml" xref="S4.SS8.p1.2.m2.1.1.1"></eq><ci id="S4.SS8.p1.2.m2.1.1.2.cmml" xref="S4.SS8.p1.2.m2.1.1.2">𝑡</ci><cn id="S4.SS8.p1.2.m2.1.1.3.cmml" type="integer" xref="S4.SS8.p1.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS8.p1.2.m2.1c">t=2</annotation><annotation encoding="application/x-llamapun" id="S4.SS8.p1.2.m2.1d">italic_t = 2</annotation></semantics></math>, affects recall and candidate count. As <math alttext="k" class="ltx_Math" display="inline" id="S4.SS8.p1.3.m3.1"><semantics id="S4.SS8.p1.3.m3.1a"><mi id="S4.SS8.p1.3.m3.1.1" xref="S4.SS8.p1.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS8.p1.3.m3.1b"><ci id="S4.SS8.p1.3.m3.1.1.cmml" xref="S4.SS8.p1.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS8.p1.3.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS8.p1.3.m3.1d">italic_k</annotation></semantics></math> grows, second-stage recall dips due to more candidates, but overall recall peaks at 55.1% with <math alttext="k=11" class="ltx_Math" display="inline" id="S4.SS8.p1.4.m4.1"><semantics id="S4.SS8.p1.4.m4.1a"><mrow id="S4.SS8.p1.4.m4.1.1" xref="S4.SS8.p1.4.m4.1.1.cmml"><mi id="S4.SS8.p1.4.m4.1.1.2" xref="S4.SS8.p1.4.m4.1.1.2.cmml">k</mi><mo id="S4.SS8.p1.4.m4.1.1.1" xref="S4.SS8.p1.4.m4.1.1.1.cmml">=</mo><mn id="S4.SS8.p1.4.m4.1.1.3" xref="S4.SS8.p1.4.m4.1.1.3.cmml">11</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS8.p1.4.m4.1b"><apply id="S4.SS8.p1.4.m4.1.1.cmml" xref="S4.SS8.p1.4.m4.1.1"><eq id="S4.SS8.p1.4.m4.1.1.1.cmml" xref="S4.SS8.p1.4.m4.1.1.1"></eq><ci id="S4.SS8.p1.4.m4.1.1.2.cmml" xref="S4.SS8.p1.4.m4.1.1.2">𝑘</ci><cn id="S4.SS8.p1.4.m4.1.1.3.cmml" type="integer" xref="S4.SS8.p1.4.m4.1.1.3">11</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS8.p1.4.m4.1c">k=11</annotation><annotation encoding="application/x-llamapun" id="S4.SS8.p1.4.m4.1d">italic_k = 11</annotation></semantics></math>. Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S4.F5" title="Figure 5 ‣ 4.8. Parameter Analysis ‣ 4. Experiments ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_tag">5</span></a> (b) examines the impact of different <math alttext="t" class="ltx_Math" display="inline" id="S4.SS8.p1.5.m5.1"><semantics id="S4.SS8.p1.5.m5.1a"><mi id="S4.SS8.p1.5.m5.1.1" xref="S4.SS8.p1.5.m5.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS8.p1.5.m5.1b"><ci id="S4.SS8.p1.5.m5.1.1.cmml" xref="S4.SS8.p1.5.m5.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS8.p1.5.m5.1c">t</annotation><annotation encoding="application/x-llamapun" id="S4.SS8.p1.5.m5.1d">italic_t</annotation></semantics></math> values on recall and candidate sets when <math alttext="k=11" class="ltx_Math" display="inline" id="S4.SS8.p1.6.m6.1"><semantics id="S4.SS8.p1.6.m6.1a"><mrow id="S4.SS8.p1.6.m6.1.1" xref="S4.SS8.p1.6.m6.1.1.cmml"><mi id="S4.SS8.p1.6.m6.1.1.2" xref="S4.SS8.p1.6.m6.1.1.2.cmml">k</mi><mo id="S4.SS8.p1.6.m6.1.1.1" xref="S4.SS8.p1.6.m6.1.1.1.cmml">=</mo><mn id="S4.SS8.p1.6.m6.1.1.3" xref="S4.SS8.p1.6.m6.1.1.3.cmml">11</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS8.p1.6.m6.1b"><apply id="S4.SS8.p1.6.m6.1.1.cmml" xref="S4.SS8.p1.6.m6.1.1"><eq id="S4.SS8.p1.6.m6.1.1.1.cmml" xref="S4.SS8.p1.6.m6.1.1.1"></eq><ci id="S4.SS8.p1.6.m6.1.1.2.cmml" xref="S4.SS8.p1.6.m6.1.1.2">𝑘</ci><cn id="S4.SS8.p1.6.m6.1.1.3.cmml" type="integer" xref="S4.SS8.p1.6.m6.1.1.3">11</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS8.p1.6.m6.1c">k=11</annotation><annotation encoding="application/x-llamapun" id="S4.SS8.p1.6.m6.1d">italic_k = 11</annotation></semantics></math>, showing optimal results at <math alttext="t=2" class="ltx_Math" display="inline" id="S4.SS8.p1.7.m7.1"><semantics id="S4.SS8.p1.7.m7.1a"><mrow id="S4.SS8.p1.7.m7.1.1" xref="S4.SS8.p1.7.m7.1.1.cmml"><mi id="S4.SS8.p1.7.m7.1.1.2" xref="S4.SS8.p1.7.m7.1.1.2.cmml">t</mi><mo id="S4.SS8.p1.7.m7.1.1.1" xref="S4.SS8.p1.7.m7.1.1.1.cmml">=</mo><mn id="S4.SS8.p1.7.m7.1.1.3" xref="S4.SS8.p1.7.m7.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS8.p1.7.m7.1b"><apply id="S4.SS8.p1.7.m7.1.1.cmml" xref="S4.SS8.p1.7.m7.1.1"><eq id="S4.SS8.p1.7.m7.1.1.1.cmml" xref="S4.SS8.p1.7.m7.1.1.1"></eq><ci id="S4.SS8.p1.7.m7.1.1.2.cmml" xref="S4.SS8.p1.7.m7.1.1.2">𝑡</ci><cn id="S4.SS8.p1.7.m7.1.1.3.cmml" type="integer" xref="S4.SS8.p1.7.m7.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS8.p1.7.m7.1c">t=2</annotation><annotation encoding="application/x-llamapun" id="S4.SS8.p1.7.m7.1d">italic_t = 2</annotation></semantics></math>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Limitation and Future Work</h2>
<figure class="ltx_table" id="S5.T8">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 8. </span>Ensemble framework comparative analysis. Pre-select size represents the number of videos pre-selected in the first stage.</figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S5.T8.1" style="width:433.6pt;height:93.1pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-7.7pt,1.6pt) scale(0.96574451622445,0.96574451622445) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T8.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T8.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S5.T8.1.1.1.1.1" rowspan="2"><span class="ltx_text" id="S5.T8.1.1.1.1.1.1">Ensemble framework</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="3" id="S5.T8.1.1.1.1.2">Pre-select size 50</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="3" id="S5.T8.1.1.1.1.3">Pre-select size 265</th>
</tr>
<tr class="ltx_tr" id="S5.T8.1.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T8.1.1.2.2.1">
<table class="ltx_tabular ltx_align_middle" id="S5.T8.1.1.2.2.1.1">
<tr class="ltx_tr" id="S5.T8.1.1.2.2.1.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T8.1.1.2.2.1.1.1.1">Stage 1</td>
</tr>
<tr class="ltx_tr" id="S5.T8.1.1.2.2.1.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T8.1.1.2.2.1.1.2.1">Recall</td>
</tr>
</table>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T8.1.1.2.2.2">
<table class="ltx_tabular ltx_align_middle" id="S5.T8.1.1.2.2.2.1">
<tr class="ltx_tr" id="S5.T8.1.1.2.2.2.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T8.1.1.2.2.2.1.1.1">Overall</td>
</tr>
<tr class="ltx_tr" id="S5.T8.1.1.2.2.2.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T8.1.1.2.2.2.1.2.1">R@1</td>
</tr>
</table>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T8.1.1.2.2.3">
<table class="ltx_tabular ltx_align_middle" id="S5.T8.1.1.2.2.3.1">
<tr class="ltx_tr" id="S5.T8.1.1.2.2.3.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T8.1.1.2.2.3.1.1.1">Inference</td>
</tr>
<tr class="ltx_tr" id="S5.T8.1.1.2.2.3.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T8.1.1.2.2.3.1.2.1">Time (ms)</td>
</tr>
</table>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T8.1.1.2.2.4">
<table class="ltx_tabular ltx_align_middle" id="S5.T8.1.1.2.2.4.1">
<tr class="ltx_tr" id="S5.T8.1.1.2.2.4.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T8.1.1.2.2.4.1.1.1">Stage 1</td>
</tr>
<tr class="ltx_tr" id="S5.T8.1.1.2.2.4.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T8.1.1.2.2.4.1.2.1">Recall</td>
</tr>
</table>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T8.1.1.2.2.5">
<table class="ltx_tabular ltx_align_middle" id="S5.T8.1.1.2.2.5.1">
<tr class="ltx_tr" id="S5.T8.1.1.2.2.5.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T8.1.1.2.2.5.1.1.1">Overall</td>
</tr>
<tr class="ltx_tr" id="S5.T8.1.1.2.2.5.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T8.1.1.2.2.5.1.2.1">R@1</td>
</tr>
</table>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S5.T8.1.1.2.2.6">
<table class="ltx_tabular ltx_align_middle" id="S5.T8.1.1.2.2.6.1">
<tr class="ltx_tr" id="S5.T8.1.1.2.2.6.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T8.1.1.2.2.6.1.1.1">Inference</td>
</tr>
<tr class="ltx_tr" id="S5.T8.1.1.2.2.6.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S5.T8.1.1.2.2.6.1.2.1">Time (ms)</td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T8.1.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T8.1.1.3.1.1">mPLUG+CLIP-VIP</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.1.1.3.1.2"><span class="ltx_text ltx_font_bold" id="S5.T8.1.1.3.1.2.1">93.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.1.1.3.1.3"><span class="ltx_text ltx_font_bold" id="S5.T8.1.1.3.1.3.1">55.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T8.1.1.3.1.4">198(189+9)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.1.1.3.1.5"><span class="ltx_text ltx_font_bold" id="S5.T8.1.1.3.1.5.1">97.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.1.1.3.1.6"><span class="ltx_text ltx_font_bold" id="S5.T8.1.1.3.1.6.1">57.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.1.1.3.1.7">235(189+46)</td>
</tr>
<tr class="ltx_tr" id="S5.T8.1.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r" id="S5.T8.1.1.4.2.1">T2VIndexer+CLIP-VIP</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T8.1.1.4.2.2">42.9</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T8.1.1.4.2.3">21.4</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="S5.T8.1.1.4.2.4"><span class="ltx_text ltx_font_bold" id="S5.T8.1.1.4.2.4.1">61(52+9)</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T8.1.1.4.2.5">93.7</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T8.1.1.4.2.6">55.1</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S5.T8.1.1.4.2.7"><span class="ltx_text ltx_font_bold" id="S5.T8.1.1.4.2.7.1">98(52+46)</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Although T2VIndexer has achieved certain results in efficient text-video retrieval, there still exists performance limitations. It uses a two-stage process: pre-select and precise retrieval, akin to an ensemble method. We compared it with a two-stage ensemble of mPLUG and CLIP-VIP, shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2408.11432v1#S5.T8" title="Table 8 ‣ 5. Limitation and Future Work ‣ T2VIndexer: A Generative Video Indexer for Efficient Text-Video Retrieval"><span class="ltx_text ltx_ref_tag">8</span></a>. While ensemble methods enhance accuracy at the cost of efficiency, they outperform T2VIndexer’s generative approach. However, T2VIndexer excels in efficiency by directly targeting candidate sets, unlike existing models that process all candidates. Additionally, existing pipelines struggle with new videos, requiring costly similarity calculations and sorting for each insertion into Vi-SemTree, averaging 200 ms per video in the MSR-VTT test set. Our future efforts will enhance the generative stage’s accuracy for better precision and aim to cut new data processing time and boost flexibility.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this paper, we propose T2VIndexer, a model-based video indexer that generates video identifiers directly and retrieves candidate videos with constant time complexity, in order to shorten the overall retrieval time while maintaining the retrieval accuracy of the base model. We use hierarchical clustering to organize videos into a tree structure called Vi-SemTree, which contains multiple layers corresponding to relationships from coarse to fine. We specifically trained a generative model for Vi-SemTree paths, correctly mapping natural language space and video semantic space. T2VIndexer is model-independent and can be seamlessly integrated with existing methods. However, the retrieval effect of the generative model is currently limited, and our future work will focus on improving the accuracy of the generative retrieval to achieve precise retrieval, and further improve the flexibility of the model when receiving new videos and reduce preprocessing time.
</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
This work was supported by the Central Guidance for Local Special Project (Grant No. Z231100005923044) and the Climbing Plan Project (Grant No. E3Z0261).

</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anne Hendricks et al<span class="ltx_text" id="bib.bib2.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Lisa Anne Hendricks, Oliver Wang, Eli Shechtman, Josef Sivic, Trevor Darrell, and Bryan Russell. 2017.

</span>
<span class="ltx_bibblock">Localizing moments in video with natural language. In <em class="ltx_emph ltx_font_italic" id="bib.bib2.3.1">2017 IEEE international conference on computer vision</em>. 5803–5812.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bain et al<span class="ltx_text" id="bib.bib3.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Max Bain, Arsha Nagrani, Gül Varol, and Andrew Zisserman. 2021.

</span>
<span class="ltx_bibblock">Frozen in Time: A Joint Video and Image Encoder for End-to-End Retrieval. In <em class="ltx_emph ltx_font_italic" id="bib.bib3.3.1">2021 IEEE International Conference on Computer Vision</em>. 1708–1718.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bevilacqua et al<span class="ltx_text" id="bib.bib4.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Michele Bevilacqua, Giuseppe Ottaviano, Patrick S. H. Lewis, Scott Yih, Sebastian Riedel, and Fabio Petroni. 2022.

</span>
<span class="ltx_bibblock">Autoregressive Search Engines: Generating Substrings as Document Identifiers. In <em class="ltx_emph ltx_font_italic" id="bib.bib4.3.1">Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al<span class="ltx_text" id="bib.bib5.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,
and Dario Amodei. 2020.

</span>
<span class="ltx_bibblock">Language Models are Few-Shot Learners. In <em class="ltx_emph ltx_font_italic" id="bib.bib5.3.1">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen and Dolan (2011)</span>
<span class="ltx_bibblock">
David Chen and William B Dolan. 2011.

</span>
<span class="ltx_bibblock">Collecting highly parallel data for paraphrase evaluation. In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Proceedings of the 49th annual meeting of the association for computational linguistics: human language technologies</em>. 190–200.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al<span class="ltx_text" id="bib.bib7.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Xing Cheng, Hezheng Lin, Xiangyu Wu, Fan Yang, and Dong Shen. 2021.

</span>
<span class="ltx_bibblock">Improving video-text retrieval by multi-stream corpus alignment and dual softmax loss.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.3.1">arXiv preprint arXiv:2109.04290</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dosovitskiy et al<span class="ltx_text" id="bib.bib8.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. 2021.

</span>
<span class="ltx_bibblock">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. In <em class="ltx_emph ltx_font_italic" id="bib.bib8.3.1">2021 9th International Conference on Learning Representations</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fang et al<span class="ltx_text" id="bib.bib9.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Han Fang, Pengfei Xiong, Luhui Xu, and Yu Chen. 2021.

</span>
<span class="ltx_bibblock">CLIP2Video: Mastering Video-Text Retrieval via Image CLIP.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.3.1">arXiv preprint arXiv:2106.11097</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gabeur et al<span class="ltx_text" id="bib.bib10.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Valentin Gabeur, Chen Sun, Karteek Alahari, and Cordelia Schmid. 2020.

</span>
<span class="ltx_bibblock">Multi-modal Transformer for Video Retrieval. In <em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">Computer Vision - ECCV 2020 - 16th European Conference</em>. 214–229.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krishna et al<span class="ltx_text" id="bib.bib11.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Ranjay Krishna, Kenji Hata, Frederic Ren, Li Fei-Fei, and Juan Carlos Niebles. 2017.

</span>
<span class="ltx_bibblock">Dense-Captioning Events in Videos. In <em class="ltx_emph ltx_font_italic" id="bib.bib11.3.1">IEEE International Conference on Computer Vision 2017</em>. 706–715.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lei et al<span class="ltx_text" id="bib.bib12.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Jie Lei, Linjie Li, Luowei Zhou, Zhe Gan, Tamara L Berg, Mohit Bansal, and Jingjing Liu. 2021.

</span>
<span class="ltx_bibblock">Less is more: Clipbert for video-and-language learning via sparse sampling. In <em class="ltx_emph ltx_font_italic" id="bib.bib12.3.1">IEEE conference on computer vision and pattern recognition</em>. 7331–7341.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span class="ltx_text" id="bib.bib13.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Yuncheng Li, Yale Song, Liangliang Cao, Joel R. Tetreault, Larry Goldberg, Alejandro Jaimes, and Jiebo Luo. 2016.

</span>
<span class="ltx_bibblock">TGIF: A New Dataset and Benchmark on Animated GIF Description. In <em class="ltx_emph ltx_font_italic" id="bib.bib13.3.1">2016 IEEE Conference on Computer Vision and Pattern Recognition</em>. 4641–4650.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span class="ltx_text" id="bib.bib14.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Yang Liu, Samuel Albanie, Arsha Nagrani, and Andrew Zisserman. 2019.

</span>
<span class="ltx_bibblock">Use What You Have: Video retrieval using representations from collaborative experts. In <em class="ltx_emph ltx_font_italic" id="bib.bib14.3.1">30th British Machine Vision Conference 2019</em>. 279.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luo et al<span class="ltx_text" id="bib.bib15.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Huaishao Luo, Lei Ji, Botian Shi, Haoyang Huang, Nan Duan, Tianrui Li, Jason Li, Taroon Bharti, and Ming Zhou. 2020.

</span>
<span class="ltx_bibblock">Univl: A unified video and language pre-training model for multimodal understanding and generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.3.1">arXiv preprint arXiv:2002.06353</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luo et al<span class="ltx_text" id="bib.bib16.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Huaishao Luo, Lei Ji, Ming Zhong, Yang Chen, Wen Lei, Nan Duan, and Tianrui Li. 2022.

</span>
<span class="ltx_bibblock">CLIP4Clip: An empirical study of CLIP for end to end video clip retrieval and captioning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.3.1">Neurocomputing</em> 508 (2022), 293–304.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pedregosa et al<span class="ltx_text" id="bib.bib17.2.2.1">.</span> (2011)</span>
<span class="ltx_bibblock">
Fabian Pedregosa, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, et al<span class="ltx_text" id="bib.bib17.3.1">.</span> 2011.

</span>
<span class="ltx_bibblock">Scikit-learn: Machine learning in Python.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.4.1">the Journal of machine Learning research</em> 12 (2011), 2825–2830.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al<span class="ltx_text" id="bib.bib18.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al<span class="ltx_text" id="bib.bib18.3.1">.</span> 2021.

</span>
<span class="ltx_bibblock">Learning transferable visual models from natural language supervision. In <em class="ltx_emph ltx_font_italic" id="bib.bib18.4.1">International conference on machine learning</em>. PMLR, 8748–8763.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ren et al<span class="ltx_text" id="bib.bib19.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Ruiyang Ren, Wayne Xin Zhao, Jing Liu, Hua Wu, Ji-Rong Wen, and Haifeng Wang. 2023.

</span>
<span class="ltx_bibblock">TOME: A Two-stage Approach for Model-based Retrieval. In <em class="ltx_emph ltx_font_italic" id="bib.bib19.3.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics 2023</em>. 6102–6114.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Si et al<span class="ltx_text" id="bib.bib20.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Zihua Si, Zhongxiang Sun, Jiale Chen, Guozhang Chen, Xiaoxue Zang, Kai Zheng, Yang Song, Xiao Zhang, and Jun Xu. 2023.

</span>
<span class="ltx_bibblock">Generative Retrieval with Semantic Tree-Structured Item Identifiers via Contrastive Learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.3.1">arXiv preprint arXiv:2309.13375</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tay et al<span class="ltx_text" id="bib.bib21.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Yi Tay, Vinh Tran, Mostafa Dehghani, Jianmo Ni, Dara Bahri, Harsh Mehta, Zhen Qin, Kai Hui, Zhe Zhao, Jai Prakash Gupta, Tal Schuster, William W. Cohen, and Donald Metzler. 2022.

</span>
<span class="ltx_bibblock">Transformer Memory as a Differentiable Search Index. In <em class="ltx_emph ltx_font_italic" id="bib.bib21.3.1">Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib22.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Yujing Wang, Yingyan Hou, Haonan Wang, Ziming Miao, Shibin Wu, Qi Chen, Yuqing Xia, Chengmin Chi, Guoshuai Zhao, Zheng Liu, Xing Xie, Hao Sun, Weiwei Deng, Qi Zhang, and Mao Yang. 2022.

</span>
<span class="ltx_bibblock">A Neural Corpus Indexer for Document Retrieval. In <em class="ltx_emph ltx_font_italic" id="bib.bib22.3.1">Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span class="ltx_text" id="bib.bib23.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Wenhao Wu, Haipeng Luo, Bo Fang, Jingdong Wang, and Wanli Ouyang. 2023.

</span>
<span class="ltx_bibblock">Cap4Video: What Can Auxiliary Captions Do for Text-Video Retrieval?. In <em class="ltx_emph ltx_font_italic" id="bib.bib23.3.1">2023 IEEE Conference on Computer Vision and Pattern Recognition</em>. 10704–10713.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al<span class="ltx_text" id="bib.bib24.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Hu Xu, Gargi Ghosh, Po-Yao Huang, Prahal Arora, Masoumeh Aminzadeh, Christoph Feichtenhofer, Florian Metze, and Luke Zettlemoyer. 2021.

</span>
<span class="ltx_bibblock">Vlm: Task-agnostic video-language model pre-training for video understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.3.1">arXiv preprint arXiv:2105.09996</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al<span class="ltx_text" id="bib.bib25.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Haiyang Xu, Qinghao Ye, Ming Yan, Yaya Shi, Jiabo Ye, Yuanhong Xu, Chenliang Li, Bin Bi, Qi Qian, Wei Wang, Guohai Xu, Ji Zhang, Songfang Huang, Fei Huang, and Jingren Zhou. 2023.

</span>
<span class="ltx_bibblock">mPLUG-2: A Modularized Multi-modal Foundation Model Across Text, Image and Video. In <em class="ltx_emph ltx_font_italic" id="bib.bib25.3.1">International Conference on Machine Learning</em>. 38728–38748.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al<span class="ltx_text" id="bib.bib26.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Jun Xu, Tao Mei, Ting Yao, and Yong Rui. 2016.

</span>
<span class="ltx_bibblock">Msr-vtt: A large video description dataset for bridging video and language. In <em class="ltx_emph ltx_font_italic" id="bib.bib26.3.1">2016 IEEE conference on computer vision and pattern recognition</em>. 5288–5296.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xue et al<span class="ltx_text" id="bib.bib27.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Hongwei Xue, Yuchong Sun, Bei Liu, Jianlong Fu, Ruihua Song, Houqiang Li, and Jiebo Luo. 2023.

</span>
<span class="ltx_bibblock">Clip-vip: Adapting pre-trained image-text model to video-language alignment. In <em class="ltx_emph ltx_font_italic" id="bib.bib27.3.1">2023 International Conference on Learning Representations</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et al<span class="ltx_text" id="bib.bib28.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Qinghao Ye, Haiyang Xu, Guohai Xu, Jiabo Ye, Ming Yan, Yiyang Zhou, Junyang Wang, Anwen Hu, Pengcheng Shi, Yaya Shi, et al<span class="ltx_text" id="bib.bib28.3.1">.</span> 2023.

</span>
<span class="ltx_bibblock">mplug-owl: Modularization empowers large language models with multimodality.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.4.1">arXiv preprint arXiv:2304.14178</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span class="ltx_text" id="bib.bib29.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Bowen Zhang, Hexiang Hu, and Fei Sha. 2018.

</span>
<span class="ltx_bibblock">Cross-modal and hierarchical modeling of video and text. In <em class="ltx_emph ltx_font_italic" id="bib.bib29.3.1">2018 european conference on computer vision</em>. 374–390.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span class="ltx_text" id="bib.bib30.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Yidan Zhang, Ting Zhang, Dong Chen, Yujing Wang, Qi Chen, Xing Xie, Hao Sun, Weiwei Deng, Qi Zhang, Fan Yang, et al<span class="ltx_text" id="bib.bib30.3.1">.</span> 2023.

</span>
<span class="ltx_bibblock">Irgen: Generative modeling for image retrieval.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.4.1">arXiv preprint arXiv:2303.10126</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al<span class="ltx_text" id="bib.bib31.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Shuai Zhao, Linchao Zhu, Xiaohan Wang, and Yi Yang. 2022.

</span>
<span class="ltx_bibblock">Centerclip: Token clustering for efficient text-video retrieval. In <em class="ltx_emph ltx_font_italic" id="bib.bib31.3.1">2022 International Conference on Research and Development in Information Retrieval</em>. 970–981.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu and Yang (2020)</span>
<span class="ltx_bibblock">
Linchao Zhu and Yi Yang. 2020.

</span>
<span class="ltx_bibblock">Actbert: Learning global-local video-text representations. In <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">2020 IEEE conference on computer vision and pattern recognition</em>. 8746–8755.

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Aug 21 08:33:04 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
