<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2202.05297] Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de</title><meta property="og:description" content="Systems that analyse faces have seen significant improvements in recent years and are today used in numerous application scenarios. However, these systems have been found to be negatively affected by facial alterations…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2202.05297">

<!--Generated on Thu Mar  7 20:38:37 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Facial tattoos,  synthetic data generation,  tattoo removal,  face recognition
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition 
<br class="ltx_break"><span id="id1.id1" class="ltx_text" style="font-size:120%;">Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch </span>
<span id="id2.id2" class="ltx_note ltx_role_thanks"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">thanks: </span>The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany
<br class="ltx_break">E-mail: mathias.ibsen@h-da.de</span></span></span>
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id3.id1" class="ltx_p">Systems that analyse faces have seen significant improvements in recent years and are today used in numerous application scenarios. However, these systems have been found to be negatively affected by facial alterations such as tattoos. To better understand and mitigate the effect of facial tattoos in facial analysis systems, large datasets of images of individuals with and without tattoos are needed. To this end, we propose a generator for automatically adding realistic tattoos to facial images. Moreover, we demonstrate the feasibility of the generation by using a deep learning-based model for removing tattoos from face images. The experimental results show that it is possible to remove facial tattoos from real images without degrading the quality of the image. Additionally, we show that it is possible to improve face recognition accuracy by using the proposed deep learning-based tattoo removal before extracting and comparing facial features.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Facial tattoos, synthetic data generation, tattoo removal, face recognition

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Facial analysis systems are deployed in various applications ranging from medical analysis to border control. Such facial analysis systems are known to be negatively affected by facial occlusions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. A specific kind of facial alteration that partially occludes a face is a face tattoo. Facial tattoos have become more appealing recently and have been described as a mainstream trend in several major newspapers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. Ensuring inclusiveness and accessibility for all individuals, independent of physical appearance, is imperative in developing fair facial analysis systems. In this regard, facial tattoos are especially challenging, as they cause permanent alterations where ink is induced into the dermis layer of the skin. For instance, Ibsen <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">et al.</span> investigated in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> the impact of facial tattoos and paintings on state-of-the-art face recognition systems. The authors showed that tattoos might impair the recognition accuracy and thus the security of such a facial analysis system.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2202.05297/assets/graphics/tattoo_removal_example.jpg" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="449" height="635" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.3.2" class="ltx_text" style="font-size:90%;">Examples of using deep learning-based tattoo removal.</span></figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In coherence with the findings in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, it is of interest to make facial analysis systems more robust towards facial tattoos. One way to do this is face completion, where missing or occluded parts of a face are reconstructed; such approaches have, for instance, shown to improve face recognition performance for some occlusions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. An additional benefit of using face completion over approaches like occlusion-aware face recognition is the potential to use the reconstructed facial image for other purposes, e.g. visualising how a face might look without the occlusion or preventing that tattoos are used for recognition purposes; which is something that raises ethical issues as discussed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">However, one major problem with face completion for tattoo removal is the lack of sufficient and high-quality training data, as no extensive database of facial tattoos is currently available.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The main focus of this work is, therefore, two-fold. First, we propose a method for synthetically adding tattoos to facial images, which we use to create a large database of facial images with tattoos. The proposed method uses face detection and landmark localisation to divide the face into regions, whereafter suitable placements of tattoos are found. Subsequently, we approximate depth and construct depth and cut-out maps which are used to realistically blend tattoos onto a face. It has recently been shown that synthetic data can be beneficial for face analysis tasks and be a good alternative to real data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Secondly, we show the usefulness of our synthetic data by training a deep learning-based model for tattoo removal (as illustrated in Fig. <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) and evaluate the impact of removing facial tattoos on a state-of-the-art face recognition system using a database comprising real facial images with tattoos.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">The approach for synthetically adding tattoos to a facial image in a fully automated way is, to the authors’ best knowledge, the first of its kind. The proposed generator can be used to create large databases which can be used in related fields such as tattoo detection or studying the effects of tattoos on human perception. Additionally, we are the first to measure the effect of removing facial tattoos on face recognition systems. The code for synthetically adding tattoos to face images will be made publicly available<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Generation code will be released upon acceptance of this manuscript</span></span></span>.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">In summary, this work makes the following contributions:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">A novel algorithm for synthetically adding facial tattoos to face images.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">An algorithm for removing tattoos from facial images trained on only facial images with synthetically added tattoos. We refer to this algorithm as TRNet.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">An experimental analysis of the quality of the tattoo removal.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">Showcasing the application of tattoo removal in a face recognition system by conducting an experimental analysis on the effect of removing facial tattoos on a face recognition system.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">The outline of the remaining article is as follows: Sect. <a href="#S2" title="II Related Work ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> describes prominent related works, Sect. <a href="#S3" title="III Facial Tattoo Generator ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> describes an automated approach for synthetically blending tattoos to facial images, which is used in Sect. <a href="#S4" title="IV Synthetic Tattoo Database ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a> to generate a database of facial images with tattoos. Sect. <a href="#S5" title="V Tattoo Removal ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a> and <a href="#S6" title="VI Application to Face Recognition ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a> show the feasibility of the synthetic generation by training a deep learning-based model for tattoo removal and evaluating if it can improve biometric recognition performance, respectively. Finally, Sect. <a href="#S7" title="VII Summary ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VII</span></a> provides a summary of this work.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Related Work</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">The following subsections summarise related works w.r.t. synthetic data generation for facial analysis (Sect. <a href="#S2.SS1" title="II-A Synthetic Data Generation for Face Analysis ‣ II Related Work ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">II-A</span></span></a>), facial alterations (Sect. <a href="#S2.SS2" title="II-B Facial Alterations ‣ II Related Work ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">II-B</span></span></a>), and facial completion (Sect. <a href="#S2.SS3" title="II-C Facial Completion ‣ II Related Work ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">II-C</span></span></a>).</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.4.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.5.2" class="ltx_text ltx_font_italic">Synthetic Data Generation for Face Analysis</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Synthetically generated data has seen many application scenarios in face analysis, most notably for addressing the lack of training data. Synthetic data has especially become relevant with the recent advances in deep learning-based algorithms, which usually require a large amount of training data. Privacy regulations, <span id="S2.SS1.p1.1.1" class="ltx_text ltx_font_italic">e.g.</span> the European General Data Protection Regulation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, make sharing and distributing large-scale face databases impracticable as face images are classified as a special category of personal data when used for biometric identification. As an alternative, researchers have explored the use of synthetic data. The generation of realistic-looking synthetic face data has especially become feasible with the recent advances in Generative Adversarial Networks (GANs), first proposed by Goodfellow <span id="S2.SS1.p1.1.2" class="ltx_text ltx_font_italic">et al.</span> in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. Prominent work in this field includes StyleGAN, which was first introduced in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> by Karras <span id="S2.SS1.p1.1.3" class="ltx_text ltx_font_italic">et al.</span> and showed, at the time, state-of-the-art performance for synthesising facial images. Since the original work, two improved versions of StyleGAN have been proposed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. Much current research in this area focuses on GAN-inversion, where existing face images are encoded into the latent space of a generator. Thereafter, the resulting latent code can be shifted in the latent space, whereby the inverted image of the shifted vector results in an alteration of the original image. The technique can, for instance, be used for face age progression <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. In addition to the face, some research has also been conducted for other biometric modalities, <span id="S2.SS1.p1.1.4" class="ltx_text ltx_font_italic">e.g.</span> fingerprint <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> and iris <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Little work has been conducted regarding synthetic data generation of facial images with tattoos. However, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> the authors proposed a method for transforming digital portrait images into realistic-looking tattoos. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, the author also shows examples of tattoo images added to facial and body images using an existing GAN for drawing art portraits; however, details about this approach are not scientifically documented.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2202.05297/assets/graphics/tattoo_removal_overview.jpg" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="419" height="278" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S2.F2.3.2" class="ltx_text" style="font-size:90%;">Synthetic facial tattoo generation workflow.</span></figcaption>
</figure>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.4.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.5.2" class="ltx_text ltx_font_italic">Facial Alterations</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Facial alterations can occur in either the physical or digital domain and cause permanent or temporary changes of a face. Several studies have explored the impact of physical and digital alterations on face recognition systems. In the physical domain, predominantly the effects of makeup and plastic surgery on face recognition have been studied <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> the authors collected a database of 900 individuals to analyse the effect of plastic surgery and found that the tested algorithms were unable to effectively account for the appearance changes caused by plastic surgery. More recently, Rathgeb <span id="S2.SS2.p1.1.1" class="ltx_text ltx_font_italic">et al.</span> showed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, using a database of mostly ICAO-quality face images <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> captured before and after various types of facial plastic surgeries, that different tested state-of-the-art face recognition systems maintained almost perfect verification performance at an operationally relevant threshold corresponding to a False Match Rate (FMR) of <math id="S2.SS2.p1.1.m1.1" class="ltx_Math" alttext="0.1\%" display="inline"><semantics id="S2.SS2.p1.1.m1.1a"><mrow id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml"><mn id="S2.SS2.p1.1.m1.1.1.2" xref="S2.SS2.p1.1.m1.1.1.2.cmml">0.1</mn><mo id="S2.SS2.p1.1.m1.1.1.1" xref="S2.SS2.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><apply id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1"><csymbol cd="latexml" id="S2.SS2.p1.1.m1.1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S2.SS2.p1.1.m1.1.1.2.cmml" xref="S2.SS2.p1.1.m1.1.1.2">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">0.1\%</annotation></semantics></math>. Numerous works have addressed the impact of temporary alterations on face recognition systems. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, Dantcheva <span id="S2.SS2.p1.1.2" class="ltx_text ltx_font_italic">et al.</span> found that makeup can hinder reliable face recognition; similar conclusions were drawn by Wang <span id="S2.SS2.p1.1.3" class="ltx_text ltx_font_italic">et al.</span> in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> where they investigated the impact of human faces under disguise and makeup. The previous work shows that makeup might be successfully used for identity concealment; in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>, the authors additionally showed that makeup could also be used for presentation attacks with the goal of impersonating another identity. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>, the authors found that especially high-quality makeup-based presentation attacks can hamper the security of face recognition systems. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, the authors found that disguised faces severely affect recognition performance, especially for occlusions near the periocular region. The database used by the authors includes different types of disguises, including facial paintings. Coherent with these findings, Ibsen <span id="S2.SS2.p1.1.4" class="ltx_text ltx_font_italic">et al.</span> showed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> that facial tattoos and paintings can severely affect different modules of a face recognition system, including face detection as well as feature extraction and comparison.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">Ferrara <span id="S2.SS2.p2.1.1" class="ltx_text ltx_font_italic">et al.</span> were among the first to show that digital alterations can impair the security of face recognition systems. Especially notable is their work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> where they showed the possibility of attacking face recognition systems using morphed images. Specifically, they showed that if a high-quality morphed image is infiltrated into a face recognition system (<span id="S2.SS2.p2.1.2" class="ltx_text ltx_font_italic">e.g.</span> stored in a passport), it is likely that individuals contributing to the morph are positively authenticated by the biometric system. Since then, there have been numerous works on face recognition systems under morphing attacks. For a comprehensive survey, the reader is referred to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. Facial retouching is another area which has seen some attention in the research community. While some early works showed that face recognition can be significantly affected by retouching, Rathgeb <span id="S2.SS2.p2.1.3" class="ltx_text ltx_font_italic">et al.</span> showed more recently that face recognition systems might be robust to slight alterations caused by retouching <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>. Similar improvements have been shown for geometrical distortions, <span id="S2.SS2.p2.1.4" class="ltx_text ltx_font_italic">e.g.</span> stretching <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>. A more recent threat that has arrived with the prevalence of deep-learning techniques is so-called DeepFakes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>, which can be used to spread misinformation and as such lead to a loss of trust in digital content. Many researchers are working on the detection or generation of deep learning-based alterations. Several arduous challenges and benchmarks have already been established, for instance, the recent <span id="S2.SS2.p2.1.5" class="ltx_text ltx_font_italic">Deepfake Detection Challenge</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> where the top model only achieved an accuracy of approximately <math id="S2.SS2.p2.1.m1.1" class="ltx_Math" alttext="65\%" display="inline"><semantics id="S2.SS2.p2.1.m1.1a"><mrow id="S2.SS2.p2.1.m1.1.1" xref="S2.SS2.p2.1.m1.1.1.cmml"><mn id="S2.SS2.p2.1.m1.1.1.2" xref="S2.SS2.p2.1.m1.1.1.2.cmml">65</mn><mo id="S2.SS2.p2.1.m1.1.1.1" xref="S2.SS2.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.1.m1.1b"><apply id="S2.SS2.p2.1.m1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1"><csymbol cd="latexml" id="S2.SS2.p2.1.m1.1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S2.SS2.p2.1.m1.1.1.2.cmml" xref="S2.SS2.p2.1.m1.1.1.2">65</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.1.m1.1c">65\%</annotation></semantics></math> on previously unseen data. Generation and detection of deep learning-based alterations are continuously evolving and remain a cat-and-mouse game; interested readers are referred to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> for a comprehensive survey.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS3.4.1.1" class="ltx_text">II-C</span> </span><span id="S2.SS3.5.2" class="ltx_text ltx_font_italic">Facial Completion</span>
</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Most methods for face completion<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Also called face inpainting.</span></span></span> build upon deep learning-based algorithms, which are trained on paired images where each pair contains a non-occluded face and a corresponding occluded face. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, the authors proposed an approach for general image completion and showed its applicability for facial completion. In this work, the authors leveraged a fully convolutional neural network trained with global and local context discriminators. Similar work was done in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> where the authors occluded faces by adding random squares of noise pixels. Subsequently, they trained an autoencoder to reconstruct the occluded part of the face using global and local adversarial losses as well as a semantic parsing loss. Motivated by the prevalence of VR/AR displays which can hinder face-to-face communication, Zhao <span id="S2.SS3.p1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> proposed a new generative architecture with an identity preserving loss. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>, Song <span id="S2.SS3.p1.1.2" class="ltx_text ltx_font_italic">et al.</span> used landmark detection to estimate the geometry of a face and used it, together with the occluded face image, as input to an encoder-decoder architecture for reconstructing the occluded parts of the face. The proposed approach allows generating diverse results by altering the estimated facial geometry. More recently, Din <span id="S2.SS3.p1.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> employed a GAN-based architecture for the unmasking of masked facial images. The proposed architecture consists of two stages where the first stage detects the masked area of the face and creates a binary segmentation map. The segmentation map is then used in the second stage for facial completion using a GAN-based architecture with two discriminators where one focuses on the global structure and the other on the occluded parts of the face. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, it was found that facial completion can improve face recognition performance.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Facial Tattoo Generator</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">To address the lack of existing databases of image pairs of individuals before and after they got facial tattoos, we propose an automated approach for synthetically adding facial tattoos to images. An overview of the proposed generation is depicted in Fig. <a href="#S2.F2" title="Figure 2 ‣ II-A Synthetic Data Generation for Face Analysis ‣ II Related Work ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The process of synthetically adding tattoos to a facial image can be split into two main steps which are described in the following subsections: (1) finding the placement of tattoos in a face and (2) blending the tattoos to the face.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.4.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.5.2" class="ltx_text ltx_font_italic">Placement of Tattoos</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">To find suitable placements of tattoos in a face, we start by localising the facial region and detecting landmarks of the face. To this end, we use <span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_italic">dlib</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> which returns a list of 68 landmarks as shown in Fig. <a href="#S3.F3" title="Figure 3 ‣ III-A Placement of Tattoos ‣ III Facial Tattoo Generator ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2202.05297/assets/x1.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="230" height="230" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.3.2" class="ltx_text" style="font-size:90%;">Facial landmarks detected by dlib.</span></figcaption>
</figure>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">Thereafter, the landmarks are used to divide the face into small regions of triangles by performing a fixed Delaunay triangulation. The regions are then extended to the forehead by using the length of the nose as an estimate. Each region now constitutes a possible placement of a tattoo; however, such a division is inadequate for the placement of larger tattoos. Therefore, the face is divided into six larger regions. The division of the face into large and small regions gives high controllability in the data generation. As indicated, some regions are excluded, <span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_italic">i.e.</span> regions around the nostrils, mouth and nose. These regions are estimated based on the detected landmarks. The division of a face into regions is illustrated in Fig. <a href="#S3.F4" title="Figure 4 ‣ III-A Placement of Tattoos ‣ III Facial Tattoo Generator ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. The regions make it possible to avoid placing tattoos in heavily bearded areas or on top of glasses if such information is available about the facial images during the generation phase. In our work, we do not use beard or glass detectors; however, for some of the images information about beard or glasses is available which we use to avoid placing tattoos in the affected regions.</p>
</div>
<figure id="S3.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F4.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2202.05297/assets/graphics/regions_no_forehead.jpg" id="S3.F4.sf1.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="598" height="798" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F4.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2202.05297/assets/graphics/regions.jpg" id="S3.F4.sf2.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="598" height="798" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F4.sf3" class="ltx_figure ltx_figure_panel">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2202.05297/assets/graphics/predefined_regions.jpg" id="S3.F4.sf3.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_portrait" width="598" height="798" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S3.F4.sf3.3" class="ltx_p ltx_figure_panel ltx_align_center">.</p>
</div>
</div>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S3.F4.3.2" class="ltx_text" style="font-size:90%;">(a) Division of a facial image into regions from landmarks, (b) extended to the forehead, and (c) division into six pre-defined regions.</span></figcaption>
</figure>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">A tattoo can now be placed in one of the six predefined regions, or the regions can be further combined to allow placing the tattoos in larger areas of the face. A combined region is simply a new region consisting of several smaller regions. The exact placement of a tattoo within a region depends on a pre-selected generation strategy. The generation strategy determines (1) possible regions where a tattoo can be placed, (2) the selection of tattoos, and (3) the size and placement of a tattoo within a region. An example is illustrated in Fig. <a href="#S3.F5" title="Figure 5 ‣ III-A Placement of Tattoos ‣ III Facial Tattoo Generator ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> where one of the cheeks is selected as a possible region, whereafter the largest unoccupied subset within that region is found. Thereafter, the tattoo is placed by estimating its largest possible placement within the selected subset without altering the original aspect ratio of the tattoo. In this work, we use a database comprising more than 600 distinct tattoo templates, which mainly consist of real tattoo designs collected from acquired tattoo books. The selection of which tattoos to place depends on the generation strategies, which are further described in Sect. <a href="#S3.SS3" title="III-C Generation Strategies ‣ III Facial Tattoo Generator ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-C</span></span></a>.</p>
</div>
<figure id="S3.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F5.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2202.05297/assets/graphics/left_chin_region.jpg" id="S3.F5.sf1.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="598" height="798" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F5.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S3.F5.sf1.3.2" class="ltx_text" style="font-size:90%;">Selected region</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F5.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2202.05297/assets/graphics/left_chin_free_not_free.jpg" id="S3.F5.sf2.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="598" height="798" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F5.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S3.F5.sf2.3.2" class="ltx_text" style="font-size:90%;">Find a subset of the region not occupied (the green area).</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F5.sf3" class="ltx_figure ltx_figure_panel"><img src="/html/2202.05297/assets/graphics/left_chin_placement.jpg" id="S3.F5.sf3.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="598" height="798" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F5.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S3.F5.sf3.3.2" class="ltx_text" style="font-size:90%;">Find a placement for the tattoo</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F5.3.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S3.F5.4.2" class="ltx_text" style="font-size:90%;">Illustration showing an example of how a placement of a tattoo in a region can be found. The red area in (b) illustrates that there might be some areas within a selected region where a tattoo cannot be placed, <span id="S3.F5.4.2.1" class="ltx_text ltx_font_italic">e.g.</span> if the area is reserved for another tattoo.</span></figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.4.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.5.2" class="ltx_text ltx_font_italic">Blending</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">To blend the tattoos to faces, various image manipulations are performed.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">Given a facial image and placement of tattoos (see Sect. <a href="#S3.SS1" title="III-A Placement of Tattoos ‣ III Facial Tattoo Generator ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-A</span></span></a>); each tattoo is placed and overlayed on the facial image by multiplying the tattoo layer with the facial image. Afterwards, the tattoo is displaced to match the contours of the face using displacement mapping. Areas of the tattoo which have been displaced outside the face or inside the mouth, nostrils and eyes are cut out. This is done by using cut-out maps (see Fig. <a href="#S2.F2" title="Figure 2 ‣ II-A Synthetic Data Generation for Face Analysis ‣ II Related Work ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>), which are calculated from the landmarks detected by dlib in the placement phase. Lastly, the tattoo is made more realistic by colour adjustment, Gaussian blurring, and lowering the opacity of the tattoo.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.4" class="ltx_p">As previously stated, displacement mapping is used for mapping tattoos to the contours of a face. It is a technique which utilises depth information of texture maps to alter the positions of pixels according to the depth information in the provided map. Contrary to other approaches, such as bump mapping, it alters the source image by displacing pixels. In displacement mapping, a map <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">M</annotation></semantics></math> containing values in the range 0-255 is used to displace pixels in a source image <math id="S3.SS2.p3.2.m2.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S3.SS2.p3.2.m2.1a"><mi id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><ci id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">I</annotation></semantics></math>. In general, a specific pixel, <math id="S3.SS2.p3.3.m3.2" class="ltx_Math" alttext="I(x,y)" display="inline"><semantics id="S3.SS2.p3.3.m3.2a"><mrow id="S3.SS2.p3.3.m3.2.3" xref="S3.SS2.p3.3.m3.2.3.cmml"><mi id="S3.SS2.p3.3.m3.2.3.2" xref="S3.SS2.p3.3.m3.2.3.2.cmml">I</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.3.m3.2.3.1" xref="S3.SS2.p3.3.m3.2.3.1.cmml">​</mo><mrow id="S3.SS2.p3.3.m3.2.3.3.2" xref="S3.SS2.p3.3.m3.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS2.p3.3.m3.2.3.3.2.1" xref="S3.SS2.p3.3.m3.2.3.3.1.cmml">(</mo><mi id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml">x</mi><mo id="S3.SS2.p3.3.m3.2.3.3.2.2" xref="S3.SS2.p3.3.m3.2.3.3.1.cmml">,</mo><mi id="S3.SS2.p3.3.m3.2.2" xref="S3.SS2.p3.3.m3.2.2.cmml">y</mi><mo stretchy="false" id="S3.SS2.p3.3.m3.2.3.3.2.3" xref="S3.SS2.p3.3.m3.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.2b"><apply id="S3.SS2.p3.3.m3.2.3.cmml" xref="S3.SS2.p3.3.m3.2.3"><times id="S3.SS2.p3.3.m3.2.3.1.cmml" xref="S3.SS2.p3.3.m3.2.3.1"></times><ci id="S3.SS2.p3.3.m3.2.3.2.cmml" xref="S3.SS2.p3.3.m3.2.3.2">𝐼</ci><interval closure="open" id="S3.SS2.p3.3.m3.2.3.3.1.cmml" xref="S3.SS2.p3.3.m3.2.3.3.2"><ci id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">𝑥</ci><ci id="S3.SS2.p3.3.m3.2.2.cmml" xref="S3.SS2.p3.3.m3.2.2">𝑦</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.2c">I(x,y)</annotation></semantics></math>, is displaced in one direction if <math id="S3.SS2.p3.4.m4.2" class="ltx_Math" alttext="M(x,y)" display="inline"><semantics id="S3.SS2.p3.4.m4.2a"><mrow id="S3.SS2.p3.4.m4.2.3" xref="S3.SS2.p3.4.m4.2.3.cmml"><mi id="S3.SS2.p3.4.m4.2.3.2" xref="S3.SS2.p3.4.m4.2.3.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.4.m4.2.3.1" xref="S3.SS2.p3.4.m4.2.3.1.cmml">​</mo><mrow id="S3.SS2.p3.4.m4.2.3.3.2" xref="S3.SS2.p3.4.m4.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS2.p3.4.m4.2.3.3.2.1" xref="S3.SS2.p3.4.m4.2.3.3.1.cmml">(</mo><mi id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml">x</mi><mo id="S3.SS2.p3.4.m4.2.3.3.2.2" xref="S3.SS2.p3.4.m4.2.3.3.1.cmml">,</mo><mi id="S3.SS2.p3.4.m4.2.2" xref="S3.SS2.p3.4.m4.2.2.cmml">y</mi><mo stretchy="false" id="S3.SS2.p3.4.m4.2.3.3.2.3" xref="S3.SS2.p3.4.m4.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.2b"><apply id="S3.SS2.p3.4.m4.2.3.cmml" xref="S3.SS2.p3.4.m4.2.3"><times id="S3.SS2.p3.4.m4.2.3.1.cmml" xref="S3.SS2.p3.4.m4.2.3.1"></times><ci id="S3.SS2.p3.4.m4.2.3.2.cmml" xref="S3.SS2.p3.4.m4.2.3.2">𝑀</ci><interval closure="open" id="S3.SS2.p3.4.m4.2.3.3.1.cmml" xref="S3.SS2.p3.4.m4.2.3.3.2"><ci id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1">𝑥</ci><ci id="S3.SS2.p3.4.m4.2.2.cmml" xref="S3.SS2.p3.4.m4.2.2">𝑦</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.2c">M(x,y)</annotation></semantics></math> is less than the theoretical average pixel value of the map (127.5); else it is displaced in the opposite direction. For the displacement technique used in this work, a pixel in the source image is displaced both vertically and horizontally.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.4" class="ltx_p">More specifically, let <math id="S3.SS2.p4.1.m1.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS2.p4.1.m1.1a"><mi id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><ci id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">c</annotation></semantics></math> be a coefficient, let <math id="S3.SS2.p4.2.m2.2" class="ltx_Math" alttext="(x,y)\in I" display="inline"><semantics id="S3.SS2.p4.2.m2.2a"><mrow id="S3.SS2.p4.2.m2.2.3" xref="S3.SS2.p4.2.m2.2.3.cmml"><mrow id="S3.SS2.p4.2.m2.2.3.2.2" xref="S3.SS2.p4.2.m2.2.3.2.1.cmml"><mo stretchy="false" id="S3.SS2.p4.2.m2.2.3.2.2.1" xref="S3.SS2.p4.2.m2.2.3.2.1.cmml">(</mo><mi id="S3.SS2.p4.2.m2.1.1" xref="S3.SS2.p4.2.m2.1.1.cmml">x</mi><mo id="S3.SS2.p4.2.m2.2.3.2.2.2" xref="S3.SS2.p4.2.m2.2.3.2.1.cmml">,</mo><mi id="S3.SS2.p4.2.m2.2.2" xref="S3.SS2.p4.2.m2.2.2.cmml">y</mi><mo stretchy="false" id="S3.SS2.p4.2.m2.2.3.2.2.3" xref="S3.SS2.p4.2.m2.2.3.2.1.cmml">)</mo></mrow><mo id="S3.SS2.p4.2.m2.2.3.1" xref="S3.SS2.p4.2.m2.2.3.1.cmml">∈</mo><mi id="S3.SS2.p4.2.m2.2.3.3" xref="S3.SS2.p4.2.m2.2.3.3.cmml">I</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m2.2b"><apply id="S3.SS2.p4.2.m2.2.3.cmml" xref="S3.SS2.p4.2.m2.2.3"><in id="S3.SS2.p4.2.m2.2.3.1.cmml" xref="S3.SS2.p4.2.m2.2.3.1"></in><interval closure="open" id="S3.SS2.p4.2.m2.2.3.2.1.cmml" xref="S3.SS2.p4.2.m2.2.3.2.2"><ci id="S3.SS2.p4.2.m2.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1">𝑥</ci><ci id="S3.SS2.p4.2.m2.2.2.cmml" xref="S3.SS2.p4.2.m2.2.2">𝑦</ci></interval><ci id="S3.SS2.p4.2.m2.2.3.3.cmml" xref="S3.SS2.p4.2.m2.2.3.3">𝐼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m2.2c">(x,y)\in I</annotation></semantics></math>, and let <math id="S3.SS2.p4.3.m3.2" class="ltx_Math" alttext="(x,y)\in M" display="inline"><semantics id="S3.SS2.p4.3.m3.2a"><mrow id="S3.SS2.p4.3.m3.2.3" xref="S3.SS2.p4.3.m3.2.3.cmml"><mrow id="S3.SS2.p4.3.m3.2.3.2.2" xref="S3.SS2.p4.3.m3.2.3.2.1.cmml"><mo stretchy="false" id="S3.SS2.p4.3.m3.2.3.2.2.1" xref="S3.SS2.p4.3.m3.2.3.2.1.cmml">(</mo><mi id="S3.SS2.p4.3.m3.1.1" xref="S3.SS2.p4.3.m3.1.1.cmml">x</mi><mo id="S3.SS2.p4.3.m3.2.3.2.2.2" xref="S3.SS2.p4.3.m3.2.3.2.1.cmml">,</mo><mi id="S3.SS2.p4.3.m3.2.2" xref="S3.SS2.p4.3.m3.2.2.cmml">y</mi><mo stretchy="false" id="S3.SS2.p4.3.m3.2.3.2.2.3" xref="S3.SS2.p4.3.m3.2.3.2.1.cmml">)</mo></mrow><mo id="S3.SS2.p4.3.m3.2.3.1" xref="S3.SS2.p4.3.m3.2.3.1.cmml">∈</mo><mi id="S3.SS2.p4.3.m3.2.3.3" xref="S3.SS2.p4.3.m3.2.3.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.3.m3.2b"><apply id="S3.SS2.p4.3.m3.2.3.cmml" xref="S3.SS2.p4.3.m3.2.3"><in id="S3.SS2.p4.3.m3.2.3.1.cmml" xref="S3.SS2.p4.3.m3.2.3.1"></in><interval closure="open" id="S3.SS2.p4.3.m3.2.3.2.1.cmml" xref="S3.SS2.p4.3.m3.2.3.2.2"><ci id="S3.SS2.p4.3.m3.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1">𝑥</ci><ci id="S3.SS2.p4.3.m3.2.2.cmml" xref="S3.SS2.p4.3.m3.2.2">𝑦</ci></interval><ci id="S3.SS2.p4.3.m3.2.3.3.cmml" xref="S3.SS2.p4.3.m3.2.3.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.3.m3.2c">(x,y)\in M</annotation></semantics></math>. The distance for displacing a pixel, <math id="S3.SS2.p4.4.m4.2" class="ltx_Math" alttext="I(x,y)" display="inline"><semantics id="S3.SS2.p4.4.m4.2a"><mrow id="S3.SS2.p4.4.m4.2.3" xref="S3.SS2.p4.4.m4.2.3.cmml"><mi id="S3.SS2.p4.4.m4.2.3.2" xref="S3.SS2.p4.4.m4.2.3.2.cmml">I</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p4.4.m4.2.3.1" xref="S3.SS2.p4.4.m4.2.3.1.cmml">​</mo><mrow id="S3.SS2.p4.4.m4.2.3.3.2" xref="S3.SS2.p4.4.m4.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS2.p4.4.m4.2.3.3.2.1" xref="S3.SS2.p4.4.m4.2.3.3.1.cmml">(</mo><mi id="S3.SS2.p4.4.m4.1.1" xref="S3.SS2.p4.4.m4.1.1.cmml">x</mi><mo id="S3.SS2.p4.4.m4.2.3.3.2.2" xref="S3.SS2.p4.4.m4.2.3.3.1.cmml">,</mo><mi id="S3.SS2.p4.4.m4.2.2" xref="S3.SS2.p4.4.m4.2.2.cmml">y</mi><mo stretchy="false" id="S3.SS2.p4.4.m4.2.3.3.2.3" xref="S3.SS2.p4.4.m4.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.4.m4.2b"><apply id="S3.SS2.p4.4.m4.2.3.cmml" xref="S3.SS2.p4.4.m4.2.3"><times id="S3.SS2.p4.4.m4.2.3.1.cmml" xref="S3.SS2.p4.4.m4.2.3.1"></times><ci id="S3.SS2.p4.4.m4.2.3.2.cmml" xref="S3.SS2.p4.4.m4.2.3.2">𝐼</ci><interval closure="open" id="S3.SS2.p4.4.m4.2.3.3.1.cmml" xref="S3.SS2.p4.4.m4.2.3.3.2"><ci id="S3.SS2.p4.4.m4.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1">𝑥</ci><ci id="S3.SS2.p4.4.m4.2.2.cmml" xref="S3.SS2.p4.4.m4.2.2">𝑦</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.4.m4.2c">I(x,y)</annotation></semantics></math>, in the vertical and horizontal direction is then:</p>
</div>
<div id="S3.SS2.p5" class="ltx_para">
<table id="S3.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.Ex1.m1.4" class="ltx_Math" alttext="D(x,y)=c\cdot\frac{M(x,y)-127.5}{127.5}" display="block"><semantics id="S3.Ex1.m1.4a"><mrow id="S3.Ex1.m1.4.5" xref="S3.Ex1.m1.4.5.cmml"><mrow id="S3.Ex1.m1.4.5.2" xref="S3.Ex1.m1.4.5.2.cmml"><mi id="S3.Ex1.m1.4.5.2.2" xref="S3.Ex1.m1.4.5.2.2.cmml">D</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.4.5.2.1" xref="S3.Ex1.m1.4.5.2.1.cmml">​</mo><mrow id="S3.Ex1.m1.4.5.2.3.2" xref="S3.Ex1.m1.4.5.2.3.1.cmml"><mo stretchy="false" id="S3.Ex1.m1.4.5.2.3.2.1" xref="S3.Ex1.m1.4.5.2.3.1.cmml">(</mo><mi id="S3.Ex1.m1.3.3" xref="S3.Ex1.m1.3.3.cmml">x</mi><mo id="S3.Ex1.m1.4.5.2.3.2.2" xref="S3.Ex1.m1.4.5.2.3.1.cmml">,</mo><mi id="S3.Ex1.m1.4.4" xref="S3.Ex1.m1.4.4.cmml">y</mi><mo stretchy="false" id="S3.Ex1.m1.4.5.2.3.2.3" xref="S3.Ex1.m1.4.5.2.3.1.cmml">)</mo></mrow></mrow><mo id="S3.Ex1.m1.4.5.1" xref="S3.Ex1.m1.4.5.1.cmml">=</mo><mrow id="S3.Ex1.m1.4.5.3" xref="S3.Ex1.m1.4.5.3.cmml"><mi id="S3.Ex1.m1.4.5.3.2" xref="S3.Ex1.m1.4.5.3.2.cmml">c</mi><mo lspace="0.222em" rspace="0.222em" id="S3.Ex1.m1.4.5.3.1" xref="S3.Ex1.m1.4.5.3.1.cmml">⋅</mo><mfrac id="S3.Ex1.m1.2.2" xref="S3.Ex1.m1.2.2.cmml"><mrow id="S3.Ex1.m1.2.2.2" xref="S3.Ex1.m1.2.2.2.cmml"><mrow id="S3.Ex1.m1.2.2.2.4" xref="S3.Ex1.m1.2.2.2.4.cmml"><mi id="S3.Ex1.m1.2.2.2.4.2" xref="S3.Ex1.m1.2.2.2.4.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.2.2.2.4.1" xref="S3.Ex1.m1.2.2.2.4.1.cmml">​</mo><mrow id="S3.Ex1.m1.2.2.2.4.3.2" xref="S3.Ex1.m1.2.2.2.4.3.1.cmml"><mo stretchy="false" id="S3.Ex1.m1.2.2.2.4.3.2.1" xref="S3.Ex1.m1.2.2.2.4.3.1.cmml">(</mo><mi id="S3.Ex1.m1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.cmml">x</mi><mo id="S3.Ex1.m1.2.2.2.4.3.2.2" xref="S3.Ex1.m1.2.2.2.4.3.1.cmml">,</mo><mi id="S3.Ex1.m1.2.2.2.2" xref="S3.Ex1.m1.2.2.2.2.cmml">y</mi><mo stretchy="false" id="S3.Ex1.m1.2.2.2.4.3.2.3" xref="S3.Ex1.m1.2.2.2.4.3.1.cmml">)</mo></mrow></mrow><mo id="S3.Ex1.m1.2.2.2.3" xref="S3.Ex1.m1.2.2.2.3.cmml">−</mo><mn id="S3.Ex1.m1.2.2.2.5" xref="S3.Ex1.m1.2.2.2.5.cmml">127.5</mn></mrow><mn id="S3.Ex1.m1.2.2.4" xref="S3.Ex1.m1.2.2.4.cmml">127.5</mn></mfrac></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex1.m1.4b"><apply id="S3.Ex1.m1.4.5.cmml" xref="S3.Ex1.m1.4.5"><eq id="S3.Ex1.m1.4.5.1.cmml" xref="S3.Ex1.m1.4.5.1"></eq><apply id="S3.Ex1.m1.4.5.2.cmml" xref="S3.Ex1.m1.4.5.2"><times id="S3.Ex1.m1.4.5.2.1.cmml" xref="S3.Ex1.m1.4.5.2.1"></times><ci id="S3.Ex1.m1.4.5.2.2.cmml" xref="S3.Ex1.m1.4.5.2.2">𝐷</ci><interval closure="open" id="S3.Ex1.m1.4.5.2.3.1.cmml" xref="S3.Ex1.m1.4.5.2.3.2"><ci id="S3.Ex1.m1.3.3.cmml" xref="S3.Ex1.m1.3.3">𝑥</ci><ci id="S3.Ex1.m1.4.4.cmml" xref="S3.Ex1.m1.4.4">𝑦</ci></interval></apply><apply id="S3.Ex1.m1.4.5.3.cmml" xref="S3.Ex1.m1.4.5.3"><ci id="S3.Ex1.m1.4.5.3.1.cmml" xref="S3.Ex1.m1.4.5.3.1">⋅</ci><ci id="S3.Ex1.m1.4.5.3.2.cmml" xref="S3.Ex1.m1.4.5.3.2">𝑐</ci><apply id="S3.Ex1.m1.2.2.cmml" xref="S3.Ex1.m1.2.2"><divide id="S3.Ex1.m1.2.2.3.cmml" xref="S3.Ex1.m1.2.2"></divide><apply id="S3.Ex1.m1.2.2.2.cmml" xref="S3.Ex1.m1.2.2.2"><minus id="S3.Ex1.m1.2.2.2.3.cmml" xref="S3.Ex1.m1.2.2.2.3"></minus><apply id="S3.Ex1.m1.2.2.2.4.cmml" xref="S3.Ex1.m1.2.2.2.4"><times id="S3.Ex1.m1.2.2.2.4.1.cmml" xref="S3.Ex1.m1.2.2.2.4.1"></times><ci id="S3.Ex1.m1.2.2.2.4.2.cmml" xref="S3.Ex1.m1.2.2.2.4.2">𝑀</ci><interval closure="open" id="S3.Ex1.m1.2.2.2.4.3.1.cmml" xref="S3.Ex1.m1.2.2.2.4.3.2"><ci id="S3.Ex1.m1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1">𝑥</ci><ci id="S3.Ex1.m1.2.2.2.2.cmml" xref="S3.Ex1.m1.2.2.2.2">𝑦</ci></interval></apply><cn type="float" id="S3.Ex1.m1.2.2.2.5.cmml" xref="S3.Ex1.m1.2.2.2.5">127.5</cn></apply><cn type="float" id="S3.Ex1.m1.2.2.4.cmml" xref="S3.Ex1.m1.2.2.4">127.5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex1.m1.4c">D(x,y)=c\cdot\frac{M(x,y)-127.5}{127.5}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.p6" class="ltx_para">
<p id="S3.SS2.p6.1" class="ltx_p">PRNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> is used to generate the depth maps used in this work. PRNet is capable of performing 3D face reconstruction from 2D face images, and as such, it can also approximate depth maps from 2D facial images. An example of a depth map generated using PRNet is shown in Fig. <a href="#S3.F6.sf1" title="In Figure 6 ‣ III-B Blending ‣ III Facial Tattoo Generator ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(a)</span></a>.</p>
</div>
<figure id="S3.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F6.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2202.05297/assets/graphics/04746d02_depth.jpg" id="S3.F6.sf1.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="359" height="479" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F6.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S3.F6.sf1.3.2" class="ltx_text" style="font-size:90%;">Depth image generated by PRNet</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F6.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2202.05297/assets/graphics/04746d02_depth_transformed.png" id="S3.F6.sf2.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="359" height="479" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F6.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S3.F6.sf2.3.2" class="ltx_text" style="font-size:90%;">Transformed depth image</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S3.F6.3.2" class="ltx_text" style="font-size:90%;">Example of (a) a depth map generated from a facial image using PRNet and (b) after it has been transformed.</span></figcaption>
</figure>
<figure id="S3.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F7.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2202.05297/assets/graphics/displace_25/04697d02_447_nodisplace.jpg" id="S3.F7.sf1.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="359" height="479" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F7.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S3.F7.sf1.3.2" class="ltx_text" style="font-size:90%;">not displaced</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F7.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2202.05297/assets/graphics/displace_25/04697d02_447_displace.jpg" id="S3.F7.sf2.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="359" height="479" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F7.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S3.F7.sf2.3.2" class="ltx_text" style="font-size:90%;">displaced</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F7.2.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S3.F7.3.2" class="ltx_text" style="font-size:90%;">Facial images with tattoos (a) before and (b) after applying the displacement technique. For (b) the tattoo is bended around the anticipated 3D shape of the nose. Best viewed in electronic format (zoomed in).</span></figcaption>
</figure>
<div id="S3.SS2.p7" class="ltx_para">
<p id="S3.SS2.p7.1" class="ltx_p">As seen in Fig. <a href="#S3.F6.sf1" title="In Figure 6 ‣ III-B Blending ‣ III Facial Tattoo Generator ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(a)</span></a>, the pixel values in the face region are rather bright, and there is little contrast. The small contrast between the pixel values and the high offset from the theoretical average pixel value implies that the depth map will not work very well as tattoos will be displaced too much in certain regions and too little in others. Therefore, to make the displacement more realistic, the depth map generated by PRNet is transformed by increasing the contrast and lowering the brightness of the map. Fig. <a href="#S3.F6.sf2" title="In Figure 6 ‣ III-B Blending ‣ III Facial Tattoo Generator ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(b)</span></a> shows an example of a transformed depth map, and as it can be seen, the pixel values are much closer to the theoretical average value than the unaltered map, while the contrast around the nose, eyes and mouth are still high. Fig. <a href="#S3.F7" title="Figure 7 ‣ III-B Blending ‣ III Facial Tattoo Generator ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows an example where two facial tattoos are displaced to match the contours of a face.</p>
</div>
<figure id="S3.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F8.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2202.05297/assets/graphics/new_cut/04816d36_321.jpg" id="S3.F8.1.g1" class="ltx_graphics ltx_img_portrait" width="598" height="798" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F8.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2202.05297/assets/graphics/new_cut/04846d98_585_576.jpg" id="S3.F8.2.g1" class="ltx_graphics ltx_img_portrait" width="598" height="798" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F8.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2202.05297/assets/graphics/new_cut/04874d00_130_414.jpg" id="S3.F8.3.g1" class="ltx_graphics ltx_img_portrait" width="598" height="798" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F8.5.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="S3.F8.6.2" class="ltx_text" style="font-size:90%;">Examples of facial images where parts of one or more tattoos have been cut out.</span></figcaption>
</figure>
<div id="S3.SS2.p8" class="ltx_para">
<p id="S3.SS2.p8.1" class="ltx_p">Black ink tends to change in colour slightly over time due to the pigment used in black ink. Therefore, for colour adjustment, all pixels of a tattoo which is similar to pure black are selected and changed to simulate different colours of grey, green, and blue, which causes black tattoos to appear different for different facial images. The colour adjustments of black pixels are determined per tattoo, and as such slight variations can occur between different tattoos in the same facial image. Examples are given in Fig. <a href="#S3.F9" title="Figure 9 ‣ III-B Blending ‣ III Facial Tattoo Generator ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>.</p>
</div>
<figure id="S3.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F9.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2202.05297/assets/graphics/new_black/04763d02_443_452.jpg" id="S3.F9.1.g1" class="ltx_graphics ltx_img_portrait" width="598" height="798" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F9.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2202.05297/assets/graphics/new_black/04575d74_590_420_467.jpg" id="S3.F9.2.g1" class="ltx_graphics ltx_img_portrait" width="598" height="798" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F9.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2202.05297/assets/graphics/new_black/04936d02_580_441.jpg" id="S3.F9.3.g1" class="ltx_graphics ltx_img_portrait" width="598" height="798" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F9.5.1.1" class="ltx_text" style="font-size:90%;">Figure 9</span>: </span><span id="S3.F9.6.2" class="ltx_text" style="font-size:90%;">Examples of black tattoos blended to facial images.</span></figcaption>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.4.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.5.2" class="ltx_text ltx_font_italic">Generation Strategies</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">By varying how tattoos are selected and placed (Sect. <a href="#S3.SS1" title="III-A Placement of Tattoos ‣ III Facial Tattoo Generator ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-A</span></span></a>), many different types of facial images with tattoos can be generated. For the database used in this work, we employed two different strategies. In the first strategy, a desired coverage percent of tattoos on a face is randomly chosen from a specified range. Subsequently, tattoos are arbitrarily selected and placed on facial regions until the resulting coverage approximates the desired coverage. The coverage of a tattoo on a face is calculated based on the total amount of facial regions to which tattoos can be placed (see Fig. <a href="#S3.F4.sf3" title="In Figure 4 ‣ III-A Placement of Tattoos ‣ III Facial Tattoo Generator ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(c)</span></a>) and the number of non-transparent pixels in the placed tattoos. In the second strategy, a specific region is always selected. Using the first strategy, it is possible to create databases where tattoos are placed arbitrarily until a selected coverage percent has been reached (see Fig. <a href="#S3.F10.sf1" title="In Figure 10 ‣ III-C Generation Strategies ‣ III Facial Tattoo Generator ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10(a)</span></a>-<a href="#S3.F10.sf3" title="In Figure 10 ‣ III-C Generation Strategies ‣ III Facial Tattoo Generator ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10(c)</span></a>). Using the latter approach allows for more controlled placement of tattoos, <span id="S3.SS3.p1.1.1" class="ltx_text ltx_font_italic">e.g.</span> placing tattoos in the entire face region (Fig. <a href="#S3.F10.sf4" title="In Figure 10 ‣ III-C Generation Strategies ‣ III Facial Tattoo Generator ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10(d)</span></a>) or in a specific region (Fig. <a href="#S3.F10.sf5" title="In Figure 10 ‣ III-C Generation Strategies ‣ III Facial Tattoo Generator ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10(e)</span></a>-<a href="#S3.F10.sf6" title="In Figure 10 ‣ III-C Generation Strategies ‣ III Facial Tattoo Generator ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10(f)</span></a>).</p>
</div>
<figure id="S3.F10" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F10.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2202.05297/assets/graphics/generation_types_examples/04789d10_41_212_425_401_cov5.jpg" id="S3.F10.sf1.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="598" height="798" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F10.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F10.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2202.05297/assets/graphics/generation_types_examples/04789d10_499_135_405_185_211_540_279_487_306_86_412_577_406_422_283_329_cov15.jpg" id="S3.F10.sf2.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="598" height="798" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F10.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F10.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2202.05297/assets/graphics/generation_types_examples/04789d10_405_323_cov25.jpg" id="S3.F10.sf3.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="598" height="798" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F10.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F10.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2202.05297/assets/graphics/generation_types_examples/04789d10_28_extreme.jpg" id="S3.F10.sf4.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="598" height="798" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F10.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F10.sf5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2202.05297/assets/graphics/generation_types_examples/04789d10_16_portrait.jpg" id="S3.F10.sf5.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="598" height="798" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F10.sf5.2.1.1" class="ltx_text" style="font-size:90%;">(e)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F10.sf6" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2202.05297/assets/graphics/generation_types_examples/04789d10_455_585_145_458_left_cheek.jpg" id="S3.F10.sf6.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="598" height="798" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F10.sf6.2.1.1" class="ltx_text" style="font-size:90%;">(f)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F10.2.1.1" class="ltx_text" style="font-size:90%;">Figure 10</span>: </span><span id="S3.F10.3.2" class="ltx_text" style="font-size:90%;">Examples for different types of tattooed face that can be generated: (a) 5%, (b) 15%, (c) 25% coverage, (d) entire face, (e) single tattoo, and (f) specific region.</span></figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Synthetic Tattoo Database</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.2" class="ltx_p">This section describes the generation of a large database of facial images with tattoos. The database is used in section <a href="#S5" title="V Tattoo Removal ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a> to train deep learning-based models for removing tattoos from facial images. To generate the synthetic tattoo database, subsets of original images from the FERET <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>, FRGCv2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>, and CelebA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> datasets were used. An overview of the generated database is given in Table <a href="#S4.T1" title="TABLE I ‣ IV Synthetic Tattoo Database ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>. For the FERET and FRGCv2 datasets, different generation strategies were used, including facial images where tattoos have been placed randomly, with specific coverage ranging from 5<math id="S4.p1.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.p1.1.m1.1a"><mo id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><csymbol cd="latexml" id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">\%</annotation></semantics></math> to 25<math id="S4.p1.2.m2.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.p1.2.m2.1a"><mo id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><csymbol cd="latexml" id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">\%</annotation></semantics></math> as well as placement of single tattoos. For the single tattoos, we generated two versions: one version where the tattoo is placed in the entire facial region and another where portrait tattoos are blended to a random region in the face. For the CelebA database, which is more uncontrolled, facial tattoos were placed randomly. To simulate varying image qualities, a data augmentation was performed by randomly applying differing degrees of JPEG compression or Gaussian blur to all the images. Tattoo images and corresponding original (bona fide) images were paired such that similar augmentation was applied to corresponding images.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T1.2.1.1" class="ltx_text" style="font-size:90%;">TABLE I</span>: </span><span id="S4.T1.3.2" class="ltx_text" style="font-size:90%;">Overview of the generated database (before augmentation).</span></figcaption>
<table id="S4.T1.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T1.4.1" class="ltx_tr">
<td id="S4.T1.4.1.1" class="ltx_td ltx_align_left ltx_border_tt" rowspan="2"><span id="S4.T1.4.1.1.1" class="ltx_text ltx_font_bold">Database</span></td>
<td id="S4.T1.4.1.2" class="ltx_td ltx_align_right ltx_border_tt" rowspan="2"><span id="S4.T1.4.1.2.1" class="ltx_text ltx_font_bold">Subjects</span></td>
<td id="S4.T1.4.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S4.T1.4.1.3.1" class="ltx_text ltx_font_bold">Images</span></td>
</tr>
<tr id="S4.T1.4.2" class="ltx_tr">
<td id="S4.T1.4.2.1" class="ltx_td ltx_align_right ltx_border_t"><span id="S4.T1.4.2.1.1" class="ltx_text ltx_font_bold">Bona fide</span></td>
<td id="S4.T1.4.2.2" class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t"><span id="S4.T1.4.2.2.1" class="ltx_text ltx_font_bold">Tattooed</span></td>
</tr>
<tr id="S4.T1.4.3" class="ltx_tr">
<td id="S4.T1.4.3.1" class="ltx_td ltx_align_left ltx_border_t">FERET</td>
<td id="S4.T1.4.3.2" class="ltx_td ltx_align_right ltx_border_t">529</td>
<td id="S4.T1.4.3.3" class="ltx_td ltx_align_right ltx_border_t">621</td>
<td id="S4.T1.4.3.4" class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t">6,743</td>
</tr>
<tr id="S4.T1.4.4" class="ltx_tr">
<td id="S4.T1.4.4.1" class="ltx_td ltx_align_left">FRGCv2</td>
<td id="S4.T1.4.4.2" class="ltx_td ltx_align_right">533</td>
<td id="S4.T1.4.4.3" class="ltx_td ltx_align_right">1,436</td>
<td id="S4.T1.4.4.4" class="ltx_td ltx_nopad_r ltx_align_right">16,209</td>
</tr>
<tr id="S4.T1.4.5" class="ltx_tr">
<td id="S4.T1.4.5.1" class="ltx_td ltx_align_left ltx_border_bb">CelebA</td>
<td id="S4.T1.4.5.2" class="ltx_td ltx_align_right ltx_border_bb">6,872</td>
<td id="S4.T1.4.5.3" class="ltx_td ltx_align_right ltx_border_bb">6,872</td>
<td id="S4.T1.4.5.4" class="ltx_td ltx_nopad_r ltx_align_right ltx_border_bb">6,872</td>
</tr>
</table>
</figure>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">Examples of images in the generated database are depicted in Fig. <a href="#S4.F11" title="Figure 11 ‣ IV Synthetic Tattoo Database ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>.</p>
</div>
<figure id="S4.F11" class="ltx_figure"><img src="/html/2202.05297/assets/graphics/generation_examples_alligned.jpg" id="S4.F11.g1" class="ltx_graphics ltx_centering ltx_img_square" width="419" height="437" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F11.2.1.1" class="ltx_text" style="font-size:90%;">Figure 11</span>: </span><span id="S4.F11.3.2" class="ltx_text" style="font-size:90%;">Examples of generated facial images with tattoos.</span></figcaption>
</figure>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Tattoo Removal</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">To evaluate the realism of the proposed data generation and its use in real-world applications, two models are trained for the task of tattoo removal. Sect. <a href="#S5.SS1" title="V-A Models ‣ V Tattoo Removal ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-A</span></span></a> briefly describes the different models used for removing tattoos. Sect. <a href="#S5.SS2" title="V-B Quality Metrics ‣ V Tattoo Removal ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-B</span></span></a> describes different metrics for evaluating the quality of the tattoo removal which is then evaluated in Sect. <a href="#S5.SS3" title="V-C Removal Quality Results ‣ V Tattoo Removal ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-C</span></span></a>.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.4.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.5.2" class="ltx_text ltx_font_italic">Models</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">Two different deep learning-based methods were trained for removing tattoos from facial images:</p>
<dl id="S5.I1" class="ltx_description">
<dt id="S5.I1.ix1" class="ltx_item"><span class="ltx_tag ltx_tag_item"><span id="S5.I1.ix1.1.1.1" class="ltx_text ltx_font_bold">pix2pix</span></span></dt>
<dd class="ltx_item">
<div id="S5.I1.ix1.p1" class="ltx_para">
<p id="S5.I1.ix1.p1.1" class="ltx_p">is a supervised conditional GAN for image-to-image translation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>. For the generator, a U-Net architecture is used, whereas the discriminator is based on a PatchGAN classifier which divides the image into <math id="S5.I1.ix1.p1.1.m1.1" class="ltx_Math" alttext="N\times N" display="inline"><semantics id="S5.I1.ix1.p1.1.m1.1a"><mrow id="S5.I1.ix1.p1.1.m1.1.1" xref="S5.I1.ix1.p1.1.m1.1.1.cmml"><mi id="S5.I1.ix1.p1.1.m1.1.1.2" xref="S5.I1.ix1.p1.1.m1.1.1.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S5.I1.ix1.p1.1.m1.1.1.1" xref="S5.I1.ix1.p1.1.m1.1.1.1.cmml">×</mo><mi id="S5.I1.ix1.p1.1.m1.1.1.3" xref="S5.I1.ix1.p1.1.m1.1.1.3.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.ix1.p1.1.m1.1b"><apply id="S5.I1.ix1.p1.1.m1.1.1.cmml" xref="S5.I1.ix1.p1.1.m1.1.1"><times id="S5.I1.ix1.p1.1.m1.1.1.1.cmml" xref="S5.I1.ix1.p1.1.m1.1.1.1"></times><ci id="S5.I1.ix1.p1.1.m1.1.1.2.cmml" xref="S5.I1.ix1.p1.1.m1.1.1.2">𝑁</ci><ci id="S5.I1.ix1.p1.1.m1.1.1.3.cmml" xref="S5.I1.ix1.p1.1.m1.1.1.3">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.ix1.p1.1.m1.1c">N\times N</annotation></semantics></math> patches and discriminates between bona fide (<span id="S5.I1.ix1.p1.1.1" class="ltx_text ltx_font_italic">i.e.</span>, real images) and fake images.</p>
</div>
</dd>
</dl>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<dl id="S5.I2" class="ltx_description">
<dt id="S5.I2.ix1" class="ltx_item"><span class="ltx_tag ltx_tag_item"><span id="S5.I2.ix1.1.1.1" class="ltx_text ltx_font_bold">Tattoo Removal Net (TRNet)</span></span></dt>
<dd class="ltx_item">
<div id="S5.I2.ix1.p1" class="ltx_para">
<p id="S5.I2.ix1.p1.1" class="ltx_p">is a U-net architecture <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> with spectral normalization and self-attention trained on our synthetic data (Sect.<a href="#S4" title="IV Synthetic Tattoo Database ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>). The U-Net architecture is depicted in Fig. <a href="#S5.F12" title="Figure 12 ‣ V-A Models ‣ V Tattoo Removal ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>; the encoder is based on ResNet34 and the decoder consist of four main blocks and utilize PixelShuffling <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>. The loss function is a combination of feature loss (perceptual loss) from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>, gram matrix style loss <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>, and pixel (L1) loss. For the gram matrix loss and the feature loss, blocks from a pre-trained VGG-16 model is used <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>.</p>
</div>
</dd>
</dl>
</div>
<figure id="S5.F12" class="ltx_figure"><img src="/html/2202.05297/assets/x2.png" id="S5.F12.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="438" height="253" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F12.2.1.1" class="ltx_text" style="font-size:90%;">Figure 12</span>: </span><span id="S5.F12.3.2" class="ltx_text" style="font-size:90%;">Architecture of the tattoo removal network (TRNet).</span></figcaption>
</figure>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS2.4.1.1" class="ltx_text">V-B</span> </span><span id="S5.SS2.5.2" class="ltx_text ltx_font_italic">Quality Metrics</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">To evaluate the quality of the different tattoo removal models, we use three different metrics commonly used in the literature:</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<dl id="S5.I3" class="ltx_description">
<dt id="S5.I3.ix1" class="ltx_item"><span class="ltx_tag ltx_tag_item"><span id="S5.I3.ix1.1.1.1" class="ltx_text ltx_font_bold">Peak signal-to-noise ratio (PSNR)</span></span></dt>
<dd class="ltx_item">
<div id="S5.I3.ix1.p1" class="ltx_para">
<p id="S5.I3.ix1.p1.1" class="ltx_p">is a measurement of error between an input and an output image and is calculated as follows:</p>
</div>
<div id="S5.I3.ix1.p2" class="ltx_para">
<table id="S5.Ex2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S5.Ex2.m1.4" class="ltx_Math" alttext="\mathit{PSNR}(X,Y)=20\cdot log_{10}\ (\frac{\mathit{MAX}_{I}}{\sqrt{\mathit{MSE}(X,Y)}})" display="block"><semantics id="S5.Ex2.m1.4a"><mrow id="S5.Ex2.m1.4.5" xref="S5.Ex2.m1.4.5.cmml"><mrow id="S5.Ex2.m1.4.5.2" xref="S5.Ex2.m1.4.5.2.cmml"><mi id="S5.Ex2.m1.4.5.2.2" xref="S5.Ex2.m1.4.5.2.2.cmml">𝑃𝑆𝑁𝑅</mi><mo lspace="0em" rspace="0em" id="S5.Ex2.m1.4.5.2.1" xref="S5.Ex2.m1.4.5.2.1.cmml">​</mo><mrow id="S5.Ex2.m1.4.5.2.3.2" xref="S5.Ex2.m1.4.5.2.3.1.cmml"><mo stretchy="false" id="S5.Ex2.m1.4.5.2.3.2.1" xref="S5.Ex2.m1.4.5.2.3.1.cmml">(</mo><mi id="S5.Ex2.m1.3.3" xref="S5.Ex2.m1.3.3.cmml">X</mi><mo id="S5.Ex2.m1.4.5.2.3.2.2" xref="S5.Ex2.m1.4.5.2.3.1.cmml">,</mo><mi id="S5.Ex2.m1.4.4" xref="S5.Ex2.m1.4.4.cmml">Y</mi><mo stretchy="false" id="S5.Ex2.m1.4.5.2.3.2.3" xref="S5.Ex2.m1.4.5.2.3.1.cmml">)</mo></mrow></mrow><mo id="S5.Ex2.m1.4.5.1" xref="S5.Ex2.m1.4.5.1.cmml">=</mo><mrow id="S5.Ex2.m1.4.5.3" xref="S5.Ex2.m1.4.5.3.cmml"><mrow id="S5.Ex2.m1.4.5.3.2" xref="S5.Ex2.m1.4.5.3.2.cmml"><mn id="S5.Ex2.m1.4.5.3.2.2" xref="S5.Ex2.m1.4.5.3.2.2.cmml">20</mn><mo lspace="0.222em" rspace="0.222em" id="S5.Ex2.m1.4.5.3.2.1" xref="S5.Ex2.m1.4.5.3.2.1.cmml">⋅</mo><mi id="S5.Ex2.m1.4.5.3.2.3" xref="S5.Ex2.m1.4.5.3.2.3.cmml">l</mi></mrow><mo lspace="0em" rspace="0em" id="S5.Ex2.m1.4.5.3.1" xref="S5.Ex2.m1.4.5.3.1.cmml">​</mo><mi id="S5.Ex2.m1.4.5.3.3" xref="S5.Ex2.m1.4.5.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.Ex2.m1.4.5.3.1a" xref="S5.Ex2.m1.4.5.3.1.cmml">​</mo><msub id="S5.Ex2.m1.4.5.3.4" xref="S5.Ex2.m1.4.5.3.4.cmml"><mi id="S5.Ex2.m1.4.5.3.4.2" xref="S5.Ex2.m1.4.5.3.4.2.cmml">g</mi><mn id="S5.Ex2.m1.4.5.3.4.3" xref="S5.Ex2.m1.4.5.3.4.3.cmml">10</mn></msub><mo lspace="0em" rspace="0em" id="S5.Ex2.m1.4.5.3.1b" xref="S5.Ex2.m1.4.5.3.1.cmml">​</mo><mrow id="S5.Ex2.m1.4.5.3.5.2" xref="S5.Ex2.m1.2.2.cmml"><mo stretchy="false" id="S5.Ex2.m1.4.5.3.5.2.1" xref="S5.Ex2.m1.2.2.cmml">(</mo><mfrac id="S5.Ex2.m1.2.2" xref="S5.Ex2.m1.2.2.cmml"><msub id="S5.Ex2.m1.2.2.4" xref="S5.Ex2.m1.2.2.4.cmml"><mi id="S5.Ex2.m1.2.2.4.2" xref="S5.Ex2.m1.2.2.4.2.cmml">𝑀𝐴𝑋</mi><mi id="S5.Ex2.m1.2.2.4.3" xref="S5.Ex2.m1.2.2.4.3.cmml">I</mi></msub><msqrt id="S5.Ex2.m1.2.2.2" xref="S5.Ex2.m1.2.2.2.cmml"><mrow id="S5.Ex2.m1.2.2.2.2.2" xref="S5.Ex2.m1.2.2.2.2.2.cmml"><mi id="S5.Ex2.m1.2.2.2.2.2.4" xref="S5.Ex2.m1.2.2.2.2.2.4.cmml">𝑀𝑆𝐸</mi><mo lspace="0em" rspace="0em" id="S5.Ex2.m1.2.2.2.2.2.3" xref="S5.Ex2.m1.2.2.2.2.2.3.cmml">​</mo><mrow id="S5.Ex2.m1.2.2.2.2.2.5.2" xref="S5.Ex2.m1.2.2.2.2.2.5.1.cmml"><mo stretchy="false" id="S5.Ex2.m1.2.2.2.2.2.5.2.1" xref="S5.Ex2.m1.2.2.2.2.2.5.1.cmml">(</mo><mi id="S5.Ex2.m1.1.1.1.1.1.1" xref="S5.Ex2.m1.1.1.1.1.1.1.cmml">X</mi><mo id="S5.Ex2.m1.2.2.2.2.2.5.2.2" xref="S5.Ex2.m1.2.2.2.2.2.5.1.cmml">,</mo><mi id="S5.Ex2.m1.2.2.2.2.2.2" xref="S5.Ex2.m1.2.2.2.2.2.2.cmml">Y</mi><mo stretchy="false" id="S5.Ex2.m1.2.2.2.2.2.5.2.3" xref="S5.Ex2.m1.2.2.2.2.2.5.1.cmml">)</mo></mrow></mrow></msqrt></mfrac><mo stretchy="false" id="S5.Ex2.m1.4.5.3.5.2.2" xref="S5.Ex2.m1.2.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.Ex2.m1.4b"><apply id="S5.Ex2.m1.4.5.cmml" xref="S5.Ex2.m1.4.5"><eq id="S5.Ex2.m1.4.5.1.cmml" xref="S5.Ex2.m1.4.5.1"></eq><apply id="S5.Ex2.m1.4.5.2.cmml" xref="S5.Ex2.m1.4.5.2"><times id="S5.Ex2.m1.4.5.2.1.cmml" xref="S5.Ex2.m1.4.5.2.1"></times><ci id="S5.Ex2.m1.4.5.2.2.cmml" xref="S5.Ex2.m1.4.5.2.2">𝑃𝑆𝑁𝑅</ci><interval closure="open" id="S5.Ex2.m1.4.5.2.3.1.cmml" xref="S5.Ex2.m1.4.5.2.3.2"><ci id="S5.Ex2.m1.3.3.cmml" xref="S5.Ex2.m1.3.3">𝑋</ci><ci id="S5.Ex2.m1.4.4.cmml" xref="S5.Ex2.m1.4.4">𝑌</ci></interval></apply><apply id="S5.Ex2.m1.4.5.3.cmml" xref="S5.Ex2.m1.4.5.3"><times id="S5.Ex2.m1.4.5.3.1.cmml" xref="S5.Ex2.m1.4.5.3.1"></times><apply id="S5.Ex2.m1.4.5.3.2.cmml" xref="S5.Ex2.m1.4.5.3.2"><ci id="S5.Ex2.m1.4.5.3.2.1.cmml" xref="S5.Ex2.m1.4.5.3.2.1">⋅</ci><cn type="integer" id="S5.Ex2.m1.4.5.3.2.2.cmml" xref="S5.Ex2.m1.4.5.3.2.2">20</cn><ci id="S5.Ex2.m1.4.5.3.2.3.cmml" xref="S5.Ex2.m1.4.5.3.2.3">𝑙</ci></apply><ci id="S5.Ex2.m1.4.5.3.3.cmml" xref="S5.Ex2.m1.4.5.3.3">𝑜</ci><apply id="S5.Ex2.m1.4.5.3.4.cmml" xref="S5.Ex2.m1.4.5.3.4"><csymbol cd="ambiguous" id="S5.Ex2.m1.4.5.3.4.1.cmml" xref="S5.Ex2.m1.4.5.3.4">subscript</csymbol><ci id="S5.Ex2.m1.4.5.3.4.2.cmml" xref="S5.Ex2.m1.4.5.3.4.2">𝑔</ci><cn type="integer" id="S5.Ex2.m1.4.5.3.4.3.cmml" xref="S5.Ex2.m1.4.5.3.4.3">10</cn></apply><apply id="S5.Ex2.m1.2.2.cmml" xref="S5.Ex2.m1.4.5.3.5.2"><divide id="S5.Ex2.m1.2.2.3.cmml" xref="S5.Ex2.m1.4.5.3.5.2"></divide><apply id="S5.Ex2.m1.2.2.4.cmml" xref="S5.Ex2.m1.2.2.4"><csymbol cd="ambiguous" id="S5.Ex2.m1.2.2.4.1.cmml" xref="S5.Ex2.m1.2.2.4">subscript</csymbol><ci id="S5.Ex2.m1.2.2.4.2.cmml" xref="S5.Ex2.m1.2.2.4.2">𝑀𝐴𝑋</ci><ci id="S5.Ex2.m1.2.2.4.3.cmml" xref="S5.Ex2.m1.2.2.4.3">𝐼</ci></apply><apply id="S5.Ex2.m1.2.2.2.cmml" xref="S5.Ex2.m1.2.2.2"><root id="S5.Ex2.m1.2.2.2a.cmml" xref="S5.Ex2.m1.2.2.2"></root><apply id="S5.Ex2.m1.2.2.2.2.2.cmml" xref="S5.Ex2.m1.2.2.2.2.2"><times id="S5.Ex2.m1.2.2.2.2.2.3.cmml" xref="S5.Ex2.m1.2.2.2.2.2.3"></times><ci id="S5.Ex2.m1.2.2.2.2.2.4.cmml" xref="S5.Ex2.m1.2.2.2.2.2.4">𝑀𝑆𝐸</ci><interval closure="open" id="S5.Ex2.m1.2.2.2.2.2.5.1.cmml" xref="S5.Ex2.m1.2.2.2.2.2.5.2"><ci id="S5.Ex2.m1.1.1.1.1.1.1.cmml" xref="S5.Ex2.m1.1.1.1.1.1.1">𝑋</ci><ci id="S5.Ex2.m1.2.2.2.2.2.2.cmml" xref="S5.Ex2.m1.2.2.2.2.2.2">𝑌</ci></interval></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.Ex2.m1.4c">\mathit{PSNR}(X,Y)=20\cdot log_{10}\ (\frac{\mathit{MAX}_{I}}{\sqrt{\mathit{MSE}(X,Y)}})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S5.I3.ix1.p3" class="ltx_para">
<p id="S5.I3.ix1.p3.4" class="ltx_p">where <math id="S5.I3.ix1.p3.1.m1.1" class="ltx_Math" alttext="\mathit{MAX}_{I}" display="inline"><semantics id="S5.I3.ix1.p3.1.m1.1a"><msub id="S5.I3.ix1.p3.1.m1.1.1" xref="S5.I3.ix1.p3.1.m1.1.1.cmml"><mi id="S5.I3.ix1.p3.1.m1.1.1.2" xref="S5.I3.ix1.p3.1.m1.1.1.2.cmml">𝑀𝐴𝑋</mi><mi id="S5.I3.ix1.p3.1.m1.1.1.3" xref="S5.I3.ix1.p3.1.m1.1.1.3.cmml">I</mi></msub><annotation-xml encoding="MathML-Content" id="S5.I3.ix1.p3.1.m1.1b"><apply id="S5.I3.ix1.p3.1.m1.1.1.cmml" xref="S5.I3.ix1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S5.I3.ix1.p3.1.m1.1.1.1.cmml" xref="S5.I3.ix1.p3.1.m1.1.1">subscript</csymbol><ci id="S5.I3.ix1.p3.1.m1.1.1.2.cmml" xref="S5.I3.ix1.p3.1.m1.1.1.2">𝑀𝐴𝑋</ci><ci id="S5.I3.ix1.p3.1.m1.1.1.3.cmml" xref="S5.I3.ix1.p3.1.m1.1.1.3">𝐼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I3.ix1.p3.1.m1.1c">\mathit{MAX}_{I}</annotation></semantics></math> is the theoretical maximum pixel value (<span id="S5.I3.ix1.p3.4.1" class="ltx_text ltx_font_italic">i.e.</span> 255 for 8 bit channels) and <math id="S5.I3.ix1.p3.2.m2.2" class="ltx_Math" alttext="\mathit{MSE}(X,Y)" display="inline"><semantics id="S5.I3.ix1.p3.2.m2.2a"><mrow id="S5.I3.ix1.p3.2.m2.2.3" xref="S5.I3.ix1.p3.2.m2.2.3.cmml"><mi id="S5.I3.ix1.p3.2.m2.2.3.2" xref="S5.I3.ix1.p3.2.m2.2.3.2.cmml">𝑀𝑆𝐸</mi><mo lspace="0em" rspace="0em" id="S5.I3.ix1.p3.2.m2.2.3.1" xref="S5.I3.ix1.p3.2.m2.2.3.1.cmml">​</mo><mrow id="S5.I3.ix1.p3.2.m2.2.3.3.2" xref="S5.I3.ix1.p3.2.m2.2.3.3.1.cmml"><mo stretchy="false" id="S5.I3.ix1.p3.2.m2.2.3.3.2.1" xref="S5.I3.ix1.p3.2.m2.2.3.3.1.cmml">(</mo><mi id="S5.I3.ix1.p3.2.m2.1.1" xref="S5.I3.ix1.p3.2.m2.1.1.cmml">X</mi><mo id="S5.I3.ix1.p3.2.m2.2.3.3.2.2" xref="S5.I3.ix1.p3.2.m2.2.3.3.1.cmml">,</mo><mi id="S5.I3.ix1.p3.2.m2.2.2" xref="S5.I3.ix1.p3.2.m2.2.2.cmml">Y</mi><mo stretchy="false" id="S5.I3.ix1.p3.2.m2.2.3.3.2.3" xref="S5.I3.ix1.p3.2.m2.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.I3.ix1.p3.2.m2.2b"><apply id="S5.I3.ix1.p3.2.m2.2.3.cmml" xref="S5.I3.ix1.p3.2.m2.2.3"><times id="S5.I3.ix1.p3.2.m2.2.3.1.cmml" xref="S5.I3.ix1.p3.2.m2.2.3.1"></times><ci id="S5.I3.ix1.p3.2.m2.2.3.2.cmml" xref="S5.I3.ix1.p3.2.m2.2.3.2">𝑀𝑆𝐸</ci><interval closure="open" id="S5.I3.ix1.p3.2.m2.2.3.3.1.cmml" xref="S5.I3.ix1.p3.2.m2.2.3.3.2"><ci id="S5.I3.ix1.p3.2.m2.1.1.cmml" xref="S5.I3.ix1.p3.2.m2.1.1">𝑋</ci><ci id="S5.I3.ix1.p3.2.m2.2.2.cmml" xref="S5.I3.ix1.p3.2.m2.2.2">𝑌</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I3.ix1.p3.2.m2.2c">\mathit{MSE}(X,Y)</annotation></semantics></math> is the mean squared error between the ground truth image <math id="S5.I3.ix1.p3.3.m3.1" class="ltx_Math" alttext="X" display="inline"><semantics id="S5.I3.ix1.p3.3.m3.1a"><mi id="S5.I3.ix1.p3.3.m3.1.1" xref="S5.I3.ix1.p3.3.m3.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S5.I3.ix1.p3.3.m3.1b"><ci id="S5.I3.ix1.p3.3.m3.1.1.cmml" xref="S5.I3.ix1.p3.3.m3.1.1">𝑋</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.I3.ix1.p3.3.m3.1c">X</annotation></semantics></math> and the inpainted image <math id="S5.I3.ix1.p3.4.m4.1" class="ltx_Math" alttext="Y" display="inline"><semantics id="S5.I3.ix1.p3.4.m4.1a"><mi id="S5.I3.ix1.p3.4.m4.1.1" xref="S5.I3.ix1.p3.4.m4.1.1.cmml">Y</mi><annotation-xml encoding="MathML-Content" id="S5.I3.ix1.p3.4.m4.1b"><ci id="S5.I3.ix1.p3.4.m4.1.1.cmml" xref="S5.I3.ix1.p3.4.m4.1.1">𝑌</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.I3.ix1.p3.4.m4.1c">Y</annotation></semantics></math>. The PSNR is measured in decibel and a higher value indicates better quality of the reconstructed image.</p>
</div>
</dd>
</dl>
</div>
<div id="S5.SS2.p3" class="ltx_para">
<dl id="S5.I4" class="ltx_description">
<dt id="S5.I4.ix1" class="ltx_item"><span class="ltx_tag ltx_tag_item"><span id="S5.I4.ix1.1.1.1" class="ltx_text ltx_font_bold">Mean Structural Similarity Index (MSSIM)</span></span></dt>
<dd class="ltx_item">
<div id="S5.I4.ix1.p1" class="ltx_para">
<p id="S5.I4.ix1.p1.1" class="ltx_p">as given in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>, is defined as follows:</p>
</div>
<div id="S5.I4.ix1.p2" class="ltx_para">
<table id="S5.Ex3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S5.Ex3.m1.1" class="ltx_math_unparsed" alttext="\mathit{MSSIM}(X.Y)=\frac{1}{M}\sum_{i=1}^{M}\mathit{SSIM}(x_{i},y_{i})" display="block"><semantics id="S5.Ex3.m1.1a"><mrow id="S5.Ex3.m1.1b"><mi id="S5.Ex3.m1.1.1">𝑀𝑆𝑆𝐼𝑀</mi><mrow id="S5.Ex3.m1.1.2"><mo stretchy="false" id="S5.Ex3.m1.1.2.1">(</mo><mi id="S5.Ex3.m1.1.2.2">X</mi><mo lspace="0em" rspace="0.167em" id="S5.Ex3.m1.1.2.3">.</mo><mi id="S5.Ex3.m1.1.2.4">Y</mi><mo stretchy="false" id="S5.Ex3.m1.1.2.5">)</mo></mrow><mo id="S5.Ex3.m1.1.3">=</mo><mfrac id="S5.Ex3.m1.1.4"><mn id="S5.Ex3.m1.1.4.2">1</mn><mi id="S5.Ex3.m1.1.4.3">M</mi></mfrac><munderover id="S5.Ex3.m1.1.5"><mo movablelimits="false" id="S5.Ex3.m1.1.5.2.2">∑</mo><mrow id="S5.Ex3.m1.1.5.2.3"><mi id="S5.Ex3.m1.1.5.2.3.2">i</mi><mo id="S5.Ex3.m1.1.5.2.3.1">=</mo><mn id="S5.Ex3.m1.1.5.2.3.3">1</mn></mrow><mi id="S5.Ex3.m1.1.5.3">M</mi></munderover><mi id="S5.Ex3.m1.1.6">𝑆𝑆𝐼𝑀</mi><mrow id="S5.Ex3.m1.1.7"><mo stretchy="false" id="S5.Ex3.m1.1.7.1">(</mo><msub id="S5.Ex3.m1.1.7.2"><mi id="S5.Ex3.m1.1.7.2.2">x</mi><mi id="S5.Ex3.m1.1.7.2.3">i</mi></msub><mo id="S5.Ex3.m1.1.7.3">,</mo><msub id="S5.Ex3.m1.1.7.4"><mi id="S5.Ex3.m1.1.7.4.2">y</mi><mi id="S5.Ex3.m1.1.7.4.3">i</mi></msub><mo stretchy="false" id="S5.Ex3.m1.1.7.5">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S5.Ex3.m1.1c">\mathit{MSSIM}(X.Y)=\frac{1}{M}\sum_{i=1}^{M}\mathit{SSIM}(x_{i},y_{i})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S5.I4.ix1.p3" class="ltx_para">
<p id="S5.I4.ix1.p3.5" class="ltx_p">where X and Y are the ground truth image and inpainted image, respectively, <math id="S5.I4.ix1.p3.1.m1.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S5.I4.ix1.p3.1.m1.1a"><mi id="S5.I4.ix1.p3.1.m1.1.1" xref="S5.I4.ix1.p3.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S5.I4.ix1.p3.1.m1.1b"><ci id="S5.I4.ix1.p3.1.m1.1.1.cmml" xref="S5.I4.ix1.p3.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.I4.ix1.p3.1.m1.1c">M</annotation></semantics></math> is the number of local windows in an image and <math id="S5.I4.ix1.p3.2.m2.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="S5.I4.ix1.p3.2.m2.1a"><msub id="S5.I4.ix1.p3.2.m2.1.1" xref="S5.I4.ix1.p3.2.m2.1.1.cmml"><mi id="S5.I4.ix1.p3.2.m2.1.1.2" xref="S5.I4.ix1.p3.2.m2.1.1.2.cmml">x</mi><mi id="S5.I4.ix1.p3.2.m2.1.1.3" xref="S5.I4.ix1.p3.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.I4.ix1.p3.2.m2.1b"><apply id="S5.I4.ix1.p3.2.m2.1.1.cmml" xref="S5.I4.ix1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S5.I4.ix1.p3.2.m2.1.1.1.cmml" xref="S5.I4.ix1.p3.2.m2.1.1">subscript</csymbol><ci id="S5.I4.ix1.p3.2.m2.1.1.2.cmml" xref="S5.I4.ix1.p3.2.m2.1.1.2">𝑥</ci><ci id="S5.I4.ix1.p3.2.m2.1.1.3.cmml" xref="S5.I4.ix1.p3.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I4.ix1.p3.2.m2.1c">x_{i}</annotation></semantics></math> and <math id="S5.I4.ix1.p3.3.m3.1" class="ltx_Math" alttext="y_{i}" display="inline"><semantics id="S5.I4.ix1.p3.3.m3.1a"><msub id="S5.I4.ix1.p3.3.m3.1.1" xref="S5.I4.ix1.p3.3.m3.1.1.cmml"><mi id="S5.I4.ix1.p3.3.m3.1.1.2" xref="S5.I4.ix1.p3.3.m3.1.1.2.cmml">y</mi><mi id="S5.I4.ix1.p3.3.m3.1.1.3" xref="S5.I4.ix1.p3.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.I4.ix1.p3.3.m3.1b"><apply id="S5.I4.ix1.p3.3.m3.1.1.cmml" xref="S5.I4.ix1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S5.I4.ix1.p3.3.m3.1.1.1.cmml" xref="S5.I4.ix1.p3.3.m3.1.1">subscript</csymbol><ci id="S5.I4.ix1.p3.3.m3.1.1.2.cmml" xref="S5.I4.ix1.p3.3.m3.1.1.2">𝑦</ci><ci id="S5.I4.ix1.p3.3.m3.1.1.3.cmml" xref="S5.I4.ix1.p3.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I4.ix1.p3.3.m3.1c">y_{i}</annotation></semantics></math> are the image content of the <math id="S5.I4.ix1.p3.4.m4.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S5.I4.ix1.p3.4.m4.1a"><mi id="S5.I4.ix1.p3.4.m4.1.1" xref="S5.I4.ix1.p3.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S5.I4.ix1.p3.4.m4.1b"><ci id="S5.I4.ix1.p3.4.m4.1.1.cmml" xref="S5.I4.ix1.p3.4.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.I4.ix1.p3.4.m4.1c">i</annotation></semantics></math>’th local window. The SSIM over local window patches <math id="S5.I4.ix1.p3.5.m5.2" class="ltx_Math" alttext="(x,y)" display="inline"><semantics id="S5.I4.ix1.p3.5.m5.2a"><mrow id="S5.I4.ix1.p3.5.m5.2.3.2" xref="S5.I4.ix1.p3.5.m5.2.3.1.cmml"><mo stretchy="false" id="S5.I4.ix1.p3.5.m5.2.3.2.1" xref="S5.I4.ix1.p3.5.m5.2.3.1.cmml">(</mo><mi id="S5.I4.ix1.p3.5.m5.1.1" xref="S5.I4.ix1.p3.5.m5.1.1.cmml">x</mi><mo id="S5.I4.ix1.p3.5.m5.2.3.2.2" xref="S5.I4.ix1.p3.5.m5.2.3.1.cmml">,</mo><mi id="S5.I4.ix1.p3.5.m5.2.2" xref="S5.I4.ix1.p3.5.m5.2.2.cmml">y</mi><mo stretchy="false" id="S5.I4.ix1.p3.5.m5.2.3.2.3" xref="S5.I4.ix1.p3.5.m5.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.I4.ix1.p3.5.m5.2b"><interval closure="open" id="S5.I4.ix1.p3.5.m5.2.3.1.cmml" xref="S5.I4.ix1.p3.5.m5.2.3.2"><ci id="S5.I4.ix1.p3.5.m5.1.1.cmml" xref="S5.I4.ix1.p3.5.m5.1.1">𝑥</ci><ci id="S5.I4.ix1.p3.5.m5.2.2.cmml" xref="S5.I4.ix1.p3.5.m5.2.2">𝑦</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.I4.ix1.p3.5.m5.2c">(x,y)</annotation></semantics></math> is defined as:</p>
</div>
<div id="S5.I4.ix1.p4" class="ltx_para">
<table id="S5.Ex4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S5.Ex4.m1.6" class="ltx_Math" alttext="\mathit{SSIM}(x,y)=\frac{(2\mu_{x}\mu_{y}+C_{1})(2\sigma_{xy}+C_{2})}{(\mu_{x}^{2}+\mu_{y}^{2}+C_{1})+(\sigma_{x}^{2}+\sigma_{y}^{2}+C_{2})}" display="block"><semantics id="S5.Ex4.m1.6a"><mrow id="S5.Ex4.m1.6.7" xref="S5.Ex4.m1.6.7.cmml"><mrow id="S5.Ex4.m1.6.7.2" xref="S5.Ex4.m1.6.7.2.cmml"><mi id="S5.Ex4.m1.6.7.2.2" xref="S5.Ex4.m1.6.7.2.2.cmml">𝑆𝑆𝐼𝑀</mi><mo lspace="0em" rspace="0em" id="S5.Ex4.m1.6.7.2.1" xref="S5.Ex4.m1.6.7.2.1.cmml">​</mo><mrow id="S5.Ex4.m1.6.7.2.3.2" xref="S5.Ex4.m1.6.7.2.3.1.cmml"><mo stretchy="false" id="S5.Ex4.m1.6.7.2.3.2.1" xref="S5.Ex4.m1.6.7.2.3.1.cmml">(</mo><mi id="S5.Ex4.m1.5.5" xref="S5.Ex4.m1.5.5.cmml">x</mi><mo id="S5.Ex4.m1.6.7.2.3.2.2" xref="S5.Ex4.m1.6.7.2.3.1.cmml">,</mo><mi id="S5.Ex4.m1.6.6" xref="S5.Ex4.m1.6.6.cmml">y</mi><mo stretchy="false" id="S5.Ex4.m1.6.7.2.3.2.3" xref="S5.Ex4.m1.6.7.2.3.1.cmml">)</mo></mrow></mrow><mo id="S5.Ex4.m1.6.7.1" xref="S5.Ex4.m1.6.7.1.cmml">=</mo><mfrac id="S5.Ex4.m1.4.4" xref="S5.Ex4.m1.4.4.cmml"><mrow id="S5.Ex4.m1.2.2.2" xref="S5.Ex4.m1.2.2.2.cmml"><mrow id="S5.Ex4.m1.1.1.1.1.1" xref="S5.Ex4.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.Ex4.m1.1.1.1.1.1.2" xref="S5.Ex4.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.Ex4.m1.1.1.1.1.1.1" xref="S5.Ex4.m1.1.1.1.1.1.1.cmml"><mrow id="S5.Ex4.m1.1.1.1.1.1.1.2" xref="S5.Ex4.m1.1.1.1.1.1.1.2.cmml"><mn id="S5.Ex4.m1.1.1.1.1.1.1.2.2" xref="S5.Ex4.m1.1.1.1.1.1.1.2.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S5.Ex4.m1.1.1.1.1.1.1.2.1" xref="S5.Ex4.m1.1.1.1.1.1.1.2.1.cmml">​</mo><msub id="S5.Ex4.m1.1.1.1.1.1.1.2.3" xref="S5.Ex4.m1.1.1.1.1.1.1.2.3.cmml"><mi id="S5.Ex4.m1.1.1.1.1.1.1.2.3.2" xref="S5.Ex4.m1.1.1.1.1.1.1.2.3.2.cmml">μ</mi><mi id="S5.Ex4.m1.1.1.1.1.1.1.2.3.3" xref="S5.Ex4.m1.1.1.1.1.1.1.2.3.3.cmml">x</mi></msub><mo lspace="0em" rspace="0em" id="S5.Ex4.m1.1.1.1.1.1.1.2.1a" xref="S5.Ex4.m1.1.1.1.1.1.1.2.1.cmml">​</mo><msub id="S5.Ex4.m1.1.1.1.1.1.1.2.4" xref="S5.Ex4.m1.1.1.1.1.1.1.2.4.cmml"><mi id="S5.Ex4.m1.1.1.1.1.1.1.2.4.2" xref="S5.Ex4.m1.1.1.1.1.1.1.2.4.2.cmml">μ</mi><mi id="S5.Ex4.m1.1.1.1.1.1.1.2.4.3" xref="S5.Ex4.m1.1.1.1.1.1.1.2.4.3.cmml">y</mi></msub></mrow><mo id="S5.Ex4.m1.1.1.1.1.1.1.1" xref="S5.Ex4.m1.1.1.1.1.1.1.1.cmml">+</mo><msub id="S5.Ex4.m1.1.1.1.1.1.1.3" xref="S5.Ex4.m1.1.1.1.1.1.1.3.cmml"><mi id="S5.Ex4.m1.1.1.1.1.1.1.3.2" xref="S5.Ex4.m1.1.1.1.1.1.1.3.2.cmml">C</mi><mn id="S5.Ex4.m1.1.1.1.1.1.1.3.3" xref="S5.Ex4.m1.1.1.1.1.1.1.3.3.cmml">1</mn></msub></mrow><mo stretchy="false" id="S5.Ex4.m1.1.1.1.1.1.3" xref="S5.Ex4.m1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S5.Ex4.m1.2.2.2.3" xref="S5.Ex4.m1.2.2.2.3.cmml">​</mo><mrow id="S5.Ex4.m1.2.2.2.2.1" xref="S5.Ex4.m1.2.2.2.2.1.1.cmml"><mo stretchy="false" id="S5.Ex4.m1.2.2.2.2.1.2" xref="S5.Ex4.m1.2.2.2.2.1.1.cmml">(</mo><mrow id="S5.Ex4.m1.2.2.2.2.1.1" xref="S5.Ex4.m1.2.2.2.2.1.1.cmml"><mrow id="S5.Ex4.m1.2.2.2.2.1.1.2" xref="S5.Ex4.m1.2.2.2.2.1.1.2.cmml"><mn id="S5.Ex4.m1.2.2.2.2.1.1.2.2" xref="S5.Ex4.m1.2.2.2.2.1.1.2.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S5.Ex4.m1.2.2.2.2.1.1.2.1" xref="S5.Ex4.m1.2.2.2.2.1.1.2.1.cmml">​</mo><msub id="S5.Ex4.m1.2.2.2.2.1.1.2.3" xref="S5.Ex4.m1.2.2.2.2.1.1.2.3.cmml"><mi id="S5.Ex4.m1.2.2.2.2.1.1.2.3.2" xref="S5.Ex4.m1.2.2.2.2.1.1.2.3.2.cmml">σ</mi><mrow id="S5.Ex4.m1.2.2.2.2.1.1.2.3.3" xref="S5.Ex4.m1.2.2.2.2.1.1.2.3.3.cmml"><mi id="S5.Ex4.m1.2.2.2.2.1.1.2.3.3.2" xref="S5.Ex4.m1.2.2.2.2.1.1.2.3.3.2.cmml">x</mi><mo lspace="0em" rspace="0em" id="S5.Ex4.m1.2.2.2.2.1.1.2.3.3.1" xref="S5.Ex4.m1.2.2.2.2.1.1.2.3.3.1.cmml">​</mo><mi id="S5.Ex4.m1.2.2.2.2.1.1.2.3.3.3" xref="S5.Ex4.m1.2.2.2.2.1.1.2.3.3.3.cmml">y</mi></mrow></msub></mrow><mo id="S5.Ex4.m1.2.2.2.2.1.1.1" xref="S5.Ex4.m1.2.2.2.2.1.1.1.cmml">+</mo><msub id="S5.Ex4.m1.2.2.2.2.1.1.3" xref="S5.Ex4.m1.2.2.2.2.1.1.3.cmml"><mi id="S5.Ex4.m1.2.2.2.2.1.1.3.2" xref="S5.Ex4.m1.2.2.2.2.1.1.3.2.cmml">C</mi><mn id="S5.Ex4.m1.2.2.2.2.1.1.3.3" xref="S5.Ex4.m1.2.2.2.2.1.1.3.3.cmml">2</mn></msub></mrow><mo stretchy="false" id="S5.Ex4.m1.2.2.2.2.1.3" xref="S5.Ex4.m1.2.2.2.2.1.1.cmml">)</mo></mrow></mrow><mrow id="S5.Ex4.m1.4.4.4" xref="S5.Ex4.m1.4.4.4.cmml"><mrow id="S5.Ex4.m1.3.3.3.1.1" xref="S5.Ex4.m1.3.3.3.1.1.1.cmml"><mo stretchy="false" id="S5.Ex4.m1.3.3.3.1.1.2" xref="S5.Ex4.m1.3.3.3.1.1.1.cmml">(</mo><mrow id="S5.Ex4.m1.3.3.3.1.1.1" xref="S5.Ex4.m1.3.3.3.1.1.1.cmml"><msubsup id="S5.Ex4.m1.3.3.3.1.1.1.2" xref="S5.Ex4.m1.3.3.3.1.1.1.2.cmml"><mi id="S5.Ex4.m1.3.3.3.1.1.1.2.2.2" xref="S5.Ex4.m1.3.3.3.1.1.1.2.2.2.cmml">μ</mi><mi id="S5.Ex4.m1.3.3.3.1.1.1.2.2.3" xref="S5.Ex4.m1.3.3.3.1.1.1.2.2.3.cmml">x</mi><mn id="S5.Ex4.m1.3.3.3.1.1.1.2.3" xref="S5.Ex4.m1.3.3.3.1.1.1.2.3.cmml">2</mn></msubsup><mo id="S5.Ex4.m1.3.3.3.1.1.1.1" xref="S5.Ex4.m1.3.3.3.1.1.1.1.cmml">+</mo><msubsup id="S5.Ex4.m1.3.3.3.1.1.1.3" xref="S5.Ex4.m1.3.3.3.1.1.1.3.cmml"><mi id="S5.Ex4.m1.3.3.3.1.1.1.3.2.2" xref="S5.Ex4.m1.3.3.3.1.1.1.3.2.2.cmml">μ</mi><mi id="S5.Ex4.m1.3.3.3.1.1.1.3.2.3" xref="S5.Ex4.m1.3.3.3.1.1.1.3.2.3.cmml">y</mi><mn id="S5.Ex4.m1.3.3.3.1.1.1.3.3" xref="S5.Ex4.m1.3.3.3.1.1.1.3.3.cmml">2</mn></msubsup><mo id="S5.Ex4.m1.3.3.3.1.1.1.1a" xref="S5.Ex4.m1.3.3.3.1.1.1.1.cmml">+</mo><msub id="S5.Ex4.m1.3.3.3.1.1.1.4" xref="S5.Ex4.m1.3.3.3.1.1.1.4.cmml"><mi id="S5.Ex4.m1.3.3.3.1.1.1.4.2" xref="S5.Ex4.m1.3.3.3.1.1.1.4.2.cmml">C</mi><mn id="S5.Ex4.m1.3.3.3.1.1.1.4.3" xref="S5.Ex4.m1.3.3.3.1.1.1.4.3.cmml">1</mn></msub></mrow><mo stretchy="false" id="S5.Ex4.m1.3.3.3.1.1.3" xref="S5.Ex4.m1.3.3.3.1.1.1.cmml">)</mo></mrow><mo id="S5.Ex4.m1.4.4.4.3" xref="S5.Ex4.m1.4.4.4.3.cmml">+</mo><mrow id="S5.Ex4.m1.4.4.4.2.1" xref="S5.Ex4.m1.4.4.4.2.1.1.cmml"><mo stretchy="false" id="S5.Ex4.m1.4.4.4.2.1.2" xref="S5.Ex4.m1.4.4.4.2.1.1.cmml">(</mo><mrow id="S5.Ex4.m1.4.4.4.2.1.1" xref="S5.Ex4.m1.4.4.4.2.1.1.cmml"><msubsup id="S5.Ex4.m1.4.4.4.2.1.1.2" xref="S5.Ex4.m1.4.4.4.2.1.1.2.cmml"><mi id="S5.Ex4.m1.4.4.4.2.1.1.2.2.2" xref="S5.Ex4.m1.4.4.4.2.1.1.2.2.2.cmml">σ</mi><mi id="S5.Ex4.m1.4.4.4.2.1.1.2.2.3" xref="S5.Ex4.m1.4.4.4.2.1.1.2.2.3.cmml">x</mi><mn id="S5.Ex4.m1.4.4.4.2.1.1.2.3" xref="S5.Ex4.m1.4.4.4.2.1.1.2.3.cmml">2</mn></msubsup><mo id="S5.Ex4.m1.4.4.4.2.1.1.1" xref="S5.Ex4.m1.4.4.4.2.1.1.1.cmml">+</mo><msubsup id="S5.Ex4.m1.4.4.4.2.1.1.3" xref="S5.Ex4.m1.4.4.4.2.1.1.3.cmml"><mi id="S5.Ex4.m1.4.4.4.2.1.1.3.2.2" xref="S5.Ex4.m1.4.4.4.2.1.1.3.2.2.cmml">σ</mi><mi id="S5.Ex4.m1.4.4.4.2.1.1.3.2.3" xref="S5.Ex4.m1.4.4.4.2.1.1.3.2.3.cmml">y</mi><mn id="S5.Ex4.m1.4.4.4.2.1.1.3.3" xref="S5.Ex4.m1.4.4.4.2.1.1.3.3.cmml">2</mn></msubsup><mo id="S5.Ex4.m1.4.4.4.2.1.1.1a" xref="S5.Ex4.m1.4.4.4.2.1.1.1.cmml">+</mo><msub id="S5.Ex4.m1.4.4.4.2.1.1.4" xref="S5.Ex4.m1.4.4.4.2.1.1.4.cmml"><mi id="S5.Ex4.m1.4.4.4.2.1.1.4.2" xref="S5.Ex4.m1.4.4.4.2.1.1.4.2.cmml">C</mi><mn id="S5.Ex4.m1.4.4.4.2.1.1.4.3" xref="S5.Ex4.m1.4.4.4.2.1.1.4.3.cmml">2</mn></msub></mrow><mo stretchy="false" id="S5.Ex4.m1.4.4.4.2.1.3" xref="S5.Ex4.m1.4.4.4.2.1.1.cmml">)</mo></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S5.Ex4.m1.6b"><apply id="S5.Ex4.m1.6.7.cmml" xref="S5.Ex4.m1.6.7"><eq id="S5.Ex4.m1.6.7.1.cmml" xref="S5.Ex4.m1.6.7.1"></eq><apply id="S5.Ex4.m1.6.7.2.cmml" xref="S5.Ex4.m1.6.7.2"><times id="S5.Ex4.m1.6.7.2.1.cmml" xref="S5.Ex4.m1.6.7.2.1"></times><ci id="S5.Ex4.m1.6.7.2.2.cmml" xref="S5.Ex4.m1.6.7.2.2">𝑆𝑆𝐼𝑀</ci><interval closure="open" id="S5.Ex4.m1.6.7.2.3.1.cmml" xref="S5.Ex4.m1.6.7.2.3.2"><ci id="S5.Ex4.m1.5.5.cmml" xref="S5.Ex4.m1.5.5">𝑥</ci><ci id="S5.Ex4.m1.6.6.cmml" xref="S5.Ex4.m1.6.6">𝑦</ci></interval></apply><apply id="S5.Ex4.m1.4.4.cmml" xref="S5.Ex4.m1.4.4"><divide id="S5.Ex4.m1.4.4.5.cmml" xref="S5.Ex4.m1.4.4"></divide><apply id="S5.Ex4.m1.2.2.2.cmml" xref="S5.Ex4.m1.2.2.2"><times id="S5.Ex4.m1.2.2.2.3.cmml" xref="S5.Ex4.m1.2.2.2.3"></times><apply id="S5.Ex4.m1.1.1.1.1.1.1.cmml" xref="S5.Ex4.m1.1.1.1.1.1"><plus id="S5.Ex4.m1.1.1.1.1.1.1.1.cmml" xref="S5.Ex4.m1.1.1.1.1.1.1.1"></plus><apply id="S5.Ex4.m1.1.1.1.1.1.1.2.cmml" xref="S5.Ex4.m1.1.1.1.1.1.1.2"><times id="S5.Ex4.m1.1.1.1.1.1.1.2.1.cmml" xref="S5.Ex4.m1.1.1.1.1.1.1.2.1"></times><cn type="integer" id="S5.Ex4.m1.1.1.1.1.1.1.2.2.cmml" xref="S5.Ex4.m1.1.1.1.1.1.1.2.2">2</cn><apply id="S5.Ex4.m1.1.1.1.1.1.1.2.3.cmml" xref="S5.Ex4.m1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S5.Ex4.m1.1.1.1.1.1.1.2.3.1.cmml" xref="S5.Ex4.m1.1.1.1.1.1.1.2.3">subscript</csymbol><ci id="S5.Ex4.m1.1.1.1.1.1.1.2.3.2.cmml" xref="S5.Ex4.m1.1.1.1.1.1.1.2.3.2">𝜇</ci><ci id="S5.Ex4.m1.1.1.1.1.1.1.2.3.3.cmml" xref="S5.Ex4.m1.1.1.1.1.1.1.2.3.3">𝑥</ci></apply><apply id="S5.Ex4.m1.1.1.1.1.1.1.2.4.cmml" xref="S5.Ex4.m1.1.1.1.1.1.1.2.4"><csymbol cd="ambiguous" id="S5.Ex4.m1.1.1.1.1.1.1.2.4.1.cmml" xref="S5.Ex4.m1.1.1.1.1.1.1.2.4">subscript</csymbol><ci id="S5.Ex4.m1.1.1.1.1.1.1.2.4.2.cmml" xref="S5.Ex4.m1.1.1.1.1.1.1.2.4.2">𝜇</ci><ci id="S5.Ex4.m1.1.1.1.1.1.1.2.4.3.cmml" xref="S5.Ex4.m1.1.1.1.1.1.1.2.4.3">𝑦</ci></apply></apply><apply id="S5.Ex4.m1.1.1.1.1.1.1.3.cmml" xref="S5.Ex4.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.Ex4.m1.1.1.1.1.1.1.3.1.cmml" xref="S5.Ex4.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S5.Ex4.m1.1.1.1.1.1.1.3.2.cmml" xref="S5.Ex4.m1.1.1.1.1.1.1.3.2">𝐶</ci><cn type="integer" id="S5.Ex4.m1.1.1.1.1.1.1.3.3.cmml" xref="S5.Ex4.m1.1.1.1.1.1.1.3.3">1</cn></apply></apply><apply id="S5.Ex4.m1.2.2.2.2.1.1.cmml" xref="S5.Ex4.m1.2.2.2.2.1"><plus id="S5.Ex4.m1.2.2.2.2.1.1.1.cmml" xref="S5.Ex4.m1.2.2.2.2.1.1.1"></plus><apply id="S5.Ex4.m1.2.2.2.2.1.1.2.cmml" xref="S5.Ex4.m1.2.2.2.2.1.1.2"><times id="S5.Ex4.m1.2.2.2.2.1.1.2.1.cmml" xref="S5.Ex4.m1.2.2.2.2.1.1.2.1"></times><cn type="integer" id="S5.Ex4.m1.2.2.2.2.1.1.2.2.cmml" xref="S5.Ex4.m1.2.2.2.2.1.1.2.2">2</cn><apply id="S5.Ex4.m1.2.2.2.2.1.1.2.3.cmml" xref="S5.Ex4.m1.2.2.2.2.1.1.2.3"><csymbol cd="ambiguous" id="S5.Ex4.m1.2.2.2.2.1.1.2.3.1.cmml" xref="S5.Ex4.m1.2.2.2.2.1.1.2.3">subscript</csymbol><ci id="S5.Ex4.m1.2.2.2.2.1.1.2.3.2.cmml" xref="S5.Ex4.m1.2.2.2.2.1.1.2.3.2">𝜎</ci><apply id="S5.Ex4.m1.2.2.2.2.1.1.2.3.3.cmml" xref="S5.Ex4.m1.2.2.2.2.1.1.2.3.3"><times id="S5.Ex4.m1.2.2.2.2.1.1.2.3.3.1.cmml" xref="S5.Ex4.m1.2.2.2.2.1.1.2.3.3.1"></times><ci id="S5.Ex4.m1.2.2.2.2.1.1.2.3.3.2.cmml" xref="S5.Ex4.m1.2.2.2.2.1.1.2.3.3.2">𝑥</ci><ci id="S5.Ex4.m1.2.2.2.2.1.1.2.3.3.3.cmml" xref="S5.Ex4.m1.2.2.2.2.1.1.2.3.3.3">𝑦</ci></apply></apply></apply><apply id="S5.Ex4.m1.2.2.2.2.1.1.3.cmml" xref="S5.Ex4.m1.2.2.2.2.1.1.3"><csymbol cd="ambiguous" id="S5.Ex4.m1.2.2.2.2.1.1.3.1.cmml" xref="S5.Ex4.m1.2.2.2.2.1.1.3">subscript</csymbol><ci id="S5.Ex4.m1.2.2.2.2.1.1.3.2.cmml" xref="S5.Ex4.m1.2.2.2.2.1.1.3.2">𝐶</ci><cn type="integer" id="S5.Ex4.m1.2.2.2.2.1.1.3.3.cmml" xref="S5.Ex4.m1.2.2.2.2.1.1.3.3">2</cn></apply></apply></apply><apply id="S5.Ex4.m1.4.4.4.cmml" xref="S5.Ex4.m1.4.4.4"><plus id="S5.Ex4.m1.4.4.4.3.cmml" xref="S5.Ex4.m1.4.4.4.3"></plus><apply id="S5.Ex4.m1.3.3.3.1.1.1.cmml" xref="S5.Ex4.m1.3.3.3.1.1"><plus id="S5.Ex4.m1.3.3.3.1.1.1.1.cmml" xref="S5.Ex4.m1.3.3.3.1.1.1.1"></plus><apply id="S5.Ex4.m1.3.3.3.1.1.1.2.cmml" xref="S5.Ex4.m1.3.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S5.Ex4.m1.3.3.3.1.1.1.2.1.cmml" xref="S5.Ex4.m1.3.3.3.1.1.1.2">superscript</csymbol><apply id="S5.Ex4.m1.3.3.3.1.1.1.2.2.cmml" xref="S5.Ex4.m1.3.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S5.Ex4.m1.3.3.3.1.1.1.2.2.1.cmml" xref="S5.Ex4.m1.3.3.3.1.1.1.2">subscript</csymbol><ci id="S5.Ex4.m1.3.3.3.1.1.1.2.2.2.cmml" xref="S5.Ex4.m1.3.3.3.1.1.1.2.2.2">𝜇</ci><ci id="S5.Ex4.m1.3.3.3.1.1.1.2.2.3.cmml" xref="S5.Ex4.m1.3.3.3.1.1.1.2.2.3">𝑥</ci></apply><cn type="integer" id="S5.Ex4.m1.3.3.3.1.1.1.2.3.cmml" xref="S5.Ex4.m1.3.3.3.1.1.1.2.3">2</cn></apply><apply id="S5.Ex4.m1.3.3.3.1.1.1.3.cmml" xref="S5.Ex4.m1.3.3.3.1.1.1.3"><csymbol cd="ambiguous" id="S5.Ex4.m1.3.3.3.1.1.1.3.1.cmml" xref="S5.Ex4.m1.3.3.3.1.1.1.3">superscript</csymbol><apply id="S5.Ex4.m1.3.3.3.1.1.1.3.2.cmml" xref="S5.Ex4.m1.3.3.3.1.1.1.3"><csymbol cd="ambiguous" id="S5.Ex4.m1.3.3.3.1.1.1.3.2.1.cmml" xref="S5.Ex4.m1.3.3.3.1.1.1.3">subscript</csymbol><ci id="S5.Ex4.m1.3.3.3.1.1.1.3.2.2.cmml" xref="S5.Ex4.m1.3.3.3.1.1.1.3.2.2">𝜇</ci><ci id="S5.Ex4.m1.3.3.3.1.1.1.3.2.3.cmml" xref="S5.Ex4.m1.3.3.3.1.1.1.3.2.3">𝑦</ci></apply><cn type="integer" id="S5.Ex4.m1.3.3.3.1.1.1.3.3.cmml" xref="S5.Ex4.m1.3.3.3.1.1.1.3.3">2</cn></apply><apply id="S5.Ex4.m1.3.3.3.1.1.1.4.cmml" xref="S5.Ex4.m1.3.3.3.1.1.1.4"><csymbol cd="ambiguous" id="S5.Ex4.m1.3.3.3.1.1.1.4.1.cmml" xref="S5.Ex4.m1.3.3.3.1.1.1.4">subscript</csymbol><ci id="S5.Ex4.m1.3.3.3.1.1.1.4.2.cmml" xref="S5.Ex4.m1.3.3.3.1.1.1.4.2">𝐶</ci><cn type="integer" id="S5.Ex4.m1.3.3.3.1.1.1.4.3.cmml" xref="S5.Ex4.m1.3.3.3.1.1.1.4.3">1</cn></apply></apply><apply id="S5.Ex4.m1.4.4.4.2.1.1.cmml" xref="S5.Ex4.m1.4.4.4.2.1"><plus id="S5.Ex4.m1.4.4.4.2.1.1.1.cmml" xref="S5.Ex4.m1.4.4.4.2.1.1.1"></plus><apply id="S5.Ex4.m1.4.4.4.2.1.1.2.cmml" xref="S5.Ex4.m1.4.4.4.2.1.1.2"><csymbol cd="ambiguous" id="S5.Ex4.m1.4.4.4.2.1.1.2.1.cmml" xref="S5.Ex4.m1.4.4.4.2.1.1.2">superscript</csymbol><apply id="S5.Ex4.m1.4.4.4.2.1.1.2.2.cmml" xref="S5.Ex4.m1.4.4.4.2.1.1.2"><csymbol cd="ambiguous" id="S5.Ex4.m1.4.4.4.2.1.1.2.2.1.cmml" xref="S5.Ex4.m1.4.4.4.2.1.1.2">subscript</csymbol><ci id="S5.Ex4.m1.4.4.4.2.1.1.2.2.2.cmml" xref="S5.Ex4.m1.4.4.4.2.1.1.2.2.2">𝜎</ci><ci id="S5.Ex4.m1.4.4.4.2.1.1.2.2.3.cmml" xref="S5.Ex4.m1.4.4.4.2.1.1.2.2.3">𝑥</ci></apply><cn type="integer" id="S5.Ex4.m1.4.4.4.2.1.1.2.3.cmml" xref="S5.Ex4.m1.4.4.4.2.1.1.2.3">2</cn></apply><apply id="S5.Ex4.m1.4.4.4.2.1.1.3.cmml" xref="S5.Ex4.m1.4.4.4.2.1.1.3"><csymbol cd="ambiguous" id="S5.Ex4.m1.4.4.4.2.1.1.3.1.cmml" xref="S5.Ex4.m1.4.4.4.2.1.1.3">superscript</csymbol><apply id="S5.Ex4.m1.4.4.4.2.1.1.3.2.cmml" xref="S5.Ex4.m1.4.4.4.2.1.1.3"><csymbol cd="ambiguous" id="S5.Ex4.m1.4.4.4.2.1.1.3.2.1.cmml" xref="S5.Ex4.m1.4.4.4.2.1.1.3">subscript</csymbol><ci id="S5.Ex4.m1.4.4.4.2.1.1.3.2.2.cmml" xref="S5.Ex4.m1.4.4.4.2.1.1.3.2.2">𝜎</ci><ci id="S5.Ex4.m1.4.4.4.2.1.1.3.2.3.cmml" xref="S5.Ex4.m1.4.4.4.2.1.1.3.2.3">𝑦</ci></apply><cn type="integer" id="S5.Ex4.m1.4.4.4.2.1.1.3.3.cmml" xref="S5.Ex4.m1.4.4.4.2.1.1.3.3">2</cn></apply><apply id="S5.Ex4.m1.4.4.4.2.1.1.4.cmml" xref="S5.Ex4.m1.4.4.4.2.1.1.4"><csymbol cd="ambiguous" id="S5.Ex4.m1.4.4.4.2.1.1.4.1.cmml" xref="S5.Ex4.m1.4.4.4.2.1.1.4">subscript</csymbol><ci id="S5.Ex4.m1.4.4.4.2.1.1.4.2.cmml" xref="S5.Ex4.m1.4.4.4.2.1.1.4.2">𝐶</ci><cn type="integer" id="S5.Ex4.m1.4.4.4.2.1.1.4.3.cmml" xref="S5.Ex4.m1.4.4.4.2.1.1.4.3">2</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.Ex4.m1.6c">\mathit{SSIM}(x,y)=\frac{(2\mu_{x}\mu_{y}+C_{1})(2\sigma_{xy}+C_{2})}{(\mu_{x}^{2}+\mu_{y}^{2}+C_{1})+(\sigma_{x}^{2}+\sigma_{y}^{2}+C_{2})}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S5.I4.ix1.p5" class="ltx_para">
<p id="S5.I4.ix1.p5.11" class="ltx_p">where <math id="S5.I4.ix1.p5.1.m1.1" class="ltx_Math" alttext="\mu_{x}" display="inline"><semantics id="S5.I4.ix1.p5.1.m1.1a"><msub id="S5.I4.ix1.p5.1.m1.1.1" xref="S5.I4.ix1.p5.1.m1.1.1.cmml"><mi id="S5.I4.ix1.p5.1.m1.1.1.2" xref="S5.I4.ix1.p5.1.m1.1.1.2.cmml">μ</mi><mi id="S5.I4.ix1.p5.1.m1.1.1.3" xref="S5.I4.ix1.p5.1.m1.1.1.3.cmml">x</mi></msub><annotation-xml encoding="MathML-Content" id="S5.I4.ix1.p5.1.m1.1b"><apply id="S5.I4.ix1.p5.1.m1.1.1.cmml" xref="S5.I4.ix1.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S5.I4.ix1.p5.1.m1.1.1.1.cmml" xref="S5.I4.ix1.p5.1.m1.1.1">subscript</csymbol><ci id="S5.I4.ix1.p5.1.m1.1.1.2.cmml" xref="S5.I4.ix1.p5.1.m1.1.1.2">𝜇</ci><ci id="S5.I4.ix1.p5.1.m1.1.1.3.cmml" xref="S5.I4.ix1.p5.1.m1.1.1.3">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I4.ix1.p5.1.m1.1c">\mu_{x}</annotation></semantics></math> and <math id="S5.I4.ix1.p5.2.m2.1" class="ltx_Math" alttext="\mu_{y}" display="inline"><semantics id="S5.I4.ix1.p5.2.m2.1a"><msub id="S5.I4.ix1.p5.2.m2.1.1" xref="S5.I4.ix1.p5.2.m2.1.1.cmml"><mi id="S5.I4.ix1.p5.2.m2.1.1.2" xref="S5.I4.ix1.p5.2.m2.1.1.2.cmml">μ</mi><mi id="S5.I4.ix1.p5.2.m2.1.1.3" xref="S5.I4.ix1.p5.2.m2.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S5.I4.ix1.p5.2.m2.1b"><apply id="S5.I4.ix1.p5.2.m2.1.1.cmml" xref="S5.I4.ix1.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S5.I4.ix1.p5.2.m2.1.1.1.cmml" xref="S5.I4.ix1.p5.2.m2.1.1">subscript</csymbol><ci id="S5.I4.ix1.p5.2.m2.1.1.2.cmml" xref="S5.I4.ix1.p5.2.m2.1.1.2">𝜇</ci><ci id="S5.I4.ix1.p5.2.m2.1.1.3.cmml" xref="S5.I4.ix1.p5.2.m2.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I4.ix1.p5.2.m2.1c">\mu_{y}</annotation></semantics></math> are the mean values of the local window patches <math id="S5.I4.ix1.p5.3.m3.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S5.I4.ix1.p5.3.m3.1a"><mi id="S5.I4.ix1.p5.3.m3.1.1" xref="S5.I4.ix1.p5.3.m3.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S5.I4.ix1.p5.3.m3.1b"><ci id="S5.I4.ix1.p5.3.m3.1.1.cmml" xref="S5.I4.ix1.p5.3.m3.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.I4.ix1.p5.3.m3.1c">x</annotation></semantics></math> and <math id="S5.I4.ix1.p5.4.m4.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S5.I4.ix1.p5.4.m4.1a"><mi id="S5.I4.ix1.p5.4.m4.1.1" xref="S5.I4.ix1.p5.4.m4.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S5.I4.ix1.p5.4.m4.1b"><ci id="S5.I4.ix1.p5.4.m4.1.1.cmml" xref="S5.I4.ix1.p5.4.m4.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.I4.ix1.p5.4.m4.1c">y</annotation></semantics></math>, respectively; <math id="S5.I4.ix1.p5.5.m5.1" class="ltx_Math" alttext="\sigma_{x}^{2}+\sigma_{y}^{2}" display="inline"><semantics id="S5.I4.ix1.p5.5.m5.1a"><mrow id="S5.I4.ix1.p5.5.m5.1.1" xref="S5.I4.ix1.p5.5.m5.1.1.cmml"><msubsup id="S5.I4.ix1.p5.5.m5.1.1.2" xref="S5.I4.ix1.p5.5.m5.1.1.2.cmml"><mi id="S5.I4.ix1.p5.5.m5.1.1.2.2.2" xref="S5.I4.ix1.p5.5.m5.1.1.2.2.2.cmml">σ</mi><mi id="S5.I4.ix1.p5.5.m5.1.1.2.2.3" xref="S5.I4.ix1.p5.5.m5.1.1.2.2.3.cmml">x</mi><mn id="S5.I4.ix1.p5.5.m5.1.1.2.3" xref="S5.I4.ix1.p5.5.m5.1.1.2.3.cmml">2</mn></msubsup><mo id="S5.I4.ix1.p5.5.m5.1.1.1" xref="S5.I4.ix1.p5.5.m5.1.1.1.cmml">+</mo><msubsup id="S5.I4.ix1.p5.5.m5.1.1.3" xref="S5.I4.ix1.p5.5.m5.1.1.3.cmml"><mi id="S5.I4.ix1.p5.5.m5.1.1.3.2.2" xref="S5.I4.ix1.p5.5.m5.1.1.3.2.2.cmml">σ</mi><mi id="S5.I4.ix1.p5.5.m5.1.1.3.2.3" xref="S5.I4.ix1.p5.5.m5.1.1.3.2.3.cmml">y</mi><mn id="S5.I4.ix1.p5.5.m5.1.1.3.3" xref="S5.I4.ix1.p5.5.m5.1.1.3.3.cmml">2</mn></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S5.I4.ix1.p5.5.m5.1b"><apply id="S5.I4.ix1.p5.5.m5.1.1.cmml" xref="S5.I4.ix1.p5.5.m5.1.1"><plus id="S5.I4.ix1.p5.5.m5.1.1.1.cmml" xref="S5.I4.ix1.p5.5.m5.1.1.1"></plus><apply id="S5.I4.ix1.p5.5.m5.1.1.2.cmml" xref="S5.I4.ix1.p5.5.m5.1.1.2"><csymbol cd="ambiguous" id="S5.I4.ix1.p5.5.m5.1.1.2.1.cmml" xref="S5.I4.ix1.p5.5.m5.1.1.2">superscript</csymbol><apply id="S5.I4.ix1.p5.5.m5.1.1.2.2.cmml" xref="S5.I4.ix1.p5.5.m5.1.1.2"><csymbol cd="ambiguous" id="S5.I4.ix1.p5.5.m5.1.1.2.2.1.cmml" xref="S5.I4.ix1.p5.5.m5.1.1.2">subscript</csymbol><ci id="S5.I4.ix1.p5.5.m5.1.1.2.2.2.cmml" xref="S5.I4.ix1.p5.5.m5.1.1.2.2.2">𝜎</ci><ci id="S5.I4.ix1.p5.5.m5.1.1.2.2.3.cmml" xref="S5.I4.ix1.p5.5.m5.1.1.2.2.3">𝑥</ci></apply><cn type="integer" id="S5.I4.ix1.p5.5.m5.1.1.2.3.cmml" xref="S5.I4.ix1.p5.5.m5.1.1.2.3">2</cn></apply><apply id="S5.I4.ix1.p5.5.m5.1.1.3.cmml" xref="S5.I4.ix1.p5.5.m5.1.1.3"><csymbol cd="ambiguous" id="S5.I4.ix1.p5.5.m5.1.1.3.1.cmml" xref="S5.I4.ix1.p5.5.m5.1.1.3">superscript</csymbol><apply id="S5.I4.ix1.p5.5.m5.1.1.3.2.cmml" xref="S5.I4.ix1.p5.5.m5.1.1.3"><csymbol cd="ambiguous" id="S5.I4.ix1.p5.5.m5.1.1.3.2.1.cmml" xref="S5.I4.ix1.p5.5.m5.1.1.3">subscript</csymbol><ci id="S5.I4.ix1.p5.5.m5.1.1.3.2.2.cmml" xref="S5.I4.ix1.p5.5.m5.1.1.3.2.2">𝜎</ci><ci id="S5.I4.ix1.p5.5.m5.1.1.3.2.3.cmml" xref="S5.I4.ix1.p5.5.m5.1.1.3.2.3">𝑦</ci></apply><cn type="integer" id="S5.I4.ix1.p5.5.m5.1.1.3.3.cmml" xref="S5.I4.ix1.p5.5.m5.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I4.ix1.p5.5.m5.1c">\sigma_{x}^{2}+\sigma_{y}^{2}</annotation></semantics></math> are their local variances and <math id="S5.I4.ix1.p5.6.m6.1" class="ltx_Math" alttext="\sigma_{xy}" display="inline"><semantics id="S5.I4.ix1.p5.6.m6.1a"><msub id="S5.I4.ix1.p5.6.m6.1.1" xref="S5.I4.ix1.p5.6.m6.1.1.cmml"><mi id="S5.I4.ix1.p5.6.m6.1.1.2" xref="S5.I4.ix1.p5.6.m6.1.1.2.cmml">σ</mi><mrow id="S5.I4.ix1.p5.6.m6.1.1.3" xref="S5.I4.ix1.p5.6.m6.1.1.3.cmml"><mi id="S5.I4.ix1.p5.6.m6.1.1.3.2" xref="S5.I4.ix1.p5.6.m6.1.1.3.2.cmml">x</mi><mo lspace="0em" rspace="0em" id="S5.I4.ix1.p5.6.m6.1.1.3.1" xref="S5.I4.ix1.p5.6.m6.1.1.3.1.cmml">​</mo><mi id="S5.I4.ix1.p5.6.m6.1.1.3.3" xref="S5.I4.ix1.p5.6.m6.1.1.3.3.cmml">y</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.I4.ix1.p5.6.m6.1b"><apply id="S5.I4.ix1.p5.6.m6.1.1.cmml" xref="S5.I4.ix1.p5.6.m6.1.1"><csymbol cd="ambiguous" id="S5.I4.ix1.p5.6.m6.1.1.1.cmml" xref="S5.I4.ix1.p5.6.m6.1.1">subscript</csymbol><ci id="S5.I4.ix1.p5.6.m6.1.1.2.cmml" xref="S5.I4.ix1.p5.6.m6.1.1.2">𝜎</ci><apply id="S5.I4.ix1.p5.6.m6.1.1.3.cmml" xref="S5.I4.ix1.p5.6.m6.1.1.3"><times id="S5.I4.ix1.p5.6.m6.1.1.3.1.cmml" xref="S5.I4.ix1.p5.6.m6.1.1.3.1"></times><ci id="S5.I4.ix1.p5.6.m6.1.1.3.2.cmml" xref="S5.I4.ix1.p5.6.m6.1.1.3.2">𝑥</ci><ci id="S5.I4.ix1.p5.6.m6.1.1.3.3.cmml" xref="S5.I4.ix1.p5.6.m6.1.1.3.3">𝑦</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I4.ix1.p5.6.m6.1c">\sigma_{xy}</annotation></semantics></math> is the local covariance of <math id="S5.I4.ix1.p5.7.m7.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S5.I4.ix1.p5.7.m7.1a"><mi id="S5.I4.ix1.p5.7.m7.1.1" xref="S5.I4.ix1.p5.7.m7.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S5.I4.ix1.p5.7.m7.1b"><ci id="S5.I4.ix1.p5.7.m7.1.1.cmml" xref="S5.I4.ix1.p5.7.m7.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.I4.ix1.p5.7.m7.1c">x</annotation></semantics></math> and <math id="S5.I4.ix1.p5.8.m8.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S5.I4.ix1.p5.8.m8.1a"><mi id="S5.I4.ix1.p5.8.m8.1.1" xref="S5.I4.ix1.p5.8.m8.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S5.I4.ix1.p5.8.m8.1b"><ci id="S5.I4.ix1.p5.8.m8.1.1.cmml" xref="S5.I4.ix1.p5.8.m8.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.I4.ix1.p5.8.m8.1c">y</annotation></semantics></math>. <math id="S5.I4.ix1.p5.9.m9.1" class="ltx_Math" alttext="C_{1}" display="inline"><semantics id="S5.I4.ix1.p5.9.m9.1a"><msub id="S5.I4.ix1.p5.9.m9.1.1" xref="S5.I4.ix1.p5.9.m9.1.1.cmml"><mi id="S5.I4.ix1.p5.9.m9.1.1.2" xref="S5.I4.ix1.p5.9.m9.1.1.2.cmml">C</mi><mn id="S5.I4.ix1.p5.9.m9.1.1.3" xref="S5.I4.ix1.p5.9.m9.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S5.I4.ix1.p5.9.m9.1b"><apply id="S5.I4.ix1.p5.9.m9.1.1.cmml" xref="S5.I4.ix1.p5.9.m9.1.1"><csymbol cd="ambiguous" id="S5.I4.ix1.p5.9.m9.1.1.1.cmml" xref="S5.I4.ix1.p5.9.m9.1.1">subscript</csymbol><ci id="S5.I4.ix1.p5.9.m9.1.1.2.cmml" xref="S5.I4.ix1.p5.9.m9.1.1.2">𝐶</ci><cn type="integer" id="S5.I4.ix1.p5.9.m9.1.1.3.cmml" xref="S5.I4.ix1.p5.9.m9.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I4.ix1.p5.9.m9.1c">C_{1}</annotation></semantics></math> and <math id="S5.I4.ix1.p5.10.m10.1" class="ltx_Math" alttext="C_{2}" display="inline"><semantics id="S5.I4.ix1.p5.10.m10.1a"><msub id="S5.I4.ix1.p5.10.m10.1.1" xref="S5.I4.ix1.p5.10.m10.1.1.cmml"><mi id="S5.I4.ix1.p5.10.m10.1.1.2" xref="S5.I4.ix1.p5.10.m10.1.1.2.cmml">C</mi><mn id="S5.I4.ix1.p5.10.m10.1.1.3" xref="S5.I4.ix1.p5.10.m10.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S5.I4.ix1.p5.10.m10.1b"><apply id="S5.I4.ix1.p5.10.m10.1.1.cmml" xref="S5.I4.ix1.p5.10.m10.1.1"><csymbol cd="ambiguous" id="S5.I4.ix1.p5.10.m10.1.1.1.cmml" xref="S5.I4.ix1.p5.10.m10.1.1">subscript</csymbol><ci id="S5.I4.ix1.p5.10.m10.1.1.2.cmml" xref="S5.I4.ix1.p5.10.m10.1.1.2">𝐶</ci><cn type="integer" id="S5.I4.ix1.p5.10.m10.1.1.3.cmml" xref="S5.I4.ix1.p5.10.m10.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I4.ix1.p5.10.m10.1c">C_{2}</annotation></semantics></math> are constants set based on the same parameter settings as Wang <span id="S5.I4.ix1.p5.11.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>, <span id="S5.I4.ix1.p5.11.2" class="ltx_text ltx_font_italic">i.e.</span> <math id="S5.I4.ix1.p5.11.m11.2" class="ltx_Math" alttext="C_{1}\approx 6.55,C_{2}\approx 58.98" display="inline"><semantics id="S5.I4.ix1.p5.11.m11.2a"><mrow id="S5.I4.ix1.p5.11.m11.2.2.2" xref="S5.I4.ix1.p5.11.m11.2.2.3.cmml"><mrow id="S5.I4.ix1.p5.11.m11.1.1.1.1" xref="S5.I4.ix1.p5.11.m11.1.1.1.1.cmml"><msub id="S5.I4.ix1.p5.11.m11.1.1.1.1.2" xref="S5.I4.ix1.p5.11.m11.1.1.1.1.2.cmml"><mi id="S5.I4.ix1.p5.11.m11.1.1.1.1.2.2" xref="S5.I4.ix1.p5.11.m11.1.1.1.1.2.2.cmml">C</mi><mn id="S5.I4.ix1.p5.11.m11.1.1.1.1.2.3" xref="S5.I4.ix1.p5.11.m11.1.1.1.1.2.3.cmml">1</mn></msub><mo id="S5.I4.ix1.p5.11.m11.1.1.1.1.1" xref="S5.I4.ix1.p5.11.m11.1.1.1.1.1.cmml">≈</mo><mn id="S5.I4.ix1.p5.11.m11.1.1.1.1.3" xref="S5.I4.ix1.p5.11.m11.1.1.1.1.3.cmml">6.55</mn></mrow><mo id="S5.I4.ix1.p5.11.m11.2.2.2.3" xref="S5.I4.ix1.p5.11.m11.2.2.3a.cmml">,</mo><mrow id="S5.I4.ix1.p5.11.m11.2.2.2.2" xref="S5.I4.ix1.p5.11.m11.2.2.2.2.cmml"><msub id="S5.I4.ix1.p5.11.m11.2.2.2.2.2" xref="S5.I4.ix1.p5.11.m11.2.2.2.2.2.cmml"><mi id="S5.I4.ix1.p5.11.m11.2.2.2.2.2.2" xref="S5.I4.ix1.p5.11.m11.2.2.2.2.2.2.cmml">C</mi><mn id="S5.I4.ix1.p5.11.m11.2.2.2.2.2.3" xref="S5.I4.ix1.p5.11.m11.2.2.2.2.2.3.cmml">2</mn></msub><mo id="S5.I4.ix1.p5.11.m11.2.2.2.2.1" xref="S5.I4.ix1.p5.11.m11.2.2.2.2.1.cmml">≈</mo><mn id="S5.I4.ix1.p5.11.m11.2.2.2.2.3" xref="S5.I4.ix1.p5.11.m11.2.2.2.2.3.cmml">58.98</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.I4.ix1.p5.11.m11.2b"><apply id="S5.I4.ix1.p5.11.m11.2.2.3.cmml" xref="S5.I4.ix1.p5.11.m11.2.2.2"><csymbol cd="ambiguous" id="S5.I4.ix1.p5.11.m11.2.2.3a.cmml" xref="S5.I4.ix1.p5.11.m11.2.2.2.3">formulae-sequence</csymbol><apply id="S5.I4.ix1.p5.11.m11.1.1.1.1.cmml" xref="S5.I4.ix1.p5.11.m11.1.1.1.1"><approx id="S5.I4.ix1.p5.11.m11.1.1.1.1.1.cmml" xref="S5.I4.ix1.p5.11.m11.1.1.1.1.1"></approx><apply id="S5.I4.ix1.p5.11.m11.1.1.1.1.2.cmml" xref="S5.I4.ix1.p5.11.m11.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.I4.ix1.p5.11.m11.1.1.1.1.2.1.cmml" xref="S5.I4.ix1.p5.11.m11.1.1.1.1.2">subscript</csymbol><ci id="S5.I4.ix1.p5.11.m11.1.1.1.1.2.2.cmml" xref="S5.I4.ix1.p5.11.m11.1.1.1.1.2.2">𝐶</ci><cn type="integer" id="S5.I4.ix1.p5.11.m11.1.1.1.1.2.3.cmml" xref="S5.I4.ix1.p5.11.m11.1.1.1.1.2.3">1</cn></apply><cn type="float" id="S5.I4.ix1.p5.11.m11.1.1.1.1.3.cmml" xref="S5.I4.ix1.p5.11.m11.1.1.1.1.3">6.55</cn></apply><apply id="S5.I4.ix1.p5.11.m11.2.2.2.2.cmml" xref="S5.I4.ix1.p5.11.m11.2.2.2.2"><approx id="S5.I4.ix1.p5.11.m11.2.2.2.2.1.cmml" xref="S5.I4.ix1.p5.11.m11.2.2.2.2.1"></approx><apply id="S5.I4.ix1.p5.11.m11.2.2.2.2.2.cmml" xref="S5.I4.ix1.p5.11.m11.2.2.2.2.2"><csymbol cd="ambiguous" id="S5.I4.ix1.p5.11.m11.2.2.2.2.2.1.cmml" xref="S5.I4.ix1.p5.11.m11.2.2.2.2.2">subscript</csymbol><ci id="S5.I4.ix1.p5.11.m11.2.2.2.2.2.2.cmml" xref="S5.I4.ix1.p5.11.m11.2.2.2.2.2.2">𝐶</ci><cn type="integer" id="S5.I4.ix1.p5.11.m11.2.2.2.2.2.3.cmml" xref="S5.I4.ix1.p5.11.m11.2.2.2.2.2.3">2</cn></apply><cn type="float" id="S5.I4.ix1.p5.11.m11.2.2.2.2.3.cmml" xref="S5.I4.ix1.p5.11.m11.2.2.2.2.3">58.98</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I4.ix1.p5.11.m11.2c">C_{1}\approx 6.55,C_{2}\approx 58.98</annotation></semantics></math>. MSSIM returns a value in the range of 0 to 1, where 1 means that X and Y are identical.</p>
</div>
</dd>
</dl>
</div>
<div id="S5.SS2.p4" class="ltx_para">
<dl id="S5.I5" class="ltx_description">
<dt id="S5.I5.ix1" class="ltx_item"><span class="ltx_tag ltx_tag_item"><span id="S5.I5.ix1.1.1.1" class="ltx_text ltx_font_bold">Visual Information Fidelity (VIF)</span></span></dt>
<dd class="ltx_item">
<div id="S5.I5.ix1.p1" class="ltx_para">
<p id="S5.I5.ix1.p1.1" class="ltx_p">is a full reference image quality assessment measurement proposed by Sheikh and Bovik in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>. VIF is derived from a statistical model for natural scenes as well as models for image distortion and the human visual system. <math id="S5.I5.ix1.p1.1.m1.2" class="ltx_Math" alttext="VIF(X,Y)" display="inline"><semantics id="S5.I5.ix1.p1.1.m1.2a"><mrow id="S5.I5.ix1.p1.1.m1.2.3" xref="S5.I5.ix1.p1.1.m1.2.3.cmml"><mi id="S5.I5.ix1.p1.1.m1.2.3.2" xref="S5.I5.ix1.p1.1.m1.2.3.2.cmml">V</mi><mo lspace="0em" rspace="0em" id="S5.I5.ix1.p1.1.m1.2.3.1" xref="S5.I5.ix1.p1.1.m1.2.3.1.cmml">​</mo><mi id="S5.I5.ix1.p1.1.m1.2.3.3" xref="S5.I5.ix1.p1.1.m1.2.3.3.cmml">I</mi><mo lspace="0em" rspace="0em" id="S5.I5.ix1.p1.1.m1.2.3.1a" xref="S5.I5.ix1.p1.1.m1.2.3.1.cmml">​</mo><mi id="S5.I5.ix1.p1.1.m1.2.3.4" xref="S5.I5.ix1.p1.1.m1.2.3.4.cmml">F</mi><mo lspace="0em" rspace="0em" id="S5.I5.ix1.p1.1.m1.2.3.1b" xref="S5.I5.ix1.p1.1.m1.2.3.1.cmml">​</mo><mrow id="S5.I5.ix1.p1.1.m1.2.3.5.2" xref="S5.I5.ix1.p1.1.m1.2.3.5.1.cmml"><mo stretchy="false" id="S5.I5.ix1.p1.1.m1.2.3.5.2.1" xref="S5.I5.ix1.p1.1.m1.2.3.5.1.cmml">(</mo><mi id="S5.I5.ix1.p1.1.m1.1.1" xref="S5.I5.ix1.p1.1.m1.1.1.cmml">X</mi><mo id="S5.I5.ix1.p1.1.m1.2.3.5.2.2" xref="S5.I5.ix1.p1.1.m1.2.3.5.1.cmml">,</mo><mi id="S5.I5.ix1.p1.1.m1.2.2" xref="S5.I5.ix1.p1.1.m1.2.2.cmml">Y</mi><mo stretchy="false" id="S5.I5.ix1.p1.1.m1.2.3.5.2.3" xref="S5.I5.ix1.p1.1.m1.2.3.5.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.I5.ix1.p1.1.m1.2b"><apply id="S5.I5.ix1.p1.1.m1.2.3.cmml" xref="S5.I5.ix1.p1.1.m1.2.3"><times id="S5.I5.ix1.p1.1.m1.2.3.1.cmml" xref="S5.I5.ix1.p1.1.m1.2.3.1"></times><ci id="S5.I5.ix1.p1.1.m1.2.3.2.cmml" xref="S5.I5.ix1.p1.1.m1.2.3.2">𝑉</ci><ci id="S5.I5.ix1.p1.1.m1.2.3.3.cmml" xref="S5.I5.ix1.p1.1.m1.2.3.3">𝐼</ci><ci id="S5.I5.ix1.p1.1.m1.2.3.4.cmml" xref="S5.I5.ix1.p1.1.m1.2.3.4">𝐹</ci><interval closure="open" id="S5.I5.ix1.p1.1.m1.2.3.5.1.cmml" xref="S5.I5.ix1.p1.1.m1.2.3.5.2"><ci id="S5.I5.ix1.p1.1.m1.1.1.cmml" xref="S5.I5.ix1.p1.1.m1.1.1">𝑋</ci><ci id="S5.I5.ix1.p1.1.m1.2.2.cmml" xref="S5.I5.ix1.p1.1.m1.2.2">𝑌</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I5.ix1.p1.1.m1.2c">VIF(X,Y)</annotation></semantics></math> returns a value in range of 0 to 1, where 1 indicates that the ground truth and inpainted images are identical. We use the pixel domain version as implemented in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>.</p>
</div>
</dd>
</dl>
</div>
<div id="S5.SS2.p5" class="ltx_para">
<p id="S5.SS2.p5.1" class="ltx_p">We estimate the different quality metrics both on portrait images, <span id="S5.SS2.p5.1.1" class="ltx_text ltx_font_italic">i.e.</span> where the entire face is visible and on the inner part of the face (corresponding to the area covered by the 68 dlib landmark points; see Fig. <a href="#S3.F3" title="Figure 3 ‣ III-A Placement of Tattoos ‣ III Facial Tattoo Generator ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>) where we focus on only the area from the eyebrows to the chin; these regions are shown in Fig. <a href="#S5.F13" title="Figure 13 ‣ V-B Quality Metrics ‣ V Tattoo Removal ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></a>.</p>
</div>
<figure id="S5.F13" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F13.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2202.05297/assets/graphics/portrait_inner_examples/man.jpg" id="S5.F13.sf1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="359" height="359" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F13.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S5.F13.sf1.3.2" class="ltx_text" style="font-size:90%;">Portrait</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F13.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2202.05297/assets/graphics/portrait_inner_examples/man_cropped.jpg" id="S5.F13.sf2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="359" height="359" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F13.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S5.F13.sf2.3.2" class="ltx_text" style="font-size:90%;">Inner</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F13.2.1.1" class="ltx_text" style="font-size:90%;">Figure 13</span>: </span><span id="S5.F13.3.2" class="ltx_text" style="font-size:90%;">Examples of (a) a full portrait image where the entire face is visible and (b) a crop of the inner face region.</span></figcaption>
</figure>
<figure id="S5.F14" class="ltx_figure"><img src="/html/2202.05297/assets/x3.png" id="S5.F14.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="345" height="277" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F14.2.1.1" class="ltx_text" style="font-size:90%;">Figure 14</span>: </span><span id="S5.F14.3.2" class="ltx_text" style="font-size:90%;">Examples of using deep-learning based algorithms for facial tattoo removal. Best viewed in electronic format (zoomed in).</span></figcaption>
</figure>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS3.4.1.1" class="ltx_text">V-C</span> </span><span id="S5.SS3.5.2" class="ltx_text ltx_font_italic">Removal Quality Results</span>
</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">We use a total of 41 facial images with tattoos where the tattoos have been manually removed using PhotoShop; we refer to these as our ground truth images. Examples of using the different deep learning-based methods for removing tattoos are given in Fig. <a href="#S5.F14" title="Figure 14 ‣ V-B Quality Metrics ‣ V Tattoo Removal ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14</span></a>. As seen, the best model (TRNet) is able to remove most tattoos with only a few artefacts, whereas the other models perform less well and, for some images, alter the face or fail to remove all tattoos accurately.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.1" class="ltx_p">Different quality scores are reported in Tab. <a href="#S5.T2" title="TABLE II ‣ V-C Removal Quality Results ‣ V Tattoo Removal ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> which shows that the TRNet model performs best in most scenarios especially when only looking at the inner part of the face.</p>
</div>
<figure id="S5.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T2.20.1.1" class="ltx_text" style="font-size:90%;">TABLE II</span>: </span><span id="S5.T2.21.2" class="ltx_text" style="font-size:90%;">Quality measurements of the reconstructed images compared to ground truth images where tattoos have been manually removed. ”Tattooed” denotes the baseline case where the tattooed images are compared to the ground truth images.</span></figcaption>
<div id="S5.T2.18" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:76.4pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-56.9pt,9.9pt) scale(0.7922,0.7922) ;">
<p id="S5.T2.18.18" class="ltx_p"><span id="S5.T2.18.18.18" class="ltx_text">
<span id="S5.T2.18.18.18.18" class="ltx_inline-block ltx_transformed_outer" style="width:547.4pt;height:96.4pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span id="S5.T2.18.18.18.18.18" class="ltx_p"><span id="S5.T2.18.18.18.18.18.18" class="ltx_text">
<span id="S5.T2.18.18.18.18.18.18.18" class="ltx_tabular ltx_align_middle">
<span id="S5.T2.18.18.18.18.18.18.18.19" class="ltx_tr">
<span id="S5.T2.18.18.18.18.18.18.18.19.1" class="ltx_td ltx_align_right ltx_border_tt ltx_rowspan ltx_rowspan_2">   <span id="S5.T2.18.18.18.18.18.18.18.19.1.1" class="ltx_text ltx_font_bold">Scenario</span></span>
<span id="S5.T2.18.18.18.18.18.18.18.19.2" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_3"><span id="S5.T2.18.18.18.18.18.18.18.19.2.1" class="ltx_text ltx_font_bold">Portrait</span></span>
<span id="S5.T2.18.18.18.18.18.18.18.19.3" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_3">
<span id="S5.T2.18.18.18.18.18.18.18.19.3.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T2.18.18.18.18.18.18.18.19.3.1.1" class="ltx_tr">
<span id="S5.T2.18.18.18.18.18.18.18.19.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S5.T2.18.18.18.18.18.18.18.19.3.1.1.1.1" class="ltx_text ltx_font_bold">Inner</span></span></span>
</span></span></span>
<span id="S5.T2.18.18.18.18.18.18.18.20" class="ltx_tr">
<span id="S5.T2.18.18.18.18.18.18.18.20.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T2.18.18.18.18.18.18.18.20.1.1" class="ltx_text ltx_font_bold">MSSIM</span></span>
<span id="S5.T2.18.18.18.18.18.18.18.20.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T2.18.18.18.18.18.18.18.20.2.1" class="ltx_text ltx_font_bold">PSNR</span></span>
<span id="S5.T2.18.18.18.18.18.18.18.20.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T2.18.18.18.18.18.18.18.20.3.1" class="ltx_text ltx_font_bold">VIF</span></span>
<span id="S5.T2.18.18.18.18.18.18.18.20.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T2.18.18.18.18.18.18.18.20.4.1" class="ltx_text ltx_font_bold">MSSIM</span></span>
<span id="S5.T2.18.18.18.18.18.18.18.20.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T2.18.18.18.18.18.18.18.20.5.1" class="ltx_text ltx_font_bold">PSNR</span></span>
<span id="S5.T2.18.18.18.18.18.18.18.20.6" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S5.T2.18.18.18.18.18.18.18.20.6.1" class="ltx_text ltx_font_bold">VIF</span></span></span>
<span id="S5.T2.6.6.6.6.6.6.6.6" class="ltx_tr">
<span id="S5.T2.6.6.6.6.6.6.6.6.7" class="ltx_td ltx_align_left ltx_border_t">Tattooed</span>
<span id="S5.T2.1.1.1.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S5.T2.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="0.947\ (\pm 0.053)" display="inline"><semantics id="S5.T2.1.1.1.1.1.1.1.1.1.m1.1a"><mrow id="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.cmml"><mn id="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.3" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml">0.947</mn><mo lspace="0.500em" rspace="0em" id="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.2" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml">​</mo><mrow id="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.1.1" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.1.1.2" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.1.1.1" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.cmml"><mo id="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.1.1.1a" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.cmml">±</mo><mn id="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.2" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.2.cmml">0.053</mn></mrow><mo stretchy="false" id="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.1.1.3" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.1.1.1.1.1.1.m1.1b"><apply id="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1"><times id="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.2"></times><cn type="float" id="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.3">0.947</cn><apply id="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.cmml" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.1.1"><csymbol cd="latexml" id="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.1.cmml" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.2.cmml" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.2">0.053</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.1.1.1.1.1.1.1.1.1.m1.1c">0.947\ (\pm 0.053)</annotation></semantics></math></span>
<span id="S5.T2.2.2.2.2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S5.T2.2.2.2.2.2.2.2.2.2.m1.1" class="ltx_Math" alttext="31.31\ (\pm 5.04)" display="inline"><semantics id="S5.T2.2.2.2.2.2.2.2.2.2.m1.1a"><mrow id="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1" xref="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1.cmml"><mn id="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1.3" xref="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1.3.cmml">31.31</mn><mo lspace="0.500em" rspace="0em" id="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1.2" xref="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1.2.cmml">​</mo><mrow id="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1.1.1" xref="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1.1.1.2" xref="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1.1.1.1" xref="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1.1.1.1.cmml"><mo id="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1.1.1.1a" xref="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1.1.1.1.cmml">±</mo><mn id="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1.1.1.1.2" xref="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1.1.1.1.2.cmml">5.04</mn></mrow><mo stretchy="false" id="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1.1.1.3" xref="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.2.2.2.2.2.2.2.2.2.m1.1b"><apply id="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1.cmml" xref="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1"><times id="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1.2.cmml" xref="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1.2"></times><cn type="float" id="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1.3.cmml" xref="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1.3">31.31</cn><apply id="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1.1.1.1.cmml" xref="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1.1.1"><csymbol cd="latexml" id="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1.1.1.1.1.cmml" xref="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1.1.1.1.2.cmml" xref="S5.T2.2.2.2.2.2.2.2.2.2.m1.1.1.1.1.1.2">5.04</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.2.2.2.2.2.2.2.2.m1.1c">31.31\ (\pm 5.04)</annotation></semantics></math></span>
<span id="S5.T2.3.3.3.3.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t"><math id="S5.T2.3.3.3.3.3.3.3.3.3.m1.1" class="ltx_Math" alttext="0.884\ (\pm 0.093)" display="inline"><semantics id="S5.T2.3.3.3.3.3.3.3.3.3.m1.1a"><mrow id="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1" xref="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1.cmml"><mn id="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1.3" xref="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1.3.cmml">0.884</mn><mo lspace="0.500em" rspace="0em" id="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1.2" xref="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1.2.cmml">​</mo><mrow id="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1.1.1" xref="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1.1.1.2" xref="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1.1.1.1" xref="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1.1.1.1.cmml"><mo id="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1.1.1.1a" xref="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1.1.1.1.cmml">±</mo><mn id="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1.1.1.1.2" xref="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1.1.1.1.2.cmml">0.093</mn></mrow><mo stretchy="false" id="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1.1.1.3" xref="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.3.3.3.3.3.3.3.3.3.m1.1b"><apply id="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1.cmml" xref="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1"><times id="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1.2.cmml" xref="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1.2"></times><cn type="float" id="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1.3.cmml" xref="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1.3">0.884</cn><apply id="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1.1.1.1.cmml" xref="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1.1.1"><csymbol cd="latexml" id="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1.1.1.1.1.cmml" xref="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1.1.1.1.2.cmml" xref="S5.T2.3.3.3.3.3.3.3.3.3.m1.1.1.1.1.1.2">0.093</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.3.3.3.3.3.3.3.3.3.m1.1c">0.884\ (\pm 0.093)</annotation></semantics></math></span>
<span id="S5.T2.4.4.4.4.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_t"><math id="S5.T2.4.4.4.4.4.4.4.4.4.m1.1" class="ltx_Math" alttext="0.974\ (\pm 0.027)" display="inline"><semantics id="S5.T2.4.4.4.4.4.4.4.4.4.m1.1a"><mrow id="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1" xref="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1.cmml"><mn id="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1.3" xref="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1.3.cmml">0.974</mn><mo lspace="0.500em" rspace="0em" id="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1.2" xref="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1.2.cmml">​</mo><mrow id="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1.1.1" xref="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1.1.1.2" xref="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1.1.1.1" xref="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1.1.1.1.cmml"><mo id="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1.1.1.1a" xref="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1.1.1.1.cmml">±</mo><mn id="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1.1.1.1.2" xref="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1.1.1.1.2.cmml">0.027</mn></mrow><mo stretchy="false" id="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1.1.1.3" xref="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.4.4.4.4.4.4.4.4.4.m1.1b"><apply id="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1.cmml" xref="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1"><times id="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1.2.cmml" xref="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1.2"></times><cn type="float" id="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1.3.cmml" xref="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1.3">0.974</cn><apply id="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1.1.1.1.cmml" xref="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1.1.1"><csymbol cd="latexml" id="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1.1.1.1.1.cmml" xref="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1.1.1.1.2.cmml" xref="S5.T2.4.4.4.4.4.4.4.4.4.m1.1.1.1.1.1.2">0.027</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.4.4.4.4.4.4.4.4.4.m1.1c">0.974\ (\pm 0.027)</annotation></semantics></math></span>
<span id="S5.T2.5.5.5.5.5.5.5.5.5" class="ltx_td ltx_align_center ltx_border_t"><math id="S5.T2.5.5.5.5.5.5.5.5.5.m1.1" class="ltx_Math" alttext="35.37\ (\pm 6.63)" display="inline"><semantics id="S5.T2.5.5.5.5.5.5.5.5.5.m1.1a"><mrow id="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1" xref="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1.cmml"><mn id="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1.3" xref="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1.3.cmml">35.37</mn><mo lspace="0.500em" rspace="0em" id="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1.2" xref="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1.2.cmml">​</mo><mrow id="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1.1.1" xref="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1.1.1.2" xref="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1.1.1.1" xref="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1.1.1.1.cmml"><mo id="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1.1.1.1a" xref="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1.1.1.1.cmml">±</mo><mn id="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1.1.1.1.2" xref="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1.1.1.1.2.cmml">6.63</mn></mrow><mo stretchy="false" id="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1.1.1.3" xref="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.5.5.5.5.5.5.5.5.5.m1.1b"><apply id="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1.cmml" xref="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1"><times id="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1.2.cmml" xref="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1.2"></times><cn type="float" id="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1.3.cmml" xref="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1.3">35.37</cn><apply id="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1.1.1.1.cmml" xref="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1.1.1"><csymbol cd="latexml" id="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1.1.1.1.1.cmml" xref="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1.1.1.1.2.cmml" xref="S5.T2.5.5.5.5.5.5.5.5.5.m1.1.1.1.1.1.2">6.63</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.5.5.5.5.5.5.5.5.5.m1.1c">35.37\ (\pm 6.63)</annotation></semantics></math></span>
<span id="S5.T2.6.6.6.6.6.6.6.6.6" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><math id="S5.T2.6.6.6.6.6.6.6.6.6.m1.1" class="ltx_Math" alttext="0.879\ (\pm 0.097)" display="inline"><semantics id="S5.T2.6.6.6.6.6.6.6.6.6.m1.1a"><mrow id="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1" xref="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1.cmml"><mn id="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1.3" xref="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1.3.cmml">0.879</mn><mo lspace="0.500em" rspace="0em" id="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1.2" xref="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1.2.cmml">​</mo><mrow id="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1.1.1" xref="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1.1.1.2" xref="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1.1.1.1" xref="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1.1.1.1.cmml"><mo id="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1.1.1.1a" xref="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1.1.1.1.cmml">±</mo><mn id="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1.1.1.1.2" xref="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1.1.1.1.2.cmml">0.097</mn></mrow><mo stretchy="false" id="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1.1.1.3" xref="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.6.6.6.6.6.6.6.6.6.m1.1b"><apply id="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1.cmml" xref="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1"><times id="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1.2.cmml" xref="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1.2"></times><cn type="float" id="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1.3.cmml" xref="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1.3">0.879</cn><apply id="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1.1.1.1.cmml" xref="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1.1.1"><csymbol cd="latexml" id="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1.1.1.1.1.cmml" xref="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1.1.1.1.2.cmml" xref="S5.T2.6.6.6.6.6.6.6.6.6.m1.1.1.1.1.1.2">0.097</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.6.6.6.6.6.6.6.6.6.m1.1c">0.879\ (\pm 0.097)</annotation></semantics></math></span></span>
<span id="S5.T2.12.12.12.12.12.12.12.12" class="ltx_tr">
<span id="S5.T2.12.12.12.12.12.12.12.12.7" class="ltx_td ltx_align_left">pix2pix</span>
<span id="S5.T2.7.7.7.7.7.7.7.7.1" class="ltx_td ltx_align_center"><math id="S5.T2.7.7.7.7.7.7.7.7.1.m1.1" class="ltx_Math" alttext="0.943\ (\pm 0.043)" display="inline"><semantics id="S5.T2.7.7.7.7.7.7.7.7.1.m1.1a"><mrow id="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1" xref="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1.cmml"><mn id="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1.3" xref="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1.3.cmml">0.943</mn><mo lspace="0.500em" rspace="0em" id="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1.2" xref="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1.2.cmml">​</mo><mrow id="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1.1.1" xref="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1.1.1.2" xref="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1.1.1.1" xref="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1.1.1.1.cmml"><mo id="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1.1.1.1a" xref="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1.1.1.1.cmml">±</mo><mn id="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1.1.1.1.2" xref="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1.1.1.1.2.cmml">0.043</mn></mrow><mo stretchy="false" id="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1.1.1.3" xref="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.7.7.7.7.7.7.7.7.1.m1.1b"><apply id="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1.cmml" xref="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1"><times id="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1.2.cmml" xref="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1.2"></times><cn type="float" id="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1.3.cmml" xref="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1.3">0.943</cn><apply id="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1.1.1.1.cmml" xref="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1.1.1"><csymbol cd="latexml" id="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1.1.1.1.1.cmml" xref="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1.1.1.1.2.cmml" xref="S5.T2.7.7.7.7.7.7.7.7.1.m1.1.1.1.1.1.2">0.043</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.7.7.7.7.7.7.7.7.1.m1.1c">0.943\ (\pm 0.043)</annotation></semantics></math></span>
<span id="S5.T2.8.8.8.8.8.8.8.8.2" class="ltx_td ltx_align_center"><math id="S5.T2.8.8.8.8.8.8.8.8.2.m1.1" class="ltx_Math" alttext="33.24\ (\pm 4.82)" display="inline"><semantics id="S5.T2.8.8.8.8.8.8.8.8.2.m1.1a"><mrow id="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1" xref="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1.cmml"><mn id="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1.3" xref="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1.3.cmml">33.24</mn><mo lspace="0.500em" rspace="0em" id="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1.2" xref="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1.2.cmml">​</mo><mrow id="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1.1.1" xref="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1.1.1.2" xref="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1.1.1.1" xref="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1.1.1.1.cmml"><mo id="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1.1.1.1a" xref="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1.1.1.1.cmml">±</mo><mn id="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1.1.1.1.2" xref="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1.1.1.1.2.cmml">4.82</mn></mrow><mo stretchy="false" id="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1.1.1.3" xref="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.8.8.8.8.8.8.8.8.2.m1.1b"><apply id="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1.cmml" xref="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1"><times id="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1.2.cmml" xref="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1.2"></times><cn type="float" id="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1.3.cmml" xref="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1.3">33.24</cn><apply id="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1.1.1.1.cmml" xref="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1.1.1"><csymbol cd="latexml" id="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1.1.1.1.1.cmml" xref="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1.1.1.1.2.cmml" xref="S5.T2.8.8.8.8.8.8.8.8.2.m1.1.1.1.1.1.2">4.82</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.8.8.8.8.8.8.8.8.2.m1.1c">33.24\ (\pm 4.82)</annotation></semantics></math></span>
<span id="S5.T2.9.9.9.9.9.9.9.9.3" class="ltx_td ltx_align_center"><math id="S5.T2.9.9.9.9.9.9.9.9.3.m1.1" class="ltx_Math" alttext="0.732\ (\pm 0.081)" display="inline"><semantics id="S5.T2.9.9.9.9.9.9.9.9.3.m1.1a"><mrow id="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1" xref="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1.cmml"><mn id="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1.3" xref="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1.3.cmml">0.732</mn><mo lspace="0.500em" rspace="0em" id="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1.2" xref="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1.2.cmml">​</mo><mrow id="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1.1.1" xref="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1.1.1.2" xref="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1.1.1.1" xref="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1.1.1.1.cmml"><mo id="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1.1.1.1a" xref="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1.1.1.1.cmml">±</mo><mn id="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1.1.1.1.2" xref="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1.1.1.1.2.cmml">0.081</mn></mrow><mo stretchy="false" id="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1.1.1.3" xref="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.9.9.9.9.9.9.9.9.3.m1.1b"><apply id="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1.cmml" xref="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1"><times id="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1.2.cmml" xref="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1.2"></times><cn type="float" id="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1.3.cmml" xref="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1.3">0.732</cn><apply id="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1.1.1.1.cmml" xref="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1.1.1"><csymbol cd="latexml" id="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1.1.1.1.1.cmml" xref="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1.1.1.1.2.cmml" xref="S5.T2.9.9.9.9.9.9.9.9.3.m1.1.1.1.1.1.2">0.081</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.9.9.9.9.9.9.9.9.3.m1.1c">0.732\ (\pm 0.081)</annotation></semantics></math></span>
<span id="S5.T2.10.10.10.10.10.10.10.10.4" class="ltx_td ltx_align_center"><math id="S5.T2.10.10.10.10.10.10.10.10.4.m1.1" class="ltx_Math" alttext="0.978\ (\pm 0.021)" display="inline"><semantics id="S5.T2.10.10.10.10.10.10.10.10.4.m1.1a"><mrow id="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1" xref="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1.cmml"><mn id="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1.3" xref="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1.3.cmml">0.978</mn><mo lspace="0.500em" rspace="0em" id="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1.2" xref="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1.2.cmml">​</mo><mrow id="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1.1.1" xref="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1.1.1.2" xref="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1.1.1.1" xref="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1.1.1.1.cmml"><mo id="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1.1.1.1a" xref="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1.1.1.1.cmml">±</mo><mn id="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1.1.1.1.2" xref="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1.1.1.1.2.cmml">0.021</mn></mrow><mo stretchy="false" id="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1.1.1.3" xref="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.10.10.10.10.10.10.10.10.4.m1.1b"><apply id="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1.cmml" xref="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1"><times id="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1.2.cmml" xref="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1.2"></times><cn type="float" id="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1.3.cmml" xref="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1.3">0.978</cn><apply id="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1.1.1.1.cmml" xref="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1.1.1"><csymbol cd="latexml" id="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1.1.1.1.1.cmml" xref="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1.1.1.1.2.cmml" xref="S5.T2.10.10.10.10.10.10.10.10.4.m1.1.1.1.1.1.2">0.021</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.10.10.10.10.10.10.10.10.4.m1.1c">0.978\ (\pm 0.021)</annotation></semantics></math></span>
<span id="S5.T2.11.11.11.11.11.11.11.11.5" class="ltx_td ltx_align_center"><math id="S5.T2.11.11.11.11.11.11.11.11.5.m1.1" class="ltx_Math" alttext="37.66\ (\pm 5.39)" display="inline"><semantics id="S5.T2.11.11.11.11.11.11.11.11.5.m1.1a"><mrow id="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1" xref="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1.cmml"><mn id="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1.3" xref="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1.3.cmml">37.66</mn><mo lspace="0.500em" rspace="0em" id="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1.2" xref="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1.2.cmml">​</mo><mrow id="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1.1.1" xref="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1.1.1.2" xref="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1.1.1.1" xref="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1.1.1.1.cmml"><mo id="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1.1.1.1a" xref="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1.1.1.1.cmml">±</mo><mn id="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1.1.1.1.2" xref="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1.1.1.1.2.cmml">5.39</mn></mrow><mo stretchy="false" id="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1.1.1.3" xref="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.11.11.11.11.11.11.11.11.5.m1.1b"><apply id="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1.cmml" xref="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1"><times id="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1.2.cmml" xref="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1.2"></times><cn type="float" id="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1.3.cmml" xref="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1.3">37.66</cn><apply id="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1.1.1.1.cmml" xref="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1.1.1"><csymbol cd="latexml" id="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1.1.1.1.1.cmml" xref="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1.1.1.1.2.cmml" xref="S5.T2.11.11.11.11.11.11.11.11.5.m1.1.1.1.1.1.2">5.39</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.11.11.11.11.11.11.11.11.5.m1.1c">37.66\ (\pm 5.39)</annotation></semantics></math></span>
<span id="S5.T2.12.12.12.12.12.12.12.12.6" class="ltx_td ltx_nopad_r ltx_align_center"><math id="S5.T2.12.12.12.12.12.12.12.12.6.m1.1" class="ltx_Math" alttext="0.779\ (\pm 0.087)" display="inline"><semantics id="S5.T2.12.12.12.12.12.12.12.12.6.m1.1a"><mrow id="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1" xref="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1.cmml"><mn id="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1.3" xref="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1.3.cmml">0.779</mn><mo lspace="0.500em" rspace="0em" id="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1.2" xref="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1.2.cmml">​</mo><mrow id="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1.1.1" xref="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1.1.1.2" xref="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1.1.1.1" xref="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1.1.1.1.cmml"><mo id="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1.1.1.1a" xref="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1.1.1.1.cmml">±</mo><mn id="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1.1.1.1.2" xref="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1.1.1.1.2.cmml">0.087</mn></mrow><mo stretchy="false" id="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1.1.1.3" xref="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.12.12.12.12.12.12.12.12.6.m1.1b"><apply id="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1.cmml" xref="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1"><times id="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1.2.cmml" xref="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1.2"></times><cn type="float" id="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1.3.cmml" xref="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1.3">0.779</cn><apply id="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1.1.1.1.cmml" xref="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1.1.1"><csymbol cd="latexml" id="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1.1.1.1.1.cmml" xref="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1.1.1.1.2.cmml" xref="S5.T2.12.12.12.12.12.12.12.12.6.m1.1.1.1.1.1.2">0.087</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.12.12.12.12.12.12.12.12.6.m1.1c">0.779\ (\pm 0.087)</annotation></semantics></math></span></span>
<span id="S5.T2.18.18.18.18.18.18.18.18" class="ltx_tr">
<span id="S5.T2.18.18.18.18.18.18.18.18.7" class="ltx_td ltx_align_left ltx_border_bb">TRNet</span>
<span id="S5.T2.13.13.13.13.13.13.13.13.1" class="ltx_td ltx_align_center ltx_border_bb"><math id="S5.T2.13.13.13.13.13.13.13.13.1.m1.1" class="ltx_Math" alttext="0.967\ (\pm 0.034)" display="inline"><semantics id="S5.T2.13.13.13.13.13.13.13.13.1.m1.1a"><mrow id="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1" xref="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1.cmml"><mn id="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1.3" xref="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1.3.cmml">0.967</mn><mo lspace="0.500em" rspace="0em" id="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1.2" xref="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1.2.cmml">​</mo><mrow id="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1.1.1" xref="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1.1.1.2" xref="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1.1.1.1" xref="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1.1.1.1.cmml"><mo id="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1.1.1.1a" xref="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1.1.1.1.cmml">±</mo><mn id="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1.1.1.1.2" xref="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1.1.1.1.2.cmml">0.034</mn></mrow><mo stretchy="false" id="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1.1.1.3" xref="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.13.13.13.13.13.13.13.13.1.m1.1b"><apply id="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1.cmml" xref="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1"><times id="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1.2.cmml" xref="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1.2"></times><cn type="float" id="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1.3.cmml" xref="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1.3">0.967</cn><apply id="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1.1.1.1.cmml" xref="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1.1.1"><csymbol cd="latexml" id="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1.1.1.1.1.cmml" xref="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1.1.1.1.2.cmml" xref="S5.T2.13.13.13.13.13.13.13.13.1.m1.1.1.1.1.1.2">0.034</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.13.13.13.13.13.13.13.13.1.m1.1c">0.967\ (\pm 0.034)</annotation></semantics></math></span>
<span id="S5.T2.14.14.14.14.14.14.14.14.2" class="ltx_td ltx_align_center ltx_border_bb"><math id="S5.T2.14.14.14.14.14.14.14.14.2.m1.1" class="ltx_Math" alttext="36.22\ (\pm 6.00)" display="inline"><semantics id="S5.T2.14.14.14.14.14.14.14.14.2.m1.1a"><mrow id="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1" xref="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1.cmml"><mn id="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1.3" xref="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1.3.cmml">36.22</mn><mo lspace="0.500em" rspace="0em" id="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1.2" xref="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1.2.cmml">​</mo><mrow id="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1.1.1" xref="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1.1.1.2" xref="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1.1.1.1" xref="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1.1.1.1.cmml"><mo id="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1.1.1.1a" xref="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1.1.1.1.cmml">±</mo><mn id="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1.1.1.1.2" xref="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1.1.1.1.2.cmml">6.00</mn></mrow><mo stretchy="false" id="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1.1.1.3" xref="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.14.14.14.14.14.14.14.14.2.m1.1b"><apply id="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1.cmml" xref="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1"><times id="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1.2.cmml" xref="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1.2"></times><cn type="float" id="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1.3.cmml" xref="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1.3">36.22</cn><apply id="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1.1.1.1.cmml" xref="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1.1.1"><csymbol cd="latexml" id="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1.1.1.1.1.cmml" xref="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1.1.1.1.2.cmml" xref="S5.T2.14.14.14.14.14.14.14.14.2.m1.1.1.1.1.1.2">6.00</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.14.14.14.14.14.14.14.14.2.m1.1c">36.22\ (\pm 6.00)</annotation></semantics></math></span>
<span id="S5.T2.15.15.15.15.15.15.15.15.3" class="ltx_td ltx_align_center ltx_border_bb"><math id="S5.T2.15.15.15.15.15.15.15.15.3.m1.1" class="ltx_Math" alttext="0.883\ (\pm 0.079)" display="inline"><semantics id="S5.T2.15.15.15.15.15.15.15.15.3.m1.1a"><mrow id="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1" xref="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1.cmml"><mn id="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1.3" xref="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1.3.cmml">0.883</mn><mo lspace="0.500em" rspace="0em" id="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1.2" xref="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1.2.cmml">​</mo><mrow id="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1.1.1" xref="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1.1.1.2" xref="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1.1.1.1" xref="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1.1.1.1.cmml"><mo id="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1.1.1.1a" xref="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1.1.1.1.cmml">±</mo><mn id="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1.1.1.1.2" xref="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1.1.1.1.2.cmml">0.079</mn></mrow><mo stretchy="false" id="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1.1.1.3" xref="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.15.15.15.15.15.15.15.15.3.m1.1b"><apply id="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1.cmml" xref="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1"><times id="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1.2.cmml" xref="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1.2"></times><cn type="float" id="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1.3.cmml" xref="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1.3">0.883</cn><apply id="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1.1.1.1.cmml" xref="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1.1.1"><csymbol cd="latexml" id="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1.1.1.1.1.cmml" xref="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1.1.1.1.2.cmml" xref="S5.T2.15.15.15.15.15.15.15.15.3.m1.1.1.1.1.1.2">0.079</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.15.15.15.15.15.15.15.15.3.m1.1c">0.883\ (\pm 0.079)</annotation></semantics></math></span>
<span id="S5.T2.16.16.16.16.16.16.16.16.4" class="ltx_td ltx_align_center ltx_border_bb"><math id="S5.T2.16.16.16.16.16.16.16.16.4.m1.1" class="ltx_Math" alttext="0.987\ (\pm 0.015)" display="inline"><semantics id="S5.T2.16.16.16.16.16.16.16.16.4.m1.1a"><mrow id="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1" xref="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1.cmml"><mn id="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1.3" xref="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1.3.cmml">0.987</mn><mo lspace="0.500em" rspace="0em" id="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1.2" xref="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1.2.cmml">​</mo><mrow id="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1.1.1" xref="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1.1.1.2" xref="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1.1.1.1" xref="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1.1.1.1.cmml"><mo id="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1.1.1.1a" xref="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1.1.1.1.cmml">±</mo><mn id="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1.1.1.1.2" xref="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1.1.1.1.2.cmml">0.015</mn></mrow><mo stretchy="false" id="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1.1.1.3" xref="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.16.16.16.16.16.16.16.16.4.m1.1b"><apply id="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1.cmml" xref="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1"><times id="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1.2.cmml" xref="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1.2"></times><cn type="float" id="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1.3.cmml" xref="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1.3">0.987</cn><apply id="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1.1.1.1.cmml" xref="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1.1.1"><csymbol cd="latexml" id="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1.1.1.1.1.cmml" xref="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1.1.1.1.2.cmml" xref="S5.T2.16.16.16.16.16.16.16.16.4.m1.1.1.1.1.1.2">0.015</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.16.16.16.16.16.16.16.16.4.m1.1c">0.987\ (\pm 0.015)</annotation></semantics></math></span>
<span id="S5.T2.17.17.17.17.17.17.17.17.5" class="ltx_td ltx_align_center ltx_border_bb"><math id="S5.T2.17.17.17.17.17.17.17.17.5.m1.1" class="ltx_Math" alttext="42.34\ (\pm 6.74)" display="inline"><semantics id="S5.T2.17.17.17.17.17.17.17.17.5.m1.1a"><mrow id="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1" xref="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1.cmml"><mn id="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1.3" xref="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1.3.cmml">42.34</mn><mo lspace="0.500em" rspace="0em" id="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1.2" xref="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1.2.cmml">​</mo><mrow id="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1.1.1" xref="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1.1.1.2" xref="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1.1.1.1" xref="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1.1.1.1.cmml"><mo id="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1.1.1.1a" xref="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1.1.1.1.cmml">±</mo><mn id="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1.1.1.1.2" xref="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1.1.1.1.2.cmml">6.74</mn></mrow><mo stretchy="false" id="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1.1.1.3" xref="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.17.17.17.17.17.17.17.17.5.m1.1b"><apply id="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1.cmml" xref="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1"><times id="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1.2.cmml" xref="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1.2"></times><cn type="float" id="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1.3.cmml" xref="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1.3">42.34</cn><apply id="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1.1.1.1.cmml" xref="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1.1.1"><csymbol cd="latexml" id="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1.1.1.1.1.cmml" xref="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1.1.1.1.2.cmml" xref="S5.T2.17.17.17.17.17.17.17.17.5.m1.1.1.1.1.1.2">6.74</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.17.17.17.17.17.17.17.17.5.m1.1c">42.34\ (\pm 6.74)</annotation></semantics></math></span>
<span id="S5.T2.18.18.18.18.18.18.18.18.6" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb"><math id="S5.T2.18.18.18.18.18.18.18.18.6.m1.1" class="ltx_Math" alttext="0.891\ (\pm 0.083)" display="inline"><semantics id="S5.T2.18.18.18.18.18.18.18.18.6.m1.1a"><mrow id="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1" xref="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1.cmml"><mn id="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1.3" xref="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1.3.cmml">0.891</mn><mo lspace="0.500em" rspace="0em" id="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1.2" xref="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1.2.cmml">​</mo><mrow id="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1.1.1" xref="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1.1.1.2" xref="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1.1.1.1" xref="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1.1.1.1.cmml"><mo id="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1.1.1.1a" xref="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1.1.1.1.cmml">±</mo><mn id="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1.1.1.1.2" xref="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1.1.1.1.2.cmml">0.083</mn></mrow><mo stretchy="false" id="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1.1.1.3" xref="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.18.18.18.18.18.18.18.18.6.m1.1b"><apply id="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1.cmml" xref="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1"><times id="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1.2.cmml" xref="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1.2"></times><cn type="float" id="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1.3.cmml" xref="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1.3">0.891</cn><apply id="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1.1.1.1.cmml" xref="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1.1.1"><csymbol cd="latexml" id="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1.1.1.1.1.cmml" xref="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1.1.1.1.2.cmml" xref="S5.T2.18.18.18.18.18.18.18.18.6.m1.1.1.1.1.1.2">0.083</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.18.18.18.18.18.18.18.18.6.m1.1c">0.891\ (\pm 0.083)</annotation></semantics></math></span></span>
</span></span></span>
</span></span></span></p>
</span></div>
</figure>
<div id="S5.SS3.p3" class="ltx_para">
<p id="S5.SS3.p3.1" class="ltx_p">While the tattoo removal performs well in many scenarios, there are also some extreme cases where it does not work so well. Examples of removing large coverage of tattoos from facial images are shown in Fig. <a href="#S5.F15" title="Figure 15 ‣ V-C Removal Quality Results ‣ V Tattoo Removal ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">15</span></a>. Depicted example images clearly show the limitations of the presented approach.</p>
</div>
<figure id="S5.F15" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F15.2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2202.05297/assets/graphics/extreme_examples/397_extreme_bp.jpg" id="S5.F15.1.g1" class="ltx_graphics ltx_figure_panel ltx_img_square" width="287" height="287" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2202.05297/assets/graphics/extreme_examples/397_extreme_mp.jpg" id="S5.F15.2.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" width="287" height="287" alt="Refer to caption"></div>
</div>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F15.4" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2202.05297/assets/graphics/extreme_examples/418_extreme_bp.jpg" id="S5.F15.3.g1" class="ltx_graphics ltx_figure_panel ltx_img_square" width="287" height="287" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2202.05297/assets/graphics/extreme_examples/418_extreme_mp.jpg" id="S5.F15.4.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" width="287" height="287" alt="Refer to caption"></div>
</div>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F15.6" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2202.05297/assets/graphics/extreme_examples/486_extreme_bp.jpg" id="S5.F15.5.g1" class="ltx_graphics ltx_figure_panel ltx_img_square" width="287" height="287" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2202.05297/assets/graphics/extreme_examples/486_extreme_mp.jpg" id="S5.F15.6.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" width="287" height="287" alt="Refer to caption"></div>
</div>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F15.8" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2202.05297/assets/graphics/extreme_examples/95_extreme_bp.jpg" id="S5.F15.7.g1" class="ltx_graphics ltx_figure_panel ltx_img_square" width="287" height="287" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2202.05297/assets/graphics/extreme_examples/95_extreme_mp.jpg" id="S5.F15.8.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" width="287" height="287" alt="Refer to caption"></div>
</div>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F15.10.1.1" class="ltx_text" style="font-size:90%;">Figure 15</span>: </span><span id="S5.F15.11.2" class="ltx_text" style="font-size:90%;">Facial images with extreme coverage of tattoos, which remain challenging for our tattoo removal approach. Before (left) and after (right) tattoo removal. </span></figcaption>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Application to Face Recognition</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this section, we describe how tattoo removal can be integrated and used in a face recognition system. A face recognition system consists of several preprocessing modules such as face alignment and quality estimation. These modules help to minimise factors which are unimportant for face recognition and ensure that only images of sufficient quality are used during authentication. As part of the preprocessing, we propose to use the deep learning-based removal algorithms described in Sect. <a href="#S5" title="V Tattoo Removal ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a>. While facial tattoos can be seen as distinctive and helpful in identifying individuals, tattoo removal is useful for face recognition in cases where only one of the face images in a comparison contains tattoos <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. In our experiments, we trained the classifiers to remove facial tattoos from aligned images and as such will assume that our input images have already been aligned since our focus is on improving feature extraction and comparison. Note that the proposed tattoo removal method could also be retrained on unaligned images and placed before the detection module to improve detection accuracy.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS1.4.1.1" class="ltx_text">VI-A</span> </span><span id="S6.SS1.5.2" class="ltx_text ltx_font_italic">Experimental Setup</span>
</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">In the following, we describe the database, the employed face recognition system, and metrics used to evaluate the biometric performance:</p>
</div>
<div id="S6.SS1.p2" class="ltx_para">
<dl id="S6.I1" class="ltx_description">
<dt id="S6.I1.ix1" class="ltx_item"><span class="ltx_tag ltx_tag_item"><span id="S6.I1.ix1.1.1.1" class="ltx_text ltx_font_bold">Database</span></span></dt>
<dd class="ltx_item">
<div id="S6.I1.ix1.p1" class="ltx_para">
<p id="S6.I1.ix1.p1.1" class="ltx_p">for the evaluation, we use the publicly available database <span id="S6.I1.ix1.p1.1.1" class="ltx_text ltx_font_italic">HDA Facial Tattoo and Painting Database<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note"><span id="footnote3.1.1.1" class="ltx_text ltx_font_upright">3</span></span><span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_font_upright ltx_ref_self">https://dasec.h-da.de/research/biometrics/hda-facial-tattoo-and-painting-database</span></span></span></span></span>, which consists of 250 image pairs of individuals with and without real facial tattoos. The database was originally collected by Ibsen <span id="S6.I1.ix1.p1.1.2" class="ltx_text ltx_font_italic">et al.</span> in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. The images have all been aligned using the RetinaFace facial detector <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>. Examples of original image-pairs (before tattoo removal) are given in Fig. <a href="#S6.F16" title="Figure 16 ‣ item Database ‣ VI-A Experimental Setup ‣ VI Application to Face Recognition ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">16</span></a>. These pairs of images are used for evaluating the performance of a face recognition system. For evaluating the effect of tattoo removal, the models described in Sect. <a href="#S5.SS1" title="V-A Models ‣ V Tattoo Removal ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-A</span></span></a> are employed on the facial images containing tattoos, whereafter the resulting images are used during the evaluation.</p>
</div>
<figure id="S6.F16" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F16.2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2202.05297/assets/graphics/127_2.jpg" id="S6.F16.1.g1" class="ltx_graphics ltx_figure_panel ltx_img_square" width="287" height="287" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2202.05297/assets/graphics/127_1.jpg" id="S6.F16.2.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" width="287" height="287" alt="Refer to caption"></div>
</div>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F16.4" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2202.05297/assets/graphics/108_2.jpg" id="S6.F16.3.g1" class="ltx_graphics ltx_figure_panel ltx_img_square" width="287" height="287" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2202.05297/assets/graphics/108_1.jpg" id="S6.F16.4.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" width="287" height="287" alt="Refer to caption"></div>
</div>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F16.6.1.1" class="ltx_text" style="font-size:90%;">Figure 16</span>: </span><span id="S6.F16.7.2" class="ltx_text" style="font-size:90%;">Examples of image-pairs in the HDA facial tattoo and painting database.</span></figcaption>
</figure>
</dd>
</dl>
</div>
<div id="S6.SS1.p3" class="ltx_para">
<dl id="S6.I2" class="ltx_description">
<dt id="S6.I2.ix1" class="ltx_item"><span class="ltx_tag ltx_tag_item"><span id="S6.I2.ix1.1.1.1" class="ltx_text ltx_font_bold">Face recognition system</span></span></dt>
<dd class="ltx_item">
<div id="S6.I2.ix1.p1" class="ltx_para">
<p id="S6.I2.ix1.p1.1" class="ltx_p">to evaluate the applicability of tattoo removal for face recognition, we use the established ArcFace pre-trained model (LResNet100E-IR,ArcFace@ms1m-refine-v2) with the RetinaFace facial detector.</p>
</div>
</dd>
</dl>
</div>
<div id="S6.SS1.p4" class="ltx_para">
<dl id="S6.I3" class="ltx_description">
<dt id="S6.I3.ix1" class="ltx_item"><span class="ltx_tag ltx_tag_item"><span id="S6.I3.ix1.1.1.1" class="ltx_text ltx_font_bold">Recognition performance metrics</span></span></dt>
<dd class="ltx_item">
<div id="S6.I3.ix1.p1" class="ltx_para">
<p id="S6.I3.ix1.p1.2" class="ltx_p">the effect of removing facial tattoos is evaluated empirically <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>. Specifically, we measure the FNMR at operationally relevant thresholds corresponding to a FMR of <math id="S6.I3.ix1.p1.1.m1.1" class="ltx_Math" alttext="0.1\%" display="inline"><semantics id="S6.I3.ix1.p1.1.m1.1a"><mrow id="S6.I3.ix1.p1.1.m1.1.1" xref="S6.I3.ix1.p1.1.m1.1.1.cmml"><mn id="S6.I3.ix1.p1.1.m1.1.1.2" xref="S6.I3.ix1.p1.1.m1.1.1.2.cmml">0.1</mn><mo id="S6.I3.ix1.p1.1.m1.1.1.1" xref="S6.I3.ix1.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.I3.ix1.p1.1.m1.1b"><apply id="S6.I3.ix1.p1.1.m1.1.1.cmml" xref="S6.I3.ix1.p1.1.m1.1.1"><csymbol cd="latexml" id="S6.I3.ix1.p1.1.m1.1.1.1.cmml" xref="S6.I3.ix1.p1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S6.I3.ix1.p1.1.m1.1.1.2.cmml" xref="S6.I3.ix1.p1.1.m1.1.1.2">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.I3.ix1.p1.1.m1.1c">0.1\%</annotation></semantics></math> and <math id="S6.I3.ix1.p1.2.m2.1" class="ltx_Math" alttext="1\%" display="inline"><semantics id="S6.I3.ix1.p1.2.m2.1a"><mrow id="S6.I3.ix1.p1.2.m2.1.1" xref="S6.I3.ix1.p1.2.m2.1.1.cmml"><mn id="S6.I3.ix1.p1.2.m2.1.1.2" xref="S6.I3.ix1.p1.2.m2.1.1.2.cmml">1</mn><mo id="S6.I3.ix1.p1.2.m2.1.1.1" xref="S6.I3.ix1.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.I3.ix1.p1.2.m2.1b"><apply id="S6.I3.ix1.p1.2.m2.1.1.cmml" xref="S6.I3.ix1.p1.2.m2.1.1"><csymbol cd="latexml" id="S6.I3.ix1.p1.2.m2.1.1.1.cmml" xref="S6.I3.ix1.p1.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S6.I3.ix1.p1.2.m2.1.1.2.cmml" xref="S6.I3.ix1.p1.2.m2.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.I3.ix1.p1.2.m2.1c">1\%</annotation></semantics></math>:</p>
</div>
<div id="S6.I3.ix1.p2" class="ltx_para">
<ul id="S6.I3.ix1.I1" class="ltx_itemize">
<li id="S6.I3.ix1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S6.I3.ix1.I1.i1.1.1.1" class="ltx_text ltx_font_bold">•</span></span> 
<div id="S6.I3.ix1.I1.i1.p1" class="ltx_para">
<p id="S6.I3.ix1.I1.i1.p1.1" class="ltx_p"><span id="S6.I3.ix1.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">False Match Rate (FMR)</span>: the proportion of the completed biometric non-mated comparison trials that result in a false match.</p>
</div>
</li>
<li id="S6.I3.ix1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S6.I3.ix1.I1.i2.1.1.1" class="ltx_text ltx_font_bold">•</span></span> 
<div id="S6.I3.ix1.I1.i2.p1" class="ltx_para">
<p id="S6.I3.ix1.I1.i2.p1.1" class="ltx_p"><span id="S6.I3.ix1.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">False Non-Match Rate (FNMR)</span>: the proportion of the completed biometric mated comparison trials that result in a false non-match.</p>
</div>
</li>
</ul>
</div>
<div id="S6.I3.ix1.p3" class="ltx_para">
<p id="S6.I3.ix1.p3.1" class="ltx_p">Additionally, we report the Equal Error Rate (EER), <span id="S6.I3.ix1.p3.1.1" class="ltx_text ltx_font_italic">i.e.</span> the point where FNMR and FMR are equal. To show the distribution of comparison scores, boxplots are used. The comparison scores are computed between pairs of feature vectors using the Euclidean distance.</p>
</div>
</dd>
</dl>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS2.4.1.1" class="ltx_text">VI-B</span> </span><span id="S6.SS2.5.2" class="ltx_text ltx_font_italic">Experimental Results</span>
</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">The effect of removing tattoos on the computed comparison scores is visualised in Fig. <a href="#S6.F17" title="Figure 17 ‣ VI-B Experimental Results ‣ VI Application to Face Recognition ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">17</span></a>. As can be seen, the comparison scores are not significantly affected for the pix2pix model which only showed moderate capabilities of removing tattoos from facial images. However, for TRNet, which has been trained on the synthetic database, it is shown that the dissimilarity score on average gets lower, which indicates that the recognition performance might improve.</p>
</div>
<figure id="S6.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S6.T3.13.1.1" class="ltx_text" style="font-size:90%;">TABLE III</span>: </span><span id="S6.T3.14.2" class="ltx_text" style="font-size:90%;">Biometric performance results for ArcFace.</span></figcaption>
<table id="S6.T3.11" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S6.T3.11.12" class="ltx_tr">
<td id="S6.T3.11.12.1" class="ltx_td ltx_align_left ltx_border_tt" rowspan="2"><span id="S6.T3.11.12.1.1" class="ltx_text ltx_font_bold">Type</span></td>
<td id="S6.T3.11.12.2" class="ltx_td ltx_align_right ltx_border_tt" rowspan="2"><span id="S6.T3.11.12.2.1" class="ltx_text ltx_font_bold">EER%</span></td>
<td id="S6.T3.11.12.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S6.T3.11.12.3.1" class="ltx_text ltx_font_bold">FNMR%</span></td>
</tr>
<tr id="S6.T3.2.2" class="ltx_tr">
<td id="S6.T3.1.1.1" class="ltx_td ltx_align_right ltx_border_t"><span id="S6.T3.1.1.1.1" class="ltx_text ltx_font_bold">FMR<math id="S6.T3.1.1.1.1.m1.1" class="ltx_Math" alttext="=" display="inline"><semantics id="S6.T3.1.1.1.1.m1.1a"><mo id="S6.T3.1.1.1.1.m1.1.1" xref="S6.T3.1.1.1.1.m1.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S6.T3.1.1.1.1.m1.1b"><eq id="S6.T3.1.1.1.1.m1.1.1.cmml" xref="S6.T3.1.1.1.1.m1.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.1.1.1.1.m1.1c">=</annotation></semantics></math>0.1%</span></td>
<td id="S6.T3.2.2.2" class="ltx_td ltx_align_right ltx_border_t"><span id="S6.T3.2.2.2.1" class="ltx_text ltx_font_bold">FMR<math id="S6.T3.2.2.2.1.m1.1" class="ltx_Math" alttext="=" display="inline"><semantics id="S6.T3.2.2.2.1.m1.1a"><mo id="S6.T3.2.2.2.1.m1.1.1" xref="S6.T3.2.2.2.1.m1.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S6.T3.2.2.2.1.m1.1b"><eq id="S6.T3.2.2.2.1.m1.1.1.cmml" xref="S6.T3.2.2.2.1.m1.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.2.2.2.1.m1.1c">=</annotation></semantics></math>1%</span></td>
</tr>
<tr id="S6.T3.5.5" class="ltx_tr">
<td id="S6.T3.5.5.4" class="ltx_td ltx_align_left ltx_border_t">Tattooed</td>
<td id="S6.T3.3.3.1" class="ltx_td ltx_align_right ltx_border_t"><math id="S6.T3.3.3.1.m1.1" class="ltx_Math" alttext="0.80" display="inline"><semantics id="S6.T3.3.3.1.m1.1a"><mn id="S6.T3.3.3.1.m1.1.1" xref="S6.T3.3.3.1.m1.1.1.cmml">0.80</mn><annotation-xml encoding="MathML-Content" id="S6.T3.3.3.1.m1.1b"><cn type="float" id="S6.T3.3.3.1.m1.1.1.cmml" xref="S6.T3.3.3.1.m1.1.1">0.80</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.3.3.1.m1.1c">0.80</annotation></semantics></math></td>
<td id="S6.T3.4.4.2" class="ltx_td ltx_align_right ltx_border_t"><math id="S6.T3.4.4.2.m1.1" class="ltx_Math" alttext="1.20" display="inline"><semantics id="S6.T3.4.4.2.m1.1a"><mn id="S6.T3.4.4.2.m1.1.1" xref="S6.T3.4.4.2.m1.1.1.cmml">1.20</mn><annotation-xml encoding="MathML-Content" id="S6.T3.4.4.2.m1.1b"><cn type="float" id="S6.T3.4.4.2.m1.1.1.cmml" xref="S6.T3.4.4.2.m1.1.1">1.20</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.4.4.2.m1.1c">1.20</annotation></semantics></math></td>
<td id="S6.T3.5.5.3" class="ltx_td ltx_align_right ltx_border_t"><math id="S6.T3.5.5.3.m1.1" class="ltx_Math" alttext="0.80" display="inline"><semantics id="S6.T3.5.5.3.m1.1a"><mn id="S6.T3.5.5.3.m1.1.1" xref="S6.T3.5.5.3.m1.1.1.cmml">0.80</mn><annotation-xml encoding="MathML-Content" id="S6.T3.5.5.3.m1.1b"><cn type="float" id="S6.T3.5.5.3.m1.1.1.cmml" xref="S6.T3.5.5.3.m1.1.1">0.80</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.5.5.3.m1.1c">0.80</annotation></semantics></math></td>
</tr>
<tr id="S6.T3.8.8" class="ltx_tr">
<td id="S6.T3.8.8.4" class="ltx_td ltx_align_left">pix2pix</td>
<td id="S6.T3.6.6.1" class="ltx_td ltx_align_right"><math id="S6.T3.6.6.1.m1.1" class="ltx_Math" alttext="0.80" display="inline"><semantics id="S6.T3.6.6.1.m1.1a"><mn id="S6.T3.6.6.1.m1.1.1" xref="S6.T3.6.6.1.m1.1.1.cmml">0.80</mn><annotation-xml encoding="MathML-Content" id="S6.T3.6.6.1.m1.1b"><cn type="float" id="S6.T3.6.6.1.m1.1.1.cmml" xref="S6.T3.6.6.1.m1.1.1">0.80</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.6.6.1.m1.1c">0.80</annotation></semantics></math></td>
<td id="S6.T3.7.7.2" class="ltx_td ltx_align_right"><math id="S6.T3.7.7.2.m1.1" class="ltx_Math" alttext="1.60" display="inline"><semantics id="S6.T3.7.7.2.m1.1a"><mn id="S6.T3.7.7.2.m1.1.1" xref="S6.T3.7.7.2.m1.1.1.cmml">1.60</mn><annotation-xml encoding="MathML-Content" id="S6.T3.7.7.2.m1.1b"><cn type="float" id="S6.T3.7.7.2.m1.1.1.cmml" xref="S6.T3.7.7.2.m1.1.1">1.60</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.7.7.2.m1.1c">1.60</annotation></semantics></math></td>
<td id="S6.T3.8.8.3" class="ltx_td ltx_align_right"><math id="S6.T3.8.8.3.m1.1" class="ltx_Math" alttext="0.80" display="inline"><semantics id="S6.T3.8.8.3.m1.1a"><mn id="S6.T3.8.8.3.m1.1.1" xref="S6.T3.8.8.3.m1.1.1.cmml">0.80</mn><annotation-xml encoding="MathML-Content" id="S6.T3.8.8.3.m1.1b"><cn type="float" id="S6.T3.8.8.3.m1.1.1.cmml" xref="S6.T3.8.8.3.m1.1.1">0.80</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.8.8.3.m1.1c">0.80</annotation></semantics></math></td>
</tr>
<tr id="S6.T3.11.11" class="ltx_tr">
<td id="S6.T3.11.11.4" class="ltx_td ltx_align_left ltx_border_bb">TRNet</td>
<td id="S6.T3.9.9.1" class="ltx_td ltx_align_right ltx_border_bb"><math id="S6.T3.9.9.1.m1.1" class="ltx_Math" alttext="0.40" display="inline"><semantics id="S6.T3.9.9.1.m1.1a"><mn id="S6.T3.9.9.1.m1.1.1" xref="S6.T3.9.9.1.m1.1.1.cmml">0.40</mn><annotation-xml encoding="MathML-Content" id="S6.T3.9.9.1.m1.1b"><cn type="float" id="S6.T3.9.9.1.m1.1.1.cmml" xref="S6.T3.9.9.1.m1.1.1">0.40</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.9.9.1.m1.1c">0.40</annotation></semantics></math></td>
<td id="S6.T3.10.10.2" class="ltx_td ltx_align_right ltx_border_bb"><math id="S6.T3.10.10.2.m1.1" class="ltx_Math" alttext="1.20" display="inline"><semantics id="S6.T3.10.10.2.m1.1a"><mn id="S6.T3.10.10.2.m1.1.1" xref="S6.T3.10.10.2.m1.1.1.cmml">1.20</mn><annotation-xml encoding="MathML-Content" id="S6.T3.10.10.2.m1.1b"><cn type="float" id="S6.T3.10.10.2.m1.1.1.cmml" xref="S6.T3.10.10.2.m1.1.1">1.20</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.10.10.2.m1.1c">1.20</annotation></semantics></math></td>
<td id="S6.T3.11.11.3" class="ltx_td ltx_align_right ltx_border_bb"><math id="S6.T3.11.11.3.m1.1" class="ltx_Math" alttext="0.00" display="inline"><semantics id="S6.T3.11.11.3.m1.1a"><mn id="S6.T3.11.11.3.m1.1.1" xref="S6.T3.11.11.3.m1.1.1.cmml">0.00</mn><annotation-xml encoding="MathML-Content" id="S6.T3.11.11.3.m1.1b"><cn type="float" id="S6.T3.11.11.3.m1.1.1.cmml" xref="S6.T3.11.11.3.m1.1.1">0.00</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.11.11.3.m1.1c">0.00</annotation></semantics></math></td>
</tr>
</table>
</figure>
<figure id="S6.F17" class="ltx_figure"><img src="/html/2202.05297/assets/x4.png" id="S6.F17.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="298" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F17.2.1.1" class="ltx_text" style="font-size:90%;">Figure 17</span>: </span><span id="S6.F17.3.2" class="ltx_text" style="font-size:90%;">Boxplots showing the effect of tattoo removal on biometric comparison scores.</span></figcaption>
</figure>
<div id="S6.SS2.p2" class="ltx_para">
<p id="S6.SS2.p2.2" class="ltx_p">Table <a href="#S6.T3" title="TABLE III ‣ VI-B Experimental Results ‣ VI Application to Face Recognition ‣ Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition Mathias Ibsen, Christian Rathgeb, Pawel Drozdowski, Christoph Busch The authors are with the Biometrics and Internet Security Research Group at Hochschule Darmstadt, Germany E-mail: mathias.ibsen@h-da.de" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> shows the biometric performance scores calculated on the tattooed images and the inpainted facial images for the different used models. The scores indicate that realistic removal of tattoos (TRNet) might improve face recognition performance since we can observe that, compared to the baseline (tattooed), the EER is halved, and the FNMR at an FMR of <math id="S6.SS2.p2.1.m1.1" class="ltx_Math" alttext="1\%" display="inline"><semantics id="S6.SS2.p2.1.m1.1a"><mrow id="S6.SS2.p2.1.m1.1.1" xref="S6.SS2.p2.1.m1.1.1.cmml"><mn id="S6.SS2.p2.1.m1.1.1.2" xref="S6.SS2.p2.1.m1.1.1.2.cmml">1</mn><mo id="S6.SS2.p2.1.m1.1.1.1" xref="S6.SS2.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.p2.1.m1.1b"><apply id="S6.SS2.p2.1.m1.1.1.cmml" xref="S6.SS2.p2.1.m1.1.1"><csymbol cd="latexml" id="S6.SS2.p2.1.m1.1.1.1.cmml" xref="S6.SS2.p2.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S6.SS2.p2.1.m1.1.1.2.cmml" xref="S6.SS2.p2.1.m1.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p2.1.m1.1c">1\%</annotation></semantics></math> is reduced to <math id="S6.SS2.p2.2.m2.1" class="ltx_Math" alttext="0\%" display="inline"><semantics id="S6.SS2.p2.2.m2.1a"><mrow id="S6.SS2.p2.2.m2.1.1" xref="S6.SS2.p2.2.m2.1.1.cmml"><mn id="S6.SS2.p2.2.m2.1.1.2" xref="S6.SS2.p2.2.m2.1.1.2.cmml">0</mn><mo id="S6.SS2.p2.2.m2.1.1.1" xref="S6.SS2.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.p2.2.m2.1b"><apply id="S6.SS2.p2.2.m2.1.1.cmml" xref="S6.SS2.p2.2.m2.1.1"><csymbol cd="latexml" id="S6.SS2.p2.2.m2.1.1.1.cmml" xref="S6.SS2.p2.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S6.SS2.p2.2.m2.1.1.2.cmml" xref="S6.SS2.p2.2.m2.1.1.2">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p2.2.m2.1c">0\%</annotation></semantics></math>. The results indicate that a tattoo removal module can be integrated into the processing chain of a face recognition system and help make it more robust towards facial tattoos.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span id="S7.1.1" class="ltx_text ltx_font_smallcaps">Summary</span>
</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">In this paper, we proposed an automatic approach for blending tattoos onto facial images and showed that it is possible to use synthetic data to train a deep learning-based facial tattoo removal algorithm, thereby enhancing the performance of a state-of-the-art face recognition system. To create a facial image with tattoos, the face is first divided into face regions using landmark detection whereafter tattoo placements can be found. Subsequently, deep reconstruction maps and cut-out maps can be estimated from the input image. Thereafter, the information is combined to realistically blend tattoos to the facial image. Using this approach, we created a large database of facial images with tattoos and used it to train a deep learning-based algorithm for removing tattoos. Experimental results show a high quality of the tattoo removal. To further show the feasibility of the reconstruction, we evaluated the effect of removing facial tattoos on a state-of-the-art face recognition system and found that it can improve automated face recognition performance.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">Acknowledgements</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This research work has been funded by the German Federal Ministry of Education and Research and the Hessian Ministry of Higher Education, Research, Science and the Arts within their joint support of the National Research Center for Applied Cybersecurity ATHENE and the European Union’s Horizon 2020 research and innovation programme under the Marie Skłodowska-Curie grant agreement No. 860813 - TReSPAsS-ETN.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
D. Zeng, R. Veldhuis, and L. Spreeuwers, “A survey of face recognition
techniques under occlusion,” <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">IET Biometrics</em>, vol. 10, no. 6, pp.
581–606, 2021.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
S. Kurutz, “Face Tattoos Go Mainstream,”
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.nytimes.com/2018/08/04/style/face-tattoos.html</span>, 2018, last
accessed: 2021-10-27.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
M. Abrams, “Why are face tattoos the latest celebrity trend,”
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.standard.co.uk/insider/style/face-tattoos-celebrity-trend-justin-bieber-presley-gerber-a4360511.html</span>,
2020, last accessed: 2021-10-27.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
M. Ibsen, C. Rathgeb, T. Fink, P. Drozdowski, and C. Busch, “Impact of facial
tattoos and paintings on face recognition systems,” <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">IET
Biometrics</em>, vol. 10, no. 6, pp. 706–719, 2021.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
J. Mathai, I. Masi, and W. AbdAlmageed, “Does generative face completion help
face recognition?” in <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Int’l. Conf. on Biometrics (ICB)</em>, 2019, pp.
1–8.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
F. Bacchini and L. Lorusso, “A tattoo is not a face. ethical aspects of
tattoo-based biometrics,” <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Journal of Information, Communication and
Ethics in Society</em>, vol. 16, no. 2, 2017.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
E. Wood, T. Baltrušaitis, C. Hewitt, S. Dziadzio <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Fake it
till you make it: Face analysis in the wild using synthetic data alone,” in
<em id="bib.bib7.2.2" class="ltx_emph ltx_font_italic">Proc. of the IEEE/CVF Int’l. Conf. on Computer Vision (ICCV)</em>,
2021, pp. 3681–3691.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
European Council, “Regulation of the european parliament and of the council
on the protection of individuals with regard to the processing of personal
data and on the free movement of such data (general data protection
regulation),” April 2016.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Generative
adversarial nets,” in <em id="bib.bib9.2.2" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em>, vol. 27, 2014.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
T. Karras, S. Laine, and T. Aila, “A style-based generator architecture for
generative adversarial networks,” in <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">IEEE/CVF Conf. on Computer
Vision and Pattern Recognition (CVPR)</em>, 2019, pp. 4396–4405.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
T. Karras, S. Laine, M. Aittala, J. Hellsten <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Analyzing and
improving the image quality of StyleGAN,” in <em id="bib.bib11.2.2" class="ltx_emph ltx_font_italic">IEEE/CVF Conf. on
Computer Vision and Pattern Recognition (CVPR)</em>, 2020, pp. 8107–8116.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
T. Karras, M. Aittala, S. Laine, E. Härkönen <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Alias-free
generative adversarial networks,” in <em id="bib.bib12.2.2" class="ltx_emph ltx_font_italic">Proc. NeurIPS</em>, 2021.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
M. Grimmer, R. Raghavendra, and C. Christoph, “Deep face age progression: A
survey,” <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol. 9, pp. 83 376–83 393, 2021.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
R. Cappelli, D. Maio, and D. Maltoni, “SFinGe: an approach to synthetic
fingerprint generation,” <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Int’l. Workshop on Biometric Technologies</em>,
2004.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
J. Priesnitz, C. Rathgeb, N. Buchmann, and C. Busch, “SynCoLFinGer:
Synthetic Contactless Fingerprint Generator,” <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv e-prints</em>, p.
arXiv:2110.09144, oct 2021.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
A. B. V. Wyzykowski, M. P. Segundo, and R. de Paula Lemes, “Level three
synthetic fingerprint generation,” in <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">25th Int’l Conf. on Pattern
Recognition (ICPR)</em>, 2021, pp. 9250–9257.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
P. Drozdowski, C. Rathgeb, and C. Busch, “SIC-Gen: A synthetic Iris-Code
generator,” in <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Int’l. Conf. of the Biometrics Special Interest Group
(BIOSIG)</em>, 2017, pp. 61–69.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
J. Dole, “Synthetic Iris Generation, Manipulation, &amp; ID Preservation,”
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://eab.org/cgi-bin/dl.pl?/upload/documents/2256/06-Dole-SyntheticIrisPresentation-210913.pdf</span>,
2021, last accessed: 2021-12-26.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
X. Xu, W. M. Matkowski, and A. W. K. Kong, “A portrait photo-to-tattoo
transform based on digital tattooing,” <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Multimedia Tools and
Applications</em>, vol. 79, no. 33, pp. 24 367–24 392, 2020.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
V. Madhavan, “SkinDeep,” <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://github.com/vijishmadhavan/SkinDeep</span>,
2021, last accessed: 2021-11-01.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
C. Rathgeb, A. Dantcheva, and C. Busch, “Impact and detection of facial
beautification in face recognition: An overview,” <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>,
vol. 7, pp. 152 667–152 678, 2019.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
R. Singh, M. Vatsa, H. S. Bhatt, S. Bharadwaj <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Plastic surgery:
A new dimension to face recognition,” <em id="bib.bib22.2.2" class="ltx_emph ltx_font_italic">IEEE Trans. on Information
Forensics and Security</em>, vol. 5, no. 3, pp. 441–448, 2010.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
C. Rathgeb, D. Dogan, F. Stockhardt, M. D. Marsico, and C. Busch, “Plastic
surgery: An obstacle for deep face recognition?” in <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Proc. 15th IEEE
Computer Society Workshop on Biometrics (CVPRW)</em>, 2020, pp. 3510–3517.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
International Civil Aviation Organization, “Machine readable passports –
part 9 – deployment of biometric identification and electronic storage of
data in eMRTDs,” International Civil Aviation Organization (ICAO), 2015.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
A. Dantcheva, C. Chen, and A. Ross, “Can facial cosmetics affect the
matching accuracy of face recognition systems?” in <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">IEEE Fifth
Int’l. Conf. on Biometrics: Theory, Applications and Systems (BTAS)</em>,
2012, pp. 391–398.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
T. Y. Wang and A. Kumar, “Recognizing human faces under disguise and
makeup,” in <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">IEEE Int’l. Conf. on Identity, Security and Behavior
Analysis (ISBA)</em>, 2016, pp. 1–7.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
C. Chen, A. Dantcheva, T. Swearingen, and A. Ross, “Spoofing faces using
makeup: An investigative study,” in <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">IEEE Int’l. Conf. on
Identity, Security and Behavior Analysis (ISBA)</em>, 2017, pp. 1–8.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
C. Rathgeb, P. Drozdowski, D. Fischer, and C. Busch, “Vulnerability assessment
and detection of makeup presentation attacks,” in <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Proc. Int’l.
Workshop on Biometrics and Forensics (IWBF)</em>.   IEEE, 2020, pp. 1–6.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
M. Singh, R. Singh, M. Vatsa, N. K. Ratha, and R. Chellappa, “Recognizing
disguised faces in the wild,” <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Trans. on Biometrics, Behavior, and
Identity Science (TBIOM)</em>, vol. 1, no. 2, pp. 97–108, 2019.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
M. Ferrara, A. Franco, and D. Maltoni, “The magic passport,” in <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">IEEE
Int’l. Joint Conf. on Biometrics (IJCB)</em>, 2014, pp. 1–7.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
U. Scherhag, C. Rathgeb, J. Merkle, R. Breithaupt, and C. Busch,
“Face recognition systems under morphing attacks: A survey,” <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">IEEE
Access</em>, vol. 7, pp. 23 012–23 026, 2019.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
C. Rathgeb, A. Botaljov, F. Stockhardt, S. Isadskiy <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">et al.</em>,
“PRNU-based detection of facial retouching,” <em id="bib.bib32.2.2" class="ltx_emph ltx_font_italic">IET Biometrics</em>,
2020.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
M. F. Hedberg, “Effects of sample stretching in face recognition,” in
<em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Int’l. conf. of the Biometrics Special Interest Group (BIOSIG)</em>,
2020, pp. 1–4.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
L. Verdoliva, “Media forensics and deepfakes: An overview,” <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">IEEE
Journal of Selected Topics in Signal Processing</em>, vol. 14, no. 5, pp.
910–932, 2020.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
C. C. Ferrer, B. Pflaum, J. Pan, B. Dolhansky <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Deepfake
detection challenge results: An open initiative to advance AI,”
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://ai.facebook.com/blog/deepfake-detection-challenge-results-an-open-initiative-to-advance-ai/</span>,
2020, last accessed: 2021-11-12.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
R. Tolosana, R. Vera-Rodriguez, J. Fierrez, A. Morales, and J. Ortega-Garcia,
“Deepfakes and beyond: A survey of face manipulation and fake detection,”
<em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Information Fusion</em>, vol. 64, pp. 131–148, 2020.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
S. Iizuka, E. Simo-Serra, and H. Ishikawa, “Globally and locally consistent
image completion,” <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">ACM Trans. Graph.</em>, vol. 36, no. 4, 2017.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Y. Li, S. Liu, J. Yang, and M.-H. Yang, “Generative face completion,” in
<em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</em>,
2017, pp. 5892–5900.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Y. Zhao, W. Chen, J. Xing, X. Li <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Identity preserving face
completion for large ocular region occlusion,” in <em id="bib.bib39.2.2" class="ltx_emph ltx_font_italic">29th British Machine
Vision Conf. (BMVC)</em>, 2018.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
L. Song, J. Cao, L. Song, Y. Hu, and R. He, “Geometry-aware face completion
and editing,” <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conf. on Artificial
Intelligence</em>, vol. 33, no. 01, pp. 2506–2513, 2019.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
N. U. Din, K. Javed, S. Bae, and J. Yi, “A novel GAN-based network for
unmasking of masked face,” <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol. 8, pp.
44 276–44 287, 2020.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
D. King, “Dlib-ml: A machine learning toolkit,” <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Journal of Machine
Learning Research</em>, 2009.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Y. Feng, F. Wu, X. Shao, Y. Wang, and X. Zhou, “Joint 3D Face Reconstruction
and Dense Alignment with Position Map Regression Network,” in <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">ECCV</em>,
2018.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
P. J. Phillips, H. Wechsler, J. Huang, and P. J. Rauss, “The FERET database
and evaluation procedure for face-recognition algorithms,” <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">Image and
Vision Computing</em>, vol. 16, no. 5, pp. 295–306, 1998.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
P. J. Phillips, P. J. Flynn, T. Scruggs, K. Bowyer <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Overview of
the face recognition grand challenge,” in <em id="bib.bib45.2.2" class="ltx_emph ltx_font_italic">IEEE Computer Society
Conf. on Computer Vision and Pattern Recognition (CVPR)</em>, vol. 1.   IEEE, 2005, pp. 947–954.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Z. Liu, P. Luo, X. Wang, and X. Tang, “Deep learning face attributes in the
wild,” in <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">Proceedings of Int’l Conf. on Computer Vision (ICCV)</em>,
2015.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
P. Isola, J.-Y. Zhu, T. Zhou, and A. A. Efros, “Image-to-image translation
with conditional adversarial networks,” in <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">IEEE Conf. on Computer
Vision and Pattern Recognition (CVPR)</em>, 2017, pp. 5967–5976.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
J. Howard <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “fastai,” <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://github.com/fastai/fastai</span>,
2018.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
W. Shi, J. Caballero, F. Huszár, J. Totz <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Real-time single
image and video super-resolution using an efficient sub-pixel convolutional
neural network,” in <em id="bib.bib49.2.2" class="ltx_emph ltx_font_italic">IEEE Conf. on Computer Vision and Pattern
Recognition (CVPR)</em>, 2016, pp. 1874–1883.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
J. Johnson, A. Alahi, and L. Fei-Fei, “Perceptual losses for real-time style
transfer and super-resolution,” in <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">European Conference on Computer
Vision (ECCV)</em>, 2016.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
L. A. Gatys, A. S. Ecker, and M. Bethge, “A neural algorithm of artistic
style,” <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">arXiv e-prints</em>, p. arXiv:1508.06576, aug 2015.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
S. Liu and W. Deng, “Very deep convolutional neural network based image
classification using small training sample size,” in <em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">3rd IAPR Asian
Conference on Pattern Recognition (ACPR)</em>, 2015, pp. 730–734.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Z. Wang, A. C. Bovik, H. R. Sheikh, and E. P. Simoncelli, “Image quality
assessment: from error visibility to structural similarity,” <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">IEEE
Trans. on Image Processing</em>, vol. 13, no. 4, pp. 600–612, 2004.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
H. R. Sheikh and A. C. Bovik, “Image information and visual quality,”
<em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">IEEE Trans. on Image Processing</em>, vol. 15, no. 2, pp. 430–444, 2006.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
A. Khalel, “Sewar,” <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://github.com/andrewekhalel/sewar</span>, 2021,
last accessed: 2021-12-05.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
J. Deng, J. Guo, E. Ververas, I. Kotsia, and S. Zafeiriou, “RetinaFace:
Single-shot multi-level face localisation in the wild,” in <em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">Proceedings
of the IEEE/CVF Conf. on Computer Vision and Pattern Recognition (CVPR)</em>,
2020.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
ISO/IEC JTC1 SC37 Biometrics, <em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">ISO/IEC 19795-1:2021. Information
Technology – Biometric Performance Testing and Reporting – Part 1:
Principles and Framework</em>, International Organization for Standardization,
2021.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2202.05296" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2202.05297" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2202.05297">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2202.05297" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2202.05299" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Mar  7 20:38:37 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
