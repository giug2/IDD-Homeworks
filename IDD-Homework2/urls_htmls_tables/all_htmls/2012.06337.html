<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2012.06337] Privacy and Robustness in Federated Learning: Attacks and Defenses</title><meta property="og:description" content="As data are increasingly being stored in different silos and societies becoming more aware of data privacy issues, the traditional centralized training of artificial intelligence (AI) models are facing efficiency and p…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Privacy and Robustness in Federated Learning: Attacks and Defenses">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Privacy and Robustness in Federated Learning: Attacks and Defenses">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2012.06337">

<!--Generated on Thu Mar  7 02:58:22 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Federated Learning,  Privacy,  Robustness,  Attacks,  Defenses
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div class="ltx_pagination ltx_role_newpage"></div>
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\extrafloats</span>
<p id="p1.2" class="ltx_p">100


<span id="p1.2.1" class="ltx_ERROR undefined">\pdfcolInitStack</span>tcb@breakable</p>
</div>
<h1 class="ltx_title ltx_title_document">Privacy and Robustness in Federated Learning: Attacks and Defenses</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Lingjuan Lyu<sup id="id5.5.id1" class="ltx_sup"><span id="id5.5.id1.1" class="ltx_text ltx_font_italic">∗</span></sup>,
Han Yu<sup id="id6.6.id2" class="ltx_sup"><span id="id6.6.id2.1" class="ltx_text ltx_font_italic">∗</span></sup>,
Xingjun Ma, Chen Chen, Lichao Sun, Jun Zhao,
Qiang Yang<sup id="id7.7.id3" class="ltx_sup"><span id="id7.7.id3.1" class="ltx_text ltx_font_italic">∗</span></sup>, , and Philip S. Yu
</span><span class="ltx_author_notes">Lingjuan Lyu is with Sony AI. E-mail: Lingjuan.Lv@sony.com.Han Yu and Jun Zhao are with the School of Computer Science and Engineering, Nanyang Technological University, Singapore. E-mail: han.yu@ntu.edu.sg, junzhao@ntu.edu.sg.Xingjun Ma is with the School of Information Technology, Deakin University, Geelong, Australia. E-mail: daniel.ma@deakin.edu.au.Chen Chen is with College of Computer Science, Zhejiang University, China. E-mail:cc33@zju.edu.cn.Lichao Sun is with Department of Computer Science and Engineering, Lehigh University. E-mail: lis221@lehigh.edu.Qiang Yang is with Department of AI, WeBank, Shenzhen, China, and Department of Computer Science and Engineering, Hong Kong University of Science and Technology. E-mail: qyang@ust.hkPhilip S. Yu is with Information Technology, University of Illinois at Chicago. E-mail: psyu@uic.edu.<sup id="id8.8.id1" class="ltx_sup"><span id="id8.8.id1.1" class="ltx_text ltx_font_italic">∗</span></sup>Corresponding authors.
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id9.id1" class="ltx_p">As data are increasingly being stored in different silos and societies becoming more aware of data privacy issues, the traditional centralized training of artificial intelligence (AI) models are facing efficiency and privacy challenges. Recently, federated learning (FL) has emerged as an alternative solution and continue to thrive in this new reality. Existing FL protocol designs have been shown to be vulnerable to adversaries within or outside of the system, compromising data privacy and system robustness. Besides training powerful global models, it is of paramount importance to design FL systems that have privacy guarantees and are resistant to different types of adversaries. In this paper, we conduct a comprehensive survey on privacy and robustness in federated learning over the past 5 years. Through a concise introduction to the concept of FL, and a unique taxonomy covering: 1) threat models; 2) privacy attacks and defenses; 3) poisoning attacks and defenses, we provide an accessible review of this important topic. We highlight the intuitions, key techniques as well as fundamental assumptions adopted by various attacks and defenses. Finally, we discuss promising future research directions towards robust and privacy-preserving FL, and their interplays with multidisciplinary goals of FL.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Federated Learning, Privacy, Robustness, Attacks, Defenses

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">As computing devices become increasingly ubiquitous, people generate huge amounts of data through their day-to-day usage. Collecting such data into centralized storage facilities is costly and time consuming. Traditional centralized machine learning (ML) approaches cannot support such ubiquitous deployments and applications due to infrastructure shortcomings such as limited communication bandwidth, intermittent network connectivity, and strict delay constraints <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Another critical concern is data privacy and user confidentiality as the usage data usually contain sensitive information <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Sensitive data such as facial images, location-based services, or health information can be used for targeted social advertising and recommendation, posing immediate or potential privacy risks. Hence, private data should not be directly shared without any privacy protection. As societies become increasingly aware of privacy preservation, legal restrictions such as the General Data Protection Regulation (GDPR) are emerging, which makes data aggregation practices less feasible <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In this scenario, federated learning (FL) (also well known as collaborative learning), which distributes model training to the devices from which data originate, emerged as a promising alternative ML paradigm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. FL enables a multitude of participants to construct a joint ML model without exposing their private training data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. It can also handle unbalanced and non-independent and identically distributed (non-I.I.D.) data, which naturally arise in the real world <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. In recent years, FL has benefited a wide range of applications such as next word prediction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, visual object detection for safety <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, entity resolution <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, recommendation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, industrial IoT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, and graph-based analysis <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, etc.</p>
</div>
<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S1.SS1.4.1.1" class="ltx_text">I-A</span> </span><span id="S1.SS1.5.2" class="ltx_text ltx_font_italic">Categorization of Federated Learning based on Distribution</span>
</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p id="S1.SS1.p1.1" class="ltx_p">Based on the distribution of data features and data samples among participants, federated learning can be generally classified as horizontally federated learning (HFL), vertically federated learning (VFL) and federated transfer learning (FTL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>.</p>
</div>
<figure id="S1.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S1.T1.2.1.1" class="ltx_text" style="font-size:90%;">TABLE I</span>: </span><span id="S1.T1.3.2" class="ltx_text" style="font-size:90%;">Taxonomy for horizontal federated learning (HFL).</span></figcaption>
<div id="S1.T1.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:437.0pt;height:504.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table id="S1.T1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S1.T1.4.1.1" class="ltx_tr">
<td id="S1.T1.4.1.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S1.T1.4.1.1.1.1" class="ltx_text ltx_font_bold">HFL</span></td>
<td id="S1.T1.4.1.1.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S1.T1.4.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.4.1.1.2.1.1" class="ltx_p"><span id="S1.T1.4.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Number of Participants</span></span>
</span>
</td>
<td id="S1.T1.4.1.1.3" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S1.T1.4.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.4.1.1.3.1.1" class="ltx_p"><span id="S1.T1.4.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Training Participation</span></span>
</span>
</td>
<td id="S1.T1.4.1.1.4" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S1.T1.4.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.4.1.1.4.1.1" class="ltx_p"><span id="S1.T1.4.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Technical Capability</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.4.1.2" class="ltx_tr">
<td id="S1.T1.4.1.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">H2B</td>
<td id="S1.T1.4.1.2.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S1.T1.4.1.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.4.1.2.2.1.1" class="ltx_p">small</span>
</span>
</td>
<td id="S1.T1.4.1.2.3" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S1.T1.4.1.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.4.1.2.3.1.1" class="ltx_p">frequent</span>
</span>
</td>
<td id="S1.T1.4.1.2.4" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S1.T1.4.1.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.4.1.2.4.1.1" class="ltx_p">high</span>
</span>
</td>
</tr>
<tr id="S1.T1.4.1.3" class="ltx_tr">
<td id="S1.T1.4.1.3.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">H2C</td>
<td id="S1.T1.4.1.3.2" class="ltx_td ltx_align_justify ltx_border_b ltx_border_r ltx_border_t">
<span id="S1.T1.4.1.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.4.1.3.2.1.1" class="ltx_p">large</span>
</span>
</td>
<td id="S1.T1.4.1.3.3" class="ltx_td ltx_align_justify ltx_border_b ltx_border_r ltx_border_t">
<span id="S1.T1.4.1.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.4.1.3.3.1.1" class="ltx_p">not frequent</span>
</span>
</td>
<td id="S1.T1.4.1.3.4" class="ltx_td ltx_align_justify ltx_border_b ltx_border_r ltx_border_t">
<span id="S1.T1.4.1.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.4.1.3.4.1.1" class="ltx_p">low</span>
</span>
</td>
</tr>
</table>
</span></div>
</figure>
<div id="S1.SS1.p2" class="ltx_para">
<p id="S1.SS1.p2.1" class="ltx_p">Under HFL, datasets owned by each participant share similar features but concern different users <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. For example, several hospitals may each store similar types of data (<span id="S1.SS1.p2.1.1" class="ltx_text ltx_font_italic">e.g.</span>, demographic, clinical, and genomics) about different patients. If they decide to build a machine learning model together using FL, we refer to such a scenario as HFL. In this paper, we further classify HFL into HFL to businesses (H2B), and HFL to consumers (H2C). A comparison between H2B and H2C is listed in Table <a href="#S1.T1" title="TABLE I ‣ I-A Categorization of Federated Learning based on Distribution ‣ I Introduction ‣ Privacy and Robustness in Federated Learning: Attacks and Defenses" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>. The main difference lies in the number of participants, FL training participation level and technical capability, which can influence how adversaries attempt to compromise the FL system. Under H2B, there are typically a handful of participants. They can be frequently selected during FL training. The participants tend to possess significant computational power and sophisticated technical capabilities <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. Under H2C, there can be thousands or even millions of potential participants. In each round of training, only a subset of them are selected. As their datasets tend to be small, the chance of a participant being selected repeatedly for FL training is low. They generally possess limited computational power and low technical capabilities. An example of H2C is Google’s GBoard application <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.</p>
</div>
<div id="S1.SS1.p3" class="ltx_para">
<p id="S1.SS1.p3.1" class="ltx_p">VFL is applicable to the cases in which participants have large overlaps in the sample space but differ in the feature space,
<span id="S1.SS1.p3.1.1" class="ltx_text ltx_font_italic">i.e.</span>, different participants hold different attributes of the same records <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>.
VFL mainly targets business participants. Thus, the characteristics of VFL participants are similar to those of H2B participants.</p>
</div>
<div id="S1.SS1.p4" class="ltx_para">
<p id="S1.SS1.p4.1" class="ltx_p">Nowadays, FTL is attracting increasing attention in industries such as finance, medicine and healthcare. FTL deals with scenarios in which FL participants have little overlap in both the sample space and the feature space <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. In this case, transfer learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> techniques can be applied to provide solutions for the entire sample and feature space under a federation. FTL enables complementary knowledge to be transferred across domains in a data federation, thereby enabling a target-domain party to build flexible and effective models by leveraging rich labels from a source domain <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2012.06337/assets/figures/FL_train_new.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="327" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.3.2" class="ltx_text" style="font-size:90%;">A typical FL training process, in which both the (potentially malicious) FL server/aggregator and malicious participants may pose threats to the FL system.</span></figcaption>
</figure>
</section>
<section id="S1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S1.SS2.4.1.1" class="ltx_text">I-B</span> </span><span id="S1.SS2.5.2" class="ltx_text ltx_font_italic">Categorization of Federated Learning based on Architectures</span>
</h3>

<div id="S1.SS2.p1" class="ltx_para">
<p id="S1.SS2.p1.8" class="ltx_p"><span id="S1.SS2.p1.8.1" class="ltx_text ltx_font_bold">FL with Homogeneous Architectures:</span> Sharing gradients is typically limited only to homogeneous FL architectures, <span id="S1.SS2.p1.8.2" class="ltx_text ltx_font_italic">i.e.</span>, the same model is shared with all participants. Participants aim to collaboratively learn a more accurate model. Specifically, the model parameters <math id="S1.SS2.p1.1.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S1.SS2.p1.1.m1.1a"><mi id="S1.SS2.p1.1.m1.1.1" xref="S1.SS2.p1.1.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S1.SS2.p1.1.m1.1b"><ci id="S1.SS2.p1.1.m1.1.1.cmml" xref="S1.SS2.p1.1.m1.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.SS2.p1.1.m1.1c">w</annotation></semantics></math> of the model are often obtained via solving the following optimization problem: <math id="S1.SS2.p1.2.m2.2" class="ltx_Math" alttext="\min_{w}{\textstyle\sum}_{i=1}^{n}F(w,D_{i})" display="inline"><semantics id="S1.SS2.p1.2.m2.2a"><mrow id="S1.SS2.p1.2.m2.2.2" xref="S1.SS2.p1.2.m2.2.2.cmml"><msub id="S1.SS2.p1.2.m2.2.2.3" xref="S1.SS2.p1.2.m2.2.2.3.cmml"><mi id="S1.SS2.p1.2.m2.2.2.3.2" xref="S1.SS2.p1.2.m2.2.2.3.2.cmml">min</mi><mi id="S1.SS2.p1.2.m2.2.2.3.3" xref="S1.SS2.p1.2.m2.2.2.3.3.cmml">w</mi></msub><mo lspace="0em" rspace="0em" id="S1.SS2.p1.2.m2.2.2.2" xref="S1.SS2.p1.2.m2.2.2.2.cmml">​</mo><mrow id="S1.SS2.p1.2.m2.2.2.1" xref="S1.SS2.p1.2.m2.2.2.1.cmml"><msubsup id="S1.SS2.p1.2.m2.2.2.1.2" xref="S1.SS2.p1.2.m2.2.2.1.2.cmml"><mo id="S1.SS2.p1.2.m2.2.2.1.2.2.2" xref="S1.SS2.p1.2.m2.2.2.1.2.2.2.cmml">∑</mo><mrow id="S1.SS2.p1.2.m2.2.2.1.2.2.3" xref="S1.SS2.p1.2.m2.2.2.1.2.2.3.cmml"><mi id="S1.SS2.p1.2.m2.2.2.1.2.2.3.2" xref="S1.SS2.p1.2.m2.2.2.1.2.2.3.2.cmml">i</mi><mo id="S1.SS2.p1.2.m2.2.2.1.2.2.3.1" xref="S1.SS2.p1.2.m2.2.2.1.2.2.3.1.cmml">=</mo><mn id="S1.SS2.p1.2.m2.2.2.1.2.2.3.3" xref="S1.SS2.p1.2.m2.2.2.1.2.2.3.3.cmml">1</mn></mrow><mi id="S1.SS2.p1.2.m2.2.2.1.2.3" xref="S1.SS2.p1.2.m2.2.2.1.2.3.cmml">n</mi></msubsup><mrow id="S1.SS2.p1.2.m2.2.2.1.1" xref="S1.SS2.p1.2.m2.2.2.1.1.cmml"><mi id="S1.SS2.p1.2.m2.2.2.1.1.3" xref="S1.SS2.p1.2.m2.2.2.1.1.3.cmml">F</mi><mo lspace="0em" rspace="0em" id="S1.SS2.p1.2.m2.2.2.1.1.2" xref="S1.SS2.p1.2.m2.2.2.1.1.2.cmml">​</mo><mrow id="S1.SS2.p1.2.m2.2.2.1.1.1.1" xref="S1.SS2.p1.2.m2.2.2.1.1.1.2.cmml"><mo stretchy="false" id="S1.SS2.p1.2.m2.2.2.1.1.1.1.2" xref="S1.SS2.p1.2.m2.2.2.1.1.1.2.cmml">(</mo><mi id="S1.SS2.p1.2.m2.1.1" xref="S1.SS2.p1.2.m2.1.1.cmml">w</mi><mo id="S1.SS2.p1.2.m2.2.2.1.1.1.1.3" xref="S1.SS2.p1.2.m2.2.2.1.1.1.2.cmml">,</mo><msub id="S1.SS2.p1.2.m2.2.2.1.1.1.1.1" xref="S1.SS2.p1.2.m2.2.2.1.1.1.1.1.cmml"><mi id="S1.SS2.p1.2.m2.2.2.1.1.1.1.1.2" xref="S1.SS2.p1.2.m2.2.2.1.1.1.1.1.2.cmml">D</mi><mi id="S1.SS2.p1.2.m2.2.2.1.1.1.1.1.3" xref="S1.SS2.p1.2.m2.2.2.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S1.SS2.p1.2.m2.2.2.1.1.1.1.4" xref="S1.SS2.p1.2.m2.2.2.1.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.SS2.p1.2.m2.2b"><apply id="S1.SS2.p1.2.m2.2.2.cmml" xref="S1.SS2.p1.2.m2.2.2"><times id="S1.SS2.p1.2.m2.2.2.2.cmml" xref="S1.SS2.p1.2.m2.2.2.2"></times><apply id="S1.SS2.p1.2.m2.2.2.3.cmml" xref="S1.SS2.p1.2.m2.2.2.3"><csymbol cd="ambiguous" id="S1.SS2.p1.2.m2.2.2.3.1.cmml" xref="S1.SS2.p1.2.m2.2.2.3">subscript</csymbol><min id="S1.SS2.p1.2.m2.2.2.3.2.cmml" xref="S1.SS2.p1.2.m2.2.2.3.2"></min><ci id="S1.SS2.p1.2.m2.2.2.3.3.cmml" xref="S1.SS2.p1.2.m2.2.2.3.3">𝑤</ci></apply><apply id="S1.SS2.p1.2.m2.2.2.1.cmml" xref="S1.SS2.p1.2.m2.2.2.1"><apply id="S1.SS2.p1.2.m2.2.2.1.2.cmml" xref="S1.SS2.p1.2.m2.2.2.1.2"><csymbol cd="ambiguous" id="S1.SS2.p1.2.m2.2.2.1.2.1.cmml" xref="S1.SS2.p1.2.m2.2.2.1.2">superscript</csymbol><apply id="S1.SS2.p1.2.m2.2.2.1.2.2.cmml" xref="S1.SS2.p1.2.m2.2.2.1.2"><csymbol cd="ambiguous" id="S1.SS2.p1.2.m2.2.2.1.2.2.1.cmml" xref="S1.SS2.p1.2.m2.2.2.1.2">subscript</csymbol><sum id="S1.SS2.p1.2.m2.2.2.1.2.2.2.cmml" xref="S1.SS2.p1.2.m2.2.2.1.2.2.2"></sum><apply id="S1.SS2.p1.2.m2.2.2.1.2.2.3.cmml" xref="S1.SS2.p1.2.m2.2.2.1.2.2.3"><eq id="S1.SS2.p1.2.m2.2.2.1.2.2.3.1.cmml" xref="S1.SS2.p1.2.m2.2.2.1.2.2.3.1"></eq><ci id="S1.SS2.p1.2.m2.2.2.1.2.2.3.2.cmml" xref="S1.SS2.p1.2.m2.2.2.1.2.2.3.2">𝑖</ci><cn type="integer" id="S1.SS2.p1.2.m2.2.2.1.2.2.3.3.cmml" xref="S1.SS2.p1.2.m2.2.2.1.2.2.3.3">1</cn></apply></apply><ci id="S1.SS2.p1.2.m2.2.2.1.2.3.cmml" xref="S1.SS2.p1.2.m2.2.2.1.2.3">𝑛</ci></apply><apply id="S1.SS2.p1.2.m2.2.2.1.1.cmml" xref="S1.SS2.p1.2.m2.2.2.1.1"><times id="S1.SS2.p1.2.m2.2.2.1.1.2.cmml" xref="S1.SS2.p1.2.m2.2.2.1.1.2"></times><ci id="S1.SS2.p1.2.m2.2.2.1.1.3.cmml" xref="S1.SS2.p1.2.m2.2.2.1.1.3">𝐹</ci><interval closure="open" id="S1.SS2.p1.2.m2.2.2.1.1.1.2.cmml" xref="S1.SS2.p1.2.m2.2.2.1.1.1.1"><ci id="S1.SS2.p1.2.m2.1.1.cmml" xref="S1.SS2.p1.2.m2.1.1">𝑤</ci><apply id="S1.SS2.p1.2.m2.2.2.1.1.1.1.1.cmml" xref="S1.SS2.p1.2.m2.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S1.SS2.p1.2.m2.2.2.1.1.1.1.1.1.cmml" xref="S1.SS2.p1.2.m2.2.2.1.1.1.1.1">subscript</csymbol><ci id="S1.SS2.p1.2.m2.2.2.1.1.1.1.1.2.cmml" xref="S1.SS2.p1.2.m2.2.2.1.1.1.1.1.2">𝐷</ci><ci id="S1.SS2.p1.2.m2.2.2.1.1.1.1.1.3.cmml" xref="S1.SS2.p1.2.m2.2.2.1.1.1.1.1.3">𝑖</ci></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.SS2.p1.2.m2.2c">\min_{w}{\textstyle\sum}_{i=1}^{n}F(w,D_{i})</annotation></semantics></math>, where <math id="S1.SS2.p1.3.m3.2" class="ltx_Math" alttext="F(w,D_{i})" display="inline"><semantics id="S1.SS2.p1.3.m3.2a"><mrow id="S1.SS2.p1.3.m3.2.2" xref="S1.SS2.p1.3.m3.2.2.cmml"><mi id="S1.SS2.p1.3.m3.2.2.3" xref="S1.SS2.p1.3.m3.2.2.3.cmml">F</mi><mo lspace="0em" rspace="0em" id="S1.SS2.p1.3.m3.2.2.2" xref="S1.SS2.p1.3.m3.2.2.2.cmml">​</mo><mrow id="S1.SS2.p1.3.m3.2.2.1.1" xref="S1.SS2.p1.3.m3.2.2.1.2.cmml"><mo stretchy="false" id="S1.SS2.p1.3.m3.2.2.1.1.2" xref="S1.SS2.p1.3.m3.2.2.1.2.cmml">(</mo><mi id="S1.SS2.p1.3.m3.1.1" xref="S1.SS2.p1.3.m3.1.1.cmml">w</mi><mo id="S1.SS2.p1.3.m3.2.2.1.1.3" xref="S1.SS2.p1.3.m3.2.2.1.2.cmml">,</mo><msub id="S1.SS2.p1.3.m3.2.2.1.1.1" xref="S1.SS2.p1.3.m3.2.2.1.1.1.cmml"><mi id="S1.SS2.p1.3.m3.2.2.1.1.1.2" xref="S1.SS2.p1.3.m3.2.2.1.1.1.2.cmml">D</mi><mi id="S1.SS2.p1.3.m3.2.2.1.1.1.3" xref="S1.SS2.p1.3.m3.2.2.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S1.SS2.p1.3.m3.2.2.1.1.4" xref="S1.SS2.p1.3.m3.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.SS2.p1.3.m3.2b"><apply id="S1.SS2.p1.3.m3.2.2.cmml" xref="S1.SS2.p1.3.m3.2.2"><times id="S1.SS2.p1.3.m3.2.2.2.cmml" xref="S1.SS2.p1.3.m3.2.2.2"></times><ci id="S1.SS2.p1.3.m3.2.2.3.cmml" xref="S1.SS2.p1.3.m3.2.2.3">𝐹</ci><interval closure="open" id="S1.SS2.p1.3.m3.2.2.1.2.cmml" xref="S1.SS2.p1.3.m3.2.2.1.1"><ci id="S1.SS2.p1.3.m3.1.1.cmml" xref="S1.SS2.p1.3.m3.1.1">𝑤</ci><apply id="S1.SS2.p1.3.m3.2.2.1.1.1.cmml" xref="S1.SS2.p1.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S1.SS2.p1.3.m3.2.2.1.1.1.1.cmml" xref="S1.SS2.p1.3.m3.2.2.1.1.1">subscript</csymbol><ci id="S1.SS2.p1.3.m3.2.2.1.1.1.2.cmml" xref="S1.SS2.p1.3.m3.2.2.1.1.1.2">𝐷</ci><ci id="S1.SS2.p1.3.m3.2.2.1.1.1.3.cmml" xref="S1.SS2.p1.3.m3.2.2.1.1.1.3">𝑖</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.SS2.p1.3.m3.2c">F(w,D_{i})</annotation></semantics></math> is the objective function for the local training dataset on the <math id="S1.SS2.p1.4.m4.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S1.SS2.p1.4.m4.1a"><mi id="S1.SS2.p1.4.m4.1.1" xref="S1.SS2.p1.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S1.SS2.p1.4.m4.1b"><ci id="S1.SS2.p1.4.m4.1.1.cmml" xref="S1.SS2.p1.4.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.SS2.p1.4.m4.1c">i</annotation></semantics></math>-th participant and characterizes how well the parameters <math id="S1.SS2.p1.5.m5.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S1.SS2.p1.5.m5.1a"><mi id="S1.SS2.p1.5.m5.1.1" xref="S1.SS2.p1.5.m5.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S1.SS2.p1.5.m5.1b"><ci id="S1.SS2.p1.5.m5.1.1.cmml" xref="S1.SS2.p1.5.m5.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.SS2.p1.5.m5.1c">w</annotation></semantics></math> model the local training dataset <math id="S1.SS2.p1.6.m6.1" class="ltx_Math" alttext="D_{i}" display="inline"><semantics id="S1.SS2.p1.6.m6.1a"><msub id="S1.SS2.p1.6.m6.1.1" xref="S1.SS2.p1.6.m6.1.1.cmml"><mi id="S1.SS2.p1.6.m6.1.1.2" xref="S1.SS2.p1.6.m6.1.1.2.cmml">D</mi><mi id="S1.SS2.p1.6.m6.1.1.3" xref="S1.SS2.p1.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S1.SS2.p1.6.m6.1b"><apply id="S1.SS2.p1.6.m6.1.1.cmml" xref="S1.SS2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S1.SS2.p1.6.m6.1.1.1.cmml" xref="S1.SS2.p1.6.m6.1.1">subscript</csymbol><ci id="S1.SS2.p1.6.m6.1.1.2.cmml" xref="S1.SS2.p1.6.m6.1.1.2">𝐷</ci><ci id="S1.SS2.p1.6.m6.1.1.3.cmml" xref="S1.SS2.p1.6.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.SS2.p1.6.m6.1c">D_{i}</annotation></semantics></math> on the <math id="S1.SS2.p1.7.m7.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S1.SS2.p1.7.m7.1a"><mi id="S1.SS2.p1.7.m7.1.1" xref="S1.SS2.p1.7.m7.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S1.SS2.p1.7.m7.1b"><ci id="S1.SS2.p1.7.m7.1.1.cmml" xref="S1.SS2.p1.7.m7.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.SS2.p1.7.m7.1c">i</annotation></semantics></math>-th participant. Different classifiers (<span id="S1.SS2.p1.8.3" class="ltx_text ltx_font_italic">e.g.</span>, logistic regression, deep neural networks) use different objective functions. In FL, each participant maintains a local model for its local training dataset. The server maintains a global model via aggregating local models from <math id="S1.SS2.p1.8.m8.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S1.SS2.p1.8.m8.1a"><mi id="S1.SS2.p1.8.m8.1.1" xref="S1.SS2.p1.8.m8.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S1.SS2.p1.8.m8.1b"><ci id="S1.SS2.p1.8.m8.1.1.cmml" xref="S1.SS2.p1.8.m8.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.SS2.p1.8.m8.1c">n</annotation></semantics></math> participants. Specifically, FL with homogeneous architectures performs the steps in Fig. <a href="#S1.F1" title="Figure 1 ‣ I-A Categorization of Federated Learning based on Distribution ‣ I Introduction ‣ Privacy and Robustness in Federated Learning: Attacks and Defenses" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. FL with homogeneous architectures generally comes in two forms <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>: (1) FedSGD, in which each participant sends every SGD update to the server; (2) FedAvg, in which participants locally batch multiple iterations of SGD before sending updates to the server, which is more communication efficient. These methods are all based on the mean aggregation rule that takes the average of the local model parameters as the global model. However, the global model mean value can be arbitrarily manipulated even if just one participant is compromised <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>.</p>
</div>
<div id="S1.SS2.p2" class="ltx_para">
<p id="S1.SS2.p2.1" class="ltx_p"><span id="S1.SS2.p2.1.1" class="ltx_text ltx_font_bold">FL with Heterogeneous Architectures:</span> The most recent efforts extended FL to collaboratively train models with heterogeneous architectures <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. Conventional federated model training which directly averages model weights is only possible if all local models have the same model structure. Naturally, it limits collaboration among data owners with heterogeneous model architectures. Sharing model prediction instead of model parameters or updates removes this obstacle and eliminates the risk of white-box inference attacks in conventional federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. Unlike the existing federated learning algorithms, <em id="S1.SS2.p2.1.2" class="ltx_emph ltx_font_italic">Federated Model Distillation</em> (FedMD) does not force a single global model onto local models. Instead, it is conducted in a succinct, black-box and model agnostic manner. Each local model is updated separately, participants share the knowledge of their local models via their predictions on an unlabeled public set <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. Another obvious benefit of sharing logits is the reduced communication costs, without significantly affecting utility <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>.</p>
</div>
<div id="S1.SS2.p3" class="ltx_para">
<p id="S1.SS2.p3.1" class="ltx_p">In summary, all the above sharing methods did not provide defense against privacy and poisoning attacks – two main source of threats to FL.</p>
</div>
</section>
<section id="S1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S1.SS3.4.1.1" class="ltx_text">I-C</span> </span><span id="S1.SS3.5.2" class="ltx_text ltx_font_italic">Threats to FL</span>
</h3>

<div id="S1.SS3.p1" class="ltx_para">
<p id="S1.SS3.p1.1" class="ltx_p">FL offers a privacy-aware paradigm of model training which does not require data sharing and allows participants to join and leave a federation freely. Nevertheless, recent works have demonstrated that FL may not always provide sufficient privacy and robustness guarantees. Existing FL protocol designs are vulnerable to: (1) a malicious server who aims to infer sensitive information from individual updates over time, tamper with the training process or control the view of the participants on the global parameters; (2) any adversarial participant who can infer other participants’ sensitive information, tamper the global parameter aggregation or poison the global model.</p>
</div>
<div id="S1.SS3.p2" class="ltx_para">
<p id="S1.SS3.p2.1" class="ltx_p">In terms of privacy leakage, communicating gradients throughout the training process can reveal sensitive information <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>, even cause deep leakage <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, either to a third party or the central server <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. For instance, as mentioned in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, even a small portion of gradients can reveal a fair amount of sensitive information about the local data. Recent works further show that, by simply observing the gradients, a malicious attacker can successfully steal the training data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>.</p>
</div>
<div id="S1.SS3.p3" class="ltx_para">
<p id="S1.SS3.p3.1" class="ltx_p">In terms of robustness, FL systems are vulnerable to both data poisoning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> and model poisoning attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>.
Malicious participants can attack the convergence of the global model or implant backdoor triggers into the global model by deliberately altering their local data (data poisoning) or their gradients uploads (model poisoning). More broadly, poisoning attacks can be categorized into (1) untargeted attack such as Byzantine attack where the adversary aims to destroy the convergence and performance of the global model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>; and (2) targeted attack such as backdoor attack where the adversary aims to implant a backdoor trigger into the global model so as to trick the model to constantly predict an adversarial class on a subtask while keeping good performance on the main task <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>.</p>
</div>
<div id="S1.SS3.p4" class="ltx_para">
<p id="S1.SS3.p4.1" class="ltx_p">These privacy and robustness attacks pose significant threats to FL. In centralized learning, the server is responsible for all the participants’ privacy and model robustness. However, in FL, any participant can attack the server and spy on other participants, which sometimes even without involving the server. Therefore, it is important to understand the principles behind these privacy and robustness attacks. The properties of the representative privacy and robustness attacks in server-based FL are summarized in Table <a href="#S1.T2" title="TABLE II ‣ I-C Threats to FL ‣ I Introduction ‣ Privacy and Robustness in Federated Learning: Attacks and Defenses" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>.</p>
</div>
<figure id="S1.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S1.T2.2.1.1" class="ltx_text" style="font-size:90%;">TABLE II</span>: </span><span id="S1.T2.3.2" class="ltx_text" style="font-size:90%;">A summary of attacks against server-based FL.</span></figcaption>
<div id="S1.T2.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:88.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-178.5pt,36.6pt) scale(0.548460900449351,0.548460900449351) ;">
<table id="S1.T2.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S1.T2.4.1.1" class="ltx_tr">
<td id="S1.T2.4.1.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" colspan="2" rowspan="3"><span id="S1.T2.4.1.1.1.1" class="ltx_text ltx_font_bold">Attack Type</span></td>
<td id="S1.T2.4.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2"><span id="S1.T2.4.1.1.2.1" class="ltx_text ltx_font_bold">Attack Target</span></td>
<td id="S1.T2.4.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2"><span id="S1.T2.4.1.1.3.1" class="ltx_text ltx_font_bold">Attacker Role</span></td>
<td id="S1.T2.4.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2"><span id="S1.T2.4.1.1.4.1" class="ltx_text ltx_font_bold">FL Scenario</span></td>
<td id="S1.T2.4.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3"><span id="S1.T2.4.1.1.5.1" class="ltx_text ltx_font_bold">Attack Complexity</span></td>
</tr>
<tr id="S1.T2.4.1.2" class="ltx_tr">
<td id="S1.T2.4.1.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T2.4.1.2.1.1" class="ltx_text ltx_font_bold">Model</span></td>
<td id="S1.T2.4.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T2.4.1.2.2.1" class="ltx_text ltx_font_bold">Training Data</span></td>
<td id="S1.T2.4.1.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T2.4.1.2.3.1" class="ltx_text ltx_font_bold">Participant</span></td>
<td id="S1.T2.4.1.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T2.4.1.2.4.1" class="ltx_text ltx_font_bold">Server</span></td>
<td id="S1.T2.4.1.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T2.4.1.2.5.1" class="ltx_text ltx_font_bold">H2B</span></td>
<td id="S1.T2.4.1.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T2.4.1.2.6.1" class="ltx_text ltx_font_bold">H2C</span></td>
<td id="S1.T2.4.1.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2"><span id="S1.T2.4.1.2.7.1" class="ltx_text ltx_font_bold">Attack Iteration</span></td>
<td id="S1.T2.4.1.2.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T2.4.1.2.8.1" class="ltx_text ltx_font_bold">Auxiliary Knowledge Required</span></td>
</tr>
<tr id="S1.T2.4.1.3" class="ltx_tr">
<td id="S1.T2.4.1.3.1" class="ltx_td ltx_border_r"></td>
<td id="S1.T2.4.1.3.2" class="ltx_td ltx_border_r"></td>
<td id="S1.T2.4.1.3.3" class="ltx_td ltx_border_r"></td>
<td id="S1.T2.4.1.3.4" class="ltx_td ltx_border_r"></td>
<td id="S1.T2.4.1.3.5" class="ltx_td ltx_border_r"></td>
<td id="S1.T2.4.1.3.6" class="ltx_td ltx_border_r"></td>
<td id="S1.T2.4.1.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T2.4.1.3.7.1" class="ltx_text ltx_font_bold">One Round</span></td>
<td id="S1.T2.4.1.3.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T2.4.1.3.8.1" class="ltx_text ltx_font_bold">Multiple Rounds</span></td>
<td id="S1.T2.4.1.3.9" class="ltx_td ltx_border_r"></td>
</tr>
<tr id="S1.T2.4.1.4" class="ltx_tr">
<td id="S1.T2.4.1.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" rowspan="2"><span id="S1.T2.4.1.4.1.1" class="ltx_text">Robustness</span></td>
<td id="S1.T2.4.1.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Untargeted attack</td>
<td id="S1.T2.4.1.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NO</td>
<td id="S1.T2.4.1.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NO</td>
<td id="S1.T2.4.1.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.4.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NO</td>
<td id="S1.T2.4.1.4.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.4.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.4.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
</tr>
<tr id="S1.T2.4.1.5" class="ltx_tr">
<td id="S1.T2.4.1.5.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Targeted attack</td>
<td id="S1.T2.4.1.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NO</td>
<td id="S1.T2.4.1.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NO</td>
<td id="S1.T2.4.1.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.5.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NO</td>
<td id="S1.T2.4.1.5.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.5.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.5.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
</tr>
<tr id="S1.T2.4.1.6" class="ltx_tr">
<td id="S1.T2.4.1.6.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" rowspan="4"><span id="S1.T2.4.1.6.1.1" class="ltx_text">Privacy</span></td>
<td id="S1.T2.4.1.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Infer Class Representatives</td>
<td id="S1.T2.4.1.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NO</td>
<td id="S1.T2.4.1.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.6.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.6.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NO</td>
<td id="S1.T2.4.1.6.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NO</td>
<td id="S1.T2.4.1.6.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.6.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
</tr>
<tr id="S1.T2.4.1.7" class="ltx_tr">
<td id="S1.T2.4.1.7.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Infer Membership</td>
<td id="S1.T2.4.1.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NO</td>
<td id="S1.T2.4.1.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.7.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.7.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NO</td>
<td id="S1.T2.4.1.7.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NO</td>
<td id="S1.T2.4.1.7.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.7.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
</tr>
<tr id="S1.T2.4.1.8" class="ltx_tr">
<td id="S1.T2.4.1.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Infer Properties</td>
<td id="S1.T2.4.1.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NO</td>
<td id="S1.T2.4.1.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.8.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.8.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.8.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NO</td>
<td id="S1.T2.4.1.8.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NO</td>
<td id="S1.T2.4.1.8.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.8.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">YES</td>
</tr>
<tr id="S1.T2.4.1.9" class="ltx_tr">
<td id="S1.T2.4.1.9.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Infer Training Inputs and Labels</td>
<td id="S1.T2.4.1.9.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">NO</td>
<td id="S1.T2.4.1.9.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.9.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">NO</td>
<td id="S1.T2.4.1.9.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.9.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.9.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">NO</td>
<td id="S1.T2.4.1.9.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.9.9" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">YES</td>
<td id="S1.T2.4.1.9.10" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">NO</td>
</tr>
</table>
</span></div>
</figure>
</section>
<section id="S1.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S1.SS4.4.1.1" class="ltx_text">I-D</span> </span><span id="S1.SS4.5.2" class="ltx_text ltx_font_italic">Secure FL</span>
</h3>

<div id="S1.SS4.p1" class="ltx_para">
<p id="S1.SS4.p1.1" class="ltx_p">Attacks on FL come from either the privacy perspective when a malicious participant or the central server attempts to infer the private information of a victim participant, or the robustness perspective when a malicious participant aims to compromise the global model.</p>
</div>
<div id="S1.SS4.p2" class="ltx_para">
<p id="S1.SS4.p2.1" class="ltx_p">To secure FL against privacy attacks, existing privacy-preserving methodologies in centralized machine learning have been tried to be adopted into FL, including homomorphic encryption (HE), secure multiparty computation (SMC), and differential privacy (DP). However, HE and SMC may not be applicable to large-scale FL, as they incur substantial communication and computation overhead. In aggregation-based tasks, DP requires the aggregated value to contain random noise up to a certain magnitude to ensure <math id="S1.SS4.p2.1.m1.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="S1.SS4.p2.1.m1.2a"><mrow id="S1.SS4.p2.1.m1.2.3.2" xref="S1.SS4.p2.1.m1.2.3.1.cmml"><mo stretchy="false" id="S1.SS4.p2.1.m1.2.3.2.1" xref="S1.SS4.p2.1.m1.2.3.1.cmml">(</mo><mi id="S1.SS4.p2.1.m1.1.1" xref="S1.SS4.p2.1.m1.1.1.cmml">ϵ</mi><mo id="S1.SS4.p2.1.m1.2.3.2.2" xref="S1.SS4.p2.1.m1.2.3.1.cmml">,</mo><mi id="S1.SS4.p2.1.m1.2.2" xref="S1.SS4.p2.1.m1.2.2.cmml">δ</mi><mo stretchy="false" id="S1.SS4.p2.1.m1.2.3.2.3" xref="S1.SS4.p2.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.SS4.p2.1.m1.2b"><interval closure="open" id="S1.SS4.p2.1.m1.2.3.1.cmml" xref="S1.SS4.p2.1.m1.2.3.2"><ci id="S1.SS4.p2.1.m1.1.1.cmml" xref="S1.SS4.p2.1.m1.1.1">italic-ϵ</ci><ci id="S1.SS4.p2.1.m1.2.2.cmml" xref="S1.SS4.p2.1.m1.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S1.SS4.p2.1.m1.2c">(\epsilon,\delta)</annotation></semantics></math>-DP, thus is also not ideal for FL.
The noise addition required by DP is also hard to execute in FL. In an ideal scenario where the server (aggregator) is trusted, the server can add the noise to the aggregated gradients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. However, in many real-world scenarios, the participants may not trust the central server nor each other. In this case, the participants would compete with each other, and all want to ensure Local Differential Privacy (LDP) by adding as much noise as possible to their local gradients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>. This tends to accumulate significant error at the server side. <em id="S1.SS4.p2.1.1" class="ltx_emph ltx_font_italic">Distributed Differential Privacy</em> (DDP) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> can mitigate this problem to some extent when at least a certain fraction of the participants are honest and do not conduct such malicious competition.</p>
</div>
<div id="S1.SS4.p3" class="ltx_para">
<p id="S1.SS4.p3.1" class="ltx_p">Defending FL against various robustness attacks (<span id="S1.SS4.p3.1.1" class="ltx_text ltx_font_italic">e.g.</span>, untargeted Byzantine attack, targeted backdoor attack) is an extremely challenging task. This is due to two main reasons. First, the defense can only be executed at the server side where only local gradients are available. This invalids many backdoor defense methods developed in the centralized machine learning, for example, denoising (preprocessing) methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>, backdoor sample/trigger detection methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>, <a href="#bib.bib48" title="" class="ltx_ref">48</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>, <a href="#bib.bib50" title="" class="ltx_ref">50</a>, <a href="#bib.bib51" title="" class="ltx_ref">51</a>, <a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>, robust data augmentations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>, finetuning methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>, neural attention distillation (NAD) based method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>, and more recent anti-backdoor learning method based on a sophisticated learning process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>. Second, the defense method has to be robust to both data poisoning and model poisoning attacks.
Most existing robustness defenses are gradient aggregation methods mainly developed for defending against the untargeted Byzantine attackers, such as Krum/Multi-Krum <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, AGGREGATHOR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>, Byzantine Gradient Descent (BGD) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, Median-based Gradient Descent <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, Trimmed-mean-based Gradient Descent <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> and <span id="S1.SS4.p3.1.2" class="ltx_text" style="font-size:70%;">SIGN</span>SGD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>. These defense methods have never been tested on the targeted backdoor attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>.
Dedicated defense methods against both data poisoning and model poisoning attacks have been investigated, such as norm clipping <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>, geometric median based Robust Federated Aggregation (RFA) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite> and robust learning rate <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>. For the collusion of Sybil attacks, contribution similarity  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> can be leveraged as a strategy for defense.</p>
</div>
<figure id="S1.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S1.T3.2.1.1" class="ltx_text" style="font-size:90%;">TABLE III</span>: </span><span id="S1.T3.3.2" class="ltx_text" style="font-size:90%;">A list of abbreviations used in this survey.</span></figcaption>
<div id="S1.T3.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:437.0pt;height:7472.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table id="S1.T3.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S1.T3.4.1.1" class="ltx_tr">
<td id="S1.T3.4.1.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">AI</td>
<td id="S1.T3.4.1.1.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S1.T3.4.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.4.1.1.2.1.1" class="ltx_p">Artificial Intelligence</span>
</span>
</td>
</tr>
<tr id="S1.T3.4.1.2" class="ltx_tr">
<td id="S1.T3.4.1.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">ML</td>
<td id="S1.T3.4.1.2.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S1.T3.4.1.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.4.1.2.2.1.1" class="ltx_p">Machine Learning</span>
</span>
</td>
</tr>
<tr id="S1.T3.4.1.3" class="ltx_tr">
<td id="S1.T3.4.1.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">FL</td>
<td id="S1.T3.4.1.3.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S1.T3.4.1.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.4.1.3.2.1.1" class="ltx_p">Federated Learning</span>
</span>
</td>
</tr>
<tr id="S1.T3.4.1.4" class="ltx_tr">
<td id="S1.T3.4.1.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">GDPR</td>
<td id="S1.T3.4.1.4.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S1.T3.4.1.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.4.1.4.2.1.1" class="ltx_p">General Data Protection Regulation</span>
</span>
</td>
</tr>
<tr id="S1.T3.4.1.5" class="ltx_tr">
<td id="S1.T3.4.1.5.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">I.I.D.</td>
<td id="S1.T3.4.1.5.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S1.T3.4.1.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.4.1.5.2.1.1" class="ltx_p">Independent and Identically Distributed</span>
</span>
</td>
</tr>
<tr id="S1.T3.4.1.6" class="ltx_tr">
<td id="S1.T3.4.1.6.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">IoT</td>
<td id="S1.T3.4.1.6.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S1.T3.4.1.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.4.1.6.2.1.1" class="ltx_p">Internet of Things</span>
</span>
</td>
</tr>
<tr id="S1.T3.4.1.7" class="ltx_tr">
<td id="S1.T3.4.1.7.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">HFL</td>
<td id="S1.T3.4.1.7.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S1.T3.4.1.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.4.1.7.2.1.1" class="ltx_p">Horizontally Federated Learning</span>
</span>
</td>
</tr>
<tr id="S1.T3.4.1.8" class="ltx_tr">
<td id="S1.T3.4.1.8.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">VFL</td>
<td id="S1.T3.4.1.8.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S1.T3.4.1.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.4.1.8.2.1.1" class="ltx_p">Vertically Federated Learning</span>
</span>
</td>
</tr>
<tr id="S1.T3.4.1.9" class="ltx_tr">
<td id="S1.T3.4.1.9.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">FTL</td>
<td id="S1.T3.4.1.9.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S1.T3.4.1.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.4.1.9.2.1.1" class="ltx_p">Federated Transfer Learning</span>
</span>
</td>
</tr>
<tr id="S1.T3.4.1.10" class="ltx_tr">
<td id="S1.T3.4.1.10.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">H2B</td>
<td id="S1.T3.4.1.10.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S1.T3.4.1.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.4.1.10.2.1.1" class="ltx_p">HFL to businesses</span>
</span>
</td>
</tr>
<tr id="S1.T3.4.1.11" class="ltx_tr">
<td id="S1.T3.4.1.11.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">H2C</td>
<td id="S1.T3.4.1.11.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S1.T3.4.1.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.4.1.11.2.1.1" class="ltx_p">HFL to consumers</span>
</span>
</td>
</tr>
<tr id="S1.T3.4.1.12" class="ltx_tr">
<td id="S1.T3.4.1.12.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">SGD</td>
<td id="S1.T3.4.1.12.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S1.T3.4.1.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.4.1.12.2.1.1" class="ltx_p">Stochastic Gradient Descent</span>
</span>
</td>
</tr>
<tr id="S1.T3.4.1.13" class="ltx_tr">
<td id="S1.T3.4.1.13.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">SMC</td>
<td id="S1.T3.4.1.13.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S1.T3.4.1.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.4.1.13.2.1.1" class="ltx_p">Secure Multiparty Computation</span>
</span>
</td>
</tr>
<tr id="S1.T3.4.1.14" class="ltx_tr">
<td id="S1.T3.4.1.14.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">DP</td>
<td id="S1.T3.4.1.14.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S1.T3.4.1.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.4.1.14.2.1.1" class="ltx_p">Differential Privacy</span>
</span>
</td>
</tr>
<tr id="S1.T3.4.1.15" class="ltx_tr">
<td id="S1.T3.4.1.15.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">CDP</td>
<td id="S1.T3.4.1.15.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S1.T3.4.1.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.4.1.15.2.1.1" class="ltx_p">Centralized Differential Privacy</span>
</span>
</td>
</tr>
<tr id="S1.T3.4.1.16" class="ltx_tr">
<td id="S1.T3.4.1.16.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">LDP</td>
<td id="S1.T3.4.1.16.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S1.T3.4.1.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.4.1.16.2.1.1" class="ltx_p">Local Differential Privacy</span>
</span>
</td>
</tr>
<tr id="S1.T3.4.1.17" class="ltx_tr">
<td id="S1.T3.4.1.17.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">DDP</td>
<td id="S1.T3.4.1.17.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S1.T3.4.1.17.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.4.1.17.2.1.1" class="ltx_p">Distributed Differential Privacy</span>
</span>
</td>
</tr>
<tr id="S1.T3.4.1.18" class="ltx_tr">
<td id="S1.T3.4.1.18.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">HE</td>
<td id="S1.T3.4.1.18.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S1.T3.4.1.18.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.4.1.18.2.1.1" class="ltx_p">Homomorphic Encryption</span>
</span>
</td>
</tr>
<tr id="S1.T3.4.1.19" class="ltx_tr">
<td id="S1.T3.4.1.19.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">RFA</td>
<td id="S1.T3.4.1.19.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S1.T3.4.1.19.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.4.1.19.2.1.1" class="ltx_p">Robust Federated Aggregation</span>
</span>
</td>
</tr>
<tr id="S1.T3.4.1.20" class="ltx_tr">
<td id="S1.T3.4.1.20.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">GAN</td>
<td id="S1.T3.4.1.20.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S1.T3.4.1.20.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.4.1.20.2.1.1" class="ltx_p">Generative Adversarial Network</span>
</span>
</td>
</tr>
<tr id="S1.T3.4.1.21" class="ltx_tr">
<td id="S1.T3.4.1.21.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">MIA</td>
<td id="S1.T3.4.1.21.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S1.T3.4.1.21.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.4.1.21.2.1.1" class="ltx_p">Membership Inference Attack</span>
</span>
</td>
</tr>
<tr id="S1.T3.4.1.22" class="ltx_tr">
<td id="S1.T3.4.1.22.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">AT</td>
<td id="S1.T3.4.1.22.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S1.T3.4.1.22.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.4.1.22.2.1.1" class="ltx_p">Adversarial Training</span>
</span>
</td>
</tr>
<tr id="S1.T3.4.1.23" class="ltx_tr">
<td id="S1.T3.4.1.23.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">FAT</td>
<td id="S1.T3.4.1.23.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S1.T3.4.1.23.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.4.1.23.2.1.1" class="ltx_p">Federated Adversarial Training</span>
</span>
</td>
</tr>
<tr id="S1.T3.4.1.24" class="ltx_tr">
<td id="S1.T3.4.1.24.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">API</td>
<td id="S1.T3.4.1.24.2" class="ltx_td ltx_align_justify ltx_border_b ltx_border_r ltx_border_t">
<span id="S1.T3.4.1.24.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T3.4.1.24.2.1.1" class="ltx_p">Application Programming Interface</span>
</span>
</td>
</tr>
</table>
</span></div>
</figure>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2012.06337/assets/figures/flow.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="1181" height="744" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S1.F2.3.2" class="ltx_text" style="font-size:90%;">Survey organization.</span></figcaption>
</figure>
</section>
<section id="S1.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S1.SS5.4.1.1" class="ltx_text">I-E</span> </span><span id="S1.SS5.5.2" class="ltx_text ltx_font_italic">Motivation of this Survey and Our Contribution</span>
</h3>

<div id="S1.SS5.p1" class="ltx_para">
<p id="S1.SS5.p1.1" class="ltx_p">Existing surveys on FL are mostly focused on the system or protocol design <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib60" title="" class="ltx_ref">60</a>, <a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>.
A notable number of research works have been conducted on privacy and robustness. Although these works attempt to discover the vulnerabilities of FL and aim to enhance the privacy and system robustness of FL, there are very few efforts for categorizing them in a systemic manner, and privacy and robustness threats to FL have not been systematically explored. To fill in this gap, in this paper, we have conducted an extensive survey on the recent advances in privacy and robustness threats to FL and their defenses. In particular, we focus on two specific threats initiated by insiders in FL systems: 1) privacy attacks that attempt to infer the victim participants’ private information; 2) poisoning attacks that attempt to prevent the learning of a global model, or implant triggers to control the behaviour of the global model. This article mainly surveys the literature over the past 5 years on privacy and robustness in federated learning, it can be a notable inclusion to the existing literature, helping the community better understand the state-of-the-art privacy and robustness progress in FL. The limitations and the promising use cases of the existing works in literature, and open directions for future research are also offered to identify the research gaps to address the challenges of privacy and robustness in FL. The major contributions of this survey include:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">This survey presents a comprehensive categorization of FL, and summarized threats and the corresponding protections for FL in a systematic manner.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Existing privacy and robustness attacks and defenses are well explored to help readers better understand the assumptions, principles, reasons and differences of the current progress in the domain of FL privacy and robustness.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">The conflicts between privacy and robustness, and among multiple design goals are identified; the gaps between the current works and the real scenarios in FL are summarized.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">Future research directions will assist community to rethink and improve their current designs towards robust and privacy-preserving FL of real practicality and impact. Meanwhile, it is suggested to integrate multidisciplinary goals in the system design of FL.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S1.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S1.SS6.4.1.1" class="ltx_text">I-F</span> </span><span id="S1.SS6.5.2" class="ltx_text ltx_font_italic">Survey Organization</span>
</h3>

<div id="S1.SS6.p1" class="ltx_para">
<p id="S1.SS6.p1.1" class="ltx_p">The rest of the survey is organized as follows. Before going into an in-depth discussion on privacy and robustness in FL, in Section <a href="#S2" title="II Threat Models ‣ Privacy and Robustness in Federated Learning: Attacks and Defenses" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>, we first summarize the threat models from a general perspective and discuss the customized threat models for privacy and robustness respectively. Section <a href="#S3" title="III Privacy Attacks ‣ Privacy and Robustness in Federated Learning: Attacks and Defenses" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> presents a comprehensive review of the privacy attacks in FL, particularly targeting the sensitive information (class representative, membership, properties, training inputs and labels) in HFL with homogeneous architectures. To address the corresponding privacy attacks, Section <a href="#S4" title="IV Defenses against Privacy Attacks ‣ Privacy and Robustness in Federated Learning: Attacks and Defenses" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a> lists the most representative privacy-preserving techniques and current practices that have applied these techniques in FL. Section <a href="#S5" title="V Poisoning Attacks ‣ Privacy and Robustness in Federated Learning: Attacks and Defenses" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a> shows the detailed poisoning attacks that aim to compromise system robustness, including the untargeted and targeted poisoning attacks, followed by their countermeasures in Section <a href="#S6" title="VI Defenses against Poisoning Attacks ‣ Privacy and Robustness in Federated Learning: Attacks and Defenses" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a>. From the lessons learned in this survey paper, the research gaps towards realizing trustworthy FL, along with directions for future research are provided in Section <a href="#S7" title="VII Discussions and Promising Directions ‣ Privacy and Robustness in Federated Learning: Attacks and Defenses" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VII</span></a>. Finally, concluding remarks are drawn in Section <a href="#S8" title="VIII Conclusions ‣ Privacy and Robustness in Federated Learning: Attacks and Defenses" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VIII</span></a>.</p>
</div>
<div id="S1.SS6.p2" class="ltx_para">
<p id="S1.SS6.p2.1" class="ltx_p">For better readability, we give a diagram in Fig. <a href="#S1.F2" title="Figure 2 ‣ I-D Secure FL ‣ I Introduction ‣ Privacy and Robustness in Federated Learning: Attacks and Defenses" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> showing the different aspects covered in the survey. The list of abbreviations used in this survey is provided in Table <a href="#S1.T3" title="TABLE III ‣ I-D Secure FL ‣ I Introduction ‣ Privacy and Robustness in Federated Learning: Attacks and Defenses" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>. Throughout this survey, we will interchangeably use participants/clients/users to represent the participants in FL.</p>
</div>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Threat Models</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Before reviewing attacks on FL, we first present a summary of the threat models. Generally, threat models in FL can be categorized into two types: (1) Insider v.s. Outsider; (2) Training Phase v.s. Inference Phase. These threat models apply to both the privacy and robustness. Additionally, privacy and robustness have their own threat models.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.4.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.5.2" class="ltx_text ltx_font_italic">Insider v.s. Outsider</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Attacks can be carried out by insiders and outsiders. Insider attacks include those launched by the FL server and the participants in the FL system. Outsider attacks include those launched by the eavesdroppers on the communication channel between participants and the FL server, and by users of the final FL model when it is deployed as a service.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Insider attacks are generally more dangerous than outsider attacks, as it strictly enhances the capability of the adversary. Thus, our discussion of attacks against FL will focus primarily on the insider attacks.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.4.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.5.2" class="ltx_text ltx_font_italic">Training Phase v.s. Inference Phase</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para ltx_noindent">
<p id="S2.SS2.p1.1" class="ltx_p"><span id="S2.SS2.p1.1.1" class="ltx_text ltx_font_bold">Training Phase.</span> Attacks conducted during the training phase attempt to learn, influence, or corrupt the FL model itself <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>.
During the training phase, the attacker can run data poisoning attacks to compromise the integrity of the training dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib63" title="" class="ltx_ref">63</a>, <a href="#bib.bib64" title="" class="ltx_ref">64</a>, <a href="#bib.bib65" title="" class="ltx_ref">65</a>, <a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite>, or model poisoning attacks to compromise the integrity of the learning process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>. The attacker can also launch a range of inference attacks on an individual participant’s update or on the aggregated update from all participants during training phase <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para ltx_noindent">
<p id="S2.SS2.p2.1" class="ltx_p"><span id="S2.SS2.p2.1.1" class="ltx_text ltx_font_bold">Inference Phase.</span> Attacks conducted during the inference phase are called evasion or exploratory attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite>. They generally do not alter the targeted model, instead, either trick it to produce wrong predictions (targeted/untargeted) or collect evidence about the model characteristics, causing privacy and robustness problems. The effectiveness of such attacks are largely determined by the information that is available to the adversary about the model.
Inference phase attacks can be classified into white-box attacks (<span id="S2.SS2.p2.1.2" class="ltx_text ltx_font_italic">i.e.</span>, with full access to the FL model) and black-box attacks (<span id="S2.SS2.p2.1.3" class="ltx_text ltx_font_italic">i.e.</span>, only able to query the FL model). In FL, the global model maintained by the server suffers from the same evasion attacks as in the conventional ML setting when the target model is deployed as a service. While black-box attacks may be more natural to consider in the centralized settings, the model broadcast step in FL makes the global model a white-box to any malicious participant. Thus, FL requires extra efforts to defend against white-box evasion attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS3.4.1.1" class="ltx_text">II-C</span> </span><span id="S2.SS3.5.2" class="ltx_text ltx_font_italic">Privacy: Semi-honest v.s. Malicious</span>
</h3>

<div id="S2.SS3.p1" class="ltx_para ltx_noindent">
<p id="S2.SS3.p1.1" class="ltx_p"><span id="S2.SS3.p1.1.1" class="ltx_text ltx_font_bold">Semi-honest Setting.</span> Adversaries are considered passive or honest-but-curious. They try to learn the private states of other participants without deviating from the FL protocol. The adversaries can only observe the received information, <span id="S2.SS3.p1.1.2" class="ltx_text ltx_font_italic">i.e.</span>, parameters of the global model.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para ltx_noindent">
<p id="S2.SS3.p2.1" class="ltx_p"><span id="S2.SS3.p2.1.1" class="ltx_text ltx_font_bold">Malicious Setting.</span> An active or malicious adversary tries to learn the private states of honest participants, and deviates arbitrarily from the FL protocol by modifying, re-playing, or removing messages. This setting allows the adversary to conduct particularly devastating attacks.</p>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS4.4.1.1" class="ltx_text">II-D</span> </span><span id="S2.SS4.5.2" class="ltx_text ltx_font_italic">Robustness: Untargeted v.s. Targeted</span>
</h3>

<div id="S2.SS4.p1" class="ltx_para">
<ol id="S2.I1" class="ltx_enumerate">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p">Untargeted attack: The untargeted poisoning attack aims to arbitrarily compromise the integrity of the target model. Byzantine attack is one type of the untargeted poisoning attacks that uploads arbitrarily malicious gradients to the server so as to cause the failure of the global model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib56" title="" class="ltx_ref">56</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite>.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p">Targeted attack: The targeted poisoning attack induces the model to output the target label specified by the adversary for particular testing examples, while the testing error for other testing examples is unaffected <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>.</p>
</div>
</li>
</ol>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Privacy Attacks</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.2" class="ltx_p">Although FL prevents the participants from directly sharing their private data, a series of works have demonstrated that exchanging gradients in FL can also leak sensitive information about the participants’ private data to either passive or active attackers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>, <a href="#bib.bib72" title="" class="ltx_ref">72</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite>. For example, gradients or two consecutive snapshots of the FL model parameters can leak unintended features of the participants’ training data to the adversarial participants, as deep learning models tend to recognize and remember more features of the data than needed for the main learning task <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite>. Fig. <a href="#S3.F3" title="Figure 3 ‣ III Privacy Attacks ‣ Privacy and Robustness in Federated Learning: Attacks and Defenses" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> illustrates the set of information an adversary can infer from the gradients (<span id="S3.p1.2.1" class="ltx_text ltx_font_italic">i.e.</span>, <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="\Delta\bm{w}_{1}^{t}" display="inline"><semantics id="S3.p1.1.m1.1a"><mrow id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml"><mi mathvariant="normal" id="S3.p1.1.m1.1.1.2" xref="S3.p1.1.m1.1.1.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S3.p1.1.m1.1.1.1" xref="S3.p1.1.m1.1.1.1.cmml">​</mo><msubsup id="S3.p1.1.m1.1.1.3" xref="S3.p1.1.m1.1.1.3.cmml"><mi id="S3.p1.1.m1.1.1.3.2.2" xref="S3.p1.1.m1.1.1.3.2.2.cmml">𝒘</mi><mn id="S3.p1.1.m1.1.1.3.2.3" xref="S3.p1.1.m1.1.1.3.2.3.cmml">1</mn><mi id="S3.p1.1.m1.1.1.3.3" xref="S3.p1.1.m1.1.1.3.3.cmml">t</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><apply id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1"><times id="S3.p1.1.m1.1.1.1.cmml" xref="S3.p1.1.m1.1.1.1"></times><ci id="S3.p1.1.m1.1.1.2.cmml" xref="S3.p1.1.m1.1.1.2">Δ</ci><apply id="S3.p1.1.m1.1.1.3.cmml" xref="S3.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.p1.1.m1.1.1.3.1.cmml" xref="S3.p1.1.m1.1.1.3">superscript</csymbol><apply id="S3.p1.1.m1.1.1.3.2.cmml" xref="S3.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.p1.1.m1.1.1.3.2.1.cmml" xref="S3.p1.1.m1.1.1.3">subscript</csymbol><ci id="S3.p1.1.m1.1.1.3.2.2.cmml" xref="S3.p1.1.m1.1.1.3.2.2">𝒘</ci><cn type="integer" id="S3.p1.1.m1.1.1.3.2.3.cmml" xref="S3.p1.1.m1.1.1.3.2.3">1</cn></apply><ci id="S3.p1.1.m1.1.1.3.3.cmml" xref="S3.p1.1.m1.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">\Delta\bm{w}_{1}^{t}</annotation></semantics></math>), or equivalently the difference of two successive snapshots of the model parameters (<span id="S3.p1.2.2" class="ltx_text ltx_font_italic">i.e.</span>, <math id="S3.p1.2.m2.1" class="ltx_Math" alttext="\bm{w}^{t+1}-\bm{w}^{t}" display="inline"><semantics id="S3.p1.2.m2.1a"><mrow id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml"><msup id="S3.p1.2.m2.1.1.2" xref="S3.p1.2.m2.1.1.2.cmml"><mi id="S3.p1.2.m2.1.1.2.2" xref="S3.p1.2.m2.1.1.2.2.cmml">𝒘</mi><mrow id="S3.p1.2.m2.1.1.2.3" xref="S3.p1.2.m2.1.1.2.3.cmml"><mi id="S3.p1.2.m2.1.1.2.3.2" xref="S3.p1.2.m2.1.1.2.3.2.cmml">t</mi><mo id="S3.p1.2.m2.1.1.2.3.1" xref="S3.p1.2.m2.1.1.2.3.1.cmml">+</mo><mn id="S3.p1.2.m2.1.1.2.3.3" xref="S3.p1.2.m2.1.1.2.3.3.cmml">1</mn></mrow></msup><mo id="S3.p1.2.m2.1.1.1" xref="S3.p1.2.m2.1.1.1.cmml">−</mo><msup id="S3.p1.2.m2.1.1.3" xref="S3.p1.2.m2.1.1.3.cmml"><mi id="S3.p1.2.m2.1.1.3.2" xref="S3.p1.2.m2.1.1.3.2.cmml">𝒘</mi><mi id="S3.p1.2.m2.1.1.3.3" xref="S3.p1.2.m2.1.1.3.3.cmml">t</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><apply id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1"><minus id="S3.p1.2.m2.1.1.1.cmml" xref="S3.p1.2.m2.1.1.1"></minus><apply id="S3.p1.2.m2.1.1.2.cmml" xref="S3.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.2.1.cmml" xref="S3.p1.2.m2.1.1.2">superscript</csymbol><ci id="S3.p1.2.m2.1.1.2.2.cmml" xref="S3.p1.2.m2.1.1.2.2">𝒘</ci><apply id="S3.p1.2.m2.1.1.2.3.cmml" xref="S3.p1.2.m2.1.1.2.3"><plus id="S3.p1.2.m2.1.1.2.3.1.cmml" xref="S3.p1.2.m2.1.1.2.3.1"></plus><ci id="S3.p1.2.m2.1.1.2.3.2.cmml" xref="S3.p1.2.m2.1.1.2.3.2">𝑡</ci><cn type="integer" id="S3.p1.2.m2.1.1.2.3.3.cmml" xref="S3.p1.2.m2.1.1.2.3.3">1</cn></apply></apply><apply id="S3.p1.2.m2.1.1.3.cmml" xref="S3.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.3.1.cmml" xref="S3.p1.2.m2.1.1.3">superscript</csymbol><ci id="S3.p1.2.m2.1.1.3.2.cmml" xref="S3.p1.2.m2.1.1.3.2">𝒘</ci><ci id="S3.p1.2.m2.1.1.3.3.cmml" xref="S3.p1.2.m2.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">\bm{w}^{t+1}-\bm{w}^{t}</annotation></semantics></math>).</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2012.06337/assets/figures/inference_FL_updated.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="1167" height="469" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.3.2" class="ltx_text" style="font-size:90%;">A demo of privacy leakage in FL. Attacker can infer various private information about the victim participant from the received gradients or the snapshot of the FL model parameters.</span></figcaption>
</figure>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">The reason why gradients can cause privacy leakage is that the gradients are derived from the participants’ private training data, and a learning model can be considered as a representation of the high-level statistics of the dataset it was trained on <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite>.
In deep learning models, gradients of a given layer are computed based on the layer’s features and the error from the layer after (<span id="S3.p2.1.1" class="ltx_text ltx_font_italic">i.e.</span>, backpropagation). In the case of sequential fully-connected layers, the gradients of the weights are the inner products of the current layer’s features and the error from the layer after. Similarly, for a convolutional layer, the gradients of the weights are convolutions of the layer’s features and the error from the layer after <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. Consequently, observations of gradients can be used to infer a significant amount of private information, such as class representatives, membership and properties of a subset of the training data. Even worse, an attacker can infer labels from the shared gradients and recover the original training samples without any prior knowledge about the training data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. Next, we detail the potential privacy leakage of FL according to the type of the sensitive information that the attacker is targeting at.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.4.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.5.2" class="ltx_text ltx_font_italic">Inferring Class Representatives</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Hitaj <span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite> firstly devised an active inference attack called <em id="S3.SS1.p1.1.2" class="ltx_emph ltx_font_italic">Generative Adversarial Networks</em> (GAN) attack against deep FL models. In this attack, a malicious participant can intentionally compromise any other participant.
The GAN attack exploits the real-time nature of the FL learning process which allows the adversarial participant to train a GAN to generate prototypical samples of the targeted private training data. The generated samples appear to come from the same distribution as the training data. Hence, GAN attack is not targeted to reconstruct the exact training inputs, but only the class representatives. It should be noted that GAN attack assumes the entire training corpus for a given class comes from a single participant, which means the GAN-constructed representatives are similar to the training data only when all class members are similar. This resembles model inversion attacks in the centralized ML settings <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite>. Note that these assumptions may be less practical in FL. Since GAN attack requires a substantial amount of computational resources to train the GAN model, it is less suitable for H2C scenarios.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.4.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.5.2" class="ltx_text ltx_font_italic">Inferring Membership</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Given an exact data point, membership inference attacks (MIA) aim to determine if it was used to train the model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite>. For example, an attacker can infer whether a specific patient profile was used to train a classifier associated with a certain disease. FL opens new possibilities for such attacks. In FL, the adversary can infer if a particular sample belongs to the private training data of a particular participant (if the target update is from a single participant) or any participant (if the target update is the aggregate). For example, during FL model training, the non-zero gradients of the embedding layer of a deep natural language processing model trained on text data can reveal which words are in the training batches of the honest participants <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">Attackers in a FL system can conduct both active and passive membership inference attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. In the passive case, the attacker observes the updated model parameters and performs inference without modifying the learning process. In the active case, the attacker can tamper with the FL model training protocol and perform a more powerful attack against other participants. For instance, the attacker may share malicious updates and trick the FL model to expose more information about other participants’ local data. One such attack is the gradient ascent attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite>, where the attacker runs gradient ascent on a target data sample and observes whether its increased loss can be drastically reduced in the next communication round, if so, the sample is very likely to be in the training set. This attack can be applied on a batch of target data samples all at the same time <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.4.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.5.2" class="ltx_text ltx_font_italic">Inferring Properties</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">An adversary can launch both passive and active property inference attacks to infer certain properties of other participants’ training data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. Property inference attacks assume that the adversary has auxiliary training data that are correctly labelled with the target property. A passive adversary can only observe or eavesdrop the gradients and perform inference by training a binary property classifier. An active adversary can exploit multi-task learning to trick the FL model into learning a better separation between data with and without the target property so as to extract more information. An adversarial participant can also infer when a property appears or disappears in the training data (<span id="S3.SS3.p1.1.1" class="ltx_text ltx_font_italic">e.g.</span>, identifying when a person first appears in the photos used to train a gender classifier). The assumption of auxiliary training data in property inference attacks may limit its applicability in H2C.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS4.4.1.1" class="ltx_text">III-D</span> </span><span id="S3.SS4.5.2" class="ltx_text ltx_font_italic">Inferring Training Inputs and Labels</span>
</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">One recent work called <em id="S3.SS4.p1.1.1" class="ltx_emph ltx_font_italic">Deep Leakage from Gradient</em> (DLG) proposes an optimization algorithm to extract both the training inputs and the labels <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. This attack is much stronger than previous approaches. It can accurately recover the raw images and texts used to train a deep learning model. In a follow-up work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>, an analytical approach called <em id="S3.SS4.p1.1.2" class="ltx_emph ltx_font_italic">Improved Deep Leakage from Gradient</em> (iDLG) was proposed to extract labels based on the shared gradients and an exploration of the correlation between the labels and the signs of the gradients. iDLG can be applied to attack any differentiable models trained with cross-entropy loss and one-hot labels, which is a typical setting for classification tasks.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.1" class="ltx_p">In summary, inference attacks generally assume that the adversaries possess sophisticated technical capabilities and unlimited computational resources. Moreover, most attacks assume that the adversarial participants can be selected (to update the global model) in many rounds of the FL training process. In FL, these assumptions are generally not practical in H2C scenarios, but more likely happen in H2B scenarios. These inference attacks highlight the need for gradient protection in FL, possibly through various privacy-preserving mechanisms <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> detailed in Section <a href="#S4" title="IV Defenses against Privacy Attacks ‣ Privacy and Robustness in Federated Learning: Attacks and Defenses" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Defenses against Privacy Attacks</span>
</h2>

<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.2.1.1" class="ltx_text" style="font-size:90%;">TABLE IV</span>: </span><span id="S4.T4.3.2" class="ltx_text" style="font-size:90%;">Privacy-preserving Techniques for FL.</span></figcaption>
<table id="S4.T4.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T4.4.1" class="ltx_tr">
<td id="S4.T4.4.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" colspan="2"><span id="S4.T4.4.1.1.1" class="ltx_text ltx_font_bold">Privacy-preserving Techniques</span></td>
<td id="S4.T4.4.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T4.4.1.2.1" class="ltx_text ltx_font_bold">Existing Works</span></td>
</tr>
<tr id="S4.T4.4.2" class="ltx_tr">
<td id="S4.T4.4.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" colspan="2">Homomorphic Encryption</td>
<td id="S4.T4.4.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>, <a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite>
</td>
</tr>
<tr id="S4.T4.4.3" class="ltx_tr">
<td id="S4.T4.4.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" rowspan="3"><span id="S4.T4.4.3.1.1" class="ltx_text"><span id="S4.T4.4.3.1.1.1" class="ltx_text"></span> <span id="S4.T4.4.3.1.1.2" class="ltx_text">
<span id="S4.T4.4.3.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T4.4.3.1.1.2.1.1" class="ltx_tr">
<span id="S4.T4.4.3.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">DP</span></span>
</span></span> <span id="S4.T4.4.3.1.1.3" class="ltx_text"></span></span></td>
<td id="S4.T4.4.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">CDP</td>
<td id="S4.T4.4.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>
</td>
</tr>
<tr id="S4.T4.4.4" class="ltx_tr">
<td id="S4.T4.4.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">LDP</td>
<td id="S4.T4.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>, <a href="#bib.bib83" title="" class="ltx_ref">83</a>, <a href="#bib.bib84" title="" class="ltx_ref">84</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib85" title="" class="ltx_ref">85</a>, <a href="#bib.bib86" title="" class="ltx_ref">86</a>, <a href="#bib.bib87" title="" class="ltx_ref">87</a>]</cite>
</td>
</tr>
<tr id="S4.T4.4.5" class="ltx_tr">
<td id="S4.T4.4.5.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">DDP+Cryptography</td>
<td id="S4.T4.4.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite>
</td>
</tr>
<tr id="S4.T4.4.6" class="ltx_tr">
<td id="S4.T4.4.6.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" colspan="2">Secure Multiparty Computation</td>
<td id="S4.T4.4.6.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib89" title="" class="ltx_ref">89</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>
</td>
</tr>
</table>
</figure>
<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">While privacy preservation has been extensively studied in the machine learning community, privacy preservation in federated learning can be more challenging due to the sporadic access to power and network connectivity, statistical heterogeneity in the data, etc. Existing works in privacy-preserving federated learning are mostly developed based on the well-known privacy-preserving techniques, including: (1) <em id="S4.p1.1.1" class="ltx_emph ltx_font_italic">homomorphic encryption</em> (HE), such as Paillier <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib90" title="" class="ltx_ref">90</a>]</cite>, Elgamal <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite> and Brakerski-Gentry-Vaikuntanathan cryptosystems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite>; (2) <em id="S4.p1.1.2" class="ltx_emph ltx_font_italic">Secure Multiparty Computation</em> (SMC), such as garbled circuits <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib93" title="" class="ltx_ref">93</a>]</cite> and secret sharing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>]</cite>; and (3) <em id="S4.p1.1.3" class="ltx_emph ltx_font_italic">differential privacy</em> (DP) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>, <a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite>. A concise summary of privacy-preserving techniques is listed in Table <a href="#S4.T4" title="TABLE IV ‣ IV Defenses against Privacy Attacks ‣ Privacy and Robustness in Federated Learning: Attacks and Defenses" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.4.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.5.2" class="ltx_text ltx_font_italic">Privacy Preservation through Homomorphic Encryption</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">A homomorphic encryption scheme allows arithmetic operations to be directly performed on ciphertexts, which is equivalent to a specific linear algebraic manipulation of the plaintext.
Existing homomorphic encryption techniques can be categorized into: 1) fully homomorphic encryption, 2) somewhat homomorphic encryption, and 3) partially homomorphic encryption. Fully homomorphic encryption can support arbitrary computation on ciphertexts, but is less efficient <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite>. On the other hand, somewhat homomorphic encryption and partially homomorphic encryption are more efficient but are specified by a limited number of operations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>, <a href="#bib.bib98" title="" class="ltx_ref">98</a>, <a href="#bib.bib91" title="" class="ltx_ref">91</a>, <a href="#bib.bib90" title="" class="ltx_ref">90</a>]</cite>. Partially homomorphic encryption schemes are more widely used in practice, including RSA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite>, El Gamal <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite>, Paillier <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib90" title="" class="ltx_ref">90</a>]</cite>, etc.
The homomorphic properties can be described as:</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<table id="S4.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.Ex1.m1.1" class="ltx_Math" alttext="E_{pk}(m_{1}+m_{2})=c_{1}\oplus c_{2}\\
" display="block"><semantics id="S4.Ex1.m1.1a"><mrow id="S4.Ex1.m1.1.1" xref="S4.Ex1.m1.1.1.cmml"><mrow id="S4.Ex1.m1.1.1.1" xref="S4.Ex1.m1.1.1.1.cmml"><msub id="S4.Ex1.m1.1.1.1.3" xref="S4.Ex1.m1.1.1.1.3.cmml"><mi id="S4.Ex1.m1.1.1.1.3.2" xref="S4.Ex1.m1.1.1.1.3.2.cmml">E</mi><mrow id="S4.Ex1.m1.1.1.1.3.3" xref="S4.Ex1.m1.1.1.1.3.3.cmml"><mi id="S4.Ex1.m1.1.1.1.3.3.2" xref="S4.Ex1.m1.1.1.1.3.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.1.1.1.3.3.1" xref="S4.Ex1.m1.1.1.1.3.3.1.cmml">​</mo><mi id="S4.Ex1.m1.1.1.1.3.3.3" xref="S4.Ex1.m1.1.1.1.3.3.3.cmml">k</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.1.1.1.2" xref="S4.Ex1.m1.1.1.1.2.cmml">​</mo><mrow id="S4.Ex1.m1.1.1.1.1.1" xref="S4.Ex1.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.Ex1.m1.1.1.1.1.1.2" xref="S4.Ex1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.Ex1.m1.1.1.1.1.1.1" xref="S4.Ex1.m1.1.1.1.1.1.1.cmml"><msub id="S4.Ex1.m1.1.1.1.1.1.1.2" xref="S4.Ex1.m1.1.1.1.1.1.1.2.cmml"><mi id="S4.Ex1.m1.1.1.1.1.1.1.2.2" xref="S4.Ex1.m1.1.1.1.1.1.1.2.2.cmml">m</mi><mn id="S4.Ex1.m1.1.1.1.1.1.1.2.3" xref="S4.Ex1.m1.1.1.1.1.1.1.2.3.cmml">1</mn></msub><mo id="S4.Ex1.m1.1.1.1.1.1.1.1" xref="S4.Ex1.m1.1.1.1.1.1.1.1.cmml">+</mo><msub id="S4.Ex1.m1.1.1.1.1.1.1.3" xref="S4.Ex1.m1.1.1.1.1.1.1.3.cmml"><mi id="S4.Ex1.m1.1.1.1.1.1.1.3.2" xref="S4.Ex1.m1.1.1.1.1.1.1.3.2.cmml">m</mi><mn id="S4.Ex1.m1.1.1.1.1.1.1.3.3" xref="S4.Ex1.m1.1.1.1.1.1.1.3.3.cmml">2</mn></msub></mrow><mo stretchy="false" id="S4.Ex1.m1.1.1.1.1.1.3" xref="S4.Ex1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.Ex1.m1.1.1.2" xref="S4.Ex1.m1.1.1.2.cmml">=</mo><mrow id="S4.Ex1.m1.1.1.3" xref="S4.Ex1.m1.1.1.3.cmml"><msub id="S4.Ex1.m1.1.1.3.2" xref="S4.Ex1.m1.1.1.3.2.cmml"><mi id="S4.Ex1.m1.1.1.3.2.2" xref="S4.Ex1.m1.1.1.3.2.2.cmml">c</mi><mn id="S4.Ex1.m1.1.1.3.2.3" xref="S4.Ex1.m1.1.1.3.2.3.cmml">1</mn></msub><mo id="S4.Ex1.m1.1.1.3.1" xref="S4.Ex1.m1.1.1.3.1.cmml">⊕</mo><msub id="S4.Ex1.m1.1.1.3.3" xref="S4.Ex1.m1.1.1.3.3.cmml"><mi id="S4.Ex1.m1.1.1.3.3.2" xref="S4.Ex1.m1.1.1.3.3.2.cmml">c</mi><mn id="S4.Ex1.m1.1.1.3.3.3" xref="S4.Ex1.m1.1.1.3.3.3.cmml">2</mn></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex1.m1.1b"><apply id="S4.Ex1.m1.1.1.cmml" xref="S4.Ex1.m1.1.1"><eq id="S4.Ex1.m1.1.1.2.cmml" xref="S4.Ex1.m1.1.1.2"></eq><apply id="S4.Ex1.m1.1.1.1.cmml" xref="S4.Ex1.m1.1.1.1"><times id="S4.Ex1.m1.1.1.1.2.cmml" xref="S4.Ex1.m1.1.1.1.2"></times><apply id="S4.Ex1.m1.1.1.1.3.cmml" xref="S4.Ex1.m1.1.1.1.3"><csymbol cd="ambiguous" id="S4.Ex1.m1.1.1.1.3.1.cmml" xref="S4.Ex1.m1.1.1.1.3">subscript</csymbol><ci id="S4.Ex1.m1.1.1.1.3.2.cmml" xref="S4.Ex1.m1.1.1.1.3.2">𝐸</ci><apply id="S4.Ex1.m1.1.1.1.3.3.cmml" xref="S4.Ex1.m1.1.1.1.3.3"><times id="S4.Ex1.m1.1.1.1.3.3.1.cmml" xref="S4.Ex1.m1.1.1.1.3.3.1"></times><ci id="S4.Ex1.m1.1.1.1.3.3.2.cmml" xref="S4.Ex1.m1.1.1.1.3.3.2">𝑝</ci><ci id="S4.Ex1.m1.1.1.1.3.3.3.cmml" xref="S4.Ex1.m1.1.1.1.3.3.3">𝑘</ci></apply></apply><apply id="S4.Ex1.m1.1.1.1.1.1.1.cmml" xref="S4.Ex1.m1.1.1.1.1.1"><plus id="S4.Ex1.m1.1.1.1.1.1.1.1.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.1"></plus><apply id="S4.Ex1.m1.1.1.1.1.1.1.2.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.Ex1.m1.1.1.1.1.1.1.2.1.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.Ex1.m1.1.1.1.1.1.1.2.2.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.2.2">𝑚</ci><cn type="integer" id="S4.Ex1.m1.1.1.1.1.1.1.2.3.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.2.3">1</cn></apply><apply id="S4.Ex1.m1.1.1.1.1.1.1.3.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.Ex1.m1.1.1.1.1.1.1.3.1.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.Ex1.m1.1.1.1.1.1.1.3.2.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.3.2">𝑚</ci><cn type="integer" id="S4.Ex1.m1.1.1.1.1.1.1.3.3.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.3.3">2</cn></apply></apply></apply><apply id="S4.Ex1.m1.1.1.3.cmml" xref="S4.Ex1.m1.1.1.3"><csymbol cd="latexml" id="S4.Ex1.m1.1.1.3.1.cmml" xref="S4.Ex1.m1.1.1.3.1">direct-sum</csymbol><apply id="S4.Ex1.m1.1.1.3.2.cmml" xref="S4.Ex1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S4.Ex1.m1.1.1.3.2.1.cmml" xref="S4.Ex1.m1.1.1.3.2">subscript</csymbol><ci id="S4.Ex1.m1.1.1.3.2.2.cmml" xref="S4.Ex1.m1.1.1.3.2.2">𝑐</ci><cn type="integer" id="S4.Ex1.m1.1.1.3.2.3.cmml" xref="S4.Ex1.m1.1.1.3.2.3">1</cn></apply><apply id="S4.Ex1.m1.1.1.3.3.cmml" xref="S4.Ex1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S4.Ex1.m1.1.1.3.3.1.cmml" xref="S4.Ex1.m1.1.1.3.3">subscript</csymbol><ci id="S4.Ex1.m1.1.1.3.3.2.cmml" xref="S4.Ex1.m1.1.1.3.3.2">𝑐</ci><cn type="integer" id="S4.Ex1.m1.1.1.3.3.3.cmml" xref="S4.Ex1.m1.1.1.3.3.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex1.m1.1c">E_{pk}(m_{1}+m_{2})=c_{1}\oplus c_{2}\\
</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<table id="S4.Ex2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.Ex2.m1.1" class="ltx_Math" alttext="E_{pk}(a\cdot m_{1})=a\otimes c_{1}" display="block"><semantics id="S4.Ex2.m1.1a"><mrow id="S4.Ex2.m1.1.1" xref="S4.Ex2.m1.1.1.cmml"><mrow id="S4.Ex2.m1.1.1.1" xref="S4.Ex2.m1.1.1.1.cmml"><msub id="S4.Ex2.m1.1.1.1.3" xref="S4.Ex2.m1.1.1.1.3.cmml"><mi id="S4.Ex2.m1.1.1.1.3.2" xref="S4.Ex2.m1.1.1.1.3.2.cmml">E</mi><mrow id="S4.Ex2.m1.1.1.1.3.3" xref="S4.Ex2.m1.1.1.1.3.3.cmml"><mi id="S4.Ex2.m1.1.1.1.3.3.2" xref="S4.Ex2.m1.1.1.1.3.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.Ex2.m1.1.1.1.3.3.1" xref="S4.Ex2.m1.1.1.1.3.3.1.cmml">​</mo><mi id="S4.Ex2.m1.1.1.1.3.3.3" xref="S4.Ex2.m1.1.1.1.3.3.3.cmml">k</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.Ex2.m1.1.1.1.2" xref="S4.Ex2.m1.1.1.1.2.cmml">​</mo><mrow id="S4.Ex2.m1.1.1.1.1.1" xref="S4.Ex2.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.Ex2.m1.1.1.1.1.1.2" xref="S4.Ex2.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.Ex2.m1.1.1.1.1.1.1" xref="S4.Ex2.m1.1.1.1.1.1.1.cmml"><mi id="S4.Ex2.m1.1.1.1.1.1.1.2" xref="S4.Ex2.m1.1.1.1.1.1.1.2.cmml">a</mi><mo lspace="0.222em" rspace="0.222em" id="S4.Ex2.m1.1.1.1.1.1.1.1" xref="S4.Ex2.m1.1.1.1.1.1.1.1.cmml">⋅</mo><msub id="S4.Ex2.m1.1.1.1.1.1.1.3" xref="S4.Ex2.m1.1.1.1.1.1.1.3.cmml"><mi id="S4.Ex2.m1.1.1.1.1.1.1.3.2" xref="S4.Ex2.m1.1.1.1.1.1.1.3.2.cmml">m</mi><mn id="S4.Ex2.m1.1.1.1.1.1.1.3.3" xref="S4.Ex2.m1.1.1.1.1.1.1.3.3.cmml">1</mn></msub></mrow><mo stretchy="false" id="S4.Ex2.m1.1.1.1.1.1.3" xref="S4.Ex2.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.Ex2.m1.1.1.2" xref="S4.Ex2.m1.1.1.2.cmml">=</mo><mrow id="S4.Ex2.m1.1.1.3" xref="S4.Ex2.m1.1.1.3.cmml"><mi id="S4.Ex2.m1.1.1.3.2" xref="S4.Ex2.m1.1.1.3.2.cmml">a</mi><mo lspace="0.222em" rspace="0.222em" id="S4.Ex2.m1.1.1.3.1" xref="S4.Ex2.m1.1.1.3.1.cmml">⊗</mo><msub id="S4.Ex2.m1.1.1.3.3" xref="S4.Ex2.m1.1.1.3.3.cmml"><mi id="S4.Ex2.m1.1.1.3.3.2" xref="S4.Ex2.m1.1.1.3.3.2.cmml">c</mi><mn id="S4.Ex2.m1.1.1.3.3.3" xref="S4.Ex2.m1.1.1.3.3.3.cmml">1</mn></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex2.m1.1b"><apply id="S4.Ex2.m1.1.1.cmml" xref="S4.Ex2.m1.1.1"><eq id="S4.Ex2.m1.1.1.2.cmml" xref="S4.Ex2.m1.1.1.2"></eq><apply id="S4.Ex2.m1.1.1.1.cmml" xref="S4.Ex2.m1.1.1.1"><times id="S4.Ex2.m1.1.1.1.2.cmml" xref="S4.Ex2.m1.1.1.1.2"></times><apply id="S4.Ex2.m1.1.1.1.3.cmml" xref="S4.Ex2.m1.1.1.1.3"><csymbol cd="ambiguous" id="S4.Ex2.m1.1.1.1.3.1.cmml" xref="S4.Ex2.m1.1.1.1.3">subscript</csymbol><ci id="S4.Ex2.m1.1.1.1.3.2.cmml" xref="S4.Ex2.m1.1.1.1.3.2">𝐸</ci><apply id="S4.Ex2.m1.1.1.1.3.3.cmml" xref="S4.Ex2.m1.1.1.1.3.3"><times id="S4.Ex2.m1.1.1.1.3.3.1.cmml" xref="S4.Ex2.m1.1.1.1.3.3.1"></times><ci id="S4.Ex2.m1.1.1.1.3.3.2.cmml" xref="S4.Ex2.m1.1.1.1.3.3.2">𝑝</ci><ci id="S4.Ex2.m1.1.1.1.3.3.3.cmml" xref="S4.Ex2.m1.1.1.1.3.3.3">𝑘</ci></apply></apply><apply id="S4.Ex2.m1.1.1.1.1.1.1.cmml" xref="S4.Ex2.m1.1.1.1.1.1"><ci id="S4.Ex2.m1.1.1.1.1.1.1.1.cmml" xref="S4.Ex2.m1.1.1.1.1.1.1.1">⋅</ci><ci id="S4.Ex2.m1.1.1.1.1.1.1.2.cmml" xref="S4.Ex2.m1.1.1.1.1.1.1.2">𝑎</ci><apply id="S4.Ex2.m1.1.1.1.1.1.1.3.cmml" xref="S4.Ex2.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.Ex2.m1.1.1.1.1.1.1.3.1.cmml" xref="S4.Ex2.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.Ex2.m1.1.1.1.1.1.1.3.2.cmml" xref="S4.Ex2.m1.1.1.1.1.1.1.3.2">𝑚</ci><cn type="integer" id="S4.Ex2.m1.1.1.1.1.1.1.3.3.cmml" xref="S4.Ex2.m1.1.1.1.1.1.1.3.3">1</cn></apply></apply></apply><apply id="S4.Ex2.m1.1.1.3.cmml" xref="S4.Ex2.m1.1.1.3"><csymbol cd="latexml" id="S4.Ex2.m1.1.1.3.1.cmml" xref="S4.Ex2.m1.1.1.3.1">tensor-product</csymbol><ci id="S4.Ex2.m1.1.1.3.2.cmml" xref="S4.Ex2.m1.1.1.3.2">𝑎</ci><apply id="S4.Ex2.m1.1.1.3.3.cmml" xref="S4.Ex2.m1.1.1.3.3"><csymbol cd="ambiguous" id="S4.Ex2.m1.1.1.3.3.1.cmml" xref="S4.Ex2.m1.1.1.3.3">subscript</csymbol><ci id="S4.Ex2.m1.1.1.3.3.2.cmml" xref="S4.Ex2.m1.1.1.3.3.2">𝑐</ci><cn type="integer" id="S4.Ex2.m1.1.1.3.3.3.cmml" xref="S4.Ex2.m1.1.1.3.3.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex2.m1.1c">E_{pk}(a\cdot m_{1})=a\otimes c_{1}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S4.SS1.p2.7" class="ltx_p">where <math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="a" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mi id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><ci id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">𝑎</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">a</annotation></semantics></math> is a constant, <math id="S4.SS1.p2.2.m2.1" class="ltx_Math" alttext="m_{1}" display="inline"><semantics id="S4.SS1.p2.2.m2.1a"><msub id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml"><mi id="S4.SS1.p2.2.m2.1.1.2" xref="S4.SS1.p2.2.m2.1.1.2.cmml">m</mi><mn id="S4.SS1.p2.2.m2.1.1.3" xref="S4.SS1.p2.2.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><apply id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.2.m2.1.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1">subscript</csymbol><ci id="S4.SS1.p2.2.m2.1.1.2.cmml" xref="S4.SS1.p2.2.m2.1.1.2">𝑚</ci><cn type="integer" id="S4.SS1.p2.2.m2.1.1.3.cmml" xref="S4.SS1.p2.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">m_{1}</annotation></semantics></math>, <math id="S4.SS1.p2.3.m3.1" class="ltx_Math" alttext="m_{2}" display="inline"><semantics id="S4.SS1.p2.3.m3.1a"><msub id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml"><mi id="S4.SS1.p2.3.m3.1.1.2" xref="S4.SS1.p2.3.m3.1.1.2.cmml">m</mi><mn id="S4.SS1.p2.3.m3.1.1.3" xref="S4.SS1.p2.3.m3.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><apply id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.3.m3.1.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.p2.3.m3.1.1.2.cmml" xref="S4.SS1.p2.3.m3.1.1.2">𝑚</ci><cn type="integer" id="S4.SS1.p2.3.m3.1.1.3.cmml" xref="S4.SS1.p2.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">m_{2}</annotation></semantics></math> are the plaintexts that need to be encrypted, <math id="S4.SS1.p2.4.m4.1" class="ltx_Math" alttext="c_{1}" display="inline"><semantics id="S4.SS1.p2.4.m4.1a"><msub id="S4.SS1.p2.4.m4.1.1" xref="S4.SS1.p2.4.m4.1.1.cmml"><mi id="S4.SS1.p2.4.m4.1.1.2" xref="S4.SS1.p2.4.m4.1.1.2.cmml">c</mi><mn id="S4.SS1.p2.4.m4.1.1.3" xref="S4.SS1.p2.4.m4.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.4.m4.1b"><apply id="S4.SS1.p2.4.m4.1.1.cmml" xref="S4.SS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.4.m4.1.1.1.cmml" xref="S4.SS1.p2.4.m4.1.1">subscript</csymbol><ci id="S4.SS1.p2.4.m4.1.1.2.cmml" xref="S4.SS1.p2.4.m4.1.1.2">𝑐</ci><cn type="integer" id="S4.SS1.p2.4.m4.1.1.3.cmml" xref="S4.SS1.p2.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.4.m4.1c">c_{1}</annotation></semantics></math>, <math id="S4.SS1.p2.5.m5.1" class="ltx_Math" alttext="c_{2}" display="inline"><semantics id="S4.SS1.p2.5.m5.1a"><msub id="S4.SS1.p2.5.m5.1.1" xref="S4.SS1.p2.5.m5.1.1.cmml"><mi id="S4.SS1.p2.5.m5.1.1.2" xref="S4.SS1.p2.5.m5.1.1.2.cmml">c</mi><mn id="S4.SS1.p2.5.m5.1.1.3" xref="S4.SS1.p2.5.m5.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.5.m5.1b"><apply id="S4.SS1.p2.5.m5.1.1.cmml" xref="S4.SS1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.5.m5.1.1.1.cmml" xref="S4.SS1.p2.5.m5.1.1">subscript</csymbol><ci id="S4.SS1.p2.5.m5.1.1.2.cmml" xref="S4.SS1.p2.5.m5.1.1.2">𝑐</ci><cn type="integer" id="S4.SS1.p2.5.m5.1.1.3.cmml" xref="S4.SS1.p2.5.m5.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.5.m5.1c">c_{2}</annotation></semantics></math> are the ciphertext of <math id="S4.SS1.p2.6.m6.1" class="ltx_Math" alttext="m_{1}" display="inline"><semantics id="S4.SS1.p2.6.m6.1a"><msub id="S4.SS1.p2.6.m6.1.1" xref="S4.SS1.p2.6.m6.1.1.cmml"><mi id="S4.SS1.p2.6.m6.1.1.2" xref="S4.SS1.p2.6.m6.1.1.2.cmml">m</mi><mn id="S4.SS1.p2.6.m6.1.1.3" xref="S4.SS1.p2.6.m6.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.6.m6.1b"><apply id="S4.SS1.p2.6.m6.1.1.cmml" xref="S4.SS1.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.6.m6.1.1.1.cmml" xref="S4.SS1.p2.6.m6.1.1">subscript</csymbol><ci id="S4.SS1.p2.6.m6.1.1.2.cmml" xref="S4.SS1.p2.6.m6.1.1.2">𝑚</ci><cn type="integer" id="S4.SS1.p2.6.m6.1.1.3.cmml" xref="S4.SS1.p2.6.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.6.m6.1c">m_{1}</annotation></semantics></math>, <math id="S4.SS1.p2.7.m7.1" class="ltx_Math" alttext="m_{2}" display="inline"><semantics id="S4.SS1.p2.7.m7.1a"><msub id="S4.SS1.p2.7.m7.1.1" xref="S4.SS1.p2.7.m7.1.1.cmml"><mi id="S4.SS1.p2.7.m7.1.1.2" xref="S4.SS1.p2.7.m7.1.1.2.cmml">m</mi><mn id="S4.SS1.p2.7.m7.1.1.3" xref="S4.SS1.p2.7.m7.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.7.m7.1b"><apply id="S4.SS1.p2.7.m7.1.1.cmml" xref="S4.SS1.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.7.m7.1.1.1.cmml" xref="S4.SS1.p2.7.m7.1.1">subscript</csymbol><ci id="S4.SS1.p2.7.m7.1.1.2.cmml" xref="S4.SS1.p2.7.m7.1.1.2">𝑚</ci><cn type="integer" id="S4.SS1.p2.7.m7.1.1.3.cmml" xref="S4.SS1.p2.7.m7.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.7.m7.1c">m_{2}</annotation></semantics></math> respectively.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.3" class="ltx_p">Homomorphic encryption is widely used and is especially useful for securing the learning process by computing on encrypted data. However, doing arithmetic on the encrypted numbers comes at a cost of memory and processing time. For example, with Paillier encryption scheme, the encryption of an encoded floating-point number (whether single or double precision) is <math id="S4.SS1.p3.1.m1.1" class="ltx_Math" alttext="2m" display="inline"><semantics id="S4.SS1.p3.1.m1.1a"><mrow id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml"><mn id="S4.SS1.p3.1.m1.1.1.2" xref="S4.SS1.p3.1.m1.1.1.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S4.SS1.p3.1.m1.1.1.1" xref="S4.SS1.p3.1.m1.1.1.1.cmml">​</mo><mi id="S4.SS1.p3.1.m1.1.1.3" xref="S4.SS1.p3.1.m1.1.1.3.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><apply id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1"><times id="S4.SS1.p3.1.m1.1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1.1"></times><cn type="integer" id="S4.SS1.p3.1.m1.1.1.2.cmml" xref="S4.SS1.p3.1.m1.1.1.2">2</cn><ci id="S4.SS1.p3.1.m1.1.1.3.cmml" xref="S4.SS1.p3.1.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">2m</annotation></semantics></math> bits long, where <math id="S4.SS1.p3.2.m2.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S4.SS1.p3.2.m2.1a"><mi id="S4.SS1.p3.2.m2.1.1" xref="S4.SS1.p3.2.m2.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.2.m2.1b"><ci id="S4.SS1.p3.2.m2.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.2.m2.1c">m</annotation></semantics></math> is typically at least 1024 and the addition of two encrypted numbers is 2<math id="S4.SS1.p3.3.m3.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.SS1.p3.3.m3.1a"><mo id="S4.SS1.p3.3.m3.1.1" xref="S4.SS1.p3.3.m3.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.3.m3.1b"><csymbol cd="latexml" id="S4.SS1.p3.3.m3.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.3.m3.1c">\sim</annotation></semantics></math>3 orders of magnitude slower than the unencrypted equivalent <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.
Moreover, polynomial approximations need to be made to evaluate non-linear functions in machine learning algorithms, resulting in a trade-off between utility and privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>, <a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite>. For example, to protect individual gradients, Aono <span id="S4.SS1.p3.3.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> used additively homomorphic encryption to preserve the privacy of gradients and enhance the security of the distributed learning system. However, their protocol not only incurs large communication and computational overhead, but also results in utility loss. Furthermore, it is not able to withstand collusion between the server and multiple participants. Hardy <span id="S4.SS1.p3.3.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> applied federated logistic regression on vertically partitioned data encrypted with an additively homomorphic scheme to secure against an honest-but-curious adversary. Overall, all these works incur extra communication and computational overheads, which limit their applications in H2C scenarios.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.4.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.5.2" class="ltx_text ltx_font_italic">Privacy-Preservation through SMC</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p"><em id="S4.SS2.p1.1.1" class="ltx_emph ltx_font_italic">Secure Multiparty Computation</em> (SMC) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib93" title="" class="ltx_ref">93</a>]</cite> enables different participants with private inputs to perform a joint computation on their inputs without revealing them to each other. Mohassel <span id="S4.SS2.p1.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib89" title="" class="ltx_ref">89</a>]</cite> proposed SecureML which conducts privacy-preserving learning via SMC, where data owners need to process, encrypt and/or secret-share their data among two non-colluding servers in the initial setup phase. SecureML allows data owners to train various models on their joint data without revealing any information beyond the outcome. However, this comes at a cost of high computation and communication overhead, which may hamper participants’ interest to collaborate. Bonawitz <span id="S4.SS2.p1.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> proposed a secure, communication-efficient, and failure-robust protocol based on SMC for secure aggregation of individual gradients. It ensures that the only information about the individual users the server learns is what can be inferred from the aggregated results. The security of their protocol is maintained under both the honest-but-curious and malicious settings, even when the server and a subset of users act maliciously – colluding and deviating arbitrarily from the protocol. That is, no party learns anything more than the sum of the inputs of a subset of honest users of a large size <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">In general, SMC techniques ensure a high level of privacy and accuracy, at the expense of high computation and communication overhead, thereby doing a disservice to attracting participation. Another main challenge facing SMC-based schemes is the requirement for simultaneous coordination of all participants during the entire training process. Such a multi-party interaction model may not be desirable in practical settings, especially under the commonly considered participant-server architecture in FL settings. Besides, SMC-based protocols can enable multiple participants to collaboratively compute an agreed-upon function without leaking input information from any participant except for what can be inferred from the outcomes of the computation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib99" title="" class="ltx_ref">99</a>, <a href="#bib.bib100" title="" class="ltx_ref">100</a>]</cite>. That said, SMC cannot fully guarantee protection from information leakage, which requires additional differential privacy techniques to be incorporated into the multi-party protocol to address such concerns <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>, <a href="#bib.bib102" title="" class="ltx_ref">102</a>, <a href="#bib.bib103" title="" class="ltx_ref">103</a>, <a href="#bib.bib104" title="" class="ltx_ref">104</a>]</cite>.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">In summary, homomorphic encryption or SMC-based approaches may not be applicable to large-scale FL scenarios as they incur substantial additional communication and computation costs. Moreover, encryption based techniques need to be carefully designed and implemented for each operation in the target learning algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib105" title="" class="ltx_ref">105</a>, <a href="#bib.bib106" title="" class="ltx_ref">106</a>]</cite>. Lastly, all the cryptography based protocols prevent anyone from auditing participants’ updates to the joint model, which leaves spaces for
the malicious participants to attack. For example, malicious participants can introduce stealthy backdoor functionality into the global model without being detected <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.4.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.5.2" class="ltx_text ltx_font_italic">Privacy-Preservation through Differential Privacy</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Differential privacy (DP) was originally designed for the single database scenario, where for every query made, a database server answers the query in a privacy-preserving manner with tailored randomization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite>. In comparison with encryption based approaches, differential privacy trades off privacy and accuracy by perturbing the data in a way that (i) is computationally efficient, (ii) does not allow an attacker to recover the original data, and (iii) does not severely affect the utility.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.4" class="ltx_p">The concept of differential privacy is that the effect of the presence or the absence of a single record on the output likelihood is bounded by a small factor <math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mi id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><ci id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">\epsilon</annotation></semantics></math>. As defined in Definition <a href="#S4.Thmdefinition1" title="Definition IV.1 ‣ IV-C Privacy-Preservation through Differential Privacy ‣ IV Defenses against Privacy Attacks ‣ Privacy and Robustness in Federated Learning: Attacks and Defenses" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV.1</span></a>, <math id="S4.SS3.p2.2.m2.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="S4.SS3.p2.2.m2.2a"><mrow id="S4.SS3.p2.2.m2.2.3.2" xref="S4.SS3.p2.2.m2.2.3.1.cmml"><mo stretchy="false" id="S4.SS3.p2.2.m2.2.3.2.1" xref="S4.SS3.p2.2.m2.2.3.1.cmml">(</mo><mi id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml">ϵ</mi><mo id="S4.SS3.p2.2.m2.2.3.2.2" xref="S4.SS3.p2.2.m2.2.3.1.cmml">,</mo><mi id="S4.SS3.p2.2.m2.2.2" xref="S4.SS3.p2.2.m2.2.2.cmml">δ</mi><mo stretchy="false" id="S4.SS3.p2.2.m2.2.3.2.3" xref="S4.SS3.p2.2.m2.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.2b"><interval closure="open" id="S4.SS3.p2.2.m2.2.3.1.cmml" xref="S4.SS3.p2.2.m2.2.3.2"><ci id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1">italic-ϵ</ci><ci id="S4.SS3.p2.2.m2.2.2.cmml" xref="S4.SS3.p2.2.m2.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.2c">(\epsilon,\delta)</annotation></semantics></math>-approximate differential privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite> relaxes pure <math id="S4.SS3.p2.3.m3.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S4.SS3.p2.3.m3.1a"><mi id="S4.SS3.p2.3.m3.1.1" xref="S4.SS3.p2.3.m3.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.3.m3.1b"><ci id="S4.SS3.p2.3.m3.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.1c">\epsilon</annotation></semantics></math>-differential privacy by a <math id="S4.SS3.p2.4.m4.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="S4.SS3.p2.4.m4.1a"><mi id="S4.SS3.p2.4.m4.1.1" xref="S4.SS3.p2.4.m4.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.4.m4.1b"><ci id="S4.SS3.p2.4.m4.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.4.m4.1c">\delta</annotation></semantics></math> additive term, which means the unlikely responses need not satisfy the pure differential privacy criterion.</p>
</div>
<div id="S4.Thmdefinition1" class="ltx_theorem ltx_theorem_definition">
<h6 class="ltx_title ltx_runin ltx_title_theorem"><span class="ltx_tag ltx_tag_theorem"><span id="S4.Thmdefinition1.1.1.1" class="ltx_text ltx_font_bold">Definition IV.1</span></span></h6>
<div id="S4.Thmdefinition1.p1" class="ltx_para">
<p id="S4.Thmdefinition1.p1.7" class="ltx_p"><math id="S4.Thmdefinition1.p1.1.m1.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="S4.Thmdefinition1.p1.1.m1.2a"><mrow id="S4.Thmdefinition1.p1.1.m1.2.3.2" xref="S4.Thmdefinition1.p1.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.Thmdefinition1.p1.1.m1.2.3.2.1" xref="S4.Thmdefinition1.p1.1.m1.2.3.1.cmml">(</mo><mi id="S4.Thmdefinition1.p1.1.m1.1.1" xref="S4.Thmdefinition1.p1.1.m1.1.1.cmml">ϵ</mi><mo id="S4.Thmdefinition1.p1.1.m1.2.3.2.2" xref="S4.Thmdefinition1.p1.1.m1.2.3.1.cmml">,</mo><mi id="S4.Thmdefinition1.p1.1.m1.2.2" xref="S4.Thmdefinition1.p1.1.m1.2.2.cmml">δ</mi><mo stretchy="false" id="S4.Thmdefinition1.p1.1.m1.2.3.2.3" xref="S4.Thmdefinition1.p1.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.Thmdefinition1.p1.1.m1.2b"><interval closure="open" id="S4.Thmdefinition1.p1.1.m1.2.3.1.cmml" xref="S4.Thmdefinition1.p1.1.m1.2.3.2"><ci id="S4.Thmdefinition1.p1.1.m1.1.1.cmml" xref="S4.Thmdefinition1.p1.1.m1.1.1">italic-ϵ</ci><ci id="S4.Thmdefinition1.p1.1.m1.2.2.cmml" xref="S4.Thmdefinition1.p1.1.m1.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.Thmdefinition1.p1.1.m1.2c">(\epsilon,\delta)</annotation></semantics></math><span id="S4.Thmdefinition1.p1.7.6" class="ltx_text ltx_font_italic">-differential privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite>. For scalars <math id="S4.Thmdefinition1.p1.2.1.m1.1" class="ltx_Math" alttext="\epsilon&gt;0" display="inline"><semantics id="S4.Thmdefinition1.p1.2.1.m1.1a"><mrow id="S4.Thmdefinition1.p1.2.1.m1.1.1" xref="S4.Thmdefinition1.p1.2.1.m1.1.1.cmml"><mi id="S4.Thmdefinition1.p1.2.1.m1.1.1.2" xref="S4.Thmdefinition1.p1.2.1.m1.1.1.2.cmml">ϵ</mi><mo id="S4.Thmdefinition1.p1.2.1.m1.1.1.1" xref="S4.Thmdefinition1.p1.2.1.m1.1.1.1.cmml">&gt;</mo><mn id="S4.Thmdefinition1.p1.2.1.m1.1.1.3" xref="S4.Thmdefinition1.p1.2.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.Thmdefinition1.p1.2.1.m1.1b"><apply id="S4.Thmdefinition1.p1.2.1.m1.1.1.cmml" xref="S4.Thmdefinition1.p1.2.1.m1.1.1"><gt id="S4.Thmdefinition1.p1.2.1.m1.1.1.1.cmml" xref="S4.Thmdefinition1.p1.2.1.m1.1.1.1"></gt><ci id="S4.Thmdefinition1.p1.2.1.m1.1.1.2.cmml" xref="S4.Thmdefinition1.p1.2.1.m1.1.1.2">italic-ϵ</ci><cn type="integer" id="S4.Thmdefinition1.p1.2.1.m1.1.1.3.cmml" xref="S4.Thmdefinition1.p1.2.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Thmdefinition1.p1.2.1.m1.1c">\epsilon&gt;0</annotation></semantics></math> and <math id="S4.Thmdefinition1.p1.3.2.m2.1" class="ltx_Math" alttext="0\leq\delta&lt;1" display="inline"><semantics id="S4.Thmdefinition1.p1.3.2.m2.1a"><mrow id="S4.Thmdefinition1.p1.3.2.m2.1.1" xref="S4.Thmdefinition1.p1.3.2.m2.1.1.cmml"><mn id="S4.Thmdefinition1.p1.3.2.m2.1.1.2" xref="S4.Thmdefinition1.p1.3.2.m2.1.1.2.cmml">0</mn><mo id="S4.Thmdefinition1.p1.3.2.m2.1.1.3" xref="S4.Thmdefinition1.p1.3.2.m2.1.1.3.cmml">≤</mo><mi id="S4.Thmdefinition1.p1.3.2.m2.1.1.4" xref="S4.Thmdefinition1.p1.3.2.m2.1.1.4.cmml">δ</mi><mo id="S4.Thmdefinition1.p1.3.2.m2.1.1.5" xref="S4.Thmdefinition1.p1.3.2.m2.1.1.5.cmml">&lt;</mo><mn id="S4.Thmdefinition1.p1.3.2.m2.1.1.6" xref="S4.Thmdefinition1.p1.3.2.m2.1.1.6.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.Thmdefinition1.p1.3.2.m2.1b"><apply id="S4.Thmdefinition1.p1.3.2.m2.1.1.cmml" xref="S4.Thmdefinition1.p1.3.2.m2.1.1"><and id="S4.Thmdefinition1.p1.3.2.m2.1.1a.cmml" xref="S4.Thmdefinition1.p1.3.2.m2.1.1"></and><apply id="S4.Thmdefinition1.p1.3.2.m2.1.1b.cmml" xref="S4.Thmdefinition1.p1.3.2.m2.1.1"><leq id="S4.Thmdefinition1.p1.3.2.m2.1.1.3.cmml" xref="S4.Thmdefinition1.p1.3.2.m2.1.1.3"></leq><cn type="integer" id="S4.Thmdefinition1.p1.3.2.m2.1.1.2.cmml" xref="S4.Thmdefinition1.p1.3.2.m2.1.1.2">0</cn><ci id="S4.Thmdefinition1.p1.3.2.m2.1.1.4.cmml" xref="S4.Thmdefinition1.p1.3.2.m2.1.1.4">𝛿</ci></apply><apply id="S4.Thmdefinition1.p1.3.2.m2.1.1c.cmml" xref="S4.Thmdefinition1.p1.3.2.m2.1.1"><lt id="S4.Thmdefinition1.p1.3.2.m2.1.1.5.cmml" xref="S4.Thmdefinition1.p1.3.2.m2.1.1.5"></lt><share href="#S4.Thmdefinition1.p1.3.2.m2.1.1.4.cmml" id="S4.Thmdefinition1.p1.3.2.m2.1.1d.cmml" xref="S4.Thmdefinition1.p1.3.2.m2.1.1"></share><cn type="integer" id="S4.Thmdefinition1.p1.3.2.m2.1.1.6.cmml" xref="S4.Thmdefinition1.p1.3.2.m2.1.1.6">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Thmdefinition1.p1.3.2.m2.1c">0\leq\delta&lt;1</annotation></semantics></math>, mechanism <math id="S4.Thmdefinition1.p1.4.3.m3.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S4.Thmdefinition1.p1.4.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S4.Thmdefinition1.p1.4.3.m3.1.1" xref="S4.Thmdefinition1.p1.4.3.m3.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S4.Thmdefinition1.p1.4.3.m3.1b"><ci id="S4.Thmdefinition1.p1.4.3.m3.1.1.cmml" xref="S4.Thmdefinition1.p1.4.3.m3.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.Thmdefinition1.p1.4.3.m3.1c">\mathcal{M}</annotation></semantics></math> is said to preserve (approximate) <math id="S4.Thmdefinition1.p1.5.4.m4.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="S4.Thmdefinition1.p1.5.4.m4.2a"><mrow id="S4.Thmdefinition1.p1.5.4.m4.2.3.2" xref="S4.Thmdefinition1.p1.5.4.m4.2.3.1.cmml"><mo stretchy="false" id="S4.Thmdefinition1.p1.5.4.m4.2.3.2.1" xref="S4.Thmdefinition1.p1.5.4.m4.2.3.1.cmml">(</mo><mi id="S4.Thmdefinition1.p1.5.4.m4.1.1" xref="S4.Thmdefinition1.p1.5.4.m4.1.1.cmml">ϵ</mi><mo id="S4.Thmdefinition1.p1.5.4.m4.2.3.2.2" xref="S4.Thmdefinition1.p1.5.4.m4.2.3.1.cmml">,</mo><mi id="S4.Thmdefinition1.p1.5.4.m4.2.2" xref="S4.Thmdefinition1.p1.5.4.m4.2.2.cmml">δ</mi><mo stretchy="false" id="S4.Thmdefinition1.p1.5.4.m4.2.3.2.3" xref="S4.Thmdefinition1.p1.5.4.m4.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.Thmdefinition1.p1.5.4.m4.2b"><interval closure="open" id="S4.Thmdefinition1.p1.5.4.m4.2.3.1.cmml" xref="S4.Thmdefinition1.p1.5.4.m4.2.3.2"><ci id="S4.Thmdefinition1.p1.5.4.m4.1.1.cmml" xref="S4.Thmdefinition1.p1.5.4.m4.1.1">italic-ϵ</ci><ci id="S4.Thmdefinition1.p1.5.4.m4.2.2.cmml" xref="S4.Thmdefinition1.p1.5.4.m4.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.Thmdefinition1.p1.5.4.m4.2c">(\epsilon,\delta)</annotation></semantics></math>-differential privacy if for all adjacent datasets <math id="S4.Thmdefinition1.p1.6.5.m5.2" class="ltx_Math" alttext="D,D^{\prime}\in\mathcal{D}^{n}" display="inline"><semantics id="S4.Thmdefinition1.p1.6.5.m5.2a"><mrow id="S4.Thmdefinition1.p1.6.5.m5.2.2" xref="S4.Thmdefinition1.p1.6.5.m5.2.2.cmml"><mrow id="S4.Thmdefinition1.p1.6.5.m5.2.2.1.1" xref="S4.Thmdefinition1.p1.6.5.m5.2.2.1.2.cmml"><mi id="S4.Thmdefinition1.p1.6.5.m5.1.1" xref="S4.Thmdefinition1.p1.6.5.m5.1.1.cmml">D</mi><mo id="S4.Thmdefinition1.p1.6.5.m5.2.2.1.1.2" xref="S4.Thmdefinition1.p1.6.5.m5.2.2.1.2.cmml">,</mo><msup id="S4.Thmdefinition1.p1.6.5.m5.2.2.1.1.1" xref="S4.Thmdefinition1.p1.6.5.m5.2.2.1.1.1.cmml"><mi id="S4.Thmdefinition1.p1.6.5.m5.2.2.1.1.1.2" xref="S4.Thmdefinition1.p1.6.5.m5.2.2.1.1.1.2.cmml">D</mi><mo id="S4.Thmdefinition1.p1.6.5.m5.2.2.1.1.1.3" xref="S4.Thmdefinition1.p1.6.5.m5.2.2.1.1.1.3.cmml">′</mo></msup></mrow><mo id="S4.Thmdefinition1.p1.6.5.m5.2.2.2" xref="S4.Thmdefinition1.p1.6.5.m5.2.2.2.cmml">∈</mo><msup id="S4.Thmdefinition1.p1.6.5.m5.2.2.3" xref="S4.Thmdefinition1.p1.6.5.m5.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Thmdefinition1.p1.6.5.m5.2.2.3.2" xref="S4.Thmdefinition1.p1.6.5.m5.2.2.3.2.cmml">𝒟</mi><mi id="S4.Thmdefinition1.p1.6.5.m5.2.2.3.3" xref="S4.Thmdefinition1.p1.6.5.m5.2.2.3.3.cmml">n</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.Thmdefinition1.p1.6.5.m5.2b"><apply id="S4.Thmdefinition1.p1.6.5.m5.2.2.cmml" xref="S4.Thmdefinition1.p1.6.5.m5.2.2"><in id="S4.Thmdefinition1.p1.6.5.m5.2.2.2.cmml" xref="S4.Thmdefinition1.p1.6.5.m5.2.2.2"></in><list id="S4.Thmdefinition1.p1.6.5.m5.2.2.1.2.cmml" xref="S4.Thmdefinition1.p1.6.5.m5.2.2.1.1"><ci id="S4.Thmdefinition1.p1.6.5.m5.1.1.cmml" xref="S4.Thmdefinition1.p1.6.5.m5.1.1">𝐷</ci><apply id="S4.Thmdefinition1.p1.6.5.m5.2.2.1.1.1.cmml" xref="S4.Thmdefinition1.p1.6.5.m5.2.2.1.1.1"><csymbol cd="ambiguous" id="S4.Thmdefinition1.p1.6.5.m5.2.2.1.1.1.1.cmml" xref="S4.Thmdefinition1.p1.6.5.m5.2.2.1.1.1">superscript</csymbol><ci id="S4.Thmdefinition1.p1.6.5.m5.2.2.1.1.1.2.cmml" xref="S4.Thmdefinition1.p1.6.5.m5.2.2.1.1.1.2">𝐷</ci><ci id="S4.Thmdefinition1.p1.6.5.m5.2.2.1.1.1.3.cmml" xref="S4.Thmdefinition1.p1.6.5.m5.2.2.1.1.1.3">′</ci></apply></list><apply id="S4.Thmdefinition1.p1.6.5.m5.2.2.3.cmml" xref="S4.Thmdefinition1.p1.6.5.m5.2.2.3"><csymbol cd="ambiguous" id="S4.Thmdefinition1.p1.6.5.m5.2.2.3.1.cmml" xref="S4.Thmdefinition1.p1.6.5.m5.2.2.3">superscript</csymbol><ci id="S4.Thmdefinition1.p1.6.5.m5.2.2.3.2.cmml" xref="S4.Thmdefinition1.p1.6.5.m5.2.2.3.2">𝒟</ci><ci id="S4.Thmdefinition1.p1.6.5.m5.2.2.3.3.cmml" xref="S4.Thmdefinition1.p1.6.5.m5.2.2.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Thmdefinition1.p1.6.5.m5.2c">D,D^{\prime}\in\mathcal{D}^{n}</annotation></semantics></math> and measurable <math id="S4.Thmdefinition1.p1.7.6.m6.1" class="ltx_Math" alttext="S\in\mathrm{range}(\mathcal{M})" display="inline"><semantics id="S4.Thmdefinition1.p1.7.6.m6.1a"><mrow id="S4.Thmdefinition1.p1.7.6.m6.1.2" xref="S4.Thmdefinition1.p1.7.6.m6.1.2.cmml"><mi id="S4.Thmdefinition1.p1.7.6.m6.1.2.2" xref="S4.Thmdefinition1.p1.7.6.m6.1.2.2.cmml">S</mi><mo id="S4.Thmdefinition1.p1.7.6.m6.1.2.1" xref="S4.Thmdefinition1.p1.7.6.m6.1.2.1.cmml">∈</mo><mrow id="S4.Thmdefinition1.p1.7.6.m6.1.2.3" xref="S4.Thmdefinition1.p1.7.6.m6.1.2.3.cmml"><mi id="S4.Thmdefinition1.p1.7.6.m6.1.2.3.2" xref="S4.Thmdefinition1.p1.7.6.m6.1.2.3.2.cmml">range</mi><mo lspace="0em" rspace="0em" id="S4.Thmdefinition1.p1.7.6.m6.1.2.3.1" xref="S4.Thmdefinition1.p1.7.6.m6.1.2.3.1.cmml">​</mo><mrow id="S4.Thmdefinition1.p1.7.6.m6.1.2.3.3.2" xref="S4.Thmdefinition1.p1.7.6.m6.1.2.3.cmml"><mo stretchy="false" id="S4.Thmdefinition1.p1.7.6.m6.1.2.3.3.2.1" xref="S4.Thmdefinition1.p1.7.6.m6.1.2.3.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.Thmdefinition1.p1.7.6.m6.1.1" xref="S4.Thmdefinition1.p1.7.6.m6.1.1.cmml">ℳ</mi><mo stretchy="false" id="S4.Thmdefinition1.p1.7.6.m6.1.2.3.3.2.2" xref="S4.Thmdefinition1.p1.7.6.m6.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.Thmdefinition1.p1.7.6.m6.1b"><apply id="S4.Thmdefinition1.p1.7.6.m6.1.2.cmml" xref="S4.Thmdefinition1.p1.7.6.m6.1.2"><in id="S4.Thmdefinition1.p1.7.6.m6.1.2.1.cmml" xref="S4.Thmdefinition1.p1.7.6.m6.1.2.1"></in><ci id="S4.Thmdefinition1.p1.7.6.m6.1.2.2.cmml" xref="S4.Thmdefinition1.p1.7.6.m6.1.2.2">𝑆</ci><apply id="S4.Thmdefinition1.p1.7.6.m6.1.2.3.cmml" xref="S4.Thmdefinition1.p1.7.6.m6.1.2.3"><times id="S4.Thmdefinition1.p1.7.6.m6.1.2.3.1.cmml" xref="S4.Thmdefinition1.p1.7.6.m6.1.2.3.1"></times><ci id="S4.Thmdefinition1.p1.7.6.m6.1.2.3.2.cmml" xref="S4.Thmdefinition1.p1.7.6.m6.1.2.3.2">range</ci><ci id="S4.Thmdefinition1.p1.7.6.m6.1.1.cmml" xref="S4.Thmdefinition1.p1.7.6.m6.1.1">ℳ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Thmdefinition1.p1.7.6.m6.1c">S\in\mathrm{range}(\mathcal{M})</annotation></semantics></math>,</span></p>
<table id="S8.EGx1" class="ltx_equationgroup ltx_eqn_eqnarray ltx_eqn_table">

<tbody id="S4.Ex3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.Ex3.m1.3" class="ltx_Math" alttext="\displaystyle\Pr\{\mathcal{M}(D)\in S\}" display="inline"><semantics id="S4.Ex3.m1.3a"><mrow id="S4.Ex3.m1.3.3.1" xref="S4.Ex3.m1.3.3.2.cmml"><mi id="S4.Ex3.m1.2.2" xref="S4.Ex3.m1.2.2.cmml">Pr</mi><mo id="S4.Ex3.m1.3.3.1a" xref="S4.Ex3.m1.3.3.2.cmml">⁡</mo><mrow id="S4.Ex3.m1.3.3.1.1" xref="S4.Ex3.m1.3.3.2.cmml"><mo stretchy="false" id="S4.Ex3.m1.3.3.1.1.2" xref="S4.Ex3.m1.3.3.2.cmml">{</mo><mrow id="S4.Ex3.m1.3.3.1.1.1" xref="S4.Ex3.m1.3.3.1.1.1.cmml"><mrow id="S4.Ex3.m1.3.3.1.1.1.2" xref="S4.Ex3.m1.3.3.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex3.m1.3.3.1.1.1.2.2" xref="S4.Ex3.m1.3.3.1.1.1.2.2.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S4.Ex3.m1.3.3.1.1.1.2.1" xref="S4.Ex3.m1.3.3.1.1.1.2.1.cmml">​</mo><mrow id="S4.Ex3.m1.3.3.1.1.1.2.3.2" xref="S4.Ex3.m1.3.3.1.1.1.2.cmml"><mo stretchy="false" id="S4.Ex3.m1.3.3.1.1.1.2.3.2.1" xref="S4.Ex3.m1.3.3.1.1.1.2.cmml">(</mo><mi id="S4.Ex3.m1.1.1" xref="S4.Ex3.m1.1.1.cmml">D</mi><mo stretchy="false" id="S4.Ex3.m1.3.3.1.1.1.2.3.2.2" xref="S4.Ex3.m1.3.3.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S4.Ex3.m1.3.3.1.1.1.1" xref="S4.Ex3.m1.3.3.1.1.1.1.cmml">∈</mo><mi id="S4.Ex3.m1.3.3.1.1.1.3" xref="S4.Ex3.m1.3.3.1.1.1.3.cmml">S</mi></mrow><mo stretchy="false" id="S4.Ex3.m1.3.3.1.1.3" xref="S4.Ex3.m1.3.3.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex3.m1.3b"><apply id="S4.Ex3.m1.3.3.2.cmml" xref="S4.Ex3.m1.3.3.1"><ci id="S4.Ex3.m1.2.2.cmml" xref="S4.Ex3.m1.2.2">Pr</ci><apply id="S4.Ex3.m1.3.3.1.1.1.cmml" xref="S4.Ex3.m1.3.3.1.1.1"><in id="S4.Ex3.m1.3.3.1.1.1.1.cmml" xref="S4.Ex3.m1.3.3.1.1.1.1"></in><apply id="S4.Ex3.m1.3.3.1.1.1.2.cmml" xref="S4.Ex3.m1.3.3.1.1.1.2"><times id="S4.Ex3.m1.3.3.1.1.1.2.1.cmml" xref="S4.Ex3.m1.3.3.1.1.1.2.1"></times><ci id="S4.Ex3.m1.3.3.1.1.1.2.2.cmml" xref="S4.Ex3.m1.3.3.1.1.1.2.2">ℳ</ci><ci id="S4.Ex3.m1.1.1.cmml" xref="S4.Ex3.m1.1.1">𝐷</ci></apply><ci id="S4.Ex3.m1.3.3.1.1.1.3.cmml" xref="S4.Ex3.m1.3.3.1.1.1.3">𝑆</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex3.m1.3c">\displaystyle\Pr\{\mathcal{M}(D)\in S\}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_eqn_cell"><math id="S4.Ex3.m2.1" class="ltx_Math" alttext="\displaystyle\leq" display="inline"><semantics id="S4.Ex3.m2.1a"><mo id="S4.Ex3.m2.1.1" xref="S4.Ex3.m2.1.1.cmml">≤</mo><annotation-xml encoding="MathML-Content" id="S4.Ex3.m2.1b"><leq id="S4.Ex3.m2.1.1.cmml" xref="S4.Ex3.m2.1.1"></leq></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex3.m2.1c">\displaystyle\leq</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S4.Ex3.m3.4" class="ltx_Math" alttext="\displaystyle\exp(\epsilon)\cdot\Pr\{\mathcal{M}(D^{\prime})\in S\}+\delta\enspace." display="inline"><semantics id="S4.Ex3.m3.4a"><mrow id="S4.Ex3.m3.4.4.1" xref="S4.Ex3.m3.4.4.1.1.cmml"><mrow id="S4.Ex3.m3.4.4.1.1" xref="S4.Ex3.m3.4.4.1.1.cmml"><mrow id="S4.Ex3.m3.4.4.1.1.1" xref="S4.Ex3.m3.4.4.1.1.1.cmml"><mrow id="S4.Ex3.m3.4.4.1.1.1.3.2" xref="S4.Ex3.m3.4.4.1.1.1.3.1.cmml"><mi id="S4.Ex3.m3.1.1" xref="S4.Ex3.m3.1.1.cmml">exp</mi><mo id="S4.Ex3.m3.4.4.1.1.1.3.2a" xref="S4.Ex3.m3.4.4.1.1.1.3.1.cmml">⁡</mo><mrow id="S4.Ex3.m3.4.4.1.1.1.3.2.1" xref="S4.Ex3.m3.4.4.1.1.1.3.1.cmml"><mo stretchy="false" id="S4.Ex3.m3.4.4.1.1.1.3.2.1.1" xref="S4.Ex3.m3.4.4.1.1.1.3.1.cmml">(</mo><mi id="S4.Ex3.m3.2.2" xref="S4.Ex3.m3.2.2.cmml">ϵ</mi><mo rspace="0.055em" stretchy="false" id="S4.Ex3.m3.4.4.1.1.1.3.2.1.2" xref="S4.Ex3.m3.4.4.1.1.1.3.1.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="S4.Ex3.m3.4.4.1.1.1.2" xref="S4.Ex3.m3.4.4.1.1.1.2.cmml">⋅</mo><mrow id="S4.Ex3.m3.4.4.1.1.1.1.1" xref="S4.Ex3.m3.4.4.1.1.1.1.2.cmml"><mi id="S4.Ex3.m3.3.3" xref="S4.Ex3.m3.3.3.cmml">Pr</mi><mo id="S4.Ex3.m3.4.4.1.1.1.1.1a" xref="S4.Ex3.m3.4.4.1.1.1.1.2.cmml">⁡</mo><mrow id="S4.Ex3.m3.4.4.1.1.1.1.1.1" xref="S4.Ex3.m3.4.4.1.1.1.1.2.cmml"><mo stretchy="false" id="S4.Ex3.m3.4.4.1.1.1.1.1.1.2" xref="S4.Ex3.m3.4.4.1.1.1.1.2.cmml">{</mo><mrow id="S4.Ex3.m3.4.4.1.1.1.1.1.1.1" xref="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.cmml"><mrow id="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1" xref="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.3" xref="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.3.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.2" xref="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.1.1" xref="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.1.1.2" xref="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msup id="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.1.1.1" xref="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.1.1.1.2" xref="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.1.1.1.2.cmml">D</mi><mo id="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.1.1.1.3" xref="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.1.1.1.3.cmml">′</mo></msup><mo stretchy="false" id="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.1.1.3" xref="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.2" xref="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.2.cmml">∈</mo><mi id="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.3" xref="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.3.cmml">S</mi></mrow><mo stretchy="false" id="S4.Ex3.m3.4.4.1.1.1.1.1.1.3" xref="S4.Ex3.m3.4.4.1.1.1.1.2.cmml">}</mo></mrow></mrow></mrow><mo id="S4.Ex3.m3.4.4.1.1.2" xref="S4.Ex3.m3.4.4.1.1.2.cmml">+</mo><mi id="S4.Ex3.m3.4.4.1.1.3" xref="S4.Ex3.m3.4.4.1.1.3.cmml">δ</mi></mrow><mo lspace="0.500em" id="S4.Ex3.m3.4.4.1.2" xref="S4.Ex3.m3.4.4.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex3.m3.4b"><apply id="S4.Ex3.m3.4.4.1.1.cmml" xref="S4.Ex3.m3.4.4.1"><plus id="S4.Ex3.m3.4.4.1.1.2.cmml" xref="S4.Ex3.m3.4.4.1.1.2"></plus><apply id="S4.Ex3.m3.4.4.1.1.1.cmml" xref="S4.Ex3.m3.4.4.1.1.1"><ci id="S4.Ex3.m3.4.4.1.1.1.2.cmml" xref="S4.Ex3.m3.4.4.1.1.1.2">⋅</ci><apply id="S4.Ex3.m3.4.4.1.1.1.3.1.cmml" xref="S4.Ex3.m3.4.4.1.1.1.3.2"><exp id="S4.Ex3.m3.1.1.cmml" xref="S4.Ex3.m3.1.1"></exp><ci id="S4.Ex3.m3.2.2.cmml" xref="S4.Ex3.m3.2.2">italic-ϵ</ci></apply><apply id="S4.Ex3.m3.4.4.1.1.1.1.2.cmml" xref="S4.Ex3.m3.4.4.1.1.1.1.1"><ci id="S4.Ex3.m3.3.3.cmml" xref="S4.Ex3.m3.3.3">Pr</ci><apply id="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.cmml" xref="S4.Ex3.m3.4.4.1.1.1.1.1.1.1"><in id="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.2.cmml" xref="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.2"></in><apply id="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.cmml" xref="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1"><times id="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.2.cmml" xref="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.2"></times><ci id="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.3.cmml" xref="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.3">ℳ</ci><apply id="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.1.1.1.2">𝐷</ci><ci id="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.1.1.1.1.3">′</ci></apply></apply><ci id="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.3.cmml" xref="S4.Ex3.m3.4.4.1.1.1.1.1.1.1.3">𝑆</ci></apply></apply></apply><ci id="S4.Ex3.m3.4.4.1.1.3.cmml" xref="S4.Ex3.m3.4.4.1.1.3">𝛿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex3.m3.4c">\displaystyle\exp(\epsilon)\cdot\Pr\{\mathcal{M}(D^{\prime})\in S\}+\delta\enspace.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.3" class="ltx_p">To avoid the worst-case scenario of always violating privacy of a <math id="S4.SS3.p3.1.m1.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="S4.SS3.p3.1.m1.1a"><mi id="S4.SS3.p3.1.m1.1.1" xref="S4.SS3.p3.1.m1.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.1.m1.1b"><ci id="S4.SS3.p3.1.m1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.1.m1.1c">\delta</annotation></semantics></math> fraction, the standard recommendation is to choose <math id="S4.SS3.p3.2.m2.1" class="ltx_Math" alttext="\delta\ll 1/|D|" display="inline"><semantics id="S4.SS3.p3.2.m2.1a"><mrow id="S4.SS3.p3.2.m2.1.2" xref="S4.SS3.p3.2.m2.1.2.cmml"><mi id="S4.SS3.p3.2.m2.1.2.2" xref="S4.SS3.p3.2.m2.1.2.2.cmml">δ</mi><mo id="S4.SS3.p3.2.m2.1.2.1" xref="S4.SS3.p3.2.m2.1.2.1.cmml">≪</mo><mrow id="S4.SS3.p3.2.m2.1.2.3" xref="S4.SS3.p3.2.m2.1.2.3.cmml"><mn id="S4.SS3.p3.2.m2.1.2.3.2" xref="S4.SS3.p3.2.m2.1.2.3.2.cmml">1</mn><mo id="S4.SS3.p3.2.m2.1.2.3.1" xref="S4.SS3.p3.2.m2.1.2.3.1.cmml">/</mo><mrow id="S4.SS3.p3.2.m2.1.2.3.3.2" xref="S4.SS3.p3.2.m2.1.2.3.3.1.cmml"><mo stretchy="false" id="S4.SS3.p3.2.m2.1.2.3.3.2.1" xref="S4.SS3.p3.2.m2.1.2.3.3.1.1.cmml">|</mo><mi id="S4.SS3.p3.2.m2.1.1" xref="S4.SS3.p3.2.m2.1.1.cmml">D</mi><mo stretchy="false" id="S4.SS3.p3.2.m2.1.2.3.3.2.2" xref="S4.SS3.p3.2.m2.1.2.3.3.1.1.cmml">|</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.2.m2.1b"><apply id="S4.SS3.p3.2.m2.1.2.cmml" xref="S4.SS3.p3.2.m2.1.2"><csymbol cd="latexml" id="S4.SS3.p3.2.m2.1.2.1.cmml" xref="S4.SS3.p3.2.m2.1.2.1">much-less-than</csymbol><ci id="S4.SS3.p3.2.m2.1.2.2.cmml" xref="S4.SS3.p3.2.m2.1.2.2">𝛿</ci><apply id="S4.SS3.p3.2.m2.1.2.3.cmml" xref="S4.SS3.p3.2.m2.1.2.3"><divide id="S4.SS3.p3.2.m2.1.2.3.1.cmml" xref="S4.SS3.p3.2.m2.1.2.3.1"></divide><cn type="integer" id="S4.SS3.p3.2.m2.1.2.3.2.cmml" xref="S4.SS3.p3.2.m2.1.2.3.2">1</cn><apply id="S4.SS3.p3.2.m2.1.2.3.3.1.cmml" xref="S4.SS3.p3.2.m2.1.2.3.3.2"><abs id="S4.SS3.p3.2.m2.1.2.3.3.1.1.cmml" xref="S4.SS3.p3.2.m2.1.2.3.3.2.1"></abs><ci id="S4.SS3.p3.2.m2.1.1.cmml" xref="S4.SS3.p3.2.m2.1.1">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.2.m2.1c">\delta\ll 1/|D|</annotation></semantics></math>, where <math id="S4.SS3.p3.3.m3.1" class="ltx_Math" alttext="|D|" display="inline"><semantics id="S4.SS3.p3.3.m3.1a"><mrow id="S4.SS3.p3.3.m3.1.2.2" xref="S4.SS3.p3.3.m3.1.2.1.cmml"><mo stretchy="false" id="S4.SS3.p3.3.m3.1.2.2.1" xref="S4.SS3.p3.3.m3.1.2.1.1.cmml">|</mo><mi id="S4.SS3.p3.3.m3.1.1" xref="S4.SS3.p3.3.m3.1.1.cmml">D</mi><mo stretchy="false" id="S4.SS3.p3.3.m3.1.2.2.2" xref="S4.SS3.p3.3.m3.1.2.1.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.3.m3.1b"><apply id="S4.SS3.p3.3.m3.1.2.1.cmml" xref="S4.SS3.p3.3.m3.1.2.2"><abs id="S4.SS3.p3.3.m3.1.2.1.1.cmml" xref="S4.SS3.p3.3.m3.1.2.2.1"></abs><ci id="S4.SS3.p3.3.m3.1.1.cmml" xref="S4.SS3.p3.3.m3.1.1">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.3.m3.1c">|D|</annotation></semantics></math> is the size of the database. This strategy forecloses possibility of one particularly devastating outcome, but other forms of information leakage remain.</p>
</div>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.1" class="ltx_p">The privacy community generally categorizes DP into the following three categories as per different trust assumptions and noise sources: centralized DP (CDP), local DP (LDP) and distributed DP (DDP). A comprehensive comparison among CDP, LDP and DDP is listed in Table <a href="#S4.T5" title="TABLE V ‣ IV-C Privacy-Preservation through Differential Privacy ‣ IV Defenses against Privacy Attacks ‣ Privacy and Robustness in Federated Learning: Attacks and Defenses" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a>.</p>
</div>
<figure id="S4.T5" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T5.5.1.1" class="ltx_text" style="font-size:90%;">TABLE V</span>: </span><span id="S4.T5.6.2" class="ltx_text" style="font-size:90%;">Comparative analysis among CDP, LDP and DDP.</span></figcaption>
<div id="S4.T5.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:579.4pt;height:64.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-32.2pt,3.6pt) scale(0.9,0.9) ;">
<table id="S4.T5.3.3" class="ltx_tabular ltx_align_middle">
<tr id="S4.T5.3.3.4" class="ltx_tr">
<td id="S4.T5.3.3.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S4.T5.3.3.4.1.1" class="ltx_text ltx_font_bold">DP type</span></td>
<td id="S4.T5.3.3.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S4.T5.3.3.4.2.1" class="ltx_text ltx_font_bold">Trusted aggregator?</span></td>
<td id="S4.T5.3.3.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S4.T5.3.3.4.3.1" class="ltx_text ltx_font_bold">Who should add noise?</span></td>
<td id="S4.T5.3.3.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S4.T5.3.3.4.4.1" class="ltx_text ltx_font_bold">Privacy Guarantee</span></td>
<td id="S4.T5.3.3.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S4.T5.3.3.4.5.1" class="ltx_text ltx_font_bold">Error Bound</span></td>
</tr>
<tr id="S4.T5.1.1.1" class="ltx_tr">
<td id="S4.T5.1.1.1.2" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">CDP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>
</td>
<td id="S4.T5.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">Yes</td>
<td id="S4.T5.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">aggregator</td>
<td id="S4.T5.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">aggregated value</td>
<td id="S4.T5.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"><math id="S4.T5.1.1.1.1.m1.1" class="ltx_Math" alttext="O(\frac{1}{\epsilon})" display="inline"><semantics id="S4.T5.1.1.1.1.m1.1a"><mrow id="S4.T5.1.1.1.1.m1.1.2" xref="S4.T5.1.1.1.1.m1.1.2.cmml"><mi id="S4.T5.1.1.1.1.m1.1.2.2" xref="S4.T5.1.1.1.1.m1.1.2.2.cmml">O</mi><mo lspace="0em" rspace="0em" id="S4.T5.1.1.1.1.m1.1.2.1" xref="S4.T5.1.1.1.1.m1.1.2.1.cmml">​</mo><mrow id="S4.T5.1.1.1.1.m1.1.2.3.2" xref="S4.T5.1.1.1.1.m1.1.1.cmml"><mo stretchy="false" id="S4.T5.1.1.1.1.m1.1.2.3.2.1" xref="S4.T5.1.1.1.1.m1.1.1.cmml">(</mo><mfrac id="S4.T5.1.1.1.1.m1.1.1" xref="S4.T5.1.1.1.1.m1.1.1.cmml"><mn id="S4.T5.1.1.1.1.m1.1.1.2" xref="S4.T5.1.1.1.1.m1.1.1.2.cmml">1</mn><mi id="S4.T5.1.1.1.1.m1.1.1.3" xref="S4.T5.1.1.1.1.m1.1.1.3.cmml">ϵ</mi></mfrac><mo stretchy="false" id="S4.T5.1.1.1.1.m1.1.2.3.2.2" xref="S4.T5.1.1.1.1.m1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.1.1.1.1.m1.1b"><apply id="S4.T5.1.1.1.1.m1.1.2.cmml" xref="S4.T5.1.1.1.1.m1.1.2"><times id="S4.T5.1.1.1.1.m1.1.2.1.cmml" xref="S4.T5.1.1.1.1.m1.1.2.1"></times><ci id="S4.T5.1.1.1.1.m1.1.2.2.cmml" xref="S4.T5.1.1.1.1.m1.1.2.2">𝑂</ci><apply id="S4.T5.1.1.1.1.m1.1.1.cmml" xref="S4.T5.1.1.1.1.m1.1.2.3.2"><divide id="S4.T5.1.1.1.1.m1.1.1.1.cmml" xref="S4.T5.1.1.1.1.m1.1.2.3.2"></divide><cn type="integer" id="S4.T5.1.1.1.1.m1.1.1.2.cmml" xref="S4.T5.1.1.1.1.m1.1.1.2">1</cn><ci id="S4.T5.1.1.1.1.m1.1.1.3.cmml" xref="S4.T5.1.1.1.1.m1.1.1.3">italic-ϵ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.1.1.1.1.m1.1c">O(\frac{1}{\epsilon})</annotation></semantics></math></td>
</tr>
<tr id="S4.T5.2.2.2" class="ltx_tr">
<td id="S4.T5.2.2.2.2" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">LDP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib107" title="" class="ltx_ref">107</a>]</cite>
</td>
<td id="S4.T5.2.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">No</td>
<td id="S4.T5.2.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">user</td>
<td id="S4.T5.2.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">locally released value</td>
<td id="S4.T5.2.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"><math id="S4.T5.2.2.2.1.m1.1" class="ltx_Math" alttext="O(\frac{\sqrt{n}}{\epsilon})" display="inline"><semantics id="S4.T5.2.2.2.1.m1.1a"><mrow id="S4.T5.2.2.2.1.m1.1.2" xref="S4.T5.2.2.2.1.m1.1.2.cmml"><mi id="S4.T5.2.2.2.1.m1.1.2.2" xref="S4.T5.2.2.2.1.m1.1.2.2.cmml">O</mi><mo lspace="0em" rspace="0em" id="S4.T5.2.2.2.1.m1.1.2.1" xref="S4.T5.2.2.2.1.m1.1.2.1.cmml">​</mo><mrow id="S4.T5.2.2.2.1.m1.1.2.3.2" xref="S4.T5.2.2.2.1.m1.1.1.cmml"><mo stretchy="false" id="S4.T5.2.2.2.1.m1.1.2.3.2.1" xref="S4.T5.2.2.2.1.m1.1.1.cmml">(</mo><mfrac id="S4.T5.2.2.2.1.m1.1.1" xref="S4.T5.2.2.2.1.m1.1.1.cmml"><msqrt id="S4.T5.2.2.2.1.m1.1.1.2" xref="S4.T5.2.2.2.1.m1.1.1.2.cmml"><mi id="S4.T5.2.2.2.1.m1.1.1.2.2" xref="S4.T5.2.2.2.1.m1.1.1.2.2.cmml">n</mi></msqrt><mi id="S4.T5.2.2.2.1.m1.1.1.3" xref="S4.T5.2.2.2.1.m1.1.1.3.cmml">ϵ</mi></mfrac><mo stretchy="false" id="S4.T5.2.2.2.1.m1.1.2.3.2.2" xref="S4.T5.2.2.2.1.m1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.2.2.2.1.m1.1b"><apply id="S4.T5.2.2.2.1.m1.1.2.cmml" xref="S4.T5.2.2.2.1.m1.1.2"><times id="S4.T5.2.2.2.1.m1.1.2.1.cmml" xref="S4.T5.2.2.2.1.m1.1.2.1"></times><ci id="S4.T5.2.2.2.1.m1.1.2.2.cmml" xref="S4.T5.2.2.2.1.m1.1.2.2">𝑂</ci><apply id="S4.T5.2.2.2.1.m1.1.1.cmml" xref="S4.T5.2.2.2.1.m1.1.2.3.2"><divide id="S4.T5.2.2.2.1.m1.1.1.1.cmml" xref="S4.T5.2.2.2.1.m1.1.2.3.2"></divide><apply id="S4.T5.2.2.2.1.m1.1.1.2.cmml" xref="S4.T5.2.2.2.1.m1.1.1.2"><root id="S4.T5.2.2.2.1.m1.1.1.2a.cmml" xref="S4.T5.2.2.2.1.m1.1.1.2"></root><ci id="S4.T5.2.2.2.1.m1.1.1.2.2.cmml" xref="S4.T5.2.2.2.1.m1.1.1.2.2">𝑛</ci></apply><ci id="S4.T5.2.2.2.1.m1.1.1.3.cmml" xref="S4.T5.2.2.2.1.m1.1.1.3">italic-ϵ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.2.2.2.1.m1.1c">O(\frac{\sqrt{n}}{\epsilon})</annotation></semantics></math></td>
</tr>
<tr id="S4.T5.3.3.3" class="ltx_tr">
<td id="S4.T5.3.3.3.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">DDP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>
</td>
<td id="S4.T5.3.3.3.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">No</td>
<td id="S4.T5.3.3.3.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">user</td>
<td id="S4.T5.3.3.3.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">aggregated value</td>
<td id="S4.T5.3.3.3.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"><math id="S4.T5.3.3.3.1.m1.1" class="ltx_Math" alttext="O(\frac{1}{\epsilon})" display="inline"><semantics id="S4.T5.3.3.3.1.m1.1a"><mrow id="S4.T5.3.3.3.1.m1.1.2" xref="S4.T5.3.3.3.1.m1.1.2.cmml"><mi id="S4.T5.3.3.3.1.m1.1.2.2" xref="S4.T5.3.3.3.1.m1.1.2.2.cmml">O</mi><mo lspace="0em" rspace="0em" id="S4.T5.3.3.3.1.m1.1.2.1" xref="S4.T5.3.3.3.1.m1.1.2.1.cmml">​</mo><mrow id="S4.T5.3.3.3.1.m1.1.2.3.2" xref="S4.T5.3.3.3.1.m1.1.1.cmml"><mo stretchy="false" id="S4.T5.3.3.3.1.m1.1.2.3.2.1" xref="S4.T5.3.3.3.1.m1.1.1.cmml">(</mo><mfrac id="S4.T5.3.3.3.1.m1.1.1" xref="S4.T5.3.3.3.1.m1.1.1.cmml"><mn id="S4.T5.3.3.3.1.m1.1.1.2" xref="S4.T5.3.3.3.1.m1.1.1.2.cmml">1</mn><mi id="S4.T5.3.3.3.1.m1.1.1.3" xref="S4.T5.3.3.3.1.m1.1.1.3.cmml">ϵ</mi></mfrac><mo stretchy="false" id="S4.T5.3.3.3.1.m1.1.2.3.2.2" xref="S4.T5.3.3.3.1.m1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.3.3.3.1.m1.1b"><apply id="S4.T5.3.3.3.1.m1.1.2.cmml" xref="S4.T5.3.3.3.1.m1.1.2"><times id="S4.T5.3.3.3.1.m1.1.2.1.cmml" xref="S4.T5.3.3.3.1.m1.1.2.1"></times><ci id="S4.T5.3.3.3.1.m1.1.2.2.cmml" xref="S4.T5.3.3.3.1.m1.1.2.2">𝑂</ci><apply id="S4.T5.3.3.3.1.m1.1.1.cmml" xref="S4.T5.3.3.3.1.m1.1.2.3.2"><divide id="S4.T5.3.3.3.1.m1.1.1.1.cmml" xref="S4.T5.3.3.3.1.m1.1.2.3.2"></divide><cn type="integer" id="S4.T5.3.3.3.1.m1.1.1.2.cmml" xref="S4.T5.3.3.3.1.m1.1.1.2">1</cn><ci id="S4.T5.3.3.3.1.m1.1.1.3.cmml" xref="S4.T5.3.3.3.1.m1.1.1.3">italic-ϵ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.3.3.3.1.m1.1c">O(\frac{1}{\epsilon})</annotation></semantics></math></td>
</tr>
</table>
</span></div>
</figure>
<div id="S4.SS3.p5" class="ltx_para">
<p id="S4.SS3.p5.1" class="ltx_p"><span id="S4.SS3.p5.1.1" class="ltx_text ltx_font_bold">Centralized Differential Privacy (CDP)</span>. CDP was originally designed for the centralized scenario where a trusted database server, who is entitled to see all participants’ data in the clear, wishes to <em id="S4.SS3.p5.1.2" class="ltx_emph ltx_font_italic">answer queries or publish statistics</em> in a privacy-preserving manner by randomizing query results <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>, <a href="#bib.bib108" title="" class="ltx_ref">108</a>, <a href="#bib.bib109" title="" class="ltx_ref">109</a>]</cite>. When CDP meets FL, CDP assumes a trusted aggregator, who is responsible for adding noise to the aggregated local gradients to ensure record-level privacy of the whole data of all participants <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite>.
However, CDP is geared to tackle thousands of users for training to converge and achieve an acceptable trade-off between privacy and accuracy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, resulting in a convergence problem with a small number of participants <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib110" title="" class="ltx_ref">110</a>]</cite>. Moreover, CDP can achieve acceptable accuracy only with a large number of participants, thus not applicable to H2B with relatively a small number of participants.</p>
</div>
<div id="S4.SS3.p6" class="ltx_para">
<p id="S4.SS3.p6.1" class="ltx_p">Meanwhile, the assumption of a trusted server in CDP is ill-suited in many applications as it constitutes a single point of failure for data breaches, and saddles the trusted curator with legal and ethical obligations to keep the user data secure. When the aggregator is untrusted which is often the case in distributed scenarios, Local Differential Privacy (LDP) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib111" title="" class="ltx_ref">111</a>]</cite> or <em id="S4.SS3.p6.1.1" class="ltx_emph ltx_font_italic">Distributed Differential Privacy</em> (DDP) are needed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib112" title="" class="ltx_ref">112</a>, <a href="#bib.bib102" title="" class="ltx_ref">102</a>]</cite> to protect privacy of individuals.</p>
</div>
<div id="S4.SS3.p7" class="ltx_para">
<p id="S4.SS3.p7.1" class="ltx_p"><span id="S4.SS3.p7.1.1" class="ltx_text ltx_font_bold">Local Differential Privacy (LDP)</span>. Local differential privacy (LDP) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib111" title="" class="ltx_ref">111</a>]</cite> offers stronger privacy guarantee, data owners perturb their private information to satisfy DP locally before reporting it to an untrusted data curator <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>, <a href="#bib.bib113" title="" class="ltx_ref">113</a>, <a href="#bib.bib86" title="" class="ltx_ref">86</a>]</cite>. A comprehensive survey of LDP can be referred to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib114" title="" class="ltx_ref">114</a>]</cite>. A formal definition of LDP is given in Definition <a href="#S4.Thmdefinition2" title="Definition IV.2 ‣ IV-C Privacy-Preservation through Differential Privacy ‣ IV Defenses against Privacy Attacks ‣ Privacy and Robustness in Federated Learning: Attacks and Defenses" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV.2</span></a>.</p>
</div>
<div id="S4.Thmdefinition2" class="ltx_theorem ltx_theorem_definition">
<h6 class="ltx_title ltx_runin ltx_title_theorem"><span class="ltx_tag ltx_tag_theorem"><span id="S4.Thmdefinition2.1.1.1" class="ltx_text ltx_font_bold">Definition IV.2</span></span></h6>
<div id="S4.Thmdefinition2.p1" class="ltx_para">
<p id="S4.Thmdefinition2.p1.6" class="ltx_p"><span id="S4.Thmdefinition2.p1.6.6" class="ltx_text ltx_font_italic">(<math id="S4.Thmdefinition2.p1.1.1.m1.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="S4.Thmdefinition2.p1.1.1.m1.2a"><mrow id="S4.Thmdefinition2.p1.1.1.m1.2.3.2" xref="S4.Thmdefinition2.p1.1.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.Thmdefinition2.p1.1.1.m1.2.3.2.1" xref="S4.Thmdefinition2.p1.1.1.m1.2.3.1.cmml">(</mo><mi id="S4.Thmdefinition2.p1.1.1.m1.1.1" xref="S4.Thmdefinition2.p1.1.1.m1.1.1.cmml">ϵ</mi><mo id="S4.Thmdefinition2.p1.1.1.m1.2.3.2.2" xref="S4.Thmdefinition2.p1.1.1.m1.2.3.1.cmml">,</mo><mi id="S4.Thmdefinition2.p1.1.1.m1.2.2" xref="S4.Thmdefinition2.p1.1.1.m1.2.2.cmml">δ</mi><mo stretchy="false" id="S4.Thmdefinition2.p1.1.1.m1.2.3.2.3" xref="S4.Thmdefinition2.p1.1.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.Thmdefinition2.p1.1.1.m1.2b"><interval closure="open" id="S4.Thmdefinition2.p1.1.1.m1.2.3.1.cmml" xref="S4.Thmdefinition2.p1.1.1.m1.2.3.2"><ci id="S4.Thmdefinition2.p1.1.1.m1.1.1.cmml" xref="S4.Thmdefinition2.p1.1.1.m1.1.1">italic-ϵ</ci><ci id="S4.Thmdefinition2.p1.1.1.m1.2.2.cmml" xref="S4.Thmdefinition2.p1.1.1.m1.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.Thmdefinition2.p1.1.1.m1.2c">(\epsilon,\delta)</annotation></semantics></math>-Local Differential Privacy). A randomized algorithm <math id="S4.Thmdefinition2.p1.2.2.m2.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S4.Thmdefinition2.p1.2.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S4.Thmdefinition2.p1.2.2.m2.1.1" xref="S4.Thmdefinition2.p1.2.2.m2.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S4.Thmdefinition2.p1.2.2.m2.1b"><ci id="S4.Thmdefinition2.p1.2.2.m2.1.1.cmml" xref="S4.Thmdefinition2.p1.2.2.m2.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.Thmdefinition2.p1.2.2.m2.1c">\mathcal{M}</annotation></semantics></math> satisfies <math id="S4.Thmdefinition2.p1.3.3.m3.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="S4.Thmdefinition2.p1.3.3.m3.2a"><mrow id="S4.Thmdefinition2.p1.3.3.m3.2.3.2" xref="S4.Thmdefinition2.p1.3.3.m3.2.3.1.cmml"><mo stretchy="false" id="S4.Thmdefinition2.p1.3.3.m3.2.3.2.1" xref="S4.Thmdefinition2.p1.3.3.m3.2.3.1.cmml">(</mo><mi id="S4.Thmdefinition2.p1.3.3.m3.1.1" xref="S4.Thmdefinition2.p1.3.3.m3.1.1.cmml">ϵ</mi><mo id="S4.Thmdefinition2.p1.3.3.m3.2.3.2.2" xref="S4.Thmdefinition2.p1.3.3.m3.2.3.1.cmml">,</mo><mi id="S4.Thmdefinition2.p1.3.3.m3.2.2" xref="S4.Thmdefinition2.p1.3.3.m3.2.2.cmml">δ</mi><mo stretchy="false" id="S4.Thmdefinition2.p1.3.3.m3.2.3.2.3" xref="S4.Thmdefinition2.p1.3.3.m3.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.Thmdefinition2.p1.3.3.m3.2b"><interval closure="open" id="S4.Thmdefinition2.p1.3.3.m3.2.3.1.cmml" xref="S4.Thmdefinition2.p1.3.3.m3.2.3.2"><ci id="S4.Thmdefinition2.p1.3.3.m3.1.1.cmml" xref="S4.Thmdefinition2.p1.3.3.m3.1.1">italic-ϵ</ci><ci id="S4.Thmdefinition2.p1.3.3.m3.2.2.cmml" xref="S4.Thmdefinition2.p1.3.3.m3.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.Thmdefinition2.p1.3.3.m3.2c">(\epsilon,\delta)</annotation></semantics></math>-local differential privacy (<math id="S4.Thmdefinition2.p1.4.4.m4.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="S4.Thmdefinition2.p1.4.4.m4.2a"><mrow id="S4.Thmdefinition2.p1.4.4.m4.2.3.2" xref="S4.Thmdefinition2.p1.4.4.m4.2.3.1.cmml"><mo stretchy="false" id="S4.Thmdefinition2.p1.4.4.m4.2.3.2.1" xref="S4.Thmdefinition2.p1.4.4.m4.2.3.1.cmml">(</mo><mi id="S4.Thmdefinition2.p1.4.4.m4.1.1" xref="S4.Thmdefinition2.p1.4.4.m4.1.1.cmml">ϵ</mi><mo id="S4.Thmdefinition2.p1.4.4.m4.2.3.2.2" xref="S4.Thmdefinition2.p1.4.4.m4.2.3.1.cmml">,</mo><mi id="S4.Thmdefinition2.p1.4.4.m4.2.2" xref="S4.Thmdefinition2.p1.4.4.m4.2.2.cmml">δ</mi><mo stretchy="false" id="S4.Thmdefinition2.p1.4.4.m4.2.3.2.3" xref="S4.Thmdefinition2.p1.4.4.m4.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.Thmdefinition2.p1.4.4.m4.2b"><interval closure="open" id="S4.Thmdefinition2.p1.4.4.m4.2.3.1.cmml" xref="S4.Thmdefinition2.p1.4.4.m4.2.3.2"><ci id="S4.Thmdefinition2.p1.4.4.m4.1.1.cmml" xref="S4.Thmdefinition2.p1.4.4.m4.1.1">italic-ϵ</ci><ci id="S4.Thmdefinition2.p1.4.4.m4.2.2.cmml" xref="S4.Thmdefinition2.p1.4.4.m4.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.Thmdefinition2.p1.4.4.m4.2c">(\epsilon,\delta)</annotation></semantics></math>-LDP) if and only if for any input <math id="S4.Thmdefinition2.p1.5.5.m5.1" class="ltx_Math" alttext="v" display="inline"><semantics id="S4.Thmdefinition2.p1.5.5.m5.1a"><mi id="S4.Thmdefinition2.p1.5.5.m5.1.1" xref="S4.Thmdefinition2.p1.5.5.m5.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S4.Thmdefinition2.p1.5.5.m5.1b"><ci id="S4.Thmdefinition2.p1.5.5.m5.1.1.cmml" xref="S4.Thmdefinition2.p1.5.5.m5.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.Thmdefinition2.p1.5.5.m5.1c">v</annotation></semantics></math> and <math id="S4.Thmdefinition2.p1.6.6.m6.1" class="ltx_Math" alttext="v^{\prime}" display="inline"><semantics id="S4.Thmdefinition2.p1.6.6.m6.1a"><msup id="S4.Thmdefinition2.p1.6.6.m6.1.1" xref="S4.Thmdefinition2.p1.6.6.m6.1.1.cmml"><mi id="S4.Thmdefinition2.p1.6.6.m6.1.1.2" xref="S4.Thmdefinition2.p1.6.6.m6.1.1.2.cmml">v</mi><mo id="S4.Thmdefinition2.p1.6.6.m6.1.1.3" xref="S4.Thmdefinition2.p1.6.6.m6.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S4.Thmdefinition2.p1.6.6.m6.1b"><apply id="S4.Thmdefinition2.p1.6.6.m6.1.1.cmml" xref="S4.Thmdefinition2.p1.6.6.m6.1.1"><csymbol cd="ambiguous" id="S4.Thmdefinition2.p1.6.6.m6.1.1.1.cmml" xref="S4.Thmdefinition2.p1.6.6.m6.1.1">superscript</csymbol><ci id="S4.Thmdefinition2.p1.6.6.m6.1.1.2.cmml" xref="S4.Thmdefinition2.p1.6.6.m6.1.1.2">𝑣</ci><ci id="S4.Thmdefinition2.p1.6.6.m6.1.1.3.cmml" xref="S4.Thmdefinition2.p1.6.6.m6.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Thmdefinition2.p1.6.6.m6.1c">v^{\prime}</annotation></semantics></math>, we have</span></p>
<table id="S8.EGx2" class="ltx_equationgroup ltx_eqn_eqnarray ltx_eqn_table">

<tbody id="S4.Ex4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.Ex4.m1.3" class="ltx_Math" alttext="\displaystyle\Pr\{\mathcal{M}(v)=o\}" display="inline"><semantics id="S4.Ex4.m1.3a"><mrow id="S4.Ex4.m1.3.3.1" xref="S4.Ex4.m1.3.3.2.cmml"><mi id="S4.Ex4.m1.2.2" xref="S4.Ex4.m1.2.2.cmml">Pr</mi><mo id="S4.Ex4.m1.3.3.1a" xref="S4.Ex4.m1.3.3.2.cmml">⁡</mo><mrow id="S4.Ex4.m1.3.3.1.1" xref="S4.Ex4.m1.3.3.2.cmml"><mo stretchy="false" id="S4.Ex4.m1.3.3.1.1.2" xref="S4.Ex4.m1.3.3.2.cmml">{</mo><mrow id="S4.Ex4.m1.3.3.1.1.1" xref="S4.Ex4.m1.3.3.1.1.1.cmml"><mrow id="S4.Ex4.m1.3.3.1.1.1.2" xref="S4.Ex4.m1.3.3.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex4.m1.3.3.1.1.1.2.2" xref="S4.Ex4.m1.3.3.1.1.1.2.2.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S4.Ex4.m1.3.3.1.1.1.2.1" xref="S4.Ex4.m1.3.3.1.1.1.2.1.cmml">​</mo><mrow id="S4.Ex4.m1.3.3.1.1.1.2.3.2" xref="S4.Ex4.m1.3.3.1.1.1.2.cmml"><mo stretchy="false" id="S4.Ex4.m1.3.3.1.1.1.2.3.2.1" xref="S4.Ex4.m1.3.3.1.1.1.2.cmml">(</mo><mi id="S4.Ex4.m1.1.1" xref="S4.Ex4.m1.1.1.cmml">v</mi><mo stretchy="false" id="S4.Ex4.m1.3.3.1.1.1.2.3.2.2" xref="S4.Ex4.m1.3.3.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S4.Ex4.m1.3.3.1.1.1.1" xref="S4.Ex4.m1.3.3.1.1.1.1.cmml">=</mo><mi id="S4.Ex4.m1.3.3.1.1.1.3" xref="S4.Ex4.m1.3.3.1.1.1.3.cmml">o</mi></mrow><mo stretchy="false" id="S4.Ex4.m1.3.3.1.1.3" xref="S4.Ex4.m1.3.3.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex4.m1.3b"><apply id="S4.Ex4.m1.3.3.2.cmml" xref="S4.Ex4.m1.3.3.1"><ci id="S4.Ex4.m1.2.2.cmml" xref="S4.Ex4.m1.2.2">Pr</ci><apply id="S4.Ex4.m1.3.3.1.1.1.cmml" xref="S4.Ex4.m1.3.3.1.1.1"><eq id="S4.Ex4.m1.3.3.1.1.1.1.cmml" xref="S4.Ex4.m1.3.3.1.1.1.1"></eq><apply id="S4.Ex4.m1.3.3.1.1.1.2.cmml" xref="S4.Ex4.m1.3.3.1.1.1.2"><times id="S4.Ex4.m1.3.3.1.1.1.2.1.cmml" xref="S4.Ex4.m1.3.3.1.1.1.2.1"></times><ci id="S4.Ex4.m1.3.3.1.1.1.2.2.cmml" xref="S4.Ex4.m1.3.3.1.1.1.2.2">ℳ</ci><ci id="S4.Ex4.m1.1.1.cmml" xref="S4.Ex4.m1.1.1">𝑣</ci></apply><ci id="S4.Ex4.m1.3.3.1.1.1.3.cmml" xref="S4.Ex4.m1.3.3.1.1.1.3">𝑜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex4.m1.3c">\displaystyle\Pr\{\mathcal{M}(v)=o\}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_eqn_cell"><math id="S4.Ex4.m2.1" class="ltx_Math" alttext="\displaystyle\leq" display="inline"><semantics id="S4.Ex4.m2.1a"><mo id="S4.Ex4.m2.1.1" xref="S4.Ex4.m2.1.1.cmml">≤</mo><annotation-xml encoding="MathML-Content" id="S4.Ex4.m2.1b"><leq id="S4.Ex4.m2.1.1.cmml" xref="S4.Ex4.m2.1.1"></leq></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex4.m2.1c">\displaystyle\leq</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S4.Ex4.m3.4" class="ltx_Math" alttext="\displaystyle\exp(\epsilon)\cdot\Pr\{\mathcal{M}(v^{\prime})=o\}+\delta\enspace" display="inline"><semantics id="S4.Ex4.m3.4a"><mrow id="S4.Ex4.m3.4.4" xref="S4.Ex4.m3.4.4.cmml"><mrow id="S4.Ex4.m3.4.4.1" xref="S4.Ex4.m3.4.4.1.cmml"><mrow id="S4.Ex4.m3.4.4.1.3.2" xref="S4.Ex4.m3.4.4.1.3.1.cmml"><mi id="S4.Ex4.m3.1.1" xref="S4.Ex4.m3.1.1.cmml">exp</mi><mo id="S4.Ex4.m3.4.4.1.3.2a" xref="S4.Ex4.m3.4.4.1.3.1.cmml">⁡</mo><mrow id="S4.Ex4.m3.4.4.1.3.2.1" xref="S4.Ex4.m3.4.4.1.3.1.cmml"><mo stretchy="false" id="S4.Ex4.m3.4.4.1.3.2.1.1" xref="S4.Ex4.m3.4.4.1.3.1.cmml">(</mo><mi id="S4.Ex4.m3.2.2" xref="S4.Ex4.m3.2.2.cmml">ϵ</mi><mo rspace="0.055em" stretchy="false" id="S4.Ex4.m3.4.4.1.3.2.1.2" xref="S4.Ex4.m3.4.4.1.3.1.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="S4.Ex4.m3.4.4.1.2" xref="S4.Ex4.m3.4.4.1.2.cmml">⋅</mo><mrow id="S4.Ex4.m3.4.4.1.1.1" xref="S4.Ex4.m3.4.4.1.1.2.cmml"><mi id="S4.Ex4.m3.3.3" xref="S4.Ex4.m3.3.3.cmml">Pr</mi><mo id="S4.Ex4.m3.4.4.1.1.1a" xref="S4.Ex4.m3.4.4.1.1.2.cmml">⁡</mo><mrow id="S4.Ex4.m3.4.4.1.1.1.1" xref="S4.Ex4.m3.4.4.1.1.2.cmml"><mo stretchy="false" id="S4.Ex4.m3.4.4.1.1.1.1.2" xref="S4.Ex4.m3.4.4.1.1.2.cmml">{</mo><mrow id="S4.Ex4.m3.4.4.1.1.1.1.1" xref="S4.Ex4.m3.4.4.1.1.1.1.1.cmml"><mrow id="S4.Ex4.m3.4.4.1.1.1.1.1.1" xref="S4.Ex4.m3.4.4.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex4.m3.4.4.1.1.1.1.1.1.3" xref="S4.Ex4.m3.4.4.1.1.1.1.1.1.3.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S4.Ex4.m3.4.4.1.1.1.1.1.1.2" xref="S4.Ex4.m3.4.4.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S4.Ex4.m3.4.4.1.1.1.1.1.1.1.1" xref="S4.Ex4.m3.4.4.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.Ex4.m3.4.4.1.1.1.1.1.1.1.1.2" xref="S4.Ex4.m3.4.4.1.1.1.1.1.1.1.1.1.cmml">(</mo><msup id="S4.Ex4.m3.4.4.1.1.1.1.1.1.1.1.1" xref="S4.Ex4.m3.4.4.1.1.1.1.1.1.1.1.1.cmml"><mi id="S4.Ex4.m3.4.4.1.1.1.1.1.1.1.1.1.2" xref="S4.Ex4.m3.4.4.1.1.1.1.1.1.1.1.1.2.cmml">v</mi><mo id="S4.Ex4.m3.4.4.1.1.1.1.1.1.1.1.1.3" xref="S4.Ex4.m3.4.4.1.1.1.1.1.1.1.1.1.3.cmml">′</mo></msup><mo stretchy="false" id="S4.Ex4.m3.4.4.1.1.1.1.1.1.1.1.3" xref="S4.Ex4.m3.4.4.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.Ex4.m3.4.4.1.1.1.1.1.2" xref="S4.Ex4.m3.4.4.1.1.1.1.1.2.cmml">=</mo><mi id="S4.Ex4.m3.4.4.1.1.1.1.1.3" xref="S4.Ex4.m3.4.4.1.1.1.1.1.3.cmml">o</mi></mrow><mo stretchy="false" id="S4.Ex4.m3.4.4.1.1.1.1.3" xref="S4.Ex4.m3.4.4.1.1.2.cmml">}</mo></mrow></mrow></mrow><mo id="S4.Ex4.m3.4.4.2" xref="S4.Ex4.m3.4.4.2.cmml">+</mo><mi id="S4.Ex4.m3.4.4.3" xref="S4.Ex4.m3.4.4.3.cmml">δ</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex4.m3.4b"><apply id="S4.Ex4.m3.4.4.cmml" xref="S4.Ex4.m3.4.4"><plus id="S4.Ex4.m3.4.4.2.cmml" xref="S4.Ex4.m3.4.4.2"></plus><apply id="S4.Ex4.m3.4.4.1.cmml" xref="S4.Ex4.m3.4.4.1"><ci id="S4.Ex4.m3.4.4.1.2.cmml" xref="S4.Ex4.m3.4.4.1.2">⋅</ci><apply id="S4.Ex4.m3.4.4.1.3.1.cmml" xref="S4.Ex4.m3.4.4.1.3.2"><exp id="S4.Ex4.m3.1.1.cmml" xref="S4.Ex4.m3.1.1"></exp><ci id="S4.Ex4.m3.2.2.cmml" xref="S4.Ex4.m3.2.2">italic-ϵ</ci></apply><apply id="S4.Ex4.m3.4.4.1.1.2.cmml" xref="S4.Ex4.m3.4.4.1.1.1"><ci id="S4.Ex4.m3.3.3.cmml" xref="S4.Ex4.m3.3.3">Pr</ci><apply id="S4.Ex4.m3.4.4.1.1.1.1.1.cmml" xref="S4.Ex4.m3.4.4.1.1.1.1.1"><eq id="S4.Ex4.m3.4.4.1.1.1.1.1.2.cmml" xref="S4.Ex4.m3.4.4.1.1.1.1.1.2"></eq><apply id="S4.Ex4.m3.4.4.1.1.1.1.1.1.cmml" xref="S4.Ex4.m3.4.4.1.1.1.1.1.1"><times id="S4.Ex4.m3.4.4.1.1.1.1.1.1.2.cmml" xref="S4.Ex4.m3.4.4.1.1.1.1.1.1.2"></times><ci id="S4.Ex4.m3.4.4.1.1.1.1.1.1.3.cmml" xref="S4.Ex4.m3.4.4.1.1.1.1.1.1.3">ℳ</ci><apply id="S4.Ex4.m3.4.4.1.1.1.1.1.1.1.1.1.cmml" xref="S4.Ex4.m3.4.4.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.Ex4.m3.4.4.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.Ex4.m3.4.4.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S4.Ex4.m3.4.4.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.Ex4.m3.4.4.1.1.1.1.1.1.1.1.1.2">𝑣</ci><ci id="S4.Ex4.m3.4.4.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.Ex4.m3.4.4.1.1.1.1.1.1.1.1.1.3">′</ci></apply></apply><ci id="S4.Ex4.m3.4.4.1.1.1.1.1.3.cmml" xref="S4.Ex4.m3.4.4.1.1.1.1.1.3">𝑜</ci></apply></apply></apply><ci id="S4.Ex4.m3.4.4.3.cmml" xref="S4.Ex4.m3.4.4.3">𝛿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex4.m3.4c">\displaystyle\exp(\epsilon)\cdot\Pr\{\mathcal{M}(v^{\prime})=o\}+\delta\enspace</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S4.Thmdefinition2.p2" class="ltx_para">
<p id="S4.Thmdefinition2.p2.6" class="ltx_p"><span id="S4.Thmdefinition2.p2.6.6" class="ltx_text ltx_font_italic">for <math id="S4.Thmdefinition2.p2.1.1.m1.1" class="ltx_Math" alttext="\forall o\in Range(\mathcal{M})" display="inline"><semantics id="S4.Thmdefinition2.p2.1.1.m1.1a"><mrow id="S4.Thmdefinition2.p2.1.1.m1.1.2" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.cmml"><mrow id="S4.Thmdefinition2.p2.1.1.m1.1.2.2" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.2.cmml"><mo rspace="0.167em" id="S4.Thmdefinition2.p2.1.1.m1.1.2.2.1" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.2.1.cmml">∀</mo><mi id="S4.Thmdefinition2.p2.1.1.m1.1.2.2.2" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.2.2.cmml">o</mi></mrow><mo id="S4.Thmdefinition2.p2.1.1.m1.1.2.1" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.1.cmml">∈</mo><mrow id="S4.Thmdefinition2.p2.1.1.m1.1.2.3" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.3.cmml"><mi id="S4.Thmdefinition2.p2.1.1.m1.1.2.3.2" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.3.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S4.Thmdefinition2.p2.1.1.m1.1.2.3.1" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.3.1.cmml">​</mo><mi id="S4.Thmdefinition2.p2.1.1.m1.1.2.3.3" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.Thmdefinition2.p2.1.1.m1.1.2.3.1a" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.3.1.cmml">​</mo><mi id="S4.Thmdefinition2.p2.1.1.m1.1.2.3.4" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.Thmdefinition2.p2.1.1.m1.1.2.3.1b" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.3.1.cmml">​</mo><mi id="S4.Thmdefinition2.p2.1.1.m1.1.2.3.5" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.3.5.cmml">g</mi><mo lspace="0em" rspace="0em" id="S4.Thmdefinition2.p2.1.1.m1.1.2.3.1c" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.3.1.cmml">​</mo><mi id="S4.Thmdefinition2.p2.1.1.m1.1.2.3.6" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.3.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.Thmdefinition2.p2.1.1.m1.1.2.3.1d" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.3.1.cmml">​</mo><mrow id="S4.Thmdefinition2.p2.1.1.m1.1.2.3.7.2" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.3.cmml"><mo stretchy="false" id="S4.Thmdefinition2.p2.1.1.m1.1.2.3.7.2.1" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.3.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.Thmdefinition2.p2.1.1.m1.1.1" xref="S4.Thmdefinition2.p2.1.1.m1.1.1.cmml">ℳ</mi><mo stretchy="false" id="S4.Thmdefinition2.p2.1.1.m1.1.2.3.7.2.2" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.Thmdefinition2.p2.1.1.m1.1b"><apply id="S4.Thmdefinition2.p2.1.1.m1.1.2.cmml" xref="S4.Thmdefinition2.p2.1.1.m1.1.2"><in id="S4.Thmdefinition2.p2.1.1.m1.1.2.1.cmml" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.1"></in><apply id="S4.Thmdefinition2.p2.1.1.m1.1.2.2.cmml" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.2"><csymbol cd="latexml" id="S4.Thmdefinition2.p2.1.1.m1.1.2.2.1.cmml" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.2.1">for-all</csymbol><ci id="S4.Thmdefinition2.p2.1.1.m1.1.2.2.2.cmml" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.2.2">𝑜</ci></apply><apply id="S4.Thmdefinition2.p2.1.1.m1.1.2.3.cmml" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.3"><times id="S4.Thmdefinition2.p2.1.1.m1.1.2.3.1.cmml" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.3.1"></times><ci id="S4.Thmdefinition2.p2.1.1.m1.1.2.3.2.cmml" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.3.2">𝑅</ci><ci id="S4.Thmdefinition2.p2.1.1.m1.1.2.3.3.cmml" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.3.3">𝑎</ci><ci id="S4.Thmdefinition2.p2.1.1.m1.1.2.3.4.cmml" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.3.4">𝑛</ci><ci id="S4.Thmdefinition2.p2.1.1.m1.1.2.3.5.cmml" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.3.5">𝑔</ci><ci id="S4.Thmdefinition2.p2.1.1.m1.1.2.3.6.cmml" xref="S4.Thmdefinition2.p2.1.1.m1.1.2.3.6">𝑒</ci><ci id="S4.Thmdefinition2.p2.1.1.m1.1.1.cmml" xref="S4.Thmdefinition2.p2.1.1.m1.1.1">ℳ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Thmdefinition2.p2.1.1.m1.1c">\forall o\in Range(\mathcal{M})</annotation></semantics></math>, where <math id="S4.Thmdefinition2.p2.2.2.m2.1" class="ltx_Math" alttext="Range(\mathcal{M})" display="inline"><semantics id="S4.Thmdefinition2.p2.2.2.m2.1a"><mrow id="S4.Thmdefinition2.p2.2.2.m2.1.2" xref="S4.Thmdefinition2.p2.2.2.m2.1.2.cmml"><mi id="S4.Thmdefinition2.p2.2.2.m2.1.2.2" xref="S4.Thmdefinition2.p2.2.2.m2.1.2.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S4.Thmdefinition2.p2.2.2.m2.1.2.1" xref="S4.Thmdefinition2.p2.2.2.m2.1.2.1.cmml">​</mo><mi id="S4.Thmdefinition2.p2.2.2.m2.1.2.3" xref="S4.Thmdefinition2.p2.2.2.m2.1.2.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.Thmdefinition2.p2.2.2.m2.1.2.1a" xref="S4.Thmdefinition2.p2.2.2.m2.1.2.1.cmml">​</mo><mi id="S4.Thmdefinition2.p2.2.2.m2.1.2.4" xref="S4.Thmdefinition2.p2.2.2.m2.1.2.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.Thmdefinition2.p2.2.2.m2.1.2.1b" xref="S4.Thmdefinition2.p2.2.2.m2.1.2.1.cmml">​</mo><mi id="S4.Thmdefinition2.p2.2.2.m2.1.2.5" xref="S4.Thmdefinition2.p2.2.2.m2.1.2.5.cmml">g</mi><mo lspace="0em" rspace="0em" id="S4.Thmdefinition2.p2.2.2.m2.1.2.1c" xref="S4.Thmdefinition2.p2.2.2.m2.1.2.1.cmml">​</mo><mi id="S4.Thmdefinition2.p2.2.2.m2.1.2.6" xref="S4.Thmdefinition2.p2.2.2.m2.1.2.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.Thmdefinition2.p2.2.2.m2.1.2.1d" xref="S4.Thmdefinition2.p2.2.2.m2.1.2.1.cmml">​</mo><mrow id="S4.Thmdefinition2.p2.2.2.m2.1.2.7.2" xref="S4.Thmdefinition2.p2.2.2.m2.1.2.cmml"><mo stretchy="false" id="S4.Thmdefinition2.p2.2.2.m2.1.2.7.2.1" xref="S4.Thmdefinition2.p2.2.2.m2.1.2.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.Thmdefinition2.p2.2.2.m2.1.1" xref="S4.Thmdefinition2.p2.2.2.m2.1.1.cmml">ℳ</mi><mo stretchy="false" id="S4.Thmdefinition2.p2.2.2.m2.1.2.7.2.2" xref="S4.Thmdefinition2.p2.2.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.Thmdefinition2.p2.2.2.m2.1b"><apply id="S4.Thmdefinition2.p2.2.2.m2.1.2.cmml" xref="S4.Thmdefinition2.p2.2.2.m2.1.2"><times id="S4.Thmdefinition2.p2.2.2.m2.1.2.1.cmml" xref="S4.Thmdefinition2.p2.2.2.m2.1.2.1"></times><ci id="S4.Thmdefinition2.p2.2.2.m2.1.2.2.cmml" xref="S4.Thmdefinition2.p2.2.2.m2.1.2.2">𝑅</ci><ci id="S4.Thmdefinition2.p2.2.2.m2.1.2.3.cmml" xref="S4.Thmdefinition2.p2.2.2.m2.1.2.3">𝑎</ci><ci id="S4.Thmdefinition2.p2.2.2.m2.1.2.4.cmml" xref="S4.Thmdefinition2.p2.2.2.m2.1.2.4">𝑛</ci><ci id="S4.Thmdefinition2.p2.2.2.m2.1.2.5.cmml" xref="S4.Thmdefinition2.p2.2.2.m2.1.2.5">𝑔</ci><ci id="S4.Thmdefinition2.p2.2.2.m2.1.2.6.cmml" xref="S4.Thmdefinition2.p2.2.2.m2.1.2.6">𝑒</ci><ci id="S4.Thmdefinition2.p2.2.2.m2.1.1.cmml" xref="S4.Thmdefinition2.p2.2.2.m2.1.1">ℳ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Thmdefinition2.p2.2.2.m2.1c">Range(\mathcal{M})</annotation></semantics></math> denotes the set of all possible outputs of the algorithm <math id="S4.Thmdefinition2.p2.3.3.m3.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S4.Thmdefinition2.p2.3.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S4.Thmdefinition2.p2.3.3.m3.1.1" xref="S4.Thmdefinition2.p2.3.3.m3.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S4.Thmdefinition2.p2.3.3.m3.1b"><ci id="S4.Thmdefinition2.p2.3.3.m3.1.1.cmml" xref="S4.Thmdefinition2.p2.3.3.m3.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.Thmdefinition2.p2.3.3.m3.1c">\mathcal{M}</annotation></semantics></math>. Furthermore <math id="S4.Thmdefinition2.p2.4.4.m4.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S4.Thmdefinition2.p2.4.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S4.Thmdefinition2.p2.4.4.m4.1.1" xref="S4.Thmdefinition2.p2.4.4.m4.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S4.Thmdefinition2.p2.4.4.m4.1b"><ci id="S4.Thmdefinition2.p2.4.4.m4.1.1.cmml" xref="S4.Thmdefinition2.p2.4.4.m4.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.Thmdefinition2.p2.4.4.m4.1c">\mathcal{M}</annotation></semantics></math> is said to preserve (pure) <math id="S4.Thmdefinition2.p2.5.5.m5.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S4.Thmdefinition2.p2.5.5.m5.1a"><mi id="S4.Thmdefinition2.p2.5.5.m5.1.1" xref="S4.Thmdefinition2.p2.5.5.m5.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S4.Thmdefinition2.p2.5.5.m5.1b"><ci id="S4.Thmdefinition2.p2.5.5.m5.1.1.cmml" xref="S4.Thmdefinition2.p2.5.5.m5.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.Thmdefinition2.p2.5.5.m5.1c">\epsilon</annotation></semantics></math>-LDP if the condition holds for <math id="S4.Thmdefinition2.p2.6.6.m6.1" class="ltx_Math" alttext="\delta=0" display="inline"><semantics id="S4.Thmdefinition2.p2.6.6.m6.1a"><mrow id="S4.Thmdefinition2.p2.6.6.m6.1.1" xref="S4.Thmdefinition2.p2.6.6.m6.1.1.cmml"><mi id="S4.Thmdefinition2.p2.6.6.m6.1.1.2" xref="S4.Thmdefinition2.p2.6.6.m6.1.1.2.cmml">δ</mi><mo id="S4.Thmdefinition2.p2.6.6.m6.1.1.1" xref="S4.Thmdefinition2.p2.6.6.m6.1.1.1.cmml">=</mo><mn id="S4.Thmdefinition2.p2.6.6.m6.1.1.3" xref="S4.Thmdefinition2.p2.6.6.m6.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.Thmdefinition2.p2.6.6.m6.1b"><apply id="S4.Thmdefinition2.p2.6.6.m6.1.1.cmml" xref="S4.Thmdefinition2.p2.6.6.m6.1.1"><eq id="S4.Thmdefinition2.p2.6.6.m6.1.1.1.cmml" xref="S4.Thmdefinition2.p2.6.6.m6.1.1.1"></eq><ci id="S4.Thmdefinition2.p2.6.6.m6.1.1.2.cmml" xref="S4.Thmdefinition2.p2.6.6.m6.1.1.2">𝛿</ci><cn type="integer" id="S4.Thmdefinition2.p2.6.6.m6.1.1.3.cmml" xref="S4.Thmdefinition2.p2.6.6.m6.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Thmdefinition2.p2.6.6.m6.1c">\delta=0</annotation></semantics></math>.</span></p>
</div>
</div>
<div id="S4.SS3.p8" class="ltx_para">
<p id="S4.SS3.p8.4" class="ltx_p">Although the randomized response <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib115" title="" class="ltx_ref">115</a>]</cite> and its variants <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib116" title="" class="ltx_ref">116</a>]</cite> have been widely used to provide LDP when individuals disclose their personal information. We remark that all the randomization mechanisms used for CDP, such as Laplace mechanism and Gaussian mechanism <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite>, can be individually used by each participant to ensure LDP in isolation. However, in distributed scenario, without the help of cryptographic techniques, each participant has to add enough calibrated noise to ensure LDP.
The attractive privacy properties of LDP thus come with a huge utility degradation, especially with billions of individuals. Under the CDP model, the aggregator releases the aggregated value with an expected additive error of at most <math id="S4.SS3.p8.1.m1.1" class="ltx_Math" alttext="\Theta(1/\epsilon)" display="inline"><semantics id="S4.SS3.p8.1.m1.1a"><mrow id="S4.SS3.p8.1.m1.1.1" xref="S4.SS3.p8.1.m1.1.1.cmml"><mi mathvariant="normal" id="S4.SS3.p8.1.m1.1.1.3" xref="S4.SS3.p8.1.m1.1.1.3.cmml">Θ</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p8.1.m1.1.1.2" xref="S4.SS3.p8.1.m1.1.1.2.cmml">​</mo><mrow id="S4.SS3.p8.1.m1.1.1.1.1" xref="S4.SS3.p8.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS3.p8.1.m1.1.1.1.1.2" xref="S4.SS3.p8.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS3.p8.1.m1.1.1.1.1.1" xref="S4.SS3.p8.1.m1.1.1.1.1.1.cmml"><mn id="S4.SS3.p8.1.m1.1.1.1.1.1.2" xref="S4.SS3.p8.1.m1.1.1.1.1.1.2.cmml">1</mn><mo id="S4.SS3.p8.1.m1.1.1.1.1.1.1" xref="S4.SS3.p8.1.m1.1.1.1.1.1.1.cmml">/</mo><mi id="S4.SS3.p8.1.m1.1.1.1.1.1.3" xref="S4.SS3.p8.1.m1.1.1.1.1.1.3.cmml">ϵ</mi></mrow><mo stretchy="false" id="S4.SS3.p8.1.m1.1.1.1.1.3" xref="S4.SS3.p8.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p8.1.m1.1b"><apply id="S4.SS3.p8.1.m1.1.1.cmml" xref="S4.SS3.p8.1.m1.1.1"><times id="S4.SS3.p8.1.m1.1.1.2.cmml" xref="S4.SS3.p8.1.m1.1.1.2"></times><ci id="S4.SS3.p8.1.m1.1.1.3.cmml" xref="S4.SS3.p8.1.m1.1.1.3">Θ</ci><apply id="S4.SS3.p8.1.m1.1.1.1.1.1.cmml" xref="S4.SS3.p8.1.m1.1.1.1.1"><divide id="S4.SS3.p8.1.m1.1.1.1.1.1.1.cmml" xref="S4.SS3.p8.1.m1.1.1.1.1.1.1"></divide><cn type="integer" id="S4.SS3.p8.1.m1.1.1.1.1.1.2.cmml" xref="S4.SS3.p8.1.m1.1.1.1.1.1.2">1</cn><ci id="S4.SS3.p8.1.m1.1.1.1.1.1.3.cmml" xref="S4.SS3.p8.1.m1.1.1.1.1.1.3">italic-ϵ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p8.1.m1.1c">\Theta(1/\epsilon)</annotation></semantics></math> to ensure <math id="S4.SS3.p8.2.m2.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S4.SS3.p8.2.m2.1a"><mi id="S4.SS3.p8.2.m2.1.1" xref="S4.SS3.p8.2.m2.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p8.2.m2.1b"><ci id="S4.SS3.p8.2.m2.1.1.cmml" xref="S4.SS3.p8.2.m2.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p8.2.m2.1c">\epsilon</annotation></semantics></math>-DP (<span id="S4.SS3.p8.4.1" class="ltx_text ltx_font_italic">e.g.</span>, using the Laplace mechanism <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite>). In contrast, under the LDP model, at least <math id="S4.SS3.p8.3.m3.1" class="ltx_Math" alttext="\Omega(\sqrt{n}/\epsilon)" display="inline"><semantics id="S4.SS3.p8.3.m3.1a"><mrow id="S4.SS3.p8.3.m3.1.1" xref="S4.SS3.p8.3.m3.1.1.cmml"><mi mathvariant="normal" id="S4.SS3.p8.3.m3.1.1.3" xref="S4.SS3.p8.3.m3.1.1.3.cmml">Ω</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p8.3.m3.1.1.2" xref="S4.SS3.p8.3.m3.1.1.2.cmml">​</mo><mrow id="S4.SS3.p8.3.m3.1.1.1.1" xref="S4.SS3.p8.3.m3.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS3.p8.3.m3.1.1.1.1.2" xref="S4.SS3.p8.3.m3.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS3.p8.3.m3.1.1.1.1.1" xref="S4.SS3.p8.3.m3.1.1.1.1.1.cmml"><msqrt id="S4.SS3.p8.3.m3.1.1.1.1.1.2" xref="S4.SS3.p8.3.m3.1.1.1.1.1.2.cmml"><mi id="S4.SS3.p8.3.m3.1.1.1.1.1.2.2" xref="S4.SS3.p8.3.m3.1.1.1.1.1.2.2.cmml">n</mi></msqrt><mo id="S4.SS3.p8.3.m3.1.1.1.1.1.1" xref="S4.SS3.p8.3.m3.1.1.1.1.1.1.cmml">/</mo><mi id="S4.SS3.p8.3.m3.1.1.1.1.1.3" xref="S4.SS3.p8.3.m3.1.1.1.1.1.3.cmml">ϵ</mi></mrow><mo stretchy="false" id="S4.SS3.p8.3.m3.1.1.1.1.3" xref="S4.SS3.p8.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p8.3.m3.1b"><apply id="S4.SS3.p8.3.m3.1.1.cmml" xref="S4.SS3.p8.3.m3.1.1"><times id="S4.SS3.p8.3.m3.1.1.2.cmml" xref="S4.SS3.p8.3.m3.1.1.2"></times><ci id="S4.SS3.p8.3.m3.1.1.3.cmml" xref="S4.SS3.p8.3.m3.1.1.3">Ω</ci><apply id="S4.SS3.p8.3.m3.1.1.1.1.1.cmml" xref="S4.SS3.p8.3.m3.1.1.1.1"><divide id="S4.SS3.p8.3.m3.1.1.1.1.1.1.cmml" xref="S4.SS3.p8.3.m3.1.1.1.1.1.1"></divide><apply id="S4.SS3.p8.3.m3.1.1.1.1.1.2.cmml" xref="S4.SS3.p8.3.m3.1.1.1.1.1.2"><root id="S4.SS3.p8.3.m3.1.1.1.1.1.2a.cmml" xref="S4.SS3.p8.3.m3.1.1.1.1.1.2"></root><ci id="S4.SS3.p8.3.m3.1.1.1.1.1.2.2.cmml" xref="S4.SS3.p8.3.m3.1.1.1.1.1.2.2">𝑛</ci></apply><ci id="S4.SS3.p8.3.m3.1.1.1.1.1.3.cmml" xref="S4.SS3.p8.3.m3.1.1.1.1.1.3">italic-ϵ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p8.3.m3.1c">\Omega(\sqrt{n}/\epsilon)</annotation></semantics></math> additive error in expectation must be incurred by any <math id="S4.SS3.p8.4.m4.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S4.SS3.p8.4.m4.1a"><mi id="S4.SS3.p8.4.m4.1.1" xref="S4.SS3.p8.4.m4.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p8.4.m4.1b"><ci id="S4.SS3.p8.4.m4.1.1.cmml" xref="S4.SS3.p8.4.m4.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p8.4.m4.1c">\epsilon</annotation></semantics></math>-DP mechanism for the same task <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib117" title="" class="ltx_ref">117</a>, <a href="#bib.bib111" title="" class="ltx_ref">111</a>]</cite>. This gap is essential for eliminating the trust in the centralized server, and cannot be removed by algorithmic improvement <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib118" title="" class="ltx_ref">118</a>]</cite>.</p>
</div>
<div id="S4.SS3.p9" class="ltx_para">
<p id="S4.SS3.p9.8" class="ltx_p">Several prior works have attempted to apply LDP to FL.
For example, Shokri et al.  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib119" title="" class="ltx_ref">119</a>]</cite> firstly applied LDP to distributed/federated learning, in which each participant individually adds noise to its gradients before releasing to the server, thus ensuring local DP. However, their privacy bounds are given per-parameter, the large number of parameters prevents their method from providing a meaningful privacy guarantee <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib108" title="" class="ltx_ref">108</a>]</cite>. Other approaches that also considered to apply LDP to FL can only support shallow models such as logistic regression and only focus on simple tasks and datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>, <a href="#bib.bib83" title="" class="ltx_ref">83</a>, <a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite>. Bhowmick et al.  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> presented a viable approach to large-scale local private model training, and introduced a relaxed version of LDP by limiting the power of potential adversaries. Due to the high variance of their mechanism, it requires more than 200 communication rounds and incurs much higher privacy cost, <span id="S4.SS3.p9.8.1" class="ltx_text ltx_font_italic">i.e.</span>, MNIST (<math id="S4.SS3.p9.1.m1.1" class="ltx_Math" alttext="\epsilon=500" display="inline"><semantics id="S4.SS3.p9.1.m1.1a"><mrow id="S4.SS3.p9.1.m1.1.1" xref="S4.SS3.p9.1.m1.1.1.cmml"><mi id="S4.SS3.p9.1.m1.1.1.2" xref="S4.SS3.p9.1.m1.1.1.2.cmml">ϵ</mi><mo id="S4.SS3.p9.1.m1.1.1.1" xref="S4.SS3.p9.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS3.p9.1.m1.1.1.3" xref="S4.SS3.p9.1.m1.1.1.3.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p9.1.m1.1b"><apply id="S4.SS3.p9.1.m1.1.1.cmml" xref="S4.SS3.p9.1.m1.1.1"><eq id="S4.SS3.p9.1.m1.1.1.1.cmml" xref="S4.SS3.p9.1.m1.1.1.1"></eq><ci id="S4.SS3.p9.1.m1.1.1.2.cmml" xref="S4.SS3.p9.1.m1.1.1.2">italic-ϵ</ci><cn type="integer" id="S4.SS3.p9.1.m1.1.1.3.cmml" xref="S4.SS3.p9.1.m1.1.1.3">500</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p9.1.m1.1c">\epsilon=500</annotation></semantics></math>) and CIFAR-10 (<math id="S4.SS3.p9.2.m2.1" class="ltx_Math" alttext="\epsilon=5000" display="inline"><semantics id="S4.SS3.p9.2.m2.1a"><mrow id="S4.SS3.p9.2.m2.1.1" xref="S4.SS3.p9.2.m2.1.1.cmml"><mi id="S4.SS3.p9.2.m2.1.1.2" xref="S4.SS3.p9.2.m2.1.1.2.cmml">ϵ</mi><mo id="S4.SS3.p9.2.m2.1.1.1" xref="S4.SS3.p9.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS3.p9.2.m2.1.1.3" xref="S4.SS3.p9.2.m2.1.1.3.cmml">5000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p9.2.m2.1b"><apply id="S4.SS3.p9.2.m2.1.1.cmml" xref="S4.SS3.p9.2.m2.1.1"><eq id="S4.SS3.p9.2.m2.1.1.1.cmml" xref="S4.SS3.p9.2.m2.1.1.1"></eq><ci id="S4.SS3.p9.2.m2.1.1.2.cmml" xref="S4.SS3.p9.2.m2.1.1.2">italic-ϵ</ci><cn type="integer" id="S4.SS3.p9.2.m2.1.1.3.cmml" xref="S4.SS3.p9.2.m2.1.1.3">5000</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p9.2.m2.1c">\epsilon=5000</annotation></semantics></math>). Note that the <math id="S4.SS3.p9.3.m3.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S4.SS3.p9.3.m3.1a"><mi id="S4.SS3.p9.3.m3.1.1" xref="S4.SS3.p9.3.m3.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p9.3.m3.1b"><ci id="S4.SS3.p9.3.m3.1.1.cmml" xref="S4.SS3.p9.3.m3.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p9.3.m3.1c">\epsilon</annotation></semantics></math> required in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> is relatively large, as they considered only privacy protection against <em id="S4.SS3.p9.8.2" class="ltx_emph ltx_font_italic">reconstruction attacks</em> instead of membership attacks, and they pointed out that local privacy as traditionally employed may prove too stringent for practical use, especially in modern high-dimensional statistical and machine learning problems. Their obtained results suggested that using LDP mechanisms with <em id="S4.SS3.p9.8.3" class="ltx_emph ltx_font_italic">large</em> <math id="S4.SS3.p9.4.m4.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S4.SS3.p9.4.m4.1a"><mi id="S4.SS3.p9.4.m4.1.1" xref="S4.SS3.p9.4.m4.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p9.4.m4.1b"><ci id="S4.SS3.p9.4.m4.1.1.cmml" xref="S4.SS3.p9.4.m4.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p9.4.m4.1c">\epsilon</annotation></semantics></math> may still provide decent protection against reconstruction. Li <span id="S4.SS3.p9.8.4" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib107" title="" class="ltx_ref">107</a>]</cite> proposed locally differentially-private algorithms in the context of meta-learning, which might be applicable to FL with personalization. However, it only provides provable learning guarantees in convex settings. Truex <span id="S4.SS3.p9.8.5" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>]</cite> applied Condensed Local Differential Privacy (<math id="S4.SS3.p9.5.m5.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS3.p9.5.m5.1a"><mi id="S4.SS3.p9.5.m5.1.1" xref="S4.SS3.p9.5.m5.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p9.5.m5.1b"><ci id="S4.SS3.p9.5.m5.1.1.cmml" xref="S4.SS3.p9.5.m5.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p9.5.m5.1c">\alpha</annotation></semantics></math>-CLDP) into FL. However, <math id="S4.SS3.p9.6.m6.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS3.p9.6.m6.1a"><mi id="S4.SS3.p9.6.m6.1.1" xref="S4.SS3.p9.6.m6.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p9.6.m6.1b"><ci id="S4.SS3.p9.6.m6.1.1.cmml" xref="S4.SS3.p9.6.m6.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p9.6.m6.1c">\alpha</annotation></semantics></math>-CLDP required privacy budget <math id="S4.SS3.p9.7.m7.1" class="ltx_Math" alttext="\epsilon=\alpha\cdot 2c\cdot 10^{p}" display="inline"><semantics id="S4.SS3.p9.7.m7.1a"><mrow id="S4.SS3.p9.7.m7.1.1" xref="S4.SS3.p9.7.m7.1.1.cmml"><mi id="S4.SS3.p9.7.m7.1.1.2" xref="S4.SS3.p9.7.m7.1.1.2.cmml">ϵ</mi><mo id="S4.SS3.p9.7.m7.1.1.1" xref="S4.SS3.p9.7.m7.1.1.1.cmml">=</mo><mrow id="S4.SS3.p9.7.m7.1.1.3" xref="S4.SS3.p9.7.m7.1.1.3.cmml"><mrow id="S4.SS3.p9.7.m7.1.1.3.2" xref="S4.SS3.p9.7.m7.1.1.3.2.cmml"><mrow id="S4.SS3.p9.7.m7.1.1.3.2.2" xref="S4.SS3.p9.7.m7.1.1.3.2.2.cmml"><mi id="S4.SS3.p9.7.m7.1.1.3.2.2.2" xref="S4.SS3.p9.7.m7.1.1.3.2.2.2.cmml">α</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.p9.7.m7.1.1.3.2.2.1" xref="S4.SS3.p9.7.m7.1.1.3.2.2.1.cmml">⋅</mo><mn id="S4.SS3.p9.7.m7.1.1.3.2.2.3" xref="S4.SS3.p9.7.m7.1.1.3.2.2.3.cmml">2</mn></mrow><mo lspace="0em" rspace="0em" id="S4.SS3.p9.7.m7.1.1.3.2.1" xref="S4.SS3.p9.7.m7.1.1.3.2.1.cmml">​</mo><mi id="S4.SS3.p9.7.m7.1.1.3.2.3" xref="S4.SS3.p9.7.m7.1.1.3.2.3.cmml">c</mi></mrow><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.p9.7.m7.1.1.3.1" xref="S4.SS3.p9.7.m7.1.1.3.1.cmml">⋅</mo><msup id="S4.SS3.p9.7.m7.1.1.3.3" xref="S4.SS3.p9.7.m7.1.1.3.3.cmml"><mn id="S4.SS3.p9.7.m7.1.1.3.3.2" xref="S4.SS3.p9.7.m7.1.1.3.3.2.cmml">10</mn><mi id="S4.SS3.p9.7.m7.1.1.3.3.3" xref="S4.SS3.p9.7.m7.1.1.3.3.3.cmml">p</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p9.7.m7.1b"><apply id="S4.SS3.p9.7.m7.1.1.cmml" xref="S4.SS3.p9.7.m7.1.1"><eq id="S4.SS3.p9.7.m7.1.1.1.cmml" xref="S4.SS3.p9.7.m7.1.1.1"></eq><ci id="S4.SS3.p9.7.m7.1.1.2.cmml" xref="S4.SS3.p9.7.m7.1.1.2">italic-ϵ</ci><apply id="S4.SS3.p9.7.m7.1.1.3.cmml" xref="S4.SS3.p9.7.m7.1.1.3"><ci id="S4.SS3.p9.7.m7.1.1.3.1.cmml" xref="S4.SS3.p9.7.m7.1.1.3.1">⋅</ci><apply id="S4.SS3.p9.7.m7.1.1.3.2.cmml" xref="S4.SS3.p9.7.m7.1.1.3.2"><times id="S4.SS3.p9.7.m7.1.1.3.2.1.cmml" xref="S4.SS3.p9.7.m7.1.1.3.2.1"></times><apply id="S4.SS3.p9.7.m7.1.1.3.2.2.cmml" xref="S4.SS3.p9.7.m7.1.1.3.2.2"><ci id="S4.SS3.p9.7.m7.1.1.3.2.2.1.cmml" xref="S4.SS3.p9.7.m7.1.1.3.2.2.1">⋅</ci><ci id="S4.SS3.p9.7.m7.1.1.3.2.2.2.cmml" xref="S4.SS3.p9.7.m7.1.1.3.2.2.2">𝛼</ci><cn type="integer" id="S4.SS3.p9.7.m7.1.1.3.2.2.3.cmml" xref="S4.SS3.p9.7.m7.1.1.3.2.2.3">2</cn></apply><ci id="S4.SS3.p9.7.m7.1.1.3.2.3.cmml" xref="S4.SS3.p9.7.m7.1.1.3.2.3">𝑐</ci></apply><apply id="S4.SS3.p9.7.m7.1.1.3.3.cmml" xref="S4.SS3.p9.7.m7.1.1.3.3"><csymbol cd="ambiguous" id="S4.SS3.p9.7.m7.1.1.3.3.1.cmml" xref="S4.SS3.p9.7.m7.1.1.3.3">superscript</csymbol><cn type="integer" id="S4.SS3.p9.7.m7.1.1.3.3.2.cmml" xref="S4.SS3.p9.7.m7.1.1.3.3.2">10</cn><ci id="S4.SS3.p9.7.m7.1.1.3.3.3.cmml" xref="S4.SS3.p9.7.m7.1.1.3.3.3">𝑝</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p9.7.m7.1c">\epsilon=\alpha\cdot 2c\cdot 10^{p}</annotation></semantics></math> (e.g. <math id="S4.SS3.p9.8.m8.2" class="ltx_Math" alttext="\alpha=1,c=1,p=10" display="inline"><semantics id="S4.SS3.p9.8.m8.2a"><mrow id="S4.SS3.p9.8.m8.2.2.2" xref="S4.SS3.p9.8.m8.2.2.3.cmml"><mrow id="S4.SS3.p9.8.m8.1.1.1.1" xref="S4.SS3.p9.8.m8.1.1.1.1.cmml"><mi id="S4.SS3.p9.8.m8.1.1.1.1.2" xref="S4.SS3.p9.8.m8.1.1.1.1.2.cmml">α</mi><mo id="S4.SS3.p9.8.m8.1.1.1.1.1" xref="S4.SS3.p9.8.m8.1.1.1.1.1.cmml">=</mo><mn id="S4.SS3.p9.8.m8.1.1.1.1.3" xref="S4.SS3.p9.8.m8.1.1.1.1.3.cmml">1</mn></mrow><mo id="S4.SS3.p9.8.m8.2.2.2.3" xref="S4.SS3.p9.8.m8.2.2.3a.cmml">,</mo><mrow id="S4.SS3.p9.8.m8.2.2.2.2.2" xref="S4.SS3.p9.8.m8.2.2.2.2.3.cmml"><mrow id="S4.SS3.p9.8.m8.2.2.2.2.1.1" xref="S4.SS3.p9.8.m8.2.2.2.2.1.1.cmml"><mi id="S4.SS3.p9.8.m8.2.2.2.2.1.1.2" xref="S4.SS3.p9.8.m8.2.2.2.2.1.1.2.cmml">c</mi><mo id="S4.SS3.p9.8.m8.2.2.2.2.1.1.1" xref="S4.SS3.p9.8.m8.2.2.2.2.1.1.1.cmml">=</mo><mn id="S4.SS3.p9.8.m8.2.2.2.2.1.1.3" xref="S4.SS3.p9.8.m8.2.2.2.2.1.1.3.cmml">1</mn></mrow><mo id="S4.SS3.p9.8.m8.2.2.2.2.2.3" xref="S4.SS3.p9.8.m8.2.2.2.2.3a.cmml">,</mo><mrow id="S4.SS3.p9.8.m8.2.2.2.2.2.2" xref="S4.SS3.p9.8.m8.2.2.2.2.2.2.cmml"><mi id="S4.SS3.p9.8.m8.2.2.2.2.2.2.2" xref="S4.SS3.p9.8.m8.2.2.2.2.2.2.2.cmml">p</mi><mo id="S4.SS3.p9.8.m8.2.2.2.2.2.2.1" xref="S4.SS3.p9.8.m8.2.2.2.2.2.2.1.cmml">=</mo><mn id="S4.SS3.p9.8.m8.2.2.2.2.2.2.3" xref="S4.SS3.p9.8.m8.2.2.2.2.2.2.3.cmml">10</mn></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p9.8.m8.2b"><apply id="S4.SS3.p9.8.m8.2.2.3.cmml" xref="S4.SS3.p9.8.m8.2.2.2"><csymbol cd="ambiguous" id="S4.SS3.p9.8.m8.2.2.3a.cmml" xref="S4.SS3.p9.8.m8.2.2.2.3">formulae-sequence</csymbol><apply id="S4.SS3.p9.8.m8.1.1.1.1.cmml" xref="S4.SS3.p9.8.m8.1.1.1.1"><eq id="S4.SS3.p9.8.m8.1.1.1.1.1.cmml" xref="S4.SS3.p9.8.m8.1.1.1.1.1"></eq><ci id="S4.SS3.p9.8.m8.1.1.1.1.2.cmml" xref="S4.SS3.p9.8.m8.1.1.1.1.2">𝛼</ci><cn type="integer" id="S4.SS3.p9.8.m8.1.1.1.1.3.cmml" xref="S4.SS3.p9.8.m8.1.1.1.1.3">1</cn></apply><apply id="S4.SS3.p9.8.m8.2.2.2.2.3.cmml" xref="S4.SS3.p9.8.m8.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS3.p9.8.m8.2.2.2.2.3a.cmml" xref="S4.SS3.p9.8.m8.2.2.2.2.2.3">formulae-sequence</csymbol><apply id="S4.SS3.p9.8.m8.2.2.2.2.1.1.cmml" xref="S4.SS3.p9.8.m8.2.2.2.2.1.1"><eq id="S4.SS3.p9.8.m8.2.2.2.2.1.1.1.cmml" xref="S4.SS3.p9.8.m8.2.2.2.2.1.1.1"></eq><ci id="S4.SS3.p9.8.m8.2.2.2.2.1.1.2.cmml" xref="S4.SS3.p9.8.m8.2.2.2.2.1.1.2">𝑐</ci><cn type="integer" id="S4.SS3.p9.8.m8.2.2.2.2.1.1.3.cmml" xref="S4.SS3.p9.8.m8.2.2.2.2.1.1.3">1</cn></apply><apply id="S4.SS3.p9.8.m8.2.2.2.2.2.2.cmml" xref="S4.SS3.p9.8.m8.2.2.2.2.2.2"><eq id="S4.SS3.p9.8.m8.2.2.2.2.2.2.1.cmml" xref="S4.SS3.p9.8.m8.2.2.2.2.2.2.1"></eq><ci id="S4.SS3.p9.8.m8.2.2.2.2.2.2.2.cmml" xref="S4.SS3.p9.8.m8.2.2.2.2.2.2.2">𝑝</ci><cn type="integer" id="S4.SS3.p9.8.m8.2.2.2.2.2.2.3.cmml" xref="S4.SS3.p9.8.m8.2.2.2.2.2.2.3">10</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p9.8.m8.2c">\alpha=1,c=1,p=10</annotation></semantics></math>), which results in a weak privacy guarantee. Another contemporary work called LDP-FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>]</cite> achieves better performance on both effectiveness and efficiency than <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>]</cite> with a special communication design for deep learning approaches.</p>
</div>
<div id="S4.SS3.p10" class="ltx_para">
<p id="S4.SS3.p10.1" class="ltx_p">In addition to the privacy leakage in FL with homogeneous architectures, FL with heterogeneous architectures suffers from the similar privacy issues. In FL with homogeneous architectures, the predictions from local models are also sensitive and may leak private information <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib108" title="" class="ltx_ref">108</a>, <a href="#bib.bib75" title="" class="ltx_ref">75</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib87" title="" class="ltx_ref">87</a>]</cite>. Currently, there is no theoretic guarantee that sharing prediction is private and secure <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>, <a href="#bib.bib87" title="" class="ltx_ref">87</a>]</cite>. To address this issue, one naive approach is adding the locally differentially private random noise to the predictions like previous works. Although the privacy concern is mitigated with random noise perturbation, it brings a new problem with a substantial trade-off between privacy budget and model utility. Sun <span id="S4.SS3.p10.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib87" title="" class="ltx_ref">87</a>]</cite> filled in this gap by proposing a novel framework called FEDMD-NFDP, which integrated a novel Noise-Free Differential Privacy (NFDP) mechanism into federated model distillation. The LDP guarantee of NFDP roots in local data sampling process, which explicitly eliminates noise addition and privacy cost explosion issues in previous works.</p>
</div>
<figure id="S4.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F4.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2012.06337/assets/x1.png" id="S4.F4.sf1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="116" height="110" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F4.sf1.3.2" class="ltx_text" style="font-size:90%;">FL without privacy.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F4.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2012.06337/assets/x2.png" id="S4.F4.sf2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="120" height="110" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F4.sf2.3.2" class="ltx_text" style="font-size:90%;">Centralized DP: FL with a trusted server.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F4.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2012.06337/assets/x3.png" id="S4.F4.sf3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="136" height="110" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S4.F4.sf3.3.2" class="ltx_text" style="font-size:90%;">Local DP: FL without a trusted server.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F4.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2012.06337/assets/figures/FL_DDPHE_new.png" id="S4.F4.sf4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="451" height="298" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S4.F4.sf4.3.2" class="ltx_text" style="font-size:90%;">Distributed DP with SMC: FL without a trusted server.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.10.5.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S4.F4.8.4" class="ltx_text" style="font-size:90%;">An illustration of one round of federated learning without privacy and with different DP mechanisms. <math id="S4.F4.5.1.m1.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S4.F4.5.1.m1.1b"><mi id="S4.F4.5.1.m1.1.1" xref="S4.F4.5.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S4.F4.5.1.m1.1c"><ci id="S4.F4.5.1.m1.1.1.cmml" xref="S4.F4.5.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.5.1.m1.1d">M</annotation></semantics></math> denotes a DP mechanism used to privatize the data. In centralized DP (b), the central server is trusted. In local DP (c), the central server is not trusted, gradients are perturbed to ensure local DP before forwarding to the central server. In distributed DP (d), the central server is also not trusted, gradients are perturbed via DP mechanism <math id="S4.F4.6.2.m2.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S4.F4.6.2.m2.1b"><mi id="S4.F4.6.2.m2.1.1" xref="S4.F4.6.2.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S4.F4.6.2.m2.1c"><ci id="S4.F4.6.2.m2.1.1.cmml" xref="S4.F4.6.2.m2.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.6.2.m2.1d">M</annotation></semantics></math> and encrypted via encryption operation <math id="S4.F4.7.3.m3.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S4.F4.7.3.m3.1b"><mi id="S4.F4.7.3.m3.1.1" xref="S4.F4.7.3.m3.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S4.F4.7.3.m3.1c"><ci id="S4.F4.7.3.m3.1.1.cmml" xref="S4.F4.7.3.m3.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.7.3.m3.1d">E</annotation></semantics></math> to ensure privacy before forwarding to the central server, who needs to finally decrypt (<math id="S4.F4.8.4.m4.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S4.F4.8.4.m4.1b"><mi id="S4.F4.8.4.m4.1.1" xref="S4.F4.8.4.m4.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.F4.8.4.m4.1c"><ci id="S4.F4.8.4.m4.1.1.cmml" xref="S4.F4.8.4.m4.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.8.4.m4.1d">D</annotation></semantics></math>) the aggregated ciphertext.</span></figcaption>
</figure>
<div id="S4.SS3.p11" class="ltx_para">
<p id="S4.SS3.p11.1" class="ltx_p"><span id="S4.SS3.p11.1.1" class="ltx_text ltx_font_bold">Distributed Differential Privacy (DDP).</span>
<em id="S4.SS3.p11.1.2" class="ltx_emph ltx_font_italic">Distributed Differential Privacy</em> (DDP) bridges the gap between LDP and CDP, while ensuring the privacy of each individual by combining with cryptographic protocols <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>, <a href="#bib.bib102" title="" class="ltx_ref">102</a>, <a href="#bib.bib103" title="" class="ltx_ref">103</a>, <a href="#bib.bib104" title="" class="ltx_ref">104</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. Therefore, DDP avoids placing trust in any server, and offers better utility than LDP. Theoretically, DDP offers the same utility as CDP, as the total amount of noise is the same.</p>
</div>
<div id="S4.SS3.p12" class="ltx_para">
<p id="S4.SS3.p12.6" class="ltx_p">The notion of DDP reflects the fact that the required noise in the target statistic is sourced from multiple participants <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib112" title="" class="ltx_ref">112</a>]</cite>.
Approaches to DDP that implement an overall additive noise mechanism by summing the same mechanism run at each participant (typically with less noise) necessitate mechanisms with stable distributions—to guarantee proper calibration of known end-to-end response distribution—and cryptography for hiding all but the final result from participants <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib102" title="" class="ltx_ref">102</a>, <a href="#bib.bib112" title="" class="ltx_ref">112</a>, <a href="#bib.bib103" title="" class="ltx_ref">103</a>, <a href="#bib.bib101" title="" class="ltx_ref">101</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite>.
Stable distributions include Gaussian distribution, Binomial distribution <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>, etc, <span id="S4.SS3.p12.6.1" class="ltx_text ltx_font_italic">i.e.</span>, sum of Gaussian random variables still follow a Gaussian distribution, and sum of Binomial random variables still follow a Binomial distribution. DDP utilizes this nice stability to permit each participant to randomise its local statistic to a lesser degree than would LDP.
However, in DDP, only the sum of the individually released statistics is <math id="S4.SS3.p12.1.m1.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="S4.SS3.p12.1.m1.2a"><mrow id="S4.SS3.p12.1.m1.2.3.2" xref="S4.SS3.p12.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.SS3.p12.1.m1.2.3.2.1" xref="S4.SS3.p12.1.m1.2.3.1.cmml">(</mo><mi id="S4.SS3.p12.1.m1.1.1" xref="S4.SS3.p12.1.m1.1.1.cmml">ϵ</mi><mo id="S4.SS3.p12.1.m1.2.3.2.2" xref="S4.SS3.p12.1.m1.2.3.1.cmml">,</mo><mi id="S4.SS3.p12.1.m1.2.2" xref="S4.SS3.p12.1.m1.2.2.cmml">δ</mi><mo stretchy="false" id="S4.SS3.p12.1.m1.2.3.2.3" xref="S4.SS3.p12.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p12.1.m1.2b"><interval closure="open" id="S4.SS3.p12.1.m1.2.3.1.cmml" xref="S4.SS3.p12.1.m1.2.3.2"><ci id="S4.SS3.p12.1.m1.1.1.cmml" xref="S4.SS3.p12.1.m1.1.1">italic-ϵ</ci><ci id="S4.SS3.p12.1.m1.2.2.cmml" xref="S4.SS3.p12.1.m1.2.2">𝛿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p12.1.m1.2c">(\epsilon,\delta)</annotation></semantics></math>-differentially private but not the individually released statistic, <span id="S4.SS3.p12.6.2" class="ltx_text ltx_font_italic">i.e.</span>, <math id="S4.SS3.p12.2.m2.1" class="ltx_Math" alttext="{\textstyle\sum}{\mathchoice{\mbox{\boldmath$\displaystyle r_{i}$}}{\mbox{\boldmath$\textstyle r_{i}$}}{\mbox{\boldmath$\scriptstyle r_{i}$}}{\mbox{\boldmath$\scriptscriptstyle r_{i}$}}}" display="inline"><semantics id="S4.SS3.p12.2.m2.1a"><mrow id="S4.SS3.p12.2.m2.1.2" xref="S4.SS3.p12.2.m2.1.2.cmml"><mo id="S4.SS3.p12.2.m2.1.2.1" xref="S4.SS3.p12.2.m2.1.2.1.cmml">∑</mo><msub id="S4.SS3.p12.2.m2.1.1.1" xref="S4.SS3.p12.2.m2.1.1.1.cmml"><mi id="S4.SS3.p12.2.m2.1.1.1.3" xref="S4.SS3.p12.2.m2.1.1.1.3.cmml">𝒓</mi><mi id="S4.SS3.p12.2.m2.1.1.1.4" xref="S4.SS3.p12.2.m2.1.1.1.4.cmml">𝒊</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p12.2.m2.1b"><apply id="S4.SS3.p12.2.m2.1.2.cmml" xref="S4.SS3.p12.2.m2.1.2"><sum id="S4.SS3.p12.2.m2.1.2.1.cmml" xref="S4.SS3.p12.2.m2.1.2.1"></sum><apply id="S4.SS3.p12.2.m2.1.1.1.cmml" xref="S4.SS3.p12.2.m2.1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p12.2.m2.1.1.1.2.cmml" xref="S4.SS3.p12.2.m2.1.1.1">subscript</csymbol><ci id="S4.SS3.p12.2.m2.1.1.1.3.cmml" xref="S4.SS3.p12.2.m2.1.1.1.3">𝒓</ci><ci id="S4.SS3.p12.2.m2.1.1.1.4.cmml" xref="S4.SS3.p12.2.m2.1.1.1.4">𝒊</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p12.2.m2.1c">{\textstyle\sum}{\mathchoice{\mbox{\boldmath$\displaystyle r_{i}$}}{\mbox{\boldmath$\textstyle r_{i}$}}{\mbox{\boldmath$\scriptstyle r_{i}$}}{\mbox{\boldmath$\scriptscriptstyle r_{i}$}}}</annotation></semantics></math> is sufficient for this level of differential privacy, but individual noise <span id="S4.SS3.p12.3.m3.1.1.1" class="ltx_text ltx_markedasmath"><math id="S4.SS3.p12.3.m3.1.1.1.m1.1" class="ltx_Math" alttext="\textstyle r_{i}" display="inline"><semantics id="S4.SS3.p12.3.m3.1.1.1.m1.1a"><msub id="S4.SS3.p12.3.m3.1.1.1.m1.1.1" xref="S4.SS3.p12.3.m3.1.1.1.m1.1.1.cmml"><mi id="S4.SS3.p12.3.m3.1.1.1.m1.1.1.2" xref="S4.SS3.p12.3.m3.1.1.1.m1.1.1.2.cmml">𝒓</mi><mi id="S4.SS3.p12.3.m3.1.1.1.m1.1.1.3" xref="S4.SS3.p12.3.m3.1.1.1.m1.1.1.3.cmml">𝒊</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p12.3.m3.1.1.1.m1.1b"><apply id="S4.SS3.p12.3.m3.1.1.1.m1.1.1.cmml" xref="S4.SS3.p12.3.m3.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p12.3.m3.1.1.1.m1.1.1.1.cmml" xref="S4.SS3.p12.3.m3.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.SS3.p12.3.m3.1.1.1.m1.1.1.2.cmml" xref="S4.SS3.p12.3.m3.1.1.1.m1.1.1.2">𝒓</ci><ci id="S4.SS3.p12.3.m3.1.1.1.m1.1.1.3.cmml" xref="S4.SS3.p12.3.m3.1.1.1.m1.1.1.3">𝒊</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p12.3.m3.1.1.1.m1.1c">\textstyle r_{i}</annotation></semantics></math></span> alone is not sufficient, thus <math id="S4.SS3.p12.4.m4.2" class="ltx_Math" alttext="\mathchoice{\mbox{\boldmath$\displaystyle x_{i}$}}{\mbox{\boldmath$\textstyle x_{i}$}}{\mbox{\boldmath$\scriptstyle x_{i}$}}{\mbox{\boldmath$\scriptscriptstyle x_{i}$}}+\mathchoice{\mbox{\boldmath$\displaystyle r_{i}$}}{\mbox{\boldmath$\textstyle r_{i}$}}{\mbox{\boldmath$\scriptstyle r_{i}$}}{\mbox{\boldmath$\scriptscriptstyle r_{i}$}}" display="inline"><semantics id="S4.SS3.p12.4.m4.2a"><mrow id="S4.SS3.p12.4.m4.2.3" xref="S4.SS3.p12.4.m4.2.3.cmml"><msub id="S4.SS3.p12.4.m4.1.1.1" xref="S4.SS3.p12.4.m4.1.1.1.cmml"><mi id="S4.SS3.p12.4.m4.1.1.1.3" xref="S4.SS3.p12.4.m4.1.1.1.3.cmml">𝒙</mi><mi id="S4.SS3.p12.4.m4.1.1.1.4" xref="S4.SS3.p12.4.m4.1.1.1.4.cmml">𝒊</mi></msub><mo id="S4.SS3.p12.4.m4.2.3.1" xref="S4.SS3.p12.4.m4.2.3.1.cmml">+</mo><msub id="S4.SS3.p12.4.m4.2.2.1" xref="S4.SS3.p12.4.m4.2.2.1.cmml"><mi id="S4.SS3.p12.4.m4.2.2.1.3" xref="S4.SS3.p12.4.m4.2.2.1.3.cmml">𝒓</mi><mi id="S4.SS3.p12.4.m4.2.2.1.4" xref="S4.SS3.p12.4.m4.2.2.1.4.cmml">𝒊</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p12.4.m4.2b"><apply id="S4.SS3.p12.4.m4.2.3.cmml" xref="S4.SS3.p12.4.m4.2.3"><plus id="S4.SS3.p12.4.m4.2.3.1.cmml" xref="S4.SS3.p12.4.m4.2.3.1"></plus><apply id="S4.SS3.p12.4.m4.1.1.1.cmml" xref="S4.SS3.p12.4.m4.1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p12.4.m4.1.1.1.2.cmml" xref="S4.SS3.p12.4.m4.1.1.1">subscript</csymbol><ci id="S4.SS3.p12.4.m4.1.1.1.3.cmml" xref="S4.SS3.p12.4.m4.1.1.1.3">𝒙</ci><ci id="S4.SS3.p12.4.m4.1.1.1.4.cmml" xref="S4.SS3.p12.4.m4.1.1.1.4">𝒊</ci></apply><apply id="S4.SS3.p12.4.m4.2.2.1.cmml" xref="S4.SS3.p12.4.m4.2.2.1"><csymbol cd="ambiguous" id="S4.SS3.p12.4.m4.2.2.1.2.cmml" xref="S4.SS3.p12.4.m4.2.2.1">subscript</csymbol><ci id="S4.SS3.p12.4.m4.2.2.1.3.cmml" xref="S4.SS3.p12.4.m4.2.2.1.3">𝒓</ci><ci id="S4.SS3.p12.4.m4.2.2.1.4.cmml" xref="S4.SS3.p12.4.m4.2.2.1.4">𝒊</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p12.4.m4.2c">\mathchoice{\mbox{\boldmath$\displaystyle x_{i}$}}{\mbox{\boldmath$\textstyle x_{i}$}}{\mbox{\boldmath$\scriptstyle x_{i}$}}{\mbox{\boldmath$\scriptscriptstyle x_{i}$}}+\mathchoice{\mbox{\boldmath$\displaystyle r_{i}$}}{\mbox{\boldmath$\textstyle r_{i}$}}{\mbox{\boldmath$\scriptstyle r_{i}$}}{\mbox{\boldmath$\scriptscriptstyle r_{i}$}}</annotation></semantics></math> cannot be released directly. Here <span id="S4.SS3.p12.5.m5.1.1.1" class="ltx_text ltx_markedasmath"><math id="S4.SS3.p12.5.m5.1.1.1.m1.1" class="ltx_Math" alttext="\textstyle x_{i}" display="inline"><semantics id="S4.SS3.p12.5.m5.1.1.1.m1.1a"><msub id="S4.SS3.p12.5.m5.1.1.1.m1.1.1" xref="S4.SS3.p12.5.m5.1.1.1.m1.1.1.cmml"><mi id="S4.SS3.p12.5.m5.1.1.1.m1.1.1.2" xref="S4.SS3.p12.5.m5.1.1.1.m1.1.1.2.cmml">𝒙</mi><mi id="S4.SS3.p12.5.m5.1.1.1.m1.1.1.3" xref="S4.SS3.p12.5.m5.1.1.1.m1.1.1.3.cmml">𝒊</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p12.5.m5.1.1.1.m1.1b"><apply id="S4.SS3.p12.5.m5.1.1.1.m1.1.1.cmml" xref="S4.SS3.p12.5.m5.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p12.5.m5.1.1.1.m1.1.1.1.cmml" xref="S4.SS3.p12.5.m5.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.SS3.p12.5.m5.1.1.1.m1.1.1.2.cmml" xref="S4.SS3.p12.5.m5.1.1.1.m1.1.1.2">𝒙</ci><ci id="S4.SS3.p12.5.m5.1.1.1.m1.1.1.3.cmml" xref="S4.SS3.p12.5.m5.1.1.1.m1.1.1.3">𝒊</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p12.5.m5.1.1.1.m1.1c">\textstyle x_{i}</annotation></semantics></math></span> and <span id="S4.SS3.p12.6.m6.1.1.1" class="ltx_text ltx_markedasmath"><math id="S4.SS3.p12.6.m6.1.1.1.m1.1" class="ltx_Math" alttext="\textstyle r_{i}" display="inline"><semantics id="S4.SS3.p12.6.m6.1.1.1.m1.1a"><msub id="S4.SS3.p12.6.m6.1.1.1.m1.1.1" xref="S4.SS3.p12.6.m6.1.1.1.m1.1.1.cmml"><mi id="S4.SS3.p12.6.m6.1.1.1.m1.1.1.2" xref="S4.SS3.p12.6.m6.1.1.1.m1.1.1.2.cmml">𝒓</mi><mi id="S4.SS3.p12.6.m6.1.1.1.m1.1.1.3" xref="S4.SS3.p12.6.m6.1.1.1.m1.1.1.3.cmml">𝒊</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p12.6.m6.1.1.1.m1.1b"><apply id="S4.SS3.p12.6.m6.1.1.1.m1.1.1.cmml" xref="S4.SS3.p12.6.m6.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p12.6.m6.1.1.1.m1.1.1.1.cmml" xref="S4.SS3.p12.6.m6.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.SS3.p12.6.m6.1.1.1.m1.1.1.2.cmml" xref="S4.SS3.p12.6.m6.1.1.1.m1.1.1.2">𝒓</ci><ci id="S4.SS3.p12.6.m6.1.1.1.m1.1.1.3.cmml" xref="S4.SS3.p12.6.m6.1.1.1.m1.1.1.3">𝒊</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p12.6.m6.1.1.1.m1.1c">\textstyle r_{i}</annotation></semantics></math></span> indicate the individual plaintext and noise respectively.
Therefore, DDP necessitates the help of SMC to maintain utility and ensure aggregator obliviousness, as evidenced in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>, <a href="#bib.bib102" title="" class="ltx_ref">102</a>, <a href="#bib.bib103" title="" class="ltx_ref">103</a>, <a href="#bib.bib104" title="" class="ltx_ref">104</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite>.</p>
</div>
<div id="S4.SS3.p13" class="ltx_para">
<p id="S4.SS3.p13.1" class="ltx_p">An illustration of one round of FL without privacy and with different DP mechanisms is given in Fig. <a href="#S4.F4" title="Figure 4 ‣ IV-C Privacy-Preservation through Differential Privacy ‣ IV Defenses against Privacy Attacks ‣ Privacy and Robustness in Federated Learning: Attacks and Defenses" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. Another parallel line of work for privacy-preserving distributed learning is to transfer the knowledge of the ensemble of multiple models to a student model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib120" title="" class="ltx_ref">120</a>, <a href="#bib.bib108" title="" class="ltx_ref">108</a>, <a href="#bib.bib109" title="" class="ltx_ref">109</a>, <a href="#bib.bib121" title="" class="ltx_ref">121</a>]</cite>. For example, Hamm <span id="S4.SS3.p13.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib120" title="" class="ltx_ref">120</a>]</cite> first created labeled data from auxiliary unlabeled data, and then used the labeled auxiliary data to find an empirical risk minimizer, finally released a differentially private classifier using output perturbation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib122" title="" class="ltx_ref">122</a>]</cite>. Similarly, Papernot <span id="S4.SS3.p13.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib108" title="" class="ltx_ref">108</a>, <a href="#bib.bib109" title="" class="ltx_ref">109</a>]</cite> proposed <em id="S4.SS3.p13.1.3" class="ltx_emph ltx_font_italic">Private Aggregation of Teacher Ensembles</em> (PATE) to first train an ensemble of teachers on disjoint subsets of private data, then perturb the knowledge of the ensemble of teachers by adding noise to the aggregated teacher votes before transferring the knowledge to a student. Finally, a student model is trained on the aggregate output of the ensemble, such that the student learns to accurately mimic the ensemble. PATE requires a lot of participants to achieve reasonable accuracy, and each participant needs to have enough data to train an accurate model, which might not hold in FL system, where the data distribution of participants might be highly unbalanced, making this approach unsuitable to FL system.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Poisoning Attacks</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Different from privacy attacks that are targeting at data privacy, poisoning attacks aim to compromise the system robustness. Depending on the attacker’s objective, poisoning attacks can be broadly classified into two categories: 1) untargeted poisoning attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>, <a href="#bib.bib124" title="" class="ltx_ref">124</a>, <a href="#bib.bib125" title="" class="ltx_ref">125</a>, <a href="#bib.bib70" title="" class="ltx_ref">70</a>, <a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>; and 2) targeted poisoning attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib126" title="" class="ltx_ref">126</a>, <a href="#bib.bib127" title="" class="ltx_ref">127</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib128" title="" class="ltx_ref">128</a>, <a href="#bib.bib129" title="" class="ltx_ref">129</a>, <a href="#bib.bib130" title="" class="ltx_ref">130</a>, <a href="#bib.bib131" title="" class="ltx_ref">131</a>]</cite>.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">Note that the untargeted and targeted poisoning attacks during the training phase can be mounted on both the data and the model. Fig. <a href="#S5.F5" title="Figure 5 ‣ V Poisoning Attacks ‣ Privacy and Robustness in Federated Learning: Attacks and Defenses" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows that the poisoned updates can be sourced from two poisoning attacks: (1) data poisoning attack during local data collection; and (2) model poisoning attack during local model training process. At a high level, both poisoning attacks attempt to modify the behavior of the target model in some undesirable way. However, due to the model sharing nature of FL with homogeneous architectures, data poisoning attacks are generally less effective than model poisoning attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>. In fact, model poisoning subsumes data poisoning in FL settings, as data poisoning attacks eventually change a subset of updates sent to the model at any given iteration. This is functionally identical to a centralized poisoning attack in which a subset of the training data is poisoned.</p>
</div>
<figure id="S5.F5" class="ltx_figure"><img src="/html/2012.06337/assets/figures/poisoning_flow_new.png" id="S5.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="254" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S5.F5.3.2" class="ltx_text" style="font-size:90%;">Data v.s. model poisoning attacks in FL.</span></figcaption>
</figure>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.4.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.5.2" class="ltx_text ltx_font_italic">Untargeted Attacks</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">Untargeted poisoning attacks aim to arbitrarily compromise the integrity of the target model. Byzantine attack is one type of <em id="S5.SS1.p1.1.1" class="ltx_emph ltx_font_italic">untargeted</em> poisoning attacks that uploads arbitrarily malicious gradients to the server so as to cause the failure of the global model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib56" title="" class="ltx_ref">56</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite>.
A formal definition of Byzantine attack is given in Definition <a href="#S5.Thmdefinition1" title="Definition V.1 ‣ V-A Untargeted Attacks ‣ V Poisoning Attacks ‣ Privacy and Robustness in Federated Learning: Attacks and Defenses" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V.1</span></a>.</p>
</div>
<div id="S5.Thmdefinition1" class="ltx_theorem ltx_theorem_definition">
<h6 class="ltx_title ltx_runin ltx_title_theorem"><span class="ltx_tag ltx_tag_theorem"><span id="S5.Thmdefinition1.1.1.1" class="ltx_text ltx_font_bold">Definition V.1</span></span></h6>
<div id="S5.Thmdefinition1.p1" class="ltx_para">
<p id="S5.Thmdefinition1.p1.1" class="ltx_p"><span id="S5.Thmdefinition1.p1.1.1" class="ltx_text ltx_font_italic">[Byzantine attack] <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. An honest participant uploads <math id="S5.Thmdefinition1.p1.1.1.m1.1" class="ltx_Math" alttext="\Delta\bm{w}_{i}\coloneqq\nabla F_{i}(\bm{w}_{i})" display="inline"><semantics id="S5.Thmdefinition1.p1.1.1.m1.1a"><mrow id="S5.Thmdefinition1.p1.1.1.m1.1.1" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.cmml"><mrow id="S5.Thmdefinition1.p1.1.1.m1.1.1.3" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.3.cmml"><mi mathvariant="normal" id="S5.Thmdefinition1.p1.1.1.m1.1.1.3.2" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.3.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S5.Thmdefinition1.p1.1.1.m1.1.1.3.1" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.3.1.cmml">​</mo><msub id="S5.Thmdefinition1.p1.1.1.m1.1.1.3.3" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.3.3.cmml"><mi id="S5.Thmdefinition1.p1.1.1.m1.1.1.3.3.2" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.3.3.2.cmml">𝐰</mi><mi id="S5.Thmdefinition1.p1.1.1.m1.1.1.3.3.3" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.3.3.3.cmml">i</mi></msub></mrow><mo id="S5.Thmdefinition1.p1.1.1.m1.1.1.2" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.2.cmml">≔</mo><mrow id="S5.Thmdefinition1.p1.1.1.m1.1.1.1" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.1.cmml"><mrow id="S5.Thmdefinition1.p1.1.1.m1.1.1.1.3" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.1.3.cmml"><mo rspace="0.167em" id="S5.Thmdefinition1.p1.1.1.m1.1.1.1.3.1" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.1.3.1.cmml">∇</mo><msub id="S5.Thmdefinition1.p1.1.1.m1.1.1.1.3.2" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.1.3.2.cmml"><mi id="S5.Thmdefinition1.p1.1.1.m1.1.1.1.3.2.2" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.1.3.2.2.cmml">F</mi><mi id="S5.Thmdefinition1.p1.1.1.m1.1.1.1.3.2.3" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.1.3.2.3.cmml">i</mi></msub></mrow><mo lspace="0em" rspace="0em" id="S5.Thmdefinition1.p1.1.1.m1.1.1.1.2" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.1.2.cmml">​</mo><mrow id="S5.Thmdefinition1.p1.1.1.m1.1.1.1.1.1" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.Thmdefinition1.p1.1.1.m1.1.1.1.1.1.2" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.1.1.1.1.cmml">(</mo><msub id="S5.Thmdefinition1.p1.1.1.m1.1.1.1.1.1.1" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.1.1.1.1.cmml"><mi id="S5.Thmdefinition1.p1.1.1.m1.1.1.1.1.1.1.2" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.1.1.1.1.2.cmml">𝐰</mi><mi id="S5.Thmdefinition1.p1.1.1.m1.1.1.1.1.1.1.3" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S5.Thmdefinition1.p1.1.1.m1.1.1.1.1.1.3" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.Thmdefinition1.p1.1.1.m1.1b"><apply id="S5.Thmdefinition1.p1.1.1.m1.1.1.cmml" xref="S5.Thmdefinition1.p1.1.1.m1.1.1"><ci id="S5.Thmdefinition1.p1.1.1.m1.1.1.2.cmml" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.2">≔</ci><apply id="S5.Thmdefinition1.p1.1.1.m1.1.1.3.cmml" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.3"><times id="S5.Thmdefinition1.p1.1.1.m1.1.1.3.1.cmml" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.3.1"></times><ci id="S5.Thmdefinition1.p1.1.1.m1.1.1.3.2.cmml" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.3.2">Δ</ci><apply id="S5.Thmdefinition1.p1.1.1.m1.1.1.3.3.cmml" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S5.Thmdefinition1.p1.1.1.m1.1.1.3.3.1.cmml" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.3.3">subscript</csymbol><ci id="S5.Thmdefinition1.p1.1.1.m1.1.1.3.3.2.cmml" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.3.3.2">𝐰</ci><ci id="S5.Thmdefinition1.p1.1.1.m1.1.1.3.3.3.cmml" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.3.3.3">𝑖</ci></apply></apply><apply id="S5.Thmdefinition1.p1.1.1.m1.1.1.1.cmml" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.1"><times id="S5.Thmdefinition1.p1.1.1.m1.1.1.1.2.cmml" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.1.2"></times><apply id="S5.Thmdefinition1.p1.1.1.m1.1.1.1.3.cmml" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.1.3"><ci id="S5.Thmdefinition1.p1.1.1.m1.1.1.1.3.1.cmml" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.1.3.1">∇</ci><apply id="S5.Thmdefinition1.p1.1.1.m1.1.1.1.3.2.cmml" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.1.3.2"><csymbol cd="ambiguous" id="S5.Thmdefinition1.p1.1.1.m1.1.1.1.3.2.1.cmml" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.1.3.2">subscript</csymbol><ci id="S5.Thmdefinition1.p1.1.1.m1.1.1.1.3.2.2.cmml" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.1.3.2.2">𝐹</ci><ci id="S5.Thmdefinition1.p1.1.1.m1.1.1.1.3.2.3.cmml" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.1.3.2.3">𝑖</ci></apply></apply><apply id="S5.Thmdefinition1.p1.1.1.m1.1.1.1.1.1.1.cmml" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.Thmdefinition1.p1.1.1.m1.1.1.1.1.1.1.1.cmml" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S5.Thmdefinition1.p1.1.1.m1.1.1.1.1.1.1.2.cmml" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.1.1.1.1.2">𝐰</ci><ci id="S5.Thmdefinition1.p1.1.1.m1.1.1.1.1.1.1.3.cmml" xref="S5.Thmdefinition1.p1.1.1.m1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.Thmdefinition1.p1.1.1.m1.1c">\Delta\bm{w}_{i}\coloneqq\nabla F_{i}(\bm{w}_{i})</annotation></semantics></math> while a dishonest participant can upload arbitrary values.</span></p>
</div>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<table id="S8.EGx3" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S5.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S5.E1.m1.4" class="ltx_Math" alttext="\displaystyle\Delta\bm{w}_{i}=\begin{cases}*,&amp;\mbox{if $i$-th participant is Byzantine},\\
\nabla F_{i}(\bm{w}_{i}),&amp;\mbox{otherwise,}\end{cases}" display="inline"><semantics id="S5.E1.m1.4a"><mrow id="S5.E1.m1.4.5" xref="S5.E1.m1.4.5.cmml"><mrow id="S5.E1.m1.4.5.2" xref="S5.E1.m1.4.5.2.cmml"><mi mathvariant="normal" id="S5.E1.m1.4.5.2.2" xref="S5.E1.m1.4.5.2.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S5.E1.m1.4.5.2.1" xref="S5.E1.m1.4.5.2.1.cmml">​</mo><msub id="S5.E1.m1.4.5.2.3" xref="S5.E1.m1.4.5.2.3.cmml"><mi id="S5.E1.m1.4.5.2.3.2" xref="S5.E1.m1.4.5.2.3.2.cmml">𝒘</mi><mi id="S5.E1.m1.4.5.2.3.3" xref="S5.E1.m1.4.5.2.3.3.cmml">i</mi></msub></mrow><mo id="S5.E1.m1.4.5.1" xref="S5.E1.m1.4.5.1.cmml">=</mo><mrow id="S5.E1.m1.4.4a" xref="S5.E1.m1.4.5.3.1.cmml"><mo id="S5.E1.m1.4.4a.5" xref="S5.E1.m1.4.5.3.1.1.cmml">{</mo><mtable columnspacing="5pt" rowspacing="0pt" id="S5.E1.m1.4.4.4a" xref="S5.E1.m1.4.5.3.1.cmml"><mtr id="S5.E1.m1.4.4.4aa" xref="S5.E1.m1.4.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S5.E1.m1.4.4.4ab" xref="S5.E1.m1.4.5.3.1.cmml"><mrow id="S5.E1.m1.2.2.2.2.2.1.3" xref="S5.E1.m1.4.5.3.1.cmml"><mo rspace="0em" id="S5.E1.m1.2.2.2.2.2.1.1" xref="S5.E1.m1.2.2.2.2.2.1.1.cmml">∗</mo><mo id="S5.E1.m1.2.2.2.2.2.1.3.1" xref="S5.E1.m1.4.5.3.1.cmml">,</mo></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S5.E1.m1.4.4.4ac" xref="S5.E1.m1.4.5.3.1.cmml"><mrow id="S5.E1.m1.1.1.1.1.1.1.3" xref="S5.E1.m1.1.1.1.1.1.1.1.1ac.cmml"><mrow id="S5.E1.m1.1.1.1.1.1.1.1.1a" xref="S5.E1.m1.1.1.1.1.1.1.1.1ac.cmml"><mtext id="S5.E1.m1.1.1.1.1.1.1.1.1aa" xref="S5.E1.m1.1.1.1.1.1.1.1.1aa.cmml">if </mtext><mi id="S5.E1.m1.1.1.1.1.1.1.1.1.m1.1.1" xref="S5.E1.m1.1.1.1.1.1.1.1.1.m1.1.1.cmml">i</mi><mtext id="S5.E1.m1.1.1.1.1.1.1.1.1ab" xref="S5.E1.m1.1.1.1.1.1.1.1.1aa.cmml">-th participant is Byzantine</mtext></mrow><mo id="S5.E1.m1.1.1.1.1.1.1.3.1" xref="S5.E1.m1.1.1.1.1.1.1.1.1ac.cmml">,</mo></mrow></mtd></mtr><mtr id="S5.E1.m1.4.4.4ad" xref="S5.E1.m1.4.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S5.E1.m1.4.4.4ae" xref="S5.E1.m1.4.5.3.1.cmml"><mrow id="S5.E1.m1.3.3.3.3.1.1.1" xref="S5.E1.m1.3.3.3.3.1.1.1.1.cmml"><mrow id="S5.E1.m1.3.3.3.3.1.1.1.1" xref="S5.E1.m1.3.3.3.3.1.1.1.1.cmml"><mrow id="S5.E1.m1.3.3.3.3.1.1.1.1.3" xref="S5.E1.m1.3.3.3.3.1.1.1.1.3.cmml"><mo rspace="0.167em" id="S5.E1.m1.3.3.3.3.1.1.1.1.3.1" xref="S5.E1.m1.3.3.3.3.1.1.1.1.3.1.cmml">∇</mo><msub id="S5.E1.m1.3.3.3.3.1.1.1.1.3.2" xref="S5.E1.m1.3.3.3.3.1.1.1.1.3.2.cmml"><mi id="S5.E1.m1.3.3.3.3.1.1.1.1.3.2.2" xref="S5.E1.m1.3.3.3.3.1.1.1.1.3.2.2.cmml">F</mi><mi id="S5.E1.m1.3.3.3.3.1.1.1.1.3.2.3" xref="S5.E1.m1.3.3.3.3.1.1.1.1.3.2.3.cmml">i</mi></msub></mrow><mo lspace="0em" rspace="0em" id="S5.E1.m1.3.3.3.3.1.1.1.1.2" xref="S5.E1.m1.3.3.3.3.1.1.1.1.2.cmml">​</mo><mrow id="S5.E1.m1.3.3.3.3.1.1.1.1.1.1" xref="S5.E1.m1.3.3.3.3.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.E1.m1.3.3.3.3.1.1.1.1.1.1.2" xref="S5.E1.m1.3.3.3.3.1.1.1.1.1.1.1.cmml">(</mo><msub id="S5.E1.m1.3.3.3.3.1.1.1.1.1.1.1" xref="S5.E1.m1.3.3.3.3.1.1.1.1.1.1.1.cmml"><mi id="S5.E1.m1.3.3.3.3.1.1.1.1.1.1.1.2" xref="S5.E1.m1.3.3.3.3.1.1.1.1.1.1.1.2.cmml">𝒘</mi><mi id="S5.E1.m1.3.3.3.3.1.1.1.1.1.1.1.3" xref="S5.E1.m1.3.3.3.3.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S5.E1.m1.3.3.3.3.1.1.1.1.1.1.3" xref="S5.E1.m1.3.3.3.3.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S5.E1.m1.3.3.3.3.1.1.1.2" xref="S5.E1.m1.3.3.3.3.1.1.1.1.cmml">,</mo></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S5.E1.m1.4.4.4af" xref="S5.E1.m1.4.5.3.1.cmml"><mtext id="S5.E1.m1.4.4.4.4.2.1" xref="S5.E1.m1.4.4.4.4.2.1a.cmml">otherwise,</mtext></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E1.m1.4b"><apply id="S5.E1.m1.4.5.cmml" xref="S5.E1.m1.4.5"><eq id="S5.E1.m1.4.5.1.cmml" xref="S5.E1.m1.4.5.1"></eq><apply id="S5.E1.m1.4.5.2.cmml" xref="S5.E1.m1.4.5.2"><times id="S5.E1.m1.4.5.2.1.cmml" xref="S5.E1.m1.4.5.2.1"></times><ci id="S5.E1.m1.4.5.2.2.cmml" xref="S5.E1.m1.4.5.2.2">Δ</ci><apply id="S5.E1.m1.4.5.2.3.cmml" xref="S5.E1.m1.4.5.2.3"><csymbol cd="ambiguous" id="S5.E1.m1.4.5.2.3.1.cmml" xref="S5.E1.m1.4.5.2.3">subscript</csymbol><ci id="S5.E1.m1.4.5.2.3.2.cmml" xref="S5.E1.m1.4.5.2.3.2">𝒘</ci><ci id="S5.E1.m1.4.5.2.3.3.cmml" xref="S5.E1.m1.4.5.2.3.3">𝑖</ci></apply></apply><apply id="S5.E1.m1.4.5.3.1.cmml" xref="S5.E1.m1.4.4a"><csymbol cd="latexml" id="S5.E1.m1.4.5.3.1.1.cmml" xref="S5.E1.m1.4.4a.5">cases</csymbol><times id="S5.E1.m1.2.2.2.2.2.1.1.cmml" xref="S5.E1.m1.2.2.2.2.2.1.1"></times><ci id="S5.E1.m1.1.1.1.1.1.1.1.1ac.cmml" xref="S5.E1.m1.1.1.1.1.1.1.3"><mrow id="S5.E1.m1.1.1.1.1.1.1.1.1a.cmml" xref="S5.E1.m1.1.1.1.1.1.1.3"><mtext id="S5.E1.m1.1.1.1.1.1.1.1.1aa.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1aa">if </mtext><mi id="S5.E1.m1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1.m1.1.1">i</mi><mtext id="S5.E1.m1.1.1.1.1.1.1.1.1ab.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1.1aa">-th participant is Byzantine</mtext></mrow></ci><apply id="S5.E1.m1.3.3.3.3.1.1.1.1.cmml" xref="S5.E1.m1.3.3.3.3.1.1.1"><times id="S5.E1.m1.3.3.3.3.1.1.1.1.2.cmml" xref="S5.E1.m1.3.3.3.3.1.1.1.1.2"></times><apply id="S5.E1.m1.3.3.3.3.1.1.1.1.3.cmml" xref="S5.E1.m1.3.3.3.3.1.1.1.1.3"><ci id="S5.E1.m1.3.3.3.3.1.1.1.1.3.1.cmml" xref="S5.E1.m1.3.3.3.3.1.1.1.1.3.1">∇</ci><apply id="S5.E1.m1.3.3.3.3.1.1.1.1.3.2.cmml" xref="S5.E1.m1.3.3.3.3.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S5.E1.m1.3.3.3.3.1.1.1.1.3.2.1.cmml" xref="S5.E1.m1.3.3.3.3.1.1.1.1.3.2">subscript</csymbol><ci id="S5.E1.m1.3.3.3.3.1.1.1.1.3.2.2.cmml" xref="S5.E1.m1.3.3.3.3.1.1.1.1.3.2.2">𝐹</ci><ci id="S5.E1.m1.3.3.3.3.1.1.1.1.3.2.3.cmml" xref="S5.E1.m1.3.3.3.3.1.1.1.1.3.2.3">𝑖</ci></apply></apply><apply id="S5.E1.m1.3.3.3.3.1.1.1.1.1.1.1.cmml" xref="S5.E1.m1.3.3.3.3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E1.m1.3.3.3.3.1.1.1.1.1.1.1.1.cmml" xref="S5.E1.m1.3.3.3.3.1.1.1.1.1.1">subscript</csymbol><ci id="S5.E1.m1.3.3.3.3.1.1.1.1.1.1.1.2.cmml" xref="S5.E1.m1.3.3.3.3.1.1.1.1.1.1.1.2">𝒘</ci><ci id="S5.E1.m1.3.3.3.3.1.1.1.1.1.1.1.3.cmml" xref="S5.E1.m1.3.3.3.3.1.1.1.1.1.1.1.3">𝑖</ci></apply></apply><ci id="S5.E1.m1.4.4.4.4.2.1a.cmml" xref="S5.E1.m1.4.4.4.4.2.1"><mtext id="S5.E1.m1.4.4.4.4.2.1.cmml" xref="S5.E1.m1.4.4.4.4.2.1">otherwise,</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E1.m1.4c">\displaystyle\Delta\bm{w}_{i}=\begin{cases}*,&amp;\mbox{if $i$-th participant is Byzantine},\\
\nabla F_{i}(\bm{w}_{i}),&amp;\mbox{otherwise,}\end{cases}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S5.SS1.p2.3" class="ltx_p">where “<math id="S5.SS1.p2.1.m1.1" class="ltx_Math" alttext="*" display="inline"><semantics id="S5.SS1.p2.1.m1.1a"><mo id="S5.SS1.p2.1.m1.1.1" xref="S5.SS1.p2.1.m1.1.1.cmml">∗</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.1.m1.1b"><times id="S5.SS1.p2.1.m1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.1.m1.1c">*</annotation></semantics></math>” represents arbitrary values, <math id="S5.SS1.p2.2.m2.1" class="ltx_Math" alttext="F_{i}" display="inline"><semantics id="S5.SS1.p2.2.m2.1a"><msub id="S5.SS1.p2.2.m2.1.1" xref="S5.SS1.p2.2.m2.1.1.cmml"><mi id="S5.SS1.p2.2.m2.1.1.2" xref="S5.SS1.p2.2.m2.1.1.2.cmml">F</mi><mi id="S5.SS1.p2.2.m2.1.1.3" xref="S5.SS1.p2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.2.m2.1b"><apply id="S5.SS1.p2.2.m2.1.1.cmml" xref="S5.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.2.m2.1.1.1.cmml" xref="S5.SS1.p2.2.m2.1.1">subscript</csymbol><ci id="S5.SS1.p2.2.m2.1.1.2.cmml" xref="S5.SS1.p2.2.m2.1.1.2">𝐹</ci><ci id="S5.SS1.p2.2.m2.1.1.3.cmml" xref="S5.SS1.p2.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.2.m2.1c">F_{i}</annotation></semantics></math> represents participant <math id="S5.SS1.p2.3.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S5.SS1.p2.3.m3.1a"><mi id="S5.SS1.p2.3.m3.1.1" xref="S5.SS1.p2.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.3.m3.1b"><ci id="S5.SS1.p2.3.m3.1.1.cmml" xref="S5.SS1.p2.3.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.3.m3.1c">i</annotation></semantics></math>’s local model objective function.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.5" class="ltx_p">Blanchard <span id="S5.SS1.p3.5.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> showed that the aggregation of FL can be completely controlled by a single Byzantine participant if there is no defense in the FL. In particular, suppose there are <math id="S5.SS1.p3.1.m1.1" class="ltx_Math" alttext="n-1" display="inline"><semantics id="S5.SS1.p3.1.m1.1a"><mrow id="S5.SS1.p3.1.m1.1.1" xref="S5.SS1.p3.1.m1.1.1.cmml"><mi id="S5.SS1.p3.1.m1.1.1.2" xref="S5.SS1.p3.1.m1.1.1.2.cmml">n</mi><mo id="S5.SS1.p3.1.m1.1.1.1" xref="S5.SS1.p3.1.m1.1.1.1.cmml">−</mo><mn id="S5.SS1.p3.1.m1.1.1.3" xref="S5.SS1.p3.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.1.m1.1b"><apply id="S5.SS1.p3.1.m1.1.1.cmml" xref="S5.SS1.p3.1.m1.1.1"><minus id="S5.SS1.p3.1.m1.1.1.1.cmml" xref="S5.SS1.p3.1.m1.1.1.1"></minus><ci id="S5.SS1.p3.1.m1.1.1.2.cmml" xref="S5.SS1.p3.1.m1.1.1.2">𝑛</ci><cn type="integer" id="S5.SS1.p3.1.m1.1.1.3.cmml" xref="S5.SS1.p3.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.1.m1.1c">n-1</annotation></semantics></math> benign participants and a Byzantine participant, the server aggregates the gradients by <math id="S5.SS1.p3.2.m2.1" class="ltx_Math" alttext="\Delta\bm{w}^{\prime}=\frac{1}{n}\sum_{i=1}^{n}\Delta\bm{w}_{i}" display="inline"><semantics id="S5.SS1.p3.2.m2.1a"><mrow id="S5.SS1.p3.2.m2.1.1" xref="S5.SS1.p3.2.m2.1.1.cmml"><mrow id="S5.SS1.p3.2.m2.1.1.2" xref="S5.SS1.p3.2.m2.1.1.2.cmml"><mi mathvariant="normal" id="S5.SS1.p3.2.m2.1.1.2.2" xref="S5.SS1.p3.2.m2.1.1.2.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p3.2.m2.1.1.2.1" xref="S5.SS1.p3.2.m2.1.1.2.1.cmml">​</mo><msup id="S5.SS1.p3.2.m2.1.1.2.3" xref="S5.SS1.p3.2.m2.1.1.2.3.cmml"><mi id="S5.SS1.p3.2.m2.1.1.2.3.2" xref="S5.SS1.p3.2.m2.1.1.2.3.2.cmml">𝒘</mi><mo id="S5.SS1.p3.2.m2.1.1.2.3.3" xref="S5.SS1.p3.2.m2.1.1.2.3.3.cmml">′</mo></msup></mrow><mo id="S5.SS1.p3.2.m2.1.1.1" xref="S5.SS1.p3.2.m2.1.1.1.cmml">=</mo><mrow id="S5.SS1.p3.2.m2.1.1.3" xref="S5.SS1.p3.2.m2.1.1.3.cmml"><mfrac id="S5.SS1.p3.2.m2.1.1.3.2" xref="S5.SS1.p3.2.m2.1.1.3.2.cmml"><mn id="S5.SS1.p3.2.m2.1.1.3.2.2" xref="S5.SS1.p3.2.m2.1.1.3.2.2.cmml">1</mn><mi id="S5.SS1.p3.2.m2.1.1.3.2.3" xref="S5.SS1.p3.2.m2.1.1.3.2.3.cmml">n</mi></mfrac><mo lspace="0em" rspace="0em" id="S5.SS1.p3.2.m2.1.1.3.1" xref="S5.SS1.p3.2.m2.1.1.3.1.cmml">​</mo><mrow id="S5.SS1.p3.2.m2.1.1.3.3" xref="S5.SS1.p3.2.m2.1.1.3.3.cmml"><msubsup id="S5.SS1.p3.2.m2.1.1.3.3.1" xref="S5.SS1.p3.2.m2.1.1.3.3.1.cmml"><mo id="S5.SS1.p3.2.m2.1.1.3.3.1.2.2" xref="S5.SS1.p3.2.m2.1.1.3.3.1.2.2.cmml">∑</mo><mrow id="S5.SS1.p3.2.m2.1.1.3.3.1.2.3" xref="S5.SS1.p3.2.m2.1.1.3.3.1.2.3.cmml"><mi id="S5.SS1.p3.2.m2.1.1.3.3.1.2.3.2" xref="S5.SS1.p3.2.m2.1.1.3.3.1.2.3.2.cmml">i</mi><mo id="S5.SS1.p3.2.m2.1.1.3.3.1.2.3.1" xref="S5.SS1.p3.2.m2.1.1.3.3.1.2.3.1.cmml">=</mo><mn id="S5.SS1.p3.2.m2.1.1.3.3.1.2.3.3" xref="S5.SS1.p3.2.m2.1.1.3.3.1.2.3.3.cmml">1</mn></mrow><mi id="S5.SS1.p3.2.m2.1.1.3.3.1.3" xref="S5.SS1.p3.2.m2.1.1.3.3.1.3.cmml">n</mi></msubsup><mrow id="S5.SS1.p3.2.m2.1.1.3.3.2" xref="S5.SS1.p3.2.m2.1.1.3.3.2.cmml"><mi mathvariant="normal" id="S5.SS1.p3.2.m2.1.1.3.3.2.2" xref="S5.SS1.p3.2.m2.1.1.3.3.2.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p3.2.m2.1.1.3.3.2.1" xref="S5.SS1.p3.2.m2.1.1.3.3.2.1.cmml">​</mo><msub id="S5.SS1.p3.2.m2.1.1.3.3.2.3" xref="S5.SS1.p3.2.m2.1.1.3.3.2.3.cmml"><mi id="S5.SS1.p3.2.m2.1.1.3.3.2.3.2" xref="S5.SS1.p3.2.m2.1.1.3.3.2.3.2.cmml">𝒘</mi><mi id="S5.SS1.p3.2.m2.1.1.3.3.2.3.3" xref="S5.SS1.p3.2.m2.1.1.3.3.2.3.3.cmml">i</mi></msub></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.2.m2.1b"><apply id="S5.SS1.p3.2.m2.1.1.cmml" xref="S5.SS1.p3.2.m2.1.1"><eq id="S5.SS1.p3.2.m2.1.1.1.cmml" xref="S5.SS1.p3.2.m2.1.1.1"></eq><apply id="S5.SS1.p3.2.m2.1.1.2.cmml" xref="S5.SS1.p3.2.m2.1.1.2"><times id="S5.SS1.p3.2.m2.1.1.2.1.cmml" xref="S5.SS1.p3.2.m2.1.1.2.1"></times><ci id="S5.SS1.p3.2.m2.1.1.2.2.cmml" xref="S5.SS1.p3.2.m2.1.1.2.2">Δ</ci><apply id="S5.SS1.p3.2.m2.1.1.2.3.cmml" xref="S5.SS1.p3.2.m2.1.1.2.3"><csymbol cd="ambiguous" id="S5.SS1.p3.2.m2.1.1.2.3.1.cmml" xref="S5.SS1.p3.2.m2.1.1.2.3">superscript</csymbol><ci id="S5.SS1.p3.2.m2.1.1.2.3.2.cmml" xref="S5.SS1.p3.2.m2.1.1.2.3.2">𝒘</ci><ci id="S5.SS1.p3.2.m2.1.1.2.3.3.cmml" xref="S5.SS1.p3.2.m2.1.1.2.3.3">′</ci></apply></apply><apply id="S5.SS1.p3.2.m2.1.1.3.cmml" xref="S5.SS1.p3.2.m2.1.1.3"><times id="S5.SS1.p3.2.m2.1.1.3.1.cmml" xref="S5.SS1.p3.2.m2.1.1.3.1"></times><apply id="S5.SS1.p3.2.m2.1.1.3.2.cmml" xref="S5.SS1.p3.2.m2.1.1.3.2"><divide id="S5.SS1.p3.2.m2.1.1.3.2.1.cmml" xref="S5.SS1.p3.2.m2.1.1.3.2"></divide><cn type="integer" id="S5.SS1.p3.2.m2.1.1.3.2.2.cmml" xref="S5.SS1.p3.2.m2.1.1.3.2.2">1</cn><ci id="S5.SS1.p3.2.m2.1.1.3.2.3.cmml" xref="S5.SS1.p3.2.m2.1.1.3.2.3">𝑛</ci></apply><apply id="S5.SS1.p3.2.m2.1.1.3.3.cmml" xref="S5.SS1.p3.2.m2.1.1.3.3"><apply id="S5.SS1.p3.2.m2.1.1.3.3.1.cmml" xref="S5.SS1.p3.2.m2.1.1.3.3.1"><csymbol cd="ambiguous" id="S5.SS1.p3.2.m2.1.1.3.3.1.1.cmml" xref="S5.SS1.p3.2.m2.1.1.3.3.1">superscript</csymbol><apply id="S5.SS1.p3.2.m2.1.1.3.3.1.2.cmml" xref="S5.SS1.p3.2.m2.1.1.3.3.1"><csymbol cd="ambiguous" id="S5.SS1.p3.2.m2.1.1.3.3.1.2.1.cmml" xref="S5.SS1.p3.2.m2.1.1.3.3.1">subscript</csymbol><sum id="S5.SS1.p3.2.m2.1.1.3.3.1.2.2.cmml" xref="S5.SS1.p3.2.m2.1.1.3.3.1.2.2"></sum><apply id="S5.SS1.p3.2.m2.1.1.3.3.1.2.3.cmml" xref="S5.SS1.p3.2.m2.1.1.3.3.1.2.3"><eq id="S5.SS1.p3.2.m2.1.1.3.3.1.2.3.1.cmml" xref="S5.SS1.p3.2.m2.1.1.3.3.1.2.3.1"></eq><ci id="S5.SS1.p3.2.m2.1.1.3.3.1.2.3.2.cmml" xref="S5.SS1.p3.2.m2.1.1.3.3.1.2.3.2">𝑖</ci><cn type="integer" id="S5.SS1.p3.2.m2.1.1.3.3.1.2.3.3.cmml" xref="S5.SS1.p3.2.m2.1.1.3.3.1.2.3.3">1</cn></apply></apply><ci id="S5.SS1.p3.2.m2.1.1.3.3.1.3.cmml" xref="S5.SS1.p3.2.m2.1.1.3.3.1.3">𝑛</ci></apply><apply id="S5.SS1.p3.2.m2.1.1.3.3.2.cmml" xref="S5.SS1.p3.2.m2.1.1.3.3.2"><times id="S5.SS1.p3.2.m2.1.1.3.3.2.1.cmml" xref="S5.SS1.p3.2.m2.1.1.3.3.2.1"></times><ci id="S5.SS1.p3.2.m2.1.1.3.3.2.2.cmml" xref="S5.SS1.p3.2.m2.1.1.3.3.2.2">Δ</ci><apply id="S5.SS1.p3.2.m2.1.1.3.3.2.3.cmml" xref="S5.SS1.p3.2.m2.1.1.3.3.2.3"><csymbol cd="ambiguous" id="S5.SS1.p3.2.m2.1.1.3.3.2.3.1.cmml" xref="S5.SS1.p3.2.m2.1.1.3.3.2.3">subscript</csymbol><ci id="S5.SS1.p3.2.m2.1.1.3.3.2.3.2.cmml" xref="S5.SS1.p3.2.m2.1.1.3.3.2.3.2">𝒘</ci><ci id="S5.SS1.p3.2.m2.1.1.3.3.2.3.3.cmml" xref="S5.SS1.p3.2.m2.1.1.3.3.2.3.3">𝑖</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.2.m2.1c">\Delta\bm{w}^{\prime}=\frac{1}{n}\sum_{i=1}^{n}\Delta\bm{w}_{i}</annotation></semantics></math>, where <math id="S5.SS1.p3.3.m3.1" class="ltx_Math" alttext="\Delta\bm{w}^{\prime}" display="inline"><semantics id="S5.SS1.p3.3.m3.1a"><mrow id="S5.SS1.p3.3.m3.1.1" xref="S5.SS1.p3.3.m3.1.1.cmml"><mi mathvariant="normal" id="S5.SS1.p3.3.m3.1.1.2" xref="S5.SS1.p3.3.m3.1.1.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p3.3.m3.1.1.1" xref="S5.SS1.p3.3.m3.1.1.1.cmml">​</mo><msup id="S5.SS1.p3.3.m3.1.1.3" xref="S5.SS1.p3.3.m3.1.1.3.cmml"><mi id="S5.SS1.p3.3.m3.1.1.3.2" xref="S5.SS1.p3.3.m3.1.1.3.2.cmml">𝒘</mi><mo id="S5.SS1.p3.3.m3.1.1.3.3" xref="S5.SS1.p3.3.m3.1.1.3.3.cmml">′</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.3.m3.1b"><apply id="S5.SS1.p3.3.m3.1.1.cmml" xref="S5.SS1.p3.3.m3.1.1"><times id="S5.SS1.p3.3.m3.1.1.1.cmml" xref="S5.SS1.p3.3.m3.1.1.1"></times><ci id="S5.SS1.p3.3.m3.1.1.2.cmml" xref="S5.SS1.p3.3.m3.1.1.2">Δ</ci><apply id="S5.SS1.p3.3.m3.1.1.3.cmml" xref="S5.SS1.p3.3.m3.1.1.3"><csymbol cd="ambiguous" id="S5.SS1.p3.3.m3.1.1.3.1.cmml" xref="S5.SS1.p3.3.m3.1.1.3">superscript</csymbol><ci id="S5.SS1.p3.3.m3.1.1.3.2.cmml" xref="S5.SS1.p3.3.m3.1.1.3.2">𝒘</ci><ci id="S5.SS1.p3.3.m3.1.1.3.3.cmml" xref="S5.SS1.p3.3.m3.1.1.3.3">′</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.3.m3.1c">\Delta\bm{w}^{\prime}</annotation></semantics></math> is the aggregated gradient.
Assume the <math id="S5.SS1.p3.4.m4.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S5.SS1.p3.4.m4.1a"><mi id="S5.SS1.p3.4.m4.1.1" xref="S5.SS1.p3.4.m4.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.4.m4.1b"><ci id="S5.SS1.p3.4.m4.1.1.cmml" xref="S5.SS1.p3.4.m4.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.4.m4.1c">n</annotation></semantics></math>-th participant is Byzantine, it can always make the aggregated gradient become any vector <math id="S5.SS1.p3.5.m5.1" class="ltx_Math" alttext="\bm{u}" display="inline"><semantics id="S5.SS1.p3.5.m5.1a"><mi id="S5.SS1.p3.5.m5.1.1" xref="S5.SS1.p3.5.m5.1.1.cmml">𝒖</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.5.m5.1b"><ci id="S5.SS1.p3.5.m5.1.1.cmml" xref="S5.SS1.p3.5.m5.1.1">𝒖</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.5.m5.1c">\bm{u}</annotation></semantics></math> by uploading the following gradient:</p>
<table id="S5.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S5.E2.m1.1" class="ltx_Math" alttext="\Delta\bm{w}_{n}=n\bm{u}-\sum_{i=1}^{n-1}\Delta\bm{w}_{i}." display="block"><semantics id="S5.E2.m1.1a"><mrow id="S5.E2.m1.1.1.1" xref="S5.E2.m1.1.1.1.1.cmml"><mrow id="S5.E2.m1.1.1.1.1" xref="S5.E2.m1.1.1.1.1.cmml"><mrow id="S5.E2.m1.1.1.1.1.2" xref="S5.E2.m1.1.1.1.1.2.cmml"><mi mathvariant="normal" id="S5.E2.m1.1.1.1.1.2.2" xref="S5.E2.m1.1.1.1.1.2.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S5.E2.m1.1.1.1.1.2.1" xref="S5.E2.m1.1.1.1.1.2.1.cmml">​</mo><msub id="S5.E2.m1.1.1.1.1.2.3" xref="S5.E2.m1.1.1.1.1.2.3.cmml"><mi id="S5.E2.m1.1.1.1.1.2.3.2" xref="S5.E2.m1.1.1.1.1.2.3.2.cmml">𝒘</mi><mi id="S5.E2.m1.1.1.1.1.2.3.3" xref="S5.E2.m1.1.1.1.1.2.3.3.cmml">n</mi></msub></mrow><mo id="S5.E2.m1.1.1.1.1.1" xref="S5.E2.m1.1.1.1.1.1.cmml">=</mo><mrow id="S5.E2.m1.1.1.1.1.3" xref="S5.E2.m1.1.1.1.1.3.cmml"><mrow id="S5.E2.m1.1.1.1.1.3.2" xref="S5.E2.m1.1.1.1.1.3.2.cmml"><mi id="S5.E2.m1.1.1.1.1.3.2.2" xref="S5.E2.m1.1.1.1.1.3.2.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.E2.m1.1.1.1.1.3.2.1" xref="S5.E2.m1.1.1.1.1.3.2.1.cmml">​</mo><mi id="S5.E2.m1.1.1.1.1.3.2.3" xref="S5.E2.m1.1.1.1.1.3.2.3.cmml">𝒖</mi></mrow><mo rspace="0.055em" id="S5.E2.m1.1.1.1.1.3.1" xref="S5.E2.m1.1.1.1.1.3.1.cmml">−</mo><mrow id="S5.E2.m1.1.1.1.1.3.3" xref="S5.E2.m1.1.1.1.1.3.3.cmml"><munderover id="S5.E2.m1.1.1.1.1.3.3.1" xref="S5.E2.m1.1.1.1.1.3.3.1.cmml"><mo movablelimits="false" id="S5.E2.m1.1.1.1.1.3.3.1.2.2" xref="S5.E2.m1.1.1.1.1.3.3.1.2.2.cmml">∑</mo><mrow id="S5.E2.m1.1.1.1.1.3.3.1.2.3" xref="S5.E2.m1.1.1.1.1.3.3.1.2.3.cmml"><mi id="S5.E2.m1.1.1.1.1.3.3.1.2.3.2" xref="S5.E2.m1.1.1.1.1.3.3.1.2.3.2.cmml">i</mi><mo id="S5.E2.m1.1.1.1.1.3.3.1.2.3.1" xref="S5.E2.m1.1.1.1.1.3.3.1.2.3.1.cmml">=</mo><mn id="S5.E2.m1.1.1.1.1.3.3.1.2.3.3" xref="S5.E2.m1.1.1.1.1.3.3.1.2.3.3.cmml">1</mn></mrow><mrow id="S5.E2.m1.1.1.1.1.3.3.1.3" xref="S5.E2.m1.1.1.1.1.3.3.1.3.cmml"><mi id="S5.E2.m1.1.1.1.1.3.3.1.3.2" xref="S5.E2.m1.1.1.1.1.3.3.1.3.2.cmml">n</mi><mo id="S5.E2.m1.1.1.1.1.3.3.1.3.1" xref="S5.E2.m1.1.1.1.1.3.3.1.3.1.cmml">−</mo><mn id="S5.E2.m1.1.1.1.1.3.3.1.3.3" xref="S5.E2.m1.1.1.1.1.3.3.1.3.3.cmml">1</mn></mrow></munderover><mrow id="S5.E2.m1.1.1.1.1.3.3.2" xref="S5.E2.m1.1.1.1.1.3.3.2.cmml"><mi mathvariant="normal" id="S5.E2.m1.1.1.1.1.3.3.2.2" xref="S5.E2.m1.1.1.1.1.3.3.2.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S5.E2.m1.1.1.1.1.3.3.2.1" xref="S5.E2.m1.1.1.1.1.3.3.2.1.cmml">​</mo><msub id="S5.E2.m1.1.1.1.1.3.3.2.3" xref="S5.E2.m1.1.1.1.1.3.3.2.3.cmml"><mi id="S5.E2.m1.1.1.1.1.3.3.2.3.2" xref="S5.E2.m1.1.1.1.1.3.3.2.3.2.cmml">𝒘</mi><mi id="S5.E2.m1.1.1.1.1.3.3.2.3.3" xref="S5.E2.m1.1.1.1.1.3.3.2.3.3.cmml">i</mi></msub></mrow></mrow></mrow></mrow><mo lspace="0em" id="S5.E2.m1.1.1.1.2" xref="S5.E2.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.E2.m1.1b"><apply id="S5.E2.m1.1.1.1.1.cmml" xref="S5.E2.m1.1.1.1"><eq id="S5.E2.m1.1.1.1.1.1.cmml" xref="S5.E2.m1.1.1.1.1.1"></eq><apply id="S5.E2.m1.1.1.1.1.2.cmml" xref="S5.E2.m1.1.1.1.1.2"><times id="S5.E2.m1.1.1.1.1.2.1.cmml" xref="S5.E2.m1.1.1.1.1.2.1"></times><ci id="S5.E2.m1.1.1.1.1.2.2.cmml" xref="S5.E2.m1.1.1.1.1.2.2">Δ</ci><apply id="S5.E2.m1.1.1.1.1.2.3.cmml" xref="S5.E2.m1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S5.E2.m1.1.1.1.1.2.3.1.cmml" xref="S5.E2.m1.1.1.1.1.2.3">subscript</csymbol><ci id="S5.E2.m1.1.1.1.1.2.3.2.cmml" xref="S5.E2.m1.1.1.1.1.2.3.2">𝒘</ci><ci id="S5.E2.m1.1.1.1.1.2.3.3.cmml" xref="S5.E2.m1.1.1.1.1.2.3.3">𝑛</ci></apply></apply><apply id="S5.E2.m1.1.1.1.1.3.cmml" xref="S5.E2.m1.1.1.1.1.3"><minus id="S5.E2.m1.1.1.1.1.3.1.cmml" xref="S5.E2.m1.1.1.1.1.3.1"></minus><apply id="S5.E2.m1.1.1.1.1.3.2.cmml" xref="S5.E2.m1.1.1.1.1.3.2"><times id="S5.E2.m1.1.1.1.1.3.2.1.cmml" xref="S5.E2.m1.1.1.1.1.3.2.1"></times><ci id="S5.E2.m1.1.1.1.1.3.2.2.cmml" xref="S5.E2.m1.1.1.1.1.3.2.2">𝑛</ci><ci id="S5.E2.m1.1.1.1.1.3.2.3.cmml" xref="S5.E2.m1.1.1.1.1.3.2.3">𝒖</ci></apply><apply id="S5.E2.m1.1.1.1.1.3.3.cmml" xref="S5.E2.m1.1.1.1.1.3.3"><apply id="S5.E2.m1.1.1.1.1.3.3.1.cmml" xref="S5.E2.m1.1.1.1.1.3.3.1"><csymbol cd="ambiguous" id="S5.E2.m1.1.1.1.1.3.3.1.1.cmml" xref="S5.E2.m1.1.1.1.1.3.3.1">superscript</csymbol><apply id="S5.E2.m1.1.1.1.1.3.3.1.2.cmml" xref="S5.E2.m1.1.1.1.1.3.3.1"><csymbol cd="ambiguous" id="S5.E2.m1.1.1.1.1.3.3.1.2.1.cmml" xref="S5.E2.m1.1.1.1.1.3.3.1">subscript</csymbol><sum id="S5.E2.m1.1.1.1.1.3.3.1.2.2.cmml" xref="S5.E2.m1.1.1.1.1.3.3.1.2.2"></sum><apply id="S5.E2.m1.1.1.1.1.3.3.1.2.3.cmml" xref="S5.E2.m1.1.1.1.1.3.3.1.2.3"><eq id="S5.E2.m1.1.1.1.1.3.3.1.2.3.1.cmml" xref="S5.E2.m1.1.1.1.1.3.3.1.2.3.1"></eq><ci id="S5.E2.m1.1.1.1.1.3.3.1.2.3.2.cmml" xref="S5.E2.m1.1.1.1.1.3.3.1.2.3.2">𝑖</ci><cn type="integer" id="S5.E2.m1.1.1.1.1.3.3.1.2.3.3.cmml" xref="S5.E2.m1.1.1.1.1.3.3.1.2.3.3">1</cn></apply></apply><apply id="S5.E2.m1.1.1.1.1.3.3.1.3.cmml" xref="S5.E2.m1.1.1.1.1.3.3.1.3"><minus id="S5.E2.m1.1.1.1.1.3.3.1.3.1.cmml" xref="S5.E2.m1.1.1.1.1.3.3.1.3.1"></minus><ci id="S5.E2.m1.1.1.1.1.3.3.1.3.2.cmml" xref="S5.E2.m1.1.1.1.1.3.3.1.3.2">𝑛</ci><cn type="integer" id="S5.E2.m1.1.1.1.1.3.3.1.3.3.cmml" xref="S5.E2.m1.1.1.1.1.3.3.1.3.3">1</cn></apply></apply><apply id="S5.E2.m1.1.1.1.1.3.3.2.cmml" xref="S5.E2.m1.1.1.1.1.3.3.2"><times id="S5.E2.m1.1.1.1.1.3.3.2.1.cmml" xref="S5.E2.m1.1.1.1.1.3.3.2.1"></times><ci id="S5.E2.m1.1.1.1.1.3.3.2.2.cmml" xref="S5.E2.m1.1.1.1.1.3.3.2.2">Δ</ci><apply id="S5.E2.m1.1.1.1.1.3.3.2.3.cmml" xref="S5.E2.m1.1.1.1.1.3.3.2.3"><csymbol cd="ambiguous" id="S5.E2.m1.1.1.1.1.3.3.2.3.1.cmml" xref="S5.E2.m1.1.1.1.1.3.3.2.3">subscript</csymbol><ci id="S5.E2.m1.1.1.1.1.3.3.2.3.2.cmml" xref="S5.E2.m1.1.1.1.1.3.3.2.3.2">𝒘</ci><ci id="S5.E2.m1.1.1.1.1.3.3.2.3.3.cmml" xref="S5.E2.m1.1.1.1.1.3.3.2.3.3">𝑖</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E2.m1.1c">\Delta\bm{w}_{n}=n\bm{u}-\sum_{i=1}^{n-1}\Delta\bm{w}_{i}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S5.SS1.p3.6" class="ltx_p">Such a simple attack exposes the vulnerability of FL against Byzantine attack.</p>
</div>
<div id="S5.SS1.p4" class="ltx_para">
<p id="S5.SS1.p4.6" class="ltx_p">Chen <span id="S5.SS1.p4.6.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib132" title="" class="ltx_ref">132</a>]</cite> discussed Byzantine attacks in Adam-based FL and proposed a camouflage attack that can camouflage the model updates and launch effective attacks. Their proposed attack also works on other well-known optimizers such as AdaGrad and RMSProp.
Baruch <span id="S5.SS1.p4.6.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib133" title="" class="ltx_ref">133</a>]</cite> showed that the core part of gradient descent algorithms is the direction of the descent. Specifically, for gradient descent algorithms, to guarantee the descent of the loss, the inner product between the ground-truth gradient and the robust aggregated gradient must be non-negative:</p>
<table id="S5.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S5.E3.m1.13" class="ltx_Math" alttext="\begin{split}\langle\Delta\bm{w},\Delta\bm{w}^{\prime}\rangle\geq 0,\end{split}" display="block"><semantics id="S5.E3.m1.13a"><mtable displaystyle="true" id="S5.E3.m1.13.13.2"><mtr id="S5.E3.m1.13.13.2a"><mtd class="ltx_align_right" columnalign="right" id="S5.E3.m1.13.13.2b"><mrow id="S5.E3.m1.13.13.2.12.12.12.12"><mrow id="S5.E3.m1.13.13.2.12.12.12.12.1"><mrow id="S5.E3.m1.13.13.2.12.12.12.12.1.2.2"><mo stretchy="false" id="S5.E3.m1.1.1.1.1.1.1" xref="S5.E3.m1.12.12.1.1.1.cmml">⟨</mo><mrow id="S5.E3.m1.13.13.2.12.12.12.12.1.1.1.1"><mi mathvariant="normal" id="S5.E3.m1.2.2.2.2.2.2" xref="S5.E3.m1.2.2.2.2.2.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S5.E3.m1.13.13.2.12.12.12.12.1.1.1.1.1" xref="S5.E3.m1.12.12.1.1.1.cmml">​</mo><mi id="S5.E3.m1.3.3.3.3.3.3" xref="S5.E3.m1.3.3.3.3.3.3.cmml">𝒘</mi></mrow><mo id="S5.E3.m1.4.4.4.4.4.4" xref="S5.E3.m1.12.12.1.1.1.cmml">,</mo><mrow id="S5.E3.m1.13.13.2.12.12.12.12.1.2.2.2"><mi mathvariant="normal" id="S5.E3.m1.5.5.5.5.5.5" xref="S5.E3.m1.5.5.5.5.5.5.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S5.E3.m1.13.13.2.12.12.12.12.1.2.2.2.1" xref="S5.E3.m1.12.12.1.1.1.cmml">​</mo><msup id="S5.E3.m1.13.13.2.12.12.12.12.1.2.2.2.2"><mi id="S5.E3.m1.6.6.6.6.6.6" xref="S5.E3.m1.6.6.6.6.6.6.cmml">𝒘</mi><mo id="S5.E3.m1.7.7.7.7.7.7.1" xref="S5.E3.m1.7.7.7.7.7.7.1.cmml">′</mo></msup></mrow><mo stretchy="false" id="S5.E3.m1.8.8.8.8.8.8" xref="S5.E3.m1.12.12.1.1.1.cmml">⟩</mo></mrow><mo id="S5.E3.m1.9.9.9.9.9.9" xref="S5.E3.m1.9.9.9.9.9.9.cmml">≥</mo><mn id="S5.E3.m1.10.10.10.10.10.10" xref="S5.E3.m1.10.10.10.10.10.10.cmml">0</mn></mrow><mo id="S5.E3.m1.11.11.11.11.11.11" xref="S5.E3.m1.12.12.1.1.1.cmml">,</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S5.E3.m1.13b"><apply id="S5.E3.m1.12.12.1.1.1.cmml" xref="S5.E3.m1.1.1.1.1.1.1"><geq id="S5.E3.m1.9.9.9.9.9.9.cmml" xref="S5.E3.m1.9.9.9.9.9.9"></geq><list id="S5.E3.m1.12.12.1.1.1.2.3.cmml" xref="S5.E3.m1.1.1.1.1.1.1"><apply id="S5.E3.m1.12.12.1.1.1.1.1.1.cmml" xref="S5.E3.m1.1.1.1.1.1.1"><times id="S5.E3.m1.12.12.1.1.1.1.1.1.1.cmml" xref="S5.E3.m1.1.1.1.1.1.1"></times><ci id="S5.E3.m1.2.2.2.2.2.2.cmml" xref="S5.E3.m1.2.2.2.2.2.2">Δ</ci><ci id="S5.E3.m1.3.3.3.3.3.3.cmml" xref="S5.E3.m1.3.3.3.3.3.3">𝒘</ci></apply><apply id="S5.E3.m1.12.12.1.1.1.2.2.2.cmml" xref="S5.E3.m1.1.1.1.1.1.1"><times id="S5.E3.m1.12.12.1.1.1.2.2.2.1.cmml" xref="S5.E3.m1.1.1.1.1.1.1"></times><ci id="S5.E3.m1.5.5.5.5.5.5.cmml" xref="S5.E3.m1.5.5.5.5.5.5">Δ</ci><apply id="S5.E3.m1.12.12.1.1.1.2.2.2.3.cmml" xref="S5.E3.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E3.m1.12.12.1.1.1.2.2.2.3.1.cmml" xref="S5.E3.m1.1.1.1.1.1.1">superscript</csymbol><ci id="S5.E3.m1.6.6.6.6.6.6.cmml" xref="S5.E3.m1.6.6.6.6.6.6">𝒘</ci><ci id="S5.E3.m1.7.7.7.7.7.7.1.cmml" xref="S5.E3.m1.7.7.7.7.7.7.1">′</ci></apply></apply></list><cn type="integer" id="S5.E3.m1.10.10.10.10.10.10.cmml" xref="S5.E3.m1.10.10.10.10.10.10">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E3.m1.13c">\begin{split}\langle\Delta\bm{w},\Delta\bm{w}^{\prime}\rangle\geq 0,\end{split}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S5.SS1.p4.5" class="ltx_p">where <math id="S5.SS1.p4.1.m1.2" class="ltx_Math" alttext="\langle\cdot,\cdot\rangle" display="inline"><semantics id="S5.SS1.p4.1.m1.2a"><mrow id="S5.SS1.p4.1.m1.2.3.2" xref="S5.SS1.p4.1.m1.2.3.1.cmml"><mo stretchy="false" id="S5.SS1.p4.1.m1.2.3.2.1" xref="S5.SS1.p4.1.m1.2.3.1.cmml">⟨</mo><mo lspace="0em" rspace="0em" id="S5.SS1.p4.1.m1.1.1" xref="S5.SS1.p4.1.m1.1.1.cmml">⋅</mo><mo rspace="0em" id="S5.SS1.p4.1.m1.2.3.2.2" xref="S5.SS1.p4.1.m1.2.3.1.cmml">,</mo><mo lspace="0em" rspace="0em" id="S5.SS1.p4.1.m1.2.2" xref="S5.SS1.p4.1.m1.2.2.cmml">⋅</mo><mo stretchy="false" id="S5.SS1.p4.1.m1.2.3.2.3" xref="S5.SS1.p4.1.m1.2.3.1.cmml">⟩</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.1.m1.2b"><list id="S5.SS1.p4.1.m1.2.3.1.cmml" xref="S5.SS1.p4.1.m1.2.3.2"><ci id="S5.SS1.p4.1.m1.1.1.cmml" xref="S5.SS1.p4.1.m1.1.1">⋅</ci><ci id="S5.SS1.p4.1.m1.2.2.cmml" xref="S5.SS1.p4.1.m1.2.2">⋅</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.1.m1.2c">\langle\cdot,\cdot\rangle</annotation></semantics></math> is the inner product operation, <math id="S5.SS1.p4.2.m2.1" class="ltx_Math" alttext="\Delta\bm{w}" display="inline"><semantics id="S5.SS1.p4.2.m2.1a"><mrow id="S5.SS1.p4.2.m2.1.1" xref="S5.SS1.p4.2.m2.1.1.cmml"><mi mathvariant="normal" id="S5.SS1.p4.2.m2.1.1.2" xref="S5.SS1.p4.2.m2.1.1.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p4.2.m2.1.1.1" xref="S5.SS1.p4.2.m2.1.1.1.cmml">​</mo><mi id="S5.SS1.p4.2.m2.1.1.3" xref="S5.SS1.p4.2.m2.1.1.3.cmml">𝒘</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.2.m2.1b"><apply id="S5.SS1.p4.2.m2.1.1.cmml" xref="S5.SS1.p4.2.m2.1.1"><times id="S5.SS1.p4.2.m2.1.1.1.cmml" xref="S5.SS1.p4.2.m2.1.1.1"></times><ci id="S5.SS1.p4.2.m2.1.1.2.cmml" xref="S5.SS1.p4.2.m2.1.1.2">Δ</ci><ci id="S5.SS1.p4.2.m2.1.1.3.cmml" xref="S5.SS1.p4.2.m2.1.1.3">𝒘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.2.m2.1c">\Delta\bm{w}</annotation></semantics></math> is the optimal gradient, and <math id="S5.SS1.p4.3.m3.1" class="ltx_Math" alttext="\Delta\bm{w}^{\prime}=" display="inline"><semantics id="S5.SS1.p4.3.m3.1a"><mrow id="S5.SS1.p4.3.m3.1.1" xref="S5.SS1.p4.3.m3.1.1.cmml"><mrow id="S5.SS1.p4.3.m3.1.1.2" xref="S5.SS1.p4.3.m3.1.1.2.cmml"><mi mathvariant="normal" id="S5.SS1.p4.3.m3.1.1.2.2" xref="S5.SS1.p4.3.m3.1.1.2.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p4.3.m3.1.1.2.1" xref="S5.SS1.p4.3.m3.1.1.2.1.cmml">​</mo><msup id="S5.SS1.p4.3.m3.1.1.2.3" xref="S5.SS1.p4.3.m3.1.1.2.3.cmml"><mi id="S5.SS1.p4.3.m3.1.1.2.3.2" xref="S5.SS1.p4.3.m3.1.1.2.3.2.cmml">𝒘</mi><mo id="S5.SS1.p4.3.m3.1.1.2.3.3" xref="S5.SS1.p4.3.m3.1.1.2.3.3.cmml">′</mo></msup></mrow><mo id="S5.SS1.p4.3.m3.1.1.1" xref="S5.SS1.p4.3.m3.1.1.1.cmml">=</mo><mi id="S5.SS1.p4.3.m3.1.1.3" xref="S5.SS1.p4.3.m3.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.3.m3.1b"><apply id="S5.SS1.p4.3.m3.1.1.cmml" xref="S5.SS1.p4.3.m3.1.1"><eq id="S5.SS1.p4.3.m3.1.1.1.cmml" xref="S5.SS1.p4.3.m3.1.1.1"></eq><apply id="S5.SS1.p4.3.m3.1.1.2.cmml" xref="S5.SS1.p4.3.m3.1.1.2"><times id="S5.SS1.p4.3.m3.1.1.2.1.cmml" xref="S5.SS1.p4.3.m3.1.1.2.1"></times><ci id="S5.SS1.p4.3.m3.1.1.2.2.cmml" xref="S5.SS1.p4.3.m3.1.1.2.2">Δ</ci><apply id="S5.SS1.p4.3.m3.1.1.2.3.cmml" xref="S5.SS1.p4.3.m3.1.1.2.3"><csymbol cd="ambiguous" id="S5.SS1.p4.3.m3.1.1.2.3.1.cmml" xref="S5.SS1.p4.3.m3.1.1.2.3">superscript</csymbol><ci id="S5.SS1.p4.3.m3.1.1.2.3.2.cmml" xref="S5.SS1.p4.3.m3.1.1.2.3.2">𝒘</ci><ci id="S5.SS1.p4.3.m3.1.1.2.3.3.cmml" xref="S5.SS1.p4.3.m3.1.1.2.3.3">′</ci></apply></apply><csymbol cd="latexml" id="S5.SS1.p4.3.m3.1.1.3.cmml" xref="S5.SS1.p4.3.m3.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.3.m3.1c">\Delta\bm{w}^{\prime}=</annotation></semantics></math> aggregate<math id="S5.SS1.p4.4.m4.3" class="ltx_Math" alttext="(\Delta\bm{w}_{1},\cdots,\Delta\bm{w}_{n})" display="inline"><semantics id="S5.SS1.p4.4.m4.3a"><mrow id="S5.SS1.p4.4.m4.3.3.2" xref="S5.SS1.p4.4.m4.3.3.3.cmml"><mo stretchy="false" id="S5.SS1.p4.4.m4.3.3.2.3" xref="S5.SS1.p4.4.m4.3.3.3.cmml">(</mo><mrow id="S5.SS1.p4.4.m4.2.2.1.1" xref="S5.SS1.p4.4.m4.2.2.1.1.cmml"><mi mathvariant="normal" id="S5.SS1.p4.4.m4.2.2.1.1.2" xref="S5.SS1.p4.4.m4.2.2.1.1.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p4.4.m4.2.2.1.1.1" xref="S5.SS1.p4.4.m4.2.2.1.1.1.cmml">​</mo><msub id="S5.SS1.p4.4.m4.2.2.1.1.3" xref="S5.SS1.p4.4.m4.2.2.1.1.3.cmml"><mi id="S5.SS1.p4.4.m4.2.2.1.1.3.2" xref="S5.SS1.p4.4.m4.2.2.1.1.3.2.cmml">𝒘</mi><mn id="S5.SS1.p4.4.m4.2.2.1.1.3.3" xref="S5.SS1.p4.4.m4.2.2.1.1.3.3.cmml">1</mn></msub></mrow><mo id="S5.SS1.p4.4.m4.3.3.2.4" xref="S5.SS1.p4.4.m4.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S5.SS1.p4.4.m4.1.1" xref="S5.SS1.p4.4.m4.1.1.cmml">⋯</mi><mo id="S5.SS1.p4.4.m4.3.3.2.5" xref="S5.SS1.p4.4.m4.3.3.3.cmml">,</mo><mrow id="S5.SS1.p4.4.m4.3.3.2.2" xref="S5.SS1.p4.4.m4.3.3.2.2.cmml"><mi mathvariant="normal" id="S5.SS1.p4.4.m4.3.3.2.2.2" xref="S5.SS1.p4.4.m4.3.3.2.2.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p4.4.m4.3.3.2.2.1" xref="S5.SS1.p4.4.m4.3.3.2.2.1.cmml">​</mo><msub id="S5.SS1.p4.4.m4.3.3.2.2.3" xref="S5.SS1.p4.4.m4.3.3.2.2.3.cmml"><mi id="S5.SS1.p4.4.m4.3.3.2.2.3.2" xref="S5.SS1.p4.4.m4.3.3.2.2.3.2.cmml">𝒘</mi><mi id="S5.SS1.p4.4.m4.3.3.2.2.3.3" xref="S5.SS1.p4.4.m4.3.3.2.2.3.3.cmml">n</mi></msub></mrow><mo stretchy="false" id="S5.SS1.p4.4.m4.3.3.2.6" xref="S5.SS1.p4.4.m4.3.3.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.4.m4.3b"><vector id="S5.SS1.p4.4.m4.3.3.3.cmml" xref="S5.SS1.p4.4.m4.3.3.2"><apply id="S5.SS1.p4.4.m4.2.2.1.1.cmml" xref="S5.SS1.p4.4.m4.2.2.1.1"><times id="S5.SS1.p4.4.m4.2.2.1.1.1.cmml" xref="S5.SS1.p4.4.m4.2.2.1.1.1"></times><ci id="S5.SS1.p4.4.m4.2.2.1.1.2.cmml" xref="S5.SS1.p4.4.m4.2.2.1.1.2">Δ</ci><apply id="S5.SS1.p4.4.m4.2.2.1.1.3.cmml" xref="S5.SS1.p4.4.m4.2.2.1.1.3"><csymbol cd="ambiguous" id="S5.SS1.p4.4.m4.2.2.1.1.3.1.cmml" xref="S5.SS1.p4.4.m4.2.2.1.1.3">subscript</csymbol><ci id="S5.SS1.p4.4.m4.2.2.1.1.3.2.cmml" xref="S5.SS1.p4.4.m4.2.2.1.1.3.2">𝒘</ci><cn type="integer" id="S5.SS1.p4.4.m4.2.2.1.1.3.3.cmml" xref="S5.SS1.p4.4.m4.2.2.1.1.3.3">1</cn></apply></apply><ci id="S5.SS1.p4.4.m4.1.1.cmml" xref="S5.SS1.p4.4.m4.1.1">⋯</ci><apply id="S5.SS1.p4.4.m4.3.3.2.2.cmml" xref="S5.SS1.p4.4.m4.3.3.2.2"><times id="S5.SS1.p4.4.m4.3.3.2.2.1.cmml" xref="S5.SS1.p4.4.m4.3.3.2.2.1"></times><ci id="S5.SS1.p4.4.m4.3.3.2.2.2.cmml" xref="S5.SS1.p4.4.m4.3.3.2.2.2">Δ</ci><apply id="S5.SS1.p4.4.m4.3.3.2.2.3.cmml" xref="S5.SS1.p4.4.m4.3.3.2.2.3"><csymbol cd="ambiguous" id="S5.SS1.p4.4.m4.3.3.2.2.3.1.cmml" xref="S5.SS1.p4.4.m4.3.3.2.2.3">subscript</csymbol><ci id="S5.SS1.p4.4.m4.3.3.2.2.3.2.cmml" xref="S5.SS1.p4.4.m4.3.3.2.2.3.2">𝒘</ci><ci id="S5.SS1.p4.4.m4.3.3.2.2.3.3.cmml" xref="S5.SS1.p4.4.m4.3.3.2.2.3.3">𝑛</ci></apply></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.4.m4.3c">(\Delta\bm{w}_{1},\cdots,\Delta\bm{w}_{n})</annotation></semantics></math> is the aggregated gradient with aggregate<math id="S5.SS1.p4.5.m5.1" class="ltx_Math" alttext="(\cdot)" display="inline"><semantics id="S5.SS1.p4.5.m5.1a"><mrow id="S5.SS1.p4.5.m5.1.2.2"><mo stretchy="false" id="S5.SS1.p4.5.m5.1.2.2.1">(</mo><mo lspace="0em" rspace="0em" id="S5.SS1.p4.5.m5.1.1" xref="S5.SS1.p4.5.m5.1.1.cmml">⋅</mo><mo stretchy="false" id="S5.SS1.p4.5.m5.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.5.m5.1b"><ci id="S5.SS1.p4.5.m5.1.1.cmml" xref="S5.SS1.p4.5.m5.1.1">⋅</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.5.m5.1c">(\cdot)</annotation></semantics></math> being arbitrary aggregation function.
To make the aggregation fail, they proposed an “inner product manipulation attack” that can make the inner product between the ground-truth gradient and the robust aggregated gradient negative. To do this, each Byzantine participant uploaded the negative of the average benign gradients. They showed the proposed attack can successfully bypass Coordinate-wise Median <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> and Krum <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. Xie <span id="S5.SS1.p4.5.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite> claimed that by consistently applying small changes to many parameters, a Byzantine participant can perturb the model’s convergence. First, they used the local data of Byzantine participants to estimate the mean and standard deviation of the distribution.
Then, they analyzed the range in which changes to the parameters will not be detected by the defense, and upon choosing the maxima of this range the convergence is averted.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS2.4.1.1" class="ltx_text">V-B</span> </span><span id="S5.SS2.5.2" class="ltx_text ltx_font_italic">Targeted Attacks</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">In targeted poisoning attacks, the learnt model outputs the target label specified by the adversary for particular testing examples, <span id="S5.SS2.p1.1.1" class="ltx_text ltx_font_italic">e.g.</span>, predicting spams as non-spams, and predicting attacker-desired labels for testing examples with a particular Trojan trigger (backdoor/trojan attacks). However, the testing error for other testing examples is unaffected.
Generally, targeted attacks is more difficult to conduct than untargeted attacks as the attacker has a specific goal to achieve.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">One common example of targeted poisoning attack is the label-flipping attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib124" title="" class="ltx_ref">124</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. The labels of honest training examples of one class are flipped to another class while the features of the data are kept unchanged. For example, the malicious participants in the system can poison their dataset by flipping all 1s into 7s. A successful attack produces a model that is unable to correctly classify 1s and incorrectly predicts them to be 7s.</p>
</div>
<div id="S5.SS2.p3" class="ltx_para">
<p id="S5.SS2.p3.1" class="ltx_p">Another realistic targeted poisoning attack is backdoor poisoning attack, in which an adversary can modify individual features or small regions of the original training dataset to implant a backdoor trigger into the model. The model will behave normally on clean data, yet will constantly predict a target class whenever the trigger (<span id="S5.SS2.p3.1.1" class="ltx_text ltx_font_italic">e.g.</span>, a stamp on an image) appears. For instance, a backdoor attack can cause the FL model to reach 100% accuracy on the backdoor task, <span id="S5.SS2.p3.1.2" class="ltx_text ltx_font_italic">e.g.</span>, to control an image classifier to assign an attacker-chosen label to images with certain features in an image-classification task, or a next-word predictor completes certain sentences with an attacker-chosen word in a word-prediction task <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>.</p>
</div>
<div id="S5.SS2.p4" class="ltx_para">
<p id="S5.SS2.p4.1" class="ltx_p">Backdoor attacks can be further divided into two categories: dirty-label attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib129" title="" class="ltx_ref">129</a>, <a href="#bib.bib128" title="" class="ltx_ref">128</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>, <a href="#bib.bib134" title="" class="ltx_ref">134</a>]</cite> and clean-label attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib135" title="" class="ltx_ref">135</a>, <a href="#bib.bib136" title="" class="ltx_ref">136</a>, <a href="#bib.bib130" title="" class="ltx_ref">130</a>, <a href="#bib.bib137" title="" class="ltx_ref">137</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>, <a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite>.
Clean-label attacks assume that the adversary cannot change the label of any training data as there is a process by which data are certified as belonging to the correct class and the poisoning of data samples has to be imperceptible. In contrast, in dirty-label poisoning, the adversary can introduce a number of data samples that are expected to be misclassified by the model with the desired target label into the training data. Clean-label attacks are arguably stealthier as they do not change the labels.</p>
</div>
<div id="S5.SS2.p5" class="ltx_para">
<p id="S5.SS2.p5.1" class="ltx_p">The targeted poisoning attack in FL can be carried out by any FL participant or via collusion on either the data or the gradients. Bhagoji <span id="S5.SS2.p5.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> demonstrated a single, non-colluding malicious participant can cause the model to misclassify a set of chosen inputs with high confidence. Bagdasaryan <span id="S5.SS2.p5.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> pointed out that the poisoned updates can be generated by training the local model on backdoored local training data, and even a single-shot attack may be enough to inject a backdoor into the global model. Xie <span id="S5.SS2.p5.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> demonstrated that a global trigger pattern can be decomposed into separate local patterns and embedded into the training set of colluding adversarial participants respectively. The impact on the FL model depends on the extent to which the backdoor participants engage in the attacks, and the amount of training data being poisoned. A recent work shows that poisoning edge-case (low probability) training samples are more effective <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>.</p>
</div>
<div id="S5.SS2.p6" class="ltx_para">
<p id="S5.SS2.p6.2" class="ltx_p">Lastly, we remark that most of the previous research on poisoning attacks focus on Byzantine or backdoor attackers. A system that allows participants to join and leave is susceptible to Sybil attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib138" title="" class="ltx_ref">138</a>]</cite>, in which an attacker gains influence by joining a system to inject <math id="S5.SS2.p6.1.m1.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S5.SS2.p6.1.m1.1a"><mi id="S5.SS2.p6.1.m1.1.1" xref="S5.SS2.p6.1.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p6.1.m1.1b"><ci id="S5.SS2.p6.1.m1.1.1.cmml" xref="S5.SS2.p6.1.m1.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p6.1.m1.1c">c</annotation></semantics></math> fake participants into the FL system or compromise <math id="S5.SS2.p6.2.m2.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S5.SS2.p6.2.m2.1a"><mi id="S5.SS2.p6.2.m2.1.1" xref="S5.SS2.p6.2.m2.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p6.2.m2.1b"><ci id="S5.SS2.p6.2.m2.1.1.cmml" xref="S5.SS2.p6.2.m2.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p6.2.m2.1c">c</annotation></semantics></math> benign participants <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. Sybil attacks can be launched in both the untargeted and targeted manner. For example, targeted poisoning can be conducted by sybil clones, who contribute updates towards a specific poisoning objective <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. Concretely, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> considered two types of targeted attacks by sybil clones: label-flipping attacks and backdoor attacks.</p>
</div>
<figure id="S5.T6" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S5.T6.42.2.1" class="ltx_text" style="font-size:90%;">TABLE VI</span>: </span><span id="S5.T6.2.1" class="ltx_text" style="font-size:90%;">The state-of-the-art defenses against federated learning poisoning. <math id="S5.T6.2.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S5.T6.2.1.m1.1b"><mi id="S5.T6.2.1.m1.1.1" xref="S5.T6.2.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S5.T6.2.1.m1.1c"><ci id="S5.T6.2.1.m1.1.1.cmml" xref="S5.T6.2.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.2.1.m1.1d">n</annotation></semantics></math> is number of participants. Note that some defenses have no theoretic breaking point.</span></figcaption>
<div id="S5.T6.40" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:698.5pt;height:162pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-38.8pt,9.0pt) scale(0.9,0.9) ;">
<table id="S5.T6.40.38" class="ltx_tabular ltx_align_middle">
<tr id="S5.T6.40.38.39" class="ltx_tr">
<td id="S5.T6.40.38.39.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S5.T6.40.38.39.1.1" class="ltx_text ltx_font_bold">Defense</span></td>
<td id="S5.T6.40.38.39.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T6.40.38.39.2.1" class="ltx_text ltx_font_bold">Technique</span></td>
<td id="S5.T6.40.38.39.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T6.40.38.39.3.1" class="ltx_text ltx_font_bold">IID Data</span></td>
<td id="S5.T6.40.38.39.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T6.40.38.39.4.1" class="ltx_text ltx_font_bold">Non-IID Data</span></td>
<td id="S5.T6.40.38.39.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T6.40.38.39.5.1" class="ltx_text ltx_font_bold">Breaking Point</span></td>
<td id="S5.T6.40.38.39.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T6.40.38.39.6.1" class="ltx_text ltx_font_bold">Targeted Poisoning</span></td>
<td id="S5.T6.40.38.39.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T6.40.38.39.7.1" class="ltx_text ltx_font_bold">Untargeted Poisoning</span></td>
</tr>
<tr id="S5.T6.6.4.4" class="ltx_tr">
<td id="S5.T6.6.4.4.5" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">AUROR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib139" title="" class="ltx_ref">139</a>]</cite>
</td>
<td id="S5.T6.6.4.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Clustering</td>
<td id="S5.T6.3.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.3.1.1.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T6.3.1.1.1.m1.1a"><mi mathvariant="normal" id="S5.T6.3.1.1.1.m1.1.1" xref="S5.T6.3.1.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T6.3.1.1.1.m1.1b"><ci id="S5.T6.3.1.1.1.m1.1.1.cmml" xref="S5.T6.3.1.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.3.1.1.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T6.4.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.4.2.2.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T6.4.2.2.2.m1.1a"><mo id="S5.T6.4.2.2.2.m1.1.1" xref="S5.T6.4.2.2.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T6.4.2.2.2.m1.1b"><times id="S5.T6.4.2.2.2.m1.1.1.cmml" xref="S5.T6.4.2.2.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.4.2.2.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T6.6.4.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NA</td>
<td id="S5.T6.5.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.5.3.3.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T6.5.3.3.3.m1.1a"><mo id="S5.T6.5.3.3.3.m1.1.1" xref="S5.T6.5.3.3.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T6.5.3.3.3.m1.1b"><times id="S5.T6.5.3.3.3.m1.1.1.cmml" xref="S5.T6.5.3.3.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.5.3.3.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T6.6.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.6.4.4.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T6.6.4.4.4.m1.1a"><mi mathvariant="normal" id="S5.T6.6.4.4.4.m1.1.1" xref="S5.T6.6.4.4.4.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T6.6.4.4.4.m1.1b"><ci id="S5.T6.6.4.4.4.m1.1.1.cmml" xref="S5.T6.6.4.4.4.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.6.4.4.4.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S5.T6.11.9.9" class="ltx_tr">
<td id="S5.T6.11.9.9.6" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Krum/Multi-Krum <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>
</td>
<td id="S5.T6.11.9.9.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Euclidean distance</td>
<td id="S5.T6.7.5.5.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.7.5.5.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T6.7.5.5.1.m1.1a"><mi mathvariant="normal" id="S5.T6.7.5.5.1.m1.1.1" xref="S5.T6.7.5.5.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T6.7.5.5.1.m1.1b"><ci id="S5.T6.7.5.5.1.m1.1.1.cmml" xref="S5.T6.7.5.5.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.7.5.5.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T6.8.6.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.8.6.6.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T6.8.6.6.2.m1.1a"><mo id="S5.T6.8.6.6.2.m1.1.1" xref="S5.T6.8.6.6.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T6.8.6.6.2.m1.1b"><times id="S5.T6.8.6.6.2.m1.1.1.cmml" xref="S5.T6.8.6.6.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.8.6.6.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T6.9.7.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.9.7.7.3.m1.1" class="ltx_Math" alttext="(n-2)/2n" display="inline"><semantics id="S5.T6.9.7.7.3.m1.1a"><mrow id="S5.T6.9.7.7.3.m1.1.1" xref="S5.T6.9.7.7.3.m1.1.1.cmml"><mrow id="S5.T6.9.7.7.3.m1.1.1.1" xref="S5.T6.9.7.7.3.m1.1.1.1.cmml"><mrow id="S5.T6.9.7.7.3.m1.1.1.1.1.1" xref="S5.T6.9.7.7.3.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.T6.9.7.7.3.m1.1.1.1.1.1.2" xref="S5.T6.9.7.7.3.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T6.9.7.7.3.m1.1.1.1.1.1.1" xref="S5.T6.9.7.7.3.m1.1.1.1.1.1.1.cmml"><mi id="S5.T6.9.7.7.3.m1.1.1.1.1.1.1.2" xref="S5.T6.9.7.7.3.m1.1.1.1.1.1.1.2.cmml">n</mi><mo id="S5.T6.9.7.7.3.m1.1.1.1.1.1.1.1" xref="S5.T6.9.7.7.3.m1.1.1.1.1.1.1.1.cmml">−</mo><mn id="S5.T6.9.7.7.3.m1.1.1.1.1.1.1.3" xref="S5.T6.9.7.7.3.m1.1.1.1.1.1.1.3.cmml">2</mn></mrow><mo stretchy="false" id="S5.T6.9.7.7.3.m1.1.1.1.1.1.3" xref="S5.T6.9.7.7.3.m1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S5.T6.9.7.7.3.m1.1.1.1.2" xref="S5.T6.9.7.7.3.m1.1.1.1.2.cmml">/</mo><mn id="S5.T6.9.7.7.3.m1.1.1.1.3" xref="S5.T6.9.7.7.3.m1.1.1.1.3.cmml">2</mn></mrow><mo lspace="0em" rspace="0em" id="S5.T6.9.7.7.3.m1.1.1.2" xref="S5.T6.9.7.7.3.m1.1.1.2.cmml">​</mo><mi id="S5.T6.9.7.7.3.m1.1.1.3" xref="S5.T6.9.7.7.3.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.T6.9.7.7.3.m1.1b"><apply id="S5.T6.9.7.7.3.m1.1.1.cmml" xref="S5.T6.9.7.7.3.m1.1.1"><times id="S5.T6.9.7.7.3.m1.1.1.2.cmml" xref="S5.T6.9.7.7.3.m1.1.1.2"></times><apply id="S5.T6.9.7.7.3.m1.1.1.1.cmml" xref="S5.T6.9.7.7.3.m1.1.1.1"><divide id="S5.T6.9.7.7.3.m1.1.1.1.2.cmml" xref="S5.T6.9.7.7.3.m1.1.1.1.2"></divide><apply id="S5.T6.9.7.7.3.m1.1.1.1.1.1.1.cmml" xref="S5.T6.9.7.7.3.m1.1.1.1.1.1"><minus id="S5.T6.9.7.7.3.m1.1.1.1.1.1.1.1.cmml" xref="S5.T6.9.7.7.3.m1.1.1.1.1.1.1.1"></minus><ci id="S5.T6.9.7.7.3.m1.1.1.1.1.1.1.2.cmml" xref="S5.T6.9.7.7.3.m1.1.1.1.1.1.1.2">𝑛</ci><cn type="integer" id="S5.T6.9.7.7.3.m1.1.1.1.1.1.1.3.cmml" xref="S5.T6.9.7.7.3.m1.1.1.1.1.1.1.3">2</cn></apply><cn type="integer" id="S5.T6.9.7.7.3.m1.1.1.1.3.cmml" xref="S5.T6.9.7.7.3.m1.1.1.1.3">2</cn></apply><ci id="S5.T6.9.7.7.3.m1.1.1.3.cmml" xref="S5.T6.9.7.7.3.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.9.7.7.3.m1.1c">(n-2)/2n</annotation></semantics></math></td>
<td id="S5.T6.10.8.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.10.8.8.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T6.10.8.8.4.m1.1a"><mo id="S5.T6.10.8.8.4.m1.1.1" xref="S5.T6.10.8.8.4.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T6.10.8.8.4.m1.1b"><times id="S5.T6.10.8.8.4.m1.1.1.cmml" xref="S5.T6.10.8.8.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.10.8.8.4.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T6.11.9.9.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.11.9.9.5.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T6.11.9.9.5.m1.1a"><mi mathvariant="normal" id="S5.T6.11.9.9.5.m1.1.1" xref="S5.T6.11.9.9.5.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T6.11.9.9.5.m1.1b"><ci id="S5.T6.11.9.9.5.m1.1.1.cmml" xref="S5.T6.11.9.9.5.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.11.9.9.5.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S5.T6.15.13.13" class="ltx_tr">
<td id="S5.T6.15.13.13.5" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Coordinate-wise Median <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>
</td>
<td id="S5.T6.15.13.13.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Coordinate-wise median</td>
<td id="S5.T6.12.10.10.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.12.10.10.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T6.12.10.10.1.m1.1a"><mi mathvariant="normal" id="S5.T6.12.10.10.1.m1.1.1" xref="S5.T6.12.10.10.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T6.12.10.10.1.m1.1b"><ci id="S5.T6.12.10.10.1.m1.1.1.cmml" xref="S5.T6.12.10.10.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.12.10.10.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T6.13.11.11.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.13.11.11.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T6.13.11.11.2.m1.1a"><mo id="S5.T6.13.11.11.2.m1.1.1" xref="S5.T6.13.11.11.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T6.13.11.11.2.m1.1b"><times id="S5.T6.13.11.11.2.m1.1.1.cmml" xref="S5.T6.13.11.11.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.13.11.11.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T6.15.13.13.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1/2</td>
<td id="S5.T6.14.12.12.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.14.12.12.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T6.14.12.12.3.m1.1a"><mo id="S5.T6.14.12.12.3.m1.1.1" xref="S5.T6.14.12.12.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T6.14.12.12.3.m1.1b"><times id="S5.T6.14.12.12.3.m1.1.1.cmml" xref="S5.T6.14.12.12.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.14.12.12.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T6.15.13.13.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.15.13.13.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T6.15.13.13.4.m1.1a"><mi mathvariant="normal" id="S5.T6.15.13.13.4.m1.1.1" xref="S5.T6.15.13.13.4.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T6.15.13.13.4.m1.1b"><ci id="S5.T6.15.13.13.4.m1.1.1.cmml" xref="S5.T6.15.13.13.4.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.15.13.13.4.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S5.T6.20.18.18" class="ltx_tr">
<td id="S5.T6.20.18.18.6" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Bulyan <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib140" title="" class="ltx_ref">140</a>]</cite>
</td>
<td id="S5.T6.20.18.18.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Krum + trimmed median</td>
<td id="S5.T6.16.14.14.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.16.14.14.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T6.16.14.14.1.m1.1a"><mi mathvariant="normal" id="S5.T6.16.14.14.1.m1.1.1" xref="S5.T6.16.14.14.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T6.16.14.14.1.m1.1b"><ci id="S5.T6.16.14.14.1.m1.1.1.cmml" xref="S5.T6.16.14.14.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.16.14.14.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T6.17.15.15.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.17.15.15.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T6.17.15.15.2.m1.1a"><mo id="S5.T6.17.15.15.2.m1.1.1" xref="S5.T6.17.15.15.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T6.17.15.15.2.m1.1b"><times id="S5.T6.17.15.15.2.m1.1.1.cmml" xref="S5.T6.17.15.15.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.17.15.15.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T6.18.16.16.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.18.16.16.3.m1.1" class="ltx_Math" alttext="(n-3)/4n" display="inline"><semantics id="S5.T6.18.16.16.3.m1.1a"><mrow id="S5.T6.18.16.16.3.m1.1.1" xref="S5.T6.18.16.16.3.m1.1.1.cmml"><mrow id="S5.T6.18.16.16.3.m1.1.1.1" xref="S5.T6.18.16.16.3.m1.1.1.1.cmml"><mrow id="S5.T6.18.16.16.3.m1.1.1.1.1.1" xref="S5.T6.18.16.16.3.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.T6.18.16.16.3.m1.1.1.1.1.1.2" xref="S5.T6.18.16.16.3.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T6.18.16.16.3.m1.1.1.1.1.1.1" xref="S5.T6.18.16.16.3.m1.1.1.1.1.1.1.cmml"><mi id="S5.T6.18.16.16.3.m1.1.1.1.1.1.1.2" xref="S5.T6.18.16.16.3.m1.1.1.1.1.1.1.2.cmml">n</mi><mo id="S5.T6.18.16.16.3.m1.1.1.1.1.1.1.1" xref="S5.T6.18.16.16.3.m1.1.1.1.1.1.1.1.cmml">−</mo><mn id="S5.T6.18.16.16.3.m1.1.1.1.1.1.1.3" xref="S5.T6.18.16.16.3.m1.1.1.1.1.1.1.3.cmml">3</mn></mrow><mo stretchy="false" id="S5.T6.18.16.16.3.m1.1.1.1.1.1.3" xref="S5.T6.18.16.16.3.m1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S5.T6.18.16.16.3.m1.1.1.1.2" xref="S5.T6.18.16.16.3.m1.1.1.1.2.cmml">/</mo><mn id="S5.T6.18.16.16.3.m1.1.1.1.3" xref="S5.T6.18.16.16.3.m1.1.1.1.3.cmml">4</mn></mrow><mo lspace="0em" rspace="0em" id="S5.T6.18.16.16.3.m1.1.1.2" xref="S5.T6.18.16.16.3.m1.1.1.2.cmml">​</mo><mi id="S5.T6.18.16.16.3.m1.1.1.3" xref="S5.T6.18.16.16.3.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.T6.18.16.16.3.m1.1b"><apply id="S5.T6.18.16.16.3.m1.1.1.cmml" xref="S5.T6.18.16.16.3.m1.1.1"><times id="S5.T6.18.16.16.3.m1.1.1.2.cmml" xref="S5.T6.18.16.16.3.m1.1.1.2"></times><apply id="S5.T6.18.16.16.3.m1.1.1.1.cmml" xref="S5.T6.18.16.16.3.m1.1.1.1"><divide id="S5.T6.18.16.16.3.m1.1.1.1.2.cmml" xref="S5.T6.18.16.16.3.m1.1.1.1.2"></divide><apply id="S5.T6.18.16.16.3.m1.1.1.1.1.1.1.cmml" xref="S5.T6.18.16.16.3.m1.1.1.1.1.1"><minus id="S5.T6.18.16.16.3.m1.1.1.1.1.1.1.1.cmml" xref="S5.T6.18.16.16.3.m1.1.1.1.1.1.1.1"></minus><ci id="S5.T6.18.16.16.3.m1.1.1.1.1.1.1.2.cmml" xref="S5.T6.18.16.16.3.m1.1.1.1.1.1.1.2">𝑛</ci><cn type="integer" id="S5.T6.18.16.16.3.m1.1.1.1.1.1.1.3.cmml" xref="S5.T6.18.16.16.3.m1.1.1.1.1.1.1.3">3</cn></apply><cn type="integer" id="S5.T6.18.16.16.3.m1.1.1.1.3.cmml" xref="S5.T6.18.16.16.3.m1.1.1.1.3">4</cn></apply><ci id="S5.T6.18.16.16.3.m1.1.1.3.cmml" xref="S5.T6.18.16.16.3.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.18.16.16.3.m1.1c">(n-3)/4n</annotation></semantics></math></td>
<td id="S5.T6.19.17.17.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.19.17.17.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T6.19.17.17.4.m1.1a"><mo id="S5.T6.19.17.17.4.m1.1.1" xref="S5.T6.19.17.17.4.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T6.19.17.17.4.m1.1b"><times id="S5.T6.19.17.17.4.m1.1.1.cmml" xref="S5.T6.19.17.17.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.19.17.17.4.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T6.20.18.18.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.20.18.18.5.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T6.20.18.18.5.m1.1a"><mi mathvariant="normal" id="S5.T6.20.18.18.5.m1.1.1" xref="S5.T6.20.18.18.5.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T6.20.18.18.5.m1.1b"><ci id="S5.T6.20.18.18.5.m1.1.1.cmml" xref="S5.T6.20.18.18.5.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.20.18.18.5.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S5.T6.24.22.22" class="ltx_tr">
<td id="S5.T6.24.22.22.5" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">RFA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>
</td>
<td id="S5.T6.24.22.22.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Geometric median</td>
<td id="S5.T6.21.19.19.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.21.19.19.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T6.21.19.19.1.m1.1a"><mi mathvariant="normal" id="S5.T6.21.19.19.1.m1.1.1" xref="S5.T6.21.19.19.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T6.21.19.19.1.m1.1b"><ci id="S5.T6.21.19.19.1.m1.1.1.cmml" xref="S5.T6.21.19.19.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.21.19.19.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T6.22.20.20.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.22.20.20.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T6.22.20.20.2.m1.1a"><mo id="S5.T6.22.20.20.2.m1.1.1" xref="S5.T6.22.20.20.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T6.22.20.20.2.m1.1b"><times id="S5.T6.22.20.20.2.m1.1.1.cmml" xref="S5.T6.22.20.20.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.22.20.20.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T6.24.22.22.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NA</td>
<td id="S5.T6.23.21.21.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.23.21.21.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T6.23.21.21.3.m1.1a"><mo id="S5.T6.23.21.21.3.m1.1.1" xref="S5.T6.23.21.21.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T6.23.21.21.3.m1.1b"><times id="S5.T6.23.21.21.3.m1.1.1.cmml" xref="S5.T6.23.21.21.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.23.21.21.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T6.24.22.22.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.24.22.22.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T6.24.22.22.4.m1.1a"><mi mathvariant="normal" id="S5.T6.24.22.22.4.m1.1.1" xref="S5.T6.24.22.22.4.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T6.24.22.22.4.m1.1b"><ci id="S5.T6.24.22.22.4.m1.1.1.cmml" xref="S5.T6.24.22.22.4.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.24.22.22.4.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S5.T6.28.26.26" class="ltx_tr">
<td id="S5.T6.28.26.26.5" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">FoolsGold <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>
</td>
<td id="S5.T6.28.26.26.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Contribution similarity</td>
<td id="S5.T6.25.23.23.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.25.23.23.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T6.25.23.23.1.m1.1a"><mi mathvariant="normal" id="S5.T6.25.23.23.1.m1.1.1" xref="S5.T6.25.23.23.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T6.25.23.23.1.m1.1b"><ci id="S5.T6.25.23.23.1.m1.1.1.cmml" xref="S5.T6.25.23.23.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.25.23.23.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T6.26.24.24.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.26.24.24.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T6.26.24.24.2.m1.1a"><mi mathvariant="normal" id="S5.T6.26.24.24.2.m1.1.1" xref="S5.T6.26.24.24.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T6.26.24.24.2.m1.1b"><ci id="S5.T6.26.24.24.2.m1.1.1.cmml" xref="S5.T6.26.24.24.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.26.24.24.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T6.28.26.26.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NA</td>
<td id="S5.T6.27.25.25.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.27.25.25.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T6.27.25.25.3.m1.1a"><mi mathvariant="normal" id="S5.T6.27.25.25.3.m1.1.1" xref="S5.T6.27.25.25.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T6.27.25.25.3.m1.1b"><ci id="S5.T6.27.25.25.3.m1.1.1.cmml" xref="S5.T6.27.25.25.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.27.25.25.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T6.28.26.26.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.28.26.26.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T6.28.26.26.4.m1.1a"><mo id="S5.T6.28.26.26.4.m1.1.1" xref="S5.T6.28.26.26.4.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T6.28.26.26.4.m1.1b"><times id="S5.T6.28.26.26.4.m1.1.1.cmml" xref="S5.T6.28.26.26.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.28.26.26.4.m1.1c">\times</annotation></semantics></math></td>
</tr>
<tr id="S5.T6.32.30.30" class="ltx_tr">
<td id="S5.T6.32.30.30.5" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Sun <span id="S5.T6.32.30.30.5.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>
</td>
<td id="S5.T6.32.30.30.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Norm-bounding and DP</td>
<td id="S5.T6.29.27.27.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.29.27.27.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T6.29.27.27.1.m1.1a"><mi mathvariant="normal" id="S5.T6.29.27.27.1.m1.1.1" xref="S5.T6.29.27.27.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T6.29.27.27.1.m1.1b"><ci id="S5.T6.29.27.27.1.m1.1.1.cmml" xref="S5.T6.29.27.27.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.29.27.27.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T6.30.28.28.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.30.28.28.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T6.30.28.28.2.m1.1a"><mi mathvariant="normal" id="S5.T6.30.28.28.2.m1.1.1" xref="S5.T6.30.28.28.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T6.30.28.28.2.m1.1b"><ci id="S5.T6.30.28.28.2.m1.1.1.cmml" xref="S5.T6.30.28.28.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.30.28.28.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T6.32.30.30.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NA</td>
<td id="S5.T6.31.29.29.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.31.29.29.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T6.31.29.29.3.m1.1a"><mi mathvariant="normal" id="S5.T6.31.29.29.3.m1.1.1" xref="S5.T6.31.29.29.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T6.31.29.29.3.m1.1b"><ci id="S5.T6.31.29.29.3.m1.1.1.cmml" xref="S5.T6.31.29.29.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.31.29.29.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T6.32.30.30.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<math id="S5.T6.32.30.30.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T6.32.30.30.4.m1.1a"><mi mathvariant="normal" id="S5.T6.32.30.30.4.m1.1.1" xref="S5.T6.32.30.30.4.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T6.32.30.30.4.m1.1b"><ci id="S5.T6.32.30.30.4.m1.1.1.cmml" xref="S5.T6.32.30.30.4.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.32.30.30.4.m1.1c">\checkmark</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib141" title="" class="ltx_ref">141</a>]</cite>
</td>
</tr>
<tr id="S5.T6.36.34.34" class="ltx_tr">
<td id="S5.T6.36.34.34.5" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Wu <span id="S5.T6.36.34.34.5.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib142" title="" class="ltx_ref">142</a>]</cite>
</td>
<td id="S5.T6.36.34.34.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Pruning</td>
<td id="S5.T6.33.31.31.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.33.31.31.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T6.33.31.31.1.m1.1a"><mi mathvariant="normal" id="S5.T6.33.31.31.1.m1.1.1" xref="S5.T6.33.31.31.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T6.33.31.31.1.m1.1b"><ci id="S5.T6.33.31.31.1.m1.1.1.cmml" xref="S5.T6.33.31.31.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.33.31.31.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T6.34.32.32.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.34.32.32.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T6.34.32.32.2.m1.1a"><mi mathvariant="normal" id="S5.T6.34.32.32.2.m1.1.1" xref="S5.T6.34.32.32.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T6.34.32.32.2.m1.1b"><ci id="S5.T6.34.32.32.2.m1.1.1.cmml" xref="S5.T6.34.32.32.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.34.32.32.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T6.36.34.34.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NA</td>
<td id="S5.T6.35.33.33.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.35.33.33.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T6.35.33.33.3.m1.1a"><mi mathvariant="normal" id="S5.T6.35.33.33.3.m1.1.1" xref="S5.T6.35.33.33.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T6.35.33.33.3.m1.1b"><ci id="S5.T6.35.33.33.3.m1.1.1.cmml" xref="S5.T6.35.33.33.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.35.33.33.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T6.36.34.34.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T6.36.34.34.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T6.36.34.34.4.m1.1a"><mo id="S5.T6.36.34.34.4.m1.1.1" xref="S5.T6.36.34.34.4.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T6.36.34.34.4.m1.1b"><times id="S5.T6.36.34.34.4.m1.1.1.cmml" xref="S5.T6.36.34.34.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.36.34.34.4.m1.1c">\times</annotation></semantics></math></td>
</tr>
<tr id="S5.T6.40.38.38" class="ltx_tr">
<td id="S5.T6.40.38.38.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">CRFL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib143" title="" class="ltx_ref">143</a>]</cite>
</td>
<td id="S5.T6.40.38.38.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Clipping and smoothing</td>
<td id="S5.T6.37.35.35.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="S5.T6.37.35.35.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T6.37.35.35.1.m1.1a"><mi mathvariant="normal" id="S5.T6.37.35.35.1.m1.1.1" xref="S5.T6.37.35.35.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T6.37.35.35.1.m1.1b"><ci id="S5.T6.37.35.35.1.m1.1.1.cmml" xref="S5.T6.37.35.35.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.37.35.35.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T6.38.36.36.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="S5.T6.38.36.36.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T6.38.36.36.2.m1.1a"><mi mathvariant="normal" id="S5.T6.38.36.36.2.m1.1.1" xref="S5.T6.38.36.36.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T6.38.36.36.2.m1.1b"><ci id="S5.T6.38.36.36.2.m1.1.1.cmml" xref="S5.T6.38.36.36.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.38.36.36.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T6.40.38.38.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">NA</td>
<td id="S5.T6.39.37.37.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="S5.T6.39.37.37.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T6.39.37.37.3.m1.1a"><mi mathvariant="normal" id="S5.T6.39.37.37.3.m1.1.1" xref="S5.T6.39.37.37.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T6.39.37.37.3.m1.1b"><ci id="S5.T6.39.37.37.3.m1.1.1.cmml" xref="S5.T6.39.37.37.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.39.37.37.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T6.40.38.38.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="S5.T6.40.38.38.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T6.40.38.38.4.m1.1a"><mo id="S5.T6.40.38.38.4.m1.1.1" xref="S5.T6.40.38.38.4.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T6.40.38.38.4.m1.1b"><times id="S5.T6.40.38.38.4.m1.1.1.cmml" xref="S5.T6.40.38.38.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.40.38.38.4.m1.1c">\times</annotation></semantics></math></td>
</tr>
</table>
</span></div>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Defenses against Poisoning Attacks</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">Robustness to poisoning attacks is a desirable property in FL. To address poisoning attacks, many robust aggregation schemes are proposed in the literature. Known defenses to poisoning attacks in a centralized setting, such as robust losses <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib144" title="" class="ltx_ref">144</a>]</cite> and anomaly detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>]</cite>, assume control of the participants or explicit observation of the training data. Neither of these assumptions are applicable to FL in which the server only observes model parameters/updates sent as part of the iterative ML algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. We summarize the robustness-focused FL defenses against untargeted and targeted attacks as follows.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS1.4.1.1" class="ltx_text">VI-A</span> </span><span id="S6.SS1.5.2" class="ltx_text ltx_font_italic">Defenses against Untargeted Attacks</span>
</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">For Byzantine-resilient aggregation, an algorithm is Byzantine fault tolerant <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> if its convergence is robust even when a large portion of participants are adversarial. Below, we list several representative attempts that try to defend against the untargeted Byzantine attacks.</p>
</div>
<div id="S6.SS1.p2" class="ltx_para">
<p id="S6.SS1.p2.1" class="ltx_p">Shen <span id="S6.SS1.p2.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib139" title="" class="ltx_ref">139</a>]</cite> introduced a statistical mechanism called AUROR to detect the malicious users while generating an accurate model. AUROR is based on the observation that indicative features (most important model features) from the majority of honest users will exhibit a similar distribution while those from malicious users will exhibit an anomalous distribution. It then uses k-means to cluster participants’ updates across training rounds and discards the outliers, <span id="S6.SS1.p2.1.2" class="ltx_text ltx_font_italic">i.e.</span>, contributions from small clusters that exceed a threshold distance are removed. The accuracy of a model trained using AUROR drops by only 3% even when 30% of all the users are adversarial.</p>
</div>
<div id="S6.SS1.p3" class="ltx_para">
<p id="S6.SS1.p3.13" class="ltx_p">Blanchard <span id="S6.SS1.p3.13.1" class="ltx_text ltx_font_italic">et al.</span> proposed Krum <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, in which, the top <math id="S6.SS1.p3.1.m1.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S6.SS1.p3.1.m1.1a"><mi id="S6.SS1.p3.1.m1.1.1" xref="S6.SS1.p3.1.m1.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.1.m1.1b"><ci id="S6.SS1.p3.1.m1.1.1.cmml" xref="S6.SS1.p3.1.m1.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.1.m1.1c">f</annotation></semantics></math> contributions to the model that are furthest from the mean participant contribution are removed from the aggregation. Krum uses the Euclidean distance to determine which gradient contributions should be removed, and can theoretically withstand poisoning attacks of up to 33% adversaries in the participant pool, <span id="S6.SS1.p3.13.2" class="ltx_text ltx_font_italic">i.e.</span>, given <math id="S6.SS1.p3.2.m2.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S6.SS1.p3.2.m2.1a"><mi id="S6.SS1.p3.2.m2.1.1" xref="S6.SS1.p3.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.2.m2.1b"><ci id="S6.SS1.p3.2.m2.1.1.cmml" xref="S6.SS1.p3.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.2.m2.1c">n</annotation></semantics></math> agents of which <math id="S6.SS1.p3.3.m3.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S6.SS1.p3.3.m3.1a"><mi id="S6.SS1.p3.3.m3.1.1" xref="S6.SS1.p3.3.m3.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.3.m3.1b"><ci id="S6.SS1.p3.3.m3.1.1.cmml" xref="S6.SS1.p3.3.m3.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.3.m3.1c">f</annotation></semantics></math> are Byzantine, Krum requires that <math id="S6.SS1.p3.4.m4.1" class="ltx_Math" alttext="n\geq 2f+3" display="inline"><semantics id="S6.SS1.p3.4.m4.1a"><mrow id="S6.SS1.p3.4.m4.1.1" xref="S6.SS1.p3.4.m4.1.1.cmml"><mi id="S6.SS1.p3.4.m4.1.1.2" xref="S6.SS1.p3.4.m4.1.1.2.cmml">n</mi><mo id="S6.SS1.p3.4.m4.1.1.1" xref="S6.SS1.p3.4.m4.1.1.1.cmml">≥</mo><mrow id="S6.SS1.p3.4.m4.1.1.3" xref="S6.SS1.p3.4.m4.1.1.3.cmml"><mrow id="S6.SS1.p3.4.m4.1.1.3.2" xref="S6.SS1.p3.4.m4.1.1.3.2.cmml"><mn id="S6.SS1.p3.4.m4.1.1.3.2.2" xref="S6.SS1.p3.4.m4.1.1.3.2.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S6.SS1.p3.4.m4.1.1.3.2.1" xref="S6.SS1.p3.4.m4.1.1.3.2.1.cmml">​</mo><mi id="S6.SS1.p3.4.m4.1.1.3.2.3" xref="S6.SS1.p3.4.m4.1.1.3.2.3.cmml">f</mi></mrow><mo id="S6.SS1.p3.4.m4.1.1.3.1" xref="S6.SS1.p3.4.m4.1.1.3.1.cmml">+</mo><mn id="S6.SS1.p3.4.m4.1.1.3.3" xref="S6.SS1.p3.4.m4.1.1.3.3.cmml">3</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.4.m4.1b"><apply id="S6.SS1.p3.4.m4.1.1.cmml" xref="S6.SS1.p3.4.m4.1.1"><geq id="S6.SS1.p3.4.m4.1.1.1.cmml" xref="S6.SS1.p3.4.m4.1.1.1"></geq><ci id="S6.SS1.p3.4.m4.1.1.2.cmml" xref="S6.SS1.p3.4.m4.1.1.2">𝑛</ci><apply id="S6.SS1.p3.4.m4.1.1.3.cmml" xref="S6.SS1.p3.4.m4.1.1.3"><plus id="S6.SS1.p3.4.m4.1.1.3.1.cmml" xref="S6.SS1.p3.4.m4.1.1.3.1"></plus><apply id="S6.SS1.p3.4.m4.1.1.3.2.cmml" xref="S6.SS1.p3.4.m4.1.1.3.2"><times id="S6.SS1.p3.4.m4.1.1.3.2.1.cmml" xref="S6.SS1.p3.4.m4.1.1.3.2.1"></times><cn type="integer" id="S6.SS1.p3.4.m4.1.1.3.2.2.cmml" xref="S6.SS1.p3.4.m4.1.1.3.2.2">2</cn><ci id="S6.SS1.p3.4.m4.1.1.3.2.3.cmml" xref="S6.SS1.p3.4.m4.1.1.3.2.3">𝑓</ci></apply><cn type="integer" id="S6.SS1.p3.4.m4.1.1.3.3.cmml" xref="S6.SS1.p3.4.m4.1.1.3.3">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.4.m4.1c">n\geq 2f+3</annotation></semantics></math>. At any time step <math id="S6.SS1.p3.5.m5.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S6.SS1.p3.5.m5.1a"><mi id="S6.SS1.p3.5.m5.1.1" xref="S6.SS1.p3.5.m5.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.5.m5.1b"><ci id="S6.SS1.p3.5.m5.1.1.cmml" xref="S6.SS1.p3.5.m5.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.5.m5.1c">t</annotation></semantics></math>, updates <math id="S6.SS1.p3.6.m6.3" class="ltx_Math" alttext="\{\delta_{1}^{t},\cdots,\delta_{n}^{t}\}" display="inline"><semantics id="S6.SS1.p3.6.m6.3a"><mrow id="S6.SS1.p3.6.m6.3.3.2" xref="S6.SS1.p3.6.m6.3.3.3.cmml"><mo stretchy="false" id="S6.SS1.p3.6.m6.3.3.2.3" xref="S6.SS1.p3.6.m6.3.3.3.cmml">{</mo><msubsup id="S6.SS1.p3.6.m6.2.2.1.1" xref="S6.SS1.p3.6.m6.2.2.1.1.cmml"><mi id="S6.SS1.p3.6.m6.2.2.1.1.2.2" xref="S6.SS1.p3.6.m6.2.2.1.1.2.2.cmml">δ</mi><mn id="S6.SS1.p3.6.m6.2.2.1.1.2.3" xref="S6.SS1.p3.6.m6.2.2.1.1.2.3.cmml">1</mn><mi id="S6.SS1.p3.6.m6.2.2.1.1.3" xref="S6.SS1.p3.6.m6.2.2.1.1.3.cmml">t</mi></msubsup><mo id="S6.SS1.p3.6.m6.3.3.2.4" xref="S6.SS1.p3.6.m6.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S6.SS1.p3.6.m6.1.1" xref="S6.SS1.p3.6.m6.1.1.cmml">⋯</mi><mo id="S6.SS1.p3.6.m6.3.3.2.5" xref="S6.SS1.p3.6.m6.3.3.3.cmml">,</mo><msubsup id="S6.SS1.p3.6.m6.3.3.2.2" xref="S6.SS1.p3.6.m6.3.3.2.2.cmml"><mi id="S6.SS1.p3.6.m6.3.3.2.2.2.2" xref="S6.SS1.p3.6.m6.3.3.2.2.2.2.cmml">δ</mi><mi id="S6.SS1.p3.6.m6.3.3.2.2.2.3" xref="S6.SS1.p3.6.m6.3.3.2.2.2.3.cmml">n</mi><mi id="S6.SS1.p3.6.m6.3.3.2.2.3" xref="S6.SS1.p3.6.m6.3.3.2.2.3.cmml">t</mi></msubsup><mo stretchy="false" id="S6.SS1.p3.6.m6.3.3.2.6" xref="S6.SS1.p3.6.m6.3.3.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.6.m6.3b"><set id="S6.SS1.p3.6.m6.3.3.3.cmml" xref="S6.SS1.p3.6.m6.3.3.2"><apply id="S6.SS1.p3.6.m6.2.2.1.1.cmml" xref="S6.SS1.p3.6.m6.2.2.1.1"><csymbol cd="ambiguous" id="S6.SS1.p3.6.m6.2.2.1.1.1.cmml" xref="S6.SS1.p3.6.m6.2.2.1.1">superscript</csymbol><apply id="S6.SS1.p3.6.m6.2.2.1.1.2.cmml" xref="S6.SS1.p3.6.m6.2.2.1.1"><csymbol cd="ambiguous" id="S6.SS1.p3.6.m6.2.2.1.1.2.1.cmml" xref="S6.SS1.p3.6.m6.2.2.1.1">subscript</csymbol><ci id="S6.SS1.p3.6.m6.2.2.1.1.2.2.cmml" xref="S6.SS1.p3.6.m6.2.2.1.1.2.2">𝛿</ci><cn type="integer" id="S6.SS1.p3.6.m6.2.2.1.1.2.3.cmml" xref="S6.SS1.p3.6.m6.2.2.1.1.2.3">1</cn></apply><ci id="S6.SS1.p3.6.m6.2.2.1.1.3.cmml" xref="S6.SS1.p3.6.m6.2.2.1.1.3">𝑡</ci></apply><ci id="S6.SS1.p3.6.m6.1.1.cmml" xref="S6.SS1.p3.6.m6.1.1">⋯</ci><apply id="S6.SS1.p3.6.m6.3.3.2.2.cmml" xref="S6.SS1.p3.6.m6.3.3.2.2"><csymbol cd="ambiguous" id="S6.SS1.p3.6.m6.3.3.2.2.1.cmml" xref="S6.SS1.p3.6.m6.3.3.2.2">superscript</csymbol><apply id="S6.SS1.p3.6.m6.3.3.2.2.2.cmml" xref="S6.SS1.p3.6.m6.3.3.2.2"><csymbol cd="ambiguous" id="S6.SS1.p3.6.m6.3.3.2.2.2.1.cmml" xref="S6.SS1.p3.6.m6.3.3.2.2">subscript</csymbol><ci id="S6.SS1.p3.6.m6.3.3.2.2.2.2.cmml" xref="S6.SS1.p3.6.m6.3.3.2.2.2.2">𝛿</ci><ci id="S6.SS1.p3.6.m6.3.3.2.2.2.3.cmml" xref="S6.SS1.p3.6.m6.3.3.2.2.2.3">𝑛</ci></apply><ci id="S6.SS1.p3.6.m6.3.3.2.2.3.cmml" xref="S6.SS1.p3.6.m6.3.3.2.2.3">𝑡</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.6.m6.3c">\{\delta_{1}^{t},\cdots,\delta_{n}^{t}\}</annotation></semantics></math> are received at the server. For each <math id="S6.SS1.p3.7.m7.1" class="ltx_Math" alttext="\delta_{i}^{t}" display="inline"><semantics id="S6.SS1.p3.7.m7.1a"><msubsup id="S6.SS1.p3.7.m7.1.1" xref="S6.SS1.p3.7.m7.1.1.cmml"><mi id="S6.SS1.p3.7.m7.1.1.2.2" xref="S6.SS1.p3.7.m7.1.1.2.2.cmml">δ</mi><mi id="S6.SS1.p3.7.m7.1.1.2.3" xref="S6.SS1.p3.7.m7.1.1.2.3.cmml">i</mi><mi id="S6.SS1.p3.7.m7.1.1.3" xref="S6.SS1.p3.7.m7.1.1.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.7.m7.1b"><apply id="S6.SS1.p3.7.m7.1.1.cmml" xref="S6.SS1.p3.7.m7.1.1"><csymbol cd="ambiguous" id="S6.SS1.p3.7.m7.1.1.1.cmml" xref="S6.SS1.p3.7.m7.1.1">superscript</csymbol><apply id="S6.SS1.p3.7.m7.1.1.2.cmml" xref="S6.SS1.p3.7.m7.1.1"><csymbol cd="ambiguous" id="S6.SS1.p3.7.m7.1.1.2.1.cmml" xref="S6.SS1.p3.7.m7.1.1">subscript</csymbol><ci id="S6.SS1.p3.7.m7.1.1.2.2.cmml" xref="S6.SS1.p3.7.m7.1.1.2.2">𝛿</ci><ci id="S6.SS1.p3.7.m7.1.1.2.3.cmml" xref="S6.SS1.p3.7.m7.1.1.2.3">𝑖</ci></apply><ci id="S6.SS1.p3.7.m7.1.1.3.cmml" xref="S6.SS1.p3.7.m7.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.7.m7.1c">\delta_{i}^{t}</annotation></semantics></math>, the <math id="S6.SS1.p3.8.m8.1" class="ltx_Math" alttext="n-f-2" display="inline"><semantics id="S6.SS1.p3.8.m8.1a"><mrow id="S6.SS1.p3.8.m8.1.1" xref="S6.SS1.p3.8.m8.1.1.cmml"><mi id="S6.SS1.p3.8.m8.1.1.2" xref="S6.SS1.p3.8.m8.1.1.2.cmml">n</mi><mo id="S6.SS1.p3.8.m8.1.1.1" xref="S6.SS1.p3.8.m8.1.1.1.cmml">−</mo><mi id="S6.SS1.p3.8.m8.1.1.3" xref="S6.SS1.p3.8.m8.1.1.3.cmml">f</mi><mo id="S6.SS1.p3.8.m8.1.1.1a" xref="S6.SS1.p3.8.m8.1.1.1.cmml">−</mo><mn id="S6.SS1.p3.8.m8.1.1.4" xref="S6.SS1.p3.8.m8.1.1.4.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.8.m8.1b"><apply id="S6.SS1.p3.8.m8.1.1.cmml" xref="S6.SS1.p3.8.m8.1.1"><minus id="S6.SS1.p3.8.m8.1.1.1.cmml" xref="S6.SS1.p3.8.m8.1.1.1"></minus><ci id="S6.SS1.p3.8.m8.1.1.2.cmml" xref="S6.SS1.p3.8.m8.1.1.2">𝑛</ci><ci id="S6.SS1.p3.8.m8.1.1.3.cmml" xref="S6.SS1.p3.8.m8.1.1.3">𝑓</ci><cn type="integer" id="S6.SS1.p3.8.m8.1.1.4.cmml" xref="S6.SS1.p3.8.m8.1.1.4">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.8.m8.1c">n-f-2</annotation></semantics></math> closest (in terms of <math id="S6.SS1.p3.9.m9.1" class="ltx_Math" alttext="L_{2}" display="inline"><semantics id="S6.SS1.p3.9.m9.1a"><msub id="S6.SS1.p3.9.m9.1.1" xref="S6.SS1.p3.9.m9.1.1.cmml"><mi id="S6.SS1.p3.9.m9.1.1.2" xref="S6.SS1.p3.9.m9.1.1.2.cmml">L</mi><mn id="S6.SS1.p3.9.m9.1.1.3" xref="S6.SS1.p3.9.m9.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.9.m9.1b"><apply id="S6.SS1.p3.9.m9.1.1.cmml" xref="S6.SS1.p3.9.m9.1.1"><csymbol cd="ambiguous" id="S6.SS1.p3.9.m9.1.1.1.cmml" xref="S6.SS1.p3.9.m9.1.1">subscript</csymbol><ci id="S6.SS1.p3.9.m9.1.1.2.cmml" xref="S6.SS1.p3.9.m9.1.1.2">𝐿</ci><cn type="integer" id="S6.SS1.p3.9.m9.1.1.3.cmml" xref="S6.SS1.p3.9.m9.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.9.m9.1c">L_{2}</annotation></semantics></math> norm) other updates are chosen to form a set <math id="S6.SS1.p3.10.m10.1" class="ltx_Math" alttext="C_{i}" display="inline"><semantics id="S6.SS1.p3.10.m10.1a"><msub id="S6.SS1.p3.10.m10.1.1" xref="S6.SS1.p3.10.m10.1.1.cmml"><mi id="S6.SS1.p3.10.m10.1.1.2" xref="S6.SS1.p3.10.m10.1.1.2.cmml">C</mi><mi id="S6.SS1.p3.10.m10.1.1.3" xref="S6.SS1.p3.10.m10.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.10.m10.1b"><apply id="S6.SS1.p3.10.m10.1.1.cmml" xref="S6.SS1.p3.10.m10.1.1"><csymbol cd="ambiguous" id="S6.SS1.p3.10.m10.1.1.1.cmml" xref="S6.SS1.p3.10.m10.1.1">subscript</csymbol><ci id="S6.SS1.p3.10.m10.1.1.2.cmml" xref="S6.SS1.p3.10.m10.1.1.2">𝐶</ci><ci id="S6.SS1.p3.10.m10.1.1.3.cmml" xref="S6.SS1.p3.10.m10.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.10.m10.1c">C_{i}</annotation></semantics></math>, and their distances are added up to give a score <math id="S6.SS1.p3.11.m11.2" class="ltx_Math" alttext="S(\delta_{i}^{t})={\textstyle\sum}_{\delta\in C_{i}}\|\delta_{i}^{t}-\delta\|" display="inline"><semantics id="S6.SS1.p3.11.m11.2a"><mrow id="S6.SS1.p3.11.m11.2.2" xref="S6.SS1.p3.11.m11.2.2.cmml"><mrow id="S6.SS1.p3.11.m11.1.1.1" xref="S6.SS1.p3.11.m11.1.1.1.cmml"><mi id="S6.SS1.p3.11.m11.1.1.1.3" xref="S6.SS1.p3.11.m11.1.1.1.3.cmml">S</mi><mo lspace="0em" rspace="0em" id="S6.SS1.p3.11.m11.1.1.1.2" xref="S6.SS1.p3.11.m11.1.1.1.2.cmml">​</mo><mrow id="S6.SS1.p3.11.m11.1.1.1.1.1" xref="S6.SS1.p3.11.m11.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S6.SS1.p3.11.m11.1.1.1.1.1.2" xref="S6.SS1.p3.11.m11.1.1.1.1.1.1.cmml">(</mo><msubsup id="S6.SS1.p3.11.m11.1.1.1.1.1.1" xref="S6.SS1.p3.11.m11.1.1.1.1.1.1.cmml"><mi id="S6.SS1.p3.11.m11.1.1.1.1.1.1.2.2" xref="S6.SS1.p3.11.m11.1.1.1.1.1.1.2.2.cmml">δ</mi><mi id="S6.SS1.p3.11.m11.1.1.1.1.1.1.2.3" xref="S6.SS1.p3.11.m11.1.1.1.1.1.1.2.3.cmml">i</mi><mi id="S6.SS1.p3.11.m11.1.1.1.1.1.1.3" xref="S6.SS1.p3.11.m11.1.1.1.1.1.1.3.cmml">t</mi></msubsup><mo stretchy="false" id="S6.SS1.p3.11.m11.1.1.1.1.1.3" xref="S6.SS1.p3.11.m11.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo rspace="0.111em" id="S6.SS1.p3.11.m11.2.2.3" xref="S6.SS1.p3.11.m11.2.2.3.cmml">=</mo><mrow id="S6.SS1.p3.11.m11.2.2.2" xref="S6.SS1.p3.11.m11.2.2.2.cmml"><msub id="S6.SS1.p3.11.m11.2.2.2.2" xref="S6.SS1.p3.11.m11.2.2.2.2.cmml"><mo rspace="0em" id="S6.SS1.p3.11.m11.2.2.2.2.2" xref="S6.SS1.p3.11.m11.2.2.2.2.2.cmml">∑</mo><mrow id="S6.SS1.p3.11.m11.2.2.2.2.3" xref="S6.SS1.p3.11.m11.2.2.2.2.3.cmml"><mi id="S6.SS1.p3.11.m11.2.2.2.2.3.2" xref="S6.SS1.p3.11.m11.2.2.2.2.3.2.cmml">δ</mi><mo id="S6.SS1.p3.11.m11.2.2.2.2.3.1" xref="S6.SS1.p3.11.m11.2.2.2.2.3.1.cmml">∈</mo><msub id="S6.SS1.p3.11.m11.2.2.2.2.3.3" xref="S6.SS1.p3.11.m11.2.2.2.2.3.3.cmml"><mi id="S6.SS1.p3.11.m11.2.2.2.2.3.3.2" xref="S6.SS1.p3.11.m11.2.2.2.2.3.3.2.cmml">C</mi><mi id="S6.SS1.p3.11.m11.2.2.2.2.3.3.3" xref="S6.SS1.p3.11.m11.2.2.2.2.3.3.3.cmml">i</mi></msub></mrow></msub><mrow id="S6.SS1.p3.11.m11.2.2.2.1.1" xref="S6.SS1.p3.11.m11.2.2.2.1.2.cmml"><mo stretchy="false" id="S6.SS1.p3.11.m11.2.2.2.1.1.2" xref="S6.SS1.p3.11.m11.2.2.2.1.2.1.cmml">‖</mo><mrow id="S6.SS1.p3.11.m11.2.2.2.1.1.1" xref="S6.SS1.p3.11.m11.2.2.2.1.1.1.cmml"><msubsup id="S6.SS1.p3.11.m11.2.2.2.1.1.1.2" xref="S6.SS1.p3.11.m11.2.2.2.1.1.1.2.cmml"><mi id="S6.SS1.p3.11.m11.2.2.2.1.1.1.2.2.2" xref="S6.SS1.p3.11.m11.2.2.2.1.1.1.2.2.2.cmml">δ</mi><mi id="S6.SS1.p3.11.m11.2.2.2.1.1.1.2.2.3" xref="S6.SS1.p3.11.m11.2.2.2.1.1.1.2.2.3.cmml">i</mi><mi id="S6.SS1.p3.11.m11.2.2.2.1.1.1.2.3" xref="S6.SS1.p3.11.m11.2.2.2.1.1.1.2.3.cmml">t</mi></msubsup><mo id="S6.SS1.p3.11.m11.2.2.2.1.1.1.1" xref="S6.SS1.p3.11.m11.2.2.2.1.1.1.1.cmml">−</mo><mi id="S6.SS1.p3.11.m11.2.2.2.1.1.1.3" xref="S6.SS1.p3.11.m11.2.2.2.1.1.1.3.cmml">δ</mi></mrow><mo stretchy="false" id="S6.SS1.p3.11.m11.2.2.2.1.1.3" xref="S6.SS1.p3.11.m11.2.2.2.1.2.1.cmml">‖</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.11.m11.2b"><apply id="S6.SS1.p3.11.m11.2.2.cmml" xref="S6.SS1.p3.11.m11.2.2"><eq id="S6.SS1.p3.11.m11.2.2.3.cmml" xref="S6.SS1.p3.11.m11.2.2.3"></eq><apply id="S6.SS1.p3.11.m11.1.1.1.cmml" xref="S6.SS1.p3.11.m11.1.1.1"><times id="S6.SS1.p3.11.m11.1.1.1.2.cmml" xref="S6.SS1.p3.11.m11.1.1.1.2"></times><ci id="S6.SS1.p3.11.m11.1.1.1.3.cmml" xref="S6.SS1.p3.11.m11.1.1.1.3">𝑆</ci><apply id="S6.SS1.p3.11.m11.1.1.1.1.1.1.cmml" xref="S6.SS1.p3.11.m11.1.1.1.1.1"><csymbol cd="ambiguous" id="S6.SS1.p3.11.m11.1.1.1.1.1.1.1.cmml" xref="S6.SS1.p3.11.m11.1.1.1.1.1">superscript</csymbol><apply id="S6.SS1.p3.11.m11.1.1.1.1.1.1.2.cmml" xref="S6.SS1.p3.11.m11.1.1.1.1.1"><csymbol cd="ambiguous" id="S6.SS1.p3.11.m11.1.1.1.1.1.1.2.1.cmml" xref="S6.SS1.p3.11.m11.1.1.1.1.1">subscript</csymbol><ci id="S6.SS1.p3.11.m11.1.1.1.1.1.1.2.2.cmml" xref="S6.SS1.p3.11.m11.1.1.1.1.1.1.2.2">𝛿</ci><ci id="S6.SS1.p3.11.m11.1.1.1.1.1.1.2.3.cmml" xref="S6.SS1.p3.11.m11.1.1.1.1.1.1.2.3">𝑖</ci></apply><ci id="S6.SS1.p3.11.m11.1.1.1.1.1.1.3.cmml" xref="S6.SS1.p3.11.m11.1.1.1.1.1.1.3">𝑡</ci></apply></apply><apply id="S6.SS1.p3.11.m11.2.2.2.cmml" xref="S6.SS1.p3.11.m11.2.2.2"><apply id="S6.SS1.p3.11.m11.2.2.2.2.cmml" xref="S6.SS1.p3.11.m11.2.2.2.2"><csymbol cd="ambiguous" id="S6.SS1.p3.11.m11.2.2.2.2.1.cmml" xref="S6.SS1.p3.11.m11.2.2.2.2">subscript</csymbol><sum id="S6.SS1.p3.11.m11.2.2.2.2.2.cmml" xref="S6.SS1.p3.11.m11.2.2.2.2.2"></sum><apply id="S6.SS1.p3.11.m11.2.2.2.2.3.cmml" xref="S6.SS1.p3.11.m11.2.2.2.2.3"><in id="S6.SS1.p3.11.m11.2.2.2.2.3.1.cmml" xref="S6.SS1.p3.11.m11.2.2.2.2.3.1"></in><ci id="S6.SS1.p3.11.m11.2.2.2.2.3.2.cmml" xref="S6.SS1.p3.11.m11.2.2.2.2.3.2">𝛿</ci><apply id="S6.SS1.p3.11.m11.2.2.2.2.3.3.cmml" xref="S6.SS1.p3.11.m11.2.2.2.2.3.3"><csymbol cd="ambiguous" id="S6.SS1.p3.11.m11.2.2.2.2.3.3.1.cmml" xref="S6.SS1.p3.11.m11.2.2.2.2.3.3">subscript</csymbol><ci id="S6.SS1.p3.11.m11.2.2.2.2.3.3.2.cmml" xref="S6.SS1.p3.11.m11.2.2.2.2.3.3.2">𝐶</ci><ci id="S6.SS1.p3.11.m11.2.2.2.2.3.3.3.cmml" xref="S6.SS1.p3.11.m11.2.2.2.2.3.3.3">𝑖</ci></apply></apply></apply><apply id="S6.SS1.p3.11.m11.2.2.2.1.2.cmml" xref="S6.SS1.p3.11.m11.2.2.2.1.1"><csymbol cd="latexml" id="S6.SS1.p3.11.m11.2.2.2.1.2.1.cmml" xref="S6.SS1.p3.11.m11.2.2.2.1.1.2">norm</csymbol><apply id="S6.SS1.p3.11.m11.2.2.2.1.1.1.cmml" xref="S6.SS1.p3.11.m11.2.2.2.1.1.1"><minus id="S6.SS1.p3.11.m11.2.2.2.1.1.1.1.cmml" xref="S6.SS1.p3.11.m11.2.2.2.1.1.1.1"></minus><apply id="S6.SS1.p3.11.m11.2.2.2.1.1.1.2.cmml" xref="S6.SS1.p3.11.m11.2.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S6.SS1.p3.11.m11.2.2.2.1.1.1.2.1.cmml" xref="S6.SS1.p3.11.m11.2.2.2.1.1.1.2">superscript</csymbol><apply id="S6.SS1.p3.11.m11.2.2.2.1.1.1.2.2.cmml" xref="S6.SS1.p3.11.m11.2.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S6.SS1.p3.11.m11.2.2.2.1.1.1.2.2.1.cmml" xref="S6.SS1.p3.11.m11.2.2.2.1.1.1.2">subscript</csymbol><ci id="S6.SS1.p3.11.m11.2.2.2.1.1.1.2.2.2.cmml" xref="S6.SS1.p3.11.m11.2.2.2.1.1.1.2.2.2">𝛿</ci><ci id="S6.SS1.p3.11.m11.2.2.2.1.1.1.2.2.3.cmml" xref="S6.SS1.p3.11.m11.2.2.2.1.1.1.2.2.3">𝑖</ci></apply><ci id="S6.SS1.p3.11.m11.2.2.2.1.1.1.2.3.cmml" xref="S6.SS1.p3.11.m11.2.2.2.1.1.1.2.3">𝑡</ci></apply><ci id="S6.SS1.p3.11.m11.2.2.2.1.1.1.3.cmml" xref="S6.SS1.p3.11.m11.2.2.2.1.1.1.3">𝛿</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.11.m11.2c">S(\delta_{i}^{t})={\textstyle\sum}_{\delta\in C_{i}}\|\delta_{i}^{t}-\delta\|</annotation></semantics></math>. Krum then chooses <math id="S6.SS1.p3.12.m12.1" class="ltx_Math" alttext="\delta_{krum}=\delta_{i}^{t}" display="inline"><semantics id="S6.SS1.p3.12.m12.1a"><mrow id="S6.SS1.p3.12.m12.1.1" xref="S6.SS1.p3.12.m12.1.1.cmml"><msub id="S6.SS1.p3.12.m12.1.1.2" xref="S6.SS1.p3.12.m12.1.1.2.cmml"><mi id="S6.SS1.p3.12.m12.1.1.2.2" xref="S6.SS1.p3.12.m12.1.1.2.2.cmml">δ</mi><mrow id="S6.SS1.p3.12.m12.1.1.2.3" xref="S6.SS1.p3.12.m12.1.1.2.3.cmml"><mi id="S6.SS1.p3.12.m12.1.1.2.3.2" xref="S6.SS1.p3.12.m12.1.1.2.3.2.cmml">k</mi><mo lspace="0em" rspace="0em" id="S6.SS1.p3.12.m12.1.1.2.3.1" xref="S6.SS1.p3.12.m12.1.1.2.3.1.cmml">​</mo><mi id="S6.SS1.p3.12.m12.1.1.2.3.3" xref="S6.SS1.p3.12.m12.1.1.2.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S6.SS1.p3.12.m12.1.1.2.3.1a" xref="S6.SS1.p3.12.m12.1.1.2.3.1.cmml">​</mo><mi id="S6.SS1.p3.12.m12.1.1.2.3.4" xref="S6.SS1.p3.12.m12.1.1.2.3.4.cmml">u</mi><mo lspace="0em" rspace="0em" id="S6.SS1.p3.12.m12.1.1.2.3.1b" xref="S6.SS1.p3.12.m12.1.1.2.3.1.cmml">​</mo><mi id="S6.SS1.p3.12.m12.1.1.2.3.5" xref="S6.SS1.p3.12.m12.1.1.2.3.5.cmml">m</mi></mrow></msub><mo id="S6.SS1.p3.12.m12.1.1.1" xref="S6.SS1.p3.12.m12.1.1.1.cmml">=</mo><msubsup id="S6.SS1.p3.12.m12.1.1.3" xref="S6.SS1.p3.12.m12.1.1.3.cmml"><mi id="S6.SS1.p3.12.m12.1.1.3.2.2" xref="S6.SS1.p3.12.m12.1.1.3.2.2.cmml">δ</mi><mi id="S6.SS1.p3.12.m12.1.1.3.2.3" xref="S6.SS1.p3.12.m12.1.1.3.2.3.cmml">i</mi><mi id="S6.SS1.p3.12.m12.1.1.3.3" xref="S6.SS1.p3.12.m12.1.1.3.3.cmml">t</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.12.m12.1b"><apply id="S6.SS1.p3.12.m12.1.1.cmml" xref="S6.SS1.p3.12.m12.1.1"><eq id="S6.SS1.p3.12.m12.1.1.1.cmml" xref="S6.SS1.p3.12.m12.1.1.1"></eq><apply id="S6.SS1.p3.12.m12.1.1.2.cmml" xref="S6.SS1.p3.12.m12.1.1.2"><csymbol cd="ambiguous" id="S6.SS1.p3.12.m12.1.1.2.1.cmml" xref="S6.SS1.p3.12.m12.1.1.2">subscript</csymbol><ci id="S6.SS1.p3.12.m12.1.1.2.2.cmml" xref="S6.SS1.p3.12.m12.1.1.2.2">𝛿</ci><apply id="S6.SS1.p3.12.m12.1.1.2.3.cmml" xref="S6.SS1.p3.12.m12.1.1.2.3"><times id="S6.SS1.p3.12.m12.1.1.2.3.1.cmml" xref="S6.SS1.p3.12.m12.1.1.2.3.1"></times><ci id="S6.SS1.p3.12.m12.1.1.2.3.2.cmml" xref="S6.SS1.p3.12.m12.1.1.2.3.2">𝑘</ci><ci id="S6.SS1.p3.12.m12.1.1.2.3.3.cmml" xref="S6.SS1.p3.12.m12.1.1.2.3.3">𝑟</ci><ci id="S6.SS1.p3.12.m12.1.1.2.3.4.cmml" xref="S6.SS1.p3.12.m12.1.1.2.3.4">𝑢</ci><ci id="S6.SS1.p3.12.m12.1.1.2.3.5.cmml" xref="S6.SS1.p3.12.m12.1.1.2.3.5">𝑚</ci></apply></apply><apply id="S6.SS1.p3.12.m12.1.1.3.cmml" xref="S6.SS1.p3.12.m12.1.1.3"><csymbol cd="ambiguous" id="S6.SS1.p3.12.m12.1.1.3.1.cmml" xref="S6.SS1.p3.12.m12.1.1.3">superscript</csymbol><apply id="S6.SS1.p3.12.m12.1.1.3.2.cmml" xref="S6.SS1.p3.12.m12.1.1.3"><csymbol cd="ambiguous" id="S6.SS1.p3.12.m12.1.1.3.2.1.cmml" xref="S6.SS1.p3.12.m12.1.1.3">subscript</csymbol><ci id="S6.SS1.p3.12.m12.1.1.3.2.2.cmml" xref="S6.SS1.p3.12.m12.1.1.3.2.2">𝛿</ci><ci id="S6.SS1.p3.12.m12.1.1.3.2.3.cmml" xref="S6.SS1.p3.12.m12.1.1.3.2.3">𝑖</ci></apply><ci id="S6.SS1.p3.12.m12.1.1.3.3.cmml" xref="S6.SS1.p3.12.m12.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.12.m12.1c">\delta_{krum}=\delta_{i}^{t}</annotation></semantics></math> with the lowest score to update the global parameter <math id="S6.SS1.p3.13.m13.1" class="ltx_Math" alttext="w_{i}^{t+1}=w_{i}^{t}+\delta_{krum}" display="inline"><semantics id="S6.SS1.p3.13.m13.1a"><mrow id="S6.SS1.p3.13.m13.1.1" xref="S6.SS1.p3.13.m13.1.1.cmml"><msubsup id="S6.SS1.p3.13.m13.1.1.2" xref="S6.SS1.p3.13.m13.1.1.2.cmml"><mi id="S6.SS1.p3.13.m13.1.1.2.2.2" xref="S6.SS1.p3.13.m13.1.1.2.2.2.cmml">w</mi><mi id="S6.SS1.p3.13.m13.1.1.2.2.3" xref="S6.SS1.p3.13.m13.1.1.2.2.3.cmml">i</mi><mrow id="S6.SS1.p3.13.m13.1.1.2.3" xref="S6.SS1.p3.13.m13.1.1.2.3.cmml"><mi id="S6.SS1.p3.13.m13.1.1.2.3.2" xref="S6.SS1.p3.13.m13.1.1.2.3.2.cmml">t</mi><mo id="S6.SS1.p3.13.m13.1.1.2.3.1" xref="S6.SS1.p3.13.m13.1.1.2.3.1.cmml">+</mo><mn id="S6.SS1.p3.13.m13.1.1.2.3.3" xref="S6.SS1.p3.13.m13.1.1.2.3.3.cmml">1</mn></mrow></msubsup><mo id="S6.SS1.p3.13.m13.1.1.1" xref="S6.SS1.p3.13.m13.1.1.1.cmml">=</mo><mrow id="S6.SS1.p3.13.m13.1.1.3" xref="S6.SS1.p3.13.m13.1.1.3.cmml"><msubsup id="S6.SS1.p3.13.m13.1.1.3.2" xref="S6.SS1.p3.13.m13.1.1.3.2.cmml"><mi id="S6.SS1.p3.13.m13.1.1.3.2.2.2" xref="S6.SS1.p3.13.m13.1.1.3.2.2.2.cmml">w</mi><mi id="S6.SS1.p3.13.m13.1.1.3.2.2.3" xref="S6.SS1.p3.13.m13.1.1.3.2.2.3.cmml">i</mi><mi id="S6.SS1.p3.13.m13.1.1.3.2.3" xref="S6.SS1.p3.13.m13.1.1.3.2.3.cmml">t</mi></msubsup><mo id="S6.SS1.p3.13.m13.1.1.3.1" xref="S6.SS1.p3.13.m13.1.1.3.1.cmml">+</mo><msub id="S6.SS1.p3.13.m13.1.1.3.3" xref="S6.SS1.p3.13.m13.1.1.3.3.cmml"><mi id="S6.SS1.p3.13.m13.1.1.3.3.2" xref="S6.SS1.p3.13.m13.1.1.3.3.2.cmml">δ</mi><mrow id="S6.SS1.p3.13.m13.1.1.3.3.3" xref="S6.SS1.p3.13.m13.1.1.3.3.3.cmml"><mi id="S6.SS1.p3.13.m13.1.1.3.3.3.2" xref="S6.SS1.p3.13.m13.1.1.3.3.3.2.cmml">k</mi><mo lspace="0em" rspace="0em" id="S6.SS1.p3.13.m13.1.1.3.3.3.1" xref="S6.SS1.p3.13.m13.1.1.3.3.3.1.cmml">​</mo><mi id="S6.SS1.p3.13.m13.1.1.3.3.3.3" xref="S6.SS1.p3.13.m13.1.1.3.3.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S6.SS1.p3.13.m13.1.1.3.3.3.1a" xref="S6.SS1.p3.13.m13.1.1.3.3.3.1.cmml">​</mo><mi id="S6.SS1.p3.13.m13.1.1.3.3.3.4" xref="S6.SS1.p3.13.m13.1.1.3.3.3.4.cmml">u</mi><mo lspace="0em" rspace="0em" id="S6.SS1.p3.13.m13.1.1.3.3.3.1b" xref="S6.SS1.p3.13.m13.1.1.3.3.3.1.cmml">​</mo><mi id="S6.SS1.p3.13.m13.1.1.3.3.3.5" xref="S6.SS1.p3.13.m13.1.1.3.3.3.5.cmml">m</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.p3.13.m13.1b"><apply id="S6.SS1.p3.13.m13.1.1.cmml" xref="S6.SS1.p3.13.m13.1.1"><eq id="S6.SS1.p3.13.m13.1.1.1.cmml" xref="S6.SS1.p3.13.m13.1.1.1"></eq><apply id="S6.SS1.p3.13.m13.1.1.2.cmml" xref="S6.SS1.p3.13.m13.1.1.2"><csymbol cd="ambiguous" id="S6.SS1.p3.13.m13.1.1.2.1.cmml" xref="S6.SS1.p3.13.m13.1.1.2">superscript</csymbol><apply id="S6.SS1.p3.13.m13.1.1.2.2.cmml" xref="S6.SS1.p3.13.m13.1.1.2"><csymbol cd="ambiguous" id="S6.SS1.p3.13.m13.1.1.2.2.1.cmml" xref="S6.SS1.p3.13.m13.1.1.2">subscript</csymbol><ci id="S6.SS1.p3.13.m13.1.1.2.2.2.cmml" xref="S6.SS1.p3.13.m13.1.1.2.2.2">𝑤</ci><ci id="S6.SS1.p3.13.m13.1.1.2.2.3.cmml" xref="S6.SS1.p3.13.m13.1.1.2.2.3">𝑖</ci></apply><apply id="S6.SS1.p3.13.m13.1.1.2.3.cmml" xref="S6.SS1.p3.13.m13.1.1.2.3"><plus id="S6.SS1.p3.13.m13.1.1.2.3.1.cmml" xref="S6.SS1.p3.13.m13.1.1.2.3.1"></plus><ci id="S6.SS1.p3.13.m13.1.1.2.3.2.cmml" xref="S6.SS1.p3.13.m13.1.1.2.3.2">𝑡</ci><cn type="integer" id="S6.SS1.p3.13.m13.1.1.2.3.3.cmml" xref="S6.SS1.p3.13.m13.1.1.2.3.3">1</cn></apply></apply><apply id="S6.SS1.p3.13.m13.1.1.3.cmml" xref="S6.SS1.p3.13.m13.1.1.3"><plus id="S6.SS1.p3.13.m13.1.1.3.1.cmml" xref="S6.SS1.p3.13.m13.1.1.3.1"></plus><apply id="S6.SS1.p3.13.m13.1.1.3.2.cmml" xref="S6.SS1.p3.13.m13.1.1.3.2"><csymbol cd="ambiguous" id="S6.SS1.p3.13.m13.1.1.3.2.1.cmml" xref="S6.SS1.p3.13.m13.1.1.3.2">superscript</csymbol><apply id="S6.SS1.p3.13.m13.1.1.3.2.2.cmml" xref="S6.SS1.p3.13.m13.1.1.3.2"><csymbol cd="ambiguous" id="S6.SS1.p3.13.m13.1.1.3.2.2.1.cmml" xref="S6.SS1.p3.13.m13.1.1.3.2">subscript</csymbol><ci id="S6.SS1.p3.13.m13.1.1.3.2.2.2.cmml" xref="S6.SS1.p3.13.m13.1.1.3.2.2.2">𝑤</ci><ci id="S6.SS1.p3.13.m13.1.1.3.2.2.3.cmml" xref="S6.SS1.p3.13.m13.1.1.3.2.2.3">𝑖</ci></apply><ci id="S6.SS1.p3.13.m13.1.1.3.2.3.cmml" xref="S6.SS1.p3.13.m13.1.1.3.2.3">𝑡</ci></apply><apply id="S6.SS1.p3.13.m13.1.1.3.3.cmml" xref="S6.SS1.p3.13.m13.1.1.3.3"><csymbol cd="ambiguous" id="S6.SS1.p3.13.m13.1.1.3.3.1.cmml" xref="S6.SS1.p3.13.m13.1.1.3.3">subscript</csymbol><ci id="S6.SS1.p3.13.m13.1.1.3.3.2.cmml" xref="S6.SS1.p3.13.m13.1.1.3.3.2">𝛿</ci><apply id="S6.SS1.p3.13.m13.1.1.3.3.3.cmml" xref="S6.SS1.p3.13.m13.1.1.3.3.3"><times id="S6.SS1.p3.13.m13.1.1.3.3.3.1.cmml" xref="S6.SS1.p3.13.m13.1.1.3.3.3.1"></times><ci id="S6.SS1.p3.13.m13.1.1.3.3.3.2.cmml" xref="S6.SS1.p3.13.m13.1.1.3.3.3.2">𝑘</ci><ci id="S6.SS1.p3.13.m13.1.1.3.3.3.3.cmml" xref="S6.SS1.p3.13.m13.1.1.3.3.3.3">𝑟</ci><ci id="S6.SS1.p3.13.m13.1.1.3.3.3.4.cmml" xref="S6.SS1.p3.13.m13.1.1.3.3.3.4">𝑢</ci><ci id="S6.SS1.p3.13.m13.1.1.3.3.3.5.cmml" xref="S6.SS1.p3.13.m13.1.1.3.3.3.5">𝑚</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p3.13.m13.1c">w_{i}^{t+1}=w_{i}^{t}+\delta_{krum}</annotation></semantics></math>. Krum is resistant to attacks by omniscient adversaries – aware of a good estimate of the gradient – who send the opposite vector multiplied by a large factor. It is also resistant to attacks by adversaries who send random vectors drawn from a Gaussian distribution (the larger the variance of the distribution, the stronger the attack).
Multi-Krum is a variant of Krum, which intuitively interpolates between Krum and averaging, thereby combining the resilience properties of Krum with the convergence speed of averaging. Essentially, Krum filters outliers based on the entire update vector, but does not filter coordinate-wise outliers.</p>
</div>
<div id="S6.SS1.p4" class="ltx_para">
<p id="S6.SS1.p4.1" class="ltx_p">To address this issue,
Yin <span id="S6.SS1.p4.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> proposed two robust distributed gradient descent algorithms, one based on coordinate-wise median, and the other based on the coordinate-wise trimmed mean. Unfortunately, median-based rules can incur a prohibitive computational overhead in large-scale settings <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib145" title="" class="ltx_ref">145</a>]</cite>. Mhamdi <span id="S6.SS1.p4.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib140" title="" class="ltx_ref">140</a>]</cite> proposed a meta-aggregation rule called Bulyan, a two-step meta-aggregation algorithm based on the Krum and trimmed median, which filters malicious updates followed by computing the trimmed median of the remaining updates. Median and geometric-median based robust aggregation rules are also extensively explored in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib146" title="" class="ltx_ref">146</a>, <a href="#bib.bib147" title="" class="ltx_ref">147</a>]</cite>.
Pillutla <span id="S6.SS1.p4.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite> proposed a robust aggregation approach called RFA by replacing the weighted arithmetic mean with an approximate geometric median, so as to reduce the impact of the contaminated updates. Unfortunately, RFA can only handle a few types of poisoning attackers, but not applicable to Byzantine attacks.</p>
</div>
<div id="S6.SS1.p5" class="ltx_para">
<p id="S6.SS1.p5.1" class="ltx_p">In spite of their robustness guarantees, recent inspections revealed that previous Byzantine-robust FL mechanisms are also quite brittle and can be easily circumvented. Bhagoji <span id="S6.SS1.p5.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> showed that targeted model poisoning of deep neural networks is effective even against the Byzantine-robust aggregation rules such as Krum and coordinate-wise median. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib133" title="" class="ltx_ref">133</a>, <a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite> showed that while the Byzantine-robust aggregation rules may ensure that the influence of the Byzantine workers in any single round is limited, the attackers can couple their attacks across the rounds, moving weights significantly away from the desired direction and thus achieve the goal of lowering the model quality. Xu <span id="S6.SS1.p5.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib148" title="" class="ltx_ref">148</a>]</cite> demonstrated that Multi-Krum is not robust against the untargeted poisoning. This is because Multi-Krum is based on the distance between each gradient vector and the mean vector, while the mean vector is not robust against untargeted poisoning. Fang <span id="S6.SS1.p5.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite> showed that aggregation rules (<span id="S6.SS1.p5.1.4" class="ltx_text ltx_font_italic">e.g.</span>, Krum <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, Bulyan <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib140" title="" class="ltx_ref">140</a>]</cite>, trimmed mean <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, coordinate-wise median <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, and other median-based aggregators <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>) that were claimed to be robust against Byzantine failures are not effective in practice against optimized local model poisoning attacks that carefully craft local models on the compromised participants such that the aggregated global model deviates the most towards the inverse of the direction along which the global model would change when there are no attacks. All these highlight the need for more effective defenses against Byzantine attackers in FL.</p>
</div>
<div id="S6.SS1.p6" class="ltx_para">
<p id="S6.SS1.p6.1" class="ltx_p">Other works investigate Byzantine robustness from different lens. Chen <span id="S6.SS1.p6.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib145" title="" class="ltx_ref">145</a>]</cite> presented DRACO, a framework for robust distributed training via algorithmic redundancy. DRACO is robust to arbitrarily malicious computing nodes, while being orders of magnitude faster than state-of-the-art robust distributed systems. However, DRACO assumes that each participant can access other participants’ data, limiting its practicability in FL.
Su <span id="S6.SS1.p6.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite> proposed to robustly aggregate the gradients computed by the Byzantine participants based on the filtering procedure proposed by Steinhardt <span id="S6.SS1.p6.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib149" title="" class="ltx_ref">149</a>]</cite>. Bernstein <span id="S6.SS1.p6.1.4" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> proposed <span id="S6.SS1.p6.1.5" class="ltx_text" style="font-size:70%;">SIGN</span>SGD, which is combined with majority vote to enable participants to upload element-wise signs of their gradients to defend against three types of half “blind” Byzantine adversaries: (i) adversaries that arbitrarily rescale their stochastic gradient estimate;
(ii) adversaries that randomise the sign of each coordinate of the stochastic gradient;
(iii) adversaries that invert their stochastic gradient estimate.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS2.4.1.1" class="ltx_text">VI-B</span> </span><span id="S6.SS2.5.2" class="ltx_text ltx_font_italic">Defenses against Targeted Attacks</span>
</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">Existing defenses against the targeted backdoor attacks can be categorized into two types: detection methods and erasing methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib150" title="" class="ltx_ref">150</a>]</cite>. Detection methods exploit activation statistics or model properties to determine whether a model is backdoored <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib151" title="" class="ltx_ref">151</a>, <a href="#bib.bib152" title="" class="ltx_ref">152</a>]</cite>, or whether a training/test example is a backdoor example <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>.</p>
</div>
<div id="S6.SS2.p2" class="ltx_para">
<p id="S6.SS2.p2.1" class="ltx_p">There are a number of detection algorithms that are designed to detect which inputs contain backdoor, and which parts of the model (its activation functions specifically) are responsible for triggering the adversarial behavior of the model, in order to remove the backdoor <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>, <a href="#bib.bib128" title="" class="ltx_ref">128</a>, <a href="#bib.bib153" title="" class="ltx_ref">153</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>. These algorithms rely on the statistical difference between the latent representations of backdoor-enabled and clean (benign) inputs in the poisoned model. These backdoor detection algorithms can however be bypassed by maximizing the latent indistinguishability of backdoor-enabled adversarial inputs and clean inputs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib154" title="" class="ltx_ref">154</a>]</cite>.</p>
</div>
<div id="S6.SS2.p3" class="ltx_para">
<p id="S6.SS2.p3.1" class="ltx_p">While detection can help identify potential risks, the backdoored model still needs to be purified since the potential impact of backdoor triggers remains uncleared in the backdoored models. The erasing methods take a step further and aim to purify the adverse impacts on models caused by the backdoor triggers. The current state-of-the-art erasing methods are Mode Connectivity Repair (MCR) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib155" title="" class="ltx_ref">155</a>]</cite> and Neural Attention Distillation (NAD) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>. MCR mitigates the backdoors by selecting a robust model in the path of loss landscape, while NAD leverages knowledge distillation to erase triggers. Other previous methods, including finetuning, denoising, and fine-pruning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib153" title="" class="ltx_ref">153</a>]</cite>, have been shown to be insufficient against the latest attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib156" title="" class="ltx_ref">156</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>. Another more recent work called Anti-Backdoor Learning (ABL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite> aims to train clean models given backdoor-poisoned data. They frame the overall learning process as a dual-task of learning the clean and the backdoor portions of data. From this view, they identify two inherent characteristics of backdoor attacks as their weaknesses: 1) the models learn backdoored data much faster than learning with clean data, and the stronger the attack the faster the model converges on backdoored data; 2) the backdoor task is tied to a specific class (the backdoor target class). Based on these two weaknesses, ABL introduces a two-stage gradient ascent mechanism for standard training to 1) help isolate backdoor examples at an early training stage, and 2) break the correlation between backdoor examples and the target class at a later training stage. Extensive experiments on multiple benchmark datasets against 10 state-of-the-art attacks empirically show that ABL can automatically prevent backdoor attacks during training, without degrading the main performance.</p>
</div>
<div id="S6.SS2.p4" class="ltx_para">
<p id="S6.SS2.p4.1" class="ltx_p">Despite the promising backdoor defense results in the centralized setting, it is still unclear whether these defenses can be smoothly adapted to FL setting, especially in the non-iid setting. For backdoor defense in FL, Sun <span id="S6.SS2.p4.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> showed that clipping the norm of model updates and adding Gaussian noise can mitigate backdoor attacks that are based on the model replacement paradigm. Andreina <span id="S6.SS2.p4.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib157" title="" class="ltx_ref">157</a>]</cite> incorporated an additional validation phase in each round of FL to detect backdoor.
However, None of these provides certified robustness guarantees. Certified robustness for FL against backdoor attacks remain largely unexplored. Xie <span id="S6.SS2.p4.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib143" title="" class="ltx_ref">143</a>]</cite> provided the first general framework called <em id="S6.SS2.p4.1.4" class="ltx_emph ltx_font_italic">Certifiably Robust Federated Learning</em> (CRFL), to train certifiably robust FL models against backdoors.</p>
</div>
<div id="S6.SS2.p5" class="ltx_para">
<p id="S6.SS2.p5.1" class="ltx_p">To defend against the targeted poisoning attack by sybil clones, Fung <span id="S6.SS2.p5.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> exploited the characteristic behavior that sybils are more similar to each other than the similarity observed amongst the honest clients, and proposed FoolsGold: a new defense scheme against FL Sybil attacks by adapting the learning rate of participants based on contribution similarity. Note that FoolsGold does not bound the expected number of attackers by assuming that attackers can spawn a large number of Sybils, rendering assumptions about proportions of honest participants unrealistic <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. Additionally, FoolsGold requires no auxiliary information beyond the learning process, and makes fewer assumptions about participants and their data. The robustness of FoolsGold holds for different distributions of participant data, varying poisoning targets, and various Sybil strategies, and can be applied successfully on both FedSGD and FedAvg.</p>
</div>
<div id="S6.SS2.p6" class="ltx_para">
<p id="S6.SS2.p6.1" class="ltx_p">We list the most representative defenses against poisoning attacks against FL in Table <a href="#S5.T6" title="TABLE VI ‣ V-B Targeted Attacks ‣ V Poisoning Attacks ‣ Privacy and Robustness in Federated Learning: Attacks and Defenses" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a>. Some robust aggregation algorithms have breaking points, <span id="S6.SS2.p6.1.1" class="ltx_text ltx_font_italic">i.e.</span>, the fraction of malicious participants, robustness guarantees cannot be provided if the fraction of malicious participants is larger than the breaking point.</p>
</div>
<div id="S6.SS2.p7" class="ltx_para">
<p id="S6.SS2.p7.1" class="ltx_p"><span id="S6.SS2.p7.1.1" class="ltx_text ltx_font_bold">Remark</span>. Note that both the untargeted and targeted poisoning attacks are less effective in settings with
infrequent participation like H2C <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. Moreover, under practical production FL environments, Shejwalkar <span id="S6.SS2.p7.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib141" title="" class="ltx_ref">141</a>]</cite> have showed that FL, even without any defenses, is highly robust in practice. For production cross-device FL (H2C), which contains thousands to billions of clients, poisoning attacks have no impact on existing robust FL algorithms even with impractically high percentages of compromised clients. For production cross-silo FL (H2B), which contains up to hundred clients, data poisoning attacks are completely ineffective; model poisoning attacks are unlikely to play a major risk when the clients involved are bound by contract and their software stacks professionally maintained (e.g., in banks, hospitals). Some exceptional cross-silo scenarios are most likely with a strong incentive (e.g., financial) causing multiple parties to be willing to risk breach of contract by colluding or for one party to hack thereby risking criminal liability. Therefore, we conclude that these poisoning attacks are more likely to happen in some exceptional H2B scenarios.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span id="S7.1.1" class="ltx_text ltx_font_smallcaps">Discussions and Promising Directions</span>
</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">There are still potential vulnerabilities which need to be addressed in order to improve the privacy and robustness of FL systems. Moreover, there are multiple design goals that are equally important with privacy and robustness, thus need to be considered simultaneously in FL. In this section, we outline research directions which we believe are promising.</p>
</div>
<div id="S7.p2" class="ltx_para">
<p id="S7.p2.1" class="ltx_p"><span id="S7.p2.1.1" class="ltx_text ltx_font_bold">Curse of Dimensionality:</span>
Large models, with high dimensional parameter vectors, are particularly susceptible to privacy and security attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib158" title="" class="ltx_ref">158</a>]</cite>. Most FL algorithms require overwriting the local model parameters with the global model. This makes them susceptible to poisoning attacks, as the adversary can make small but damaging changes in the high-dimensional models without being detected. Almost all of the well-designed Byzantine-robust aggregators <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite> still suffer from the curse of dimensionality. Specifically, the estimation error scales up with the size of the model in a square-root manner. Thus, sharing model parameters may not be a strong design choice in FL, it opens all the internal state of the model to inference attacks, and maximizes the model’s malleability by poisoning attacks. The large number of hyperparameters might also adversely affect communication and accuracy, though the follow up work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib159" title="" class="ltx_ref">159</a>]</cite> tried adaptive gradient clipping strategies to help alleviate this issue. To address these fundamental shortcomings of FL, it is worthwhile to explore whether sharing gradients is essential. Instead, sharing less sensitive information (<span id="S7.p2.1.2" class="ltx_text ltx_font_italic">e.g.</span>,<span id="S7.p2.1.3" class="ltx_text" style="font-size:70%;">SIGN</span>SGD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib160" title="" class="ltx_ref">160</a>]</cite>) or only sharing model predictions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib158" title="" class="ltx_ref">158</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib87" title="" class="ltx_ref">87</a>]</cite> in a black-box manner may result in more robust privacy protection in FL.</p>
</div>
<div id="S7.p3" class="ltx_para">
<p id="S7.p3.1" class="ltx_p"><span id="S7.p3.1.1" class="ltx_text ltx_font_bold">Rethinking Current Privacy Attacks:</span>
There are several inherent weaknesses in current attacks that may limit their applicability in FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib161" title="" class="ltx_ref">161</a>]</cite>. For example, GAN attack assumes that the entire training corpus for a given class comes from a single participant, and only in the special case where all class members are similar, GAN-constructed representatives are similar to the training data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite>. These assumptions may be less practical in FL. For DLG <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> and iDLG <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>, both works: (1) adopt a second-order optimization method called L-BFGS, which is more computationally expensive compared with first-order optimization methods; (2) are only applicable to gradients computed on mini-batches of data, <span id="S7.p3.1.2" class="ltx_text ltx_font_italic">i.e.</span>, at most B=8 in DLG, and B=1 in iDLG, which is not the real case for FL, in which gradient is normally shared after at least 1 epoch of local training; (3) used untrained model, neglecting gradients over multiple communication rounds. Attacking FL system in a more efficient manner and under more practical settings remains largely unexplored.</p>
</div>
<div id="S7.p4" class="ltx_para">
<p id="S7.p4.1" class="ltx_p"><span id="S7.p4.1.1" class="ltx_text ltx_font_bold">Rethinking Current Defenses:</span>
FL with secure aggregation for the purpose of privacy is more susceptible to poisoning attacks as the individual updates cannot be inspected. Similarly, it is still unclear if adversarial training, one state-of-the-art defense approach against adversarial attacks in conventional ML <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib162" title="" class="ltx_ref">162</a>, <a href="#bib.bib163" title="" class="ltx_ref">163</a>, <a href="#bib.bib164" title="" class="ltx_ref">164</a>]</cite>, can be adapted to FL, as adversarial training was developed primarily for IID data and remains unclear for its performance in non-IID settings. Moreover, adversarial training is computationally expensive and may hurt the performance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib165" title="" class="ltx_ref">165</a>]</cite>, which may not be feasible for H2C scenario. In terms of differential privacy (DP) based methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib166" title="" class="ltx_ref">166</a>, <a href="#bib.bib84" title="" class="ltx_ref">84</a>, <a href="#bib.bib167" title="" class="ltx_ref">167</a>, <a href="#bib.bib168" title="" class="ltx_ref">168</a>, <a href="#bib.bib169" title="" class="ltx_ref">169</a>]</cite>,
record-level DP bounds the success of membership inference, but does not prevent property inference applied to a group of training records <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. Participant-level DP, on the other hand, is geared to work with thousands of users for training to converge and achieving an acceptable trade-off between privacy and accuracy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. The FL model fails to converge with a small number of participants, making it unsuitable for H2B scenarios. Furthermore, DP may hurt the accuracy of the learned model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib170" title="" class="ltx_ref">170</a>]</cite>, which may not be appealing to the industry. Further work is needed to investigate if participant-level DP can protect FL systems with fewer participants.</p>
</div>
<div id="S7.p5" class="ltx_para">
<p id="S7.p5.1" class="ltx_p"><span id="S7.p5.1.1" class="ltx_text ltx_font_bold">Optimizing Defense Mechanism Deployment:</span>
When deploying defense mechanisms to check if any adversary is attacking the FL system, the FL server will need additional computational cost. In addition, different types of defense mechanisms may have different effectiveness against different attacks, and incur different costs. It is important to study how to optimize the timing of deploying the defense mechanisms or the announcement of deterrence measures. Game theoretic research holds promise in addressing this challenge.</p>
</div>
<div id="S7.p6" class="ltx_para">
<p id="S7.p6.1" class="ltx_p"><span id="S7.p6.1.1" class="ltx_text ltx_font_bold">Test-phase Privacy in FL:</span>
This survey mainly focuses on the training phase attacks and defenses in FL, considering the more attack possibilities opened by the distributed training property of FL systems. In fact, FL is also vulnerable to both privacy and robustness attacks during test/inference phase by the users of the final FL model when it is deployed as a service.</p>
</div>
<div id="S7.p7" class="ltx_para">
<p id="S7.p7.1" class="ltx_p">In terms of the privacy vulnerability, the trained global model may reveal sensitive information from model predictions when deployed as a service, causing privacy leakage. In such a setting, an adversary does not have direct access to the model parameters, but may be able to view input-output pairs.
Previous researches have shown a series of privacy leakage given only black-box access to the trained models, such as (1) model stealing attacks in which model parameters can be reconstructed by an adversary who only has access to an inference/prediction API based on those parameters <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib171" title="" class="ltx_ref">171</a>, <a href="#bib.bib172" title="" class="ltx_ref">172</a>, <a href="#bib.bib173" title="" class="ltx_ref">173</a>, <a href="#bib.bib174" title="" class="ltx_ref">174</a>]</cite>; (2) membership inference attacks which aim to determine if a particular record was used to train the model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite>. FL models face the similar dilemma during model deployment for testing purpose. The development of effective defenses against privacy leakage during model deployment calls for further investigations.</p>
</div>
<div id="S7.p8" class="ltx_para">
<p id="S7.p8.1" class="ltx_p"><span id="S7.p8.1.1" class="ltx_text ltx_font_bold">Test-phase Robustness in FL:</span>
In terms of the robustness vulnerability, recent studies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib175" title="" class="ltx_ref">175</a>, <a href="#bib.bib176" title="" class="ltx_ref">176</a>, <a href="#bib.bib177" title="" class="ltx_ref">177</a>]</cite> have shown that FL is also vulnerable to well-crafted adversarial examples. During inference time, the attackers can add a very small perturbation to the test data, making the test data almost indistinguishable from natural data and yet classified incorrectly by the global model. For federated robustness against adversarial examples, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib175" title="" class="ltx_ref">175</a>, <a href="#bib.bib176" title="" class="ltx_ref">176</a>]</cite> proposed to apply adversarial training (AT) to FL, i.e, federated adversarial training (FAT), in order to achieve adversarial robustness in FL.
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib175" title="" class="ltx_ref">175</a>]</cite> noticed that conducting AT on all participants leads to divergence of the model. To solve this problem, they conducted AT on only a proportion of participants for better convergence.
Another recent work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib176" title="" class="ltx_ref">176</a>]</cite> considered hardware heterogeneity in FL, <span id="S7.p8.1.2" class="ltx_text ltx_font_italic">i.e.</span>, only limited users can afford AT. Hence, they conduct AT on only a proportion of participants that have powerful computation resources while conducting standard training on the rest of the participants.
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib177" title="" class="ltx_ref">177</a>]</cite> investigated the impact of communication rounds in FAT and proposed a dynamic adversarial training.
The training of all the above FAT works are unstable, which potentially hurts the convergence and performance. Moreover, adversarial training typically requires significant computation and longer time to converge, and it is unclear how it performs in non-IID settings. How to speed up adversarial training in FL and the investigation of its applicability in non-IID settings may be required in the future.
Overall, there exist difficulties in applying adversarial training to the federated setting. This motivates future works to explore more effective approaches to maintain both natural accuracy and robust accuracy in FL.</p>
</div>
<div id="S7.p9" class="ltx_para">
<p id="S7.p9.1" class="ltx_p">In addition to the adversarial examples, recent works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib172" title="" class="ltx_ref">172</a>, <a href="#bib.bib173" title="" class="ltx_ref">173</a>]</cite> have validated that the API services (the victim/target model) can be easily stolen and are vulnerable to adversarial example transferability attack. It would be interesting to explore whether the collaboratively built global model in FL is also facing the similar problem, and how to effectively claim the ownership of the trained model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib178" title="" class="ltx_ref">178</a>]</cite>.</p>
</div>
<div id="S7.p10" class="ltx_para">
<p id="S7.p10.1" class="ltx_p">Overall, it would be of much importance towards realizing trustworthy FL by defending against both training-phase and test-phase attacks.</p>
</div>
<div id="S7.p11" class="ltx_para">
<p id="S7.p11.1" class="ltx_p"><span id="S7.p11.1.1" class="ltx_text ltx_font_bold">Relationship with GDPR:</span>
GDPR <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://gdpr-info.eu</span></span></span></span> defines 6-core principles as rational guidelines for service providers to manage personal data, including: (1) Lawfulness, fairness and transparency; (2) Purpose limitation; (3) Data minimisation; (4) Accuracy; (5) Storage limitation; (6) Integrity and confidentiality (security). GDPR also requires Data Controllers to provide the following rights for Data Subjects if capable (The GDPR Articles 12–23): (1) Right to be informed, (2) Right of access, (3) Right to rectification, (4) Right to erasure (Right to be forgotten), (5) Right to restrict processing, (6) Right to data portability, (7) Right to object, and (8) Rights in relation to automated decision making and profiling.
Although FL has emerged as a prospective solution that facilitates distributed collaborative learning without disclosing original training data, unfortunately, FL is not naturally compliant with the GDPR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib179" title="" class="ltx_ref">179</a>]</cite>, as pointed out by a recent survey <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib179" title="" class="ltx_ref">179</a>]</cite> that has dedicated to surveying the relationship between FL and GDPR requirements. For example, secure aggregation mechanism in FL amplifies the lack of transparency and fairness in FL systems, thus fails to fully comply with the GDPR requirements of fairness and transparency; malicious participants in FL may conduct either data or model poisoning attack for an unauthorised purpose, local ML model parameters obtained from participants is no longer minimal for the original purpose. These possible attacks, which lead to non-compliance with the GDPR, should be addressed. Henceforth, it is worthwhile to explore approaches to empower FL-based systems to follow the GDPR regulatory guidelines, thus fully comply with the GDPR.</p>
</div>
<div id="S7.p12" class="ltx_para">
<p id="S7.p12.1" class="ltx_p"><span id="S7.p12.1.1" class="ltx_text ltx_font_bold">Threats and Protections of VFL and FTL:</span>
This survey mainly focuses on the threats to HFL, there are some recent exploratory efforts on threats and protections of VFL and FTL.</p>
</div>
<div id="S7.p13" class="ltx_para">
<p id="S7.p13.1" class="ltx_p">For VFL, Secureboost <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib180" title="" class="ltx_ref">180</a>]</cite> considered user privacy and data confidentiality in VFL, and presented an approach to train a high-quality tree boosting model collaboratively.
A recent work called FederBoost <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib181" title="" class="ltx_ref">181</a>]</cite> pointed out that Secureboost is expensive since it requires cryptoraphic computation and communication for each possible split, thus they proposed a vertical FederBoost which does <span id="S7.p13.1.1" class="ltx_text ltx_font_italic">not</span> require any cryptographic operation.
Another recent work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib182" title="" class="ltx_ref">182</a>]</cite> uncovered the risk of <em id="S7.p13.1.2" class="ltx_emph ltx_font_italic">catastrophic data leakage in vertical federated learning</em> (CAFE) through a novel algorithm that can perform large-batch data leakage with high data recovery quality and theoretical guarantees. They empirically demonstrated that CAFE can recover large-scale private data from the shared aggregated gradients in VFL settings, overcoming the batch limitation problem in current data leakage attacks.</p>
</div>
<div id="S7.p14" class="ltx_para">
<p id="S7.p14.1" class="ltx_p">For FTL, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib183" title="" class="ltx_ref">183</a>]</cite> proposed an end-to-end privacy-preserving multi-party learning approach with two variants based on homomorphic encryption and secret sharing techniques, respectively, to build a heterogeneous federated transfer learning (HFTL) framework. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> adopted two secure approaches, namely, homomorphic encryption (HE) and secret sharing for preserving privacy. The HE approach is simple but computationally expensive. By contrast, the secret sharing approach offers the following advantages: (i) there is no accuracy loss, (ii) computation is much faster than HE approach. The major drawback of the secret sharing approach is that one has to offline generate and store many triplets before online computation.</p>
</div>
<div id="S7.p15" class="ltx_para">
<p id="S7.p15.1" class="ltx_p">Overall, there is still a large space for VFL and FTL. It is worth further investigation as for whether existing threats in HFL are all valid in VFL and FTL, or if there are new threats and countermeasures in VFL and FTL.</p>
</div>
<div id="S7.p16" class="ltx_para">
<p id="S7.p16.1" class="ltx_p"><span id="S7.p16.1.1" class="ltx_text ltx_font_bold">Vulnerabilities to Free-riding Participants:</span>
In FL systems, there may exist free-riders, who aim to benefit from the global model, but do not want to contribute any useful information, thus compromising collaborative fairness <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib167" title="" class="ltx_ref">167</a>, <a href="#bib.bib168" title="" class="ltx_ref">168</a>, <a href="#bib.bib184" title="" class="ltx_ref">184</a>]</cite>. The main incentives for free-riders include: (1) the participant dose not have any data to train the local model; (2) the participant is too concerned about its privacy thus chooses to release fake updates; (3) the participant does not want to consume or does not have any local computation power to train the local model. In the current FL paradigm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, all participants receive the same federated model at the end of the collaborative training, regardless of their individual contributions. This makes the paradigm vulnerable to free-riding participants <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib167" title="" class="ltx_ref">167</a>, <a href="#bib.bib168" title="" class="ltx_ref">168</a>, <a href="#bib.bib185" title="" class="ltx_ref">185</a>, <a href="#bib.bib148" title="" class="ltx_ref">148</a>, <a href="#bib.bib186" title="" class="ltx_ref">186</a>]</cite>. How to prevent free-riding remains an open challenge.</p>
</div>
<div id="S7.p17" class="ltx_para">
<p id="S7.p17.1" class="ltx_p"><span id="S7.p17.1.1" class="ltx_text ltx_font_bold">More Possibilities in FL with Heterogeneous Architectures:</span> Most privacy and robustness researches are focused on FL with homogeneous architectures. It remains unclear whether existing attacks, privacy-preserving techniques and defense mechanisms can be adapted to FL with heterogeneous architectures. It is valuable future work to explore similar types of attacks and defenses in heterogeneous FL.</p>
</div>
<div id="S7.p18" class="ltx_para">
<p id="S7.p18.1" class="ltx_p"><span id="S7.p18.1.1" class="ltx_text ltx_font_bold">Decentralized FL:</span>
Decentralized FL is an emerging research area, where there is no single central server in the system <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib167" title="" class="ltx_ref">167</a>, <a href="#bib.bib168" title="" class="ltx_ref">168</a>]</cite>. Decentralized FL is potentially more useful for H2B scenarios where the business participants do not trust any third party. In this paradigm, each participant could be elected as a server in a round robin manner. The recent emerging swarm learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib187" title="" class="ltx_ref">187</a>]</cite> can be deemed as a decentralized FL framework, which unites edge computing, blockchain-based peer-to-peer networking and coordination while maintaining confidentiality without the need for a central coordinator. It is interesting to investigate whether existing threats to server-based FL still apply in decentralized FL.</p>
</div>
<div id="S7.p19" class="ltx_para">
<p id="S7.p19.1" class="ltx_p"><span id="S7.p19.1.1" class="ltx_text ltx_font_bold">Efficient FL with Single Round Communication:</span>
In addition to privacy and robustness, communication cost is another major concern that may hinder the practical deployment of FL. One-shot FL has recently emerged as a promising approach for communication efficiency. It allows the central server to learn a model in a single communication round. Despite the low communication cost, existing one-shot FL methods are mostly impractical or face inherent limitations, <span id="S7.p19.1.2" class="ltx_text ltx_font_italic">e.g.</span>, a public dataset is required, participants’ models are homogeneous, additional data/model information needs to be uploaded, unsatisfactory performance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib188" title="" class="ltx_ref">188</a>, <a href="#bib.bib189" title="" class="ltx_ref">189</a>, <a href="#bib.bib190" title="" class="ltx_ref">190</a>]</cite>. A recent work proposed a more practical data-free approach named FedSyn for one-shot FL framework with heterogeneity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib191" title="" class="ltx_ref">191</a>]</cite>. FedSyn is the first method that can be practically applied to various real-world applications due to the following benefits:
(1) FedSyn requires no additional information (except the model parameters) to be transferred between participants and the server;
(2) FedSyn does not require any auxiliary dataset for training;
(3) FedSyn is the first to consider both model and statistical heterogeneities in FL, <span id="S7.p19.1.3" class="ltx_text ltx_font_italic">i.e.</span>, the participants’ data are non-iid and different participants may have different model architectures. Other alternative one-shot FL approaches with practical assumptions are worthwhile to explore, considering the alluring communication efficiency and less privacy and robustness attack surfaces exposed in one-shot FL.</p>
</div>
<div id="S7.p20" class="ltx_para">
<p id="S7.p20.1" class="ltx_p"><span id="S7.p20.1.1" class="ltx_text ltx_font_bold">Achieving Multiple Objectives Simultaneously:</span>
There are no existing works that can satisfy multiple goals simultaneously: (1) fast algorithmic convergence; (2) good generalisation performance; (3) communication efficiency; (4) fault tolerance; (5) privacy preservation; and (6) robustness to targeted, untargeted poisoning attacks, and free-riders. Previous works have attempted to solve multiple objectives at the same time. For example,  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib168" title="" class="ltx_ref">168</a>, <a href="#bib.bib167" title="" class="ltx_ref">167</a>]</cite> addressed collaborative fairness and privacy simultaneously;  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib148" title="" class="ltx_ref">148</a>, <a href="#bib.bib192" title="" class="ltx_ref">192</a>]</cite> proposed a <em id="S7.p20.1.2" class="ltx_emph ltx_font_italic">Robust and Fair Federated Learning</em> (RFFL) framework to address both collaborative fairness and Byzantine robustness. However, it is important to highlight that there is an inherent conflict between privacy and robustness: defending against robustness attacks usually require complete control of the training process or access to the training data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib193" title="" class="ltx_ref">193</a>, <a href="#bib.bib139" title="" class="ltx_ref">139</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib194" title="" class="ltx_ref">194</a>]</cite>, which goes against the privacy requirements of FL. Although using encryption or DP-based techniques can provide provably privacy preservation, they are not robust to poisoning attacks and may produce models with undesirably poor privacy-utility trade-offs.
Agarwal <span id="S7.p20.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> combined differential privacy with model compression techniques to reduce communication cost and obtain privacy benefits simultaneously. It remains largely unexplored and there exist large gaps as for how to simultaneously achieve all the above six objectives.</p>
</div>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VIII </span><span id="S8.1.1" class="ltx_text ltx_font_smallcaps">Conclusions</span>
</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">Although federated learning is still in its infancy, it will continue to thrive and will be an active and important research area in the foreseeable future.
As FL evolves, so will the privacy and robustness threats to FL. It is of vital importance to provide a broad overview of current attacks and defenses on FL so that future FL system designers are well aware of the potential vulnerabilities in the current designs, and help them clear roadblocks towards the real-world deployment of FL. This survey serves as a concise and accessible overview of this topic, and it would greatly help our understanding of the privacy and robustness attack and defense landscape in FL. Global collaboration on FL is emerging through a number of workshops in leading AI conferences<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">http://www.federated-learning.org/</span></span></span></span>. The ultimate goal of developing a general purpose FL defense mechanism that can be robust against various attacks without degrading model performance will require interdisciplinary effort from the wider research community.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
H. Li, K. Ota, and M. Dong, “Learning iot in edge: Deep learning for the
internet of things with edge computing,” <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">IEEE Network</em>, vol. 32,
no. 1, pp. 96–101, 2018.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
M. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov, K. Talwar, and
L. Zhang, “Deep learning with differential privacy,” in <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">CCS</em>, 2016,
pp. 308–318.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Q. Yang, Y. Liu, Y. Cheng, Y. Kang, T. Chen, and H. Yu, <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Federated
Learning</em>.   Morgan &amp; Claypool
Publishers, 2019.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
H. B. McMahan, E. Moore, D. Ramage, and B. A. y Arcas, “Federated learning of
deep networks using model averaging,” <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">CoRR, arXiv:1602.05629</em>, 2016.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
K. Bonawitz, V. Ivanov, B. Kreuter, A. Marcedone, H. B. McMahan, S. Patel,
D. Ramage, A. Segal, and K. Seth, “Practical secure aggregation for
privacy-preserving machine learning,” in <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">CCS</em>, 2017, pp. 1175–1191.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-efficient learning of deep networks from decentralized
data,” in <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Artificial Intelligence and Statistics</em>, 2017, pp.
1273–1282.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
H. B. McMahan, D. Ramage, K. Talwar, and L. Zhang, “Learning differentially
private recurrent language models,” in <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">ICLR</em>, 2018.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Y. Liu, A. Huang, Y. Luo, H. Huang, Y. Liu, Y. Chen, L. Feng, T. Chen, H. Yu,
and Q. Yang, “Fedvision: An online visual object detection platform powered
by federated learning,” in <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">IAAI</em>, 2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
S. Hardy, W. Henecka, H. Ivey-Law, R. Nock, G. Patrini, G. Smith, and
B. Thorne, “Private federated learning on vertically partitioned data via
entity resolution and additively homomorphic encryption,” <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">CoRR,
arXiv:1711.10677</em>, 2017.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
C. Wu, F. Wu, R. Liu, L. Lyu, Y. Huang, and X. Xie, “Fedkd: Communication
efficient federated learning via knowledge distillation,” <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2108.13323</em>, 2021.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
C. Wu, F. Wu, L. Lyu, T. Di, Y. Huang, and X. Xie, “Fedctr: Federated native
ad ctr prediction with multi-platform user behavior data,” <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2007.12135</em>, 2020.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
J. Cui, C. Chen, L. Lyu, C. Yang, and W. Li, “Exploiting data sparsity in
secure cross-platform social recommendation,” <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Advances in Neural
Information Processing Systems</em>, vol. 34, 2021.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
J. Li, L. Lyu, X. Liu, X. Zhang, and X. Lv, “Fleam: A federated learning
empowered architecture to mitigate ddos in industrial iot,” <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Industrial Informatics</em>, 2021.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
C. Wu, F. Wu, Y. Cao, L. Lyu, Y. Huang, and X. Xie, “Fedgnn: Federated graph
neural network for privacy-preserving recommendation,” <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2102.04925</em>, 2021.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
J. Zhou, C. Chen, L. Zheng, X. Zheng, B. Wu, L. Lyu, Z. Liu, and L. Wang,
“Privacy-preserving graph neural network for node classification,”
<em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv e-prints</em>, pp. arXiv–2005, 2020.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
X. Ni, X. Xu, L. Lyu, C. Meng, and W. Wang, “A vertical federated learning
framework for graph convolutional network,” <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2106.11593</em>, 2021.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Q. Yang, Y. Liu, T. Chen, and Y. Tong, “Federated machine learning: Concept
and applications,” <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Intelligent Systems and
Technology (TIST)</em>, vol. 10, no. 2, pp. 1–19, 2019.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
M. Kantarcioglu and C. Clifton, “Privacy-preserving distributed mining of
association rules on horizontally partitioned data,” <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions
on Knowledge &amp; Data Engineering</em>, no. 9, pp. 1026–1037, 2004.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
J. Vaidya and C. Clifton, “Privacy preserving association rule mining in
vertically partitioned data,” in <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">KDD</em>, 2002, pp. 639–644.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
S. J. Pan and Q. Yang, “A survey on transfer learning,” <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on knowledge and data engineering</em>, vol. 22, no. 10, pp.
1345–1359, 2009.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Y. Liu, Y. Kang, C. Xing, T. Chen, and Q. Yang, “A secure federated transfer
learning framework,” <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">IEEE Intelligent Systems</em>, vol. 35, no. 4, pp.
70–82, 2020.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
P. Blanchard, R. Guerraoui, J. Stainer <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Machine learning with
adversaries: Byzantine tolerant gradient descent,” in <em id="bib.bib22.2.2" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2017,
pp. 119–129.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
D. Yin, Y. Chen, K. Ramchandran, and P. Bartlett, “Byzantine-robust
distributed learning: Towards optimal statistical rates,” <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">CoRR,
arXiv:1803.01498</em>, 2018.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
D. Gao, Y. Liu, A. Huang, C. Ju, H. Yu, and Q. Yang, “Privacy-preserving
heterogeneous federated transfer learning,” in <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">IEEE BigData</em>, 2019.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
D. Li and J. Wang, “Fedmd: Heterogenous federated learning via model
distillation,” <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1910.03581</em>, 2019.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
E. Jeong, S. Oh, H. Kim, J. Park, M. Bennis, and S.-L. Kim,
“Communication-efficient on-device machine learning: Federated distillation
and augmentation under non-iid private data,” <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1811.11479</em>, 2018.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
A. Bhowmick, J. Duchi, J. Freudiger, G. Kapoor, and R. Rogers, “Protection
against reconstruction and its applications in private federated learning,”
<em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">CoRR, arXiv:1812.00984</em>, 2018.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
L. Melis, C. Song, E. De Cristofaro, and V. Shmatikov, “Exploiting unintended
feature leakage in collaborative learning,” in <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">SP</em>, 2019, pp.
691–706.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
L. Zhu, Z. Liu, and S. Han, “Deep leakage from gradients,” in <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>,
2019, pp. 14 747–14 756.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
N. Agarwal, A. T. Suresh, F. X. X. Yu, S. Kumar, and B. McMahan, “cpsgd:
Communication-efficient and differentially-private distributed sgd,” in
<em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2018, pp. 7564–7575.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Y. Aono, T. Hayashi, L. Wang, S. Moriai <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Privacy-preserving
deep learning via additively homomorphic encryption,” <em id="bib.bib31.2.2" class="ltx_emph ltx_font_italic">IEEE
Transactions on Information Forensics and Security</em>, vol. 13, no. 5, pp.
1333–1345, 2018.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
B. Zhao, K. R. Mopuri, and H. Bilen, “idlg: Improved deep leakage from
gradients,” <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">CoRR, arXiv:2001.02610</em>, 2020.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
H. Wang, K. Sreenivasan, S. Rajput, H. Vishwakarma, S. Agarwal, J.-y. Sohn,
K. Lee, and D. Papailiopoulos, “Attack of the tails: Yes, you really can
backdoor federated learning,” <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2020.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
C. Xie, K. Huang, P. Chen, and B. Li, “DBA: distributed backdoor attacks
against federated learning,” in <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">8th International Conference on
Learning Representations</em>, 2020.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
E. Bagdasaryan, A. Veit, Y. Hua, D. Estrin, and V. Shmatikov, “How to backdoor
federated learning,” <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">CoRR, arXiv:1807.00459</em>, 2018.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
A. N. Bhagoji, S. Chakraborty, P. Mittal, and S. Calo, “Analyzing federated
learning through an adversarial lens,” <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">CoRR, arXiv:1811.12470</em>, 2018.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
C. Fung, C. J. Yoon, and I. Beschastnikh, “The limitations of federated
learning in sybil settings,” in <em id="bib.bib37.2.2" class="ltx_emph ltx_font_italic">23rd International Symposium on
Research in Attacks, Intrusions and Defenses (<math id="bib.bib37.1.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib37.1.1.m1.1a"><mo stretchy="false" id="bib.bib37.1.1.m1.1.1" xref="bib.bib37.1.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib37.1.1.m1.1b"><ci id="bib.bib37.1.1.m1.1.1.cmml" xref="bib.bib37.1.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib37.1.1.m1.1c">\{</annotation></semantics></math>RAID<math id="bib.bib37.2.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib37.2.2.m2.1a"><mo stretchy="false" id="bib.bib37.2.2.m2.1.1" xref="bib.bib37.2.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib37.2.2.m2.1b"><ci id="bib.bib37.2.2.m2.1.1.cmml" xref="bib.bib37.2.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib37.2.2.m2.1c">\}</annotation></semantics></math> 2020)</em>, 2020, pp.
301–316.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Z. Sun, P. Kairouz, A. T. Suresh, and H. B. McMahan, “Can you really backdoor
federated learning?” <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1911.07963</em>, 2019.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
J. Bernstein, J. Zhao, K. Azizzadenesheli, and A. Anandkumar, “signSGD with
majority vote is communication efficient and byzantine fault tolerant,” in
<em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">In Seventh International Conference on Learning Representations
(ICLR)</em>, 2019.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
S. Truex, N. Baracaldo, A. Anwar, T. Steinke, H. Ludwig, and R. Zhang, “A
hybrid approach to privacy-preserving federated learning,” <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">CoRR,
arXiv:1812.03224</em>, 2018.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
L. Lyu, Y. W. Law, K. S. Ng, S. Xue, J. Zhao, M. Yang, and L. Liu,
“Distributed privacy-preserving prediction,” in <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">International
Conference on Systems, Man, and Cybernetics</em>, 2020.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Y. Liu, Y. Xie, and A. Srivastava, “Neural trojans,” in <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">ICCD</em>, 2017,
pp. 45–48.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
B. G. Doan, E. Abbasnejad, and D. C. Ranasinghe, “Februus: Input purification
defense against trojan attacks on deep neural network systems,” in
<em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">arXiv: 1908.03369</em>, 2019.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
S. Udeshi, S. Peng, G. Woo, L. Loh, L. Rawshan, and S. Chattopadhyay, “Model
agnostic defence against backdoor attacks in machine learning,” <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:1908.02203</em>, 2019.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
M. Villarreal-Vasquez and B. Bhargava, “Confoc: Content-focus protection
against trojan attacks on neural networks,” <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2007.00711</em>, 2020.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Y. Li, T. Zhai, B. Wu, Y. Jiang, Z. Li, and S. Xia, “Rethinking the trigger of
backdoor attack,” <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2004.04692</em>, 2020.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
B. Tran, J. Li, and A. Madry, “Spectral signatures in backdoor attacks,” in
<em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2018, pp. 8000–8010.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
B. Chen, W. Carvalho, N. Baracaldo, H. Ludwig, B. Edwards, T. Lee, I. Molloy,
and B. Srivastava, “Detecting backdoor attacks on deep neural networks by
activation clustering,” <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">CoRR, arXiv:1811.03728</em>, 2018.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
D. Tang, X. Wang, H. Tang, and K. Zhang, “Demon in the variant: Statistical
analysis of dnns for robust backdoor contamination detection,”
<em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">USENIX</em>, 2021.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
E. Soremekun, S. Udeshi, S. Chattopadhyay, and A. Zeller, “Exposing backdoors
in robust machine learning models,” <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2003.00865</em>,
2020.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
A. Chan and Y.-S. Ong, “Poison as a cure: Detecting &amp; neutralizing
variable-sized backdoor attacks in deep neural networks,” <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:1911.08040</em>, 2019.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
E. Chou, F. Tramer, and G. Pellegrino, “Sentinet: Detecting localized
universal attack against deep learning systems,” <em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">IEEE SPW</em>, 2020.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Y. Liu, X. Ma, J. Bailey, and F. Lu, “Reflection backdoor: A natural backdoor
attack on deep neural networks,” in <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">ECCV</em>.   Springer, 2020, pp. 182–199.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Y. Li, X. Lyu, N. Koren, L. Lyu, B. Li, and X. Ma, “Neural attention
distillation: Erasing backdoor triggers from deep neural networks,”
<em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2101.05930</em>, 2021.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
——, “Anti-backdoor learning: Training clean models on poisoned data,”
<em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, vol. 34, 2021.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
G. Damaskinos, E. M. El Mhamdi, R. Guerraoui, A. H. A. Guirguis, and S. L. A.
Rouault, “Aggregathor: Byzantine machine learning via robust gradient
aggregation,” in <em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">SysML</em>, 2019.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Y. Chen, L. Su, and J. Xu, “Distributed statistical machine learning in
adversarial settings: Byzantine gradient descent,” <em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
ACM on Measurement and Analysis of Computing Systems</em>, vol. 1, no. 2, p. 44,
2017.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
K. Pillutla, S. M. Kakade, and Z. Harchaoui, “Robust aggregation for federated
learning,” <em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1912.13445</em>, 2019.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
M. S. Ozdayi, M. Kantarcioglu, and Y. R. Gel, “Defending against backdoors in
federated learning with robust learning rate,” <em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2007.03767</em>, 2020.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
T. Li, A. K. Sahu, A. Talwalkar, and V. Smith, “Federated learning:
Challenges, methods, and future directions,” <em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">CoRR, arXiv:1908.07873</em>,
2019.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
P. Kairouz, H. B. McMahan, B. Avent, A. Bellet, M. Bennis, A. N. Bhagoji,
K. Bonawitz, Z. Charles, G. Cormode, R. Cummings <em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Advances
and open problems in federated learning,” <em id="bib.bib61.2.2" class="ltx_emph ltx_font_italic">CoRR, arXiv:1912.04977</em>,
2019.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
B. Biggio, B. Nelson, and P. Laskov, “Support vector machines under
adversarial label noise,” in <em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">ACML</em>, 2011, pp. 97–112.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
C. Miao, Q. Li, H. Xiao, W. Jiang, M. Huai, and L. Su, “Towards data poisoning
attacks in crowd sensing systems,” in <em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Eighteenth
ACM International Symposium on Mobile Ad Hoc Networking and Computing</em>, 2018,
pp. 111–120.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
C. Miao, Q. Li, L. Su, M. Huai, W. Jiang, and J. Gao, “Attack under disguise:
An intelligent data poisoning attack mechanism in crowdsourcing,” in
<em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 World Wide Web Conference</em>, 2018, pp. 13–22.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
H. Zhang, T. Zheng, J. Gao, C. Miao, L. Su, Y. Li, and K. Ren, “Data poisoning
attack against knowledge graph embedding,” <em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1904.12052</em>, 2019.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
G. Sun, Y. Cong, J. Dong, Q. Wang, L. Lyu, and J. Liu, “Data poisoning attacks
on federated machine learning,” <em id="bib.bib66.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>,
2021.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
M. Fang, X. Cao, J. Jia, and N. Gong, “Local model poisoning attacks to
byzantine-robust federated learning,” in <em id="bib.bib67.4.4" class="ltx_emph ltx_font_italic">29th <math id="bib.bib67.1.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib67.1.1.m1.1a"><mo stretchy="false" id="bib.bib67.1.1.m1.1.1" xref="bib.bib67.1.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib67.1.1.m1.1b"><ci id="bib.bib67.1.1.m1.1.1.cmml" xref="bib.bib67.1.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib67.1.1.m1.1c">\{</annotation></semantics></math>USENIX<math id="bib.bib67.2.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib67.2.2.m2.1a"><mo stretchy="false" id="bib.bib67.2.2.m2.1.1" xref="bib.bib67.2.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib67.2.2.m2.1b"><ci id="bib.bib67.2.2.m2.1.1.cmml" xref="bib.bib67.2.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib67.2.2.m2.1c">\}</annotation></semantics></math> Security
Symposium (<math id="bib.bib67.3.3.m3.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib67.3.3.m3.1a"><mo stretchy="false" id="bib.bib67.3.3.m3.1.1" xref="bib.bib67.3.3.m3.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib67.3.3.m3.1b"><ci id="bib.bib67.3.3.m3.1.1.cmml" xref="bib.bib67.3.3.m3.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib67.3.3.m3.1c">\{</annotation></semantics></math>USENIX<math id="bib.bib67.4.4.m4.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib67.4.4.m4.1a"><mo stretchy="false" id="bib.bib67.4.4.m4.1.1" xref="bib.bib67.4.4.m4.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib67.4.4.m4.1b"><ci id="bib.bib67.4.4.m4.1.1.cmml" xref="bib.bib67.4.4.m4.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib67.4.4.m4.1c">\}</annotation></semantics></math> Security 20)</em>, 2020, pp. 1605–1622.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
M. Barreno, B. Nelson, R. Sears, A. D. Joseph, and J. D. Tygar, “Can machine
learning be secure?” in <em id="bib.bib68.1.1" class="ltx_emph ltx_font_italic">ICCS</em>, 2006, pp. 16–25.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
L. Lamport, R. Shostak, and M. Pease, “The byzantine generals problem,”
<em id="bib.bib69.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Programming Languages and Systems (TOPLAS)</em>,
vol. 4, no. 3, pp. 382–401, 1982.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
C. Xie, O. Koyejo, and I. Gupta, “Fall of empires: Breaking byzantine-tolerant
sgd by inner product manipulation,” in <em id="bib.bib70.1.1" class="ltx_emph ltx_font_italic">UAI</em>.   PMLR, 2020, pp. 261–270.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
L. T. Phong, Y. Aono, T. Hayashi, L. Wang, and S. Moriai, “Privacy-preserving
deep learning via additively homomorphic encryption,” <em id="bib.bib71.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Information Forensics and Security</em>, vol. 13, no. 5, pp.
1333–1345, 2018.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
L. Su and J. Xu, “Securing distributed machine learning in high dimensions,”
<em id="bib.bib72.1.1" class="ltx_emph ltx_font_italic">CoRR, arXiv:1804.10140</em>, 2018.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
M. Nasr, R. Shokri, and A. Houmansadr, “Comprehensive privacy analysis of deep
learning: Passive and active white-box inference attacks against centralized
and federated learning,” in <em id="bib.bib73.1.1" class="ltx_emph ltx_font_italic">SP</em>, 2019, pp. 739–753.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
C. Zhang, S. Bengio, M. Hardt, B. Recht, and O. Vinyals, “Understanding deep
learning requires rethinking generalization,” in <em id="bib.bib74.1.1" class="ltx_emph ltx_font_italic">ICLR</em>, 2017.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
L. Lyu, “Privacy-preserving machine learning and data aggregation for internet
of things,” Ph.D. dissertation, The University of Melbourne, 2018.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
B. Hitaj, G. Ateniese, and F. Pérez-Cruz, “Deep models under the gan:
information leakage from collaborative deep learning,” in <em id="bib.bib76.1.1" class="ltx_emph ltx_font_italic">CSS</em>, 2017,
pp. 603–618.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
M. Fredrikson, S. Jha, and T. Ristenpart, “Model inversion attacks that
exploit confidence information and basic countermeasures,” in <em id="bib.bib77.1.1" class="ltx_emph ltx_font_italic">CCS</em>,
2015, pp. 1322–1333.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
R. Shokri, M. Stronati, C. Song, and V. Shmatikov, “Membership inference
attacks against machine learning models,” in <em id="bib.bib78.1.1" class="ltx_emph ltx_font_italic">SP</em>, 2017, pp. 3–18.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
Y. Aono, T. Hayashi, L. Trieu Phong, and L. Wang, “Scalable and secure
logistic regression via homomorphic encryption,” in <em id="bib.bib79.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
Sixth ACM Conference on Data and Application Security and Privacy</em>, 2016, pp.
142–144.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
M. Kim, Y. Song, S. Wang, Y. Xia, and X. Jiang, “Secure logistic regression
based on homomorphic encryption: Design and evaluation,” <em id="bib.bib80.1.1" class="ltx_emph ltx_font_italic">JMIR medical
informatics</em>, vol. 6, no. 2, p. e19, 2018.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
R. C. Geyer, T. Klein, and M. Nabi, “Differentially private federated
learning: A client level perspective,” <em id="bib.bib81.1.1" class="ltx_emph ltx_font_italic">CoRR, arXiv:1712.07557</em>, 2017.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
T. T. Nguyên, X. Xiao, Y. Yang, S. C. Hui, H. Shin, and J. Shin,
“Collecting and analyzing data from smart device users with local
differential privacy,” <em id="bib.bib82.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1606.05053</em>, 2016.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
N. Wang, X. Xiao, Y. Yang, J. Zhao, S. C. Hui, H. Shin, J. Shin, and G. Yu,
“Collecting and analyzing multidimensional data with local differential
privacy,” in <em id="bib.bib83.1.1" class="ltx_emph ltx_font_italic">2019 IEEE 35th International Conference on Data
Engineering (ICDE)</em>.   IEEE, 2019, pp.
638–649.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
Y. Zhao, J. Zhao, M. Yang, T. Wang, N. Wang, L. Lyu, D. Niyato, and K. Y. Lam,
“Local differential privacy based federated learning for internet of
things,” <em id="bib.bib84.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2004.08856</em>, 2020.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock">
L. Sun, J. Qian, X. Chen, and P. S. Yu, “Ldp-fl: Practical private aggregation
in federated learning with local differential privacy,” <em id="bib.bib85.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2007.15789</em>, 2020.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock">
S. Truex, L. Liu, K.-H. Chow, M. E. Gursoy, and W. Wei, “Ldp-fed: federated
learning with local differential privacy,” in <em id="bib.bib86.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Third
ACM International Workshop on Edge Systems, Analytics and Networking</em>, 2020,
pp. 61–66.

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock">
L. Sun and L. Lyu, “Federated model distillation with noise-free differential
privacy,” <em id="bib.bib87.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2009.05537</em>, 2020.

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock">
L. Lyu, “Lightweight crypto-assisted distributed differential privacy for
privacy-preserving distributed learning,” in <em id="bib.bib88.1.1" class="ltx_emph ltx_font_italic">2020 International Joint
Conference on Neural Networks (IJCNN)</em>.   IEEE, 2020, pp. 1–8.

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock">
P. Mohassel and Y. Zhang, “Secureml: A system for scalable privacy-preserving
machine learning,” in <em id="bib.bib89.1.1" class="ltx_emph ltx_font_italic">SP</em>, 2017, pp. 19–38.

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock">
P. Paillier <em id="bib.bib90.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Public-key cryptosystems based on composite degree
residuosity classes,” in <em id="bib.bib90.2.2" class="ltx_emph ltx_font_italic">Eurocrypt</em>, vol. 99, 1999, pp. 223–238.

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock">
T. ElGamal, “A public key cryptosystem and a signature scheme based on
discrete logarithms,” <em id="bib.bib91.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Theory</em>,
vol. 31, no. 4, pp. 469–472, 1985.

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[92]</span>
<span class="ltx_bibblock">
C. Gentry, “Fully homomorphic encryption using ideal lattices,” in
<em id="bib.bib92.1.1" class="ltx_emph ltx_font_italic">STOC</em>, 2009, pp. 169–178.

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[93]</span>
<span class="ltx_bibblock">
A. C. Yao, “Protocols for secure computations,” in <em id="bib.bib93.1.1" class="ltx_emph ltx_font_italic">SFCS</em>, 1982, pp.
160–164.

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[94]</span>
<span class="ltx_bibblock">
D. Demmler, T. Schneider, and M. Zohner, “Aby-a framework for efficient
mixed-protocol secure two-party computation.” in <em id="bib.bib94.1.1" class="ltx_emph ltx_font_italic">NDSS</em>, 2015.

</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[95]</span>
<span class="ltx_bibblock">
C. Dwork, F. McSherry, K. Nissim, and A. Smith, “Calibrating noise to
sensitivity in private data analysis,” in <em id="bib.bib95.1.1" class="ltx_emph ltx_font_italic">Theory of cryptography
conference</em>, 2006, pp. 265–284.

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[96]</span>
<span class="ltx_bibblock">
C. Dwork and A. Roth, “The algorithmic foundations of differential privacy,”
<em id="bib.bib96.1.1" class="ltx_emph ltx_font_italic">Foundations and Trends® in Theoretical Computer
Science</em>, vol. 9, no. 3–4, pp. 211–407, 2014.

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[97]</span>
<span class="ltx_bibblock">
I. Damgård, V. Pastro, N. Smart, and S. Zakarias, “Multiparty computation
from somewhat homomorphic encryption,” in <em id="bib.bib97.1.1" class="ltx_emph ltx_font_italic">Annual Cryptology
Conference</em>, 2012, pp. 643–662.

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[98]</span>
<span class="ltx_bibblock">
R. L. Rivest, A. Shamir, and L. Adleman, “A method for obtaining digital
signatures and public-key cryptosystems,” <em id="bib.bib98.1.1" class="ltx_emph ltx_font_italic">Communications of the ACM</em>,
vol. 21, no. 2, pp. 120–126, 1978.

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[99]</span>
<span class="ltx_bibblock">
S. Goryczka and L. Xiong, “A comprehensive comparison of multiparty secure
additions with differential privacy,” <em id="bib.bib99.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on dependable
and secure computing</em>, vol. 14, no. 5, pp. 463–477, 2015.

</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[100]</span>
<span class="ltx_bibblock">
M. S. Riazi, C. Weinert, O. Tkachenko, E. M. Songhori, T. Schneider, and
F. Koushanfar, “Chameleon: A hybrid secure computation framework for machine
learning applications,” in <em id="bib.bib100.1.1" class="ltx_emph ltx_font_italic">CCS</em>, 2018, pp. 707–721.

</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[101]</span>
<span class="ltx_bibblock">
V. Rastogi and S. Nath, “Differentially private aggregation of distributed
time-series with transformation and encryption,” in <em id="bib.bib101.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
2010 ACM SIGMOD International Conference on Management of data</em>, 2010, pp.
735–746.

</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[102]</span>
<span class="ltx_bibblock">
E. Shi, H. Chan, E. Rieffel, R. Chow, and D. Song, “Privacy-preserving
aggregation of time-series data,” in <em id="bib.bib102.1.1" class="ltx_emph ltx_font_italic">Annual Network &amp; Distributed
System Security Symposium (NDSS)</em>, 2011.

</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[103]</span>
<span class="ltx_bibblock">
G. Ács and C. Castelluccia, “I have a dream!(differentially private smart
metering).” in <em id="bib.bib103.1.1" class="ltx_emph ltx_font_italic">Information hiding</em>, vol. 6958, 2011, pp. 118–132.

</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[104]</span>
<span class="ltx_bibblock">
L. Lyu, K. Nandakumar, B. Rubinstein, J. Jin, J. Bedo, and M. Palaniswami,
“PPFA: Privacy preserving fog-enabled aggregation in smart grid,”
<em id="bib.bib104.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Industrial Informatics</em>, vol. 14, no. 8, pp.
3733–3744, 2018.

</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[105]</span>
<span class="ltx_bibblock">
V. Chen, V. Pastro, and M. Raykova, “Secure computation for machine learning
with spdz,” <em id="bib.bib105.1.1" class="ltx_emph ltx_font_italic">CoRR, arXiv:1901.00329</em>, 2019.

</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[106]</span>
<span class="ltx_bibblock">
P. Mohassel and P. Rindal, “Aby 3: a mixed protocol framework for machine
learning,” in <em id="bib.bib106.1.1" class="ltx_emph ltx_font_italic">CCS</em>, 2018, pp. 35–52.

</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[107]</span>
<span class="ltx_bibblock">
J. Li, M. Khodak, S. Caldas, and A. Talwalkar, “Differentially private
meta-learning,” <em id="bib.bib107.1.1" class="ltx_emph ltx_font_italic">CoRR, arXiv:1909.05830</em>, 2019.

</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[108]</span>
<span class="ltx_bibblock">
N. Papernot, M. Abadi, U. Erlingsson, I. Goodfellow, and K. Talwar,
“Semi-supervised knowledge transfer for deep learning from private training
data,” in <em id="bib.bib108.1.1" class="ltx_emph ltx_font_italic">ICLR</em>, 2017.

</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[109]</span>
<span class="ltx_bibblock">
N. Papernot, S. Song, I. Mironov, A. Raghunathan, K. Talwar, and
Ú. Erlingsson, “Scalable private learning with pate,” <em id="bib.bib109.1.1" class="ltx_emph ltx_font_italic">CoRR,
arXiv:1802.08908</em>, 2018.

</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[110]</span>
<span class="ltx_bibblock">
L. Lyu, H. Yu, and Q. Yang, “Threats to federated learning: A survey,”
<em id="bib.bib110.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2003.02133</em>, 2020.

</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[111]</span>
<span class="ltx_bibblock">
J. C. Duchi, M. I. Jordan, and M. J. Wainwright, “Local privacy and
statistical minimax rates,” in <em id="bib.bib111.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 54th IEEE Annual
Symposium on Foundations of Computer Science</em>, 2013, pp. 429–438.

</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[112]</span>
<span class="ltx_bibblock">
C. Dwork, K. Kenthapadi, F. McSherry, I. Mironov, and M. Naor, “Our data,
ourselves: Privacy via distributed noise generation,” in <em id="bib.bib112.1.1" class="ltx_emph ltx_font_italic">Annual
International Conference on the Theory and Applications of Cryptographic
Techniques</em>, 2006, pp. 486–503.

</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[113]</span>
<span class="ltx_bibblock">
L. Lyu, X. He, and Y. Li, “Differentially private representation for nlp:
Formal guarantee and an empirical study on privacy and fairness,”
<em id="bib.bib113.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.01285</em>, 2020.

</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[114]</span>
<span class="ltx_bibblock">
M. Yang, L. Lyu, J. Zhao, T. Zhu, and K.-Y. Lam, “Local differential privacy
and its applications: A comprehensive survey,” <em id="bib.bib114.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2008.03686</em>, 2020.

</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[115]</span>
<span class="ltx_bibblock">
S. L. Warner, “Randomized response: A survey technique for eliminating evasive
answer bias,” <em id="bib.bib115.1.1" class="ltx_emph ltx_font_italic">Journal of the American Statistical Association</em>,
vol. 60, no. 309, pp. 63–69, 1965.

</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[116]</span>
<span class="ltx_bibblock">
Ú. Erlingsson, V. Pihur, and A. Korolova, “Rappor: Randomized aggregatable
privacy-preserving ordinal response,” in <em id="bib.bib116.1.1" class="ltx_emph ltx_font_italic">CCS</em>, 2014, pp. 1054–1067.

</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[117]</span>
<span class="ltx_bibblock">
T. H. Chan, E. Shi, and D. Song, “Optimal lower bound for differentially
private multi-party aggregation,” in <em id="bib.bib117.1.1" class="ltx_emph ltx_font_italic">European Symposium on
Algorithms</em>, 2012, pp. 277–288.

</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[118]</span>
<span class="ltx_bibblock">
T. Chan, K.-M. Chung, B. M. Maggs, and E. Shi, “Foundations of differentially
oblivious algorithms,” in <em id="bib.bib118.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 30th Annual ACM-SIAM
Symposium on Discrete Algorithms</em>, 2019, pp. 2448–2467.

</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[119]</span>
<span class="ltx_bibblock">
R. Shokri and V. Shmatikov, “Privacy-preserving deep learning,” in
<em id="bib.bib119.1.1" class="ltx_emph ltx_font_italic">CCS</em>, 2015, pp. 1310–1321.

</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[120]</span>
<span class="ltx_bibblock">
J. Hamm, Y. Cao, and M. Belkin, “Learning privately from multiparty data,” in
<em id="bib.bib120.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, 2016, pp. 555–563.

</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[121]</span>
<span class="ltx_bibblock">
L. Lyu and C.-H. Chen, “Differentially private knowledge distillation for
mobile analytics,” in <em id="bib.bib121.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 43rd International ACM SIGIR
Conference on Research and Development in Information Retrieval</em>, 2020, pp.
1809–1812.

</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[122]</span>
<span class="ltx_bibblock">
K. Chaudhuri, C. Monteleoni, and A. D. Sarwate, “Differentially private
empirical risk minimization,” <em id="bib.bib122.1.1" class="ltx_emph ltx_font_italic">Journal of Machine Learning Research</em>,
vol. 12, no. Mar, pp. 1069–1109, 2011.

</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[123]</span>
<span class="ltx_bibblock">
B. I. P. Rubinstein, B. Nelson, L. Huang, A. D. Joseph, S. Lau, S. Rao,
N. Taft, and J. D. Tygar, “ANTIDOTE: understanding and defending against
poisoning of anomaly detectors,” in <em id="bib.bib123.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 9th ACM
SIGCOMM Internet Measurement Conference</em>.   ACM, 2009, pp. 1–14.

</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[124]</span>
<span class="ltx_bibblock">
B. Biggio, B. Nelson, and P. Laskov, “Poisoning attacks against support vector
machines,” <em id="bib.bib124.1.1" class="ltx_emph ltx_font_italic">CoRR, arXiv:1206.6389</em>, 2012.

</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[125]</span>
<span class="ltx_bibblock">
M. Jagielski, A. Oprea, B. Biggio, C. Liu, C. Nita-Rotaru, and B. Li,
“Manipulating machine learning: Poisoning attacks and countermeasures for
regression learning,” in <em id="bib.bib125.1.1" class="ltx_emph ltx_font_italic">SP</em>, 2018, pp. 19–35.

</span>
</li>
<li id="bib.bib126" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[126]</span>
<span class="ltx_bibblock">
B. Nelson, M. Barreno, F. J. Chi, A. D. Joseph, B. I. Rubinstein, U. Saini,
C. A. Sutton, J. D. Tygar, and K. Xia, “Exploiting machine learning to
subvert your spam filter.” <em id="bib.bib126.1.1" class="ltx_emph ltx_font_italic">LEET</em>, vol. 8, pp. 1–9, 2008.

</span>
</li>
<li id="bib.bib127" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[127]</span>
<span class="ltx_bibblock">
L. Huang, A. D. Joseph, B. Nelson, B. I. Rubinstein, and J. D. Tygar,
“Adversarial machine learning,” in <em id="bib.bib127.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 4th ACM
workshop on Security and Artificial Intelligence</em>, 2011, pp. 43–58.

</span>
</li>
<li id="bib.bib128" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[128]</span>
<span class="ltx_bibblock">
X. Chen, C. Liu, B. Li, K. Lu, and D. Song, “Targeted backdoor attacks on deep
learning systems using data poisoning,” <em id="bib.bib128.1.1" class="ltx_emph ltx_font_italic">CoRR, arXiv:1712.05526</em>, 2017.

</span>
</li>
<li id="bib.bib129" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[129]</span>
<span class="ltx_bibblock">
T. Gu, B. Dolan-Gavitt, and S. Garg, “Badnets: Identifying vulnerabilities in
the machine learning model supply chain,” <em id="bib.bib129.1.1" class="ltx_emph ltx_font_italic">CoRR, arXiv:1708.06733</em>,
2017.

</span>
</li>
<li id="bib.bib130" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[130]</span>
<span class="ltx_bibblock">
A. Shafahi, W. R. Huang, M. Najibi, O. Suciu, C. Studer, T. Dumitras, and
T. Goldstein, “Poison frogs! targeted clean-label poisoning attacks on
neural networks,” in <em id="bib.bib130.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2018, pp. 6103–6113.

</span>
</li>
<li id="bib.bib131" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[131]</span>
<span class="ltx_bibblock">
Y. Liu, S. Ma, Y. Aafer, W.-C. Lee, J. Zhai, W. Wang, and X. Zhang, “Trojaning
attack on neural networks,” in <em id="bib.bib131.1.1" class="ltx_emph ltx_font_italic">NDSS</em>, 2018.

</span>
</li>
<li id="bib.bib132" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[132]</span>
<span class="ltx_bibblock">
C. Chen, J. Zhang, A. K. Tung, M. Kankanhalli, and G. Chen, “Robust federated
recommendation system,” <em id="bib.bib132.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2006.08259</em>, 2020.

</span>
</li>
<li id="bib.bib133" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[133]</span>
<span class="ltx_bibblock">
G. Baruch, M. Baruch, and Y. Goldberg, “A little is enough: Circumventing
defenses for distributed learning,” in <em id="bib.bib133.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information
Processing Systems</em>, 2019, pp. 8632–8642.

</span>
</li>
<li id="bib.bib134" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[134]</span>
<span class="ltx_bibblock">
T. A. Nguyen and A. Tran, “Input-aware dynamic backdoor attack,”
<em id="bib.bib134.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, vol. 33, pp.
3454–3464, 2020.

</span>
</li>
<li id="bib.bib135" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[135]</span>
<span class="ltx_bibblock">
L. Muñoz-González, B. Biggio, A. Demontis, A. Paudice, V. Wongrassamee,
E. C. Lupu, and F. Roli, “Towards poisoning of deep learning algorithms with
back-gradient optimization,” in <em id="bib.bib135.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 10th ACM Workshop
on Artificial Intelligence and Security</em>, 2017, pp. 27–38.

</span>
</li>
<li id="bib.bib136" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[136]</span>
<span class="ltx_bibblock">
P. W. Koh and P. Liang, “Understanding black-box predictions via influence
functions,” in <em id="bib.bib136.1.1" class="ltx_emph ltx_font_italic">ICML</em>, 2017, pp. 1885–1894.

</span>
</li>
<li id="bib.bib137" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[137]</span>
<span class="ltx_bibblock">
S. Zhao, X. Ma, X. Zheng, J. Bailey, J. Chen, and Y.-G. Jiang, “Clean-label
backdoor attacks on video recognition models,” in <em id="bib.bib137.1.1" class="ltx_emph ltx_font_italic">CVPR</em>, 2020, pp.
14 443–14 452.

</span>
</li>
<li id="bib.bib138" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[138]</span>
<span class="ltx_bibblock">
J. R. Douceur, “The sybil attack,” in <em id="bib.bib138.1.1" class="ltx_emph ltx_font_italic">International Workshop on
Peer-to-Peer Systems</em>, 2002, pp. 251–260.

</span>
</li>
<li id="bib.bib139" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[139]</span>
<span class="ltx_bibblock">
S. Shen, S. Tople, and P. Saxena, “Auror: defending against poisoning attacks
in collaborative deep learning systems,” in <em id="bib.bib139.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 32nd
Annual Conference on Computer Security Applications</em>.   ACM, 2016, pp. 508–519.

</span>
</li>
<li id="bib.bib140" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[140]</span>
<span class="ltx_bibblock">
E. M. E. Mhamdi, R. Guerraoui, and S. Rouault, “The hidden vulnerability of
distributed learning in byzantium,” <em id="bib.bib140.1.1" class="ltx_emph ltx_font_italic">CoRR, arXiv:1802.07927</em>, 2018.

</span>
</li>
<li id="bib.bib141" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[141]</span>
<span class="ltx_bibblock">
V. Shejwalkar, A. Houmansadr, P. Kairouz, and D. Ramage, “Back to the drawing
board: A critical evaluation of poisoning attacks on federated learning,”
<em id="bib.bib141.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2108.10241</em>, 2021.

</span>
</li>
<li id="bib.bib142" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[142]</span>
<span class="ltx_bibblock">
C. Wu, X. Yang, S. Zhu, and P. Mitra, “Mitigating backdoor attacks in
federated learning,” <em id="bib.bib142.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2011.01767</em>, 2020.

</span>
</li>
<li id="bib.bib143" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[143]</span>
<span class="ltx_bibblock">
C. Xie, M. Chen, P.-Y. Chen, and B. Li, “Crfl: Certifiably robust federated
learning against backdoor attacks,” <em id="bib.bib143.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2106.08283</em>,
2021.

</span>
</li>
<li id="bib.bib144" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[144]</span>
<span class="ltx_bibblock">
B. Han, I. W. Tsang, and L. Chen, “On the convergence of a family of robust
losses for stochastic gradient descent,” in <em id="bib.bib144.1.1" class="ltx_emph ltx_font_italic">Machine Learning and
Knowledge Discovery in Databases - European Conference, ECML PKDD</em>, 2016,
pp. 665–680.

</span>
</li>
<li id="bib.bib145" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[145]</span>
<span class="ltx_bibblock">
L. Chen, H. Wang, Z. Charles, and D. Papailiopoulos, “Draco:
Byzantine-resilient distributed training via redundant gradients,”
<em id="bib.bib145.1.1" class="ltx_emph ltx_font_italic">CoRR, arXiv:1803.09877</em>, 2018.

</span>
</li>
<li id="bib.bib146" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[146]</span>
<span class="ltx_bibblock">
C. Xie, O. Koyejo, and I. Gupta, “Generalized byzantine-tolerant sgd,”
<em id="bib.bib146.1.1" class="ltx_emph ltx_font_italic">CoRR, arXiv:1802.10116</em>, 2018.

</span>
</li>
<li id="bib.bib147" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[147]</span>
<span class="ltx_bibblock">
D. Alistarh, Z. Allen-Zhu, and J. Li, “Byzantine stochastic gradient
descent,” in <em id="bib.bib147.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 2018,
pp. 4613–4623.

</span>
</li>
<li id="bib.bib148" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[148]</span>
<span class="ltx_bibblock">
X. Xu and L. Lyu, “Towards building a robust and fair federated learning
system,” <em id="bib.bib148.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2011.10464</em>, 2020.

</span>
</li>
<li id="bib.bib149" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[149]</span>
<span class="ltx_bibblock">
J. Steinhardt, M. Charikar, and G. Valiant, “Resilience: A criterion for
learning in the presence of arbitrary outliers,” <em id="bib.bib149.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1703.04940</em>, 2017.

</span>
</li>
<li id="bib.bib150" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[150]</span>
<span class="ltx_bibblock">
Y. Li, B. Wu, Y. Jiang, Z. Li, and S.-T. Xia, “Backdoor learning: A survey,”
<em id="bib.bib150.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.08745</em>, 2020.

</span>
</li>
<li id="bib.bib151" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[151]</span>
<span class="ltx_bibblock">
B. Wang, Y. Yao, S. Shan, H. Li, B. Viswanath, H. Zheng, and B. Y. Zhao,
“Neural cleanse: Identifying and mitigating backdoor attacks in neural
networks,” in <em id="bib.bib151.1.1" class="ltx_emph ltx_font_italic">2019 IEEE Symposium on Security and Privacy (SP)</em>.   IEEE, 2019, pp. 707–723.

</span>
</li>
<li id="bib.bib152" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[152]</span>
<span class="ltx_bibblock">
H. Chen, C. Fu, J. Zhao, and F. Koushanfar, “Deepinspect: A black-box trojan
detection and mitigation framework for deep neural networks.” in
<em id="bib.bib152.1.1" class="ltx_emph ltx_font_italic">IJCAI</em>, 2019, pp. 4658–4664.

</span>
</li>
<li id="bib.bib153" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[153]</span>
<span class="ltx_bibblock">
K. Liu, B. Dolan-Gavitt, and S. Garg, “Fine-pruning: Defending against
backdooring attacks on deep neural networks,” in <em id="bib.bib153.1.1" class="ltx_emph ltx_font_italic">International
Symposium on Research in Attacks, Intrusions, and Defenses</em>, 2018, pp.
273–294.

</span>
</li>
<li id="bib.bib154" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[154]</span>
<span class="ltx_bibblock">
T. J. L. Tan and R. Shokri, “Bypassing backdoor detection algorithms in deep
learning,” <em id="bib.bib154.1.1" class="ltx_emph ltx_font_italic">CoRR, arXiv:1905.13409</em>, 2019.

</span>
</li>
<li id="bib.bib155" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[155]</span>
<span class="ltx_bibblock">
P. Zhao, P.-Y. Chen, P. Das, K. N. Ramamurthy, and X. Lin, “Bridging mode
connectivity in loss landscapes and adversarial robustness,” <em id="bib.bib155.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2005.00060</em>, 2020.

</span>
</li>
<li id="bib.bib156" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[156]</span>
<span class="ltx_bibblock">
Y. Yao, H. Li, H. Zheng, and B. Y. Zhao, “Latent backdoor attacks on deep
neural networks,” in <em id="bib.bib156.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 ACM SIGSAC Conference on
Computer and Communications Security</em>, 2019, pp. 2041–2055.

</span>
</li>
<li id="bib.bib157" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[157]</span>
<span class="ltx_bibblock">
S. Andreina, G. A. Marson, H. Möllering, and G. Karame, “Baffle: Backdoor
detection via feedback-based federated learning,” in <em id="bib.bib157.1.1" class="ltx_emph ltx_font_italic">2021 IEEE 41st
International Conference on Distributed Computing Systems (ICDCS)</em>.   IEEE, 2021, pp. 852–863.

</span>
</li>
<li id="bib.bib158" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[158]</span>
<span class="ltx_bibblock">
H. Chang, V. Shejwalkar, R. Shokri, and A. Houmansadr, “Cronus: Robust and
heterogeneous collaborative learning with black-box knowledge transfer,”
<em id="bib.bib158.1.1" class="ltx_emph ltx_font_italic">CoRR, arXiv:1912.11279</em>, 2019.

</span>
</li>
<li id="bib.bib159" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[159]</span>
<span class="ltx_bibblock">
O. Thakkar, G. Andrew, and H. B. McMahan, “Differentially private learning
with adaptive clipping,” <em id="bib.bib159.1.1" class="ltx_emph ltx_font_italic">CoRR, arXiv:1905.03871</em>, 2019.

</span>
</li>
<li id="bib.bib160" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[160]</span>
<span class="ltx_bibblock">
J. Bernstein, J. Zhao, K. Azizzadenesheli, and A. Anandkumar, “signsgd with
majority vote is communication efficient and fault tolerant,” <em id="bib.bib160.1.1" class="ltx_emph ltx_font_italic">CoRR,
arXiv:1810.05291</em>, 2018.

</span>
</li>
<li id="bib.bib161" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[161]</span>
<span class="ltx_bibblock">
L. Lyu and C. Chen, “A novel attribute reconstruction attack in federated
learning,” <em id="bib.bib161.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2108.06910</em>, 2021.

</span>
</li>
<li id="bib.bib162" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[162]</span>
<span class="ltx_bibblock">
A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu, “Towards deep
learning models resistant to adversarial attacks,” in <em id="bib.bib162.1.1" class="ltx_emph ltx_font_italic">ICLR</em>, 2018.

</span>
</li>
<li id="bib.bib163" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[163]</span>
<span class="ltx_bibblock">
Y. Wang, X. Ma, J. Bailey, J. Yi, B. Zhou, and Q. Gu, “On the convergence and
robustness of adversarial training.” in <em id="bib.bib163.1.1" class="ltx_emph ltx_font_italic">ICML</em>, vol. 1, 2019, p. 2.

</span>
</li>
<li id="bib.bib164" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[164]</span>
<span class="ltx_bibblock">
Y. Wang, D. Zou, J. Yi, J. Bailey, X. Ma, and Q. Gu, “Improving adversarial
robustness requires revisiting misclassified examples,” in <em id="bib.bib164.1.1" class="ltx_emph ltx_font_italic">ICLR</em>,
2019.

</span>
</li>
<li id="bib.bib165" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[165]</span>
<span class="ltx_bibblock">
D. Tsipras, S. Santurkar, L. Engstrom, A. Turner, and A. Madry, “Robustness
may be at odds with accuracy,” in <em id="bib.bib165.1.1" class="ltx_emph ltx_font_italic">ICLR</em>, 2019.

</span>
</li>
<li id="bib.bib166" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[166]</span>
<span class="ltx_bibblock">
L. Lyu, J. C. Bezdek, X. He, and J. Jin, “Fog-embedded deep learning for the
internet of things,” <em id="bib.bib166.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Industrial Informatics</em>,
vol. 15, no. 7, pp. 4206–4215, 2019.

</span>
</li>
<li id="bib.bib167" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[167]</span>
<span class="ltx_bibblock">
L. Lyu, J. Yu, K. Nandakumar, Y. Li, X. Ma, J. Jin, H. Yu, and K. S. Ng,
“Towards fair and privacy-preserving federated deep models,” <em id="bib.bib167.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Parallel and Distributed Systems</em>, vol. 31, no. 11, pp.
2524–2541, 2020.

</span>
</li>
<li id="bib.bib168" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[168]</span>
<span class="ltx_bibblock">
L. Lyu, Y. Li, K. Nandakumar, J. Yu, and X. Ma, “How to democratise and
protect ai: Fair and differentially private decentralised deep learning,”
<em id="bib.bib168.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Dependable and Secure Computing</em>, 2020.

</span>
</li>
<li id="bib.bib169" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[169]</span>
<span class="ltx_bibblock">
L. Lyu, J. C. Bezdek, J. Jin, and Y. Yang, “Foreseen: Towards differentially
private deep inference for intelligent internet of things,” <em id="bib.bib169.1.1" class="ltx_emph ltx_font_italic">IEEE
Journal on Selected Areas in Communications</em>, 2020.

</span>
</li>
<li id="bib.bib170" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[170]</span>
<span class="ltx_bibblock">
X. Pan, M. Zhang, S. Ji, and M. Yang, “Privacy risks of general-purpose
language models,” in <em id="bib.bib170.1.1" class="ltx_emph ltx_font_italic">2020 IEEE Symposium on Security and Privacy
(SP)</em>.   IEEE, 2020, pp. 1314–1331.

</span>
</li>
<li id="bib.bib171" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[171]</span>
<span class="ltx_bibblock">
F. Tramèr, F. Zhang, A. Juels, M. K. Reiter, and T. Ristenpart, “Stealing
machine learning models via prediction apis.” in <em id="bib.bib171.1.1" class="ltx_emph ltx_font_italic">USENIX Security
Symposium</em>, 2016, pp. 601–618.

</span>
</li>
<li id="bib.bib172" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[172]</span>
<span class="ltx_bibblock">
X. He, L. Lyu, L. Sun, and Q. Xu, “Model extraction and adversarial
transferability, your bert is vulnerable!” in <em id="bib.bib172.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021
Conference of the North American Chapter of the Association for Computational
Linguistics: Human Language Technologies</em>, 2021, pp. 2006–2012.

</span>
</li>
<li id="bib.bib173" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[173]</span>
<span class="ltx_bibblock">
Q. Xu, X. He, L. Lyu, L. Qu, and G. Haffari, “Beyond model extraction:
Imitation attack for black-box nlp apis,” <em id="bib.bib173.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2108.13873</em>, 2021.

</span>
</li>
<li id="bib.bib174" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[174]</span>
<span class="ltx_bibblock">
C. Chen, X. He, L. Lyu, and F. Wu, “Killing one bird with two stone: Stealing
model and inferring attribute from bert-based apis,” <em id="bib.bib174.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2105.10909</em>, 2021.

</span>
</li>
<li id="bib.bib175" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[175]</span>
<span class="ltx_bibblock">
G. Zizzo, A. Rawat, M. Sinn, and B. Buesser, “Fat: Federated adversarial
training,” <em id="bib.bib175.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.01791</em>, 2020.

</span>
</li>
<li id="bib.bib176" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[176]</span>
<span class="ltx_bibblock">
J. Hong, H. Wang, Z. Wang, and J. Zhou, “Federated robustness propagation:
Sharing adversarial robustness in federated learning,” <em id="bib.bib176.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2106.10196</em>, 2021.

</span>
</li>
<li id="bib.bib177" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[177]</span>
<span class="ltx_bibblock">
D. Shah, P. Dube, S. Chakraborty, and A. Verma, “Adversarial training in
communication constrained federated learning,” <em id="bib.bib177.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2103.01319</em>, 2021.

</span>
</li>
<li id="bib.bib178" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[178]</span>
<span class="ltx_bibblock">
X. He, Q. Xu, L. Lyu, F. Wu, and C. Wang, “Protecting intellectual property of
language generation apis with lexical watermark,” in <em id="bib.bib178.1.1" class="ltx_emph ltx_font_italic">AAAI</em>, 2022.

</span>
</li>
<li id="bib.bib179" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[179]</span>
<span class="ltx_bibblock">
N. Truong, K. Sun, S. Wang, F. Guitton, and Y. Guo, “Privacy preservation in
federated learning: An insightful survey from the gdpr perspective,”
<em id="bib.bib179.1.1" class="ltx_emph ltx_font_italic">Computers &amp; Security</em>, vol. 110, p. 102402, 2021.

</span>
</li>
<li id="bib.bib180" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[180]</span>
<span class="ltx_bibblock">
K. Cheng, T. Fan, Y. Jin, Y. Liu, T. Chen, D. Papadopoulos, and Q. Yang,
“Secureboost: A lossless federated learning framework,” <em id="bib.bib180.1.1" class="ltx_emph ltx_font_italic">IEEE
Intelligent Systems</em>, 2021.

</span>
</li>
<li id="bib.bib181" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[181]</span>
<span class="ltx_bibblock">
Z. Tian, R. Zhang, X. Hou, J. Liu, and K. Ren, “Federboost: Private federated
learning for gbdt,” <em id="bib.bib181.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2011.02796</em>, 2020.

</span>
</li>
<li id="bib.bib182" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[182]</span>
<span class="ltx_bibblock">
X. Jin, P.-Y. Chen, C.-Y. Hsu, C.-M. Yu, and T. Chen, “Catastrophic data
leakage in vertical federated learning,” <em id="bib.bib182.1.1" class="ltx_emph ltx_font_italic">Advances in Neural
Information Processing Systems</em>, vol. 34, 2021.

</span>
</li>
<li id="bib.bib183" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[183]</span>
<span class="ltx_bibblock">
D. Gao, Y. Liu, A. Huang, C. Ju, H. Yu, and Q. Yang, “Privacy-preserving
heterogeneous federated transfer learning,” in <em id="bib.bib183.1.1" class="ltx_emph ltx_font_italic">2019 IEEE International
Conference on Big Data (Big Data)</em>.   IEEE, 2019, pp. 2552–2559.

</span>
</li>
<li id="bib.bib184" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[184]</span>
<span class="ltx_bibblock">
X. Xinyi, L. Lyu, X. Ma, C. Miao, C.-S. Foo, and B. K. H. Low, “Gradient
driven rewards to guarantee fairness in collaborative machine learning,” in
<em id="bib.bib184.1.1" class="ltx_emph ltx_font_italic">Thirty-Fifth Conference on Neural Information Processing Systems</em>,
2021.

</span>
</li>
<li id="bib.bib185" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[185]</span>
<span class="ltx_bibblock">
X. X. Lingjuan Lyu and Q. Wang, “Collaborative fairness in federated
learning,” <em id="bib.bib185.1.1" class="ltx_emph ltx_font_italic">https://arxiv.org/abs/2008.12161v1</em>, 2020.

</span>
</li>
<li id="bib.bib186" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[186]</span>
<span class="ltx_bibblock">
Q. Yang, L. Fan, and H. Yu, Eds., <em id="bib.bib186.1.1" class="ltx_emph ltx_font_italic">Federated Learning: Privacy and
Incentive</em>.   Springer International
Publishing, 2020.

</span>
</li>
<li id="bib.bib187" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[187]</span>
<span class="ltx_bibblock">
S. Warnat-Herresthal, H. Schultze, K. L. Shastry, S. Manamohan, S. Mukherjee,
V. Garg, R. Sarveswara, K. Händler, P. Pickkers, N. A. Aziz
<em id="bib.bib187.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Swarm learning for decentralized and confidential clinical
machine learning,” <em id="bib.bib187.2.2" class="ltx_emph ltx_font_italic">Nature</em>, vol. 594, no. 7862, pp. 265–270, 2021.

</span>
</li>
<li id="bib.bib188" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[188]</span>
<span class="ltx_bibblock">
N. Guha, A. Talwalkar, and V. Smith, “One-shot federated learning,”
<em id="bib.bib188.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1902.11175</em>, 2019.

</span>
</li>
<li id="bib.bib189" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[189]</span>
<span class="ltx_bibblock">
Q. Li, B. He, and D. Song, “Practical one-shot federated learning for
cross-silo setting,” <em id="bib.bib189.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.01017</em>, 2020.

</span>
</li>
<li id="bib.bib190" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[190]</span>
<span class="ltx_bibblock">
D. K. Dennis, T. Li, and V. Smith, “Heterogeneity for the win: One-shot
federated clustering,” 2021.

</span>
</li>
<li id="bib.bib191" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[191]</span>
<span class="ltx_bibblock">
J. Zhang, C. Chen, B. Li, L. Lyu, S. Wu, J. Xu, S. Ding, and C. Wu, “A
practical data-free approach to one-shot federated learning with
heterogeneity,” <em id="bib.bib191.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2112.12371</em>, 2021.

</span>
</li>
<li id="bib.bib192" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[192]</span>
<span class="ltx_bibblock">
X. Xu and L. Lyu, “A reputation mechanism is all you need: Collaborative
fairness and adversarial robustness in federated learning,” in <em id="bib.bib192.1.1" class="ltx_emph ltx_font_italic">Proc.
ICML Workshop on Federated Learning for User Privacy and Data
Confidentiality</em>, 2021.

</span>
</li>
<li id="bib.bib193" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[193]</span>
<span class="ltx_bibblock">
M. Barreno, B. Nelson, A. D. Joseph, and J. D. Tygar, “The security of machine
learning,” <em id="bib.bib193.1.1" class="ltx_emph ltx_font_italic">Machine Learning</em>, vol. 81, no. 2, pp. 121–148, 2010.

</span>
</li>
<li id="bib.bib194" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[194]</span>
<span class="ltx_bibblock">
J. Steinhardt, P. W. W. Koh, and P. S. Liang, “Certified defenses for data
poisoning attacks,” in <em id="bib.bib194.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2017, pp. 3517–3529.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2012.06336" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2012.06337" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2012.06337">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2012.06337" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2012.06338" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Mar  7 02:58:22 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
