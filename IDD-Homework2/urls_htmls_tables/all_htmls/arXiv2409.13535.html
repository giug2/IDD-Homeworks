<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Formula-Supervised Visual-Geometric Pre-training</title>
<!--Generated on Fri Sep 20 14:19:04 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Visual-Geometric representation Synthetic pre-training" lang="en" name="keywords"/>
<base href="/html/2409.13535v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S1" title="In Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S2" title="In Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S3" title="In Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Formula-supervised visual-geometric pre-training</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S3.SS1" title="In 3 Formula-supervised visual-geometric pre-training â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Visual-geometric fractal database (VG-FractalDB)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S3.SS2" title="In 3 Formula-supervised visual-geometric pre-training â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>VG-FractalDB Pre-training on a unified transformer model</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4" title="In Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.SS1" title="In 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Experimental setting</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.SS2" title="In 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>FSVGP effects on image and 3D object recognition</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.SS3" title="In 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Comparative analysis in image recognition</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.SS4" title="In 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Comparative analysis in geometric recognition</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.SS5" title="In 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.5 </span>Ablation study</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S5" title="In Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Discussion and Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S6" title="In Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Acknowledgments</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#Pt0.A1" title="In Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>FSVGP details</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#Pt0.A1.SS1" title="In Appendix A FSVGP details â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>VG-FractalDB construction details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#Pt0.A1.SS2" title="In Appendix A FSVGP details â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Pre-training transformer model details</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#Pt0.A2" title="In Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Experimental setting details</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#Pt0.A2.SS1" title="In Appendix B Experimental setting details â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.1 </span>Pre-training</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#Pt0.A2.SS2" title="In Appendix B Experimental setting details â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.2 </span>Image recognition</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#Pt0.A2.SS3" title="In Appendix B Experimental setting details â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.3 </span>3D object recognition</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#Pt0.A2.SS4" title="In Appendix B Experimental setting details â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.4 </span>Ablation study</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#Pt0.A3" title="In Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Additional experiments</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#Pt0.A3.SS1" title="In Appendix C Additional experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.1 </span>What is the pre-training effect of collapsing the pair labels in VG-FractalDB?</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#Pt0.A3.SS2" title="In Appendix C Additional experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.2 </span>Does the standard cross-entropy loss function alone suffice for pre-training in FSVGP?</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#Pt0.A3.SS3" title="In Appendix C Additional experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.3 </span>Evaluation of the performance of pre-training models by linear probing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#Pt0.A3.SS4" title="In Appendix C Additional experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.4 </span>Multi-modal evaluations in 3D object classification</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#Pt0.A4" title="In Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Qualitative examples</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span class="ltx_note ltx_role_institutetext" id="id1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>
1 AIST, â€ƒ2 University of Tsukuba, â€ƒ3 Tokyo Institute of Technology 
<br class="ltx_break"/>equal contribution 
<br class="ltx_break"/>
Project Page: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ryosuke-yamada.github.io/fdsl-fsvgp/" title="">https://ryosuke-yamada.github.io/fdsl-fsvgp/</a>
</span></span></span>
<h1 class="ltx_title ltx_title_document">Formula-Supervised 
<br class="ltx_break"/>Visual-Geometric Pre-training</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ryosuke Yamada*<span class="ltx_ERROR undefined" id="id1.1.id1">\orcidlink</span>0000-0002-2154-8230
</span><span class="ltx_author_notes">1122</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Kensho Hara*<span class="ltx_ERROR undefined" id="id2.1.id1">\orcidlink</span>0000-0001-6463-7738
</span><span class="ltx_author_notes">11</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<br class="ltx_break"/>Hirokatsu Kataoka<span class="ltx_ERROR undefined" id="id3.1.id1">\orcidlink</span>0000-0001-8844-165X
</span><span class="ltx_author_notes">11</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Koshi Makihara<span class="ltx_ERROR undefined" id="id4.1.id1">\orcidlink</span>0000-0003-4145-7595
</span><span class="ltx_author_notes">11</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Nakamasa Inoue<span class="ltx_ERROR undefined" id="id5.1.id1">\orcidlink</span>0000-0002-9761-4142
</span><span class="ltx_author_notes">1133</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<br class="ltx_break"/>Rio Yokota<span class="ltx_ERROR undefined" id="id6.1.id1">\orcidlink</span>0000-0001-7573-7873
</span><span class="ltx_author_notes">1133</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yutaka Satoh<span class="ltx_ERROR undefined" id="id7.1.id1">\orcidlink</span>0000-0002-0638-0855
</span><span class="ltx_author_notes">1122</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id8.id1">Throughout the history of computer vision, while research has explored the integration of images (visual) and point clouds (geometric), many advancements in image and 3D object recognition have tended to process these modalities separately.
We aim to bridge this divide by integrating images and point clouds on a unified transformer model. This approach integrates the modality-specific properties of images and point clouds and achieves fundamental downstream tasks in image and 3D object recognition on a unified transformer model by learning visual-geometric representations. In this work, we introduce <span class="ltx_text ltx_font_bold" id="id8.id1.1">F</span>ormula-<span class="ltx_text ltx_font_bold" id="id8.id1.2">S</span>upervised <span class="ltx_text ltx_font_bold" id="id8.id1.3">V</span>isual-<span class="ltx_text ltx_font_bold" id="id8.id1.4">G</span>eometric <span class="ltx_text ltx_font_bold" id="id8.id1.5">P</span>re-training (<span class="ltx_text ltx_font_bold" id="id8.id1.6">FSVGP</span>), a novel synthetic pre-training method that automatically generates aligned synthetic images and point clouds from mathematical formulas. Through cross-modality supervision, we enable supervised pre-training between visual and geometric modalities. FSVGP also reduces reliance on real data collection, cross-modality alignment, and human annotation. Our experimental results show that FSVGP pre-trains more effectively than VisualAtom and PC-FractalDB across six tasks: image and 3D object classification, detection, and segmentation. These achievements demonstrate FSVGPâ€™s superior generalization in image and 3D object recognition and underscore the potential of synthetic pre-training in visual-geometric representation learning. Our project website is available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ryosuke-yamada.github.io/fdsl-fsvgp/" title="">https://ryosuke-yamada.github.io/fdsl-fsvgp/</a>.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>Visual-Geometric representation Synthetic pre-training
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Fusing images (visual) and point clouds (geometric) is crucial for developing vision models that enhance understanding of the real world. This is because the visual and geometric modalities are complementary.
For example, a vision model that relies only on point clouds cannot distinguish a picture and a poster attached to the wall. However, the difference in texture between these two objects can easily be identified by fusing images in the same 3D scene.
Therefore, extracting visual-geometric representations by integrating images and point clouds enhances the recognition capabilities of vision models.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="392" id="S1.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F1.2.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S1.F1.3.2" style="font-size:90%;">
FSVGP enables pre-training visual and geometric modalities on a unified transformer model by constructing VG-FractalDB from a mathematical formula.
VG-FractalDB consists of fractal images, fractal point clouds, and cross-modal supervision called formula-supervised consistency labels. FSVGP simultaneously inputs a fractal image and a fractal point cloud and pre-trains in classification (CLS) tasks based on a formula-supervised consistency label.
We show that FSVGP improves six tasks of image and 3D object CLS, detection (DET), and segmentation (SEG).
</span></figcaption>
</figure>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Despite the ongoing research in visual-geometric representation learning that utilizes images and point clouds, a significant gap exists in developing a unified vision model that effectively trains on both modalities, enhancing both image and 3D object recognition capabilities.
Within the realm of visual-geometric representation learning, various studiesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib42" title="">42</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib27" title="">27</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib22" title="">22</a>]</cite> have pursued improvements in image recognition by integrating visual and geometric data, while othersÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib34" title="">34</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib26" title="">26</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib46" title="">46</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib39" title="">39</a>]</cite> have aimed to enhance 3D object recognition. In 2024, recognition models have emerged that are limited to segmentation tasks yet can address both image and 3D dataÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib15" title="">15</a>]</cite>.
The challenge is partly due to the scarcity of large-scale datasets pairing images with point clouds, suggesting extensive paired data is necessary to bridge visual and geometric modalities effectively.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">However, given the scarcity of high-quality 3D data on the web, collecting paired images and point clouds proves significantly more challenging and costly.
Furthermore, accurate annotations often necessitate manual labeling by experts who can interpret complex spatial information of 3D data.
In addition, aligning images with point clouds requires significant correspondence and pre-processing costs to address distortions in raw point clouds and their associated image projections, which are prone to distortion.
Consequently, the construction of large-scale datasets for visual and geometric modalities poses a formidable challenge, demanding substantial human resources and specialized expertise.
Moreover, copyright and ethical biases are becoming an increasing concern on real datasets.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">We facilitate visual-geometric representation learning by employing formula-driven supervised learning (FDSL) to address these challenges. FDSLÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib18" title="">18</a>]</cite> automatically generates synthetic data and supervision from a mathematical formula based on principles such as fractal geometry. Furthermore, FDSL helps circumvent common issues associated with real data, including manual labeling costs, copyright concerns, and ethical biases.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Hence, we introduce a visual-geometric pre-training method called <span class="ltx_text ltx_font_bold" id="S1.p5.1.1">F</span>ormula-<span class="ltx_text ltx_font_bold" id="S1.p5.1.2">S</span>upervised <span class="ltx_text ltx_font_bold" id="S1.p5.1.3">V</span>isual-<span class="ltx_text ltx_font_bold" id="S1.p5.1.4">G</span>eometric <span class="ltx_text ltx_font_bold" id="S1.p5.1.5">P</span>re-training (<span class="ltx_text ltx_font_bold" id="S1.p5.1.6">FSVGP</span>).
FSVGP enables synthetic pre-training through a unified transformer model by automatically generating aligned synthetic images and point clouds, as shown in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">1</span></a>.
We first developed the visual-geometric fractal database (VG-FractalDB), which employs fractal geometry to generate fractal point clouds and their corresponding fractal images automatically, processed simultaneously by a unified transformer model.
VG-FractalDB provides a formula-supervised consistency label as cross-modality supervision between visual and geometric modalities.
The formula-supervised consistency labels ensure correspondences between fractal images and fractal point clouds, facilitating supervised pre-training for classification tasks on a unified transformer model.
For the transformer model, we made minimal modifications to the input processingâ€”drawing upon the Vision Transformer (ViT)Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib10" title="">10</a>]</cite> and Point Transformer (PointT)Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib48" title="">48</a>]</cite>â€”to maintain its flexibility.
Thus, FSVGP achieves synthetic pre-training, effectively learning visual-geometric representations to integrate images and point clouds into a unified transformer model. This facilitates image and 3D object recognition using a unified transformer model.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">In summary, FSVGP is a novel supervised synthetic pre-training designed to train the VG-FractalDB on a unified transformer model. Our contributions are as follows: (i) Our experimental results show that FSVGP improves fine-tuning performance across six tasks, including image and 3D object classification, detection, and segmentation. (ii) We demonstrate that FSVGP surpasses the latest FDSL method (VisualAtom) in image classification, detection, and segmentation tasks. (iii) We show that FSVGP is superior to the latest FDSL method (PC-FractalDB) in 3D object classification, detection, and segmentation tasks.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">In this section, we limit the discussion of related work to that closely related to the proposed FSVGP.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">In image recognition, recent self-supervised learning (SSL) methodsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib12" title="">12</a>]</cite> using massive datasets such as JFT-300MÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib36" title="">36</a>]</cite> or ImageNet-21k have begun to surpass the longstanding de facto standard of ImageNet-1k for supervised pre-training.
Various SSL methods Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib47" title="">47</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib32" title="">32</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib25" title="">25</a>]</cite> in 3D object recognition, utilizing ShapeNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib4" title="">4</a>]</cite>, have been proposed, showcasing certain pre-training effects in downstream tasks.
In addition, large-scale 3D datasets such as Objaverse-XLÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib8" title="">8</a>]</cite> have recently been introduced in 3D vision tasks.
Nevertheless, using large-scale real datasets raises ethical concerns, including manual labeling costs, copyright issues, and biases.
It is possible to delete 3D objects from the web by their creators in Objaverse-XL.
The importance of open-source datasets becomes evident as models like ViT-22BÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib7" title="">7</a>]</cite> are often trained with non-public datasets, underscoring the need for transparency and accessibility in computer vision.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">Visual-geometric representation learning with images and point clouds aims to improve recognition performance over a single modality vision model. This research is categorized into two main areas: enhancing visual and geometric recognition. For the former, the goal is to integrate geometric information from 3D data into visual representations to enrich the understanding of 3D scenesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib42" title="">42</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib27" title="">27</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib22" title="">22</a>]</cite>.
For instance, Pri3DÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib13" title="">13</a>]</cite> utilizes contrastive learning to fuse the relationship between corresponding point clouds and pixels.
Conversely, methods to enhance 3D object recognition leverage visual knowledge derived from massive imagesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib34" title="">34</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib26" title="">26</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib46" title="">46</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib39" title="">39</a>]</cite>.
CrossPointÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib1" title="">1</a>]</cite> uses contrastive learning between point clouds and multi-view images.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">Furthermore, FDSL is a notable method that addresses pre-training real dataset limitationsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib18" title="">18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib17" title="">17</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib38" title="">38</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib44" title="">44</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib35" title="">35</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib37" title="">37</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib5" title="">5</a>]</cite>.
Unlike SSL, which assigns pseudo-labels to unlabeled data, FDSL uses a mathematical formula to generate synthetic data and corresponding labels for pre-training.
For instance, VisualAtomÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib38" title="">38</a>]</cite> utilizes FDSL to generate synthetic images with complex contours to pre-train ViT, demonstrating effectiveness in image classification, detection, and segmentation. Similarly, PC-FractalDBÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib44" title="">44</a>]</cite>, a synthetic 3D scene dataset, enhances fine-tuning performance in 3D object detection through VoteNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib33" title="">33</a>]</cite> pre-training.
However, the previous FDSL mainly focused on specific modalities and tasks.</p>
</div>
<div class="ltx_para" id="S2.p5">
<p class="ltx_p" id="S2.p5.1">Thus, we introduce FSVGP, which extends FDSL to visual-geometric representation learning, achieving supervised pre-training on a unified transformer model.
FSVGP can effectively serve as a backbone network for a broad image and 3D object recognition spectrum through we develop vanilla transformers with minimal modification.
Moreover, since FSVGP utilizes synthetic data, it circumvents the ethical issues of real data.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Formula-supervised visual-geometric pre-training</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">This section introduces FSVGP, a novel synthetic pre-training method designed to learn visual-geometric representations for image and 3D object recognition.
Unlike previous visual-geometric representation learning methods that predominantly focus on image or 3D object recognition in isolation, FSVGP trains visual-geometric representations on a unified transformer model.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">To implement FSVGP, we construct VG-FractalDB, which automatically generates fractal images and fractal point clouds based on fractal geometry, as shown in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S3.F2" title="Figure 2 â€£ 3 Formula-supervised visual-geometric pre-training â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">2</span></a>.
The generation process of fractal images and fractal point clouds refers to previous researchÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib45" title="">45</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib44" title="">44</a>]</cite>.
Our studyâ€™s key distinction from previous researchÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib45" title="">45</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib44" title="">44</a>]</cite> is the implementation of supervised pre-training on a unified transformer model by utilizing formula-supervised consistency labels between visual and geometric modalities derived directly from a mathematical formula as cross-modality supervision.
As a result, our approach supports visual-geometric learning within a shared label space.
Furthermore, our studyâ€™s concept is based on the fact that FSVGP learns the natural law of visual-geometric relationships by using fractal geometry as a generation rule.</p>
</div>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">Furthermore, we do not develop special cross-modal modules and complex multi-task learning. As a result, by implementing minimal modifications to the transformer model and employing a straightforward loss function for pre-training, we not only facilitate visual-geometric representation learning but also broaden the FSVGPâ€™s range of applicability.</p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="282" id="S3.F2.g1" src="x2.png" width="789"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F2.3.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S3.F2.4.2" style="font-size:90%;">
<span class="ltx_text ltx_font_bold" id="S3.F2.4.2.1">Overview of the fractal generation process and VG-FractalDB.</span> The fractal generation process creates paired fractal data and formula-supervised consistency labels. Initially, fractal point clouds are generated using the 3D Iterated Function System (3D-IFS). The fractal point clouds are then projected onto 2D planes to form fractal images. Simultaneously, formula-supervised consistency labels are automatically generated based on the variance of 3D coordinates, serving as cross-modality supervision.
We construct the VG-FractalDB by repeating these generations.
</span></figcaption>
</figure>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Visual-geometric fractal database (VG-FractalDB)</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.8">VG-FractalDB is a pre-training dataset that consists of fractal images and fractal point clouds with formula-supervised consistency labels (see FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S3.F2" title="Figure 2 â€£ 3 Formula-supervised visual-geometric pre-training â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">2</span></a>).
Specifically, the VG-FractalDB is defined by <math alttext="\mathcal{D}=\{({X}_{j},I_{j},y_{j})\}_{j=1}^{N}" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mrow id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml">ğ’Ÿ</mi><mo id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">=</mo><msubsup id="S3.SS1.p1.1.m1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.cmml"><mrow id="S3.SS1.p1.1.m1.1.1.1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.1.1.2.cmml"><mo id="S3.SS1.p1.1.m1.1.1.1.1.1.1.2" stretchy="false" xref="S3.SS1.p1.1.m1.1.1.1.1.1.2.cmml">{</mo><mrow id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.4.cmml"><mo id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.3.4" stretchy="false" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.4.cmml">(</mo><msub id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml">X</mi><mi id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.3.cmml">j</mi></msub><mo id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.3.5" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.4.cmml">,</mo><msub id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.2.2" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.2.2.cmml"><mi id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.2.2.2" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.2.2.2.cmml">I</mi><mi id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.2.2.3" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.2.2.3.cmml">j</mi></msub><mo id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.3.6" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.4.cmml">,</mo><msub id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.3.3" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.3.3.cmml"><mi id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.3.3.2" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.3.3.2.cmml">y</mi><mi id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.3.3.3" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.3.3.3.cmml">j</mi></msub><mo id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.3.7" stretchy="false" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.4.cmml">)</mo></mrow><mo id="S3.SS1.p1.1.m1.1.1.1.1.1.1.3" stretchy="false" xref="S3.SS1.p1.1.m1.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S3.SS1.p1.1.m1.1.1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.1.1.3.cmml"><mi id="S3.SS1.p1.1.m1.1.1.1.1.3.2" xref="S3.SS1.p1.1.m1.1.1.1.1.3.2.cmml">j</mi><mo id="S3.SS1.p1.1.m1.1.1.1.1.3.1" xref="S3.SS1.p1.1.m1.1.1.1.1.3.1.cmml">=</mo><mn id="S3.SS1.p1.1.m1.1.1.1.1.3.3" xref="S3.SS1.p1.1.m1.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S3.SS1.p1.1.m1.1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.1.3.cmml">N</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><eq id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2"></eq><ci id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3">ğ’Ÿ</ci><apply id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1">superscript</csymbol><apply id="S3.SS1.p1.1.m1.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1">subscript</csymbol><set id="S3.SS1.p1.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1"><vector id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.4.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.3"><apply id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.2">ğ‘‹</ci><ci id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.1.1.3">ğ‘—</ci></apply><apply id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.2.2.2">ğ¼</ci><ci id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.2.2.3">ğ‘—</ci></apply><apply id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.3.3.2">ğ‘¦</ci><ci id="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.1.1.3.3.3">ğ‘—</ci></apply></vector></set><apply id="S3.SS1.p1.1.m1.1.1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.3"><eq id="S3.SS1.p1.1.m1.1.1.1.1.3.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.3.1"></eq><ci id="S3.SS1.p1.1.m1.1.1.1.1.3.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.3.2">ğ‘—</ci><cn id="S3.SS1.p1.1.m1.1.1.1.1.3.3.cmml" type="integer" xref="S3.SS1.p1.1.m1.1.1.1.1.3.3">1</cn></apply></apply><ci id="S3.SS1.p1.1.m1.1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.1.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">\mathcal{D}=\{({X}_{j},I_{j},y_{j})\}_{j=1}^{N}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">caligraphic_D = { ( italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) } start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT</annotation></semantics></math>, where <math alttext="X_{j}" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><msub id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml">X</mi><mi id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2">ğ‘‹</ci><ci id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">X_{j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> represents a fractal point cloud, <math alttext="I_{j}" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1"><semantics id="S3.SS1.p1.3.m3.1a"><msub id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml"><mi id="S3.SS1.p1.3.m3.1.1.2" xref="S3.SS1.p1.3.m3.1.1.2.cmml">I</mi><mi id="S3.SS1.p1.3.m3.1.1.3" xref="S3.SS1.p1.3.m3.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2">ğ¼</ci><ci id="S3.SS1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">I_{j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.1d">italic_I start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> indicates a fractal image, and <math alttext="y_{j}" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m4.1"><semantics id="S3.SS1.p1.4.m4.1a"><msub id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml"><mi id="S3.SS1.p1.4.m4.1.1.2" xref="S3.SS1.p1.4.m4.1.1.2.cmml">y</mi><mi id="S3.SS1.p1.4.m4.1.1.3" xref="S3.SS1.p1.4.m4.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2">ğ‘¦</ci><ci id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">y_{j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.4.m4.1d">italic_y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> is a formula-supervised consistency label that relates to both visual and geometric modalities.
Here, <math alttext="N" class="ltx_Math" display="inline" id="S3.SS1.p1.5.m5.1"><semantics id="S3.SS1.p1.5.m5.1a"><mi id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><ci id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.5.m5.1d">italic_N</annotation></semantics></math> signifies the total number of pre-training data. The formula-supervised consistency labels are categorized discretely within <math alttext="\{1,2,\cdots,C\}" class="ltx_Math" display="inline" id="S3.SS1.p1.6.m6.4"><semantics id="S3.SS1.p1.6.m6.4a"><mrow id="S3.SS1.p1.6.m6.4.5.2" xref="S3.SS1.p1.6.m6.4.5.1.cmml"><mo id="S3.SS1.p1.6.m6.4.5.2.1" stretchy="false" xref="S3.SS1.p1.6.m6.4.5.1.cmml">{</mo><mn id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml">1</mn><mo id="S3.SS1.p1.6.m6.4.5.2.2" xref="S3.SS1.p1.6.m6.4.5.1.cmml">,</mo><mn id="S3.SS1.p1.6.m6.2.2" xref="S3.SS1.p1.6.m6.2.2.cmml">2</mn><mo id="S3.SS1.p1.6.m6.4.5.2.3" xref="S3.SS1.p1.6.m6.4.5.1.cmml">,</mo><mi id="S3.SS1.p1.6.m6.3.3" mathvariant="normal" xref="S3.SS1.p1.6.m6.3.3.cmml">â‹¯</mi><mo id="S3.SS1.p1.6.m6.4.5.2.4" xref="S3.SS1.p1.6.m6.4.5.1.cmml">,</mo><mi id="S3.SS1.p1.6.m6.4.4" xref="S3.SS1.p1.6.m6.4.4.cmml">C</mi><mo id="S3.SS1.p1.6.m6.4.5.2.5" stretchy="false" xref="S3.SS1.p1.6.m6.4.5.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.4b"><set id="S3.SS1.p1.6.m6.4.5.1.cmml" xref="S3.SS1.p1.6.m6.4.5.2"><cn id="S3.SS1.p1.6.m6.1.1.cmml" type="integer" xref="S3.SS1.p1.6.m6.1.1">1</cn><cn id="S3.SS1.p1.6.m6.2.2.cmml" type="integer" xref="S3.SS1.p1.6.m6.2.2">2</cn><ci id="S3.SS1.p1.6.m6.3.3.cmml" xref="S3.SS1.p1.6.m6.3.3">â‹¯</ci><ci id="S3.SS1.p1.6.m6.4.4.cmml" xref="S3.SS1.p1.6.m6.4.4">ğ¶</ci></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.4c">\{1,2,\cdots,C\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.6.m6.4d">{ 1 , 2 , â‹¯ , italic_C }</annotation></semantics></math>, where <math alttext="C" class="ltx_Math" display="inline" id="S3.SS1.p1.7.m7.1"><semantics id="S3.SS1.p1.7.m7.1a"><mi id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><ci id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">C</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.7.m7.1d">italic_C</annotation></semantics></math> denotes the number of categories. Note that the number of data in VG-FractalDB is <math alttext="N" class="ltx_Math" display="inline" id="S3.SS1.p1.8.m8.1"><semantics id="S3.SS1.p1.8.m8.1a"><mi id="S3.SS1.p1.8.m8.1.1" xref="S3.SS1.p1.8.m8.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m8.1b"><ci id="S3.SS1.p1.8.m8.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m8.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.8.m8.1d">italic_N</annotation></semantics></math>, since the fractal image is not generated by the other formulas but by simply projecting a fractal point cloud onto a 2D image plane.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.26"><span class="ltx_text ltx_font_bold" id="S3.SS1.p2.26.1">Geometric modality â€“ fractal point cloud.</span>
A fractal point cloud is generated using the 3D Iterated Function System (3D-IFS), a method rooted in fractal geometry for creating complex, self-similar structures. The 3D-IFS for generating a fractal point cloud of category <math alttext="c" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><mi id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">c</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">italic_c</annotation></semantics></math>, denoted as <math alttext="\Theta^{c}" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.1"><semantics id="S3.SS1.p2.2.m2.1a"><msup id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml"><mi id="S3.SS1.p2.2.m2.1.1.2" mathvariant="normal" xref="S3.SS1.p2.2.m2.1.1.2.cmml">Î˜</mi><mi id="S3.SS1.p2.2.m2.1.1.3" xref="S3.SS1.p2.2.m2.1.1.3.cmml">c</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><apply id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">superscript</csymbol><ci id="S3.SS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1.2">Î˜</ci><ci id="S3.SS1.p2.2.m2.1.1.3.cmml" xref="S3.SS1.p2.2.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">\Theta^{c}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.2.m2.1d">roman_Î˜ start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT</annotation></semantics></math>, is defined as <math alttext="\Theta^{c}=\{\mathcal{X};t_{1}^{c},t_{2}^{c},\cdots,t_{n}^{c};p_{1}^{c},p_{2}^%
{c},\cdots,p_{n}^{c}\}" class="ltx_Math" display="inline" id="S3.SS1.p2.3.m3.9"><semantics id="S3.SS1.p2.3.m3.9a"><mrow id="S3.SS1.p2.3.m3.9.9" xref="S3.SS1.p2.3.m3.9.9.cmml"><msup id="S3.SS1.p2.3.m3.9.9.8" xref="S3.SS1.p2.3.m3.9.9.8.cmml"><mi id="S3.SS1.p2.3.m3.9.9.8.2" mathvariant="normal" xref="S3.SS1.p2.3.m3.9.9.8.2.cmml">Î˜</mi><mi id="S3.SS1.p2.3.m3.9.9.8.3" xref="S3.SS1.p2.3.m3.9.9.8.3.cmml">c</mi></msup><mo id="S3.SS1.p2.3.m3.9.9.7" xref="S3.SS1.p2.3.m3.9.9.7.cmml">=</mo><mrow id="S3.SS1.p2.3.m3.9.9.6.6" xref="S3.SS1.p2.3.m3.9.9.6.7.cmml"><mo id="S3.SS1.p2.3.m3.9.9.6.6.7" stretchy="false" xref="S3.SS1.p2.3.m3.9.9.6.7.cmml">{</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml">ğ’³</mi><mo id="S3.SS1.p2.3.m3.9.9.6.6.8" xref="S3.SS1.p2.3.m3.9.9.6.7.cmml">;</mo><msubsup id="S3.SS1.p2.3.m3.4.4.1.1.1" xref="S3.SS1.p2.3.m3.4.4.1.1.1.cmml"><mi id="S3.SS1.p2.3.m3.4.4.1.1.1.2.2" xref="S3.SS1.p2.3.m3.4.4.1.1.1.2.2.cmml">t</mi><mn id="S3.SS1.p2.3.m3.4.4.1.1.1.2.3" xref="S3.SS1.p2.3.m3.4.4.1.1.1.2.3.cmml">1</mn><mi id="S3.SS1.p2.3.m3.4.4.1.1.1.3" xref="S3.SS1.p2.3.m3.4.4.1.1.1.3.cmml">c</mi></msubsup><mo id="S3.SS1.p2.3.m3.9.9.6.6.9" xref="S3.SS1.p2.3.m3.9.9.6.7.cmml">,</mo><msubsup id="S3.SS1.p2.3.m3.5.5.2.2.2" xref="S3.SS1.p2.3.m3.5.5.2.2.2.cmml"><mi id="S3.SS1.p2.3.m3.5.5.2.2.2.2.2" xref="S3.SS1.p2.3.m3.5.5.2.2.2.2.2.cmml">t</mi><mn id="S3.SS1.p2.3.m3.5.5.2.2.2.2.3" xref="S3.SS1.p2.3.m3.5.5.2.2.2.2.3.cmml">2</mn><mi id="S3.SS1.p2.3.m3.5.5.2.2.2.3" xref="S3.SS1.p2.3.m3.5.5.2.2.2.3.cmml">c</mi></msubsup><mo id="S3.SS1.p2.3.m3.9.9.6.6.10" xref="S3.SS1.p2.3.m3.9.9.6.7.cmml">,</mo><mi id="S3.SS1.p2.3.m3.2.2" mathvariant="normal" xref="S3.SS1.p2.3.m3.2.2.cmml">â‹¯</mi><mo id="S3.SS1.p2.3.m3.9.9.6.6.11" xref="S3.SS1.p2.3.m3.9.9.6.7.cmml">,</mo><msubsup id="S3.SS1.p2.3.m3.6.6.3.3.3" xref="S3.SS1.p2.3.m3.6.6.3.3.3.cmml"><mi id="S3.SS1.p2.3.m3.6.6.3.3.3.2.2" xref="S3.SS1.p2.3.m3.6.6.3.3.3.2.2.cmml">t</mi><mi id="S3.SS1.p2.3.m3.6.6.3.3.3.2.3" xref="S3.SS1.p2.3.m3.6.6.3.3.3.2.3.cmml">n</mi><mi id="S3.SS1.p2.3.m3.6.6.3.3.3.3" xref="S3.SS1.p2.3.m3.6.6.3.3.3.3.cmml">c</mi></msubsup><mo id="S3.SS1.p2.3.m3.9.9.6.6.12" xref="S3.SS1.p2.3.m3.9.9.6.7.cmml">;</mo><msubsup id="S3.SS1.p2.3.m3.7.7.4.4.4" xref="S3.SS1.p2.3.m3.7.7.4.4.4.cmml"><mi id="S3.SS1.p2.3.m3.7.7.4.4.4.2.2" xref="S3.SS1.p2.3.m3.7.7.4.4.4.2.2.cmml">p</mi><mn id="S3.SS1.p2.3.m3.7.7.4.4.4.2.3" xref="S3.SS1.p2.3.m3.7.7.4.4.4.2.3.cmml">1</mn><mi id="S3.SS1.p2.3.m3.7.7.4.4.4.3" xref="S3.SS1.p2.3.m3.7.7.4.4.4.3.cmml">c</mi></msubsup><mo id="S3.SS1.p2.3.m3.9.9.6.6.13" xref="S3.SS1.p2.3.m3.9.9.6.7.cmml">,</mo><msubsup id="S3.SS1.p2.3.m3.8.8.5.5.5" xref="S3.SS1.p2.3.m3.8.8.5.5.5.cmml"><mi id="S3.SS1.p2.3.m3.8.8.5.5.5.2.2" xref="S3.SS1.p2.3.m3.8.8.5.5.5.2.2.cmml">p</mi><mn id="S3.SS1.p2.3.m3.8.8.5.5.5.2.3" xref="S3.SS1.p2.3.m3.8.8.5.5.5.2.3.cmml">2</mn><mi id="S3.SS1.p2.3.m3.8.8.5.5.5.3" xref="S3.SS1.p2.3.m3.8.8.5.5.5.3.cmml">c</mi></msubsup><mo id="S3.SS1.p2.3.m3.9.9.6.6.14" xref="S3.SS1.p2.3.m3.9.9.6.7.cmml">,</mo><mi id="S3.SS1.p2.3.m3.3.3" mathvariant="normal" xref="S3.SS1.p2.3.m3.3.3.cmml">â‹¯</mi><mo id="S3.SS1.p2.3.m3.9.9.6.6.15" xref="S3.SS1.p2.3.m3.9.9.6.7.cmml">,</mo><msubsup id="S3.SS1.p2.3.m3.9.9.6.6.6" xref="S3.SS1.p2.3.m3.9.9.6.6.6.cmml"><mi id="S3.SS1.p2.3.m3.9.9.6.6.6.2.2" xref="S3.SS1.p2.3.m3.9.9.6.6.6.2.2.cmml">p</mi><mi id="S3.SS1.p2.3.m3.9.9.6.6.6.2.3" xref="S3.SS1.p2.3.m3.9.9.6.6.6.2.3.cmml">n</mi><mi id="S3.SS1.p2.3.m3.9.9.6.6.6.3" xref="S3.SS1.p2.3.m3.9.9.6.6.6.3.cmml">c</mi></msubsup><mo id="S3.SS1.p2.3.m3.9.9.6.6.16" stretchy="false" xref="S3.SS1.p2.3.m3.9.9.6.7.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.9b"><apply id="S3.SS1.p2.3.m3.9.9.cmml" xref="S3.SS1.p2.3.m3.9.9"><eq id="S3.SS1.p2.3.m3.9.9.7.cmml" xref="S3.SS1.p2.3.m3.9.9.7"></eq><apply id="S3.SS1.p2.3.m3.9.9.8.cmml" xref="S3.SS1.p2.3.m3.9.9.8"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.9.9.8.1.cmml" xref="S3.SS1.p2.3.m3.9.9.8">superscript</csymbol><ci id="S3.SS1.p2.3.m3.9.9.8.2.cmml" xref="S3.SS1.p2.3.m3.9.9.8.2">Î˜</ci><ci id="S3.SS1.p2.3.m3.9.9.8.3.cmml" xref="S3.SS1.p2.3.m3.9.9.8.3">ğ‘</ci></apply><list id="S3.SS1.p2.3.m3.9.9.6.7.cmml" xref="S3.SS1.p2.3.m3.9.9.6.6"><ci id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">ğ’³</ci><apply id="S3.SS1.p2.3.m3.4.4.1.1.1.cmml" xref="S3.SS1.p2.3.m3.4.4.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.4.4.1.1.1.1.cmml" xref="S3.SS1.p2.3.m3.4.4.1.1.1">superscript</csymbol><apply id="S3.SS1.p2.3.m3.4.4.1.1.1.2.cmml" xref="S3.SS1.p2.3.m3.4.4.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.4.4.1.1.1.2.1.cmml" xref="S3.SS1.p2.3.m3.4.4.1.1.1">subscript</csymbol><ci id="S3.SS1.p2.3.m3.4.4.1.1.1.2.2.cmml" xref="S3.SS1.p2.3.m3.4.4.1.1.1.2.2">ğ‘¡</ci><cn id="S3.SS1.p2.3.m3.4.4.1.1.1.2.3.cmml" type="integer" xref="S3.SS1.p2.3.m3.4.4.1.1.1.2.3">1</cn></apply><ci id="S3.SS1.p2.3.m3.4.4.1.1.1.3.cmml" xref="S3.SS1.p2.3.m3.4.4.1.1.1.3">ğ‘</ci></apply><apply id="S3.SS1.p2.3.m3.5.5.2.2.2.cmml" xref="S3.SS1.p2.3.m3.5.5.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.5.5.2.2.2.1.cmml" xref="S3.SS1.p2.3.m3.5.5.2.2.2">superscript</csymbol><apply id="S3.SS1.p2.3.m3.5.5.2.2.2.2.cmml" xref="S3.SS1.p2.3.m3.5.5.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.5.5.2.2.2.2.1.cmml" xref="S3.SS1.p2.3.m3.5.5.2.2.2">subscript</csymbol><ci id="S3.SS1.p2.3.m3.5.5.2.2.2.2.2.cmml" xref="S3.SS1.p2.3.m3.5.5.2.2.2.2.2">ğ‘¡</ci><cn id="S3.SS1.p2.3.m3.5.5.2.2.2.2.3.cmml" type="integer" xref="S3.SS1.p2.3.m3.5.5.2.2.2.2.3">2</cn></apply><ci id="S3.SS1.p2.3.m3.5.5.2.2.2.3.cmml" xref="S3.SS1.p2.3.m3.5.5.2.2.2.3">ğ‘</ci></apply><ci id="S3.SS1.p2.3.m3.2.2.cmml" xref="S3.SS1.p2.3.m3.2.2">â‹¯</ci><apply id="S3.SS1.p2.3.m3.6.6.3.3.3.cmml" xref="S3.SS1.p2.3.m3.6.6.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.6.6.3.3.3.1.cmml" xref="S3.SS1.p2.3.m3.6.6.3.3.3">superscript</csymbol><apply id="S3.SS1.p2.3.m3.6.6.3.3.3.2.cmml" xref="S3.SS1.p2.3.m3.6.6.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.6.6.3.3.3.2.1.cmml" xref="S3.SS1.p2.3.m3.6.6.3.3.3">subscript</csymbol><ci id="S3.SS1.p2.3.m3.6.6.3.3.3.2.2.cmml" xref="S3.SS1.p2.3.m3.6.6.3.3.3.2.2">ğ‘¡</ci><ci id="S3.SS1.p2.3.m3.6.6.3.3.3.2.3.cmml" xref="S3.SS1.p2.3.m3.6.6.3.3.3.2.3">ğ‘›</ci></apply><ci id="S3.SS1.p2.3.m3.6.6.3.3.3.3.cmml" xref="S3.SS1.p2.3.m3.6.6.3.3.3.3">ğ‘</ci></apply><apply id="S3.SS1.p2.3.m3.7.7.4.4.4.cmml" xref="S3.SS1.p2.3.m3.7.7.4.4.4"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.7.7.4.4.4.1.cmml" xref="S3.SS1.p2.3.m3.7.7.4.4.4">superscript</csymbol><apply id="S3.SS1.p2.3.m3.7.7.4.4.4.2.cmml" xref="S3.SS1.p2.3.m3.7.7.4.4.4"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.7.7.4.4.4.2.1.cmml" xref="S3.SS1.p2.3.m3.7.7.4.4.4">subscript</csymbol><ci id="S3.SS1.p2.3.m3.7.7.4.4.4.2.2.cmml" xref="S3.SS1.p2.3.m3.7.7.4.4.4.2.2">ğ‘</ci><cn id="S3.SS1.p2.3.m3.7.7.4.4.4.2.3.cmml" type="integer" xref="S3.SS1.p2.3.m3.7.7.4.4.4.2.3">1</cn></apply><ci id="S3.SS1.p2.3.m3.7.7.4.4.4.3.cmml" xref="S3.SS1.p2.3.m3.7.7.4.4.4.3">ğ‘</ci></apply><apply id="S3.SS1.p2.3.m3.8.8.5.5.5.cmml" xref="S3.SS1.p2.3.m3.8.8.5.5.5"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.8.8.5.5.5.1.cmml" xref="S3.SS1.p2.3.m3.8.8.5.5.5">superscript</csymbol><apply id="S3.SS1.p2.3.m3.8.8.5.5.5.2.cmml" xref="S3.SS1.p2.3.m3.8.8.5.5.5"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.8.8.5.5.5.2.1.cmml" xref="S3.SS1.p2.3.m3.8.8.5.5.5">subscript</csymbol><ci id="S3.SS1.p2.3.m3.8.8.5.5.5.2.2.cmml" xref="S3.SS1.p2.3.m3.8.8.5.5.5.2.2">ğ‘</ci><cn id="S3.SS1.p2.3.m3.8.8.5.5.5.2.3.cmml" type="integer" xref="S3.SS1.p2.3.m3.8.8.5.5.5.2.3">2</cn></apply><ci id="S3.SS1.p2.3.m3.8.8.5.5.5.3.cmml" xref="S3.SS1.p2.3.m3.8.8.5.5.5.3">ğ‘</ci></apply><ci id="S3.SS1.p2.3.m3.3.3.cmml" xref="S3.SS1.p2.3.m3.3.3">â‹¯</ci><apply id="S3.SS1.p2.3.m3.9.9.6.6.6.cmml" xref="S3.SS1.p2.3.m3.9.9.6.6.6"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.9.9.6.6.6.1.cmml" xref="S3.SS1.p2.3.m3.9.9.6.6.6">superscript</csymbol><apply id="S3.SS1.p2.3.m3.9.9.6.6.6.2.cmml" xref="S3.SS1.p2.3.m3.9.9.6.6.6"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.9.9.6.6.6.2.1.cmml" xref="S3.SS1.p2.3.m3.9.9.6.6.6">subscript</csymbol><ci id="S3.SS1.p2.3.m3.9.9.6.6.6.2.2.cmml" xref="S3.SS1.p2.3.m3.9.9.6.6.6.2.2">ğ‘</ci><ci id="S3.SS1.p2.3.m3.9.9.6.6.6.2.3.cmml" xref="S3.SS1.p2.3.m3.9.9.6.6.6.2.3">ğ‘›</ci></apply><ci id="S3.SS1.p2.3.m3.9.9.6.6.6.3.cmml" xref="S3.SS1.p2.3.m3.9.9.6.6.6.3">ğ‘</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.9c">\Theta^{c}=\{\mathcal{X};t_{1}^{c},t_{2}^{c},\cdots,t_{n}^{c};p_{1}^{c},p_{2}^%
{c},\cdots,p_{n}^{c}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.3.m3.9d">roman_Î˜ start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT = { caligraphic_X ; italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT , italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT , â‹¯ , italic_t start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT ; italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT , italic_p start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT , â‹¯ , italic_p start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT }</annotation></semantics></math>, where each <math alttext="t_{i}^{c}:\mathcal{X}\to\mathcal{X}" class="ltx_Math" display="inline" id="S3.SS1.p2.4.m4.1"><semantics id="S3.SS1.p2.4.m4.1a"><mrow id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml"><msubsup id="S3.SS1.p2.4.m4.1.1.2" xref="S3.SS1.p2.4.m4.1.1.2.cmml"><mi id="S3.SS1.p2.4.m4.1.1.2.2.2" xref="S3.SS1.p2.4.m4.1.1.2.2.2.cmml">t</mi><mi id="S3.SS1.p2.4.m4.1.1.2.2.3" xref="S3.SS1.p2.4.m4.1.1.2.2.3.cmml">i</mi><mi id="S3.SS1.p2.4.m4.1.1.2.3" xref="S3.SS1.p2.4.m4.1.1.2.3.cmml">c</mi></msubsup><mo id="S3.SS1.p2.4.m4.1.1.1" lspace="0.278em" rspace="0.278em" xref="S3.SS1.p2.4.m4.1.1.1.cmml">:</mo><mrow id="S3.SS1.p2.4.m4.1.1.3" xref="S3.SS1.p2.4.m4.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.4.m4.1.1.3.2" xref="S3.SS1.p2.4.m4.1.1.3.2.cmml">ğ’³</mi><mo id="S3.SS1.p2.4.m4.1.1.3.1" stretchy="false" xref="S3.SS1.p2.4.m4.1.1.3.1.cmml">â†’</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.4.m4.1.1.3.3" xref="S3.SS1.p2.4.m4.1.1.3.3.cmml">ğ’³</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"><ci id="S3.SS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1.1">:</ci><apply id="S3.SS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.1.1.2.1.cmml" xref="S3.SS1.p2.4.m4.1.1.2">superscript</csymbol><apply id="S3.SS1.p2.4.m4.1.1.2.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.1.1.2.2.1.cmml" xref="S3.SS1.p2.4.m4.1.1.2">subscript</csymbol><ci id="S3.SS1.p2.4.m4.1.1.2.2.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2.2.2">ğ‘¡</ci><ci id="S3.SS1.p2.4.m4.1.1.2.2.3.cmml" xref="S3.SS1.p2.4.m4.1.1.2.2.3">ğ‘–</ci></apply><ci id="S3.SS1.p2.4.m4.1.1.2.3.cmml" xref="S3.SS1.p2.4.m4.1.1.2.3">ğ‘</ci></apply><apply id="S3.SS1.p2.4.m4.1.1.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3"><ci id="S3.SS1.p2.4.m4.1.1.3.1.cmml" xref="S3.SS1.p2.4.m4.1.1.3.1">â†’</ci><ci id="S3.SS1.p2.4.m4.1.1.3.2.cmml" xref="S3.SS1.p2.4.m4.1.1.3.2">ğ’³</ci><ci id="S3.SS1.p2.4.m4.1.1.3.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3.3">ğ’³</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">t_{i}^{c}:\mathcal{X}\to\mathcal{X}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.4.m4.1d">italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT : caligraphic_X â†’ caligraphic_X</annotation></semantics></math> represents an affine transformation function within the space <math alttext="\mathcal{X}" class="ltx_Math" display="inline" id="S3.SS1.p2.5.m5.1"><semantics id="S3.SS1.p2.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml">ğ’³</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><ci id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1">ğ’³</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">\mathcal{X}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.5.m5.1d">caligraphic_X</annotation></semantics></math>, and <math alttext="\{p_{i}^{c}\}" class="ltx_Math" display="inline" id="S3.SS1.p2.6.m6.1"><semantics id="S3.SS1.p2.6.m6.1a"><mrow id="S3.SS1.p2.6.m6.1.1.1" xref="S3.SS1.p2.6.m6.1.1.2.cmml"><mo id="S3.SS1.p2.6.m6.1.1.1.2" stretchy="false" xref="S3.SS1.p2.6.m6.1.1.2.cmml">{</mo><msubsup id="S3.SS1.p2.6.m6.1.1.1.1" xref="S3.SS1.p2.6.m6.1.1.1.1.cmml"><mi id="S3.SS1.p2.6.m6.1.1.1.1.2.2" xref="S3.SS1.p2.6.m6.1.1.1.1.2.2.cmml">p</mi><mi id="S3.SS1.p2.6.m6.1.1.1.1.2.3" xref="S3.SS1.p2.6.m6.1.1.1.1.2.3.cmml">i</mi><mi id="S3.SS1.p2.6.m6.1.1.1.1.3" xref="S3.SS1.p2.6.m6.1.1.1.1.3.cmml">c</mi></msubsup><mo id="S3.SS1.p2.6.m6.1.1.1.3" stretchy="false" xref="S3.SS1.p2.6.m6.1.1.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b"><set id="S3.SS1.p2.6.m6.1.1.2.cmml" xref="S3.SS1.p2.6.m6.1.1.1"><apply id="S3.SS1.p2.6.m6.1.1.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.6.m6.1.1.1.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1.1.1">superscript</csymbol><apply id="S3.SS1.p2.6.m6.1.1.1.1.2.cmml" xref="S3.SS1.p2.6.m6.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.6.m6.1.1.1.1.2.1.cmml" xref="S3.SS1.p2.6.m6.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p2.6.m6.1.1.1.1.2.2.cmml" xref="S3.SS1.p2.6.m6.1.1.1.1.2.2">ğ‘</ci><ci id="S3.SS1.p2.6.m6.1.1.1.1.2.3.cmml" xref="S3.SS1.p2.6.m6.1.1.1.1.2.3">ğ‘–</ci></apply><ci id="S3.SS1.p2.6.m6.1.1.1.1.3.cmml" xref="S3.SS1.p2.6.m6.1.1.1.1.3">ğ‘</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">\{p_{i}^{c}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.6.m6.1d">{ italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT }</annotation></semantics></math> are the associated probabilities of each transformation, with <math alttext="n=7" class="ltx_Math" display="inline" id="S3.SS1.p2.7.m7.1"><semantics id="S3.SS1.p2.7.m7.1a"><mrow id="S3.SS1.p2.7.m7.1.1" xref="S3.SS1.p2.7.m7.1.1.cmml"><mi id="S3.SS1.p2.7.m7.1.1.2" xref="S3.SS1.p2.7.m7.1.1.2.cmml">n</mi><mo id="S3.SS1.p2.7.m7.1.1.1" xref="S3.SS1.p2.7.m7.1.1.1.cmml">=</mo><mn id="S3.SS1.p2.7.m7.1.1.3" xref="S3.SS1.p2.7.m7.1.1.3.cmml">7</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.7.m7.1b"><apply id="S3.SS1.p2.7.m7.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1"><eq id="S3.SS1.p2.7.m7.1.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1.1"></eq><ci id="S3.SS1.p2.7.m7.1.1.2.cmml" xref="S3.SS1.p2.7.m7.1.1.2">ğ‘›</ci><cn id="S3.SS1.p2.7.m7.1.1.3.cmml" type="integer" xref="S3.SS1.p2.7.m7.1.1.3">7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.7.m7.1c">n=7</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.7.m7.1d">italic_n = 7</annotation></semantics></math> denoting the number of transformations.
A fractal point cloud is represented as a set of coordinates, <math alttext="\{\bm{x}_{t}\}_{t=1}^{T}" class="ltx_Math" display="inline" id="S3.SS1.p2.8.m8.1"><semantics id="S3.SS1.p2.8.m8.1a"><msubsup id="S3.SS1.p2.8.m8.1.1" xref="S3.SS1.p2.8.m8.1.1.cmml"><mrow id="S3.SS1.p2.8.m8.1.1.1.1.1" xref="S3.SS1.p2.8.m8.1.1.1.1.2.cmml"><mo id="S3.SS1.p2.8.m8.1.1.1.1.1.2" stretchy="false" xref="S3.SS1.p2.8.m8.1.1.1.1.2.cmml">{</mo><msub id="S3.SS1.p2.8.m8.1.1.1.1.1.1" xref="S3.SS1.p2.8.m8.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p2.8.m8.1.1.1.1.1.1.2" xref="S3.SS1.p2.8.m8.1.1.1.1.1.1.2.cmml">ğ’™</mi><mi id="S3.SS1.p2.8.m8.1.1.1.1.1.1.3" xref="S3.SS1.p2.8.m8.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.SS1.p2.8.m8.1.1.1.1.1.3" stretchy="false" xref="S3.SS1.p2.8.m8.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S3.SS1.p2.8.m8.1.1.1.3" xref="S3.SS1.p2.8.m8.1.1.1.3.cmml"><mi id="S3.SS1.p2.8.m8.1.1.1.3.2" xref="S3.SS1.p2.8.m8.1.1.1.3.2.cmml">t</mi><mo id="S3.SS1.p2.8.m8.1.1.1.3.1" xref="S3.SS1.p2.8.m8.1.1.1.3.1.cmml">=</mo><mn id="S3.SS1.p2.8.m8.1.1.1.3.3" xref="S3.SS1.p2.8.m8.1.1.1.3.3.cmml">1</mn></mrow><mi id="S3.SS1.p2.8.m8.1.1.3" xref="S3.SS1.p2.8.m8.1.1.3.cmml">T</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.8.m8.1b"><apply id="S3.SS1.p2.8.m8.1.1.cmml" xref="S3.SS1.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.8.m8.1.1.2.cmml" xref="S3.SS1.p2.8.m8.1.1">superscript</csymbol><apply id="S3.SS1.p2.8.m8.1.1.1.cmml" xref="S3.SS1.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.8.m8.1.1.1.2.cmml" xref="S3.SS1.p2.8.m8.1.1">subscript</csymbol><set id="S3.SS1.p2.8.m8.1.1.1.1.2.cmml" xref="S3.SS1.p2.8.m8.1.1.1.1.1"><apply id="S3.SS1.p2.8.m8.1.1.1.1.1.1.cmml" xref="S3.SS1.p2.8.m8.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.8.m8.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p2.8.m8.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p2.8.m8.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p2.8.m8.1.1.1.1.1.1.2">ğ’™</ci><ci id="S3.SS1.p2.8.m8.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p2.8.m8.1.1.1.1.1.1.3">ğ‘¡</ci></apply></set><apply id="S3.SS1.p2.8.m8.1.1.1.3.cmml" xref="S3.SS1.p2.8.m8.1.1.1.3"><eq id="S3.SS1.p2.8.m8.1.1.1.3.1.cmml" xref="S3.SS1.p2.8.m8.1.1.1.3.1"></eq><ci id="S3.SS1.p2.8.m8.1.1.1.3.2.cmml" xref="S3.SS1.p2.8.m8.1.1.1.3.2">ğ‘¡</ci><cn id="S3.SS1.p2.8.m8.1.1.1.3.3.cmml" type="integer" xref="S3.SS1.p2.8.m8.1.1.1.3.3">1</cn></apply></apply><ci id="S3.SS1.p2.8.m8.1.1.3.cmml" xref="S3.SS1.p2.8.m8.1.1.3">ğ‘‡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.8.m8.1c">\{\bm{x}_{t}\}_{t=1}^{T}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.8.m8.1d">{ bold_italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT</annotation></semantics></math>, within the complete metric space <math alttext="\mathcal{X}" class="ltx_Math" display="inline" id="S3.SS1.p2.9.m9.1"><semantics id="S3.SS1.p2.9.m9.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.9.m9.1.1" xref="S3.SS1.p2.9.m9.1.1.cmml">ğ’³</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.9.m9.1b"><ci id="S3.SS1.p2.9.m9.1.1.cmml" xref="S3.SS1.p2.9.m9.1.1">ğ’³</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.9.m9.1c">\mathcal{X}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.9.m9.1d">caligraphic_X</annotation></semantics></math>, here employing the 3D Euclidean space <math alttext="\mathcal{X}=\mathbb{R}^{3}" class="ltx_Math" display="inline" id="S3.SS1.p2.10.m10.1"><semantics id="S3.SS1.p2.10.m10.1a"><mrow id="S3.SS1.p2.10.m10.1.1" xref="S3.SS1.p2.10.m10.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.10.m10.1.1.2" xref="S3.SS1.p2.10.m10.1.1.2.cmml">ğ’³</mi><mo id="S3.SS1.p2.10.m10.1.1.1" xref="S3.SS1.p2.10.m10.1.1.1.cmml">=</mo><msup id="S3.SS1.p2.10.m10.1.1.3" xref="S3.SS1.p2.10.m10.1.1.3.cmml"><mi id="S3.SS1.p2.10.m10.1.1.3.2" xref="S3.SS1.p2.10.m10.1.1.3.2.cmml">â„</mi><mn id="S3.SS1.p2.10.m10.1.1.3.3" xref="S3.SS1.p2.10.m10.1.1.3.3.cmml">3</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.10.m10.1b"><apply id="S3.SS1.p2.10.m10.1.1.cmml" xref="S3.SS1.p2.10.m10.1.1"><eq id="S3.SS1.p2.10.m10.1.1.1.cmml" xref="S3.SS1.p2.10.m10.1.1.1"></eq><ci id="S3.SS1.p2.10.m10.1.1.2.cmml" xref="S3.SS1.p2.10.m10.1.1.2">ğ’³</ci><apply id="S3.SS1.p2.10.m10.1.1.3.cmml" xref="S3.SS1.p2.10.m10.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p2.10.m10.1.1.3.1.cmml" xref="S3.SS1.p2.10.m10.1.1.3">superscript</csymbol><ci id="S3.SS1.p2.10.m10.1.1.3.2.cmml" xref="S3.SS1.p2.10.m10.1.1.3.2">â„</ci><cn id="S3.SS1.p2.10.m10.1.1.3.3.cmml" type="integer" xref="S3.SS1.p2.10.m10.1.1.3.3">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.10.m10.1c">\mathcal{X}=\mathbb{R}^{3}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.10.m10.1d">caligraphic_X = blackboard_R start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT</annotation></semantics></math>. The point cloud is generated by a series of affine transformations <math alttext="t_{i}" class="ltx_Math" display="inline" id="S3.SS1.p2.11.m11.1"><semantics id="S3.SS1.p2.11.m11.1a"><msub id="S3.SS1.p2.11.m11.1.1" xref="S3.SS1.p2.11.m11.1.1.cmml"><mi id="S3.SS1.p2.11.m11.1.1.2" xref="S3.SS1.p2.11.m11.1.1.2.cmml">t</mi><mi id="S3.SS1.p2.11.m11.1.1.3" xref="S3.SS1.p2.11.m11.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.11.m11.1b"><apply id="S3.SS1.p2.11.m11.1.1.cmml" xref="S3.SS1.p2.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.11.m11.1.1.1.cmml" xref="S3.SS1.p2.11.m11.1.1">subscript</csymbol><ci id="S3.SS1.p2.11.m11.1.1.2.cmml" xref="S3.SS1.p2.11.m11.1.1.2">ğ‘¡</ci><ci id="S3.SS1.p2.11.m11.1.1.3.cmml" xref="S3.SS1.p2.11.m11.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.11.m11.1c">t_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.11.m11.1d">italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> applied within this space.
Each affine transformation <math alttext="t_{i}" class="ltx_Math" display="inline" id="S3.SS1.p2.12.m12.1"><semantics id="S3.SS1.p2.12.m12.1a"><msub id="S3.SS1.p2.12.m12.1.1" xref="S3.SS1.p2.12.m12.1.1.cmml"><mi id="S3.SS1.p2.12.m12.1.1.2" xref="S3.SS1.p2.12.m12.1.1.2.cmml">t</mi><mi id="S3.SS1.p2.12.m12.1.1.3" xref="S3.SS1.p2.12.m12.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.12.m12.1b"><apply id="S3.SS1.p2.12.m12.1.1.cmml" xref="S3.SS1.p2.12.m12.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.12.m12.1.1.1.cmml" xref="S3.SS1.p2.12.m12.1.1">subscript</csymbol><ci id="S3.SS1.p2.12.m12.1.1.2.cmml" xref="S3.SS1.p2.12.m12.1.1.2">ğ‘¡</ci><ci id="S3.SS1.p2.12.m12.1.1.3.cmml" xref="S3.SS1.p2.12.m12.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.12.m12.1c">t_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.12.m12.1d">italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is defined by the equation
<math alttext="t_{i}(\bm{x})=\bm{r}_{i}\bm{x}+\bm{b}_{i}" class="ltx_Math" display="inline" id="S3.SS1.p2.13.m13.1"><semantics id="S3.SS1.p2.13.m13.1a"><mrow id="S3.SS1.p2.13.m13.1.2" xref="S3.SS1.p2.13.m13.1.2.cmml"><mrow id="S3.SS1.p2.13.m13.1.2.2" xref="S3.SS1.p2.13.m13.1.2.2.cmml"><msub id="S3.SS1.p2.13.m13.1.2.2.2" xref="S3.SS1.p2.13.m13.1.2.2.2.cmml"><mi id="S3.SS1.p2.13.m13.1.2.2.2.2" xref="S3.SS1.p2.13.m13.1.2.2.2.2.cmml">t</mi><mi id="S3.SS1.p2.13.m13.1.2.2.2.3" xref="S3.SS1.p2.13.m13.1.2.2.2.3.cmml">i</mi></msub><mo id="S3.SS1.p2.13.m13.1.2.2.1" xref="S3.SS1.p2.13.m13.1.2.2.1.cmml">â¢</mo><mrow id="S3.SS1.p2.13.m13.1.2.2.3.2" xref="S3.SS1.p2.13.m13.1.2.2.cmml"><mo id="S3.SS1.p2.13.m13.1.2.2.3.2.1" stretchy="false" xref="S3.SS1.p2.13.m13.1.2.2.cmml">(</mo><mi id="S3.SS1.p2.13.m13.1.1" xref="S3.SS1.p2.13.m13.1.1.cmml">ğ’™</mi><mo id="S3.SS1.p2.13.m13.1.2.2.3.2.2" stretchy="false" xref="S3.SS1.p2.13.m13.1.2.2.cmml">)</mo></mrow></mrow><mo id="S3.SS1.p2.13.m13.1.2.1" xref="S3.SS1.p2.13.m13.1.2.1.cmml">=</mo><mrow id="S3.SS1.p2.13.m13.1.2.3" xref="S3.SS1.p2.13.m13.1.2.3.cmml"><mrow id="S3.SS1.p2.13.m13.1.2.3.2" xref="S3.SS1.p2.13.m13.1.2.3.2.cmml"><msub id="S3.SS1.p2.13.m13.1.2.3.2.2" xref="S3.SS1.p2.13.m13.1.2.3.2.2.cmml"><mi id="S3.SS1.p2.13.m13.1.2.3.2.2.2" xref="S3.SS1.p2.13.m13.1.2.3.2.2.2.cmml">ğ’“</mi><mi id="S3.SS1.p2.13.m13.1.2.3.2.2.3" xref="S3.SS1.p2.13.m13.1.2.3.2.2.3.cmml">i</mi></msub><mo id="S3.SS1.p2.13.m13.1.2.3.2.1" xref="S3.SS1.p2.13.m13.1.2.3.2.1.cmml">â¢</mo><mi id="S3.SS1.p2.13.m13.1.2.3.2.3" xref="S3.SS1.p2.13.m13.1.2.3.2.3.cmml">ğ’™</mi></mrow><mo id="S3.SS1.p2.13.m13.1.2.3.1" xref="S3.SS1.p2.13.m13.1.2.3.1.cmml">+</mo><msub id="S3.SS1.p2.13.m13.1.2.3.3" xref="S3.SS1.p2.13.m13.1.2.3.3.cmml"><mi id="S3.SS1.p2.13.m13.1.2.3.3.2" xref="S3.SS1.p2.13.m13.1.2.3.3.2.cmml">ğ’ƒ</mi><mi id="S3.SS1.p2.13.m13.1.2.3.3.3" xref="S3.SS1.p2.13.m13.1.2.3.3.3.cmml">i</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.13.m13.1b"><apply id="S3.SS1.p2.13.m13.1.2.cmml" xref="S3.SS1.p2.13.m13.1.2"><eq id="S3.SS1.p2.13.m13.1.2.1.cmml" xref="S3.SS1.p2.13.m13.1.2.1"></eq><apply id="S3.SS1.p2.13.m13.1.2.2.cmml" xref="S3.SS1.p2.13.m13.1.2.2"><times id="S3.SS1.p2.13.m13.1.2.2.1.cmml" xref="S3.SS1.p2.13.m13.1.2.2.1"></times><apply id="S3.SS1.p2.13.m13.1.2.2.2.cmml" xref="S3.SS1.p2.13.m13.1.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.13.m13.1.2.2.2.1.cmml" xref="S3.SS1.p2.13.m13.1.2.2.2">subscript</csymbol><ci id="S3.SS1.p2.13.m13.1.2.2.2.2.cmml" xref="S3.SS1.p2.13.m13.1.2.2.2.2">ğ‘¡</ci><ci id="S3.SS1.p2.13.m13.1.2.2.2.3.cmml" xref="S3.SS1.p2.13.m13.1.2.2.2.3">ğ‘–</ci></apply><ci id="S3.SS1.p2.13.m13.1.1.cmml" xref="S3.SS1.p2.13.m13.1.1">ğ’™</ci></apply><apply id="S3.SS1.p2.13.m13.1.2.3.cmml" xref="S3.SS1.p2.13.m13.1.2.3"><plus id="S3.SS1.p2.13.m13.1.2.3.1.cmml" xref="S3.SS1.p2.13.m13.1.2.3.1"></plus><apply id="S3.SS1.p2.13.m13.1.2.3.2.cmml" xref="S3.SS1.p2.13.m13.1.2.3.2"><times id="S3.SS1.p2.13.m13.1.2.3.2.1.cmml" xref="S3.SS1.p2.13.m13.1.2.3.2.1"></times><apply id="S3.SS1.p2.13.m13.1.2.3.2.2.cmml" xref="S3.SS1.p2.13.m13.1.2.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.13.m13.1.2.3.2.2.1.cmml" xref="S3.SS1.p2.13.m13.1.2.3.2.2">subscript</csymbol><ci id="S3.SS1.p2.13.m13.1.2.3.2.2.2.cmml" xref="S3.SS1.p2.13.m13.1.2.3.2.2.2">ğ’“</ci><ci id="S3.SS1.p2.13.m13.1.2.3.2.2.3.cmml" xref="S3.SS1.p2.13.m13.1.2.3.2.2.3">ğ‘–</ci></apply><ci id="S3.SS1.p2.13.m13.1.2.3.2.3.cmml" xref="S3.SS1.p2.13.m13.1.2.3.2.3">ğ’™</ci></apply><apply id="S3.SS1.p2.13.m13.1.2.3.3.cmml" xref="S3.SS1.p2.13.m13.1.2.3.3"><csymbol cd="ambiguous" id="S3.SS1.p2.13.m13.1.2.3.3.1.cmml" xref="S3.SS1.p2.13.m13.1.2.3.3">subscript</csymbol><ci id="S3.SS1.p2.13.m13.1.2.3.3.2.cmml" xref="S3.SS1.p2.13.m13.1.2.3.3.2">ğ’ƒ</ci><ci id="S3.SS1.p2.13.m13.1.2.3.3.3.cmml" xref="S3.SS1.p2.13.m13.1.2.3.3.3">ğ‘–</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.13.m13.1c">t_{i}(\bm{x})=\bm{r}_{i}\bm{x}+\bm{b}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.13.m13.1d">italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( bold_italic_x ) = bold_italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT bold_italic_x + bold_italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>,
where <math alttext="\bm{r}_{i}" class="ltx_Math" display="inline" id="S3.SS1.p2.14.m14.1"><semantics id="S3.SS1.p2.14.m14.1a"><msub id="S3.SS1.p2.14.m14.1.1" xref="S3.SS1.p2.14.m14.1.1.cmml"><mi id="S3.SS1.p2.14.m14.1.1.2" xref="S3.SS1.p2.14.m14.1.1.2.cmml">ğ’“</mi><mi id="S3.SS1.p2.14.m14.1.1.3" xref="S3.SS1.p2.14.m14.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.14.m14.1b"><apply id="S3.SS1.p2.14.m14.1.1.cmml" xref="S3.SS1.p2.14.m14.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.14.m14.1.1.1.cmml" xref="S3.SS1.p2.14.m14.1.1">subscript</csymbol><ci id="S3.SS1.p2.14.m14.1.1.2.cmml" xref="S3.SS1.p2.14.m14.1.1.2">ğ’“</ci><ci id="S3.SS1.p2.14.m14.1.1.3.cmml" xref="S3.SS1.p2.14.m14.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.14.m14.1c">\bm{r}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.14.m14.1d">bold_italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is a transformation matrix within <math alttext="\mathbb{R}^{3\times 3}" class="ltx_Math" display="inline" id="S3.SS1.p2.15.m15.1"><semantics id="S3.SS1.p2.15.m15.1a"><msup id="S3.SS1.p2.15.m15.1.1" xref="S3.SS1.p2.15.m15.1.1.cmml"><mi id="S3.SS1.p2.15.m15.1.1.2" xref="S3.SS1.p2.15.m15.1.1.2.cmml">â„</mi><mrow id="S3.SS1.p2.15.m15.1.1.3" xref="S3.SS1.p2.15.m15.1.1.3.cmml"><mn id="S3.SS1.p2.15.m15.1.1.3.2" xref="S3.SS1.p2.15.m15.1.1.3.2.cmml">3</mn><mo id="S3.SS1.p2.15.m15.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p2.15.m15.1.1.3.1.cmml">Ã—</mo><mn id="S3.SS1.p2.15.m15.1.1.3.3" xref="S3.SS1.p2.15.m15.1.1.3.3.cmml">3</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.15.m15.1b"><apply id="S3.SS1.p2.15.m15.1.1.cmml" xref="S3.SS1.p2.15.m15.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.15.m15.1.1.1.cmml" xref="S3.SS1.p2.15.m15.1.1">superscript</csymbol><ci id="S3.SS1.p2.15.m15.1.1.2.cmml" xref="S3.SS1.p2.15.m15.1.1.2">â„</ci><apply id="S3.SS1.p2.15.m15.1.1.3.cmml" xref="S3.SS1.p2.15.m15.1.1.3"><times id="S3.SS1.p2.15.m15.1.1.3.1.cmml" xref="S3.SS1.p2.15.m15.1.1.3.1"></times><cn id="S3.SS1.p2.15.m15.1.1.3.2.cmml" type="integer" xref="S3.SS1.p2.15.m15.1.1.3.2">3</cn><cn id="S3.SS1.p2.15.m15.1.1.3.3.cmml" type="integer" xref="S3.SS1.p2.15.m15.1.1.3.3">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.15.m15.1c">\mathbb{R}^{3\times 3}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.15.m15.1d">blackboard_R start_POSTSUPERSCRIPT 3 Ã— 3 end_POSTSUPERSCRIPT</annotation></semantics></math>, <math alttext="\bm{x}" class="ltx_Math" display="inline" id="S3.SS1.p2.16.m16.1"><semantics id="S3.SS1.p2.16.m16.1a"><mi id="S3.SS1.p2.16.m16.1.1" xref="S3.SS1.p2.16.m16.1.1.cmml">ğ’™</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.16.m16.1b"><ci id="S3.SS1.p2.16.m16.1.1.cmml" xref="S3.SS1.p2.16.m16.1.1">ğ’™</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.16.m16.1c">\bm{x}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.16.m16.1d">bold_italic_x</annotation></semantics></math> represents the coordinates within <math alttext="\mathbb{R}^{3}" class="ltx_Math" display="inline" id="S3.SS1.p2.17.m17.1"><semantics id="S3.SS1.p2.17.m17.1a"><msup id="S3.SS1.p2.17.m17.1.1" xref="S3.SS1.p2.17.m17.1.1.cmml"><mi id="S3.SS1.p2.17.m17.1.1.2" xref="S3.SS1.p2.17.m17.1.1.2.cmml">â„</mi><mn id="S3.SS1.p2.17.m17.1.1.3" xref="S3.SS1.p2.17.m17.1.1.3.cmml">3</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.17.m17.1b"><apply id="S3.SS1.p2.17.m17.1.1.cmml" xref="S3.SS1.p2.17.m17.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.17.m17.1.1.1.cmml" xref="S3.SS1.p2.17.m17.1.1">superscript</csymbol><ci id="S3.SS1.p2.17.m17.1.1.2.cmml" xref="S3.SS1.p2.17.m17.1.1.2">â„</ci><cn id="S3.SS1.p2.17.m17.1.1.3.cmml" type="integer" xref="S3.SS1.p2.17.m17.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.17.m17.1c">\mathbb{R}^{3}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.17.m17.1d">blackboard_R start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT</annotation></semantics></math>, and <math alttext="\bm{b}_{i}" class="ltx_Math" display="inline" id="S3.SS1.p2.18.m18.1"><semantics id="S3.SS1.p2.18.m18.1a"><msub id="S3.SS1.p2.18.m18.1.1" xref="S3.SS1.p2.18.m18.1.1.cmml"><mi id="S3.SS1.p2.18.m18.1.1.2" xref="S3.SS1.p2.18.m18.1.1.2.cmml">ğ’ƒ</mi><mi id="S3.SS1.p2.18.m18.1.1.3" xref="S3.SS1.p2.18.m18.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.18.m18.1b"><apply id="S3.SS1.p2.18.m18.1.1.cmml" xref="S3.SS1.p2.18.m18.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.18.m18.1.1.1.cmml" xref="S3.SS1.p2.18.m18.1.1">subscript</csymbol><ci id="S3.SS1.p2.18.m18.1.1.2.cmml" xref="S3.SS1.p2.18.m18.1.1.2">ğ’ƒ</ci><ci id="S3.SS1.p2.18.m18.1.1.3.cmml" xref="S3.SS1.p2.18.m18.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.18.m18.1c">\bm{b}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.18.m18.1d">bold_italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is a bias vector. The initial point <math alttext="\bm{x}_{1}" class="ltx_Math" display="inline" id="S3.SS1.p2.19.m19.1"><semantics id="S3.SS1.p2.19.m19.1a"><msub id="S3.SS1.p2.19.m19.1.1" xref="S3.SS1.p2.19.m19.1.1.cmml"><mi id="S3.SS1.p2.19.m19.1.1.2" xref="S3.SS1.p2.19.m19.1.1.2.cmml">ğ’™</mi><mn id="S3.SS1.p2.19.m19.1.1.3" xref="S3.SS1.p2.19.m19.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.19.m19.1b"><apply id="S3.SS1.p2.19.m19.1.1.cmml" xref="S3.SS1.p2.19.m19.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.19.m19.1.1.1.cmml" xref="S3.SS1.p2.19.m19.1.1">subscript</csymbol><ci id="S3.SS1.p2.19.m19.1.1.2.cmml" xref="S3.SS1.p2.19.m19.1.1.2">ğ’™</ci><cn id="S3.SS1.p2.19.m19.1.1.3.cmml" type="integer" xref="S3.SS1.p2.19.m19.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.19.m19.1c">\bm{x}_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.19.m19.1d">bold_italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> is conventionally set to the origin (zero vector).
The number of affine transformations, <math alttext="n" class="ltx_Math" display="inline" id="S3.SS1.p2.20.m20.1"><semantics id="S3.SS1.p2.20.m20.1a"><mi id="S3.SS1.p2.20.m20.1.1" xref="S3.SS1.p2.20.m20.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.20.m20.1b"><ci id="S3.SS1.p2.20.m20.1.1.cmml" xref="S3.SS1.p2.20.m20.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.20.m20.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.20.m20.1d">italic_n</annotation></semantics></math>, along with the elements of each rotation matrix <math alttext="\bm{r}_{i}" class="ltx_Math" display="inline" id="S3.SS1.p2.21.m21.1"><semantics id="S3.SS1.p2.21.m21.1a"><msub id="S3.SS1.p2.21.m21.1.1" xref="S3.SS1.p2.21.m21.1.1.cmml"><mi id="S3.SS1.p2.21.m21.1.1.2" xref="S3.SS1.p2.21.m21.1.1.2.cmml">ğ’“</mi><mi id="S3.SS1.p2.21.m21.1.1.3" xref="S3.SS1.p2.21.m21.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.21.m21.1b"><apply id="S3.SS1.p2.21.m21.1.1.cmml" xref="S3.SS1.p2.21.m21.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.21.m21.1.1.1.cmml" xref="S3.SS1.p2.21.m21.1.1">subscript</csymbol><ci id="S3.SS1.p2.21.m21.1.1.2.cmml" xref="S3.SS1.p2.21.m21.1.1.2">ğ’“</ci><ci id="S3.SS1.p2.21.m21.1.1.3.cmml" xref="S3.SS1.p2.21.m21.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.21.m21.1c">\bm{r}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.21.m21.1d">bold_italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> and bias vector <math alttext="\bm{b}_{i}" class="ltx_Math" display="inline" id="S3.SS1.p2.22.m22.1"><semantics id="S3.SS1.p2.22.m22.1a"><msub id="S3.SS1.p2.22.m22.1.1" xref="S3.SS1.p2.22.m22.1.1.cmml"><mi id="S3.SS1.p2.22.m22.1.1.2" xref="S3.SS1.p2.22.m22.1.1.2.cmml">ğ’ƒ</mi><mi id="S3.SS1.p2.22.m22.1.1.3" xref="S3.SS1.p2.22.m22.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.22.m22.1b"><apply id="S3.SS1.p2.22.m22.1.1.cmml" xref="S3.SS1.p2.22.m22.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.22.m22.1.1.1.cmml" xref="S3.SS1.p2.22.m22.1.1">subscript</csymbol><ci id="S3.SS1.p2.22.m22.1.1.2.cmml" xref="S3.SS1.p2.22.m22.1.1.2">ğ’ƒ</ci><ci id="S3.SS1.p2.22.m22.1.1.3.cmml" xref="S3.SS1.p2.22.m22.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.22.m22.1c">\bm{b}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.22.m22.1d">bold_italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, are determined through random sampling from specified uniform distributions. The transformation probability, <math alttext="p_{i}" class="ltx_Math" display="inline" id="S3.SS1.p2.23.m23.1"><semantics id="S3.SS1.p2.23.m23.1a"><msub id="S3.SS1.p2.23.m23.1.1" xref="S3.SS1.p2.23.m23.1.1.cmml"><mi id="S3.SS1.p2.23.m23.1.1.2" xref="S3.SS1.p2.23.m23.1.1.2.cmml">p</mi><mi id="S3.SS1.p2.23.m23.1.1.3" xref="S3.SS1.p2.23.m23.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.23.m23.1b"><apply id="S3.SS1.p2.23.m23.1.1.cmml" xref="S3.SS1.p2.23.m23.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.23.m23.1.1.1.cmml" xref="S3.SS1.p2.23.m23.1.1">subscript</csymbol><ci id="S3.SS1.p2.23.m23.1.1.2.cmml" xref="S3.SS1.p2.23.m23.1.1.2">ğ‘</ci><ci id="S3.SS1.p2.23.m23.1.1.3.cmml" xref="S3.SS1.p2.23.m23.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.23.m23.1c">p_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.23.m23.1d">italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, is calculated proportionally to the determinant of <math alttext="\bm{r}_{i}" class="ltx_Math" display="inline" id="S3.SS1.p2.24.m24.1"><semantics id="S3.SS1.p2.24.m24.1a"><msub id="S3.SS1.p2.24.m24.1.1" xref="S3.SS1.p2.24.m24.1.1.cmml"><mi id="S3.SS1.p2.24.m24.1.1.2" xref="S3.SS1.p2.24.m24.1.1.2.cmml">ğ’“</mi><mi id="S3.SS1.p2.24.m24.1.1.3" xref="S3.SS1.p2.24.m24.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.24.m24.1b"><apply id="S3.SS1.p2.24.m24.1.1.cmml" xref="S3.SS1.p2.24.m24.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.24.m24.1.1.1.cmml" xref="S3.SS1.p2.24.m24.1.1">subscript</csymbol><ci id="S3.SS1.p2.24.m24.1.1.2.cmml" xref="S3.SS1.p2.24.m24.1.1.2">ğ’“</ci><ci id="S3.SS1.p2.24.m24.1.1.3.cmml" xref="S3.SS1.p2.24.m24.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.24.m24.1c">\bm{r}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.24.m24.1d">bold_italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, normalized by the sum of determinants for all transformations.
The final coordinate set, <math alttext="X" class="ltx_Math" display="inline" id="S3.SS1.p2.25.m25.1"><semantics id="S3.SS1.p2.25.m25.1a"><mi id="S3.SS1.p2.25.m25.1.1" xref="S3.SS1.p2.25.m25.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.25.m25.1b"><ci id="S3.SS1.p2.25.m25.1.1.cmml" xref="S3.SS1.p2.25.m25.1.1">ğ‘‹</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.25.m25.1c">X</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.25.m25.1d">italic_X</annotation></semantics></math>, comprises the sequence of coordinates generated up to a predetermined limit <math alttext="T=8192" class="ltx_Math" display="inline" id="S3.SS1.p2.26.m26.1"><semantics id="S3.SS1.p2.26.m26.1a"><mrow id="S3.SS1.p2.26.m26.1.1" xref="S3.SS1.p2.26.m26.1.1.cmml"><mi id="S3.SS1.p2.26.m26.1.1.2" xref="S3.SS1.p2.26.m26.1.1.2.cmml">T</mi><mo id="S3.SS1.p2.26.m26.1.1.1" xref="S3.SS1.p2.26.m26.1.1.1.cmml">=</mo><mn id="S3.SS1.p2.26.m26.1.1.3" xref="S3.SS1.p2.26.m26.1.1.3.cmml">8192</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.26.m26.1b"><apply id="S3.SS1.p2.26.m26.1.1.cmml" xref="S3.SS1.p2.26.m26.1.1"><eq id="S3.SS1.p2.26.m26.1.1.1.cmml" xref="S3.SS1.p2.26.m26.1.1.1"></eq><ci id="S3.SS1.p2.26.m26.1.1.2.cmml" xref="S3.SS1.p2.26.m26.1.1.2">ğ‘‡</ci><cn id="S3.SS1.p2.26.m26.1.1.3.cmml" type="integer" xref="S3.SS1.p2.26.m26.1.1.3">8192</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.26.m26.1c">T=8192</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.26.m26.1d">italic_T = 8192</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.5"><span class="ltx_text ltx_font_bold" id="S3.SS1.p3.5.1">Visual modality â€“ fractal image.</span>
We detail transforming a fractal point cloud into a fractal image by projecting it onto an image plane. This conversion employs a mapping, <math alttext="\mathcal{F}_{\text{RGB}}" class="ltx_Math" display="inline" id="S3.SS1.p3.1.m1.1"><semantics id="S3.SS1.p3.1.m1.1a"><msub id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.1.m1.1.1.2" xref="S3.SS1.p3.1.m1.1.1.2.cmml">â„±</mi><mtext id="S3.SS1.p3.1.m1.1.1.3" xref="S3.SS1.p3.1.m1.1.1.3a.cmml">RGB</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><apply id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p3.1.m1.1.1.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2">â„±</ci><ci id="S3.SS1.p3.1.m1.1.1.3a.cmml" xref="S3.SS1.p3.1.m1.1.1.3"><mtext id="S3.SS1.p3.1.m1.1.1.3.cmml" mathsize="70%" xref="S3.SS1.p3.1.m1.1.1.3">RGB</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">\mathcal{F}_{\text{RGB}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.1.m1.1d">caligraphic_F start_POSTSUBSCRIPT RGB end_POSTSUBSCRIPT</annotation></semantics></math>, which interprets the coordinates in <math alttext="X_{j}" class="ltx_Math" display="inline" id="S3.SS1.p3.2.m2.1"><semantics id="S3.SS1.p3.2.m2.1a"><msub id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml"><mi id="S3.SS1.p3.2.m2.1.1.2" xref="S3.SS1.p3.2.m2.1.1.2.cmml">X</mi><mi id="S3.SS1.p3.2.m2.1.1.3" xref="S3.SS1.p3.2.m2.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><apply id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.1.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p3.2.m2.1.1.2.cmml" xref="S3.SS1.p3.2.m2.1.1.2">ğ‘‹</ci><ci id="S3.SS1.p3.2.m2.1.1.3.cmml" xref="S3.SS1.p3.2.m2.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">X_{j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.2.m2.1d">italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> as white dots against a black background, effectively rendering the fractal geometry visually in two dimensions. To facilitate this transformation, we introduce a virtual camera, <math alttext="\bm{c}" class="ltx_Math" display="inline" id="S3.SS1.p3.3.m3.1"><semantics id="S3.SS1.p3.3.m3.1a"><mi id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml">ğ’„</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><ci id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1">ğ’„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">\bm{c}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.3.m3.1d">bold_italic_c</annotation></semantics></math>, designed to map the 3D coordinate set into a fractal image, <math alttext="I_{j}" class="ltx_Math" display="inline" id="S3.SS1.p3.4.m4.1"><semantics id="S3.SS1.p3.4.m4.1a"><msub id="S3.SS1.p3.4.m4.1.1" xref="S3.SS1.p3.4.m4.1.1.cmml"><mi id="S3.SS1.p3.4.m4.1.1.2" xref="S3.SS1.p3.4.m4.1.1.2.cmml">I</mi><mi id="S3.SS1.p3.4.m4.1.1.3" xref="S3.SS1.p3.4.m4.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.4.m4.1b"><apply id="S3.SS1.p3.4.m4.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.4.m4.1.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p3.4.m4.1.1.2.cmml" xref="S3.SS1.p3.4.m4.1.1.2">ğ¼</ci><ci id="S3.SS1.p3.4.m4.1.1.3.cmml" xref="S3.SS1.p3.4.m4.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.4.m4.1c">I_{j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.4.m4.1d">italic_I start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math>. The mapping process is succinctly represented as <math alttext="I_{j}=\mathcal{F}_{\text{RGB}}(X_{j};\bm{c})" class="ltx_Math" display="inline" id="S3.SS1.p3.5.m5.2"><semantics id="S3.SS1.p3.5.m5.2a"><mrow id="S3.SS1.p3.5.m5.2.2" xref="S3.SS1.p3.5.m5.2.2.cmml"><msub id="S3.SS1.p3.5.m5.2.2.3" xref="S3.SS1.p3.5.m5.2.2.3.cmml"><mi id="S3.SS1.p3.5.m5.2.2.3.2" xref="S3.SS1.p3.5.m5.2.2.3.2.cmml">I</mi><mi id="S3.SS1.p3.5.m5.2.2.3.3" xref="S3.SS1.p3.5.m5.2.2.3.3.cmml">j</mi></msub><mo id="S3.SS1.p3.5.m5.2.2.2" xref="S3.SS1.p3.5.m5.2.2.2.cmml">=</mo><mrow id="S3.SS1.p3.5.m5.2.2.1" xref="S3.SS1.p3.5.m5.2.2.1.cmml"><msub id="S3.SS1.p3.5.m5.2.2.1.3" xref="S3.SS1.p3.5.m5.2.2.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.5.m5.2.2.1.3.2" xref="S3.SS1.p3.5.m5.2.2.1.3.2.cmml">â„±</mi><mtext id="S3.SS1.p3.5.m5.2.2.1.3.3" xref="S3.SS1.p3.5.m5.2.2.1.3.3a.cmml">RGB</mtext></msub><mo id="S3.SS1.p3.5.m5.2.2.1.2" xref="S3.SS1.p3.5.m5.2.2.1.2.cmml">â¢</mo><mrow id="S3.SS1.p3.5.m5.2.2.1.1.1" xref="S3.SS1.p3.5.m5.2.2.1.1.2.cmml"><mo id="S3.SS1.p3.5.m5.2.2.1.1.1.2" stretchy="false" xref="S3.SS1.p3.5.m5.2.2.1.1.2.cmml">(</mo><msub id="S3.SS1.p3.5.m5.2.2.1.1.1.1" xref="S3.SS1.p3.5.m5.2.2.1.1.1.1.cmml"><mi id="S3.SS1.p3.5.m5.2.2.1.1.1.1.2" xref="S3.SS1.p3.5.m5.2.2.1.1.1.1.2.cmml">X</mi><mi id="S3.SS1.p3.5.m5.2.2.1.1.1.1.3" xref="S3.SS1.p3.5.m5.2.2.1.1.1.1.3.cmml">j</mi></msub><mo id="S3.SS1.p3.5.m5.2.2.1.1.1.3" xref="S3.SS1.p3.5.m5.2.2.1.1.2.cmml">;</mo><mi id="S3.SS1.p3.5.m5.1.1" xref="S3.SS1.p3.5.m5.1.1.cmml">ğ’„</mi><mo id="S3.SS1.p3.5.m5.2.2.1.1.1.4" stretchy="false" xref="S3.SS1.p3.5.m5.2.2.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.5.m5.2b"><apply id="S3.SS1.p3.5.m5.2.2.cmml" xref="S3.SS1.p3.5.m5.2.2"><eq id="S3.SS1.p3.5.m5.2.2.2.cmml" xref="S3.SS1.p3.5.m5.2.2.2"></eq><apply id="S3.SS1.p3.5.m5.2.2.3.cmml" xref="S3.SS1.p3.5.m5.2.2.3"><csymbol cd="ambiguous" id="S3.SS1.p3.5.m5.2.2.3.1.cmml" xref="S3.SS1.p3.5.m5.2.2.3">subscript</csymbol><ci id="S3.SS1.p3.5.m5.2.2.3.2.cmml" xref="S3.SS1.p3.5.m5.2.2.3.2">ğ¼</ci><ci id="S3.SS1.p3.5.m5.2.2.3.3.cmml" xref="S3.SS1.p3.5.m5.2.2.3.3">ğ‘—</ci></apply><apply id="S3.SS1.p3.5.m5.2.2.1.cmml" xref="S3.SS1.p3.5.m5.2.2.1"><times id="S3.SS1.p3.5.m5.2.2.1.2.cmml" xref="S3.SS1.p3.5.m5.2.2.1.2"></times><apply id="S3.SS1.p3.5.m5.2.2.1.3.cmml" xref="S3.SS1.p3.5.m5.2.2.1.3"><csymbol cd="ambiguous" id="S3.SS1.p3.5.m5.2.2.1.3.1.cmml" xref="S3.SS1.p3.5.m5.2.2.1.3">subscript</csymbol><ci id="S3.SS1.p3.5.m5.2.2.1.3.2.cmml" xref="S3.SS1.p3.5.m5.2.2.1.3.2">â„±</ci><ci id="S3.SS1.p3.5.m5.2.2.1.3.3a.cmml" xref="S3.SS1.p3.5.m5.2.2.1.3.3"><mtext id="S3.SS1.p3.5.m5.2.2.1.3.3.cmml" mathsize="70%" xref="S3.SS1.p3.5.m5.2.2.1.3.3">RGB</mtext></ci></apply><list id="S3.SS1.p3.5.m5.2.2.1.1.2.cmml" xref="S3.SS1.p3.5.m5.2.2.1.1.1"><apply id="S3.SS1.p3.5.m5.2.2.1.1.1.1.cmml" xref="S3.SS1.p3.5.m5.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.5.m5.2.2.1.1.1.1.1.cmml" xref="S3.SS1.p3.5.m5.2.2.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p3.5.m5.2.2.1.1.1.1.2.cmml" xref="S3.SS1.p3.5.m5.2.2.1.1.1.1.2">ğ‘‹</ci><ci id="S3.SS1.p3.5.m5.2.2.1.1.1.1.3.cmml" xref="S3.SS1.p3.5.m5.2.2.1.1.1.1.3">ğ‘—</ci></apply><ci id="S3.SS1.p3.5.m5.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1">ğ’„</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.5.m5.2c">I_{j}=\mathcal{F}_{\text{RGB}}(X_{j};\bm{c})</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.5.m5.2d">italic_I start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT = caligraphic_F start_POSTSUBSCRIPT RGB end_POSTSUBSCRIPT ( italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ; bold_italic_c )</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.3">To ensure a precise alignment between the fractal images and their corresponding fractal point cloudsâ€”thus maintaining a coherent pairing of visual and geometric dataâ€”we allocate one virtual camera, <math alttext="\bm{c}_{v}" class="ltx_Math" display="inline" id="S3.SS1.p4.1.m1.1"><semantics id="S3.SS1.p4.1.m1.1a"><msub id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml"><mi id="S3.SS1.p4.1.m1.1.1.2" xref="S3.SS1.p4.1.m1.1.1.2.cmml">ğ’„</mi><mi id="S3.SS1.p4.1.m1.1.1.3" xref="S3.SS1.p4.1.m1.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><apply id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.1.m1.1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p4.1.m1.1.1.2.cmml" xref="S3.SS1.p4.1.m1.1.1.2">ğ’„</ci><ci id="S3.SS1.p4.1.m1.1.1.3.cmml" xref="S3.SS1.p4.1.m1.1.1.3">ğ‘£</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">\bm{c}_{v}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.1.m1.1d">bold_italic_c start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT</annotation></semantics></math>, per fractal point cloud, where <math alttext="v=1" class="ltx_Math" display="inline" id="S3.SS1.p4.2.m2.1"><semantics id="S3.SS1.p4.2.m2.1a"><mrow id="S3.SS1.p4.2.m2.1.1" xref="S3.SS1.p4.2.m2.1.1.cmml"><mi id="S3.SS1.p4.2.m2.1.1.2" xref="S3.SS1.p4.2.m2.1.1.2.cmml">v</mi><mo id="S3.SS1.p4.2.m2.1.1.1" xref="S3.SS1.p4.2.m2.1.1.1.cmml">=</mo><mn id="S3.SS1.p4.2.m2.1.1.3" xref="S3.SS1.p4.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m2.1b"><apply id="S3.SS1.p4.2.m2.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1"><eq id="S3.SS1.p4.2.m2.1.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1.1"></eq><ci id="S3.SS1.p4.2.m2.1.1.2.cmml" xref="S3.SS1.p4.2.m2.1.1.2">ğ‘£</ci><cn id="S3.SS1.p4.2.m2.1.1.3.cmml" type="integer" xref="S3.SS1.p4.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m2.1c">v=1</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.2.m2.1d">italic_v = 1</annotation></semantics></math>. The chosen method for projection is perspective projection, offering a realistic spatial representation. The positioning of the virtual camera is determined randomly but is strategically placed on a sphere that centers around the fractal objectâ€™s center of gravity, optimizing the view of the fractalâ€™s intricate structures.
The fractal image size is set to <math alttext="(W,H)=(224,224)" class="ltx_Math" display="inline" id="S3.SS1.p4.3.m3.4"><semantics id="S3.SS1.p4.3.m3.4a"><mrow id="S3.SS1.p4.3.m3.4.5" xref="S3.SS1.p4.3.m3.4.5.cmml"><mrow id="S3.SS1.p4.3.m3.4.5.2.2" xref="S3.SS1.p4.3.m3.4.5.2.1.cmml"><mo id="S3.SS1.p4.3.m3.4.5.2.2.1" stretchy="false" xref="S3.SS1.p4.3.m3.4.5.2.1.cmml">(</mo><mi id="S3.SS1.p4.3.m3.1.1" xref="S3.SS1.p4.3.m3.1.1.cmml">W</mi><mo id="S3.SS1.p4.3.m3.4.5.2.2.2" xref="S3.SS1.p4.3.m3.4.5.2.1.cmml">,</mo><mi id="S3.SS1.p4.3.m3.2.2" xref="S3.SS1.p4.3.m3.2.2.cmml">H</mi><mo id="S3.SS1.p4.3.m3.4.5.2.2.3" stretchy="false" xref="S3.SS1.p4.3.m3.4.5.2.1.cmml">)</mo></mrow><mo id="S3.SS1.p4.3.m3.4.5.1" xref="S3.SS1.p4.3.m3.4.5.1.cmml">=</mo><mrow id="S3.SS1.p4.3.m3.4.5.3.2" xref="S3.SS1.p4.3.m3.4.5.3.1.cmml"><mo id="S3.SS1.p4.3.m3.4.5.3.2.1" stretchy="false" xref="S3.SS1.p4.3.m3.4.5.3.1.cmml">(</mo><mn id="S3.SS1.p4.3.m3.3.3" xref="S3.SS1.p4.3.m3.3.3.cmml">224</mn><mo id="S3.SS1.p4.3.m3.4.5.3.2.2" xref="S3.SS1.p4.3.m3.4.5.3.1.cmml">,</mo><mn id="S3.SS1.p4.3.m3.4.4" xref="S3.SS1.p4.3.m3.4.4.cmml">224</mn><mo id="S3.SS1.p4.3.m3.4.5.3.2.3" stretchy="false" xref="S3.SS1.p4.3.m3.4.5.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.3.m3.4b"><apply id="S3.SS1.p4.3.m3.4.5.cmml" xref="S3.SS1.p4.3.m3.4.5"><eq id="S3.SS1.p4.3.m3.4.5.1.cmml" xref="S3.SS1.p4.3.m3.4.5.1"></eq><interval closure="open" id="S3.SS1.p4.3.m3.4.5.2.1.cmml" xref="S3.SS1.p4.3.m3.4.5.2.2"><ci id="S3.SS1.p4.3.m3.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1">ğ‘Š</ci><ci id="S3.SS1.p4.3.m3.2.2.cmml" xref="S3.SS1.p4.3.m3.2.2">ğ»</ci></interval><interval closure="open" id="S3.SS1.p4.3.m3.4.5.3.1.cmml" xref="S3.SS1.p4.3.m3.4.5.3.2"><cn id="S3.SS1.p4.3.m3.3.3.cmml" type="integer" xref="S3.SS1.p4.3.m3.3.3">224</cn><cn id="S3.SS1.p4.3.m3.4.4.cmml" type="integer" xref="S3.SS1.p4.3.m3.4.4">224</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.3.m3.4c">(W,H)=(224,224)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.3.m3.4d">( italic_W , italic_H ) = ( 224 , 224 )</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p5">
<p class="ltx_p" id="S3.SS1.p5.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p5.1.1">Formula-supervised consistency label.</span>
We introduce a new approach that assigns formula-based supervision, termed â€œformula-supervised consistency labels,â€ to fractal images and fractal point clouds, originating from a unified mathematical formula (see FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S3.F2" title="Figure 2 â€£ 3 Formula-supervised visual-geometric pre-training â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">2</span></a> Left). These labels emerge from mathematical formulas, enabling the definition of common labels across modalitiesâ€”a process traditionally requiring costly and specialized pre-processing to map images to point clouds and vice versa. Moreover, formula-supervised consistency labels facilitate the simultaneous input of fractal images and fractal point clouds into a unified transformer model, promoting learning within a shared label space.</p>
</div>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="365" id="S3.F3.g1" src="x3.png" width="789"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F3.5.1.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text ltx_font_bold" id="S3.F3.6.2" style="font-size:90%;">VG-FractalDB pre-training.<span class="ltx_text ltx_font_medium" id="S3.F3.6.2.1"> </span>Left:<span class="ltx_text ltx_font_medium" id="S3.F3.6.2.2"> We trains VG-FractalDB on a unified transformer model. After pre-training, we can fine-tune the image and 3D object recognition by using the same unified transformer model. </span>Right:<span class="ltx_text ltx_font_medium" id="S3.F3.6.2.3"> FSVGP learns visual and geometric modalities by supervised pre-training based on a formula-supervised consistency label. Therefore, FSVGP can train different modalities within a common label space on a unified transformer model.
</span></span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.p6">
<p class="ltx_p" id="S3.SS1.p6.2">As described above, a fractal category <math alttext="c" class="ltx_Math" display="inline" id="S3.SS1.p6.1.m1.1"><semantics id="S3.SS1.p6.1.m1.1a"><mi id="S3.SS1.p6.1.m1.1.1" xref="S3.SS1.p6.1.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.1.m1.1b"><ci id="S3.SS1.p6.1.m1.1.1.cmml" xref="S3.SS1.p6.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.1.m1.1c">c</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p6.1.m1.1d">italic_c</annotation></semantics></math> is defined by 3D-IFS <math alttext="\Theta^{c}" class="ltx_Math" display="inline" id="S3.SS1.p6.2.m2.1"><semantics id="S3.SS1.p6.2.m2.1a"><msup id="S3.SS1.p6.2.m2.1.1" xref="S3.SS1.p6.2.m2.1.1.cmml"><mi id="S3.SS1.p6.2.m2.1.1.2" mathvariant="normal" xref="S3.SS1.p6.2.m2.1.1.2.cmml">Î˜</mi><mi id="S3.SS1.p6.2.m2.1.1.3" xref="S3.SS1.p6.2.m2.1.1.3.cmml">c</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.2.m2.1b"><apply id="S3.SS1.p6.2.m2.1.1.cmml" xref="S3.SS1.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.2.m2.1.1.1.cmml" xref="S3.SS1.p6.2.m2.1.1">superscript</csymbol><ci id="S3.SS1.p6.2.m2.1.1.2.cmml" xref="S3.SS1.p6.2.m2.1.1.2">Î˜</ci><ci id="S3.SS1.p6.2.m2.1.1.3.cmml" xref="S3.SS1.p6.2.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.2.m2.1c">\Theta^{c}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p6.2.m2.1d">roman_Î˜ start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT</annotation></semantics></math>. A 3D fractal point cloud is generated by the 3D-IFS and is projected onto a 2D image plane to generate a 2D fractal image. Therefore, the 2D fractal image and 3D fractal point cloud share the consistent label.
To remove ineffective fractal categories, we employ a variance threshold criterion.
This algorithm assesses whether the variance of a fractal category exceeds a predefined threshold (0.05) along each coordinate axis. We determined the threshold with reference toÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib44" title="">44</a>]</cite>.
In other words, we only define fractal point clouds that are above the threshold as a fractal category.
To enrich the diversity of instances within each fractal category, we implement a technique named FractalNoiseMix, as described inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib44" title="">44</a>]</cite>. This method integrates an additional 20% of points generated from randomly selected fractal point clouds in VG-FractalDB, enhancing the datasetâ€™s robustness and variability.
Further details on VG-FractalDB, including examples and parameter specifications, are available in the <span class="ltx_text" id="S3.SS1.p6.2.1" style="color:#FF0000;">Supplementary Material</span>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>VG-FractalDB Pre-training on a unified transformer model</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">To train VG-FractalDB with a unified transformer model, we modified the ViT and PointT to input a fractal image and a fractal point cloud simultaneously, as shown in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S3.F3" title="Figure 3 â€£ 3.1 Visual-geometric fractal database (VG-FractalDB) â€£ 3 Formula-supervised visual-geometric pre-training â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">3</span></a> Left. Our modifications were limited to the input processing, ensuring the transformer model remains as straightforward as possible. This approach maintains the modelâ€™s adaptability to various tasks without compromising its pre-training flexibility.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.6">For embedding vectors specific to each modality, we utilized ViT for fractal images and PointT for fractal point clouds. Specifically, a fractal image and a fractal point cloud are divided and embedded into the image tokens <math alttext="\mathbf{z}_{\mathrm{i}}=[x_{\mathrm{class}},\mathbf{z}_{\mathrm{i}}^{1},%
\mathbf{z}_{\mathrm{i}}^{2},\dots,\mathbf{z}_{\mathrm{i}}^{M_{\mathrm{i}}}]" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.5"><semantics id="S3.SS2.p2.1.m1.5a"><mrow id="S3.SS2.p2.1.m1.5.5" xref="S3.SS2.p2.1.m1.5.5.cmml"><msub id="S3.SS2.p2.1.m1.5.5.6" xref="S3.SS2.p2.1.m1.5.5.6.cmml"><mi id="S3.SS2.p2.1.m1.5.5.6.2" xref="S3.SS2.p2.1.m1.5.5.6.2.cmml">ğ³</mi><mi id="S3.SS2.p2.1.m1.5.5.6.3" mathvariant="normal" xref="S3.SS2.p2.1.m1.5.5.6.3.cmml">i</mi></msub><mo id="S3.SS2.p2.1.m1.5.5.5" xref="S3.SS2.p2.1.m1.5.5.5.cmml">=</mo><mrow id="S3.SS2.p2.1.m1.5.5.4.4" xref="S3.SS2.p2.1.m1.5.5.4.5.cmml"><mo id="S3.SS2.p2.1.m1.5.5.4.4.5" stretchy="false" xref="S3.SS2.p2.1.m1.5.5.4.5.cmml">[</mo><msub id="S3.SS2.p2.1.m1.2.2.1.1.1" xref="S3.SS2.p2.1.m1.2.2.1.1.1.cmml"><mi id="S3.SS2.p2.1.m1.2.2.1.1.1.2" xref="S3.SS2.p2.1.m1.2.2.1.1.1.2.cmml">x</mi><mi id="S3.SS2.p2.1.m1.2.2.1.1.1.3" xref="S3.SS2.p2.1.m1.2.2.1.1.1.3.cmml">class</mi></msub><mo id="S3.SS2.p2.1.m1.5.5.4.4.6" xref="S3.SS2.p2.1.m1.5.5.4.5.cmml">,</mo><msubsup id="S3.SS2.p2.1.m1.3.3.2.2.2" xref="S3.SS2.p2.1.m1.3.3.2.2.2.cmml"><mi id="S3.SS2.p2.1.m1.3.3.2.2.2.2.2" xref="S3.SS2.p2.1.m1.3.3.2.2.2.2.2.cmml">ğ³</mi><mi id="S3.SS2.p2.1.m1.3.3.2.2.2.2.3" mathvariant="normal" xref="S3.SS2.p2.1.m1.3.3.2.2.2.2.3.cmml">i</mi><mn id="S3.SS2.p2.1.m1.3.3.2.2.2.3" xref="S3.SS2.p2.1.m1.3.3.2.2.2.3.cmml">1</mn></msubsup><mo id="S3.SS2.p2.1.m1.5.5.4.4.7" xref="S3.SS2.p2.1.m1.5.5.4.5.cmml">,</mo><msubsup id="S3.SS2.p2.1.m1.4.4.3.3.3" xref="S3.SS2.p2.1.m1.4.4.3.3.3.cmml"><mi id="S3.SS2.p2.1.m1.4.4.3.3.3.2.2" xref="S3.SS2.p2.1.m1.4.4.3.3.3.2.2.cmml">ğ³</mi><mi id="S3.SS2.p2.1.m1.4.4.3.3.3.2.3" mathvariant="normal" xref="S3.SS2.p2.1.m1.4.4.3.3.3.2.3.cmml">i</mi><mn id="S3.SS2.p2.1.m1.4.4.3.3.3.3" xref="S3.SS2.p2.1.m1.4.4.3.3.3.3.cmml">2</mn></msubsup><mo id="S3.SS2.p2.1.m1.5.5.4.4.8" xref="S3.SS2.p2.1.m1.5.5.4.5.cmml">,</mo><mi id="S3.SS2.p2.1.m1.1.1" mathvariant="normal" xref="S3.SS2.p2.1.m1.1.1.cmml">â€¦</mi><mo id="S3.SS2.p2.1.m1.5.5.4.4.9" xref="S3.SS2.p2.1.m1.5.5.4.5.cmml">,</mo><msubsup id="S3.SS2.p2.1.m1.5.5.4.4.4" xref="S3.SS2.p2.1.m1.5.5.4.4.4.cmml"><mi id="S3.SS2.p2.1.m1.5.5.4.4.4.2.2" xref="S3.SS2.p2.1.m1.5.5.4.4.4.2.2.cmml">ğ³</mi><mi id="S3.SS2.p2.1.m1.5.5.4.4.4.2.3" mathvariant="normal" xref="S3.SS2.p2.1.m1.5.5.4.4.4.2.3.cmml">i</mi><msub id="S3.SS2.p2.1.m1.5.5.4.4.4.3" xref="S3.SS2.p2.1.m1.5.5.4.4.4.3.cmml"><mi id="S3.SS2.p2.1.m1.5.5.4.4.4.3.2" xref="S3.SS2.p2.1.m1.5.5.4.4.4.3.2.cmml">M</mi><mi id="S3.SS2.p2.1.m1.5.5.4.4.4.3.3" mathvariant="normal" xref="S3.SS2.p2.1.m1.5.5.4.4.4.3.3.cmml">i</mi></msub></msubsup><mo id="S3.SS2.p2.1.m1.5.5.4.4.10" stretchy="false" xref="S3.SS2.p2.1.m1.5.5.4.5.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.5b"><apply id="S3.SS2.p2.1.m1.5.5.cmml" xref="S3.SS2.p2.1.m1.5.5"><eq id="S3.SS2.p2.1.m1.5.5.5.cmml" xref="S3.SS2.p2.1.m1.5.5.5"></eq><apply id="S3.SS2.p2.1.m1.5.5.6.cmml" xref="S3.SS2.p2.1.m1.5.5.6"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.5.5.6.1.cmml" xref="S3.SS2.p2.1.m1.5.5.6">subscript</csymbol><ci id="S3.SS2.p2.1.m1.5.5.6.2.cmml" xref="S3.SS2.p2.1.m1.5.5.6.2">ğ³</ci><ci id="S3.SS2.p2.1.m1.5.5.6.3.cmml" xref="S3.SS2.p2.1.m1.5.5.6.3">i</ci></apply><list id="S3.SS2.p2.1.m1.5.5.4.5.cmml" xref="S3.SS2.p2.1.m1.5.5.4.4"><apply id="S3.SS2.p2.1.m1.2.2.1.1.1.cmml" xref="S3.SS2.p2.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.2.2.1.1.1.2">ğ‘¥</ci><ci id="S3.SS2.p2.1.m1.2.2.1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.2.2.1.1.1.3">class</ci></apply><apply id="S3.SS2.p2.1.m1.3.3.2.2.2.cmml" xref="S3.SS2.p2.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.3.3.2.2.2.1.cmml" xref="S3.SS2.p2.1.m1.3.3.2.2.2">superscript</csymbol><apply id="S3.SS2.p2.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS2.p2.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.3.3.2.2.2.2.1.cmml" xref="S3.SS2.p2.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.SS2.p2.1.m1.3.3.2.2.2.2.2.cmml" xref="S3.SS2.p2.1.m1.3.3.2.2.2.2.2">ğ³</ci><ci id="S3.SS2.p2.1.m1.3.3.2.2.2.2.3.cmml" xref="S3.SS2.p2.1.m1.3.3.2.2.2.2.3">i</ci></apply><cn id="S3.SS2.p2.1.m1.3.3.2.2.2.3.cmml" type="integer" xref="S3.SS2.p2.1.m1.3.3.2.2.2.3">1</cn></apply><apply id="S3.SS2.p2.1.m1.4.4.3.3.3.cmml" xref="S3.SS2.p2.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.4.4.3.3.3.1.cmml" xref="S3.SS2.p2.1.m1.4.4.3.3.3">superscript</csymbol><apply id="S3.SS2.p2.1.m1.4.4.3.3.3.2.cmml" xref="S3.SS2.p2.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.4.4.3.3.3.2.1.cmml" xref="S3.SS2.p2.1.m1.4.4.3.3.3">subscript</csymbol><ci id="S3.SS2.p2.1.m1.4.4.3.3.3.2.2.cmml" xref="S3.SS2.p2.1.m1.4.4.3.3.3.2.2">ğ³</ci><ci id="S3.SS2.p2.1.m1.4.4.3.3.3.2.3.cmml" xref="S3.SS2.p2.1.m1.4.4.3.3.3.2.3">i</ci></apply><cn id="S3.SS2.p2.1.m1.4.4.3.3.3.3.cmml" type="integer" xref="S3.SS2.p2.1.m1.4.4.3.3.3.3">2</cn></apply><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">â€¦</ci><apply id="S3.SS2.p2.1.m1.5.5.4.4.4.cmml" xref="S3.SS2.p2.1.m1.5.5.4.4.4"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.5.5.4.4.4.1.cmml" xref="S3.SS2.p2.1.m1.5.5.4.4.4">superscript</csymbol><apply id="S3.SS2.p2.1.m1.5.5.4.4.4.2.cmml" xref="S3.SS2.p2.1.m1.5.5.4.4.4"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.5.5.4.4.4.2.1.cmml" xref="S3.SS2.p2.1.m1.5.5.4.4.4">subscript</csymbol><ci id="S3.SS2.p2.1.m1.5.5.4.4.4.2.2.cmml" xref="S3.SS2.p2.1.m1.5.5.4.4.4.2.2">ğ³</ci><ci id="S3.SS2.p2.1.m1.5.5.4.4.4.2.3.cmml" xref="S3.SS2.p2.1.m1.5.5.4.4.4.2.3">i</ci></apply><apply id="S3.SS2.p2.1.m1.5.5.4.4.4.3.cmml" xref="S3.SS2.p2.1.m1.5.5.4.4.4.3"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.5.5.4.4.4.3.1.cmml" xref="S3.SS2.p2.1.m1.5.5.4.4.4.3">subscript</csymbol><ci id="S3.SS2.p2.1.m1.5.5.4.4.4.3.2.cmml" xref="S3.SS2.p2.1.m1.5.5.4.4.4.3.2">ğ‘€</ci><ci id="S3.SS2.p2.1.m1.5.5.4.4.4.3.3.cmml" xref="S3.SS2.p2.1.m1.5.5.4.4.4.3.3">i</ci></apply></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.5c">\mathbf{z}_{\mathrm{i}}=[x_{\mathrm{class}},\mathbf{z}_{\mathrm{i}}^{1},%
\mathbf{z}_{\mathrm{i}}^{2},\dots,\mathbf{z}_{\mathrm{i}}^{M_{\mathrm{i}}}]</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.5d">bold_z start_POSTSUBSCRIPT roman_i end_POSTSUBSCRIPT = [ italic_x start_POSTSUBSCRIPT roman_class end_POSTSUBSCRIPT , bold_z start_POSTSUBSCRIPT roman_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , bold_z start_POSTSUBSCRIPT roman_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , â€¦ , bold_z start_POSTSUBSCRIPT roman_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_M start_POSTSUBSCRIPT roman_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ]</annotation></semantics></math> and point cloud tokens <math alttext="\mathbf{z}_{\mathrm{p}}=[x_{\mathrm{class}},\mathbf{z}_{\mathrm{p}}^{1},%
\mathbf{z}_{\mathrm{p}}^{2},\dots,\mathbf{z}_{\mathrm{p}}^{M_{\mathrm{p}}}]" class="ltx_Math" display="inline" id="S3.SS2.p2.2.m2.5"><semantics id="S3.SS2.p2.2.m2.5a"><mrow id="S3.SS2.p2.2.m2.5.5" xref="S3.SS2.p2.2.m2.5.5.cmml"><msub id="S3.SS2.p2.2.m2.5.5.6" xref="S3.SS2.p2.2.m2.5.5.6.cmml"><mi id="S3.SS2.p2.2.m2.5.5.6.2" xref="S3.SS2.p2.2.m2.5.5.6.2.cmml">ğ³</mi><mi id="S3.SS2.p2.2.m2.5.5.6.3" mathvariant="normal" xref="S3.SS2.p2.2.m2.5.5.6.3.cmml">p</mi></msub><mo id="S3.SS2.p2.2.m2.5.5.5" xref="S3.SS2.p2.2.m2.5.5.5.cmml">=</mo><mrow id="S3.SS2.p2.2.m2.5.5.4.4" xref="S3.SS2.p2.2.m2.5.5.4.5.cmml"><mo id="S3.SS2.p2.2.m2.5.5.4.4.5" stretchy="false" xref="S3.SS2.p2.2.m2.5.5.4.5.cmml">[</mo><msub id="S3.SS2.p2.2.m2.2.2.1.1.1" xref="S3.SS2.p2.2.m2.2.2.1.1.1.cmml"><mi id="S3.SS2.p2.2.m2.2.2.1.1.1.2" xref="S3.SS2.p2.2.m2.2.2.1.1.1.2.cmml">x</mi><mi id="S3.SS2.p2.2.m2.2.2.1.1.1.3" xref="S3.SS2.p2.2.m2.2.2.1.1.1.3.cmml">class</mi></msub><mo id="S3.SS2.p2.2.m2.5.5.4.4.6" xref="S3.SS2.p2.2.m2.5.5.4.5.cmml">,</mo><msubsup id="S3.SS2.p2.2.m2.3.3.2.2.2" xref="S3.SS2.p2.2.m2.3.3.2.2.2.cmml"><mi id="S3.SS2.p2.2.m2.3.3.2.2.2.2.2" xref="S3.SS2.p2.2.m2.3.3.2.2.2.2.2.cmml">ğ³</mi><mi id="S3.SS2.p2.2.m2.3.3.2.2.2.2.3" mathvariant="normal" xref="S3.SS2.p2.2.m2.3.3.2.2.2.2.3.cmml">p</mi><mn id="S3.SS2.p2.2.m2.3.3.2.2.2.3" xref="S3.SS2.p2.2.m2.3.3.2.2.2.3.cmml">1</mn></msubsup><mo id="S3.SS2.p2.2.m2.5.5.4.4.7" xref="S3.SS2.p2.2.m2.5.5.4.5.cmml">,</mo><msubsup id="S3.SS2.p2.2.m2.4.4.3.3.3" xref="S3.SS2.p2.2.m2.4.4.3.3.3.cmml"><mi id="S3.SS2.p2.2.m2.4.4.3.3.3.2.2" xref="S3.SS2.p2.2.m2.4.4.3.3.3.2.2.cmml">ğ³</mi><mi id="S3.SS2.p2.2.m2.4.4.3.3.3.2.3" mathvariant="normal" xref="S3.SS2.p2.2.m2.4.4.3.3.3.2.3.cmml">p</mi><mn id="S3.SS2.p2.2.m2.4.4.3.3.3.3" xref="S3.SS2.p2.2.m2.4.4.3.3.3.3.cmml">2</mn></msubsup><mo id="S3.SS2.p2.2.m2.5.5.4.4.8" xref="S3.SS2.p2.2.m2.5.5.4.5.cmml">,</mo><mi id="S3.SS2.p2.2.m2.1.1" mathvariant="normal" xref="S3.SS2.p2.2.m2.1.1.cmml">â€¦</mi><mo id="S3.SS2.p2.2.m2.5.5.4.4.9" xref="S3.SS2.p2.2.m2.5.5.4.5.cmml">,</mo><msubsup id="S3.SS2.p2.2.m2.5.5.4.4.4" xref="S3.SS2.p2.2.m2.5.5.4.4.4.cmml"><mi id="S3.SS2.p2.2.m2.5.5.4.4.4.2.2" xref="S3.SS2.p2.2.m2.5.5.4.4.4.2.2.cmml">ğ³</mi><mi id="S3.SS2.p2.2.m2.5.5.4.4.4.2.3" mathvariant="normal" xref="S3.SS2.p2.2.m2.5.5.4.4.4.2.3.cmml">p</mi><msub id="S3.SS2.p2.2.m2.5.5.4.4.4.3" xref="S3.SS2.p2.2.m2.5.5.4.4.4.3.cmml"><mi id="S3.SS2.p2.2.m2.5.5.4.4.4.3.2" xref="S3.SS2.p2.2.m2.5.5.4.4.4.3.2.cmml">M</mi><mi id="S3.SS2.p2.2.m2.5.5.4.4.4.3.3" mathvariant="normal" xref="S3.SS2.p2.2.m2.5.5.4.4.4.3.3.cmml">p</mi></msub></msubsup><mo id="S3.SS2.p2.2.m2.5.5.4.4.10" stretchy="false" xref="S3.SS2.p2.2.m2.5.5.4.5.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.5b"><apply id="S3.SS2.p2.2.m2.5.5.cmml" xref="S3.SS2.p2.2.m2.5.5"><eq id="S3.SS2.p2.2.m2.5.5.5.cmml" xref="S3.SS2.p2.2.m2.5.5.5"></eq><apply id="S3.SS2.p2.2.m2.5.5.6.cmml" xref="S3.SS2.p2.2.m2.5.5.6"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.5.5.6.1.cmml" xref="S3.SS2.p2.2.m2.5.5.6">subscript</csymbol><ci id="S3.SS2.p2.2.m2.5.5.6.2.cmml" xref="S3.SS2.p2.2.m2.5.5.6.2">ğ³</ci><ci id="S3.SS2.p2.2.m2.5.5.6.3.cmml" xref="S3.SS2.p2.2.m2.5.5.6.3">p</ci></apply><list id="S3.SS2.p2.2.m2.5.5.4.5.cmml" xref="S3.SS2.p2.2.m2.5.5.4.4"><apply id="S3.SS2.p2.2.m2.2.2.1.1.1.cmml" xref="S3.SS2.p2.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.2.2.1.1.1.1.cmml" xref="S3.SS2.p2.2.m2.2.2.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.2.m2.2.2.1.1.1.2.cmml" xref="S3.SS2.p2.2.m2.2.2.1.1.1.2">ğ‘¥</ci><ci id="S3.SS2.p2.2.m2.2.2.1.1.1.3.cmml" xref="S3.SS2.p2.2.m2.2.2.1.1.1.3">class</ci></apply><apply id="S3.SS2.p2.2.m2.3.3.2.2.2.cmml" xref="S3.SS2.p2.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.3.3.2.2.2.1.cmml" xref="S3.SS2.p2.2.m2.3.3.2.2.2">superscript</csymbol><apply id="S3.SS2.p2.2.m2.3.3.2.2.2.2.cmml" xref="S3.SS2.p2.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.3.3.2.2.2.2.1.cmml" xref="S3.SS2.p2.2.m2.3.3.2.2.2">subscript</csymbol><ci id="S3.SS2.p2.2.m2.3.3.2.2.2.2.2.cmml" xref="S3.SS2.p2.2.m2.3.3.2.2.2.2.2">ğ³</ci><ci id="S3.SS2.p2.2.m2.3.3.2.2.2.2.3.cmml" xref="S3.SS2.p2.2.m2.3.3.2.2.2.2.3">p</ci></apply><cn id="S3.SS2.p2.2.m2.3.3.2.2.2.3.cmml" type="integer" xref="S3.SS2.p2.2.m2.3.3.2.2.2.3">1</cn></apply><apply id="S3.SS2.p2.2.m2.4.4.3.3.3.cmml" xref="S3.SS2.p2.2.m2.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.4.4.3.3.3.1.cmml" xref="S3.SS2.p2.2.m2.4.4.3.3.3">superscript</csymbol><apply id="S3.SS2.p2.2.m2.4.4.3.3.3.2.cmml" xref="S3.SS2.p2.2.m2.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.4.4.3.3.3.2.1.cmml" xref="S3.SS2.p2.2.m2.4.4.3.3.3">subscript</csymbol><ci id="S3.SS2.p2.2.m2.4.4.3.3.3.2.2.cmml" xref="S3.SS2.p2.2.m2.4.4.3.3.3.2.2">ğ³</ci><ci id="S3.SS2.p2.2.m2.4.4.3.3.3.2.3.cmml" xref="S3.SS2.p2.2.m2.4.4.3.3.3.2.3">p</ci></apply><cn id="S3.SS2.p2.2.m2.4.4.3.3.3.3.cmml" type="integer" xref="S3.SS2.p2.2.m2.4.4.3.3.3.3">2</cn></apply><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">â€¦</ci><apply id="S3.SS2.p2.2.m2.5.5.4.4.4.cmml" xref="S3.SS2.p2.2.m2.5.5.4.4.4"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.5.5.4.4.4.1.cmml" xref="S3.SS2.p2.2.m2.5.5.4.4.4">superscript</csymbol><apply id="S3.SS2.p2.2.m2.5.5.4.4.4.2.cmml" xref="S3.SS2.p2.2.m2.5.5.4.4.4"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.5.5.4.4.4.2.1.cmml" xref="S3.SS2.p2.2.m2.5.5.4.4.4">subscript</csymbol><ci id="S3.SS2.p2.2.m2.5.5.4.4.4.2.2.cmml" xref="S3.SS2.p2.2.m2.5.5.4.4.4.2.2">ğ³</ci><ci id="S3.SS2.p2.2.m2.5.5.4.4.4.2.3.cmml" xref="S3.SS2.p2.2.m2.5.5.4.4.4.2.3">p</ci></apply><apply id="S3.SS2.p2.2.m2.5.5.4.4.4.3.cmml" xref="S3.SS2.p2.2.m2.5.5.4.4.4.3"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.5.5.4.4.4.3.1.cmml" xref="S3.SS2.p2.2.m2.5.5.4.4.4.3">subscript</csymbol><ci id="S3.SS2.p2.2.m2.5.5.4.4.4.3.2.cmml" xref="S3.SS2.p2.2.m2.5.5.4.4.4.3.2">ğ‘€</ci><ci id="S3.SS2.p2.2.m2.5.5.4.4.4.3.3.cmml" xref="S3.SS2.p2.2.m2.5.5.4.4.4.3.3">p</ci></apply></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.5c">\mathbf{z}_{\mathrm{p}}=[x_{\mathrm{class}},\mathbf{z}_{\mathrm{p}}^{1},%
\mathbf{z}_{\mathrm{p}}^{2},\dots,\mathbf{z}_{\mathrm{p}}^{M_{\mathrm{p}}}]</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.2.m2.5d">bold_z start_POSTSUBSCRIPT roman_p end_POSTSUBSCRIPT = [ italic_x start_POSTSUBSCRIPT roman_class end_POSTSUBSCRIPT , bold_z start_POSTSUBSCRIPT roman_p end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , bold_z start_POSTSUBSCRIPT roman_p end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , â€¦ , bold_z start_POSTSUBSCRIPT roman_p end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_M start_POSTSUBSCRIPT roman_p end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ]</annotation></semantics></math>, where <math alttext="M_{\mathrm{i}}" class="ltx_Math" display="inline" id="S3.SS2.p2.3.m3.1"><semantics id="S3.SS2.p2.3.m3.1a"><msub id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml"><mi id="S3.SS2.p2.3.m3.1.1.2" xref="S3.SS2.p2.3.m3.1.1.2.cmml">M</mi><mi id="S3.SS2.p2.3.m3.1.1.3" mathvariant="normal" xref="S3.SS2.p2.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><apply id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p2.3.m3.1.1.2.cmml" xref="S3.SS2.p2.3.m3.1.1.2">ğ‘€</ci><ci id="S3.SS2.p2.3.m3.1.1.3.cmml" xref="S3.SS2.p2.3.m3.1.1.3">i</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">M_{\mathrm{i}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.3.m3.1d">italic_M start_POSTSUBSCRIPT roman_i end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="M_{\mathrm{p}}" class="ltx_Math" display="inline" id="S3.SS2.p2.4.m4.1"><semantics id="S3.SS2.p2.4.m4.1a"><msub id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml"><mi id="S3.SS2.p2.4.m4.1.1.2" xref="S3.SS2.p2.4.m4.1.1.2.cmml">M</mi><mi id="S3.SS2.p2.4.m4.1.1.3" mathvariant="normal" xref="S3.SS2.p2.4.m4.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><apply id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.4.m4.1.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.p2.4.m4.1.1.2.cmml" xref="S3.SS2.p2.4.m4.1.1.2">ğ‘€</ci><ci id="S3.SS2.p2.4.m4.1.1.3.cmml" xref="S3.SS2.p2.4.m4.1.1.3">p</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">M_{\mathrm{p}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.4.m4.1d">italic_M start_POSTSUBSCRIPT roman_p end_POSTSUBSCRIPT</annotation></semantics></math> are the numbers of image and point cloud tokens, respectively.
Moreover, a class token <math alttext="x_{\mathrm{class}}" class="ltx_Math" display="inline" id="S3.SS2.p2.5.m5.1"><semantics id="S3.SS2.p2.5.m5.1a"><msub id="S3.SS2.p2.5.m5.1.1" xref="S3.SS2.p2.5.m5.1.1.cmml"><mi id="S3.SS2.p2.5.m5.1.1.2" xref="S3.SS2.p2.5.m5.1.1.2.cmml">x</mi><mi id="S3.SS2.p2.5.m5.1.1.3" xref="S3.SS2.p2.5.m5.1.1.3.cmml">class</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.1b"><apply id="S3.SS2.p2.5.m5.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.5.m5.1.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.p2.5.m5.1.1.2.cmml" xref="S3.SS2.p2.5.m5.1.1.2">ğ‘¥</ci><ci id="S3.SS2.p2.5.m5.1.1.3.cmml" xref="S3.SS2.p2.5.m5.1.1.3">class</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.1c">x_{\mathrm{class}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.5.m5.1d">italic_x start_POSTSUBSCRIPT roman_class end_POSTSUBSCRIPT</annotation></semantics></math> is added to the tokens of each modality.
The fractal image and fractal point cloud tokens are then input into the transformer encoder. The class token <math alttext="x_{\mathrm{class}}" class="ltx_Math" display="inline" id="S3.SS2.p2.6.m6.1"><semantics id="S3.SS2.p2.6.m6.1a"><msub id="S3.SS2.p2.6.m6.1.1" xref="S3.SS2.p2.6.m6.1.1.cmml"><mi id="S3.SS2.p2.6.m6.1.1.2" xref="S3.SS2.p2.6.m6.1.1.2.cmml">x</mi><mi id="S3.SS2.p2.6.m6.1.1.3" xref="S3.SS2.p2.6.m6.1.1.3.cmml">class</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m6.1b"><apply id="S3.SS2.p2.6.m6.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.6.m6.1.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.p2.6.m6.1.1.2.cmml" xref="S3.SS2.p2.6.m6.1.1.2">ğ‘¥</ci><ci id="S3.SS2.p2.6.m6.1.1.3.cmml" xref="S3.SS2.p2.6.m6.1.1.3">class</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m6.1c">x_{\mathrm{class}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.6.m6.1d">italic_x start_POSTSUBSCRIPT roman_class end_POSTSUBSCRIPT</annotation></semantics></math> and the MLP layer used for classification are shared between the two modalities.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">In addition, for the pre-training task of VG-FractalDB, we train our transformer model <math alttext="f" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">ğ‘“</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">f</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">italic_f</annotation></semantics></math> using cross-entropy (CE) loss for the classification task (see FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S3.F3" title="Figure 3 â€£ 3.1 Visual-geometric fractal database (VG-FractalDB) â€£ 3 Formula-supervised visual-geometric pre-training â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">3</span></a> Left), which is given by</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="Pt0.A4.EGx1">
<tbody id="S3.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathcal{L}_{\text{ce}}(f(\mathcal{D}))=-\frac{1}{N}\sum_{j=1}^{N%
}\sum_{c=1}^{C}y_{j,c}\log\hat{y}_{j,c}" class="ltx_Math" display="inline" id="S3.E1.m1.6"><semantics id="S3.E1.m1.6a"><mrow id="S3.E1.m1.6.6" xref="S3.E1.m1.6.6.cmml"><mrow id="S3.E1.m1.6.6.1" xref="S3.E1.m1.6.6.1.cmml"><msub id="S3.E1.m1.6.6.1.3" xref="S3.E1.m1.6.6.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.6.6.1.3.2" xref="S3.E1.m1.6.6.1.3.2.cmml">â„’</mi><mtext id="S3.E1.m1.6.6.1.3.3" xref="S3.E1.m1.6.6.1.3.3a.cmml">ce</mtext></msub><mo id="S3.E1.m1.6.6.1.2" xref="S3.E1.m1.6.6.1.2.cmml">â¢</mo><mrow id="S3.E1.m1.6.6.1.1.1" xref="S3.E1.m1.6.6.1.1.1.1.cmml"><mo id="S3.E1.m1.6.6.1.1.1.2" stretchy="false" xref="S3.E1.m1.6.6.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.6.6.1.1.1.1" xref="S3.E1.m1.6.6.1.1.1.1.cmml"><mi id="S3.E1.m1.6.6.1.1.1.1.2" xref="S3.E1.m1.6.6.1.1.1.1.2.cmml">f</mi><mo id="S3.E1.m1.6.6.1.1.1.1.1" xref="S3.E1.m1.6.6.1.1.1.1.1.cmml">â¢</mo><mrow id="S3.E1.m1.6.6.1.1.1.1.3.2" xref="S3.E1.m1.6.6.1.1.1.1.cmml"><mo id="S3.E1.m1.6.6.1.1.1.1.3.2.1" stretchy="false" xref="S3.E1.m1.6.6.1.1.1.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.5.5" xref="S3.E1.m1.5.5.cmml">ğ’Ÿ</mi><mo id="S3.E1.m1.6.6.1.1.1.1.3.2.2" stretchy="false" xref="S3.E1.m1.6.6.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.6.6.1.1.1.3" stretchy="false" xref="S3.E1.m1.6.6.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.6.6.2" xref="S3.E1.m1.6.6.2.cmml">=</mo><mrow id="S3.E1.m1.6.6.3" xref="S3.E1.m1.6.6.3.cmml"><mo id="S3.E1.m1.6.6.3a" xref="S3.E1.m1.6.6.3.cmml">âˆ’</mo><mrow id="S3.E1.m1.6.6.3.2" xref="S3.E1.m1.6.6.3.2.cmml"><mstyle displaystyle="true" id="S3.E1.m1.6.6.3.2.2" xref="S3.E1.m1.6.6.3.2.2.cmml"><mfrac id="S3.E1.m1.6.6.3.2.2a" xref="S3.E1.m1.6.6.3.2.2.cmml"><mn id="S3.E1.m1.6.6.3.2.2.2" xref="S3.E1.m1.6.6.3.2.2.2.cmml">1</mn><mi id="S3.E1.m1.6.6.3.2.2.3" xref="S3.E1.m1.6.6.3.2.2.3.cmml">N</mi></mfrac></mstyle><mo id="S3.E1.m1.6.6.3.2.1" xref="S3.E1.m1.6.6.3.2.1.cmml">â¢</mo><mrow id="S3.E1.m1.6.6.3.2.3" xref="S3.E1.m1.6.6.3.2.3.cmml"><mstyle displaystyle="true" id="S3.E1.m1.6.6.3.2.3.1" xref="S3.E1.m1.6.6.3.2.3.1.cmml"><munderover id="S3.E1.m1.6.6.3.2.3.1a" xref="S3.E1.m1.6.6.3.2.3.1.cmml"><mo id="S3.E1.m1.6.6.3.2.3.1.2.2" movablelimits="false" xref="S3.E1.m1.6.6.3.2.3.1.2.2.cmml">âˆ‘</mo><mrow id="S3.E1.m1.6.6.3.2.3.1.2.3" xref="S3.E1.m1.6.6.3.2.3.1.2.3.cmml"><mi id="S3.E1.m1.6.6.3.2.3.1.2.3.2" xref="S3.E1.m1.6.6.3.2.3.1.2.3.2.cmml">j</mi><mo id="S3.E1.m1.6.6.3.2.3.1.2.3.1" xref="S3.E1.m1.6.6.3.2.3.1.2.3.1.cmml">=</mo><mn id="S3.E1.m1.6.6.3.2.3.1.2.3.3" xref="S3.E1.m1.6.6.3.2.3.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E1.m1.6.6.3.2.3.1.3" xref="S3.E1.m1.6.6.3.2.3.1.3.cmml">N</mi></munderover></mstyle><mrow id="S3.E1.m1.6.6.3.2.3.2" xref="S3.E1.m1.6.6.3.2.3.2.cmml"><mstyle displaystyle="true" id="S3.E1.m1.6.6.3.2.3.2.1" xref="S3.E1.m1.6.6.3.2.3.2.1.cmml"><munderover id="S3.E1.m1.6.6.3.2.3.2.1a" xref="S3.E1.m1.6.6.3.2.3.2.1.cmml"><mo id="S3.E1.m1.6.6.3.2.3.2.1.2.2" movablelimits="false" xref="S3.E1.m1.6.6.3.2.3.2.1.2.2.cmml">âˆ‘</mo><mrow id="S3.E1.m1.6.6.3.2.3.2.1.2.3" xref="S3.E1.m1.6.6.3.2.3.2.1.2.3.cmml"><mi id="S3.E1.m1.6.6.3.2.3.2.1.2.3.2" xref="S3.E1.m1.6.6.3.2.3.2.1.2.3.2.cmml">c</mi><mo id="S3.E1.m1.6.6.3.2.3.2.1.2.3.1" xref="S3.E1.m1.6.6.3.2.3.2.1.2.3.1.cmml">=</mo><mn id="S3.E1.m1.6.6.3.2.3.2.1.2.3.3" xref="S3.E1.m1.6.6.3.2.3.2.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E1.m1.6.6.3.2.3.2.1.3" xref="S3.E1.m1.6.6.3.2.3.2.1.3.cmml">C</mi></munderover></mstyle><mrow id="S3.E1.m1.6.6.3.2.3.2.2" xref="S3.E1.m1.6.6.3.2.3.2.2.cmml"><msub id="S3.E1.m1.6.6.3.2.3.2.2.2" xref="S3.E1.m1.6.6.3.2.3.2.2.2.cmml"><mi id="S3.E1.m1.6.6.3.2.3.2.2.2.2" xref="S3.E1.m1.6.6.3.2.3.2.2.2.2.cmml">y</mi><mrow id="S3.E1.m1.2.2.2.4" xref="S3.E1.m1.2.2.2.3.cmml"><mi id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml">j</mi><mo id="S3.E1.m1.2.2.2.4.1" xref="S3.E1.m1.2.2.2.3.cmml">,</mo><mi id="S3.E1.m1.2.2.2.2" xref="S3.E1.m1.2.2.2.2.cmml">c</mi></mrow></msub><mo id="S3.E1.m1.6.6.3.2.3.2.2.1" lspace="0.167em" xref="S3.E1.m1.6.6.3.2.3.2.2.1.cmml">â¢</mo><mrow id="S3.E1.m1.6.6.3.2.3.2.2.3" xref="S3.E1.m1.6.6.3.2.3.2.2.3.cmml"><mi id="S3.E1.m1.6.6.3.2.3.2.2.3.1" xref="S3.E1.m1.6.6.3.2.3.2.2.3.1.cmml">log</mi><mo id="S3.E1.m1.6.6.3.2.3.2.2.3a" lspace="0.167em" xref="S3.E1.m1.6.6.3.2.3.2.2.3.cmml">â¡</mo><msub id="S3.E1.m1.6.6.3.2.3.2.2.3.2" xref="S3.E1.m1.6.6.3.2.3.2.2.3.2.cmml"><mover accent="true" id="S3.E1.m1.6.6.3.2.3.2.2.3.2.2" xref="S3.E1.m1.6.6.3.2.3.2.2.3.2.2.cmml"><mi id="S3.E1.m1.6.6.3.2.3.2.2.3.2.2.2" xref="S3.E1.m1.6.6.3.2.3.2.2.3.2.2.2.cmml">y</mi><mo id="S3.E1.m1.6.6.3.2.3.2.2.3.2.2.1" xref="S3.E1.m1.6.6.3.2.3.2.2.3.2.2.1.cmml">^</mo></mover><mrow id="S3.E1.m1.4.4.2.4" xref="S3.E1.m1.4.4.2.3.cmml"><mi id="S3.E1.m1.3.3.1.1" xref="S3.E1.m1.3.3.1.1.cmml">j</mi><mo id="S3.E1.m1.4.4.2.4.1" xref="S3.E1.m1.4.4.2.3.cmml">,</mo><mi id="S3.E1.m1.4.4.2.2" xref="S3.E1.m1.4.4.2.2.cmml">c</mi></mrow></msub></mrow></mrow></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.6b"><apply id="S3.E1.m1.6.6.cmml" xref="S3.E1.m1.6.6"><eq id="S3.E1.m1.6.6.2.cmml" xref="S3.E1.m1.6.6.2"></eq><apply id="S3.E1.m1.6.6.1.cmml" xref="S3.E1.m1.6.6.1"><times id="S3.E1.m1.6.6.1.2.cmml" xref="S3.E1.m1.6.6.1.2"></times><apply id="S3.E1.m1.6.6.1.3.cmml" xref="S3.E1.m1.6.6.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.6.6.1.3.1.cmml" xref="S3.E1.m1.6.6.1.3">subscript</csymbol><ci id="S3.E1.m1.6.6.1.3.2.cmml" xref="S3.E1.m1.6.6.1.3.2">â„’</ci><ci id="S3.E1.m1.6.6.1.3.3a.cmml" xref="S3.E1.m1.6.6.1.3.3"><mtext id="S3.E1.m1.6.6.1.3.3.cmml" mathsize="70%" xref="S3.E1.m1.6.6.1.3.3">ce</mtext></ci></apply><apply id="S3.E1.m1.6.6.1.1.1.1.cmml" xref="S3.E1.m1.6.6.1.1.1"><times id="S3.E1.m1.6.6.1.1.1.1.1.cmml" xref="S3.E1.m1.6.6.1.1.1.1.1"></times><ci id="S3.E1.m1.6.6.1.1.1.1.2.cmml" xref="S3.E1.m1.6.6.1.1.1.1.2">ğ‘“</ci><ci id="S3.E1.m1.5.5.cmml" xref="S3.E1.m1.5.5">ğ’Ÿ</ci></apply></apply><apply id="S3.E1.m1.6.6.3.cmml" xref="S3.E1.m1.6.6.3"><minus id="S3.E1.m1.6.6.3.1.cmml" xref="S3.E1.m1.6.6.3"></minus><apply id="S3.E1.m1.6.6.3.2.cmml" xref="S3.E1.m1.6.6.3.2"><times id="S3.E1.m1.6.6.3.2.1.cmml" xref="S3.E1.m1.6.6.3.2.1"></times><apply id="S3.E1.m1.6.6.3.2.2.cmml" xref="S3.E1.m1.6.6.3.2.2"><divide id="S3.E1.m1.6.6.3.2.2.1.cmml" xref="S3.E1.m1.6.6.3.2.2"></divide><cn id="S3.E1.m1.6.6.3.2.2.2.cmml" type="integer" xref="S3.E1.m1.6.6.3.2.2.2">1</cn><ci id="S3.E1.m1.6.6.3.2.2.3.cmml" xref="S3.E1.m1.6.6.3.2.2.3">ğ‘</ci></apply><apply id="S3.E1.m1.6.6.3.2.3.cmml" xref="S3.E1.m1.6.6.3.2.3"><apply id="S3.E1.m1.6.6.3.2.3.1.cmml" xref="S3.E1.m1.6.6.3.2.3.1"><csymbol cd="ambiguous" id="S3.E1.m1.6.6.3.2.3.1.1.cmml" xref="S3.E1.m1.6.6.3.2.3.1">superscript</csymbol><apply id="S3.E1.m1.6.6.3.2.3.1.2.cmml" xref="S3.E1.m1.6.6.3.2.3.1"><csymbol cd="ambiguous" id="S3.E1.m1.6.6.3.2.3.1.2.1.cmml" xref="S3.E1.m1.6.6.3.2.3.1">subscript</csymbol><sum id="S3.E1.m1.6.6.3.2.3.1.2.2.cmml" xref="S3.E1.m1.6.6.3.2.3.1.2.2"></sum><apply id="S3.E1.m1.6.6.3.2.3.1.2.3.cmml" xref="S3.E1.m1.6.6.3.2.3.1.2.3"><eq id="S3.E1.m1.6.6.3.2.3.1.2.3.1.cmml" xref="S3.E1.m1.6.6.3.2.3.1.2.3.1"></eq><ci id="S3.E1.m1.6.6.3.2.3.1.2.3.2.cmml" xref="S3.E1.m1.6.6.3.2.3.1.2.3.2">ğ‘—</ci><cn id="S3.E1.m1.6.6.3.2.3.1.2.3.3.cmml" type="integer" xref="S3.E1.m1.6.6.3.2.3.1.2.3.3">1</cn></apply></apply><ci id="S3.E1.m1.6.6.3.2.3.1.3.cmml" xref="S3.E1.m1.6.6.3.2.3.1.3">ğ‘</ci></apply><apply id="S3.E1.m1.6.6.3.2.3.2.cmml" xref="S3.E1.m1.6.6.3.2.3.2"><apply id="S3.E1.m1.6.6.3.2.3.2.1.cmml" xref="S3.E1.m1.6.6.3.2.3.2.1"><csymbol cd="ambiguous" id="S3.E1.m1.6.6.3.2.3.2.1.1.cmml" xref="S3.E1.m1.6.6.3.2.3.2.1">superscript</csymbol><apply id="S3.E1.m1.6.6.3.2.3.2.1.2.cmml" xref="S3.E1.m1.6.6.3.2.3.2.1"><csymbol cd="ambiguous" id="S3.E1.m1.6.6.3.2.3.2.1.2.1.cmml" xref="S3.E1.m1.6.6.3.2.3.2.1">subscript</csymbol><sum id="S3.E1.m1.6.6.3.2.3.2.1.2.2.cmml" xref="S3.E1.m1.6.6.3.2.3.2.1.2.2"></sum><apply id="S3.E1.m1.6.6.3.2.3.2.1.2.3.cmml" xref="S3.E1.m1.6.6.3.2.3.2.1.2.3"><eq id="S3.E1.m1.6.6.3.2.3.2.1.2.3.1.cmml" xref="S3.E1.m1.6.6.3.2.3.2.1.2.3.1"></eq><ci id="S3.E1.m1.6.6.3.2.3.2.1.2.3.2.cmml" xref="S3.E1.m1.6.6.3.2.3.2.1.2.3.2">ğ‘</ci><cn id="S3.E1.m1.6.6.3.2.3.2.1.2.3.3.cmml" type="integer" xref="S3.E1.m1.6.6.3.2.3.2.1.2.3.3">1</cn></apply></apply><ci id="S3.E1.m1.6.6.3.2.3.2.1.3.cmml" xref="S3.E1.m1.6.6.3.2.3.2.1.3">ğ¶</ci></apply><apply id="S3.E1.m1.6.6.3.2.3.2.2.cmml" xref="S3.E1.m1.6.6.3.2.3.2.2"><times id="S3.E1.m1.6.6.3.2.3.2.2.1.cmml" xref="S3.E1.m1.6.6.3.2.3.2.2.1"></times><apply id="S3.E1.m1.6.6.3.2.3.2.2.2.cmml" xref="S3.E1.m1.6.6.3.2.3.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.6.6.3.2.3.2.2.2.1.cmml" xref="S3.E1.m1.6.6.3.2.3.2.2.2">subscript</csymbol><ci id="S3.E1.m1.6.6.3.2.3.2.2.2.2.cmml" xref="S3.E1.m1.6.6.3.2.3.2.2.2.2">ğ‘¦</ci><list id="S3.E1.m1.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.4"><ci id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1">ğ‘—</ci><ci id="S3.E1.m1.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2">ğ‘</ci></list></apply><apply id="S3.E1.m1.6.6.3.2.3.2.2.3.cmml" xref="S3.E1.m1.6.6.3.2.3.2.2.3"><log id="S3.E1.m1.6.6.3.2.3.2.2.3.1.cmml" xref="S3.E1.m1.6.6.3.2.3.2.2.3.1"></log><apply id="S3.E1.m1.6.6.3.2.3.2.2.3.2.cmml" xref="S3.E1.m1.6.6.3.2.3.2.2.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.6.6.3.2.3.2.2.3.2.1.cmml" xref="S3.E1.m1.6.6.3.2.3.2.2.3.2">subscript</csymbol><apply id="S3.E1.m1.6.6.3.2.3.2.2.3.2.2.cmml" xref="S3.E1.m1.6.6.3.2.3.2.2.3.2.2"><ci id="S3.E1.m1.6.6.3.2.3.2.2.3.2.2.1.cmml" xref="S3.E1.m1.6.6.3.2.3.2.2.3.2.2.1">^</ci><ci id="S3.E1.m1.6.6.3.2.3.2.2.3.2.2.2.cmml" xref="S3.E1.m1.6.6.3.2.3.2.2.3.2.2.2">ğ‘¦</ci></apply><list id="S3.E1.m1.4.4.2.3.cmml" xref="S3.E1.m1.4.4.2.4"><ci id="S3.E1.m1.3.3.1.1.cmml" xref="S3.E1.m1.3.3.1.1">ğ‘—</ci><ci id="S3.E1.m1.4.4.2.2.cmml" xref="S3.E1.m1.4.4.2.2">ğ‘</ci></list></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.6c">\displaystyle\mathcal{L}_{\text{ce}}(f(\mathcal{D}))=-\frac{1}{N}\sum_{j=1}^{N%
}\sum_{c=1}^{C}y_{j,c}\log\hat{y}_{j,c}</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.6d">caligraphic_L start_POSTSUBSCRIPT ce end_POSTSUBSCRIPT ( italic_f ( caligraphic_D ) ) = - divide start_ARG 1 end_ARG start_ARG italic_N end_ARG âˆ‘ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT âˆ‘ start_POSTSUBSCRIPT italic_c = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_C end_POSTSUPERSCRIPT italic_y start_POSTSUBSCRIPT italic_j , italic_c end_POSTSUBSCRIPT roman_log over^ start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_j , italic_c end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p3.2">where <math alttext="\hat{y}_{j}=f(X_{j},I_{j})" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m1.2"><semantics id="S3.SS2.p3.2.m1.2a"><mrow id="S3.SS2.p3.2.m1.2.2" xref="S3.SS2.p3.2.m1.2.2.cmml"><msub id="S3.SS2.p3.2.m1.2.2.4" xref="S3.SS2.p3.2.m1.2.2.4.cmml"><mover accent="true" id="S3.SS2.p3.2.m1.2.2.4.2" xref="S3.SS2.p3.2.m1.2.2.4.2.cmml"><mi id="S3.SS2.p3.2.m1.2.2.4.2.2" xref="S3.SS2.p3.2.m1.2.2.4.2.2.cmml">y</mi><mo id="S3.SS2.p3.2.m1.2.2.4.2.1" xref="S3.SS2.p3.2.m1.2.2.4.2.1.cmml">^</mo></mover><mi id="S3.SS2.p3.2.m1.2.2.4.3" xref="S3.SS2.p3.2.m1.2.2.4.3.cmml">j</mi></msub><mo id="S3.SS2.p3.2.m1.2.2.3" xref="S3.SS2.p3.2.m1.2.2.3.cmml">=</mo><mrow id="S3.SS2.p3.2.m1.2.2.2" xref="S3.SS2.p3.2.m1.2.2.2.cmml"><mi id="S3.SS2.p3.2.m1.2.2.2.4" xref="S3.SS2.p3.2.m1.2.2.2.4.cmml">f</mi><mo id="S3.SS2.p3.2.m1.2.2.2.3" xref="S3.SS2.p3.2.m1.2.2.2.3.cmml">â¢</mo><mrow id="S3.SS2.p3.2.m1.2.2.2.2.2" xref="S3.SS2.p3.2.m1.2.2.2.2.3.cmml"><mo id="S3.SS2.p3.2.m1.2.2.2.2.2.3" stretchy="false" xref="S3.SS2.p3.2.m1.2.2.2.2.3.cmml">(</mo><msub id="S3.SS2.p3.2.m1.1.1.1.1.1.1" xref="S3.SS2.p3.2.m1.1.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.2.m1.1.1.1.1.1.1.2" xref="S3.SS2.p3.2.m1.1.1.1.1.1.1.2.cmml">X</mi><mi id="S3.SS2.p3.2.m1.1.1.1.1.1.1.3" xref="S3.SS2.p3.2.m1.1.1.1.1.1.1.3.cmml">j</mi></msub><mo id="S3.SS2.p3.2.m1.2.2.2.2.2.4" xref="S3.SS2.p3.2.m1.2.2.2.2.3.cmml">,</mo><msub id="S3.SS2.p3.2.m1.2.2.2.2.2.2" xref="S3.SS2.p3.2.m1.2.2.2.2.2.2.cmml"><mi id="S3.SS2.p3.2.m1.2.2.2.2.2.2.2" xref="S3.SS2.p3.2.m1.2.2.2.2.2.2.2.cmml">I</mi><mi id="S3.SS2.p3.2.m1.2.2.2.2.2.2.3" xref="S3.SS2.p3.2.m1.2.2.2.2.2.2.3.cmml">j</mi></msub><mo id="S3.SS2.p3.2.m1.2.2.2.2.2.5" stretchy="false" xref="S3.SS2.p3.2.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m1.2b"><apply id="S3.SS2.p3.2.m1.2.2.cmml" xref="S3.SS2.p3.2.m1.2.2"><eq id="S3.SS2.p3.2.m1.2.2.3.cmml" xref="S3.SS2.p3.2.m1.2.2.3"></eq><apply id="S3.SS2.p3.2.m1.2.2.4.cmml" xref="S3.SS2.p3.2.m1.2.2.4"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m1.2.2.4.1.cmml" xref="S3.SS2.p3.2.m1.2.2.4">subscript</csymbol><apply id="S3.SS2.p3.2.m1.2.2.4.2.cmml" xref="S3.SS2.p3.2.m1.2.2.4.2"><ci id="S3.SS2.p3.2.m1.2.2.4.2.1.cmml" xref="S3.SS2.p3.2.m1.2.2.4.2.1">^</ci><ci id="S3.SS2.p3.2.m1.2.2.4.2.2.cmml" xref="S3.SS2.p3.2.m1.2.2.4.2.2">ğ‘¦</ci></apply><ci id="S3.SS2.p3.2.m1.2.2.4.3.cmml" xref="S3.SS2.p3.2.m1.2.2.4.3">ğ‘—</ci></apply><apply id="S3.SS2.p3.2.m1.2.2.2.cmml" xref="S3.SS2.p3.2.m1.2.2.2"><times id="S3.SS2.p3.2.m1.2.2.2.3.cmml" xref="S3.SS2.p3.2.m1.2.2.2.3"></times><ci id="S3.SS2.p3.2.m1.2.2.2.4.cmml" xref="S3.SS2.p3.2.m1.2.2.2.4">ğ‘“</ci><interval closure="open" id="S3.SS2.p3.2.m1.2.2.2.2.3.cmml" xref="S3.SS2.p3.2.m1.2.2.2.2.2"><apply id="S3.SS2.p3.2.m1.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.2.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.2.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.2.m1.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.2.m1.1.1.1.1.1.1.2">ğ‘‹</ci><ci id="S3.SS2.p3.2.m1.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.2.m1.1.1.1.1.1.1.3">ğ‘—</ci></apply><apply id="S3.SS2.p3.2.m1.2.2.2.2.2.2.cmml" xref="S3.SS2.p3.2.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m1.2.2.2.2.2.2.1.cmml" xref="S3.SS2.p3.2.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p3.2.m1.2.2.2.2.2.2.2.cmml" xref="S3.SS2.p3.2.m1.2.2.2.2.2.2.2">ğ¼</ci><ci id="S3.SS2.p3.2.m1.2.2.2.2.2.2.3.cmml" xref="S3.SS2.p3.2.m1.2.2.2.2.2.2.3">ğ‘—</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m1.2c">\hat{y}_{j}=f(X_{j},I_{j})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m1.2d">over^ start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT = italic_f ( italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT )</annotation></semantics></math> is the output vector.
FSVGP trains a unified transformer model on VG-FractalDB to minimize CE loss using AdamWÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib28" title="">28</a>]</cite>.
Our approach to supervised pre-training distinguishes itself from conventional visual-geometric learning methods in several key ways. Whereas the visual-geometric representation learning methodÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib26" title="">26</a>]</cite> focused on pixel-point correspondence for training, FSVGP facilitates learning across different modalities within a common label space (see FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S3.F3" title="Figure 3 â€£ 3.1 Visual-geometric fractal database (VG-FractalDB) â€£ 3 Formula-supervised visual-geometric pre-training â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">3</span></a> Right). This unified label space allows for optimizing a unified transformer model, the learning process across modalities.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T1.2.1.1" style="font-size:90%;">Table 1</span>: </span><span class="ltx_text" id="S3.T1.3.2" style="font-size:90%;">Details of fine-tuning datasets, fine-tuning task, model type, number of classes (#classes), training data (#train), validation data (#val), and evaluation metrics.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T1.4" style="width:514.3pt;height:191.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-90.3pt,33.7pt) scale(0.74,0.74) ;">
<table class="ltx_tabular ltx_align_middle" id="S3.T1.4.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.4.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S3.T1.4.1.1.1.1">Fine-tuning dataset</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.4.1.1.1.2">Fine-tuning task</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.4.1.1.1.3">Table</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.4.1.1.1.4">Model type</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.4.1.1.1.5">#classes</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.4.1.1.1.6">#train</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.4.1.1.1.7">#val</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.4.1.1.1.8">Metrics</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.2.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.4.1.2.2.1"><span class="ltx_text" id="S3.T1.4.1.2.2.1.1" style="color:#0D4DC7;">CIFAR10 (C10)Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib21" title="">21</a>]</cite></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.1.2.2.2"><span class="ltx_text" id="S3.T1.4.1.2.2.2.1" style="color:#0D4DC7;">Image CLS</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.1.2.2.3">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T3" title="Table 3 â€£ 4.2 FSVGP effects on image and 3D object recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">3</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T4" title="Table 4 â€£ 4.3 Comparative analysis in image recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">4</span></a>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.1.2.2.4">ViT-B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.1.2.2.5">10</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.1.2.2.6">50k</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.1.2.2.7">10k</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.1.2.2.8">Acc.</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.3.3">
<td class="ltx_td ltx_align_left" id="S3.T1.4.1.3.3.1"><span class="ltx_text" id="S3.T1.4.1.3.3.1.1" style="color:#0D4DC7;">CIFAR100 (C100)Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib21" title="">21</a>]</cite></span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.3.3.2"><span class="ltx_text" id="S3.T1.4.1.3.3.2.1" style="color:#0D4DC7;">Image CLS</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.3.3.3">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T3" title="Table 3 â€£ 4.2 FSVGP effects on image and 3D object recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">3</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T4" title="Table 4 â€£ 4.3 Comparative analysis in image recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">4</span></a>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.3.3.4">ViT-B</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.3.3.5">100</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.3.3.6">50k</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.3.3.7">10k</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.3.3.8">Acc.</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.4.4">
<td class="ltx_td ltx_align_left" id="S3.T1.4.1.4.4.1"><span class="ltx_text" id="S3.T1.4.1.4.4.1.1" style="color:#0D4DC7;">Stanford Cars (Cars)Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib20" title="">20</a>]</cite></span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.4.4.2"><span class="ltx_text" id="S3.T1.4.1.4.4.2.1" style="color:#0D4DC7;">Image CLS</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.4.4.3">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T3" title="Table 3 â€£ 4.2 FSVGP effects on image and 3D object recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">3</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T4" title="Table 4 â€£ 4.3 Comparative analysis in image recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">4</span></a>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.4.4.4">ViT-B</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.4.4.5">196</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.4.4.6">8k</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.4.4.7">8k</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.4.4.8">Acc.</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.5.5">
<td class="ltx_td ltx_align_left" id="S3.T1.4.1.5.5.1"><span class="ltx_text" id="S3.T1.4.1.5.5.1.1" style="color:#0D4DC7;">Oxford Flowers (Flowers)Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib31" title="">31</a>]</cite></span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.5.5.2"><span class="ltx_text" id="S3.T1.4.1.5.5.2.1" style="color:#0D4DC7;">Image CLS</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.5.5.3">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T3" title="Table 3 â€£ 4.2 FSVGP effects on image and 3D object recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">3</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T4" title="Table 4 â€£ 4.3 Comparative analysis in image recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">4</span></a>,</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.5.5.4">ViT-B</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.5.5.5">102</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.5.5.6">6k</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.5.5.7">818</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.5.5.8">Acc.</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.6.6">
<td class="ltx_td ltx_align_left" id="S3.T1.4.1.6.6.1"><span class="ltx_text" id="S3.T1.4.1.6.6.1.1" style="color:#0D4DC7;">PascalVOC 2012 (VOC)Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib11" title="">11</a>]</cite></span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.6.6.2"><span class="ltx_text" id="S3.T1.4.1.6.6.2.1" style="color:#0D4DC7;">Image CLS</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.6.6.3">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T3" title="Table 3 â€£ 4.2 FSVGP effects on image and 3D object recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">3</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T4" title="Table 4 â€£ 4.3 Comparative analysis in image recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">4</span></a>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.6.6.4">ViT-B</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.6.6.5">20</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.6.6.6">13k</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.6.6.7">13k</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.6.6.8">Acc.</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.7.7">
<td class="ltx_td ltx_align_left" id="S3.T1.4.1.7.7.1"><span class="ltx_text" id="S3.T1.4.1.7.7.1.1" style="color:#0D4DC7;">Places30 (P30)Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib49" title="">49</a>]</cite></span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.7.7.2"><span class="ltx_text" id="S3.T1.4.1.7.7.2.1" style="color:#0D4DC7;">Image CLS</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.7.7.3">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T3" title="Table 3 â€£ 4.2 FSVGP effects on image and 3D object recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">3</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T4" title="Table 4 â€£ 4.3 Comparative analysis in image recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">4</span></a>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.7.7.4">ViT-B</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.7.7.5">30</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.7.7.6">150k</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.7.7.7">3k</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.7.7.8">Acc.</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.8.8">
<td class="ltx_td ltx_align_left" id="S3.T1.4.1.8.8.1"><span class="ltx_text" id="S3.T1.4.1.8.8.1.1" style="color:#0D4DC7;">ImageNet100 (IN100)Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib9" title="">9</a>]</cite></span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.8.8.2"><span class="ltx_text" id="S3.T1.4.1.8.8.2.1" style="color:#0D4DC7;">Image CLS</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.8.8.3">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T2" title="Table 2 â€£ 4.1 Experimental setting â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">2</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T3" title="Table 3 â€£ 4.2 FSVGP effects on image and 3D object recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">3</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T4" title="Table 4 â€£ 4.3 Comparative analysis in image recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">4</span></a>, <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:shapenet</span>, <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:perlin</span>, <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:pt_task</span>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.8.8.4">ViT-B</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.8.8.5">100</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.8.8.6">120k</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.8.8.7">5k</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.8.8.8">Acc.</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.9.9">
<td class="ltx_td ltx_align_left" id="S3.T1.4.1.9.9.1"><span class="ltx_text" id="S3.T1.4.1.9.9.1.1" style="color:#0D4DC7;">MS COCO 2017 (COCO)Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib24" title="">24</a>]</cite></span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.9.9.2"><span class="ltx_text" id="S3.T1.4.1.9.9.2.1" style="color:#0D4DC7;">Image DET / SEG</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.9.9.3">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T2" title="Table 2 â€£ 4.1 Experimental setting â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">2</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T6" title="Table 6 â€£ 4.3 Comparative analysis in image recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">6</span></a>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.9.9.4">ViTDet-B</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.9.9.5">80</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.9.9.6">118k</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.9.9.7">5k</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.9.9.8">AP</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.10.10">
<td class="ltx_td ltx_align_left" id="S3.T1.4.1.10.10.1"><span class="ltx_text" id="S3.T1.4.1.10.10.1.1" style="color:#0D4DC7;">ImageNet-1kÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib9" title="">9</a>]</cite></span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.10.10.2"><span class="ltx_text" id="S3.T1.4.1.10.10.2.1" style="color:#0D4DC7;">Image CLS</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.10.10.3"><a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T6" title="Table 6 â€£ 4.3 Comparative analysis in image recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">6</span></a></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.10.10.4">ViT-B</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.10.10.5">1000</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.10.10.6">1.2M</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.10.10.7">50k</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.10.10.8">Acc.</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.11.11">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.4.1.11.11.1"><span class="ltx_text" id="S3.T1.4.1.11.11.1.1" style="color:#33801C;">ModelNet40 (M40)Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib43" title="">43</a>]</cite></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.1.11.11.2"><span class="ltx_text" id="S3.T1.4.1.11.11.2.1" style="color:#33801C;">3D object CLS</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.1.11.11.3">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T3" title="Table 3 â€£ 4.2 FSVGP effects on image and 3D object recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">3</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T7" title="Table 7 â€£ 4.4 Comparative analysis in geometric recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">7</span></a>, <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:few-shot</span>, <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:shapenet</span>, <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:perlin</span>, <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:pt_task</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.1.11.11.4">PointT-S</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.1.11.11.5">40</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.1.11.11.6">9.8k</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.1.11.11.7">2.4k</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.1.11.11.8">Acc.</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.12.12">
<td class="ltx_td ltx_align_left" id="S3.T1.4.1.12.12.1"><span class="ltx_text" id="S3.T1.4.1.12.12.1.1" style="color:#33801C;">ScanObjectNN (SONN)Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib41" title="">41</a>]</cite></span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.12.12.2"><span class="ltx_text" id="S3.T1.4.1.12.12.2.1" style="color:#33801C;">3D object CLS</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.12.12.3">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T2" title="Table 2 â€£ 4.1 Experimental setting â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">2</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T3" title="Table 3 â€£ 4.2 FSVGP effects on image and 3D object recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">3</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T7" title="Table 7 â€£ 4.4 Comparative analysis in geometric recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">7</span></a>, <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:few-shot</span>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.12.12.4">PointT-S</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.12.12.5">15</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.12.12.6">2.3k</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.12.12.7">581</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.12.12.8">Acc.</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.13.13">
<td class="ltx_td ltx_align_left" id="S3.T1.4.1.13.13.1"><span class="ltx_text" id="S3.T1.4.1.13.13.1.1" style="color:#33801C;">ShapeNet-PartsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib41" title="">41</a>]</cite></span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.13.13.2"><span class="ltx_text" id="S3.T1.4.1.13.13.2.1" style="color:#33801C;">3D object (parts) SEG</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.13.13.3">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T2" title="Table 2 â€£ 4.1 Experimental setting â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">2</span></a>, <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:3ddet</span>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.13.13.4">PointT-S</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.13.13.5">15</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.13.13.6">14k</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.13.13.7">2.8k</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.13.13.8">mIoU</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.14.14">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T1.4.1.14.14.1"><span class="ltx_text" id="S3.T1.4.1.14.14.1.1" style="color:#33801C;">ScanNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib6" title="">6</a>]</cite></span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.4.1.14.14.2"><span class="ltx_text" id="S3.T1.4.1.14.14.2.1" style="color:#33801C;">3D object DET</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.4.1.14.14.3">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T2" title="Table 2 â€£ 4.1 Experimental setting â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">2</span></a>, <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:3ddet</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.4.1.14.14.4">3DETR</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.4.1.14.14.5">18</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.4.1.14.14.6">1.2k</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.4.1.14.14.7">312</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.4.1.14.14.8">mAP</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this section, we evaluate the effectiveness of FSVGP by comparing it with previous pre-training methods. First, SectionÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.SS1" title="4.1 Experimental setting â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">4.1</span></a> outlines our experimental setup. In addition, SectionÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.SS2" title="4.2 FSVGP effects on image and 3D object recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">4.2</span></a> briefly describes the main experimental results in image recognition and 3D object recognition with FSVGP.
Subsequently, SectionsÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.SS3" title="4.3 Comparative analysis in image recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">4.3</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.SS4" title="4.4 Comparative analysis in geometric recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">4.4</span></a> compare FSVGP with established pre-training methods across six vision tasks, explicitly focusing on visual recognition and geometric recognition, respectively.
Finally, SectionÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.SS5" title="4.5 Ablation study â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">4.5</span></a> presents an ablation study to explore the fundamental components of FSVGP.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Experimental setting</h3>
<div class="ltx_para ltx_noindent" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.1">Pre-trainig.</span>
We use VG-FractalDB-1k (1000 categories, 1000 instances per category), ensuring equitable comparison with the existing FDSL methods.
Following the approach of previous SSL and FDSL methods, we conduct pre-training using a unified transformer (Base) for image recognition and a unified transformer (Small) for 3D object recognition. The Warm-up Cosine Scheduler is employed for scheduling during pre-training. The batch size is 64 for each GPU, the initial learning rate is 5e-4, the momentum is 0.9, the weight decay is 5e-2, and the number of epochs is 200. For example, training on VG-FractalDB-1k uses 16 NVIDIA V100 GPUs and requires about 60 hours.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.1">Comparison methods.</span>
For image recognition, we evaluate FSVGP against transformer-based pre-training methods, including supervised pre-training on ImageNet and SSL methods such as MAEÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib12" title="">12</a>]</cite> and DINOÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib3" title="">3</a>]</cite>. Additionally, we compare with FDSL methods, including ExFractalDB-21kÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib17" title="">17</a>]</cite>, RCDB-21kÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib17" title="">17</a>]</cite>, and VisualAtom-21kÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib38" title="">38</a>]</cite>. SAMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib19" title="">19</a>]</cite> is also included in comparisons for image detection and segmentation.
For 3D object recognition, we focus on transformer-based pre-training methods suited to point clouds, comparing SSL approaches such as PointBERTÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib47" title="">47</a>]</cite>, PointMAEÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib32" title="">32</a>]</cite>, and MaskPointÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib25" title="">25</a>]</cite> to evaluate FSVGPâ€™s effectiveness. For 3D object recognition, we specifically compare with the latest FDSL method, such as PC-FractalDB-1kÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib44" title="">44</a>]</cite>. However, since PC-FractalDB-1k proposed pre-trained on VoteNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib33" title="">33</a>]</cite>, to ensure a fair comparison, we also pre-train PC-FractalDB-1k using 3DETRÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib29" title="">29</a>]</cite>. For fine-tuning in geometric classification and segmentation, we utilize the backbone network of the PC-FractalDB-1k pre-trained model on 3DETR.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p3.1.1">Fine-tuning datasets and evaluation metrics.</span>
TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S3.T1" title="Table 1 â€£ 3.2 VG-FractalDB Pre-training on a unified transformer model â€£ 3 Formula-supervised visual-geometric pre-training â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">1</span></a> describes the detailed settings of fine-tuning datasets used in the experimental section. For detailed information on each fine-tuning dataset, the hyperparameters employed in the pre-training and fine-tuning processes, and the comparison baselines, please refer to the <span class="ltx_text" id="S4.SS1.p3.1.2" style="color:#FF0000;">Supplementary Material</span>.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T2.7.1.1" style="font-size:90%;">Table 2</span>: </span><span class="ltx_text" id="S4.T2.8.2" style="font-size:90%;">Comparison of the latest FDSL methods in image and 3D object classification (CLS), detection (DET), and segmentation (SEG). The best score is shown in <span class="ltx_text ltx_font_bold" id="S4.T2.8.2.1">bold</span>.
</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T2.4.4" style="width:315.8pt;height:106.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-1.6pt,0.5pt) scale(0.99,0.99) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T2.4.4.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.4.4.4.5.1">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T2.4.4.4.5.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T2.4.4.4.5.1.2"><span class="ltx_text" id="S4.T2.4.4.4.5.1.2.1" style="color:#0D4DC7;">Visual recognition</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T2.4.4.4.5.1.3"><span class="ltx_text" id="S4.T2.4.4.4.5.1.3.1" style="color:#33801C;">Geometric recognition</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.4.4.4.6.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T2.4.4.4.6.1.1">Pre-training dataset</th>
<td class="ltx_td ltx_align_center" id="S4.T2.4.4.4.6.1.2"><span class="ltx_text" id="S4.T2.4.4.4.6.1.2.1" style="color:#0D4DC7;">CLS</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.4.4.6.1.3"><span class="ltx_text" id="S4.T2.4.4.4.6.1.3.1" style="color:#0D4DC7;">DET</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.4.4.6.1.4"><span class="ltx_text" id="S4.T2.4.4.4.6.1.4.1" style="color:#0D4DC7;">SEG</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.4.4.6.1.5"><span class="ltx_text" id="S4.T2.4.4.4.6.1.5.1" style="color:#33801C;">CLS</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.4.4.6.1.6"><span class="ltx_text" id="S4.T2.4.4.4.6.1.6.1" style="color:#33801C;">DET</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.4.4.6.1.7"><span class="ltx_text" id="S4.T2.4.4.4.6.1.7.1" style="color:#33801C;">SEG</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.4.4.4">
<th class="ltx_td ltx_th ltx_th_row ltx_border_r" id="S4.T2.4.4.4.4.5"></th>
<td class="ltx_td ltx_align_center" id="S4.T2.4.4.4.4.6">Acc.</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.1.1.1">AP<sub class="ltx_sub" id="S4.T2.1.1.1.1.1.1"><span class="ltx_text ltx_font_italic" id="S4.T2.1.1.1.1.1.1.1">50</span></sub>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.2.2.2.2.2">AP<sub class="ltx_sub" id="S4.T2.2.2.2.2.2.1"><span class="ltx_text ltx_font_italic" id="S4.T2.2.2.2.2.2.1.1">50</span></sub>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.4.4.4.7">Acc.</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.3.3.3">mAP<sub class="ltx_sub" id="S4.T2.3.3.3.3.3.1"><span class="ltx_text ltx_font_italic" id="S4.T2.3.3.3.3.3.1.1">25</span></sub>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.4.4.4.4">mIoU<sub class="ltx_sub" id="S4.T2.4.4.4.4.4.1"><span class="ltx_text ltx_font_italic" id="S4.T2.4.4.4.4.4.1.1">cat</span></sub>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.4.4.7.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.4.4.4.7.2.1">VisualAtom-21k</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.4.4.4.7.2.2">91.3</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.4.4.4.7.2.3">66.3</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.4.4.4.7.2.4">63.3</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.4.4.4.7.2.5"><span class="ltx_text" id="S4.T2.4.4.4.7.2.5.1" style="color:#808080;">âœ—</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.4.4.4.7.2.6"><span class="ltx_text" id="S4.T2.4.4.4.7.2.6.1" style="color:#808080;">âœ—</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.4.4.4.7.2.7"><span class="ltx_text" id="S4.T2.4.4.4.7.2.7.1" style="color:#808080;">âœ—</span></th>
</tr>
<tr class="ltx_tr" id="S4.T2.4.4.4.8.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T2.4.4.4.8.3.1">PC-FractalDB-1k</th>
<td class="ltx_td ltx_align_center" id="S4.T2.4.4.4.8.3.2"><span class="ltx_text" id="S4.T2.4.4.4.8.3.2.1" style="color:#808080;">âœ—</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.4.4.8.3.3"><span class="ltx_text" id="S4.T2.4.4.4.8.3.3.1" style="color:#808080;">âœ—</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.4.4.8.3.4"><span class="ltx_text" id="S4.T2.4.4.4.8.3.4.1" style="color:#808080;">âœ—</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.4.4.8.3.5">83.3</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.4.4.8.3.6">63.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.4.4.8.3.7">83.7</td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.4.4.9.4" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T2.4.4.4.9.4.1"><span class="ltx_text" id="S4.T2.4.4.4.9.4.1.1" style="background-color:#E6E6E6;">VG-FractalDB-1k</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.4.4.4.9.4.2"><span class="ltx_text ltx_font_bold" id="S4.T2.4.4.4.9.4.2.1" style="background-color:#E6E6E6;">92.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.4.4.4.9.4.3"><span class="ltx_text ltx_font_bold" id="S4.T2.4.4.4.9.4.3.1" style="background-color:#E6E6E6;">68.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.4.4.4.9.4.4"><span class="ltx_text ltx_font_bold" id="S4.T2.4.4.4.9.4.4.1" style="background-color:#E6E6E6;">65.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.4.4.4.9.4.5"><span class="ltx_text ltx_font_bold" id="S4.T2.4.4.4.9.4.5.1" style="background-color:#E6E6E6;">83.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.4.4.4.9.4.6"><span class="ltx_text ltx_font_bold" id="S4.T2.4.4.4.9.4.6.1" style="background-color:#E6E6E6;">63.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.4.4.4.9.4.7"><span class="ltx_text ltx_font_bold" id="S4.T2.4.4.4.9.4.7.1" style="background-color:#E6E6E6;">84.1</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>FSVGP effects on image and 3D object recognition</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">In the beginning, we begin by presenting in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T2" title="Table 2 â€£ 4.1 Experimental setting â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">2</span></a> a comparison against the latest FDSL methods across all six tasks in both image and 3D object recognition classification (CLS), detection (DET) and segmentation (SEG).
In image recognition, CLS signifies fine-tuning accuracy on ImageNet100, while DET and SEG refer to fine-tuning performance on MS COCO for detection and segmentation tasks. In 3D object recognition, CLS represents fine-tuning accuracy in ScanObjectNN (PB-T50-RS).
DET involves fine-tuning performance on ScanNet, and SEG involves fine-tuning performance on ShapeNet-parts.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T2" title="Table 2 â€£ 4.1 Experimental setting â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">2</span></a> demonstrates FSVGP (VG-FractalDB-1k) performs equally or better than VisualAtom-21k and PC-FractalDB-1k in all tasks of classification, detection, and segmentation for image and 3D object recognition.
VisualAtom-21k or PC-FractalDB-1k pre-trained models are designed to fine-tune datasets of the same modality, and it is considered difficult to apply them to datasets of different modalities. However, our FSVGP performs better on both visual and geometric recognition.
This result shows FSVGPâ€™s capability to process image and 3D object recognition using a unified pre-trained model by supervised pre-training with the formula-supervised consistency label.</p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">In addition, we investigate the pre-training effects of learning visual-geometric representations. We evaluate the performance of pre-trained models on either visual or geometric modality compared to pre-trained models on both modalities.
TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T3" title="Table 3 â€£ 4.2 FSVGP effects on image and 3D object recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">3</span></a> shows the results of pre-trained models on both real (ImageNet, ShapeNet) and synthetic (VG-FractalDB-1k) datasets.
All pre-training utilized the same supervised learning to conduct a fair comparison.
FSVGP (VG-FractalDB-1k, V + G), which uses both modalities, improves the recognition performance in both modalities and achieves similar performances to ImageNet and ShapeNet in visual and geometric recognition, respectively, even though VG-FractalDB consists of synthetic data. These results indicate the effect of FSVGP, which bridges the modality gap over single-modality pre-trained models.</p>
</div>
<div class="ltx_para" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.1">In the following sections, we show the detailed analyses of FSVGP and comparisons with other pre-training on real datasets, such as SSL.</p>
</div>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T3.2.1.1" style="font-size:90%;">Table 3</span>: </span><span class="ltx_text" id="S4.T3.3.2" style="font-size:90%;">Comparison of performance on pre-training on either visual or geometric modality with FSVGP (VG-FractalDB-1k, visual (V) + geometric (G)).
</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T3.4" style="width:472.4pt;height:91.5pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-45.0pt,8.6pt) scale(0.84,0.84) ;">
<table class="ltx_tabular ltx_align_middle" id="S4.T3.4.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.4.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S4.T3.4.1.1.1.1">Dataset</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.4.1.1.1.2">Modal</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T3.4.1.1.1.3">#data</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.4.1.1.1.4"><span class="ltx_text" id="S4.T3.4.1.1.1.4.1" style="color:#0D4DC7;">C10</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.4.1.1.1.5"><span class="ltx_text" id="S4.T3.4.1.1.1.5.1" style="color:#0D4DC7;">C100</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.4.1.1.1.6"><span class="ltx_text" id="S4.T3.4.1.1.1.6.1" style="color:#0D4DC7;">Cars</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.4.1.1.1.7"><span class="ltx_text" id="S4.T3.4.1.1.1.7.1" style="color:#0D4DC7;">Flowers</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.4.1.1.1.8"><span class="ltx_text" id="S4.T3.4.1.1.1.8.1" style="color:#0D4DC7;">VOC12</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.4.1.1.1.9"><span class="ltx_text" id="S4.T3.4.1.1.1.9.1" style="color:#0D4DC7;">P30</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T3.4.1.1.1.10"><span class="ltx_text" id="S4.T3.4.1.1.1.10.1" style="color:#0D4DC7;">IN100</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T3.4.1.1.1.11"><span class="ltx_text" id="S4.T3.4.1.1.1.11.1" style="color:#0D4DC7;">Avg.</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.4.1.1.1.12"><span class="ltx_text" id="S4.T3.4.1.1.1.12.1" style="color:#33801C;">M40</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T3.4.1.1.1.13"><span class="ltx_text" id="S4.T3.4.1.1.1.13.1" style="color:#33801C;">SONN</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.4.1.1.1.14"><span class="ltx_text" id="S4.T3.4.1.1.1.14.1" style="color:#33801C;">Avg.</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.1.2.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.4.1.2.2.1">ImageNet</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.2.2">V</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.4.1.2.2.3">1M</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.2.4"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.2.2.4.1">99.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.2.5"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.2.2.5.1">89.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.2.6"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.2.2.6.1">81.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.2.7"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.2.2.7.1">99.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.2.8"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.2.2.8.1">86.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.2.9"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.2.2.9.1">82.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.4.1.2.2.10"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.2.2.10.1">93.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.4.1.2.2.11"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.2.2.11.1">90.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.2.12">92.2</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.4.1.2.2.13">82.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.2.14">87.1</td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.1.3.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T3.4.1.3.3.1">ShapeNet</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.3.3.2">G</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.4.1.3.3.3">50k</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.3.3.4">82.1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.3.3.5">65.4</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.3.3.6">8.25</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.3.3.7">74.8</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.3.3.8">53.1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.3.3.9">79.3</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.4.1.3.3.10">79.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.4.1.3.3.11">63.2</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.3.3.12"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.3.3.12.1">92.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.4.1.3.3.13"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.3.3.13.1">83.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.3.3.14"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.3.3.14.1">88.0</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.1.4.4">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.4.1.4.4.1">VG-FractalDB-1k</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.4.4.2">V</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.4.1.4.4.3">1M</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.4.4.4">98.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.4.4.5">84.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.4.4.6">88.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.4.4.7">99.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.4.4.8">82.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.4.4.9">80.9</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.4.1.4.4.10">91.2</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.4.1.4.4.11">89.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.4.4.12">92.7</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.4.1.4.4.13">83.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.4.4.14">88.0</td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.1.5.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T3.4.1.5.5.1">VG-FractalDB-1k</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.5.5.2">G</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.4.1.5.5.3">1M</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.5.5.4">87.5</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.5.5.5">68.4</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.5.5.6">11.2</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.5.5.7">82.1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.5.5.8">57.6</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.5.5.9">80.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.4.1.5.5.10">82.8</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.4.1.5.5.11">67.2</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.5.5.12">92.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.4.1.5.5.13">83.3</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.5.5.14">88.0</td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.1.6.6" style="background-color:#E6E6E6;">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S4.T3.4.1.6.6.1"><span class="ltx_text" id="S4.T3.4.1.6.6.1.1" style="background-color:#E6E6E6;">VG-FractalDB-1k</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.1.6.6.2"><span class="ltx_text" id="S4.T3.4.1.6.6.2.1" style="background-color:#E6E6E6;">V+G</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T3.4.1.6.6.3"><span class="ltx_text" id="S4.T3.4.1.6.6.3.1" style="background-color:#E6E6E6;">1M</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.1.6.6.4"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.6.6.4.1" style="background-color:#E6E6E6;">98.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.1.6.6.5"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.6.6.5.1" style="background-color:#E6E6E6;">85.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.1.6.6.6"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.6.6.6.1" style="background-color:#E6E6E6;">89.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.1.6.6.7"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.6.6.7.1" style="background-color:#E6E6E6;">99.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.1.6.6.8"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.6.6.8.1" style="background-color:#E6E6E6;">83.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.1.6.6.9"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.6.6.9.1" style="background-color:#E6E6E6;">81.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T3.4.1.6.6.10"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.6.6.10.1" style="background-color:#E6E6E6;">92.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T3.4.1.6.6.11"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.6.6.11.1" style="background-color:#E6E6E6;">90.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.1.6.6.12"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.6.6.12.1" style="background-color:#E6E6E6;">92.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T3.4.1.6.6.13"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.6.6.13.1" style="background-color:#E6E6E6;">83.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.1.6.6.14"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.6.6.14.1" style="background-color:#E6E6E6;">88.3</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Comparative analysis in image recognition</h3>
<div class="ltx_para ltx_noindent" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p1.1.1">Image classification.</span>
TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T4" title="Table 4 â€£ 4.3 Comparative analysis in image recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">4</span></a> compares the fine-tuning results with existing pre-training methods (SL, SSL, and FDSL) in image classification.
TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T4" title="Table 4 â€£ 4.3 Comparative analysis in image recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">4</span></a> shows that the FSVGP (VG-FractalDB-1k) improvement compared with training from scratch (random initialization) in all datasets.
In addition, the FSVGP (VG-FractalDB-1k) pre-trained model shows improvement compared with previous FDSL methods. In particular, FSVGP (VG-FractalDB-1k) improves performance by Avg. +0.3% from VisualAtom-21k despite the number of pre-training data is 1/21.
However, FSVGP did not surpass the fine-tuning performance of SL, DINO, and MAE. Nevertheless, given real dataset issues associated with copyright, privacy, and social bias, we demonstrate the benefits of FSVGP.</p>
</div>
<figure class="ltx_table" id="S4.T4">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T4.3.1.1" style="font-size:90%;">Table 4</span>: </span><span class="ltx_text" id="S4.T4.4.2" style="font-size:90%;">Comparison of the latest supervised learning (SL), SSL, and FDSL methods in 2D image classification. â€˜Modalâ€™ indicates a modality with â€˜Vâ€™isual and/or â€˜Gâ€™eometric inputs. The best scores for each learning type are shown in <span class="ltx_text ltx_font_bold" id="S4.T4.4.2.1">bold</span>.
</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T4.5" style="width:541.8pt;height:132pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-63.5pt,15.4pt) scale(0.81,0.81) ;">
<table class="ltx_tabular ltx_align_middle" id="S4.T4.5.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.5.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T4.5.1.1.1.1">Method</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.5.1.1.1.2">#Data</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.5.1.1.1.3">Modal</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T4.5.1.1.1.4">Supervision</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.5.1.1.1.5"><span class="ltx_text" id="S4.T4.5.1.1.1.5.1" style="color:#0D4DC7;">C10</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.5.1.1.1.6"><span class="ltx_text" id="S4.T4.5.1.1.1.6.1" style="color:#0D4DC7;">C100</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.5.1.1.1.7"><span class="ltx_text" id="S4.T4.5.1.1.1.7.1" style="color:#0D4DC7;">Cars</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.5.1.1.1.8"><span class="ltx_text" id="S4.T4.5.1.1.1.8.1" style="color:#0D4DC7;">Flowers</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.5.1.1.1.9"><span class="ltx_text" id="S4.T4.5.1.1.1.9.1" style="color:#0D4DC7;">VOC12</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.5.1.1.1.10"><span class="ltx_text" id="S4.T4.5.1.1.1.10.1" style="color:#0D4DC7;">P30</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T4.5.1.1.1.11"><span class="ltx_text" id="S4.T4.5.1.1.1.11.1" style="color:#0D4DC7;">IN100</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.5.1.1.1.12">Avg.</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.1.2.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.2.2.1">From scratch</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.1.2.2.2">â€“</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.1.2.2.3">â€“</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.5.1.2.2.4">â€“</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.1.2.2.5">78.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.1.2.2.6">57.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.1.2.2.7">16.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.1.2.2.8">77.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.1.2.2.9">64.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.1.2.2.10">75.7</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.5.1.2.2.11">73.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.1.2.2.12">63.3</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.1.3.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.3.3.1">ImageNet-1k</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.1.3.3.2">1.2M</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.1.3.3.3">V</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.5.1.3.3.4">SL</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.1.3.3.5">99.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.1.3.3.6">89.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.1.3.3.7">81.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.1.3.3.8">99.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.1.3.3.9">86.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.1.3.3.10">82.1</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.5.1.3.3.11">93.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.1.3.3.12">90.2</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.1.4.4">
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.4.4.1">ImageNet-1k</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.4.4.2">1.2M</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.4.4.3">V</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.5.1.4.4.4">SSL (DINO)</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.4.4.5">98.9</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.4.4.6">88.9</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.4.4.7"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.4.4.7.1">92.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.4.4.8">99.6</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.4.4.9">89.4</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.4.4.10">82.3</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.5.1.4.4.11">93.2</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.4.4.12">92.1</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.1.5.5">
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.5.5.1">ImageNet-1k</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.5.5.2">1.2M</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.5.5.3">V</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.5.1.5.5.4">SSL (MAE)</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.5.5.5"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.5.5.5.1">99.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.5.5.6"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.5.5.6.1">90.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.5.5.7">91.3</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.5.5.8"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.5.5.8.1">99.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.5.5.9"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.5.5.9.1">90.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.5.5.10"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.5.5.10.1">82.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.5.1.5.5.11"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.5.5.11.1">94.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.5.5.12"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.5.5.12.1">92.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.1.6.6">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.5.1.6.6.1">ExFractalDB-21kÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib17" title="">17</a>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.1.6.6.2">21M</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.1.6.6.3">V</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.5.1.6.6.4">FDSL</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.1.6.6.5">97.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.1.6.6.6">85.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.1.6.6.7">88.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.1.6.6.8"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.6.6.8.1">99.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.1.6.6.9">82.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.1.6.6.10">81.6</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.5.1.6.6.11">90.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.1.6.6.12">89.3</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.1.7.7">
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.7.7.1">RCDB-21kÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib17" title="">17</a>]</cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.7.7.2">21M</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.7.7.3">V</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.5.1.7.7.4">FDSL</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.7.7.5">96.8</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.7.7.6">82.9</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.7.7.7">85.9</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.7.7.8">99.0</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.7.7.9">81.2</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.7.7.10">81.2</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.5.1.7.7.11">90.2</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.7.7.12">88.2</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.1.8.8">
<td class="ltx_td ltx_align_left" id="S4.T4.5.1.8.8.1">VisualAtom-21kÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib38" title="">38</a>]</cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.8.8.2">21M</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.8.8.3">V</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.5.1.8.8.4">FDSL</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.8.8.5">97.7</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.8.8.6"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.8.8.6.1">86.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.8.8.7"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.8.8.7.1">89.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.8.8.8">99.0</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.8.8.9">82.4</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.8.8.10">81.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.5.1.8.8.11">91.3</td>
<td class="ltx_td ltx_align_center" id="S4.T4.5.1.8.8.12">89.7</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.1.9.9" style="background-color:#E6E6E6;">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T4.5.1.9.9.1"><span class="ltx_text" id="S4.T4.5.1.9.9.1.1" style="background-color:#E6E6E6;">VG-FractalDB-1k</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.5.1.9.9.2"><span class="ltx_text" id="S4.T4.5.1.9.9.2.1" style="background-color:#E6E6E6;">1.0M</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.5.1.9.9.3"><span class="ltx_text" id="S4.T4.5.1.9.9.3.1" style="background-color:#E6E6E6;">V + G</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T4.5.1.9.9.4"><span class="ltx_text" id="S4.T4.5.1.9.9.4.1" style="background-color:#E6E6E6;">FDSL (FSVGP)</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.5.1.9.9.5"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.9.9.5.1" style="background-color:#E6E6E6;">98.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.5.1.9.9.6"><span class="ltx_text" id="S4.T4.5.1.9.9.6.1" style="background-color:#E6E6E6;">85.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.5.1.9.9.7"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.9.9.7.1" style="background-color:#E6E6E6;">89.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.5.1.9.9.8"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.9.9.8.1" style="background-color:#E6E6E6;">99.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.5.1.9.9.9"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.9.9.9.1" style="background-color:#E6E6E6;">83.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.5.1.9.9.10"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.9.9.10.1" style="background-color:#E6E6E6;">81.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T4.5.1.9.9.11"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.9.9.11.1" style="background-color:#E6E6E6;">92.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.5.1.9.9.12"><span class="ltx_text ltx_font_bold" id="S4.T4.5.1.9.9.12.1" style="background-color:#E6E6E6;">90.0</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p2.1.1">Object detection and instance segmentation.</span>
We compare FSVGP with existing pre-training models for the fine-tuning results on average precision (AP) to COCO object detection and instance segmentation in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T6" title="Table 6 â€£ 4.3 Comparative analysis in image recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">6</span></a>.
We employ ViT-B as the backbone network and use MaskR-CNN as the detection head, referring from ViTDeT. TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T6" title="Table 6 â€£ 4.3 Comparative analysis in image recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">6</span></a> reports that FSVGP has superior results to training from scratch (random initialization) for COCO object detection and instance segmentation.
In comparison to VisualAtom-21k, FSVGP (VG-FractalDB-1k) provides 2.5% and 2.0% higher AP in visual detection and segmentation, respectively.
FSVGP (VG-FractalDB-1k) is inferior to SAM and MAE. However, FSVGP (VG-FractalDB-1k) outperforms ImageNet supervised pre-training and DINO despite synthetic pre-training.
From these results, ViT has a lower inductive bias, but because FSVGP is trained with visual and geometric modalities, it has the potential to give ViT a stronger inductive bias regarding spatial information and object shape than ImageNet supervised pre-training.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.3"><span class="ltx_text ltx_font_bold" id="S4.SS3.p3.3.1">ImageNet-1k classification.</span>
TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T6" title="Table 6 â€£ 4.3 Comparative analysis in image recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">6</span></a> presents the fine-tuning accuracy on ImageNet-1k with different image resolutions (<math alttext="224\times 224" class="ltx_Math" display="inline" id="S4.SS3.p3.1.m1.1"><semantics id="S4.SS3.p3.1.m1.1a"><mrow id="S4.SS3.p3.1.m1.1.1" xref="S4.SS3.p3.1.m1.1.1.cmml"><mn id="S4.SS3.p3.1.m1.1.1.2" xref="S4.SS3.p3.1.m1.1.1.2.cmml">224</mn><mo id="S4.SS3.p3.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.SS3.p3.1.m1.1.1.1.cmml">Ã—</mo><mn id="S4.SS3.p3.1.m1.1.1.3" xref="S4.SS3.p3.1.m1.1.1.3.cmml">224</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.1.m1.1b"><apply id="S4.SS3.p3.1.m1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1"><times id="S4.SS3.p3.1.m1.1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1.1"></times><cn id="S4.SS3.p3.1.m1.1.1.2.cmml" type="integer" xref="S4.SS3.p3.1.m1.1.1.2">224</cn><cn id="S4.SS3.p3.1.m1.1.1.3.cmml" type="integer" xref="S4.SS3.p3.1.m1.1.1.3">224</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.1.m1.1c">224\times 224</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.1.m1.1d">224 Ã— 224</annotation></semantics></math> or <math alttext="384\times 384" class="ltx_Math" display="inline" id="S4.SS3.p3.2.m2.1"><semantics id="S4.SS3.p3.2.m2.1a"><mrow id="S4.SS3.p3.2.m2.1.1" xref="S4.SS3.p3.2.m2.1.1.cmml"><mn id="S4.SS3.p3.2.m2.1.1.2" xref="S4.SS3.p3.2.m2.1.1.2.cmml">384</mn><mo id="S4.SS3.p3.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.SS3.p3.2.m2.1.1.1.cmml">Ã—</mo><mn id="S4.SS3.p3.2.m2.1.1.3" xref="S4.SS3.p3.2.m2.1.1.3.cmml">384</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.2.m2.1b"><apply id="S4.SS3.p3.2.m2.1.1.cmml" xref="S4.SS3.p3.2.m2.1.1"><times id="S4.SS3.p3.2.m2.1.1.1.cmml" xref="S4.SS3.p3.2.m2.1.1.1"></times><cn id="S4.SS3.p3.2.m2.1.1.2.cmml" type="integer" xref="S4.SS3.p3.2.m2.1.1.2">384</cn><cn id="S4.SS3.p3.2.m2.1.1.3.cmml" type="integer" xref="S4.SS3.p3.2.m2.1.1.3">384</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.2.m2.1c">384\times 384</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.2.m2.1d">384 Ã— 384</annotation></semantics></math>), compared with representative conventional approaches.
TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T6" title="Table 6 â€£ 4.3 Comparative analysis in image recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">6</span></a> reveals that FSVGP (VG-FractalDB-1k) performs comparably to the VisualAtom-21k pre-trained model in image resolution, respectively.
Moreover, it is noteworthy that the large-scale FSVGP (VG-FractalDB-21k; 21000 categories, 1000 instances per category) achieves a similar performance of JFT-300MÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib10" title="">10</a>]</cite> pre-training (83.8% vs. 84.2%), even though FSVGP using about 1/14 of the pre-training data when fine-tuning with image resolutions of <math alttext="384\times 384" class="ltx_Math" display="inline" id="S4.SS3.p3.3.m3.1"><semantics id="S4.SS3.p3.3.m3.1a"><mrow id="S4.SS3.p3.3.m3.1.1" xref="S4.SS3.p3.3.m3.1.1.cmml"><mn id="S4.SS3.p3.3.m3.1.1.2" xref="S4.SS3.p3.3.m3.1.1.2.cmml">384</mn><mo id="S4.SS3.p3.3.m3.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.SS3.p3.3.m3.1.1.1.cmml">Ã—</mo><mn id="S4.SS3.p3.3.m3.1.1.3" xref="S4.SS3.p3.3.m3.1.1.3.cmml">384</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.3.m3.1b"><apply id="S4.SS3.p3.3.m3.1.1.cmml" xref="S4.SS3.p3.3.m3.1.1"><times id="S4.SS3.p3.3.m3.1.1.1.cmml" xref="S4.SS3.p3.3.m3.1.1.1"></times><cn id="S4.SS3.p3.3.m3.1.1.2.cmml" type="integer" xref="S4.SS3.p3.3.m3.1.1.2">384</cn><cn id="S4.SS3.p3.3.m3.1.1.3.cmml" type="integer" xref="S4.SS3.p3.3.m3.1.1.3">384</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.3.m3.1c">384\times 384</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p3.3.m3.1d">384 Ã— 384</annotation></semantics></math>. We consider that the result is worthwhile because JFT-300M is a non-public dataset. However, VG-FractalDB is more transparent and has fewer copyright, privacy, and social bias issues.</p>
</div>
<figure class="ltx_table" id="S4.T6">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" id="S4.T6.4" style="width:225.5pt;">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.T6.4.6.1.1" style="font-size:90%;">Table 5</span>: </span><span class="ltx_text" id="S4.T6.4.7.2" style="font-size:90%;">
Comparison of representative pre-trained models in image object detection and instance segmentation. The best values for each learning type are in <span class="ltx_text ltx_font_bold" id="S4.T6.4.7.2.1">bold</span>.</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T6.4.4" style="width:208.1pt;height:128.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-56.0pt,34.6pt) scale(0.65,0.65) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T6.4.4.4">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T6.4.4.4.5.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S4.T6.4.4.4.5.1.1">Method</th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T6.4.4.4.5.1.2"><span class="ltx_text" id="S4.T6.4.4.4.5.1.2.1" style="color:#0D4DC7;">COCO Det</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T6.4.4.4.5.1.3"><span class="ltx_text" id="S4.T6.4.4.4.5.1.3.1" style="color:#0D4DC7;">COCO Ins Seg</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.4.4.4">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T6.4.4.4.4.5"></th>
<td class="ltx_td ltx_align_center" id="S4.T6.2.2.2.2.2">AP<sub class="ltx_sub" id="S4.T6.2.2.2.2.2.1"><span class="ltx_text ltx_font_italic" id="S4.T6.2.2.2.2.2.1.1">50</span></sub> / AP / AP<sub class="ltx_sub" id="S4.T6.2.2.2.2.2.2"><span class="ltx_text ltx_font_italic" id="S4.T6.2.2.2.2.2.2.1">75</span></sub>
</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.4.4.4.4">AP<sub class="ltx_sub" id="S4.T6.4.4.4.4.4.1"><span class="ltx_text ltx_font_italic" id="S4.T6.4.4.4.4.4.1.1">50</span></sub> / AP / AP<sub class="ltx_sub" id="S4.T6.4.4.4.4.4.2"><span class="ltx_text ltx_font_italic" id="S4.T6.4.4.4.4.4.2.1">75</span></sub>
</td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.4.4.6.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T6.4.4.4.6.2.1">From scratch</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.4.4.4.6.2.2">65.7 / 45.5 / 49.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.4.4.4.6.2.3">62.8 / 40.4 / 43.7</td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.4.4.7.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T6.4.4.4.7.3.1">ImageNet-1k (SL)</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.4.4.4.7.3.2">63.9 / 43.1 / 47.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.4.4.4.7.3.3">60.9 / 38.9 / 41.7</td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.4.4.8.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T6.4.4.4.8.4.1">ImageNet-1k (DINO)</th>
<td class="ltx_td ltx_align_center" id="S4.T6.4.4.4.8.4.2">65.0 / 44.6 / 48.8</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.4.4.8.4.3">62.3 / 39.9 / 42.8</td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.4.4.9.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T6.4.4.4.9.5.1">ImageNet-1k (MAE)</th>
<td class="ltx_td ltx_align_center" id="S4.T6.4.4.4.9.5.2">
<span class="ltx_text ltx_font_bold" id="S4.T6.4.4.4.9.5.2.1">70.7</span> / <span class="ltx_text ltx_font_bold" id="S4.T6.4.4.4.9.5.2.2">50.5</span> / <span class="ltx_text ltx_font_bold" id="S4.T6.4.4.4.9.5.2.3">55.4</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.4.4.9.5.3">68.1 / 44.8 / <span class="ltx_text ltx_font_bold" id="S4.T6.4.4.4.9.5.3.1">48.6</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.4.4.10.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T6.4.4.4.10.6.1">SAM-1B (SAM)</th>
<td class="ltx_td ltx_align_center" id="S4.T6.4.4.4.10.6.2">
<span class="ltx_text ltx_font_bold" id="S4.T6.4.4.4.10.6.2.1">70.7</span> / <span class="ltx_text ltx_font_bold" id="S4.T6.4.4.4.10.6.2.2">50.5</span> / 55.3</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.4.4.10.6.3">
<span class="ltx_text ltx_font_bold" id="S4.T6.4.4.4.10.6.3.1">68.4</span> / <span class="ltx_text ltx_font_bold" id="S4.T6.4.4.4.10.6.3.2">45.0</span> / 48.5</td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.4.4.11.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T6.4.4.4.11.7.1">ExFractalDB-21k</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.4.4.4.11.7.2">66.8 / 46.1 / 50.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.4.4.4.11.7.3">63.8 / 40.7 / 43.4</td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.4.4.12.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T6.4.4.4.12.8.1">RCDB-21k</th>
<td class="ltx_td ltx_align_center" id="S4.T6.4.4.4.12.8.2">64.5 / 44.1 / 48.1</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.4.4.12.8.3">61.7 / 39.1 / 41.5</td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.4.4.13.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T6.4.4.4.13.9.1">VisualAtom-21k</th>
<td class="ltx_td ltx_align_center" id="S4.T6.4.4.4.13.9.2">66.3 / 45.4 / 49.8</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.4.4.13.9.3">63.3 / 40.4 / 42.9</td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.4.4.14.10" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T6.4.4.4.14.10.1"><span class="ltx_text" id="S4.T6.4.4.4.14.10.1.1" style="background-color:#E6E6E6;">VG-FractalDB-1k (FSVGP)</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T6.4.4.4.14.10.2"><span class="ltx_text ltx_font_bold" id="S4.T6.4.4.4.14.10.2.1" style="background-color:#E6E6E6;">68.3<span class="ltx_text ltx_font_medium" id="S4.T6.4.4.4.14.10.2.1.1"> / </span>47.9<span class="ltx_text ltx_font_medium" id="S4.T6.4.4.4.14.10.2.1.2"> / </span>51.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T6.4.4.4.14.10.3"><span class="ltx_text ltx_font_bold" id="S4.T6.4.4.4.14.10.3.1" style="background-color:#E6E6E6;">65.6<span class="ltx_text ltx_font_medium" id="S4.T6.4.4.4.14.10.3.1.1"> / </span>42.4<span class="ltx_text ltx_font_medium" id="S4.T6.4.4.4.14.10.3.1.2"> / </span>45.3</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" id="S4.T6.17" style="width:195.1pt;">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.T6.17.15.1.1" style="font-size:90%;">Table 6</span>: </span><span class="ltx_text" id="S4.T6.17.16.2" style="font-size:90%;">Comparison of fine-tuning accuracy on ImageNet-1k. The best value for each image resolution is in <span class="ltx_text ltx_font_bold" id="S4.T6.17.16.2.1">bold</span>.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T6.17.13" style="width:239.7pt;height:146.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-86.8pt,52.9pt) scale(0.58,0.58) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T6.17.13.13">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T6.17.13.13.14.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T6.17.13.13.14.1.1">Method</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T6.17.13.13.14.1.2">Res.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T6.17.13.13.14.1.3">Image</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T6.17.13.13.14.1.4"><span class="ltx_text" id="S4.T6.17.13.13.14.1.4.1" style="color:#0D4DC7;">ImageNet-1k</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T6.5.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T6.5.1.1.1.2">From scratch</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T6.5.1.1.1.1">224<sup class="ltx_sup" id="S4.T6.5.1.1.1.1.1">2</sup>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.5.1.1.1.3">Real</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.5.1.1.1.4">80.5</td>
</tr>
<tr class="ltx_tr" id="S4.T6.6.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T6.6.2.2.2.2">ImageNet-1k (DINO)Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib3" title="">3</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T6.6.2.2.2.1">224<sup class="ltx_sup" id="S4.T6.6.2.2.2.1.1">2</sup>
</th>
<td class="ltx_td ltx_align_center" id="S4.T6.6.2.2.2.3">Real</td>
<td class="ltx_td ltx_align_center" id="S4.T6.6.2.2.2.4">82.8</td>
</tr>
<tr class="ltx_tr" id="S4.T6.7.3.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T6.7.3.3.3.2">ImageNet-1k (MAE)Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib12" title="">12</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T6.7.3.3.3.1">224<sup class="ltx_sup" id="S4.T6.7.3.3.3.1.1">2</sup>
</th>
<td class="ltx_td ltx_align_center" id="S4.T6.7.3.3.3.3">Real</td>
<td class="ltx_td ltx_align_center" id="S4.T6.7.3.3.3.4"><span class="ltx_text ltx_font_bold" id="S4.T6.7.3.3.3.4.1">83.6</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.8.4.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T6.8.4.4.4.2">ExFractalDB-21kÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib17" title="">17</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T6.8.4.4.4.1">224<sup class="ltx_sup" id="S4.T6.8.4.4.4.1.1">2</sup>
</th>
<td class="ltx_td ltx_align_center" id="S4.T6.8.4.4.4.3">Synthetic</td>
<td class="ltx_td ltx_align_center" id="S4.T6.8.4.4.4.4">82.7</td>
</tr>
<tr class="ltx_tr" id="S4.T6.9.5.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T6.9.5.5.5.2">RCDB-21kÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib17" title="">17</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T6.9.5.5.5.1">224<sup class="ltx_sup" id="S4.T6.9.5.5.5.1.1">2</sup>
</th>
<td class="ltx_td ltx_align_center" id="S4.T6.9.5.5.5.3">Synthetic</td>
<td class="ltx_td ltx_align_center" id="S4.T6.9.5.5.5.4">82.4</td>
</tr>
<tr class="ltx_tr" id="S4.T6.10.6.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T6.10.6.6.6.2">VisualAtom-21kÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib38" title="">38</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T6.10.6.6.6.1">224<sup class="ltx_sup" id="S4.T6.10.6.6.6.1.1">2</sup>
</th>
<td class="ltx_td ltx_align_center" id="S4.T6.10.6.6.6.3">Synthetic</td>
<td class="ltx_td ltx_align_center" id="S4.T6.10.6.6.6.4">82.7</td>
</tr>
<tr class="ltx_tr" id="S4.T6.11.7.7.7" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T6.11.7.7.7.2"><span class="ltx_text" id="S4.T6.11.7.7.7.2.1" style="background-color:#E6E6E6;">VG-FractalDB-1k (FSVGP)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T6.11.7.7.7.1"><span class="ltx_text" id="S4.T6.11.7.7.7.1.1" style="background-color:#E6E6E6;">224<sup class="ltx_sup" id="S4.T6.11.7.7.7.1.1.1"><span class="ltx_text" id="S4.T6.11.7.7.7.1.1.1.1" style="background-color:#E6E6E6;">2</span></sup></span></th>
<td class="ltx_td ltx_align_center" id="S4.T6.11.7.7.7.3"><span class="ltx_text" id="S4.T6.11.7.7.7.3.1" style="background-color:#E6E6E6;">Synthetic</span></td>
<td class="ltx_td ltx_align_center" id="S4.T6.11.7.7.7.4"><span class="ltx_text" id="S4.T6.11.7.7.7.4.1" style="background-color:#E6E6E6;">82.7</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.12.8.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T6.12.8.8.8.2">From scratch</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T6.12.8.8.8.1">384<sup class="ltx_sup" id="S4.T6.12.8.8.8.1.1">2</sup>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.12.8.8.8.3">Real</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.12.8.8.8.4">81.2</td>
</tr>
<tr class="ltx_tr" id="S4.T6.13.9.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T6.13.9.9.9.2">ImageNet-21k (SL)Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib10" title="">10</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T6.13.9.9.9.1">384<sup class="ltx_sup" id="S4.T6.13.9.9.9.1.1">2</sup>
</th>
<td class="ltx_td ltx_align_center" id="S4.T6.13.9.9.9.3">Real</td>
<td class="ltx_td ltx_align_center" id="S4.T6.13.9.9.9.4">83.0</td>
</tr>
<tr class="ltx_tr" id="S4.T6.14.10.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T6.14.10.10.10.2">JFT-300M (<span class="ltx_text ltx_font_italic" id="S4.T6.14.10.10.10.2.1">Dosovitskiy et al.,</span>) Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib10" title="">10</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T6.14.10.10.10.1">384<sup class="ltx_sup" id="S4.T6.14.10.10.10.1.1">2</sup>
</th>
<td class="ltx_td ltx_align_center" id="S4.T6.14.10.10.10.3">Real</td>
<td class="ltx_td ltx_align_center" id="S4.T6.14.10.10.10.4"><span class="ltx_text ltx_font_bold" id="S4.T6.14.10.10.10.4.1">84.2</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.15.11.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T6.15.11.11.11.2">VisualAtom-21kÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib38" title="">38</a>]</cite>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T6.15.11.11.11.1">384<sup class="ltx_sup" id="S4.T6.15.11.11.11.1.1">2</sup>
</th>
<td class="ltx_td ltx_align_center" id="S4.T6.15.11.11.11.3">Synthetic</td>
<td class="ltx_td ltx_align_center" id="S4.T6.15.11.11.11.4">83.7</td>
</tr>
<tr class="ltx_tr" id="S4.T6.16.12.12.12" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T6.16.12.12.12.2"><span class="ltx_text" id="S4.T6.16.12.12.12.2.1" style="background-color:#E6E6E6;">VG-FractalDB-1k (FSVGP)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T6.16.12.12.12.1"><span class="ltx_text" id="S4.T6.16.12.12.12.1.1" style="background-color:#E6E6E6;">384<sup class="ltx_sup" id="S4.T6.16.12.12.12.1.1.1"><span class="ltx_text" id="S4.T6.16.12.12.12.1.1.1.1" style="background-color:#E6E6E6;">2</span></sup></span></th>
<td class="ltx_td ltx_align_center" id="S4.T6.16.12.12.12.3"><span class="ltx_text" id="S4.T6.16.12.12.12.3.1" style="background-color:#E6E6E6;">Synthetic</span></td>
<td class="ltx_td ltx_align_center" id="S4.T6.16.12.12.12.4"><span class="ltx_text" id="S4.T6.16.12.12.12.4.1" style="background-color:#E6E6E6;">83.6</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.17.13.13.13" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T6.17.13.13.13.2"><span class="ltx_text" id="S4.T6.17.13.13.13.2.1" style="background-color:#E6E6E6;">VG-FractalDB-21k (FSVGP)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S4.T6.17.13.13.13.1"><span class="ltx_text" id="S4.T6.17.13.13.13.1.1" style="background-color:#E6E6E6;">384<sup class="ltx_sup" id="S4.T6.17.13.13.13.1.1.1"><span class="ltx_text" id="S4.T6.17.13.13.13.1.1.1.1" style="background-color:#E6E6E6;">2</span></sup></span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T6.17.13.13.13.3"><span class="ltx_text" id="S4.T6.17.13.13.13.3.1" style="background-color:#E6E6E6;">Synthetic</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T6.17.13.13.13.4"><span class="ltx_text" id="S4.T6.17.13.13.13.4.1" style="background-color:#E6E6E6;">83.8</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</div>
</div>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Comparative analysis in geometric recognition</h3>
<div class="ltx_para ltx_noindent" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1"><span class="ltx_text ltx_font_bold" id="S4.SS4.p1.1.1">3D object classification.</span>
In TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T7" title="Table 7 â€£ 4.4 Comparative analysis in geometric recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">7</span></a>, we evaluate the fine-tuning accuracy on ModelNet40 and three subsets of ScanObjectNN, namely {OBJ-BG, OBJ-ONLY, PB-T50-RS} in 3D object classification.
TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#S4.T7" title="Table 7 â€£ 4.4 Comparative analysis in geometric recognition â€£ 4 Experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">7</span></a> shows that FSVGP (VG-FractalDB-1k) yields more accurate performance than training from scratch (random initialization), similar to the experimental results in image classification.
Furthermore, FSVGP (VG-FractalDB-1k) improves the average accuracy in fine-tuning performance by +0.4% compared to the latest FDSL method (PC-FractalDB).
In contrast, FSVGP (VG-FractalDB-1k) has lower fine-tuning accuracy than ShapeNet self-supervised pre-training methods (PointBERT, PointMAE, and MaskPoint).
One reason for this result may be that there are many overlapping categories, such as chairs, desks, etc., in the pre-training dataset (ShapeNet) and the fine-tuning datasets (ModelNet40 and ScanOjectNN). However, the goal of FSVGP is not only to perform the highest result on a specific task but also to achieve a superior pre-training effect for various tasks.</p>
</div>
<figure class="ltx_table" id="S4.T7">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T7.3.1.1" style="font-size:90%;">Table 7</span>: </span><span class="ltx_text" id="S4.T7.4.2" style="font-size:90%;">
Comparison of the latest supervised learning (SL), SSL, and FDSL methods in 3D object classification. â€˜Modalâ€™ indicates a modality with â€˜Vâ€™isual and/or â€˜Gâ€™eometric inputs. The best score for each learning type is in <span class="ltx_text ltx_font_bold" id="S4.T7.4.2.1">bold</span>.
</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T7.5" style="width:427.5pt;height:118.5pt;vertical-align:-6.2pt;"><span class="ltx_transformed_inner" style="transform:translate(-60.3pt,15.8pt) scale(0.78,0.78) ;">
<table class="ltx_tabular ltx_align_middle" id="S4.T7.5.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T7.5.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T7.5.1.1.1.1">Method</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T7.5.1.1.1.2">#Data</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T7.5.1.1.1.3">Modal</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T7.5.1.1.1.4">Supervision</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T7.5.1.1.1.5"><span class="ltx_text" id="S4.T7.5.1.1.1.5.1" style="color:#33801C;">ModelNet40</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T7.5.1.1.1.6"><span class="ltx_text" id="S4.T7.5.1.1.1.6.1" style="color:#33801C;">ScanObjectNN</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T7.5.1.1.1.7">Avg.</td>
</tr>
<tr class="ltx_tr" id="S4.T7.5.1.2.2">
<td class="ltx_td" id="S4.T7.5.1.2.2.1"></td>
<td class="ltx_td" id="S4.T7.5.1.2.2.2"></td>
<td class="ltx_td" id="S4.T7.5.1.2.2.3"></td>
<td class="ltx_td ltx_border_r" id="S4.T7.5.1.2.2.4"></td>
<td class="ltx_td" id="S4.T7.5.1.2.2.5"></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.5.1.2.2.6">OBJ-BG / OBJ-ONLY / PB-T50-RS</td>
<td class="ltx_td" id="S4.T7.5.1.2.2.7"></td>
</tr>
<tr class="ltx_tr" id="S4.T7.5.1.3.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T7.5.1.3.3.1">From scratch</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.5.1.3.3.2">â€“</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.5.1.3.3.3">â€“</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T7.5.1.3.3.4">â€“</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.5.1.3.3.5">92.1</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T7.5.1.3.3.6">86.6 Â Â Â  / Â Â Â  86.9 Â Â Â  / Â Â Â  81.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.5.1.3.3.7">86.7</td>
</tr>
<tr class="ltx_tr" id="S4.T7.5.1.4.4">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T7.5.1.4.4.1">ShapeNet</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.5.1.4.4.2">50k</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.5.1.4.4.3">G</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T7.5.1.4.4.4">SSL (Point-BERT)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.5.1.4.4.5"><span class="ltx_text ltx_font_bold" id="S4.T7.5.1.4.4.5.1">93.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T7.5.1.4.4.6">
<span class="ltx_text ltx_font_bold" id="S4.T7.5.1.4.4.6.1">90.5</span> Â Â Â  / Â Â Â  <span class="ltx_text ltx_font_bold" id="S4.T7.5.1.4.4.6.2">89.5 </span>Â Â Â  / Â Â Â  85.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.5.1.4.4.7"><span class="ltx_text ltx_font_bold" id="S4.T7.5.1.4.4.7.1">89.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.5.1.5.5">
<td class="ltx_td ltx_align_left" id="S4.T7.5.1.5.5.1">ShapeNet</td>
<td class="ltx_td ltx_align_center" id="S4.T7.5.1.5.5.2">50k</td>
<td class="ltx_td ltx_align_center" id="S4.T7.5.1.5.5.3">G</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.5.1.5.5.4">SSL (Point-MAE)</td>
<td class="ltx_td ltx_align_center" id="S4.T7.5.1.5.5.5"><span class="ltx_text ltx_font_bold" id="S4.T7.5.1.5.5.5.1">93.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.5.1.5.5.6">90.4 Â Â Â  / Â Â Â  88.1 Â Â Â  / Â Â Â  <span class="ltx_text ltx_font_bold" id="S4.T7.5.1.5.5.6.1">85.8</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T7.5.1.5.5.7">89.4</td>
</tr>
<tr class="ltx_tr" id="S4.T7.5.1.6.6">
<td class="ltx_td ltx_align_left" id="S4.T7.5.1.6.6.1">ShapeNet</td>
<td class="ltx_td ltx_align_center" id="S4.T7.5.1.6.6.2">50k</td>
<td class="ltx_td ltx_align_center" id="S4.T7.5.1.6.6.3">G</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.5.1.6.6.4">SSL (MaskPoint)</td>
<td class="ltx_td ltx_align_center" id="S4.T7.5.1.6.6.5">92.8</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.5.1.6.6.6">89.5 Â Â Â  / Â Â Â  88.1 Â Â Â  / Â Â Â  83.8</td>
<td class="ltx_td ltx_align_center" id="S4.T7.5.1.6.6.7">88.6</td>
</tr>
<tr class="ltx_tr" id="S4.T7.5.1.7.7">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T7.5.1.7.7.1">PC-FractalDB-1k</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.5.1.7.7.2">1.0M</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.5.1.7.7.3">G</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T7.5.1.7.7.4">FDSL</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.5.1.7.7.5">92.6</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T7.5.1.7.7.6">88.3 Â Â Â  / Â Â Â  88.3 Â Â Â  / Â Â Â  83.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.5.1.7.7.7">88.1</td>
</tr>
<tr class="ltx_tr" id="S4.T7.5.1.8.8" style="background-color:#E6E6E6;">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T7.5.1.8.8.1"><span class="ltx_text" id="S4.T7.5.1.8.8.1.1" style="background-color:#E6E6E6;">VG-FractalDB-1k</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T7.5.1.8.8.2"><span class="ltx_text" id="S4.T7.5.1.8.8.2.1" style="background-color:#E6E6E6;">1.0M</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T7.5.1.8.8.3"><span class="ltx_text" id="S4.T7.5.1.8.8.3.1" style="background-color:#E6E6E6;">V + G</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T7.5.1.8.8.4"><span class="ltx_text" id="S4.T7.5.1.8.8.4.1" style="background-color:#E6E6E6;">FDSL (FSVGP)</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T7.5.1.8.8.5"><span class="ltx_text ltx_font_bold" id="S4.T7.5.1.8.8.5.1" style="background-color:#E6E6E6;">92.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T7.5.1.8.8.6"><span class="ltx_text ltx_font_bold" id="S4.T7.5.1.8.8.6.1" style="background-color:#E6E6E6;">88.9<span class="ltx_text ltx_font_medium" id="S4.T7.5.1.8.8.6.1.1"> Â Â Â  / Â Â Â  </span>88.5 <span class="ltx_text ltx_font_medium" id="S4.T7.5.1.8.8.6.1.2">Â Â Â  / Â Â Â  </span>83.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T7.5.1.8.8.7"><span class="ltx_text ltx_font_bold" id="S4.T7.5.1.8.8.7.1" style="background-color:#E6E6E6;">88.5</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="S4.T9">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" id="S4.T9.fig1" style="width:195.1pt;">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.T9.fig1.2.1.1" style="font-size:90%;">Table 8</span>: </span><span class="ltx_text" id="S4.T9.fig1.3.2" style="font-size:90%;">Comparison of few-shot learning.
The best averaged accuracy for each learning type is in <span class="ltx_text ltx_font_bold" id="S4.T9.fig1.3.2.1">bold</span>.
</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T9.fig1.4" style="width:209.8pt;height:143.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-18.5pt,12.7pt) scale(0.85,0.85) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T9.fig1.4.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T9.fig1.4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S4.T9.fig1.4.1.1.1.1">Method</th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S4.T9.fig1.4.1.1.1.2"><span class="ltx_text" id="S4.T9.fig1.4.1.1.1.2.1" style="color:#33801C;">ModelNet40 Classification</span></td>
</tr>
<tr class="ltx_tr" id="S4.T9.fig1.4.1.2.2">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T9.fig1.4.1.2.2.1"></th>
<td class="ltx_td ltx_align_center" colspan="2" id="S4.T9.fig1.4.1.2.2.2">5-way</td>
<td class="ltx_td ltx_align_center" colspan="2" id="S4.T9.fig1.4.1.2.2.3">10-way</td>
</tr>
<tr class="ltx_tr" id="S4.T9.fig1.4.1.3.3">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T9.fig1.4.1.3.3.1"></th>
<td class="ltx_td ltx_align_center" id="S4.T9.fig1.4.1.3.3.2">10-shot</td>
<td class="ltx_td ltx_align_center" id="S4.T9.fig1.4.1.3.3.3">20-shot</td>
<td class="ltx_td ltx_align_center" id="S4.T9.fig1.4.1.3.3.4">10-shot</td>
<td class="ltx_td ltx_align_center" id="S4.T9.fig1.4.1.3.3.5">20-shot</td>
</tr>
<tr class="ltx_tr" id="S4.T9.fig1.4.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T9.fig1.4.1.4.4.1">Scratch</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.fig1.4.1.4.4.2">94.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.fig1.4.1.4.4.3">96.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.fig1.4.1.4.4.4">91.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.fig1.4.1.4.4.5">92.8</td>
</tr>
<tr class="ltx_tr" id="S4.T9.fig1.4.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T9.fig1.4.1.5.5.1">PointBERT</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.fig1.4.1.5.5.2">94.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.fig1.4.1.5.5.3">96.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.fig1.4.1.5.5.4">91.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.fig1.4.1.5.5.5">92.7</td>
</tr>
<tr class="ltx_tr" id="S4.T9.fig1.4.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T9.fig1.4.1.6.6.1">PointMAE</th>
<td class="ltx_td ltx_align_center" id="S4.T9.fig1.4.1.6.6.2"><span class="ltx_text ltx_font_bold" id="S4.T9.fig1.4.1.6.6.2.1">96.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.fig1.4.1.6.6.3"><span class="ltx_text ltx_font_bold" id="S4.T9.fig1.4.1.6.6.3.1">97.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.fig1.4.1.6.6.4"><span class="ltx_text ltx_font_bold" id="S4.T9.fig1.4.1.6.6.4.1">92.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.fig1.4.1.6.6.5"><span class="ltx_text ltx_font_bold" id="S4.T9.fig1.4.1.6.6.5.1">95.0</span></td>
</tr>
<tr class="ltx_tr" id="S4.T9.fig1.4.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T9.fig1.4.1.7.7.1">MaskPoint</th>
<td class="ltx_td ltx_align_center" id="S4.T9.fig1.4.1.7.7.2">95.0</td>
<td class="ltx_td ltx_align_center" id="S4.T9.fig1.4.1.7.7.3">97.2</td>
<td class="ltx_td ltx_align_center" id="S4.T9.fig1.4.1.7.7.4">91.4</td>
<td class="ltx_td ltx_align_center" id="S4.T9.fig1.4.1.7.7.5">93.4</td>
</tr>
<tr class="ltx_tr" id="S4.T9.fig1.4.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T9.fig1.4.1.8.8.1">PC-FDB-1k</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.fig1.4.1.8.8.2">95.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.fig1.4.1.8.8.3"><span class="ltx_text ltx_font_bold" id="S4.T9.fig1.4.1.8.8.3.1">96.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.fig1.4.1.8.8.4">91.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.fig1.4.1.8.8.5">93.2</td>
</tr>
<tr class="ltx_tr" id="S4.T9.fig1.4.1.9.9" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T9.fig1.4.1.9.9.1"><span class="ltx_text" id="S4.T9.fig1.4.1.9.9.1.1" style="background-color:#E6E6E6;">VG-FDB-1k</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T9.fig1.4.1.9.9.2"><span class="ltx_text ltx_font_bold" id="S4.T9.fig1.4.1.9.9.2.1" style="background-color:#E6E6E6;">96.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T9.fig1.4.1.9.9.3"><span class="ltx_text" id="S4.T9.fig1.4.1.9.9.3.1" style="background-color:#E6E6E6;">96.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T9.fig1.4.1.9.9.4"><span class="ltx_text ltx_font_bold" id="S4.T9.fig1.4.1.9.9.4.1" style="background-color:#E6E6E6;">92.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T9.fig1.4.1.9.9.5"><span class="ltx_text ltx_font_bold" id="S4.T9.fig1.4.1.9.9.5.1" style="background-color:#E6E6E6;">93.3</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" id="S4.T9.4" style="width:216.8pt;">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.T9.4.6.1.1" style="font-size:90%;">Table 9</span>: </span><span class="ltx_text" id="S4.T9.4.7.2" style="font-size:90%;">Comparison of pre-training methods in 3D object detection and parts segmentation.
The best value for each learning type is in <span class="ltx_text ltx_font_bold" id="S4.T9.4.7.2.1">bold</span>.
</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T9.4.4" style="width:215.7pt;height:131.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-16.1pt,9.8pt) scale(0.87,0.87) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T9.4.4.4">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T9.4.4.4.5.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S4.T9.4.4.4.5.1.1">Method</th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T9.4.4.4.5.1.2"><span class="ltx_text" id="S4.T9.4.4.4.5.1.2.1" style="color:#33801C;">ScanNetV2 Det</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T9.4.4.4.5.1.3"><span class="ltx_text" id="S4.T9.4.4.4.5.1.3.1" style="color:#33801C;">ShapeNet PartsSeg</span></td>
</tr>
<tr class="ltx_tr" id="S4.T9.4.4.4.4">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T9.4.4.4.4.5"></th>
<td class="ltx_td ltx_align_center" id="S4.T9.2.2.2.2.2">mAP<sub class="ltx_sub" id="S4.T9.2.2.2.2.2.1"><span class="ltx_text ltx_font_italic" id="S4.T9.2.2.2.2.2.1.1">25</span></sub> / mAP<sub class="ltx_sub" id="S4.T9.2.2.2.2.2.2"><span class="ltx_text ltx_font_italic" id="S4.T9.2.2.2.2.2.2.1">50</span></sub>
</td>
<td class="ltx_td ltx_align_center" id="S4.T9.4.4.4.4.4">mIoU<sub class="ltx_sub" id="S4.T9.4.4.4.4.4.1"><span class="ltx_text ltx_font_italic" id="S4.T9.4.4.4.4.4.1.1">cat</span></sub> / mIoU<sub class="ltx_sub" id="S4.T9.4.4.4.4.4.2"><span class="ltx_text ltx_font_italic" id="S4.T9.4.4.4.4.4.2.1">ins</span></sub>
</td>
</tr>
<tr class="ltx_tr" id="S4.T9.4.4.4.6.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T9.4.4.4.6.2.1">Scratch</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.4.4.4.6.2.2">62.7 Â Â  / Â Â  37.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.4.4.4.6.2.3">83.3 Â Â Â  / Â Â Â  85.4</td>
</tr>
<tr class="ltx_tr" id="S4.T9.4.4.4.7.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T9.4.4.4.7.3.1">PointBERT</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.4.4.4.7.3.2">61.0 Â Â  / Â Â  38.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.4.4.4.7.3.3">84.1 Â Â Â  / Â Â Â  86.0</td>
</tr>
<tr class="ltx_tr" id="S4.T9.4.4.4.8.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T9.4.4.4.8.4.1">PointMAE</th>
<td class="ltx_td ltx_align_center" id="S4.T9.4.4.4.8.4.2">â€“ Â Â  / Â Â  â€“</td>
<td class="ltx_td ltx_align_center" id="S4.T9.4.4.4.8.4.3">84.1 Â Â Â  / Â Â Â  <span class="ltx_text ltx_font_bold" id="S4.T9.4.4.4.8.4.3.1">86.1</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T9.4.4.4.9.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T9.4.4.4.9.5.1">MaskPoint</th>
<td class="ltx_td ltx_align_center" id="S4.T9.4.4.4.9.5.2">
<span class="ltx_text ltx_font_bold" id="S4.T9.4.4.4.9.5.2.1">63.4</span> Â Â  / Â Â  <span class="ltx_text ltx_font_bold" id="S4.T9.4.4.4.9.5.2.2">40.6</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T9.4.4.4.9.5.3">
<span class="ltx_text ltx_font_bold" id="S4.T9.4.4.4.9.5.3.1">84.4</span> Â Â Â  / Â Â Â  86.0</td>
</tr>
<tr class="ltx_tr" id="S4.T9.4.4.4.10.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T9.4.4.4.10.6.1">PC-FDB-1k</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.4.4.4.10.6.2">63.0 Â Â  / Â Â  <span class="ltx_text ltx_font_bold" id="S4.T9.4.4.4.10.6.2.1">42.5</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.4.4.4.10.6.3">83.7 Â Â Â  / Â Â Â  <span class="ltx_text ltx_font_bold" id="S4.T9.4.4.4.10.6.3.1">85.7</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T9.4.4.4.11.7" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T9.4.4.4.11.7.1"><span class="ltx_text" id="S4.T9.4.4.4.11.7.1.1" style="background-color:#E6E6E6;">VG-FDB-1k</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T9.4.4.4.11.7.2"><span class="ltx_text ltx_font_bold" id="S4.T9.4.4.4.11.7.2.1" style="background-color:#E6E6E6;">63.7<span class="ltx_text ltx_font_medium" id="S4.T9.4.4.4.11.7.2.1.1"> Â Â  / Â Â  42.0</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T9.4.4.4.11.7.3"><span class="ltx_text ltx_font_bold" id="S4.T9.4.4.4.11.7.3.1" style="background-color:#E6E6E6;">84.1<span class="ltx_text ltx_font_medium" id="S4.T9.4.4.4.11.7.3.1.1"> Â Â Â  / Â Â Â  </span>85.7</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</div>
</div>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS4.p2">
<p class="ltx_p" id="S4.SS4.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS4.p2.1.1">Few-shot learning.</span>
We compare and verify the performance of few-shot learning on ModelNet40 in TableÂ <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:few-shot</span>. For few-shot learning, we randomly sample <span class="ltx_text ltx_font_italic" id="S4.SS4.p2.1.2">K</span> categories from ModelNet40 and <span class="ltx_text ltx_font_italic" id="S4.SS4.p2.1.3">N</span> shots of training samples from each category, following the experimental setting inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib32" title="">32</a>]</cite>.
FSVGP (VG-FractalDB-1k) achieves inspiring performance, outperforming training from scratch (random initialization) by a large margin in all few-shot settings despite different domain ModelNet40.
In addition, FSVGP (VG-FractalDB-1k) achieves equal or better performance improvement over PC-FractalDB-1k in all few-shot settings. This result shows the FSVGP can achieve few-shot learning.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS4.p3">
<p class="ltx_p" id="S4.SS4.p3.5"><span class="ltx_text ltx_font_bold" id="S4.SS4.p3.5.1">3D object detection.</span>
TableÂ <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:3ddet</span> reports fine-tuning performance for 3D bounding box mAP in 3D object detection. We fine-tune 3DETR on ScanNet. Our FSVGP (VG-FractalDB-1k) performs better under mAP<sub class="ltx_sub" id="S4.SS4.p3.5.2"><span class="ltx_text ltx_font_italic" id="S4.SS4.p3.5.2.1">25</span></sub> and mAP<sub class="ltx_sub" id="S4.SS4.p3.5.3"><span class="ltx_text ltx_font_italic" id="S4.SS4.p3.5.3.1">50</span></sub> than previous SSL methods.
The FSVGP (VG-FractalDB-1k) is 1.4 points higher than MaskPointÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib25" title="">25</a>]</cite>, the latest SSL method (42.0 vs 40.6, mAP<sub class="ltx_sub" id="S4.SS4.p3.5.4"><span class="ltx_text ltx_font_italic" id="S4.SS4.p3.5.4.1">50</span></sub>).
More significantly, FSVGP (VG-FractalDB-1k) outperforms the PC-FractalDB-1k pre-trained modelÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib44" title="">44</a>]</cite> by 0.7 points on mAP<sub class="ltx_sub" id="S4.SS4.p3.5.5"><span class="ltx_text ltx_font_italic" id="S4.SS4.p3.5.5.1">25</span></sub>, but falls short by 0.5 points on mAP<sub class="ltx_sub" id="S4.SS4.p3.5.6"><span class="ltx_text ltx_font_italic" id="S4.SS4.p3.5.6.1">50</span></sub>.
This result suggests that the potential of FSVGP works well when applied to backbone networks of 3DETR.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS4.p4">
<p class="ltx_p" id="S4.SS4.p4.3"><span class="ltx_text ltx_font_bold" id="S4.SS4.p4.3.1">Parts segmentation.</span>
TableÂ <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:3ddet</span> also compares the performance of FSVGP (VG-FractalDB-1k) with existing pre-training methods for parts segmentation. We fine-tune PointT-S on ShapeNet-parts and evaluate the performance using the mIoU for all categories (mIoU<sub class="ltx_sub" id="S4.SS4.p4.3.2"><span class="ltx_text ltx_font_italic" id="S4.SS4.p4.3.2.1">cat</span></sub>) and all instances (mIoU<sub class="ltx_sub" id="S4.SS4.p4.3.3"><span class="ltx_text ltx_font_italic" id="S4.SS4.p4.3.3.1">ins</span></sub>).
TableÂ <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:3ddet</span> shows that our FSVGP (VG-FractalDB-1k) improves results over training from scratch (random initialization), for example, by 0.8 points (84.1 vs. 83.3, mIoU<sub class="ltx_sub" id="S4.SS4.p4.3.4"><span class="ltx_text ltx_font_italic" id="S4.SS4.p4.3.4.1">cat</span></sub>). In addition, even though SSL duplicates pre-training and fine-tuning data, our method achieved performance comparable to SSL.
These results suggest that FSVGP is even more effective for recognizing more detailed 3D object structures.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Ablation study</h3>
<div class="ltx_para" id="S4.SS5.p1">
<p class="ltx_p" id="S4.SS5.p1.1">In this section, we conduct additional experiments to explore essential factors of FSVGP guiding visual-geometric representation learning.
Specifically, we investigate to answer the following questions:
(i) Which is more effective, fractal point clouds or CAD models? in FSVGP (ii) Can other generation rules be effective in FSVGP? Moreover, (iii) what is the effect of the pre-training task for VG-FractalDB?</p>
</div>
<figure class="ltx_table" id="S4.T12">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" id="S4.T12.fig1" style="width:138.8pt;">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.T12.fig1.1.1.1" style="font-size:90%;">Table 10</span>: </span><span class="ltx_text" id="S4.T12.fig1.2.2" style="font-size:90%;">ShapeNet vs. VG-FractalDB (VG-FDB) in visual geometric pre-training.
The datasets were assigned visual and geometric modalities.
</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T12.fig1.3" style="width:153.0pt;height:56.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-8.5pt,3.1pt) scale(0.9,0.9) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T12.fig1.3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T12.fig1.3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T12.fig1.3.1.1.1.1">Method</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T12.fig1.3.1.1.1.2">#data</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T12.fig1.3.1.1.1.3"><span class="ltx_text" id="S4.T12.fig1.3.1.1.1.3.1" style="color:#0D4DC7;">IN100</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T12.fig1.3.1.1.1.4"><span class="ltx_text" id="S4.T12.fig1.3.1.1.1.4.1" style="color:#33801C;">M40</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T12.fig1.3.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T12.fig1.3.1.2.1.1">ShapeNet</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T12.fig1.3.1.2.1.2">50k</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T12.fig1.3.1.2.1.3">87.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T12.fig1.3.1.2.1.4">92.7</td>
</tr>
<tr class="ltx_tr" id="S4.T12.fig1.3.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T12.fig1.3.1.3.2.1">VG-FDB</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T12.fig1.3.1.3.2.2">50k</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T12.fig1.3.1.3.2.3"><span class="ltx_text ltx_font_bold" id="S4.T12.fig1.3.1.3.2.3.1">87.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T12.fig1.3.1.3.2.4"><span class="ltx_text ltx_font_bold" id="S4.T12.fig1.3.1.3.2.4.1">92.8</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" id="S4.T12.fig2" style="width:121.4pt;">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.T12.fig2.1.1.1" style="font-size:90%;">Table 11</span>: </span><span class="ltx_text" id="S4.T12.fig2.2.2" style="font-size:90%;">Effect of generation rules. We compared Perlin noise (VG-PN-1k) with fractal (VG-FDB-1k) in FSVGP.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T12.fig2.3" style="width:127.1pt;height:56.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-7.1pt,3.1pt) scale(0.9,0.9) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T12.fig2.3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T12.fig2.3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T12.fig2.3.1.1.1.1">Method</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T12.fig2.3.1.1.1.2"><span class="ltx_text" id="S4.T12.fig2.3.1.1.1.2.1" style="color:#0D4DC7;">IN100</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T12.fig2.3.1.1.1.3"><span class="ltx_text" id="S4.T12.fig2.3.1.1.1.3.1" style="color:#33801C;">M40</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T12.fig2.3.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T12.fig2.3.1.2.1.1">VG-PN-1k</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T12.fig2.3.1.2.1.2">90.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T12.fig2.3.1.2.1.3">92.6</td>
</tr>
<tr class="ltx_tr" id="S4.T12.fig2.3.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T12.fig2.3.1.3.2.1">VG-FDB-1k</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T12.fig2.3.1.3.2.2"><span class="ltx_text ltx_font_bold" id="S4.T12.fig2.3.1.3.2.2.1">92.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T12.fig2.3.1.3.2.3"><span class="ltx_text ltx_font_bold" id="S4.T12.fig2.3.1.3.2.3.1">92.9</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" id="S4.T12.fig3" style="width:160.4pt;">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.T12.fig3.1.1.1" style="font-size:90%;">Table 12</span>: </span><span class="ltx_text" id="S4.T12.fig3.2.2" style="font-size:90%;">
Effect of supervisions in SSL (MAE) and our FSVGP. In both supervision settings, we utilized VG-FractalDB-1k (VG-FDB-1k) with visual and geometric modalities.
</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="S4.T12.fig3.3" style="width:163.9pt;height:55.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-11.2pt,3.8pt) scale(0.88,0.88) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T12.fig3.3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T12.fig3.3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T12.fig3.3.1.1.1.1">Method</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T12.fig3.3.1.1.1.2"><span class="ltx_text" id="S4.T12.fig3.3.1.1.1.2.1" style="color:#0D4DC7;">IN100</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T12.fig3.3.1.1.1.3"><span class="ltx_text" id="S4.T12.fig3.3.1.1.1.3.1" style="color:#33801C;">M40</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T12.fig3.3.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T12.fig3.3.1.2.1.1">VG-FDB-1k (MAE)</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T12.fig3.3.1.2.1.2">80.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T12.fig3.3.1.2.1.3">92.8</td>
</tr>
<tr class="ltx_tr" id="S4.T12.fig3.3.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T12.fig3.3.1.3.2.1">VG-FDB-1k (FSVGP)</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T12.fig3.3.1.3.2.2"><span class="ltx_text ltx_font_bold" id="S4.T12.fig3.3.1.3.2.2.1">92.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T12.fig3.3.1.3.2.3"><span class="ltx_text ltx_font_bold" id="S4.T12.fig3.3.1.3.2.3.1">92.9</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</div>
</div>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS5.p2">
<p class="ltx_p" id="S4.SS5.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS5.p2.1.1">(i) Which is more effective, fractal point clouds or CAD models in FSVGP?</span>
We investigate the pre-training effects in FSVGP using VG-FractalDB and an existing 3D dataset, ShapeNet.
Under the same conditions as VG-FractalDB, we project point clouds from ShapeNet onto images to generate visual-geometric data. Subsequently, the generated visual-geometric data from ShapeNet undergoes pre-training under the same conditions as FSVGP. Please refer to the <span class="ltx_text" id="S4.SS5.p2.1.2" style="color:#FF0000;">Supplementary Material</span> for instances of image and point cloud data generated from ShapeNet.
To equalize the number of instances for ShapeNet and pre-training data, VG-FractalDB undergoes random sampling of data, with 50 instances per category.
TableÂ <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:shapenet</span> shows that the VG-FractalDB pre-trained model is more accurate than the ShapeNet pre-trained model in ImageNet100 and ModelNet40 despite the same number of data.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS5.p3">
<p class="ltx_p" id="S4.SS5.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS5.p3.1.1">(ii) Can other generation rules be effective in FSVGP?</span>
We verify the pre-training effect regarding which generation rules (fractal and Perlin noise) are more effective in FSVGP.
We extended Perling Noise, effective as a dataset generation functionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib16" title="">16</a>]</cite>, to point clouds and constructed a Visual Geometric Perlin Noise (VG-PN) dataset. Please consult the <span class="ltx_text" id="S4.SS5.p3.1.2" style="color:#FF0000;">Supplementary Material</span> for additional details on the generation process of the VG-PN dataset and examples of both point clouds and images.
We pre-train VG-PN with the same config and fine-tune it for image and 3D object classification. TableÂ <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:perlin</span> shows that the VG-FractalDB outperforms the VG-PN in ImageNet100 and ModelNet40.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS5.p4">
<p class="ltx_p" id="S4.SS5.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS5.p4.1.1">(iii) Effect of pre-training tasks for VG-FractalDB.</span>
We explore the supervision types of VG-FractalDB by comparing the formula-supervised consistency label with self-supervision adopted by MAE, a representative SSL method. The implementations of decoders for the SSL are the same as MAEÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib12" title="">12</a>]</cite> and PointMAEÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib32" title="">32</a>]</cite>, and the decoders reconstruct masked patches of 2D fractal images and 3D point clouds for pre-training based on the self-supervision.
TableÂ <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:pt_task</span> shows that utilizing the formula-supervised consistency label is more effective than utilizing the self-supervision based on MAE in ImageNet100 and ModelNet40.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion and Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">This paper proposes FSVGP, which blends visual and geometric representations to achieve image and 3D object recognition on a unified transform model.
FSVGP automatically generates fractal images, fractal point clouds, and their formula-supervised consistency labels based on fractal geometry.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">In the beginning, contrary to previous visual-geometric representation learning transfer the one-way knowledge using visual and geometric modalities, we show that FSVGP effectively achieved the pre-training effects in both image and 3D object classification, detection, and segmentation.
Furthermore, TableÂ <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:shapenet</span> and TableÂ <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:perlin</span> show that VG-FractalDB pre-training is more effective than the pre-training of ShapeNet and VG-PN dataset. We consider that these results are attributed to VG-FractalDB being generated based on more parameters of generation function, allowing it to pre-train on geometric shapes that are even more complex than those in the ShapeNet and VG-PN dataset.
Finally, TableÂ <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:pt_task</span> shows the effectiveness of the pre-training by simple classification task for VG-FractalDB and suggests that FSVGP is sufficient to learn visual-geometric representation in VG-FractalDB pre-training.
These observations show that FSVGP effectively improves fine-tuning performance in image recognition and 3D object recognition despite synthetic pre-training. Furthermore, FSVGP can reduce real dataset issues such as copyright, personal information, and social bias.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.p3">
<p class="ltx_p" id="S5.p3.1"><span class="ltx_text ltx_font_bold" id="S5.p3.1.1">Technical limitations and future work.</span>
FSVGP is a pre-training method using VG-FractalDB (<span class="ltx_text ltx_font_italic" id="S5.p3.1.2">i.e.,</span> synthetic data).
A previous FDSL studyÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib30" title="">30</a>]</cite> reported that when FDSL is fine-tuning, a certain amount of real data regarding the domain gap between real and synthetic data is necessary. Therefore, compared to MAE (ImageNet), FSVGP (VG-FractalDB) is more challenging to work well with linear probing (Please consult the <span class="ltx_text" id="S5.p3.1.3" style="color:#FF0000;">Supplementary Material</span> for more details).
Designing an efficient fine-tuning approach using FSVGP will be essential.
We consider it important to validate FSVGP in 3D shape retrieval and multi-modal recognition involving birdâ€™s-eye view images and point clouds for future applications such as autonomous driving and search systems.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Acknowledgments</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">This paper is based on results obtained from a project, JPNP20006, commissioned by the New Energy and Industrial Technology Development Organization (NEDO).
A computational resource, AI Bridging Cloud Infrastructure (ABCI), provided by the National Institute of Advanced Industrial Science and Technology (AIST), was used.
We want to thank Ryota Suzuki, Yoshihiro Fukuhara, Naoya Chiba, Ryo Nakamura, Kodai Nakashima, Sora Takashima, Risa Shinoda, Masatoshi Tateno, Go Ohtani and Ryu Tadokoro for their helpful comments in the research discussions.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Afham, M., Dissanayake, I., Dissanayake, D., Dharmasiri, A., Thilakarathna, K., Rodrigo, R.: Crosspoint: Self-supervised cross-modal contrastive learning for 3d point cloud understanding. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 9902â€“9912 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Barnsley, M.F.: Fractals everywhere. Academic press (2014)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Caron, M., Touvron, H., Misra, I., JÃ©gou, H., Mairal, J., Bojanowski, P., Joulin, A.: Emerging properties in self-supervised vision transformers. In: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). pp. 9650â€“9660 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Chang, A.X., Funkhouser, T., Guibas, L., Hanrahan, P., Huang, Q., Li, Z., Savarese, S., Savva, M., Song, S., Su, H., etÂ al.: Shapenet: An information-rich 3d model repository. arXiv preprint arXiv:1512.03012 (2015)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Chiche, B.N., Horikawa, Y., Fujita, R.: Pre-training vision models with mandelbulb variations. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 22062â€“22071 (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Dai, A., Chang, A.X., Savva, M., Halber, M., Funkhouser, T., NieÃŸner, M.: Scannet: Richly-annotated 3d reconstructions of indoor scenes. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). pp. 5828â€“5839 (2017)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Dehghani, M., Djolonga, J., Mustafa, B., Padlewski, P., Heek, J., Gilmer, J., Steiner, A.P., Caron, M., Geirhos, R., Alabdulmohsin, I., etÂ al.: Scaling vision transformers to 22 billion parameters. In: Proceedings of the International Conference on Machine Learning (ICML). pp. 7480â€“7512 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Deitke, M., Liu, R., Wallingford, M., Ngo, H., Michel, O., Kusupati, A., Fan, A., Laforte, C., Voleti, V., Gadre, S.Y., VanderBilt, E., Kembhavi, A., Vondrick, C., Gkioxari, G., Ehsani, K., Schmidt, L., Farhadi, A.: Objaverse-XL: A universe of 10m+ 3d objects. In: Proceedings of the Conference on Neural Information Processing Systems Datasets and Benchmarks Track (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L.: ImageNet: A large-scale hierarchical image database. In: Proceedings of the IEEE/CVF International Conference on Computer Vision and Pattern Recognition (CVPR). pp. 248â€“255 (2009)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., Uszkoreit, J., Houlsby, N.: An image is worth 16x16 words: Transformers for image recognition at scale. In: Proceedings of the International Conference on Learning Representation (ICLR) (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Everingham, M., Eslami, S.M.A., VanÂ Gool, L., Williams, C.K.I., Winn, J., Zisserman, A.: The pascal visual object classes challenge: A retrospective. International Journal of Computer Vision (IJCV) <span class="ltx_text ltx_font_bold" id="bib.bib11.1.1">111</span>(1), 98â€“136 (2015)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
He, K., Chen, X., Xie, S., Li, Y., DollÃ¡r, P., Girshick, R.: Masked autoencoders are scalable vision learners. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 16000â€“16009 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Hou, J., Xie, S., Graham, B., Dai, A., NieÃŸner, M.: Pri3d: Can 3d priors help 2d representation learning? In: Proceedings of the IEEE/CVF International Conference on Computer Vision (CVPR). pp. 5693â€“5702 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Inoue, N., Yamagata, E., Kataoka, H.: Initialization using perlin noise for training networks with a limited amount of data. In: Proceedings of the International Conference on Pattern Recognition (ICPR). pp. 1023â€“1028 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Jain, A., Katara, P., Gkanatsios, N., Harley, A.W., Sarch, G., Aggarwal, K., Chaudhary, V., Fragkiadaki, K.: Odin: A single model for 2d and 3d segmentation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 3564â€“3574 (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Kataoka, H., Hara, K., Hayashi, R., Yamagata, E., Inoue, N.: Spatiotemporal initialization for 3d cnns with generated motion patterns. In: Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV). pp. 1279â€“1288 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Kataoka, H., Hayamizu, R., Yamada, R., Nakashima, K., Takashima, S., Zhang, X., Martinez-Noriega, E.J., Inoue, N., Yokota, R.: Replacing labeled real-image datasets with auto-generated contours. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 21232â€“21241 (June 2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Kataoka, H., Okayasu, K., Matsumoto, A., Yamagata, E., Yamada, R., Inoue, N., Nakamura, A., Satoh, Y.: Pre-training without natural images. In: Proceedings of the Asian Conference on Computer Vision (ACCV) (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Kirillov, A., Mintun, E., Ravi, N., Mao, H., Rolland, C., Gustafson, L., Xiao, T., Whitehead, S., Berg, A.C., Lo, W.Y., DollÃ¡r, P., Girshick, R.: Segment anything. arXiv preprint arXiv:2304.02643 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Krause, J., Stark, M., Deng, J., Fei-Fei, L.: 3d object representations for fine-grained categorization. In: Proceedings of the International IEEE Workshop on 3D Representation and Recognition (3DRR-13). pp. 554â€“561 (2013)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Krizhevsky, A., Hinton, G.: Learning Multiple Layers of Features from Tiny Images. Technical report, University of Toronto (2009)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Kundu, A., Yin, X., Fathi, A., Ross, D., Brewington, B., Funkhouser, T., Pantofaru, C.: Virtual multi-view fusion for 3d semantic segmentation. In: Proceedings of the European Conference on Computer Vision (ECCV). pp. 518â€“535 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Li, Y., Mao, H., Girshick, R., He, K.: Exploring plain vision transformer backbones for object detection. In: European Conference on Computer Vision (ECCV). pp. 280â€“296. Springer (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Lin, T.Y., Maire, M., Belongie, S., Bourdev, L., Girshick, R., Hays, J., Perona, P., Ramanan, D., Zitnick, C.L., Dollar, P.: Microsoft COCO: Common objects in context. In: Proceedings of the European Conference on Computer Vision (ECCV). pp. 740â€“755 (2014)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Liu, H., Cai, M., Lee, Y.J.: Masked discrimination for self-supervised learning on point clouds. In: Proceedings of the European Conference on Computer Vision (ECCV). pp. 657â€“675 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Liu, Y.C., Huang, Y.K., Chiang, H.Y., Su, H.T., Liu, Z.Y., Chen, C.T., Tseng, C.Y., Hsu, W.H.: Learning from 2d: Contrastive pixel-to-point knowledge transfer for 3d pretraining. arXiv preprint arXiv:2104.04687 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Liu, Z., Qi, X., Fu, C.W.: 3d-to-2d distillation for indoor scene parsing. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 4464â€“4474 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Loshchilov, I., Hutter, F.: Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101 (2017)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Misra, I., Girdhar, R., Joulin, A.: An end-to-end transformer model for 3d object detection. In: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). pp. 2906â€“2917 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Nakashima, K., Kataoka, H., Satoh, Y.: Does formula-driven supervised learning work on small datasets? IEEE Access (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Nilsback, M.E., Zisserman, A.: Automated flower classification over a large number of classes. In: Proceedings of the Indian Conference on Computer Vision, Graphics and Image Processing. pp. 722â€“729 (2008)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Pang, Y., Wang, W., Tay, F.E., Liu, W., Tian, Y., Yuan, L.: Masked autoencoders for point cloud self-supervised learning. In: Proceedings of the European Conference on Computer Vision (ECCV). pp. 604â€“621 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Qi, C.R., Litany, O., He, K., Guibas, L.J.: Deep hough voting for 3d object detection in point clouds. In: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). pp. 9277â€“9286 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Robert, D., Vallet, B., Landrieu, L.: Learning multi-view aggregation in the wild for large-scale 3d semantic segmentation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 5575â€“5584 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Shinoda, R., Hayamizu, R., Nakashima, K., Inoue, N., Yokota, R., Kataoka, H.: Segrcdb: Semantic segmentation via formula-driven supervised learning. In: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). pp. 20054â€“20063 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Sun, C., Shrivastava, A., Singh, S., Gupta, A.: Revisiting unreasonable effectiveness of data in deep learning era. In: Proceedings of the IEEE International Conference on Computer Vision (ICCV). pp. 843â€“852 (2017)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Tadokoro, R., Yamada, R., Nakashima, K., Nakamura, R., Kataoka, H.: Primitive geometry segment pre-training for 3d medical image segmentation. arXiv preprint arXiv:2401.03665 (2024)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Takashima, S., Hayamizu, R., Inoue, N., Kataoka, H., Yokota, R.: Visual atoms: Pre-training vision transformers with sinusoidal waves. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 18579â€“18588 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Tang, P., Xu, H.M., Ma, C.: Prototransfer: Cross-modal prototype transfer for point cloud segmentation. In: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). pp. 3337â€“3347 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Touvron, H., Cord, M., Douze, M., Massa, F., Sablayrolles, A., JÃ©gou, H.: Training data-efficient image transformers &amp; distillation through attention. In: Proceedings of the International Conference on Machine Learning (ICML). pp. 10347â€“10357 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Uy, M.A., Pham, Q.H., Hua, B.S., Nguyen, T., Yeung, S.K.: Revisiting point cloud classification: A new benchmark dataset and classification model on real-world data. In: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). pp. 1588â€“1597 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Wang, Z., Yu, X., Rao, Y., Zhou, J., Lu, J.: P2p: Tuning pre-trained image models for point cloud analysis with point-to-pixel prompting. Proceedings of the Advances in Neural Information Processing Systems (NeurIPS) pp. 14388â€“14402 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Wu, Z., Song, S., Khosla, A., Yu, F., Zhang, L., Tang, X., Xiao, J.: 3d shapenets: A deep representation for volumetric shapes. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 1912â€“1920 (2015)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Yamada, R., Kataoka, H., Chiba, N., Domae, Y., Ogata, T.: Point cloud pre-training with natural 3d structures. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 21283â€“21293 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Yamada, R., Takahashi, R., Suzuki, R., Nakamura, A., Yoshiyasu, Y., Sagawa, R., Kataoka, H.: Mv-fractaldb: formula-driven supervised learning for multi-view image recognition. In: Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). pp. 2076â€“2083 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Yi, X., Deng, J., Sun, Q., Hua, X.S., Lim, J.H., Zhang, H.: Invariant training 2d-3d joint hard samples for few-shot point cloud recognition. In: Proceedings of the IEEE/CVF International Conference on Computer Vision (CVPR). pp. 14463â€“14474 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Yu, X., Tang, L., Rao, Y., Huang, T., Zhou, J., Lu, J.: Point-bert: Pre-training 3d point cloud transformers with masked point modeling. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 19313â€“19322 (June 2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Zhao, H., Jiang, L., Jia, J., Torr, P.H., Koltun, V.: Point transformer. In: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). pp. 16259â€“16268 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Zhou, B., Lapedriza, A., Khosla, A., Oliva, A., Torralba, A.: Places: A 10 million image database for scene recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) <span class="ltx_text ltx_font_bold" id="bib.bib49.1.1">40</span>(6), 1452â€“1464 (2017)

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_para" id="p1">
<p class="ltx_p ltx_align_center" id="p1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1" style="font-size:144%;">Supplementary Material</span></p>
</div>
<section class="ltx_appendix" id="Pt0.A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>FSVGP details</h2>
<div class="ltx_para" id="Pt0.A1.p1">
<p class="ltx_p" id="Pt0.A1.p1.1">This section describes the details of our Formula-Supervised Visual-Geometric Pre-training (FSVGP). SectionÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#Pt0.A1.SS1" title="A.1 VG-FractalDB construction details â€£ Appendix A FSVGP details â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">A.1</span></a> details the Visual Geometric Fractal Database (VG-FractalDB). SectionÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#Pt0.A1.SS2" title="A.2 Pre-training transformer model details â€£ Appendix A FSVGP details â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">A.2</span></a> details a unified model for pre-training VG-FractalDB.</p>
</div>
<section class="ltx_subsection" id="Pt0.A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>VG-FractalDB construction details</h3>
<div class="ltx_para" id="Pt0.A1.SS1.p1">
<p class="ltx_p" id="Pt0.A1.SS1.p1.1">This section delineates the methodology employed in constructing the VG-FractalDB, focusing on using 3D Iterated Function Systems (3D-IFS)Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib2" title="">2</a>]</cite> and our dataset diversity and consistency between visual and geometric modalities.</p>
</div>
<div class="ltx_para" id="Pt0.A1.SS1.p2">
<p class="ltx_p" id="Pt0.A1.SS1.p2.1">3D-IFS is a mathematical framework for generating fractal geometry. It is central to defining the categories and variations in VG-FractalDB.
Formula-supervised consistency labels in VG-FractalDB are linked to the 3D-IFS parameters.
In certain 3D-IFS parameter cases, the 3D fractal point cloud is concentrated in a part of the 3D space.
Therefore, the quality of the 3D fractal point cloud is checked based on the variance threshold to exclude such 3D fractal point clouds.
Only the 3D fractal point clouds whose variance value exceeds the variance threshold value in all axes are defined as the categories of VG-FractalDB. The variance threshold ensures a wide variety of fractal shapes.
For augmenting within each category, we used FractalNoiseMix proposed by Yamada et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib44" title="">44</a>]</cite>. This augmentation technique enriches the dataset with a broader range of fractal geometries by augmenting 3D fractal models by mixing other 3D fractal models.</p>
</div>
<div class="ltx_para" id="Pt0.A1.SS1.p3">
<p class="ltx_p" id="Pt0.A1.SS1.p3.1">The 3D fractal models are then projected onto 2D planes to generate fractal images. This process randomly selects a camera viewpoint in 3D space. A perspective projection transformation maps point clouds onto a 2D plane. This particular transformation is chosen to accurately maintain the relative size and shape of 3D objects in the 2D rendering. Each parameter must be defined to achieve a realistic projection, such as the viewing angle (focal length), aspect ratio, and near and far planes. We set the focal length to 45 degrees, the aspect ratio to 1.0, and the near and far planes to 1.0 and 100, respectively.
The camera viewpoint setting is also an integral part of the projection process. This involves determining the cameraâ€™s position, the point it is looking at, and its upward direction. These elements are used to compute a view matrix, which transforms the 3D objects from the world coordinate system to the camera coordinate system.</p>
</div>
<div class="ltx_para" id="Pt0.A1.SS1.p4">
<p class="ltx_p" id="Pt0.A1.SS1.p4.1">For each 3D fractal model, a corresponding fractal image is generated from a randomly selected viewpoint. This approach ensures that each pair of 3D fractal point clouds and fractal images uniquely represents a particular viewpoint.
The resulting VG-FractalDB provides a rich 2D-3D fractal data representation for classification pre-training.</p>
</div>
</section>
<section class="ltx_subsection" id="Pt0.A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Pre-training transformer model details</h3>
<div class="ltx_para" id="Pt0.A1.SS2.p1">
<p class="ltx_p" id="Pt0.A1.SS2.p1.1">We designed a single transformer model for learning VG-FractalDB. Our transformer model is built upon the standard Vision Transformer (ViT)Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib10" title="">10</a>]</cite> and Point Transformer (PointT)Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib48" title="">48</a>]</cite> structure, comprising transformer blocks.
Each block includes a multi-head self-attention mechanism and a Multi-Layer Perceptron (MLP) block integrated with LayerNorm for normalization.</p>
</div>
<div class="ltx_para" id="Pt0.A1.SS2.p2">
<p class="ltx_p" id="Pt0.A1.SS2.p2.1">The property of our single transformer model is to process both fractal images and 3D fractal point clouds through different embedding procedures tailored to the nature of each data type.
For images, the image is then divided into patches of size <math alttext="16\times 16" class="ltx_Math" display="inline" id="Pt0.A1.SS2.p2.1.m1.1"><semantics id="Pt0.A1.SS2.p2.1.m1.1a"><mrow id="Pt0.A1.SS2.p2.1.m1.1.1" xref="Pt0.A1.SS2.p2.1.m1.1.1.cmml"><mn id="Pt0.A1.SS2.p2.1.m1.1.1.2" xref="Pt0.A1.SS2.p2.1.m1.1.1.2.cmml">16</mn><mo id="Pt0.A1.SS2.p2.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="Pt0.A1.SS2.p2.1.m1.1.1.1.cmml">Ã—</mo><mn id="Pt0.A1.SS2.p2.1.m1.1.1.3" xref="Pt0.A1.SS2.p2.1.m1.1.1.3.cmml">16</mn></mrow><annotation-xml encoding="MathML-Content" id="Pt0.A1.SS2.p2.1.m1.1b"><apply id="Pt0.A1.SS2.p2.1.m1.1.1.cmml" xref="Pt0.A1.SS2.p2.1.m1.1.1"><times id="Pt0.A1.SS2.p2.1.m1.1.1.1.cmml" xref="Pt0.A1.SS2.p2.1.m1.1.1.1"></times><cn id="Pt0.A1.SS2.p2.1.m1.1.1.2.cmml" type="integer" xref="Pt0.A1.SS2.p2.1.m1.1.1.2">16</cn><cn id="Pt0.A1.SS2.p2.1.m1.1.1.3.cmml" type="integer" xref="Pt0.A1.SS2.p2.1.m1.1.1.3">16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A1.SS2.p2.1.m1.1c">16\times 16</annotation><annotation encoding="application/x-llamapun" id="Pt0.A1.SS2.p2.1.m1.1d">16 Ã— 16</annotation></semantics></math>, with each patch undergoing a linear projection to transform it into an embedding.
For point cloud data, we start by downsampling a point cloud to a specific number of points. The downsampling point cloud is then clustered using a K-nearest neighbor, ensuring that local geometries within the cloud are preserved. These clustered points are passed through an MLP, generating embeddings.</p>
</div>
<div class="ltx_para" id="Pt0.A1.SS2.p3">
<p class="ltx_p" id="Pt0.A1.SS2.p3.1">Our transformer model is designed to be simple, learning visual-geometric representation from VG-FractalDB.
Using distinct embedding processes for different data types showcases our transformer modelâ€™s flexibility and potential to adapt diverse downstream tasks.</p>
</div>
</section>
</section>
<section class="ltx_appendix" id="Pt0.A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Experimental setting details</h2>
<div class="ltx_para" id="Pt0.A2.p1">
<p class="ltx_p" id="Pt0.A2.p1.1">This section describes the experimental setup in detail. First, SectionÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#Pt0.A2.SS1" title="B.1 Pre-training â€£ Appendix B Experimental setting details â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">B.1</span></a> describes the training setup in FSVGP. SectionsÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#Pt0.A2.SS2" title="B.2 Image recognition â€£ Appendix B Experimental setting details â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">B.2</span></a> and SectionÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#Pt0.A2.SS3" title="B.3 3D object recognition â€£ Appendix B Experimental setting details â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">B.3</span></a> describe the experimental setup for image recognition and 3D object recognition, respectively. Finally, SectionÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#Pt0.A2.SS4" title="B.4 Ablation study â€£ Appendix B Experimental setting details â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">B.4</span></a> explains in detail the setup of the ablation study.</p>
</div>
<section class="ltx_subsection" id="Pt0.A2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Pre-training</h3>
<div class="ltx_para" id="Pt0.A2.SS1.p1">
<p class="ltx_p" id="Pt0.A2.SS1.p1.1">Our experiments set the hyperparameters based on the Data-efficient image Transformers (DeiT) modelÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib40" title="">40</a>]</cite>, as detailed in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#Pt0.A2.T1" title="Table A â€£ B.1 Pre-training â€£ Appendix B Experimental setting details â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">A</span></a>.
The training scripts were adapted from previous studiesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib38" title="">38</a>]</cite>, providing a foundational framework for our approach.</p>
</div>
<figure class="ltx_table" id="Pt0.A2.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="Pt0.A2.T1.4.1.1" style="font-size:90%;">Table A</span>: </span><span class="ltx_text" id="Pt0.A2.T1.5.2" style="font-size:90%;">Pre-training setting.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="Pt0.A2.T1.2.2" style="width:274.4pt;height:285.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-1.4pt,1.4pt) scale(0.99,0.99) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="Pt0.A2.T1.2.2.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="Pt0.A2.T1.2.2.2.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="Pt0.A2.T1.2.2.2.3.1.1">Config</th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="Pt0.A2.T1.2.2.2.3.1.2">Value</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T1.2.2.2.4.2">
<th class="ltx_td ltx_th ltx_th_row" id="Pt0.A2.T1.2.2.2.4.2.1"></th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T1.2.2.2.4.2.2">VG-FractalDB-1k</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T1.2.2.2.4.2.3">VG-FractalDB-21k</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T1.2.2.2.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="Pt0.A2.T1.2.2.2.5.3.1">Epochs</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="Pt0.A2.T1.2.2.2.5.3.2">200</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Pt0.A2.T1.2.2.2.5.3.3">100</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T1.2.2.2.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T1.2.2.2.6.4.1">Batch Size</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T1.2.2.2.6.4.2">1024</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T1.2.2.2.6.4.3">8192</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T1.2.2.2.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T1.2.2.2.7.5.1">Optimizer</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T1.2.2.2.7.5.2">AdamW</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T1.2.2.2.7.5.3">AdamW</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T1.2.2.2.8.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T1.2.2.2.8.6.1">LR</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T1.2.2.2.8.6.2">5e-4</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T1.2.2.2.8.6.3">5e-4</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T1.2.2.2.9.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T1.2.2.2.9.7.1">Weight Decay</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T1.2.2.2.9.7.2">0.05</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T1.2.2.2.9.7.3">0.05</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T1.2.2.2.10.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T1.2.2.2.10.8.1">LR Scheduler</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T1.2.2.2.10.8.2">Cosine decay</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T1.2.2.2.10.8.3">Cosine decay</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T1.2.2.2.11.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T1.2.2.2.11.9.1">Warmup Steps</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T1.2.2.2.11.9.2">5k</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T1.2.2.2.11.9.3">5k</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T1.2.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T1.2.2.2.2.3">Resolution</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T1.1.1.1.1.1">224<math alttext="\times" class="ltx_Math" display="inline" id="Pt0.A2.T1.1.1.1.1.1.m1.1"><semantics id="Pt0.A2.T1.1.1.1.1.1.m1.1a"><mo id="Pt0.A2.T1.1.1.1.1.1.m1.1.1" xref="Pt0.A2.T1.1.1.1.1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="Pt0.A2.T1.1.1.1.1.1.m1.1b"><times id="Pt0.A2.T1.1.1.1.1.1.m1.1.1.cmml" xref="Pt0.A2.T1.1.1.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A2.T1.1.1.1.1.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="Pt0.A2.T1.1.1.1.1.1.m1.1d">Ã—</annotation></semantics></math>224</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T1.2.2.2.2.2">224<math alttext="\times" class="ltx_Math" display="inline" id="Pt0.A2.T1.2.2.2.2.2.m1.1"><semantics id="Pt0.A2.T1.2.2.2.2.2.m1.1a"><mo id="Pt0.A2.T1.2.2.2.2.2.m1.1.1" xref="Pt0.A2.T1.2.2.2.2.2.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="Pt0.A2.T1.2.2.2.2.2.m1.1b"><times id="Pt0.A2.T1.2.2.2.2.2.m1.1.1.cmml" xref="Pt0.A2.T1.2.2.2.2.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A2.T1.2.2.2.2.2.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="Pt0.A2.T1.2.2.2.2.2.m1.1d">Ã—</annotation></semantics></math>224</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T1.2.2.2.12.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T1.2.2.2.12.10.1">Label Smoothing</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T1.2.2.2.12.10.2">0.1</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T1.2.2.2.12.10.3">0.1</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T1.2.2.2.13.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T1.2.2.2.13.11.1">Drop Path</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T1.2.2.2.13.11.2">0.1</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T1.2.2.2.13.11.3">0.1</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T1.2.2.2.14.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T1.2.2.2.14.12.1">Rand Augment</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T1.2.2.2.14.12.2">9 / 0.5</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T1.2.2.2.14.12.3">9 / 0.5</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T1.2.2.2.15.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T1.2.2.2.15.13.1">Mixup</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T1.2.2.2.15.13.2">0.8</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T1.2.2.2.15.13.3">0.8</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T1.2.2.2.16.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T1.2.2.2.16.14.1">Cutmix</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T1.2.2.2.16.14.2">1.0</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T1.2.2.2.16.14.3">1.0</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T1.2.2.2.17.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="Pt0.A2.T1.2.2.2.17.15.1">Erasing</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Pt0.A2.T1.2.2.2.17.15.2">0.25</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Pt0.A2.T1.2.2.2.17.15.3">0.25</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="Pt0.A2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>Image recognition</h3>
<div class="ltx_para ltx_noindent" id="Pt0.A2.SS2.p1">
<p class="ltx_p" id="Pt0.A2.SS2.p1.1"><span class="ltx_text ltx_font_bold" id="Pt0.A2.SS2.p1.1.1">Image classification.</span>
Our experiments validated our results using the image classification dataset that previous studies evaluated.
We compare the top-1 accuracy during fine-tuning in 300 epochs as an evaluation metric.
Hyper-parameters at additional learning are shown in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#Pt0.A2.T3" title="Table C â€£ B.2 Image recognition â€£ Appendix B Experimental setting details â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">C</span></a>. These are the same conditions as in the previous experimental setup in FDSLÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib38" title="">38</a>]</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="Pt0.A2.SS2.p2">
<p class="ltx_p" id="Pt0.A2.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="Pt0.A2.SS2.p2.1.1">Image object detection and instance segmentation.</span>
This experiment was validated at MS COCO2017 using the official ViTDetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib23" title="">23</a>]</cite> GitHub. We used the hyperparameters of ViTDet as they are. The specific hyperparameters for the fine-tuning are shown in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#Pt0.A2.T3" title="Table C â€£ B.2 Image recognition â€£ Appendix B Experimental setting details â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">C</span></a>.</p>
</div>
<figure class="ltx_table" id="Pt0.A2.T3">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" id="Pt0.A2.T3.3" style="width:208.1pt;">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="Pt0.A2.T3.3.4.1.1" style="font-size:90%;">Table B</span>: </span><span class="ltx_text" id="Pt0.A2.T3.3.5.2" style="font-size:90%;">Image classification setting.</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="Pt0.A2.T3.3.3" style="width:195.9pt;height:216pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-32.6pt,36.0pt) scale(0.75,0.75) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="Pt0.A2.T3.3.3.3">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="Pt0.A2.T3.3.3.3.4.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="Pt0.A2.T3.3.3.3.4.1.1">Config</th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="Pt0.A2.T3.3.3.3.4.1.2">Value</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T3.3.3.3.5.2">
<th class="ltx_td ltx_th ltx_th_row" id="Pt0.A2.T3.3.3.3.5.2.1"></th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.3.3.3.5.2.2">ImageNet-1k</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.3.3.3.5.2.3">Others</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T3.3.3.3.6.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="Pt0.A2.T3.3.3.3.6.3.1">Epochs</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="Pt0.A2.T3.3.3.3.6.3.2">300</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Pt0.A2.T3.3.3.3.6.3.3">300</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T3.3.3.3.7.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T3.3.3.3.7.4.1">Batch Size</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.3.3.3.7.4.2">1024</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.3.3.3.7.4.3">1024</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T3.3.3.3.8.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T3.3.3.3.8.5.1">Optimizer</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.3.3.3.8.5.2">AdamW</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.3.3.3.8.5.3">AdamW</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T3.3.3.3.9.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T3.3.3.3.9.6.1">LR</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.3.3.3.9.6.2">5e-4</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.3.3.3.9.6.3">5e-4</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T3.3.3.3.10.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T3.3.3.3.10.7.1">Weight Decay</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.3.3.3.10.7.2">0.05</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.3.3.3.10.7.3">0.05</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T3.3.3.3.11.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T3.3.3.3.11.8.1">LR Scheduler</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.3.3.3.11.8.2">Cosine decay</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.3.3.3.11.8.3">Cosine decay</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T3.3.3.3.12.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T3.3.3.3.12.9.1">Warmup Steps</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.3.3.3.12.9.2">5 (epoch)</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.3.3.3.12.9.3">5 (epoch)</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T3.3.3.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T3.3.3.3.3.4">Resolution</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.2.2.2.2.2">224<math alttext="\times" class="ltx_Math" display="inline" id="Pt0.A2.T3.1.1.1.1.1.m1.1"><semantics id="Pt0.A2.T3.1.1.1.1.1.m1.1a"><mo id="Pt0.A2.T3.1.1.1.1.1.m1.1.1" xref="Pt0.A2.T3.1.1.1.1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="Pt0.A2.T3.1.1.1.1.1.m1.1b"><times id="Pt0.A2.T3.1.1.1.1.1.m1.1.1.cmml" xref="Pt0.A2.T3.1.1.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A2.T3.1.1.1.1.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="Pt0.A2.T3.1.1.1.1.1.m1.1d">Ã—</annotation></semantics></math>224 / 384<math alttext="\times" class="ltx_Math" display="inline" id="Pt0.A2.T3.2.2.2.2.2.m2.1"><semantics id="Pt0.A2.T3.2.2.2.2.2.m2.1a"><mo id="Pt0.A2.T3.2.2.2.2.2.m2.1.1" xref="Pt0.A2.T3.2.2.2.2.2.m2.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="Pt0.A2.T3.2.2.2.2.2.m2.1b"><times id="Pt0.A2.T3.2.2.2.2.2.m2.1.1.cmml" xref="Pt0.A2.T3.2.2.2.2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A2.T3.2.2.2.2.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="Pt0.A2.T3.2.2.2.2.2.m2.1d">Ã—</annotation></semantics></math>384</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.3.3.3.3.3">224<math alttext="\times" class="ltx_Math" display="inline" id="Pt0.A2.T3.3.3.3.3.3.m1.1"><semantics id="Pt0.A2.T3.3.3.3.3.3.m1.1a"><mo id="Pt0.A2.T3.3.3.3.3.3.m1.1.1" xref="Pt0.A2.T3.3.3.3.3.3.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="Pt0.A2.T3.3.3.3.3.3.m1.1b"><times id="Pt0.A2.T3.3.3.3.3.3.m1.1.1.cmml" xref="Pt0.A2.T3.3.3.3.3.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A2.T3.3.3.3.3.3.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="Pt0.A2.T3.3.3.3.3.3.m1.1d">Ã—</annotation></semantics></math>224</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T3.3.3.3.13.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T3.3.3.3.13.10.1">Label Smoothing</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.3.3.3.13.10.2">0.1</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.3.3.3.13.10.3">0.1</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T3.3.3.3.14.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T3.3.3.3.14.11.1">Drop Path</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.3.3.3.14.11.2">0.1</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.3.3.3.14.11.3">0.1</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T3.3.3.3.15.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T3.3.3.3.15.12.1">Rand Augment</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.3.3.3.15.12.2">9 / 0.5</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.3.3.3.15.12.3">9 / 0.5</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T3.3.3.3.16.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T3.3.3.3.16.13.1">Mixup</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.3.3.3.16.13.2">0.8</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.3.3.3.16.13.3">0.8</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T3.3.3.3.17.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T3.3.3.3.17.14.1">Cutmix</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.3.3.3.17.14.2">1.0</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.3.3.3.17.14.3">1.0</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T3.3.3.3.18.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="Pt0.A2.T3.3.3.3.18.15.1">Erasing</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Pt0.A2.T3.3.3.3.18.15.2">0.25</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Pt0.A2.T3.3.3.3.18.15.3">0.25</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" id="Pt0.A2.T3.5" style="width:208.1pt;">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="Pt0.A2.T3.5.3.1.1" style="font-size:90%;">Table C</span>: </span><span class="ltx_text" id="Pt0.A2.T3.5.4.2" style="font-size:90%;">Image object detection and instance segmentation setting.</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="Pt0.A2.T3.5.2" style="width:210.9pt;height:200.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-7.9pt,7.6pt) scale(0.93,0.93) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="Pt0.A2.T3.5.2.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="Pt0.A2.T3.5.2.2.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="Pt0.A2.T3.5.2.2.3.1.1">Config</th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="Pt0.A2.T3.5.2.2.3.1.2">Value</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T3.5.2.2.4.2">
<th class="ltx_td ltx_th ltx_th_row" id="Pt0.A2.T3.5.2.2.4.2.1"></th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.5.2.2.4.2.2">From Scratch</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.5.2.2.4.2.3">Pre-train</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T3.5.2.2.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="Pt0.A2.T3.5.2.2.5.3.1">Epochs</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="Pt0.A2.T3.5.2.2.5.3.2">30</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Pt0.A2.T3.5.2.2.5.3.3">30</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T3.5.2.2.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T3.5.2.2.6.4.1">Batch Size</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.5.2.2.6.4.2">16</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.5.2.2.6.4.3">16</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T3.5.2.2.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T3.5.2.2.7.5.1">Optimizer</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.5.2.2.7.5.2">AdamW</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.5.2.2.7.5.3">AdamW</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T3.5.2.2.8.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T3.5.2.2.8.6.1">LR</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.5.2.2.8.6.2">1.6e-4</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.5.2.2.8.6.3">4e-1</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T3.5.2.2.9.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T3.5.2.2.9.7.1">Weight Decay</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.5.2.2.9.7.2">0.2</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.5.2.2.9.7.3">0.1</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T3.5.2.2.10.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T3.5.2.2.10.8.1">Warmup Steps</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.5.2.2.10.8.2">1k</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.5.2.2.10.8.3">1k</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T3.5.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T3.5.2.2.2.3">Resolution</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.4.1.1.1.1">1024<math alttext="\times" class="ltx_Math" display="inline" id="Pt0.A2.T3.4.1.1.1.1.m1.1"><semantics id="Pt0.A2.T3.4.1.1.1.1.m1.1a"><mo id="Pt0.A2.T3.4.1.1.1.1.m1.1.1" xref="Pt0.A2.T3.4.1.1.1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="Pt0.A2.T3.4.1.1.1.1.m1.1b"><times id="Pt0.A2.T3.4.1.1.1.1.m1.1.1.cmml" xref="Pt0.A2.T3.4.1.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A2.T3.4.1.1.1.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="Pt0.A2.T3.4.1.1.1.1.m1.1d">Ã—</annotation></semantics></math>1024</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.5.2.2.2.2">1024<math alttext="\times" class="ltx_Math" display="inline" id="Pt0.A2.T3.5.2.2.2.2.m1.1"><semantics id="Pt0.A2.T3.5.2.2.2.2.m1.1a"><mo id="Pt0.A2.T3.5.2.2.2.2.m1.1.1" xref="Pt0.A2.T3.5.2.2.2.2.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="Pt0.A2.T3.5.2.2.2.2.m1.1b"><times id="Pt0.A2.T3.5.2.2.2.2.m1.1.1.cmml" xref="Pt0.A2.T3.5.2.2.2.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A2.T3.5.2.2.2.2.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="Pt0.A2.T3.5.2.2.2.2.m1.1d">Ã—</annotation></semantics></math>1024</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T3.5.2.2.11.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T3.5.2.2.11.9.1">Drop Path</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.5.2.2.11.9.2">0.1/0.4</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.5.2.2.11.9.3">0.1/0.4</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T3.5.2.2.12.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T3.5.2.2.12.10.1">Large Scale Jitter</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.5.2.2.12.10.2">[0.1, 2.0]</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T3.5.2.2.12.10.3">[0.1, 2.0]</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T3.5.2.2.13.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="Pt0.A2.T3.5.2.2.13.11.1">Rand Flip</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Pt0.A2.T3.5.2.2.13.11.2">0.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Pt0.A2.T3.5.2.2.13.11.3">0.5</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</div>
</div>
</figure>
</section>
<section class="ltx_subsection" id="Pt0.A2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.3 </span>3D object recognition</h3>
<div class="ltx_para ltx_noindent" id="Pt0.A2.SS3.p1">
<p class="ltx_p" id="Pt0.A2.SS3.p1.1"><span class="ltx_text ltx_font_bold" id="Pt0.A2.SS3.p1.1.1">3D object classification.</span>
We used ModelNet40 and ScanObjectNN.
The evaluation was conducted on ModelNet40 and three ScanObjectNN subsets: OBJ-BG (including object surroundings), OBJ-ONLY (objects without background), and PB-T50-RS (a challenging subset with translated, rotated, and scaled objects).
We employed the AdamW optimizer for fine-tuning and adjusted over 300 epochs using a cosine decay schedule.
Models were fine-tuned on point clouds with 1024 points for ModelNet40 and 2048 points for ScanObjectNN, and performance was measured using overall accuracy, focusing on the highest accuracy achieved within 300 epochs. The specific hyperparameters for the fine-tuning are shown in TableÂ <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:3D_cls_params</span>.</p>
</div>
<div class="ltx_para ltx_noindent" id="Pt0.A2.SS3.p2">
<p class="ltx_p" id="Pt0.A2.SS3.p2.6"><span class="ltx_text ltx_font_bold" id="Pt0.A2.SS3.p2.6.1">Few-shot learning.</span>
We conducted experiments by selecting <math alttext="K" class="ltx_Math" display="inline" id="Pt0.A2.SS3.p2.1.m1.1"><semantics id="Pt0.A2.SS3.p2.1.m1.1a"><mi id="Pt0.A2.SS3.p2.1.m1.1.1" xref="Pt0.A2.SS3.p2.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="Pt0.A2.SS3.p2.1.m1.1b"><ci id="Pt0.A2.SS3.p2.1.m1.1.1.cmml" xref="Pt0.A2.SS3.p2.1.m1.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A2.SS3.p2.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="Pt0.A2.SS3.p2.1.m1.1d">italic_K</annotation></semantics></math> classes from the ModelNet40 dataset and sampling <math alttext="N+20" class="ltx_Math" display="inline" id="Pt0.A2.SS3.p2.2.m2.1"><semantics id="Pt0.A2.SS3.p2.2.m2.1a"><mrow id="Pt0.A2.SS3.p2.2.m2.1.1" xref="Pt0.A2.SS3.p2.2.m2.1.1.cmml"><mi id="Pt0.A2.SS3.p2.2.m2.1.1.2" xref="Pt0.A2.SS3.p2.2.m2.1.1.2.cmml">N</mi><mo id="Pt0.A2.SS3.p2.2.m2.1.1.1" xref="Pt0.A2.SS3.p2.2.m2.1.1.1.cmml">+</mo><mn id="Pt0.A2.SS3.p2.2.m2.1.1.3" xref="Pt0.A2.SS3.p2.2.m2.1.1.3.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="Pt0.A2.SS3.p2.2.m2.1b"><apply id="Pt0.A2.SS3.p2.2.m2.1.1.cmml" xref="Pt0.A2.SS3.p2.2.m2.1.1"><plus id="Pt0.A2.SS3.p2.2.m2.1.1.1.cmml" xref="Pt0.A2.SS3.p2.2.m2.1.1.1"></plus><ci id="Pt0.A2.SS3.p2.2.m2.1.1.2.cmml" xref="Pt0.A2.SS3.p2.2.m2.1.1.2">ğ‘</ci><cn id="Pt0.A2.SS3.p2.2.m2.1.1.3.cmml" type="integer" xref="Pt0.A2.SS3.p2.2.m2.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A2.SS3.p2.2.m2.1c">N+20</annotation><annotation encoding="application/x-llamapun" id="Pt0.A2.SS3.p2.2.m2.1d">italic_N + 20</annotation></semantics></math> objects from each class. These classes formed the basis for <math alttext="K" class="ltx_Math" display="inline" id="Pt0.A2.SS3.p2.3.m3.1"><semantics id="Pt0.A2.SS3.p2.3.m3.1a"><mi id="Pt0.A2.SS3.p2.3.m3.1.1" xref="Pt0.A2.SS3.p2.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="Pt0.A2.SS3.p2.3.m3.1b"><ci id="Pt0.A2.SS3.p2.3.m3.1.1.cmml" xref="Pt0.A2.SS3.p2.3.m3.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A2.SS3.p2.3.m3.1c">K</annotation><annotation encoding="application/x-llamapun" id="Pt0.A2.SS3.p2.3.m3.1d">italic_K</annotation></semantics></math>-way, <math alttext="N" class="ltx_Math" display="inline" id="Pt0.A2.SS3.p2.4.m4.1"><semantics id="Pt0.A2.SS3.p2.4.m4.1a"><mi id="Pt0.A2.SS3.p2.4.m4.1.1" xref="Pt0.A2.SS3.p2.4.m4.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="Pt0.A2.SS3.p2.4.m4.1b"><ci id="Pt0.A2.SS3.p2.4.m4.1.1.cmml" xref="Pt0.A2.SS3.p2.4.m4.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A2.SS3.p2.4.m4.1c">N</annotation><annotation encoding="application/x-llamapun" id="Pt0.A2.SS3.p2.4.m4.1d">italic_N</annotation></semantics></math>-shot training subsets, with <math alttext="K" class="ltx_Math" display="inline" id="Pt0.A2.SS3.p2.5.m5.1"><semantics id="Pt0.A2.SS3.p2.5.m5.1a"><mi id="Pt0.A2.SS3.p2.5.m5.1.1" xref="Pt0.A2.SS3.p2.5.m5.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="Pt0.A2.SS3.p2.5.m5.1b"><ci id="Pt0.A2.SS3.p2.5.m5.1.1.cmml" xref="Pt0.A2.SS3.p2.5.m5.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A2.SS3.p2.5.m5.1c">K</annotation><annotation encoding="application/x-llamapun" id="Pt0.A2.SS3.p2.5.m5.1d">italic_K</annotation></semantics></math> and <math alttext="N" class="ltx_Math" display="inline" id="Pt0.A2.SS3.p2.6.m6.1"><semantics id="Pt0.A2.SS3.p2.6.m6.1a"><mi id="Pt0.A2.SS3.p2.6.m6.1.1" xref="Pt0.A2.SS3.p2.6.m6.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="Pt0.A2.SS3.p2.6.m6.1b"><ci id="Pt0.A2.SS3.p2.6.m6.1.1.cmml" xref="Pt0.A2.SS3.p2.6.m6.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A2.SS3.p2.6.m6.1c">N</annotation><annotation encoding="application/x-llamapun" id="Pt0.A2.SS3.p2.6.m6.1d">italic_N</annotation></semantics></math> varying between {5, 10} and {10, 20}, respectively.
We created ten different subsets for these experiments and evaluated the modelâ€™s performance by computing the mean and standard deviation of the highest accuracy obtained across these subsets. The AdamW optimizer was used during fine-tuning, adjusting it according to a cosine decay schedule over 150 epochs. We fine-tuned the model on ModelNet40 using point clouds of 1024 points each.</p>
</div>
<figure class="ltx_table" id="Pt0.A2.T5">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" id="Pt0.A2.T5.fig1" style="width:208.1pt;">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="Pt0.A2.T5.fig1.1.1.1" style="font-size:90%;">Table D</span>: </span><span class="ltx_text" id="Pt0.A2.T5.fig1.2.2" style="font-size:90%;">3D object classification setting.</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="Pt0.A2.T5.fig1.3" style="width:206.9pt;height:182.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-34.5pt,30.4pt) scale(0.75,0.75) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="Pt0.A2.T5.fig1.3.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="Pt0.A2.T5.fig1.3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="Pt0.A2.T5.fig1.3.1.1.1.1">Config</th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="Pt0.A2.T5.fig1.3.1.1.1.2">Value</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T5.fig1.3.1.2.2">
<th class="ltx_td ltx_th ltx_th_row" id="Pt0.A2.T5.fig1.3.1.2.2.1"></th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig1.3.1.2.2.2">VG-FractalDB</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig1.3.1.2.2.3">Others</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T5.fig1.3.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="Pt0.A2.T5.fig1.3.1.3.3.1">Epochs</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="Pt0.A2.T5.fig1.3.1.3.3.2">300</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Pt0.A2.T5.fig1.3.1.3.3.3">300</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T5.fig1.3.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T5.fig1.3.1.4.4.1">Batch Size</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig1.3.1.4.4.2">32</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig1.3.1.4.4.3">32</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T5.fig1.3.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T5.fig1.3.1.5.5.1">Optimizer</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig1.3.1.5.5.2">AdamW</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig1.3.1.5.5.3">AdamW</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T5.fig1.3.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T5.fig1.3.1.6.6.1">LR</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig1.3.1.6.6.2">5e-4</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig1.3.1.6.6.3">5e-4</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T5.fig1.3.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T5.fig1.3.1.7.7.1">Weight Decay</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig1.3.1.7.7.2">0.05</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig1.3.1.7.7.3">0.05</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T5.fig1.3.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T5.fig1.3.1.8.8.1">LR Scheduler</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig1.3.1.8.8.2">Cosine decay</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig1.3.1.8.8.3">Cosine decay</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T5.fig1.3.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T5.fig1.3.1.9.9.1">Warmup Steps</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig1.3.1.9.9.2">10 (epoch)</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig1.3.1.9.9.3">10 (epoch)</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T5.fig1.3.1.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T5.fig1.3.1.10.10.1">Num. of Points</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig1.3.1.10.10.2">1024(M)/2048(S)</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig1.3.1.10.10.3">1024(M)/2048(S)</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T5.fig1.3.1.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T5.fig1.3.1.11.11.1">Num of Patches</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig1.3.1.11.11.2">64</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig1.3.1.11.11.3">64</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T5.fig1.3.1.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T5.fig1.3.1.12.12.1">Patch Size</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig1.3.1.12.12.2">32</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig1.3.1.12.12.3">32</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T5.fig1.3.1.13.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="Pt0.A2.T5.fig1.3.1.13.13.1">Augmentation</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Pt0.A2.T5.fig1.3.1.13.13.2">ScaleAndTranslate</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Pt0.A2.T5.fig1.3.1.13.13.3">ScaleAndTranslate</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" id="Pt0.A2.T5.fig2" style="width:208.1pt;">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="Pt0.A2.T5.fig2.1.1.1" style="font-size:90%;">Table E</span>: </span><span class="ltx_text" id="Pt0.A2.T5.fig2.2.2" style="font-size:90%;">3D object detection and parts segmentation setting.</span></figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="Pt0.A2.T5.fig2.3" style="width:200.4pt;height:165.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-47.2pt,38.9pt) scale(0.68,0.68) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="Pt0.A2.T5.fig2.3.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="Pt0.A2.T5.fig2.3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="Pt0.A2.T5.fig2.3.1.1.1.1">Config</th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="Pt0.A2.T5.fig2.3.1.1.1.2">Value</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T5.fig2.3.1.2.2">
<th class="ltx_td ltx_th ltx_th_row" id="Pt0.A2.T5.fig2.3.1.2.2.1"></th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig2.3.1.2.2.2">ScanNet</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig2.3.1.2.2.3">ShapeNet-parts</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T5.fig2.3.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="Pt0.A2.T5.fig2.3.1.3.3.1">Epochs</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="Pt0.A2.T5.fig2.3.1.3.3.2">1080</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Pt0.A2.T5.fig2.3.1.3.3.3">300</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T5.fig2.3.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T5.fig2.3.1.4.4.1">Batch Size</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig2.3.1.4.4.2">32</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig2.3.1.4.4.3">32</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T5.fig2.3.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T5.fig2.3.1.5.5.1">Optimizer</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig2.3.1.5.5.2">AdamW</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig2.3.1.5.5.3">AdamW</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T5.fig2.3.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T5.fig2.3.1.6.6.1">LR</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig2.3.1.6.6.2">4e-4</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig2.3.1.6.6.3">5e-4</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T5.fig2.3.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T5.fig2.3.1.7.7.1">Weight Decay</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig2.3.1.7.7.2">0.1</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig2.3.1.7.7.3">0.05</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T5.fig2.3.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T5.fig2.3.1.8.8.1">LR Scheduler</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig2.3.1.8.8.2">Linear warmup</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig2.3.1.8.8.3">Cosine decay</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T5.fig2.3.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T5.fig2.3.1.9.9.1">Warmup Steps</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig2.3.1.9.9.2">20 (epoch)</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig2.3.1.9.9.3">10 (epoch)</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T5.fig2.3.1.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T5.fig2.3.1.10.10.1">Num. of Points</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig2.3.1.10.10.2">40000</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig2.3.1.10.10.3">2048</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T5.fig2.3.1.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T5.fig2.3.1.11.11.1">Num of Query/Patches</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig2.3.1.11.11.2">256</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig2.3.1.11.11.3">64</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T5.fig2.3.1.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T5.fig2.3.1.12.12.1">Patch Size</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig2.3.1.12.12.2">â€“</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T5.fig2.3.1.12.12.3">32</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T5.fig2.3.1.13.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="Pt0.A2.T5.fig2.3.1.13.13.1">Augmentation</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Pt0.A2.T5.fig2.3.1.13.13.2">RandomCuboid</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Pt0.A2.T5.fig2.3.1.13.13.3">ScaleAndTranslate</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</div>
</div>
</figure>
<div class="ltx_para ltx_noindent" id="Pt0.A2.SS3.p3">
<p class="ltx_p" id="Pt0.A2.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="Pt0.A2.SS3.p3.1.1">3D object detection.</span>
In our 3D object detection experiment, the ScanNet was used as a benchmark. We adopted the 3DETR model to fine-tune our 3D object detection approach, using its PointT-Small backbone network. The hyperparameters were tuned to those used in the original 3DETR. Our evaluation metrics were based on mean average precision (mAP) at 25% and 50% intersection over union (IoU). The specific fine-tuning hyperparameters are shown in TableÂ <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:3D_det_params</span>.</p>
</div>
<div class="ltx_para ltx_noindent" id="Pt0.A2.SS3.p4">
<p class="ltx_p" id="Pt0.A2.SS3.p4.2"><span class="ltx_text ltx_font_bold" id="Pt0.A2.SS3.p4.2.1">Parts segmentatoin.</span>
We employed the ShapeNetPart dataset to evaluate part segmentation, which involves identifying detailed class labels for each point of a 3D model. We assessed performance using the mean IoU (mIoU<sub class="ltx_sub" id="Pt0.A2.SS3.p4.2.2"><span class="ltx_text ltx_font_italic" id="Pt0.A2.SS3.p4.2.2.1">ins</span></sub>) across all instances and IoU for each category. Furthermore, we reported the Mean IoU across all categories (mIoU<sub class="ltx_sub" id="Pt0.A2.SS3.p4.2.3"><span class="ltx_text ltx_font_italic" id="Pt0.A2.SS3.p4.2.3.1">cat</span></sub>), ensuring equal treatment of each category in the dataset, irrespective of its frequency. This approach provides a comprehensive overview of the modelâ€™s segmentation performance.
The specific hyperparameters for the fine-tuning are shown in TableÂ <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:3D_det_params</span>.</p>
</div>
<figure class="ltx_figure" id="Pt0.A2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="224" id="Pt0.A2.F1.g1" src="x4.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="Pt0.A2.F1.2.1.1" style="font-size:90%;">Figure A</span>: </span><span class="ltx_text" id="Pt0.A2.F1.3.2" style="font-size:90%;">The examples of image and point cloud pair data in ShapeNet. </span></figcaption>
</figure>
<figure class="ltx_figure" id="Pt0.A2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="190" id="Pt0.A2.F2.g1" src="x5.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="Pt0.A2.F2.2.1.1" style="font-size:90%;">Figure B</span>: </span><span class="ltx_text" id="Pt0.A2.F2.3.2" style="font-size:90%;">The examples of image and point cloud pair data in the Visual-Geometric Perlin Noise dataset. </span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="Pt0.A2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.4 </span>Ablation study</h3>
<div class="ltx_para ltx_noindent" id="Pt0.A2.SS4.p1">
<p class="ltx_p" id="Pt0.A2.SS4.p1.1"><span class="ltx_text ltx_font_bold" id="Pt0.A2.SS4.p1.1.1">(i) Which is more effective, fractal point clouds or CAD models in FSVGP?</span>
In this experiment, we tested the pre-training effect of FSVGP by applying it to an existing 3D dataset, ShapeNet.
We generated images and point clouds for ShapeNet based on the VG-FractalDB construction procedure. Specifically, we project each 3D model of a ShapeNet onto an image from a random viewpoint position. An example of a generated image and point cloud is shown in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#Pt0.A2.F1" title="Figure A â€£ B.3 3D object recognition â€£ Appendix B Experimental setting details â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">A</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="Pt0.A2.SS4.p2">
<p class="ltx_p" id="Pt0.A2.SS4.p2.1"><span class="ltx_text ltx_font_bold" id="Pt0.A2.SS4.p2.1.1">(ii) Can other generation rules be effective in FSVGP?</span>
In this experiment, we verified the pre-training effect of the generation rules by comparing fractal and Perlin noise in terms of the mathematical formula regularity that generates the data. Perlin noise is a gradient noise function for generating natural-looking textures and shapes, and previous studiesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#bib.bib16" title="">16</a>]</cite> have reported its effectiveness in generating pre-trained datasets for image and video recognition. Therefore, we employed Perlin noise as the generating function to be compared in this experiment, considering its extensibility to 3D models.</p>
</div>
<div class="ltx_para" id="Pt0.A2.SS4.p3">
<p class="ltx_p" id="Pt0.A2.SS4.p3.1">We first generate 2D Perlin noise. Next, we lift the 2D Perlin noise to a point cloud. We then construct the Visual-Geometric Perlin Noise (VG-PN) dataset by projecting the point cloud onto an image. The 2D Perlin noise is pre-defined as a <math alttext="100\times 100" class="ltx_Math" display="inline" id="Pt0.A2.SS4.p3.1.m1.1"><semantics id="Pt0.A2.SS4.p3.1.m1.1a"><mrow id="Pt0.A2.SS4.p3.1.m1.1.1" xref="Pt0.A2.SS4.p3.1.m1.1.1.cmml"><mn id="Pt0.A2.SS4.p3.1.m1.1.1.2" xref="Pt0.A2.SS4.p3.1.m1.1.1.2.cmml">100</mn><mo id="Pt0.A2.SS4.p3.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="Pt0.A2.SS4.p3.1.m1.1.1.1.cmml">Ã—</mo><mn id="Pt0.A2.SS4.p3.1.m1.1.1.3" xref="Pt0.A2.SS4.p3.1.m1.1.1.3.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="Pt0.A2.SS4.p3.1.m1.1b"><apply id="Pt0.A2.SS4.p3.1.m1.1.1.cmml" xref="Pt0.A2.SS4.p3.1.m1.1.1"><times id="Pt0.A2.SS4.p3.1.m1.1.1.1.cmml" xref="Pt0.A2.SS4.p3.1.m1.1.1.1"></times><cn id="Pt0.A2.SS4.p3.1.m1.1.1.2.cmml" type="integer" xref="Pt0.A2.SS4.p3.1.m1.1.1.2">100</cn><cn id="Pt0.A2.SS4.p3.1.m1.1.1.3.cmml" type="integer" xref="Pt0.A2.SS4.p3.1.m1.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A2.SS4.p3.1.m1.1c">100\times 100</annotation><annotation encoding="application/x-llamapun" id="Pt0.A2.SS4.p3.1.m1.1d">100 Ã— 100</annotation></semantics></math> grid. Random coordinates are determined within each grid, and a gradient vector is generated from the vertices of each grid based on these coordinates. The values in the grid are determined by linearly complementing the gradient vectors. The key parameters for generating the Perlin noise, the frequency, and scale, are varied within a specific range to ensure the diversity of the shape of the 3D Perlin noise. The VG-PN dataset defines these parameters as categories. The 2D Perlin noise is converted to a 3D Perlin noise as a point cloud by taking the values of each grid of the 2D Perlin noise as the Z-coordinate, finally, by projecting the 3D Perlin noise onto a image under the same conditions as VG-FractalDB. Finally, the 3D Perlin noise is projected onto the image under the same conditions as VG-FractalDB to generate the image/point cloud pair data, as shown in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#Pt0.A2.F2" title="Figure B â€£ B.3 3D object recognition â€£ Appendix B Experimental setting details â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">B</span></a>.</p>
</div>
<figure class="ltx_table" id="Pt0.A2.T7">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" id="Pt0.A2.T7.fig1" style="width:208.1pt;">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="Pt0.A2.T7.fig1.1.1.1" style="font-size:90%;">Table F</span>: </span><span class="ltx_text" id="Pt0.A2.T7.fig1.2.2" style="font-size:90%;">Effect of formula supervision.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="Pt0.A2.T7.fig1.3" style="width:213.7pt;height:76.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-5.6pt,2.0pt) scale(0.95,0.95) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="Pt0.A2.T7.fig1.3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="Pt0.A2.T7.fig1.3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="Pt0.A2.T7.fig1.3.1.1.1.1">Shuffle type</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="Pt0.A2.T7.fig1.3.1.1.1.2"><span class="ltx_text" id="Pt0.A2.T7.fig1.3.1.1.1.2.1" style="color:#0D4DC7;">CIFAR100</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="Pt0.A2.T7.fig1.3.1.1.1.3"><span class="ltx_text" id="Pt0.A2.T7.fig1.3.1.1.1.3.1" style="color:#33801C;">ModelNe40</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="Pt0.A2.T7.fig1.3.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="Pt0.A2.T7.fig1.3.1.2.1.1">w/o shuffle</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="Pt0.A2.T7.fig1.3.1.2.1.2"><span class="ltx_text ltx_font_bold" id="Pt0.A2.T7.fig1.3.1.2.1.2.1">85.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Pt0.A2.T7.fig1.3.1.2.1.3"><span class="ltx_text ltx_font_bold" id="Pt0.A2.T7.fig1.3.1.2.1.3.1">92.9</span></td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T7.fig1.3.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T7.fig1.3.1.3.2.1">category</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T7.fig1.3.1.3.2.2">84.4</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T7.fig1.3.1.3.2.3">92.7</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T7.fig1.3.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="Pt0.A2.T7.fig1.3.1.4.3.1">instance + category</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Pt0.A2.T7.fig1.3.1.4.3.2">83.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Pt0.A2.T7.fig1.3.1.4.3.3">92.5</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" id="Pt0.A2.T7.fig2" style="width:208.1pt;">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="Pt0.A2.T7.fig2.1.1.1" style="font-size:90%;">Table G</span>: </span><span class="ltx_text" id="Pt0.A2.T7.fig2.2.2" style="font-size:90%;">Effect of loss functions.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="Pt0.A2.T7.fig2.3" style="width:190.1pt;height:76.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-5.0pt,2.0pt) scale(0.95,0.95) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="Pt0.A2.T7.fig2.3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="Pt0.A2.T7.fig2.3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="Pt0.A2.T7.fig2.3.1.1.1.1">Loss function</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="Pt0.A2.T7.fig2.3.1.1.1.2"><span class="ltx_text" id="Pt0.A2.T7.fig2.3.1.1.1.2.1" style="color:#0D4DC7;">CIFAR100</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="Pt0.A2.T7.fig2.3.1.1.1.3"><span class="ltx_text" id="Pt0.A2.T7.fig2.3.1.1.1.3.1" style="color:#33801C;">ModelNet40</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="Pt0.A2.T7.fig2.3.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="Pt0.A2.T7.fig2.3.1.2.1.1">CE</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="Pt0.A2.T7.fig2.3.1.2.1.2"><span class="ltx_text ltx_font_bold" id="Pt0.A2.T7.fig2.3.1.2.1.2.1">85.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Pt0.A2.T7.fig2.3.1.2.1.3"><span class="ltx_text ltx_font_bold" id="Pt0.A2.T7.fig2.3.1.2.1.3.1">92.9</span></td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T7.fig2.3.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Pt0.A2.T7.fig2.3.1.3.2.1">VGC</th>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T7.fig2.3.1.3.2.2">8.4</td>
<td class="ltx_td ltx_align_center" id="Pt0.A2.T7.fig2.3.1.3.2.3">92.5</td>
</tr>
<tr class="ltx_tr" id="Pt0.A2.T7.fig2.3.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="Pt0.A2.T7.fig2.3.1.4.3.1">CE + VGC</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Pt0.A2.T7.fig2.3.1.4.3.2">85.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Pt0.A2.T7.fig2.3.1.4.3.3">92.2</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</div>
</div>
</figure>
</section>
</section>
<section class="ltx_appendix" id="Pt0.A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Additional experiments</h2>
<section class="ltx_subsection" id="Pt0.A3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.1 </span>What is the pre-training effect of collapsing the pair labels in VG-FractalDB?</h3>
<div class="ltx_para" id="Pt0.A3.SS1.p1">
<p class="ltx_p" id="Pt0.A3.SS1.p1.7">This experiment verifies the pre-training effect based on the formula-supervised consistency label.
We shuffled each pair of fractal data in VG-FractalDB to make it inconsistent.
Specifically, we implement two shuffle methods, named <span class="ltx_text ltx_font_italic" id="Pt0.A3.SS1.p1.7.1">category</span> and <span class="ltx_text ltx_font_italic" id="Pt0.A3.SS1.p1.7.2">instance + category</span>, which shuffle the categories of 3D fractal point clouds for each category and instance, respectively.
Let <math alttext="\mathbf{I}=\{\mathbf{I}^{1},\mathbf{I}^{2},\dots,\mathbf{I}^{C}\}" class="ltx_Math" display="inline" id="Pt0.A3.SS1.p1.1.m1.4"><semantics id="Pt0.A3.SS1.p1.1.m1.4a"><mrow id="Pt0.A3.SS1.p1.1.m1.4.4" xref="Pt0.A3.SS1.p1.1.m1.4.4.cmml"><mi id="Pt0.A3.SS1.p1.1.m1.4.4.5" xref="Pt0.A3.SS1.p1.1.m1.4.4.5.cmml">ğˆ</mi><mo id="Pt0.A3.SS1.p1.1.m1.4.4.4" xref="Pt0.A3.SS1.p1.1.m1.4.4.4.cmml">=</mo><mrow id="Pt0.A3.SS1.p1.1.m1.4.4.3.3" xref="Pt0.A3.SS1.p1.1.m1.4.4.3.4.cmml"><mo id="Pt0.A3.SS1.p1.1.m1.4.4.3.3.4" stretchy="false" xref="Pt0.A3.SS1.p1.1.m1.4.4.3.4.cmml">{</mo><msup id="Pt0.A3.SS1.p1.1.m1.2.2.1.1.1" xref="Pt0.A3.SS1.p1.1.m1.2.2.1.1.1.cmml"><mi id="Pt0.A3.SS1.p1.1.m1.2.2.1.1.1.2" xref="Pt0.A3.SS1.p1.1.m1.2.2.1.1.1.2.cmml">ğˆ</mi><mn id="Pt0.A3.SS1.p1.1.m1.2.2.1.1.1.3" xref="Pt0.A3.SS1.p1.1.m1.2.2.1.1.1.3.cmml">1</mn></msup><mo id="Pt0.A3.SS1.p1.1.m1.4.4.3.3.5" xref="Pt0.A3.SS1.p1.1.m1.4.4.3.4.cmml">,</mo><msup id="Pt0.A3.SS1.p1.1.m1.3.3.2.2.2" xref="Pt0.A3.SS1.p1.1.m1.3.3.2.2.2.cmml"><mi id="Pt0.A3.SS1.p1.1.m1.3.3.2.2.2.2" xref="Pt0.A3.SS1.p1.1.m1.3.3.2.2.2.2.cmml">ğˆ</mi><mn id="Pt0.A3.SS1.p1.1.m1.3.3.2.2.2.3" xref="Pt0.A3.SS1.p1.1.m1.3.3.2.2.2.3.cmml">2</mn></msup><mo id="Pt0.A3.SS1.p1.1.m1.4.4.3.3.6" xref="Pt0.A3.SS1.p1.1.m1.4.4.3.4.cmml">,</mo><mi id="Pt0.A3.SS1.p1.1.m1.1.1" mathvariant="normal" xref="Pt0.A3.SS1.p1.1.m1.1.1.cmml">â€¦</mi><mo id="Pt0.A3.SS1.p1.1.m1.4.4.3.3.7" xref="Pt0.A3.SS1.p1.1.m1.4.4.3.4.cmml">,</mo><msup id="Pt0.A3.SS1.p1.1.m1.4.4.3.3.3" xref="Pt0.A3.SS1.p1.1.m1.4.4.3.3.3.cmml"><mi id="Pt0.A3.SS1.p1.1.m1.4.4.3.3.3.2" xref="Pt0.A3.SS1.p1.1.m1.4.4.3.3.3.2.cmml">ğˆ</mi><mi id="Pt0.A3.SS1.p1.1.m1.4.4.3.3.3.3" xref="Pt0.A3.SS1.p1.1.m1.4.4.3.3.3.3.cmml">C</mi></msup><mo id="Pt0.A3.SS1.p1.1.m1.4.4.3.3.8" stretchy="false" xref="Pt0.A3.SS1.p1.1.m1.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Pt0.A3.SS1.p1.1.m1.4b"><apply id="Pt0.A3.SS1.p1.1.m1.4.4.cmml" xref="Pt0.A3.SS1.p1.1.m1.4.4"><eq id="Pt0.A3.SS1.p1.1.m1.4.4.4.cmml" xref="Pt0.A3.SS1.p1.1.m1.4.4.4"></eq><ci id="Pt0.A3.SS1.p1.1.m1.4.4.5.cmml" xref="Pt0.A3.SS1.p1.1.m1.4.4.5">ğˆ</ci><set id="Pt0.A3.SS1.p1.1.m1.4.4.3.4.cmml" xref="Pt0.A3.SS1.p1.1.m1.4.4.3.3"><apply id="Pt0.A3.SS1.p1.1.m1.2.2.1.1.1.cmml" xref="Pt0.A3.SS1.p1.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p1.1.m1.2.2.1.1.1.1.cmml" xref="Pt0.A3.SS1.p1.1.m1.2.2.1.1.1">superscript</csymbol><ci id="Pt0.A3.SS1.p1.1.m1.2.2.1.1.1.2.cmml" xref="Pt0.A3.SS1.p1.1.m1.2.2.1.1.1.2">ğˆ</ci><cn id="Pt0.A3.SS1.p1.1.m1.2.2.1.1.1.3.cmml" type="integer" xref="Pt0.A3.SS1.p1.1.m1.2.2.1.1.1.3">1</cn></apply><apply id="Pt0.A3.SS1.p1.1.m1.3.3.2.2.2.cmml" xref="Pt0.A3.SS1.p1.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p1.1.m1.3.3.2.2.2.1.cmml" xref="Pt0.A3.SS1.p1.1.m1.3.3.2.2.2">superscript</csymbol><ci id="Pt0.A3.SS1.p1.1.m1.3.3.2.2.2.2.cmml" xref="Pt0.A3.SS1.p1.1.m1.3.3.2.2.2.2">ğˆ</ci><cn id="Pt0.A3.SS1.p1.1.m1.3.3.2.2.2.3.cmml" type="integer" xref="Pt0.A3.SS1.p1.1.m1.3.3.2.2.2.3">2</cn></apply><ci id="Pt0.A3.SS1.p1.1.m1.1.1.cmml" xref="Pt0.A3.SS1.p1.1.m1.1.1">â€¦</ci><apply id="Pt0.A3.SS1.p1.1.m1.4.4.3.3.3.cmml" xref="Pt0.A3.SS1.p1.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p1.1.m1.4.4.3.3.3.1.cmml" xref="Pt0.A3.SS1.p1.1.m1.4.4.3.3.3">superscript</csymbol><ci id="Pt0.A3.SS1.p1.1.m1.4.4.3.3.3.2.cmml" xref="Pt0.A3.SS1.p1.1.m1.4.4.3.3.3.2">ğˆ</ci><ci id="Pt0.A3.SS1.p1.1.m1.4.4.3.3.3.3.cmml" xref="Pt0.A3.SS1.p1.1.m1.4.4.3.3.3.3">ğ¶</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A3.SS1.p1.1.m1.4c">\mathbf{I}=\{\mathbf{I}^{1},\mathbf{I}^{2},\dots,\mathbf{I}^{C}\}</annotation><annotation encoding="application/x-llamapun" id="Pt0.A3.SS1.p1.1.m1.4d">bold_I = { bold_I start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , bold_I start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , â€¦ , bold_I start_POSTSUPERSCRIPT italic_C end_POSTSUPERSCRIPT }</annotation></semantics></math> and <math alttext="\mathbf{X}=\{\mathbf{X}^{1},\mathbf{X}^{2},\dots,\mathbf{X}^{C}\}" class="ltx_Math" display="inline" id="Pt0.A3.SS1.p1.2.m2.4"><semantics id="Pt0.A3.SS1.p1.2.m2.4a"><mrow id="Pt0.A3.SS1.p1.2.m2.4.4" xref="Pt0.A3.SS1.p1.2.m2.4.4.cmml"><mi id="Pt0.A3.SS1.p1.2.m2.4.4.5" xref="Pt0.A3.SS1.p1.2.m2.4.4.5.cmml">ğ—</mi><mo id="Pt0.A3.SS1.p1.2.m2.4.4.4" xref="Pt0.A3.SS1.p1.2.m2.4.4.4.cmml">=</mo><mrow id="Pt0.A3.SS1.p1.2.m2.4.4.3.3" xref="Pt0.A3.SS1.p1.2.m2.4.4.3.4.cmml"><mo id="Pt0.A3.SS1.p1.2.m2.4.4.3.3.4" stretchy="false" xref="Pt0.A3.SS1.p1.2.m2.4.4.3.4.cmml">{</mo><msup id="Pt0.A3.SS1.p1.2.m2.2.2.1.1.1" xref="Pt0.A3.SS1.p1.2.m2.2.2.1.1.1.cmml"><mi id="Pt0.A3.SS1.p1.2.m2.2.2.1.1.1.2" xref="Pt0.A3.SS1.p1.2.m2.2.2.1.1.1.2.cmml">ğ—</mi><mn id="Pt0.A3.SS1.p1.2.m2.2.2.1.1.1.3" xref="Pt0.A3.SS1.p1.2.m2.2.2.1.1.1.3.cmml">1</mn></msup><mo id="Pt0.A3.SS1.p1.2.m2.4.4.3.3.5" xref="Pt0.A3.SS1.p1.2.m2.4.4.3.4.cmml">,</mo><msup id="Pt0.A3.SS1.p1.2.m2.3.3.2.2.2" xref="Pt0.A3.SS1.p1.2.m2.3.3.2.2.2.cmml"><mi id="Pt0.A3.SS1.p1.2.m2.3.3.2.2.2.2" xref="Pt0.A3.SS1.p1.2.m2.3.3.2.2.2.2.cmml">ğ—</mi><mn id="Pt0.A3.SS1.p1.2.m2.3.3.2.2.2.3" xref="Pt0.A3.SS1.p1.2.m2.3.3.2.2.2.3.cmml">2</mn></msup><mo id="Pt0.A3.SS1.p1.2.m2.4.4.3.3.6" xref="Pt0.A3.SS1.p1.2.m2.4.4.3.4.cmml">,</mo><mi id="Pt0.A3.SS1.p1.2.m2.1.1" mathvariant="normal" xref="Pt0.A3.SS1.p1.2.m2.1.1.cmml">â€¦</mi><mo id="Pt0.A3.SS1.p1.2.m2.4.4.3.3.7" xref="Pt0.A3.SS1.p1.2.m2.4.4.3.4.cmml">,</mo><msup id="Pt0.A3.SS1.p1.2.m2.4.4.3.3.3" xref="Pt0.A3.SS1.p1.2.m2.4.4.3.3.3.cmml"><mi id="Pt0.A3.SS1.p1.2.m2.4.4.3.3.3.2" xref="Pt0.A3.SS1.p1.2.m2.4.4.3.3.3.2.cmml">ğ—</mi><mi id="Pt0.A3.SS1.p1.2.m2.4.4.3.3.3.3" xref="Pt0.A3.SS1.p1.2.m2.4.4.3.3.3.3.cmml">C</mi></msup><mo id="Pt0.A3.SS1.p1.2.m2.4.4.3.3.8" stretchy="false" xref="Pt0.A3.SS1.p1.2.m2.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Pt0.A3.SS1.p1.2.m2.4b"><apply id="Pt0.A3.SS1.p1.2.m2.4.4.cmml" xref="Pt0.A3.SS1.p1.2.m2.4.4"><eq id="Pt0.A3.SS1.p1.2.m2.4.4.4.cmml" xref="Pt0.A3.SS1.p1.2.m2.4.4.4"></eq><ci id="Pt0.A3.SS1.p1.2.m2.4.4.5.cmml" xref="Pt0.A3.SS1.p1.2.m2.4.4.5">ğ—</ci><set id="Pt0.A3.SS1.p1.2.m2.4.4.3.4.cmml" xref="Pt0.A3.SS1.p1.2.m2.4.4.3.3"><apply id="Pt0.A3.SS1.p1.2.m2.2.2.1.1.1.cmml" xref="Pt0.A3.SS1.p1.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p1.2.m2.2.2.1.1.1.1.cmml" xref="Pt0.A3.SS1.p1.2.m2.2.2.1.1.1">superscript</csymbol><ci id="Pt0.A3.SS1.p1.2.m2.2.2.1.1.1.2.cmml" xref="Pt0.A3.SS1.p1.2.m2.2.2.1.1.1.2">ğ—</ci><cn id="Pt0.A3.SS1.p1.2.m2.2.2.1.1.1.3.cmml" type="integer" xref="Pt0.A3.SS1.p1.2.m2.2.2.1.1.1.3">1</cn></apply><apply id="Pt0.A3.SS1.p1.2.m2.3.3.2.2.2.cmml" xref="Pt0.A3.SS1.p1.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p1.2.m2.3.3.2.2.2.1.cmml" xref="Pt0.A3.SS1.p1.2.m2.3.3.2.2.2">superscript</csymbol><ci id="Pt0.A3.SS1.p1.2.m2.3.3.2.2.2.2.cmml" xref="Pt0.A3.SS1.p1.2.m2.3.3.2.2.2.2">ğ—</ci><cn id="Pt0.A3.SS1.p1.2.m2.3.3.2.2.2.3.cmml" type="integer" xref="Pt0.A3.SS1.p1.2.m2.3.3.2.2.2.3">2</cn></apply><ci id="Pt0.A3.SS1.p1.2.m2.1.1.cmml" xref="Pt0.A3.SS1.p1.2.m2.1.1">â€¦</ci><apply id="Pt0.A3.SS1.p1.2.m2.4.4.3.3.3.cmml" xref="Pt0.A3.SS1.p1.2.m2.4.4.3.3.3"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p1.2.m2.4.4.3.3.3.1.cmml" xref="Pt0.A3.SS1.p1.2.m2.4.4.3.3.3">superscript</csymbol><ci id="Pt0.A3.SS1.p1.2.m2.4.4.3.3.3.2.cmml" xref="Pt0.A3.SS1.p1.2.m2.4.4.3.3.3.2">ğ—</ci><ci id="Pt0.A3.SS1.p1.2.m2.4.4.3.3.3.3.cmml" xref="Pt0.A3.SS1.p1.2.m2.4.4.3.3.3.3">ğ¶</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A3.SS1.p1.2.m2.4c">\mathbf{X}=\{\mathbf{X}^{1},\mathbf{X}^{2},\dots,\mathbf{X}^{C}\}</annotation><annotation encoding="application/x-llamapun" id="Pt0.A3.SS1.p1.2.m2.4d">bold_X = { bold_X start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , bold_X start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , â€¦ , bold_X start_POSTSUPERSCRIPT italic_C end_POSTSUPERSCRIPT }</annotation></semantics></math> denote the image and pointcloud data, respectively, where <math alttext="C" class="ltx_Math" display="inline" id="Pt0.A3.SS1.p1.3.m3.1"><semantics id="Pt0.A3.SS1.p1.3.m3.1a"><mi id="Pt0.A3.SS1.p1.3.m3.1.1" xref="Pt0.A3.SS1.p1.3.m3.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="Pt0.A3.SS1.p1.3.m3.1b"><ci id="Pt0.A3.SS1.p1.3.m3.1.1.cmml" xref="Pt0.A3.SS1.p1.3.m3.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A3.SS1.p1.3.m3.1c">C</annotation><annotation encoding="application/x-llamapun" id="Pt0.A3.SS1.p1.3.m3.1d">italic_C</annotation></semantics></math> is the number of categories.
The instances of images and point clouds in category <math alttext="c" class="ltx_Math" display="inline" id="Pt0.A3.SS1.p1.4.m4.1"><semantics id="Pt0.A3.SS1.p1.4.m4.1a"><mi id="Pt0.A3.SS1.p1.4.m4.1.1" xref="Pt0.A3.SS1.p1.4.m4.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="Pt0.A3.SS1.p1.4.m4.1b"><ci id="Pt0.A3.SS1.p1.4.m4.1.1.cmml" xref="Pt0.A3.SS1.p1.4.m4.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A3.SS1.p1.4.m4.1c">c</annotation><annotation encoding="application/x-llamapun" id="Pt0.A3.SS1.p1.4.m4.1d">italic_c</annotation></semantics></math> are denoted as <math alttext="\mathbf{I}^{c}=\{\mathbf{I}^{c}_{1},\mathbf{I}^{c}_{2},\dots,\mathbf{I}^{c}_{M}\}" class="ltx_Math" display="inline" id="Pt0.A3.SS1.p1.5.m5.4"><semantics id="Pt0.A3.SS1.p1.5.m5.4a"><mrow id="Pt0.A3.SS1.p1.5.m5.4.4" xref="Pt0.A3.SS1.p1.5.m5.4.4.cmml"><msup id="Pt0.A3.SS1.p1.5.m5.4.4.5" xref="Pt0.A3.SS1.p1.5.m5.4.4.5.cmml"><mi id="Pt0.A3.SS1.p1.5.m5.4.4.5.2" xref="Pt0.A3.SS1.p1.5.m5.4.4.5.2.cmml">ğˆ</mi><mi id="Pt0.A3.SS1.p1.5.m5.4.4.5.3" xref="Pt0.A3.SS1.p1.5.m5.4.4.5.3.cmml">c</mi></msup><mo id="Pt0.A3.SS1.p1.5.m5.4.4.4" xref="Pt0.A3.SS1.p1.5.m5.4.4.4.cmml">=</mo><mrow id="Pt0.A3.SS1.p1.5.m5.4.4.3.3" xref="Pt0.A3.SS1.p1.5.m5.4.4.3.4.cmml"><mo id="Pt0.A3.SS1.p1.5.m5.4.4.3.3.4" stretchy="false" xref="Pt0.A3.SS1.p1.5.m5.4.4.3.4.cmml">{</mo><msubsup id="Pt0.A3.SS1.p1.5.m5.2.2.1.1.1" xref="Pt0.A3.SS1.p1.5.m5.2.2.1.1.1.cmml"><mi id="Pt0.A3.SS1.p1.5.m5.2.2.1.1.1.2.2" xref="Pt0.A3.SS1.p1.5.m5.2.2.1.1.1.2.2.cmml">ğˆ</mi><mn id="Pt0.A3.SS1.p1.5.m5.2.2.1.1.1.3" xref="Pt0.A3.SS1.p1.5.m5.2.2.1.1.1.3.cmml">1</mn><mi id="Pt0.A3.SS1.p1.5.m5.2.2.1.1.1.2.3" xref="Pt0.A3.SS1.p1.5.m5.2.2.1.1.1.2.3.cmml">c</mi></msubsup><mo id="Pt0.A3.SS1.p1.5.m5.4.4.3.3.5" xref="Pt0.A3.SS1.p1.5.m5.4.4.3.4.cmml">,</mo><msubsup id="Pt0.A3.SS1.p1.5.m5.3.3.2.2.2" xref="Pt0.A3.SS1.p1.5.m5.3.3.2.2.2.cmml"><mi id="Pt0.A3.SS1.p1.5.m5.3.3.2.2.2.2.2" xref="Pt0.A3.SS1.p1.5.m5.3.3.2.2.2.2.2.cmml">ğˆ</mi><mn id="Pt0.A3.SS1.p1.5.m5.3.3.2.2.2.3" xref="Pt0.A3.SS1.p1.5.m5.3.3.2.2.2.3.cmml">2</mn><mi id="Pt0.A3.SS1.p1.5.m5.3.3.2.2.2.2.3" xref="Pt0.A3.SS1.p1.5.m5.3.3.2.2.2.2.3.cmml">c</mi></msubsup><mo id="Pt0.A3.SS1.p1.5.m5.4.4.3.3.6" xref="Pt0.A3.SS1.p1.5.m5.4.4.3.4.cmml">,</mo><mi id="Pt0.A3.SS1.p1.5.m5.1.1" mathvariant="normal" xref="Pt0.A3.SS1.p1.5.m5.1.1.cmml">â€¦</mi><mo id="Pt0.A3.SS1.p1.5.m5.4.4.3.3.7" xref="Pt0.A3.SS1.p1.5.m5.4.4.3.4.cmml">,</mo><msubsup id="Pt0.A3.SS1.p1.5.m5.4.4.3.3.3" xref="Pt0.A3.SS1.p1.5.m5.4.4.3.3.3.cmml"><mi id="Pt0.A3.SS1.p1.5.m5.4.4.3.3.3.2.2" xref="Pt0.A3.SS1.p1.5.m5.4.4.3.3.3.2.2.cmml">ğˆ</mi><mi id="Pt0.A3.SS1.p1.5.m5.4.4.3.3.3.3" xref="Pt0.A3.SS1.p1.5.m5.4.4.3.3.3.3.cmml">M</mi><mi id="Pt0.A3.SS1.p1.5.m5.4.4.3.3.3.2.3" xref="Pt0.A3.SS1.p1.5.m5.4.4.3.3.3.2.3.cmml">c</mi></msubsup><mo id="Pt0.A3.SS1.p1.5.m5.4.4.3.3.8" stretchy="false" xref="Pt0.A3.SS1.p1.5.m5.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Pt0.A3.SS1.p1.5.m5.4b"><apply id="Pt0.A3.SS1.p1.5.m5.4.4.cmml" xref="Pt0.A3.SS1.p1.5.m5.4.4"><eq id="Pt0.A3.SS1.p1.5.m5.4.4.4.cmml" xref="Pt0.A3.SS1.p1.5.m5.4.4.4"></eq><apply id="Pt0.A3.SS1.p1.5.m5.4.4.5.cmml" xref="Pt0.A3.SS1.p1.5.m5.4.4.5"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p1.5.m5.4.4.5.1.cmml" xref="Pt0.A3.SS1.p1.5.m5.4.4.5">superscript</csymbol><ci id="Pt0.A3.SS1.p1.5.m5.4.4.5.2.cmml" xref="Pt0.A3.SS1.p1.5.m5.4.4.5.2">ğˆ</ci><ci id="Pt0.A3.SS1.p1.5.m5.4.4.5.3.cmml" xref="Pt0.A3.SS1.p1.5.m5.4.4.5.3">ğ‘</ci></apply><set id="Pt0.A3.SS1.p1.5.m5.4.4.3.4.cmml" xref="Pt0.A3.SS1.p1.5.m5.4.4.3.3"><apply id="Pt0.A3.SS1.p1.5.m5.2.2.1.1.1.cmml" xref="Pt0.A3.SS1.p1.5.m5.2.2.1.1.1"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p1.5.m5.2.2.1.1.1.1.cmml" xref="Pt0.A3.SS1.p1.5.m5.2.2.1.1.1">subscript</csymbol><apply id="Pt0.A3.SS1.p1.5.m5.2.2.1.1.1.2.cmml" xref="Pt0.A3.SS1.p1.5.m5.2.2.1.1.1"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p1.5.m5.2.2.1.1.1.2.1.cmml" xref="Pt0.A3.SS1.p1.5.m5.2.2.1.1.1">superscript</csymbol><ci id="Pt0.A3.SS1.p1.5.m5.2.2.1.1.1.2.2.cmml" xref="Pt0.A3.SS1.p1.5.m5.2.2.1.1.1.2.2">ğˆ</ci><ci id="Pt0.A3.SS1.p1.5.m5.2.2.1.1.1.2.3.cmml" xref="Pt0.A3.SS1.p1.5.m5.2.2.1.1.1.2.3">ğ‘</ci></apply><cn id="Pt0.A3.SS1.p1.5.m5.2.2.1.1.1.3.cmml" type="integer" xref="Pt0.A3.SS1.p1.5.m5.2.2.1.1.1.3">1</cn></apply><apply id="Pt0.A3.SS1.p1.5.m5.3.3.2.2.2.cmml" xref="Pt0.A3.SS1.p1.5.m5.3.3.2.2.2"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p1.5.m5.3.3.2.2.2.1.cmml" xref="Pt0.A3.SS1.p1.5.m5.3.3.2.2.2">subscript</csymbol><apply id="Pt0.A3.SS1.p1.5.m5.3.3.2.2.2.2.cmml" xref="Pt0.A3.SS1.p1.5.m5.3.3.2.2.2"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p1.5.m5.3.3.2.2.2.2.1.cmml" xref="Pt0.A3.SS1.p1.5.m5.3.3.2.2.2">superscript</csymbol><ci id="Pt0.A3.SS1.p1.5.m5.3.3.2.2.2.2.2.cmml" xref="Pt0.A3.SS1.p1.5.m5.3.3.2.2.2.2.2">ğˆ</ci><ci id="Pt0.A3.SS1.p1.5.m5.3.3.2.2.2.2.3.cmml" xref="Pt0.A3.SS1.p1.5.m5.3.3.2.2.2.2.3">ğ‘</ci></apply><cn id="Pt0.A3.SS1.p1.5.m5.3.3.2.2.2.3.cmml" type="integer" xref="Pt0.A3.SS1.p1.5.m5.3.3.2.2.2.3">2</cn></apply><ci id="Pt0.A3.SS1.p1.5.m5.1.1.cmml" xref="Pt0.A3.SS1.p1.5.m5.1.1">â€¦</ci><apply id="Pt0.A3.SS1.p1.5.m5.4.4.3.3.3.cmml" xref="Pt0.A3.SS1.p1.5.m5.4.4.3.3.3"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p1.5.m5.4.4.3.3.3.1.cmml" xref="Pt0.A3.SS1.p1.5.m5.4.4.3.3.3">subscript</csymbol><apply id="Pt0.A3.SS1.p1.5.m5.4.4.3.3.3.2.cmml" xref="Pt0.A3.SS1.p1.5.m5.4.4.3.3.3"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p1.5.m5.4.4.3.3.3.2.1.cmml" xref="Pt0.A3.SS1.p1.5.m5.4.4.3.3.3">superscript</csymbol><ci id="Pt0.A3.SS1.p1.5.m5.4.4.3.3.3.2.2.cmml" xref="Pt0.A3.SS1.p1.5.m5.4.4.3.3.3.2.2">ğˆ</ci><ci id="Pt0.A3.SS1.p1.5.m5.4.4.3.3.3.2.3.cmml" xref="Pt0.A3.SS1.p1.5.m5.4.4.3.3.3.2.3">ğ‘</ci></apply><ci id="Pt0.A3.SS1.p1.5.m5.4.4.3.3.3.3.cmml" xref="Pt0.A3.SS1.p1.5.m5.4.4.3.3.3.3">ğ‘€</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A3.SS1.p1.5.m5.4c">\mathbf{I}^{c}=\{\mathbf{I}^{c}_{1},\mathbf{I}^{c}_{2},\dots,\mathbf{I}^{c}_{M}\}</annotation><annotation encoding="application/x-llamapun" id="Pt0.A3.SS1.p1.5.m5.4d">bold_I start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT = { bold_I start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , bold_I start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , â€¦ , bold_I start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT }</annotation></semantics></math> and <math alttext="\mathbf{X}^{c}=\{\mathbf{X}^{c}_{1},\mathbf{X}^{c}_{2},\dots,\mathbf{X}^{c}_{M}\}" class="ltx_Math" display="inline" id="Pt0.A3.SS1.p1.6.m6.4"><semantics id="Pt0.A3.SS1.p1.6.m6.4a"><mrow id="Pt0.A3.SS1.p1.6.m6.4.4" xref="Pt0.A3.SS1.p1.6.m6.4.4.cmml"><msup id="Pt0.A3.SS1.p1.6.m6.4.4.5" xref="Pt0.A3.SS1.p1.6.m6.4.4.5.cmml"><mi id="Pt0.A3.SS1.p1.6.m6.4.4.5.2" xref="Pt0.A3.SS1.p1.6.m6.4.4.5.2.cmml">ğ—</mi><mi id="Pt0.A3.SS1.p1.6.m6.4.4.5.3" xref="Pt0.A3.SS1.p1.6.m6.4.4.5.3.cmml">c</mi></msup><mo id="Pt0.A3.SS1.p1.6.m6.4.4.4" xref="Pt0.A3.SS1.p1.6.m6.4.4.4.cmml">=</mo><mrow id="Pt0.A3.SS1.p1.6.m6.4.4.3.3" xref="Pt0.A3.SS1.p1.6.m6.4.4.3.4.cmml"><mo id="Pt0.A3.SS1.p1.6.m6.4.4.3.3.4" stretchy="false" xref="Pt0.A3.SS1.p1.6.m6.4.4.3.4.cmml">{</mo><msubsup id="Pt0.A3.SS1.p1.6.m6.2.2.1.1.1" xref="Pt0.A3.SS1.p1.6.m6.2.2.1.1.1.cmml"><mi id="Pt0.A3.SS1.p1.6.m6.2.2.1.1.1.2.2" xref="Pt0.A3.SS1.p1.6.m6.2.2.1.1.1.2.2.cmml">ğ—</mi><mn id="Pt0.A3.SS1.p1.6.m6.2.2.1.1.1.3" xref="Pt0.A3.SS1.p1.6.m6.2.2.1.1.1.3.cmml">1</mn><mi id="Pt0.A3.SS1.p1.6.m6.2.2.1.1.1.2.3" xref="Pt0.A3.SS1.p1.6.m6.2.2.1.1.1.2.3.cmml">c</mi></msubsup><mo id="Pt0.A3.SS1.p1.6.m6.4.4.3.3.5" xref="Pt0.A3.SS1.p1.6.m6.4.4.3.4.cmml">,</mo><msubsup id="Pt0.A3.SS1.p1.6.m6.3.3.2.2.2" xref="Pt0.A3.SS1.p1.6.m6.3.3.2.2.2.cmml"><mi id="Pt0.A3.SS1.p1.6.m6.3.3.2.2.2.2.2" xref="Pt0.A3.SS1.p1.6.m6.3.3.2.2.2.2.2.cmml">ğ—</mi><mn id="Pt0.A3.SS1.p1.6.m6.3.3.2.2.2.3" xref="Pt0.A3.SS1.p1.6.m6.3.3.2.2.2.3.cmml">2</mn><mi id="Pt0.A3.SS1.p1.6.m6.3.3.2.2.2.2.3" xref="Pt0.A3.SS1.p1.6.m6.3.3.2.2.2.2.3.cmml">c</mi></msubsup><mo id="Pt0.A3.SS1.p1.6.m6.4.4.3.3.6" xref="Pt0.A3.SS1.p1.6.m6.4.4.3.4.cmml">,</mo><mi id="Pt0.A3.SS1.p1.6.m6.1.1" mathvariant="normal" xref="Pt0.A3.SS1.p1.6.m6.1.1.cmml">â€¦</mi><mo id="Pt0.A3.SS1.p1.6.m6.4.4.3.3.7" xref="Pt0.A3.SS1.p1.6.m6.4.4.3.4.cmml">,</mo><msubsup id="Pt0.A3.SS1.p1.6.m6.4.4.3.3.3" xref="Pt0.A3.SS1.p1.6.m6.4.4.3.3.3.cmml"><mi id="Pt0.A3.SS1.p1.6.m6.4.4.3.3.3.2.2" xref="Pt0.A3.SS1.p1.6.m6.4.4.3.3.3.2.2.cmml">ğ—</mi><mi id="Pt0.A3.SS1.p1.6.m6.4.4.3.3.3.3" xref="Pt0.A3.SS1.p1.6.m6.4.4.3.3.3.3.cmml">M</mi><mi id="Pt0.A3.SS1.p1.6.m6.4.4.3.3.3.2.3" xref="Pt0.A3.SS1.p1.6.m6.4.4.3.3.3.2.3.cmml">c</mi></msubsup><mo id="Pt0.A3.SS1.p1.6.m6.4.4.3.3.8" stretchy="false" xref="Pt0.A3.SS1.p1.6.m6.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Pt0.A3.SS1.p1.6.m6.4b"><apply id="Pt0.A3.SS1.p1.6.m6.4.4.cmml" xref="Pt0.A3.SS1.p1.6.m6.4.4"><eq id="Pt0.A3.SS1.p1.6.m6.4.4.4.cmml" xref="Pt0.A3.SS1.p1.6.m6.4.4.4"></eq><apply id="Pt0.A3.SS1.p1.6.m6.4.4.5.cmml" xref="Pt0.A3.SS1.p1.6.m6.4.4.5"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p1.6.m6.4.4.5.1.cmml" xref="Pt0.A3.SS1.p1.6.m6.4.4.5">superscript</csymbol><ci id="Pt0.A3.SS1.p1.6.m6.4.4.5.2.cmml" xref="Pt0.A3.SS1.p1.6.m6.4.4.5.2">ğ—</ci><ci id="Pt0.A3.SS1.p1.6.m6.4.4.5.3.cmml" xref="Pt0.A3.SS1.p1.6.m6.4.4.5.3">ğ‘</ci></apply><set id="Pt0.A3.SS1.p1.6.m6.4.4.3.4.cmml" xref="Pt0.A3.SS1.p1.6.m6.4.4.3.3"><apply id="Pt0.A3.SS1.p1.6.m6.2.2.1.1.1.cmml" xref="Pt0.A3.SS1.p1.6.m6.2.2.1.1.1"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p1.6.m6.2.2.1.1.1.1.cmml" xref="Pt0.A3.SS1.p1.6.m6.2.2.1.1.1">subscript</csymbol><apply id="Pt0.A3.SS1.p1.6.m6.2.2.1.1.1.2.cmml" xref="Pt0.A3.SS1.p1.6.m6.2.2.1.1.1"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p1.6.m6.2.2.1.1.1.2.1.cmml" xref="Pt0.A3.SS1.p1.6.m6.2.2.1.1.1">superscript</csymbol><ci id="Pt0.A3.SS1.p1.6.m6.2.2.1.1.1.2.2.cmml" xref="Pt0.A3.SS1.p1.6.m6.2.2.1.1.1.2.2">ğ—</ci><ci id="Pt0.A3.SS1.p1.6.m6.2.2.1.1.1.2.3.cmml" xref="Pt0.A3.SS1.p1.6.m6.2.2.1.1.1.2.3">ğ‘</ci></apply><cn id="Pt0.A3.SS1.p1.6.m6.2.2.1.1.1.3.cmml" type="integer" xref="Pt0.A3.SS1.p1.6.m6.2.2.1.1.1.3">1</cn></apply><apply id="Pt0.A3.SS1.p1.6.m6.3.3.2.2.2.cmml" xref="Pt0.A3.SS1.p1.6.m6.3.3.2.2.2"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p1.6.m6.3.3.2.2.2.1.cmml" xref="Pt0.A3.SS1.p1.6.m6.3.3.2.2.2">subscript</csymbol><apply id="Pt0.A3.SS1.p1.6.m6.3.3.2.2.2.2.cmml" xref="Pt0.A3.SS1.p1.6.m6.3.3.2.2.2"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p1.6.m6.3.3.2.2.2.2.1.cmml" xref="Pt0.A3.SS1.p1.6.m6.3.3.2.2.2">superscript</csymbol><ci id="Pt0.A3.SS1.p1.6.m6.3.3.2.2.2.2.2.cmml" xref="Pt0.A3.SS1.p1.6.m6.3.3.2.2.2.2.2">ğ—</ci><ci id="Pt0.A3.SS1.p1.6.m6.3.3.2.2.2.2.3.cmml" xref="Pt0.A3.SS1.p1.6.m6.3.3.2.2.2.2.3">ğ‘</ci></apply><cn id="Pt0.A3.SS1.p1.6.m6.3.3.2.2.2.3.cmml" type="integer" xref="Pt0.A3.SS1.p1.6.m6.3.3.2.2.2.3">2</cn></apply><ci id="Pt0.A3.SS1.p1.6.m6.1.1.cmml" xref="Pt0.A3.SS1.p1.6.m6.1.1">â€¦</ci><apply id="Pt0.A3.SS1.p1.6.m6.4.4.3.3.3.cmml" xref="Pt0.A3.SS1.p1.6.m6.4.4.3.3.3"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p1.6.m6.4.4.3.3.3.1.cmml" xref="Pt0.A3.SS1.p1.6.m6.4.4.3.3.3">subscript</csymbol><apply id="Pt0.A3.SS1.p1.6.m6.4.4.3.3.3.2.cmml" xref="Pt0.A3.SS1.p1.6.m6.4.4.3.3.3"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p1.6.m6.4.4.3.3.3.2.1.cmml" xref="Pt0.A3.SS1.p1.6.m6.4.4.3.3.3">superscript</csymbol><ci id="Pt0.A3.SS1.p1.6.m6.4.4.3.3.3.2.2.cmml" xref="Pt0.A3.SS1.p1.6.m6.4.4.3.3.3.2.2">ğ—</ci><ci id="Pt0.A3.SS1.p1.6.m6.4.4.3.3.3.2.3.cmml" xref="Pt0.A3.SS1.p1.6.m6.4.4.3.3.3.2.3">ğ‘</ci></apply><ci id="Pt0.A3.SS1.p1.6.m6.4.4.3.3.3.3.cmml" xref="Pt0.A3.SS1.p1.6.m6.4.4.3.3.3.3">ğ‘€</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A3.SS1.p1.6.m6.4c">\mathbf{X}^{c}=\{\mathbf{X}^{c}_{1},\mathbf{X}^{c}_{2},\dots,\mathbf{X}^{c}_{M}\}</annotation><annotation encoding="application/x-llamapun" id="Pt0.A3.SS1.p1.6.m6.4d">bold_X start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT = { bold_X start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , bold_X start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , â€¦ , bold_X start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT }</annotation></semantics></math>, respectively, where <math alttext="M" class="ltx_Math" display="inline" id="Pt0.A3.SS1.p1.7.m7.1"><semantics id="Pt0.A3.SS1.p1.7.m7.1a"><mi id="Pt0.A3.SS1.p1.7.m7.1.1" xref="Pt0.A3.SS1.p1.7.m7.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="Pt0.A3.SS1.p1.7.m7.1b"><ci id="Pt0.A3.SS1.p1.7.m7.1.1.cmml" xref="Pt0.A3.SS1.p1.7.m7.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A3.SS1.p1.7.m7.1c">M</annotation><annotation encoding="application/x-llamapun" id="Pt0.A3.SS1.p1.7.m7.1d">italic_M</annotation></semantics></math> is the number of instances in each category.</p>
</div>
<div class="ltx_para" id="Pt0.A3.SS1.p2">
<p class="ltx_p" id="Pt0.A3.SS1.p2.3">The <span class="ltx_text ltx_font_italic" id="Pt0.A3.SS1.p2.3.1">category</span> shuffle randomizes the category indices of point clouds to destroy the consistency of categories for images and point clouds.
After <span class="ltx_text ltx_font_italic" id="Pt0.A3.SS1.p2.3.2">category</span> shuffle, the instances of point clouds in category <math alttext="c" class="ltx_Math" display="inline" id="Pt0.A3.SS1.p2.1.m1.1"><semantics id="Pt0.A3.SS1.p2.1.m1.1a"><mi id="Pt0.A3.SS1.p2.1.m1.1.1" xref="Pt0.A3.SS1.p2.1.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="Pt0.A3.SS1.p2.1.m1.1b"><ci id="Pt0.A3.SS1.p2.1.m1.1.1.cmml" xref="Pt0.A3.SS1.p2.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A3.SS1.p2.1.m1.1c">c</annotation><annotation encoding="application/x-llamapun" id="Pt0.A3.SS1.p2.1.m1.1d">italic_c</annotation></semantics></math> are denoted as <math alttext="\mathbf{X}^{c}_{\mathrm{cs}}=\{\mathbf{X}^{c^{\prime}}_{1},\mathbf{X}^{c^{%
\prime}}_{2},\dots,\mathbf{X}^{c^{\prime}}_{M}\}" class="ltx_Math" display="inline" id="Pt0.A3.SS1.p2.2.m2.4"><semantics id="Pt0.A3.SS1.p2.2.m2.4a"><mrow id="Pt0.A3.SS1.p2.2.m2.4.4" xref="Pt0.A3.SS1.p2.2.m2.4.4.cmml"><msubsup id="Pt0.A3.SS1.p2.2.m2.4.4.5" xref="Pt0.A3.SS1.p2.2.m2.4.4.5.cmml"><mi id="Pt0.A3.SS1.p2.2.m2.4.4.5.2.2" xref="Pt0.A3.SS1.p2.2.m2.4.4.5.2.2.cmml">ğ—</mi><mi id="Pt0.A3.SS1.p2.2.m2.4.4.5.3" xref="Pt0.A3.SS1.p2.2.m2.4.4.5.3.cmml">cs</mi><mi id="Pt0.A3.SS1.p2.2.m2.4.4.5.2.3" xref="Pt0.A3.SS1.p2.2.m2.4.4.5.2.3.cmml">c</mi></msubsup><mo id="Pt0.A3.SS1.p2.2.m2.4.4.4" xref="Pt0.A3.SS1.p2.2.m2.4.4.4.cmml">=</mo><mrow id="Pt0.A3.SS1.p2.2.m2.4.4.3.3" xref="Pt0.A3.SS1.p2.2.m2.4.4.3.4.cmml"><mo id="Pt0.A3.SS1.p2.2.m2.4.4.3.3.4" stretchy="false" xref="Pt0.A3.SS1.p2.2.m2.4.4.3.4.cmml">{</mo><msubsup id="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1" xref="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1.cmml"><mi id="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1.2.2" xref="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1.2.2.cmml">ğ—</mi><mn id="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1.3" xref="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1.3.cmml">1</mn><msup id="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1.2.3" xref="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1.2.3.cmml"><mi id="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1.2.3.2" xref="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1.2.3.2.cmml">c</mi><mo id="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1.2.3.3" xref="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1.2.3.3.cmml">â€²</mo></msup></msubsup><mo id="Pt0.A3.SS1.p2.2.m2.4.4.3.3.5" xref="Pt0.A3.SS1.p2.2.m2.4.4.3.4.cmml">,</mo><msubsup id="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2" xref="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2.cmml"><mi id="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2.2.2" xref="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2.2.2.cmml">ğ—</mi><mn id="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2.3" xref="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2.3.cmml">2</mn><msup id="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2.2.3" xref="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2.2.3.cmml"><mi id="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2.2.3.2" xref="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2.2.3.2.cmml">c</mi><mo id="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2.2.3.3" xref="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2.2.3.3.cmml">â€²</mo></msup></msubsup><mo id="Pt0.A3.SS1.p2.2.m2.4.4.3.3.6" xref="Pt0.A3.SS1.p2.2.m2.4.4.3.4.cmml">,</mo><mi id="Pt0.A3.SS1.p2.2.m2.1.1" mathvariant="normal" xref="Pt0.A3.SS1.p2.2.m2.1.1.cmml">â€¦</mi><mo id="Pt0.A3.SS1.p2.2.m2.4.4.3.3.7" xref="Pt0.A3.SS1.p2.2.m2.4.4.3.4.cmml">,</mo><msubsup id="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3" xref="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3.cmml"><mi id="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3.2.2" xref="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3.2.2.cmml">ğ—</mi><mi id="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3.3" xref="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3.3.cmml">M</mi><msup id="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3.2.3" xref="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3.2.3.cmml"><mi id="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3.2.3.2" xref="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3.2.3.2.cmml">c</mi><mo id="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3.2.3.3" xref="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3.2.3.3.cmml">â€²</mo></msup></msubsup><mo id="Pt0.A3.SS1.p2.2.m2.4.4.3.3.8" stretchy="false" xref="Pt0.A3.SS1.p2.2.m2.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Pt0.A3.SS1.p2.2.m2.4b"><apply id="Pt0.A3.SS1.p2.2.m2.4.4.cmml" xref="Pt0.A3.SS1.p2.2.m2.4.4"><eq id="Pt0.A3.SS1.p2.2.m2.4.4.4.cmml" xref="Pt0.A3.SS1.p2.2.m2.4.4.4"></eq><apply id="Pt0.A3.SS1.p2.2.m2.4.4.5.cmml" xref="Pt0.A3.SS1.p2.2.m2.4.4.5"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p2.2.m2.4.4.5.1.cmml" xref="Pt0.A3.SS1.p2.2.m2.4.4.5">subscript</csymbol><apply id="Pt0.A3.SS1.p2.2.m2.4.4.5.2.cmml" xref="Pt0.A3.SS1.p2.2.m2.4.4.5"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p2.2.m2.4.4.5.2.1.cmml" xref="Pt0.A3.SS1.p2.2.m2.4.4.5">superscript</csymbol><ci id="Pt0.A3.SS1.p2.2.m2.4.4.5.2.2.cmml" xref="Pt0.A3.SS1.p2.2.m2.4.4.5.2.2">ğ—</ci><ci id="Pt0.A3.SS1.p2.2.m2.4.4.5.2.3.cmml" xref="Pt0.A3.SS1.p2.2.m2.4.4.5.2.3">ğ‘</ci></apply><ci id="Pt0.A3.SS1.p2.2.m2.4.4.5.3.cmml" xref="Pt0.A3.SS1.p2.2.m2.4.4.5.3">cs</ci></apply><set id="Pt0.A3.SS1.p2.2.m2.4.4.3.4.cmml" xref="Pt0.A3.SS1.p2.2.m2.4.4.3.3"><apply id="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1.cmml" xref="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1.1.cmml" xref="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1">subscript</csymbol><apply id="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1.2.cmml" xref="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1.2.1.cmml" xref="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1">superscript</csymbol><ci id="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1.2.2.cmml" xref="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1.2.2">ğ—</ci><apply id="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1.2.3.cmml" xref="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1.2.3"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1.2.3.1.cmml" xref="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1.2.3">superscript</csymbol><ci id="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1.2.3.2.cmml" xref="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1.2.3.2">ğ‘</ci><ci id="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1.2.3.3.cmml" xref="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1.2.3.3">â€²</ci></apply></apply><cn id="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1.3.cmml" type="integer" xref="Pt0.A3.SS1.p2.2.m2.2.2.1.1.1.3">1</cn></apply><apply id="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2.cmml" xref="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2.1.cmml" xref="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2">subscript</csymbol><apply id="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2.2.cmml" xref="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2.2.1.cmml" xref="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2">superscript</csymbol><ci id="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2.2.2.cmml" xref="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2.2.2">ğ—</ci><apply id="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2.2.3.cmml" xref="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2.2.3"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2.2.3.1.cmml" xref="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2.2.3">superscript</csymbol><ci id="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2.2.3.2.cmml" xref="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2.2.3.2">ğ‘</ci><ci id="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2.2.3.3.cmml" xref="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2.2.3.3">â€²</ci></apply></apply><cn id="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2.3.cmml" type="integer" xref="Pt0.A3.SS1.p2.2.m2.3.3.2.2.2.3">2</cn></apply><ci id="Pt0.A3.SS1.p2.2.m2.1.1.cmml" xref="Pt0.A3.SS1.p2.2.m2.1.1">â€¦</ci><apply id="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3.cmml" xref="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3.1.cmml" xref="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3">subscript</csymbol><apply id="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3.2.cmml" xref="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3.2.1.cmml" xref="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3">superscript</csymbol><ci id="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3.2.2.cmml" xref="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3.2.2">ğ—</ci><apply id="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3.2.3.cmml" xref="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3.2.3"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3.2.3.1.cmml" xref="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3.2.3">superscript</csymbol><ci id="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3.2.3.2.cmml" xref="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3.2.3.2">ğ‘</ci><ci id="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3.2.3.3.cmml" xref="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3.2.3.3">â€²</ci></apply></apply><ci id="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3.3.cmml" xref="Pt0.A3.SS1.p2.2.m2.4.4.3.3.3.3">ğ‘€</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A3.SS1.p2.2.m2.4c">\mathbf{X}^{c}_{\mathrm{cs}}=\{\mathbf{X}^{c^{\prime}}_{1},\mathbf{X}^{c^{%
\prime}}_{2},\dots,\mathbf{X}^{c^{\prime}}_{M}\}</annotation><annotation encoding="application/x-llamapun" id="Pt0.A3.SS1.p2.2.m2.4d">bold_X start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_cs end_POSTSUBSCRIPT = { bold_X start_POSTSUPERSCRIPT italic_c start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , bold_X start_POSTSUPERSCRIPT italic_c start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , â€¦ , bold_X start_POSTSUPERSCRIPT italic_c start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT }</annotation></semantics></math>, where <math alttext="c^{\prime}" class="ltx_Math" display="inline" id="Pt0.A3.SS1.p2.3.m3.1"><semantics id="Pt0.A3.SS1.p2.3.m3.1a"><msup id="Pt0.A3.SS1.p2.3.m3.1.1" xref="Pt0.A3.SS1.p2.3.m3.1.1.cmml"><mi id="Pt0.A3.SS1.p2.3.m3.1.1.2" xref="Pt0.A3.SS1.p2.3.m3.1.1.2.cmml">c</mi><mo id="Pt0.A3.SS1.p2.3.m3.1.1.3" xref="Pt0.A3.SS1.p2.3.m3.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="Pt0.A3.SS1.p2.3.m3.1b"><apply id="Pt0.A3.SS1.p2.3.m3.1.1.cmml" xref="Pt0.A3.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p2.3.m3.1.1.1.cmml" xref="Pt0.A3.SS1.p2.3.m3.1.1">superscript</csymbol><ci id="Pt0.A3.SS1.p2.3.m3.1.1.2.cmml" xref="Pt0.A3.SS1.p2.3.m3.1.1.2">ğ‘</ci><ci id="Pt0.A3.SS1.p2.3.m3.1.1.3.cmml" xref="Pt0.A3.SS1.p2.3.m3.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A3.SS1.p2.3.m3.1c">c^{\prime}</annotation><annotation encoding="application/x-llamapun" id="Pt0.A3.SS1.p2.3.m3.1d">italic_c start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT</annotation></semantics></math> is the shuffled category index.
Therefore, the category labels for point cloud data are different from those for image data in the pre-training step, though the labels in each category are consistent for both images and point clouds.</p>
</div>
<div class="ltx_para" id="Pt0.A3.SS1.p3">
<p class="ltx_p" id="Pt0.A3.SS1.p3.5">The <span class="ltx_text ltx_font_italic" id="Pt0.A3.SS1.p3.5.1">instance + category</span> shuffle randomizes both instance and category indices of point clouds to disrupt the consistency of instances for images and point clouds.
After <span class="ltx_text ltx_font_italic" id="Pt0.A3.SS1.p3.5.2">instance + category</span> shuffle, the instances of point clouds in category <math alttext="c" class="ltx_Math" display="inline" id="Pt0.A3.SS1.p3.1.m1.1"><semantics id="Pt0.A3.SS1.p3.1.m1.1a"><mi id="Pt0.A3.SS1.p3.1.m1.1.1" xref="Pt0.A3.SS1.p3.1.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="Pt0.A3.SS1.p3.1.m1.1b"><ci id="Pt0.A3.SS1.p3.1.m1.1.1.cmml" xref="Pt0.A3.SS1.p3.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A3.SS1.p3.1.m1.1c">c</annotation><annotation encoding="application/x-llamapun" id="Pt0.A3.SS1.p3.1.m1.1d">italic_c</annotation></semantics></math> are denoted as <math alttext="\mathbf{X}^{c}_{\mathrm{ics}}=\{\mathbf{X}^{c^{\prime}_{1}}_{i^{\prime}_{1}},%
\mathbf{X}^{c^{\prime}_{2}}_{i^{\prime}_{2}},\dots,\mathbf{X}^{c^{\prime}_{M}}%
_{i^{\prime}_{M}}\}" class="ltx_Math" display="inline" id="Pt0.A3.SS1.p3.2.m2.4"><semantics id="Pt0.A3.SS1.p3.2.m2.4a"><mrow id="Pt0.A3.SS1.p3.2.m2.4.4" xref="Pt0.A3.SS1.p3.2.m2.4.4.cmml"><msubsup id="Pt0.A3.SS1.p3.2.m2.4.4.5" xref="Pt0.A3.SS1.p3.2.m2.4.4.5.cmml"><mi id="Pt0.A3.SS1.p3.2.m2.4.4.5.2.2" xref="Pt0.A3.SS1.p3.2.m2.4.4.5.2.2.cmml">ğ—</mi><mi id="Pt0.A3.SS1.p3.2.m2.4.4.5.3" xref="Pt0.A3.SS1.p3.2.m2.4.4.5.3.cmml">ics</mi><mi id="Pt0.A3.SS1.p3.2.m2.4.4.5.2.3" xref="Pt0.A3.SS1.p3.2.m2.4.4.5.2.3.cmml">c</mi></msubsup><mo id="Pt0.A3.SS1.p3.2.m2.4.4.4" xref="Pt0.A3.SS1.p3.2.m2.4.4.4.cmml">=</mo><mrow id="Pt0.A3.SS1.p3.2.m2.4.4.3.3" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.4.cmml"><mo id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.4" stretchy="false" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.4.cmml">{</mo><msubsup id="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1" xref="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.cmml"><mi id="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.2.2" xref="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.2.2.cmml">ğ—</mi><msubsup id="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.3" xref="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.3.cmml"><mi id="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.3.2.2" xref="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.3.2.2.cmml">i</mi><mn id="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.3.3" xref="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.3.3.cmml">1</mn><mo id="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.3.2.3" xref="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.3.2.3.cmml">â€²</mo></msubsup><msubsup id="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.2.3" xref="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.2.3.cmml"><mi id="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.2.3.2.2" xref="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.2.3.2.2.cmml">c</mi><mn id="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.2.3.3" xref="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.2.3.3.cmml">1</mn><mo id="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.2.3.2.3" xref="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.2.3.2.3.cmml">â€²</mo></msubsup></msubsup><mo id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.5" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.4.cmml">,</mo><msubsup id="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2" xref="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.cmml"><mi id="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.2.2" xref="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.2.2.cmml">ğ—</mi><msubsup id="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.3" xref="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.3.cmml"><mi id="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.3.2.2" xref="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.3.2.2.cmml">i</mi><mn id="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.3.3" xref="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.3.3.cmml">2</mn><mo id="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.3.2.3" xref="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.3.2.3.cmml">â€²</mo></msubsup><msubsup id="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.2.3" xref="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.2.3.cmml"><mi id="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.2.3.2.2" xref="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.2.3.2.2.cmml">c</mi><mn id="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.2.3.3" xref="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.2.3.3.cmml">2</mn><mo id="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.2.3.2.3" xref="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.2.3.2.3.cmml">â€²</mo></msubsup></msubsup><mo id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.6" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.4.cmml">,</mo><mi id="Pt0.A3.SS1.p3.2.m2.1.1" mathvariant="normal" xref="Pt0.A3.SS1.p3.2.m2.1.1.cmml">â€¦</mi><mo id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.7" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.4.cmml">,</mo><msubsup id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.cmml"><mi id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.2.2" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.2.2.cmml">ğ—</mi><msubsup id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.3" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.3.cmml"><mi id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.3.2.2" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.3.2.2.cmml">i</mi><mi id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.3.3" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.3.3.cmml">M</mi><mo id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.3.2.3" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.3.2.3.cmml">â€²</mo></msubsup><msubsup id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.2.3" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.2.3.cmml"><mi id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.2.3.2.2" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.2.3.2.2.cmml">c</mi><mi id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.2.3.3" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.2.3.3.cmml">M</mi><mo id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.2.3.2.3" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.2.3.2.3.cmml">â€²</mo></msubsup></msubsup><mo id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.8" stretchy="false" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Pt0.A3.SS1.p3.2.m2.4b"><apply id="Pt0.A3.SS1.p3.2.m2.4.4.cmml" xref="Pt0.A3.SS1.p3.2.m2.4.4"><eq id="Pt0.A3.SS1.p3.2.m2.4.4.4.cmml" xref="Pt0.A3.SS1.p3.2.m2.4.4.4"></eq><apply id="Pt0.A3.SS1.p3.2.m2.4.4.5.cmml" xref="Pt0.A3.SS1.p3.2.m2.4.4.5"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p3.2.m2.4.4.5.1.cmml" xref="Pt0.A3.SS1.p3.2.m2.4.4.5">subscript</csymbol><apply id="Pt0.A3.SS1.p3.2.m2.4.4.5.2.cmml" xref="Pt0.A3.SS1.p3.2.m2.4.4.5"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p3.2.m2.4.4.5.2.1.cmml" xref="Pt0.A3.SS1.p3.2.m2.4.4.5">superscript</csymbol><ci id="Pt0.A3.SS1.p3.2.m2.4.4.5.2.2.cmml" xref="Pt0.A3.SS1.p3.2.m2.4.4.5.2.2">ğ—</ci><ci id="Pt0.A3.SS1.p3.2.m2.4.4.5.2.3.cmml" xref="Pt0.A3.SS1.p3.2.m2.4.4.5.2.3">ğ‘</ci></apply><ci id="Pt0.A3.SS1.p3.2.m2.4.4.5.3.cmml" xref="Pt0.A3.SS1.p3.2.m2.4.4.5.3">ics</ci></apply><set id="Pt0.A3.SS1.p3.2.m2.4.4.3.4.cmml" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3"><apply id="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.cmml" xref="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.1.cmml" xref="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1">subscript</csymbol><apply id="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.2.cmml" xref="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.2.1.cmml" xref="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1">superscript</csymbol><ci id="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.2.2.cmml" xref="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.2.2">ğ—</ci><apply id="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.2.3.cmml" xref="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.2.3"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.2.3.1.cmml" xref="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.2.3">subscript</csymbol><apply id="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.2.3.2.cmml" xref="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.2.3"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.2.3.2.1.cmml" xref="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.2.3">superscript</csymbol><ci id="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.2.3.2.2.cmml" xref="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.2.3.2.2">ğ‘</ci><ci id="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.2.3.2.3.cmml" xref="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.2.3.2.3">â€²</ci></apply><cn id="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.2.3.3.cmml" type="integer" xref="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.2.3.3">1</cn></apply></apply><apply id="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.3.cmml" xref="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.3"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.3.1.cmml" xref="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.3">subscript</csymbol><apply id="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.3.2.cmml" xref="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.3"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.3.2.1.cmml" xref="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.3">superscript</csymbol><ci id="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.3.2.2.cmml" xref="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.3.2.2">ğ‘–</ci><ci id="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.3.2.3.cmml" xref="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.3.2.3">â€²</ci></apply><cn id="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.3.3.cmml" type="integer" xref="Pt0.A3.SS1.p3.2.m2.2.2.1.1.1.3.3">1</cn></apply></apply><apply id="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.cmml" xref="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.1.cmml" xref="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2">subscript</csymbol><apply id="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.2.cmml" xref="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.2.1.cmml" xref="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2">superscript</csymbol><ci id="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.2.2.cmml" xref="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.2.2">ğ—</ci><apply id="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.2.3.cmml" xref="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.2.3"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.2.3.1.cmml" xref="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.2.3">subscript</csymbol><apply id="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.2.3.2.cmml" xref="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.2.3"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.2.3.2.1.cmml" xref="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.2.3">superscript</csymbol><ci id="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.2.3.2.2.cmml" xref="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.2.3.2.2">ğ‘</ci><ci id="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.2.3.2.3.cmml" xref="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.2.3.2.3">â€²</ci></apply><cn id="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.2.3.3.cmml" type="integer" xref="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.2.3.3">2</cn></apply></apply><apply id="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.3.cmml" xref="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.3"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.3.1.cmml" xref="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.3">subscript</csymbol><apply id="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.3.2.cmml" xref="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.3"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.3.2.1.cmml" xref="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.3">superscript</csymbol><ci id="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.3.2.2.cmml" xref="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.3.2.2">ğ‘–</ci><ci id="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.3.2.3.cmml" xref="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.3.2.3">â€²</ci></apply><cn id="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.3.3.cmml" type="integer" xref="Pt0.A3.SS1.p3.2.m2.3.3.2.2.2.3.3">2</cn></apply></apply><ci id="Pt0.A3.SS1.p3.2.m2.1.1.cmml" xref="Pt0.A3.SS1.p3.2.m2.1.1">â€¦</ci><apply id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.cmml" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.1.cmml" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3">subscript</csymbol><apply id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.2.cmml" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.2.1.cmml" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3">superscript</csymbol><ci id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.2.2.cmml" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.2.2">ğ—</ci><apply id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.2.3.cmml" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.2.3"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.2.3.1.cmml" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.2.3">subscript</csymbol><apply id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.2.3.2.cmml" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.2.3"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.2.3.2.1.cmml" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.2.3">superscript</csymbol><ci id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.2.3.2.2.cmml" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.2.3.2.2">ğ‘</ci><ci id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.2.3.2.3.cmml" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.2.3.2.3">â€²</ci></apply><ci id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.2.3.3.cmml" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.2.3.3">ğ‘€</ci></apply></apply><apply id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.3.cmml" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.3"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.3.1.cmml" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.3">subscript</csymbol><apply id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.3.2.cmml" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.3"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.3.2.1.cmml" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.3">superscript</csymbol><ci id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.3.2.2.cmml" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.3.2.2">ğ‘–</ci><ci id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.3.2.3.cmml" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.3.2.3">â€²</ci></apply><ci id="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.3.3.cmml" xref="Pt0.A3.SS1.p3.2.m2.4.4.3.3.3.3.3">ğ‘€</ci></apply></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A3.SS1.p3.2.m2.4c">\mathbf{X}^{c}_{\mathrm{ics}}=\{\mathbf{X}^{c^{\prime}_{1}}_{i^{\prime}_{1}},%
\mathbf{X}^{c^{\prime}_{2}}_{i^{\prime}_{2}},\dots,\mathbf{X}^{c^{\prime}_{M}}%
_{i^{\prime}_{M}}\}</annotation><annotation encoding="application/x-llamapun" id="Pt0.A3.SS1.p3.2.m2.4d">bold_X start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_ics end_POSTSUBSCRIPT = { bold_X start_POSTSUPERSCRIPT italic_c start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , bold_X start_POSTSUPERSCRIPT italic_c start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , â€¦ , bold_X start_POSTSUPERSCRIPT italic_c start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT end_POSTSUBSCRIPT }</annotation></semantics></math>, where <math alttext="c^{\prime}_{j}" class="ltx_Math" display="inline" id="Pt0.A3.SS1.p3.3.m3.1"><semantics id="Pt0.A3.SS1.p3.3.m3.1a"><msubsup id="Pt0.A3.SS1.p3.3.m3.1.1" xref="Pt0.A3.SS1.p3.3.m3.1.1.cmml"><mi id="Pt0.A3.SS1.p3.3.m3.1.1.2.2" xref="Pt0.A3.SS1.p3.3.m3.1.1.2.2.cmml">c</mi><mi id="Pt0.A3.SS1.p3.3.m3.1.1.3" xref="Pt0.A3.SS1.p3.3.m3.1.1.3.cmml">j</mi><mo id="Pt0.A3.SS1.p3.3.m3.1.1.2.3" xref="Pt0.A3.SS1.p3.3.m3.1.1.2.3.cmml">â€²</mo></msubsup><annotation-xml encoding="MathML-Content" id="Pt0.A3.SS1.p3.3.m3.1b"><apply id="Pt0.A3.SS1.p3.3.m3.1.1.cmml" xref="Pt0.A3.SS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p3.3.m3.1.1.1.cmml" xref="Pt0.A3.SS1.p3.3.m3.1.1">subscript</csymbol><apply id="Pt0.A3.SS1.p3.3.m3.1.1.2.cmml" xref="Pt0.A3.SS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p3.3.m3.1.1.2.1.cmml" xref="Pt0.A3.SS1.p3.3.m3.1.1">superscript</csymbol><ci id="Pt0.A3.SS1.p3.3.m3.1.1.2.2.cmml" xref="Pt0.A3.SS1.p3.3.m3.1.1.2.2">ğ‘</ci><ci id="Pt0.A3.SS1.p3.3.m3.1.1.2.3.cmml" xref="Pt0.A3.SS1.p3.3.m3.1.1.2.3">â€²</ci></apply><ci id="Pt0.A3.SS1.p3.3.m3.1.1.3.cmml" xref="Pt0.A3.SS1.p3.3.m3.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A3.SS1.p3.3.m3.1c">c^{\prime}_{j}</annotation><annotation encoding="application/x-llamapun" id="Pt0.A3.SS1.p3.3.m3.1d">italic_c start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="i^{\prime}_{j}" class="ltx_Math" display="inline" id="Pt0.A3.SS1.p3.4.m4.1"><semantics id="Pt0.A3.SS1.p3.4.m4.1a"><msubsup id="Pt0.A3.SS1.p3.4.m4.1.1" xref="Pt0.A3.SS1.p3.4.m4.1.1.cmml"><mi id="Pt0.A3.SS1.p3.4.m4.1.1.2.2" xref="Pt0.A3.SS1.p3.4.m4.1.1.2.2.cmml">i</mi><mi id="Pt0.A3.SS1.p3.4.m4.1.1.3" xref="Pt0.A3.SS1.p3.4.m4.1.1.3.cmml">j</mi><mo id="Pt0.A3.SS1.p3.4.m4.1.1.2.3" xref="Pt0.A3.SS1.p3.4.m4.1.1.2.3.cmml">â€²</mo></msubsup><annotation-xml encoding="MathML-Content" id="Pt0.A3.SS1.p3.4.m4.1b"><apply id="Pt0.A3.SS1.p3.4.m4.1.1.cmml" xref="Pt0.A3.SS1.p3.4.m4.1.1"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p3.4.m4.1.1.1.cmml" xref="Pt0.A3.SS1.p3.4.m4.1.1">subscript</csymbol><apply id="Pt0.A3.SS1.p3.4.m4.1.1.2.cmml" xref="Pt0.A3.SS1.p3.4.m4.1.1"><csymbol cd="ambiguous" id="Pt0.A3.SS1.p3.4.m4.1.1.2.1.cmml" xref="Pt0.A3.SS1.p3.4.m4.1.1">superscript</csymbol><ci id="Pt0.A3.SS1.p3.4.m4.1.1.2.2.cmml" xref="Pt0.A3.SS1.p3.4.m4.1.1.2.2">ğ‘–</ci><ci id="Pt0.A3.SS1.p3.4.m4.1.1.2.3.cmml" xref="Pt0.A3.SS1.p3.4.m4.1.1.2.3">â€²</ci></apply><ci id="Pt0.A3.SS1.p3.4.m4.1.1.3.cmml" xref="Pt0.A3.SS1.p3.4.m4.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A3.SS1.p3.4.m4.1c">i^{\prime}_{j}</annotation><annotation encoding="application/x-llamapun" id="Pt0.A3.SS1.p3.4.m4.1d">italic_i start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> are the shuffled category and instance indices for the <math alttext="j" class="ltx_Math" display="inline" id="Pt0.A3.SS1.p3.5.m5.1"><semantics id="Pt0.A3.SS1.p3.5.m5.1a"><mi id="Pt0.A3.SS1.p3.5.m5.1.1" xref="Pt0.A3.SS1.p3.5.m5.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="Pt0.A3.SS1.p3.5.m5.1b"><ci id="Pt0.A3.SS1.p3.5.m5.1.1.cmml" xref="Pt0.A3.SS1.p3.5.m5.1.1">ğ‘—</ci></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A3.SS1.p3.5.m5.1c">j</annotation><annotation encoding="application/x-llamapun" id="Pt0.A3.SS1.p3.5.m5.1d">italic_j</annotation></semantics></math>-th instance, respectively.
Therefore, even the labels in each category are not consistent in point clouds.
Note that the shuffling methods exclusively randomize the labels for point cloud data to disrupt the consistency between image and point cloud data.
In other words, the labels associated with image data remain unaffected by the shuffling.</p>
</div>
<div class="ltx_para" id="Pt0.A3.SS1.p4">
<p class="ltx_p" id="Pt0.A3.SS1.p4.1">TableÂ <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:train_data</span> shows that FSVGP without shuffling was more effective than <span class="ltx_text ltx_font_italic" id="Pt0.A3.SS1.p4.1.1">category shuffle</span> and <span class="ltx_text ltx_font_italic" id="Pt0.A3.SS1.p4.1.2">instance + category</span> shuffle in CIFAR100 and ModelNet40.
This result shows that the formula-supervised consistency labels used in FSVGP improve the performance of pre-training.
The pre-training using the data shuffled by <span class="ltx_text ltx_font_italic" id="Pt0.A3.SS1.p4.1.3">instance + category</span> still achieved reasonable results.
We believe pre-training on such data optimizes the model towards near-optimal parameters based on consistent image data, even though the shuffled point cloud data may impede convergence.
To validate the hypothesis, we examined the loss values both with and without the shuffling.
The values for image data were similar (2.45 vs 2.48), whereas the values for point cloud data differed significantly (6.90 vs 1.02).
In addition, the shuffling of both visual and geometric modalities disrupted the pre-training, causing a divergence in the loss values.</p>
</div>
</section>
<section class="ltx_subsection" id="Pt0.A3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.2 </span>Does the standard cross-entropy loss function alone suffice for pre-training in FSVGP?</h3>
<div class="ltx_para" id="Pt0.A3.SS2.p1">
<p class="ltx_p" id="Pt0.A3.SS2.p1.1">We contrast two scenarios: one employing CE loss based on the formula-supervised consistency label and another employing cross-entropy loss with a constraint term derived from visual-geometric correspondence (VGC).
We developed VGC as consistency labels, representing whether the pair of images and point cloud represent the same instance.
We shuffle the point cloud data instances in each category to generate a non-consistent pair. In each epoch of pre-training, we utilize both non-shuffled and shuffled data equally, randomly splitting the dataset in half.
VGC calculates the loss values using cross-entropy loss with consistency labels.
TableÂ <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:effect_of_loss</span> shows that FSVGP with only CE loss is better than the fine-tuning accuracy with VGC + CE loss.
This result finds that FSVGP learns visual-geometric representation with only CE loss rather than explicit visual-geometric correspondence terms such as VGC.</p>
</div>
</section>
<section class="ltx_subsection" id="Pt0.A3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.3 </span>Evaluation of the performance of pre-training models by linear probing</h3>
<div class="ltx_para" id="Pt0.A3.SS3.p1">
<p class="ltx_p" id="Pt0.A3.SS3.p1.1">Our experiment of this paper basically followed the evaluation protocols of previous FDSL studies. However, we believe that it is important to know about the feature representation that the pre-trained models learn through linear probing.
Therefore, we investigate the feature representations learned by FSVGP (VG-FractalDB-1k) and MAE (ImageNet). Specifically, we stop the gradient update of some transformer blocks in ViT during fine-tuning and evaluate which transformer block feature representations in ViT contribute to fine-tuning.</p>
</div>
<figure class="ltx_figure" id="Pt0.A3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="483" id="Pt0.A3.F3.g1" src="x6.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="Pt0.A3.F3.2.1.1" style="font-size:90%;">Figure C</span>: </span><span class="ltx_text" id="Pt0.A3.F3.3.2" style="font-size:90%;">Comparison of classification accuracy when parameter update of each transformer block is frozen during fine-tuning of SVGP (VG-FractalDB-1k) and MAE (ImageNet). We use ViT-B on ImageNet100. </span></figcaption>
</figure>
<div class="ltx_para" id="Pt0.A3.SS3.p2">
<p class="ltx_p" id="Pt0.A3.SS3.p2.1">We froze the first <span class="ltx_text ltx_font_italic" id="Pt0.A3.SS3.p2.1.1">m</span> blocks of ViT-B during the fine-tuning (<span class="ltx_text ltx_font_italic" id="Pt0.A3.SS3.p2.1.2">m</span> = 0 and 12 indicate full fine-tuning and linear probing, respectively).
As shown in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#Pt0.A3.F3" title="Figure C â€£ C.3 Evaluation of the performance of pre-training models by linear probing â€£ Appendix C Additional experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">C</span></a>, although the difference in data domain between real images and fractal data degenerates the performance of FSVGP in linear probing, the fine-tuning from pre-trained representations significantly improves the performance. This result indicates the meaningful representation learned from FSVGP, especially in early layers.</p>
</div>
</section>
<section class="ltx_subsection" id="Pt0.A3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.4 </span>Multi-modal evaluations in 3D object classification</h3>
<div class="ltx_para" id="Pt0.A3.SS4.p1">
<p class="ltx_p" id="Pt0.A3.SS4.p1.1">We consider multi-modal evaluation important for showing the use case of FSVGP. Therefore, We conducted an initial experiment of 3D object classification using images and point clouds on ModelNet40. We confirmed that VG-FractalDB (V + G) outperforms VG-FractalDB (V or G) by +0.2 points and +0.6 points, respectively, when fine-tuning images and point clouds on ModelNet40. This result suggests the potential applications of FSVGP, such as autonomous driving with point clouds and birdâ€™s-eye view images.</p>
</div>
<figure class="ltx_figure" id="Pt0.A3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="356" id="Pt0.A3.F4.g1" src="x7.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="Pt0.A3.F4.3.1.1" style="font-size:90%;">Figure D</span>: </span><span class="ltx_text ltx_font_bold" id="Pt0.A3.F4.4.2" style="font-size:90%;">FSVGP Success Cases:<span class="ltx_text ltx_font_medium" id="Pt0.A3.F4.4.2.1"> compare ground truth with training from scratch, MAE, VisualAtom, and FSVGP output results.
We use VitDet (ViT-B) on MS COCO 2017 Val. </span></span></figcaption>
</figure>
</section>
</section>
<section class="ltx_appendix" id="Pt0.A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Qualitative examples</h2>
<div class="ltx_para" id="Pt0.A4.p1">
<p class="ltx_p" id="Pt0.A4.p1.1">The visualized predictions of the MS COCO underscore the ability of our FSVGP model to identify and delineate objects with high accuracy in complex scenes. FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#Pt0.A3.F4" title="Figure D â€£ C.4 Multi-modal evaluations in 3D object classification â€£ Appendix C Additional experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">D</span></a> demonstrates the FSVGPâ€™s accuracy in pinpointing object locations and discriminating between overlapping entities in detail-rich images.
For example, in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13535v1#Pt0.A3.F4" title="Figure D â€£ C.4 Multi-modal evaluations in 3D object classification â€£ Appendix C Additional experiments â€£ Formula-Supervised Visual-Geometric Pre-training"><span class="ltx_text ltx_ref_tag">D</span></a>, one can observe the FSVGPâ€™s acute precision in detecting and separating a cluster of beans on a plate, demonstrating its ability to locate and distinguish even the smallest objects. In addition, the figure highlights the modelâ€™s ability to detect overlapping objects, such as a book partially obscured by a houseplant, demonstrating the nuanced recognition capabilities of FSVGP across a wide range of object categories.</p>
<div class="ltx_pagination ltx_role_newpage"></div>
</div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Fri Sep 20 14:19:04 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
