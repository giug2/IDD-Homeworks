<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering</title>
<!--Generated on Thu Aug 15 22:30:55 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Retrieval Augmented Generation,  Open-domain Question Answering,  Weak Supervised Learning,  Dense Retrieval" lang="en" name="keywords"/>
<base href="/html/2408.08444v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S1" title="In W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S2" title="In W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S2.SS1" title="In 2. Related Work ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Dense Retrieval</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S2.SS2" title="In 2. Related Work ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>RAG for OpenQA</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S2.SS3" title="In 2. Related Work ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>LLMs for Ranking</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S3" title="In W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S3.SS1" title="In 3. Method ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Weak-label Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S3.SS2" title="In 3. Method ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Training Dense Retriever</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S3.SS2.SSS1" title="In 3.2. Training Dense Retriever ‣ 3. Method ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.1 </span><span class="ltx_text ltx_font_bold">DPR</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S3.SS2.SSS2" title="In 3.2. Training Dense Retriever ‣ 3. Method ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.2 </span><span class="ltx_text ltx_font_bold">ColBERT</span></span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S4" title="In W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S4.SS1" title="In 4. Experiments ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Task and Datasets</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S4.SS1.SSS1" title="In 4.1. Task and Datasets ‣ 4. Experiments ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.1 </span><span class="ltx_text ltx_font_bold">Weak Label Quality</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S4.SS1.SSS2" title="In 4.1. Task and Datasets ‣ 4. Experiments ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.2 </span><span class="ltx_text ltx_font_bold">Weakly Trained Retriever</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S4.SS1.SSS3" title="In 4.1. Task and Datasets ‣ 4. Experiments ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.3 </span><span class="ltx_text ltx_font_bold">OpenQA Performance</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S4.SS2" title="In 4. Experiments ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Baselines</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S4.SS3" title="In 4. Experiments ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Experimental Settings</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S4.SS4" title="In 4. Experiments ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Evaluation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S5" title="In W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experimental Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S5.SS1" title="In 5. Experimental Results ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Main Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S5.SS2" title="In 5. Experimental Results ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Retrieval Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S5.SS3" title="In 5. Experimental Results ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>W-RAG Labels</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S5.SS4" title="In 5. Experimental Results ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Ablation Study</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S6" title="In W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusions and Future Work</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jinming Nian
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id2.1.id1">Santa Clara University</span><span class="ltx_text ltx_affiliation_city" id="id3.2.id2">Santa Clara</span><span class="ltx_text ltx_affiliation_state" id="id4.3.id3">CA</span><span class="ltx_text ltx_affiliation_country" id="id5.4.id4">USA</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:jnian@scu.edu">jnian@scu.edu</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zhiyuan Peng
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id6.1.id1">Santa Clara University</span><span class="ltx_text ltx_affiliation_city" id="id7.2.id2">Santa Clara</span><span class="ltx_text ltx_affiliation_state" id="id8.3.id3">CA</span><span class="ltx_text ltx_affiliation_country" id="id9.4.id4">USA</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:zpeng@scu.edu">zpeng@scu.edu</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Qifan Wang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id10.1.id1">Meta AI</span><span class="ltx_text ltx_affiliation_city" id="id11.2.id2">Menlo Park</span><span class="ltx_text ltx_affiliation_state" id="id12.3.id3">CA</span><span class="ltx_text ltx_affiliation_country" id="id13.4.id4">USA</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:wqfcr@meta.com">wqfcr@meta.com</a>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yi Fang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id14.1.id1">Santa Clara University</span><span class="ltx_text ltx_affiliation_city" id="id15.2.id2">Santa Clara</span><span class="ltx_text ltx_affiliation_state" id="id16.3.id3">CA</span><span class="ltx_text ltx_affiliation_country" id="id17.4.id4">USA</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:yfang@scu.edu">yfang@scu.edu</a>
</span></span></span>
</div>
<div class="ltx_dates">(2018)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id1.1">In knowledge-intensive tasks such as open-domain question answering (OpenQA), Large Language Models (LLMs) often struggle to generate factual answers relying solely on their internal (parametric) knowledge. To address this limitation, Retrieval-Augmented Generation (RAG) systems enhance LLMs by retrieving relevant information from external sources, thereby positioning the retriever as a pivotal component. Although dense retrieval demonstrates state-of-the-art performance, its training poses challenges due to the scarcity of ground-truth evidence, largely attributed to the high costs of human annotation. In this paper, we propose W-RAG by utilizing the ranking capabilities of LLMs to create weakly labeled data for training dense retrievers. Specifically, we rerank the top-<math alttext="K" class="ltx_Math" display="inline" id="id1.1.m1.1"><semantics id="id1.1.m1.1a"><mi id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><ci id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.1d">italic_K</annotation></semantics></math> passages retrieved via BM25 by assessing the probability that LLMs will generate the correct answer based on the question and each passage. The highest-ranking passages are then used as positive training examples for dense retrieval. Our comprehensive experiments across four publicly available OpenQA datasets demonstrate that our approach enhances both retrieval and OpenQA performance compared to baseline models. Source code is published <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/jmnian/weak_label_for_rag" title="">https://github.com/jmnian/weak_label_for_rag</a></span></span></span>.</p>
</div>
<div class="ltx_keywords">Retrieval Augmented Generation, Open-domain Question Answering, Weak Supervised Learning, Dense Retrieval
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmlicensed</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2018</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id3"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>XXXXXXX.XXXXXXX</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id4"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>Make sure to enter the correct
conference title from your rights confirmation emai; June 03–05,
2018; Woodstock, NY</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_isbn" id="id5"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>978-1-4503-XXXX-X/18/06</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Open-domain question answering (OpenQA) dating back to the 1960s <cite class="ltx_cite ltx_citemacro_citep">(Jr. et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib19" title="">1961</a>)</cite> provides natural language-like answers to reply users’ questions. OpenQA adopts the “Retriever-Reader” architecture <cite class="ltx_cite ltx_citemacro_citep">(Zhu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib56" title="">2021</a>)</cite>, where the retriever retrieves relevant passages for the reader to generate answers. Previous studies <cite class="ltx_cite ltx_citemacro_citep">(Lewis et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib28" title="">2020</a>; Xiong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib53" title="">2020a</a>)</cite> adopt a seq2seq model as a reader and train it on the labeled dataset. Recently, large language models (LLMs) like GPT-4 <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib34" title="">2023</a>)</cite> and LLaMA <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib47" title="">2023</a>)</cite> have demonstrated astonishing performance on various tasks, including OpenQA, attributing to the substantial amount of knowledge stored in their internal parameters. Despite the unprecedented achievements of LLMs, they face constraints such as the inability to consistently integrate up-to-date knowledge, as their parametric knowledge is fixed after being trained on huge datasets. Additionally, they are prone to generating plausible but non-factual responses, known as hallucinations <cite class="ltx_cite ltx_citemacro_citep">(Welleck et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib50" title="">2020</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">To overcome the limitations of LLMs’ parametric knowledge, retrieval augmented generation (RAG) <cite class="ltx_cite ltx_citemacro_citep">(Lewis et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib28" title="">2020</a>; Guu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib12" title="">2020</a>)</cite> is explored, equipping LLMs with a retriever to gather necessary evidence from external sources. Among the two components of RAG, improving the retriever is more feasible due to the recent trend of black-box APIs <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib34" title="">2023</a>)</cite> and the high cost and time requirements of fine-tuning open-source LLMs <cite class="ltx_cite ltx_citemacro_citep">(Dubey et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib11" title="">2024</a>)</cite>.
The retriever, a critical part of RAG, is typically either a traditional unsupervised retriever like BM25 <cite class="ltx_cite ltx_citemacro_citep">(Robertson and Zaragoza, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib39" title="">2009</a>)</cite> or a more advanced neural retriever, such as dense retrieval <cite class="ltx_cite ltx_citemacro_citep">(Nogueira et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib33" title="">2020</a>; Xiong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib52" title="">2020b</a>; Khattab and Zaharia, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib22" title="">2020a</a>; Karpukhin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib21" title="">2020b</a>)</cite>, which encodes questions and passages into the same embedding space and then measures the question-passage relevance score by vector similarity. A key challenge in training dense retrievers is the scarcity of human-annotated data, as in OpenQA, human-labeled evidence passages are often unavailable. Methods like UPR <cite class="ltx_cite ltx_citemacro_citep">(Sachan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib40" title="">2022a</a>)</cite>, which ranks passages based on the likelihood of LLMs generating the question given the passage, and AAR <cite class="ltx_cite ltx_citemacro_citep">(Yu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib55" title="">2023</a>)</cite>, which combines the top-<math alttext="K" class="ltx_Math" display="inline" id="S1.p2.1.m1.1"><semantics id="S1.p2.1.m1.1a"><mi id="S1.p2.1.m1.1.1" xref="S1.p2.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S1.p2.1.m1.1b"><ci id="S1.p2.1.m1.1.1.cmml" xref="S1.p2.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S1.p2.1.m1.1d">italic_K</annotation></semantics></math> passages ranked by the LLM’s averaged cross-attention scores with ground-truth passages as positive passages, have been employed to train dense retrievers. These approaches can train retrievers to find semantically relevant passages but do not guarantee improved RAG performance in OpenQA. As <cite class="ltx_cite ltx_citemacro_citet">Cuconasu et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib7" title="">2024</a>)</cite> demonstrated, retrieving relevant passages that cannot answer the question may negatively impact RAG performance in OpenQA tasks. Neither cross-attention scores nor the likelihood of LLMs generating the question based on the input passage explicitly ensures that the question can be answered by the “positive” passage.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">To address the scarcity of training data for dense retrievers in RAG for OpenQA, we propose extracting weak labels from existing OpenQA question-answer pairs by leveraging the ranking capabilities of LLMs <cite class="ltx_cite ltx_citemacro_citep">(Sun et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib46" title="">2023</a>)</cite>. Specifically, we first use BM25 to retrieve the top-<math alttext="K" class="ltx_Math" display="inline" id="S1.p3.1.m1.1"><semantics id="S1.p3.1.m1.1a"><mi id="S1.p3.1.m1.1.1" xref="S1.p3.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S1.p3.1.m1.1b"><ci id="S1.p3.1.m1.1.1.cmml" xref="S1.p3.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S1.p3.1.m1.1d">italic_K</annotation></semantics></math> passages for a question, then pair each passage with the question. We rank the passages based on the likelihood that the LLM would generate the question’s ground-truth answer from each question-passage pair. Only the top-ranked passage is selected as the positive example for the question, and we train the dense retrievers using in-batch negative sampling. Our method evaluates the relevance of the question-passage pair by the likelihood of the answer given a passage and the question, making it particularly suitable for OpenQA, where retrieved passages must be capable of providing the correct answer.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">We conducted comprehensive experiments across four publicly available OpenQA datasets, and the results demonstrate that our approach
enhances both retrieval and OpenQA performances compared to baseline models. Our contributions can be summarized as:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We propose W-RAG, a general framework to generate weak labels from question-answer pairs for training dense retrievers in RAG.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">Comprehensive experiments were conducted, and the results prove that W-RAG improves both retrieval and OpenQA performance over baselines.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">Open source LLMs were used, and the code was released anonymously to ensure reproducibility.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related Work</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Dense Retrieval</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Traditional information retrieval (IR) method are based on exact term matching, like BM25. While it is still widely used due to its efficiency, effectiveness, and robustness, it suffers from the well-known issue of lexical gap <cite class="ltx_cite ltx_citemacro_citep">(Berger et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib4" title="">2000</a>)</cite>. To address this, leveraging the neural networks, dense retrieval (DR) employs pre-trained language models like BERT <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib8" title="">2019</a>)</cite>, to encode questions and passages into embeddings, and measures the question-passage relevance score by the vector similarly in the embedding space. Specifically, DP encodes the whole corpus into embeddings and builds the index, such as Faiss <cite class="ltx_cite ltx_citemacro_citep">(Douze et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib9" title="">2024</a>)</cite>, on them. When a new question comes in, DR encodes the question into an embedding and performs a nearest neighbor search. DR can be classified into two categories: supervised, like DPR <cite class="ltx_cite ltx_citemacro_citep">(Karpukhin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib21" title="">2020b</a>)</cite>, TAS-B <cite class="ltx_cite ltx_citemacro_citep">(Hofstätter et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib14" title="">2021</a>)</cite>, and ColBERT <cite class="ltx_cite ltx_citemacro_citep">(Khattab and Zaharia, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib22" title="">2020a</a>; Santhanam et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib42" title="">2022</a>)</cite>; unsupervised, like Contriever<cite class="ltx_cite ltx_citemacro_citep">(Izacard et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib16" title="">2022</a>)</cite> and ReContriever<cite class="ltx_cite ltx_citemacro_citep">(Lei et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib26" title="">2023a</a>)</cite>, based on the training method.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">DPR utilizes a dual-tower architecture, with one BERT model dedicated to encode questions and another to encode passages. The similarity between the question and passage embeddings is then calculated, aiming to maximize the log-likelihood of the positive passage. ColBERT uses the same BERT model for both the question and passage encoders, differentiating them by appending a unique special token after the <span class="ltx_text ltx_font_typewriter" id="S2.SS1.p2.1.1">[CLS]</span> token. Unlike DPR, which directly compares question and passage embeddings, ColBERT introduces a late interaction mechanism. It computes the similarity between each question token and all passage tokens, followed by maximum pooling over these similarities. The final similarity score for a question-passage pair is the sum of the pooled scores. TAS-B groups queries based on their embedding similarities and applies a training data sampling technique along with dual-teacher supervision distillation. Contriever trains a bi-encoder model using contrastive learning, generating positive question-passage pairs from an unlabeled corpus. ReContriever follows the same approach as Contriever for generating weak question-passage pairs but adds a self-scoring mechanism during training, where the loss is weighted by these scores.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>RAG for OpenQA</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">RAG models have been applied to OpenQA, demonstrating significant performance improvement. Different RAG models have been proposed to solve the critical issues in OpenQA, such as how to retrieve relevant passages <cite class="ltx_cite ltx_citemacro_citep">(Yu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib55" title="">2023</a>; Shi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib45" title="">2023</a>; Shao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib43" title="">2023</a>; Trivedi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib48" title="">2023</a>)</cite>, when to call the retriever <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib18" title="">2023b</a>; Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib49" title="">2023</a>; Cheng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib5" title="">2024</a>)</cite>, and how to decrease the computational complexity <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib29" title="">2023</a>; Jiang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib17" title="">2023a</a>; Xu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib54" title="">2024</a>; Kim et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib24" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">Since the retriever is a critical component in RAG, some studies have tried to improve the quality of retrieved passages, including training a better retriever <cite class="ltx_cite ltx_citemacro_citep">(Yu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib55" title="">2023</a>; Shi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib45" title="">2023</a>)</cite> and prompt engineering <cite class="ltx_cite ltx_citemacro_citep">(Shao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib43" title="">2023</a>; Trivedi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib48" title="">2023</a>)</cite>. REPLUG <cite class="ltx_cite ltx_citemacro_citep">(Shi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib45" title="">2023</a>)</cite> trains a dense retriever by minimizing the KL divergence between the retrieval likelihood and the language model likelihood computed as the normalized language model probability of the ground-truth, given the question and passage. AAR <cite class="ltx_cite ltx_citemacro_citep">(Yu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib55" title="">2023</a>)</cite> combines the top-<math alttext="K" class="ltx_Math" display="inline" id="S2.SS2.p2.1.m1.1"><semantics id="S2.SS2.p2.1.m1.1a"><mi id="S2.SS2.p2.1.m1.1.1" xref="S2.SS2.p2.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.1.m1.1b"><ci id="S2.SS2.p2.1.m1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.1.m1.1d">italic_K</annotation></semantics></math> passages ranked by the LLM’s averaged corss-attention scores with ground-truth passages as positive passages and then follow ANCE <cite class="ltx_cite ltx_citemacro_citep">(Xiong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib51" title="">2021</a>)</cite> to sample negative passages to train the dense retriever. ITER-RETGEN <cite class="ltx_cite ltx_citemacro_citep">(Shao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib43" title="">2023</a>)</cite> leverages the model output from the previous iteration as a specific context to help retrieve more relevant knowledge. IRCoT <cite class="ltx_cite ltx_citemacro_citep">(Trivedi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib48" title="">2023</a>)</cite> also adopt a similar approach to perform retrieval, but applies CoT for generating responses.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">In some cases, LLMs can generate factual content well without external knowledge, and retrieving passages will decrease RAG’s performance. Self-RAG <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib49" title="">2023</a>)</cite> and FLARE <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib18" title="">2023b</a>)</cite> both fine-tune the LLMs to call the search engine automatically when external knowledge is needed. UAR <cite class="ltx_cite ltx_citemacro_citep">(Cheng et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib5" title="">2024</a>)</cite> trains classifiers to identify the need for external knowledge.</p>
</div>
<div class="ltx_para" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.1">Applying all the top-<math alttext="K" class="ltx_Math" display="inline" id="S2.SS2.p4.1.m1.1"><semantics id="S2.SS2.p4.1.m1.1a"><mi id="S2.SS2.p4.1.m1.1.1" xref="S2.SS2.p4.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p4.1.m1.1b"><ci id="S2.SS2.p4.1.m1.1.1.cmml" xref="S2.SS2.p4.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p4.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p4.1.m1.1d">italic_K</annotation></semantics></math> retrieved passages as context not only increases the computational complexity and inference latency but also brings noise. Numerous methods have been proposed to compress the retrieved passages. Selective-Context <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib29" title="">2023</a>)</cite> filters non-essential lexical units by the summarization of self-information of each token contained in the unit. LongLLMLingua <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib17" title="">2023a</a>)</cite> contrasts the perplexity score of each token in the passage with the perplexity score of the same token conditioned on the question and adopts this conservative perplexity score to filter out tokens. RECOMP <cite class="ltx_cite ltx_citemacro_citep">(Xu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib54" title="">2024</a>)</cite> leverages the summarization models to summarize the retrieved passages. SuRe <cite class="ltx_cite ltx_citemacro_citep">(Kim et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib24" title="">2024</a>)</cite> summarizes retrieved passages conditioned on each answer candidates generated by prompting the LLMs and then selects the top summarizations ranked by LLMs through a combination of pointwise and pairwise scoring method.</p>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="484" id="S2.F1.g1" src="x1.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F1.2.1.1" style="font-size:90%;">Figure 1</span>. </span><span class="ltx_text" id="S2.F1.3.2" style="font-size:90%;">W-RAG fits into the general RAG pipeline by training the retriever with LLM generated weak labels. Following the steps from top to bottom, we retrieve candidate passages using BM25, present each passage to the LLM to rerank based on the answer likelihood, then use the reranked top passage to train the retriever to finally enhance LLM’s response quality through the standard RAG pipeline. The entire prompt is shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S3.F2" title="Figure 2 ‣ 3. Method ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_tag">2</span></a>.</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>LLMs for Ranking</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">Concerning the generation of weakly labeled ranking data using LLMs as passage rankers, existing work can be categorized into three categories. The first involves a zero-shot listwise ranking strategy, where a prompt containing the question, instructions, and multiple passages are given to the LLM, and the LLM generates a permutation of ranked indices <cite class="ltx_cite ltx_citemacro_citep">(Baldelli et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib2" title="">2024</a>; Ma et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib31" title="">2023</a>; Pradeep et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib36" title="">2023</a>; Shen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib44" title="">2023</a>)</cite>. The second category prompts the LLM with passages and directly instructs it to rate their relevance <cite class="ltx_cite ltx_citemacro_citep">(Zhuang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib57" title="">2024</a>)</cite>, or perform pairwise comparisons <cite class="ltx_cite ltx_citemacro_citep">(Qin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib37" title="">2023</a>)</cite>. The third approach calculates the question generation likelihood when a passage is included in the prompt <cite class="ltx_cite ltx_citemacro_citep">(Cho et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib6" title="">2023</a>; Sachan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib41" title="">2022b</a>; Zhuang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib58" title="">2023</a>)</cite>. Our method for scoring passages aligns with this third approach; however, as mentioned in Section <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S1" title="1. Introduction ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_tag">1</span></a>, we rank the passages by the likelihood of the LLM generating the question’s ground-truth answer based on the question-passage pair.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Method</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">As illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S2.F1" title="Figure 1 ‣ 2.2. RAG for OpenQA ‣ 2. Related Work ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_tag">1</span></a>, W-RAG introduces a novel approach for training the retrieval component within the RAG pipeline from scratch. Our method leverages a weakly-supervised training paradigm that requires only a set of question-answer pairs and an evidence corpus. The W-RAG process unfolds in three stages: first, it retrieves relevant passages from the evidence corpus; second, it employs a LLM to generate weak labels from them by reranking the retrieved passages by the likelihood of generating the ground-truth answer; finally, the dense retiever is trained using these weak labels. The resulting dense retriever is then capable of retrieving evidence, thereby enhancing the performance of LLMs across a wide array of tasks.</p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="549" id="S3.F2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F2.2.1.1" style="font-size:90%;">Figure 2</span>. </span><span class="ltx_text" id="S3.F2.3.2" style="font-size:90%;">Prompts used for weak label generation and question answering</span></figcaption>
</figure>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Weak-label Generation</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.5">Given an evidence corpus <math alttext="\mathcal{C}=\{d_{1},\dots,d_{N}\}" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.3"><semantics id="S3.SS1.p1.1.m1.3a"><mrow id="S3.SS1.p1.1.m1.3.3" xref="S3.SS1.p1.1.m1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.1.m1.3.3.4" xref="S3.SS1.p1.1.m1.3.3.4.cmml">𝒞</mi><mo id="S3.SS1.p1.1.m1.3.3.3" xref="S3.SS1.p1.1.m1.3.3.3.cmml">=</mo><mrow id="S3.SS1.p1.1.m1.3.3.2.2" xref="S3.SS1.p1.1.m1.3.3.2.3.cmml"><mo id="S3.SS1.p1.1.m1.3.3.2.2.3" stretchy="false" xref="S3.SS1.p1.1.m1.3.3.2.3.cmml">{</mo><msub id="S3.SS1.p1.1.m1.2.2.1.1.1" xref="S3.SS1.p1.1.m1.2.2.1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.2.2.1.1.1.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.2.cmml">d</mi><mn id="S3.SS1.p1.1.m1.2.2.1.1.1.3" xref="S3.SS1.p1.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p1.1.m1.3.3.2.2.4" xref="S3.SS1.p1.1.m1.3.3.2.3.cmml">,</mo><mi id="S3.SS1.p1.1.m1.1.1" mathvariant="normal" xref="S3.SS1.p1.1.m1.1.1.cmml">…</mi><mo id="S3.SS1.p1.1.m1.3.3.2.2.5" xref="S3.SS1.p1.1.m1.3.3.2.3.cmml">,</mo><msub id="S3.SS1.p1.1.m1.3.3.2.2.2" xref="S3.SS1.p1.1.m1.3.3.2.2.2.cmml"><mi id="S3.SS1.p1.1.m1.3.3.2.2.2.2" xref="S3.SS1.p1.1.m1.3.3.2.2.2.2.cmml">d</mi><mi id="S3.SS1.p1.1.m1.3.3.2.2.2.3" xref="S3.SS1.p1.1.m1.3.3.2.2.2.3.cmml">N</mi></msub><mo id="S3.SS1.p1.1.m1.3.3.2.2.6" stretchy="false" xref="S3.SS1.p1.1.m1.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.3b"><apply id="S3.SS1.p1.1.m1.3.3.cmml" xref="S3.SS1.p1.1.m1.3.3"><eq id="S3.SS1.p1.1.m1.3.3.3.cmml" xref="S3.SS1.p1.1.m1.3.3.3"></eq><ci id="S3.SS1.p1.1.m1.3.3.4.cmml" xref="S3.SS1.p1.1.m1.3.3.4">𝒞</ci><set id="S3.SS1.p1.1.m1.3.3.2.3.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2"><apply id="S3.SS1.p1.1.m1.2.2.1.1.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.2">𝑑</ci><cn id="S3.SS1.p1.1.m1.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS1.p1.1.m1.2.2.1.1.1.3">1</cn></apply><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">…</ci><apply id="S3.SS1.p1.1.m1.3.3.2.2.2.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.3.3.2.2.2.1.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2.2.2">𝑑</ci><ci id="S3.SS1.p1.1.m1.3.3.2.2.2.3.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2.2.3">𝑁</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.3c">\mathcal{C}=\{d_{1},\dots,d_{N}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.3d">caligraphic_C = { italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_d start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT }</annotation></semantics></math>, we use a simple retreiver to conduct first-stage retrieval. Given a question <math alttext="q" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">q</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">italic_q</annotation></semantics></math>, the retriever ranks each passage by relevance and selects the top-<math alttext="K" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1"><semantics id="S3.SS1.p1.3.m3.1a"><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.1d">italic_K</annotation></semantics></math> passages <math alttext="\mathcal{P}=\{s_{1},\dots,s_{K}\}" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m4.3"><semantics id="S3.SS1.p1.4.m4.3a"><mrow id="S3.SS1.p1.4.m4.3.3" xref="S3.SS1.p1.4.m4.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.4.m4.3.3.4" xref="S3.SS1.p1.4.m4.3.3.4.cmml">𝒫</mi><mo id="S3.SS1.p1.4.m4.3.3.3" xref="S3.SS1.p1.4.m4.3.3.3.cmml">=</mo><mrow id="S3.SS1.p1.4.m4.3.3.2.2" xref="S3.SS1.p1.4.m4.3.3.2.3.cmml"><mo id="S3.SS1.p1.4.m4.3.3.2.2.3" stretchy="false" xref="S3.SS1.p1.4.m4.3.3.2.3.cmml">{</mo><msub id="S3.SS1.p1.4.m4.2.2.1.1.1" xref="S3.SS1.p1.4.m4.2.2.1.1.1.cmml"><mi id="S3.SS1.p1.4.m4.2.2.1.1.1.2" xref="S3.SS1.p1.4.m4.2.2.1.1.1.2.cmml">s</mi><mn id="S3.SS1.p1.4.m4.2.2.1.1.1.3" xref="S3.SS1.p1.4.m4.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p1.4.m4.3.3.2.2.4" xref="S3.SS1.p1.4.m4.3.3.2.3.cmml">,</mo><mi id="S3.SS1.p1.4.m4.1.1" mathvariant="normal" xref="S3.SS1.p1.4.m4.1.1.cmml">…</mi><mo id="S3.SS1.p1.4.m4.3.3.2.2.5" xref="S3.SS1.p1.4.m4.3.3.2.3.cmml">,</mo><msub id="S3.SS1.p1.4.m4.3.3.2.2.2" xref="S3.SS1.p1.4.m4.3.3.2.2.2.cmml"><mi id="S3.SS1.p1.4.m4.3.3.2.2.2.2" xref="S3.SS1.p1.4.m4.3.3.2.2.2.2.cmml">s</mi><mi id="S3.SS1.p1.4.m4.3.3.2.2.2.3" xref="S3.SS1.p1.4.m4.3.3.2.2.2.3.cmml">K</mi></msub><mo id="S3.SS1.p1.4.m4.3.3.2.2.6" stretchy="false" xref="S3.SS1.p1.4.m4.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.3b"><apply id="S3.SS1.p1.4.m4.3.3.cmml" xref="S3.SS1.p1.4.m4.3.3"><eq id="S3.SS1.p1.4.m4.3.3.3.cmml" xref="S3.SS1.p1.4.m4.3.3.3"></eq><ci id="S3.SS1.p1.4.m4.3.3.4.cmml" xref="S3.SS1.p1.4.m4.3.3.4">𝒫</ci><set id="S3.SS1.p1.4.m4.3.3.2.3.cmml" xref="S3.SS1.p1.4.m4.3.3.2.2"><apply id="S3.SS1.p1.4.m4.2.2.1.1.1.cmml" xref="S3.SS1.p1.4.m4.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.2.2.1.1.1.1.cmml" xref="S3.SS1.p1.4.m4.2.2.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.4.m4.2.2.1.1.1.2.cmml" xref="S3.SS1.p1.4.m4.2.2.1.1.1.2">𝑠</ci><cn id="S3.SS1.p1.4.m4.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS1.p1.4.m4.2.2.1.1.1.3">1</cn></apply><ci id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">…</ci><apply id="S3.SS1.p1.4.m4.3.3.2.2.2.cmml" xref="S3.SS1.p1.4.m4.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.3.3.2.2.2.1.cmml" xref="S3.SS1.p1.4.m4.3.3.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.4.m4.3.3.2.2.2.2.cmml" xref="S3.SS1.p1.4.m4.3.3.2.2.2.2">𝑠</ci><ci id="S3.SS1.p1.4.m4.3.3.2.2.2.3.cmml" xref="S3.SS1.p1.4.m4.3.3.2.2.2.3">𝐾</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.3c">\mathcal{P}=\{s_{1},\dots,s_{K}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.4.m4.3d">caligraphic_P = { italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_s start_POSTSUBSCRIPT italic_K end_POSTSUBSCRIPT }</annotation></semantics></math>, where <math alttext="\mathcal{P}\subset\mathcal{C}" class="ltx_Math" display="inline" id="S3.SS1.p1.5.m5.1"><semantics id="S3.SS1.p1.5.m5.1a"><mrow id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.5.m5.1.1.2" xref="S3.SS1.p1.5.m5.1.1.2.cmml">𝒫</mi><mo id="S3.SS1.p1.5.m5.1.1.1" xref="S3.SS1.p1.5.m5.1.1.1.cmml">⊂</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.5.m5.1.1.3" xref="S3.SS1.p1.5.m5.1.1.3.cmml">𝒞</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><apply id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1"><subset id="S3.SS1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1.1"></subset><ci id="S3.SS1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2">𝒫</ci><ci id="S3.SS1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3">𝒞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">\mathcal{P}\subset\mathcal{C}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.5.m5.1d">caligraphic_P ⊂ caligraphic_C</annotation></semantics></math>. The corpus may comprise chuncked Wikipedia articles or from online sources such as Reddit and Common Crawl, while the question-answer pairs could be sourced from OpenQA platforms such as Quora and StackOverflow. The simple first-stage retriever could be lexical such as BM25 <cite class="ltx_cite ltx_citemacro_citep">(Robertson and Zaragoza, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib39" title="">2009</a>)</cite>, or a dense retriever. The primary objective at this stage is to maximize recall within a manageable set of retrieved passages. Ideally, this step curates evidence passages containing the correct answer to the question</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">W-RAG is motivated by the hypothesis that an autoregressive LLM is more likely to generate the correct answer if the provided passage contains the necessary information to answer the question. Our approach aims to harness signals from the LLM’s downstream tasks to evaluate the effectiveness of a passage in eliciting the correct answer. It is important to note that traditional relevance measures, such as term overlap or semantic similarity, do no necessarily guarantee that the most relevant passage contains the needed information. Instead, our target is on identifying passages that most effectively prompt the LLM to produce the correct answer and using these passages to train the dense retriever. In this context, we redefine passage relevance as the degree to which a passage can elicit the ground-truth answer, and this criterion serves as the target for training the dense retriever.</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.5">As depicted in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S2.F1" title="Figure 1 ‣ 2.2. RAG for OpenQA ‣ 2. Related Work ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_tag">1</span></a> Step 2, we construct weak label generation prompts with candidate passage <math alttext="s_{i}" class="ltx_Math" display="inline" id="S3.SS1.p3.1.m1.1"><semantics id="S3.SS1.p3.1.m1.1a"><msub id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml"><mi id="S3.SS1.p3.1.m1.1.1.2" xref="S3.SS1.p3.1.m1.1.1.2.cmml">s</mi><mi id="S3.SS1.p3.1.m1.1.1.3" xref="S3.SS1.p3.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><apply id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p3.1.m1.1.1.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2">𝑠</ci><ci id="S3.SS1.p3.1.m1.1.1.3.cmml" xref="S3.SS1.p3.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">s_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.1.m1.1d">italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, question <math alttext="q" class="ltx_Math" display="inline" id="S3.SS1.p3.2.m2.1"><semantics id="S3.SS1.p3.2.m2.1a"><mi id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><ci id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">q</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.2.m2.1d">italic_q</annotation></semantics></math>, some instructions <math alttext="I" class="ltx_Math" display="inline" id="S3.SS1.p3.3.m3.1"><semantics id="S3.SS1.p3.3.m3.1a"><mi id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><ci id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">I</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.3.m3.1d">italic_I</annotation></semantics></math>, and ground-truth answer <math alttext="a" class="ltx_Math" display="inline" id="S3.SS1.p3.4.m4.1"><semantics id="S3.SS1.p3.4.m4.1a"><mi id="S3.SS1.p3.4.m4.1.1" xref="S3.SS1.p3.4.m4.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.4.m4.1b"><ci id="S3.SS1.p3.4.m4.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1">𝑎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.4.m4.1c">a</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.4.m4.1d">italic_a</annotation></semantics></math>. The downstream signal is captured through the conditional probability of the ground-truth answer, denoted as <math alttext="p(a|s_{i},q,I)" class="ltx_Math" display="inline" id="S3.SS1.p3.5.m5.3"><semantics id="S3.SS1.p3.5.m5.3a"><mrow id="S3.SS1.p3.5.m5.3.3" xref="S3.SS1.p3.5.m5.3.3.cmml"><mi id="S3.SS1.p3.5.m5.3.3.3" xref="S3.SS1.p3.5.m5.3.3.3.cmml">p</mi><mo id="S3.SS1.p3.5.m5.3.3.2" xref="S3.SS1.p3.5.m5.3.3.2.cmml">⁢</mo><mrow id="S3.SS1.p3.5.m5.3.3.1.1" xref="S3.SS1.p3.5.m5.3.3.1.1.1.cmml"><mo id="S3.SS1.p3.5.m5.3.3.1.1.2" stretchy="false" xref="S3.SS1.p3.5.m5.3.3.1.1.1.cmml">(</mo><mrow id="S3.SS1.p3.5.m5.3.3.1.1.1" xref="S3.SS1.p3.5.m5.3.3.1.1.1.cmml"><mi id="S3.SS1.p3.5.m5.3.3.1.1.1.3" xref="S3.SS1.p3.5.m5.3.3.1.1.1.3.cmml">a</mi><mo fence="false" id="S3.SS1.p3.5.m5.3.3.1.1.1.2" xref="S3.SS1.p3.5.m5.3.3.1.1.1.2.cmml">|</mo><mrow id="S3.SS1.p3.5.m5.3.3.1.1.1.1.1" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.cmml"><msub id="S3.SS1.p3.5.m5.3.3.1.1.1.1.1.1" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p3.5.m5.3.3.1.1.1.1.1.1.2" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1.1.1.2.cmml">s</mi><mi id="S3.SS1.p3.5.m5.3.3.1.1.1.1.1.1.3" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS1.p3.5.m5.3.3.1.1.1.1.1.2" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.cmml">,</mo><mi id="S3.SS1.p3.5.m5.1.1" xref="S3.SS1.p3.5.m5.1.1.cmml">q</mi><mo id="S3.SS1.p3.5.m5.3.3.1.1.1.1.1.3" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.cmml">,</mo><mi id="S3.SS1.p3.5.m5.2.2" xref="S3.SS1.p3.5.m5.2.2.cmml">I</mi></mrow></mrow><mo id="S3.SS1.p3.5.m5.3.3.1.1.3" stretchy="false" xref="S3.SS1.p3.5.m5.3.3.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.5.m5.3b"><apply id="S3.SS1.p3.5.m5.3.3.cmml" xref="S3.SS1.p3.5.m5.3.3"><times id="S3.SS1.p3.5.m5.3.3.2.cmml" xref="S3.SS1.p3.5.m5.3.3.2"></times><ci id="S3.SS1.p3.5.m5.3.3.3.cmml" xref="S3.SS1.p3.5.m5.3.3.3">𝑝</ci><apply id="S3.SS1.p3.5.m5.3.3.1.1.1.cmml" xref="S3.SS1.p3.5.m5.3.3.1.1"><csymbol cd="latexml" id="S3.SS1.p3.5.m5.3.3.1.1.1.2.cmml" xref="S3.SS1.p3.5.m5.3.3.1.1.1.2">conditional</csymbol><ci id="S3.SS1.p3.5.m5.3.3.1.1.1.3.cmml" xref="S3.SS1.p3.5.m5.3.3.1.1.1.3">𝑎</ci><list id="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.cmml" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1.1"><apply id="S3.SS1.p3.5.m5.3.3.1.1.1.1.1.1.cmml" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.5.m5.3.3.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p3.5.m5.3.3.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1.1.1.2">𝑠</ci><ci id="S3.SS1.p3.5.m5.3.3.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1.1.1.3">𝑖</ci></apply><ci id="S3.SS1.p3.5.m5.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1">𝑞</ci><ci id="S3.SS1.p3.5.m5.2.2.cmml" xref="S3.SS1.p3.5.m5.2.2">𝐼</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.5.m5.3c">p(a|s_{i},q,I)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.5.m5.3d">italic_p ( italic_a | italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_q , italic_I )</annotation></semantics></math>:</p>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="p(a|s_{i},q,I)=\prod_{j}\text{LLM}(a_{j}|s_{i},q,I,a_{&lt;j})" class="ltx_Math" display="block" id="S3.E1.m1.6"><semantics id="S3.E1.m1.6a"><mrow id="S3.E1.m1.6.6" xref="S3.E1.m1.6.6.cmml"><mrow id="S3.E1.m1.5.5.1" xref="S3.E1.m1.5.5.1.cmml"><mi id="S3.E1.m1.5.5.1.3" xref="S3.E1.m1.5.5.1.3.cmml">p</mi><mo id="S3.E1.m1.5.5.1.2" xref="S3.E1.m1.5.5.1.2.cmml">⁢</mo><mrow id="S3.E1.m1.5.5.1.1.1" xref="S3.E1.m1.5.5.1.1.1.1.cmml"><mo id="S3.E1.m1.5.5.1.1.1.2" stretchy="false" xref="S3.E1.m1.5.5.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.5.5.1.1.1.1" xref="S3.E1.m1.5.5.1.1.1.1.cmml"><mi id="S3.E1.m1.5.5.1.1.1.1.3" xref="S3.E1.m1.5.5.1.1.1.1.3.cmml">a</mi><mo fence="false" id="S3.E1.m1.5.5.1.1.1.1.2" xref="S3.E1.m1.5.5.1.1.1.1.2.cmml">|</mo><mrow id="S3.E1.m1.5.5.1.1.1.1.1.1" xref="S3.E1.m1.5.5.1.1.1.1.1.2.cmml"><msub id="S3.E1.m1.5.5.1.1.1.1.1.1.1" xref="S3.E1.m1.5.5.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.5.5.1.1.1.1.1.1.1.2" xref="S3.E1.m1.5.5.1.1.1.1.1.1.1.2.cmml">s</mi><mi id="S3.E1.m1.5.5.1.1.1.1.1.1.1.3" xref="S3.E1.m1.5.5.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E1.m1.5.5.1.1.1.1.1.1.2" xref="S3.E1.m1.5.5.1.1.1.1.1.2.cmml">,</mo><mi id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">q</mi><mo id="S3.E1.m1.5.5.1.1.1.1.1.1.3" xref="S3.E1.m1.5.5.1.1.1.1.1.2.cmml">,</mo><mi id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml">I</mi></mrow></mrow><mo id="S3.E1.m1.5.5.1.1.1.3" stretchy="false" xref="S3.E1.m1.5.5.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.6.6.3" rspace="0.111em" xref="S3.E1.m1.6.6.3.cmml">=</mo><mrow id="S3.E1.m1.6.6.2" xref="S3.E1.m1.6.6.2.cmml"><munder id="S3.E1.m1.6.6.2.2" xref="S3.E1.m1.6.6.2.2.cmml"><mo id="S3.E1.m1.6.6.2.2.2" movablelimits="false" xref="S3.E1.m1.6.6.2.2.2.cmml">∏</mo><mi id="S3.E1.m1.6.6.2.2.3" xref="S3.E1.m1.6.6.2.2.3.cmml">j</mi></munder><mrow id="S3.E1.m1.6.6.2.1" xref="S3.E1.m1.6.6.2.1.cmml"><mtext id="S3.E1.m1.6.6.2.1.3" xref="S3.E1.m1.6.6.2.1.3a.cmml">LLM</mtext><mo id="S3.E1.m1.6.6.2.1.2" xref="S3.E1.m1.6.6.2.1.2.cmml">⁢</mo><mrow id="S3.E1.m1.6.6.2.1.1.1" xref="S3.E1.m1.6.6.2.1.1.1.1.cmml"><mo id="S3.E1.m1.6.6.2.1.1.1.2" stretchy="false" xref="S3.E1.m1.6.6.2.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.6.6.2.1.1.1.1" xref="S3.E1.m1.6.6.2.1.1.1.1.cmml"><msub id="S3.E1.m1.6.6.2.1.1.1.1.4" xref="S3.E1.m1.6.6.2.1.1.1.1.4.cmml"><mi id="S3.E1.m1.6.6.2.1.1.1.1.4.2" xref="S3.E1.m1.6.6.2.1.1.1.1.4.2.cmml">a</mi><mi id="S3.E1.m1.6.6.2.1.1.1.1.4.3" xref="S3.E1.m1.6.6.2.1.1.1.1.4.3.cmml">j</mi></msub><mo fence="false" id="S3.E1.m1.6.6.2.1.1.1.1.3" xref="S3.E1.m1.6.6.2.1.1.1.1.3.cmml">|</mo><mrow id="S3.E1.m1.6.6.2.1.1.1.1.2.2" xref="S3.E1.m1.6.6.2.1.1.1.1.2.3.cmml"><msub id="S3.E1.m1.6.6.2.1.1.1.1.1.1.1" xref="S3.E1.m1.6.6.2.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.6.6.2.1.1.1.1.1.1.1.2" xref="S3.E1.m1.6.6.2.1.1.1.1.1.1.1.2.cmml">s</mi><mi id="S3.E1.m1.6.6.2.1.1.1.1.1.1.1.3" xref="S3.E1.m1.6.6.2.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E1.m1.6.6.2.1.1.1.1.2.2.3" xref="S3.E1.m1.6.6.2.1.1.1.1.2.3.cmml">,</mo><mi id="S3.E1.m1.3.3" xref="S3.E1.m1.3.3.cmml">q</mi><mo id="S3.E1.m1.6.6.2.1.1.1.1.2.2.4" xref="S3.E1.m1.6.6.2.1.1.1.1.2.3.cmml">,</mo><mi id="S3.E1.m1.4.4" xref="S3.E1.m1.4.4.cmml">I</mi><mo id="S3.E1.m1.6.6.2.1.1.1.1.2.2.5" xref="S3.E1.m1.6.6.2.1.1.1.1.2.3.cmml">,</mo><msub id="S3.E1.m1.6.6.2.1.1.1.1.2.2.2" xref="S3.E1.m1.6.6.2.1.1.1.1.2.2.2.cmml"><mi id="S3.E1.m1.6.6.2.1.1.1.1.2.2.2.2" xref="S3.E1.m1.6.6.2.1.1.1.1.2.2.2.2.cmml">a</mi><mrow id="S3.E1.m1.6.6.2.1.1.1.1.2.2.2.3" xref="S3.E1.m1.6.6.2.1.1.1.1.2.2.2.3.cmml"><mi id="S3.E1.m1.6.6.2.1.1.1.1.2.2.2.3.2" xref="S3.E1.m1.6.6.2.1.1.1.1.2.2.2.3.2.cmml"></mi><mo id="S3.E1.m1.6.6.2.1.1.1.1.2.2.2.3.1" xref="S3.E1.m1.6.6.2.1.1.1.1.2.2.2.3.1.cmml">&lt;</mo><mi id="S3.E1.m1.6.6.2.1.1.1.1.2.2.2.3.3" xref="S3.E1.m1.6.6.2.1.1.1.1.2.2.2.3.3.cmml">j</mi></mrow></msub></mrow></mrow><mo id="S3.E1.m1.6.6.2.1.1.1.3" stretchy="false" xref="S3.E1.m1.6.6.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.6b"><apply id="S3.E1.m1.6.6.cmml" xref="S3.E1.m1.6.6"><eq id="S3.E1.m1.6.6.3.cmml" xref="S3.E1.m1.6.6.3"></eq><apply id="S3.E1.m1.5.5.1.cmml" xref="S3.E1.m1.5.5.1"><times id="S3.E1.m1.5.5.1.2.cmml" xref="S3.E1.m1.5.5.1.2"></times><ci id="S3.E1.m1.5.5.1.3.cmml" xref="S3.E1.m1.5.5.1.3">𝑝</ci><apply id="S3.E1.m1.5.5.1.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.5.5.1.1.1.1.2.cmml" xref="S3.E1.m1.5.5.1.1.1.1.2">conditional</csymbol><ci id="S3.E1.m1.5.5.1.1.1.1.3.cmml" xref="S3.E1.m1.5.5.1.1.1.1.3">𝑎</ci><list id="S3.E1.m1.5.5.1.1.1.1.1.2.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1.1"><apply id="S3.E1.m1.5.5.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.5.5.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1.1.1.2">𝑠</ci><ci id="S3.E1.m1.5.5.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.5.5.1.1.1.1.1.1.1.3">𝑖</ci></apply><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">𝑞</ci><ci id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2">𝐼</ci></list></apply></apply><apply id="S3.E1.m1.6.6.2.cmml" xref="S3.E1.m1.6.6.2"><apply id="S3.E1.m1.6.6.2.2.cmml" xref="S3.E1.m1.6.6.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.6.6.2.2.1.cmml" xref="S3.E1.m1.6.6.2.2">subscript</csymbol><csymbol cd="latexml" id="S3.E1.m1.6.6.2.2.2.cmml" xref="S3.E1.m1.6.6.2.2.2">product</csymbol><ci id="S3.E1.m1.6.6.2.2.3.cmml" xref="S3.E1.m1.6.6.2.2.3">𝑗</ci></apply><apply id="S3.E1.m1.6.6.2.1.cmml" xref="S3.E1.m1.6.6.2.1"><times id="S3.E1.m1.6.6.2.1.2.cmml" xref="S3.E1.m1.6.6.2.1.2"></times><ci id="S3.E1.m1.6.6.2.1.3a.cmml" xref="S3.E1.m1.6.6.2.1.3"><mtext id="S3.E1.m1.6.6.2.1.3.cmml" xref="S3.E1.m1.6.6.2.1.3">LLM</mtext></ci><apply id="S3.E1.m1.6.6.2.1.1.1.1.cmml" xref="S3.E1.m1.6.6.2.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.6.6.2.1.1.1.1.3.cmml" xref="S3.E1.m1.6.6.2.1.1.1.1.3">conditional</csymbol><apply id="S3.E1.m1.6.6.2.1.1.1.1.4.cmml" xref="S3.E1.m1.6.6.2.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E1.m1.6.6.2.1.1.1.1.4.1.cmml" xref="S3.E1.m1.6.6.2.1.1.1.1.4">subscript</csymbol><ci id="S3.E1.m1.6.6.2.1.1.1.1.4.2.cmml" xref="S3.E1.m1.6.6.2.1.1.1.1.4.2">𝑎</ci><ci id="S3.E1.m1.6.6.2.1.1.1.1.4.3.cmml" xref="S3.E1.m1.6.6.2.1.1.1.1.4.3">𝑗</ci></apply><list id="S3.E1.m1.6.6.2.1.1.1.1.2.3.cmml" xref="S3.E1.m1.6.6.2.1.1.1.1.2.2"><apply id="S3.E1.m1.6.6.2.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.6.6.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.6.6.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.6.6.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.6.6.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.6.6.2.1.1.1.1.1.1.1.2">𝑠</ci><ci id="S3.E1.m1.6.6.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.6.6.2.1.1.1.1.1.1.1.3">𝑖</ci></apply><ci id="S3.E1.m1.3.3.cmml" xref="S3.E1.m1.3.3">𝑞</ci><ci id="S3.E1.m1.4.4.cmml" xref="S3.E1.m1.4.4">𝐼</ci><apply id="S3.E1.m1.6.6.2.1.1.1.1.2.2.2.cmml" xref="S3.E1.m1.6.6.2.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.6.6.2.1.1.1.1.2.2.2.1.cmml" xref="S3.E1.m1.6.6.2.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.E1.m1.6.6.2.1.1.1.1.2.2.2.2.cmml" xref="S3.E1.m1.6.6.2.1.1.1.1.2.2.2.2">𝑎</ci><apply id="S3.E1.m1.6.6.2.1.1.1.1.2.2.2.3.cmml" xref="S3.E1.m1.6.6.2.1.1.1.1.2.2.2.3"><lt id="S3.E1.m1.6.6.2.1.1.1.1.2.2.2.3.1.cmml" xref="S3.E1.m1.6.6.2.1.1.1.1.2.2.2.3.1"></lt><csymbol cd="latexml" id="S3.E1.m1.6.6.2.1.1.1.1.2.2.2.3.2.cmml" xref="S3.E1.m1.6.6.2.1.1.1.1.2.2.2.3.2">absent</csymbol><ci id="S3.E1.m1.6.6.2.1.1.1.1.2.2.2.3.3.cmml" xref="S3.E1.m1.6.6.2.1.1.1.1.2.2.2.3.3">𝑗</ci></apply></apply></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.6c">p(a|s_{i},q,I)=\prod_{j}\text{LLM}(a_{j}|s_{i},q,I,a_{&lt;j})</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.6d">italic_p ( italic_a | italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_q , italic_I ) = ∏ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT LLM ( italic_a start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT | italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_q , italic_I , italic_a start_POSTSUBSCRIPT &lt; italic_j end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS1.p5">
<p class="ltx_p" id="S3.SS1.p5.3">For each token in the input prompt, the LLM assigns logits, which after applying a softmax operation, correspond to the probability of each vocabulary token being the next in the sequence. The probability of the <math alttext="j" class="ltx_Math" display="inline" id="S3.SS1.p5.1.m1.1"><semantics id="S3.SS1.p5.1.m1.1a"><mi id="S3.SS1.p5.1.m1.1.1" xref="S3.SS1.p5.1.m1.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.1.m1.1b"><ci id="S3.SS1.p5.1.m1.1.1.cmml" xref="S3.SS1.p5.1.m1.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.1.m1.1c">j</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p5.1.m1.1d">italic_j</annotation></semantics></math>th answer token, denoted as <math alttext="\text{LLM}(a_{j}|s_{i},q,I,a_{&lt;j})" class="ltx_Math" display="inline" id="S3.SS1.p5.2.m2.3"><semantics id="S3.SS1.p5.2.m2.3a"><mrow id="S3.SS1.p5.2.m2.3.3" xref="S3.SS1.p5.2.m2.3.3.cmml"><mtext id="S3.SS1.p5.2.m2.3.3.3" xref="S3.SS1.p5.2.m2.3.3.3a.cmml">LLM</mtext><mo id="S3.SS1.p5.2.m2.3.3.2" xref="S3.SS1.p5.2.m2.3.3.2.cmml">⁢</mo><mrow id="S3.SS1.p5.2.m2.3.3.1.1" xref="S3.SS1.p5.2.m2.3.3.1.1.1.cmml"><mo id="S3.SS1.p5.2.m2.3.3.1.1.2" stretchy="false" xref="S3.SS1.p5.2.m2.3.3.1.1.1.cmml">(</mo><mrow id="S3.SS1.p5.2.m2.3.3.1.1.1" xref="S3.SS1.p5.2.m2.3.3.1.1.1.cmml"><msub id="S3.SS1.p5.2.m2.3.3.1.1.1.4" xref="S3.SS1.p5.2.m2.3.3.1.1.1.4.cmml"><mi id="S3.SS1.p5.2.m2.3.3.1.1.1.4.2" xref="S3.SS1.p5.2.m2.3.3.1.1.1.4.2.cmml">a</mi><mi id="S3.SS1.p5.2.m2.3.3.1.1.1.4.3" xref="S3.SS1.p5.2.m2.3.3.1.1.1.4.3.cmml">j</mi></msub><mo fence="false" id="S3.SS1.p5.2.m2.3.3.1.1.1.3" xref="S3.SS1.p5.2.m2.3.3.1.1.1.3.cmml">|</mo><mrow id="S3.SS1.p5.2.m2.3.3.1.1.1.2.2" xref="S3.SS1.p5.2.m2.3.3.1.1.1.2.3.cmml"><msub id="S3.SS1.p5.2.m2.3.3.1.1.1.1.1.1" xref="S3.SS1.p5.2.m2.3.3.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p5.2.m2.3.3.1.1.1.1.1.1.2" xref="S3.SS1.p5.2.m2.3.3.1.1.1.1.1.1.2.cmml">s</mi><mi id="S3.SS1.p5.2.m2.3.3.1.1.1.1.1.1.3" xref="S3.SS1.p5.2.m2.3.3.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS1.p5.2.m2.3.3.1.1.1.2.2.3" xref="S3.SS1.p5.2.m2.3.3.1.1.1.2.3.cmml">,</mo><mi id="S3.SS1.p5.2.m2.1.1" xref="S3.SS1.p5.2.m2.1.1.cmml">q</mi><mo id="S3.SS1.p5.2.m2.3.3.1.1.1.2.2.4" xref="S3.SS1.p5.2.m2.3.3.1.1.1.2.3.cmml">,</mo><mi id="S3.SS1.p5.2.m2.2.2" xref="S3.SS1.p5.2.m2.2.2.cmml">I</mi><mo id="S3.SS1.p5.2.m2.3.3.1.1.1.2.2.5" xref="S3.SS1.p5.2.m2.3.3.1.1.1.2.3.cmml">,</mo><msub id="S3.SS1.p5.2.m2.3.3.1.1.1.2.2.2" xref="S3.SS1.p5.2.m2.3.3.1.1.1.2.2.2.cmml"><mi id="S3.SS1.p5.2.m2.3.3.1.1.1.2.2.2.2" xref="S3.SS1.p5.2.m2.3.3.1.1.1.2.2.2.2.cmml">a</mi><mrow id="S3.SS1.p5.2.m2.3.3.1.1.1.2.2.2.3" xref="S3.SS1.p5.2.m2.3.3.1.1.1.2.2.2.3.cmml"><mi id="S3.SS1.p5.2.m2.3.3.1.1.1.2.2.2.3.2" xref="S3.SS1.p5.2.m2.3.3.1.1.1.2.2.2.3.2.cmml"></mi><mo id="S3.SS1.p5.2.m2.3.3.1.1.1.2.2.2.3.1" xref="S3.SS1.p5.2.m2.3.3.1.1.1.2.2.2.3.1.cmml">&lt;</mo><mi id="S3.SS1.p5.2.m2.3.3.1.1.1.2.2.2.3.3" xref="S3.SS1.p5.2.m2.3.3.1.1.1.2.2.2.3.3.cmml">j</mi></mrow></msub></mrow></mrow><mo id="S3.SS1.p5.2.m2.3.3.1.1.3" stretchy="false" xref="S3.SS1.p5.2.m2.3.3.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.2.m2.3b"><apply id="S3.SS1.p5.2.m2.3.3.cmml" xref="S3.SS1.p5.2.m2.3.3"><times id="S3.SS1.p5.2.m2.3.3.2.cmml" xref="S3.SS1.p5.2.m2.3.3.2"></times><ci id="S3.SS1.p5.2.m2.3.3.3a.cmml" xref="S3.SS1.p5.2.m2.3.3.3"><mtext id="S3.SS1.p5.2.m2.3.3.3.cmml" xref="S3.SS1.p5.2.m2.3.3.3">LLM</mtext></ci><apply id="S3.SS1.p5.2.m2.3.3.1.1.1.cmml" xref="S3.SS1.p5.2.m2.3.3.1.1"><csymbol cd="latexml" id="S3.SS1.p5.2.m2.3.3.1.1.1.3.cmml" xref="S3.SS1.p5.2.m2.3.3.1.1.1.3">conditional</csymbol><apply id="S3.SS1.p5.2.m2.3.3.1.1.1.4.cmml" xref="S3.SS1.p5.2.m2.3.3.1.1.1.4"><csymbol cd="ambiguous" id="S3.SS1.p5.2.m2.3.3.1.1.1.4.1.cmml" xref="S3.SS1.p5.2.m2.3.3.1.1.1.4">subscript</csymbol><ci id="S3.SS1.p5.2.m2.3.3.1.1.1.4.2.cmml" xref="S3.SS1.p5.2.m2.3.3.1.1.1.4.2">𝑎</ci><ci id="S3.SS1.p5.2.m2.3.3.1.1.1.4.3.cmml" xref="S3.SS1.p5.2.m2.3.3.1.1.1.4.3">𝑗</ci></apply><list id="S3.SS1.p5.2.m2.3.3.1.1.1.2.3.cmml" xref="S3.SS1.p5.2.m2.3.3.1.1.1.2.2"><apply id="S3.SS1.p5.2.m2.3.3.1.1.1.1.1.1.cmml" xref="S3.SS1.p5.2.m2.3.3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.2.m2.3.3.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p5.2.m2.3.3.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p5.2.m2.3.3.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p5.2.m2.3.3.1.1.1.1.1.1.2">𝑠</ci><ci id="S3.SS1.p5.2.m2.3.3.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p5.2.m2.3.3.1.1.1.1.1.1.3">𝑖</ci></apply><ci id="S3.SS1.p5.2.m2.1.1.cmml" xref="S3.SS1.p5.2.m2.1.1">𝑞</ci><ci id="S3.SS1.p5.2.m2.2.2.cmml" xref="S3.SS1.p5.2.m2.2.2">𝐼</ci><apply id="S3.SS1.p5.2.m2.3.3.1.1.1.2.2.2.cmml" xref="S3.SS1.p5.2.m2.3.3.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p5.2.m2.3.3.1.1.1.2.2.2.1.cmml" xref="S3.SS1.p5.2.m2.3.3.1.1.1.2.2.2">subscript</csymbol><ci id="S3.SS1.p5.2.m2.3.3.1.1.1.2.2.2.2.cmml" xref="S3.SS1.p5.2.m2.3.3.1.1.1.2.2.2.2">𝑎</ci><apply id="S3.SS1.p5.2.m2.3.3.1.1.1.2.2.2.3.cmml" xref="S3.SS1.p5.2.m2.3.3.1.1.1.2.2.2.3"><lt id="S3.SS1.p5.2.m2.3.3.1.1.1.2.2.2.3.1.cmml" xref="S3.SS1.p5.2.m2.3.3.1.1.1.2.2.2.3.1"></lt><csymbol cd="latexml" id="S3.SS1.p5.2.m2.3.3.1.1.1.2.2.2.3.2.cmml" xref="S3.SS1.p5.2.m2.3.3.1.1.1.2.2.2.3.2">absent</csymbol><ci id="S3.SS1.p5.2.m2.3.3.1.1.1.2.2.2.3.3.cmml" xref="S3.SS1.p5.2.m2.3.3.1.1.1.2.2.2.3.3">𝑗</ci></apply></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.2.m2.3c">\text{LLM}(a_{j}|s_{i},q,I,a_{&lt;j})</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p5.2.m2.3d">LLM ( italic_a start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT | italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_q , italic_I , italic_a start_POSTSUBSCRIPT &lt; italic_j end_POSTSUBSCRIPT )</annotation></semantics></math>, is directly extracted from the logits of the preceding token. Since the ground-truth answer typically consists of multiple tokens, the cumulative probability can diminish rapidly. To address this, we simply take the logarithm on both sides of Equation 1, converting each token’s probability into log-likelihood. The overall probability of the answer <math alttext="a" class="ltx_Math" display="inline" id="S3.SS1.p5.3.m3.1"><semantics id="S3.SS1.p5.3.m3.1a"><mi id="S3.SS1.p5.3.m3.1.1" xref="S3.SS1.p5.3.m3.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.3.m3.1b"><ci id="S3.SS1.p5.3.m3.1.1.cmml" xref="S3.SS1.p5.3.m3.1.1">𝑎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.3.m3.1c">a</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p5.3.m3.1d">italic_a</annotation></semantics></math> is then computed as the average of the sum of the log-likelihoods for each token in the answer:</p>
</div>
<div class="ltx_para" id="S3.SS1.p6">
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(2)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\log p(a|s_{i},q,I)=\frac{1}{|a|}\sum_{j}\log\text{LLM}(a_{j}|s_{i},q,I,a_{&lt;j})" class="ltx_Math" display="block" id="S3.E2.m1.7"><semantics id="S3.E2.m1.7a"><mrow id="S3.E2.m1.7.7" xref="S3.E2.m1.7.7.cmml"><mrow id="S3.E2.m1.6.6.1" xref="S3.E2.m1.6.6.1.cmml"><mrow id="S3.E2.m1.6.6.1.3" xref="S3.E2.m1.6.6.1.3.cmml"><mi id="S3.E2.m1.6.6.1.3.1" xref="S3.E2.m1.6.6.1.3.1.cmml">log</mi><mo id="S3.E2.m1.6.6.1.3a" lspace="0.167em" xref="S3.E2.m1.6.6.1.3.cmml">⁡</mo><mi id="S3.E2.m1.6.6.1.3.2" xref="S3.E2.m1.6.6.1.3.2.cmml">p</mi></mrow><mo id="S3.E2.m1.6.6.1.2" xref="S3.E2.m1.6.6.1.2.cmml">⁢</mo><mrow id="S3.E2.m1.6.6.1.1.1" xref="S3.E2.m1.6.6.1.1.1.1.cmml"><mo id="S3.E2.m1.6.6.1.1.1.2" stretchy="false" xref="S3.E2.m1.6.6.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.6.6.1.1.1.1" xref="S3.E2.m1.6.6.1.1.1.1.cmml"><mi id="S3.E2.m1.6.6.1.1.1.1.3" xref="S3.E2.m1.6.6.1.1.1.1.3.cmml">a</mi><mo fence="false" id="S3.E2.m1.6.6.1.1.1.1.2" xref="S3.E2.m1.6.6.1.1.1.1.2.cmml">|</mo><mrow id="S3.E2.m1.6.6.1.1.1.1.1.1" xref="S3.E2.m1.6.6.1.1.1.1.1.2.cmml"><msub id="S3.E2.m1.6.6.1.1.1.1.1.1.1" xref="S3.E2.m1.6.6.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.6.6.1.1.1.1.1.1.1.2" xref="S3.E2.m1.6.6.1.1.1.1.1.1.1.2.cmml">s</mi><mi id="S3.E2.m1.6.6.1.1.1.1.1.1.1.3" xref="S3.E2.m1.6.6.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E2.m1.6.6.1.1.1.1.1.1.2" xref="S3.E2.m1.6.6.1.1.1.1.1.2.cmml">,</mo><mi id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml">q</mi><mo id="S3.E2.m1.6.6.1.1.1.1.1.1.3" xref="S3.E2.m1.6.6.1.1.1.1.1.2.cmml">,</mo><mi id="S3.E2.m1.3.3" xref="S3.E2.m1.3.3.cmml">I</mi></mrow></mrow><mo id="S3.E2.m1.6.6.1.1.1.3" stretchy="false" xref="S3.E2.m1.6.6.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.7.7.3" xref="S3.E2.m1.7.7.3.cmml">=</mo><mrow id="S3.E2.m1.7.7.2" xref="S3.E2.m1.7.7.2.cmml"><mfrac id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml"><mn id="S3.E2.m1.1.1.3" xref="S3.E2.m1.1.1.3.cmml">1</mn><mrow id="S3.E2.m1.1.1.1.3" xref="S3.E2.m1.1.1.1.2.cmml"><mo id="S3.E2.m1.1.1.1.3.1" stretchy="false" xref="S3.E2.m1.1.1.1.2.1.cmml">|</mo><mi id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml">a</mi><mo id="S3.E2.m1.1.1.1.3.2" stretchy="false" xref="S3.E2.m1.1.1.1.2.1.cmml">|</mo></mrow></mfrac><mo id="S3.E2.m1.7.7.2.2" xref="S3.E2.m1.7.7.2.2.cmml">⁢</mo><mrow id="S3.E2.m1.7.7.2.1" xref="S3.E2.m1.7.7.2.1.cmml"><munder id="S3.E2.m1.7.7.2.1.2" xref="S3.E2.m1.7.7.2.1.2.cmml"><mo id="S3.E2.m1.7.7.2.1.2.2" movablelimits="false" xref="S3.E2.m1.7.7.2.1.2.2.cmml">∑</mo><mi id="S3.E2.m1.7.7.2.1.2.3" xref="S3.E2.m1.7.7.2.1.2.3.cmml">j</mi></munder><mrow id="S3.E2.m1.7.7.2.1.1" xref="S3.E2.m1.7.7.2.1.1.cmml"><mrow id="S3.E2.m1.7.7.2.1.1.3" xref="S3.E2.m1.7.7.2.1.1.3.cmml"><mi id="S3.E2.m1.7.7.2.1.1.3.1" xref="S3.E2.m1.7.7.2.1.1.3.1.cmml">log</mi><mo id="S3.E2.m1.7.7.2.1.1.3a" lspace="0.167em" xref="S3.E2.m1.7.7.2.1.1.3.cmml">⁡</mo><mtext id="S3.E2.m1.7.7.2.1.1.3.2" xref="S3.E2.m1.7.7.2.1.1.3.2a.cmml">LLM</mtext></mrow><mo id="S3.E2.m1.7.7.2.1.1.2" xref="S3.E2.m1.7.7.2.1.1.2.cmml">⁢</mo><mrow id="S3.E2.m1.7.7.2.1.1.1.1" xref="S3.E2.m1.7.7.2.1.1.1.1.1.cmml"><mo id="S3.E2.m1.7.7.2.1.1.1.1.2" stretchy="false" xref="S3.E2.m1.7.7.2.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.7.7.2.1.1.1.1.1" xref="S3.E2.m1.7.7.2.1.1.1.1.1.cmml"><msub id="S3.E2.m1.7.7.2.1.1.1.1.1.4" xref="S3.E2.m1.7.7.2.1.1.1.1.1.4.cmml"><mi id="S3.E2.m1.7.7.2.1.1.1.1.1.4.2" xref="S3.E2.m1.7.7.2.1.1.1.1.1.4.2.cmml">a</mi><mi id="S3.E2.m1.7.7.2.1.1.1.1.1.4.3" xref="S3.E2.m1.7.7.2.1.1.1.1.1.4.3.cmml">j</mi></msub><mo fence="false" id="S3.E2.m1.7.7.2.1.1.1.1.1.3" xref="S3.E2.m1.7.7.2.1.1.1.1.1.3.cmml">|</mo><mrow id="S3.E2.m1.7.7.2.1.1.1.1.1.2.2" xref="S3.E2.m1.7.7.2.1.1.1.1.1.2.3.cmml"><msub id="S3.E2.m1.7.7.2.1.1.1.1.1.1.1.1" xref="S3.E2.m1.7.7.2.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.7.7.2.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.7.7.2.1.1.1.1.1.1.1.1.2.cmml">s</mi><mi id="S3.E2.m1.7.7.2.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.7.7.2.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E2.m1.7.7.2.1.1.1.1.1.2.2.3" xref="S3.E2.m1.7.7.2.1.1.1.1.1.2.3.cmml">,</mo><mi id="S3.E2.m1.4.4" xref="S3.E2.m1.4.4.cmml">q</mi><mo id="S3.E2.m1.7.7.2.1.1.1.1.1.2.2.4" xref="S3.E2.m1.7.7.2.1.1.1.1.1.2.3.cmml">,</mo><mi id="S3.E2.m1.5.5" xref="S3.E2.m1.5.5.cmml">I</mi><mo id="S3.E2.m1.7.7.2.1.1.1.1.1.2.2.5" xref="S3.E2.m1.7.7.2.1.1.1.1.1.2.3.cmml">,</mo><msub id="S3.E2.m1.7.7.2.1.1.1.1.1.2.2.2" xref="S3.E2.m1.7.7.2.1.1.1.1.1.2.2.2.cmml"><mi id="S3.E2.m1.7.7.2.1.1.1.1.1.2.2.2.2" xref="S3.E2.m1.7.7.2.1.1.1.1.1.2.2.2.2.cmml">a</mi><mrow id="S3.E2.m1.7.7.2.1.1.1.1.1.2.2.2.3" xref="S3.E2.m1.7.7.2.1.1.1.1.1.2.2.2.3.cmml"><mi id="S3.E2.m1.7.7.2.1.1.1.1.1.2.2.2.3.2" xref="S3.E2.m1.7.7.2.1.1.1.1.1.2.2.2.3.2.cmml"></mi><mo id="S3.E2.m1.7.7.2.1.1.1.1.1.2.2.2.3.1" xref="S3.E2.m1.7.7.2.1.1.1.1.1.2.2.2.3.1.cmml">&lt;</mo><mi id="S3.E2.m1.7.7.2.1.1.1.1.1.2.2.2.3.3" xref="S3.E2.m1.7.7.2.1.1.1.1.1.2.2.2.3.3.cmml">j</mi></mrow></msub></mrow></mrow><mo id="S3.E2.m1.7.7.2.1.1.1.1.3" stretchy="false" xref="S3.E2.m1.7.7.2.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.7b"><apply id="S3.E2.m1.7.7.cmml" xref="S3.E2.m1.7.7"><eq id="S3.E2.m1.7.7.3.cmml" xref="S3.E2.m1.7.7.3"></eq><apply id="S3.E2.m1.6.6.1.cmml" xref="S3.E2.m1.6.6.1"><times id="S3.E2.m1.6.6.1.2.cmml" xref="S3.E2.m1.6.6.1.2"></times><apply id="S3.E2.m1.6.6.1.3.cmml" xref="S3.E2.m1.6.6.1.3"><log id="S3.E2.m1.6.6.1.3.1.cmml" xref="S3.E2.m1.6.6.1.3.1"></log><ci id="S3.E2.m1.6.6.1.3.2.cmml" xref="S3.E2.m1.6.6.1.3.2">𝑝</ci></apply><apply id="S3.E2.m1.6.6.1.1.1.1.cmml" xref="S3.E2.m1.6.6.1.1.1"><csymbol cd="latexml" id="S3.E2.m1.6.6.1.1.1.1.2.cmml" xref="S3.E2.m1.6.6.1.1.1.1.2">conditional</csymbol><ci id="S3.E2.m1.6.6.1.1.1.1.3.cmml" xref="S3.E2.m1.6.6.1.1.1.1.3">𝑎</ci><list id="S3.E2.m1.6.6.1.1.1.1.1.2.cmml" xref="S3.E2.m1.6.6.1.1.1.1.1.1"><apply id="S3.E2.m1.6.6.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.6.6.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.6.6.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.6.6.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.6.6.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.6.6.1.1.1.1.1.1.1.2">𝑠</ci><ci id="S3.E2.m1.6.6.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.6.6.1.1.1.1.1.1.1.3">𝑖</ci></apply><ci id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2">𝑞</ci><ci id="S3.E2.m1.3.3.cmml" xref="S3.E2.m1.3.3">𝐼</ci></list></apply></apply><apply id="S3.E2.m1.7.7.2.cmml" xref="S3.E2.m1.7.7.2"><times id="S3.E2.m1.7.7.2.2.cmml" xref="S3.E2.m1.7.7.2.2"></times><apply id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1"><divide id="S3.E2.m1.1.1.2.cmml" xref="S3.E2.m1.1.1"></divide><cn id="S3.E2.m1.1.1.3.cmml" type="integer" xref="S3.E2.m1.1.1.3">1</cn><apply id="S3.E2.m1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.3"><abs id="S3.E2.m1.1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.1.3.1"></abs><ci id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1">𝑎</ci></apply></apply><apply id="S3.E2.m1.7.7.2.1.cmml" xref="S3.E2.m1.7.7.2.1"><apply id="S3.E2.m1.7.7.2.1.2.cmml" xref="S3.E2.m1.7.7.2.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.2.1.2.1.cmml" xref="S3.E2.m1.7.7.2.1.2">subscript</csymbol><sum id="S3.E2.m1.7.7.2.1.2.2.cmml" xref="S3.E2.m1.7.7.2.1.2.2"></sum><ci id="S3.E2.m1.7.7.2.1.2.3.cmml" xref="S3.E2.m1.7.7.2.1.2.3">𝑗</ci></apply><apply id="S3.E2.m1.7.7.2.1.1.cmml" xref="S3.E2.m1.7.7.2.1.1"><times id="S3.E2.m1.7.7.2.1.1.2.cmml" xref="S3.E2.m1.7.7.2.1.1.2"></times><apply id="S3.E2.m1.7.7.2.1.1.3.cmml" xref="S3.E2.m1.7.7.2.1.1.3"><log id="S3.E2.m1.7.7.2.1.1.3.1.cmml" xref="S3.E2.m1.7.7.2.1.1.3.1"></log><ci id="S3.E2.m1.7.7.2.1.1.3.2a.cmml" xref="S3.E2.m1.7.7.2.1.1.3.2"><mtext id="S3.E2.m1.7.7.2.1.1.3.2.cmml" xref="S3.E2.m1.7.7.2.1.1.3.2">LLM</mtext></ci></apply><apply id="S3.E2.m1.7.7.2.1.1.1.1.1.cmml" xref="S3.E2.m1.7.7.2.1.1.1.1"><csymbol cd="latexml" id="S3.E2.m1.7.7.2.1.1.1.1.1.3.cmml" xref="S3.E2.m1.7.7.2.1.1.1.1.1.3">conditional</csymbol><apply id="S3.E2.m1.7.7.2.1.1.1.1.1.4.cmml" xref="S3.E2.m1.7.7.2.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.2.1.1.1.1.1.4.1.cmml" xref="S3.E2.m1.7.7.2.1.1.1.1.1.4">subscript</csymbol><ci id="S3.E2.m1.7.7.2.1.1.1.1.1.4.2.cmml" xref="S3.E2.m1.7.7.2.1.1.1.1.1.4.2">𝑎</ci><ci id="S3.E2.m1.7.7.2.1.1.1.1.1.4.3.cmml" xref="S3.E2.m1.7.7.2.1.1.1.1.1.4.3">𝑗</ci></apply><list id="S3.E2.m1.7.7.2.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.7.7.2.1.1.1.1.1.2.2"><apply id="S3.E2.m1.7.7.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.7.7.2.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.7.7.2.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.7.7.2.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.7.7.2.1.1.1.1.1.1.1.1.2">𝑠</ci><ci id="S3.E2.m1.7.7.2.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.7.7.2.1.1.1.1.1.1.1.1.3">𝑖</ci></apply><ci id="S3.E2.m1.4.4.cmml" xref="S3.E2.m1.4.4">𝑞</ci><ci id="S3.E2.m1.5.5.cmml" xref="S3.E2.m1.5.5">𝐼</ci><apply id="S3.E2.m1.7.7.2.1.1.1.1.1.2.2.2.cmml" xref="S3.E2.m1.7.7.2.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.2.1.1.1.1.1.2.2.2.1.cmml" xref="S3.E2.m1.7.7.2.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.E2.m1.7.7.2.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E2.m1.7.7.2.1.1.1.1.1.2.2.2.2">𝑎</ci><apply id="S3.E2.m1.7.7.2.1.1.1.1.1.2.2.2.3.cmml" xref="S3.E2.m1.7.7.2.1.1.1.1.1.2.2.2.3"><lt id="S3.E2.m1.7.7.2.1.1.1.1.1.2.2.2.3.1.cmml" xref="S3.E2.m1.7.7.2.1.1.1.1.1.2.2.2.3.1"></lt><csymbol cd="latexml" id="S3.E2.m1.7.7.2.1.1.1.1.1.2.2.2.3.2.cmml" xref="S3.E2.m1.7.7.2.1.1.1.1.1.2.2.2.3.2">absent</csymbol><ci id="S3.E2.m1.7.7.2.1.1.1.1.1.2.2.2.3.3.cmml" xref="S3.E2.m1.7.7.2.1.1.1.1.1.2.2.2.3.3">𝑗</ci></apply></apply></list></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.7c">\log p(a|s_{i},q,I)=\frac{1}{|a|}\sum_{j}\log\text{LLM}(a_{j}|s_{i},q,I,a_{&lt;j})</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.7d">roman_log italic_p ( italic_a | italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_q , italic_I ) = divide start_ARG 1 end_ARG start_ARG | italic_a | end_ARG ∑ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT roman_log LLM ( italic_a start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT | italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_q , italic_I , italic_a start_POSTSUBSCRIPT &lt; italic_j end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS1.p7">
<p class="ltx_p" id="S3.SS1.p7.4">We consider this log-likelihood as the relevance score for the candidate passage <math alttext="s_{i}" class="ltx_Math" display="inline" id="S3.SS1.p7.1.m1.1"><semantics id="S3.SS1.p7.1.m1.1a"><msub id="S3.SS1.p7.1.m1.1.1" xref="S3.SS1.p7.1.m1.1.1.cmml"><mi id="S3.SS1.p7.1.m1.1.1.2" xref="S3.SS1.p7.1.m1.1.1.2.cmml">s</mi><mi id="S3.SS1.p7.1.m1.1.1.3" xref="S3.SS1.p7.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p7.1.m1.1b"><apply id="S3.SS1.p7.1.m1.1.1.cmml" xref="S3.SS1.p7.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p7.1.m1.1.1.1.cmml" xref="S3.SS1.p7.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p7.1.m1.1.1.2.cmml" xref="S3.SS1.p7.1.m1.1.1.2">𝑠</ci><ci id="S3.SS1.p7.1.m1.1.1.3.cmml" xref="S3.SS1.p7.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p7.1.m1.1c">s_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p7.1.m1.1d">italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>. Each of the <math alttext="K" class="ltx_Math" display="inline" id="S3.SS1.p7.2.m2.1"><semantics id="S3.SS1.p7.2.m2.1a"><mi id="S3.SS1.p7.2.m2.1.1" xref="S3.SS1.p7.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p7.2.m2.1b"><ci id="S3.SS1.p7.2.m2.1.1.cmml" xref="S3.SS1.p7.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p7.2.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p7.2.m2.1d">italic_K</annotation></semantics></math> candidate passages is weakly labeled in this manner, resulting in a ranked list of passages, denoted as <math alttext="\mathcal{S}=\{s_{r_{1}},\dots,s_{r_{K}}\}" class="ltx_Math" display="inline" id="S3.SS1.p7.3.m3.3"><semantics id="S3.SS1.p7.3.m3.3a"><mrow id="S3.SS1.p7.3.m3.3.3" xref="S3.SS1.p7.3.m3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p7.3.m3.3.3.4" xref="S3.SS1.p7.3.m3.3.3.4.cmml">𝒮</mi><mo id="S3.SS1.p7.3.m3.3.3.3" xref="S3.SS1.p7.3.m3.3.3.3.cmml">=</mo><mrow id="S3.SS1.p7.3.m3.3.3.2.2" xref="S3.SS1.p7.3.m3.3.3.2.3.cmml"><mo id="S3.SS1.p7.3.m3.3.3.2.2.3" stretchy="false" xref="S3.SS1.p7.3.m3.3.3.2.3.cmml">{</mo><msub id="S3.SS1.p7.3.m3.2.2.1.1.1" xref="S3.SS1.p7.3.m3.2.2.1.1.1.cmml"><mi id="S3.SS1.p7.3.m3.2.2.1.1.1.2" xref="S3.SS1.p7.3.m3.2.2.1.1.1.2.cmml">s</mi><msub id="S3.SS1.p7.3.m3.2.2.1.1.1.3" xref="S3.SS1.p7.3.m3.2.2.1.1.1.3.cmml"><mi id="S3.SS1.p7.3.m3.2.2.1.1.1.3.2" xref="S3.SS1.p7.3.m3.2.2.1.1.1.3.2.cmml">r</mi><mn id="S3.SS1.p7.3.m3.2.2.1.1.1.3.3" xref="S3.SS1.p7.3.m3.2.2.1.1.1.3.3.cmml">1</mn></msub></msub><mo id="S3.SS1.p7.3.m3.3.3.2.2.4" xref="S3.SS1.p7.3.m3.3.3.2.3.cmml">,</mo><mi id="S3.SS1.p7.3.m3.1.1" mathvariant="normal" xref="S3.SS1.p7.3.m3.1.1.cmml">…</mi><mo id="S3.SS1.p7.3.m3.3.3.2.2.5" xref="S3.SS1.p7.3.m3.3.3.2.3.cmml">,</mo><msub id="S3.SS1.p7.3.m3.3.3.2.2.2" xref="S3.SS1.p7.3.m3.3.3.2.2.2.cmml"><mi id="S3.SS1.p7.3.m3.3.3.2.2.2.2" xref="S3.SS1.p7.3.m3.3.3.2.2.2.2.cmml">s</mi><msub id="S3.SS1.p7.3.m3.3.3.2.2.2.3" xref="S3.SS1.p7.3.m3.3.3.2.2.2.3.cmml"><mi id="S3.SS1.p7.3.m3.3.3.2.2.2.3.2" xref="S3.SS1.p7.3.m3.3.3.2.2.2.3.2.cmml">r</mi><mi id="S3.SS1.p7.3.m3.3.3.2.2.2.3.3" xref="S3.SS1.p7.3.m3.3.3.2.2.2.3.3.cmml">K</mi></msub></msub><mo id="S3.SS1.p7.3.m3.3.3.2.2.6" stretchy="false" xref="S3.SS1.p7.3.m3.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p7.3.m3.3b"><apply id="S3.SS1.p7.3.m3.3.3.cmml" xref="S3.SS1.p7.3.m3.3.3"><eq id="S3.SS1.p7.3.m3.3.3.3.cmml" xref="S3.SS1.p7.3.m3.3.3.3"></eq><ci id="S3.SS1.p7.3.m3.3.3.4.cmml" xref="S3.SS1.p7.3.m3.3.3.4">𝒮</ci><set id="S3.SS1.p7.3.m3.3.3.2.3.cmml" xref="S3.SS1.p7.3.m3.3.3.2.2"><apply id="S3.SS1.p7.3.m3.2.2.1.1.1.cmml" xref="S3.SS1.p7.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p7.3.m3.2.2.1.1.1.1.cmml" xref="S3.SS1.p7.3.m3.2.2.1.1.1">subscript</csymbol><ci id="S3.SS1.p7.3.m3.2.2.1.1.1.2.cmml" xref="S3.SS1.p7.3.m3.2.2.1.1.1.2">𝑠</ci><apply id="S3.SS1.p7.3.m3.2.2.1.1.1.3.cmml" xref="S3.SS1.p7.3.m3.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p7.3.m3.2.2.1.1.1.3.1.cmml" xref="S3.SS1.p7.3.m3.2.2.1.1.1.3">subscript</csymbol><ci id="S3.SS1.p7.3.m3.2.2.1.1.1.3.2.cmml" xref="S3.SS1.p7.3.m3.2.2.1.1.1.3.2">𝑟</ci><cn id="S3.SS1.p7.3.m3.2.2.1.1.1.3.3.cmml" type="integer" xref="S3.SS1.p7.3.m3.2.2.1.1.1.3.3">1</cn></apply></apply><ci id="S3.SS1.p7.3.m3.1.1.cmml" xref="S3.SS1.p7.3.m3.1.1">…</ci><apply id="S3.SS1.p7.3.m3.3.3.2.2.2.cmml" xref="S3.SS1.p7.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p7.3.m3.3.3.2.2.2.1.cmml" xref="S3.SS1.p7.3.m3.3.3.2.2.2">subscript</csymbol><ci id="S3.SS1.p7.3.m3.3.3.2.2.2.2.cmml" xref="S3.SS1.p7.3.m3.3.3.2.2.2.2">𝑠</ci><apply id="S3.SS1.p7.3.m3.3.3.2.2.2.3.cmml" xref="S3.SS1.p7.3.m3.3.3.2.2.2.3"><csymbol cd="ambiguous" id="S3.SS1.p7.3.m3.3.3.2.2.2.3.1.cmml" xref="S3.SS1.p7.3.m3.3.3.2.2.2.3">subscript</csymbol><ci id="S3.SS1.p7.3.m3.3.3.2.2.2.3.2.cmml" xref="S3.SS1.p7.3.m3.3.3.2.2.2.3.2">𝑟</ci><ci id="S3.SS1.p7.3.m3.3.3.2.2.2.3.3.cmml" xref="S3.SS1.p7.3.m3.3.3.2.2.2.3.3">𝐾</ci></apply></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p7.3.m3.3c">\mathcal{S}=\{s_{r_{1}},\dots,s_{r_{K}}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p7.3.m3.3d">caligraphic_S = { italic_s start_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , … , italic_s start_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT italic_K end_POSTSUBSCRIPT end_POSTSUBSCRIPT }</annotation></semantics></math>. This list is produced by sorting the set of candidate passages <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S3.SS1.p7.4.m4.1"><semantics id="S3.SS1.p7.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p7.4.m4.1.1" xref="S3.SS1.p7.4.m4.1.1.cmml">𝒮</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p7.4.m4.1b"><ci id="S3.SS1.p7.4.m4.1.1.cmml" xref="S3.SS1.p7.4.m4.1.1">𝒮</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p7.4.m4.1c">\mathcal{S}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p7.4.m4.1d">caligraphic_S</annotation></semantics></math> according to their relevance scores.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Training Dense Retriever</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.2">Once we have accumulated a sufficient number of weakly labeled passages for a total of <math alttext="M" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">italic_M</annotation></semantics></math> question-answer pairs, denoted as <math alttext="\mathcal{W}=\{\mathcal{S}_{1},\dots,\mathcal{S}_{M}\}" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.3"><semantics id="S3.SS2.p1.2.m2.3a"><mrow id="S3.SS2.p1.2.m2.3.3" xref="S3.SS2.p1.2.m2.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.2.m2.3.3.4" xref="S3.SS2.p1.2.m2.3.3.4.cmml">𝒲</mi><mo id="S3.SS2.p1.2.m2.3.3.3" xref="S3.SS2.p1.2.m2.3.3.3.cmml">=</mo><mrow id="S3.SS2.p1.2.m2.3.3.2.2" xref="S3.SS2.p1.2.m2.3.3.2.3.cmml"><mo id="S3.SS2.p1.2.m2.3.3.2.2.3" stretchy="false" xref="S3.SS2.p1.2.m2.3.3.2.3.cmml">{</mo><msub id="S3.SS2.p1.2.m2.2.2.1.1.1" xref="S3.SS2.p1.2.m2.2.2.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.2.m2.2.2.1.1.1.2" xref="S3.SS2.p1.2.m2.2.2.1.1.1.2.cmml">𝒮</mi><mn id="S3.SS2.p1.2.m2.2.2.1.1.1.3" xref="S3.SS2.p1.2.m2.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS2.p1.2.m2.3.3.2.2.4" xref="S3.SS2.p1.2.m2.3.3.2.3.cmml">,</mo><mi id="S3.SS2.p1.2.m2.1.1" mathvariant="normal" xref="S3.SS2.p1.2.m2.1.1.cmml">…</mi><mo id="S3.SS2.p1.2.m2.3.3.2.2.5" xref="S3.SS2.p1.2.m2.3.3.2.3.cmml">,</mo><msub id="S3.SS2.p1.2.m2.3.3.2.2.2" xref="S3.SS2.p1.2.m2.3.3.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.2.m2.3.3.2.2.2.2" xref="S3.SS2.p1.2.m2.3.3.2.2.2.2.cmml">𝒮</mi><mi id="S3.SS2.p1.2.m2.3.3.2.2.2.3" xref="S3.SS2.p1.2.m2.3.3.2.2.2.3.cmml">M</mi></msub><mo id="S3.SS2.p1.2.m2.3.3.2.2.6" stretchy="false" xref="S3.SS2.p1.2.m2.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.3b"><apply id="S3.SS2.p1.2.m2.3.3.cmml" xref="S3.SS2.p1.2.m2.3.3"><eq id="S3.SS2.p1.2.m2.3.3.3.cmml" xref="S3.SS2.p1.2.m2.3.3.3"></eq><ci id="S3.SS2.p1.2.m2.3.3.4.cmml" xref="S3.SS2.p1.2.m2.3.3.4">𝒲</ci><set id="S3.SS2.p1.2.m2.3.3.2.3.cmml" xref="S3.SS2.p1.2.m2.3.3.2.2"><apply id="S3.SS2.p1.2.m2.2.2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.2.2.1.1.1.1.cmml" xref="S3.SS2.p1.2.m2.2.2.1.1.1">subscript</csymbol><ci id="S3.SS2.p1.2.m2.2.2.1.1.1.2.cmml" xref="S3.SS2.p1.2.m2.2.2.1.1.1.2">𝒮</ci><cn id="S3.SS2.p1.2.m2.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS2.p1.2.m2.2.2.1.1.1.3">1</cn></apply><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">…</ci><apply id="S3.SS2.p1.2.m2.3.3.2.2.2.cmml" xref="S3.SS2.p1.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.3.3.2.2.2.1.cmml" xref="S3.SS2.p1.2.m2.3.3.2.2.2">subscript</csymbol><ci id="S3.SS2.p1.2.m2.3.3.2.2.2.2.cmml" xref="S3.SS2.p1.2.m2.3.3.2.2.2.2">𝒮</ci><ci id="S3.SS2.p1.2.m2.3.3.2.2.2.3.cmml" xref="S3.SS2.p1.2.m2.3.3.2.2.2.3">𝑀</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.3c">\mathcal{W}=\{\mathcal{S}_{1},\dots,\mathcal{S}_{M}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.3d">caligraphic_W = { caligraphic_S start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , caligraphic_S start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT }</annotation></semantics></math>, we are ready to train a dense retriever that will assign higher scores to passages more likely to elicit the correct answer. In principle, any dense retriever, regardless of the specific objective function, can be trained using the generated weak labels. In this paper, we investigate two representative dense retrievers: DPR <cite class="ltx_cite ltx_citemacro_citep">(Karpukhin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib20" title="">2020a</a>)</cite> and ColBERT <cite class="ltx_cite ltx_citemacro_citep">(Khattab and Zaharia, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib23" title="">2020b</a>)</cite>.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1. </span><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.1.1">DPR</span>
</h4>
<div class="ltx_para" id="S3.SS2.SSS1.p1">
<p class="ltx_p" id="S3.SS2.SSS1.p1.5">DPR utilizes a bi-encoder architecture, where the question and passage are independently mapped to an embedding space through two separate BERT encoders. For a given question <math alttext="q" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p1.1.m1.1"><semantics id="S3.SS2.SSS1.p1.1.m1.1a"><mi id="S3.SS2.SSS1.p1.1.m1.1.1" xref="S3.SS2.SSS1.p1.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.1.m1.1b"><ci id="S3.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.1.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p1.1.m1.1d">italic_q</annotation></semantics></math>, the relevance score <math alttext="R_{q,s}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p1.2.m2.2"><semantics id="S3.SS2.SSS1.p1.2.m2.2a"><msub id="S3.SS2.SSS1.p1.2.m2.2.3" xref="S3.SS2.SSS1.p1.2.m2.2.3.cmml"><mi id="S3.SS2.SSS1.p1.2.m2.2.3.2" xref="S3.SS2.SSS1.p1.2.m2.2.3.2.cmml">R</mi><mrow id="S3.SS2.SSS1.p1.2.m2.2.2.2.4" xref="S3.SS2.SSS1.p1.2.m2.2.2.2.3.cmml"><mi id="S3.SS2.SSS1.p1.2.m2.1.1.1.1" xref="S3.SS2.SSS1.p1.2.m2.1.1.1.1.cmml">q</mi><mo id="S3.SS2.SSS1.p1.2.m2.2.2.2.4.1" xref="S3.SS2.SSS1.p1.2.m2.2.2.2.3.cmml">,</mo><mi id="S3.SS2.SSS1.p1.2.m2.2.2.2.2" xref="S3.SS2.SSS1.p1.2.m2.2.2.2.2.cmml">s</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.2.m2.2b"><apply id="S3.SS2.SSS1.p1.2.m2.2.3.cmml" xref="S3.SS2.SSS1.p1.2.m2.2.3"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.2.m2.2.3.1.cmml" xref="S3.SS2.SSS1.p1.2.m2.2.3">subscript</csymbol><ci id="S3.SS2.SSS1.p1.2.m2.2.3.2.cmml" xref="S3.SS2.SSS1.p1.2.m2.2.3.2">𝑅</ci><list id="S3.SS2.SSS1.p1.2.m2.2.2.2.3.cmml" xref="S3.SS2.SSS1.p1.2.m2.2.2.2.4"><ci id="S3.SS2.SSS1.p1.2.m2.1.1.1.1.cmml" xref="S3.SS2.SSS1.p1.2.m2.1.1.1.1">𝑞</ci><ci id="S3.SS2.SSS1.p1.2.m2.2.2.2.2.cmml" xref="S3.SS2.SSS1.p1.2.m2.2.2.2.2">𝑠</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.2.m2.2c">R_{q,s}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p1.2.m2.2d">italic_R start_POSTSUBSCRIPT italic_q , italic_s end_POSTSUBSCRIPT</annotation></semantics></math> for each passage <math alttext="s" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p1.3.m3.1"><semantics id="S3.SS2.SSS1.p1.3.m3.1a"><mi id="S3.SS2.SSS1.p1.3.m3.1.1" xref="S3.SS2.SSS1.p1.3.m3.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.3.m3.1b"><ci id="S3.SS2.SSS1.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.3.m3.1c">s</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p1.3.m3.1d">italic_s</annotation></semantics></math> is given by the similarity between their respective <span class="ltx_text ltx_font_typewriter" id="S3.SS2.SSS1.p1.5.1">[CLS]</span> token embeddings, <math alttext="\mathbf{e}_{q}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p1.4.m4.1"><semantics id="S3.SS2.SSS1.p1.4.m4.1a"><msub id="S3.SS2.SSS1.p1.4.m4.1.1" xref="S3.SS2.SSS1.p1.4.m4.1.1.cmml"><mi id="S3.SS2.SSS1.p1.4.m4.1.1.2" xref="S3.SS2.SSS1.p1.4.m4.1.1.2.cmml">𝐞</mi><mi id="S3.SS2.SSS1.p1.4.m4.1.1.3" xref="S3.SS2.SSS1.p1.4.m4.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.4.m4.1b"><apply id="S3.SS2.SSS1.p1.4.m4.1.1.cmml" xref="S3.SS2.SSS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.4.m4.1.1.1.cmml" xref="S3.SS2.SSS1.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p1.4.m4.1.1.2.cmml" xref="S3.SS2.SSS1.p1.4.m4.1.1.2">𝐞</ci><ci id="S3.SS2.SSS1.p1.4.m4.1.1.3.cmml" xref="S3.SS2.SSS1.p1.4.m4.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.4.m4.1c">\mathbf{e}_{q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p1.4.m4.1d">bold_e start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\mathbf{e}_{s}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p1.5.m5.1"><semantics id="S3.SS2.SSS1.p1.5.m5.1a"><msub id="S3.SS2.SSS1.p1.5.m5.1.1" xref="S3.SS2.SSS1.p1.5.m5.1.1.cmml"><mi id="S3.SS2.SSS1.p1.5.m5.1.1.2" xref="S3.SS2.SSS1.p1.5.m5.1.1.2.cmml">𝐞</mi><mi id="S3.SS2.SSS1.p1.5.m5.1.1.3" xref="S3.SS2.SSS1.p1.5.m5.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.5.m5.1b"><apply id="S3.SS2.SSS1.p1.5.m5.1.1.cmml" xref="S3.SS2.SSS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.5.m5.1.1.1.cmml" xref="S3.SS2.SSS1.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p1.5.m5.1.1.2.cmml" xref="S3.SS2.SSS1.p1.5.m5.1.1.2">𝐞</ci><ci id="S3.SS2.SSS1.p1.5.m5.1.1.3.cmml" xref="S3.SS2.SSS1.p1.5.m5.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.5.m5.1c">\mathbf{e}_{s}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p1.5.m5.1d">bold_e start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math>. We use cosine similarity as the similarity function:</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p2">
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(3)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="R_{q,s}=\cos(\mathbf{e}_{q},\mathbf{e}_{s})" class="ltx_Math" display="block" id="S3.E3.m1.5"><semantics id="S3.E3.m1.5a"><mrow id="S3.E3.m1.5.5" xref="S3.E3.m1.5.5.cmml"><msub id="S3.E3.m1.5.5.4" xref="S3.E3.m1.5.5.4.cmml"><mi id="S3.E3.m1.5.5.4.2" xref="S3.E3.m1.5.5.4.2.cmml">R</mi><mrow id="S3.E3.m1.2.2.2.4" xref="S3.E3.m1.2.2.2.3.cmml"><mi id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml">q</mi><mo id="S3.E3.m1.2.2.2.4.1" xref="S3.E3.m1.2.2.2.3.cmml">,</mo><mi id="S3.E3.m1.2.2.2.2" xref="S3.E3.m1.2.2.2.2.cmml">s</mi></mrow></msub><mo id="S3.E3.m1.5.5.3" xref="S3.E3.m1.5.5.3.cmml">=</mo><mrow id="S3.E3.m1.5.5.2.2" xref="S3.E3.m1.5.5.2.3.cmml"><mi id="S3.E3.m1.3.3" xref="S3.E3.m1.3.3.cmml">cos</mi><mo id="S3.E3.m1.5.5.2.2a" xref="S3.E3.m1.5.5.2.3.cmml">⁡</mo><mrow id="S3.E3.m1.5.5.2.2.2" xref="S3.E3.m1.5.5.2.3.cmml"><mo id="S3.E3.m1.5.5.2.2.2.3" stretchy="false" xref="S3.E3.m1.5.5.2.3.cmml">(</mo><msub id="S3.E3.m1.4.4.1.1.1.1" xref="S3.E3.m1.4.4.1.1.1.1.cmml"><mi id="S3.E3.m1.4.4.1.1.1.1.2" xref="S3.E3.m1.4.4.1.1.1.1.2.cmml">𝐞</mi><mi id="S3.E3.m1.4.4.1.1.1.1.3" xref="S3.E3.m1.4.4.1.1.1.1.3.cmml">q</mi></msub><mo id="S3.E3.m1.5.5.2.2.2.4" xref="S3.E3.m1.5.5.2.3.cmml">,</mo><msub id="S3.E3.m1.5.5.2.2.2.2" xref="S3.E3.m1.5.5.2.2.2.2.cmml"><mi id="S3.E3.m1.5.5.2.2.2.2.2" xref="S3.E3.m1.5.5.2.2.2.2.2.cmml">𝐞</mi><mi id="S3.E3.m1.5.5.2.2.2.2.3" xref="S3.E3.m1.5.5.2.2.2.2.3.cmml">s</mi></msub><mo id="S3.E3.m1.5.5.2.2.2.5" stretchy="false" xref="S3.E3.m1.5.5.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.5b"><apply id="S3.E3.m1.5.5.cmml" xref="S3.E3.m1.5.5"><eq id="S3.E3.m1.5.5.3.cmml" xref="S3.E3.m1.5.5.3"></eq><apply id="S3.E3.m1.5.5.4.cmml" xref="S3.E3.m1.5.5.4"><csymbol cd="ambiguous" id="S3.E3.m1.5.5.4.1.cmml" xref="S3.E3.m1.5.5.4">subscript</csymbol><ci id="S3.E3.m1.5.5.4.2.cmml" xref="S3.E3.m1.5.5.4.2">𝑅</ci><list id="S3.E3.m1.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.4"><ci id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1">𝑞</ci><ci id="S3.E3.m1.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2">𝑠</ci></list></apply><apply id="S3.E3.m1.5.5.2.3.cmml" xref="S3.E3.m1.5.5.2.2"><cos id="S3.E3.m1.3.3.cmml" xref="S3.E3.m1.3.3"></cos><apply id="S3.E3.m1.4.4.1.1.1.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.1.1.1.1.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.4.4.1.1.1.1.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2">𝐞</ci><ci id="S3.E3.m1.4.4.1.1.1.1.3.cmml" xref="S3.E3.m1.4.4.1.1.1.1.3">𝑞</ci></apply><apply id="S3.E3.m1.5.5.2.2.2.2.cmml" xref="S3.E3.m1.5.5.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.5.5.2.2.2.2.1.cmml" xref="S3.E3.m1.5.5.2.2.2.2">subscript</csymbol><ci id="S3.E3.m1.5.5.2.2.2.2.2.cmml" xref="S3.E3.m1.5.5.2.2.2.2.2">𝐞</ci><ci id="S3.E3.m1.5.5.2.2.2.2.3.cmml" xref="S3.E3.m1.5.5.2.2.2.2.3">𝑠</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.5c">R_{q,s}=\cos(\mathbf{e}_{q},\mathbf{e}_{s})</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.5d">italic_R start_POSTSUBSCRIPT italic_q , italic_s end_POSTSUBSCRIPT = roman_cos ( bold_e start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT , bold_e start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p3">
<p class="ltx_p" id="S3.SS2.SSS1.p3.6">Following the in-batch negative training method introduced in DPR, we process each ranked list <math alttext="\mathcal{S}\in\mathcal{W}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.1.m1.1"><semantics id="S3.SS2.SSS1.p3.1.m1.1a"><mrow id="S3.SS2.SSS1.p3.1.m1.1.1" xref="S3.SS2.SSS1.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS1.p3.1.m1.1.1.2" xref="S3.SS2.SSS1.p3.1.m1.1.1.2.cmml">𝒮</mi><mo id="S3.SS2.SSS1.p3.1.m1.1.1.1" xref="S3.SS2.SSS1.p3.1.m1.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS1.p3.1.m1.1.1.3" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.cmml">𝒲</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.1.m1.1b"><apply id="S3.SS2.SSS1.p3.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1"><in id="S3.SS2.SSS1.p3.1.m1.1.1.1.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.1"></in><ci id="S3.SS2.SSS1.p3.1.m1.1.1.2.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.2">𝒮</ci><ci id="S3.SS2.SSS1.p3.1.m1.1.1.3.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.3">𝒲</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.1.m1.1c">\mathcal{S}\in\mathcal{W}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.1.m1.1d">caligraphic_S ∈ caligraphic_W</annotation></semantics></math> by extracting the top-ranked passage <math alttext="s_{i}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.2.m2.1"><semantics id="S3.SS2.SSS1.p3.2.m2.1a"><msub id="S3.SS2.SSS1.p3.2.m2.1.1" xref="S3.SS2.SSS1.p3.2.m2.1.1.cmml"><mi id="S3.SS2.SSS1.p3.2.m2.1.1.2" xref="S3.SS2.SSS1.p3.2.m2.1.1.2.cmml">s</mi><mi id="S3.SS2.SSS1.p3.2.m2.1.1.3" xref="S3.SS2.SSS1.p3.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.2.m2.1b"><apply id="S3.SS2.SSS1.p3.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.2.m2.1.1.1.cmml" xref="S3.SS2.SSS1.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p3.2.m2.1.1.2.cmml" xref="S3.SS2.SSS1.p3.2.m2.1.1.2">𝑠</ci><ci id="S3.SS2.SSS1.p3.2.m2.1.1.3.cmml" xref="S3.SS2.SSS1.p3.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.2.m2.1c">s_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.2.m2.1d">italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> along with its associated question <math alttext="q_{i}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.3.m3.1"><semantics id="S3.SS2.SSS1.p3.3.m3.1a"><msub id="S3.SS2.SSS1.p3.3.m3.1.1" xref="S3.SS2.SSS1.p3.3.m3.1.1.cmml"><mi id="S3.SS2.SSS1.p3.3.m3.1.1.2" xref="S3.SS2.SSS1.p3.3.m3.1.1.2.cmml">q</mi><mi id="S3.SS2.SSS1.p3.3.m3.1.1.3" xref="S3.SS2.SSS1.p3.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.3.m3.1b"><apply id="S3.SS2.SSS1.p3.3.m3.1.1.cmml" xref="S3.SS2.SSS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.3.m3.1.1.1.cmml" xref="S3.SS2.SSS1.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p3.3.m3.1.1.2.cmml" xref="S3.SS2.SSS1.p3.3.m3.1.1.2">𝑞</ci><ci id="S3.SS2.SSS1.p3.3.m3.1.1.3.cmml" xref="S3.SS2.SSS1.p3.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.3.m3.1c">q_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.3.m3.1d">italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>. These pairs are then grouped into batches of size <math alttext="n" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.4.m4.1"><semantics id="S3.SS2.SSS1.p3.4.m4.1a"><mi id="S3.SS2.SSS1.p3.4.m4.1.1" xref="S3.SS2.SSS1.p3.4.m4.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.4.m4.1b"><ci id="S3.SS2.SSS1.p3.4.m4.1.1.cmml" xref="S3.SS2.SSS1.p3.4.m4.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.4.m4.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.4.m4.1d">italic_n</annotation></semantics></math> to form training batches, optimizing the retriever using a Multiple Negatives Ranking (MNR) loss <cite class="ltx_cite ltx_citemacro_citep">(Henderson et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib13" title="">2017</a>)</cite>. In this approach, for the <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.5.m5.1"><semantics id="S3.SS2.SSS1.p3.5.m5.1a"><mi id="S3.SS2.SSS1.p3.5.m5.1.1" xref="S3.SS2.SSS1.p3.5.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.5.m5.1b"><ci id="S3.SS2.SSS1.p3.5.m5.1.1.cmml" xref="S3.SS2.SSS1.p3.5.m5.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.5.m5.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.5.m5.1d">italic_i</annotation></semantics></math>th question-passage pair, <math alttext="s_{i}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.6.m6.1"><semantics id="S3.SS2.SSS1.p3.6.m6.1a"><msub id="S3.SS2.SSS1.p3.6.m6.1.1" xref="S3.SS2.SSS1.p3.6.m6.1.1.cmml"><mi id="S3.SS2.SSS1.p3.6.m6.1.1.2" xref="S3.SS2.SSS1.p3.6.m6.1.1.2.cmml">s</mi><mi id="S3.SS2.SSS1.p3.6.m6.1.1.3" xref="S3.SS2.SSS1.p3.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.6.m6.1b"><apply id="S3.SS2.SSS1.p3.6.m6.1.1.cmml" xref="S3.SS2.SSS1.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.6.m6.1.1.1.cmml" xref="S3.SS2.SSS1.p3.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p3.6.m6.1.1.2.cmml" xref="S3.SS2.SSS1.p3.6.m6.1.1.2">𝑠</ci><ci id="S3.SS2.SSS1.p3.6.m6.1.1.3.cmml" xref="S3.SS2.SSS1.p3.6.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.6.m6.1c">s_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.6.m6.1d">italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is treated as the positive example, while the other passages within the same batch are treated as negative examples. The loss function is thus:</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p4">
<table class="ltx_equation ltx_eqn_table" id="S3.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(4)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{MNR}=-\sum_{i=1}^{n}\log(\frac{\exp(\alpha\cdot R_{q_{i},s_{i}})}%
{\sum_{j=1}^{n}\exp(\alpha\cdot R_{q_{i},s_{j}})})" class="ltx_Math" display="block" id="S3.E4.m1.9"><semantics id="S3.E4.m1.9a"><mrow id="S3.E4.m1.9.10" xref="S3.E4.m1.9.10.cmml"><msub id="S3.E4.m1.9.10.2" xref="S3.E4.m1.9.10.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E4.m1.9.10.2.2" xref="S3.E4.m1.9.10.2.2.cmml">ℒ</mi><mrow id="S3.E4.m1.9.10.2.3" xref="S3.E4.m1.9.10.2.3.cmml"><mi id="S3.E4.m1.9.10.2.3.2" xref="S3.E4.m1.9.10.2.3.2.cmml">M</mi><mo id="S3.E4.m1.9.10.2.3.1" xref="S3.E4.m1.9.10.2.3.1.cmml">⁢</mo><mi id="S3.E4.m1.9.10.2.3.3" xref="S3.E4.m1.9.10.2.3.3.cmml">N</mi><mo id="S3.E4.m1.9.10.2.3.1a" xref="S3.E4.m1.9.10.2.3.1.cmml">⁢</mo><mi id="S3.E4.m1.9.10.2.3.4" xref="S3.E4.m1.9.10.2.3.4.cmml">R</mi></mrow></msub><mo id="S3.E4.m1.9.10.1" xref="S3.E4.m1.9.10.1.cmml">=</mo><mrow id="S3.E4.m1.9.10.3" xref="S3.E4.m1.9.10.3.cmml"><mo id="S3.E4.m1.9.10.3a" xref="S3.E4.m1.9.10.3.cmml">−</mo><mrow id="S3.E4.m1.9.10.3.2" xref="S3.E4.m1.9.10.3.2.cmml"><munderover id="S3.E4.m1.9.10.3.2.1" xref="S3.E4.m1.9.10.3.2.1.cmml"><mo id="S3.E4.m1.9.10.3.2.1.2.2" movablelimits="false" xref="S3.E4.m1.9.10.3.2.1.2.2.cmml">∑</mo><mrow id="S3.E4.m1.9.10.3.2.1.2.3" xref="S3.E4.m1.9.10.3.2.1.2.3.cmml"><mi id="S3.E4.m1.9.10.3.2.1.2.3.2" xref="S3.E4.m1.9.10.3.2.1.2.3.2.cmml">i</mi><mo id="S3.E4.m1.9.10.3.2.1.2.3.1" xref="S3.E4.m1.9.10.3.2.1.2.3.1.cmml">=</mo><mn id="S3.E4.m1.9.10.3.2.1.2.3.3" xref="S3.E4.m1.9.10.3.2.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E4.m1.9.10.3.2.1.3" xref="S3.E4.m1.9.10.3.2.1.3.cmml">n</mi></munderover><mrow id="S3.E4.m1.9.10.3.2.2.2" xref="S3.E4.m1.9.10.3.2.2.1.cmml"><mi id="S3.E4.m1.9.9" xref="S3.E4.m1.9.9.cmml">log</mi><mo id="S3.E4.m1.9.10.3.2.2.2a" xref="S3.E4.m1.9.10.3.2.2.1.cmml">⁡</mo><mrow id="S3.E4.m1.9.10.3.2.2.2.1" xref="S3.E4.m1.9.10.3.2.2.1.cmml"><mo id="S3.E4.m1.9.10.3.2.2.2.1.1" stretchy="false" xref="S3.E4.m1.9.10.3.2.2.1.cmml">(</mo><mfrac id="S3.E4.m1.8.8" xref="S3.E4.m1.8.8.cmml"><mrow id="S3.E4.m1.4.4.4.4" xref="S3.E4.m1.4.4.4.5.cmml"><mi id="S3.E4.m1.3.3.3.3" xref="S3.E4.m1.3.3.3.3.cmml">exp</mi><mo id="S3.E4.m1.4.4.4.4a" xref="S3.E4.m1.4.4.4.5.cmml">⁡</mo><mrow id="S3.E4.m1.4.4.4.4.1" xref="S3.E4.m1.4.4.4.5.cmml"><mo id="S3.E4.m1.4.4.4.4.1.2" stretchy="false" xref="S3.E4.m1.4.4.4.5.cmml">(</mo><mrow id="S3.E4.m1.4.4.4.4.1.1" xref="S3.E4.m1.4.4.4.4.1.1.cmml"><mi id="S3.E4.m1.4.4.4.4.1.1.2" xref="S3.E4.m1.4.4.4.4.1.1.2.cmml">α</mi><mo id="S3.E4.m1.4.4.4.4.1.1.1" lspace="0.222em" rspace="0.222em" xref="S3.E4.m1.4.4.4.4.1.1.1.cmml">⋅</mo><msub id="S3.E4.m1.4.4.4.4.1.1.3" xref="S3.E4.m1.4.4.4.4.1.1.3.cmml"><mi id="S3.E4.m1.4.4.4.4.1.1.3.2" xref="S3.E4.m1.4.4.4.4.1.1.3.2.cmml">R</mi><mrow id="S3.E4.m1.2.2.2.2.2.2" xref="S3.E4.m1.2.2.2.2.2.3.cmml"><msub id="S3.E4.m1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.2.cmml">q</mi><mi id="S3.E4.m1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E4.m1.2.2.2.2.2.2.3" xref="S3.E4.m1.2.2.2.2.2.3.cmml">,</mo><msub id="S3.E4.m1.2.2.2.2.2.2.2" xref="S3.E4.m1.2.2.2.2.2.2.2.cmml"><mi id="S3.E4.m1.2.2.2.2.2.2.2.2" xref="S3.E4.m1.2.2.2.2.2.2.2.2.cmml">s</mi><mi id="S3.E4.m1.2.2.2.2.2.2.2.3" xref="S3.E4.m1.2.2.2.2.2.2.2.3.cmml">i</mi></msub></mrow></msub></mrow><mo id="S3.E4.m1.4.4.4.4.1.3" stretchy="false" xref="S3.E4.m1.4.4.4.5.cmml">)</mo></mrow></mrow><mrow id="S3.E4.m1.8.8.8" xref="S3.E4.m1.8.8.8.cmml"><msubsup id="S3.E4.m1.8.8.8.5" xref="S3.E4.m1.8.8.8.5.cmml"><mo id="S3.E4.m1.8.8.8.5.2.2" xref="S3.E4.m1.8.8.8.5.2.2.cmml">∑</mo><mrow id="S3.E4.m1.8.8.8.5.2.3" xref="S3.E4.m1.8.8.8.5.2.3.cmml"><mi id="S3.E4.m1.8.8.8.5.2.3.2" xref="S3.E4.m1.8.8.8.5.2.3.2.cmml">j</mi><mo id="S3.E4.m1.8.8.8.5.2.3.1" xref="S3.E4.m1.8.8.8.5.2.3.1.cmml">=</mo><mn id="S3.E4.m1.8.8.8.5.2.3.3" xref="S3.E4.m1.8.8.8.5.2.3.3.cmml">1</mn></mrow><mi id="S3.E4.m1.8.8.8.5.3" xref="S3.E4.m1.8.8.8.5.3.cmml">n</mi></msubsup><mrow id="S3.E4.m1.8.8.8.4.1" xref="S3.E4.m1.8.8.8.4.2.cmml"><mi id="S3.E4.m1.7.7.7.3" xref="S3.E4.m1.7.7.7.3.cmml">exp</mi><mo id="S3.E4.m1.8.8.8.4.1a" xref="S3.E4.m1.8.8.8.4.2.cmml">⁡</mo><mrow id="S3.E4.m1.8.8.8.4.1.1" xref="S3.E4.m1.8.8.8.4.2.cmml"><mo id="S3.E4.m1.8.8.8.4.1.1.2" stretchy="false" xref="S3.E4.m1.8.8.8.4.2.cmml">(</mo><mrow id="S3.E4.m1.8.8.8.4.1.1.1" xref="S3.E4.m1.8.8.8.4.1.1.1.cmml"><mi id="S3.E4.m1.8.8.8.4.1.1.1.2" xref="S3.E4.m1.8.8.8.4.1.1.1.2.cmml">α</mi><mo id="S3.E4.m1.8.8.8.4.1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S3.E4.m1.8.8.8.4.1.1.1.1.cmml">⋅</mo><msub id="S3.E4.m1.8.8.8.4.1.1.1.3" xref="S3.E4.m1.8.8.8.4.1.1.1.3.cmml"><mi id="S3.E4.m1.8.8.8.4.1.1.1.3.2" xref="S3.E4.m1.8.8.8.4.1.1.1.3.2.cmml">R</mi><mrow id="S3.E4.m1.6.6.6.2.2.2" xref="S3.E4.m1.6.6.6.2.2.3.cmml"><msub id="S3.E4.m1.5.5.5.1.1.1.1" xref="S3.E4.m1.5.5.5.1.1.1.1.cmml"><mi id="S3.E4.m1.5.5.5.1.1.1.1.2" xref="S3.E4.m1.5.5.5.1.1.1.1.2.cmml">q</mi><mi id="S3.E4.m1.5.5.5.1.1.1.1.3" xref="S3.E4.m1.5.5.5.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E4.m1.6.6.6.2.2.2.3" xref="S3.E4.m1.6.6.6.2.2.3.cmml">,</mo><msub id="S3.E4.m1.6.6.6.2.2.2.2" xref="S3.E4.m1.6.6.6.2.2.2.2.cmml"><mi id="S3.E4.m1.6.6.6.2.2.2.2.2" xref="S3.E4.m1.6.6.6.2.2.2.2.2.cmml">s</mi><mi id="S3.E4.m1.6.6.6.2.2.2.2.3" xref="S3.E4.m1.6.6.6.2.2.2.2.3.cmml">j</mi></msub></mrow></msub></mrow><mo id="S3.E4.m1.8.8.8.4.1.1.3" stretchy="false" xref="S3.E4.m1.8.8.8.4.2.cmml">)</mo></mrow></mrow></mrow></mfrac><mo id="S3.E4.m1.9.10.3.2.2.2.1.2" stretchy="false" xref="S3.E4.m1.9.10.3.2.2.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.9b"><apply id="S3.E4.m1.9.10.cmml" xref="S3.E4.m1.9.10"><eq id="S3.E4.m1.9.10.1.cmml" xref="S3.E4.m1.9.10.1"></eq><apply id="S3.E4.m1.9.10.2.cmml" xref="S3.E4.m1.9.10.2"><csymbol cd="ambiguous" id="S3.E4.m1.9.10.2.1.cmml" xref="S3.E4.m1.9.10.2">subscript</csymbol><ci id="S3.E4.m1.9.10.2.2.cmml" xref="S3.E4.m1.9.10.2.2">ℒ</ci><apply id="S3.E4.m1.9.10.2.3.cmml" xref="S3.E4.m1.9.10.2.3"><times id="S3.E4.m1.9.10.2.3.1.cmml" xref="S3.E4.m1.9.10.2.3.1"></times><ci id="S3.E4.m1.9.10.2.3.2.cmml" xref="S3.E4.m1.9.10.2.3.2">𝑀</ci><ci id="S3.E4.m1.9.10.2.3.3.cmml" xref="S3.E4.m1.9.10.2.3.3">𝑁</ci><ci id="S3.E4.m1.9.10.2.3.4.cmml" xref="S3.E4.m1.9.10.2.3.4">𝑅</ci></apply></apply><apply id="S3.E4.m1.9.10.3.cmml" xref="S3.E4.m1.9.10.3"><minus id="S3.E4.m1.9.10.3.1.cmml" xref="S3.E4.m1.9.10.3"></minus><apply id="S3.E4.m1.9.10.3.2.cmml" xref="S3.E4.m1.9.10.3.2"><apply id="S3.E4.m1.9.10.3.2.1.cmml" xref="S3.E4.m1.9.10.3.2.1"><csymbol cd="ambiguous" id="S3.E4.m1.9.10.3.2.1.1.cmml" xref="S3.E4.m1.9.10.3.2.1">superscript</csymbol><apply id="S3.E4.m1.9.10.3.2.1.2.cmml" xref="S3.E4.m1.9.10.3.2.1"><csymbol cd="ambiguous" id="S3.E4.m1.9.10.3.2.1.2.1.cmml" xref="S3.E4.m1.9.10.3.2.1">subscript</csymbol><sum id="S3.E4.m1.9.10.3.2.1.2.2.cmml" xref="S3.E4.m1.9.10.3.2.1.2.2"></sum><apply id="S3.E4.m1.9.10.3.2.1.2.3.cmml" xref="S3.E4.m1.9.10.3.2.1.2.3"><eq id="S3.E4.m1.9.10.3.2.1.2.3.1.cmml" xref="S3.E4.m1.9.10.3.2.1.2.3.1"></eq><ci id="S3.E4.m1.9.10.3.2.1.2.3.2.cmml" xref="S3.E4.m1.9.10.3.2.1.2.3.2">𝑖</ci><cn id="S3.E4.m1.9.10.3.2.1.2.3.3.cmml" type="integer" xref="S3.E4.m1.9.10.3.2.1.2.3.3">1</cn></apply></apply><ci id="S3.E4.m1.9.10.3.2.1.3.cmml" xref="S3.E4.m1.9.10.3.2.1.3">𝑛</ci></apply><apply id="S3.E4.m1.9.10.3.2.2.1.cmml" xref="S3.E4.m1.9.10.3.2.2.2"><log id="S3.E4.m1.9.9.cmml" xref="S3.E4.m1.9.9"></log><apply id="S3.E4.m1.8.8.cmml" xref="S3.E4.m1.8.8"><divide id="S3.E4.m1.8.8.9.cmml" xref="S3.E4.m1.8.8"></divide><apply id="S3.E4.m1.4.4.4.5.cmml" xref="S3.E4.m1.4.4.4.4"><exp id="S3.E4.m1.3.3.3.3.cmml" xref="S3.E4.m1.3.3.3.3"></exp><apply id="S3.E4.m1.4.4.4.4.1.1.cmml" xref="S3.E4.m1.4.4.4.4.1.1"><ci id="S3.E4.m1.4.4.4.4.1.1.1.cmml" xref="S3.E4.m1.4.4.4.4.1.1.1">⋅</ci><ci id="S3.E4.m1.4.4.4.4.1.1.2.cmml" xref="S3.E4.m1.4.4.4.4.1.1.2">𝛼</ci><apply id="S3.E4.m1.4.4.4.4.1.1.3.cmml" xref="S3.E4.m1.4.4.4.4.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.4.4.4.4.1.1.3.1.cmml" xref="S3.E4.m1.4.4.4.4.1.1.3">subscript</csymbol><ci id="S3.E4.m1.4.4.4.4.1.1.3.2.cmml" xref="S3.E4.m1.4.4.4.4.1.1.3.2">𝑅</ci><list id="S3.E4.m1.2.2.2.2.2.3.cmml" xref="S3.E4.m1.2.2.2.2.2.2"><apply id="S3.E4.m1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.2">𝑞</ci><ci id="S3.E4.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.E4.m1.2.2.2.2.2.2.2.cmml" xref="S3.E4.m1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.2.2.2.2.1.cmml" xref="S3.E4.m1.2.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E4.m1.2.2.2.2.2.2.2.2.cmml" xref="S3.E4.m1.2.2.2.2.2.2.2.2">𝑠</ci><ci id="S3.E4.m1.2.2.2.2.2.2.2.3.cmml" xref="S3.E4.m1.2.2.2.2.2.2.2.3">𝑖</ci></apply></list></apply></apply></apply><apply id="S3.E4.m1.8.8.8.cmml" xref="S3.E4.m1.8.8.8"><apply id="S3.E4.m1.8.8.8.5.cmml" xref="S3.E4.m1.8.8.8.5"><csymbol cd="ambiguous" id="S3.E4.m1.8.8.8.5.1.cmml" xref="S3.E4.m1.8.8.8.5">superscript</csymbol><apply id="S3.E4.m1.8.8.8.5.2.cmml" xref="S3.E4.m1.8.8.8.5"><csymbol cd="ambiguous" id="S3.E4.m1.8.8.8.5.2.1.cmml" xref="S3.E4.m1.8.8.8.5">subscript</csymbol><sum id="S3.E4.m1.8.8.8.5.2.2.cmml" xref="S3.E4.m1.8.8.8.5.2.2"></sum><apply id="S3.E4.m1.8.8.8.5.2.3.cmml" xref="S3.E4.m1.8.8.8.5.2.3"><eq id="S3.E4.m1.8.8.8.5.2.3.1.cmml" xref="S3.E4.m1.8.8.8.5.2.3.1"></eq><ci id="S3.E4.m1.8.8.8.5.2.3.2.cmml" xref="S3.E4.m1.8.8.8.5.2.3.2">𝑗</ci><cn id="S3.E4.m1.8.8.8.5.2.3.3.cmml" type="integer" xref="S3.E4.m1.8.8.8.5.2.3.3">1</cn></apply></apply><ci id="S3.E4.m1.8.8.8.5.3.cmml" xref="S3.E4.m1.8.8.8.5.3">𝑛</ci></apply><apply id="S3.E4.m1.8.8.8.4.2.cmml" xref="S3.E4.m1.8.8.8.4.1"><exp id="S3.E4.m1.7.7.7.3.cmml" xref="S3.E4.m1.7.7.7.3"></exp><apply id="S3.E4.m1.8.8.8.4.1.1.1.cmml" xref="S3.E4.m1.8.8.8.4.1.1.1"><ci id="S3.E4.m1.8.8.8.4.1.1.1.1.cmml" xref="S3.E4.m1.8.8.8.4.1.1.1.1">⋅</ci><ci id="S3.E4.m1.8.8.8.4.1.1.1.2.cmml" xref="S3.E4.m1.8.8.8.4.1.1.1.2">𝛼</ci><apply id="S3.E4.m1.8.8.8.4.1.1.1.3.cmml" xref="S3.E4.m1.8.8.8.4.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.8.8.8.4.1.1.1.3.1.cmml" xref="S3.E4.m1.8.8.8.4.1.1.1.3">subscript</csymbol><ci id="S3.E4.m1.8.8.8.4.1.1.1.3.2.cmml" xref="S3.E4.m1.8.8.8.4.1.1.1.3.2">𝑅</ci><list id="S3.E4.m1.6.6.6.2.2.3.cmml" xref="S3.E4.m1.6.6.6.2.2.2"><apply id="S3.E4.m1.5.5.5.1.1.1.1.cmml" xref="S3.E4.m1.5.5.5.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.5.5.5.1.1.1.1.1.cmml" xref="S3.E4.m1.5.5.5.1.1.1.1">subscript</csymbol><ci id="S3.E4.m1.5.5.5.1.1.1.1.2.cmml" xref="S3.E4.m1.5.5.5.1.1.1.1.2">𝑞</ci><ci id="S3.E4.m1.5.5.5.1.1.1.1.3.cmml" xref="S3.E4.m1.5.5.5.1.1.1.1.3">𝑖</ci></apply><apply id="S3.E4.m1.6.6.6.2.2.2.2.cmml" xref="S3.E4.m1.6.6.6.2.2.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.6.6.6.2.2.2.2.1.cmml" xref="S3.E4.m1.6.6.6.2.2.2.2">subscript</csymbol><ci id="S3.E4.m1.6.6.6.2.2.2.2.2.cmml" xref="S3.E4.m1.6.6.6.2.2.2.2.2">𝑠</ci><ci id="S3.E4.m1.6.6.6.2.2.2.2.3.cmml" xref="S3.E4.m1.6.6.6.2.2.2.2.3">𝑗</ci></apply></list></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.9c">\mathcal{L}_{MNR}=-\sum_{i=1}^{n}\log(\frac{\exp(\alpha\cdot R_{q_{i},s_{i}})}%
{\sum_{j=1}^{n}\exp(\alpha\cdot R_{q_{i},s_{j}})})</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.9d">caligraphic_L start_POSTSUBSCRIPT italic_M italic_N italic_R end_POSTSUBSCRIPT = - ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT roman_log ( divide start_ARG roman_exp ( italic_α ⋅ italic_R start_POSTSUBSCRIPT italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) end_ARG start_ARG ∑ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT roman_exp ( italic_α ⋅ italic_R start_POSTSUBSCRIPT italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) end_ARG )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p5">
<p class="ltx_p" id="S3.SS2.SSS1.p5.1">The scaler <math alttext="\alpha" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p5.1.m1.1"><semantics id="S3.SS2.SSS1.p5.1.m1.1a"><mi id="S3.SS2.SSS1.p5.1.m1.1.1" xref="S3.SS2.SSS1.p5.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p5.1.m1.1b"><ci id="S3.SS2.SSS1.p5.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p5.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p5.1.m1.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p5.1.m1.1d">italic_α</annotation></semantics></math> is used to amplify the cosine similarity score, usually set at 20 according to the default setting in <span class="ltx_text ltx_font_typewriter" id="S3.SS2.SSS1.p5.1.1">sentence-transformers</span> <span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://sbert.net/docs/package_reference/sentence_transformer/losses.html#multiplenegativesrankingloss" title="">https://sbert.net/docs/package_reference/sentence_transformer/losses.html#multiplenegativesrankingloss</a></span></span></span>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2. </span><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS2.1.1">ColBERT</span>
</h4>
<div class="ltx_para" id="S3.SS2.SSS2.p1">
<p class="ltx_p" id="S3.SS2.SSS2.p1.2">ColBERT employes a bi-encoder architecture with late interaction, where the question and passage are independently encoded using a shared BERT model to obtain embeddings <math alttext="E_{q}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p1.1.m1.1"><semantics id="S3.SS2.SSS2.p1.1.m1.1a"><msub id="S3.SS2.SSS2.p1.1.m1.1.1" xref="S3.SS2.SSS2.p1.1.m1.1.1.cmml"><mi id="S3.SS2.SSS2.p1.1.m1.1.1.2" xref="S3.SS2.SSS2.p1.1.m1.1.1.2.cmml">E</mi><mi id="S3.SS2.SSS2.p1.1.m1.1.1.3" xref="S3.SS2.SSS2.p1.1.m1.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.1.m1.1b"><apply id="S3.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1.2">𝐸</ci><ci id="S3.SS2.SSS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.1.m1.1c">E_{q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p1.1.m1.1d">italic_E start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="E_{s}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p1.2.m2.1"><semantics id="S3.SS2.SSS2.p1.2.m2.1a"><msub id="S3.SS2.SSS2.p1.2.m2.1.1" xref="S3.SS2.SSS2.p1.2.m2.1.1.cmml"><mi id="S3.SS2.SSS2.p1.2.m2.1.1.2" xref="S3.SS2.SSS2.p1.2.m2.1.1.2.cmml">E</mi><mi id="S3.SS2.SSS2.p1.2.m2.1.1.3" xref="S3.SS2.SSS2.p1.2.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.2.m2.1b"><apply id="S3.SS2.SSS2.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.SSS2.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.SSS2.p1.2.m2.1.1.2">𝐸</ci><ci id="S3.SS2.SSS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.SSS2.p1.2.m2.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.2.m2.1c">E_{s}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p1.2.m2.1d">italic_E start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math>. The relevance score for each passage is computed on the question side using a “MaxSim” operation, which sums the maximum similarities between any passage token embedding with each question token embedding:</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p2">
<table class="ltx_equation ltx_eqn_table" id="S3.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(5)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="R_{q,s}=\sum_{i\in|E_{q}|}\max_{j\in|E_{s}|}\text{dot}(E_{q_{i}},E_{s_{j}})" class="ltx_Math" display="block" id="S3.E5.m1.6"><semantics id="S3.E5.m1.6a"><mrow id="S3.E5.m1.6.6" xref="S3.E5.m1.6.6.cmml"><msub id="S3.E5.m1.6.6.4" xref="S3.E5.m1.6.6.4.cmml"><mi id="S3.E5.m1.6.6.4.2" xref="S3.E5.m1.6.6.4.2.cmml">R</mi><mrow id="S3.E5.m1.2.2.2.4" xref="S3.E5.m1.2.2.2.3.cmml"><mi id="S3.E5.m1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml">q</mi><mo id="S3.E5.m1.2.2.2.4.1" xref="S3.E5.m1.2.2.2.3.cmml">,</mo><mi id="S3.E5.m1.2.2.2.2" xref="S3.E5.m1.2.2.2.2.cmml">s</mi></mrow></msub><mo id="S3.E5.m1.6.6.3" rspace="0.111em" xref="S3.E5.m1.6.6.3.cmml">=</mo><mrow id="S3.E5.m1.6.6.2" xref="S3.E5.m1.6.6.2.cmml"><munder id="S3.E5.m1.6.6.2.3" xref="S3.E5.m1.6.6.2.3.cmml"><mo id="S3.E5.m1.6.6.2.3.2" movablelimits="false" xref="S3.E5.m1.6.6.2.3.2.cmml">∑</mo><mrow id="S3.E5.m1.3.3.1" xref="S3.E5.m1.3.3.1.cmml"><mi id="S3.E5.m1.3.3.1.3" xref="S3.E5.m1.3.3.1.3.cmml">i</mi><mo id="S3.E5.m1.3.3.1.2" xref="S3.E5.m1.3.3.1.2.cmml">∈</mo><mrow id="S3.E5.m1.3.3.1.1.1" xref="S3.E5.m1.3.3.1.1.2.cmml"><mo id="S3.E5.m1.3.3.1.1.1.2" stretchy="false" xref="S3.E5.m1.3.3.1.1.2.1.cmml">|</mo><msub id="S3.E5.m1.3.3.1.1.1.1" xref="S3.E5.m1.3.3.1.1.1.1.cmml"><mi id="S3.E5.m1.3.3.1.1.1.1.2" xref="S3.E5.m1.3.3.1.1.1.1.2.cmml">E</mi><mi id="S3.E5.m1.3.3.1.1.1.1.3" xref="S3.E5.m1.3.3.1.1.1.1.3.cmml">q</mi></msub><mo id="S3.E5.m1.3.3.1.1.1.3" stretchy="false" xref="S3.E5.m1.3.3.1.1.2.1.cmml">|</mo></mrow></mrow></munder><mrow id="S3.E5.m1.6.6.2.2" xref="S3.E5.m1.6.6.2.2.cmml"><mrow id="S3.E5.m1.6.6.2.2.4" xref="S3.E5.m1.6.6.2.2.4.cmml"><munder id="S3.E5.m1.6.6.2.2.4.1" xref="S3.E5.m1.6.6.2.2.4.1.cmml"><mi id="S3.E5.m1.6.6.2.2.4.1.2" xref="S3.E5.m1.6.6.2.2.4.1.2.cmml">max</mi><mrow id="S3.E5.m1.4.4.1" xref="S3.E5.m1.4.4.1.cmml"><mi id="S3.E5.m1.4.4.1.3" xref="S3.E5.m1.4.4.1.3.cmml">j</mi><mo id="S3.E5.m1.4.4.1.2" xref="S3.E5.m1.4.4.1.2.cmml">∈</mo><mrow id="S3.E5.m1.4.4.1.1.1" xref="S3.E5.m1.4.4.1.1.2.cmml"><mo id="S3.E5.m1.4.4.1.1.1.2" stretchy="false" xref="S3.E5.m1.4.4.1.1.2.1.cmml">|</mo><msub id="S3.E5.m1.4.4.1.1.1.1" xref="S3.E5.m1.4.4.1.1.1.1.cmml"><mi id="S3.E5.m1.4.4.1.1.1.1.2" xref="S3.E5.m1.4.4.1.1.1.1.2.cmml">E</mi><mi id="S3.E5.m1.4.4.1.1.1.1.3" xref="S3.E5.m1.4.4.1.1.1.1.3.cmml">s</mi></msub><mo id="S3.E5.m1.4.4.1.1.1.3" stretchy="false" xref="S3.E5.m1.4.4.1.1.2.1.cmml">|</mo></mrow></mrow></munder><mo id="S3.E5.m1.6.6.2.2.4a" lspace="0.167em" xref="S3.E5.m1.6.6.2.2.4.cmml">⁡</mo><mtext id="S3.E5.m1.6.6.2.2.4.2" xref="S3.E5.m1.6.6.2.2.4.2a.cmml">dot</mtext></mrow><mo id="S3.E5.m1.6.6.2.2.3" xref="S3.E5.m1.6.6.2.2.3.cmml">⁢</mo><mrow id="S3.E5.m1.6.6.2.2.2.2" xref="S3.E5.m1.6.6.2.2.2.3.cmml"><mo id="S3.E5.m1.6.6.2.2.2.2.3" stretchy="false" xref="S3.E5.m1.6.6.2.2.2.3.cmml">(</mo><msub id="S3.E5.m1.5.5.1.1.1.1.1" xref="S3.E5.m1.5.5.1.1.1.1.1.cmml"><mi id="S3.E5.m1.5.5.1.1.1.1.1.2" xref="S3.E5.m1.5.5.1.1.1.1.1.2.cmml">E</mi><msub id="S3.E5.m1.5.5.1.1.1.1.1.3" xref="S3.E5.m1.5.5.1.1.1.1.1.3.cmml"><mi id="S3.E5.m1.5.5.1.1.1.1.1.3.2" xref="S3.E5.m1.5.5.1.1.1.1.1.3.2.cmml">q</mi><mi id="S3.E5.m1.5.5.1.1.1.1.1.3.3" xref="S3.E5.m1.5.5.1.1.1.1.1.3.3.cmml">i</mi></msub></msub><mo id="S3.E5.m1.6.6.2.2.2.2.4" xref="S3.E5.m1.6.6.2.2.2.3.cmml">,</mo><msub id="S3.E5.m1.6.6.2.2.2.2.2" xref="S3.E5.m1.6.6.2.2.2.2.2.cmml"><mi id="S3.E5.m1.6.6.2.2.2.2.2.2" xref="S3.E5.m1.6.6.2.2.2.2.2.2.cmml">E</mi><msub id="S3.E5.m1.6.6.2.2.2.2.2.3" xref="S3.E5.m1.6.6.2.2.2.2.2.3.cmml"><mi id="S3.E5.m1.6.6.2.2.2.2.2.3.2" xref="S3.E5.m1.6.6.2.2.2.2.2.3.2.cmml">s</mi><mi id="S3.E5.m1.6.6.2.2.2.2.2.3.3" xref="S3.E5.m1.6.6.2.2.2.2.2.3.3.cmml">j</mi></msub></msub><mo id="S3.E5.m1.6.6.2.2.2.2.5" stretchy="false" xref="S3.E5.m1.6.6.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.6b"><apply id="S3.E5.m1.6.6.cmml" xref="S3.E5.m1.6.6"><eq id="S3.E5.m1.6.6.3.cmml" xref="S3.E5.m1.6.6.3"></eq><apply id="S3.E5.m1.6.6.4.cmml" xref="S3.E5.m1.6.6.4"><csymbol cd="ambiguous" id="S3.E5.m1.6.6.4.1.cmml" xref="S3.E5.m1.6.6.4">subscript</csymbol><ci id="S3.E5.m1.6.6.4.2.cmml" xref="S3.E5.m1.6.6.4.2">𝑅</ci><list id="S3.E5.m1.2.2.2.3.cmml" xref="S3.E5.m1.2.2.2.4"><ci id="S3.E5.m1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1">𝑞</ci><ci id="S3.E5.m1.2.2.2.2.cmml" xref="S3.E5.m1.2.2.2.2">𝑠</ci></list></apply><apply id="S3.E5.m1.6.6.2.cmml" xref="S3.E5.m1.6.6.2"><apply id="S3.E5.m1.6.6.2.3.cmml" xref="S3.E5.m1.6.6.2.3"><csymbol cd="ambiguous" id="S3.E5.m1.6.6.2.3.1.cmml" xref="S3.E5.m1.6.6.2.3">subscript</csymbol><sum id="S3.E5.m1.6.6.2.3.2.cmml" xref="S3.E5.m1.6.6.2.3.2"></sum><apply id="S3.E5.m1.3.3.1.cmml" xref="S3.E5.m1.3.3.1"><in id="S3.E5.m1.3.3.1.2.cmml" xref="S3.E5.m1.3.3.1.2"></in><ci id="S3.E5.m1.3.3.1.3.cmml" xref="S3.E5.m1.3.3.1.3">𝑖</ci><apply id="S3.E5.m1.3.3.1.1.2.cmml" xref="S3.E5.m1.3.3.1.1.1"><abs id="S3.E5.m1.3.3.1.1.2.1.cmml" xref="S3.E5.m1.3.3.1.1.1.2"></abs><apply id="S3.E5.m1.3.3.1.1.1.1.cmml" xref="S3.E5.m1.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.1.1.1.1.1.cmml" xref="S3.E5.m1.3.3.1.1.1.1">subscript</csymbol><ci id="S3.E5.m1.3.3.1.1.1.1.2.cmml" xref="S3.E5.m1.3.3.1.1.1.1.2">𝐸</ci><ci id="S3.E5.m1.3.3.1.1.1.1.3.cmml" xref="S3.E5.m1.3.3.1.1.1.1.3">𝑞</ci></apply></apply></apply></apply><apply id="S3.E5.m1.6.6.2.2.cmml" xref="S3.E5.m1.6.6.2.2"><times id="S3.E5.m1.6.6.2.2.3.cmml" xref="S3.E5.m1.6.6.2.2.3"></times><apply id="S3.E5.m1.6.6.2.2.4.cmml" xref="S3.E5.m1.6.6.2.2.4"><apply id="S3.E5.m1.6.6.2.2.4.1.cmml" xref="S3.E5.m1.6.6.2.2.4.1"><csymbol cd="ambiguous" id="S3.E5.m1.6.6.2.2.4.1.1.cmml" xref="S3.E5.m1.6.6.2.2.4.1">subscript</csymbol><max id="S3.E5.m1.6.6.2.2.4.1.2.cmml" xref="S3.E5.m1.6.6.2.2.4.1.2"></max><apply id="S3.E5.m1.4.4.1.cmml" xref="S3.E5.m1.4.4.1"><in id="S3.E5.m1.4.4.1.2.cmml" xref="S3.E5.m1.4.4.1.2"></in><ci id="S3.E5.m1.4.4.1.3.cmml" xref="S3.E5.m1.4.4.1.3">𝑗</ci><apply id="S3.E5.m1.4.4.1.1.2.cmml" xref="S3.E5.m1.4.4.1.1.1"><abs id="S3.E5.m1.4.4.1.1.2.1.cmml" xref="S3.E5.m1.4.4.1.1.1.2"></abs><apply id="S3.E5.m1.4.4.1.1.1.1.cmml" xref="S3.E5.m1.4.4.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.4.4.1.1.1.1.1.cmml" xref="S3.E5.m1.4.4.1.1.1.1">subscript</csymbol><ci id="S3.E5.m1.4.4.1.1.1.1.2.cmml" xref="S3.E5.m1.4.4.1.1.1.1.2">𝐸</ci><ci id="S3.E5.m1.4.4.1.1.1.1.3.cmml" xref="S3.E5.m1.4.4.1.1.1.1.3">𝑠</ci></apply></apply></apply></apply><ci id="S3.E5.m1.6.6.2.2.4.2a.cmml" xref="S3.E5.m1.6.6.2.2.4.2"><mtext id="S3.E5.m1.6.6.2.2.4.2.cmml" xref="S3.E5.m1.6.6.2.2.4.2">dot</mtext></ci></apply><interval closure="open" id="S3.E5.m1.6.6.2.2.2.3.cmml" xref="S3.E5.m1.6.6.2.2.2.2"><apply id="S3.E5.m1.5.5.1.1.1.1.1.cmml" xref="S3.E5.m1.5.5.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.5.5.1.1.1.1.1.1.cmml" xref="S3.E5.m1.5.5.1.1.1.1.1">subscript</csymbol><ci id="S3.E5.m1.5.5.1.1.1.1.1.2.cmml" xref="S3.E5.m1.5.5.1.1.1.1.1.2">𝐸</ci><apply id="S3.E5.m1.5.5.1.1.1.1.1.3.cmml" xref="S3.E5.m1.5.5.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.5.5.1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.5.5.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E5.m1.5.5.1.1.1.1.1.3.2.cmml" xref="S3.E5.m1.5.5.1.1.1.1.1.3.2">𝑞</ci><ci id="S3.E5.m1.5.5.1.1.1.1.1.3.3.cmml" xref="S3.E5.m1.5.5.1.1.1.1.1.3.3">𝑖</ci></apply></apply><apply id="S3.E5.m1.6.6.2.2.2.2.2.cmml" xref="S3.E5.m1.6.6.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.6.6.2.2.2.2.2.1.cmml" xref="S3.E5.m1.6.6.2.2.2.2.2">subscript</csymbol><ci id="S3.E5.m1.6.6.2.2.2.2.2.2.cmml" xref="S3.E5.m1.6.6.2.2.2.2.2.2">𝐸</ci><apply id="S3.E5.m1.6.6.2.2.2.2.2.3.cmml" xref="S3.E5.m1.6.6.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E5.m1.6.6.2.2.2.2.2.3.1.cmml" xref="S3.E5.m1.6.6.2.2.2.2.2.3">subscript</csymbol><ci id="S3.E5.m1.6.6.2.2.2.2.2.3.2.cmml" xref="S3.E5.m1.6.6.2.2.2.2.2.3.2">𝑠</ci><ci id="S3.E5.m1.6.6.2.2.2.2.2.3.3.cmml" xref="S3.E5.m1.6.6.2.2.2.2.2.3.3">𝑗</ci></apply></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.6c">R_{q,s}=\sum_{i\in|E_{q}|}\max_{j\in|E_{s}|}\text{dot}(E_{q_{i}},E_{s_{j}})</annotation><annotation encoding="application/x-llamapun" id="S3.E5.m1.6d">italic_R start_POSTSUBSCRIPT italic_q , italic_s end_POSTSUBSCRIPT = ∑ start_POSTSUBSCRIPT italic_i ∈ | italic_E start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT | end_POSTSUBSCRIPT roman_max start_POSTSUBSCRIPT italic_j ∈ | italic_E start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT | end_POSTSUBSCRIPT dot ( italic_E start_POSTSUBSCRIPT italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT , italic_E start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p3">
<p class="ltx_p" id="S3.SS2.SSS2.p3.13">Here, <math alttext="\text{dot}(x,y)" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p3.1.m1.2"><semantics id="S3.SS2.SSS2.p3.1.m1.2a"><mrow id="S3.SS2.SSS2.p3.1.m1.2.3" xref="S3.SS2.SSS2.p3.1.m1.2.3.cmml"><mtext id="S3.SS2.SSS2.p3.1.m1.2.3.2" xref="S3.SS2.SSS2.p3.1.m1.2.3.2a.cmml">dot</mtext><mo id="S3.SS2.SSS2.p3.1.m1.2.3.1" xref="S3.SS2.SSS2.p3.1.m1.2.3.1.cmml">⁢</mo><mrow id="S3.SS2.SSS2.p3.1.m1.2.3.3.2" xref="S3.SS2.SSS2.p3.1.m1.2.3.3.1.cmml"><mo id="S3.SS2.SSS2.p3.1.m1.2.3.3.2.1" stretchy="false" xref="S3.SS2.SSS2.p3.1.m1.2.3.3.1.cmml">(</mo><mi id="S3.SS2.SSS2.p3.1.m1.1.1" xref="S3.SS2.SSS2.p3.1.m1.1.1.cmml">x</mi><mo id="S3.SS2.SSS2.p3.1.m1.2.3.3.2.2" xref="S3.SS2.SSS2.p3.1.m1.2.3.3.1.cmml">,</mo><mi id="S3.SS2.SSS2.p3.1.m1.2.2" xref="S3.SS2.SSS2.p3.1.m1.2.2.cmml">y</mi><mo id="S3.SS2.SSS2.p3.1.m1.2.3.3.2.3" stretchy="false" xref="S3.SS2.SSS2.p3.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.1.m1.2b"><apply id="S3.SS2.SSS2.p3.1.m1.2.3.cmml" xref="S3.SS2.SSS2.p3.1.m1.2.3"><times id="S3.SS2.SSS2.p3.1.m1.2.3.1.cmml" xref="S3.SS2.SSS2.p3.1.m1.2.3.1"></times><ci id="S3.SS2.SSS2.p3.1.m1.2.3.2a.cmml" xref="S3.SS2.SSS2.p3.1.m1.2.3.2"><mtext id="S3.SS2.SSS2.p3.1.m1.2.3.2.cmml" xref="S3.SS2.SSS2.p3.1.m1.2.3.2">dot</mtext></ci><interval closure="open" id="S3.SS2.SSS2.p3.1.m1.2.3.3.1.cmml" xref="S3.SS2.SSS2.p3.1.m1.2.3.3.2"><ci id="S3.SS2.SSS2.p3.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1">𝑥</ci><ci id="S3.SS2.SSS2.p3.1.m1.2.2.cmml" xref="S3.SS2.SSS2.p3.1.m1.2.2">𝑦</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.1.m1.2c">\text{dot}(x,y)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p3.1.m1.2d">dot ( italic_x , italic_y )</annotation></semantics></math> represents the dot product between <math alttext="x" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p3.2.m2.1"><semantics id="S3.SS2.SSS2.p3.2.m2.1a"><mi id="S3.SS2.SSS2.p3.2.m2.1.1" xref="S3.SS2.SSS2.p3.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.2.m2.1b"><ci id="S3.SS2.SSS2.p3.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.2.m2.1c">x</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p3.2.m2.1d">italic_x</annotation></semantics></math> and <math alttext="y" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p3.3.m3.1"><semantics id="S3.SS2.SSS2.p3.3.m3.1a"><mi id="S3.SS2.SSS2.p3.3.m3.1.1" xref="S3.SS2.SSS2.p3.3.m3.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.3.m3.1b"><ci id="S3.SS2.SSS2.p3.3.m3.1.1.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.3.m3.1c">y</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p3.3.m3.1d">italic_y</annotation></semantics></math>.
The training dataset for ColBERT consists of triplet samples <math alttext="\langle q,s^{+},s^{-}\rangle" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p3.4.m4.3"><semantics id="S3.SS2.SSS2.p3.4.m4.3a"><mrow id="S3.SS2.SSS2.p3.4.m4.3.3.2" xref="S3.SS2.SSS2.p3.4.m4.3.3.3.cmml"><mo id="S3.SS2.SSS2.p3.4.m4.3.3.2.3" stretchy="false" xref="S3.SS2.SSS2.p3.4.m4.3.3.3.cmml">⟨</mo><mi id="S3.SS2.SSS2.p3.4.m4.1.1" xref="S3.SS2.SSS2.p3.4.m4.1.1.cmml">q</mi><mo id="S3.SS2.SSS2.p3.4.m4.3.3.2.4" xref="S3.SS2.SSS2.p3.4.m4.3.3.3.cmml">,</mo><msup id="S3.SS2.SSS2.p3.4.m4.2.2.1.1" xref="S3.SS2.SSS2.p3.4.m4.2.2.1.1.cmml"><mi id="S3.SS2.SSS2.p3.4.m4.2.2.1.1.2" xref="S3.SS2.SSS2.p3.4.m4.2.2.1.1.2.cmml">s</mi><mo id="S3.SS2.SSS2.p3.4.m4.2.2.1.1.3" xref="S3.SS2.SSS2.p3.4.m4.2.2.1.1.3.cmml">+</mo></msup><mo id="S3.SS2.SSS2.p3.4.m4.3.3.2.5" xref="S3.SS2.SSS2.p3.4.m4.3.3.3.cmml">,</mo><msup id="S3.SS2.SSS2.p3.4.m4.3.3.2.2" xref="S3.SS2.SSS2.p3.4.m4.3.3.2.2.cmml"><mi id="S3.SS2.SSS2.p3.4.m4.3.3.2.2.2" xref="S3.SS2.SSS2.p3.4.m4.3.3.2.2.2.cmml">s</mi><mo id="S3.SS2.SSS2.p3.4.m4.3.3.2.2.3" xref="S3.SS2.SSS2.p3.4.m4.3.3.2.2.3.cmml">−</mo></msup><mo id="S3.SS2.SSS2.p3.4.m4.3.3.2.6" stretchy="false" xref="S3.SS2.SSS2.p3.4.m4.3.3.3.cmml">⟩</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.4.m4.3b"><list id="S3.SS2.SSS2.p3.4.m4.3.3.3.cmml" xref="S3.SS2.SSS2.p3.4.m4.3.3.2"><ci id="S3.SS2.SSS2.p3.4.m4.1.1.cmml" xref="S3.SS2.SSS2.p3.4.m4.1.1">𝑞</ci><apply id="S3.SS2.SSS2.p3.4.m4.2.2.1.1.cmml" xref="S3.SS2.SSS2.p3.4.m4.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.4.m4.2.2.1.1.1.cmml" xref="S3.SS2.SSS2.p3.4.m4.2.2.1.1">superscript</csymbol><ci id="S3.SS2.SSS2.p3.4.m4.2.2.1.1.2.cmml" xref="S3.SS2.SSS2.p3.4.m4.2.2.1.1.2">𝑠</ci><plus id="S3.SS2.SSS2.p3.4.m4.2.2.1.1.3.cmml" xref="S3.SS2.SSS2.p3.4.m4.2.2.1.1.3"></plus></apply><apply id="S3.SS2.SSS2.p3.4.m4.3.3.2.2.cmml" xref="S3.SS2.SSS2.p3.4.m4.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.4.m4.3.3.2.2.1.cmml" xref="S3.SS2.SSS2.p3.4.m4.3.3.2.2">superscript</csymbol><ci id="S3.SS2.SSS2.p3.4.m4.3.3.2.2.2.cmml" xref="S3.SS2.SSS2.p3.4.m4.3.3.2.2.2">𝑠</ci><minus id="S3.SS2.SSS2.p3.4.m4.3.3.2.2.3.cmml" xref="S3.SS2.SSS2.p3.4.m4.3.3.2.2.3"></minus></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.4.m4.3c">\langle q,s^{+},s^{-}\rangle</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p3.4.m4.3d">⟨ italic_q , italic_s start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT , italic_s start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT ⟩</annotation></semantics></math>, extracted from each ranked list <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p3.5.m5.1"><semantics id="S3.SS2.SSS2.p3.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS2.p3.5.m5.1.1" xref="S3.SS2.SSS2.p3.5.m5.1.1.cmml">𝒮</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.5.m5.1b"><ci id="S3.SS2.SSS2.p3.5.m5.1.1.cmml" xref="S3.SS2.SSS2.p3.5.m5.1.1">𝒮</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.5.m5.1c">\mathcal{S}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p3.5.m5.1d">caligraphic_S</annotation></semantics></math>. In these triplets, <math alttext="s_{r_{1}}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p3.6.m6.1"><semantics id="S3.SS2.SSS2.p3.6.m6.1a"><msub id="S3.SS2.SSS2.p3.6.m6.1.1" xref="S3.SS2.SSS2.p3.6.m6.1.1.cmml"><mi id="S3.SS2.SSS2.p3.6.m6.1.1.2" xref="S3.SS2.SSS2.p3.6.m6.1.1.2.cmml">s</mi><msub id="S3.SS2.SSS2.p3.6.m6.1.1.3" xref="S3.SS2.SSS2.p3.6.m6.1.1.3.cmml"><mi id="S3.SS2.SSS2.p3.6.m6.1.1.3.2" xref="S3.SS2.SSS2.p3.6.m6.1.1.3.2.cmml">r</mi><mn id="S3.SS2.SSS2.p3.6.m6.1.1.3.3" xref="S3.SS2.SSS2.p3.6.m6.1.1.3.3.cmml">1</mn></msub></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.6.m6.1b"><apply id="S3.SS2.SSS2.p3.6.m6.1.1.cmml" xref="S3.SS2.SSS2.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.6.m6.1.1.1.cmml" xref="S3.SS2.SSS2.p3.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p3.6.m6.1.1.2.cmml" xref="S3.SS2.SSS2.p3.6.m6.1.1.2">𝑠</ci><apply id="S3.SS2.SSS2.p3.6.m6.1.1.3.cmml" xref="S3.SS2.SSS2.p3.6.m6.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.6.m6.1.1.3.1.cmml" xref="S3.SS2.SSS2.p3.6.m6.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS2.p3.6.m6.1.1.3.2.cmml" xref="S3.SS2.SSS2.p3.6.m6.1.1.3.2">𝑟</ci><cn id="S3.SS2.SSS2.p3.6.m6.1.1.3.3.cmml" type="integer" xref="S3.SS2.SSS2.p3.6.m6.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.6.m6.1c">s_{r_{1}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p3.6.m6.1d">italic_s start_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT</annotation></semantics></math> is treated as the positive passage <math alttext="s^{+}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p3.7.m7.1"><semantics id="S3.SS2.SSS2.p3.7.m7.1a"><msup id="S3.SS2.SSS2.p3.7.m7.1.1" xref="S3.SS2.SSS2.p3.7.m7.1.1.cmml"><mi id="S3.SS2.SSS2.p3.7.m7.1.1.2" xref="S3.SS2.SSS2.p3.7.m7.1.1.2.cmml">s</mi><mo id="S3.SS2.SSS2.p3.7.m7.1.1.3" xref="S3.SS2.SSS2.p3.7.m7.1.1.3.cmml">+</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.7.m7.1b"><apply id="S3.SS2.SSS2.p3.7.m7.1.1.cmml" xref="S3.SS2.SSS2.p3.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.7.m7.1.1.1.cmml" xref="S3.SS2.SSS2.p3.7.m7.1.1">superscript</csymbol><ci id="S3.SS2.SSS2.p3.7.m7.1.1.2.cmml" xref="S3.SS2.SSS2.p3.7.m7.1.1.2">𝑠</ci><plus id="S3.SS2.SSS2.p3.7.m7.1.1.3.cmml" xref="S3.SS2.SSS2.p3.7.m7.1.1.3"></plus></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.7.m7.1c">s^{+}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p3.7.m7.1d">italic_s start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT</annotation></semantics></math>, while <math alttext="s_{r_{2}},s_{r_{3}},\dots,s_{r_{m+1}}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p3.8.m8.4"><semantics id="S3.SS2.SSS2.p3.8.m8.4a"><mrow id="S3.SS2.SSS2.p3.8.m8.4.4.3" xref="S3.SS2.SSS2.p3.8.m8.4.4.4.cmml"><msub id="S3.SS2.SSS2.p3.8.m8.2.2.1.1" xref="S3.SS2.SSS2.p3.8.m8.2.2.1.1.cmml"><mi id="S3.SS2.SSS2.p3.8.m8.2.2.1.1.2" xref="S3.SS2.SSS2.p3.8.m8.2.2.1.1.2.cmml">s</mi><msub id="S3.SS2.SSS2.p3.8.m8.2.2.1.1.3" xref="S3.SS2.SSS2.p3.8.m8.2.2.1.1.3.cmml"><mi id="S3.SS2.SSS2.p3.8.m8.2.2.1.1.3.2" xref="S3.SS2.SSS2.p3.8.m8.2.2.1.1.3.2.cmml">r</mi><mn id="S3.SS2.SSS2.p3.8.m8.2.2.1.1.3.3" xref="S3.SS2.SSS2.p3.8.m8.2.2.1.1.3.3.cmml">2</mn></msub></msub><mo id="S3.SS2.SSS2.p3.8.m8.4.4.3.4" xref="S3.SS2.SSS2.p3.8.m8.4.4.4.cmml">,</mo><msub id="S3.SS2.SSS2.p3.8.m8.3.3.2.2" xref="S3.SS2.SSS2.p3.8.m8.3.3.2.2.cmml"><mi id="S3.SS2.SSS2.p3.8.m8.3.3.2.2.2" xref="S3.SS2.SSS2.p3.8.m8.3.3.2.2.2.cmml">s</mi><msub id="S3.SS2.SSS2.p3.8.m8.3.3.2.2.3" xref="S3.SS2.SSS2.p3.8.m8.3.3.2.2.3.cmml"><mi id="S3.SS2.SSS2.p3.8.m8.3.3.2.2.3.2" xref="S3.SS2.SSS2.p3.8.m8.3.3.2.2.3.2.cmml">r</mi><mn id="S3.SS2.SSS2.p3.8.m8.3.3.2.2.3.3" xref="S3.SS2.SSS2.p3.8.m8.3.3.2.2.3.3.cmml">3</mn></msub></msub><mo id="S3.SS2.SSS2.p3.8.m8.4.4.3.5" xref="S3.SS2.SSS2.p3.8.m8.4.4.4.cmml">,</mo><mi id="S3.SS2.SSS2.p3.8.m8.1.1" mathvariant="normal" xref="S3.SS2.SSS2.p3.8.m8.1.1.cmml">…</mi><mo id="S3.SS2.SSS2.p3.8.m8.4.4.3.6" xref="S3.SS2.SSS2.p3.8.m8.4.4.4.cmml">,</mo><msub id="S3.SS2.SSS2.p3.8.m8.4.4.3.3" xref="S3.SS2.SSS2.p3.8.m8.4.4.3.3.cmml"><mi id="S3.SS2.SSS2.p3.8.m8.4.4.3.3.2" xref="S3.SS2.SSS2.p3.8.m8.4.4.3.3.2.cmml">s</mi><msub id="S3.SS2.SSS2.p3.8.m8.4.4.3.3.3" xref="S3.SS2.SSS2.p3.8.m8.4.4.3.3.3.cmml"><mi id="S3.SS2.SSS2.p3.8.m8.4.4.3.3.3.2" xref="S3.SS2.SSS2.p3.8.m8.4.4.3.3.3.2.cmml">r</mi><mrow id="S3.SS2.SSS2.p3.8.m8.4.4.3.3.3.3" xref="S3.SS2.SSS2.p3.8.m8.4.4.3.3.3.3.cmml"><mi id="S3.SS2.SSS2.p3.8.m8.4.4.3.3.3.3.2" xref="S3.SS2.SSS2.p3.8.m8.4.4.3.3.3.3.2.cmml">m</mi><mo id="S3.SS2.SSS2.p3.8.m8.4.4.3.3.3.3.1" xref="S3.SS2.SSS2.p3.8.m8.4.4.3.3.3.3.1.cmml">+</mo><mn id="S3.SS2.SSS2.p3.8.m8.4.4.3.3.3.3.3" xref="S3.SS2.SSS2.p3.8.m8.4.4.3.3.3.3.3.cmml">1</mn></mrow></msub></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.8.m8.4b"><list id="S3.SS2.SSS2.p3.8.m8.4.4.4.cmml" xref="S3.SS2.SSS2.p3.8.m8.4.4.3"><apply id="S3.SS2.SSS2.p3.8.m8.2.2.1.1.cmml" xref="S3.SS2.SSS2.p3.8.m8.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.8.m8.2.2.1.1.1.cmml" xref="S3.SS2.SSS2.p3.8.m8.2.2.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p3.8.m8.2.2.1.1.2.cmml" xref="S3.SS2.SSS2.p3.8.m8.2.2.1.1.2">𝑠</ci><apply id="S3.SS2.SSS2.p3.8.m8.2.2.1.1.3.cmml" xref="S3.SS2.SSS2.p3.8.m8.2.2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.8.m8.2.2.1.1.3.1.cmml" xref="S3.SS2.SSS2.p3.8.m8.2.2.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS2.p3.8.m8.2.2.1.1.3.2.cmml" xref="S3.SS2.SSS2.p3.8.m8.2.2.1.1.3.2">𝑟</ci><cn id="S3.SS2.SSS2.p3.8.m8.2.2.1.1.3.3.cmml" type="integer" xref="S3.SS2.SSS2.p3.8.m8.2.2.1.1.3.3">2</cn></apply></apply><apply id="S3.SS2.SSS2.p3.8.m8.3.3.2.2.cmml" xref="S3.SS2.SSS2.p3.8.m8.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.8.m8.3.3.2.2.1.cmml" xref="S3.SS2.SSS2.p3.8.m8.3.3.2.2">subscript</csymbol><ci id="S3.SS2.SSS2.p3.8.m8.3.3.2.2.2.cmml" xref="S3.SS2.SSS2.p3.8.m8.3.3.2.2.2">𝑠</ci><apply id="S3.SS2.SSS2.p3.8.m8.3.3.2.2.3.cmml" xref="S3.SS2.SSS2.p3.8.m8.3.3.2.2.3"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.8.m8.3.3.2.2.3.1.cmml" xref="S3.SS2.SSS2.p3.8.m8.3.3.2.2.3">subscript</csymbol><ci id="S3.SS2.SSS2.p3.8.m8.3.3.2.2.3.2.cmml" xref="S3.SS2.SSS2.p3.8.m8.3.3.2.2.3.2">𝑟</ci><cn id="S3.SS2.SSS2.p3.8.m8.3.3.2.2.3.3.cmml" type="integer" xref="S3.SS2.SSS2.p3.8.m8.3.3.2.2.3.3">3</cn></apply></apply><ci id="S3.SS2.SSS2.p3.8.m8.1.1.cmml" xref="S3.SS2.SSS2.p3.8.m8.1.1">…</ci><apply id="S3.SS2.SSS2.p3.8.m8.4.4.3.3.cmml" xref="S3.SS2.SSS2.p3.8.m8.4.4.3.3"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.8.m8.4.4.3.3.1.cmml" xref="S3.SS2.SSS2.p3.8.m8.4.4.3.3">subscript</csymbol><ci id="S3.SS2.SSS2.p3.8.m8.4.4.3.3.2.cmml" xref="S3.SS2.SSS2.p3.8.m8.4.4.3.3.2">𝑠</ci><apply id="S3.SS2.SSS2.p3.8.m8.4.4.3.3.3.cmml" xref="S3.SS2.SSS2.p3.8.m8.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.8.m8.4.4.3.3.3.1.cmml" xref="S3.SS2.SSS2.p3.8.m8.4.4.3.3.3">subscript</csymbol><ci id="S3.SS2.SSS2.p3.8.m8.4.4.3.3.3.2.cmml" xref="S3.SS2.SSS2.p3.8.m8.4.4.3.3.3.2">𝑟</ci><apply id="S3.SS2.SSS2.p3.8.m8.4.4.3.3.3.3.cmml" xref="S3.SS2.SSS2.p3.8.m8.4.4.3.3.3.3"><plus id="S3.SS2.SSS2.p3.8.m8.4.4.3.3.3.3.1.cmml" xref="S3.SS2.SSS2.p3.8.m8.4.4.3.3.3.3.1"></plus><ci id="S3.SS2.SSS2.p3.8.m8.4.4.3.3.3.3.2.cmml" xref="S3.SS2.SSS2.p3.8.m8.4.4.3.3.3.3.2">𝑚</ci><cn id="S3.SS2.SSS2.p3.8.m8.4.4.3.3.3.3.3.cmml" type="integer" xref="S3.SS2.SSS2.p3.8.m8.4.4.3.3.3.3.3">1</cn></apply></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.8.m8.4c">s_{r_{2}},s_{r_{3}},\dots,s_{r_{m+1}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p3.8.m8.4d">italic_s start_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , … , italic_s start_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT italic_m + 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT</annotation></semantics></math> are treated as negative passages <math alttext="s^{-}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p3.9.m9.1"><semantics id="S3.SS2.SSS2.p3.9.m9.1a"><msup id="S3.SS2.SSS2.p3.9.m9.1.1" xref="S3.SS2.SSS2.p3.9.m9.1.1.cmml"><mi id="S3.SS2.SSS2.p3.9.m9.1.1.2" xref="S3.SS2.SSS2.p3.9.m9.1.1.2.cmml">s</mi><mo id="S3.SS2.SSS2.p3.9.m9.1.1.3" xref="S3.SS2.SSS2.p3.9.m9.1.1.3.cmml">−</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.9.m9.1b"><apply id="S3.SS2.SSS2.p3.9.m9.1.1.cmml" xref="S3.SS2.SSS2.p3.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.9.m9.1.1.1.cmml" xref="S3.SS2.SSS2.p3.9.m9.1.1">superscript</csymbol><ci id="S3.SS2.SSS2.p3.9.m9.1.1.2.cmml" xref="S3.SS2.SSS2.p3.9.m9.1.1.2">𝑠</ci><minus id="S3.SS2.SSS2.p3.9.m9.1.1.3.cmml" xref="S3.SS2.SSS2.p3.9.m9.1.1.3"></minus></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.9.m9.1c">s^{-}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p3.9.m9.1d">italic_s start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT</annotation></semantics></math>. Here, <math alttext="m" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p3.10.m10.1"><semantics id="S3.SS2.SSS2.p3.10.m10.1a"><mi id="S3.SS2.SSS2.p3.10.m10.1.1" xref="S3.SS2.SSS2.p3.10.m10.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.10.m10.1b"><ci id="S3.SS2.SSS2.p3.10.m10.1.1.cmml" xref="S3.SS2.SSS2.p3.10.m10.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.10.m10.1c">m</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p3.10.m10.1d">italic_m</annotation></semantics></math> represents the number of hard negatives selected from <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p3.11.m11.1"><semantics id="S3.SS2.SSS2.p3.11.m11.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS2.p3.11.m11.1.1" xref="S3.SS2.SSS2.p3.11.m11.1.1.cmml">𝒮</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.11.m11.1b"><ci id="S3.SS2.SSS2.p3.11.m11.1.1.cmml" xref="S3.SS2.SSS2.p3.11.m11.1.1">𝒮</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.11.m11.1c">\mathcal{S}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p3.11.m11.1d">caligraphic_S</annotation></semantics></math>. ColBERT produces two scores <math alttext="R_{q,s^{+}}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p3.12.m12.2"><semantics id="S3.SS2.SSS2.p3.12.m12.2a"><msub id="S3.SS2.SSS2.p3.12.m12.2.3" xref="S3.SS2.SSS2.p3.12.m12.2.3.cmml"><mi id="S3.SS2.SSS2.p3.12.m12.2.3.2" xref="S3.SS2.SSS2.p3.12.m12.2.3.2.cmml">R</mi><mrow id="S3.SS2.SSS2.p3.12.m12.2.2.2.2" xref="S3.SS2.SSS2.p3.12.m12.2.2.2.3.cmml"><mi id="S3.SS2.SSS2.p3.12.m12.1.1.1.1" xref="S3.SS2.SSS2.p3.12.m12.1.1.1.1.cmml">q</mi><mo id="S3.SS2.SSS2.p3.12.m12.2.2.2.2.2" xref="S3.SS2.SSS2.p3.12.m12.2.2.2.3.cmml">,</mo><msup id="S3.SS2.SSS2.p3.12.m12.2.2.2.2.1" xref="S3.SS2.SSS2.p3.12.m12.2.2.2.2.1.cmml"><mi id="S3.SS2.SSS2.p3.12.m12.2.2.2.2.1.2" xref="S3.SS2.SSS2.p3.12.m12.2.2.2.2.1.2.cmml">s</mi><mo id="S3.SS2.SSS2.p3.12.m12.2.2.2.2.1.3" xref="S3.SS2.SSS2.p3.12.m12.2.2.2.2.1.3.cmml">+</mo></msup></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.12.m12.2b"><apply id="S3.SS2.SSS2.p3.12.m12.2.3.cmml" xref="S3.SS2.SSS2.p3.12.m12.2.3"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.12.m12.2.3.1.cmml" xref="S3.SS2.SSS2.p3.12.m12.2.3">subscript</csymbol><ci id="S3.SS2.SSS2.p3.12.m12.2.3.2.cmml" xref="S3.SS2.SSS2.p3.12.m12.2.3.2">𝑅</ci><list id="S3.SS2.SSS2.p3.12.m12.2.2.2.3.cmml" xref="S3.SS2.SSS2.p3.12.m12.2.2.2.2"><ci id="S3.SS2.SSS2.p3.12.m12.1.1.1.1.cmml" xref="S3.SS2.SSS2.p3.12.m12.1.1.1.1">𝑞</ci><apply id="S3.SS2.SSS2.p3.12.m12.2.2.2.2.1.cmml" xref="S3.SS2.SSS2.p3.12.m12.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.12.m12.2.2.2.2.1.1.cmml" xref="S3.SS2.SSS2.p3.12.m12.2.2.2.2.1">superscript</csymbol><ci id="S3.SS2.SSS2.p3.12.m12.2.2.2.2.1.2.cmml" xref="S3.SS2.SSS2.p3.12.m12.2.2.2.2.1.2">𝑠</ci><plus id="S3.SS2.SSS2.p3.12.m12.2.2.2.2.1.3.cmml" xref="S3.SS2.SSS2.p3.12.m12.2.2.2.2.1.3"></plus></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.12.m12.2c">R_{q,s^{+}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p3.12.m12.2d">italic_R start_POSTSUBSCRIPT italic_q , italic_s start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="R_{q,s^{-}}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p3.13.m13.2"><semantics id="S3.SS2.SSS2.p3.13.m13.2a"><msub id="S3.SS2.SSS2.p3.13.m13.2.3" xref="S3.SS2.SSS2.p3.13.m13.2.3.cmml"><mi id="S3.SS2.SSS2.p3.13.m13.2.3.2" xref="S3.SS2.SSS2.p3.13.m13.2.3.2.cmml">R</mi><mrow id="S3.SS2.SSS2.p3.13.m13.2.2.2.2" xref="S3.SS2.SSS2.p3.13.m13.2.2.2.3.cmml"><mi id="S3.SS2.SSS2.p3.13.m13.1.1.1.1" xref="S3.SS2.SSS2.p3.13.m13.1.1.1.1.cmml">q</mi><mo id="S3.SS2.SSS2.p3.13.m13.2.2.2.2.2" xref="S3.SS2.SSS2.p3.13.m13.2.2.2.3.cmml">,</mo><msup id="S3.SS2.SSS2.p3.13.m13.2.2.2.2.1" xref="S3.SS2.SSS2.p3.13.m13.2.2.2.2.1.cmml"><mi id="S3.SS2.SSS2.p3.13.m13.2.2.2.2.1.2" xref="S3.SS2.SSS2.p3.13.m13.2.2.2.2.1.2.cmml">s</mi><mo id="S3.SS2.SSS2.p3.13.m13.2.2.2.2.1.3" xref="S3.SS2.SSS2.p3.13.m13.2.2.2.2.1.3.cmml">−</mo></msup></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.13.m13.2b"><apply id="S3.SS2.SSS2.p3.13.m13.2.3.cmml" xref="S3.SS2.SSS2.p3.13.m13.2.3"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.13.m13.2.3.1.cmml" xref="S3.SS2.SSS2.p3.13.m13.2.3">subscript</csymbol><ci id="S3.SS2.SSS2.p3.13.m13.2.3.2.cmml" xref="S3.SS2.SSS2.p3.13.m13.2.3.2">𝑅</ci><list id="S3.SS2.SSS2.p3.13.m13.2.2.2.3.cmml" xref="S3.SS2.SSS2.p3.13.m13.2.2.2.2"><ci id="S3.SS2.SSS2.p3.13.m13.1.1.1.1.cmml" xref="S3.SS2.SSS2.p3.13.m13.1.1.1.1">𝑞</ci><apply id="S3.SS2.SSS2.p3.13.m13.2.2.2.2.1.cmml" xref="S3.SS2.SSS2.p3.13.m13.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.13.m13.2.2.2.2.1.1.cmml" xref="S3.SS2.SSS2.p3.13.m13.2.2.2.2.1">superscript</csymbol><ci id="S3.SS2.SSS2.p3.13.m13.2.2.2.2.1.2.cmml" xref="S3.SS2.SSS2.p3.13.m13.2.2.2.2.1.2">𝑠</ci><minus id="S3.SS2.SSS2.p3.13.m13.2.2.2.2.1.3.cmml" xref="S3.SS2.SSS2.p3.13.m13.2.2.2.2.1.3"></minus></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.13.m13.2c">R_{q,s^{-}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p3.13.m13.2d">italic_R start_POSTSUBSCRIPT italic_q , italic_s start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT end_POSTSUBSCRIPT</annotation></semantics></math> from each triplet, and the model is optimized through a pairwise softmax cross-entropy loss:</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p4">
<table class="ltx_equation ltx_eqn_table" id="S3.E6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(6)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{ColBERT}=-\log(\frac{\exp R_{q,s^{+}}}{\exp R_{q,s^{+}}+\exp R_{q%
,s^{-}}})" class="ltx_Math" display="block" id="S3.E6.m1.7"><semantics id="S3.E6.m1.7a"><mrow id="S3.E6.m1.7.8" xref="S3.E6.m1.7.8.cmml"><msub id="S3.E6.m1.7.8.2" xref="S3.E6.m1.7.8.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.7.8.2.2" xref="S3.E6.m1.7.8.2.2.cmml">ℒ</mi><mrow id="S3.E6.m1.7.8.2.3" xref="S3.E6.m1.7.8.2.3.cmml"><mi id="S3.E6.m1.7.8.2.3.2" xref="S3.E6.m1.7.8.2.3.2.cmml">C</mi><mo id="S3.E6.m1.7.8.2.3.1" xref="S3.E6.m1.7.8.2.3.1.cmml">⁢</mo><mi id="S3.E6.m1.7.8.2.3.3" xref="S3.E6.m1.7.8.2.3.3.cmml">o</mi><mo id="S3.E6.m1.7.8.2.3.1a" xref="S3.E6.m1.7.8.2.3.1.cmml">⁢</mo><mi id="S3.E6.m1.7.8.2.3.4" xref="S3.E6.m1.7.8.2.3.4.cmml">l</mi><mo id="S3.E6.m1.7.8.2.3.1b" xref="S3.E6.m1.7.8.2.3.1.cmml">⁢</mo><mi id="S3.E6.m1.7.8.2.3.5" xref="S3.E6.m1.7.8.2.3.5.cmml">B</mi><mo id="S3.E6.m1.7.8.2.3.1c" xref="S3.E6.m1.7.8.2.3.1.cmml">⁢</mo><mi id="S3.E6.m1.7.8.2.3.6" xref="S3.E6.m1.7.8.2.3.6.cmml">E</mi><mo id="S3.E6.m1.7.8.2.3.1d" xref="S3.E6.m1.7.8.2.3.1.cmml">⁢</mo><mi id="S3.E6.m1.7.8.2.3.7" xref="S3.E6.m1.7.8.2.3.7.cmml">R</mi><mo id="S3.E6.m1.7.8.2.3.1e" xref="S3.E6.m1.7.8.2.3.1.cmml">⁢</mo><mi id="S3.E6.m1.7.8.2.3.8" xref="S3.E6.m1.7.8.2.3.8.cmml">T</mi></mrow></msub><mo id="S3.E6.m1.7.8.1" xref="S3.E6.m1.7.8.1.cmml">=</mo><mrow id="S3.E6.m1.7.8.3" xref="S3.E6.m1.7.8.3.cmml"><mo id="S3.E6.m1.7.8.3a" rspace="0.167em" xref="S3.E6.m1.7.8.3.cmml">−</mo><mrow id="S3.E6.m1.7.8.3.2.2" xref="S3.E6.m1.7.8.3.2.1.cmml"><mi id="S3.E6.m1.7.7" xref="S3.E6.m1.7.7.cmml">log</mi><mo id="S3.E6.m1.7.8.3.2.2a" xref="S3.E6.m1.7.8.3.2.1.cmml">⁡</mo><mrow id="S3.E6.m1.7.8.3.2.2.1" xref="S3.E6.m1.7.8.3.2.1.cmml"><mo id="S3.E6.m1.7.8.3.2.2.1.1" stretchy="false" xref="S3.E6.m1.7.8.3.2.1.cmml">(</mo><mfrac id="S3.E6.m1.6.6" xref="S3.E6.m1.6.6.cmml"><mrow id="S3.E6.m1.2.2.2" xref="S3.E6.m1.2.2.2.cmml"><mi id="S3.E6.m1.2.2.2.3" xref="S3.E6.m1.2.2.2.3.cmml">exp</mi><mo id="S3.E6.m1.2.2.2a" lspace="0.167em" xref="S3.E6.m1.2.2.2.cmml">⁡</mo><msub id="S3.E6.m1.2.2.2.4" xref="S3.E6.m1.2.2.2.4.cmml"><mi id="S3.E6.m1.2.2.2.4.2" xref="S3.E6.m1.2.2.2.4.2.cmml">R</mi><mrow id="S3.E6.m1.2.2.2.2.2.2" xref="S3.E6.m1.2.2.2.2.2.3.cmml"><mi id="S3.E6.m1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.cmml">q</mi><mo id="S3.E6.m1.2.2.2.2.2.2.2" xref="S3.E6.m1.2.2.2.2.2.3.cmml">,</mo><msup id="S3.E6.m1.2.2.2.2.2.2.1" xref="S3.E6.m1.2.2.2.2.2.2.1.cmml"><mi id="S3.E6.m1.2.2.2.2.2.2.1.2" xref="S3.E6.m1.2.2.2.2.2.2.1.2.cmml">s</mi><mo id="S3.E6.m1.2.2.2.2.2.2.1.3" xref="S3.E6.m1.2.2.2.2.2.2.1.3.cmml">+</mo></msup></mrow></msub></mrow><mrow id="S3.E6.m1.6.6.6" xref="S3.E6.m1.6.6.6.cmml"><mrow id="S3.E6.m1.6.6.6.6" xref="S3.E6.m1.6.6.6.6.cmml"><mi id="S3.E6.m1.6.6.6.6.1" xref="S3.E6.m1.6.6.6.6.1.cmml">exp</mi><mo id="S3.E6.m1.6.6.6.6a" lspace="0.167em" xref="S3.E6.m1.6.6.6.6.cmml">⁡</mo><msub id="S3.E6.m1.6.6.6.6.2" xref="S3.E6.m1.6.6.6.6.2.cmml"><mi id="S3.E6.m1.6.6.6.6.2.2" xref="S3.E6.m1.6.6.6.6.2.2.cmml">R</mi><mrow id="S3.E6.m1.4.4.4.2.2.2" xref="S3.E6.m1.4.4.4.2.2.3.cmml"><mi id="S3.E6.m1.3.3.3.1.1.1" xref="S3.E6.m1.3.3.3.1.1.1.cmml">q</mi><mo id="S3.E6.m1.4.4.4.2.2.2.2" xref="S3.E6.m1.4.4.4.2.2.3.cmml">,</mo><msup id="S3.E6.m1.4.4.4.2.2.2.1" xref="S3.E6.m1.4.4.4.2.2.2.1.cmml"><mi id="S3.E6.m1.4.4.4.2.2.2.1.2" xref="S3.E6.m1.4.4.4.2.2.2.1.2.cmml">s</mi><mo id="S3.E6.m1.4.4.4.2.2.2.1.3" xref="S3.E6.m1.4.4.4.2.2.2.1.3.cmml">+</mo></msup></mrow></msub></mrow><mo id="S3.E6.m1.6.6.6.5" xref="S3.E6.m1.6.6.6.5.cmml">+</mo><mrow id="S3.E6.m1.6.6.6.7" xref="S3.E6.m1.6.6.6.7.cmml"><mi id="S3.E6.m1.6.6.6.7.1" xref="S3.E6.m1.6.6.6.7.1.cmml">exp</mi><mo id="S3.E6.m1.6.6.6.7a" lspace="0.167em" xref="S3.E6.m1.6.6.6.7.cmml">⁡</mo><msub id="S3.E6.m1.6.6.6.7.2" xref="S3.E6.m1.6.6.6.7.2.cmml"><mi id="S3.E6.m1.6.6.6.7.2.2" xref="S3.E6.m1.6.6.6.7.2.2.cmml">R</mi><mrow id="S3.E6.m1.6.6.6.4.2.2" xref="S3.E6.m1.6.6.6.4.2.3.cmml"><mi id="S3.E6.m1.5.5.5.3.1.1" xref="S3.E6.m1.5.5.5.3.1.1.cmml">q</mi><mo id="S3.E6.m1.6.6.6.4.2.2.2" xref="S3.E6.m1.6.6.6.4.2.3.cmml">,</mo><msup id="S3.E6.m1.6.6.6.4.2.2.1" xref="S3.E6.m1.6.6.6.4.2.2.1.cmml"><mi id="S3.E6.m1.6.6.6.4.2.2.1.2" xref="S3.E6.m1.6.6.6.4.2.2.1.2.cmml">s</mi><mo id="S3.E6.m1.6.6.6.4.2.2.1.3" xref="S3.E6.m1.6.6.6.4.2.2.1.3.cmml">−</mo></msup></mrow></msub></mrow></mrow></mfrac><mo id="S3.E6.m1.7.8.3.2.2.1.2" stretchy="false" xref="S3.E6.m1.7.8.3.2.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.7b"><apply id="S3.E6.m1.7.8.cmml" xref="S3.E6.m1.7.8"><eq id="S3.E6.m1.7.8.1.cmml" xref="S3.E6.m1.7.8.1"></eq><apply id="S3.E6.m1.7.8.2.cmml" xref="S3.E6.m1.7.8.2"><csymbol cd="ambiguous" id="S3.E6.m1.7.8.2.1.cmml" xref="S3.E6.m1.7.8.2">subscript</csymbol><ci id="S3.E6.m1.7.8.2.2.cmml" xref="S3.E6.m1.7.8.2.2">ℒ</ci><apply id="S3.E6.m1.7.8.2.3.cmml" xref="S3.E6.m1.7.8.2.3"><times id="S3.E6.m1.7.8.2.3.1.cmml" xref="S3.E6.m1.7.8.2.3.1"></times><ci id="S3.E6.m1.7.8.2.3.2.cmml" xref="S3.E6.m1.7.8.2.3.2">𝐶</ci><ci id="S3.E6.m1.7.8.2.3.3.cmml" xref="S3.E6.m1.7.8.2.3.3">𝑜</ci><ci id="S3.E6.m1.7.8.2.3.4.cmml" xref="S3.E6.m1.7.8.2.3.4">𝑙</ci><ci id="S3.E6.m1.7.8.2.3.5.cmml" xref="S3.E6.m1.7.8.2.3.5">𝐵</ci><ci id="S3.E6.m1.7.8.2.3.6.cmml" xref="S3.E6.m1.7.8.2.3.6">𝐸</ci><ci id="S3.E6.m1.7.8.2.3.7.cmml" xref="S3.E6.m1.7.8.2.3.7">𝑅</ci><ci id="S3.E6.m1.7.8.2.3.8.cmml" xref="S3.E6.m1.7.8.2.3.8">𝑇</ci></apply></apply><apply id="S3.E6.m1.7.8.3.cmml" xref="S3.E6.m1.7.8.3"><minus id="S3.E6.m1.7.8.3.1.cmml" xref="S3.E6.m1.7.8.3"></minus><apply id="S3.E6.m1.7.8.3.2.1.cmml" xref="S3.E6.m1.7.8.3.2.2"><log id="S3.E6.m1.7.7.cmml" xref="S3.E6.m1.7.7"></log><apply id="S3.E6.m1.6.6.cmml" xref="S3.E6.m1.6.6"><divide id="S3.E6.m1.6.6.7.cmml" xref="S3.E6.m1.6.6"></divide><apply id="S3.E6.m1.2.2.2.cmml" xref="S3.E6.m1.2.2.2"><exp id="S3.E6.m1.2.2.2.3.cmml" xref="S3.E6.m1.2.2.2.3"></exp><apply id="S3.E6.m1.2.2.2.4.cmml" xref="S3.E6.m1.2.2.2.4"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.2.4.1.cmml" xref="S3.E6.m1.2.2.2.4">subscript</csymbol><ci id="S3.E6.m1.2.2.2.4.2.cmml" xref="S3.E6.m1.2.2.2.4.2">𝑅</ci><list id="S3.E6.m1.2.2.2.2.2.3.cmml" xref="S3.E6.m1.2.2.2.2.2.2"><ci id="S3.E6.m1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1">𝑞</ci><apply id="S3.E6.m1.2.2.2.2.2.2.1.cmml" xref="S3.E6.m1.2.2.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.2.2.2.2.1.1.cmml" xref="S3.E6.m1.2.2.2.2.2.2.1">superscript</csymbol><ci id="S3.E6.m1.2.2.2.2.2.2.1.2.cmml" xref="S3.E6.m1.2.2.2.2.2.2.1.2">𝑠</ci><plus id="S3.E6.m1.2.2.2.2.2.2.1.3.cmml" xref="S3.E6.m1.2.2.2.2.2.2.1.3"></plus></apply></list></apply></apply><apply id="S3.E6.m1.6.6.6.cmml" xref="S3.E6.m1.6.6.6"><plus id="S3.E6.m1.6.6.6.5.cmml" xref="S3.E6.m1.6.6.6.5"></plus><apply id="S3.E6.m1.6.6.6.6.cmml" xref="S3.E6.m1.6.6.6.6"><exp id="S3.E6.m1.6.6.6.6.1.cmml" xref="S3.E6.m1.6.6.6.6.1"></exp><apply id="S3.E6.m1.6.6.6.6.2.cmml" xref="S3.E6.m1.6.6.6.6.2"><csymbol cd="ambiguous" id="S3.E6.m1.6.6.6.6.2.1.cmml" xref="S3.E6.m1.6.6.6.6.2">subscript</csymbol><ci id="S3.E6.m1.6.6.6.6.2.2.cmml" xref="S3.E6.m1.6.6.6.6.2.2">𝑅</ci><list id="S3.E6.m1.4.4.4.2.2.3.cmml" xref="S3.E6.m1.4.4.4.2.2.2"><ci id="S3.E6.m1.3.3.3.1.1.1.cmml" xref="S3.E6.m1.3.3.3.1.1.1">𝑞</ci><apply id="S3.E6.m1.4.4.4.2.2.2.1.cmml" xref="S3.E6.m1.4.4.4.2.2.2.1"><csymbol cd="ambiguous" id="S3.E6.m1.4.4.4.2.2.2.1.1.cmml" xref="S3.E6.m1.4.4.4.2.2.2.1">superscript</csymbol><ci id="S3.E6.m1.4.4.4.2.2.2.1.2.cmml" xref="S3.E6.m1.4.4.4.2.2.2.1.2">𝑠</ci><plus id="S3.E6.m1.4.4.4.2.2.2.1.3.cmml" xref="S3.E6.m1.4.4.4.2.2.2.1.3"></plus></apply></list></apply></apply><apply id="S3.E6.m1.6.6.6.7.cmml" xref="S3.E6.m1.6.6.6.7"><exp id="S3.E6.m1.6.6.6.7.1.cmml" xref="S3.E6.m1.6.6.6.7.1"></exp><apply id="S3.E6.m1.6.6.6.7.2.cmml" xref="S3.E6.m1.6.6.6.7.2"><csymbol cd="ambiguous" id="S3.E6.m1.6.6.6.7.2.1.cmml" xref="S3.E6.m1.6.6.6.7.2">subscript</csymbol><ci id="S3.E6.m1.6.6.6.7.2.2.cmml" xref="S3.E6.m1.6.6.6.7.2.2">𝑅</ci><list id="S3.E6.m1.6.6.6.4.2.3.cmml" xref="S3.E6.m1.6.6.6.4.2.2"><ci id="S3.E6.m1.5.5.5.3.1.1.cmml" xref="S3.E6.m1.5.5.5.3.1.1">𝑞</ci><apply id="S3.E6.m1.6.6.6.4.2.2.1.cmml" xref="S3.E6.m1.6.6.6.4.2.2.1"><csymbol cd="ambiguous" id="S3.E6.m1.6.6.6.4.2.2.1.1.cmml" xref="S3.E6.m1.6.6.6.4.2.2.1">superscript</csymbol><ci id="S3.E6.m1.6.6.6.4.2.2.1.2.cmml" xref="S3.E6.m1.6.6.6.4.2.2.1.2">𝑠</ci><minus id="S3.E6.m1.6.6.6.4.2.2.1.3.cmml" xref="S3.E6.m1.6.6.6.4.2.2.1.3"></minus></apply></list></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.7c">\mathcal{L}_{ColBERT}=-\log(\frac{\exp R_{q,s^{+}}}{\exp R_{q,s^{+}}+\exp R_{q%
,s^{-}}})</annotation><annotation encoding="application/x-llamapun" id="S3.E6.m1.7d">caligraphic_L start_POSTSUBSCRIPT italic_C italic_o italic_l italic_B italic_E italic_R italic_T end_POSTSUBSCRIPT = - roman_log ( divide start_ARG roman_exp italic_R start_POSTSUBSCRIPT italic_q , italic_s start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT end_POSTSUBSCRIPT end_ARG start_ARG roman_exp italic_R start_POSTSUBSCRIPT italic_q , italic_s start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT end_POSTSUBSCRIPT + roman_exp italic_R start_POSTSUBSCRIPT italic_q , italic_s start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT end_POSTSUBSCRIPT end_ARG )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Experiments</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Task and Datasets</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">To assess the effectiveness of W-RAG, we study three crucial components: the quality of the LLM-generated weak labels, the retrieval performance of the weakly trained dense retriever, and the overall effectiveness of the RAG system on the OpenQA task. We conduct experiments on four well-known datasets for OpenQA: MSMARCO QnA v2.1 <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib32" title="">2016</a>)</cite>, NQ <cite class="ltx_cite ltx_citemacro_citep">(Kwiatkowski et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib25" title="">2019</a>)</cite>, SQuAD <cite class="ltx_cite ltx_citemacro_citep">(Rajpurkar et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib38" title="">2016</a>)</cite>, and WebQ <cite class="ltx_cite ltx_citemacro_citep">(Berant et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib3" title="">2013</a>)</cite>. MSMARCO QnA v2.1 shares the same corpus as MSMARCOv1 Passage Retrieval, with questions originating from real user queries submitted to Bing, making the language conversational. NQ also features real user questions and uses a corpus of documents from the English Wikipedia. In this work, we use a chuncked version of NQ as prepared by Karpukhin et al. <cite class="ltx_cite ltx_citemacro_citep">(Karpukhin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib20" title="">2020a</a>)</cite>. SQuAD’s corpus is similarly derived from the English Wikipedia, where the passages were first retrieved and then sampled. The questions and answers are manually written by crowdworkers, so they do not reflect natural language as closely as questions from real user queries like MSMARCO and NQ. WebQ’s corpus is drawn from Freebase, a large knowledge graph. Due to the nature of knowledge graphs, WebQ’s questions and answers are entity-related and factoid-based, thus making them less conversational compared to other datasets like MSMARCO and NQ.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">For each dataset, we uniformly random sampled 5,000 question-answer pairs and a corpus of 500,000 passages from the training set, ensuring that all questions had relevant passages included in the corpus. We then split the question-answer pairs into 2,000 as training set, 1,000 as validation set, and 2,000 as test set. This sampling was necessitated by resource and time constraints. We argue that this small training set is sufficient to demonstrate statistically significant differences in both retrieval and the final OpenQA performance. While our results are indicative, our method could benefit from further validation using larger datasets to ensure generalizability.</p>
</div>
<section class="ltx_subsubsection" id="S4.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1. </span><span class="ltx_text ltx_font_bold" id="S4.SS1.SSS1.1.1">Weak Label Quality</span>
</h4>
<div class="ltx_para" id="S4.SS1.SSS1.p1">
<p class="ltx_p" id="S4.SS1.SSS1.p1.1">For our main experiments, we use Llama3-8B-Instruct <cite class="ltx_cite ltx_citemacro_citep">(Dubey and .etl, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib10" title="">2024</a>)</cite> to serve as the reranker. The 2,000 question-answer pairs in the training set are used to generate weak labels. For each question, weak labels are generated by scoring the top 100 passages retrieved by BM25, based on the LLM’s likelihood of generating the answer. This process requires the LLM to perform inference 100 times to produce a ranked list. The choice of 100 passages is a trade-off between accuracy and latency. We found that BM25’s Recall@100 reaches approximately 80% across all four datasets, and retrieving additional passages yields diminishing returns as the LLM’s inference time increases linearly. We evaluate the reranking performance using different prompts and LLMs, which will be elaborated on later in the ablation studies (<a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S5.SS4" title="5.4. Ablation Study ‣ 5. Experimental Results ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_tag">5.4</span></a>).</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2. </span><span class="ltx_text ltx_font_bold" id="S4.SS1.SSS2.1.1">Weakly Trained Retriever</span>
</h4>
<div class="ltx_para" id="S4.SS1.SSS2.p1">
<p class="ltx_p" id="S4.SS1.SSS2.p1.2">After the LLM weakly labels the training set, we use these labels to train DPR and ColBERT. For DPR, since in-batch negatives are used during training, we only need to select the top-ranked passage to curate a list of relevant question-passage pairs, thus forming 2,000 training samples. For all four datasets, we used two different initializaiton settings for DPR: one is using <span class="ltx_text ltx_font_typewriter" id="S4.SS1.SSS2.p1.2.1">bert-base-uncased</span> to train from scratch (denoted as “DPR<sub class="ltx_sub" id="S4.SS1.SSS2.p1.2.2"><span class="ltx_text ltx_font_italic" id="S4.SS1.SSS2.p1.2.2.1">base</span></sub>”), and the other by resuming training from an unsupervised dense retriever using <span class="ltx_text ltx_font_typewriter" id="S4.SS1.SSS2.p1.2.3">Yibin-Lei/ReContriever</span> <cite class="ltx_cite ltx_citemacro_citep">(Lei et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib27" title="">2023b</a>)</cite> (denoted as “DPR<sub class="ltx_sub" id="S4.SS1.SSS2.p1.2.4"><span class="ltx_text ltx_font_italic" id="S4.SS1.SSS2.p1.2.4.1">ReCon</span></sub>”).</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p2">
<p class="ltx_p" id="S4.SS1.SSS2.p2.1">ColBERT’s training process differs slightly from that of DPR because it requires the sampling of negative passages. For each question, we select the top-ranked passage from the reranked list as the positive passage and the immediate following 10 passages as hard negatives. These hard negatives are relevant but not sufficiently informative to elicit the correct answer from the LLM. We did not explore varying the number of hard negatives, as this is not the primary focus of this work. Additionally, since the off-the-shelf ColBERTv2 is trained on the entire MSMARCO dataset, using it as the starting point would introduce data leakage. For consistency, we always train ColBERT from scratch using <span class="ltx_text ltx_font_typewriter" id="S4.SS1.SSS2.p2.1.1">bert-base-uncased</span> for all four datasets (denoted as “ColBERT<sub class="ltx_sub" id="S4.SS1.SSS2.p2.1.2"><span class="ltx_text ltx_font_italic" id="S4.SS1.SSS2.p2.1.2.1">base</span></sub>”).</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.3. </span><span class="ltx_text ltx_font_bold" id="S4.SS1.SSS3.1.1">OpenQA Performance</span>
</h4>
<div class="ltx_para" id="S4.SS1.SSS3.p1">
<p class="ltx_p" id="S4.SS1.SSS3.p1.1">Once the dense retriever is trained, we integrate it into the generic RAG pipeline, where it is used to retrieve the top-<math alttext="K" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p1.1.m1.1"><semantics id="S4.SS1.SSS3.p1.1.m1.1a"><mi id="S4.SS1.SSS3.p1.1.m1.1.1" xref="S4.SS1.SSS3.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p1.1.m1.1b"><ci id="S4.SS1.SSS3.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS3.p1.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p1.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p1.1.m1.1d">italic_K</annotation></semantics></math> evidence passages for a given user question. The retrieved passages are directly inserted into the prompt, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S3.F2" title="Figure 2 ‣ 3. Method ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_tag">2</span></a> alongside the question and instructions asking the LLM to generate an answer based on the retrieved passages or, if the passages are not useful, to answer using its internal knowledge. For our main experiments, we restrict Llama3-8B-Instruct to generate a maximum of 20 tokens and only use top 1 retrieved passage to supplement the prompt. We also explored the impact of using different numbers of supplemental evidence passages on both OpenQA performance and latency, which we discuss in the ablation studies (<a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S5.SS4" title="5.4. Ablation Study ‣ 5. Experimental Results ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_tag">5.4</span></a>). We did not experiment with different LLMs for the OpenQA task, as the LLM component of RAG is not the primary focus of our study.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Baselines</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Since our retriever is trained from scratch with limited data, we do not compare it to state-of-the-art retrievers or RAG systems. Instead, we focus on the improvement from untrained baselines to our weakly trained models and compare them with models trained on ground-truth data.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">For OpenQA evaluation, we use Llama3-8B-Instruct as the LLM in the RAG pipeline, assessing the impact of different retrievers on final OpenQA performance. We compare these retrievers against the same baseline models used for OpenQA. Additionally, we introduce two baselines: “Naive,” where Llama3 answers the question without any external information, showcasing its parameter knowledge, and “Groundtruth,” where the ground-truth passage is inserted into the prompt, representing the best possible OpenQA performance.</p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.3">To assess weak label quality, we compare Llama3-8B-Instruct with BM25 after Llama3 generates weak labels on the training set of each dataset. For retriever performance, we evaluate two categories of models. The first category includes entirely unsupervised models: BM25, ColBERT initialized with <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p3.3.1">bert-base-uncased</span> (denoted as “ColBERT<sub class="ltx_sub" id="S4.SS2.p3.3.2"><span class="ltx_text ltx_font_italic" id="S4.SS2.p3.3.2.1">init</span></sub>”), Contriever <cite class="ltx_cite ltx_citemacro_citep">(Izacard et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib15" title="">2021</a>)</cite>, and ReContriever <cite class="ltx_cite ltx_citemacro_citep">(Lei et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib27" title="">2023b</a>)</cite>. Contriever learns by contrasting sampled passages from different documents, assuming that each document is somewhat unique, while ReContriever enhances this by estimating relevance among sampled passages. The second category includes DPR<sub class="ltx_sub" id="S4.SS2.p3.3.3"><span class="ltx_text ltx_font_italic" id="S4.SS2.p3.3.3.1">ReCon</span></sub> and ColBERT<sub class="ltx_sub" id="S4.SS2.p3.3.4"><span class="ltx_text ltx_font_italic" id="S4.SS2.p3.3.4.1">base</span></sub>, both trained on ground-truth data. For a fair comparison, we use the same questions and an equal number of positive and negative samples as training data.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T1.5">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.5.6.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T1.5.6.1.1" rowspan="2"><span class="ltx_text" id="S4.T1.5.6.1.1.1">Retriever</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S4.T1.5.6.1.2">MSMARCO QnA</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S4.T1.5.6.1.3">NQ</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S4.T1.5.6.1.4">SQuAD</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S4.T1.5.6.1.5">WebQ</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.7.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.7.2.1">F1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.7.2.2">Rouge-L</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.5.7.2.3">BLEU-1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.7.2.4">F1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.7.2.5">Rouge-L</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.5.7.2.6">BLEU-1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.7.2.7">F1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.7.2.8">Rouge-L</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.5.7.2.9">BLEU-1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.7.2.10">F1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.7.2.11">Rouge-L</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.7.2.12">BLEU-1</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.8.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.5.8.3.1">Naive</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.8.3.2">0.2749</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.8.3.3">0.2392</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.5.8.3.4">0.2019</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.8.3.5">0.1158</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.8.3.6">0.1136</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.5.8.3.7">0.0618</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.8.3.8">0.0885</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.8.3.9">0.0845</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.5.8.3.10">0.0508</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.8.3.11">0.1512</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.8.3.12">0.1487</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.5.8.3.13">0.0823</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.9.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T1.5.9.4.1">Groundtruth</th>
<td class="ltx_td ltx_align_center" id="S4.T1.5.9.4.2">0.4677</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.9.4.3">0.4310</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.9.4.4">0.3541</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.9.4.5">0.2186</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.9.4.6">0.2171</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.9.4.7">0.1193</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.9.4.8">0.2691</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.9.4.9">0.2675</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.9.4.10">0.1613</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.9.4.11">0.1736</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.9.4.12">0.1707</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.9.4.13">0.0937</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.1.1.1">ColBERT<sub class="ltx_sub" id="S4.T1.1.1.1.1"><span class="ltx_text ltx_font_italic" id="S4.T1.1.1.1.1.1">init</span></sub>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.2">0.2185</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3">0.1867</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.4">0.1619</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.5">0.0525</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.6">0.0518</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.7">0.0283</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.8">0.0501</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.9">0.0482</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.10">0.0296</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.11">0.0434</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.12">0.0423</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.13">0.0233</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.10.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T1.5.10.5.1">BM25</th>
<td class="ltx_td ltx_align_center" id="S4.T1.5.10.5.2">0.3060</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.10.5.3">0.2712</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.10.5.4">0.2292</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.10.5.5">0.1374</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.10.5.6">0.1358</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.10.5.7">0.0748</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.10.5.8">0.1387</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.10.5.9">0.1369</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.10.5.10">0.0835</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.10.5.11">0.1085</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.10.5.12">0.1055</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.10.5.13">0.0594</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.11.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T1.5.11.6.1">Contriever</th>
<td class="ltx_td ltx_align_center" id="S4.T1.5.11.6.2">0.3125</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.11.6.3">0.2798</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.11.6.4">0.2347</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.11.6.5">0.1446</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.11.6.6">0.1432</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.11.6.7">0.0796</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.11.6.8">0.1144</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.11.6.9">0.1124</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.11.6.10">0.0680</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.11.6.11">0.1273</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.11.6.12">0.1257</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.11.6.13">0.0702</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.12.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T1.5.12.7.1">ReContriever</th>
<td class="ltx_td ltx_align_center" id="S4.T1.5.12.7.2">0.3171</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.12.7.3">0.2854</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.12.7.4">0.2387</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.12.7.5">0.1440</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.12.7.6">0.1429</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.12.7.7">0.0789</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.12.7.8">0.1257</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.12.7.9">0.1233</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.12.7.10">0.0753</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.12.7.11">0.1274</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.12.7.12">0.1239</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.12.7.13">0.0695</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.13.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="13" id="S4.T1.5.13.8.1">Trained on Groundtruth Data</th>
</tr>
<tr class="ltx_tr" id="S4.T1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.2.2.1">ColBERT<sub class="ltx_sub" id="S4.T1.2.2.1.1"><span class="ltx_text ltx_font_italic" id="S4.T1.2.2.1.1.1">base</span></sub>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.2.2">0.3227</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.2.3">0.2876</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.2.2.4">0.2421</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.2.5">0.1494</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.2.6">0.1482</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.2.2.7">0.0814</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.2.8">0.1524</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.2.9">0.1497</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.2.2.10">0.0900</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.2.11">0.1006</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.2.12">0.1001</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.2.13">0.0538</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T1.3.3.1">DPR<sub class="ltx_sub" id="S4.T1.3.3.1.1"><span class="ltx_text ltx_font_italic" id="S4.T1.3.3.1.1.1">ReCon</span></sub>
</th>
<td class="ltx_td ltx_align_center" id="S4.T1.3.3.2">0.3424</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.3.3">0.3102</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.3.3.4">0.2588</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.3.5">0.1641</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.3.6">0.1628</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.3.3.7">0.0902</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.3.8">0.1550</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.3.9">0.1531</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.3.3.10">0.0919</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.3.11">0.1397</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.3.12">0.1378</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.3.13">0.0771</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.14.9">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="13" id="S4.T1.5.14.9.1">Trained on W-RAG Data</th>
</tr>
<tr class="ltx_tr" id="S4.T1.4.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.4.4.1">ColBERT<sub class="ltx_sub" id="S4.T1.4.4.1.1"><span class="ltx_text ltx_font_italic" id="S4.T1.4.4.1.1.1">base</span></sub>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.4.2">0.3150<sup class="ltx_sup" id="S4.T1.4.4.2.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.4.3">0.2803<sup class="ltx_sup" id="S4.T1.4.4.3.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.4.4.4">0.2365<sup class="ltx_sup" id="S4.T1.4.4.4.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.4.5">0.1313<sup class="ltx_sup" id="S4.T1.4.4.5.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.4.6">0.1301<sup class="ltx_sup" id="S4.T1.4.4.6.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.4.4.7">0.0712<sup class="ltx_sup" id="S4.T1.4.4.7.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.4.8">0.1509<sup class="ltx_sup" id="S4.T1.4.4.8.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.4.9">0.1489<sup class="ltx_sup" id="S4.T1.4.4.9.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.4.4.10">0.0897<sup class="ltx_sup" id="S4.T1.4.4.10.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.4.11">0.1003<sup class="ltx_sup" id="S4.T1.4.4.11.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.4.12">0.0989<sup class="ltx_sup" id="S4.T1.4.4.12.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.4.13">0.0545<sup class="ltx_sup" id="S4.T1.4.4.13.1">†</sup>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T1.5.5.1">DPR<sub class="ltx_sub" id="S4.T1.5.5.1.1"><span class="ltx_text ltx_font_italic" id="S4.T1.5.5.1.1.1">ReCon</span></sub>
</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.5.5.2">0.3397<sup class="ltx_sup" id="S4.T1.5.5.2.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.5.5.3">0.3074<sup class="ltx_sup" id="S4.T1.5.5.3.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T1.5.5.4">0.2559<sup class="ltx_sup" id="S4.T1.5.5.4.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.5.5.5">0.1528<sup class="ltx_sup" id="S4.T1.5.5.5.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.5.5.6">0.1515<sup class="ltx_sup" id="S4.T1.5.5.6.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T1.5.5.7">0.0837<sup class="ltx_sup" id="S4.T1.5.5.7.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.5.5.8">0.1425<sup class="ltx_sup" id="S4.T1.5.5.8.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.5.5.9">0.1402<sup class="ltx_sup" id="S4.T1.5.5.9.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T1.5.5.10">0.0850<sup class="ltx_sup" id="S4.T1.5.5.10.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.5.5.11">0.1304</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.5.5.12">0.1276</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.5.5.13">0.0727</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T1.19.5.1" style="font-size:90%;">Table 1</span>. </span><span class="ltx_text" id="S4.T1.13.4" style="font-size:90%;">OpenQA Performance. Top 1 passage is inserted into the OpenQA prompt, limit number of generated tokens to 20. <sup class="ltx_sup" id="S4.T1.13.4.1">†</sup>: Performance improvements are statistically significant with a ttest of <math alttext="p&lt;0.05" class="ltx_Math" display="inline" id="S4.T1.10.1.m1.1"><semantics id="S4.T1.10.1.m1.1b"><mrow id="S4.T1.10.1.m1.1.1" xref="S4.T1.10.1.m1.1.1.cmml"><mi id="S4.T1.10.1.m1.1.1.2" xref="S4.T1.10.1.m1.1.1.2.cmml">p</mi><mo id="S4.T1.10.1.m1.1.1.1" xref="S4.T1.10.1.m1.1.1.1.cmml">&lt;</mo><mn id="S4.T1.10.1.m1.1.1.3" xref="S4.T1.10.1.m1.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.10.1.m1.1c"><apply id="S4.T1.10.1.m1.1.1.cmml" xref="S4.T1.10.1.m1.1.1"><lt id="S4.T1.10.1.m1.1.1.1.cmml" xref="S4.T1.10.1.m1.1.1.1"></lt><ci id="S4.T1.10.1.m1.1.1.2.cmml" xref="S4.T1.10.1.m1.1.1.2">𝑝</ci><cn id="S4.T1.10.1.m1.1.1.3.cmml" type="float" xref="S4.T1.10.1.m1.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.10.1.m1.1d">p&lt;0.05</annotation><annotation encoding="application/x-llamapun" id="S4.T1.10.1.m1.1e">italic_p &lt; 0.05</annotation></semantics></math>. DPR<sub class="ltx_sub" id="S4.T1.13.4.2"><span class="ltx_text ltx_font_italic" id="S4.T1.13.4.2.1">ReCon</span></sub>’s baseline is ReContriever, ColBERT<sub class="ltx_sub" id="S4.T1.13.4.3"><span class="ltx_text ltx_font_italic" id="S4.T1.13.4.3.1">base</span></sub>’s baseline is ColBERT<sub class="ltx_sub" id="S4.T1.13.4.4"><span class="ltx_text ltx_font_italic" id="S4.T1.13.4.4.1">init</span></sub></span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Experimental Settings</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.5">We begin by retrieving the top 100 passages using BM25 with the <span class="ltx_text ltx_font_typewriter" id="S4.SS3.p1.5.1">rank_bm25</span> <span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/dorianbrown/rank_bm25" title="">https://github.com/dorianbrown/rank_bm25</a></span></span></span> BM25Okapi with <math alttext="k_{1}" class="ltx_Math" display="inline" id="S4.SS3.p1.1.m1.1"><semantics id="S4.SS3.p1.1.m1.1a"><msub id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml"><mi id="S4.SS3.p1.1.m1.1.1.2" xref="S4.SS3.p1.1.m1.1.1.2.cmml">k</mi><mn id="S4.SS3.p1.1.m1.1.1.3" xref="S4.SS3.p1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><apply id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.1.m1.1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS3.p1.1.m1.1.1.2.cmml" xref="S4.SS3.p1.1.m1.1.1.2">𝑘</ci><cn id="S4.SS3.p1.1.m1.1.1.3.cmml" type="integer" xref="S4.SS3.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">k_{1}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.1.m1.1d">italic_k start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>=1.5, <math alttext="b" class="ltx_Math" display="inline" id="S4.SS3.p1.2.m2.1"><semantics id="S4.SS3.p1.2.m2.1a"><mi id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><ci id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">b</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.2.m2.1d">italic_b</annotation></semantics></math>=0.75 and <math alttext="\epsilon" class="ltx_Math" display="inline" id="S4.SS3.p1.3.m3.1"><semantics id="S4.SS3.p1.3.m3.1a"><mi id="S4.SS3.p1.3.m3.1.1" xref="S4.SS3.p1.3.m3.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.3.m3.1b"><ci id="S4.SS3.p1.3.m3.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.3.m3.1c">\epsilon</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.3.m3.1d">italic_ϵ</annotation></semantics></math>=0.25. The <span class="ltx_text ltx_font_typewriter" id="S4.SS3.p1.5.2">nltk</span> <span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/nltk/nltk" title="">https://github.com/nltk/nltk</a></span></span></span> tokenizer is used to tokenize the questions and passages. We use BEIR <span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/beir-cellar/beir" title="">https://github.com/beir-cellar/beir</a></span></span></span> to manage data, and the DPR models are trained using <span class="ltx_text ltx_font_typewriter" id="S4.SS3.p1.5.3">sentence-transformers</span> with the following hyperparameters: batch size of 128, learning rate of <math alttext="2\times 10^{-5}" class="ltx_Math" display="inline" id="S4.SS3.p1.4.m4.1"><semantics id="S4.SS3.p1.4.m4.1a"><mrow id="S4.SS3.p1.4.m4.1.1" xref="S4.SS3.p1.4.m4.1.1.cmml"><mn id="S4.SS3.p1.4.m4.1.1.2" xref="S4.SS3.p1.4.m4.1.1.2.cmml">2</mn><mo id="S4.SS3.p1.4.m4.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.SS3.p1.4.m4.1.1.1.cmml">×</mo><msup id="S4.SS3.p1.4.m4.1.1.3" xref="S4.SS3.p1.4.m4.1.1.3.cmml"><mn id="S4.SS3.p1.4.m4.1.1.3.2" xref="S4.SS3.p1.4.m4.1.1.3.2.cmml">10</mn><mrow id="S4.SS3.p1.4.m4.1.1.3.3" xref="S4.SS3.p1.4.m4.1.1.3.3.cmml"><mo id="S4.SS3.p1.4.m4.1.1.3.3a" xref="S4.SS3.p1.4.m4.1.1.3.3.cmml">−</mo><mn id="S4.SS3.p1.4.m4.1.1.3.3.2" xref="S4.SS3.p1.4.m4.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.4.m4.1b"><apply id="S4.SS3.p1.4.m4.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1"><times id="S4.SS3.p1.4.m4.1.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1.1"></times><cn id="S4.SS3.p1.4.m4.1.1.2.cmml" type="integer" xref="S4.SS3.p1.4.m4.1.1.2">2</cn><apply id="S4.SS3.p1.4.m4.1.1.3.cmml" xref="S4.SS3.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.p1.4.m4.1.1.3.1.cmml" xref="S4.SS3.p1.4.m4.1.1.3">superscript</csymbol><cn id="S4.SS3.p1.4.m4.1.1.3.2.cmml" type="integer" xref="S4.SS3.p1.4.m4.1.1.3.2">10</cn><apply id="S4.SS3.p1.4.m4.1.1.3.3.cmml" xref="S4.SS3.p1.4.m4.1.1.3.3"><minus id="S4.SS3.p1.4.m4.1.1.3.3.1.cmml" xref="S4.SS3.p1.4.m4.1.1.3.3"></minus><cn id="S4.SS3.p1.4.m4.1.1.3.3.2.cmml" type="integer" xref="S4.SS3.p1.4.m4.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.4.m4.1c">2\times 10^{-5}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.4.m4.1d">2 × 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT</annotation></semantics></math>, AdamW optimizer, 20 epoch, and model weights are saved based on the best Recall@5 on the validation set. ColBERT is trained from scratch using RAGatouille <span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/bclavie/RAGatouille" title="">https://github.com/bclavie/RAGatouille</a></span></span></span> with a batch size of 64, 10 hard negatives per positive, learning rate of <math alttext="1\times 10^{-5}" class="ltx_Math" display="inline" id="S4.SS3.p1.5.m5.1"><semantics id="S4.SS3.p1.5.m5.1a"><mrow id="S4.SS3.p1.5.m5.1.1" xref="S4.SS3.p1.5.m5.1.1.cmml"><mn id="S4.SS3.p1.5.m5.1.1.2" xref="S4.SS3.p1.5.m5.1.1.2.cmml">1</mn><mo id="S4.SS3.p1.5.m5.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.SS3.p1.5.m5.1.1.1.cmml">×</mo><msup id="S4.SS3.p1.5.m5.1.1.3" xref="S4.SS3.p1.5.m5.1.1.3.cmml"><mn id="S4.SS3.p1.5.m5.1.1.3.2" xref="S4.SS3.p1.5.m5.1.1.3.2.cmml">10</mn><mrow id="S4.SS3.p1.5.m5.1.1.3.3" xref="S4.SS3.p1.5.m5.1.1.3.3.cmml"><mo id="S4.SS3.p1.5.m5.1.1.3.3a" xref="S4.SS3.p1.5.m5.1.1.3.3.cmml">−</mo><mn id="S4.SS3.p1.5.m5.1.1.3.3.2" xref="S4.SS3.p1.5.m5.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.5.m5.1b"><apply id="S4.SS3.p1.5.m5.1.1.cmml" xref="S4.SS3.p1.5.m5.1.1"><times id="S4.SS3.p1.5.m5.1.1.1.cmml" xref="S4.SS3.p1.5.m5.1.1.1"></times><cn id="S4.SS3.p1.5.m5.1.1.2.cmml" type="integer" xref="S4.SS3.p1.5.m5.1.1.2">1</cn><apply id="S4.SS3.p1.5.m5.1.1.3.cmml" xref="S4.SS3.p1.5.m5.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.p1.5.m5.1.1.3.1.cmml" xref="S4.SS3.p1.5.m5.1.1.3">superscript</csymbol><cn id="S4.SS3.p1.5.m5.1.1.3.2.cmml" type="integer" xref="S4.SS3.p1.5.m5.1.1.3.2">10</cn><apply id="S4.SS3.p1.5.m5.1.1.3.3.cmml" xref="S4.SS3.p1.5.m5.1.1.3.3"><minus id="S4.SS3.p1.5.m5.1.1.3.3.1.cmml" xref="S4.SS3.p1.5.m5.1.1.3.3"></minus><cn id="S4.SS3.p1.5.m5.1.1.3.3.2.cmml" type="integer" xref="S4.SS3.p1.5.m5.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.5.m5.1c">1\times 10^{-5}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.5.m5.1d">1 × 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT</annotation></semantics></math>, AdamW optimizer, and 1 epoch. Generating weak labels took approximately two days per dataset on an Nvidia V100 GPU. Our experiments are easily reproducible since BM25, ColBERT, DPR, Llama3, and all four datasets are publicly accessable.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">The prompts used to generate weak labels are shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S3.F2" title="Figure 2 ‣ 3. Method ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_tag">2</span></a>. We use the term “DOCUMENT” instead of “PASSAGE” because our testing experiments showed that “DOCUMENT” consistently yields better reranking performance. We suspect this is because “DOCUMENT” is a more common term and likely appears more frequently in Llama3’s training data, leading it to a deeper understanding of the word “DOCUMENT”. Additionally, we tested different orderings of the passage, question, and instructions, finding that the Passage-Question-Instruction format consistently outperforms Passage-Instruction-Question and Instruction-Passage-Question.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4. </span>Evaluation</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">We use Recall as our primary metric to evaluate the retrieval performance, as it focuses on whether the relevant passage is included within a specific ranking range. We also report MRR (Mean Reciprocal Rank), which is similar to Recall but also considers the position at which the relevant passage is ranked.</p>
</div>
<div class="ltx_para" id="S4.SS4.p2">
<p class="ltx_p" id="S4.SS4.p2.1">To gauge the alignment between machine-generated answers and ground-truth answers, we use F1, Rouge-L <cite class="ltx_cite ltx_citemacro_citep">(Lin, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib30" title="">2004</a>)</cite>, and BLEU-1 <cite class="ltx_cite ltx_citemacro_citep">(Papineni et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib35" title="">2002</a>)</cite>. These metrics collectively measure the overlap and sequence matching between generated and actual answers. We evaluate OpenQA performance on our uniformly random sampled test set, which contains 2,000 questions for each datasets. For questions with multiple correct answers in the dataset, we select the answer with the highest cumulative score across all OpenQA metrics.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T2.7">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.7.8.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T2.7.8.1.1" rowspan="2"><span class="ltx_text" id="S4.T2.7.8.1.1.1">Retriever</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S4.T2.7.8.1.2">MSMARCO QnA</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S4.T2.7.8.1.3">NQ</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S4.T2.7.8.1.4">SQuAD</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S4.T2.7.8.1.5">WebQ</td>
</tr>
<tr class="ltx_tr" id="S4.T2.7.9.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.7.9.2.1">MRR@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.7.9.2.2">R@1</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.7.9.2.3">R@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.7.9.2.4">MRR@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.7.9.2.5">R@1</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.7.9.2.6">R@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.7.9.2.7">MRR@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.7.9.2.8">R@1</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.7.9.2.9">R@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.7.9.2.10">MRR@5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.7.9.2.11">R@1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.7.9.2.12">R@5</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.1.1.1">ColBERT<sub class="ltx_sub" id="S4.T2.1.1.1.1"><span class="ltx_text ltx_font_italic" id="S4.T2.1.1.1.1.1">init</span></sub>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.2">0.0163</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3">0.0120</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.1.4">0.0220</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.5">0.0866</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.6">0.0093</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.1.7">0.0224</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.8">0.0504</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.9">0.0063</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.1.10">0.0158</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.11">0.0031</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.12">0.0001</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.13">0.0004</td>
</tr>
<tr class="ltx_tr" id="S4.T2.7.10.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T2.7.10.3.1">BM25</th>
<td class="ltx_td ltx_align_center" id="S4.T2.7.10.3.2">0.2781</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.10.3.3">0.1647</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.7.10.3.4">0.4580</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.10.3.5">0.5686</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.10.3.6">0.0869</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.7.10.3.7">0.3575</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.10.3.8">0.2978</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.10.3.9">0.0400</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.7.10.3.10">0.2011</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.10.3.11">0.2737</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.10.3.12">0.0285</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.10.3.13">0.1336</td>
</tr>
<tr class="ltx_tr" id="S4.T2.7.11.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T2.7.11.4.1">Contriever</th>
<td class="ltx_td ltx_align_center" id="S4.T2.7.11.4.2">0.2826</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.11.4.3">0.1585</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.7.11.4.4">0.4901</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.11.4.5">0.5524</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.11.4.6">0.0988</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.7.11.4.7">0.3585</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.11.4.8">0.2221</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.11.4.9">0.0294</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.7.11.4.10">0.1606</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.11.4.11">0.2990</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.11.4.12">0.0165</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.11.4.13">0.1304</td>
</tr>
<tr class="ltx_tr" id="S4.T2.7.12.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T2.7.12.5.1">ReContriever</th>
<td class="ltx_td ltx_align_center" id="S4.T2.7.12.5.2">0.2908</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.12.5.3">0.1589</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.7.12.5.4">0.5093</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.12.5.5">0.5831</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.12.5.6">0.1118</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.7.12.5.7">0.3952</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.12.5.8">0.2150</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.12.5.9">0.0284</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.7.12.5.10">0.1597</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.12.5.11">0.3022</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.12.5.12">0.0194</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.12.5.13">0.1370</td>
</tr>
<tr class="ltx_tr" id="S4.T2.7.13.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="13" id="S4.T2.7.13.6.1">Trained on Groundtruth Data</th>
</tr>
<tr class="ltx_tr" id="S4.T2.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.2.2.1"><math alttext="\text{DPR}_{base}" class="ltx_Math" display="inline" id="S4.T2.2.2.1.m1.1"><semantics id="S4.T2.2.2.1.m1.1a"><msub id="S4.T2.2.2.1.m1.1.1" xref="S4.T2.2.2.1.m1.1.1.cmml"><mtext id="S4.T2.2.2.1.m1.1.1.2" xref="S4.T2.2.2.1.m1.1.1.2a.cmml">DPR</mtext><mrow id="S4.T2.2.2.1.m1.1.1.3" xref="S4.T2.2.2.1.m1.1.1.3.cmml"><mi id="S4.T2.2.2.1.m1.1.1.3.2" xref="S4.T2.2.2.1.m1.1.1.3.2.cmml">b</mi><mo id="S4.T2.2.2.1.m1.1.1.3.1" xref="S4.T2.2.2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S4.T2.2.2.1.m1.1.1.3.3" xref="S4.T2.2.2.1.m1.1.1.3.3.cmml">a</mi><mo id="S4.T2.2.2.1.m1.1.1.3.1a" xref="S4.T2.2.2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S4.T2.2.2.1.m1.1.1.3.4" xref="S4.T2.2.2.1.m1.1.1.3.4.cmml">s</mi><mo id="S4.T2.2.2.1.m1.1.1.3.1b" xref="S4.T2.2.2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S4.T2.2.2.1.m1.1.1.3.5" xref="S4.T2.2.2.1.m1.1.1.3.5.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.1.m1.1b"><apply id="S4.T2.2.2.1.m1.1.1.cmml" xref="S4.T2.2.2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.2.2.1.m1.1.1.1.cmml" xref="S4.T2.2.2.1.m1.1.1">subscript</csymbol><ci id="S4.T2.2.2.1.m1.1.1.2a.cmml" xref="S4.T2.2.2.1.m1.1.1.2"><mtext id="S4.T2.2.2.1.m1.1.1.2.cmml" xref="S4.T2.2.2.1.m1.1.1.2">DPR</mtext></ci><apply id="S4.T2.2.2.1.m1.1.1.3.cmml" xref="S4.T2.2.2.1.m1.1.1.3"><times id="S4.T2.2.2.1.m1.1.1.3.1.cmml" xref="S4.T2.2.2.1.m1.1.1.3.1"></times><ci id="S4.T2.2.2.1.m1.1.1.3.2.cmml" xref="S4.T2.2.2.1.m1.1.1.3.2">𝑏</ci><ci id="S4.T2.2.2.1.m1.1.1.3.3.cmml" xref="S4.T2.2.2.1.m1.1.1.3.3">𝑎</ci><ci id="S4.T2.2.2.1.m1.1.1.3.4.cmml" xref="S4.T2.2.2.1.m1.1.1.3.4">𝑠</ci><ci id="S4.T2.2.2.1.m1.1.1.3.5.cmml" xref="S4.T2.2.2.1.m1.1.1.3.5">𝑒</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.1.m1.1c">\text{DPR}_{base}</annotation><annotation encoding="application/x-llamapun" id="S4.T2.2.2.1.m1.1d">DPR start_POSTSUBSCRIPT italic_b italic_a italic_s italic_e end_POSTSUBSCRIPT</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.2.2.2">0.3237</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.2.2.3">0.2117</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.2.2.4">0.4994</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.2.2.5">0.5608</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.2.2.6">0.1174</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.2.2.7">0.3619</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.2.2.8">0.1786</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.2.2.9">0.0199</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.2.2.10">0.1054</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.2.2.11">0.4028</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.2.2.12">0.0561</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.2.2.13">0.2059</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T2.3.3.1">ColBERT<sub class="ltx_sub" id="S4.T2.3.3.1.1"><span class="ltx_text ltx_font_italic" id="S4.T2.3.3.1.1.1">base</span></sub>
</th>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.2">0.3484</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.3">0.2097</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.3.3.4">0.5112</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.5">0.5925</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.6">0.1316</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.3.3.7">0.3082</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.8">0.2310</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.9">0.0469</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.3.3.10">0.1072</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.11">0.1157</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.12">0.0180</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.13">0.0501</td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T2.4.4.1">DPR<sub class="ltx_sub" id="S4.T2.4.4.1.1"><span class="ltx_text ltx_font_italic" id="S4.T2.4.4.1.1.1">ReCon</span></sub>
</th>
<td class="ltx_td ltx_align_center" id="S4.T2.4.4.2">0.3652</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.4.3">0.2284</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.4.4.4">0.5913</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.4.5">0.6632</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.4.6">0.1516</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.4.4.7">0.4715</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.4.8">0.2829</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.4.9">0.0393</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.4.4.10">0.2072</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.4.11">0.4155</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.4.12">0.0640</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.4.13">0.2262</td>
</tr>
<tr class="ltx_tr" id="S4.T2.7.14.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="13" id="S4.T2.7.14.7.1">Trained on W-RAG Data</th>
</tr>
<tr class="ltx_tr" id="S4.T2.5.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.5.5.1"><math alttext="\text{DPR}_{base}" class="ltx_Math" display="inline" id="S4.T2.5.5.1.m1.1"><semantics id="S4.T2.5.5.1.m1.1a"><msub id="S4.T2.5.5.1.m1.1.1" xref="S4.T2.5.5.1.m1.1.1.cmml"><mtext id="S4.T2.5.5.1.m1.1.1.2" xref="S4.T2.5.5.1.m1.1.1.2a.cmml">DPR</mtext><mrow id="S4.T2.5.5.1.m1.1.1.3" xref="S4.T2.5.5.1.m1.1.1.3.cmml"><mi id="S4.T2.5.5.1.m1.1.1.3.2" xref="S4.T2.5.5.1.m1.1.1.3.2.cmml">b</mi><mo id="S4.T2.5.5.1.m1.1.1.3.1" xref="S4.T2.5.5.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S4.T2.5.5.1.m1.1.1.3.3" xref="S4.T2.5.5.1.m1.1.1.3.3.cmml">a</mi><mo id="S4.T2.5.5.1.m1.1.1.3.1a" xref="S4.T2.5.5.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S4.T2.5.5.1.m1.1.1.3.4" xref="S4.T2.5.5.1.m1.1.1.3.4.cmml">s</mi><mo id="S4.T2.5.5.1.m1.1.1.3.1b" xref="S4.T2.5.5.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S4.T2.5.5.1.m1.1.1.3.5" xref="S4.T2.5.5.1.m1.1.1.3.5.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.1.m1.1b"><apply id="S4.T2.5.5.1.m1.1.1.cmml" xref="S4.T2.5.5.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.5.5.1.m1.1.1.1.cmml" xref="S4.T2.5.5.1.m1.1.1">subscript</csymbol><ci id="S4.T2.5.5.1.m1.1.1.2a.cmml" xref="S4.T2.5.5.1.m1.1.1.2"><mtext id="S4.T2.5.5.1.m1.1.1.2.cmml" xref="S4.T2.5.5.1.m1.1.1.2">DPR</mtext></ci><apply id="S4.T2.5.5.1.m1.1.1.3.cmml" xref="S4.T2.5.5.1.m1.1.1.3"><times id="S4.T2.5.5.1.m1.1.1.3.1.cmml" xref="S4.T2.5.5.1.m1.1.1.3.1"></times><ci id="S4.T2.5.5.1.m1.1.1.3.2.cmml" xref="S4.T2.5.5.1.m1.1.1.3.2">𝑏</ci><ci id="S4.T2.5.5.1.m1.1.1.3.3.cmml" xref="S4.T2.5.5.1.m1.1.1.3.3">𝑎</ci><ci id="S4.T2.5.5.1.m1.1.1.3.4.cmml" xref="S4.T2.5.5.1.m1.1.1.3.4">𝑠</ci><ci id="S4.T2.5.5.1.m1.1.1.3.5.cmml" xref="S4.T2.5.5.1.m1.1.1.3.5">𝑒</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.1.m1.1c">\text{DPR}_{base}</annotation><annotation encoding="application/x-llamapun" id="S4.T2.5.5.1.m1.1d">DPR start_POSTSUBSCRIPT italic_b italic_a italic_s italic_e end_POSTSUBSCRIPT</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.5.2">0.2981</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.5.3">0.1809</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.5.5.4">0.4813</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.5.5">0.5302</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.5.6">0.1012</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.5.5.7">0.3364</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.5.8">0.1781</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.5.9">0.0210</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.5.5.10">0.1020</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.5.11">0.3377</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.5.12">0.0478</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.5.13">0.1656</td>
</tr>
<tr class="ltx_tr" id="S4.T2.6.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T2.6.6.1">ColBERT<sub class="ltx_sub" id="S4.T2.6.6.1.1"><span class="ltx_text ltx_font_italic" id="S4.T2.6.6.1.1.1">base</span></sub>
</th>
<td class="ltx_td ltx_align_center" id="S4.T2.6.6.2">0.3116<sup class="ltx_sup" id="S4.T2.6.6.2.1">†</sup>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.6.3">0.1973<sup class="ltx_sup" id="S4.T2.6.6.3.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.6.6.4">0.4904<sup class="ltx_sup" id="S4.T2.6.6.4.1">†</sup>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.6.5">0.5229<sup class="ltx_sup" id="S4.T2.6.6.5.1">†</sup>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.6.6">0.0982<sup class="ltx_sup" id="S4.T2.6.6.6.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.6.6.7">0.2672<sup class="ltx_sup" id="S4.T2.6.6.7.1">†</sup>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.6.8">0.2265<sup class="ltx_sup" id="S4.T2.6.6.8.1">†</sup>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.6.9">0.0445<sup class="ltx_sup" id="S4.T2.6.6.9.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.6.6.10">0.1029<sup class="ltx_sup" id="S4.T2.6.6.10.1">†</sup>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.6.11">0.0831<sup class="ltx_sup" id="S4.T2.6.6.11.1">†</sup>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.6.12">0.0153<sup class="ltx_sup" id="S4.T2.6.6.12.1">†</sup>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.6.13">0.0326<sup class="ltx_sup" id="S4.T2.6.6.13.1">†</sup>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.7.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T2.7.7.1">DPR<sub class="ltx_sub" id="S4.T2.7.7.1.1"><span class="ltx_text ltx_font_italic" id="S4.T2.7.7.1.1.1">ReCon</span></sub>
</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.7.7.2">0.3496<sup class="ltx_sup" id="S4.T2.7.7.2.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.7.7.3">0.2023<sup class="ltx_sup" id="S4.T2.7.7.3.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T2.7.7.4">0.5887<sup class="ltx_sup" id="S4.T2.7.7.4.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.7.7.5">0.6301<sup class="ltx_sup" id="S4.T2.7.7.5.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.7.7.6">0.1311<sup class="ltx_sup" id="S4.T2.7.7.6.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T2.7.7.7">0.4267<sup class="ltx_sup" id="S4.T2.7.7.7.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.7.7.8">0.2811<sup class="ltx_sup" id="S4.T2.7.7.8.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.7.7.9">0.0382</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T2.7.7.10">0.2001<sup class="ltx_sup" id="S4.T2.7.7.10.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.7.7.11">0.3610<sup class="ltx_sup" id="S4.T2.7.7.11.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.7.7.12">0.0499<sup class="ltx_sup" id="S4.T2.7.7.12.1">†</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.7.7.13">0.1880<sup class="ltx_sup" id="S4.T2.7.7.13.1">†</sup>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T2.12.2.1" style="font-size:90%;">Table 2</span>. </span><span class="ltx_text" id="S4.T2.9.1" style="font-size:90%;">Retrieval Performance after training with W-RAG or ground-truth data. <sup class="ltx_sup" id="S4.T2.9.1.1">†</sup>: Performance improvements are statistically significant with a ttest of <math alttext="p&lt;0.05" class="ltx_Math" display="inline" id="S4.T2.9.1.m1.1"><semantics id="S4.T2.9.1.m1.1b"><mrow id="S4.T2.9.1.m1.1.1" xref="S4.T2.9.1.m1.1.1.cmml"><mi id="S4.T2.9.1.m1.1.1.2" xref="S4.T2.9.1.m1.1.1.2.cmml">p</mi><mo id="S4.T2.9.1.m1.1.1.1" xref="S4.T2.9.1.m1.1.1.1.cmml">&lt;</mo><mn id="S4.T2.9.1.m1.1.1.3" xref="S4.T2.9.1.m1.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.9.1.m1.1c"><apply id="S4.T2.9.1.m1.1.1.cmml" xref="S4.T2.9.1.m1.1.1"><lt id="S4.T2.9.1.m1.1.1.1.cmml" xref="S4.T2.9.1.m1.1.1.1"></lt><ci id="S4.T2.9.1.m1.1.1.2.cmml" xref="S4.T2.9.1.m1.1.1.2">𝑝</ci><cn id="S4.T2.9.1.m1.1.1.3.cmml" type="float" xref="S4.T2.9.1.m1.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.9.1.m1.1d">p&lt;0.05</annotation><annotation encoding="application/x-llamapun" id="S4.T2.9.1.m1.1e">italic_p &lt; 0.05</annotation></semantics></math>. </span></figcaption>
</figure>
<figure class="ltx_table" id="S4.T3">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T3.2" style="width:433.6pt;height:58.6pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-53.4pt,7.1pt) scale(0.802337932662692,0.802337932662692) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T3.2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.2.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T3.2.1.1.1.1" rowspan="2"><span class="ltx_text" id="S4.T3.2.1.1.1.1.1">Retriever</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T3.2.1.1.1.2">MSMARCO QnA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T3.2.1.1.1.3">NQ</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T3.2.1.1.1.4">SQuAD</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T3.2.1.1.1.5">WebQ</th>
</tr>
<tr class="ltx_tr" id="S4.T3.2.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.2.1.2.2.1">R@1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.2.1.2.2.2">R@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T3.2.1.2.2.3">R@50</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.2.1.2.2.4">R@1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.2.1.2.2.5">R@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T3.2.1.2.2.6">R@50</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.2.1.2.2.7">R@1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.2.1.2.2.8">R@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T3.2.1.2.2.9">R@50</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.2.1.2.2.10">R@1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.2.1.2.2.11">R@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.2.1.2.2.12">R@50</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.2.1.3.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.2.1.3.1.1">BM25</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.2.1.3.1.2">0.1694</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.2.1.3.1.3">0.4464</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.2.1.3.1.4">0.7577</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.2.1.3.1.5">0.088</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.2.1.3.1.6">0.353</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.2.1.3.1.7">0.7941</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.2.1.3.1.8">0.0449</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.2.1.3.1.9">0.2069</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.2.1.3.1.10">0.6461</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.2.1.3.1.11">0.0217</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.2.1.3.1.12">0.1155</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.2.1.3.1.13">0.5765</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.1.4.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T3.2.1.4.2.1">Llama3-8B</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.2.1.4.2.2">0.5239</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.2.1.4.2.3">0.6614</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T3.2.1.4.2.4">0.7517</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.2.1.4.2.5">0.1542</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.2.1.4.2.6">0.4224</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T3.2.1.4.2.7">0.7303</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.2.1.4.2.8">0.0805</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.2.1.4.2.9">0.3088</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T3.2.1.4.2.10">0.6774</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.2.1.4.2.11">0.0494</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.2.1.4.2.12">0.1887</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.2.1.4.2.13">0.5502</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T3.3.1.1" style="font-size:90%;">Table 3</span>. </span><span class="ltx_text" id="S4.T3.4.2" style="font-size:90%;">BM25 retrieves the top 100 passages, which are then reranked by Llama3-8B. The reranked lists are used as weak labels for training a dense retriever.</span></figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Experimental Results</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this section we discuss the final OpenQA performance, retrieval performance of trained retrievers, the quality of weak labels, and ablation studies.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>Main Results</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">We do not claim that W-RAG outperforms state-of-the-art RAG methods or achieves the best retrieval performance on any of the four datasets. Instead, we highlight the performance improvements of weakly trained retrievers compared to baselines, and demonstrate that the gap between weakly supervised and ground-truth trained retrievers is relatively small. This relationship is evident in both the retrieval performance and the final RAG for OpenQA performance.</p>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">The goal of W-RAG is to enhance LLM generation quality by providing relevant evidence passages. Tabel <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S4.T1" title="Table 1 ‣ 4.2. Baselines ‣ 4. Experiments ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_tag">1</span></a> presents the main OpenQA results using different retrievers in the RAG pipeline, evaluated on 2,000 test questions for each dataset. For these experiments, only the top 1 retrieved passage is added to the prompt, and the LLM is limited to generating 20 tokens. The Naive and Groundtruth baselines represent the lower and upper bounds, respectively. The Naive baseline excludes any supplementary passage, while Groundtruth includes the best passage. Any retriever that retrieves relevant passages should outperform the Naive baseline, while surpassing the Groundtruth baseline would be very unexpected. Results show consistent improvements with W-RAG trained retrievers across all datasets, with most of them being statistically significant. The relatively small gap between W-RAG trained and ground-truth trained retrievers suggests that W-RAG data approaches the quality of human-labeled data.</p>
</div>
<div class="ltx_para" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1">One baseline, ColBERT<sub class="ltx_sub" id="S5.SS1.p3.1.1"><span class="ltx_text ltx_font_italic" id="S5.SS1.p3.1.1.1">init</span></sub> (initialized with <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p3.1.2">bert-base-uncased</span>), underperforms the Naive baseline, likely due to irrelevant passages being retrieved, introducing noise that misguides Llama3. We notice that for NQ, SQuAD, and WebQ, all the OpenQA metrics are small. This is due to the brevity of ground-truth answers (average length  2 words). For example, in response to the NQ question ”When did Big air Snowboarding become an Olympic sport?”, Llama3 outputs the correct answer: ”Big Air Snowboarding was first added to the 2018 Winter Olympics.” Since the ground-truth answer given by NQ is just ”2018”, standard OpenQA metrics like F1 and Rouge-L would yield low scores due to the denominator of the Precision term being the length of the generated answer, while the numerator is n-gram overlap which is at most 1 in this case. Despite this, these metrics remain valuable; if Llama3’s answer omitted ”2018,” the score would be zero. The absolute metric values are less important than the relative differences across settings. Although token length could be treated as a hyperparameter, we limited generation to 20 tokens across datasets for consistency.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>Retrieval Results</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">The retrieval results of different trained retrievers are presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S4.T2" title="Table 2 ‣ 4.4. Evaluation ‣ 4. Experiments ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_tag">2</span></a>. These results are based on 2,000 test questions for each trained or baseline retriever. On the MSMARCO QnA dataset, all retrievers trained on W-RAG data outperformed all baselines, while DPR<sub class="ltx_sub" id="S5.SS2.p1.1.1"><span class="ltx_text ltx_font_italic" id="S5.SS2.p1.1.1.1">ReCon</span></sub> consistently outperformed all unsupervised baselines, except for SQuAD where BM25 performed best. As expected, DPR trained on ReContriever showed better retrieval performance than DPR trained from scratch. Similar to the OpenQA task, W-RAG trained retrievers slightly underperform compared to those trained on ground-truth data.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.4">Although there appears to be a positive correlation between retrieval performance and OpenQA performance, this relationship is noisy and sometimes inconsistent. For instance, W-RAG trained ColBERT<sub class="ltx_sub" id="S5.SS2.p2.4.1"><span class="ltx_text ltx_font_italic" id="S5.SS2.p2.4.1.1">base</span></sub> achieved nearly 4% higher Recall@1 than ReContriever on MSMARCO QnA, ranking the relevant passage at top for about 80 more questions. However, when these top 1 passages are used for OpenQA, ColBERT<sub class="ltx_sub" id="S5.SS2.p2.4.2"><span class="ltx_text ltx_font_italic" id="S5.SS2.p2.4.2.1">base</span></sub> performed slighly worse than ReContriever. Similarly, ground-truth trained DPR<sub class="ltx_sub" id="S5.SS2.p2.4.3"><span class="ltx_text ltx_font_italic" id="S5.SS2.p2.4.3.1">ReCon</span></sub> significantly outperformed W-RAG trained DPR<sub class="ltx_sub" id="S5.SS2.p2.4.4"><span class="ltx_text ltx_font_italic" id="S5.SS2.p2.4.4.1">ReCon</span></sub> in Recall@1 on MSMARCO QnA, yet their OpenQA performance was almost identical when using the top-ranked passage.</p>
</div>
<div class="ltx_para" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.1">These findings suggest that the traditional definition of relevance may not directly impact the answer quality in RAG systems. W-RAG’s top passage is selected based on its ability to elicit the correct answer from the LLM, while ground-truth passages are typically chosen based on term overlap, semantic similarity, or human judgment. Contrary to expectations, better retrieval does not always lead to better OpenQA. This raises the question: “Is the relevance definition in existing datasets truly effective for evaluating retrievers in RAG systems?”</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3. </span>W-RAG Labels</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">After generating all of W-RAG data, we examine its retrieval performance and the quality of the weakly labeled rank lists. In Table <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S4.T3" title="Table 3 ‣ 4.4. Evaluation ‣ 4. Experiments ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_tag">3</span></a>, a significant gap between BM25 and Llama3’s reranking performance at Recall@1 is evident, which justifies our choise of only using the top 1 passage as the positive when training different retrievers. We also observe that Llama3’s performance declines as the number of passages increases. This is likely due to the fact that starting from around the 50th position, the difference in answer likelihood between adjacent passages diminishes to negligible values, such as <math alttext="\exp(-3.24815)-\exp(-3.24899)\approx 3\times 10^{-5}" class="ltx_Math" display="inline" id="S5.SS3.p1.1.m1.4"><semantics id="S5.SS3.p1.1.m1.4a"><mrow id="S5.SS3.p1.1.m1.4.4" xref="S5.SS3.p1.1.m1.4.4.cmml"><mrow id="S5.SS3.p1.1.m1.4.4.2" xref="S5.SS3.p1.1.m1.4.4.2.cmml"><mrow id="S5.SS3.p1.1.m1.3.3.1.1.1" xref="S5.SS3.p1.1.m1.3.3.1.1.2.cmml"><mi id="S5.SS3.p1.1.m1.1.1" xref="S5.SS3.p1.1.m1.1.1.cmml">exp</mi><mo id="S5.SS3.p1.1.m1.3.3.1.1.1a" xref="S5.SS3.p1.1.m1.3.3.1.1.2.cmml">⁡</mo><mrow id="S5.SS3.p1.1.m1.3.3.1.1.1.1" xref="S5.SS3.p1.1.m1.3.3.1.1.2.cmml"><mo id="S5.SS3.p1.1.m1.3.3.1.1.1.1.2" stretchy="false" xref="S5.SS3.p1.1.m1.3.3.1.1.2.cmml">(</mo><mrow id="S5.SS3.p1.1.m1.3.3.1.1.1.1.1" xref="S5.SS3.p1.1.m1.3.3.1.1.1.1.1.cmml"><mo id="S5.SS3.p1.1.m1.3.3.1.1.1.1.1a" xref="S5.SS3.p1.1.m1.3.3.1.1.1.1.1.cmml">−</mo><mn id="S5.SS3.p1.1.m1.3.3.1.1.1.1.1.2" xref="S5.SS3.p1.1.m1.3.3.1.1.1.1.1.2.cmml">3.24815</mn></mrow><mo id="S5.SS3.p1.1.m1.3.3.1.1.1.1.3" stretchy="false" xref="S5.SS3.p1.1.m1.3.3.1.1.2.cmml">)</mo></mrow></mrow><mo id="S5.SS3.p1.1.m1.4.4.2.3" xref="S5.SS3.p1.1.m1.4.4.2.3.cmml">−</mo><mrow id="S5.SS3.p1.1.m1.4.4.2.2.1" xref="S5.SS3.p1.1.m1.4.4.2.2.2.cmml"><mi id="S5.SS3.p1.1.m1.2.2" xref="S5.SS3.p1.1.m1.2.2.cmml">exp</mi><mo id="S5.SS3.p1.1.m1.4.4.2.2.1a" xref="S5.SS3.p1.1.m1.4.4.2.2.2.cmml">⁡</mo><mrow id="S5.SS3.p1.1.m1.4.4.2.2.1.1" xref="S5.SS3.p1.1.m1.4.4.2.2.2.cmml"><mo id="S5.SS3.p1.1.m1.4.4.2.2.1.1.2" stretchy="false" xref="S5.SS3.p1.1.m1.4.4.2.2.2.cmml">(</mo><mrow id="S5.SS3.p1.1.m1.4.4.2.2.1.1.1" xref="S5.SS3.p1.1.m1.4.4.2.2.1.1.1.cmml"><mo id="S5.SS3.p1.1.m1.4.4.2.2.1.1.1a" xref="S5.SS3.p1.1.m1.4.4.2.2.1.1.1.cmml">−</mo><mn id="S5.SS3.p1.1.m1.4.4.2.2.1.1.1.2" xref="S5.SS3.p1.1.m1.4.4.2.2.1.1.1.2.cmml">3.24899</mn></mrow><mo id="S5.SS3.p1.1.m1.4.4.2.2.1.1.3" stretchy="false" xref="S5.SS3.p1.1.m1.4.4.2.2.2.cmml">)</mo></mrow></mrow></mrow><mo id="S5.SS3.p1.1.m1.4.4.3" xref="S5.SS3.p1.1.m1.4.4.3.cmml">≈</mo><mrow id="S5.SS3.p1.1.m1.4.4.4" xref="S5.SS3.p1.1.m1.4.4.4.cmml"><mn id="S5.SS3.p1.1.m1.4.4.4.2" xref="S5.SS3.p1.1.m1.4.4.4.2.cmml">3</mn><mo id="S5.SS3.p1.1.m1.4.4.4.1" lspace="0.222em" rspace="0.222em" xref="S5.SS3.p1.1.m1.4.4.4.1.cmml">×</mo><msup id="S5.SS3.p1.1.m1.4.4.4.3" xref="S5.SS3.p1.1.m1.4.4.4.3.cmml"><mn id="S5.SS3.p1.1.m1.4.4.4.3.2" xref="S5.SS3.p1.1.m1.4.4.4.3.2.cmml">10</mn><mrow id="S5.SS3.p1.1.m1.4.4.4.3.3" xref="S5.SS3.p1.1.m1.4.4.4.3.3.cmml"><mo id="S5.SS3.p1.1.m1.4.4.4.3.3a" xref="S5.SS3.p1.1.m1.4.4.4.3.3.cmml">−</mo><mn id="S5.SS3.p1.1.m1.4.4.4.3.3.2" xref="S5.SS3.p1.1.m1.4.4.4.3.3.2.cmml">5</mn></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.1.m1.4b"><apply id="S5.SS3.p1.1.m1.4.4.cmml" xref="S5.SS3.p1.1.m1.4.4"><approx id="S5.SS3.p1.1.m1.4.4.3.cmml" xref="S5.SS3.p1.1.m1.4.4.3"></approx><apply id="S5.SS3.p1.1.m1.4.4.2.cmml" xref="S5.SS3.p1.1.m1.4.4.2"><minus id="S5.SS3.p1.1.m1.4.4.2.3.cmml" xref="S5.SS3.p1.1.m1.4.4.2.3"></minus><apply id="S5.SS3.p1.1.m1.3.3.1.1.2.cmml" xref="S5.SS3.p1.1.m1.3.3.1.1.1"><exp id="S5.SS3.p1.1.m1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1"></exp><apply id="S5.SS3.p1.1.m1.3.3.1.1.1.1.1.cmml" xref="S5.SS3.p1.1.m1.3.3.1.1.1.1.1"><minus id="S5.SS3.p1.1.m1.3.3.1.1.1.1.1.1.cmml" xref="S5.SS3.p1.1.m1.3.3.1.1.1.1.1"></minus><cn id="S5.SS3.p1.1.m1.3.3.1.1.1.1.1.2.cmml" type="float" xref="S5.SS3.p1.1.m1.3.3.1.1.1.1.1.2">3.24815</cn></apply></apply><apply id="S5.SS3.p1.1.m1.4.4.2.2.2.cmml" xref="S5.SS3.p1.1.m1.4.4.2.2.1"><exp id="S5.SS3.p1.1.m1.2.2.cmml" xref="S5.SS3.p1.1.m1.2.2"></exp><apply id="S5.SS3.p1.1.m1.4.4.2.2.1.1.1.cmml" xref="S5.SS3.p1.1.m1.4.4.2.2.1.1.1"><minus id="S5.SS3.p1.1.m1.4.4.2.2.1.1.1.1.cmml" xref="S5.SS3.p1.1.m1.4.4.2.2.1.1.1"></minus><cn id="S5.SS3.p1.1.m1.4.4.2.2.1.1.1.2.cmml" type="float" xref="S5.SS3.p1.1.m1.4.4.2.2.1.1.1.2">3.24899</cn></apply></apply></apply><apply id="S5.SS3.p1.1.m1.4.4.4.cmml" xref="S5.SS3.p1.1.m1.4.4.4"><times id="S5.SS3.p1.1.m1.4.4.4.1.cmml" xref="S5.SS3.p1.1.m1.4.4.4.1"></times><cn id="S5.SS3.p1.1.m1.4.4.4.2.cmml" type="integer" xref="S5.SS3.p1.1.m1.4.4.4.2">3</cn><apply id="S5.SS3.p1.1.m1.4.4.4.3.cmml" xref="S5.SS3.p1.1.m1.4.4.4.3"><csymbol cd="ambiguous" id="S5.SS3.p1.1.m1.4.4.4.3.1.cmml" xref="S5.SS3.p1.1.m1.4.4.4.3">superscript</csymbol><cn id="S5.SS3.p1.1.m1.4.4.4.3.2.cmml" type="integer" xref="S5.SS3.p1.1.m1.4.4.4.3.2">10</cn><apply id="S5.SS3.p1.1.m1.4.4.4.3.3.cmml" xref="S5.SS3.p1.1.m1.4.4.4.3.3"><minus id="S5.SS3.p1.1.m1.4.4.4.3.3.1.cmml" xref="S5.SS3.p1.1.m1.4.4.4.3.3"></minus><cn id="S5.SS3.p1.1.m1.4.4.4.3.3.2.cmml" type="integer" xref="S5.SS3.p1.1.m1.4.4.4.3.3.2">5</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.1.m1.4c">\exp(-3.24815)-\exp(-3.24899)\approx 3\times 10^{-5}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.1.m1.4d">roman_exp ( - 3.24815 ) - roman_exp ( - 3.24899 ) ≈ 3 × 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT</annotation></semantics></math>.</p>
</div>
<figure class="ltx_table" id="S5.T4">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T4.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T4.2.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S5.T4.2.1.1.1">Prompt</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T4.2.1.1.2">R@1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S5.T4.2.1.1.3">R@5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T4.2.1.1.4">F1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T4.2.1.1.5">Rouge-L</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T4.2.1.1.6">BLEU</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T4.2.2.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.2.2.1.1">BM25</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.2.2.1.2">0.1343</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.2.2.1.3">0.4128</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.2.2.1.4">0.2797</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.2.2.1.5">0.2436</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.2.2.1.6">0.0640</td>
</tr>
<tr class="ltx_tr" id="S5.T4.2.3.2">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.2.3.2.1">UPR</td>
<td class="ltx_td ltx_align_center" id="S5.T4.2.3.2.2">0.1970</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.2.3.2.3">0.4970</td>
<td class="ltx_td ltx_align_center" id="S5.T4.2.3.2.4">0.2898</td>
<td class="ltx_td ltx_align_center" id="S5.T4.2.3.2.5">0.2538</td>
<td class="ltx_td ltx_align_center" id="S5.T4.2.3.2.6">0.0677</td>
</tr>
<tr class="ltx_tr" id="S5.T4.2.4.3">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.2.4.3.1">Zero-shot</td>
<td class="ltx_td ltx_align_center" id="S5.T4.2.4.3.2">0.5027</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.2.4.3.3">0.6289</td>
<td class="ltx_td ltx_align_center" id="S5.T4.2.4.3.4">0.4300</td>
<td class="ltx_td ltx_align_center" id="S5.T4.2.4.3.5">0.3924</td>
<td class="ltx_td ltx_align_center" id="S5.T4.2.4.3.6">0.1876</td>
</tr>
<tr class="ltx_tr" id="S5.T4.2.5.4">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.2.5.4.1">One-shot</td>
<td class="ltx_td ltx_align_center" id="S5.T4.2.5.4.2">0.5187</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.2.5.4.3">0.6690</td>
<td class="ltx_td ltx_align_center" id="S5.T4.2.5.4.4">0.4358</td>
<td class="ltx_td ltx_align_center" id="S5.T4.2.5.4.5">0.3976</td>
<td class="ltx_td ltx_align_center" id="S5.T4.2.5.4.6">0.1939</td>
</tr>
<tr class="ltx_tr" id="S5.T4.2.6.5">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T4.2.6.5.1">Two-shot</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.2.6.5.2">0.5137</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T4.2.6.5.3">0.6840</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.2.6.5.4">0.4256</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.2.6.5.5">0.3858</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.2.6.5.6">0.1812</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S5.T4.3.1.1" style="font-size:90%;">Table 4</span>. </span><span class="ltx_text" id="S5.T4.4.2" style="font-size:90%;">Llama3-8B-Instruct’s reranking performance using different prompts on 500 validation questions from the MSMARCO QnA dataset. Answers are generated using only the top 1 reranked passage. </span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4. </span>Ablation Study</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1">We assessed the quality of W-RAG data generated by different LLMs, specifically their ability to rerank passages based on answer likelihood. This is illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S5.F3" title="Figure 3 ‣ 5.4. Ablation Study ‣ 5. Experimental Results ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_tag">3</span></a>, showing the reranking performance of various LLMs on 500 questions from the validation set of MSMARCO QnA. Although the LLMs notably differs at Recall@5, they exhibit consistent trends with each other. We notice Llama3-8B-Instruct is weak when compared to other examined LLMs. However, since their recall distributions are similar, any of these LLMs can serve as the reranker. We chose to use Llama3-8B-Instruct for all our experiments.</p>
</div>
<figure class="ltx_table" id="S5.T5">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T5.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T5.4.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S5.T5.4.1.1.1">#</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.4.1.1.2">F1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.4.1.1.3">Rouge-L</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.4.1.1.4">BLEU-1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.4.1.1.5">Latency (sec/infer)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T5.4.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T5.4.2.1.1">1</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.4.2.1.2">0.3397</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.4.2.1.3">0.3074</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.4.2.1.4">0.2559</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.4.2.1.5">1.043</td>
</tr>
<tr class="ltx_tr" id="S5.T5.4.3.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T5.4.3.2.1">3</th>
<td class="ltx_td ltx_align_center" id="S5.T5.4.3.2.2">0.3744</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.3.2.3">0.3395</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.3.2.4">0.2818</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.3.2.5">1.270</td>
</tr>
<tr class="ltx_tr" id="S5.T5.4.4.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S5.T5.4.4.3.1">5</th>
<td class="ltx_td ltx_align_center" id="S5.T5.4.4.3.2">0.3767</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.4.3.3">0.3427</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.4.3.4">0.2835</td>
<td class="ltx_td ltx_align_center" id="S5.T5.4.4.3.5">1.454</td>
</tr>
<tr class="ltx_tr" id="S5.T5.4.5.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S5.T5.4.5.4.1">10</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.4.5.4.2">0.3864</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.4.5.4.3">0.3524</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.4.5.4.4">0.2911</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.4.5.4.5">2.134</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S5.T5.6.2.1" style="font-size:90%;">Table 5</span>. </span><span class="ltx_text" id="S5.T5.2.1" style="font-size:90%;">Adding different # of evidence passages to the prompt when doing OpenQA using DPR<sub class="ltx_sub" id="S5.T5.2.1.1"><span class="ltx_text ltx_font_italic" id="S5.T5.2.1.1.1">ReCon</span></sub> on 2,000 test questions from MSMARCO QnA.</span></figcaption>
</figure>
<div class="ltx_para" id="S5.SS4.p2">
<p class="ltx_p" id="S5.SS4.p2.1">Using Llama3-8B-Instruct, we evaluated reranking and OpenQA performance, as presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S5.T4" title="Table 4 ‣ 5.3. W-RAG Labels ‣ 5. Experimental Results ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_tag">4</span></a>. UPR <cite class="ltx_cite ltx_citemacro_citep">(Sachan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib40" title="">2022a</a>)</cite>, which ranks passages based on question likelihood, serve as an unsupervised approach for generating training labels. With weak supervision of ground-truth answers, W-RAG’s zero-shot, one-shot, and two-shot prompts significantly outperforms BM25 and UPR in both reranking and OpenQA metrics. However, the differences between the various shot prompts are not very consistent and are not significant. We hypothesize that this inconsistency may have stemmed from the LLM misinterpreting example passages as the relevant passage, or if the question types are drastically different between the example and the given question, thus introducing noise and reducing result reliability. Due to this, we conducted all subsequent experiments using zero-shot prompts, shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S3.F2" title="Figure 2 ‣ 3. Method ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div class="ltx_para" id="S5.SS4.p3">
<p class="ltx_p" id="S5.SS4.p3.1">During the final OpenQA, we also study the impact of giving more evidence passages, shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#S5.T5" title="Table 5 ‣ 5.4. Ablation Study ‣ 5. Experimental Results ‣ W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering"><span class="ltx_text ltx_ref_tag">5</span></a>. We observe a consistent and steady increase in all OpenQA metrics when more evidence passages are inserted into the prompt. This behavior is expected because the more passages supplied, the better chance a good passage is within them. However, latency also grows as we increase the number of passages.</p>
</div>
<figure class="ltx_figure" id="S5.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="359" id="S5.F3.g1" src="extracted/5794588/imgs/diff_llm.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F3.2.1.1" style="font-size:90%;">Figure 3</span>. </span><span class="ltx_text" id="S5.F3.3.2" style="font-size:90%;">Comparison of recall for various LLMs at different top k positions, when reranking top 100 passages retrieved by BM25. </span></figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Conclusions and Future Work</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">This paper introduces a general framework, W-RAG, for extracting weak labels from question-answer pairs to address the scarcity of training data for dense retrieval in RAG for OpenQA. W-RAG reranks the top-<math alttext="K" class="ltx_Math" display="inline" id="S6.p1.1.m1.1"><semantics id="S6.p1.1.m1.1a"><mi id="S6.p1.1.m1.1.1" xref="S6.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S6.p1.1.m1.1b"><ci id="S6.p1.1.m1.1.1.cmml" xref="S6.p1.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S6.p1.1.m1.1d">italic_K</annotation></semantics></math> initially retrieved passages by the probability of LLMs generating the OpenQA answer conditioned on each question-passage pair. This ranking score computation method aligns well with the latest study <cite class="ltx_cite ltx_citemacro_citep">(Cuconasu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib7" title="">2024</a>)</cite>, which states that the retrieved passage should answer the question; otherwise, performance will be negatively impacted. Extensive experimental results on four public OpenQA datasets demonstrate the effectiveness of W-RAG.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">In future work, we plan to explore which types of passages most effectively enhance RAG’s performance in OpenQA, as indicated by <cite class="ltx_cite ltx_citemacro_citep">(Cuconasu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2408.08444v1#bib.bib7" title="">2024</a>)</cite>, where even randomly sampled tokens were beneficial in some cases. Understanding the types of passages preferred by LLMs will allow us to design more effective dense retrieval methods, including new structures and evaluation metrics. Additionally, the compression of retrieved passages warrants further study, as directly feeding all retrieved passages to LLMs not only increases computational complexity but also introduces significant noise. Finally, even with a ground-truth evidence passage, RAG can still produce incorrect answers, known as hallucinations; enhancing the robustness of RAG in OpenQA is another promising direction for future research.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baldelli et al<span class="ltx_text" id="bib.bib2.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Davide Baldelli, Junfeng Jiang, Akiko Aizawa, and Paolo Torroni. 2024.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.3.1">TWOLAR: A TWO-Step LLM-Augmented Distillation Method for Passage Reranking</em>.

</span>
<span class="ltx_bibblock">470–485.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1007/978-3-031-56027-9_29" title="">https://doi.org/10.1007/978-3-031-56027-9_29</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Berant et al<span class="ltx_text" id="bib.bib3.2.2.1">.</span> (2013)</span>
<span class="ltx_bibblock">
Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. 2013.

</span>
<span class="ltx_bibblock">Semantic Parsing on Freebase from Question-Answer Pairs. In <em class="ltx_emph ltx_font_italic" id="bib.bib3.3.1">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</em>, David Yarowsky, Timothy Baldwin, Anna Korhonen, Karen Livescu, and Steven Bethard (Eds.). Association for Computational Linguistics, Seattle, Washington, USA, 1533–1544.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/D13-1160" title="">https://aclanthology.org/D13-1160</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Berger et al<span class="ltx_text" id="bib.bib4.2.2.1">.</span> (2000)</span>
<span class="ltx_bibblock">
Adam L. Berger, Rich Caruana, David Cohn, Dayne Freitag, and Vibhu O. Mittal. 2000.

</span>
<span class="ltx_bibblock">Bridging the lexical chasm: statistical approaches to answer-finding. In <em class="ltx_emph ltx_font_italic" id="bib.bib4.3.1">SIGIR 2000: Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, July 24-28, 2000, Athens, Greece</em>, Emmanuel J. Yannakoudakis, Nicholas J. Belkin, Peter Ingwersen, and Mun-Kew Leong (Eds.). ACM, 192–199.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/345508.345576" title="">https://doi.org/10.1145/345508.345576</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al<span class="ltx_text" id="bib.bib5.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Qinyuan Cheng, Xiaonan Li, Shimin Li, Qin Zhu, Zhangyue Yin, Yunfan Shao, Linyang Li, Tianxiang Sun, Hang Yan, and Xipeng Qiu. 2024.

</span>
<span class="ltx_bibblock">Unified Active Retrieval for Retrieval Augmented Generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.3.1">CoRR</em> abs/2406.12534 (2024).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/ARXIV.2406.12534" title="">https://doi.org/10.48550/ARXIV.2406.12534</a>
arXiv:2406.12534

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cho et al<span class="ltx_text" id="bib.bib6.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Sukmin Cho, Soyeong Jeong, Jeongyeon Seo, and Jong C. Park. 2023.

</span>
<span class="ltx_bibblock">Discrete Prompt Optimization via Constrained Generation for Zero-shot Re-ranker.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2305.13729 [cs.IR]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cuconasu et al<span class="ltx_text" id="bib.bib7.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Florin Cuconasu, Giovanni Trappolini, Federico Siciliano, Simone Filice, Cesare Campagnano, Yoelle Maarek, Nicola Tonellotto, and Fabrizio Silvestri. 2024.

</span>
<span class="ltx_bibblock">The Power of Noise: Redefining Retrieval for RAG Systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib7.3.1">Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval</em> (Washington DC, USA) <em class="ltx_emph ltx_font_italic" id="bib.bib7.4.2">(SIGIR ’24)</em>. Association for Computing Machinery, New York, NY, USA, 719–729.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3626772.3657834" title="">https://doi.org/10.1145/3626772.3657834</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al<span class="ltx_text" id="bib.bib8.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.

</span>
<span class="ltx_bibblock">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In <em class="ltx_emph ltx_font_italic" id="bib.bib8.3.1">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers)</em>, Jill Burstein, Christy Doran, and Thamar Solorio (Eds.). Association for Computational Linguistics, 4171–4186.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/V1/N19-1423" title="">https://doi.org/10.18653/V1/N19-1423</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Douze et al<span class="ltx_text" id="bib.bib9.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Matthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff Johnson, Gergely Szilvasy, Pierre-Emmanuel Mazaré, Maria Lomeli, Lucas Hosseini, and Hervé Jégou. 2024.

</span>
<span class="ltx_bibblock">The Faiss library.

</span>
<span class="ltx_bibblock">(2024).

</span>
<span class="ltx_bibblock">arXiv:2401.08281 [cs.LG]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dubey and .etl (2024)</span>
<span class="ltx_bibblock">
Abhimanyu Dubey and Abhinav Jauhri .etl. 2024.

</span>
<span class="ltx_bibblock">The Llama 3 Herd of Models.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2407.21783 [cs.AI]

<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2407.21783" title="">https://arxiv.org/abs/2407.21783</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dubey et al<span class="ltx_text" id="bib.bib11.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al<span class="ltx_text" id="bib.bib11.3.1">.</span> 2024.

</span>
<span class="ltx_bibblock">The llama 3 herd of models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.4.1">arXiv preprint arXiv:2407.21783</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guu et al<span class="ltx_text" id="bib.bib12.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang. 2020.

</span>
<span class="ltx_bibblock">REALM: Retrieval-Augmented Language Model Pre-Training.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.3.1">CoRR</em> abs/2002.08909 (2020).

</span>
<span class="ltx_bibblock">arXiv:2002.08909

<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2002.08909" title="">https://arxiv.org/abs/2002.08909</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Henderson et al<span class="ltx_text" id="bib.bib13.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Matthew Henderson, Rami Al-Rfou, Brian Strope, Yun hsuan Sung, Laszlo Lukacs, Ruiqi Guo, Sanjiv Kumar, Balint Miklos, and Ray Kurzweil. 2017.

</span>
<span class="ltx_bibblock">Efficient Natural Language Response Suggestion for Smart Reply.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1705.00652 [cs.CL]

<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/1705.00652" title="">https://arxiv.org/abs/1705.00652</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hofstätter et al<span class="ltx_text" id="bib.bib14.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Sebastian Hofstätter, Sheng-Chieh Lin, Jheng-Hong Yang, Jimmy Lin, and Allan Hanbury. 2021.

</span>
<span class="ltx_bibblock">Efficiently Teaching an Effective Dense Retriever with Balanced Topic Aware Sampling. In <em class="ltx_emph ltx_font_italic" id="bib.bib14.3.1">SIGIR ’21: The 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, Virtual Event, Canada, July 11-15, 2021</em>, Fernando Diaz, Chirag Shah, Torsten Suel, Pablo Castells, Rosie Jones, and Tetsuya Sakai (Eds.). ACM, 113–122.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3404835.3462891" title="">https://doi.org/10.1145/3404835.3462891</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard et al<span class="ltx_text" id="bib.bib15.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bojanowski, Armand Joulin, and Edouard Grave. 2021.

</span>
<span class="ltx_bibblock">Unsupervised Dense Information Retrieval with Contrastive Learning.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/ARXIV.2112.09118" title="">https://doi.org/10.48550/ARXIV.2112.09118</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard et al<span class="ltx_text" id="bib.bib16.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bojanowski, Armand Joulin, and Edouard Grave. 2022.

</span>
<span class="ltx_bibblock">Unsupervised Dense Information Retrieval with Contrastive Learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.3.1">Trans. Mach. Learn. Res.</em> 2022 (2022).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=jKN1pXi7b0" title="">https://openreview.net/forum?id=jKN1pXi7b0</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al<span class="ltx_text" id="bib.bib17.2.2.1">.</span> (2023a)</span>
<span class="ltx_bibblock">
Huiqiang Jiang, Qianhui Wu, Xufang Luo, Dongsheng Li, Chin-Yew Lin, Yuqing Yang, and Lili Qiu. 2023a.

</span>
<span class="ltx_bibblock">LongLLMLingua: Accelerating and Enhancing LLMs in Long Context Scenarios via Prompt Compression.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.3.1">CoRR</em> abs/2310.06839 (2023).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/ARXIV.2310.06839" title="">https://doi.org/10.48550/ARXIV.2310.06839</a>
arXiv:2310.06839

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al<span class="ltx_text" id="bib.bib18.2.2.1">.</span> (2023b)</span>
<span class="ltx_bibblock">
Zhengbao Jiang, Frank F. Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, and Graham Neubig. 2023b.

</span>
<span class="ltx_bibblock">Active Retrieval Augmented Generation. In <em class="ltx_emph ltx_font_italic" id="bib.bib18.3.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023</em>, Houda Bouamor, Juan Pino, and Kalika Bali (Eds.). Association for Computational Linguistics, 7969–7992.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/V1/2023.EMNLP-MAIN.495" title="">https://doi.org/10.18653/V1/2023.EMNLP-MAIN.495</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jr. et al<span class="ltx_text" id="bib.bib19.2.2.1">.</span> (1961)</span>
<span class="ltx_bibblock">
Bert F. Green Jr., Alice K. Wolf, Carol Chomsky, and Kenneth Laughery. 1961.

</span>
<span class="ltx_bibblock">Baseball: an automatic question-answerer. In <em class="ltx_emph ltx_font_italic" id="bib.bib19.3.1">Papers presented at the 1961 western joint IRE-AIEE-ACM computer conference, IRE-AIEE-ACM 1961 (Western), Los Angeles, California, USA, May 9-11, 1961</em>, Walter F. Bauer (Ed.). ACM, 219–224.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/1460690.1460714" title="">https://doi.org/10.1145/1460690.1460714</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karpukhin et al<span class="ltx_text" id="bib.bib20.2.2.1">.</span> (2020a)</span>
<span class="ltx_bibblock">
Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020a.

</span>
<span class="ltx_bibblock">Dense Passage Retrieval for Open-Domain Question Answering. In <em class="ltx_emph ltx_font_italic" id="bib.bib20.3.1">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>. Association for Computational Linguistics, Online, 6769–6781.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2020.emnlp-main.550" title="">https://doi.org/10.18653/v1/2020.emnlp-main.550</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karpukhin et al<span class="ltx_text" id="bib.bib21.2.2.1">.</span> (2020b)</span>
<span class="ltx_bibblock">
Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick S. H. Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020b.

</span>
<span class="ltx_bibblock">Dense Passage Retrieval for Open-Domain Question Answering. In <em class="ltx_emph ltx_font_italic" id="bib.bib21.3.1">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020</em>, Bonnie Webber, Trevor Cohn, Yulan He, and Yang Liu (Eds.). Association for Computational Linguistics, 6769–6781.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/V1/2020.EMNLP-MAIN.550" title="">https://doi.org/10.18653/V1/2020.EMNLP-MAIN.550</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khattab and Zaharia (2020a)</span>
<span class="ltx_bibblock">
Omar Khattab and Matei Zaharia. 2020a.

</span>
<span class="ltx_bibblock">ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT. In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval, SIGIR 2020, Virtual Event, China, July 25-30, 2020</em>, Jimmy X. Huang, Yi Chang, Xueqi Cheng, Jaap Kamps, Vanessa Murdock, Ji-Rong Wen, and Yiqun Liu (Eds.). ACM, 39–48.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3397271.3401075" title="">https://doi.org/10.1145/3397271.3401075</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khattab and Zaharia (2020b)</span>
<span class="ltx_bibblock">
Omar Khattab and Matei Zaharia. 2020b.

</span>
<span class="ltx_bibblock">ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT. In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</em> (Virtual Event, China) <em class="ltx_emph ltx_font_italic" id="bib.bib23.2.2">(SIGIR ’20)</em>. Association for Computing Machinery, New York, NY, USA, 39–48.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3397271.3401075" title="">https://doi.org/10.1145/3397271.3401075</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al<span class="ltx_text" id="bib.bib24.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Jaehyung Kim, Jaehyun Nam, Sangwoo Mo, Jongjin Park, Sang-Woo Lee, Minjoon Seo, Jung-Woo Ha, and Jinwoo Shin. 2024.

</span>
<span class="ltx_bibblock">SuRe: Summarizing Retrievals using Answer Candidates for Open-domain QA of LLMs. In <em class="ltx_emph ltx_font_italic" id="bib.bib24.3.1">The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024</em>. OpenReview.net.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=w4DW6qkRmt" title="">https://openreview.net/forum?id=w4DW6qkRmt</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kwiatkowski et al<span class="ltx_text" id="bib.bib25.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. 2019.

</span>
<span class="ltx_bibblock">Natural Questions: A Benchmark for Question Answering Research.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.3.1">Transactions of the Association for Computational Linguistics</em> 7 (2019), 452–466.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1162/tacl_a_00276" title="">https://doi.org/10.1162/tacl_a_00276</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lei et al<span class="ltx_text" id="bib.bib26.2.2.1">.</span> (2023a)</span>
<span class="ltx_bibblock">
Yibin Lei, Liang Ding, Yu Cao, Changtong Zan, Andrew Yates, and Dacheng Tao. 2023a.

</span>
<span class="ltx_bibblock">Unsupervised Dense Retrieval with Relevance-Aware Contrastive Pre-Training. In <em class="ltx_emph ltx_font_italic" id="bib.bib26.3.1">Findings of the Association for Computational Linguistics: ACL 2023, Toronto, Canada, July 9-14, 2023</em>, Anna Rogers, Jordan L. Boyd-Graber, and Naoaki Okazaki (Eds.). Association for Computational Linguistics, 10932–10940.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/V1/2023.FINDINGS-ACL.695" title="">https://doi.org/10.18653/V1/2023.FINDINGS-ACL.695</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lei et al<span class="ltx_text" id="bib.bib27.2.2.1">.</span> (2023b)</span>
<span class="ltx_bibblock">
Yibin Lei, Liang Ding, Yu Cao, Changtong Zan, Andrew Yates, and Dacheng Tao. 2023b.

</span>
<span class="ltx_bibblock">Unsupervised Dense Retrieval with Relevance-Aware Contrastive Pre-Training. In <em class="ltx_emph ltx_font_italic" id="bib.bib27.3.1">Findings of the Association for Computational Linguistics: ACL 2023</em>, Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki (Eds.). Association for Computational Linguistics, Toronto, Canada, 10932–10940.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2023.findings-acl.695" title="">https://doi.org/10.18653/v1/2023.findings-acl.695</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et al<span class="ltx_text" id="bib.bib28.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al<span class="ltx_text" id="bib.bib28.3.1">.</span> 2020.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for knowledge-intensive nlp tasks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.4.1">Advances in Neural Information Processing Systems</em> 33 (2020), 9459–9474.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span class="ltx_text" id="bib.bib29.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Yucheng Li, Bo Dong, Frank Guerin, and Chenghua Lin. 2023.

</span>
<span class="ltx_bibblock">Compressing Context to Enhance Inference Efficiency of Large Language Models. In <em class="ltx_emph ltx_font_italic" id="bib.bib29.3.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023</em>, Houda Bouamor, Juan Pino, and Kalika Bali (Eds.). Association for Computational Linguistics, 6342–6353.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/V1/2023.EMNLP-MAIN.391" title="">https://doi.org/10.18653/V1/2023.EMNLP-MAIN.391</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin (2004)</span>
<span class="ltx_bibblock">
Chin-Yew Lin. 2004.

</span>
<span class="ltx_bibblock">ROUGE: A Package for Automatic Evaluation of Summaries. In <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Text Summarization Branches Out</em>. Association for Computational Linguistics, Barcelona, Spain, 74–81.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/W04-1013" title="">https://aclanthology.org/W04-1013</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et al<span class="ltx_text" id="bib.bib31.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Xueguang Ma, Xinyu Zhang, Ronak Pradeep, and Jimmy Lin. 2023.

</span>
<span class="ltx_bibblock">Zero-shot listwise document reranking with a large language model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.3.1">arXiv preprint arXiv:2305.02156</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen et al<span class="ltx_text" id="bib.bib32.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, and Li Deng. 2016.

</span>
<span class="ltx_bibblock">Ms marco: A human-generated machine reading comprehension dataset.

</span>
<span class="ltx_bibblock">(2016).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nogueira et al<span class="ltx_text" id="bib.bib33.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Rodrigo Nogueira, Zhiying Jiang, and Jimmy Lin. 2020.

</span>
<span class="ltx_bibblock">Document Ranking with a Pretrained Sequence-to-Sequence Model.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2003.06713 [cs.IR]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI. 2023.

</span>
<span class="ltx_bibblock">GPT-4 Technical Report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">CoRR</em> abs/2303.08774 (2023).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/ARXIV.2303.08774" title="">https://doi.org/10.48550/ARXIV.2303.08774</a>
arXiv:2303.08774

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papineni et al<span class="ltx_text" id="bib.bib35.2.2.1">.</span> (2002)</span>
<span class="ltx_bibblock">
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002.

</span>
<span class="ltx_bibblock">BLEU: a method for automatic evaluation of machine translation. In <em class="ltx_emph ltx_font_italic" id="bib.bib35.3.1">Proceedings of the 40th Annual Meeting on Association for Computational Linguistics</em> (Philadelphia, Pennsylvania) <em class="ltx_emph ltx_font_italic" id="bib.bib35.4.2">(ACL ’02)</em>. Association for Computational Linguistics, USA, 311–318.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.3115/1073083.1073135" title="">https://doi.org/10.3115/1073083.1073135</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pradeep et al<span class="ltx_text" id="bib.bib36.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Ronak Pradeep, Sahel Sharifymoghaddam, and Jimmy Lin. 2023.

</span>
<span class="ltx_bibblock">RankVicuna: Zero-Shot Listwise Document Reranking with Open-Source Large Language Models.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2309.15088 [cs.IR]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qin et al<span class="ltx_text" id="bib.bib37.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Zhen Qin, Rolf Jagerman, Kai Hui, Honglei Zhuang, Junru Wu, Jiaming Shen, Tianqi Liu, Jialu Liu, Donald Metzler, Xuanhui Wang, et al<span class="ltx_text" id="bib.bib37.3.1">.</span> 2023.

</span>
<span class="ltx_bibblock">Large language models are effective text rankers with pairwise ranking prompting.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.4.1">arXiv preprint arXiv:2306.17563</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rajpurkar et al<span class="ltx_text" id="bib.bib38.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016.

</span>
<span class="ltx_bibblock">SQuAD: 100,000+ Questions for Machine Comprehension of Text. In <em class="ltx_emph ltx_font_italic" id="bib.bib38.3.1">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</em>, Jian Su, Kevin Duh, and Xavier Carreras (Eds.). Association for Computational Linguistics, Austin, Texas, 2383–2392.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/D16-1264" title="">https://doi.org/10.18653/v1/D16-1264</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Robertson and Zaragoza (2009)</span>
<span class="ltx_bibblock">
Stephen Robertson and Hugo Zaragoza. 2009.

</span>
<span class="ltx_bibblock">The Probabilistic Relevance Framework: BM25 and Beyond.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Found. Trends Inf. Retr.</em> 3, 4 (apr 2009), 333–389.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1561/1500000019" title="">https://doi.org/10.1561/1500000019</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sachan et al<span class="ltx_text" id="bib.bib40.2.2.1">.</span> (2022a)</span>
<span class="ltx_bibblock">
Devendra Sachan, Mike Lewis, Mandar Joshi, Armen Aghajanyan, Wen-tau Yih, Joelle Pineau, and Luke Zettlemoyer. 2022a.

</span>
<span class="ltx_bibblock">Improving Passage Retrieval with Zero-Shot Question Generation.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sachan et al<span class="ltx_text" id="bib.bib41.2.2.1">.</span> (2022b)</span>
<span class="ltx_bibblock">
Devendra Singh Sachan, Mike Lewis, Mandar Joshi, Armen Aghajanyan, Wen-tau Yih, Joelle Pineau, and Luke Zettlemoyer. 2022b.

</span>
<span class="ltx_bibblock">Improving Passage Retrieval with Zero-Shot Question Generation.

</span>
<span class="ltx_bibblock">(2022).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2204.07496" title="">https://arxiv.org/abs/2204.07496</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Santhanam et al<span class="ltx_text" id="bib.bib42.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Keshav Santhanam, Omar Khattab, Jon Saad-Falcon, Christopher Potts, and Matei Zaharia. 2022.

</span>
<span class="ltx_bibblock">ColBERTv2: Effective and Efficient Retrieval via Lightweight Late Interaction. In <em class="ltx_emph ltx_font_italic" id="bib.bib42.3.1">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2022, Seattle, WA, United States, July 10-15, 2022</em>, Marine Carpuat, Marie-Catherine de Marneffe, and Iván Vladimir Meza Ruíz (Eds.). Association for Computational Linguistics, 3715–3734.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/V1/2022.NAACL-MAIN.272" title="">https://doi.org/10.18653/V1/2022.NAACL-MAIN.272</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shao et al<span class="ltx_text" id="bib.bib43.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan Duan, and Weizhu Chen. 2023.

</span>
<span class="ltx_bibblock">Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy. In <em class="ltx_emph ltx_font_italic" id="bib.bib43.3.1">Findings of the Association for Computational Linguistics: EMNLP 2023, Singapore, December 6-10, 2023</em>, Houda Bouamor, Juan Pino, and Kalika Bali (Eds.). Association for Computational Linguistics, 9248–9274.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/V1/2023.FINDINGS-EMNLP.620" title="">https://doi.org/10.18653/V1/2023.FINDINGS-EMNLP.620</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen et al<span class="ltx_text" id="bib.bib44.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Tao Shen, Guodong Long, Xiubo Geng, Chongyang Tao, Tianyi Zhou, and Daxin Jiang. 2023.

</span>
<span class="ltx_bibblock">Large Language Models are Strong Zero-Shot Retriever.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2304.14233 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et al<span class="ltx_text" id="bib.bib45.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, Mike Lewis, Luke Zettlemoyer, and Wen-tau Yih. 2023.

</span>
<span class="ltx_bibblock">REPLUG: Retrieval-Augmented Black-Box Language Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.3.1">CoRR</em> abs/2301.12652 (2023).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/ARXIV.2301.12652" title="">https://doi.org/10.48550/ARXIV.2301.12652</a>
arXiv:2301.12652

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al<span class="ltx_text" id="bib.bib46.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Weiwei Sun, Lingyong Yan, Xinyu Ma, Pengjie Ren, Dawei Yin, and Zhaochun Ren. 2023.

</span>
<span class="ltx_bibblock">Is chatgpt good at search? investigating large language models as re-ranking agent.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.3.1">arXiv preprint arXiv:2304.09542</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al<span class="ltx_text" id="bib.bib47.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,
Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen
Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. 2023.

</span>
<span class="ltx_bibblock">Llama 2: Open Foundation and Fine-Tuned Chat Models.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2307.09288 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Trivedi et al<span class="ltx_text" id="bib.bib48.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal. 2023.

</span>
<span class="ltx_bibblock">Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions. In <em class="ltx_emph ltx_font_italic" id="bib.bib48.3.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023</em>, Anna Rogers, Jordan L. Boyd-Graber, and Naoaki Okazaki (Eds.). Association for Computational Linguistics, 10014–10037.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/V1/2023.ACL-LONG.557" title="">https://doi.org/10.18653/V1/2023.ACL-LONG.557</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib49.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Yile Wang, Peng Li, Maosong Sun, and Yang Liu. 2023.

</span>
<span class="ltx_bibblock">Self-Knowledge Guided Retrieval Augmentation for Large Language Models. In <em class="ltx_emph ltx_font_italic" id="bib.bib49.3.1">Findings of the Association for Computational Linguistics: EMNLP 2023, Singapore, December 6-10, 2023</em>, Houda Bouamor, Juan Pino, and Kalika Bali (Eds.). Association for Computational Linguistics, 10303–10315.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/V1/2023.FINDINGS-EMNLP.691" title="">https://doi.org/10.18653/V1/2023.FINDINGS-EMNLP.691</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Welleck et al<span class="ltx_text" id="bib.bib50.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Sean Welleck, Ilia Kulikov, Stephen Roller, Emily Dinan, Kyunghyun Cho, and Jason Weston. 2020.

</span>
<span class="ltx_bibblock">Neural Text Generation With Unlikelihood Training. In <em class="ltx_emph ltx_font_italic" id="bib.bib50.3.1">8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020</em>. OpenReview.net.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=SJeYe0NtvH" title="">https://openreview.net/forum?id=SJeYe0NtvH</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiong et al<span class="ltx_text" id="bib.bib51.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul N. Bennett, Junaid Ahmed, and Arnold Overwijk. 2021.

</span>
<span class="ltx_bibblock">Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval. In <em class="ltx_emph ltx_font_italic" id="bib.bib51.3.1">9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021</em>. OpenReview.net.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=zeFrfgyZln" title="">https://openreview.net/forum?id=zeFrfgyZln</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiong et al<span class="ltx_text" id="bib.bib52.2.2.1">.</span> (2020b)</span>
<span class="ltx_bibblock">
Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul Bennett, Junaid Ahmed, and Arnold Overwijk. 2020b.

</span>
<span class="ltx_bibblock">Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2007.00808 [cs.IR]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiong et al<span class="ltx_text" id="bib.bib53.2.2.1">.</span> (2020a)</span>
<span class="ltx_bibblock">
Wenhan Xiong, Xiang Lorraine Li, Srini Iyer, Jingfei Du, Patrick Lewis, William Yang Wang, Yashar Mehdad, Wen-tau Yih, Sebastian Riedel, Douwe Kiela, et al<span class="ltx_text" id="bib.bib53.3.1">.</span> 2020a.

</span>
<span class="ltx_bibblock">Answering complex open-domain questions with multi-hop dense retrieval.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib53.4.1">arXiv preprint arXiv:2009.12756</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al<span class="ltx_text" id="bib.bib54.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Fangyuan Xu, Weijia Shi, and Eunsol Choi. 2024.

</span>
<span class="ltx_bibblock">RECOMP: Improving Retrieval-Augmented LMs with Context Compression and Selective Augmentation. In <em class="ltx_emph ltx_font_italic" id="bib.bib54.3.1">The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024</em>. OpenReview.net.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=mlJLVigNHp" title="">https://openreview.net/forum?id=mlJLVigNHp</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al<span class="ltx_text" id="bib.bib55.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Zichun Yu, Chenyan Xiong, Shi Yu, and Zhiyuan Liu. 2023.

</span>
<span class="ltx_bibblock">Augmentation-Adapted Retriever Improves Generalization of Language Models as Generic Plug-In. In <em class="ltx_emph ltx_font_italic" id="bib.bib55.3.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023</em>, Anna Rogers, Jordan L. Boyd-Graber, and Naoaki Okazaki (Eds.). Association for Computational Linguistics, 2421–2436.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/V1/2023.ACL-LONG.136" title="">https://doi.org/10.18653/V1/2023.ACL-LONG.136</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al<span class="ltx_text" id="bib.bib56.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Fengbin Zhu, Wenqiang Lei, Chao Wang, Jianming Zheng, Soujanya Poria, and Tat-Seng Chua. 2021.

</span>
<span class="ltx_bibblock">Retrieving and Reading: A Comprehensive Survey on Open-domain Question Answering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib56.3.1">CoRR</em> abs/2101.00774 (2021).

</span>
<span class="ltx_bibblock">arXiv:2101.00774

<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2101.00774" title="">https://arxiv.org/abs/2101.00774</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhuang et al<span class="ltx_text" id="bib.bib57.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Honglei Zhuang, Zhen Qin, Kai Hui, Junru Wu, Le Yan, Xuanhui Wang, and Michael Bendersky. 2024.

</span>
<span class="ltx_bibblock">Beyond Yes and No: Improving Zero-Shot LLM Rankers via Scoring Fine-Grained Relevance Labels.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2310.14122 [cs.IR]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhuang et al<span class="ltx_text" id="bib.bib58.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Shengyao Zhuang, Bing Liu, Bevan Koopman, and Guido Zuccon. 2023.

</span>
<span class="ltx_bibblock">Open-source Large Language Models are Strong Zero-shot Query Likelihood Models for Document Ranking. In <em class="ltx_emph ltx_font_italic" id="bib.bib58.3.1">Findings of the Association for Computational Linguistics: EMNLP 2023</em>, Houda Bouamor, Juan Pino, and Kalika Bali (Eds.). Association for Computational Linguistics, Singapore, 8807–8817.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2023.findings-emnlp.590" title="">https://doi.org/10.18653/v1/2023.findings-emnlp.590</a>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Aug 15 22:30:55 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
