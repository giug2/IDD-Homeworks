<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2307.00359] When Synthetic Data Met Regulation</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="When Synthetic Data Met Regulation">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="When Synthetic Data Met Regulation">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2307.00359">

<!--Generated on Wed Feb 28 20:25:21 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Synthetic Data,  Regulation,  Differential Privacy,  Generative AI,  Machine Learning,  GenLaw,  ICML">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_pruned_first">
<h1 class="ltx_title ltx_title_document">When Synthetic Data Met Regulation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Georgi Ganev
</span></span>
</div>

<div class="ltx_keywords">Synthetic Data, Regulation, Differential Privacy, Generative AI, Machine Learning, GenLaw, ICML
</div>
<div id="p2" class="ltx_para">
<br class="ltx_break">
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Motivation</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Generative AI has made significant progress recently, with applications spanning text, code, image, video, speech, and structured data <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Sequoia Capital</span>, <a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite>.
Investor interest has also grown – start-ups received $2.2B in 2022 <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">TechCrunch</span>, <a href="#bib.bib54" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023b</span></a>)</cite> and Microsoft reportedly invested $10B in OpenAI’s ChatGPT <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Bloomberg</span>, <a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>, which has reached 100M monthly users <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Reuters</span>, <a href="#bib.bib47" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>.
However, concerns about privacy, robustness, copyright, and compliance have increased as well.
Active legal cases against Generative AI companies and products <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">TechCrunch</span>, <a href="#bib.bib53" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023a</span></a>)</cite> have led some organizations and countries, such as Italy, to (temporarily) restrict ChatGPT usage <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">CNN</span>, <a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>; <span class="ltx_text" style="font-size:90%;">Politico</span>, <a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.1" class="ltx_p"><span id="S1.p2.1.1" class="ltx_text ltx_font_bold">Synthetic Data.</span>
In this paper, we focus on synthetic data, a subfield of Generative AI that utilizes generative machine learning models such as GANs <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Goodfellow et al.</span>, <a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2014</span></a>)</cite>, Diffusion Models <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Sohl-Dickstein et al.</span>, <a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2015</span></a>)</cite>, and Transformers <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Vaswani et al.</span>, <a href="#bib.bib57" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2017</span></a>)</cite>, albeit typically at a smaller scale.
We opt for tabular data comprising sensitive information as training data as it is still the most extensively used data type in large enterprises.
Furthermore, synthetic data is comparatively more established and has recently been examined by reputable organizations <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Royal Society</span>, <a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>; <span class="ltx_text" style="font-size:90%;">UN</span>, <a href="#bib.bib55" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite> and regulators <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">ICO UK</span>, <a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>; <span class="ltx_text" style="font-size:90%;">FCA UK</span>, <a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>, alas without any definitive compliance directives.</p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p id="S1.p3.1" class="ltx_p"><span id="S1.p3.1.1" class="ltx_text ltx_font_bold">Main Question.</span>
This prompts the question: <span id="S1.p3.1.2" class="ltx_text ltx_font_italic">“Can we make synthetic data regulatory compliant?”</span>
Namely, we explore the legality of privacy-preserving synthetic data created by generative models trained on structured personal data.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Regulatory Definitions</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Personal Data.</span>
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_text" style="font-size:90%;">EP and Council</span> (<a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2016a</span></a>)</cite> define personal data as “any information relating to an identified or identifiable living individual” and the latter as someone who can be identified (directly or indirectly) by reference to factors such as name, id number, or physical, genetic, social identity, etc.
On the other hand, information that is effectively anonymized is not personal data and data protection law does not apply to it <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">EP and Council</span>, <a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2016b</span></a>)</cite>.
But in practice the actual identifiability of individuals can be highly context-specific as different types of information carry different levels of identifiability risks depending on the circumstances.
Clearly, creating synthetic data based on sensitive personal data requires processing it.
However, whether the resultant synthetic data constitutes personal or anonymous information is a question to be determined based on an assessment of the identifiability risk.
This raises the question, what constitutes a sufficient level of anonymization.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Sufficient Anonymization.</span>
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_text" style="font-size:90%;">ICO UK</span> (<a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite> states that “effective anonymization reduces identifiability risk to a sufficiently remote level.”
When assessing whether someone is identifiable, objective factors to be considered include the cost and time required to identify, the available technologies, and their developments over time.
However, not every hypothetical/theoretical chance of identifiability needs to be taken into account.
The focus should be on what is reasonably likely to be used relative to the circumstances, not in absolute.
This is consistent with <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_text" style="font-size:90%;">A29WP</span> (<a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2014</span></a>)</cite>’s approach, that also notes that data controllers should regularly reassess the attending risks.
In terms of technical analysis, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_text" style="font-size:90%;">A29WP</span> (<a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2014</span></a>); <span class="ltx_text" style="font-size:90%;">ICO UK</span> (<a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite> assert that the following three key risks need to be reduced for sufficient anonymization:</p>
<ol id="S2.I1" class="ltx_enumerate">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p">(<span id="S2.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">singling out</span>) any individual being isolated;</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p">(<span id="S2.I1.i2.p1.1.1" class="ltx_text ltx_font_italic">linkability</span>) any records/datasets (publicly available or not) being combined with synthetic data and thereby enabling the identification of an individual;</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p">(<span id="S2.I1.i3.p1.1.1" class="ltx_text ltx_font_italic">inferences</span>) an attribute being deduced with significant probability from the values of other attributes.<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>This is in direct contradiction with good quality synthetic data and has led to leading privacy researchers abandoning statistical inference as privacy violation <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">McSherry</span>, <a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2016</span></a>; <span class="ltx_text" style="font-size:90%;">Bun et al.</span>, <a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite>.</span></span></span></p>
</div>
</li>
</ol>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_text" style="font-size:90%;">ICO UK</span> (<a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite> explains that the three risks should be looked through the <span id="S2.p3.1.1" class="ltx_text ltx_font_italic">motivated intruder</span> test – a competent intruder having access to appropriate resources being able to achieve identification if they were motivated to attempt it.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Synthetic Data as Anonymous Data</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we show that producing synthetic data by combining two techniques—generative models and Differential Privacy (DP)—reduces all identifiability risks to sufficiently remote level and, therefore, the resulting data can be considered anonymous per <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">A29WP</span>, <a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2014</span></a>; <span class="ltx_text" style="font-size:90%;">ICO UK</span>, <a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite>.
Overall, we rely on generative models to create high utility synthetic data and DP to provably guarantee privacy.</p>
</div>
<div id="S3.p2" class="ltx_para ltx_noindent">
<p id="S3.p2.1" class="ltx_p"><span id="S3.p2.1.1" class="ltx_text ltx_font_bold">Generative Models</span>
break the 1-to-1 mapping and to an extent reduce singling out and linkability but could be susceptible to various privacy attacks (see below).</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">The process of training a generative model to learn the probability distribution of the input sensitive data, discarding it, and sampling from the fitted parameters to create new (synthetic) data, naturally lowers some privacy concerns.
For instance, it breaks the 1-to-1 mapping from a single real record to a single synthetic one which makes singling out difficult.
Since the models are probabilistic in nature, they capture the inherent data uncertainty and variability, which reduces linkability.
Furthermore, launching adversarial privacy attacks versus generative models is more challenging compared to discriminative ones <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">De Cristofaro</span>, <a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite>.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p">However, some generative models could occasionally memorize records and reproduce them (exactly or approximately) in the synthetic data <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Carlini et al.</span>, <a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2019</span></a>; <span class="ltx_text" style="font-size:90%;">van den Burg &amp; Williams</span>, <a href="#bib.bib56" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite>.
In turn, a strategic adversary with side knowledge (e.g., the training algorithm, representable data, etc.) could infer the presence of these records <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Hayes et al.</span>, <a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2019</span></a>; <span class="ltx_text" style="font-size:90%;">Chen et al.</span>, <a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>; <span class="ltx_text" style="font-size:90%;">Stadler et al.</span>, <a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite>, thus violating the linkability test and rendering the synthetic data pseudonymous at best or personal at worst <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">López &amp; Elbi</span>, <a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite>.
Even more powerful privacy attack is reconstruction <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Carlini et al.</span>, <a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>, <a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>, in which the adversary manages to recover whole training records and, therefore, leaks all of their private attributes.</p>
</div>
<div id="S3.p5" class="ltx_para ltx_noindent">
<p id="S3.p5.1" class="ltx_p"><span id="S3.p5.1.1" class="ltx_text ltx_font_bold">DP</span>
mechanisms formally protect against singling out, linkability, and other re-identifiability concerns even if faced with a resourceful and strategic adversary (see below).</p>
</div>
<div id="S3.p6" class="ltx_para">
<p id="S3.p6.1" class="ltx_p">DP <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Dwork et al.</span>, <a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2006</span></a>; <span class="ltx_text" style="font-size:90%;">Dwork &amp; Roth</span>, <a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2014</span></a>)</cite> is a mathematical definition of privacy which formally bounds the probability of distinguishing whether any given individual’s data was included in the input data.
The level of indistinguishability is controlled and quantified by a parameter, <math id="S3.p6.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.p6.1.m1.1a"><mi id="S3.p6.1.m1.1.1" xref="S3.p6.1.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S3.p6.1.m1.1b"><ci id="S3.p6.1.m1.1.1.cmml" xref="S3.p6.1.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.1.m1.1c">\epsilon</annotation></semantics></math>, or the privacy budget.
In the context of Generative AI, DP is usually satisfied by training the models with noisy/random mechanisms and frameworks such as DP-SGD <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Abadi et al.</span>, <a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2016</span></a>)</cite> and PATE <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Papernot et al.</span>, <a href="#bib.bib44" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2017</span></a>, <a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2018</span></a>)</cite>.</p>
</div>
<div id="S3.p7" class="ltx_para">
<p id="S3.p7.1" class="ltx_p">Since DP makes the trained model indistinguishable, whether any individual’s data was included or not, it averts memorization and singling out.
The protection against GDPR’s singling out has been robustly formalized <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Cohen &amp; Nissim</span>, <a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>)</cite> (<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_text" style="font-size:90%;">Nissim et al.</span> (<a href="#bib.bib42" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2017</span></a>)</cite> also argue DP satisfies FERPA requirements).
Additionally, DP defends against potential harms, such as linkability, that could be caused by the publication of other sensitive information.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_text" style="font-size:90%;">Stadler et al.</span> (<a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite> show this holds true even for outliers or potentially the most vulnerable individuals who have a higher chance of being memorized <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Feldman</span>, <a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>)</cite>.
Furthermore, DP does not make any assumptions about the adversary and the provable mathematical guarantees apply in the worst-case scenario (e.g., the attacker has prior information, knowledge of the training algorithm, strong computing power, etc.) which means that DP protects against motivated adversaries.
The protections are not just theoretical, DP reduces all key risks empirically, too <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Giomi et al.</span>, <a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite>.</p>
</div>
<div id="S3.p8" class="ltx_para">
<p id="S3.p8.1" class="ltx_p">Using DP-trained models makes privacy an attribute of the generating process rather than a given synthetic dataset.
Thanks to its resistance to post-processing property, DP allows reusing models (to generate data) without further privacy leakage.
This means that even in the unlikely scenario in which a synthetic record very similar to a real is generated (which could be dissatisfactory <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">ONS UK</span>, <a href="#bib.bib43" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2018</span></a>)</cite>), it does not constitute a privacy violation <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Jordon et al.</span>, <a href="#bib.bib36" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite>.</p>
</div>
<div id="S3.p9" class="ltx_para ltx_noindent">
<p id="S3.p9.1" class="ltx_p"><span id="S3.p9.1.1" class="ltx_text ltx_font_bold">Potential Limitations.</span>
While DP offers robust privacy protection, in certain scenarios it could be too conservative <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Nasr et al.</span>, <a href="#bib.bib41" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite>.
Furthermore, DP often leads to utility reduction, particularly impacting outliers and underrepresented subgroups <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Stadler et al.</span>, <a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>; <span class="ltx_text" style="font-size:90%;">Ganev et al.</span>, <a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite> and causing inconsistencies <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Kulynych et al.</span>, <a href="#bib.bib38" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>.
Selecting both the right privacy budget and DP mechanism is non-trivial and highly context-specific <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Hsu et al.</span>, <a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2014</span></a>; <span class="ltx_text" style="font-size:90%;">Ganev et al.</span>, <a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>.
Lastly, implementing DP in practice and effectively conveying its properties can be challenging/complex <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Cummings et al.</span>, <a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>; <span class="ltx_text" style="font-size:90%;">Houssiau et al.</span>, <a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite>.</p>
</div>
<div id="S3.p10" class="ltx_para ltx_noindent">
<p id="S3.p10.1" class="ltx_p"><span id="S3.p10.1.1" class="ltx_text ltx_font_bold">Related Work.</span>
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_text" style="font-size:90%;">Cummings et al.</span> (<a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite> discuss further DP benefits/challenges/open questions and <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_text" style="font-size:90%;">Jordon et al.</span> (<a href="#bib.bib36" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>); <span class="ltx_text" style="font-size:90%;">De Cristofaro</span> (<a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite> focus on combining synthetic data with DP (also advised by <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Bellovin et al.</span>, <a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2019</span></a>)</cite>).
Specific (DP) generative models include GANs <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Xie et al.</span>, <a href="#bib.bib58" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2018</span></a>; <span class="ltx_text" style="font-size:90%;">Jordon et al.</span>, <a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2018</span></a>; <span class="ltx_text" style="font-size:90%;">Xu et al.</span>, <a href="#bib.bib59" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>, Diffusion Models <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Kotelnikov et al.</span>, <a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>; <span class="ltx_text" style="font-size:90%;">Ghalebikesabi et al.</span>, <a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>, and Transformers <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Borisov et al.</span>, <a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>; <span class="ltx_text" style="font-size:90%;">Solatorio &amp; Dupriez</span>, <a href="#bib.bib51" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Future Work</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this paper, we argue that synthetic data produced by DP generative models can be sufficiently anonymized and, therefore, anonymous data and regulatory compliant.
Our work aims to establish a foundation for broader Generative AI solutions.
Nevertheless, they face added obstacles, such as training on vast multi-modal datasets that may include proprietary/copyrighted data with commercial usage limitations.
Moreover, as datasets are often distributed over the internet, it becomes increasingly difficult for individuals to assert their right to consent or be forgotten.
Factors like data accessibility (e.g., decentralized/scraped data), governance, robustness, transparency, explainability, and fairness must also be considered <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:90%;">Gal &amp; Lynskey</span>, <a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>; <span class="ltx_text" style="font-size:90%;">IAPP</span>, <a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">We would like to thank Diana Sofronieva for helping with the structure, clarity, and rigorousness of the paper;
Ian Stevens, Samikah Ahmed, and Suzanne Jopling for providing legal expertise and consultation;
Emiliano De Cristofaro and Meenatchi Sundaram Muthu Selva Annamalai for providing technical feedback;
Adriano Basso, Andrew Keen, and Gareth Rees for reviewing earlier versions of the paper and offering overall support;
Orla Lynskey and James Jordon for the helpful discussions;
as well as the anonymous reviewers for their encouraging and helpful comments.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib1.4.4.1" class="ltx_text" style="font-size:90%;">A29WP (2014)</span></span>
<span class="ltx_bibblock"><span id="bib.bib1.6.1" class="ltx_text" style="font-size:90%;">
A29WP.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.7.1" class="ltx_text" style="font-size:90%;">Opinion on anonymisation techniques.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://ec.europa.eu/justice/article-29/documentation/opinion-recommendation/files/2014/wp216_en.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://ec.europa.eu/justice/article-29/documentation/opinion-recommendation/files/2014/wp216_en.pdf</a><span id="bib.bib1.8.1" class="ltx_text" style="font-size:90%;">,
2014.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib2.5.5.1" class="ltx_text" style="font-size:90%;">Abadi et al. (2016)</span></span>
<span class="ltx_bibblock"><span id="bib.bib2.7.1" class="ltx_text" style="font-size:90%;">
Abadi, M., Chu, A., Goodfellow, I., McMahan, H. B., Mironov, I., Talwar, K.,
and Zhang, L.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.8.1" class="ltx_text" style="font-size:90%;">Deep learning with differential privacy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib2.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ACM CCS</em><span id="bib.bib2.11.3" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib3.5.5.1" class="ltx_text" style="font-size:90%;">Bellovin et al. (2019)</span></span>
<span class="ltx_bibblock"><span id="bib.bib3.7.1" class="ltx_text" style="font-size:90%;">
Bellovin, S. M., Dutta, P. K., and Reitinger, N.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.8.1" class="ltx_text" style="font-size:90%;">Privacy and synthetic datasets.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib3.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">STLR</em><span id="bib.bib3.10.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib4.4.4.1" class="ltx_text" style="font-size:90%;">Bloomberg (2023)</span></span>
<span class="ltx_bibblock"><span id="bib.bib4.6.1" class="ltx_text" style="font-size:90%;">
Bloomberg.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.7.1" class="ltx_text" style="font-size:90%;">Microsoft Invests $10 Billion in ChatGPT Maker OpenAI.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.bloomberg.com/news/articles/2023-01-23/microsoft-makes-multibillion-dollar-investment-in-openai" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://www.bloomberg.com/news/articles/2023-01-23/microsoft-makes-multibillion-dollar-investment-in-openai</a><span id="bib.bib4.8.1" class="ltx_text" style="font-size:90%;">,
2023.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib5.5.5.1" class="ltx_text" style="font-size:90%;">Borisov et al. (2022)</span></span>
<span class="ltx_bibblock"><span id="bib.bib5.7.1" class="ltx_text" style="font-size:90%;">
Borisov, V., Seßler, K., Leemann, T., Pawelczyk, M., and Kasneci, G.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.8.1" class="ltx_text" style="font-size:90%;">Language models are realistic tabular data generators.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib5.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv:2210.06280</em><span id="bib.bib5.10.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib6.5.5.1" class="ltx_text" style="font-size:90%;">Bun et al. (2021)</span></span>
<span class="ltx_bibblock"><span id="bib.bib6.7.1" class="ltx_text" style="font-size:90%;">
Bun, M., Desfontaines, D., Dwork, C., Naor, M., Nissim, K., Roth, A., Smith,
A., Steinke, T., Ullman, J., and Vadhan, S.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.8.1" class="ltx_text" style="font-size:90%;">Statistical Inference is Not a Privacy Violation.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://differentialprivacy.org/inference-is-not-a-privacy-violation/" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://differentialprivacy.org/inference-is-not-a-privacy-violation/</a><span id="bib.bib6.9.1" class="ltx_text" style="font-size:90%;">,
2021.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib7.5.5.1" class="ltx_text" style="font-size:90%;">Carlini et al. (2019)</span></span>
<span class="ltx_bibblock"><span id="bib.bib7.7.1" class="ltx_text" style="font-size:90%;">
Carlini, N., Liu, C., Erlingsson, Ú., Kos, J., and Song, D.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.8.1" class="ltx_text" style="font-size:90%;">The secret sharer: Evaluating and testing unintended memorization in
neural networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib7.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">USENIX Security</em><span id="bib.bib7.11.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib8.5.5.1" class="ltx_text" style="font-size:90%;">Carlini et al. (2021)</span></span>
<span class="ltx_bibblock"><span id="bib.bib8.7.1" class="ltx_text" style="font-size:90%;">
Carlini, N., Tramer, F., Wallace, E., Jagielski, M., Herbert-Voss, A., Lee, K.,
Roberts, A., Brown, T., Song, D., Erlingsson, U., Oprea, A., and Raffel, C.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.8.1" class="ltx_text" style="font-size:90%;">Extracting training data from large language models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib8.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">USENIX Security</em><span id="bib.bib8.11.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib9.5.5.1" class="ltx_text" style="font-size:90%;">Carlini et al. (2023)</span></span>
<span class="ltx_bibblock"><span id="bib.bib9.7.1" class="ltx_text" style="font-size:90%;">
Carlini, N., Hayes, J., Nasr, M., Jagielski, M., Sehwag, V., Tramèr, F.,
Balle, B., Ippolito, D., and Wallace, E.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.8.1" class="ltx_text" style="font-size:90%;">Extracting training data from diffusion models.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib9.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv:2301.13188</em><span id="bib.bib9.10.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib10.5.5.1" class="ltx_text" style="font-size:90%;">Chen et al. (2020)</span></span>
<span class="ltx_bibblock"><span id="bib.bib10.7.1" class="ltx_text" style="font-size:90%;">
Chen, D., Yu, N., Zhang, Y., and Fritz, M.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.8.1" class="ltx_text" style="font-size:90%;">Gan-leaks: a taxonomy of membership inference attacks against
generative models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib10.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ACM CCS</em><span id="bib.bib10.11.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib11.4.4.1" class="ltx_text" style="font-size:90%;">CNN (2023)</span></span>
<span class="ltx_bibblock"><span id="bib.bib11.6.1" class="ltx_text" style="font-size:90%;">
CNN.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.7.1" class="ltx_text" style="font-size:90%;">Don’t tell anything to a chatbot you want to keep private.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://edition.cnn.com/2023/04/06/tech/chatgpt-ai-privacy-concerns/index.html" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://edition.cnn.com/2023/04/06/tech/chatgpt-ai-privacy-concerns/index.html</a><span id="bib.bib11.8.1" class="ltx_text" style="font-size:90%;">,
2023.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib12.5.5.1" class="ltx_text" style="font-size:90%;">Cohen &amp; Nissim (2020)</span></span>
<span class="ltx_bibblock"><span id="bib.bib12.7.1" class="ltx_text" style="font-size:90%;">
Cohen, A. and Nissim, K.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.8.1" class="ltx_text" style="font-size:90%;">Towards formalizing the GDPR’s notion of singling out.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib12.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">PNAS</em><span id="bib.bib12.10.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib13.5.5.1" class="ltx_text" style="font-size:90%;">Cummings et al. (2021)</span></span>
<span class="ltx_bibblock"><span id="bib.bib13.7.1" class="ltx_text" style="font-size:90%;">
Cummings, R., Kaptchuk, G., and Redmiles, E. M.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.8.1" class="ltx_text" style="font-size:90%;">”I need a better description”: an investigation into user
expectations for differential privacy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib13.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ACM CCS</em><span id="bib.bib13.11.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib14.5.5.1" class="ltx_text" style="font-size:90%;">Cummings et al. (2023)</span></span>
<span class="ltx_bibblock"><span id="bib.bib14.7.1" class="ltx_text" style="font-size:90%;">
Cummings, R., Desfontaines, D., Evans, D., Geambasu, R., Jagielski, M., Huang,
Y., Kairouz, P., Kamath, G., Oh, S., Ohrimenko, O., Papernot, N., Rogers, R.,
Shen, M., Song, S., Su, W., Terzis, A., Thakurta, A., Vassilvitskii, S.,
Wang, Y.-X., Xiong, L., Yekhanin, S., Yu, D., Zhan, H., and Zhang, W.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.8.1" class="ltx_text" style="font-size:90%;">Challenges towards the Next Frontier in Privacy.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib14.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv:2304.06929</em><span id="bib.bib14.10.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib15.4.4.1" class="ltx_text" style="font-size:90%;">De Cristofaro (2021)</span></span>
<span class="ltx_bibblock"><span id="bib.bib15.6.1" class="ltx_text" style="font-size:90%;">
De Cristofaro, E.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.7.1" class="ltx_text" style="font-size:90%;">A critical overview of privacy in machine learning.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib15.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE S&amp;P</em><span id="bib.bib15.9.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib16.4.4.1" class="ltx_text" style="font-size:90%;">De Cristofaro (2023)</span></span>
<span class="ltx_bibblock"><span id="bib.bib16.6.1" class="ltx_text" style="font-size:90%;">
De Cristofaro, E.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.7.1" class="ltx_text" style="font-size:90%;">What Is Synthetic Data? The Good, The Bad, and The Ugly.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib16.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv:2303.01230</em><span id="bib.bib16.9.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib17.5.5.1" class="ltx_text" style="font-size:90%;">Dwork &amp; Roth (2014)</span></span>
<span class="ltx_bibblock"><span id="bib.bib17.7.1" class="ltx_text" style="font-size:90%;">
Dwork, C. and Roth, A.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.8.1" class="ltx_text" style="font-size:90%;">The algorithmic foundations of differential privacy.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib17.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Foundations and Trends in Theoretical Computer Science</em><span id="bib.bib17.10.2" class="ltx_text" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib18.5.5.1" class="ltx_text" style="font-size:90%;">Dwork et al. (2006)</span></span>
<span class="ltx_bibblock"><span id="bib.bib18.7.1" class="ltx_text" style="font-size:90%;">
Dwork, C., McSherry, F., Nissim, K., and Smith, A.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.8.1" class="ltx_text" style="font-size:90%;">Calibrating noise to sensitivity in private data analysis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib18.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">TCC</em><span id="bib.bib18.11.3" class="ltx_text" style="font-size:90%;">, 2006.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib19.4.4.1" class="ltx_text" style="font-size:90%;">EP and Council (2016a)</span></span>
<span class="ltx_bibblock"><span id="bib.bib19.6.1" class="ltx_text" style="font-size:90%;">
EP and Council.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.7.1" class="ltx_text" style="font-size:90%;">Article 4 GDPR Definitions.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://gdpr-info.eu/art-4-gdpr/" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://gdpr-info.eu/art-4-gdpr/</a><span id="bib.bib19.8.1" class="ltx_text" style="font-size:90%;">, 2016a.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib20.4.4.1" class="ltx_text" style="font-size:90%;">EP and Council (2016b)</span></span>
<span class="ltx_bibblock"><span id="bib.bib20.6.1" class="ltx_text" style="font-size:90%;">
EP and Council.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.7.1" class="ltx_text" style="font-size:90%;">Recital 26 EU GDPR.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.privacy-regulation.eu/en/recital-26-GDPR.htm" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://www.privacy-regulation.eu/en/recital-26-GDPR.htm</a><span id="bib.bib20.8.1" class="ltx_text" style="font-size:90%;">,
2016b.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib21.4.4.1" class="ltx_text" style="font-size:90%;">FCA UK (2023)</span></span>
<span class="ltx_bibblock"><span id="bib.bib21.6.1" class="ltx_text" style="font-size:90%;">
FCA UK.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.7.1" class="ltx_text" style="font-size:90%;">Synthetic data call for input feedback statement.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.fca.org.uk/publication/feedback/fs23-1.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://www.fca.org.uk/publication/feedback/fs23-1.pdf</a><span id="bib.bib21.8.1" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib22.4.4.1" class="ltx_text" style="font-size:90%;">Feldman (2020)</span></span>
<span class="ltx_bibblock"><span id="bib.bib22.6.1" class="ltx_text" style="font-size:90%;">
Feldman, V.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.7.1" class="ltx_text" style="font-size:90%;">Does learning require memorization? a short tale about a long tail.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.8.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib22.9.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">STOC</em><span id="bib.bib22.10.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib23.5.5.1" class="ltx_text" style="font-size:90%;">Gal &amp; Lynskey (2023)</span></span>
<span class="ltx_bibblock"><span id="bib.bib23.7.1" class="ltx_text" style="font-size:90%;">
Gal, M. and Lynskey, O.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.8.1" class="ltx_text" style="font-size:90%;">Synthetic Data: Legal Implications of the Data-Generation
Revolution.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib23.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">109 Iowa Law Review</em><span id="bib.bib23.10.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib24.5.5.1" class="ltx_text" style="font-size:90%;">Ganev et al. (2022)</span></span>
<span class="ltx_bibblock"><span id="bib.bib24.7.1" class="ltx_text" style="font-size:90%;">
Ganev, G., Oprisanu, B., and De Cristofaro, E.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.8.1" class="ltx_text" style="font-size:90%;">Robin Hood and Matthew Effects: Differential privacy has disparate
impact on synthetic data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib24.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ICML</em><span id="bib.bib24.11.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib25.5.5.1" class="ltx_text" style="font-size:90%;">Ganev et al. (2023)</span></span>
<span class="ltx_bibblock"><span id="bib.bib25.7.1" class="ltx_text" style="font-size:90%;">
Ganev, G., Xu, K., and De Cristofaro, E.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.8.1" class="ltx_text" style="font-size:90%;">Understanding how Differentially Private Generative Models Spend
their Privacy Budget.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib25.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv:2305.10994</em><span id="bib.bib25.10.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib26.5.5.1" class="ltx_text" style="font-size:90%;">Ghalebikesabi et al. (2023)</span></span>
<span class="ltx_bibblock"><span id="bib.bib26.7.1" class="ltx_text" style="font-size:90%;">
Ghalebikesabi, S., Berrada, L., Gowal, S., Ktena, I., Stanforth, R., Hayes, J.,
De, S., Smith, S. L., Wiles, O., and Balle, B.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.8.1" class="ltx_text" style="font-size:90%;">Differentially Private Diffusion Models Generate Useful Synthetic
Images.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib26.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv:2302.13861</em><span id="bib.bib26.10.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib27.5.5.1" class="ltx_text" style="font-size:90%;">Giomi et al. (2022)</span></span>
<span class="ltx_bibblock"><span id="bib.bib27.7.1" class="ltx_text" style="font-size:90%;">
Giomi, M., Boenisch, F., Wehmeyer, C., and Tasnádi, B.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.8.1" class="ltx_text" style="font-size:90%;">A unified framework for quantifying privacy risk in synthetic data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib27.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">PETs</em><span id="bib.bib27.11.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib28.5.5.1" class="ltx_text" style="font-size:90%;">Goodfellow et al. (2014)</span></span>
<span class="ltx_bibblock"><span id="bib.bib28.7.1" class="ltx_text" style="font-size:90%;">
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
S., Courville, A., and Bengio, Y.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.8.1" class="ltx_text" style="font-size:90%;">Generative adversarial nets.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib28.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">NIPS</em><span id="bib.bib28.10.2" class="ltx_text" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib29.5.5.1" class="ltx_text" style="font-size:90%;">Hayes et al. (2019)</span></span>
<span class="ltx_bibblock"><span id="bib.bib29.7.1" class="ltx_text" style="font-size:90%;">
Hayes, J., Melis, L., Danezis, G., and De Cristofaro, E.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.8.1" class="ltx_text" style="font-size:90%;">Logan: membership inference attacks against generative models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib29.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">PoPETs</em><span id="bib.bib29.11.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib30.5.5.1" class="ltx_text" style="font-size:90%;">Houssiau et al. (2022)</span></span>
<span class="ltx_bibblock"><span id="bib.bib30.7.1" class="ltx_text" style="font-size:90%;">
Houssiau, F., Rocher, L., and de Montjoye, Y.-A.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.8.1" class="ltx_text" style="font-size:90%;">On the difficulty of achieving differential privacy in practice:
user-level guarantees in aggregate location data.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib30.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Nature Communications</em><span id="bib.bib30.10.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib31.5.5.1" class="ltx_text" style="font-size:90%;">Hsu et al. (2014)</span></span>
<span class="ltx_bibblock"><span id="bib.bib31.7.1" class="ltx_text" style="font-size:90%;">
Hsu, J., Gaboardi, M., Haeberlen, A., Khanna, S., Narayan, A., Pierce, B. C.,
and Roth, A.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.8.1" class="ltx_text" style="font-size:90%;">Differential privacy: an economic method for choosing epsilon.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib31.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE CSF</em><span id="bib.bib31.11.3" class="ltx_text" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib32.4.4.1" class="ltx_text" style="font-size:90%;">IAPP (2023)</span></span>
<span class="ltx_bibblock"><span id="bib.bib32.6.1" class="ltx_text" style="font-size:90%;">
IAPP.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.7.1" class="ltx_text" style="font-size:90%;">Generative AI: Privacy and tech perspectives.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://iapp.org/news/a/generative-ai-privacy-and-tech-perspectives/" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://iapp.org/news/a/generative-ai-privacy-and-tech-perspectives/</a><span id="bib.bib32.8.1" class="ltx_text" style="font-size:90%;">,
2023.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib33.4.4.1" class="ltx_text" style="font-size:90%;">ICO UK (2021)</span></span>
<span class="ltx_bibblock"><span id="bib.bib33.6.1" class="ltx_text" style="font-size:90%;">
ICO UK.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.7.1" class="ltx_text" style="font-size:90%;">Chapter 2: how do we ensure anonymisation is effective?
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://ico.org.uk/media/about-the-ico/documents/4018606/chapter-2-anonymisation-draft.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://ico.org.uk/media/about-the-ico/documents/4018606/chapter-2-anonymisation-draft.pdf</a><span id="bib.bib33.8.1" class="ltx_text" style="font-size:90%;">,
2021.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib34.4.4.1" class="ltx_text" style="font-size:90%;">ICO UK (2022)</span></span>
<span class="ltx_bibblock"><span id="bib.bib34.6.1" class="ltx_text" style="font-size:90%;">
ICO UK.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.7.1" class="ltx_text" style="font-size:90%;">Chapter 5: privacy-enhancing technologies (PETs).
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://ico.org.uk/media/about-the-ico/consultations/4021464/chapter-5-anonymisation-pets.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://ico.org.uk/media/about-the-ico/consultations/4021464/chapter-5-anonymisation-pets.pdf</a><span id="bib.bib34.8.1" class="ltx_text" style="font-size:90%;">,
2022.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib35.5.5.1" class="ltx_text" style="font-size:90%;">Jordon et al. (2018)</span></span>
<span class="ltx_bibblock"><span id="bib.bib35.7.1" class="ltx_text" style="font-size:90%;">
Jordon, J., Yoon, J., and Van Der Schaar, M.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.8.1" class="ltx_text" style="font-size:90%;">PATE-GAN: generating synthetic data with differential privacy
guarantees.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib35.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ICLR</em><span id="bib.bib35.11.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib36.5.5.1" class="ltx_text" style="font-size:90%;">Jordon et al. (2022)</span></span>
<span class="ltx_bibblock"><span id="bib.bib36.7.1" class="ltx_text" style="font-size:90%;">
Jordon, J., Szpruch, L., Houssiau, F., Bottarelli, M., Cherubin, G., Maple, C.,
Cohen, S. N., and Weller, A.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.8.1" class="ltx_text" style="font-size:90%;">Synthetic Data–what, why and how?
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib36.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv:2205.03257</em><span id="bib.bib36.10.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib37.5.5.1" class="ltx_text" style="font-size:90%;">Kotelnikov et al. (2022)</span></span>
<span class="ltx_bibblock"><span id="bib.bib37.7.1" class="ltx_text" style="font-size:90%;">
Kotelnikov, A., Baranchuk, D., Rubachev, I., and Babenko, A.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.8.1" class="ltx_text" style="font-size:90%;">TabDDPM: Modelling Tabular Data with Diffusion Models.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib37.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv:2209.15421</em><span id="bib.bib37.10.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib38.5.5.1" class="ltx_text" style="font-size:90%;">Kulynych et al. (2023)</span></span>
<span class="ltx_bibblock"><span id="bib.bib38.7.1" class="ltx_text" style="font-size:90%;">
Kulynych, B., Hsu, H., Troncoso, C., and Calmon, F. P.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.8.1" class="ltx_text" style="font-size:90%;">Arbitrary decisions are a hidden cost of differentially-private
training.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib38.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ACM FAccT</em><span id="bib.bib38.11.3" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib39.5.5.1" class="ltx_text" style="font-size:90%;">López &amp; Elbi (2022)</span></span>
<span class="ltx_bibblock"><span id="bib.bib39.7.1" class="ltx_text" style="font-size:90%;">
López, C. A. F. and Elbi, A.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.8.1" class="ltx_text" style="font-size:90%;">On the legal nature of synthetic data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib39.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">NeurIPS SyntheticData4ML</em><span id="bib.bib39.11.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib40.4.4.1" class="ltx_text" style="font-size:90%;">McSherry (2016)</span></span>
<span class="ltx_bibblock"><span id="bib.bib40.6.1" class="ltx_text" style="font-size:90%;">
McSherry, F.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.7.1" class="ltx_text" style="font-size:90%;">Statistical inference considered harmful.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/frankmcsherry/blog/blob/master/posts/2016-06-14.md" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://github.com/frankmcsherry/blog/blob/master/posts/2016-06-14.md</a><span id="bib.bib40.8.1" class="ltx_text" style="font-size:90%;">,
2016.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib41.5.5.1" class="ltx_text" style="font-size:90%;">Nasr et al. (2021)</span></span>
<span class="ltx_bibblock"><span id="bib.bib41.7.1" class="ltx_text" style="font-size:90%;">
Nasr, M., Songi, S., Thakurta, A., Papernot, N., and Carlin, N.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.8.1" class="ltx_text" style="font-size:90%;">Adversary instantiation: lower bounds for differentially private
machine learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib41.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE S&amp;P</em><span id="bib.bib41.11.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib42.5.5.1" class="ltx_text" style="font-size:90%;">Nissim et al. (2017)</span></span>
<span class="ltx_bibblock"><span id="bib.bib42.7.1" class="ltx_text" style="font-size:90%;">
Nissim, K., Bembenek, A., Wood, A., Bun, M., Gaboardi, M., Gasser, U., O’Brien,
D. R., Steinke, T., and Vadhan, S.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.8.1" class="ltx_text" style="font-size:90%;">Bridging the gap between computer science and legal approaches to
privacy.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib42.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Harvard JOLT</em><span id="bib.bib42.10.2" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib43.4.4.1" class="ltx_text" style="font-size:90%;">ONS UK (2018)</span></span>
<span class="ltx_bibblock"><span id="bib.bib43.6.1" class="ltx_text" style="font-size:90%;">
ONS UK.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.7.1" class="ltx_text" style="font-size:90%;">Privacy and data confidentiality methods: a data and analysis method
review.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://analysisfunction.civilservice.gov.uk/policy-store/privacy-and-data-confidentiality-methods-a-national-statisticians-quality-review-nsqr/" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://analysisfunction.civilservice.gov.uk/policy-store/privacy-and-data-confidentiality-methods-a-national-statisticians-quality-review-nsqr/</a><span id="bib.bib43.8.1" class="ltx_text" style="font-size:90%;">,
2018.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib44.5.5.1" class="ltx_text" style="font-size:90%;">Papernot et al. (2017)</span></span>
<span class="ltx_bibblock"><span id="bib.bib44.7.1" class="ltx_text" style="font-size:90%;">
Papernot, N., Abadi, M., Erlingsson, U., Goodfellow, I., and Talwar, K.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.8.1" class="ltx_text" style="font-size:90%;">Semi-supervised knowledge transfer for deep learning from private
training data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib44.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ICLR</em><span id="bib.bib44.11.3" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib45.5.5.1" class="ltx_text" style="font-size:90%;">Papernot et al. (2018)</span></span>
<span class="ltx_bibblock"><span id="bib.bib45.7.1" class="ltx_text" style="font-size:90%;">
Papernot, N., Song, S., Mironov, I., Raghunathan, A., Talwar, K., and
Erlingsson, Ú.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.8.1" class="ltx_text" style="font-size:90%;">Scalable private learning with pate.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib45.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ICLR</em><span id="bib.bib45.11.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib46.4.4.1" class="ltx_text" style="font-size:90%;">Politico (2023)</span></span>
<span class="ltx_bibblock"><span id="bib.bib46.6.1" class="ltx_text" style="font-size:90%;">
Politico.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.7.1" class="ltx_text" style="font-size:90%;">Italian privacy regulator bans ChatGPT.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.politico.eu/article/italian-privacy-regulator-bans-chatgpt/" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://www.politico.eu/article/italian-privacy-regulator-bans-chatgpt/</a><span id="bib.bib46.8.1" class="ltx_text" style="font-size:90%;">,
2023.
</span>
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib47.4.4.1" class="ltx_text" style="font-size:90%;">Reuters (2023)</span></span>
<span class="ltx_bibblock"><span id="bib.bib47.6.1" class="ltx_text" style="font-size:90%;">
Reuters.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.7.1" class="ltx_text" style="font-size:90%;">ChatGPT sets record for fastest-growing user base.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.reuters.com/technology/chatgpt-sets-record-fastest-growing-user-base-analyst-note-2023-02-01/" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://www.reuters.com/technology/chatgpt-sets-record-fastest-growing-user-base-analyst-note-2023-02-01/</a><span id="bib.bib47.8.1" class="ltx_text" style="font-size:90%;">,
2023.
</span>
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib48.4.4.1" class="ltx_text" style="font-size:90%;">Royal Society (2023)</span></span>
<span class="ltx_bibblock"><span id="bib.bib48.6.1" class="ltx_text" style="font-size:90%;">
Royal Society.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.7.1" class="ltx_text" style="font-size:90%;">From privacy to partnership: the role of PETs in data governance and
collaborative analysis.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://royalsociety.org/-/media/policy/projects/privacy-enhancing-technologies/From-Privacy-to-Partnership.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://royalsociety.org/-/media/policy/projects/privacy-enhancing-technologies/From-Privacy-to-Partnership.pdf</a><span id="bib.bib48.8.1" class="ltx_text" style="font-size:90%;">,
2023.
</span>
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib49.4.4.1" class="ltx_text" style="font-size:90%;">Sequoia Capital (2022)</span></span>
<span class="ltx_bibblock"><span id="bib.bib49.6.1" class="ltx_text" style="font-size:90%;">
Sequoia Capital.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.7.1" class="ltx_text" style="font-size:90%;">Generative AI: A Creative New World.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.sequoiacap.com/article/generative-ai-a-creative-new-world/" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://www.sequoiacap.com/article/generative-ai-a-creative-new-world/</a><span id="bib.bib49.8.1" class="ltx_text" style="font-size:90%;">,
2022.
</span>
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib50.5.5.1" class="ltx_text" style="font-size:90%;">Sohl-Dickstein et al. (2015)</span></span>
<span class="ltx_bibblock"><span id="bib.bib50.7.1" class="ltx_text" style="font-size:90%;">
Sohl-Dickstein, J., Weiss, E., Maheswaranathan, N., and Ganguli, S.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.8.1" class="ltx_text" style="font-size:90%;">Deep unsupervised learning using nonequilibrium thermodynamics.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib50.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ICML</em><span id="bib.bib50.11.3" class="ltx_text" style="font-size:90%;">, 2015.
</span>
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib51.5.5.1" class="ltx_text" style="font-size:90%;">Solatorio &amp; Dupriez (2023)</span></span>
<span class="ltx_bibblock"><span id="bib.bib51.7.1" class="ltx_text" style="font-size:90%;">
Solatorio, A. V. and Dupriez, O.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.8.1" class="ltx_text" style="font-size:90%;">REaLTabFormer: Generating Realistic Relational and Tabular Data
using Transformers.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib51.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv:2302.02041</em><span id="bib.bib51.10.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib52.5.5.1" class="ltx_text" style="font-size:90%;">Stadler et al. (2022)</span></span>
<span class="ltx_bibblock"><span id="bib.bib52.7.1" class="ltx_text" style="font-size:90%;">
Stadler, T., Oprisanu, B., and Troncoso, C.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.8.1" class="ltx_text" style="font-size:90%;">Synthetic data – anonymization groundhog day.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib52.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Usenix Security</em><span id="bib.bib52.11.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib53.4.4.1" class="ltx_text" style="font-size:90%;">TechCrunch (2023a)</span></span>
<span class="ltx_bibblock"><span id="bib.bib53.6.1" class="ltx_text" style="font-size:90%;">
TechCrunch.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.7.1" class="ltx_text" style="font-size:90%;">The current legal cases against generative AI are just the
beginning.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://techcrunch.com/2023/01/27/the-current-legal-cases-against-generative-ai-are-just-the-beginning/" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://techcrunch.com/2023/01/27/the-current-legal-cases-against-generative-ai-are-just-the-beginning/</a><span id="bib.bib53.8.1" class="ltx_text" style="font-size:90%;">,
2023a.
</span>
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib54.4.4.1" class="ltx_text" style="font-size:90%;">TechCrunch (2023b)</span></span>
<span class="ltx_bibblock"><span id="bib.bib54.6.1" class="ltx_text" style="font-size:90%;">
TechCrunch.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.7.1" class="ltx_text" style="font-size:90%;">VCs continue to pour dollars into generative AI.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://techcrunch.com/2023/03/28/generative-ai-venture-capital/" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://techcrunch.com/2023/03/28/generative-ai-venture-capital/</a><span id="bib.bib54.8.1" class="ltx_text" style="font-size:90%;">,
2023b.
</span>
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib55.4.4.1" class="ltx_text" style="font-size:90%;">UN (2023)</span></span>
<span class="ltx_bibblock"><span id="bib.bib55.6.1" class="ltx_text" style="font-size:90%;">
UN.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.7.1" class="ltx_text" style="font-size:90%;">The United Nations Guide on privacy-enhancing technologies for
official statistics.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://unstats.un.org/bigdata/task-teams/privacy/guide/2023_UN%20PET%20Guide.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://unstats.un.org/bigdata/task-teams/privacy/guide/2023_UN%20PET%20Guide.pdf</a><span id="bib.bib55.8.1" class="ltx_text" style="font-size:90%;">,
2023.
</span>
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib56.5.5.1" class="ltx_text" style="font-size:90%;">van den Burg &amp; Williams (2021)</span></span>
<span class="ltx_bibblock"><span id="bib.bib56.7.1" class="ltx_text" style="font-size:90%;">
van den Burg, G. and Williams, C.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.8.1" class="ltx_text" style="font-size:90%;">On memorization in probabilistic deep generative models.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib56.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">NeurIPS</em><span id="bib.bib56.10.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib57.5.5.1" class="ltx_text" style="font-size:90%;">Vaswani et al. (2017)</span></span>
<span class="ltx_bibblock"><span id="bib.bib57.7.1" class="ltx_text" style="font-size:90%;">
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N.,
Kaiser, Ł., and Polosukhin, I.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.8.1" class="ltx_text" style="font-size:90%;">Attention is all you need.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib57.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">NeurIPS</em><span id="bib.bib57.10.2" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib58.5.5.1" class="ltx_text" style="font-size:90%;">Xie et al. (2018)</span></span>
<span class="ltx_bibblock"><span id="bib.bib58.7.1" class="ltx_text" style="font-size:90%;">
Xie, L., Lin, K., Wang, S., Wang, F., and Zhou, J.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.8.1" class="ltx_text" style="font-size:90%;">Differentially private generative adversarial network.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib58.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv:1802.06739</em><span id="bib.bib58.10.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib59.5.5.1" class="ltx_text" style="font-size:90%;">Xu et al. (2023)</span></span>
<span class="ltx_bibblock"><span id="bib.bib59.7.1" class="ltx_text" style="font-size:90%;">
Xu, K., Ganev, G., Joubert, E., Davison, R., Van Acker, O., and Robinson, L.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.8.1" class="ltx_text" style="font-size:90%;">Synthetic data generation of many-to-many datasets via random graph
generation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib59.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ICLR</em><span id="bib.bib59.11.3" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2307.00358" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2307.00359" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2307.00359">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2307.00359" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2307.00360" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Feb 28 20:25:21 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
