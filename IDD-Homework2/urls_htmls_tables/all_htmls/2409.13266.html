<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts</title>
<!--Generated on Wed Oct  2 01:13:01 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.13266v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S1" title="In Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S2" title="In Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Method</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S3" title="In Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Datasets</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S3.SS1" title="In 3 Datasets â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Natural Language Processing  (<span class="ltx_text ltx_font_typewriter">nlp</span>)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S3.SS2" title="In 3 Datasets â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Astrophysics  (<span class="ltx_text ltx_font_typewriter">astro</span>)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S3.SS3" title="In 3 Datasets â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Paleontology  (<span class="ltx_text ltx_font_typewriter">paleo</span>)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S3.SS4" title="In 3 Datasets â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Statistics and Analysis</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S4" title="In Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experimental Settings</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S4.SS1" title="In 4 Experimental Settings â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Initial Model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S4.SS2" title="In 4 Experimental Settings â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Domain Adaptation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S4.SS3" title="In 4 Experimental Settings â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Baselines</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S4.SS4" title="In 4 Experimental Settings â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Datasets and Evaluation Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S4.SS5" title="In 4 Experimental Settings â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.5 </span>Performance of Models on KP20k</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S5" title="In Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S5.SS1" title="In 5 Results â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Confidence Ranking of synthetic samples</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S5.SS2" title="In 5 Results â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Forgetting of Domain Adaptation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S5.SS3" title="In 5 Results â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Qualitative analysis</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S5.SS4" title="In 5 Results â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Bias towards Highly Cited Papers</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S6" title="In Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion and Future Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#A1" title="In Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Appendices</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#A1.SS1" title="In Appendix A Appendices â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Related work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#A1.SS2" title="In Appendix A Appendices â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Implementation Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#A1.SS3" title="In Appendix A Appendices â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.3 </span>Guidelines for manual evaluation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#A1.SS4" title="In Appendix A Appendices â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.4 </span>Sources used for collecting test data</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Florian Boudin 
<br class="ltx_break"/>JFLI, CNRS, Nantes University, France 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">florian.boudin@univ-nantes.fr</span>
<br class="ltx_break"/>&amp;Akiko Aizawa 
<br class="ltx_break"/>National Institute of Informatics, Japan 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id2.2.id2">aizawa@nii.ac.jp</span>
<br class="ltx_break"/>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id3.id1">Adapting keyphrase generation models to new domains typically involves few-shot fine-tuning with in-domain labeled data.
However, annotating documents with keyphrases is often prohibitively expensive and impractical, requiring expert annotators.
This paper presents <span class="ltx_text ltx_font_typewriter" id="id3.id1.1">silk</span>, an unsupervised method designed to address this issue by extracting silver-standard keyphrases from citation contexts to create synthetic labeled data for domain adaptation.
Extensive experiments across three distinct domains demonstrate that our method yields high-quality synthetic samples, resulting in significant and consistent improvements in in-domain performance over strong baselines.</p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<div class="ltx_block ltx_align_bottom" id="p1.1">
<p class="ltx_p" id="p1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1.1">Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.1.2" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p1.1.2.1" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.1.2.1.1">
<span class="ltx_tr" id="p1.1.2.1.1.1">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.1.1.1">Florian Boudin</span></span></span>
<span class="ltx_tr" id="p1.1.2.1.1.2">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.2.1">JFLI, CNRS, Nantes University, France</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.3">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.3.1"><span class="ltx_text ltx_font_typewriter" id="p1.1.2.1.1.3.1.1">florian.boudin@univ-nantes.fr</span></span></span>
</span></span>Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â <span class="ltx_text ltx_inline-block" id="p1.1.2.2" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.1.2.2.1">
<span class="ltx_tr" id="p1.1.2.2.1.1">
<span class="ltx_td ltx_align_center" id="p1.1.2.2.1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.2.1.1.1.1">Akiko Aizawa</span></span></span>
<span class="ltx_tr" id="p1.1.2.2.1.2">
<span class="ltx_td ltx_align_center" id="p1.1.2.2.1.2.1">National Institute of Informatics, Japan</span></span>
<span class="ltx_tr" id="p1.1.2.2.1.3">
<span class="ltx_td ltx_align_center" id="p1.1.2.2.1.3.1"><span class="ltx_text ltx_font_typewriter" id="p1.1.2.2.1.3.1.1">aizawa@nii.ac.jp</span></span></span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Keyphrase generation aims at automatically predicting a set of keyphrases â€”words or phrases that represent the main conceptsâ€” given a source text.
Because they distill the important information from documents, keyphrases are useful for many applications in natural language processing and information retrieval, most notably for document indexingÂ <cite class="ltx_cite ltx_citemacro_cite">Fagan (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib16" title="">1987</a>); Zhai (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib58" title="">1997</a>); Jones and Staveley (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib26" title="">1999</a>); Gutwin etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib22" title="">1999</a>); Boudin etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib7" title="">2020</a>)</cite> and summarizationÂ <cite class="ltx_cite ltx_citemacro_cite">Zha (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib57" title="">2002</a>); Wan etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib51" title="">2007</a>); Liu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib33" title="">2021</a>); Koto etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib29" title="">2022</a>)</cite>.
Keyphrase generation differs from its extractive counterpart in that it requires the capability of predicting keyphrases that do not necessarily appear
in the source textÂ <cite class="ltx_cite ltx_citemacro_cite">Liu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib34" title="">2011</a>); Meng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib40" title="">2017</a>)</cite>.
Current models for this task are built upon sequence-to-sequence models, and achieve remarkable prediction performance when a large amount of labeled data is availableÂ <cite class="ltx_cite ltx_citemacro_cite">Meng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib39" title="">2021</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">However, keyphrase-labeled data is notably scarce even for resource-rich languages.
To date, there are only a handful of available datasets large enough to train keyphrase generation models, therefore restricting their applicability to specific domainsÂ <cite class="ltx_cite ltx_citemacro_cite">Ye and Wang (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib54" title="">2018</a>); Wu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib53" title="">2022</a>); Garg etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib21" title="">2023</a>)</cite>.
Here, we are concerned with generating keyphrases from scientific papers, for which datasets only exist in the broader scope of computer scienceÂ <cite class="ltx_cite ltx_citemacro_cite">Meng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib40" title="">2017</a>); Mahata etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib35" title="">2022</a>)</cite> and biomedicineÂ <cite class="ltx_cite ltx_citemacro_cite">Houbre etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib23" title="">2022</a>)</cite>.
This data scarcity issue is all the more important since current models demonstrate very limited generalization capabilitiesÂ <cite class="ltx_cite ltx_citemacro_cite">Gallina etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib18" title="">2019</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib19" title="">2020</a>); Meng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib39" title="">2021</a>)</cite>.
All of this, coupled with the high computational cost of training models, underscores the necessity of developing domain adaptation methods for keyphrase generation.</p>
</div>
<figure class="ltx_figure" id="S1.F1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S1.F1.1" style="width:433.6pt;height:206.8pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-128.1pt,60.9pt) scale(0.628527387049134,0.628527387049134) ;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="630" id="S1.F1.1.g1" src="x1.png" width="1319"/>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Illustration of the <span class="ltx_text ltx_font_typewriter" id="S1.F1.3.1">silk</span> method for mining silver-standard keyphrases (highlighted in red) from citation contexts and generating synthetic samples for adapting models to new domains.</figcaption>
</figure>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">An effective strategy for addressing this challenge involves low-resource fine-tuningÂ <cite class="ltx_cite ltx_citemacro_cite">Wu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib53" title="">2022</a>); Meng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib38" title="">2023</a>)</cite>, wherein a pre-trained model is exposed to a limited amount of in-domain data with annotated keyphrases.
Nevertheless, annotating even a limited number of documents can be prohibitively expensive, and often impractical due to the necessity for expert annotatorsÂ <cite class="ltx_cite ltx_citemacro_cite">Chau etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib10" title="">2020</a>)</cite>.
Finding a way to collect such data in an unsupervised fashion would open up possibilities for effortlessly adapting models to new domains.
Here, we propose <span class="ltx_text ltx_font_typewriter" id="S1.p3.1.1">silk</span>, a method to do so that relies on extracting <span class="ltx_text ltx_framed ltx_framed_underline" id="S1.p3.1.2">sil</span>ver-standard <span class="ltx_text ltx_framed ltx_framed_underline" id="S1.p3.1.3">k</span>eyphrases from citation contexts to generate synthetic labeled data for domain adaptation (see FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_tag">1</span></a>).</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Citation contexts â€”text passages within the citing document containing the referenceâ€” often highlight the contributions of a cited paper, and have be shown to be useful not only for paper summarizationÂ <cite class="ltx_cite ltx_citemacro_cite">(Nakov etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib42" title="">2004</a>; Schwartz and Hearst, <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib46" title="">2006</a>; Mei and Zhai, <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib37" title="">2008</a>; Abu-Jbara and Radev, <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib1" title="">2011</a>; Mao etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib36" title="">2022</a>, <span class="ltx_text ltx_font_italic" id="S1.p4.1.1.1">inter alia</span>)</cite>, but also for tasks such as claim verificationÂ <cite class="ltx_cite ltx_citemacro_cite">Wadden etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib50" title="">2020</a>)</cite> or information extractionÂ <cite class="ltx_cite ltx_citemacro_cite">Viswanathan etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib49" title="">2021</a>)</cite>.
In this paper, we advocate for using citation contexts, specifically in the <em class="ltx_emph ltx_font_italic" id="S1.p4.1.2">mining of phrases representing the key concepts of cited papers</em>, to generate synthetic data for adapting keyphrase generation models to new domains.
Earlier research on keyphrase extraction has emphasized the value of citation context information as a feature for ranking phrasesÂ <cite class="ltx_cite ltx_citemacro_cite">DasÂ Gollapalli and Caragea (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib14" title="">2014</a>); Caragea etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib9" title="">2014</a>)</cite>.
We take this idea further and explore how it can be applied to create silver-labeled in-domain data for fine-tuning keyphrase generation models.
Our contributions can be summarized as follows:</p>
</div>
<div class="ltx_para" id="S1.p5">
<ol class="ltx_enumerate" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(<span class="ltx_text ltx_font_bold" id="S1.I1.i1.1.1.1">1</span>)</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We propose <span class="ltx_text ltx_font_typewriter" id="S1.I1.i1.p1.1.1">silk</span>, a method that leverages citation contexts to create synthetic samples of documents paired with silver-standard keyphrases for adapting keyphrase generation models to new domains.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(<span class="ltx_text ltx_font_bold" id="S1.I1.i2.1.1.1">2</span>)</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We apply our method on three distinct scientific domains â€”namely, Natural Language Processing, Astrophysics and Paleontologyâ€”, thereby creating new adaptation data for each domain.
We further provide three human-labeled test sets to assess the performance of keyphrase generation across these domains.
We view this effort as a significant contribution of our work.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(<span class="ltx_text ltx_font_bold" id="S1.I1.i3.1.1.1">3</span>)</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We conduct experiments on few-shot fine-tuning a pre-trained model for keyphrase generation and report significant improvements in in-domain performance using synthetic samples generated by <span class="ltx_text ltx_font_typewriter" id="S1.I1.i3.p1.1.1">silk</span>.
Additionally, we undertake further experiments to validate the quality of the synthetic samples through both empirical (Â§<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S5.SS1" title="5.1 Confidence Ranking of synthetic samples â€£ 5 Results â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_tag">5.1</span></a>) and human (Â§<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S5.SS3" title="5.3 Qualitative analysis â€£ 5 Results â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_tag">5.3</span></a>) evaluations, and we examine whether our adapted models experience catastrophic forgetting of the initial domain (Â§<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S5.SS2" title="5.2 Forgetting of Domain Adaptation â€£ 5 Results â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_tag">5.2</span></a>) <span class="ltx_text" id="S1.I1.i3.p1.1.2">or exhibit bias towards keyphrases from highly cited papers (Â§<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S5.SS4" title="5.4 Bias towards Highly Cited Papers â€£ 5 Results â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_tag">5.4</span></a>)<span class="ltx_text" id="S1.I1.i3.p1.1.2.1">.</span></span></p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">Our code, model weights and data are available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/boudinfl/silk/" title="">https://github.com/boudinfl/silk/</a>.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Method</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.9">This section describes the implementation details of our method for producing synthetic fine-tuning data from citation contexts.
Given a collection of in-domain scientific documents <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="S2.p1.1.m1.1"><semantics id="S2.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">ğ’Ÿ</mi><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><ci id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">ğ’Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">\mathcal{D}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.1.m1.1d">caligraphic_D</annotation></semantics></math>, we start by extracting the subset of sentences that contain citation anchors to build a set of citation contextsÂ <math alttext="\mathcal{C}" class="ltx_Math" display="inline" id="S2.p1.2.m2.1"><semantics id="S2.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml">ğ’</mi><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><ci id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1">ğ’</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">\mathcal{C}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.2.m2.1d">caligraphic_C</annotation></semantics></math>.
Heuristics are applied to filter out citation contexts that either reference a document <math alttext="d\not\in\mathcal{D}" class="ltx_Math" display="inline" id="S2.p1.3.m3.1"><semantics id="S2.p1.3.m3.1a"><mrow id="S2.p1.3.m3.1.1" xref="S2.p1.3.m3.1.1.cmml"><mi id="S2.p1.3.m3.1.1.2" xref="S2.p1.3.m3.1.1.2.cmml">d</mi><mo id="S2.p1.3.m3.1.1.1" xref="S2.p1.3.m3.1.1.1.cmml">âˆ‰</mo><mi class="ltx_font_mathcaligraphic" id="S2.p1.3.m3.1.1.3" xref="S2.p1.3.m3.1.1.3.cmml">ğ’Ÿ</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.3.m3.1b"><apply id="S2.p1.3.m3.1.1.cmml" xref="S2.p1.3.m3.1.1"><notin id="S2.p1.3.m3.1.1.1.cmml" xref="S2.p1.3.m3.1.1.1"></notin><ci id="S2.p1.3.m3.1.1.2.cmml" xref="S2.p1.3.m3.1.1.2">ğ‘‘</ci><ci id="S2.p1.3.m3.1.1.3.cmml" xref="S2.p1.3.m3.1.1.3">ğ’Ÿ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.3.m3.1c">d\not\in\mathcal{D}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.3.m3.1d">italic_d âˆ‰ caligraphic_D</annotation></semantics></math> or whose purpose of citing is ambiguous (i.e.Â containing multiple scattered citation anchors throughout the text).
For each cited document <math alttext="d\in\mathcal{D}" class="ltx_Math" display="inline" id="S2.p1.4.m4.1"><semantics id="S2.p1.4.m4.1a"><mrow id="S2.p1.4.m4.1.1" xref="S2.p1.4.m4.1.1.cmml"><mi id="S2.p1.4.m4.1.1.2" xref="S2.p1.4.m4.1.1.2.cmml">d</mi><mo id="S2.p1.4.m4.1.1.1" xref="S2.p1.4.m4.1.1.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S2.p1.4.m4.1.1.3" xref="S2.p1.4.m4.1.1.3.cmml">ğ’Ÿ</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.4.m4.1b"><apply id="S2.p1.4.m4.1.1.cmml" xref="S2.p1.4.m4.1.1"><in id="S2.p1.4.m4.1.1.1.cmml" xref="S2.p1.4.m4.1.1.1"></in><ci id="S2.p1.4.m4.1.1.2.cmml" xref="S2.p1.4.m4.1.1.2">ğ‘‘</ci><ci id="S2.p1.4.m4.1.1.3.cmml" xref="S2.p1.4.m4.1.1.3">ğ’Ÿ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.4.m4.1c">d\in\mathcal{D}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.4.m4.1d">italic_d âˆˆ caligraphic_D</annotation></semantics></math>, we extract all the phrases<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>We use spacy (<span class="ltx_text ltx_font_typewriter" id="footnote1.1">en_core_web_sm</span> model) and consider the noun phrases (<span class="ltx_text ltx_font_typewriter" id="footnote1.2">/Adj*Noun+/</span>) in their lemma forms as candidates. Irrelevant candidates are filtered out using a stoplist of high-frequency phrases.</span></span></span> from its title <math alttext="t_{d}" class="ltx_Math" display="inline" id="S2.p1.5.m5.1"><semantics id="S2.p1.5.m5.1a"><msub id="S2.p1.5.m5.1.1" xref="S2.p1.5.m5.1.1.cmml"><mi id="S2.p1.5.m5.1.1.2" xref="S2.p1.5.m5.1.1.2.cmml">t</mi><mi id="S2.p1.5.m5.1.1.3" xref="S2.p1.5.m5.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p1.5.m5.1b"><apply id="S2.p1.5.m5.1.1.cmml" xref="S2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.p1.5.m5.1.1.1.cmml" xref="S2.p1.5.m5.1.1">subscript</csymbol><ci id="S2.p1.5.m5.1.1.2.cmml" xref="S2.p1.5.m5.1.1.2">ğ‘¡</ci><ci id="S2.p1.5.m5.1.1.3.cmml" xref="S2.p1.5.m5.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.5.m5.1c">t_{d}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.5.m5.1d">italic_t start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math>, abstract <math alttext="a_{d}" class="ltx_Math" display="inline" id="S2.p1.6.m6.1"><semantics id="S2.p1.6.m6.1a"><msub id="S2.p1.6.m6.1.1" xref="S2.p1.6.m6.1.1.cmml"><mi id="S2.p1.6.m6.1.1.2" xref="S2.p1.6.m6.1.1.2.cmml">a</mi><mi id="S2.p1.6.m6.1.1.3" xref="S2.p1.6.m6.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p1.6.m6.1b"><apply id="S2.p1.6.m6.1.1.cmml" xref="S2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S2.p1.6.m6.1.1.1.cmml" xref="S2.p1.6.m6.1.1">subscript</csymbol><ci id="S2.p1.6.m6.1.1.2.cmml" xref="S2.p1.6.m6.1.1.2">ğ‘</ci><ci id="S2.p1.6.m6.1.1.3.cmml" xref="S2.p1.6.m6.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.6.m6.1c">a_{d}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.6.m6.1d">italic_a start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math> and corresponding citation contexts <math alttext="c_{d}" class="ltx_Math" display="inline" id="S2.p1.7.m7.1"><semantics id="S2.p1.7.m7.1a"><msub id="S2.p1.7.m7.1.1" xref="S2.p1.7.m7.1.1.cmml"><mi id="S2.p1.7.m7.1.1.2" xref="S2.p1.7.m7.1.1.2.cmml">c</mi><mi id="S2.p1.7.m7.1.1.3" xref="S2.p1.7.m7.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p1.7.m7.1b"><apply id="S2.p1.7.m7.1.1.cmml" xref="S2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S2.p1.7.m7.1.1.1.cmml" xref="S2.p1.7.m7.1.1">subscript</csymbol><ci id="S2.p1.7.m7.1.1.2.cmml" xref="S2.p1.7.m7.1.1.2">ğ‘</ci><ci id="S2.p1.7.m7.1.1.3.cmml" xref="S2.p1.7.m7.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.7.m7.1c">c_{d}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.7.m7.1d">italic_c start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math> to build a set of silver-standard keyphrase candidates <math alttext="\mathcal{P}_{d}" class="ltx_Math" display="inline" id="S2.p1.8.m8.1"><semantics id="S2.p1.8.m8.1a"><msub id="S2.p1.8.m8.1.1" xref="S2.p1.8.m8.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p1.8.m8.1.1.2" xref="S2.p1.8.m8.1.1.2.cmml">ğ’«</mi><mi id="S2.p1.8.m8.1.1.3" xref="S2.p1.8.m8.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p1.8.m8.1b"><apply id="S2.p1.8.m8.1.1.cmml" xref="S2.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S2.p1.8.m8.1.1.1.cmml" xref="S2.p1.8.m8.1.1">subscript</csymbol><ci id="S2.p1.8.m8.1.1.2.cmml" xref="S2.p1.8.m8.1.1.2">ğ’«</ci><ci id="S2.p1.8.m8.1.1.3.cmml" xref="S2.p1.8.m8.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.8.m8.1c">\mathcal{P}_{d}</annotation><annotation encoding="application/x-llamapun" id="S2.p1.8.m8.1d">caligraphic_P start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math>.
Our method for generating synthetic samples from pairs of <math alttext="(d,~{}\mathcal{P}_{d})" class="ltx_Math" display="inline" id="S2.p1.9.m9.2"><semantics id="S2.p1.9.m9.2a"><mrow id="S2.p1.9.m9.2.2.1" xref="S2.p1.9.m9.2.2.2.cmml"><mo id="S2.p1.9.m9.2.2.1.2" stretchy="false" xref="S2.p1.9.m9.2.2.2.cmml">(</mo><mi id="S2.p1.9.m9.1.1" xref="S2.p1.9.m9.1.1.cmml">d</mi><mo id="S2.p1.9.m9.2.2.1.3" rspace="0.497em" xref="S2.p1.9.m9.2.2.2.cmml">,</mo><msub id="S2.p1.9.m9.2.2.1.1" xref="S2.p1.9.m9.2.2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p1.9.m9.2.2.1.1.2" xref="S2.p1.9.m9.2.2.1.1.2.cmml">ğ’«</mi><mi id="S2.p1.9.m9.2.2.1.1.3" xref="S2.p1.9.m9.2.2.1.1.3.cmml">d</mi></msub><mo id="S2.p1.9.m9.2.2.1.4" stretchy="false" xref="S2.p1.9.m9.2.2.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.9.m9.2b"><interval closure="open" id="S2.p1.9.m9.2.2.2.cmml" xref="S2.p1.9.m9.2.2.1"><ci id="S2.p1.9.m9.1.1.cmml" xref="S2.p1.9.m9.1.1">ğ‘‘</ci><apply id="S2.p1.9.m9.2.2.1.1.cmml" xref="S2.p1.9.m9.2.2.1.1"><csymbol cd="ambiguous" id="S2.p1.9.m9.2.2.1.1.1.cmml" xref="S2.p1.9.m9.2.2.1.1">subscript</csymbol><ci id="S2.p1.9.m9.2.2.1.1.2.cmml" xref="S2.p1.9.m9.2.2.1.1.2">ğ’«</ci><ci id="S2.p1.9.m9.2.2.1.1.3.cmml" xref="S2.p1.9.m9.2.2.1.1.3">ğ‘‘</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.9.m9.2c">(d,~{}\mathcal{P}_{d})</annotation><annotation encoding="application/x-llamapun" id="S2.p1.9.m9.2d">( italic_d , caligraphic_P start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT )</annotation></semantics></math> involves three steps, which are described below.</p>
</div>
<section class="ltx_subsection" id="S2.SSx1">
<h3 class="ltx_title ltx_title_subsection">Step 1: Ranking Keyphrase Candidates</h3>
<div class="ltx_para" id="S2.SSx1.p1">
<p class="ltx_p" id="S2.SSx1.p1.1">We rank each keyphrase candidate <math alttext="p\in\mathcal{P}_{d}" class="ltx_Math" display="inline" id="S2.SSx1.p1.1.m1.1"><semantics id="S2.SSx1.p1.1.m1.1a"><mrow id="S2.SSx1.p1.1.m1.1.1" xref="S2.SSx1.p1.1.m1.1.1.cmml"><mi id="S2.SSx1.p1.1.m1.1.1.2" xref="S2.SSx1.p1.1.m1.1.1.2.cmml">p</mi><mo id="S2.SSx1.p1.1.m1.1.1.1" xref="S2.SSx1.p1.1.m1.1.1.1.cmml">âˆˆ</mo><msub id="S2.SSx1.p1.1.m1.1.1.3" xref="S2.SSx1.p1.1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SSx1.p1.1.m1.1.1.3.2" xref="S2.SSx1.p1.1.m1.1.1.3.2.cmml">ğ’«</mi><mi id="S2.SSx1.p1.1.m1.1.1.3.3" xref="S2.SSx1.p1.1.m1.1.1.3.3.cmml">d</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SSx1.p1.1.m1.1b"><apply id="S2.SSx1.p1.1.m1.1.1.cmml" xref="S2.SSx1.p1.1.m1.1.1"><in id="S2.SSx1.p1.1.m1.1.1.1.cmml" xref="S2.SSx1.p1.1.m1.1.1.1"></in><ci id="S2.SSx1.p1.1.m1.1.1.2.cmml" xref="S2.SSx1.p1.1.m1.1.1.2">ğ‘</ci><apply id="S2.SSx1.p1.1.m1.1.1.3.cmml" xref="S2.SSx1.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.SSx1.p1.1.m1.1.1.3.1.cmml" xref="S2.SSx1.p1.1.m1.1.1.3">subscript</csymbol><ci id="S2.SSx1.p1.1.m1.1.1.3.2.cmml" xref="S2.SSx1.p1.1.m1.1.1.3.2">ğ’«</ci><ci id="S2.SSx1.p1.1.m1.1.1.3.3.cmml" xref="S2.SSx1.p1.1.m1.1.1.3.3">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx1.p1.1.m1.1c">p\in\mathcal{P}_{d}</annotation><annotation encoding="application/x-llamapun" id="S2.SSx1.p1.1.m1.1d">italic_p âˆˆ caligraphic_P start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math> based on three criteria:</p>
<ul class="ltx_itemize" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i1.p1.5">its <span class="ltx_text" id="S2.I1.i1.p1.5.1" style="color:#FF0A9C;">salience</span>, defined as the presence of <math alttext="p" class="ltx_Math" display="inline" id="S2.I1.i1.p1.1.m1.1"><semantics id="S2.I1.i1.p1.1.m1.1a"><mi id="S2.I1.i1.p1.1.m1.1.1" xref="S2.I1.i1.p1.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.1.m1.1b"><ci id="S2.I1.i1.p1.1.m1.1.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.1.m1.1c">p</annotation><annotation encoding="application/x-llamapun" id="S2.I1.i1.p1.1.m1.1d">italic_p</annotation></semantics></math> in <math alttext="t_{d}" class="ltx_Math" display="inline" id="S2.I1.i1.p1.2.m2.1"><semantics id="S2.I1.i1.p1.2.m2.1a"><msub id="S2.I1.i1.p1.2.m2.1.1" xref="S2.I1.i1.p1.2.m2.1.1.cmml"><mi id="S2.I1.i1.p1.2.m2.1.1.2" xref="S2.I1.i1.p1.2.m2.1.1.2.cmml">t</mi><mi id="S2.I1.i1.p1.2.m2.1.1.3" xref="S2.I1.i1.p1.2.m2.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.2.m2.1b"><apply id="S2.I1.i1.p1.2.m2.1.1.cmml" xref="S2.I1.i1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.I1.i1.p1.2.m2.1.1.1.cmml" xref="S2.I1.i1.p1.2.m2.1.1">subscript</csymbol><ci id="S2.I1.i1.p1.2.m2.1.1.2.cmml" xref="S2.I1.i1.p1.2.m2.1.1.2">ğ‘¡</ci><ci id="S2.I1.i1.p1.2.m2.1.1.3.cmml" xref="S2.I1.i1.p1.2.m2.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.2.m2.1c">t_{d}</annotation><annotation encoding="application/x-llamapun" id="S2.I1.i1.p1.2.m2.1d">italic_t start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="a_{d}" class="ltx_Math" display="inline" id="S2.I1.i1.p1.3.m3.1"><semantics id="S2.I1.i1.p1.3.m3.1a"><msub id="S2.I1.i1.p1.3.m3.1.1" xref="S2.I1.i1.p1.3.m3.1.1.cmml"><mi id="S2.I1.i1.p1.3.m3.1.1.2" xref="S2.I1.i1.p1.3.m3.1.1.2.cmml">a</mi><mi id="S2.I1.i1.p1.3.m3.1.1.3" xref="S2.I1.i1.p1.3.m3.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.3.m3.1b"><apply id="S2.I1.i1.p1.3.m3.1.1.cmml" xref="S2.I1.i1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.I1.i1.p1.3.m3.1.1.1.cmml" xref="S2.I1.i1.p1.3.m3.1.1">subscript</csymbol><ci id="S2.I1.i1.p1.3.m3.1.1.2.cmml" xref="S2.I1.i1.p1.3.m3.1.1.2">ğ‘</ci><ci id="S2.I1.i1.p1.3.m3.1.1.3.cmml" xref="S2.I1.i1.p1.3.m3.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.3.m3.1c">a_{d}</annotation><annotation encoding="application/x-llamapun" id="S2.I1.i1.p1.3.m3.1d">italic_a start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="c_{d}" class="ltx_Math" display="inline" id="S2.I1.i1.p1.4.m4.1"><semantics id="S2.I1.i1.p1.4.m4.1a"><msub id="S2.I1.i1.p1.4.m4.1.1" xref="S2.I1.i1.p1.4.m4.1.1.cmml"><mi id="S2.I1.i1.p1.4.m4.1.1.2" xref="S2.I1.i1.p1.4.m4.1.1.2.cmml">c</mi><mi id="S2.I1.i1.p1.4.m4.1.1.3" xref="S2.I1.i1.p1.4.m4.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.4.m4.1b"><apply id="S2.I1.i1.p1.4.m4.1.1.cmml" xref="S2.I1.i1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.I1.i1.p1.4.m4.1.1.1.cmml" xref="S2.I1.i1.p1.4.m4.1.1">subscript</csymbol><ci id="S2.I1.i1.p1.4.m4.1.1.2.cmml" xref="S2.I1.i1.p1.4.m4.1.1.2">ğ‘</ci><ci id="S2.I1.i1.p1.4.m4.1.1.3.cmml" xref="S2.I1.i1.p1.4.m4.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.4.m4.1c">c_{d}</annotation><annotation encoding="application/x-llamapun" id="S2.I1.i1.p1.4.m4.1d">italic_c start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math>.
Here, we assume that a phrase simultaneously occurring in all elements holds greater importance that a phrase found solely in one or two of them.
A boosting parameter <math alttext="\alpha=\{1,1.5,2\}" class="ltx_Math" display="inline" id="S2.I1.i1.p1.5.m5.3"><semantics id="S2.I1.i1.p1.5.m5.3a"><mrow id="S2.I1.i1.p1.5.m5.3.4" xref="S2.I1.i1.p1.5.m5.3.4.cmml"><mi id="S2.I1.i1.p1.5.m5.3.4.2" xref="S2.I1.i1.p1.5.m5.3.4.2.cmml">Î±</mi><mo id="S2.I1.i1.p1.5.m5.3.4.1" xref="S2.I1.i1.p1.5.m5.3.4.1.cmml">=</mo><mrow id="S2.I1.i1.p1.5.m5.3.4.3.2" xref="S2.I1.i1.p1.5.m5.3.4.3.1.cmml"><mo id="S2.I1.i1.p1.5.m5.3.4.3.2.1" stretchy="false" xref="S2.I1.i1.p1.5.m5.3.4.3.1.cmml">{</mo><mn id="S2.I1.i1.p1.5.m5.1.1" xref="S2.I1.i1.p1.5.m5.1.1.cmml">1</mn><mo id="S2.I1.i1.p1.5.m5.3.4.3.2.2" xref="S2.I1.i1.p1.5.m5.3.4.3.1.cmml">,</mo><mn id="S2.I1.i1.p1.5.m5.2.2" xref="S2.I1.i1.p1.5.m5.2.2.cmml">1.5</mn><mo id="S2.I1.i1.p1.5.m5.3.4.3.2.3" xref="S2.I1.i1.p1.5.m5.3.4.3.1.cmml">,</mo><mn id="S2.I1.i1.p1.5.m5.3.3" xref="S2.I1.i1.p1.5.m5.3.3.cmml">2</mn><mo id="S2.I1.i1.p1.5.m5.3.4.3.2.4" stretchy="false" xref="S2.I1.i1.p1.5.m5.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.5.m5.3b"><apply id="S2.I1.i1.p1.5.m5.3.4.cmml" xref="S2.I1.i1.p1.5.m5.3.4"><eq id="S2.I1.i1.p1.5.m5.3.4.1.cmml" xref="S2.I1.i1.p1.5.m5.3.4.1"></eq><ci id="S2.I1.i1.p1.5.m5.3.4.2.cmml" xref="S2.I1.i1.p1.5.m5.3.4.2">ğ›¼</ci><set id="S2.I1.i1.p1.5.m5.3.4.3.1.cmml" xref="S2.I1.i1.p1.5.m5.3.4.3.2"><cn id="S2.I1.i1.p1.5.m5.1.1.cmml" type="integer" xref="S2.I1.i1.p1.5.m5.1.1">1</cn><cn id="S2.I1.i1.p1.5.m5.2.2.cmml" type="float" xref="S2.I1.i1.p1.5.m5.2.2">1.5</cn><cn id="S2.I1.i1.p1.5.m5.3.3.cmml" type="integer" xref="S2.I1.i1.p1.5.m5.3.3">2</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.5.m5.3c">\alpha=\{1,1.5,2\}</annotation><annotation encoding="application/x-llamapun" id="S2.I1.i1.p1.5.m5.3d">italic_Î± = { 1 , 1.5 , 2 }</annotation></semantics></math> is introduced to prioritize phrases based on the number of elements in which they appear.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S2.I1.i2.p1">
<p class="ltx_p" id="S2.I1.i2.p1.2">its <span class="ltx_text" id="S2.I1.i2.p1.2.1" style="color:#00FF80;">relevance</span>, computed as the cosine distance between the embedding vectors of <math alttext="p" class="ltx_Math" display="inline" id="S2.I1.i2.p1.1.m1.1"><semantics id="S2.I1.i2.p1.1.m1.1a"><mi id="S2.I1.i2.p1.1.m1.1.1" xref="S2.I1.i2.p1.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.1.m1.1b"><ci id="S2.I1.i2.p1.1.m1.1.1.cmml" xref="S2.I1.i2.p1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.1.m1.1c">p</annotation><annotation encoding="application/x-llamapun" id="S2.I1.i2.p1.1.m1.1d">italic_p</annotation></semantics></math> and <math alttext="t_{d}" class="ltx_Math" display="inline" id="S2.I1.i2.p1.2.m2.1"><semantics id="S2.I1.i2.p1.2.m2.1a"><msub id="S2.I1.i2.p1.2.m2.1.1" xref="S2.I1.i2.p1.2.m2.1.1.cmml"><mi id="S2.I1.i2.p1.2.m2.1.1.2" xref="S2.I1.i2.p1.2.m2.1.1.2.cmml">t</mi><mi id="S2.I1.i2.p1.2.m2.1.1.3" xref="S2.I1.i2.p1.2.m2.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.2.m2.1b"><apply id="S2.I1.i2.p1.2.m2.1.1.cmml" xref="S2.I1.i2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.I1.i2.p1.2.m2.1.1.1.cmml" xref="S2.I1.i2.p1.2.m2.1.1">subscript</csymbol><ci id="S2.I1.i2.p1.2.m2.1.1.2.cmml" xref="S2.I1.i2.p1.2.m2.1.1.2">ğ‘¡</ci><ci id="S2.I1.i2.p1.2.m2.1.1.3.cmml" xref="S2.I1.i2.p1.2.m2.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.2.m2.1c">t_{d}</annotation><annotation encoding="application/x-llamapun" id="S2.I1.i2.p1.2.m2.1d">italic_t start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math>.
We use the title as a high-level summary of the document, and assume that relevant phrases should be semantically close to it.
We leverage SPECTER<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/sentence-transformers/allenai-specter" title="">https://huggingface.co/sentence-transformers/allenai-specter</a></span></span></span>Â <cite class="ltx_cite ltx_citemacro_cite">Cohan etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib13" title="">2020</a>)</cite>, a BERT-based model pre-trained on scientific documents, to compute the embedding vectors.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S2.I1.i3.p1">
<p class="ltx_p" id="S2.I1.i3.p1.3">its <span class="ltx_text" id="S2.I1.i3.p1.3.1" style="color:#6E73FF;">reliability</span>, estimated by the number of citation contexts in which <math alttext="p" class="ltx_Math" display="inline" id="S2.I1.i3.p1.1.m1.1"><semantics id="S2.I1.i3.p1.1.m1.1a"><mi id="S2.I1.i3.p1.1.m1.1.1" xref="S2.I1.i3.p1.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.1.m1.1b"><ci id="S2.I1.i3.p1.1.m1.1.1.cmml" xref="S2.I1.i3.p1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.1.m1.1c">p</annotation><annotation encoding="application/x-llamapun" id="S2.I1.i3.p1.1.m1.1d">italic_p</annotation></semantics></math> occurs.
We rely on the citation context frequency as a means to estimate how reliable a phrase is, the hypothesis being that phrases that appears in multiple citation contexts are more likely to be reliable.
Specifically, we use the log-frequency of <math alttext="p" class="ltx_Math" display="inline" id="S2.I1.i3.p1.2.m2.1"><semantics id="S2.I1.i3.p1.2.m2.1a"><mi id="S2.I1.i3.p1.2.m2.1.1" xref="S2.I1.i3.p1.2.m2.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.2.m2.1b"><ci id="S2.I1.i3.p1.2.m2.1.1.cmml" xref="S2.I1.i3.p1.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.2.m2.1c">p</annotation><annotation encoding="application/x-llamapun" id="S2.I1.i3.p1.2.m2.1d">italic_p</annotation></semantics></math> in <math alttext="c_{d}" class="ltx_Math" display="inline" id="S2.I1.i3.p1.3.m3.1"><semantics id="S2.I1.i3.p1.3.m3.1a"><msub id="S2.I1.i3.p1.3.m3.1.1" xref="S2.I1.i3.p1.3.m3.1.1.cmml"><mi id="S2.I1.i3.p1.3.m3.1.1.2" xref="S2.I1.i3.p1.3.m3.1.1.2.cmml">c</mi><mi id="S2.I1.i3.p1.3.m3.1.1.3" xref="S2.I1.i3.p1.3.m3.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.3.m3.1b"><apply id="S2.I1.i3.p1.3.m3.1.1.cmml" xref="S2.I1.i3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.I1.i3.p1.3.m3.1.1.1.cmml" xref="S2.I1.i3.p1.3.m3.1.1">subscript</csymbol><ci id="S2.I1.i3.p1.3.m3.1.1.2.cmml" xref="S2.I1.i3.p1.3.m3.1.1.2">ğ‘</ci><ci id="S2.I1.i3.p1.3.m3.1.1.3.cmml" xref="S2.I1.i3.p1.3.m3.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.3.m3.1c">c_{d}</annotation><annotation encoding="application/x-llamapun" id="S2.I1.i3.p1.3.m3.1d">italic_c start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math> to squash the range of values in a log-scale.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S2.SSx1.p2">
<p class="ltx_p" id="S2.SSx1.p2.2">More formally, given a document <math alttext="d" class="ltx_Math" display="inline" id="S2.SSx1.p2.1.m1.1"><semantics id="S2.SSx1.p2.1.m1.1a"><mi id="S2.SSx1.p2.1.m1.1.1" xref="S2.SSx1.p2.1.m1.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S2.SSx1.p2.1.m1.1b"><ci id="S2.SSx1.p2.1.m1.1.1.cmml" xref="S2.SSx1.p2.1.m1.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx1.p2.1.m1.1c">d</annotation><annotation encoding="application/x-llamapun" id="S2.SSx1.p2.1.m1.1d">italic_d</annotation></semantics></math>, the score of a keyphrase candidate <math alttext="p" class="ltx_Math" display="inline" id="S2.SSx1.p2.2.m2.1"><semantics id="S2.SSx1.p2.2.m2.1a"><mi id="S2.SSx1.p2.2.m2.1.1" xref="S2.SSx1.p2.2.m2.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S2.SSx1.p2.2.m2.1b"><ci id="S2.SSx1.p2.2.m2.1.1.cmml" xref="S2.SSx1.p2.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx1.p2.2.m2.1c">p</annotation><annotation encoding="application/x-llamapun" id="S2.SSx1.p2.2.m2.1d">italic_p</annotation></semantics></math> is calculated as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathrm{score}(p,d)={\color[rgb]{1,0.04,0.61}\definecolor[named]{%
pgfstrokecolor}{rgb}{1,0.04,0.61}\pgfsys@color@cmyk@stroke{0}{0.96}{0.39}{0}%
\pgfsys@color@cmyk@fill{0}{0.96}{0.39}{0}\alpha_{(p)}}\cdot{\color[rgb]{%
0,1,0.5}\definecolor[named]{pgfstrokecolor}{rgb}{0,1,0.5}%
\pgfsys@color@cmyk@stroke{1}{0}{0.50}{0}\pgfsys@color@cmyk@fill{1}{0}{0.50}{0}%
\mathrm{cos}\textrm{-}\mathrm{sim}\bigl{(}\mathrm{emb}(p),\mathrm{emb}(t_{d})%
\bigr{)}}\\
\cdot{\color[rgb]{0.43,0.45,1}\definecolor[named]{pgfstrokecolor}{rgb}{%
0.43,0.45,1}\pgfsys@color@cmyk@stroke{0.57}{0.55}{0}{0}\pgfsys@color@cmyk@fill%
{0.57}{0.55}{0}{0}\log\bigl{(}\mathrm{freq}_{\mathrm{cc}}(p)\bigr{)}}" class="ltx_Math" display="block" id="S2.E1.m1.40"><semantics id="S2.E1.m1.40a"><mtable displaystyle="true" id="S2.E1.m1.40.40.6" rowspacing="0pt" xref="S2.E1.m1.37.37.3.cmml"><mtr id="S2.E1.m1.40.40.6a" xref="S2.E1.m1.37.37.3.cmml"><mtd class="ltx_align_left" columnalign="left" id="S2.E1.m1.40.40.6b" xref="S2.E1.m1.37.37.3.cmml"><mrow id="S2.E1.m1.39.39.5.36.27.27" xref="S2.E1.m1.37.37.3.cmml"><mrow id="S2.E1.m1.39.39.5.36.27.27.28" xref="S2.E1.m1.37.37.3.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.cmml">score</mi><mo id="S2.E1.m1.39.39.5.36.27.27.28.1" xref="S2.E1.m1.37.37.3.cmml">â¢</mo><mrow id="S2.E1.m1.39.39.5.36.27.27.28.2" xref="S2.E1.m1.37.37.3.cmml"><mo id="S2.E1.m1.2.2.2.2.2.2" stretchy="false" xref="S2.E1.m1.37.37.3.cmml">(</mo><mi id="S2.E1.m1.3.3.3.3.3.3" xref="S2.E1.m1.3.3.3.3.3.3.cmml">p</mi><mo id="S2.E1.m1.4.4.4.4.4.4" xref="S2.E1.m1.37.37.3.cmml">,</mo><mi id="S2.E1.m1.5.5.5.5.5.5" xref="S2.E1.m1.5.5.5.5.5.5.cmml">d</mi><mo id="S2.E1.m1.6.6.6.6.6.6" stretchy="false" xref="S2.E1.m1.37.37.3.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.7.7.7.7.7.7" xref="S2.E1.m1.7.7.7.7.7.7.cmml">=</mo><mrow id="S2.E1.m1.39.39.5.36.27.27.27" xref="S2.E1.m1.37.37.3.cmml"><mrow id="S2.E1.m1.39.39.5.36.27.27.27.4" xref="S2.E1.m1.37.37.3.cmml"><msub id="S2.E1.m1.39.39.5.36.27.27.27.4.1" xref="S2.E1.m1.37.37.3.cmml"><mi id="S2.E1.m1.8.8.8.8.8.8" mathcolor="#FF0A9C" xref="S2.E1.m1.8.8.8.8.8.8.cmml">Î±</mi><mrow id="S2.E1.m1.9.9.9.9.9.9.1.3" xref="S2.E1.m1.37.37.3.cmml"><mo id="S2.E1.m1.9.9.9.9.9.9.1.3.1" mathcolor="#FF0A9C" stretchy="false" xref="S2.E1.m1.37.37.3.cmml">(</mo><mi id="S2.E1.m1.9.9.9.9.9.9.1.1" mathcolor="#FF0A9C" xref="S2.E1.m1.9.9.9.9.9.9.1.1.cmml">p</mi><mo id="S2.E1.m1.9.9.9.9.9.9.1.3.2" mathcolor="#FF0A9C" stretchy="false" xref="S2.E1.m1.37.37.3.cmml">)</mo></mrow></msub><mo id="S2.E1.m1.10.10.10.10.10.10" lspace="0.222em" rspace="0.222em" xref="S2.E1.m1.10.10.10.10.10.10.cmml">â‹…</mo><mi id="S2.E1.m1.11.11.11.11.11.11" mathcolor="#00FF80" xref="S2.E1.m1.11.11.11.11.11.11.cmml">cos</mi></mrow><mo id="S2.E1.m1.39.39.5.36.27.27.27.3" xref="S2.E1.m1.37.37.3.cmml">â¢</mo><mtext id="S2.E1.m1.12.12.12.12.12.12" mathcolor="#00FF80" xref="S2.E1.m1.12.12.12.12.12.12a.cmml">-</mtext><mo id="S2.E1.m1.39.39.5.36.27.27.27.3a" xref="S2.E1.m1.37.37.3.cmml">â¢</mo><mi id="S2.E1.m1.13.13.13.13.13.13" mathcolor="#00FF80" xref="S2.E1.m1.13.13.13.13.13.13.cmml">sim</mi><mo id="S2.E1.m1.39.39.5.36.27.27.27.3b" xref="S2.E1.m1.37.37.3.cmml">â¢</mo><mrow id="S2.E1.m1.39.39.5.36.27.27.27.2.2" xref="S2.E1.m1.37.37.3.cmml"><mo id="S2.E1.m1.14.14.14.14.14.14" mathcolor="#00FF80" maxsize="120%" minsize="120%" xref="S2.E1.m1.37.37.3.cmml">(</mo><mrow id="S2.E1.m1.38.38.4.35.26.26.26.1.1.1" xref="S2.E1.m1.37.37.3.cmml"><mi id="S2.E1.m1.15.15.15.15.15.15" mathcolor="#00FF80" xref="S2.E1.m1.15.15.15.15.15.15.cmml">emb</mi><mo id="S2.E1.m1.38.38.4.35.26.26.26.1.1.1.1" xref="S2.E1.m1.37.37.3.cmml">â¢</mo><mrow id="S2.E1.m1.38.38.4.35.26.26.26.1.1.1.2" xref="S2.E1.m1.37.37.3.cmml"><mo id="S2.E1.m1.16.16.16.16.16.16" mathcolor="#00FF80" stretchy="false" xref="S2.E1.m1.37.37.3.cmml">(</mo><mi id="S2.E1.m1.17.17.17.17.17.17" mathcolor="#00FF80" xref="S2.E1.m1.17.17.17.17.17.17.cmml">p</mi><mo id="S2.E1.m1.18.18.18.18.18.18" mathcolor="#00FF80" stretchy="false" xref="S2.E1.m1.37.37.3.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.19.19.19.19.19.19" mathcolor="#00FF80" xref="S2.E1.m1.37.37.3.cmml">,</mo><mrow id="S2.E1.m1.39.39.5.36.27.27.27.2.2.2" xref="S2.E1.m1.37.37.3.cmml"><mi id="S2.E1.m1.20.20.20.20.20.20" mathcolor="#00FF80" xref="S2.E1.m1.20.20.20.20.20.20.cmml">emb</mi><mo id="S2.E1.m1.39.39.5.36.27.27.27.2.2.2.2" xref="S2.E1.m1.37.37.3.cmml">â¢</mo><mrow id="S2.E1.m1.39.39.5.36.27.27.27.2.2.2.1.1" xref="S2.E1.m1.37.37.3.cmml"><mo id="S2.E1.m1.21.21.21.21.21.21" mathcolor="#00FF80" stretchy="false" xref="S2.E1.m1.37.37.3.cmml">(</mo><msub id="S2.E1.m1.39.39.5.36.27.27.27.2.2.2.1.1.1" xref="S2.E1.m1.37.37.3.cmml"><mi id="S2.E1.m1.22.22.22.22.22.22" mathcolor="#00FF80" xref="S2.E1.m1.22.22.22.22.22.22.cmml">t</mi><mi id="S2.E1.m1.23.23.23.23.23.23.1" mathcolor="#00FF80" xref="S2.E1.m1.23.23.23.23.23.23.1.cmml">d</mi></msub><mo id="S2.E1.m1.24.24.24.24.24.24" mathcolor="#00FF80" stretchy="false" xref="S2.E1.m1.37.37.3.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.25.25.25.25.25.25" mathcolor="#00FF80" maxsize="120%" minsize="120%" xref="S2.E1.m1.37.37.3.cmml">)</mo></mrow></mrow></mrow></mtd></mtr><mtr id="S2.E1.m1.40.40.6c" xref="S2.E1.m1.37.37.3.cmml"><mtd class="ltx_align_right" columnalign="right" id="S2.E1.m1.40.40.6d" xref="S2.E1.m1.37.37.3.cmml"><mrow id="S2.E1.m1.40.40.6.37.10.10" xref="S2.E1.m1.37.37.3.cmml"><mi id="S2.E1.m1.40.40.6.37.10.10.11" xref="S2.E1.m1.37.37.3.cmml"></mi><mo id="S2.E1.m1.26.26.26.1.1.1" lspace="0.222em" rspace="0.222em" xref="S2.E1.m1.26.26.26.1.1.1.cmml">â‹…</mo><mrow id="S2.E1.m1.40.40.6.37.10.10.10.1" xref="S2.E1.m1.37.37.3.cmml"><mi id="S2.E1.m1.27.27.27.2.2.2" mathcolor="#6E73FF" xref="S2.E1.m1.27.27.27.2.2.2.cmml">log</mi><mo id="S2.E1.m1.40.40.6.37.10.10.10.1a" xref="S2.E1.m1.37.37.3.cmml">â¡</mo><mrow id="S2.E1.m1.40.40.6.37.10.10.10.1.1" xref="S2.E1.m1.37.37.3.cmml"><mo id="S2.E1.m1.28.28.28.3.3.3" mathcolor="#6E73FF" maxsize="120%" minsize="120%" xref="S2.E1.m1.37.37.3.cmml">(</mo><mrow id="S2.E1.m1.40.40.6.37.10.10.10.1.1.1" xref="S2.E1.m1.37.37.3.cmml"><msub id="S2.E1.m1.40.40.6.37.10.10.10.1.1.1.2" xref="S2.E1.m1.37.37.3.cmml"><mi id="S2.E1.m1.29.29.29.4.4.4" mathcolor="#6E73FF" xref="S2.E1.m1.29.29.29.4.4.4.cmml">freq</mi><mi id="S2.E1.m1.30.30.30.5.5.5.1" mathcolor="#6E73FF" xref="S2.E1.m1.30.30.30.5.5.5.1.cmml">cc</mi></msub><mo id="S2.E1.m1.40.40.6.37.10.10.10.1.1.1.1" xref="S2.E1.m1.37.37.3.cmml">â¢</mo><mrow id="S2.E1.m1.40.40.6.37.10.10.10.1.1.1.3" xref="S2.E1.m1.37.37.3.cmml"><mo id="S2.E1.m1.31.31.31.6.6.6" mathcolor="#6E73FF" stretchy="false" xref="S2.E1.m1.37.37.3.cmml">(</mo><mi id="S2.E1.m1.32.32.32.7.7.7" mathcolor="#6E73FF" xref="S2.E1.m1.32.32.32.7.7.7.cmml">p</mi><mo id="S2.E1.m1.33.33.33.8.8.8" mathcolor="#6E73FF" stretchy="false" xref="S2.E1.m1.37.37.3.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.34.34.34.9.9.9" mathcolor="#6E73FF" maxsize="120%" minsize="120%" xref="S2.E1.m1.37.37.3.cmml">)</mo></mrow></mrow></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S2.E1.m1.40b"><apply id="S2.E1.m1.37.37.3.cmml" xref="S2.E1.m1.40.40.6"><eq id="S2.E1.m1.7.7.7.7.7.7.cmml" xref="S2.E1.m1.7.7.7.7.7.7"></eq><apply id="S2.E1.m1.37.37.3.5.cmml" xref="S2.E1.m1.40.40.6"><times id="S2.E1.m1.37.37.3.5.1.cmml" xref="S2.E1.m1.40.40.6"></times><ci id="S2.E1.m1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1">score</ci><interval closure="open" id="S2.E1.m1.37.37.3.5.3.cmml" xref="S2.E1.m1.40.40.6"><ci id="S2.E1.m1.3.3.3.3.3.3.cmml" xref="S2.E1.m1.3.3.3.3.3.3">ğ‘</ci><ci id="S2.E1.m1.5.5.5.5.5.5.cmml" xref="S2.E1.m1.5.5.5.5.5.5">ğ‘‘</ci></interval></apply><apply id="S2.E1.m1.37.37.3.3.cmml" xref="S2.E1.m1.40.40.6"><ci id="S2.E1.m1.26.26.26.1.1.1.cmml" xref="S2.E1.m1.26.26.26.1.1.1">â‹…</ci><apply id="S2.E1.m1.36.36.2.2.2.cmml" xref="S2.E1.m1.40.40.6"><times id="S2.E1.m1.36.36.2.2.2.3.cmml" xref="S2.E1.m1.40.40.6"></times><apply id="S2.E1.m1.36.36.2.2.2.4.cmml" xref="S2.E1.m1.40.40.6"><ci id="S2.E1.m1.10.10.10.10.10.10.cmml" xref="S2.E1.m1.10.10.10.10.10.10">â‹…</ci><apply id="S2.E1.m1.36.36.2.2.2.4.2.cmml" xref="S2.E1.m1.40.40.6"><csymbol cd="ambiguous" id="S2.E1.m1.36.36.2.2.2.4.2.1.cmml" xref="S2.E1.m1.40.40.6">subscript</csymbol><ci id="S2.E1.m1.8.8.8.8.8.8.cmml" xref="S2.E1.m1.8.8.8.8.8.8">ğ›¼</ci><ci id="S2.E1.m1.9.9.9.9.9.9.1.1.cmml" xref="S2.E1.m1.9.9.9.9.9.9.1.1">ğ‘</ci></apply><ci id="S2.E1.m1.11.11.11.11.11.11.cmml" xref="S2.E1.m1.11.11.11.11.11.11">cos</ci></apply><ci id="S2.E1.m1.12.12.12.12.12.12a.cmml" xref="S2.E1.m1.12.12.12.12.12.12"><mtext id="S2.E1.m1.12.12.12.12.12.12.cmml" mathcolor="#00FF80" xref="S2.E1.m1.12.12.12.12.12.12">-</mtext></ci><ci id="S2.E1.m1.13.13.13.13.13.13.cmml" xref="S2.E1.m1.13.13.13.13.13.13">sim</ci><interval closure="open" id="S2.E1.m1.36.36.2.2.2.2.3.cmml" xref="S2.E1.m1.40.40.6"><apply id="S2.E1.m1.35.35.1.1.1.1.1.1.cmml" xref="S2.E1.m1.40.40.6"><times id="S2.E1.m1.35.35.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.40.40.6"></times><ci id="S2.E1.m1.15.15.15.15.15.15.cmml" xref="S2.E1.m1.15.15.15.15.15.15">emb</ci><ci id="S2.E1.m1.17.17.17.17.17.17.cmml" xref="S2.E1.m1.17.17.17.17.17.17">ğ‘</ci></apply><apply id="S2.E1.m1.36.36.2.2.2.2.2.2.cmml" xref="S2.E1.m1.40.40.6"><times id="S2.E1.m1.36.36.2.2.2.2.2.2.2.cmml" xref="S2.E1.m1.40.40.6"></times><ci id="S2.E1.m1.20.20.20.20.20.20.cmml" xref="S2.E1.m1.20.20.20.20.20.20">emb</ci><apply id="S2.E1.m1.36.36.2.2.2.2.2.2.1.1.1.cmml" xref="S2.E1.m1.40.40.6"><csymbol cd="ambiguous" id="S2.E1.m1.36.36.2.2.2.2.2.2.1.1.1.1.cmml" xref="S2.E1.m1.40.40.6">subscript</csymbol><ci id="S2.E1.m1.22.22.22.22.22.22.cmml" xref="S2.E1.m1.22.22.22.22.22.22">ğ‘¡</ci><ci id="S2.E1.m1.23.23.23.23.23.23.1.cmml" xref="S2.E1.m1.23.23.23.23.23.23.1">ğ‘‘</ci></apply></apply></interval></apply><apply id="S2.E1.m1.37.37.3.3.3.2.cmml" xref="S2.E1.m1.40.40.6"><log id="S2.E1.m1.27.27.27.2.2.2.cmml" xref="S2.E1.m1.27.27.27.2.2.2"></log><apply id="S2.E1.m1.37.37.3.3.3.1.1.1.cmml" xref="S2.E1.m1.40.40.6"><times id="S2.E1.m1.37.37.3.3.3.1.1.1.1.cmml" xref="S2.E1.m1.40.40.6"></times><apply id="S2.E1.m1.37.37.3.3.3.1.1.1.2.cmml" xref="S2.E1.m1.40.40.6"><csymbol cd="ambiguous" id="S2.E1.m1.37.37.3.3.3.1.1.1.2.1.cmml" xref="S2.E1.m1.40.40.6">subscript</csymbol><ci id="S2.E1.m1.29.29.29.4.4.4.cmml" xref="S2.E1.m1.29.29.29.4.4.4">freq</ci><ci id="S2.E1.m1.30.30.30.5.5.5.1.cmml" xref="S2.E1.m1.30.30.30.5.5.5.1">cc</ci></apply><ci id="S2.E1.m1.32.32.32.7.7.7.cmml" xref="S2.E1.m1.32.32.32.7.7.7">ğ‘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.40c">\mathrm{score}(p,d)={\color[rgb]{1,0.04,0.61}\definecolor[named]{%
pgfstrokecolor}{rgb}{1,0.04,0.61}\pgfsys@color@cmyk@stroke{0}{0.96}{0.39}{0}%
\pgfsys@color@cmyk@fill{0}{0.96}{0.39}{0}\alpha_{(p)}}\cdot{\color[rgb]{%
0,1,0.5}\definecolor[named]{pgfstrokecolor}{rgb}{0,1,0.5}%
\pgfsys@color@cmyk@stroke{1}{0}{0.50}{0}\pgfsys@color@cmyk@fill{1}{0}{0.50}{0}%
\mathrm{cos}\textrm{-}\mathrm{sim}\bigl{(}\mathrm{emb}(p),\mathrm{emb}(t_{d})%
\bigr{)}}\\
\cdot{\color[rgb]{0.43,0.45,1}\definecolor[named]{pgfstrokecolor}{rgb}{%
0.43,0.45,1}\pgfsys@color@cmyk@stroke{0.57}{0.55}{0}{0}\pgfsys@color@cmyk@fill%
{0.57}{0.55}{0}{0}\log\bigl{(}\mathrm{freq}_{\mathrm{cc}}(p)\bigr{)}}</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m1.40d">start_ROW start_CELL roman_score ( italic_p , italic_d ) = italic_Î± start_POSTSUBSCRIPT ( italic_p ) end_POSTSUBSCRIPT â‹… roman_cos - roman_sim ( roman_emb ( italic_p ) , roman_emb ( italic_t start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ) ) end_CELL end_ROW start_ROW start_CELL â‹… roman_log ( roman_freq start_POSTSUBSCRIPT roman_cc end_POSTSUBSCRIPT ( italic_p ) ) end_CELL end_ROW</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SSx1.p2.6">where <math alttext="\mathrm{emb}(s)" class="ltx_Math" display="inline" id="S2.SSx1.p2.3.m1.1"><semantics id="S2.SSx1.p2.3.m1.1a"><mrow id="S2.SSx1.p2.3.m1.1.2" xref="S2.SSx1.p2.3.m1.1.2.cmml"><mi id="S2.SSx1.p2.3.m1.1.2.2" xref="S2.SSx1.p2.3.m1.1.2.2.cmml">emb</mi><mo id="S2.SSx1.p2.3.m1.1.2.1" xref="S2.SSx1.p2.3.m1.1.2.1.cmml">â¢</mo><mrow id="S2.SSx1.p2.3.m1.1.2.3.2" xref="S2.SSx1.p2.3.m1.1.2.cmml"><mo id="S2.SSx1.p2.3.m1.1.2.3.2.1" stretchy="false" xref="S2.SSx1.p2.3.m1.1.2.cmml">(</mo><mi id="S2.SSx1.p2.3.m1.1.1" xref="S2.SSx1.p2.3.m1.1.1.cmml">s</mi><mo id="S2.SSx1.p2.3.m1.1.2.3.2.2" stretchy="false" xref="S2.SSx1.p2.3.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SSx1.p2.3.m1.1b"><apply id="S2.SSx1.p2.3.m1.1.2.cmml" xref="S2.SSx1.p2.3.m1.1.2"><times id="S2.SSx1.p2.3.m1.1.2.1.cmml" xref="S2.SSx1.p2.3.m1.1.2.1"></times><ci id="S2.SSx1.p2.3.m1.1.2.2.cmml" xref="S2.SSx1.p2.3.m1.1.2.2">emb</ci><ci id="S2.SSx1.p2.3.m1.1.1.cmml" xref="S2.SSx1.p2.3.m1.1.1">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx1.p2.3.m1.1c">\mathrm{emb}(s)</annotation><annotation encoding="application/x-llamapun" id="S2.SSx1.p2.3.m1.1d">roman_emb ( italic_s )</annotation></semantics></math> denotes the embedding vector output of SPECTER for input text <math alttext="s" class="ltx_Math" display="inline" id="S2.SSx1.p2.4.m2.1"><semantics id="S2.SSx1.p2.4.m2.1a"><mi id="S2.SSx1.p2.4.m2.1.1" xref="S2.SSx1.p2.4.m2.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S2.SSx1.p2.4.m2.1b"><ci id="S2.SSx1.p2.4.m2.1.1.cmml" xref="S2.SSx1.p2.4.m2.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx1.p2.4.m2.1c">s</annotation><annotation encoding="application/x-llamapun" id="S2.SSx1.p2.4.m2.1d">italic_s</annotation></semantics></math>, <math alttext="\mathrm{freq}_{\mathrm{cc}}(p)" class="ltx_Math" display="inline" id="S2.SSx1.p2.5.m3.1"><semantics id="S2.SSx1.p2.5.m3.1a"><mrow id="S2.SSx1.p2.5.m3.1.2" xref="S2.SSx1.p2.5.m3.1.2.cmml"><msub id="S2.SSx1.p2.5.m3.1.2.2" xref="S2.SSx1.p2.5.m3.1.2.2.cmml"><mi id="S2.SSx1.p2.5.m3.1.2.2.2" xref="S2.SSx1.p2.5.m3.1.2.2.2.cmml">freq</mi><mi id="S2.SSx1.p2.5.m3.1.2.2.3" xref="S2.SSx1.p2.5.m3.1.2.2.3.cmml">cc</mi></msub><mo id="S2.SSx1.p2.5.m3.1.2.1" xref="S2.SSx1.p2.5.m3.1.2.1.cmml">â¢</mo><mrow id="S2.SSx1.p2.5.m3.1.2.3.2" xref="S2.SSx1.p2.5.m3.1.2.cmml"><mo id="S2.SSx1.p2.5.m3.1.2.3.2.1" stretchy="false" xref="S2.SSx1.p2.5.m3.1.2.cmml">(</mo><mi id="S2.SSx1.p2.5.m3.1.1" xref="S2.SSx1.p2.5.m3.1.1.cmml">p</mi><mo id="S2.SSx1.p2.5.m3.1.2.3.2.2" stretchy="false" xref="S2.SSx1.p2.5.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SSx1.p2.5.m3.1b"><apply id="S2.SSx1.p2.5.m3.1.2.cmml" xref="S2.SSx1.p2.5.m3.1.2"><times id="S2.SSx1.p2.5.m3.1.2.1.cmml" xref="S2.SSx1.p2.5.m3.1.2.1"></times><apply id="S2.SSx1.p2.5.m3.1.2.2.cmml" xref="S2.SSx1.p2.5.m3.1.2.2"><csymbol cd="ambiguous" id="S2.SSx1.p2.5.m3.1.2.2.1.cmml" xref="S2.SSx1.p2.5.m3.1.2.2">subscript</csymbol><ci id="S2.SSx1.p2.5.m3.1.2.2.2.cmml" xref="S2.SSx1.p2.5.m3.1.2.2.2">freq</ci><ci id="S2.SSx1.p2.5.m3.1.2.2.3.cmml" xref="S2.SSx1.p2.5.m3.1.2.2.3">cc</ci></apply><ci id="S2.SSx1.p2.5.m3.1.1.cmml" xref="S2.SSx1.p2.5.m3.1.1">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx1.p2.5.m3.1c">\mathrm{freq}_{\mathrm{cc}}(p)</annotation><annotation encoding="application/x-llamapun" id="S2.SSx1.p2.5.m3.1d">roman_freq start_POSTSUBSCRIPT roman_cc end_POSTSUBSCRIPT ( italic_p )</annotation></semantics></math> is the number of citation contexts in which <math alttext="p" class="ltx_Math" display="inline" id="S2.SSx1.p2.6.m4.1"><semantics id="S2.SSx1.p2.6.m4.1a"><mi id="S2.SSx1.p2.6.m4.1.1" xref="S2.SSx1.p2.6.m4.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S2.SSx1.p2.6.m4.1b"><ci id="S2.SSx1.p2.6.m4.1.1.cmml" xref="S2.SSx1.p2.6.m4.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx1.p2.6.m4.1c">p</annotation><annotation encoding="application/x-llamapun" id="S2.SSx1.p2.6.m4.1d">italic_p</annotation></semantics></math> occurs.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SSx2">
<h3 class="ltx_title ltx_title_subsection">Step 2: Selecting Silver-Standard Keyphrases</h3>
<div class="ltx_para" id="S2.SSx2.p1">
<p class="ltx_p" id="S2.SSx2.p1.5">To select the optimal subset of phrases from <math alttext="\mathcal{P}_{d}" class="ltx_Math" display="inline" id="S2.SSx2.p1.1.m1.1"><semantics id="S2.SSx2.p1.1.m1.1a"><msub id="S2.SSx2.p1.1.m1.1.1" xref="S2.SSx2.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SSx2.p1.1.m1.1.1.2" xref="S2.SSx2.p1.1.m1.1.1.2.cmml">ğ’«</mi><mi id="S2.SSx2.p1.1.m1.1.1.3" xref="S2.SSx2.p1.1.m1.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SSx2.p1.1.m1.1b"><apply id="S2.SSx2.p1.1.m1.1.1.cmml" xref="S2.SSx2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SSx2.p1.1.m1.1.1.1.cmml" xref="S2.SSx2.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SSx2.p1.1.m1.1.1.2.cmml" xref="S2.SSx2.p1.1.m1.1.1.2">ğ’«</ci><ci id="S2.SSx2.p1.1.m1.1.1.3.cmml" xref="S2.SSx2.p1.1.m1.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx2.p1.1.m1.1c">\mathcal{P}_{d}</annotation><annotation encoding="application/x-llamapun" id="S2.SSx2.p1.1.m1.1d">caligraphic_P start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math>, we define a set of constraints that mirrors the typical characteristics found in gold standard keyphrases of scientific papers.
Building on past observations, our objective is to select between 3 and 5 phrases per document, comprising up to 3 phrases from its content (i.e.Â occurring in <math alttext="t_{d}" class="ltx_Math" display="inline" id="S2.SSx2.p1.2.m2.1"><semantics id="S2.SSx2.p1.2.m2.1a"><msub id="S2.SSx2.p1.2.m2.1.1" xref="S2.SSx2.p1.2.m2.1.1.cmml"><mi id="S2.SSx2.p1.2.m2.1.1.2" xref="S2.SSx2.p1.2.m2.1.1.2.cmml">t</mi><mi id="S2.SSx2.p1.2.m2.1.1.3" xref="S2.SSx2.p1.2.m2.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SSx2.p1.2.m2.1b"><apply id="S2.SSx2.p1.2.m2.1.1.cmml" xref="S2.SSx2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SSx2.p1.2.m2.1.1.1.cmml" xref="S2.SSx2.p1.2.m2.1.1">subscript</csymbol><ci id="S2.SSx2.p1.2.m2.1.1.2.cmml" xref="S2.SSx2.p1.2.m2.1.1.2">ğ‘¡</ci><ci id="S2.SSx2.p1.2.m2.1.1.3.cmml" xref="S2.SSx2.p1.2.m2.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx2.p1.2.m2.1c">t_{d}</annotation><annotation encoding="application/x-llamapun" id="S2.SSx2.p1.2.m2.1d">italic_t start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math> or <math alttext="a_{d}" class="ltx_Math" display="inline" id="S2.SSx2.p1.3.m3.1"><semantics id="S2.SSx2.p1.3.m3.1a"><msub id="S2.SSx2.p1.3.m3.1.1" xref="S2.SSx2.p1.3.m3.1.1.cmml"><mi id="S2.SSx2.p1.3.m3.1.1.2" xref="S2.SSx2.p1.3.m3.1.1.2.cmml">a</mi><mi id="S2.SSx2.p1.3.m3.1.1.3" xref="S2.SSx2.p1.3.m3.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SSx2.p1.3.m3.1b"><apply id="S2.SSx2.p1.3.m3.1.1.cmml" xref="S2.SSx2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SSx2.p1.3.m3.1.1.1.cmml" xref="S2.SSx2.p1.3.m3.1.1">subscript</csymbol><ci id="S2.SSx2.p1.3.m3.1.1.2.cmml" xref="S2.SSx2.p1.3.m3.1.1.2">ğ‘</ci><ci id="S2.SSx2.p1.3.m3.1.1.3.cmml" xref="S2.SSx2.p1.3.m3.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx2.p1.3.m3.1c">a_{d}</annotation><annotation encoding="application/x-llamapun" id="S2.SSx2.p1.3.m3.1d">italic_a start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math>) and the remainder from the citation contexts.
We promote the selection of diverse keyphrases by introducing a maximum cross-phrase similarity threshold parameter <math alttext="\lambda_{x}" class="ltx_Math" display="inline" id="S2.SSx2.p1.4.m4.1"><semantics id="S2.SSx2.p1.4.m4.1a"><msub id="S2.SSx2.p1.4.m4.1.1" xref="S2.SSx2.p1.4.m4.1.1.cmml"><mi id="S2.SSx2.p1.4.m4.1.1.2" xref="S2.SSx2.p1.4.m4.1.1.2.cmml">Î»</mi><mi id="S2.SSx2.p1.4.m4.1.1.3" xref="S2.SSx2.p1.4.m4.1.1.3.cmml">x</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SSx2.p1.4.m4.1b"><apply id="S2.SSx2.p1.4.m4.1.1.cmml" xref="S2.SSx2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SSx2.p1.4.m4.1.1.1.cmml" xref="S2.SSx2.p1.4.m4.1.1">subscript</csymbol><ci id="S2.SSx2.p1.4.m4.1.1.2.cmml" xref="S2.SSx2.p1.4.m4.1.1.2">ğœ†</ci><ci id="S2.SSx2.p1.4.m4.1.1.3.cmml" xref="S2.SSx2.p1.4.m4.1.1.3">ğ‘¥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx2.p1.4.m4.1c">\lambda_{x}</annotation><annotation encoding="application/x-llamapun" id="S2.SSx2.p1.4.m4.1d">italic_Î» start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT</annotation></semantics></math>.
This parameter prevents the inclusion of redundant candidates, as determined by the cosine distance between their embedding vectors.
Because candidates extracted from citation contexts are inherently noisy, we introduce a second threshold parameter <math alttext="\lambda_{r}" class="ltx_Math" display="inline" id="S2.SSx2.p1.5.m5.1"><semantics id="S2.SSx2.p1.5.m5.1a"><msub id="S2.SSx2.p1.5.m5.1.1" xref="S2.SSx2.p1.5.m5.1.1.cmml"><mi id="S2.SSx2.p1.5.m5.1.1.2" xref="S2.SSx2.p1.5.m5.1.1.2.cmml">Î»</mi><mi id="S2.SSx2.p1.5.m5.1.1.3" xref="S2.SSx2.p1.5.m5.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SSx2.p1.5.m5.1b"><apply id="S2.SSx2.p1.5.m5.1.1.cmml" xref="S2.SSx2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SSx2.p1.5.m5.1.1.1.cmml" xref="S2.SSx2.p1.5.m5.1.1">subscript</csymbol><ci id="S2.SSx2.p1.5.m5.1.1.2.cmml" xref="S2.SSx2.p1.5.m5.1.1.2">ğœ†</ci><ci id="S2.SSx2.p1.5.m5.1.1.3.cmml" xref="S2.SSx2.p1.5.m5.1.1.3">ğ‘Ÿ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx2.p1.5.m5.1c">\lambda_{r}</annotation><annotation encoding="application/x-llamapun" id="S2.SSx2.p1.5.m5.1d">italic_Î» start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> to filter out spurious candidates based on their <span class="ltx_text" id="S2.SSx2.p1.5.1" style="color:#00FF80;">relevance</span> scores.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SSx3">
<h3 class="ltx_title ltx_title_subsection">Step 3: Ordering Samples by Confidence</h3>
<div class="ltx_para" id="S2.SSx3.p1">
<p class="ltx_p" id="S2.SSx3.p1.1">The final step involves ordering the cited documents based on how confident our method is in its silver-standard keyphrases, and selecting the top-<math alttext="N" class="ltx_Math" display="inline" id="S2.SSx3.p1.1.m1.1"><semantics id="S2.SSx3.p1.1.m1.1a"><mi id="S2.SSx3.p1.1.m1.1.1" xref="S2.SSx3.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SSx3.p1.1.m1.1b"><ci id="S2.SSx3.p1.1.m1.1.1.cmml" xref="S2.SSx3.p1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx3.p1.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S2.SSx3.p1.1.m1.1d">italic_N</annotation></semantics></math> ranked documents as synthetic labeled data.
Here, we determine the confidence of our method by averaging the scores of its silver-standard keyphrases, as computed in EquationÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S2.E1" title="In Step 1: Ranking Keyphrase Candidates â€£ 2 Method â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_tag">1</span></a>.
We remind that our objective is to <em class="ltx_emph ltx_font_italic" id="S2.SSx3.p1.1.1">generate small, high quality in-domain data for fine-tuning keyphrase generation models</em>, which advocates for a conservative approach.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Datasets</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.3">We use the widely adopted KP20k datasetÂ <cite class="ltx_cite ltx_citemacro_cite">Meng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib40" title="">2017</a>)</cite> as a starting point for pre-training keyphrase generation models.
This dataset contains <math alttext="\approx 514\mathrm{K}" class="ltx_Math" display="inline" id="S3.p1.1.m1.1"><semantics id="S3.p1.1.m1.1a"><mrow id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml"><mi id="S3.p1.1.m1.1.1.2" xref="S3.p1.1.m1.1.1.2.cmml"></mi><mo id="S3.p1.1.m1.1.1.1" xref="S3.p1.1.m1.1.1.1.cmml">â‰ˆ</mo><mrow id="S3.p1.1.m1.1.1.3" xref="S3.p1.1.m1.1.1.3.cmml"><mn id="S3.p1.1.m1.1.1.3.2" xref="S3.p1.1.m1.1.1.3.2.cmml">514</mn><mo id="S3.p1.1.m1.1.1.3.1" xref="S3.p1.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S3.p1.1.m1.1.1.3.3" mathvariant="normal" xref="S3.p1.1.m1.1.1.3.3.cmml">K</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><apply id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1"><approx id="S3.p1.1.m1.1.1.1.cmml" xref="S3.p1.1.m1.1.1.1"></approx><csymbol cd="latexml" id="S3.p1.1.m1.1.1.2.cmml" xref="S3.p1.1.m1.1.1.2">absent</csymbol><apply id="S3.p1.1.m1.1.1.3.cmml" xref="S3.p1.1.m1.1.1.3"><times id="S3.p1.1.m1.1.1.3.1.cmml" xref="S3.p1.1.m1.1.1.3.1"></times><cn id="S3.p1.1.m1.1.1.3.2.cmml" type="integer" xref="S3.p1.1.m1.1.1.3.2">514</cn><ci id="S3.p1.1.m1.1.1.3.3.cmml" xref="S3.p1.1.m1.1.1.3.3">K</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">\approx 514\mathrm{K}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.1.m1.1d">â‰ˆ 514 roman_K</annotation></semantics></math> scientific documents (titles and abstracts) paired with author-assigned keyphrases in the broader domain of computer science.
We investigate the effectiveness of our domain adaptation method across three distinct scientific domains: Natural Language Processing (<span class="ltx_text ltx_font_typewriter" id="S3.p1.3.1">nlp</span>), Astrophysics (<span class="ltx_text ltx_font_typewriter" id="S3.p1.3.2">astro</span>), and Paleontology (<span class="ltx_text ltx_font_typewriter" id="S3.p1.3.3">paleo</span>).
These domains differ with increasing distances from the initial KP20k dataset, with <span class="ltx_text ltx_font_typewriter" id="S3.p1.3.4">nlp</span> being the closest and <span class="ltx_text ltx_font_typewriter" id="S3.p1.3.5">paleo</span> standing as the furthest.
This section gives details about the data we use for each domain, presents the statistics of the resulting synthetic in-domain data we generate, and describes how we collect<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Detailed information on the sources can be found inÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#A1.SS4" title="A.4 Sources used for collecting test data â€£ Appendix A Appendices â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_tag">A.4</span></a>.</span></span></span> annotated test data to validate the usefulness of our method for domain adaptation.
We set our method parameters (step 2 in Â§<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S2.SSx2" title="Step 2: Selecting Silver-Standard Keyphrases â€£ 2 Method â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_tag">2</span></a>) based on their observed values in the validation split of KP20k, specifically, <math alttext="\lambda_{x}=0.85" class="ltx_Math" display="inline" id="S3.p1.2.m2.1"><semantics id="S3.p1.2.m2.1a"><mrow id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml"><msub id="S3.p1.2.m2.1.1.2" xref="S3.p1.2.m2.1.1.2.cmml"><mi id="S3.p1.2.m2.1.1.2.2" xref="S3.p1.2.m2.1.1.2.2.cmml">Î»</mi><mi id="S3.p1.2.m2.1.1.2.3" xref="S3.p1.2.m2.1.1.2.3.cmml">x</mi></msub><mo id="S3.p1.2.m2.1.1.1" xref="S3.p1.2.m2.1.1.1.cmml">=</mo><mn id="S3.p1.2.m2.1.1.3" xref="S3.p1.2.m2.1.1.3.cmml">0.85</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><apply id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1"><eq id="S3.p1.2.m2.1.1.1.cmml" xref="S3.p1.2.m2.1.1.1"></eq><apply id="S3.p1.2.m2.1.1.2.cmml" xref="S3.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.2.1.cmml" xref="S3.p1.2.m2.1.1.2">subscript</csymbol><ci id="S3.p1.2.m2.1.1.2.2.cmml" xref="S3.p1.2.m2.1.1.2.2">ğœ†</ci><ci id="S3.p1.2.m2.1.1.2.3.cmml" xref="S3.p1.2.m2.1.1.2.3">ğ‘¥</ci></apply><cn id="S3.p1.2.m2.1.1.3.cmml" type="float" xref="S3.p1.2.m2.1.1.3">0.85</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">\lambda_{x}=0.85</annotation><annotation encoding="application/x-llamapun" id="S3.p1.2.m2.1d">italic_Î» start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT = 0.85</annotation></semantics></math> and <math alttext="\lambda_{r}=0.75" class="ltx_Math" display="inline" id="S3.p1.3.m3.1"><semantics id="S3.p1.3.m3.1a"><mrow id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml"><msub id="S3.p1.3.m3.1.1.2" xref="S3.p1.3.m3.1.1.2.cmml"><mi id="S3.p1.3.m3.1.1.2.2" xref="S3.p1.3.m3.1.1.2.2.cmml">Î»</mi><mi id="S3.p1.3.m3.1.1.2.3" xref="S3.p1.3.m3.1.1.2.3.cmml">r</mi></msub><mo id="S3.p1.3.m3.1.1.1" xref="S3.p1.3.m3.1.1.1.cmml">=</mo><mn id="S3.p1.3.m3.1.1.3" xref="S3.p1.3.m3.1.1.3.cmml">0.75</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.1b"><apply id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1"><eq id="S3.p1.3.m3.1.1.1.cmml" xref="S3.p1.3.m3.1.1.1"></eq><apply id="S3.p1.3.m3.1.1.2.cmml" xref="S3.p1.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.p1.3.m3.1.1.2.1.cmml" xref="S3.p1.3.m3.1.1.2">subscript</csymbol><ci id="S3.p1.3.m3.1.1.2.2.cmml" xref="S3.p1.3.m3.1.1.2.2">ğœ†</ci><ci id="S3.p1.3.m3.1.1.2.3.cmml" xref="S3.p1.3.m3.1.1.2.3">ğ‘Ÿ</ci></apply><cn id="S3.p1.3.m3.1.1.3.cmml" type="float" xref="S3.p1.3.m3.1.1.3">0.75</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.1c">\lambda_{r}=0.75</annotation><annotation encoding="application/x-llamapun" id="S3.p1.3.m3.1d">italic_Î» start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT = 0.75</annotation></semantics></math>.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Natural Language Processing  (<span class="ltx_text ltx_font_typewriter" id="S3.SS1.1.1">nlp</span>)</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">For the <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p1.1.1">nlp</span> domain, we use the ACL Anthology Sentence Corpus<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://kmcs.nii.ac.jp/resource/AASC/" title="">https://kmcs.nii.ac.jp/resource/AASC/</a></span></span></span> that contains the sentences of 65â€‰662 papers from the ACL Anthology up until 2022.
For quality reasons, we only consider sentences from papers published in the last 20 years (2003 and upwards) and occurring within the introduction and related work sections.
From these, we extracted 260â€‰324 citation contexts with the restriction that they include at least one citation to a paper within the ACL Anthology.
For each cited paper, we applied our method to extract silver-standard keyphrases from citation contexts, resulting in a confidence-ordered list of 6â€‰199 synthetic samples.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">As most papers in the ACL Anthology do not provide keyphrases, we mainly relied on NLP-related conferences and journals to compile the test data for the <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p2.1.1">nlp</span> domain.
More precisely, we manually collected a set of 212 documents (title and abstract) with author-assigned keyphrases from a variety of sources (e.g.Â LREC, SIGIR, CIKM).</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Astrophysics  (<span class="ltx_text ltx_font_typewriter" id="S3.SS2.1.1">astro</span>)</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">For the <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p1.1.1">astro</span> domain, we use the unarXive 2022 datasetÂ <cite class="ltx_cite ltx_citemacro_cite">Saier etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib45" title="">2023</a>)</cite> that contains 1.9M full-text papers from arXiv.
We selected the subset of 198â€‰349 papers that belong to the Astrophysics category (astro-ph), and extracted 133â€‰320 citation contexts originating from the introduction sections of these papers.
Applying our method for each cited paper produces in a confidence-ordered list of 2â€‰680 synthetic samples.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">For the <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p2.1.1">astro</span> test data, we manually collected a set of 255 documents (title and abstract) paired with author-assigned<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>It should be noted that controlled vocabularies are also used to index papers in astrophysics, but these are not considered in our study.</span></span></span> keyphrases from both arXiv and journals.
To ensure topic diversity, we uniformly selected 20 documents from each astrophysics sub-category in arXiv and retrieved documents from broader-scope journals.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Paleontology  (<span class="ltx_text ltx_font_typewriter" id="S3.SS3.1.1">paleo</span>)</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">To the best of our knowledge, there is no dataset of scientific papers available for the <span class="ltx_text ltx_font_typewriter" id="S3.SS3.p1.1.1">paleo</span> domain.
Thus, we collected 12â€‰353 open- or free-access papers in PDF format from a wide range of journals in Paleontology.<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>See TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#A1.T13" title="Table 13 â€£ A.4 Sources used for collecting test data â€£ Appendix A Appendices â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_tag">13</span></a> in AppendixÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#A1" title="Appendix A Appendices â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_tag">A</span></a> for the detailed sources.</span></span></span>
We use GROBID<span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/kermitt2/grobid" title="">https://github.com/kermitt2/grobid</a></span></span></span> for extracting the full-text from PDF papers, detecting inline citations and parsing bibliography, as it was shown to outperform other freely available toolsÂ <cite class="ltx_cite ltx_citemacro_cite">Meuschke etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib41" title="">2023</a>); Rohatgi etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib44" title="">2023</a>)</cite>.
From the XML output of GROBID, we extracted 53â€‰133 citation contexts from the introductory parts of the papers (i.e.Â â€œ<span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.2">Introduction</span>â€, â€œ<span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.3">Materials and Methodsâ€™</span>â€™ and â€œ<span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.4">Geological Settings</span>â€).
With such a small collection, applying our method yields too few synthetic samples.
To generate sufficient data for fine-tuning keyphrase generation models, we adjusted the threshold for candidate relevance (i.e.Â <math alttext="\lambda_{r}=0.75\rightarrow 0.60" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><mrow id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><msub id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml"><mi id="S3.SS3.p1.1.m1.1.1.2.2" xref="S3.SS3.p1.1.m1.1.1.2.2.cmml">Î»</mi><mi id="S3.SS3.p1.1.m1.1.1.2.3" xref="S3.SS3.p1.1.m1.1.1.2.3.cmml">r</mi></msub><mo id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml">=</mo><mn id="S3.SS3.p1.1.m1.1.1.4" xref="S3.SS3.p1.1.m1.1.1.4.cmml">0.75</mn><mo id="S3.SS3.p1.1.m1.1.1.5" stretchy="false" xref="S3.SS3.p1.1.m1.1.1.5.cmml">â†’</mo><mn id="S3.SS3.p1.1.m1.1.1.6" xref="S3.SS3.p1.1.m1.1.1.6.cmml">0.60</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><and id="S3.SS3.p1.1.m1.1.1a.cmml" xref="S3.SS3.p1.1.m1.1.1"></and><apply id="S3.SS3.p1.1.m1.1.1b.cmml" xref="S3.SS3.p1.1.m1.1.1"><eq id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3"></eq><apply id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.2.1.cmml" xref="S3.SS3.p1.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.2.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2.2">ğœ†</ci><ci id="S3.SS3.p1.1.m1.1.1.2.3.cmml" xref="S3.SS3.p1.1.m1.1.1.2.3">ğ‘Ÿ</ci></apply><cn id="S3.SS3.p1.1.m1.1.1.4.cmml" type="float" xref="S3.SS3.p1.1.m1.1.1.4">0.75</cn></apply><apply id="S3.SS3.p1.1.m1.1.1c.cmml" xref="S3.SS3.p1.1.m1.1.1"><ci id="S3.SS3.p1.1.m1.1.1.5.cmml" xref="S3.SS3.p1.1.m1.1.1.5">â†’</ci><share href="https://arxiv.org/html/2409.13266v2#S3.SS3.p1.1.m1.1.1.4.cmml" id="S3.SS3.p1.1.m1.1.1d.cmml" xref="S3.SS3.p1.1.m1.1.1"></share><cn id="S3.SS3.p1.1.m1.1.1.6.cmml" type="float" xref="S3.SS3.p1.1.m1.1.1.6">0.60</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">\lambda_{r}=0.75\rightarrow 0.60</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">italic_Î» start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT = 0.75 â†’ 0.60</annotation></semantics></math>) and queried the Semantic Scholar API<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.semanticscholar.org/" title="">https://www.semanticscholar.org/</a></span></span></span> to include cited papers not present in our collection.
These modifications resulted in our method generating a confidence-ordered list of 2â€‰806 synthetic samples.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">For the <span class="ltx_text ltx_font_typewriter" id="S3.SS3.p2.1.1">paleo</span> test data, we manually collected a set of 244 documents, each paired with author-assigned keyphrases, sourced from approximately 10 different journals that encompass a wide spectrum of palaeontological topics (e.g.Â palaeogeography, palaeoecology or stratigraphy).</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Statistics and Analysis</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">In this section, our aim is to deepen our understanding of the characteristics of the datasets we use for each domain and to assess how the compiled test data aligns with existing test datasets.</p>
</div>
<div class="ltx_para" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.1">TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S3.T1" title="Table 1 â€£ 3.4 Statistics and Analysis â€£ 3 Datasets â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_tag">1</span></a> summarizes the statistics of the datasets for each domain we apply our method on.
There is a noticeable diversity in characteristics across the datasets, with <span class="ltx_text ltx_font_typewriter" id="S3.SS4.p2.1.1">nlp</span> showing the highest citation rate per document and <span class="ltx_text ltx_font_typewriter" id="S3.SS4.p2.1.2">paleo</span> the lowest.
We suspect there are two reasons for this.
First, papers within the <span class="ltx_text ltx_font_typewriter" id="S3.SS4.p2.1.3">nlp</span> domain seem to garner higher average citations compared to papers in the other two domains.
Second, papers from <span class="ltx_text ltx_font_typewriter" id="S3.SS4.p2.1.4">paleo</span> tend to cite works from both related domains (e.g.Â Biology, Geology) and sources outside our collection of gathered papers.
Conversely, the average number of candidate keyphrases per document â€”those found in the title, abstract, or citation contextsâ€” remains stable across the domains (<math alttext="\approx" class="ltx_Math" display="inline" id="S3.SS4.p2.1.m1.1"><semantics id="S3.SS4.p2.1.m1.1a"><mo id="S3.SS4.p2.1.m1.1.1" xref="S3.SS4.p2.1.m1.1.1.cmml">â‰ˆ</mo><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.1.m1.1b"><approx id="S3.SS4.p2.1.m1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.1.m1.1c">\approx</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.1.m1.1d">â‰ˆ</annotation></semantics></math>80 candidates).</p>
</div>
<figure class="ltx_table" id="S3.T1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T1.1" style="width:433.6pt;height:364.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(93.9pt,-78.9pt) scale(1.76387480772408,1.76387480772408) ;">
<table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1">
<tr class="ltx_tr" id="S3.T1.1.1.2">
<td class="ltx_td ltx_border_r ltx_border_tt" id="S3.T1.1.1.2.1"></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S3.T1.1.1.2.2"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S3.T1.1.1.2.2.1">nlp</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S3.T1.1.1.2.3"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S3.T1.1.1.2.3.1">astro</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S3.T1.1.1.2.4"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S3.T1.1.1.2.4.1">paleo</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.3">
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.1.1.3.1"># documents</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T1.1.1.3.2">65â€‰662</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T1.1.1.3.3">198â€‰349</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T1.1.1.3.4">12â€‰353</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.4">
<td class="ltx_td ltx_align_right ltx_border_r" id="S3.T1.1.1.4.1"># citation contexts</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.1.4.2">260â€‰324</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.1.4.3">133â€‰320</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.1.4.4">53â€‰133</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.5">
<td class="ltx_td ltx_align_right ltx_border_r" id="S3.T1.1.1.5.1"># cited doc</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.1.5.2">32â€‰448</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.1.5.3">20â€‰436</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.1.5.4">3â€‰252</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.6">
<td class="ltx_td ltx_align_right ltx_border_r" id="S3.T1.1.1.6.1">cites / doc</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.1.6.2">6.0</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.1.6.3">3.2</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.1.6.4">1.6</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.7">
<td class="ltx_td ltx_align_right ltx_border_r" id="S3.T1.1.1.7.1">phrases / cited doc</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.1.7.2">72.9</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.1.7.3">76.8</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.1.7.4">87.4</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.1">
<td class="ltx_td ltx_nopad ltx_align_center ltx_border_t" colspan="4" id="S3.T1.1.1.1.1"><svg height="29.35" overflow="visible" version="1.1" width="300"><g transform="translate(0,29.35) scale(1,-1)"><path d="M 0,29.35 300,0" stroke="#000000" stroke-width="0.4"></path><g class="ltx_svg_fog" transform="translate(0,0)"><g transform="translate(0,13.84) scale(1, -1)"><foreignobject height="13.84" overflow="visible" width="118.08">
<span class="ltx_inline-block" id="S3.T1.1.1.1.1.pic1.1.1">
<span class="ltx_inline-block ltx_align_left" id="S3.T1.1.1.1.1.pic1.1.1.1">
<span class="ltx_p" id="S3.T1.1.1.1.1.pic1.1.1.1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.T1.1.1.1.1.pic1.1.1.1.1.1" style="position:relative; bottom:-4.3pt;"><math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T1.1.1.1.1.pic1.1.1.1.1.1.m1.1"><semantics id="S3.T1.1.1.1.1.pic1.1.1.1.1.1.m1.1a"><mo id="S3.T1.1.1.1.1.pic1.1.1.1.1.1.m1.1.1" stretchy="false" xref="S3.T1.1.1.1.1.pic1.1.1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.1.pic1.1.1.1.1.1.m1.1b"><ci id="S3.T1.1.1.1.1.pic1.1.1.1.1.1.m1.1.1.cmml" xref="S3.T1.1.1.1.1.pic1.1.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.1.pic1.1.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.1.1.1.1.pic1.1.1.1.1.1.m1.1d">â†“</annotation></semantics></math> <span class="ltx_text ltx_font_typewriter" id="S3.T1.1.1.1.1.pic1.1.1.1.1.1.1">silk</span> (top-1K - all)</span></span>
</span>
</span></foreignobject></g></g><g class="ltx_svg_fog" transform="translate(239.12,13.84)"><g transform="translate(0,15.51) scale(1, -1)"><foreignobject height="15.51" overflow="visible" width="60.88">
<span class="ltx_inline-block" id="S3.T1.1.1.1.1.pic1.2.1">
<span class="ltx_inline-block ltx_align_right" id="S3.T1.1.1.1.1.pic1.2.1.1">
<span class="ltx_p" id="S3.T1.1.1.1.1.pic1.2.1.1.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.T1.1.1.1.1.pic1.2.1.1.1.1" style="position:relative; bottom:4.3pt;">datasets <math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T1.1.1.1.1.pic1.2.1.1.1.1.m1.1"><semantics id="S3.T1.1.1.1.1.pic1.2.1.1.1.1.m1.1a"><mo id="S3.T1.1.1.1.1.pic1.2.1.1.1.1.m1.1.1" stretchy="false" xref="S3.T1.1.1.1.1.pic1.2.1.1.1.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.1.pic1.2.1.1.1.1.m1.1b"><ci id="S3.T1.1.1.1.1.pic1.2.1.1.1.1.m1.1.1.cmml" xref="S3.T1.1.1.1.1.pic1.2.1.1.1.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.1.pic1.2.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S3.T1.1.1.1.1.pic1.2.1.1.1.1.m1.1d">â†‘</annotation></semantics></math></span></span>
</span>
</span></foreignobject></g></g></g></svg></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.8">
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T1.1.1.8.1">doc len. (tokens)</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T1.1.1.8.2">149</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T1.1.1.8.3">202</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T1.1.1.8.4">278</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.9">
<td class="ltx_td ltx_align_right ltx_border_r" id="S3.T1.1.1.9.1">keyphrase / doc</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.1.9.2">3.9 3.6</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.1.9.3">3.6 3.5</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.1.9.4">3.6 3.6</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.10">
<td class="ltx_td ltx_align_right ltx_border_r" id="S3.T1.1.1.10.1">keyphrase len.</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.1.10.2">1.8</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.1.10.3">1.9</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.1.10.4">1.6</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.11">
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_r" id="S3.T1.1.1.11.1">% abs keyphrases</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T1.1.1.11.2">23.7 21.8</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T1.1.1.11.3">16.7 14.8</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T1.1.1.11.4">4.3 5.3</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Statistics for the datasets and the top-1K synthetics samples generated by <span class="ltx_text ltx_font_typewriter" id="S3.T1.3.1">silk</span> for each domain.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS4.p3">
<p class="ltx_p" id="S3.SS4.p3.1">Upon examining the synthetic fine-tuning data generated by our method (restricted to the top-1K), we observe that <span class="ltx_text ltx_font_typewriter" id="S3.SS4.p3.1.1">nlp</span> documents are nearly half the length of those in the <span class="ltx_text ltx_font_typewriter" id="S3.SS4.p3.1.2">paleo</span> domain, while <span class="ltx_text ltx_font_typewriter" id="S3.SS4.p3.1.3">astro</span> documents fall in-between.
These differences in length directly impact the ratio of absent keyphrases<span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>We follow the definition ofÂ <cite class="ltx_cite ltx_citemacro_cite">Boudin and Gallina (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib6" title="">2021</a>)</cite> and consider keyphrases that do not match contiguous sequences of (stemmed) words in the source document as absent.</span></span></span>, decreasing from 24% to below 10%.
These numbers further decrease when computed beyond the top-1K, as the number of citation contexts declines and, consequently, as the pool of absent keyphrase candidates reduces.
Constraints we introduced for selecting the optimal subset of phrases allow for an average of about 4 silver keyphrases per document, predominantly unigrams and bigrams, which is in line with both past observations and the test data we compiled (see TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S3.T2" title="Table 2 â€£ 3.4 Statistics and Analysis â€£ 3 Datasets â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_tag">2</span></a>).</p>
</div>
<div class="ltx_para" id="S3.SS4.p4">
<p class="ltx_p" id="S3.SS4.p4.3">To analyze the disparities between the domains we selected, and also how they depart from KP20k (initial domain) and from other existing test datasets for keyphrase generation, we compare the main statistics of their test splits in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S3.T2" title="Table 2 â€£ 3.4 Statistics and Analysis â€£ 3 Datasets â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_tag">2</span></a>.
Here, we include three additional datasets, InspecÂ <cite class="ltx_cite ltx_citemacro_cite">Hulth (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib25" title="">2003</a>)</cite>, NUSÂ <cite class="ltx_cite ltx_citemacro_cite">Nguyen and Kan (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib43" title="">2007</a>)</cite> and SemEval-2010Â <cite class="ltx_cite ltx_citemacro_cite">Kim etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib28" title="">2010</a>)</cite>, that are composed of scientific abstracts in the computer science domain.
Together with KP20k, these are likely the most commonly-used datasets for evaluating keyphrase generation models.
Overall, we observe many similarities between KP20k and the test data we collected for each domain, whether in terms of the number of gold keyphrases (<math alttext="\approx" class="ltx_Math" display="inline" id="S3.SS4.p4.1.m1.1"><semantics id="S3.SS4.p4.1.m1.1a"><mo id="S3.SS4.p4.1.m1.1.1" xref="S3.SS4.p4.1.m1.1.1.cmml">â‰ˆ</mo><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.1.m1.1b"><approx id="S3.SS4.p4.1.m1.1.1.cmml" xref="S3.SS4.p4.1.m1.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.1.m1.1c">\approx</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p4.1.m1.1d">â‰ˆ</annotation></semantics></math>5 per document), their average length (<math alttext="\approx" class="ltx_Math" display="inline" id="S3.SS4.p4.2.m2.1"><semantics id="S3.SS4.p4.2.m2.1a"><mo id="S3.SS4.p4.2.m2.1.1" xref="S3.SS4.p4.2.m2.1.1.cmml">â‰ˆ</mo><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.2.m2.1b"><approx id="S3.SS4.p4.2.m2.1.1.cmml" xref="S3.SS4.p4.2.m2.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.2.m2.1c">\approx</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p4.2.m2.1d">â‰ˆ</annotation></semantics></math>2 tokens) or the ratio of absent keyphrases (<math alttext="\approx" class="ltx_Math" display="inline" id="S3.SS4.p4.3.m3.1"><semantics id="S3.SS4.p4.3.m3.1a"><mo id="S3.SS4.p4.3.m3.1.1" xref="S3.SS4.p4.3.m3.1.1.cmml">â‰ˆ</mo><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.3.m3.1b"><approx id="S3.SS4.p4.3.m3.1.1.cmml" xref="S3.SS4.p4.3.m3.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.3.m3.1c">\approx</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p4.3.m3.1d">â‰ˆ</annotation></semantics></math>40%).
This suggests a uniform trend in author-assigned keyphrases across scientific domains, which should facilitate generalization for keyphrase generation models.
It should be noted that higher number of gold keyphrases in NUS, SemEval-2010 and Inspec stems from their distinct annotation processes, with the former two combining author- and reader-assigned keyphrases and the latter relying on professional indexers.
Comparing the sizes of our domain-specific test data with those of the test splits in existing datasets shows that they are on a similar scale.</p>
</div>
<figure class="ltx_table" id="S3.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T2.1" style="width:212.5pt;height:131pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-10.6pt,6.5pt) scale(0.909635942802733,0.909635942802733) ;">
<table class="ltx_tabular ltx_align_middle" id="S3.T2.1.1">
<tr class="ltx_tr" id="S3.T2.1.1.1">
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S3.T2.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.1.1">Dataset</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S3.T2.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.2.1">#doc</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S3.T2.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.3.1">len<sub class="ltx_sub" id="S3.T2.1.1.1.3.1.1">doc</sub></span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S3.T2.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.4.1">#kp</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S3.T2.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.5.1">len<sub class="ltx_sub" id="S3.T2.1.1.1.5.1.1">kp</sub></span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S3.T2.1.1.1.6"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.6.1">%abs</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.2">
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T2.1.1.2.1">KP20k</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T2.1.1.2.2">20K</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T2.1.1.2.3">176</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T2.1.1.2.4">5.2</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T2.1.1.2.5">2.0</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T2.1.1.2.6">41.5</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.3">
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T2.1.1.3.1"><span class="ltx_text ltx_font_typewriter" id="S3.T2.1.1.3.1.1">nlp</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T2.1.1.3.2">212</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T2.1.1.3.3">210</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T2.1.1.3.4">4.1</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T2.1.1.3.5">2.0</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T2.1.1.3.6">36.7</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.4">
<td class="ltx_td ltx_align_right ltx_border_r" id="S3.T2.1.1.4.1"><span class="ltx_text ltx_font_typewriter" id="S3.T2.1.1.4.1.1">astro</span></td>
<td class="ltx_td ltx_align_right" id="S3.T2.1.1.4.2">255</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S3.T2.1.1.4.3">224</td>
<td class="ltx_td ltx_align_right" id="S3.T2.1.1.4.4">4.9</td>
<td class="ltx_td ltx_align_right" id="S3.T2.1.1.4.5">2.1</td>
<td class="ltx_td ltx_align_right" id="S3.T2.1.1.4.6">47.8</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.5">
<td class="ltx_td ltx_align_right ltx_border_r" id="S3.T2.1.1.5.1"><span class="ltx_text ltx_font_typewriter" id="S3.T2.1.1.5.1.1">paleo</span></td>
<td class="ltx_td ltx_align_right" id="S3.T2.1.1.5.2">244</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S3.T2.1.1.5.3">255</td>
<td class="ltx_td ltx_align_right" id="S3.T2.1.1.5.4">5.5</td>
<td class="ltx_td ltx_align_right" id="S3.T2.1.1.5.5">1.5</td>
<td class="ltx_td ltx_align_right" id="S3.T2.1.1.5.6">38.6</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.6">
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T2.1.1.6.1">Inspec</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T2.1.1.6.2">500</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S3.T2.1.1.6.3">134</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T2.1.1.6.4">9.8</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T2.1.1.6.5">2.3</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T2.1.1.6.6">21.4</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.7">
<td class="ltx_td ltx_align_right ltx_border_r" id="S3.T2.1.1.7.1">NUS</td>
<td class="ltx_td ltx_align_right" id="S3.T2.1.1.7.2">211</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S3.T2.1.1.7.3">182</td>
<td class="ltx_td ltx_align_right" id="S3.T2.1.1.7.4">11.7</td>
<td class="ltx_td ltx_align_right" id="S3.T2.1.1.7.5">2.1</td>
<td class="ltx_td ltx_align_right" id="S3.T2.1.1.7.6">45.2</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.8">
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_r" id="S3.T2.1.1.8.1">SemEval</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T2.1.1.8.2">100</td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_r" id="S3.T2.1.1.8.3">203</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T2.1.1.8.4">14.5</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T2.1.1.8.5">2.1</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T2.1.1.8.6">60.7</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Statistics for the test data we collected for each domain in comparison with the commonly used test sets for keyphrase generation.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS4.p5">
<p class="ltx_p" id="S3.SS4.p5.1">Lastly, we examine the differences between the domains from a semantic perspective.
FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S3.F2" title="Figure 2 â€£ 3.4 Statistics and Analysis â€£ 3 Datasets â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_tag">2</span></a> shows a t-SNE visualizationÂ <cite class="ltx_cite ltx_citemacro_cite">vanÂ der Maaten and Hinton (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib48" title="">2008</a>)</cite> of the gold keyphrases in the test data that we collected for each domain and those of the KP20k test split.
We clearly discern the different domains within the vector space, roughly dividing it into four clusters.
The most notable overlap occurs between <span class="ltx_text ltx_font_typewriter" id="S3.SS4.p5.1.1">nlp</span> and KP20k (computer science), whereas <span class="ltx_text ltx_font_typewriter" id="S3.SS4.p5.1.2">astro</span> and <span class="ltx_text ltx_font_typewriter" id="S3.SS4.p5.1.3">paleo</span> exhibit clear separation.
These visual insights support our initial assumptions regarding the growing differences of our selected domains from KP20k, with <span class="ltx_text ltx_font_typewriter" id="S3.SS4.p5.1.4">nlp</span> being the closest and <span class="ltx_text ltx_font_typewriter" id="S3.SS4.p5.1.5">paleo</span> standing as the furthest.</p>
</div>
<figure class="ltx_figure" id="S3.F2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.F2.1" style="width:433.6pt;height:250.8pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-37.1pt,21.4pt) scale(0.853955981498019,0.853955981498019) ;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="562" id="S3.F2.1.g1" src="x2.png" width="969"/>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>t-SNE 2-D projections of the gold keyphrases from <math alttext="\bullet" class="ltx_Math" display="inline" id="S3.F2.6.m1.1"><semantics id="S3.F2.6.m1.1b"><mo id="S3.F2.6.m1.1.1" mathcolor="#EE2967" xref="S3.F2.6.m1.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S3.F2.6.m1.1c"><ci id="S3.F2.6.m1.1.1.cmml" xref="S3.F2.6.m1.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.6.m1.1d">\bullet</annotation><annotation encoding="application/x-llamapun" id="S3.F2.6.m1.1e">âˆ™</annotation></semantics></math> KP20k, <math alttext="\bullet" class="ltx_Math" display="inline" id="S3.F2.7.m2.1"><semantics id="S3.F2.7.m2.1b"><mo id="S3.F2.7.m2.1.1" mathcolor="#613F99" xref="S3.F2.7.m2.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S3.F2.7.m2.1c"><ci id="S3.F2.7.m2.1.1.cmml" xref="S3.F2.7.m2.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.7.m2.1d">\bullet</annotation><annotation encoding="application/x-llamapun" id="S3.F2.7.m2.1e">âˆ™</annotation></semantics></math> <span class="ltx_text ltx_font_typewriter" id="S3.F2.13.1">nlp</span>, <math alttext="\bullet" class="ltx_Math" display="inline" id="S3.F2.8.m3.1"><semantics id="S3.F2.8.m3.1b"><mo id="S3.F2.8.m3.1.1" mathcolor="#008B72" xref="S3.F2.8.m3.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S3.F2.8.m3.1c"><ci id="S3.F2.8.m3.1.1.cmml" xref="S3.F2.8.m3.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.8.m3.1d">\bullet</annotation><annotation encoding="application/x-llamapun" id="S3.F2.8.m3.1e">âˆ™</annotation></semantics></math> <span class="ltx_text ltx_font_typewriter" id="S3.F2.14.2">astro</span> and <math alttext="\bullet" class="ltx_Math" display="inline" id="S3.F2.9.m4.1"><semantics id="S3.F2.9.m4.1b"><mo id="S3.F2.9.m4.1.1" mathcolor="#FFD966" xref="S3.F2.9.m4.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S3.F2.9.m4.1c"><ci id="S3.F2.9.m4.1.1.cmml" xref="S3.F2.9.m4.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.9.m4.1d">\bullet</annotation><annotation encoding="application/x-llamapun" id="S3.F2.9.m4.1e">âˆ™</annotation></semantics></math> <span class="ltx_text ltx_font_typewriter" id="S3.F2.15.3">paleo</span>.
We leverage SPECTER to compute the keyphrase embeddings and use the first 500 documents from KP20k for clarity.
</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experimental Settings</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Initial Model</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">We use BARTÂ <cite class="ltx_cite ltx_citemacro_cite">Lewis etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib31" title="">2020</a>)</cite> as our initial pre-trained language model and perform fine-tuning on the KP20k training set for 15 epochs, followingÂ <cite class="ltx_cite ltx_citemacro_cite">Wu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib52" title="">2023</a>)</cite>.
BART was shown to yield state-of-the-art performance in keyphrase generationÂ <cite class="ltx_cite ltx_citemacro_cite">Zhao etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib59" title="">2022</a>); Wu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib53" title="">2022</a>); Meng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib38" title="">2023</a>)</cite>, surpassing other pre-trained language models, such as T5Â <cite class="ltx_cite ltx_citemacro_cite">Wu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib52" title="">2023</a>)</cite>.
Following previous work, we fine-tune BART in a <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p1.1.1">One2Many</span> settingÂ <cite class="ltx_cite ltx_citemacro_citep">(Yuan etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib56" title="">2020</a>)</cite>, that is, given a source text as input, the task is to generate keyphrases as a single sequence of delimiter-separated phrases.
During fine-tuning, gold keyphrases are arranged in the present-absent order which was found to give the best resultsÂ <cite class="ltx_cite ltx_citemacro_cite">Meng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib39" title="">2021</a>)</cite>.
At test time, we use either greedy decoding and let the model generate the most probable keyphrases, or beam search (K=20) and assemble the top-<math alttext="k" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.1"><semantics id="S4.SS1.p1.1.m1.1a"><mi id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><ci id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.1d">italic_k</annotation></semantics></math> keyphrases from all the beams as the model output.
Implementation details and training times are provided in AppendixÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#A1.SS2" title="A.2 Implementation Details â€£ Appendix A Appendices â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_tag">A.2</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Domain Adaptation</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.2">For adapting our fine-tuned BART model to a specific domain, we continue fine-tuning it on the synthetic labeled data generated by <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p1.2.1">silk</span> for 3 epochs.
Specifically, we use the top-<math alttext="N" class="ltx_Math" display="inline" id="S4.SS2.p1.1.m1.1"><semantics id="S4.SS2.p1.1.m1.1a"><mi id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><ci id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.1.m1.1d">italic_N</annotation></semantics></math> most confident silver-labeled examples to further fine-tune BART, creating three gradually adapted models for each domain by varying <math alttext="N\in\{500,1K,2K\}" class="ltx_Math" display="inline" id="S4.SS2.p1.2.m2.3"><semantics id="S4.SS2.p1.2.m2.3a"><mrow id="S4.SS2.p1.2.m2.3.3" xref="S4.SS2.p1.2.m2.3.3.cmml"><mi id="S4.SS2.p1.2.m2.3.3.4" xref="S4.SS2.p1.2.m2.3.3.4.cmml">N</mi><mo id="S4.SS2.p1.2.m2.3.3.3" xref="S4.SS2.p1.2.m2.3.3.3.cmml">âˆˆ</mo><mrow id="S4.SS2.p1.2.m2.3.3.2.2" xref="S4.SS2.p1.2.m2.3.3.2.3.cmml"><mo id="S4.SS2.p1.2.m2.3.3.2.2.3" stretchy="false" xref="S4.SS2.p1.2.m2.3.3.2.3.cmml">{</mo><mn id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml">500</mn><mo id="S4.SS2.p1.2.m2.3.3.2.2.4" xref="S4.SS2.p1.2.m2.3.3.2.3.cmml">,</mo><mrow id="S4.SS2.p1.2.m2.2.2.1.1.1" xref="S4.SS2.p1.2.m2.2.2.1.1.1.cmml"><mn id="S4.SS2.p1.2.m2.2.2.1.1.1.2" xref="S4.SS2.p1.2.m2.2.2.1.1.1.2.cmml">1</mn><mo id="S4.SS2.p1.2.m2.2.2.1.1.1.1" xref="S4.SS2.p1.2.m2.2.2.1.1.1.1.cmml">â¢</mo><mi id="S4.SS2.p1.2.m2.2.2.1.1.1.3" xref="S4.SS2.p1.2.m2.2.2.1.1.1.3.cmml">K</mi></mrow><mo id="S4.SS2.p1.2.m2.3.3.2.2.5" xref="S4.SS2.p1.2.m2.3.3.2.3.cmml">,</mo><mrow id="S4.SS2.p1.2.m2.3.3.2.2.2" xref="S4.SS2.p1.2.m2.3.3.2.2.2.cmml"><mn id="S4.SS2.p1.2.m2.3.3.2.2.2.2" xref="S4.SS2.p1.2.m2.3.3.2.2.2.2.cmml">2</mn><mo id="S4.SS2.p1.2.m2.3.3.2.2.2.1" xref="S4.SS2.p1.2.m2.3.3.2.2.2.1.cmml">â¢</mo><mi id="S4.SS2.p1.2.m2.3.3.2.2.2.3" xref="S4.SS2.p1.2.m2.3.3.2.2.2.3.cmml">K</mi></mrow><mo id="S4.SS2.p1.2.m2.3.3.2.2.6" stretchy="false" xref="S4.SS2.p1.2.m2.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.3b"><apply id="S4.SS2.p1.2.m2.3.3.cmml" xref="S4.SS2.p1.2.m2.3.3"><in id="S4.SS2.p1.2.m2.3.3.3.cmml" xref="S4.SS2.p1.2.m2.3.3.3"></in><ci id="S4.SS2.p1.2.m2.3.3.4.cmml" xref="S4.SS2.p1.2.m2.3.3.4">ğ‘</ci><set id="S4.SS2.p1.2.m2.3.3.2.3.cmml" xref="S4.SS2.p1.2.m2.3.3.2.2"><cn id="S4.SS2.p1.2.m2.1.1.cmml" type="integer" xref="S4.SS2.p1.2.m2.1.1">500</cn><apply id="S4.SS2.p1.2.m2.2.2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.2.2.1.1.1"><times id="S4.SS2.p1.2.m2.2.2.1.1.1.1.cmml" xref="S4.SS2.p1.2.m2.2.2.1.1.1.1"></times><cn id="S4.SS2.p1.2.m2.2.2.1.1.1.2.cmml" type="integer" xref="S4.SS2.p1.2.m2.2.2.1.1.1.2">1</cn><ci id="S4.SS2.p1.2.m2.2.2.1.1.1.3.cmml" xref="S4.SS2.p1.2.m2.2.2.1.1.1.3">ğ¾</ci></apply><apply id="S4.SS2.p1.2.m2.3.3.2.2.2.cmml" xref="S4.SS2.p1.2.m2.3.3.2.2.2"><times id="S4.SS2.p1.2.m2.3.3.2.2.2.1.cmml" xref="S4.SS2.p1.2.m2.3.3.2.2.2.1"></times><cn id="S4.SS2.p1.2.m2.3.3.2.2.2.2.cmml" type="integer" xref="S4.SS2.p1.2.m2.3.3.2.2.2.2">2</cn><ci id="S4.SS2.p1.2.m2.3.3.2.2.2.3.cmml" xref="S4.SS2.p1.2.m2.3.3.2.2.2.3">ğ¾</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.3c">N\in\{500,1K,2K\}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.2.m2.3d">italic_N âˆˆ { 500 , 1 italic_K , 2 italic_K }</annotation></semantics></math>.
We compare the effectiveness of our domain adaptation method with that of the only other unsupervised approach we are aware of, which is self-learningÂ <cite class="ltx_cite ltx_citemacro_cite">Ye and Wang (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib54" title="">2018</a>); Meng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib38" title="">2023</a>)</cite>.
Self-learning consists in using a model to generate pseudo-labels for in-domain documents and then re-train itself on this data.
Here, we use our fine-tuned BART model to generate keyphrases for the same documents as those produced by <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p1.2.2">silk</span>, and further fine-tune it on this self-labeled data for 3 epochs.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Baselines</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">Although the focus of this work is domain adaption, we also provide the results of several baselines as a point of reference.
The first baseline is MultiPartiteRankÂ <cite class="ltx_cite ltx_citemacro_cite">Boudin (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib5" title="">2018</a>)</cite>, an unsupervised method for keyphrase extraction that leverages graph-based ranking and topical information.
Despite being limited to present keyphrases, MultiPartiteRank yields the best results among non deep learning methodsÂ <cite class="ltx_cite ltx_citemacro_cite">Do etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib15" title="">2023</a>)</cite>.
We use the authorâ€™s implementation provided by the <span class="ltx_text ltx_font_typewriter" id="S4.SS3.p1.1.1">pke</span> toolkitÂ <cite class="ltx_cite ltx_citemacro_cite">Boudin (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib4" title="">2016</a>)</cite>.<span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/boudinfl/pke" title="">https://github.com/boudinfl/pke</a></span></span></span>
The second baseline is YakeÂ <cite class="ltx_cite ltx_citemacro_cite">Campos etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib8" title="">2020</a>)</cite>, another unsupervised method for keyphrase extraction that relies on statistical text features.
We use the authorâ€™s implementation.<span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/LIAAD/yake" title="">https://github.com/LIAAD/yake</a></span></span></span>
The third baseline is KeyBARTÂ <cite class="ltx_cite ltx_citemacro_cite">Kulkarni etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib30" title="">2022</a>)</cite> in a zero-shot setting, a task-specific language model trained to learn rich representations of keyphrases.
We use the model weights released by the authors.<span class="ltx_note ltx_role_footnote" id="footnote12"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/bloomberg/KeyBART" title="">https://huggingface.co/bloomberg/KeyBART</a></span></span></span>
The fourth baseline is One2SetÂ <cite class="ltx_cite ltx_citemacro_cite">Ye etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib55" title="">2021</a>)</cite>, a Transformer-based model that uses learned control codes to generate a set of keyphrases.
Trained on KP20k, this model achieves strong performance, often on-par with state-of-the-art modelsÂ <cite class="ltx_cite ltx_citemacro_cite">Wu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib52" title="">2023</a>)</cite>.
We use the model weights released by the authors.<span class="ltx_note ltx_role_footnote" id="footnote13"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/jiacheng-ye/kg_one2set" title="">https://github.com/jiacheng-ye/kg_one2set</a></span></span></span></p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Datasets and Evaluation Metrics</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.8">We use the test split of KP20k for evaluating the initial performance of the models, and our manually collected test sets to assess their in-domain performance.
Detailed statistics for these datasets are presented in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S3.T2" title="Table 2 â€£ 3.4 Statistics and Analysis â€£ 3 Datasets â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_tag">2</span></a>.
Following common practice, we evaluate the performance of the models in terms of <math alttext="F_{1}" class="ltx_Math" display="inline" id="S4.SS4.p1.1.m1.1"><semantics id="S4.SS4.p1.1.m1.1a"><msub id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml"><mi id="S4.SS4.p1.1.m1.1.1.2" xref="S4.SS4.p1.1.m1.1.1.2.cmml">F</mi><mn id="S4.SS4.p1.1.m1.1.1.3" xref="S4.SS4.p1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><apply id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS4.p1.1.m1.1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS4.p1.1.m1.1.1.2.cmml" xref="S4.SS4.p1.1.m1.1.1.2">ğ¹</ci><cn id="S4.SS4.p1.1.m1.1.1.3.cmml" type="integer" xref="S4.SS4.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">F_{1}</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.1.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> score using exact match between gold and predicted keyphrases.
Stemming (Porter stemmer) is applied to reduce the number of mismatches and duplicates are removed.
We compute the scores both at the top-<math alttext="k" class="ltx_Math" display="inline" id="S4.SS4.p1.2.m2.1"><semantics id="S4.SS4.p1.2.m2.1a"><mi id="S4.SS4.p1.2.m2.1.1" xref="S4.SS4.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.2.m2.1b"><ci id="S4.SS4.p1.2.m2.1.1.cmml" xref="S4.SS4.p1.2.m2.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.2.m2.1d">italic_k</annotation></semantics></math> predicted keyphrases with <math alttext="k\in{5,10}" class="ltx_Math" display="inline" id="S4.SS4.p1.3.m3.2"><semantics id="S4.SS4.p1.3.m3.2a"><mrow id="S4.SS4.p1.3.m3.2.3" xref="S4.SS4.p1.3.m3.2.3.cmml"><mi id="S4.SS4.p1.3.m3.2.3.2" xref="S4.SS4.p1.3.m3.2.3.2.cmml">k</mi><mo id="S4.SS4.p1.3.m3.2.3.1" xref="S4.SS4.p1.3.m3.2.3.1.cmml">âˆˆ</mo><mrow id="S4.SS4.p1.3.m3.2.3.3.2" xref="S4.SS4.p1.3.m3.2.3.3.1.cmml"><mn id="S4.SS4.p1.3.m3.1.1" xref="S4.SS4.p1.3.m3.1.1.cmml">5</mn><mo id="S4.SS4.p1.3.m3.2.3.3.2.1" xref="S4.SS4.p1.3.m3.2.3.3.1.cmml">,</mo><mn id="S4.SS4.p1.3.m3.2.2" xref="S4.SS4.p1.3.m3.2.2.cmml">10</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.3.m3.2b"><apply id="S4.SS4.p1.3.m3.2.3.cmml" xref="S4.SS4.p1.3.m3.2.3"><in id="S4.SS4.p1.3.m3.2.3.1.cmml" xref="S4.SS4.p1.3.m3.2.3.1"></in><ci id="S4.SS4.p1.3.m3.2.3.2.cmml" xref="S4.SS4.p1.3.m3.2.3.2">ğ‘˜</ci><list id="S4.SS4.p1.3.m3.2.3.3.1.cmml" xref="S4.SS4.p1.3.m3.2.3.3.2"><cn id="S4.SS4.p1.3.m3.1.1.cmml" type="integer" xref="S4.SS4.p1.3.m3.1.1">5</cn><cn id="S4.SS4.p1.3.m3.2.2.cmml" type="integer" xref="S4.SS4.p1.3.m3.2.2">10</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.3.m3.2c">k\in{5,10}</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.3.m3.2d">italic_k âˆˆ 5 , 10</annotation></semantics></math>, and at the number <math alttext="M" class="ltx_Math" display="inline" id="S4.SS4.p1.4.m4.1"><semantics id="S4.SS4.p1.4.m4.1a"><mi id="S4.SS4.p1.4.m4.1.1" xref="S4.SS4.p1.4.m4.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.4.m4.1b"><ci id="S4.SS4.p1.4.m4.1.1.cmml" xref="S4.SS4.p1.4.m4.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.4.m4.1c">M</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.4.m4.1d">italic_M</annotation></semantics></math> of keyphrases predicted by the models as proposed inÂ <cite class="ltx_cite ltx_citemacro_cite">Yuan etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib56" title="">2020</a>)</cite>.
For <math alttext="F_{1}@k" class="ltx_Math" display="inline" id="S4.SS4.p1.5.m5.1"><semantics id="S4.SS4.p1.5.m5.1a"><mrow id="S4.SS4.p1.5.m5.1.1" xref="S4.SS4.p1.5.m5.1.1.cmml"><msub id="S4.SS4.p1.5.m5.1.1.2" xref="S4.SS4.p1.5.m5.1.1.2.cmml"><mi id="S4.SS4.p1.5.m5.1.1.2.2" xref="S4.SS4.p1.5.m5.1.1.2.2.cmml">F</mi><mn id="S4.SS4.p1.5.m5.1.1.2.3" xref="S4.SS4.p1.5.m5.1.1.2.3.cmml">1</mn></msub><mo id="S4.SS4.p1.5.m5.1.1.1" xref="S4.SS4.p1.5.m5.1.1.1.cmml">â¢</mo><mi id="S4.SS4.p1.5.m5.1.1.3" mathvariant="normal" xref="S4.SS4.p1.5.m5.1.1.3.cmml">@</mi><mo id="S4.SS4.p1.5.m5.1.1.1a" xref="S4.SS4.p1.5.m5.1.1.1.cmml">â¢</mo><mi id="S4.SS4.p1.5.m5.1.1.4" xref="S4.SS4.p1.5.m5.1.1.4.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.5.m5.1b"><apply id="S4.SS4.p1.5.m5.1.1.cmml" xref="S4.SS4.p1.5.m5.1.1"><times id="S4.SS4.p1.5.m5.1.1.1.cmml" xref="S4.SS4.p1.5.m5.1.1.1"></times><apply id="S4.SS4.p1.5.m5.1.1.2.cmml" xref="S4.SS4.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="S4.SS4.p1.5.m5.1.1.2.1.cmml" xref="S4.SS4.p1.5.m5.1.1.2">subscript</csymbol><ci id="S4.SS4.p1.5.m5.1.1.2.2.cmml" xref="S4.SS4.p1.5.m5.1.1.2.2">ğ¹</ci><cn id="S4.SS4.p1.5.m5.1.1.2.3.cmml" type="integer" xref="S4.SS4.p1.5.m5.1.1.2.3">1</cn></apply><ci id="S4.SS4.p1.5.m5.1.1.3.cmml" xref="S4.SS4.p1.5.m5.1.1.3">@</ci><ci id="S4.SS4.p1.5.m5.1.1.4.cmml" xref="S4.SS4.p1.5.m5.1.1.4">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.5.m5.1c">F_{1}@k</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.5.m5.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ italic_k</annotation></semantics></math> scores, if the number of predicted keyphrases is below <math alttext="k" class="ltx_Math" display="inline" id="S4.SS4.p1.6.m6.1"><semantics id="S4.SS4.p1.6.m6.1a"><mi id="S4.SS4.p1.6.m6.1.1" xref="S4.SS4.p1.6.m6.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.6.m6.1b"><ci id="S4.SS4.p1.6.m6.1.1.cmml" xref="S4.SS4.p1.6.m6.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.6.m6.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.6.m6.1d">italic_k</annotation></semantics></math>, we append incorrect predictions until it reaches exactly <math alttext="k" class="ltx_Math" display="inline" id="S4.SS4.p1.7.m7.1"><semantics id="S4.SS4.p1.7.m7.1a"><mi id="S4.SS4.p1.7.m7.1.1" xref="S4.SS4.p1.7.m7.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.7.m7.1b"><ci id="S4.SS4.p1.7.m7.1.1.cmml" xref="S4.SS4.p1.7.m7.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.7.m7.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.7.m7.1d">italic_k</annotation></semantics></math> keyphrases.
We also report scores for present and absent keyphrases separately to get more insights about the extractive and generative capabilities of the models.
We compute the Studentâ€™s paired t-test to assess the statistical significance of our results at <math alttext="p&lt;0.05" class="ltx_Math" display="inline" id="S4.SS4.p1.8.m8.1"><semantics id="S4.SS4.p1.8.m8.1a"><mrow id="S4.SS4.p1.8.m8.1.1" xref="S4.SS4.p1.8.m8.1.1.cmml"><mi id="S4.SS4.p1.8.m8.1.1.2" xref="S4.SS4.p1.8.m8.1.1.2.cmml">p</mi><mo id="S4.SS4.p1.8.m8.1.1.1" xref="S4.SS4.p1.8.m8.1.1.1.cmml">&lt;</mo><mn id="S4.SS4.p1.8.m8.1.1.3" xref="S4.SS4.p1.8.m8.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.8.m8.1b"><apply id="S4.SS4.p1.8.m8.1.1.cmml" xref="S4.SS4.p1.8.m8.1.1"><lt id="S4.SS4.p1.8.m8.1.1.1.cmml" xref="S4.SS4.p1.8.m8.1.1.1"></lt><ci id="S4.SS4.p1.8.m8.1.1.2.cmml" xref="S4.SS4.p1.8.m8.1.1.2">ğ‘</ci><cn id="S4.SS4.p1.8.m8.1.1.3.cmml" type="float" xref="S4.SS4.p1.8.m8.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.8.m8.1c">p&lt;0.05</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.8.m8.1d">italic_p &lt; 0.05</annotation></semantics></math>.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Performance of Models on KP20k</h3>
<div class="ltx_para" id="S4.SS5.p1">
<p class="ltx_p" id="S4.SS5.p1.4">TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S4.T3" title="Table 3 â€£ 4.5 Performance of Models on KP20k â€£ 4 Experimental Settings â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_tag">3</span></a> presents the results of our fine-tuned BART model (hereafter denoted as BART-FT) and the baselines on the test split of KP20k.
It should be noted that MultiPartiteRank and Yake cannot be assessed using <math alttext="F_{1}@M" class="ltx_Math" display="inline" id="S4.SS5.p1.1.m1.1"><semantics id="S4.SS5.p1.1.m1.1a"><mrow id="S4.SS5.p1.1.m1.1.1" xref="S4.SS5.p1.1.m1.1.1.cmml"><msub id="S4.SS5.p1.1.m1.1.1.2" xref="S4.SS5.p1.1.m1.1.1.2.cmml"><mi id="S4.SS5.p1.1.m1.1.1.2.2" xref="S4.SS5.p1.1.m1.1.1.2.2.cmml">F</mi><mn id="S4.SS5.p1.1.m1.1.1.2.3" xref="S4.SS5.p1.1.m1.1.1.2.3.cmml">1</mn></msub><mo id="S4.SS5.p1.1.m1.1.1.1" xref="S4.SS5.p1.1.m1.1.1.1.cmml">â¢</mo><mi id="S4.SS5.p1.1.m1.1.1.3" mathvariant="normal" xref="S4.SS5.p1.1.m1.1.1.3.cmml">@</mi><mo id="S4.SS5.p1.1.m1.1.1.1a" xref="S4.SS5.p1.1.m1.1.1.1.cmml">â¢</mo><mi id="S4.SS5.p1.1.m1.1.1.4" xref="S4.SS5.p1.1.m1.1.1.4.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.1.m1.1b"><apply id="S4.SS5.p1.1.m1.1.1.cmml" xref="S4.SS5.p1.1.m1.1.1"><times id="S4.SS5.p1.1.m1.1.1.1.cmml" xref="S4.SS5.p1.1.m1.1.1.1"></times><apply id="S4.SS5.p1.1.m1.1.1.2.cmml" xref="S4.SS5.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.SS5.p1.1.m1.1.1.2.1.cmml" xref="S4.SS5.p1.1.m1.1.1.2">subscript</csymbol><ci id="S4.SS5.p1.1.m1.1.1.2.2.cmml" xref="S4.SS5.p1.1.m1.1.1.2.2">ğ¹</ci><cn id="S4.SS5.p1.1.m1.1.1.2.3.cmml" type="integer" xref="S4.SS5.p1.1.m1.1.1.2.3">1</cn></apply><ci id="S4.SS5.p1.1.m1.1.1.3.cmml" xref="S4.SS5.p1.1.m1.1.1.3">@</ci><ci id="S4.SS5.p1.1.m1.1.1.4.cmml" xref="S4.SS5.p1.1.m1.1.1.4">ğ‘€</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.1.m1.1c">F_{1}@M</annotation><annotation encoding="application/x-llamapun" id="S4.SS5.p1.1.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ italic_M</annotation></semantics></math> as they require setting a top-<math alttext="k" class="ltx_Math" display="inline" id="S4.SS5.p1.2.m2.1"><semantics id="S4.SS5.p1.2.m2.1a"><mi id="S4.SS5.p1.2.m2.1.1" xref="S4.SS5.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.2.m2.1b"><ci id="S4.SS5.p1.2.m2.1.1.cmml" xref="S4.SS5.p1.2.m2.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS5.p1.2.m2.1d">italic_k</annotation></semantics></math> parameter, and that One2Set cannot be assessed using <math alttext="F_{1}@10" class="ltx_Math" display="inline" id="S4.SS5.p1.3.m3.1"><semantics id="S4.SS5.p1.3.m3.1a"><mrow id="S4.SS5.p1.3.m3.1.1" xref="S4.SS5.p1.3.m3.1.1.cmml"><msub id="S4.SS5.p1.3.m3.1.1.2" xref="S4.SS5.p1.3.m3.1.1.2.cmml"><mi id="S4.SS5.p1.3.m3.1.1.2.2" xref="S4.SS5.p1.3.m3.1.1.2.2.cmml">F</mi><mn id="S4.SS5.p1.3.m3.1.1.2.3" xref="S4.SS5.p1.3.m3.1.1.2.3.cmml">1</mn></msub><mo id="S4.SS5.p1.3.m3.1.1.1" xref="S4.SS5.p1.3.m3.1.1.1.cmml">â¢</mo><mi id="S4.SS5.p1.3.m3.1.1.3" mathvariant="normal" xref="S4.SS5.p1.3.m3.1.1.3.cmml">@</mi><mo id="S4.SS5.p1.3.m3.1.1.1a" xref="S4.SS5.p1.3.m3.1.1.1.cmml">â¢</mo><mn id="S4.SS5.p1.3.m3.1.1.4" xref="S4.SS5.p1.3.m3.1.1.4.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.3.m3.1b"><apply id="S4.SS5.p1.3.m3.1.1.cmml" xref="S4.SS5.p1.3.m3.1.1"><times id="S4.SS5.p1.3.m3.1.1.1.cmml" xref="S4.SS5.p1.3.m3.1.1.1"></times><apply id="S4.SS5.p1.3.m3.1.1.2.cmml" xref="S4.SS5.p1.3.m3.1.1.2"><csymbol cd="ambiguous" id="S4.SS5.p1.3.m3.1.1.2.1.cmml" xref="S4.SS5.p1.3.m3.1.1.2">subscript</csymbol><ci id="S4.SS5.p1.3.m3.1.1.2.2.cmml" xref="S4.SS5.p1.3.m3.1.1.2.2">ğ¹</ci><cn id="S4.SS5.p1.3.m3.1.1.2.3.cmml" type="integer" xref="S4.SS5.p1.3.m3.1.1.2.3">1</cn></apply><ci id="S4.SS5.p1.3.m3.1.1.3.cmml" xref="S4.SS5.p1.3.m3.1.1.3">@</ci><cn id="S4.SS5.p1.3.m3.1.1.4.cmml" type="integer" xref="S4.SS5.p1.3.m3.1.1.4">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.3.m3.1c">F_{1}@10</annotation><annotation encoding="application/x-llamapun" id="S4.SS5.p1.3.m3.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ 10</annotation></semantics></math> since it only outputs the most probable keyphrases (<math alttext="\approx" class="ltx_Math" display="inline" id="S4.SS5.p1.4.m4.1"><semantics id="S4.SS5.p1.4.m4.1a"><mo id="S4.SS5.p1.4.m4.1.1" xref="S4.SS5.p1.4.m4.1.1.cmml">â‰ˆ</mo><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.4.m4.1b"><approx id="S4.SS5.p1.4.m4.1.1.cmml" xref="S4.SS5.p1.4.m4.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.4.m4.1c">\approx</annotation><annotation encoding="application/x-llamapun" id="S4.SS5.p1.4.m4.1d">â‰ˆ</annotation></semantics></math>7 per document).
Overall, BART-FT demonstrates superior performance, significantly outperforming the baselines for both all and only the present keyphrases.
We observe that One2Set achieves the best scores for the absent keyphrases, confirming previous findingsÂ <cite class="ltx_cite ltx_citemacro_cite">Wu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib52" title="">2023</a>)</cite>.
In light of these results, we argue that BART-FT is a strong model for keyphrase generation, providing a solid basis for the application of our domain adaptation method.</p>
</div>
<figure class="ltx_table" id="S4.T3">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T3.11" style="width:433.6pt;height:181.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(66.4pt,-27.8pt) scale(1.44155421142865,1.44155421142865) ;">
<table class="ltx_tabular ltx_align_middle" id="S4.T3.11.11">
<tr class="ltx_tr" id="S4.T3.3.3.3">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S4.T3.3.3.3.4" rowspan="2"><span class="ltx_text ltx_font_bold" id="S4.T3.3.3.3.4.1">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S4.T3.1.1.1.1"><math alttext="F_{1}@M" class="ltx_Math" display="inline" id="S4.T3.1.1.1.1.m1.1"><semantics id="S4.T3.1.1.1.1.m1.1a"><mrow id="S4.T3.1.1.1.1.m1.1.1" xref="S4.T3.1.1.1.1.m1.1.1.cmml"><msub id="S4.T3.1.1.1.1.m1.1.1.2" xref="S4.T3.1.1.1.1.m1.1.1.2.cmml"><mi id="S4.T3.1.1.1.1.m1.1.1.2.2" xref="S4.T3.1.1.1.1.m1.1.1.2.2.cmml">F</mi><mn id="S4.T3.1.1.1.1.m1.1.1.2.3" xref="S4.T3.1.1.1.1.m1.1.1.2.3.cmml">1</mn></msub><mo id="S4.T3.1.1.1.1.m1.1.1.1" xref="S4.T3.1.1.1.1.m1.1.1.1.cmml">â¢</mo><mi id="S4.T3.1.1.1.1.m1.1.1.3" mathvariant="normal" xref="S4.T3.1.1.1.1.m1.1.1.3.cmml">@</mi><mo id="S4.T3.1.1.1.1.m1.1.1.1a" xref="S4.T3.1.1.1.1.m1.1.1.1.cmml">â¢</mo><mi id="S4.T3.1.1.1.1.m1.1.1.4" xref="S4.T3.1.1.1.1.m1.1.1.4.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.1.m1.1b"><apply id="S4.T3.1.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.1.m1.1.1"><times id="S4.T3.1.1.1.1.m1.1.1.1.cmml" xref="S4.T3.1.1.1.1.m1.1.1.1"></times><apply id="S4.T3.1.1.1.1.m1.1.1.2.cmml" xref="S4.T3.1.1.1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.T3.1.1.1.1.m1.1.1.2.1.cmml" xref="S4.T3.1.1.1.1.m1.1.1.2">subscript</csymbol><ci id="S4.T3.1.1.1.1.m1.1.1.2.2.cmml" xref="S4.T3.1.1.1.1.m1.1.1.2.2">ğ¹</ci><cn id="S4.T3.1.1.1.1.m1.1.1.2.3.cmml" type="integer" xref="S4.T3.1.1.1.1.m1.1.1.2.3">1</cn></apply><ci id="S4.T3.1.1.1.1.m1.1.1.3.cmml" xref="S4.T3.1.1.1.1.m1.1.1.3">@</ci><ci id="S4.T3.1.1.1.1.m1.1.1.4.cmml" xref="S4.T3.1.1.1.1.m1.1.1.4">ğ‘€</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.1.m1.1c">F_{1}@M</annotation><annotation encoding="application/x-llamapun" id="S4.T3.1.1.1.1.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ italic_M</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S4.T3.2.2.2.2"><math alttext="F_{1}@5" class="ltx_Math" display="inline" id="S4.T3.2.2.2.2.m1.1"><semantics id="S4.T3.2.2.2.2.m1.1a"><mrow id="S4.T3.2.2.2.2.m1.1.1" xref="S4.T3.2.2.2.2.m1.1.1.cmml"><msub id="S4.T3.2.2.2.2.m1.1.1.2" xref="S4.T3.2.2.2.2.m1.1.1.2.cmml"><mi id="S4.T3.2.2.2.2.m1.1.1.2.2" xref="S4.T3.2.2.2.2.m1.1.1.2.2.cmml">F</mi><mn id="S4.T3.2.2.2.2.m1.1.1.2.3" xref="S4.T3.2.2.2.2.m1.1.1.2.3.cmml">1</mn></msub><mo id="S4.T3.2.2.2.2.m1.1.1.1" xref="S4.T3.2.2.2.2.m1.1.1.1.cmml">â¢</mo><mi id="S4.T3.2.2.2.2.m1.1.1.3" mathvariant="normal" xref="S4.T3.2.2.2.2.m1.1.1.3.cmml">@</mi><mo id="S4.T3.2.2.2.2.m1.1.1.1a" xref="S4.T3.2.2.2.2.m1.1.1.1.cmml">â¢</mo><mn id="S4.T3.2.2.2.2.m1.1.1.4" xref="S4.T3.2.2.2.2.m1.1.1.4.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.2.m1.1b"><apply id="S4.T3.2.2.2.2.m1.1.1.cmml" xref="S4.T3.2.2.2.2.m1.1.1"><times id="S4.T3.2.2.2.2.m1.1.1.1.cmml" xref="S4.T3.2.2.2.2.m1.1.1.1"></times><apply id="S4.T3.2.2.2.2.m1.1.1.2.cmml" xref="S4.T3.2.2.2.2.m1.1.1.2"><csymbol cd="ambiguous" id="S4.T3.2.2.2.2.m1.1.1.2.1.cmml" xref="S4.T3.2.2.2.2.m1.1.1.2">subscript</csymbol><ci id="S4.T3.2.2.2.2.m1.1.1.2.2.cmml" xref="S4.T3.2.2.2.2.m1.1.1.2.2">ğ¹</ci><cn id="S4.T3.2.2.2.2.m1.1.1.2.3.cmml" type="integer" xref="S4.T3.2.2.2.2.m1.1.1.2.3">1</cn></apply><ci id="S4.T3.2.2.2.2.m1.1.1.3.cmml" xref="S4.T3.2.2.2.2.m1.1.1.3">@</ci><cn id="S4.T3.2.2.2.2.m1.1.1.4.cmml" type="integer" xref="S4.T3.2.2.2.2.m1.1.1.4">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.2.m1.1c">F_{1}@5</annotation><annotation encoding="application/x-llamapun" id="S4.T3.2.2.2.2.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ 5</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S4.T3.3.3.3.3"><math alttext="F_{1}@10" class="ltx_Math" display="inline" id="S4.T3.3.3.3.3.m1.1"><semantics id="S4.T3.3.3.3.3.m1.1a"><mrow id="S4.T3.3.3.3.3.m1.1.1" xref="S4.T3.3.3.3.3.m1.1.1.cmml"><msub id="S4.T3.3.3.3.3.m1.1.1.2" xref="S4.T3.3.3.3.3.m1.1.1.2.cmml"><mi id="S4.T3.3.3.3.3.m1.1.1.2.2" xref="S4.T3.3.3.3.3.m1.1.1.2.2.cmml">F</mi><mn id="S4.T3.3.3.3.3.m1.1.1.2.3" xref="S4.T3.3.3.3.3.m1.1.1.2.3.cmml">1</mn></msub><mo id="S4.T3.3.3.3.3.m1.1.1.1" xref="S4.T3.3.3.3.3.m1.1.1.1.cmml">â¢</mo><mi id="S4.T3.3.3.3.3.m1.1.1.3" mathvariant="normal" xref="S4.T3.3.3.3.3.m1.1.1.3.cmml">@</mi><mo id="S4.T3.3.3.3.3.m1.1.1.1a" xref="S4.T3.3.3.3.3.m1.1.1.1.cmml">â¢</mo><mn id="S4.T3.3.3.3.3.m1.1.1.4" xref="S4.T3.3.3.3.3.m1.1.1.4.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.3.m1.1b"><apply id="S4.T3.3.3.3.3.m1.1.1.cmml" xref="S4.T3.3.3.3.3.m1.1.1"><times id="S4.T3.3.3.3.3.m1.1.1.1.cmml" xref="S4.T3.3.3.3.3.m1.1.1.1"></times><apply id="S4.T3.3.3.3.3.m1.1.1.2.cmml" xref="S4.T3.3.3.3.3.m1.1.1.2"><csymbol cd="ambiguous" id="S4.T3.3.3.3.3.m1.1.1.2.1.cmml" xref="S4.T3.3.3.3.3.m1.1.1.2">subscript</csymbol><ci id="S4.T3.3.3.3.3.m1.1.1.2.2.cmml" xref="S4.T3.3.3.3.3.m1.1.1.2.2">ğ¹</ci><cn id="S4.T3.3.3.3.3.m1.1.1.2.3.cmml" type="integer" xref="S4.T3.3.3.3.3.m1.1.1.2.3">1</cn></apply><ci id="S4.T3.3.3.3.3.m1.1.1.3.cmml" xref="S4.T3.3.3.3.3.m1.1.1.3">@</ci><cn id="S4.T3.3.3.3.3.m1.1.1.4.cmml" type="integer" xref="S4.T3.3.3.3.3.m1.1.1.4">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.3.3.m1.1c">F_{1}@10</annotation><annotation encoding="application/x-llamapun" id="S4.T3.3.3.3.3.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ 10</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T3.11.11.12">
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.11.11.12.1">all</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S4.T3.11.11.12.2">pres</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S4.T3.11.11.12.3">abs</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.11.11.12.4">all</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S4.T3.11.11.12.5">pres</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S4.T3.11.11.12.6">abs</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.11.11.12.7">all</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S4.T3.11.11.12.8">pres</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S4.T3.11.11.12.9">abs</td>
</tr>
<tr class="ltx_tr" id="S4.T3.11.11.13">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T3.11.11.13.1">MPRank</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="S4.T3.11.11.13.2">-</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.11.11.13.3">14.8</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S4.T3.11.11.13.4">18.7</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S4.T3.11.11.13.5">-</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.11.11.13.6">13.7</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S4.T3.11.11.13.7">16.2</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S4.T3.11.11.13.8">-</td>
</tr>
<tr class="ltx_tr" id="S4.T3.11.11.14">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T3.11.11.14.1">YAKE</td>
<td class="ltx_td ltx_align_center" colspan="3" id="S4.T3.11.11.14.2">-</td>
<td class="ltx_td ltx_align_right" id="S4.T3.11.11.14.3">14.5</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S4.T3.11.11.14.4">18.5</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S4.T3.11.11.14.5">-</td>
<td class="ltx_td ltx_align_right" id="S4.T3.11.11.14.6">14.6</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S4.T3.11.11.14.7">17.4</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S4.T3.11.11.14.8">-</td>
</tr>
<tr class="ltx_tr" id="S4.T3.11.11.15">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T3.11.11.15.1">KeyBART</td>
<td class="ltx_td ltx_align_right" id="S4.T3.11.11.15.2">11.4</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S4.T3.11.11.15.3">16.4</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S4.T3.11.11.15.4">1.6</td>
<td class="ltx_td ltx_align_right" id="S4.T3.11.11.15.5">11.9</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S4.T3.11.11.15.6">17.4</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S4.T3.11.11.15.7">1.9</td>
<td class="ltx_td ltx_align_right" id="S4.T3.11.11.15.8">11.0</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S4.T3.11.11.15.9">15.3</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S4.T3.11.11.15.10">1.7</td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.4.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T3.4.4.4.2">One2Set</td>
<td class="ltx_td ltx_align_right" id="S4.T3.4.4.4.3">23.2</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S4.T3.4.4.4.4">35.1</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S4.T3.4.4.4.1">5.5<sup class="ltx_sup" id="S4.T3.4.4.4.1.1"><span class="ltx_text ltx_font_italic" id="S4.T3.4.4.4.1.1.1">â€ </span></sup>
</td>
<td class="ltx_td ltx_align_right" id="S4.T3.4.4.4.5">23.5</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S4.T3.4.4.4.6">29.9</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S4.T3.4.4.4.7">4.2</td>
<td class="ltx_td ltx_align_center" colspan="3" id="S4.T3.4.4.4.8">-</td>
</tr>
<tr class="ltx_tr" id="S4.T3.11.11.11">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S4.T3.11.11.11.8">BART-FT</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T3.5.5.5.1">28.7<sup class="ltx_sup" id="S4.T3.5.5.5.1.1"><span class="ltx_text ltx_font_italic" id="S4.T3.5.5.5.1.1.1">â€ </span></sup>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" id="S4.T3.6.6.6.2">37.3<sup class="ltx_sup" id="S4.T3.6.6.6.2.1"><span class="ltx_text ltx_font_italic" id="S4.T3.6.6.6.2.1.1">â€ </span></sup>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" id="S4.T3.11.11.11.9">2.4</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T3.7.7.7.3">28.0<sup class="ltx_sup" id="S4.T3.7.7.7.3.1"><span class="ltx_text ltx_font_italic" id="S4.T3.7.7.7.3.1.1">â€ </span></sup>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" id="S4.T3.8.8.8.4">35.5<sup class="ltx_sup" id="S4.T3.8.8.8.4.1"><span class="ltx_text ltx_font_italic" id="S4.T3.8.8.8.4.1.1">â€ </span></sup>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" id="S4.T3.9.9.9.5">5.9<sup class="ltx_sup" id="S4.T3.9.9.9.5.1"><span class="ltx_text ltx_font_italic" id="S4.T3.9.9.9.5.1.1">â€ </span></sup>
</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T3.10.10.10.6">25.4<sup class="ltx_sup" id="S4.T3.10.10.10.6.1"><span class="ltx_text ltx_font_italic" id="S4.T3.10.10.10.6.1.1">â€ </span></sup>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" id="S4.T3.11.11.11.7">29.2<sup class="ltx_sup" id="S4.T3.11.11.11.7.1"><span class="ltx_text ltx_font_italic" id="S4.T3.11.11.11.7.1.1">â€ </span></sup>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" id="S4.T3.11.11.11.10">5.8</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Performance comparison of our fine-tuned BART model and baseline models on the KP20k test set, with <math alttext="\dagger" class="ltx_Math" display="inline" id="S4.T3.13.m1.1"><semantics id="S4.T3.13.m1.1b"><mo id="S4.T3.13.m1.1.1" xref="S4.T3.13.m1.1.1.cmml">â€ </mo><annotation-xml encoding="MathML-Content" id="S4.T3.13.m1.1c"><ci id="S4.T3.13.m1.1.1.cmml" xref="S4.T3.13.m1.1.1">â€ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.13.m1.1d">\dagger</annotation><annotation encoding="application/x-llamapun" id="S4.T3.13.m1.1e">â€ </annotation></semantics></math> indicating statistical significance. Scores for present and absent keyphrases separately are reported.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results</h2>
<figure class="ltx_table" id="S5.T4">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T4.16">
<tr class="ltx_tr" id="S5.T4.16.17">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T4.16.17.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S5.T4.16.17.1.1">Model</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt" id="S5.T4.16.17.2" rowspan="2"><span class="ltx_text ltx_font_bold" id="S5.T4.16.17.2.1">FT</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S5.T4.16.17.3"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S5.T4.16.17.3.1">nlp</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S5.T4.16.17.4"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S5.T4.16.17.4.1">astro</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S5.T4.16.17.5"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S5.T4.16.17.5.1">paleo</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.9.9">
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.1.1.1"><math alttext="F_{1}@M" class="ltx_Math" display="inline" id="S5.T4.1.1.1.m1.1"><semantics id="S5.T4.1.1.1.m1.1a"><mrow id="S5.T4.1.1.1.m1.1.1" xref="S5.T4.1.1.1.m1.1.1.cmml"><msub id="S5.T4.1.1.1.m1.1.1.2" xref="S5.T4.1.1.1.m1.1.1.2.cmml"><mi id="S5.T4.1.1.1.m1.1.1.2.2" xref="S5.T4.1.1.1.m1.1.1.2.2.cmml">F</mi><mn id="S5.T4.1.1.1.m1.1.1.2.3" xref="S5.T4.1.1.1.m1.1.1.2.3.cmml">1</mn></msub><mo id="S5.T4.1.1.1.m1.1.1.1" xref="S5.T4.1.1.1.m1.1.1.1.cmml">â¢</mo><mi id="S5.T4.1.1.1.m1.1.1.3" mathvariant="normal" xref="S5.T4.1.1.1.m1.1.1.3.cmml">@</mi><mo id="S5.T4.1.1.1.m1.1.1.1a" xref="S5.T4.1.1.1.m1.1.1.1.cmml">â¢</mo><mi id="S5.T4.1.1.1.m1.1.1.4" xref="S5.T4.1.1.1.m1.1.1.4.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.1.1.1.m1.1b"><apply id="S5.T4.1.1.1.m1.1.1.cmml" xref="S5.T4.1.1.1.m1.1.1"><times id="S5.T4.1.1.1.m1.1.1.1.cmml" xref="S5.T4.1.1.1.m1.1.1.1"></times><apply id="S5.T4.1.1.1.m1.1.1.2.cmml" xref="S5.T4.1.1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S5.T4.1.1.1.m1.1.1.2.1.cmml" xref="S5.T4.1.1.1.m1.1.1.2">subscript</csymbol><ci id="S5.T4.1.1.1.m1.1.1.2.2.cmml" xref="S5.T4.1.1.1.m1.1.1.2.2">ğ¹</ci><cn id="S5.T4.1.1.1.m1.1.1.2.3.cmml" type="integer" xref="S5.T4.1.1.1.m1.1.1.2.3">1</cn></apply><ci id="S5.T4.1.1.1.m1.1.1.3.cmml" xref="S5.T4.1.1.1.m1.1.1.3">@</ci><ci id="S5.T4.1.1.1.m1.1.1.4.cmml" xref="S5.T4.1.1.1.m1.1.1.4">ğ‘€</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.1.1.1.m1.1c">F_{1}@M</annotation><annotation encoding="application/x-llamapun" id="S5.T4.1.1.1.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ italic_M</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.2.2.2"><math alttext="F_{1}@5" class="ltx_Math" display="inline" id="S5.T4.2.2.2.m1.1"><semantics id="S5.T4.2.2.2.m1.1a"><mrow id="S5.T4.2.2.2.m1.1.1" xref="S5.T4.2.2.2.m1.1.1.cmml"><msub id="S5.T4.2.2.2.m1.1.1.2" xref="S5.T4.2.2.2.m1.1.1.2.cmml"><mi id="S5.T4.2.2.2.m1.1.1.2.2" xref="S5.T4.2.2.2.m1.1.1.2.2.cmml">F</mi><mn id="S5.T4.2.2.2.m1.1.1.2.3" xref="S5.T4.2.2.2.m1.1.1.2.3.cmml">1</mn></msub><mo id="S5.T4.2.2.2.m1.1.1.1" xref="S5.T4.2.2.2.m1.1.1.1.cmml">â¢</mo><mi id="S5.T4.2.2.2.m1.1.1.3" mathvariant="normal" xref="S5.T4.2.2.2.m1.1.1.3.cmml">@</mi><mo id="S5.T4.2.2.2.m1.1.1.1a" xref="S5.T4.2.2.2.m1.1.1.1.cmml">â¢</mo><mn id="S5.T4.2.2.2.m1.1.1.4" xref="S5.T4.2.2.2.m1.1.1.4.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.2.2.2.m1.1b"><apply id="S5.T4.2.2.2.m1.1.1.cmml" xref="S5.T4.2.2.2.m1.1.1"><times id="S5.T4.2.2.2.m1.1.1.1.cmml" xref="S5.T4.2.2.2.m1.1.1.1"></times><apply id="S5.T4.2.2.2.m1.1.1.2.cmml" xref="S5.T4.2.2.2.m1.1.1.2"><csymbol cd="ambiguous" id="S5.T4.2.2.2.m1.1.1.2.1.cmml" xref="S5.T4.2.2.2.m1.1.1.2">subscript</csymbol><ci id="S5.T4.2.2.2.m1.1.1.2.2.cmml" xref="S5.T4.2.2.2.m1.1.1.2.2">ğ¹</ci><cn id="S5.T4.2.2.2.m1.1.1.2.3.cmml" type="integer" xref="S5.T4.2.2.2.m1.1.1.2.3">1</cn></apply><ci id="S5.T4.2.2.2.m1.1.1.3.cmml" xref="S5.T4.2.2.2.m1.1.1.3">@</ci><cn id="S5.T4.2.2.2.m1.1.1.4.cmml" type="integer" xref="S5.T4.2.2.2.m1.1.1.4">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.2.2.2.m1.1c">F_{1}@5</annotation><annotation encoding="application/x-llamapun" id="S5.T4.2.2.2.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ 5</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S5.T4.3.3.3"><math alttext="F_{1}@10" class="ltx_Math" display="inline" id="S5.T4.3.3.3.m1.1"><semantics id="S5.T4.3.3.3.m1.1a"><mrow id="S5.T4.3.3.3.m1.1.1" xref="S5.T4.3.3.3.m1.1.1.cmml"><msub id="S5.T4.3.3.3.m1.1.1.2" xref="S5.T4.3.3.3.m1.1.1.2.cmml"><mi id="S5.T4.3.3.3.m1.1.1.2.2" xref="S5.T4.3.3.3.m1.1.1.2.2.cmml">F</mi><mn id="S5.T4.3.3.3.m1.1.1.2.3" xref="S5.T4.3.3.3.m1.1.1.2.3.cmml">1</mn></msub><mo id="S5.T4.3.3.3.m1.1.1.1" xref="S5.T4.3.3.3.m1.1.1.1.cmml">â¢</mo><mi id="S5.T4.3.3.3.m1.1.1.3" mathvariant="normal" xref="S5.T4.3.3.3.m1.1.1.3.cmml">@</mi><mo id="S5.T4.3.3.3.m1.1.1.1a" xref="S5.T4.3.3.3.m1.1.1.1.cmml">â¢</mo><mn id="S5.T4.3.3.3.m1.1.1.4" xref="S5.T4.3.3.3.m1.1.1.4.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.3.3.3.m1.1b"><apply id="S5.T4.3.3.3.m1.1.1.cmml" xref="S5.T4.3.3.3.m1.1.1"><times id="S5.T4.3.3.3.m1.1.1.1.cmml" xref="S5.T4.3.3.3.m1.1.1.1"></times><apply id="S5.T4.3.3.3.m1.1.1.2.cmml" xref="S5.T4.3.3.3.m1.1.1.2"><csymbol cd="ambiguous" id="S5.T4.3.3.3.m1.1.1.2.1.cmml" xref="S5.T4.3.3.3.m1.1.1.2">subscript</csymbol><ci id="S5.T4.3.3.3.m1.1.1.2.2.cmml" xref="S5.T4.3.3.3.m1.1.1.2.2">ğ¹</ci><cn id="S5.T4.3.3.3.m1.1.1.2.3.cmml" type="integer" xref="S5.T4.3.3.3.m1.1.1.2.3">1</cn></apply><ci id="S5.T4.3.3.3.m1.1.1.3.cmml" xref="S5.T4.3.3.3.m1.1.1.3">@</ci><cn id="S5.T4.3.3.3.m1.1.1.4.cmml" type="integer" xref="S5.T4.3.3.3.m1.1.1.4">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.3.3.3.m1.1c">F_{1}@10</annotation><annotation encoding="application/x-llamapun" id="S5.T4.3.3.3.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ 10</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.4.4.4"><math alttext="F_{1}@M" class="ltx_Math" display="inline" id="S5.T4.4.4.4.m1.1"><semantics id="S5.T4.4.4.4.m1.1a"><mrow id="S5.T4.4.4.4.m1.1.1" xref="S5.T4.4.4.4.m1.1.1.cmml"><msub id="S5.T4.4.4.4.m1.1.1.2" xref="S5.T4.4.4.4.m1.1.1.2.cmml"><mi id="S5.T4.4.4.4.m1.1.1.2.2" xref="S5.T4.4.4.4.m1.1.1.2.2.cmml">F</mi><mn id="S5.T4.4.4.4.m1.1.1.2.3" xref="S5.T4.4.4.4.m1.1.1.2.3.cmml">1</mn></msub><mo id="S5.T4.4.4.4.m1.1.1.1" xref="S5.T4.4.4.4.m1.1.1.1.cmml">â¢</mo><mi id="S5.T4.4.4.4.m1.1.1.3" mathvariant="normal" xref="S5.T4.4.4.4.m1.1.1.3.cmml">@</mi><mo id="S5.T4.4.4.4.m1.1.1.1a" xref="S5.T4.4.4.4.m1.1.1.1.cmml">â¢</mo><mi id="S5.T4.4.4.4.m1.1.1.4" xref="S5.T4.4.4.4.m1.1.1.4.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.4.4.4.m1.1b"><apply id="S5.T4.4.4.4.m1.1.1.cmml" xref="S5.T4.4.4.4.m1.1.1"><times id="S5.T4.4.4.4.m1.1.1.1.cmml" xref="S5.T4.4.4.4.m1.1.1.1"></times><apply id="S5.T4.4.4.4.m1.1.1.2.cmml" xref="S5.T4.4.4.4.m1.1.1.2"><csymbol cd="ambiguous" id="S5.T4.4.4.4.m1.1.1.2.1.cmml" xref="S5.T4.4.4.4.m1.1.1.2">subscript</csymbol><ci id="S5.T4.4.4.4.m1.1.1.2.2.cmml" xref="S5.T4.4.4.4.m1.1.1.2.2">ğ¹</ci><cn id="S5.T4.4.4.4.m1.1.1.2.3.cmml" type="integer" xref="S5.T4.4.4.4.m1.1.1.2.3">1</cn></apply><ci id="S5.T4.4.4.4.m1.1.1.3.cmml" xref="S5.T4.4.4.4.m1.1.1.3">@</ci><ci id="S5.T4.4.4.4.m1.1.1.4.cmml" xref="S5.T4.4.4.4.m1.1.1.4">ğ‘€</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.4.4.4.m1.1c">F_{1}@M</annotation><annotation encoding="application/x-llamapun" id="S5.T4.4.4.4.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ italic_M</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.5.5.5"><math alttext="F_{1}@5" class="ltx_Math" display="inline" id="S5.T4.5.5.5.m1.1"><semantics id="S5.T4.5.5.5.m1.1a"><mrow id="S5.T4.5.5.5.m1.1.1" xref="S5.T4.5.5.5.m1.1.1.cmml"><msub id="S5.T4.5.5.5.m1.1.1.2" xref="S5.T4.5.5.5.m1.1.1.2.cmml"><mi id="S5.T4.5.5.5.m1.1.1.2.2" xref="S5.T4.5.5.5.m1.1.1.2.2.cmml">F</mi><mn id="S5.T4.5.5.5.m1.1.1.2.3" xref="S5.T4.5.5.5.m1.1.1.2.3.cmml">1</mn></msub><mo id="S5.T4.5.5.5.m1.1.1.1" xref="S5.T4.5.5.5.m1.1.1.1.cmml">â¢</mo><mi id="S5.T4.5.5.5.m1.1.1.3" mathvariant="normal" xref="S5.T4.5.5.5.m1.1.1.3.cmml">@</mi><mo id="S5.T4.5.5.5.m1.1.1.1a" xref="S5.T4.5.5.5.m1.1.1.1.cmml">â¢</mo><mn id="S5.T4.5.5.5.m1.1.1.4" xref="S5.T4.5.5.5.m1.1.1.4.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.5.5.5.m1.1b"><apply id="S5.T4.5.5.5.m1.1.1.cmml" xref="S5.T4.5.5.5.m1.1.1"><times id="S5.T4.5.5.5.m1.1.1.1.cmml" xref="S5.T4.5.5.5.m1.1.1.1"></times><apply id="S5.T4.5.5.5.m1.1.1.2.cmml" xref="S5.T4.5.5.5.m1.1.1.2"><csymbol cd="ambiguous" id="S5.T4.5.5.5.m1.1.1.2.1.cmml" xref="S5.T4.5.5.5.m1.1.1.2">subscript</csymbol><ci id="S5.T4.5.5.5.m1.1.1.2.2.cmml" xref="S5.T4.5.5.5.m1.1.1.2.2">ğ¹</ci><cn id="S5.T4.5.5.5.m1.1.1.2.3.cmml" type="integer" xref="S5.T4.5.5.5.m1.1.1.2.3">1</cn></apply><ci id="S5.T4.5.5.5.m1.1.1.3.cmml" xref="S5.T4.5.5.5.m1.1.1.3">@</ci><cn id="S5.T4.5.5.5.m1.1.1.4.cmml" type="integer" xref="S5.T4.5.5.5.m1.1.1.4">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.5.5.5.m1.1c">F_{1}@5</annotation><annotation encoding="application/x-llamapun" id="S5.T4.5.5.5.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ 5</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S5.T4.6.6.6"><math alttext="F_{1}@10" class="ltx_Math" display="inline" id="S5.T4.6.6.6.m1.1"><semantics id="S5.T4.6.6.6.m1.1a"><mrow id="S5.T4.6.6.6.m1.1.1" xref="S5.T4.6.6.6.m1.1.1.cmml"><msub id="S5.T4.6.6.6.m1.1.1.2" xref="S5.T4.6.6.6.m1.1.1.2.cmml"><mi id="S5.T4.6.6.6.m1.1.1.2.2" xref="S5.T4.6.6.6.m1.1.1.2.2.cmml">F</mi><mn id="S5.T4.6.6.6.m1.1.1.2.3" xref="S5.T4.6.6.6.m1.1.1.2.3.cmml">1</mn></msub><mo id="S5.T4.6.6.6.m1.1.1.1" xref="S5.T4.6.6.6.m1.1.1.1.cmml">â¢</mo><mi id="S5.T4.6.6.6.m1.1.1.3" mathvariant="normal" xref="S5.T4.6.6.6.m1.1.1.3.cmml">@</mi><mo id="S5.T4.6.6.6.m1.1.1.1a" xref="S5.T4.6.6.6.m1.1.1.1.cmml">â¢</mo><mn id="S5.T4.6.6.6.m1.1.1.4" xref="S5.T4.6.6.6.m1.1.1.4.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.6.6.6.m1.1b"><apply id="S5.T4.6.6.6.m1.1.1.cmml" xref="S5.T4.6.6.6.m1.1.1"><times id="S5.T4.6.6.6.m1.1.1.1.cmml" xref="S5.T4.6.6.6.m1.1.1.1"></times><apply id="S5.T4.6.6.6.m1.1.1.2.cmml" xref="S5.T4.6.6.6.m1.1.1.2"><csymbol cd="ambiguous" id="S5.T4.6.6.6.m1.1.1.2.1.cmml" xref="S5.T4.6.6.6.m1.1.1.2">subscript</csymbol><ci id="S5.T4.6.6.6.m1.1.1.2.2.cmml" xref="S5.T4.6.6.6.m1.1.1.2.2">ğ¹</ci><cn id="S5.T4.6.6.6.m1.1.1.2.3.cmml" type="integer" xref="S5.T4.6.6.6.m1.1.1.2.3">1</cn></apply><ci id="S5.T4.6.6.6.m1.1.1.3.cmml" xref="S5.T4.6.6.6.m1.1.1.3">@</ci><cn id="S5.T4.6.6.6.m1.1.1.4.cmml" type="integer" xref="S5.T4.6.6.6.m1.1.1.4">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.6.6.6.m1.1c">F_{1}@10</annotation><annotation encoding="application/x-llamapun" id="S5.T4.6.6.6.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ 10</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.7.7.7"><math alttext="F_{1}@M" class="ltx_Math" display="inline" id="S5.T4.7.7.7.m1.1"><semantics id="S5.T4.7.7.7.m1.1a"><mrow id="S5.T4.7.7.7.m1.1.1" xref="S5.T4.7.7.7.m1.1.1.cmml"><msub id="S5.T4.7.7.7.m1.1.1.2" xref="S5.T4.7.7.7.m1.1.1.2.cmml"><mi id="S5.T4.7.7.7.m1.1.1.2.2" xref="S5.T4.7.7.7.m1.1.1.2.2.cmml">F</mi><mn id="S5.T4.7.7.7.m1.1.1.2.3" xref="S5.T4.7.7.7.m1.1.1.2.3.cmml">1</mn></msub><mo id="S5.T4.7.7.7.m1.1.1.1" xref="S5.T4.7.7.7.m1.1.1.1.cmml">â¢</mo><mi id="S5.T4.7.7.7.m1.1.1.3" mathvariant="normal" xref="S5.T4.7.7.7.m1.1.1.3.cmml">@</mi><mo id="S5.T4.7.7.7.m1.1.1.1a" xref="S5.T4.7.7.7.m1.1.1.1.cmml">â¢</mo><mi id="S5.T4.7.7.7.m1.1.1.4" xref="S5.T4.7.7.7.m1.1.1.4.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.7.7.7.m1.1b"><apply id="S5.T4.7.7.7.m1.1.1.cmml" xref="S5.T4.7.7.7.m1.1.1"><times id="S5.T4.7.7.7.m1.1.1.1.cmml" xref="S5.T4.7.7.7.m1.1.1.1"></times><apply id="S5.T4.7.7.7.m1.1.1.2.cmml" xref="S5.T4.7.7.7.m1.1.1.2"><csymbol cd="ambiguous" id="S5.T4.7.7.7.m1.1.1.2.1.cmml" xref="S5.T4.7.7.7.m1.1.1.2">subscript</csymbol><ci id="S5.T4.7.7.7.m1.1.1.2.2.cmml" xref="S5.T4.7.7.7.m1.1.1.2.2">ğ¹</ci><cn id="S5.T4.7.7.7.m1.1.1.2.3.cmml" type="integer" xref="S5.T4.7.7.7.m1.1.1.2.3">1</cn></apply><ci id="S5.T4.7.7.7.m1.1.1.3.cmml" xref="S5.T4.7.7.7.m1.1.1.3">@</ci><ci id="S5.T4.7.7.7.m1.1.1.4.cmml" xref="S5.T4.7.7.7.m1.1.1.4">ğ‘€</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.7.7.7.m1.1c">F_{1}@M</annotation><annotation encoding="application/x-llamapun" id="S5.T4.7.7.7.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ italic_M</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.8.8.8"><math alttext="F_{1}@5" class="ltx_Math" display="inline" id="S5.T4.8.8.8.m1.1"><semantics id="S5.T4.8.8.8.m1.1a"><mrow id="S5.T4.8.8.8.m1.1.1" xref="S5.T4.8.8.8.m1.1.1.cmml"><msub id="S5.T4.8.8.8.m1.1.1.2" xref="S5.T4.8.8.8.m1.1.1.2.cmml"><mi id="S5.T4.8.8.8.m1.1.1.2.2" xref="S5.T4.8.8.8.m1.1.1.2.2.cmml">F</mi><mn id="S5.T4.8.8.8.m1.1.1.2.3" xref="S5.T4.8.8.8.m1.1.1.2.3.cmml">1</mn></msub><mo id="S5.T4.8.8.8.m1.1.1.1" xref="S5.T4.8.8.8.m1.1.1.1.cmml">â¢</mo><mi id="S5.T4.8.8.8.m1.1.1.3" mathvariant="normal" xref="S5.T4.8.8.8.m1.1.1.3.cmml">@</mi><mo id="S5.T4.8.8.8.m1.1.1.1a" xref="S5.T4.8.8.8.m1.1.1.1.cmml">â¢</mo><mn id="S5.T4.8.8.8.m1.1.1.4" xref="S5.T4.8.8.8.m1.1.1.4.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.8.8.8.m1.1b"><apply id="S5.T4.8.8.8.m1.1.1.cmml" xref="S5.T4.8.8.8.m1.1.1"><times id="S5.T4.8.8.8.m1.1.1.1.cmml" xref="S5.T4.8.8.8.m1.1.1.1"></times><apply id="S5.T4.8.8.8.m1.1.1.2.cmml" xref="S5.T4.8.8.8.m1.1.1.2"><csymbol cd="ambiguous" id="S5.T4.8.8.8.m1.1.1.2.1.cmml" xref="S5.T4.8.8.8.m1.1.1.2">subscript</csymbol><ci id="S5.T4.8.8.8.m1.1.1.2.2.cmml" xref="S5.T4.8.8.8.m1.1.1.2.2">ğ¹</ci><cn id="S5.T4.8.8.8.m1.1.1.2.3.cmml" type="integer" xref="S5.T4.8.8.8.m1.1.1.2.3">1</cn></apply><ci id="S5.T4.8.8.8.m1.1.1.3.cmml" xref="S5.T4.8.8.8.m1.1.1.3">@</ci><cn id="S5.T4.8.8.8.m1.1.1.4.cmml" type="integer" xref="S5.T4.8.8.8.m1.1.1.4">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.8.8.8.m1.1c">F_{1}@5</annotation><annotation encoding="application/x-llamapun" id="S5.T4.8.8.8.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ 5</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.9.9.9"><math alttext="F_{1}@10" class="ltx_Math" display="inline" id="S5.T4.9.9.9.m1.1"><semantics id="S5.T4.9.9.9.m1.1a"><mrow id="S5.T4.9.9.9.m1.1.1" xref="S5.T4.9.9.9.m1.1.1.cmml"><msub id="S5.T4.9.9.9.m1.1.1.2" xref="S5.T4.9.9.9.m1.1.1.2.cmml"><mi id="S5.T4.9.9.9.m1.1.1.2.2" xref="S5.T4.9.9.9.m1.1.1.2.2.cmml">F</mi><mn id="S5.T4.9.9.9.m1.1.1.2.3" xref="S5.T4.9.9.9.m1.1.1.2.3.cmml">1</mn></msub><mo id="S5.T4.9.9.9.m1.1.1.1" xref="S5.T4.9.9.9.m1.1.1.1.cmml">â¢</mo><mi id="S5.T4.9.9.9.m1.1.1.3" mathvariant="normal" xref="S5.T4.9.9.9.m1.1.1.3.cmml">@</mi><mo id="S5.T4.9.9.9.m1.1.1.1a" xref="S5.T4.9.9.9.m1.1.1.1.cmml">â¢</mo><mn id="S5.T4.9.9.9.m1.1.1.4" xref="S5.T4.9.9.9.m1.1.1.4.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.9.9.9.m1.1b"><apply id="S5.T4.9.9.9.m1.1.1.cmml" xref="S5.T4.9.9.9.m1.1.1"><times id="S5.T4.9.9.9.m1.1.1.1.cmml" xref="S5.T4.9.9.9.m1.1.1.1"></times><apply id="S5.T4.9.9.9.m1.1.1.2.cmml" xref="S5.T4.9.9.9.m1.1.1.2"><csymbol cd="ambiguous" id="S5.T4.9.9.9.m1.1.1.2.1.cmml" xref="S5.T4.9.9.9.m1.1.1.2">subscript</csymbol><ci id="S5.T4.9.9.9.m1.1.1.2.2.cmml" xref="S5.T4.9.9.9.m1.1.1.2.2">ğ¹</ci><cn id="S5.T4.9.9.9.m1.1.1.2.3.cmml" type="integer" xref="S5.T4.9.9.9.m1.1.1.2.3">1</cn></apply><ci id="S5.T4.9.9.9.m1.1.1.3.cmml" xref="S5.T4.9.9.9.m1.1.1.3">@</ci><cn id="S5.T4.9.9.9.m1.1.1.4.cmml" type="integer" xref="S5.T4.9.9.9.m1.1.1.4">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.9.9.9.m1.1c">F_{1}@10</annotation><annotation encoding="application/x-llamapun" id="S5.T4.9.9.9.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ 10</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S5.T4.16.18">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.16.18.1">MPRank</td>
<td class="ltx_td ltx_nopad_l ltx_border_r ltx_border_t" id="S5.T4.16.18.2"></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.16.18.3">-</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.16.18.4">17.1</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S5.T4.16.18.5">14.3</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.16.18.6">-</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.16.18.7">13.4</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S5.T4.16.18.8">11.7</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.16.18.9">-</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.16.18.10">13.5</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.16.18.11">13.8</td>
</tr>
<tr class="ltx_tr" id="S5.T4.16.19">
<td class="ltx_td ltx_align_left" id="S5.T4.16.19.1">YAKE</td>
<td class="ltx_td ltx_nopad_l ltx_border_r" id="S5.T4.16.19.2"></td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.19.3">-</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.19.4">20.3</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S5.T4.16.19.5">18.1</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.19.6">-</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.19.7">11.5</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S5.T4.16.19.8">11.8</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.19.9">-</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.19.10">9.6</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.19.11">11.3</td>
</tr>
<tr class="ltx_tr" id="S5.T4.16.20">
<td class="ltx_td ltx_align_left" id="S5.T4.16.20.1">KeyBART</td>
<td class="ltx_td ltx_nopad_l ltx_border_r" id="S5.T4.16.20.2"></td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.20.3">11.8</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.20.4">12.8</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S5.T4.16.20.5">11.0</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.20.6">11.8</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.20.7">11.4</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S5.T4.16.20.8">10.6</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.20.9">8.2</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.20.10">8.0</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.20.11">8.8</td>
</tr>
<tr class="ltx_tr" id="S5.T4.16.21">
<td class="ltx_td ltx_align_left" id="S5.T4.16.21.1">One2Set</td>
<td class="ltx_td ltx_nopad_l ltx_border_r" id="S5.T4.16.21.2"></td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.21.3">21.6</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.21.4">24.1</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S5.T4.16.21.5">-</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.21.6">13.2</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.21.7">12.7</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S5.T4.16.21.8">-</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.21.9">13.4</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.21.10">12.1</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.21.11">-</td>
</tr>
<tr class="ltx_tr" id="S5.T4.16.22">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.16.22.1">BART-FT</td>
<td class="ltx_td ltx_nopad_l ltx_border_r ltx_border_t" id="S5.T4.16.22.2"></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.16.22.3">30.8</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.16.22.4">29.8</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S5.T4.16.22.5">24.9</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.16.22.6">19.2</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.16.22.7">18.6</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S5.T4.16.22.8">16.6</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.16.22.9">18.4</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.16.22.10">18.9</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.16.22.11">18.8</td>
</tr>
<tr class="ltx_tr" id="S5.T4.16.23">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.16.23.1">+self-learning</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.16.23.2">500</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.16.23.3">31.2</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.16.23.4">30.0</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S5.T4.16.23.5">24.5</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.16.23.6">19.2</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.16.23.7">19.0</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S5.T4.16.23.8">16.2</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.16.23.9">18.9</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.16.23.10">18.7</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.16.23.11">18.6</td>
</tr>
<tr class="ltx_tr" id="S5.T4.16.24">
<td class="ltx_td" id="S5.T4.16.24.1"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r" id="S5.T4.16.24.2">1K</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.24.3">30.7</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.24.4">30.7</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S5.T4.16.24.5">24.1</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.24.6">19.7</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.24.7">19.6</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S5.T4.16.24.8">16.6</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.24.9">19.5</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.24.10">19.2</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.24.11">18.8</td>
</tr>
<tr class="ltx_tr" id="S5.T4.16.25">
<td class="ltx_td" id="S5.T4.16.25.1"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r" id="S5.T4.16.25.2">2K</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.25.3">30.0</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.25.4">29.2</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S5.T4.16.25.5">24.4</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.25.6">18.4</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.25.7">19.2</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S5.T4.16.25.8">16.4</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.25.9">19.2</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.25.10">19.7</td>
<td class="ltx_td ltx_align_right" id="S5.T4.16.25.11">18.4</td>
</tr>
<tr class="ltx_tr" id="S5.T4.16.26">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T4.16.26.1">+<span class="ltx_text ltx_font_typewriter" id="S5.T4.16.26.1.1">silk</span> (ours)</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.16.26.2">500</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.16.26.3">31.0</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.16.26.4">29.7</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S5.T4.16.26.5"><span class="ltx_text ltx_font_bold" id="S5.T4.16.26.5.1">25.2</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.16.26.6">18.9</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.16.26.7">19.3</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S5.T4.16.26.8">17.1</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.16.26.9">19.0</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.16.26.10">19.3</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T4.16.26.11">19.2</td>
</tr>
<tr class="ltx_tr" id="S5.T4.14.14">
<td class="ltx_td" id="S5.T4.14.14.6"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r" id="S5.T4.14.14.7">1K</td>
<td class="ltx_td ltx_align_right" id="S5.T4.10.10.1"><span class="ltx_text ltx_font_bold" id="S5.T4.10.10.1.1">33.7<sup class="ltx_sup" id="S5.T4.10.10.1.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S5.T4.10.10.1.1.1.1">â€ </span></sup></span></td>
<td class="ltx_td ltx_align_right" id="S5.T4.11.11.2"><span class="ltx_text ltx_font_bold" id="S5.T4.11.11.2.1">32.2<sup class="ltx_sup" id="S5.T4.11.11.2.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S5.T4.11.11.2.1.1.1">â€ </span></sup></span></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S5.T4.14.14.8"><span class="ltx_text ltx_font_bold" id="S5.T4.14.14.8.1">25.2</span></td>
<td class="ltx_td ltx_align_right" id="S5.T4.14.14.9">19.3</td>
<td class="ltx_td ltx_align_right" id="S5.T4.12.12.3">20.5<sup class="ltx_sup" id="S5.T4.12.12.3.1"><span class="ltx_text ltx_font_italic" id="S5.T4.12.12.3.1.1">â€ </span></sup>
</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S5.T4.13.13.4">17.7<sup class="ltx_sup" id="S5.T4.13.13.4.1"><span class="ltx_text ltx_font_italic" id="S5.T4.13.13.4.1.1">â€ </span></sup>
</td>
<td class="ltx_td ltx_align_right" id="S5.T4.14.14.10"><span class="ltx_text ltx_font_bold" id="S5.T4.14.14.10.1">19.6</span></td>
<td class="ltx_td ltx_align_right" id="S5.T4.14.14.5"><span class="ltx_text ltx_font_bold" id="S5.T4.14.14.5.1">20.4<sup class="ltx_sup" id="S5.T4.14.14.5.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S5.T4.14.14.5.1.1.1">â€ </span></sup></span></td>
<td class="ltx_td ltx_align_right" id="S5.T4.14.14.11"><span class="ltx_text ltx_font_bold" id="S5.T4.14.14.11.1">19.5</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.16.16">
<td class="ltx_td ltx_border_bb" id="S5.T4.16.16.3"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r" id="S5.T4.16.16.4">2K</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T4.16.16.5">31.0</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T4.16.16.6">31.0</td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_r" id="S5.T4.16.16.7">24.3</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T4.16.16.8"><span class="ltx_text ltx_font_bold" id="S5.T4.16.16.8.1">20.4</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T4.15.15.1"><span class="ltx_text ltx_font_bold" id="S5.T4.15.15.1.1">21.5<sup class="ltx_sup" id="S5.T4.15.15.1.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S5.T4.15.15.1.1.1.1">â€ </span></sup></span></td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_r" id="S5.T4.16.16.2"><span class="ltx_text ltx_font_bold" id="S5.T4.16.16.2.1">17.9<sup class="ltx_sup" id="S5.T4.16.16.2.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="S5.T4.16.16.2.1.1.1">â€ </span></sup></span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T4.16.16.9">17.7</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T4.16.16.10">19.1</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T4.16.16.11">18.0</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Performance of keyphrase generation models on the <span class="ltx_text ltx_font_typewriter" id="S5.T4.23.1">nlp</span>, <span class="ltx_text ltx_font_typewriter" id="S5.T4.24.2">astro</span> and <span class="ltx_text ltx_font_typewriter" id="S5.T4.25.3">paleo</span> domains for all keyphrases (i.e. present and absent combined). Values in <span class="ltx_text ltx_font_bold" id="S5.T4.26.4">bold</span> indicate best scores and <math alttext="\dagger" class="ltx_Math" display="inline" id="S5.T4.18.m1.1"><semantics id="S5.T4.18.m1.1b"><mo id="S5.T4.18.m1.1.1" xref="S5.T4.18.m1.1.1.cmml">â€ </mo><annotation-xml encoding="MathML-Content" id="S5.T4.18.m1.1c"><ci id="S5.T4.18.m1.1.1.cmml" xref="S5.T4.18.m1.1.1">â€ </ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.18.m1.1d">\dagger</annotation><annotation encoding="application/x-llamapun" id="S5.T4.18.m1.1e">â€ </annotation></semantics></math> indicates significance over BART-FT.</figcaption>
</figure>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S5.T4" title="Table 4 â€£ 5 Results â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_tag">4</span></a> presents the results of the keyphrase generation models and our domain adaptation method on each domain.<span class="ltx_note ltx_role_footnote" id="footnote14"><sup class="ltx_note_mark">14</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">14</sup><span class="ltx_tag ltx_tag_note">14</span>See TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#A1.T14" title="Table 14 â€£ A.4 Sources used for collecting test data â€£ Appendix A Appendices â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_tag">14</span></a> in AppendixÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#A1" title="Appendix A Appendices â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_tag">A</span></a> for present/absent results.</span></span></span>
We observe that <span class="ltx_text ltx_font_typewriter" id="S5.p1.1.1">silk</span> brings consistent and significant improvements over BART-FT on the three domains.
The best overall performance is achieved by fine-tuning the model with the top-1K most confident synthetic samples, however gains are observed with just the top-500 samples.
Self-learning for domain adaptation yields only marginal gains at best and often degrades performance.
This suggests that the initial performance of BART-FT on these domains is not sufficient to generate high-quality pseudo-labels.
A closer look at the numbers shows that BART-FT performs comparably on <span class="ltx_text ltx_font_typewriter" id="S5.p1.1.2">nlp</span> as it does on KP20k (see TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S4.T3" title="Table 3 â€£ 4.5 Performance of Models on KP20k â€£ 4 Experimental Settings â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_tag">3</span></a>), but it gives substantially lower scores on <span class="ltx_text ltx_font_typewriter" id="S5.p1.1.3">paleo</span> and <span class="ltx_text ltx_font_typewriter" id="S5.p1.1.4">astro</span>.
This empirically confirms the growing distance between KP20k and these three domains, correlating model performance with the distance from the initial domain.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">Among the three domains, <span class="ltx_text ltx_font_typewriter" id="S5.p2.1.1">paleo</span> poses the greatest challenge for our method.
We see two main reasons for this.
First, the limited size of our collection of full-text papers (<math alttext="\approx" class="ltx_Math" display="inline" id="S5.p2.1.m1.1"><semantics id="S5.p2.1.m1.1a"><mo id="S5.p2.1.m1.1.1" xref="S5.p2.1.m1.1.1.cmml">â‰ˆ</mo><annotation-xml encoding="MathML-Content" id="S5.p2.1.m1.1b"><approx id="S5.p2.1.m1.1.1.cmml" xref="S5.p2.1.m1.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.m1.1c">\approx</annotation><annotation encoding="application/x-llamapun" id="S5.p2.1.m1.1d">â‰ˆ</annotation></semantics></math>12K), and the necessary parameter adjustments made to accommodate it, adversely affect the quality of the synthetic samples.
Second, the <span class="ltx_text ltx_font_typewriter" id="S5.p2.1.2">paleo</span> domain in itself appears to be more challenging to handle due to its interdisciplinary nature, spanning subjects such as geology, biology, history, and ecology, among others.
Examining the performance of the baselines, we observe the poor generalization of One2Set whose results nearly drop by half for non-computer science domains, and that is even surpassed by MultiPartiteRank.
This latter delivers consistent, albeit modest, performance across domains which makes it relevant as an estimator of lower-bound performance for research on domain adaptation.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Confidence Ranking of synthetic samples</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">The purpose of <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p1.1.1">silk</span> is to generate small, high quality in-domain data for fine-tuning keyphrase generation models.
Accordingly, synthetic samples are ordered by confidence (described in Â§<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S2.SSx3" title="Step 3: Ordering Samples by Confidence â€£ 2 Method â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_tag">2</span></a>) and only the top-<math alttext="N" class="ltx_Math" display="inline" id="S5.SS1.p1.1.m1.1"><semantics id="S5.SS1.p1.1.m1.1a"><mi id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><ci id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.1.m1.1d">italic_N</annotation></semantics></math> ranked samples are employed for adapting models.
To validate the quality of our ranking, and consequently the effectiveness of our keyphrase candidate scoring function (see EquationÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S2.E1" title="In Step 1: Ranking Keyphrase Candidates â€£ 2 Method â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_tag">1</span></a>), we compare the performance of BART-FT when we continue the fine-tuning with the top-1K, bottom-1K and a random selection of 1K samples.
Results are presented in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S5.T5" title="Table 5 â€£ 5.1 Confidence Ranking of synthetic samples â€£ 5 Results â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_tag">5</span></a>.
We note that, uniformly across the three domains, the random and top-1K ordering schemes lead to improvements, with top-1K yielding the best results.
In contrast, using the least confident samples (bottom-1K) systematically degrades the performance.
Insights from these results are twofold: 1)Â our confidence ranking proves to be beneficial for selecting high-quality synthetic samples, and 2)Â even samples beyond the top-1K are qualitative enough for domain adaptation.</p>
</div>
<figure class="ltx_table" id="S5.T5">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T5.9" style="width:433.6pt;height:162.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(72.7pt,-27.3pt) scale(1.50485303735163,1.50485303735163) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T5.9.9">
<tr class="ltx_tr" id="S5.T5.9.9.10">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S5.T5.9.9.10.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S5.T5.9.9.10.1.1">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S5.T5.9.9.10.2"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S5.T5.9.9.10.2.1">nlp</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S5.T5.9.9.10.3"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S5.T5.9.9.10.3.1">astro</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S5.T5.9.9.10.4"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S5.T5.9.9.10.4.1">paleo</span></td>
</tr>
<tr class="ltx_tr" id="S5.T5.6.6.6">
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T5.1.1.1.1"><math alttext="F_{1}@M" class="ltx_Math" display="inline" id="S5.T5.1.1.1.1.m1.1"><semantics id="S5.T5.1.1.1.1.m1.1a"><mrow id="S5.T5.1.1.1.1.m1.1.1" xref="S5.T5.1.1.1.1.m1.1.1.cmml"><msub id="S5.T5.1.1.1.1.m1.1.1.2" xref="S5.T5.1.1.1.1.m1.1.1.2.cmml"><mi id="S5.T5.1.1.1.1.m1.1.1.2.2" xref="S5.T5.1.1.1.1.m1.1.1.2.2.cmml">F</mi><mn id="S5.T5.1.1.1.1.m1.1.1.2.3" xref="S5.T5.1.1.1.1.m1.1.1.2.3.cmml">1</mn></msub><mo id="S5.T5.1.1.1.1.m1.1.1.1" xref="S5.T5.1.1.1.1.m1.1.1.1.cmml">â¢</mo><mi id="S5.T5.1.1.1.1.m1.1.1.3" mathvariant="normal" xref="S5.T5.1.1.1.1.m1.1.1.3.cmml">@</mi><mo id="S5.T5.1.1.1.1.m1.1.1.1a" xref="S5.T5.1.1.1.1.m1.1.1.1.cmml">â¢</mo><mi id="S5.T5.1.1.1.1.m1.1.1.4" xref="S5.T5.1.1.1.1.m1.1.1.4.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.T5.1.1.1.1.m1.1b"><apply id="S5.T5.1.1.1.1.m1.1.1.cmml" xref="S5.T5.1.1.1.1.m1.1.1"><times id="S5.T5.1.1.1.1.m1.1.1.1.cmml" xref="S5.T5.1.1.1.1.m1.1.1.1"></times><apply id="S5.T5.1.1.1.1.m1.1.1.2.cmml" xref="S5.T5.1.1.1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S5.T5.1.1.1.1.m1.1.1.2.1.cmml" xref="S5.T5.1.1.1.1.m1.1.1.2">subscript</csymbol><ci id="S5.T5.1.1.1.1.m1.1.1.2.2.cmml" xref="S5.T5.1.1.1.1.m1.1.1.2.2">ğ¹</ci><cn id="S5.T5.1.1.1.1.m1.1.1.2.3.cmml" type="integer" xref="S5.T5.1.1.1.1.m1.1.1.2.3">1</cn></apply><ci id="S5.T5.1.1.1.1.m1.1.1.3.cmml" xref="S5.T5.1.1.1.1.m1.1.1.3">@</ci><ci id="S5.T5.1.1.1.1.m1.1.1.4.cmml" xref="S5.T5.1.1.1.1.m1.1.1.4">ğ‘€</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.1.1.1.1.m1.1c">F_{1}@M</annotation><annotation encoding="application/x-llamapun" id="S5.T5.1.1.1.1.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ italic_M</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T5.2.2.2.2"><math alttext="F_{1}@10" class="ltx_Math" display="inline" id="S5.T5.2.2.2.2.m1.1"><semantics id="S5.T5.2.2.2.2.m1.1a"><mrow id="S5.T5.2.2.2.2.m1.1.1" xref="S5.T5.2.2.2.2.m1.1.1.cmml"><msub id="S5.T5.2.2.2.2.m1.1.1.2" xref="S5.T5.2.2.2.2.m1.1.1.2.cmml"><mi id="S5.T5.2.2.2.2.m1.1.1.2.2" xref="S5.T5.2.2.2.2.m1.1.1.2.2.cmml">F</mi><mn id="S5.T5.2.2.2.2.m1.1.1.2.3" xref="S5.T5.2.2.2.2.m1.1.1.2.3.cmml">1</mn></msub><mo id="S5.T5.2.2.2.2.m1.1.1.1" xref="S5.T5.2.2.2.2.m1.1.1.1.cmml">â¢</mo><mi id="S5.T5.2.2.2.2.m1.1.1.3" mathvariant="normal" xref="S5.T5.2.2.2.2.m1.1.1.3.cmml">@</mi><mo id="S5.T5.2.2.2.2.m1.1.1.1a" xref="S5.T5.2.2.2.2.m1.1.1.1.cmml">â¢</mo><mn id="S5.T5.2.2.2.2.m1.1.1.4" xref="S5.T5.2.2.2.2.m1.1.1.4.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T5.2.2.2.2.m1.1b"><apply id="S5.T5.2.2.2.2.m1.1.1.cmml" xref="S5.T5.2.2.2.2.m1.1.1"><times id="S5.T5.2.2.2.2.m1.1.1.1.cmml" xref="S5.T5.2.2.2.2.m1.1.1.1"></times><apply id="S5.T5.2.2.2.2.m1.1.1.2.cmml" xref="S5.T5.2.2.2.2.m1.1.1.2"><csymbol cd="ambiguous" id="S5.T5.2.2.2.2.m1.1.1.2.1.cmml" xref="S5.T5.2.2.2.2.m1.1.1.2">subscript</csymbol><ci id="S5.T5.2.2.2.2.m1.1.1.2.2.cmml" xref="S5.T5.2.2.2.2.m1.1.1.2.2">ğ¹</ci><cn id="S5.T5.2.2.2.2.m1.1.1.2.3.cmml" type="integer" xref="S5.T5.2.2.2.2.m1.1.1.2.3">1</cn></apply><ci id="S5.T5.2.2.2.2.m1.1.1.3.cmml" xref="S5.T5.2.2.2.2.m1.1.1.3">@</ci><cn id="S5.T5.2.2.2.2.m1.1.1.4.cmml" type="integer" xref="S5.T5.2.2.2.2.m1.1.1.4">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.2.2.2.2.m1.1c">F_{1}@10</annotation><annotation encoding="application/x-llamapun" id="S5.T5.2.2.2.2.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ 10</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T5.3.3.3.3"><math alttext="F_{1}@M" class="ltx_Math" display="inline" id="S5.T5.3.3.3.3.m1.1"><semantics id="S5.T5.3.3.3.3.m1.1a"><mrow id="S5.T5.3.3.3.3.m1.1.1" xref="S5.T5.3.3.3.3.m1.1.1.cmml"><msub id="S5.T5.3.3.3.3.m1.1.1.2" xref="S5.T5.3.3.3.3.m1.1.1.2.cmml"><mi id="S5.T5.3.3.3.3.m1.1.1.2.2" xref="S5.T5.3.3.3.3.m1.1.1.2.2.cmml">F</mi><mn id="S5.T5.3.3.3.3.m1.1.1.2.3" xref="S5.T5.3.3.3.3.m1.1.1.2.3.cmml">1</mn></msub><mo id="S5.T5.3.3.3.3.m1.1.1.1" xref="S5.T5.3.3.3.3.m1.1.1.1.cmml">â¢</mo><mi id="S5.T5.3.3.3.3.m1.1.1.3" mathvariant="normal" xref="S5.T5.3.3.3.3.m1.1.1.3.cmml">@</mi><mo id="S5.T5.3.3.3.3.m1.1.1.1a" xref="S5.T5.3.3.3.3.m1.1.1.1.cmml">â¢</mo><mi id="S5.T5.3.3.3.3.m1.1.1.4" xref="S5.T5.3.3.3.3.m1.1.1.4.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.T5.3.3.3.3.m1.1b"><apply id="S5.T5.3.3.3.3.m1.1.1.cmml" xref="S5.T5.3.3.3.3.m1.1.1"><times id="S5.T5.3.3.3.3.m1.1.1.1.cmml" xref="S5.T5.3.3.3.3.m1.1.1.1"></times><apply id="S5.T5.3.3.3.3.m1.1.1.2.cmml" xref="S5.T5.3.3.3.3.m1.1.1.2"><csymbol cd="ambiguous" id="S5.T5.3.3.3.3.m1.1.1.2.1.cmml" xref="S5.T5.3.3.3.3.m1.1.1.2">subscript</csymbol><ci id="S5.T5.3.3.3.3.m1.1.1.2.2.cmml" xref="S5.T5.3.3.3.3.m1.1.1.2.2">ğ¹</ci><cn id="S5.T5.3.3.3.3.m1.1.1.2.3.cmml" type="integer" xref="S5.T5.3.3.3.3.m1.1.1.2.3">1</cn></apply><ci id="S5.T5.3.3.3.3.m1.1.1.3.cmml" xref="S5.T5.3.3.3.3.m1.1.1.3">@</ci><ci id="S5.T5.3.3.3.3.m1.1.1.4.cmml" xref="S5.T5.3.3.3.3.m1.1.1.4">ğ‘€</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.3.3.3.3.m1.1c">F_{1}@M</annotation><annotation encoding="application/x-llamapun" id="S5.T5.3.3.3.3.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ italic_M</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T5.4.4.4.4"><math alttext="F_{1}@10" class="ltx_Math" display="inline" id="S5.T5.4.4.4.4.m1.1"><semantics id="S5.T5.4.4.4.4.m1.1a"><mrow id="S5.T5.4.4.4.4.m1.1.1" xref="S5.T5.4.4.4.4.m1.1.1.cmml"><msub id="S5.T5.4.4.4.4.m1.1.1.2" xref="S5.T5.4.4.4.4.m1.1.1.2.cmml"><mi id="S5.T5.4.4.4.4.m1.1.1.2.2" xref="S5.T5.4.4.4.4.m1.1.1.2.2.cmml">F</mi><mn id="S5.T5.4.4.4.4.m1.1.1.2.3" xref="S5.T5.4.4.4.4.m1.1.1.2.3.cmml">1</mn></msub><mo id="S5.T5.4.4.4.4.m1.1.1.1" xref="S5.T5.4.4.4.4.m1.1.1.1.cmml">â¢</mo><mi id="S5.T5.4.4.4.4.m1.1.1.3" mathvariant="normal" xref="S5.T5.4.4.4.4.m1.1.1.3.cmml">@</mi><mo id="S5.T5.4.4.4.4.m1.1.1.1a" xref="S5.T5.4.4.4.4.m1.1.1.1.cmml">â¢</mo><mn id="S5.T5.4.4.4.4.m1.1.1.4" xref="S5.T5.4.4.4.4.m1.1.1.4.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T5.4.4.4.4.m1.1b"><apply id="S5.T5.4.4.4.4.m1.1.1.cmml" xref="S5.T5.4.4.4.4.m1.1.1"><times id="S5.T5.4.4.4.4.m1.1.1.1.cmml" xref="S5.T5.4.4.4.4.m1.1.1.1"></times><apply id="S5.T5.4.4.4.4.m1.1.1.2.cmml" xref="S5.T5.4.4.4.4.m1.1.1.2"><csymbol cd="ambiguous" id="S5.T5.4.4.4.4.m1.1.1.2.1.cmml" xref="S5.T5.4.4.4.4.m1.1.1.2">subscript</csymbol><ci id="S5.T5.4.4.4.4.m1.1.1.2.2.cmml" xref="S5.T5.4.4.4.4.m1.1.1.2.2">ğ¹</ci><cn id="S5.T5.4.4.4.4.m1.1.1.2.3.cmml" type="integer" xref="S5.T5.4.4.4.4.m1.1.1.2.3">1</cn></apply><ci id="S5.T5.4.4.4.4.m1.1.1.3.cmml" xref="S5.T5.4.4.4.4.m1.1.1.3">@</ci><cn id="S5.T5.4.4.4.4.m1.1.1.4.cmml" type="integer" xref="S5.T5.4.4.4.4.m1.1.1.4">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.4.4.4.4.m1.1c">F_{1}@10</annotation><annotation encoding="application/x-llamapun" id="S5.T5.4.4.4.4.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ 10</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T5.5.5.5.5"><math alttext="F_{1}@M" class="ltx_Math" display="inline" id="S5.T5.5.5.5.5.m1.1"><semantics id="S5.T5.5.5.5.5.m1.1a"><mrow id="S5.T5.5.5.5.5.m1.1.1" xref="S5.T5.5.5.5.5.m1.1.1.cmml"><msub id="S5.T5.5.5.5.5.m1.1.1.2" xref="S5.T5.5.5.5.5.m1.1.1.2.cmml"><mi id="S5.T5.5.5.5.5.m1.1.1.2.2" xref="S5.T5.5.5.5.5.m1.1.1.2.2.cmml">F</mi><mn id="S5.T5.5.5.5.5.m1.1.1.2.3" xref="S5.T5.5.5.5.5.m1.1.1.2.3.cmml">1</mn></msub><mo id="S5.T5.5.5.5.5.m1.1.1.1" xref="S5.T5.5.5.5.5.m1.1.1.1.cmml">â¢</mo><mi id="S5.T5.5.5.5.5.m1.1.1.3" mathvariant="normal" xref="S5.T5.5.5.5.5.m1.1.1.3.cmml">@</mi><mo id="S5.T5.5.5.5.5.m1.1.1.1a" xref="S5.T5.5.5.5.5.m1.1.1.1.cmml">â¢</mo><mi id="S5.T5.5.5.5.5.m1.1.1.4" xref="S5.T5.5.5.5.5.m1.1.1.4.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.T5.5.5.5.5.m1.1b"><apply id="S5.T5.5.5.5.5.m1.1.1.cmml" xref="S5.T5.5.5.5.5.m1.1.1"><times id="S5.T5.5.5.5.5.m1.1.1.1.cmml" xref="S5.T5.5.5.5.5.m1.1.1.1"></times><apply id="S5.T5.5.5.5.5.m1.1.1.2.cmml" xref="S5.T5.5.5.5.5.m1.1.1.2"><csymbol cd="ambiguous" id="S5.T5.5.5.5.5.m1.1.1.2.1.cmml" xref="S5.T5.5.5.5.5.m1.1.1.2">subscript</csymbol><ci id="S5.T5.5.5.5.5.m1.1.1.2.2.cmml" xref="S5.T5.5.5.5.5.m1.1.1.2.2">ğ¹</ci><cn id="S5.T5.5.5.5.5.m1.1.1.2.3.cmml" type="integer" xref="S5.T5.5.5.5.5.m1.1.1.2.3">1</cn></apply><ci id="S5.T5.5.5.5.5.m1.1.1.3.cmml" xref="S5.T5.5.5.5.5.m1.1.1.3">@</ci><ci id="S5.T5.5.5.5.5.m1.1.1.4.cmml" xref="S5.T5.5.5.5.5.m1.1.1.4">ğ‘€</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.5.5.5.5.m1.1c">F_{1}@M</annotation><annotation encoding="application/x-llamapun" id="S5.T5.5.5.5.5.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ italic_M</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T5.6.6.6.6"><math alttext="F_{1}@10" class="ltx_Math" display="inline" id="S5.T5.6.6.6.6.m1.1"><semantics id="S5.T5.6.6.6.6.m1.1a"><mrow id="S5.T5.6.6.6.6.m1.1.1" xref="S5.T5.6.6.6.6.m1.1.1.cmml"><msub id="S5.T5.6.6.6.6.m1.1.1.2" xref="S5.T5.6.6.6.6.m1.1.1.2.cmml"><mi id="S5.T5.6.6.6.6.m1.1.1.2.2" xref="S5.T5.6.6.6.6.m1.1.1.2.2.cmml">F</mi><mn id="S5.T5.6.6.6.6.m1.1.1.2.3" xref="S5.T5.6.6.6.6.m1.1.1.2.3.cmml">1</mn></msub><mo id="S5.T5.6.6.6.6.m1.1.1.1" xref="S5.T5.6.6.6.6.m1.1.1.1.cmml">â¢</mo><mi id="S5.T5.6.6.6.6.m1.1.1.3" mathvariant="normal" xref="S5.T5.6.6.6.6.m1.1.1.3.cmml">@</mi><mo id="S5.T5.6.6.6.6.m1.1.1.1a" xref="S5.T5.6.6.6.6.m1.1.1.1.cmml">â¢</mo><mn id="S5.T5.6.6.6.6.m1.1.1.4" xref="S5.T5.6.6.6.6.m1.1.1.4.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T5.6.6.6.6.m1.1b"><apply id="S5.T5.6.6.6.6.m1.1.1.cmml" xref="S5.T5.6.6.6.6.m1.1.1"><times id="S5.T5.6.6.6.6.m1.1.1.1.cmml" xref="S5.T5.6.6.6.6.m1.1.1.1"></times><apply id="S5.T5.6.6.6.6.m1.1.1.2.cmml" xref="S5.T5.6.6.6.6.m1.1.1.2"><csymbol cd="ambiguous" id="S5.T5.6.6.6.6.m1.1.1.2.1.cmml" xref="S5.T5.6.6.6.6.m1.1.1.2">subscript</csymbol><ci id="S5.T5.6.6.6.6.m1.1.1.2.2.cmml" xref="S5.T5.6.6.6.6.m1.1.1.2.2">ğ¹</ci><cn id="S5.T5.6.6.6.6.m1.1.1.2.3.cmml" type="integer" xref="S5.T5.6.6.6.6.m1.1.1.2.3">1</cn></apply><ci id="S5.T5.6.6.6.6.m1.1.1.3.cmml" xref="S5.T5.6.6.6.6.m1.1.1.3">@</ci><cn id="S5.T5.6.6.6.6.m1.1.1.4.cmml" type="integer" xref="S5.T5.6.6.6.6.m1.1.1.4">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.6.6.6.6.m1.1c">F_{1}@10</annotation><annotation encoding="application/x-llamapun" id="S5.T5.6.6.6.6.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ 10</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S5.T5.9.9.11">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T5.9.9.11.1">BART-FT</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T5.9.9.11.2">30.8</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T5.9.9.11.3">24.9</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T5.9.9.11.4">19.2</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T5.9.9.11.5">16.6</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T5.9.9.11.6">18.4</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T5.9.9.11.7">18.8</td>
</tr>
<tr class="ltx_tr" id="S5.T5.8.8.8">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T5.8.8.8.3">+<span class="ltx_text ltx_font_typewriter" id="S5.T5.8.8.8.3.1">silk</span> (top)</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T5.7.7.7.1">33.7<sup class="ltx_sup" id="S5.T5.7.7.7.1.1"><span class="ltx_text ltx_font_italic" id="S5.T5.7.7.7.1.1.1">â€ </span></sup>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T5.8.8.8.4">25.2</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T5.8.8.8.5">19.2</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T5.8.8.8.2">17.7<sup class="ltx_sup" id="S5.T5.8.8.8.2.1"><span class="ltx_text ltx_font_italic" id="S5.T5.8.8.8.2.1.1">â€ </span></sup>
</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T5.8.8.8.6">19.4</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T5.8.8.8.7">19.5</td>
</tr>
<tr class="ltx_tr" id="S5.T5.9.9.9">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T5.9.9.9.2">+<span class="ltx_text ltx_font_typewriter" id="S5.T5.9.9.9.2.1">silk</span> (ran)</td>
<td class="ltx_td ltx_align_right" id="S5.T5.9.9.9.1">33.2<sup class="ltx_sup" id="S5.T5.9.9.9.1.1"><span class="ltx_text ltx_font_italic" id="S5.T5.9.9.9.1.1.1">â€ </span></sup>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T5.9.9.9.3">25.1</td>
<td class="ltx_td ltx_align_right" id="S5.T5.9.9.9.4">19.3</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T5.9.9.9.5">17.4</td>
<td class="ltx_td ltx_align_right" id="S5.T5.9.9.9.6">19.4</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T5.9.9.9.7">19.4</td>
</tr>
<tr class="ltx_tr" id="S5.T5.9.9.12">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S5.T5.9.9.12.1">+<span class="ltx_text ltx_font_typewriter" id="S5.T5.9.9.12.1.1">silk</span> (bot)</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T5.9.9.12.2">27.8</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" id="S5.T5.9.9.12.3">21.4</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T5.9.9.12.4">16.5</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" id="S5.T5.9.9.12.5">15.1</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T5.9.9.12.6">16.9</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" id="S5.T5.9.9.12.7">17.3</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Performance of BART-FT fine-tuned on the top-1K, bottom-1K and random-1K (averaged over 5 runs with different seed values) samples. <math alttext="\dagger" class="ltx_Math" display="inline" id="S5.T5.11.m1.1"><semantics id="S5.T5.11.m1.1b"><mo id="S5.T5.11.m1.1.1" xref="S5.T5.11.m1.1.1.cmml">â€ </mo><annotation-xml encoding="MathML-Content" id="S5.T5.11.m1.1c"><ci id="S5.T5.11.m1.1.1.cmml" xref="S5.T5.11.m1.1.1">â€ </ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.11.m1.1d">\dagger</annotation><annotation encoding="application/x-llamapun" id="S5.T5.11.m1.1e">â€ </annotation></semantics></math> indicates significance over BART-FT.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Forgetting of Domain Adaptation</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">Although continued training is effective for domain adaptation, it has been found to adversely affect performance in the initial domain for language generation tasksÂ <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib32" title="">2022</a>)</cite>.
Here, we investigate whether this phenomenon, referred to in the literature as catastrophic forgettingÂ <cite class="ltx_cite ltx_citemacro_cite">French (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib17" title="">1999</a>)</cite>, also manifests in our adapted models.
TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S5.T6" title="Table 6 â€£ 5.2 Forgetting of Domain Adaptation â€£ 5 Results â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_tag">6</span></a> presents the results of our domain adapted BART-FT models (using 1K synthetic samples) on the KP20k test set.
Overall, we observe no drop in performance for our adapted models.
Rather surprisingly, we notice small improvements in <math alttext="F_{1}@k" class="ltx_Math" display="inline" id="S5.SS2.p1.1.m1.1"><semantics id="S5.SS2.p1.1.m1.1a"><mrow id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml"><msub id="S5.SS2.p1.1.m1.1.1.2" xref="S5.SS2.p1.1.m1.1.1.2.cmml"><mi id="S5.SS2.p1.1.m1.1.1.2.2" xref="S5.SS2.p1.1.m1.1.1.2.2.cmml">F</mi><mn id="S5.SS2.p1.1.m1.1.1.2.3" xref="S5.SS2.p1.1.m1.1.1.2.3.cmml">1</mn></msub><mo id="S5.SS2.p1.1.m1.1.1.1" xref="S5.SS2.p1.1.m1.1.1.1.cmml">â¢</mo><mi id="S5.SS2.p1.1.m1.1.1.3" mathvariant="normal" xref="S5.SS2.p1.1.m1.1.1.3.cmml">@</mi><mo id="S5.SS2.p1.1.m1.1.1.1a" xref="S5.SS2.p1.1.m1.1.1.1.cmml">â¢</mo><mi id="S5.SS2.p1.1.m1.1.1.4" xref="S5.SS2.p1.1.m1.1.1.4.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><apply id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1"><times id="S5.SS2.p1.1.m1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1.1"></times><apply id="S5.SS2.p1.1.m1.1.1.2.cmml" xref="S5.SS2.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S5.SS2.p1.1.m1.1.1.2.1.cmml" xref="S5.SS2.p1.1.m1.1.1.2">subscript</csymbol><ci id="S5.SS2.p1.1.m1.1.1.2.2.cmml" xref="S5.SS2.p1.1.m1.1.1.2.2">ğ¹</ci><cn id="S5.SS2.p1.1.m1.1.1.2.3.cmml" type="integer" xref="S5.SS2.p1.1.m1.1.1.2.3">1</cn></apply><ci id="S5.SS2.p1.1.m1.1.1.3.cmml" xref="S5.SS2.p1.1.m1.1.1.3">@</ci><ci id="S5.SS2.p1.1.m1.1.1.4.cmml" xref="S5.SS2.p1.1.m1.1.1.4">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">F_{1}@k</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.1.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ italic_k</annotation></semantics></math> scores over the initial BART-FT model.
Upon closer examination, these gains derive from improved extractive capabilities, while the scores for absent keyphrases consistently degrade.
We hypothesise that the domain adaption process makes the model lose generative ability and reinforces its extractive capability which translates more effectively across domains.</p>
</div>
<figure class="ltx_table" id="S5.T6">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T6.3" style="width:433.6pt;height:162.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(72.4pt,-27.1pt) scale(1.5011516003206,1.5011516003206) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T6.3.3">
<tr class="ltx_tr" id="S5.T6.3.3.3">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S5.T6.3.3.3.4" rowspan="2"><span class="ltx_text ltx_font_bold" id="S5.T6.3.3.3.4.1">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S5.T6.1.1.1.1"><math alttext="F_{1}@M" class="ltx_Math" display="inline" id="S5.T6.1.1.1.1.m1.1"><semantics id="S5.T6.1.1.1.1.m1.1a"><mrow id="S5.T6.1.1.1.1.m1.1.1" xref="S5.T6.1.1.1.1.m1.1.1.cmml"><msub id="S5.T6.1.1.1.1.m1.1.1.2" xref="S5.T6.1.1.1.1.m1.1.1.2.cmml"><mi id="S5.T6.1.1.1.1.m1.1.1.2.2" xref="S5.T6.1.1.1.1.m1.1.1.2.2.cmml">F</mi><mn id="S5.T6.1.1.1.1.m1.1.1.2.3" xref="S5.T6.1.1.1.1.m1.1.1.2.3.cmml">1</mn></msub><mo id="S5.T6.1.1.1.1.m1.1.1.1" xref="S5.T6.1.1.1.1.m1.1.1.1.cmml">â¢</mo><mi id="S5.T6.1.1.1.1.m1.1.1.3" mathvariant="normal" xref="S5.T6.1.1.1.1.m1.1.1.3.cmml">@</mi><mo id="S5.T6.1.1.1.1.m1.1.1.1a" xref="S5.T6.1.1.1.1.m1.1.1.1.cmml">â¢</mo><mi id="S5.T6.1.1.1.1.m1.1.1.4" xref="S5.T6.1.1.1.1.m1.1.1.4.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.T6.1.1.1.1.m1.1b"><apply id="S5.T6.1.1.1.1.m1.1.1.cmml" xref="S5.T6.1.1.1.1.m1.1.1"><times id="S5.T6.1.1.1.1.m1.1.1.1.cmml" xref="S5.T6.1.1.1.1.m1.1.1.1"></times><apply id="S5.T6.1.1.1.1.m1.1.1.2.cmml" xref="S5.T6.1.1.1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S5.T6.1.1.1.1.m1.1.1.2.1.cmml" xref="S5.T6.1.1.1.1.m1.1.1.2">subscript</csymbol><ci id="S5.T6.1.1.1.1.m1.1.1.2.2.cmml" xref="S5.T6.1.1.1.1.m1.1.1.2.2">ğ¹</ci><cn id="S5.T6.1.1.1.1.m1.1.1.2.3.cmml" type="integer" xref="S5.T6.1.1.1.1.m1.1.1.2.3">1</cn></apply><ci id="S5.T6.1.1.1.1.m1.1.1.3.cmml" xref="S5.T6.1.1.1.1.m1.1.1.3">@</ci><ci id="S5.T6.1.1.1.1.m1.1.1.4.cmml" xref="S5.T6.1.1.1.1.m1.1.1.4">ğ‘€</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.1.1.1.1.m1.1c">F_{1}@M</annotation><annotation encoding="application/x-llamapun" id="S5.T6.1.1.1.1.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ italic_M</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S5.T6.2.2.2.2"><math alttext="F_{1}@5" class="ltx_Math" display="inline" id="S5.T6.2.2.2.2.m1.1"><semantics id="S5.T6.2.2.2.2.m1.1a"><mrow id="S5.T6.2.2.2.2.m1.1.1" xref="S5.T6.2.2.2.2.m1.1.1.cmml"><msub id="S5.T6.2.2.2.2.m1.1.1.2" xref="S5.T6.2.2.2.2.m1.1.1.2.cmml"><mi id="S5.T6.2.2.2.2.m1.1.1.2.2" xref="S5.T6.2.2.2.2.m1.1.1.2.2.cmml">F</mi><mn id="S5.T6.2.2.2.2.m1.1.1.2.3" xref="S5.T6.2.2.2.2.m1.1.1.2.3.cmml">1</mn></msub><mo id="S5.T6.2.2.2.2.m1.1.1.1" xref="S5.T6.2.2.2.2.m1.1.1.1.cmml">â¢</mo><mi id="S5.T6.2.2.2.2.m1.1.1.3" mathvariant="normal" xref="S5.T6.2.2.2.2.m1.1.1.3.cmml">@</mi><mo id="S5.T6.2.2.2.2.m1.1.1.1a" xref="S5.T6.2.2.2.2.m1.1.1.1.cmml">â¢</mo><mn id="S5.T6.2.2.2.2.m1.1.1.4" xref="S5.T6.2.2.2.2.m1.1.1.4.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T6.2.2.2.2.m1.1b"><apply id="S5.T6.2.2.2.2.m1.1.1.cmml" xref="S5.T6.2.2.2.2.m1.1.1"><times id="S5.T6.2.2.2.2.m1.1.1.1.cmml" xref="S5.T6.2.2.2.2.m1.1.1.1"></times><apply id="S5.T6.2.2.2.2.m1.1.1.2.cmml" xref="S5.T6.2.2.2.2.m1.1.1.2"><csymbol cd="ambiguous" id="S5.T6.2.2.2.2.m1.1.1.2.1.cmml" xref="S5.T6.2.2.2.2.m1.1.1.2">subscript</csymbol><ci id="S5.T6.2.2.2.2.m1.1.1.2.2.cmml" xref="S5.T6.2.2.2.2.m1.1.1.2.2">ğ¹</ci><cn id="S5.T6.2.2.2.2.m1.1.1.2.3.cmml" type="integer" xref="S5.T6.2.2.2.2.m1.1.1.2.3">1</cn></apply><ci id="S5.T6.2.2.2.2.m1.1.1.3.cmml" xref="S5.T6.2.2.2.2.m1.1.1.3">@</ci><cn id="S5.T6.2.2.2.2.m1.1.1.4.cmml" type="integer" xref="S5.T6.2.2.2.2.m1.1.1.4">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.2.2.2.2.m1.1c">F_{1}@5</annotation><annotation encoding="application/x-llamapun" id="S5.T6.2.2.2.2.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ 5</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S5.T6.3.3.3.3"><math alttext="F_{1}@10" class="ltx_Math" display="inline" id="S5.T6.3.3.3.3.m1.1"><semantics id="S5.T6.3.3.3.3.m1.1a"><mrow id="S5.T6.3.3.3.3.m1.1.1" xref="S5.T6.3.3.3.3.m1.1.1.cmml"><msub id="S5.T6.3.3.3.3.m1.1.1.2" xref="S5.T6.3.3.3.3.m1.1.1.2.cmml"><mi id="S5.T6.3.3.3.3.m1.1.1.2.2" xref="S5.T6.3.3.3.3.m1.1.1.2.2.cmml">F</mi><mn id="S5.T6.3.3.3.3.m1.1.1.2.3" xref="S5.T6.3.3.3.3.m1.1.1.2.3.cmml">1</mn></msub><mo id="S5.T6.3.3.3.3.m1.1.1.1" xref="S5.T6.3.3.3.3.m1.1.1.1.cmml">â¢</mo><mi id="S5.T6.3.3.3.3.m1.1.1.3" mathvariant="normal" xref="S5.T6.3.3.3.3.m1.1.1.3.cmml">@</mi><mo id="S5.T6.3.3.3.3.m1.1.1.1a" xref="S5.T6.3.3.3.3.m1.1.1.1.cmml">â¢</mo><mn id="S5.T6.3.3.3.3.m1.1.1.4" xref="S5.T6.3.3.3.3.m1.1.1.4.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T6.3.3.3.3.m1.1b"><apply id="S5.T6.3.3.3.3.m1.1.1.cmml" xref="S5.T6.3.3.3.3.m1.1.1"><times id="S5.T6.3.3.3.3.m1.1.1.1.cmml" xref="S5.T6.3.3.3.3.m1.1.1.1"></times><apply id="S5.T6.3.3.3.3.m1.1.1.2.cmml" xref="S5.T6.3.3.3.3.m1.1.1.2"><csymbol cd="ambiguous" id="S5.T6.3.3.3.3.m1.1.1.2.1.cmml" xref="S5.T6.3.3.3.3.m1.1.1.2">subscript</csymbol><ci id="S5.T6.3.3.3.3.m1.1.1.2.2.cmml" xref="S5.T6.3.3.3.3.m1.1.1.2.2">ğ¹</ci><cn id="S5.T6.3.3.3.3.m1.1.1.2.3.cmml" type="integer" xref="S5.T6.3.3.3.3.m1.1.1.2.3">1</cn></apply><ci id="S5.T6.3.3.3.3.m1.1.1.3.cmml" xref="S5.T6.3.3.3.3.m1.1.1.3">@</ci><cn id="S5.T6.3.3.3.3.m1.1.1.4.cmml" type="integer" xref="S5.T6.3.3.3.3.m1.1.1.4">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.3.3.3.3.m1.1c">F_{1}@10</annotation><annotation encoding="application/x-llamapun" id="S5.T6.3.3.3.3.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ 10</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S5.T6.3.3.4">
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T6.3.3.4.1">all</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T6.3.3.4.2">pres</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T6.3.3.4.3">abs</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T6.3.3.4.4">all</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T6.3.3.4.5">pres</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T6.3.3.4.6">abs</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T6.3.3.4.7">all</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T6.3.3.4.8">pres</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T6.3.3.4.9">abs</td>
</tr>
<tr class="ltx_tr" id="S5.T6.3.3.5">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T6.3.3.5.1">BART-FT</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T6.3.3.5.2">28.7</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T6.3.3.5.3">37.3</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T6.3.3.5.4">2.4</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T6.3.3.5.5">28.0</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T6.3.3.5.6">35.5</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T6.3.3.5.7">5.9</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T6.3.3.5.8">25.4</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T6.3.3.5.9">29.2</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T6.3.3.5.10">5.8</td>
</tr>
<tr class="ltx_tr" id="S5.T6.3.3.6">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T6.3.3.6.1">+<span class="ltx_text ltx_font_typewriter" id="S5.T6.3.3.6.1.1">silk</span>Â (<span class="ltx_text ltx_font_typewriter" id="S5.T6.3.3.6.1.2">nlp</span>)</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T6.3.3.6.2">28.6</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T6.3.3.6.3">37.5</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T6.3.3.6.4">1.6</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T6.3.3.6.5">28.3</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T6.3.3.6.6">35.9</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T6.3.3.6.7">5.5</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T6.3.3.6.8">25.7</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T6.3.3.6.9">29.7</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S5.T6.3.3.6.10">5.4</td>
</tr>
<tr class="ltx_tr" id="S5.T6.3.3.7">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T6.3.3.7.1">+<span class="ltx_text ltx_font_typewriter" id="S5.T6.3.3.7.1.1">silk</span>Â (<span class="ltx_text ltx_font_typewriter" id="S5.T6.3.3.7.1.2">astro</span>)</td>
<td class="ltx_td ltx_align_right" id="S5.T6.3.3.7.2">28.7</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T6.3.3.7.3">37.8</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T6.3.3.7.4">1.7</td>
<td class="ltx_td ltx_align_right" id="S5.T6.3.3.7.5">28.7</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T6.3.3.7.6">36.4</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T6.3.3.7.7">5.9</td>
<td class="ltx_td ltx_align_right" id="S5.T6.3.3.7.8">25.9</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T6.3.3.7.9">29.8</td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S5.T6.3.3.7.10">5.9</td>
</tr>
<tr class="ltx_tr" id="S5.T6.3.3.8">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S5.T6.3.3.8.1">+<span class="ltx_text ltx_font_typewriter" id="S5.T6.3.3.8.1.1">silk</span>Â (<span class="ltx_text ltx_font_typewriter" id="S5.T6.3.3.8.1.2">paleo</span>)</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T6.3.3.8.2">28.4</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" id="S5.T6.3.3.8.3">37.5</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" id="S5.T6.3.3.8.4">1.4</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T6.3.3.8.5">28.6</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" id="S5.T6.3.3.8.6">36.2</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" id="S5.T6.3.3.8.7">5.7</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T6.3.3.8.8">25.8</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" id="S5.T6.3.3.8.9">29.7</td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" id="S5.T6.3.3.8.10">5.6</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Performance comparison of BART-FT and its adaptions (<span class="ltx_text ltx_font_typewriter" id="S5.T6.5.1">silk</span> 1K) on the KP20k test set.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Qualitative analysis</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">We further examine the quality of the synthetic samples produced with <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p1.1.1">silk</span> by conducting a manual evaluation of the top-100 samples of the <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p1.1.2">nlp</span> domain.<span class="ltx_note ltx_role_footnote" id="footnote15"><sup class="ltx_note_mark">15</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">15</sup><span class="ltx_tag ltx_tag_note">15</span>Annotation guidelines and examples can be found inÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#A1.SS3" title="A.3 Guidelines for manual evaluation â€£ Appendix A Appendices â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_tag">A.3</span></a>.</span></span></span>
Annotators were instructed to assess the relevance of silver-standard keyphrases using a 3-point scale: â€œ<span class="ltx_text ltx_font_italic" id="S5.SS3.p1.1.3">not relevant</span>â€, â€œ<span class="ltx_text ltx_font_italic" id="S5.SS3.p1.1.4">partially relevant</span>â€ and â€œ<span class="ltx_text ltx_font_italic" id="S5.SS3.p1.1.5">relevant</span>â€.
Additionally, we requested annotators to assess the well-formedness of the keyphrases with a binary rating.
To quantify the qualitative difference between <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p1.1.6">silk</span> keyphrases and automatically generated ones, we perform a second round of human evaluation for BART-FT utilizing the same top-100 samples.
TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S5.T7" title="Table 7 â€£ 5.3 Qualitative analysis â€£ 5 Results â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_tag">7</span></a> presents the results of our qualitative analysis.
First, we note that nearly all <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p1.1.7">silk</span> keyphrases are well-formed, with any exceptions attributable to tagging errors (e.g.Â â€œ<span class="ltx_text ltx_font_italic" id="S5.SS3.p1.1.8">inter alia</span>â€).
More importantly, we observe that 80% of <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p1.1.9">silk</span> keyphrases are relevant, demonstrating the effectiveness of our method.
In contrast, only 54.5% of the keyphrases generated by BART-FT are deemed relevant, which explains why the self-learning approach to domain adaptation falls short.
We also note that BART-FT tends to generate more keyphrases (<math alttext="\approx" class="ltx_Math" display="inline" id="S5.SS3.p1.1.m1.1"><semantics id="S5.SS3.p1.1.m1.1a"><mo id="S5.SS3.p1.1.m1.1.1" xref="S5.SS3.p1.1.m1.1.1.cmml">â‰ˆ</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.1.m1.1b"><approx id="S5.SS3.p1.1.m1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.1.m1.1c">\approx</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.1.m1.1d">â‰ˆ</annotation></semantics></math>5.5 per doc.), many of which are broader terms that are often irrelevant for the NLP domain (e.g.Â â€œ<span class="ltx_text ltx_font_italic" id="S5.SS3.p1.1.10">natural language processing</span>â€, â€œ<span class="ltx_text ltx_font_italic" id="S5.SS3.p1.1.11">statistics</span>â€ or â€œ<span class="ltx_text ltx_font_italic" id="S5.SS3.p1.1.12">machine learning</span>â€).</p>
</div>
<figure class="ltx_table" id="S5.T7">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T7.1" style="width:433.6pt;height:128.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(95.6pt,-28.4pt) scale(1.78812087836373,1.78812087836373) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T7.1.1">
<tr class="ltx_tr" id="S5.T7.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S5.T7.1.1.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S5.T7.1.1.1.1.1">Model</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S5.T7.1.1.1.2" rowspan="2"><span class="ltx_text ltx_font_bold" id="S5.T7.1.1.1.2.1">#kp</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S5.T7.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S5.T7.1.1.1.3.1">WFness</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S5.T7.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S5.T7.1.1.1.4.1">Relevance</span></td>
</tr>
<tr class="ltx_tr" id="S5.T7.1.1.2">
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T7.1.1.2.1">no</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T7.1.1.2.2">yes</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T7.1.1.2.3">no</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T7.1.1.2.4">part.</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T7.1.1.2.5">yes</td>
</tr>
<tr class="ltx_tr" id="S5.T7.1.1.3">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T7.1.1.3.1">BART-FT</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S5.T7.1.1.3.2">545</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T7.1.1.3.3">6.2</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T7.1.1.3.4">93.8</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T7.1.1.3.5">35.0</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T7.1.1.3.6">10.5</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T7.1.1.3.7">54.5</td>
</tr>
<tr class="ltx_tr" id="S5.T7.1.1.4">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S5.T7.1.1.4.1"><span class="ltx_text ltx_font_typewriter" id="S5.T7.1.1.4.1.1">silk</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_r" id="S5.T7.1.1.4.2">411</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T7.1.1.4.3">2.9</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T7.1.1.4.4">97.1</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T7.1.1.4.5">11.9</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T7.1.1.4.6">8.0</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T7.1.1.4.7">80.0</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Human evaluation results (%) in terms of well-formedness and relevance of the top-100 <span class="ltx_text ltx_font_typewriter" id="S5.T7.4.1">nlp</span> samples generated by <span class="ltx_text ltx_font_typewriter" id="S5.T7.5.2">silk</span> and re-annotated using BART-FT.
</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Bias towards Highly Cited Papers</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1">Since our method leverages citation contexts, it produces synthetic samples that are inherently biased towards highly cited papers and their corresponding keyphrases.
To investigate whether this bias is present in the adapted BART-FT models, we measure how frequently they generate keyphrases found in the synthetic samples and compare this number to that of our initial model.
Results are presented in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#S5.T8" title="Table 8 â€£ 5.4 Bias towards Highly Cited Papers â€£ 5 Results â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_tag">8</span></a>.
We observe only minor differences in the number of generated keyphrases from the synthetic samples, suggesting no apparent bias.
Conversely, we notice that the adapted models produce fewer of these keyphrases, as evidenced by the negative scores.
We attribute this to the few-shot fine-tuning, which may not sufficiently affect the model weights to propagate bias, and reinforces the extractive capabilities of the models, thereby making them less sensitive to bias.</p>
</div>
<figure class="ltx_table" id="S5.T8">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T8.1">
<tr class="ltx_tr" id="S5.T8.1.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S5.T8.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.T8.1.1.1.1">Model</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S5.T8.1.1.2"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S5.T8.1.1.2.1">nlp</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S5.T8.1.1.3"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S5.T8.1.1.3.1">astro</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S5.T8.1.1.4"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S5.T8.1.1.4.1">paleo</span></td>
</tr>
<tr class="ltx_tr" id="S5.T8.1.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T8.1.2.1">+<span class="ltx_text ltx_font_typewriter" id="S5.T8.1.2.1.1">silk</span> (500)</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T8.1.2.2">-0.04</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T8.1.2.3">-0.02</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T8.1.2.4">-0.02</td>
</tr>
<tr class="ltx_tr" id="S5.T8.1.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T8.1.3.1">+<span class="ltx_text ltx_font_typewriter" id="S5.T8.1.3.1.1">silk</span> (1K)</td>
<td class="ltx_td ltx_align_right" id="S5.T8.1.3.2">-0.19</td>
<td class="ltx_td ltx_align_right" id="S5.T8.1.3.3">-0.01</td>
<td class="ltx_td ltx_align_right" id="S5.T8.1.3.4">-0.12</td>
</tr>
<tr class="ltx_tr" id="S5.T8.1.4">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S5.T8.1.4.1">+<span class="ltx_text ltx_font_typewriter" id="S5.T8.1.4.1.1">silk</span> (2K)</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T8.1.4.2">-0.37</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T8.1.4.3">+0.18</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T8.1.4.4">-0.23</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Difference in the number of generated keyphrases found in <span class="ltx_text ltx_font_typewriter" id="S5.T8.3.1">silk</span> samples between BART-FT and its adaptations; a negative number means the adapted model generates fewer keyphrases from highly cited papers.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion and Future Work</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this paper, we propose <span class="ltx_text ltx_font_typewriter" id="S6.p1.1.1">silk</span>, an unsupervised method that relies on citation contexts to create silver-standard data for adapting keyphrase generation models to new domains.
We conduct experiments across three distinct scientific domains and demonstrate the effectiveness of our method for domain adaptation by few-shot fine-tuning a pre-trained model for keyphrase generation.
Our results show significant improvements in in-domain performance with 1K synthetic samples over strong baselines and self-supervised domain adaptation.
We further validate the quality of the synthetic samples created by <span class="ltx_text ltx_font_typewriter" id="S6.p1.1.2">silk</span> through human evaluation and analysis.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">Our work addresses the issue of domain adaptation in keyphrase generation by introducing a solution that leverages citation contexts.
Considering that citing papers is the <span class="ltx_text ltx_font_italic" id="S6.p2.1.1">de-facto</span> means for discussing past work in scientific writing, we argue that it is possible to generate silver-standard data for most domains, provided that there is a minimal number of papers available.
Such data would not only be useful for adapting existing models to new domains but also for keeping them up-to-date, given the rapid expansion of scientific literature and the evolving terminology across all domains.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Limitations</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">While our proposed method is both straightforward and effective, it is important to acknowledge its limitations.
First, we did not optimize each component of our method, relying instead on heuristics for selecting and filtering citation contexts and scoring silver-standard keyphrases using a simple combination of criteria.
Since our work focuses on generating synthetic data for domain adaptation, and we did not search for the optimal fine-tuning parameters, and also relied on a single pre-trained model (BART-base).
Even though we have conducted extensive experiments across three domains, it remains unclear how our findings generalize to other or larger pre-trained models.
Manually evaluating the quality of automatically generated keyphrases is inherently subjective.
Although we developed simple and detailed guidelines to minimize variability in assessments, it remains unclear how the results from our qualitative analysis extend beyond the top 100 samples in <span class="ltx_text ltx_font_typewriter" id="Sx1.p1.1.1">nlp</span> or to the other two domains.</p>
</div>
</section>
<section class="ltx_section" id="Sx2">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>
<div class="ltx_para" id="Sx2.p1">
<p class="ltx_p" id="Sx2.p1.1">This work was supported by the French National Research Agency (ANR) through the DELICES project (ANR-19-CE38-0005-01), and by the Defense Innovation Agency (AID) and the National Centre for Scientific Research (CNRS) through the NaviTerm project (convention 2022 65 0079 CNRS Occitanie Ouest).</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abu-Jbara and Radev (2011)</span>
<span class="ltx_bibblock">
Amjad Abu-Jbara and Dragomir Radev. 2011.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/P11-1051" title="">Coherent citation-based summarization of scientific papers</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</em>, pages 500â€“509, Portland, Oregon, USA. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ahmad etÂ al. (2021)</span>
<span class="ltx_bibblock">
Wasi Ahmad, Xiao Bai, Soomin Lee, and Kai-Wei Chang. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.acl-long.111" title="">Select, extract and generate: Neural keyphrase generation with layer-wise coverage attention</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</em>, pages 1389â€“1404, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bahuleyan and ElÂ Asri (2020)</span>
<span class="ltx_bibblock">
Hareesh Bahuleyan and Layla ElÂ Asri. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.coling-main.462" title="">Diverse keyphrase generation with neural unlikelihood training</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Proceedings of the 28th International Conference on Computational Linguistics</em>, pages 5271â€“5287, Barcelona, Spain (Online). International Committee on Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Boudin (2016)</span>
<span class="ltx_bibblock">
Florian Boudin. 2016.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/C16-2015" title="">pke: an open source python-based keyphrase extraction toolkit</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations</em>, pages 69â€“73, Osaka, Japan. The COLING 2016 Organizing Committee.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Boudin (2018)</span>
<span class="ltx_bibblock">
Florian Boudin. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/N18-2105" title="">Unsupervised keyphrase extraction with multipartite graphs</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)</em>, pages 667â€“672, New Orleans, Louisiana. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Boudin and Gallina (2021)</span>
<span class="ltx_bibblock">
Florian Boudin and Ygor Gallina. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.naacl-main.330" title="">Redefining absent keyphrases and their effect on retrieval effectiveness</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pages 4185â€“4193, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Boudin etÂ al. (2020)</span>
<span class="ltx_bibblock">
Florian Boudin, Ygor Gallina, and Akiko Aizawa. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.acl-main.105" title="">Keyphrase generation for scientific document retrieval</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, pages 1118â€“1126, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Campos etÂ al. (2020)</span>
<span class="ltx_bibblock">
Ricardo Campos, VÃ­tor Mangaravite, Arian Pasquali, AlÃ­pio Jorge, CÃ©lia Nunes, and Adam Jatowt. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/https://doi.org/10.1016/j.ins.2019.09.013" title="">Yake! keyword extraction from single documents using multiple local features</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Information Sciences</em>, 509:257â€“289.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caragea etÂ al. (2014)</span>
<span class="ltx_bibblock">
Cornelia Caragea, FlorinÂ Adrian Bulgarov, Andreea Godea, and Sujatha DasÂ Gollapalli. 2014.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.3115/v1/D14-1150" title="">Citation-enhanced keyphrase extraction from research papers: A supervised approach</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, pages 1435â€“1446, Doha, Qatar. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chau etÂ al. (2020)</span>
<span class="ltx_bibblock">
Hung Chau, Saeid Balaneshin, Kai Liu, and Ondrej Linda. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2020.law-1.7" title="">Understanding the tradeoff between cost and quality of expert annotations for keyphrase extraction</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Proceedings of the 14th Linguistic Annotation Workshop</em>, pages 74â€“86, Barcelona, Spain. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al. (2018)</span>
<span class="ltx_bibblock">
Jun Chen, Xiaoming Zhang, YuÂ Wu, Zhao Yan, and Zhoujun Li. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/D18-1439" title="">Keyphrase generation with correlation constraints</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</em>, pages 4057â€“4066, Brussels, Belgium. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al. (2019)</span>
<span class="ltx_bibblock">
Wang Chen, Yifan Gao, Jiani Zhang, Irwin King, and MichaelÂ R. Lyu. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1609/aaai.v33i01.33016268" title="">Title-guided encoding for keyphrase generation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence and Thirty-First Innovative Applications of Artificial Intelligence Conference and Ninth AAAI Symposium on Educational Advances in Artificial Intelligence</em>, AAAIâ€™19/IAAIâ€™19/EAAIâ€™19. AAAI Press.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cohan etÂ al. (2020)</span>
<span class="ltx_bibblock">
Arman Cohan, Sergey Feldman, IzÂ Beltagy, Doug Downey, and Daniel Weld. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.acl-main.207" title="">SPECTER: Document-level representation learning using citation-informed transformers</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, pages 2270â€“2282, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">DasÂ Gollapalli and Caragea (2014)</span>
<span class="ltx_bibblock">
Sujatha DasÂ Gollapalli and Cornelia Caragea. 2014.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1609/aaai.v28i1.8946" title="">Extracting keyphrases from research papers using citation networks</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of the AAAI Conference on Artificial Intelligence</em>, 28(1).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Do etÂ al. (2023)</span>
<span class="ltx_bibblock">
Lam Do, PritomÂ Saha Akash, and Kevin Chen-Chuan Chang. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.acl-long.592" title="">Unsupervised open-domain keyphrase generation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 10614â€“10627, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fagan (1987)</span>
<span class="ltx_bibblock">
J.Â Fagan. 1987.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/42005.42016" title="">Automatic phrase indexing for document retrieval</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Proceedings of the 10th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</em>, SIGIR â€™87, page 91â€“101, New York, NY, USA. Association for Computing Machinery.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">French (1999)</span>
<span class="ltx_bibblock">
RobertÂ M. French. 1999.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/https://doi.org/10.1016/S1364-6613(99)01294-2" title="">Catastrophic forgetting in connectionist networks</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Trends in Cognitive Sciences</em>, 3(4):128â€“135.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gallina etÂ al. (2019)</span>
<span class="ltx_bibblock">
Ygor Gallina, Florian Boudin, and Beatrice Daille. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/W19-8617" title="">KPTimes: A large-scale dataset for keyphrase generation on news documents</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Proceedings of the 12th International Conference on Natural Language Generation</em>, pages 130â€“135, Tokyo, Japan. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gallina etÂ al. (2020)</span>
<span class="ltx_bibblock">
Ygor Gallina, Florian Boudin, and BÃ©atrice Daille. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3383583.3398517" title="">Large-scale evaluation of keyphrase extraction models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Proceedings of the ACM/IEEE Joint Conference on Digital Libraries in 2020</em>, JCDL â€™20, page 271â€“278, New York, NY, USA. Association for Computing Machinery.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Garg etÂ al. (2022)</span>
<span class="ltx_bibblock">
Krishna Garg, Jishnu RayÂ Chowdhury, and Cornelia Caragea. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.findings-emnlp.427" title="">Keyphrase generation beyond the boundaries of title and abstract</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Findings of the Association for Computational Linguistics: EMNLP 2022</em>, pages 5809â€“5821, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Garg etÂ al. (2023)</span>
<span class="ltx_bibblock">
Krishna Garg, Jishnu RayÂ Chowdhury, and Cornelia Caragea. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.findings-acl.534" title="">Data augmentation for low-resource keyphrase generation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Findings of the Association for Computational Linguistics: ACL 2023</em>, pages 8442â€“8455, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gutwin etÂ al. (1999)</span>
<span class="ltx_bibblock">
Carl Gutwin, Gordon Paynter, Ian Witten, Craig Nevill-Manning, and Eibe Frank. 1999.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/https://doi.org/10.1016/S0167-9236(99)00038-X" title="">Improving browsing in digital libraries with keyphrase indexes</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Decision Support Systems</em>, 27(1):81â€“104.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Houbre etÂ al. (2022)</span>
<span class="ltx_bibblock">
MaÃ«l Houbre, Florian Boudin, and Beatrice Daille. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.louhi-1.6" title="">A large-scale dataset for biomedical keyphrase generation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Proceedings of the 13th International Workshop on Health Text Mining and Information Analysis (LOUHI)</em>, pages 47â€“53, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang etÂ al. (2021)</span>
<span class="ltx_bibblock">
Xiaoli Huang, Tongge Xu, Lvan Jiao, Yueran Zu, and Youmin Zhang. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1609/aaai.v35i14.17546" title="">Adaptive beam search decoding for discrete keyphrase generation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proceedings of the AAAI Conference on Artificial Intelligence</em>, 35(14):13082â€“13089.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hulth (2003)</span>
<span class="ltx_bibblock">
Anette Hulth. 2003.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/W03-1028" title="">Improved automatic keyword extraction given more linguistic knowledge</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing</em>, pages 216â€“223.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jones and Staveley (1999)</span>
<span class="ltx_bibblock">
Steve Jones and MarkÂ S. Staveley. 1999.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/312624.312671" title="">Phrasier: A system for interactive document retrieval using keyphrases</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</em>, SIGIR â€™99, page 160â€“167, New York, NY, USA. Association for Computing Machinery.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim etÂ al. (2021)</span>
<span class="ltx_bibblock">
Jihyuk Kim, Myeongho Jeong, Seungtaek Choi, and Seung-won Hwang. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.emnlp-main.209" title="">Structure-augmented keyphrase generation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</em>, pages 2657â€“2667, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim etÂ al. (2010)</span>
<span class="ltx_bibblock">
SuÂ Nam Kim, Olena Medelyan, Min-Yen Kan, and Timothy Baldwin. 2010.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/S10-1004" title="">SemEval-2010 task 5 : Automatic keyphrase extraction from scientific articles</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Proceedings of the 5th International Workshop on Semantic Evaluation</em>, pages 21â€“26, Uppsala, Sweden. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koto etÂ al. (2022)</span>
<span class="ltx_bibblock">
Fajri Koto, Timothy Baldwin, and JeyÂ Han Lau. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.coling-1.303" title="">LipKey: A large-scale news dataset for absent keyphrases generation and abstractive summarization</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Proceedings of the 29th International Conference on Computational Linguistics</em>, pages 3427â€“3437, Gyeongju, Republic of Korea. International Committee on Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kulkarni etÂ al. (2022)</span>
<span class="ltx_bibblock">
Mayank Kulkarni, Debanjan Mahata, Ravneet Arora, and Rajarshi Bhowmik. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.findings-naacl.67" title="">Learning rich representation of keyphrases from text</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Findings of the Association for Computational Linguistics: NAACL 2022</em>, pages 891â€“906, Seattle, United States. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis etÂ al. (2020)</span>
<span class="ltx_bibblock">
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.acl-main.703" title="">BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, pages 7871â€“7880, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2022)</span>
<span class="ltx_bibblock">
Dingcheng Li, Zheng Chen, Eunah Cho, Jie Hao, Xiaohu Liu, Fan Xing, Chenlei Guo, and Yang Liu. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.naacl-main.398" title="">Overcoming catastrophic forgetting during domain adaptation of seq2seq language generation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pages 5441â€“5454, Seattle, United States. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al. (2021)</span>
<span class="ltx_bibblock">
Yizhu Liu, QiÂ Jia, and Kenny Zhu. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3442381.3449906" title="">Keyword-aware abstractive summarization by extracting set-level intermediate summaries</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Proceedings of the Web Conference 2021</em>, WWW â€™21, page 3042â€“3054, New York, NY, USA. Association for Computing Machinery.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al. (2011)</span>
<span class="ltx_bibblock">
Zhiyuan Liu, Xinxiong Chen, Yabin Zheng, and Maosong Sun. 2011.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/W11-0316" title="">Automatic keyphrase extraction by bridging vocabulary gap</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Proceedings of the Fifteenth Conference on Computational Natural Language Learning</em>, pages 135â€“144, Portland, Oregon, USA. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mahata etÂ al. (2022)</span>
<span class="ltx_bibblock">
Debanjan Mahata, Navneet Agarwal, Dibya Gautam, Amardeep Kumar, Swapnil Parekh, YamanÂ Kumar Singla, Anish Acharya, and RajivÂ Ratn Shah. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2203.15349" title="">Ldkp: A dataset for identifying keyphrases from long scientific documents</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mao etÂ al. (2022)</span>
<span class="ltx_bibblock">
Yuning Mao, Ming Zhong, and Jiawei Han. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.emnlp-main.750" title="">CiteSum: Citation text-guided scientific extreme summarization and domain adaptation with limited supervision</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</em>, pages 10922â€“10935, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mei and Zhai (2008)</span>
<span class="ltx_bibblock">
Qiaozhu Mei and ChengXiang Zhai. 2008.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/P08-1093" title="">Generating impact-based summaries for scientific literature</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Proceedings of ACL-08: HLT</em>, pages 816â€“824, Columbus, Ohio. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meng etÂ al. (2023)</span>
<span class="ltx_bibblock">
Rui Meng, Tong Wang, Xingdi Yuan, Yingbo Zhou, and Daqing He. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.findings-acl.102" title="">General-to-specific transfer labeling for domain adaptable keyphrase generation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Findings of the Association for Computational Linguistics: ACL 2023</em>, pages 1602â€“1618, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meng etÂ al. (2021)</span>
<span class="ltx_bibblock">
Rui Meng, Xingdi Yuan, Tong Wang, Sanqiang Zhao, Adam Trischler, and Daqing He. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.naacl-main.396" title="">An empirical study on neural keyphrase generation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pages 4985â€“5007, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meng etÂ al. (2017)</span>
<span class="ltx_bibblock">
Rui Meng, Sanqiang Zhao, Shuguang Han, Daqing He, Peter Brusilovsky, and YuÂ Chi. 2017.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/P17-1054" title="">Deep keyphrase generation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 582â€“592, Vancouver, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meuschke etÂ al. (2023)</span>
<span class="ltx_bibblock">
Norman Meuschke, Apurva Jagdale, Timo Spinde, Jelena MitroviÄ‡, and Bela Gipp. 2023.

</span>
<span class="ltx_bibblock">A benchmark of pdf information extraction tools using a multi-task and multi-domain evaluation framework for academic documents.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">Information for a Better World: Normality, Virtuality, Physicality, Inclusivity</em>, pages 383â€“405, Cham. Springer Nature Switzerland.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nakov etÂ al. (2004)</span>
<span class="ltx_bibblock">
PreslavÂ I Nakov, ArielÂ S Schwartz, and Marti Hearst. 2004.

</span>
<span class="ltx_bibblock">Citances: Citation sentences for semantic analysis of bioscience text.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">Proceedings of the SIGIRâ€™04 workshop on Search and Discovery in Bioinformatics</em>, volumeÂ 4, pages 81â€“88. Citeseer.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen and Kan (2007)</span>
<span class="ltx_bibblock">
ThuyÂ Dung Nguyen and Min-Yen Kan. 2007.

</span>
<span class="ltx_bibblock">Keyphrase extraction in scientific publications.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">Asian Digital Libraries. Looking Back 10 Years and Forging New Frontiers</em>, pages 317â€“326, Berlin, Heidelberg. Springer Berlin Heidelberg.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rohatgi etÂ al. (2023)</span>
<span class="ltx_bibblock">
Shaurya Rohatgi, Yanxia Qin, Benjamin Aw, Niranjana Unnithan, and Min-Yen Kan. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.emnlp-main.640" title="">The ACL OCL corpus: Advancing open science in computational linguistics</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 10348â€“10361, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saier etÂ al. (2023)</span>
<span class="ltx_bibblock">
Tarek Saier, Johan Krause, and Michael FÃ¤rber. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1109/JCDL57899.2023.00020" title="">unarXive 2022: All arXiv Publications Pre-Processed for NLP, Including Structured Full-Text and Citation Network</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">2023 ACM/IEEE Joint Conference on Digital Libraries (JCDL)</em>, pages 66â€“70, Los Alamitos, CA, USA. IEEE Computer Society.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schwartz and Hearst (2006)</span>
<span class="ltx_bibblock">
ArielÂ S. Schwartz and Marti Hearst. 2006.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/W06-3326" title="">Summarizing key concepts using citation sentences</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">Proceedings of the HLT-NAACL BioNLP Workshop on Linking Natural Language and Biology</em>, pages 134â€“135, New York, New York. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen etÂ al. (2022)</span>
<span class="ltx_bibblock">
Xianjie Shen, Yinghan Wang, Rui Meng, and Jingbo Shang. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1609/aaai.v36i10.21381" title="">Unsupervised deep keyphrase generation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">Proceedings of the AAAI Conference on Artificial Intelligence</em>, 36(10):11303â€“11311.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">vanÂ der Maaten and Hinton (2008)</span>
<span class="ltx_bibblock">
Laurens vanÂ der Maaten and Geoffrey Hinton. 2008.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://jmlr.org/papers/v9/vandermaaten08a.html" title="">Visualizing data using t-sne</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">Journal of Machine Learning Research</em>, 9(86):2579â€“2605.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Viswanathan etÂ al. (2021)</span>
<span class="ltx_bibblock">
Vijay Viswanathan, Graham Neubig, and Pengfei Liu. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.acl-long.59" title="">CitationIE: Leveraging the citation graph for scientific information extraction</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</em>, pages 719â€“731, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wadden etÂ al. (2020)</span>
<span class="ltx_bibblock">
David Wadden, Shanchuan Lin, Kyle Lo, LucyÂ Lu Wang, Madeleine van Zuylen, Arman Cohan, and Hannaneh Hajishirzi. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.emnlp-main.609" title="">Fact or fiction: Verifying scientific claims</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, pages 7534â€“7550, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wan etÂ al. (2007)</span>
<span class="ltx_bibblock">
Xiaojun Wan, Jianwu Yang, and Jianguo Xiao. 2007.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/P07-1070" title="">Towards an iterative reinforcement approach for simultaneous document summarization and keyword extraction</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics</em>, pages 552â€“559, Prague, Czech Republic. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al. (2023)</span>
<span class="ltx_bibblock">
DiÂ Wu, Wasi Ahmad, and Kai-Wei Chang. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.emnlp-main.410" title="">Rethinking model selection and decoding for keyphrase generation with pre-trained sequence-to-sequence models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 6642â€“6658, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al. (2022)</span>
<span class="ltx_bibblock">
DiÂ Wu, Wasi Ahmad, Sunipa Dev, and Kai-Wei Chang. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.findings-emnlp.49" title="">Representation learning for resource-constrained keyphrase generation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">Findings of the Association for Computational Linguistics: EMNLP 2022</em>, pages 700â€“716, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye and Wang (2018)</span>
<span class="ltx_bibblock">
Hai Ye and LuÂ Wang. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/D18-1447" title="">Semi-supervised learning for neural keyphrase generation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</em>, pages 4142â€“4153, Brussels, Belgium. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye etÂ al. (2021)</span>
<span class="ltx_bibblock">
Jiacheng Ye, Tao Gui, Yichao Luo, Yige Xu, and QiÂ Zhang. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.acl-long.354" title="">One2Set: Generating diverse keyphrases as a set</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</em>, pages 4598â€“4608, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yuan etÂ al. (2020)</span>
<span class="ltx_bibblock">
Xingdi Yuan, Tong Wang, Rui Meng, Khushboo Thaker, Peter Brusilovsky, Daqing He, and Adam Trischler. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.acl-main.710" title="">One size does not fit all: Generating and evaluating variable number of keyphrases</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, pages 7961â€“7975, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zha (2002)</span>
<span class="ltx_bibblock">
Hongyuan Zha. 2002.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/564376.564398" title="">Generic summarization and keyphrase extraction using mutual reinforcement principle and sentence clustering</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</em>, SIGIR â€™02, page 113â€“120, New York, NY, USA. Association for Computing Machinery.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhai (1997)</span>
<span class="ltx_bibblock">
Chengxiang Zhai. 1997.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.3115/974557.974603" title="">Fast statistical parsing of noun phrases for document indexing</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">Fifth Conference on Applied Natural Language Processing</em>, pages 312â€“319, Washington, DC, USA. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao etÂ al. (2022)</span>
<span class="ltx_bibblock">
Guangzhen Zhao, Guoshun Yin, Peng Yang, and YuÂ Yao. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.emnlp-main.529" title="">Keyphrase generation via soft and hard semantic corrections</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</em>, pages 7757â€“7768, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao and Zhang (2019)</span>
<span class="ltx_bibblock">
Jing Zhao and Yuxiang Zhang. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/P19-1515" title="">Incorporating linguistic constraints into keyphrase generation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>, pages 5224â€“5233, Florence, Italy. Association for Computational Linguistics.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendices</h2>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Related work</h3>
<div class="ltx_para" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.1">Keyphrase generation was first introduced byÂ <cite class="ltx_cite ltx_citemacro_cite">Liu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib34" title="">2011</a>)</cite> and subsequently formulated as a sequence-to-sequence language generation task byÂ <cite class="ltx_cite ltx_citemacro_cite">Meng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib40" title="">2017</a>)</cite>.
They proposed an RNN-based encoder-decoder model with attention and copy mechanisms, which was later enhanced by the addition of decoding constraints to improve keyphrase diversityÂ <cite class="ltx_cite ltx_citemacro_cite">Chen etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib11" title="">2018</a>); Zhao and Zhang (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib60" title="">2019</a>); Bahuleyan and ElÂ Asri (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib3" title="">2020</a>); Yuan etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib56" title="">2020</a>); Huang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib24" title="">2021</a>)</cite>, or by learning to encode the structural information of input documentsÂ <cite class="ltx_cite ltx_citemacro_cite">Ye and Wang (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib54" title="">2018</a>); Chen etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib12" title="">2019</a>); Kim etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib27" title="">2021</a>)</cite>.
Later work switched to Transformers-based modelsÂ <cite class="ltx_cite ltx_citemacro_cite">Meng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib39" title="">2021</a>); Ye etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib55" title="">2021</a>); Ahmad etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib2" title="">2021</a>)</cite>, reporting better performance.
Recently, pre-trained language models (PLMs) have been used for keyphrase generation, predominantly through continued fine-tuningÂ <cite class="ltx_cite ltx_citemacro_cite">Zhao etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib59" title="">2022</a>); Meng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib38" title="">2023</a>); Wu etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib52" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="A1.SS1.p2">
<p class="ltx_p" id="A1.SS1.p2.1">Our work also intersects with unsupervised models for keyphrase generationÂ <cite class="ltx_cite ltx_citemacro_cite">Shen etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib47" title="">2022</a>); Do etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib15" title="">2023</a>)</cite>, which evaluate the informativeness of keyphrases based on their semantic similarity to the source document.
Another direction to mitigate the data scarcity issue in keyphrase generation involves leveraging both labeled and unlabeled data for training.
<cite class="ltx_cite ltx_citemacro_citet">Ye and Wang (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib54" title="">2018</a>)</cite> proposed a self-learning approach to augment the training data with synthetic samples.
Similarly, <cite class="ltx_cite ltx_citemacro_citet">Meng etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib38" title="">2023</a>)</cite> extended this concept to adapt models to new domains by generating domain-specific synthetic samples.
In a low-resource setting, <cite class="ltx_cite ltx_citemacro_citet">Garg etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib21" title="">2023</a>)</cite> introduced a data augmentation method that leverages the full text of the documents to add diversity to the training samples.</p>
</div>
<div class="ltx_para" id="A1.SS1.p3">
<p class="ltx_p" id="A1.SS1.p3.1">Our work is closely related to the use of citation contexts in automated models for producing keyphrases.
For keyphrase extraction, <cite class="ltx_cite ltx_citemacro_citet">DasÂ Gollapalli and Caragea (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib14" title="">2014</a>)</cite> proposed a graph-ranking approach that leverages citation contexts while scoring candidates, and <cite class="ltx_cite ltx_citemacro_citet">Caragea etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib9" title="">2014</a>)</cite> use the occurrence of candidates in citation contexts as a feature in a supervised model.
For keyphrase generation, <cite class="ltx_cite ltx_citemacro_citet">Garg etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#bib.bib20" title="">2022</a>)</cite> proposed to append citation contexts to enrich the input document.</p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Implementation Details</h3>
<div class="ltx_para" id="A1.SS2.p1">
<p class="ltx_p" id="A1.SS2.p1.1">We use the BART-base model weights as our initial pre-trained language model and perform fine-tuning
on the KP20k training set for 15 epochs.
We use the AdamW optimizer with a learning rate of 1e-5 and a batch size of 24.
Fine-tuning the model using 2 Nvidia GeForce RTX 2080 took 62 hours.</p>
</div>
<div class="ltx_para" id="A1.SS2.p2">
<p class="ltx_p" id="A1.SS2.p2.1">For adapting BART-FT to a each domain, we continue fine-tuning on <math alttext="N\in\{500,1K,2K\}" class="ltx_Math" display="inline" id="A1.SS2.p2.1.m1.3"><semantics id="A1.SS2.p2.1.m1.3a"><mrow id="A1.SS2.p2.1.m1.3.3" xref="A1.SS2.p2.1.m1.3.3.cmml"><mi id="A1.SS2.p2.1.m1.3.3.4" xref="A1.SS2.p2.1.m1.3.3.4.cmml">N</mi><mo id="A1.SS2.p2.1.m1.3.3.3" xref="A1.SS2.p2.1.m1.3.3.3.cmml">âˆˆ</mo><mrow id="A1.SS2.p2.1.m1.3.3.2.2" xref="A1.SS2.p2.1.m1.3.3.2.3.cmml"><mo id="A1.SS2.p2.1.m1.3.3.2.2.3" stretchy="false" xref="A1.SS2.p2.1.m1.3.3.2.3.cmml">{</mo><mn id="A1.SS2.p2.1.m1.1.1" xref="A1.SS2.p2.1.m1.1.1.cmml">500</mn><mo id="A1.SS2.p2.1.m1.3.3.2.2.4" xref="A1.SS2.p2.1.m1.3.3.2.3.cmml">,</mo><mrow id="A1.SS2.p2.1.m1.2.2.1.1.1" xref="A1.SS2.p2.1.m1.2.2.1.1.1.cmml"><mn id="A1.SS2.p2.1.m1.2.2.1.1.1.2" xref="A1.SS2.p2.1.m1.2.2.1.1.1.2.cmml">1</mn><mo id="A1.SS2.p2.1.m1.2.2.1.1.1.1" xref="A1.SS2.p2.1.m1.2.2.1.1.1.1.cmml">â¢</mo><mi id="A1.SS2.p2.1.m1.2.2.1.1.1.3" xref="A1.SS2.p2.1.m1.2.2.1.1.1.3.cmml">K</mi></mrow><mo id="A1.SS2.p2.1.m1.3.3.2.2.5" xref="A1.SS2.p2.1.m1.3.3.2.3.cmml">,</mo><mrow id="A1.SS2.p2.1.m1.3.3.2.2.2" xref="A1.SS2.p2.1.m1.3.3.2.2.2.cmml"><mn id="A1.SS2.p2.1.m1.3.3.2.2.2.2" xref="A1.SS2.p2.1.m1.3.3.2.2.2.2.cmml">2</mn><mo id="A1.SS2.p2.1.m1.3.3.2.2.2.1" xref="A1.SS2.p2.1.m1.3.3.2.2.2.1.cmml">â¢</mo><mi id="A1.SS2.p2.1.m1.3.3.2.2.2.3" xref="A1.SS2.p2.1.m1.3.3.2.2.2.3.cmml">K</mi></mrow><mo id="A1.SS2.p2.1.m1.3.3.2.2.6" stretchy="false" xref="A1.SS2.p2.1.m1.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p2.1.m1.3b"><apply id="A1.SS2.p2.1.m1.3.3.cmml" xref="A1.SS2.p2.1.m1.3.3"><in id="A1.SS2.p2.1.m1.3.3.3.cmml" xref="A1.SS2.p2.1.m1.3.3.3"></in><ci id="A1.SS2.p2.1.m1.3.3.4.cmml" xref="A1.SS2.p2.1.m1.3.3.4">ğ‘</ci><set id="A1.SS2.p2.1.m1.3.3.2.3.cmml" xref="A1.SS2.p2.1.m1.3.3.2.2"><cn id="A1.SS2.p2.1.m1.1.1.cmml" type="integer" xref="A1.SS2.p2.1.m1.1.1">500</cn><apply id="A1.SS2.p2.1.m1.2.2.1.1.1.cmml" xref="A1.SS2.p2.1.m1.2.2.1.1.1"><times id="A1.SS2.p2.1.m1.2.2.1.1.1.1.cmml" xref="A1.SS2.p2.1.m1.2.2.1.1.1.1"></times><cn id="A1.SS2.p2.1.m1.2.2.1.1.1.2.cmml" type="integer" xref="A1.SS2.p2.1.m1.2.2.1.1.1.2">1</cn><ci id="A1.SS2.p2.1.m1.2.2.1.1.1.3.cmml" xref="A1.SS2.p2.1.m1.2.2.1.1.1.3">ğ¾</ci></apply><apply id="A1.SS2.p2.1.m1.3.3.2.2.2.cmml" xref="A1.SS2.p2.1.m1.3.3.2.2.2"><times id="A1.SS2.p2.1.m1.3.3.2.2.2.1.cmml" xref="A1.SS2.p2.1.m1.3.3.2.2.2.1"></times><cn id="A1.SS2.p2.1.m1.3.3.2.2.2.2.cmml" type="integer" xref="A1.SS2.p2.1.m1.3.3.2.2.2.2">2</cn><ci id="A1.SS2.p2.1.m1.3.3.2.2.2.3.cmml" xref="A1.SS2.p2.1.m1.3.3.2.2.2.3">ğ¾</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p2.1.m1.3c">N\in\{500,1K,2K\}</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p2.1.m1.3d">italic_N âˆˆ { 500 , 1 italic_K , 2 italic_K }</annotation></semantics></math> synthetic samples for 3 epochs.
We use the AdamW optimizer with a learning rate of 1e-6 and a batch size of 16.
Few-shot fine-tuning, conducted on a MacBook Pro M1 Max, required an average of 5 minutes per model, totaling 3 hours for all 12 models per domain.</p>
</div>
<div class="ltx_para" id="A1.SS2.p3">
<p class="ltx_p" id="A1.SS2.p3.1">For MultiPartiteRank, we use the authorâ€™s implementation provided by the <span class="ltx_text ltx_font_typewriter" id="A1.SS2.p3.1.1">pke</span> toolkit.<span class="ltx_note ltx_role_footnote" id="footnote16"><sup class="ltx_note_mark">16</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">16</sup><span class="ltx_tag ltx_tag_note">16</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/boudinfl/pke" title="">https://github.com/boudinfl/pke</a></span></span></span>
For Yake, we use the authorâ€™s implementation.<span class="ltx_note ltx_role_footnote" id="footnote17"><sup class="ltx_note_mark">17</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">17</sup><span class="ltx_tag ltx_tag_note">17</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/LIAAD/yake" title="">https://github.com/LIAAD/yake</a></span></span></span>
For KeyBART, we use the model weights released by the authors and the suggested parameter settings (i.e.Â beam width = 50, maximum generated sequence length = 40 tokens).<span class="ltx_note ltx_role_footnote" id="footnote18"><sup class="ltx_note_mark">18</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">18</sup><span class="ltx_tag ltx_tag_note">18</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/bloomberg/KeyBART" title="">https://huggingface.co/bloomberg/KeyBART</a></span></span></span>
For One2Set, we use the model weights released by the authors.<span class="ltx_note ltx_role_footnote" id="footnote19"><sup class="ltx_note_mark">19</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">19</sup><span class="ltx_tag ltx_tag_note">19</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/jiacheng-ye/kg_one2set" title="">https://github.com/jiacheng-ye/kg_one2set</a></span></span></span></p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Guidelines for manual evaluation</h3>
<div class="ltx_para" id="A1.SS3.p1">
<p class="ltx_p" id="A1.SS3.p1.1">We evaluate the silver-standard keyphrases created by <span class="ltx_text ltx_font_typewriter" id="A1.SS3.p1.1.1">silk</span> and those generated by BART-FT along two criteria: their relevance with respect to the source document, and their well-formedness.
Annotators (authors of this paper) were given the title, the abstract and access to the full-text paper when evaluating the quality of the keyphrases.
We perform manual evaluation on the top-100 synthetic samples generated by <span class="ltx_text ltx_font_typewriter" id="A1.SS3.p1.1.2">silk</span>, confined to the <span class="ltx_text ltx_font_typewriter" id="A1.SS3.p1.1.3">nlp</span> domain for which annotators have expertise.</p>
<ol class="ltx_enumerate" id="A1.I1">
<li class="ltx_item" id="A1.I1.ix1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="A1.I1.ix1.1.1.1">Relevance</span></span>
<div class="ltx_para" id="A1.I1.ix1.p1">
<p class="ltx_p" id="A1.I1.ix1.p1.1">is assessed on a 3-point scale, where 0 indicates that the keyphrase is not relevant, 1 that it is partially relevant (i.e.Â covering a related concept) and 2 that it is relevant to the source document.</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.ix2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="A1.I1.ix2.1.1.1">Well-formedness</span></span>
<div class="ltx_para" id="A1.I1.ix2.p1">
<p class="ltx_p" id="A1.I1.ix2.p1.1">is assessed on a binary scale, with 0 indicating that the keyphrase lacks proper form, such as being improperly structured (e.g.Â â€œ<span class="ltx_text ltx_font_italic" id="A1.I1.ix2.p1.1.1">algorithms and data structures</span>â€) or not forming a self-contained phrase (e.g.Â â€œ<span class="ltx_text ltx_font_italic" id="A1.I1.ix2.p1.1.2">large amount</span>â€), while 1 signifies that the keyphrase is well-formed.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="A1.SS3.p2">
<p class="ltx_p" id="A1.SS3.p2.1">Orthographic variants occurring in a set of keyphrases (e.g.Â â€œ<span class="ltx_text ltx_font_italic" id="A1.SS3.p2.1.1">co-reference resolution</span>â€ and â€œ<span class="ltx_text ltx_font_italic" id="A1.SS3.p2.1.2">coreference resolution</span>â€) are identified, and only one of them is considered as relevant.
We do not consider abbreviations as variants of their expanded forms.
Broader terms such as â€œ<span class="ltx_text ltx_font_italic" id="A1.SS3.p2.1.3">natural language processing</span>â€ or â€œ<span class="ltx_text ltx_font_italic" id="A1.SS3.p2.1.4">neural networks</span>â€ are generally considered as too generic and not relevant.</p>
</div>
<div class="ltx_para" id="A1.SS3.p3">
<p class="ltx_p" id="A1.SS3.p3.1">An example of output for <span class="ltx_text ltx_font_typewriter" id="A1.SS3.p3.1.1">silk</span> and BART-FT is shown is TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.13266v2#A1.T9" title="Table 9 â€£ A.3 Guidelines for manual evaluation â€£ Appendix A Appendices â€£ Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"><span class="ltx_text ltx_ref_tag">9</span></a>.</p>
</div>
<figure class="ltx_table" id="A1.T9">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A1.T9.1" style="width:433.6pt;height:435.8pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-36.2pt,36.3pt) scale(0.856860622669243,0.856860622669243) ;">
<table class="ltx_tabular ltx_align_middle" id="A1.T9.1.1">
<tr class="ltx_tr" id="A1.T9.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" colspan="2" id="A1.T9.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T9.1.1.1.1.1">
<span class="ltx_p" id="A1.T9.1.1.1.1.1.1" style="width:433.6pt;">
<span class="ltx_text ltx_font_bold" id="A1.T9.1.1.1.1.1.1.1">Get To The Point: Summarization with Pointer-Generator Networks</span> (Bibkey: see-etal-2017-get)</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T9.1.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="2" id="A1.T9.1.1.2.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T9.1.1.2.1.1">
<span class="ltx_p" id="A1.T9.1.1.2.1.1.1" style="width:433.6pt;">
Neural sequence-to-sequence models have provided a viable new approach for abstractive text summarization (meaning they are not restricted to simply selecting and rearranging passages from the original text). However, these models have two shortcomings: they are liable to reproduce factual details inaccurately, and they tend to repeat themselves. In this work we propose a novel architecture that augments the standard sequence-to-sequence attentional model in two orthogonal ways. First, we use a hybrid pointer-generator network that can copy words from the source text via pointing, which aids accurate reproduction of information, while retaining the ability to produce novel words through the generator. Second, we use coverage to keep track of what has been summarized, which discourages repetition. We apply our model to the CNN / Daily Mail summarization task, outperforming the current abstractive state-of-the-art by at least 2 ROUGE points.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T9.1.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T9.1.1.3.1"><span class="ltx_text ltx_font_typewriter" id="A1.T9.1.1.3.1.1">silk</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T9.1.1.3.2">summarization, pointer-generator network, sequence-to-sequence model, copy mechanism, coverage mechanism</td>
</tr>
<tr class="ltx_tr" id="A1.T9.1.1.4">
<td class="ltx_td" id="A1.T9.1.1.4.1" style="padding-bottom:3.00003pt;"></td>
<td class="ltx_td ltx_align_left" id="A1.T9.1.1.4.2" style="padding-bottom:3.00003pt;">well-formedness: 1 1 1 1 1 â€ƒrelevance: 1 1 1 1 1</td>
</tr>
<tr class="ltx_tr" id="A1.T9.1.1.5">
<td class="ltx_td ltx_align_left" id="A1.T9.1.1.5.1">BART-FT</td>
<td class="ltx_td ltx_align_left" id="A1.T9.1.1.5.2">summarization, sequence-to-sequence models, attentional models, cnn, daily mail, neural networks, text mining</td>
</tr>
<tr class="ltx_tr" id="A1.T9.1.1.6">
<td class="ltx_td" id="A1.T9.1.1.6.1"></td>
<td class="ltx_td ltx_align_left" id="A1.T9.1.1.6.2">well-formedness: 1 1 1 1 1 1 1 â€ƒrelevance: 1 1 1 1 1 0 0</td>
</tr>
<tr class="ltx_tr" id="A1.T9.1.1.7">
<td class="ltx_td ltx_align_left ltx_border_tt ltx_border_tt" colspan="2" id="A1.T9.1.1.7.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T9.1.1.7.1.1">
<span class="ltx_p" id="A1.T9.1.1.7.1.1.1" style="width:433.6pt;">
<span class="ltx_text ltx_font_bold" id="A1.T9.1.1.7.1.1.1.1">Improving Neural Machine Translation Models with Monolingual Data</span> (Bibkey: sennrich-etal-2016-improving)</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T9.1.1.8">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="2" id="A1.T9.1.1.8.1">
<span class="ltx_inline-block ltx_align_top" id="A1.T9.1.1.8.1.1">
<span class="ltx_p" id="A1.T9.1.1.8.1.1.1" style="width:433.6pt;">
Neural Machine Translation (NMT) has obtained state-of-the art performance for several language pairs, while only using parallel data for training. Target-side monolingual data plays an important role in boosting fluency for phrase-based statistical machine translation, and we investigate the use of monolingual data for NMT. In contrast to previous work, which combines NMT models with separately trained language models, we note that encoder-decoder NMT architectures already have the capacity to learn the same information as a language model, and we explore strategies to train with monolingual data without changing the neural network architecture. By pairing monolingual training data with an automatic back-translation, we can treat it as additional parallel training data, and we obtain substantial improvements on the WMT 15 task English German (+2.8-3.7 BLEU), and for the low-resourced IWSLT 14 task Turkish-&gt;English (+2.1-3.4 BLEU), obtaining new state-of-the-art results. We also show that fine-tuning on in-domain monolingual and parallel data gives substantial improvements for the IWSLT 15 task English-&gt;German.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T9.1.1.9">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T9.1.1.9.1"><span class="ltx_text ltx_font_typewriter" id="A1.T9.1.1.9.1.1">silk</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T9.1.1.9.2">neural machine translation, monolingual data, back-translation, data augmentation, synthetic parallel corpus</td>
</tr>
<tr class="ltx_tr" id="A1.T9.1.1.10">
<td class="ltx_td" id="A1.T9.1.1.10.1" style="padding-bottom:3.00003pt;"></td>
<td class="ltx_td ltx_align_left" id="A1.T9.1.1.10.2" style="padding-bottom:3.00003pt;">well-formedness: 1 1 1 1 1 â€ƒrelevance: 1 1 1 1 1</td>
</tr>
<tr class="ltx_tr" id="A1.T9.1.1.11">
<td class="ltx_td ltx_align_left" id="A1.T9.1.1.11.1">BART-FT</td>
<td class="ltx_td ltx_align_left" id="A1.T9.1.1.11.2">neural machine translation, monolingual data, language models, back-translation, language modeling and</td>
</tr>
<tr class="ltx_tr" id="A1.T9.1.1.12">
<td class="ltx_td" id="A1.T9.1.1.12.1"></td>
<td class="ltx_td ltx_align_left" id="A1.T9.1.1.12.2">translation, parallel training data</td>
</tr>
<tr class="ltx_tr" id="A1.T9.1.1.13">
<td class="ltx_td ltx_border_bb" id="A1.T9.1.1.13.1" style="padding-bottom:3.00003pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T9.1.1.13.2" style="padding-bottom:3.00003pt;">well-formedness: 1 1 1 1 0 1 â€ƒrelevance: 1 1 1 1 0 0.5</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>Examples of document (title and abstract) from the <span class="ltx_text ltx_font_typewriter" id="A1.T9.4.1">nlp</span> domain with silver-standard keyphrases generated by <span class="ltx_text ltx_font_typewriter" id="A1.T9.5.2">silk</span> and automatically generated keyphrases from BART-FT.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_subsection" id="A1.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.4 </span>Sources used for collecting test data</h3>
<figure class="ltx_table" id="A1.T10">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A1.T10.1" style="width:216.8pt;height:197.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-40.1pt,36.4pt) scale(0.73013525903074,0.73013525903074) ;">
<table class="ltx_tabular ltx_align_middle" id="A1.T10.1.1">
<tr class="ltx_tr" id="A1.T10.1.1.1">
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="A1.T10.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.T10.1.1.1.1.1">Source</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T10.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A1.T10.1.1.1.2.1">Session / Volume</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="A1.T10.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A1.T10.1.1.1.3.1">#nb</span></td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.1.2">
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="A1.T10.1.1.2.1">SIGIR 2023</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T10.1.1.2.2">Language Models</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T10.1.1.2.3">6</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.1.3">
<td class="ltx_td ltx_border_r" id="A1.T10.1.1.3.1"></td>
<td class="ltx_td ltx_align_left" id="A1.T10.1.1.3.2">Question Answering</td>
<td class="ltx_td ltx_align_right" id="A1.T10.1.1.3.3">3</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.1.4">
<td class="ltx_td ltx_border_r" id="A1.T10.1.1.4.1"></td>
<td class="ltx_td ltx_align_left" id="A1.T10.1.1.4.2">Summarization &amp; Text Generation</td>
<td class="ltx_td ltx_align_right" id="A1.T10.1.1.4.3">5</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.1.5">
<td class="ltx_td ltx_border_r" id="A1.T10.1.1.5.1"></td>
<td class="ltx_td ltx_align_left" id="A1.T10.1.1.5.2">Short Research Papers<sup class="ltx_sup" id="A1.T10.1.1.5.2.1"><span class="ltx_ERROR undefined" id="A1.T10.1.1.5.2.1.1">\faHandPaper</span>[regular]</sup>
</td>
<td class="ltx_td ltx_align_right" id="A1.T10.1.1.5.3">16</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.1.6">
<td class="ltx_td ltx_align_right ltx_border_r" id="A1.T10.1.1.6.1">CIKM 2023</td>
<td class="ltx_td ltx_align_left" id="A1.T10.1.1.6.2">Natural Language</td>
<td class="ltx_td ltx_align_right" id="A1.T10.1.1.6.3">24</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.1.7">
<td class="ltx_td ltx_align_right ltx_border_r" id="A1.T10.1.1.7.1">WSDM 2023</td>
<td class="ltx_td ltx_align_left" id="A1.T10.1.1.7.2">Language Models and Text Mining</td>
<td class="ltx_td ltx_align_right" id="A1.T10.1.1.7.3">6</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.1.8">
<td class="ltx_td ltx_align_right ltx_border_r" id="A1.T10.1.1.8.1">SIGIR 2022</td>
<td class="ltx_td ltx_align_left" id="A1.T10.1.1.8.2">NLP and Semantics</td>
<td class="ltx_td ltx_align_right" id="A1.T10.1.1.8.3">8</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.1.9">
<td class="ltx_td ltx_border_r" id="A1.T10.1.1.9.1"></td>
<td class="ltx_td ltx_align_left" id="A1.T10.1.1.9.2">Question Answering</td>
<td class="ltx_td ltx_align_right" id="A1.T10.1.1.9.3">4</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.1.10">
<td class="ltx_td ltx_border_r" id="A1.T10.1.1.10.1"></td>
<td class="ltx_td ltx_align_left" id="A1.T10.1.1.10.2">Sentiment Analysis and Classification</td>
<td class="ltx_td ltx_align_right" id="A1.T10.1.1.10.3">5</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.1.11">
<td class="ltx_td ltx_border_r" id="A1.T10.1.1.11.1"></td>
<td class="ltx_td ltx_align_left" id="A1.T10.1.1.11.2">Short Research Papers<sup class="ltx_sup" id="A1.T10.1.1.11.2.1"><span class="ltx_ERROR undefined" id="A1.T10.1.1.11.2.1.1">\faHandPaper</span>[regular]</sup>
</td>
<td class="ltx_td ltx_align_right" id="A1.T10.1.1.11.3">14</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.1.12">
<td class="ltx_td ltx_align_right ltx_border_r" id="A1.T10.1.1.12.1">CHI 2022</td>
<td class="ltx_td ltx_align_left" id="A1.T10.1.1.12.2">Natural Language</td>
<td class="ltx_td ltx_align_right" id="A1.T10.1.1.12.3">5</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.1.13">
<td class="ltx_td ltx_align_right ltx_border_r" id="A1.T10.1.1.13.1">LREC 2022</td>
<td class="ltx_td ltx_align_left" id="A1.T10.1.1.13.2">Oral sessions<sup class="ltx_sup" id="A1.T10.1.1.13.2.1"><span class="ltx_ERROR undefined" id="A1.T10.1.1.13.2.1.1">\faHandPaper</span>[regular]</sup>
</td>
<td class="ltx_td ltx_align_right" id="A1.T10.1.1.13.3">81</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.1.14">
<td class="ltx_td ltx_align_right ltx_border_r" id="A1.T10.1.1.14.1">NLP Journal<span class="ltx_note ltx_role_footnote" id="footnote20"><sup class="ltx_note_mark">20</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">20</sup><span class="ltx_tag ltx_tag_note">20</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.sciencedirect.com/journal/natural-language-processing-journal" title="">https://www.sciencedirect.com/journal/natural-language-processing-journal</a></span></span></span>
</td>
<td class="ltx_td ltx_align_left" id="A1.T10.1.1.14.2">Volumes 2-5</td>
<td class="ltx_td ltx_align_right" id="A1.T10.1.1.14.3">35</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.1.15">
<td class="ltx_td ltx_border_bb ltx_border_r ltx_border_t" id="A1.T10.1.1.15.1"></td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="A1.T10.1.1.15.2">Total</td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="A1.T10.1.1.15.3">212</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 10: </span>Detailed information on the sources of the test documents for the <span class="ltx_text ltx_font_typewriter" id="A1.T10.4.1">nlp</span> domain. <span class="ltx_ERROR undefined" id="A1.T10.5.2">\faHandPaper</span>[regular] indicates that we manually selected the documents to filter out out-of-domain ones.</figcaption>
</figure>
<figure class="ltx_table" id="A1.T11">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A1.T11.1" style="width:216.8pt;height:101.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-84.5pt,39.4pt) scale(0.561925589150715,0.561925589150715) ;">
<table class="ltx_tabular ltx_align_middle" id="A1.T11.1.1">
<tr class="ltx_tr" id="A1.T11.1.1.2">
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="A1.T11.1.1.2.1"><span class="ltx_text ltx_font_bold" id="A1.T11.1.1.2.1.1">Source</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T11.1.1.2.2"><span class="ltx_text ltx_font_bold" id="A1.T11.1.1.2.2.1">Category / Year</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="A1.T11.1.1.2.3"><span class="ltx_text ltx_font_bold" id="A1.T11.1.1.2.3.1">#nb</span></td>
</tr>
<tr class="ltx_tr" id="A1.T11.1.1.3">
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="A1.T11.1.1.3.1">arXiv</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T11.1.1.3.2">astro-ph.HE (High Energy Astro. Phenomena)</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T11.1.1.3.3">20</td>
</tr>
<tr class="ltx_tr" id="A1.T11.1.1.1">
<td class="ltx_td ltx_align_right ltx_border_r" id="A1.T11.1.1.1.1">(oct<math alttext="\rightarrow" class="ltx_Math" display="inline" id="A1.T11.1.1.1.1.m1.1"><semantics id="A1.T11.1.1.1.1.m1.1a"><mo id="A1.T11.1.1.1.1.m1.1.1" stretchy="false" xref="A1.T11.1.1.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="A1.T11.1.1.1.1.m1.1b"><ci id="A1.T11.1.1.1.1.m1.1.1.cmml" xref="A1.T11.1.1.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T11.1.1.1.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="A1.T11.1.1.1.1.m1.1d">â†’</annotation></semantics></math>dec 2023)</td>
<td class="ltx_td ltx_align_left" id="A1.T11.1.1.1.2">astro-ph.CO (Cosmology and Nongalactic Astro.)</td>
<td class="ltx_td ltx_align_right" id="A1.T11.1.1.1.3">20</td>
</tr>
<tr class="ltx_tr" id="A1.T11.1.1.4">
<td class="ltx_td ltx_border_r" id="A1.T11.1.1.4.1"></td>
<td class="ltx_td ltx_align_left" id="A1.T11.1.1.4.2">astro-ph.IM (Instrumentation and Methods for Astro.)</td>
<td class="ltx_td ltx_align_right" id="A1.T11.1.1.4.3">20</td>
</tr>
<tr class="ltx_tr" id="A1.T11.1.1.5">
<td class="ltx_td ltx_border_r" id="A1.T11.1.1.5.1"></td>
<td class="ltx_td ltx_align_left" id="A1.T11.1.1.5.2">astro-ph.SR (Solar and Stellar Astro.)</td>
<td class="ltx_td ltx_align_right" id="A1.T11.1.1.5.3">20</td>
</tr>
<tr class="ltx_tr" id="A1.T11.1.1.6">
<td class="ltx_td ltx_border_r" id="A1.T11.1.1.6.1"></td>
<td class="ltx_td ltx_align_left" id="A1.T11.1.1.6.2">astro-ph.EP (Earth and Planetary Astro.)</td>
<td class="ltx_td ltx_align_right" id="A1.T11.1.1.6.3">20</td>
</tr>
<tr class="ltx_tr" id="A1.T11.1.1.7">
<td class="ltx_td ltx_border_r" id="A1.T11.1.1.7.1"></td>
<td class="ltx_td ltx_align_left" id="A1.T11.1.1.7.2">astro-ph.GA (Astro. of Galaxies)</td>
<td class="ltx_td ltx_align_right" id="A1.T11.1.1.7.3">20</td>
</tr>
<tr class="ltx_tr" id="A1.T11.1.1.8">
<td class="ltx_td ltx_align_right ltx_border_r" id="A1.T11.1.1.8.1">Frontiers in Astro.</td>
<td class="ltx_td ltx_align_left" id="A1.T11.1.1.8.2">2022-23 (selected using arXiv keywords)</td>
<td class="ltx_td ltx_align_right" id="A1.T11.1.1.8.3">76</td>
</tr>
<tr class="ltx_tr" id="A1.T11.1.1.9">
<td class="ltx_td ltx_align_right ltx_border_r" id="A1.T11.1.1.9.1">Astrophysics</td>
<td class="ltx_td ltx_align_left" id="A1.T11.1.1.9.2">2022-23</td>
<td class="ltx_td ltx_align_right" id="A1.T11.1.1.9.3">59</td>
</tr>
<tr class="ltx_tr" id="A1.T11.1.1.10">
<td class="ltx_td ltx_border_bb ltx_border_r ltx_border_t" id="A1.T11.1.1.10.1"></td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="A1.T11.1.1.10.2">Total</td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="A1.T11.1.1.10.3">255</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 11: </span>Detailed information on the sources of the test documents for the <span class="ltx_text ltx_font_typewriter" id="A1.T11.3.1">astro</span> domain.</figcaption>
</figure>
<figure class="ltx_table" id="A1.T12">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A1.T12.1" style="width:216.8pt;height:133.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-52.9pt,32.5pt) scale(0.672161900982845,0.672161900982845) ;">
<table class="ltx_tabular ltx_align_middle" id="A1.T12.1.1">
<tr class="ltx_tr" id="A1.T12.1.1.1">
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="A1.T12.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.T12.1.1.1.1.1">Source</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T12.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A1.T12.1.1.1.2.1">Year</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="A1.T12.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A1.T12.1.1.1.3.1">#nb</span></td>
</tr>
<tr class="ltx_tr" id="A1.T12.1.1.2">
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="A1.T12.1.1.2.1">Palaeontologia Electronica</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T12.1.1.2.2">2023-24</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T12.1.1.2.3">21</td>
</tr>
<tr class="ltx_tr" id="A1.T12.1.1.3">
<td class="ltx_td ltx_align_right ltx_border_r" id="A1.T12.1.1.3.1">Acta Palaeontologica Polonica</td>
<td class="ltx_td ltx_align_left" id="A1.T12.1.1.3.2">2023</td>
<td class="ltx_td ltx_align_right" id="A1.T12.1.1.3.3">22</td>
</tr>
<tr class="ltx_tr" id="A1.T12.1.1.4">
<td class="ltx_td ltx_align_right ltx_border_r" id="A1.T12.1.1.4.1">Palaeontology</td>
<td class="ltx_td ltx_align_left" id="A1.T12.1.1.4.2">2023</td>
<td class="ltx_td ltx_align_right" id="A1.T12.1.1.4.3">26</td>
</tr>
<tr class="ltx_tr" id="A1.T12.1.1.5">
<td class="ltx_td ltx_align_right ltx_border_r" id="A1.T12.1.1.5.1">Cretaceous Research</td>
<td class="ltx_td ltx_align_left" id="A1.T12.1.1.5.2">2024</td>
<td class="ltx_td ltx_align_right" id="A1.T12.1.1.5.3">20</td>
</tr>
<tr class="ltx_tr" id="A1.T12.1.1.6">
<td class="ltx_td ltx_align_right ltx_border_r" id="A1.T12.1.1.6.1">Palaeogeography, Palaeoclimatology, Palaeoecology</td>
<td class="ltx_td ltx_align_left" id="A1.T12.1.1.6.2">2024</td>
<td class="ltx_td ltx_align_right" id="A1.T12.1.1.6.3">47</td>
</tr>
<tr class="ltx_tr" id="A1.T12.1.1.7">
<td class="ltx_td ltx_align_right ltx_border_r" id="A1.T12.1.1.7.1">Papers in Palaeontology</td>
<td class="ltx_td ltx_align_left" id="A1.T12.1.1.7.2">2023</td>
<td class="ltx_td ltx_align_right" id="A1.T12.1.1.7.3">29</td>
</tr>
<tr class="ltx_tr" id="A1.T12.1.1.8">
<td class="ltx_td ltx_align_right ltx_border_r" id="A1.T12.1.1.8.1">Proc. Royal Soc. B: Biological Sciences</td>
<td class="ltx_td ltx_align_left" id="A1.T12.1.1.8.2">2023</td>
<td class="ltx_td ltx_align_right" id="A1.T12.1.1.8.3">25</td>
</tr>
<tr class="ltx_tr" id="A1.T12.1.1.9">
<td class="ltx_td ltx_align_right ltx_border_r" id="A1.T12.1.1.9.1">Biology Letters</td>
<td class="ltx_td ltx_align_left" id="A1.T12.1.1.9.2">2023</td>
<td class="ltx_td ltx_align_right" id="A1.T12.1.1.9.3">25</td>
</tr>
<tr class="ltx_tr" id="A1.T12.1.1.10">
<td class="ltx_td ltx_align_right ltx_border_r" id="A1.T12.1.1.10.1">Palaeobiodiversity and Palaeoenvironments</td>
<td class="ltx_td ltx_align_left" id="A1.T12.1.1.10.2">2023</td>
<td class="ltx_td ltx_align_right" id="A1.T12.1.1.10.3">16</td>
</tr>
<tr class="ltx_tr" id="A1.T12.1.1.11">
<td class="ltx_td ltx_border_bb ltx_border_r ltx_border_t" id="A1.T12.1.1.11.1"></td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="A1.T12.1.1.11.2">Total</td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="A1.T12.1.1.11.3">244</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 12: </span>Detailed information on the sources of the test documents for the <span class="ltx_text ltx_font_typewriter" id="A1.T12.3.1">paleo</span> domain.</figcaption>
</figure>
<figure class="ltx_table" id="A1.T13">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A1.T13.1" style="width:433.6pt;height:499.9pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-17.8pt,20.5pt) scale(0.924013736979165,0.924013736979165) ;">
<table class="ltx_tabular ltx_align_middle" id="A1.T13.1.1">
<tr class="ltx_tr" id="A1.T13.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T13.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.T13.1.1.1.1.1">Source</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T13.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A1.T13.1.1.1.2.1">Licence</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T13.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A1.T13.1.1.1.3.1">Year</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="A1.T13.1.1.1.4"><span class="ltx_text ltx_font_bold" id="A1.T13.1.1.1.4.1">#nb</span></td>
</tr>
<tr class="ltx_tr" id="A1.T13.1.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T13.1.1.2.1">Acta Geologica Sinica</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T13.1.1.2.2">open</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T13.1.1.2.3">2021-2023</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T13.1.1.2.4">21</td>
</tr>
<tr class="ltx_tr" id="A1.T13.1.1.3">
<td class="ltx_td ltx_align_left" id="A1.T13.1.1.3.1">Acta Palaeontologica Polonica</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.3.2">open</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.3.3">2002-2023</td>
<td class="ltx_td ltx_align_right" id="A1.T13.1.1.3.4">1â€‰398</td>
</tr>
<tr class="ltx_tr" id="A1.T13.1.1.4">
<td class="ltx_td ltx_align_left" id="A1.T13.1.1.4.1">Alcheringa: An Australasian Journal of Palaeontology</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.4.2">open</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.4.3">2016-2023</td>
<td class="ltx_td ltx_align_right" id="A1.T13.1.1.4.4">32</td>
</tr>
<tr class="ltx_tr" id="A1.T13.1.1.5">
<td class="ltx_td ltx_align_left" id="A1.T13.1.1.5.1">Carnets de Geologie</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.5.2">open</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.5.3">2015-2023</td>
<td class="ltx_td ltx_align_right" id="A1.T13.1.1.5.4">147</td>
</tr>
<tr class="ltx_tr" id="A1.T13.1.1.6">
<td class="ltx_td ltx_align_left" id="A1.T13.1.1.6.1">Cretacious Research</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.6.2">open</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.6.3">2019-2023</td>
<td class="ltx_td ltx_align_right" id="A1.T13.1.1.6.4">81</td>
</tr>
<tr class="ltx_tr" id="A1.T13.1.1.7">
<td class="ltx_td ltx_align_left" id="A1.T13.1.1.7.1">Journal of paleontology</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.7.2">open</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.7.3">2015-2023</td>
<td class="ltx_td ltx_align_right" id="A1.T13.1.1.7.4">144</td>
</tr>
<tr class="ltx_tr" id="A1.T13.1.1.8">
<td class="ltx_td ltx_align_left" id="A1.T13.1.1.8.1">Journal of Systematic Palaeontology</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.8.2">open</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.8.3">2016-2023</td>
<td class="ltx_td ltx_align_right" id="A1.T13.1.1.8.4">34</td>
</tr>
<tr class="ltx_tr" id="A1.T13.1.1.9">
<td class="ltx_td ltx_align_left" id="A1.T13.1.1.9.1">Journal of Vertebrate Paleontology</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.9.2">open</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.9.3">2013-2023</td>
<td class="ltx_td ltx_align_right" id="A1.T13.1.1.9.4">95</td>
</tr>
<tr class="ltx_tr" id="A1.T13.1.1.10">
<td class="ltx_td ltx_align_left" id="A1.T13.1.1.10.1">Lethaia</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.10.2">open/free</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.10.3">2018-2023</td>
<td class="ltx_td ltx_align_right" id="A1.T13.1.1.10.4">239</td>
</tr>
<tr class="ltx_tr" id="A1.T13.1.1.11">
<td class="ltx_td ltx_align_left" id="A1.T13.1.1.11.1">Nature</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.11.2">open</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.11.3">2010-2023</td>
<td class="ltx_td ltx_align_right" id="A1.T13.1.1.11.4">705</td>
</tr>
<tr class="ltx_tr" id="A1.T13.1.1.12">
<td class="ltx_td ltx_align_left" id="A1.T13.1.1.12.1">Palaeobiodiversity and Palaeoenvironments</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.12.2">open</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.12.3">2002-2023</td>
<td class="ltx_td ltx_align_right" id="A1.T13.1.1.12.4">811</td>
</tr>
<tr class="ltx_tr" id="A1.T13.1.1.13">
<td class="ltx_td ltx_align_left" id="A1.T13.1.1.13.1">Palaeodiversity</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.13.2">open</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.13.3">2016-2023</td>
<td class="ltx_td ltx_align_right" id="A1.T13.1.1.13.4">74</td>
</tr>
<tr class="ltx_tr" id="A1.T13.1.1.14">
<td class="ltx_td ltx_align_left" id="A1.T13.1.1.14.1">Palaeogeography, Palaeoclimatology, Palaeoecology</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.14.2">open</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.14.3">2019-2023</td>
<td class="ltx_td ltx_align_right" id="A1.T13.1.1.14.4">201</td>
</tr>
<tr class="ltx_tr" id="A1.T13.1.1.15">
<td class="ltx_td ltx_align_left" id="A1.T13.1.1.15.1">Palaeontologia Electronica</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.15.2">open</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.15.3">1998â€“2023</td>
<td class="ltx_td ltx_align_right" id="A1.T13.1.1.15.4">841</td>
</tr>
<tr class="ltx_tr" id="A1.T13.1.1.16">
<td class="ltx_td ltx_align_left" id="A1.T13.1.1.16.1">Palaeontology</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.16.2">open/free</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.16.3">1999-2023</td>
<td class="ltx_td ltx_align_right" id="A1.T13.1.1.16.4">1â€‰474</td>
</tr>
<tr class="ltx_tr" id="A1.T13.1.1.17">
<td class="ltx_td ltx_align_left" id="A1.T13.1.1.17.1">Paleobiology</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.17.2">open</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.17.3">2013-2023</td>
<td class="ltx_td ltx_align_right" id="A1.T13.1.1.17.4">133</td>
</tr>
<tr class="ltx_tr" id="A1.T13.1.1.18">
<td class="ltx_td ltx_align_left" id="A1.T13.1.1.18.1">Paleoceanography and Paleoclimatology</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.18.2">open</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.18.3">2014-2023</td>
<td class="ltx_td ltx_align_right" id="A1.T13.1.1.18.4">128</td>
</tr>
<tr class="ltx_tr" id="A1.T13.1.1.19">
<td class="ltx_td ltx_align_left" id="A1.T13.1.1.19.1">PalZ</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.19.2">open/free</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.19.3">2009-2023</td>
<td class="ltx_td ltx_align_right" id="A1.T13.1.1.19.4">651</td>
</tr>
<tr class="ltx_tr" id="A1.T13.1.1.20">
<td class="ltx_td ltx_align_left" id="A1.T13.1.1.20.1">Papers in Palaeontology</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.20.2">open</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.20.3">2015-2023</td>
<td class="ltx_td ltx_align_right" id="A1.T13.1.1.20.4">71</td>
</tr>
<tr class="ltx_tr" id="A1.T13.1.1.21">
<td class="ltx_td ltx_align_left" id="A1.T13.1.1.21.1">Plos Paleontology</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.21.2">open</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.21.3">2011-2017</td>
<td class="ltx_td ltx_align_right" id="A1.T13.1.1.21.4">237</td>
</tr>
<tr class="ltx_tr" id="A1.T13.1.1.22">
<td class="ltx_td ltx_align_left" id="A1.T13.1.1.22.1">Proceedings of the Royal Society B: Biological Sciences (paleontology)</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.22.2">open/free</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.22.3">2009-2023</td>
<td class="ltx_td ltx_align_right" id="A1.T13.1.1.22.4">354</td>
</tr>
<tr class="ltx_tr" id="A1.T13.1.1.23">
<td class="ltx_td ltx_align_left" id="A1.T13.1.1.23.1">PubMedfreef ulltext (query="Paleontology[MeSH Terms]")</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.23.2">open/free</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.23.3">1955-2023</td>
<td class="ltx_td ltx_align_right" id="A1.T13.1.1.23.4">3â€‰462</td>
</tr>
<tr class="ltx_tr" id="A1.T13.1.1.24">
<td class="ltx_td ltx_align_left" id="A1.T13.1.1.24.1">Research in Paleontology and Stratigraphy</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.24.2">open</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.24.3">2019-2023</td>
<td class="ltx_td ltx_align_right" id="A1.T13.1.1.24.4">157</td>
</tr>
<tr class="ltx_tr" id="A1.T13.1.1.25">
<td class="ltx_td ltx_align_left" id="A1.T13.1.1.25.1">Royal Society Science (paleontology)</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.25.2">open/free</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.25.3">2014-2023</td>
<td class="ltx_td ltx_align_right" id="A1.T13.1.1.25.4">270</td>
</tr>
<tr class="ltx_tr" id="A1.T13.1.1.26">
<td class="ltx_td ltx_align_left" id="A1.T13.1.1.26.1">Royal Society Biology Letters (paleontology)</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.26.2">open/free</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.26.3">2009-2023</td>
<td class="ltx_td ltx_align_right" id="A1.T13.1.1.26.4">235</td>
</tr>
<tr class="ltx_tr" id="A1.T13.1.1.27">
<td class="ltx_td ltx_align_left" id="A1.T13.1.1.27.1">Swiss Journal of Palaeontology</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.27.2">open/free</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.27.3">2011-2023</td>
<td class="ltx_td ltx_align_right" id="A1.T13.1.1.27.4">282</td>
</tr>
<tr class="ltx_tr" id="A1.T13.1.1.28">
<td class="ltx_td ltx_align_left" id="A1.T13.1.1.28.1">Trends in Ecology and Evolution (paleobiology)</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.28.2">open</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.28.3">2020-2022</td>
<td class="ltx_td ltx_align_right" id="A1.T13.1.1.28.4">15</td>
</tr>
<tr class="ltx_tr" id="A1.T13.1.1.29">
<td class="ltx_td ltx_align_left" id="A1.T13.1.1.29.1">Zookeys (paleontology)</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.29.2">open</td>
<td class="ltx_td ltx_align_center" id="A1.T13.1.1.29.3">2015-2023</td>
<td class="ltx_td ltx_align_right" id="A1.T13.1.1.29.4">61</td>
</tr>
<tr class="ltx_tr" id="A1.T13.1.1.30">
<td class="ltx_td ltx_border_bb ltx_border_t" id="A1.T13.1.1.30.1"></td>
<td class="ltx_td ltx_border_bb ltx_border_t" id="A1.T13.1.1.30.2"></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A1.T13.1.1.30.3">Total</td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="A1.T13.1.1.30.4">12â€‰353</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 13: </span>Detailed information on the sources of the scientific papers collected for the Paleontology corpus.</figcaption>
</figure>
<figure class="ltx_table" id="A1.T14">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A1.T14.16" style="width:433.6pt;height:179.1pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-89.5pt,36.8pt) scale(0.707877016602518,0.707877016602518) ;">
<table class="ltx_tabular ltx_align_middle" id="A1.T14.16.16">
<tr class="ltx_tr" id="A1.T14.16.16.17">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T14.16.16.17.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="A1.T14.16.16.17.1.1">Model</span></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt" id="A1.T14.16.16.17.2" rowspan="2"><span class="ltx_text ltx_font_bold" id="A1.T14.16.16.17.2.1">FT</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="6" id="A1.T14.16.16.17.3"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="A1.T14.16.16.17.3.1">nlp</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="6" id="A1.T14.16.16.17.4"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="A1.T14.16.16.17.4.1">astro</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="6" id="A1.T14.16.16.17.5"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="A1.T14.16.16.17.5.1">paleo</span></td>
</tr>
<tr class="ltx_tr" id="A1.T14.9.9.9">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="A1.T14.1.1.1.1"><math alttext="F_{1}@M" class="ltx_Math" display="inline" id="A1.T14.1.1.1.1.m1.1"><semantics id="A1.T14.1.1.1.1.m1.1a"><mrow id="A1.T14.1.1.1.1.m1.1.1" xref="A1.T14.1.1.1.1.m1.1.1.cmml"><msub id="A1.T14.1.1.1.1.m1.1.1.2" xref="A1.T14.1.1.1.1.m1.1.1.2.cmml"><mi id="A1.T14.1.1.1.1.m1.1.1.2.2" xref="A1.T14.1.1.1.1.m1.1.1.2.2.cmml">F</mi><mn id="A1.T14.1.1.1.1.m1.1.1.2.3" xref="A1.T14.1.1.1.1.m1.1.1.2.3.cmml">1</mn></msub><mo id="A1.T14.1.1.1.1.m1.1.1.1" xref="A1.T14.1.1.1.1.m1.1.1.1.cmml">â¢</mo><mi id="A1.T14.1.1.1.1.m1.1.1.3" mathvariant="normal" xref="A1.T14.1.1.1.1.m1.1.1.3.cmml">@</mi><mo id="A1.T14.1.1.1.1.m1.1.1.1a" xref="A1.T14.1.1.1.1.m1.1.1.1.cmml">â¢</mo><mi id="A1.T14.1.1.1.1.m1.1.1.4" xref="A1.T14.1.1.1.1.m1.1.1.4.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.T14.1.1.1.1.m1.1b"><apply id="A1.T14.1.1.1.1.m1.1.1.cmml" xref="A1.T14.1.1.1.1.m1.1.1"><times id="A1.T14.1.1.1.1.m1.1.1.1.cmml" xref="A1.T14.1.1.1.1.m1.1.1.1"></times><apply id="A1.T14.1.1.1.1.m1.1.1.2.cmml" xref="A1.T14.1.1.1.1.m1.1.1.2"><csymbol cd="ambiguous" id="A1.T14.1.1.1.1.m1.1.1.2.1.cmml" xref="A1.T14.1.1.1.1.m1.1.1.2">subscript</csymbol><ci id="A1.T14.1.1.1.1.m1.1.1.2.2.cmml" xref="A1.T14.1.1.1.1.m1.1.1.2.2">ğ¹</ci><cn id="A1.T14.1.1.1.1.m1.1.1.2.3.cmml" type="integer" xref="A1.T14.1.1.1.1.m1.1.1.2.3">1</cn></apply><ci id="A1.T14.1.1.1.1.m1.1.1.3.cmml" xref="A1.T14.1.1.1.1.m1.1.1.3">@</ci><ci id="A1.T14.1.1.1.1.m1.1.1.4.cmml" xref="A1.T14.1.1.1.1.m1.1.1.4">ğ‘€</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T14.1.1.1.1.m1.1c">F_{1}@M</annotation><annotation encoding="application/x-llamapun" id="A1.T14.1.1.1.1.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ italic_M</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="A1.T14.2.2.2.2"><math alttext="F_{1}@5" class="ltx_Math" display="inline" id="A1.T14.2.2.2.2.m1.1"><semantics id="A1.T14.2.2.2.2.m1.1a"><mrow id="A1.T14.2.2.2.2.m1.1.1" xref="A1.T14.2.2.2.2.m1.1.1.cmml"><msub id="A1.T14.2.2.2.2.m1.1.1.2" xref="A1.T14.2.2.2.2.m1.1.1.2.cmml"><mi id="A1.T14.2.2.2.2.m1.1.1.2.2" xref="A1.T14.2.2.2.2.m1.1.1.2.2.cmml">F</mi><mn id="A1.T14.2.2.2.2.m1.1.1.2.3" xref="A1.T14.2.2.2.2.m1.1.1.2.3.cmml">1</mn></msub><mo id="A1.T14.2.2.2.2.m1.1.1.1" xref="A1.T14.2.2.2.2.m1.1.1.1.cmml">â¢</mo><mi id="A1.T14.2.2.2.2.m1.1.1.3" mathvariant="normal" xref="A1.T14.2.2.2.2.m1.1.1.3.cmml">@</mi><mo id="A1.T14.2.2.2.2.m1.1.1.1a" xref="A1.T14.2.2.2.2.m1.1.1.1.cmml">â¢</mo><mn id="A1.T14.2.2.2.2.m1.1.1.4" xref="A1.T14.2.2.2.2.m1.1.1.4.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T14.2.2.2.2.m1.1b"><apply id="A1.T14.2.2.2.2.m1.1.1.cmml" xref="A1.T14.2.2.2.2.m1.1.1"><times id="A1.T14.2.2.2.2.m1.1.1.1.cmml" xref="A1.T14.2.2.2.2.m1.1.1.1"></times><apply id="A1.T14.2.2.2.2.m1.1.1.2.cmml" xref="A1.T14.2.2.2.2.m1.1.1.2"><csymbol cd="ambiguous" id="A1.T14.2.2.2.2.m1.1.1.2.1.cmml" xref="A1.T14.2.2.2.2.m1.1.1.2">subscript</csymbol><ci id="A1.T14.2.2.2.2.m1.1.1.2.2.cmml" xref="A1.T14.2.2.2.2.m1.1.1.2.2">ğ¹</ci><cn id="A1.T14.2.2.2.2.m1.1.1.2.3.cmml" type="integer" xref="A1.T14.2.2.2.2.m1.1.1.2.3">1</cn></apply><ci id="A1.T14.2.2.2.2.m1.1.1.3.cmml" xref="A1.T14.2.2.2.2.m1.1.1.3">@</ci><cn id="A1.T14.2.2.2.2.m1.1.1.4.cmml" type="integer" xref="A1.T14.2.2.2.2.m1.1.1.4">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T14.2.2.2.2.m1.1c">F_{1}@5</annotation><annotation encoding="application/x-llamapun" id="A1.T14.2.2.2.2.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ 5</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="A1.T14.3.3.3.3"><math alttext="F_{1}@10" class="ltx_Math" display="inline" id="A1.T14.3.3.3.3.m1.1"><semantics id="A1.T14.3.3.3.3.m1.1a"><mrow id="A1.T14.3.3.3.3.m1.1.1" xref="A1.T14.3.3.3.3.m1.1.1.cmml"><msub id="A1.T14.3.3.3.3.m1.1.1.2" xref="A1.T14.3.3.3.3.m1.1.1.2.cmml"><mi id="A1.T14.3.3.3.3.m1.1.1.2.2" xref="A1.T14.3.3.3.3.m1.1.1.2.2.cmml">F</mi><mn id="A1.T14.3.3.3.3.m1.1.1.2.3" xref="A1.T14.3.3.3.3.m1.1.1.2.3.cmml">1</mn></msub><mo id="A1.T14.3.3.3.3.m1.1.1.1" xref="A1.T14.3.3.3.3.m1.1.1.1.cmml">â¢</mo><mi id="A1.T14.3.3.3.3.m1.1.1.3" mathvariant="normal" xref="A1.T14.3.3.3.3.m1.1.1.3.cmml">@</mi><mo id="A1.T14.3.3.3.3.m1.1.1.1a" xref="A1.T14.3.3.3.3.m1.1.1.1.cmml">â¢</mo><mn id="A1.T14.3.3.3.3.m1.1.1.4" xref="A1.T14.3.3.3.3.m1.1.1.4.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T14.3.3.3.3.m1.1b"><apply id="A1.T14.3.3.3.3.m1.1.1.cmml" xref="A1.T14.3.3.3.3.m1.1.1"><times id="A1.T14.3.3.3.3.m1.1.1.1.cmml" xref="A1.T14.3.3.3.3.m1.1.1.1"></times><apply id="A1.T14.3.3.3.3.m1.1.1.2.cmml" xref="A1.T14.3.3.3.3.m1.1.1.2"><csymbol cd="ambiguous" id="A1.T14.3.3.3.3.m1.1.1.2.1.cmml" xref="A1.T14.3.3.3.3.m1.1.1.2">subscript</csymbol><ci id="A1.T14.3.3.3.3.m1.1.1.2.2.cmml" xref="A1.T14.3.3.3.3.m1.1.1.2.2">ğ¹</ci><cn id="A1.T14.3.3.3.3.m1.1.1.2.3.cmml" type="integer" xref="A1.T14.3.3.3.3.m1.1.1.2.3">1</cn></apply><ci id="A1.T14.3.3.3.3.m1.1.1.3.cmml" xref="A1.T14.3.3.3.3.m1.1.1.3">@</ci><cn id="A1.T14.3.3.3.3.m1.1.1.4.cmml" type="integer" xref="A1.T14.3.3.3.3.m1.1.1.4">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T14.3.3.3.3.m1.1c">F_{1}@10</annotation><annotation encoding="application/x-llamapun" id="A1.T14.3.3.3.3.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ 10</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="A1.T14.4.4.4.4"><math alttext="F_{1}@M" class="ltx_Math" display="inline" id="A1.T14.4.4.4.4.m1.1"><semantics id="A1.T14.4.4.4.4.m1.1a"><mrow id="A1.T14.4.4.4.4.m1.1.1" xref="A1.T14.4.4.4.4.m1.1.1.cmml"><msub id="A1.T14.4.4.4.4.m1.1.1.2" xref="A1.T14.4.4.4.4.m1.1.1.2.cmml"><mi id="A1.T14.4.4.4.4.m1.1.1.2.2" xref="A1.T14.4.4.4.4.m1.1.1.2.2.cmml">F</mi><mn id="A1.T14.4.4.4.4.m1.1.1.2.3" xref="A1.T14.4.4.4.4.m1.1.1.2.3.cmml">1</mn></msub><mo id="A1.T14.4.4.4.4.m1.1.1.1" xref="A1.T14.4.4.4.4.m1.1.1.1.cmml">â¢</mo><mi id="A1.T14.4.4.4.4.m1.1.1.3" mathvariant="normal" xref="A1.T14.4.4.4.4.m1.1.1.3.cmml">@</mi><mo id="A1.T14.4.4.4.4.m1.1.1.1a" xref="A1.T14.4.4.4.4.m1.1.1.1.cmml">â¢</mo><mi id="A1.T14.4.4.4.4.m1.1.1.4" xref="A1.T14.4.4.4.4.m1.1.1.4.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.T14.4.4.4.4.m1.1b"><apply id="A1.T14.4.4.4.4.m1.1.1.cmml" xref="A1.T14.4.4.4.4.m1.1.1"><times id="A1.T14.4.4.4.4.m1.1.1.1.cmml" xref="A1.T14.4.4.4.4.m1.1.1.1"></times><apply id="A1.T14.4.4.4.4.m1.1.1.2.cmml" xref="A1.T14.4.4.4.4.m1.1.1.2"><csymbol cd="ambiguous" id="A1.T14.4.4.4.4.m1.1.1.2.1.cmml" xref="A1.T14.4.4.4.4.m1.1.1.2">subscript</csymbol><ci id="A1.T14.4.4.4.4.m1.1.1.2.2.cmml" xref="A1.T14.4.4.4.4.m1.1.1.2.2">ğ¹</ci><cn id="A1.T14.4.4.4.4.m1.1.1.2.3.cmml" type="integer" xref="A1.T14.4.4.4.4.m1.1.1.2.3">1</cn></apply><ci id="A1.T14.4.4.4.4.m1.1.1.3.cmml" xref="A1.T14.4.4.4.4.m1.1.1.3">@</ci><ci id="A1.T14.4.4.4.4.m1.1.1.4.cmml" xref="A1.T14.4.4.4.4.m1.1.1.4">ğ‘€</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T14.4.4.4.4.m1.1c">F_{1}@M</annotation><annotation encoding="application/x-llamapun" id="A1.T14.4.4.4.4.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ italic_M</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="A1.T14.5.5.5.5"><math alttext="F_{1}@5" class="ltx_Math" display="inline" id="A1.T14.5.5.5.5.m1.1"><semantics id="A1.T14.5.5.5.5.m1.1a"><mrow id="A1.T14.5.5.5.5.m1.1.1" xref="A1.T14.5.5.5.5.m1.1.1.cmml"><msub id="A1.T14.5.5.5.5.m1.1.1.2" xref="A1.T14.5.5.5.5.m1.1.1.2.cmml"><mi id="A1.T14.5.5.5.5.m1.1.1.2.2" xref="A1.T14.5.5.5.5.m1.1.1.2.2.cmml">F</mi><mn id="A1.T14.5.5.5.5.m1.1.1.2.3" xref="A1.T14.5.5.5.5.m1.1.1.2.3.cmml">1</mn></msub><mo id="A1.T14.5.5.5.5.m1.1.1.1" xref="A1.T14.5.5.5.5.m1.1.1.1.cmml">â¢</mo><mi id="A1.T14.5.5.5.5.m1.1.1.3" mathvariant="normal" xref="A1.T14.5.5.5.5.m1.1.1.3.cmml">@</mi><mo id="A1.T14.5.5.5.5.m1.1.1.1a" xref="A1.T14.5.5.5.5.m1.1.1.1.cmml">â¢</mo><mn id="A1.T14.5.5.5.5.m1.1.1.4" xref="A1.T14.5.5.5.5.m1.1.1.4.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T14.5.5.5.5.m1.1b"><apply id="A1.T14.5.5.5.5.m1.1.1.cmml" xref="A1.T14.5.5.5.5.m1.1.1"><times id="A1.T14.5.5.5.5.m1.1.1.1.cmml" xref="A1.T14.5.5.5.5.m1.1.1.1"></times><apply id="A1.T14.5.5.5.5.m1.1.1.2.cmml" xref="A1.T14.5.5.5.5.m1.1.1.2"><csymbol cd="ambiguous" id="A1.T14.5.5.5.5.m1.1.1.2.1.cmml" xref="A1.T14.5.5.5.5.m1.1.1.2">subscript</csymbol><ci id="A1.T14.5.5.5.5.m1.1.1.2.2.cmml" xref="A1.T14.5.5.5.5.m1.1.1.2.2">ğ¹</ci><cn id="A1.T14.5.5.5.5.m1.1.1.2.3.cmml" type="integer" xref="A1.T14.5.5.5.5.m1.1.1.2.3">1</cn></apply><ci id="A1.T14.5.5.5.5.m1.1.1.3.cmml" xref="A1.T14.5.5.5.5.m1.1.1.3">@</ci><cn id="A1.T14.5.5.5.5.m1.1.1.4.cmml" type="integer" xref="A1.T14.5.5.5.5.m1.1.1.4">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T14.5.5.5.5.m1.1c">F_{1}@5</annotation><annotation encoding="application/x-llamapun" id="A1.T14.5.5.5.5.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ 5</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="A1.T14.6.6.6.6"><math alttext="F_{1}@10" class="ltx_Math" display="inline" id="A1.T14.6.6.6.6.m1.1"><semantics id="A1.T14.6.6.6.6.m1.1a"><mrow id="A1.T14.6.6.6.6.m1.1.1" xref="A1.T14.6.6.6.6.m1.1.1.cmml"><msub id="A1.T14.6.6.6.6.m1.1.1.2" xref="A1.T14.6.6.6.6.m1.1.1.2.cmml"><mi id="A1.T14.6.6.6.6.m1.1.1.2.2" xref="A1.T14.6.6.6.6.m1.1.1.2.2.cmml">F</mi><mn id="A1.T14.6.6.6.6.m1.1.1.2.3" xref="A1.T14.6.6.6.6.m1.1.1.2.3.cmml">1</mn></msub><mo id="A1.T14.6.6.6.6.m1.1.1.1" xref="A1.T14.6.6.6.6.m1.1.1.1.cmml">â¢</mo><mi id="A1.T14.6.6.6.6.m1.1.1.3" mathvariant="normal" xref="A1.T14.6.6.6.6.m1.1.1.3.cmml">@</mi><mo id="A1.T14.6.6.6.6.m1.1.1.1a" xref="A1.T14.6.6.6.6.m1.1.1.1.cmml">â¢</mo><mn id="A1.T14.6.6.6.6.m1.1.1.4" xref="A1.T14.6.6.6.6.m1.1.1.4.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T14.6.6.6.6.m1.1b"><apply id="A1.T14.6.6.6.6.m1.1.1.cmml" xref="A1.T14.6.6.6.6.m1.1.1"><times id="A1.T14.6.6.6.6.m1.1.1.1.cmml" xref="A1.T14.6.6.6.6.m1.1.1.1"></times><apply id="A1.T14.6.6.6.6.m1.1.1.2.cmml" xref="A1.T14.6.6.6.6.m1.1.1.2"><csymbol cd="ambiguous" id="A1.T14.6.6.6.6.m1.1.1.2.1.cmml" xref="A1.T14.6.6.6.6.m1.1.1.2">subscript</csymbol><ci id="A1.T14.6.6.6.6.m1.1.1.2.2.cmml" xref="A1.T14.6.6.6.6.m1.1.1.2.2">ğ¹</ci><cn id="A1.T14.6.6.6.6.m1.1.1.2.3.cmml" type="integer" xref="A1.T14.6.6.6.6.m1.1.1.2.3">1</cn></apply><ci id="A1.T14.6.6.6.6.m1.1.1.3.cmml" xref="A1.T14.6.6.6.6.m1.1.1.3">@</ci><cn id="A1.T14.6.6.6.6.m1.1.1.4.cmml" type="integer" xref="A1.T14.6.6.6.6.m1.1.1.4">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T14.6.6.6.6.m1.1c">F_{1}@10</annotation><annotation encoding="application/x-llamapun" id="A1.T14.6.6.6.6.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ 10</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="A1.T14.7.7.7.7"><math alttext="F_{1}@M" class="ltx_Math" display="inline" id="A1.T14.7.7.7.7.m1.1"><semantics id="A1.T14.7.7.7.7.m1.1a"><mrow id="A1.T14.7.7.7.7.m1.1.1" xref="A1.T14.7.7.7.7.m1.1.1.cmml"><msub id="A1.T14.7.7.7.7.m1.1.1.2" xref="A1.T14.7.7.7.7.m1.1.1.2.cmml"><mi id="A1.T14.7.7.7.7.m1.1.1.2.2" xref="A1.T14.7.7.7.7.m1.1.1.2.2.cmml">F</mi><mn id="A1.T14.7.7.7.7.m1.1.1.2.3" xref="A1.T14.7.7.7.7.m1.1.1.2.3.cmml">1</mn></msub><mo id="A1.T14.7.7.7.7.m1.1.1.1" xref="A1.T14.7.7.7.7.m1.1.1.1.cmml">â¢</mo><mi id="A1.T14.7.7.7.7.m1.1.1.3" mathvariant="normal" xref="A1.T14.7.7.7.7.m1.1.1.3.cmml">@</mi><mo id="A1.T14.7.7.7.7.m1.1.1.1a" xref="A1.T14.7.7.7.7.m1.1.1.1.cmml">â¢</mo><mi id="A1.T14.7.7.7.7.m1.1.1.4" xref="A1.T14.7.7.7.7.m1.1.1.4.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.T14.7.7.7.7.m1.1b"><apply id="A1.T14.7.7.7.7.m1.1.1.cmml" xref="A1.T14.7.7.7.7.m1.1.1"><times id="A1.T14.7.7.7.7.m1.1.1.1.cmml" xref="A1.T14.7.7.7.7.m1.1.1.1"></times><apply id="A1.T14.7.7.7.7.m1.1.1.2.cmml" xref="A1.T14.7.7.7.7.m1.1.1.2"><csymbol cd="ambiguous" id="A1.T14.7.7.7.7.m1.1.1.2.1.cmml" xref="A1.T14.7.7.7.7.m1.1.1.2">subscript</csymbol><ci id="A1.T14.7.7.7.7.m1.1.1.2.2.cmml" xref="A1.T14.7.7.7.7.m1.1.1.2.2">ğ¹</ci><cn id="A1.T14.7.7.7.7.m1.1.1.2.3.cmml" type="integer" xref="A1.T14.7.7.7.7.m1.1.1.2.3">1</cn></apply><ci id="A1.T14.7.7.7.7.m1.1.1.3.cmml" xref="A1.T14.7.7.7.7.m1.1.1.3">@</ci><ci id="A1.T14.7.7.7.7.m1.1.1.4.cmml" xref="A1.T14.7.7.7.7.m1.1.1.4">ğ‘€</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T14.7.7.7.7.m1.1c">F_{1}@M</annotation><annotation encoding="application/x-llamapun" id="A1.T14.7.7.7.7.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ italic_M</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="A1.T14.8.8.8.8"><math alttext="F_{1}@5" class="ltx_Math" display="inline" id="A1.T14.8.8.8.8.m1.1"><semantics id="A1.T14.8.8.8.8.m1.1a"><mrow id="A1.T14.8.8.8.8.m1.1.1" xref="A1.T14.8.8.8.8.m1.1.1.cmml"><msub id="A1.T14.8.8.8.8.m1.1.1.2" xref="A1.T14.8.8.8.8.m1.1.1.2.cmml"><mi id="A1.T14.8.8.8.8.m1.1.1.2.2" xref="A1.T14.8.8.8.8.m1.1.1.2.2.cmml">F</mi><mn id="A1.T14.8.8.8.8.m1.1.1.2.3" xref="A1.T14.8.8.8.8.m1.1.1.2.3.cmml">1</mn></msub><mo id="A1.T14.8.8.8.8.m1.1.1.1" xref="A1.T14.8.8.8.8.m1.1.1.1.cmml">â¢</mo><mi id="A1.T14.8.8.8.8.m1.1.1.3" mathvariant="normal" xref="A1.T14.8.8.8.8.m1.1.1.3.cmml">@</mi><mo id="A1.T14.8.8.8.8.m1.1.1.1a" xref="A1.T14.8.8.8.8.m1.1.1.1.cmml">â¢</mo><mn id="A1.T14.8.8.8.8.m1.1.1.4" xref="A1.T14.8.8.8.8.m1.1.1.4.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T14.8.8.8.8.m1.1b"><apply id="A1.T14.8.8.8.8.m1.1.1.cmml" xref="A1.T14.8.8.8.8.m1.1.1"><times id="A1.T14.8.8.8.8.m1.1.1.1.cmml" xref="A1.T14.8.8.8.8.m1.1.1.1"></times><apply id="A1.T14.8.8.8.8.m1.1.1.2.cmml" xref="A1.T14.8.8.8.8.m1.1.1.2"><csymbol cd="ambiguous" id="A1.T14.8.8.8.8.m1.1.1.2.1.cmml" xref="A1.T14.8.8.8.8.m1.1.1.2">subscript</csymbol><ci id="A1.T14.8.8.8.8.m1.1.1.2.2.cmml" xref="A1.T14.8.8.8.8.m1.1.1.2.2">ğ¹</ci><cn id="A1.T14.8.8.8.8.m1.1.1.2.3.cmml" type="integer" xref="A1.T14.8.8.8.8.m1.1.1.2.3">1</cn></apply><ci id="A1.T14.8.8.8.8.m1.1.1.3.cmml" xref="A1.T14.8.8.8.8.m1.1.1.3">@</ci><cn id="A1.T14.8.8.8.8.m1.1.1.4.cmml" type="integer" xref="A1.T14.8.8.8.8.m1.1.1.4">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T14.8.8.8.8.m1.1c">F_{1}@5</annotation><annotation encoding="application/x-llamapun" id="A1.T14.8.8.8.8.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ 5</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="A1.T14.9.9.9.9"><math alttext="F_{1}@10" class="ltx_Math" display="inline" id="A1.T14.9.9.9.9.m1.1"><semantics id="A1.T14.9.9.9.9.m1.1a"><mrow id="A1.T14.9.9.9.9.m1.1.1" xref="A1.T14.9.9.9.9.m1.1.1.cmml"><msub id="A1.T14.9.9.9.9.m1.1.1.2" xref="A1.T14.9.9.9.9.m1.1.1.2.cmml"><mi id="A1.T14.9.9.9.9.m1.1.1.2.2" xref="A1.T14.9.9.9.9.m1.1.1.2.2.cmml">F</mi><mn id="A1.T14.9.9.9.9.m1.1.1.2.3" xref="A1.T14.9.9.9.9.m1.1.1.2.3.cmml">1</mn></msub><mo id="A1.T14.9.9.9.9.m1.1.1.1" xref="A1.T14.9.9.9.9.m1.1.1.1.cmml">â¢</mo><mi id="A1.T14.9.9.9.9.m1.1.1.3" mathvariant="normal" xref="A1.T14.9.9.9.9.m1.1.1.3.cmml">@</mi><mo id="A1.T14.9.9.9.9.m1.1.1.1a" xref="A1.T14.9.9.9.9.m1.1.1.1.cmml">â¢</mo><mn id="A1.T14.9.9.9.9.m1.1.1.4" xref="A1.T14.9.9.9.9.m1.1.1.4.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T14.9.9.9.9.m1.1b"><apply id="A1.T14.9.9.9.9.m1.1.1.cmml" xref="A1.T14.9.9.9.9.m1.1.1"><times id="A1.T14.9.9.9.9.m1.1.1.1.cmml" xref="A1.T14.9.9.9.9.m1.1.1.1"></times><apply id="A1.T14.9.9.9.9.m1.1.1.2.cmml" xref="A1.T14.9.9.9.9.m1.1.1.2"><csymbol cd="ambiguous" id="A1.T14.9.9.9.9.m1.1.1.2.1.cmml" xref="A1.T14.9.9.9.9.m1.1.1.2">subscript</csymbol><ci id="A1.T14.9.9.9.9.m1.1.1.2.2.cmml" xref="A1.T14.9.9.9.9.m1.1.1.2.2">ğ¹</ci><cn id="A1.T14.9.9.9.9.m1.1.1.2.3.cmml" type="integer" xref="A1.T14.9.9.9.9.m1.1.1.2.3">1</cn></apply><ci id="A1.T14.9.9.9.9.m1.1.1.3.cmml" xref="A1.T14.9.9.9.9.m1.1.1.3">@</ci><cn id="A1.T14.9.9.9.9.m1.1.1.4.cmml" type="integer" xref="A1.T14.9.9.9.9.m1.1.1.4">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T14.9.9.9.9.m1.1c">F_{1}@10</annotation><annotation encoding="application/x-llamapun" id="A1.T14.9.9.9.9.m1.1d">italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT @ 10</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="A1.T14.16.16.18">
<td class="ltx_td" id="A1.T14.16.16.18.1"></td>
<td class="ltx_td ltx_nopad_l ltx_border_r" id="A1.T14.16.16.18.2"></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.18.3">pres</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.18.4">abs</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.18.5">pres</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.18.6">abs</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.18.7">pres</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="A1.T14.16.16.18.8">abs</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.18.9">pres</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.18.10">abs</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.18.11">pres</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.18.12">abs</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.18.13">pres</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="A1.T14.16.16.18.14">abs</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.18.15">pres</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.18.16">abs</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.18.17">pres</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.18.18">abs</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.18.19">pres</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.18.20">abs</td>
</tr>
<tr class="ltx_tr" id="A1.T14.16.16.19">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T14.16.16.19.1">MPRank</td>
<td class="ltx_td ltx_nopad_l ltx_border_r ltx_border_t" id="A1.T14.16.16.19.2"></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="A1.T14.16.16.19.3">-</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.19.4">20.4</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.19.5">-</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.19.6">16.2</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="A1.T14.16.16.19.7">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="A1.T14.16.16.19.8">-</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.19.9">17.7</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.19.10">-</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.19.11">14.2</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="A1.T14.16.16.19.12">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="A1.T14.16.16.19.13">-</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.19.14">16.4</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.19.15">-</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.19.16">15.7</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.19.17">-</td>
</tr>
<tr class="ltx_tr" id="A1.T14.16.16.20">
<td class="ltx_td ltx_align_left" id="A1.T14.16.16.20.1">Yake</td>
<td class="ltx_td ltx_nopad_l ltx_border_r" id="A1.T14.16.16.20.2"></td>
<td class="ltx_td ltx_align_center" colspan="2" id="A1.T14.16.16.20.3">-</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.20.4">24.3</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.20.5">-</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.20.6">20.5</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A1.T14.16.16.20.7">-</td>
<td class="ltx_td ltx_align_center" colspan="2" id="A1.T14.16.16.20.8">-</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.20.9">15.4</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.20.10">-</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.20.11">14.3</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A1.T14.16.16.20.12">-</td>
<td class="ltx_td ltx_align_center" colspan="2" id="A1.T14.16.16.20.13">-</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.20.14">11.9</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.20.15">-</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.20.16">12.9</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.20.17">-</td>
</tr>
<tr class="ltx_tr" id="A1.T14.16.16.21">
<td class="ltx_td ltx_align_left" id="A1.T14.16.16.21.1">KeyBART</td>
<td class="ltx_td ltx_nopad_l ltx_border_r" id="A1.T14.16.16.21.2"></td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.21.3">16.6</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.21.4">0.8</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.21.5">17.3</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.21.6">1.5</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.21.7">14.0</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A1.T14.16.16.21.8">1.5</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.21.9">19.7</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.21.10"><span class="ltx_text ltx_font_bold" id="A1.T14.16.16.21.10.1">2.1</span></td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.21.11">17.8</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.21.12"><span class="ltx_text ltx_font_bold" id="A1.T14.16.16.21.12.1">2.1</span></td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.21.13">13.6</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A1.T14.16.16.21.14"><span class="ltx_text ltx_font_bold" id="A1.T14.16.16.21.14.1">1.7</span></td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.21.15">11.6</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.21.16"><span class="ltx_text ltx_font_bold" id="A1.T14.16.16.21.16.1">1.8</span></td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.21.17">12.5</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.21.18"><span class="ltx_text ltx_font_bold" id="A1.T14.16.16.21.18.1">1.9</span></td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.21.19">13.0</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.21.20"><span class="ltx_text ltx_font_bold" id="A1.T14.16.16.21.20.1">1.7</span></td>
</tr>
<tr class="ltx_tr" id="A1.T14.16.16.22">
<td class="ltx_td ltx_align_left" id="A1.T14.16.16.22.1">One2Set</td>
<td class="ltx_td ltx_nopad_l ltx_border_r" id="A1.T14.16.16.22.2"></td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.22.3">36.1</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.22.4"><span class="ltx_text ltx_font_bold" id="A1.T14.16.16.22.4.1">3.3</span></td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.22.5">28.3</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.22.6">2.8</td>
<td class="ltx_td ltx_align_center ltx_border_r" colspan="2" id="A1.T14.16.16.22.7">-</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.22.8">20.1</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.22.9">1.6</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.22.10">17.3</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.22.11">1.2</td>
<td class="ltx_td ltx_align_center ltx_border_r" colspan="2" id="A1.T14.16.16.22.12">-</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.22.13">18.6</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.22.14">0.3</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.22.15">16.5</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.22.16">0.2</td>
<td class="ltx_td ltx_align_center" colspan="2" id="A1.T14.16.16.22.17">-</td>
</tr>
<tr class="ltx_tr" id="A1.T14.16.16.23">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T14.16.16.23.1">BART-FT</td>
<td class="ltx_td ltx_nopad_l ltx_border_r ltx_border_t" id="A1.T14.16.16.23.2"></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.23.3">38.8</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.23.4">2.0</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.23.5">36.8</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.23.6"><span class="ltx_text ltx_font_bold" id="A1.T14.16.16.23.6.1">3.7</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.23.7">27.9</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="A1.T14.16.16.23.8"><span class="ltx_text ltx_font_bold" id="A1.T14.16.16.23.8.1">3.6</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.23.9">26.7</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.23.10">0.2</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.23.11">25.6</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.23.12">1.4</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.23.13">20.2</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="A1.T14.16.16.23.14">1.4</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.23.15">23.5</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.23.16">0.5</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.23.17">24.3</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.23.18">1.3</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.23.19">22.6</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.23.20">1.2</td>
</tr>
<tr class="ltx_tr" id="A1.T14.16.16.24">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T14.16.16.24.1">+self-learning</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t" id="A1.T14.16.16.24.2">500</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.24.3">38.9</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.24.4">2.0</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.24.5">36.9</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.24.6">3.0</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.24.7">27.7</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="A1.T14.16.16.24.8">3.0</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.24.9">26.5</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.24.10">0.0</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.24.11">26.0</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.24.12">0.7</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.24.13">19.9</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="A1.T14.16.16.24.14">0.7</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.24.15">24.1</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.24.16">0.5</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.24.17">23.8</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.24.18">1.2</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.24.19">22.6</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.16.16.24.20">1.1</td>
</tr>
<tr class="ltx_tr" id="A1.T14.16.16.25">
<td class="ltx_td" id="A1.T14.16.16.25.1"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r" id="A1.T14.16.16.25.2">1K</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.25.3">38.2</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.25.4">2.0</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.25.5">36.8</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.25.6">3.1</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.25.7">27.6</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A1.T14.16.16.25.8">3.0</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.25.9">27.0</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.25.10">0.0</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.25.11">26.1</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.25.12">0.5</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.25.13">20.5</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A1.T14.16.16.25.14">0.5</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.25.15">24.5</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.25.16">0.2</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.25.17">24.8</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.25.18">0.6</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.25.19">22.9</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.25.20">0.7</td>
</tr>
<tr class="ltx_tr" id="A1.T14.16.16.26">
<td class="ltx_td" id="A1.T14.16.16.26.1"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r" id="A1.T14.16.16.26.2">2K</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.26.3">37.2</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.26.4">2.6</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.26.5">36.8</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.26.6">3.2</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.26.7">27.8</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A1.T14.16.16.26.8">3.0</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.26.9">25.3</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.26.10">0.2</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.26.11">25.3</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.26.12">0.5</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.26.13">20.2</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A1.T14.16.16.26.14">0.7</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.26.15">24.3</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.26.16">0.2</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.26.17">25.7</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.26.18">0.6</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.26.19">22.7</td>
<td class="ltx_td ltx_align_right" id="A1.T14.16.16.26.20">0.6</td>
</tr>
<tr class="ltx_tr" id="A1.T14.10.10.10">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T14.10.10.10.2">+<span class="ltx_text ltx_font_typewriter" id="A1.T14.10.10.10.2.1">silk</span> (ours)</td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t" id="A1.T14.10.10.10.3">500</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.10.10.10.4">39.1</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.10.10.10.5">0.5</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.10.10.10.6">36.2</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.10.10.10.7">2.8</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.10.10.10.8"><span class="ltx_text ltx_font_bold" id="A1.T14.10.10.10.8.1">28.2</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="A1.T14.10.10.10.9">2.9</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.10.10.10.10">26.4</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.10.10.10.11">0.2</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.10.10.10.12">26.7</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.10.10.10.13">1.1</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.10.10.10.1">21.1<sup class="ltx_sup" id="A1.T14.10.10.10.1.1"><span class="ltx_text ltx_font_italic" id="A1.T14.10.10.10.1.1.1">â€ </span></sup>
</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="A1.T14.10.10.10.14">1.1</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.10.10.10.15">24.4</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.10.10.10.16">0.5</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.10.10.10.17">24.8</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.10.10.10.18">1.0</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.10.10.10.19"><span class="ltx_text ltx_font_bold" id="A1.T14.10.10.10.19.1">23.5</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T14.10.10.10.20">0.9</td>
</tr>
<tr class="ltx_tr" id="A1.T14.14.14.14">
<td class="ltx_td" id="A1.T14.14.14.14.5"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r" id="A1.T14.14.14.14.6">1K</td>
<td class="ltx_td ltx_align_right" id="A1.T14.11.11.11.1"><span class="ltx_text ltx_font_bold" id="A1.T14.11.11.11.1.1">41.7<sup class="ltx_sup" id="A1.T14.11.11.11.1.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="A1.T14.11.11.11.1.1.1.1">â€ </span></sup></span></td>
<td class="ltx_td ltx_align_right" id="A1.T14.14.14.14.7">1.2</td>
<td class="ltx_td ltx_align_right" id="A1.T14.14.14.14.8"><span class="ltx_text ltx_font_bold" id="A1.T14.14.14.14.8.1">38.3</span></td>
<td class="ltx_td ltx_align_right" id="A1.T14.14.14.14.9">3.3</td>
<td class="ltx_td ltx_align_right" id="A1.T14.14.14.14.10">28.1</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A1.T14.14.14.14.11">3.4</td>
<td class="ltx_td ltx_align_right" id="A1.T14.14.14.14.12">27.0</td>
<td class="ltx_td ltx_align_right" id="A1.T14.14.14.14.13">0.0</td>
<td class="ltx_td ltx_align_right" id="A1.T14.12.12.12.2">27.7<sup class="ltx_sup" id="A1.T14.12.12.12.2.1"><span class="ltx_text ltx_font_italic" id="A1.T14.12.12.12.2.1.1">â€ </span></sup>
</td>
<td class="ltx_td ltx_align_right" id="A1.T14.14.14.14.14">1.1</td>
<td class="ltx_td ltx_align_right" id="A1.T14.13.13.13.3">21.7<sup class="ltx_sup" id="A1.T14.13.13.13.3.1"><span class="ltx_text ltx_font_italic" id="A1.T14.13.13.13.3.1.1">â€ </span></sup>
</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="A1.T14.14.14.14.15">1.0</td>
<td class="ltx_td ltx_align_right" id="A1.T14.14.14.14.16"><span class="ltx_text ltx_font_bold" id="A1.T14.14.14.14.16.1">25.4</span></td>
<td class="ltx_td ltx_align_right" id="A1.T14.14.14.14.17">0.7</td>
<td class="ltx_td ltx_align_right" id="A1.T14.14.14.14.4"><span class="ltx_text ltx_font_bold" id="A1.T14.14.14.14.4.1">26.3<sup class="ltx_sup" id="A1.T14.14.14.14.4.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="A1.T14.14.14.14.4.1.1.1">â€ </span></sup></span></td>
<td class="ltx_td ltx_align_right" id="A1.T14.14.14.14.18">0.6</td>
<td class="ltx_td ltx_align_right" id="A1.T14.14.14.14.19"><span class="ltx_text ltx_font_bold" id="A1.T14.14.14.14.19.1">23.5</span></td>
<td class="ltx_td ltx_align_right" id="A1.T14.14.14.14.20">0.5</td>
</tr>
<tr class="ltx_tr" id="A1.T14.16.16.16">
<td class="ltx_td ltx_border_bb" id="A1.T14.16.16.16.3"></td>
<td class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r" id="A1.T14.16.16.16.4">2K</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T14.16.16.16.5">38.8</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T14.16.16.16.6">0.3</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T14.16.16.16.7">37.2</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T14.16.16.16.8">2.8</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T14.16.16.16.9">27.3</td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_r" id="A1.T14.16.16.16.10">2.8</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T14.16.16.16.11"><span class="ltx_text ltx_font_bold" id="A1.T14.16.16.16.11.1">29.0</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T14.16.16.16.12">0.0</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T14.15.15.15.1"><span class="ltx_text ltx_font_bold" id="A1.T14.15.15.15.1.1">28.9<sup class="ltx_sup" id="A1.T14.15.15.15.1.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="A1.T14.15.15.15.1.1.1.1">â€ </span></sup></span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T14.16.16.16.13">0.2</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T14.16.16.16.2"><span class="ltx_text ltx_font_bold" id="A1.T14.16.16.16.2.1">22.2<sup class="ltx_sup" id="A1.T14.16.16.16.2.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="A1.T14.16.16.16.2.1.1.1">â€ </span></sup></span></td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_r" id="A1.T14.16.16.16.14">0.2</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T14.16.16.16.15">23.2</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T14.16.16.16.16">0.0</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T14.16.16.16.17">24.5</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T14.16.16.16.18">0.5</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T14.16.16.16.19">21.9</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T14.16.16.16.20">0.5</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 14: </span>Performance of keyphrase generation models on the <span class="ltx_text ltx_font_typewriter" id="A1.T14.23.1">nlp</span>, <span class="ltx_text ltx_font_typewriter" id="A1.T14.24.2">astro</span> and <span class="ltx_text ltx_font_typewriter" id="A1.T14.25.3">paleo</span> domains for present and absent keyphrases separately. Values in <span class="ltx_text ltx_font_bold" id="A1.T14.26.4">bold</span> indicate best scores and <math alttext="\dagger" class="ltx_Math" display="inline" id="A1.T14.18.m1.1"><semantics id="A1.T14.18.m1.1b"><mo id="A1.T14.18.m1.1.1" xref="A1.T14.18.m1.1.1.cmml">â€ </mo><annotation-xml encoding="MathML-Content" id="A1.T14.18.m1.1c"><ci id="A1.T14.18.m1.1.1.cmml" xref="A1.T14.18.m1.1.1">â€ </ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T14.18.m1.1d">\dagger</annotation><annotation encoding="application/x-llamapun" id="A1.T14.18.m1.1e">â€ </annotation></semantics></math> indicates significance over BART-FT.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Oct  2 01:13:01 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
