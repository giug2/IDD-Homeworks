<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Direct Neural Machine Translation with Task-level Mixture of Experts models</title>
<!--Generated on Sun May 19 17:47:21 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2310.12236v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#S1" title="In Direct Neural Machine Translation with Task-level Mixture of Experts models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#S2" title="In Direct Neural Machine Translation with Task-level Mixture of Experts models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#S3" title="In Direct Neural Machine Translation with Task-level Mixture of Experts models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Experiments</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#S4" title="In Direct Neural Machine Translation with Task-level Mixture of Experts models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Results &amp; Discussion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#S5" title="In Direct Neural Machine Translation with Task-level Mixture of Experts models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusions</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Direct Neural Machine Translation with Task-level Mixture of Experts models</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Isidora Chara Tourni  
<br class="ltx_break"/>Boston University 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">isidora@bu.edu</span>
<br class="ltx_break"/>&amp;Subhajit Naskar 
<br class="ltx_break"/>Google
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id2.2.id2">snaskar@google.com</span>
<br class="ltx_break"/>
</span><span class="ltx_author_notes">Work completed while interning at Google.</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id3.id1">Direct neural machine translation (direct NMT) is a type of NMT system that translates text between two non-English languages. Direct NMT systems often face limitations due to the scarcity of parallel data between non-English language pairs. Several approaches have been proposed to address this limitation, such as multilingual NMT and pivot NMT (translation between two languages via English).
Task-level Mixture of expert models (Task-level MoE), an inference-efficient variation of Transformer-based models, has shown promising NMT performance for a large number of language pairs. In Task-level MoE, different language groups can use different routing strategies to optimize cross-lingual learning and inference speed. In this work, we examine Task-level MoE’s applicability in direct NMT and propose a series of high-performing training and evaluation configurations, through which Task-level MoE-based direct NMT systems outperform bilingual and pivot-based models for a large number of low and high-resource direct pairs, and translation directions. Our Task-level MoE model with 16 experts outperforms bilingual NMT, Pivot NMT models for 7 language pairs, while pivot-based models still performed better in 9 pairs and directions.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="283" id="S1.F1.g1" src="extracted/5605726/figures/taskmoes.png" width="799"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Task-level MoE model, with LP - based routing; each Language Pair is routed through a top-2 router to an expert in the model experts’ layer. From a pretrained Task-level MoE model we can extract a smaller dense network specializing in a certain task, e.g. ja-ko NMT.</figcaption>
</figure>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">NMT <cite class="ltx_cite ltx_citemacro_citep">(Sutskever et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib48" title="">2014</a>; Bahdanau et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib4" title="">2014</a>; Firat et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib20" title="">2016a</a>; Johnson et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib29" title="">2017</a>; Zoph and Knight, <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib63" title="">2016</a>; Bahdanau et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib4" title="">2014</a>)</cite> has made remarkable progress in recent years, particularly with the advent of the Transformer architecture <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib52" title="">2017</a>)</cite>, which has shown impressive results in bilingual and multilingual translation tasks <cite class="ltx_cite ltx_citemacro_citep">(Aharoni et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib1" title="">2019</a>; Hassan et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib26" title="">2018</a>; Tang et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib50" title="">2021</a>)</cite>. Large Multilingual NMT models in particular have shown noteworthy performance and can serve translations between any languages, even for language pairs not seen in training, for which though NMT quality is often still low. The focus so far has primarily been on English-centric NMT, as there is an abundance of English-centric MT data <cite class="ltx_cite ltx_citemacro_citep">(Tiedemann, <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib51" title="">2018</a>)</cite> but few parallel data for non-English (low-resource) language pairs. Hence the need for improving methods for Direct NMT, i.e. NMT between non-English languages is evident <cite class="ltx_cite ltx_citemacro_citep">(Yang et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib57" title="">2021</a>; Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib60" title="">2020</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Direct NMT methods, when no xx–yy data is available (where xx represents the source language code, and yy represents the target language code),
can be categorized into Zero-shot and Zero-resource approaches.
In Zero-shot NMT <cite class="ltx_cite ltx_citemacro_citep">(Johnson et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib29" title="">2017</a>; Gu et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib25" title="">2019</a>; Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib53" title="">2021</a>; Philip et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib40" title="">2020</a>)</cite>, translation occurs as follows: either through a bridging language, typically English, where models are trained on En–yy and xx–En datasets without ever being exposed to xx–yy data, while evaluation takes place on the few existing xx–yy pairs; or evaluating large multilingual models on xx–yy pairs, with neither xx or yy seen during model training. Zero-resource NMT <cite class="ltx_cite ltx_citemacro_citep">(Currey and Heafield, <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib15" title="">2019</a>; Firat et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib21" title="">2016b</a>; Bapna et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib6" title="">2022</a>)</cite>, on the other hand, generates pseudo-parallel data between direct language pairs, utilizing these synthetic xx–yy datasets during training. Yet bilingual or pivot-based models for direct NMT, though showing impressive NMT quality, are not practical and cost-efficient, especially as the number of languages for translation increases. Additionally, relying on related languages when evaluating a multilingual model on an unseen pair does not guarantee good NMT performance.
At the same time, scaling up to multilingual models of billions of parameters, trained on very large datasets of multiple language pairs, induces large training and inference costs.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Sparse models, and specifically, sparsely activated Mixture-of-Experts (MoE) models <cite class="ltx_cite ltx_citemacro_citep">(Shazeer et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib47" title="">2017</a>; Lepikhin et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib35" title="">2020</a>; Zoph et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib62" title="">2022</a>; Ryabinin and Gusev, <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib45" title="">2020</a>)</cite>, shape a promising direction in creating a universal translation model between all languages, while addressing efficiency concerns. We are the first to investigate performance of a specific type of MoE models, Task-level MoE models <cite class="ltx_cite ltx_citemacro_citep">(Kudugunta et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib32" title="">2021</a>)</cite> in the context of Direct NMT, focusing on the impact of different task-to-expert mapping methods on model performance and expert utilization.
In our experiments, we train large multilingual Task-level MoE models across various configurations, including Zero-shot, Zero-resource, and scenarios where direct language pair data is available.
We conduct a comparative analysis of BLEU scores across Task-level MoE models with different mapping strategies and expert counts, as well as bilingual NMT and pivot-based NMT models; our findings serve as a valuable resource for determining the optimal model configuration to achieve high-quality translation results in various direct language pairs. By training large sparse multilingual Task-level MoE models which perform well for direct pairs, and showcase training efficiency, we may be able to extract smaller expert-specific dense models, which specialize in translating between Language Pairs or translating into one particular language. These models are ready for deployment and can replace bilingual or pivot-based models (Figure <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Direct Neural Machine Translation with Task-level Mixture of Experts models"><span class="ltx_text ltx_ref_tag">1</span></a>).
Prior work on Task-level MoEs <cite class="ltx_cite ltx_citemacro_cite">Kudugunta et al. (<a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib32" title="">2021</a>)</cite> demonstrates the inference efficiency of task-level routing, compared to other approaches (token- or sentence-level), for the task of Multilingual NMT between English-centric pairs (En-yy and xx–En). To the best of our knowledge, we’re the first ones to examine performance of Task-level MoE models in Direct NMT, offering a practical solution for expanding the coverage and quality of NMT across diverse language pairs.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<section class="ltx_subsection" id="S2.SSx1">
<h3 class="ltx_title ltx_title_subsection">Direct Neural Machine Translation</h3>
<div class="ltx_para" id="S2.SSx1.p1">
<p class="ltx_p" id="S2.SSx1.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Firat et al. (<a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib21" title="">2016b</a>)</cite> first proposed a multilingual multi-way zero-resource NMT model which outperformed previous pivot-based approaches, laying the foundation for numerous subsequent zero-shot and/or zero-resource NMT methods. Various researchers have since expanded upon this foundational work, exploring different techniques and strategies for improving direct NMT <cite class="ltx_cite ltx_citemacro_citep">(Ji et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib28" title="">2020</a>; Johnson et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib29" title="">2017</a>; Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib60" title="">2020</a>; Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib11" title="">2017</a>; Lu et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib37" title="">2018</a>; Al-Shedivat and Parikh, <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib2" title="">2019</a>; Rios et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib43" title="">2020</a>; Zheng et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib61" title="">2017</a>; Gu et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib25" title="">2019</a>; Arivazhagan et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib3" title="">2019</a>; Kim et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib30" title="">2019</a>; Cheng and Cheng, <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib13" title="">2019</a>; Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib12" title="">2018</a>; Currey and Heafield, <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib15" title="">2019</a>; Ballesteros and Sanderson, <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib5" title="">2003</a>; Lakew et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib33" title="">2021</a>)</cite>.
More specifically, <cite class="ltx_cite ltx_citemacro_citet">Freitag and Firat (<a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib22" title="">2020</a>)</cite> constructed a multi-way aligned training set from existing training corpora, aligning examples in different language pairs with identical source or target sentences. They introduced a hierarchical data sampling strategy to prevent the over-representation of English in the training set and employed a temperature-based strategy to select target languages, while choosing source languages uniformly. Their complete Multilingual NMT models demonstrated improved performance on direct pairs and comparable to baseline results on English-centric pairs.
<cite class="ltx_cite ltx_citemacro_citet">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib36" title="">2020</a>)</cite> discretized the encoder output latent space into entries in a learned codebook, enabling the representation of source sentences in a common language and increasing model robustness and performance in zero-shot setups.
More recently, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">eriguchi2022building</span></cite>
pre-trained and fine-tuned a many-to-many multilingual NMT model that surpassed several pivoting and bilingual baselines for Direct NMT, and <cite class="ltx_cite ltx_citemacro_citet">ElNokrashy et al. (<a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib17" title="">2022</a>)</cite>, presented a novel approach in which source and target language tokens are appended to the encoder input, while target language tokens are added to the decoder input. This differs from previous methods that used Source-only tokens and beginning of Sentence tokens for the encoder and decoder inputs, respectively, and aims to improve performance of Direct NMT models by providing more relevant context to both the encoder and decoder.</p>
</div>
<div class="ltx_para" id="S2.SSx1.p2">
<p class="ltx_p" id="S2.SSx1.p2.1">Latest works include the approach of <cite class="ltx_cite ltx_citemacro_citet">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib56" title="">2022</a>)</cite>, who unified three distinct models to guide the student model during Direct NMT, aiming to improve its performance by harnessing the strengths of multiple models; and <cite class="ltx_cite ltx_citemacro_citet">Xu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib55" title="">2022</a>)</cite>, who proposed a Direct NMT method comprising two stages: extraction of highly similar examples and their translations across different languages to construct a multi-way aligned parallel dataset, which enables the model to learn from a richer set of translation examples, and generation of additional aligned examples using a well-trained generative model.</p>
</div>
<figure class="ltx_table" id="S2.T1">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" id="S2.T1.8" style="width:433.6pt;height:124.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-1.9pt,0.6pt) scale(0.99119,0.99119) ;">
<p class="ltx_p" id="S2.T1.8.8"><span class="ltx_text" id="S2.T1.8.8.8">
<span class="ltx_inline-block ltx_transformed_outer" id="S2.T1.8.8.8.8" style="width:437.5pt;height:126pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span class="ltx_p" id="S2.T1.8.8.8.8.8"><span class="ltx_text" id="S2.T1.8.8.8.8.8.8">
<span class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S2.T1.8.8.8.8.8.8.8">
<span class="ltx_tbody">
<span class="ltx_tr" id="S2.T1.8.8.8.8.8.8.8.9.1">
<span class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S2.T1.8.8.8.8.8.8.8.9.1.1" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_right ltx_border_tt" id="S2.T1.8.8.8.8.8.8.8.9.1.2" style="padding-left:5.0pt;padding-right:5.0pt;">  ja–th</span>
<span class="ltx_td ltx_border_r ltx_border_tt" id="S2.T1.8.8.8.8.8.8.8.9.1.3" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_right ltx_border_tt" id="S2.T1.8.8.8.8.8.8.8.9.1.4" style="padding-left:5.0pt;padding-right:5.0pt;">  bg–mk</span>
<span class="ltx_td ltx_border_r ltx_border_tt" id="S2.T1.8.8.8.8.8.8.8.9.1.5" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_right ltx_border_tt" id="S2.T1.8.8.8.8.8.8.8.9.1.6" style="padding-left:5.0pt;padding-right:5.0pt;">   ru–tr</span>
<span class="ltx_td ltx_border_r ltx_border_tt" id="S2.T1.8.8.8.8.8.8.8.9.1.7" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_right ltx_border_tt" id="S2.T1.8.8.8.8.8.8.8.9.1.8" style="padding-left:5.0pt;padding-right:5.0pt;">  fr–ar</span>
<span class="ltx_td ltx_border_tt" id="S2.T1.8.8.8.8.8.8.8.9.1.9" style="padding-left:5.0pt;padding-right:5.0pt;"></span></span>
<span class="ltx_tr" id="S2.T1.8.8.8.8.8.8.8.8">
<span class="ltx_td ltx_th ltx_th_row" id="S2.T1.8.8.8.8.8.8.8.8.9" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.1.1.1.1.1.1.1.1.1" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\leftarrow" class="ltx_Math" display="inline" id="S2.T1.1.1.1.1.1.1.1.1.1.m1.1"><semantics id="S2.T1.1.1.1.1.1.1.1.1.1.m1.1a"><mo id="S2.T1.1.1.1.1.1.1.1.1.1.m1.1.1" stretchy="false" xref="S2.T1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="S2.T1.1.1.1.1.1.1.1.1.1.m1.1b"><ci id="S2.T1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S2.T1.1.1.1.1.1.1.1.1.1.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.1.1.1.1.1.1.1.1.1.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T1.1.1.1.1.1.1.1.1.1.m1.1d">←</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S2.T1.2.2.2.2.2.2.2.2.2" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\rightarrow" class="ltx_Math" display="inline" id="S2.T1.2.2.2.2.2.2.2.2.2.m1.1"><semantics id="S2.T1.2.2.2.2.2.2.2.2.2.m1.1a"><mo id="S2.T1.2.2.2.2.2.2.2.2.2.m1.1.1" stretchy="false" xref="S2.T1.2.2.2.2.2.2.2.2.2.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S2.T1.2.2.2.2.2.2.2.2.2.m1.1b"><ci id="S2.T1.2.2.2.2.2.2.2.2.2.m1.1.1.cmml" xref="S2.T1.2.2.2.2.2.2.2.2.2.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.2.2.2.2.2.2.2.2.2.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T1.2.2.2.2.2.2.2.2.2.m1.1d">→</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.3.3.3.3.3.3.3.3.3" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\leftarrow" class="ltx_Math" display="inline" id="S2.T1.3.3.3.3.3.3.3.3.3.m1.1"><semantics id="S2.T1.3.3.3.3.3.3.3.3.3.m1.1a"><mo id="S2.T1.3.3.3.3.3.3.3.3.3.m1.1.1" stretchy="false" xref="S2.T1.3.3.3.3.3.3.3.3.3.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="S2.T1.3.3.3.3.3.3.3.3.3.m1.1b"><ci id="S2.T1.3.3.3.3.3.3.3.3.3.m1.1.1.cmml" xref="S2.T1.3.3.3.3.3.3.3.3.3.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.3.3.3.3.3.3.3.3.3.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T1.3.3.3.3.3.3.3.3.3.m1.1d">←</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S2.T1.4.4.4.4.4.4.4.4.4" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\rightarrow" class="ltx_Math" display="inline" id="S2.T1.4.4.4.4.4.4.4.4.4.m1.1"><semantics id="S2.T1.4.4.4.4.4.4.4.4.4.m1.1a"><mo id="S2.T1.4.4.4.4.4.4.4.4.4.m1.1.1" stretchy="false" xref="S2.T1.4.4.4.4.4.4.4.4.4.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S2.T1.4.4.4.4.4.4.4.4.4.m1.1b"><ci id="S2.T1.4.4.4.4.4.4.4.4.4.m1.1.1.cmml" xref="S2.T1.4.4.4.4.4.4.4.4.4.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.4.4.4.4.4.4.4.4.4.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T1.4.4.4.4.4.4.4.4.4.m1.1d">→</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.5.5.5.5.5.5.5.5.5" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\leftarrow" class="ltx_Math" display="inline" id="S2.T1.5.5.5.5.5.5.5.5.5.m1.1"><semantics id="S2.T1.5.5.5.5.5.5.5.5.5.m1.1a"><mo id="S2.T1.5.5.5.5.5.5.5.5.5.m1.1.1" stretchy="false" xref="S2.T1.5.5.5.5.5.5.5.5.5.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="S2.T1.5.5.5.5.5.5.5.5.5.m1.1b"><ci id="S2.T1.5.5.5.5.5.5.5.5.5.m1.1.1.cmml" xref="S2.T1.5.5.5.5.5.5.5.5.5.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.5.5.5.5.5.5.5.5.5.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T1.5.5.5.5.5.5.5.5.5.m1.1d">←</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S2.T1.6.6.6.6.6.6.6.6.6" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\rightarrow" class="ltx_Math" display="inline" id="S2.T1.6.6.6.6.6.6.6.6.6.m1.1"><semantics id="S2.T1.6.6.6.6.6.6.6.6.6.m1.1a"><mo id="S2.T1.6.6.6.6.6.6.6.6.6.m1.1.1" stretchy="false" xref="S2.T1.6.6.6.6.6.6.6.6.6.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S2.T1.6.6.6.6.6.6.6.6.6.m1.1b"><ci id="S2.T1.6.6.6.6.6.6.6.6.6.m1.1.1.cmml" xref="S2.T1.6.6.6.6.6.6.6.6.6.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.6.6.6.6.6.6.6.6.6.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T1.6.6.6.6.6.6.6.6.6.m1.1d">→</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.7.7.7.7.7.7.7.7.7" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\leftarrow" class="ltx_Math" display="inline" id="S2.T1.7.7.7.7.7.7.7.7.7.m1.1"><semantics id="S2.T1.7.7.7.7.7.7.7.7.7.m1.1a"><mo id="S2.T1.7.7.7.7.7.7.7.7.7.m1.1.1" stretchy="false" xref="S2.T1.7.7.7.7.7.7.7.7.7.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="S2.T1.7.7.7.7.7.7.7.7.7.m1.1b"><ci id="S2.T1.7.7.7.7.7.7.7.7.7.m1.1.1.cmml" xref="S2.T1.7.7.7.7.7.7.7.7.7.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.7.7.7.7.7.7.7.7.7.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T1.7.7.7.7.7.7.7.7.7.m1.1d">←</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.8.8.8.8.8.8.8.8.8" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\rightarrow" class="ltx_Math" display="inline" id="S2.T1.8.8.8.8.8.8.8.8.8.m1.1"><semantics id="S2.T1.8.8.8.8.8.8.8.8.8.m1.1a"><mo id="S2.T1.8.8.8.8.8.8.8.8.8.m1.1.1" stretchy="false" xref="S2.T1.8.8.8.8.8.8.8.8.8.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S2.T1.8.8.8.8.8.8.8.8.8.m1.1b"><ci id="S2.T1.8.8.8.8.8.8.8.8.8.m1.1.1.cmml" xref="S2.T1.8.8.8.8.8.8.8.8.8.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.8.8.8.8.8.8.8.8.8.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T1.8.8.8.8.8.8.8.8.8.m1.1d">→</annotation></semantics></math></span></span>
<span class="ltx_tr" id="S2.T1.8.8.8.8.8.8.8.10.2">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S2.T1.8.8.8.8.8.8.8.10.2.1" style="padding-left:5.0pt;padding-right:5.0pt;">Task-level MoE</span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.8.8.8.8.8.8.8.10.2.2" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.8.8.8.8.8.8.8.10.2.2.1">21.51</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S2.T1.8.8.8.8.8.8.8.10.2.3" style="padding-left:5.0pt;padding-right:5.0pt;">25.36</span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.8.8.8.8.8.8.8.10.2.4" style="padding-left:5.0pt;padding-right:5.0pt;">26.44</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S2.T1.8.8.8.8.8.8.8.10.2.5" style="padding-left:5.0pt;padding-right:5.0pt;">23.29</span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.8.8.8.8.8.8.8.10.2.6" style="padding-left:5.0pt;padding-right:5.0pt;">10.24</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S2.T1.8.8.8.8.8.8.8.10.2.7" style="padding-left:5.0pt;padding-right:5.0pt;">8.72</span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.8.8.8.8.8.8.8.10.2.8" style="padding-left:5.0pt;padding-right:5.0pt;">19.37</span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.8.8.8.8.8.8.8.10.2.9" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.8.8.8.8.8.8.8.10.2.9.1">15.06</span></span></span>
<span class="ltx_tr" id="S2.T1.8.8.8.8.8.8.8.11.3">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.8.8.8.8.8.8.8.11.3.1" style="padding-left:5.0pt;padding-right:5.0pt;">Bilingual</span>
<span class="ltx_td ltx_align_left" id="S2.T1.8.8.8.8.8.8.8.11.3.2" style="padding-left:5.0pt;padding-right:5.0pt;">6.24</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.8.8.8.8.8.8.8.11.3.3" style="padding-left:5.0pt;padding-right:5.0pt;">7.26</span>
<span class="ltx_td ltx_align_left" id="S2.T1.8.8.8.8.8.8.8.11.3.4" style="padding-left:5.0pt;padding-right:5.0pt;">24.47</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.8.8.8.8.8.8.8.11.3.5" style="padding-left:5.0pt;padding-right:5.0pt;">21.28</span>
<span class="ltx_td ltx_align_left" id="S2.T1.8.8.8.8.8.8.8.11.3.6" style="padding-left:5.0pt;padding-right:5.0pt;">9.53</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.8.8.8.8.8.8.8.11.3.7" style="padding-left:5.0pt;padding-right:5.0pt;">7.58</span>
<span class="ltx_td ltx_align_left" id="S2.T1.8.8.8.8.8.8.8.11.3.8" style="padding-left:5.0pt;padding-right:5.0pt;">19.6</span>
<span class="ltx_td ltx_align_left" id="S2.T1.8.8.8.8.8.8.8.11.3.9" style="padding-left:5.0pt;padding-right:5.0pt;">9.71</span></span>
<span class="ltx_tr" id="S2.T1.8.8.8.8.8.8.8.12.4">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.8.8.8.8.8.8.8.12.4.1" style="padding-left:5.0pt;padding-right:5.0pt;">Pivot-level</span>
<span class="ltx_td ltx_align_left" id="S2.T1.8.8.8.8.8.8.8.12.4.2" style="padding-left:5.0pt;padding-right:5.0pt;">18.34</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.8.8.8.8.8.8.8.12.4.3" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.8.8.8.8.8.8.8.12.4.3.1">39.28</span></span>
<span class="ltx_td ltx_align_left" id="S2.T1.8.8.8.8.8.8.8.12.4.4" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.8.8.8.8.8.8.8.12.4.4.1">28.24</span></span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.8.8.8.8.8.8.8.12.4.5" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.8.8.8.8.8.8.8.12.4.5.1">27.03</span></span>
<span class="ltx_td ltx_align_left" id="S2.T1.8.8.8.8.8.8.8.12.4.6" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.8.8.8.8.8.8.8.12.4.6.1">18.44</span></span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.8.8.8.8.8.8.8.12.4.7" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.8.8.8.8.8.8.8.12.4.7.1">13.84</span></span>
<span class="ltx_td ltx_align_left" id="S2.T1.8.8.8.8.8.8.8.12.4.8" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.8.8.8.8.8.8.8.12.4.8.1">21.57</span></span>
<span class="ltx_td ltx_align_left" id="S2.T1.8.8.8.8.8.8.8.12.4.9" style="padding-left:5.0pt;padding-right:5.0pt;">14.91</span></span>
<span class="ltx_tr" id="S2.T1.8.8.8.8.8.8.8.13.5">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S2.T1.8.8.8.8.8.8.8.13.5.1" style="padding-left:5.0pt;padding-right:5.0pt;">Number of Experts</span>
<span class="ltx_td ltx_align_left ltx_border_tt" id="S2.T1.8.8.8.8.8.8.8.13.5.2" style="padding-left:5.0pt;padding-right:5.0pt;">16</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S2.T1.8.8.8.8.8.8.8.13.5.3" style="padding-left:5.0pt;padding-right:5.0pt;">64</span>
<span class="ltx_td ltx_align_left ltx_border_tt" id="S2.T1.8.8.8.8.8.8.8.13.5.4" style="padding-left:5.0pt;padding-right:5.0pt;">16</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S2.T1.8.8.8.8.8.8.8.13.5.5" style="padding-left:5.0pt;padding-right:5.0pt;">16</span>
<span class="ltx_td ltx_align_left ltx_border_tt" id="S2.T1.8.8.8.8.8.8.8.13.5.6" style="padding-left:5.0pt;padding-right:5.0pt;">16</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S2.T1.8.8.8.8.8.8.8.13.5.7" style="padding-left:5.0pt;padding-right:5.0pt;">16</span>
<span class="ltx_td ltx_align_left ltx_border_tt" id="S2.T1.8.8.8.8.8.8.8.13.5.8" style="padding-left:5.0pt;padding-right:5.0pt;">16</span>
<span class="ltx_td ltx_align_left ltx_border_tt" id="S2.T1.8.8.8.8.8.8.8.13.5.9" style="padding-left:5.0pt;padding-right:5.0pt;">16</span></span>
<span class="ltx_tr" id="S2.T1.8.8.8.8.8.8.8.14.6">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S2.T1.8.8.8.8.8.8.8.14.6.1" style="padding-left:5.0pt;padding-right:5.0pt;">Decoding mapping method</span>
<span class="ltx_td ltx_align_left ltx_border_bb" id="S2.T1.8.8.8.8.8.8.8.14.6.2" style="padding-left:5.0pt;padding-right:5.0pt;">lp_b</span>
<span class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S2.T1.8.8.8.8.8.8.8.14.6.3" style="padding-left:5.0pt;padding-right:5.0pt;">tl_b</span>
<span class="ltx_td ltx_align_left ltx_border_bb" id="S2.T1.8.8.8.8.8.8.8.14.6.4" style="padding-left:5.0pt;padding-right:5.0pt;">tl_a</span>
<span class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S2.T1.8.8.8.8.8.8.8.14.6.5" style="padding-left:5.0pt;padding-right:5.0pt;">tl_a</span>
<span class="ltx_td ltx_align_left ltx_border_bb" id="S2.T1.8.8.8.8.8.8.8.14.6.6" style="padding-left:5.0pt;padding-right:5.0pt;">tl_a</span>
<span class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S2.T1.8.8.8.8.8.8.8.14.6.7" style="padding-left:5.0pt;padding-right:5.0pt;">tl_a</span>
<span class="ltx_td ltx_align_left ltx_border_bb" id="S2.T1.8.8.8.8.8.8.8.14.6.8" style="padding-left:5.0pt;padding-right:5.0pt;">tl_a</span>
<span class="ltx_td ltx_align_left ltx_border_bb" id="S2.T1.8.8.8.8.8.8.8.14.6.9" style="padding-left:5.0pt;padding-right:5.0pt;">tl_a</span></span>
</span>
</span></span></span>
</span></span></span></p>
</span></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" id="S2.T1.16" style="width:390.3pt;height:113.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-22.3pt,6.5pt) scale(0.89742,0.89742) ;">
<p class="ltx_p" id="S2.T1.16.8"><span class="ltx_text" id="S2.T1.16.8.8">
<span class="ltx_inline-block ltx_transformed_outer" id="S2.T1.16.8.8.8" style="width:434.9pt;height:126pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span class="ltx_p" id="S2.T1.16.8.8.8.8"><span class="ltx_text" id="S2.T1.16.8.8.8.8.8">
<span class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S2.T1.16.8.8.8.8.8.8">
<span class="ltx_tbody">
<span class="ltx_tr" id="S2.T1.16.8.8.8.8.8.8.9.1">
<span class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S2.T1.16.8.8.8.8.8.8.9.1.1" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_right ltx_border_tt" id="S2.T1.16.8.8.8.8.8.8.9.1.2" style="padding-left:5.0pt;padding-right:5.0pt;">  zh–ko</span>
<span class="ltx_td ltx_border_r ltx_border_tt" id="S2.T1.16.8.8.8.8.8.8.9.1.3" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_right ltx_border_tt" id="S2.T1.16.8.8.8.8.8.8.9.1.4" style="padding-left:5.0pt;padding-right:5.0pt;">   ja–vi</span>
<span class="ltx_td ltx_border_r ltx_border_tt" id="S2.T1.16.8.8.8.8.8.8.9.1.5" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_right ltx_border_tt" id="S2.T1.16.8.8.8.8.8.8.9.1.6" style="padding-left:5.0pt;padding-right:5.0pt;">   ja–ko</span>
<span class="ltx_td ltx_border_r ltx_border_tt" id="S2.T1.16.8.8.8.8.8.8.9.1.7" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_right ltx_border_tt" id="S2.T1.16.8.8.8.8.8.8.9.1.8" style="padding-left:5.0pt;padding-right:5.0pt;">   ja–zh</span>
<span class="ltx_td ltx_border_tt" id="S2.T1.16.8.8.8.8.8.8.9.1.9" style="padding-left:5.0pt;padding-right:5.0pt;"></span></span>
<span class="ltx_tr" id="S2.T1.16.8.8.8.8.8.8.8">
<span class="ltx_td ltx_th ltx_th_row" id="S2.T1.16.8.8.8.8.8.8.8.9" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.9.1.1.1.1.1.1.1.1" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\leftarrow" class="ltx_Math" display="inline" id="S2.T1.9.1.1.1.1.1.1.1.1.m1.1"><semantics id="S2.T1.9.1.1.1.1.1.1.1.1.m1.1a"><mo id="S2.T1.9.1.1.1.1.1.1.1.1.m1.1.1" stretchy="false" xref="S2.T1.9.1.1.1.1.1.1.1.1.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="S2.T1.9.1.1.1.1.1.1.1.1.m1.1b"><ci id="S2.T1.9.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S2.T1.9.1.1.1.1.1.1.1.1.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.9.1.1.1.1.1.1.1.1.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T1.9.1.1.1.1.1.1.1.1.m1.1d">←</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S2.T1.10.2.2.2.2.2.2.2.2" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\rightarrow" class="ltx_Math" display="inline" id="S2.T1.10.2.2.2.2.2.2.2.2.m1.1"><semantics id="S2.T1.10.2.2.2.2.2.2.2.2.m1.1a"><mo id="S2.T1.10.2.2.2.2.2.2.2.2.m1.1.1" stretchy="false" xref="S2.T1.10.2.2.2.2.2.2.2.2.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S2.T1.10.2.2.2.2.2.2.2.2.m1.1b"><ci id="S2.T1.10.2.2.2.2.2.2.2.2.m1.1.1.cmml" xref="S2.T1.10.2.2.2.2.2.2.2.2.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.10.2.2.2.2.2.2.2.2.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T1.10.2.2.2.2.2.2.2.2.m1.1d">→</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.11.3.3.3.3.3.3.3.3" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\leftarrow" class="ltx_Math" display="inline" id="S2.T1.11.3.3.3.3.3.3.3.3.m1.1"><semantics id="S2.T1.11.3.3.3.3.3.3.3.3.m1.1a"><mo id="S2.T1.11.3.3.3.3.3.3.3.3.m1.1.1" stretchy="false" xref="S2.T1.11.3.3.3.3.3.3.3.3.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="S2.T1.11.3.3.3.3.3.3.3.3.m1.1b"><ci id="S2.T1.11.3.3.3.3.3.3.3.3.m1.1.1.cmml" xref="S2.T1.11.3.3.3.3.3.3.3.3.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.11.3.3.3.3.3.3.3.3.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T1.11.3.3.3.3.3.3.3.3.m1.1d">←</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S2.T1.12.4.4.4.4.4.4.4.4" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\rightarrow" class="ltx_Math" display="inline" id="S2.T1.12.4.4.4.4.4.4.4.4.m1.1"><semantics id="S2.T1.12.4.4.4.4.4.4.4.4.m1.1a"><mo id="S2.T1.12.4.4.4.4.4.4.4.4.m1.1.1" stretchy="false" xref="S2.T1.12.4.4.4.4.4.4.4.4.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S2.T1.12.4.4.4.4.4.4.4.4.m1.1b"><ci id="S2.T1.12.4.4.4.4.4.4.4.4.m1.1.1.cmml" xref="S2.T1.12.4.4.4.4.4.4.4.4.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.12.4.4.4.4.4.4.4.4.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T1.12.4.4.4.4.4.4.4.4.m1.1d">→</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.13.5.5.5.5.5.5.5.5" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\leftarrow" class="ltx_Math" display="inline" id="S2.T1.13.5.5.5.5.5.5.5.5.m1.1"><semantics id="S2.T1.13.5.5.5.5.5.5.5.5.m1.1a"><mo id="S2.T1.13.5.5.5.5.5.5.5.5.m1.1.1" stretchy="false" xref="S2.T1.13.5.5.5.5.5.5.5.5.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="S2.T1.13.5.5.5.5.5.5.5.5.m1.1b"><ci id="S2.T1.13.5.5.5.5.5.5.5.5.m1.1.1.cmml" xref="S2.T1.13.5.5.5.5.5.5.5.5.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.13.5.5.5.5.5.5.5.5.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T1.13.5.5.5.5.5.5.5.5.m1.1d">←</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S2.T1.14.6.6.6.6.6.6.6.6" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\rightarrow" class="ltx_Math" display="inline" id="S2.T1.14.6.6.6.6.6.6.6.6.m1.1"><semantics id="S2.T1.14.6.6.6.6.6.6.6.6.m1.1a"><mo id="S2.T1.14.6.6.6.6.6.6.6.6.m1.1.1" stretchy="false" xref="S2.T1.14.6.6.6.6.6.6.6.6.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S2.T1.14.6.6.6.6.6.6.6.6.m1.1b"><ci id="S2.T1.14.6.6.6.6.6.6.6.6.m1.1.1.cmml" xref="S2.T1.14.6.6.6.6.6.6.6.6.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.14.6.6.6.6.6.6.6.6.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T1.14.6.6.6.6.6.6.6.6.m1.1d">→</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.15.7.7.7.7.7.7.7.7" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\leftarrow" class="ltx_Math" display="inline" id="S2.T1.15.7.7.7.7.7.7.7.7.m1.1"><semantics id="S2.T1.15.7.7.7.7.7.7.7.7.m1.1a"><mo id="S2.T1.15.7.7.7.7.7.7.7.7.m1.1.1" stretchy="false" xref="S2.T1.15.7.7.7.7.7.7.7.7.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="S2.T1.15.7.7.7.7.7.7.7.7.m1.1b"><ci id="S2.T1.15.7.7.7.7.7.7.7.7.m1.1.1.cmml" xref="S2.T1.15.7.7.7.7.7.7.7.7.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.15.7.7.7.7.7.7.7.7.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T1.15.7.7.7.7.7.7.7.7.m1.1d">←</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.16.8.8.8.8.8.8.8.8" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\rightarrow" class="ltx_Math" display="inline" id="S2.T1.16.8.8.8.8.8.8.8.8.m1.1"><semantics id="S2.T1.16.8.8.8.8.8.8.8.8.m1.1a"><mo id="S2.T1.16.8.8.8.8.8.8.8.8.m1.1.1" stretchy="false" xref="S2.T1.16.8.8.8.8.8.8.8.8.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S2.T1.16.8.8.8.8.8.8.8.8.m1.1b"><ci id="S2.T1.16.8.8.8.8.8.8.8.8.m1.1.1.cmml" xref="S2.T1.16.8.8.8.8.8.8.8.8.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.16.8.8.8.8.8.8.8.8.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T1.16.8.8.8.8.8.8.8.8.m1.1d">→</annotation></semantics></math></span></span>
<span class="ltx_tr" id="S2.T1.16.8.8.8.8.8.8.10.2">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S2.T1.16.8.8.8.8.8.8.10.2.1" style="padding-left:5.0pt;padding-right:5.0pt;">Task-level MoE</span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.16.8.8.8.8.8.8.10.2.2" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.16.8.8.8.8.8.8.10.2.2.1">34.35</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S2.T1.16.8.8.8.8.8.8.10.2.3" style="padding-left:5.0pt;padding-right:5.0pt;">28.70</span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.16.8.8.8.8.8.8.10.2.4" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.16.8.8.8.8.8.8.10.2.4.1">25.17</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S2.T1.16.8.8.8.8.8.8.10.2.5" style="padding-left:5.0pt;padding-right:5.0pt;">19.18</span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.16.8.8.8.8.8.8.10.2.6" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.16.8.8.8.8.8.8.10.2.6.1">42.64</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S2.T1.16.8.8.8.8.8.8.10.2.7" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.16.8.8.8.8.8.8.10.2.7.1">41.38</span></span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.16.8.8.8.8.8.8.10.2.8" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.16.8.8.8.8.8.8.10.2.8.1">34.94</span></span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.16.8.8.8.8.8.8.10.2.9" style="padding-left:5.0pt;padding-right:5.0pt;">22.52</span></span>
<span class="ltx_tr" id="S2.T1.16.8.8.8.8.8.8.11.3">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.16.8.8.8.8.8.8.11.3.1" style="padding-left:5.0pt;padding-right:5.0pt;">Bilingual</span>
<span class="ltx_td ltx_align_left" id="S2.T1.16.8.8.8.8.8.8.11.3.2" style="padding-left:5.0pt;padding-right:5.0pt;">5.71</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.16.8.8.8.8.8.8.11.3.3" style="padding-left:5.0pt;padding-right:5.0pt;">3.16</span>
<span class="ltx_td ltx_align_left" id="S2.T1.16.8.8.8.8.8.8.11.3.4" style="padding-left:5.0pt;padding-right:5.0pt;">8.20</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.16.8.8.8.8.8.8.11.3.5" style="padding-left:5.0pt;padding-right:5.0pt;">19.6</span>
<span class="ltx_td ltx_align_left" id="S2.T1.16.8.8.8.8.8.8.11.3.6" style="padding-left:5.0pt;padding-right:5.0pt;">6.12</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.16.8.8.8.8.8.8.11.3.7" style="padding-left:5.0pt;padding-right:5.0pt;">4.47</span>
<span class="ltx_td ltx_align_left" id="S2.T1.16.8.8.8.8.8.8.11.3.8" style="padding-left:5.0pt;padding-right:5.0pt;">3.16</span>
<span class="ltx_td ltx_align_left" id="S2.T1.16.8.8.8.8.8.8.11.3.9" style="padding-left:5.0pt;padding-right:5.0pt;">7.26</span></span>
<span class="ltx_tr" id="S2.T1.16.8.8.8.8.8.8.12.4">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.16.8.8.8.8.8.8.12.4.1" style="padding-left:5.0pt;padding-right:5.0pt;">Pivot-level</span>
<span class="ltx_td ltx_align_left" id="S2.T1.16.8.8.8.8.8.8.12.4.2" style="padding-left:5.0pt;padding-right:5.0pt;">28.13</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.16.8.8.8.8.8.8.12.4.3" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.16.8.8.8.8.8.8.12.4.3.1">35.24</span></span>
<span class="ltx_td ltx_align_left" id="S2.T1.16.8.8.8.8.8.8.12.4.4" style="padding-left:5.0pt;padding-right:5.0pt;">18.97</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.16.8.8.8.8.8.8.12.4.5" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.16.8.8.8.8.8.8.12.4.5.1">19.61</span></span>
<span class="ltx_td ltx_align_left" id="S2.T1.16.8.8.8.8.8.8.12.4.6" style="padding-left:5.0pt;padding-right:5.0pt;">21.49</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T1.16.8.8.8.8.8.8.12.4.7" style="padding-left:5.0pt;padding-right:5.0pt;">36.69</span>
<span class="ltx_td ltx_align_left" id="S2.T1.16.8.8.8.8.8.8.12.4.8" style="padding-left:5.0pt;padding-right:5.0pt;">19.98</span>
<span class="ltx_td ltx_align_left" id="S2.T1.16.8.8.8.8.8.8.12.4.9" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.16.8.8.8.8.8.8.12.4.9.1">27.46</span></span></span>
<span class="ltx_tr" id="S2.T1.16.8.8.8.8.8.8.13.5">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S2.T1.16.8.8.8.8.8.8.13.5.1" style="padding-left:5.0pt;padding-right:5.0pt;">Number of Experts</span>
<span class="ltx_td ltx_align_left ltx_border_tt" id="S2.T1.16.8.8.8.8.8.8.13.5.2" style="padding-left:5.0pt;padding-right:5.0pt;">16</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S2.T1.16.8.8.8.8.8.8.13.5.3" style="padding-left:5.0pt;padding-right:5.0pt;">16</span>
<span class="ltx_td ltx_align_left ltx_border_tt" id="S2.T1.16.8.8.8.8.8.8.13.5.4" style="padding-left:5.0pt;padding-right:5.0pt;">16</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S2.T1.16.8.8.8.8.8.8.13.5.5" style="padding-left:5.0pt;padding-right:5.0pt;">64</span>
<span class="ltx_td ltx_align_left ltx_border_tt" id="S2.T1.16.8.8.8.8.8.8.13.5.6" style="padding-left:5.0pt;padding-right:5.0pt;">16</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S2.T1.16.8.8.8.8.8.8.13.5.7" style="padding-left:5.0pt;padding-right:5.0pt;">16</span>
<span class="ltx_td ltx_align_left ltx_border_tt" id="S2.T1.16.8.8.8.8.8.8.13.5.8" style="padding-left:5.0pt;padding-right:5.0pt;">16</span>
<span class="ltx_td ltx_align_left ltx_border_tt" id="S2.T1.16.8.8.8.8.8.8.13.5.9" style="padding-left:5.0pt;padding-right:5.0pt;">64</span></span>
<span class="ltx_tr" id="S2.T1.16.8.8.8.8.8.8.14.6">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S2.T1.16.8.8.8.8.8.8.14.6.1" style="padding-left:5.0pt;padding-right:5.0pt;">Decoding mapping method</span>
<span class="ltx_td ltx_align_left ltx_border_bb" id="S2.T1.16.8.8.8.8.8.8.14.6.2" style="padding-left:5.0pt;padding-right:5.0pt;">lp_b</span>
<span class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S2.T1.16.8.8.8.8.8.8.14.6.3" style="padding-left:5.0pt;padding-right:5.0pt;">lp_b</span>
<span class="ltx_td ltx_align_left ltx_border_bb" id="S2.T1.16.8.8.8.8.8.8.14.6.4" style="padding-left:5.0pt;padding-right:5.0pt;">lp_b</span>
<span class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S2.T1.16.8.8.8.8.8.8.14.6.5" style="padding-left:5.0pt;padding-right:5.0pt;">lp_a</span>
<span class="ltx_td ltx_align_left ltx_border_bb" id="S2.T1.16.8.8.8.8.8.8.14.6.6" style="padding-left:5.0pt;padding-right:5.0pt;">lp_b</span>
<span class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S2.T1.16.8.8.8.8.8.8.14.6.7" style="padding-left:5.0pt;padding-right:5.0pt;">lp_b</span>
<span class="ltx_td ltx_align_left ltx_border_bb" id="S2.T1.16.8.8.8.8.8.8.14.6.8" style="padding-left:5.0pt;padding-right:5.0pt;">lp_b</span>
<span class="ltx_td ltx_align_left ltx_border_bb" id="S2.T1.16.8.8.8.8.8.8.14.6.9" style="padding-left:5.0pt;padding-right:5.0pt;">lp_a</span></span>
</span>
</span></span></span>
</span></span></span></p>
</span></div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Best BLEU scores from our Task-level MoE models trained with 16 or 64 experts, for direct pairs. We compare to Bilingual and Pivot-level NMT models’ scores and state the Task-level MoE model/setup under which best scores were obtained. overall best scores per pair are highlighted. lp_x decoding mapping method implies a model trained with Language Pair (LP) - based task to expert mapping, and tl_x implies target language (TL) - based task to expert mapping.</figcaption>
</figure>
<figure class="ltx_table" id="S2.T2">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" id="S2.T2.8" style="width:433.6pt;height:159.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-27.4pt,10.1pt) scale(0.88765,0.88765) ;">
<p class="ltx_p" id="S2.T2.8.8"><span class="ltx_text" id="S2.T2.8.8.8">
<span class="ltx_inline-block ltx_transformed_outer" id="S2.T2.8.8.8.8" style="width:488.5pt;height:180pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span class="ltx_p" id="S2.T2.8.8.8.8.8"><span class="ltx_text" id="S2.T2.8.8.8.8.8.8">
<span class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S2.T2.8.8.8.8.8.8.8">
<span class="ltx_thead">
<span class="ltx_tr" id="S2.T2.8.8.8.8.8.8.8.9.1">
<span class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S2.T2.8.8.8.8.8.8.8.9.1.1" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S2.T2.8.8.8.8.8.8.8.9.1.2" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S2.T2.8.8.8.8.8.8.8.9.1.3" style="padding-left:5.0pt;padding-right:5.0pt;">  ja–th</span>
<span class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S2.T2.8.8.8.8.8.8.8.9.1.4" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S2.T2.8.8.8.8.8.8.8.9.1.5" style="padding-left:5.0pt;padding-right:5.0pt;">  bg–mk</span>
<span class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S2.T2.8.8.8.8.8.8.8.9.1.6" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S2.T2.8.8.8.8.8.8.8.9.1.7" style="padding-left:5.0pt;padding-right:5.0pt;">   ru–tr</span>
<span class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S2.T2.8.8.8.8.8.8.8.9.1.8" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S2.T2.8.8.8.8.8.8.8.9.1.9" style="padding-left:5.0pt;padding-right:5.0pt;">  fr–ar</span>
<span class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="S2.T2.8.8.8.8.8.8.8.9.1.10" style="padding-left:5.0pt;padding-right:5.0pt;"></span></span>
<span class="ltx_tr" id="S2.T2.8.8.8.8.8.8.8.8">
<span class="ltx_td ltx_th ltx_th_column ltx_th_row" id="S2.T2.8.8.8.8.8.8.8.8.9" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_th ltx_th_column ltx_th_row" id="S2.T2.8.8.8.8.8.8.8.8.10" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S2.T2.1.1.1.1.1.1.1.1.1" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\leftarrow" class="ltx_Math" display="inline" id="S2.T2.1.1.1.1.1.1.1.1.1.m1.1"><semantics id="S2.T2.1.1.1.1.1.1.1.1.1.m1.1a"><mo id="S2.T2.1.1.1.1.1.1.1.1.1.m1.1.1" stretchy="false" xref="S2.T2.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="S2.T2.1.1.1.1.1.1.1.1.1.m1.1b"><ci id="S2.T2.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S2.T2.1.1.1.1.1.1.1.1.1.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.1.1.1.1.1.1.1.1.1.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T2.1.1.1.1.1.1.1.1.1.m1.1d">←</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S2.T2.2.2.2.2.2.2.2.2.2" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\rightarrow" class="ltx_Math" display="inline" id="S2.T2.2.2.2.2.2.2.2.2.2.m1.1"><semantics id="S2.T2.2.2.2.2.2.2.2.2.2.m1.1a"><mo id="S2.T2.2.2.2.2.2.2.2.2.2.m1.1.1" stretchy="false" xref="S2.T2.2.2.2.2.2.2.2.2.2.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S2.T2.2.2.2.2.2.2.2.2.2.m1.1b"><ci id="S2.T2.2.2.2.2.2.2.2.2.2.m1.1.1.cmml" xref="S2.T2.2.2.2.2.2.2.2.2.2.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.2.2.2.2.2.2.2.2.2.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T2.2.2.2.2.2.2.2.2.2.m1.1d">→</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S2.T2.3.3.3.3.3.3.3.3.3" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\leftarrow" class="ltx_Math" display="inline" id="S2.T2.3.3.3.3.3.3.3.3.3.m1.1"><semantics id="S2.T2.3.3.3.3.3.3.3.3.3.m1.1a"><mo id="S2.T2.3.3.3.3.3.3.3.3.3.m1.1.1" stretchy="false" xref="S2.T2.3.3.3.3.3.3.3.3.3.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="S2.T2.3.3.3.3.3.3.3.3.3.m1.1b"><ci id="S2.T2.3.3.3.3.3.3.3.3.3.m1.1.1.cmml" xref="S2.T2.3.3.3.3.3.3.3.3.3.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.3.3.3.3.3.3.3.3.3.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T2.3.3.3.3.3.3.3.3.3.m1.1d">←</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S2.T2.4.4.4.4.4.4.4.4.4" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\rightarrow" class="ltx_Math" display="inline" id="S2.T2.4.4.4.4.4.4.4.4.4.m1.1"><semantics id="S2.T2.4.4.4.4.4.4.4.4.4.m1.1a"><mo id="S2.T2.4.4.4.4.4.4.4.4.4.m1.1.1" stretchy="false" xref="S2.T2.4.4.4.4.4.4.4.4.4.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S2.T2.4.4.4.4.4.4.4.4.4.m1.1b"><ci id="S2.T2.4.4.4.4.4.4.4.4.4.m1.1.1.cmml" xref="S2.T2.4.4.4.4.4.4.4.4.4.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.4.4.4.4.4.4.4.4.4.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T2.4.4.4.4.4.4.4.4.4.m1.1d">→</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S2.T2.5.5.5.5.5.5.5.5.5" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\leftarrow" class="ltx_Math" display="inline" id="S2.T2.5.5.5.5.5.5.5.5.5.m1.1"><semantics id="S2.T2.5.5.5.5.5.5.5.5.5.m1.1a"><mo id="S2.T2.5.5.5.5.5.5.5.5.5.m1.1.1" stretchy="false" xref="S2.T2.5.5.5.5.5.5.5.5.5.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="S2.T2.5.5.5.5.5.5.5.5.5.m1.1b"><ci id="S2.T2.5.5.5.5.5.5.5.5.5.m1.1.1.cmml" xref="S2.T2.5.5.5.5.5.5.5.5.5.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.5.5.5.5.5.5.5.5.5.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T2.5.5.5.5.5.5.5.5.5.m1.1d">←</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S2.T2.6.6.6.6.6.6.6.6.6" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\rightarrow" class="ltx_Math" display="inline" id="S2.T2.6.6.6.6.6.6.6.6.6.m1.1"><semantics id="S2.T2.6.6.6.6.6.6.6.6.6.m1.1a"><mo id="S2.T2.6.6.6.6.6.6.6.6.6.m1.1.1" stretchy="false" xref="S2.T2.6.6.6.6.6.6.6.6.6.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S2.T2.6.6.6.6.6.6.6.6.6.m1.1b"><ci id="S2.T2.6.6.6.6.6.6.6.6.6.m1.1.1.cmml" xref="S2.T2.6.6.6.6.6.6.6.6.6.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.6.6.6.6.6.6.6.6.6.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T2.6.6.6.6.6.6.6.6.6.m1.1d">→</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S2.T2.7.7.7.7.7.7.7.7.7" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\leftarrow" class="ltx_Math" display="inline" id="S2.T2.7.7.7.7.7.7.7.7.7.m1.1"><semantics id="S2.T2.7.7.7.7.7.7.7.7.7.m1.1a"><mo id="S2.T2.7.7.7.7.7.7.7.7.7.m1.1.1" stretchy="false" xref="S2.T2.7.7.7.7.7.7.7.7.7.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="S2.T2.7.7.7.7.7.7.7.7.7.m1.1b"><ci id="S2.T2.7.7.7.7.7.7.7.7.7.m1.1.1.cmml" xref="S2.T2.7.7.7.7.7.7.7.7.7.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.7.7.7.7.7.7.7.7.7.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T2.7.7.7.7.7.7.7.7.7.m1.1d">←</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S2.T2.8.8.8.8.8.8.8.8.8" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\rightarrow" class="ltx_Math" display="inline" id="S2.T2.8.8.8.8.8.8.8.8.8.m1.1"><semantics id="S2.T2.8.8.8.8.8.8.8.8.8.m1.1a"><mo id="S2.T2.8.8.8.8.8.8.8.8.8.m1.1.1" stretchy="false" xref="S2.T2.8.8.8.8.8.8.8.8.8.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S2.T2.8.8.8.8.8.8.8.8.8.m1.1b"><ci id="S2.T2.8.8.8.8.8.8.8.8.8.m1.1.1.cmml" xref="S2.T2.8.8.8.8.8.8.8.8.8.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.8.8.8.8.8.8.8.8.8.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T2.8.8.8.8.8.8.8.8.8.m1.1d">→</annotation></semantics></math></span></span>
</span>
<span class="ltx_tbody">
<span class="ltx_tr" id="S2.T2.8.8.8.8.8.8.8.10.1">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S2.T2.8.8.8.8.8.8.8.10.1.1" style="padding-left:5.0pt;padding-right:5.0pt;">Task-level MoE (LP)</span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S2.T2.8.8.8.8.8.8.8.10.1.2" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T2.8.8.8.8.8.8.8.10.1.2.1">lp_a</span></span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.8.8.8.8.8.8.8.10.1.3" style="padding-left:5.0pt;padding-right:5.0pt;">0.47</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S2.T2.8.8.8.8.8.8.8.10.1.4" style="padding-left:5.0pt;padding-right:5.0pt;">2.26</span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.8.8.8.8.8.8.8.10.1.5" style="padding-left:5.0pt;padding-right:5.0pt;">3.21</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S2.T2.8.8.8.8.8.8.8.10.1.6" style="padding-left:5.0pt;padding-right:5.0pt;">22.75</span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.8.8.8.8.8.8.8.10.1.7" style="padding-left:5.0pt;padding-right:5.0pt;">1.55</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S2.T2.8.8.8.8.8.8.8.10.1.8" style="padding-left:5.0pt;padding-right:5.0pt;">0.74</span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.8.8.8.8.8.8.8.10.1.9" style="padding-left:5.0pt;padding-right:5.0pt;">-</span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.8.8.8.8.8.8.8.10.1.10" style="padding-left:5.0pt;padding-right:5.0pt;">-</span></span>
<span class="ltx_tr" id="S2.T2.8.8.8.8.8.8.8.11.2">
<span class="ltx_td ltx_th ltx_th_row" id="S2.T2.8.8.8.8.8.8.8.11.2.1" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T2.8.8.8.8.8.8.8.11.2.2" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T2.8.8.8.8.8.8.8.11.2.2.1">lp_b</span></span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.11.2.3" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T2.8.8.8.8.8.8.8.11.2.3.1">21.51</span></span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.8.8.8.8.8.8.8.11.2.4" style="padding-left:5.0pt;padding-right:5.0pt;">18.92</span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.11.2.5" style="padding-left:5.0pt;padding-right:5.0pt;">3.07</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.8.8.8.8.8.8.8.11.2.6" style="padding-left:5.0pt;padding-right:5.0pt;">20.43</span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.11.2.7" style="padding-left:5.0pt;padding-right:5.0pt;">4.86</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.8.8.8.8.8.8.8.11.2.8" style="padding-left:5.0pt;padding-right:5.0pt;">0.83</span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.11.2.9" style="padding-left:5.0pt;padding-right:5.0pt;">19.37</span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.11.2.10" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T2.8.8.8.8.8.8.8.11.2.10.1">15.06</span></span></span>
<span class="ltx_tr" id="S2.T2.8.8.8.8.8.8.8.12.3">
<span class="ltx_td ltx_th ltx_th_row" id="S2.T2.8.8.8.8.8.8.8.12.3.1" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T2.8.8.8.8.8.8.8.12.3.2" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T2.8.8.8.8.8.8.8.12.3.2.1">lp_c</span></span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.12.3.3" style="padding-left:5.0pt;padding-right:5.0pt;">0.42</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.8.8.8.8.8.8.8.12.3.4" style="padding-left:5.0pt;padding-right:5.0pt;">1.50</span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.12.3.5" style="padding-left:5.0pt;padding-right:5.0pt;">5.97</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.8.8.8.8.8.8.8.12.3.6" style="padding-left:5.0pt;padding-right:5.0pt;">18.32</span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.12.3.7" style="padding-left:5.0pt;padding-right:5.0pt;">5.57</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.8.8.8.8.8.8.8.12.3.8" style="padding-left:5.0pt;padding-right:5.0pt;">0.80</span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.12.3.9" style="padding-left:5.0pt;padding-right:5.0pt;">2.40</span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.12.3.10" style="padding-left:5.0pt;padding-right:5.0pt;">0.86</span></span>
<span class="ltx_tr" id="S2.T2.8.8.8.8.8.8.8.13.4">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T2.8.8.8.8.8.8.8.13.4.1" style="padding-left:5.0pt;padding-right:5.0pt;">Task-level MoE (TL)</span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T2.8.8.8.8.8.8.8.13.4.2" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T2.8.8.8.8.8.8.8.13.4.2.1">tl_a</span></span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.13.4.3" style="padding-left:5.0pt;padding-right:5.0pt;">1.15</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.8.8.8.8.8.8.8.13.4.4" style="padding-left:5.0pt;padding-right:5.0pt;">0.78</span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.13.4.5" style="padding-left:5.0pt;padding-right:5.0pt;">26.44</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.8.8.8.8.8.8.8.13.4.6" style="padding-left:5.0pt;padding-right:5.0pt;">23.29</span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.13.4.7" style="padding-left:5.0pt;padding-right:5.0pt;">10.24</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.8.8.8.8.8.8.8.13.4.8" style="padding-left:5.0pt;padding-right:5.0pt;">8.72</span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.13.4.9" style="padding-left:5.0pt;padding-right:5.0pt;">5.36</span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.13.4.10" style="padding-left:5.0pt;padding-right:5.0pt;">1.18</span></span>
<span class="ltx_tr" id="S2.T2.8.8.8.8.8.8.8.14.5">
<span class="ltx_td ltx_th ltx_th_row" id="S2.T2.8.8.8.8.8.8.8.14.5.1" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T2.8.8.8.8.8.8.8.14.5.2" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T2.8.8.8.8.8.8.8.14.5.2.1">tl_b</span></span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.14.5.3" style="padding-left:5.0pt;padding-right:5.0pt;">1.39</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.8.8.8.8.8.8.8.14.5.4" style="padding-left:5.0pt;padding-right:5.0pt;">6.09</span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.14.5.5" style="padding-left:5.0pt;padding-right:5.0pt;">5.19</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.8.8.8.8.8.8.8.14.5.6" style="padding-left:5.0pt;padding-right:5.0pt;">10.15</span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.14.5.7" style="padding-left:5.0pt;padding-right:5.0pt;">4.45</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.8.8.8.8.8.8.8.14.5.8" style="padding-left:5.0pt;padding-right:5.0pt;">0.86</span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.14.5.9" style="padding-left:5.0pt;padding-right:5.0pt;">5.62</span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.14.5.10" style="padding-left:5.0pt;padding-right:5.0pt;">0.81</span></span>
<span class="ltx_tr" id="S2.T2.8.8.8.8.8.8.8.15.6">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T2.8.8.8.8.8.8.8.15.6.1" style="padding-left:5.0pt;padding-right:5.0pt;">Bilingual</span>
<span class="ltx_td ltx_th ltx_th_row" id="S2.T2.8.8.8.8.8.8.8.15.6.2" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.15.6.3" style="padding-left:5.0pt;padding-right:5.0pt;">6.24</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.8.8.8.8.8.8.8.15.6.4" style="padding-left:5.0pt;padding-right:5.0pt;">7.26</span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.15.6.5" style="padding-left:5.0pt;padding-right:5.0pt;">24.47</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.8.8.8.8.8.8.8.15.6.6" style="padding-left:5.0pt;padding-right:5.0pt;">21.28</span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.15.6.7" style="padding-left:5.0pt;padding-right:5.0pt;">9.53</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.8.8.8.8.8.8.8.15.6.8" style="padding-left:5.0pt;padding-right:5.0pt;">7.58</span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.15.6.9" style="padding-left:5.0pt;padding-right:5.0pt;">19.60</span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.15.6.10" style="padding-left:5.0pt;padding-right:5.0pt;">9.71</span></span>
<span class="ltx_tr" id="S2.T2.8.8.8.8.8.8.8.16.7">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T2.8.8.8.8.8.8.8.16.7.1" style="padding-left:5.0pt;padding-right:5.0pt;">Pivot-level</span>
<span class="ltx_td ltx_th ltx_th_row" id="S2.T2.8.8.8.8.8.8.8.16.7.2" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.16.7.3" style="padding-left:5.0pt;padding-right:5.0pt;">18.34</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.8.8.8.8.8.8.8.16.7.4" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T2.8.8.8.8.8.8.8.16.7.4.1">39.28</span></span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.16.7.5" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T2.8.8.8.8.8.8.8.16.7.5.1">28.24</span></span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.8.8.8.8.8.8.8.16.7.6" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T2.8.8.8.8.8.8.8.16.7.6.1">27.03</span></span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.16.7.7" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T2.8.8.8.8.8.8.8.16.7.7.1">18.44</span></span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.8.8.8.8.8.8.8.16.7.8" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T2.8.8.8.8.8.8.8.16.7.8.1">13.84</span></span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.16.7.9" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T2.8.8.8.8.8.8.8.16.7.9.1">21.57</span></span>
<span class="ltx_td ltx_align_left" id="S2.T2.8.8.8.8.8.8.8.16.7.10" style="padding-left:5.0pt;padding-right:5.0pt;">14.91</span></span>
<span class="ltx_tr" id="S2.T2.8.8.8.8.8.8.8.17.8">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S2.T2.8.8.8.8.8.8.8.17.8.1" style="padding-left:5.0pt;padding-right:5.0pt;">Number of train sentences</span>
<span class="ltx_td ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S2.T2.8.8.8.8.8.8.8.17.8.2" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S2.T2.8.8.8.8.8.8.8.17.8.3" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S2.T2.8.8.8.8.8.8.8.17.8.3.1">6,200</span></span>
<span class="ltx_td ltx_border_bb ltx_border_r ltx_border_t" id="S2.T2.8.8.8.8.8.8.8.17.8.4" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S2.T2.8.8.8.8.8.8.8.17.8.5" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S2.T2.8.8.8.8.8.8.8.17.8.5.1">205,651</span></span>
<span class="ltx_td ltx_border_bb ltx_border_r ltx_border_t" id="S2.T2.8.8.8.8.8.8.8.17.8.6" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S2.T2.8.8.8.8.8.8.8.17.8.7" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S2.T2.8.8.8.8.8.8.8.17.8.7.1">1,467,160</span></span>
<span class="ltx_td ltx_border_bb ltx_border_r ltx_border_t" id="S2.T2.8.8.8.8.8.8.8.17.8.8" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S2.T2.8.8.8.8.8.8.8.17.8.9" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S2.T2.8.8.8.8.8.8.8.17.8.9.1">17,163,359</span></span>
<span class="ltx_td ltx_border_bb ltx_border_t" id="S2.T2.8.8.8.8.8.8.8.17.8.10" style="padding-left:5.0pt;padding-right:5.0pt;"></span></span>
</span>
</span></span></span>
</span></span></span></p>
</span></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" id="S2.T2.16" style="width:390.3pt;height:148.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-40.9pt,15.6pt) scale(0.82662,0.82662) ;">
<p class="ltx_p" id="S2.T2.16.8"><span class="ltx_text" id="S2.T2.16.8.8">
<span class="ltx_inline-block ltx_transformed_outer" id="S2.T2.16.8.8.8" style="width:472.1pt;height:180pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span class="ltx_p" id="S2.T2.16.8.8.8.8"><span class="ltx_text" id="S2.T2.16.8.8.8.8.8">
<span class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S2.T2.16.8.8.8.8.8.8">
<span class="ltx_thead">
<span class="ltx_tr" id="S2.T2.16.8.8.8.8.8.8.9.1">
<span class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S2.T2.16.8.8.8.8.8.8.9.1.1" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S2.T2.16.8.8.8.8.8.8.9.1.2" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S2.T2.16.8.8.8.8.8.8.9.1.3" style="padding-left:5.0pt;padding-right:5.0pt;">  zh–ko</span>
<span class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S2.T2.16.8.8.8.8.8.8.9.1.4" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S2.T2.16.8.8.8.8.8.8.9.1.5" style="padding-left:5.0pt;padding-right:5.0pt;">   ja–vi</span>
<span class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S2.T2.16.8.8.8.8.8.8.9.1.6" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S2.T2.16.8.8.8.8.8.8.9.1.7" style="padding-left:5.0pt;padding-right:5.0pt;">   ja–ko</span>
<span class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S2.T2.16.8.8.8.8.8.8.9.1.8" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S2.T2.16.8.8.8.8.8.8.9.1.9" style="padding-left:5.0pt;padding-right:5.0pt;">   ja–zh</span>
<span class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="S2.T2.16.8.8.8.8.8.8.9.1.10" style="padding-left:5.0pt;padding-right:5.0pt;"></span></span>
<span class="ltx_tr" id="S2.T2.16.8.8.8.8.8.8.8">
<span class="ltx_td ltx_th ltx_th_column ltx_th_row" id="S2.T2.16.8.8.8.8.8.8.8.9" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_th ltx_th_column ltx_th_row" id="S2.T2.16.8.8.8.8.8.8.8.10" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S2.T2.9.1.1.1.1.1.1.1.1" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\leftarrow" class="ltx_Math" display="inline" id="S2.T2.9.1.1.1.1.1.1.1.1.m1.1"><semantics id="S2.T2.9.1.1.1.1.1.1.1.1.m1.1a"><mo id="S2.T2.9.1.1.1.1.1.1.1.1.m1.1.1" stretchy="false" xref="S2.T2.9.1.1.1.1.1.1.1.1.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="S2.T2.9.1.1.1.1.1.1.1.1.m1.1b"><ci id="S2.T2.9.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S2.T2.9.1.1.1.1.1.1.1.1.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.9.1.1.1.1.1.1.1.1.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T2.9.1.1.1.1.1.1.1.1.m1.1d">←</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S2.T2.10.2.2.2.2.2.2.2.2" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\rightarrow" class="ltx_Math" display="inline" id="S2.T2.10.2.2.2.2.2.2.2.2.m1.1"><semantics id="S2.T2.10.2.2.2.2.2.2.2.2.m1.1a"><mo id="S2.T2.10.2.2.2.2.2.2.2.2.m1.1.1" stretchy="false" xref="S2.T2.10.2.2.2.2.2.2.2.2.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S2.T2.10.2.2.2.2.2.2.2.2.m1.1b"><ci id="S2.T2.10.2.2.2.2.2.2.2.2.m1.1.1.cmml" xref="S2.T2.10.2.2.2.2.2.2.2.2.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.10.2.2.2.2.2.2.2.2.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T2.10.2.2.2.2.2.2.2.2.m1.1d">→</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S2.T2.11.3.3.3.3.3.3.3.3" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\leftarrow" class="ltx_Math" display="inline" id="S2.T2.11.3.3.3.3.3.3.3.3.m1.1"><semantics id="S2.T2.11.3.3.3.3.3.3.3.3.m1.1a"><mo id="S2.T2.11.3.3.3.3.3.3.3.3.m1.1.1" stretchy="false" xref="S2.T2.11.3.3.3.3.3.3.3.3.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="S2.T2.11.3.3.3.3.3.3.3.3.m1.1b"><ci id="S2.T2.11.3.3.3.3.3.3.3.3.m1.1.1.cmml" xref="S2.T2.11.3.3.3.3.3.3.3.3.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.11.3.3.3.3.3.3.3.3.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T2.11.3.3.3.3.3.3.3.3.m1.1d">←</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S2.T2.12.4.4.4.4.4.4.4.4" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\rightarrow" class="ltx_Math" display="inline" id="S2.T2.12.4.4.4.4.4.4.4.4.m1.1"><semantics id="S2.T2.12.4.4.4.4.4.4.4.4.m1.1a"><mo id="S2.T2.12.4.4.4.4.4.4.4.4.m1.1.1" stretchy="false" xref="S2.T2.12.4.4.4.4.4.4.4.4.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S2.T2.12.4.4.4.4.4.4.4.4.m1.1b"><ci id="S2.T2.12.4.4.4.4.4.4.4.4.m1.1.1.cmml" xref="S2.T2.12.4.4.4.4.4.4.4.4.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.12.4.4.4.4.4.4.4.4.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T2.12.4.4.4.4.4.4.4.4.m1.1d">→</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S2.T2.13.5.5.5.5.5.5.5.5" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\leftarrow" class="ltx_Math" display="inline" id="S2.T2.13.5.5.5.5.5.5.5.5.m1.1"><semantics id="S2.T2.13.5.5.5.5.5.5.5.5.m1.1a"><mo id="S2.T2.13.5.5.5.5.5.5.5.5.m1.1.1" stretchy="false" xref="S2.T2.13.5.5.5.5.5.5.5.5.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="S2.T2.13.5.5.5.5.5.5.5.5.m1.1b"><ci id="S2.T2.13.5.5.5.5.5.5.5.5.m1.1.1.cmml" xref="S2.T2.13.5.5.5.5.5.5.5.5.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.13.5.5.5.5.5.5.5.5.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T2.13.5.5.5.5.5.5.5.5.m1.1d">←</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S2.T2.14.6.6.6.6.6.6.6.6" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\rightarrow" class="ltx_Math" display="inline" id="S2.T2.14.6.6.6.6.6.6.6.6.m1.1"><semantics id="S2.T2.14.6.6.6.6.6.6.6.6.m1.1a"><mo id="S2.T2.14.6.6.6.6.6.6.6.6.m1.1.1" stretchy="false" xref="S2.T2.14.6.6.6.6.6.6.6.6.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S2.T2.14.6.6.6.6.6.6.6.6.m1.1b"><ci id="S2.T2.14.6.6.6.6.6.6.6.6.m1.1.1.cmml" xref="S2.T2.14.6.6.6.6.6.6.6.6.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.14.6.6.6.6.6.6.6.6.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T2.14.6.6.6.6.6.6.6.6.m1.1d">→</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S2.T2.15.7.7.7.7.7.7.7.7" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\leftarrow" class="ltx_Math" display="inline" id="S2.T2.15.7.7.7.7.7.7.7.7.m1.1"><semantics id="S2.T2.15.7.7.7.7.7.7.7.7.m1.1a"><mo id="S2.T2.15.7.7.7.7.7.7.7.7.m1.1.1" stretchy="false" xref="S2.T2.15.7.7.7.7.7.7.7.7.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="S2.T2.15.7.7.7.7.7.7.7.7.m1.1b"><ci id="S2.T2.15.7.7.7.7.7.7.7.7.m1.1.1.cmml" xref="S2.T2.15.7.7.7.7.7.7.7.7.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.15.7.7.7.7.7.7.7.7.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T2.15.7.7.7.7.7.7.7.7.m1.1d">←</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S2.T2.16.8.8.8.8.8.8.8.8" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\rightarrow" class="ltx_Math" display="inline" id="S2.T2.16.8.8.8.8.8.8.8.8.m1.1"><semantics id="S2.T2.16.8.8.8.8.8.8.8.8.m1.1a"><mo id="S2.T2.16.8.8.8.8.8.8.8.8.m1.1.1" stretchy="false" xref="S2.T2.16.8.8.8.8.8.8.8.8.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S2.T2.16.8.8.8.8.8.8.8.8.m1.1b"><ci id="S2.T2.16.8.8.8.8.8.8.8.8.m1.1.1.cmml" xref="S2.T2.16.8.8.8.8.8.8.8.8.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.16.8.8.8.8.8.8.8.8.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T2.16.8.8.8.8.8.8.8.8.m1.1d">→</annotation></semantics></math></span></span>
</span>
<span class="ltx_tbody">
<span class="ltx_tr" id="S2.T2.16.8.8.8.8.8.8.10.1">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S2.T2.16.8.8.8.8.8.8.10.1.1" style="padding-left:5.0pt;padding-right:5.0pt;">Task-level MoE (LP)</span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S2.T2.16.8.8.8.8.8.8.10.1.2" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T2.16.8.8.8.8.8.8.10.1.2.1">lp_a</span></span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.16.8.8.8.8.8.8.10.1.3" style="padding-left:5.0pt;padding-right:5.0pt;">2.81</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S2.T2.16.8.8.8.8.8.8.10.1.4" style="padding-left:5.0pt;padding-right:5.0pt;">4.09</span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.16.8.8.8.8.8.8.10.1.5" style="padding-left:5.0pt;padding-right:5.0pt;">0.77</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S2.T2.16.8.8.8.8.8.8.10.1.6" style="padding-left:5.0pt;padding-right:5.0pt;">5.32</span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.16.8.8.8.8.8.8.10.1.7" style="padding-left:5.0pt;padding-right:5.0pt;">3.33</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S2.T2.16.8.8.8.8.8.8.10.1.8" style="padding-left:5.0pt;padding-right:5.0pt;">11.78</span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.16.8.8.8.8.8.8.10.1.9" style="padding-left:5.0pt;padding-right:5.0pt;">1.67</span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.16.8.8.8.8.8.8.10.1.10" style="padding-left:5.0pt;padding-right:5.0pt;">9.06</span></span>
<span class="ltx_tr" id="S2.T2.16.8.8.8.8.8.8.11.2">
<span class="ltx_td ltx_th ltx_th_row" id="S2.T2.16.8.8.8.8.8.8.11.2.1" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T2.16.8.8.8.8.8.8.11.2.2" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T2.16.8.8.8.8.8.8.11.2.2.1">lp_b</span></span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.11.2.3" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T2.16.8.8.8.8.8.8.11.2.3.1">34.35</span></span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.16.8.8.8.8.8.8.11.2.4" style="padding-left:5.0pt;padding-right:5.0pt;">28.70</span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.11.2.5" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T2.16.8.8.8.8.8.8.11.2.5.1">25.17</span></span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.16.8.8.8.8.8.8.11.2.6" style="padding-left:5.0pt;padding-right:5.0pt;">1.78</span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.11.2.7" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T2.16.8.8.8.8.8.8.11.2.7.1">42.64</span></span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.16.8.8.8.8.8.8.11.2.8" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T2.16.8.8.8.8.8.8.11.2.8.1">41.38</span></span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.11.2.9" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T2.16.8.8.8.8.8.8.11.2.9.1">34.93</span></span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.11.2.10" style="padding-left:5.0pt;padding-right:5.0pt;">2.50</span></span>
<span class="ltx_tr" id="S2.T2.16.8.8.8.8.8.8.12.3">
<span class="ltx_td ltx_th ltx_th_row" id="S2.T2.16.8.8.8.8.8.8.12.3.1" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T2.16.8.8.8.8.8.8.12.3.2" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T2.16.8.8.8.8.8.8.12.3.2.1">lp_c</span></span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.12.3.3" style="padding-left:5.0pt;padding-right:5.0pt;">2.35</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.16.8.8.8.8.8.8.12.3.4" style="padding-left:5.0pt;padding-right:5.0pt;">3.04</span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.12.3.5" style="padding-left:5.0pt;padding-right:5.0pt;">0.57</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.16.8.8.8.8.8.8.12.3.6" style="padding-left:5.0pt;padding-right:5.0pt;">1.31</span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.12.3.7" style="padding-left:5.0pt;padding-right:5.0pt;">2.71</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.16.8.8.8.8.8.8.12.3.8" style="padding-left:5.0pt;padding-right:5.0pt;">10.14</span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.12.3.9" style="padding-left:5.0pt;padding-right:5.0pt;">1.30</span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.12.3.10" style="padding-left:5.0pt;padding-right:5.0pt;">2.26</span></span>
<span class="ltx_tr" id="S2.T2.16.8.8.8.8.8.8.13.4">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T2.16.8.8.8.8.8.8.13.4.1" style="padding-left:5.0pt;padding-right:5.0pt;">Task-level MoE (TL)</span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T2.16.8.8.8.8.8.8.13.4.2" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T2.16.8.8.8.8.8.8.13.4.2.1">tl_a</span></span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.13.4.3" style="padding-left:5.0pt;padding-right:5.0pt;">4.51</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.16.8.8.8.8.8.8.13.4.4" style="padding-left:5.0pt;padding-right:5.0pt;">0.61</span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.13.4.5" style="padding-left:5.0pt;padding-right:5.0pt;">0.87</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.16.8.8.8.8.8.8.13.4.6" style="padding-left:5.0pt;padding-right:5.0pt;">14.31</span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.13.4.7" style="padding-left:5.0pt;padding-right:5.0pt;">3.87</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.16.8.8.8.8.8.8.13.4.8" style="padding-left:5.0pt;padding-right:5.0pt;">1.30</span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.13.4.9" style="padding-left:5.0pt;padding-right:5.0pt;">1.86</span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.13.4.10" style="padding-left:5.0pt;padding-right:5.0pt;">18.77</span></span>
<span class="ltx_tr" id="S2.T2.16.8.8.8.8.8.8.14.5">
<span class="ltx_td ltx_th ltx_th_row" id="S2.T2.16.8.8.8.8.8.8.14.5.1" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T2.16.8.8.8.8.8.8.14.5.2" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T2.16.8.8.8.8.8.8.14.5.2.1">tl_b</span></span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.14.5.3" style="padding-left:5.0pt;padding-right:5.0pt;">4.44</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.16.8.8.8.8.8.8.14.5.4" style="padding-left:5.0pt;padding-right:5.0pt;">10.7</span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.14.5.5" style="padding-left:5.0pt;padding-right:5.0pt;">1.34</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.16.8.8.8.8.8.8.14.5.6" style="padding-left:5.0pt;padding-right:5.0pt;">4.80</span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.14.5.7" style="padding-left:5.0pt;padding-right:5.0pt;">3.91</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.16.8.8.8.8.8.8.14.5.8" style="padding-left:5.0pt;padding-right:5.0pt;">19.91</span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.14.5.9" style="padding-left:5.0pt;padding-right:5.0pt;">2.79</span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.14.5.10" style="padding-left:5.0pt;padding-right:5.0pt;">4.06</span></span>
<span class="ltx_tr" id="S2.T2.16.8.8.8.8.8.8.15.6">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T2.16.8.8.8.8.8.8.15.6.1" style="padding-left:5.0pt;padding-right:5.0pt;">Bilingual</span>
<span class="ltx_td ltx_th ltx_th_row" id="S2.T2.16.8.8.8.8.8.8.15.6.2" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.15.6.3" style="padding-left:5.0pt;padding-right:5.0pt;">5.71</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.16.8.8.8.8.8.8.15.6.4" style="padding-left:5.0pt;padding-right:5.0pt;">3.16</span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.15.6.5" style="padding-left:5.0pt;padding-right:5.0pt;">8.20</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.16.8.8.8.8.8.8.15.6.6" style="padding-left:5.0pt;padding-right:5.0pt;">19.6</span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.15.6.7" style="padding-left:5.0pt;padding-right:5.0pt;">6.12</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.16.8.8.8.8.8.8.15.6.8" style="padding-left:5.0pt;padding-right:5.0pt;">4.47</span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.15.6.9" style="padding-left:5.0pt;padding-right:5.0pt;">3.16</span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.15.6.10" style="padding-left:5.0pt;padding-right:5.0pt;">7.26</span></span>
<span class="ltx_tr" id="S2.T2.16.8.8.8.8.8.8.16.7">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T2.16.8.8.8.8.8.8.16.7.1" style="padding-left:5.0pt;padding-right:5.0pt;">Pivot-level</span>
<span class="ltx_td ltx_th ltx_th_row" id="S2.T2.16.8.8.8.8.8.8.16.7.2" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.16.7.3" style="padding-left:5.0pt;padding-right:5.0pt;">28.13</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.16.8.8.8.8.8.8.16.7.4" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T2.16.8.8.8.8.8.8.16.7.4.1">35.24</span></span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.16.7.5" style="padding-left:5.0pt;padding-right:5.0pt;">18.97</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.16.8.8.8.8.8.8.16.7.6" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T2.16.8.8.8.8.8.8.16.7.6.1">19.61</span></span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.16.7.7" style="padding-left:5.0pt;padding-right:5.0pt;">21.49</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T2.16.8.8.8.8.8.8.16.7.8" style="padding-left:5.0pt;padding-right:5.0pt;">36.69</span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.16.7.9" style="padding-left:5.0pt;padding-right:5.0pt;">19.98</span>
<span class="ltx_td ltx_align_left" id="S2.T2.16.8.8.8.8.8.8.16.7.10" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T2.16.8.8.8.8.8.8.16.7.10.1">27.46</span></span></span>
<span class="ltx_tr" id="S2.T2.16.8.8.8.8.8.8.17.8">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S2.T2.16.8.8.8.8.8.8.17.8.1" style="padding-left:5.0pt;padding-right:5.0pt;">Number of train sentences</span>
<span class="ltx_td ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S2.T2.16.8.8.8.8.8.8.17.8.2" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S2.T2.16.8.8.8.8.8.8.17.8.3" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S2.T2.16.8.8.8.8.8.8.17.8.3.1">498,968</span></span>
<span class="ltx_td ltx_border_bb ltx_border_r ltx_border_t" id="S2.T2.16.8.8.8.8.8.8.17.8.4" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S2.T2.16.8.8.8.8.8.8.17.8.5" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S2.T2.16.8.8.8.8.8.8.17.8.5.1">604,940</span></span>
<span class="ltx_td ltx_border_bb ltx_border_r ltx_border_t" id="S2.T2.16.8.8.8.8.8.8.17.8.6" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S2.T2.16.8.8.8.8.8.8.17.8.7" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S2.T2.16.8.8.8.8.8.8.17.8.7.1">974,896</span></span>
<span class="ltx_td ltx_border_bb ltx_border_r ltx_border_t" id="S2.T2.16.8.8.8.8.8.8.17.8.8" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S2.T2.16.8.8.8.8.8.8.17.8.9" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S2.T2.16.8.8.8.8.8.8.17.8.9.1">1,339,622</span></span>
<span class="ltx_td ltx_border_bb ltx_border_t" id="S2.T2.16.8.8.8.8.8.8.17.8.10" style="padding-left:5.0pt;padding-right:5.0pt;"></span></span>
</span>
</span></span></span>
</span></span></span></p>
</span></div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>BLEU scores of Task-level MoE models trained with 16 experts, for direct pairs, in both directions, for models with Language Pair (LP) - or target language (TL) - based routing during training, lp_a, lp_b, lp_c and tl_a, tl_b mapping during inference, respectively. We compare to Bilingual and Pivot-level NMT models’ scores and highlight the model/setup under which best scores were obtained.</figcaption>
</figure>
<figure class="ltx_table" id="S2.T3">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S2.T3.11" style="width:433.6pt;height:125pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-95.4pt,27.5pt) scale(0.69453,0.69453) ;">
<p class="ltx_p" id="S2.T3.11.11"><span class="ltx_text" id="S2.T3.11.11.11">
<span class="ltx_inline-block ltx_transformed_outer" id="S2.T3.11.11.11.11" style="width:624.3pt;height:180pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span class="ltx_p" id="S2.T3.11.11.11.11.11"><span class="ltx_text" id="S2.T3.11.11.11.11.11.11">
<span class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S2.T3.11.11.11.11.11.11.11">
<span class="ltx_thead">
<span class="ltx_tr" id="S2.T3.11.11.11.11.11.11.11.12.1">
<span class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="S2.T3.11.11.11.11.11.11.11.12.1.1" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="S2.T3.11.11.11.11.11.11.11.12.1.2" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S2.T3.11.11.11.11.11.11.11.12.1.3" style="padding-left:5.0pt;padding-right:5.0pt;">  ja-th</span>
<span class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S2.T3.11.11.11.11.11.11.11.12.1.4" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S2.T3.11.11.11.11.11.11.11.12.1.5" style="padding-left:5.0pt;padding-right:5.0pt;">bg-mk</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S2.T3.11.11.11.11.11.11.11.12.1.6" style="padding-left:5.0pt;padding-right:5.0pt;">   fr-ar</span>
<span class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S2.T3.11.11.11.11.11.11.11.12.1.7" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S2.T3.11.11.11.11.11.11.11.12.1.8" style="padding-left:5.0pt;padding-right:5.0pt;">  zh–ko</span>
<span class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S2.T3.11.11.11.11.11.11.11.12.1.9" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S2.T3.11.11.11.11.11.11.11.12.1.10" style="padding-left:5.0pt;padding-right:5.0pt;">ja–vi</span>
<span class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S2.T3.11.11.11.11.11.11.11.12.1.11" style="padding-left:5.0pt;padding-right:5.0pt;">  ja–ko</span>
<span class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S2.T3.11.11.11.11.11.11.11.12.1.12" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T3.11.11.11.11.11.11.11.12.1.13" style="padding-left:5.0pt;padding-right:5.0pt;">ja–zh</span></span>
<span class="ltx_tr" id="S2.T3.11.11.11.11.11.11.11.11">
<span class="ltx_td ltx_th ltx_th_column" id="S2.T3.11.11.11.11.11.11.11.11.12" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_th ltx_th_column" id="S2.T3.11.11.11.11.11.11.11.11.13" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S2.T3.1.1.1.1.1.1.1.1.1" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\leftarrow" class="ltx_Math" display="inline" id="S2.T3.1.1.1.1.1.1.1.1.1.m1.1"><semantics id="S2.T3.1.1.1.1.1.1.1.1.1.m1.1a"><mo id="S2.T3.1.1.1.1.1.1.1.1.1.m1.1.1" stretchy="false" xref="S2.T3.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="S2.T3.1.1.1.1.1.1.1.1.1.m1.1b"><ci id="S2.T3.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S2.T3.1.1.1.1.1.1.1.1.1.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.1.1.1.1.1.1.1.1.1.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T3.1.1.1.1.1.1.1.1.1.m1.1d">←</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S2.T3.2.2.2.2.2.2.2.2.2" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\rightarrow" class="ltx_Math" display="inline" id="S2.T3.2.2.2.2.2.2.2.2.2.m1.1"><semantics id="S2.T3.2.2.2.2.2.2.2.2.2.m1.1a"><mo id="S2.T3.2.2.2.2.2.2.2.2.2.m1.1.1" stretchy="false" xref="S2.T3.2.2.2.2.2.2.2.2.2.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S2.T3.2.2.2.2.2.2.2.2.2.m1.1b"><ci id="S2.T3.2.2.2.2.2.2.2.2.2.m1.1.1.cmml" xref="S2.T3.2.2.2.2.2.2.2.2.2.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.2.2.2.2.2.2.2.2.2.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T3.2.2.2.2.2.2.2.2.2.m1.1d">→</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S2.T3.3.3.3.3.3.3.3.3.3" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\rightarrow" class="ltx_Math" display="inline" id="S2.T3.3.3.3.3.3.3.3.3.3.m1.1"><semantics id="S2.T3.3.3.3.3.3.3.3.3.3.m1.1a"><mo id="S2.T3.3.3.3.3.3.3.3.3.3.m1.1.1" stretchy="false" xref="S2.T3.3.3.3.3.3.3.3.3.3.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S2.T3.3.3.3.3.3.3.3.3.3.m1.1b"><ci id="S2.T3.3.3.3.3.3.3.3.3.3.m1.1.1.cmml" xref="S2.T3.3.3.3.3.3.3.3.3.3.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.3.3.3.3.3.3.3.3.3.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T3.3.3.3.3.3.3.3.3.3.m1.1d">→</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S2.T3.4.4.4.4.4.4.4.4.4" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\leftarrow" class="ltx_Math" display="inline" id="S2.T3.4.4.4.4.4.4.4.4.4.m1.1"><semantics id="S2.T3.4.4.4.4.4.4.4.4.4.m1.1a"><mo id="S2.T3.4.4.4.4.4.4.4.4.4.m1.1.1" stretchy="false" xref="S2.T3.4.4.4.4.4.4.4.4.4.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="S2.T3.4.4.4.4.4.4.4.4.4.m1.1b"><ci id="S2.T3.4.4.4.4.4.4.4.4.4.m1.1.1.cmml" xref="S2.T3.4.4.4.4.4.4.4.4.4.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.4.4.4.4.4.4.4.4.4.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T3.4.4.4.4.4.4.4.4.4.m1.1d">←</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S2.T3.5.5.5.5.5.5.5.5.5" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\rightarrow" class="ltx_Math" display="inline" id="S2.T3.5.5.5.5.5.5.5.5.5.m1.1"><semantics id="S2.T3.5.5.5.5.5.5.5.5.5.m1.1a"><mo id="S2.T3.5.5.5.5.5.5.5.5.5.m1.1.1" stretchy="false" xref="S2.T3.5.5.5.5.5.5.5.5.5.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S2.T3.5.5.5.5.5.5.5.5.5.m1.1b"><ci id="S2.T3.5.5.5.5.5.5.5.5.5.m1.1.1.cmml" xref="S2.T3.5.5.5.5.5.5.5.5.5.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.5.5.5.5.5.5.5.5.5.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T3.5.5.5.5.5.5.5.5.5.m1.1d">→</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S2.T3.6.6.6.6.6.6.6.6.6" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\leftarrow" class="ltx_Math" display="inline" id="S2.T3.6.6.6.6.6.6.6.6.6.m1.1"><semantics id="S2.T3.6.6.6.6.6.6.6.6.6.m1.1a"><mo id="S2.T3.6.6.6.6.6.6.6.6.6.m1.1.1" stretchy="false" xref="S2.T3.6.6.6.6.6.6.6.6.6.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="S2.T3.6.6.6.6.6.6.6.6.6.m1.1b"><ci id="S2.T3.6.6.6.6.6.6.6.6.6.m1.1.1.cmml" xref="S2.T3.6.6.6.6.6.6.6.6.6.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.6.6.6.6.6.6.6.6.6.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T3.6.6.6.6.6.6.6.6.6.m1.1d">←</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S2.T3.7.7.7.7.7.7.7.7.7" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\rightarrow" class="ltx_Math" display="inline" id="S2.T3.7.7.7.7.7.7.7.7.7.m1.1"><semantics id="S2.T3.7.7.7.7.7.7.7.7.7.m1.1a"><mo id="S2.T3.7.7.7.7.7.7.7.7.7.m1.1.1" stretchy="false" xref="S2.T3.7.7.7.7.7.7.7.7.7.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S2.T3.7.7.7.7.7.7.7.7.7.m1.1b"><ci id="S2.T3.7.7.7.7.7.7.7.7.7.m1.1.1.cmml" xref="S2.T3.7.7.7.7.7.7.7.7.7.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.7.7.7.7.7.7.7.7.7.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T3.7.7.7.7.7.7.7.7.7.m1.1d">→</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S2.T3.8.8.8.8.8.8.8.8.8" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\leftarrow" class="ltx_Math" display="inline" id="S2.T3.8.8.8.8.8.8.8.8.8.m1.1"><semantics id="S2.T3.8.8.8.8.8.8.8.8.8.m1.1a"><mo id="S2.T3.8.8.8.8.8.8.8.8.8.m1.1.1" stretchy="false" xref="S2.T3.8.8.8.8.8.8.8.8.8.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="S2.T3.8.8.8.8.8.8.8.8.8.m1.1b"><ci id="S2.T3.8.8.8.8.8.8.8.8.8.m1.1.1.cmml" xref="S2.T3.8.8.8.8.8.8.8.8.8.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.8.8.8.8.8.8.8.8.8.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T3.8.8.8.8.8.8.8.8.8.m1.1d">←</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S2.T3.9.9.9.9.9.9.9.9.9" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\leftarrow" class="ltx_Math" display="inline" id="S2.T3.9.9.9.9.9.9.9.9.9.m1.1"><semantics id="S2.T3.9.9.9.9.9.9.9.9.9.m1.1a"><mo id="S2.T3.9.9.9.9.9.9.9.9.9.m1.1.1" stretchy="false" xref="S2.T3.9.9.9.9.9.9.9.9.9.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="S2.T3.9.9.9.9.9.9.9.9.9.m1.1b"><ci id="S2.T3.9.9.9.9.9.9.9.9.9.m1.1.1.cmml" xref="S2.T3.9.9.9.9.9.9.9.9.9.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.9.9.9.9.9.9.9.9.9.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T3.9.9.9.9.9.9.9.9.9.m1.1d">←</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S2.T3.10.10.10.10.10.10.10.10.10" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\rightarrow" class="ltx_Math" display="inline" id="S2.T3.10.10.10.10.10.10.10.10.10.m1.1"><semantics id="S2.T3.10.10.10.10.10.10.10.10.10.m1.1a"><mo id="S2.T3.10.10.10.10.10.10.10.10.10.m1.1.1" stretchy="false" xref="S2.T3.10.10.10.10.10.10.10.10.10.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S2.T3.10.10.10.10.10.10.10.10.10.m1.1b"><ci id="S2.T3.10.10.10.10.10.10.10.10.10.m1.1.1.cmml" xref="S2.T3.10.10.10.10.10.10.10.10.10.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.10.10.10.10.10.10.10.10.10.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T3.10.10.10.10.10.10.10.10.10.m1.1d">→</annotation></semantics></math></span>
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S2.T3.11.11.11.11.11.11.11.11.11" style="padding-left:5.0pt;padding-right:5.0pt;"><math alttext="\leftarrow" class="ltx_Math" display="inline" id="S2.T3.11.11.11.11.11.11.11.11.11.m1.1"><semantics id="S2.T3.11.11.11.11.11.11.11.11.11.m1.1a"><mo id="S2.T3.11.11.11.11.11.11.11.11.11.m1.1.1" stretchy="false" xref="S2.T3.11.11.11.11.11.11.11.11.11.m1.1.1.cmml">←</mo><annotation-xml encoding="MathML-Content" id="S2.T3.11.11.11.11.11.11.11.11.11.m1.1b"><ci id="S2.T3.11.11.11.11.11.11.11.11.11.m1.1.1.cmml" xref="S2.T3.11.11.11.11.11.11.11.11.11.m1.1.1">←</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.11.11.11.11.11.11.11.11.11.m1.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="S2.T3.11.11.11.11.11.11.11.11.11.m1.1d">←</annotation></semantics></math></span></span>
</span>
<span class="ltx_tbody">
<span class="ltx_tr" id="S2.T3.11.11.11.11.11.11.11.13.1">
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T3.11.11.11.11.11.11.11.13.1.1" style="padding-left:5.0pt;padding-right:5.0pt;">Task-level MoE (LP)</span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T3.11.11.11.11.11.11.11.13.1.2" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T3.11.11.11.11.11.11.11.13.1.2.1">lp_a</span></span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T3.11.11.11.11.11.11.11.13.1.3" style="padding-left:5.0pt;padding-right:5.0pt;">16.33</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S2.T3.11.11.11.11.11.11.11.13.1.4" style="padding-left:5.0pt;padding-right:5.0pt;">17.50</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S2.T3.11.11.11.11.11.11.11.13.1.5" style="padding-left:5.0pt;padding-right:5.0pt;">19.18</span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T3.11.11.11.11.11.11.11.13.1.6" style="padding-left:5.0pt;padding-right:5.0pt;">-</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S2.T3.11.11.11.11.11.11.11.13.1.7" style="padding-left:5.0pt;padding-right:5.0pt;">-</span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T3.11.11.11.11.11.11.11.13.1.8" style="padding-left:5.0pt;padding-right:5.0pt;">21.34</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S2.T3.11.11.11.11.11.11.11.13.1.9" style="padding-left:5.0pt;padding-right:5.0pt;">19.08</span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S2.T3.11.11.11.11.11.11.11.13.1.10" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T3.11.11.11.11.11.11.11.13.1.10.1">19.18</span></span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T3.11.11.11.11.11.11.11.13.1.11" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T3.11.11.11.11.11.11.11.13.1.11.1">25.3</span></span>
<span class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S2.T3.11.11.11.11.11.11.11.13.1.12" style="padding-left:5.0pt;padding-right:5.0pt;">25.25</span>
<span class="ltx_td ltx_align_left ltx_border_t" id="S2.T3.11.11.11.11.11.11.11.13.1.13" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T3.11.11.11.11.11.11.11.13.1.13.1">22.52</span></span></span>
<span class="ltx_tr" id="S2.T3.11.11.11.11.11.11.11.14.2">
<span class="ltx_td" id="S2.T3.11.11.11.11.11.11.11.14.2.1" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.14.2.2" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T3.11.11.11.11.11.11.11.14.2.2.1">lp_b</span></span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.14.2.3" style="padding-left:5.0pt;padding-right:5.0pt;">0.44</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.14.2.4" style="padding-left:5.0pt;padding-right:5.0pt;">2.79</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.14.2.5" style="padding-left:5.0pt;padding-right:5.0pt;">19.07</span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.14.2.6" style="padding-left:5.0pt;padding-right:5.0pt;">4.47</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.14.2.7" style="padding-left:5.0pt;padding-right:5.0pt;">2.13</span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.14.2.8" style="padding-left:5.0pt;padding-right:5.0pt;">2.05</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.14.2.9" style="padding-left:5.0pt;padding-right:5.0pt;">2.51</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.14.2.10" style="padding-left:5.0pt;padding-right:5.0pt;">0.47</span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.14.2.11" style="padding-left:5.0pt;padding-right:5.0pt;">0.96</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.14.2.12" style="padding-left:5.0pt;padding-right:5.0pt;">4.46</span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.14.2.13" style="padding-left:5.0pt;padding-right:5.0pt;">0.71</span></span>
<span class="ltx_tr" id="S2.T3.11.11.11.11.11.11.11.15.3">
<span class="ltx_td" id="S2.T3.11.11.11.11.11.11.11.15.3.1" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.15.3.2" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T3.11.11.11.11.11.11.11.15.3.2.1">lp_c</span></span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.15.3.3" style="padding-left:5.0pt;padding-right:5.0pt;">0.36</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.15.3.4" style="padding-left:5.0pt;padding-right:5.0pt;">0.50</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.15.3.5" style="padding-left:5.0pt;padding-right:5.0pt;">19.04</span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.15.3.6" style="padding-left:5.0pt;padding-right:5.0pt;">2.69</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.15.3.7" style="padding-left:5.0pt;padding-right:5.0pt;">1.18</span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.15.3.8" style="padding-left:5.0pt;padding-right:5.0pt;">0.59</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.15.3.9" style="padding-left:5.0pt;padding-right:5.0pt;">0.47</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.15.3.10" style="padding-left:5.0pt;padding-right:5.0pt;">0.45</span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.15.3.11" style="padding-left:5.0pt;padding-right:5.0pt;">0.80</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.15.3.12" style="padding-left:5.0pt;padding-right:5.0pt;">2.05</span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.15.3.13" style="padding-left:5.0pt;padding-right:5.0pt;">0.56</span></span>
<span class="ltx_tr" id="S2.T3.11.11.11.11.11.11.11.16.4">
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.16.4.1" style="padding-left:5.0pt;padding-right:5.0pt;">Task-level MoE (TL)</span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.16.4.2" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T3.11.11.11.11.11.11.11.16.4.2.1">tl_a</span></span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.16.4.3" style="padding-left:5.0pt;padding-right:5.0pt;">8.30</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.16.4.4" style="padding-left:5.0pt;padding-right:5.0pt;">25.33</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.16.4.5" style="padding-left:5.0pt;padding-right:5.0pt;">20.29</span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.16.4.6" style="padding-left:5.0pt;padding-right:5.0pt;">7.37</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.16.4.7" style="padding-left:5.0pt;padding-right:5.0pt;">5.38</span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.16.4.8" style="padding-left:5.0pt;padding-right:5.0pt;">12.61</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.16.4.9" style="padding-left:5.0pt;padding-right:5.0pt;">20.27</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.16.4.10" style="padding-left:5.0pt;padding-right:5.0pt;">5.95</span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.16.4.11" style="padding-left:5.0pt;padding-right:5.0pt;">14.25</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.16.4.12" style="padding-left:5.0pt;padding-right:5.0pt;">26.39</span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.16.4.13" style="padding-left:5.0pt;padding-right:5.0pt;">0.01</span></span>
<span class="ltx_tr" id="S2.T3.11.11.11.11.11.11.11.17.5">
<span class="ltx_td" id="S2.T3.11.11.11.11.11.11.11.17.5.1" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.17.5.2" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T3.11.11.11.11.11.11.11.17.5.2.1">tl_b</span></span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.17.5.3" style="padding-left:5.0pt;padding-right:5.0pt;">8.33</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.17.5.4" style="padding-left:5.0pt;padding-right:5.0pt;">25.36</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.17.5.5" style="padding-left:5.0pt;padding-right:5.0pt;">20.35</span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.17.5.6" style="padding-left:5.0pt;padding-right:5.0pt;">7.32</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.17.5.7" style="padding-left:5.0pt;padding-right:5.0pt;">5.50</span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.17.5.8" style="padding-left:5.0pt;padding-right:5.0pt;">12.43</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.17.5.9" style="padding-left:5.0pt;padding-right:5.0pt;">20.34</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.17.5.10" style="padding-left:5.0pt;padding-right:5.0pt;">5.96</span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.17.5.11" style="padding-left:5.0pt;padding-right:5.0pt;">14.26</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.17.5.12" style="padding-left:5.0pt;padding-right:5.0pt;">26.40</span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.17.5.13" style="padding-left:5.0pt;padding-right:5.0pt;">10.49</span></span>
<span class="ltx_tr" id="S2.T3.11.11.11.11.11.11.11.18.6">
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.18.6.1" style="padding-left:5.0pt;padding-right:5.0pt;">Bilingual</span>
<span class="ltx_td" id="S2.T3.11.11.11.11.11.11.11.18.6.2" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.18.6.3" style="padding-left:5.0pt;padding-right:5.0pt;">6.24</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.18.6.4" style="padding-left:5.0pt;padding-right:5.0pt;">7.26</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.18.6.5" style="padding-left:5.0pt;padding-right:5.0pt;">21.28</span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.18.6.6" style="padding-left:5.0pt;padding-right:5.0pt;">9.71</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.18.6.7" style="padding-left:5.0pt;padding-right:5.0pt;">19.60</span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.18.6.8" style="padding-left:5.0pt;padding-right:5.0pt;">5.71</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.18.6.9" style="padding-left:5.0pt;padding-right:5.0pt;">3.16</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.18.6.10" style="padding-left:5.0pt;padding-right:5.0pt;">8.20</span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.18.6.11" style="padding-left:5.0pt;padding-right:5.0pt;">6.12</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.18.6.12" style="padding-left:5.0pt;padding-right:5.0pt;">4.47</span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.18.6.13" style="padding-left:5.0pt;padding-right:5.0pt;">3.16</span></span>
<span class="ltx_tr" id="S2.T3.11.11.11.11.11.11.11.19.7">
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.19.7.1" style="padding-left:5.0pt;padding-right:5.0pt;">Pivot-level</span>
<span class="ltx_td" id="S2.T3.11.11.11.11.11.11.11.19.7.2" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.19.7.3" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T3.11.11.11.11.11.11.11.19.7.3.1">18.34</span></span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.19.7.4" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T3.11.11.11.11.11.11.11.19.7.4.1">39.28</span></span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.19.7.5" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T3.11.11.11.11.11.11.11.19.7.5.1">27.03</span></span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.19.7.6" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T3.11.11.11.11.11.11.11.19.7.6.1">14.91</span></span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.19.7.7" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T3.11.11.11.11.11.11.11.19.7.7.1">21.57</span></span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.19.7.8" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T3.11.11.11.11.11.11.11.19.7.8.1">28.13</span></span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.19.7.9" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T3.11.11.11.11.11.11.11.19.7.9.1">35.24</span></span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.19.7.10" style="padding-left:5.0pt;padding-right:5.0pt;">18.97</span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.19.7.11" style="padding-left:5.0pt;padding-right:5.0pt;">21.49</span>
<span class="ltx_td ltx_align_left ltx_border_r" id="S2.T3.11.11.11.11.11.11.11.19.7.12" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T3.11.11.11.11.11.11.11.19.7.12.1">36.69</span></span>
<span class="ltx_td ltx_align_left" id="S2.T3.11.11.11.11.11.11.11.19.7.13" style="padding-left:5.0pt;padding-right:5.0pt;">19.98</span></span>
<span class="ltx_tr" id="S2.T3.11.11.11.11.11.11.11.20.8">
<span class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S2.T3.11.11.11.11.11.11.11.20.8.1" style="padding-left:5.0pt;padding-right:5.0pt;">Number of train sentences</span>
<span class="ltx_td ltx_border_bb ltx_border_t" id="S2.T3.11.11.11.11.11.11.11.20.8.2" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S2.T3.11.11.11.11.11.11.11.20.8.3" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S2.T3.11.11.11.11.11.11.11.20.8.3.1">6,200</span></span>
<span class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S2.T3.11.11.11.11.11.11.11.20.8.4" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S2.T3.11.11.11.11.11.11.11.20.8.4.1">205,651</span></span>
<span class="ltx_td ltx_border_bb ltx_border_r ltx_border_t" id="S2.T3.11.11.11.11.11.11.11.20.8.5" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S2.T3.11.11.11.11.11.11.11.20.8.6" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S2.T3.11.11.11.11.11.11.11.20.8.6.1">17,163,359</span></span>
<span class="ltx_td ltx_border_bb ltx_border_r ltx_border_t" id="S2.T3.11.11.11.11.11.11.11.20.8.7" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S2.T3.11.11.11.11.11.11.11.20.8.8" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S2.T3.11.11.11.11.11.11.11.20.8.8.1">498,968</span></span>
<span class="ltx_td ltx_border_bb ltx_border_r ltx_border_t" id="S2.T3.11.11.11.11.11.11.11.20.8.9" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S2.T3.11.11.11.11.11.11.11.20.8.10" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S2.T3.11.11.11.11.11.11.11.20.8.10.1">604,940</span></span>
<span class="ltx_td ltx_border_bb ltx_border_t" id="S2.T3.11.11.11.11.11.11.11.20.8.11" style="padding-left:5.0pt;padding-right:5.0pt;"></span>
<span class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S2.T3.11.11.11.11.11.11.11.20.8.12" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S2.T3.11.11.11.11.11.11.11.20.8.12.1">974,896</span></span>
<span class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S2.T3.11.11.11.11.11.11.11.20.8.13" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text" id="S2.T3.11.11.11.11.11.11.11.20.8.13.1">1,339,622</span></span></span>
</span>
</span></span></span>
</span></span></span></p>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>BLEU scores of Task-level MoE models trained with 64 experts, for direct pairs, in both directions, for models with Language Pair (LP) - or target language (TL) - based routing during training, lp_a, lp_b, lp_c and tl_a, tl_b mapping during inference, respectively. We compare to Bilingual and Pivot-level NMT models’ scores and highlight the model/setup under which best scores were obtained.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S2.SSx2">
<h3 class="ltx_title ltx_title_subsection">Conditional Computation, Sparsity and Mixture-of-Experts models</h3>
<div class="ltx_para" id="S2.SSx2.p1">
<p class="ltx_p" id="S2.SSx2.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Fedus et al. (<a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib18" title="">2022</a>)</cite> extensively review sparse Mixture-of-Experts (MoE) models in Deep Learning, starting from the foundational work of <cite class="ltx_cite ltx_citemacro_citet">Shazeer et al. (<a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib47" title="">2017</a>)</cite>, <cite class="ltx_cite ltx_citemacro_citet">Lepikhin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib35" title="">2020</a>)</cite> and
<cite class="ltx_cite ltx_citemacro_citet">Fedus et al. (<a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib19" title="">2021</a>)</cite>. Their work delves into the scaling characteristics, routing algorithms, and training improvements proposed for MoE models, as well as the latest applications of Sparse MoE models across various domains, such as Natural Language Processing (NLP) <cite class="ltx_cite ltx_citemacro_citep">(Zoph et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib62" title="">2022</a>; Chowdhery et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib14" title="">2022</a>; Lee-Thorp and Ainslie, <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib34" title="">2022</a>; Du et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib16" title="">2022</a>)</cite>, Computer Vision <cite class="ltx_cite ltx_citemacro_citep">(Riquelme et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib44" title="">2021</a>; Puigcerver et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib41" title="">2020</a>; Wu et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib54" title="">2022</a>; Hwang et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib27" title="">2022</a>)</cite>, Speech Recognition <cite class="ltx_cite ltx_citemacro_citep">(You et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib58" title="">2021</a>, <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib59" title="">2022</a>)</cite>, and Multimodal Learning <cite class="ltx_cite ltx_citemacro_citep">(Mustafa et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib38" title="">2022</a>)</cite>.
In NLP, numerous studies have explored the potential of Sparse MoE models for diverse applications. <cite class="ltx_cite ltx_citemacro_citet">Kudugunta et al. (<a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib32" title="">2021</a>)</cite> introduced the concept of task-level routing in MoE models, achieving improved translation scores compared to large multilingual models with the same inference cost and dense student models distilled from token- or position-level MoE models.
By using task-level MoE models in our experiments, we investigate and optimize their performance in direct pairs’ NMT.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experiments</h2>
<section class="ltx_subsection" id="S3.SSx1">
<h3 class="ltx_title ltx_title_subsection">Model</h3>
<div class="ltx_para" id="S3.SSx1.p1">
<p class="ltx_p" id="S3.SSx1.p1.1">We train sparse encoder-decoder Task - level MoE models,
with dim = 1024, hidden dim = 4096, 8 heads, 3 layers. Following <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">kudugunta-etal-2021-beyond-distillation</span></cite>,
we similarly replace the Transformer Feed Forward Network (FFN) with a set of identical FFN experts. We use a 32,000 token SentencePiece vocabulary <cite class="ltx_cite ltx_citemacro_citep">(Kudo and Richardson, <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib31" title="">2018</a>)</cite>, shared in both the encoder and decoder of the model. We experiment with the number of experts, selecting either 16 or 64 experts, which correspond to models with approximately 1 billion and 3.5 billion parameters, respectively.
We investigate the impact of different task id to expert mapping methods, setting the task id to be either the Target Language or the Language Pair for translation.
Following <cite class="ltx_cite ltx_citemacro_citet">Kudo and Richardson (<a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib31" title="">2018</a>); Kudugunta et al. (<a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib32" title="">2021</a>)</cite>, data sampling temperature is T=5 during training, and we train 8 models for 2 million steps.</p>
</div>
<div class="ltx_para" id="S3.SSx1.p2">
<p class="ltx_p" id="S3.SSx1.p2.1">The training process has a batch size of 256, a maximum sentence length of 128. By examining performance of these models under different configurations, we want to better understand the relationship between the number of experts, task id to experts’ mappings, and translation quality, ultimately informing the optimal design choices for Task-level MoE models in various scenarios.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SSx2">
<h3 class="ltx_title ltx_title_subsection">Languages and Training Datasets</h3>
<div class="ltx_para" id="S3.SSx2.p1">
<p class="ltx_p" id="S3.SSx2.p1.1">We train our models using in-house production-scale datasets, consisting of English-centric, and Direct pairs’ parallel sentences, covering 108 languages, including English. Our training data includes a total of 107 English-centric pairs, and 53 direct pairs, with data sizes for each language pair ranging from a few
thousand to a few billion sentences for each pair. The number of sentences in each parallel pair in the train set is provided in Table <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#Ax1.T4" title="Table 4 ‣ Appendix ‣ Direct Neural Machine Translation with Task-level Mixture of Experts models"><span class="ltx_text ltx_ref_tag">4</span></a> in the Appendix.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SSx3">
<h3 class="ltx_title ltx_title_subsection">Evaluation Sets and Task Mapping</h3>
<div class="ltx_para" id="S3.SSx3.p1">
<p class="ltx_p" id="S3.SSx3.p1.1">For evaluation, we use internal test sets from two distinct sources: the Web Domain and Wikipedia. These test sets vary in size, containing anywhere from 500 to 5,000 sentences for each language pair.
In both training and evaluation datasets, we follow a specific preprocessing convention, prepending the source sentence with &lt;4xx&gt; &lt;2yy&gt; tokens. These tokens serve as a cue for the model, helping it identify the source and target languages in context, and the model to better learn and adapt to various language pair combinations.</p>
</div>
<div class="ltx_para" id="S3.SSx3.p2">
<p class="ltx_p" id="S3.SSx3.p2.1">Our models use either the exact train set Language Pair (LP) or the target language (TL) of the pair as the task id for mapping translation pairs to different experts.
In the former case, we directly map the specific language pair (En–yy, xx–En or xx–yy) to a task id, and have a total of 214 tasks (107 x 2 English-centric pairs) when training with English-only datasets, or 267 tasks (+ 53 direct Language Pairs) when incorporating Direct LPs.
On the other hand, when using the target language as the task id, we have 108 tasks (107 languages and English) in all scenarios. There we leverage and try to benefit from the shared characteristics of translations into the same target language.
Since we evaluate our models on direct (non-English) data Language Pairs, it is often the case that the exact mapping of the pair to an expert was not defined during training. To address this issue, we experiment with several approaches for mapping language pair xx–yy to a task id at inference time - in each method mentioned below we name the component used as task id:</p>
<ul class="ltx_itemize" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1">Language Pair (LP) as task id.</p>
<ul class="ltx_itemize" id="S3.I1.i1.I1">
<li class="ltx_item" id="S3.I1.i1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S3.I1.i1.I1.i1.1.1.1">–</span></span>
<div class="ltx_para" id="S3.I1.i1.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i1.I1.i1.p1.1.1">lp_mapping_a (lp_a)</span>: exact LP</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S3.I1.i1.I1.i2.1.1.1">–</span></span>
<div class="ltx_para" id="S3.I1.i1.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i1.I1.i2.p1.1.1">lp_mapping_b (lp_b)</span>: En–yy LP</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S3.I1.i1.I1.i3.1.1.1">–</span></span>
<div class="ltx_para" id="S3.I1.i1.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i1.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i1.I1.i3.p1.1.1">lp_mapping_c (lp_c)</span>: xx–En LP</p>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1">Target language as task id</p>
<ul class="ltx_itemize" id="S3.I1.i2.I1">
<li class="ltx_item" id="S3.I1.i2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S3.I1.i2.I1.i1.1.1.1">–</span></span>
<div class="ltx_para" id="S3.I1.i2.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i2.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i2.I1.i1.p1.1.1">tl_mapping_a (tl_a)</span>: yy</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="S3.I1.i2.I1.i2.1.1.1">–</span></span>
<div class="ltx_para" id="S3.I1.i2.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i2.I1.i2.p1.1.1">tl_mapping_b (tl_b)</span>: xx</p>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results &amp; Discussion</h2>
<figure class="ltx_figure" id="S4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="376" id="S4.F2.g1" src="extracted/5605726/figures/bleu/bleu_diff_16_64.png" width="635"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Difference between BLEU scores of Task-level MoE models trained with 16 and 64 experts, for direct pairs, for models with Language Pair (LP) - based routing during training, lp_a, lp_b, lp_c mapping during inference, respectively, and models with Target Language (TL) - based routing during training, tl_a, tl_b mapping during inference. For each pair, we mark the BLEU score value of the model which shows the largest difference among the 16 and 64 experts Task-level MoE variation.</figcaption>
</figure>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this study, we have two primary baselines for comparison: bilingual NMT models and pivot-based NMT models, which are trained using a bridging strategy through English. We use BLEU <cite class="ltx_cite ltx_citemacro_citep">(Papineni et al., <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib39" title="">2002</a>)</cite> for evaluating the translation quality of all direct language pairs. We are aware that learned metrics like COMET <cite class="ltx_cite ltx_citemacro_cite">Rei et al. (<a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib42" title="">2022</a>)</cite> and BLEURT <cite class="ltx_cite ltx_citemacro_cite">Sellam et al. (<a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib46" title="">2020</a>)</cite> show higher correlation with human judgements for high resource, English centric language pairs <cite class="ltx_cite ltx_citemacro_cite">Freitag et al. (<a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib23" title="">2022</a>)</cite>. However, it is unknown how well learned metrics perform on low resource languages and thus we decide to stick with BLEU for the main part of the paper.
Tables <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#S2.T2" title="Table 2 ‣ Direct Neural Machine Translation ‣ 2 Related Work ‣ Direct Neural Machine Translation with Task-level Mixture of Experts models"><span class="ltx_text ltx_ref_tag">2</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#S2.T3" title="Table 3 ‣ Direct Neural Machine Translation ‣ 2 Related Work ‣ Direct Neural Machine Translation with Task-level Mixture of Experts models"><span class="ltx_text ltx_ref_tag">3</span></a> summarize results for Task-level MoE models with either 16 or 64 experts.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">In Table <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#S2.T1" title="Table 1 ‣ Direct Neural Machine Translation ‣ 2 Related Work ‣ Direct Neural Machine Translation with Task-level Mixture of Experts models"><span class="ltx_text ltx_ref_tag">1</span></a>, we show the specific configurations that led to the highest BLEU scores for Task-level MoE models - comparing those to the performance of bilingual and pivot-based models, we aim to emphasize the best BLEU scores for each language pair. This analysis allows us to identify the most effective models for each pair and gain insights into how different model configurations and expert counts contribute to translation performance, so we can better understand the advantages and limitations of Task-level MoE models with varying numbers of experts, as well as bilingual and pivot-based NMT models.
Our results ultimately help inform the choice of translation models and strategies to optimize performance for different language pairs</p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">Performance of NMT models varies significantly depending on the pair, and on the direction of translation - certain pairs show large discrepancies between translation directions.
We see that pivot-based models perform better than bilingual ones for the majority of pairs. Bilingual NMT and pivot-based NMT models demonstrate strong results in several instances, while Task-level MoE models show mixed performance across different Language Pairs.</p>
</div>
<section class="ltx_subsection" id="S4.SSx1">
<h3 class="ltx_title ltx_title_subsection">Which model performs best for each pair?</h3>
<div class="ltx_para" id="S4.SSx1.p1">
<p class="ltx_p" id="S4.SSx1.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#S2.T1" title="Table 1 ‣ Direct Neural Machine Translation ‣ 2 Related Work ‣ Direct Neural Machine Translation with Task-level Mixture of Experts models"><span class="ltx_text ltx_ref_tag">1</span></a> results reveal that for the majority of direct language pairs, the highest Task-level MoE BLEU scores are achieved using a model with 16 experts, with the tl_a and lp_b mapping-to-experts methods surpassing other approaches. It is particularly noteworthy that for pairs of languages belonging to closely related language families (Japanese, Chinese, Korean, Vietnamese, and Thai), the LP-mapping-based models seem to perform best. In contrast, TL-based models tend to outperform the rest of the other language pairs.
In this case, Task-level MoE models show superior performance in the forward translation direction across all pairs. Meanwhile, pivot-based models yield the best results in the backward translation direction for four out of five pairs in those related languages. This observation suggests that different mapping-to-experts strategies may be more effective for certain language pairs or translation directions, depending on the linguistic relationships and unique characteristics of the languages involved; a tailored approach in employing Task-level MoE models and mapping-to-experts methods is the key to optimizing translation performance for different language pairs and directions.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SSx2">
<h3 class="ltx_title ltx_title_subsection">Comparison of different task to expert mapping methods</h3>
<div class="ltx_para" id="S4.SSx2.p1">
<p class="ltx_p" id="S4.SSx2.p1.1">From Table <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#S2.T2" title="Table 2 ‣ Direct Neural Machine Translation ‣ 2 Related Work ‣ Direct Neural Machine Translation with Task-level Mixture of Experts models"><span class="ltx_text ltx_ref_tag">2</span></a>, pivot-based models, Task-level MoE (LP) models with lp_b task id mapping and Task-level MoE (TL) models with tl_a task id mapping (both trained with 16 experts) are primarily the best performing models among all pairs.</p>
</div>
<div class="ltx_para" id="S4.SSx2.p2">
<p class="ltx_p" id="S4.SSx2.p2.1">Task-level MoE models with LP task id to expert routing and lp_b mapping at inference time excel in translations to Japanese, from Thai, Vietnamese, Korean, and Chinese (+3.17, +6.2, +21.15, +14.95 BLEU points over the pivot-level NMT model, respectively, and +15.27, +16.97, +36.52, +31.77 BLEU gain against bilingual models) as well as Korean-Chinese (ko-zh) (+6.22 BLEU compared to pivot-based model, +28.64 BLEU over the bilingual baseline) and French-Arabic (fr–ar) (+0.15 and +5.35 BLEU over the pivot and bilingual NMT models, respectively). This indicates the lp_b mapping strategy is particularly effective for these language pairs; routing to the expert best at En–yy translation, where yy is each pair’s target language, instead of routing to the expert explicitly trained on the exact direct pair, xx–yy, likely captures better the linguistic nuances of the pair and leads to improved translation scores.</p>
</div>
<div class="ltx_para" id="S4.SSx2.p3">
<p class="ltx_p" id="S4.SSx2.p3.1">Task-level MoE models trained with the TL task-to-expert mapping approach and the tl_a task id mapping, which leverages target language pairs for routing during inference, achieve the highest scores for translations involving Kazakh (kk), such as Kazakh-Russian (kk–ru) in both directions (+13.62 and +13.68 BLEU gain against pivot-based model, +0.34 and +12.34 BLEU points over bilingual models). Success of tl_a mapping strategy suggests the model shows superior performance in those cases and when the pair is properly routed to the expert specialised in the pair’s target language.
</p>
</div>
<div class="ltx_para" id="S4.SSx2.p4">
<p class="ltx_p" id="S4.SSx2.p4.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#S2.T3" title="Table 3 ‣ Direct Neural Machine Translation ‣ 2 Related Work ‣ Direct Neural Machine Translation with Task-level Mixture of Experts models"><span class="ltx_text ltx_ref_tag">3</span></a> shows results from our evaluation of 64 experts’ Task-level MoE models. Interestingly, pivot-based methods stand out as top performing in the majority of pairs and directions. These pairs include Bulgarian–Macedonian (bg–mk), French–Arabic (fr–ar), and Japanese–Thai (ja–th), as well as Chinese-Korean (zh-ko) in both directions, and Japanese-Korean (ja–ko).
In all other pairs and directions, specifically when translating to Japanese from Vietnamese, Korean, and Chinese, Task-level MoE (LP) models with the lp_a mapping approach emerge as the best-performing models (+0.21, +3.81, +2.54 BLEU points against the pivot-based model, respectively, and +10, +19.18, +19.36 BLEU gain over the bilingual baseline).</p>
</div>
<div class="ltx_para" id="S4.SSx2.p5">
<p class="ltx_p" id="S4.SSx2.p5.1">For certain Language Pairs with smaller amounts of training data bilingual NMT models achieve reasonable performance even with limited data and often outperform others.
On the other hand, we see that pivot-based NMT models perform well when there is a substantial amount of training data (e.g., Belarusian–Macedonian, and Russian–Turkish in both directions, Arabic–French, Chinese–Korean, Japanese–{Thai, Vietnamese, Chinese}). This might be due to the fact that these models leverage English as an intermediate bridging language between source and target languages, which is helpful when there’s enough data to help in learning meaningful representations.
</p>
</div>
<section class="ltx_subsubsection" id="S4.SSx2.SSSx1">
<h4 class="ltx_title ltx_title_subsubsection">Comparison of models with different number of experts</h4>
<div class="ltx_para" id="S4.SSx2.SSSx1.p1">
<p class="ltx_p" id="S4.SSx2.SSSx1.p1.1">In Figure <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#S4.F2" title="Figure 2 ‣ 4 Results &amp; Discussion ‣ Direct Neural Machine Translation with Task-level Mixture of Experts models"><span class="ltx_text ltx_ref_tag">2</span></a>, we present the difference in BLEU scores on select direct language pairs for Task-level MoE models trained using Language Pair (LP) or Target Language (TL) based mapping, with 16 and 64 experts. We seek to visually emphasize differences in performance across models that utilize varying numbers of experts, in order to get insights into their relative effectiveness and understand how the choice of mapping strategy (LP or TL) and the number of experts (16 or 64) impacts translation performance. For the majority of pairs (Vietnamese–Japanese, and both directions of French–Arabic, Japanese–Thai, Chinese–Korean, Japanese–Korean, Japanese–Chinese), Task-level MoE models with 16 experts outperform those with 64. For those language pairs, with the exception of Japanese–Chinese, for which TL-based Task-level MoE with tl_a shows best performance, LP-based Task-level MoE with lp_b mapping show the largest gain when trained with fewer experts, corroborating our previous findings. For other pairs, such as Japanese–Thai, Japanese–Chinese, and Bengali–Macedonian, different model variations show a largest improvement when trained with either 16 or 64 experts. We also notice a significant, yet not maximum, BLEU score gain for a large number of pairs with the TL-based Task-level MoE model and the LP-based Task-level MoE model, when using tl_a and lp_a on the task-to-expert mapping during inference, respectively, between 16 and 64 experts’ models.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SSx3">
<h3 class="ltx_title ltx_title_subsection">Routing decisions analysis</h3>
<div class="ltx_para" id="S4.SSx3.p1">
<p class="ltx_p" id="S4.SSx3.p1.1">In Figures <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#S4.F3" title="Figure 3 ‣ Routing decisions analysis ‣ 4 Results &amp; Discussion ‣ Direct Neural Machine Translation with Task-level Mixture of Experts models"><span class="ltx_text ltx_ref_tag">3</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#S4.F4" title="Figure 4 ‣ Routing decisions analysis ‣ 4 Results &amp; Discussion ‣ Direct Neural Machine Translation with Task-level Mixture of Experts models"><span class="ltx_text ltx_ref_tag">4</span></a>,
<a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#S4.F5" title="Figure 5 ‣ Routing decisions analysis ‣ 4 Results &amp; Discussion ‣ Direct Neural Machine Translation with Task-level Mixture of Experts models"><span class="ltx_text ltx_ref_tag">5</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#S4.F6" title="Figure 6 ‣ Routing decisions analysis ‣ 4 Results &amp; Discussion ‣ Direct Neural Machine Translation with Task-level Mixture of Experts models"><span class="ltx_text ltx_ref_tag">6</span></a> we show the experts’ utilization for the last model’s encoder and decoder layers for different pairs, for our TL-based Task-level MoE model, with tl_a used as a task to expert mapping approach during training; The darker a cell is in each of the Figures, the more that expert is used by the specific language pair. We can observe that language pairs with the same target language get properly routed to the same expert, as expected. It’s interesting to see that there are no major differences between the encoder’s routing decisions across checkpoints, yet we notice changes in experts’ assignment in the decoder during and at the end of training; at first, pairs with the same target language are mapped to the same different experts, yet as the model converges, we see a significant overlap in the selected experts, for pairs with different target languages. We also see a great overlap in experts chosen in the encoder during and at the end of training - the majority of experts are the same throughout model training and certain experts are preferred over others. This preference differs from the experts chosen in the decoder, where we see almost no overlap. It is also worth noting that the number of common experts between the encoder and the decoder is minimal, both during training and upon model convergence.</p>
</div>
<div class="ltx_para" id="S4.SSx3.p2">
<p class="ltx_p" id="S4.SSx3.p2.1">In the Appendix, we additionally show experts’ utilization in the encoder and decoder of our 64 experts’ TL-based Task-level MoE model.</p>
</div>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="146" id="S4.F3.g1" src="extracted/5605726/figures/experts_plots/TaskMoE_16_C128_B256_all_4yy_2xx_dt_c/tl_mapping_a/ckpt-1m/enc_3_01010000_web1_1_.png" width="294"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Routing decisions of the last encoder layer of our Task-level MoE model with 16 experts, trained with pair target language to task id mapping, with tl_a used during inference, for 1M steps.</figcaption>
</figure>
<figure class="ltx_figure" id="S4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="146" id="S4.F4.g1" src="extracted/5605726/figures/experts_plots/TaskMoE_16_C128_B256_all_4yy_2xx_dt_c/tl_mapping_a/ckpt-1m/dec_3_01010000_web1_1_.png" width="294"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Routing decisions of the last decoder layer of our Task-level MoE model with 16 experts, trained with pair target language to task id mapping, with tl_a used during inference, for 1M steps.</figcaption>
</figure>
<figure class="ltx_figure" id="S4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="146" id="S4.F5.g1" src="extracted/5605726/figures/experts_plots/TaskMoE_16_C128_B256_all_4yy_2xx_dt_c/tl_mapping_a/ckpt-2m/enc_3_02000000_web1_1_.png" width="294"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Routing decisions of the last encoder layer of our Task-level MoE model with 16 experts, trained with pair target language to task id mapping, with tl_a used during inference, for 2M steps.</figcaption>
</figure>
<figure class="ltx_figure" id="S4.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="146" id="S4.F6.g1" src="extracted/5605726/figures/experts_plots/TaskMoE_16_C128_B256_all_4yy_2xx_dt_c/tl_mapping_a/ckpt-2m/dec_3_02000000_web1_1_.png" width="294"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Routing decisions of the last decoder layer of our Task-level MoE model with 16 experts, trained with pair target language to task id mapping, with tl_a used during inference, for 2M steps.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusions</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">We conducted a thorough analysis of the usage of Task-level Mixture of Expert models for Direct NMT.
Our experiments reveal the strengths and weaknesses of different approaches and shed light on which configurations work best for specific direct language pairs. Our comparisons help in identifying best-performing models and offer valuable insights into how varying numbers of experts, and different task-to-expert mapping methods, during training and inference, can influence direct pairs’ translation quality in Task-level MoE models.
Specifically, we noticed that Task-level MoE NMT models, along with pivot-based approaches, are frequently top performers for numerous direct language pairs. However, their performance varies between different pairs and translation directions. Besides observing NMT quality results, our analysis of expert’s usage throughout training also serves as an informative way to visualize and understand mapping of language pairs to model experts in the encoder and decoder throughout training. Future work can focus on enhancing this model for broader language coverage, including other low-resource languages, to further improve translation quality and efficiency.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Limitations</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">Training and evaluation of Task-level MoE models can be very challenging due to the models’ size and complexity. There is a large number of parameters that require tuning, such as the number and size of experts, the number and diversity of languages, and of English-centric and direct Language Pairs in training, the batch size, the vocabulary size and the maximum sentence length. At the same time, it is time and computationally expensive to evaluate on a large number of direct pairs, train separate Bilingual and Pivot-level models for all to use as baselines, and also perform the experts’ analysis and visualizations for those pairs. This automatically restricts the amount and breadth of results, and calls for further exploration of the model capabilities in the future.</p>
</div>
</section>
<section class="ltx_section" id="Sx2">
<h2 class="ltx_title ltx_title_section">Ethics Statement</h2>
<div class="ltx_para" id="Sx2.p1">
<p class="ltx_p" id="Sx2.p1.1">Working with large language models raises several ethical concerns in NLP research, particularly related to quality, bias and toxicity of the output result <cite class="ltx_cite ltx_citemacro_cite">Bender et al. (<a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib7" title="">2021</a>); Chowdhery et al. (<a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib14" title="">2022</a>); Blodgett et al. (<a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib9" title="">2020</a>); Brown et al. (<a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib10" title="">2020</a>)</cite>.
In the context of NMT, involvement of many stakeholders in the task, as well as the dangers arising from mistranslation of the original text need to be taken into consideration, since they can potentially affect the perception of the work and harm the interests of the different parts <cite class="ltx_cite ltx_citemacro_citep">(Taivalkoski-Shilov, <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib49" title="">2019</a>; Gambier and Van Doorslaer, <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib24" title="">2016</a>)</cite>. Undoubtedly, the benefits of responsibly developed and deployed NMT systems lie in making an author’s work more accessible, enabling the transfer of ideas to other audiences, and enhancing both the reader’s capabilities and the translator’s role and sense of contribution <cite class="ltx_cite ltx_citemacro_citep">(Besacier, <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#bib.bib8" title="">2014</a>)</cite>, which are directions any work in the area should aim to focus on.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aharoni et al. (2019)</span>
<span class="ltx_bibblock">
Roee Aharoni, Melvin Johnson, and Orhan Firat. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/N19-1388" title="">Massively multilingual neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>, pages 3874–3884, Minneapolis, Minnesota. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Al-Shedivat and Parikh (2019)</span>
<span class="ltx_bibblock">
Maruan Al-Shedivat and Ankur P Parikh. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/1904.02338.pdf" title="">Consistency by agreement in zero-shot neural machine translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:1904.02338</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arivazhagan et al. (2019)</span>
<span class="ltx_bibblock">
Naveen Arivazhagan, Ankur Bapna, Orhan Firat, Roee Aharoni, Melvin Johnson, and Wolfgang Macherey. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/1903.07091.pdf" title="">The missing ingredient in zero-shot neural machine translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">arXiv preprint arXiv:1903.07091</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bahdanau et al. (2014)</span>
<span class="ltx_bibblock">
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/1409.0473.pdf" title="">Neural machine translation by jointly learning to align and translate</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">arXiv preprint arXiv:1409.0473</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ballesteros and Sanderson (2003)</span>
<span class="ltx_bibblock">
Lisa Ballesteros and Mark Sanderson. 2003.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://dl.acm.org/doi/10.1145/956863.956891" title="">Addressing the lack of direct translation resources for cross-language retrieval</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the twelfth international conference on Information and knowledge management</em>, pages 147–152.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bapna et al. (2022)</span>
<span class="ltx_bibblock">
Ankur Bapna, Isaac Caswell, Julia Kreutzer, Orhan Firat, Daan van Esch, Aditya Siddhant, Mengmeng Niu, Pallavi Baljekar, Xavier Garcia, Wolfgang Macherey, et al. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/2205.03983.pdf" title="">Building machine translation systems for the next thousand languages</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:2205.03983</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bender et al. (2021)</span>
<span class="ltx_bibblock">
Emily M. Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3442188.3445922" title="">On the dangers of stochastic parrots: Can language models be too big?</a>
</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</em>, FAccT ’21, page 610–623, New York, NY, USA. Association for Computing Machinery.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Besacier (2014)</span>
<span class="ltx_bibblock">
Laurent Besacier. 2014.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/F14-2001" title="">Machine translation for litterature: a pilot study (traduction automatisée d’une oeuvre littéraire: une étude pilote) [in French]</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Proceedings of TALN 2014 (Volume 2: Short Papers)</em>, pages 389–394, Marseille, France. Association pour le Traitement Automatique des Langues.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blodgett et al. (2020)</span>
<span class="ltx_bibblock">
Su Lin Blodgett, Solon Barocas, Hal Daumé III, and Hanna Wallach. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.acl-main.485" title="">Language (technology) is power: A critical survey of “bias” in NLP</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, pages 5454–5476, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al. (2020)</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html" title="">Language models are few-shot learners</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Advances in neural information processing systems</em>, 33:1877–1901.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2017)</span>
<span class="ltx_bibblock">
Yun Chen, Yang Liu, Yong Cheng, and Victor OK Li. 2017.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/1705.00753.pdf" title="">A teacher-student framework for zero-resource neural machine translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:1705.00753</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2018)</span>
<span class="ltx_bibblock">
Yun Chen, Yang Liu, and Victor Li. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://ojs.aaai.org/index.php/AAAI/article/view/11976" title="">Zero-resource neural machine translation with multi-agent communication game</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the aaai conference on artificial intelligence</em>, volume 32.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng and Cheng (2019)</span>
<span class="ltx_bibblock">
Yong Cheng and Yong Cheng. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://www.ijcai.org/proceedings/2017/0555.pdf" title="">Joint training for pivot-based neural machine translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Joint training for neural machine translation</em>, pages 41–54.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chowdhery et al. (2022)</span>
<span class="ltx_bibblock">
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2204.02311" title="">Palm: Scaling language modeling with pathways</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2204.02311</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Currey and Heafield (2019)</span>
<span class="ltx_bibblock">
Anna Currey and Kenneth Heafield. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/D19-5610.pdf" title="">Zero-resource neural machine translation with monolingual pivot data</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Proceedings of the 3rd Workshop on Neural Generation and Translation</em>, pages 99–107.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du et al. (2022)</span>
<span class="ltx_bibblock">
Nan Du, Yanping Huang, Andrew M Dai, Simon Tong, Dmitry Lepikhin, Yuanzhong Xu, Maxim Krikun, Yanqi Zhou, Adams Wei Yu, Orhan Firat, et al. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.mlr.press/v162/du22c.html" title="">Glam: Efficient scaling of language models with mixture-of-experts</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">International Conference on Machine Learning</em>, pages 5547–5569. PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">ElNokrashy et al. (2022)</span>
<span class="ltx_bibblock">
Muhammad ElNokrashy, Amr Hendy, Mohamed Maher, Mohamed Afify, and Hany Hassan Awadalla. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/2208.05852.pdf" title="">Language tokens: A frustratingly simple approach improves zero-shot performance of multilingual translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">arXiv preprint arXiv:2208.05852</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fedus et al. (2022)</span>
<span class="ltx_bibblock">
William Fedus, Jeff Dean, and Barret Zoph. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/2209.01667.pdf" title="">A review of sparse expert models in deep learning</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">arXiv preprint arXiv:2209.01667</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fedus et al. (2021)</span>
<span class="ltx_bibblock">
William Fedus, Barret Zoph, and Noam Shazeer. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://www.jmlr.org/papers/volume23/21-0998/21-0998.pdf" title="">Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">J. Mach. Learn. Res</em>, 23:1–40.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Firat et al. (2016a)</span>
<span class="ltx_bibblock">
Orhan Firat, Kyunghyun Cho, and Yoshua Bengio. 2016a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/1601.01073.pdf" title="">Multi-way, multilingual neural machine translation with a shared attention mechanism</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">arXiv preprint arXiv:1601.01073</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Firat et al. (2016b)</span>
<span class="ltx_bibblock">
Orhan Firat, Baskaran Sankaran, Yaser Al-Onaizan, Fatos T Yarman Vural, and Kyunghyun Cho. 2016b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/1606.04164.pdf" title="">Zero-resource translation with multi-lingual neural machine translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:1606.04164</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Freitag and Firat (2020)</span>
<span class="ltx_bibblock">
Markus Freitag and Orhan Firat. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/2010.10239.pdf" title="">Complete multilingual neural machine translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">arXiv preprint arXiv:2010.10239</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Freitag et al. (2022)</span>
<span class="ltx_bibblock">
Markus Freitag, Ricardo Rei, Nitika Mathur, Chi-kiu Lo, Craig Stewart, Eleftherios Avramidis, Tom Kocmi, George Foster, Alon Lavie, and André F. T. Martins. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.wmt-1.2" title="">Results of WMT22 metrics shared task: Stop using BLEU – neural metrics are better and more robust</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Proceedings of the Seventh Conference on Machine Translation (WMT)</em>, pages 46–68, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gambier and Van Doorslaer (2016)</span>
<span class="ltx_bibblock">
Yves Gambier and Luc Van Doorslaer. 2016.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Border crossings: Translation studies and other disciplines</em>, volume 126.

</span>
<span class="ltx_bibblock">John Benjamins Publishing Company.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu et al. (2019)</span>
<span class="ltx_bibblock">
Jiatao Gu, Yong Wang, Kyunghyun Cho, and Victor OK Li. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/1906.01181.pdf" title="">Improved zero-shot neural machine translation via ignoring spurious correlations</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">arXiv preprint arXiv:1906.01181</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hassan et al. (2018)</span>
<span class="ltx_bibblock">
Hany Hassan, Anthony Aue, Chang Chen, Vishal Chowdhary, Jonathan Clark, Christian Federmann, Xuedong Huang, Marcin Junczys-Dowmunt, William Lewis, Mu Li, et al. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/1803.05567.pdf" title="">Achieving human parity on automatic chinese to english news translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">arXiv preprint arXiv:1803.05567</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hwang et al. (2022)</span>
<span class="ltx_bibblock">
Changho Hwang, Wei Cui, Yifan Xiong, Ziyue Yang, Ze Liu, Han Hu, Zilong Wang, Rafael Salas, Jithin Jose, Prabhat Ram, et al. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/2206.03382.pdf" title="">Tutel: Adaptive mixture-of-experts at scale</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">arXiv preprint arXiv:2206.03382</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ji et al. (2020)</span>
<span class="ltx_bibblock">
Baijun Ji, Zhirui Zhang, Xiangyu Duan, Min Zhang, Boxing Chen, and Weihua Luo. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://ojs.aaai.org/index.php/AAAI/article/download/5341/5197" title="">Cross-lingual pre-training based transfer for zero-shot neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Proceedings of the AAAI conference on artificial intelligence</em>, volume 34, pages 115–122.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Johnson et al. (2017)</span>
<span class="ltx_bibblock">
Melvin Johnson, Mike Schuster, Quoc V Le, Maxim Krikun, Yonghui Wu, Zhifeng Chen, Nikhil Thorat, Fernanda Viégas, Martin Wattenberg, Greg Corrado, et al. 2017.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/Q17-1024.pdf" title="">Google’s multilingual neural machine translation system: Enabling zero-shot translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Transactions of the Association for Computational Linguistics</em>, 5:339–351.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al. (2019)</span>
<span class="ltx_bibblock">
Yunsu Kim, Petre Petrov, Pavel Petrushkov, Shahram Khadivi, and Hermann Ney. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/1909.09524.pdf" title="">Pivot-based transfer learning for neural machine translation between non-english languages</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">arXiv preprint arXiv:1909.09524</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kudo and Richardson (2018)</span>
<span class="ltx_bibblock">
Taku Kudo and John Richardson. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/1808.06226.pdf" title="">Sentencepiece: A simple and language independent subword tokenizer and detokenizer for neural text processing</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">arXiv preprint arXiv:1808.06226</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kudugunta et al. (2021)</span>
<span class="ltx_bibblock">
Sneha Kudugunta, Yanping Huang, Ankur Bapna, Maxim Krikun, Dmitry Lepikhin, Minh-Thang Luong, and Orhan Firat. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/2110.03742.pdf" title="">Beyond distillation: Task-level mixture-of-experts for efficient inference</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">arXiv preprint arXiv:2110.03742</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lakew et al. (2021)</span>
<span class="ltx_bibblock">
Surafel M Lakew, Matteo Negri, and Marco Turchi. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2021.mtsummit-loresmt.10.pdf" title="">Zero-shot neural machine translation with self-learning cycle</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Proceedings of the 4th Workshop on Technologies for MT of Low Resource Languages (LoResMT2021)</em>, pages 96–113.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee-Thorp and Ainslie (2022)</span>
<span class="ltx_bibblock">
James Lee-Thorp and Joshua Ainslie. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.findings-emnlp.5.pdf" title="">Sparse mixers: Combining moe and mixing to build a more efficient bert</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">arXiv preprint arXiv:2205.12399</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lepikhin et al. (2020)</span>
<span class="ltx_bibblock">
Dmitry Lepikhin, HyoukJoong Lee, Yuanzhong Xu, Dehao Chen, Orhan Firat, Yanping Huang, Maxim Krikun, Noam Shazeer, and Zhifeng Chen. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/2006.16668.pdf" title="">Gshard: Scaling giant models with conditional computation and automatic sharding</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">arXiv preprint arXiv:2006.16668</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2020)</span>
<span class="ltx_bibblock">
Danni Liu, Jan Niehues, James Cross, Francisco Guzmán, and Xian Li. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2021.acl-long.101.pdf" title="">Improving zero-shot translation by disentangling positional information</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">arXiv preprint arXiv:2012.15127</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al. (2018)</span>
<span class="ltx_bibblock">
Yichao Lu, Phillip Keung, Faisal Ladhak, Vikas Bhardwaj, Shaonan Zhang, and Jason Sun. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/1804.08198.pdf" title="">A neural interlingua for multilingual machine translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">arXiv preprint arXiv:1804.08198</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mustafa et al. (2022)</span>
<span class="ltx_bibblock">
Basil Mustafa, Carlos Riquelme, Joan Puigcerver, Rodolphe Jenatton, and Neil Houlsby. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/ARXIV.2206.02770" title="">Multimodal contrastive learning with limoe: the language-image mixture of experts</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papineni et al. (2002)</span>
<span class="ltx_bibblock">
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.3115/1073083.1073135" title="">Bleu: a method for automatic evaluation of machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</em>, pages 311–318, Philadelphia, Pennsylvania, USA. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Philip et al. (2020)</span>
<span class="ltx_bibblock">
Jerin Philip, Alexandre Berard, Matthias Gallé, and Laurent Besacier. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.emnlp-main.361" title="">Monolingual adapters for zero-shot neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, pages 4465–4470, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Puigcerver et al. (2020)</span>
<span class="ltx_bibblock">
Joan Puigcerver, Carlos Riquelme, Basil Mustafa, Cédric Renggli, André Susano Pinto, Sylvain Gelly, Daniel Keysers, and Neil Houlsby. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2009.13239" title="">Scalable transfer learning with expert models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">CoRR</em>, abs/2009.13239.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rei et al. (2022)</span>
<span class="ltx_bibblock">
Ricardo Rei, José G. C. de Souza, Duarte Alves, Chrysoula Zerva, Ana C Farinha, Taisiya Glushkova, Alon Lavie, Luisa Coheur, and André F. T. Martins. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.wmt-1.52" title="">COMET-22: Unbabel-IST 2022 submission for the metrics shared task</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">Proceedings of the Seventh Conference on Machine Translation (WMT)</em>, pages 578–585, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rios et al. (2020)</span>
<span class="ltx_bibblock">
Annette Rios, Mathias Müller, and Rico Sennrich. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/2011.01703.pdf" title="">Subword segmentation and a single bridge language affect zero-shot neural machine translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">arXiv preprint arXiv:2011.01703</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Riquelme et al. (2021)</span>
<span class="ltx_bibblock">
Carlos Riquelme, Joan Puigcerver, Basil Mustafa, Maxim Neumann, Rodolphe Jenatton, André Susano Pinto, Daniel Keysers, and Neil Houlsby. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper/2021/file/48237d9f2dea8c74c2a72126cf63d933-Paper.pdf" title="">Scaling vision with sparse mixture of experts</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">Advances in Neural Information Processing Systems</em>, 34:8583–8595.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ryabinin and Gusev (2020)</span>
<span class="ltx_bibblock">
Max Ryabinin and Anton Gusev. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2002.04013" title="">Towards crowdsourced training of large neural networks using decentralized mixture-of-experts</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sellam et al. (2020)</span>
<span class="ltx_bibblock">
Thibault Sellam, Dipanjan Das, and Ankur Parikh. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.acl-main.704" title="">BLEURT: Learning robust metrics for text generation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, pages 7881–7892, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shazeer et al. (2017)</span>
<span class="ltx_bibblock">
Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, and Jeff Dean. 2017.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/1701.06538.pdf" title="">Outrageously large neural networks: The sparsely-gated mixture-of-experts layer</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">arXiv preprint arXiv:1701.06538</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sutskever et al. (2014)</span>
<span class="ltx_bibblock">
Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper/2014/file/a14ac55a4f27472c5d894ec1c3c743d2-Paper.pdf" title="">Sequence to sequence learning with neural networks</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">Advances in neural information processing systems</em>, 27.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taivalkoski-Shilov (2019)</span>
<span class="ltx_bibblock">
Kristiina Taivalkoski-Shilov. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://www.tandfonline.com/doi/pdf/10.1080/0907676X.2018.1520907?needAccess=true&amp;role=button" title="">Ethical issues regarding machine (-assisted) translation of literary texts</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">Perspectives</em>, 27(5):689–703.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et al. (2021)</span>
<span class="ltx_bibblock">
Yuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu, and Angela Fan. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.findings-acl.304" title="">Multilingual translation from denoising pre-training</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</em>, pages 3450–3466, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tiedemann (2018)</span>
<span class="ltx_bibblock">
Jörg Tiedemann. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/1802.00273.pdf" title="">Emerging language spaces learned from massively multilingual corpora</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">arXiv preprint arXiv:1802.00273</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al. (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/1706.03762.pdf" title="">Attention is all you need</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">Advances in neural information processing systems</em>, 30.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2021)</span>
<span class="ltx_bibblock">
Weizhi Wang, Zhirui Zhang, Yichao Du, Boxing Chen, Jun Xie, and Weihua Luo. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.findings-emnlp.366" title="">Rethinking zero-shot neural machine translation: From a perspective of latent variables</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">Findings of the Association for Computational Linguistics: EMNLP 2021</em>, pages 4321–4327, Punta Cana, Dominican Republic. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2022)</span>
<span class="ltx_bibblock">
Lemeng Wu, Mengchen Liu, Yinpeng Chen, Dongdong Chen, Xiyang Dai, and Lu Yuan. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/2204.09636.pdf" title="">Residual mixture of experts</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">arXiv preprint arXiv:2204.09636</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2022)</span>
<span class="ltx_bibblock">
Yulin Xu, Zhen Yang, Fandong Meng, et al. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/2203.02180.pdf" title="">Eag: Extract and generate multi-way aligned corpus for complete multi-lingual neural machine translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">arXiv preprint arXiv:2203.02180</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2022)</span>
<span class="ltx_bibblock">
Jian Yang, Yuwei Yin, Shuming Ma, Dongdong Zhang, Shuangzhi Wu, Hongcheng Guo, Zhoujun Li, and Furu Wei. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.24963/ijcai.2022/618" title="">UM4: Unified multilingual multiple teacher-student model for zero-resource neural machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence</em>. International Joint Conferences on Artificial Intelligence Organization.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2021)</span>
<span class="ltx_bibblock">
Yilin Yang, Akiko Eriguchi, Alexandre Muzio, Prasad Tadepalli, Stefan Lee, and Hany Hassan. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.emnlp-main.578" title="">Improving multilingual translation by representation and gradient regularization</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</em>, pages 7266–7279, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">You et al. (2021)</span>
<span class="ltx_bibblock">
Zhao You, Shulin Feng, Dan Su, and Dong Yu. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2105.03036" title="">Speechmoe: Scaling to large acoustic models with dynamic routing mixture of experts</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">CoRR</em>, abs/2105.03036.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">You et al. (2022)</span>
<span class="ltx_bibblock">
Zhao You, Shulin Feng, Dan Su, and Dong Yu. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9747065" title="">Speechmoe2: Mixture-of-experts model with improved routing</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pages 7217–7221. IEEE.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2020)</span>
<span class="ltx_bibblock">
Biao Zhang, Philip Williams, Ivan Titov, and Rico Sennrich. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/pdf/2004.11867.pdf" title="">Improving massively multilingual neural machine translation and zero-shot translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">arXiv preprint arXiv:2004.11867</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al. (2017)</span>
<span class="ltx_bibblock">
Hao Zheng, Yong Cheng, and Yang Liu. 2017.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://www.ijcai.org/proceedings/2017/0594.pdf" title="">Maximum expected likelihood estimation for zero-resource neural machine translation.</a>
</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib61.1.1">IJCAI</em>, pages 4251–4257.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zoph et al. (2022)</span>
<span class="ltx_bibblock">
Barret Zoph, Irwan Bello, Sameer Kumar, Nan Du, Yanping Huang, Jeff Dean, Noam Shazeer, and William Fedus. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2202.08906" title="">St-moe: Designing stable and transferable sparse expert models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib62.1.1">arXiv preprint arXiv:2202.08906</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zoph and Knight (2016)</span>
<span class="ltx_bibblock">
Barret Zoph and Kevin Knight. 2016.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/N16-1004" title="">Multi-source neural translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pages 30–34, San Diego, California. Association for Computational Linguistics.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="Ax1">
<h2 class="ltx_title ltx_title_appendix">Appendix</h2>
<div class="ltx_para" id="Ax1.p1">
<p class="ltx_p" id="Ax1.p1.1">In Figures <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#Ax1.F7" title="Figure 7 ‣ Appendix ‣ Direct Neural Machine Translation with Task-level Mixture of Experts models"><span class="ltx_text ltx_ref_tag">7</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2310.12236v2#Ax1.F8" title="Figure 8 ‣ Appendix ‣ Direct Neural Machine Translation with Task-level Mixture of Experts models"><span class="ltx_text ltx_ref_tag">8</span></a> we see the routing decisions maps for the last encoder and decoder layer of TL- based task-level MoE models trained with 64 experts and tl_a mapping during inference. The distribution to the experts is similarly expected here, following the training and inference pairs-to-experts’ mapping, as same target language pairs get routed to the same experts. The overlap in the encoder and decoder experts is minimal. All but one selected experts are different between the encoder and decoder.</p>
</div>
<figure class="ltx_figure" id="Ax1.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="175" id="Ax1.F7.g1" src="extracted/5605726/figures/experts_plots/TaskMoE_64_C128_B256_all_4yy_2xx_dt_c/tl_mapping_a/ckpt-2m/enc_3_01010000_web1_1_.png" width="353"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Routing decisions of the last encoder layer of our Task-level MoE model with 64 experts, trained with pair target language to task id mapping, with tl_a used during inference, for 2M steps.</figcaption>
</figure>
<figure class="ltx_figure" id="Ax1.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="175" id="Ax1.F8.g1" src="extracted/5605726/figures/experts_plots/TaskMoE_64_C128_B256_all_4yy_2xx_dt_c/tl_mapping_a/ckpt-2m/dec_3_01010000_web1_1_.png" width="353"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Routing decisions of the last decoder layer of our Task-level MoE model with 64 experts, trained with pair target language to task id mapping, with tl_a used during inference, for 2M steps.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<figure class="ltx_table" id="Ax1.tab1">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="Ax1.tab1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="Ax1.tab1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="Ax1.tab1.1.1.1.1" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="Ax1.tab1.1.1.1.1.1">LP</span></th>
<th class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="Ax1.tab1.1.1.1.2" style="padding-left:5.0pt;padding-right:5.0pt;">
<span class="ltx_text ltx_font_bold" id="Ax1.tab1.1.1.1.2.1">Num. of sentences</span>   |</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="Ax1.tab1.1.1.1.3" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="Ax1.tab1.1.1.1.3.1">LP</span></th>
<th class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="Ax1.tab1.1.1.1.4" style="padding-left:5.0pt;padding-right:5.0pt;">
<span class="ltx_text ltx_font_bold" id="Ax1.tab1.1.1.1.4.1">Num. of sentences</span>   |</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="Ax1.tab1.1.1.1.5" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="Ax1.tab1.1.1.1.5.1">LP</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="Ax1.tab1.1.1.1.6" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="Ax1.tab1.1.1.1.6.1">Num. of sentences</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="Ax1.tab1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="Ax1.tab1.1.2.1.1" style="padding-left:5.0pt;padding-right:5.0pt;">ar–fr</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="Ax1.tab1.1.2.1.2" style="padding-left:5.0pt;padding-right:5.0pt;">0</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="Ax1.tab1.1.2.1.3" style="padding-left:5.0pt;padding-right:5.0pt;">fr–ar</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="Ax1.tab1.1.2.1.4" style="padding-left:5.0pt;padding-right:5.0pt;">0</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="Ax1.tab1.1.2.1.5" style="padding-left:5.0pt;padding-right:5.0pt;">be–ru</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="Ax1.tab1.1.2.1.6" style="padding-left:5.0pt;padding-right:5.0pt;">3,641</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.3.2.1" style="padding-left:5.0pt;padding-right:5.0pt;">ru–be</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.3.2.2" style="padding-left:5.0pt;padding-right:5.0pt;">3,641</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.3.2.3" style="padding-left:5.0pt;padding-right:5.0pt;">ja–th</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.3.2.4" style="padding-left:5.0pt;padding-right:5.0pt;">6,200</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.3.2.5" style="padding-left:5.0pt;padding-right:5.0pt;">th–ja</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.3.2.6" style="padding-left:5.0pt;padding-right:5.0pt;">6,200</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.4.3.1" style="padding-left:5.0pt;padding-right:5.0pt;">ko–th</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.4.3.2" style="padding-left:5.0pt;padding-right:5.0pt;">6,208</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.4.3.3" style="padding-left:5.0pt;padding-right:5.0pt;">th–zh</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.4.3.4" style="padding-left:5.0pt;padding-right:5.0pt;">12,305</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.4.3.5" style="padding-left:5.0pt;padding-right:5.0pt;">zh–th</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.4.3.6" style="padding-left:5.0pt;padding-right:5.0pt;">12,305</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.5.4.1" style="padding-left:5.0pt;padding-right:5.0pt;">id–ms</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.5.4.2" style="padding-left:5.0pt;padding-right:5.0pt;">24,535</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.5.4.3" style="padding-left:5.0pt;padding-right:5.0pt;">kk–tr</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.5.4.4" style="padding-left:5.0pt;padding-right:5.0pt;">69,476</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.5.4.5" style="padding-left:5.0pt;padding-right:5.0pt;">tr–kk</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.5.4.6" style="padding-left:5.0pt;padding-right:5.0pt;">69,476</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.6.5.1" style="padding-left:5.0pt;padding-right:5.0pt;">ug–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.6.5.2" style="padding-left:5.0pt;padding-right:5.0pt;">129,688</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.6.5.3" style="padding-left:5.0pt;padding-right:5.0pt;">tk–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.6.5.4" style="padding-left:5.0pt;padding-right:5.0pt;">140,247</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.6.5.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–tk</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.6.5.6" style="padding-left:5.0pt;padding-right:5.0pt;">144,094</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.7.6.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–ug</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.7.6.2" style="padding-left:5.0pt;padding-right:5.0pt;">167,741</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.7.6.3" style="padding-left:5.0pt;padding-right:5.0pt;">kk–ru</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.7.6.4" style="padding-left:5.0pt;padding-right:5.0pt;">177,931</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.7.6.5" style="padding-left:5.0pt;padding-right:5.0pt;">ru–kk</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.7.6.6" style="padding-left:5.0pt;padding-right:5.0pt;">177,931</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.8.7.1" style="padding-left:5.0pt;padding-right:5.0pt;">bg–mk</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.8.7.2" style="padding-left:5.0pt;padding-right:5.0pt;">205,651</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.8.7.3" style="padding-left:5.0pt;padding-right:5.0pt;">mk–bg</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.8.7.4" style="padding-left:5.0pt;padding-right:5.0pt;">205,651</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.8.7.5" style="padding-left:5.0pt;padding-right:5.0pt;">or–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.8.7.6" style="padding-left:5.0pt;padding-right:5.0pt;">262,099</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.9.8.1" style="padding-left:5.0pt;padding-right:5.0pt;">cs–es</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.9.8.2" style="padding-left:5.0pt;padding-right:5.0pt;">285,546</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.9.8.3" style="padding-left:5.0pt;padding-right:5.0pt;">es–cs</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.9.8.4" style="padding-left:5.0pt;padding-right:5.0pt;">285,546</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.9.8.5" style="padding-left:5.0pt;padding-right:5.0pt;">ko–vi</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.9.8.6" style="padding-left:5.0pt;padding-right:5.0pt;">369,594</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.10.9.1" style="padding-left:5.0pt;padding-right:5.0pt;">vi–ko</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.10.9.2" style="padding-left:5.0pt;padding-right:5.0pt;">369,594</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.10.9.3" style="padding-left:5.0pt;padding-right:5.0pt;">et–fi</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.10.9.4" style="padding-left:5.0pt;padding-right:5.0pt;">466,254</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.10.9.5" style="padding-left:5.0pt;padding-right:5.0pt;">fi–et</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.10.9.6" style="padding-left:5.0pt;padding-right:5.0pt;">466,254</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.11.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.11.10.1" style="padding-left:5.0pt;padding-right:5.0pt;">ko–zh</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.11.10.2" style="padding-left:5.0pt;padding-right:5.0pt;">498,968</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.11.10.3" style="padding-left:5.0pt;padding-right:5.0pt;">zh–ko</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.11.10.4" style="padding-left:5.0pt;padding-right:5.0pt;">498,968</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.11.10.5" style="padding-left:5.0pt;padding-right:5.0pt;">vi–zh</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.11.10.6" style="padding-left:5.0pt;padding-right:5.0pt;">504,037</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.12.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.12.11.1" style="padding-left:5.0pt;padding-right:5.0pt;">zh–vi</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.12.11.2" style="padding-left:5.0pt;padding-right:5.0pt;">504,037</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.12.11.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–tt</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.12.11.4" style="padding-left:5.0pt;padding-right:5.0pt;">556,751</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.12.11.5" style="padding-left:5.0pt;padding-right:5.0pt;">de–ru</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.12.11.6" style="padding-left:5.0pt;padding-right:5.0pt;">585,161</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.13.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.13.12.1" style="padding-left:5.0pt;padding-right:5.0pt;">ru–de</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.13.12.2" style="padding-left:5.0pt;padding-right:5.0pt;">585,161</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.13.12.3" style="padding-left:5.0pt;padding-right:5.0pt;">ja–vi</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.13.12.4" style="padding-left:5.0pt;padding-right:5.0pt;">604,940</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.13.12.5" style="padding-left:5.0pt;padding-right:5.0pt;">vi–ja</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.13.12.6" style="padding-left:5.0pt;padding-right:5.0pt;">604,940</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.14.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.14.13.1" style="padding-left:5.0pt;padding-right:5.0pt;">zh–tr</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.14.13.2" style="padding-left:5.0pt;padding-right:5.0pt;">609,066</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.14.13.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–or</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.14.13.4" style="padding-left:5.0pt;padding-right:5.0pt;">658,015</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.14.13.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–rw</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.14.13.6" style="padding-left:5.0pt;padding-right:5.0pt;">792,559</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.15.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.15.14.1" style="padding-left:5.0pt;padding-right:5.0pt;">tt–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.15.14.2" style="padding-left:5.0pt;padding-right:5.0pt;">819,579</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.15.14.3" style="padding-left:5.0pt;padding-right:5.0pt;">cs–fr</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.15.14.4" style="padding-left:5.0pt;padding-right:5.0pt;">895,912</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.15.14.5" style="padding-left:5.0pt;padding-right:5.0pt;">fr–cs</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.15.14.6" style="padding-left:5.0pt;padding-right:5.0pt;">895,912</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.16.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.16.15.1" style="padding-left:5.0pt;padding-right:5.0pt;">ja–ko</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.16.15.2" style="padding-left:5.0pt;padding-right:5.0pt;">974,896</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.16.15.3" style="padding-left:5.0pt;padding-right:5.0pt;">ko–ja</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.16.15.4" style="padding-left:5.0pt;padding-right:5.0pt;">974,896</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.16.15.5" style="padding-left:5.0pt;padding-right:5.0pt;">cs–de</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.16.15.6" style="padding-left:5.0pt;padding-right:5.0pt;">1,007,448</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.17.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.17.16.1" style="padding-left:5.0pt;padding-right:5.0pt;">de–cs</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.17.16.2" style="padding-left:5.0pt;padding-right:5.0pt;">1,007,448</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.17.16.3" style="padding-left:5.0pt;padding-right:5.0pt;">rw–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.17.16.4" style="padding-left:5.0pt;padding-right:5.0pt;">1,264,813</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.17.16.5" style="padding-left:5.0pt;padding-right:5.0pt;">ja–zh</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.17.16.6" style="padding-left:5.0pt;padding-right:5.0pt;">1,339,622</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.18.17">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.18.17.1" style="padding-left:5.0pt;padding-right:5.0pt;">zh–ja</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.18.17.2" style="padding-left:5.0pt;padding-right:5.0pt;">1,339,622</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.18.17.3" style="padding-left:5.0pt;padding-right:5.0pt;">ru–tr</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.18.17.4" style="padding-left:5.0pt;padding-right:5.0pt;">1,467,160</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.18.17.5" style="padding-left:5.0pt;padding-right:5.0pt;">tr–ru</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.18.17.6" style="padding-left:5.0pt;padding-right:5.0pt;">1,467,160</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.19.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.19.18.1" style="padding-left:5.0pt;padding-right:5.0pt;">cs–ru</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.19.18.2" style="padding-left:5.0pt;padding-right:5.0pt;">1,644,795</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.19.18.3" style="padding-left:5.0pt;padding-right:5.0pt;">ru–cs</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.19.18.4" style="padding-left:5.0pt;padding-right:5.0pt;">1,644,795</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.19.18.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–la</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.19.18.6" style="padding-left:5.0pt;padding-right:5.0pt;">1,809,003</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.20.19">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.20.19.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–xh</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.20.19.2" style="padding-left:5.0pt;padding-right:5.0pt;">1,895,974</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.20.19.3" style="padding-left:5.0pt;padding-right:5.0pt;">la–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.20.19.4" style="padding-left:5.0pt;padding-right:5.0pt;">2,167,039</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.20.19.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–sm</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.20.19.6" style="padding-left:5.0pt;padding-right:5.0pt;">2,353,608</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.21.20">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.21.20.1" style="padding-left:5.0pt;padding-right:5.0pt;">de–es</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.21.20.2" style="padding-left:5.0pt;padding-right:5.0pt;">2,886,854</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.21.20.3" style="padding-left:5.0pt;padding-right:5.0pt;">de–fr</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.21.20.4" style="padding-left:5.0pt;padding-right:5.0pt;">2,886,854</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.21.20.5" style="padding-left:5.0pt;padding-right:5.0pt;">es–de</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.21.20.6" style="padding-left:5.0pt;padding-right:5.0pt;">2,886,854</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.22.21">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.22.21.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–st</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.22.21.2" style="padding-left:5.0pt;padding-right:5.0pt;">2,931,225</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.22.21.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–sn</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.22.21.4" style="padding-left:5.0pt;padding-right:5.0pt;">3,022,722</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.22.21.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–ig</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.22.21.6" style="padding-left:5.0pt;padding-right:5.0pt;">3,058,540</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.23.22">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.23.22.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–haw</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.23.22.2" style="padding-left:5.0pt;padding-right:5.0pt;">3,393,044</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.23.22.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–yo</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.23.22.4" style="padding-left:5.0pt;padding-right:5.0pt;">3,404,254</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.23.22.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–lo</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.23.22.6" style="padding-left:5.0pt;padding-right:5.0pt;">3,573,485</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.24.23">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.24.23.1" style="padding-left:5.0pt;padding-right:5.0pt;">fr–de</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.24.23.2" style="padding-left:5.0pt;padding-right:5.0pt;">3,681,694</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.24.23.3" style="padding-left:5.0pt;padding-right:5.0pt;">ru–uk</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.24.23.4" style="padding-left:5.0pt;padding-right:5.0pt;">3,792,978</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.24.23.5" style="padding-left:5.0pt;padding-right:5.0pt;">uk–ru</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.24.23.6" style="padding-left:5.0pt;padding-right:5.0pt;">3,792,978</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.25.24">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.25.24.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–yi</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.25.24.2" style="padding-left:5.0pt;padding-right:5.0pt;">3,904,022</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.25.24.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–ku</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.25.24.4" style="padding-left:5.0pt;padding-right:5.0pt;">5,254,260</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.25.24.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–ny</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.25.24.6" style="padding-left:5.0pt;padding-right:5.0pt;">5,408,239</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.26.25">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.26.25.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–so</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.26.25.2" style="padding-left:5.0pt;padding-right:5.0pt;">5,472,253</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.26.25.3" style="padding-left:5.0pt;padding-right:5.0pt;">xh–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.26.25.4" style="padding-left:5.0pt;padding-right:5.0pt;">5,728,449</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.26.25.5" style="padding-left:5.0pt;padding-right:5.0pt;">sm–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.26.25.6" style="padding-left:5.0pt;padding-right:5.0pt;">5,730,016</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.27.26">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.27.26.1" style="padding-left:5.0pt;padding-right:5.0pt;">lo–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.27.26.2" style="padding-left:5.0pt;padding-right:5.0pt;">5,766,691</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.27.26.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–mi</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.27.26.4" style="padding-left:5.0pt;padding-right:5.0pt;">5,793,624</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.27.26.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–co</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.27.26.6" style="padding-left:5.0pt;padding-right:5.0pt;">6,847,178</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.28.27">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.28.27.1" style="padding-left:5.0pt;padding-right:5.0pt;">ig–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.28.27.2" style="padding-left:5.0pt;padding-right:5.0pt;">7,224,372</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.28.27.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–tg</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.28.27.4" style="padding-left:5.0pt;padding-right:5.0pt;">8,136,182</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.28.27.5" style="padding-left:5.0pt;padding-right:5.0pt;">sn–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.28.27.6" style="padding-left:5.0pt;padding-right:5.0pt;">8,319,539</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.29.28">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.29.28.1" style="padding-left:5.0pt;padding-right:5.0pt;">yi–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.29.28.2" style="padding-left:5.0pt;padding-right:5.0pt;">8,347,482</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.29.28.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–zu</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.29.28.4" style="padding-left:5.0pt;padding-right:5.0pt;">8,376,755</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.29.28.5" style="padding-left:5.0pt;padding-right:5.0pt;">haw–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.29.28.6" style="padding-left:5.0pt;padding-right:5.0pt;">8,646,782</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.30.29">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.30.29.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–ha</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.30.29.2" style="padding-left:5.0pt;padding-right:5.0pt;">8,995,196</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.30.29.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–sd</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.30.29.4" style="padding-left:5.0pt;padding-right:5.0pt;">9,095,582</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.30.29.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–ps</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.30.29.6" style="padding-left:5.0pt;padding-right:5.0pt;">9,446,484</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.31.30">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.31.30.1" style="padding-left:5.0pt;padding-right:5.0pt;">yo–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.31.30.2" style="padding-left:5.0pt;padding-right:5.0pt;">9,565,981</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.31.30.3" style="padding-left:5.0pt;padding-right:5.0pt;">st–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.31.30.4" style="padding-left:5.0pt;padding-right:5.0pt;">10,052,460</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.31.30.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–ky</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.31.30.6" style="padding-left:5.0pt;padding-right:5.0pt;">10,213,875</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.32.31">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.32.31.1" style="padding-left:5.0pt;padding-right:5.0pt;">mi–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.32.31.2" style="padding-left:5.0pt;padding-right:5.0pt;">10,383,802</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.32.31.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–ht</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.32.31.4" style="padding-left:5.0pt;padding-right:5.0pt;">11,758,532</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.32.31.5" style="padding-left:5.0pt;padding-right:5.0pt;">ku–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.32.31.6" style="padding-left:5.0pt;padding-right:5.0pt;">11,984,479</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.33.32">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.33.32.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–ga</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.33.32.2" style="padding-left:5.0pt;padding-right:5.0pt;">12,494,184</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.33.32.3" style="padding-left:5.0pt;padding-right:5.0pt;">ny–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.33.32.4" style="padding-left:5.0pt;padding-right:5.0pt;">12,616,421</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.33.32.5" style="padding-left:5.0pt;padding-right:5.0pt;">so–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.33.32.6" style="padding-left:5.0pt;padding-right:5.0pt;">12,745,144</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.34.33">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.34.33.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–su</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.34.33.2" style="padding-left:5.0pt;padding-right:5.0pt;">14,088,043</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.34.33.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–am</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.34.33.4" style="padding-left:5.0pt;padding-right:5.0pt;">14,583,643</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.34.33.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–mt</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.34.33.6" style="padding-left:5.0pt;padding-right:5.0pt;">15,693,771</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.35.34">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.35.34.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–pa</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.35.34.2" style="padding-left:5.0pt;padding-right:5.0pt;">15,784,955</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.35.34.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–ceb</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.35.34.4" style="padding-left:5.0pt;padding-right:5.0pt;">15,965,215</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.35.34.5" style="padding-left:5.0pt;padding-right:5.0pt;">ga–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.35.34.6" style="padding-left:5.0pt;padding-right:5.0pt;">16,145,438</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.36.35">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.36.35.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–mg</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.36.35.2" style="padding-left:5.0pt;padding-right:5.0pt;">17,474,049</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.36.35.3" style="padding-left:5.0pt;padding-right:5.0pt;">co–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.36.35.4" style="padding-left:5.0pt;padding-right:5.0pt;">17,490,449</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.36.35.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–be</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.36.35.6" style="padding-left:5.0pt;padding-right:5.0pt;">17,645,900</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.37.36">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.37.36.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–eo</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.37.36.2" style="padding-left:5.0pt;padding-right:5.0pt;">18,104,746</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.37.36.3" style="padding-left:5.0pt;padding-right:5.0pt;">es–ru</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.37.36.4" style="padding-left:5.0pt;padding-right:5.0pt;">18,363,087</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.37.36.5" style="padding-left:5.0pt;padding-right:5.0pt;">ru–es</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.37.36.6" style="padding-left:5.0pt;padding-right:5.0pt;">18,363,087</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.38.37">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.38.37.1" style="padding-left:5.0pt;padding-right:5.0pt;">tg–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.38.37.2" style="padding-left:5.0pt;padding-right:5.0pt;">18,509,169</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.38.37.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–fy</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.38.37.4" style="padding-left:5.0pt;padding-right:5.0pt;">19,495,193</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.38.37.5" style="padding-left:5.0pt;padding-right:5.0pt;">ha–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.38.37.6" style="padding-left:5.0pt;padding-right:5.0pt;">19,687,379</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.39.38">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.39.38.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–mn</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.39.38.2" style="padding-left:5.0pt;padding-right:5.0pt;">20,012,644</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.39.38.3" style="padding-left:5.0pt;padding-right:5.0pt;">sd–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.39.38.4" style="padding-left:5.0pt;padding-right:5.0pt;">20,337,227</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.39.38.5" style="padding-left:5.0pt;padding-right:5.0pt;">es–fr</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.39.38.6" style="padding-left:5.0pt;padding-right:5.0pt;">20,792,781</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.40.39">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.40.39.1" style="padding-left:5.0pt;padding-right:5.0pt;">fr–es</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.40.39.2" style="padding-left:5.0pt;padding-right:5.0pt;">20,792,781</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.40.39.3" style="padding-left:5.0pt;padding-right:5.0pt;">zu–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.40.39.4" style="padding-left:5.0pt;padding-right:5.0pt;">21,010,498</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.40.39.5" style="padding-left:5.0pt;padding-right:5.0pt;">ky–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.40.39.6" style="padding-left:5.0pt;padding-right:5.0pt;">21,357,639</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.41.40">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.41.40.1" style="padding-left:5.0pt;padding-right:5.0pt;">ps–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.41.40.2" style="padding-left:5.0pt;padding-right:5.0pt;">21,613,753</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.41.40.3" style="padding-left:5.0pt;padding-right:5.0pt;">ht–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.41.40.4" style="padding-left:5.0pt;padding-right:5.0pt;">22,455,117</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.41.40.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–gd</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.41.40.6" style="padding-left:5.0pt;padding-right:5.0pt;">22,495,036</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.42.41">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.42.41.1" style="padding-left:5.0pt;padding-right:5.0pt;">fr–ru</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.42.41.2" style="padding-left:5.0pt;padding-right:5.0pt;">22,890,960</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.42.41.3" style="padding-left:5.0pt;padding-right:5.0pt;">ru–fr</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.42.41.4" style="padding-left:5.0pt;padding-right:5.0pt;">22,890,960</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.42.41.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–eu</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.42.41.6" style="padding-left:5.0pt;padding-right:5.0pt;">23,279,562</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.43.42">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.43.42.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–my</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.43.42.2" style="padding-left:5.0pt;padding-right:5.0pt;">23,848,386</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.43.42.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–hy</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.43.42.4" style="padding-left:5.0pt;padding-right:5.0pt;">25,779,512</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.43.42.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–lb</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.43.42.6" style="padding-left:5.0pt;padding-right:5.0pt;">25,943,545</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.44.43">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.44.43.1" style="padding-left:5.0pt;padding-right:5.0pt;">be–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.44.43.2" style="padding-left:5.0pt;padding-right:5.0pt;">28,585,822</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.44.43.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–hmn</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.44.43.4" style="padding-left:5.0pt;padding-right:5.0pt;">29,258,771</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.44.43.5" style="padding-left:5.0pt;padding-right:5.0pt;">pa–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.44.43.6" style="padding-left:5.0pt;padding-right:5.0pt;">29,592,573</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.45.44">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.45.44.1" style="padding-left:5.0pt;padding-right:5.0pt;">su–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.45.44.2" style="padding-left:5.0pt;padding-right:5.0pt;">30,234,526</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.45.44.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–jv</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.45.44.4" style="padding-left:5.0pt;padding-right:5.0pt;">30,315,732</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.45.44.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–uz</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.45.44.6" style="padding-left:5.0pt;padding-right:5.0pt;">30,943,271</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.46.45">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.46.45.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–si</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.46.45.2" style="padding-left:5.0pt;padding-right:5.0pt;">31,847,809</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.46.45.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–kk</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.46.45.4" style="padding-left:5.0pt;padding-right:5.0pt;">32,075,645</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.46.45.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–cy</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.46.45.6" style="padding-left:5.0pt;padding-right:5.0pt;">32,089,017</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.47.46">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.47.46.1" style="padding-left:5.0pt;padding-right:5.0pt;">am–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.47.46.2" style="padding-left:5.0pt;padding-right:5.0pt;">32,110,524</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.47.46.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–ml</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.47.46.4" style="padding-left:5.0pt;padding-right:5.0pt;">32,335,094</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.47.46.5" style="padding-left:5.0pt;padding-right:5.0pt;">mg–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.47.46.6" style="padding-left:5.0pt;padding-right:5.0pt;">32,356,401</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.48.47">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.48.47.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–gu</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.48.47.2" style="padding-left:5.0pt;padding-right:5.0pt;">32,742,711</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.48.47.3" style="padding-left:5.0pt;padding-right:5.0pt;">fy–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.48.47.4" style="padding-left:5.0pt;padding-right:5.0pt;">33,389,347</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.48.47.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–mk</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.48.47.6" style="padding-left:5.0pt;padding-right:5.0pt;">33,546,951</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.49.48">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.49.48.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–mr</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.49.48.2" style="padding-left:5.0pt;padding-right:5.0pt;">33,629,504</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.49.48.3" style="padding-left:5.0pt;padding-right:5.0pt;">hy–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.49.48.4" style="padding-left:5.0pt;padding-right:5.0pt;">34,146,553</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.49.48.5" style="padding-left:5.0pt;padding-right:5.0pt;">eu–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.49.48.6" style="padding-left:5.0pt;padding-right:5.0pt;">35,158,779</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.50.49">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.50.49.1" style="padding-left:5.0pt;padding-right:5.0pt;">hmn–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.50.49.2" style="padding-left:5.0pt;padding-right:5.0pt;">35,795,085</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.50.49.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–bs</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.50.49.4" style="padding-left:5.0pt;padding-right:5.0pt;">35,801,135</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.50.49.5" style="padding-left:5.0pt;padding-right:5.0pt;">gd–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.50.49.6" style="padding-left:5.0pt;padding-right:5.0pt;">36,082,889</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.51.50">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.51.50.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–kn</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.51.50.2" style="padding-left:5.0pt;padding-right:5.0pt;">36,472,587</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.51.50.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–km</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.tab1.1.51.50.4" style="padding-left:5.0pt;padding-right:5.0pt;">37,229,149</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.tab1.1.51.50.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–hr</th>
<td class="ltx_td ltx_align_left" id="Ax1.tab1.1.51.50.6" style="padding-left:5.0pt;padding-right:5.0pt;">37,248,537</td>
</tr>
<tr class="ltx_tr" id="Ax1.tab1.1.52.51">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="Ax1.tab1.1.52.51.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–ne</th>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="Ax1.tab1.1.52.51.2" style="padding-left:5.0pt;padding-right:5.0pt;">38,606,074</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="Ax1.tab1.1.52.51.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–sw</th>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="Ax1.tab1.1.52.51.4" style="padding-left:5.0pt;padding-right:5.0pt;">41,198,888</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="Ax1.tab1.1.52.51.5" style="padding-left:5.0pt;padding-right:5.0pt;">mt–en</th>
<td class="ltx_td ltx_align_left ltx_border_bb" id="Ax1.tab1.1.52.51.6" style="padding-left:5.0pt;padding-right:5.0pt;">41,723,852</td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_table" id="Ax1.T4">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="Ax1.T4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="Ax1.T4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="Ax1.T4.1.1.1.1" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="Ax1.T4.1.1.1.1.1">LP</span></th>
<th class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="Ax1.T4.1.1.1.2" style="padding-left:5.0pt;padding-right:5.0pt;">
<span class="ltx_text ltx_font_bold" id="Ax1.T4.1.1.1.2.1">Num. of sentences</span>   |</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="Ax1.T4.1.1.1.3" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="Ax1.T4.1.1.1.3.1">LP</span></th>
<th class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="Ax1.T4.1.1.1.4" style="padding-left:5.0pt;padding-right:5.0pt;">
<span class="ltx_text ltx_font_bold" id="Ax1.T4.1.1.1.4.1">Num. of sentences</span>   |</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="Ax1.T4.1.1.1.5" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="Ax1.T4.1.1.1.5.1">LP</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="Ax1.T4.1.1.1.6" style="padding-left:5.0pt;padding-right:5.0pt;"><span class="ltx_text ltx_font_bold" id="Ax1.T4.1.1.1.6.1">Num. of sentences</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="Ax1.T4.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="Ax1.T4.1.2.1.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–ka</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="Ax1.T4.1.2.1.2" style="padding-left:5.0pt;padding-right:5.0pt;">42,992,730</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="Ax1.T4.1.2.1.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–te</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="Ax1.T4.1.2.1.4" style="padding-left:5.0pt;padding-right:5.0pt;">43,112,561</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="Ax1.T4.1.2.1.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–gl</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="Ax1.T4.1.2.1.6" style="padding-left:5.0pt;padding-right:5.0pt;">45,053,738</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.3.2.1" style="padding-left:5.0pt;padding-right:5.0pt;">lb–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.3.2.2" style="padding-left:5.0pt;padding-right:5.0pt;">46,042,055</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.3.2.3" style="padding-left:5.0pt;padding-right:5.0pt;">kn–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.3.2.4" style="padding-left:5.0pt;padding-right:5.0pt;">46,847,179</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.3.2.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–sr</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.3.2.6" style="padding-left:5.0pt;padding-right:5.0pt;">48,786,193</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.4.3.1" style="padding-left:5.0pt;padding-right:5.0pt;">mn–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.4.3.2" style="padding-left:5.0pt;padding-right:5.0pt;">49,510,283</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.4.3.3" style="padding-left:5.0pt;padding-right:5.0pt;">cy–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.4.3.4" style="padding-left:5.0pt;padding-right:5.0pt;">50,252,795</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.4.3.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–af</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.4.3.6" style="padding-left:5.0pt;padding-right:5.0pt;">50,525,196</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.5.4.1" style="padding-left:5.0pt;padding-right:5.0pt;">gu–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.5.4.2" style="padding-left:5.0pt;padding-right:5.0pt;">53,217,408</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.5.4.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–sq</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.5.4.4" style="padding-left:5.0pt;padding-right:5.0pt;">55,374,368</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.5.4.5" style="padding-left:5.0pt;padding-right:5.0pt;">my–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.5.4.6" style="padding-left:5.0pt;padding-right:5.0pt;">55,886,059</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.6.5.1" style="padding-left:5.0pt;padding-right:5.0pt;">jv–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.6.5.2" style="padding-left:5.0pt;padding-right:5.0pt;">57,400,218</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.6.5.3" style="padding-left:5.0pt;padding-right:5.0pt;">ceb–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.6.5.4" style="padding-left:5.0pt;padding-right:5.0pt;">59,055,133</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.6.5.5" style="padding-left:5.0pt;padding-right:5.0pt;">mk–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.6.5.6" style="padding-left:5.0pt;padding-right:5.0pt;">61,867,654</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.7.6.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–ta</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.7.6.2" style="padding-left:5.0pt;padding-right:5.0pt;">62,352,671</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.7.6.3" style="padding-left:5.0pt;padding-right:5.0pt;">eo–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.7.6.4" style="padding-left:5.0pt;padding-right:5.0pt;">62,552,455</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.7.6.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–az</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.7.6.6" style="padding-left:5.0pt;padding-right:5.0pt;">64,274,455</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.8.7.1" style="padding-left:5.0pt;padding-right:5.0pt;">kk–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.8.7.2" style="padding-left:5.0pt;padding-right:5.0pt;">64,724,987</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.8.7.3" style="padding-left:5.0pt;padding-right:5.0pt;">ne–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.8.7.4" style="padding-left:5.0pt;padding-right:5.0pt;">69,288,148</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.8.7.5" style="padding-left:5.0pt;padding-right:5.0pt;">si–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.8.7.6" style="padding-left:5.0pt;padding-right:5.0pt;">69,667,030</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.9.8.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–lv</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.9.8.2" style="padding-left:5.0pt;padding-right:5.0pt;">69,998,174</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.9.8.3" style="padding-left:5.0pt;padding-right:5.0pt;">ml–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.9.8.4" style="padding-left:5.0pt;padding-right:5.0pt;">70,059,552</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.9.8.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–is</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.9.8.6" style="padding-left:5.0pt;padding-right:5.0pt;">71,837,680</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.10.9.1" style="padding-left:5.0pt;padding-right:5.0pt;">hr–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.10.9.2" style="padding-left:5.0pt;padding-right:5.0pt;">72,301,373</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.10.9.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–ur</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.10.9.4" style="padding-left:5.0pt;padding-right:5.0pt;">74,947,168</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.10.9.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–et</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.10.9.6" style="padding-left:5.0pt;padding-right:5.0pt;">75,581,372</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.11.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.11.10.1" style="padding-left:5.0pt;padding-right:5.0pt;">te–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.11.10.2" style="padding-left:5.0pt;padding-right:5.0pt;">75,967,139</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.11.10.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–bn</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.11.10.4" style="padding-left:5.0pt;padding-right:5.0pt;">80,362,347</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.11.10.5" style="padding-left:5.0pt;padding-right:5.0pt;">km–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.11.10.6" style="padding-left:5.0pt;padding-right:5.0pt;">80,514,558</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.12.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.12.11.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–uk</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.12.11.2" style="padding-left:5.0pt;padding-right:5.0pt;">86,997,037</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.12.11.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–ca</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.12.11.4" style="padding-left:5.0pt;padding-right:5.0pt;">87,267,893</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.12.11.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–sk</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.12.11.6" style="padding-left:5.0pt;padding-right:5.0pt;">89,304,972</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.13.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.13.12.1" style="padding-left:5.0pt;padding-right:5.0pt;">gl–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.13.12.2" style="padding-left:5.0pt;padding-right:5.0pt;">89,695,691</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.13.12.3" style="padding-left:5.0pt;padding-right:5.0pt;">bs–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.13.12.4" style="padding-left:5.0pt;padding-right:5.0pt;">90,263,002</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.13.12.5" style="padding-left:5.0pt;padding-right:5.0pt;">sw–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.13.12.6" style="padding-left:5.0pt;padding-right:5.0pt;">90,493,834</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.14.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.14.13.1" style="padding-left:5.0pt;padding-right:5.0pt;">af–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.14.13.2" style="padding-left:5.0pt;padding-right:5.0pt;">94,492,215</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.14.13.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–fil</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.14.13.4" style="padding-left:5.0pt;padding-right:5.0pt;">97,193,343</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.14.13.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–sl</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.14.13.6" style="padding-left:5.0pt;padding-right:5.0pt;">97,924,827</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.15.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.15.14.1" style="padding-left:5.0pt;padding-right:5.0pt;">ka–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.15.14.2" style="padding-left:5.0pt;padding-right:5.0pt;">99,344,373</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.15.14.3" style="padding-left:5.0pt;padding-right:5.0pt;">ta–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.15.14.4" style="padding-left:5.0pt;padding-right:5.0pt;">100,659,244</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.15.14.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–lt</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.15.14.6" style="padding-left:5.0pt;padding-right:5.0pt;">102,081,855</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.16.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.16.15.1" style="padding-left:5.0pt;padding-right:5.0pt;">is–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.16.15.2" style="padding-left:5.0pt;padding-right:5.0pt;">103,425,627</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.16.15.3" style="padding-left:5.0pt;padding-right:5.0pt;">sq–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.16.15.4" style="padding-left:5.0pt;padding-right:5.0pt;">104,573,595</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.16.15.5" style="padding-left:5.0pt;padding-right:5.0pt;">mr–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.16.15.6" style="padding-left:5.0pt;padding-right:5.0pt;">105,247,834</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.17.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.17.16.1" style="padding-left:5.0pt;padding-right:5.0pt;">uz–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.17.16.2" style="padding-left:5.0pt;padding-right:5.0pt;">105,701,543</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.17.16.3" style="padding-left:5.0pt;padding-right:5.0pt;">az–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.17.16.4" style="padding-left:5.0pt;padding-right:5.0pt;">115,304,502</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.17.16.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–iw</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.17.16.6" style="padding-left:5.0pt;padding-right:5.0pt;">117,411,687</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.18.17">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.18.17.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–ms</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.18.17.2" style="padding-left:5.0pt;padding-right:5.0pt;">117,562,320</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.18.17.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–fa</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.18.17.4" style="padding-left:5.0pt;padding-right:5.0pt;">117,720,531</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.18.17.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–bg</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.18.17.6" style="padding-left:5.0pt;padding-right:5.0pt;">128,893,255</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.19.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.19.18.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–fi</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.19.18.2" style="padding-left:5.0pt;padding-right:5.0pt;">133,307,056</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.19.18.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–el</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.19.18.4" style="padding-left:5.0pt;padding-right:5.0pt;">135,547,629</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.19.18.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–ro</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.19.18.6" style="padding-left:5.0pt;padding-right:5.0pt;">136,723,562</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.20.19">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.20.19.1" style="padding-left:5.0pt;padding-right:5.0pt;">ca–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.20.19.2" style="padding-left:5.0pt;padding-right:5.0pt;">137,014,332</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.20.19.3" style="padding-left:5.0pt;padding-right:5.0pt;">sr–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.20.19.4" style="padding-left:5.0pt;padding-right:5.0pt;">137,913,360</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.20.19.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–hu</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.20.19.6" style="padding-left:5.0pt;padding-right:5.0pt;">146,210,128</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.21.20">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.21.20.1" style="padding-left:5.0pt;padding-right:5.0pt;">ur–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.21.20.2" style="padding-left:5.0pt;padding-right:5.0pt;">149,852,215</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.21.20.3" style="padding-left:5.0pt;padding-right:5.0pt;">fil–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.21.20.4" style="padding-left:5.0pt;padding-right:5.0pt;">156,986,036</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.21.20.5" style="padding-left:5.0pt;padding-right:5.0pt;">lv–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.21.20.6" style="padding-left:5.0pt;padding-right:5.0pt;">163,533,602</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.22.21">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.22.21.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–no</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.22.21.2" style="padding-left:5.0pt;padding-right:5.0pt;">165,068,512</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.22.21.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–cs</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.22.21.4" style="padding-left:5.0pt;padding-right:5.0pt;">167,802,683</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.22.21.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–da</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.22.21.6" style="padding-left:5.0pt;padding-right:5.0pt;">176,676,171</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.23.22">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.23.22.1" style="padding-left:5.0pt;padding-right:5.0pt;">sl–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.23.22.2" style="padding-left:5.0pt;padding-right:5.0pt;">189,776,212</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.23.22.3" style="padding-left:5.0pt;padding-right:5.0pt;">bn–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.23.22.4" style="padding-left:5.0pt;padding-right:5.0pt;">190,650,787</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.23.22.5" style="padding-left:5.0pt;padding-right:5.0pt;">et–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.23.22.6" style="padding-left:5.0pt;padding-right:5.0pt;">197,134,423</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.24.23">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.24.23.1" style="padding-left:5.0pt;padding-right:5.0pt;">uk–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.24.23.2" style="padding-left:5.0pt;padding-right:5.0pt;">209,888,151</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.24.23.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–sv</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.24.23.4" style="padding-left:5.0pt;padding-right:5.0pt;">217,128,777</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.24.23.5" style="padding-left:5.0pt;padding-right:5.0pt;">lt–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.24.23.6" style="padding-left:5.0pt;padding-right:5.0pt;">245,092,644</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.25.24">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.25.24.1" style="padding-left:5.0pt;padding-right:5.0pt;">bg–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.25.24.2" style="padding-left:5.0pt;padding-right:5.0pt;">289,282,624</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.25.24.3" style="padding-left:5.0pt;padding-right:5.0pt;">sk–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.25.24.4" style="padding-left:5.0pt;padding-right:5.0pt;">295,623,418</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.25.24.5" style="padding-left:5.0pt;padding-right:5.0pt;">fi–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.25.24.6" style="padding-left:5.0pt;padding-right:5.0pt;">300,151,301</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.26.25">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.26.25.1" style="padding-left:5.0pt;padding-right:5.0pt;">el–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.26.25.2" style="padding-left:5.0pt;padding-right:5.0pt;">322,429,692</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.26.25.3" style="padding-left:5.0pt;padding-right:5.0pt;">th–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.26.25.4" style="padding-left:5.0pt;padding-right:5.0pt;">340,378,951</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.26.25.5" style="padding-left:5.0pt;padding-right:5.0pt;">ro–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.26.25.6" style="padding-left:5.0pt;padding-right:5.0pt;">352,986,741</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.27.26">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.27.26.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–th</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.27.26.2" style="padding-left:5.0pt;padding-right:5.0pt;">353,001,311</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.27.26.3" style="padding-left:5.0pt;padding-right:5.0pt;">fa–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.27.26.4" style="padding-left:5.0pt;padding-right:5.0pt;">402,836,484</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.27.26.5" style="padding-left:5.0pt;padding-right:5.0pt;">ms–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.27.26.6" style="padding-left:5.0pt;padding-right:5.0pt;">414,693,796</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.28.27">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.28.27.1" style="padding-left:5.0pt;padding-right:5.0pt;">iw–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.28.27.2" style="padding-left:5.0pt;padding-right:5.0pt;">427,057,571</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.28.27.3" style="padding-left:5.0pt;padding-right:5.0pt;">hu–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.28.27.4" style="padding-left:5.0pt;padding-right:5.0pt;">436,082,952</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.28.27.5" style="padding-left:5.0pt;padding-right:5.0pt;">hi–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.28.27.6" style="padding-left:5.0pt;padding-right:5.0pt;">490,464,288</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.29.28">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.29.28.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–hi</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.29.28.2" style="padding-left:5.0pt;padding-right:5.0pt;">494,638,634</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.29.28.3" style="padding-left:5.0pt;padding-right:5.0pt;">ar–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.29.28.4" style="padding-left:5.0pt;padding-right:5.0pt;">525,411,304</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.29.28.5" style="padding-left:5.0pt;padding-right:5.0pt;">id–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.29.28.6" style="padding-left:5.0pt;padding-right:5.0pt;">527,345,119</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.30.29">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.30.29.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–ar</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.30.29.2" style="padding-left:5.0pt;padding-right:5.0pt;">532,778,336</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.30.29.3" style="padding-left:5.0pt;padding-right:5.0pt;">ko–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.30.29.4" style="padding-left:5.0pt;padding-right:5.0pt;">535,863,357</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.30.29.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–id</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.30.29.6" style="padding-left:5.0pt;padding-right:5.0pt;">538,581,029</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.31.30">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.31.30.1" style="padding-left:5.0pt;padding-right:5.0pt;">da–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.31.30.2" style="padding-left:5.0pt;padding-right:5.0pt;">539,573,001</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.31.30.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–ko</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.31.30.4" style="padding-left:5.0pt;padding-right:5.0pt;">546,191,335</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.31.30.5" style="padding-left:5.0pt;padding-right:5.0pt;">no–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.31.30.6" style="padding-left:5.0pt;padding-right:5.0pt;">613,221,604</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.32.31">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.32.31.1" style="padding-left:5.0pt;padding-right:5.0pt;">vi–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.32.31.2" style="padding-left:5.0pt;padding-right:5.0pt;">632,740,475</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.32.31.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–vi</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.32.31.4" style="padding-left:5.0pt;padding-right:5.0pt;">656,115,977</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.32.31.5" style="padding-left:5.0pt;padding-right:5.0pt;">cs–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.32.31.6" style="padding-left:5.0pt;padding-right:5.0pt;">661,833,636</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.33.32">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.33.32.1" style="padding-left:5.0pt;padding-right:5.0pt;">sv–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.33.32.2" style="padding-left:5.0pt;padding-right:5.0pt;">800,882,060</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.33.32.3" style="padding-left:5.0pt;padding-right:5.0pt;">ja–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.33.32.4" style="padding-left:5.0pt;padding-right:5.0pt;">846,991,020</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.33.32.5" style="padding-left:5.0pt;padding-right:5.0pt;">tr–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.33.32.6" style="padding-left:5.0pt;padding-right:5.0pt;">850,154,583</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.34.33">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.34.33.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–tr</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.34.33.2" style="padding-left:5.0pt;padding-right:5.0pt;">869,295,018</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.34.33.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–ja</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.34.33.4" style="padding-left:5.0pt;padding-right:5.0pt;">876,842,917</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.34.33.5" style="padding-left:5.0pt;padding-right:5.0pt;">it–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.34.33.6" style="padding-left:5.0pt;padding-right:5.0pt;">998,195,505</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.35.34">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.35.34.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–it</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.35.34.2" style="padding-left:5.0pt;padding-right:5.0pt;">100,981,5294</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.35.34.3" style="padding-left:5.0pt;padding-right:5.0pt;">pl–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.35.34.4" style="padding-left:5.0pt;padding-right:5.0pt;">111,935,3071</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.35.34.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–pl</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.35.34.6" style="padding-left:5.0pt;padding-right:5.0pt;">1,141,598,628</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.36.35">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.36.35.1" style="padding-left:5.0pt;padding-right:5.0pt;">pt–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.36.35.2" style="padding-left:5.0pt;padding-right:5.0pt;">1,155,038,272</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.36.35.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–pt</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.36.35.4" style="padding-left:5.0pt;padding-right:5.0pt;">1,184,401,180</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.36.35.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–zh</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.36.35.6" style="padding-left:5.0pt;padding-right:5.0pt;">1,228,817,744</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.37.36">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.37.36.1" style="padding-left:5.0pt;padding-right:5.0pt;">zh–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.37.36.2" style="padding-left:5.0pt;padding-right:5.0pt;">1,238,691,743</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.37.36.3" style="padding-left:5.0pt;padding-right:5.0pt;">ru–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.37.36.4" style="padding-left:5.0pt;padding-right:5.0pt;">1,425,268,039</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.37.36.5" style="padding-left:5.0pt;padding-right:5.0pt;">en–ru</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.37.36.6" style="padding-left:5.0pt;padding-right:5.0pt;">1,455,103,126</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.38.37">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.38.37.1" style="padding-left:5.0pt;padding-right:5.0pt;">nl–en</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.38.37.2" style="padding-left:5.0pt;padding-right:5.0pt;">1,580,819,532</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.38.37.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–nl</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.38.37.4" style="padding-left:5.0pt;padding-right:5.0pt;">1,587,530,791</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.38.37.5" style="padding-left:5.0pt;padding-right:5.0pt;">de–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.38.37.6" style="padding-left:5.0pt;padding-right:5.0pt;">1,680,270,443</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.39.38">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.39.38.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–de</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.39.38.2" style="padding-left:5.0pt;padding-right:5.0pt;">1,695,095,726</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.39.38.3" style="padding-left:5.0pt;padding-right:5.0pt;">en–fr</th>
<td class="ltx_td ltx_align_left ltx_border_r" id="Ax1.T4.1.39.38.4" style="padding-left:5.0pt;padding-right:5.0pt;">1,887,609,530</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="Ax1.T4.1.39.38.5" style="padding-left:5.0pt;padding-right:5.0pt;">fr–en</th>
<td class="ltx_td ltx_align_left" id="Ax1.T4.1.39.38.6" style="padding-left:5.0pt;padding-right:5.0pt;">1,922,463,803</td>
</tr>
<tr class="ltx_tr" id="Ax1.T4.1.40.39">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="Ax1.T4.1.40.39.1" style="padding-left:5.0pt;padding-right:5.0pt;">en–es</th>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="Ax1.T4.1.40.39.2" style="padding-left:5.0pt;padding-right:5.0pt;">2,419,825,975</td>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="Ax1.T4.1.40.39.3" style="padding-left:5.0pt;padding-right:5.0pt;">es–en</th>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="Ax1.T4.1.40.39.4" style="padding-left:5.0pt;padding-right:5.0pt;">2,435,228,645</td>
<th class="ltx_td ltx_th ltx_th_row ltx_border_bb" id="Ax1.T4.1.40.39.5" style="padding-left:5.0pt;padding-right:5.0pt;"></th>
<td class="ltx_td ltx_border_bb" id="Ax1.T4.1.40.39.6" style="padding-left:5.0pt;padding-right:5.0pt;"></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Number of Sentences of each Language Pair (LP) in our train set.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sun May 19 17:47:21 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
