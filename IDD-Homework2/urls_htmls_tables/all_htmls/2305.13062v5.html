<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2305.13062] Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study</title><meta property="og:description" content="Large language models (LLMs) are becoming attractive as few-shot reasoners to solve Natural Language (NL)-related tasks. However, there is still much to learn about how well LLMs understand structured data, such as tab…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2305.13062">

<!--Generated on Thu Feb 29 06:34:40 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="large language models,  semi-structured data,  structural understanding capabilities,  benchmark">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yuan Sui
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:yuan.sui@u.nus.edu">yuan.sui@u.nus.edu</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="6.1.1" class="ltx_text ltx_affiliation_institution">National University of Singapore</span><span id="7.2.2" class="ltx_text ltx_affiliation_country">Singapore</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mengyu Zhou
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:mezho@microsoft.com">mezho@microsoft.com</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="8.1.1" class="ltx_text ltx_affiliation_institution">Microsoft</span><span id="9.2.2" class="ltx_text ltx_affiliation_country">Beijing, China</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mingjie Zhou
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:mjzhou@connect.hku.hk">mjzhou@connect.hku.hk</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="10.1.1" class="ltx_text ltx_affiliation_institution">The University of Hong Kong</span><span id="11.2.2" class="ltx_text ltx_affiliation_country">Hong Kong, China</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Shi Han
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:shihan@microsoft.com">shihan@microsoft.com</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="12.1.1" class="ltx_text ltx_affiliation_institution">Microsoft</span><span id="13.2.2" class="ltx_text ltx_affiliation_country">Beijing, China</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Dongmei Zhang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:dongmeiz@microsoft.com">dongmeiz@microsoft.com</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="14.1.1" class="ltx_text ltx_affiliation_institution">Microsoft</span><span id="15.2.2" class="ltx_text ltx_affiliation_country">Beijing, China</span>
</span></span></span>
</div>
<div class="ltx_dates">(2024)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id5.5" class="ltx_p">Large language models (LLMs) are becoming attractive as few-shot reasoners to solve Natural Language (NL)-related tasks. However, there is still much to learn about how well LLMs understand structured data, such as tables. Although tables can be used as input to LLMs with serialization, there is a lack of comprehensive studies that examine whether LLMs can truly comprehend such data. In this paper, we try to understand this by designing a benchmark to evaluate the structural understanding capabilities (SUC) of LLMs. The benchmark we create includes seven tasks, each with its own unique challenges, <span id="id5.5.1" class="ltx_text ltx_font_italic">e.g.</span>, cell lookup, row retrieval, and size detection.
We perform a series of evaluations on GPT-3.5 and GPT-4. We find that performance varied depending on several input choices, including table input format, content order, role prompting, and partition marks. Drawing from the insights gained through the benchmark evaluations, we propose <span id="id5.5.2" class="ltx_text ltx_font_italic">self-augmentation</span> for effective structural prompting, such as critical value / range identification using internal knowledge of LLMs. When combined with carefully chosen input choices, these structural prompting methods lead to promising improvements in LLM performance on a variety of tabular tasks, <span id="id5.5.3" class="ltx_text ltx_font_italic">e.g.</span>, TabFact(<math id="1.m1.1" class="ltx_Math" alttext="\uparrow 2.31\%" display="inline"><semantics id="1.m1.1a"><mrow id="1.m1.1.1" xref="1.m1.1.1.cmml"><mi id="1.m1.1.1.2" xref="1.m1.1.1.2.cmml"></mi><mo stretchy="false" id="1.m1.1.1.1" xref="1.m1.1.1.1.cmml">↑</mo><mrow id="1.m1.1.1.3" xref="1.m1.1.1.3.cmml"><mn id="1.m1.1.1.3.2" xref="1.m1.1.1.3.2.cmml">2.31</mn><mo id="1.m1.1.1.3.1" xref="1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="1.m1.1b"><apply id="1.m1.1.1.cmml" xref="1.m1.1.1"><ci id="1.m1.1.1.1.cmml" xref="1.m1.1.1.1">↑</ci><csymbol cd="latexml" id="1.m1.1.1.2.cmml" xref="1.m1.1.1.2">absent</csymbol><apply id="1.m1.1.1.3.cmml" xref="1.m1.1.1.3"><csymbol cd="latexml" id="1.m1.1.1.3.1.cmml" xref="1.m1.1.1.3.1">percent</csymbol><cn type="float" id="1.m1.1.1.3.2.cmml" xref="1.m1.1.1.3.2">2.31</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="1.m1.1c">\uparrow 2.31\%</annotation></semantics></math>), HybridQA(<math id="id2.2.m2.1" class="ltx_Math" alttext="\uparrow 2.13\%" display="inline"><semantics id="id2.2.m2.1a"><mrow id="id2.2.m2.1.1" xref="id2.2.m2.1.1.cmml"><mi id="id2.2.m2.1.1.2" xref="id2.2.m2.1.1.2.cmml"></mi><mo stretchy="false" id="id2.2.m2.1.1.1" xref="id2.2.m2.1.1.1.cmml">↑</mo><mrow id="id2.2.m2.1.1.3" xref="id2.2.m2.1.1.3.cmml"><mn id="id2.2.m2.1.1.3.2" xref="id2.2.m2.1.1.3.2.cmml">2.13</mn><mo id="id2.2.m2.1.1.3.1" xref="id2.2.m2.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="id2.2.m2.1b"><apply id="id2.2.m2.1.1.cmml" xref="id2.2.m2.1.1"><ci id="id2.2.m2.1.1.1.cmml" xref="id2.2.m2.1.1.1">↑</ci><csymbol cd="latexml" id="id2.2.m2.1.1.2.cmml" xref="id2.2.m2.1.1.2">absent</csymbol><apply id="id2.2.m2.1.1.3.cmml" xref="id2.2.m2.1.1.3"><csymbol cd="latexml" id="id2.2.m2.1.1.3.1.cmml" xref="id2.2.m2.1.1.3.1">percent</csymbol><cn type="float" id="id2.2.m2.1.1.3.2.cmml" xref="id2.2.m2.1.1.3.2">2.13</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="id2.2.m2.1c">\uparrow 2.13\%</annotation></semantics></math>), SQA(<math id="id3.3.m3.1" class="ltx_Math" alttext="\uparrow 2.72\%" display="inline"><semantics id="id3.3.m3.1a"><mrow id="id3.3.m3.1.1" xref="id3.3.m3.1.1.cmml"><mi id="id3.3.m3.1.1.2" xref="id3.3.m3.1.1.2.cmml"></mi><mo stretchy="false" id="id3.3.m3.1.1.1" xref="id3.3.m3.1.1.1.cmml">↑</mo><mrow id="id3.3.m3.1.1.3" xref="id3.3.m3.1.1.3.cmml"><mn id="id3.3.m3.1.1.3.2" xref="id3.3.m3.1.1.3.2.cmml">2.72</mn><mo id="id3.3.m3.1.1.3.1" xref="id3.3.m3.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="id3.3.m3.1b"><apply id="id3.3.m3.1.1.cmml" xref="id3.3.m3.1.1"><ci id="id3.3.m3.1.1.1.cmml" xref="id3.3.m3.1.1.1">↑</ci><csymbol cd="latexml" id="id3.3.m3.1.1.2.cmml" xref="id3.3.m3.1.1.2">absent</csymbol><apply id="id3.3.m3.1.1.3.cmml" xref="id3.3.m3.1.1.3"><csymbol cd="latexml" id="id3.3.m3.1.1.3.1.cmml" xref="id3.3.m3.1.1.3.1">percent</csymbol><cn type="float" id="id3.3.m3.1.1.3.2.cmml" xref="id3.3.m3.1.1.3.2">2.72</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="id3.3.m3.1c">\uparrow 2.72\%</annotation></semantics></math>), Feverous(<math id="id4.4.m4.1" class="ltx_Math" alttext="\uparrow 0.84\%" display="inline"><semantics id="id4.4.m4.1a"><mrow id="id4.4.m4.1.1" xref="id4.4.m4.1.1.cmml"><mi id="id4.4.m4.1.1.2" xref="id4.4.m4.1.1.2.cmml"></mi><mo stretchy="false" id="id4.4.m4.1.1.1" xref="id4.4.m4.1.1.1.cmml">↑</mo><mrow id="id4.4.m4.1.1.3" xref="id4.4.m4.1.1.3.cmml"><mn id="id4.4.m4.1.1.3.2" xref="id4.4.m4.1.1.3.2.cmml">0.84</mn><mo id="id4.4.m4.1.1.3.1" xref="id4.4.m4.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="id4.4.m4.1b"><apply id="id4.4.m4.1.1.cmml" xref="id4.4.m4.1.1"><ci id="id4.4.m4.1.1.1.cmml" xref="id4.4.m4.1.1.1">↑</ci><csymbol cd="latexml" id="id4.4.m4.1.1.2.cmml" xref="id4.4.m4.1.1.2">absent</csymbol><apply id="id4.4.m4.1.1.3.cmml" xref="id4.4.m4.1.1.3"><csymbol cd="latexml" id="id4.4.m4.1.1.3.1.cmml" xref="id4.4.m4.1.1.3.1">percent</csymbol><cn type="float" id="id4.4.m4.1.1.3.2.cmml" xref="id4.4.m4.1.1.3.2">0.84</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="id4.4.m4.1c">\uparrow 0.84\%</annotation></semantics></math>), and ToTTo(<math id="id5.5.m5.1" class="ltx_Math" alttext="\uparrow 5.68\%" display="inline"><semantics id="id5.5.m5.1a"><mrow id="id5.5.m5.1.1" xref="id5.5.m5.1.1.cmml"><mi id="id5.5.m5.1.1.2" xref="id5.5.m5.1.1.2.cmml"></mi><mo stretchy="false" id="id5.5.m5.1.1.1" xref="id5.5.m5.1.1.1.cmml">↑</mo><mrow id="id5.5.m5.1.1.3" xref="id5.5.m5.1.1.3.cmml"><mn id="id5.5.m5.1.1.3.2" xref="id5.5.m5.1.1.3.2.cmml">5.68</mn><mo id="id5.5.m5.1.1.3.1" xref="id5.5.m5.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="id5.5.m5.1b"><apply id="id5.5.m5.1.1.cmml" xref="id5.5.m5.1.1"><ci id="id5.5.m5.1.1.1.cmml" xref="id5.5.m5.1.1.1">↑</ci><csymbol cd="latexml" id="id5.5.m5.1.1.2.cmml" xref="id5.5.m5.1.1.2">absent</csymbol><apply id="id5.5.m5.1.1.3.cmml" xref="id5.5.m5.1.1.3"><csymbol cd="latexml" id="id5.5.m5.1.1.3.1.cmml" xref="id5.5.m5.1.1.3.1">percent</csymbol><cn type="float" id="id5.5.m5.1.1.3.2.cmml" xref="id5.5.m5.1.1.3.2">5.68</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="id5.5.m5.1c">\uparrow 5.68\%</annotation></semantics></math>). We believe that our open source<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Please find code and data of the paper at <a target="_blank" href="https://github.com/microsoft/TableProvider" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/microsoft/TableProvider</a>.</span></span></span> benchmark and proposed prompting methods can serve as a simple yet generic selection for future research.</p>
</div>
<div class="ltx_keywords">large language models, semi-structured data, structural understanding capabilities, benchmark
</div>
<span id="16" class="ltx_note ltx_note_frontmatter ltx_role_journalyear"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2024</span></span></span><span id="17" class="ltx_note ltx_note_frontmatter ltx_role_copyright"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmlicensed</span></span></span><span id="18" class="ltx_note ltx_note_frontmatter ltx_role_conference"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>Proceedings of the 17th ACM International Conference on Web Search and Data Mining; March 4–8, 2024; Mérida, Yucatán, Mexico.</span></span></span><span id="19" class="ltx_note ltx_note_frontmatter ltx_role_booktitle"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">booktitle: </span>Proceedings of the 17th ACM International Conference on Web Search and Data Mining (WSDM ’24), March 4–8, 2024, Mérida, Yucatán, Mexico</span></span></span><span id="20" class="ltx_note ltx_note_frontmatter ltx_role_price"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">price: </span>15.00</span></span></span><span id="21" class="ltx_note ltx_note_frontmatter ltx_role_isbn"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>979-8-4007-0371-3/24/03</span></span></span><span id="22" class="ltx_note ltx_note_frontmatter ltx_role_doi"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>10.1145/3616855.3635752</span></span></span><span id="23" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Information systems Information retrieval query processing</span></span></span><span id="24" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Natural language processing</span></span></span><span id="25" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Natural language generation</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Structured data consists of plain text blocks organized by predefined structures to compress recurring information. It makes data more manageable and facilitates data analysis and processing by machines. <span id="S1.p1.1.1" class="ltx_text ltx_font_bold">Table</span> is one of such structured data types with many applications such as Table-based Question Answering (TQA) <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2020b</a>; Iyyer et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2017</a>)</cite>, Table-based Fact Verification (TFV) <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2020a</a>; Xie et al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2022</a>)</cite>, Table-to-Text <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2021</a>)</cite> and Column Type &amp; Relation Classification <cite class="ltx_cite ltx_citemacro_citep">(Iida et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2021</a>; Deng et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2020</a>)</cite>. The adoption of structured data has significantly contributed to the advancement of information retrieval and knowledge extraction in web mining and content analysis <cite class="ltx_cite ltx_citemacro_citep">(Engelmann et al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2023</a>; Trabelsi et al<span class="ltx_text">.</span>, <a href="#bib.bib35" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Prompt engineering has been proven as a highly effective method for in-context learning (ICL). Recent studies, such as “chain of thoughts” (CoT) <cite class="ltx_cite ltx_citemacro_citep">(Wei et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2022</a>)</cite> and “self-consistency” <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2022</a>)</cite> or hybrid approaches using both generation and retrieval methods <cite class="ltx_cite ltx_citemacro_citep">(Aggarwal et al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2023</a>; Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib43" title="" class="ltx_ref">2023</a>)</cite> have demonstrated that LLMs, <span id="S1.p2.1.1" class="ltx_text ltx_font_italic">e.g.</span>, GPT-X <cite class="ltx_cite ltx_citemacro_citep">(Brown et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2020</a>; Ouyang et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2022</a>)</cite> and FlanT5 <cite class="ltx_cite ltx_citemacro_citep">(Chung et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2022</a>)</cite>, can solve complex mathematical reasoning tasks in both zero-shot and few-shot settings. Furthermore,
<cite class="ltx_cite ltx_citemacro_citet">Chen (<a href="#bib.bib7" title="" class="ltx_ref">2022</a>)</cite> illustrates that by using CoT with LLMs, GPT-3.5 shows impressive performance with just one-shot demonstration on several tabular tasks. These findings have opened new possibilities for the use of LLMs in structured data.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">However, previous work has not provided comprehensive studies that examined whether LLMs can truly understand tabular data or given a detailed discussion of the extent to which LLMs have already achieved structural understanding capabilities. Furthermore, despite the remarkable success of LLMs in handling natural languages, their application to tabular data modality presents unique challenges: as different tables define structure and features in distinct ways and often lack straightforward transformation into sequential text (table serialization).
Based on our survey, we believe that the process of table serialization, along with context and corresponding queries, is highly flexible. That is, there is a lack of grounded consensus or comprehensive investigation on what constitutes a common-sense or exhaustive input design for LLMs on tabular tasks. Previous work used various input designs in an ad-hoc manner <cite class="ltx_cite ltx_citemacro_citep">(Herzig et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2020</a>; Eisenschlos et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2021</a>; Chen, <a href="#bib.bib7" title="" class="ltx_ref">2022</a>; Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2021</a>; Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2022a</a>; Iida et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2021</a>; Gong et al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2020</a>)</cite>.
For example, TaPEx <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2022a</a>)</cite> uses special tokens to indicate components like headers ¡HEAD¿ and rows ¡ROW¿;
TABBIE <cite class="ltx_cite ltx_citemacro_citep">(Iida et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2021</a>)</cite> serialize tables by both row-wise and column-wise;
while TableGPT <cite class="ltx_cite ltx_citemacro_citep">(Gong et al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2020</a>)</cite> use a template-based method to serialize attribute-value pairs in each table record, <span id="S1.p3.1.1" class="ltx_text ltx_font_italic">e.g.</span>, changing “name: Elon Musk” to “name is Elon Musk.” and concatenating all the sentences according to the order of the records.
The complex landscape of varied input design further complicates the challenges faced by researchers and developers in this field. Therefore, in this paper, our aim is to address the question: <span id="S1.p3.1.2" class="ltx_text ltx_font_italic">What input designs and choices are the most effective in enabling LLMs to understand tables?</span></p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.5" class="ltx_p">In this paper, our goal is to address the chaotic landscape of input designs and determine whether LLMs can truly comprehend tabular data. We also aim to discuss the extent to which LLMs have already achieved in terms of their structural understanding capabilities.
To achieve this, we propose a benchmark called <span id="S1.p4.5.1" class="ltx_text ltx_font_italic">SUC</span> (structural understanding capabilities) to compare various input designs and create specific tasks in  §<a href="#S3" title="3. SUC Benchmark ‣ Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> that focus on each structural understanding capability of LLMs.
To assess the effectiveness of multiple input choices, we conduct a series of experiments using different prompt variants. These variants include input format, format explanation, role prompting, partition mark <cite class="ltx_cite ltx_citemacro_citep">(Dou et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2022</a>)</cite>, and zero-shot / one-shot approaches. The SUC benchmark offers a comprehensive comparison of multiple input designs, evaluating different aspects of structural understanding capabilities over table(s) as illustrated in §<a href="#S5" title="5. Experiments ‣ Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.
We then provide pragmatic guidance on how to better utilize LLM in understanding structured data in  §<a href="#S4" title="4. Structural Prompting ‣ Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. Specifically, we propose a <span id="S1.p4.5.2" class="ltx_text ltx_font_italic">model-agnostic</span> method called <span id="S1.p4.5.3" class="ltx_text ltx_font_italic">self-augmented prompting</span> to directly boost the performance of LLM in downstream tabular-based tasks. This method motivates LLMs to generate intermediate structural knowledge by internally retrieving their own knowledge, <span id="S1.p4.5.4" class="ltx_text ltx_font_italic">e.g.</span>, motivates LLMs to generate critical value / range identification by itself. These choices diverge from previous approaches like CoT and Zero-shot-CoT <cite class="ltx_cite ltx_citemacro_citep">(Kojima et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2022</a>)</cite> by focusing on identifying effective methods for unlocking LLMs’ capabilities to correctly comprehend structured information.
We find that when combined with carefully chosen input choices, these structural prompting methods lead to promising improvements in LLM performance on various tabular reasoning tasks, <span id="S1.p4.5.5" class="ltx_text ltx_font_italic">e.g.</span>, TabFact(<math id="S1.p4.1.m1.1" class="ltx_Math" alttext="\uparrow 2.31\%" display="inline"><semantics id="S1.p4.1.m1.1a"><mrow id="S1.p4.1.m1.1.1" xref="S1.p4.1.m1.1.1.cmml"><mi id="S1.p4.1.m1.1.1.2" xref="S1.p4.1.m1.1.1.2.cmml"></mi><mo stretchy="false" id="S1.p4.1.m1.1.1.1" xref="S1.p4.1.m1.1.1.1.cmml">↑</mo><mrow id="S1.p4.1.m1.1.1.3" xref="S1.p4.1.m1.1.1.3.cmml"><mn id="S1.p4.1.m1.1.1.3.2" xref="S1.p4.1.m1.1.1.3.2.cmml">2.31</mn><mo id="S1.p4.1.m1.1.1.3.1" xref="S1.p4.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.p4.1.m1.1b"><apply id="S1.p4.1.m1.1.1.cmml" xref="S1.p4.1.m1.1.1"><ci id="S1.p4.1.m1.1.1.1.cmml" xref="S1.p4.1.m1.1.1.1">↑</ci><csymbol cd="latexml" id="S1.p4.1.m1.1.1.2.cmml" xref="S1.p4.1.m1.1.1.2">absent</csymbol><apply id="S1.p4.1.m1.1.1.3.cmml" xref="S1.p4.1.m1.1.1.3"><csymbol cd="latexml" id="S1.p4.1.m1.1.1.3.1.cmml" xref="S1.p4.1.m1.1.1.3.1">percent</csymbol><cn type="float" id="S1.p4.1.m1.1.1.3.2.cmml" xref="S1.p4.1.m1.1.1.3.2">2.31</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.1.m1.1c">\uparrow 2.31\%</annotation></semantics></math>), HybridQA(<math id="S1.p4.2.m2.1" class="ltx_Math" alttext="\uparrow 2.13\%" display="inline"><semantics id="S1.p4.2.m2.1a"><mrow id="S1.p4.2.m2.1.1" xref="S1.p4.2.m2.1.1.cmml"><mi id="S1.p4.2.m2.1.1.2" xref="S1.p4.2.m2.1.1.2.cmml"></mi><mo stretchy="false" id="S1.p4.2.m2.1.1.1" xref="S1.p4.2.m2.1.1.1.cmml">↑</mo><mrow id="S1.p4.2.m2.1.1.3" xref="S1.p4.2.m2.1.1.3.cmml"><mn id="S1.p4.2.m2.1.1.3.2" xref="S1.p4.2.m2.1.1.3.2.cmml">2.13</mn><mo id="S1.p4.2.m2.1.1.3.1" xref="S1.p4.2.m2.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.p4.2.m2.1b"><apply id="S1.p4.2.m2.1.1.cmml" xref="S1.p4.2.m2.1.1"><ci id="S1.p4.2.m2.1.1.1.cmml" xref="S1.p4.2.m2.1.1.1">↑</ci><csymbol cd="latexml" id="S1.p4.2.m2.1.1.2.cmml" xref="S1.p4.2.m2.1.1.2">absent</csymbol><apply id="S1.p4.2.m2.1.1.3.cmml" xref="S1.p4.2.m2.1.1.3"><csymbol cd="latexml" id="S1.p4.2.m2.1.1.3.1.cmml" xref="S1.p4.2.m2.1.1.3.1">percent</csymbol><cn type="float" id="S1.p4.2.m2.1.1.3.2.cmml" xref="S1.p4.2.m2.1.1.3.2">2.13</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.2.m2.1c">\uparrow 2.13\%</annotation></semantics></math>), SQA(<math id="S1.p4.3.m3.1" class="ltx_Math" alttext="\uparrow 2.72\%" display="inline"><semantics id="S1.p4.3.m3.1a"><mrow id="S1.p4.3.m3.1.1" xref="S1.p4.3.m3.1.1.cmml"><mi id="S1.p4.3.m3.1.1.2" xref="S1.p4.3.m3.1.1.2.cmml"></mi><mo stretchy="false" id="S1.p4.3.m3.1.1.1" xref="S1.p4.3.m3.1.1.1.cmml">↑</mo><mrow id="S1.p4.3.m3.1.1.3" xref="S1.p4.3.m3.1.1.3.cmml"><mn id="S1.p4.3.m3.1.1.3.2" xref="S1.p4.3.m3.1.1.3.2.cmml">2.72</mn><mo id="S1.p4.3.m3.1.1.3.1" xref="S1.p4.3.m3.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.p4.3.m3.1b"><apply id="S1.p4.3.m3.1.1.cmml" xref="S1.p4.3.m3.1.1"><ci id="S1.p4.3.m3.1.1.1.cmml" xref="S1.p4.3.m3.1.1.1">↑</ci><csymbol cd="latexml" id="S1.p4.3.m3.1.1.2.cmml" xref="S1.p4.3.m3.1.1.2">absent</csymbol><apply id="S1.p4.3.m3.1.1.3.cmml" xref="S1.p4.3.m3.1.1.3"><csymbol cd="latexml" id="S1.p4.3.m3.1.1.3.1.cmml" xref="S1.p4.3.m3.1.1.3.1">percent</csymbol><cn type="float" id="S1.p4.3.m3.1.1.3.2.cmml" xref="S1.p4.3.m3.1.1.3.2">2.72</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.3.m3.1c">\uparrow 2.72\%</annotation></semantics></math>), Feverous(<math id="S1.p4.4.m4.1" class="ltx_Math" alttext="\uparrow 0.84\%" display="inline"><semantics id="S1.p4.4.m4.1a"><mrow id="S1.p4.4.m4.1.1" xref="S1.p4.4.m4.1.1.cmml"><mi id="S1.p4.4.m4.1.1.2" xref="S1.p4.4.m4.1.1.2.cmml"></mi><mo stretchy="false" id="S1.p4.4.m4.1.1.1" xref="S1.p4.4.m4.1.1.1.cmml">↑</mo><mrow id="S1.p4.4.m4.1.1.3" xref="S1.p4.4.m4.1.1.3.cmml"><mn id="S1.p4.4.m4.1.1.3.2" xref="S1.p4.4.m4.1.1.3.2.cmml">0.84</mn><mo id="S1.p4.4.m4.1.1.3.1" xref="S1.p4.4.m4.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.p4.4.m4.1b"><apply id="S1.p4.4.m4.1.1.cmml" xref="S1.p4.4.m4.1.1"><ci id="S1.p4.4.m4.1.1.1.cmml" xref="S1.p4.4.m4.1.1.1">↑</ci><csymbol cd="latexml" id="S1.p4.4.m4.1.1.2.cmml" xref="S1.p4.4.m4.1.1.2">absent</csymbol><apply id="S1.p4.4.m4.1.1.3.cmml" xref="S1.p4.4.m4.1.1.3"><csymbol cd="latexml" id="S1.p4.4.m4.1.1.3.1.cmml" xref="S1.p4.4.m4.1.1.3.1">percent</csymbol><cn type="float" id="S1.p4.4.m4.1.1.3.2.cmml" xref="S1.p4.4.m4.1.1.3.2">0.84</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.4.m4.1c">\uparrow 0.84\%</annotation></semantics></math>), and ToTTo(<math id="S1.p4.5.m5.1" class="ltx_Math" alttext="\uparrow 5.68\%" display="inline"><semantics id="S1.p4.5.m5.1a"><mrow id="S1.p4.5.m5.1.1" xref="S1.p4.5.m5.1.1.cmml"><mi id="S1.p4.5.m5.1.1.2" xref="S1.p4.5.m5.1.1.2.cmml"></mi><mo stretchy="false" id="S1.p4.5.m5.1.1.1" xref="S1.p4.5.m5.1.1.1.cmml">↑</mo><mrow id="S1.p4.5.m5.1.1.3" xref="S1.p4.5.m5.1.1.3.cmml"><mn id="S1.p4.5.m5.1.1.3.2" xref="S1.p4.5.m5.1.1.3.2.cmml">5.68</mn><mo id="S1.p4.5.m5.1.1.3.1" xref="S1.p4.5.m5.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.p4.5.m5.1b"><apply id="S1.p4.5.m5.1.1.cmml" xref="S1.p4.5.m5.1.1"><ci id="S1.p4.5.m5.1.1.1.cmml" xref="S1.p4.5.m5.1.1.1">↑</ci><csymbol cd="latexml" id="S1.p4.5.m5.1.1.2.cmml" xref="S1.p4.5.m5.1.1.2">absent</csymbol><apply id="S1.p4.5.m5.1.1.3.cmml" xref="S1.p4.5.m5.1.1.3"><csymbol cd="latexml" id="S1.p4.5.m5.1.1.3.1.cmml" xref="S1.p4.5.m5.1.1.3.1">percent</csymbol><cn type="float" id="S1.p4.5.m5.1.1.3.2.cmml" xref="S1.p4.5.m5.1.1.3.2">5.68</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.5.m5.1c">\uparrow 5.68\%</annotation></semantics></math>) compared to baseline methods. See the results in  §<a href="#S5" title="5. Experiments ‣ Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Our exploration leads us to believe that
1) LLMs have basic structural understanding capabilities but are far from perfect, even on trivial tasks, <span id="S1.p5.1.1" class="ltx_text ltx_font_italic">e.g.</span>, table size detection (detect the number of columns and rows in a table);
2) Choosing the right combination of input designs can significantly enhance LLMs’ understanding of structured data. Different combinations of serialization functions and input options demonstrate noticeable performance gaps in downstream tasks (see  §<a href="#S5" title="5. Experiments ‣ Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>). The disparity remains even when using GPT-4, validating the effectiveness of our benchmarking approach;
3) Self-augmented prompting is a simple model-agnostic method for better utilizing LLMs’ internal knowledge and unraveling new possibilities to improve their structural understanding capabilities.
In summary, we propose using markup language like <span id="S1.p5.1.2" class="ltx_text ltx_font_bold">HTML</span> with certain structural features like format explanation and partition mark, combined with self-augmented prompting, to fully leverage LLMs’ internal knowledge and achieve better results in tabular reasoning tasks.
<span id="S1.p5.1.3" class="ltx_text ltx_font_bold">Our main contributions are:</span></p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We propose the SUC benchmark to evaluate the multiple structural understanding capabilities of LLMs.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Through comprehensive experiments on the benchmark, we provide insights and guidelines on tabular input choices for future work (see  §<a href="#S5" title="5. Experiments ‣ Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>).</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We propose self-augmentation as a method to enhance the performance of LLMs by leveraging internal knowledge. We verify the effectiveness of this simple but generic method on five tabular reasoning datasets.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Preliminaries</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Table Structure</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Tabular data exhibit remarkable flexibility in diverse structures, as illustrated in <cite class="ltx_cite ltx_citemacro_citep">(Zhang and Balog, <a href="#bib.bib42" title="" class="ltx_ref">2020</a>)</cite>. These structures include relational tables, entity tables, matrix tables, layout tables, and more. Tables can have horizontal or vertical orientations and span the spectrum from flat to hierarchical. In this paper, we mainly focus on flat relational tables but also have some discussion on hierarchical tables, such as ToTTo <cite class="ltx_cite ltx_citemacro_citep">(Parikh et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2020</a>)</cite>. In these tables, each row corresponds to a distinct record, while columns represent specific fields, without any hierarchical arrangement.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Tabular data also exhibit various approaches for formatting values, including text, numbers, date/time, formulas, and other relevant information. In particular, text plays a pivotal role in tables, capturing meta-information such as headers, notes, captions, and cells within the data region. On the other hand, numbers often involve arithmetic relationships like summation and proportion, as well as statistical attributes such as distribution and trends. Furthermore, tables commonly present meticulously organized numerical data, making it easy for reference and comparison. These structured numerical values are often documented using spreadsheet formulas <cite class="ltx_cite ltx_citemacro_citep">(Dong et al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2022</a>)</cite>.
The flexibility of tabular data poses unique challenges for LLMs, as different tables define structure and formatting in distinct ways. The gap between tabular data and natural languages (NL) hinders the application of NL reasoning to facilitate table reasoning.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Table Serialization &amp; Splitting</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Table serialization refers to the process of converting data from tables into a linear, sequential text format. This adaptation is essential for training and utilizing LLMs, especially for tasks like masked language modeling, where understanding and predicting language patterns is crucial. A simple serialization function is to serialize tables row-by-row. Many works such as TaPas <cite class="ltx_cite ltx_citemacro_citep">(Herzig et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2020</a>)</cite>, MATE <cite class="ltx_cite ltx_citemacro_citep">(Eisenschlos et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2021</a>)</cite>, TableFormer <cite class="ltx_cite ltx_citemacro_citep">(Nassar et al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2022</a>)</cite>, TUTA <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2021</a>)</cite>, and TURL <cite class="ltx_cite ltx_citemacro_citep">(Deng et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2020</a>)</cite> use this method. TaPEx <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2022a</a>)</cite> uses special tokens to indicate components like headers ¡HEAD¿ and rows ¡ROW¿.
TABBIE <cite class="ltx_cite ltx_citemacro_citep">(Iida et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2021</a>)</cite> serialize tables both by row-wise and column-wise. While TableGPT <cite class="ltx_cite ltx_citemacro_citep">(Gong et al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2020</a>)</cite> use a template-based method to serialize attribute-value pairs in each table record.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">Furthermore, most LLMs are inefficient in dealing with long sentences due to the quadratic complexity of self-attention <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2017</a>; Tay et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2022</a>)</cite><span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>The maximum sequence length of text-Davinci-003 is constrained to 4k tokens.</span></span></span>. However, structured data typically contains dozens of components, which presents a significant challenge in terms of <span id="S2.SS2.p2.1.1" class="ltx_text ltx_font_italic">memory</span> and <span id="S2.SS2.p2.1.2" class="ltx_text ltx_font_italic">computational efficiency</span>. While <cite class="ltx_cite ltx_citemacro_citet">Liu et al<span class="ltx_text">.</span> (<a href="#bib.bib26" title="" class="ltx_ref">2022a</a>); Herzig et al<span class="ltx_text">.</span> (<a href="#bib.bib19" title="" class="ltx_ref">2020</a>)</cite> use naive methods to truncate the input based on a maximum sequence length, this approach may result in the loss of critical information and disrupt the structure of the entire table. In our experiments, we have predefined certain constraints to meet the LLM call request. For example, (1) to avoid potential disruption caused by truncation, we employ a random row sampling strategy when the number of tokens in the table exceeds a certain threshold, and (2) we append a 1-shot example based on the estimated remaining token capacity. Several meticulously crafted sequence serialization functions have been proposed as common practices in table serialization, including <cite class="ltx_cite ltx_citemacro_citet">Liu et al<span class="ltx_text">.</span> (<a href="#bib.bib26" title="" class="ltx_ref">2022a</a>); Herzig et al<span class="ltx_text">.</span> (<a href="#bib.bib19" title="" class="ltx_ref">2020</a>); Wang et al<span class="ltx_text">.</span> (<a href="#bib.bib38" title="" class="ltx_ref">2021</a>); Shao et al<span class="ltx_text">.</span> (<a href="#bib.bib32" title="" class="ltx_ref">2022</a>); Xie et al<span class="ltx_text">.</span> (<a href="#bib.bib40" title="" class="ltx_ref">2022</a>); Dou et al<span class="ltx_text">.</span> (<a href="#bib.bib14" title="" class="ltx_ref">2022</a>)</cite>. In this paper, we gather various commonly used serialization methods as baselines and conduct a fair comparison in Sec §<a href="#S3" title="3. SUC Benchmark ‣ Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>SUC Benchmark</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we aim to develop a benchmark for comparing different input designs and investigating the structural understanding capabilities of LLMs. Specifically, we explore the following aspects: 1) <span id="S3.p1.1.1" class="ltx_text ltx_font_italic">What input designs and choices are most effective in enabling LLMs to understand tables?</span>; 2) <span id="S3.p1.1.2" class="ltx_text ltx_font_italic">To what extent do LLMs already possess structural understanding capabilities for structured data?</span>
Additionally, we analyze the intricate trade-off of multiple combinations of input designs. Find the benchmark collection and pre-processing details in Sec §<a href="#S3.SS3" title="3.3. Data Collection and Reformatting of SUC ‣ 3. SUC Benchmark ‣ Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Structural Understanding Capabilities</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">We categorize the essential abilities to comprehend table structures from a human point of view into two distinct folds, as illustrated in Figure <a href="#S3.F1" title="Figure 1 ‣ 3.1. Structural Understanding Capabilities ‣ 3. SUC Benchmark ‣ Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2305.13062/assets/x1.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="265" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>SUC Benchmark Overview</figcaption>
</figure>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p"><span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_italic">1) Partition &amp; Parsing.</span> Tabular datasets are always paired with knowledge from other sources to provide more context and solve a specific downstream task. For example, HybridQA <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2020b</a>)</cite> employs passage information, TabFact <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2020a</a>)</cite> and FEVEROUS <cite class="ltx_cite ltx_citemacro_citep">(Aly et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2021</a>)</cite> employs human annotation, and MultiModalQA <cite class="ltx_cite ltx_citemacro_citep">(Talmor et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2021</a>)</cite> employs image information.
However, the prerequisite for tackling these downstream tasks is the accurate partitioning of the data, which in turn requires the ability to distinguish tables from other supplementary information and an elementary understanding of the structural layout of tables.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2305.13062/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="249" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>Input Designs for SUC Evaluation</figcaption>
</figure>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">Additionally, various table storage formats, including CSV, JSON, XML, markdown, HTML <cite class="ltx_cite ltx_citemacro_citep">(Aghajanyan et al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2021</a>)</cite> and XLSX, have different levels of information compression and present different challenges for LLMs in understanding the table content. For example, a table stored in CSV format is organized in rows with column values separated by commas, while a table stored in XML format is represented as a nested set of tags.
LLMs should first understand the format or layout of the table and then grasp its content. To our knowledge, no previous work has discussed the impact of these various storage formats. We aim to determine whether LLMs have the ability to correctly parse different formatting sources and identify which type of input design is most suitable for LLMs. It is also possible that LLMs already have the capability to handle all types of storage formats. The specific input designs can be found in Figure <a href="#S3.F2" title="Figure 2 ‣ 3.1. Structural Understanding Capabilities ‣ 3. SUC Benchmark ‣ Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p"><span id="S3.SS1.p4.1.1" class="ltx_text ltx_font_italic">2) Search &amp; Retrieval.</span> In addition to the capabilities mentioned above, the ability to accurately search and retrieve information from specific positions within structured data is crucial for LLMs. This capability is highly relevant to a wide range of downstream tasks, including but not limited to Table-QA and Column Type &amp; Relation Classification. It empowers LLMs to effectively identify and extract relevant information from structured data based on user queries or requests. For instance, consider a user asking, ”For the Olympic events that took place after 2014, which event had an older flag bearer?” In order to answer this query, the LLM needs to first locate all the Olympic events that satisfy the time criterion, then compare the ages of the flag bearers associated with each event, and finally determine and return the event with the oldest flag bearer. The process of locating the relevant information within the structured data is achieved through careful analysis of the data’s structure and the identification of the target cell or cells. By disentangling the search &amp; retrieval capabilities from the downstream tasks of LLMs, we gain valuable insights into the inner learning process of LLMs when it comes to tabular data.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Task Design</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">We have designed several specific tasks to assess the capabilities of LLMs in understanding tables (See concrete prompt design in Table <a href="#S3.T1" title="Table 1 ‣ Column &amp; Row Retrieval. ‣ 3.2. Task Design ‣ 3. SUC Benchmark ‣ Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). These tasks are designed in increasing difficulty.</p>
</div>
<section id="S3.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Table Partition.</h5>

<div id="S3.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p1.5" class="ltx_p">This task assesses the capability of LLMs to identify the structure of tables. The LLM is required to detect the boundaries of the tables within a given user input design. This input design may include various types of supplementary information, such as “descriptions”, “context”, “statements” and “user queries”. Formally, given an input design, <math id="S3.SS2.SSS0.Px1.p1.1.m1.3" class="ltx_Math" alttext="D={d_{1},d_{2},...}" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.1.m1.3a"><mrow id="S3.SS2.SSS0.Px1.p1.1.m1.3.3" xref="S3.SS2.SSS0.Px1.p1.1.m1.3.3.cmml"><mi id="S3.SS2.SSS0.Px1.p1.1.m1.3.3.4" xref="S3.SS2.SSS0.Px1.p1.1.m1.3.3.4.cmml">D</mi><mo id="S3.SS2.SSS0.Px1.p1.1.m1.3.3.3" xref="S3.SS2.SSS0.Px1.p1.1.m1.3.3.3.cmml">=</mo><mrow id="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2" xref="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.3.cmml"><msub id="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1" xref="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1.cmml"><mi id="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1.2" xref="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1.2.cmml">d</mi><mn id="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1.3" xref="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.3" xref="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.3.cmml">,</mo><msub id="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2" xref="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2.cmml"><mi id="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2.2" xref="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2.2.cmml">d</mi><mn id="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2.3" xref="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.4" xref="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">…</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.1.m1.3b"><apply id="S3.SS2.SSS0.Px1.p1.1.m1.3.3.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.3.3"><eq id="S3.SS2.SSS0.Px1.p1.1.m1.3.3.3.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.3.3.3"></eq><ci id="S3.SS2.SSS0.Px1.p1.1.m1.3.3.4.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.3.3.4">𝐷</ci><list id="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.3.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2"><apply id="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1.2">𝑑</ci><cn type="integer" id="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.2.2.1.1.1.3">1</cn></apply><apply id="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2.2">𝑑</ci><cn type="integer" id="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2.3.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.3.3.2.2.2.3">2</cn></apply><ci id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1">…</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.1.m1.3c">D={d_{1},d_{2},...}</annotation></semantics></math>, where each part <math id="S3.SS2.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="d_{i}" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.2.m2.1a"><msub id="S3.SS2.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.cmml"><mi id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.cmml">d</mi><mi id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.2.m2.1b"><apply id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2">𝑑</ci><ci id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.2.m2.1c">d_{i}</annotation></semantics></math> is a “versatile” sequence containing supplementary information such as description, context, statement, or user queries. For easy evaluation and comparison, we constrain LLMs to output a tuple of table boundary with the head token <math id="S3.SS2.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="b_{h}" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.3.m3.1a"><msub id="S3.SS2.SSS0.Px1.p1.3.m3.1.1" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.cmml"><mi id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2.cmml">b</mi><mi id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3.cmml">h</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.3.m3.1b"><apply id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2">𝑏</ci><ci id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3">ℎ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.3.m3.1c">b_{h}</annotation></semantics></math> and the end token <math id="S3.SS2.SSS0.Px1.p1.4.m4.1" class="ltx_Math" alttext="b_{e}" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.4.m4.1a"><msub id="S3.SS2.SSS0.Px1.p1.4.m4.1.1" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.cmml"><mi id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.2" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.2.cmml">b</mi><mi id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.3" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.3.cmml">e</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.4.m4.1b"><apply id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.2">𝑏</ci><ci id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.3">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.4.m4.1c">b_{e}</annotation></semantics></math> that includes the table content, as <math id="S3.SS2.SSS0.Px1.p1.5.m5.2" class="ltx_Math" alttext="B=(b_{h},b_{e})" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.5.m5.2a"><mrow id="S3.SS2.SSS0.Px1.p1.5.m5.2.2" xref="S3.SS2.SSS0.Px1.p1.5.m5.2.2.cmml"><mi id="S3.SS2.SSS0.Px1.p1.5.m5.2.2.4" xref="S3.SS2.SSS0.Px1.p1.5.m5.2.2.4.cmml">B</mi><mo id="S3.SS2.SSS0.Px1.p1.5.m5.2.2.3" xref="S3.SS2.SSS0.Px1.p1.5.m5.2.2.3.cmml">=</mo><mrow id="S3.SS2.SSS0.Px1.p1.5.m5.2.2.2.2" xref="S3.SS2.SSS0.Px1.p1.5.m5.2.2.2.3.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px1.p1.5.m5.2.2.2.2.3" xref="S3.SS2.SSS0.Px1.p1.5.m5.2.2.2.3.cmml">(</mo><msub id="S3.SS2.SSS0.Px1.p1.5.m5.1.1.1.1.1" xref="S3.SS2.SSS0.Px1.p1.5.m5.1.1.1.1.1.cmml"><mi id="S3.SS2.SSS0.Px1.p1.5.m5.1.1.1.1.1.2" xref="S3.SS2.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.cmml">b</mi><mi id="S3.SS2.SSS0.Px1.p1.5.m5.1.1.1.1.1.3" xref="S3.SS2.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.cmml">h</mi></msub><mo id="S3.SS2.SSS0.Px1.p1.5.m5.2.2.2.2.4" xref="S3.SS2.SSS0.Px1.p1.5.m5.2.2.2.3.cmml">,</mo><msub id="S3.SS2.SSS0.Px1.p1.5.m5.2.2.2.2.2" xref="S3.SS2.SSS0.Px1.p1.5.m5.2.2.2.2.2.cmml"><mi id="S3.SS2.SSS0.Px1.p1.5.m5.2.2.2.2.2.2" xref="S3.SS2.SSS0.Px1.p1.5.m5.2.2.2.2.2.2.cmml">b</mi><mi id="S3.SS2.SSS0.Px1.p1.5.m5.2.2.2.2.2.3" xref="S3.SS2.SSS0.Px1.p1.5.m5.2.2.2.2.2.3.cmml">e</mi></msub><mo stretchy="false" id="S3.SS2.SSS0.Px1.p1.5.m5.2.2.2.2.5" xref="S3.SS2.SSS0.Px1.p1.5.m5.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.5.m5.2b"><apply id="S3.SS2.SSS0.Px1.p1.5.m5.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.2.2"><eq id="S3.SS2.SSS0.Px1.p1.5.m5.2.2.3.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.2.2.3"></eq><ci id="S3.SS2.SSS0.Px1.p1.5.m5.2.2.4.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.2.2.4">𝐵</ci><interval closure="open" id="S3.SS2.SSS0.Px1.p1.5.m5.2.2.2.3.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.2.2.2.2"><apply id="S3.SS2.SSS0.Px1.p1.5.m5.1.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.5.m5.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.1.1.1.1.1.2">𝑏</ci><ci id="S3.SS2.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.1.1.1.1.1.3">ℎ</ci></apply><apply id="S3.SS2.SSS0.Px1.p1.5.m5.2.2.2.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.5.m5.2.2.2.2.2.1.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.2.2.2.2.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.5.m5.2.2.2.2.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.2.2.2.2.2.2">𝑏</ci><ci id="S3.SS2.SSS0.Px1.p1.5.m5.2.2.2.2.2.3.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.2.2.2.2.2.3">𝑒</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.5.m5.2c">B=(b_{h},b_{e})</annotation></semantics></math>.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Table Size Detection.</h5>

<div id="S3.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p1.3" class="ltx_p">This task is essential to reveal the LLM’s capability to correctly parse structural information. The size of a table is an important feature that is often overlooked. In fact, the table size feature represents direct constraints to how many rows and columns are encoded in a table. For instance, if a table only has three columns, the output should not consider answers outside this scope. Formally, given a table with <math id="S3.SS2.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S3.SS2.SSS0.Px2.p1.1.m1.1a"><mi id="S3.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.1.m1.1b"><ci id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.1.m1.1c">m</annotation></semantics></math> rows and <math id="S3.SS2.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS2.SSS0.Px2.p1.2.m2.1a"><mi id="S3.SS2.SSS0.Px2.p1.2.m2.1.1" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.2.m2.1b"><ci id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.2.m2.1c">n</annotation></semantics></math> columns, a correct answer from a LLM should be <math id="S3.SS2.SSS0.Px2.p1.3.m3.2" class="ltx_Math" alttext="(m,n)" display="inline"><semantics id="S3.SS2.SSS0.Px2.p1.3.m3.2a"><mrow id="S3.SS2.SSS0.Px2.p1.3.m3.2.3.2" xref="S3.SS2.SSS0.Px2.p1.3.m3.2.3.1.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px2.p1.3.m3.2.3.2.1" xref="S3.SS2.SSS0.Px2.p1.3.m3.2.3.1.cmml">(</mo><mi id="S3.SS2.SSS0.Px2.p1.3.m3.1.1" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1.cmml">m</mi><mo id="S3.SS2.SSS0.Px2.p1.3.m3.2.3.2.2" xref="S3.SS2.SSS0.Px2.p1.3.m3.2.3.1.cmml">,</mo><mi id="S3.SS2.SSS0.Px2.p1.3.m3.2.2" xref="S3.SS2.SSS0.Px2.p1.3.m3.2.2.cmml">n</mi><mo stretchy="false" id="S3.SS2.SSS0.Px2.p1.3.m3.2.3.2.3" xref="S3.SS2.SSS0.Px2.p1.3.m3.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.3.m3.2b"><interval closure="open" id="S3.SS2.SSS0.Px2.p1.3.m3.2.3.1.cmml" xref="S3.SS2.SSS0.Px2.p1.3.m3.2.3.2"><ci id="S3.SS2.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1">𝑚</ci><ci id="S3.SS2.SSS0.Px2.p1.3.m3.2.2.cmml" xref="S3.SS2.SSS0.Px2.p1.3.m3.2.2">𝑛</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.3.m3.2c">(m,n)</annotation></semantics></math>.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Merged Cell Detection.</h5>

<div id="S3.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px3.p1.1" class="ltx_p">This task assesses LLM’s capability to parse structural information by detecting merged cells. Merged cells are special structures in table construction where two or more adjacent cells are combined to create a larger cell.
To test the robustness of LLMs, we consider merged cells as a feature in hierarchical spreadsheet tables. Formally, given a table with some merged cells, the LLM is required to detect the merged cell index <math id="S3.SS2.SSS0.Px3.p1.1.m1.2" class="ltx_Math" alttext="(r_{i},c_{j})" display="inline"><semantics id="S3.SS2.SSS0.Px3.p1.1.m1.2a"><mrow id="S3.SS2.SSS0.Px3.p1.1.m1.2.2.2" xref="S3.SS2.SSS0.Px3.p1.1.m1.2.2.3.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px3.p1.1.m1.2.2.2.3" xref="S3.SS2.SSS0.Px3.p1.1.m1.2.2.3.cmml">(</mo><msub id="S3.SS2.SSS0.Px3.p1.1.m1.1.1.1.1" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.cmml"><mi id="S3.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.2" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.2.cmml">r</mi><mi id="S3.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.3" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS2.SSS0.Px3.p1.1.m1.2.2.2.4" xref="S3.SS2.SSS0.Px3.p1.1.m1.2.2.3.cmml">,</mo><msub id="S3.SS2.SSS0.Px3.p1.1.m1.2.2.2.2" xref="S3.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.cmml"><mi id="S3.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.2" xref="S3.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.2.cmml">c</mi><mi id="S3.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.3" xref="S3.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.3.cmml">j</mi></msub><mo stretchy="false" id="S3.SS2.SSS0.Px3.p1.1.m1.2.2.2.5" xref="S3.SS2.SSS0.Px3.p1.1.m1.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p1.1.m1.2b"><interval closure="open" id="S3.SS2.SSS0.Px3.p1.1.m1.2.2.3.cmml" xref="S3.SS2.SSS0.Px3.p1.1.m1.2.2.2"><apply id="S3.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.2.cmml" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.2">𝑟</ci><ci id="S3.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.3.cmml" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.cmml" xref="S3.SS2.SSS0.Px3.p1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.1.cmml" xref="S3.SS2.SSS0.Px3.p1.1.m1.2.2.2.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.2.cmml" xref="S3.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.2">𝑐</ci><ci id="S3.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.3.cmml" xref="S3.SS2.SSS0.Px3.p1.1.m1.2.2.2.2.3">𝑗</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p1.1.m1.2c">(r_{i},c_{j})</annotation></semantics></math>. Note that any index in the merged cell that matches the condition will be considered correct.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Cell Lookup &amp; Reverse Lookup.</h5>

<div id="S3.SS2.SSS0.Px4.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px4.p1.3" class="ltx_p">This task reveals the capability to search and retrieve structural information. The LLM is required to accurately search and retrieve the cell value from a specific position. This task relies on the capabilities of information partitioning and parsing. In this task, if multiple cells with the same value are found, the LLM should retrieve their positions <math id="S3.SS2.SSS0.Px4.p1.1.m1.3" class="ltx_Math" alttext="(p_{i},p_{j}),\cdots,(p_{i}^{n},p_{j}^{n})" display="inline"><semantics id="S3.SS2.SSS0.Px4.p1.1.m1.3a"><mrow id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.3.cmml"><mrow id="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.2" xref="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.3.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.2.3" xref="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.3.cmml">(</mo><msub id="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.1.1" xref="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.1.1.cmml"><mi id="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.1.1.2" xref="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.1.1.2.cmml">p</mi><mi id="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.1.1.3" xref="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.2.4" xref="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.3.cmml">,</mo><msub id="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.2.2" xref="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.2.2.cmml"><mi id="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.2.2.2" xref="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.2.2.2.cmml">p</mi><mi id="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.2.2.3" xref="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.2.2.3.cmml">j</mi></msub><mo stretchy="false" id="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.2.5" xref="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.3.cmml">)</mo></mrow><mo id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.3" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS2.SSS0.Px4.p1.1.m1.1.1" xref="S3.SS2.SSS0.Px4.p1.1.m1.1.1.cmml">⋯</mi><mo id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.4" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.3.cmml">,</mo><mrow id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.2" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.3.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.2.3" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.3.cmml">(</mo><msubsup id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.1.1" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.1.1.cmml"><mi id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.1.1.2.2" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.1.1.2.2.cmml">p</mi><mi id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.1.1.2.3" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.1.1.2.3.cmml">i</mi><mi id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.1.1.3" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.1.1.3.cmml">n</mi></msubsup><mo id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.2.4" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.3.cmml">,</mo><msubsup id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.2.2" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.2.2.cmml"><mi id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.2.2.2.2" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.2.2.2.2.cmml">p</mi><mi id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.2.2.2.3" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.2.2.2.3.cmml">j</mi><mi id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.2.2.3" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.2.2.3.cmml">n</mi></msubsup><mo stretchy="false" id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.2.5" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px4.p1.1.m1.3b"><list id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.3.cmml" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2"><interval closure="open" id="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.3.cmml" xref="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.2"><apply id="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.1.1.2.cmml" xref="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.1.1.2">𝑝</ci><ci id="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.1.1.3.cmml" xref="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.1.1.3">𝑖</ci></apply><apply id="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.2.2.cmml" xref="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.2.2.1.cmml" xref="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.2.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.2.2.2.cmml" xref="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.2.2.2">𝑝</ci><ci id="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.2.2.3.cmml" xref="S3.SS2.SSS0.Px4.p1.1.m1.2.2.1.1.2.2.3">𝑗</ci></apply></interval><ci id="S3.SS2.SSS0.Px4.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px4.p1.1.m1.1.1">⋯</ci><interval closure="open" id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.3.cmml" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.2"><apply id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.1.1.cmml" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.1.1.1.cmml" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.1.1">superscript</csymbol><apply id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.1.1.2.cmml" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.1.1.2.2.cmml" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.1.1.2.2">𝑝</ci><ci id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.1.1.2.3.cmml" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.1.1.2.3">𝑖</ci></apply><ci id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.1.1.3.cmml" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.1.1.3">𝑛</ci></apply><apply id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.2.2.1.cmml" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.2.2">superscript</csymbol><apply id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.2.2.2.cmml" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.2.2.2.1.cmml" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.2.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.2.2.2.2.cmml" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.2.2.2.2">𝑝</ci><ci id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.2.2.2.3.cmml" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.2.2.2.3">𝑗</ci></apply><ci id="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.2.2.3.cmml" xref="S3.SS2.SSS0.Px4.p1.1.m1.3.3.2.2.2.2.3">𝑛</ci></apply></interval></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px4.p1.1.m1.3c">(p_{i},p_{j}),\cdots,(p_{i}^{n},p_{j}^{n})</annotation></semantics></math>. Conversely, given a specific cell position <math id="S3.SS2.SSS0.Px4.p1.2.m2.2" class="ltx_Math" alttext="(p_{i},p_{j})" display="inline"><semantics id="S3.SS2.SSS0.Px4.p1.2.m2.2a"><mrow id="S3.SS2.SSS0.Px4.p1.2.m2.2.2.2" xref="S3.SS2.SSS0.Px4.p1.2.m2.2.2.3.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px4.p1.2.m2.2.2.2.3" xref="S3.SS2.SSS0.Px4.p1.2.m2.2.2.3.cmml">(</mo><msub id="S3.SS2.SSS0.Px4.p1.2.m2.1.1.1.1" xref="S3.SS2.SSS0.Px4.p1.2.m2.1.1.1.1.cmml"><mi id="S3.SS2.SSS0.Px4.p1.2.m2.1.1.1.1.2" xref="S3.SS2.SSS0.Px4.p1.2.m2.1.1.1.1.2.cmml">p</mi><mi id="S3.SS2.SSS0.Px4.p1.2.m2.1.1.1.1.3" xref="S3.SS2.SSS0.Px4.p1.2.m2.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS2.SSS0.Px4.p1.2.m2.2.2.2.4" xref="S3.SS2.SSS0.Px4.p1.2.m2.2.2.3.cmml">,</mo><msub id="S3.SS2.SSS0.Px4.p1.2.m2.2.2.2.2" xref="S3.SS2.SSS0.Px4.p1.2.m2.2.2.2.2.cmml"><mi id="S3.SS2.SSS0.Px4.p1.2.m2.2.2.2.2.2" xref="S3.SS2.SSS0.Px4.p1.2.m2.2.2.2.2.2.cmml">p</mi><mi id="S3.SS2.SSS0.Px4.p1.2.m2.2.2.2.2.3" xref="S3.SS2.SSS0.Px4.p1.2.m2.2.2.2.2.3.cmml">j</mi></msub><mo stretchy="false" id="S3.SS2.SSS0.Px4.p1.2.m2.2.2.2.5" xref="S3.SS2.SSS0.Px4.p1.2.m2.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px4.p1.2.m2.2b"><interval closure="open" id="S3.SS2.SSS0.Px4.p1.2.m2.2.2.3.cmml" xref="S3.SS2.SSS0.Px4.p1.2.m2.2.2.2"><apply id="S3.SS2.SSS0.Px4.p1.2.m2.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px4.p1.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px4.p1.2.m2.1.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px4.p1.2.m2.1.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px4.p1.2.m2.1.1.1.1.2.cmml" xref="S3.SS2.SSS0.Px4.p1.2.m2.1.1.1.1.2">𝑝</ci><ci id="S3.SS2.SSS0.Px4.p1.2.m2.1.1.1.1.3.cmml" xref="S3.SS2.SSS0.Px4.p1.2.m2.1.1.1.1.3">𝑖</ci></apply><apply id="S3.SS2.SSS0.Px4.p1.2.m2.2.2.2.2.cmml" xref="S3.SS2.SSS0.Px4.p1.2.m2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px4.p1.2.m2.2.2.2.2.1.cmml" xref="S3.SS2.SSS0.Px4.p1.2.m2.2.2.2.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px4.p1.2.m2.2.2.2.2.2.cmml" xref="S3.SS2.SSS0.Px4.p1.2.m2.2.2.2.2.2">𝑝</ci><ci id="S3.SS2.SSS0.Px4.p1.2.m2.2.2.2.2.3.cmml" xref="S3.SS2.SSS0.Px4.p1.2.m2.2.2.2.2.3">𝑗</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px4.p1.2.m2.2c">(p_{i},p_{j})</annotation></semantics></math>, the LLM should retrieve the corresponding cell value <math id="S3.SS2.SSS0.Px4.p1.3.m3.1" class="ltx_Math" alttext="c_{i}" display="inline"><semantics id="S3.SS2.SSS0.Px4.p1.3.m3.1a"><msub id="S3.SS2.SSS0.Px4.p1.3.m3.1.1" xref="S3.SS2.SSS0.Px4.p1.3.m3.1.1.cmml"><mi id="S3.SS2.SSS0.Px4.p1.3.m3.1.1.2" xref="S3.SS2.SSS0.Px4.p1.3.m3.1.1.2.cmml">c</mi><mi id="S3.SS2.SSS0.Px4.p1.3.m3.1.1.3" xref="S3.SS2.SSS0.Px4.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px4.p1.3.m3.1b"><apply id="S3.SS2.SSS0.Px4.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS0.Px4.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px4.p1.3.m3.1.1.1.cmml" xref="S3.SS2.SSS0.Px4.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px4.p1.3.m3.1.1.2.cmml" xref="S3.SS2.SSS0.Px4.p1.3.m3.1.1.2">𝑐</ci><ci id="S3.SS2.SSS0.Px4.p1.3.m3.1.1.3.cmml" xref="S3.SS2.SSS0.Px4.p1.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px4.p1.3.m3.1c">c_{i}</annotation></semantics></math>.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Column &amp; Row Retrieval.</h5>

<div id="S3.SS2.SSS0.Px5.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px5.p1.3" class="ltx_p">This task assesses the LLM’s capability to search and retrieve structural information by listing cell values. For column retrieval, the LLM is required to list the cell values <math id="S3.SS2.SSS0.Px5.p1.1.m1.1" class="ltx_Math" alttext="c_{j}" display="inline"><semantics id="S3.SS2.SSS0.Px5.p1.1.m1.1a"><msub id="S3.SS2.SSS0.Px5.p1.1.m1.1.1" xref="S3.SS2.SSS0.Px5.p1.1.m1.1.1.cmml"><mi id="S3.SS2.SSS0.Px5.p1.1.m1.1.1.2" xref="S3.SS2.SSS0.Px5.p1.1.m1.1.1.2.cmml">c</mi><mi id="S3.SS2.SSS0.Px5.p1.1.m1.1.1.3" xref="S3.SS2.SSS0.Px5.p1.1.m1.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px5.p1.1.m1.1b"><apply id="S3.SS2.SSS0.Px5.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px5.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px5.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS0.Px5.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px5.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS0.Px5.p1.1.m1.1.1.2">𝑐</ci><ci id="S3.SS2.SSS0.Px5.p1.1.m1.1.1.3.cmml" xref="S3.SS2.SSS0.Px5.p1.1.m1.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px5.p1.1.m1.1c">c_{j}</annotation></semantics></math>, <math id="S3.SS2.SSS0.Px5.p1.2.m2.1" class="ltx_Math" alttext="c_{j}^{n}" display="inline"><semantics id="S3.SS2.SSS0.Px5.p1.2.m2.1a"><msubsup id="S3.SS2.SSS0.Px5.p1.2.m2.1.1" xref="S3.SS2.SSS0.Px5.p1.2.m2.1.1.cmml"><mi id="S3.SS2.SSS0.Px5.p1.2.m2.1.1.2.2" xref="S3.SS2.SSS0.Px5.p1.2.m2.1.1.2.2.cmml">c</mi><mi id="S3.SS2.SSS0.Px5.p1.2.m2.1.1.2.3" xref="S3.SS2.SSS0.Px5.p1.2.m2.1.1.2.3.cmml">j</mi><mi id="S3.SS2.SSS0.Px5.p1.2.m2.1.1.3" xref="S3.SS2.SSS0.Px5.p1.2.m2.1.1.3.cmml">n</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px5.p1.2.m2.1b"><apply id="S3.SS2.SSS0.Px5.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px5.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px5.p1.2.m2.1.1.1.cmml" xref="S3.SS2.SSS0.Px5.p1.2.m2.1.1">superscript</csymbol><apply id="S3.SS2.SSS0.Px5.p1.2.m2.1.1.2.cmml" xref="S3.SS2.SSS0.Px5.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px5.p1.2.m2.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px5.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px5.p1.2.m2.1.1.2.2.cmml" xref="S3.SS2.SSS0.Px5.p1.2.m2.1.1.2.2">𝑐</ci><ci id="S3.SS2.SSS0.Px5.p1.2.m2.1.1.2.3.cmml" xref="S3.SS2.SSS0.Px5.p1.2.m2.1.1.2.3">𝑗</ci></apply><ci id="S3.SS2.SSS0.Px5.p1.2.m2.1.1.3.cmml" xref="S3.SS2.SSS0.Px5.p1.2.m2.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px5.p1.2.m2.1c">c_{j}^{n}</annotation></semantics></math> of a specific column name <math id="S3.SS2.SSS0.Px5.p1.3.m3.1" class="ltx_Math" alttext="C_{i}" display="inline"><semantics id="S3.SS2.SSS0.Px5.p1.3.m3.1a"><msub id="S3.SS2.SSS0.Px5.p1.3.m3.1.1" xref="S3.SS2.SSS0.Px5.p1.3.m3.1.1.cmml"><mi id="S3.SS2.SSS0.Px5.p1.3.m3.1.1.2" xref="S3.SS2.SSS0.Px5.p1.3.m3.1.1.2.cmml">C</mi><mi id="S3.SS2.SSS0.Px5.p1.3.m3.1.1.3" xref="S3.SS2.SSS0.Px5.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px5.p1.3.m3.1b"><apply id="S3.SS2.SSS0.Px5.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS0.Px5.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px5.p1.3.m3.1.1.1.cmml" xref="S3.SS2.SSS0.Px5.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px5.p1.3.m3.1.1.2.cmml" xref="S3.SS2.SSS0.Px5.p1.3.m3.1.1.2">𝐶</ci><ci id="S3.SS2.SSS0.Px5.p1.3.m3.1.1.3.cmml" xref="S3.SS2.SSS0.Px5.p1.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px5.p1.3.m3.1c">C_{i}</annotation></semantics></math> from the given table. Similarly, for row retrieval, the LLM should list the cell values of a specific row index. In the evaluation process, we consider the prediction to be correct if the predicted value list matches the ground truth value list. We expect the performance of column/row retrieval tasks to be better than that of cell lookup and reverse lookup tasks, as using column/row indices to locate specific value lists is more common.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1. </span>Input design of each task in our benchmark</figcaption>
<div id="S3.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:365.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(50.4pt,-42.5pt) scale(1.30261643847735,1.30261643847735) ;">
<table id="S3.T1.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T1.1.1.1" class="ltx_tr">
<td id="S3.T1.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T1.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.1.1.1.1" class="ltx_p" style="width:71.1pt;"><span id="S3.T1.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Task</span></span>
</span>
</td>
<td id="S3.T1.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T1.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.1.2.1.1" class="ltx_p" style="width:234.5pt;"><span id="S3.T1.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Input</span></span>
</span>
</td>
</tr>
<tr id="S3.T1.1.1.2" class="ltx_tr">
<td id="S3.T1.1.1.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.2.1.1.1" class="ltx_p" style="width:71.1pt;">Table Partition</span>
</span>
</td>
<td id="S3.T1.1.1.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.2.2.1.1" class="ltx_p" style="width:234.5pt;">What is the first token (cell value instead of separator —) of the given table? What is the end token (cell value instead of separator —) of the given table? Answer questions one by one and use — to split the answer.</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.1.3" class="ltx_tr">
<td id="S3.T1.1.1.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.3.1.1.1" class="ltx_p" style="width:71.1pt;">Cell Lookup</span>
</span>
</td>
<td id="S3.T1.1.1.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.3.2.1.1" class="ltx_p" style="width:234.5pt;">What is the position of the cell value cell_value? Use row index and column index to answer</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.1.4" class="ltx_tr">
<td id="S3.T1.1.1.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.4.1.1.1" class="ltx_p" style="width:71.1pt;">Reverse Lookup</span>
</span>
</td>
<td id="S3.T1.1.1.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.4.2.1.1" class="ltx_p" style="width:234.5pt;">What is the cell value of row index, column index ? Only output the cell value without other information</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.1.5" class="ltx_tr">
<td id="S3.T1.1.1.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.5.1.1.1" class="ltx_p" style="width:71.1pt;">Column Retrieval</span>
</span>
</td>
<td id="S3.T1.1.1.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.5.2.1.1" class="ltx_p" style="width:234.5pt;">What is the column name with the index column_idx of the following table? Only give the column name without any explanation</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.1.6" class="ltx_tr">
<td id="S3.T1.1.1.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.6.1.1.1" class="ltx_p" style="width:71.1pt;">Row Retrieval</span>
</span>
</td>
<td id="S3.T1.1.1.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.6.2.1.1" class="ltx_p" style="width:234.5pt;">What are the cell values of the row_idx row in following table? Only list the cell values one by one using — to split the answers</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.1.7" class="ltx_tr">
<td id="S3.T1.1.1.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.7.1.1.1" class="ltx_p" style="width:71.1pt;">Size Detection</span>
</span>
</td>
<td id="S3.T1.1.1.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.1.1.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.7.2.1.1" class="ltx_p" style="width:234.5pt;">How many rows in the table? How many columns in the table. Answer the questions one by one and use — to split the answer</span>
</span>
</td>
</tr>
<tr id="S3.T1.1.1.8" class="ltx_tr">
<td id="S3.T1.1.1.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T1.1.1.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.8.1.1.1" class="ltx_p" style="width:71.1pt;">Merged Cell Detection</span>
</span>
</td>
<td id="S3.T1.1.1.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T1.1.1.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.8.2.1.1" class="ltx_p" style="width:234.5pt;">What is the column index of the cell which span is over 1. use — to split the answer (e.g., 3 — 4), the column index starts from 0. If there’s no answer, return None</span>
</span>
</td>
</tr>
</table>
</span></div>
</figure>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Data Collection and Reformatting of SUC</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">We collect structured data from various public datasets, <span id="S3.SS3.p1.1.1" class="ltx_text ltx_font_italic">e.g.</span>, TabFact <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2020a</a>)</cite>, FEVEROUS <cite class="ltx_cite ltx_citemacro_citep">(Aly et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2021</a>)</cite>, SQA <cite class="ltx_cite ltx_citemacro_citep">(Iyyer et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2017</a>)</cite>, HybridQA <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2020b</a>)</cite> and ToTTo <cite class="ltx_cite ltx_citemacro_citep">(Parikh et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2020</a>)</cite>. All the tables are from Wikipedia. We only consider the structural portions of the original datasets, which are labeled with ”table,” ”rows,” or ”headers,” and exclude the other parts like ”ID,” ”Answer,” ”Question,” ”FileName,”. To identify a specific value within the structured data, we append each parsed sample with a unique question. Most of these questions are one sentence long, with a median length of 15 words. For example, “How many rows (columns) are in the table?” Each question is accompanied by a set of reference answers (“groundtruth”) sourced from the original datasets. For better evaluation, most of these questions are paired with some constraints such as ”Answer the questions one by one and use ”—” to split the answer.”. We evaluate these questions using GPT-3.5 (Text-Davinci-003)<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>We perform the experiments through the public playground of OpenAI GPT-3.5 in <a target="_blank" href="https://beta.openai.com/playground/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://beta.openai.com/playground/</a>.</span></span></span> and manually eliminate any question that the model consistently answers correctly when multiple random samples are generated at a nonzero temperature<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>Temperature controls the randomness of the generation process. As the temperature approaches zero, the model becomes more deterministic and repetitive with very limited variation. Here, we set the temperature to 0.7 when creating the question and set the temperature to 0 when performing other experiments</span></span></span>. For the merged cell detection task, we only sample from ToTTo dataset since this is the only source paired with the merged cell. For each task setting, we randomly sample 1,500 tables for testing with a guaranteed table distribution.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p"><span id="S3.SS3.p2.1.1" class="ltx_text ltx_font_italic">One-shot Setting.</span> The SUC benchmark is designed as a one-shot in-context learning benchmark for tabular tasks. This means that the model can access one example from the SUC and may gain some context when generating the answers. Large Language Models (LLMs) have shown impressive capability in following few-shot prompts to accomplish unseen tasks without any fine-tuning <cite class="ltx_cite ltx_citemacro_citep">(Lin et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2022</a>)</cite>. This emergent capability is not captured by small language models. SUC leverages this property to better reveal the potential capabilities that LLMs may lack. We also conduct experiments using the zero-shot setting for comparison (See Table <a href="#S4.T3" title="Table 3 ‣ 4. Structural Prompting ‣ Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>).</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2305.13062/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="147" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span>Illustration of self-augmented prompting. This process consists of two phases: 1) using self-augmented prompts to ask the LLM to generate additional knowledge (intermediate output) about the table; 2) incorporating the self-augmented response into the second prompt to request the final answer for a downstream task. As depicted in the figure, the LLM is able to identify important values in the table, which assists in generating a more accurate answer for the downstream task.</figcaption>
</figure>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4. </span>Evaluation</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">We evaluate the benchmark using common input designs for table reasoning tasks and apply the methods to different LLMs for a deeper analysis. Specifically, we consider CSV, JSON, XML, markdown, HTML <cite class="ltx_cite ltx_citemacro_citep">(Aghajanyan et al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2021</a>)</cite>, and XLSX as different format options. Each format represents a different level of information compression and poses different challenges for LLMs to understand the table content. we also consider using the most common way of concatenating a special token <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2020</a>; Xie et al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2022</a>)</cite> as a separator, such as ”—”, as the baseline. The comparison numbers can be found in Table <a href="#S4.T2" title="Table 2 ‣ 4. Structural Prompting ‣ Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
We also explore other input design options, such as grammar explanation, partition mark <cite class="ltx_cite ltx_citemacro_citep">(Dou et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2022</a>)</cite>, role prompting <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2022a</a>)</cite>, and format explanation, as augmentations for input designs. More details can be found in Figure <a href="#S3.F2" title="Figure 2 ‣ 3.1. Structural Understanding Capabilities ‣ 3. SUC Benchmark ‣ Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and Table <a href="#S4.T3" title="Table 3 ‣ 4. Structural Prompting ‣ Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
In particular, we consider using the <span id="S3.SS4.p1.1.1" class="ltx_text ltx_font_italic">accuracy</span> for each task’s evaluation.
To ensure better evaluation, we have added some constraints to the output format. For example, in the table partition task, we include the instruction ”Answer questions one by one and use ’—’ to split the answer.” Based on empirical observations, over 90% of the answers follow these specific format instructions. For the remaining 10% of samples, we apply a semantic-parsing strategy using regular expressions (Re) <span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a target="_blank" href="https://docs.python.org/3/library/re.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://docs.python.org/3/library/re.html</a></span></span></span> to parse the answers.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Structural Prompting</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Our findings and insights over the SUC comparisons (See Sec §<a href="#S5" title="5. Experiments ‣ Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>) have led us to the discovery that 1) LLMs have the basic structural understanding capabilities but are far from perfect, even on some trivial tasks, <span id="S4.p1.1.1" class="ltx_text ltx_font_italic">e.g.</span>, table size detection; 2) Correctly choosing the combination of input designs is a potential factor in boosting LLMs understanding over tabular data. In this section, we propose a simple and generic method, <span id="S4.p1.1.2" class="ltx_text ltx_font_bold">self-augmented prompting</span>, to generate additional constraints using LLMs’ self-knowledge. We find that when combined with carefully chosen input choices, these structural prompting methods lead to promising improvements on a variety of tabular downstream tasks (See Table <a href="#S5.T4" title="Table 4 ‣ 5.2.1. Benchmark Highlights ‣ 5.2. Results ‣ 5. Experiments ‣ Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>).</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">Recently, CoT <cite class="ltx_cite ltx_citemacro_citep">(Wei et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2022</a>)</cite> has been discovered to empower LLMs to perform complex reasoning over text and lead to a long line of work <cite class="ltx_cite ltx_citemacro_citep">(Kojima et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2022</a>; Cobbe et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2021</a>; Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2022</a>; Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2022b</a>)</cite>. By providing the model with several exemplars of reasoning chains, LLMs can learn to follow the template to solve difficult unseen tasks. Inspired by these works, we propose a simple, generic, and effective method, <span id="S4.p2.1.1" class="ltx_text ltx_font_italic">self-augmented prompting</span>, to generate intermediate structural knowledge based on the internal retrieving of LLMs’ self knowledge base. We design several ways to squeeze knowledge from LLM (see Table <a href="#S5.T4" title="Table 4 ‣ 5.2.1. Benchmark Highlights ‣ 5.2. Results ‣ 5. Experiments ‣ Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>). For example, we ask LLM to generate the format specification, which intends to clarify the input format pattern by LLM itself.
These choices diverge from previous approaches like CoT and Zero-shot-CoT <cite class="ltx_cite ltx_citemacro_citep">(Kojima et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2022</a>)</cite> by focusing on identifying effective methods for unlocking LLMs’ capabilities to correctly comprehend structured information. Additionally, this method is <span id="S4.p2.1.2" class="ltx_text ltx_font_italic">model-agnostic</span>, that is, any standard structural data reasoning tasks can be used as the backbone, and can also be integrated with other prompting-based methods like self-consistency <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">Formally, self-augmented prompting is a simple idea that utilizes prompting twice to leverage the capabilities of LLMs in understanding structured data, as shown in Figure <a href="#S3.F3" title="Figure 3 ‣ 3.3. Data Collection and Reformatting of SUC ‣ 3. SUC Benchmark ‣ Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. In the first prompt, the original task of “requesting” information is replaced with a simple demand to “Identify critical values and ranges of the last table related to the statement”. Each demand represents an important aspect of structural information. The purpose of this replacement is to unlock the reasoning abilities of LLMs for complex reasoning over structured data. The prompted text is then fed into the LLM model, which generates a subsequent sentence containing specific structural information. In the second prompt, the generated subsequent sequence is appended to the task request and fed into the LLM model to generate the final answer. Refer to Table <a href="#S5.T4" title="Table 4 ‣ 5.2.1. Benchmark Highlights ‣ 5.2. Results ‣ 5. Experiments ‣ Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> for a comparison of the experiment results using self-augmented prompting.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2. </span>Micro results of the benchmark. Change order <cite class="ltx_cite ltx_citemacro_citep">(Xie et al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2022</a>)</cite> refers to put external text (like questions, statement) ahead of tables. Noted that ”GPT-4” refers to the evaluation outcomes utilizing the GPT-4 model. Given the resource-intensive nature of GPT-4 calls, we only conducting the GPT-4 inference test on a subset of 300 samples (randomly sampled) from each task set. Each column follows the roles of graded color scale, <span id="S4.T2.2.1" class="ltx_text ltx_font_italic">i.e.</span>, the deeper color refers to better perf.</figcaption>
<div id="S4.T2.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:81.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-117.5pt,22.1pt) scale(0.648510091690527,0.648510091690527) ;">
<table id="S4.T2.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.3.1.1" class="ltx_tr">
<td id="S4.T2.3.1.1.1" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T2.3.1.1.1.1" class="ltx_text">Format</span></td>
<td id="S4.T2.3.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">Table Partition</td>
<td id="S4.T2.3.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">Cell Lookup</td>
<td id="S4.T2.3.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">Reverse Lookup</td>
<td id="S4.T2.3.1.1.5" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">Column Retrieval</td>
<td id="S4.T2.3.1.1.6" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">Row Retrieval</td>
<td id="S4.T2.3.1.1.7" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">Size Detection</td>
<td id="S4.T2.3.1.1.8" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">Merged Cell Detection</td>
</tr>
<tr id="S4.T2.3.1.2" class="ltx_tr">
<td id="S4.T2.3.1.2.1" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S4.T2.3.1.2.2" class="ltx_td ltx_align_center ltx_border_t">GPT-4</td>
<td id="S4.T2.3.1.2.3" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S4.T2.3.1.2.4" class="ltx_td ltx_align_center ltx_border_t">GPT-4</td>
<td id="S4.T2.3.1.2.5" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S4.T2.3.1.2.6" class="ltx_td ltx_align_center ltx_border_t">GPT-4</td>
<td id="S4.T2.3.1.2.7" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S4.T2.3.1.2.8" class="ltx_td ltx_align_center ltx_border_t">GPT-4</td>
<td id="S4.T2.3.1.2.9" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S4.T2.3.1.2.10" class="ltx_td ltx_align_center ltx_border_t">GPT-4</td>
<td id="S4.T2.3.1.2.11" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S4.T2.3.1.2.12" class="ltx_td ltx_align_center ltx_border_t">GPT-4</td>
<td id="S4.T2.3.1.2.13" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S4.T2.3.1.2.14" class="ltx_td ltx_align_center ltx_border_t">GPT-4</td>
</tr>
<tr id="S4.T2.3.1.3" class="ltx_tr">
<td id="S4.T2.3.1.3.1" class="ltx_td ltx_align_left ltx_border_t">NL + Sep</td>
<td id="S4.T2.3.1.3.2" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="S4.T2.3.1.3.2.1" class="ltx_text" style="background-color:#FCFCFF;">93.00%</span></td>
<td id="S4.T2.3.1.3.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="S4.T2.3.1.3.3.1" class="ltx_text" style="background-color:#FCFCFF;">96.78%</span></td>
<td id="S4.T2.3.1.3.4" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="S4.T2.3.1.3.4.1" class="ltx_text" style="background-color:#FCFCFF;">39.67%</span></td>
<td id="S4.T2.3.1.3.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#DCECF9;"><span id="S4.T2.3.1.3.5.1" class="ltx_text" style="background-color:#DCECF9;">72.48%</span></td>
<td id="S4.T2.3.1.3.6" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#DBEFE3;"><span id="S4.T2.3.1.3.6.1" class="ltx_text" style="background-color:#DBEFE3;">52.00%</span></td>
<td id="S4.T2.3.1.3.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F3F8FE;"><span id="S4.T2.3.1.3.7.1" class="ltx_text" style="background-color:#F3F8FE;">59.12%</span></td>
<td id="S4.T2.3.1.3.8" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#81CA95;"><span id="S4.T2.3.1.3.8.1" class="ltx_text" style="background-color:#81CA95;">60.67%</span></td>
<td id="S4.T2.3.1.3.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#EBF4FC;"><span id="S4.T2.3.1.3.9.1" class="ltx_text" style="background-color:#EBF4FC;">66.32%</span></td>
<td id="S4.T2.3.1.3.10" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="S4.T2.3.1.3.10.1" class="ltx_text" style="background-color:#FCFCFF;">31.00%</span></td>
<td id="S4.T2.3.1.3.11" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="S4.T2.3.1.3.11.1" class="ltx_text" style="background-color:#FCFCFF;">48.67%</span></td>
<td id="S4.T2.3.1.3.12" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="S4.T2.3.1.3.12.1" class="ltx_text" style="background-color:#FCFCFF;">42.00%</span></td>
<td id="S4.T2.3.1.3.13" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="S4.T2.3.1.3.13.1" class="ltx_text" style="background-color:#FCFCFF;">73.12%</span></td>
<td id="S4.T2.3.1.3.14" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="S4.T2.3.1.3.14.1" class="ltx_text" style="background-color:#FCFCFF;">71.33%</span></td>
<td id="S4.T2.3.1.3.15" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="S4.T2.3.1.3.15.1" class="ltx_text" style="background-color:#FCFCFF;">74.98%</span></td>
</tr>
<tr id="S4.T2.3.1.4" class="ltx_tr">
<td id="S4.T2.3.1.4.1" class="ltx_td ltx_align_left">Markdown</td>
<td id="S4.T2.3.1.4.2" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S4.T2.3.1.4.2.1" class="ltx_text" style="background-color:#FCFCFF;">92.33%</span></td>
<td id="S4.T2.3.1.4.3" class="ltx_td ltx_align_center" style="background-color:#CBE3F5;"><span id="S4.T2.3.1.4.3.1" class="ltx_text ltx_font_bold" style="background-color:#CBE3F5;">98.32%</span></td>
<td id="S4.T2.3.1.4.4" class="ltx_td ltx_align_center" style="background-color:#93D2A4;"><span id="S4.T2.3.1.4.4.1" class="ltx_text" style="background-color:#93D2A4;">43.33%</span></td>
<td id="S4.T2.3.1.4.5" class="ltx_td ltx_align_center" style="background-color:#E7F2FB;"><span id="S4.T2.3.1.4.5.1" class="ltx_text" style="background-color:#E7F2FB;">71.93%</span></td>
<td id="S4.T2.3.1.4.6" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S4.T2.3.1.4.6.1" class="ltx_text" style="background-color:#FCFCFF;">51.00%</span></td>
<td id="S4.T2.3.1.4.7" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S4.T2.3.1.4.7.1" class="ltx_text" style="background-color:#FCFCFF;">57.32%</span></td>
<td id="S4.T2.3.1.4.8" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S4.T2.3.1.4.8.1" class="ltx_text" style="background-color:#FCFCFF;">35.33%</span></td>
<td id="S4.T2.3.1.4.9" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S4.T2.3.1.4.9.1" class="ltx_text" style="background-color:#FCFCFF;">60.12%</span></td>
<td id="S4.T2.3.1.4.10" class="ltx_td ltx_align_center" style="background-color:#63BE7B;"><span id="S4.T2.3.1.4.10.1" class="ltx_text ltx_font_bold" style="background-color:#63BE7B;">42.33%</span></td>
<td id="S4.T2.3.1.4.11" class="ltx_td ltx_align_center" style="background-color:#DAEBF9;"><span id="S4.T2.3.1.4.11.1" class="ltx_text" style="background-color:#DAEBF9;">49.98%</span></td>
<td id="S4.T2.3.1.4.12" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S4.T2.3.1.4.12.1" class="ltx_text" style="background-color:#FCFCFF;">40.67%</span></td>
<td id="S4.T2.3.1.4.13" class="ltx_td ltx_align_center" style="background-color:#D8EAF8;"><span id="S4.T2.3.1.4.13.1" class="ltx_text" style="background-color:#D8EAF8;">82.12%</span></td>
<td id="S4.T2.3.1.4.14" class="ltx_td ltx_align_center" style="background-color:#63BE7B;"><span id="S4.T2.3.1.4.14.1" class="ltx_text ltx_font_bold" style="background-color:#63BE7B;">78.00%</span></td>
<td id="S4.T2.3.1.4.15" class="ltx_td ltx_align_center" style="background-color:#CBE3F5;"><span id="S4.T2.3.1.4.15.1" class="ltx_text ltx_font_bold" style="background-color:#CBE3F5;">82.64%</span></td>
</tr>
<tr id="S4.T2.3.1.5" class="ltx_tr">
<td id="S4.T2.3.1.5.1" class="ltx_td ltx_align_left">JSON</td>
<td id="S4.T2.3.1.5.2" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S4.T2.3.1.5.2.1" class="ltx_text" style="background-color:#FCFCFF;">94.00%</span></td>
<td id="S4.T2.3.1.5.3" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S4.T2.3.1.5.3.1" class="ltx_text" style="background-color:#FCFCFF;">97.12%</span></td>
<td id="S4.T2.3.1.5.4" class="ltx_td ltx_align_center" style="background-color:#C2E5CD;"><span id="S4.T2.3.1.5.4.1" class="ltx_text" style="background-color:#C2E5CD;">42.67%</span></td>
<td id="S4.T2.3.1.5.5" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S4.T2.3.1.5.5.1" class="ltx_text" style="background-color:#FCFCFF;">68.32%</span></td>
<td id="S4.T2.3.1.5.6" class="ltx_td ltx_align_center" style="background-color:#7EC992;"><span id="S4.T2.3.1.5.6.1" class="ltx_text" style="background-color:#7EC992;">54.33%</span></td>
<td id="S4.T2.3.1.5.7" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S4.T2.3.1.5.7.1" class="ltx_text" style="background-color:#FCFCFF;">58.12%</span></td>
<td id="S4.T2.3.1.5.8" class="ltx_td ltx_align_center" style="background-color:#C6E6D0;"><span id="S4.T2.3.1.5.8.1" class="ltx_text" style="background-color:#C6E6D0;">54.33%</span></td>
<td id="S4.T2.3.1.5.9" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S4.T2.3.1.5.9.1" class="ltx_text" style="background-color:#FCFCFF;">64.32%</span></td>
<td id="S4.T2.3.1.5.10" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S4.T2.3.1.5.10.1" class="ltx_text" style="background-color:#FCFCFF;">29.00%</span></td>
<td id="S4.T2.3.1.5.11" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S4.T2.3.1.5.11.1" class="ltx_text" style="background-color:#FCFCFF;">48.32%</span></td>
<td id="S4.T2.3.1.5.12" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S4.T2.3.1.5.12.1" class="ltx_text" style="background-color:#FCFCFF;">42.67%</span></td>
<td id="S4.T2.3.1.5.13" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S4.T2.3.1.5.13.1" class="ltx_text" style="background-color:#FCFCFF;">76.43%</span></td>
<td id="S4.T2.3.1.5.14" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S4.T2.3.1.5.14.1" class="ltx_text" style="background-color:#FCFCFF;">73.33%</span></td>
<td id="S4.T2.3.1.5.15" class="ltx_td ltx_align_center" style="background-color:#FAFBFF;"><span id="S4.T2.3.1.5.15.1" class="ltx_text" style="background-color:#FAFBFF;">78.98%</span></td>
</tr>
<tr id="S4.T2.3.1.6" class="ltx_tr">
<td id="S4.T2.3.1.6.1" class="ltx_td ltx_align_left">XML</td>
<td id="S4.T2.3.1.6.2" class="ltx_td ltx_align_center" style="background-color:#93D2A4;"><span id="S4.T2.3.1.6.2.1" class="ltx_text" style="background-color:#93D2A4;">96.00%</span></td>
<td id="S4.T2.3.1.6.3" class="ltx_td ltx_align_center" style="background-color:#F7FAFE;"><span id="S4.T2.3.1.6.3.1" class="ltx_text" style="background-color:#F7FAFE;">97.64%</span></td>
<td id="S4.T2.3.1.6.4" class="ltx_td ltx_align_center" style="background-color:#93D2A4;"><span id="S4.T2.3.1.6.4.1" class="ltx_text" style="background-color:#93D2A4;">43.33%</span></td>
<td id="S4.T2.3.1.6.5" class="ltx_td ltx_align_center" style="background-color:#E0EEFA;"><span id="S4.T2.3.1.6.5.1" class="ltx_text" style="background-color:#E0EEFA;">72.28%</span></td>
<td id="S4.T2.3.1.6.6" class="ltx_td ltx_align_center" style="background-color:#63BE7B;"><span id="S4.T2.3.1.6.6.1" class="ltx_text ltx_font_bold" style="background-color:#63BE7B;">55.00%</span></td>
<td id="S4.T2.3.1.6.7" class="ltx_td ltx_align_center" style="background-color:#CBE3F5;"><span id="S4.T2.3.1.6.7.1" class="ltx_text ltx_font_bold" style="background-color:#CBE3F5;">60.32%</span></td>
<td id="S4.T2.3.1.6.8" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S4.T2.3.1.6.8.1" class="ltx_text" style="background-color:#FCFCFF;">41.33%</span></td>
<td id="S4.T2.3.1.6.9" class="ltx_td ltx_align_center" style="background-color:#D7E9F8;"><span id="S4.T2.3.1.6.9.1" class="ltx_text" style="background-color:#D7E9F8;">68.28%</span></td>
<td id="S4.T2.3.1.6.10" class="ltx_td ltx_align_center" style="background-color:#82CB96;"><span id="S4.T2.3.1.6.10.1" class="ltx_text" style="background-color:#82CB96;">41.00%</span></td>
<td id="S4.T2.3.1.6.11" class="ltx_td ltx_align_center" style="background-color:#CBE3F5;"><span id="S4.T2.3.1.6.11.1" class="ltx_text ltx_font_bold" style="background-color:#CBE3F5;">50.28%</span></td>
<td id="S4.T2.3.1.6.12" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S4.T2.3.1.6.12.1" class="ltx_text" style="background-color:#FCFCFF;">43.67%</span></td>
<td id="S4.T2.3.1.6.13" class="ltx_td ltx_align_center" style="background-color:#EAF3FC;"><span id="S4.T2.3.1.6.13.1" class="ltx_text" style="background-color:#EAF3FC;">80.21%</span></td>
<td id="S4.T2.3.1.6.14" class="ltx_td ltx_align_center" style="background-color:#EDF6F2;"><span id="S4.T2.3.1.6.14.1" class="ltx_text" style="background-color:#EDF6F2;">75.00%</span></td>
<td id="S4.T2.3.1.6.15" class="ltx_td ltx_align_center" style="background-color:#E9F3FC;"><span id="S4.T2.3.1.6.15.1" class="ltx_text" style="background-color:#E9F3FC;">80.32%</span></td>
</tr>
<tr id="S4.T2.3.1.7" class="ltx_tr">
<td id="S4.T2.3.1.7.1" class="ltx_td ltx_align_left ltx_border_bb">HTML</td>
<td id="S4.T2.3.1.7.2" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#63BE7B;"><span id="S4.T2.3.1.7.2.1" class="ltx_text ltx_font_bold" style="background-color:#63BE7B;">96.67%</span></td>
<td id="S4.T2.3.1.7.3" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#CBE3F5;"><span id="S4.T2.3.1.7.3.1" class="ltx_text ltx_font_bold" style="background-color:#CBE3F5;">98.32%</span></td>
<td id="S4.T2.3.1.7.4" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#63BE7B;"><span id="S4.T2.3.1.7.4.1" class="ltx_text ltx_font_bold" style="background-color:#63BE7B;">44.00%</span></td>
<td id="S4.T2.3.1.7.5" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#CBE3F5;"><span id="S4.T2.3.1.7.5.1" class="ltx_text ltx_font_bold" style="background-color:#CBE3F5;">73.34%</span></td>
<td id="S4.T2.3.1.7.6" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#FCFCFF;"><span id="S4.T2.3.1.7.6.1" class="ltx_text" style="background-color:#FCFCFF;">47.33%</span></td>
<td id="S4.T2.3.1.7.7" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#E8F2FB;"><span id="S4.T2.3.1.7.7.1" class="ltx_text" style="background-color:#E8F2FB;">59.45%</span></td>
<td id="S4.T2.3.1.7.8" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#63BE7B;"><span id="S4.T2.3.1.7.8.1" class="ltx_text ltx_font_bold" style="background-color:#63BE7B;">63.33%</span></td>
<td id="S4.T2.3.1.7.9" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#CBE3F5;"><span id="S4.T2.3.1.7.9.1" class="ltx_text ltx_font_bold" style="background-color:#CBE3F5;">69.32%</span></td>
<td id="S4.T2.3.1.7.10" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#6BC282;"><span id="S4.T2.3.1.7.10.1" class="ltx_text" style="background-color:#6BC282;">42.00%</span></td>
<td id="S4.T2.3.1.7.11" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#D0E6F6;"><span id="S4.T2.3.1.7.11.1" class="ltx_text" style="background-color:#D0E6F6;">50.19%</span></td>
<td id="S4.T2.3.1.7.12" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#63BE7B;"><span id="S4.T2.3.1.7.12.1" class="ltx_text ltx_font_bold" style="background-color:#63BE7B;">67.00%</span></td>
<td id="S4.T2.3.1.7.13" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#CBE3F5;"><span id="S4.T2.3.1.7.13.1" class="ltx_text ltx_font_bold" style="background-color:#CBE3F5;">83.43%</span></td>
<td id="S4.T2.3.1.7.14" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#A1D7B0;"><span id="S4.T2.3.1.7.14.1" class="ltx_text" style="background-color:#A1D7B0;">76.67%</span></td>
<td id="S4.T2.3.1.7.15" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#DDECF9;"><span id="S4.T2.3.1.7.15.1" class="ltx_text" style="background-color:#DDECF9;">81.28%</span></td>
</tr>
</table>
</span></div>
</figure>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3. </span>Micro ablation results of the input designs over benchmark.</figcaption>
<div id="S4.T3.7" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:93.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-159.6pt,34.3pt) scale(0.576004126482494,0.576004126482494) ;">
<table id="S4.T3.7.7" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.7.7.8" class="ltx_tr">
<td id="S4.T3.7.7.8.1" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T3.7.7.8.1.1" class="ltx_text">Input Design</span></td>
<td id="S4.T3.7.7.8.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">Table Partition</td>
<td id="S4.T3.7.7.8.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">Cell Lookup</td>
<td id="S4.T3.7.7.8.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">Reverse Lookup</td>
<td id="S4.T3.7.7.8.5" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">Column Retrieval</td>
<td id="S4.T3.7.7.8.6" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">Row Retrieval</td>
<td id="S4.T3.7.7.8.7" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">Size Detection</td>
<td id="S4.T3.7.7.8.8" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">Merged Cell Detection</td>
</tr>
<tr id="S4.T3.7.7.7" class="ltx_tr">
<td id="S4.T3.7.7.7.8" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S4.T3.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S4.T3.1.1.1.1.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="S4.T3.1.1.1.1.m1.1a"><mi mathvariant="normal" id="S4.T3.1.1.1.1.m1.1.1" xref="S4.T3.1.1.1.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.1.m1.1b"><ci id="S4.T3.1.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.1.m1.1c">\Delta</annotation></semantics></math></td>
<td id="S4.T3.7.7.7.9" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S4.T3.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S4.T3.2.2.2.2.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="S4.T3.2.2.2.2.m1.1a"><mi mathvariant="normal" id="S4.T3.2.2.2.2.m1.1.1" xref="S4.T3.2.2.2.2.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.2.m1.1b"><ci id="S4.T3.2.2.2.2.m1.1.1.cmml" xref="S4.T3.2.2.2.2.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.2.m1.1c">\Delta</annotation></semantics></math></td>
<td id="S4.T3.7.7.7.10" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S4.T3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t"><math id="S4.T3.3.3.3.3.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="S4.T3.3.3.3.3.m1.1a"><mi mathvariant="normal" id="S4.T3.3.3.3.3.m1.1.1" xref="S4.T3.3.3.3.3.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.3.m1.1b"><ci id="S4.T3.3.3.3.3.m1.1.1.cmml" xref="S4.T3.3.3.3.3.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.3.3.m1.1c">\Delta</annotation></semantics></math></td>
<td id="S4.T3.7.7.7.11" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S4.T3.4.4.4.4" class="ltx_td ltx_align_center ltx_border_t"><math id="S4.T3.4.4.4.4.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="S4.T3.4.4.4.4.m1.1a"><mi mathvariant="normal" id="S4.T3.4.4.4.4.m1.1.1" xref="S4.T3.4.4.4.4.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.T3.4.4.4.4.m1.1b"><ci id="S4.T3.4.4.4.4.m1.1.1.cmml" xref="S4.T3.4.4.4.4.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.4.4.4.m1.1c">\Delta</annotation></semantics></math></td>
<td id="S4.T3.7.7.7.12" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S4.T3.5.5.5.5" class="ltx_td ltx_align_center ltx_border_t"><math id="S4.T3.5.5.5.5.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="S4.T3.5.5.5.5.m1.1a"><mi mathvariant="normal" id="S4.T3.5.5.5.5.m1.1.1" xref="S4.T3.5.5.5.5.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.T3.5.5.5.5.m1.1b"><ci id="S4.T3.5.5.5.5.m1.1.1.cmml" xref="S4.T3.5.5.5.5.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.5.5.5.m1.1c">\Delta</annotation></semantics></math></td>
<td id="S4.T3.7.7.7.13" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S4.T3.6.6.6.6" class="ltx_td ltx_align_center ltx_border_t"><math id="S4.T3.6.6.6.6.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="S4.T3.6.6.6.6.m1.1a"><mi mathvariant="normal" id="S4.T3.6.6.6.6.m1.1.1" xref="S4.T3.6.6.6.6.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.T3.6.6.6.6.m1.1b"><ci id="S4.T3.6.6.6.6.m1.1.1.cmml" xref="S4.T3.6.6.6.6.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.6.6.6.m1.1c">\Delta</annotation></semantics></math></td>
<td id="S4.T3.7.7.7.14" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S4.T3.7.7.7.7" class="ltx_td ltx_align_center ltx_border_t"><math id="S4.T3.7.7.7.7.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="S4.T3.7.7.7.7.m1.1a"><mi mathvariant="normal" id="S4.T3.7.7.7.7.m1.1.1" xref="S4.T3.7.7.7.7.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.T3.7.7.7.7.m1.1b"><ci id="S4.T3.7.7.7.7.m1.1.1.cmml" xref="S4.T3.7.7.7.7.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.7.7.7.7.m1.1c">\Delta</annotation></semantics></math></td>
</tr>
<tr id="S4.T3.7.7.9" class="ltx_tr">
<td id="S4.T3.7.7.9.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T3.7.7.9.1.1" class="ltx_text ltx_font_bold">Markup Lan. HTML</span></td>
<td id="S4.T3.7.7.9.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.7.7.9.2.1" class="ltx_text ltx_font_bold">96.67%</span></td>
<td id="S4.T3.7.7.9.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="S4.T3.7.7.9.3.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="S4.T3.7.7.9.4" class="ltx_td ltx_align_center ltx_border_t">44.00%</td>
<td id="S4.T3.7.7.9.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FBE0E3;"><span id="S4.T3.7.7.9.5.1" class="ltx_text" style="background-color:#FBE0E3;">0.00%</span></td>
<td id="S4.T3.7.7.9.6" class="ltx_td ltx_align_center ltx_border_t">47.33%</td>
<td id="S4.T3.7.7.9.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="S4.T3.7.7.9.7.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="S4.T3.7.7.9.8" class="ltx_td ltx_align_center ltx_border_t">63.33%</td>
<td id="S4.T3.7.7.9.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="S4.T3.7.7.9.9.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="S4.T3.7.7.9.10" class="ltx_td ltx_align_center ltx_border_t">42.00%</td>
<td id="S4.T3.7.7.9.11" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#D9E3F3;"><span id="S4.T3.7.7.9.11.1" class="ltx_text" style="background-color:#D9E3F3;">0.00%</span></td>
<td id="S4.T3.7.7.9.12" class="ltx_td ltx_align_center ltx_border_t">67.00%</td>
<td id="S4.T3.7.7.9.13" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="S4.T3.7.7.9.13.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="S4.T3.7.7.9.14" class="ltx_td ltx_align_center ltx_border_t">76.67%</td>
<td id="S4.T3.7.7.9.15" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#D1DEF0;"><span id="S4.T3.7.7.9.15.1" class="ltx_text" style="background-color:#D1DEF0;">0.00%</span></td>
</tr>
<tr id="S4.T3.7.7.10" class="ltx_tr">
<td id="S4.T3.7.7.10.1" class="ltx_td ltx_align_left">w/o format explanation</td>
<td id="S4.T3.7.7.10.2" class="ltx_td ltx_align_center">92.00%</td>
<td id="S4.T3.7.7.10.3" class="ltx_td ltx_align_center" style="background-color:#FBE7EA;"><span id="S4.T3.7.7.10.3.1" class="ltx_text" style="background-color:#FBE7EA;">-4.67%</span></td>
<td id="S4.T3.7.7.10.4" class="ltx_td ltx_align_center">52.00%</td>
<td id="S4.T3.7.7.10.5" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S4.T3.7.7.10.5.1" class="ltx_text" style="background-color:#FCFCFF;">8.00%</span></td>
<td id="S4.T3.7.7.10.6" class="ltx_td ltx_align_center">52.33%</td>
<td id="S4.T3.7.7.10.7" class="ltx_td ltx_align_center" style="background-color:#BACDE8;"><span id="S4.T3.7.7.10.7.1" class="ltx_text" style="background-color:#BACDE8;">5.00%</span></td>
<td id="S4.T3.7.7.10.8" class="ltx_td ltx_align_center">64.33%</td>
<td id="S4.T3.7.7.10.9" class="ltx_td ltx_align_center" style="background-color:#E1E9F6;"><span id="S4.T3.7.7.10.9.1" class="ltx_text" style="background-color:#E1E9F6;">1.00%</span></td>
<td id="S4.T3.7.7.10.10" class="ltx_td ltx_align_center">36.00%</td>
<td id="S4.T3.7.7.10.11" class="ltx_td ltx_align_center" style="background-color:#FAC4C6;"><span id="S4.T3.7.7.10.11.1" class="ltx_text" style="background-color:#FAC4C6;">-6.00%</span></td>
<td id="S4.T3.7.7.10.12" class="ltx_td ltx_align_center"><span id="S4.T3.7.7.10.12.1" class="ltx_text ltx_font_bold">78.00%</span></td>
<td id="S4.T3.7.7.10.13" class="ltx_td ltx_align_center" style="background-color:#90B0D9;"><span id="S4.T3.7.7.10.13.1" class="ltx_text" style="background-color:#90B0D9;">11.00%</span></td>
<td id="S4.T3.7.7.10.14" class="ltx_td ltx_align_center"><span id="S4.T3.7.7.10.14.1" class="ltx_text ltx_font_bold">77.67%</span></td>
<td id="S4.T3.7.7.10.15" class="ltx_td ltx_align_center" style="background-color:#B8CCE7;"><span id="S4.T3.7.7.10.15.1" class="ltx_text" style="background-color:#B8CCE7;">1.00%</span></td>
</tr>
<tr id="S4.T3.7.7.11" class="ltx_tr">
<td id="S4.T3.7.7.11.1" class="ltx_td ltx_align_left">w/o partition mark</td>
<td id="S4.T3.7.7.11.2" class="ltx_td ltx_align_center"><span id="S4.T3.7.7.11.2.1" class="ltx_text ltx_font_bold">98.00%</span></td>
<td id="S4.T3.7.7.11.3" class="ltx_td ltx_align_center" style="background-color:#B5CAE6;"><span id="S4.T3.7.7.11.3.1" class="ltx_text" style="background-color:#B5CAE6;">1.33%</span></td>
<td id="S4.T3.7.7.11.4" class="ltx_td ltx_align_center"><span id="S4.T3.7.7.11.4.1" class="ltx_text ltx_font_bold">59.00%</span></td>
<td id="S4.T3.7.7.11.5" class="ltx_td ltx_align_center" style="background-color:#C7D7ED;"><span id="S4.T3.7.7.11.5.1" class="ltx_text" style="background-color:#C7D7ED;">15.00%</span></td>
<td id="S4.T3.7.7.11.6" class="ltx_td ltx_align_center">53.00%</td>
<td id="S4.T3.7.7.11.7" class="ltx_td ltx_align_center" style="background-color:#B1C7E5;"><span id="S4.T3.7.7.11.7.1" class="ltx_text" style="background-color:#B1C7E5;">5.67%</span></td>
<td id="S4.T3.7.7.11.8" class="ltx_td ltx_align_center">66.00%</td>
<td id="S4.T3.7.7.11.9" class="ltx_td ltx_align_center" style="background-color:#B4CAE6;"><span id="S4.T3.7.7.11.9.1" class="ltx_text" style="background-color:#B4CAE6;">2.67%</span></td>
<td id="S4.T3.7.7.11.10" class="ltx_td ltx_align_center">39.67%</td>
<td id="S4.T3.7.7.11.11" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S4.T3.7.7.11.11.1" class="ltx_text" style="background-color:#FCFCFF;">-2.33%</span></td>
<td id="S4.T3.7.7.11.12" class="ltx_td ltx_align_center"><span id="S4.T3.7.7.11.12.1" class="ltx_text ltx_font_bold">72.00%</span></td>
<td id="S4.T3.7.7.11.13" class="ltx_td ltx_align_center" style="background-color:#CBDAEE;"><span id="S4.T3.7.7.11.13.1" class="ltx_text" style="background-color:#CBDAEE;">5.00%</span></td>
<td id="S4.T3.7.7.11.14" class="ltx_td ltx_align_center">70.33%</td>
<td id="S4.T3.7.7.11.15" class="ltx_td ltx_align_center" style="background-color:#FBE9EC;"><span id="S4.T3.7.7.11.15.1" class="ltx_text" style="background-color:#FBE9EC;">-6.33%</span></td>
</tr>
<tr id="S4.T3.7.7.12" class="ltx_tr">
<td id="S4.T3.7.7.12.1" class="ltx_td ltx_align_left">w/o role prompting</td>
<td id="S4.T3.7.7.12.2" class="ltx_td ltx_align_center">95.00%</td>
<td id="S4.T3.7.7.12.3" class="ltx_td ltx_align_center" style="background-color:#5A8AC6;"><span id="S4.T3.7.7.12.3.1" class="ltx_text" style="background-color:#5A8AC6;">3.00%</span></td>
<td id="S4.T3.7.7.12.4" class="ltx_td ltx_align_center">40.67%</td>
<td id="S4.T3.7.7.12.5" class="ltx_td ltx_align_center" style="background-color:#FAB9BB;"><span id="S4.T3.7.7.12.5.1" class="ltx_text" style="background-color:#FAB9BB;">-11.33%</span></td>
<td id="S4.T3.7.7.12.6" class="ltx_td ltx_align_center">44.67%</td>
<td id="S4.T3.7.7.12.7" class="ltx_td ltx_align_center" style="background-color:#FAD6D9;"><span id="S4.T3.7.7.12.7.1" class="ltx_text" style="background-color:#FAD6D9;">-7.67%</span></td>
<td id="S4.T3.7.7.12.8" class="ltx_td ltx_align_center">59.00%</td>
<td id="S4.T3.7.7.12.9" class="ltx_td ltx_align_center" style="background-color:#FAC1C3;"><span id="S4.T3.7.7.12.9.1" class="ltx_text" style="background-color:#FAC1C3;">-5.33%</span></td>
<td id="S4.T3.7.7.12.10" class="ltx_td ltx_align_center">39.33%</td>
<td id="S4.T3.7.7.12.11" class="ltx_td ltx_align_center" style="background-color:#A5BFE1;"><span id="S4.T3.7.7.12.11.1" class="ltx_text" style="background-color:#A5BFE1;">3.33%</span></td>
<td id="S4.T3.7.7.12.12" class="ltx_td ltx_align_center"><span id="S4.T3.7.7.12.12.1" class="ltx_text ltx_font_bold">69.00%</span></td>
<td id="S4.T3.7.7.12.13" class="ltx_td ltx_align_center" style="background-color:#FBE1E4;"><span id="S4.T3.7.7.12.13.1" class="ltx_text" style="background-color:#FBE1E4;">-9.00%</span></td>
<td id="S4.T3.7.7.12.14" class="ltx_td ltx_align_center">76.00%</td>
<td id="S4.T3.7.7.12.15" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S4.T3.7.7.12.15.1" class="ltx_text" style="background-color:#FCFCFF;">-1.67%</span></td>
</tr>
<tr id="S4.T3.7.7.13" class="ltx_tr">
<td id="S4.T3.7.7.13.1" class="ltx_td ltx_align_left">w/o change order</td>
<td id="S4.T3.7.7.13.2" class="ltx_td ltx_align_center"><span id="S4.T3.7.7.13.2.1" class="ltx_text ltx_font_bold">96.67%</span></td>
<td id="S4.T3.7.7.13.3" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S4.T3.7.7.13.3.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="S4.T3.7.7.13.4" class="ltx_td ltx_align_center">52.33%</td>
<td id="S4.T3.7.7.13.5" class="ltx_td ltx_align_center" style="background-color:#FAFBFF;"><span id="S4.T3.7.7.13.5.1" class="ltx_text" style="background-color:#FAFBFF;">8.33%</span></td>
<td id="S4.T3.7.7.13.6" class="ltx_td ltx_align_center">40.67%</td>
<td id="S4.T3.7.7.13.7" class="ltx_td ltx_align_center" style="background-color:#FBDBDE;"><span id="S4.T3.7.7.13.7.1" class="ltx_text" style="background-color:#FBDBDE;">-6.67%</span></td>
<td id="S4.T3.7.7.13.8" class="ltx_td ltx_align_center">55.67%</td>
<td id="S4.T3.7.7.13.9" class="ltx_td ltx_align_center" style="background-color:#F9A7A9;"><span id="S4.T3.7.7.13.9.1" class="ltx_text" style="background-color:#F9A7A9;">-7.67%</span></td>
<td id="S4.T3.7.7.13.10" class="ltx_td ltx_align_center">31.67%</td>
<td id="S4.T3.7.7.13.11" class="ltx_td ltx_align_center" style="background-color:#F88284;"><span id="S4.T3.7.7.13.11.1" class="ltx_text" style="background-color:#F88284;">-10.33%</span></td>
<td id="S4.T3.7.7.13.12" class="ltx_td ltx_align_center">52.67%</td>
<td id="S4.T3.7.7.13.13" class="ltx_td ltx_align_center" style="background-color:#FAD2D4;"><span id="S4.T3.7.7.13.13.1" class="ltx_text" style="background-color:#FAD2D4;">-14.33%</span></td>
<td id="S4.T3.7.7.13.14" class="ltx_td ltx_align_center">65.67%</td>
<td id="S4.T3.7.7.13.15" class="ltx_td ltx_align_center" style="background-color:#FAD6D9;"><span id="S4.T3.7.7.13.15.1" class="ltx_text" style="background-color:#FAD6D9;">-11.00%</span></td>
</tr>
<tr id="S4.T3.7.7.14" class="ltx_tr">
<td id="S4.T3.7.7.14.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T3.7.7.14.1.1" class="ltx_text ltx_font_bold">w/o 1-shot</span></td>
<td id="S4.T3.7.7.14.2" class="ltx_td ltx_align_center ltx_border_t">63.00%</td>
<td id="S4.T3.7.7.14.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="S4.T3.7.7.14.3.1" class="ltx_text" style="background-color:#F8696B;">-33.67%</span></td>
<td id="S4.T3.7.7.14.4" class="ltx_td ltx_align_center ltx_border_t">9.33%</td>
<td id="S4.T3.7.7.14.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="S4.T3.7.7.14.5.1" class="ltx_text" style="background-color:#F8696B;">-34.67%</span></td>
<td id="S4.T3.7.7.14.6" class="ltx_td ltx_align_center ltx_border_t">17.33%</td>
<td id="S4.T3.7.7.14.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="S4.T3.7.7.14.7.1" class="ltx_text" style="background-color:#F8696B;">-30.00%</span></td>
<td id="S4.T3.7.7.14.8" class="ltx_td ltx_align_center ltx_border_t">50.00%</td>
<td id="S4.T3.7.7.14.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="S4.T3.7.7.14.9.1" class="ltx_text" style="background-color:#F8696B;">-13.33%</span></td>
<td id="S4.T3.7.7.14.10" class="ltx_td ltx_align_center ltx_border_t">30.00%</td>
<td id="S4.T3.7.7.14.11" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="S4.T3.7.7.14.11.1" class="ltx_text" style="background-color:#F8696B;">-12.00%</span></td>
<td id="S4.T3.7.7.14.12" class="ltx_td ltx_align_center ltx_border_t">16.67%</td>
<td id="S4.T3.7.7.14.13" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="S4.T3.7.7.14.13.1" class="ltx_text" style="background-color:#F8696B;">-50.33%</span></td>
<td id="S4.T3.7.7.14.14" class="ltx_td ltx_align_center ltx_border_t">38.00%</td>
<td id="S4.T3.7.7.14.15" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="S4.T3.7.7.14.15.1" class="ltx_text" style="background-color:#F8696B;">-38.67%</span></td>
</tr>
<tr id="S4.T3.7.7.15" class="ltx_tr">
<td id="S4.T3.7.7.15.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"><span id="S4.T3.7.7.15.1.1" class="ltx_text ltx_font_bold">GPT-4 w/ Lan. HTML</span></td>
<td id="S4.T3.7.7.15.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T3.7.7.15.2.1" class="ltx_text ltx_font_bold">98.32%</span></td>
<td id="S4.T3.7.7.15.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="background-color:#A3BEE0;"><span id="S4.T3.7.7.15.3.1" class="ltx_text" style="background-color:#A3BEE0;">1.65%</span></td>
<td id="S4.T3.7.7.15.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">73.34%</td>
<td id="S4.T3.7.7.15.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="background-color:#5A8AC6;"><span id="S4.T3.7.7.15.5.1" class="ltx_text" style="background-color:#5A8AC6;">29.34%</span></td>
<td id="S4.T3.7.7.15.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">59.45%</td>
<td id="S4.T3.7.7.15.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="background-color:#5A8AC6;"><span id="S4.T3.7.7.15.7.1" class="ltx_text" style="background-color:#5A8AC6;">12.12%</span></td>
<td id="S4.T3.7.7.15.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">69.32%</td>
<td id="S4.T3.7.7.15.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="background-color:#5A8AC6;"><span id="S4.T3.7.7.15.9.1" class="ltx_text" style="background-color:#5A8AC6;">5.99%</span></td>
<td id="S4.T3.7.7.15.10" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">50.19%</td>
<td id="S4.T3.7.7.15.11" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="background-color:#5A8AC6;"><span id="S4.T3.7.7.15.11.1" class="ltx_text" style="background-color:#5A8AC6;">8.19%</span></td>
<td id="S4.T3.7.7.15.12" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">83.43%</td>
<td id="S4.T3.7.7.15.13" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="background-color:#5A8AC6;"><span id="S4.T3.7.7.15.13.1" class="ltx_text" style="background-color:#5A8AC6;">16.43%</span></td>
<td id="S4.T3.7.7.15.14" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">81.28%</td>
<td id="S4.T3.7.7.15.15" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="background-color:#5A8AC6;"><span id="S4.T3.7.7.15.15.1" class="ltx_text" style="background-color:#5A8AC6;">4.61%</span></td>
</tr>
</table>
</span></div>
</figure>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.1" class="ltx_p">Based on the empirical observations, it is evident that structural information plays a crucial role in comprehending a table. Researchers such as <cite class="ltx_cite ltx_citemacro_citet">Xie et al<span class="ltx_text">.</span> (<a href="#bib.bib40" title="" class="ltx_ref">2022</a>); Yin et al<span class="ltx_text">.</span> (<a href="#bib.bib41" title="" class="ltx_ref">2020</a>); Aghajanyan et al<span class="ltx_text">.</span> (<a href="#bib.bib3" title="" class="ltx_ref">2021</a>)</cite> have made progress by incorporating prompts with special tokens to encode different structural information. Building on their work and the findings from the SUC benchmark results, we explore the concept of manual prompt engineering as an additional technique for self-augmented prompting.
Specifically, we consider extracting structural information from the raw input and incorporating it into the input itself. This can involve using cell addresses and clearly indicating the number of rows and columns in the table. Such augmentation aims to provide additional knowledge and constraints, thereby improving the LLM’s ability to reason in tabular downstream tasks.
We have observed that the LLM performs poorly in the task of table size detection (refer to Section <a href="#S3" title="3. SUC Benchmark ‣ Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>), which motivates us to include structural features in the input. For example, we append information about the table size and merged cell positions to create a more structure-aware in-context learning environment for downstream tasks. Our ablation study in Sec §<a href="#S5.SS2.SSS1" title="5.2.1. Benchmark Highlights ‣ 5.2. Results ‣ 5. Experiments ‣ Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2.1</span></a> shows that appending table size and merged cell position leads to an improvement in the LLM’s performance on downstream tasks.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Experiments</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>Experiment Settings</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p"><span id="S5.SS1.p1.1.1" class="ltx_text ltx_font_bold">Models.</span>
In this study, we evaluate the performance on GPT-3.5 <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2022</a>)</cite> and GPT-4 <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a href="#bib.bib28" title="" class="ltx_ref">2023</a>)</cite>. Unless otherwise specified, we utilize text-davinci-003 in all experiments. Specifically, we set the hyper-parameter temperature to 0, top_p to 1, with n set to 1 when performing the experiments;
<span id="S5.SS1.p1.1.2" class="ltx_text ltx_font_bold">Downstream Tasks and Datasets.</span>
In addition to evaluate LLMs’ capabilities toward understanding structured data through our benchmark. We also conduct experiments on five typical tabular downstream tasks. The datasets are shown as follows, and the evaluation number can be found in Table <a href="#S5.T4" title="Table 4 ‣ 5.2.1. Benchmark Highlights ‣ 5.2. Results ‣ 5. Experiments ‣ Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">Specifically, we use <span id="S5.SS1.p2.1.1" class="ltx_text ltx_font_bold">(1) SQA</span> which is composed of 6,066 question sequences (2.9 questions per sequence on average), constructed by decomposing a subset of highly compositional WTQ questions; <span id="S5.SS1.p2.1.2" class="ltx_text ltx_font_bold">(2) HybridQA</span> which requires reasoning on heterogeneous information rather than homogeneous information alone, which involves 62,682 questions. Each question is aligned with a Wikipedia table and multiple free-form corpora linked with the entities in the table. The questions are designed to aggregate both tabular information and text information, <span id="S5.SS1.p2.1.3" class="ltx_text ltx_font_italic">i.e.</span>, lack of either form would render the question unanswerable; <span id="S5.SS1.p2.1.4" class="ltx_text ltx_font_bold">(3) ToTTo</span> which is a high-quality English table-to-text dataset with more than 100,000 examples in which a table from Wikipedia with highlighted cells is paired with a sentence that describes the highlighted cells. The task is like given a Wikipedia table with row names, column names and table cells, with a subset of cells highlighted, generate a natural language description for the highlighted part of the table; <span id="S5.SS1.p2.1.5" class="ltx_text ltx_font_bold">(4) FEVEROUS</span> which is a fact verification dataset consisting of 87,026 verified claims. Each claim is annotated with evidence in the form of sentences and/or cells from tables in Wikipedia, as well as a label indicating whether this evidence supports, refutes, or does not provide enough information to reach a verdict;
<span id="S5.SS1.p2.1.6" class="ltx_text ltx_font_bold">(5) TabFact</span> which is a fact verification dataset in which the tables were extracted from Wikipedia and sentences were written by crowd workers.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>Results</h3>

<section id="S5.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.1. </span>Benchmark Highlights</h4>

<figure id="S5.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4. </span>Downstream tasks evaluation. SA. refers to Self-augmented Prompting.</figcaption>
<div id="S5.T4.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:122.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-101.6pt,28.7pt) scale(0.68095851762463,0.68095851762463) ;">
<table id="S5.T4.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T4.1.1.1" class="ltx_tr">
<td id="S5.T4.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S5.T4.1.1.1.1.1" class="ltx_text">Type</span></td>
<td id="S5.T4.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S5.T4.1.1.1.2.1" class="ltx_text">Choice</span></td>
<td id="S5.T4.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">TabFact</td>
<td id="S5.T4.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">HybridQA</td>
<td id="S5.T4.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt">SQA</td>
<td id="S5.T4.1.1.1.6" class="ltx_td ltx_align_center ltx_border_tt">Feverous</td>
<td id="S5.T4.1.1.1.7" class="ltx_td ltx_align_center ltx_border_tt" colspan="4">ToTTo</td>
</tr>
<tr id="S5.T4.1.1.2" class="ltx_tr">
<td id="S5.T4.1.1.2.1" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S5.T4.1.1.2.2" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S5.T4.1.1.2.3" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S5.T4.1.1.2.4" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S5.T4.1.1.2.5" class="ltx_td ltx_align_center ltx_border_t">BLEU-1</td>
<td id="S5.T4.1.1.2.6" class="ltx_td ltx_align_center ltx_border_t">BLEU-2</td>
<td id="S5.T4.1.1.2.7" class="ltx_td ltx_align_center ltx_border_t">BLEU-3</td>
<td id="S5.T4.1.1.2.8" class="ltx_td ltx_align_center ltx_border_t">BLEU-4</td>
</tr>
<tr id="S5.T4.1.1.3" class="ltx_tr">
<td id="S5.T4.1.1.3.1" class="ltx_td ltx_align_center ltx_border_t">1-shot</td>
<td id="S5.T4.1.1.3.2" class="ltx_td ltx_align_left ltx_border_t">1-shot</td>
<td id="S5.T4.1.1.3.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#D8E1F3;"><span id="S5.T4.1.1.3.3.1" class="ltx_text" style="background-color:#D8E1F3;">72.04%</span></td>
<td id="S5.T4.1.1.3.4" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E2E8F7;"><span id="S5.T4.1.1.3.4.1" class="ltx_text" style="background-color:#E2E8F7;">46.07%</span></td>
<td id="S5.T4.1.1.3.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#CCD8F0;"><span id="S5.T4.1.1.3.5.1" class="ltx_text" style="background-color:#CCD8F0;">73.81%</span></td>
<td id="S5.T4.1.1.3.6" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#D7E0F3;"><span id="S5.T4.1.1.3.6.1" class="ltx_text" style="background-color:#D7E0F3;">75.56%</span></td>
<td id="S5.T4.1.1.3.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E8EDF9;"><span id="S5.T4.1.1.3.7.1" class="ltx_text" style="background-color:#E8EDF9;">72.43%</span></td>
<td id="S5.T4.1.1.3.8" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E0E7F6;"><span id="S5.T4.1.1.3.8.1" class="ltx_text" style="background-color:#E0E7F6;">44.36%</span></td>
<td id="S5.T4.1.1.3.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E5EBF8;"><span id="S5.T4.1.1.3.9.1" class="ltx_text" style="background-color:#E5EBF8;">27.01%</span></td>
<td id="S5.T4.1.1.3.10" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#EBEFFA;"><span id="S5.T4.1.1.3.10.1" class="ltx_text" style="background-color:#EBEFFA;">17.24%</span></td>
</tr>
<tr id="S5.T4.1.1.4" class="ltx_tr">
<td id="S5.T4.1.1.4.1" class="ltx_td ltx_align_center">1-shot</td>
<td id="S5.T4.1.1.4.2" class="ltx_td ltx_align_left">w/o table size</td>
<td id="S5.T4.1.1.4.3" class="ltx_td ltx_align_center" style="background-color:#EEF1FB;"><span id="S5.T4.1.1.4.3.1" class="ltx_text" style="background-color:#EEF1FB;">71.33%</span></td>
<td id="S5.T4.1.1.4.4" class="ltx_td ltx_align_center" style="background-color:#F7F9FE;"><span id="S5.T4.1.1.4.4.1" class="ltx_text" style="background-color:#F7F9FE;">45.52%</span></td>
<td id="S5.T4.1.1.4.5" class="ltx_td ltx_align_center" style="background-color:#E1E8F6;"><span id="S5.T4.1.1.4.5.1" class="ltx_text" style="background-color:#E1E8F6;">72.91%</span></td>
<td id="S5.T4.1.1.4.6" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S5.T4.1.1.4.6.1" class="ltx_text" style="background-color:#FCFCFF;">74.66%</span></td>
<td id="S5.T4.1.1.4.7" class="ltx_td ltx_align_center" style="background-color:#EAEEF9;"><span id="S5.T4.1.1.4.7.1" class="ltx_text" style="background-color:#EAEEF9;">72.30%</span></td>
<td id="S5.T4.1.1.4.8" class="ltx_td ltx_align_center" style="background-color:#E3E9F7;"><span id="S5.T4.1.1.4.8.1" class="ltx_text" style="background-color:#E3E9F7;">44.23%</span></td>
<td id="S5.T4.1.1.4.9" class="ltx_td ltx_align_center" style="background-color:#E2E9F7;"><span id="S5.T4.1.1.4.9.1" class="ltx_text" style="background-color:#E2E9F7;">27.14%</span></td>
<td id="S5.T4.1.1.4.10" class="ltx_td ltx_align_center" style="background-color:#EBEFFA;"><span id="S5.T4.1.1.4.10.1" class="ltx_text" style="background-color:#EBEFFA;">17.25%</span></td>
</tr>
<tr id="S5.T4.1.1.5" class="ltx_tr">
<td id="S5.T4.1.1.5.1" class="ltx_td ltx_align_center">1-shot</td>
<td id="S5.T4.1.1.5.2" class="ltx_td ltx_align_left">w/o partition mark</td>
<td id="S5.T4.1.1.5.3" class="ltx_td ltx_align_center" style="background-color:#F0F3FC;"><span id="S5.T4.1.1.5.3.1" class="ltx_text" style="background-color:#F0F3FC;">71.25%</span></td>
<td id="S5.T4.1.1.5.4" class="ltx_td ltx_align_center" style="background-color:#F9FAFE;"><span id="S5.T4.1.1.5.4.1" class="ltx_text" style="background-color:#F9FAFE;">45.48%</span></td>
<td id="S5.T4.1.1.5.5" class="ltx_td ltx_align_center" style="background-color:#DDE4F5;"><span id="S5.T4.1.1.5.5.1" class="ltx_text" style="background-color:#DDE4F5;">73.09%</span></td>
<td id="S5.T4.1.1.5.6" class="ltx_td ltx_align_center" style="background-color:#E9EEF9;"><span id="S5.T4.1.1.5.6.1" class="ltx_text" style="background-color:#E9EEF9;">75.11%</span></td>
<td id="S5.T4.1.1.5.7" class="ltx_td ltx_align_center" style="background-color:#F6F7FD;"><span id="S5.T4.1.1.5.7.1" class="ltx_text" style="background-color:#F6F7FD;">71.18%</span></td>
<td id="S5.T4.1.1.5.8" class="ltx_td ltx_align_center" style="background-color:#FBFBFF;"><span id="S5.T4.1.1.5.8.1" class="ltx_text" style="background-color:#FBFBFF;">43.17%</span></td>
<td id="S5.T4.1.1.5.9" class="ltx_td ltx_align_center" style="background-color:#F4F6FD;"><span id="S5.T4.1.1.5.9.1" class="ltx_text" style="background-color:#F4F6FD;">26.36%</span></td>
<td id="S5.T4.1.1.5.10" class="ltx_td ltx_align_center" style="background-color:#F9FAFE;"><span id="S5.T4.1.1.5.10.1" class="ltx_text" style="background-color:#F9FAFE;">16.34%</span></td>
</tr>
<tr id="S5.T4.1.1.6" class="ltx_tr">
<td id="S5.T4.1.1.6.1" class="ltx_td ltx_align_center">1-shot</td>
<td id="S5.T4.1.1.6.2" class="ltx_td ltx_align_left">w/o format explanation</td>
<td id="S5.T4.1.1.6.3" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S5.T4.1.1.6.3.1" class="ltx_text" style="background-color:#FCFCFF;">70.87%</span></td>
<td id="S5.T4.1.1.6.4" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S5.T4.1.1.6.4.1" class="ltx_text" style="background-color:#FCFCFF;">45.39%</span></td>
<td id="S5.T4.1.1.6.5" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S5.T4.1.1.6.5.1" class="ltx_text" style="background-color:#FCFCFF;">71.69%</span></td>
<td id="S5.T4.1.1.6.6" class="ltx_td ltx_align_center" style="background-color:#C5D3ED;"><span id="S5.T4.1.1.6.6.1" class="ltx_text" style="background-color:#C5D3ED;">75.97%</span></td>
<td id="S5.T4.1.1.6.7" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S5.T4.1.1.6.7.1" class="ltx_text" style="background-color:#FCFCFF;">70.54%</span></td>
<td id="S5.T4.1.1.6.8" class="ltx_td ltx_align_center" style="background-color:#F1F4FC;"><span id="S5.T4.1.1.6.8.1" class="ltx_text" style="background-color:#F1F4FC;">43.59%</span></td>
<td id="S5.T4.1.1.6.9" class="ltx_td ltx_align_center" style="background-color:#F1F4FC;"><span id="S5.T4.1.1.6.9.1" class="ltx_text" style="background-color:#F1F4FC;">26.52%</span></td>
<td id="S5.T4.1.1.6.10" class="ltx_td ltx_align_center" style="background-color:#F3F5FC;"><span id="S5.T4.1.1.6.10.1" class="ltx_text" style="background-color:#F3F5FC;">16.74%</span></td>
</tr>
<tr id="S5.T4.1.1.7" class="ltx_tr">
<td id="S5.T4.1.1.7.1" class="ltx_td ltx_align_center">1-shot</td>
<td id="S5.T4.1.1.7.2" class="ltx_td ltx_align_left">w/o role prompting</td>
<td id="S5.T4.1.1.7.3" class="ltx_td ltx_align_center" style="background-color:#EDF1FB;"><span id="S5.T4.1.1.7.3.1" class="ltx_text" style="background-color:#EDF1FB;">71.35%</span></td>
<td id="S5.T4.1.1.7.4" class="ltx_td ltx_align_center" style="background-color:#E3E9F7;"><span id="S5.T4.1.1.7.4.1" class="ltx_text" style="background-color:#E3E9F7;">46.05%</span></td>
<td id="S5.T4.1.1.7.5" class="ltx_td ltx_align_center" style="background-color:#D6DFF3;"><span id="S5.T4.1.1.7.5.1" class="ltx_text" style="background-color:#D6DFF3;">73.39%</span></td>
<td id="S5.T4.1.1.7.6" class="ltx_td ltx_align_center" style="background-color:#D8E1F4;"><span id="S5.T4.1.1.7.6.1" class="ltx_text" style="background-color:#D8E1F4;">75.52%</span></td>
<td id="S5.T4.1.1.7.7" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S5.T4.1.1.7.7.1" class="ltx_text" style="background-color:#FCFCFF;">70.61%</span></td>
<td id="S5.T4.1.1.7.8" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S5.T4.1.1.7.8.1" class="ltx_text" style="background-color:#FCFCFF;">43.10%</span></td>
<td id="S5.T4.1.1.7.9" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S5.T4.1.1.7.9.1" class="ltx_text" style="background-color:#FCFCFF;">26.02%</span></td>
<td id="S5.T4.1.1.7.10" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S5.T4.1.1.7.10.1" class="ltx_text" style="background-color:#FCFCFF;">16.15%</span></td>
</tr>
<tr id="S5.T4.1.1.8" class="ltx_tr">
<td id="S5.T4.1.1.8.1" class="ltx_td ltx_align_center ltx_border_t">SA</td>
<td id="S5.T4.1.1.8.2" class="ltx_td ltx_align_left ltx_border_t">self format explanation</td>
<td id="S5.T4.1.1.8.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#D2DCF1;"><span id="S5.T4.1.1.8.3.1" class="ltx_text" style="background-color:#D2DCF1;">72.23%</span></td>
<td id="S5.T4.1.1.8.4" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E0E7F6;"><span id="S5.T4.1.1.8.4.1" class="ltx_text" style="background-color:#E0E7F6;">46.12%</span></td>
<td id="S5.T4.1.1.8.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#CAD6EF;"><span id="S5.T4.1.1.8.5.1" class="ltx_text" style="background-color:#CAD6EF;">73.91%</span></td>
<td id="S5.T4.1.1.8.6" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#BECDEB;"><span id="S5.T4.1.1.8.6.1" class="ltx_text" style="background-color:#BECDEB;">76.15%</span></td>
<td id="S5.T4.1.1.8.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#D6DFF3;"><span id="S5.T4.1.1.8.7.1" class="ltx_text" style="background-color:#D6DFF3;">74.18%</span></td>
<td id="S5.T4.1.1.8.8" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#CCD8F0;"><span id="S5.T4.1.1.8.8.1" class="ltx_text" style="background-color:#CCD8F0;">45.25%</span></td>
<td id="S5.T4.1.1.8.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#DEE5F5;"><span id="S5.T4.1.1.8.9.1" class="ltx_text" style="background-color:#DEE5F5;">27.32%</span></td>
<td id="S5.T4.1.1.8.10" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#D9E2F4;"><span id="S5.T4.1.1.8.10.1" class="ltx_text" style="background-color:#D9E2F4;">18.34%</span></td>
</tr>
<tr id="S5.T4.1.1.9" class="ltx_tr">
<td id="S5.T4.1.1.9.1" class="ltx_td ltx_align_center">SA</td>
<td id="S5.T4.1.1.9.2" class="ltx_td ltx_align_left">self critical values and ranges identification</td>
<td id="S5.T4.1.1.9.3" class="ltx_td ltx_align_center" style="background-color:#8EA9DB;"><span id="S5.T4.1.1.9.3.1" class="ltx_text" style="background-color:#8EA9DB;">74.35%</span></td>
<td id="S5.T4.1.1.9.4" class="ltx_td ltx_align_center" style="background-color:#8EA9DB;"><span id="S5.T4.1.1.9.4.1" class="ltx_text" style="background-color:#8EA9DB;">48.20%</span></td>
<td id="S5.T4.1.1.9.5" class="ltx_td ltx_align_center" style="background-color:#8EA9DB;"><span id="S5.T4.1.1.9.5.1" class="ltx_text" style="background-color:#8EA9DB;">76.53%</span></td>
<td id="S5.T4.1.1.9.6" class="ltx_td ltx_align_center" style="background-color:#B7C8E9;"><span id="S5.T4.1.1.9.6.1" class="ltx_text" style="background-color:#B7C8E9;">76.32%</span></td>
<td id="S5.T4.1.1.9.7" class="ltx_td ltx_align_center" style="background-color:#8EA9DB;"><span id="S5.T4.1.1.9.7.1" class="ltx_text" style="background-color:#8EA9DB;">80.83%</span></td>
<td id="S5.T4.1.1.9.8" class="ltx_td ltx_align_center" style="background-color:#8EA9DB;"><span id="S5.T4.1.1.9.8.1" class="ltx_text" style="background-color:#8EA9DB;">47.96%</span></td>
<td id="S5.T4.1.1.9.9" class="ltx_td ltx_align_center" style="background-color:#8EA9DB;"><span id="S5.T4.1.1.9.9.1" class="ltx_text" style="background-color:#8EA9DB;">30.68%</span></td>
<td id="S5.T4.1.1.9.10" class="ltx_td ltx_align_center" style="background-color:#8EA9DB;"><span id="S5.T4.1.1.9.10.1" class="ltx_text" style="background-color:#8EA9DB;">22.92%</span></td>
</tr>
<tr id="S5.T4.1.1.10" class="ltx_tr">
<td id="S5.T4.1.1.10.1" class="ltx_td ltx_align_center ltx_border_bb">SA</td>
<td id="S5.T4.1.1.10.2" class="ltx_td ltx_align_left ltx_border_bb">self structural information description</td>
<td id="S5.T4.1.1.10.3" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#ACC0E5;"><span id="S5.T4.1.1.10.3.1" class="ltx_text" style="background-color:#ACC0E5;">73.42%</span></td>
<td id="S5.T4.1.1.10.4" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#BFCEEB;"><span id="S5.T4.1.1.10.4.1" class="ltx_text" style="background-color:#BFCEEB;">46.97%</span></td>
<td id="S5.T4.1.1.10.5" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#9BB3E0;"><span id="S5.T4.1.1.10.5.1" class="ltx_text" style="background-color:#9BB3E0;">75.97%</span></td>
<td id="S5.T4.1.1.10.6" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#8EA9DB;"><span id="S5.T4.1.1.10.6.1" class="ltx_text" style="background-color:#8EA9DB;">77.28%</span></td>
<td id="S5.T4.1.1.10.7" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#A3B9E2;"><span id="S5.T4.1.1.10.7.1" class="ltx_text" style="background-color:#A3B9E2;">78.93%</span></td>
<td id="S5.T4.1.1.10.8" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#A6BBE3;"><span id="S5.T4.1.1.10.8.1" class="ltx_text" style="background-color:#A6BBE3;">46.91%</span></td>
<td id="S5.T4.1.1.10.9" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#B8C8E9;"><span id="S5.T4.1.1.10.9.1" class="ltx_text" style="background-color:#B8C8E9;">28.94%</span></td>
<td id="S5.T4.1.1.10.10" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#C9D6EF;"><span id="S5.T4.1.1.10.10.1" class="ltx_text" style="background-color:#C9D6EF;">19.32%</span></td>
</tr>
</table>
</span></div>
</figure>
<div id="S5.SS2.SSS1.p1" class="ltx_para">
<p id="S5.SS2.SSS1.p1.1" class="ltx_p">Comprehensive evaluations of different structural understanding tasks with various input designs over SUC are presented in Table <a href="#S4.T3" title="Table 3 ‣ 4. Structural Prompting ‣ Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
The results show that the system’s overall accuracy gets highest when using the HTML markup language with format explanations and role prompts, and without order change, achieving a 65.43% overall accuracy on seven tasks. It indicates that the LLM has significant potential for understanding the structural information of tables in this specific format. However, it is also evident that the LLM’s performance is negatively impacted when certain features are removed, especially when the prompt example is removed.
We give some highlights associated with the benchmark results as follows:</p>
</div>
<section id="S5.SS2.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">NL+Sep vs. Markup Lan.</h5>

<div id="S5.SS2.SSS1.Px1.p1" class="ltx_para">
<p id="S5.SS2.SSS1.Px1.p1.1" class="ltx_p">We compare the use of natural language with specific separators (NL+Sep) and markup languages such as HTML, XML, and JSON.
Even “NL+Sep” is commonly used in tabular downstream tasks <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2020</a>; Herzig et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2020</a>; Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2022a</a>; Chen, <a href="#bib.bib7" title="" class="ltx_ref">2022</a>)</cite>, however, our results show that using markup languages, specifically HTML, outperforms “NL+Sep” with a 6.76% improvement.
We assume that the training process of the LLMs involves code tuning and that the training dataset contains a significant amount of web data. As a result, the LLM is more familiar with HTML and XML formats when interpreting tables. (For more information about the GPT-3.5 training, see <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2022</a>)</cite>).</p>
</div>
<figure id="S5.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5. </span>Main results of the downstream tasks ablation study</figcaption>
<div id="S5.T5.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:181.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(44.4pt,-18.5pt) scale(1.2575256803408,1.2575256803408) ;">
<table id="S5.T5.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T5.1.1.1" class="ltx_tr">
<td id="S5.T5.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S5.T5.1.1.1.1.1" class="ltx_text">Format</span></td>
<td id="S5.T5.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt">TabFact</td>
<td id="S5.T5.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">HybridQA</td>
<td id="S5.T5.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">SQA</td>
<td id="S5.T5.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt">Feverous</td>
<td id="S5.T5.1.1.1.6" class="ltx_td ltx_align_center ltx_border_tt">ToTTo</td>
</tr>
<tr id="S5.T5.1.1.2" class="ltx_tr">
<td id="S5.T5.1.1.2.1" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S5.T5.1.1.2.2" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S5.T5.1.1.2.3" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S5.T5.1.1.2.4" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="S5.T5.1.1.2.5" class="ltx_td ltx_align_center ltx_border_t">BLEU-4</td>
</tr>
<tr id="S5.T5.1.1.3" class="ltx_tr">
<td id="S5.T5.1.1.3.1" class="ltx_td ltx_align_left ltx_border_t">NL + Sep</td>
<td id="S5.T5.1.1.3.2" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#C7E7D1;"><span id="S5.T5.1.1.3.2.1" class="ltx_text" style="background-color:#C7E7D1;">70.26%</span></td>
<td id="S5.T5.1.1.3.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F1F8F6;"><span id="S5.T5.1.1.3.3.1" class="ltx_text" style="background-color:#F1F8F6;">45.02%</span></td>
<td id="S5.T5.1.1.3.4" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#9ED6AE;"><span id="S5.T5.1.1.3.4.1" class="ltx_text" style="background-color:#9ED6AE;">70.41%</span></td>
<td id="S5.T5.1.1.3.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#68C07F;"><span id="S5.T5.1.1.3.5.1" class="ltx_text" style="background-color:#68C07F;">75.15%</span></td>
<td id="S5.T5.1.1.3.6" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#63BE7B;"><span id="S5.T5.1.1.3.6.1" class="ltx_text ltx_font_bold" style="background-color:#63BE7B;">12.70%</span></td>
</tr>
<tr id="S5.T5.1.1.4" class="ltx_tr">
<td id="S5.T5.1.1.4.1" class="ltx_td ltx_align_left">Markdown</td>
<td id="S5.T5.1.1.4.2" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S5.T5.1.1.4.2.1" class="ltx_text" style="background-color:#FCFCFF;">68.40%</span></td>
<td id="S5.T5.1.1.4.3" class="ltx_td ltx_align_center" style="background-color:#BBE2C7;"><span id="S5.T5.1.1.4.3.1" class="ltx_text" style="background-color:#BBE2C7;">45.88%</span></td>
<td id="S5.T5.1.1.4.4" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S5.T5.1.1.4.4.1" class="ltx_text" style="background-color:#FCFCFF;">66.59%</span></td>
<td id="S5.T5.1.1.4.5" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S5.T5.1.1.4.5.1" class="ltx_text" style="background-color:#FCFCFF;">71.88%</span></td>
<td id="S5.T5.1.1.4.6" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S5.T5.1.1.4.6.1" class="ltx_text" style="background-color:#FCFCFF;">8.57%</span></td>
</tr>
<tr id="S5.T5.1.1.5" class="ltx_tr">
<td id="S5.T5.1.1.5.1" class="ltx_td ltx_align_left">JSON</td>
<td id="S5.T5.1.1.5.2" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S5.T5.1.1.5.2.1" class="ltx_text" style="background-color:#FCFCFF;">68.04%</span></td>
<td id="S5.T5.1.1.5.3" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S5.T5.1.1.5.3.1" class="ltx_text" style="background-color:#FCFCFF;">42.40%</span></td>
<td id="S5.T5.1.1.5.4" class="ltx_td ltx_align_center" style="background-color:#9FD7AF;"><span id="S5.T5.1.1.5.4.1" class="ltx_text" style="background-color:#9FD7AF;">70.39%</span></td>
<td id="S5.T5.1.1.5.5" class="ltx_td ltx_align_center" style="background-color:#E1F1E8;"><span id="S5.T5.1.1.5.5.1" class="ltx_text" style="background-color:#E1F1E8;">73.84%</span></td>
<td id="S5.T5.1.1.5.6" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S5.T5.1.1.5.6.1" class="ltx_text" style="background-color:#FCFCFF;">8.82%</span></td>
</tr>
<tr id="S5.T5.1.1.6" class="ltx_tr">
<td id="S5.T5.1.1.6.1" class="ltx_td ltx_align_left">XML</td>
<td id="S5.T5.1.1.6.2" class="ltx_td ltx_align_center" style="background-color:#DFF1E6;"><span id="S5.T5.1.1.6.2.1" class="ltx_text" style="background-color:#DFF1E6;">70.00%</span></td>
<td id="S5.T5.1.1.6.3" class="ltx_td ltx_align_center" style="background-color:#69C180;"><span id="S5.T5.1.1.6.3.1" class="ltx_text" style="background-color:#69C180;">47.20%</span></td>
<td id="S5.T5.1.1.6.4" class="ltx_td ltx_align_center" style="background-color:#88CD9B;"><span id="S5.T5.1.1.6.4.1" class="ltx_text" style="background-color:#88CD9B;">70.74%</span></td>
<td id="S5.T5.1.1.6.5" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S5.T5.1.1.6.5.1" class="ltx_text" style="background-color:#FCFCFF;">73.14%</span></td>
<td id="S5.T5.1.1.6.6" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="S5.T5.1.1.6.6.1" class="ltx_text" style="background-color:#FCFCFF;">8.82%</span></td>
</tr>
<tr id="S5.T5.1.1.7" class="ltx_tr">
<td id="S5.T5.1.1.7.1" class="ltx_td ltx_align_left">HTML</td>
<td id="S5.T5.1.1.7.2" class="ltx_td ltx_align_center" style="background-color:#63BE7B;"><span id="S5.T5.1.1.7.2.1" class="ltx_text ltx_font_bold" style="background-color:#63BE7B;">71.33%</span></td>
<td id="S5.T5.1.1.7.3" class="ltx_td ltx_align_center" style="background-color:#63BE7B;"><span id="S5.T5.1.1.7.3.1" class="ltx_text ltx_font_bold" style="background-color:#63BE7B;">47.29%</span></td>
<td id="S5.T5.1.1.7.4" class="ltx_td ltx_align_center" style="background-color:#63BE7B;"><span id="S5.T5.1.1.7.4.1" class="ltx_text ltx_font_bold" style="background-color:#63BE7B;">71.31%</span></td>
<td id="S5.T5.1.1.7.5" class="ltx_td ltx_align_center" style="background-color:#63BE7B;"><span id="S5.T5.1.1.7.5.1" class="ltx_text ltx_font_bold" style="background-color:#63BE7B;">75.20%</span></td>
<td id="S5.T5.1.1.7.6" class="ltx_td ltx_align_center" style="background-color:#81CA95;"><span id="S5.T5.1.1.7.6.1" class="ltx_text" style="background-color:#81CA95;">12.30%</span></td>
</tr>
<tr id="S5.T5.1.1.8" class="ltx_tr">
<td id="S5.T5.1.1.8.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">GPT-4 w/ HTML</td>
<td id="S5.T5.1.1.8.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">78.40%</td>
<td id="S5.T5.1.1.8.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">56.68%</td>
<td id="S5.T5.1.1.8.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">75.35%</td>
<td id="S5.T5.1.1.8.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">83.21%</td>
<td id="S5.T5.1.1.8.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">20.12%</td>
</tr>
</table>
</span></div>
</figure>
</section>
<section id="S5.SS2.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">1-shot vs. 0-shot.</h5>

<div id="S5.SS2.SSS1.Px2.p1" class="ltx_para">
<p id="S5.SS2.SSS1.Px2.p1.1" class="ltx_p">A notable finding is that the system’s performance drops significantly when it is in a zero-shot setting, with an overall accuracy decrease of 30.38% on all tasks using HTML format. This indicates that learning structural information is highly dependent on in-context learning. This is particularly significant for tasks such as size detection and merged cell detection, which are closely related to the ability to parse structural information.</p>
</div>
</section>
<section id="S5.SS2.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">External information should appear ahead of tables.</h5>

<div id="S5.SS2.SSS1.Px3.p1" class="ltx_para">
<p id="S5.SS2.SSS1.Px3.p1.1" class="ltx_p">In order to understand the impact of the order on the input design, we observed that when we manually placed external information such as questions and statements behind the table, there was an overall 6.81% decrease in performance across all tasks. One possible explanation for this is that placing external information ahead of tables could assist LLM in better generalization and gaining more context regarding the structural information of tables.</p>
</div>
</section>
<section id="S5.SS2.SSS1.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Partition mark and format explanation may undermine Search and Retrieval capability</h5>

<div id="S5.SS2.SSS1.Px4.p1" class="ltx_para">
<p id="S5.SS2.SSS1.Px4.p1.1" class="ltx_p">Partition mark <cite class="ltx_cite ltx_citemacro_citep">(Dou et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2022</a>)</cite> is commonly used in input designs. Inspired by the partition mark, we propose another similar choice called ”format explanation”. It provides an additional explanation of the adopted format. For example, in the case of HTML format, we explain that ”Each table cell is defined by a ¡td¿ and a ¡/td¿ tag; Each table row starts with a ¡tr¿ and ends with a ¡/tr¿ tag; th stands for table header.” However, when it comes to the task of Cell Lookup, adding partition marks and format explanations actually results in a decrease in performance across all input designs. This suggests that such additional structural information may bias the searching and retrieval process of LLM over the tabular structure. However, adding partition marks or format explanations does show some benefits for specific tasks such as merged cell detection. To provide a clearer understanding of the impact of adding additional explanations or special tokens, we conducted experiments as shown in Table <a href="#S5.T4" title="Table 4 ‣ 5.2.1. Benchmark Highlights ‣ 5.2. Results ‣ 5. Experiments ‣ Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. The results reveal that while they may undermine the search and retrieval capability of LLMs, they still improve overall performance in downstream tasks.</p>
</div>
<div id="S5.SS2.SSS1.Px4.p2" class="ltx_para">
<p id="S5.SS2.SSS1.Px4.p2.1" class="ltx_p">The SUC benchmark provides a comprehensive comparison using multiple input designs to evaluate the structural understanding capabilities of tables. Based on the findings, guidelines are proposed to address the questions mentioned in Sec §<a href="#S3" title="3. SUC Benchmark ‣ Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>:</p>
<ul id="S5.I1" class="ltx_itemize">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i1.p1" class="ltx_para">
<p id="S5.I1.i1.p1.1" class="ltx_p">1) LLMs have basic structural understanding capabilities, but are far from perfect, even for some trivial tasks, <span id="S5.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">e.g.</span>, table size detection;</p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i2.p1" class="ltx_para">
<p id="S5.I1.i2.p1.1" class="ltx_p">2) Choosing the right combination of input designs is a potential factor in improving the performance of LLMs when working with structured data.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="S5.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.2. </span>Downstream Tasks</h4>

<div id="S5.SS2.SSS2.p1" class="ltx_para">
<p id="S5.SS2.SSS2.p1.1" class="ltx_p">Table <a href="#S5.T4" title="Table 4 ‣ 5.2.1. Benchmark Highlights ‣ 5.2. Results ‣ 5. Experiments ‣ Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> gives the comparison using self-augmented prompting with the trick of structural feature detection. We find one notable insight that the models perform better using self-augmented prompting than 1-shot, as seen in the ”SA” rows where the models are given self-generated information: format explanation, key range and values identification, and structural information description. These rows have higher accuracy and BLEU scores than the ”1-shot” rows. Especially for generating key range and values identification gives an overall 3.26% performance improvement than 1-shot setting on all the tasks. Furthermore, manually prompting structural features like “table size” from the input has a slight impact on the model’s performance on downstream tasks. The drop of table size option gives an overall 0.4% decrease, as seen by the small difference between the “1-shot” row and the “1-shot w/o table size” row.</p>
</div>
<figure id="S5.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6. </span>Format explanation example from FEVEROUS</figcaption>
<div id="S5.T6.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:252.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(77.3pt,-45.0pt) scale(1.5540059576466,1.5540059576466) ;">
<table id="S5.T6.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T6.1.1.1" class="ltx_tr">
<td id="S5.T6.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S5.T6.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.1.1.1.1" class="ltx_p" style="width:73.9pt;"><span id="S5.T6.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Manual Prompt</span></span>
</span>
</td>
<td id="S5.T6.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S5.T6.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.1.2.1.1" class="ltx_p" style="width:177.8pt;"><span id="S5.T6.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Self-augmented Prompt Generation</span></span>
</span>
</td>
</tr>
<tr id="S5.T6.1.1.2" class="ltx_tr">
<td id="S5.T6.1.1.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S5.T6.1.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.2.1.1.1" class="ltx_p" style="width:73.9pt;">Each table cell is defined by a ¡td¿ and a ¡/td¿ tag.
<br class="ltx_break"> Each table row starts with a ¡tr¿ and ends with a ¡/tr¿ tag.
<br class="ltx_break"> th stands for table header.</span>
</span>
</td>
<td id="S5.T6.1.1.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S5.T6.1.1.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.2.2.1.1" class="ltx_p" style="width:177.8pt;">’15 rows and 4 columns, with the first column being an index, the second column being empty, the third column being the name of the Marshal, the fourth column being the date of promotion, and the fifth column being the defence branch.\nThe table is defined by HTML tags, with each table cell being defined by a ¡td¿ and a ¡/td¿ tag, and each table row starting with a ¡tr¿ and ending with a ¡/tr¿ tag.\nThe table header is denoted by the th tag.’</span>
</span>
</td>
</tr>
</table>
</span></div>
</figure>
<div id="S5.SS2.SSS2.p2" class="ltx_para">
<p id="S5.SS2.SSS2.p2.1" class="ltx_p">Based on the comparison between the ”1-shot w/o format explanation” row and the ”SA self format explanation” row, we observe that manually labeling the format explanation may have a negative impact on downstream tasks like FEVEROUS. This is because the table structure in FEVEROUS is more irregular, with numerous segments and subtables. These structural complexities pose significant challenges for GPT-3.5. Additionally, manually-crafted knowledge is more general and cannot cover detailed information of this nature. On the other hand, self-augmented prompting can learn patterns independently and generate more comprehensive and helpful cues to address the questions. We provide an example of a format explanation from FEVEROUS using two prompt designs in Table <a href="#S5.T6" title="Table 6 ‣ 5.2.2. Downstream Tasks ‣ 5.2. Results ‣ 5. Experiments ‣ Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
</section>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Related Work</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p"><span id="S6.p1.1.1" class="ltx_text ltx_font_bold">In-context Learning with LLMs.</span>
Large language models, such as GPT-3 <cite class="ltx_cite ltx_citemacro_citep">(Brown et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2020</a>)</cite>, Instruct-GPT, and Codex <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2021</a>)</cite>, have demonstrated their capability as few-shot reasoners in natural language-related tasks. The effectiveness of this capability is influenced by factors such as the model size, the amount of data used, and the available computing power. Recent studies <cite class="ltx_cite ltx_citemacro_citep">(Chung et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2022</a>; Cobbe et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2021</a>; Rae et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2022</a>)</cite> have proposed various methods for training these large language models (LLMs). These models have exhibited an impressive ability to perform tasks that they haven’t been specifically fine-tuned for, which is an emergent capability not observed in smaller language models.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p"><span id="S6.p2.1.1" class="ltx_text ltx_font_bold">Intermediate of Prompt Engineering.</span>
Recently, several intermediate prompt engineering methods have been proposed following ”CoT” <cite class="ltx_cite ltx_citemacro_citep">(Wei et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2022</a>)</cite>. CoT provides a few examples with explanations of the reasoning process. This step-by-step reasoning approach helps LLMs generate more accurate results. However, according to <cite class="ltx_cite ltx_citemacro_citep">(Wei et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2022</a>)</cite>, ”CoT only yields performance gains when used with models of nearly 100B parameters.” Smaller models tend to produce illogical chains of thought, resulting in lower accuracy compared to standard prompting. Typically, the performance boost from CoT prompting is proportional to the model’s size.
Zero-shot chain of Thought (Zero-shot-CoT) prompting is a follow-up to CoT that introduces an incredibly simple zero-shot prompt. By appending the words ”Let’s think step by step.” to the end of a question, LLMs can generate a chain of thoughts that answers the question. Extracting answers from this chain of thought leads to more accurate results. Another follow-up to CoT is Self-consistency <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2022</a>)</cite>, which generates multiple chains of thoughts and selects the majority answer based on a voting strategy as the final answer. Self-consistency has shown improvements in arithmetic, commonsense, and symbolic reasoning tasks. Even when regular CoT is found to be ineffective, self-consistency can still enhance results.
In addition, <cite class="ltx_cite ltx_citemacro_citet">Liu et al<span class="ltx_text">.</span> (<a href="#bib.bib25" title="" class="ltx_ref">2022b</a>)</cite> propose the generated knowledge approach, which prompts the LLM to generate potentially useful information about the question before generating a response.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7. </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">In this paper, we propose a benchmark to compare various input designs in order to study the structural understanding capabilities of LLMs on tables. Surprisingly, we obtain some insights of the input designs and the comparison reveal that LLMs have the basic capabilities towards understanding structural information of tables. We also give some guidance on how to apply our benchmark insights on downstream tasks and propose a simple, generic but effective method, <span id="S7.p1.1.1" class="ltx_text ltx_font_italic">i.e.</span>, self-augmented prompting, by generating additional knowledge with LLMs self-knowledge. We believe this study will be beneficial for table-based, even structured data based research, or serve as a auxiliary tool to help better understand the table(s) from structural perspectives.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Ethical Considerations</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">Structured data often includes metadata, which provides additional information about the data and helps to provide context (<span id="Sx1.p1.1.1" class="ltx_text ltx_font_italic">e.g.</span>, column names, data types, <span id="Sx1.p1.1.2" class="ltx_text ltx_font_italic">etc.</span>). Interpreting and utilizing metadata is a challenge when the meaning and significance of the structured data may not be immediately apparent and must be inferred from the metadata and other contextual clues. This capability is highly dependent on downstream tasks, such as column type prediction <cite class="ltx_cite ltx_citemacro_citep">(Hulsebos et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2022</a>)</cite> and dimension/measure classification <cite class="ltx_cite ltx_citemacro_citep">(He et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2022</a>)</cite>. We believe that understanding this challenge is an important area of research. However, due to space limitations, we will leave this section for further exploration.
Furthermore, our method is primarily designed for languages with limited morphology, such as English. The scalability of our approach to longer texts is a topic that we will explore in more detail.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aggarwal et al<span id="bib.bib2.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Pranjal Aggarwal, Aman Madaan, Yiming Yang, and Mausam. 2023.

</span>
<span class="ltx_bibblock">Let’s Sample Step by Step: Adaptive-Consistency for Efficient Reasoning with LLMs.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2305.11860" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2305.11860</a>
arXiv:2305.11860 [cs]

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aghajanyan et al<span id="bib.bib3.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Armen Aghajanyan, Dmytro Okhonko, Mike Lewis, Mandar Joshi, Hu Xu, Gargi Ghosh, and Luke Zettlemoyer. 2021.

</span>
<span class="ltx_bibblock">HTLM: Hyper-Text Pre-Training and Prompting of Language Models.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2107.06955 [cs]

<a target="_blank" href="http://arxiv.org/abs/2107.06955" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/2107.06955</a>

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aly et al<span id="bib.bib4.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Rami Aly, Zhijiang Guo, Michael Schlichtkrull, James Thorne, Andreas Vlachos, Christos Christodoulopoulos, Oana Cocarascu, and Arpit Mittal. 2021.

</span>
<span class="ltx_bibblock">FEVEROUS: Fact Extraction and VERification Over Unstructured and Structured Information.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2106.05707" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2106.05707</a>
arXiv:2106.05707 [cs]

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al<span id="bib.bib5.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Dhariwal, et al<span id="bib.bib5.3.1" class="ltx_text">.</span> 2020.

</span>
<span class="ltx_bibblock">Language Models Are Few-Shot Learners. In <em id="bib.bib5.4.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, Vol. 33. Curran Associates, Inc., 1877–1901.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html</a>

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib6.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Kaplan, et al<span id="bib.bib6.3.1" class="ltx_text">.</span> 2021.

</span>
<span class="ltx_bibblock">Evaluating Large Language Models Trained on Code.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2107.03374" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2107.03374</a>
arXiv:2107.03374 [cs]

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen (2022)</span>
<span class="ltx_bibblock">
Wenhu Chen. 2022.

</span>
<span class="ltx_bibblock">Large Language Models Are Few(1)-Shot Table Reasoners.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2210.06710" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2210.06710</a>
arXiv:2210.06710 [cs]

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib8.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Wenhu Chen, Hongmin Wang, Jianshu Chen, Yunkai Zhang, Hong Wang, Shiyang Li, Xiyou Zhou, and William Yang Wang. 2020a.

</span>
<span class="ltx_bibblock">TabFact: A Large-Scale Dataset for Table-Based Fact Verification.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.1909.02164" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.1909.02164</a>
arXiv:1909.02164 [cs]

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Wenhu Chen, Hanwen Zha, Zhiyu Chen, Wenhan Xiong, Hong Wang, and William Yang Wang. 2020b.

</span>
<span class="ltx_bibblock">HybridQA: A Dataset of Multi-Hop Question Answering over Tabular and Textual Data. In <em id="bib.bib9.3.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: EMNLP 2020</em>. Association for Computational Linguistics, Online, 1026–1036.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/2020.findings-emnlp.91" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2020.findings-emnlp.91</a>

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chung et al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Alex Castro-Ros, Marie Pellat, Kevin Robinson, Dasha Valter, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin,
Adam Roberts, Denny Zhou, Quoc V. Le, and Jason Wei. 2022.

</span>
<span class="ltx_bibblock">Scaling Instruction-Finetuned Language Models.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2210.11416" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2210.11416</a>
arXiv:2210.11416 [cs]

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cobbe et al<span id="bib.bib11.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. 2021.

</span>
<span class="ltx_bibblock">Training Verifiers to Solve Math Word Problems.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2110.14168" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2110.14168</a>
arXiv:2110.14168 [cs]

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng et al<span id="bib.bib12.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Xiang Deng, Huan Sun, Alyssa Lees, You Wu, and Cong Yu. 2020.

</span>
<span class="ltx_bibblock">TURL: Table Understanding through Representation Learning.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2006.14806" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2006.14806</a>
arXiv:2006.14806 [cs]

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong et al<span id="bib.bib13.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Haoyu Dong, Zhoujun Cheng, Xinyi He, Mengyu Zhou, Anda Zhou, Fan Zhou, Ao Liu, Shi Han, and Dongmei Zhang. 2022.

</span>
<span class="ltx_bibblock">Table Pre-training: A Survey on Model Architectures, Pre-training Objectives, and Downstream Tasks.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2201.09745" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2201.09745</a>
arXiv:2201.09745 [cs]

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dou et al<span id="bib.bib14.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Longxu Dou, Yan Gao, Mingyang Pan, Dingzirui Wang, Wanxiang Che, Dechen Zhan, and Jian-Guang Lou. 2022.

</span>
<span class="ltx_bibblock">UniSAr: A Unified Structure-Aware Autoregressive Language Model for Text-to-SQL.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2203.07781 [cs]

<a target="_blank" href="http://arxiv.org/abs/2203.07781" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/2203.07781</a>

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eisenschlos et al<span id="bib.bib15.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Julian Martin Eisenschlos, Maharshi Gor, Thomas Müller, and William W. Cohen. 2021.

</span>
<span class="ltx_bibblock">MATE: Multi-View Attention for Table Transformer Efficiency.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2109.04312" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2109.04312</a>
arXiv:2109.04312 [cs]

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Engelmann et al<span id="bib.bib16.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Björn Engelmann, Timo Breuer, and Philipp Schaer. 2023.

</span>
<span class="ltx_bibblock">Simulating Users in Interactive Web Table Retrieval. In <em id="bib.bib16.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 32nd ACM International Conference on Information and Knowledge Management</em> (Birmingham, United Kingdom) <em id="bib.bib16.4.2" class="ltx_emph ltx_font_italic">(CIKM ’23)</em>. Association for Computing Machinery, New York, NY, USA, 3875–3879.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3583780.3615187" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3583780.3615187</a>

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gong et al<span id="bib.bib17.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Heng Gong, Yawei Sun, Xiaocheng Feng, Bing Qin, Wei Bi, Xiaojiang Liu, and Ting Liu. 2020.

</span>
<span class="ltx_bibblock">TableGPT: Few-Shot Table-to-Text Generation with Table Structure Reconstruction and Content Matching. In <em id="bib.bib17.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th International Conference on Computational Linguistics</em>. International Committee on Computational Linguistics, Barcelona, Spain (Online), 1978–1988.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/2020.coling-main.179" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2020.coling-main.179</a>

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al<span id="bib.bib18.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Xinyi He, Mengyu Zhou, Jialiang Xu, Xiao Lv, Tianle Li, Yijia Shao, Shi Han, Zejian Yuan, and Dongmei Zhang. 2022.

</span>
<span class="ltx_bibblock">Inferring Tabular Analysis Metadata by Infusing Distribution and Knowledge Information.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2209.00946" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2209.00946</a>
arXiv:2209.00946 [cs]

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Herzig et al<span id="bib.bib19.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Jonathan Herzig, Pawel Krzysztof Nowak, Thomas Müller, Francesco Piccinno, and Julian Eisenschlos. 2020.

</span>
<span class="ltx_bibblock">TaPas: Weakly Supervised Table Parsing via Pre-Training. In <em id="bib.bib19.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>. Association for Computational Linguistics, Online, 4320–4333.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/2020.acl-main.398" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2020.acl-main.398</a>

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hulsebos et al<span id="bib.bib20.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Madelon Hulsebos, Çağatay Demiralp, and Paul Groth. 2022.

</span>
<span class="ltx_bibblock">GitTables: A Large-Scale Corpus of Relational Tables.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2106.07258" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2106.07258</a>
arXiv:2106.07258 [cs]

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iida et al<span id="bib.bib21.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Hiroshi Iida, Dung Thai, Varun Manjunatha, and Mohit Iyyer. 2021.

</span>
<span class="ltx_bibblock">TABBIE: Pretrained Representations of Tabular Data.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2105.02584" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2105.02584</a>
arXiv:2105.02584 [cs]

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iyyer et al<span id="bib.bib22.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Mohit Iyyer, Wen-tau Yih, and Ming-Wei Chang. 2017.

</span>
<span class="ltx_bibblock">Search-Based Neural Structured Learning for Sequential Question Answering. In <em id="bib.bib22.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>. Association for Computational Linguistics, Vancouver, Canada, 1821–1831.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/P17-1167" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/P17-1167</a>

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kojima et al<span id="bib.bib23.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022.

</span>
<span class="ltx_bibblock">Large Language Models Are Zero-Shot Reasoners.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2205.11916" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2205.11916</a>
arXiv:2205.11916 [cs]

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al<span id="bib.bib24.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Stephanie Lin, Jacob Hilton, and Owain Evans. 2022.

</span>
<span class="ltx_bibblock">TruthfulQA: Measuring How Models Mimic Human Falsehoods.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2109.07958 [cs]

<a target="_blank" href="http://arxiv.org/abs/2109.07958" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/2109.07958</a>

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib25.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Jiacheng Liu, Alisa Liu, Ximing Lu, Sean Welleck, Peter West, Ronan Le Bras, Yejin Choi, and Hannaneh Hajishirzi. 2022b.

</span>
<span class="ltx_bibblock">Generated Knowledge Prompting for Commonsense Reasoning.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2110.08387" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2110.08387</a>
arXiv:2110.08387 [cs]

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib26.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Qian Liu, Bei Chen, Jiaqi Guo, Morteza Ziyadi, Zeqi Lin, Weizhu Chen, and Jian-Guang Lou. 2022a.

</span>
<span class="ltx_bibblock">TAPEX: Table Pre-Training via Learning a Neural SQL Executor.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2107.07653" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2107.07653</a>
arXiv:2107.07653 [cs]

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nassar et al<span id="bib.bib27.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Ahmed Nassar, Nikolaos Livathinos, Maksym Lysak, and Peter Staar. 2022.

</span>
<span class="ltx_bibblock">TableFormer: Table Structure Understanding with Transformers.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2203.01017" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2203.01017</a>
arXiv:2203.01017 [cs]

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI. 2023.

</span>
<span class="ltx_bibblock">GPT-4 Technical Report.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2303.08774" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2303.08774</a>
arXiv:2303.08774 [cs]

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et al<span id="bib.bib29.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. 2022.

</span>
<span class="ltx_bibblock">Training Language Models to Follow Instructions with Human Feedback.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2203.02155" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2203.02155</a>
arXiv:2203.02155 [cs]

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Parikh et al<span id="bib.bib30.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Ankur P. Parikh, Xuezhi Wang, Sebastian Gehrmann, Manaal Faruqui, Bhuwan Dhingra, Diyi Yang, and Dipanjan Das. 2020.

</span>
<span class="ltx_bibblock">ToTTo: A Controlled Table-To-Text Generation Dataset.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2004.14373" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2004.14373</a>
arXiv:2004.14373 [cs]

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rae et al<span id="bib.bib31.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Jack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Song, et al<span id="bib.bib31.3.1" class="ltx_text">.</span> 2022.

</span>
<span class="ltx_bibblock">Scaling Language Models: Methods, Analysis &amp; Insights from Training Gopher.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2112.11446" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2112.11446</a>
arXiv:2112.11446 [cs]

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shao et al<span id="bib.bib32.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Yijia Shao, Mengyu Zhou, Yifan Zhong, Tao Wu, Hongwei Han, Shi Han, Gideon Huang, and Dongmei Zhang. 2022.

</span>
<span class="ltx_bibblock">FormLM: Recommending Creation Ideas for Online Forms by Modelling Semantic and Structural Information.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2211.05284" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2211.05284</a>
arXiv:2211.05284 [cs]

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Talmor et al<span id="bib.bib33.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Alon Talmor, Ori Yoran, Amnon Catav, Dan Lahav, Yizhong Wang, Akari Asai, Gabriel Ilharco, Hannaneh Hajishirzi, and Jonathan Berant. 2021.

</span>
<span class="ltx_bibblock">MultiModalQA: Complex Question Answering over Text, Tables and Images.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2104.06039" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2104.06039</a>
arXiv:2104.06039 [cs]

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tay et al<span id="bib.bib34.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Yi Tay, Mostafa Dehghani, Dara Bahri, and Donald Metzler. 2022.

</span>
<span class="ltx_bibblock">Efficient Transformers: A Survey.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2009.06732" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2009.06732</a>
arXiv:2009.06732 [cs]

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Trabelsi et al<span id="bib.bib35.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Mohamed Trabelsi, Zhiyu Chen, Shuo Zhang, Brian D. Davison, and Jeff Heflin. 2022.

</span>
<span class="ltx_bibblock">StruBERT: Structure-aware BERT for Table Search and Matching. In <em id="bib.bib35.3.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM Web Conference 2022</em>. ACM.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3485447.3511972" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3485447.3511972</a>

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al<span id="bib.bib36.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017.

</span>
<span class="ltx_bibblock">Attention Is All You Need. In <em id="bib.bib36.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, Vol. 30. Curran Associates, Inc.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html</a>

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib37.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2022.

</span>
<span class="ltx_bibblock">Self-Consistency Improves Chain of Thought Reasoning in Language Models.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2203.11171" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2203.11171</a>
arXiv:2203.11171 [cs]

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib38.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Zhiruo Wang, Haoyu Dong, Ran Jia, Jia Li, Zhiyi Fu, Shi Han, and Dongmei Zhang. 2021.

</span>
<span class="ltx_bibblock">TUTA: Tree-Based Transformers for Generally Structured Table Pre-Training. In <em id="bib.bib38.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</em>. 1780–1790.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3447548.3467434" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3447548.3467434</a>
arXiv:2010.12537 [cs]

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al<span id="bib.bib39.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2022.

</span>
<span class="ltx_bibblock">Chain of Thought Prompting Elicits Reasoning in Large Language Models.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2201.11903" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2201.11903</a>
arXiv:2201.11903 [cs]

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al<span id="bib.bib40.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Tianbao Xie, Chen Henry Wu, Peng Shi, Ruiqi Zhong, Torsten Scholak, Michihiro Yasunaga, Chien-Sheng Wu, Ming Zhong, Pengcheng Yin, Sida I. Wang, Victor Zhong, Bailin Wang, Chengzu Li, Connor Boyle, Ansong Ni, Ziyu Yao, Dragomir Radev, Caiming Xiong, Lingpeng Kong, Rui Zhang, Noah A. Smith, Luke Zettlemoyer, and Tao Yu. 2022.

</span>
<span class="ltx_bibblock">UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2201.05966" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2201.05966</a>
arXiv:2201.05966 [cs]

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al<span id="bib.bib41.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Pengcheng Yin, Graham Neubig, Wen-tau Yih, and Sebastian Riedel. 2020.

</span>
<span class="ltx_bibblock">TaBERT: Pretraining for Joint Understanding of Textual and Tabular Data. In <em id="bib.bib41.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>. Association for Computational Linguistics, Online, 8413–8426.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/2020.acl-main.745" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2020.acl-main.745</a>

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang and Balog (2020)</span>
<span class="ltx_bibblock">
Shuo Zhang and Krisztian Balog. 2020.

</span>
<span class="ltx_bibblock">Web Table Extraction, Retrieval and Augmentation: A Survey.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/ARXIV.2002.00207" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/ARXIV.2002.00207</a>

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib43.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Shun Zhang, Zhenfang Chen, Yikang Shen, Mingyu Ding, Joshua B. Tenenbaum, and Chuang Gan. 2023.

</span>
<span class="ltx_bibblock">Planning with Large Language Models for Code Generation.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.2303.05510" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.2303.05510</a>
arXiv:2303.05510 [cs]

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2>

<figure id="A1.T7" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7. </span>Full results of the downstream tasks.</figcaption>
<div id="A1.T7.8" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:204.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-202.4pt,95.6pt) scale(0.517222412925118,0.517222412925118) ;">
<table id="A1.T7.8.8" class="ltx_tabular ltx_align_middle">
<tr id="A1.T7.8.8.9" class="ltx_tr">
<td id="A1.T7.8.8.9.1" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="A1.T7.8.8.9.1.1" class="ltx_text">Input Design</span></td>
<td id="A1.T7.8.8.9.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">TabFact</td>
<td id="A1.T7.8.8.9.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">HybridQA</td>
<td id="A1.T7.8.8.9.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">SQA</td>
<td id="A1.T7.8.8.9.5" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">Feverous</td>
<td id="A1.T7.8.8.9.6" class="ltx_td ltx_align_center ltx_border_tt" colspan="8">ToTTo</td>
</tr>
<tr id="A1.T7.8.8.8" class="ltx_tr">
<td id="A1.T7.8.8.8.9" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="A1.T7.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T7.1.1.1.1.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="A1.T7.1.1.1.1.m1.1a"><mi mathvariant="normal" id="A1.T7.1.1.1.1.m1.1.1" xref="A1.T7.1.1.1.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="A1.T7.1.1.1.1.m1.1b"><ci id="A1.T7.1.1.1.1.m1.1.1.cmml" xref="A1.T7.1.1.1.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T7.1.1.1.1.m1.1c">\Delta</annotation></semantics></math></td>
<td id="A1.T7.8.8.8.10" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="A1.T7.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T7.2.2.2.2.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="A1.T7.2.2.2.2.m1.1a"><mi mathvariant="normal" id="A1.T7.2.2.2.2.m1.1.1" xref="A1.T7.2.2.2.2.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="A1.T7.2.2.2.2.m1.1b"><ci id="A1.T7.2.2.2.2.m1.1.1.cmml" xref="A1.T7.2.2.2.2.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T7.2.2.2.2.m1.1c">\Delta</annotation></semantics></math></td>
<td id="A1.T7.8.8.8.11" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="A1.T7.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T7.3.3.3.3.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="A1.T7.3.3.3.3.m1.1a"><mi mathvariant="normal" id="A1.T7.3.3.3.3.m1.1.1" xref="A1.T7.3.3.3.3.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="A1.T7.3.3.3.3.m1.1b"><ci id="A1.T7.3.3.3.3.m1.1.1.cmml" xref="A1.T7.3.3.3.3.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T7.3.3.3.3.m1.1c">\Delta</annotation></semantics></math></td>
<td id="A1.T7.8.8.8.12" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="A1.T7.4.4.4.4" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T7.4.4.4.4.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="A1.T7.4.4.4.4.m1.1a"><mi mathvariant="normal" id="A1.T7.4.4.4.4.m1.1.1" xref="A1.T7.4.4.4.4.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="A1.T7.4.4.4.4.m1.1b"><ci id="A1.T7.4.4.4.4.m1.1.1.cmml" xref="A1.T7.4.4.4.4.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T7.4.4.4.4.m1.1c">\Delta</annotation></semantics></math></td>
<td id="A1.T7.8.8.8.13" class="ltx_td ltx_align_center ltx_border_t">BLEU-1</td>
<td id="A1.T7.5.5.5.5" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T7.5.5.5.5.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="A1.T7.5.5.5.5.m1.1a"><mi mathvariant="normal" id="A1.T7.5.5.5.5.m1.1.1" xref="A1.T7.5.5.5.5.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="A1.T7.5.5.5.5.m1.1b"><ci id="A1.T7.5.5.5.5.m1.1.1.cmml" xref="A1.T7.5.5.5.5.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T7.5.5.5.5.m1.1c">\Delta</annotation></semantics></math></td>
<td id="A1.T7.8.8.8.14" class="ltx_td ltx_align_center ltx_border_t">BLEU-2</td>
<td id="A1.T7.6.6.6.6" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T7.6.6.6.6.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="A1.T7.6.6.6.6.m1.1a"><mi mathvariant="normal" id="A1.T7.6.6.6.6.m1.1.1" xref="A1.T7.6.6.6.6.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="A1.T7.6.6.6.6.m1.1b"><ci id="A1.T7.6.6.6.6.m1.1.1.cmml" xref="A1.T7.6.6.6.6.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T7.6.6.6.6.m1.1c">\Delta</annotation></semantics></math></td>
<td id="A1.T7.8.8.8.15" class="ltx_td ltx_align_center ltx_border_t">BLEU-3</td>
<td id="A1.T7.7.7.7.7" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T7.7.7.7.7.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="A1.T7.7.7.7.7.m1.1a"><mi mathvariant="normal" id="A1.T7.7.7.7.7.m1.1.1" xref="A1.T7.7.7.7.7.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="A1.T7.7.7.7.7.m1.1b"><ci id="A1.T7.7.7.7.7.m1.1.1.cmml" xref="A1.T7.7.7.7.7.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T7.7.7.7.7.m1.1c">\Delta</annotation></semantics></math></td>
<td id="A1.T7.8.8.8.16" class="ltx_td ltx_align_center ltx_border_t">BLEU-4</td>
<td id="A1.T7.8.8.8.8" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T7.8.8.8.8.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="A1.T7.8.8.8.8.m1.1a"><mi mathvariant="normal" id="A1.T7.8.8.8.8.m1.1.1" xref="A1.T7.8.8.8.8.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="A1.T7.8.8.8.8.m1.1b"><ci id="A1.T7.8.8.8.8.m1.1.1.cmml" xref="A1.T7.8.8.8.8.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T7.8.8.8.8.m1.1c">\Delta</annotation></semantics></math></td>
</tr>
<tr id="A1.T7.8.8.10" class="ltx_tr">
<td id="A1.T7.8.8.10.1" class="ltx_td ltx_align_left ltx_border_t"><span id="A1.T7.8.8.10.1.1" class="ltx_text ltx_font_bold">NL + Sep</span></td>
<td id="A1.T7.8.8.10.2" class="ltx_td ltx_align_center ltx_border_t">70.26%</td>
<td id="A1.T7.8.8.10.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.10.3.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.10.4" class="ltx_td ltx_align_center ltx_border_t">45.02%</td>
<td id="A1.T7.8.8.10.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.10.5.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.10.6" class="ltx_td ltx_align_center ltx_border_t">70.41%</td>
<td id="A1.T7.8.8.10.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.10.7.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.10.8" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T7.8.8.10.8.1" class="ltx_text ltx_font_bold">75.15%</span></td>
<td id="A1.T7.8.8.10.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.10.9.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.10.10" class="ltx_td ltx_align_center ltx_border_t">67.64%</td>
<td id="A1.T7.8.8.10.11" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.10.11.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.10.12" class="ltx_td ltx_align_center ltx_border_t">38.25%</td>
<td id="A1.T7.8.8.10.13" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.10.13.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.10.14" class="ltx_td ltx_align_center ltx_border_t">21.28%</td>
<td id="A1.T7.8.8.10.15" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.10.15.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.10.16" class="ltx_td ltx_align_center ltx_border_t">12.70%</td>
<td id="A1.T7.8.8.10.17" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.10.17.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
</tr>
<tr id="A1.T7.8.8.11" class="ltx_tr">
<td id="A1.T7.8.8.11.1" class="ltx_td ltx_align_left">w/o format explanation</td>
<td id="A1.T7.8.8.11.2" class="ltx_td ltx_align_center">69.61%</td>
<td id="A1.T7.8.8.11.3" class="ltx_td ltx_align_center" style="background-color:#FBF5F8;"><span id="A1.T7.8.8.11.3.1" class="ltx_text" style="background-color:#FBF5F8;">-0.65%</span></td>
<td id="A1.T7.8.8.11.4" class="ltx_td ltx_align_center">44.28%</td>
<td id="A1.T7.8.8.11.5" class="ltx_td ltx_align_center" style="background-color:#FBF4F7;"><span id="A1.T7.8.8.11.5.1" class="ltx_text" style="background-color:#FBF4F7;">-0.74%</span></td>
<td id="A1.T7.8.8.11.6" class="ltx_td ltx_align_center">70.92%</td>
<td id="A1.T7.8.8.11.7" class="ltx_td ltx_align_center" style="background-color:#F7F9FE;"><span id="A1.T7.8.8.11.7.1" class="ltx_text" style="background-color:#F7F9FE;">0.51%</span></td>
<td id="A1.T7.8.8.11.8" class="ltx_td ltx_align_center">71.03%</td>
<td id="A1.T7.8.8.11.9" class="ltx_td ltx_align_center" style="background-color:#FAD3D6;"><span id="A1.T7.8.8.11.9.1" class="ltx_text" style="background-color:#FAD3D6;">-4.12%</span></td>
<td id="A1.T7.8.8.11.10" class="ltx_td ltx_align_center">72.49%</td>
<td id="A1.T7.8.8.11.11" class="ltx_td ltx_align_center" style="background-color:#C8D8ED;"><span id="A1.T7.8.8.11.11.1" class="ltx_text" style="background-color:#C8D8ED;">4.84%</span></td>
<td id="A1.T7.8.8.11.12" class="ltx_td ltx_align_center"><span id="A1.T7.8.8.11.12.1" class="ltx_text ltx_font_bold">42.50%</span></td>
<td id="A1.T7.8.8.11.13" class="ltx_td ltx_align_center" style="background-color:#CFDCEF;"><span id="A1.T7.8.8.11.13.1" class="ltx_text" style="background-color:#CFDCEF;">4.25%</span></td>
<td id="A1.T7.8.8.11.14" class="ltx_td ltx_align_center"><span id="A1.T7.8.8.11.14.1" class="ltx_text ltx_font_bold">24.32%</span></td>
<td id="A1.T7.8.8.11.15" class="ltx_td ltx_align_center" style="background-color:#DCE5F4;"><span id="A1.T7.8.8.11.15.1" class="ltx_text" style="background-color:#DCE5F4;">3.04%</span></td>
<td id="A1.T7.8.8.11.16" class="ltx_td ltx_align_center"><span id="A1.T7.8.8.11.16.1" class="ltx_text ltx_font_bold">13.71%</span></td>
<td id="A1.T7.8.8.11.17" class="ltx_td ltx_align_center" style="background-color:#F2F5FC;"><span id="A1.T7.8.8.11.17.1" class="ltx_text" style="background-color:#F2F5FC;">1.01%</span></td>
</tr>
<tr id="A1.T7.8.8.12" class="ltx_tr">
<td id="A1.T7.8.8.12.1" class="ltx_td ltx_align_left">w/o partition mark</td>
<td id="A1.T7.8.8.12.2" class="ltx_td ltx_align_center">69.12%</td>
<td id="A1.T7.8.8.12.3" class="ltx_td ltx_align_center" style="background-color:#FBF0F3;"><span id="A1.T7.8.8.12.3.1" class="ltx_text" style="background-color:#FBF0F3;">-1.14%</span></td>
<td id="A1.T7.8.8.12.4" class="ltx_td ltx_align_center">43.68%</td>
<td id="A1.T7.8.8.12.5" class="ltx_td ltx_align_center" style="background-color:#FBEEF1;"><span id="A1.T7.8.8.12.5.1" class="ltx_text" style="background-color:#FBEEF1;">-1.35%</span></td>
<td id="A1.T7.8.8.12.6" class="ltx_td ltx_align_center"><span id="A1.T7.8.8.12.6.1" class="ltx_text ltx_font_bold">71.79%</span></td>
<td id="A1.T7.8.8.12.7" class="ltx_td ltx_align_center" style="background-color:#EEF2FA;"><span id="A1.T7.8.8.12.7.1" class="ltx_text" style="background-color:#EEF2FA;">1.38%</span></td>
<td id="A1.T7.8.8.12.8" class="ltx_td ltx_align_center"><span id="A1.T7.8.8.12.8.1" class="ltx_text ltx_font_bold">74.37%</span></td>
<td id="A1.T7.8.8.12.9" class="ltx_td ltx_align_center" style="background-color:#FBF4F7;"><span id="A1.T7.8.8.12.9.1" class="ltx_text" style="background-color:#FBF4F7;">-0.78%</span></td>
<td id="A1.T7.8.8.12.10" class="ltx_td ltx_align_center">73.29%</td>
<td id="A1.T7.8.8.12.11" class="ltx_td ltx_align_center" style="background-color:#BFD2EA;"><span id="A1.T7.8.8.12.11.1" class="ltx_text" style="background-color:#BFD2EA;">5.65%</span></td>
<td id="A1.T7.8.8.12.12" class="ltx_td ltx_align_center"><span id="A1.T7.8.8.12.12.1" class="ltx_text ltx_font_bold">40.99%</span></td>
<td id="A1.T7.8.8.12.13" class="ltx_td ltx_align_center" style="background-color:#DFE8F5;"><span id="A1.T7.8.8.12.13.1" class="ltx_text" style="background-color:#DFE8F5;">2.73%</span></td>
<td id="A1.T7.8.8.12.14" class="ltx_td ltx_align_center"><span id="A1.T7.8.8.12.14.1" class="ltx_text ltx_font_bold">22.58%</span></td>
<td id="A1.T7.8.8.12.15" class="ltx_td ltx_align_center" style="background-color:#EFF3FB;"><span id="A1.T7.8.8.12.15.1" class="ltx_text" style="background-color:#EFF3FB;">1.29%</span></td>
<td id="A1.T7.8.8.12.16" class="ltx_td ltx_align_center">13.28%</td>
<td id="A1.T7.8.8.12.17" class="ltx_td ltx_align_center" style="background-color:#F6F8FD;"><span id="A1.T7.8.8.12.17.1" class="ltx_text" style="background-color:#F6F8FD;">0.58%</span></td>
</tr>
<tr id="A1.T7.8.8.13" class="ltx_tr">
<td id="A1.T7.8.8.13.1" class="ltx_td ltx_align_left">w/o role prompting</td>
<td id="A1.T7.8.8.13.2" class="ltx_td ltx_align_center">68.89%</td>
<td id="A1.T7.8.8.13.3" class="ltx_td ltx_align_center" style="background-color:#FBEEF1;"><span id="A1.T7.8.8.13.3.1" class="ltx_text" style="background-color:#FBEEF1;">-1.37%</span></td>
<td id="A1.T7.8.8.13.4" class="ltx_td ltx_align_center">42.88%</td>
<td id="A1.T7.8.8.13.5" class="ltx_td ltx_align_center" style="background-color:#FBE6E9;"><span id="A1.T7.8.8.13.5.1" class="ltx_text" style="background-color:#FBE6E9;">-2.14%</span></td>
<td id="A1.T7.8.8.13.6" class="ltx_td ltx_align_center">70.74%</td>
<td id="A1.T7.8.8.13.7" class="ltx_td ltx_align_center" style="background-color:#F9FAFE;"><span id="A1.T7.8.8.13.7.1" class="ltx_text" style="background-color:#F9FAFE;">0.33%</span></td>
<td id="A1.T7.8.8.13.8" class="ltx_td ltx_align_center">73.71%</td>
<td id="A1.T7.8.8.13.9" class="ltx_td ltx_align_center" style="background-color:#FBEDF0;"><span id="A1.T7.8.8.13.9.1" class="ltx_text" style="background-color:#FBEDF0;">-1.45%</span></td>
<td id="A1.T7.8.8.13.10" class="ltx_td ltx_align_center">48.58%</td>
<td id="A1.T7.8.8.13.11" class="ltx_td ltx_align_center" style="background-color:#F8696B;"><span id="A1.T7.8.8.13.11.1" class="ltx_text" style="background-color:#F8696B;">-19.06%</span></td>
<td id="A1.T7.8.8.13.12" class="ltx_td ltx_align_center">28.49%</td>
<td id="A1.T7.8.8.13.13" class="ltx_td ltx_align_center" style="background-color:#F99C9E;"><span id="A1.T7.8.8.13.13.1" class="ltx_text" style="background-color:#F99C9E;">-9.76%</span></td>
<td id="A1.T7.8.8.13.14" class="ltx_td ltx_align_center">16.35%</td>
<td id="A1.T7.8.8.13.15" class="ltx_td ltx_align_center" style="background-color:#FACBCE;"><span id="A1.T7.8.8.13.15.1" class="ltx_text" style="background-color:#FACBCE;">-4.93%</span></td>
<td id="A1.T7.8.8.13.16" class="ltx_td ltx_align_center">9.83%</td>
<td id="A1.T7.8.8.13.17" class="ltx_td ltx_align_center" style="background-color:#FBDFE2;"><span id="A1.T7.8.8.13.17.1" class="ltx_text" style="background-color:#FBDFE2;">-2.87%</span></td>
</tr>
<tr id="A1.T7.8.8.14" class="ltx_tr">
<td id="A1.T7.8.8.14.1" class="ltx_td ltx_align_left ltx_border_t"><span id="A1.T7.8.8.14.1.1" class="ltx_text ltx_font_bold">Markup Lan. Markdown</span></td>
<td id="A1.T7.8.8.14.2" class="ltx_td ltx_align_center ltx_border_t">68.40%</td>
<td id="A1.T7.8.8.14.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.14.3.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.14.4" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T7.8.8.14.4.1" class="ltx_text ltx_font_bold">45.88%</span></td>
<td id="A1.T7.8.8.14.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.14.5.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.14.6" class="ltx_td ltx_align_center ltx_border_t">66.59%</td>
<td id="A1.T7.8.8.14.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.14.7.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.14.8" class="ltx_td ltx_align_center ltx_border_t">71.88%</td>
<td id="A1.T7.8.8.14.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.14.9.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.14.10" class="ltx_td ltx_align_center ltx_border_t">63.96%</td>
<td id="A1.T7.8.8.14.11" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.14.11.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.14.12" class="ltx_td ltx_align_center ltx_border_t">33.44%</td>
<td id="A1.T7.8.8.14.13" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.14.13.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.14.14" class="ltx_td ltx_align_center ltx_border_t">15.82%</td>
<td id="A1.T7.8.8.14.15" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.14.15.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.14.16" class="ltx_td ltx_align_center ltx_border_t">8.57%</td>
<td id="A1.T7.8.8.14.17" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.14.17.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
</tr>
<tr id="A1.T7.8.8.15" class="ltx_tr">
<td id="A1.T7.8.8.15.1" class="ltx_td ltx_align_left">w/o format explanation</td>
<td id="A1.T7.8.8.15.2" class="ltx_td ltx_align_center">67.90%</td>
<td id="A1.T7.8.8.15.3" class="ltx_td ltx_align_center" style="background-color:#FBF7FA;"><span id="A1.T7.8.8.15.3.1" class="ltx_text" style="background-color:#FBF7FA;">-0.51%</span></td>
<td id="A1.T7.8.8.15.4" class="ltx_td ltx_align_center">43.09%</td>
<td id="A1.T7.8.8.15.5" class="ltx_td ltx_align_center" style="background-color:#FBE0E3;"><span id="A1.T7.8.8.15.5.1" class="ltx_text" style="background-color:#FBE0E3;">-2.80%</span></td>
<td id="A1.T7.8.8.15.6" class="ltx_td ltx_align_center">66.96%</td>
<td id="A1.T7.8.8.15.7" class="ltx_td ltx_align_center" style="background-color:#F9FAFE;"><span id="A1.T7.8.8.15.7.1" class="ltx_text" style="background-color:#F9FAFE;">0.36%</span></td>
<td id="A1.T7.8.8.15.8" class="ltx_td ltx_align_center">65.97%</td>
<td id="A1.T7.8.8.15.9" class="ltx_td ltx_align_center" style="background-color:#FAC2C4;"><span id="A1.T7.8.8.15.9.1" class="ltx_text" style="background-color:#FAC2C4;">-5.91%</span></td>
<td id="A1.T7.8.8.15.10" class="ltx_td ltx_align_center">70.41%</td>
<td id="A1.T7.8.8.15.11" class="ltx_td ltx_align_center" style="background-color:#B7CCE7;"><span id="A1.T7.8.8.15.11.1" class="ltx_text" style="background-color:#B7CCE7;">6.45%</span></td>
<td id="A1.T7.8.8.15.12" class="ltx_td ltx_align_center">38.79%</td>
<td id="A1.T7.8.8.15.13" class="ltx_td ltx_align_center" style="background-color:#C3D4EB;"><span id="A1.T7.8.8.15.13.1" class="ltx_text" style="background-color:#C3D4EB;">5.35%</span></td>
<td id="A1.T7.8.8.15.14" class="ltx_td ltx_align_center">18.71%</td>
<td id="A1.T7.8.8.15.15" class="ltx_td ltx_align_center" style="background-color:#DDE7F5;"><span id="A1.T7.8.8.15.15.1" class="ltx_text" style="background-color:#DDE7F5;">2.89%</span></td>
<td id="A1.T7.8.8.15.16" class="ltx_td ltx_align_center"><span id="A1.T7.8.8.15.16.1" class="ltx_text ltx_font_bold">18.71%</span></td>
<td id="A1.T7.8.8.15.17" class="ltx_td ltx_align_center" style="background-color:#8FAFD9;"><span id="A1.T7.8.8.15.17.1" class="ltx_text" style="background-color:#8FAFD9;">10.14%</span></td>
</tr>
<tr id="A1.T7.8.8.16" class="ltx_tr">
<td id="A1.T7.8.8.16.1" class="ltx_td ltx_align_left">w/o partition mark</td>
<td id="A1.T7.8.8.16.2" class="ltx_td ltx_align_center">67.53%</td>
<td id="A1.T7.8.8.16.3" class="ltx_td ltx_align_center" style="background-color:#FBF3F6;"><span id="A1.T7.8.8.16.3.1" class="ltx_text" style="background-color:#FBF3F6;">-0.87%</span></td>
<td id="A1.T7.8.8.16.4" class="ltx_td ltx_align_center">42.61%</td>
<td id="A1.T7.8.8.16.5" class="ltx_td ltx_align_center" style="background-color:#FBDBDE;"><span id="A1.T7.8.8.16.5.1" class="ltx_text" style="background-color:#FBDBDE;">-3.27%</span></td>
<td id="A1.T7.8.8.16.6" class="ltx_td ltx_align_center">67.27%</td>
<td id="A1.T7.8.8.16.7" class="ltx_td ltx_align_center" style="background-color:#F5F7FD;"><span id="A1.T7.8.8.16.7.1" class="ltx_text" style="background-color:#F5F7FD;">0.68%</span></td>
<td id="A1.T7.8.8.16.8" class="ltx_td ltx_align_center">70.34%</td>
<td id="A1.T7.8.8.16.9" class="ltx_td ltx_align_center" style="background-color:#FBECEF;"><span id="A1.T7.8.8.16.9.1" class="ltx_text" style="background-color:#FBECEF;">-1.54%</span></td>
<td id="A1.T7.8.8.16.10" class="ltx_td ltx_align_center">67.97%</td>
<td id="A1.T7.8.8.16.11" class="ltx_td ltx_align_center" style="background-color:#D1DEF0;"><span id="A1.T7.8.8.16.11.1" class="ltx_text" style="background-color:#D1DEF0;">4.01%</span></td>
<td id="A1.T7.8.8.16.12" class="ltx_td ltx_align_center">33.59%</td>
<td id="A1.T7.8.8.16.13" class="ltx_td ltx_align_center" style="background-color:#FBFBFF;"><span id="A1.T7.8.8.16.13.1" class="ltx_text" style="background-color:#FBFBFF;">0.15%</span></td>
<td id="A1.T7.8.8.16.14" class="ltx_td ltx_align_center">18.12%</td>
<td id="A1.T7.8.8.16.15" class="ltx_td ltx_align_center" style="background-color:#E4EBF7;"><span id="A1.T7.8.8.16.15.1" class="ltx_text" style="background-color:#E4EBF7;">2.30%</span></td>
<td id="A1.T7.8.8.16.16" class="ltx_td ltx_align_center">10.08%</td>
<td id="A1.T7.8.8.16.17" class="ltx_td ltx_align_center" style="background-color:#ECF1FA;"><span id="A1.T7.8.8.16.17.1" class="ltx_text" style="background-color:#ECF1FA;">1.51%</span></td>
</tr>
<tr id="A1.T7.8.8.17" class="ltx_tr">
<td id="A1.T7.8.8.17.1" class="ltx_td ltx_align_left">w/o role prompting</td>
<td id="A1.T7.8.8.17.2" class="ltx_td ltx_align_center">67.74%</td>
<td id="A1.T7.8.8.17.3" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.17.3.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.17.4" class="ltx_td ltx_align_center">42.77%</td>
<td id="A1.T7.8.8.17.5" class="ltx_td ltx_align_center" style="background-color:#FBDDE0;"><span id="A1.T7.8.8.17.5.1" class="ltx_text" style="background-color:#FBDDE0;">-3.11%</span></td>
<td id="A1.T7.8.8.17.6" class="ltx_td ltx_align_center">66.33%</td>
<td id="A1.T7.8.8.17.7" class="ltx_td ltx_align_center" style="background-color:#FBF9FC;"><span id="A1.T7.8.8.17.7.1" class="ltx_text" style="background-color:#FBF9FC;">-0.26%</span></td>
<td id="A1.T7.8.8.17.8" class="ltx_td ltx_align_center">70.19%</td>
<td id="A1.T7.8.8.17.9" class="ltx_td ltx_align_center" style="background-color:#FBEBEE;"><span id="A1.T7.8.8.17.9.1" class="ltx_text" style="background-color:#FBEBEE;">-1.69%</span></td>
<td id="A1.T7.8.8.17.10" class="ltx_td ltx_align_center">58.63%</td>
<td id="A1.T7.8.8.17.11" class="ltx_td ltx_align_center" style="background-color:#FAC7CA;"><span id="A1.T7.8.8.17.11.1" class="ltx_text" style="background-color:#FAC7CA;">-5.33%</span></td>
<td id="A1.T7.8.8.17.12" class="ltx_td ltx_align_center">25.31%</td>
<td id="A1.T7.8.8.17.13" class="ltx_td ltx_align_center" style="background-color:#F9ACAE;"><span id="A1.T7.8.8.17.13.1" class="ltx_text" style="background-color:#F9ACAE;">-8.13%</span></td>
<td id="A1.T7.8.8.17.14" class="ltx_td ltx_align_center">9.94%</td>
<td id="A1.T7.8.8.17.15" class="ltx_td ltx_align_center" style="background-color:#FAC2C4;"><span id="A1.T7.8.8.17.15.1" class="ltx_text" style="background-color:#FAC2C4;">-5.88%</span></td>
<td id="A1.T7.8.8.17.16" class="ltx_td ltx_align_center">5.40%</td>
<td id="A1.T7.8.8.17.17" class="ltx_td ltx_align_center" style="background-color:#FBDCDF;"><span id="A1.T7.8.8.17.17.1" class="ltx_text" style="background-color:#FBDCDF;">-3.17%</span></td>
</tr>
<tr id="A1.T7.8.8.18" class="ltx_tr">
<td id="A1.T7.8.8.18.1" class="ltx_td ltx_align_left ltx_border_t"><span id="A1.T7.8.8.18.1.1" class="ltx_text ltx_font_bold">Storing Lan. JSON</span></td>
<td id="A1.T7.8.8.18.2" class="ltx_td ltx_align_center ltx_border_t">68.04%</td>
<td id="A1.T7.8.8.18.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.18.3.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.18.4" class="ltx_td ltx_align_center ltx_border_t">42.40%</td>
<td id="A1.T7.8.8.18.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.18.5.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.18.6" class="ltx_td ltx_align_center ltx_border_t">70.39%</td>
<td id="A1.T7.8.8.18.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.18.7.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.18.8" class="ltx_td ltx_align_center ltx_border_t">73.84%</td>
<td id="A1.T7.8.8.18.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.18.9.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.18.10" class="ltx_td ltx_align_center ltx_border_t">63.99%</td>
<td id="A1.T7.8.8.18.11" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.18.11.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.18.12" class="ltx_td ltx_align_center ltx_border_t">28.14%</td>
<td id="A1.T7.8.8.18.13" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.18.13.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.18.14" class="ltx_td ltx_align_center ltx_border_t">15.23%</td>
<td id="A1.T7.8.8.18.15" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.18.15.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.18.16" class="ltx_td ltx_align_center ltx_border_t">8.82%</td>
<td id="A1.T7.8.8.18.17" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.18.17.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
</tr>
<tr id="A1.T7.8.8.19" class="ltx_tr">
<td id="A1.T7.8.8.19.1" class="ltx_td ltx_align_left">w/o format explanation</td>
<td id="A1.T7.8.8.19.2" class="ltx_td ltx_align_center">67.96%</td>
<td id="A1.T7.8.8.19.3" class="ltx_td ltx_align_center" style="background-color:#FBFBFE;"><span id="A1.T7.8.8.19.3.1" class="ltx_text" style="background-color:#FBFBFE;">-0.08%</span></td>
<td id="A1.T7.8.8.19.4" class="ltx_td ltx_align_center">41.35%</td>
<td id="A1.T7.8.8.19.5" class="ltx_td ltx_align_center" style="background-color:#FBF1F4;"><span id="A1.T7.8.8.19.5.1" class="ltx_text" style="background-color:#FBF1F4;">-1.05%</span></td>
<td id="A1.T7.8.8.19.6" class="ltx_td ltx_align_center">70.85%</td>
<td id="A1.T7.8.8.19.7" class="ltx_td ltx_align_center" style="background-color:#F2F5FC;"><span id="A1.T7.8.8.19.7.1" class="ltx_text" style="background-color:#F2F5FC;">0.98%</span></td>
<td id="A1.T7.8.8.19.8" class="ltx_td ltx_align_center">73.51%</td>
<td id="A1.T7.8.8.19.9" class="ltx_td ltx_align_center" style="background-color:#FBF8FB;"><span id="A1.T7.8.8.19.9.1" class="ltx_text" style="background-color:#FBF8FB;">-0.33%</span></td>
<td id="A1.T7.8.8.19.10" class="ltx_td ltx_align_center">72.59%</td>
<td id="A1.T7.8.8.19.11" class="ltx_td ltx_align_center" style="background-color:#A0BBDF;"><span id="A1.T7.8.8.19.11.1" class="ltx_text" style="background-color:#A0BBDF;">8.60%</span></td>
<td id="A1.T7.8.8.19.12" class="ltx_td ltx_align_center">31.78%</td>
<td id="A1.T7.8.8.19.13" class="ltx_td ltx_align_center" style="background-color:#D5E1F2;"><span id="A1.T7.8.8.19.13.1" class="ltx_text" style="background-color:#D5E1F2;">3.63%</span></td>
<td id="A1.T7.8.8.19.14" class="ltx_td ltx_align_center">20.30%</td>
<td id="A1.T7.8.8.19.15" class="ltx_td ltx_align_center" style="background-color:#C6D6EC;"><span id="A1.T7.8.8.19.15.1" class="ltx_text" style="background-color:#C6D6EC;">5.07%</span></td>
<td id="A1.T7.8.8.19.16" class="ltx_td ltx_align_center">11.73%</td>
<td id="A1.T7.8.8.19.17" class="ltx_td ltx_align_center" style="background-color:#DDE6F4;"><span id="A1.T7.8.8.19.17.1" class="ltx_text" style="background-color:#DDE6F4;">2.91%</span></td>
</tr>
<tr id="A1.T7.8.8.20" class="ltx_tr">
<td id="A1.T7.8.8.20.1" class="ltx_td ltx_align_left">w/o partition mark</td>
<td id="A1.T7.8.8.20.2" class="ltx_td ltx_align_center">67.65%</td>
<td id="A1.T7.8.8.20.3" class="ltx_td ltx_align_center" style="background-color:#FBF8FB;"><span id="A1.T7.8.8.20.3.1" class="ltx_text" style="background-color:#FBF8FB;">-0.40%</span></td>
<td id="A1.T7.8.8.20.4" class="ltx_td ltx_align_center">42.40%</td>
<td id="A1.T7.8.8.20.5" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.20.5.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.20.6" class="ltx_td ltx_align_center">69.96%</td>
<td id="A1.T7.8.8.20.7" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.20.7.1" class="ltx_text" style="background-color:#FCFCFF;">0.09%</span></td>
<td id="A1.T7.8.8.20.8" class="ltx_td ltx_align_center">72.83%</td>
<td id="A1.T7.8.8.20.9" class="ltx_td ltx_align_center" style="background-color:#FBF2F5;"><span id="A1.T7.8.8.20.9.1" class="ltx_text" style="background-color:#FBF2F5;">-1.01%</span></td>
<td id="A1.T7.8.8.20.10" class="ltx_td ltx_align_center">63.97%</td>
<td id="A1.T7.8.8.20.11" class="ltx_td ltx_align_center" style="background-color:#FBFBFE;"><span id="A1.T7.8.8.20.11.1" class="ltx_text" style="background-color:#FBFBFE;">-0.02%</span></td>
<td id="A1.T7.8.8.20.12" class="ltx_td ltx_align_center">33.97%</td>
<td id="A1.T7.8.8.20.13" class="ltx_td ltx_align_center" style="background-color:#BED0E9;"><span id="A1.T7.8.8.20.13.1" class="ltx_text" style="background-color:#BED0E9;">5.83%</span></td>
<td id="A1.T7.8.8.20.14" class="ltx_td ltx_align_center">17.54%</td>
<td id="A1.T7.8.8.20.15" class="ltx_td ltx_align_center" style="background-color:#E4EBF7;"><span id="A1.T7.8.8.20.15.1" class="ltx_text" style="background-color:#E4EBF7;">2.30%</span></td>
<td id="A1.T7.8.8.20.16" class="ltx_td ltx_align_center">10.14%</td>
<td id="A1.T7.8.8.20.17" class="ltx_td ltx_align_center" style="background-color:#EEF2FA;"><span id="A1.T7.8.8.20.17.1" class="ltx_text" style="background-color:#EEF2FA;">1.32%</span></td>
</tr>
<tr id="A1.T7.8.8.21" class="ltx_tr">
<td id="A1.T7.8.8.21.1" class="ltx_td ltx_align_left">w/o role prompting</td>
<td id="A1.T7.8.8.21.2" class="ltx_td ltx_align_center">67.60%</td>
<td id="A1.T7.8.8.21.3" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.21.3.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.21.4" class="ltx_td ltx_align_center">42.15%</td>
<td id="A1.T7.8.8.21.5" class="ltx_td ltx_align_center" style="background-color:#FBF9FC;"><span id="A1.T7.8.8.21.5.1" class="ltx_text" style="background-color:#FBF9FC;">-0.25%</span></td>
<td id="A1.T7.8.8.21.6" class="ltx_td ltx_align_center">69.87%</td>
<td id="A1.T7.8.8.21.7" class="ltx_td ltx_align_center" style="background-color:#F7F9FE;"><span id="A1.T7.8.8.21.7.1" class="ltx_text" style="background-color:#F7F9FE;">0.53%</span></td>
<td id="A1.T7.8.8.21.8" class="ltx_td ltx_align_center">72.99%</td>
<td id="A1.T7.8.8.21.9" class="ltx_td ltx_align_center" style="background-color:#FBF3F6;"><span id="A1.T7.8.8.21.9.1" class="ltx_text" style="background-color:#FBF3F6;">-0.85%</span></td>
<td id="A1.T7.8.8.21.10" class="ltx_td ltx_align_center">50.39%</td>
<td id="A1.T7.8.8.21.11" class="ltx_td ltx_align_center" style="background-color:#F87678;"><span id="A1.T7.8.8.21.11.1" class="ltx_text" style="background-color:#F87678;">-13.59%</span></td>
<td id="A1.T7.8.8.21.12" class="ltx_td ltx_align_center">24.65%</td>
<td id="A1.T7.8.8.21.13" class="ltx_td ltx_align_center" style="background-color:#FBD9DC;"><span id="A1.T7.8.8.21.13.1" class="ltx_text" style="background-color:#FBD9DC;">-3.50%</span></td>
<td id="A1.T7.8.8.21.14" class="ltx_td ltx_align_center">12.75%</td>
<td id="A1.T7.8.8.21.15" class="ltx_td ltx_align_center" style="background-color:#FBE3E6;"><span id="A1.T7.8.8.21.15.1" class="ltx_text" style="background-color:#FBE3E6;">-2.48%</span></td>
<td id="A1.T7.8.8.21.16" class="ltx_td ltx_align_center">7.13%</td>
<td id="A1.T7.8.8.21.17" class="ltx_td ltx_align_center" style="background-color:#FBEBEE;"><span id="A1.T7.8.8.21.17.1" class="ltx_text" style="background-color:#FBEBEE;">-1.70%</span></td>
</tr>
<tr id="A1.T7.8.8.22" class="ltx_tr">
<td id="A1.T7.8.8.22.1" class="ltx_td ltx_align_left ltx_border_t"><span id="A1.T7.8.8.22.1.1" class="ltx_text ltx_font_bold">Markup Lan. XML</span></td>
<td id="A1.T7.8.8.22.2" class="ltx_td ltx_align_center ltx_border_t">70.00%</td>
<td id="A1.T7.8.8.22.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.22.3.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.22.4" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T7.8.8.22.4.1" class="ltx_text ltx_font_bold">47.20%</span></td>
<td id="A1.T7.8.8.22.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.22.5.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.22.6" class="ltx_td ltx_align_center ltx_border_t">70.74%</td>
<td id="A1.T7.8.8.22.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.22.7.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.22.8" class="ltx_td ltx_align_center ltx_border_t">73.14%</td>
<td id="A1.T7.8.8.22.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.22.9.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.22.10" class="ltx_td ltx_align_center ltx_border_t">52.26%</td>
<td id="A1.T7.8.8.22.11" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.22.11.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.22.12" class="ltx_td ltx_align_center ltx_border_t">32.16%</td>
<td id="A1.T7.8.8.22.13" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.22.13.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.22.14" class="ltx_td ltx_align_center ltx_border_t">15.23%</td>
<td id="A1.T7.8.8.22.15" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.22.15.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.22.16" class="ltx_td ltx_align_center ltx_border_t">8.82%</td>
<td id="A1.T7.8.8.22.17" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.22.17.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
</tr>
<tr id="A1.T7.8.8.23" class="ltx_tr">
<td id="A1.T7.8.8.23.1" class="ltx_td ltx_align_left">w/o format explanation</td>
<td id="A1.T7.8.8.23.2" class="ltx_td ltx_align_center"><span id="A1.T7.8.8.23.2.1" class="ltx_text ltx_font_bold">70.45%</span></td>
<td id="A1.T7.8.8.23.3" class="ltx_td ltx_align_center" style="background-color:#F8F9FE;"><span id="A1.T7.8.8.23.3.1" class="ltx_text" style="background-color:#F8F9FE;">0.45%</span></td>
<td id="A1.T7.8.8.23.4" class="ltx_td ltx_align_center">43.92%</td>
<td id="A1.T7.8.8.23.5" class="ltx_td ltx_align_center" style="background-color:#FBDBDE;"><span id="A1.T7.8.8.23.5.1" class="ltx_text" style="background-color:#FBDBDE;">-3.28%</span></td>
<td id="A1.T7.8.8.23.6" class="ltx_td ltx_align_center"><span id="A1.T7.8.8.23.6.1" class="ltx_text ltx_font_bold">71.74%</span></td>
<td id="A1.T7.8.8.23.7" class="ltx_td ltx_align_center" style="background-color:#F2F5FC;"><span id="A1.T7.8.8.23.7.1" class="ltx_text" style="background-color:#F2F5FC;">1.01%</span></td>
<td id="A1.T7.8.8.23.8" class="ltx_td ltx_align_center">72.03%</td>
<td id="A1.T7.8.8.23.9" class="ltx_td ltx_align_center" style="background-color:#FBF1F4;"><span id="A1.T7.8.8.23.9.1" class="ltx_text" style="background-color:#FBF1F4;">-1.10%</span></td>
<td id="A1.T7.8.8.23.10" class="ltx_td ltx_align_center">58.66%</td>
<td id="A1.T7.8.8.23.11" class="ltx_td ltx_align_center" style="background-color:#B7CCE7;"><span id="A1.T7.8.8.23.11.1" class="ltx_text" style="background-color:#B7CCE7;">6.40%</span></td>
<td id="A1.T7.8.8.23.12" class="ltx_td ltx_align_center">36.57%</td>
<td id="A1.T7.8.8.23.13" class="ltx_td ltx_align_center" style="background-color:#CDDBEF;"><span id="A1.T7.8.8.23.13.1" class="ltx_text" style="background-color:#CDDBEF;">4.42%</span></td>
<td id="A1.T7.8.8.23.14" class="ltx_td ltx_align_center">17.12%</td>
<td id="A1.T7.8.8.23.15" class="ltx_td ltx_align_center" style="background-color:#E8EEF8;"><span id="A1.T7.8.8.23.15.1" class="ltx_text" style="background-color:#E8EEF8;">1.88%</span></td>
<td id="A1.T7.8.8.23.16" class="ltx_td ltx_align_center">10.06%</td>
<td id="A1.T7.8.8.23.17" class="ltx_td ltx_align_center" style="background-color:#EFF3FB;"><span id="A1.T7.8.8.23.17.1" class="ltx_text" style="background-color:#EFF3FB;">1.23%</span></td>
</tr>
<tr id="A1.T7.8.8.24" class="ltx_tr">
<td id="A1.T7.8.8.24.1" class="ltx_td ltx_align_left">w/o partition mark</td>
<td id="A1.T7.8.8.24.2" class="ltx_td ltx_align_center">70.16%</td>
<td id="A1.T7.8.8.24.3" class="ltx_td ltx_align_center" style="background-color:#FBFBFF;"><span id="A1.T7.8.8.24.3.1" class="ltx_text" style="background-color:#FBFBFF;">0.15%</span></td>
<td id="A1.T7.8.8.24.4" class="ltx_td ltx_align_center">44.01%</td>
<td id="A1.T7.8.8.24.5" class="ltx_td ltx_align_center" style="background-color:#FBDCDF;"><span id="A1.T7.8.8.24.5.1" class="ltx_text" style="background-color:#FBDCDF;">-3.19%</span></td>
<td id="A1.T7.8.8.24.6" class="ltx_td ltx_align_center">70.77%</td>
<td id="A1.T7.8.8.24.7" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.24.7.1" class="ltx_text" style="background-color:#FCFCFF;">0.03%</span></td>
<td id="A1.T7.8.8.24.8" class="ltx_td ltx_align_center">71.18%</td>
<td id="A1.T7.8.8.24.9" class="ltx_td ltx_align_center" style="background-color:#FBE8EB;"><span id="A1.T7.8.8.24.9.1" class="ltx_text" style="background-color:#FBE8EB;">-1.96%</span></td>
<td id="A1.T7.8.8.24.10" class="ltx_td ltx_align_center">62.77%</td>
<td id="A1.T7.8.8.24.11" class="ltx_td ltx_align_center" style="background-color:#8BADD8;"><span id="A1.T7.8.8.24.11.1" class="ltx_text" style="background-color:#8BADD8;">10.51%</span></td>
<td id="A1.T7.8.8.24.12" class="ltx_td ltx_align_center">35.40%</td>
<td id="A1.T7.8.8.24.13" class="ltx_td ltx_align_center" style="background-color:#D9E4F3;"><span id="A1.T7.8.8.24.13.1" class="ltx_text" style="background-color:#D9E4F3;">3.24%</span></td>
<td id="A1.T7.8.8.24.14" class="ltx_td ltx_align_center">18.69%</td>
<td id="A1.T7.8.8.24.15" class="ltx_td ltx_align_center" style="background-color:#D7E2F2;"><span id="A1.T7.8.8.24.15.1" class="ltx_text" style="background-color:#D7E2F2;">3.45%</span></td>
<td id="A1.T7.8.8.24.16" class="ltx_td ltx_align_center">10.97%</td>
<td id="A1.T7.8.8.24.17" class="ltx_td ltx_align_center" style="background-color:#E5ECF7;"><span id="A1.T7.8.8.24.17.1" class="ltx_text" style="background-color:#E5ECF7;">2.14%</span></td>
</tr>
<tr id="A1.T7.8.8.25" class="ltx_tr">
<td id="A1.T7.8.8.25.1" class="ltx_td ltx_align_left">w/o role prompting</td>
<td id="A1.T7.8.8.25.2" class="ltx_td ltx_align_center">70.30%</td>
<td id="A1.T7.8.8.25.3" class="ltx_td ltx_align_center" style="background-color:#F9FAFE;"><span id="A1.T7.8.8.25.3.1" class="ltx_text" style="background-color:#F9FAFE;">0.30%</span></td>
<td id="A1.T7.8.8.25.4" class="ltx_td ltx_align_center">44.65%</td>
<td id="A1.T7.8.8.25.5" class="ltx_td ltx_align_center" style="background-color:#FBE2E5;"><span id="A1.T7.8.8.25.5.1" class="ltx_text" style="background-color:#FBE2E5;">-2.55%</span></td>
<td id="A1.T7.8.8.25.6" class="ltx_td ltx_align_center">69.47%</td>
<td id="A1.T7.8.8.25.7" class="ltx_td ltx_align_center" style="background-color:#FBEFF2;"><span id="A1.T7.8.8.25.7.1" class="ltx_text" style="background-color:#FBEFF2;">-1.26%</span></td>
<td id="A1.T7.8.8.25.8" class="ltx_td ltx_align_center">72.43%</td>
<td id="A1.T7.8.8.25.9" class="ltx_td ltx_align_center" style="background-color:#FBF5F8;"><span id="A1.T7.8.8.25.9.1" class="ltx_text" style="background-color:#FBF5F8;">-0.71%</span></td>
<td id="A1.T7.8.8.25.10" class="ltx_td ltx_align_center">43.45%</td>
<td id="A1.T7.8.8.25.11" class="ltx_td ltx_align_center" style="background-color:#F9A5A8;"><span id="A1.T7.8.8.25.11.1" class="ltx_text" style="background-color:#F9A5A8;">-8.81%</span></td>
<td id="A1.T7.8.8.25.12" class="ltx_td ltx_align_center">20.32%</td>
<td id="A1.T7.8.8.25.13" class="ltx_td ltx_align_center" style="background-color:#F8878A;"><span id="A1.T7.8.8.25.13.1" class="ltx_text" style="background-color:#F8878A;">-11.84%</span></td>
<td id="A1.T7.8.8.25.14" class="ltx_td ltx_align_center">14.05%</td>
<td id="A1.T7.8.8.25.15" class="ltx_td ltx_align_center" style="background-color:#FBF0F3;"><span id="A1.T7.8.8.25.15.1" class="ltx_text" style="background-color:#FBF0F3;">-1.18%</span></td>
<td id="A1.T7.8.8.25.16" class="ltx_td ltx_align_center">8.23%</td>
<td id="A1.T7.8.8.25.17" class="ltx_td ltx_align_center" style="background-color:#FBF6F9;"><span id="A1.T7.8.8.25.17.1" class="ltx_text" style="background-color:#FBF6F9;">-0.60%</span></td>
</tr>
<tr id="A1.T7.8.8.26" class="ltx_tr">
<td id="A1.T7.8.8.26.1" class="ltx_td ltx_align_left ltx_border_t"><span id="A1.T7.8.8.26.1.1" class="ltx_text ltx_font_bold">Markup Lan. HTML</span></td>
<td id="A1.T7.8.8.26.2" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T7.8.8.26.2.1" class="ltx_text ltx_font_bold">71.33%</span></td>
<td id="A1.T7.8.8.26.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.26.3.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.26.4" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T7.8.8.26.4.1" class="ltx_text ltx_font_bold">47.29%</span></td>
<td id="A1.T7.8.8.26.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.26.5.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.26.6" class="ltx_td ltx_align_center ltx_border_t">71.31%</td>
<td id="A1.T7.8.8.26.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.26.7.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.26.8" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T7.8.8.26.8.1" class="ltx_text ltx_font_bold">75.20%</span></td>
<td id="A1.T7.8.8.26.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.26.9.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.26.10" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T7.8.8.26.10.1" class="ltx_text ltx_font_bold">79.04%</span></td>
<td id="A1.T7.8.8.26.11" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.26.11.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.26.12" class="ltx_td ltx_align_center ltx_border_t">39.72%</td>
<td id="A1.T7.8.8.26.13" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.26.13.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.26.14" class="ltx_td ltx_align_center ltx_border_t">21.45%</td>
<td id="A1.T7.8.8.26.15" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.26.15.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T7.8.8.26.16" class="ltx_td ltx_align_center ltx_border_t">12.30%</td>
<td id="A1.T7.8.8.26.17" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T7.8.8.26.17.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
</tr>
<tr id="A1.T7.8.8.27" class="ltx_tr">
<td id="A1.T7.8.8.27.1" class="ltx_td ltx_align_left">w/o format explanation</td>
<td id="A1.T7.8.8.27.2" class="ltx_td ltx_align_center">70.28%</td>
<td id="A1.T7.8.8.27.3" class="ltx_td ltx_align_center" style="background-color:#FBF1F4;"><span id="A1.T7.8.8.27.3.1" class="ltx_text" style="background-color:#FBF1F4;">-1.04%</span></td>
<td id="A1.T7.8.8.27.4" class="ltx_td ltx_align_center">44.00%</td>
<td id="A1.T7.8.8.27.5" class="ltx_td ltx_align_center" style="background-color:#FBDBDE;"><span id="A1.T7.8.8.27.5.1" class="ltx_text" style="background-color:#FBDBDE;">-3.29%</span></td>
<td id="A1.T7.8.8.27.6" class="ltx_td ltx_align_center"><span id="A1.T7.8.8.27.6.1" class="ltx_text ltx_font_bold">72.19%</span></td>
<td id="A1.T7.8.8.27.7" class="ltx_td ltx_align_center" style="background-color:#F3F6FC;"><span id="A1.T7.8.8.27.7.1" class="ltx_text" style="background-color:#F3F6FC;">0.88%</span></td>
<td id="A1.T7.8.8.27.8" class="ltx_td ltx_align_center">67.92%</td>
<td id="A1.T7.8.8.27.9" class="ltx_td ltx_align_center" style="background-color:#FAB4B7;"><span id="A1.T7.8.8.27.9.1" class="ltx_text" style="background-color:#FAB4B7;">-7.28%</span></td>
<td id="A1.T7.8.8.27.10" class="ltx_td ltx_align_center"><span id="A1.T7.8.8.27.10.1" class="ltx_text ltx_font_bold">73.45%</span></td>
<td id="A1.T7.8.8.27.11" class="ltx_td ltx_align_center" style="background-color:#FAC5C7;"><span id="A1.T7.8.8.27.11.1" class="ltx_text" style="background-color:#FAC5C7;">-5.60%</span></td>
<td id="A1.T7.8.8.27.12" class="ltx_td ltx_align_center"><span id="A1.T7.8.8.27.12.1" class="ltx_text ltx_font_bold">43.00%</span></td>
<td id="A1.T7.8.8.27.13" class="ltx_td ltx_align_center" style="background-color:#D9E4F3;"><span id="A1.T7.8.8.27.13.1" class="ltx_text" style="background-color:#D9E4F3;">3.27%</span></td>
<td id="A1.T7.8.8.27.14" class="ltx_td ltx_align_center"><span id="A1.T7.8.8.27.14.1" class="ltx_text ltx_font_bold">23.31%</span></td>
<td id="A1.T7.8.8.27.15" class="ltx_td ltx_align_center" style="background-color:#E8EEF8;"><span id="A1.T7.8.8.27.15.1" class="ltx_text" style="background-color:#E8EEF8;">1.86%</span></td>
<td id="A1.T7.8.8.27.16" class="ltx_td ltx_align_center"><span id="A1.T7.8.8.27.16.1" class="ltx_text ltx_font_bold">14.53%</span></td>
<td id="A1.T7.8.8.27.17" class="ltx_td ltx_align_center" style="background-color:#E4ECF7;"><span id="A1.T7.8.8.27.17.1" class="ltx_text" style="background-color:#E4ECF7;">2.22%</span></td>
</tr>
<tr id="A1.T7.8.8.28" class="ltx_tr">
<td id="A1.T7.8.8.28.1" class="ltx_td ltx_align_left">w/o partition mark</td>
<td id="A1.T7.8.8.28.2" class="ltx_td ltx_align_center">69.93%</td>
<td id="A1.T7.8.8.28.3" class="ltx_td ltx_align_center" style="background-color:#FBEEF1;"><span id="A1.T7.8.8.28.3.1" class="ltx_text" style="background-color:#FBEEF1;">-1.40%</span></td>
<td id="A1.T7.8.8.28.4" class="ltx_td ltx_align_center">44.83%</td>
<td id="A1.T7.8.8.28.5" class="ltx_td ltx_align_center" style="background-color:#FBE3E6;"><span id="A1.T7.8.8.28.5.1" class="ltx_text" style="background-color:#FBE3E6;">-2.45%</span></td>
<td id="A1.T7.8.8.28.6" class="ltx_td ltx_align_center">71.59%</td>
<td id="A1.T7.8.8.28.7" class="ltx_td ltx_align_center" style="background-color:#F9FAFE;"><span id="A1.T7.8.8.28.7.1" class="ltx_text" style="background-color:#F9FAFE;">0.28%</span></td>
<td id="A1.T7.8.8.28.8" class="ltx_td ltx_align_center">71.05%</td>
<td id="A1.T7.8.8.28.9" class="ltx_td ltx_align_center" style="background-color:#FAD3D6;"><span id="A1.T7.8.8.28.9.1" class="ltx_text" style="background-color:#FAD3D6;">-4.15%</span></td>
<td id="A1.T7.8.8.28.10" class="ltx_td ltx_align_center"><span id="A1.T7.8.8.28.10.1" class="ltx_text ltx_font_bold">76.35%</span></td>
<td id="A1.T7.8.8.28.11" class="ltx_td ltx_align_center" style="background-color:#FAC5C7;"><span id="A1.T7.8.8.28.11.1" class="ltx_text" style="background-color:#FAC5C7;">-5.60%</span></td>
<td id="A1.T7.8.8.28.12" class="ltx_td ltx_align_center">40.84%</td>
<td id="A1.T7.8.8.28.13" class="ltx_td ltx_align_center" style="background-color:#F0F4FB;"><span id="A1.T7.8.8.28.13.1" class="ltx_text" style="background-color:#F0F4FB;">1.11%</span></td>
<td id="A1.T7.8.8.28.14" class="ltx_td ltx_align_center">21.75%</td>
<td id="A1.T7.8.8.28.15" class="ltx_td ltx_align_center" style="background-color:#F9FAFE;"><span id="A1.T7.8.8.28.15.1" class="ltx_text" style="background-color:#F9FAFE;">0.30%</span></td>
<td id="A1.T7.8.8.28.16" class="ltx_td ltx_align_center">12.51%</td>
<td id="A1.T7.8.8.28.17" class="ltx_td ltx_align_center" style="background-color:#FAFBFF;"><span id="A1.T7.8.8.28.17.1" class="ltx_text" style="background-color:#FAFBFF;">0.21%</span></td>
</tr>
<tr id="A1.T7.8.8.29" class="ltx_tr">
<td id="A1.T7.8.8.29.1" class="ltx_td ltx_align_left ltx_border_bb">w/o role prompting</td>
<td id="A1.T7.8.8.29.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T7.8.8.29.2.1" class="ltx_text ltx_font_bold">70.30%</span></td>
<td id="A1.T7.8.8.29.3" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#FBF1F4;"><span id="A1.T7.8.8.29.3.1" class="ltx_text" style="background-color:#FBF1F4;">-1.03%</span></td>
<td id="A1.T7.8.8.29.4" class="ltx_td ltx_align_center ltx_border_bb">44.29%</td>
<td id="A1.T7.8.8.29.5" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#FBDEE1;"><span id="A1.T7.8.8.29.5.1" class="ltx_text" style="background-color:#FBDEE1;">-2.99%</span></td>
<td id="A1.T7.8.8.29.6" class="ltx_td ltx_align_center ltx_border_bb">70.48%</td>
<td id="A1.T7.8.8.29.7" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#FBEBEE;"><span id="A1.T7.8.8.29.7.1" class="ltx_text" style="background-color:#FBEBEE;">-1.71%</span></td>
<td id="A1.T7.8.8.29.8" class="ltx_td ltx_align_center ltx_border_bb">65.00%</td>
<td id="A1.T7.8.8.29.9" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#F9989A;"><span id="A1.T7.8.8.29.9.1" class="ltx_text" style="background-color:#F9989A;">-10.20%</span></td>
<td id="A1.T7.8.8.29.10" class="ltx_td ltx_align_center ltx_border_bb">69.80%</td>
<td id="A1.T7.8.8.29.11" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#F9A1A3;"><span id="A1.T7.8.8.29.11.1" class="ltx_text" style="background-color:#F9A1A3;">-9.25%</span></td>
<td id="A1.T7.8.8.29.12" class="ltx_td ltx_align_center ltx_border_bb">31.43%</td>
<td id="A1.T7.8.8.29.13" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#F9AAAD;"><span id="A1.T7.8.8.29.13.1" class="ltx_text" style="background-color:#F9AAAD;">-8.29%</span></td>
<td id="A1.T7.8.8.29.14" class="ltx_td ltx_align_center ltx_border_bb">17.15%</td>
<td id="A1.T7.8.8.29.15" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#FAD1D4;"><span id="A1.T7.8.8.29.15.1" class="ltx_text" style="background-color:#FAD1D4;">-4.30%</span></td>
<td id="A1.T7.8.8.29.16" class="ltx_td ltx_align_center ltx_border_bb">9.74%</td>
<td id="A1.T7.8.8.29.17" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#FBE2E5;"><span id="A1.T7.8.8.29.17.1" class="ltx_text" style="background-color:#FBE2E5;">-2.56%</span></td>
</tr>
</table>
</span></div>
</figure>
<figure id="A1.T8" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8. </span>Full results of the benchmark.</figcaption>
<div id="A1.T8.7" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:328.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-163.7pt,123.9pt) scale(0.569780926318368,0.569780926318368) ;">
<table id="A1.T8.7.7" class="ltx_tabular ltx_align_middle">
<tr id="A1.T8.7.7.8" class="ltx_tr">
<td id="A1.T8.7.7.8.1" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="A1.T8.7.7.8.1.1" class="ltx_text">Input Design</span></td>
<td id="A1.T8.7.7.8.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">Table Partition</td>
<td id="A1.T8.7.7.8.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">Cell Lookup</td>
<td id="A1.T8.7.7.8.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">Reverse Lookup</td>
<td id="A1.T8.7.7.8.5" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">Column Retrieval</td>
<td id="A1.T8.7.7.8.6" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">Row Retrieval</td>
<td id="A1.T8.7.7.8.7" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">Size Detection</td>
<td id="A1.T8.7.7.8.8" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">Merged Cell Detection</td>
</tr>
<tr id="A1.T8.7.7.7" class="ltx_tr">
<td id="A1.T8.7.7.7.8" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="A1.T8.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T8.1.1.1.1.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="A1.T8.1.1.1.1.m1.1a"><mi mathvariant="normal" id="A1.T8.1.1.1.1.m1.1.1" xref="A1.T8.1.1.1.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="A1.T8.1.1.1.1.m1.1b"><ci id="A1.T8.1.1.1.1.m1.1.1.cmml" xref="A1.T8.1.1.1.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T8.1.1.1.1.m1.1c">\Delta</annotation></semantics></math></td>
<td id="A1.T8.7.7.7.9" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="A1.T8.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T8.2.2.2.2.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="A1.T8.2.2.2.2.m1.1a"><mi mathvariant="normal" id="A1.T8.2.2.2.2.m1.1.1" xref="A1.T8.2.2.2.2.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="A1.T8.2.2.2.2.m1.1b"><ci id="A1.T8.2.2.2.2.m1.1.1.cmml" xref="A1.T8.2.2.2.2.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T8.2.2.2.2.m1.1c">\Delta</annotation></semantics></math></td>
<td id="A1.T8.7.7.7.10" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="A1.T8.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T8.3.3.3.3.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="A1.T8.3.3.3.3.m1.1a"><mi mathvariant="normal" id="A1.T8.3.3.3.3.m1.1.1" xref="A1.T8.3.3.3.3.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="A1.T8.3.3.3.3.m1.1b"><ci id="A1.T8.3.3.3.3.m1.1.1.cmml" xref="A1.T8.3.3.3.3.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T8.3.3.3.3.m1.1c">\Delta</annotation></semantics></math></td>
<td id="A1.T8.7.7.7.11" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="A1.T8.4.4.4.4" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T8.4.4.4.4.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="A1.T8.4.4.4.4.m1.1a"><mi mathvariant="normal" id="A1.T8.4.4.4.4.m1.1.1" xref="A1.T8.4.4.4.4.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="A1.T8.4.4.4.4.m1.1b"><ci id="A1.T8.4.4.4.4.m1.1.1.cmml" xref="A1.T8.4.4.4.4.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T8.4.4.4.4.m1.1c">\Delta</annotation></semantics></math></td>
<td id="A1.T8.7.7.7.12" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="A1.T8.5.5.5.5" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T8.5.5.5.5.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="A1.T8.5.5.5.5.m1.1a"><mi mathvariant="normal" id="A1.T8.5.5.5.5.m1.1.1" xref="A1.T8.5.5.5.5.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="A1.T8.5.5.5.5.m1.1b"><ci id="A1.T8.5.5.5.5.m1.1.1.cmml" xref="A1.T8.5.5.5.5.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T8.5.5.5.5.m1.1c">\Delta</annotation></semantics></math></td>
<td id="A1.T8.7.7.7.13" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="A1.T8.6.6.6.6" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T8.6.6.6.6.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="A1.T8.6.6.6.6.m1.1a"><mi mathvariant="normal" id="A1.T8.6.6.6.6.m1.1.1" xref="A1.T8.6.6.6.6.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="A1.T8.6.6.6.6.m1.1b"><ci id="A1.T8.6.6.6.6.m1.1.1.cmml" xref="A1.T8.6.6.6.6.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T8.6.6.6.6.m1.1c">\Delta</annotation></semantics></math></td>
<td id="A1.T8.7.7.7.14" class="ltx_td ltx_align_center ltx_border_t">Acc</td>
<td id="A1.T8.7.7.7.7" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T8.7.7.7.7.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="A1.T8.7.7.7.7.m1.1a"><mi mathvariant="normal" id="A1.T8.7.7.7.7.m1.1.1" xref="A1.T8.7.7.7.7.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="A1.T8.7.7.7.7.m1.1b"><ci id="A1.T8.7.7.7.7.m1.1.1.cmml" xref="A1.T8.7.7.7.7.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T8.7.7.7.7.m1.1c">\Delta</annotation></semantics></math></td>
</tr>
<tr id="A1.T8.7.7.9" class="ltx_tr">
<td id="A1.T8.7.7.9.1" class="ltx_td ltx_align_left ltx_border_t"><span id="A1.T8.7.7.9.1.1" class="ltx_text ltx_font_bold">NL + Sep</span></td>
<td id="A1.T8.7.7.9.2" class="ltx_td ltx_align_center ltx_border_t">93.00%</td>
<td id="A1.T8.7.7.9.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.9.3.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.9.4" class="ltx_td ltx_align_center ltx_border_t">39.67%</td>
<td id="A1.T8.7.7.9.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.9.5.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.9.6" class="ltx_td ltx_align_center ltx_border_t">52.00%</td>
<td id="A1.T8.7.7.9.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.9.7.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.9.8" class="ltx_td ltx_align_center ltx_border_t">60.67%</td>
<td id="A1.T8.7.7.9.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.9.9.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.9.10" class="ltx_td ltx_align_center ltx_border_t">31.00%</td>
<td id="A1.T8.7.7.9.11" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.9.11.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.9.12" class="ltx_td ltx_align_center ltx_border_t">42.00%</td>
<td id="A1.T8.7.7.9.13" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.9.13.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.9.14" class="ltx_td ltx_align_center ltx_border_t">71.33%</td>
<td id="A1.T8.7.7.9.15" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.9.15.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
</tr>
<tr id="A1.T8.7.7.10" class="ltx_tr">
<td id="A1.T8.7.7.10.1" class="ltx_td ltx_align_left">w/o format explanation</td>
<td id="A1.T8.7.7.10.2" class="ltx_td ltx_align_center">91.33%</td>
<td id="A1.T8.7.7.10.3" class="ltx_td ltx_align_center" style="background-color:#FBEBEE;"><span id="A1.T8.7.7.10.3.1" class="ltx_text" style="background-color:#FBEBEE;">-1.67%</span></td>
<td id="A1.T8.7.7.10.4" class="ltx_td ltx_align_center">50.00%</td>
<td id="A1.T8.7.7.10.5" class="ltx_td ltx_align_center" style="background-color:#8DAED8;"><span id="A1.T8.7.7.10.5.1" class="ltx_text" style="background-color:#8DAED8;">10.33%</span></td>
<td id="A1.T8.7.7.10.6" class="ltx_td ltx_align_center"><span id="A1.T8.7.7.10.6.1" class="ltx_text ltx_font_bold">58.33%</span></td>
<td id="A1.T8.7.7.10.7" class="ltx_td ltx_align_center" style="background-color:#B8CCE7;"><span id="A1.T8.7.7.10.7.1" class="ltx_text" style="background-color:#B8CCE7;">6.33%</span></td>
<td id="A1.T8.7.7.10.8" class="ltx_td ltx_align_center">58.00%</td>
<td id="A1.T8.7.7.10.9" class="ltx_td ltx_align_center" style="background-color:#FBE1E4;"><span id="A1.T8.7.7.10.9.1" class="ltx_text" style="background-color:#FBE1E4;">-2.67%</span></td>
<td id="A1.T8.7.7.10.10" class="ltx_td ltx_align_center">31.67%</td>
<td id="A1.T8.7.7.10.11" class="ltx_td ltx_align_center" style="background-color:#F5F7FD;"><span id="A1.T8.7.7.10.11.1" class="ltx_text" style="background-color:#F5F7FD;">0.67%</span></td>
<td id="A1.T8.7.7.10.12" class="ltx_td ltx_align_center">40.67%</td>
<td id="A1.T8.7.7.10.13" class="ltx_td ltx_align_center" style="background-color:#FBEEF1;"><span id="A1.T8.7.7.10.13.1" class="ltx_text" style="background-color:#FBEEF1;">-1.33%</span></td>
<td id="A1.T8.7.7.10.14" class="ltx_td ltx_align_center">73.33%</td>
<td id="A1.T8.7.7.10.15" class="ltx_td ltx_align_center" style="background-color:#E7EDF8;"><span id="A1.T8.7.7.10.15.1" class="ltx_text" style="background-color:#E7EDF8;">2.00%</span></td>
</tr>
<tr id="A1.T8.7.7.11" class="ltx_tr">
<td id="A1.T8.7.7.11.1" class="ltx_td ltx_align_left">w/o partition mark</td>
<td id="A1.T8.7.7.11.2" class="ltx_td ltx_align_center">90.00%</td>
<td id="A1.T8.7.7.11.3" class="ltx_td ltx_align_center" style="background-color:#FBDEE1;"><span id="A1.T8.7.7.11.3.1" class="ltx_text" style="background-color:#FBDEE1;">-3.00%</span></td>
<td id="A1.T8.7.7.11.4" class="ltx_td ltx_align_center">40.33%</td>
<td id="A1.T8.7.7.11.5" class="ltx_td ltx_align_center" style="background-color:#F5F7FD;"><span id="A1.T8.7.7.11.5.1" class="ltx_text" style="background-color:#F5F7FD;">0.67%</span></td>
<td id="A1.T8.7.7.11.6" class="ltx_td ltx_align_center">50.00%</td>
<td id="A1.T8.7.7.11.7" class="ltx_td ltx_align_center" style="background-color:#FBE8EB;"><span id="A1.T8.7.7.11.7.1" class="ltx_text" style="background-color:#FBE8EB;">-2.00%</span></td>
<td id="A1.T8.7.7.11.8" class="ltx_td ltx_align_center">56.67%</td>
<td id="A1.T8.7.7.11.9" class="ltx_td ltx_align_center" style="background-color:#FAD4D7;"><span id="A1.T8.7.7.11.9.1" class="ltx_text" style="background-color:#FAD4D7;">-4.00%</span></td>
<td id="A1.T8.7.7.11.10" class="ltx_td ltx_align_center">36.33%</td>
<td id="A1.T8.7.7.11.11" class="ltx_td ltx_align_center" style="background-color:#C3D4EB;"><span id="A1.T8.7.7.11.11.1" class="ltx_text" style="background-color:#C3D4EB;">5.33%</span></td>
<td id="A1.T8.7.7.11.12" class="ltx_td ltx_align_center">40.00%</td>
<td id="A1.T8.7.7.11.13" class="ltx_td ltx_align_center" style="background-color:#FBE8EB;"><span id="A1.T8.7.7.11.13.1" class="ltx_text" style="background-color:#FBE8EB;">-2.00%</span></td>
<td id="A1.T8.7.7.11.14" class="ltx_td ltx_align_center">69.00%</td>
<td id="A1.T8.7.7.11.15" class="ltx_td ltx_align_center" style="background-color:#FBE5E7;"><span id="A1.T8.7.7.11.15.1" class="ltx_text" style="background-color:#FBE5E7;">-2.33%</span></td>
</tr>
<tr id="A1.T8.7.7.12" class="ltx_tr">
<td id="A1.T8.7.7.12.1" class="ltx_td ltx_align_left">w/o role prompting</td>
<td id="A1.T8.7.7.12.2" class="ltx_td ltx_align_center">91.33%</td>
<td id="A1.T8.7.7.12.3" class="ltx_td ltx_align_center" style="background-color:#FBEBEE;"><span id="A1.T8.7.7.12.3.1" class="ltx_text" style="background-color:#FBEBEE;">-1.67%</span></td>
<td id="A1.T8.7.7.12.4" class="ltx_td ltx_align_center">45.67%</td>
<td id="A1.T8.7.7.12.5" class="ltx_td ltx_align_center" style="background-color:#BCCFE9;"><span id="A1.T8.7.7.12.5.1" class="ltx_text" style="background-color:#BCCFE9;">6.00%</span></td>
<td id="A1.T8.7.7.12.6" class="ltx_td ltx_align_center">41.00%</td>
<td id="A1.T8.7.7.12.7" class="ltx_td ltx_align_center" style="background-color:#F99092;"><span id="A1.T8.7.7.12.7.1" class="ltx_text" style="background-color:#F99092;">-11.00%</span></td>
<td id="A1.T8.7.7.12.8" class="ltx_td ltx_align_center">54.00%</td>
<td id="A1.T8.7.7.12.9" class="ltx_td ltx_align_center" style="background-color:#FABABD;"><span id="A1.T8.7.7.12.9.1" class="ltx_text" style="background-color:#FABABD;">-6.67%</span></td>
<td id="A1.T8.7.7.12.10" class="ltx_td ltx_align_center">25.33%</td>
<td id="A1.T8.7.7.12.11" class="ltx_td ltx_align_center" style="background-color:#FAC4C7;"><span id="A1.T8.7.7.12.11.1" class="ltx_text" style="background-color:#FAC4C7;">-5.67%</span></td>
<td id="A1.T8.7.7.12.12" class="ltx_td ltx_align_center">41.67%</td>
<td id="A1.T8.7.7.12.13" class="ltx_td ltx_align_center" style="background-color:#FBF8FB;"><span id="A1.T8.7.7.12.13.1" class="ltx_text" style="background-color:#FBF8FB;">-0.33%</span></td>
<td id="A1.T8.7.7.12.14" class="ltx_td ltx_align_center">74.00%</td>
<td id="A1.T8.7.7.12.15" class="ltx_td ltx_align_center" style="background-color:#E0E8F5;"><span id="A1.T8.7.7.12.15.1" class="ltx_text" style="background-color:#E0E8F5;">2.67%</span></td>
</tr>
<tr id="A1.T8.7.7.13" class="ltx_tr">
<td id="A1.T8.7.7.13.1" class="ltx_td ltx_align_left">w/o change order</td>
<td id="A1.T8.7.7.13.2" class="ltx_td ltx_align_center">88.00%</td>
<td id="A1.T8.7.7.13.3" class="ltx_td ltx_align_center" style="background-color:#FACACD;"><span id="A1.T8.7.7.13.3.1" class="ltx_text" style="background-color:#FACACD;">-5.00%</span></td>
<td id="A1.T8.7.7.13.4" class="ltx_td ltx_align_center">35.33%</td>
<td id="A1.T8.7.7.13.5" class="ltx_td ltx_align_center" style="background-color:#FAD1D4;"><span id="A1.T8.7.7.13.5.1" class="ltx_text" style="background-color:#FAD1D4;">-4.33%</span></td>
<td id="A1.T8.7.7.13.6" class="ltx_td ltx_align_center">40.33%</td>
<td id="A1.T8.7.7.13.7" class="ltx_td ltx_align_center" style="background-color:#F8898B;"><span id="A1.T8.7.7.13.7.1" class="ltx_text" style="background-color:#F8898B;">-11.67%</span></td>
<td id="A1.T8.7.7.13.8" class="ltx_td ltx_align_center">55.33%</td>
<td id="A1.T8.7.7.13.9" class="ltx_td ltx_align_center" style="background-color:#FAC7CA;"><span id="A1.T8.7.7.13.9.1" class="ltx_text" style="background-color:#FAC7CA;">-5.33%</span></td>
<td id="A1.T8.7.7.13.10" class="ltx_td ltx_align_center">24.67%</td>
<td id="A1.T8.7.7.13.11" class="ltx_td ltx_align_center" style="background-color:#FABDC0;"><span id="A1.T8.7.7.13.11.1" class="ltx_text" style="background-color:#FABDC0;">-6.33%</span></td>
<td id="A1.T8.7.7.13.12" class="ltx_td ltx_align_center">36.67%</td>
<td id="A1.T8.7.7.13.13" class="ltx_td ltx_align_center" style="background-color:#FAC7CA;"><span id="A1.T8.7.7.13.13.1" class="ltx_text" style="background-color:#FAC7CA;">-5.33%</span></td>
<td id="A1.T8.7.7.13.14" class="ltx_td ltx_align_center">61.00%</td>
<td id="A1.T8.7.7.13.15" class="ltx_td ltx_align_center" style="background-color:#F99699;"><span id="A1.T8.7.7.13.15.1" class="ltx_text" style="background-color:#F99699;">-10.33%</span></td>
</tr>
<tr id="A1.T8.7.7.14" class="ltx_tr">
<td id="A1.T8.7.7.14.1" class="ltx_td ltx_align_left ltx_border_t"><span id="A1.T8.7.7.14.1.1" class="ltx_text ltx_font_bold">w/o 1-shot</span></td>
<td id="A1.T8.7.7.14.2" class="ltx_td ltx_align_center ltx_border_t">75.33%</td>
<td id="A1.T8.7.7.14.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="A1.T8.7.7.14.3.1" class="ltx_text" style="background-color:#F8696B;">-17.67%</span></td>
<td id="A1.T8.7.7.14.4" class="ltx_td ltx_align_center ltx_border_t">9.00%</td>
<td id="A1.T8.7.7.14.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="A1.T8.7.7.14.5.1" class="ltx_text" style="background-color:#F8696B;">-30.67%</span></td>
<td id="A1.T8.7.7.14.6" class="ltx_td ltx_align_center ltx_border_t">37.33%</td>
<td id="A1.T8.7.7.14.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F86C6E;"><span id="A1.T8.7.7.14.7.1" class="ltx_text" style="background-color:#F86C6E;">-14.67%</span></td>
<td id="A1.T8.7.7.14.8" class="ltx_td ltx_align_center ltx_border_t">50.33%</td>
<td id="A1.T8.7.7.14.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F99699;"><span id="A1.T8.7.7.14.9.1" class="ltx_text" style="background-color:#F99699;">-10.33%</span></td>
<td id="A1.T8.7.7.14.10" class="ltx_td ltx_align_center ltx_border_t">17.00%</td>
<td id="A1.T8.7.7.14.11" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F87274;"><span id="A1.T8.7.7.14.11.1" class="ltx_text" style="background-color:#F87274;">-14.00%</span></td>
<td id="A1.T8.7.7.14.12" class="ltx_td ltx_align_center ltx_border_t">26.33%</td>
<td id="A1.T8.7.7.14.13" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="A1.T8.7.7.14.13.1" class="ltx_text" style="background-color:#F8696B;">-15.67%</span></td>
<td id="A1.T8.7.7.14.14" class="ltx_td ltx_align_center ltx_border_t">17.33%</td>
<td id="A1.T8.7.7.14.15" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="A1.T8.7.7.14.15.1" class="ltx_text" style="background-color:#F8696B;">-54.00%</span></td>
</tr>
<tr id="A1.T8.7.7.15" class="ltx_tr">
<td id="A1.T8.7.7.15.1" class="ltx_td ltx_align_left ltx_border_t"><span id="A1.T8.7.7.15.1.1" class="ltx_text ltx_font_bold">Storing Lang. JSON</span></td>
<td id="A1.T8.7.7.15.2" class="ltx_td ltx_align_center ltx_border_t">94.00%</td>
<td id="A1.T8.7.7.15.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.15.3.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.15.4" class="ltx_td ltx_align_center ltx_border_t">42.67%</td>
<td id="A1.T8.7.7.15.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.15.5.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.15.6" class="ltx_td ltx_align_center ltx_border_t">54.33%</td>
<td id="A1.T8.7.7.15.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.15.7.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.15.8" class="ltx_td ltx_align_center ltx_border_t">54.33%</td>
<td id="A1.T8.7.7.15.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.15.9.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.15.10" class="ltx_td ltx_align_center ltx_border_t">29.00%</td>
<td id="A1.T8.7.7.15.11" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.15.11.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.15.12" class="ltx_td ltx_align_center ltx_border_t">42.67%</td>
<td id="A1.T8.7.7.15.13" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.15.13.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.15.14" class="ltx_td ltx_align_center ltx_border_t">73.33%</td>
<td id="A1.T8.7.7.15.15" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.15.15.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
</tr>
<tr id="A1.T8.7.7.16" class="ltx_tr">
<td id="A1.T8.7.7.16.1" class="ltx_td ltx_align_left">w/o format explanation</td>
<td id="A1.T8.7.7.16.2" class="ltx_td ltx_align_center">87.67%</td>
<td id="A1.T8.7.7.16.3" class="ltx_td ltx_align_center" style="background-color:#FABDC0;"><span id="A1.T8.7.7.16.3.1" class="ltx_text" style="background-color:#FABDC0;">-6.33%</span></td>
<td id="A1.T8.7.7.16.4" class="ltx_td ltx_align_center">47.67%</td>
<td id="A1.T8.7.7.16.5" class="ltx_td ltx_align_center" style="background-color:#C6D6EC;"><span id="A1.T8.7.7.16.5.1" class="ltx_text" style="background-color:#C6D6EC;">5.00%</span></td>
<td id="A1.T8.7.7.16.6" class="ltx_td ltx_align_center">57.67%</td>
<td id="A1.T8.7.7.16.7" class="ltx_td ltx_align_center" style="background-color:#D9E3F3;"><span id="A1.T8.7.7.16.7.1" class="ltx_text" style="background-color:#D9E3F3;">3.33%</span></td>
<td id="A1.T8.7.7.16.8" class="ltx_td ltx_align_center">49.00%</td>
<td id="A1.T8.7.7.16.9" class="ltx_td ltx_align_center" style="background-color:#FAC7CA;"><span id="A1.T8.7.7.16.9.1" class="ltx_text" style="background-color:#FAC7CA;">-5.33%</span></td>
<td id="A1.T8.7.7.16.10" class="ltx_td ltx_align_center">30.33%</td>
<td id="A1.T8.7.7.16.11" class="ltx_td ltx_align_center" style="background-color:#EEF2FA;"><span id="A1.T8.7.7.16.11.1" class="ltx_text" style="background-color:#EEF2FA;">1.33%</span></td>
<td id="A1.T8.7.7.16.12" class="ltx_td ltx_align_center">39.67%</td>
<td id="A1.T8.7.7.16.13" class="ltx_td ltx_align_center" style="background-color:#FBDEE1;"><span id="A1.T8.7.7.16.13.1" class="ltx_text" style="background-color:#FBDEE1;">-3.00%</span></td>
<td id="A1.T8.7.7.16.14" class="ltx_td ltx_align_center">71.67%</td>
<td id="A1.T8.7.7.16.15" class="ltx_td ltx_align_center" style="background-color:#FBEBEE;"><span id="A1.T8.7.7.16.15.1" class="ltx_text" style="background-color:#FBEBEE;">-1.67%</span></td>
</tr>
<tr id="A1.T8.7.7.17" class="ltx_tr">
<td id="A1.T8.7.7.17.1" class="ltx_td ltx_align_left">w/o partition mark</td>
<td id="A1.T8.7.7.17.2" class="ltx_td ltx_align_center">92.00%</td>
<td id="A1.T8.7.7.17.3" class="ltx_td ltx_align_center" style="background-color:#FBE8EB;"><span id="A1.T8.7.7.17.3.1" class="ltx_text" style="background-color:#FBE8EB;">-2.00%</span></td>
<td id="A1.T8.7.7.17.4" class="ltx_td ltx_align_center">48.67%</td>
<td id="A1.T8.7.7.17.5" class="ltx_td ltx_align_center" style="background-color:#BCCFE9;"><span id="A1.T8.7.7.17.5.1" class="ltx_text" style="background-color:#BCCFE9;">6.00%</span></td>
<td id="A1.T8.7.7.17.6" class="ltx_td ltx_align_center">44.00%</td>
<td id="A1.T8.7.7.17.7" class="ltx_td ltx_align_center" style="background-color:#F99699;"><span id="A1.T8.7.7.17.7.1" class="ltx_text" style="background-color:#F99699;">-10.33%</span></td>
<td id="A1.T8.7.7.17.8" class="ltx_td ltx_align_center">59.67%</td>
<td id="A1.T8.7.7.17.9" class="ltx_td ltx_align_center" style="background-color:#C3D4EB;"><span id="A1.T8.7.7.17.9.1" class="ltx_text" style="background-color:#C3D4EB;">5.33%</span></td>
<td id="A1.T8.7.7.17.10" class="ltx_td ltx_align_center">40.33%</td>
<td id="A1.T8.7.7.17.11" class="ltx_td ltx_align_center" style="background-color:#82A6D4;"><span id="A1.T8.7.7.17.11.1" class="ltx_text" style="background-color:#82A6D4;">11.33%</span></td>
<td id="A1.T8.7.7.17.12" class="ltx_td ltx_align_center">39.67%</td>
<td id="A1.T8.7.7.17.13" class="ltx_td ltx_align_center" style="background-color:#FBDEE1;"><span id="A1.T8.7.7.17.13.1" class="ltx_text" style="background-color:#FBDEE1;">-3.00%</span></td>
<td id="A1.T8.7.7.17.14" class="ltx_td ltx_align_center">72.67%</td>
<td id="A1.T8.7.7.17.15" class="ltx_td ltx_align_center" style="background-color:#FBF5F8;"><span id="A1.T8.7.7.17.15.1" class="ltx_text" style="background-color:#FBF5F8;">-0.67%</span></td>
</tr>
<tr id="A1.T8.7.7.18" class="ltx_tr">
<td id="A1.T8.7.7.18.1" class="ltx_td ltx_align_left">w/o role prompting</td>
<td id="A1.T8.7.7.18.2" class="ltx_td ltx_align_center">90.67%</td>
<td id="A1.T8.7.7.18.3" class="ltx_td ltx_align_center" style="background-color:#FBDBDE;"><span id="A1.T8.7.7.18.3.1" class="ltx_text" style="background-color:#FBDBDE;">-3.33%</span></td>
<td id="A1.T8.7.7.18.4" class="ltx_td ltx_align_center">44.67%</td>
<td id="A1.T8.7.7.18.5" class="ltx_td ltx_align_center" style="background-color:#E7EDF8;"><span id="A1.T8.7.7.18.5.1" class="ltx_text" style="background-color:#E7EDF8;">2.00%</span></td>
<td id="A1.T8.7.7.18.6" class="ltx_td ltx_align_center">41.67%</td>
<td id="A1.T8.7.7.18.7" class="ltx_td ltx_align_center" style="background-color:#F87F82;"><span id="A1.T8.7.7.18.7.1" class="ltx_text" style="background-color:#F87F82;">-12.67%</span></td>
<td id="A1.T8.7.7.18.8" class="ltx_td ltx_align_center">57.33%</td>
<td id="A1.T8.7.7.18.9" class="ltx_td ltx_align_center" style="background-color:#DCE6F4;"><span id="A1.T8.7.7.18.9.1" class="ltx_text" style="background-color:#DCE6F4;">3.00%</span></td>
<td id="A1.T8.7.7.18.10" class="ltx_td ltx_align_center">29.33%</td>
<td id="A1.T8.7.7.18.11" class="ltx_td ltx_align_center" style="background-color:#F9FAFE;"><span id="A1.T8.7.7.18.11.1" class="ltx_text" style="background-color:#F9FAFE;">0.33%</span></td>
<td id="A1.T8.7.7.18.12" class="ltx_td ltx_align_center">38.33%</td>
<td id="A1.T8.7.7.18.13" class="ltx_td ltx_align_center" style="background-color:#FAD1D4;"><span id="A1.T8.7.7.18.13.1" class="ltx_text" style="background-color:#FAD1D4;">-4.33%</span></td>
<td id="A1.T8.7.7.18.14" class="ltx_td ltx_align_center">72.67%</td>
<td id="A1.T8.7.7.18.15" class="ltx_td ltx_align_center" style="background-color:#FBF5F8;"><span id="A1.T8.7.7.18.15.1" class="ltx_text" style="background-color:#FBF5F8;">-0.67%</span></td>
</tr>
<tr id="A1.T8.7.7.19" class="ltx_tr">
<td id="A1.T8.7.7.19.1" class="ltx_td ltx_align_left">w/o change order</td>
<td id="A1.T8.7.7.19.2" class="ltx_td ltx_align_center">90.67%</td>
<td id="A1.T8.7.7.19.3" class="ltx_td ltx_align_center" style="background-color:#FBDBDE;"><span id="A1.T8.7.7.19.3.1" class="ltx_text" style="background-color:#FBDBDE;">-3.33%</span></td>
<td id="A1.T8.7.7.19.4" class="ltx_td ltx_align_center">37.67%</td>
<td id="A1.T8.7.7.19.5" class="ltx_td ltx_align_center" style="background-color:#FACBCD;"><span id="A1.T8.7.7.19.5.1" class="ltx_text" style="background-color:#FACBCD;">-5.00%</span></td>
<td id="A1.T8.7.7.19.6" class="ltx_td ltx_align_center">42.67%</td>
<td id="A1.T8.7.7.19.7" class="ltx_td ltx_align_center" style="background-color:#F8898B;"><span id="A1.T8.7.7.19.7.1" class="ltx_text" style="background-color:#F8898B;">-11.67%</span></td>
<td id="A1.T8.7.7.19.8" class="ltx_td ltx_align_center">55.67%</td>
<td id="A1.T8.7.7.19.9" class="ltx_td ltx_align_center" style="background-color:#EEF2FA;"><span id="A1.T8.7.7.19.9.1" class="ltx_text" style="background-color:#EEF2FA;">1.33%</span></td>
<td id="A1.T8.7.7.19.10" class="ltx_td ltx_align_center">26.00%</td>
<td id="A1.T8.7.7.19.11" class="ltx_td ltx_align_center" style="background-color:#FBDEE1;"><span id="A1.T8.7.7.19.11.1" class="ltx_text" style="background-color:#FBDEE1;">-3.00%</span></td>
<td id="A1.T8.7.7.19.12" class="ltx_td ltx_align_center">33.00%</td>
<td id="A1.T8.7.7.19.13" class="ltx_td ltx_align_center" style="background-color:#F99D9F;"><span id="A1.T8.7.7.19.13.1" class="ltx_text" style="background-color:#F99D9F;">-9.67%</span></td>
<td id="A1.T8.7.7.19.14" class="ltx_td ltx_align_center">62.67%</td>
<td id="A1.T8.7.7.19.15" class="ltx_td ltx_align_center" style="background-color:#F99395;"><span id="A1.T8.7.7.19.15.1" class="ltx_text" style="background-color:#F99395;">-10.67%</span></td>
</tr>
<tr id="A1.T8.7.7.20" class="ltx_tr">
<td id="A1.T8.7.7.20.1" class="ltx_td ltx_align_left ltx_border_t"><span id="A1.T8.7.7.20.1.1" class="ltx_text ltx_font_bold">w/o 1-shot</span></td>
<td id="A1.T8.7.7.20.2" class="ltx_td ltx_align_center ltx_border_t">74.67%</td>
<td id="A1.T8.7.7.20.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="A1.T8.7.7.20.3.1" class="ltx_text" style="background-color:#F8696B;">-19.33%</span></td>
<td id="A1.T8.7.7.20.4" class="ltx_td ltx_align_center ltx_border_t">11.33%</td>
<td id="A1.T8.7.7.20.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="A1.T8.7.7.20.5.1" class="ltx_text" style="background-color:#F8696B;">-31.33%</span></td>
<td id="A1.T8.7.7.20.6" class="ltx_td ltx_align_center ltx_border_t">30.00%</td>
<td id="A1.T8.7.7.20.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="A1.T8.7.7.20.7.1" class="ltx_text" style="background-color:#F8696B;">-24.33%</span></td>
<td id="A1.T8.7.7.20.8" class="ltx_td ltx_align_center ltx_border_t">52.67%</td>
<td id="A1.T8.7.7.20.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FBEBEE;"><span id="A1.T8.7.7.20.9.1" class="ltx_text" style="background-color:#FBEBEE;">-1.67%</span></td>
<td id="A1.T8.7.7.20.10" class="ltx_td ltx_align_center ltx_border_t">14.00%</td>
<td id="A1.T8.7.7.20.11" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="A1.T8.7.7.20.11.1" class="ltx_text" style="background-color:#F8696B;">-15.00%</span></td>
<td id="A1.T8.7.7.20.12" class="ltx_td ltx_align_center ltx_border_t">27.33%</td>
<td id="A1.T8.7.7.20.13" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="A1.T8.7.7.20.13.1" class="ltx_text" style="background-color:#F8696B;">-15.33%</span></td>
<td id="A1.T8.7.7.20.14" class="ltx_td ltx_align_center ltx_border_t">19.67%</td>
<td id="A1.T8.7.7.20.15" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="A1.T8.7.7.20.15.1" class="ltx_text" style="background-color:#F8696B;">-53.67%</span></td>
</tr>
<tr id="A1.T8.7.7.21" class="ltx_tr">
<td id="A1.T8.7.7.21.1" class="ltx_td ltx_align_left ltx_border_t"><span id="A1.T8.7.7.21.1.1" class="ltx_text ltx_font_bold">Markup Lang. Markdown</span></td>
<td id="A1.T8.7.7.21.2" class="ltx_td ltx_align_center ltx_border_t">92.33%</td>
<td id="A1.T8.7.7.21.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.21.3.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.21.4" class="ltx_td ltx_align_center ltx_border_t">43.33%</td>
<td id="A1.T8.7.7.21.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.21.5.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.21.6" class="ltx_td ltx_align_center ltx_border_t">51.00%</td>
<td id="A1.T8.7.7.21.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.21.7.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.21.8" class="ltx_td ltx_align_center ltx_border_t">35.33%</td>
<td id="A1.T8.7.7.21.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.21.9.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.21.10" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T8.7.7.21.10.1" class="ltx_text ltx_font_bold">42.33%</span></td>
<td id="A1.T8.7.7.21.11" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.21.11.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.21.12" class="ltx_td ltx_align_center ltx_border_t">40.67%</td>
<td id="A1.T8.7.7.21.13" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.21.13.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.21.14" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T8.7.7.21.14.1" class="ltx_text ltx_font_bold">78.00%</span></td>
<td id="A1.T8.7.7.21.15" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.21.15.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
</tr>
<tr id="A1.T8.7.7.22" class="ltx_tr">
<td id="A1.T8.7.7.22.1" class="ltx_td ltx_align_left">w/o format explanation</td>
<td id="A1.T8.7.7.22.2" class="ltx_td ltx_align_center">88.00%</td>
<td id="A1.T8.7.7.22.3" class="ltx_td ltx_align_center" style="background-color:#FAD1D4;"><span id="A1.T8.7.7.22.3.1" class="ltx_text" style="background-color:#FAD1D4;">-4.33%</span></td>
<td id="A1.T8.7.7.22.4" class="ltx_td ltx_align_center"><span id="A1.T8.7.7.22.4.1" class="ltx_text ltx_font_bold">56.00%</span></td>
<td id="A1.T8.7.7.22.5" class="ltx_td ltx_align_center" style="background-color:#749CCF;"><span id="A1.T8.7.7.22.5.1" class="ltx_text" style="background-color:#749CCF;">12.67%</span></td>
<td id="A1.T8.7.7.22.6" class="ltx_td ltx_align_center">50.67%</td>
<td id="A1.T8.7.7.22.7" class="ltx_td ltx_align_center" style="background-color:#FBF8FB;"><span id="A1.T8.7.7.22.7.1" class="ltx_text" style="background-color:#FBF8FB;">-0.33%</span></td>
<td id="A1.T8.7.7.22.8" class="ltx_td ltx_align_center">34.33%</td>
<td id="A1.T8.7.7.22.9" class="ltx_td ltx_align_center" style="background-color:#FBF2F5;"><span id="A1.T8.7.7.22.9.1" class="ltx_text" style="background-color:#FBF2F5;">-1.00%</span></td>
<td id="A1.T8.7.7.22.10" class="ltx_td ltx_align_center">33.33%</td>
<td id="A1.T8.7.7.22.11" class="ltx_td ltx_align_center" style="background-color:#F9A3A6;"><span id="A1.T8.7.7.22.11.1" class="ltx_text" style="background-color:#F9A3A6;">-9.00%</span></td>
<td id="A1.T8.7.7.22.12" class="ltx_td ltx_align_center">39.00%</td>
<td id="A1.T8.7.7.22.13" class="ltx_td ltx_align_center" style="background-color:#FBEBEE;"><span id="A1.T8.7.7.22.13.1" class="ltx_text" style="background-color:#FBEBEE;">-1.67%</span></td>
<td id="A1.T8.7.7.22.14" class="ltx_td ltx_align_center">74.00%</td>
<td id="A1.T8.7.7.22.15" class="ltx_td ltx_align_center" style="background-color:#FAD4D7;"><span id="A1.T8.7.7.22.15.1" class="ltx_text" style="background-color:#FAD4D7;">-4.00%</span></td>
</tr>
<tr id="A1.T8.7.7.23" class="ltx_tr">
<td id="A1.T8.7.7.23.1" class="ltx_td ltx_align_left">w/o partition mark</td>
<td id="A1.T8.7.7.23.2" class="ltx_td ltx_align_center">96.33%</td>
<td id="A1.T8.7.7.23.3" class="ltx_td ltx_align_center" style="background-color:#D1DEF0;"><span id="A1.T8.7.7.23.3.1" class="ltx_text" style="background-color:#D1DEF0;">4.00%</span></td>
<td id="A1.T8.7.7.23.4" class="ltx_td ltx_align_center">52.67%</td>
<td id="A1.T8.7.7.23.5" class="ltx_td ltx_align_center" style="background-color:#98B6DC;"><span id="A1.T8.7.7.23.5.1" class="ltx_text" style="background-color:#98B6DC;">9.33%</span></td>
<td id="A1.T8.7.7.23.6" class="ltx_td ltx_align_center">54.67%</td>
<td id="A1.T8.7.7.23.7" class="ltx_td ltx_align_center" style="background-color:#D5E1F2;"><span id="A1.T8.7.7.23.7.1" class="ltx_text" style="background-color:#D5E1F2;">3.67%</span></td>
<td id="A1.T8.7.7.23.8" class="ltx_td ltx_align_center">35.33%</td>
<td id="A1.T8.7.7.23.9" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.23.9.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.23.10" class="ltx_td ltx_align_center"><span id="A1.T8.7.7.23.10.1" class="ltx_text ltx_font_bold">45.00%</span></td>
<td id="A1.T8.7.7.23.11" class="ltx_td ltx_align_center" style="background-color:#E0E8F5;"><span id="A1.T8.7.7.23.11.1" class="ltx_text" style="background-color:#E0E8F5;">2.67%</span></td>
<td id="A1.T8.7.7.23.12" class="ltx_td ltx_align_center">43.00%</td>
<td id="A1.T8.7.7.23.13" class="ltx_td ltx_align_center" style="background-color:#E3EBF7;"><span id="A1.T8.7.7.23.13.1" class="ltx_text" style="background-color:#E3EBF7;">2.33%</span></td>
<td id="A1.T8.7.7.23.14" class="ltx_td ltx_align_center">74.67%</td>
<td id="A1.T8.7.7.23.15" class="ltx_td ltx_align_center" style="background-color:#FBDBDE;"><span id="A1.T8.7.7.23.15.1" class="ltx_text" style="background-color:#FBDBDE;">-3.33%</span></td>
</tr>
<tr id="A1.T8.7.7.24" class="ltx_tr">
<td id="A1.T8.7.7.24.1" class="ltx_td ltx_align_left">w/o role prompting</td>
<td id="A1.T8.7.7.24.2" class="ltx_td ltx_align_center">94.33%</td>
<td id="A1.T8.7.7.24.3" class="ltx_td ltx_align_center" style="background-color:#E7EDF8;"><span id="A1.T8.7.7.24.3.1" class="ltx_text" style="background-color:#E7EDF8;">2.00%</span></td>
<td id="A1.T8.7.7.24.4" class="ltx_td ltx_align_center">48.33%</td>
<td id="A1.T8.7.7.24.5" class="ltx_td ltx_align_center" style="background-color:#C7D7ED;"><span id="A1.T8.7.7.24.5.1" class="ltx_text" style="background-color:#C7D7ED;">5.00%</span></td>
<td id="A1.T8.7.7.24.6" class="ltx_td ltx_align_center"><span id="A1.T8.7.7.24.6.1" class="ltx_text ltx_font_bold">58.67%</span></td>
<td id="A1.T8.7.7.24.7" class="ltx_td ltx_align_center" style="background-color:#AAC2E2;"><span id="A1.T8.7.7.24.7.1" class="ltx_text" style="background-color:#AAC2E2;">7.67%</span></td>
<td id="A1.T8.7.7.24.8" class="ltx_td ltx_align_center">35.67%</td>
<td id="A1.T8.7.7.24.9" class="ltx_td ltx_align_center" style="background-color:#F9FAFE;"><span id="A1.T8.7.7.24.9.1" class="ltx_text" style="background-color:#F9FAFE;">0.33%</span></td>
<td id="A1.T8.7.7.24.10" class="ltx_td ltx_align_center">39.67%</td>
<td id="A1.T8.7.7.24.11" class="ltx_td ltx_align_center" style="background-color:#FBE1E4;"><span id="A1.T8.7.7.24.11.1" class="ltx_text" style="background-color:#FBE1E4;">-2.67%</span></td>
<td id="A1.T8.7.7.24.12" class="ltx_td ltx_align_center">40.00%</td>
<td id="A1.T8.7.7.24.13" class="ltx_td ltx_align_center" style="background-color:#FBF5F8;"><span id="A1.T8.7.7.24.13.1" class="ltx_text" style="background-color:#FBF5F8;">-0.67%</span></td>
<td id="A1.T8.7.7.24.14" class="ltx_td ltx_align_center"><span id="A1.T8.7.7.24.14.1" class="ltx_text ltx_font_bold">78.00%</span></td>
<td id="A1.T8.7.7.24.15" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.24.15.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
</tr>
<tr id="A1.T8.7.7.25" class="ltx_tr">
<td id="A1.T8.7.7.25.1" class="ltx_td ltx_align_left">w/o change order</td>
<td id="A1.T8.7.7.25.2" class="ltx_td ltx_align_center">89.67%</td>
<td id="A1.T8.7.7.25.3" class="ltx_td ltx_align_center" style="background-color:#FBE1E4;"><span id="A1.T8.7.7.25.3.1" class="ltx_text" style="background-color:#FBE1E4;">-2.67%</span></td>
<td id="A1.T8.7.7.25.4" class="ltx_td ltx_align_center">40.33%</td>
<td id="A1.T8.7.7.25.5" class="ltx_td ltx_align_center" style="background-color:#FBDEE1;"><span id="A1.T8.7.7.25.5.1" class="ltx_text" style="background-color:#FBDEE1;">-3.00%</span></td>
<td id="A1.T8.7.7.25.6" class="ltx_td ltx_align_center">52.00%</td>
<td id="A1.T8.7.7.25.7" class="ltx_td ltx_align_center" style="background-color:#F2F5FC;"><span id="A1.T8.7.7.25.7.1" class="ltx_text" style="background-color:#F2F5FC;">1.00%</span></td>
<td id="A1.T8.7.7.25.8" class="ltx_td ltx_align_center">36.67%</td>
<td id="A1.T8.7.7.25.9" class="ltx_td ltx_align_center" style="background-color:#EEF2FA;"><span id="A1.T8.7.7.25.9.1" class="ltx_text" style="background-color:#EEF2FA;">1.33%</span></td>
<td id="A1.T8.7.7.25.10" class="ltx_td ltx_align_center">34.00%</td>
<td id="A1.T8.7.7.25.11" class="ltx_td ltx_align_center" style="background-color:#F9AAAC;"><span id="A1.T8.7.7.25.11.1" class="ltx_text" style="background-color:#F9AAAC;">-8.33%</span></td>
<td id="A1.T8.7.7.25.12" class="ltx_td ltx_align_center">24.67%</td>
<td id="A1.T8.7.7.25.13" class="ltx_td ltx_align_center" style="background-color:#F8696B;"><span id="A1.T8.7.7.25.13.1" class="ltx_text" style="background-color:#F8696B;">-16.00%</span></td>
<td id="A1.T8.7.7.25.14" class="ltx_td ltx_align_center">59.67%</td>
<td id="A1.T8.7.7.25.15" class="ltx_td ltx_align_center" style="background-color:#F8696B;"><span id="A1.T8.7.7.25.15.1" class="ltx_text" style="background-color:#F8696B;">-18.33%</span></td>
</tr>
<tr id="A1.T8.7.7.26" class="ltx_tr">
<td id="A1.T8.7.7.26.1" class="ltx_td ltx_align_left ltx_border_t"><span id="A1.T8.7.7.26.1.1" class="ltx_text ltx_font_bold">w/o 1-shot</span></td>
<td id="A1.T8.7.7.26.2" class="ltx_td ltx_align_center ltx_border_t">60.70%</td>
<td id="A1.T8.7.7.26.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="A1.T8.7.7.26.3.1" class="ltx_text" style="background-color:#F8696B;">-31.64%</span></td>
<td id="A1.T8.7.7.26.4" class="ltx_td ltx_align_center ltx_border_t">8.67%</td>
<td id="A1.T8.7.7.26.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="A1.T8.7.7.26.5.1" class="ltx_text" style="background-color:#F8696B;">-34.67%</span></td>
<td id="A1.T8.7.7.26.6" class="ltx_td ltx_align_center ltx_border_t">35.33%</td>
<td id="A1.T8.7.7.26.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="A1.T8.7.7.26.7.1" class="ltx_text" style="background-color:#F8696B;">-15.67%</span></td>
<td id="A1.T8.7.7.26.8" class="ltx_td ltx_align_center ltx_border_t">30.67%</td>
<td id="A1.T8.7.7.26.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FACED0;"><span id="A1.T8.7.7.26.9.1" class="ltx_text" style="background-color:#FACED0;">-4.67%</span></td>
<td id="A1.T8.7.7.26.10" class="ltx_td ltx_align_center ltx_border_t">19.00%</td>
<td id="A1.T8.7.7.26.11" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="A1.T8.7.7.26.11.1" class="ltx_text" style="background-color:#F8696B;">-23.33%</span></td>
<td id="A1.T8.7.7.26.12" class="ltx_td ltx_align_center ltx_border_t">11.67%</td>
<td id="A1.T8.7.7.26.13" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="A1.T8.7.7.26.13.1" class="ltx_text" style="background-color:#F8696B;">-29.00%</span></td>
<td id="A1.T8.7.7.26.14" class="ltx_td ltx_align_center ltx_border_t">23.67%</td>
<td id="A1.T8.7.7.26.15" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="A1.T8.7.7.26.15.1" class="ltx_text" style="background-color:#F8696B;">-54.33%</span></td>
</tr>
<tr id="A1.T8.7.7.27" class="ltx_tr">
<td id="A1.T8.7.7.27.1" class="ltx_td ltx_align_left ltx_border_t"><span id="A1.T8.7.7.27.1.1" class="ltx_text ltx_font_bold">Markup Lang. XML</span></td>
<td id="A1.T8.7.7.27.2" class="ltx_td ltx_align_center ltx_border_t">96.00%</td>
<td id="A1.T8.7.7.27.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.27.3.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.27.4" class="ltx_td ltx_align_center ltx_border_t">43.33%</td>
<td id="A1.T8.7.7.27.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.27.5.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.27.6" class="ltx_td ltx_align_center ltx_border_t">55.00%</td>
<td id="A1.T8.7.7.27.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.27.7.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.27.8" class="ltx_td ltx_align_center ltx_border_t">41.33%</td>
<td id="A1.T8.7.7.27.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.27.9.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.27.10" class="ltx_td ltx_align_center ltx_border_t">41.00%</td>
<td id="A1.T8.7.7.27.11" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.27.11.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.27.12" class="ltx_td ltx_align_center ltx_border_t">43.67%</td>
<td id="A1.T8.7.7.27.13" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.27.13.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.27.14" class="ltx_td ltx_align_center ltx_border_t">75.00%</td>
<td id="A1.T8.7.7.27.15" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.27.15.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
</tr>
<tr id="A1.T8.7.7.28" class="ltx_tr">
<td id="A1.T8.7.7.28.1" class="ltx_td ltx_align_left">w/o format explanation</td>
<td id="A1.T8.7.7.28.2" class="ltx_td ltx_align_center">89.00%</td>
<td id="A1.T8.7.7.28.3" class="ltx_td ltx_align_center" style="background-color:#FAB7B9;"><span id="A1.T8.7.7.28.3.1" class="ltx_text" style="background-color:#FAB7B9;">-7.00%</span></td>
<td id="A1.T8.7.7.28.4" class="ltx_td ltx_align_center"><span id="A1.T8.7.7.28.4.1" class="ltx_text ltx_font_bold">58.33%</span></td>
<td id="A1.T8.7.7.28.5" class="ltx_td ltx_align_center" style="background-color:#5A8AC6;"><span id="A1.T8.7.7.28.5.1" class="ltx_text" style="background-color:#5A8AC6;">15.00%</span></td>
<td id="A1.T8.7.7.28.6" class="ltx_td ltx_align_center">51.33%</td>
<td id="A1.T8.7.7.28.7" class="ltx_td ltx_align_center" style="background-color:#FBD8DA;"><span id="A1.T8.7.7.28.7.1" class="ltx_text" style="background-color:#FBD8DA;">-3.67%</span></td>
<td id="A1.T8.7.7.28.8" class="ltx_td ltx_align_center">35.33%</td>
<td id="A1.T8.7.7.28.9" class="ltx_td ltx_align_center" style="background-color:#FAC1C3;"><span id="A1.T8.7.7.28.9.1" class="ltx_text" style="background-color:#FAC1C3;">-6.00%</span></td>
<td id="A1.T8.7.7.28.10" class="ltx_td ltx_align_center">32.67%</td>
<td id="A1.T8.7.7.28.11" class="ltx_td ltx_align_center" style="background-color:#F9AAAC;"><span id="A1.T8.7.7.28.11.1" class="ltx_text" style="background-color:#F9AAAC;">-8.33%</span></td>
<td id="A1.T8.7.7.28.12" class="ltx_td ltx_align_center">37.67%</td>
<td id="A1.T8.7.7.28.13" class="ltx_td ltx_align_center" style="background-color:#FAC1C3;"><span id="A1.T8.7.7.28.13.1" class="ltx_text" style="background-color:#FAC1C3;">-6.00%</span></td>
<td id="A1.T8.7.7.28.14" class="ltx_td ltx_align_center">74.00%</td>
<td id="A1.T8.7.7.28.15" class="ltx_td ltx_align_center" style="background-color:#FBF2F5;"><span id="A1.T8.7.7.28.15.1" class="ltx_text" style="background-color:#FBF2F5;">-1.00%</span></td>
</tr>
<tr id="A1.T8.7.7.29" class="ltx_tr">
<td id="A1.T8.7.7.29.1" class="ltx_td ltx_align_left">w/o partition mark</td>
<td id="A1.T8.7.7.29.2" class="ltx_td ltx_align_center">96.33%</td>
<td id="A1.T8.7.7.29.3" class="ltx_td ltx_align_center" style="background-color:#F9FAFE;"><span id="A1.T8.7.7.29.3.1" class="ltx_text" style="background-color:#F9FAFE;">0.33%</span></td>
<td id="A1.T8.7.7.29.4" class="ltx_td ltx_align_center">54.67%</td>
<td id="A1.T8.7.7.29.5" class="ltx_td ltx_align_center" style="background-color:#82A6D4;"><span id="A1.T8.7.7.29.5.1" class="ltx_text" style="background-color:#82A6D4;">11.33%</span></td>
<td id="A1.T8.7.7.29.6" class="ltx_td ltx_align_center">55.00%</td>
<td id="A1.T8.7.7.29.7" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.29.7.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.29.8" class="ltx_td ltx_align_center">36.00%</td>
<td id="A1.T8.7.7.29.9" class="ltx_td ltx_align_center" style="background-color:#FAC7CA;"><span id="A1.T8.7.7.29.9.1" class="ltx_text" style="background-color:#FAC7CA;">-5.33%</span></td>
<td id="A1.T8.7.7.29.10" class="ltx_td ltx_align_center"><span id="A1.T8.7.7.29.10.1" class="ltx_text ltx_font_bold">48.00%</span></td>
<td id="A1.T8.7.7.29.11" class="ltx_td ltx_align_center" style="background-color:#B1C7E5;"><span id="A1.T8.7.7.29.11.1" class="ltx_text" style="background-color:#B1C7E5;">7.00%</span></td>
<td id="A1.T8.7.7.29.12" class="ltx_td ltx_align_center">39.33%</td>
<td id="A1.T8.7.7.29.13" class="ltx_td ltx_align_center" style="background-color:#FAD1D4;"><span id="A1.T8.7.7.29.13.1" class="ltx_text" style="background-color:#FAD1D4;">-4.33%</span></td>
<td id="A1.T8.7.7.29.14" class="ltx_td ltx_align_center">74.33%</td>
<td id="A1.T8.7.7.29.15" class="ltx_td ltx_align_center" style="background-color:#FBF5F8;"><span id="A1.T8.7.7.29.15.1" class="ltx_text" style="background-color:#FBF5F8;">-0.67%</span></td>
</tr>
<tr id="A1.T8.7.7.30" class="ltx_tr">
<td id="A1.T8.7.7.30.1" class="ltx_td ltx_align_left">w/o role prompting</td>
<td id="A1.T8.7.7.30.2" class="ltx_td ltx_align_center">93.67%</td>
<td id="A1.T8.7.7.30.3" class="ltx_td ltx_align_center" style="background-color:#FBE5E7;"><span id="A1.T8.7.7.30.3.1" class="ltx_text" style="background-color:#FBE5E7;">-2.33%</span></td>
<td id="A1.T8.7.7.30.4" class="ltx_td ltx_align_center">47.33%</td>
<td id="A1.T8.7.7.30.5" class="ltx_td ltx_align_center" style="background-color:#D1DEF0;"><span id="A1.T8.7.7.30.5.1" class="ltx_text" style="background-color:#D1DEF0;">4.00%</span></td>
<td id="A1.T8.7.7.30.6" class="ltx_td ltx_align_center"><span id="A1.T8.7.7.30.6.1" class="ltx_text ltx_font_bold">60.33%</span></td>
<td id="A1.T8.7.7.30.7" class="ltx_td ltx_align_center" style="background-color:#C3D4EB;"><span id="A1.T8.7.7.30.7.1" class="ltx_text" style="background-color:#C3D4EB;">5.33%</span></td>
<td id="A1.T8.7.7.30.8" class="ltx_td ltx_align_center">42.33%</td>
<td id="A1.T8.7.7.30.9" class="ltx_td ltx_align_center" style="background-color:#F2F5FC;"><span id="A1.T8.7.7.30.9.1" class="ltx_text" style="background-color:#F2F5FC;">1.00%</span></td>
<td id="A1.T8.7.7.30.10" class="ltx_td ltx_align_center">37.00%</td>
<td id="A1.T8.7.7.30.11" class="ltx_td ltx_align_center" style="background-color:#FAD4D7;"><span id="A1.T8.7.7.30.11.1" class="ltx_text" style="background-color:#FAD4D7;">-4.00%</span></td>
<td id="A1.T8.7.7.30.12" class="ltx_td ltx_align_center">40.67%</td>
<td id="A1.T8.7.7.30.13" class="ltx_td ltx_align_center" style="background-color:#FBDEE1;"><span id="A1.T8.7.7.30.13.1" class="ltx_text" style="background-color:#FBDEE1;">-3.00%</span></td>
<td id="A1.T8.7.7.30.14" class="ltx_td ltx_align_center">73.33%</td>
<td id="A1.T8.7.7.30.15" class="ltx_td ltx_align_center" style="background-color:#FBEBEE;"><span id="A1.T8.7.7.30.15.1" class="ltx_text" style="background-color:#FBEBEE;">-1.67%</span></td>
</tr>
<tr id="A1.T8.7.7.31" class="ltx_tr">
<td id="A1.T8.7.7.31.1" class="ltx_td ltx_align_left">w/o change order</td>
<td id="A1.T8.7.7.31.2" class="ltx_td ltx_align_center">88.67%</td>
<td id="A1.T8.7.7.31.3" class="ltx_td ltx_align_center" style="background-color:#FAB4B6;"><span id="A1.T8.7.7.31.3.1" class="ltx_text" style="background-color:#FAB4B6;">-7.33%</span></td>
<td id="A1.T8.7.7.31.4" class="ltx_td ltx_align_center">42.33%</td>
<td id="A1.T8.7.7.31.5" class="ltx_td ltx_align_center" style="background-color:#FBF2F5;"><span id="A1.T8.7.7.31.5.1" class="ltx_text" style="background-color:#FBF2F5;">-1.00%</span></td>
<td id="A1.T8.7.7.31.6" class="ltx_td ltx_align_center">49.00%</td>
<td id="A1.T8.7.7.31.7" class="ltx_td ltx_align_center" style="background-color:#FAC1C3;"><span id="A1.T8.7.7.31.7.1" class="ltx_text" style="background-color:#FAC1C3;">-6.00%</span></td>
<td id="A1.T8.7.7.31.8" class="ltx_td ltx_align_center">37.67%</td>
<td id="A1.T8.7.7.31.9" class="ltx_td ltx_align_center" style="background-color:#FBD8DA;"><span id="A1.T8.7.7.31.9.1" class="ltx_text" style="background-color:#FBD8DA;">-3.67%</span></td>
<td id="A1.T8.7.7.31.10" class="ltx_td ltx_align_center">33.33%</td>
<td id="A1.T8.7.7.31.11" class="ltx_td ltx_align_center" style="background-color:#F9B0B3;"><span id="A1.T8.7.7.31.11.1" class="ltx_text" style="background-color:#F9B0B3;">-7.67%</span></td>
<td id="A1.T8.7.7.31.12" class="ltx_td ltx_align_center">27.00%</td>
<td id="A1.T8.7.7.31.13" class="ltx_td ltx_align_center" style="background-color:#F8696B;"><span id="A1.T8.7.7.31.13.1" class="ltx_text" style="background-color:#F8696B;">-16.67%</span></td>
<td id="A1.T8.7.7.31.14" class="ltx_td ltx_align_center">57.00%</td>
<td id="A1.T8.7.7.31.15" class="ltx_td ltx_align_center" style="background-color:#F8696B;"><span id="A1.T8.7.7.31.15.1" class="ltx_text" style="background-color:#F8696B;">-18.00%</span></td>
</tr>
<tr id="A1.T8.7.7.32" class="ltx_tr">
<td id="A1.T8.7.7.32.1" class="ltx_td ltx_align_left ltx_border_t"><span id="A1.T8.7.7.32.1.1" class="ltx_text ltx_font_bold">w/o 1-shot</span></td>
<td id="A1.T8.7.7.32.2" class="ltx_td ltx_align_center ltx_border_t">69.33%</td>
<td id="A1.T8.7.7.32.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="A1.T8.7.7.32.3.1" class="ltx_text" style="background-color:#F8696B;">-26.67%</span></td>
<td id="A1.T8.7.7.32.4" class="ltx_td ltx_align_center ltx_border_t">9.00%</td>
<td id="A1.T8.7.7.32.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="A1.T8.7.7.32.5.1" class="ltx_text" style="background-color:#F8696B;">-34.33%</span></td>
<td id="A1.T8.7.7.32.6" class="ltx_td ltx_align_center ltx_border_t">33.00%</td>
<td id="A1.T8.7.7.32.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="A1.T8.7.7.32.7.1" class="ltx_text" style="background-color:#F8696B;">-22.00%</span></td>
<td id="A1.T8.7.7.32.8" class="ltx_td ltx_align_center ltx_border_t">25.33%</td>
<td id="A1.T8.7.7.32.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="A1.T8.7.7.32.9.1" class="ltx_text" style="background-color:#F8696B;">-16.00%</span></td>
<td id="A1.T8.7.7.32.10" class="ltx_td ltx_align_center ltx_border_t">15.33%</td>
<td id="A1.T8.7.7.32.11" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="A1.T8.7.7.32.11.1" class="ltx_text" style="background-color:#F8696B;">-25.67%</span></td>
<td id="A1.T8.7.7.32.12" class="ltx_td ltx_align_center ltx_border_t">12.67%</td>
<td id="A1.T8.7.7.32.13" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="A1.T8.7.7.32.13.1" class="ltx_text" style="background-color:#F8696B;">-31.00%</span></td>
<td id="A1.T8.7.7.32.14" class="ltx_td ltx_align_center ltx_border_t">22.33%</td>
<td id="A1.T8.7.7.32.15" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#F8696B;"><span id="A1.T8.7.7.32.15.1" class="ltx_text" style="background-color:#F8696B;">-52.67%</span></td>
</tr>
<tr id="A1.T8.7.7.33" class="ltx_tr">
<td id="A1.T8.7.7.33.1" class="ltx_td ltx_align_left ltx_border_t"><span id="A1.T8.7.7.33.1.1" class="ltx_text ltx_font_bold">Markup Lang. HTML</span></td>
<td id="A1.T8.7.7.33.2" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T8.7.7.33.2.1" class="ltx_text ltx_font_bold">96.67%</span></td>
<td id="A1.T8.7.7.33.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.33.3.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.33.4" class="ltx_td ltx_align_center ltx_border_t">44.00%</td>
<td id="A1.T8.7.7.33.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.33.5.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.33.6" class="ltx_td ltx_align_center ltx_border_t">47.33%</td>
<td id="A1.T8.7.7.33.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.33.7.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.33.8" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T8.7.7.33.8.1" class="ltx_text ltx_font_bold">63.33%</span></td>
<td id="A1.T8.7.7.33.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.33.9.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.33.10" class="ltx_td ltx_align_center ltx_border_t">42.00%</td>
<td id="A1.T8.7.7.33.11" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.33.11.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.33.12" class="ltx_td ltx_align_center ltx_border_t">67.00%</td>
<td id="A1.T8.7.7.33.13" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.33.13.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.33.14" class="ltx_td ltx_align_center ltx_border_t">76.67%</td>
<td id="A1.T8.7.7.33.15" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.33.15.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
</tr>
<tr id="A1.T8.7.7.34" class="ltx_tr">
<td id="A1.T8.7.7.34.1" class="ltx_td ltx_align_left">w/o format explanation</td>
<td id="A1.T8.7.7.34.2" class="ltx_td ltx_align_center">92.00%</td>
<td id="A1.T8.7.7.34.3" class="ltx_td ltx_align_center" style="background-color:#FACED0;"><span id="A1.T8.7.7.34.3.1" class="ltx_text" style="background-color:#FACED0;">-4.67%</span></td>
<td id="A1.T8.7.7.34.4" class="ltx_td ltx_align_center">52.00%</td>
<td id="A1.T8.7.7.34.5" class="ltx_td ltx_align_center" style="background-color:#A6C0E1;"><span id="A1.T8.7.7.34.5.1" class="ltx_text" style="background-color:#A6C0E1;">8.00%</span></td>
<td id="A1.T8.7.7.34.6" class="ltx_td ltx_align_center">52.33%</td>
<td id="A1.T8.7.7.34.7" class="ltx_td ltx_align_center" style="background-color:#C7D7ED;"><span id="A1.T8.7.7.34.7.1" class="ltx_text" style="background-color:#C7D7ED;">5.00%</span></td>
<td id="A1.T8.7.7.34.8" class="ltx_td ltx_align_center"><span id="A1.T8.7.7.34.8.1" class="ltx_text ltx_font_bold">64.33%</span></td>
<td id="A1.T8.7.7.34.9" class="ltx_td ltx_align_center" style="background-color:#F2F5FC;"><span id="A1.T8.7.7.34.9.1" class="ltx_text" style="background-color:#F2F5FC;">1.00%</span></td>
<td id="A1.T8.7.7.34.10" class="ltx_td ltx_align_center">36.00%</td>
<td id="A1.T8.7.7.34.11" class="ltx_td ltx_align_center" style="background-color:#FAC1C3;"><span id="A1.T8.7.7.34.11.1" class="ltx_text" style="background-color:#FAC1C3;">-6.00%</span></td>
<td id="A1.T8.7.7.34.12" class="ltx_td ltx_align_center"><span id="A1.T8.7.7.34.12.1" class="ltx_text ltx_font_bold">78.00%</span></td>
<td id="A1.T8.7.7.34.13" class="ltx_td ltx_align_center" style="background-color:#86A9D6;"><span id="A1.T8.7.7.34.13.1" class="ltx_text" style="background-color:#86A9D6;">11.00%</span></td>
<td id="A1.T8.7.7.34.14" class="ltx_td ltx_align_center"><span id="A1.T8.7.7.34.14.1" class="ltx_text ltx_font_bold">77.67%</span></td>
<td id="A1.T8.7.7.34.15" class="ltx_td ltx_align_center" style="background-color:#F2F5FC;"><span id="A1.T8.7.7.34.15.1" class="ltx_text" style="background-color:#F2F5FC;">1.00%</span></td>
</tr>
<tr id="A1.T8.7.7.35" class="ltx_tr">
<td id="A1.T8.7.7.35.1" class="ltx_td ltx_align_left">w/o partition mark</td>
<td id="A1.T8.7.7.35.2" class="ltx_td ltx_align_center"><span id="A1.T8.7.7.35.2.1" class="ltx_text ltx_font_bold">98.00%</span></td>
<td id="A1.T8.7.7.35.3" class="ltx_td ltx_align_center" style="background-color:#EEF2FA;"><span id="A1.T8.7.7.35.3.1" class="ltx_text" style="background-color:#EEF2FA;">1.33%</span></td>
<td id="A1.T8.7.7.35.4" class="ltx_td ltx_align_center"><span id="A1.T8.7.7.35.4.1" class="ltx_text ltx_font_bold">59.00%</span></td>
<td id="A1.T8.7.7.35.5" class="ltx_td ltx_align_center" style="background-color:#5B8BC7;"><span id="A1.T8.7.7.35.5.1" class="ltx_text" style="background-color:#5B8BC7;">15.00%</span></td>
<td id="A1.T8.7.7.35.6" class="ltx_td ltx_align_center">53.00%</td>
<td id="A1.T8.7.7.35.7" class="ltx_td ltx_align_center" style="background-color:#BFD1EA;"><span id="A1.T8.7.7.35.7.1" class="ltx_text" style="background-color:#BFD1EA;">5.67%</span></td>
<td id="A1.T8.7.7.35.8" class="ltx_td ltx_align_center"><span id="A1.T8.7.7.35.8.1" class="ltx_text ltx_font_bold">66.00%</span></td>
<td id="A1.T8.7.7.35.9" class="ltx_td ltx_align_center" style="background-color:#E0E8F5;"><span id="A1.T8.7.7.35.9.1" class="ltx_text" style="background-color:#E0E8F5;">2.67%</span></td>
<td id="A1.T8.7.7.35.10" class="ltx_td ltx_align_center">39.67%</td>
<td id="A1.T8.7.7.35.11" class="ltx_td ltx_align_center" style="background-color:#FBE5E7;"><span id="A1.T8.7.7.35.11.1" class="ltx_text" style="background-color:#FBE5E7;">-2.33%</span></td>
<td id="A1.T8.7.7.35.12" class="ltx_td ltx_align_center"><span id="A1.T8.7.7.35.12.1" class="ltx_text ltx_font_bold">72.00%</span></td>
<td id="A1.T8.7.7.35.13" class="ltx_td ltx_align_center" style="background-color:#C7D7ED;"><span id="A1.T8.7.7.35.13.1" class="ltx_text" style="background-color:#C7D7ED;">5.00%</span></td>
<td id="A1.T8.7.7.35.14" class="ltx_td ltx_align_center">70.33%</td>
<td id="A1.T8.7.7.35.15" class="ltx_td ltx_align_center" style="background-color:#FABDC0;"><span id="A1.T8.7.7.35.15.1" class="ltx_text" style="background-color:#FABDC0;">-6.33%</span></td>
</tr>
<tr id="A1.T8.7.7.36" class="ltx_tr">
<td id="A1.T8.7.7.36.1" class="ltx_td ltx_align_left">w/o role prompting</td>
<td id="A1.T8.7.7.36.2" class="ltx_td ltx_align_center">95.00%</td>
<td id="A1.T8.7.7.36.3" class="ltx_td ltx_align_center" style="background-color:#DCE6F4;"><span id="A1.T8.7.7.36.3.1" class="ltx_text" style="background-color:#DCE6F4;">3.00%</span></td>
<td id="A1.T8.7.7.36.4" class="ltx_td ltx_align_center">40.67%</td>
<td id="A1.T8.7.7.36.5" class="ltx_td ltx_align_center" style="background-color:#F88C8F;"><span id="A1.T8.7.7.36.5.1" class="ltx_text" style="background-color:#F88C8F;">-11.33%</span></td>
<td id="A1.T8.7.7.36.6" class="ltx_td ltx_align_center">44.67%</td>
<td id="A1.T8.7.7.36.7" class="ltx_td ltx_align_center" style="background-color:#F9B0B3;"><span id="A1.T8.7.7.36.7.1" class="ltx_text" style="background-color:#F9B0B3;">-7.67%</span></td>
<td id="A1.T8.7.7.36.8" class="ltx_td ltx_align_center">59.00%</td>
<td id="A1.T8.7.7.36.9" class="ltx_td ltx_align_center" style="background-color:#FAC7CA;"><span id="A1.T8.7.7.36.9.1" class="ltx_text" style="background-color:#FAC7CA;">-5.33%</span></td>
<td id="A1.T8.7.7.36.10" class="ltx_td ltx_align_center">39.33%</td>
<td id="A1.T8.7.7.36.11" class="ltx_td ltx_align_center" style="background-color:#D9E3F3;"><span id="A1.T8.7.7.36.11.1" class="ltx_text" style="background-color:#D9E3F3;">3.33%</span></td>
<td id="A1.T8.7.7.36.12" class="ltx_td ltx_align_center"><span id="A1.T8.7.7.36.12.1" class="ltx_text ltx_font_bold">69.00%</span></td>
<td id="A1.T8.7.7.36.13" class="ltx_td ltx_align_center" style="background-color:#F9A3A6;"><span id="A1.T8.7.7.36.13.1" class="ltx_text" style="background-color:#F9A3A6;">-9.00%</span></td>
<td id="A1.T8.7.7.36.14" class="ltx_td ltx_align_center">76.00%</td>
<td id="A1.T8.7.7.36.15" class="ltx_td ltx_align_center" style="background-color:#FBEBEE;"><span id="A1.T8.7.7.36.15.1" class="ltx_text" style="background-color:#FBEBEE;">-1.67%</span></td>
</tr>
<tr id="A1.T8.7.7.37" class="ltx_tr">
<td id="A1.T8.7.7.37.1" class="ltx_td ltx_align_left">w/o change order</td>
<td id="A1.T8.7.7.37.2" class="ltx_td ltx_align_center"><span id="A1.T8.7.7.37.2.1" class="ltx_text ltx_font_bold">96.67%</span></td>
<td id="A1.T8.7.7.37.3" class="ltx_td ltx_align_center" style="background-color:#FCFCFF;"><span id="A1.T8.7.7.37.3.1" class="ltx_text" style="background-color:#FCFCFF;">0.00%</span></td>
<td id="A1.T8.7.7.37.4" class="ltx_td ltx_align_center">52.33%</td>
<td id="A1.T8.7.7.37.5" class="ltx_td ltx_align_center" style="background-color:#A3BDE0;"><span id="A1.T8.7.7.37.5.1" class="ltx_text" style="background-color:#A3BDE0;">8.33%</span></td>
<td id="A1.T8.7.7.37.6" class="ltx_td ltx_align_center">40.67%</td>
<td id="A1.T8.7.7.37.7" class="ltx_td ltx_align_center" style="background-color:#FABABD;"><span id="A1.T8.7.7.37.7.1" class="ltx_text" style="background-color:#FABABD;">-6.67%</span></td>
<td id="A1.T8.7.7.37.8" class="ltx_td ltx_align_center">55.67%</td>
<td id="A1.T8.7.7.37.9" class="ltx_td ltx_align_center" style="background-color:#F9B0B3;"><span id="A1.T8.7.7.37.9.1" class="ltx_text" style="background-color:#F9B0B3;">-7.67%</span></td>
<td id="A1.T8.7.7.37.10" class="ltx_td ltx_align_center">31.67%</td>
<td id="A1.T8.7.7.37.11" class="ltx_td ltx_align_center" style="background-color:#F99699;"><span id="A1.T8.7.7.37.11.1" class="ltx_text" style="background-color:#F99699;">-10.33%</span></td>
<td id="A1.T8.7.7.37.12" class="ltx_td ltx_align_center">52.67%</td>
<td id="A1.T8.7.7.37.13" class="ltx_td ltx_align_center" style="background-color:#F86F71;"><span id="A1.T8.7.7.37.13.1" class="ltx_text" style="background-color:#F86F71;">-14.33%</span></td>
<td id="A1.T8.7.7.37.14" class="ltx_td ltx_align_center">65.67%</td>
<td id="A1.T8.7.7.37.15" class="ltx_td ltx_align_center" style="background-color:#F99092;"><span id="A1.T8.7.7.37.15.1" class="ltx_text" style="background-color:#F99092;">-11.00%</span></td>
</tr>
<tr id="A1.T8.7.7.38" class="ltx_tr">
<td id="A1.T8.7.7.38.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"><span id="A1.T8.7.7.38.1.1" class="ltx_text ltx_font_bold">w/o 1-shot</span></td>
<td id="A1.T8.7.7.38.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">63.00%</td>
<td id="A1.T8.7.7.38.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="background-color:#F8696B;"><span id="A1.T8.7.7.38.3.1" class="ltx_text" style="background-color:#F8696B;">-33.67%</span></td>
<td id="A1.T8.7.7.38.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">9.33%</td>
<td id="A1.T8.7.7.38.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="background-color:#F8696B;"><span id="A1.T8.7.7.38.5.1" class="ltx_text" style="background-color:#F8696B;">-34.67%</span></td>
<td id="A1.T8.7.7.38.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">17.33%</td>
<td id="A1.T8.7.7.38.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="background-color:#F8696B;"><span id="A1.T8.7.7.38.7.1" class="ltx_text" style="background-color:#F8696B;">-30.00%</span></td>
<td id="A1.T8.7.7.38.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">50.00%</td>
<td id="A1.T8.7.7.38.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="background-color:#F8797B;"><span id="A1.T8.7.7.38.9.1" class="ltx_text" style="background-color:#F8797B;">-13.33%</span></td>
<td id="A1.T8.7.7.38.10" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">30.00%</td>
<td id="A1.T8.7.7.38.11" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="background-color:#F88688;"><span id="A1.T8.7.7.38.11.1" class="ltx_text" style="background-color:#F88688;">-12.00%</span></td>
<td id="A1.T8.7.7.38.12" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">16.67%</td>
<td id="A1.T8.7.7.38.13" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="background-color:#F8696B;"><span id="A1.T8.7.7.38.13.1" class="ltx_text" style="background-color:#F8696B;">-50.33%</span></td>
<td id="A1.T8.7.7.38.14" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">38.00%</td>
<td id="A1.T8.7.7.38.15" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="background-color:#F8696B;"><span id="A1.T8.7.7.38.15.1" class="ltx_text" style="background-color:#F8696B;">-38.67%</span></td>
</tr>
</table>
</span></div>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2305.13061" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2305.13062" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2305.13062">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2305.13062" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2305.13063" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Feb 29 06:34:40 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
