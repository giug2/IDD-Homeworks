<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2406.11145] Federated Face Forgery Detection Learning with Personalized Representation</title><meta property="og:description" content="Deep generator technology can produce high-quality fake videos that are indistinguishable, posing a serious social threat.
Traditional forgery detection methods directly centralized training on data and lacked considerâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Federated Face Forgery Detection Learning with Personalized Representation">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Federated Face Forgery Detection Learning with Personalized Representation">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2406.11145">

<!--Generated on Fri Jul  5 19:04:47 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Facial forgery detection,  personalized forgery representation learning,  federated learning,  privacy preserving.
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Federated Face Forgery Detection Learning with Personalized Representation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">DechengÂ Liu,Â ZhanÂ Dang,Â ChunleiÂ Peng,Â Â ,Â NannanÂ Wang,Â ,Â Ruimin HuÂ and Xinbo Gao, 


</span><span class="ltx_author_notes">D. Liu, Z. Dang, C. Peng and R. Hu are with the State Key Laboratory of Integrated Services Networks, School of Cyber Engineering, Xidian University, Xiâ€™an 710071, Shaanxi, P. R. China (e-mail: dchliu@xidian.edu.cn; zd.xidian@gmail.com; clpeng@xidian.edu.cn; rmhu@xidian.edu.cn).
<br class="ltx_break">N. Wang is with the State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xiâ€™an 710071, Shaanxi, P. R. China (e-mail: nnwang@xidian.edu.cn).
<br class="ltx_break">X. Gao is with the Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing 400065, P. R. China.(e-mail: gaoxb@cqupt.edu.cn).</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Deep generator technology can produce high-quality fake videos that are indistinguishable, posing a serious social threat.
Traditional forgery detection methods directly centralized training on data and lacked consideration of information sharing in non-public video data scenarios and data privacy.
Naturally, the federated learning strategy can be applied for privacy protection, which aggregates model parameters of clients but not original data.
However, simple federated learning canâ€™t achieve satisfactory performance because of poor generalization capabilities for the real hybrid-domain forgery dataset.
To solve the problem, the paper proposes a novel federated face forgery detection learning with personalized representation.
The designed Personalized Forgery Representation Learning aims to learn the personalized representation of each client to improve the detection performance of individual client models.
In addition, a personalized federated learning training strategy is utilized to update the parameters of the distributed detection model.
Here collaborative training is conducted on multiple distributed client devices, and shared representations of these client models are uploaded to the server side for aggregation.
Experiments on several public face forgery detection datasets demonstrate the superior performance of the proposed algorithm compared with state-of-the-art methods.
The code is available at <em id="id1.id1.1" class="ltx_emph ltx_font_italic">https://github.com/GANG370/PFR-Forgery.</em></p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Facial forgery detection, personalized forgery representation learning, federated learning, privacy preserving.

</div>
<section id="S1" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">With the breakthrough of depth generation technology, face processing technology continues to emerge, resulting in high-quality fake videos that are indistinguishable from the naked eye. Therefore, they are easily abused by malicious users. For example, fake face images are used to deceive system authentication and fraud. Using synthetic fake face images for malicious intrusion, these phenomena are likely to cause serious social security problems. Therefore, detecting fake media content has become a hotspot of research. Although many deep fake detection methods have emerged, they are not effective for video data with large distribution differences in terms of complex sources, forgery methods, and personnel races. This brings great challenges to the face forgery detection task. Therefore, designing a more efficient face forgery detection model has become an important issue faced by the current biometric community and media forensics field.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2406.11145/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="221" height="178" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The differences between our method and traditional face forgery detection methods and traditional federated learning forgery detection method. (a) Traditional forgery detection methods require centralized aggregation of all client data for training, which is detrimental to privacy protection. (b) Traditional federated learning forgery detection method requires uploading all client model parameters to the server side, which prevents learning unique representations from individual clients. (c) Our method can extract personalized representations for complex forgery datasets with diverse types, and upload the shared representation to the server side for updates. In the testing stage, each client leverages its personalized model for local testing.</figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Existing face forgery detection can be roughly divided into two categories: image-based detection methods and video-based detection methods. Image-based detection methods mainly utilize image client artifacts <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, mixed boundary information <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, RGB images and their advanced semantic information in the frequency domain <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, etc.
Different from forgery in image detection, video-based methods mainly use the inconsistency between forged video frames for authenticity detection.
Nowadays, the privacy of personal data draws more and more attention.
However, these mentioned traditional forgery detection algorithm lacks considering the privacy of training data.
As shown in Figure <a href="#S1.F1" title="Figure 1 â€£ I Introduction â€£ Federated Face Forgery Detection Learning with Personalized Representation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> (a),
traditional face forgery detection directly concentrates all client data for training, which can easily lead to the leakage of personal information and have serious consequences.
Naturally, federated learning is a distributed and privacy-preserving machine learning strategy, which is explored in the forgery detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> as shown in Figure <a href="#S1.F1" title="Figure 1 â€£ I Introduction â€£ Federated Face Forgery Detection Learning with Personalized Representation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> (b).
However, related experiment results prove that simple federated learning canâ€™t adapt to real forgery detection scenarios, where there exist different types of forgery clues.
Thus, it is necessary to design a specific federated learning strategy for real forgery detection scenarios.
The designed personalization federated learning is an improved federated learning method that aims to improve the personalized performance and adaptability of the model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. As shown in Figure <a href="#S1.F1" title="Figure 1 â€£ I Introduction â€£ Federated Face Forgery Detection Learning with Personalized Representation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> (c), the key challenge is how to disentangle personalized features and shared features in the client when training.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">To solve the mentioned problem, we propose a federated face forgery detection learning with personalized representation.
The proposed method can not only train forgery detection models with distributed non-public data but also improve the detection ability of complex forgery data.
First, considering the diversity of distribution in the forgery dataset with mixed types, personalized forgery representation learning is designed to learn personalized features for client-side forgery types.
Secondly, a personalized federated training strategy is introduced to cyclically update the shared representation of each client under the aggregation of the server, while the personalized part of each client is updated locally based on private data.
In this framework, model parameters trained on clients are shared and aggregated, while training data on individual clients remains private, thus protecting the security of the data.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The main contributions of our paper can be summarized as follows:</p>
</div>
<div id="S1.p5" class="ltx_para">
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">To the best of our knowledge, we first explore a federated face forgery detection learning with personalized representation, which further explores more robust face forgery clues by combining the shared representation of multiple distributed client models.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">The designed personalized forgery representation learning framework can disentangle shared features and personalized features. Personalized features contain more suitable properties of the client data set, further improving the applicability of complex forgery datasets with diverse types.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Experimental results on public face forgery detection datasets show that the proposed algorithm has superior performance compared with state-of-the-art face forgery detection methods. The code is available at <em id="S1.I1.i3.p1.1.1" class="ltx_emph ltx_font_italic">https://github.com/GANG370/PFR-Forgery.</em></p>
</div>
</li>
</ol>
</div>
</section>
<section id="S2" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Related Work</span>
</h2>

<section id="S2.SS1" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.4.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.5.2" class="ltx_text ltx_font_italic">Face Forgery Detection</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Current detection methods can be divided into image-based forgery detection methods and video-based forgery detection methods.
Early-generation algorithms tend to produce obvious visual artifacts and inconsistencies between true and false directly in the facial area. Yang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> determined the authenticity of the image by introducing inconsistencies in estimating 3D personalized poses from face images. Yang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> proposed a GAN fingerprint unwrapping network to unwrap fingerprint features from GAN-generated images. Luo et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> used SRM technology to suppress the texture deviation of images, thereby avoiding the over-fitting problem of the training model. Dang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> proposed a mechanism to jointly predict binary labels of manipulated areas and attention maps to further improve forgery detection performance. The use of signal differences from the proposed face recognition network and background recognition network for image authenticity identification was proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. Li et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> found that forged images usually contain some distortion and blurring effects, thus proposing a more challenging face forgery detection method. Qian et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> applied DCT transform technology to images to collect frequency-aware clues, which can be used to further mine subtle artifacts in images. Chen et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> proposed a multi-stream design and combined DFT features for image-level forgery detection. Cao et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> learned the common features of real faces by reconstructing face images and mined the essential differences between real faces and fake faces based on classification tasks to further improve detection performance.
Luo et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> construct a fine-grained triplet and suppress specific forgery traces through data augmentation independent of prior knowledge. They design a progressive learning controller to guide the model to focus on the main feature components, allowing the network to learn key counterfeit features to achieve advanced counterfeit detection performance.
Miao et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> proposed a high-frequency fine-grained transformer network based on central differential attention and high-frequency wavelet sampler. Extensive experiments show that the specially designed framework performs well in the face of cross-datasets, cross-manipulations, and unseen perturbations. Face forgery detection is also very effective.
Tian et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> proposed a categorical attention region proposal module that can localize false cues in the process.
Classification and supplementary learning modules to empower the network
Learn about richer false clues. The additional generated operation graphs can also serve as better supervision to enhance the performance of face forgery detectors.
Hua et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>
convert the feature reconstruction layer into a deep neural network,
and at the same time, classification tasks and correspondence relationships will be optimized. The task is completed through alternative optimization. Therefore, the model can maintain high detection accuracy.
Yu et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> expressed the learning of the model as a meta-learning process and generated zero-shot face manipulation tasks for the model to learn meta-knowledge shared by diverse attacks. Experimental results show that the method achieves competitive results in the zero-sample setting.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Recent work treats deepfake detection as a video-level prediction problem and learns video-level features. Temporal features are often combined with spatial features for video forgery detection. Gu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> proposed using a spatiotemporal discontinuity learning module to jointly learn the inconsistencies between single frames and consecutive frames in deepfake videos, respectively. Sun et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> proposed temporal modeling based on precise geometric features to detect deepfake videos. Li et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> used the extracted eye region sequence through a convolutional neural network and lstm network to predict the blink probability to determine the authenticity of the video. With the further development of face forgery detection technology, the author <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> designed a video classifier based on physiological signal change synthesis to detect the authenticity of videos. Ganiyusufoglu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> used a three-dimensional convolutional neural network to model spatio-temporal features to capture the similarities between different deepfakes and further improve cross-domain fake video detection capabilities. However, these mentioned methods lack considering the privacy of training data.
Peng et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> observed the difference in gaze direction pattern distribution between real videos and fake videos, so they proposed to use a gaze analysis model to analyze the gaze features of face video frames and then applied a spatiotemporal feature aggregator to achieve gaze feature-based authenticity classification.
Wang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> proposed a forgery cue enhancement network based on discrete cosine transform to achieve a more comprehensive representation of spectral-spatial and temporal features and make full use of the rich information in video sequences.
Ding et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> proposed a spatiotemporal difference network to mine low-level clues for face forgery detection, and furthermore, used a multi-modal attention fusion module to effectively fuse complementary features from different branches.
Liu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> designed a hybrid spatiotemporal network that integrates spatial and temporal information in the same framework and jointly learns short-range and long-range relationships in the spatiotemporal dimension. A large number of experiments show that this method achieves excellent detection performance.
Zhao et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> designed an interpretable spatiotemporal video transformer. The proposed decomposed spatiotemporal self-attention and self-reduction mechanisms are used to capture spatial artifacts and temporal inconsistencies to improve algorithm robustness.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.4.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.5.2" class="ltx_text ltx_font_italic">Federated Learning</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">With the advancement of artificial intelligence technology, peopleâ€™s requirements for data privacy and security are becoming more and more stringent, thus promoting the development of the field of federated learning. Most existing federated learning training methods are derived from the federated averaging algorithm, which aims to train a well-performing global model. McMahan et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> proposed a federated learning algorithm for the first time, which can complete the weighted aggregation update of the model without direct contact with the training data. The optimization method of Yoshida et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> is to make the server select client data to form a dataset that approximates IID. Sprague et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> proposed a new asynchronous federated learning algorithm and applied it to image-based geolocation. Recently, W. Hongyi et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> and others proposed a federated matching average algorithm, which uses coordinate weighted averaging and the arrangement invariance of network neurons to improve it. Liu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> used residual federated learning and combined it with variational autoencoders to learn robust discriminative residual feature maps to detect face forgery cues.
However, these mentioned methods have poor generalization capabilities for the complex forgery datasets with diverse types.
This paper proposes a personalized representation learning method. Each client improves the generalization of the algorithm by extracting personalized representations further exploring more robust face forgery clues of multiple distributed client models.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Proposed Approach</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">This section details federated face forgery detection learning with personalized representation. The overall framework of the algorithm is shown in Figure <a href="#S3.F2" title="Figure 2 â€£ III-A Motivation â€£ III Proposed Approach â€£ Federated Face Forgery Detection Learning with Personalized Representation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The designed personalized forgery representation learning framework can disentangle shared features and personalized features. Personalized features contain more suitable properties of the client data set, further improving the applicability of complex forgery datasets with diverse types. At the same time, by combining the shared representation of multiple distributed client models to explore more robust face forgery clues.</p>
</div>
<section id="S3.SS1" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.4.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.5.2" class="ltx_text ltx_font_italic">Motivation</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">As shown in Figure <a href="#S1.F1" title="Figure 1 â€£ I Introduction â€£ Federated Face Forgery Detection Learning with Personalized Representation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> (b), traditional federated learning directly uses the weighted average of all training parameters of each client as the basis for shared model parameter update, ignoring the inconsistency of data characteristics between different clients, resulting in poor performance of the model for real forgery detection scenarios. Some studies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> have shown that complex forgery datasets with diverse types may share a common representation. Hence, the paper proposes a novel federated face forgery detection learning with personalized representation. The designed personalized forgery representation learning framework can disentangle shared features and personalized features. Personalized features contain more suitable properties of the client data set, further improving the applicability of complex forgery datasets with diverse types. Aggregation updates are also performed on the server side by uploading the shared features of the client model, while each clientâ€™s personalized features are retained locally for training updates, which further explores more robust face forgery clues.
<em id="S3.SS1.p1.1.1" class="ltx_emph ltx_font_italic">This not only protects the privacy of the client data sets but also further improves the generalization capabilities of complex forgery datasets with diverse types.</em></p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2406.11145/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="369" height="251" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The overall framework of the proposed federated face forgery detection learning with personalized representation method.
</figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.4.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.5.2" class="ltx_text ltx_font_italic">Preliminaries: Personalized Federated Learning</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.16" class="ltx_p">Inspired by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, we consider using personalized federated learning methods when processing data from complex forgery datasets with diverse types. In order to further explore more robust face forgery clues, we design a novel federated face forgery detection learning with personalized representation. The personalized forgery representation learning framework can disentangle shared features and personalized features. Personalized features contain more suitable properties of the client data set, further improving the applicability of complex forgery datasets with diverse types. Additionally, the captured shared representation information further explores more robust face forgery clues by aggregating updates on the server side. As shown in Figure <a href="#S3.F2" title="Figure 2 â€£ III-A Motivation â€£ III Proposed Approach â€£ Federated Face Forgery Detection Learning with Personalized Representation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the personalized forgery representation learning framework is designed to simulate data from complex sources in real scenarios. The specific settings are as follows: there are <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">K</annotation></semantics></math> different clients, and the fake face dataset <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mi id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">D</annotation></semantics></math> is distributed and stored in each client (<math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">D</annotation></semantics></math><sub id="S3.SS2.p1.16.1" class="ltx_sub">1</sub>â€¦<math id="S3.SS2.p1.5.m5.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS2.p1.5.m5.1a"><mi id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.1b"><ci id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.1c">D</annotation></semantics></math><sub id="S3.SS2.p1.16.2" class="ltx_sub"><span id="S3.SS2.p1.16.2.1" class="ltx_text ltx_font_italic">K</span></sub>). Client data cannot be exchanged or transferred between clients. Clients train their own face forgery detection models locally. Since the data is a complex forged dataset with various types, traditional federated learning forgery detection directly concentrates all client parameters for training, which can easily lead to the inability to learn local personalized information and result in poor generalization ability. Therefore, uploading the shared representation of each client to the weighted average on the server side can not only ensure the privacy of the data but also improve the generalization ability of complex forged datasets with various types. Moreover, the designed personalized forgery representation learning framework can disentangle shared features and personalized features. Personalized features contain more suitable properties of the client data set, further improving the applicability of complex forgery datasets with diverse types. The personalized features of the <math id="S3.SS2.p1.7.m7.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.p1.7.m7.1a"><mi id="S3.SS2.p1.7.m7.1.1" xref="S3.SS2.p1.7.m7.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.7.m7.1b"><ci id="S3.SS2.p1.7.m7.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.7.m7.1c">k</annotation></semantics></math>-th client is parameterized as <math id="S3.SS2.p1.8.m8.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S3.SS2.p1.8.m8.1a"><mi id="S3.SS2.p1.8.m8.1.1" xref="S3.SS2.p1.8.m8.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.8.m8.1b"><ci id="S3.SS2.p1.8.m8.1.1.cmml" xref="S3.SS2.p1.8.m8.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.8.m8.1c">\theta</annotation></semantics></math><sub id="S3.SS2.p1.16.3" class="ltx_sub"><span id="S3.SS2.p1.16.3.1" class="ltx_text ltx_font_italic">p,k</span></sub> (<math id="S3.SS2.p1.10.m10.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.p1.10.m10.1a"><mi id="S3.SS2.p1.10.m10.1.1" xref="S3.SS2.p1.10.m10.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.10.m10.1b"><ci id="S3.SS2.p1.10.m10.1.1.cmml" xref="S3.SS2.p1.10.m10.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.10.m10.1c">k</annotation></semantics></math> = 1, 2, 3, â€¦, <math id="S3.SS2.p1.11.m11.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS2.p1.11.m11.1a"><mi id="S3.SS2.p1.11.m11.1.1" xref="S3.SS2.p1.11.m11.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.11.m11.1b"><ci id="S3.SS2.p1.11.m11.1.1.cmml" xref="S3.SS2.p1.11.m11.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.11.m11.1c">K</annotation></semantics></math>). The shared features of the <math id="S3.SS2.p1.12.m12.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.p1.12.m12.1a"><mi id="S3.SS2.p1.12.m12.1.1" xref="S3.SS2.p1.12.m12.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.12.m12.1b"><ci id="S3.SS2.p1.12.m12.1.1.cmml" xref="S3.SS2.p1.12.m12.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.12.m12.1c">k</annotation></semantics></math>-th client is parameterized as <math id="S3.SS2.p1.13.m13.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S3.SS2.p1.13.m13.1a"><mi id="S3.SS2.p1.13.m13.1.1" xref="S3.SS2.p1.13.m13.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.13.m13.1b"><ci id="S3.SS2.p1.13.m13.1.1.cmml" xref="S3.SS2.p1.13.m13.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.13.m13.1c">\theta</annotation></semantics></math><sub id="S3.SS2.p1.16.4" class="ltx_sub"><span id="S3.SS2.p1.16.4.1" class="ltx_text ltx_font_italic">s,k</span></sub> (<math id="S3.SS2.p1.15.m15.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.p1.15.m15.1a"><mi id="S3.SS2.p1.15.m15.1.1" xref="S3.SS2.p1.15.m15.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.15.m15.1b"><ci id="S3.SS2.p1.15.m15.1.1.cmml" xref="S3.SS2.p1.15.m15.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.15.m15.1c">k</annotation></semantics></math> = 1, 2, 3, â€¦, <math id="S3.SS2.p1.16.m16.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS2.p1.16.m16.1a"><mi id="S3.SS2.p1.16.m16.1.1" xref="S3.SS2.p1.16.m16.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.16.m16.1b"><ci id="S3.SS2.p1.16.m16.1.1.cmml" xref="S3.SS2.p1.16.m16.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.16.m16.1c">K</annotation></semantics></math>).
In the testing stage, each client leverages its own personalized model for local testing.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.4.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.5.2" class="ltx_text ltx_font_italic">Personalized Forgery Representation Learning</span>
</h3>

<figure id="alg1" class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top">

<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="alg1.7.1.1" class="ltx_text ltx_font_bold">Algorithm 1</span> </span> FedPR</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="alg1.5" class="ltx_p ltx_figure_panel"><span id="alg1.5.1" class="ltx_text ltx_font_bold">Parameter</span>: Personalized personalized representation <math id="alg1.1.m1.1" class="ltx_Math" alttext="\theta_{s}" display="inline"><semantics id="alg1.1.m1.1a"><msub id="alg1.1.m1.1.1" xref="alg1.1.m1.1.1.cmml"><mi id="alg1.1.m1.1.1.2" xref="alg1.1.m1.1.1.2.cmml">Î¸</mi><mi id="alg1.1.m1.1.1.3" xref="alg1.1.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.1.m1.1b"><apply id="alg1.1.m1.1.1.cmml" xref="alg1.1.m1.1.1"><csymbol cd="ambiguous" id="alg1.1.m1.1.1.1.cmml" xref="alg1.1.m1.1.1">subscript</csymbol><ci id="alg1.1.m1.1.1.2.cmml" xref="alg1.1.m1.1.1.2">ğœƒ</ci><ci id="alg1.1.m1.1.1.3.cmml" xref="alg1.1.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.1.m1.1c">\theta_{s}</annotation></semantics></math> and shared representation <math id="alg1.2.m2.1" class="ltx_Math" alttext="\theta_{p}" display="inline"><semantics id="alg1.2.m2.1a"><msub id="alg1.2.m2.1.1" xref="alg1.2.m2.1.1.cmml"><mi id="alg1.2.m2.1.1.2" xref="alg1.2.m2.1.1.2.cmml">Î¸</mi><mi id="alg1.2.m2.1.1.3" xref="alg1.2.m2.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.2.m2.1b"><apply id="alg1.2.m2.1.1.cmml" xref="alg1.2.m2.1.1"><csymbol cd="ambiguous" id="alg1.2.m2.1.1.1.cmml" xref="alg1.2.m2.1.1">subscript</csymbol><ci id="alg1.2.m2.1.1.2.cmml" xref="alg1.2.m2.1.1.2">ğœƒ</ci><ci id="alg1.2.m2.1.1.3.cmml" xref="alg1.2.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.2.m2.1c">\theta_{p}</annotation></semantics></math>; Number of communication rounds <math id="alg1.3.m3.1" class="ltx_Math" alttext="t" display="inline"><semantics id="alg1.3.m3.1a"><mi id="alg1.3.m3.1.1" xref="alg1.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="alg1.3.m3.1b"><ci id="alg1.3.m3.1.1.cmml" xref="alg1.3.m3.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.3.m3.1c">t</annotation></semantics></math>; <math id="alg1.4.m4.1" class="ltx_Math" alttext="w" display="inline"><semantics id="alg1.4.m4.1a"><mi id="alg1.4.m4.1.1" xref="alg1.4.m4.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="alg1.4.m4.1b"><ci id="alg1.4.m4.1.1.cmml" xref="alg1.4.m4.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.4.m4.1c">w</annotation></semantics></math> is the proportion of selected clients. <math id="alg1.5.m5.1" class="ltx_Math" alttext="k" display="inline"><semantics id="alg1.5.m5.1a"><mi id="alg1.5.m5.1.1" xref="alg1.5.m5.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="alg1.5.m5.1b"><ci id="alg1.5.m5.1.1.cmml" xref="alg1.5.m5.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.5.m5.1c">k</annotation></semantics></math> represents the selected clients;</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="alg1.8" class="ltx_listing ltx_figure_panel ltx_listing">
<div id="alg1.l1" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l1.1.1.1" class="ltx_text" style="font-size:80%;">1:</span></span>Â Â Initialize <math id="alg1.l1.m1.1" class="ltx_Math" alttext="\theta_{s}^{0}" display="inline"><semantics id="alg1.l1.m1.1a"><msubsup id="alg1.l1.m1.1.1" xref="alg1.l1.m1.1.1.cmml"><mi id="alg1.l1.m1.1.1.2.2" xref="alg1.l1.m1.1.1.2.2.cmml">Î¸</mi><mi id="alg1.l1.m1.1.1.2.3" xref="alg1.l1.m1.1.1.2.3.cmml">s</mi><mn id="alg1.l1.m1.1.1.3" xref="alg1.l1.m1.1.1.3.cmml">0</mn></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l1.m1.1b"><apply id="alg1.l1.m1.1.1.cmml" xref="alg1.l1.m1.1.1"><csymbol cd="ambiguous" id="alg1.l1.m1.1.1.1.cmml" xref="alg1.l1.m1.1.1">superscript</csymbol><apply id="alg1.l1.m1.1.1.2.cmml" xref="alg1.l1.m1.1.1"><csymbol cd="ambiguous" id="alg1.l1.m1.1.1.2.1.cmml" xref="alg1.l1.m1.1.1">subscript</csymbol><ci id="alg1.l1.m1.1.1.2.2.cmml" xref="alg1.l1.m1.1.1.2.2">ğœƒ</ci><ci id="alg1.l1.m1.1.1.2.3.cmml" xref="alg1.l1.m1.1.1.2.3">ğ‘ </ci></apply><cn type="integer" id="alg1.l1.m1.1.1.3.cmml" xref="alg1.l1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m1.1c">\theta_{s}^{0}</annotation></semantics></math>, <math id="alg1.l1.m2.2" class="ltx_Math" alttext="\theta_{p,1}^{0}" display="inline"><semantics id="alg1.l1.m2.2a"><msubsup id="alg1.l1.m2.2.3" xref="alg1.l1.m2.2.3.cmml"><mi id="alg1.l1.m2.2.3.2.2" xref="alg1.l1.m2.2.3.2.2.cmml">Î¸</mi><mrow id="alg1.l1.m2.2.2.2.4" xref="alg1.l1.m2.2.2.2.3.cmml"><mi id="alg1.l1.m2.1.1.1.1" xref="alg1.l1.m2.1.1.1.1.cmml">p</mi><mo id="alg1.l1.m2.2.2.2.4.1" xref="alg1.l1.m2.2.2.2.3.cmml">,</mo><mn id="alg1.l1.m2.2.2.2.2" xref="alg1.l1.m2.2.2.2.2.cmml">1</mn></mrow><mn id="alg1.l1.m2.2.3.3" xref="alg1.l1.m2.2.3.3.cmml">0</mn></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l1.m2.2b"><apply id="alg1.l1.m2.2.3.cmml" xref="alg1.l1.m2.2.3"><csymbol cd="ambiguous" id="alg1.l1.m2.2.3.1.cmml" xref="alg1.l1.m2.2.3">superscript</csymbol><apply id="alg1.l1.m2.2.3.2.cmml" xref="alg1.l1.m2.2.3"><csymbol cd="ambiguous" id="alg1.l1.m2.2.3.2.1.cmml" xref="alg1.l1.m2.2.3">subscript</csymbol><ci id="alg1.l1.m2.2.3.2.2.cmml" xref="alg1.l1.m2.2.3.2.2">ğœƒ</ci><list id="alg1.l1.m2.2.2.2.3.cmml" xref="alg1.l1.m2.2.2.2.4"><ci id="alg1.l1.m2.1.1.1.1.cmml" xref="alg1.l1.m2.1.1.1.1">ğ‘</ci><cn type="integer" id="alg1.l1.m2.2.2.2.2.cmml" xref="alg1.l1.m2.2.2.2.2">1</cn></list></apply><cn type="integer" id="alg1.l1.m2.2.3.3.cmml" xref="alg1.l1.m2.2.3.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m2.2c">\theta_{p,1}^{0}</annotation></semantics></math>, â€¦, <math id="alg1.l1.m3.2" class="ltx_Math" alttext="\theta_{p,K}^{0}" display="inline"><semantics id="alg1.l1.m3.2a"><msubsup id="alg1.l1.m3.2.3" xref="alg1.l1.m3.2.3.cmml"><mi id="alg1.l1.m3.2.3.2.2" xref="alg1.l1.m3.2.3.2.2.cmml">Î¸</mi><mrow id="alg1.l1.m3.2.2.2.4" xref="alg1.l1.m3.2.2.2.3.cmml"><mi id="alg1.l1.m3.1.1.1.1" xref="alg1.l1.m3.1.1.1.1.cmml">p</mi><mo id="alg1.l1.m3.2.2.2.4.1" xref="alg1.l1.m3.2.2.2.3.cmml">,</mo><mi id="alg1.l1.m3.2.2.2.2" xref="alg1.l1.m3.2.2.2.2.cmml">K</mi></mrow><mn id="alg1.l1.m3.2.3.3" xref="alg1.l1.m3.2.3.3.cmml">0</mn></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l1.m3.2b"><apply id="alg1.l1.m3.2.3.cmml" xref="alg1.l1.m3.2.3"><csymbol cd="ambiguous" id="alg1.l1.m3.2.3.1.cmml" xref="alg1.l1.m3.2.3">superscript</csymbol><apply id="alg1.l1.m3.2.3.2.cmml" xref="alg1.l1.m3.2.3"><csymbol cd="ambiguous" id="alg1.l1.m3.2.3.2.1.cmml" xref="alg1.l1.m3.2.3">subscript</csymbol><ci id="alg1.l1.m3.2.3.2.2.cmml" xref="alg1.l1.m3.2.3.2.2">ğœƒ</ci><list id="alg1.l1.m3.2.2.2.3.cmml" xref="alg1.l1.m3.2.2.2.4"><ci id="alg1.l1.m3.1.1.1.1.cmml" xref="alg1.l1.m3.1.1.1.1">ğ‘</ci><ci id="alg1.l1.m3.2.2.2.2.cmml" xref="alg1.l1.m3.2.2.2.2">ğ¾</ci></list></apply><cn type="integer" id="alg1.l1.m3.2.3.3.cmml" xref="alg1.l1.m3.2.3.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m3.2c">\theta_{p,K}^{0}</annotation></semantics></math>;

</div>
<div id="alg1.l2" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l2.1.1.1" class="ltx_text" style="font-size:80%;">2:</span></span>Â Â Center Update:
</div>
<div id="alg1.l3" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l3.1.1.1" class="ltx_text" style="font-size:80%;">3:</span></span>Â Â <span id="alg1.l3.2" class="ltx_text ltx_font_bold">for all</span>Â <math id="alg1.l3.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="alg1.l3.m1.1a"><mi id="alg1.l3.m1.1.1" xref="alg1.l3.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="alg1.l3.m1.1b"><ci id="alg1.l3.m1.1.1.cmml" xref="alg1.l3.m1.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m1.1c">t</annotation></semantics></math>=1, 2, â€¦,Â <span id="alg1.l3.3" class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg1.l4" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l4.1.1.1" class="ltx_text" style="font-size:80%;">4:</span></span>Â Â Â Â Â <span id="alg1.l4.2" class="ltx_text ltx_font_bold">for all</span>Â selected client <math id="alg1.l4.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="alg1.l4.m1.1a"><mi id="alg1.l4.m1.1.1" xref="alg1.l4.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="alg1.l4.m1.1b"><ci id="alg1.l4.m1.1.1.cmml" xref="alg1.l4.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m1.1c">k</annotation></semantics></math>=1, 2, â€¦, (in parallel)Â <span id="alg1.l4.3" class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg1.l5" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l5.1.1.1" class="ltx_text" style="font-size:80%;">5:</span></span>Â Â Â Â Â Â Â Â Initializes <math id="alg1.l5.m1.2" class="ltx_Math" alttext="\theta_{p,k}^{t}" display="inline"><semantics id="alg1.l5.m1.2a"><msubsup id="alg1.l5.m1.2.3" xref="alg1.l5.m1.2.3.cmml"><mi id="alg1.l5.m1.2.3.2.2" xref="alg1.l5.m1.2.3.2.2.cmml">Î¸</mi><mrow id="alg1.l5.m1.2.2.2.4" xref="alg1.l5.m1.2.2.2.3.cmml"><mi id="alg1.l5.m1.1.1.1.1" xref="alg1.l5.m1.1.1.1.1.cmml">p</mi><mo id="alg1.l5.m1.2.2.2.4.1" xref="alg1.l5.m1.2.2.2.3.cmml">,</mo><mi id="alg1.l5.m1.2.2.2.2" xref="alg1.l5.m1.2.2.2.2.cmml">k</mi></mrow><mi id="alg1.l5.m1.2.3.3" xref="alg1.l5.m1.2.3.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l5.m1.2b"><apply id="alg1.l5.m1.2.3.cmml" xref="alg1.l5.m1.2.3"><csymbol cd="ambiguous" id="alg1.l5.m1.2.3.1.cmml" xref="alg1.l5.m1.2.3">superscript</csymbol><apply id="alg1.l5.m1.2.3.2.cmml" xref="alg1.l5.m1.2.3"><csymbol cd="ambiguous" id="alg1.l5.m1.2.3.2.1.cmml" xref="alg1.l5.m1.2.3">subscript</csymbol><ci id="alg1.l5.m1.2.3.2.2.cmml" xref="alg1.l5.m1.2.3.2.2">ğœƒ</ci><list id="alg1.l5.m1.2.2.2.3.cmml" xref="alg1.l5.m1.2.2.2.4"><ci id="alg1.l5.m1.1.1.1.1.cmml" xref="alg1.l5.m1.1.1.1.1">ğ‘</ci><ci id="alg1.l5.m1.2.2.2.2.cmml" xref="alg1.l5.m1.2.2.2.2">ğ‘˜</ci></list></apply><ci id="alg1.l5.m1.2.3.3.cmml" xref="alg1.l5.m1.2.3.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m1.2c">\theta_{p,k}^{t}</annotation></semantics></math> <math id="alg1.l5.m2.1" class="ltx_Math" alttext="\leftarrow" display="inline"><semantics id="alg1.l5.m2.1a"><mo stretchy="false" id="alg1.l5.m2.1.1" xref="alg1.l5.m2.1.1.cmml">â†</mo><annotation-xml encoding="MathML-Content" id="alg1.l5.m2.1b"><ci id="alg1.l5.m2.1.1.cmml" xref="alg1.l5.m2.1.1">â†</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m2.1c">\leftarrow</annotation></semantics></math> <math id="alg1.l5.m3.2" class="ltx_Math" alttext="\theta_{p,k}^{t-1}" display="inline"><semantics id="alg1.l5.m3.2a"><msubsup id="alg1.l5.m3.2.3" xref="alg1.l5.m3.2.3.cmml"><mi id="alg1.l5.m3.2.3.2.2" xref="alg1.l5.m3.2.3.2.2.cmml">Î¸</mi><mrow id="alg1.l5.m3.2.2.2.4" xref="alg1.l5.m3.2.2.2.3.cmml"><mi id="alg1.l5.m3.1.1.1.1" xref="alg1.l5.m3.1.1.1.1.cmml">p</mi><mo id="alg1.l5.m3.2.2.2.4.1" xref="alg1.l5.m3.2.2.2.3.cmml">,</mo><mi id="alg1.l5.m3.2.2.2.2" xref="alg1.l5.m3.2.2.2.2.cmml">k</mi></mrow><mrow id="alg1.l5.m3.2.3.3" xref="alg1.l5.m3.2.3.3.cmml"><mi id="alg1.l5.m3.2.3.3.2" xref="alg1.l5.m3.2.3.3.2.cmml">t</mi><mo id="alg1.l5.m3.2.3.3.1" xref="alg1.l5.m3.2.3.3.1.cmml">âˆ’</mo><mn id="alg1.l5.m3.2.3.3.3" xref="alg1.l5.m3.2.3.3.3.cmml">1</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l5.m3.2b"><apply id="alg1.l5.m3.2.3.cmml" xref="alg1.l5.m3.2.3"><csymbol cd="ambiguous" id="alg1.l5.m3.2.3.1.cmml" xref="alg1.l5.m3.2.3">superscript</csymbol><apply id="alg1.l5.m3.2.3.2.cmml" xref="alg1.l5.m3.2.3"><csymbol cd="ambiguous" id="alg1.l5.m3.2.3.2.1.cmml" xref="alg1.l5.m3.2.3">subscript</csymbol><ci id="alg1.l5.m3.2.3.2.2.cmml" xref="alg1.l5.m3.2.3.2.2">ğœƒ</ci><list id="alg1.l5.m3.2.2.2.3.cmml" xref="alg1.l5.m3.2.2.2.4"><ci id="alg1.l5.m3.1.1.1.1.cmml" xref="alg1.l5.m3.1.1.1.1">ğ‘</ci><ci id="alg1.l5.m3.2.2.2.2.cmml" xref="alg1.l5.m3.2.2.2.2">ğ‘˜</ci></list></apply><apply id="alg1.l5.m3.2.3.3.cmml" xref="alg1.l5.m3.2.3.3"><minus id="alg1.l5.m3.2.3.3.1.cmml" xref="alg1.l5.m3.2.3.3.1"></minus><ci id="alg1.l5.m3.2.3.3.2.cmml" xref="alg1.l5.m3.2.3.3.2">ğ‘¡</ci><cn type="integer" id="alg1.l5.m3.2.3.3.3.cmml" xref="alg1.l5.m3.2.3.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m3.2c">\theta_{p,k}^{t-1}</annotation></semantics></math>

</div>
<div id="alg1.l6" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l6.1.1.1" class="ltx_text" style="font-size:80%;">6:</span></span>Â Â Â Â Â Â Â Â <span id="alg1.l6.2" class="ltx_text ltx_font_bold">for all</span>Â <math id="alg1.l6.m1.1" class="ltx_Math" alttext="l" display="inline"><semantics id="alg1.l6.m1.1a"><mi id="alg1.l6.m1.1.1" xref="alg1.l6.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="alg1.l6.m1.1b"><ci id="alg1.l6.m1.1.1.cmml" xref="alg1.l6.m1.1.1">ğ‘™</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m1.1c">l</annotation></semantics></math>=1, 2, â€¦,Â <span id="alg1.l6.3" class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg1.l7" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l7.1.1.1" class="ltx_text" style="font-size:80%;">7:</span></span>Â Â Â Â Â Â Â Â Â Â Â <math id="alg1.l7.m1.4" class="ltx_Math" alttext="\theta_{p,k}^{t,l+1}" display="inline"><semantics id="alg1.l7.m1.4a"><msubsup id="alg1.l7.m1.4.5" xref="alg1.l7.m1.4.5.cmml"><mi id="alg1.l7.m1.4.5.2.2" xref="alg1.l7.m1.4.5.2.2.cmml">Î¸</mi><mrow id="alg1.l7.m1.2.2.2.4" xref="alg1.l7.m1.2.2.2.3.cmml"><mi id="alg1.l7.m1.1.1.1.1" xref="alg1.l7.m1.1.1.1.1.cmml">p</mi><mo id="alg1.l7.m1.2.2.2.4.1" xref="alg1.l7.m1.2.2.2.3.cmml">,</mo><mi id="alg1.l7.m1.2.2.2.2" xref="alg1.l7.m1.2.2.2.2.cmml">k</mi></mrow><mrow id="alg1.l7.m1.4.4.2.2" xref="alg1.l7.m1.4.4.2.3.cmml"><mi id="alg1.l7.m1.3.3.1.1" xref="alg1.l7.m1.3.3.1.1.cmml">t</mi><mo id="alg1.l7.m1.4.4.2.2.2" xref="alg1.l7.m1.4.4.2.3.cmml">,</mo><mrow id="alg1.l7.m1.4.4.2.2.1" xref="alg1.l7.m1.4.4.2.2.1.cmml"><mi id="alg1.l7.m1.4.4.2.2.1.2" xref="alg1.l7.m1.4.4.2.2.1.2.cmml">l</mi><mo id="alg1.l7.m1.4.4.2.2.1.1" xref="alg1.l7.m1.4.4.2.2.1.1.cmml">+</mo><mn id="alg1.l7.m1.4.4.2.2.1.3" xref="alg1.l7.m1.4.4.2.2.1.3.cmml">1</mn></mrow></mrow></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l7.m1.4b"><apply id="alg1.l7.m1.4.5.cmml" xref="alg1.l7.m1.4.5"><csymbol cd="ambiguous" id="alg1.l7.m1.4.5.1.cmml" xref="alg1.l7.m1.4.5">superscript</csymbol><apply id="alg1.l7.m1.4.5.2.cmml" xref="alg1.l7.m1.4.5"><csymbol cd="ambiguous" id="alg1.l7.m1.4.5.2.1.cmml" xref="alg1.l7.m1.4.5">subscript</csymbol><ci id="alg1.l7.m1.4.5.2.2.cmml" xref="alg1.l7.m1.4.5.2.2">ğœƒ</ci><list id="alg1.l7.m1.2.2.2.3.cmml" xref="alg1.l7.m1.2.2.2.4"><ci id="alg1.l7.m1.1.1.1.1.cmml" xref="alg1.l7.m1.1.1.1.1">ğ‘</ci><ci id="alg1.l7.m1.2.2.2.2.cmml" xref="alg1.l7.m1.2.2.2.2">ğ‘˜</ci></list></apply><list id="alg1.l7.m1.4.4.2.3.cmml" xref="alg1.l7.m1.4.4.2.2"><ci id="alg1.l7.m1.3.3.1.1.cmml" xref="alg1.l7.m1.3.3.1.1">ğ‘¡</ci><apply id="alg1.l7.m1.4.4.2.2.1.cmml" xref="alg1.l7.m1.4.4.2.2.1"><plus id="alg1.l7.m1.4.4.2.2.1.1.cmml" xref="alg1.l7.m1.4.4.2.2.1.1"></plus><ci id="alg1.l7.m1.4.4.2.2.1.2.cmml" xref="alg1.l7.m1.4.4.2.2.1.2">ğ‘™</ci><cn type="integer" id="alg1.l7.m1.4.4.2.2.1.3.cmml" xref="alg1.l7.m1.4.4.2.2.1.3">1</cn></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m1.4c">\theta_{p,k}^{t,l+1}</annotation></semantics></math> <math id="alg1.l7.m2.1" class="ltx_Math" alttext="\leftarrow" display="inline"><semantics id="alg1.l7.m2.1a"><mo stretchy="false" id="alg1.l7.m2.1.1" xref="alg1.l7.m2.1.1.cmml">â†</mo><annotation-xml encoding="MathML-Content" id="alg1.l7.m2.1b"><ci id="alg1.l7.m2.1.1.cmml" xref="alg1.l7.m2.1.1">â†</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m2.1c">\leftarrow</annotation></semantics></math> (<math id="alg1.l7.m3.1" class="ltx_Math" alttext="L" display="inline"><semantics id="alg1.l7.m3.1a"><mi id="alg1.l7.m3.1.1" xref="alg1.l7.m3.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="alg1.l7.m3.1b"><ci id="alg1.l7.m3.1.1.cmml" xref="alg1.l7.m3.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m3.1c">L</annotation></semantics></math><sub id="alg1.l7.2" class="ltx_sub"><span id="alg1.l7.2.1" class="ltx_text ltx_font_italic">k</span></sub> (<math id="alg1.l7.m5.4" class="ltx_Math" alttext="\theta_{p,k}^{t,l}" display="inline"><semantics id="alg1.l7.m5.4a"><msubsup id="alg1.l7.m5.4.5" xref="alg1.l7.m5.4.5.cmml"><mi id="alg1.l7.m5.4.5.2.2" xref="alg1.l7.m5.4.5.2.2.cmml">Î¸</mi><mrow id="alg1.l7.m5.2.2.2.4" xref="alg1.l7.m5.2.2.2.3.cmml"><mi id="alg1.l7.m5.1.1.1.1" xref="alg1.l7.m5.1.1.1.1.cmml">p</mi><mo id="alg1.l7.m5.2.2.2.4.1" xref="alg1.l7.m5.2.2.2.3.cmml">,</mo><mi id="alg1.l7.m5.2.2.2.2" xref="alg1.l7.m5.2.2.2.2.cmml">k</mi></mrow><mrow id="alg1.l7.m5.4.4.2.4" xref="alg1.l7.m5.4.4.2.3.cmml"><mi id="alg1.l7.m5.3.3.1.1" xref="alg1.l7.m5.3.3.1.1.cmml">t</mi><mo id="alg1.l7.m5.4.4.2.4.1" xref="alg1.l7.m5.4.4.2.3.cmml">,</mo><mi id="alg1.l7.m5.4.4.2.2" xref="alg1.l7.m5.4.4.2.2.cmml">l</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l7.m5.4b"><apply id="alg1.l7.m5.4.5.cmml" xref="alg1.l7.m5.4.5"><csymbol cd="ambiguous" id="alg1.l7.m5.4.5.1.cmml" xref="alg1.l7.m5.4.5">superscript</csymbol><apply id="alg1.l7.m5.4.5.2.cmml" xref="alg1.l7.m5.4.5"><csymbol cd="ambiguous" id="alg1.l7.m5.4.5.2.1.cmml" xref="alg1.l7.m5.4.5">subscript</csymbol><ci id="alg1.l7.m5.4.5.2.2.cmml" xref="alg1.l7.m5.4.5.2.2">ğœƒ</ci><list id="alg1.l7.m5.2.2.2.3.cmml" xref="alg1.l7.m5.2.2.2.4"><ci id="alg1.l7.m5.1.1.1.1.cmml" xref="alg1.l7.m5.1.1.1.1">ğ‘</ci><ci id="alg1.l7.m5.2.2.2.2.cmml" xref="alg1.l7.m5.2.2.2.2">ğ‘˜</ci></list></apply><list id="alg1.l7.m5.4.4.2.3.cmml" xref="alg1.l7.m5.4.4.2.4"><ci id="alg1.l7.m5.3.3.1.1.cmml" xref="alg1.l7.m5.3.3.1.1">ğ‘¡</ci><ci id="alg1.l7.m5.4.4.2.2.cmml" xref="alg1.l7.m5.4.4.2.2">ğ‘™</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m5.4c">\theta_{p,k}^{t,l}</annotation></semantics></math>, <math id="alg1.l7.m6.1" class="ltx_Math" alttext="\theta_{s}^{t}" display="inline"><semantics id="alg1.l7.m6.1a"><msubsup id="alg1.l7.m6.1.1" xref="alg1.l7.m6.1.1.cmml"><mi id="alg1.l7.m6.1.1.2.2" xref="alg1.l7.m6.1.1.2.2.cmml">Î¸</mi><mi id="alg1.l7.m6.1.1.2.3" xref="alg1.l7.m6.1.1.2.3.cmml">s</mi><mi id="alg1.l7.m6.1.1.3" xref="alg1.l7.m6.1.1.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l7.m6.1b"><apply id="alg1.l7.m6.1.1.cmml" xref="alg1.l7.m6.1.1"><csymbol cd="ambiguous" id="alg1.l7.m6.1.1.1.cmml" xref="alg1.l7.m6.1.1">superscript</csymbol><apply id="alg1.l7.m6.1.1.2.cmml" xref="alg1.l7.m6.1.1"><csymbol cd="ambiguous" id="alg1.l7.m6.1.1.2.1.cmml" xref="alg1.l7.m6.1.1">subscript</csymbol><ci id="alg1.l7.m6.1.1.2.2.cmml" xref="alg1.l7.m6.1.1.2.2">ğœƒ</ci><ci id="alg1.l7.m6.1.1.2.3.cmml" xref="alg1.l7.m6.1.1.2.3">ğ‘ </ci></apply><ci id="alg1.l7.m6.1.1.3.cmml" xref="alg1.l7.m6.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m6.1c">\theta_{s}^{t}</annotation></semantics></math>), <math id="alg1.l7.m7.4" class="ltx_Math" alttext="\theta_{p,k}^{t,l}" display="inline"><semantics id="alg1.l7.m7.4a"><msubsup id="alg1.l7.m7.4.5" xref="alg1.l7.m7.4.5.cmml"><mi id="alg1.l7.m7.4.5.2.2" xref="alg1.l7.m7.4.5.2.2.cmml">Î¸</mi><mrow id="alg1.l7.m7.2.2.2.4" xref="alg1.l7.m7.2.2.2.3.cmml"><mi id="alg1.l7.m7.1.1.1.1" xref="alg1.l7.m7.1.1.1.1.cmml">p</mi><mo id="alg1.l7.m7.2.2.2.4.1" xref="alg1.l7.m7.2.2.2.3.cmml">,</mo><mi id="alg1.l7.m7.2.2.2.2" xref="alg1.l7.m7.2.2.2.2.cmml">k</mi></mrow><mrow id="alg1.l7.m7.4.4.2.4" xref="alg1.l7.m7.4.4.2.3.cmml"><mi id="alg1.l7.m7.3.3.1.1" xref="alg1.l7.m7.3.3.1.1.cmml">t</mi><mo id="alg1.l7.m7.4.4.2.4.1" xref="alg1.l7.m7.4.4.2.3.cmml">,</mo><mi id="alg1.l7.m7.4.4.2.2" xref="alg1.l7.m7.4.4.2.2.cmml">l</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l7.m7.4b"><apply id="alg1.l7.m7.4.5.cmml" xref="alg1.l7.m7.4.5"><csymbol cd="ambiguous" id="alg1.l7.m7.4.5.1.cmml" xref="alg1.l7.m7.4.5">superscript</csymbol><apply id="alg1.l7.m7.4.5.2.cmml" xref="alg1.l7.m7.4.5"><csymbol cd="ambiguous" id="alg1.l7.m7.4.5.2.1.cmml" xref="alg1.l7.m7.4.5">subscript</csymbol><ci id="alg1.l7.m7.4.5.2.2.cmml" xref="alg1.l7.m7.4.5.2.2">ğœƒ</ci><list id="alg1.l7.m7.2.2.2.3.cmml" xref="alg1.l7.m7.2.2.2.4"><ci id="alg1.l7.m7.1.1.1.1.cmml" xref="alg1.l7.m7.1.1.1.1">ğ‘</ci><ci id="alg1.l7.m7.2.2.2.2.cmml" xref="alg1.l7.m7.2.2.2.2">ğ‘˜</ci></list></apply><list id="alg1.l7.m7.4.4.2.3.cmml" xref="alg1.l7.m7.4.4.2.4"><ci id="alg1.l7.m7.3.3.1.1.cmml" xref="alg1.l7.m7.3.3.1.1">ğ‘¡</ci><ci id="alg1.l7.m7.4.4.2.2.cmml" xref="alg1.l7.m7.4.4.2.2">ğ‘™</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m7.4c">\theta_{p,k}^{t,l}</annotation></semantics></math>).

</div>
<div id="alg1.l8" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l8.1.1.1" class="ltx_text" style="font-size:80%;">8:</span></span>Â Â Â Â Â Â Â Â <span id="alg1.l8.2" class="ltx_text ltx_font_bold">end</span>Â <span id="alg1.l8.3" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l9" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l9.1.1.1" class="ltx_text" style="font-size:80%;">9:</span></span>Â Â Â Â Â Â Â Â Client <math id="alg1.l9.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="alg1.l9.m1.1a"><mi id="alg1.l9.m1.1.1" xref="alg1.l9.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="alg1.l9.m1.1b"><ci id="alg1.l9.m1.1.1.cmml" xref="alg1.l9.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m1.1c">k</annotation></semantics></math> locally updates the representation as:
â€ƒâ€ƒâ€ƒâ€ƒ<math id="alg1.l9.m2.2" class="ltx_Math" alttext="\theta_{s,k}^{t+1}" display="inline"><semantics id="alg1.l9.m2.2a"><msubsup id="alg1.l9.m2.2.3" xref="alg1.l9.m2.2.3.cmml"><mi id="alg1.l9.m2.2.3.2.2" xref="alg1.l9.m2.2.3.2.2.cmml">Î¸</mi><mrow id="alg1.l9.m2.2.2.2.4" xref="alg1.l9.m2.2.2.2.3.cmml"><mi id="alg1.l9.m2.1.1.1.1" xref="alg1.l9.m2.1.1.1.1.cmml">s</mi><mo id="alg1.l9.m2.2.2.2.4.1" xref="alg1.l9.m2.2.2.2.3.cmml">,</mo><mi id="alg1.l9.m2.2.2.2.2" xref="alg1.l9.m2.2.2.2.2.cmml">k</mi></mrow><mrow id="alg1.l9.m2.2.3.3" xref="alg1.l9.m2.2.3.3.cmml"><mi id="alg1.l9.m2.2.3.3.2" xref="alg1.l9.m2.2.3.3.2.cmml">t</mi><mo id="alg1.l9.m2.2.3.3.1" xref="alg1.l9.m2.2.3.3.1.cmml">+</mo><mn id="alg1.l9.m2.2.3.3.3" xref="alg1.l9.m2.2.3.3.3.cmml">1</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l9.m2.2b"><apply id="alg1.l9.m2.2.3.cmml" xref="alg1.l9.m2.2.3"><csymbol cd="ambiguous" id="alg1.l9.m2.2.3.1.cmml" xref="alg1.l9.m2.2.3">superscript</csymbol><apply id="alg1.l9.m2.2.3.2.cmml" xref="alg1.l9.m2.2.3"><csymbol cd="ambiguous" id="alg1.l9.m2.2.3.2.1.cmml" xref="alg1.l9.m2.2.3">subscript</csymbol><ci id="alg1.l9.m2.2.3.2.2.cmml" xref="alg1.l9.m2.2.3.2.2">ğœƒ</ci><list id="alg1.l9.m2.2.2.2.3.cmml" xref="alg1.l9.m2.2.2.2.4"><ci id="alg1.l9.m2.1.1.1.1.cmml" xref="alg1.l9.m2.1.1.1.1">ğ‘ </ci><ci id="alg1.l9.m2.2.2.2.2.cmml" xref="alg1.l9.m2.2.2.2.2">ğ‘˜</ci></list></apply><apply id="alg1.l9.m2.2.3.3.cmml" xref="alg1.l9.m2.2.3.3"><plus id="alg1.l9.m2.2.3.3.1.cmml" xref="alg1.l9.m2.2.3.3.1"></plus><ci id="alg1.l9.m2.2.3.3.2.cmml" xref="alg1.l9.m2.2.3.3.2">ğ‘¡</ci><cn type="integer" id="alg1.l9.m2.2.3.3.3.cmml" xref="alg1.l9.m2.2.3.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m2.2c">\theta_{s,k}^{t+1}</annotation></semantics></math> <math id="alg1.l9.m3.1" class="ltx_Math" alttext="\leftarrow" display="inline"><semantics id="alg1.l9.m3.1a"><mo stretchy="false" id="alg1.l9.m3.1.1" xref="alg1.l9.m3.1.1.cmml">â†</mo><annotation-xml encoding="MathML-Content" id="alg1.l9.m3.1b"><ci id="alg1.l9.m3.1.1.cmml" xref="alg1.l9.m3.1.1">â†</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m3.1c">\leftarrow</annotation></semantics></math> (<math id="alg1.l9.m4.1" class="ltx_Math" alttext="L" display="inline"><semantics id="alg1.l9.m4.1a"><mi id="alg1.l9.m4.1.1" xref="alg1.l9.m4.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="alg1.l9.m4.1b"><ci id="alg1.l9.m4.1.1.cmml" xref="alg1.l9.m4.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m4.1c">L</annotation></semantics></math><sub id="alg1.l9.2" class="ltx_sub"><span id="alg1.l9.2.1" class="ltx_text ltx_font_italic">k</span></sub> (<math id="alg1.l9.m6.2" class="ltx_Math" alttext="\theta_{p,k}^{t}" display="inline"><semantics id="alg1.l9.m6.2a"><msubsup id="alg1.l9.m6.2.3" xref="alg1.l9.m6.2.3.cmml"><mi id="alg1.l9.m6.2.3.2.2" xref="alg1.l9.m6.2.3.2.2.cmml">Î¸</mi><mrow id="alg1.l9.m6.2.2.2.4" xref="alg1.l9.m6.2.2.2.3.cmml"><mi id="alg1.l9.m6.1.1.1.1" xref="alg1.l9.m6.1.1.1.1.cmml">p</mi><mo id="alg1.l9.m6.2.2.2.4.1" xref="alg1.l9.m6.2.2.2.3.cmml">,</mo><mi id="alg1.l9.m6.2.2.2.2" xref="alg1.l9.m6.2.2.2.2.cmml">k</mi></mrow><mi id="alg1.l9.m6.2.3.3" xref="alg1.l9.m6.2.3.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l9.m6.2b"><apply id="alg1.l9.m6.2.3.cmml" xref="alg1.l9.m6.2.3"><csymbol cd="ambiguous" id="alg1.l9.m6.2.3.1.cmml" xref="alg1.l9.m6.2.3">superscript</csymbol><apply id="alg1.l9.m6.2.3.2.cmml" xref="alg1.l9.m6.2.3"><csymbol cd="ambiguous" id="alg1.l9.m6.2.3.2.1.cmml" xref="alg1.l9.m6.2.3">subscript</csymbol><ci id="alg1.l9.m6.2.3.2.2.cmml" xref="alg1.l9.m6.2.3.2.2">ğœƒ</ci><list id="alg1.l9.m6.2.2.2.3.cmml" xref="alg1.l9.m6.2.2.2.4"><ci id="alg1.l9.m6.1.1.1.1.cmml" xref="alg1.l9.m6.1.1.1.1">ğ‘</ci><ci id="alg1.l9.m6.2.2.2.2.cmml" xref="alg1.l9.m6.2.2.2.2">ğ‘˜</ci></list></apply><ci id="alg1.l9.m6.2.3.3.cmml" xref="alg1.l9.m6.2.3.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m6.2c">\theta_{p,k}^{t}</annotation></semantics></math>, <math id="alg1.l9.m7.1" class="ltx_Math" alttext="\theta_{s}^{t}" display="inline"><semantics id="alg1.l9.m7.1a"><msubsup id="alg1.l9.m7.1.1" xref="alg1.l9.m7.1.1.cmml"><mi id="alg1.l9.m7.1.1.2.2" xref="alg1.l9.m7.1.1.2.2.cmml">Î¸</mi><mi id="alg1.l9.m7.1.1.2.3" xref="alg1.l9.m7.1.1.2.3.cmml">s</mi><mi id="alg1.l9.m7.1.1.3" xref="alg1.l9.m7.1.1.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l9.m7.1b"><apply id="alg1.l9.m7.1.1.cmml" xref="alg1.l9.m7.1.1"><csymbol cd="ambiguous" id="alg1.l9.m7.1.1.1.cmml" xref="alg1.l9.m7.1.1">superscript</csymbol><apply id="alg1.l9.m7.1.1.2.cmml" xref="alg1.l9.m7.1.1"><csymbol cd="ambiguous" id="alg1.l9.m7.1.1.2.1.cmml" xref="alg1.l9.m7.1.1">subscript</csymbol><ci id="alg1.l9.m7.1.1.2.2.cmml" xref="alg1.l9.m7.1.1.2.2">ğœƒ</ci><ci id="alg1.l9.m7.1.1.2.3.cmml" xref="alg1.l9.m7.1.1.2.3">ğ‘ </ci></apply><ci id="alg1.l9.m7.1.1.3.cmml" xref="alg1.l9.m7.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m7.1c">\theta_{s}^{t}</annotation></semantics></math>), <math id="alg1.l9.m8.1" class="ltx_Math" alttext="\theta_{s}^{t}" display="inline"><semantics id="alg1.l9.m8.1a"><msubsup id="alg1.l9.m8.1.1" xref="alg1.l9.m8.1.1.cmml"><mi id="alg1.l9.m8.1.1.2.2" xref="alg1.l9.m8.1.1.2.2.cmml">Î¸</mi><mi id="alg1.l9.m8.1.1.2.3" xref="alg1.l9.m8.1.1.2.3.cmml">s</mi><mi id="alg1.l9.m8.1.1.3" xref="alg1.l9.m8.1.1.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l9.m8.1b"><apply id="alg1.l9.m8.1.1.cmml" xref="alg1.l9.m8.1.1"><csymbol cd="ambiguous" id="alg1.l9.m8.1.1.1.cmml" xref="alg1.l9.m8.1.1">superscript</csymbol><apply id="alg1.l9.m8.1.1.2.cmml" xref="alg1.l9.m8.1.1"><csymbol cd="ambiguous" id="alg1.l9.m8.1.1.2.1.cmml" xref="alg1.l9.m8.1.1">subscript</csymbol><ci id="alg1.l9.m8.1.1.2.2.cmml" xref="alg1.l9.m8.1.1.2.2">ğœƒ</ci><ci id="alg1.l9.m8.1.1.2.3.cmml" xref="alg1.l9.m8.1.1.2.3">ğ‘ </ci></apply><ci id="alg1.l9.m8.1.1.3.cmml" xref="alg1.l9.m8.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m8.1c">\theta_{s}^{t}</annotation></semantics></math>)

</div>
<div id="alg1.l10" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l10.1.1.1" class="ltx_text" style="font-size:80%;">10:</span></span>Â Â Â Â Â Â Â Â Client <math id="alg1.l10.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="alg1.l10.m1.1a"><mi id="alg1.l10.m1.1.1" xref="alg1.l10.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="alg1.l10.m1.1b"><ci id="alg1.l10.m1.1.1.cmml" xref="alg1.l10.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.m1.1c">k</annotation></semantics></math> sends <math id="alg1.l10.m2.2" class="ltx_Math" alttext="\theta_{s,k}^{t+1}" display="inline"><semantics id="alg1.l10.m2.2a"><msubsup id="alg1.l10.m2.2.3" xref="alg1.l10.m2.2.3.cmml"><mi id="alg1.l10.m2.2.3.2.2" xref="alg1.l10.m2.2.3.2.2.cmml">Î¸</mi><mrow id="alg1.l10.m2.2.2.2.4" xref="alg1.l10.m2.2.2.2.3.cmml"><mi id="alg1.l10.m2.1.1.1.1" xref="alg1.l10.m2.1.1.1.1.cmml">s</mi><mo id="alg1.l10.m2.2.2.2.4.1" xref="alg1.l10.m2.2.2.2.3.cmml">,</mo><mi id="alg1.l10.m2.2.2.2.2" xref="alg1.l10.m2.2.2.2.2.cmml">k</mi></mrow><mrow id="alg1.l10.m2.2.3.3" xref="alg1.l10.m2.2.3.3.cmml"><mi id="alg1.l10.m2.2.3.3.2" xref="alg1.l10.m2.2.3.3.2.cmml">t</mi><mo id="alg1.l10.m2.2.3.3.1" xref="alg1.l10.m2.2.3.3.1.cmml">+</mo><mn id="alg1.l10.m2.2.3.3.3" xref="alg1.l10.m2.2.3.3.3.cmml">1</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l10.m2.2b"><apply id="alg1.l10.m2.2.3.cmml" xref="alg1.l10.m2.2.3"><csymbol cd="ambiguous" id="alg1.l10.m2.2.3.1.cmml" xref="alg1.l10.m2.2.3">superscript</csymbol><apply id="alg1.l10.m2.2.3.2.cmml" xref="alg1.l10.m2.2.3"><csymbol cd="ambiguous" id="alg1.l10.m2.2.3.2.1.cmml" xref="alg1.l10.m2.2.3">subscript</csymbol><ci id="alg1.l10.m2.2.3.2.2.cmml" xref="alg1.l10.m2.2.3.2.2">ğœƒ</ci><list id="alg1.l10.m2.2.2.2.3.cmml" xref="alg1.l10.m2.2.2.2.4"><ci id="alg1.l10.m2.1.1.1.1.cmml" xref="alg1.l10.m2.1.1.1.1">ğ‘ </ci><ci id="alg1.l10.m2.2.2.2.2.cmml" xref="alg1.l10.m2.2.2.2.2">ğ‘˜</ci></list></apply><apply id="alg1.l10.m2.2.3.3.cmml" xref="alg1.l10.m2.2.3.3"><plus id="alg1.l10.m2.2.3.3.1.cmml" xref="alg1.l10.m2.2.3.3.1"></plus><ci id="alg1.l10.m2.2.3.3.2.cmml" xref="alg1.l10.m2.2.3.3.2">ğ‘¡</ci><cn type="integer" id="alg1.l10.m2.2.3.3.3.cmml" xref="alg1.l10.m2.2.3.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.m2.2c">\theta_{s,k}^{t+1}</annotation></semantics></math> to server

</div>
<div id="alg1.l11" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l11.1.1.1" class="ltx_text" style="font-size:80%;">11:</span></span>Â Â Â Â Â <span id="alg1.l11.2" class="ltx_text ltx_font_bold">end</span>Â <span id="alg1.l11.3" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l12" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l12.1.1.1" class="ltx_text" style="font-size:80%;">12:</span></span>Â Â Â Â Â Server computes:
<math id="alg1.l12.m1.1" class="ltx_Math" alttext="\theta_{s}^{t+1}" display="inline"><semantics id="alg1.l12.m1.1a"><msubsup id="alg1.l12.m1.1.1" xref="alg1.l12.m1.1.1.cmml"><mi id="alg1.l12.m1.1.1.2.2" xref="alg1.l12.m1.1.1.2.2.cmml">Î¸</mi><mi id="alg1.l12.m1.1.1.2.3" xref="alg1.l12.m1.1.1.2.3.cmml">s</mi><mrow id="alg1.l12.m1.1.1.3" xref="alg1.l12.m1.1.1.3.cmml"><mi id="alg1.l12.m1.1.1.3.2" xref="alg1.l12.m1.1.1.3.2.cmml">t</mi><mo id="alg1.l12.m1.1.1.3.1" xref="alg1.l12.m1.1.1.3.1.cmml">+</mo><mn id="alg1.l12.m1.1.1.3.3" xref="alg1.l12.m1.1.1.3.3.cmml">1</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l12.m1.1b"><apply id="alg1.l12.m1.1.1.cmml" xref="alg1.l12.m1.1.1"><csymbol cd="ambiguous" id="alg1.l12.m1.1.1.1.cmml" xref="alg1.l12.m1.1.1">superscript</csymbol><apply id="alg1.l12.m1.1.1.2.cmml" xref="alg1.l12.m1.1.1"><csymbol cd="ambiguous" id="alg1.l12.m1.1.1.2.1.cmml" xref="alg1.l12.m1.1.1">subscript</csymbol><ci id="alg1.l12.m1.1.1.2.2.cmml" xref="alg1.l12.m1.1.1.2.2">ğœƒ</ci><ci id="alg1.l12.m1.1.1.2.3.cmml" xref="alg1.l12.m1.1.1.2.3">ğ‘ </ci></apply><apply id="alg1.l12.m1.1.1.3.cmml" xref="alg1.l12.m1.1.1.3"><plus id="alg1.l12.m1.1.1.3.1.cmml" xref="alg1.l12.m1.1.1.3.1"></plus><ci id="alg1.l12.m1.1.1.3.2.cmml" xref="alg1.l12.m1.1.1.3.2">ğ‘¡</ci><cn type="integer" id="alg1.l12.m1.1.1.3.3.cmml" xref="alg1.l12.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l12.m1.1c">\theta_{s}^{t+1}</annotation></semantics></math>=<math id="alg1.l12.m2.1" class="ltx_Math" alttext="w" display="inline"><semantics id="alg1.l12.m2.1a"><mi id="alg1.l12.m2.1.1" xref="alg1.l12.m2.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="alg1.l12.m2.1b"><ci id="alg1.l12.m2.1.1.cmml" xref="alg1.l12.m2.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l12.m2.1c">w</annotation></semantics></math> <math id="alg1.l12.m3.1" class="ltx_Math" alttext="\sum" display="inline"><semantics id="alg1.l12.m3.1a"><mo id="alg1.l12.m3.1.1" xref="alg1.l12.m3.1.1.cmml">âˆ‘</mo><annotation-xml encoding="MathML-Content" id="alg1.l12.m3.1b"><sum id="alg1.l12.m3.1.1.cmml" xref="alg1.l12.m3.1.1"></sum></annotation-xml><annotation encoding="application/x-tex" id="alg1.l12.m3.1c">\sum</annotation></semantics></math> <math id="alg1.l12.m4.2" class="ltx_Math" alttext="\theta_{s,k}^{t+1}" display="inline"><semantics id="alg1.l12.m4.2a"><msubsup id="alg1.l12.m4.2.3" xref="alg1.l12.m4.2.3.cmml"><mi id="alg1.l12.m4.2.3.2.2" xref="alg1.l12.m4.2.3.2.2.cmml">Î¸</mi><mrow id="alg1.l12.m4.2.2.2.4" xref="alg1.l12.m4.2.2.2.3.cmml"><mi id="alg1.l12.m4.1.1.1.1" xref="alg1.l12.m4.1.1.1.1.cmml">s</mi><mo id="alg1.l12.m4.2.2.2.4.1" xref="alg1.l12.m4.2.2.2.3.cmml">,</mo><mi id="alg1.l12.m4.2.2.2.2" xref="alg1.l12.m4.2.2.2.2.cmml">k</mi></mrow><mrow id="alg1.l12.m4.2.3.3" xref="alg1.l12.m4.2.3.3.cmml"><mi id="alg1.l12.m4.2.3.3.2" xref="alg1.l12.m4.2.3.3.2.cmml">t</mi><mo id="alg1.l12.m4.2.3.3.1" xref="alg1.l12.m4.2.3.3.1.cmml">+</mo><mn id="alg1.l12.m4.2.3.3.3" xref="alg1.l12.m4.2.3.3.3.cmml">1</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l12.m4.2b"><apply id="alg1.l12.m4.2.3.cmml" xref="alg1.l12.m4.2.3"><csymbol cd="ambiguous" id="alg1.l12.m4.2.3.1.cmml" xref="alg1.l12.m4.2.3">superscript</csymbol><apply id="alg1.l12.m4.2.3.2.cmml" xref="alg1.l12.m4.2.3"><csymbol cd="ambiguous" id="alg1.l12.m4.2.3.2.1.cmml" xref="alg1.l12.m4.2.3">subscript</csymbol><ci id="alg1.l12.m4.2.3.2.2.cmml" xref="alg1.l12.m4.2.3.2.2">ğœƒ</ci><list id="alg1.l12.m4.2.2.2.3.cmml" xref="alg1.l12.m4.2.2.2.4"><ci id="alg1.l12.m4.1.1.1.1.cmml" xref="alg1.l12.m4.1.1.1.1">ğ‘ </ci><ci id="alg1.l12.m4.2.2.2.2.cmml" xref="alg1.l12.m4.2.2.2.2">ğ‘˜</ci></list></apply><apply id="alg1.l12.m4.2.3.3.cmml" xref="alg1.l12.m4.2.3.3"><plus id="alg1.l12.m4.2.3.3.1.cmml" xref="alg1.l12.m4.2.3.3.1"></plus><ci id="alg1.l12.m4.2.3.3.2.cmml" xref="alg1.l12.m4.2.3.3.2">ğ‘¡</ci><cn type="integer" id="alg1.l12.m4.2.3.3.3.cmml" xref="alg1.l12.m4.2.3.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l12.m4.2c">\theta_{s,k}^{t+1}</annotation></semantics></math>

</div>
<div id="alg1.l13" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l13.1.1.1" class="ltx_text" style="font-size:80%;">13:</span></span>Â Â <span id="alg1.l13.2" class="ltx_text ltx_font_bold">end</span>Â <span id="alg1.l13.3" class="ltx_text ltx_font_bold">for</span>
</div>
</div>
</div>
</div>
</figure>
<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.9" class="ltx_p">Considering that complex forged datasets with various types on the client will have a negative impact on traditional federated learning forgery detection. The key to personalized federated learning is to extract personalized representations of models trained by clients with complex forgery datasets with diverse types, as well as shared representation of multiple distributed client models. Therefore, we designed a novel federated face forgery detection learning with personalized representation. The framework of methods is shown in Figure <a href="#S3.F2" title="Figure 2 â€£ III-A Motivation â€£ III Proposed Approach â€£ Federated Face Forgery Detection Learning with Personalized Representation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The client model consists of three parts: feature extractor, personalized feature extractor, and shared feature extractor. Input images <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">x</annotation></semantics></math>, <math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="x^{\prime}" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><msup id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml"><mi id="S3.SS3.p1.2.m2.1.1.2" xref="S3.SS3.p1.2.m2.1.1.2.cmml">x</mi><mo id="S3.SS3.p1.2.m2.1.1.3" xref="S3.SS3.p1.2.m2.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">superscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2">ğ‘¥</ci><ci id="S3.SS3.p1.2.m2.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">x^{\prime}</annotation></semantics></math>, and the first pass through the feature extractor to obtain intermediate feature maps <math id="S3.SS3.p1.3.m3.1" class="ltx_Math" alttext="e" display="inline"><semantics id="S3.SS3.p1.3.m3.1a"><mi id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml">e</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><ci id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">ğ‘’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">e</annotation></semantics></math>, <math id="S3.SS3.p1.4.m4.1" class="ltx_Math" alttext="e^{\prime}" display="inline"><semantics id="S3.SS3.p1.4.m4.1a"><msup id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml"><mi id="S3.SS3.p1.4.m4.1.1.2" xref="S3.SS3.p1.4.m4.1.1.2.cmml">e</mi><mo id="S3.SS3.p1.4.m4.1.1.3" xref="S3.SS3.p1.4.m4.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><apply id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m4.1.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1">superscript</csymbol><ci id="S3.SS3.p1.4.m4.1.1.2.cmml" xref="S3.SS3.p1.4.m4.1.1.2">ğ‘’</ci><ci id="S3.SS3.p1.4.m4.1.1.3.cmml" xref="S3.SS3.p1.4.m4.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">e^{\prime}</annotation></semantics></math> <math id="S3.SS3.p1.5.m5.1" class="ltx_Math" alttext="\in" display="inline"><semantics id="S3.SS3.p1.5.m5.1a"><mo id="S3.SS3.p1.5.m5.1.1" xref="S3.SS3.p1.5.m5.1.1.cmml">âˆˆ</mo><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m5.1b"><in id="S3.SS3.p1.5.m5.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1"></in></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m5.1c">\in</annotation></semantics></math> <math id="S3.SS3.p1.6.m6.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S3.SS3.p1.6.m6.1a"><mi id="S3.SS3.p1.6.m6.1.1" xref="S3.SS3.p1.6.m6.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.6.m6.1b"><ci id="S3.SS3.p1.6.m6.1.1.cmml" xref="S3.SS3.p1.6.m6.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.6.m6.1c">R</annotation></semantics></math><sup id="S3.SS3.p1.9.1" class="ltx_sup"><span id="S3.SS3.p1.9.1.1" class="ltx_text ltx_font_italic">DÃ—HÃ—W</span></sup>. Then calculate the summary statistics (channel mean and standard deviation) and spatial configuration of <math id="S3.SS3.p1.8.m8.1" class="ltx_Math" alttext="e" display="inline"><semantics id="S3.SS3.p1.8.m8.1a"><mi id="S3.SS3.p1.8.m8.1.1" xref="S3.SS3.p1.8.m8.1.1.cmml">e</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.8.m8.1b"><ci id="S3.SS3.p1.8.m8.1.1.cmml" xref="S3.SS3.p1.8.m8.1.1">ğ‘’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.8.m8.1c">e</annotation></semantics></math>, <math id="S3.SS3.p1.9.m9.1" class="ltx_Math" alttext="e^{\prime}" display="inline"><semantics id="S3.SS3.p1.9.m9.1a"><msup id="S3.SS3.p1.9.m9.1.1" xref="S3.SS3.p1.9.m9.1.1.cmml"><mi id="S3.SS3.p1.9.m9.1.1.2" xref="S3.SS3.p1.9.m9.1.1.2.cmml">e</mi><mo id="S3.SS3.p1.9.m9.1.1.3" xref="S3.SS3.p1.9.m9.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.9.m9.1b"><apply id="S3.SS3.p1.9.m9.1.1.cmml" xref="S3.SS3.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.9.m9.1.1.1.cmml" xref="S3.SS3.p1.9.m9.1.1">superscript</csymbol><ci id="S3.SS3.p1.9.m9.1.1.2.cmml" xref="S3.SS3.p1.9.m9.1.1.2">ğ‘’</ci><ci id="S3.SS3.p1.9.m9.1.1.3.cmml" xref="S3.SS3.p1.9.m9.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.9.m9.1c">e^{\prime}</annotation></semantics></math>. Adaptive instance normalization(AdaIN) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> is a method of instance normalization. Inspired by AdaIN
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, we encourage network learning to pay more attention to features related to distinguishing true from false by interpolating feature statistics between different face samples.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.4" class="ltx_Math" alttext="R_{p}(e,\epsilon^{*},\varphi^{*})=\epsilon^{*}\cdot(\frac{e-\varphi(e)}{\epsilon(e)})+\varphi^{*}." display="block"><semantics id="S3.E1.m1.4a"><mrow id="S3.E1.m1.4.4.1" xref="S3.E1.m1.4.4.1.1.cmml"><mrow id="S3.E1.m1.4.4.1.1" xref="S3.E1.m1.4.4.1.1.cmml"><mrow id="S3.E1.m1.4.4.1.1.2" xref="S3.E1.m1.4.4.1.1.2.cmml"><msub id="S3.E1.m1.4.4.1.1.2.4" xref="S3.E1.m1.4.4.1.1.2.4.cmml"><mi id="S3.E1.m1.4.4.1.1.2.4.2" xref="S3.E1.m1.4.4.1.1.2.4.2.cmml">R</mi><mi id="S3.E1.m1.4.4.1.1.2.4.3" xref="S3.E1.m1.4.4.1.1.2.4.3.cmml">p</mi></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.4.1.1.2.3" xref="S3.E1.m1.4.4.1.1.2.3.cmml">â€‹</mo><mrow id="S3.E1.m1.4.4.1.1.2.2.2" xref="S3.E1.m1.4.4.1.1.2.2.3.cmml"><mo stretchy="false" id="S3.E1.m1.4.4.1.1.2.2.2.3" xref="S3.E1.m1.4.4.1.1.2.2.3.cmml">(</mo><mi id="S3.E1.m1.3.3" xref="S3.E1.m1.3.3.cmml">e</mi><mo id="S3.E1.m1.4.4.1.1.2.2.2.4" xref="S3.E1.m1.4.4.1.1.2.2.3.cmml">,</mo><msup id="S3.E1.m1.4.4.1.1.1.1.1.1" xref="S3.E1.m1.4.4.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.4.4.1.1.1.1.1.1.2" xref="S3.E1.m1.4.4.1.1.1.1.1.1.2.cmml">Ïµ</mi><mo id="S3.E1.m1.4.4.1.1.1.1.1.1.3" xref="S3.E1.m1.4.4.1.1.1.1.1.1.3.cmml">âˆ—</mo></msup><mo id="S3.E1.m1.4.4.1.1.2.2.2.5" xref="S3.E1.m1.4.4.1.1.2.2.3.cmml">,</mo><msup id="S3.E1.m1.4.4.1.1.2.2.2.2" xref="S3.E1.m1.4.4.1.1.2.2.2.2.cmml"><mi id="S3.E1.m1.4.4.1.1.2.2.2.2.2" xref="S3.E1.m1.4.4.1.1.2.2.2.2.2.cmml">Ï†</mi><mo id="S3.E1.m1.4.4.1.1.2.2.2.2.3" xref="S3.E1.m1.4.4.1.1.2.2.2.2.3.cmml">âˆ—</mo></msup><mo stretchy="false" id="S3.E1.m1.4.4.1.1.2.2.2.6" xref="S3.E1.m1.4.4.1.1.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.4.4.1.1.3" xref="S3.E1.m1.4.4.1.1.3.cmml">=</mo><mrow id="S3.E1.m1.4.4.1.1.4" xref="S3.E1.m1.4.4.1.1.4.cmml"><mrow id="S3.E1.m1.4.4.1.1.4.2" xref="S3.E1.m1.4.4.1.1.4.2.cmml"><msup id="S3.E1.m1.4.4.1.1.4.2.2" xref="S3.E1.m1.4.4.1.1.4.2.2.cmml"><mi id="S3.E1.m1.4.4.1.1.4.2.2.2" xref="S3.E1.m1.4.4.1.1.4.2.2.2.cmml">Ïµ</mi><mo id="S3.E1.m1.4.4.1.1.4.2.2.3" xref="S3.E1.m1.4.4.1.1.4.2.2.3.cmml">âˆ—</mo></msup><mo lspace="0.222em" rspace="0.222em" id="S3.E1.m1.4.4.1.1.4.2.1" xref="S3.E1.m1.4.4.1.1.4.2.1.cmml">â‹…</mo><mrow id="S3.E1.m1.4.4.1.1.4.2.3.2" xref="S3.E1.m1.2.2.cmml"><mo stretchy="false" id="S3.E1.m1.4.4.1.1.4.2.3.2.1" xref="S3.E1.m1.2.2.cmml">(</mo><mfrac id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.3" xref="S3.E1.m1.1.1.1.3.cmml">e</mi><mo id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.2.cmml">âˆ’</mo><mrow id="S3.E1.m1.1.1.1.4" xref="S3.E1.m1.1.1.1.4.cmml"><mi id="S3.E1.m1.1.1.1.4.2" xref="S3.E1.m1.1.1.1.4.2.cmml">Ï†</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.4.1" xref="S3.E1.m1.1.1.1.4.1.cmml">â€‹</mo><mrow id="S3.E1.m1.1.1.1.4.3.2" xref="S3.E1.m1.1.1.1.4.cmml"><mo stretchy="false" id="S3.E1.m1.1.1.1.4.3.2.1" xref="S3.E1.m1.1.1.1.4.cmml">(</mo><mi id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml">e</mi><mo stretchy="false" id="S3.E1.m1.1.1.1.4.3.2.2" xref="S3.E1.m1.1.1.1.4.cmml">)</mo></mrow></mrow></mrow><mrow id="S3.E1.m1.2.2.2" xref="S3.E1.m1.2.2.2.cmml"><mi id="S3.E1.m1.2.2.2.3" xref="S3.E1.m1.2.2.2.3.cmml">Ïµ</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.2.2" xref="S3.E1.m1.2.2.2.2.cmml">â€‹</mo><mrow id="S3.E1.m1.2.2.2.4.2" xref="S3.E1.m1.2.2.2.cmml"><mo stretchy="false" id="S3.E1.m1.2.2.2.4.2.1" xref="S3.E1.m1.2.2.2.cmml">(</mo><mi id="S3.E1.m1.2.2.2.1" xref="S3.E1.m1.2.2.2.1.cmml">e</mi><mo stretchy="false" id="S3.E1.m1.2.2.2.4.2.2" xref="S3.E1.m1.2.2.2.cmml">)</mo></mrow></mrow></mfrac><mo stretchy="false" id="S3.E1.m1.4.4.1.1.4.2.3.2.2" xref="S3.E1.m1.2.2.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.4.4.1.1.4.1" xref="S3.E1.m1.4.4.1.1.4.1.cmml">+</mo><msup id="S3.E1.m1.4.4.1.1.4.3" xref="S3.E1.m1.4.4.1.1.4.3.cmml"><mi id="S3.E1.m1.4.4.1.1.4.3.2" xref="S3.E1.m1.4.4.1.1.4.3.2.cmml">Ï†</mi><mo id="S3.E1.m1.4.4.1.1.4.3.3" xref="S3.E1.m1.4.4.1.1.4.3.3.cmml">âˆ—</mo></msup></mrow></mrow><mo lspace="0em" id="S3.E1.m1.4.4.1.2" xref="S3.E1.m1.4.4.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.4b"><apply id="S3.E1.m1.4.4.1.1.cmml" xref="S3.E1.m1.4.4.1"><eq id="S3.E1.m1.4.4.1.1.3.cmml" xref="S3.E1.m1.4.4.1.1.3"></eq><apply id="S3.E1.m1.4.4.1.1.2.cmml" xref="S3.E1.m1.4.4.1.1.2"><times id="S3.E1.m1.4.4.1.1.2.3.cmml" xref="S3.E1.m1.4.4.1.1.2.3"></times><apply id="S3.E1.m1.4.4.1.1.2.4.cmml" xref="S3.E1.m1.4.4.1.1.2.4"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.1.1.2.4.1.cmml" xref="S3.E1.m1.4.4.1.1.2.4">subscript</csymbol><ci id="S3.E1.m1.4.4.1.1.2.4.2.cmml" xref="S3.E1.m1.4.4.1.1.2.4.2">ğ‘…</ci><ci id="S3.E1.m1.4.4.1.1.2.4.3.cmml" xref="S3.E1.m1.4.4.1.1.2.4.3">ğ‘</ci></apply><vector id="S3.E1.m1.4.4.1.1.2.2.3.cmml" xref="S3.E1.m1.4.4.1.1.2.2.2"><ci id="S3.E1.m1.3.3.cmml" xref="S3.E1.m1.3.3">ğ‘’</ci><apply id="S3.E1.m1.4.4.1.1.1.1.1.1.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E1.m1.4.4.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1.2">italic-Ïµ</ci><times id="S3.E1.m1.4.4.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.4.4.1.1.1.1.1.1.3"></times></apply><apply id="S3.E1.m1.4.4.1.1.2.2.2.2.cmml" xref="S3.E1.m1.4.4.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.1.1.2.2.2.2.1.cmml" xref="S3.E1.m1.4.4.1.1.2.2.2.2">superscript</csymbol><ci id="S3.E1.m1.4.4.1.1.2.2.2.2.2.cmml" xref="S3.E1.m1.4.4.1.1.2.2.2.2.2">ğœ‘</ci><times id="S3.E1.m1.4.4.1.1.2.2.2.2.3.cmml" xref="S3.E1.m1.4.4.1.1.2.2.2.2.3"></times></apply></vector></apply><apply id="S3.E1.m1.4.4.1.1.4.cmml" xref="S3.E1.m1.4.4.1.1.4"><plus id="S3.E1.m1.4.4.1.1.4.1.cmml" xref="S3.E1.m1.4.4.1.1.4.1"></plus><apply id="S3.E1.m1.4.4.1.1.4.2.cmml" xref="S3.E1.m1.4.4.1.1.4.2"><ci id="S3.E1.m1.4.4.1.1.4.2.1.cmml" xref="S3.E1.m1.4.4.1.1.4.2.1">â‹…</ci><apply id="S3.E1.m1.4.4.1.1.4.2.2.cmml" xref="S3.E1.m1.4.4.1.1.4.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.1.1.4.2.2.1.cmml" xref="S3.E1.m1.4.4.1.1.4.2.2">superscript</csymbol><ci id="S3.E1.m1.4.4.1.1.4.2.2.2.cmml" xref="S3.E1.m1.4.4.1.1.4.2.2.2">italic-Ïµ</ci><times id="S3.E1.m1.4.4.1.1.4.2.2.3.cmml" xref="S3.E1.m1.4.4.1.1.4.2.2.3"></times></apply><apply id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.4.4.1.1.4.2.3.2"><divide id="S3.E1.m1.2.2.3.cmml" xref="S3.E1.m1.4.4.1.1.4.2.3.2"></divide><apply id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><minus id="S3.E1.m1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.2"></minus><ci id="S3.E1.m1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.3">ğ‘’</ci><apply id="S3.E1.m1.1.1.1.4.cmml" xref="S3.E1.m1.1.1.1.4"><times id="S3.E1.m1.1.1.1.4.1.cmml" xref="S3.E1.m1.1.1.1.4.1"></times><ci id="S3.E1.m1.1.1.1.4.2.cmml" xref="S3.E1.m1.1.1.1.4.2">ğœ‘</ci><ci id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1">ğ‘’</ci></apply></apply><apply id="S3.E1.m1.2.2.2.cmml" xref="S3.E1.m1.2.2.2"><times id="S3.E1.m1.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2"></times><ci id="S3.E1.m1.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.3">italic-Ïµ</ci><ci id="S3.E1.m1.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.1">ğ‘’</ci></apply></apply></apply><apply id="S3.E1.m1.4.4.1.1.4.3.cmml" xref="S3.E1.m1.4.4.1.1.4.3"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.1.1.4.3.1.cmml" xref="S3.E1.m1.4.4.1.1.4.3">superscript</csymbol><ci id="S3.E1.m1.4.4.1.1.4.3.2.cmml" xref="S3.E1.m1.4.4.1.1.4.3.2">ğœ‘</ci><times id="S3.E1.m1.4.4.1.1.4.3.3.cmml" xref="S3.E1.m1.4.4.1.1.4.3.3"></times></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.4c">R_{p}(e,\epsilon^{*},\varphi^{*})=\epsilon^{*}\cdot(\frac{e-\varphi(e)}{\epsilon(e)})+\varphi^{*}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.4" class="ltx_p">Here <math id="S3.SS3.p3.1.m1.1" class="ltx_Math" alttext="\varphi" display="inline"><semantics id="S3.SS3.p3.1.m1.1a"><mi id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml">Ï†</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><ci id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">ğœ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">\varphi</annotation></semantics></math>(Â·) and <math id="S3.SS3.p3.2.m2.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.SS3.p3.2.m2.1a"><mi id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml">Ïµ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b"><ci id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1">italic-Ïµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">\epsilon</annotation></semantics></math>(Â·) represent the channel mean and standard deviation respectively, and <math id="S3.SS3.p3.3.m3.1" class="ltx_Math" alttext="\varphi^{*}" display="inline"><semantics id="S3.SS3.p3.3.m3.1a"><msup id="S3.SS3.p3.3.m3.1.1" xref="S3.SS3.p3.3.m3.1.1.cmml"><mi id="S3.SS3.p3.3.m3.1.1.2" xref="S3.SS3.p3.3.m3.1.1.2.cmml">Ï†</mi><mo id="S3.SS3.p3.3.m3.1.1.3" xref="S3.SS3.p3.3.m3.1.1.3.cmml">âˆ—</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.3.m3.1b"><apply id="S3.SS3.p3.3.m3.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.3.m3.1.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1">superscript</csymbol><ci id="S3.SS3.p3.3.m3.1.1.2.cmml" xref="S3.SS3.p3.3.m3.1.1.2">ğœ‘</ci><times id="S3.SS3.p3.3.m3.1.1.3.cmml" xref="S3.SS3.p3.3.m3.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.3.m3.1c">\varphi^{*}</annotation></semantics></math>, <math id="S3.SS3.p3.4.m4.1" class="ltx_Math" alttext="\epsilon^{*}" display="inline"><semantics id="S3.SS3.p3.4.m4.1a"><msup id="S3.SS3.p3.4.m4.1.1" xref="S3.SS3.p3.4.m4.1.1.cmml"><mi id="S3.SS3.p3.4.m4.1.1.2" xref="S3.SS3.p3.4.m4.1.1.2.cmml">Ïµ</mi><mo id="S3.SS3.p3.4.m4.1.1.3" xref="S3.SS3.p3.4.m4.1.1.3.cmml">âˆ—</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.4.m4.1b"><apply id="S3.SS3.p3.4.m4.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.4.m4.1.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1">superscript</csymbol><ci id="S3.SS3.p3.4.m4.1.1.2.cmml" xref="S3.SS3.p3.4.m4.1.1.2">italic-Ïµ</ci><times id="S3.SS3.p3.4.m4.1.1.3.cmml" xref="S3.SS3.p3.4.m4.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.4.m4.1c">\epsilon^{*}</annotation></semantics></math> represent the linear interpolation results of the channel mean and standard deviation respectively.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para">
<p id="S3.SS3.p4.6" class="ltx_p">For the intermediate feature maps <math id="S3.SS3.p4.1.m1.1" class="ltx_Math" alttext="e" display="inline"><semantics id="S3.SS3.p4.1.m1.1a"><mi id="S3.SS3.p4.1.m1.1.1" xref="S3.SS3.p4.1.m1.1.1.cmml">e</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.1b"><ci id="S3.SS3.p4.1.m1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1">ğ‘’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.1c">e</annotation></semantics></math>, <math id="S3.SS3.p4.2.m2.1" class="ltx_Math" alttext="e^{\prime}" display="inline"><semantics id="S3.SS3.p4.2.m2.1a"><msup id="S3.SS3.p4.2.m2.1.1" xref="S3.SS3.p4.2.m2.1.1.cmml"><mi id="S3.SS3.p4.2.m2.1.1.2" xref="S3.SS3.p4.2.m2.1.1.2.cmml">e</mi><mo id="S3.SS3.p4.2.m2.1.1.3" xref="S3.SS3.p4.2.m2.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.2.m2.1b"><apply id="S3.SS3.p4.2.m2.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.2.m2.1.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1">superscript</csymbol><ci id="S3.SS3.p4.2.m2.1.1.2.cmml" xref="S3.SS3.p4.2.m2.1.1.2">ğ‘’</ci><ci id="S3.SS3.p4.2.m2.1.1.3.cmml" xref="S3.SS3.p4.2.m2.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.2.m2.1c">e^{\prime}</annotation></semantics></math> corresponding to the input image <math id="S3.SS3.p4.3.m3.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS3.p4.3.m3.1a"><mi id="S3.SS3.p4.3.m3.1.1" xref="S3.SS3.p4.3.m3.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.3.m3.1b"><ci id="S3.SS3.p4.3.m3.1.1.cmml" xref="S3.SS3.p4.3.m3.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.3.m3.1c">x</annotation></semantics></math> and the randomly selected image <math id="S3.SS3.p4.4.m4.1" class="ltx_Math" alttext="x^{\prime}" display="inline"><semantics id="S3.SS3.p4.4.m4.1a"><msup id="S3.SS3.p4.4.m4.1.1" xref="S3.SS3.p4.4.m4.1.1.cmml"><mi id="S3.SS3.p4.4.m4.1.1.2" xref="S3.SS3.p4.4.m4.1.1.2.cmml">x</mi><mo id="S3.SS3.p4.4.m4.1.1.3" xref="S3.SS3.p4.4.m4.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.4.m4.1b"><apply id="S3.SS3.p4.4.m4.1.1.cmml" xref="S3.SS3.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.4.m4.1.1.1.cmml" xref="S3.SS3.p4.4.m4.1.1">superscript</csymbol><ci id="S3.SS3.p4.4.m4.1.1.2.cmml" xref="S3.SS3.p4.4.m4.1.1.2">ğ‘¥</ci><ci id="S3.SS3.p4.4.m4.1.1.3.cmml" xref="S3.SS3.p4.4.m4.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.4.m4.1c">x^{\prime}</annotation></semantics></math>, we replace the spatial configuration of <math id="S3.SS3.p4.5.m5.1" class="ltx_Math" alttext="e" display="inline"><semantics id="S3.SS3.p4.5.m5.1a"><mi id="S3.SS3.p4.5.m5.1.1" xref="S3.SS3.p4.5.m5.1.1.cmml">e</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.5.m5.1b"><ci id="S3.SS3.p4.5.m5.1.1.cmml" xref="S3.SS3.p4.5.m5.1.1">ğ‘’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.5.m5.1c">e</annotation></semantics></math> with the channel mean and standard deviation of <math id="S3.SS3.p4.6.m6.1" class="ltx_Math" alttext="e^{\prime}" display="inline"><semantics id="S3.SS3.p4.6.m6.1a"><msup id="S3.SS3.p4.6.m6.1.1" xref="S3.SS3.p4.6.m6.1.1.cmml"><mi id="S3.SS3.p4.6.m6.1.1.2" xref="S3.SS3.p4.6.m6.1.1.2.cmml">e</mi><mo id="S3.SS3.p4.6.m6.1.1.3" xref="S3.SS3.p4.6.m6.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.6.m6.1b"><apply id="S3.SS3.p4.6.m6.1.1.cmml" xref="S3.SS3.p4.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.6.m6.1.1.1.cmml" xref="S3.SS3.p4.6.m6.1.1">superscript</csymbol><ci id="S3.SS3.p4.6.m6.1.1.2.cmml" xref="S3.SS3.p4.6.m6.1.1.2">ğ‘’</ci><ci id="S3.SS3.p4.6.m6.1.1.3.cmml" xref="S3.SS3.p4.6.m6.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.6.m6.1c">e^{\prime}</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>,</p>
</div>
<div id="S3.SS3.p5" class="ltx_para">
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.7" class="ltx_Math" alttext="R_{s}(e^{\prime},\epsilon,\varphi)=\epsilon(e)\cdot(\frac{e^{\prime}-\varphi(e^{\prime})}{\epsilon(e^{\prime})})+\varphi(e)." display="block"><semantics id="S3.E2.m1.7a"><mrow id="S3.E2.m1.7.7.1" xref="S3.E2.m1.7.7.1.1.cmml"><mrow id="S3.E2.m1.7.7.1.1" xref="S3.E2.m1.7.7.1.1.cmml"><mrow id="S3.E2.m1.7.7.1.1.1" xref="S3.E2.m1.7.7.1.1.1.cmml"><msub id="S3.E2.m1.7.7.1.1.1.3" xref="S3.E2.m1.7.7.1.1.1.3.cmml"><mi id="S3.E2.m1.7.7.1.1.1.3.2" xref="S3.E2.m1.7.7.1.1.1.3.2.cmml">R</mi><mi id="S3.E2.m1.7.7.1.1.1.3.3" xref="S3.E2.m1.7.7.1.1.1.3.3.cmml">s</mi></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.7.7.1.1.1.2" xref="S3.E2.m1.7.7.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E2.m1.7.7.1.1.1.1.1" xref="S3.E2.m1.7.7.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E2.m1.7.7.1.1.1.1.1.2" xref="S3.E2.m1.7.7.1.1.1.1.2.cmml">(</mo><msup id="S3.E2.m1.7.7.1.1.1.1.1.1" xref="S3.E2.m1.7.7.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.7.7.1.1.1.1.1.1.2" xref="S3.E2.m1.7.7.1.1.1.1.1.1.2.cmml">e</mi><mo id="S3.E2.m1.7.7.1.1.1.1.1.1.3" xref="S3.E2.m1.7.7.1.1.1.1.1.1.3.cmml">â€²</mo></msup><mo id="S3.E2.m1.7.7.1.1.1.1.1.3" xref="S3.E2.m1.7.7.1.1.1.1.2.cmml">,</mo><mi id="S3.E2.m1.3.3" xref="S3.E2.m1.3.3.cmml">Ïµ</mi><mo id="S3.E2.m1.7.7.1.1.1.1.1.4" xref="S3.E2.m1.7.7.1.1.1.1.2.cmml">,</mo><mi id="S3.E2.m1.4.4" xref="S3.E2.m1.4.4.cmml">Ï†</mi><mo stretchy="false" id="S3.E2.m1.7.7.1.1.1.1.1.5" xref="S3.E2.m1.7.7.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.7.7.1.1.2" xref="S3.E2.m1.7.7.1.1.2.cmml">=</mo><mrow id="S3.E2.m1.7.7.1.1.3" xref="S3.E2.m1.7.7.1.1.3.cmml"><mrow id="S3.E2.m1.7.7.1.1.3.2" xref="S3.E2.m1.7.7.1.1.3.2.cmml"><mrow id="S3.E2.m1.7.7.1.1.3.2.2" xref="S3.E2.m1.7.7.1.1.3.2.2.cmml"><mi id="S3.E2.m1.7.7.1.1.3.2.2.2" xref="S3.E2.m1.7.7.1.1.3.2.2.2.cmml">Ïµ</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.7.7.1.1.3.2.2.1" xref="S3.E2.m1.7.7.1.1.3.2.2.1.cmml">â€‹</mo><mrow id="S3.E2.m1.7.7.1.1.3.2.2.3.2" xref="S3.E2.m1.7.7.1.1.3.2.2.cmml"><mo stretchy="false" id="S3.E2.m1.7.7.1.1.3.2.2.3.2.1" xref="S3.E2.m1.7.7.1.1.3.2.2.cmml">(</mo><mi id="S3.E2.m1.5.5" xref="S3.E2.m1.5.5.cmml">e</mi><mo rspace="0.055em" stretchy="false" id="S3.E2.m1.7.7.1.1.3.2.2.3.2.2" xref="S3.E2.m1.7.7.1.1.3.2.2.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="S3.E2.m1.7.7.1.1.3.2.1" xref="S3.E2.m1.7.7.1.1.3.2.1.cmml">â‹…</mo><mrow id="S3.E2.m1.7.7.1.1.3.2.3.2" xref="S3.E2.m1.2.2.cmml"><mo stretchy="false" id="S3.E2.m1.7.7.1.1.3.2.3.2.1" xref="S3.E2.m1.2.2.cmml">(</mo><mfrac id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml"><mrow id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.cmml"><msup id="S3.E2.m1.1.1.1.3" xref="S3.E2.m1.1.1.1.3.cmml"><mi id="S3.E2.m1.1.1.1.3.2" xref="S3.E2.m1.1.1.1.3.2.cmml">e</mi><mo id="S3.E2.m1.1.1.1.3.3" xref="S3.E2.m1.1.1.1.3.3.cmml">â€²</mo></msup><mo id="S3.E2.m1.1.1.1.2" xref="S3.E2.m1.1.1.1.2.cmml">âˆ’</mo><mrow id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.3.cmml">Ï†</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml">(</mo><msup id="S3.E2.m1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.1.2.cmml">e</mi><mo id="S3.E2.m1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.1.3.cmml">â€²</mo></msup><mo stretchy="false" id="S3.E2.m1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mrow id="S3.E2.m1.2.2.2" xref="S3.E2.m1.2.2.2.cmml"><mi id="S3.E2.m1.2.2.2.3" xref="S3.E2.m1.2.2.2.3.cmml">Ïµ</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.2" xref="S3.E2.m1.2.2.2.2.cmml">â€‹</mo><mrow id="S3.E2.m1.2.2.2.1.1" xref="S3.E2.m1.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.2.2.2.1.1.2" xref="S3.E2.m1.2.2.2.1.1.1.cmml">(</mo><msup id="S3.E2.m1.2.2.2.1.1.1" xref="S3.E2.m1.2.2.2.1.1.1.cmml"><mi id="S3.E2.m1.2.2.2.1.1.1.2" xref="S3.E2.m1.2.2.2.1.1.1.2.cmml">e</mi><mo id="S3.E2.m1.2.2.2.1.1.1.3" xref="S3.E2.m1.2.2.2.1.1.1.3.cmml">â€²</mo></msup><mo stretchy="false" id="S3.E2.m1.2.2.2.1.1.3" xref="S3.E2.m1.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mfrac><mo stretchy="false" id="S3.E2.m1.7.7.1.1.3.2.3.2.2" xref="S3.E2.m1.2.2.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.7.7.1.1.3.1" xref="S3.E2.m1.7.7.1.1.3.1.cmml">+</mo><mrow id="S3.E2.m1.7.7.1.1.3.3" xref="S3.E2.m1.7.7.1.1.3.3.cmml"><mi id="S3.E2.m1.7.7.1.1.3.3.2" xref="S3.E2.m1.7.7.1.1.3.3.2.cmml">Ï†</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.7.7.1.1.3.3.1" xref="S3.E2.m1.7.7.1.1.3.3.1.cmml">â€‹</mo><mrow id="S3.E2.m1.7.7.1.1.3.3.3.2" xref="S3.E2.m1.7.7.1.1.3.3.cmml"><mo stretchy="false" id="S3.E2.m1.7.7.1.1.3.3.3.2.1" xref="S3.E2.m1.7.7.1.1.3.3.cmml">(</mo><mi id="S3.E2.m1.6.6" xref="S3.E2.m1.6.6.cmml">e</mi><mo stretchy="false" id="S3.E2.m1.7.7.1.1.3.3.3.2.2" xref="S3.E2.m1.7.7.1.1.3.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo lspace="0em" id="S3.E2.m1.7.7.1.2" xref="S3.E2.m1.7.7.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.7b"><apply id="S3.E2.m1.7.7.1.1.cmml" xref="S3.E2.m1.7.7.1"><eq id="S3.E2.m1.7.7.1.1.2.cmml" xref="S3.E2.m1.7.7.1.1.2"></eq><apply id="S3.E2.m1.7.7.1.1.1.cmml" xref="S3.E2.m1.7.7.1.1.1"><times id="S3.E2.m1.7.7.1.1.1.2.cmml" xref="S3.E2.m1.7.7.1.1.1.2"></times><apply id="S3.E2.m1.7.7.1.1.1.3.cmml" xref="S3.E2.m1.7.7.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.1.1.1.3.1.cmml" xref="S3.E2.m1.7.7.1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.7.7.1.1.1.3.2.cmml" xref="S3.E2.m1.7.7.1.1.1.3.2">ğ‘…</ci><ci id="S3.E2.m1.7.7.1.1.1.3.3.cmml" xref="S3.E2.m1.7.7.1.1.1.3.3">ğ‘ </ci></apply><vector id="S3.E2.m1.7.7.1.1.1.1.2.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1"><apply id="S3.E2.m1.7.7.1.1.1.1.1.1.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E2.m1.7.7.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1.1.2">ğ‘’</ci><ci id="S3.E2.m1.7.7.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.7.7.1.1.1.1.1.1.3">â€²</ci></apply><ci id="S3.E2.m1.3.3.cmml" xref="S3.E2.m1.3.3">italic-Ïµ</ci><ci id="S3.E2.m1.4.4.cmml" xref="S3.E2.m1.4.4">ğœ‘</ci></vector></apply><apply id="S3.E2.m1.7.7.1.1.3.cmml" xref="S3.E2.m1.7.7.1.1.3"><plus id="S3.E2.m1.7.7.1.1.3.1.cmml" xref="S3.E2.m1.7.7.1.1.3.1"></plus><apply id="S3.E2.m1.7.7.1.1.3.2.cmml" xref="S3.E2.m1.7.7.1.1.3.2"><ci id="S3.E2.m1.7.7.1.1.3.2.1.cmml" xref="S3.E2.m1.7.7.1.1.3.2.1">â‹…</ci><apply id="S3.E2.m1.7.7.1.1.3.2.2.cmml" xref="S3.E2.m1.7.7.1.1.3.2.2"><times id="S3.E2.m1.7.7.1.1.3.2.2.1.cmml" xref="S3.E2.m1.7.7.1.1.3.2.2.1"></times><ci id="S3.E2.m1.7.7.1.1.3.2.2.2.cmml" xref="S3.E2.m1.7.7.1.1.3.2.2.2">italic-Ïµ</ci><ci id="S3.E2.m1.5.5.cmml" xref="S3.E2.m1.5.5">ğ‘’</ci></apply><apply id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.7.7.1.1.3.2.3.2"><divide id="S3.E2.m1.2.2.3.cmml" xref="S3.E2.m1.7.7.1.1.3.2.3.2"></divide><apply id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"><minus id="S3.E2.m1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.2"></minus><apply id="S3.E2.m1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.3">superscript</csymbol><ci id="S3.E2.m1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.3.2">ğ‘’</ci><ci id="S3.E2.m1.1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.3.3">â€²</ci></apply><apply id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1"><times id="S3.E2.m1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.2"></times><ci id="S3.E2.m1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.3">ğœ‘</ci><apply id="S3.E2.m1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.2">ğ‘’</ci><ci id="S3.E2.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.3">â€²</ci></apply></apply></apply><apply id="S3.E2.m1.2.2.2.cmml" xref="S3.E2.m1.2.2.2"><times id="S3.E2.m1.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2"></times><ci id="S3.E2.m1.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.3">italic-Ïµ</ci><apply id="S3.E2.m1.2.2.2.1.1.1.cmml" xref="S3.E2.m1.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.1.1.1.1.cmml" xref="S3.E2.m1.2.2.2.1.1">superscript</csymbol><ci id="S3.E2.m1.2.2.2.1.1.1.2.cmml" xref="S3.E2.m1.2.2.2.1.1.1.2">ğ‘’</ci><ci id="S3.E2.m1.2.2.2.1.1.1.3.cmml" xref="S3.E2.m1.2.2.2.1.1.1.3">â€²</ci></apply></apply></apply></apply><apply id="S3.E2.m1.7.7.1.1.3.3.cmml" xref="S3.E2.m1.7.7.1.1.3.3"><times id="S3.E2.m1.7.7.1.1.3.3.1.cmml" xref="S3.E2.m1.7.7.1.1.3.3.1"></times><ci id="S3.E2.m1.7.7.1.1.3.3.2.cmml" xref="S3.E2.m1.7.7.1.1.3.3.2">ğœ‘</ci><ci id="S3.E2.m1.6.6.cmml" xref="S3.E2.m1.6.6">ğ‘’</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.7c">R_{s}(e^{\prime},\epsilon,\varphi)=\epsilon(e)\cdot(\frac{e^{\prime}-\varphi(e^{\prime})}{\epsilon(e^{\prime})})+\varphi(e).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS3.p6" class="ltx_para">
<p id="S3.SS3.p6.7" class="ltx_p">The <math id="S3.SS3.p6.1.m1.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S3.SS3.p6.1.m1.1a"><mi id="S3.SS3.p6.1.m1.1.1" xref="S3.SS3.p6.1.m1.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.1.m1.1b"><ci id="S3.SS3.p6.1.m1.1.1.cmml" xref="S3.SS3.p6.1.m1.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.1.m1.1c">R</annotation></semantics></math><sub id="S3.SS3.p6.7.1" class="ltx_sub"><span id="S3.SS3.p6.7.1.1" class="ltx_text ltx_font_italic">p</span></sub> (e, <math id="S3.SS3.p6.3.m3.1" class="ltx_Math" alttext="\epsilon^{*}" display="inline"><semantics id="S3.SS3.p6.3.m3.1a"><msup id="S3.SS3.p6.3.m3.1.1" xref="S3.SS3.p6.3.m3.1.1.cmml"><mi id="S3.SS3.p6.3.m3.1.1.2" xref="S3.SS3.p6.3.m3.1.1.2.cmml">Ïµ</mi><mo id="S3.SS3.p6.3.m3.1.1.3" xref="S3.SS3.p6.3.m3.1.1.3.cmml">âˆ—</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.3.m3.1b"><apply id="S3.SS3.p6.3.m3.1.1.cmml" xref="S3.SS3.p6.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p6.3.m3.1.1.1.cmml" xref="S3.SS3.p6.3.m3.1.1">superscript</csymbol><ci id="S3.SS3.p6.3.m3.1.1.2.cmml" xref="S3.SS3.p6.3.m3.1.1.2">italic-Ïµ</ci><times id="S3.SS3.p6.3.m3.1.1.3.cmml" xref="S3.SS3.p6.3.m3.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.3.m3.1c">\epsilon^{*}</annotation></semantics></math>, <math id="S3.SS3.p6.4.m4.1" class="ltx_Math" alttext="\varphi^{*}" display="inline"><semantics id="S3.SS3.p6.4.m4.1a"><msup id="S3.SS3.p6.4.m4.1.1" xref="S3.SS3.p6.4.m4.1.1.cmml"><mi id="S3.SS3.p6.4.m4.1.1.2" xref="S3.SS3.p6.4.m4.1.1.2.cmml">Ï†</mi><mo id="S3.SS3.p6.4.m4.1.1.3" xref="S3.SS3.p6.4.m4.1.1.3.cmml">âˆ—</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.4.m4.1b"><apply id="S3.SS3.p6.4.m4.1.1.cmml" xref="S3.SS3.p6.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p6.4.m4.1.1.1.cmml" xref="S3.SS3.p6.4.m4.1.1">superscript</csymbol><ci id="S3.SS3.p6.4.m4.1.1.2.cmml" xref="S3.SS3.p6.4.m4.1.1.2">ğœ‘</ci><times id="S3.SS3.p6.4.m4.1.1.3.cmml" xref="S3.SS3.p6.4.m4.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.4.m4.1c">\varphi^{*}</annotation></semantics></math>) is fed into the personalized feature extraction network, and the feature extractor F<sub id="S3.SS3.p6.7.2" class="ltx_sub"><span id="S3.SS3.p6.7.2.1" class="ltx_text ltx_font_italic">f</span></sub> and personalized feature extractor F<sub id="S3.SS3.p6.7.3" class="ltx_sub"><span id="S3.SS3.p6.7.3.1" class="ltx_text ltx_font_italic">p</span></sub> are further optimized through the loss function L<sub id="S3.SS3.p6.7.4" class="ltx_sub"><span id="S3.SS3.p6.7.4.1" class="ltx_text ltx_font_italic">p</span></sub>:</p>
</div>
<div id="S3.SS3.p7" class="ltx_para">
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.2" class="ltx_Math" alttext="L_{p}=-\sum_{n=1}^{N}y_{n}logF_{p}[R_{p}(e,\epsilon^{*},\varphi^{*})]_{n}." display="block"><semantics id="S3.E3.m1.2a"><mrow id="S3.E3.m1.2.2.1" xref="S3.E3.m1.2.2.1.1.cmml"><mrow id="S3.E3.m1.2.2.1.1" xref="S3.E3.m1.2.2.1.1.cmml"><msub id="S3.E3.m1.2.2.1.1.3" xref="S3.E3.m1.2.2.1.1.3.cmml"><mi id="S3.E3.m1.2.2.1.1.3.2" xref="S3.E3.m1.2.2.1.1.3.2.cmml">L</mi><mi id="S3.E3.m1.2.2.1.1.3.3" xref="S3.E3.m1.2.2.1.1.3.3.cmml">p</mi></msub><mo id="S3.E3.m1.2.2.1.1.2" xref="S3.E3.m1.2.2.1.1.2.cmml">=</mo><mrow id="S3.E3.m1.2.2.1.1.1" xref="S3.E3.m1.2.2.1.1.1.cmml"><mo id="S3.E3.m1.2.2.1.1.1a" xref="S3.E3.m1.2.2.1.1.1.cmml">âˆ’</mo><mrow id="S3.E3.m1.2.2.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.cmml"><munderover id="S3.E3.m1.2.2.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.2.cmml"><mo movablelimits="false" id="S3.E3.m1.2.2.1.1.1.1.2.2.2" xref="S3.E3.m1.2.2.1.1.1.1.2.2.2.cmml">âˆ‘</mo><mrow id="S3.E3.m1.2.2.1.1.1.1.2.2.3" xref="S3.E3.m1.2.2.1.1.1.1.2.2.3.cmml"><mi id="S3.E3.m1.2.2.1.1.1.1.2.2.3.2" xref="S3.E3.m1.2.2.1.1.1.1.2.2.3.2.cmml">n</mi><mo id="S3.E3.m1.2.2.1.1.1.1.2.2.3.1" xref="S3.E3.m1.2.2.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E3.m1.2.2.1.1.1.1.2.2.3.3" xref="S3.E3.m1.2.2.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E3.m1.2.2.1.1.1.1.2.3" xref="S3.E3.m1.2.2.1.1.1.1.2.3.cmml">N</mi></munderover><mrow id="S3.E3.m1.2.2.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.cmml"><msub id="S3.E3.m1.2.2.1.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.2.2.1.1.1.1.1.3.2" xref="S3.E3.m1.2.2.1.1.1.1.1.3.2.cmml">y</mi><mi id="S3.E3.m1.2.2.1.1.1.1.1.3.3" xref="S3.E3.m1.2.2.1.1.1.1.1.3.3.cmml">n</mi></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.1.1.1.4" xref="S3.E3.m1.2.2.1.1.1.1.1.4.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.2a" xref="S3.E3.m1.2.2.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.1.1.1.5" xref="S3.E3.m1.2.2.1.1.1.1.1.5.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.2b" xref="S3.E3.m1.2.2.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.1.1.1.6" xref="S3.E3.m1.2.2.1.1.1.1.1.6.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.2c" xref="S3.E3.m1.2.2.1.1.1.1.1.2.cmml">â€‹</mo><msub id="S3.E3.m1.2.2.1.1.1.1.1.7" xref="S3.E3.m1.2.2.1.1.1.1.1.7.cmml"><mi id="S3.E3.m1.2.2.1.1.1.1.1.7.2" xref="S3.E3.m1.2.2.1.1.1.1.1.7.2.cmml">F</mi><mi id="S3.E3.m1.2.2.1.1.1.1.1.7.3" xref="S3.E3.m1.2.2.1.1.1.1.1.7.3.cmml">p</mi></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.2d" xref="S3.E3.m1.2.2.1.1.1.1.1.2.cmml">â€‹</mo><msub id="S3.E3.m1.2.2.1.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.1.cmml"><mrow id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.2.1.cmml">[</mo><mrow id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.4" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.4.cmml"><mi id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.4.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.4.2.cmml">R</mi><mi id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.4.3" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.4.3.cmml">p</mi></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml">â€‹</mo><mrow id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.3" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.cmml">(</mo><mi id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">e</mi><mo id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.4" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.cmml">,</mo><msup id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">Ïµ</mi><mo id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">âˆ—</mo></msup><mo id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.5" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.cmml">,</mo><msup id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.cmml"><mi id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml">Ï†</mi><mo id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.3" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml">âˆ—</mo></msup><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.6" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.2.1.cmml">]</mo></mrow><mi id="S3.E3.m1.2.2.1.1.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.1.1.3.cmml">n</mi></msub></mrow></mrow></mrow></mrow><mo lspace="0em" id="S3.E3.m1.2.2.1.2" xref="S3.E3.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.2b"><apply id="S3.E3.m1.2.2.1.1.cmml" xref="S3.E3.m1.2.2.1"><eq id="S3.E3.m1.2.2.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.2"></eq><apply id="S3.E3.m1.2.2.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.3.1.cmml" xref="S3.E3.m1.2.2.1.1.3">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.3.2.cmml" xref="S3.E3.m1.2.2.1.1.3.2">ğ¿</ci><ci id="S3.E3.m1.2.2.1.1.3.3.cmml" xref="S3.E3.m1.2.2.1.1.3.3">ğ‘</ci></apply><apply id="S3.E3.m1.2.2.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1"><minus id="S3.E3.m1.2.2.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1"></minus><apply id="S3.E3.m1.2.2.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1"><apply id="S3.E3.m1.2.2.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.1.2.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.2">superscript</csymbol><apply id="S3.E3.m1.2.2.1.1.1.1.2.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.1.2.2.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.2">subscript</csymbol><sum id="S3.E3.m1.2.2.1.1.1.1.2.2.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.2.2.2"></sum><apply id="S3.E3.m1.2.2.1.1.1.1.2.2.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.2.2.3"><eq id="S3.E3.m1.2.2.1.1.1.1.2.2.3.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.2.2.3.1"></eq><ci id="S3.E3.m1.2.2.1.1.1.1.2.2.3.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.2.2.3.2">ğ‘›</ci><cn type="integer" id="S3.E3.m1.2.2.1.1.1.1.2.2.3.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E3.m1.2.2.1.1.1.1.2.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.2.3">ğ‘</ci></apply><apply id="S3.E3.m1.2.2.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1"><times id="S3.E3.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.2"></times><apply id="S3.E3.m1.2.2.1.1.1.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.3.2">ğ‘¦</ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.3.3">ğ‘›</ci></apply><ci id="S3.E3.m1.2.2.1.1.1.1.1.4.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.4">ğ‘™</ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.5.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.5">ğ‘œ</ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.6.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.6">ğ‘”</ci><apply id="S3.E3.m1.2.2.1.1.1.1.1.7.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.7"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.1.1.7.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.7">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.1.1.1.7.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.7.2">ğ¹</ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.7.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.7.3">ğ‘</ci></apply><apply id="S3.E3.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E3.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1"><times id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.3"></times><apply id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.4.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.4.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.4">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.4.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.4.2">ğ‘…</ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.4.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.4.3">ğ‘</ci></apply><vector id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.2"><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">ğ‘’</ci><apply id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2">italic-Ïµ</ci><times id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3"></times></apply><apply id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2">superscript</csymbol><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.2">ğœ‘</ci><times id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.3"></times></apply></vector></apply></apply><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.3">ğ‘›</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.2c">L_{p}=-\sum_{n=1}^{N}y_{n}logF_{p}[R_{p}(e,\epsilon^{*},\varphi^{*})]_{n}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS3.p8" class="ltx_para">
<p id="S3.SS3.p8.7" class="ltx_p">By reorganizing the channel mean and standard deviation during the training process, the personalized forgery representation learning pays more attention to the personalized representation of the client training model when making decisions. Where <math id="S3.SS3.p8.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS3.p8.1.m1.1a"><mi id="S3.SS3.p8.1.m1.1.1" xref="S3.SS3.p8.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p8.1.m1.1b"><ci id="S3.SS3.p8.1.m1.1.1.cmml" xref="S3.SS3.p8.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p8.1.m1.1c">N</annotation></semantics></math> is the number of class categories, <math id="S3.SS3.p8.2.m2.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S3.SS3.p8.2.m2.1a"><mi id="S3.SS3.p8.2.m2.1.1" xref="S3.SS3.p8.2.m2.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p8.2.m2.1b"><ci id="S3.SS3.p8.2.m2.1.1.cmml" xref="S3.SS3.p8.2.m2.1.1">ğ‘¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p8.2.m2.1c">y</annotation></semantics></math><math id="S3.SS3.p8.3.m3.1" class="ltx_Math" alttext="\in" display="inline"><semantics id="S3.SS3.p8.3.m3.1a"><mo id="S3.SS3.p8.3.m3.1.1" xref="S3.SS3.p8.3.m3.1.1.cmml">âˆˆ</mo><annotation-xml encoding="MathML-Content" id="S3.SS3.p8.3.m3.1b"><in id="S3.SS3.p8.3.m3.1.1.cmml" xref="S3.SS3.p8.3.m3.1.1"></in></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p8.3.m3.1c">\in</annotation></semantics></math>{0,1}<sup id="S3.SS3.p8.7.1" class="ltx_sup"><span id="S3.SS3.p8.7.1.1" class="ltx_text ltx_font_italic">N</span></sup> is the one-hot label of input <math id="S3.SS3.p8.5.m5.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS3.p8.5.m5.1a"><mi id="S3.SS3.p8.5.m5.1.1" xref="S3.SS3.p8.5.m5.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p8.5.m5.1b"><ci id="S3.SS3.p8.5.m5.1.1.cmml" xref="S3.SS3.p8.5.m5.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p8.5.m5.1c">x</annotation></semantics></math>.
The network is trained to learn shared features by minimizing the loss function <math id="S3.SS3.p8.6.m6.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.SS3.p8.6.m6.1a"><mi id="S3.SS3.p8.6.m6.1.1" xref="S3.SS3.p8.6.m6.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p8.6.m6.1b"><ci id="S3.SS3.p8.6.m6.1.1.cmml" xref="S3.SS3.p8.6.m6.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p8.6.m6.1c">L</annotation></semantics></math><sub id="S3.SS3.p8.7.2" class="ltx_sub"><span id="S3.SS3.p8.7.2.1" class="ltx_text ltx_font_italic">s</span></sub>:</p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.3" class="ltx_Math" alttext="L_{s}=-\sum_{n=1}^{N}y_{n}logF_{s}[R_{s}(e^{\prime},\epsilon,\varphi)]_{n}." display="block"><semantics id="S3.E4.m1.3a"><mrow id="S3.E4.m1.3.3.1" xref="S3.E4.m1.3.3.1.1.cmml"><mrow id="S3.E4.m1.3.3.1.1" xref="S3.E4.m1.3.3.1.1.cmml"><msub id="S3.E4.m1.3.3.1.1.3" xref="S3.E4.m1.3.3.1.1.3.cmml"><mi id="S3.E4.m1.3.3.1.1.3.2" xref="S3.E4.m1.3.3.1.1.3.2.cmml">L</mi><mi id="S3.E4.m1.3.3.1.1.3.3" xref="S3.E4.m1.3.3.1.1.3.3.cmml">s</mi></msub><mo id="S3.E4.m1.3.3.1.1.2" xref="S3.E4.m1.3.3.1.1.2.cmml">=</mo><mrow id="S3.E4.m1.3.3.1.1.1" xref="S3.E4.m1.3.3.1.1.1.cmml"><mo id="S3.E4.m1.3.3.1.1.1a" xref="S3.E4.m1.3.3.1.1.1.cmml">âˆ’</mo><mrow id="S3.E4.m1.3.3.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.cmml"><munderover id="S3.E4.m1.3.3.1.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.1.2.cmml"><mo movablelimits="false" id="S3.E4.m1.3.3.1.1.1.1.2.2.2" xref="S3.E4.m1.3.3.1.1.1.1.2.2.2.cmml">âˆ‘</mo><mrow id="S3.E4.m1.3.3.1.1.1.1.2.2.3" xref="S3.E4.m1.3.3.1.1.1.1.2.2.3.cmml"><mi id="S3.E4.m1.3.3.1.1.1.1.2.2.3.2" xref="S3.E4.m1.3.3.1.1.1.1.2.2.3.2.cmml">n</mi><mo id="S3.E4.m1.3.3.1.1.1.1.2.2.3.1" xref="S3.E4.m1.3.3.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E4.m1.3.3.1.1.1.1.2.2.3.3" xref="S3.E4.m1.3.3.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E4.m1.3.3.1.1.1.1.2.3" xref="S3.E4.m1.3.3.1.1.1.1.2.3.cmml">N</mi></munderover><mrow id="S3.E4.m1.3.3.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.cmml"><msub id="S3.E4.m1.3.3.1.1.1.1.1.3" xref="S3.E4.m1.3.3.1.1.1.1.1.3.cmml"><mi id="S3.E4.m1.3.3.1.1.1.1.1.3.2" xref="S3.E4.m1.3.3.1.1.1.1.1.3.2.cmml">y</mi><mi id="S3.E4.m1.3.3.1.1.1.1.1.3.3" xref="S3.E4.m1.3.3.1.1.1.1.1.3.3.cmml">n</mi></msub><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E4.m1.3.3.1.1.1.1.1.4" xref="S3.E4.m1.3.3.1.1.1.1.1.4.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.1.1.1.2a" xref="S3.E4.m1.3.3.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E4.m1.3.3.1.1.1.1.1.5" xref="S3.E4.m1.3.3.1.1.1.1.1.5.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.1.1.1.2b" xref="S3.E4.m1.3.3.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E4.m1.3.3.1.1.1.1.1.6" xref="S3.E4.m1.3.3.1.1.1.1.1.6.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.1.1.1.2c" xref="S3.E4.m1.3.3.1.1.1.1.1.2.cmml">â€‹</mo><msub id="S3.E4.m1.3.3.1.1.1.1.1.7" xref="S3.E4.m1.3.3.1.1.1.1.1.7.cmml"><mi id="S3.E4.m1.3.3.1.1.1.1.1.7.2" xref="S3.E4.m1.3.3.1.1.1.1.1.7.2.cmml">F</mi><mi id="S3.E4.m1.3.3.1.1.1.1.1.7.3" xref="S3.E4.m1.3.3.1.1.1.1.1.7.3.cmml">s</mi></msub><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.1.1.1.2d" xref="S3.E4.m1.3.3.1.1.1.1.1.2.cmml">â€‹</mo><msub id="S3.E4.m1.3.3.1.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.1.cmml"><mrow id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.2.1.cmml">[</mo><mrow id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.2.cmml">R</mi><mi id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.3.cmml">s</mi></msub><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml">(</mo><msup id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">e</mi><mo id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">â€²</mo></msup><mo id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml">Ïµ</mi><mo id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.4" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S3.E4.m1.2.2" xref="S3.E4.m1.2.2.cmml">Ï†</mi><mo stretchy="false" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.5" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.2.1.cmml">]</mo></mrow><mi id="S3.E4.m1.3.3.1.1.1.1.1.1.3" xref="S3.E4.m1.3.3.1.1.1.1.1.1.3.cmml">n</mi></msub></mrow></mrow></mrow></mrow><mo lspace="0em" id="S3.E4.m1.3.3.1.2" xref="S3.E4.m1.3.3.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.3b"><apply id="S3.E4.m1.3.3.1.1.cmml" xref="S3.E4.m1.3.3.1"><eq id="S3.E4.m1.3.3.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.2"></eq><apply id="S3.E4.m1.3.3.1.1.3.cmml" xref="S3.E4.m1.3.3.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.3.1.cmml" xref="S3.E4.m1.3.3.1.1.3">subscript</csymbol><ci id="S3.E4.m1.3.3.1.1.3.2.cmml" xref="S3.E4.m1.3.3.1.1.3.2">ğ¿</ci><ci id="S3.E4.m1.3.3.1.1.3.3.cmml" xref="S3.E4.m1.3.3.1.1.3.3">ğ‘ </ci></apply><apply id="S3.E4.m1.3.3.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1"><minus id="S3.E4.m1.3.3.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1"></minus><apply id="S3.E4.m1.3.3.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1"><apply id="S3.E4.m1.3.3.1.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.2.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.2">superscript</csymbol><apply id="S3.E4.m1.3.3.1.1.1.1.2.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.2.2.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.2">subscript</csymbol><sum id="S3.E4.m1.3.3.1.1.1.1.2.2.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.2.2.2"></sum><apply id="S3.E4.m1.3.3.1.1.1.1.2.2.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.2.2.3"><eq id="S3.E4.m1.3.3.1.1.1.1.2.2.3.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.2.2.3.1"></eq><ci id="S3.E4.m1.3.3.1.1.1.1.2.2.3.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.2.2.3.2">ğ‘›</ci><cn type="integer" id="S3.E4.m1.3.3.1.1.1.1.2.2.3.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E4.m1.3.3.1.1.1.1.2.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.2.3">ğ‘</ci></apply><apply id="S3.E4.m1.3.3.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1"><times id="S3.E4.m1.3.3.1.1.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.2"></times><apply id="S3.E4.m1.3.3.1.1.1.1.1.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E4.m1.3.3.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.3.2">ğ‘¦</ci><ci id="S3.E4.m1.3.3.1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.3.3">ğ‘›</ci></apply><ci id="S3.E4.m1.3.3.1.1.1.1.1.4.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.4">ğ‘™</ci><ci id="S3.E4.m1.3.3.1.1.1.1.1.5.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.5">ğ‘œ</ci><ci id="S3.E4.m1.3.3.1.1.1.1.1.6.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.6">ğ‘”</ci><apply id="S3.E4.m1.3.3.1.1.1.1.1.7.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.7"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.1.7.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.7">subscript</csymbol><ci id="S3.E4.m1.3.3.1.1.1.1.1.7.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.7.2">ğ¹</ci><ci id="S3.E4.m1.3.3.1.1.1.1.1.7.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.7.3">ğ‘ </ci></apply><apply id="S3.E4.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E4.m1.3.3.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1"><times id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2"></times><apply id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.2">ğ‘…</ci><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.3.3">ğ‘ </ci></apply><vector id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1"><apply id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2">ğ‘’</ci><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.3">â€²</ci></apply><ci id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1">italic-Ïµ</ci><ci id="S3.E4.m1.2.2.cmml" xref="S3.E4.m1.2.2">ğœ‘</ci></vector></apply></apply><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.3">ğ‘›</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.3c">L_{s}=-\sum_{n=1}^{N}y_{n}logF_{s}[R_{s}(e^{\prime},\epsilon,\varphi)]_{n}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS3.p9" class="ltx_para">
<p id="S3.SS3.p9.3" class="ltx_p">In order to cooperate with personalized federated learning for information exchange to improve model generalization ability, we propose to use the shared feature extractor F<sub id="S3.SS3.p9.3.1" class="ltx_sub"><span id="S3.SS3.p9.3.1.1" class="ltx_text ltx_font_italic">s</span></sub> for adversarial learning. The feature extractor is trained with adversarial learning by minimizing the adversarial loss <math id="S3.SS3.p9.2.m2.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.SS3.p9.2.m2.1a"><mi id="S3.SS3.p9.2.m2.1.1" xref="S3.SS3.p9.2.m2.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p9.2.m2.1b"><ci id="S3.SS3.p9.2.m2.1.1.cmml" xref="S3.SS3.p9.2.m2.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p9.2.m2.1c">L</annotation></semantics></math><sub id="S3.SS3.p9.3.2" class="ltx_sub"><span id="S3.SS3.p9.3.2.1" class="ltx_text ltx_font_italic">adv</span></sub> calculated by the cross-entropy between the shared feature prediction and the uniform distribution.</p>
</div>
<div id="S3.SS3.p10" class="ltx_para">
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.3" class="ltx_Math" alttext="L_{adv}=-\sum_{n=1}^{N}\frac{1}{N}logF_{s}[R_{s}(e^{\prime},\epsilon,\varphi)]_{n}," display="block"><semantics id="S3.E5.m1.3a"><mrow id="S3.E5.m1.3.3.1" xref="S3.E5.m1.3.3.1.1.cmml"><mrow id="S3.E5.m1.3.3.1.1" xref="S3.E5.m1.3.3.1.1.cmml"><msub id="S3.E5.m1.3.3.1.1.3" xref="S3.E5.m1.3.3.1.1.3.cmml"><mi id="S3.E5.m1.3.3.1.1.3.2" xref="S3.E5.m1.3.3.1.1.3.2.cmml">L</mi><mrow id="S3.E5.m1.3.3.1.1.3.3" xref="S3.E5.m1.3.3.1.1.3.3.cmml"><mi id="S3.E5.m1.3.3.1.1.3.3.2" xref="S3.E5.m1.3.3.1.1.3.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.3.3.1.1.3.3.1" xref="S3.E5.m1.3.3.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.E5.m1.3.3.1.1.3.3.3" xref="S3.E5.m1.3.3.1.1.3.3.3.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.3.3.1.1.3.3.1a" xref="S3.E5.m1.3.3.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.E5.m1.3.3.1.1.3.3.4" xref="S3.E5.m1.3.3.1.1.3.3.4.cmml">v</mi></mrow></msub><mo id="S3.E5.m1.3.3.1.1.2" xref="S3.E5.m1.3.3.1.1.2.cmml">=</mo><mrow id="S3.E5.m1.3.3.1.1.1" xref="S3.E5.m1.3.3.1.1.1.cmml"><mo id="S3.E5.m1.3.3.1.1.1a" xref="S3.E5.m1.3.3.1.1.1.cmml">âˆ’</mo><mrow id="S3.E5.m1.3.3.1.1.1.1" xref="S3.E5.m1.3.3.1.1.1.1.cmml"><munderover id="S3.E5.m1.3.3.1.1.1.1.2" xref="S3.E5.m1.3.3.1.1.1.1.2.cmml"><mo movablelimits="false" id="S3.E5.m1.3.3.1.1.1.1.2.2.2" xref="S3.E5.m1.3.3.1.1.1.1.2.2.2.cmml">âˆ‘</mo><mrow id="S3.E5.m1.3.3.1.1.1.1.2.2.3" xref="S3.E5.m1.3.3.1.1.1.1.2.2.3.cmml"><mi id="S3.E5.m1.3.3.1.1.1.1.2.2.3.2" xref="S3.E5.m1.3.3.1.1.1.1.2.2.3.2.cmml">n</mi><mo id="S3.E5.m1.3.3.1.1.1.1.2.2.3.1" xref="S3.E5.m1.3.3.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E5.m1.3.3.1.1.1.1.2.2.3.3" xref="S3.E5.m1.3.3.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E5.m1.3.3.1.1.1.1.2.3" xref="S3.E5.m1.3.3.1.1.1.1.2.3.cmml">N</mi></munderover><mrow id="S3.E5.m1.3.3.1.1.1.1.1" xref="S3.E5.m1.3.3.1.1.1.1.1.cmml"><mfrac id="S3.E5.m1.3.3.1.1.1.1.1.3" xref="S3.E5.m1.3.3.1.1.1.1.1.3.cmml"><mn id="S3.E5.m1.3.3.1.1.1.1.1.3.2" xref="S3.E5.m1.3.3.1.1.1.1.1.3.2.cmml">1</mn><mi id="S3.E5.m1.3.3.1.1.1.1.1.3.3" xref="S3.E5.m1.3.3.1.1.1.1.1.3.3.cmml">N</mi></mfrac><mo lspace="0em" rspace="0em" id="S3.E5.m1.3.3.1.1.1.1.1.2" xref="S3.E5.m1.3.3.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E5.m1.3.3.1.1.1.1.1.4" xref="S3.E5.m1.3.3.1.1.1.1.1.4.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.3.3.1.1.1.1.1.2a" xref="S3.E5.m1.3.3.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E5.m1.3.3.1.1.1.1.1.5" xref="S3.E5.m1.3.3.1.1.1.1.1.5.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.3.3.1.1.1.1.1.2b" xref="S3.E5.m1.3.3.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E5.m1.3.3.1.1.1.1.1.6" xref="S3.E5.m1.3.3.1.1.1.1.1.6.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.3.3.1.1.1.1.1.2c" xref="S3.E5.m1.3.3.1.1.1.1.1.2.cmml">â€‹</mo><msub id="S3.E5.m1.3.3.1.1.1.1.1.7" xref="S3.E5.m1.3.3.1.1.1.1.1.7.cmml"><mi id="S3.E5.m1.3.3.1.1.1.1.1.7.2" xref="S3.E5.m1.3.3.1.1.1.1.1.7.2.cmml">F</mi><mi id="S3.E5.m1.3.3.1.1.1.1.1.7.3" xref="S3.E5.m1.3.3.1.1.1.1.1.7.3.cmml">s</mi></msub><mo lspace="0em" rspace="0em" id="S3.E5.m1.3.3.1.1.1.1.1.2d" xref="S3.E5.m1.3.3.1.1.1.1.1.2.cmml">â€‹</mo><msub id="S3.E5.m1.3.3.1.1.1.1.1.1" xref="S3.E5.m1.3.3.1.1.1.1.1.1.cmml"><mrow id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.2.1.cmml">[</mo><mrow id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.3.2.cmml">R</mi><mi id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.3.3.cmml">s</mi></msub><mo lspace="0em" rspace="0em" id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml">(</mo><msup id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">e</mi><mo id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">â€²</mo></msup><mo id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml">Ïµ</mi><mo id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.4" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S3.E5.m1.2.2" xref="S3.E5.m1.2.2.cmml">Ï†</mi><mo stretchy="false" id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.5" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.2.1.cmml">]</mo></mrow><mi id="S3.E5.m1.3.3.1.1.1.1.1.1.3" xref="S3.E5.m1.3.3.1.1.1.1.1.1.3.cmml">n</mi></msub></mrow></mrow></mrow></mrow><mo id="S3.E5.m1.3.3.1.2" xref="S3.E5.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.3b"><apply id="S3.E5.m1.3.3.1.1.cmml" xref="S3.E5.m1.3.3.1"><eq id="S3.E5.m1.3.3.1.1.2.cmml" xref="S3.E5.m1.3.3.1.1.2"></eq><apply id="S3.E5.m1.3.3.1.1.3.cmml" xref="S3.E5.m1.3.3.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.1.1.3.1.cmml" xref="S3.E5.m1.3.3.1.1.3">subscript</csymbol><ci id="S3.E5.m1.3.3.1.1.3.2.cmml" xref="S3.E5.m1.3.3.1.1.3.2">ğ¿</ci><apply id="S3.E5.m1.3.3.1.1.3.3.cmml" xref="S3.E5.m1.3.3.1.1.3.3"><times id="S3.E5.m1.3.3.1.1.3.3.1.cmml" xref="S3.E5.m1.3.3.1.1.3.3.1"></times><ci id="S3.E5.m1.3.3.1.1.3.3.2.cmml" xref="S3.E5.m1.3.3.1.1.3.3.2">ğ‘</ci><ci id="S3.E5.m1.3.3.1.1.3.3.3.cmml" xref="S3.E5.m1.3.3.1.1.3.3.3">ğ‘‘</ci><ci id="S3.E5.m1.3.3.1.1.3.3.4.cmml" xref="S3.E5.m1.3.3.1.1.3.3.4">ğ‘£</ci></apply></apply><apply id="S3.E5.m1.3.3.1.1.1.cmml" xref="S3.E5.m1.3.3.1.1.1"><minus id="S3.E5.m1.3.3.1.1.1.2.cmml" xref="S3.E5.m1.3.3.1.1.1"></minus><apply id="S3.E5.m1.3.3.1.1.1.1.cmml" xref="S3.E5.m1.3.3.1.1.1.1"><apply id="S3.E5.m1.3.3.1.1.1.1.2.cmml" xref="S3.E5.m1.3.3.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.1.1.1.1.2.1.cmml" xref="S3.E5.m1.3.3.1.1.1.1.2">superscript</csymbol><apply id="S3.E5.m1.3.3.1.1.1.1.2.2.cmml" xref="S3.E5.m1.3.3.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.1.1.1.1.2.2.1.cmml" xref="S3.E5.m1.3.3.1.1.1.1.2">subscript</csymbol><sum id="S3.E5.m1.3.3.1.1.1.1.2.2.2.cmml" xref="S3.E5.m1.3.3.1.1.1.1.2.2.2"></sum><apply id="S3.E5.m1.3.3.1.1.1.1.2.2.3.cmml" xref="S3.E5.m1.3.3.1.1.1.1.2.2.3"><eq id="S3.E5.m1.3.3.1.1.1.1.2.2.3.1.cmml" xref="S3.E5.m1.3.3.1.1.1.1.2.2.3.1"></eq><ci id="S3.E5.m1.3.3.1.1.1.1.2.2.3.2.cmml" xref="S3.E5.m1.3.3.1.1.1.1.2.2.3.2">ğ‘›</ci><cn type="integer" id="S3.E5.m1.3.3.1.1.1.1.2.2.3.3.cmml" xref="S3.E5.m1.3.3.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E5.m1.3.3.1.1.1.1.2.3.cmml" xref="S3.E5.m1.3.3.1.1.1.1.2.3">ğ‘</ci></apply><apply id="S3.E5.m1.3.3.1.1.1.1.1.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1"><times id="S3.E5.m1.3.3.1.1.1.1.1.2.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.2"></times><apply id="S3.E5.m1.3.3.1.1.1.1.1.3.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.3"><divide id="S3.E5.m1.3.3.1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.3"></divide><cn type="integer" id="S3.E5.m1.3.3.1.1.1.1.1.3.2.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.3.2">1</cn><ci id="S3.E5.m1.3.3.1.1.1.1.1.3.3.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.3.3">ğ‘</ci></apply><ci id="S3.E5.m1.3.3.1.1.1.1.1.4.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.4">ğ‘™</ci><ci id="S3.E5.m1.3.3.1.1.1.1.1.5.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.5">ğ‘œ</ci><ci id="S3.E5.m1.3.3.1.1.1.1.1.6.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.6">ğ‘”</ci><apply id="S3.E5.m1.3.3.1.1.1.1.1.7.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.7"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.1.1.1.1.1.7.1.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.7">subscript</csymbol><ci id="S3.E5.m1.3.3.1.1.1.1.1.7.2.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.7.2">ğ¹</ci><ci id="S3.E5.m1.3.3.1.1.1.1.1.7.3.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.7.3">ğ‘ </ci></apply><apply id="S3.E5.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E5.m1.3.3.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E5.m1.3.3.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1"><times id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.2"></times><apply id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.3.2">ğ‘…</ci><ci id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.3.3">ğ‘ </ci></apply><vector id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.1"><apply id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2">ğ‘’</ci><ci id="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.3">â€²</ci></apply><ci id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1">italic-Ïµ</ci><ci id="S3.E5.m1.2.2.cmml" xref="S3.E5.m1.2.2">ğœ‘</ci></vector></apply></apply><ci id="S3.E5.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1.3">ğ‘›</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.3c">L_{adv}=-\sum_{n=1}^{N}\frac{1}{N}logF_{s}[R_{s}(e^{\prime},\epsilon,\varphi)]_{n},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS3.p11" class="ltx_para">
<table id="S3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E6.m1.1" class="ltx_Math" alttext="L=\alpha L_{adv}+\beta L_{p}+\gamma L_{s}." display="block"><semantics id="S3.E6.m1.1a"><mrow id="S3.E6.m1.1.1.1" xref="S3.E6.m1.1.1.1.1.cmml"><mrow id="S3.E6.m1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.cmml"><mi id="S3.E6.m1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.2.cmml">L</mi><mo id="S3.E6.m1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E6.m1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.3.cmml"><mrow id="S3.E6.m1.1.1.1.1.3.2" xref="S3.E6.m1.1.1.1.1.3.2.cmml"><mi id="S3.E6.m1.1.1.1.1.3.2.2" xref="S3.E6.m1.1.1.1.1.3.2.2.cmml">Î±</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.3.2.1" xref="S3.E6.m1.1.1.1.1.3.2.1.cmml">â€‹</mo><msub id="S3.E6.m1.1.1.1.1.3.2.3" xref="S3.E6.m1.1.1.1.1.3.2.3.cmml"><mi id="S3.E6.m1.1.1.1.1.3.2.3.2" xref="S3.E6.m1.1.1.1.1.3.2.3.2.cmml">L</mi><mrow id="S3.E6.m1.1.1.1.1.3.2.3.3" xref="S3.E6.m1.1.1.1.1.3.2.3.3.cmml"><mi id="S3.E6.m1.1.1.1.1.3.2.3.3.2" xref="S3.E6.m1.1.1.1.1.3.2.3.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.3.2.3.3.1" xref="S3.E6.m1.1.1.1.1.3.2.3.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.1.1.1.1.3.2.3.3.3" xref="S3.E6.m1.1.1.1.1.3.2.3.3.3.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.3.2.3.3.1a" xref="S3.E6.m1.1.1.1.1.3.2.3.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.1.1.1.1.3.2.3.3.4" xref="S3.E6.m1.1.1.1.1.3.2.3.3.4.cmml">v</mi></mrow></msub></mrow><mo id="S3.E6.m1.1.1.1.1.3.1" xref="S3.E6.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S3.E6.m1.1.1.1.1.3.3" xref="S3.E6.m1.1.1.1.1.3.3.cmml"><mi id="S3.E6.m1.1.1.1.1.3.3.2" xref="S3.E6.m1.1.1.1.1.3.3.2.cmml">Î²</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.3.3.1" xref="S3.E6.m1.1.1.1.1.3.3.1.cmml">â€‹</mo><msub id="S3.E6.m1.1.1.1.1.3.3.3" xref="S3.E6.m1.1.1.1.1.3.3.3.cmml"><mi id="S3.E6.m1.1.1.1.1.3.3.3.2" xref="S3.E6.m1.1.1.1.1.3.3.3.2.cmml">L</mi><mi id="S3.E6.m1.1.1.1.1.3.3.3.3" xref="S3.E6.m1.1.1.1.1.3.3.3.3.cmml">p</mi></msub></mrow><mo id="S3.E6.m1.1.1.1.1.3.1a" xref="S3.E6.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S3.E6.m1.1.1.1.1.3.4" xref="S3.E6.m1.1.1.1.1.3.4.cmml"><mi id="S3.E6.m1.1.1.1.1.3.4.2" xref="S3.E6.m1.1.1.1.1.3.4.2.cmml">Î³</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.3.4.1" xref="S3.E6.m1.1.1.1.1.3.4.1.cmml">â€‹</mo><msub id="S3.E6.m1.1.1.1.1.3.4.3" xref="S3.E6.m1.1.1.1.1.3.4.3.cmml"><mi id="S3.E6.m1.1.1.1.1.3.4.3.2" xref="S3.E6.m1.1.1.1.1.3.4.3.2.cmml">L</mi><mi id="S3.E6.m1.1.1.1.1.3.4.3.3" xref="S3.E6.m1.1.1.1.1.3.4.3.3.cmml">s</mi></msub></mrow></mrow></mrow><mo lspace="0em" id="S3.E6.m1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.1b"><apply id="S3.E6.m1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1"><eq id="S3.E6.m1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1"></eq><ci id="S3.E6.m1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.2">ğ¿</ci><apply id="S3.E6.m1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.3"><plus id="S3.E6.m1.1.1.1.1.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.1"></plus><apply id="S3.E6.m1.1.1.1.1.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2"><times id="S3.E6.m1.1.1.1.1.3.2.1.cmml" xref="S3.E6.m1.1.1.1.1.3.2.1"></times><ci id="S3.E6.m1.1.1.1.1.3.2.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2.2">ğ›¼</ci><apply id="S3.E6.m1.1.1.1.1.3.2.3.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.2.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.3.2.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.2">ğ¿</ci><apply id="S3.E6.m1.1.1.1.1.3.2.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.3"><times id="S3.E6.m1.1.1.1.1.3.2.3.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.3.1"></times><ci id="S3.E6.m1.1.1.1.1.3.2.3.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.3.2">ğ‘</ci><ci id="S3.E6.m1.1.1.1.1.3.2.3.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.3.3">ğ‘‘</ci><ci id="S3.E6.m1.1.1.1.1.3.2.3.3.4.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.3.4">ğ‘£</ci></apply></apply></apply><apply id="S3.E6.m1.1.1.1.1.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.3"><times id="S3.E6.m1.1.1.1.1.3.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.3.1"></times><ci id="S3.E6.m1.1.1.1.1.3.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.3.2">ğ›½</ci><apply id="S3.E6.m1.1.1.1.1.3.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.3.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.3.3.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3.2">ğ¿</ci><ci id="S3.E6.m1.1.1.1.1.3.3.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3.3">ğ‘</ci></apply></apply><apply id="S3.E6.m1.1.1.1.1.3.4.cmml" xref="S3.E6.m1.1.1.1.1.3.4"><times id="S3.E6.m1.1.1.1.1.3.4.1.cmml" xref="S3.E6.m1.1.1.1.1.3.4.1"></times><ci id="S3.E6.m1.1.1.1.1.3.4.2.cmml" xref="S3.E6.m1.1.1.1.1.3.4.2">ğ›¾</ci><apply id="S3.E6.m1.1.1.1.1.3.4.3.cmml" xref="S3.E6.m1.1.1.1.1.3.4.3"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.4.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.4.3">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.3.4.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.4.3.2">ğ¿</ci><ci id="S3.E6.m1.1.1.1.1.3.4.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.4.3.3">ğ‘ </ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.1c">L=\alpha L_{adv}+\beta L_{p}+\gamma L_{s}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS3.p12" class="ltx_para">
<p id="S3.SS3.p12.3" class="ltx_p">Here <math id="S3.SS3.p12.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS3.p12.1.m1.1a"><mi id="S3.SS3.p12.1.m1.1.1" xref="S3.SS3.p12.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p12.1.m1.1b"><ci id="S3.SS3.p12.1.m1.1.1.cmml" xref="S3.SS3.p12.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p12.1.m1.1c">\alpha</annotation></semantics></math> controls the weight of the adversarial learning part, <math id="S3.SS3.p12.2.m2.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S3.SS3.p12.2.m2.1a"><mi id="S3.SS3.p12.2.m2.1.1" xref="S3.SS3.p12.2.m2.1.1.cmml">Î²</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p12.2.m2.1b"><ci id="S3.SS3.p12.2.m2.1.1.cmml" xref="S3.SS3.p12.2.m2.1.1">ğ›½</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p12.2.m2.1c">\beta</annotation></semantics></math> controls the weight of personalized representation extraction, and <math id="S3.SS3.p12.3.m3.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S3.SS3.p12.3.m3.1a"><mi id="S3.SS3.p12.3.m3.1.1" xref="S3.SS3.p12.3.m3.1.1.cmml">Î³</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p12.3.m3.1b"><ci id="S3.SS3.p12.3.m3.1.1.cmml" xref="S3.SS3.p12.3.m3.1.1">ğ›¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p12.3.m3.1c">\gamma</annotation></semantics></math> controls the weight of shared representation. The detailed procedures of the proposed FedPR algorithm are shown in AlgorithmÂ <a href="#alg1" title="Algorithm 1 â€£ III-C Personalized Forgery Representation Learning â€£ III Proposed Approach â€£ Federated Face Forgery Detection Learning with Personalized Representation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
In the testing stage, each client leverages its own personalized model for local testing.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Experiments and Results</span>
</h2>

<section id="S4.SS1" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.4.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.5.2" class="ltx_text ltx_font_italic">Dataset</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">In this article, we use four public datasets, namely the FaceForensics++ dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>, WildDeepfake dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>, CelebDF-v2 dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>, Deeperforensics-1.0 dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>, and FMFCC-V dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>. Examples are shown in Figure <a href="#S4.F3" title="Figure 3 â€£ IV-A Dataset â€£ IV Experiments and Results â€£ Federated Face Forgery Detection Learning with Personalized Representation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. The first line displays real face samples, and the second line displays fake face samples. In addition, we also constructed the Forgery Source Hybrid Dataset to simulate complex real-life scenarios.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2406.11145/assets/x3.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="221" height="96" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The samples of public face forgery datasets: (a) FaceForensics++. (b)WildDeepfake. (c) CelebDF-v2. (d) Deeperforensics-1.0. (e) FMFCC-V.</figcaption>
</figure>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">FaceForensics++:</span> The real videos of the FaceForensics++ dataset are composed of 1000 real videos extracted from YouTube. Its fake videos include four subtypes: Deepfakes, Face2Face, FaceSwap and NeuralTextures. Each subset has different forgery methods and characteristics to simulate different forgery scenarios in the real world. In our personalized representation learning approach, the training data is divided into four age groups and assigned to eight customers, and the age range of every two customers is kept consistent.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p"><span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_bold">WildDeepfake:</span> The WildDeepfake dataset contains 7314 face sequences. The videos in WildDeepfake are collected from the Internet, and their face-changing videos are synthesized through various methods, which makes the detection of the WildDeepfake dataset more challenging. In our personalized-based federated learning method, the training data is divided into four races and assigned to eight clients, and the race types of each two clients are kept consistent.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p"><span id="S4.SS1.p4.1.1" class="ltx_text ltx_font_bold">CelebDF-v2:</span> The CelebDF-v2 dataset contains 590 real original videos and 5639 corresponding fake videos collected from YouTube. Compared with the v1 version, this version of the dataset has excellent visual effects, so detection is more difficult. This dataset is currently widely used in the field of face forgery detection.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para">
<p id="S4.SS1.p5.1" class="ltx_p"><span id="S4.SS1.p5.1.1" class="ltx_text ltx_font_bold">Deepforensics-1.0:</span> The Deepforensics-1.0 dataset is a large-scale and widely used benchmark dataset for estimating face forgery detection methods. Fake videos are generated through an end-to-end face exchange framework. The authors also took into account factors such as different poses, lighting conditions, and expressions, so the dataset is more consistent with real-world scenarios. In our personalized-based federated learning method, the training data is first divided into five races and assigned to ten clients, and the race types of each two clients are kept consistent.</p>
</div>
<div id="S4.SS1.p6" class="ltx_para">
<p id="S4.SS1.p6.1" class="ltx_p"><span id="S4.SS1.p6.1.1" class="ltx_text ltx_font_bold">FMFCC-V:</span> The FMFCC-V dataset is the first largest and public Asian DeepFake detection dataset. Among them, the real video sources come from 83 people, and the fake videos include four popular face-changing methods. In order to simulate real world scenarios, the authors introduced diversity to the deepfake video and the original video by adding 12 types of perturbations.</p>
</div>
<div id="S4.SS1.p7" class="ltx_para">
<p id="S4.SS1.p7.1" class="ltx_p"><span id="S4.SS1.p7.1.1" class="ltx_text ltx_font_bold">Forgery Source Hybrid Dataset:</span> In order to effectively evaluate the face forgery detection performance of the proposed method in complex forgery datasets with diverse types, we used these four public datasets to construct a new mixed source dataset. The designed protocol details are as follows: four different types of FaceForensics++ dataset, WildDeepfake dataset, CelebDF-v2 dataset, and FMFCC-V dataset are used to form a mixed source dataset. The training set contains approximately 20,000 images of each subtype. The ratio of the training set to the test set is kept at 7:3. For the convenience of expression, we abbreviate Deepfakes data as FF++_DF.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.4.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.5.2" class="ltx_text ltx_font_italic">Implementation Details</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.3" class="ltx_p">For the video dataset, we extract 50 frames for each video. We choose the Dlib <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> tool as the face detection extractor for the face forgery detection dataset. After the data is processed, only the facial area is cropped out as input to the face forgery detection model. We normalize all aligned faces and resize them to 256Ã—256 before sending them to the network for training. Our personalized forgery representation learning network is implemented on the PyTorch platform. We adopt SGD with a momentum factor of 0.5 as the optimizer to minimize the loss function. The batch size is set to 32 and the initial learning rate is 0.01. In the following experiments, we set the weight coefficient <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mi id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><ci id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">\alpha</annotation></semantics></math> to 0.1, <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><mi id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml">Î²</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><ci id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">ğ›½</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">\beta</annotation></semantics></math> to 1 and <math id="S4.SS2.p1.3.m3.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S4.SS2.p1.3.m3.1a"><mi id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml">Î³</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><ci id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1">ğ›¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">\gamma</annotation></semantics></math> to 1 empirically.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.4.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.5.2" class="ltx_text ltx_font_italic">Comparison Results</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">In this section, we compare the proposed method with state-of-the-art methods on constructed Forgery Source Hybrid Dataset and public datasets Deeperforensics-1.0, FaceForensics++, WildDeepfake and CelebDF-v2.
In order to fully evaluate the forgery detection performance, we use classification accuracy, the area under the receiver operating characteristic curve, and equal error rate as quantitative indicators. In the table, we use FedPR (w/o FL) to represent the results of training on centralized data, and FedPR (Ours) to represent the results of using personalized federated learning.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>The forgery detection accuracy (in %) is evaluated by several state-of-the-art methods on four sub-datasets of the constructed forgery source hybrid dataset. The last column result is the average value. The best results are shown in black font, with the second place underlined.</figcaption>
<table id="S4.T1.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T1.2.3" class="ltx_tr">
<td id="S4.T1.2.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Methods</td>
<td id="S4.T1.2.3.2" class="ltx_td ltx_align_center ltx_border_t">CelebDF-v2</td>
<td id="S4.T1.2.3.3" class="ltx_td ltx_align_center ltx_border_t">FF++_DF</td>
<td id="S4.T1.2.3.4" class="ltx_td ltx_align_center ltx_border_t">FMFCC-V</td>
<td id="S4.T1.2.3.5" class="ltx_td ltx_align_center ltx_border_t">WildDeepfake</td>
<td id="S4.T1.2.3.6" class="ltx_td ltx_align_center ltx_border_t">Avg.</td>
</tr>
<tr id="S4.T1.2.4" class="ltx_tr">
<td id="S4.T1.2.4.1" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S4.T1.2.4.2" class="ltx_td ltx_align_center ltx_border_t" colspan="5"><span id="S4.T1.2.4.2.1" class="ltx_text ltx_font_bold">Without Considering Privacy</span></td>
</tr>
<tr id="S4.T1.1.1" class="ltx_tr">
<td id="S4.T1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">CNNDetection<sub id="S4.T1.1.1.1.1" class="ltx_sub">1</sub>
</td>
<td id="S4.T1.1.1.2" class="ltx_td ltx_align_center ltx_border_t">64.98</td>
<td id="S4.T1.1.1.3" class="ltx_td ltx_align_center ltx_border_t">94.18</td>
<td id="S4.T1.1.1.4" class="ltx_td ltx_align_center ltx_border_t">88.06</td>
<td id="S4.T1.1.1.5" class="ltx_td ltx_align_center ltx_border_t">71.36</td>
<td id="S4.T1.1.1.6" class="ltx_td ltx_align_center ltx_border_t">79.65</td>
</tr>
<tr id="S4.T1.2.5" class="ltx_tr">
<td id="S4.T1.2.5.1" class="ltx_td ltx_align_center ltx_border_r">Xception</td>
<td id="S4.T1.2.5.2" class="ltx_td ltx_align_center">72.12</td>
<td id="S4.T1.2.5.3" class="ltx_td ltx_align_center">87.54</td>
<td id="S4.T1.2.5.4" class="ltx_td ltx_align_center">75.54</td>
<td id="S4.T1.2.5.5" class="ltx_td ltx_align_center">57.77</td>
<td id="S4.T1.2.5.6" class="ltx_td ltx_align_center">73.27</td>
</tr>
<tr id="S4.T1.2.2" class="ltx_tr">
<td id="S4.T1.2.2.1" class="ltx_td ltx_align_center ltx_border_r">CNNDetection<sub id="S4.T1.2.2.1.1" class="ltx_sub">2</sub>
</td>
<td id="S4.T1.2.2.2" class="ltx_td ltx_align_center">65.79</td>
<td id="S4.T1.2.2.3" class="ltx_td ltx_align_center"><span id="S4.T1.2.2.3.1" class="ltx_text ltx_font_bold">96.20</span></td>
<td id="S4.T1.2.2.4" class="ltx_td ltx_align_center">83.99</td>
<td id="S4.T1.2.2.5" class="ltx_td ltx_align_center">63.61</td>
<td id="S4.T1.2.2.6" class="ltx_td ltx_align_center">77.40</td>
</tr>
<tr id="S4.T1.2.6" class="ltx_tr">
<td id="S4.T1.2.6.1" class="ltx_td ltx_align_center ltx_border_r">GFF</td>
<td id="S4.T1.2.6.2" class="ltx_td ltx_align_center">81.60</td>
<td id="S4.T1.2.6.3" class="ltx_td ltx_align_center">90.40</td>
<td id="S4.T1.2.6.4" class="ltx_td ltx_align_center">89.15</td>
<td id="S4.T1.2.6.5" class="ltx_td ltx_align_center"><span id="S4.T1.2.6.5.1" class="ltx_text ltx_framed ltx_framed_underline">71.64</span></td>
<td id="S4.T1.2.6.6" class="ltx_td ltx_align_center">83.20</td>
</tr>
<tr id="S4.T1.2.7" class="ltx_tr">
<td id="S4.T1.2.7.1" class="ltx_td ltx_align_center ltx_border_r">RFM</td>
<td id="S4.T1.2.7.2" class="ltx_td ltx_align_center"><span id="S4.T1.2.7.2.1" class="ltx_text ltx_framed ltx_framed_underline">86.44</span></td>
<td id="S4.T1.2.7.3" class="ltx_td ltx_align_center">94.77</td>
<td id="S4.T1.2.7.4" class="ltx_td ltx_align_center">99.22</td>
<td id="S4.T1.2.7.5" class="ltx_td ltx_align_center">65.92</td>
<td id="S4.T1.2.7.6" class="ltx_td ltx_align_center">86.59</td>
</tr>
<tr id="S4.T1.2.8" class="ltx_tr">
<td id="S4.T1.2.8.1" class="ltx_td ltx_align_center ltx_border_r">CADDM</td>
<td id="S4.T1.2.8.2" class="ltx_td ltx_align_center">83.05</td>
<td id="S4.T1.2.8.3" class="ltx_td ltx_align_center"><span id="S4.T1.2.8.3.1" class="ltx_text ltx_framed ltx_framed_underline">95.59</span></td>
<td id="S4.T1.2.8.4" class="ltx_td ltx_align_center">74.69</td>
<td id="S4.T1.2.8.5" class="ltx_td ltx_align_center"><span id="S4.T1.2.8.5.1" class="ltx_text ltx_font_bold">78.76</span></td>
<td id="S4.T1.2.8.6" class="ltx_td ltx_align_center">83.02</td>
</tr>
<tr id="S4.T1.2.9" class="ltx_tr">
<td id="S4.T1.2.9.1" class="ltx_td ltx_align_center ltx_border_r">FedPR (w/o FL)</td>
<td id="S4.T1.2.9.2" class="ltx_td ltx_align_center">84.29</td>
<td id="S4.T1.2.9.3" class="ltx_td ltx_align_center">94.12</td>
<td id="S4.T1.2.9.4" class="ltx_td ltx_align_center"><span id="S4.T1.2.9.4.1" class="ltx_text ltx_framed ltx_framed_underline">99.36</span></td>
<td id="S4.T1.2.9.5" class="ltx_td ltx_align_center">70.05</td>
<td id="S4.T1.2.9.6" class="ltx_td ltx_align_center"><span id="S4.T1.2.9.6.1" class="ltx_text ltx_framed ltx_framed_underline">86.96</span></td>
</tr>
<tr id="S4.T1.2.10" class="ltx_tr">
<td id="S4.T1.2.10.1" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S4.T1.2.10.2" class="ltx_td ltx_align_center ltx_border_t" colspan="5"><span id="S4.T1.2.10.2.1" class="ltx_text ltx_font_bold">Considering Privacy</span></td>
</tr>
<tr id="S4.T1.2.11" class="ltx_tr">
<td id="S4.T1.2.11.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">FedPR (Ours)</td>
<td id="S4.T1.2.11.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T1.2.11.2.1" class="ltx_text ltx_font_bold">89.90</span></td>
<td id="S4.T1.2.11.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">94.81</td>
<td id="S4.T1.2.11.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T1.2.11.4.1" class="ltx_text ltx_font_bold">99.60</span></td>
<td id="S4.T1.2.11.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">70.81</td>
<td id="S4.T1.2.11.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T1.2.11.6.1" class="ltx_text ltx_font_bold">88.78</span></td>
</tr>
</table>
</figure>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Evaluation accuracy rate (in %) and area under the receiver operating characteristic curve (in %) of forgery detection performance on constructed Forgery Source Hybrid Dataset by several state-of-the-art methods. The best result is displayed in black font and the second place is underlined.</figcaption>
<table id="S4.T2.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T2.2.3" class="ltx_tr">
<td id="S4.T2.2.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Methods</td>
<td id="S4.T2.2.3.2" class="ltx_td ltx_align_center ltx_border_t">Accuracy(%)</td>
<td id="S4.T2.2.3.3" class="ltx_td ltx_align_center ltx_border_t">AUC(%)</td>
</tr>
<tr id="S4.T2.2.4" class="ltx_tr">
<td id="S4.T2.2.4.1" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S4.T2.2.4.2" class="ltx_td ltx_align_center ltx_border_t" colspan="2"><span id="S4.T2.2.4.2.1" class="ltx_text ltx_font_bold">Without Considering Privacy</span></td>
</tr>
<tr id="S4.T2.2.5" class="ltx_tr">
<td id="S4.T2.2.5.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Xception</td>
<td id="S4.T2.2.5.2" class="ltx_td ltx_align_center ltx_border_t">69.85</td>
<td id="S4.T2.2.5.3" class="ltx_td ltx_align_center ltx_border_t">76.66</td>
</tr>
<tr id="S4.T2.1.1" class="ltx_tr">
<td id="S4.T2.1.1.1" class="ltx_td ltx_align_center ltx_border_r">CNNDetection<sub id="S4.T2.1.1.1.1" class="ltx_sub"><span id="S4.T2.1.1.1.1.1" class="ltx_text ltx_font_italic">1</span></sub>
</td>
<td id="S4.T2.1.1.2" class="ltx_td ltx_align_center">75.44</td>
<td id="S4.T2.1.1.3" class="ltx_td ltx_align_center">83.26</td>
</tr>
<tr id="S4.T2.2.2" class="ltx_tr">
<td id="S4.T2.2.2.1" class="ltx_td ltx_align_center ltx_border_r">CNNDetection<sub id="S4.T2.2.2.1.1" class="ltx_sub"><span id="S4.T2.2.2.1.1.1" class="ltx_text ltx_font_italic">2</span></sub>
</td>
<td id="S4.T2.2.2.2" class="ltx_td ltx_align_center">78.57</td>
<td id="S4.T2.2.2.3" class="ltx_td ltx_align_center">87.48</td>
</tr>
<tr id="S4.T2.2.6" class="ltx_tr">
<td id="S4.T2.2.6.1" class="ltx_td ltx_align_center ltx_border_r">GFF</td>
<td id="S4.T2.2.6.2" class="ltx_td ltx_align_center">82.71</td>
<td id="S4.T2.2.6.3" class="ltx_td ltx_align_center">91.18</td>
</tr>
<tr id="S4.T2.2.7" class="ltx_tr">
<td id="S4.T2.2.7.1" class="ltx_td ltx_align_center ltx_border_r">RFM</td>
<td id="S4.T2.2.7.2" class="ltx_td ltx_align_center"><span id="S4.T2.2.7.2.1" class="ltx_text ltx_framed ltx_framed_underline">84.79</span></td>
<td id="S4.T2.2.7.3" class="ltx_td ltx_align_center"><span id="S4.T2.2.7.3.1" class="ltx_text ltx_framed ltx_framed_underline">92.76</span></td>
</tr>
<tr id="S4.T2.2.8" class="ltx_tr">
<td id="S4.T2.2.8.1" class="ltx_td ltx_align_center ltx_border_r">CADDM</td>
<td id="S4.T2.2.8.2" class="ltx_td ltx_align_center">81.51</td>
<td id="S4.T2.2.8.3" class="ltx_td ltx_align_center">90.40</td>
</tr>
<tr id="S4.T2.2.9" class="ltx_tr">
<td id="S4.T2.2.9.1" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S4.T2.2.9.2" class="ltx_td ltx_align_center ltx_border_t" colspan="2"><span id="S4.T2.2.9.2.1" class="ltx_text ltx_font_bold">Considering Privacy</span></td>
</tr>
<tr id="S4.T2.2.10" class="ltx_tr">
<td id="S4.T2.2.10.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">FedPR (Ours)</td>
<td id="S4.T2.2.10.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T2.2.10.2.1" class="ltx_text ltx_font_bold">88.78</span></td>
<td id="S4.T2.2.10.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T2.2.10.3.1" class="ltx_text ltx_font_bold">93.52</span></td>
</tr>
</table>
</figure>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.3" class="ltx_p"><span id="S4.SS3.p2.3.1" class="ltx_text ltx_font_bold">Results on Forgery Source Hybrid Dataset</span> In order to further prove the advantages of this proposed method, we trained and tested the models in the four subtypes included in the Forgery Source Hybrid Dataset. As shown in TableÂ <a href="#S4.T1" title="TABLE I â€£ IV-C Comparison Results â€£ IV Experiments and Results â€£ Federated Face Forgery Detection Learning with Personalized Representation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>, our proposed method achieves the highest accuracy on the CelebDF-v2 and FMFCC-V datasets, outperforming
CADDM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>,
RFM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>,
GFF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> and other methods in most scenarios. This is because the designed personalized forgery representation learning can explore more robust face forgery clues. As shown in TableÂ <a href="#S4.T2" title="TABLE II â€£ IV-C Comparison Results â€£ IV Experiments and Results â€£ Federated Face Forgery Detection Learning with Personalized Representation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>, we re-implemented several representative face forgery methods on the forgery source mixed dataset. Thanks to the designed personalized forgery representation learning, our proposed method achieves optimal performance in both auc and accuracy metrics. For example, compared with RFM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>, the accuracy of our method exceeds 3.99% and the auc exceeds 0.76%. Compared with the existing CADDM method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>, this method also achieves competitive results. CNNDetection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> is susceptible to interference from specific generation methods. Therefore, two different data preprocessing methods are used to improve performance. CNNDetection<sub id="S4.SS3.p2.3.2" class="ltx_sub"><span id="S4.SS3.p2.3.2.1" class="ltx_text ltx_font_italic">1</span></sub> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> represents that the image may be gaussian blur or jpeged, each with 50% probability, where gaussian blur parameters: <math id="S4.SS3.p2.2.m2.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S4.SS3.p2.2.m2.1a"><mi id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml">Ïƒ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><ci id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">\sigma</annotation></semantics></math>~Uniform[0, 3], jpeged: the image is converted by two popular libraries OpenCV and PIL jpeg format, qualityÂ uniform{30, 31, â€¦, 100}; CNNDetection<sub id="S4.SS3.p2.3.3" class="ltx_sub"><span id="S4.SS3.p2.3.3.1" class="ltx_text ltx_font_italic">2</span></sub> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> represents that the image may be blurry and jpeg, 10% probability. Our method improves the generalization ability for complex forgery datasets with diverse types by extracting personalized representations of clients and combining the shared representation of multiple distributed client models.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE III: </span>Forgery detection performance evaluation was performed using several state-of-the-art methods on the Deepforensics-1.0 dataset, and the accuracy (in%) was calculated. The best result is displayed in black font and the second place is underlined.</figcaption>
<table id="S4.T3.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T3.1.1" class="ltx_tr">
<td id="S4.T3.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Methods</td>
<td id="S4.T3.1.1.2" class="ltx_td ltx_align_center ltx_border_t">Accuracy(%)</td>
</tr>
<tr id="S4.T3.1.2" class="ltx_tr">
<td id="S4.T3.1.2.1" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S4.T3.1.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.1.2.2.1" class="ltx_text ltx_font_bold">Without Considering Privacy</span></td>
</tr>
<tr id="S4.T3.1.3" class="ltx_tr">
<td id="S4.T3.1.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">C3D</td>
<td id="S4.T3.1.3.2" class="ltx_td ltx_align_center ltx_border_t">87.63</td>
</tr>
<tr id="S4.T3.1.4" class="ltx_tr">
<td id="S4.T3.1.4.1" class="ltx_td ltx_align_center ltx_border_r">TSN</td>
<td id="S4.T3.1.4.2" class="ltx_td ltx_align_center">91.50</td>
</tr>
<tr id="S4.T3.1.5" class="ltx_tr">
<td id="S4.T3.1.5.1" class="ltx_td ltx_align_center ltx_border_r">I3D</td>
<td id="S4.T3.1.5.2" class="ltx_td ltx_align_center">90.75</td>
</tr>
<tr id="S4.T3.1.6" class="ltx_tr">
<td id="S4.T3.1.6.1" class="ltx_td ltx_align_center ltx_border_r">Resnet+LSTM</td>
<td id="S4.T3.1.6.2" class="ltx_td ltx_align_center">90.63</td>
</tr>
<tr id="S4.T3.1.7" class="ltx_tr">
<td id="S4.T3.1.7.1" class="ltx_td ltx_align_center ltx_border_r">Xception</td>
<td id="S4.T3.1.7.2" class="ltx_td ltx_align_center">88.38</td>
</tr>
<tr id="S4.T3.1.8" class="ltx_tr">
<td id="S4.T3.1.8.1" class="ltx_td ltx_align_center ltx_border_r">FedPR (w/o FL)</td>
<td id="S4.T3.1.8.2" class="ltx_td ltx_align_center"><span id="S4.T3.1.8.2.1" class="ltx_text ltx_font_bold">98.64</span></td>
</tr>
<tr id="S4.T3.1.9" class="ltx_tr">
<td id="S4.T3.1.9.1" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S4.T3.1.9.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.1.9.2.1" class="ltx_text ltx_font_bold">Considering Privacy</span></td>
</tr>
<tr id="S4.T3.1.10" class="ltx_tr">
<td id="S4.T3.1.10.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">FedPR (Ours)</td>
<td id="S4.T3.1.10.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T3.1.10.2.1" class="ltx_text ltx_framed ltx_framed_underline">97.29</span></td>
</tr>
</table>
</figure>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p"><span id="S4.SS3.p3.1.1" class="ltx_text ltx_font_bold">Results on Deepforensics-1.0 dataset</span> As shown in TableÂ <a href="#S4.T3" title="TABLE III â€£ IV-C Comparison Results â€£ IV Experiments and Results â€£ Federated Face Forgery Detection Learning with Personalized Representation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>, we compare the algorithm proposed in this paper with other representative face forgery detection methods. In order to prove the strong generalization ability, we selected 1000 manipulated videos in the standard set. When the training set is the standard set and the test set is single-level distortion, the proposed method can achieve good accuracy, even exceeding Resnet+LSTM
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> 6.66%,
Xception <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite> 8.91%, I3D
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite> 6.54%. We believe that these accuracy improvements are due to the designed personalized forgery representation learning. It is known that in some cases the accuracy of federated learning models is lower than that of centralized training models. In our experiments, the performance degradation caused by federated learning was 1.35%.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE IV: </span>Evaluation AUC (in %) and equal error rate (in %) of forgery detection performance on WildDeepfake dataset by several state-of-the-art methods. The best result is displayed in black font and the second place is underlined.</figcaption>
<table id="S4.T4.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T4.1.2" class="ltx_tr">
<td id="S4.T4.1.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Methods</td>
<td id="S4.T4.1.2.2" class="ltx_td ltx_align_center ltx_border_t">AUC(%)</td>
<td id="S4.T4.1.2.3" class="ltx_td ltx_align_center ltx_border_t">EER(%)</td>
</tr>
<tr id="S4.T4.1.3" class="ltx_tr">
<td id="S4.T4.1.3.1" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S4.T4.1.3.2" class="ltx_td ltx_align_center ltx_border_t" colspan="2"><span id="S4.T4.1.3.2.1" class="ltx_text ltx_font_bold">Without Considering Privacy</span></td>
</tr>
<tr id="S4.T4.1.4" class="ltx_tr">
<td id="S4.T4.1.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Xception</td>
<td id="S4.T4.1.4.2" class="ltx_td ltx_align_center ltx_border_t">62.72</td>
<td id="S4.T4.1.4.3" class="ltx_td ltx_align_center ltx_border_t">-</td>
</tr>
<tr id="S4.T4.1.5" class="ltx_tr">
<td id="S4.T4.1.5.1" class="ltx_td ltx_align_center ltx_border_r">RFM</td>
<td id="S4.T4.1.5.2" class="ltx_td ltx_align_center">57.75</td>
<td id="S4.T4.1.5.3" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T4.1.6" class="ltx_tr">
<td id="S4.T4.1.6.1" class="ltx_td ltx_align_center ltx_border_r">ADD-Net</td>
<td id="S4.T4.1.6.2" class="ltx_td ltx_align_center">62.35</td>
<td id="S4.T4.1.6.3" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T4.1.1" class="ltx_tr">
<td id="S4.T4.1.1.1" class="ltx_td ltx_align_center ltx_border_r">F<sup id="S4.T4.1.1.1.1" class="ltx_sup"><span id="S4.T4.1.1.1.1.1" class="ltx_text ltx_font_italic">3</span></sup>-Net</td>
<td id="S4.T4.1.1.2" class="ltx_td ltx_align_center">57.10</td>
<td id="S4.T4.1.1.3" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T4.1.7" class="ltx_tr">
<td id="S4.T4.1.7.1" class="ltx_td ltx_align_center ltx_border_r">MultiAtt</td>
<td id="S4.T4.1.7.2" class="ltx_td ltx_align_center">59.74</td>
<td id="S4.T4.1.7.3" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T4.1.8" class="ltx_tr">
<td id="S4.T4.1.8.1" class="ltx_td ltx_align_center ltx_border_r">RECCE</td>
<td id="S4.T4.1.8.2" class="ltx_td ltx_align_center">64.31</td>
<td id="S4.T4.1.8.3" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T4.1.9" class="ltx_tr">
<td id="S4.T4.1.9.1" class="ltx_td ltx_align_center ltx_border_r">LTW</td>
<td id="S4.T4.1.9.2" class="ltx_td ltx_align_center">67.12</td>
<td id="S4.T4.1.9.3" class="ltx_td ltx_align_center">39.22</td>
</tr>
<tr id="S4.T4.1.10" class="ltx_tr">
<td id="S4.T4.1.10.1" class="ltx_td ltx_align_center ltx_border_r">EN-B4</td>
<td id="S4.T4.1.10.2" class="ltx_td ltx_align_center">67.89</td>
<td id="S4.T4.1.10.3" class="ltx_td ltx_align_center"><span id="S4.T4.1.10.3.1" class="ltx_text ltx_framed ltx_framed_underline">37.21</span></td>
</tr>
<tr id="S4.T4.1.11" class="ltx_tr">
<td id="S4.T4.1.11.1" class="ltx_td ltx_align_center ltx_border_r">GFF</td>
<td id="S4.T4.1.11.2" class="ltx_td ltx_align_center">66.51</td>
<td id="S4.T4.1.11.3" class="ltx_td ltx_align_center">41.52</td>
</tr>
<tr id="S4.T4.1.12" class="ltx_tr">
<td id="S4.T4.1.12.1" class="ltx_td ltx_align_center ltx_border_r">SBI</td>
<td id="S4.T4.1.12.2" class="ltx_td ltx_align_center">67.22</td>
<td id="S4.T4.1.12.3" class="ltx_td ltx_align_center">38.85</td>
</tr>
<tr id="S4.T4.1.13" class="ltx_tr">
<td id="S4.T4.1.13.1" class="ltx_td ltx_align_center ltx_border_r">FedPR (w/o FL)</td>
<td id="S4.T4.1.13.2" class="ltx_td ltx_align_center"><span id="S4.T4.1.13.2.1" class="ltx_text ltx_font_bold">73.73</span></td>
<td id="S4.T4.1.13.3" class="ltx_td ltx_align_center"><span id="S4.T4.1.13.3.1" class="ltx_text ltx_font_bold">33.75</span></td>
</tr>
<tr id="S4.T4.1.14" class="ltx_tr">
<td id="S4.T4.1.14.1" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S4.T4.1.14.2" class="ltx_td ltx_align_center ltx_border_t" colspan="2"><span id="S4.T4.1.14.2.1" class="ltx_text ltx_font_bold">Considering Privacy</span></td>
</tr>
<tr id="S4.T4.1.15" class="ltx_tr">
<td id="S4.T4.1.15.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">FedPR (Ours)</td>
<td id="S4.T4.1.15.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T4.1.15.2.1" class="ltx_text ltx_framed ltx_framed_underline">68.25</span></td>
<td id="S4.T4.1.15.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">37.84</td>
</tr>
</table>
</figure>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.1" class="ltx_p"><span id="S4.SS3.p4.1.1" class="ltx_text ltx_font_bold">Results on WildDeepfake dataset</span> As shown in TableÂ <a href="#S4.T4" title="TABLE IV â€£ IV-C Comparison Results â€£ IV Experiments and Results â€£ Federated Face Forgery Detection Learning with Personalized Representation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>, in order to further verify the generalization of the proposed method, we train on the FaceForensics++ dataset and test on the WildDeepfake dataset. Experimental results show that our proposed method can achieve good performance, even exceeding GFF
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> 1.74%, SBI
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite> 1.03%, LTW
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite> 1.13%. The eer index of our method reaches 37.84%, only lagging behind EN-B4
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite> 0.63%, while our method achieved auc of 73.73% and eer of 33.75% when using centralized training. It has reached the SOTA level on both indicators. This is due to the designed personalized features containing more suitable properties of the client data set, further improving the applicability of complex forgery datasets with diverse types.</p>
</div>
<figure id="S4.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE V: </span>AUC (in %) and equal error rate (in %) of forgery detection performance on CelebDF-v2 dataset by several state-of-the-art methods. The best result is displayed in black font and the second place is underlined.</figcaption>
<table id="S4.T5.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T5.1.2" class="ltx_tr">
<td id="S4.T5.1.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Methods</td>
<td id="S4.T5.1.2.2" class="ltx_td ltx_align_center ltx_border_t">AUC(%)</td>
<td id="S4.T5.1.2.3" class="ltx_td ltx_align_center ltx_border_t">EER(%)</td>
</tr>
<tr id="S4.T5.1.3" class="ltx_tr">
<td id="S4.T5.1.3.1" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S4.T5.1.3.2" class="ltx_td ltx_align_center ltx_border_t" colspan="2"><span id="S4.T5.1.3.2.1" class="ltx_text ltx_font_bold">Without Considering Privacy</span></td>
</tr>
<tr id="S4.T5.1.4" class="ltx_tr">
<td id="S4.T5.1.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Capsule</td>
<td id="S4.T5.1.4.2" class="ltx_td ltx_align_center ltx_border_t">70.18</td>
<td id="S4.T5.1.4.3" class="ltx_td ltx_align_center ltx_border_t">-</td>
</tr>
<tr id="S4.T5.1.5" class="ltx_tr">
<td id="S4.T5.1.5.1" class="ltx_td ltx_align_center ltx_border_r">Xception</td>
<td id="S4.T5.1.5.2" class="ltx_td ltx_align_center">77.91</td>
<td id="S4.T5.1.5.3" class="ltx_td ltx_align_center">29.44</td>
</tr>
<tr id="S4.T5.1.6" class="ltx_tr">
<td id="S4.T5.1.6.1" class="ltx_td ltx_align_center ltx_border_r">Add-Net</td>
<td id="S4.T5.1.6.2" class="ltx_td ltx_align_center">62.12</td>
<td id="S4.T5.1.6.3" class="ltx_td ltx_align_center">41.51</td>
</tr>
<tr id="S4.T5.1.1" class="ltx_tr">
<td id="S4.T5.1.1.1" class="ltx_td ltx_align_center ltx_border_r">F<sup id="S4.T5.1.1.1.1" class="ltx_sup"><span id="S4.T5.1.1.1.1.1" class="ltx_text ltx_font_italic">3</span></sup>-Net</td>
<td id="S4.T5.1.1.2" class="ltx_td ltx_align_center">60.88</td>
<td id="S4.T5.1.1.3" class="ltx_td ltx_align_center">42.76</td>
</tr>
<tr id="S4.T5.1.7" class="ltx_tr">
<td id="S4.T5.1.7.1" class="ltx_td ltx_align_center ltx_border_r">Multi-Att</td>
<td id="S4.T5.1.7.2" class="ltx_td ltx_align_center">76.95</td>
<td id="S4.T5.1.7.3" class="ltx_td ltx_align_center">28.11</td>
</tr>
<tr id="S4.T5.1.8" class="ltx_tr">
<td id="S4.T5.1.8.1" class="ltx_td ltx_align_center ltx_border_r">PEL</td>
<td id="S4.T5.1.8.2" class="ltx_td ltx_align_center">82.94</td>
<td id="S4.T5.1.8.3" class="ltx_td ltx_align_center"><span id="S4.T5.1.8.3.1" class="ltx_text ltx_framed ltx_framed_underline">24.24</span></td>
</tr>
<tr id="S4.T5.1.9" class="ltx_tr">
<td id="S4.T5.1.9.1" class="ltx_td ltx_align_center ltx_border_r">FedPR (w/o FL)</td>
<td id="S4.T5.1.9.2" class="ltx_td ltx_align_center"><span id="S4.T5.1.9.2.1" class="ltx_text ltx_font_bold">83.95</span></td>
<td id="S4.T5.1.9.3" class="ltx_td ltx_align_center">24.83</td>
</tr>
<tr id="S4.T5.1.10" class="ltx_tr">
<td id="S4.T5.1.10.1" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S4.T5.1.10.2" class="ltx_td ltx_align_center ltx_border_t" colspan="2"><span id="S4.T5.1.10.2.1" class="ltx_text ltx_font_bold">Considering Privacy</span></td>
</tr>
<tr id="S4.T5.1.11" class="ltx_tr">
<td id="S4.T5.1.11.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">FedPR (Ours)</td>
<td id="S4.T5.1.11.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T5.1.11.2.1" class="ltx_text ltx_framed ltx_framed_underline">83.93</span></td>
<td id="S4.T5.1.11.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T5.1.11.3.1" class="ltx_text ltx_font_bold">23.65</span></td>
</tr>
</table>
</figure>
<div id="S4.SS3.p5" class="ltx_para">
<p id="S4.SS3.p5.1" class="ltx_p"><span id="S4.SS3.p5.1.1" class="ltx_text ltx_font_bold">Results on CelebDF-v2 dataset</span> As shown in TableÂ <a href="#S4.T5" title="TABLE V â€£ IV-C Comparison Results â€£ IV Experiments and Results â€£ Federated Face Forgery Detection Learning with Personalized Representation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a>, in order to further verify the generalization ability of this method, we trained on the WildDeepfake dataset and tested on the CelebDF-v2 dataset. Experimental results show that our proposed method can achieve high auc, even exceeding
Xception <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite> 6.02%, Multi-Att <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite> 6.98%, PEL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite> 0.99%. The eer index of our method reaches 23.65%, which is better than PEL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite> 0.59%. While our method uses centralized training, the auc reaches 83.95% and the eer reaches 24.83%. This is due to the designed personalized forgery representation learning, which can further explore more robust face forgery clues on complex forgery datasets with diverse types.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS4.4.1.1" class="ltx_text">IV-D</span> </span><span id="S4.SS4.5.2" class="ltx_text ltx_font_italic">Algorithm Analysis</span>
</h3>

<figure id="S4.F4" class="ltx_figure"><img src="/html/2406.11145/assets/x4.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="161" height="118" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Results of cross-validation on different training and testing subsets. The vertical axis represents training data, the horizontal axis represents testing data, and the evaluation index is accuracy. </figcaption>
</figure>
<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p"><span id="S4.SS4.p1.1.1" class="ltx_text ltx_font_bold">The effect of personalized features.</span>
To demonstrate that our proposed method can extract personalized representations of customers, we conducted cross-validation experiments on four subtypes included in the fake source hybrid dataset, and the results are shown in Figure <a href="#S4.F4" title="Figure 4 â€£ IV-D Algorithm Analysis â€£ IV Experiments and Results â€£ Federated Face Forgery Detection Learning with Personalized Representation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. It can be seen from Figure <a href="#S4.F4" title="Figure 4 â€£ IV-D Algorithm Analysis â€£ IV Experiments and Results â€£ Federated Face Forgery Detection Learning with Personalized Representation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> that the color of the diagonal part is the darkest, and the rest of the color is lighter. For example, the personalized model is trained on the client holding the CelebDF-v2 data set, where the forgery detection accuracy of the local client can reach 89.90% on the CelebDF-v2 data set.
But the detection accuracy for other clientsâ€™ data FF++_DF, FMFCC-V and WildDeepfake is poor. The same is true for other clients. This also proves that the personalized features contain more suitable properties of the client data set, further improving the applicability of complex forgery datasets with diverse types.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">As shown in Figure <a href="#S4.F5" title="Figure 5 â€£ IV-D Algorithm Analysis â€£ IV Experiments and Results â€£ Federated Face Forgery Detection Learning with Personalized Representation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, taking the CelebDF-v2 data set as an example, with personalized federated learning, the face forgery detection accuracy is 89.90%. Without personalized federated learning, the face forgery detection accuracy is 84.29%. The accuracy rate performance index dropped by 5.61%.
Taking the subset of FaceForensics++ (Referred to as FF++_DF) data set as an example, with personalized federated learning, the face forgery detection accuracy is 94.81%. Without personalized federated learning, the face forgery detection accuracy is 94.12%. The accuracy rate performance index dropped by 0.69%.
Taking the FMFCC-V data set as an example, with personalized federated learning, the face forgery detection accuracy is 99.60%. Without personalized federated learning, the face forgery detection accuracy is 99.36%. The accuracy rate performance index dropped by 0.24%.
Taking the WildDeepfake data set as an example, with personalized federated learning, the face forgery detection accuracy is 70.81%. While without personalized federated learning, the face forgery detection accuracy is 70.05%. The accuracy rate performance index dropped by 0.76%.
It can be seen that without leveraging personalized federated learning, individual clients show poor detection performance due to the lack of shared representation of multiple distributed client models.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2406.11145/assets/x5.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="184" height="137" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Cross-validation results on different training and testing subsets of the Forgery Source Hybrid Dataset without personalized federated learning. The vertical axis represents training data, the horizontal axis represents testing data, and the evaluation index is accuracy.</figcaption>
</figure>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.1" class="ltx_p"><span id="S4.SS4.p3.1.1" class="ltx_text ltx_font_bold">Ablation study.</span>
Our methods on the Deepforensics-1.0 in publicly available large-scale datasets
dataset achieved an accuracy of 97.29%. In the case of centralized data training, our method achieved an identification accuracy of 98.64%. On the CelebDF-v2 dataset, our method achieved an accuracy of 83.93% with centralized training. An accuracy of 83.95% was achieved, clearly proving that the proposed FedPR can further explore more robust face forgery clues. On the Forgery Source Hybrid Dataset, due to complex forgery datasets with diverse types, our method achieved SOTA. The results show that FedPR can not only help improve data security but also maintain strong performance in forgery detection tasks.</p>
</div>
<div id="S4.SS4.p4" class="ltx_para">
<p id="S4.SS4.p4.1" class="ltx_p">To verify the effectiveness of personalized federated learning, we have supplemented additional ablation experiment results as follows.
As shown in Table <a href="#S4.T6" title="TABLE VI â€£ IV-D Algorithm Analysis â€£ IV Experiments and Results â€£ Federated Face Forgery Detection Learning with Personalized Representation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a>, the result in the first row means that our method removes the personalized forgery representation learning. The accuracy rate on the Deepforensics-1.0 data set is 94.10%, which is poorer than using our federated face forgery detection learning with a personalized representation method.
Through this experimental result, we verified the effectiveness and advantages of personalized forgery representation. Our approach is able to take advantage of personalized forgery representation enable client models to explore more robust face forgery clues.
The result in the second row is our federated face forgery detection learning with a personalized representation method.
The method has an accuracy of 97.29% on the Deepforensics-1.0 data set.
Compared with the method without personalized forgery representation learning, our method improves the accuracy by 3.19%, it is demonstrated that the personalized features contain attributes that are more suitable for client datasets, further improving the applicability to different types of complex forged datasets.</p>
</div>
<figure id="S4.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE VI: </span>Ablation experimental results of Personalized Forgery Representation on the Deeperforensics-1.0 data set. The evaluation index is face forgery detection accuracy. The best result is displayed in black font and the second place is underlined.</figcaption>
<table id="S4.T6.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T6.1.1" class="ltx_tr">
<td id="S4.T6.1.1.1" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T6.1.1.1.1" class="ltx_text"></span> <span id="S4.T6.1.1.1.2" class="ltx_text">
<span id="S4.T6.1.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T6.1.1.1.2.1.1" class="ltx_tr">
<span id="S4.T6.1.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Personalized</span></span>
<span id="S4.T6.1.1.1.2.1.2" class="ltx_tr">
<span id="S4.T6.1.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Federated Learning</span></span>
</span></span><span id="S4.T6.1.1.1.3" class="ltx_text"></span></td>
<td id="S4.T6.1.1.2" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T6.1.1.2.1" class="ltx_text"></span> <span id="S4.T6.1.1.2.2" class="ltx_text">
<span id="S4.T6.1.1.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T6.1.1.2.2.1.1" class="ltx_tr">
<span id="S4.T6.1.1.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Personalized</span></span>
<span id="S4.T6.1.1.2.2.1.2" class="ltx_tr">
<span id="S4.T6.1.1.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Forgery Representation</span></span>
</span></span><span id="S4.T6.1.1.2.3" class="ltx_text"></span></td>
<td id="S4.T6.1.1.3" class="ltx_td ltx_align_center ltx_border_t">Accuracy(%)</td>
</tr>
<tr id="S4.T6.1.2" class="ltx_tr">
<td id="S4.T6.1.2.1" class="ltx_td ltx_align_center ltx_border_t">âœ“</td>
<td id="S4.T6.1.2.2" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S4.T6.1.2.3" class="ltx_td ltx_align_center ltx_border_t">94.10</td>
</tr>
<tr id="S4.T6.1.3" class="ltx_tr">
<td id="S4.T6.1.3.1" class="ltx_td ltx_align_center">-</td>
<td id="S4.T6.1.3.2" class="ltx_td ltx_align_center">âœ“</td>
<td id="S4.T6.1.3.3" class="ltx_td ltx_align_center"><span id="S4.T6.1.3.3.1" class="ltx_text ltx_font_bold">98.64</span></td>
</tr>
<tr id="S4.T6.1.4" class="ltx_tr">
<td id="S4.T6.1.4.1" class="ltx_td ltx_align_center ltx_border_b">âœ“</td>
<td id="S4.T6.1.4.2" class="ltx_td ltx_align_center ltx_border_b">âœ“</td>
<td id="S4.T6.1.4.3" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T6.1.4.3.1" class="ltx_text ltx_framed ltx_framed_underline">97.29</span></td>
</tr>
</table>
</figure>
</section>
</section>
<section id="S5" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Conclusions</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper, we explore federated face forgery detection learning with personalized representation, which further explores more robust face forgery clues by combining the shared representation of multiple distributed client models. Furthermore, to improve the applicability of complex forgery datasets with diverse types, the designed personalized forgery representation learning framework can disentangle shared features and personalized features. The personalized features contain more suitable properties of the client data set, further improving the applicability of complex forgery datasets with diverse types. We conducted experiments on public face forgery detection datasets, and the experimental results show that this algorithm can effectively improve the generalization ability of complex forgery datasets with diverse types while protecting privacy. In the future, we will explore extending the personalized federated learning method to cross-modal forgery detection problems, such as combining image and voice information for forgery detection. Through the fusion of cross-modal information and federated learning, the performance and robustness of forgery detection can be further improved. Furthermore, the application of personalized representation in other fields is also worth studying.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
L.Â Chai, D.Â Bau, S.-N. Lim, and P.Â Isola, â€œWhat makes fake images detectable? understanding properties that generalize,â€ in <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Computer Visionâ€“ECCV 2020: 16th European Conference, Glasgow, UK, August 23â€“28, 2020, Proceedings, Part XXVI 16</em>.Â Â Â Springer, 2020, pp. 103â€“120.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
L.Â Li, J.Â Bao, T.Â Zhang, H.Â Yang, D.Â Chen, F.Â Wen, and B.Â Guo, â€œFace x-ray for more general face forgery detection,â€ in <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, 2020, pp. 5001â€“5010.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
I.Â Masi, A.Â Killekar, R.Â M. Mascarenhas, S.Â P. Gurudatt, and W.Â AbdAlmageed, â€œTwo-branch recurrent network for isolating deepfakes in videos,â€ in <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Computer Visionâ€“ECCV 2020: 16th European Conference, Glasgow, UK, August 23â€“28, 2020, Proceedings, Part VII 16</em>.Â Â Â Springer, 2020, pp. 667â€“684.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
D.Â Liu, Z.Â Dang, C.Â Peng, Y.Â Zheng, S.Â Li, N.Â Wang, and X.Â Gao, â€œFedforgery: generalized face forgery detection with residual federated learning,â€ <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics and Security</em>, 2023.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
L.Â Collins, H.Â Hassani, A.Â Mokhtari, and S.Â Shakkottai, â€œExploiting shared representations for personalized federated learning,â€ in <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">International conference on machine learning</em>.Â Â Â PMLR, 2021, pp. 2089â€“2099.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
X.Â Yang, Y.Â Li, and S.Â Lyu, â€œExposing deep fakes using inconsistent head poses,â€ in <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>.Â Â Â IEEE, 2019, pp. 8261â€“8265.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
T.Â Yang, J.Â Cao, Q.Â Sheng, L.Â Li, J.Â Ji, X.Â Li, and S.Â Tang, â€œLearning to disentangle gan fingerprint for fake image attribution,â€ <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2106.08749</em>, 2021.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Y.Â Luo, Y.Â Zhang, J.Â Yan, and W.Â Liu, â€œGeneralizing face forgery detection with high-frequency features,â€ in <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, 2021, pp. 16â€‰317â€“16â€‰326.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
H.Â Dang, F.Â Liu, J.Â Stehouwer, X.Â Liu, and A.Â K. Jain, â€œOn the detection of digital face manipulation,â€ in <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern recognition</em>, 2020, pp. 5781â€“5790.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Y.Â Nirkin, L.Â Wolf, Y.Â Keller, and T.Â Hassner, â€œDeepfake detection based on the discrepancy between the face and its context,â€ <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2008.12262</em>, 2020.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Y.Â Li and S.Â Lyu, â€œExposing deepfake videos by detecting face warping artifacts,â€ <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1811.00656</em>, 2018.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Y.Â Qian, G.Â Yin, L.Â Sheng, Z.Â Chen, and J.Â Shao, â€œThinking in frequency: Face forgery detection by mining frequency-aware clues,â€ in <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">European conference on computer vision</em>.Â Â Â Springer, 2020, pp. 86â€“103.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Z.Â Chen and H.Â Yang, â€œManipulated face detector: Joint spatial and frequency domain attention network,â€ <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2005.02958</em>, vol.Â 1, no.Â 2, p.Â 4, 2020.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
J.Â Cao, C.Â Ma, T.Â Yao, S.Â Chen, S.Â Ding, and X.Â Yang, â€œEnd-to-end reconstruction-classification learning for face forgery detection,â€ in <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2022, pp. 4113â€“4122.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
A.Â Luo, C.Â Kong, J.Â Huang, Y.Â Hu, X.Â Kang, and A.Â C. Kot, â€œBeyond the prior forgery knowledge: Mining critical clues for general face forgery detection,â€ <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics and Security</em>, vol.Â 19, pp. 1168â€“1182, 2024.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
C.Â Miao, Z.Â Tan, Q.Â Chu, H.Â Liu, H.Â Hu, and N.Â Yu, â€œF2trans: High-frequency fine-grained transformer for face forgery detection,â€ <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics and Security</em>, vol.Â 18, pp. 1039â€“1051, 2023.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
J.Â Tian, P.Â Chen, C.Â Yu, X.Â Fu, X.Â Wang, J.Â Dai, and J.Â Han, â€œLearning to discover forgery cues for face forgery detection,â€ <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics and Security</em>, 2024.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Y.Â Hua, R.Â Shi, P.Â Wang, and S.Â Ge, â€œLearning patch-channel correspondence for interpretable face forgery detection,â€ <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Image Processing</em>, vol.Â 32, pp. 1668â€“1680, 2023.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
B.Â Yu, X.Â Li, W.Â Li, J.Â Zhou, and J.Â Lu, â€œDiscrepancy-aware meta-learning for zero-shot face manipulation detection,â€ <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Image Processing</em>, vol.Â 32, pp. 3759â€“3773, 2023.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Z.Â Gu, Y.Â Chen, T.Â Yao, S.Â Ding, J.Â Li, F.Â Huang, and L.Â Ma, â€œSpatiotemporal inconsistency learning for deepfake video detection,â€ in <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 29th ACM international conference on multimedia</em>, 2021, pp. 3473â€“3481.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Z.Â Sun, Y.Â Han, Z.Â Hua, N.Â Ruan, and W.Â Jia, â€œImproving the efficiency and robustness of deepfakes detection through precise geometric features,â€ in <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2021, pp. 3609â€“3618.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
C.Â M. Liy and L.Â InIctuOculi, â€œExposingaicreated fakevideosbydetectingeyeblinking,â€ in <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 IEEE International workshop on information forensics and security (WIFS), Hong Kong, China</em>, 2018, pp. 11â€“13.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
U.Â A. Ciftci, I.Â Demir, and L.Â Yin, â€œFakecatcher: Detection of synthetic portrait videos using biological signals,â€ <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on pattern analysis and machine intelligence</em>, 2020.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
I.Â Ganiyusufoglu, L.Â M. NgÃ´, N.Â Savov, S.Â Karaoglu, and T.Â Gevers, â€œSpatio-temporal features for generalized detection of deepfake videos,â€ <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.11844</em>, 2020.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
C.Â Peng, Z.Â Miao, D.Â Liu, N.Â Wang, R.Â Hu, and X.Â Gao, â€œWhere deepfakes gaze at? spatial-temporal gaze inconsistency analysis for video face forgery detection,â€ <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics and Security</em>, 2024.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Y.Â Wang, C.Â Peng, D.Â Liu, N.Â Wang, and X.Â Gao, â€œSpatial-temporal frequency forgery clue for video forgery detection in vis and nir scenario,â€ <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Circuits and Systems for Video Technology</em>, 2023.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
B.Â Ding, Z.Â Fan, Z.Â Zhao, and S.Â Xia, â€œMining collaborative spatio-temporal clues for face forgery detection,â€ <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Multimedia Tools and Applications</em>, vol.Â 83, no.Â 9, pp. 27â€‰901â€“27â€‰920, 2024.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
X.Â Liu, S.Â Gao, P.Â Zhou, J.Â Liu, X.Â Luo, L.Â Zhang, and B.Â Zhang, â€œHybrid spatio-temporal network for face forgery detection,â€ in <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Asian Conference on Pattern Recognition</em>.Â Â Â Springer, 2023, pp. 250â€“264.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
C.Â Zhao, C.Â Wang, G.Â Hu, H.Â Chen, C.Â Liu, and J.Â Tang, â€œIstvt: interpretable spatial-temporal video transformer for deepfake detection,â€ <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics and Security</em>, vol.Â 18, pp. 1335â€“1348, 2023.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
B.Â McMahan, E.Â Moore, D.Â Ramage, S.Â Hampson, and B.Â A. yÂ Arcas, â€œCommunication-efficient learning of deep networks from decentralized data,â€ in <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Artificial intelligence and statistics</em>.Â Â Â PMLR, 2017, pp. 1273â€“1282.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
N.Â Yoshida, T.Â Nishio, M.Â Morikura, K.Â Yamamoto, and R.Â Yonetani, â€œHybrid-fl for wireless networks: Cooperative learning mechanism using non-iid data,â€ in <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">ICC 2020-2020 IEEE International Conference On Communications (ICC)</em>.Â Â Â IEEE, 2020, pp. 1â€“7.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
M.Â R. Sprague, A.Â Jalalirad, M.Â Scavuzzo, C.Â Capota, M.Â Neun, L.Â Do, and M.Â Kopp, â€œAsynchronous federated learning for geospatial applications,â€ in <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Joint European Conference on Machine Learning and Knowledge Discovery in Databases</em>.Â Â Â Springer, 2018, pp. 21â€“28.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
H.Â Wang, M.Â Yurochkin, Y.Â Sun, D.Â Papailiopoulos, and Y.Â Khazaeni, â€œFederated learning with matched averaging,â€ <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.06440</em>, 2020.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Y.Â Bengio, A.Â Courville, and P.Â Vincent, â€œRepresentation learning: A review and new perspectives,â€ <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on pattern analysis and machine intelligence</em>, vol.Â 35, no.Â 8, pp. 1798â€“1828, 2013.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Y.Â LeCun, Y.Â Bengio, and G.Â Hinton, â€œDeep learning,â€ <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">nature</em>, vol. 521, no. 7553, pp. 436â€“444, 2015.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
A.Â Z. Tan, H.Â Yu, L.Â Cui, and Q.Â Yang, â€œTowards personalized federated learning,â€ <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Neural Networks and Learning Systems</em>, 2022.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
X.Â Huang and S.Â Belongie, â€œArbitrary style transfer in real-time with adaptive instance normalization,â€ in <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE international conference on computer vision</em>, 2017, pp. 1501â€“1510.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
A.Â Rossler, D.Â Cozzolino, L.Â Verdoliva, C.Â Riess, J.Â Thies, and M.Â NieÃŸner, â€œFaceforensics++: Learning to detect manipulated facial images,â€ in <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF international conference on computer vision</em>, 2019, pp. 1â€“11.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
B.Â Zi, M.Â Chang, J.Â Chen, X.Â Ma, and Y.-G. Jiang, â€œWilddeepfake: A challenging real-world dataset for deepfake detection,â€ in <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th ACM international conference on multimedia</em>, 2020, pp. 2382â€“2390.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Y.Â Li, X.Â Yang, P.Â Sun, H.Â Qi, and S.Â Lyu, â€œCeleb-df (v2): a new dataset for deepfake forensics [j],â€ <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv</em>, 2019.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
L.Â Jiang, R.Â Li, W.Â Wu, C.Â Qian, and C.Â C. Loy, â€œDeeperforensics-1.0: A large-scale dataset for real-world face forgery detection,â€ in <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, 2020, pp. 2889â€“2898.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
G.Â Li, X.Â Zhao, Y.Â Cao, P.Â Pei, J.Â Li, and Z.Â Zhang, â€œFmfcc-v: An asian large-scale challenging dataset for deepfake detection,â€ in <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 ACM Workshop on Information Hiding and Multimedia Security</em>, 2022, pp. 7â€“18.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
C.Â JEONG and T.Â KIM, â€œEye blink detection using algorithm based on dlib and opencv library for game players in competitive environments,â€ <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">Journal of International Research in Medical and Pharmaceutical Sciences</em>, pp. 33â€“45, 2021.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
S.Â Dong, J.Â Wang, R.Â Ji, J.Â Liang, H.Â Fan, and Z.Â Ge, â€œImplicit identity leakage: The stumbling block to improving deepfake detection generalization,â€ in <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2023, pp. 3994â€“4004.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
C.Â Wang and W.Â Deng, â€œRepresentative forgery mining for fake face detection,â€ in <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, 2021, pp. 14â€‰923â€“14â€‰932.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
S.-Y. Wang, O.Â Wang, R.Â Zhang, A.Â Owens, and A.Â A. Efros, â€œCnn-generated images are surprisingly easy to spotâ€¦ for now,â€ in <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, 2020, pp. 8695â€“8704.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
K.Â He, X.Â Zhang, S.Â Ren, and J.Â Sun, â€œDeep residual learning for image recognition,â€ in <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and pattern recognition</em>, 2016, pp. 770â€“778.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
S.Â Hochreiter and J.Â Schmidhuber, â€œLong short-term memory,â€ <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">Neural computation</em>, vol.Â 9, no.Â 8, pp. 1735â€“1780, 1997.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
F.Â Chollet, â€œXception: Deep learning with depthwise separable convolutions,â€ in <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and pattern recognition</em>, 2017, pp. 1251â€“1258.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
J.Â Carreira and A.Â Zisserman, â€œQuo vadis, action recognition? a new model and the kinetics dataset,â€ in <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>, 2017, pp. 6299â€“6308.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
K.Â Shiohara and T.Â Yamasaki, â€œDetecting deepfakes with self-blended images,â€ in <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2022, pp. 18â€‰720â€“18â€‰729.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
K.Â Sun, H.Â Liu, Q.Â Ye, Y.Â Gao, J.Â Liu, L.Â Shao, and R.Â Ji, â€œDomain general face forgery detection by learning to weight,â€ in <em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI conference on artificial intelligence</em>, vol.Â 35, no.Â 3, 2021, pp. 2638â€“2646.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
M.Â Tan and Q.Â Le, â€œEfficientnet: Rethinking model scaling for convolutional neural networks,â€ in <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">International conference on machine learning</em>.Â Â Â PMLR, 2019, pp. 6105â€“6114.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
H.Â H. Nguyen, F.Â Fang, J.Â Yamagishi, and I.Â Echizen, â€œMulti-task learning for detecting and segmenting manipulated facial images and videos,â€ in <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">2019 IEEE 10th international conference on biometrics theory, applications and systems (BTAS)</em>.Â Â Â IEEE, 2019, pp. 1â€“8.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Q.Â Gu, S.Â Chen, T.Â Yao, Y.Â Chen, S.Â Ding, and R.Â Yi, â€œExploiting fine-grained face forgery clues via progressive enhancement learning,â€ in <em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</em>, vol.Â 36, no.Â 1, 2022, pp. 735â€“743.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2406.11144" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2406.11145" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2406.11145">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2406.11145" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2406.11146" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Jul  5 19:04:47 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
