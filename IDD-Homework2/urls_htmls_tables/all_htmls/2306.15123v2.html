<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2306.15123] Investigating Cross-Domain Behaviors of BERT in Review Understanding</title><meta property="og:description" content="Review score prediction requires review text understanding, a critical real-world application of natural language processing. Due to dissimilar text domains in product reviews, a common practice is fine-tuning BERT mod…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Investigating Cross-Domain Behaviors of BERT in Review Understanding">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Investigating Cross-Domain Behaviors of BERT in Review Understanding">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2306.15123">

<!--Generated on Wed Feb 28 22:30:38 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Investigating Cross-Domain Behaviors of BERT in Review Understanding</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Albert Lu 
<br class="ltx_break">University of Notre Dame 
<br class="ltx_break">Notre Dame, IN 46556, USA 
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter">albertlu0310@gmail.com</span> 
<br class="ltx_break"><span id="id2.2.id2" class="ltx_ERROR undefined">\And</span>Meng Jiang 
<br class="ltx_break">University of Notre Dame 
<br class="ltx_break">Notre Dame, IN 46556, USA 
<br class="ltx_break"><span id="id3.3.id3" class="ltx_text ltx_font_typewriter">mjiang2@nd.edu</span> 
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id4.id1" class="ltx_p">Review score prediction requires review text understanding, a critical real-world application of natural language processing. Due to dissimilar text domains in product reviews, a common practice is fine-tuning BERT models upon reviews of differing domains. However, there has not yet been an empirical study of cross-domain behaviors of BERT models in the various tasks of product review understanding. In this project, we investigate text classification BERT models fine-tuned on single-domain and multi-domain Amazon review data. In our findings, though single-domain models achieved marginally improved performance on their corresponding domain compared to multi-domain models, multi-domain models outperformed single-domain models when evaluated on multi-domain data, single-domain data the single-domain model was not fine-tuned on, and on average when considering all tests. Though slight increases in accuracy can be achieved through single-domain model fine-tuning, computational resources and costs can be reduced by utilizing multi-domain models that perform well across domains.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<figure id="S1.F1" class="ltx_figure"><img src="/html/2306.15123/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="410" height="293" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Seven datasets with varying combinations of domains were made, all of the same size. BERT models were trained upon all datasets and cross-domain tested. We investigate behaviors where the fine-tuning and testing domains are not fully aligned.</figcaption>
</figure>
<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Online services such as Amazon and Target have review systems where users can provide comments and ratings for products, offering valuable information to both buyers and companies. Analyzing the large volume of review data manually is impractical, so companies use data science and machine learning to extract knowledge efficiently  <cite class="ltx_cite ltx_citemacro_cite">AlZu’bi et al. (<a href="#bib.bib2" title="" class="ltx_ref">2019</a>)</cite>. An important task in review understanding is review score prediction, akin to sentiment analysis, where the text of a review is used to determine the corresponding star rating. Review score prediction aids in distinguishing between the sentiment conveyed by the star rating and the sentiment expressed in the text, addressing potential biases and ensuring accurate ratings  <cite class="ltx_cite ltx_citemacro_cite">Ul Haque et al. (<a href="#bib.bib19" title="" class="ltx_ref">2018</a>); Ibrahim Elmurngi and Gherbi (<a href="#bib.bib8" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Bidirectional encoder representations from transformers (BERT) models, a model set for natural language understanding, can be fine-tuned to predict star ratings based on review text <cite class="ltx_cite ltx_citemacro_cite">Devlin et al. (<a href="#bib.bib4" title="" class="ltx_ref">2019</a>)</cite>. BERT utilizes a transformer architecture, processing an entire text sequence at once, capturing contextual relationships between words. BERT consists of stacked transformer encoder layers with self-attention mechanisms and is pre-trained on two tasks: masked language modeling and next sentence prediction. After general pre-training, BERT is fine-tuned for specific downstream tasks by adding task-specific layers and adjusting neural network weights based on labeled data <cite class="ltx_cite ltx_citemacro_cite">Devlin et al. (<a href="#bib.bib4" title="" class="ltx_ref">2019</a>)</cite>, where rating score prediction is one of the popular downstream tasks.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">The existence of multiple domains poses a significant challenge for review score prediction. Platforms like Amazon have diverse product categories, requiring models to analyze reviews for each domain separately. Though cross-domain models have been created, it remains unclear whether a single model can perform optimally across all domains  <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a href="#bib.bib11" title="" class="ltx_ref">2021</a>); Al-Moslmi et al. (<a href="#bib.bib1" title="" class="ltx_ref">2017</a>)</cite>. To address this, BERT can be fine-tuned using training sets specific to a domain or a mixture of training sets from various domains <cite class="ltx_cite ltx_citemacro_cite">Sushil et al. (<a href="#bib.bib17" title="" class="ltx_ref">2021</a>)</cite>. Fine-tuning with domain-specific data allows models to focus on predicting the relevant data they encounter, avoiding the counterproductive task of predicting irrelevant domains. However, training individual domain-specific models increases resource use compared to training a single model for multiple domains, assuming the multi-domain model performs well in different domains. To understand the trade-offs between a specific versus general approach for multiple domains, an empirical study analyzing BERT’s cross-domain behaviors in review understanding is necessary.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">We use data from three Amazon review domains to form seven datasets, fine-tuning from them seven BERT models. Each BERT model was evaluated upon every dataset in a round-robin format. Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Investigating Cross-Domain Behaviors of BERT in Review Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and the Methods section describe our study design with details about data processing and model fine-tuning.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Below briefly are our observations. Predictions made before experimentation included that, though it would be possible to fine-tune BERT models to specialize on a certain domain, the benefit from single-domain fine-tuning would be minor. Also predicted was that multi-domain models would achieve a higher performance when evaluated on single-domain datasets compared to single-domain models not trained upon that specific domain. Observations lined up with predictions. Though BERT models were able to achieve domain specificity, the gains in performance towards single domains
were slight. Moreover, the specificity gained appears to have decreased the single-domain models’ ability to predict on other domains. Multi-domain models outperformed single-domain models on all categories besides the specific domain the single-domain models had been fine-tuned on, as well as achieving a higher average accuracy across all datasets. In addition, multi-domain models performed better on the multi-domain datasets the models were trained with compared to the single-domain models and their corresponding single-domain datasets. Towards applications in review analysis, review score prediction, and sentiment analysis, it appears that, though marginal performance improvements can be achieved through single-domain, specific fine-tuning, computational resources can be saved through training cross-domain models that achieve a high level of performance for all domains.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Method of Our Study</h2>

<figure id="S2.T1" class="ltx_table">
<table id="S2.T1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S2.T1.1.1.1" class="ltx_tr">
<td id="S2.T1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">Model</td>
<td id="S2.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="7">Model was evaluated on test sets in: (<span id="S2.T1.1.1.1.2.1" class="ltx_text ltx_font_bold">RMSE: smaller is better</span>)</td>
<td id="S2.T1.1.1.1.3" class="ltx_td ltx_border_tt"></td>
</tr>
<tr id="S2.T1.1.2.2" class="ltx_tr">
<td id="S2.T1.1.2.2.1" class="ltx_td ltx_align_left ltx_border_r">(was trained in)</td>
<td id="S2.T1.1.2.2.2" class="ltx_td ltx_align_center">Auto</td>
<td id="S2.T1.1.2.2.3" class="ltx_td ltx_align_center">Garden</td>
<td id="S2.T1.1.2.2.4" class="ltx_td ltx_align_center">Music</td>
<td id="S2.T1.1.2.2.5" class="ltx_td ltx_align_center">A+G</td>
<td id="S2.T1.1.2.2.6" class="ltx_td ltx_align_center">G+M</td>
<td id="S2.T1.1.2.2.7" class="ltx_td ltx_align_center">A+M</td>
<td id="S2.T1.1.2.2.8" class="ltx_td ltx_align_center ltx_border_r">A+G+M</td>
<td id="S2.T1.1.2.2.9" class="ltx_td ltx_align_right">Average</td>
</tr>
<tr id="S2.T1.1.3.3" class="ltx_tr">
<td id="S2.T1.1.3.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Auto</td>
<td id="S2.T1.1.3.3.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.1.3.3.2.1" class="ltx_text ltx_framed ltx_framed_underline">0.640</span></td>
<td id="S2.T1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_t">0.742</td>
<td id="S2.T1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_t">0.781</td>
<td id="S2.T1.1.3.3.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#D9D9FF;"><span id="S2.T1.1.3.3.5.1" class="ltx_text" style="background-color:#D9D9FF;">0.678</span></td>
<td id="S2.T1.1.3.3.6" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FFD9D9;"><span id="S2.T1.1.3.3.6.1" class="ltx_text" style="background-color:#FFD9D9;">0.721</span></td>
<td id="S2.T1.1.3.3.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FFD9D9;"><span id="S2.T1.1.3.3.7.1" class="ltx_text" style="background-color:#FFD9D9;">0.632</span></td>
<td id="S2.T1.1.3.3.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFD9D9;"><span id="S2.T1.1.3.3.8.1" class="ltx_text" style="background-color:#FFD9D9;">0.711</span></td>
<td id="S2.T1.1.3.3.9" class="ltx_td ltx_align_right ltx_border_t">0.701</td>
</tr>
<tr id="S2.T1.1.4.4" class="ltx_tr">
<td id="S2.T1.1.4.4.1" class="ltx_td ltx_align_left ltx_border_r">Garden</td>
<td id="S2.T1.1.4.4.2" class="ltx_td ltx_align_center"><span id="S2.T1.1.4.4.2.1" class="ltx_text ltx_font_bold">0.624</span></td>
<td id="S2.T1.1.4.4.3" class="ltx_td ltx_align_center"><span id="S2.T1.1.4.4.3.1" class="ltx_text ltx_framed ltx_framed_underline">0.721</span></td>
<td id="S2.T1.1.4.4.4" class="ltx_td ltx_align_center">0.854</td>
<td id="S2.T1.1.4.4.5" class="ltx_td ltx_align_center" style="background-color:#FFD9D9;"><span id="S2.T1.1.4.4.5.1" class="ltx_text" style="background-color:#FFD9D9;">0.707</span></td>
<td id="S2.T1.1.4.4.6" class="ltx_td ltx_align_center" style="background-color:#FFD9D9;"><span id="S2.T1.1.4.4.6.1" class="ltx_text" style="background-color:#FFD9D9;">0.787</span></td>
<td id="S2.T1.1.4.4.7" class="ltx_td ltx_align_center" style="background-color:#FFD9D9;"><span id="S2.T1.1.4.4.7.1" class="ltx_text" style="background-color:#FFD9D9;">0.648</span></td>
<td id="S2.T1.1.4.4.8" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#FFD9D9;"><span id="S2.T1.1.4.4.8.1" class="ltx_text" style="background-color:#FFD9D9;">0.724</span></td>
<td id="S2.T1.1.4.4.9" class="ltx_td ltx_align_right">0.724</td>
</tr>
<tr id="S2.T1.1.5.5" class="ltx_tr">
<td id="S2.T1.1.5.5.1" class="ltx_td ltx_align_left ltx_border_r">Music</td>
<td id="S2.T1.1.5.5.2" class="ltx_td ltx_align_center">0.860</td>
<td id="S2.T1.1.5.5.3" class="ltx_td ltx_align_center">0.781</td>
<td id="S2.T1.1.5.5.4" class="ltx_td ltx_align_center"><span id="S2.T1.1.5.5.4.1" class="ltx_text ltx_framed ltx_framed_underline">0.728</span></td>
<td id="S2.T1.1.5.5.5" class="ltx_td ltx_align_center" style="background-color:#FFD9D9;"><span id="S2.T1.1.5.5.5.1" class="ltx_text" style="background-color:#FFD9D9;">0.860</span></td>
<td id="S2.T1.1.5.5.6" class="ltx_td ltx_align_center" style="background-color:#FFD9D9;"><span id="S2.T1.1.5.5.6.1" class="ltx_text" style="background-color:#FFD9D9;">0.714</span></td>
<td id="S2.T1.1.5.5.7" class="ltx_td ltx_align_center" style="background-color:#FFD9D9;"><span id="S2.T1.1.5.5.7.1" class="ltx_text" style="background-color:#FFD9D9;">0.806</span></td>
<td id="S2.T1.1.5.5.8" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#FFD9D9;"><span id="S2.T1.1.5.5.8.1" class="ltx_text" style="background-color:#FFD9D9;">0.783</span></td>
<td id="S2.T1.1.5.5.9" class="ltx_td ltx_align_right">0.790</td>
</tr>
<tr id="S2.T1.1.6.6" class="ltx_tr">
<td id="S2.T1.1.6.6.1" class="ltx_td ltx_align_left ltx_border_r">A+G</td>
<td id="S2.T1.1.6.6.2" class="ltx_td ltx_align_center" style="background-color:#FFD9D9;"><span id="S2.T1.1.6.6.2.1" class="ltx_text" style="background-color:#FFD9D9;">0.721</span></td>
<td id="S2.T1.1.6.6.3" class="ltx_td ltx_align_center" style="background-color:#D9D9FF;"><span id="S2.T1.1.6.6.3.1" class="ltx_text" style="background-color:#D9D9FF;">0.707</span></td>
<td id="S2.T1.1.6.6.4" class="ltx_td ltx_align_center" style="background-color:#FFD9D9;"><span id="S2.T1.1.6.6.4.1" class="ltx_text" style="background-color:#FFD9D9;">0.794</span></td>
<td id="S2.T1.1.6.6.5" class="ltx_td ltx_align_center"><span id="S2.T1.1.6.6.5.1" class="ltx_text ltx_framed ltx_framed_underline">0.686</span></td>
<td id="S2.T1.1.6.6.6" class="ltx_td ltx_align_center">0.643</td>
<td id="S2.T1.1.6.6.7" class="ltx_td ltx_align_center">0.632</td>
<td id="S2.T1.1.6.6.8" class="ltx_td ltx_align_center ltx_border_r">0.663</td>
<td id="S2.T1.1.6.6.9" class="ltx_td ltx_align_right">0.691</td>
</tr>
<tr id="S2.T1.1.7.7" class="ltx_tr">
<td id="S2.T1.1.7.7.1" class="ltx_td ltx_align_left ltx_border_r">G+M</td>
<td id="S2.T1.1.7.7.2" class="ltx_td ltx_align_center" style="background-color:#FFD9D9;"><span id="S2.T1.1.7.7.2.1" class="ltx_text" style="background-color:#FFD9D9;">0.714</span></td>
<td id="S2.T1.1.7.7.3" class="ltx_td ltx_align_center" style="background-color:#D9D9FF;"><span id="S2.T1.1.7.7.3.1" class="ltx_text ltx_font_bold" style="background-color:#D9D9FF;">0.700</span></td>
<td id="S2.T1.1.7.7.4" class="ltx_td ltx_align_center" style="background-color:#FFD9D9;"><span id="S2.T1.1.7.7.4.1" class="ltx_text" style="background-color:#FFD9D9;">0.794</span></td>
<td id="S2.T1.1.7.7.5" class="ltx_td ltx_align_center">0.686</td>
<td id="S2.T1.1.7.7.6" class="ltx_td ltx_align_center"><span id="S2.T1.1.7.7.6.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">0.640</span></td>
<td id="S2.T1.1.7.7.7" class="ltx_td ltx_align_center">0.632</td>
<td id="S2.T1.1.7.7.8" class="ltx_td ltx_align_center ltx_border_r">0.661</td>
<td id="S2.T1.1.7.7.9" class="ltx_td ltx_align_right">0.689</td>
</tr>
<tr id="S2.T1.1.8.8" class="ltx_tr">
<td id="S2.T1.1.8.8.1" class="ltx_td ltx_align_left ltx_border_r">A+M</td>
<td id="S2.T1.1.8.8.2" class="ltx_td ltx_align_center" style="background-color:#FFD9D9;"><span id="S2.T1.1.8.8.2.1" class="ltx_text" style="background-color:#FFD9D9;">0.748</span></td>
<td id="S2.T1.1.8.8.3" class="ltx_td ltx_align_center" style="background-color:#FFD9D9;"><span id="S2.T1.1.8.8.3.1" class="ltx_text" style="background-color:#FFD9D9;">0.806</span></td>
<td id="S2.T1.1.8.8.4" class="ltx_td ltx_align_center" style="background-color:#D9D9FF;"><span id="S2.T1.1.8.8.4.1" class="ltx_text ltx_font_bold" style="background-color:#D9D9FF;">0.707</span></td>
<td id="S2.T1.1.8.8.5" class="ltx_td ltx_align_center">0.735</td>
<td id="S2.T1.1.8.8.6" class="ltx_td ltx_align_center">0.693</td>
<td id="S2.T1.1.8.8.7" class="ltx_td ltx_align_center"><span id="S2.T1.1.8.8.7.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">0.616</span></td>
<td id="S2.T1.1.8.8.8" class="ltx_td ltx_align_center ltx_border_r">0.731</td>
<td id="S2.T1.1.8.8.9" class="ltx_td ltx_align_right">0.719</td>
</tr>
<tr id="S2.T1.1.9.9" class="ltx_tr">
<td id="S2.T1.1.9.9.1" class="ltx_td ltx_align_left ltx_border_r">A+G+M</td>
<td id="S2.T1.1.9.9.2" class="ltx_td ltx_align_center" style="background-color:#FFD9D9;"><span id="S2.T1.1.9.9.2.1" class="ltx_text" style="background-color:#FFD9D9;">0.678</span></td>
<td id="S2.T1.1.9.9.3" class="ltx_td ltx_align_center" style="background-color:#D9D9FF;"><span id="S2.T1.1.9.9.3.1" class="ltx_text" style="background-color:#D9D9FF;">0.714</span></td>
<td id="S2.T1.1.9.9.4" class="ltx_td ltx_align_center" style="background-color:#D9D9FF;"><span id="S2.T1.1.9.9.4.1" class="ltx_text" style="background-color:#D9D9FF;">0.714</span></td>
<td id="S2.T1.1.9.9.5" class="ltx_td ltx_align_center"><span id="S2.T1.1.9.9.5.1" class="ltx_text ltx_font_bold">0.663</span></td>
<td id="S2.T1.1.9.9.6" class="ltx_td ltx_align_center">0.641</td>
<td id="S2.T1.1.9.9.7" class="ltx_td ltx_align_center">0.624</td>
<td id="S2.T1.1.9.9.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S2.T1.1.9.9.8.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">0.660</span></td>
<td id="S2.T1.1.9.9.9" class="ltx_td ltx_align_right"><span id="S2.T1.1.9.9.9.1" class="ltx_text ltx_font_bold">0.670</span></td>
</tr>
<tr id="S2.T1.1.10.10" class="ltx_tr">
<td id="S2.T1.1.10.10.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t">Average</td>
<td id="S2.T1.1.10.10.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.712</td>
<td id="S2.T1.1.10.10.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.739</td>
<td id="S2.T1.1.10.10.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.767</td>
<td id="S2.T1.1.10.10.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.716</td>
<td id="S2.T1.1.10.10.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.691</td>
<td id="S2.T1.1.10.10.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.656</td>
<td id="S2.T1.1.10.10.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">0.704</td>
<td id="S2.T1.1.10.10.9" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t">Best avg: 0.659</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Results from a comprehensive investigation on cross-domain review score prediction using BERT models.</figcaption>
</figure>
<figure id="S2.T2" class="ltx_table">
<table id="S2.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T2.1.1.1" class="ltx_tr">
<th id="S2.T2.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_rr ltx_border_tt">Model</th>
<th id="S2.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">Self</th>
<th id="S2.T2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">All</th>
<th id="S2.T2.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="2">Specific</th>
<th id="S2.T2.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="2">Semi-Specific</th>
<th id="S2.T2.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">General</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T2.1.2.1" class="ltx_tr">
<td id="S2.T2.1.2.1.1" class="ltx_td ltx_align_left ltx_border_rr">specificity</td>
<td id="S2.T2.1.2.1.2" class="ltx_td ltx_border_r"></td>
<td id="S2.T2.1.2.1.3" class="ltx_td ltx_border_r"></td>
<td id="S2.T2.1.2.1.4" class="ltx_td ltx_align_center">Familiar</td>
<td id="S2.T2.1.2.1.5" class="ltx_td ltx_align_center ltx_border_r">Unfamiliar</td>
<td id="S2.T2.1.2.1.6" class="ltx_td ltx_align_center">Familiar</td>
<td id="S2.T2.1.2.1.7" class="ltx_td ltx_align_center ltx_border_r">Unfamiliar</td>
<td id="S2.T2.1.2.1.8" class="ltx_td"></td>
</tr>
<tr id="S2.T2.1.3.2" class="ltx_tr">
<th id="S2.T2.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_rr ltx_border_t">Specific</th>
<th id="S2.T2.1.3.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">0.696</th>
<th id="S2.T2.1.3.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">0.739</th>
<th id="S2.T2.1.3.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S2.T2.1.3.2.4.1" class="ltx_text ltx_font_bold">0.696</span></th>
<th id="S2.T2.1.3.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S2.T2.1.3.2.5.1" class="ltx_text ltx_font_bold">0.774</span></th>
<th id="S2.T2.1.3.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">0.721</th>
<th id="S2.T2.1.3.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">0.789</th>
<th id="S2.T2.1.3.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">0.739</th>
</tr>
<tr id="S2.T2.1.4.3" class="ltx_tr">
<td id="S2.T2.1.4.3.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_rr">General</td>
<td id="S2.T2.1.4.3.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S2.T2.1.4.3.2.1" class="ltx_text ltx_font_bold">0.649</span></td>
<td id="S2.T2.1.4.3.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S2.T2.1.4.3.3.1" class="ltx_text ltx_font_bold">0.698</span></td>
<td id="S2.T2.1.4.3.4" class="ltx_td ltx_align_center ltx_border_bb">0.721</td>
<td id="S2.T2.1.4.3.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">0.754</td>
<td id="S2.T2.1.4.3.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T2.1.4.3.6.1" class="ltx_text ltx_font_bold">0.667</span></td>
<td id="S2.T2.1.4.3.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">NA</td>
<td id="S2.T2.1.4.3.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T2.1.4.3.8.1" class="ltx_text ltx_font_bold">0.697</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Table of average RMSEs of models towards various groups of datasets.</figcaption>
</figure>
<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Three Amazon review datasets with mutually dissimilar domains were chosen to fine-tune BERT with <cite class="ltx_cite ltx_citemacro_cite">McAuley et al. (<a href="#bib.bib12" title="" class="ltx_ref">2015</a>); He and McAuley (<a href="#bib.bib6" title="" class="ltx_ref">2016</a>)</cite>:
automobile part review data (Auto); musical instrument review data (Music); and patio, lawn, and garden review data (Garden). Datasets consisted of examples with an average review text length of 582 characters and a one-to-five rating.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Our pipeline process from data sampling to model evaluation is shown in Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Investigating Cross-Domain Behaviors of BERT in Review Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
Data for model training was processed through downsampling to reduce domain and class imbalance. Since the original Auto domain data is significantly larger than the other datasets, 2500 reviews were sampled from each domain for model fine-tuning, remedying domain imbalance. To reduce class imbalance, for each domain, the 2500 training reviews consisted of 200, 250, 300, 600, and 1150 one- to five-star reviews, respectively. 800 reviews were randomly sampled from each domain for both validation and test splits.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Processing resulted in a final training corpus of 7500 reviews, divided evenly among the three domains. Four more multi-domain datasets were created through combining examples from various domains. Three two-domain datasets with 2500 train examples each were formed through taking 1250 examples from each combination of two single-domain datasets. One three-domain dataset of 2500 train examples was formed from an even mixture of examples from all three domains.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">The pre-trained <em id="S2.p4.1.1" class="ltx_emph ltx_font_italic">BERT-base-cased</em> model served as the fine-tuning backbone. Batches of fine-tuned models configured with varying hyperparameters were trained for each dataset to discover optimal model performance towards a specific dataset. Four learning rates (5e-5, 4e-5, 3e-5, and 2e-5) and four batch sizes (32, 64, 128, and 256) were used along with a 20 epoch training duration and a learning rate warmup ratio of 0.1. High learning rates and batch sizes were found to increase model performance, and after selecting the best model from each batch, each of the seven models was evaluated against the test split of every dataset.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p">The root mean squared error (RMSE) metric was used to determine the optimal model in each dataset batch and evaluate model cross-domain testing. As RMSE is proportional to the difference between true and predicted values, a smaller RMSE indicates higher performance.</p>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.1" class="ltx_p">Models were trained and tested on a GPU server of four NVIDIA GeForce RTX 2080 Ti cards, managed by the Center for Research Computing at the University of Notre Dame.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Results and Analysis</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Model-level results and analysis</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">The results of testing each model against each dataset are shown in Table <a href="#S2.T1" title="Table 1 ‣ 2 Method of Our Study ‣ Investigating Cross-Domain Behaviors of BERT in Review Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Every row of the table represents one model being tested on all seven datasets; every column represents one dataset having all seven models evaluated upon it. Performance of the models was measured using Root Mean Squared Error (RMSE). A smaller RMSE value indicates higher model accuracy. Bold table values represent the highest performance achieved in each column. The “Average” across each column and each row indicates the mean score for that column or row. Considering the horizontal row of averages, higher RMSE values indicate a more difficult dataset. Considering the vertical average column, lower RMSE values mean a better-performing model. The “Best avg” in the bottom right corner is found by taking the best (lowest) RMSE for each test set and calculating the mean of those values. 0.659, the best average, is quite good considering the rating score ranges from one to five. Within-domain performance (Auto model with Auto data) is indicated on the table through underlining. The bottom left cells contain the RMSEs of multi-domain models tested on single-domain data, while in the top right the RMSEs of single-domain models on multi-domain data are shown. Red cells mean a higher RMSE than the underlined baseline value of the column; blue cells indicate the inverse. Our observations are as follows.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p"><span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_bold">(1) Multi-domain models perform better than single-domain ones averaged across single- and multi-domain datasets.</span> The three-domain A+M+G model achieved the lowest RMSE, 0.670, averaged across all seven datasets. This matches intuition - though single-domain models were expected to and did perform better on certain specific domains, overall the more cross-domain a model was the lower the error across all domains. This appears to be due to the multi-domain models having received exposure to data from varied domains, and so having a “background” to predict decently well on music, auto, and garden data, whereas single-domain models, though having high performance on the single domain it was fine-tuned upon, lack knowledge of domains outside its “scope,” and so performed poorly on those. It seems that the decreases in performance for single-domain models on unfamiliar domains outweighed the high accuracy on the sole familiar domain, causing single-domain models to be inferior to multi-domain models on average.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p"><span id="S3.SS1.p3.1.1" class="ltx_text ltx_font_bold">(2) Some domains are more difficult for models to predict well upon, perhaps due to differences in text content and technicality.</span> On average, models when evaluated on the Music dataset resulted in the worst performance, with a RMSE of 0.767 averaged across all seven models. Perhaps this was due to the high musical knowledge of those who purchase musical instruments causing reviews to contain more difficult vocabulary. One would think automobile and garden products (on Amazon) would not be often purchased by mechanics or professional gardeners but by amateurs whose product reviews would not utilize technical language. Musical instruments, however, are in general more expensive and niche than a simple spark plug or lawn gnome and so reviews would tend towards professionals who, instead of merely commenting with “good violin” or “bad violin” would use terms that may be clear to a human musician but would be difficult for a BERT model to interpret as positive or negative. The easiest domain for models seems to be the automobile part data, with an average RMSE of 0.712. With regards to the Auto data, an outlier presents itself: the garden model, towards the auto domain, had a higher performance than even the automobile model itself. Given the uniqueness of this outlier (there is no other example in the table of a model completely unfamiliar with a domain outperforming a model trained upon that domain), this unexpected high-performing result can be treated as a curiosity caused by data variation between domains, interesting but ultimately unimportant to overall analysis.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p"><span id="S3.SS1.p4.1.1" class="ltx_text ltx_font_bold">(3) Data combining domains allows a wider range of models to predict well upon it.</span> Looking at the latter four columns of Table 1, it seems that on average models achieved a lower RMSE when evaluated with multi-domain data (two- and three-domain data). This should not be taken as a sign that difficult domains when combined result in an easier dataset. The relative higher performance of models towards multi-domain data should be taken as more models having familiarity towards a section of the multi-domain data and thus, overall, performing better.</p>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p id="S3.SS1.p5.1" class="ltx_p"><span id="S3.SS1.p5.1.1" class="ltx_text ltx_font_bold">(4) Multi-domain models outperformed single-domain models in all multi-domain data, and can outperform single-domain models in their corresponding single-domain dataset, perhaps caused by the ability of multi-domain models to adapt to variations in data.</span> These interesting observations can be found by considering the blue-and-red shaded top right and bottom left regions of Table 1. First, the top right, single-domain model with multi-domain dataset, section had only one blue cell - only one model-dataset pair that achieved a better RMSE than the baseline, underlined value in that column. It seems that, when considering multi-domain data, no single-domain model can compete with the multi-domain model. However, through analyzing the bottom left table quadrant, the inverse turns out to be untrue. Multiple cells are blue; considering the garden and music datasets, more than half of the multi-domain model with single-domain dataset tests resulted in a higher performance than the baseline of the column. It seems that, in the auto column, due to variations in data domains discussed above, the single-domain auto model was able to achieve a high enough performance that no multi-domain model was able to exceed its accuracy. In the garden and music domains, in both cases the three-domain model outperformed the baseline single-domain model, and in the garden domain, both of the two-domain models that had garden data as part of their fine-tuning outperformed the baseline. For the music dataset, the auto plus music model was the best of its column. This is unintuitive, since one would expect each single-domain model to have the highest performance towards its corresponding domain. This may have been caused by subtle effects produced by the difference in training versus testing data. Undersampled training data is not representative of a real-world application; however, fine-tuning a model with class-biased, unprocessed amazon reviews creates a model that only outputs fives and fours. The single-domain models may have been exposed to such homogeneous data that the model was overfitted to the processed, undersampled dataset, and thus could not predict well on the test data. Multi-domain models may have avoided this issue by heterogeneous, multi-domain data (still undersampled) allowing the model to be exposed to “variations” in data. In the training data, the variation is solely a difference in domain; in evaluation, the testing data both has a difference in domain between examples and a difference in class bias compared to the training data. Multi-domain models are more accustomed to variation than single-domain models due to the nature of multi-domain data; it is not a stretch to deduce that multi-domain models could better accommodate the differences between training and testing data.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Specific models vs general models</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Table <a href="#S2.T2" title="Table 2 ‣ 2 Method of Our Study ‣ Investigating Cross-Domain Behaviors of BERT in Review Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> summarizes average RMSEs among specific versus general models for differing categories of dataset. Specific is defined as single-domain; general models are the four two- and three-domain models. The “Self” column corresponds to the underlined values in Table <a href="#S2.T1" title="Table 1 ‣ 2 Method of Our Study ‣ Investigating Cross-Domain Behaviors of BERT in Review Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> - the RMSE of each model tested against its corresponding domain. The “All” column is the average of the specific or general models’ RMSEs on all datasets. In Table <a href="#S2.T2" title="Table 2 ‣ 2 Method of Our Study ‣ Investigating Cross-Domain Behaviors of BERT in Review Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, “Specific”, “Semi-Specific”, and “General” datasets are defined as single-domain, two-domain, and three-domain datasets respectively. The “Specific” and “Semi-Specific” columns are divided into two sub-column - “Familiar” and “Unfamiliar.” Familiar is defined as a model having had any training on any constituent domain of a dataset - for example, the Auto dataset would be familiar to both the “Specific” Auto model and the “General” A+G model, but would be unfamiliar to the M+G model. (The “NA” under “Semi-Specific, Unfamiliar” is due to all three two-domain datasets being familiar to all two- and three-domain models, as all pairs of two-domain dataset and two- or three-domain model share at least one domain.) The two values in the “General” column are the average of the RMSEs of all three single-domain models tested on A+M+G and the average of the RMSEs of all four multi-domain models tested on A+M+G, respectively.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">Most of the conclusions found by analyzing the results displayed in Table <a href="#S2.T1" title="Table 1 ‣ 2 Method of Our Study ‣ Investigating Cross-Domain Behaviors of BERT in Review Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> can also be found in Table <a href="#S2.T2" title="Table 2 ‣ 2 Method of Our Study ‣ Investigating Cross-Domain Behaviors of BERT in Review Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Though general models had a lower RMSE than specific ones across all datasets, single-domain models, on average, still performed better on their corresponding domain compared to multi-domain models on both familiar and unfamiliar specifc data; 0.696 compared to 0.721 and 0.754, respectively. However, other interesting conclusions can be found by further analyzing Table <a href="#S2.T2" title="Table 2 ‣ 2 Method of Our Study ‣ Investigating Cross-Domain Behaviors of BERT in Review Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure id="S3.T3" class="ltx_table">
<table id="S3.T3.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T3.1.1.1" class="ltx_tr">
<td id="S3.T3.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt">
<span id="S3.T3.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.1.1.1.1.1" class="ltx_p" style="width:43.4pt;">Domain</span>
</span>
</td>
<td id="S3.T3.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt">
<span id="S3.T3.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.1.1.2.1.1" class="ltx_p" style="width:216.8pt;">Review Text</span>
</span>
</td>
<td id="S3.T3.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt">
<span id="S3.T3.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.1.1.3.1.1" class="ltx_p" style="width:21.7pt;">True</span>
</span>
</td>
<td id="S3.T3.1.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt">
<span id="S3.T3.1.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.1.1.4.1.1" class="ltx_p" style="width:43.4pt;">Model</span>
</span>
</td>
<td id="S3.T3.1.1.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T3.1.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.1.1.5.1.1" class="ltx_p" style="width:43.4pt;">Predicted</span>
</span>
</td>
</tr>
<tr id="S3.T3.1.2.2" class="ltx_tr">
<td id="S3.T3.1.2.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T3.1.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.2.2.1.1.1" class="ltx_p" style="width:43.4pt;">Music</span>
</span>
</td>
<td id="S3.T3.1.2.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T3.1.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.2.2.2.1.1" class="ltx_p" style="width:216.8pt;">I’m another reviewer who has, upon personal inspection, discovered that the rear leg of the stand is too short to provide staedy support for any beloved guitar. I returned it. I’ve First Act brand stands similar in appearance but more intelligently constructed.</span>
</span>
</td>
<td id="S3.T3.1.2.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T3.1.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.2.2.3.1.1" class="ltx_p" style="width:21.7pt;">1</span>
</span>
</td>
<td id="S3.T3.1.2.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T3.1.2.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.2.2.4.1.1" class="ltx_p" style="width:43.4pt;">Music 
<br class="ltx_break">Auto 
<br class="ltx_break">A+M</span>
</span>
</td>
<td id="S3.T3.1.2.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T3.1.2.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.2.2.5.1.1" class="ltx_p" style="width:43.4pt;">3 
<br class="ltx_break">4 
<br class="ltx_break">2</span>
</span>
</td>
</tr>
<tr id="S3.T3.1.3.3" class="ltx_tr">
<td id="S3.T3.1.3.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T3.1.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.3.3.1.1.1" class="ltx_p" style="width:43.4pt;">Garden</span>
</span>
</td>
<td id="S3.T3.1.3.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T3.1.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.3.3.2.1.1" class="ltx_p" style="width:216.8pt;">This sprayer is very well built and solid. It is easy to use and with the long hose and 18 inch wand it sprays a very good distance and the spray is of course adjustable to different spray patterns. I am happy with hit.</span>
</span>
</td>
<td id="S3.T3.1.3.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T3.1.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.3.3.3.1.1" class="ltx_p" style="width:21.7pt;">5</span>
</span>
</td>
<td id="S3.T3.1.3.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T3.1.3.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.3.3.4.1.1" class="ltx_p" style="width:43.4pt;">Music 
<br class="ltx_break">Auto 
<br class="ltx_break">Garden</span>
</span>
</td>
<td id="S3.T3.1.3.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T3.1.3.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.3.3.5.1.1" class="ltx_p" style="width:43.4pt;">5 
<br class="ltx_break">5 
<br class="ltx_break">5</span>
</span>
</td>
</tr>
<tr id="S3.T3.1.4.4" class="ltx_tr">
<td id="S3.T3.1.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t">
<span id="S3.T3.1.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.4.4.1.1.1" class="ltx_p" style="width:43.4pt;">Auto</span>
</span>
</td>
<td id="S3.T3.1.4.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t">
<span id="S3.T3.1.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.4.4.2.1.1" class="ltx_p" style="width:216.8pt;">Takes the dust off my car without leaving any streaking that some report with other brands. Just don’t press real hard.</span>
</span>
</td>
<td id="S3.T3.1.4.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t">
<span id="S3.T3.1.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.4.4.3.1.1" class="ltx_p" style="width:21.7pt;">5</span>
</span>
</td>
<td id="S3.T3.1.4.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t">
<span id="S3.T3.1.4.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.4.4.4.1.1" class="ltx_p" style="width:43.4pt;">Garden 
<br class="ltx_break">Auto 
<br class="ltx_break">A+G</span>
</span>
</td>
<td id="S3.T3.1.4.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T3.1.4.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.4.4.5.1.1" class="ltx_p" style="width:43.4pt;">3 
<br class="ltx_break">5 
<br class="ltx_break">5</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Examples of reviews from various domains with review text, true rating, and predicted rating by multiple models, illustrating several conclusions detailed in the Case Study section.</figcaption>
</figure>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">Despite Table <a href="#S2.T1" title="Table 1 ‣ 2 Method of Our Study ‣ Investigating Cross-Domain Behaviors of BERT in Review Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> indicating that in some cases multi-domain, general models could outperform single-domain models, <span id="S3.SS2.p3.1.1" class="ltx_text ltx_font_bold">(5) in general multi-domain models tended to lose accuracy when evaluated on data with a single domain.</span> Compared to the baseline self-test average RMSE of 0.649, the general models had a 0.072 and 0.105 increase in RMSE when evaluated on familiar and unfamiliar single-domain data, respectively. A decrease in the performance of multi-domain models on single-domain data is also apparent when comparing the “Specific” column with the “Semi-Specific” and “General” columns of Table <a href="#S2.T2" title="Table 2 ‣ 2 Method of Our Study ‣ Investigating Cross-Domain Behaviors of BERT in Review Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, specifically the values in the “General” row. The average RMSEs of 0.667 and 0.697 of general models towards two- and three-domain data, respectively, are superior to both 0.721 and 0.754, the RMSEs of familiar and unfamiliar specific data, respectively. The loss of performance on unfamiliar data is expected; however, lower accuracy on familiar single domains is more interesting. An example of lower accuracy of a multi-domain model on familiar single-domain data is the A+M model achieving a worse RMSE on the Auto dataset and the Music dataset compared to the A+M dataset. This lowered performance on familiar domains in isolation may be caused by multi-domain models, in general, being unable to fully predict well on single-domain data that may contain technical vocabulary that, though familiar, has not been completely fine-tuned to. Single-domain test datasets are also more prone to outliers, at the data sample size used - for example, a certain subsection of Auto data, selected for testing, may contain a greater-than-average level of reviews utilizing technical vocabulary; multi-domain datasets reduce the chances of a test set with complicated vocabulary the multi-domain model cannot predict well upon. Regardless of the cause, however, multi-domain models achieved a relatively lower performance on single-domain data, compared to the self-test and testing on both two- and three-domain data.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p">A conclusion made when analyzing Table <a href="#S2.T1" title="Table 1 ‣ 2 Method of Our Study ‣ Investigating Cross-Domain Behaviors of BERT in Review Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> is further supported by the averages in Table <a href="#S2.T2" title="Table 2 ‣ 2 Method of Our Study ‣ Investigating Cross-Domain Behaviors of BERT in Review Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. <span id="S3.SS2.p4.1.1" class="ltx_text ltx_font_bold">(6) Specific models, when tested on general data and specific data not of the model’s domain, exhibited an expected decrease in performance.</span> Compared to the baseline self-test average of 0.696 among the three single-domain models, the average RMSEs of the single-domain models tested on familiar two-domain, unfamiliar two-domain, and three-domain datasets were 0.025, 0.093, and 0.043 higher, respectively. A decrease in performance towards unfamiliar specific data was also observed, the increase in RMSE being 0.075 there, similar to the 0.093 value mentioned above for the increase in RMSE with specific models tested on unfamiliar semi-specific data. Note that the relatively lower performance decreases in familiar two-domain and three-domain datasets is very probably not caused by Auto or Garden models predicting better on the Music-domain half of the A+M dataset compared to the Music data alone. The higher accuracy of the Garden model towards A+G data versus A+M data is because fifty percent of the former dataset is Garden-domain, while the Garden domain is not present in the latter dataset. Single-domain model only perform worse on semi-specific and general datasets because of the unfamiliar specific data content of the multi-domain datasets.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Case study</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Some examples that highlight the conclusions presented above are shown in Table <a href="#S3.T3" title="Table 3 ‣ 3.2 Specific models vs general models ‣ 3 Results and Analysis ‣ Investigating Cross-Domain Behaviors of BERT in Review Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Echoing points 2, 4, and 7, example 1 shows a review which all models failed to predict well upon (Music, Auto, and A+M are shown to highlight various conclusions). This review showcases the varied aspects of Music domain reviews that may have created difficulty for model prediction - lack of clear adjectives and a sentiment that requires knowledge of what “guitars", “rear legs", and “stands" are. The model predictions also support that single-domain models lose accuracy when tested on a different domain (the Auto model predicted a 4), and that, in some cases, a two-domain model can outperform a single-domain one (A+M performance).</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">Example 2 provides an example of an “easy" review to predict upon. The presence of “very good" and “happy with hit [sic]" allows all models to predict well upon the review. It also highlights a point that aids cross-domain models. As one can see in this example, “simple" adjectives such as “good" and “well" are present in great amount, a trait common to most reviews. Models undergoing cross-domain testing can utilize these keywords (Auto and Music model, which both predicted the true value) to achieve accuracy on various domains.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p">Example 3 provides another review that contains domain-specific text with few “simple" adjectives. The Garden model may have latched onto the “don’t" and “without", misinterpreting those negative-connotation words as indicative of a low star rating. Example 3 again shows that single-domain models predict well on the own dataset, and that multi-domain models with familiarity towards a certain domain can predict just as well.</p>
</div>
<section id="S3.SS3.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Summary:</h4>

<div id="S3.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS3.SSS0.Px1.p1.1" class="ltx_p">To summarize the conclusions presented through analysis of Table <a href="#S2.T1" title="Table 1 ‣ 2 Method of Our Study ‣ Investigating Cross-Domain Behaviors of BERT in Review Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and Table <a href="#S2.T2" title="Table 2 ‣ 2 Method of Our Study ‣ Investigating Cross-Domain Behaviors of BERT in Review Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>:</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">On average, multi-domain models perform better than single-domain ones.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">Domains vary in difficulty of prediction.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p">Multi-domain data allows for both single- and multi-domain models to predict well.</p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p id="S3.I1.i4.p1.1" class="ltx_p">Multi-domain models outperform single-domain models in multi-domain data and can occasionally outperform single-domain models in the single-domain model’s corresponding domain.</p>
</div>
</li>
<li id="S3.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i5.p1" class="ltx_para">
<p id="S3.I1.i5.p1.1" class="ltx_p">Multi-domain models lose accuracy when evaluated upon all single-domain data, including familiar data.</p>
</div>
</li>
<li id="S3.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i6.p1" class="ltx_para">
<p id="S3.I1.i6.p1.1" class="ltx_p">Single-domain models lose accuracy when evaluated upon unfamiliar single-domain data.</p>
</div>
</li>
<li id="S3.I1.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i7.p1" class="ltx_para">
<p id="S3.I1.i7.p1.1" class="ltx_p">On average, single-domain models achieve higher accuracy towards their domain compared to multi-domain models.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Related Work</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Domain adaptation and BERT</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Work has been done on cross-domain sentiment analysis with BERT <cite class="ltx_cite ltx_citemacro_cite">Myagmar et al. (<a href="#bib.bib14" title="" class="ltx_ref">2019</a>)</cite>. In the real world, the domain-dependent nature of sentiment analysis often creates issues when the amount of data that can be gathered for a specific domain is insufficient to properly train a high-performing, single-domain model. This problem is often solved through domain adaptation, in which a model is trained upon data from a relevant, secondary domain and deployed for the primary, data-scarce domain. Existing work has shown that fine-tuned BERT models outperform state-of-the-art domain adaptation methods <cite class="ltx_cite ltx_citemacro_cite">Lin et al. (<a href="#bib.bib10" title="" class="ltx_ref">2020</a>)</cite>. The multi-domain models in our work show a similar capacity to adapt to varying domains; however, single-domain models were less capable of predicting well on unfamiliar domains <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a href="#bib.bib20" title="" class="ltx_ref">2020</a>, <a href="#bib.bib21" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">Another domain-reliant task is automatic speech recognition (ASR), in which it is common practice to pretrain generic ASR models and then fine-tune the models to domain-specific data  <cite class="ltx_cite ltx_citemacro_cite">Bell et al. (<a href="#bib.bib3" title="" class="ltx_ref">2020</a>)</cite>, an approach similar to BERT pretraining and fine-tuning. Other techniques for ASR domain adaptation include data augmentation, multi-task learning, teacher-student training, semi-supervised training, and using synthetic data created by a Text-to-Speech system  <cite class="ltx_cite ltx_citemacro_cite">Fainberg et al. (<a href="#bib.bib5" title="" class="ltx_ref">2016</a>); Sun et al. (<a href="#bib.bib16" title="" class="ltx_ref">2017</a>); Meng et al. (<a href="#bib.bib13" title="" class="ltx_ref">2019</a>); Synnaeve et al. (<a href="#bib.bib18" title="" class="ltx_ref">2020</a>); Joshi and Singh (<a href="#bib.bib9" title="" class="ltx_ref">2022</a>)</cite>. If domain adaptability and the high performance achieved by single-domain models in our work are required, instead of multi-domain models the techniques used in ASR could be employed.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Knowledge distillation</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Work by Howell et al. on domain-specific knowledge distillation for conversational commerce is closely related to this work <cite class="ltx_cite ltx_citemacro_cite">Howell et al. (<a href="#bib.bib7" title="" class="ltx_ref">2022</a>)</cite>. Knowledge distillation addresses the issue of large and computationally expensive models being too costly to be deployed through a "teacher-student" training approach, in which a trained "teacher" model facilitates the training of a smaller "student" model  <cite class="ltx_cite ltx_citemacro_cite">Sanh et al. (<a href="#bib.bib15" title="" class="ltx_ref">2019</a>)</cite>. Howell et al. show knowledge distillation can both reduce model size and adapt models to a specific domain. In this work, we show that BERT base models are capable of adapting to a domain through fine-tuning on domain-specific, instead of knowledge distillation. However, we also show that, compared to single-domain models, multi-domain models, though incurring a slight accuracy penalty, still retain high performance towards a broad range of data. We also propose multi-domain models as an alternative solution to cost of computation. Multi-domain models and knowledge distillation could be used in tandem to further reduce computational resources, using knowledge distillation to train a "student" model with a broad spectrum of data domains, creating a model that is both small in size and applicable to multiple domains.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion and Future Work</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We investigated BERT models fine-tuned on single-domain and multi-domain data for the task of Amazon review score prediction. Though single-domain models achieved marginally improved performance on their corresponding domain compared to multi-domain models, multi-domain models outperformed single-domain models when evaluated on multi-domain data, single-domain data, and on average. Though slight increases in accuracy can be achieved through single-domain model fine-tuning, computational demands and costs can be reduced by utilizing multi-domain models that perform well across many domains.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Discussion and impact</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">The primary goal of this work was to determine the tradeoffs of specific versus general model domain scopes in BERT review score prediction. The difference between model RMSEs was comparatively low relative to the raw RMSE values, around 5% for most variations. This may have been caused by the task of classifying Amazon reviews not requiring much fixation on topic-related words. Though soap and furniture reviews contain differing nouns, adjectives for negative and positive soap and furniture reviews would be mostly alike. The BERT models may have recognized the importance of sentiment-laden adjectives such as “bad” or “good” that can apply to any topic product when determining the review’s star rating, placing weight on more general keywords rather than topic-specific nouns and descriptions. However, review score prediction still requires a certain level of domain understanding, supported both by our results and by phrases such as "takes up all my time," which is negative when referring to furniture setup but positive when applied to books.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">The findings in this work support that specific models are still superior to general models for specific applications. Tasks that come to mind that specific models would be best suited for include, say, diagnosis of a certain cancer type through processing a patient’s symptom log or as a search aide for an online archive containing papers of a narrow breadth. However, these specific models will necessarily be limited in scope.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p">Though general models in this predictive task were still capable of achieving relatively high performance on all domains, they lost accuracy on specific data, even data with domains that the general model had been exposed to before. Search engines and chatbots come to mind as tasks that require a general solution. However, general models often fail to correctly interpret a specific instruction. For example, a text summarization service may not be able to interpret a technical text accurately.</p>
</div>
<div id="S5.SS1.p4" class="ltx_para">
<p id="S5.SS1.p4.1" class="ltx_p">A possible solution for the above would be to utilize a general NLP model in order to determine what domain a certain piece of text falls into – a relatively simple task that is suited to a broad, general model. The text could then be sent to a specific model customized to address the particular domain the general model determined the text fell under. This system, though resource-intensive, would both allow the general model to perform a task that does not require the precision of a specific model and prevent the specific models from encountering any text outside its domain breadth.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Further experimentation</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">Further experimentation along these lines could include expanding the number of datasets used in order to minimize the effects outliers or poorly fine-tuned models have on results. Such experimentation would also be able to determine how the “interrelatedness” of topics affects BERT and NLP – one would expect soap and detergent models to be more similar than soap and furniture models. Single- versus multi-domain testing could also be done upon tasks requiring NLP models to place weight on topic-specific vocabulary (such as text summarization or keyword extraction), creating a true “specific” model, avoiding the problem described in the Discussion section of specific models fixating on general adjectives. Such investigation would be able to determine the tradeoffs between general and specific scopes in the broader, NLP field, and whether the trends detailed in this work regarding review score prediction with BERT (a narrow subset of NLP) do or do not extend to the rest of the e-commerce and NLP field.</p>
</div>
</section>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgement</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This work was supported by National Science Foundation (NSF) IIS-2119531, IIS-2137396, IIS-2142827, IIS-2234058, CCF-1901059, and Office of Naval Research (ONR) N00014-22-1-2507.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Al-Moslmi et al. (2017)</span>
<span class="ltx_bibblock">
Tareq Al-Moslmi, Nazlia Omar, Salwani Abdullah, and Mohammed Albared. 2017.

</span>
<span class="ltx_bibblock">Approaches to cross-domain sentiment analysis: A systematic
literature review.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, volume 5, pages 16173–16192.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">AlZu’bi et al. (2019)</span>
<span class="ltx_bibblock">
Shadi AlZu’bi, Abdalraheem Alsmadiv, Sokyna AlQatawneh, Mahmoud Al-Ayyoub,
Bilal Hawashin, and Yaser Jararweh. 2019.

</span>
<span class="ltx_bibblock">A brief analysis of amazon online reviews.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">2019 Sixth International Conference on Social Networks
Analysis, Management and Security (SNAMS)</em>, pages 555–560.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bell et al. (2020)</span>
<span class="ltx_bibblock">
Peter Bell, Joachim Fainberg, Klejch Ondrej, Jinyu Li, Steve Renals, and Pawel
Swietojanski. 2020.

</span>
<span class="ltx_bibblock">Adaptation algorithms for neural network-based speech recognition: An
overview.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">IEEE Open Journal of Signal Processing</em>, pages 33–66.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al. (2019)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.

</span>
<span class="ltx_bibblock">Bert: Pre-training of deep bidirectional transformers for language
understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of NAACL-HLT</em>, pages 4171–4186.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fainberg et al. (2016)</span>
<span class="ltx_bibblock">
Joachim Fainberg, Peter Bell, Mike Lincoln, and Steve Renals. 2016.

</span>
<span class="ltx_bibblock">Improving children’s speech recognition through out-of-domain data
augmentation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">INTERSPEECH 2016</em>, pages 1598–1602.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He and McAuley (2016)</span>
<span class="ltx_bibblock">
Ruining He and Julian McAuley. 2016.

</span>
<span class="ltx_bibblock">Ups and downs: Modeling the visual evolution of fashion trends with
one-class collaborative filtering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">proceedings of the 25th international conference on world
wide web</em>, pages 507–517.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Howell et al. (2022)</span>
<span class="ltx_bibblock">
Kristen Howell, Jian Wang, Akshay Hazare, Joseph Bradley, Chris Brew, Xi Chen,
Matthew Dunn, Beth Hockey, Andrew Maurer, and Dominic Widdows. 2022.

</span>
<span class="ltx_bibblock">Domain-specific knowledge distillation yields smaller and better
models for conversational commerce.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Fifth Workshop on e-Commerce and NLP
(ECNLP 5)</em>, pages 151–160.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ibrahim Elmurngi and Gherbi (2018)</span>
<span class="ltx_bibblock">
Elshrif Ibrahim Elmurngi and Abdelouahed Gherbi. 2018.

</span>
<span class="ltx_bibblock">Unfair reviews detection on amazon reviews using sentiment analysis
with supervised learning techniques.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Journal of Computer Science</em>, pages 714–726.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Joshi and Singh (2022)</span>
<span class="ltx_bibblock">
Raviraj Joshi and Anupam Singh. 2022.

</span>
<span class="ltx_bibblock">A simple baseline for domain adaptation in end to end asr systems
using synthetic data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Fifth Workshop on e-Commerce and NLP
(ECNLP 5)</em>, pages 217–223.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2020)</span>
<span class="ltx_bibblock">
Chen Lin, Steven Bethard, Dmitriy Dligach, Farig Sadeque, Guergana Savova, and
Timothy A Miller. 2020.

</span>
<span class="ltx_bibblock">Does bert need domain adaptation for clinical negation detection?

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Journal of the American Medical Informatics Association</em>,
volume 27, page 584–591.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2021)</span>
<span class="ltx_bibblock">
Jun Liu, Shuang Zheng, Guangxia Xu, and Mingwei Lin. 2021.

</span>
<span class="ltx_bibblock">Cross-domain sentiment aware word embeddings for review sentiment
analysis.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">International Journal of Machine Learning and Cybernetics</em>,
volume 12, pages 343–354.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McAuley et al. (2015)</span>
<span class="ltx_bibblock">
Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton Van Den Hengel.
2015.

</span>
<span class="ltx_bibblock">Image-based recommendations on styles and substitutes.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 38th international ACM SIGIR conference
on research and development in information retrieval</em>, pages 43–52.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meng et al. (2019)</span>
<span class="ltx_bibblock">
Zhong Meng, Jinyu Li, Yashesh Gaur, and Yifan Gong. 2019.

</span>
<span class="ltx_bibblock">Domain adaptation via teacher-student learning for end-to-end speech
recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">IEEE Automatic Speech Recognition and Understanding Workshop
(ASRU)</em>, pages 268–275.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Myagmar et al. (2019)</span>
<span class="ltx_bibblock">
Batsergelen Myagmar, Jie Li, and Shigetomo Kimura. 2019.

</span>
<span class="ltx_bibblock">Transferable high-level representations of bert for cross-domain
sentiment classification.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings on the International Conference on Artificial
Intelligence</em>, pages 135–141.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sanh et al. (2019)</span>
<span class="ltx_bibblock">
Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. 2019.

</span>
<span class="ltx_bibblock">Distilbert, a distilled version of bert: smaller, faster, cheaper and
lighter.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">NeurIPS EMC<sup id="bib.bib15.1.1.1" class="ltx_sup">2</sup> Workshop</em>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2017)</span>
<span class="ltx_bibblock">
Sining Sun, Binbin Zhang, Lei Xie, and Yanning Zhang. 2017.

</span>
<span class="ltx_bibblock">An unsupervised deep domain adaptation approach for robust speech
recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Neurocomputing</em>, volume 257, pages 79–87.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sushil et al. (2021)</span>
<span class="ltx_bibblock">
Madhumita Sushil, Simon Suster, and Walter Daelemans. 2021.

</span>
<span class="ltx_bibblock">Are we there yet? exploring clinical domain knowledge of bert models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 20th Workshop on Biomedical Language
Processing</em>, pages 41–53.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Synnaeve et al. (2020)</span>
<span class="ltx_bibblock">
Gabriel Synnaeve, Qiantong Xu, Jacob Kahn, Tatiana Likhomanenko, Edouard Grave,
Vineel Pratap, Anuroop Sriram, Vitaliy Liptchinsky, and Ronan Collobert.
2020.

</span>
<span class="ltx_bibblock">End-to-end asr: from supervised to semi-supervised learning with
modern architectures.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">ICML Self-supervision in Audio and Speech</em>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ul Haque et al. (2018)</span>
<span class="ltx_bibblock">
Tanjim Ul Haque, Nudrat Nawal Saber, and Faisal Muhammad Shah. 2018.

</span>
<span class="ltx_bibblock">Sentiment analysis on large scale amazon product reviews.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">2018 IEEE international conference on innovative research
and development (ICIRD)</em>, pages 1–6.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2020)</span>
<span class="ltx_bibblock">
Daheng Wang, Meng Jiang, Munira Syed, Oliver Conway, Vishal Juneja, Sriram
Subramanian, and Nitesh V Chawla. 2020.

</span>
<span class="ltx_bibblock">Calendar graph neural networks for modeling time structures in
spatiotemporal user behaviors.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 26th ACM SIGKDD international conference
on knowledge discovery &amp; data mining</em>, pages 2581–2589.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2021)</span>
<span class="ltx_bibblock">
Daheng Wang, Zhihan Zhang, Yihong Ma, Tong Zhao, Tianwen Jiang, Nitesh Chawla,
and Meng Jiang. 2021.

</span>
<span class="ltx_bibblock">Modeling co-evolution of attributed and structural information in
graph sequence.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Knowledge and Data Engineering</em>.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2306.15122" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2306.15123" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2306.15123">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2306.15123" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2306.15124" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Feb 28 22:30:38 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
