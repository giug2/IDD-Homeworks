<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[1906.10169] RUBi: Reducing Unimodal Biases for Visual Question Answering</title><meta property="og:description" content="Visual Question Answering (VQA) is the task of answering questions about an
image.
Some VQA models often exploit unimodal biases to provide the correct answer without using the image information.
As a result, they suffâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="RUBi: Reducing Unimodal Biases for Visual Question Answering">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="RUBi: Reducing Unimodal Biases for Visual Question Answering">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/1906.10169">

<!--Generated on Thu Mar  7 11:31:52 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">RUBi: Reducing Unimodal Biases 
<br class="ltx_break">for Visual Question Answering</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
 Remi Cadene <sup id="id9.9.id1" class="ltx_sup"><span id="id9.9.id1.1" class="ltx_text ltx_font_italic">1</span></sup>,
Corentin Dancette <sup id="id10.10.id2" class="ltx_sup"><span id="id10.10.id2.1" class="ltx_text ltx_font_italic">1</span></sup><span id="footnotex1" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span>,
Hedi Ben-younes <sup id="id11.11.id3" class="ltx_sup"><span id="id11.11.id3.1" class="ltx_text ltx_font_italic">1</span></sup>,
Matthieu Cord <sup id="id12.12.id4" class="ltx_sup">1</sup>,
Devi Parikh <sup id="id13.13.id5" class="ltx_sup"><span id="id13.13.id5.1" class="ltx_text ltx_font_italic">2,3</span></sup> 
<br class="ltx_break"><sup id="id14.14.id6" class="ltx_sup">1</sup> Sorbonne UniversitÃ©, CNRS, LIP6, 4 place Jussieu, 75005 Paris,

<br class="ltx_break"><sup id="id15.15.id7" class="ltx_sup">2</sup> Facebook AI Research,
<sup id="id16.16.id8" class="ltx_sup">3</sup> Georgia Institute of Technology 
<br class="ltx_break"><span id="id17.17.id9" class="ltx_text ltx_font_typewriter">{remi.cadene, corentin.dancette, hedi.ben-younes, matthieu.cord}@lip6.fr</span>,

<br class="ltx_break"><span id="id18.18.id10" class="ltx_text ltx_font_typewriter">parkih@gatech.edu</span>
</span><span class="ltx_author_notes">Equal contribution</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id19.id1" class="ltx_p">Visual Question Answering (VQA) is the task of answering questions about an
image.
Some VQA models often exploit unimodal biases to provide the correct answer without using the image information.
As a result, they suffer from a huge drop in performance when evaluated on data outside their training set distribution. This critical issue makes them unsuitable for real-world settings.</p>
<p id="id20.id2" class="ltx_p">We propose RUBi, a new learning strategy to reduce biases in any VQA model.
It reduces the importance of the most biased examples, i.e. examples that can be correctly classified without looking at the image.
It implicitly forces the VQA model to use the two input modalities instead of relying on statistical regularities between the question and the answer.
We leverage a question-only model that captures the language biases by identifying when these unwanted regularities are used.
It prevents the base VQA model from learning them by influencing its predictions. This leads to dynamically adjusting the loss in order to compensate for biases.
We validate our contributions by surpassing the current state-of-the-art results on VQA-CP v2. This dataset is specifically designed to assess the robustness of VQA models when exposed to different question biases at test time than what was seen during training.</p>
<p id="id21.id3" class="ltx_p">Our code is available: <a target="_blank" href="https://github.com/cdancette/rubi.bootstrap.pytorch" title="" class="ltx_ref ltx_href ltx_font_typewriter">github.com/cdancette/rubi.bootstrap.pytorch</a></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The recent Deep Learning success in computer vision <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> and natural language understanding <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> allowed researchers to tackle multimodal tasks that combine visual and textual modalities <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.
Among these tasks, Visual Question Answering (VQA) attracts increasing attention. The goal of the VQA task is to answer a question about an image. It requires a high-level understanding of the visual scene and the question, but also to ground the textual concepts in the image and to use both modalities adequately.
Solving the VQA task could have tremendous impacts on real-world applications such as aiding visually impaired users in understanding their physical and online surroundings, searching through large quantities of visual data via natural language interfaces, or even communicating with robots using more efficient and intuitive interfaces.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Several large real image VQA datasets have recently emerged <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. Each one of them targets specific abilities that a VQA model would need to be used in real-world settings such as fine-grained recognition, object detection, counting, activity recognition, commonsense reasoning, etc. Current end-to-end VQA models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> achieve impressive results on most of these benchmarks and are even able to surpass the human accuracy on a specific benchmark accounting for compositional reasoning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>.
However, it has been shown that they tend to exploit statistical regularities between answer occurrences and certain patterns in the question <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. While they are designed to merge information from both modalities, in practice they often answer without considering the image modality.
When most of the bananas are <span id="S1.p2.1.1" class="ltx_text ltx_font_italic">yellow</span>, a model does not need to learn the correct behavior to reach a high accuracy for questions asking about the color of bananas. Instead of looking at the image, detecting a banana and assessing its color, it is much easier to learn from the statistical shortcut linking the words <span id="S1.p2.1.2" class="ltx_text ltx_font_italic">what</span>, <span id="S1.p2.1.3" class="ltx_text ltx_font_italic">color</span> and <span id="S1.p2.1.4" class="ltx_text ltx_font_italic">bananas</span> with the most occurring answer <span id="S1.p2.1.5" class="ltx_text ltx_font_italic">yellow</span>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">One way to quantify the amount of statistical shortcuts from each modality is to train unimodal models. For instance, a question-only model trained on the widely used VQA v2 dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> predicts the correct answer approximately 44% of the time over the test set.
VQA models are not discouraged to exploit these statistical shortcuts from the question modality, because their training set often follows the same distribution as their testing set. However, when evaluated on a test set that displays different statistical regularities, they usually suffer from a significant drop in accuracy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. Unfortunately, these statistical regularities are hard to avoid when collecting real datasets. As illustrated in FigureÂ <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ RUBi: Reducing Unimodal Biases for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, there is a crucial need to develop new strategies to reduce the amount of biases coming from the question modality in order to learn better behaviors.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">We propose RUBi, a training strategy to reduce the amount of biases learned by VQA models.
Our strategy reduces the importance of the most biased examples, i.e. examples that can be correctly classified without looking at the image modality.
It implicitly forces the VQA model to use the two input modalities instead of relying on statistical regularities between the question and the answer.
We take advantage of the fact that question-only models are by design biased towards the question modality.
We add a question-only branch on top of a base VQA model during training only.
This branch influences the VQA model, dynamically adjusting the loss to compensate for biases.
As a result, the gradients backpropagated through the VQA model are reduced for the most biased examples and increased for the less biased.
At the end of the training, we simply remove the question-only branch.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">We run extensive experiments on VQA-CP v2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> and demonstrate the ability of RUBi to surpass current state-of-the-art results from a significant margin. This dataset has been specifically designed to assess the capacity of VQA models to be robust to biases by the question modality.
We show that our RUBi learning framework provides gains when applied on several VQA architectures such as Stacked Attention Networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> and Top-Down Bottom-Up Attention <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.
We also show that RUBi is competitive on the standard VQA v2 dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> when compared to approaches that reduce unimodal biases.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/1906.10169/assets/images/big_picture.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="188" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.3.2" class="ltx_text" style="font-size:90%;"> Our RUBi approach aims at reducing the amount of unimodal biases learned by a VQA model during training. As depicted, current VQA models often rely on unwanted statistical correlations between the question and the answer instead of using both modalities.</span></figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Real-world datasets display some form of inherent biases due to their collection process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>.
As a result, machine learning models tend to reflect these biases because they capture often undesirable correlations between the inputs and the ground truth annotations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>.
Procedures exist to identify certain kinds of biases and to reduce them. For instance, some methods are focused on gender biases <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>, some others on the human reporting biases <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>, and also on the shift in distribution between lab-curated data and real-world data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>.
In the language and vision context, some works evaluate unimodal baselines <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> or leverage language priors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>.
In the following, we discuss about related works that assess and reduce unimodal biases learned by VQA models.</p>
</div>
<section id="S2.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Assessing unimodal biases in datasets and models</h4>

<div id="S2.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px1.p1.1" class="ltx_p">Despite being designed to merge the two input modalities, it has been found that VQA models often rely on superficial correlations between inputs from one modality and the answers without considering the other modality <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>.
An interesting way to quantify the amount of unimodal biases that can potentially be learned by a VQA model consists in training models using only one of the two modalities <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.
The question-only model is a particularly strong baseline because of the large amount of statistical regularities that can be leveraged from the question modality. With the RUBi learning strategy, we take advantage of this baseline model to prevent VQA models from learning question biases.</p>
</div>
<div id="S2.SS0.SSS0.Px1.p2" class="ltx_para">
<p id="S2.SS0.SSS0.Px1.p2.1" class="ltx_p">Unfortunately, biased models that exploit statistical shortcuts from one modality usually reach impressive accuracy on most of the current benchmarks. VQA-CP v2 and VQA-CP v1 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> were recently introduced as diagnostic datasets containing different answer distributions for each question-type between train and test splits. Consequentially, models biased towards the question modality fail on these benchmarks. We use the more challenging VQA-CP v2 dataset extensively in order to show the ability of our approach to reduce the learning of biases coming from the question modality.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Balancing datasets to avoid unimodal biases</h4>

<div id="S2.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px2.p1.1" class="ltx_p">Once the unimodal biases have been identified, one method to overcome these biases is to create more balanced datasets. For instance, the synthetic datasets for VQA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> minimize question-conditional biases via rejection sampling within families of related questions to avoid simple shortcuts to the correct answer.</p>
</div>
<div id="S2.SS0.SSS0.Px2.p2" class="ltx_para">
<p id="S2.SS0.SSS0.Px2.p2.1" class="ltx_p">Doing rejection sampling in real VQA datasets is usually not possible due to the cost of annotations. Another solution is to collect complementary examples to increase the difficulty of the task. For instance, VQA v2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> has been introduced to weaken language priors in the VQA v1 dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> by identifying complementary images. For a given VQA v1 question, VQA v2 also contains a similar image with a different answer to the same question.
However, even with this additional balancing, statistical biases from the question remain and can be leveraged <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>.
That is why we propose an approach to reduce unimodal biases during training. It is designed to learn unbiased models from biased datasets. Our learning strategy dynamically modifies the loss values to reduce biases from the question. By doing so, we reduce the importance of certain examples, similarly to the rejection sampling approach, while increasing the importance of complementary examples which are already in the training set.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Architectures and learning strategies to reduce unimodal biases</h4>

<div id="S2.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px3.p1.1" class="ltx_p">In parallel of these previous works on balancing datasets, an important effort has been carried out to design VQA models to overcome biases from datasets.
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> proposed a hand-designed architecture called Grounded VQA model (GVQA).
It breaks the task of VQA down into a first step of locating and recognizing the visual regions needed to answer the question, and a second step of identifying the space of plausible answers based on a question-only branch. This approach requires training multiple sub-models separately. In contrast, our learning strategy is end-to-end. Their complex design is not straightforward to apply on different architectures while our approach is model-agnostic. While we rely on a question-only branch, we remove it at the end of the training.</p>
</div>
<div id="S2.SS0.SSS0.Px3.p2" class="ltx_para">
<p id="S2.SS0.SSS0.Px3.p2.1" class="ltx_p">The work most related to ours in terms of approach is <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. The authors propose a learning strategy to overcome language priors in VQA models. They first introduce an adversary question-only branch. It takes as input the question encoding from the VQA model and produces a question-only loss. They use a gradient negation of this loss to discourage the question encoder to capture unwanted biases that could be exploited by the VQA model. They also propose a loss based on the difference of entropies between the VQA model and the question-only branch output distributions. These two losses are only backpropagated to the question encoder.
In contrast, our learning strategy targets the full VQA model parameters to reduce the impact of unwanted biases more effectively.
Instead of relying on these two additional losses, we use the question-only branch to dynamically adapt the value of the classification loss in order to reduce the learning of biases in the VQA model. A visual comparison between <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> and RUBi can be found in FigureÂ <a href="#S6.F5" title="Figure 5 â€£ 6 Supplementary materials â€£ RUBi: Reducing Unimodal Biases for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> in the supplementary materials.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Reducing Unimodal Biases Approach</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.16" class="ltx_p">We consider the common formulation of the Visual Question Answering (VQA) task as a multi-class classification problem. Given a dataset <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S3.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">ğ’Ÿ</mi><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><ci id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">ğ’Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">\mathcal{D}</annotation></semantics></math> consisting of <math id="S3.p1.2.m2.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.p1.2.m2.1a"><mi id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><ci id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">n</annotation></semantics></math> triplets <math id="S3.p1.3.m3.5" class="ltx_Math" alttext="(v_{i},q_{i},a_{i})_{i\in[1,n]}" display="inline"><semantics id="S3.p1.3.m3.5a"><msub id="S3.p1.3.m3.5.5" xref="S3.p1.3.m3.5.5.cmml"><mrow id="S3.p1.3.m3.5.5.3.3" xref="S3.p1.3.m3.5.5.3.4.cmml"><mo stretchy="false" id="S3.p1.3.m3.5.5.3.3.4" xref="S3.p1.3.m3.5.5.3.4.cmml">(</mo><msub id="S3.p1.3.m3.3.3.1.1.1" xref="S3.p1.3.m3.3.3.1.1.1.cmml"><mi id="S3.p1.3.m3.3.3.1.1.1.2" xref="S3.p1.3.m3.3.3.1.1.1.2.cmml">v</mi><mi id="S3.p1.3.m3.3.3.1.1.1.3" xref="S3.p1.3.m3.3.3.1.1.1.3.cmml">i</mi></msub><mo id="S3.p1.3.m3.5.5.3.3.5" xref="S3.p1.3.m3.5.5.3.4.cmml">,</mo><msub id="S3.p1.3.m3.4.4.2.2.2" xref="S3.p1.3.m3.4.4.2.2.2.cmml"><mi id="S3.p1.3.m3.4.4.2.2.2.2" xref="S3.p1.3.m3.4.4.2.2.2.2.cmml">q</mi><mi id="S3.p1.3.m3.4.4.2.2.2.3" xref="S3.p1.3.m3.4.4.2.2.2.3.cmml">i</mi></msub><mo id="S3.p1.3.m3.5.5.3.3.6" xref="S3.p1.3.m3.5.5.3.4.cmml">,</mo><msub id="S3.p1.3.m3.5.5.3.3.3" xref="S3.p1.3.m3.5.5.3.3.3.cmml"><mi id="S3.p1.3.m3.5.5.3.3.3.2" xref="S3.p1.3.m3.5.5.3.3.3.2.cmml">a</mi><mi id="S3.p1.3.m3.5.5.3.3.3.3" xref="S3.p1.3.m3.5.5.3.3.3.3.cmml">i</mi></msub><mo stretchy="false" id="S3.p1.3.m3.5.5.3.3.7" xref="S3.p1.3.m3.5.5.3.4.cmml">)</mo></mrow><mrow id="S3.p1.3.m3.2.2.2" xref="S3.p1.3.m3.2.2.2.cmml"><mi id="S3.p1.3.m3.2.2.2.4" xref="S3.p1.3.m3.2.2.2.4.cmml">i</mi><mo id="S3.p1.3.m3.2.2.2.3" xref="S3.p1.3.m3.2.2.2.3.cmml">âˆˆ</mo><mrow id="S3.p1.3.m3.2.2.2.5.2" xref="S3.p1.3.m3.2.2.2.5.1.cmml"><mo stretchy="false" id="S3.p1.3.m3.2.2.2.5.2.1" xref="S3.p1.3.m3.2.2.2.5.1.cmml">[</mo><mn id="S3.p1.3.m3.1.1.1.1" xref="S3.p1.3.m3.1.1.1.1.cmml">1</mn><mo id="S3.p1.3.m3.2.2.2.5.2.2" xref="S3.p1.3.m3.2.2.2.5.1.cmml">,</mo><mi id="S3.p1.3.m3.2.2.2.2" xref="S3.p1.3.m3.2.2.2.2.cmml">n</mi><mo stretchy="false" id="S3.p1.3.m3.2.2.2.5.2.3" xref="S3.p1.3.m3.2.2.2.5.1.cmml">]</mo></mrow></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.5b"><apply id="S3.p1.3.m3.5.5.cmml" xref="S3.p1.3.m3.5.5"><csymbol cd="ambiguous" id="S3.p1.3.m3.5.5.4.cmml" xref="S3.p1.3.m3.5.5">subscript</csymbol><vector id="S3.p1.3.m3.5.5.3.4.cmml" xref="S3.p1.3.m3.5.5.3.3"><apply id="S3.p1.3.m3.3.3.1.1.1.cmml" xref="S3.p1.3.m3.3.3.1.1.1"><csymbol cd="ambiguous" id="S3.p1.3.m3.3.3.1.1.1.1.cmml" xref="S3.p1.3.m3.3.3.1.1.1">subscript</csymbol><ci id="S3.p1.3.m3.3.3.1.1.1.2.cmml" xref="S3.p1.3.m3.3.3.1.1.1.2">ğ‘£</ci><ci id="S3.p1.3.m3.3.3.1.1.1.3.cmml" xref="S3.p1.3.m3.3.3.1.1.1.3">ğ‘–</ci></apply><apply id="S3.p1.3.m3.4.4.2.2.2.cmml" xref="S3.p1.3.m3.4.4.2.2.2"><csymbol cd="ambiguous" id="S3.p1.3.m3.4.4.2.2.2.1.cmml" xref="S3.p1.3.m3.4.4.2.2.2">subscript</csymbol><ci id="S3.p1.3.m3.4.4.2.2.2.2.cmml" xref="S3.p1.3.m3.4.4.2.2.2.2">ğ‘</ci><ci id="S3.p1.3.m3.4.4.2.2.2.3.cmml" xref="S3.p1.3.m3.4.4.2.2.2.3">ğ‘–</ci></apply><apply id="S3.p1.3.m3.5.5.3.3.3.cmml" xref="S3.p1.3.m3.5.5.3.3.3"><csymbol cd="ambiguous" id="S3.p1.3.m3.5.5.3.3.3.1.cmml" xref="S3.p1.3.m3.5.5.3.3.3">subscript</csymbol><ci id="S3.p1.3.m3.5.5.3.3.3.2.cmml" xref="S3.p1.3.m3.5.5.3.3.3.2">ğ‘</ci><ci id="S3.p1.3.m3.5.5.3.3.3.3.cmml" xref="S3.p1.3.m3.5.5.3.3.3.3">ğ‘–</ci></apply></vector><apply id="S3.p1.3.m3.2.2.2.cmml" xref="S3.p1.3.m3.2.2.2"><in id="S3.p1.3.m3.2.2.2.3.cmml" xref="S3.p1.3.m3.2.2.2.3"></in><ci id="S3.p1.3.m3.2.2.2.4.cmml" xref="S3.p1.3.m3.2.2.2.4">ğ‘–</ci><interval closure="closed" id="S3.p1.3.m3.2.2.2.5.1.cmml" xref="S3.p1.3.m3.2.2.2.5.2"><cn type="integer" id="S3.p1.3.m3.1.1.1.1.cmml" xref="S3.p1.3.m3.1.1.1.1">1</cn><ci id="S3.p1.3.m3.2.2.2.2.cmml" xref="S3.p1.3.m3.2.2.2.2">ğ‘›</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.5c">(v_{i},q_{i},a_{i})_{i\in[1,n]}</annotation></semantics></math> with <math id="S3.p1.4.m4.1" class="ltx_Math" alttext="v_{i}\in\mathcal{V}" display="inline"><semantics id="S3.p1.4.m4.1a"><mrow id="S3.p1.4.m4.1.1" xref="S3.p1.4.m4.1.1.cmml"><msub id="S3.p1.4.m4.1.1.2" xref="S3.p1.4.m4.1.1.2.cmml"><mi id="S3.p1.4.m4.1.1.2.2" xref="S3.p1.4.m4.1.1.2.2.cmml">v</mi><mi id="S3.p1.4.m4.1.1.2.3" xref="S3.p1.4.m4.1.1.2.3.cmml">i</mi></msub><mo id="S3.p1.4.m4.1.1.1" xref="S3.p1.4.m4.1.1.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S3.p1.4.m4.1.1.3" xref="S3.p1.4.m4.1.1.3.cmml">ğ’±</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.4.m4.1b"><apply id="S3.p1.4.m4.1.1.cmml" xref="S3.p1.4.m4.1.1"><in id="S3.p1.4.m4.1.1.1.cmml" xref="S3.p1.4.m4.1.1.1"></in><apply id="S3.p1.4.m4.1.1.2.cmml" xref="S3.p1.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.p1.4.m4.1.1.2.1.cmml" xref="S3.p1.4.m4.1.1.2">subscript</csymbol><ci id="S3.p1.4.m4.1.1.2.2.cmml" xref="S3.p1.4.m4.1.1.2.2">ğ‘£</ci><ci id="S3.p1.4.m4.1.1.2.3.cmml" xref="S3.p1.4.m4.1.1.2.3">ğ‘–</ci></apply><ci id="S3.p1.4.m4.1.1.3.cmml" xref="S3.p1.4.m4.1.1.3">ğ’±</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.4.m4.1c">v_{i}\in\mathcal{V}</annotation></semantics></math> an image, <math id="S3.p1.5.m5.1" class="ltx_Math" alttext="q_{i}\in\mathcal{Q}" display="inline"><semantics id="S3.p1.5.m5.1a"><mrow id="S3.p1.5.m5.1.1" xref="S3.p1.5.m5.1.1.cmml"><msub id="S3.p1.5.m5.1.1.2" xref="S3.p1.5.m5.1.1.2.cmml"><mi id="S3.p1.5.m5.1.1.2.2" xref="S3.p1.5.m5.1.1.2.2.cmml">q</mi><mi id="S3.p1.5.m5.1.1.2.3" xref="S3.p1.5.m5.1.1.2.3.cmml">i</mi></msub><mo id="S3.p1.5.m5.1.1.1" xref="S3.p1.5.m5.1.1.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S3.p1.5.m5.1.1.3" xref="S3.p1.5.m5.1.1.3.cmml">ğ’¬</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.5.m5.1b"><apply id="S3.p1.5.m5.1.1.cmml" xref="S3.p1.5.m5.1.1"><in id="S3.p1.5.m5.1.1.1.cmml" xref="S3.p1.5.m5.1.1.1"></in><apply id="S3.p1.5.m5.1.1.2.cmml" xref="S3.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.p1.5.m5.1.1.2.1.cmml" xref="S3.p1.5.m5.1.1.2">subscript</csymbol><ci id="S3.p1.5.m5.1.1.2.2.cmml" xref="S3.p1.5.m5.1.1.2.2">ğ‘</ci><ci id="S3.p1.5.m5.1.1.2.3.cmml" xref="S3.p1.5.m5.1.1.2.3">ğ‘–</ci></apply><ci id="S3.p1.5.m5.1.1.3.cmml" xref="S3.p1.5.m5.1.1.3">ğ’¬</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.5.m5.1c">q_{i}\in\mathcal{Q}</annotation></semantics></math> a question in natural language and <math id="S3.p1.6.m6.1" class="ltx_Math" alttext="a_{i}\in\mathcal{A}" display="inline"><semantics id="S3.p1.6.m6.1a"><mrow id="S3.p1.6.m6.1.1" xref="S3.p1.6.m6.1.1.cmml"><msub id="S3.p1.6.m6.1.1.2" xref="S3.p1.6.m6.1.1.2.cmml"><mi id="S3.p1.6.m6.1.1.2.2" xref="S3.p1.6.m6.1.1.2.2.cmml">a</mi><mi id="S3.p1.6.m6.1.1.2.3" xref="S3.p1.6.m6.1.1.2.3.cmml">i</mi></msub><mo id="S3.p1.6.m6.1.1.1" xref="S3.p1.6.m6.1.1.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S3.p1.6.m6.1.1.3" xref="S3.p1.6.m6.1.1.3.cmml">ğ’œ</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.6.m6.1b"><apply id="S3.p1.6.m6.1.1.cmml" xref="S3.p1.6.m6.1.1"><in id="S3.p1.6.m6.1.1.1.cmml" xref="S3.p1.6.m6.1.1.1"></in><apply id="S3.p1.6.m6.1.1.2.cmml" xref="S3.p1.6.m6.1.1.2"><csymbol cd="ambiguous" id="S3.p1.6.m6.1.1.2.1.cmml" xref="S3.p1.6.m6.1.1.2">subscript</csymbol><ci id="S3.p1.6.m6.1.1.2.2.cmml" xref="S3.p1.6.m6.1.1.2.2">ğ‘</ci><ci id="S3.p1.6.m6.1.1.2.3.cmml" xref="S3.p1.6.m6.1.1.2.3">ğ‘–</ci></apply><ci id="S3.p1.6.m6.1.1.3.cmml" xref="S3.p1.6.m6.1.1.3">ğ’œ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.6.m6.1c">a_{i}\in\mathcal{A}</annotation></semantics></math> an answer, one must optimize the parameters <math id="S3.p1.7.m7.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S3.p1.7.m7.1a"><mi id="S3.p1.7.m7.1.1" xref="S3.p1.7.m7.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="S3.p1.7.m7.1b"><ci id="S3.p1.7.m7.1.1.cmml" xref="S3.p1.7.m7.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.7.m7.1c">\theta</annotation></semantics></math> of the function <math id="S3.p1.8.m8.1" class="ltx_Math" alttext="f:\mathcal{V}\times\mathcal{Q}\rightarrow\mathbb{R}^{|\mathcal{A}|}" display="inline"><semantics id="S3.p1.8.m8.1a"><mrow id="S3.p1.8.m8.1.2" xref="S3.p1.8.m8.1.2.cmml"><mi id="S3.p1.8.m8.1.2.2" xref="S3.p1.8.m8.1.2.2.cmml">f</mi><mo lspace="0.278em" rspace="0.278em" id="S3.p1.8.m8.1.2.1" xref="S3.p1.8.m8.1.2.1.cmml">:</mo><mrow id="S3.p1.8.m8.1.2.3" xref="S3.p1.8.m8.1.2.3.cmml"><mrow id="S3.p1.8.m8.1.2.3.2" xref="S3.p1.8.m8.1.2.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p1.8.m8.1.2.3.2.2" xref="S3.p1.8.m8.1.2.3.2.2.cmml">ğ’±</mi><mo lspace="0.222em" rspace="0.222em" id="S3.p1.8.m8.1.2.3.2.1" xref="S3.p1.8.m8.1.2.3.2.1.cmml">Ã—</mo><mi class="ltx_font_mathcaligraphic" id="S3.p1.8.m8.1.2.3.2.3" xref="S3.p1.8.m8.1.2.3.2.3.cmml">ğ’¬</mi></mrow><mo stretchy="false" id="S3.p1.8.m8.1.2.3.1" xref="S3.p1.8.m8.1.2.3.1.cmml">â†’</mo><msup id="S3.p1.8.m8.1.2.3.3" xref="S3.p1.8.m8.1.2.3.3.cmml"><mi id="S3.p1.8.m8.1.2.3.3.2" xref="S3.p1.8.m8.1.2.3.3.2.cmml">â„</mi><mrow id="S3.p1.8.m8.1.1.1.3" xref="S3.p1.8.m8.1.1.1.2.cmml"><mo stretchy="false" id="S3.p1.8.m8.1.1.1.3.1" xref="S3.p1.8.m8.1.1.1.2.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S3.p1.8.m8.1.1.1.1" xref="S3.p1.8.m8.1.1.1.1.cmml">ğ’œ</mi><mo stretchy="false" id="S3.p1.8.m8.1.1.1.3.2" xref="S3.p1.8.m8.1.1.1.2.1.cmml">|</mo></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.8.m8.1b"><apply id="S3.p1.8.m8.1.2.cmml" xref="S3.p1.8.m8.1.2"><ci id="S3.p1.8.m8.1.2.1.cmml" xref="S3.p1.8.m8.1.2.1">:</ci><ci id="S3.p1.8.m8.1.2.2.cmml" xref="S3.p1.8.m8.1.2.2">ğ‘“</ci><apply id="S3.p1.8.m8.1.2.3.cmml" xref="S3.p1.8.m8.1.2.3"><ci id="S3.p1.8.m8.1.2.3.1.cmml" xref="S3.p1.8.m8.1.2.3.1">â†’</ci><apply id="S3.p1.8.m8.1.2.3.2.cmml" xref="S3.p1.8.m8.1.2.3.2"><times id="S3.p1.8.m8.1.2.3.2.1.cmml" xref="S3.p1.8.m8.1.2.3.2.1"></times><ci id="S3.p1.8.m8.1.2.3.2.2.cmml" xref="S3.p1.8.m8.1.2.3.2.2">ğ’±</ci><ci id="S3.p1.8.m8.1.2.3.2.3.cmml" xref="S3.p1.8.m8.1.2.3.2.3">ğ’¬</ci></apply><apply id="S3.p1.8.m8.1.2.3.3.cmml" xref="S3.p1.8.m8.1.2.3.3"><csymbol cd="ambiguous" id="S3.p1.8.m8.1.2.3.3.1.cmml" xref="S3.p1.8.m8.1.2.3.3">superscript</csymbol><ci id="S3.p1.8.m8.1.2.3.3.2.cmml" xref="S3.p1.8.m8.1.2.3.3.2">â„</ci><apply id="S3.p1.8.m8.1.1.1.2.cmml" xref="S3.p1.8.m8.1.1.1.3"><abs id="S3.p1.8.m8.1.1.1.2.1.cmml" xref="S3.p1.8.m8.1.1.1.3.1"></abs><ci id="S3.p1.8.m8.1.1.1.1.cmml" xref="S3.p1.8.m8.1.1.1.1">ğ’œ</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.8.m8.1c">f:\mathcal{V}\times\mathcal{Q}\rightarrow\mathbb{R}^{|\mathcal{A}|}</annotation></semantics></math> to produce accurate predictions. For a single example, VQA models use an image encoder <math id="S3.p1.9.m9.1" class="ltx_Math" alttext="e_{v}:\mathcal{V}\rightarrow\mathbb{R}^{n_{v}\times d_{v}}" display="inline"><semantics id="S3.p1.9.m9.1a"><mrow id="S3.p1.9.m9.1.1" xref="S3.p1.9.m9.1.1.cmml"><msub id="S3.p1.9.m9.1.1.2" xref="S3.p1.9.m9.1.1.2.cmml"><mi id="S3.p1.9.m9.1.1.2.2" xref="S3.p1.9.m9.1.1.2.2.cmml">e</mi><mi id="S3.p1.9.m9.1.1.2.3" xref="S3.p1.9.m9.1.1.2.3.cmml">v</mi></msub><mo lspace="0.278em" rspace="0.278em" id="S3.p1.9.m9.1.1.1" xref="S3.p1.9.m9.1.1.1.cmml">:</mo><mrow id="S3.p1.9.m9.1.1.3" xref="S3.p1.9.m9.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p1.9.m9.1.1.3.2" xref="S3.p1.9.m9.1.1.3.2.cmml">ğ’±</mi><mo stretchy="false" id="S3.p1.9.m9.1.1.3.1" xref="S3.p1.9.m9.1.1.3.1.cmml">â†’</mo><msup id="S3.p1.9.m9.1.1.3.3" xref="S3.p1.9.m9.1.1.3.3.cmml"><mi id="S3.p1.9.m9.1.1.3.3.2" xref="S3.p1.9.m9.1.1.3.3.2.cmml">â„</mi><mrow id="S3.p1.9.m9.1.1.3.3.3" xref="S3.p1.9.m9.1.1.3.3.3.cmml"><msub id="S3.p1.9.m9.1.1.3.3.3.2" xref="S3.p1.9.m9.1.1.3.3.3.2.cmml"><mi id="S3.p1.9.m9.1.1.3.3.3.2.2" xref="S3.p1.9.m9.1.1.3.3.3.2.2.cmml">n</mi><mi id="S3.p1.9.m9.1.1.3.3.3.2.3" xref="S3.p1.9.m9.1.1.3.3.3.2.3.cmml">v</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.p1.9.m9.1.1.3.3.3.1" xref="S3.p1.9.m9.1.1.3.3.3.1.cmml">Ã—</mo><msub id="S3.p1.9.m9.1.1.3.3.3.3" xref="S3.p1.9.m9.1.1.3.3.3.3.cmml"><mi id="S3.p1.9.m9.1.1.3.3.3.3.2" xref="S3.p1.9.m9.1.1.3.3.3.3.2.cmml">d</mi><mi id="S3.p1.9.m9.1.1.3.3.3.3.3" xref="S3.p1.9.m9.1.1.3.3.3.3.3.cmml">v</mi></msub></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.9.m9.1b"><apply id="S3.p1.9.m9.1.1.cmml" xref="S3.p1.9.m9.1.1"><ci id="S3.p1.9.m9.1.1.1.cmml" xref="S3.p1.9.m9.1.1.1">:</ci><apply id="S3.p1.9.m9.1.1.2.cmml" xref="S3.p1.9.m9.1.1.2"><csymbol cd="ambiguous" id="S3.p1.9.m9.1.1.2.1.cmml" xref="S3.p1.9.m9.1.1.2">subscript</csymbol><ci id="S3.p1.9.m9.1.1.2.2.cmml" xref="S3.p1.9.m9.1.1.2.2">ğ‘’</ci><ci id="S3.p1.9.m9.1.1.2.3.cmml" xref="S3.p1.9.m9.1.1.2.3">ğ‘£</ci></apply><apply id="S3.p1.9.m9.1.1.3.cmml" xref="S3.p1.9.m9.1.1.3"><ci id="S3.p1.9.m9.1.1.3.1.cmml" xref="S3.p1.9.m9.1.1.3.1">â†’</ci><ci id="S3.p1.9.m9.1.1.3.2.cmml" xref="S3.p1.9.m9.1.1.3.2">ğ’±</ci><apply id="S3.p1.9.m9.1.1.3.3.cmml" xref="S3.p1.9.m9.1.1.3.3"><csymbol cd="ambiguous" id="S3.p1.9.m9.1.1.3.3.1.cmml" xref="S3.p1.9.m9.1.1.3.3">superscript</csymbol><ci id="S3.p1.9.m9.1.1.3.3.2.cmml" xref="S3.p1.9.m9.1.1.3.3.2">â„</ci><apply id="S3.p1.9.m9.1.1.3.3.3.cmml" xref="S3.p1.9.m9.1.1.3.3.3"><times id="S3.p1.9.m9.1.1.3.3.3.1.cmml" xref="S3.p1.9.m9.1.1.3.3.3.1"></times><apply id="S3.p1.9.m9.1.1.3.3.3.2.cmml" xref="S3.p1.9.m9.1.1.3.3.3.2"><csymbol cd="ambiguous" id="S3.p1.9.m9.1.1.3.3.3.2.1.cmml" xref="S3.p1.9.m9.1.1.3.3.3.2">subscript</csymbol><ci id="S3.p1.9.m9.1.1.3.3.3.2.2.cmml" xref="S3.p1.9.m9.1.1.3.3.3.2.2">ğ‘›</ci><ci id="S3.p1.9.m9.1.1.3.3.3.2.3.cmml" xref="S3.p1.9.m9.1.1.3.3.3.2.3">ğ‘£</ci></apply><apply id="S3.p1.9.m9.1.1.3.3.3.3.cmml" xref="S3.p1.9.m9.1.1.3.3.3.3"><csymbol cd="ambiguous" id="S3.p1.9.m9.1.1.3.3.3.3.1.cmml" xref="S3.p1.9.m9.1.1.3.3.3.3">subscript</csymbol><ci id="S3.p1.9.m9.1.1.3.3.3.3.2.cmml" xref="S3.p1.9.m9.1.1.3.3.3.3.2">ğ‘‘</ci><ci id="S3.p1.9.m9.1.1.3.3.3.3.3.cmml" xref="S3.p1.9.m9.1.1.3.3.3.3.3">ğ‘£</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.9.m9.1c">e_{v}:\mathcal{V}\rightarrow\mathbb{R}^{n_{v}\times d_{v}}</annotation></semantics></math> to output a set of <math id="S3.p1.10.m10.1" class="ltx_Math" alttext="n_{v}" display="inline"><semantics id="S3.p1.10.m10.1a"><msub id="S3.p1.10.m10.1.1" xref="S3.p1.10.m10.1.1.cmml"><mi id="S3.p1.10.m10.1.1.2" xref="S3.p1.10.m10.1.1.2.cmml">n</mi><mi id="S3.p1.10.m10.1.1.3" xref="S3.p1.10.m10.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p1.10.m10.1b"><apply id="S3.p1.10.m10.1.1.cmml" xref="S3.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S3.p1.10.m10.1.1.1.cmml" xref="S3.p1.10.m10.1.1">subscript</csymbol><ci id="S3.p1.10.m10.1.1.2.cmml" xref="S3.p1.10.m10.1.1.2">ğ‘›</ci><ci id="S3.p1.10.m10.1.1.3.cmml" xref="S3.p1.10.m10.1.1.3">ğ‘£</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.10.m10.1c">n_{v}</annotation></semantics></math> vectors of dimension <math id="S3.p1.11.m11.1" class="ltx_Math" alttext="d_{v}" display="inline"><semantics id="S3.p1.11.m11.1a"><msub id="S3.p1.11.m11.1.1" xref="S3.p1.11.m11.1.1.cmml"><mi id="S3.p1.11.m11.1.1.2" xref="S3.p1.11.m11.1.1.2.cmml">d</mi><mi id="S3.p1.11.m11.1.1.3" xref="S3.p1.11.m11.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p1.11.m11.1b"><apply id="S3.p1.11.m11.1.1.cmml" xref="S3.p1.11.m11.1.1"><csymbol cd="ambiguous" id="S3.p1.11.m11.1.1.1.cmml" xref="S3.p1.11.m11.1.1">subscript</csymbol><ci id="S3.p1.11.m11.1.1.2.cmml" xref="S3.p1.11.m11.1.1.2">ğ‘‘</ci><ci id="S3.p1.11.m11.1.1.3.cmml" xref="S3.p1.11.m11.1.1.3">ğ‘£</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.11.m11.1c">d_{v}</annotation></semantics></math>, a question encoder <math id="S3.p1.12.m12.1" class="ltx_Math" alttext="e_{q}:\mathcal{Q}\rightarrow\mathbb{R}^{n_{q}\times d_{q}}" display="inline"><semantics id="S3.p1.12.m12.1a"><mrow id="S3.p1.12.m12.1.1" xref="S3.p1.12.m12.1.1.cmml"><msub id="S3.p1.12.m12.1.1.2" xref="S3.p1.12.m12.1.1.2.cmml"><mi id="S3.p1.12.m12.1.1.2.2" xref="S3.p1.12.m12.1.1.2.2.cmml">e</mi><mi id="S3.p1.12.m12.1.1.2.3" xref="S3.p1.12.m12.1.1.2.3.cmml">q</mi></msub><mo lspace="0.278em" rspace="0.278em" id="S3.p1.12.m12.1.1.1" xref="S3.p1.12.m12.1.1.1.cmml">:</mo><mrow id="S3.p1.12.m12.1.1.3" xref="S3.p1.12.m12.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p1.12.m12.1.1.3.2" xref="S3.p1.12.m12.1.1.3.2.cmml">ğ’¬</mi><mo stretchy="false" id="S3.p1.12.m12.1.1.3.1" xref="S3.p1.12.m12.1.1.3.1.cmml">â†’</mo><msup id="S3.p1.12.m12.1.1.3.3" xref="S3.p1.12.m12.1.1.3.3.cmml"><mi id="S3.p1.12.m12.1.1.3.3.2" xref="S3.p1.12.m12.1.1.3.3.2.cmml">â„</mi><mrow id="S3.p1.12.m12.1.1.3.3.3" xref="S3.p1.12.m12.1.1.3.3.3.cmml"><msub id="S3.p1.12.m12.1.1.3.3.3.2" xref="S3.p1.12.m12.1.1.3.3.3.2.cmml"><mi id="S3.p1.12.m12.1.1.3.3.3.2.2" xref="S3.p1.12.m12.1.1.3.3.3.2.2.cmml">n</mi><mi id="S3.p1.12.m12.1.1.3.3.3.2.3" xref="S3.p1.12.m12.1.1.3.3.3.2.3.cmml">q</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.p1.12.m12.1.1.3.3.3.1" xref="S3.p1.12.m12.1.1.3.3.3.1.cmml">Ã—</mo><msub id="S3.p1.12.m12.1.1.3.3.3.3" xref="S3.p1.12.m12.1.1.3.3.3.3.cmml"><mi id="S3.p1.12.m12.1.1.3.3.3.3.2" xref="S3.p1.12.m12.1.1.3.3.3.3.2.cmml">d</mi><mi id="S3.p1.12.m12.1.1.3.3.3.3.3" xref="S3.p1.12.m12.1.1.3.3.3.3.3.cmml">q</mi></msub></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.12.m12.1b"><apply id="S3.p1.12.m12.1.1.cmml" xref="S3.p1.12.m12.1.1"><ci id="S3.p1.12.m12.1.1.1.cmml" xref="S3.p1.12.m12.1.1.1">:</ci><apply id="S3.p1.12.m12.1.1.2.cmml" xref="S3.p1.12.m12.1.1.2"><csymbol cd="ambiguous" id="S3.p1.12.m12.1.1.2.1.cmml" xref="S3.p1.12.m12.1.1.2">subscript</csymbol><ci id="S3.p1.12.m12.1.1.2.2.cmml" xref="S3.p1.12.m12.1.1.2.2">ğ‘’</ci><ci id="S3.p1.12.m12.1.1.2.3.cmml" xref="S3.p1.12.m12.1.1.2.3">ğ‘</ci></apply><apply id="S3.p1.12.m12.1.1.3.cmml" xref="S3.p1.12.m12.1.1.3"><ci id="S3.p1.12.m12.1.1.3.1.cmml" xref="S3.p1.12.m12.1.1.3.1">â†’</ci><ci id="S3.p1.12.m12.1.1.3.2.cmml" xref="S3.p1.12.m12.1.1.3.2">ğ’¬</ci><apply id="S3.p1.12.m12.1.1.3.3.cmml" xref="S3.p1.12.m12.1.1.3.3"><csymbol cd="ambiguous" id="S3.p1.12.m12.1.1.3.3.1.cmml" xref="S3.p1.12.m12.1.1.3.3">superscript</csymbol><ci id="S3.p1.12.m12.1.1.3.3.2.cmml" xref="S3.p1.12.m12.1.1.3.3.2">â„</ci><apply id="S3.p1.12.m12.1.1.3.3.3.cmml" xref="S3.p1.12.m12.1.1.3.3.3"><times id="S3.p1.12.m12.1.1.3.3.3.1.cmml" xref="S3.p1.12.m12.1.1.3.3.3.1"></times><apply id="S3.p1.12.m12.1.1.3.3.3.2.cmml" xref="S3.p1.12.m12.1.1.3.3.3.2"><csymbol cd="ambiguous" id="S3.p1.12.m12.1.1.3.3.3.2.1.cmml" xref="S3.p1.12.m12.1.1.3.3.3.2">subscript</csymbol><ci id="S3.p1.12.m12.1.1.3.3.3.2.2.cmml" xref="S3.p1.12.m12.1.1.3.3.3.2.2">ğ‘›</ci><ci id="S3.p1.12.m12.1.1.3.3.3.2.3.cmml" xref="S3.p1.12.m12.1.1.3.3.3.2.3">ğ‘</ci></apply><apply id="S3.p1.12.m12.1.1.3.3.3.3.cmml" xref="S3.p1.12.m12.1.1.3.3.3.3"><csymbol cd="ambiguous" id="S3.p1.12.m12.1.1.3.3.3.3.1.cmml" xref="S3.p1.12.m12.1.1.3.3.3.3">subscript</csymbol><ci id="S3.p1.12.m12.1.1.3.3.3.3.2.cmml" xref="S3.p1.12.m12.1.1.3.3.3.3.2">ğ‘‘</ci><ci id="S3.p1.12.m12.1.1.3.3.3.3.3.cmml" xref="S3.p1.12.m12.1.1.3.3.3.3.3">ğ‘</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.12.m12.1c">e_{q}:\mathcal{Q}\rightarrow\mathbb{R}^{n_{q}\times d_{q}}</annotation></semantics></math> to output a set of <math id="S3.p1.13.m13.1" class="ltx_Math" alttext="n_{q}" display="inline"><semantics id="S3.p1.13.m13.1a"><msub id="S3.p1.13.m13.1.1" xref="S3.p1.13.m13.1.1.cmml"><mi id="S3.p1.13.m13.1.1.2" xref="S3.p1.13.m13.1.1.2.cmml">n</mi><mi id="S3.p1.13.m13.1.1.3" xref="S3.p1.13.m13.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p1.13.m13.1b"><apply id="S3.p1.13.m13.1.1.cmml" xref="S3.p1.13.m13.1.1"><csymbol cd="ambiguous" id="S3.p1.13.m13.1.1.1.cmml" xref="S3.p1.13.m13.1.1">subscript</csymbol><ci id="S3.p1.13.m13.1.1.2.cmml" xref="S3.p1.13.m13.1.1.2">ğ‘›</ci><ci id="S3.p1.13.m13.1.1.3.cmml" xref="S3.p1.13.m13.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.13.m13.1c">n_{q}</annotation></semantics></math> vectors of dimension <math id="S3.p1.14.m14.1" class="ltx_Math" alttext="d_{q}" display="inline"><semantics id="S3.p1.14.m14.1a"><msub id="S3.p1.14.m14.1.1" xref="S3.p1.14.m14.1.1.cmml"><mi id="S3.p1.14.m14.1.1.2" xref="S3.p1.14.m14.1.1.2.cmml">d</mi><mi id="S3.p1.14.m14.1.1.3" xref="S3.p1.14.m14.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p1.14.m14.1b"><apply id="S3.p1.14.m14.1.1.cmml" xref="S3.p1.14.m14.1.1"><csymbol cd="ambiguous" id="S3.p1.14.m14.1.1.1.cmml" xref="S3.p1.14.m14.1.1">subscript</csymbol><ci id="S3.p1.14.m14.1.1.2.cmml" xref="S3.p1.14.m14.1.1.2">ğ‘‘</ci><ci id="S3.p1.14.m14.1.1.3.cmml" xref="S3.p1.14.m14.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.14.m14.1c">d_{q}</annotation></semantics></math>, a multimodal fusion <math id="S3.p1.15.m15.1" class="ltx_Math" alttext="m:\mathbb{R}^{n_{v}\times d_{v}}\times\mathbb{R}^{n_{q}\times d_{q}}\rightarrow\mathbb{R}^{d_{m}}" display="inline"><semantics id="S3.p1.15.m15.1a"><mrow id="S3.p1.15.m15.1.1" xref="S3.p1.15.m15.1.1.cmml"><mi id="S3.p1.15.m15.1.1.2" xref="S3.p1.15.m15.1.1.2.cmml">m</mi><mo lspace="0.278em" rspace="0.278em" id="S3.p1.15.m15.1.1.1" xref="S3.p1.15.m15.1.1.1.cmml">:</mo><mrow id="S3.p1.15.m15.1.1.3" xref="S3.p1.15.m15.1.1.3.cmml"><mrow id="S3.p1.15.m15.1.1.3.2" xref="S3.p1.15.m15.1.1.3.2.cmml"><msup id="S3.p1.15.m15.1.1.3.2.2" xref="S3.p1.15.m15.1.1.3.2.2.cmml"><mi id="S3.p1.15.m15.1.1.3.2.2.2" xref="S3.p1.15.m15.1.1.3.2.2.2.cmml">â„</mi><mrow id="S3.p1.15.m15.1.1.3.2.2.3" xref="S3.p1.15.m15.1.1.3.2.2.3.cmml"><msub id="S3.p1.15.m15.1.1.3.2.2.3.2" xref="S3.p1.15.m15.1.1.3.2.2.3.2.cmml"><mi id="S3.p1.15.m15.1.1.3.2.2.3.2.2" xref="S3.p1.15.m15.1.1.3.2.2.3.2.2.cmml">n</mi><mi id="S3.p1.15.m15.1.1.3.2.2.3.2.3" xref="S3.p1.15.m15.1.1.3.2.2.3.2.3.cmml">v</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.p1.15.m15.1.1.3.2.2.3.1" xref="S3.p1.15.m15.1.1.3.2.2.3.1.cmml">Ã—</mo><msub id="S3.p1.15.m15.1.1.3.2.2.3.3" xref="S3.p1.15.m15.1.1.3.2.2.3.3.cmml"><mi id="S3.p1.15.m15.1.1.3.2.2.3.3.2" xref="S3.p1.15.m15.1.1.3.2.2.3.3.2.cmml">d</mi><mi id="S3.p1.15.m15.1.1.3.2.2.3.3.3" xref="S3.p1.15.m15.1.1.3.2.2.3.3.3.cmml">v</mi></msub></mrow></msup><mo lspace="0.222em" rspace="0.222em" id="S3.p1.15.m15.1.1.3.2.1" xref="S3.p1.15.m15.1.1.3.2.1.cmml">Ã—</mo><msup id="S3.p1.15.m15.1.1.3.2.3" xref="S3.p1.15.m15.1.1.3.2.3.cmml"><mi id="S3.p1.15.m15.1.1.3.2.3.2" xref="S3.p1.15.m15.1.1.3.2.3.2.cmml">â„</mi><mrow id="S3.p1.15.m15.1.1.3.2.3.3" xref="S3.p1.15.m15.1.1.3.2.3.3.cmml"><msub id="S3.p1.15.m15.1.1.3.2.3.3.2" xref="S3.p1.15.m15.1.1.3.2.3.3.2.cmml"><mi id="S3.p1.15.m15.1.1.3.2.3.3.2.2" xref="S3.p1.15.m15.1.1.3.2.3.3.2.2.cmml">n</mi><mi id="S3.p1.15.m15.1.1.3.2.3.3.2.3" xref="S3.p1.15.m15.1.1.3.2.3.3.2.3.cmml">q</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.p1.15.m15.1.1.3.2.3.3.1" xref="S3.p1.15.m15.1.1.3.2.3.3.1.cmml">Ã—</mo><msub id="S3.p1.15.m15.1.1.3.2.3.3.3" xref="S3.p1.15.m15.1.1.3.2.3.3.3.cmml"><mi id="S3.p1.15.m15.1.1.3.2.3.3.3.2" xref="S3.p1.15.m15.1.1.3.2.3.3.3.2.cmml">d</mi><mi id="S3.p1.15.m15.1.1.3.2.3.3.3.3" xref="S3.p1.15.m15.1.1.3.2.3.3.3.3.cmml">q</mi></msub></mrow></msup></mrow><mo stretchy="false" id="S3.p1.15.m15.1.1.3.1" xref="S3.p1.15.m15.1.1.3.1.cmml">â†’</mo><msup id="S3.p1.15.m15.1.1.3.3" xref="S3.p1.15.m15.1.1.3.3.cmml"><mi id="S3.p1.15.m15.1.1.3.3.2" xref="S3.p1.15.m15.1.1.3.3.2.cmml">â„</mi><msub id="S3.p1.15.m15.1.1.3.3.3" xref="S3.p1.15.m15.1.1.3.3.3.cmml"><mi id="S3.p1.15.m15.1.1.3.3.3.2" xref="S3.p1.15.m15.1.1.3.3.3.2.cmml">d</mi><mi id="S3.p1.15.m15.1.1.3.3.3.3" xref="S3.p1.15.m15.1.1.3.3.3.3.cmml">m</mi></msub></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.15.m15.1b"><apply id="S3.p1.15.m15.1.1.cmml" xref="S3.p1.15.m15.1.1"><ci id="S3.p1.15.m15.1.1.1.cmml" xref="S3.p1.15.m15.1.1.1">:</ci><ci id="S3.p1.15.m15.1.1.2.cmml" xref="S3.p1.15.m15.1.1.2">ğ‘š</ci><apply id="S3.p1.15.m15.1.1.3.cmml" xref="S3.p1.15.m15.1.1.3"><ci id="S3.p1.15.m15.1.1.3.1.cmml" xref="S3.p1.15.m15.1.1.3.1">â†’</ci><apply id="S3.p1.15.m15.1.1.3.2.cmml" xref="S3.p1.15.m15.1.1.3.2"><times id="S3.p1.15.m15.1.1.3.2.1.cmml" xref="S3.p1.15.m15.1.1.3.2.1"></times><apply id="S3.p1.15.m15.1.1.3.2.2.cmml" xref="S3.p1.15.m15.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.p1.15.m15.1.1.3.2.2.1.cmml" xref="S3.p1.15.m15.1.1.3.2.2">superscript</csymbol><ci id="S3.p1.15.m15.1.1.3.2.2.2.cmml" xref="S3.p1.15.m15.1.1.3.2.2.2">â„</ci><apply id="S3.p1.15.m15.1.1.3.2.2.3.cmml" xref="S3.p1.15.m15.1.1.3.2.2.3"><times id="S3.p1.15.m15.1.1.3.2.2.3.1.cmml" xref="S3.p1.15.m15.1.1.3.2.2.3.1"></times><apply id="S3.p1.15.m15.1.1.3.2.2.3.2.cmml" xref="S3.p1.15.m15.1.1.3.2.2.3.2"><csymbol cd="ambiguous" id="S3.p1.15.m15.1.1.3.2.2.3.2.1.cmml" xref="S3.p1.15.m15.1.1.3.2.2.3.2">subscript</csymbol><ci id="S3.p1.15.m15.1.1.3.2.2.3.2.2.cmml" xref="S3.p1.15.m15.1.1.3.2.2.3.2.2">ğ‘›</ci><ci id="S3.p1.15.m15.1.1.3.2.2.3.2.3.cmml" xref="S3.p1.15.m15.1.1.3.2.2.3.2.3">ğ‘£</ci></apply><apply id="S3.p1.15.m15.1.1.3.2.2.3.3.cmml" xref="S3.p1.15.m15.1.1.3.2.2.3.3"><csymbol cd="ambiguous" id="S3.p1.15.m15.1.1.3.2.2.3.3.1.cmml" xref="S3.p1.15.m15.1.1.3.2.2.3.3">subscript</csymbol><ci id="S3.p1.15.m15.1.1.3.2.2.3.3.2.cmml" xref="S3.p1.15.m15.1.1.3.2.2.3.3.2">ğ‘‘</ci><ci id="S3.p1.15.m15.1.1.3.2.2.3.3.3.cmml" xref="S3.p1.15.m15.1.1.3.2.2.3.3.3">ğ‘£</ci></apply></apply></apply><apply id="S3.p1.15.m15.1.1.3.2.3.cmml" xref="S3.p1.15.m15.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.p1.15.m15.1.1.3.2.3.1.cmml" xref="S3.p1.15.m15.1.1.3.2.3">superscript</csymbol><ci id="S3.p1.15.m15.1.1.3.2.3.2.cmml" xref="S3.p1.15.m15.1.1.3.2.3.2">â„</ci><apply id="S3.p1.15.m15.1.1.3.2.3.3.cmml" xref="S3.p1.15.m15.1.1.3.2.3.3"><times id="S3.p1.15.m15.1.1.3.2.3.3.1.cmml" xref="S3.p1.15.m15.1.1.3.2.3.3.1"></times><apply id="S3.p1.15.m15.1.1.3.2.3.3.2.cmml" xref="S3.p1.15.m15.1.1.3.2.3.3.2"><csymbol cd="ambiguous" id="S3.p1.15.m15.1.1.3.2.3.3.2.1.cmml" xref="S3.p1.15.m15.1.1.3.2.3.3.2">subscript</csymbol><ci id="S3.p1.15.m15.1.1.3.2.3.3.2.2.cmml" xref="S3.p1.15.m15.1.1.3.2.3.3.2.2">ğ‘›</ci><ci id="S3.p1.15.m15.1.1.3.2.3.3.2.3.cmml" xref="S3.p1.15.m15.1.1.3.2.3.3.2.3">ğ‘</ci></apply><apply id="S3.p1.15.m15.1.1.3.2.3.3.3.cmml" xref="S3.p1.15.m15.1.1.3.2.3.3.3"><csymbol cd="ambiguous" id="S3.p1.15.m15.1.1.3.2.3.3.3.1.cmml" xref="S3.p1.15.m15.1.1.3.2.3.3.3">subscript</csymbol><ci id="S3.p1.15.m15.1.1.3.2.3.3.3.2.cmml" xref="S3.p1.15.m15.1.1.3.2.3.3.3.2">ğ‘‘</ci><ci id="S3.p1.15.m15.1.1.3.2.3.3.3.3.cmml" xref="S3.p1.15.m15.1.1.3.2.3.3.3.3">ğ‘</ci></apply></apply></apply></apply><apply id="S3.p1.15.m15.1.1.3.3.cmml" xref="S3.p1.15.m15.1.1.3.3"><csymbol cd="ambiguous" id="S3.p1.15.m15.1.1.3.3.1.cmml" xref="S3.p1.15.m15.1.1.3.3">superscript</csymbol><ci id="S3.p1.15.m15.1.1.3.3.2.cmml" xref="S3.p1.15.m15.1.1.3.3.2">â„</ci><apply id="S3.p1.15.m15.1.1.3.3.3.cmml" xref="S3.p1.15.m15.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.p1.15.m15.1.1.3.3.3.1.cmml" xref="S3.p1.15.m15.1.1.3.3.3">subscript</csymbol><ci id="S3.p1.15.m15.1.1.3.3.3.2.cmml" xref="S3.p1.15.m15.1.1.3.3.3.2">ğ‘‘</ci><ci id="S3.p1.15.m15.1.1.3.3.3.3.cmml" xref="S3.p1.15.m15.1.1.3.3.3.3">ğ‘š</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.15.m15.1c">m:\mathbb{R}^{n_{v}\times d_{v}}\times\mathbb{R}^{n_{q}\times d_{q}}\rightarrow\mathbb{R}^{d_{m}}</annotation></semantics></math>, and a classifier <math id="S3.p1.16.m16.1" class="ltx_Math" alttext="c:\mathbb{R}^{d_{m}}\rightarrow\mathbb{R}^{|\mathcal{A}|}" display="inline"><semantics id="S3.p1.16.m16.1a"><mrow id="S3.p1.16.m16.1.2" xref="S3.p1.16.m16.1.2.cmml"><mi id="S3.p1.16.m16.1.2.2" xref="S3.p1.16.m16.1.2.2.cmml">c</mi><mo lspace="0.278em" rspace="0.278em" id="S3.p1.16.m16.1.2.1" xref="S3.p1.16.m16.1.2.1.cmml">:</mo><mrow id="S3.p1.16.m16.1.2.3" xref="S3.p1.16.m16.1.2.3.cmml"><msup id="S3.p1.16.m16.1.2.3.2" xref="S3.p1.16.m16.1.2.3.2.cmml"><mi id="S3.p1.16.m16.1.2.3.2.2" xref="S3.p1.16.m16.1.2.3.2.2.cmml">â„</mi><msub id="S3.p1.16.m16.1.2.3.2.3" xref="S3.p1.16.m16.1.2.3.2.3.cmml"><mi id="S3.p1.16.m16.1.2.3.2.3.2" xref="S3.p1.16.m16.1.2.3.2.3.2.cmml">d</mi><mi id="S3.p1.16.m16.1.2.3.2.3.3" xref="S3.p1.16.m16.1.2.3.2.3.3.cmml">m</mi></msub></msup><mo stretchy="false" id="S3.p1.16.m16.1.2.3.1" xref="S3.p1.16.m16.1.2.3.1.cmml">â†’</mo><msup id="S3.p1.16.m16.1.2.3.3" xref="S3.p1.16.m16.1.2.3.3.cmml"><mi id="S3.p1.16.m16.1.2.3.3.2" xref="S3.p1.16.m16.1.2.3.3.2.cmml">â„</mi><mrow id="S3.p1.16.m16.1.1.1.3" xref="S3.p1.16.m16.1.1.1.2.cmml"><mo stretchy="false" id="S3.p1.16.m16.1.1.1.3.1" xref="S3.p1.16.m16.1.1.1.2.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S3.p1.16.m16.1.1.1.1" xref="S3.p1.16.m16.1.1.1.1.cmml">ğ’œ</mi><mo stretchy="false" id="S3.p1.16.m16.1.1.1.3.2" xref="S3.p1.16.m16.1.1.1.2.1.cmml">|</mo></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.16.m16.1b"><apply id="S3.p1.16.m16.1.2.cmml" xref="S3.p1.16.m16.1.2"><ci id="S3.p1.16.m16.1.2.1.cmml" xref="S3.p1.16.m16.1.2.1">:</ci><ci id="S3.p1.16.m16.1.2.2.cmml" xref="S3.p1.16.m16.1.2.2">ğ‘</ci><apply id="S3.p1.16.m16.1.2.3.cmml" xref="S3.p1.16.m16.1.2.3"><ci id="S3.p1.16.m16.1.2.3.1.cmml" xref="S3.p1.16.m16.1.2.3.1">â†’</ci><apply id="S3.p1.16.m16.1.2.3.2.cmml" xref="S3.p1.16.m16.1.2.3.2"><csymbol cd="ambiguous" id="S3.p1.16.m16.1.2.3.2.1.cmml" xref="S3.p1.16.m16.1.2.3.2">superscript</csymbol><ci id="S3.p1.16.m16.1.2.3.2.2.cmml" xref="S3.p1.16.m16.1.2.3.2.2">â„</ci><apply id="S3.p1.16.m16.1.2.3.2.3.cmml" xref="S3.p1.16.m16.1.2.3.2.3"><csymbol cd="ambiguous" id="S3.p1.16.m16.1.2.3.2.3.1.cmml" xref="S3.p1.16.m16.1.2.3.2.3">subscript</csymbol><ci id="S3.p1.16.m16.1.2.3.2.3.2.cmml" xref="S3.p1.16.m16.1.2.3.2.3.2">ğ‘‘</ci><ci id="S3.p1.16.m16.1.2.3.2.3.3.cmml" xref="S3.p1.16.m16.1.2.3.2.3.3">ğ‘š</ci></apply></apply><apply id="S3.p1.16.m16.1.2.3.3.cmml" xref="S3.p1.16.m16.1.2.3.3"><csymbol cd="ambiguous" id="S3.p1.16.m16.1.2.3.3.1.cmml" xref="S3.p1.16.m16.1.2.3.3">superscript</csymbol><ci id="S3.p1.16.m16.1.2.3.3.2.cmml" xref="S3.p1.16.m16.1.2.3.3.2">â„</ci><apply id="S3.p1.16.m16.1.1.1.2.cmml" xref="S3.p1.16.m16.1.1.1.3"><abs id="S3.p1.16.m16.1.1.1.2.1.cmml" xref="S3.p1.16.m16.1.1.1.3.1"></abs><ci id="S3.p1.16.m16.1.1.1.1.cmml" xref="S3.p1.16.m16.1.1.1.1">ğ’œ</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.16.m16.1c">c:\mathbb{R}^{d_{m}}\rightarrow\mathbb{R}^{|\mathcal{A}|}</annotation></semantics></math>.
These functions are composed as follows:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.3" class="ltx_Math" alttext="f(v_{i},q_{i})=c(m(e_{v}(v_{i}),e_{q}(q_{i})))" display="block"><semantics id="S3.E1.m1.3a"><mrow id="S3.E1.m1.3.3" xref="S3.E1.m1.3.3.cmml"><mrow id="S3.E1.m1.2.2.2" xref="S3.E1.m1.2.2.2.cmml"><mi id="S3.E1.m1.2.2.2.4" xref="S3.E1.m1.2.2.2.4.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.2.3" xref="S3.E1.m1.2.2.2.3.cmml">â€‹</mo><mrow id="S3.E1.m1.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.E1.m1.2.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.3.cmml">(</mo><msub id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.2.cmml">v</mi><mi id="S3.E1.m1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E1.m1.2.2.2.2.2.4" xref="S3.E1.m1.2.2.2.2.3.cmml">,</mo><msub id="S3.E1.m1.2.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.2.cmml"><mi id="S3.E1.m1.2.2.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.2.2.cmml">q</mi><mi id="S3.E1.m1.2.2.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E1.m1.2.2.2.2.2.5" xref="S3.E1.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.3.3.4" xref="S3.E1.m1.3.3.4.cmml">=</mo><mrow id="S3.E1.m1.3.3.3" xref="S3.E1.m1.3.3.3.cmml"><mi id="S3.E1.m1.3.3.3.3" xref="S3.E1.m1.3.3.3.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.3.2" xref="S3.E1.m1.3.3.3.2.cmml">â€‹</mo><mrow id="S3.E1.m1.3.3.3.1.1" xref="S3.E1.m1.3.3.3.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.3.3.3.1.1.2" xref="S3.E1.m1.3.3.3.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.3.3.3.1.1.1" xref="S3.E1.m1.3.3.3.1.1.1.cmml"><mi id="S3.E1.m1.3.3.3.1.1.1.4" xref="S3.E1.m1.3.3.3.1.1.1.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.3.1.1.1.3" xref="S3.E1.m1.3.3.3.1.1.1.3.cmml">â€‹</mo><mrow id="S3.E1.m1.3.3.3.1.1.1.2.2" xref="S3.E1.m1.3.3.3.1.1.1.2.3.cmml"><mo stretchy="false" id="S3.E1.m1.3.3.3.1.1.1.2.2.3" xref="S3.E1.m1.3.3.3.1.1.1.2.3.cmml">(</mo><mrow id="S3.E1.m1.3.3.3.1.1.1.1.1.1" xref="S3.E1.m1.3.3.3.1.1.1.1.1.1.cmml"><msub id="S3.E1.m1.3.3.3.1.1.1.1.1.1.3" xref="S3.E1.m1.3.3.3.1.1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.3.3.3.1.1.1.1.1.1.3.2" xref="S3.E1.m1.3.3.3.1.1.1.1.1.1.3.2.cmml">e</mi><mi id="S3.E1.m1.3.3.3.1.1.1.1.1.1.3.3" xref="S3.E1.m1.3.3.3.1.1.1.1.1.1.3.3.cmml">v</mi></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.3.1.1.1.1.1.1.2" xref="S3.E1.m1.3.3.3.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E1.m1.3.3.3.1.1.1.1.1.1.1.1" xref="S3.E1.m1.3.3.3.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.3.3.3.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.3.3.3.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E1.m1.3.3.3.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.3.3.3.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.3.3.3.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.3.3.3.1.1.1.1.1.1.1.1.1.2.cmml">v</mi><mi id="S3.E1.m1.3.3.3.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.3.3.3.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E1.m1.3.3.3.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.3.3.3.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.3.3.3.1.1.1.2.2.4" xref="S3.E1.m1.3.3.3.1.1.1.2.3.cmml">,</mo><mrow id="S3.E1.m1.3.3.3.1.1.1.2.2.2" xref="S3.E1.m1.3.3.3.1.1.1.2.2.2.cmml"><msub id="S3.E1.m1.3.3.3.1.1.1.2.2.2.3" xref="S3.E1.m1.3.3.3.1.1.1.2.2.2.3.cmml"><mi id="S3.E1.m1.3.3.3.1.1.1.2.2.2.3.2" xref="S3.E1.m1.3.3.3.1.1.1.2.2.2.3.2.cmml">e</mi><mi id="S3.E1.m1.3.3.3.1.1.1.2.2.2.3.3" xref="S3.E1.m1.3.3.3.1.1.1.2.2.2.3.3.cmml">q</mi></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.3.1.1.1.2.2.2.2" xref="S3.E1.m1.3.3.3.1.1.1.2.2.2.2.cmml">â€‹</mo><mrow id="S3.E1.m1.3.3.3.1.1.1.2.2.2.1.1" xref="S3.E1.m1.3.3.3.1.1.1.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.3.3.3.1.1.1.2.2.2.1.1.2" xref="S3.E1.m1.3.3.3.1.1.1.2.2.2.1.1.1.cmml">(</mo><msub id="S3.E1.m1.3.3.3.1.1.1.2.2.2.1.1.1" xref="S3.E1.m1.3.3.3.1.1.1.2.2.2.1.1.1.cmml"><mi id="S3.E1.m1.3.3.3.1.1.1.2.2.2.1.1.1.2" xref="S3.E1.m1.3.3.3.1.1.1.2.2.2.1.1.1.2.cmml">q</mi><mi id="S3.E1.m1.3.3.3.1.1.1.2.2.2.1.1.1.3" xref="S3.E1.m1.3.3.3.1.1.1.2.2.2.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E1.m1.3.3.3.1.1.1.2.2.2.1.1.3" xref="S3.E1.m1.3.3.3.1.1.1.2.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E1.m1.3.3.3.1.1.1.2.2.5" xref="S3.E1.m1.3.3.3.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E1.m1.3.3.3.1.1.3" xref="S3.E1.m1.3.3.3.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.3b"><apply id="S3.E1.m1.3.3.cmml" xref="S3.E1.m1.3.3"><eq id="S3.E1.m1.3.3.4.cmml" xref="S3.E1.m1.3.3.4"></eq><apply id="S3.E1.m1.2.2.2.cmml" xref="S3.E1.m1.2.2.2"><times id="S3.E1.m1.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.3"></times><ci id="S3.E1.m1.2.2.2.4.cmml" xref="S3.E1.m1.2.2.2.4">ğ‘“</ci><interval closure="open" id="S3.E1.m1.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2"><apply id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2">ğ‘£</ci><ci id="S3.E1.m1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.E1.m1.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E1.m1.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2">ğ‘</ci><ci id="S3.E1.m1.2.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2.2.3">ğ‘–</ci></apply></interval></apply><apply id="S3.E1.m1.3.3.3.cmml" xref="S3.E1.m1.3.3.3"><times id="S3.E1.m1.3.3.3.2.cmml" xref="S3.E1.m1.3.3.3.2"></times><ci id="S3.E1.m1.3.3.3.3.cmml" xref="S3.E1.m1.3.3.3.3">ğ‘</ci><apply id="S3.E1.m1.3.3.3.1.1.1.cmml" xref="S3.E1.m1.3.3.3.1.1"><times id="S3.E1.m1.3.3.3.1.1.1.3.cmml" xref="S3.E1.m1.3.3.3.1.1.1.3"></times><ci id="S3.E1.m1.3.3.3.1.1.1.4.cmml" xref="S3.E1.m1.3.3.3.1.1.1.4">ğ‘š</ci><interval closure="open" id="S3.E1.m1.3.3.3.1.1.1.2.3.cmml" xref="S3.E1.m1.3.3.3.1.1.1.2.2"><apply id="S3.E1.m1.3.3.3.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.3.1.1.1.1.1.1"><times id="S3.E1.m1.3.3.3.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.3.1.1.1.1.1.1.2"></times><apply id="S3.E1.m1.3.3.3.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.3.3.3.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.3.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.3.3.3.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.3.3.3.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.3.3.3.1.1.1.1.1.1.3.2">ğ‘’</ci><ci id="S3.E1.m1.3.3.3.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.3.3.3.1.1.1.1.1.1.3.3">ğ‘£</ci></apply><apply id="S3.E1.m1.3.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.3.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.3.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.3.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.3.3.3.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.3.1.1.1.1.1.1.1.1.1.2">ğ‘£</ci><ci id="S3.E1.m1.3.3.3.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.3.3.3.1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply><apply id="S3.E1.m1.3.3.3.1.1.1.2.2.2.cmml" xref="S3.E1.m1.3.3.3.1.1.1.2.2.2"><times id="S3.E1.m1.3.3.3.1.1.1.2.2.2.2.cmml" xref="S3.E1.m1.3.3.3.1.1.1.2.2.2.2"></times><apply id="S3.E1.m1.3.3.3.1.1.1.2.2.2.3.cmml" xref="S3.E1.m1.3.3.3.1.1.1.2.2.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.3.1.1.1.2.2.2.3.1.cmml" xref="S3.E1.m1.3.3.3.1.1.1.2.2.2.3">subscript</csymbol><ci id="S3.E1.m1.3.3.3.1.1.1.2.2.2.3.2.cmml" xref="S3.E1.m1.3.3.3.1.1.1.2.2.2.3.2">ğ‘’</ci><ci id="S3.E1.m1.3.3.3.1.1.1.2.2.2.3.3.cmml" xref="S3.E1.m1.3.3.3.1.1.1.2.2.2.3.3">ğ‘</ci></apply><apply id="S3.E1.m1.3.3.3.1.1.1.2.2.2.1.1.1.cmml" xref="S3.E1.m1.3.3.3.1.1.1.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.3.1.1.1.2.2.2.1.1.1.1.cmml" xref="S3.E1.m1.3.3.3.1.1.1.2.2.2.1.1">subscript</csymbol><ci id="S3.E1.m1.3.3.3.1.1.1.2.2.2.1.1.1.2.cmml" xref="S3.E1.m1.3.3.3.1.1.1.2.2.2.1.1.1.2">ğ‘</ci><ci id="S3.E1.m1.3.3.3.1.1.1.2.2.2.1.1.1.3.cmml" xref="S3.E1.m1.3.3.3.1.1.1.2.2.2.1.1.1.3">ğ‘–</ci></apply></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.3c">f(v_{i},q_{i})=c(m(e_{v}(v_{i}),e_{q}(q_{i})))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.p1.17" class="ltx_p">Each one of them can be defined to instantiate most of the state of the art models, such as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> to cite a few.</p>
</div>
<section id="S3.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Classical learning strategy and pitfall</h4>

<div id="S3.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px1.p1.1" class="ltx_p">The classical learning strategy of VQA models, depicted in FigureÂ <a href="#S3.F2" title="Figure 2 â€£ 3.1 RUBi learning strategy â€£ 3 Reducing Unimodal Biases Approach â€£ RUBi: Reducing Unimodal Biases for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, consists in minimizing the standard cross-entropy criterion over a dataset of size <math id="S3.SS0.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS0.SSS0.Px1.p1.1.m1.1a"><mi id="S3.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.1.m1.1b"><ci id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.1.m1.1c">n</annotation></semantics></math>.</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.5" class="ltx_Math" alttext="\mathcal{L}(\theta;\mathcal{D})=-\frac{1}{n}\sum^{n}_{i=1}\log(\text{softmax}(f(v_{i},q_{i})))[a_{i}]" display="block"><semantics id="S3.E2.m1.5a"><mrow id="S3.E2.m1.5.5" xref="S3.E2.m1.5.5.cmml"><mrow id="S3.E2.m1.5.5.4" xref="S3.E2.m1.5.5.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.5.5.4.2" xref="S3.E2.m1.5.5.4.2.cmml">â„’</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.5.5.4.1" xref="S3.E2.m1.5.5.4.1.cmml">â€‹</mo><mrow id="S3.E2.m1.5.5.4.3.2" xref="S3.E2.m1.5.5.4.3.1.cmml"><mo stretchy="false" id="S3.E2.m1.5.5.4.3.2.1" xref="S3.E2.m1.5.5.4.3.1.cmml">(</mo><mi id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">Î¸</mi><mo id="S3.E2.m1.5.5.4.3.2.2" xref="S3.E2.m1.5.5.4.3.1.cmml">;</mo><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml">ğ’Ÿ</mi><mo stretchy="false" id="S3.E2.m1.5.5.4.3.2.3" xref="S3.E2.m1.5.5.4.3.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.5.5.3" xref="S3.E2.m1.5.5.3.cmml">=</mo><mrow id="S3.E2.m1.5.5.2" xref="S3.E2.m1.5.5.2.cmml"><mo id="S3.E2.m1.5.5.2a" xref="S3.E2.m1.5.5.2.cmml">âˆ’</mo><mrow id="S3.E2.m1.5.5.2.2" xref="S3.E2.m1.5.5.2.2.cmml"><mfrac id="S3.E2.m1.5.5.2.2.4" xref="S3.E2.m1.5.5.2.2.4.cmml"><mn id="S3.E2.m1.5.5.2.2.4.2" xref="S3.E2.m1.5.5.2.2.4.2.cmml">1</mn><mi id="S3.E2.m1.5.5.2.2.4.3" xref="S3.E2.m1.5.5.2.2.4.3.cmml">n</mi></mfrac><mo lspace="0em" rspace="0em" id="S3.E2.m1.5.5.2.2.3" xref="S3.E2.m1.5.5.2.2.3.cmml">â€‹</mo><mrow id="S3.E2.m1.5.5.2.2.2" xref="S3.E2.m1.5.5.2.2.2.cmml"><munderover id="S3.E2.m1.5.5.2.2.2.3" xref="S3.E2.m1.5.5.2.2.2.3.cmml"><mo movablelimits="false" id="S3.E2.m1.5.5.2.2.2.3.2.2" xref="S3.E2.m1.5.5.2.2.2.3.2.2.cmml">âˆ‘</mo><mrow id="S3.E2.m1.5.5.2.2.2.3.3" xref="S3.E2.m1.5.5.2.2.2.3.3.cmml"><mi id="S3.E2.m1.5.5.2.2.2.3.3.2" xref="S3.E2.m1.5.5.2.2.2.3.3.2.cmml">i</mi><mo id="S3.E2.m1.5.5.2.2.2.3.3.1" xref="S3.E2.m1.5.5.2.2.2.3.3.1.cmml">=</mo><mn id="S3.E2.m1.5.5.2.2.2.3.3.3" xref="S3.E2.m1.5.5.2.2.2.3.3.3.cmml">1</mn></mrow><mi id="S3.E2.m1.5.5.2.2.2.3.2.3" xref="S3.E2.m1.5.5.2.2.2.3.2.3.cmml">n</mi></munderover><mrow id="S3.E2.m1.5.5.2.2.2.2" xref="S3.E2.m1.5.5.2.2.2.2.cmml"><mrow id="S3.E2.m1.4.4.1.1.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.1.2.cmml"><mi id="S3.E2.m1.3.3" xref="S3.E2.m1.3.3.cmml">log</mi><mo id="S3.E2.m1.4.4.1.1.1.1.1.1a" xref="S3.E2.m1.4.4.1.1.1.1.1.2.cmml">â¡</mo><mrow id="S3.E2.m1.4.4.1.1.1.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E2.m1.4.4.1.1.1.1.1.1.1.2" xref="S3.E2.m1.4.4.1.1.1.1.1.2.cmml">(</mo><mrow id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.cmml"><mtext id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.3a.cmml">softmax</mtext><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.4" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.4.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.3.cmml">â€‹</mo><mrow id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml"><mo stretchy="false" id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.2.3" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">(</mo><msub id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">v</mi><mi id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.2.4" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">,</mo><msub id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.2.2" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml"><mi id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml">q</mi><mi id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.2.2.3" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.2.5" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E2.m1.4.4.1.1.1.1.1.1.1.3" xref="S3.E2.m1.4.4.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo lspace="0em" rspace="0em" id="S3.E2.m1.5.5.2.2.2.2.3" xref="S3.E2.m1.5.5.2.2.2.2.3.cmml">â€‹</mo><mrow id="S3.E2.m1.5.5.2.2.2.2.2.1" xref="S3.E2.m1.5.5.2.2.2.2.2.2.cmml"><mo stretchy="false" id="S3.E2.m1.5.5.2.2.2.2.2.1.2" xref="S3.E2.m1.5.5.2.2.2.2.2.2.1.cmml">[</mo><msub id="S3.E2.m1.5.5.2.2.2.2.2.1.1" xref="S3.E2.m1.5.5.2.2.2.2.2.1.1.cmml"><mi id="S3.E2.m1.5.5.2.2.2.2.2.1.1.2" xref="S3.E2.m1.5.5.2.2.2.2.2.1.1.2.cmml">a</mi><mi id="S3.E2.m1.5.5.2.2.2.2.2.1.1.3" xref="S3.E2.m1.5.5.2.2.2.2.2.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E2.m1.5.5.2.2.2.2.2.1.3" xref="S3.E2.m1.5.5.2.2.2.2.2.2.1.cmml">]</mo></mrow></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.5b"><apply id="S3.E2.m1.5.5.cmml" xref="S3.E2.m1.5.5"><eq id="S3.E2.m1.5.5.3.cmml" xref="S3.E2.m1.5.5.3"></eq><apply id="S3.E2.m1.5.5.4.cmml" xref="S3.E2.m1.5.5.4"><times id="S3.E2.m1.5.5.4.1.cmml" xref="S3.E2.m1.5.5.4.1"></times><ci id="S3.E2.m1.5.5.4.2.cmml" xref="S3.E2.m1.5.5.4.2">â„’</ci><list id="S3.E2.m1.5.5.4.3.1.cmml" xref="S3.E2.m1.5.5.4.3.2"><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">ğœƒ</ci><ci id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2">ğ’Ÿ</ci></list></apply><apply id="S3.E2.m1.5.5.2.cmml" xref="S3.E2.m1.5.5.2"><minus id="S3.E2.m1.5.5.2.3.cmml" xref="S3.E2.m1.5.5.2"></minus><apply id="S3.E2.m1.5.5.2.2.cmml" xref="S3.E2.m1.5.5.2.2"><times id="S3.E2.m1.5.5.2.2.3.cmml" xref="S3.E2.m1.5.5.2.2.3"></times><apply id="S3.E2.m1.5.5.2.2.4.cmml" xref="S3.E2.m1.5.5.2.2.4"><divide id="S3.E2.m1.5.5.2.2.4.1.cmml" xref="S3.E2.m1.5.5.2.2.4"></divide><cn type="integer" id="S3.E2.m1.5.5.2.2.4.2.cmml" xref="S3.E2.m1.5.5.2.2.4.2">1</cn><ci id="S3.E2.m1.5.5.2.2.4.3.cmml" xref="S3.E2.m1.5.5.2.2.4.3">ğ‘›</ci></apply><apply id="S3.E2.m1.5.5.2.2.2.cmml" xref="S3.E2.m1.5.5.2.2.2"><apply id="S3.E2.m1.5.5.2.2.2.3.cmml" xref="S3.E2.m1.5.5.2.2.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.5.5.2.2.2.3.1.cmml" xref="S3.E2.m1.5.5.2.2.2.3">subscript</csymbol><apply id="S3.E2.m1.5.5.2.2.2.3.2.cmml" xref="S3.E2.m1.5.5.2.2.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.5.5.2.2.2.3.2.1.cmml" xref="S3.E2.m1.5.5.2.2.2.3">superscript</csymbol><sum id="S3.E2.m1.5.5.2.2.2.3.2.2.cmml" xref="S3.E2.m1.5.5.2.2.2.3.2.2"></sum><ci id="S3.E2.m1.5.5.2.2.2.3.2.3.cmml" xref="S3.E2.m1.5.5.2.2.2.3.2.3">ğ‘›</ci></apply><apply id="S3.E2.m1.5.5.2.2.2.3.3.cmml" xref="S3.E2.m1.5.5.2.2.2.3.3"><eq id="S3.E2.m1.5.5.2.2.2.3.3.1.cmml" xref="S3.E2.m1.5.5.2.2.2.3.3.1"></eq><ci id="S3.E2.m1.5.5.2.2.2.3.3.2.cmml" xref="S3.E2.m1.5.5.2.2.2.3.3.2">ğ‘–</ci><cn type="integer" id="S3.E2.m1.5.5.2.2.2.3.3.3.cmml" xref="S3.E2.m1.5.5.2.2.2.3.3.3">1</cn></apply></apply><apply id="S3.E2.m1.5.5.2.2.2.2.cmml" xref="S3.E2.m1.5.5.2.2.2.2"><times id="S3.E2.m1.5.5.2.2.2.2.3.cmml" xref="S3.E2.m1.5.5.2.2.2.2.3"></times><apply id="S3.E2.m1.4.4.1.1.1.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1"><log id="S3.E2.m1.3.3.cmml" xref="S3.E2.m1.3.3"></log><apply id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1"><times id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.2"></times><ci id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.3a.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.3"><mtext id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.3">softmax</mtext></ci><apply id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1"><times id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.3"></times><ci id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.4.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.4">ğ‘“</ci><interval closure="open" id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.2"><apply id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2">ğ‘£</ci><ci id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2">ğ‘</ci><ci id="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2.2.2.3">ğ‘–</ci></apply></interval></apply></apply></apply><apply id="S3.E2.m1.5.5.2.2.2.2.2.2.cmml" xref="S3.E2.m1.5.5.2.2.2.2.2.1"><csymbol cd="latexml" id="S3.E2.m1.5.5.2.2.2.2.2.2.1.cmml" xref="S3.E2.m1.5.5.2.2.2.2.2.1.2">delimited-[]</csymbol><apply id="S3.E2.m1.5.5.2.2.2.2.2.1.1.cmml" xref="S3.E2.m1.5.5.2.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.5.5.2.2.2.2.2.1.1.1.cmml" xref="S3.E2.m1.5.5.2.2.2.2.2.1.1">subscript</csymbol><ci id="S3.E2.m1.5.5.2.2.2.2.2.1.1.2.cmml" xref="S3.E2.m1.5.5.2.2.2.2.2.1.1.2">ğ‘</ci><ci id="S3.E2.m1.5.5.2.2.2.2.2.1.1.3.cmml" xref="S3.E2.m1.5.5.2.2.2.2.2.1.1.3">ğ‘–</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.5c">\mathcal{L}(\theta;\mathcal{D})=-\frac{1}{n}\sum^{n}_{i=1}\log(\text{softmax}(f(v_{i},q_{i})))[a_{i}]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS0.SSS0.Px1.p1.2" class="ltx_p">VQA models are inclined to learn unimodal biases from the datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. This can be shown by evaluating models on datasets that have different distributions of answers for the test set, such as VQA-CP v2. In other words, they rely on statistical regularities from one modality to provide accurate predictions without having to consider the other modality. As an extreme example, strongly biased models towards the question modality always output <span id="S3.SS0.SSS0.Px1.p1.2.1" class="ltx_text ltx_font_italic">yellow</span> to the question <span id="S3.SS0.SSS0.Px1.p1.2.2" class="ltx_text ltx_font_italic">what color is the banana</span>. They do not learn to use the image information because there are too few examples in the dataset where the banana is not yellow. Once trained, their inability to use the two modalities adequately makes them inoperable on data coming from different distributions such as real-world data.
Our contribution consists in modifying this cost function to avoid the learning of these biases.</p>
</div>
</section>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>RUBi learning strategy</h3>

<figure id="S3.F2" class="ltx_figure"><img src="/html/1906.10169/assets/images/model.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="479" height="257" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.4.2.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S3.F2.2.1" class="ltx_text" style="font-size:90%;"> Visual comparison between the classical learning strategy of a VQA model and our RUBi learning strategy. The red highlighted modules are removed at the end of the training. The output <math id="S3.F2.2.1.m1.1" class="ltx_Math" alttext="\hat{a}_{i}" display="inline"><semantics id="S3.F2.2.1.m1.1b"><msub id="S3.F2.2.1.m1.1.1" xref="S3.F2.2.1.m1.1.1.cmml"><mover accent="true" id="S3.F2.2.1.m1.1.1.2" xref="S3.F2.2.1.m1.1.1.2.cmml"><mi id="S3.F2.2.1.m1.1.1.2.2" xref="S3.F2.2.1.m1.1.1.2.2.cmml">a</mi><mo id="S3.F2.2.1.m1.1.1.2.1" xref="S3.F2.2.1.m1.1.1.2.1.cmml">^</mo></mover><mi id="S3.F2.2.1.m1.1.1.3" xref="S3.F2.2.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F2.2.1.m1.1c"><apply id="S3.F2.2.1.m1.1.1.cmml" xref="S3.F2.2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.F2.2.1.m1.1.1.1.cmml" xref="S3.F2.2.1.m1.1.1">subscript</csymbol><apply id="S3.F2.2.1.m1.1.1.2.cmml" xref="S3.F2.2.1.m1.1.1.2"><ci id="S3.F2.2.1.m1.1.1.2.1.cmml" xref="S3.F2.2.1.m1.1.1.2.1">^</ci><ci id="S3.F2.2.1.m1.1.1.2.2.cmml" xref="S3.F2.2.1.m1.1.1.2.2">ğ‘</ci></apply><ci id="S3.F2.2.1.m1.1.1.3.cmml" xref="S3.F2.2.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.2.1.m1.1d">\hat{a}_{i}</annotation></semantics></math> is used as the final prediction.</span></figcaption>
</figure>
<section id="S3.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Capturing biases with a question-only branch</h4>

<div id="S3.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px1.p1.9" class="ltx_p">One way to measure the unimodal biases in VQA datasets is to train an unimodal model which takes only one of the two modalities as input.
The key idea of our approach, depicted in FigureÂ <a href="#S3.F2" title="Figure 2 â€£ 3.1 RUBi learning strategy â€£ 3 Reducing Unimodal Biases Approach â€£ RUBi: Reducing Unimodal Biases for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, is to adapt a question-only model as a branch of our VQA model, that will alter the main modelâ€™s predictions. By doing so, the question-only branch captures the question biases, allowing the VQA model to focus on the examples that cannot be answered correctly using the question modality only.
The question-only branch can be formalized as a function <math id="S3.SS1.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="f_{Q}:\mathcal{Q}\rightarrow\mathbb{R}^{|\mathcal{A}|}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.1.m1.1a"><mrow id="S3.SS1.SSS0.Px1.p1.1.m1.1.2" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.2.cmml"><msub id="S3.SS1.SSS0.Px1.p1.1.m1.1.2.2" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.2.2.cmml"><mi id="S3.SS1.SSS0.Px1.p1.1.m1.1.2.2.2" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.2.2.2.cmml">f</mi><mi id="S3.SS1.SSS0.Px1.p1.1.m1.1.2.2.3" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.2.2.3.cmml">Q</mi></msub><mo lspace="0.278em" rspace="0.278em" id="S3.SS1.SSS0.Px1.p1.1.m1.1.2.1" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.2.1.cmml">:</mo><mrow id="S3.SS1.SSS0.Px1.p1.1.m1.1.2.3" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS0.Px1.p1.1.m1.1.2.3.2" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.2.3.2.cmml">ğ’¬</mi><mo stretchy="false" id="S3.SS1.SSS0.Px1.p1.1.m1.1.2.3.1" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.2.3.1.cmml">â†’</mo><msup id="S3.SS1.SSS0.Px1.p1.1.m1.1.2.3.3" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.2.3.3.cmml"><mi id="S3.SS1.SSS0.Px1.p1.1.m1.1.2.3.3.2" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.2.3.3.2.cmml">â„</mi><mrow id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.1.3" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.1.3.1" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.1.2.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.1.1" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.cmml">ğ’œ</mi><mo stretchy="false" id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.1.3.2" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.1.2.1.cmml">|</mo></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.1.m1.1b"><apply id="S3.SS1.SSS0.Px1.p1.1.m1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.2"><ci id="S3.SS1.SSS0.Px1.p1.1.m1.1.2.1.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.2.1">:</ci><apply id="S3.SS1.SSS0.Px1.p1.1.m1.1.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.1.m1.1.2.2.1.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.2.2">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.1.m1.1.2.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.2.2.2">ğ‘“</ci><ci id="S3.SS1.SSS0.Px1.p1.1.m1.1.2.2.3.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.2.2.3">ğ‘„</ci></apply><apply id="S3.SS1.SSS0.Px1.p1.1.m1.1.2.3.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.2.3"><ci id="S3.SS1.SSS0.Px1.p1.1.m1.1.2.3.1.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.2.3.1">â†’</ci><ci id="S3.SS1.SSS0.Px1.p1.1.m1.1.2.3.2.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.2.3.2">ğ’¬</ci><apply id="S3.SS1.SSS0.Px1.p1.1.m1.1.2.3.3.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.2.3.3"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.1.m1.1.2.3.3.1.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.2.3.3">superscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.1.m1.1.2.3.3.2.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.2.3.3.2">â„</ci><apply id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.1.3"><abs id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.1.2.1.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.1.3.1"></abs><ci id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.1.1">ğ’œ</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.1.m1.1c">f_{Q}:\mathcal{Q}\rightarrow\mathbb{R}^{|\mathcal{A}|}</annotation></semantics></math> parameterized by <math id="S3.SS1.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="\theta_{Q}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.2.m2.1a"><msub id="S3.SS1.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.cmml">Î¸</mi><mi id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.cmml">Q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.2.m2.1b"><apply id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2">ğœƒ</ci><ci id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3">ğ‘„</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.2.m2.1c">\theta_{Q}</annotation></semantics></math>, and composed of a question encoder <math id="S3.SS1.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="e_{q}:\mathcal{Q}\rightarrow\mathbb{R}^{n_{q}\times d_{q}}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.3.m3.1a"><mrow id="S3.SS1.SSS0.Px1.p1.3.m3.1.1" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.cmml"><msub id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.cmml"><mi id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.2" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.2.cmml">e</mi><mi id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.3" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.3.cmml">q</mi></msub><mo lspace="0.278em" rspace="0.278em" id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.1" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.1.cmml">:</mo><mrow id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.2" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.2.cmml">ğ’¬</mi><mo stretchy="false" id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.1" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.1.cmml">â†’</mo><msup id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.cmml"><mi id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.2" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.2.cmml">â„</mi><mrow id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.cmml"><msub id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.2" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.2.cmml"><mi id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.2.2" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.2.2.cmml">n</mi><mi id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.2.3" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.2.3.cmml">q</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.1" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.1.cmml">Ã—</mo><msub id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.3" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.3.cmml"><mi id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.3.2" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.3.2.cmml">d</mi><mi id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.3.3" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.3.3.cmml">q</mi></msub></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.3.m3.1b"><apply id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1"><ci id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.1">:</ci><apply id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.1.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.2">ğ‘’</ci><ci id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.3.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.3">ğ‘</ci></apply><apply id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3"><ci id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.1.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.1">â†’</ci><ci id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.2.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.2">ğ’¬</ci><apply id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.1.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3">superscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.2.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.2">â„</ci><apply id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3"><times id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.1.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.1"></times><apply id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.2.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.2"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.2.1.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.2">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.2.2">ğ‘›</ci><ci id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.2.3.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.2.3">ğ‘</ci></apply><apply id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.3.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.3.1.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.3">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.3.2.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.3.2">ğ‘‘</ci><ci id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.3.3.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.3.3">ğ‘</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.3.m3.1c">e_{q}:\mathcal{Q}\rightarrow\mathbb{R}^{n_{q}\times d_{q}}</annotation></semantics></math> to output a set of <math id="S3.SS1.SSS0.Px1.p1.4.m4.1" class="ltx_Math" alttext="n_{q}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.4.m4.1a"><msub id="S3.SS1.SSS0.Px1.p1.4.m4.1.1" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.cmml">n</mi><mi id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.4.m4.1b"><apply id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2">ğ‘›</ci><ci id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.4.m4.1c">n_{q}</annotation></semantics></math> vectors of dimension <math id="S3.SS1.SSS0.Px1.p1.5.m5.1" class="ltx_Math" alttext="d_{q}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.5.m5.1a"><msub id="S3.SS1.SSS0.Px1.p1.5.m5.1.1" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.cmml">d</mi><mi id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.5.m5.1b"><apply id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2">ğ‘‘</ci><ci id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.5.m5.1c">d_{q}</annotation></semantics></math>, a neural network <math id="S3.SS1.SSS0.Px1.p1.6.m6.1" class="ltx_Math" alttext="\mathit{nn}_{q}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.6.m6.1a"><msub id="S3.SS1.SSS0.Px1.p1.6.m6.1.1" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.6.m6.1.1.2" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1.2.cmml">ğ‘›ğ‘›</mi><mi id="S3.SS1.SSS0.Px1.p1.6.m6.1.1.3" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.6.m6.1b"><apply id="S3.SS1.SSS0.Px1.p1.6.m6.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1.2">ğ‘›ğ‘›</ci><ci id="S3.SS1.SSS0.Px1.p1.6.m6.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.6.m6.1c">\mathit{nn}_{q}</annotation></semantics></math>: <math id="S3.SS1.SSS0.Px1.p1.7.m7.1" class="ltx_Math" alttext="\mathbb{R}^{n_{q}\times d_{q}}\rightarrow\mathbb{R}^{|\mathcal{A}|}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.7.m7.1a"><mrow id="S3.SS1.SSS0.Px1.p1.7.m7.1.2" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.cmml"><msup id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.cmml"><mi id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.2" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.2.cmml">â„</mi><mrow id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.cmml"><msub id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.2" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.2.cmml"><mi id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.2.2" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.2.2.cmml">n</mi><mi id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.2.3" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.2.3.cmml">q</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.1" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.1.cmml">Ã—</mo><msub id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.3" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.3.cmml"><mi id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.3.2" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.3.2.cmml">d</mi><mi id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.3.3" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.3.3.cmml">q</mi></msub></mrow></msup><mo stretchy="false" id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.1" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.1.cmml">â†’</mo><msup id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.3" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.3.cmml"><mi id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.3.2" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.3.2.cmml">â„</mi><mrow id="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.3" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.3.1" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.2.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.1" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.1.cmml">ğ’œ</mi><mo stretchy="false" id="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.3.2" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.2.1.cmml">|</mo></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.7.m7.1b"><apply id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2"><ci id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.1.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.1">â†’</ci><apply id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.1.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2">superscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.2">â„</ci><apply id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3"><times id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.1.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.1"></times><apply id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.2.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.2"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.2.1.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.2">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.2.2">ğ‘›</ci><ci id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.2.3.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.2.3">ğ‘</ci></apply><apply id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.3.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.3"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.3.1.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.3">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.3.2.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.3.2">ğ‘‘</ci><ci id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.3.3.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.2.3.3.3">ğ‘</ci></apply></apply></apply><apply id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.3.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.3"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.3.1.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.3">superscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.7.m7.1.2.3.2.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.2.3.2">â„</ci><apply id="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.3"><abs id="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.2.1.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.3.1"></abs><ci id="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.1">ğ’œ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.7.m7.1c">\mathbb{R}^{n_{q}\times d_{q}}\rightarrow\mathbb{R}^{|\mathcal{A}|}</annotation></semantics></math> and a classifier <math id="S3.SS1.SSS0.Px1.p1.8.m8.1" class="ltx_Math" alttext="c_{q}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.8.m8.1a"><msub id="S3.SS1.SSS0.Px1.p1.8.m8.1.1" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.2" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.2.cmml">c</mi><mi id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.3" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.8.m8.1b"><apply id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.2">ğ‘</ci><ci id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.8.m8.1c">c_{q}</annotation></semantics></math>: <math id="S3.SS1.SSS0.Px1.p1.9.m9.2" class="ltx_Math" alttext="\mathbb{R}^{|\mathcal{A}|}\rightarrow\mathbb{R}^{|\mathcal{A}|}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.9.m9.2a"><mrow id="S3.SS1.SSS0.Px1.p1.9.m9.2.3" xref="S3.SS1.SSS0.Px1.p1.9.m9.2.3.cmml"><msup id="S3.SS1.SSS0.Px1.p1.9.m9.2.3.2" xref="S3.SS1.SSS0.Px1.p1.9.m9.2.3.2.cmml"><mi id="S3.SS1.SSS0.Px1.p1.9.m9.2.3.2.2" xref="S3.SS1.SSS0.Px1.p1.9.m9.2.3.2.2.cmml">â„</mi><mrow id="S3.SS1.SSS0.Px1.p1.9.m9.1.1.1.3" xref="S3.SS1.SSS0.Px1.p1.9.m9.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS1.SSS0.Px1.p1.9.m9.1.1.1.3.1" xref="S3.SS1.SSS0.Px1.p1.9.m9.1.1.1.2.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS0.Px1.p1.9.m9.1.1.1.1" xref="S3.SS1.SSS0.Px1.p1.9.m9.1.1.1.1.cmml">ğ’œ</mi><mo stretchy="false" id="S3.SS1.SSS0.Px1.p1.9.m9.1.1.1.3.2" xref="S3.SS1.SSS0.Px1.p1.9.m9.1.1.1.2.1.cmml">|</mo></mrow></msup><mo stretchy="false" id="S3.SS1.SSS0.Px1.p1.9.m9.2.3.1" xref="S3.SS1.SSS0.Px1.p1.9.m9.2.3.1.cmml">â†’</mo><msup id="S3.SS1.SSS0.Px1.p1.9.m9.2.3.3" xref="S3.SS1.SSS0.Px1.p1.9.m9.2.3.3.cmml"><mi id="S3.SS1.SSS0.Px1.p1.9.m9.2.3.3.2" xref="S3.SS1.SSS0.Px1.p1.9.m9.2.3.3.2.cmml">â„</mi><mrow id="S3.SS1.SSS0.Px1.p1.9.m9.2.2.1.3" xref="S3.SS1.SSS0.Px1.p1.9.m9.2.2.1.2.cmml"><mo stretchy="false" id="S3.SS1.SSS0.Px1.p1.9.m9.2.2.1.3.1" xref="S3.SS1.SSS0.Px1.p1.9.m9.2.2.1.2.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS0.Px1.p1.9.m9.2.2.1.1" xref="S3.SS1.SSS0.Px1.p1.9.m9.2.2.1.1.cmml">ğ’œ</mi><mo stretchy="false" id="S3.SS1.SSS0.Px1.p1.9.m9.2.2.1.3.2" xref="S3.SS1.SSS0.Px1.p1.9.m9.2.2.1.2.1.cmml">|</mo></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.9.m9.2b"><apply id="S3.SS1.SSS0.Px1.p1.9.m9.2.3.cmml" xref="S3.SS1.SSS0.Px1.p1.9.m9.2.3"><ci id="S3.SS1.SSS0.Px1.p1.9.m9.2.3.1.cmml" xref="S3.SS1.SSS0.Px1.p1.9.m9.2.3.1">â†’</ci><apply id="S3.SS1.SSS0.Px1.p1.9.m9.2.3.2.cmml" xref="S3.SS1.SSS0.Px1.p1.9.m9.2.3.2"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.9.m9.2.3.2.1.cmml" xref="S3.SS1.SSS0.Px1.p1.9.m9.2.3.2">superscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.9.m9.2.3.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.9.m9.2.3.2.2">â„</ci><apply id="S3.SS1.SSS0.Px1.p1.9.m9.1.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.9.m9.1.1.1.3"><abs id="S3.SS1.SSS0.Px1.p1.9.m9.1.1.1.2.1.cmml" xref="S3.SS1.SSS0.Px1.p1.9.m9.1.1.1.3.1"></abs><ci id="S3.SS1.SSS0.Px1.p1.9.m9.1.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.9.m9.1.1.1.1">ğ’œ</ci></apply></apply><apply id="S3.SS1.SSS0.Px1.p1.9.m9.2.3.3.cmml" xref="S3.SS1.SSS0.Px1.p1.9.m9.2.3.3"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.9.m9.2.3.3.1.cmml" xref="S3.SS1.SSS0.Px1.p1.9.m9.2.3.3">superscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.9.m9.2.3.3.2.cmml" xref="S3.SS1.SSS0.Px1.p1.9.m9.2.3.3.2">â„</ci><apply id="S3.SS1.SSS0.Px1.p1.9.m9.2.2.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.9.m9.2.2.1.3"><abs id="S3.SS1.SSS0.Px1.p1.9.m9.2.2.1.2.1.cmml" xref="S3.SS1.SSS0.Px1.p1.9.m9.2.2.1.3.1"></abs><ci id="S3.SS1.SSS0.Px1.p1.9.m9.2.2.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.9.m9.2.2.1.1">ğ’œ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.9.m9.2c">\mathbb{R}^{|\mathcal{A}|}\rightarrow\mathbb{R}^{|\mathcal{A}|}</annotation></semantics></math>.
</p>
<table id="S6.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E3.m1.1" class="ltx_Math" alttext="\displaystyle f_{Q}(q_{i})" display="inline"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml"><msub id="S3.E3.m1.1.1.3" xref="S3.E3.m1.1.1.3.cmml"><mi id="S3.E3.m1.1.1.3.2" xref="S3.E3.m1.1.1.3.2.cmml">f</mi><mi id="S3.E3.m1.1.1.3.3" xref="S3.E3.m1.1.1.3.3.cmml">Q</mi></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.2" xref="S3.E3.m1.1.1.2.cmml">â€‹</mo><mrow id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.cmml">(</mo><msub id="S3.E3.m1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.2.cmml">q</mi><mi id="S3.E3.m1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E3.m1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1"><times id="S3.E3.m1.1.1.2.cmml" xref="S3.E3.m1.1.1.2"></times><apply id="S3.E3.m1.1.1.3.cmml" xref="S3.E3.m1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.3">subscript</csymbol><ci id="S3.E3.m1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.3.2">ğ‘“</ci><ci id="S3.E3.m1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.3.3">ğ‘„</ci></apply><apply id="S3.E3.m1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.2">ğ‘</ci><ci id="S3.E3.m1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">\displaystyle f_{Q}(q_{i})</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E3.m2.1" class="ltx_Math" alttext="\displaystyle=c_{q}(\mathit{nn}_{q}(e_{q}(q_{i})))" display="inline"><semantics id="S3.E3.m2.1a"><mrow id="S3.E3.m2.1.1" xref="S3.E3.m2.1.1.cmml"><mi id="S3.E3.m2.1.1.3" xref="S3.E3.m2.1.1.3.cmml"></mi><mo id="S3.E3.m2.1.1.2" xref="S3.E3.m2.1.1.2.cmml">=</mo><mrow id="S3.E3.m2.1.1.1" xref="S3.E3.m2.1.1.1.cmml"><msub id="S3.E3.m2.1.1.1.3" xref="S3.E3.m2.1.1.1.3.cmml"><mi id="S3.E3.m2.1.1.1.3.2" xref="S3.E3.m2.1.1.1.3.2.cmml">c</mi><mi id="S3.E3.m2.1.1.1.3.3" xref="S3.E3.m2.1.1.1.3.3.cmml">q</mi></msub><mo lspace="0em" rspace="0em" id="S3.E3.m2.1.1.1.2" xref="S3.E3.m2.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E3.m2.1.1.1.1.1" xref="S3.E3.m2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m2.1.1.1.1.1.2" xref="S3.E3.m2.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m2.1.1.1.1.1.1" xref="S3.E3.m2.1.1.1.1.1.1.cmml"><msub id="S3.E3.m2.1.1.1.1.1.1.3" xref="S3.E3.m2.1.1.1.1.1.1.3.cmml"><mi id="S3.E3.m2.1.1.1.1.1.1.3.2" xref="S3.E3.m2.1.1.1.1.1.1.3.2.cmml">ğ‘›ğ‘›</mi><mi id="S3.E3.m2.1.1.1.1.1.1.3.3" xref="S3.E3.m2.1.1.1.1.1.1.3.3.cmml">q</mi></msub><mo lspace="0em" rspace="0em" id="S3.E3.m2.1.1.1.1.1.1.2" xref="S3.E3.m2.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E3.m2.1.1.1.1.1.1.1.1" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m2.1.1.1.1.1.1.1.1.2" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m2.1.1.1.1.1.1.1.1.1" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E3.m2.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E3.m2.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.3.2.cmml">e</mi><mi id="S3.E3.m2.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.3.3.cmml">q</mi></msub><mo lspace="0em" rspace="0em" id="S3.E3.m2.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E3.m2.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m2.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E3.m2.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m2.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">q</mi><mi id="S3.E3.m2.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E3.m2.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E3.m2.1.1.1.1.1.1.1.1.3" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E3.m2.1.1.1.1.1.3" xref="S3.E3.m2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m2.1b"><apply id="S3.E3.m2.1.1.cmml" xref="S3.E3.m2.1.1"><eq id="S3.E3.m2.1.1.2.cmml" xref="S3.E3.m2.1.1.2"></eq><csymbol cd="latexml" id="S3.E3.m2.1.1.3.cmml" xref="S3.E3.m2.1.1.3">absent</csymbol><apply id="S3.E3.m2.1.1.1.cmml" xref="S3.E3.m2.1.1.1"><times id="S3.E3.m2.1.1.1.2.cmml" xref="S3.E3.m2.1.1.1.2"></times><apply id="S3.E3.m2.1.1.1.3.cmml" xref="S3.E3.m2.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m2.1.1.1.3.1.cmml" xref="S3.E3.m2.1.1.1.3">subscript</csymbol><ci id="S3.E3.m2.1.1.1.3.2.cmml" xref="S3.E3.m2.1.1.1.3.2">ğ‘</ci><ci id="S3.E3.m2.1.1.1.3.3.cmml" xref="S3.E3.m2.1.1.1.3.3">ğ‘</ci></apply><apply id="S3.E3.m2.1.1.1.1.1.1.cmml" xref="S3.E3.m2.1.1.1.1.1"><times id="S3.E3.m2.1.1.1.1.1.1.2.cmml" xref="S3.E3.m2.1.1.1.1.1.1.2"></times><apply id="S3.E3.m2.1.1.1.1.1.1.3.cmml" xref="S3.E3.m2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m2.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m2.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E3.m2.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m2.1.1.1.1.1.1.3.2">ğ‘›ğ‘›</ci><ci id="S3.E3.m2.1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m2.1.1.1.1.1.1.3.3">ğ‘</ci></apply><apply id="S3.E3.m2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m2.1.1.1.1.1.1.1.1"><times id="S3.E3.m2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.2"></times><apply id="S3.E3.m2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m2.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E3.m2.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.3.2">ğ‘’</ci><ci id="S3.E3.m2.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.3.3">ğ‘</ci></apply><apply id="S3.E3.m2.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.1.1.1.2">ğ‘</ci><ci id="S3.E3.m2.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m2.1c">\displaystyle=c_{q}(\mathit{nn}_{q}(e_{q}(q_{i})))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.SSS0.Px1.p1.10" class="ltx_p">During training, the branch acts as a proxy preventing any VQA model of the form presented in EquationÂ (<a href="#S3.E1" title="In 3 Reducing Unimodal Biases Approach â€£ RUBi: Reducing Unimodal Biases for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) from learning biases. At the end of the training, we simply remove the branch and use the predictions from the base VQA model.</p>
</div>
</section>
<section id="S3.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Preventing biases by masking predictions</h4>

<figure id="S3.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F3.1" class="ltx_figure ltx_figure_panel"><img src="/html/1906.10169/assets/images/model_loss_classic_low.png" id="S3.F3.1.g1" class="ltx_graphics ltx_img_square" width="592" height="557" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F3.2" class="ltx_figure ltx_figure_panel"><img src="/html/1906.10169/assets/images/model_loss_rubi_low.png" id="S3.F3.2.g1" class="ltx_graphics ltx_img_landscape" width="592" height="413" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F3.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/1906.10169/assets/images/model_loss_classic_high.png" id="S3.F3.sf1.g1" class="ltx_graphics ltx_img_square" width="592" height="559" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S3.F3.sf1.3.2" class="ltx_text" style="font-size:90%;">Classical learning strategy</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F3.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/1906.10169/assets/images/model_loss_rubi_high.png" id="S3.F3.sf2.g1" class="ltx_graphics ltx_img_landscape" width="592" height="407" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S3.F3.sf2.3.2" class="ltx_text" style="font-size:90%;">RUBi learning strategy</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.4.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.5.2" class="ltx_text" style="font-size:90%;">Detailed illustration of the RUBi impact on the learning. In the first row, we illustrate how RUBi reduces the loss for examples that can be correctly answered without looking at the image. In the second row, we illustrate how RUBi increases the loss for examples that cannot be answered without using both modalities.</span></figcaption>
</figure>
<div id="S3.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px2.p1.4" class="ltx_p">Before passing the predictions of our base VQA model to the loss function defined in EquationÂ (<a href="#S3.E2" title="In Classical learning strategy and pitfall â€£ 3 Reducing Unimodal Biases Approach â€£ RUBi: Reducing Unimodal Biases for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>), we merge them with a mask of length <math id="S3.SS1.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="|\mathcal{A}|" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.1.m1.1a"><mrow id="S3.SS1.SSS0.Px2.p1.1.m1.1.2.2" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.2.1.cmml"><mo stretchy="false" id="S3.SS1.SSS0.Px2.p1.1.m1.1.2.2.1" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.2.1.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.cmml">ğ’œ</mi><mo stretchy="false" id="S3.SS1.SSS0.Px2.p1.1.m1.1.2.2.2" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.2.1.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.1.m1.1b"><apply id="S3.SS1.SSS0.Px2.p1.1.m1.1.2.1.cmml" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.2.2"><abs id="S3.SS1.SSS0.Px2.p1.1.m1.1.2.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.2.2.1"></abs><ci id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1">ğ’œ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.1.m1.1c">|\mathcal{A}|</annotation></semantics></math> containing a scalar value between 0 and 1 for each answer.
This mask is obtained by passing the output of the neural network <math id="S3.SS1.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="\mathit{nn}_{q}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.2.m2.1a"><msub id="S3.SS1.SSS0.Px2.p1.2.m2.1.1" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.cmml"><mi id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2.cmml">ğ‘›ğ‘›</mi><mi id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.3" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.2.m2.1b"><apply id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2">ğ‘›ğ‘›</ci><ci id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.2.m2.1c">\mathit{nn}_{q}</annotation></semantics></math> through a sigmoid function <math id="S3.SS1.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.3.m3.1a"><mi id="S3.SS1.SSS0.Px2.p1.3.m3.1.1" xref="S3.SS1.SSS0.Px2.p1.3.m3.1.1.cmml">Ïƒ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.3.m3.1b"><ci id="S3.SS1.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.3.m3.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.3.m3.1c">\sigma</annotation></semantics></math>.
The goal of this mask is to dynamically alter the loss by modifying the predictions of the VQA model. To obtain the new predictions, we simply compute an element-wise product <math id="S3.SS1.SSS0.Px2.p1.4.m4.1" class="ltx_Math" alttext="\odot" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.4.m4.1a"><mo id="S3.SS1.SSS0.Px2.p1.4.m4.1.1" xref="S3.SS1.SSS0.Px2.p1.4.m4.1.1.cmml">âŠ™</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.4.m4.1b"><csymbol cd="latexml" id="S3.SS1.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.4.m4.1.1">direct-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.4.m4.1c">\odot</annotation></semantics></math> between the mask and the original predictions as defined in the following equation.</p>
<table id="S6.EGx2" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E4.m1.2" class="ltx_Math" alttext="\displaystyle f_{QM}(v_{i},q_{i})" display="inline"><semantics id="S3.E4.m1.2a"><mrow id="S3.E4.m1.2.2" xref="S3.E4.m1.2.2.cmml"><msub id="S3.E4.m1.2.2.4" xref="S3.E4.m1.2.2.4.cmml"><mi id="S3.E4.m1.2.2.4.2" xref="S3.E4.m1.2.2.4.2.cmml">f</mi><mrow id="S3.E4.m1.2.2.4.3" xref="S3.E4.m1.2.2.4.3.cmml"><mi id="S3.E4.m1.2.2.4.3.2" xref="S3.E4.m1.2.2.4.3.2.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.4.3.1" xref="S3.E4.m1.2.2.4.3.1.cmml">â€‹</mo><mi id="S3.E4.m1.2.2.4.3.3" xref="S3.E4.m1.2.2.4.3.3.cmml">M</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.3" xref="S3.E4.m1.2.2.3.cmml">â€‹</mo><mrow id="S3.E4.m1.2.2.2.2" xref="S3.E4.m1.2.2.2.3.cmml"><mo stretchy="false" id="S3.E4.m1.2.2.2.2.3" xref="S3.E4.m1.2.2.2.3.cmml">(</mo><msub id="S3.E4.m1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.2.cmml">v</mi><mi id="S3.E4.m1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E4.m1.2.2.2.2.4" xref="S3.E4.m1.2.2.2.3.cmml">,</mo><msub id="S3.E4.m1.2.2.2.2.2" xref="S3.E4.m1.2.2.2.2.2.cmml"><mi id="S3.E4.m1.2.2.2.2.2.2" xref="S3.E4.m1.2.2.2.2.2.2.cmml">q</mi><mi id="S3.E4.m1.2.2.2.2.2.3" xref="S3.E4.m1.2.2.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E4.m1.2.2.2.2.5" xref="S3.E4.m1.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.2b"><apply id="S3.E4.m1.2.2.cmml" xref="S3.E4.m1.2.2"><times id="S3.E4.m1.2.2.3.cmml" xref="S3.E4.m1.2.2.3"></times><apply id="S3.E4.m1.2.2.4.cmml" xref="S3.E4.m1.2.2.4"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.4.1.cmml" xref="S3.E4.m1.2.2.4">subscript</csymbol><ci id="S3.E4.m1.2.2.4.2.cmml" xref="S3.E4.m1.2.2.4.2">ğ‘“</ci><apply id="S3.E4.m1.2.2.4.3.cmml" xref="S3.E4.m1.2.2.4.3"><times id="S3.E4.m1.2.2.4.3.1.cmml" xref="S3.E4.m1.2.2.4.3.1"></times><ci id="S3.E4.m1.2.2.4.3.2.cmml" xref="S3.E4.m1.2.2.4.3.2">ğ‘„</ci><ci id="S3.E4.m1.2.2.4.3.3.cmml" xref="S3.E4.m1.2.2.4.3.3">ğ‘€</ci></apply></apply><interval closure="open" id="S3.E4.m1.2.2.2.3.cmml" xref="S3.E4.m1.2.2.2.2"><apply id="S3.E4.m1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.2">ğ‘£</ci><ci id="S3.E4.m1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.E4.m1.2.2.2.2.2.cmml" xref="S3.E4.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.2.2.1.cmml" xref="S3.E4.m1.2.2.2.2.2">subscript</csymbol><ci id="S3.E4.m1.2.2.2.2.2.2.cmml" xref="S3.E4.m1.2.2.2.2.2.2">ğ‘</ci><ci id="S3.E4.m1.2.2.2.2.2.3.cmml" xref="S3.E4.m1.2.2.2.2.2.3">ğ‘–</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.2c">\displaystyle f_{QM}(v_{i},q_{i})</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E4.m2.1" class="ltx_math_unparsed" alttext="\displaystyle=f(v_{i},q_{i})\odot\sigma(\mathit{nn}_{q}(e_{q}(q_{i})))))" display="inline"><semantics id="S3.E4.m2.1a"><mrow id="S3.E4.m2.1b"><mrow id="S3.E4.m2.1.1"><mo id="S3.E4.m2.1.1.1">=</mo><mi id="S3.E4.m2.1.1.2">f</mi><mrow id="S3.E4.m2.1.1.3"><mo stretchy="false" id="S3.E4.m2.1.1.3.1">(</mo><msub id="S3.E4.m2.1.1.3.2"><mi id="S3.E4.m2.1.1.3.2.2">v</mi><mi id="S3.E4.m2.1.1.3.2.3">i</mi></msub><mo id="S3.E4.m2.1.1.3.3">,</mo><msub id="S3.E4.m2.1.1.3.4"><mi id="S3.E4.m2.1.1.3.4.2">q</mi><mi id="S3.E4.m2.1.1.3.4.3">i</mi></msub><mo rspace="0.055em" stretchy="false" id="S3.E4.m2.1.1.3.5">)</mo></mrow><mo rspace="0.222em" id="S3.E4.m2.1.1.4">âŠ™</mo><mi id="S3.E4.m2.1.1.5">Ïƒ</mi><mrow id="S3.E4.m2.1.1.6"><mo stretchy="false" id="S3.E4.m2.1.1.6.1">(</mo><msub id="S3.E4.m2.1.1.6.2"><mi id="S3.E4.m2.1.1.6.2.2">ğ‘›ğ‘›</mi><mi id="S3.E4.m2.1.1.6.2.3">q</mi></msub><mrow id="S3.E4.m2.1.1.6.3"><mo stretchy="false" id="S3.E4.m2.1.1.6.3.1">(</mo><msub id="S3.E4.m2.1.1.6.3.2"><mi id="S3.E4.m2.1.1.6.3.2.2">e</mi><mi id="S3.E4.m2.1.1.6.3.2.3">q</mi></msub><mrow id="S3.E4.m2.1.1.6.3.3"><mo stretchy="false" id="S3.E4.m2.1.1.6.3.3.1">(</mo><msub id="S3.E4.m2.1.1.6.3.3.2"><mi id="S3.E4.m2.1.1.6.3.3.2.2">q</mi><mi id="S3.E4.m2.1.1.6.3.3.2.3">i</mi></msub><mo stretchy="false" id="S3.E4.m2.1.1.6.3.3.3">)</mo></mrow><mo stretchy="false" id="S3.E4.m2.1.1.6.3.4">)</mo></mrow><mo stretchy="false" id="S3.E4.m2.1.1.6.4">)</mo></mrow><mo stretchy="false" id="S3.E4.m2.1.1.7">)</mo></mrow><mo stretchy="false" id="S3.E4.m2.1.2">)</mo></mrow><annotation encoding="application/x-tex" id="S3.E4.m2.1c">\displaystyle=f(v_{i},q_{i})\odot\sigma(\mathit{nn}_{q}(e_{q}(q_{i})))))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.SSS0.Px2.p1.5" class="ltx_p">Our method modifies the predictions in this specific way to prevent the VQA model to learn biases from the question. To better understand the impact of our approach on the learning, we examine two scenarios.
First, we reduce the importance of the most biased examples, i.e. examples that can be correctly classified without using the image modality. To do so, the question-only branch outputs a mask to increase the score of the correct answer while decreasing the scores of the others. As a result, the loss is much lower for these biased examples. In other words, the gradients backpropagated through the VQA model are smaller, thereby reducing the importance of these examples in the learning.
As illustrated in the first row of FigureÂ <a href="#S3.F3" title="Figure 3 â€£ Preventing biases by masking predictions â€£ 3.1 RUBi learning strategy â€£ 3 Reducing Unimodal Biases Approach â€£ RUBi: Reducing Unimodal Biases for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, given the question <span id="S3.SS1.SSS0.Px2.p1.5.1" class="ltx_text ltx_font_italic">what color is the banana</span>, the mask takes a high value of 0.8 for the answer <span id="S3.SS1.SSS0.Px2.p1.5.2" class="ltx_text ltx_font_italic">yellow</span> which is the most likely answer for this question in the training set. On the other hand, the value for the other answers <span id="S3.SS1.SSS0.Px2.p1.5.3" class="ltx_text ltx_font_italic">green</span> and <span id="S3.SS1.SSS0.Px2.p1.5.4" class="ltx_text ltx_font_italic">white</span> are smaller. We see that the mask influences the VQA model to produce new predictions where the score associated with the answer <span id="S3.SS1.SSS0.Px2.p1.5.5" class="ltx_text ltx_font_italic">yellow</span> increases from 0.8 to 0.94. Compared to the classical learning approach, the loss is smaller with RUBi and decreases from 0.22 to 0.06.
Secondly, we increase the importance of examples that cannot be answered without using both modalities. For these examples, the question-only branch outputs a mask that increases the score of the wrong answer. As a result, the loss is much higher and the VQA model is encouraged to learn from these examples. We illustrate this behavior in the second row of FigureÂ <a href="#S3.F3" title="Figure 3 â€£ Preventing biases by masking predictions â€£ 3.1 RUBi learning strategy â€£ 3 Reducing Unimodal Biases Approach â€£ RUBi: Reducing Unimodal Biases for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> for the same question about the color of the banana. When the image contains a green banana, RUBi increases the loss from 0.69 to 1.20.</p>
</div>
</section>
<section id="S3.SS1.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Joint learning procedure</h4>

<div id="S3.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px3.p1.13" class="ltx_p">We jointly optimize the parameters of the base VQA model and its question-only branch using the gradients computed from two losses.
The main loss <math id="S3.SS1.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{QM}" display="inline"><semantics id="S3.SS1.SSS0.Px3.p1.1.m1.1a"><msub id="S3.SS1.SSS0.Px3.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.2" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1.2.cmml">â„’</mi><mrow id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.3" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1.3.cmml"><mi id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.3.2" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1.3.2.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.3.1" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.3.3" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1.3.3.cmml">M</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px3.p1.1.m1.1b"><apply id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1.2">â„’</ci><apply id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.3.cmml" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1.3"><times id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.3.1.cmml" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1.3.1"></times><ci id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.3.2.cmml" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1.3.2">ğ‘„</ci><ci id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.3.3.cmml" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1.3.3">ğ‘€</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px3.p1.1.m1.1c">\mathcal{L}_{QM}</annotation></semantics></math> refers to the cross-entropy loss associated with the predictions of <math id="S3.SS1.SSS0.Px3.p1.2.m2.2" class="ltx_Math" alttext="f_{QM}(v_{i},q_{i})" display="inline"><semantics id="S3.SS1.SSS0.Px3.p1.2.m2.2a"><mrow id="S3.SS1.SSS0.Px3.p1.2.m2.2.2" xref="S3.SS1.SSS0.Px3.p1.2.m2.2.2.cmml"><msub id="S3.SS1.SSS0.Px3.p1.2.m2.2.2.4" xref="S3.SS1.SSS0.Px3.p1.2.m2.2.2.4.cmml"><mi id="S3.SS1.SSS0.Px3.p1.2.m2.2.2.4.2" xref="S3.SS1.SSS0.Px3.p1.2.m2.2.2.4.2.cmml">f</mi><mrow id="S3.SS1.SSS0.Px3.p1.2.m2.2.2.4.3" xref="S3.SS1.SSS0.Px3.p1.2.m2.2.2.4.3.cmml"><mi id="S3.SS1.SSS0.Px3.p1.2.m2.2.2.4.3.2" xref="S3.SS1.SSS0.Px3.p1.2.m2.2.2.4.3.2.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px3.p1.2.m2.2.2.4.3.1" xref="S3.SS1.SSS0.Px3.p1.2.m2.2.2.4.3.1.cmml">â€‹</mo><mi id="S3.SS1.SSS0.Px3.p1.2.m2.2.2.4.3.3" xref="S3.SS1.SSS0.Px3.p1.2.m2.2.2.4.3.3.cmml">M</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px3.p1.2.m2.2.2.3" xref="S3.SS1.SSS0.Px3.p1.2.m2.2.2.3.cmml">â€‹</mo><mrow id="S3.SS1.SSS0.Px3.p1.2.m2.2.2.2.2" xref="S3.SS1.SSS0.Px3.p1.2.m2.2.2.2.3.cmml"><mo stretchy="false" id="S3.SS1.SSS0.Px3.p1.2.m2.2.2.2.2.3" xref="S3.SS1.SSS0.Px3.p1.2.m2.2.2.2.3.cmml">(</mo><msub id="S3.SS1.SSS0.Px3.p1.2.m2.1.1.1.1.1" xref="S3.SS1.SSS0.Px3.p1.2.m2.1.1.1.1.1.cmml"><mi id="S3.SS1.SSS0.Px3.p1.2.m2.1.1.1.1.1.2" xref="S3.SS1.SSS0.Px3.p1.2.m2.1.1.1.1.1.2.cmml">v</mi><mi id="S3.SS1.SSS0.Px3.p1.2.m2.1.1.1.1.1.3" xref="S3.SS1.SSS0.Px3.p1.2.m2.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS1.SSS0.Px3.p1.2.m2.2.2.2.2.4" xref="S3.SS1.SSS0.Px3.p1.2.m2.2.2.2.3.cmml">,</mo><msub id="S3.SS1.SSS0.Px3.p1.2.m2.2.2.2.2.2" xref="S3.SS1.SSS0.Px3.p1.2.m2.2.2.2.2.2.cmml"><mi id="S3.SS1.SSS0.Px3.p1.2.m2.2.2.2.2.2.2" xref="S3.SS1.SSS0.Px3.p1.2.m2.2.2.2.2.2.2.cmml">q</mi><mi id="S3.SS1.SSS0.Px3.p1.2.m2.2.2.2.2.2.3" xref="S3.SS1.SSS0.Px3.p1.2.m2.2.2.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS1.SSS0.Px3.p1.2.m2.2.2.2.2.5" xref="S3.SS1.SSS0.Px3.p1.2.m2.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px3.p1.2.m2.2b"><apply id="S3.SS1.SSS0.Px3.p1.2.m2.2.2.cmml" xref="S3.SS1.SSS0.Px3.p1.2.m2.2.2"><times id="S3.SS1.SSS0.Px3.p1.2.m2.2.2.3.cmml" xref="S3.SS1.SSS0.Px3.p1.2.m2.2.2.3"></times><apply id="S3.SS1.SSS0.Px3.p1.2.m2.2.2.4.cmml" xref="S3.SS1.SSS0.Px3.p1.2.m2.2.2.4"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px3.p1.2.m2.2.2.4.1.cmml" xref="S3.SS1.SSS0.Px3.p1.2.m2.2.2.4">subscript</csymbol><ci id="S3.SS1.SSS0.Px3.p1.2.m2.2.2.4.2.cmml" xref="S3.SS1.SSS0.Px3.p1.2.m2.2.2.4.2">ğ‘“</ci><apply id="S3.SS1.SSS0.Px3.p1.2.m2.2.2.4.3.cmml" xref="S3.SS1.SSS0.Px3.p1.2.m2.2.2.4.3"><times id="S3.SS1.SSS0.Px3.p1.2.m2.2.2.4.3.1.cmml" xref="S3.SS1.SSS0.Px3.p1.2.m2.2.2.4.3.1"></times><ci id="S3.SS1.SSS0.Px3.p1.2.m2.2.2.4.3.2.cmml" xref="S3.SS1.SSS0.Px3.p1.2.m2.2.2.4.3.2">ğ‘„</ci><ci id="S3.SS1.SSS0.Px3.p1.2.m2.2.2.4.3.3.cmml" xref="S3.SS1.SSS0.Px3.p1.2.m2.2.2.4.3.3">ğ‘€</ci></apply></apply><interval closure="open" id="S3.SS1.SSS0.Px3.p1.2.m2.2.2.2.3.cmml" xref="S3.SS1.SSS0.Px3.p1.2.m2.2.2.2.2"><apply id="S3.SS1.SSS0.Px3.p1.2.m2.1.1.1.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px3.p1.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.2.m2.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px3.p1.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS1.SSS0.Px3.p1.2.m2.1.1.1.1.1.2">ğ‘£</ci><ci id="S3.SS1.SSS0.Px3.p1.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS1.SSS0.Px3.p1.2.m2.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.SS1.SSS0.Px3.p1.2.m2.2.2.2.2.2.cmml" xref="S3.SS1.SSS0.Px3.p1.2.m2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px3.p1.2.m2.2.2.2.2.2.1.cmml" xref="S3.SS1.SSS0.Px3.p1.2.m2.2.2.2.2.2">subscript</csymbol><ci id="S3.SS1.SSS0.Px3.p1.2.m2.2.2.2.2.2.2.cmml" xref="S3.SS1.SSS0.Px3.p1.2.m2.2.2.2.2.2.2">ğ‘</ci><ci id="S3.SS1.SSS0.Px3.p1.2.m2.2.2.2.2.2.3.cmml" xref="S3.SS1.SSS0.Px3.p1.2.m2.2.2.2.2.2.3">ğ‘–</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px3.p1.2.m2.2c">f_{QM}(v_{i},q_{i})</annotation></semantics></math> from EquationÂ <a href="#S3.E4" title="In Preventing biases by masking predictions â€£ 3.1 RUBi learning strategy â€£ 3 Reducing Unimodal Biases Approach â€£ RUBi: Reducing Unimodal Biases for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. We backpropagate this loss to optimize all the parameters <math id="S3.SS1.SSS0.Px3.p1.3.m3.1" class="ltx_Math" alttext="\theta_{QM}" display="inline"><semantics id="S3.SS1.SSS0.Px3.p1.3.m3.1a"><msub id="S3.SS1.SSS0.Px3.p1.3.m3.1.1" xref="S3.SS1.SSS0.Px3.p1.3.m3.1.1.cmml"><mi id="S3.SS1.SSS0.Px3.p1.3.m3.1.1.2" xref="S3.SS1.SSS0.Px3.p1.3.m3.1.1.2.cmml">Î¸</mi><mrow id="S3.SS1.SSS0.Px3.p1.3.m3.1.1.3" xref="S3.SS1.SSS0.Px3.p1.3.m3.1.1.3.cmml"><mi id="S3.SS1.SSS0.Px3.p1.3.m3.1.1.3.2" xref="S3.SS1.SSS0.Px3.p1.3.m3.1.1.3.2.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px3.p1.3.m3.1.1.3.1" xref="S3.SS1.SSS0.Px3.p1.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.SSS0.Px3.p1.3.m3.1.1.3.3" xref="S3.SS1.SSS0.Px3.p1.3.m3.1.1.3.3.cmml">M</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px3.p1.3.m3.1b"><apply id="S3.SS1.SSS0.Px3.p1.3.m3.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px3.p1.3.m3.1.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px3.p1.3.m3.1.1.2.cmml" xref="S3.SS1.SSS0.Px3.p1.3.m3.1.1.2">ğœƒ</ci><apply id="S3.SS1.SSS0.Px3.p1.3.m3.1.1.3.cmml" xref="S3.SS1.SSS0.Px3.p1.3.m3.1.1.3"><times id="S3.SS1.SSS0.Px3.p1.3.m3.1.1.3.1.cmml" xref="S3.SS1.SSS0.Px3.p1.3.m3.1.1.3.1"></times><ci id="S3.SS1.SSS0.Px3.p1.3.m3.1.1.3.2.cmml" xref="S3.SS1.SSS0.Px3.p1.3.m3.1.1.3.2">ğ‘„</ci><ci id="S3.SS1.SSS0.Px3.p1.3.m3.1.1.3.3.cmml" xref="S3.SS1.SSS0.Px3.p1.3.m3.1.1.3.3">ğ‘€</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px3.p1.3.m3.1c">\theta_{QM}</annotation></semantics></math> which contributed to this loss.
<math id="S3.SS1.SSS0.Px3.p1.4.m4.1" class="ltx_Math" alttext="\theta_{QM}" display="inline"><semantics id="S3.SS1.SSS0.Px3.p1.4.m4.1a"><msub id="S3.SS1.SSS0.Px3.p1.4.m4.1.1" xref="S3.SS1.SSS0.Px3.p1.4.m4.1.1.cmml"><mi id="S3.SS1.SSS0.Px3.p1.4.m4.1.1.2" xref="S3.SS1.SSS0.Px3.p1.4.m4.1.1.2.cmml">Î¸</mi><mrow id="S3.SS1.SSS0.Px3.p1.4.m4.1.1.3" xref="S3.SS1.SSS0.Px3.p1.4.m4.1.1.3.cmml"><mi id="S3.SS1.SSS0.Px3.p1.4.m4.1.1.3.2" xref="S3.SS1.SSS0.Px3.p1.4.m4.1.1.3.2.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px3.p1.4.m4.1.1.3.1" xref="S3.SS1.SSS0.Px3.p1.4.m4.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.SSS0.Px3.p1.4.m4.1.1.3.3" xref="S3.SS1.SSS0.Px3.p1.4.m4.1.1.3.3.cmml">M</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px3.p1.4.m4.1b"><apply id="S3.SS1.SSS0.Px3.p1.4.m4.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px3.p1.4.m4.1.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px3.p1.4.m4.1.1.2.cmml" xref="S3.SS1.SSS0.Px3.p1.4.m4.1.1.2">ğœƒ</ci><apply id="S3.SS1.SSS0.Px3.p1.4.m4.1.1.3.cmml" xref="S3.SS1.SSS0.Px3.p1.4.m4.1.1.3"><times id="S3.SS1.SSS0.Px3.p1.4.m4.1.1.3.1.cmml" xref="S3.SS1.SSS0.Px3.p1.4.m4.1.1.3.1"></times><ci id="S3.SS1.SSS0.Px3.p1.4.m4.1.1.3.2.cmml" xref="S3.SS1.SSS0.Px3.p1.4.m4.1.1.3.2">ğ‘„</ci><ci id="S3.SS1.SSS0.Px3.p1.4.m4.1.1.3.3.cmml" xref="S3.SS1.SSS0.Px3.p1.4.m4.1.1.3.3">ğ‘€</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px3.p1.4.m4.1c">\theta_{QM}</annotation></semantics></math> is the union of the parameters of the base VQA model, the encoders, and the neural network <math id="S3.SS1.SSS0.Px3.p1.5.m5.1" class="ltx_Math" alttext="\mathit{nn}_{q}" display="inline"><semantics id="S3.SS1.SSS0.Px3.p1.5.m5.1a"><msub id="S3.SS1.SSS0.Px3.p1.5.m5.1.1" xref="S3.SS1.SSS0.Px3.p1.5.m5.1.1.cmml"><mi id="S3.SS1.SSS0.Px3.p1.5.m5.1.1.2" xref="S3.SS1.SSS0.Px3.p1.5.m5.1.1.2.cmml">ğ‘›ğ‘›</mi><mi id="S3.SS1.SSS0.Px3.p1.5.m5.1.1.3" xref="S3.SS1.SSS0.Px3.p1.5.m5.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px3.p1.5.m5.1b"><apply id="S3.SS1.SSS0.Px3.p1.5.m5.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px3.p1.5.m5.1.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px3.p1.5.m5.1.1.2.cmml" xref="S3.SS1.SSS0.Px3.p1.5.m5.1.1.2">ğ‘›ğ‘›</ci><ci id="S3.SS1.SSS0.Px3.p1.5.m5.1.1.3.cmml" xref="S3.SS1.SSS0.Px3.p1.5.m5.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px3.p1.5.m5.1c">\mathit{nn}_{q}</annotation></semantics></math> of the question-only branch.
In our setup, we share the parameters of the question encoder <math id="S3.SS1.SSS0.Px3.p1.6.m6.1" class="ltx_Math" alttext="e_{q}" display="inline"><semantics id="S3.SS1.SSS0.Px3.p1.6.m6.1a"><msub id="S3.SS1.SSS0.Px3.p1.6.m6.1.1" xref="S3.SS1.SSS0.Px3.p1.6.m6.1.1.cmml"><mi id="S3.SS1.SSS0.Px3.p1.6.m6.1.1.2" xref="S3.SS1.SSS0.Px3.p1.6.m6.1.1.2.cmml">e</mi><mi id="S3.SS1.SSS0.Px3.p1.6.m6.1.1.3" xref="S3.SS1.SSS0.Px3.p1.6.m6.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px3.p1.6.m6.1b"><apply id="S3.SS1.SSS0.Px3.p1.6.m6.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px3.p1.6.m6.1.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px3.p1.6.m6.1.1.2.cmml" xref="S3.SS1.SSS0.Px3.p1.6.m6.1.1.2">ğ‘’</ci><ci id="S3.SS1.SSS0.Px3.p1.6.m6.1.1.3.cmml" xref="S3.SS1.SSS0.Px3.p1.6.m6.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px3.p1.6.m6.1c">e_{q}</annotation></semantics></math> between the VQA model and the question-only branch.
The question-only loss <math id="S3.SS1.SSS0.Px3.p1.7.m7.1" class="ltx_Math" alttext="\mathcal{L}_{QO}" display="inline"><semantics id="S3.SS1.SSS0.Px3.p1.7.m7.1a"><msub id="S3.SS1.SSS0.Px3.p1.7.m7.1.1" xref="S3.SS1.SSS0.Px3.p1.7.m7.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS0.Px3.p1.7.m7.1.1.2" xref="S3.SS1.SSS0.Px3.p1.7.m7.1.1.2.cmml">â„’</mi><mrow id="S3.SS1.SSS0.Px3.p1.7.m7.1.1.3" xref="S3.SS1.SSS0.Px3.p1.7.m7.1.1.3.cmml"><mi id="S3.SS1.SSS0.Px3.p1.7.m7.1.1.3.2" xref="S3.SS1.SSS0.Px3.p1.7.m7.1.1.3.2.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px3.p1.7.m7.1.1.3.1" xref="S3.SS1.SSS0.Px3.p1.7.m7.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.SSS0.Px3.p1.7.m7.1.1.3.3" xref="S3.SS1.SSS0.Px3.p1.7.m7.1.1.3.3.cmml">O</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px3.p1.7.m7.1b"><apply id="S3.SS1.SSS0.Px3.p1.7.m7.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px3.p1.7.m7.1.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.7.m7.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px3.p1.7.m7.1.1.2.cmml" xref="S3.SS1.SSS0.Px3.p1.7.m7.1.1.2">â„’</ci><apply id="S3.SS1.SSS0.Px3.p1.7.m7.1.1.3.cmml" xref="S3.SS1.SSS0.Px3.p1.7.m7.1.1.3"><times id="S3.SS1.SSS0.Px3.p1.7.m7.1.1.3.1.cmml" xref="S3.SS1.SSS0.Px3.p1.7.m7.1.1.3.1"></times><ci id="S3.SS1.SSS0.Px3.p1.7.m7.1.1.3.2.cmml" xref="S3.SS1.SSS0.Px3.p1.7.m7.1.1.3.2">ğ‘„</ci><ci id="S3.SS1.SSS0.Px3.p1.7.m7.1.1.3.3.cmml" xref="S3.SS1.SSS0.Px3.p1.7.m7.1.1.3.3">ğ‘‚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px3.p1.7.m7.1c">\mathcal{L}_{QO}</annotation></semantics></math> is a cross-entropy loss associated with the predictions of <math id="S3.SS1.SSS0.Px3.p1.8.m8.1" class="ltx_Math" alttext="f_{Q}(q_{i})" display="inline"><semantics id="S3.SS1.SSS0.Px3.p1.8.m8.1a"><mrow id="S3.SS1.SSS0.Px3.p1.8.m8.1.1" xref="S3.SS1.SSS0.Px3.p1.8.m8.1.1.cmml"><msub id="S3.SS1.SSS0.Px3.p1.8.m8.1.1.3" xref="S3.SS1.SSS0.Px3.p1.8.m8.1.1.3.cmml"><mi id="S3.SS1.SSS0.Px3.p1.8.m8.1.1.3.2" xref="S3.SS1.SSS0.Px3.p1.8.m8.1.1.3.2.cmml">f</mi><mi id="S3.SS1.SSS0.Px3.p1.8.m8.1.1.3.3" xref="S3.SS1.SSS0.Px3.p1.8.m8.1.1.3.3.cmml">Q</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px3.p1.8.m8.1.1.2" xref="S3.SS1.SSS0.Px3.p1.8.m8.1.1.2.cmml">â€‹</mo><mrow id="S3.SS1.SSS0.Px3.p1.8.m8.1.1.1.1" xref="S3.SS1.SSS0.Px3.p1.8.m8.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.SSS0.Px3.p1.8.m8.1.1.1.1.2" xref="S3.SS1.SSS0.Px3.p1.8.m8.1.1.1.1.1.cmml">(</mo><msub id="S3.SS1.SSS0.Px3.p1.8.m8.1.1.1.1.1" xref="S3.SS1.SSS0.Px3.p1.8.m8.1.1.1.1.1.cmml"><mi id="S3.SS1.SSS0.Px3.p1.8.m8.1.1.1.1.1.2" xref="S3.SS1.SSS0.Px3.p1.8.m8.1.1.1.1.1.2.cmml">q</mi><mi id="S3.SS1.SSS0.Px3.p1.8.m8.1.1.1.1.1.3" xref="S3.SS1.SSS0.Px3.p1.8.m8.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS1.SSS0.Px3.p1.8.m8.1.1.1.1.3" xref="S3.SS1.SSS0.Px3.p1.8.m8.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px3.p1.8.m8.1b"><apply id="S3.SS1.SSS0.Px3.p1.8.m8.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.8.m8.1.1"><times id="S3.SS1.SSS0.Px3.p1.8.m8.1.1.2.cmml" xref="S3.SS1.SSS0.Px3.p1.8.m8.1.1.2"></times><apply id="S3.SS1.SSS0.Px3.p1.8.m8.1.1.3.cmml" xref="S3.SS1.SSS0.Px3.p1.8.m8.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px3.p1.8.m8.1.1.3.1.cmml" xref="S3.SS1.SSS0.Px3.p1.8.m8.1.1.3">subscript</csymbol><ci id="S3.SS1.SSS0.Px3.p1.8.m8.1.1.3.2.cmml" xref="S3.SS1.SSS0.Px3.p1.8.m8.1.1.3.2">ğ‘“</ci><ci id="S3.SS1.SSS0.Px3.p1.8.m8.1.1.3.3.cmml" xref="S3.SS1.SSS0.Px3.p1.8.m8.1.1.3.3">ğ‘„</ci></apply><apply id="S3.SS1.SSS0.Px3.p1.8.m8.1.1.1.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.8.m8.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px3.p1.8.m8.1.1.1.1.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.8.m8.1.1.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px3.p1.8.m8.1.1.1.1.1.2.cmml" xref="S3.SS1.SSS0.Px3.p1.8.m8.1.1.1.1.1.2">ğ‘</ci><ci id="S3.SS1.SSS0.Px3.p1.8.m8.1.1.1.1.1.3.cmml" xref="S3.SS1.SSS0.Px3.p1.8.m8.1.1.1.1.1.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px3.p1.8.m8.1c">f_{Q}(q_{i})</annotation></semantics></math> from EquationÂ <a href="#S3.E3" title="In Capturing biases with a question-only branch â€£ 3.1 RUBi learning strategy â€£ 3 Reducing Unimodal Biases Approach â€£ RUBi: Reducing Unimodal Biases for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
We use this loss to only optimize <math id="S3.SS1.SSS0.Px3.p1.9.m9.1" class="ltx_Math" alttext="\theta_{QO}" display="inline"><semantics id="S3.SS1.SSS0.Px3.p1.9.m9.1a"><msub id="S3.SS1.SSS0.Px3.p1.9.m9.1.1" xref="S3.SS1.SSS0.Px3.p1.9.m9.1.1.cmml"><mi id="S3.SS1.SSS0.Px3.p1.9.m9.1.1.2" xref="S3.SS1.SSS0.Px3.p1.9.m9.1.1.2.cmml">Î¸</mi><mrow id="S3.SS1.SSS0.Px3.p1.9.m9.1.1.3" xref="S3.SS1.SSS0.Px3.p1.9.m9.1.1.3.cmml"><mi id="S3.SS1.SSS0.Px3.p1.9.m9.1.1.3.2" xref="S3.SS1.SSS0.Px3.p1.9.m9.1.1.3.2.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px3.p1.9.m9.1.1.3.1" xref="S3.SS1.SSS0.Px3.p1.9.m9.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.SSS0.Px3.p1.9.m9.1.1.3.3" xref="S3.SS1.SSS0.Px3.p1.9.m9.1.1.3.3.cmml">O</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px3.p1.9.m9.1b"><apply id="S3.SS1.SSS0.Px3.p1.9.m9.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px3.p1.9.m9.1.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.9.m9.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px3.p1.9.m9.1.1.2.cmml" xref="S3.SS1.SSS0.Px3.p1.9.m9.1.1.2">ğœƒ</ci><apply id="S3.SS1.SSS0.Px3.p1.9.m9.1.1.3.cmml" xref="S3.SS1.SSS0.Px3.p1.9.m9.1.1.3"><times id="S3.SS1.SSS0.Px3.p1.9.m9.1.1.3.1.cmml" xref="S3.SS1.SSS0.Px3.p1.9.m9.1.1.3.1"></times><ci id="S3.SS1.SSS0.Px3.p1.9.m9.1.1.3.2.cmml" xref="S3.SS1.SSS0.Px3.p1.9.m9.1.1.3.2">ğ‘„</ci><ci id="S3.SS1.SSS0.Px3.p1.9.m9.1.1.3.3.cmml" xref="S3.SS1.SSS0.Px3.p1.9.m9.1.1.3.3">ğ‘‚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px3.p1.9.m9.1c">\theta_{QO}</annotation></semantics></math>, union of the parameters of <math id="S3.SS1.SSS0.Px3.p1.10.m10.1" class="ltx_Math" alttext="c_{q}" display="inline"><semantics id="S3.SS1.SSS0.Px3.p1.10.m10.1a"><msub id="S3.SS1.SSS0.Px3.p1.10.m10.1.1" xref="S3.SS1.SSS0.Px3.p1.10.m10.1.1.cmml"><mi id="S3.SS1.SSS0.Px3.p1.10.m10.1.1.2" xref="S3.SS1.SSS0.Px3.p1.10.m10.1.1.2.cmml">c</mi><mi id="S3.SS1.SSS0.Px3.p1.10.m10.1.1.3" xref="S3.SS1.SSS0.Px3.p1.10.m10.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px3.p1.10.m10.1b"><apply id="S3.SS1.SSS0.Px3.p1.10.m10.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px3.p1.10.m10.1.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.10.m10.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px3.p1.10.m10.1.1.2.cmml" xref="S3.SS1.SSS0.Px3.p1.10.m10.1.1.2">ğ‘</ci><ci id="S3.SS1.SSS0.Px3.p1.10.m10.1.1.3.cmml" xref="S3.SS1.SSS0.Px3.p1.10.m10.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px3.p1.10.m10.1c">c_{q}</annotation></semantics></math> and <math id="S3.SS1.SSS0.Px3.p1.11.m11.1" class="ltx_Math" alttext="\mathit{nn}_{q}" display="inline"><semantics id="S3.SS1.SSS0.Px3.p1.11.m11.1a"><msub id="S3.SS1.SSS0.Px3.p1.11.m11.1.1" xref="S3.SS1.SSS0.Px3.p1.11.m11.1.1.cmml"><mi id="S3.SS1.SSS0.Px3.p1.11.m11.1.1.2" xref="S3.SS1.SSS0.Px3.p1.11.m11.1.1.2.cmml">ğ‘›ğ‘›</mi><mi id="S3.SS1.SSS0.Px3.p1.11.m11.1.1.3" xref="S3.SS1.SSS0.Px3.p1.11.m11.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px3.p1.11.m11.1b"><apply id="S3.SS1.SSS0.Px3.p1.11.m11.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px3.p1.11.m11.1.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.11.m11.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px3.p1.11.m11.1.1.2.cmml" xref="S3.SS1.SSS0.Px3.p1.11.m11.1.1.2">ğ‘›ğ‘›</ci><ci id="S3.SS1.SSS0.Px3.p1.11.m11.1.1.3.cmml" xref="S3.SS1.SSS0.Px3.p1.11.m11.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px3.p1.11.m11.1c">\mathit{nn}_{q}</annotation></semantics></math>.
By doing so, we further improve the question-only branch ability to capture biases. Note that we do not backpropagate this loss to the question encoder <math id="S3.SS1.SSS0.Px3.p1.12.m12.1" class="ltx_Math" alttext="e_{q}" display="inline"><semantics id="S3.SS1.SSS0.Px3.p1.12.m12.1a"><msub id="S3.SS1.SSS0.Px3.p1.12.m12.1.1" xref="S3.SS1.SSS0.Px3.p1.12.m12.1.1.cmml"><mi id="S3.SS1.SSS0.Px3.p1.12.m12.1.1.2" xref="S3.SS1.SSS0.Px3.p1.12.m12.1.1.2.cmml">e</mi><mi id="S3.SS1.SSS0.Px3.p1.12.m12.1.1.3" xref="S3.SS1.SSS0.Px3.p1.12.m12.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px3.p1.12.m12.1b"><apply id="S3.SS1.SSS0.Px3.p1.12.m12.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.12.m12.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px3.p1.12.m12.1.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.12.m12.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px3.p1.12.m12.1.1.2.cmml" xref="S3.SS1.SSS0.Px3.p1.12.m12.1.1.2">ğ‘’</ci><ci id="S3.SS1.SSS0.Px3.p1.12.m12.1.1.3.cmml" xref="S3.SS1.SSS0.Px3.p1.12.m12.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px3.p1.12.m12.1c">e_{q}</annotation></semantics></math> preventing it from directly learning question biases.
We obtain our final loss <math id="S3.SS1.SSS0.Px3.p1.13.m13.1" class="ltx_Math" alttext="\mathcal{L}_{\text{RUBi}}" display="inline"><semantics id="S3.SS1.SSS0.Px3.p1.13.m13.1a"><msub id="S3.SS1.SSS0.Px3.p1.13.m13.1.1" xref="S3.SS1.SSS0.Px3.p1.13.m13.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS0.Px3.p1.13.m13.1.1.2" xref="S3.SS1.SSS0.Px3.p1.13.m13.1.1.2.cmml">â„’</mi><mtext id="S3.SS1.SSS0.Px3.p1.13.m13.1.1.3" xref="S3.SS1.SSS0.Px3.p1.13.m13.1.1.3a.cmml">RUBi</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px3.p1.13.m13.1b"><apply id="S3.SS1.SSS0.Px3.p1.13.m13.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.13.m13.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px3.p1.13.m13.1.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.13.m13.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px3.p1.13.m13.1.1.2.cmml" xref="S3.SS1.SSS0.Px3.p1.13.m13.1.1.2">â„’</ci><ci id="S3.SS1.SSS0.Px3.p1.13.m13.1.1.3a.cmml" xref="S3.SS1.SSS0.Px3.p1.13.m13.1.1.3"><mtext mathsize="70%" id="S3.SS1.SSS0.Px3.p1.13.m13.1.1.3.cmml" xref="S3.SS1.SSS0.Px3.p1.13.m13.1.1.3">RUBi</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px3.p1.13.m13.1c">\mathcal{L}_{\text{RUBi}}</annotation></semantics></math> by summing the two losses together in the following equation:</p>
<table id="S6.EGx3" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E5.m1.3" class="ltx_Math" alttext="\displaystyle\mathcal{L}_{\text{RUBi}}(\theta_{QM},\theta_{QO};\mathcal{D})" display="inline"><semantics id="S3.E5.m1.3a"><mrow id="S3.E5.m1.3.3" xref="S3.E5.m1.3.3.cmml"><msub id="S3.E5.m1.3.3.4" xref="S3.E5.m1.3.3.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.3.3.4.2" xref="S3.E5.m1.3.3.4.2.cmml">â„’</mi><mtext id="S3.E5.m1.3.3.4.3" xref="S3.E5.m1.3.3.4.3a.cmml">RUBi</mtext></msub><mo lspace="0em" rspace="0em" id="S3.E5.m1.3.3.3" xref="S3.E5.m1.3.3.3.cmml">â€‹</mo><mrow id="S3.E5.m1.3.3.2.2" xref="S3.E5.m1.3.3.2.3.cmml"><mo stretchy="false" id="S3.E5.m1.3.3.2.2.3" xref="S3.E5.m1.3.3.2.3.cmml">(</mo><msub id="S3.E5.m1.2.2.1.1.1" xref="S3.E5.m1.2.2.1.1.1.cmml"><mi id="S3.E5.m1.2.2.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.2.cmml">Î¸</mi><mrow id="S3.E5.m1.2.2.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.3.cmml"><mi id="S3.E5.m1.2.2.1.1.1.3.2" xref="S3.E5.m1.2.2.1.1.1.3.2.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.1.1.1.3.1" xref="S3.E5.m1.2.2.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.E5.m1.2.2.1.1.1.3.3" xref="S3.E5.m1.2.2.1.1.1.3.3.cmml">M</mi></mrow></msub><mo id="S3.E5.m1.3.3.2.2.4" xref="S3.E5.m1.3.3.2.3.cmml">,</mo><msub id="S3.E5.m1.3.3.2.2.2" xref="S3.E5.m1.3.3.2.2.2.cmml"><mi id="S3.E5.m1.3.3.2.2.2.2" xref="S3.E5.m1.3.3.2.2.2.2.cmml">Î¸</mi><mrow id="S3.E5.m1.3.3.2.2.2.3" xref="S3.E5.m1.3.3.2.2.2.3.cmml"><mi id="S3.E5.m1.3.3.2.2.2.3.2" xref="S3.E5.m1.3.3.2.2.2.3.2.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.3.3.2.2.2.3.1" xref="S3.E5.m1.3.3.2.2.2.3.1.cmml">â€‹</mo><mi id="S3.E5.m1.3.3.2.2.2.3.3" xref="S3.E5.m1.3.3.2.2.2.3.3.cmml">O</mi></mrow></msub><mo id="S3.E5.m1.3.3.2.2.5" xref="S3.E5.m1.3.3.2.3.cmml">;</mo><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml">ğ’Ÿ</mi><mo stretchy="false" id="S3.E5.m1.3.3.2.2.6" xref="S3.E5.m1.3.3.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.3b"><apply id="S3.E5.m1.3.3.cmml" xref="S3.E5.m1.3.3"><times id="S3.E5.m1.3.3.3.cmml" xref="S3.E5.m1.3.3.3"></times><apply id="S3.E5.m1.3.3.4.cmml" xref="S3.E5.m1.3.3.4"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.4.1.cmml" xref="S3.E5.m1.3.3.4">subscript</csymbol><ci id="S3.E5.m1.3.3.4.2.cmml" xref="S3.E5.m1.3.3.4.2">â„’</ci><ci id="S3.E5.m1.3.3.4.3a.cmml" xref="S3.E5.m1.3.3.4.3"><mtext mathsize="70%" id="S3.E5.m1.3.3.4.3.cmml" xref="S3.E5.m1.3.3.4.3">RUBi</mtext></ci></apply><vector id="S3.E5.m1.3.3.2.3.cmml" xref="S3.E5.m1.3.3.2.2"><apply id="S3.E5.m1.2.2.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.E5.m1.2.2.1.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.1.2">ğœƒ</ci><apply id="S3.E5.m1.2.2.1.1.1.3.cmml" xref="S3.E5.m1.2.2.1.1.1.3"><times id="S3.E5.m1.2.2.1.1.1.3.1.cmml" xref="S3.E5.m1.2.2.1.1.1.3.1"></times><ci id="S3.E5.m1.2.2.1.1.1.3.2.cmml" xref="S3.E5.m1.2.2.1.1.1.3.2">ğ‘„</ci><ci id="S3.E5.m1.2.2.1.1.1.3.3.cmml" xref="S3.E5.m1.2.2.1.1.1.3.3">ğ‘€</ci></apply></apply><apply id="S3.E5.m1.3.3.2.2.2.cmml" xref="S3.E5.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.2.2.2.1.cmml" xref="S3.E5.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.E5.m1.3.3.2.2.2.2.cmml" xref="S3.E5.m1.3.3.2.2.2.2">ğœƒ</ci><apply id="S3.E5.m1.3.3.2.2.2.3.cmml" xref="S3.E5.m1.3.3.2.2.2.3"><times id="S3.E5.m1.3.3.2.2.2.3.1.cmml" xref="S3.E5.m1.3.3.2.2.2.3.1"></times><ci id="S3.E5.m1.3.3.2.2.2.3.2.cmml" xref="S3.E5.m1.3.3.2.2.2.3.2">ğ‘„</ci><ci id="S3.E5.m1.3.3.2.2.2.3.3.cmml" xref="S3.E5.m1.3.3.2.2.2.3.3">ğ‘‚</ci></apply></apply><ci id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1">ğ’Ÿ</ci></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.3c">\displaystyle\mathcal{L}_{\text{RUBi}}(\theta_{QM},\theta_{QO};\mathcal{D})</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E5.m2.4" class="ltx_Math" alttext="\displaystyle=\mathcal{L}_{QM}(\theta_{QM};\mathcal{D})+\mathcal{L}_{QO}(\theta_{QO};\mathcal{D})" display="inline"><semantics id="S3.E5.m2.4a"><mrow id="S3.E5.m2.4.4" xref="S3.E5.m2.4.4.cmml"><mi id="S3.E5.m2.4.4.4" xref="S3.E5.m2.4.4.4.cmml"></mi><mo id="S3.E5.m2.4.4.3" xref="S3.E5.m2.4.4.3.cmml">=</mo><mrow id="S3.E5.m2.4.4.2" xref="S3.E5.m2.4.4.2.cmml"><mrow id="S3.E5.m2.3.3.1.1" xref="S3.E5.m2.3.3.1.1.cmml"><msub id="S3.E5.m2.3.3.1.1.3" xref="S3.E5.m2.3.3.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m2.3.3.1.1.3.2" xref="S3.E5.m2.3.3.1.1.3.2.cmml">â„’</mi><mrow id="S3.E5.m2.3.3.1.1.3.3" xref="S3.E5.m2.3.3.1.1.3.3.cmml"><mi id="S3.E5.m2.3.3.1.1.3.3.2" xref="S3.E5.m2.3.3.1.1.3.3.2.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S3.E5.m2.3.3.1.1.3.3.1" xref="S3.E5.m2.3.3.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.E5.m2.3.3.1.1.3.3.3" xref="S3.E5.m2.3.3.1.1.3.3.3.cmml">M</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E5.m2.3.3.1.1.2" xref="S3.E5.m2.3.3.1.1.2.cmml">â€‹</mo><mrow id="S3.E5.m2.3.3.1.1.1.1" xref="S3.E5.m2.3.3.1.1.1.2.cmml"><mo stretchy="false" id="S3.E5.m2.3.3.1.1.1.1.2" xref="S3.E5.m2.3.3.1.1.1.2.cmml">(</mo><msub id="S3.E5.m2.3.3.1.1.1.1.1" xref="S3.E5.m2.3.3.1.1.1.1.1.cmml"><mi id="S3.E5.m2.3.3.1.1.1.1.1.2" xref="S3.E5.m2.3.3.1.1.1.1.1.2.cmml">Î¸</mi><mrow id="S3.E5.m2.3.3.1.1.1.1.1.3" xref="S3.E5.m2.3.3.1.1.1.1.1.3.cmml"><mi id="S3.E5.m2.3.3.1.1.1.1.1.3.2" xref="S3.E5.m2.3.3.1.1.1.1.1.3.2.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S3.E5.m2.3.3.1.1.1.1.1.3.1" xref="S3.E5.m2.3.3.1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.E5.m2.3.3.1.1.1.1.1.3.3" xref="S3.E5.m2.3.3.1.1.1.1.1.3.3.cmml">M</mi></mrow></msub><mo id="S3.E5.m2.3.3.1.1.1.1.3" xref="S3.E5.m2.3.3.1.1.1.2.cmml">;</mo><mi class="ltx_font_mathcaligraphic" id="S3.E5.m2.1.1" xref="S3.E5.m2.1.1.cmml">ğ’Ÿ</mi><mo stretchy="false" id="S3.E5.m2.3.3.1.1.1.1.4" xref="S3.E5.m2.3.3.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E5.m2.4.4.2.3" xref="S3.E5.m2.4.4.2.3.cmml">+</mo><mrow id="S3.E5.m2.4.4.2.2" xref="S3.E5.m2.4.4.2.2.cmml"><msub id="S3.E5.m2.4.4.2.2.3" xref="S3.E5.m2.4.4.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m2.4.4.2.2.3.2" xref="S3.E5.m2.4.4.2.2.3.2.cmml">â„’</mi><mrow id="S3.E5.m2.4.4.2.2.3.3" xref="S3.E5.m2.4.4.2.2.3.3.cmml"><mi id="S3.E5.m2.4.4.2.2.3.3.2" xref="S3.E5.m2.4.4.2.2.3.3.2.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S3.E5.m2.4.4.2.2.3.3.1" xref="S3.E5.m2.4.4.2.2.3.3.1.cmml">â€‹</mo><mi id="S3.E5.m2.4.4.2.2.3.3.3" xref="S3.E5.m2.4.4.2.2.3.3.3.cmml">O</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E5.m2.4.4.2.2.2" xref="S3.E5.m2.4.4.2.2.2.cmml">â€‹</mo><mrow id="S3.E5.m2.4.4.2.2.1.1" xref="S3.E5.m2.4.4.2.2.1.2.cmml"><mo stretchy="false" id="S3.E5.m2.4.4.2.2.1.1.2" xref="S3.E5.m2.4.4.2.2.1.2.cmml">(</mo><msub id="S3.E5.m2.4.4.2.2.1.1.1" xref="S3.E5.m2.4.4.2.2.1.1.1.cmml"><mi id="S3.E5.m2.4.4.2.2.1.1.1.2" xref="S3.E5.m2.4.4.2.2.1.1.1.2.cmml">Î¸</mi><mrow id="S3.E5.m2.4.4.2.2.1.1.1.3" xref="S3.E5.m2.4.4.2.2.1.1.1.3.cmml"><mi id="S3.E5.m2.4.4.2.2.1.1.1.3.2" xref="S3.E5.m2.4.4.2.2.1.1.1.3.2.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S3.E5.m2.4.4.2.2.1.1.1.3.1" xref="S3.E5.m2.4.4.2.2.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.E5.m2.4.4.2.2.1.1.1.3.3" xref="S3.E5.m2.4.4.2.2.1.1.1.3.3.cmml">O</mi></mrow></msub><mo id="S3.E5.m2.4.4.2.2.1.1.3" xref="S3.E5.m2.4.4.2.2.1.2.cmml">;</mo><mi class="ltx_font_mathcaligraphic" id="S3.E5.m2.2.2" xref="S3.E5.m2.2.2.cmml">ğ’Ÿ</mi><mo stretchy="false" id="S3.E5.m2.4.4.2.2.1.1.4" xref="S3.E5.m2.4.4.2.2.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m2.4b"><apply id="S3.E5.m2.4.4.cmml" xref="S3.E5.m2.4.4"><eq id="S3.E5.m2.4.4.3.cmml" xref="S3.E5.m2.4.4.3"></eq><csymbol cd="latexml" id="S3.E5.m2.4.4.4.cmml" xref="S3.E5.m2.4.4.4">absent</csymbol><apply id="S3.E5.m2.4.4.2.cmml" xref="S3.E5.m2.4.4.2"><plus id="S3.E5.m2.4.4.2.3.cmml" xref="S3.E5.m2.4.4.2.3"></plus><apply id="S3.E5.m2.3.3.1.1.cmml" xref="S3.E5.m2.3.3.1.1"><times id="S3.E5.m2.3.3.1.1.2.cmml" xref="S3.E5.m2.3.3.1.1.2"></times><apply id="S3.E5.m2.3.3.1.1.3.cmml" xref="S3.E5.m2.3.3.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m2.3.3.1.1.3.1.cmml" xref="S3.E5.m2.3.3.1.1.3">subscript</csymbol><ci id="S3.E5.m2.3.3.1.1.3.2.cmml" xref="S3.E5.m2.3.3.1.1.3.2">â„’</ci><apply id="S3.E5.m2.3.3.1.1.3.3.cmml" xref="S3.E5.m2.3.3.1.1.3.3"><times id="S3.E5.m2.3.3.1.1.3.3.1.cmml" xref="S3.E5.m2.3.3.1.1.3.3.1"></times><ci id="S3.E5.m2.3.3.1.1.3.3.2.cmml" xref="S3.E5.m2.3.3.1.1.3.3.2">ğ‘„</ci><ci id="S3.E5.m2.3.3.1.1.3.3.3.cmml" xref="S3.E5.m2.3.3.1.1.3.3.3">ğ‘€</ci></apply></apply><list id="S3.E5.m2.3.3.1.1.1.2.cmml" xref="S3.E5.m2.3.3.1.1.1.1"><apply id="S3.E5.m2.3.3.1.1.1.1.1.cmml" xref="S3.E5.m2.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m2.3.3.1.1.1.1.1.1.cmml" xref="S3.E5.m2.3.3.1.1.1.1.1">subscript</csymbol><ci id="S3.E5.m2.3.3.1.1.1.1.1.2.cmml" xref="S3.E5.m2.3.3.1.1.1.1.1.2">ğœƒ</ci><apply id="S3.E5.m2.3.3.1.1.1.1.1.3.cmml" xref="S3.E5.m2.3.3.1.1.1.1.1.3"><times id="S3.E5.m2.3.3.1.1.1.1.1.3.1.cmml" xref="S3.E5.m2.3.3.1.1.1.1.1.3.1"></times><ci id="S3.E5.m2.3.3.1.1.1.1.1.3.2.cmml" xref="S3.E5.m2.3.3.1.1.1.1.1.3.2">ğ‘„</ci><ci id="S3.E5.m2.3.3.1.1.1.1.1.3.3.cmml" xref="S3.E5.m2.3.3.1.1.1.1.1.3.3">ğ‘€</ci></apply></apply><ci id="S3.E5.m2.1.1.cmml" xref="S3.E5.m2.1.1">ğ’Ÿ</ci></list></apply><apply id="S3.E5.m2.4.4.2.2.cmml" xref="S3.E5.m2.4.4.2.2"><times id="S3.E5.m2.4.4.2.2.2.cmml" xref="S3.E5.m2.4.4.2.2.2"></times><apply id="S3.E5.m2.4.4.2.2.3.cmml" xref="S3.E5.m2.4.4.2.2.3"><csymbol cd="ambiguous" id="S3.E5.m2.4.4.2.2.3.1.cmml" xref="S3.E5.m2.4.4.2.2.3">subscript</csymbol><ci id="S3.E5.m2.4.4.2.2.3.2.cmml" xref="S3.E5.m2.4.4.2.2.3.2">â„’</ci><apply id="S3.E5.m2.4.4.2.2.3.3.cmml" xref="S3.E5.m2.4.4.2.2.3.3"><times id="S3.E5.m2.4.4.2.2.3.3.1.cmml" xref="S3.E5.m2.4.4.2.2.3.3.1"></times><ci id="S3.E5.m2.4.4.2.2.3.3.2.cmml" xref="S3.E5.m2.4.4.2.2.3.3.2">ğ‘„</ci><ci id="S3.E5.m2.4.4.2.2.3.3.3.cmml" xref="S3.E5.m2.4.4.2.2.3.3.3">ğ‘‚</ci></apply></apply><list id="S3.E5.m2.4.4.2.2.1.2.cmml" xref="S3.E5.m2.4.4.2.2.1.1"><apply id="S3.E5.m2.4.4.2.2.1.1.1.cmml" xref="S3.E5.m2.4.4.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m2.4.4.2.2.1.1.1.1.cmml" xref="S3.E5.m2.4.4.2.2.1.1.1">subscript</csymbol><ci id="S3.E5.m2.4.4.2.2.1.1.1.2.cmml" xref="S3.E5.m2.4.4.2.2.1.1.1.2">ğœƒ</ci><apply id="S3.E5.m2.4.4.2.2.1.1.1.3.cmml" xref="S3.E5.m2.4.4.2.2.1.1.1.3"><times id="S3.E5.m2.4.4.2.2.1.1.1.3.1.cmml" xref="S3.E5.m2.4.4.2.2.1.1.1.3.1"></times><ci id="S3.E5.m2.4.4.2.2.1.1.1.3.2.cmml" xref="S3.E5.m2.4.4.2.2.1.1.1.3.2">ğ‘„</ci><ci id="S3.E5.m2.4.4.2.2.1.1.1.3.3.cmml" xref="S3.E5.m2.4.4.2.2.1.1.1.3.3">ğ‘‚</ci></apply></apply><ci id="S3.E5.m2.2.2.cmml" xref="S3.E5.m2.2.2">ğ’Ÿ</ci></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m2.4c">\displaystyle=\mathcal{L}_{QM}(\theta_{QM};\mathcal{D})+\mathcal{L}_{QO}(\theta_{QO};\mathcal{D})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Baseline architecture</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.6" class="ltx_p">Most VQA architectures from the state of the art are compatible with our RUBi learning strategy. To test our strategy, we design a fast and simple architecture inspired from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. This baseline architecture is detailed in the supplementary material.
As common in the state of the art, our baseline architecture encodes the image as a bag of <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="n_{v}" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><msub id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">n</mi><mi id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">ğ‘›</ci><ci id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3">ğ‘£</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">n_{v}</annotation></semantics></math> visual features <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{v}_{i}\in\mathbb{R}^{d_{v}}" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mrow id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><msub id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml"><mi id="S3.SS2.p1.2.m2.1.1.2.2" xref="S3.SS2.p1.2.m2.1.1.2.2.cmml">ğ¯</mi><mi id="S3.SS2.p1.2.m2.1.1.2.3" xref="S3.SS2.p1.2.m2.1.1.2.3.cmml">i</mi></msub><mo id="S3.SS2.p1.2.m2.1.1.1" xref="S3.SS2.p1.2.m2.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3.cmml"><mi id="S3.SS2.p1.2.m2.1.1.3.2" xref="S3.SS2.p1.2.m2.1.1.3.2.cmml">â„</mi><msub id="S3.SS2.p1.2.m2.1.1.3.3" xref="S3.SS2.p1.2.m2.1.1.3.3.cmml"><mi id="S3.SS2.p1.2.m2.1.1.3.3.2" xref="S3.SS2.p1.2.m2.1.1.3.3.2.cmml">d</mi><mi id="S3.SS2.p1.2.m2.1.1.3.3.3" xref="S3.SS2.p1.2.m2.1.1.3.3.3.cmml">v</mi></msub></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><in id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1.1"></in><apply id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.2.1.cmml" xref="S3.SS2.p1.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.2.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2.2">ğ¯</ci><ci id="S3.SS2.p1.2.m2.1.1.2.3.cmml" xref="S3.SS2.p1.2.m2.1.1.2.3">ğ‘–</ci></apply><apply id="S3.SS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.3.1.cmml" xref="S3.SS2.p1.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.3.2.cmml" xref="S3.SS2.p1.2.m2.1.1.3.2">â„</ci><apply id="S3.SS2.p1.2.m2.1.1.3.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.3.3.1.cmml" xref="S3.SS2.p1.2.m2.1.1.3.3">subscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.3.3.2.cmml" xref="S3.SS2.p1.2.m2.1.1.3.3.2">ğ‘‘</ci><ci id="S3.SS2.p1.2.m2.1.1.3.3.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3.3.3">ğ‘£</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">\mathbf{v}_{i}\in\mathbb{R}^{d_{v}}</annotation></semantics></math> using the pretrained Faster R-CNN by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, and encodes the question as a vector <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="\mathbf{q}\in\mathbb{R}^{d_{q}}" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mrow id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml"><mi id="S3.SS2.p1.3.m3.1.1.2" xref="S3.SS2.p1.3.m3.1.1.2.cmml">ğª</mi><mo id="S3.SS2.p1.3.m3.1.1.1" xref="S3.SS2.p1.3.m3.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS2.p1.3.m3.1.1.3" xref="S3.SS2.p1.3.m3.1.1.3.cmml"><mi id="S3.SS2.p1.3.m3.1.1.3.2" xref="S3.SS2.p1.3.m3.1.1.3.2.cmml">â„</mi><msub id="S3.SS2.p1.3.m3.1.1.3.3" xref="S3.SS2.p1.3.m3.1.1.3.3.cmml"><mi id="S3.SS2.p1.3.m3.1.1.3.3.2" xref="S3.SS2.p1.3.m3.1.1.3.3.2.cmml">d</mi><mi id="S3.SS2.p1.3.m3.1.1.3.3.3" xref="S3.SS2.p1.3.m3.1.1.3.3.3.cmml">q</mi></msub></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><apply id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1"><in id="S3.SS2.p1.3.m3.1.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1.1"></in><ci id="S3.SS2.p1.3.m3.1.1.2.cmml" xref="S3.SS2.p1.3.m3.1.1.2">ğª</ci><apply id="S3.SS2.p1.3.m3.1.1.3.cmml" xref="S3.SS2.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p1.3.m3.1.1.3.1.cmml" xref="S3.SS2.p1.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS2.p1.3.m3.1.1.3.2.cmml" xref="S3.SS2.p1.3.m3.1.1.3.2">â„</ci><apply id="S3.SS2.p1.3.m3.1.1.3.3.cmml" xref="S3.SS2.p1.3.m3.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS2.p1.3.m3.1.1.3.3.1.cmml" xref="S3.SS2.p1.3.m3.1.1.3.3">subscript</csymbol><ci id="S3.SS2.p1.3.m3.1.1.3.3.2.cmml" xref="S3.SS2.p1.3.m3.1.1.3.3.2">ğ‘‘</ci><ci id="S3.SS2.p1.3.m3.1.1.3.3.3.cmml" xref="S3.SS2.p1.3.m3.1.1.3.3.3">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">\mathbf{q}\in\mathbb{R}^{d_{q}}</annotation></semantics></math> using a GRU, pretrained on the skipthought task <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.
The VQA model consists of a Bilinear BLOCK fusion <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> which merges the question representation <math id="S3.SS2.p1.4.m4.1" class="ltx_Math" alttext="\mathbf{q}" display="inline"><semantics id="S3.SS2.p1.4.m4.1a"><mi id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">ğª</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">ğª</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">\mathbf{q}</annotation></semantics></math> with the features <math id="S3.SS2.p1.5.m5.1" class="ltx_Math" alttext="\mathbf{v}_{i}" display="inline"><semantics id="S3.SS2.p1.5.m5.1a"><msub id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml"><mi id="S3.SS2.p1.5.m5.1.1.2" xref="S3.SS2.p1.5.m5.1.1.2.cmml">ğ¯</mi><mi id="S3.SS2.p1.5.m5.1.1.3" xref="S3.SS2.p1.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.1b"><apply id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.1.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.p1.5.m5.1.1.2.cmml" xref="S3.SS2.p1.5.m5.1.1.2">ğ¯</ci><ci id="S3.SS2.p1.5.m5.1.1.3.cmml" xref="S3.SS2.p1.5.m5.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.1c">\mathbf{v}_{i}</annotation></semantics></math> of each region of the image. The output is aggregated using a max pooling on the <math id="S3.SS2.p1.6.m6.1" class="ltx_Math" alttext="n_{v}" display="inline"><semantics id="S3.SS2.p1.6.m6.1a"><msub id="S3.SS2.p1.6.m6.1.1" xref="S3.SS2.p1.6.m6.1.1.cmml"><mi id="S3.SS2.p1.6.m6.1.1.2" xref="S3.SS2.p1.6.m6.1.1.2.cmml">n</mi><mi id="S3.SS2.p1.6.m6.1.1.3" xref="S3.SS2.p1.6.m6.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m6.1b"><apply id="S3.SS2.p1.6.m6.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.6.m6.1.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.p1.6.m6.1.1.2.cmml" xref="S3.SS2.p1.6.m6.1.1.2">ğ‘›</ci><ci id="S3.SS2.p1.6.m6.1.1.3.cmml" xref="S3.SS2.p1.6.m6.1.1.3">ğ‘£</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m6.1c">n_{v}</annotation></semantics></math> regions. The resulting vector is then fed into a MLP classifier which outputs the final predictions.
While most of our experiments are done with this fast and simple baseline architecture, we experimentally demonstrate that the RUBi learning strategy is effective on other VQA architectures.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<section id="S4.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Experimental setup</h4>

<div id="S4.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px1.p1.1" class="ltx_p">We train and evaluate our models on VQA-CP v2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. This dataset was developed to evaluate the models robustness to question biases.
We follow the same training and evaluation protocol as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, who also propose a learning strategy to reduce biases. For each model, we report the standard VQA evaluation metric <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. We also evaluate our models on the standard VQA v2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. Further implementation details are included in the supplementary materials, as well as results on VQA-CP v1 and grounding experiments on VQA-HAT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>.</p>
</div>
</section>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Results</h3>

<section id="S4.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">State-of-the-art comparison</h4>

<div id="S4.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.p1.1" class="ltx_p">In TableÂ <a href="#S4.T1" title="Table 1 â€£ Additional baselines â€£ 4.1 Results â€£ 4 Experiments â€£ RUBi: Reducing Unimodal Biases for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we compare our approach consisting of our baseline architecture trained with RUBi on VQA-CP v2 against the state of the art. To be fair, we only report approaches that use the strong visual features from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. We compute the average accuracy over 5 experiments with different random seeds.
Our RUBi approach reaches an average overall accuracy of 47.11% with a low standard deviation of <math id="S4.SS1.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.SS1.SSS0.Px1.p1.1.m1.1a"><mo id="S4.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p1.1.m1.1b"><csymbol cd="latexml" id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p1.1.m1.1c">\pm</annotation></semantics></math>0.51. This accuracy corresponds to a gain of +5.94 percentage points over the current state-of-the-art UpDn + Q-Adv + DoE.
It also corresponds to a gain of +15.88 over GVQA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, which is a specific architecture designed for VQA-CP.
RUBi reaches a +8.65 improvement over our baseline model trained with the classical cross-entropy. In comparison, the second best approach UpDn + Q-Adv + DoE only achieves a +1.43 gain in overall accuracy over their baseline UpDn. In addition, our approach does not significantly reduce the accuracy over our baseline for the answer type <span id="S4.SS1.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_italic">Other</span>, while the second best approach reduces it by 10.57 point.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Additional baselines</h4>

<div id="S4.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px2.p1.1" class="ltx_p">We compare our results to two sampling-based training methods. In the <span id="S4.SS1.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_italic">Balanced Sampling</span> method, we sample the questions such that the answer distribution is uniform. In the <span id="S4.SS1.SSS0.Px2.p1.1.2" class="ltx_text ltx_font_italic">Question-Type Balanced Sampling</span> method, we sample the questions such that for every question type, the answer distribution is uniform, but the question type distribution remains the same overall
Both methods are tested with our baseline architecture.
We can see that the <span id="S4.SS1.SSS0.Px2.p1.1.3" class="ltx_text ltx_font_italic">Question-Type Balanced Sampling</span> improves the result from 38.46 in accuracy to 42.11. This gain is already +0.94 higher than the previous state of the art method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, but remains significantly lower than our proposed method.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T1.11.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S4.T1.12.2" class="ltx_text" style="font-size:90%;">State-of-the-art results on VQA-CP v2 <span id="S4.T1.12.2.1" class="ltx_text ltx_font_typewriter">test</span>. All reported models use the same features from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. Models with * have been trained by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. Models with ** have been trained by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>.</span></figcaption>
<p id="S4.T1.8" class="ltx_p">.


<span id="S4.T1.8.8" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<span class="ltx_tbody">
<span id="S4.T1.8.8.9.1" class="ltx_tr">
<span id="S4.T1.8.8.9.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt ltx_rowspan ltx_rowspan_2"><span id="S4.T1.8.8.9.1.1.1" class="ltx_text">Model</span></span>
<span id="S4.T1.8.8.9.1.2" class="ltx_td ltx_border_tt"></span>
<span id="S4.T1.8.8.9.1.3" class="ltx_td ltx_align_center ltx_border_tt ltx_rowspan ltx_rowspan_2"><span id="S4.T1.8.8.9.1.3.1" class="ltx_text">Overall</span></span>
<span id="S4.T1.8.8.9.1.4" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_3"><span id="S4.T1.8.8.9.1.4.1" class="ltx_text" style="font-size:80%;">Answer type</span></span></span>
<span id="S4.T1.8.8.10.2" class="ltx_tr">
<span id="S4.T1.8.8.10.2.1" class="ltx_td"></span>
<span id="S4.T1.8.8.10.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.8.8.10.2.2.1" class="ltx_text" style="font-size:80%;">Yes/No</span></span>
<span id="S4.T1.8.8.10.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.8.8.10.2.3.1" class="ltx_text" style="font-size:80%;">Number</span></span>
<span id="S4.T1.8.8.10.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.8.8.10.2.4.1" class="ltx_text" style="font-size:80%;">Other</span></span></span>
<span id="S4.T1.8.8.11.3" class="ltx_tr">
<span id="S4.T1.8.8.11.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Question-Only <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite></span>
<span id="S4.T1.8.8.11.3.2" class="ltx_td ltx_border_t"></span>
<span id="S4.T1.8.8.11.3.3" class="ltx_td ltx_align_center ltx_border_t">15.95</span>
<span id="S4.T1.8.8.11.3.4" class="ltx_td ltx_align_center ltx_border_t">35.09</span>
<span id="S4.T1.8.8.11.3.5" class="ltx_td ltx_align_center ltx_border_t">11.63</span>
<span id="S4.T1.8.8.11.3.6" class="ltx_td ltx_align_center ltx_border_t">7.11</span></span>
<span id="S4.T1.8.8.12.4" class="ltx_tr">
<span id="S4.T1.8.8.12.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">UpDn <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> **</span>
<span id="S4.T1.8.8.12.4.2" class="ltx_td"></span>
<span id="S4.T1.8.8.12.4.3" class="ltx_td ltx_align_center">38.01</span>
<span id="S4.T1.8.8.12.4.4" class="ltx_td ltx_align_center">.</span>
<span id="S4.T1.8.8.12.4.5" class="ltx_td ltx_align_center">.</span>
<span id="S4.T1.8.8.12.4.6" class="ltx_td ltx_align_center">.</span></span>
<span id="S4.T1.8.8.13.5" class="ltx_tr">
<span id="S4.T1.8.8.13.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">RAMEN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite></span>
<span id="S4.T1.8.8.13.5.2" class="ltx_td"></span>
<span id="S4.T1.8.8.13.5.3" class="ltx_td ltx_align_center">39.21</span>
<span id="S4.T1.8.8.13.5.4" class="ltx_td ltx_align_center">.</span>
<span id="S4.T1.8.8.13.5.5" class="ltx_td ltx_align_center">.</span>
<span id="S4.T1.8.8.13.5.6" class="ltx_td ltx_align_center">.</span></span>
<span id="S4.T1.8.8.14.6" class="ltx_tr">
<span id="S4.T1.8.8.14.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">BAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> **</span>
<span id="S4.T1.8.8.14.6.2" class="ltx_td"></span>
<span id="S4.T1.8.8.14.6.3" class="ltx_td ltx_align_center">39.31</span>
<span id="S4.T1.8.8.14.6.4" class="ltx_td ltx_align_center">.</span>
<span id="S4.T1.8.8.14.6.5" class="ltx_td ltx_align_center">.</span>
<span id="S4.T1.8.8.14.6.6" class="ltx_td ltx_align_center">.</span></span>
<span id="S4.T1.8.8.15.7" class="ltx_tr">
<span id="S4.T1.8.8.15.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">MuRel <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite></span>
<span id="S4.T1.8.8.15.7.2" class="ltx_td"></span>
<span id="S4.T1.8.8.15.7.3" class="ltx_td ltx_align_center">39.54</span>
<span id="S4.T1.8.8.15.7.4" class="ltx_td ltx_align_center">42.85</span>
<span id="S4.T1.8.8.15.7.5" class="ltx_td ltx_align_center">13.17</span>
<span id="S4.T1.8.8.15.7.6" class="ltx_td ltx_align_center">45.04</span></span>
<span id="S4.T1.8.8.16.8" class="ltx_tr">
<span id="S4.T1.8.8.16.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">UpDn <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> *</span>
<span id="S4.T1.8.8.16.8.2" class="ltx_td"></span>
<span id="S4.T1.8.8.16.8.3" class="ltx_td ltx_align_center">39.74</span>
<span id="S4.T1.8.8.16.8.4" class="ltx_td ltx_align_center">42.27</span>
<span id="S4.T1.8.8.16.8.5" class="ltx_td ltx_align_center">11.93</span>
<span id="S4.T1.8.8.16.8.6" class="ltx_td ltx_align_center"><span id="S4.T1.8.8.16.8.6.1" class="ltx_text ltx_font_bold">46.05</span></span></span>
<span id="S4.T1.8.8.17.9" class="ltx_tr">
<span id="S4.T1.8.8.17.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">UpDn + Q-Adv + DoE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite></span>
<span id="S4.T1.8.8.17.9.2" class="ltx_td"></span>
<span id="S4.T1.8.8.17.9.3" class="ltx_td ltx_align_center">41.17</span>
<span id="S4.T1.8.8.17.9.4" class="ltx_td ltx_align_center">65.49</span>
<span id="S4.T1.8.8.17.9.5" class="ltx_td ltx_align_center">15.48</span>
<span id="S4.T1.8.8.17.9.6" class="ltx_td ltx_align_center">35.48</span></span>
<span id="S4.T1.8.8.18.10" class="ltx_tr">
<span id="S4.T1.8.8.18.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Balanced Sampling</span>
<span id="S4.T1.8.8.18.10.2" class="ltx_td ltx_border_t"></span>
<span id="S4.T1.8.8.18.10.3" class="ltx_td ltx_align_center ltx_border_t">40.38</span>
<span id="S4.T1.8.8.18.10.4" class="ltx_td ltx_align_center ltx_border_t">57.99</span>
<span id="S4.T1.8.8.18.10.5" class="ltx_td ltx_align_center ltx_border_t">10.07</span>
<span id="S4.T1.8.8.18.10.6" class="ltx_td ltx_align_center ltx_border_t">39.23</span></span>
<span id="S4.T1.8.8.19.11" class="ltx_tr">
<span id="S4.T1.8.8.19.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Q-type Balanced Sampling</span>
<span id="S4.T1.8.8.19.11.2" class="ltx_td"></span>
<span id="S4.T1.8.8.19.11.3" class="ltx_td ltx_align_center">42.11</span>
<span id="S4.T1.8.8.19.11.4" class="ltx_td ltx_align_center">61.55</span>
<span id="S4.T1.8.8.19.11.5" class="ltx_td ltx_align_center">11.26</span>
<span id="S4.T1.8.8.19.11.6" class="ltx_td ltx_align_center">40.39</span></span>
<span id="S4.T1.4.4.4" class="ltx_tr">
<span id="S4.T1.4.4.4.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Baseline architecture (ours)</span>
<span id="S4.T1.4.4.4.6" class="ltx_td ltx_border_t"></span>
<span id="S4.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">38.46 <math id="S4.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.1.1.1.1.m1.1a"><mo id="S4.T1.1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.1.m1.1c">\pm</annotation></semantics></math> 0.07</span>
<span id="S4.T1.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">42.85 <math id="S4.T1.2.2.2.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.2.2.2.2.m1.1a"><mo id="S4.T1.2.2.2.2.m1.1.1" xref="S4.T1.2.2.2.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.2.m1.1b"><csymbol cd="latexml" id="S4.T1.2.2.2.2.m1.1.1.cmml" xref="S4.T1.2.2.2.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.2.m1.1c">\pm</annotation></semantics></math> 0.18</span>
<span id="S4.T1.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t">12.81 <math id="S4.T1.3.3.3.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.3.3.3.3.m1.1a"><mo id="S4.T1.3.3.3.3.m1.1.1" xref="S4.T1.3.3.3.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.3.m1.1b"><csymbol cd="latexml" id="S4.T1.3.3.3.3.m1.1.1.cmml" xref="S4.T1.3.3.3.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.3.m1.1c">\pm</annotation></semantics></math> 0.20</span>
<span id="S4.T1.4.4.4.4" class="ltx_td ltx_align_center ltx_border_t">43.20 <math id="S4.T1.4.4.4.4.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.4.4.4.4.m1.1a"><mo id="S4.T1.4.4.4.4.m1.1.1" xref="S4.T1.4.4.4.4.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.4.4.m1.1b"><csymbol cd="latexml" id="S4.T1.4.4.4.4.m1.1.1.cmml" xref="S4.T1.4.4.4.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.4.4.m1.1c">\pm</annotation></semantics></math> 0.15</span></span>
<span id="S4.T1.8.8.8" class="ltx_tr">
<span id="S4.T1.8.8.8.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">RUBi (ours)</span>
<span id="S4.T1.8.8.8.6" class="ltx_td ltx_border_bb"></span>
<span id="S4.T1.5.5.5.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.5.5.5.1.1" class="ltx_text ltx_font_bold">47.11</span> <math id="S4.T1.5.5.5.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.5.5.5.1.m1.1a"><mo id="S4.T1.5.5.5.1.m1.1.1" xref="S4.T1.5.5.5.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.5.5.5.1.m1.1b"><csymbol cd="latexml" id="S4.T1.5.5.5.1.m1.1.1.cmml" xref="S4.T1.5.5.5.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.5.5.1.m1.1c">\pm</annotation></semantics></math> 0.51</span>
<span id="S4.T1.6.6.6.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.6.6.6.2.1" class="ltx_text ltx_font_bold">68.65</span> <math id="S4.T1.6.6.6.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.6.6.6.2.m1.1a"><mo id="S4.T1.6.6.6.2.m1.1.1" xref="S4.T1.6.6.6.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.6.6.6.2.m1.1b"><csymbol cd="latexml" id="S4.T1.6.6.6.2.m1.1.1.cmml" xref="S4.T1.6.6.6.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.6.6.2.m1.1c">\pm</annotation></semantics></math> 1.16</span>
<span id="S4.T1.7.7.7.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.7.7.7.3.1" class="ltx_text ltx_font_bold">20.28</span> <math id="S4.T1.7.7.7.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.7.7.7.3.m1.1a"><mo id="S4.T1.7.7.7.3.m1.1.1" xref="S4.T1.7.7.7.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.7.7.7.3.m1.1b"><csymbol cd="latexml" id="S4.T1.7.7.7.3.m1.1.1.cmml" xref="S4.T1.7.7.7.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.7.7.3.m1.1c">\pm</annotation></semantics></math> 0.90</span>
<span id="S4.T1.8.8.8.4" class="ltx_td ltx_align_center ltx_border_bb">43.18 <math id="S4.T1.8.8.8.4.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T1.8.8.8.4.m1.1a"><mo id="S4.T1.8.8.8.4.m1.1.1" xref="S4.T1.8.8.8.4.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S4.T1.8.8.8.4.m1.1b"><csymbol cd="latexml" id="S4.T1.8.8.8.4.m1.1.1.cmml" xref="S4.T1.8.8.8.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.8.8.8.4.m1.1c">\pm</annotation></semantics></math> 0.43</span></span>
</span>
</span></p>
</figure>
</section>
<section id="S4.SS1.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Architecture agnostic</h4>

<div id="S4.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px3.p1.1" class="ltx_p">RUBi can be used on existing VQA models without changing the underlying architecture. In TableÂ <a href="#S4.T3" title="Table 3 â€£ Architecture agnostic â€£ 4.1 Results â€£ 4 Experiments â€£ RUBi: Reducing Unimodal Biases for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we experimentally demonstrate the generality and effectiveness of our learning scheme by showing results on two additional architectures, Stacked Attention Networks (SAN) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> and Bottom-Up and Top-Down Attention (UpDn) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.
First, we show that applying RUBi on these architectures leads to important gains over the baselines trained with their original learning strategy.
We report a gain of +11.73 accuracy point for SAN and +4.5 for UpDn. This lower gap in accuracy may show that UpDn is less driven by biases than SAN. This is consistent with results from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>.
Secondly, we show that these architectures trained with RUBi obtain better accuracy than with the state-of-the-art strategy from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. We report a gain of +3.4 with SAN + RUBi over SAN + Q-Adv + DoE, and +3.06 with UpDn + RUBi over UpDn + Q-Adv + DoE. Full results splitted by question type are available in the supplementary materials.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.T3.fig1" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" style="width:238.5pt;">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.T3.fig1.2.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S4.T3.fig1.3.2" class="ltx_text" style="font-size:90%;">Effectiveness of the RUBi learning strategy when used on different architectures on VQA-CP v2 <span id="S4.T3.fig1.3.2.1" class="ltx_text ltx_font_typewriter">test</span>. Detailed results can be found in the supplementary materials.</span></figcaption>
<table id="S4.T3.fig1.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T3.fig1.4.1.1" class="ltx_tr">
<td id="S4.T3.fig1.4.1.1.1" class="ltx_td ltx_align_center" style="padding:0.55pt 3.0pt;">
<table id="S4.T3.fig1.4.1.1.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.fig1.4.1.1.1.1.1" class="ltx_tr">
<td id="S4.T3.fig1.4.1.1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_tt" style="padding:0.55pt 3.0pt;">SAN</td>
<td id="S4.T3.fig1.4.1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding:0.55pt 3.0pt;">Overall</td>
</tr>
<tr id="S4.T3.fig1.4.1.1.1.1.2" class="ltx_tr">
<td id="S4.T3.fig1.4.1.1.1.1.2.1" class="ltx_td ltx_align_left ltx_border_t" style="padding:0.55pt 3.0pt;">Baseline <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>
</td>
<td id="S4.T3.fig1.4.1.1.1.1.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.55pt 3.0pt;">24.96</td>
</tr>
<tr id="S4.T3.fig1.4.1.1.1.1.3" class="ltx_tr">
<td id="S4.T3.fig1.4.1.1.1.1.3.1" class="ltx_td ltx_align_left" style="padding:0.55pt 3.0pt;">+ Q-Adv + DoE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>
</td>
<td id="S4.T3.fig1.4.1.1.1.1.3.2" class="ltx_td ltx_align_center" style="padding:0.55pt 3.0pt;">33.29</td>
</tr>
<tr id="S4.T3.fig1.4.1.1.1.1.4" class="ltx_tr">
<td id="S4.T3.fig1.4.1.1.1.1.4.1" class="ltx_td ltx_align_left ltx_border_bb" style="padding:0.55pt 3.0pt;">+ RUBi (ours)</td>
<td id="S4.T3.fig1.4.1.1.1.1.4.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.55pt 3.0pt;">37.63</td>
</tr>
</table>

<table id="S4.T3.fig1.4.1.1.1.2" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.fig1.4.1.1.1.2.1" class="ltx_tr">
<td id="S4.T3.fig1.4.1.1.1.2.1.1" class="ltx_td ltx_align_left ltx_border_tt" style="padding:0.55pt 3.0pt;">UpDn</td>
<td id="S4.T3.fig1.4.1.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding:0.55pt 3.0pt;">Overall</td>
</tr>
<tr id="S4.T3.fig1.4.1.1.1.2.2" class="ltx_tr">
<td id="S4.T3.fig1.4.1.1.1.2.2.1" class="ltx_td ltx_align_left ltx_border_t" style="padding:0.55pt 3.0pt;">Baseline <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>
</td>
<td id="S4.T3.fig1.4.1.1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.55pt 3.0pt;">39.74</td>
</tr>
<tr id="S4.T3.fig1.4.1.1.1.2.3" class="ltx_tr">
<td id="S4.T3.fig1.4.1.1.1.2.3.1" class="ltx_td ltx_align_left" style="padding:0.55pt 3.0pt;">+ Q-Adv + DoE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>
</td>
<td id="S4.T3.fig1.4.1.1.1.2.3.2" class="ltx_td ltx_align_center" style="padding:0.55pt 3.0pt;">41.17</td>
</tr>
<tr id="S4.T3.fig1.4.1.1.1.2.4" class="ltx_tr">
<td id="S4.T3.fig1.4.1.1.1.2.4.1" class="ltx_td ltx_align_left ltx_border_bb" style="padding:0.55pt 3.0pt;">+ RUBi (ours)</td>
<td id="S4.T3.fig1.4.1.1.1.2.4.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.55pt 3.0pt;"><span id="S4.T3.fig1.4.1.1.1.2.4.2.1" class="ltx_text ltx_font_bold">44.23</span></td>
</tr>
</table>
</td>
</tr>
</tbody>
</table>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.T3.fig2" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" style="width:151.8pt;">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.T3.fig2.3.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S4.T3.fig2.4.2" class="ltx_text" style="font-size:90%;">Overall accuracy of the RUBi learning strategy on VQA v2 <span id="S4.T3.fig2.4.2.1" class="ltx_text ltx_font_typewriter">val</span> and <span id="S4.T3.fig2.4.2.2" class="ltx_text ltx_font_typewriter">test-dev</span> splits.</span></figcaption>
<p id="S4.T3.fig2.5" class="ltx_p">.



<span id="S4.T3.fig2.5.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<span class="ltx_thead">
<span id="S4.T3.fig2.5.1.1.1" class="ltx_tr">
<span id="S4.T3.fig2.5.1.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" style="padding-left:1.5pt;padding-right:1.5pt;">Model</span>
<span id="S4.T3.fig2.5.1.1.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="S4.T3.fig2.5.1.1.1.2.1" class="ltx_text ltx_font_typewriter">val</span></span>
<span id="S4.T3.fig2.5.1.1.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="S4.T3.fig2.5.1.1.1.3.1" class="ltx_text ltx_font_typewriter">test-dev</span></span></span>
</span>
<span class="ltx_tbody">
<span id="S4.T3.fig2.5.1.2.1" class="ltx_tr">
<span id="S4.T3.fig2.5.1.2.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;">Baseline (ours)</span>
<span id="S4.T3.fig2.5.1.2.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="S4.T3.fig2.5.1.2.1.2.1" class="ltx_text ltx_font_bold">63.10</span></span>
<span id="S4.T3.fig2.5.1.2.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.5pt;padding-right:1.5pt;"><span id="S4.T3.fig2.5.1.2.1.3.1" class="ltx_text ltx_font_bold">64.75</span></span></span>
<span id="S4.T3.fig2.5.1.3.2" class="ltx_tr">
<span id="S4.T3.fig2.5.1.3.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_bb" style="padding-left:1.5pt;padding-right:1.5pt;">RUBi (ours)</span>
<span id="S4.T3.fig2.5.1.3.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:1.5pt;padding-right:1.5pt;">61.16</span>
<span id="S4.T3.fig2.5.1.3.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:1.5pt;padding-right:1.5pt;">63.18</span></span>
</span>
</span></p>
</figure>
</div>
</div>
</figure>
</section>
<section id="S4.SS1.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Impact on VQA v2</h4>

<div id="S4.SS1.SSS0.Px4.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px4.p1.1" class="ltx_p">We report the impact of our method on the standard VQA v2 dataset in TableÂ <a href="#S4.T3" title="Table 3 â€£ Architecture agnostic â€£ 4.1 Results â€£ 4 Experiments â€£ RUBi: Reducing Unimodal Biases for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. VQA v2 train, val and test sets follow the same distribution, contrarily to VQA-CP v2 train and test sets.
In this context, we usually observe a drop in accuracy using approaches focused on reducing biases. This is due to the fact that exploiting unwanted correlations from the VQA v2 train set is not discouraged and often leads to a higher accuracy on the test set.
Nevertheless, our RUBi approach leads to a comparable drop to what can be seen in the state-of-the-art.
We report a drop of 1.94 percentage points with respect to our baseline, while <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> report a drop of 3.78 between GVQA and their SAN baseline. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> report drops of 0.05, 0.73 and 2.95 for their three learning strategies with the UpDn architecture which uses the same visual features as RUBi.
As shown in this section, RUBi improves the accuracy on VQA-CP v2 from a large margin, while maintaining competitive performance on the standard VQA v2 dataset compared to similar approaches.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px5" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Validation of the masking strategy</h4>

<div id="S4.SS1.SSS0.Px5.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px5.p1.1" class="ltx_p">We compare different fusion techniques to combine the output of <math id="S4.SS1.SSS0.Px5.p1.1.m1.1" class="ltx_Math" alttext="\mathit{nn}_{q}" display="inline"><semantics id="S4.SS1.SSS0.Px5.p1.1.m1.1a"><msub id="S4.SS1.SSS0.Px5.p1.1.m1.1.1" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1.cmml"><mi id="S4.SS1.SSS0.Px5.p1.1.m1.1.1.2" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1.2.cmml">ğ‘›ğ‘›</mi><mi id="S4.SS1.SSS0.Px5.p1.1.m1.1.1.3" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px5.p1.1.m1.1b"><apply id="S4.SS1.SSS0.Px5.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px5.p1.1.m1.1.1.1.cmml" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.SSS0.Px5.p1.1.m1.1.1.2.cmml" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1.2">ğ‘›ğ‘›</ci><ci id="S4.SS1.SSS0.Px5.p1.1.m1.1.1.3.cmml" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px5.p1.1.m1.1c">\mathit{nn}_{q}</annotation></semantics></math> with the output from the VQA model. We report a drop of 7.09 accuracy point on VQA-CP v2 by replacing the sigmoid with a ReLU on our best scoring model. Using an element-wise sum instead of an element-wise product leads to a further performance drop.
These results confirm the effectiveness of our proposed masking method which relies on a sigmoid and an element-wise sum.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px6" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Validation of the question-only loss</h4>

<div id="S4.SS1.SSS0.Px6.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px6.p1.6" class="ltx_p">In TableÂ <a href="#S4.T4" title="Table 4 â€£ Validation of the question-only loss â€£ 4.1 Results â€£ 4 Experiments â€£ RUBi: Reducing Unimodal Biases for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we validate the ability of the question-only loss <math id="S4.SS1.SSS0.Px6.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{QO}" display="inline"><semantics id="S4.SS1.SSS0.Px6.p1.1.m1.1a"><msub id="S4.SS1.SSS0.Px6.p1.1.m1.1.1" xref="S4.SS1.SSS0.Px6.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS0.Px6.p1.1.m1.1.1.2" xref="S4.SS1.SSS0.Px6.p1.1.m1.1.1.2.cmml">â„’</mi><mrow id="S4.SS1.SSS0.Px6.p1.1.m1.1.1.3" xref="S4.SS1.SSS0.Px6.p1.1.m1.1.1.3.cmml"><mi id="S4.SS1.SSS0.Px6.p1.1.m1.1.1.3.2" xref="S4.SS1.SSS0.Px6.p1.1.m1.1.1.3.2.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS0.Px6.p1.1.m1.1.1.3.1" xref="S4.SS1.SSS0.Px6.p1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS1.SSS0.Px6.p1.1.m1.1.1.3.3" xref="S4.SS1.SSS0.Px6.p1.1.m1.1.1.3.3.cmml">O</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px6.p1.1.m1.1b"><apply id="S4.SS1.SSS0.Px6.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px6.p1.1.m1.1.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.SSS0.Px6.p1.1.m1.1.1.2.cmml" xref="S4.SS1.SSS0.Px6.p1.1.m1.1.1.2">â„’</ci><apply id="S4.SS1.SSS0.Px6.p1.1.m1.1.1.3.cmml" xref="S4.SS1.SSS0.Px6.p1.1.m1.1.1.3"><times id="S4.SS1.SSS0.Px6.p1.1.m1.1.1.3.1.cmml" xref="S4.SS1.SSS0.Px6.p1.1.m1.1.1.3.1"></times><ci id="S4.SS1.SSS0.Px6.p1.1.m1.1.1.3.2.cmml" xref="S4.SS1.SSS0.Px6.p1.1.m1.1.1.3.2">ğ‘„</ci><ci id="S4.SS1.SSS0.Px6.p1.1.m1.1.1.3.3.cmml" xref="S4.SS1.SSS0.Px6.p1.1.m1.1.1.3.3">ğ‘‚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px6.p1.1.m1.1c">\mathcal{L}_{QO}</annotation></semantics></math> to reduce the question biases. The absence of <math id="S4.SS1.SSS0.Px6.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{L}_{QO}" display="inline"><semantics id="S4.SS1.SSS0.Px6.p1.2.m2.1a"><msub id="S4.SS1.SSS0.Px6.p1.2.m2.1.1" xref="S4.SS1.SSS0.Px6.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS0.Px6.p1.2.m2.1.1.2" xref="S4.SS1.SSS0.Px6.p1.2.m2.1.1.2.cmml">â„’</mi><mrow id="S4.SS1.SSS0.Px6.p1.2.m2.1.1.3" xref="S4.SS1.SSS0.Px6.p1.2.m2.1.1.3.cmml"><mi id="S4.SS1.SSS0.Px6.p1.2.m2.1.1.3.2" xref="S4.SS1.SSS0.Px6.p1.2.m2.1.1.3.2.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS0.Px6.p1.2.m2.1.1.3.1" xref="S4.SS1.SSS0.Px6.p1.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS1.SSS0.Px6.p1.2.m2.1.1.3.3" xref="S4.SS1.SSS0.Px6.p1.2.m2.1.1.3.3.cmml">O</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px6.p1.2.m2.1b"><apply id="S4.SS1.SSS0.Px6.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px6.p1.2.m2.1.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS1.SSS0.Px6.p1.2.m2.1.1.2.cmml" xref="S4.SS1.SSS0.Px6.p1.2.m2.1.1.2">â„’</ci><apply id="S4.SS1.SSS0.Px6.p1.2.m2.1.1.3.cmml" xref="S4.SS1.SSS0.Px6.p1.2.m2.1.1.3"><times id="S4.SS1.SSS0.Px6.p1.2.m2.1.1.3.1.cmml" xref="S4.SS1.SSS0.Px6.p1.2.m2.1.1.3.1"></times><ci id="S4.SS1.SSS0.Px6.p1.2.m2.1.1.3.2.cmml" xref="S4.SS1.SSS0.Px6.p1.2.m2.1.1.3.2">ğ‘„</ci><ci id="S4.SS1.SSS0.Px6.p1.2.m2.1.1.3.3.cmml" xref="S4.SS1.SSS0.Px6.p1.2.m2.1.1.3.3">ğ‘‚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px6.p1.2.m2.1c">\mathcal{L}_{QO}</annotation></semantics></math> implies that the question-only classifier <math id="S4.SS1.SSS0.Px6.p1.3.m3.1" class="ltx_Math" alttext="c_{q}" display="inline"><semantics id="S4.SS1.SSS0.Px6.p1.3.m3.1a"><msub id="S4.SS1.SSS0.Px6.p1.3.m3.1.1" xref="S4.SS1.SSS0.Px6.p1.3.m3.1.1.cmml"><mi id="S4.SS1.SSS0.Px6.p1.3.m3.1.1.2" xref="S4.SS1.SSS0.Px6.p1.3.m3.1.1.2.cmml">c</mi><mi id="S4.SS1.SSS0.Px6.p1.3.m3.1.1.3" xref="S4.SS1.SSS0.Px6.p1.3.m3.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px6.p1.3.m3.1b"><apply id="S4.SS1.SSS0.Px6.p1.3.m3.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px6.p1.3.m3.1.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.SSS0.Px6.p1.3.m3.1.1.2.cmml" xref="S4.SS1.SSS0.Px6.p1.3.m3.1.1.2">ğ‘</ci><ci id="S4.SS1.SSS0.Px6.p1.3.m3.1.1.3.cmml" xref="S4.SS1.SSS0.Px6.p1.3.m3.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px6.p1.3.m3.1c">c_{q}</annotation></semantics></math> is never used, and <math id="S4.SS1.SSS0.Px6.p1.4.m4.1" class="ltx_Math" alttext="\mathit{nn}_{q}" display="inline"><semantics id="S4.SS1.SSS0.Px6.p1.4.m4.1a"><msub id="S4.SS1.SSS0.Px6.p1.4.m4.1.1" xref="S4.SS1.SSS0.Px6.p1.4.m4.1.1.cmml"><mi id="S4.SS1.SSS0.Px6.p1.4.m4.1.1.2" xref="S4.SS1.SSS0.Px6.p1.4.m4.1.1.2.cmml">ğ‘›ğ‘›</mi><mi id="S4.SS1.SSS0.Px6.p1.4.m4.1.1.3" xref="S4.SS1.SSS0.Px6.p1.4.m4.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px6.p1.4.m4.1b"><apply id="S4.SS1.SSS0.Px6.p1.4.m4.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px6.p1.4.m4.1.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.4.m4.1.1">subscript</csymbol><ci id="S4.SS1.SSS0.Px6.p1.4.m4.1.1.2.cmml" xref="S4.SS1.SSS0.Px6.p1.4.m4.1.1.2">ğ‘›ğ‘›</ci><ci id="S4.SS1.SSS0.Px6.p1.4.m4.1.1.3.cmml" xref="S4.SS1.SSS0.Px6.p1.4.m4.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px6.p1.4.m4.1c">\mathit{nn}_{q}</annotation></semantics></math> only receives gradients from the main loss <math id="S4.SS1.SSS0.Px6.p1.5.m5.1" class="ltx_Math" alttext="\mathcal{L}_{QM}" display="inline"><semantics id="S4.SS1.SSS0.Px6.p1.5.m5.1a"><msub id="S4.SS1.SSS0.Px6.p1.5.m5.1.1" xref="S4.SS1.SSS0.Px6.p1.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS0.Px6.p1.5.m5.1.1.2" xref="S4.SS1.SSS0.Px6.p1.5.m5.1.1.2.cmml">â„’</mi><mrow id="S4.SS1.SSS0.Px6.p1.5.m5.1.1.3" xref="S4.SS1.SSS0.Px6.p1.5.m5.1.1.3.cmml"><mi id="S4.SS1.SSS0.Px6.p1.5.m5.1.1.3.2" xref="S4.SS1.SSS0.Px6.p1.5.m5.1.1.3.2.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS0.Px6.p1.5.m5.1.1.3.1" xref="S4.SS1.SSS0.Px6.p1.5.m5.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS1.SSS0.Px6.p1.5.m5.1.1.3.3" xref="S4.SS1.SSS0.Px6.p1.5.m5.1.1.3.3.cmml">M</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px6.p1.5.m5.1b"><apply id="S4.SS1.SSS0.Px6.p1.5.m5.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px6.p1.5.m5.1.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.5.m5.1.1">subscript</csymbol><ci id="S4.SS1.SSS0.Px6.p1.5.m5.1.1.2.cmml" xref="S4.SS1.SSS0.Px6.p1.5.m5.1.1.2">â„’</ci><apply id="S4.SS1.SSS0.Px6.p1.5.m5.1.1.3.cmml" xref="S4.SS1.SSS0.Px6.p1.5.m5.1.1.3"><times id="S4.SS1.SSS0.Px6.p1.5.m5.1.1.3.1.cmml" xref="S4.SS1.SSS0.Px6.p1.5.m5.1.1.3.1"></times><ci id="S4.SS1.SSS0.Px6.p1.5.m5.1.1.3.2.cmml" xref="S4.SS1.SSS0.Px6.p1.5.m5.1.1.3.2">ğ‘„</ci><ci id="S4.SS1.SSS0.Px6.p1.5.m5.1.1.3.3.cmml" xref="S4.SS1.SSS0.Px6.p1.5.m5.1.1.3.3">ğ‘€</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px6.p1.5.m5.1c">\mathcal{L}_{QM}</annotation></semantics></math>. Using <math id="S4.SS1.SSS0.Px6.p1.6.m6.1" class="ltx_Math" alttext="\mathcal{L}_{QO}" display="inline"><semantics id="S4.SS1.SSS0.Px6.p1.6.m6.1a"><msub id="S4.SS1.SSS0.Px6.p1.6.m6.1.1" xref="S4.SS1.SSS0.Px6.p1.6.m6.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS0.Px6.p1.6.m6.1.1.2" xref="S4.SS1.SSS0.Px6.p1.6.m6.1.1.2.cmml">â„’</mi><mrow id="S4.SS1.SSS0.Px6.p1.6.m6.1.1.3" xref="S4.SS1.SSS0.Px6.p1.6.m6.1.1.3.cmml"><mi id="S4.SS1.SSS0.Px6.p1.6.m6.1.1.3.2" xref="S4.SS1.SSS0.Px6.p1.6.m6.1.1.3.2.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS0.Px6.p1.6.m6.1.1.3.1" xref="S4.SS1.SSS0.Px6.p1.6.m6.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS1.SSS0.Px6.p1.6.m6.1.1.3.3" xref="S4.SS1.SSS0.Px6.p1.6.m6.1.1.3.3.cmml">O</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px6.p1.6.m6.1b"><apply id="S4.SS1.SSS0.Px6.p1.6.m6.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px6.p1.6.m6.1.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.6.m6.1.1">subscript</csymbol><ci id="S4.SS1.SSS0.Px6.p1.6.m6.1.1.2.cmml" xref="S4.SS1.SSS0.Px6.p1.6.m6.1.1.2">â„’</ci><apply id="S4.SS1.SSS0.Px6.p1.6.m6.1.1.3.cmml" xref="S4.SS1.SSS0.Px6.p1.6.m6.1.1.3"><times id="S4.SS1.SSS0.Px6.p1.6.m6.1.1.3.1.cmml" xref="S4.SS1.SSS0.Px6.p1.6.m6.1.1.3.1"></times><ci id="S4.SS1.SSS0.Px6.p1.6.m6.1.1.3.2.cmml" xref="S4.SS1.SSS0.Px6.p1.6.m6.1.1.3.2">ğ‘„</ci><ci id="S4.SS1.SSS0.Px6.p1.6.m6.1.1.3.3.cmml" xref="S4.SS1.SSS0.Px6.p1.6.m6.1.1.3.3">ğ‘‚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px6.p1.6.m6.1c">\mathcal{L}_{QO}</annotation></semantics></math> leads to consistent gains on all three architectures. We report a gain of +0.89 for our Baseline architecture, +0.22 for SAN, +4.76 for UpDn.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<table id="S4.T4.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.1.1" class="ltx_tr">
<th id="S4.T4.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Model</th>
<th id="S4.T4.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><math id="S4.T4.1.1.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{QO}" display="inline"><semantics id="S4.T4.1.1.1.m1.1a"><msub id="S4.T4.1.1.1.m1.1.1" xref="S4.T4.1.1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.T4.1.1.1.m1.1.1.2" xref="S4.T4.1.1.1.m1.1.1.2.cmml">â„’</mi><mrow id="S4.T4.1.1.1.m1.1.1.3" xref="S4.T4.1.1.1.m1.1.1.3.cmml"><mi id="S4.T4.1.1.1.m1.1.1.3.2" xref="S4.T4.1.1.1.m1.1.1.3.2.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S4.T4.1.1.1.m1.1.1.3.1" xref="S4.T4.1.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.T4.1.1.1.m1.1.1.3.3" xref="S4.T4.1.1.1.m1.1.1.3.3.cmml">O</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.m1.1b"><apply id="S4.T4.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T4.1.1.1.m1.1.1.1.cmml" xref="S4.T4.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T4.1.1.1.m1.1.1.2.cmml" xref="S4.T4.1.1.1.m1.1.1.2">â„’</ci><apply id="S4.T4.1.1.1.m1.1.1.3.cmml" xref="S4.T4.1.1.1.m1.1.1.3"><times id="S4.T4.1.1.1.m1.1.1.3.1.cmml" xref="S4.T4.1.1.1.m1.1.1.3.1"></times><ci id="S4.T4.1.1.1.m1.1.1.3.2.cmml" xref="S4.T4.1.1.1.m1.1.1.3.2">ğ‘„</ci><ci id="S4.T4.1.1.1.m1.1.1.3.3.cmml" xref="S4.T4.1.1.1.m1.1.1.3.3">ğ‘‚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.m1.1c">\mathcal{L}_{QO}</annotation></semantics></math></th>
<th id="S4.T4.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Overall</th>
<th id="S4.T4.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Yes/No</th>
<th id="S4.T4.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Number</th>
<th id="S4.T4.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Other</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.1.2.1" class="ltx_tr">
<th id="S4.T4.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="S4.T4.1.2.1.1.1" class="ltx_text">Baseline + RUBi</span></th>
<td id="S4.T4.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">âœ“</td>
<td id="S4.T4.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.1.2.1.3.1" class="ltx_text ltx_font_bold">47.11</span></td>
<td id="S4.T4.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">68.65</td>
<td id="S4.T4.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t">20.28</td>
<td id="S4.T4.1.2.1.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.1.2.1.6.1" class="ltx_text ltx_font_bold">43.18</span></td>
</tr>
<tr id="S4.T4.1.3.2" class="ltx_tr">
<td id="S4.T4.1.3.2.1" class="ltx_td ltx_align_center">âœ—</td>
<td id="S4.T4.1.3.2.2" class="ltx_td ltx_align_center">46.11</td>
<td id="S4.T4.1.3.2.3" class="ltx_td ltx_align_center"><span id="S4.T4.1.3.2.3.1" class="ltx_text ltx_font_bold">69.18</span></td>
<td id="S4.T4.1.3.2.4" class="ltx_td ltx_align_center"><span id="S4.T4.1.3.2.4.1" class="ltx_text ltx_font_bold">26.85</span></td>
<td id="S4.T4.1.3.2.5" class="ltx_td ltx_align_center">39.31</td>
</tr>
<tr id="S4.T4.1.4.3" class="ltx_tr">
<th id="S4.T4.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="S4.T4.1.4.3.1.1" class="ltx_text">SAN + RUBi</span></th>
<td id="S4.T4.1.4.3.2" class="ltx_td ltx_align_center ltx_border_t">âœ“</td>
<td id="S4.T4.1.4.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.1.4.3.3.1" class="ltx_text ltx_font_bold">37.63</span></td>
<td id="S4.T4.1.4.3.4" class="ltx_td ltx_align_center ltx_border_t">59.49</td>
<td id="S4.T4.1.4.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.1.4.3.5.1" class="ltx_text ltx_font_bold">13.71</span></td>
<td id="S4.T4.1.4.3.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.1.4.3.6.1" class="ltx_text ltx_font_bold">32.74</span></td>
</tr>
<tr id="S4.T4.1.5.4" class="ltx_tr">
<td id="S4.T4.1.5.4.1" class="ltx_td ltx_align_center">âœ—</td>
<td id="S4.T4.1.5.4.2" class="ltx_td ltx_align_center">36.96</td>
<td id="S4.T4.1.5.4.3" class="ltx_td ltx_align_center">
<span id="S4.T4.1.5.4.3.1" class="ltx_text ltx_font_bold">59.7</span>8</td>
<td id="S4.T4.1.5.4.4" class="ltx_td ltx_align_center">12.55</td>
<td id="S4.T4.1.5.4.5" class="ltx_td ltx_align_center">31.69</td>
</tr>
<tr id="S4.T4.1.6.5" class="ltx_tr">
<th id="S4.T4.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" rowspan="2"><span id="S4.T4.1.6.5.1.1" class="ltx_text">UpDn + RUBi</span></th>
<td id="S4.T4.1.6.5.2" class="ltx_td ltx_align_center ltx_border_t">âœ“</td>
<td id="S4.T4.1.6.5.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.1.6.5.3.1" class="ltx_text ltx_font_bold">44.23</span></td>
<td id="S4.T4.1.6.5.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.1.6.5.4.1" class="ltx_text ltx_font_bold">67.05</span></td>
<td id="S4.T4.1.6.5.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.1.6.5.5.1" class="ltx_text ltx_font_bold">17.48</span></td>
<td id="S4.T4.1.6.5.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.1.6.5.6.1" class="ltx_text ltx_font_bold">39.61</span></td>
</tr>
<tr id="S4.T4.1.7.6" class="ltx_tr">
<td id="S4.T4.1.7.6.1" class="ltx_td ltx_align_center ltx_border_bb">âœ—</td>
<td id="S4.T4.1.7.6.2" class="ltx_td ltx_align_center ltx_border_bb">39.47</td>
<td id="S4.T4.1.7.6.3" class="ltx_td ltx_align_center ltx_border_bb">60.27</td>
<td id="S4.T4.1.7.6.4" class="ltx_td ltx_align_center ltx_border_bb">16.01</td>
<td id="S4.T4.1.7.6.5" class="ltx_td ltx_align_center ltx_border_bb">35.01</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.5.2.1" class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span id="S4.T4.3.1" class="ltx_text" style="font-size:90%;">Ablation study of the question-only loss <math id="S4.T4.3.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{QO}" display="inline"><semantics id="S4.T4.3.1.m1.1b"><msub id="S4.T4.3.1.m1.1.1" xref="S4.T4.3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.T4.3.1.m1.1.1.2" xref="S4.T4.3.1.m1.1.1.2.cmml">â„’</mi><mrow id="S4.T4.3.1.m1.1.1.3" xref="S4.T4.3.1.m1.1.1.3.cmml"><mi id="S4.T4.3.1.m1.1.1.3.2" xref="S4.T4.3.1.m1.1.1.3.2.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S4.T4.3.1.m1.1.1.3.1" xref="S4.T4.3.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.T4.3.1.m1.1.1.3.3" xref="S4.T4.3.1.m1.1.1.3.3.cmml">O</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T4.3.1.m1.1c"><apply id="S4.T4.3.1.m1.1.1.cmml" xref="S4.T4.3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T4.3.1.m1.1.1.1.cmml" xref="S4.T4.3.1.m1.1.1">subscript</csymbol><ci id="S4.T4.3.1.m1.1.1.2.cmml" xref="S4.T4.3.1.m1.1.1.2">â„’</ci><apply id="S4.T4.3.1.m1.1.1.3.cmml" xref="S4.T4.3.1.m1.1.1.3"><times id="S4.T4.3.1.m1.1.1.3.1.cmml" xref="S4.T4.3.1.m1.1.1.3.1"></times><ci id="S4.T4.3.1.m1.1.1.3.2.cmml" xref="S4.T4.3.1.m1.1.1.3.2">ğ‘„</ci><ci id="S4.T4.3.1.m1.1.1.3.3.cmml" xref="S4.T4.3.1.m1.1.1.3.3">ğ‘‚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.1.m1.1d">\mathcal{L}_{QO}</annotation></semantics></math> on VQA-CP v2.</span></figcaption>
</figure>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Qualitative analysis</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">To better understand the impact of our RUBi approach, we compare in FigureÂ <a href="#S4.F4" title="Figure 4 â€£ 4.2 Qualitative analysis â€£ 4 Experiments â€£ RUBi: Reducing Unimodal Biases for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> the answer distribution on VQA-CP v2 for some specific question patterns. We also display interesting behaviors on some examples using attention maps extracted as in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>.
In the first row, we show the ability of RUBi to reduce biases for the <span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_italic">is this person skiing</span> question pattern. Most examples in the train set have the answer <span id="S4.SS2.p1.1.2" class="ltx_text ltx_font_italic">yes</span>, while in the test set, they have the answer <span id="S4.SS2.p1.1.3" class="ltx_text ltx_font_italic">no</span>. Nevertheless, RUBi outputs 80% of <span id="S4.SS2.p1.1.4" class="ltx_text ltx_font_italic">no</span>, while the baseline almost always outputs <span id="S4.SS2.p1.1.5" class="ltx_text ltx_font_italic">yes</span>. Interestingly, the best scoring region from the attention map of both models is localized on the shoes. To get the answer right, RUBi seems to reason about the absence of skis in this region. It seems that our baseline gets it wrong by not seeing that the skis are not locked under the ski boots. This unwanted behavior could be due to the question biases.
In the second row, similar behaviors occur for the <span id="S4.SS2.p1.1.6" class="ltx_text ltx_font_italic">what color are the bananas</span> question pattern. 80% of the answers from the train set are <span id="S4.SS2.p1.1.7" class="ltx_text ltx_font_italic">yellow</span>, while most of them are <span id="S4.SS2.p1.1.8" class="ltx_text ltx_font_italic">green</span> in the test set. We show that the amount of <span id="S4.SS2.p1.1.9" class="ltx_text ltx_font_italic">green</span> and <span id="S4.SS2.p1.1.10" class="ltx_text ltx_font_italic">white</span> answers from RUBi are much closer to the ones from the test set than with our baseline. In the example, it seems that RUBi relies on the color of the banana, while our baseline misses it.
In the third row, it seems that RUBi is able to ground the textual concepts such as <span id="S4.SS2.p1.1.11" class="ltx_text ltx_font_italic">top part of the fire hydrant</span> and <span id="S4.SS2.p1.1.12" class="ltx_text ltx_font_italic">color</span> on the right visual region, while the baseline relies on the correlations between the fire hydrant, the yellow color of its core and the answer <span id="S4.SS2.p1.1.13" class="ltx_text ltx_font_italic">yellow</span>.
Similarly on the fourth row, RUBi grounds <span id="S4.SS2.p1.1.14" class="ltx_text ltx_font_italic">color</span>, <span id="S4.SS2.p1.1.15" class="ltx_text ltx_font_italic">star</span>, <span id="S4.SS2.p1.1.16" class="ltx_text ltx_font_italic">fire hydrant</span> on the right region, while our baseline relies on correlations between <span id="S4.SS2.p1.1.17" class="ltx_text ltx_font_italic">color</span>, <span id="S4.SS2.p1.1.18" class="ltx_text ltx_font_italic">fire hydrant</span>, the yellow color of the top part region and the answer <span id="S4.SS2.p1.1.19" class="ltx_text ltx_font_italic">yellow</span>. Interestingly, there is no similar question that involves the color of a star on a fire hydrant in the training set. It shows the capacity of RUBi to generalize to unseen examples by composing and grounding existing visual and textual concepts from other kinds of question patterns.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/1906.10169/assets/images/qualitative-blur.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="499" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.7.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S4.F4.8.2" class="ltx_text" style="font-size:90%;"> Qualitative comparison between the outputs of RUBi and our baseline on VQA-CP v2 <span id="S4.F4.8.2.1" class="ltx_text ltx_font_typewriter">test</span>.
On the left, we display distributions of answers for the train set, the baseline evaluated on the test set, RUBi on the test set and the ground truth answers from the test set. For each row, we filter questions in a certain way. In the first row, we keep the questions that exactly match the string <span id="S4.F4.8.2.2" class="ltx_text ltx_font_italic">is this person skiing</span>. In the three other rows, we filter questions that respectively include the following words: <span id="S4.F4.8.2.3" class="ltx_text ltx_font_italic">what color bananas</span>, <span id="S4.F4.8.2.4" class="ltx_text ltx_font_italic">what color fire hydrant</span> and <span id="S4.F4.8.2.5" class="ltx_text ltx_font_italic">what color star hydrant</span>.
On the right, we display examples that contains the pattern from the left. For each example, we display the answer of our baseline and RUBi, as well as the best scoring region from their attention map.</span></figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We propose RUBi to reduce unimodal biases learned by Visual Question Answering (VQA) models. RUBi is a simple learning strategy designed to be model agnostic. It is based on a question-only branch that captures unwanted statistical regularities from the question modality. This branch influences the base VQA model to prevent the learning of unimodal biases from the question.
We demonstrate a significant gain of +5.94 percentage point in accuracy over the state-of-the-art result on VQA-CP v2, a dataset specifically designed to account for question biases.
We also show that RUBi is effective with different kinds of common VQA models.
In future works, we would like to extend our approach on other multimodal tasks.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">We would like to thank the reviewers for valuable and constructive comments and suggestions. We additionally would like to thank Abhishek Das and Aishwarya Agrawal for their help.</p>
</div>
<div id="Sx1.p2" class="ltx_para">
<p id="Sx1.p2.1" class="ltx_p">The effort from Sorbonne University was partly supported within the Labex SMART supported by French state funds managed by the ANR within the Investissements dâ€™Avenir programme under reference ANR-11-LABX-65, and partly funded by grant DeepVision (ANR-15-CE23-0029-02, STPGP-479356-15), a joint French/Canadian call by ANR &amp; NSERC.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Alex Krizhevsky, Ilya Sutskever, and GeoffreyÂ E Hinton.

</span>
<span class="ltx_bibblock">Imagenet classification with deep convolutional neural networks.

</span>
<span class="ltx_bibblock">In F.Â Pereira, C.Â J.Â C. Burges, L.Â Bottou, and K.Â Q. Weinberger,
editors, <span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems 25</span>, pages
1097â€“1105. Curran Associates, Inc., 2012.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean.

</span>
<span class="ltx_bibblock">Efficient estimation of word representations in vector space.

</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">ICLR</span>, 2013.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Ryan Kiros, Yukun Zhu, RuslanÂ R Salakhutdinov, Richard Zemel, Raquel Urtasun,
Antonio Torralba, and Sanja Fidler.

</span>
<span class="ltx_bibblock">Skip-thought vectors.

</span>
<span class="ltx_bibblock">In <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, pages
3294â€“3302, 2015.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Andrej Karpathy and LiÂ Fei-Fei.

</span>
<span class="ltx_bibblock">Deep visual-semantic alignments for generating image descriptions.

</span>
<span class="ltx_bibblock">In <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</span>, pages 3128â€“3137, 2015.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Cewu Lu, Ranjay Krishna, Michael Bernstein, and LiÂ Fei-Fei.

</span>
<span class="ltx_bibblock">Visual relationship detection with language priors.

</span>
<span class="ltx_bibblock">In <span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">European Conference on Computer Vision</span>, pages 852â€“869.
Springer, 2016.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Abhishek Das, Satwik Kottur, Khushi Gupta, Avi Singh, Deshraj Yadav,
JosÃ©Â M.F. Moura, Devi Parikh, and Dhruv Batra.

</span>
<span class="ltx_bibblock">Visual Dialog.

</span>
<span class="ltx_bibblock">In <span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition (CVPR)</span>, 2017.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Harm deÂ Vries, Florian Strub, Sarath Chandar, Olivier Pietquin, Hugo
Larochelle, and AaronÂ C. Courville.

</span>
<span class="ltx_bibblock">GuessWhat?! Visual object discovery through multi-modal dialogue.

</span>
<span class="ltx_bibblock">In <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">Conference on Computer Vision and Pattern Recognition
(CVPR)</span>, 2017.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra,
C.Â Lawrence Zitnick, and Devi Parikh.

</span>
<span class="ltx_bibblock">VQA: Visual Question Answering.

</span>
<span class="ltx_bibblock">In <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">International Conference on Computer Vision (ICCV)</span>, 2015.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Yash Goyal, Tejas Khot, Douglas Summers-Stay, Dhruv Batra, and Devi Parikh.

</span>
<span class="ltx_bibblock">Making the V in VQA matter: Elevating the role of image
understanding in Visual Question Answering.

</span>
<span class="ltx_bibblock">In <span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition
CVPR</span>, 2017.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Aishwarya Agrawal, Dhruv Batra, Devi Parikh, and Aniruddha Kembhavi.

</span>
<span class="ltx_bibblock">Donâ€™t just assume; look and answer: Overcoming priors for visual
question answering.

</span>
<span class="ltx_bibblock">In <span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</span>, 2018.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Kushal Kafle and Christopher Kanan.

</span>
<span class="ltx_bibblock">An analysis of visual question answering algorithms.

</span>
<span class="ltx_bibblock">In <span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">The IEEE International Conference on Computer Vision (ICCV)</span>,
Oct 2017.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Danna Gurari, Qing Li, AbigaleÂ J Stangl, Anhong Guo, Chi Lin, Kristen Grauman,
Jiebo Luo, and JeffreyÂ P Bigham.

</span>
<span class="ltx_bibblock">Vizwiz grand challenge: Answering visual questions from blind people.

</span>
<span class="ltx_bibblock">In <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span>, pages 3608â€“3617, 2018.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
DrewÂ A Hudson and ChristopherÂ D Manning.

</span>
<span class="ltx_bibblock">Gqa: a new dataset for compositional question answering over
real-world images.

</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1902.09506</span>, 2019.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Rowan Zellers, Yonatan Bisk, Ali Farhadi, and Yejin Choi.

</span>
<span class="ltx_bibblock">From recognition to cognition: Visual commonsense reasoning.

</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">CVPR</span>, 2019.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Peter Anderson, Xiaodong He, Chris Buehler, Damien Teney, Mark Johnson, Stephen
Gould, and Lei Zhang.

</span>
<span class="ltx_bibblock">Bottom-up and top-down attention for image captioning and visual
question answering.

</span>
<span class="ltx_bibblock">In <span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition
CVPR</span>, June 2018.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Remi Cadene, Hedi Ben-Younes, Nicolas Thome, and Matthieu Cord.

</span>
<span class="ltx_bibblock">Murel: Multimodal Relational Reasoning for Visual Question
Answering.

</span>
<span class="ltx_bibblock">In <span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition
CVPR</span>, 2019.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Hedi Ben-Younes, Remi Cadene, Nicolas Thome, and Matthieu Cord.

</span>
<span class="ltx_bibblock">Block: Bilinear superdiagonal fusion for visual question answering
and visual relationship detection.

</span>
<span class="ltx_bibblock">In <span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">Proceedings of the 33st Conference on Artificial Intelligence
(AAAI)</span>, 2019.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Ronghang Hu, Jacob Andreas, Trevor Darrell, and Kate Saenko.

</span>
<span class="ltx_bibblock">Explainable neural computation via stack neural module networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">ECCV</span>, 2018.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Jin-Hwa Kim, Jaehyun Jun, and Byoung-Tak Zhang.

</span>
<span class="ltx_bibblock">Bilinear attention networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, pages
1564â€“1574, 2018.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
JuanziÂ Li JiaxinÂ Shi, HanwangÂ Zhang.

</span>
<span class="ltx_bibblock">Explainable and explicit visual reasoning over scene graphs.

</span>
<span class="ltx_bibblock">In <span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">CVPR</span>, 2019.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Chenfei Wu, Jinlai Liu, Xiaojie Wang, and Xuan Dong.

</span>
<span class="ltx_bibblock">Chain of Reasoning for Visual Question Answering.

</span>
<span class="ltx_bibblock">In S.Â Bengio, H.Â Wallach, H.Â Larochelle, K.Â Grauman, N.Â Cesa-Bianchi,
and R.Â Garnett, editors, <span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing
Systems 31</span>, pages 275â€“285. Curran Associates, Inc., 2018.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Gao Peng, Zhengkai Jiang, Haoxuan You, Zhengkai Jiang, Pan Lu, Steven Hoi,
Xiaogang Wang, and Hongsheng Li.

</span>
<span class="ltx_bibblock">Dynamic Fusion with Intra- and Inter- Modality Attention Flow for
Visual Question Answering.

</span>
<span class="ltx_bibblock">In <span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">CVPR</span>, Dec 2019.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Justin Johnson, Bharath Hariharan, Laurens vanÂ der Maaten, LiÂ Fei-Fei,
C.Â Lawrence Zitnick, and Ross Girshick.

</span>
<span class="ltx_bibblock">CLEVR: A diagnostic dataset for compositional language and
elementary visual reasoning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition
CVPR</span>, 2017.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Aishwarya Agrawal, Dhruv Batra, and Devi Parikh.

</span>
<span class="ltx_bibblock">Analyzing the behavior of visual question answering models.

</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">EMNLP</span>, 2016.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Sainandan Ramakrishnan, Aishwarya Agrawal, and Stefan Lee.

</span>
<span class="ltx_bibblock">Overcoming language priors in visual question answering with
adversarial regularization.

</span>
<span class="ltx_bibblock">In <span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, pages
1541â€“1551, 2018.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Zichao Yang, Xiaodong He, Jianfeng Gao, LiÂ Deng, and Alex Smola.

</span>
<span class="ltx_bibblock">Stacked attention networks for image question answering.

</span>
<span class="ltx_bibblock">In <span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</span>, pages 21â€“29, 2016.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Jonathan Gordon and Benjamin VanÂ Durme.

</span>
<span class="ltx_bibblock">Reporting bias and knowledge acquisition.

</span>
<span class="ltx_bibblock">In <span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2013 workshop on Automated knowledge base
construction</span>, pages 25â€“30. ACM, 2013.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Wei-Lun Chao, Hexiang Hu, and Fei Sha.

</span>
<span class="ltx_bibblock">Being negative but constructively: Lessons learnt from creating
better visual question answering datasets.

</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">NAACL</span>, 2018.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Antonio Torralba and AlexeiÂ A. Efros.

</span>
<span class="ltx_bibblock">Unbiased look at dataset bias.

</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">CVPR</span>, Jun 2011.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Pierre Stock and Moustapha Cisse.

</span>
<span class="ltx_bibblock">Convnets and imagenet beyond accuracy: Understanding mistakes and
uncovering biases.

</span>
<span class="ltx_bibblock">In <span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">The European Conference on Computer Vision (ECCV)</span>, September
2018.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Sen Jia, Thomas Lansdall-Welfare, and Nello Cristianini.

</span>
<span class="ltx_bibblock">Right for the Right Reason: Training Agnostic Networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">Lecture Notes in Computer Science</span>, page 164â€“174, 2018.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Varun Manjunatha, Nirat Saini, and LarryÂ S. Davis.

</span>
<span class="ltx_bibblock">Explicit Bias Discovery in Visual Question Answering Models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">CVPR</span>, Nov 2019.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
LisaÂ Anne Hendricks, Kaylee Burns, Kate Saenko, Trevor Darrell, and Anna
Rohrbach.

</span>
<span class="ltx_bibblock">Women also snowboard: Overcoming bias in captioning models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">ECCV</span>, 2018.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Jieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, and Kai-Wei Chang.

</span>
<span class="ltx_bibblock">Men also like shopping: Reducing gender bias amplification using
corpus-level constraints.

</span>
<span class="ltx_bibblock">In <span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">Conference on Empirical Methods in Natural Language
Processing (EMNLP)</span>, 2017.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Ishan Misra, CÂ LawrenceÂ Zitnick, Margaret Mitchell, and Ross Girshick.

</span>
<span class="ltx_bibblock">Seeing through the human reporting bias: Visual classifiers from
noisy human-centric labels.

</span>
<span class="ltx_bibblock">In <span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span>, pages 2930â€“2939, 2016.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Abhinav Gupta, Adithyavairavan Murali, DhirajÂ Prakashchand Gandhi, and Lerrel
Pinto.

</span>
<span class="ltx_bibblock">Robot learning in homes: Improving generalization and reducing
dataset bias.

</span>
<span class="ltx_bibblock">In <span id="bib.bib36.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, pages
9094â€“9104, 2018.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Ankesh Anand, Eugene Belilovsky, Kyle Kastner, Hugo Larochelle, and Aaron
Courville.

</span>
<span class="ltx_bibblock">Blindfold baselines for embodied qa.

</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1811.05013</span>, 2018.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Jesse Thomason, Daniel Gordon, and Yonatan Bisk.

</span>
<span class="ltx_bibblock">Shifting the baseline: Single modality performance on visual
navigation &amp; qa.

</span>
<span class="ltx_bibblock">In <span id="bib.bib38.1.1" class="ltx_text ltx_font_italic">NACL</span>, 2019.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Anna Rohrbach, LisaÂ Anne Hendricks, Kaylee Burns, Trevor Darrell, and Kate
Saenko.

</span>
<span class="ltx_bibblock">Object hallucination in image captioning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib39.1.1" class="ltx_text ltx_font_italic">EMNLP</span>, 2018.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Allan Jabri, Armand Joulin, and Laurens Van DerÂ Maaten.

</span>
<span class="ltx_bibblock">Revisiting visual question answering baselines.

</span>
<span class="ltx_bibblock">In <span id="bib.bib40.1.1" class="ltx_text ltx_font_italic">European conference on computer vision</span>, pages 727â€“739.
Springer, 2016.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Jiasen Lu, Jianwei Yang, Dhruv Batra, and Devi Parikh.

</span>
<span class="ltx_bibblock">Hierarchical question-image co-attention for visual question
answering.

</span>
<span class="ltx_bibblock">In <span id="bib.bib41.1.1" class="ltx_text ltx_font_italic">Advances In Neural Information Processing Systems</span>, pages
289â€“297, 2016.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Hedi Ben-Younes, RÃ©mi CadÃ¨ne, Nicolas Thome, and Matthieu Cord.

</span>
<span class="ltx_bibblock">Mutan: Multimodal tucker fusion for visual question answering.

</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text ltx_font_italic">ICCV</span>, 2017.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Zhou Yu, Jun Yu, Chenchao Xiang, Jianping Fan, and Dacheng Tao.

</span>
<span class="ltx_bibblock">Beyond bilinear: Generalized multi-modal factorized high-order
pooling for visual question answering.

</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Neural Networks and Learning Systems</span>,
2018.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Abhishek Das, Harsh Agrawal, C.Â Lawrence Zitnick, Devi Parikh, and Dhruv Batra.

</span>
<span class="ltx_bibblock">Human Attention in Visual Question Answering: Do Humans and Deep
Networks Look at the Same Regions?

</span>
<span class="ltx_bibblock">In <span id="bib.bib44.1.1" class="ltx_text ltx_font_italic">Conference on Empirical Methods in Natural Language
Processing (EMNLP)</span>, 2016.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Robik Shrestha, Kushal Kafle, and Christopher Kanan.

</span>
<span class="ltx_bibblock">Answer them all! toward universal visual question answering models.

</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text ltx_font_italic">CVPR</span>, 2019.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Supplementary materials</h2>

<figure id="S6.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F5.1" class="ltx_figure ltx_figure_panel"><img src="/html/1906.10169/assets/images/model_rubi.png" id="S6.F5.1.g1" class="ltx_graphics ltx_img_portrait" width="509" height="657" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F5.2" class="ltx_figure ltx_figure_panel"><img src="/html/1906.10169/assets/images/model_25.png" id="S6.F5.2.g1" class="ltx_graphics ltx_img_portrait" width="479" height="605" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F5.4.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S6.F5.5.2" class="ltx_text" style="font-size:90%;">Visual comparison between RUBi and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>.</span></figcaption>
</figure>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Additional experiments</h3>

<section id="S6.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Results on VQA-CP v1</h4>

<div id="S6.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S6.SS1.SSS0.Px1.p1.1" class="ltx_p">In Table <a href="#S6.T5" title="Table 5 â€£ Results on VQA-CP v1 â€£ 6.1 Additional experiments â€£ 6 Supplementary materials â€£ RUBi: Reducing Unimodal Biases for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we report results on the VQA-CP v1 dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. Our RUBi approach consistently leads to significant gains over the classical learning strategy with a gain of +9.8 overall accuracy point with our baseline architecture, +19.2 with SAN and +7.66 with UpDn. Additionally, RUBi leads to a gain of +2.65 over the adversarial regularization method (AdvReg) from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> with SAN. A visual comparison between RUBi and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> can be found in FigureÂ <a href="#S6.F5" title="Figure 5 â€£ 6 Supplementary materials â€£ RUBi: Reducing Unimodal Biases for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. Finally, all three architectures trained with RUBi reach a higher accuracy than GVQA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> which has been hand-designed to overcome biases.</p>
</div>
<figure id="S6.T5" class="ltx_table">
<table id="S6.T5.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S6.T5.2.1.1" class="ltx_tr">
<td id="S6.T5.2.1.1.1" class="ltx_td ltx_align_left ltx_border_tt">Model</td>
<td id="S6.T5.2.1.1.2" class="ltx_td ltx_align_left ltx_border_tt">Overall</td>
<td id="S6.T5.2.1.1.3" class="ltx_td ltx_align_left ltx_border_tt">Yes/No</td>
<td id="S6.T5.2.1.1.4" class="ltx_td ltx_align_left ltx_border_tt">Number</td>
<td id="S6.T5.2.1.1.5" class="ltx_td ltx_align_left ltx_border_tt">Other</td>
</tr>
<tr id="S6.T5.2.2.2" class="ltx_tr">
<td id="S6.T5.2.2.2.1" class="ltx_td ltx_align_left ltx_border_t">GVQA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>
</td>
<td id="S6.T5.2.2.2.2" class="ltx_td ltx_align_left ltx_border_t">39.23</td>
<td id="S6.T5.2.2.2.3" class="ltx_td ltx_align_left ltx_border_t">64.72</td>
<td id="S6.T5.2.2.2.4" class="ltx_td ltx_align_left ltx_border_t">11.87</td>
<td id="S6.T5.2.2.2.5" class="ltx_td ltx_align_left ltx_border_t">24.86</td>
</tr>
<tr id="S6.T5.2.3.3" class="ltx_tr">
<td id="S6.T5.2.3.3.1" class="ltx_td ltx_align_left ltx_border_t">Baseline (ours)</td>
<td id="S6.T5.2.3.3.2" class="ltx_td ltx_align_left ltx_border_t">37.13</td>
<td id="S6.T5.2.3.3.3" class="ltx_td ltx_align_left ltx_border_t">41.96</td>
<td id="S6.T5.2.3.3.4" class="ltx_td ltx_align_left ltx_border_t">12.54</td>
<td id="S6.T5.2.3.3.5" class="ltx_td ltx_align_left ltx_border_t">41.35</td>
</tr>
<tr id="S6.T5.2.4.4" class="ltx_tr">
<td id="S6.T5.2.4.4.1" class="ltx_td ltx_align_left">Baseline + RUBi</td>
<td id="S6.T5.2.4.4.2" class="ltx_td ltx_align_left"><span id="S6.T5.2.4.4.2.1" class="ltx_text ltx_font_bold">46.93</span></td>
<td id="S6.T5.2.4.4.3" class="ltx_td ltx_align_left"><span id="S6.T5.2.4.4.3.1" class="ltx_text ltx_font_bold">66.78</span></td>
<td id="S6.T5.2.4.4.4" class="ltx_td ltx_align_left"><span id="S6.T5.2.4.4.4.1" class="ltx_text ltx_font_bold">20.98</span></td>
<td id="S6.T5.2.4.4.5" class="ltx_td ltx_align_left"><span id="S6.T5.2.4.4.5.1" class="ltx_text ltx_font_bold">43.64</span></td>
</tr>
<tr id="S6.T5.2.5.5" class="ltx_tr">
<td id="S6.T5.2.5.5.1" class="ltx_td ltx_align_left ltx_border_t">SAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>
</td>
<td id="S6.T5.2.5.5.2" class="ltx_td ltx_align_left ltx_border_t">26.88</td>
<td id="S6.T5.2.5.5.3" class="ltx_td ltx_align_left ltx_border_t">35.34</td>
<td id="S6.T5.2.5.5.4" class="ltx_td ltx_align_left ltx_border_t">11.34</td>
<td id="S6.T5.2.5.5.5" class="ltx_td ltx_align_left ltx_border_t">24.70</td>
</tr>
<tr id="S6.T5.2.6.6" class="ltx_tr">
<td id="S6.T5.2.6.6.1" class="ltx_td ltx_align_left">SAN + AdvReg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>
</td>
<td id="S6.T5.2.6.6.2" class="ltx_td ltx_align_left">43.43</td>
<td id="S6.T5.2.6.6.3" class="ltx_td ltx_align_left">74.16</td>
<td id="S6.T5.2.6.6.4" class="ltx_td ltx_align_left">12.44</td>
<td id="S6.T5.2.6.6.5" class="ltx_td ltx_align_left">25.32</td>
</tr>
<tr id="S6.T5.2.7.7" class="ltx_tr">
<td id="S6.T5.2.7.7.1" class="ltx_td ltx_align_left">SAN + RUBi</td>
<td id="S6.T5.2.7.7.2" class="ltx_td ltx_align_left"><span id="S6.T5.2.7.7.2.1" class="ltx_text ltx_font_bold">46.08</span></td>
<td id="S6.T5.2.7.7.3" class="ltx_td ltx_align_left"><span id="S6.T5.2.7.7.3.1" class="ltx_text ltx_font_bold">75.00</span></td>
<td id="S6.T5.2.7.7.4" class="ltx_td ltx_align_left"><span id="S6.T5.2.7.7.4.1" class="ltx_text ltx_font_bold">13.30</span></td>
<td id="S6.T5.2.7.7.5" class="ltx_td ltx_align_left"><span id="S6.T5.2.7.7.5.1" class="ltx_text ltx_font_bold">30.49</span></td>
</tr>
<tr id="S6.T5.2.8.8" class="ltx_tr">
<td id="S6.T5.2.8.8.1" class="ltx_td ltx_align_left ltx_border_t">UpDn (ours)</td>
<td id="S6.T5.2.8.8.2" class="ltx_td ltx_align_left ltx_border_t">37.15</td>
<td id="S6.T5.2.8.8.3" class="ltx_td ltx_align_left ltx_border_t">41.13</td>
<td id="S6.T5.2.8.8.4" class="ltx_td ltx_align_left ltx_border_t">12.73</td>
<td id="S6.T5.2.8.8.5" class="ltx_td ltx_align_left ltx_border_t"><span id="S6.T5.2.8.8.5.1" class="ltx_text ltx_font_bold">43.00</span></td>
</tr>
<tr id="S6.T5.2.9.9" class="ltx_tr">
<td id="S6.T5.2.9.9.1" class="ltx_td ltx_align_left ltx_border_bb">UpDn + RUBi</td>
<td id="S6.T5.2.9.9.2" class="ltx_td ltx_align_left ltx_border_bb"><span id="S6.T5.2.9.9.2.1" class="ltx_text ltx_font_bold">44.81</span></td>
<td id="S6.T5.2.9.9.3" class="ltx_td ltx_align_left ltx_border_bb"><span id="S6.T5.2.9.9.3.1" class="ltx_text ltx_font_bold">69.65</span></td>
<td id="S6.T5.2.9.9.4" class="ltx_td ltx_align_left ltx_border_bb"><span id="S6.T5.2.9.9.4.1" class="ltx_text ltx_font_bold">14.91</span></td>
<td id="S6.T5.2.9.9.5" class="ltx_td ltx_align_left ltx_border_bb">32.13</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S6.T5.3.1.1" class="ltx_text" style="font-size:90%;">Table 5</span>: </span><span id="S6.T5.4.2" class="ltx_text" style="font-size:90%;">Overall accuracy top1 on VQA-CP v1</span></figcaption>
</figure>
</section>
<section id="S6.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Detailed results on VQA-CP v2</h4>

<div id="S6.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S6.SS1.SSS0.Px2.p1.1" class="ltx_p">In TableÂ <a href="#S6.T6" title="Table 6 â€£ Detailed results on VQA-CP v2 â€£ 6.1 Additional experiments â€£ 6 Supplementary materials â€£ RUBi: Reducing Unimodal Biases for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, we report the full results of our experiments for SAN and UpDn architectures on the VQA-CP v2 dataset.</p>
</div>
<figure id="S6.T6" class="ltx_table">
<table id="S6.T6.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T6.2.1.1" class="ltx_tr">
<th id="S6.T6.2.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Model</th>
<th id="S6.T6.2.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Overall</th>
<th id="S6.T6.2.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Yes/No</th>
<th id="S6.T6.2.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Number</th>
<th id="S6.T6.2.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Other</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T6.2.2.1" class="ltx_tr">
<td id="S6.T6.2.2.1.1" class="ltx_td ltx_align_left ltx_border_t">SAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>
</td>
<td id="S6.T6.2.2.1.2" class="ltx_td ltx_align_left ltx_border_t">24.96</td>
<td id="S6.T6.2.2.1.3" class="ltx_td ltx_align_left ltx_border_t">38.35</td>
<td id="S6.T6.2.2.1.4" class="ltx_td ltx_align_left ltx_border_t">11.14</td>
<td id="S6.T6.2.2.1.5" class="ltx_td ltx_align_left ltx_border_t">21.74</td>
</tr>
<tr id="S6.T6.2.3.2" class="ltx_tr">
<td id="S6.T6.2.3.2.1" class="ltx_td ltx_align_left">SAN + RUBi</td>
<td id="S6.T6.2.3.2.2" class="ltx_td ltx_align_left"><span id="S6.T6.2.3.2.2.1" class="ltx_text ltx_font_bold">37.63</span></td>
<td id="S6.T6.2.3.2.3" class="ltx_td ltx_align_left"><span id="S6.T6.2.3.2.3.1" class="ltx_text ltx_font_bold">59.49</span></td>
<td id="S6.T6.2.3.2.4" class="ltx_td ltx_align_left"><span id="S6.T6.2.3.2.4.1" class="ltx_text ltx_font_bold">13.71</span></td>
<td id="S6.T6.2.3.2.5" class="ltx_td ltx_align_left"><span id="S6.T6.2.3.2.5.1" class="ltx_text ltx_font_bold">32.74</span></td>
</tr>
<tr id="S6.T6.2.4.3" class="ltx_tr">
<td id="S6.T6.2.4.3.1" class="ltx_td ltx_align_left ltx_border_t">UpDn <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>
</td>
<td id="S6.T6.2.4.3.2" class="ltx_td ltx_align_left ltx_border_t">39.74</td>
<td id="S6.T6.2.4.3.3" class="ltx_td ltx_align_left ltx_border_t">42.27</td>
<td id="S6.T6.2.4.3.4" class="ltx_td ltx_align_left ltx_border_t">11.93</td>
<td id="S6.T6.2.4.3.5" class="ltx_td ltx_align_left ltx_border_t"><span id="S6.T6.2.4.3.5.1" class="ltx_text ltx_font_bold">46.05</span></td>
</tr>
<tr id="S6.T6.2.5.4" class="ltx_tr">
<td id="S6.T6.2.5.4.1" class="ltx_td ltx_align_left ltx_border_bb">UpDn + RUBi</td>
<td id="S6.T6.2.5.4.2" class="ltx_td ltx_align_left ltx_border_bb"><span id="S6.T6.2.5.4.2.1" class="ltx_text ltx_font_bold">44.23</span></td>
<td id="S6.T6.2.5.4.3" class="ltx_td ltx_align_left ltx_border_bb"><span id="S6.T6.2.5.4.3.1" class="ltx_text ltx_font_bold">67.05</span></td>
<td id="S6.T6.2.5.4.4" class="ltx_td ltx_align_left ltx_border_bb"><span id="S6.T6.2.5.4.4.1" class="ltx_text ltx_font_bold">17.48</span></td>
<td id="S6.T6.2.5.4.5" class="ltx_td ltx_align_left ltx_border_bb">39.61</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S6.T6.3.1.1" class="ltx_text" style="font-size:90%;">Table 6</span>: </span><span id="S6.T6.4.2" class="ltx_text" style="font-size:90%;">Overall accuracy top1 on VQA-CP v2 for the SAN and UpDn architectures.</span></figcaption>
</figure>
</section>
<section id="S6.SS1.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Quantitative study of the grounding ability on VQA-HAT</h4>

<div id="S6.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S6.SS1.SSS0.Px3.p1.1" class="ltx_p">We conduct additional studies to evaluate the grounding ability of models trained with RUBi. We follow the experimental protocol of VQA-HAT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>. We train our models on VQA v1 train set and evaluate them using rank-correlation on the VQA-HAT val set, which is a subset of the VQA v1 val set. This metric compares attention maps computed from a model against human annotations indicating which regions humans found relevant for answering the question.
In TableÂ <a href="#S6.T7" title="Table 7 â€£ Quantitative study of the grounding ability on VQA-HAT â€£ 6.1 Additional experiments â€£ 6 Supplementary materials â€£ RUBi: Reducing Unimodal Biases for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, we report a gain of +0.012 with our baseline architecture trained with RUBi, a gain of +0.019 with SAN and a loss of -0.003 with UpDn architecture. In future works, we would like to go beyond these early results in order to further evaluate the impact on grounding induced by RUBi.</p>
</div>
<figure id="S6.T7" class="ltx_table">
<table id="S6.T7.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T7.2.1.1" class="ltx_tr">
<th id="S6.T7.2.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Model</th>
<th id="S6.T7.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">RUBi</th>
<th id="S6.T7.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Rank-Corr.</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T7.2.2.1" class="ltx_tr">
<th id="S6.T7.2.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Random <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>
</th>
<td id="S6.T7.2.2.1.2" class="ltx_td ltx_border_t"></td>
<td id="S6.T7.2.2.1.3" class="ltx_td ltx_align_center ltx_border_t">0.000</td>
</tr>
<tr id="S6.T7.2.3.2" class="ltx_tr">
<th id="S6.T7.2.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Human <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>
</th>
<td id="S6.T7.2.3.2.2" class="ltx_td"></td>
<td id="S6.T7.2.3.2.3" class="ltx_td ltx_align_center">0.623</td>
</tr>
<tr id="S6.T7.2.4.3" class="ltx_tr">
<th id="S6.T7.2.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="S6.T7.2.4.3.1.1" class="ltx_text">Baseline</span></th>
<td id="S6.T7.2.4.3.2" class="ltx_td ltx_align_center ltx_border_t">âœ—</td>
<td id="S6.T7.2.4.3.3" class="ltx_td ltx_align_center ltx_border_t">0.431</td>
</tr>
<tr id="S6.T7.2.5.4" class="ltx_tr">
<td id="S6.T7.2.5.4.1" class="ltx_td ltx_align_center">âœ“</td>
<td id="S6.T7.2.5.4.2" class="ltx_td ltx_align_center"><span id="S6.T7.2.5.4.2.1" class="ltx_text ltx_font_bold">0.443</span></td>
</tr>
<tr id="S6.T7.2.6.5" class="ltx_tr">
<th id="S6.T7.2.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="S6.T7.2.6.5.1.1" class="ltx_text">SAN</span></th>
<td id="S6.T7.2.6.5.2" class="ltx_td ltx_align_center ltx_border_t">âœ—</td>
<td id="S6.T7.2.6.5.3" class="ltx_td ltx_align_center ltx_border_t">0.191</td>
</tr>
<tr id="S6.T7.2.7.6" class="ltx_tr">
<td id="S6.T7.2.7.6.1" class="ltx_td ltx_align_center">âœ“</td>
<td id="S6.T7.2.7.6.2" class="ltx_td ltx_align_center"><span id="S6.T7.2.7.6.2.1" class="ltx_text ltx_font_bold">0.210</span></td>
</tr>
<tr id="S6.T7.2.8.7" class="ltx_tr">
<th id="S6.T7.2.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" rowspan="2"><span id="S6.T7.2.8.7.1.1" class="ltx_text">UpDn</span></th>
<td id="S6.T7.2.8.7.2" class="ltx_td ltx_align_center ltx_border_t">âœ—</td>
<td id="S6.T7.2.8.7.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T7.2.8.7.3.1" class="ltx_text ltx_font_bold">0.449</span></td>
</tr>
<tr id="S6.T7.2.9.8" class="ltx_tr">
<td id="S6.T7.2.9.8.1" class="ltx_td ltx_align_center ltx_border_bb">âœ“</td>
<td id="S6.T7.2.9.8.2" class="ltx_td ltx_align_center ltx_border_bb">0.446</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S6.T7.4.1.1" class="ltx_text" style="font-size:90%;">Table 7</span>: </span><span id="S6.T7.5.2" class="ltx_text" style="font-size:90%;">Correlation with Human Attention Maps on VQA-HAT <span id="S6.T7.5.2.1" class="ltx_text ltx_font_typewriter">val</span> set <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>.</span></figcaption>
</figure>
</section>
<section id="S6.SS1.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Qualitative study of the grounding ability on VQA-HAT</h4>

<div id="S6.SS1.SSS0.Px4.p1" class="ltx_para">
<p id="S6.SS1.SSS0.Px4.p1.1" class="ltx_p">We display in FigureÂ <a href="#S6.F6" title="Figure 6 â€£ Qualitative study of the grounding ability on VQA-HAT â€£ 6.1 Additional experiments â€£ 6 Supplementary materials â€£ RUBi: Reducing Unimodal Biases for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> and FigureÂ <a href="#S6.F7" title="Figure 7 â€£ Qualitative study of the grounding ability on VQA-HAT â€£ 6.1 Additional experiments â€£ 6 Supplementary materials â€£ RUBi: Reducing Unimodal Biases for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> some manually selected VQA triplets associated to the human attention maps provided by VQA-HAT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite> and the attention maps computed from our baseline architecture when trained with and without RUBi. In FigureÂ <a href="#S6.F6" title="Figure 6 â€£ Qualitative study of the grounding ability on VQA-HAT â€£ 6.1 Additional experiments â€£ 6 Supplementary materials â€£ RUBi: Reducing Unimodal Biases for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, we observe that the attention maps with RUBi are closer to the human attention maps than without RUBi. On the contrary, we observe in FigureÂ <a href="#S6.F7" title="Figure 7 â€£ Qualitative study of the grounding ability on VQA-HAT â€£ 6.1 Additional experiments â€£ 6 Supplementary materials â€£ RUBi: Reducing Unimodal Biases for Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> some failure to improve grounding ability.</p>
</div>
<figure id="S6.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/1906.10169/assets/images/vqahat/3430380_blur.png" id="S6.F6.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="598" height="112" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/1906.10169/assets/images/vqahat/2187511.png" id="S6.F6.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="598" height="198" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/1906.10169/assets/images/vqahat/4350371.png" id="S6.F6.g3" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="598" height="104" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/1906.10169/assets/images/vqahat/4516741.png" id="S6.F6.g4" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="598" height="207" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/1906.10169/assets/images/vqahat/4794400.png" id="S6.F6.g5" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="598" height="187" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S6.F6.3.2" class="ltx_text" style="font-size:90%;">Examples of better grounding ability on VQA-HAT implied by RUBi. From the left column to the right: image-question-answer triplet, human attention map from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>, attention map from our baseline, attention map from our baseline trained with RUBi.</span></figcaption>
</figure>
<figure id="S6.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/1906.10169/assets/images/vqahat-bad/2919811.png" id="S6.F7.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="598" height="130" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/1906.10169/assets/images/vqahat-bad/496881_blur.png" id="S6.F7.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="598" height="115" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/1906.10169/assets/images/vqahat-bad/4662730.png" id="S6.F7.g3" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="598" height="110" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/1906.10169/assets/images/vqahat-bad/5399372.png" id="S6.F7.g4" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="598" height="116" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/1906.10169/assets/images/vqahat-bad/5789641.png" id="S6.F7.g5" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="598" height="116" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F7.2.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S6.F7.3.2" class="ltx_text" style="font-size:90%;">Examples of failure to improve grounding ability on VQA-HAT. From the left column to the right: image-question-answer triplet, human attention map from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>, attention map from our baseline, attention map from our baseline trained with RUBi.</span></figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Implementation details</h3>

<section id="S6.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Image encoder</h4>

<div id="S6.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S6.SS2.SSS0.Px1.p1.1" class="ltx_p">We use the pretrained Faster R-CNN by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> to extract object features. We use the setup that extracts 36 regions for each image. We do not fine-tune the image extractor.</p>
</div>
</section>
<section id="S6.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Question encoder</h4>

<div id="S6.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S6.SS2.SSS0.Px2.p1.1" class="ltx_p">We use the same preprocessing as in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. We apply a lower case transformation and remove the punctuation. We only consider the most frequent 3000 answers for both VQA v2 and VQA CP v2. We then use a pretrained Skip-thought encoder with a two-glimpses self attention mechanism. The final embedding is of size 4800. We fine-tune the question encoder during training.</p>
</div>
</section>
<section id="S6.SS2.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Baseline architecture</h4>

<div id="S6.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S6.SS2.SSS0.Px3.p1.1" class="ltx_p">Our baseline architecture is a simplified version of the MuRel architecture <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>.
First, it computes a bilinear fusion between the question vector and the visual features for each region.
The bilinear fusion module is a BLOCK <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> composed of 15 chunks, each of rank 15.
The dimension of the projection space is 1000, and the output dimension is 2048.
The output of the bilinear fusion is aggregated using a max pooling over <math id="S6.SS2.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="n_{v}" display="inline"><semantics id="S6.SS2.SSS0.Px3.p1.1.m1.1a"><msub id="S6.SS2.SSS0.Px3.p1.1.m1.1.1" xref="S6.SS2.SSS0.Px3.p1.1.m1.1.1.cmml"><mi id="S6.SS2.SSS0.Px3.p1.1.m1.1.1.2" xref="S6.SS2.SSS0.Px3.p1.1.m1.1.1.2.cmml">n</mi><mi id="S6.SS2.SSS0.Px3.p1.1.m1.1.1.3" xref="S6.SS2.SSS0.Px3.p1.1.m1.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS0.Px3.p1.1.m1.1b"><apply id="S6.SS2.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S6.SS2.SSS0.Px3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S6.SS2.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="S6.SS2.SSS0.Px3.p1.1.m1.1.1">subscript</csymbol><ci id="S6.SS2.SSS0.Px3.p1.1.m1.1.1.2.cmml" xref="S6.SS2.SSS0.Px3.p1.1.m1.1.1.2">ğ‘›</ci><ci id="S6.SS2.SSS0.Px3.p1.1.m1.1.1.3.cmml" xref="S6.SS2.SSS0.Px3.p1.1.m1.1.1.3">ğ‘£</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS0.Px3.p1.1.m1.1c">n_{v}</annotation></semantics></math> regions.
The resulting vector is then fed into a MLP classifier composed of three layers of size (2048, 2048, 3000), with ReLU activations.
It outputs the predictions over the space of the 3000 answers.</p>
</div>
</section>
<section id="S6.SS2.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Question-only branch</h4>

<div id="S6.SS2.SSS0.Px4.p1" class="ltx_para">
<p id="S6.SS2.SSS0.Px4.p1.1" class="ltx_p">The RUBi question-only branch feeds the question into a first MLP composed of three layers, of size (2048, 2048, 3000), with ReLU activations.
First, this output vector goes through a sigmoid to compute the mask that will alter the predictions of the VQA model.
Secondly, this same output vector goes through a single linear layer of size 3000. We use these question-only predictions to compute the question-only loss.</p>
</div>
</section>
<section id="S6.SS2.SSS0.Px5" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Optimization process</h4>

<div id="S6.SS2.SSS0.Px5.p1" class="ltx_para">
<p id="S6.SS2.SSS0.Px5.p1.2" class="ltx_p">We train all our models with the Adam optimizer. We train our baseline architecture with the learning rate scheduler of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. We use a learning rate of <math id="S6.SS2.SSS0.Px5.p1.1.m1.1" class="ltx_Math" alttext="1.5\times 10^{-4}" display="inline"><semantics id="S6.SS2.SSS0.Px5.p1.1.m1.1a"><mrow id="S6.SS2.SSS0.Px5.p1.1.m1.1.1" xref="S6.SS2.SSS0.Px5.p1.1.m1.1.1.cmml"><mn id="S6.SS2.SSS0.Px5.p1.1.m1.1.1.2" xref="S6.SS2.SSS0.Px5.p1.1.m1.1.1.2.cmml">1.5</mn><mo lspace="0.222em" rspace="0.222em" id="S6.SS2.SSS0.Px5.p1.1.m1.1.1.1" xref="S6.SS2.SSS0.Px5.p1.1.m1.1.1.1.cmml">Ã—</mo><msup id="S6.SS2.SSS0.Px5.p1.1.m1.1.1.3" xref="S6.SS2.SSS0.Px5.p1.1.m1.1.1.3.cmml"><mn id="S6.SS2.SSS0.Px5.p1.1.m1.1.1.3.2" xref="S6.SS2.SSS0.Px5.p1.1.m1.1.1.3.2.cmml">10</mn><mrow id="S6.SS2.SSS0.Px5.p1.1.m1.1.1.3.3" xref="S6.SS2.SSS0.Px5.p1.1.m1.1.1.3.3.cmml"><mo id="S6.SS2.SSS0.Px5.p1.1.m1.1.1.3.3a" xref="S6.SS2.SSS0.Px5.p1.1.m1.1.1.3.3.cmml">âˆ’</mo><mn id="S6.SS2.SSS0.Px5.p1.1.m1.1.1.3.3.2" xref="S6.SS2.SSS0.Px5.p1.1.m1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS0.Px5.p1.1.m1.1b"><apply id="S6.SS2.SSS0.Px5.p1.1.m1.1.1.cmml" xref="S6.SS2.SSS0.Px5.p1.1.m1.1.1"><times id="S6.SS2.SSS0.Px5.p1.1.m1.1.1.1.cmml" xref="S6.SS2.SSS0.Px5.p1.1.m1.1.1.1"></times><cn type="float" id="S6.SS2.SSS0.Px5.p1.1.m1.1.1.2.cmml" xref="S6.SS2.SSS0.Px5.p1.1.m1.1.1.2">1.5</cn><apply id="S6.SS2.SSS0.Px5.p1.1.m1.1.1.3.cmml" xref="S6.SS2.SSS0.Px5.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S6.SS2.SSS0.Px5.p1.1.m1.1.1.3.1.cmml" xref="S6.SS2.SSS0.Px5.p1.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S6.SS2.SSS0.Px5.p1.1.m1.1.1.3.2.cmml" xref="S6.SS2.SSS0.Px5.p1.1.m1.1.1.3.2">10</cn><apply id="S6.SS2.SSS0.Px5.p1.1.m1.1.1.3.3.cmml" xref="S6.SS2.SSS0.Px5.p1.1.m1.1.1.3.3"><minus id="S6.SS2.SSS0.Px5.p1.1.m1.1.1.3.3.1.cmml" xref="S6.SS2.SSS0.Px5.p1.1.m1.1.1.3.3"></minus><cn type="integer" id="S6.SS2.SSS0.Px5.p1.1.m1.1.1.3.3.2.cmml" xref="S6.SS2.SSS0.Px5.p1.1.m1.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS0.Px5.p1.1.m1.1c">1.5\times 10^{-4}</annotation></semantics></math> and a batch size of 256. During the first 7 epochs, we linearly increase the learning rate to <math id="S6.SS2.SSS0.Px5.p1.2.m2.1" class="ltx_Math" alttext="6\times 10^{-4}" display="inline"><semantics id="S6.SS2.SSS0.Px5.p1.2.m2.1a"><mrow id="S6.SS2.SSS0.Px5.p1.2.m2.1.1" xref="S6.SS2.SSS0.Px5.p1.2.m2.1.1.cmml"><mn id="S6.SS2.SSS0.Px5.p1.2.m2.1.1.2" xref="S6.SS2.SSS0.Px5.p1.2.m2.1.1.2.cmml">6</mn><mo lspace="0.222em" rspace="0.222em" id="S6.SS2.SSS0.Px5.p1.2.m2.1.1.1" xref="S6.SS2.SSS0.Px5.p1.2.m2.1.1.1.cmml">Ã—</mo><msup id="S6.SS2.SSS0.Px5.p1.2.m2.1.1.3" xref="S6.SS2.SSS0.Px5.p1.2.m2.1.1.3.cmml"><mn id="S6.SS2.SSS0.Px5.p1.2.m2.1.1.3.2" xref="S6.SS2.SSS0.Px5.p1.2.m2.1.1.3.2.cmml">10</mn><mrow id="S6.SS2.SSS0.Px5.p1.2.m2.1.1.3.3" xref="S6.SS2.SSS0.Px5.p1.2.m2.1.1.3.3.cmml"><mo id="S6.SS2.SSS0.Px5.p1.2.m2.1.1.3.3a" xref="S6.SS2.SSS0.Px5.p1.2.m2.1.1.3.3.cmml">âˆ’</mo><mn id="S6.SS2.SSS0.Px5.p1.2.m2.1.1.3.3.2" xref="S6.SS2.SSS0.Px5.p1.2.m2.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS0.Px5.p1.2.m2.1b"><apply id="S6.SS2.SSS0.Px5.p1.2.m2.1.1.cmml" xref="S6.SS2.SSS0.Px5.p1.2.m2.1.1"><times id="S6.SS2.SSS0.Px5.p1.2.m2.1.1.1.cmml" xref="S6.SS2.SSS0.Px5.p1.2.m2.1.1.1"></times><cn type="integer" id="S6.SS2.SSS0.Px5.p1.2.m2.1.1.2.cmml" xref="S6.SS2.SSS0.Px5.p1.2.m2.1.1.2">6</cn><apply id="S6.SS2.SSS0.Px5.p1.2.m2.1.1.3.cmml" xref="S6.SS2.SSS0.Px5.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S6.SS2.SSS0.Px5.p1.2.m2.1.1.3.1.cmml" xref="S6.SS2.SSS0.Px5.p1.2.m2.1.1.3">superscript</csymbol><cn type="integer" id="S6.SS2.SSS0.Px5.p1.2.m2.1.1.3.2.cmml" xref="S6.SS2.SSS0.Px5.p1.2.m2.1.1.3.2">10</cn><apply id="S6.SS2.SSS0.Px5.p1.2.m2.1.1.3.3.cmml" xref="S6.SS2.SSS0.Px5.p1.2.m2.1.1.3.3"><minus id="S6.SS2.SSS0.Px5.p1.2.m2.1.1.3.3.1.cmml" xref="S6.SS2.SSS0.Px5.p1.2.m2.1.1.3.3"></minus><cn type="integer" id="S6.SS2.SSS0.Px5.p1.2.m2.1.1.3.3.2.cmml" xref="S6.SS2.SSS0.Px5.p1.2.m2.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS0.Px5.p1.2.m2.1c">6\times 10^{-4}</annotation></semantics></math>. After epoch 14, we apply a learning rate decay strategy which multiplies the learning rate by 0.25 every two epochs. We train our models until convergence as we do not have a validation set for VQA-CP v2. For the UpDn and SAN architectures, we follow the optimization procedure described in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>.</p>
</div>
</section>
<section id="S6.SS2.SSS0.Px6" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Software and hardware</h4>

<div id="S6.SS2.SSS0.Px6.p1" class="ltx_para">
<p id="S6.SS2.SSS0.Px6.p1.1" class="ltx_p">We use pytorch 1.1.0 to implement our algorithms in order to benefit from the GPU acceleration. We use four NVidia Titan Xp GPU in this study. We use a single GPU for each experiments. We use a dedicated SSD to load the visual features using multiple threads.
A single experiment from TableÂ 1 with the baseline architecture trained with or without RUBi takes less than five hours to run.</p>
</div>
</section>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/1906.10168" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/1906.10169" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+1906.10169">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/1906.10169" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/1906.10170" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Mar  7 11:31:52 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
