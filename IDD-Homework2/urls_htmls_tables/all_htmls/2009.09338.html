<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2009.09338] When Federated Learning Meets Blockchain: A New Distributed Learning Paradigm</title><meta property="og:description" content="Motivated by the explosive computing capabilities at end user equipments, as well as the growing privacy concerns over sharing sensitive raw data, a new machine learning paradigm, named federated learning (FL) has emer…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="When Federated Learning Meets Blockchain: A New Distributed Learning Paradigm">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="When Federated Learning Meets Blockchain: A New Distributed Learning Paradigm">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2009.09338">

<!--Generated on Thu Mar 14 11:31:17 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Federated Learning,  Blockchain,  Privacy and Security
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">When Federated Learning Meets Blockchain: A New Distributed Learning Paradigm</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Chuan Ma, <em id="id1.1.id1" class="ltx_emph ltx_font_italic">Member, IEEE</em>, 
Jun Li, <em id="id2.2.id2" class="ltx_emph ltx_font_italic">Senior Member, IEEE</em>,
Ming Ding, <em id="id3.3.id3" class="ltx_emph ltx_font_italic">Senior Member, IEEE</em>,
<br class="ltx_break">
Long Shi, <em id="id4.4.id4" class="ltx_emph ltx_font_italic">Member, IEEE</em>,
Taotao Wang, <em id="id5.5.id5" class="ltx_emph ltx_font_italic">Member, IEEE</em>,
<br class="ltx_break">
Zhu Han, <em id="id6.6.id6" class="ltx_emph ltx_font_italic">Fellow, IEEE</em>, 
and H. Vincent Poor, <em id="id7.7.id7" class="ltx_emph ltx_font_italic">Fellow, IEEE</em>
</span><span class="ltx_author_notes">C. Ma, J. Li and L. Shi are with the School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China (e-mail: {chuan.ma, jun.li}@njust.edu.cn and slong1007@gmail.com).M. Ding is with Data61, CSIRO, 2015, Australia (e-mail: Ming.Ding@data61.csiro.au).T. Wang is with the College of Electronics and Information Engineering, Shenzhen University, Shenzhen 518060, China (e-mail: ttwang@szu.edu.cn).Z. Han is with the Department of Electrical and Computer Engineering, University of Houston, Houston, TX 77004, USA (e-mail: zhan2@uh.edu)H. V. Poor is with the Department of Electrical Engineering, Princeton University, Princeton, NJ 08544, USA (e-mail: poor@princeton.edu).</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id8.id1" class="ltx_p">Motivated by the explosive computing capabilities at end user equipments, as well as the growing privacy concerns over sharing sensitive raw data, a new machine learning paradigm, named federated learning (FL) has emerged. By training models locally at each client and aggregating learning models at a central server, FL has the capability to avoid sharing data directly, thereby reducing privacy leakage. However, the traditional FL framework heavily relies on a single central server and may fall apart if such a server behaves maliciously. To address this single point of failure issue, this work investigates a blockchain assisted decentralized FL (BLADE-FL) framework, which can well prevent the malicious clients from poisoning the learning process, and further provides a self-motivated and reliable learning environment for clients. In detail, the model aggregation process is fully decentralized and the tasks of training for FL and mining for blockchain are integrated into each participant. In addition, we investigate the unique issues in this framework and provide analytical and experimental results to shed light on possible solutions.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Federated Learning, Blockchain, Privacy and Security

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Future wireless networks are featured by low latency and high reliability. Thus, machine learning (ML) embedded in each device is a ravishing solution that each user equipment (UE) has the capability to make decisions by its local data, even when it loses connectivity to the wireless system. Since the data at each device is limited, the training of on-device ML models always requires the data exchange among UEs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">However, directly exchanging data among UEs may cause serious risks in privacy leakage and information hijacking <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. To reduce this risk, federated learning (FL) is proposed, which is a new ML framework that trains an AI model across multiple UEs holding local datasets. In details, FL allows to train machine learning models locally at distributed UEs; after that, the UEs share the parameters of the locally trained models to a central server (i.e., the aggregator) where a global model is aggregated. Therefore, the UEs under the FL framework have the capability to cooperatively learn a global model without exchanging their data directly. Moreover, FL has been applied to real-world applications, including health care and autonomous driving <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Although FL shows its effectiveness in preserving privacy, it still endures several limitations. First, in the FL process, the single centralized aggregator is assumed to be trustworthy and it shall make fair decisions in terms of the user selection and aggregation. However, this assumption is not always appropriate, especially in the real-world operations. This is because a biased aggregator can intentionally emerge prejudice to a few selected UEs, thereby damaging the learning performance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Second, the aim of FL is restricted to applications orchestrated by the centralized aggregator. As a result, the resiliency of an aggregator depends on the robustness of the central server, and a failure in the aggregator could collapse the entire FL network. Then, although local data is not explicitly shared in the original format, it is still possible for adversaries to reconstruct the raw data approximately, especially in the aggregation process. In particular, privacy leakage may happen during model aggregating by outsider attacks. Lastly, the existing design is vulnerable to the malicious clients that might upload poisonous models to attack the FL network <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">As a secure technology, blockchain has the capability to tolerate single point failure with distributed consensus, and it can further implement incentive mechanisms to encourage participants to effectively contribute to the system <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. Therefore, blockchain is introduced to FL to solve its limitations mentioned above. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, a blockchained FL architecture was developed to verify the uploaded parameters and it investigated the related system performances, such as the learning delay and the block generation rate. Moreover, work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> proposed a privacy-aware architecture that uses blockchain to enhance security when sharing parameters of machine learning models with other UEs. In addition, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> proposed a high-level but complicated framework by enabling encryption during model transmission and providing incentives from participants, and the work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> further applied this framework in the defensive military network. With the advanced features of blockchain such as tamper-proof, anonymity and traceability, an immutable audit trail of ML models can be created for greater trustworthiness in tracking and proving provenance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. In addition, security and privacy issues of the decentralized FL framework are investigated in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, which delegate the responsibility of storing ML models to a trust community in the blockchain. However, the assumption on the trust community may infer the same privacy issue when ML models transmitting over air, and the credibility of this community also needs further verification. In addition, these works have either not clearly clarified and fully addressed the incident issues, such as the long learning delay and the impact of blockchain forking on FL, or have difficulty in application.
Thus, in this work we have fully detailed the whole process of blockchain assisted decentralized FL (BLADE-FL), which has the capability to overcome the single point of failure problem. In addition, we further investigate the residual issues that exist in the BLADE-FL framework, and provide related solutions.
In detail, we present the design of the BLADE-FL framework in Sec. II, and residual issues including privacy, resource allocation and lazy clients are investigated in Sec. III. In Sec. IV we provide extensive experimental results to show the effectiveness of the corresponding solutions. Finally, future directions and conclusion are drawn in Sec. V.
</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">The framework of BC-FL</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">With the aid of blockchain, we aim to build up a secure and reliable FL framework. To ensure this, the model updating process of FL is decentralized at each participating client, which is robust against the malfunction of traditional aggregators.
In this article, we detail the BLADE-FL framework, to achieve a dynamic client selection and a decentralized learning aggregation process.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">The BLADE-FL framework is composed of three layers. In the network layer, the network features a decentralized P2P network that consists of task publishers and training clients, wherein a learning mission is first published by a task publisher, and then completed by the cooperation of several training clients. Different from previous work that model aggregation happens in a trust community in the blockchain <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, we realize a fully decentralized framework that each client needs to train ML models and mine blocks for publishing aggregating results. In the blockchain layer, each FL-related event, such as publishing a task, broadcasting learning models, and aggregating learning results, is tracked by blockchain. In the application layer, the SC and FL are utilized to execute the FL-related events. Next, we will detail the working flow and key components of the BLADE-FL framework.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.4.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.5.2" class="ltx_text ltx_font_italic">Working Flow</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">As shown in Fig. <a href="#S2.F1" title="Figure 1 ‣ II-A Working Flow ‣ II The framework of BC-FL ‣ When Federated Learning Meets Blockchain: A New Distributed Learning Paradigm" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, the working flow of the proposed framework operates in the following steps:</p>
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p"><span id="S2.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Step 1</span>: Task publishing and node selection. A task publisher broadcasts a FL task through deploying a SC over the blockchain network. In the deployed SC, the task publisher needs to deposit reward as financial incentives to the learning task. The SC selects available training nodes to participate in this learning task.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p"><span id="S2.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Step 2</span>: Local model broadcast. Each training client runs its local training by using its own data samples and broadcasts its local updates and the corresponding processing information (e.g., computation time and local data size) over the P2P network. Privacy leakage may happen during this transmission, and we further investigate this issue in Sec. III-A.
</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p"><span id="S2.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Step 3</span>: Model aggregation. Upon receiving the local updates from other training nodes before a preset time-stamp, each client updates the global model according to the aggregating rule defined in the SC.</p>
</div>
</li>
<li id="S2.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i4.p1" class="ltx_para">
<p id="S2.I1.i4.p1.1" class="ltx_p"><span id="S2.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Step 4</span>: Block generation. Each training client changes roles from trainer to miner and begins mining until either it finds the required nonce or it receives a generated block from other miners. The learning results are stored in the block as well. When one miner generates a new block, other clients verify the contents of this block (e.g., the nonce, the state changed by SC, the transactions, and the aggregated model). The resource allocation issue happens in each client in this step, and related discussions will be given in Sec. III-B.</p>
</div>
</li>
<li id="S2.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i5.p1" class="ltx_para">
<p id="S2.I1.i5.p1.1" class="ltx_p"><span id="S2.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">Step 5</span>: Block propagation. If a block is verified by the majority of clients, this block will be added on the blockchain and accepted by the whole network. The lazy client issue happens in this step and we further investigate it in Sec. III-C.</p>
</div>
</li>
<li id="S2.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i6.p1" class="ltx_para">
<p id="S2.I1.i6.p1.1" class="ltx_p"><span id="S2.I1.i6.p1.1.1" class="ltx_text ltx_font_bold">Step 6</span>: Global model download and update. Each training client downloads the aggregated model from the block and performs updates before the next round of learning.</p>
</div>
</li>
<li id="S2.I1.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i7.p1" class="ltx_para">
<p id="S2.I1.i7.p1.1" class="ltx_p"><span id="S2.I1.i7.p1.1.1" class="ltx_text ltx_font_bold">Step 7</span>: Reward allocation. The SC deployed by the task publisher rewards the training clients according to their contributions in the learning task.</p>
</div>
</li>
</ul>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Before delving into each step, we elaborate on key designs in the BLADE-FL as follows.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2009.09338/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="355" height="283" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The working flow of the blockchain assisted decentralized federated learning (BLADE-FL)</figcaption>
</figure>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.4.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.5.2" class="ltx_text ltx_font_italic">Smart Contract Design</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Smart contracts are self-executing contracts defining rules for negotiating, verifying the fulfilment of rules and executing the agreement using the formal code.
The BLADE-FL framework relies on SC to enable trusted dynamic client selections in terms of desired distributed learning services, without relying on a centralized authority.
Moreover, BC-FL enables all clients to verify the learning results that are recorded on the blockchain, whereby distributed clients can be incentivized to participate and untrusted learning models can be detected. Based on the verification results, the reputation of each distributed client can be automatically updated, making the selection of learning nodes more reliable.
In addition, the design of SC in the BC-FL also includes the aggregating rules, and thus provides a fair and open rewarding feedback for participating clients. The SC in BC-FL enables three main functions as follows:</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p"><span id="S2.SS2.p2.1.1" class="ltx_text ltx_font_bold">Function 1</span>: Learning task publishing. A task publisher broadcasts a FL task through SC to all users. The SC contains the task requirements (e.g., the data size, training accuracy, latency, etc.), the aggregating rules and rewards paid by the task publisher.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p"><span id="S2.SS2.p3.1.1" class="ltx_text ltx_font_bold">Function 2</span>: Dynamic bidding for requests and automatic incentive. Distributed training nodes, acting as auctioneers, bid for the task by replying their costs and capabilities. Note that in order to enforce accountability, each training client has to stake a deposit to the SC. The task replies from training nodes are recorded on the blockchain by the SC. Then the SC selects training clients with more valuable replies (e.g., higher capability and lower cost) as the bid winners to jointly execute the FL task. The training clients that lose the bidding will reclaim their deposits from the SC, while the deposits made by winners will be automatically refunded if the learning results are verified to be trustworthy afterward.</p>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<p id="S2.SS2.p4.1" class="ltx_p"><span id="S2.SS2.p4.1.1" class="ltx_text ltx_font_bold">Function 3</span>: Learning results aggregation and rewards feedback. Before generating a new block, each client will aggregate the uploaded models according to the aggregating rule in SC, in which the contribution of each one in the aggregated model is also recorded in the newly generated block. Then SC is automatically triggered to reward the miner that helps aggregate the learning model and the training clients that contribute to the FL process.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS3.4.1.1" class="ltx_text">II-C</span> </span><span id="S2.SS3.5.2" class="ltx_text ltx_font_italic">The BLADE-FL Design</span>
</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">The main purpose of the BLADE-FL is to enable a trusted cooperative machine learning among distributed nodes. The decentralized accountability enables all miners to verify the quality of uploaded models that are recorded on the blockchain. In addition, distributed training nodes can be motivated to participate in the FL process and misbehaving ones can be recognized from providing low quality of FL services. The key steps are illustrated as follows:</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p"><span id="S2.SS3.p2.1.1" class="ltx_text ltx_font_bold">Local model update and upload</span>: Training nodes are bid winners with capable devices and available sets of data samples. In each learning iteration, each training node updates a local ML model in a parallel manner by using the global model and its local data samples, and broadcasts its local model in the network. This article considers that local updates can be received by all miners through the gossip protocol <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> over the P2P network. In this context, the aggregation process in the traditional FL is decentralized to each client that stores the uploaded models in its model pool, respectively.</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<p id="S2.SS3.p3.1" class="ltx_p"><span id="S2.SS3.p3.1.1" class="ltx_text ltx_font_bold">Model aggregation</span>: After collecting the uploaded models in the pool, each client calculates the global model updates according to the aggregating rule in SC. In the proposed architecture, the clients are designed to aggregate the learning parameters truthfully through a distributed ledger. Similar to the prevailing block structure in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, each block in a ledger consists of the body and header parts. Concretely, the body stores the local model updates, such as the local data size and computing time of the associated training node and the aggregated learning parameters. The header contains the information of a pointer to the previous block, block generation rate, and the output value, such as the proof of work (PoW), in the consensus protocol.</p>
</div>
<div id="S2.SS3.p4" class="ltx_para">
<p id="S2.SS3.p4.1" class="ltx_p"><span id="S2.SS3.p4.1.1" class="ltx_text ltx_font_bold">Model recording and publishing</span>: The clients record the the aggregated models in their block and publish the recorded models by broadcasting the generated block to the whole network. The blocks can be generated by using distributed or lightweight consensus protocols, such as PoW, proof of stake (PoS), delegated PoS (DPoS), etc. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. In this article, we consider PoW due to its strong security over decentralized networks. This article uses a synchronous schedule to ensure that all miner start mining at the same time
Once a client find the hash value, its candidate block becomes to be a new block, and this block generation rate is controlled by the PoW difficulty. Then, this generated block is broadcasted to all other miners in the framework. All the other miners need to verify the nounce and the aggregated results contained in this block. For example, clients can compare the aggregated results with the one in the publishing block or use a public testing dataset to justify the effectiveness of the uploaded models. If the verification result is correct, other clients will accept it as a legal block and record it; otherwise, others will discard this generated block and continue to mine on the previous legal block.</p>
</div>
<div id="S2.SS3.p5" class="ltx_para">
<p id="S2.SS3.p5.1" class="ltx_p"><span id="S2.SS3.p5.1.1" class="ltx_text ltx_font_bold">Reward allocation</span>:
The task publisher provides learning rewards for the participating training nodes, and the volume can be proportional to the size of training data. It is noted that the reward mechanism can be further mended by combining consider the data size and the quality of data samples. In this case, clients are responsible to verify the trustworthiness of local updates after aggregation,
to address the situation that untruthful UEs may exaggerate their sample sizes with abnormal local model updates. Specifically, when clients calculate the rewards to each training node, they can give scores/reputations to the training nodes based on the model qualities. In the next aggregation, nodes with low scores will be given less weights, and identified and gradually ignored during the learning. In practice, this can be guaranteed by Intel’s software guard extensions, allowing applications to be operated within a protected environment, which has already been used in the blockchain technologies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>.
In addition, miners can also obtain rewards from mining and aggregating models, which can be treated as a gas tax in the traditional blockchain.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Unique Issues and potential solutions</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we describe three critical issues that the proposed framework may confront with, namely privacy, resource allocation, and lazy clients</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.4.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.5.2" class="ltx_text ltx_font_italic">Privacy</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">In the BLADE-FL, the roles of each client includes mining and training. To aggregate the global model, the trained local model will be published among clients which raises privacy issues. Previous works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, usually artificially assign the training and mining tasks to two disjoint sets of clients, and widely adopt that the miners are always trustful. However, if there exists an eavesdropper in the wireless environment, the published information of local models can cause privacy leakage. To address this, a differentially private mechanism can be implemented at the client side. In detail, keys steps are listed as follows:</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.3" class="ltx_p">Each client sets up a self-required privacy level for itself before training. For example, the <math id="S3.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.I1.i1.p1.1.m1.1a"><mi id="S3.I1.i1.p1.1.m1.1.1" xref="S3.I1.i1.p1.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.1.m1.1b"><ci id="S3.I1.i1.p1.1.m1.1.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.1.m1.1c">i</annotation></semantics></math>-th client may have a local privacy budget <math id="S3.I1.i1.p1.2.m2.1" class="ltx_Math" alttext="\epsilon_{i}" display="inline"><semantics id="S3.I1.i1.p1.2.m2.1a"><msub id="S3.I1.i1.p1.2.m2.1.1" xref="S3.I1.i1.p1.2.m2.1.1.cmml"><mi id="S3.I1.i1.p1.2.m2.1.1.2" xref="S3.I1.i1.p1.2.m2.1.1.2.cmml">ϵ</mi><mi id="S3.I1.i1.p1.2.m2.1.1.3" xref="S3.I1.i1.p1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.2.m2.1b"><apply id="S3.I1.i1.p1.2.m2.1.1.cmml" xref="S3.I1.i1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.I1.i1.p1.2.m2.1.1.1.cmml" xref="S3.I1.i1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.I1.i1.p1.2.m2.1.1.2.cmml" xref="S3.I1.i1.p1.2.m2.1.1.2">italic-ϵ</ci><ci id="S3.I1.i1.p1.2.m2.1.1.3.cmml" xref="S3.I1.i1.p1.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.2.m2.1c">\epsilon_{i}</annotation></semantics></math>. Note that a small value of <math id="S3.I1.i1.p1.3.m3.1" class="ltx_Math" alttext="\epsilon_{i}" display="inline"><semantics id="S3.I1.i1.p1.3.m3.1a"><msub id="S3.I1.i1.p1.3.m3.1.1" xref="S3.I1.i1.p1.3.m3.1.1.cmml"><mi id="S3.I1.i1.p1.3.m3.1.1.2" xref="S3.I1.i1.p1.3.m3.1.1.2.cmml">ϵ</mi><mi id="S3.I1.i1.p1.3.m3.1.1.3" xref="S3.I1.i1.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.3.m3.1b"><apply id="S3.I1.i1.p1.3.m3.1.1.cmml" xref="S3.I1.i1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.I1.i1.p1.3.m3.1.1.1.cmml" xref="S3.I1.i1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.I1.i1.p1.3.m3.1.1.2.cmml" xref="S3.I1.i1.p1.3.m3.1.1.2">italic-ϵ</ci><ci id="S3.I1.i1.p1.3.m3.1.1.3.cmml" xref="S3.I1.i1.p1.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.3.m3.1c">\epsilon_{i}</annotation></semantics></math> represents a high local privacy level, and will induce more additive noises on the parameters.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.3" class="ltx_p">To achieve a local differential privacy (LDP), each client will add a random noise which follows a certain distribution on the uploaded models. For example, a random Gaussian noise <math id="S3.I1.i2.p1.1.m1.2" class="ltx_Math" alttext="N(0,\sigma^{2})" display="inline"><semantics id="S3.I1.i2.p1.1.m1.2a"><mrow id="S3.I1.i2.p1.1.m1.2.2" xref="S3.I1.i2.p1.1.m1.2.2.cmml"><mi id="S3.I1.i2.p1.1.m1.2.2.3" xref="S3.I1.i2.p1.1.m1.2.2.3.cmml">N</mi><mo lspace="0em" rspace="0em" id="S3.I1.i2.p1.1.m1.2.2.2" xref="S3.I1.i2.p1.1.m1.2.2.2.cmml">​</mo><mrow id="S3.I1.i2.p1.1.m1.2.2.1.1" xref="S3.I1.i2.p1.1.m1.2.2.1.2.cmml"><mo stretchy="false" id="S3.I1.i2.p1.1.m1.2.2.1.1.2" xref="S3.I1.i2.p1.1.m1.2.2.1.2.cmml">(</mo><mn id="S3.I1.i2.p1.1.m1.1.1" xref="S3.I1.i2.p1.1.m1.1.1.cmml">0</mn><mo id="S3.I1.i2.p1.1.m1.2.2.1.1.3" xref="S3.I1.i2.p1.1.m1.2.2.1.2.cmml">,</mo><msup id="S3.I1.i2.p1.1.m1.2.2.1.1.1" xref="S3.I1.i2.p1.1.m1.2.2.1.1.1.cmml"><mi id="S3.I1.i2.p1.1.m1.2.2.1.1.1.2" xref="S3.I1.i2.p1.1.m1.2.2.1.1.1.2.cmml">σ</mi><mn id="S3.I1.i2.p1.1.m1.2.2.1.1.1.3" xref="S3.I1.i2.p1.1.m1.2.2.1.1.1.3.cmml">2</mn></msup><mo stretchy="false" id="S3.I1.i2.p1.1.m1.2.2.1.1.4" xref="S3.I1.i2.p1.1.m1.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.1.m1.2b"><apply id="S3.I1.i2.p1.1.m1.2.2.cmml" xref="S3.I1.i2.p1.1.m1.2.2"><times id="S3.I1.i2.p1.1.m1.2.2.2.cmml" xref="S3.I1.i2.p1.1.m1.2.2.2"></times><ci id="S3.I1.i2.p1.1.m1.2.2.3.cmml" xref="S3.I1.i2.p1.1.m1.2.2.3">𝑁</ci><interval closure="open" id="S3.I1.i2.p1.1.m1.2.2.1.2.cmml" xref="S3.I1.i2.p1.1.m1.2.2.1.1"><cn type="integer" id="S3.I1.i2.p1.1.m1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1">0</cn><apply id="S3.I1.i2.p1.1.m1.2.2.1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.I1.i2.p1.1.m1.2.2.1.1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.2.2.1.1.1">superscript</csymbol><ci id="S3.I1.i2.p1.1.m1.2.2.1.1.1.2.cmml" xref="S3.I1.i2.p1.1.m1.2.2.1.1.1.2">𝜎</ci><cn type="integer" id="S3.I1.i2.p1.1.m1.2.2.1.1.1.3.cmml" xref="S3.I1.i2.p1.1.m1.2.2.1.1.1.3">2</cn></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.1.m1.2c">N(0,\sigma^{2})</annotation></semantics></math> or a Laplace noise <math id="S3.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="Lap(\lambda)" display="inline"><semantics id="S3.I1.i2.p1.2.m2.1a"><mrow id="S3.I1.i2.p1.2.m2.1.2" xref="S3.I1.i2.p1.2.m2.1.2.cmml"><mi id="S3.I1.i2.p1.2.m2.1.2.2" xref="S3.I1.i2.p1.2.m2.1.2.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.I1.i2.p1.2.m2.1.2.1" xref="S3.I1.i2.p1.2.m2.1.2.1.cmml">​</mo><mi id="S3.I1.i2.p1.2.m2.1.2.3" xref="S3.I1.i2.p1.2.m2.1.2.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.I1.i2.p1.2.m2.1.2.1a" xref="S3.I1.i2.p1.2.m2.1.2.1.cmml">​</mo><mi id="S3.I1.i2.p1.2.m2.1.2.4" xref="S3.I1.i2.p1.2.m2.1.2.4.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.I1.i2.p1.2.m2.1.2.1b" xref="S3.I1.i2.p1.2.m2.1.2.1.cmml">​</mo><mrow id="S3.I1.i2.p1.2.m2.1.2.5.2" xref="S3.I1.i2.p1.2.m2.1.2.cmml"><mo stretchy="false" id="S3.I1.i2.p1.2.m2.1.2.5.2.1" xref="S3.I1.i2.p1.2.m2.1.2.cmml">(</mo><mi id="S3.I1.i2.p1.2.m2.1.1" xref="S3.I1.i2.p1.2.m2.1.1.cmml">λ</mi><mo stretchy="false" id="S3.I1.i2.p1.2.m2.1.2.5.2.2" xref="S3.I1.i2.p1.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.2.m2.1b"><apply id="S3.I1.i2.p1.2.m2.1.2.cmml" xref="S3.I1.i2.p1.2.m2.1.2"><times id="S3.I1.i2.p1.2.m2.1.2.1.cmml" xref="S3.I1.i2.p1.2.m2.1.2.1"></times><ci id="S3.I1.i2.p1.2.m2.1.2.2.cmml" xref="S3.I1.i2.p1.2.m2.1.2.2">𝐿</ci><ci id="S3.I1.i2.p1.2.m2.1.2.3.cmml" xref="S3.I1.i2.p1.2.m2.1.2.3">𝑎</ci><ci id="S3.I1.i2.p1.2.m2.1.2.4.cmml" xref="S3.I1.i2.p1.2.m2.1.2.4">𝑝</ci><ci id="S3.I1.i2.p1.2.m2.1.1.cmml" xref="S3.I1.i2.p1.2.m2.1.1">𝜆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.2.m2.1c">Lap(\lambda)</annotation></semantics></math> will be added. Note that, a large noise power, i.e., <math id="S3.I1.i2.p1.3.m3.1" class="ltx_Math" alttext="sigma^{2}" display="inline"><semantics id="S3.I1.i2.p1.3.m3.1a"><mrow id="S3.I1.i2.p1.3.m3.1.1" xref="S3.I1.i2.p1.3.m3.1.1.cmml"><mi id="S3.I1.i2.p1.3.m3.1.1.2" xref="S3.I1.i2.p1.3.m3.1.1.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.I1.i2.p1.3.m3.1.1.1" xref="S3.I1.i2.p1.3.m3.1.1.1.cmml">​</mo><mi id="S3.I1.i2.p1.3.m3.1.1.3" xref="S3.I1.i2.p1.3.m3.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.I1.i2.p1.3.m3.1.1.1a" xref="S3.I1.i2.p1.3.m3.1.1.1.cmml">​</mo><mi id="S3.I1.i2.p1.3.m3.1.1.4" xref="S3.I1.i2.p1.3.m3.1.1.4.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.I1.i2.p1.3.m3.1.1.1b" xref="S3.I1.i2.p1.3.m3.1.1.1.cmml">​</mo><mi id="S3.I1.i2.p1.3.m3.1.1.5" xref="S3.I1.i2.p1.3.m3.1.1.5.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.I1.i2.p1.3.m3.1.1.1c" xref="S3.I1.i2.p1.3.m3.1.1.1.cmml">​</mo><msup id="S3.I1.i2.p1.3.m3.1.1.6" xref="S3.I1.i2.p1.3.m3.1.1.6.cmml"><mi id="S3.I1.i2.p1.3.m3.1.1.6.2" xref="S3.I1.i2.p1.3.m3.1.1.6.2.cmml">a</mi><mn id="S3.I1.i2.p1.3.m3.1.1.6.3" xref="S3.I1.i2.p1.3.m3.1.1.6.3.cmml">2</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.3.m3.1b"><apply id="S3.I1.i2.p1.3.m3.1.1.cmml" xref="S3.I1.i2.p1.3.m3.1.1"><times id="S3.I1.i2.p1.3.m3.1.1.1.cmml" xref="S3.I1.i2.p1.3.m3.1.1.1"></times><ci id="S3.I1.i2.p1.3.m3.1.1.2.cmml" xref="S3.I1.i2.p1.3.m3.1.1.2">𝑠</ci><ci id="S3.I1.i2.p1.3.m3.1.1.3.cmml" xref="S3.I1.i2.p1.3.m3.1.1.3">𝑖</ci><ci id="S3.I1.i2.p1.3.m3.1.1.4.cmml" xref="S3.I1.i2.p1.3.m3.1.1.4">𝑔</ci><ci id="S3.I1.i2.p1.3.m3.1.1.5.cmml" xref="S3.I1.i2.p1.3.m3.1.1.5">𝑚</ci><apply id="S3.I1.i2.p1.3.m3.1.1.6.cmml" xref="S3.I1.i2.p1.3.m3.1.1.6"><csymbol cd="ambiguous" id="S3.I1.i2.p1.3.m3.1.1.6.1.cmml" xref="S3.I1.i2.p1.3.m3.1.1.6">superscript</csymbol><ci id="S3.I1.i2.p1.3.m3.1.1.6.2.cmml" xref="S3.I1.i2.p1.3.m3.1.1.6.2">𝑎</ci><cn type="integer" id="S3.I1.i2.p1.3.m3.1.1.6.3.cmml" xref="S3.I1.i2.p1.3.m3.1.1.6.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.3.m3.1c">sigma^{2}</annotation></semantics></math> implies a high privacy level.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p">Upon receiving the perturbed models, all clients can aggregate the global model locally, and store it in the generated block. Because of the injected noise, the learning convergence as well as the system performance will be negatively affected. A tradeoff between the privacy requirement and the learning performance needs further investigation. In addition, an non-uniform allocation of additive noise over communication rounds may improve the learning performance. For example, a decay rate for the noise power can be applied when the learning accuracy between two adjacent communication rounds stops improving <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.4.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.5.2" class="ltx_text ltx_font_italic">Computing Resource Allocation</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Since the computation resource is limited at each client, each participant needs to appropriately allocate the resources for local training and mining to complete the task. Specifically, more computing resources can be devoted to either faster model update or block generation. To meet the specific task requirements, such as learning difficulty, accuracy, and delay, each node optimizes its allocation strategy to maximize its reward under constraints of local capability.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">According to the constraints, the computation resource allocation can be formulated as an optimization problem under the accurate mathematical model. In details:</p>
<ul id="S3.I2" class="ltx_itemize">
<li id="S3.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i1.p1" class="ltx_para">
<p id="S3.I2.i1.p1.7" class="ltx_p">The block generation rate is determined by the computation complexity of the hash function and the total computing power of the blockchain network (i.e., total CPU cycles). The average CPU cycles required to generate a block can be defined as <math id="S3.I2.i1.p1.1.m1.1" class="ltx_Math" alttext="kc_{\textrm{B}}" display="inline"><semantics id="S3.I2.i1.p1.1.m1.1a"><mrow id="S3.I2.i1.p1.1.m1.1.1" xref="S3.I2.i1.p1.1.m1.1.1.cmml"><mi id="S3.I2.i1.p1.1.m1.1.1.2" xref="S3.I2.i1.p1.1.m1.1.1.2.cmml">k</mi><mo lspace="0em" rspace="0em" id="S3.I2.i1.p1.1.m1.1.1.1" xref="S3.I2.i1.p1.1.m1.1.1.1.cmml">​</mo><msub id="S3.I2.i1.p1.1.m1.1.1.3" xref="S3.I2.i1.p1.1.m1.1.1.3.cmml"><mi id="S3.I2.i1.p1.1.m1.1.1.3.2" xref="S3.I2.i1.p1.1.m1.1.1.3.2.cmml">c</mi><mtext id="S3.I2.i1.p1.1.m1.1.1.3.3" xref="S3.I2.i1.p1.1.m1.1.1.3.3a.cmml">B</mtext></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.I2.i1.p1.1.m1.1b"><apply id="S3.I2.i1.p1.1.m1.1.1.cmml" xref="S3.I2.i1.p1.1.m1.1.1"><times id="S3.I2.i1.p1.1.m1.1.1.1.cmml" xref="S3.I2.i1.p1.1.m1.1.1.1"></times><ci id="S3.I2.i1.p1.1.m1.1.1.2.cmml" xref="S3.I2.i1.p1.1.m1.1.1.2">𝑘</ci><apply id="S3.I2.i1.p1.1.m1.1.1.3.cmml" xref="S3.I2.i1.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.I2.i1.p1.1.m1.1.1.3.1.cmml" xref="S3.I2.i1.p1.1.m1.1.1.3">subscript</csymbol><ci id="S3.I2.i1.p1.1.m1.1.1.3.2.cmml" xref="S3.I2.i1.p1.1.m1.1.1.3.2">𝑐</ci><ci id="S3.I2.i1.p1.1.m1.1.1.3.3a.cmml" xref="S3.I2.i1.p1.1.m1.1.1.3.3"><mtext mathsize="70%" id="S3.I2.i1.p1.1.m1.1.1.3.3.cmml" xref="S3.I2.i1.p1.1.m1.1.1.3.3">B</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i1.p1.1.m1.1c">kc_{\textrm{B}}</annotation></semantics></math>, where <math id="S3.I2.i1.p1.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.I2.i1.p1.2.m2.1a"><mi id="S3.I2.i1.p1.2.m2.1.1" xref="S3.I2.i1.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.I2.i1.p1.2.m2.1b"><ci id="S3.I2.i1.p1.2.m2.1.1.cmml" xref="S3.I2.i1.p1.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i1.p1.2.m2.1c">k</annotation></semantics></math> denotes the mining difficulty, and <math id="S3.I2.i1.p1.3.m3.1" class="ltx_Math" alttext="c_{\textrm{B}}" display="inline"><semantics id="S3.I2.i1.p1.3.m3.1a"><msub id="S3.I2.i1.p1.3.m3.1.1" xref="S3.I2.i1.p1.3.m3.1.1.cmml"><mi id="S3.I2.i1.p1.3.m3.1.1.2" xref="S3.I2.i1.p1.3.m3.1.1.2.cmml">c</mi><mtext id="S3.I2.i1.p1.3.m3.1.1.3" xref="S3.I2.i1.p1.3.m3.1.1.3a.cmml">B</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.I2.i1.p1.3.m3.1b"><apply id="S3.I2.i1.p1.3.m3.1.1.cmml" xref="S3.I2.i1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.I2.i1.p1.3.m3.1.1.1.cmml" xref="S3.I2.i1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.I2.i1.p1.3.m3.1.1.2.cmml" xref="S3.I2.i1.p1.3.m3.1.1.2">𝑐</ci><ci id="S3.I2.i1.p1.3.m3.1.1.3a.cmml" xref="S3.I2.i1.p1.3.m3.1.1.3"><mtext mathsize="70%" id="S3.I2.i1.p1.3.m3.1.1.3.cmml" xref="S3.I2.i1.p1.3.m3.1.1.3">B</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i1.p1.3.m3.1c">c_{\textrm{B}}</annotation></semantics></math> denotes the average number of total CPU cycles to generate a block. Thus, the average generation time of a block (<math id="S3.I2.i1.p1.4.m4.1" class="ltx_Math" alttext="t_{\textrm{B}}" display="inline"><semantics id="S3.I2.i1.p1.4.m4.1a"><msub id="S3.I2.i1.p1.4.m4.1.1" xref="S3.I2.i1.p1.4.m4.1.1.cmml"><mi id="S3.I2.i1.p1.4.m4.1.1.2" xref="S3.I2.i1.p1.4.m4.1.1.2.cmml">t</mi><mtext id="S3.I2.i1.p1.4.m4.1.1.3" xref="S3.I2.i1.p1.4.m4.1.1.3a.cmml">B</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.I2.i1.p1.4.m4.1b"><apply id="S3.I2.i1.p1.4.m4.1.1.cmml" xref="S3.I2.i1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.I2.i1.p1.4.m4.1.1.1.cmml" xref="S3.I2.i1.p1.4.m4.1.1">subscript</csymbol><ci id="S3.I2.i1.p1.4.m4.1.1.2.cmml" xref="S3.I2.i1.p1.4.m4.1.1.2">𝑡</ci><ci id="S3.I2.i1.p1.4.m4.1.1.3a.cmml" xref="S3.I2.i1.p1.4.m4.1.1.3"><mtext mathsize="70%" id="S3.I2.i1.p1.4.m4.1.1.3.cmml" xref="S3.I2.i1.p1.4.m4.1.1.3">B</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i1.p1.4.m4.1c">t_{\textrm{B}}</annotation></semantics></math>) can be expressed as <math id="S3.I2.i1.p1.5.m5.1" class="ltx_Math" alttext="\frac{kc_{\textrm{B}}}{Nf}" display="inline"><semantics id="S3.I2.i1.p1.5.m5.1a"><mfrac id="S3.I2.i1.p1.5.m5.1.1" xref="S3.I2.i1.p1.5.m5.1.1.cmml"><mrow id="S3.I2.i1.p1.5.m5.1.1.2" xref="S3.I2.i1.p1.5.m5.1.1.2.cmml"><mi id="S3.I2.i1.p1.5.m5.1.1.2.2" xref="S3.I2.i1.p1.5.m5.1.1.2.2.cmml">k</mi><mo lspace="0em" rspace="0em" id="S3.I2.i1.p1.5.m5.1.1.2.1" xref="S3.I2.i1.p1.5.m5.1.1.2.1.cmml">​</mo><msub id="S3.I2.i1.p1.5.m5.1.1.2.3" xref="S3.I2.i1.p1.5.m5.1.1.2.3.cmml"><mi id="S3.I2.i1.p1.5.m5.1.1.2.3.2" xref="S3.I2.i1.p1.5.m5.1.1.2.3.2.cmml">c</mi><mtext id="S3.I2.i1.p1.5.m5.1.1.2.3.3" xref="S3.I2.i1.p1.5.m5.1.1.2.3.3a.cmml">B</mtext></msub></mrow><mrow id="S3.I2.i1.p1.5.m5.1.1.3" xref="S3.I2.i1.p1.5.m5.1.1.3.cmml"><mi id="S3.I2.i1.p1.5.m5.1.1.3.2" xref="S3.I2.i1.p1.5.m5.1.1.3.2.cmml">N</mi><mo lspace="0em" rspace="0em" id="S3.I2.i1.p1.5.m5.1.1.3.1" xref="S3.I2.i1.p1.5.m5.1.1.3.1.cmml">​</mo><mi id="S3.I2.i1.p1.5.m5.1.1.3.3" xref="S3.I2.i1.p1.5.m5.1.1.3.3.cmml">f</mi></mrow></mfrac><annotation-xml encoding="MathML-Content" id="S3.I2.i1.p1.5.m5.1b"><apply id="S3.I2.i1.p1.5.m5.1.1.cmml" xref="S3.I2.i1.p1.5.m5.1.1"><divide id="S3.I2.i1.p1.5.m5.1.1.1.cmml" xref="S3.I2.i1.p1.5.m5.1.1"></divide><apply id="S3.I2.i1.p1.5.m5.1.1.2.cmml" xref="S3.I2.i1.p1.5.m5.1.1.2"><times id="S3.I2.i1.p1.5.m5.1.1.2.1.cmml" xref="S3.I2.i1.p1.5.m5.1.1.2.1"></times><ci id="S3.I2.i1.p1.5.m5.1.1.2.2.cmml" xref="S3.I2.i1.p1.5.m5.1.1.2.2">𝑘</ci><apply id="S3.I2.i1.p1.5.m5.1.1.2.3.cmml" xref="S3.I2.i1.p1.5.m5.1.1.2.3"><csymbol cd="ambiguous" id="S3.I2.i1.p1.5.m5.1.1.2.3.1.cmml" xref="S3.I2.i1.p1.5.m5.1.1.2.3">subscript</csymbol><ci id="S3.I2.i1.p1.5.m5.1.1.2.3.2.cmml" xref="S3.I2.i1.p1.5.m5.1.1.2.3.2">𝑐</ci><ci id="S3.I2.i1.p1.5.m5.1.1.2.3.3a.cmml" xref="S3.I2.i1.p1.5.m5.1.1.2.3.3"><mtext mathsize="50%" id="S3.I2.i1.p1.5.m5.1.1.2.3.3.cmml" xref="S3.I2.i1.p1.5.m5.1.1.2.3.3">B</mtext></ci></apply></apply><apply id="S3.I2.i1.p1.5.m5.1.1.3.cmml" xref="S3.I2.i1.p1.5.m5.1.1.3"><times id="S3.I2.i1.p1.5.m5.1.1.3.1.cmml" xref="S3.I2.i1.p1.5.m5.1.1.3.1"></times><ci id="S3.I2.i1.p1.5.m5.1.1.3.2.cmml" xref="S3.I2.i1.p1.5.m5.1.1.3.2">𝑁</ci><ci id="S3.I2.i1.p1.5.m5.1.1.3.3.cmml" xref="S3.I2.i1.p1.5.m5.1.1.3.3">𝑓</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i1.p1.5.m5.1c">\frac{kc_{\textrm{B}}}{Nf}</annotation></semantics></math>, where <math id="S3.I2.i1.p1.6.m6.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.I2.i1.p1.6.m6.1a"><mi id="S3.I2.i1.p1.6.m6.1.1" xref="S3.I2.i1.p1.6.m6.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.I2.i1.p1.6.m6.1b"><ci id="S3.I2.i1.p1.6.m6.1.1.cmml" xref="S3.I2.i1.p1.6.m6.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i1.p1.6.m6.1c">N</annotation></semantics></math> is the number of clients, and <math id="S3.I2.i1.p1.7.m7.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S3.I2.i1.p1.7.m7.1a"><mi id="S3.I2.i1.p1.7.m7.1.1" xref="S3.I2.i1.p1.7.m7.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S3.I2.i1.p1.7.m7.1b"><ci id="S3.I2.i1.p1.7.m7.1.1.cmml" xref="S3.I2.i1.p1.7.m7.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i1.p1.7.m7.1c">f</annotation></semantics></math> denotes the CPU cycles per second of each client.</p>
</div>
</li>
<li id="S3.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i2.p1" class="ltx_para">
<p id="S3.I2.i2.p1.4" class="ltx_p">The training time consumed by each training iteration <math id="S3.I2.i2.p1.1.m1.1" class="ltx_Math" alttext="t_{\textrm{T}}" display="inline"><semantics id="S3.I2.i2.p1.1.m1.1a"><msub id="S3.I2.i2.p1.1.m1.1.1" xref="S3.I2.i2.p1.1.m1.1.1.cmml"><mi id="S3.I2.i2.p1.1.m1.1.1.2" xref="S3.I2.i2.p1.1.m1.1.1.2.cmml">t</mi><mtext id="S3.I2.i2.p1.1.m1.1.1.3" xref="S3.I2.i2.p1.1.m1.1.1.3a.cmml">T</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.I2.i2.p1.1.m1.1b"><apply id="S3.I2.i2.p1.1.m1.1.1.cmml" xref="S3.I2.i2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.I2.i2.p1.1.m1.1.1.1.cmml" xref="S3.I2.i2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.I2.i2.p1.1.m1.1.1.2.cmml" xref="S3.I2.i2.p1.1.m1.1.1.2">𝑡</ci><ci id="S3.I2.i2.p1.1.m1.1.1.3a.cmml" xref="S3.I2.i2.p1.1.m1.1.1.3"><mtext mathsize="70%" id="S3.I2.i2.p1.1.m1.1.1.3.cmml" xref="S3.I2.i2.p1.1.m1.1.1.3">T</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i2.p1.1.m1.1c">t_{\textrm{T}}</annotation></semantics></math> can be expressed as <math id="S3.I2.i2.p1.2.m2.1" class="ltx_Math" alttext="\frac{|D|c_{\textrm{T}}}{f}" display="inline"><semantics id="S3.I2.i2.p1.2.m2.1a"><mfrac id="S3.I2.i2.p1.2.m2.1.1" xref="S3.I2.i2.p1.2.m2.1.1.cmml"><mrow id="S3.I2.i2.p1.2.m2.1.1.1" xref="S3.I2.i2.p1.2.m2.1.1.1.cmml"><mrow id="S3.I2.i2.p1.2.m2.1.1.1.3.2" xref="S3.I2.i2.p1.2.m2.1.1.1.3.1.cmml"><mo stretchy="false" id="S3.I2.i2.p1.2.m2.1.1.1.3.2.1" xref="S3.I2.i2.p1.2.m2.1.1.1.3.1.1.cmml">|</mo><mi id="S3.I2.i2.p1.2.m2.1.1.1.1" xref="S3.I2.i2.p1.2.m2.1.1.1.1.cmml">D</mi><mo stretchy="false" id="S3.I2.i2.p1.2.m2.1.1.1.3.2.2" xref="S3.I2.i2.p1.2.m2.1.1.1.3.1.1.cmml">|</mo></mrow><mo lspace="0em" rspace="0em" id="S3.I2.i2.p1.2.m2.1.1.1.2" xref="S3.I2.i2.p1.2.m2.1.1.1.2.cmml">​</mo><msub id="S3.I2.i2.p1.2.m2.1.1.1.4" xref="S3.I2.i2.p1.2.m2.1.1.1.4.cmml"><mi id="S3.I2.i2.p1.2.m2.1.1.1.4.2" xref="S3.I2.i2.p1.2.m2.1.1.1.4.2.cmml">c</mi><mtext id="S3.I2.i2.p1.2.m2.1.1.1.4.3" xref="S3.I2.i2.p1.2.m2.1.1.1.4.3a.cmml">T</mtext></msub></mrow><mi id="S3.I2.i2.p1.2.m2.1.1.3" xref="S3.I2.i2.p1.2.m2.1.1.3.cmml">f</mi></mfrac><annotation-xml encoding="MathML-Content" id="S3.I2.i2.p1.2.m2.1b"><apply id="S3.I2.i2.p1.2.m2.1.1.cmml" xref="S3.I2.i2.p1.2.m2.1.1"><divide id="S3.I2.i2.p1.2.m2.1.1.2.cmml" xref="S3.I2.i2.p1.2.m2.1.1"></divide><apply id="S3.I2.i2.p1.2.m2.1.1.1.cmml" xref="S3.I2.i2.p1.2.m2.1.1.1"><times id="S3.I2.i2.p1.2.m2.1.1.1.2.cmml" xref="S3.I2.i2.p1.2.m2.1.1.1.2"></times><apply id="S3.I2.i2.p1.2.m2.1.1.1.3.1.cmml" xref="S3.I2.i2.p1.2.m2.1.1.1.3.2"><abs id="S3.I2.i2.p1.2.m2.1.1.1.3.1.1.cmml" xref="S3.I2.i2.p1.2.m2.1.1.1.3.2.1"></abs><ci id="S3.I2.i2.p1.2.m2.1.1.1.1.cmml" xref="S3.I2.i2.p1.2.m2.1.1.1.1">𝐷</ci></apply><apply id="S3.I2.i2.p1.2.m2.1.1.1.4.cmml" xref="S3.I2.i2.p1.2.m2.1.1.1.4"><csymbol cd="ambiguous" id="S3.I2.i2.p1.2.m2.1.1.1.4.1.cmml" xref="S3.I2.i2.p1.2.m2.1.1.1.4">subscript</csymbol><ci id="S3.I2.i2.p1.2.m2.1.1.1.4.2.cmml" xref="S3.I2.i2.p1.2.m2.1.1.1.4.2">𝑐</ci><ci id="S3.I2.i2.p1.2.m2.1.1.1.4.3a.cmml" xref="S3.I2.i2.p1.2.m2.1.1.1.4.3"><mtext mathsize="50%" id="S3.I2.i2.p1.2.m2.1.1.1.4.3.cmml" xref="S3.I2.i2.p1.2.m2.1.1.1.4.3">T</mtext></ci></apply></apply><ci id="S3.I2.i2.p1.2.m2.1.1.3.cmml" xref="S3.I2.i2.p1.2.m2.1.1.3">𝑓</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i2.p1.2.m2.1c">\frac{|D|c_{\textrm{T}}}{f}</annotation></semantics></math>, where <math id="S3.I2.i2.p1.3.m3.1" class="ltx_Math" alttext="|D|" display="inline"><semantics id="S3.I2.i2.p1.3.m3.1a"><mrow id="S3.I2.i2.p1.3.m3.1.2.2" xref="S3.I2.i2.p1.3.m3.1.2.1.cmml"><mo stretchy="false" id="S3.I2.i2.p1.3.m3.1.2.2.1" xref="S3.I2.i2.p1.3.m3.1.2.1.1.cmml">|</mo><mi id="S3.I2.i2.p1.3.m3.1.1" xref="S3.I2.i2.p1.3.m3.1.1.cmml">D</mi><mo stretchy="false" id="S3.I2.i2.p1.3.m3.1.2.2.2" xref="S3.I2.i2.p1.3.m3.1.2.1.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.I2.i2.p1.3.m3.1b"><apply id="S3.I2.i2.p1.3.m3.1.2.1.cmml" xref="S3.I2.i2.p1.3.m3.1.2.2"><abs id="S3.I2.i2.p1.3.m3.1.2.1.1.cmml" xref="S3.I2.i2.p1.3.m3.1.2.2.1"></abs><ci id="S3.I2.i2.p1.3.m3.1.1.cmml" xref="S3.I2.i2.p1.3.m3.1.1">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i2.p1.3.m3.1c">|D|</annotation></semantics></math> denotes the number of samples of each client, and <math id="S3.I2.i2.p1.4.m4.1" class="ltx_Math" alttext="c_{\textrm{T}}" display="inline"><semantics id="S3.I2.i2.p1.4.m4.1a"><msub id="S3.I2.i2.p1.4.m4.1.1" xref="S3.I2.i2.p1.4.m4.1.1.cmml"><mi id="S3.I2.i2.p1.4.m4.1.1.2" xref="S3.I2.i2.p1.4.m4.1.1.2.cmml">c</mi><mtext id="S3.I2.i2.p1.4.m4.1.1.3" xref="S3.I2.i2.p1.4.m4.1.1.3a.cmml">T</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.I2.i2.p1.4.m4.1b"><apply id="S3.I2.i2.p1.4.m4.1.1.cmml" xref="S3.I2.i2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.I2.i2.p1.4.m4.1.1.1.cmml" xref="S3.I2.i2.p1.4.m4.1.1">subscript</csymbol><ci id="S3.I2.i2.p1.4.m4.1.1.2.cmml" xref="S3.I2.i2.p1.4.m4.1.1.2">𝑐</ci><ci id="S3.I2.i2.p1.4.m4.1.1.3a.cmml" xref="S3.I2.i2.p1.4.m4.1.1.3"><mtext mathsize="70%" id="S3.I2.i2.p1.4.m4.1.1.3.cmml" xref="S3.I2.i2.p1.4.m4.1.1.3">T</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i2.p1.4.m4.1c">c_{\textrm{T}}</annotation></semantics></math> denotes the number of CPU cycles required to train one sample.</p>
</div>
</li>
<li id="S3.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i3.p1" class="ltx_para">
<p id="S3.I2.i3.p1.5" class="ltx_p">Considering that a typical FL learning task is required to be accomplished within a fixed duration of <math id="S3.I2.i3.p1.1.m1.1" class="ltx_Math" alttext="T_{\textrm{Sum}}" display="inline"><semantics id="S3.I2.i3.p1.1.m1.1a"><msub id="S3.I2.i3.p1.1.m1.1.1" xref="S3.I2.i3.p1.1.m1.1.1.cmml"><mi id="S3.I2.i3.p1.1.m1.1.1.2" xref="S3.I2.i3.p1.1.m1.1.1.2.cmml">T</mi><mtext id="S3.I2.i3.p1.1.m1.1.1.3" xref="S3.I2.i3.p1.1.m1.1.1.3a.cmml">Sum</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.I2.i3.p1.1.m1.1b"><apply id="S3.I2.i3.p1.1.m1.1.1.cmml" xref="S3.I2.i3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.I2.i3.p1.1.m1.1.1.1.cmml" xref="S3.I2.i3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.I2.i3.p1.1.m1.1.1.2.cmml" xref="S3.I2.i3.p1.1.m1.1.1.2">𝑇</ci><ci id="S3.I2.i3.p1.1.m1.1.1.3a.cmml" xref="S3.I2.i3.p1.1.m1.1.1.3"><mtext mathsize="70%" id="S3.I2.i3.p1.1.m1.1.1.3.cmml" xref="S3.I2.i3.p1.1.m1.1.1.3">Sum</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i3.p1.1.m1.1c">T_{\textrm{Sum}}</annotation></semantics></math>, it should satisfy that <math id="S3.I2.i3.p1.2.m2.1" class="ltx_Math" alttext="K(\tau t_{\textrm{T}}+t_{\textrm{B}})\leq T_{\textrm{Sum}}" display="inline"><semantics id="S3.I2.i3.p1.2.m2.1a"><mrow id="S3.I2.i3.p1.2.m2.1.1" xref="S3.I2.i3.p1.2.m2.1.1.cmml"><mrow id="S3.I2.i3.p1.2.m2.1.1.1" xref="S3.I2.i3.p1.2.m2.1.1.1.cmml"><mi id="S3.I2.i3.p1.2.m2.1.1.1.3" xref="S3.I2.i3.p1.2.m2.1.1.1.3.cmml">K</mi><mo lspace="0em" rspace="0em" id="S3.I2.i3.p1.2.m2.1.1.1.2" xref="S3.I2.i3.p1.2.m2.1.1.1.2.cmml">​</mo><mrow id="S3.I2.i3.p1.2.m2.1.1.1.1.1" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.I2.i3.p1.2.m2.1.1.1.1.1.2" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.cmml"><mrow id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.2" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.2.cmml"><mi id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.2.2" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.2.2.cmml">τ</mi><mo lspace="0em" rspace="0em" id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.2.1" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.2.1.cmml">​</mo><msub id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.2.3" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.2.3.cmml"><mi id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.2.3.2" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.2.3.2.cmml">t</mi><mtext id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.2.3.3" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.2.3.3a.cmml">T</mtext></msub></mrow><mo id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1.cmml">+</mo><msub id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.3" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.3.cmml"><mi id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.3.2" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.3.2.cmml">t</mi><mtext id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.3.3" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.3.3a.cmml">B</mtext></msub></mrow><mo stretchy="false" id="S3.I2.i3.p1.2.m2.1.1.1.1.1.3" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.I2.i3.p1.2.m2.1.1.2" xref="S3.I2.i3.p1.2.m2.1.1.2.cmml">≤</mo><msub id="S3.I2.i3.p1.2.m2.1.1.3" xref="S3.I2.i3.p1.2.m2.1.1.3.cmml"><mi id="S3.I2.i3.p1.2.m2.1.1.3.2" xref="S3.I2.i3.p1.2.m2.1.1.3.2.cmml">T</mi><mtext id="S3.I2.i3.p1.2.m2.1.1.3.3" xref="S3.I2.i3.p1.2.m2.1.1.3.3a.cmml">Sum</mtext></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.I2.i3.p1.2.m2.1b"><apply id="S3.I2.i3.p1.2.m2.1.1.cmml" xref="S3.I2.i3.p1.2.m2.1.1"><leq id="S3.I2.i3.p1.2.m2.1.1.2.cmml" xref="S3.I2.i3.p1.2.m2.1.1.2"></leq><apply id="S3.I2.i3.p1.2.m2.1.1.1.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1"><times id="S3.I2.i3.p1.2.m2.1.1.1.2.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.2"></times><ci id="S3.I2.i3.p1.2.m2.1.1.1.3.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.3">𝐾</ci><apply id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1"><plus id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.1"></plus><apply id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.2.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.2"><times id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.2.1.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.2.1"></times><ci id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.2.2.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.2.2">𝜏</ci><apply id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.2.3.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.2.3.1.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.2.3">subscript</csymbol><ci id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.2.3.2.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.2.3.2">𝑡</ci><ci id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.2.3.3a.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.2.3.3"><mtext mathsize="70%" id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.2.3.3.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.2.3.3">T</mtext></ci></apply></apply><apply id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.3.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.3.1.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.3.2.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.3.2">𝑡</ci><ci id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.3.3a.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.3.3"><mtext mathsize="70%" id="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.3.3.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1.1.1.1.3.3">B</mtext></ci></apply></apply></apply><apply id="S3.I2.i3.p1.2.m2.1.1.3.cmml" xref="S3.I2.i3.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.I2.i3.p1.2.m2.1.1.3.1.cmml" xref="S3.I2.i3.p1.2.m2.1.1.3">subscript</csymbol><ci id="S3.I2.i3.p1.2.m2.1.1.3.2.cmml" xref="S3.I2.i3.p1.2.m2.1.1.3.2">𝑇</ci><ci id="S3.I2.i3.p1.2.m2.1.1.3.3a.cmml" xref="S3.I2.i3.p1.2.m2.1.1.3.3"><mtext mathsize="70%" id="S3.I2.i3.p1.2.m2.1.1.3.3.cmml" xref="S3.I2.i3.p1.2.m2.1.1.3.3">Sum</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i3.p1.2.m2.1c">K(\tau t_{\textrm{T}}+t_{\textrm{B}})\leq T_{\textrm{Sum}}</annotation></semantics></math>, where <math id="S3.I2.i3.p1.3.m3.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.I2.i3.p1.3.m3.1a"><mi id="S3.I2.i3.p1.3.m3.1.1" xref="S3.I2.i3.p1.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.I2.i3.p1.3.m3.1b"><ci id="S3.I2.i3.p1.3.m3.1.1.cmml" xref="S3.I2.i3.p1.3.m3.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i3.p1.3.m3.1c">K</annotation></semantics></math> denotes the total communication round, and <math id="S3.I2.i3.p1.4.m4.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S3.I2.i3.p1.4.m4.1a"><mi id="S3.I2.i3.p1.4.m4.1.1" xref="S3.I2.i3.p1.4.m4.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="S3.I2.i3.p1.4.m4.1b"><ci id="S3.I2.i3.p1.4.m4.1.1.cmml" xref="S3.I2.i3.p1.4.m4.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i3.p1.4.m4.1c">\tau</annotation></semantics></math> denotes the local training epoches. Thus, to achieve a required learning performance, an appropriate choice for the communication round <math id="S3.I2.i3.p1.5.m5.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.I2.i3.p1.5.m5.1a"><mi id="S3.I2.i3.p1.5.m5.1.1" xref="S3.I2.i3.p1.5.m5.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.I2.i3.p1.5.m5.1b"><ci id="S3.I2.i3.p1.5.m5.1.1.cmml" xref="S3.I2.i3.p1.5.m5.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i3.p1.5.m5.1c">K</annotation></semantics></math> should be investigated under a certain ratio between the computing and mining time.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.4.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.5.2" class="ltx_text ltx_font_italic">Lazy nodes</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">As the verification is processed locally, a lazy client may not perform local learning and directly copy uploaded parameters from other clients to save its computing resource. As a result, the client can devote more mining resources to reaping more mining rewards with a higher probability. However, this action significantly degrades the network learning performance. To investigate the effect of lazy nodes on the system performance, we provide related experimental results in Sec. V-D.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">To address the lazy client issue, we can implement a signature process at each client, which is based on the pseudo-noise (PN) sequence. Note that the signature mechanism here is completely different from the digital signature. What we need is a signature that is resilient to noise perturbation because the lazy clients are likely to perturb the plagiarized local models to hide the misbehavior. This process will introduce a negligible burden to the system but can provide a high detection accuracy. In details,</p>
<ul id="S3.I3" class="ltx_itemize">
<li id="S3.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i1.p1" class="ltx_para">
<p id="S3.I3.i1.p1.2" class="ltx_p">Before broadcasting the local updates, each client will produce a PN sequence with a length <math id="S3.I3.i1.p1.1.m1.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.I3.i1.p1.1.m1.1a"><mi id="S3.I3.i1.p1.1.m1.1.1" xref="S3.I3.i1.p1.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.I3.i1.p1.1.m1.1b"><ci id="S3.I3.i1.p1.1.m1.1.1.cmml" xref="S3.I3.i1.p1.1.m1.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I3.i1.p1.1.m1.1c">L</annotation></semantics></math>, where <math id="S3.I3.i1.p1.2.m2.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.I3.i1.p1.2.m2.1a"><mi id="S3.I3.i1.p1.2.m2.1.1" xref="S3.I3.i1.p1.2.m2.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.I3.i1.p1.2.m2.1b"><ci id="S3.I3.i1.p1.2.m2.1.1.cmml" xref="S3.I3.i1.p1.2.m2.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I3.i1.p1.2.m2.1c">L</annotation></semantics></math> is usually a very large number (larger than the number of model parameters) and we select a same length with model parameters and add them to the updates. This PN sequence has a high self-correlation coefficient and is hard to detect or re-produce by other clients. At least, the complexity of detecting the PN sequence should be much larger than that of training the neural network so as to deter the attempt to discover the used PN sequence.</p>
</div>
</li>
<li id="S3.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i2.p1" class="ltx_para">
<p id="S3.I3.i2.p1.1" class="ltx_p">Upon receiving local updates from the other clients, each client will use its own PN sequence to check the correlation coefficient with the updates. If there exists high peaks in terms of the cross-correlation coefficient, then the lazy clients will be detected.</p>
</div>
</li>
<li id="S3.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i3.p1" class="ltx_para">
<p id="S3.I3.i3.p1.1" class="ltx_p">Once a lazy client is recognized by a local client, this client can publish the previously used PN sequence to others and invite other honest clients to verify this process. Then any future updates from the lazy client might be discarded as punishments.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Experimental Results and Probable Solutions</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we provide some experimental results to show the issues in the multi-functional miner in the proposed BLADE-FL system.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.4.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.5.2" class="ltx_text ltx_font_italic">System setup</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.7" class="ltx_p">For each experiment, we first divide the original training data into non i.i.d. training sets, locally compute a stochastic gradient descend (SGD) update on each dataset, and then aggregate updates to train a globally shared classifier. We evaluate the prototype on the Fashion-MNIST dataset and Cifar-10 data. In the following results, we collect 20 runs for each experiment and record the average results.
For the blockchain setup, we set the total computation resource <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="T_{\textrm{Sum}}=200" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mrow id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><msub id="S4.SS1.p1.1.m1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.2.cmml"><mi id="S4.SS1.p1.1.m1.1.1.2.2" xref="S4.SS1.p1.1.m1.1.1.2.2.cmml">T</mi><mtext id="S4.SS1.p1.1.m1.1.1.2.3" xref="S4.SS1.p1.1.m1.1.1.2.3a.cmml">Sum</mtext></msub><mo id="S4.SS1.p1.1.m1.1.1.1" xref="S4.SS1.p1.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS1.p1.1.m1.1.1.3" xref="S4.SS1.p1.1.m1.1.1.3.cmml">200</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><eq id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1.1"></eq><apply id="S4.SS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.1.1.2.1.cmml" xref="S4.SS1.p1.1.m1.1.1.2">subscript</csymbol><ci id="S4.SS1.p1.1.m1.1.1.2.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2.2">𝑇</ci><ci id="S4.SS1.p1.1.m1.1.1.2.3a.cmml" xref="S4.SS1.p1.1.m1.1.1.2.3"><mtext mathsize="70%" id="S4.SS1.p1.1.m1.1.1.2.3.cmml" xref="S4.SS1.p1.1.m1.1.1.2.3">Sum</mtext></ci></apply><cn type="integer" id="S4.SS1.p1.1.m1.1.1.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3">200</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">T_{\textrm{Sum}}=200</annotation></semantics></math> for each training node, and the total number of clients is set to <math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="N=20" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><mrow id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml"><mi id="S4.SS1.p1.2.m2.1.1.2" xref="S4.SS1.p1.2.m2.1.1.2.cmml">N</mi><mo id="S4.SS1.p1.2.m2.1.1.1" xref="S4.SS1.p1.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS1.p1.2.m2.1.1.3" xref="S4.SS1.p1.2.m2.1.1.3.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><apply id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1"><eq id="S4.SS1.p1.2.m2.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1.1"></eq><ci id="S4.SS1.p1.2.m2.1.1.2.cmml" xref="S4.SS1.p1.2.m2.1.1.2">𝑁</ci><cn type="integer" id="S4.SS1.p1.2.m2.1.1.3.cmml" xref="S4.SS1.p1.2.m2.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">N=20</annotation></semantics></math>. In each communication round, each client uses <math id="S4.SS1.p1.3.m3.1" class="ltx_Math" alttext="t_{\textrm{B}}" display="inline"><semantics id="S4.SS1.p1.3.m3.1a"><msub id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml"><mi id="S4.SS1.p1.3.m3.1.1.2" xref="S4.SS1.p1.3.m3.1.1.2.cmml">t</mi><mtext id="S4.SS1.p1.3.m3.1.1.3" xref="S4.SS1.p1.3.m3.1.1.3a.cmml">B</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><apply id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.3.m3.1.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.p1.3.m3.1.1.2.cmml" xref="S4.SS1.p1.3.m3.1.1.2">𝑡</ci><ci id="S4.SS1.p1.3.m3.1.1.3a.cmml" xref="S4.SS1.p1.3.m3.1.1.3"><mtext mathsize="70%" id="S4.SS1.p1.3.m3.1.1.3.cmml" xref="S4.SS1.p1.3.m3.1.1.3">B</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">t_{\textrm{B}}</annotation></semantics></math> time resources to generate a block and <math id="S4.SS1.p1.4.m4.1" class="ltx_Math" alttext="t_{\textrm{T}}" display="inline"><semantics id="S4.SS1.p1.4.m4.1a"><msub id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml"><mi id="S4.SS1.p1.4.m4.1.1.2" xref="S4.SS1.p1.4.m4.1.1.2.cmml">t</mi><mtext id="S4.SS1.p1.4.m4.1.1.3" xref="S4.SS1.p1.4.m4.1.1.3a.cmml">T</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><apply id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.4.m4.1.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1">subscript</csymbol><ci id="S4.SS1.p1.4.m4.1.1.2.cmml" xref="S4.SS1.p1.4.m4.1.1.2">𝑡</ci><ci id="S4.SS1.p1.4.m4.1.1.3a.cmml" xref="S4.SS1.p1.4.m4.1.1.3"><mtext mathsize="70%" id="S4.SS1.p1.4.m4.1.1.3.cmml" xref="S4.SS1.p1.4.m4.1.1.3">T</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">t_{\textrm{T}}</annotation></semantics></math> time resources to pursue a learning epoch, where <math id="S4.SS1.p1.5.m5.1" class="ltx_Math" alttext="t_{B}=2" display="inline"><semantics id="S4.SS1.p1.5.m5.1a"><mrow id="S4.SS1.p1.5.m5.1.1" xref="S4.SS1.p1.5.m5.1.1.cmml"><msub id="S4.SS1.p1.5.m5.1.1.2" xref="S4.SS1.p1.5.m5.1.1.2.cmml"><mi id="S4.SS1.p1.5.m5.1.1.2.2" xref="S4.SS1.p1.5.m5.1.1.2.2.cmml">t</mi><mi id="S4.SS1.p1.5.m5.1.1.2.3" xref="S4.SS1.p1.5.m5.1.1.2.3.cmml">B</mi></msub><mo id="S4.SS1.p1.5.m5.1.1.1" xref="S4.SS1.p1.5.m5.1.1.1.cmml">=</mo><mn id="S4.SS1.p1.5.m5.1.1.3" xref="S4.SS1.p1.5.m5.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.5.m5.1b"><apply id="S4.SS1.p1.5.m5.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1"><eq id="S4.SS1.p1.5.m5.1.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1.1"></eq><apply id="S4.SS1.p1.5.m5.1.1.2.cmml" xref="S4.SS1.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p1.5.m5.1.1.2.1.cmml" xref="S4.SS1.p1.5.m5.1.1.2">subscript</csymbol><ci id="S4.SS1.p1.5.m5.1.1.2.2.cmml" xref="S4.SS1.p1.5.m5.1.1.2.2">𝑡</ci><ci id="S4.SS1.p1.5.m5.1.1.2.3.cmml" xref="S4.SS1.p1.5.m5.1.1.2.3">𝐵</ci></apply><cn type="integer" id="S4.SS1.p1.5.m5.1.1.3.cmml" xref="S4.SS1.p1.5.m5.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.5.m5.1c">t_{B}=2</annotation></semantics></math> for all experiments. Let <math id="S4.SS1.p1.6.m6.1" class="ltx_Math" alttext="\theta=t_{\textrm{T}}/t_{\textrm{B}}" display="inline"><semantics id="S4.SS1.p1.6.m6.1a"><mrow id="S4.SS1.p1.6.m6.1.1" xref="S4.SS1.p1.6.m6.1.1.cmml"><mi id="S4.SS1.p1.6.m6.1.1.2" xref="S4.SS1.p1.6.m6.1.1.2.cmml">θ</mi><mo id="S4.SS1.p1.6.m6.1.1.1" xref="S4.SS1.p1.6.m6.1.1.1.cmml">=</mo><mrow id="S4.SS1.p1.6.m6.1.1.3" xref="S4.SS1.p1.6.m6.1.1.3.cmml"><msub id="S4.SS1.p1.6.m6.1.1.3.2" xref="S4.SS1.p1.6.m6.1.1.3.2.cmml"><mi id="S4.SS1.p1.6.m6.1.1.3.2.2" xref="S4.SS1.p1.6.m6.1.1.3.2.2.cmml">t</mi><mtext id="S4.SS1.p1.6.m6.1.1.3.2.3" xref="S4.SS1.p1.6.m6.1.1.3.2.3a.cmml">T</mtext></msub><mo id="S4.SS1.p1.6.m6.1.1.3.1" xref="S4.SS1.p1.6.m6.1.1.3.1.cmml">/</mo><msub id="S4.SS1.p1.6.m6.1.1.3.3" xref="S4.SS1.p1.6.m6.1.1.3.3.cmml"><mi id="S4.SS1.p1.6.m6.1.1.3.3.2" xref="S4.SS1.p1.6.m6.1.1.3.3.2.cmml">t</mi><mtext id="S4.SS1.p1.6.m6.1.1.3.3.3" xref="S4.SS1.p1.6.m6.1.1.3.3.3a.cmml">B</mtext></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.6.m6.1b"><apply id="S4.SS1.p1.6.m6.1.1.cmml" xref="S4.SS1.p1.6.m6.1.1"><eq id="S4.SS1.p1.6.m6.1.1.1.cmml" xref="S4.SS1.p1.6.m6.1.1.1"></eq><ci id="S4.SS1.p1.6.m6.1.1.2.cmml" xref="S4.SS1.p1.6.m6.1.1.2">𝜃</ci><apply id="S4.SS1.p1.6.m6.1.1.3.cmml" xref="S4.SS1.p1.6.m6.1.1.3"><divide id="S4.SS1.p1.6.m6.1.1.3.1.cmml" xref="S4.SS1.p1.6.m6.1.1.3.1"></divide><apply id="S4.SS1.p1.6.m6.1.1.3.2.cmml" xref="S4.SS1.p1.6.m6.1.1.3.2"><csymbol cd="ambiguous" id="S4.SS1.p1.6.m6.1.1.3.2.1.cmml" xref="S4.SS1.p1.6.m6.1.1.3.2">subscript</csymbol><ci id="S4.SS1.p1.6.m6.1.1.3.2.2.cmml" xref="S4.SS1.p1.6.m6.1.1.3.2.2">𝑡</ci><ci id="S4.SS1.p1.6.m6.1.1.3.2.3a.cmml" xref="S4.SS1.p1.6.m6.1.1.3.2.3"><mtext mathsize="70%" id="S4.SS1.p1.6.m6.1.1.3.2.3.cmml" xref="S4.SS1.p1.6.m6.1.1.3.2.3">T</mtext></ci></apply><apply id="S4.SS1.p1.6.m6.1.1.3.3.cmml" xref="S4.SS1.p1.6.m6.1.1.3.3"><csymbol cd="ambiguous" id="S4.SS1.p1.6.m6.1.1.3.3.1.cmml" xref="S4.SS1.p1.6.m6.1.1.3.3">subscript</csymbol><ci id="S4.SS1.p1.6.m6.1.1.3.3.2.cmml" xref="S4.SS1.p1.6.m6.1.1.3.3.2">𝑡</ci><ci id="S4.SS1.p1.6.m6.1.1.3.3.3a.cmml" xref="S4.SS1.p1.6.m6.1.1.3.3.3"><mtext mathsize="70%" id="S4.SS1.p1.6.m6.1.1.3.3.3.cmml" xref="S4.SS1.p1.6.m6.1.1.3.3.3">B</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.6.m6.1c">\theta=t_{\textrm{T}}/t_{\textrm{B}}</annotation></semantics></math>, and a larger <math id="S4.SS1.p1.7.m7.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S4.SS1.p1.7.m7.1a"><mi id="S4.SS1.p1.7.m7.1.1" xref="S4.SS1.p1.7.m7.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.7.m7.1b"><ci id="S4.SS1.p1.7.m7.1.1.cmml" xref="S4.SS1.p1.7.m7.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.7.m7.1c">\theta</annotation></semantics></math> implies that the client spares more computing resources to learning in each communication round.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.4.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.5.2" class="ltx_text ltx_font_italic">Investigation on the local differential privacy</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">In this subsection, we apply local differential privacy on each client by adding random Gaussian noises on the uploaded models in each communication round. The testing accuracies of the Fashion-MNIST and Cifar-10 dataset are plotted in Fig. <a href="#S4.F2" title="Figure 2 ‣ IV-B Investigation on the local differential privacy ‣ IV Experimental Results and Probable Solutions ‣ When Federated Learning Meets Blockchain: A New Distributed Learning Paradigm" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> with respect to different privacy levels <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mi id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><ci id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">\epsilon</annotation></semantics></math>. In addition, an adaptive noise decaying method is compared with the constant one, which will decrease the noise power when the accuracy stopes increasing.</p>
</div>
<figure id="S4.F2" class="ltx_figure"><img src="/html/2009.09338/assets/x2.png" id="S4.F2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="207" height="183" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The learning performance with respect to different privacy levels</figcaption>
</figure>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">As can be observed in this figure, the system achieves a higher performance with a larger value of <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><mi id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><ci id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">\epsilon</annotation></semantics></math>, which is under a weaker privacy protection, and the adaptive method can further improve the learning performance under the same level of privacy protection.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.4.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.5.2" class="ltx_text ltx_font_italic">Investigation on the resource allocation</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">In this subsection, we mainly present the results for the resource allocation, and the training loss value with different ratios (<math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><mi id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><ci id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">\theta</annotation></semantics></math>) of both datasets are represented in the Fig. <a href="#S4.F3" title="Figure 3 ‣ IV-C Investigation on the resource allocation ‣ IV Experimental Results and Probable Solutions ‣ When Federated Learning Meets Blockchain: A New Distributed Learning Paradigm" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure id="S4.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2009.09338/assets/x3.png" id="S4.F3.sf1.g1" class="ltx_graphics ltx_img_landscape" width="106" height="85" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf1.2.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><span id="S4.F3.sf1.3.2" class="ltx_text" style="font-size:80%;">Fashion-Mnist</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2009.09338/assets/x4.png" id="S4.F3.sf2.g1" class="ltx_graphics ltx_img_landscape" width="106" height="85" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf2.2.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><span id="S4.F3.sf2.3.2" class="ltx_text" style="font-size:80%;">Cifar-10</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Learning performance of different total communication rounds under different resource allocation ratios</figcaption>
</figure>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.4" class="ltx_p">As can be found in Fig. <a href="#S4.F3" title="Figure 3 ‣ IV-C Investigation on the resource allocation ‣ IV Experimental Results and Probable Solutions ‣ When Federated Learning Meets Blockchain: A New Distributed Learning Paradigm" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, the system performances for different ratios are investigated with the increasing number of total communication rounds. In details, we can find that there exists an optimal total communication round (<math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mi id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><ci id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">K</annotation></semantics></math>) for each computing ratio <math id="S4.SS3.p2.2.m2.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S4.SS3.p2.2.m2.1a"><mi id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><ci id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">\theta</annotation></semantics></math>. For example, the smallest training loss value can be obtained if clients end learning in 14 communication rounds with 15 learning epochs in each round when <math id="S4.SS3.p2.3.m3.1" class="ltx_Math" alttext="\tau=1" display="inline"><semantics id="S4.SS3.p2.3.m3.1a"><mrow id="S4.SS3.p2.3.m3.1.1" xref="S4.SS3.p2.3.m3.1.1.cmml"><mi id="S4.SS3.p2.3.m3.1.1.2" xref="S4.SS3.p2.3.m3.1.1.2.cmml">τ</mi><mo id="S4.SS3.p2.3.m3.1.1.1" xref="S4.SS3.p2.3.m3.1.1.1.cmml">=</mo><mn id="S4.SS3.p2.3.m3.1.1.3" xref="S4.SS3.p2.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.3.m3.1b"><apply id="S4.SS3.p2.3.m3.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1"><eq id="S4.SS3.p2.3.m3.1.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1.1"></eq><ci id="S4.SS3.p2.3.m3.1.1.2.cmml" xref="S4.SS3.p2.3.m3.1.1.2">𝜏</ci><cn type="integer" id="S4.SS3.p2.3.m3.1.1.3.cmml" xref="S4.SS3.p2.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.1c">\tau=1</annotation></semantics></math> in the Fashion-MNIST dataset. Moreover, for different computing ratios, the optimal loss value tends to be different. This is due to the fact that the optimal number of local learning epoch is different with various <math id="S4.SS3.p2.4.m4.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S4.SS3.p2.4.m4.1a"><mi id="S4.SS3.p2.4.m4.1.1" xref="S4.SS3.p2.4.m4.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.4.m4.1b"><ci id="S4.SS3.p2.4.m4.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.4.m4.1c">\theta</annotation></semantics></math>. In addition, similar trends can be found in the Cifar-10 dataset.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS4.4.1.1" class="ltx_text">IV-D</span> </span><span id="S4.SS4.5.2" class="ltx_text ltx_font_italic">Investigation on the lazy nodes</span>
</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.9" class="ltx_p">In this subsection, we investigate the impact of lazy clients on the proposed framework. We use signal to noise ratio (SNR) to denote the ratio between the power of original model parameters and that of the injected PN sequence, and Table <a href="#S4.T1" title="TABLE I ‣ IV-D Investigation on the lazy nodes ‣ IV Experimental Results and Probable Solutions ‣ When Federated Learning Meets Blockchain: A New Distributed Learning Paradigm" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a> represents the detecting rate of lazy clients under different SNRs. If the high peaks in terms of the cross-correlation coefficient surpass a predefined threshold, we can identify this client as a lazy one. We generate a <math id="S4.SS4.p1.1.m1.1" class="ltx_Math" alttext="2^{15}" display="inline"><semantics id="S4.SS4.p1.1.m1.1a"><msup id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml"><mn id="S4.SS4.p1.1.m1.1.1.2" xref="S4.SS4.p1.1.m1.1.1.2.cmml">2</mn><mn id="S4.SS4.p1.1.m1.1.1.3" xref="S4.SS4.p1.1.m1.1.1.3.cmml">15</mn></msup><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><apply id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS4.p1.1.m1.1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1">superscript</csymbol><cn type="integer" id="S4.SS4.p1.1.m1.1.1.2.cmml" xref="S4.SS4.p1.1.m1.1.1.2">2</cn><cn type="integer" id="S4.SS4.p1.1.m1.1.1.3.cmml" xref="S4.SS4.p1.1.m1.1.1.3">15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">2^{15}</annotation></semantics></math> length of PN sequence and use the first <math id="S4.SS4.p1.2.m2.1" class="ltx_Math" alttext="25400" display="inline"><semantics id="S4.SS4.p1.2.m2.1a"><mn id="S4.SS4.p1.2.m2.1.1" xref="S4.SS4.p1.2.m2.1.1.cmml">25400</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.2.m2.1b"><cn type="integer" id="S4.SS4.p1.2.m2.1.1.cmml" xref="S4.SS4.p1.2.m2.1.1">25400</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.2.m2.1c">25400</annotation></semantics></math> values to add on the parameters. From the results with different SNRs, the detecting performances are remarkable and we can obtain a nearly <math id="S4.SS4.p1.3.m3.1" class="ltx_Math" alttext="100\%" display="inline"><semantics id="S4.SS4.p1.3.m3.1a"><mrow id="S4.SS4.p1.3.m3.1.1" xref="S4.SS4.p1.3.m3.1.1.cmml"><mn id="S4.SS4.p1.3.m3.1.1.2" xref="S4.SS4.p1.3.m3.1.1.2.cmml">100</mn><mo id="S4.SS4.p1.3.m3.1.1.1" xref="S4.SS4.p1.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.3.m3.1b"><apply id="S4.SS4.p1.3.m3.1.1.cmml" xref="S4.SS4.p1.3.m3.1.1"><csymbol cd="latexml" id="S4.SS4.p1.3.m3.1.1.1.cmml" xref="S4.SS4.p1.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S4.SS4.p1.3.m3.1.1.2.cmml" xref="S4.SS4.p1.3.m3.1.1.2">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.3.m3.1c">100\%</annotation></semantics></math> rate to recognize the lazy clients when SNR=<math id="S4.SS4.p1.4.m4.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S4.SS4.p1.4.m4.1a"><mn id="S4.SS4.p1.4.m4.1.1" xref="S4.SS4.p1.4.m4.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.4.m4.1b"><cn type="integer" id="S4.SS4.p1.4.m4.1.1.cmml" xref="S4.SS4.p1.4.m4.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.4.m4.1c">3</annotation></semantics></math> dB. Then Fig. <a href="#S4.F4" title="Figure 4 ‣ IV-D Investigation on the lazy nodes ‣ IV Experimental Results and Probable Solutions ‣ When Federated Learning Meets Blockchain: A New Distributed Learning Paradigm" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the PN sequence protecting performance (SNR=6 dB) when there are <math id="S4.SS4.p1.5.m5.1" class="ltx_Math" alttext="30\%" display="inline"><semantics id="S4.SS4.p1.5.m5.1a"><mrow id="S4.SS4.p1.5.m5.1.1" xref="S4.SS4.p1.5.m5.1.1.cmml"><mn id="S4.SS4.p1.5.m5.1.1.2" xref="S4.SS4.p1.5.m5.1.1.2.cmml">30</mn><mo id="S4.SS4.p1.5.m5.1.1.1" xref="S4.SS4.p1.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.5.m5.1b"><apply id="S4.SS4.p1.5.m5.1.1.cmml" xref="S4.SS4.p1.5.m5.1.1"><csymbol cd="latexml" id="S4.SS4.p1.5.m5.1.1.1.cmml" xref="S4.SS4.p1.5.m5.1.1.1">percent</csymbol><cn type="integer" id="S4.SS4.p1.5.m5.1.1.2.cmml" xref="S4.SS4.p1.5.m5.1.1.2">30</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.5.m5.1c">30\%</annotation></semantics></math> (6) lazy clients in each communication round. As can be found in this figure, the system performance with a certain percentage of lazy clients degrades sharply, i.e., <math id="S4.SS4.p1.6.m6.1" class="ltx_Math" alttext="22.1\%" display="inline"><semantics id="S4.SS4.p1.6.m6.1a"><mrow id="S4.SS4.p1.6.m6.1.1" xref="S4.SS4.p1.6.m6.1.1.cmml"><mn id="S4.SS4.p1.6.m6.1.1.2" xref="S4.SS4.p1.6.m6.1.1.2.cmml">22.1</mn><mo id="S4.SS4.p1.6.m6.1.1.1" xref="S4.SS4.p1.6.m6.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.6.m6.1b"><apply id="S4.SS4.p1.6.m6.1.1.cmml" xref="S4.SS4.p1.6.m6.1.1"><csymbol cd="latexml" id="S4.SS4.p1.6.m6.1.1.1.cmml" xref="S4.SS4.p1.6.m6.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.p1.6.m6.1.1.2.cmml" xref="S4.SS4.p1.6.m6.1.1.2">22.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.6.m6.1c">22.1\%</annotation></semantics></math> and <math id="S4.SS4.p1.7.m7.1" class="ltx_Math" alttext="19.6\%" display="inline"><semantics id="S4.SS4.p1.7.m7.1a"><mrow id="S4.SS4.p1.7.m7.1.1" xref="S4.SS4.p1.7.m7.1.1.cmml"><mn id="S4.SS4.p1.7.m7.1.1.2" xref="S4.SS4.p1.7.m7.1.1.2.cmml">19.6</mn><mo id="S4.SS4.p1.7.m7.1.1.1" xref="S4.SS4.p1.7.m7.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.7.m7.1b"><apply id="S4.SS4.p1.7.m7.1.1.cmml" xref="S4.SS4.p1.7.m7.1.1"><csymbol cd="latexml" id="S4.SS4.p1.7.m7.1.1.1.cmml" xref="S4.SS4.p1.7.m7.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.p1.7.m7.1.1.2.cmml" xref="S4.SS4.p1.7.m7.1.1.2">19.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.7.m7.1c">19.6\%</annotation></semantics></math> reduction in the Fashion-MNIST and Cifar-10 datasets, respectively. In addition, the proposed PN sequence protection method achieves <math id="S4.SS4.p1.8.m8.1" class="ltx_Math" alttext="18\%" display="inline"><semantics id="S4.SS4.p1.8.m8.1a"><mrow id="S4.SS4.p1.8.m8.1.1" xref="S4.SS4.p1.8.m8.1.1.cmml"><mn id="S4.SS4.p1.8.m8.1.1.2" xref="S4.SS4.p1.8.m8.1.1.2.cmml">18</mn><mo id="S4.SS4.p1.8.m8.1.1.1" xref="S4.SS4.p1.8.m8.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.8.m8.1b"><apply id="S4.SS4.p1.8.m8.1.1.cmml" xref="S4.SS4.p1.8.m8.1.1"><csymbol cd="latexml" id="S4.SS4.p1.8.m8.1.1.1.cmml" xref="S4.SS4.p1.8.m8.1.1.1">percent</csymbol><cn type="integer" id="S4.SS4.p1.8.m8.1.1.2.cmml" xref="S4.SS4.p1.8.m8.1.1.2">18</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.8.m8.1c">18\%</annotation></semantics></math> and <math id="S4.SS4.p1.9.m9.1" class="ltx_Math" alttext="13.8\%" display="inline"><semantics id="S4.SS4.p1.9.m9.1a"><mrow id="S4.SS4.p1.9.m9.1.1" xref="S4.SS4.p1.9.m9.1.1.cmml"><mn id="S4.SS4.p1.9.m9.1.1.2" xref="S4.SS4.p1.9.m9.1.1.2.cmml">13.8</mn><mo id="S4.SS4.p1.9.m9.1.1.1" xref="S4.SS4.p1.9.m9.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.9.m9.1b"><apply id="S4.SS4.p1.9.m9.1.1.cmml" xref="S4.SS4.p1.9.m9.1.1"><csymbol cd="latexml" id="S4.SS4.p1.9.m9.1.1.1.cmml" xref="S4.SS4.p1.9.m9.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.p1.9.m9.1.1.2.cmml" xref="S4.SS4.p1.9.m9.1.1.2">13.8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.9.m9.1c">13.8\%</annotation></semantics></math> performance gain in each dataset, respectively.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>The detecting rate with different PN sequence power in the Fashion-mnist and Cifar-10 datasets</figcaption>
<table id="S4.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.1.1.1" class="ltx_tr">
<th id="S4.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">Signal to Noise Ratio</th>
<th id="S4.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">9 dB</th>
<th id="S4.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">6 dB</th>
<th id="S4.T1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">3 dB</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.1.2.1" class="ltx_tr">
<td id="S4.T1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Fashion-Mnist</td>
<td id="S4.T1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.931</td>
<td id="S4.T1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.989</td>
<td id="S4.T1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.999</td>
</tr>
<tr id="S4.T1.1.3.2" class="ltx_tr">
<td id="S4.T1.1.3.2.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">Cifar-10</td>
<td id="S4.T1.1.3.2.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.925</td>
<td id="S4.T1.1.3.2.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.975</td>
<td id="S4.T1.1.3.2.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.996</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2009.09338/assets/x5.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="207" height="183" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Learning performance with/without lazy clients detection</figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Future Directions and Conclusion</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this article, we have reviewed the weakness of FL and further investigated a blockchain assisted decentralized FL, called BLADE-FL. We then showed the effectiveness that the BLADE-FL can well address the potential issues, especially the single point of failure issue, existing in the traditional FL system. In addition, we have investigated the newly raising issues including privacy, resource allocation and lazy clients. Lastly, we have further provided related possible solutions and experimental results to solve these issues, which provide guidelines to the design of the BLADE-FL framework. For future directions, some asynchronous and heterogenetic investigations for different capabilities of clients, such as computing capability, training data size and transmitting diversity, as well as the smart contract design which provides reasonable rewards allocation for training and mining can be considered in the system. In addition, the light-weight model transmitting using quantization and sketch may be an alterative way to reduce the transmission cost.

</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
C. Ma, J. Li, M. Ding, H. H. Yang, F. Shu, T. Q. S. Quek, and H. V.
Poor, “On safeguarding privacy and security in the framework of federated
learning,” <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">IEEE Network</em>, vol. 34, no. 4, pp. 242–248, 2020.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Z. Liu, P. Longa, G. C. C. F. Pereira, O. Reparaz, and H. Seo,
“Four<math id="bib.bib2.1.m1.1" class="ltx_Math" alttext="\mathbb{Q}" display="inline"><semantics id="bib.bib2.1.m1.1a"><mi id="bib.bib2.1.m1.1.1" xref="bib.bib2.1.m1.1.1.cmml">ℚ</mi><annotation-xml encoding="MathML-Content" id="bib.bib2.1.m1.1b"><ci id="bib.bib2.1.m1.1.1.cmml" xref="bib.bib2.1.m1.1.1">ℚ</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib2.1.m1.1c">\mathbb{Q}</annotation></semantics></math>q on embedded devices with strong countermeasures against
side-channel attacks,” <em id="bib.bib2.2.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Dependable and Secure
Computing</em>, vol. 17, no. 3, pp. 536–549, 2020.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Y. Chen, X. Qin, J. Wang, C. Yu, and W. Gao, “Fedhealth: A federated
transfer learning framework for wearable healthcare,” <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">IEEE Intelligent
Systems</em>, vol. 35, no. 4, pp. 83–93, 2020.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
T. Li, A. K. Sahu, A. Talwalkar, and V. Smith, “Federated learning:
Challenges, methods, and future directions,” <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">IEEE Signal Processing
Magazine</em>, vol. 37, no. 3, pp. 50–60, 2020.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
H. Kim, J. Park, M. Bennis, and S. Kim, “Blockchained on-device
federated learning,” <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Letters</em>, vol. 24, no. 6, pp.
1279–1283, 2020.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Y. Lu, X. Huang, Y. Dai, S. Maharjan, and Y. Zhang, “Blockchain and federated
learning for privacy-preserved data sharing in industrial iot,” <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Industrial Informatics</em>, vol. 16, no. 6, pp. 4177–4186,
2020.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
X. Bao, C. Su, Y. Xiong, W. Huang, and Y. Hu, “Flchain: A blockchain
for auditable federated learning with trust and incentive,” in <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">2019
5th International Conference on Big Data Computing and Communications
(BIGCOM)</em>, 2019, pp. 151–159.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
P. K. Sharma, J. H. Park, and K. Cho, “Blockchain and federated learning-based
distributed computing defence framework for sustainable society,”
<em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Sustainable Cities and Society</em>, vol. 59, p. 102220, 2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
S. Wang, “Blockfedml: Blockchained federated machine learning systems,” in
<em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">2019 International Conference on Intelligent Computing, Automation and
Systems (ICICAS)</em>, 2019, pp. 751–756.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Y. Qu, S. R. Pokhrel, S. Garg, L. Gao, and Y. Xiang, “A blockchained federated
learning framework for cognitive computing in industry 4.0 networks,”
<em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Industrial Informatics</em>, vol. 17, no. 4, pp.
2964–2973, 2021.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
S. Otoum, I. Al Ridhawi, and H. Mouftah, “Blockchain-supported federated
learning for trustworthy vehicular networks,” 12 2020, pp. 1–6.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
M. Jelasity, “Gossip,” in <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Self-organising Software</em>.   Springer, 2011, pp. 139–162.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
L. Ismail, H. Materwala, and S. Zeadally, “Lightweight blockchain for
healthcare,” <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol. 7, pp. 149 935–149 951, 2019.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
P. Fairley, “Blockchain world - feeding the blockchain beast if bitcoin ever
does go mainstream, the electricity needed to sustain it will be enormous,”
<em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">IEEE Spectrum</em>, vol. 54, no. 10, pp. 36–59, 2017.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
K. Wei, J. Li, M. Ding, C. Ma, H. Su, B. Zhang, and H. V. Poor, “User-level
privacy-preserving federated learning: Analysis and performance
optimization,” <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Mobile Computing</em>, pp. 1–1, 2021.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2009.09337" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2009.09338" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2009.09338">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2009.09338" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2009.09339" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Mar 14 11:31:17 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
