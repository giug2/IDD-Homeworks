<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation</title>
<!--Generated on Mon May 13 20:36:42 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Neural Machine Translation,  Cantonese-English Translation,  Low Resource MT,  Data Augmentation,  Model Switch Mechanism " lang="en" name="keywords"/>
<base href="/html/2405.08172v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S1" title="In CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S2" title="In CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Background and Related Works</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S2.SS1" title="In 2. Background and Related Works ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Traditional Machine Translation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S2.SS2" title="In 2. Background and Related Works ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Neural Machine Translation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S2.SS3" title="In 2. Background and Related Works ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Large Language Models</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S2.SS3.SSS1" title="In 2.3. Large Language Models ‣ 2. Background and Related Works ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3.1 </span>Opus-MT</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S2.SS3.SSS2" title="In 2.3. Large Language Models ‣ 2. Background and Related Works ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3.2 </span>mBART</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S2.SS3.SSS3" title="In 2.3. Large Language Models ‣ 2. Background and Related Works ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3.3 </span>NLLB</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S2.SS4" title="In 2. Background and Related Works ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4 </span>Back-Translation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S2.SS4.SSS1" title="In 2.4. Back-Translation ‣ 2. Background and Related Works ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4.1 </span>English-Vietnamese Translation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S2.SS4.SSS2" title="In 2.4. Back-Translation ‣ 2. Background and Related Works ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4.2 </span>Context-aware Neural Machine Translation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S2.SS4.SSS3" title="In 2.4. Back-Translation ‣ 2. Background and Related Works ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4.3 </span>English-German Translation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S2.SS5" title="In 2. Background and Related Works ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.5 </span>MT on Cantonese</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S2.SS5.SSS1" title="In 2.5. MT on Cantonese ‣ 2. Background and Related Works ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.5.1 </span>Commercial Translators</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S2.SS5.SSS2" title="In 2.5. MT on Cantonese ‣ 2. Background and Related Works ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.5.2 </span>Research Models</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S3" title="In CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span><span class="ltx_text ltx_font_smallcaps">CantonMT</span> Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S3.SS1" title="In 3. CantonMT Methodology ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Datasets and Preprocessing</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S3.SS1.SSS1" title="In 3.1. Datasets and Preprocessing ‣ 3. CantonMT Methodology ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.1 </span>Parallel Corpus</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S3.SS1.SSS2" title="In 3.1. Datasets and Preprocessing ‣ 3. CantonMT Methodology ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2 </span>Monolingual Corpus</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S3.SS2" title="In 3. CantonMT Methodology ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Baseline Models</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S3.SS2.SSS1" title="In 3.2. Baseline Models ‣ 3. CantonMT Methodology ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.1 </span>Model Selections</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S3.SS2.SSS2" title="In 3.2. Baseline Models ‣ 3. CantonMT Methodology ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.2 </span>Fine-Tuning</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S3.SS3" title="In 3. CantonMT Methodology ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Back-Translation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S3.SS4" title="In 3. CantonMT Methodology ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Plug-and-Play: Model-Switch Mechanism</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S4" title="In CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experimental Evaluations</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S4.SS1" title="In 4. Experimental Evaluations ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Evaluation Method</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S4.SS1.SSS1" title="In 4.1. Evaluation Method ‣ 4. Experimental Evaluations ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.1 </span>Comparisons to the State-of-the-Art</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S4.SS1.SSS2" title="In 4.1. Evaluation Method ‣ 4. Experimental Evaluations ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.2 </span>Automatic Evaluation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S4.SS1.SSS3" title="In 4.1. Evaluation Method ‣ 4. Experimental Evaluations ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.3 </span>Human Evaluation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S4.SS2" title="In 4. Experimental Evaluations ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Baseline Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S4.SS3" title="In 4. Experimental Evaluations ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Back-Translation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S4.SS4" title="In 4. Experimental Evaluations ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Plug-and-Play Model Outcomes</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S4.SS5" title="In 4. Experimental Evaluations ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.5 </span>Integrating More Real Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S4.SS6" title="In 4. Experimental Evaluations ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.6 </span>Comparisons to the State-of-the-Art</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S4.SS7" title="In 4. Experimental Evaluations ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.7 </span>Human Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S4.SS7.SSS1" title="In 4.7. Human Evaluation ‣ 4. Experimental Evaluations ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.7.1 </span>Text Degeneration</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S4.SS7.SSS2" title="In 4.7. Human Evaluation ‣ 4. Experimental Evaluations ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.7.2 </span>Results</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S5" title="In CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusions and Future Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S5.SS1" title="In 5. Conclusions and Future Work ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Findings</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S5.SS2" title="In 5. Conclusions and Future Work ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Challenges and Limitations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S5.SS3" title="In 5. Conclusions and Future Work ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Future Work</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#A1" title="In CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span><span class="ltx_text ltx_font_smallcaps">CantonMT</span> Open-sourced Toolkit</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#A1.SS1" title="In Appendix A CantonMT Open-sourced Toolkit ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Web Application</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#A1.SS1.SSS1" title="In A.1. Web Application ‣ Appendix A CantonMT Open-sourced Toolkit ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1.1 </span>User Interface</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#A1.SS1.SSS2" title="In A.1. Web Application ‣ Appendix A CantonMT Open-sourced Toolkit ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1.2 </span>Server</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#A2" title="In CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Evaluation Details</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#A2.SS1" title="In Appendix B Evaluation Details ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.1 </span>Examples Output</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#A2.SS2" title="In Appendix B Evaluation Details ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.2 </span>Human Annotation Guidelines</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#A2.SS3" title="In Appendix B Evaluation Details ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.3 </span>Automatic Evaluation Results</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">
<span class="ltx_text ltx_font_smallcaps" id="id1.id1">CantonMT</span>: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Kung Yin Hong
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:kenrick.kung@gmail.com">kenrick.kung@gmail.com</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id2.1.id1">University of Manchester</span><span class="ltx_text ltx_affiliation_city" id="id3.2.id2">Greater Manchester</span><span class="ltx_text ltx_affiliation_state" id="id4.3.id3">England</span><span class="ltx_text ltx_affiliation_country" id="id5.4.id4">UK</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Lifeng Han
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id6.1.id1">University of Manchester</span><span class="ltx_text ltx_affiliation_city" id="id7.2.id2">Greater Manchester</span><span class="ltx_text ltx_affiliation_state" id="id8.3.id3">England</span><span class="ltx_text ltx_affiliation_country" id="id9.4.id4">UK</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:Lifeng.Han@manchester.ac.uk">Lifeng.Han@manchester.ac.uk</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Riza Batista-Navarro
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id10.1.id1">University of Manchester</span><span class="ltx_text ltx_affiliation_city" id="id11.2.id2">Greater Manchester</span><span class="ltx_text ltx_affiliation_state" id="id12.3.id3">England</span><span class="ltx_text ltx_affiliation_country" id="id13.4.id4">UK</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:riza.batista.Han@manchester.ac.uk">riza.batista.Han@manchester.ac.uk</a>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Goran Nenadic
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id14.1.id1">University of Manchester</span><span class="ltx_text ltx_affiliation_city" id="id15.2.id2">Greater Manchester</span><span class="ltx_text ltx_affiliation_state" id="id16.3.id3">England</span><span class="ltx_text ltx_affiliation_country" id="id17.4.id4">UK</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:g.nenadic@manchester.ac.uk">g.nenadic@manchester.ac.uk</a>
</span></span></span>
</div>
<div class="ltx_dates">(2018; xx May 2024; xx 2024; xxx)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id18.id1">This paper investigates the development and evaluation of machine translation models from Cantonese to English, where we propose a novel approach to tackle low-resource language translations.
Despite recent improvements in Neural Machine Translation (NMT) models with Transformer-based architectures, Cantonese, a language with over 80 million native speakers, has below-par State-of-the-art commercial translation models due to a lack of resources. The main objectives of the study are to develop a model that can effectively translate Cantonese to English and evaluate it against state-of-the-art commercial models.
To achieve this, a new parallel corpus has been created by combining different available corpora online with preprocessing and cleaning. In addition, a monolingual Cantonese dataset has been created through web scraping to aid the synthetic parallel corpus generation.
Following the data collection process, several approaches, including fine-tuning models, back-translation, and model switch, have been used. The translation quality of models has been evaluated with multiple quality metrics, including lexicon-based metrics (SacreBLEU and hLEPOR) and embedding-space metrics (COMET and BERTscore). Based on the automatic metrics, the best model is selected and compared against the 2 best commercial translators using the human evaluation framework HOPES.
The best model proposed in this investigation (NLLB-mBART) with model switch mechanisms has reached comparable and even better automatic evaluation scores against State-of-the-art commercial models (Bing and Baidu Translators), with a SacreBLEU score of 16.8 on our test set.
Furthermore, an open-source web application has been developed to allow users to translate between Cantonese and English, with the different trained models available for effective comparisons between models from this investigation and users. <span class="ltx_text ltx_font_smallcaps" id="id18.id1.1">CantonMT</span> is available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/kenrickkung/CantoneseTranslation" title="">https://github.com/kenrickkung/CantoneseTranslation</a></p>
</div>
<div class="ltx_keywords">Neural Machine Translation, Cantonese-English Translation, Low Resource MT, Data Augmentation, Model Switch Mechanism 
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmlicensed</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2018</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id3"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>XXXXXXX.XXXXXXX</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id4"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>Make sure to enter the correct
conference title from your rights confirmation email; June 03–05,
2018; Woodstock, NY</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_isbn" id="id5"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>978-1-4503-XXXX-X/18/06</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id6"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Software and its engineering 
Software creation and management</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id7"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>
Software development techniques</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id8"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>
Software prototyping</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Cantonese is a Sinitic language spoken in Hong Kong, Macau, and the Guangdong region of southern PRC, it is the second most spoken Sinitic language, after Mandarin Chinese <cite class="ltx_cite ltx_citemacro_citep">(Wiedenhof, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib47" title="">2015</a>)</cite>. With a substantial 80 million native speakers <cite class="ltx_cite ltx_citemacro_citep">(Eberhard et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib12" title="">2023</a>)</cite>, Cantonese is still an under-researched area in the spectrum of Natural Language Processing, as demonstrated in ACL Anthology, where only 47 papers are related to Cantonese, compared with 2355 for (Mandarin) Chinese <cite class="ltx_cite ltx_citemacro_citep">(Xiang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib51" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Despite having the second most speakers in the family of Sinitic languages, most State-of-the-art commercial translators either do not support Cantonese or have below-par translation quality when translated to English. This leads to scenarios where individuals seeking Cantonese resources face challenges, particularly in casual forums where tones are often very similar to spoken language.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">We believe that Cantonese is a unique language that captures the rich cultural history of Hong Kong, Macau, and the Guangdong province of China. Two major challenges when dealing with Cantonese translations are Colloquialism and Multilingualism. Colloquialism, a linguistic style used for informal and casual conversation, often occurs in Cantonese and includes non-standard spelling, slang, and neologisms.
As for Multilingualism, Hong Kong was once a British colony and has a rich Chinese cultural influence; code-switching <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>the act of using multiple languages together</span></span></span> happens often in day-to-day conversation; and words can also be loaned from English through phonetic transliteration <cite class="ltx_cite ltx_citemacro_citep">(Bauer, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib3" title="">2006</a>)</cite>.
Therefore, following the trend of language diversity and inclusion in NLP, we have set out the aim to develop a translation system that could translate sentences from Cantonese to English and reach comparable results against commercial translators.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In the era of the fast development of NLP, many MT models have been proposed for the majority of languages worldwide. However, low-resource language MT still challenges researchers. Cantonese can certainly be viewed as one of the low-resource languages given that its written form of collection is scarce. It is well known that NMT models require much data to obtain good translation quality. In this work, we aim to investigate one of the popular methods, i.e. synthetic data generation for data-augmented fine-tuning via forward-translation and back-translation models on Cantonese-to-English NMT.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">This work aims to fill the gap in the NLP and MT field for an open-sourced Cantonese-to-English translation tool that can obtain comparable results against commercial translators, which could potentially allow users to use the system locally.
With this in mind, we set the following objectives:</p>
</div>
<div class="ltx_para" id="S1.p6">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">Create Parallel and Monolingual corpus that can be used in further research on Cantonese NLP</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">Develop state-of-the-art models for translating Cantonese to English</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">Create an open-sourced User Interface that can be used for translation and as a toolkit for future projects on translation task</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">Regarding the Evaluation Strategy, the models developed are evaluated through a range of metrics, including lexicon-based word surface matchings (SacreBLEU and hLEPOR) and those based on embedding spaces (COMET and BERTscore). Following these metrics, the top-performing model is chosen for comparison with the two top-performing commercial translation tools, employing the HOPES human evaluation framework, which we modified based on HOPE, a human-centric post-editing based metric <cite class="ltx_cite ltx_citemacro_citep">(Gladkoff and Han, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib14" title="">2022</a>)</cite>. <span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>This is an extended solid investigation based on our preliminary work reported in <cite class="ltx_cite ltx_citemacro_citep">(Hong et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib25" title="">2024</a>)</cite>. </span></span></span>
The rest of the paper is organised as below:</p>
<ul class="ltx_itemize" id="S1.I2">
<li class="ltx_item" id="S1.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I2.i1.p1">
<p class="ltx_p" id="S1.I2.i1.p1.1">Section <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S2" title="2. Background and Related Works ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a> introduces some technical backgrounds and related works on MT, LLMs, back-translation, data augmentation, and Cantonese NLP.</p>
</div>
</li>
<li class="ltx_item" id="S1.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I2.i2.p1">
<p class="ltx_p" id="S1.I2.i2.p1.1">Section <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S3" title="3. CantonMT Methodology ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a> presents the methodology and model design for <span class="ltx_text ltx_font_smallcaps" id="S1.I2.i2.p1.1.1">CantonMT</span> including corpus collection, data preprocessing, model selections, training and fine-tuning, plug-and-play / model-switch mechanism.</p>
</div>
</li>
<li class="ltx_item" id="S1.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I2.i3.p1">
<p class="ltx_p" id="S1.I2.i3.p1.1">Section <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S4" title="4. Experimental Evaluations ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">4</span></a> lays out the experimental evaluation metrics, human evaluations, and analyses of model outcomes and their comparisons to state-of-the-art commercial translators.</p>
</div>
</li>
<li class="ltx_item" id="S1.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I2.i4.p1">
<p class="ltx_p" id="S1.I2.i4.p1.1">Section <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S5" title="5. Conclusions and Future Work ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">5</span></a> concludes this paper with findings and future work plans.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Background and Related Works</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Traditional Machine Translation</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">MT has long been one of the most important tasks in NLP intending to translate sentences into another language with the help of a computer. It was first introduced by <cite class="ltx_cite ltx_citemacro_citet">Weaver (<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib46" title="">1952</a>)</cite>.
Rule-based MT (RBMT), also known as Knowledged-Based MT, is one of the classical approaches to MT. It was first developed in the early 1970s, and one of the main systems was SYSTRAN <span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="http://www.systran.de/" title="">http://www.systran.de/</a></span></span></span>. Having an input sentence (in the source language), an RBMT system generates them to output sentence (in the target language) based on morphological, syntactical, and semantic analysis on both the source and the target language.
This approach had considerable merit at the time; however, it has its shortcomings. For example, building a dictionary for a new language is very expensive, and rules are handwritten, which could mean a lot of human judgement might be involved. Therefore, it has been replaced by Corpus-based MT and Statistical MT (SMT) <cite class="ltx_cite ltx_citemacro_citep">(Brown et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib5" title="">1988</a>; Koehn et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib27" title="">2003</a>)</cite>.
SMT is based on the availability of pairs of corresponding text that are translations of each other (Parallel Corpus) and does not rely on a deep understanding of the grammatical rules of the languages involved, which means the machine can automatically analyse the parallel corpus and generate translated text without the need of hand-crafted rules, via bilingual “phrase table” and statistical “language model”.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">However, SMT struggles with a few issues, where proper nouns might be overridden due to statistical anomaly. An example would be a sentence such as ”I took a flight to Berlin” might be translated to ”I took a flight to Paris” instead due to the abundance of ”to Paris” in the training data. Some other issues that it may struggle with are word order, idioms, and the inability to model long-distance dependencies between words <cite class="ltx_cite ltx_citemacro_citep">(Han, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib19" title="">2022</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Neural Machine Translation</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">With the breakthrough in computing power and deep learning, neural networks have become the paradigm to MT, which will be investigated in this project.
These models are defined as NMT and it is a radical change from the previous MT approaches where it does not require additional feature engineering and is instead an end-to-end training process, which simplifies the need for language-dependent expertise.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">Seq2Seq Models <cite class="ltx_cite ltx_citemacro_citep">(Sutskever et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib41" title="">2014</a>; Cho et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib8" title="">2014</a>)</cite> are a specific realisation of RNN models and are particularly useful for MT since they take a sequence (source sentence) as input and output a sequence (target sentence). It is usually composed of an encoder and a decoder, where the encoder captures the context and meaning of the input sequence, and the decoder uses the encoded input to produce a final output sequence. In the early paper when this architecture was first introduced, the encoder and decoder are normally two RNNs.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">However, despite the advancements made, this architecture struggles with information-management bottleneck, which may lead to information loss over long-distance language dependencies. The issues rise as for the encoder, it is difficult to encode the meaning of the sentence in a vector representation, and for the decoder, some information might be more relevant than others at different parts of the output sequence.</p>
</div>
<div class="ltx_para" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.1">The attention mechanism was introduced into RNN by <cite class="ltx_cite ltx_citemacro_citet">Bahdanau et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib2" title="">2015</a>)</cite>, where it aims to solve the information bottleneck from vanilla RNNs.
The Transformer architecture was later introduced based on the attention mechanism <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib45" title="">2017</a>)</cite> and has outperformed the RNN-based models.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>Large Language Models</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">LLMs were first introduced by <cite class="ltx_cite ltx_citemacro_citet">Devlin et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib10" title="">2019</a>)</cite> with the introduction of BERT and can be use for general purpose NLP tasks. It usually will be trained in two phases, pre-training and fine-tuning. Since the introduction of LLMs, they have swept the leaderboard for most NLP tasks and has reached new state-of-the-art results for probably all main NLP tasks including MT.</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1">With the rise of LLMs, there are dozens of pre-trained models which are capable on MT tasks with none or few fine-tuning. In our investigation, there are 3 models chosen for further fine-tuning with our dataset, the reason behind choosing these models can be seen in the methodology section. Here is a brief introduction of each model, which could help readers understand the difference with depth.</p>
</div>
<section class="ltx_subsubsection" id="S2.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.1. </span>Opus-MT</h4>
<div class="ltx_para" id="S2.SS3.SSS1.p1">
<p class="ltx_p" id="S2.SS3.SSS1.p1.1">Opus-MT <cite class="ltx_cite ltx_citemacro_citep">(Tiedemann and Thottingal, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib44" title="">2020</a>)</cite>, developed by Helsinki-NLP, is a Transformer-based NMT, which is using Marian-NMT <span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://marian-nmt.github.io/" title="">https://marian-nmt.github.io/</a></span></span></span> as the framework for the model training. The model family is trained with a publicly available parallel corpus collected in OPUS<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="http://opus.nlpl.eu/" title="">http://opus.nlpl.eu/</a></span></span></span>. The model is specifically trained for MT task, and should not be classified as a general purpose LLM.</p>
</div>
<div class="ltx_para" id="S2.SS3.SSS1.p2">
<p class="ltx_p" id="S2.SS3.SSS1.p2.1">Two specific models are used in this project, <span class="ltx_text ltx_font_italic" id="S2.SS3.SSS1.p2.1.1">Opus-mt-zh-en</span> and <span class="ltx_text ltx_font_italic" id="S2.SS3.SSS1.p2.1.2">Opus-mt-en-zh</span>, which are models that translate Chinese to English and English to Chinese. The forward model (Chinese to English) has around 77M parameters, which is considered quite a small model when compared to LLMs.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.2. </span>mBART</h4>
<div class="ltx_para" id="S2.SS3.SSS2.p1">
<p class="ltx_p" id="S2.SS3.SSS2.p1.1">mBART <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib33" title="">2020</a>)</cite>, a multilingual Seq2Seq denoising auto-encoder. It is trained with the BART <cite class="ltx_cite ltx_citemacro_citep">(Lewis et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib30" title="">2020</a>)</cite> objectives with a multilingual corpus.</p>
</div>
<div class="ltx_para" id="S2.SS3.SSS2.p2">
<p class="ltx_p" id="S2.SS3.SSS2.p2.1">The pre-training of mBART is trained by corrupting text with a noising function and also learning a model to reconstruct the original text. It uses the CC25 Corpus which contains 25 languages and follows the standard Transformer architecture with 12 layers of encoders and 12 layers of decoders.</p>
</div>
<div class="ltx_para" id="S2.SS3.SSS2.p3">
<p class="ltx_p" id="S2.SS3.SSS2.p3.1">In this paper, a specific version of the model is used (<span class="ltx_text ltx_font_italic" id="S2.SS3.SSS2.p3.1.1">mbart-large-50-many-to-many-mmt</span>) which supports 50 languages, including (Mandarin) Chinese. However, it does not support Cantonese as a language. The model is also fine-tuned for multilingual translation and is introduced by <cite class="ltx_cite ltx_citemacro_citet">Tang et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib42" title="">2020</a>)</cite> which has added 25 additional languages without hurting the performance of the model. The model has a total of 610M parameters, a massive increase compared to the previous Opus model.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS3.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.3. </span>NLLB</h4>
<div class="ltx_para" id="S2.SS3.SSS3.p1">
<p class="ltx_p" id="S2.SS3.SSS3.p1.1">No Language Left Behind (NLLB) <cite class="ltx_cite ltx_citemacro_citep">(NLLB-Team et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib34" title="">2022</a>)</cite>, to the best of our knowledge, is the only publicly available LLM which contains the language Cantonese (Lang-Code: yue_Hant). It is trained upon the FLORES-200 dataset which contains 200 languages and serves as a high-quality benchmark dataset. The model architecture is also based on the Transformer encoder-decoder architecture <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib45" title="">2017</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS3.SSS3.p2">
<p class="ltx_p" id="S2.SS3.SSS3.p2.1">In this work, a distilled version of NLLB (<span class="ltx_text ltx_font_italic" id="S2.SS3.SSS3.p2.1.1">nllb-200-distilled-600M</span>) is used since based on our available computation power, there is no chance of fine-tuning a larger model. The model is already fine-tuned on MT task, and the language pair in focus is Cantonese-English.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4. </span>Back-Translation</h3>
<div class="ltx_para" id="S2.SS4.p1">
<p class="ltx_p" id="S2.SS4.p1.1">Data Augmentation via Back translation is a technique used by MT researchers when tackling low-resource languages. Typically, since not enough data is available, the model may not be able to learn the translation of the language thoroughly and, thus might harm the performance of MT.
This technique has been one of the standards for leveraging monolingual corpora since SMT <cite class="ltx_cite ltx_citemacro_citep">(Bojar and Tamchyna, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib4" title="">2011</a>)</cite>, and is still being used with NMT <cite class="ltx_cite ltx_citemacro_citep">(Sennrich et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib39" title="">2016</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS4.p2">
<p class="ltx_p" id="S2.SS4.p2.1">The approach uses a model, which translates target language text to the source language (back model), for translating a monolingual corpus in the target language to the source language. This creates a synthetic parallel corpus (Silver Standard), which is different from human annotated parallel corpus (Gold Standard). In theory, with more data, the model can be performing better.</p>
</div>
<div class="ltx_para" id="S2.SS4.p3">
<p class="ltx_p" id="S2.SS4.p3.1">Iterative approaches are also being explored in this project <cite class="ltx_cite ltx_citemacro_citep">(Hoang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib23" title="">2018</a>)</cite>.
A more in-depth explanation of the approach taken in this project is given in the methodology section.
Below are some works of literature that follow this technique.</p>
</div>
<section class="ltx_subsubsection" id="S2.SS4.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.4.1. </span>English-Vietnamese Translation</h4>
<div class="ltx_para" id="S2.SS4.SSS1.p1">
<p class="ltx_p" id="S2.SS4.SSS1.p1.1">For back-translation, a monolingual corpus is required, often involving web scraping, which may lead to low-quality datasets since text from the internet often does not follow proper grammar rules. In light of that, <cite class="ltx_cite ltx_citemacro_citet">Pham et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib37" title="">2023</a>)</cite> has proposed a method to correct the sentence with grammatical errors to improve the quality of monolingual corpus.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS4.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.4.2. </span>Context-aware Neural Machine Translation</h4>
<div class="ltx_para" id="S2.SS4.SSS2.p1">
<p class="ltx_p" id="S2.SS4.SSS2.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Sugiyama and Yoshinaga (<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib40" title="">2019</a>)</cite> developed a context-aware NMT model which translates Japanese to English via back translation. They have reached state-of-the-art results in single-sentence translation from Japanese to English and Japanese to French.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS4.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.4.3. </span>English-German Translation</h4>
<div class="ltx_para" id="S2.SS4.SSS3.p1">
<p class="ltx_p" id="S2.SS4.SSS3.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Graça et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib16" title="">2019</a>)</cite> pointed out that sampling-based synthetic data generation schemes have some fundamental problems and proposed methods to remedy them by disabling label-smoothing for the back model and sampling from a restricted search space.
In our project, due to the nature of Cantonese translation, the methodology proposed by this work is not likely to succeed, and the approach in the project is a different approach inspired by <cite class="ltx_cite ltx_citemacro_citet">Hoang et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib23" title="">2018</a>)</cite>, which will be explained in the methodology section.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S2.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.5. </span>MT on Cantonese</h3>
<section class="ltx_subsubsection" id="S2.SS5.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.5.1. </span>Commercial Translators</h4>
<div class="ltx_para" id="S2.SS5.SSS1.p1">
<p class="ltx_p" id="S2.SS5.SSS1.p1.1">A survey has been conducted on four different commercial MT software, including Google, Bing, Baidu, and DeepL.</p>
</div>
<div class="ltx_para" id="S2.SS5.SSS1.p2">
<p class="ltx_p" id="S2.SS5.SSS1.p2.1">For Google<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://translate.google.com/" title="">https://translate.google.com/</a></span></span></span> and DeepL<span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.deepl.com/translator" title="">https://www.deepl.com/translator</a></span></span></span>, despite being the most popular software used for translation in daily lives, they do not support Cantonese as an option, but only (Mandarin) Chinese. Therefore, no further investigations are being made on the platforms.
For Bing<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.bing.com/translator" title="">https://www.bing.com/translator</a></span></span></span> and Baidu<span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://fanyi.baidu.com" title="">https://fanyi.baidu.com</a></span></span></span>, there are native Cantonese support in translation and therefore are chosen as a state-of-the-art comparison in the following sections.</p>
</div>
<div class="ltx_para" id="S2.SS5.SSS1.p3">
<p class="ltx_p" id="S2.SS5.SSS1.p3.1">With the rise of LLMs, there are also questions on whether or not this kind of model with prompting can give better results when compared with a more traditional approach with fine-tuning on LLMs. In this project, Generative Pre-trained Transformers(GPT)-4 <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib35" title="">2024</a>)</cite> are being investigated with specific prompting to compare against our model.
The implementation of GPT-4 that we used is Cantonese Companion, which was custom-made for translation to Cantonese by a community builder.<span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://chat.openai.com/share/7ee588af-dc48-4406-95f4-0471e1fb70a8" title="">https://chat.openai.com/share/7ee588af-dc48-4406-95f4-0471e1fb70a8</a></span></span></span>
However, it should be noted that we do not know how much data was used for this community-trained Cantonese Companion and the training was not transparent, in addition to its dependence on the commercial platform.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS5.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.5.2. </span>Research Models</h4>
<div class="ltx_para" id="S2.SS5.SSS2.p1">
<p class="ltx_p" id="S2.SS5.SSS2.p1.1">Research work focusing on Cantonese-English MT has not gained much attention up to date unfortunately, and therefore to expand the search, MT models that are focusing on Cantonese have all been investigated to understand the frontier of the research in Cantonese translation.</p>
</div>
<div class="ltx_para" id="S2.SS5.SSS2.p2">
<p class="ltx_p" id="S2.SS5.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS5.SSS2.p2.1.1">Example-based and Rule-based Machine Translation</span>
<cite class="ltx_cite ltx_citemacro_citet">Wu et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib50" title="">2006</a>)</cite> has presented a method for Cantonese-English MT with a combination of example-based and RBMT, which uses morphological knowledge, syntax analysis, translation examples and target-generation-based rules. Their approach has reached 80% accuracy on their test data report. However, this approach requires advanced knowledge in both Cantonese and English, which is very hard to scale up since it requires a lot of feature engineering and also domain-specific knowledge.</p>
</div>
<div class="ltx_para" id="S2.SS5.SSS2.p3">
<p class="ltx_p" id="S2.SS5.SSS2.p3.1"><span class="ltx_text ltx_font_bold" id="S2.SS5.SSS2.p3.1.1">Neural Machine Translation</span>
<cite class="ltx_cite ltx_citemacro_citet">Wing (<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib48" title="">2020</a>)</cite> has created a plan to develop different models in Cantonese-English MT, which include RNN and also Transformers model, however, the result cannot be found anywhere online, and therefore no cross-comparison can be used.</p>
</div>
<div class="ltx_para" id="S2.SS5.SSS2.p4">
<p class="ltx_p" id="S2.SS5.SSS2.p4.1">To the best of our knowledge, these are the only literature which has attempted to tackle the translation direction from Cantonese to English. There is also one piece of literature in the opposite direction, which we have taken inspiration from the project in terms of the dataset used which we will explain next.</p>
</div>
<div class="ltx_para" id="S2.SS5.SSS2.p5">
<p class="ltx_p" id="S2.SS5.SSS2.p5.1"><span class="ltx_text ltx_font_bold" id="S2.SS5.SSS2.p5.1.1">English-Cantonese Machine Translation</span>
TransCan<span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/ayaka14732/TransCan" title="">https://github.com/ayaka14732/TransCan</a></span></span></span> is a NMT model which translates English to Cantonese and is trained based on bart-base-Chinese and BART with additional linear projection to connect them; it has reached 28.6 in BLEU score on the tested data which is much higher than the available commercial translation. However, due to the nature of the BLEU score and also it being a different direction, the result is not comparable to the model we will be proposing.</p>
</div>
<div class="ltx_para" id="S2.SS5.SSS2.p6">
<p class="ltx_p" id="S2.SS5.SSS2.p6.1">There is also literature on <span class="ltx_text ltx_font_italic" id="S2.SS5.SSS2.p6.1.1">Chinese-Cantonese NMT</span> in a looser direction. They often use the word Mandarin instead of Chinese since Chinese could also be an umbrella term covering both Mandarin and Cantonese. However, to distinguish the difference between Chinese and Cantonese here, the report will use Chinese interchangeably with Mandarin.</p>
</div>
<div class="ltx_para" id="S2.SS5.SSS2.p7">
<p class="ltx_p" id="S2.SS5.SSS2.p7.1"><span class="ltx_text ltx_font_bold" id="S2.SS5.SSS2.p7.1.1">BiLSTM Machine Translation</span>
<cite class="ltx_cite ltx_citemacro_citet">Liu (<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib32" title="">2022</a>)</cite> has developed a Bidirectional- LSTM(BiLSTM), which is said to be one of the first benchmarks for different NMT. The literature uses parallel sentence mining (PSM) as a data augmentation technique that identifies bitexts, which are translations of each other. In the end, the best system, which uses BPE, BiLSTM and PSM, has reached a SacreBLEU score of 13.22.</p>
</div>
<div class="ltx_para" id="S2.SS5.SSS2.p8">
<p class="ltx_p" id="S2.SS5.SSS2.p8.1"><span class="ltx_text ltx_font_bold" id="S2.SS5.SSS2.p8.1.1">Transformer-based Neural Machine Translation</span>
<cite class="ltx_cite ltx_citemacro_citet">Yi Mak and Lee (<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib52" title="">2022</a>)</cite> has developed a Transformer-based NMT which outperforms Baidu Fanyi’s Chinese-to-Cantonese Translation on 6 out of 8 test sets in BLEU score. It also has another major contribution in developing an effective approach to automatically extracting semantically similar sentences from parallel articles in Wikipedia, and it has obtained 72K parallel sentences.</p>
</div>
<div class="ltx_para" id="S2.SS5.SSS2.p9">
<p class="ltx_p" id="S2.SS5.SSS2.p9.1">These are some examples of literature that have explored Cantonese NMT. Since the introduction of LLMs, most related work which does not involve Transformers is likely outdated and will likely not produce state-of-the-art performance. Therefore this project has adopted a different route compared to most of them. However, there are some useful sources of datasets stemming from TransCan, and therefore, in the project, similar datasets have been used inspired by TransCan.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">CantonMT</span> Methodology</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">This section outlines the methodology used to achieve the paper’s objectives. It began with a detailed procedure for collecting data for the upcoming model fine-tuning process with both parallel and monolingual corpus. It then discusses different baseline models, including hyper-parameters for fine-tuning and training strategies. After that, the back-translation procedure is discussed, including employing a model-switch strategy.
The design of the open-source web application can be found in Section <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#A1" title="Appendix A CantonMT Open-sourced Toolkit ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">A</span></a>.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Datasets and Preprocessing</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">Several datasets are used in this paper for training and evaluation. Since Cantonese-English parallel corpora are not readily available, combinations of different datasets are used for the initial training of baseline models. Furthermore, to aid the back-translation strategy in the latter part of the project, monolingual corpora for both Cantonese and English are required, and therefore, they will be discussed in the following section.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1. </span>Parallel Corpus</h4>
<div class="ltx_para" id="S3.SS1.SSS1.p1">
<p class="ltx_p" id="S3.SS1.SSS1.p1.1">To fine-tune different baseline models, a parallel corpus is required to train the model to translate Cantonese to English at a reasonable level.
In the end, three different parallel corpora are found between different timestamps of the investigation. Therefore, the latter two are used for training only, while the former are used for training and evaluation.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS1.p2">
<p class="ltx_p" id="S3.SS1.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.SSS1.p2.1.1">Words.hk Corpus</span>
Words.hk<span class="ltx_note ltx_role_footnote" id="footnote12"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://words.hk" title="">https://words.hk</a></span></span></span> is an open Cantonese-English dictionary publicly available for people to download.
We used the full dataset from their website, which contains different Cantonese words and some example sentences with their English translation. An example of the word
<span class="ltx_ERROR undefined" id="S3.SS1.SSS1.p2.1.2">{CJK*}</span>UTF8bkai
“投資 / touzi”
in the dictionary is given in Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S3.F1" title="Figure 1 ‣ 3.1.1. Parallel Corpus ‣ 3.1. Datasets and Preprocessing ‣ 3. CantonMT Methodology ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="99" id="S3.F1.g1" src="extracted/5591987/Images/wordshk-data.png" width="592"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F1.2.1.1" style="font-size:90%;">Figure 1</span>. </span><span class="ltx_text" id="S3.F1.3.2" style="font-size:90%;">Sample Data Format for Words.hk</span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.SSS1.p3">
<p class="ltx_p" id="S3.SS1.SSS1.p3.1">From the data, only the sentence after the tag <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS1.p3.1.1">eng</span> has been used in this case, the sentence, “<span class="ltx_text ltx_font_italic" id="S3.SS1.SSS1.p3.1.2">She invested $1 million in renovating the shop</span>”, has been extracted and also its corresponding Cantonese translation which is the sentence after the tag <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS1.p3.1.3">yue</span>. Data pre-processing has also been done, including removing hashtags and space since there is quite a lot in the dataset, potentially affecting data quality. In addition, there are sentences with multiple translations; in that case, the first translation has been taken. In the end, 44K sentences have been extracted from the dataset. A graph of the frequencies of the length of the Cantonese sentence has been plotted in Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S3.F2" title="Figure 2 ‣ 3.1.1. Parallel Corpus ‣ 3.1. Datasets and Preprocessing ‣ 3. CantonMT Methodology ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a>.
<br class="ltx_break"/></p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="225" id="S3.F2.g1" src="extracted/5591987/Images/wordshk_freq.png" width="299"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F2.2.1.1" style="font-size:90%;">Figure 2</span>. </span><span class="ltx_text" id="S3.F2.3.2" style="font-size:90%;">Words.hk - Sentence Length</span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.SSS1.p4">
<p class="ltx_p" id="S3.SS1.SSS1.p4.1">It is noticed that despite the effort only to keep sentences and no definitions, there are still quite a lot of short sentences in the dataset. Since for short sentences, it could be straightforward for the model to translate and, therefore, may lead to a bias in the evaluation, we have decided to split the dataset into short sentences and long sentences, where short sentences are sentences that have ten characters or less. In the end, there are 19.4K short sentences and 24.6K long sentences.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S3.SS1.SSS1.p5">
<p class="ltx_p" id="S3.SS1.SSS1.p5.1">Since data are already very scarce, we have decided not to opt into the standard train-dev-test split of 8/1/1 or 7/2/1 and instead went for the approach of a 3K dev set and 3K test set. The reason behind this is based on that the standard practice for Workshop of Machine Translation (WMT)<span class="ltx_note ltx_role_footnote" id="footnote13"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www2.statmt.org/wmt24" title="">https://www2.statmt.org/wmt24</a></span></span></span> shared task uses around 3K sentences for test sets when comparing different MT systems.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS1.p6">
<p class="ltx_p" id="S3.SS1.SSS1.p6.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.SSS1.p6.1.1">Wenlin Corpus</span>
Wenlin Institute <span class="ltx_note ltx_role_footnote" id="footnote14"><sup class="ltx_note_mark">14</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">14</sup><span class="ltx_tag ltx_tag_note">14</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://wenlin.com" title="">https://wenlin.com</a></span></span></span> creates software and dictionaries for learning the Chinese language, and there is a dictionary, ABC Cantonese-English Comprehensive Dictionary, which is readily available for registered users to use for research purposes. The process to obtain the dataset, however, is not straightforward. It involves first getting a list of URLs which store the data, and after that, it requires web scraping; at the end, an XML file is obtained, which includes all the sentences and other content.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS1.p7">
<p class="ltx_p" id="S3.SS1.SSS1.p7.1">Extracting is required to convert an XML file to a parallel corpus after obtaining an XML file. Based on initial inspection, the sentence should be inside the tag <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS1.p7.1.1">WL</span>; therefore, regular expression techniques are used to extract those sentences. After that, similar pre-processing as Words.hk has been done to obtain the training set and 14.5K parallel sentences are extracted.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS1.p8">
<p class="ltx_p" id="S3.SS1.SSS1.p8.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.SSS1.p8.1.1">Opus Corpora</span>
Opus Corpora <cite class="ltx_cite ltx_citemacro_citep">(Tiedemann and Nygaard, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib43" title="">2004</a>)</cite> is a collection of translated documents collected from the internet. The corpus is already aligned, and therefore, no pre-processing is required. It can be easily downloaded via their website <span class="ltx_note ltx_role_footnote" id="footnote15"><sup class="ltx_note_mark">15</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">15</sup><span class="ltx_tag ltx_tag_note">15</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://opus.nlpl.eu/" title="">https://opus.nlpl.eu/</a></span></span></span>. An additional 9.6K parallel sentences are added to the final training set.
A figure summarising the size of the parallel dataset is shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S3.T1" title="Table 1 ‣ 3.1.1. Parallel Corpus ‣ 3.1. Datasets and Preprocessing ‣ 3. CantonMT Methodology ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a></p>
</div>
<figure class="ltx_table" id="S3.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T1.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r" id="S3.T1.2.1.1.1">Source</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="S3.T1.2.1.1.2">Size</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.2.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.2.2.1.1">Wenlin</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.2.2.1.2">14476</td>
</tr>
<tr class="ltx_tr" id="S3.T1.2.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T1.2.3.2.1">Words.hk</th>
<td class="ltx_td ltx_align_left" id="S3.T1.2.3.2.2">44045</td>
</tr>
<tr class="ltx_tr" id="S3.T1.2.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T1.2.4.3.1">Opus</th>
<td class="ltx_td ltx_align_left" id="S3.T1.2.4.3.2">9588</td>
</tr>
<tr class="ltx_tr" id="S3.T1.2.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.2.5.4.1">Total</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.2.5.4.2">68109</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T1.3.1.1" style="font-size:90%;">Table 1</span>. </span><span class="ltx_text" id="S3.T1.4.2" style="font-size:90%;">Parallel Corpus Size</span></figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2. </span>Monolingual Corpus</h4>
<div class="ltx_para" id="S3.SS1.SSS2.p1">
<p class="ltx_p" id="S3.SS1.SSS2.p1.1">To aid the process of back-translation, a monolingual corpus from both the source and target language is required to investigate the <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS2.p1.1.1">iterative back-translation</span> approach.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS2.p2">
<p class="ltx_p" id="S3.SS1.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.SSS2.p2.1.1">English Corpus</span>
There are many English monolingual corpora available, and in this project, the dataset we have decided to use is from the WMT 2012 News Collection <cite class="ltx_cite ltx_citemacro_citep">(Callison-Burch et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib6" title="">2012</a>)</cite>. It can be downloaded on the WMT website and contains 434K sentences, which is more than required for the back-translation.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS2.p3">
<p class="ltx_p" id="S3.SS1.SSS2.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.SSS2.p3.1.1">Cantonese Corpus</span>
However, for the Cantonese corpus, it is difficult to find an existing monolingual corpus. There is a Hong Kong Cantonese Corpus (HKCanCor) available <cite class="ltx_cite ltx_citemacro_citep">(Lee et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib29" title="">2022</a>)</cite>. However, this is based on spontaneous speech and radio programs from the late 1990s and, therefore, might be outdated and there is the language evolution factors with time passing by. Another reason for not choosing the data is that it only consists of 10K sentences, which is insufficient for back-translation purposes.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS2.p4">
<p class="ltx_p" id="S3.SS1.SSS2.p4.1">Based on findings from <cite class="ltx_cite ltx_citemacro_citet">Liang et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib31" title="">2021</a>)</cite>, there should be abundant data on social media, including Facebook, YouTube, Instagram and different local forums. Since it will be hard to filter out Hong Kong users who use Cantonese in their social media comments, we have decided to turn to local forums. There are few mainstream ones which have an abundance of data, including Baby-Kingdom<span class="ltx_note ltx_role_footnote" id="footnote16"><sup class="ltx_note_mark">16</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">16</sup><span class="ltx_tag ltx_tag_note">16</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.baby-kingdom.com/forum.php" title="">https://www.baby-kingdom.com/forum.php</a></span></span></span>, DiscussHK<span class="ltx_note ltx_role_footnote" id="footnote17"><sup class="ltx_note_mark">17</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">17</sup><span class="ltx_tag ltx_tag_note">17</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.discuss.com.hk/" title="">https://www.discuss.com.hk/</a></span></span></span>, and LIHKG<span class="ltx_note ltx_role_footnote" id="footnote18"><sup class="ltx_note_mark">18</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">18</sup><span class="ltx_tag ltx_tag_note">18</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://lihkg.com" title="">https://lihkg.com</a></span></span></span>.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS2.p5">
<p class="ltx_p" id="S3.SS1.SSS2.p5.1">In the end, based on tools available online, we have decided to collect data from LIHKG. It is an online forum platform that was launched in 2016 and has multiple categories, including sports, entertainment,
hot topics, gossip, current affairs, etc. There is a scraper readily available online from <cite class="ltx_cite ltx_citemacro_citet">Ho and Or (<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib22" title="">2020</a>)</cite>, which we have used to scrape the data from LIHKG. Data is scraped in CSV format, where an example can be seen in Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S3.F3" title="Figure 3 ‣ 3.1.2. Monolingual Corpus ‣ 3.1. Datasets and Preprocessing ‣ 3. CantonMT Methodology ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a> (profile ID masked).</p>
</div>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="227" id="S3.F3.g1" src="extracted/5591987/Images/LIHKG-example.png" width="592"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F3.2.1.1" style="font-size:90%;">Figure 3</span>. </span><span class="ltx_text" id="S3.F3.3.2" style="font-size:90%;">LIHKG Data Example</span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.SSS2.p6">
<p class="ltx_p" id="S3.SS1.SSS2.p6.1">29K posts have been scraped, and only the text part has been used as the monolingual data. Some more <span class="ltx_text ltx_font_bold" id="S3.SS1.SSS2.p6.1.1">pre-processing</span> has been done to the data, including stripping all the links in the data and filtering out all the sentences shorter than 10 Chinese characters. In the end, 1.1M sentences have been scraped, which is more than enough for our investigation.
We <span class="ltx_text ltx_font_bold" id="S3.SS1.SSS2.p6.1.2">shuffled</span> the dataset so that it can be used by the research community for free, as long as they sign a user agreement form for non-commercial usage.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Baseline Models</h3>
<section class="ltx_subsubsection" id="S3.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1. </span>Model Selections</h4>
<div class="ltx_para" id="S3.SS2.SSS1.p1">
<p class="ltx_p" id="S3.SS2.SSS1.p1.1">In this training phase, we aim to train a set of reasonable Cantonese-English MT models for model comparisons as baselines and synthetic data generation. Three different models have been chosen for this project, including Opus-MT, NLLB and mBART. Model information can be seen in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S3.T2" title="Table 2 ‣ 3.2.1. Model Selections ‣ 3.2. Baseline Models ‣ 3. CantonMT Methodology ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a></p>
</div>
<figure class="ltx_table" id="S3.T2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T2.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.2.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S3.T2.2.1.1.1"></th>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S3.T2.2.1.1.2">Opus</td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S3.T2.2.1.1.3">NLLB</td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S3.T2.2.1.1.4">mBart</td>
</tr>
<tr class="ltx_tr" id="S3.T2.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T2.2.2.2.1">Layers</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.2.2.2.2">12</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.2.2.2.3">24</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.2.2.2.4">24</td>
</tr>
<tr class="ltx_tr" id="S3.T2.2.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T2.2.3.3.1">Hidden Unit</th>
<td class="ltx_td ltx_align_left" id="S3.T2.2.3.3.2">512</td>
<td class="ltx_td ltx_align_left" id="S3.T2.2.3.3.3">1024</td>
<td class="ltx_td ltx_align_left" id="S3.T2.2.3.3.4">1024</td>
</tr>
<tr class="ltx_tr" id="S3.T2.2.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T2.2.4.4.1">Model Parameters</th>
<td class="ltx_td ltx_align_left" id="S3.T2.2.4.4.2">77.9M</td>
<td class="ltx_td ltx_align_left" id="S3.T2.2.4.4.3">615M</td>
<td class="ltx_td ltx_align_left" id="S3.T2.2.4.4.4">610.9M</td>
</tr>
<tr class="ltx_tr" id="S3.T2.2.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T2.2.5.5.1">Language Pair</th>
<td class="ltx_td ltx_align_left" id="S3.T2.2.5.5.2">No</td>
<td class="ltx_td ltx_align_left" id="S3.T2.2.5.5.3">Yes</td>
<td class="ltx_td ltx_align_left" id="S3.T2.2.5.5.4">No</td>
</tr>
<tr class="ltx_tr" id="S3.T2.2.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S3.T2.2.6.6.1">Release Year</th>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T2.2.6.6.2">2020</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T2.2.6.6.3">2022</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T2.2.6.6.4">2020</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T2.3.1.1" style="font-size:90%;">Table 2</span>. </span><span class="ltx_text" id="S3.T2.4.2" style="font-size:90%;">Parameters from deployed models.
Language pair: if the model contains Cantonese-English as a language pair</span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.SSS1.p2">
<p class="ltx_p" id="S3.SS2.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p2.1.1">Pivot Model</span>
NLLB, as mentioned in Section <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S2" title="2. Background and Related Works ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a>, is the only LLM that states that it supports Cantonese MT and, therefore, is naturally chosen as a pivot model. Further evaluation also supports the selection. With NLLB as a pivot model, two further investigations will be made using the rationales below.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p3">
<p class="ltx_p" id="S3.SS2.SSS1.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p3.1.1">Model Size</span>
<span class="ltx_text ltx_font_italic" id="S3.SS2.SSS1.p3.1.2">Does model size affect translation performance?</span> Since the version of NLLB we have chosen contains 600M parameters, a much smaller model was chosen to investigate this question. Therefore, Opus-MT was selected because it includes 78M parameters, around an 8x difference in size.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p4">
<p class="ltx_p" id="S3.SS2.SSS1.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p4.1.1">Pre-training with the targeted language</span>
<span class="ltx_text ltx_font_italic" id="S3.SS2.SSS1.p4.1.2">How much does it matter if the pre-trained translation models have Cantonese in their pre-training?</span> For this, mBART has been chosen, another LLM which should not have Cantonese as pre-training or far less when compared to NLLB. The model also contains a similar number of parameters, and therefore, pre-training with the investigated language (Cantonese) should be the only factor.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2. </span>Fine-Tuning</h4>
<div class="ltx_para" id="S3.SS2.SSS2.p1">
<p class="ltx_p" id="S3.SS2.SSS2.p1.1">During this phase, only Words.hk data were discovered; therefore, the initial fine-tuning was conducted on this dataset.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p2">
<p class="ltx_p" id="S3.SS2.SSS2.p2.1">The fine-tuning process has mostly been done on the Hugging Face<span class="ltx_note ltx_role_footnote" id="footnote19"><sup class="ltx_note_mark">19</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">19</sup><span class="ltx_tag ltx_tag_note">19</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co" title="">https://huggingface.co</a></span></span></span> API since all the models can be found on their website. Training has been done with Adam Optimizer <cite class="ltx_cite ltx_citemacro_citep">(Kingma and Ba, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib26" title="">2017</a>)</cite> with an initial learning rate of <math alttext="10^{-4}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p2.1.m1.1"><semantics id="S3.SS2.SSS2.p2.1.m1.1a"><msup id="S3.SS2.SSS2.p2.1.m1.1.1" xref="S3.SS2.SSS2.p2.1.m1.1.1.cmml"><mn id="S3.SS2.SSS2.p2.1.m1.1.1.2" xref="S3.SS2.SSS2.p2.1.m1.1.1.2.cmml">10</mn><mrow id="S3.SS2.SSS2.p2.1.m1.1.1.3" xref="S3.SS2.SSS2.p2.1.m1.1.1.3.cmml"><mo id="S3.SS2.SSS2.p2.1.m1.1.1.3a" xref="S3.SS2.SSS2.p2.1.m1.1.1.3.cmml">−</mo><mn id="S3.SS2.SSS2.p2.1.m1.1.1.3.2" xref="S3.SS2.SSS2.p2.1.m1.1.1.3.2.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.1.m1.1b"><apply id="S3.SS2.SSS2.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1">superscript</csymbol><cn id="S3.SS2.SSS2.p2.1.m1.1.1.2.cmml" type="integer" xref="S3.SS2.SSS2.p2.1.m1.1.1.2">10</cn><apply id="S3.SS2.SSS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1.3"><minus id="S3.SS2.SSS2.p2.1.m1.1.1.3.1.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1.3"></minus><cn id="S3.SS2.SSS2.p2.1.m1.1.1.3.2.cmml" type="integer" xref="S3.SS2.SSS2.p2.1.m1.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.1.m1.1c">10^{-4}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p2.1.m1.1d">10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT</annotation></semantics></math>.
In terms of Epoch, since fine-tuning the different models takes different ranges of time and similar training time is hoped to obtain a fair result, 10 epochs are used for the OPUS-MT model, and 3 epochs are used for NLLB and mBART.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Back-Translation</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">After fine-tuning the baseline models, back-translation can be done where an iterative approach is first tried since both source and target language monolingual corpus are present.
The following approach is inspired by the literature from <cite class="ltx_cite ltx_citemacro_citet">Hoang et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib23" title="">2018</a>)</cite> with some changes. A general outline of the iterative approach is given here.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<ol class="ltx_enumerate" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1">Train a Baseline Model FM<span class="ltx_text ltx_font_smallcaps" id="S3.I1.i1.p1.1.1">0</span> for the forward direction (Cantonese to English)</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1">Generate synthetic data CANTO-SYN<span class="ltx_text ltx_font_smallcaps" id="S3.I1.i2.p1.1.1">1</span> with Cantonese monolingual data and model FM<span class="ltx_text ltx_font_smallcaps" id="S3.I1.i2.p1.1.2">0</span></p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1">Train different synthetic model BM<span class="ltx_text ltx_font_smallcaps" id="S3.I1.i3.p1.1.1">1</span> with different ratios of gold standard data and synthetic Data CANTO-SYN<span class="ltx_text ltx_font_smallcaps" id="S3.I1.i3.p1.1.2">1</span></p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(4)</span>
<div class="ltx_para" id="S3.I1.i4.p1">
<p class="ltx_p" id="S3.I1.i4.p1.1">Select best model from BM<span class="ltx_text ltx_font_smallcaps" id="S3.I1.i4.p1.1.1">1</span> with SacreBLEU and Generate synthetic data ENG-SYN<span class="ltx_text ltx_font_smallcaps" id="S3.I1.i4.p1.1.2">1</span> with English monolingual data and model BM<span class="ltx_text ltx_font_smallcaps" id="S3.I1.i4.p1.1.3">1</span></p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(5)</span>
<div class="ltx_para" id="S3.I1.i5.p1">
<p class="ltx_p" id="S3.I1.i5.p1.1">Train different synthetic model FM<span class="ltx_text ltx_font_smallcaps" id="S3.I1.i5.p1.1.1">1</span> with different ratios of gold standard data and synthetic Data ENG-SYN<span class="ltx_text ltx_font_smallcaps" id="S3.I1.i5.p1.1.2">1</span></p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(6)</span>
<div class="ltx_para" id="S3.I1.i6.p1">
<p class="ltx_p" id="S3.I1.i6.p1.1">Repeat Step 2-5</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1">Each step will now be explained in a more detailed manner, and a diagram is provided to understand the step visually in Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S3.F4" title="Figure 4 ‣ 3.3. Back-Translation ‣ 3. CantonMT Methodology ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">4</span></a>.
<br class="ltx_break"/></p>
</div>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="278" id="S3.F4.g1" src="extracted/5591987/Images/IBT.png" width="592"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F4.2.1.1" style="font-size:90%;">Figure 4</span>. </span><span class="ltx_text" id="S3.F4.3.2" style="font-size:90%;">Diagram for Iterative Back Translation</span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS3.p4">
<p class="ltx_p" id="S3.SS3.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p4.1.1">Train Baseline Model</span>
This was done in the previous phase. Since our main focus will be on NLLB, the model trained throughout this section will be NLLB.</p>
</div>
<div class="ltx_para" id="S3.SS3.p5">
<p class="ltx_p" id="S3.SS3.p5.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p5.1.1">Generate Synthetic Parallel Data from Cantonese Data</span>
We can now use the fine-tuned model to generate a synthetic parallel corpus. we have generated 200K synthetic data, randomly sampled in the LIHKG corpus using the baseline model from the previous phase. 200K is chosen since it is 5x larger than the gold standard data, which is the maximum ratio with which we will be diluting the gold standard data.</p>
</div>
<div class="ltx_para" id="S3.SS3.p6">
<p class="ltx_p" id="S3.SS3.p6.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p6.1.1">Fine-tuning Backward Model with Synthetic Data</span>
After generating synthetic data, we can now start fine-tuning the backward direction model. Inspired by <cite class="ltx_cite ltx_citemacro_citet">Hoang et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib23" title="">2018</a>)</cite>, where different ratios of synthetic data and real data are used, a similar approach has also been made here. We have experimented with ratios of 1:1, 1:2, 1:3 and 1:5 for the backward model, where all the gold standard data have been used and added with the correct ratio of synthetic data randomly sampled from the previously generated corpus. All models are trained from the deployed version of NLLB.</p>
</div>
<div class="ltx_para" id="S3.SS3.p7">
<p class="ltx_p" id="S3.SS3.p7.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p7.1.1">Generate Synthetic Parallel Data from English Data</span>
After training a set of models, the best model is chosen based on the best SacreBLEU score with the development set of gold standard data. Another set of synthetic data will then be generated with the WMT2012News corpus and the best model chosen from the last part. 200K sentences have been randomly sampled and put into the model for translation in preparation for a new synthetic data set.</p>
</div>
<div class="ltx_para" id="S3.SS3.p8">
<p class="ltx_p" id="S3.SS3.p8.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p8.1.1">Fine-tuning Forward Model with Synthetic Data</span>
The generated synthetic data can now be used to fine-tune the forward model, where the same setup is used compared to the previous fine-tuning of the backward model. An additional ratio is also experimented with by <span class="ltx_text ltx_font_italic" id="S3.SS3.p8.1.2">sampling half of the gold standard data and pairing it with the same number of synthetic sentence pairs</span>.</p>
</div>
<div class="ltx_para" id="S3.SS3.p9">
<p class="ltx_p" id="S3.SS3.p9.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p9.1.1">Limitations</span>
Due to the lack of computing power and the fact that the best backward model was the one with no synthetic data, no iterations were made afterwards.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4. </span>Plug-and-Play: Model-Switch Mechanism</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">With different models available at our disposal, another way of experimenting with back-translation has been thought of, where a different type of model will be used in the opposite direction, which we call the method plug-and-play model or more formally, Model Switch. The idea goes through a process similar to the last section, where different models are chosen instead of choosing NLLB as a model throughout the iteration.</p>
</div>
<div class="ltx_para" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.1">Since NLLB, in theory, should be the best model (most knowledge), a decision has been made to include NLLB at least in 1 direction. Below is the list of model pairs that are experimented with:</p>
<ol class="ltx_enumerate" id="S3.I2">
<li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span>
<div class="ltx_para" id="S3.I2.i1.p1">
<p class="ltx_p" id="S3.I2.i1.p1.1">Forward: NLLB, Backward: Opus-MT</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span>
<div class="ltx_para" id="S3.I2.i2.p1">
<p class="ltx_p" id="S3.I2.i2.p1.1">Forward: NLLB, Backward: mBART</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span>
<div class="ltx_para" id="S3.I2.i3.p1">
<p class="ltx_p" id="S3.I2.i3.p1.1">Forward: mBART, Backward: NLLB</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(4)</span>
<div class="ltx_para" id="S3.I2.i4.p1">
<p class="ltx_p" id="S3.I2.i4.p1.1">Forward: Opus-MT, Backward: NLLB</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S3.SS4.p3">
<p class="ltx_p" id="S3.SS4.p3.1">One thing to note is that to balance out the training time for each model, the Opus-MT model is trained for 10 epochs instead of 3 epochs for the other two models.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Experimental Evaluations</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">This section first covers the different evaluation processes used for the project, and the results are then reported and analysed in the latter part of the section.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Evaluation Method</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">After all the models have been trained, each model has been evaluated with a set of automatic metrics, where the best models are selected and compared against state-of-the-art translators.
We first introduce the automatic evaluation; then, it comes to the human evaluation settings where the modified (simplified) HOPE metric – HOPES – will be used (Section <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S4.SS1.SSS3" title="4.1.3. Human Evaluation ‣ 4.1. Evaluation Method ‣ 4. Experimental Evaluations ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">4.1.3</span></a>).</p>
</div>
<section class="ltx_subsubsection" id="S4.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1. </span>Comparisons to the State-of-the-Art </h4>
<div class="ltx_para" id="S4.SS1.SSS1.p1">
<p class="ltx_p" id="S4.SS1.SSS1.p1.1">During the evaluation, state-of-the-art translators are also included to compare against other models, such as Bing and Baidu. The translation is obtained with their API using their corresponding Cantonese and English language pair. Furthermore, GPT-4 are also included for comparisons where a fine-tuned version towards translation to Cantonese by “Community Builder” called Cantonese Companion <span class="ltx_note ltx_role_footnote" id="footnote20"><sup class="ltx_note_mark">20</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">20</sup><span class="ltx_tag ltx_tag_note">20</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://chat.openai.com/share/7ee588af-dc48-4406-95f4-0471e1fb70a8" title="">https://chat.openai.com/share/7ee588af-dc48-4406-95f4-0471e1fb70a8</a></span></span></span> is used.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2. </span>Automatic Evaluation</h4>
<div class="ltx_para" id="S4.SS1.SSS2.p1">
<p class="ltx_p" id="S4.SS1.SSS2.p1.1"><span class="ltx_text ltx_font_italic" id="S4.SS1.SSS2.p1.1.1">Lexicon-based Metrics: SacreBLEU and hLEPOR</span>.
For MT task, one of the most used metrics when evaluating MT system translation performance is BLEU <cite class="ltx_cite ltx_citemacro_citep">(Papineni et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib36" title="">2002</a>)</cite>. However, since BLEU could vary in different literature, <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS2.p1.1.2">SacreBLEU</span> <cite class="ltx_cite ltx_citemacro_citep">(Post, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib38" title="">2018</a>)</cite> is developed in the hope of having a standard way of calculating the BLEU score. It is, therefore, used as the main metric throughout the project as an evaluation during training.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p2">
<p class="ltx_p" id="S4.SS1.SSS2.p2.1">However, it should be said that with only one automatic metric, especially with a variant of BLEU, it might not fully capture and understand which is the best model. <cite class="ltx_cite ltx_citemacro_citep">(Callison-Burch et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib7" title="">2006</a>)</cite>. Therefore, another lexical-based metric is used.
<span class="ltx_text ltx_font_bold" id="S4.SS1.SSS2.p2.1.1">hLEPOR</span> <cite class="ltx_cite ltx_citemacro_citep">(Han et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib17" title="">2013a</a>)</cite> is another lexical-based metric which has reported much higher correlation scores to the human evaluation than BLEU and other lexical-based metrics on the WMT shared task data <cite class="ltx_cite ltx_citemacro_citep">(Han et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib18" title="">2013b</a>)</cite>. Therefore, it is used to pair up with SacreBLEU.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p3">
<p class="ltx_p" id="S4.SS1.SSS2.p3.1"><span class="ltx_text ltx_font_italic" id="S4.SS1.SSS2.p3.1.1">Neural-based Metrics: COMET and BERTscore</span>.
In the recent WMT findings,
it is reported by <cite class="ltx_cite ltx_citemacro_citet">Freitag et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib13" title="">2022</a>)</cite> that neural-based metrics are significantly better than non-neural metrics regarding the correlation of human evaluation.
Therefore, an additional two metrics have been used, i.e. <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS2.p3.1.2">COMET</span> and <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS2.p3.1.3">BERTscore</span>, of which COMET-22 was ranked the second highest metric from the WMT shared task, and BERTscore is used commonly in the MT community nowadays.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p4">
<p class="ltx_p" id="S4.SS1.SSS2.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.SSS2.p4.1.1">Implementations</span>
Each trained model and state-of-the-art translator will translate 3K sentences in the test set. Since all the metrics are reference-based, the gold standard translation is required, and therefore, both the translation and reference are passed on for the metric calculation. For COMET-22, SacreBLEU and BERTScore, Hugging Face Evaluate<span class="ltx_note ltx_role_footnote" id="footnote21"><sup class="ltx_note_mark">21</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">21</sup><span class="ltx_tag ltx_tag_note">21</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/docs/evaluate/index" title="">https://huggingface.co/docs/evaluate/index</a></span></span></span> modules are used to support the calculation, where hLEPOR has its own Python module<span class="ltx_note ltx_role_footnote" id="footnote22"><sup class="ltx_note_mark">22</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">22</sup><span class="ltx_tag ltx_tag_note">22</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://pypi.org/project/hLepor/" title="">https://pypi.org/project/hLepor/</a></span></span></span> for its calculation. The results are reported in the next section.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.3. </span>Human Evaluation</h4>
<div class="ltx_para" id="S4.SS1.SSS3.p1">
<p class="ltx_p" id="S4.SS1.SSS3.p1.1">Even with four different automatic metrics, it is still hard to judge the model’s performance based on those chosen metrics. Therefore, human evaluations are also being conducted to understand better the comparison with state-of-the-art models and the <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS3.p1.1.1">different types</span> of errors that the trained models or deployed translators tend to make.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS3.p2">
<p class="ltx_p" id="S4.SS1.SSS3.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.SSS3.p2.1.1">HOPES framework
</span>With that in mind, we have borrowed the HOPE framework <cite class="ltx_cite ltx_citemacro_citep">(Gladkoff and Han, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib14" title="">2022</a>)</cite>. The original HOPE framework includes eight detailed error types from industrial practice.
However, upon our review, some error types can be merged to make the human evaluation task more efficient and better match our data, where a modified framework, HOPE-Simplified (HOPES), is proposed. The merging procedure is shown in the below list.
</p>
<ol class="ltx_enumerate" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i1.p1.1.1">Merge Impact(IMP) and Mistranslation(MIS) as MIS</span>:
<br class="ltx_break"/>The definitions of IMP and MIS are “The translation fails to convert main thoughts clearly” and “Translation distorts the meaning of the source and presents mistranslation or accuracy error” respectively. They overlap in accuracy and meaning preservation from the source sentence, which both reflect the semantics error. 
<br class="ltx_break"/>Therefore, it is merged as Mistranslation(MIS), where the new definition is given as “perceived meaning differs from the actual meaning”.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i2.p1.1.1">Merge Terminology(TRM) and Proper Name (PRN) as Terms(TRM)</span>:
<br class="ltx_break"/>The original definitions of TRM and PRN are “incorrect terminology, inconsistency on the translation of entities” and “a proper name is translated incorrectly” respectively.
In our experimental data, the name is not popular, and proper names can be entity types if they appear in the test set.
<br class="ltx_break"/>Furthermore, the original data does not define the scoring mechanism in a specific way. For example, when the translation mistranslates a critical word, should it be given as a critical error since it distorts the meaning, or a minor error since there is only one mistake in the translation? With the newly defined MIS, the first case could be covered by that, and therefore, a minor error should be given. 
<br class="ltx_break"/>Therefore, the error types are merged as TRM, with the new definition of “Incorrect terminology”, including proper names or inconsistency of translation of entities, where a higher score means there are more incorrect terms”.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i3.p1.1.1">Merge Style (STL), Proofreading (PRF), Required Adaptation Missing (RAM) into Style(STL).
<br class="ltx_break"/></span>The original definitions of these three are “translation has poor style but is not necessarily ungrammatical or formally incorrect”, “linguistic error which does not affect accuracy or meaning transfer but needs to be fixed”, and “source contains error that has to be corrected or target market requires substantial adaptation of the source, which translator failed to make; impact on the end user suffers”.
These errors are all related to localisation and adaptation.
We <span class="ltx_text ltx_font_italic" id="S4.I1.i3.p1.1.2">summarise</span> the merged error type Style as “Translation has poor style, but is not necessarily ungrammatically or formally incorrect. It may also include linguistic error which does not affect meaning, but potentially makes the end user suffer”.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S4.SS1.SSS3.p3">
<p class="ltx_p" id="S4.SS1.SSS3.p3.1">There is also a human annotation guideline in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#A2.SS2" title="B.2. Human Annotation Guidelines ‣ Appendix B Evaluation Details ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">B.2</span></a>, in which examples of critical errors for each mistake and the scoring guide are given to each annotator.
Based on literature from <cite class="ltx_cite ltx_citemacro_citet">Gladkoff et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib15" title="">2022</a>)</cite> regarding evaluation uncertainty, less than 200 human evaluation sentences are insufficient to make a statistical significance. Therefore, 200 sentences from the test set are randomly sampled from the test set and used for human evaluation.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS3.p4">
<p class="ltx_p" id="S4.SS1.SSS3.p4.1">Three different translation systems are chosen, including the best model from our training, one of the commercial translators and community-finetuned GPT4. The reasons are based on the evaluation metric scores, which will be shown in the latter part.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS3.p5">
<p class="ltx_p" id="S4.SS1.SSS3.p5.1">There were a total of 4 annotators who are fluent English speakers and native Cantonese users annotated the translations for the 200 x 3 translations. Each translation is then evaluated by two annotators to measure the agreement level between them, and therefore, the results should be more accurate and reflect the performance of each system. It should also be noted that the results can also help us understand the general error types the models are making, which may be useful for future work.</p>
</div>
<figure class="ltx_table" id="S4.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T3.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T3.2.1.1.1">Model Name</th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.2.1.1.2">SacreBLEU</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.2.1.1.3">hLEPOR</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.2.1.1.4">BERTscore</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.2.1.1.5">COMET</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.2.2.2.1">nllb-forward-bl</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.2.2.2.2"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.2.2.1">16.5117</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.2.2.2.3"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.2.3.1">0.5651</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.2.2.2.4"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.2.4.1">0.9248</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.2.2.2.5"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.2.5.1">0.7376</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.2.3.3.1">mbart-forward-bl</th>
<td class="ltx_td ltx_align_center" id="S4.T3.2.3.3.2">15.7513</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.3.3.3">0.5623</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.3.3.4">0.9227</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.3.3.5">0.7314</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.2.4.4.1">opus-forward-bl-10E</th>
<td class="ltx_td ltx_align_center" id="S4.T3.2.4.4.2">15.0602</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.4.4.3">0.5581</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.4.4.4">0.9219</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.4.4.5">0.7193</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T3.2.5.5.1">nllb-200-deploy-no-finetune</th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.2.5.5.2">11.1827</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.2.5.5.3">0.4925</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.2.5.5.4">0.9129</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T3.2.5.5.5">0.6863</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.2.6.6.1">opus-deploy-no-finetune</th>
<td class="ltx_td ltx_align_center" id="S4.T3.2.6.6.2">10.4035</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.6.6.3">0.4773</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.6.6.4">0.9082</td>
<td class="ltx_td ltx_align_center" id="S4.T3.2.6.6.5">0.6584</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_b ltx_border_r" id="S4.T3.2.7.7.1">mbart-deploy-no-finetune</th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S4.T3.2.7.7.2">8.3157</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S4.T3.2.7.7.3">0.4387</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S4.T3.2.7.7.4">0.9005</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S4.T3.2.7.7.5">0.6273</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T3.3.1.1" style="font-size:90%;">Table 3</span>. </span><span class="ltx_text" id="S4.T3.4.2" style="font-size:90%;">Evaluation Scores for Baseline(bl) Models and deployed model, where NLLB and mBART are trained with three epochs, and Opus is trained with ten epochs (10E) </span></figcaption>
</figure>
<figure class="ltx_figure" id="S4.F5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F5.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="449" id="S4.F5.sf1.g1" src="extracted/5591987/Images/opus-bl.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F5.sf1.2.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S4.F5.sf1.3.2" style="font-size:90%;">OPUS-MT Training Curve - 10E</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F5.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="449" id="S4.F5.sf2.g1" src="extracted/5591987/Images/mbart-bl.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F5.sf2.2.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S4.F5.sf2.3.2" style="font-size:90%;">mBART Training Curve - 3E</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F5.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="449" id="S4.F5.sf3.g1" src="extracted/5591987/Images/nllb-bl.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F5.sf3.2.1.1" style="font-size:90%;">(c)</span> </span><span class="ltx_text" id="S4.F5.sf3.3.2" style="font-size:90%;">NLLB Training Curve - 10E</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F5.2.1.1" style="font-size:90%;">Figure 5</span>. </span><span class="ltx_text" id="S4.F5.3.2" style="font-size:90%;">Training Curves for Various Models</span></figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Baseline Models</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">The results for the fine-tuned baseline model are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S4.T3" title="Table 3 ‣ 4.1.3. Human Evaluation ‣ 4.1. Evaluation Method ‣ 4. Experimental Evaluations ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a>. Additionally, the learning curves for each baseline model have been drawn and shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S4.F5" title="Figure 5 ‣ 4.1.3. Human Evaluation ‣ 4.1. Evaluation Method ‣ 4. Experimental Evaluations ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">5</span></a>.
The learning curves show that the NLLB model reaches its highest score at Epoch 3, followed by a significant decline until Epoch 6, after which it recovers at Epoch 10. Therefore, using only three epochs on training with the rest of the models is justifiable. On the other hand, the Opus-MT model exhibits a gradual improvement in the SacreBLEU score across epochs despite experiencing minor fluctuations along the way.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">It can also be seen from the results that NLLB scores the highest across all four metrics, and therefore, it can be concluded that it performs the best for the translation task, which further justifies the choice of the pivot model. Furthermore, it can also be said that larger models and models with Cantonese in the pre-training produce better outputs.</p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">Another result that can be seen is that with minimal fine-tuning, all three baseline models have a much higher score when compared to the deployed models, improving from 5 to 7 in terms of absolute SacreBLEU score; the same phenomenon can also be seen in other metrics.</p>
</div>
<figure class="ltx_figure" id="S4.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="225" id="S4.F6.g1" src="extracted/5591987/Images/back-syn.png" width="299"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F6.2.1.1" style="font-size:90%;">Figure 6</span>. </span><span class="ltx_text" id="S4.F6.3.2" style="font-size:90%;">Effect on SacreBLEU with different ratios of synthetic data</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Back-Translation</h3>
<figure class="ltx_table" id="S4.T4">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T4.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T4.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T4.2.1.1.1">Model Name</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T4.2.1.1.2">SacreBLEU</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T4.2.1.1.3">hLEPOR</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T4.2.1.1.4">BERTscore</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T4.2.1.1.5">COMET</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.2.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T4.2.2.1.1">nllb-forward-bl</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.2.2.1.2">16.5117</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.2.2.1.3">0.5651</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.2.2.1.4">0.9248</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.2.2.1.5">0.7376</td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.2.3.2.1">nllb-forward-syn-h:h</th>
<td class="ltx_td ltx_align_center" id="S4.T4.2.3.2.2">15.7751</td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.3.2.3">0.5616</td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.3.2.4">0.9235</td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.3.2.5">0.7342</td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.2.4.3.1">nllb-forward-syn-1:1</th>
<td class="ltx_td ltx_align_center" id="S4.T4.2.4.3.2"><span class="ltx_text ltx_font_bold" id="S4.T4.2.4.3.2.1">16.5901</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.4.3.3">0.5686</td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.4.3.4"><span class="ltx_text ltx_font_bold" id="S4.T4.2.4.3.4.1">0.925</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.4.3.5"><span class="ltx_text ltx_font_bold" id="S4.T4.2.4.3.5.1">0.7409</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.2.5.4.1">nllb-forward-syn-1:1-10E</th>
<td class="ltx_td ltx_align_center" id="S4.T4.2.5.4.2">16.5203</td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.5.4.3"><span class="ltx_text ltx_font_bold" id="S4.T4.2.5.4.3.1">0.5689</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.5.4.4">0.9247</td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.5.4.5">0.738</td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.2.6.5.1">nllb-forward-syn-1:3</th>
<td class="ltx_td ltx_align_center" id="S4.T4.2.6.5.2">15.9175</td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.6.5.3">0.5626</td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.6.5.4">0.924</td>
<td class="ltx_td ltx_align_center" id="S4.T4.2.6.5.5">0.7376</td>
</tr>
<tr class="ltx_tr" id="S4.T4.2.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_b ltx_border_r" id="S4.T4.2.7.6.1">nllb-forward-syn-1:5</th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S4.T4.2.7.6.2">15.8074</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S4.T4.2.7.6.3">0.562</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S4.T4.2.7.6.4">0.9237</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S4.T4.2.7.6.5">0.7386</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T4.3.1.1" style="font-size:90%;">Table 4</span>. </span><span class="ltx_text" id="S4.T4.4.2" style="font-size:90%;">Evaluation Scores for Baseline(bl) Models and model trained with synthetic data (syn), where the first number indicates the ratio of the gold standard data used (h=half), and the second number indicates the ratio of synthetic data used</span></figcaption>
</figure>
<figure class="ltx_figure" id="S4.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="225" id="S4.F7.g1" src="extracted/5591987/Images/forward-syn.png" width="299"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F7.2.1.1" style="font-size:90%;">Figure 7</span>. </span><span class="ltx_text" id="S4.F7.3.2" style="font-size:90%;">Effect on SacreBLEU with different ratios of synthetic data</span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">The first phase of back-translation involves training a backward model (English -¿ Cantonese), where synthetic data are used in a set of ratios. A graph showing the SacreBLEU score against the ratio used ranging from 0 to 3, where 0 indicates no synthetic data is used, is shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S4.F6" title="Figure 6 ‣ 4.2. Baseline Models ‣ 4. Experimental Evaluations ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">6</span></a>.
The results indicate that the quality of the translation drops significantly with synthetic data. Potential reasons that may lead to the result are poor translation quality for the forward model or poor quality of the monolingual corpus. We are more inclined toward the latter since back-translation has proven to improve the system a lot in the literature on other language pairs. A potential improvement in the future for this aspect can be cleaning the dataset with different methods, including grammar checking, which is proposed by <cite class="ltx_cite ltx_citemacro_citet">Pham et al<span class="ltx_text">.</span> (<a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib37" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">Therefore, the chosen model for generating back-translation synthetic data is the baseline model trained with no synthetic data where 200K sentences are generated through the model selected.
The results for back-translation with a single model - NLLB are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S4.T4" title="Table 4 ‣ 4.3. Back-Translation ‣ 4. Experimental Evaluations ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">4</span></a> and a graph showing the SacreBLEU score against the ratio used ranging from 0 to 5, where 0 indicates no synthetic data is used, is shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S4.F7" title="Figure 7 ‣ 4.3. Back-Translation ‣ 4. Experimental Evaluations ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">Based on the results, NLLB-syn-1:1 slightly outperforms NLLB-bl across all metrics. However, increasing the proportion of synthetic data, as in 1:3 and 1:5 ratios, results in a decline of approximately one absolute SacreBLEU point. The results have shown that <span class="ltx_text ltx_font_italic" id="S4.SS3.p3.1.1">using synthetic data improves performance slightly</span>. Still, with too much synthetic data, since there might be more errors introduced to the data, the translation quality decreases.</p>
</div>
<figure class="ltx_table" id="S4.T5">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T5.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T5.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T5.2.1.1.1">Model Name</th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.2.1.1.2">SacreBLEU</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.2.1.1.3">hLEPOR</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.2.1.1.4">BERTscore</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.2.1.1.5">COMET</td>
</tr>
<tr class="ltx_tr" id="S4.T5.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T5.2.2.2.1">nllb-forward-bl</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.2.2.2.2">16.5117</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.2.2.2.3">0.5651</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.2.2.2.4">0.9248</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.2.2.2.5">0.7376</td>
</tr>
<tr class="ltx_tr" id="S4.T5.2.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.2.3.3.1">nllb-forward-syn-h:h</th>
<td class="ltx_td ltx_align_center" id="S4.T5.2.3.3.2">15.7751</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.3.3.3">0.5616</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.3.3.4">0.9235</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.3.3.5">0.7342</td>
</tr>
<tr class="ltx_tr" id="S4.T5.2.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.2.4.4.1">nllb-forward-syn-1:1</th>
<td class="ltx_td ltx_align_center" id="S4.T5.2.4.4.2"><span class="ltx_text ltx_font_bold" id="S4.T5.2.4.4.2.1">16.5901</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.4.4.3">0.5686</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.4.4.4"><span class="ltx_text ltx_font_bold" id="S4.T5.2.4.4.4.1">0.925</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.4.4.5"><span class="ltx_text ltx_font_bold" id="S4.T5.2.4.4.5.1">0.7409</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.2.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.2.5.5.1">nllb-forward-syn-1:1-10E</th>
<td class="ltx_td ltx_align_center" id="S4.T5.2.5.5.2">16.5203</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.5.5.3"><span class="ltx_text ltx_font_bold" id="S4.T5.2.5.5.3.1">0.5689</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.5.5.4">0.9247</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.5.5.5">0.738</td>
</tr>
<tr class="ltx_tr" id="S4.T5.2.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.2.6.6.1">nllb-forward-syn-1:3</th>
<td class="ltx_td ltx_align_center" id="S4.T5.2.6.6.2">15.9175</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.6.6.3">0.5626</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.6.6.4">0.924</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.6.6.5">0.7376</td>
</tr>
<tr class="ltx_tr" id="S4.T5.2.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.2.7.7.1">nllb-forward-syn-1:5</th>
<td class="ltx_td ltx_align_center" id="S4.T5.2.7.7.2">15.8074</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.7.7.3">0.562</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.7.7.4">0.9237</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.7.7.5">0.7386</td>
</tr>
<tr class="ltx_tr" id="S4.T5.2.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T5.2.8.8.1">nllb-forward-syn-1:1-mbart</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.2.8.8.2"><span class="ltx_text ltx_font_bold" id="S4.T5.2.8.8.2.1">16.8077</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.2.8.8.3"><span class="ltx_text ltx_font_bold" id="S4.T5.2.8.8.3.1">0.571</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.2.8.8.4"><span class="ltx_text ltx_font_bold" id="S4.T5.2.8.8.4.1">0.9256</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.2.8.8.5"><span class="ltx_text ltx_font_bold" id="S4.T5.2.8.8.5.1">0.7425</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.2.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.2.9.9.1">nllb-forward-syn-1:3-mbart</th>
<td class="ltx_td ltx_align_center" id="S4.T5.2.9.9.2">15.8621</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.9.9.3">0.5617</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.9.9.4">0.9246</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.9.9.5">0.7384</td>
</tr>
<tr class="ltx_tr" id="S4.T5.2.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.2.10.10.1">nllb-forward-syn-1:1-opus</th>
<td class="ltx_td ltx_align_center" id="S4.T5.2.10.10.2">16.5537</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.10.10.3">0.5704</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.10.10.4">0.9254</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.10.10.5">0.7416</td>
</tr>
<tr class="ltx_tr" id="S4.T5.2.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.2.11.11.1">nllb-forward-syn-1:3-opus</th>
<td class="ltx_td ltx_align_center" id="S4.T5.2.11.11.2">15.9348</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.11.11.3">0.5651</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.11.11.4">0.9242</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.11.11.5">0.7374</td>
</tr>
<tr class="ltx_tr" id="S4.T5.2.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T5.2.12.12.1">mbart-forward-bl</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.2.12.12.2">15.7513</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.2.12.12.3">0.5623</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.2.12.12.4">0.9227</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.2.12.12.5">0.7314</td>
</tr>
<tr class="ltx_tr" id="S4.T5.2.13.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.2.13.13.1">mbart-forward-syn-1:1-nllb</th>
<td class="ltx_td ltx_align_center" id="S4.T5.2.13.13.2"><span class="ltx_text ltx_font_bold" id="S4.T5.2.13.13.2.1">16.0358</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.13.13.3"><span class="ltx_text ltx_font_bold" id="S4.T5.2.13.13.3.1">0.5681</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.13.13.4"><span class="ltx_text ltx_font_bold" id="S4.T5.2.13.13.4.1">0.9241</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.13.13.5"><span class="ltx_text ltx_font_bold" id="S4.T5.2.13.13.5.1">0.738</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.2.14.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.2.14.14.1">mbart-forward-syn-1:3-nllb</th>
<td class="ltx_td ltx_align_center" id="S4.T5.2.14.14.2">15.326</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.14.14.3">0.5584</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.14.14.4">0.9225</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.14.14.5">0.7319</td>
</tr>
<tr class="ltx_tr" id="S4.T5.2.15.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T5.2.15.15.1">opus-forward-bl-10E</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.2.15.15.2"><span class="ltx_text ltx_font_bold" id="S4.T5.2.15.15.2.1">15.0602</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.2.15.15.3"><span class="ltx_text ltx_font_bold" id="S4.T5.2.15.15.3.1">0.5581</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.2.15.15.4"><span class="ltx_text ltx_font_bold" id="S4.T5.2.15.15.4.1">0.9219</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.2.15.15.5"><span class="ltx_text ltx_font_bold" id="S4.T5.2.15.15.5.1">0.7193</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.2.16.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.2.16.16.1">opus-forward-syn-1:1-10E-nllb</th>
<td class="ltx_td ltx_align_center" id="S4.T5.2.16.16.2">13.0623</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.16.16.3">0.5409</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.16.16.4">0.9164</td>
<td class="ltx_td ltx_align_center" id="S4.T5.2.16.16.5">0.6897</td>
</tr>
<tr class="ltx_tr" id="S4.T5.2.17.17">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_b ltx_border_r" id="S4.T5.2.17.17.1">opus-forward-syn-1:3-10E-nllb</th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S4.T5.2.17.17.2">13.3666</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S4.T5.2.17.17.3">0.5442</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S4.T5.2.17.17.4">0.9167</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S4.T5.2.17.17.5">0.6957</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T5.3.1.1" style="font-size:90%;">Table 5</span>. </span><span class="ltx_text" id="S4.T5.4.2" style="font-size:90%;">Automatic Evaluation Scores from Model-Switch Models and previous results, where the prefix model name indicates the model type, where there is a postfix model, it indicates the model that generated the synthetic data.
</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4. </span>Plug-and-Play Model Outcomes</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">Based on the previous results and the suspected data quality issue, no re-back translations are being done here, and the generated synthetic data from English to Cantonese are using models fine-tuned with gold standard data only.
Results are then reported for the model-switch models and are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S4.T5" title="Table 5 ‣ 4.3. Back-Translation ‣ 4. Experimental Evaluations ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">5</span></a>.
From the results, a similar conclusion from above can be drawn from the mBART model too, where mBART-syn-1:1 also outperforms mBART-bl, but more ratios of synthetic data will reduce the evaluation scores such as 1:3.</p>
</div>
<div class="ltx_para" id="S4.SS4.p2">
<p class="ltx_p" id="S4.SS4.p2.1">Surprisingly, none of the synthetic models for Opus-MT outperforms Opus-bl, which might indicate that <span class="ltx_text ltx_font_italic" id="S4.SS4.p2.1.1">with small models, the error introduced from the synthetic data might confuse the model with its pre-training</span> and lead to a drop in translation quality.</p>
</div>
<div class="ltx_para" id="S4.SS4.p3">
<p class="ltx_p" id="S4.SS4.p3.1"><span class="ltx_text ltx_font_italic" id="S4.SS4.p3.1.1">Model-switching could produce a better result when compared to the single-model approach</span>. Firstly, the NLLB model that was fine-tuned using synthetic data from mBART achieved higher scores than when it was fine-tuned with synthetic data generated from itself with 0.2 SacreBLEU point. Secondly, when mBART was fine-tuned using synthetic data produced by NLLB, its performance surpassed fine-tuned with only bilingual real data. Thirdly, Opus-MT demonstrated a different performance pattern compared to the other two models under similar circumstances probably for the same reason mentioned above.</p>
</div>
<figure class="ltx_table" id="S4.T6">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T6.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T6.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T6.2.1.1.1">Model Name</th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T6.2.1.1.2">SacreBLEU</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T6.2.1.1.3">hLEPOR</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T6.2.1.1.4">BERTscore</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T6.2.1.1.5">COMET</td>
</tr>
<tr class="ltx_tr" id="S4.T6.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T6.2.2.2.1">nllb-forward-bl</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.2.2.2.2">16.5117</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.2.2.2.3">0.5651</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.2.2.2.4">0.9248</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.2.2.2.5">0.7376</td>
</tr>
<tr class="ltx_tr" id="S4.T6.2.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T6.2.3.3.1">mbart-forward-bl</th>
<td class="ltx_td ltx_align_center" id="S4.T6.2.3.3.2">15.7513</td>
<td class="ltx_td ltx_align_center" id="S4.T6.2.3.3.3">0.5623</td>
<td class="ltx_td ltx_align_center" id="S4.T6.2.3.3.4">0.9227</td>
<td class="ltx_td ltx_align_center" id="S4.T6.2.3.3.5">0.7314</td>
</tr>
<tr class="ltx_tr" id="S4.T6.2.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T6.2.4.4.1">opus-forward-bl-10E</th>
<td class="ltx_td ltx_align_center" id="S4.T6.2.4.4.2">15.0602</td>
<td class="ltx_td ltx_align_center" id="S4.T6.2.4.4.3">0.5581</td>
<td class="ltx_td ltx_align_center" id="S4.T6.2.4.4.4">0.9219</td>
<td class="ltx_td ltx_align_center" id="S4.T6.2.4.4.5">0.7193</td>
</tr>
<tr class="ltx_tr" id="S4.T6.2.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T6.2.5.5.1">nllb-forward-syn-1:1-mbart</th>
<td class="ltx_td ltx_align_center" id="S4.T6.2.5.5.2">16.8077</td>
<td class="ltx_td ltx_align_center" id="S4.T6.2.5.5.3">0.571</td>
<td class="ltx_td ltx_align_center" id="S4.T6.2.5.5.4">0.9256</td>
<td class="ltx_td ltx_align_center" id="S4.T6.2.5.5.5">0.7425</td>
</tr>
<tr class="ltx_tr" id="S4.T6.2.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T6.2.6.6.1">mbart-forward-syn-1:1-nllb</th>
<td class="ltx_td ltx_align_center" id="S4.T6.2.6.6.2">16.0358</td>
<td class="ltx_td ltx_align_center" id="S4.T6.2.6.6.3">0.5681</td>
<td class="ltx_td ltx_align_center" id="S4.T6.2.6.6.4">0.9241</td>
<td class="ltx_td ltx_align_center" id="S4.T6.2.6.6.5">0.738</td>
</tr>
<tr class="ltx_tr" id="S4.T6.2.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T6.2.7.7.1">nllb-forward-all3corpus</th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T6.2.7.7.2"><span class="ltx_text ltx_font_bold" id="S4.T6.2.7.7.2.1">16.9986</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T6.2.7.7.3"><span class="ltx_text ltx_font_bold" id="S4.T6.2.7.7.3.1">0.583</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T6.2.7.7.4"><span class="ltx_text ltx_font_bold" id="S4.T6.2.7.7.4.1">0.927</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T6.2.7.7.5"><span class="ltx_text ltx_font_bold" id="S4.T6.2.7.7.5.1">0.7549</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.2.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T6.2.8.8.1">nllb-forward-all3corpus-10E</th>
<td class="ltx_td ltx_align_center" id="S4.T6.2.8.8.2">16.1749</td>
<td class="ltx_td ltx_align_center" id="S4.T6.2.8.8.3">0.5728</td>
<td class="ltx_td ltx_align_center" id="S4.T6.2.8.8.4">0.9254</td>
<td class="ltx_td ltx_align_center" id="S4.T6.2.8.8.5">0.7508</td>
</tr>
<tr class="ltx_tr" id="S4.T6.2.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T6.2.9.9.1">mbart-forward-all3corpus</th>
<td class="ltx_td ltx_align_center" id="S4.T6.2.9.9.2">16.3204</td>
<td class="ltx_td ltx_align_center" id="S4.T6.2.9.9.3">0.5766</td>
<td class="ltx_td ltx_align_center" id="S4.T6.2.9.9.4">0.9253</td>
<td class="ltx_td ltx_align_center" id="S4.T6.2.9.9.5">0.7482</td>
</tr>
<tr class="ltx_tr" id="S4.T6.2.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_b ltx_border_r" id="S4.T6.2.10.10.1">opus-forward-all3corpus-10E</th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S4.T6.2.10.10.2">14.4699</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S4.T6.2.10.10.3">0.5621</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S4.T6.2.10.10.4">0.9191</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S4.T6.2.10.10.5">0.7074</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T6.3.1.1" style="font-size:90%;">Table 6</span>. </span><span class="ltx_text" id="S4.T6.4.2" style="font-size:90%;">Evaluation Scores with More Data fine-tuning and selection of previous results</span></figcaption>
</figure>
<figure class="ltx_figure" id="S4.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="225" id="S4.F8.g1" src="extracted/5591987/Images/moredata.png" width="299"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F8.2.1.1" style="font-size:90%;">Figure 8</span>. </span><span class="ltx_text" id="S4.F8.3.2" style="font-size:90%;">SacreBLEU score with the baseline model, best model and all three corpus fine-tuning</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5. </span>Integrating More Real Data</h3>
<div class="ltx_para" id="S4.SS5.p1">
<p class="ltx_p" id="S4.SS5.p1.1">The additional collected datasets during the project are also used for fine-tuning the three different models, where results are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S4.T6" title="Table 6 ‣ 4.4. Plug-and-Play Model Outcomes ‣ 4. Experimental Evaluations ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">6</span></a> and Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S4.F8" title="Figure 8 ‣ 4.4. Plug-and-Play Model Outcomes ‣ 4. Experimental Evaluations ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">8</span></a>. From the results, it can be seen that fine-tuning with all three corpora outperforms the best model for NLLB and mBART; however, this is not the case for Opus-MT.
These results indicate the idea that Data Quality Matters, where even though less data is given (62K vs 76K), the models perform higher scores when compared to the best synthetic model from NLLB and mBART, respectively. This also could be a potential future work where the experiments can be re-conducted with more data, which should provide better results theoretically.</p>
</div>
<div class="ltx_para" id="S4.SS5.p2">
<p class="ltx_p" id="S4.SS5.p2.1">Another key point to this result is that the improvement shows that translation quality has generally improved, not just for the specific translation style in the test set. Since multiple datasets are combined for the training, the model should not be biased to the translation style in Words.hk but rather a more general style, which should provide a better translation output for human judgements, not just for automatic metric scores.</p>
</div>
<div class="ltx_para" id="S4.SS5.p3">
<p class="ltx_p" id="S4.SS5.p3.1">However, training with more data with OPUS-MT does not provide better performance, which might be suspect to the different translation styles in datasets; since it is a small model, there is a chance that it fully adapts to the Words.hk dataset rather than actually understanding the task of translation, where literature refers to this phenomenon as “translationese”<span class="ltx_note ltx_role_footnote" id="footnote23"><sup class="ltx_note_mark">23</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">23</sup><span class="ltx_tag ltx_tag_note">23</span>Awkwardness or ungrammatically of translation, such as due to the overly literal translation of idioms or syntax.</span></span></span>, which may lead to high automatic metric score but low-quality translation.</p>
</div>
<div class="ltx_para" id="S4.SS5.p4">
<p class="ltx_p" id="S4.SS5.p4.1">Nevertheless, these outcomes demonstrated the possibility of improving model performances with more available real data, at least for NLLB and mBART models.</p>
</div>
<figure class="ltx_table" id="S4.T7">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T7.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T7.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T7.2.1.1.1">Model Name</th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T7.2.1.1.2">SacreBLEU</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T7.2.1.1.3">hLEPOR</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T7.2.1.1.4">BERTscore</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T7.2.1.1.5">COMET</td>
</tr>
<tr class="ltx_tr" id="S4.T7.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T7.2.2.2.1">nllb-forward-bl</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.2.2.2.2">16.5117</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.2.2.2.3">0.5651</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.2.2.2.4">0.9248</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.2.2.2.5">0.7376</td>
</tr>
<tr class="ltx_tr" id="S4.T7.2.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.2.3.3.1">mbart-forward-bl</th>
<td class="ltx_td ltx_align_center" id="S4.T7.2.3.3.2">15.7513</td>
<td class="ltx_td ltx_align_center" id="S4.T7.2.3.3.3">0.5623</td>
<td class="ltx_td ltx_align_center" id="S4.T7.2.3.3.4">0.9227</td>
<td class="ltx_td ltx_align_center" id="S4.T7.2.3.3.5">0.7314</td>
</tr>
<tr class="ltx_tr" id="S4.T7.2.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.2.4.4.1">opus-forward-bl-10E</th>
<td class="ltx_td ltx_align_center" id="S4.T7.2.4.4.2">15.0602</td>
<td class="ltx_td ltx_align_center" id="S4.T7.2.4.4.3">0.5581</td>
<td class="ltx_td ltx_align_center" id="S4.T7.2.4.4.4">0.9219</td>
<td class="ltx_td ltx_align_center" id="S4.T7.2.4.4.5">0.7193</td>
</tr>
<tr class="ltx_tr" id="S4.T7.2.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.2.5.5.1">nllb-forward-syn-1:1-mbart</th>
<td class="ltx_td ltx_align_center" id="S4.T7.2.5.5.2">16.8077</td>
<td class="ltx_td ltx_align_center" id="S4.T7.2.5.5.3">0.571</td>
<td class="ltx_td ltx_align_center" id="S4.T7.2.5.5.4">0.9256</td>
<td class="ltx_td ltx_align_center" id="S4.T7.2.5.5.5">0.7425</td>
</tr>
<tr class="ltx_tr" id="S4.T7.2.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.2.6.6.1">mbart-forward-syn-1:1-nllb</th>
<td class="ltx_td ltx_align_center" id="S4.T7.2.6.6.2">16.0358</td>
<td class="ltx_td ltx_align_center" id="S4.T7.2.6.6.3">0.5681</td>
<td class="ltx_td ltx_align_center" id="S4.T7.2.6.6.4">0.9241</td>
<td class="ltx_td ltx_align_center" id="S4.T7.2.6.6.5">0.738</td>
</tr>
<tr class="ltx_tr" id="S4.T7.2.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T7.2.7.7.1">baidu</th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T7.2.7.7.2">16.5669</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T7.2.7.7.3">0.5654</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T7.2.7.7.4">0.9243</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T7.2.7.7.5">0.7401</td>
</tr>
<tr class="ltx_tr" id="S4.T7.2.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.2.8.8.1">bing</th>
<td class="ltx_td ltx_align_center" id="S4.T7.2.8.8.2">17.1098</td>
<td class="ltx_td ltx_align_center" id="S4.T7.2.8.8.3">0.5735</td>
<td class="ltx_td ltx_align_center" id="S4.T7.2.8.8.4">0.9258</td>
<td class="ltx_td ltx_align_center" id="S4.T7.2.8.8.5">0.7474</td>
</tr>
<tr class="ltx_tr" id="S4.T7.2.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_b ltx_border_r" id="S4.T7.2.9.9.1">gpt4-ft(CantoneseCompanion)</th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S4.T7.2.9.9.2"><span class="ltx_text ltx_font_bold" id="S4.T7.2.9.9.2.1">19.1622</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S4.T7.2.9.9.3"><span class="ltx_text ltx_font_bold" id="S4.T7.2.9.9.3.1">0.5917</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S4.T7.2.9.9.4"><span class="ltx_text ltx_font_bold" id="S4.T7.2.9.9.4.1">0.936</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S4.T7.2.9.9.5"><span class="ltx_text ltx_font_bold" id="S4.T7.2.9.9.5.1">0.805</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T7.3.1.1" style="font-size:90%;">Table 7</span>. </span><span class="ltx_text" id="S4.T7.4.2" style="font-size:90%;">Evaluation Score of State-of-the-art translators and selected models</span></figcaption>
</figure>
<figure class="ltx_figure" id="S4.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="225" id="S4.F9.g1" src="extracted/5591987/Images/commercial.png" width="299"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F9.2.1.1" style="font-size:90%;">Figure 9</span>. </span><span class="ltx_text" id="S4.F9.3.2" style="font-size:90%;">State-of-the-Art SacreBLEU Score against our best model</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.6. </span>Comparisons to the State-of-the-Art </h3>
<div class="ltx_para" id="S4.SS6.p1">
<p class="ltx_p" id="S4.SS6.p1.1">State-of-the-art translators are then put into comparison with our models and results are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S4.T7" title="Table 7 ‣ 4.5. Integrating More Real Data ‣ 4. Experimental Evaluations ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">7</span></a> and Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S4.F9" title="Figure 9 ‣ 4.5. Integrating More Real Data ‣ 4. Experimental Evaluations ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">9</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS6.p2">
<p class="ltx_p" id="S4.SS6.p2.1">Cutting-edge MT technologies from commercial companies have shown varied performance, with GPT-4 fine-tuned models achieving the highest evaluation scores. However, this specific version of GPT is closed behind the paywall. Even with the free version, there are <span class="ltx_text ltx_font_bold ltx_font_italic" id="S4.SS6.p2.1.1">limitations</span> such as restrictions on the number of input tokens (<span class="ltx_text ltx_font_italic" id="S4.SS6.p2.1.2">length</span> of input) and a lack of <span class="ltx_text ltx_font_italic" id="S4.SS6.p2.1.3">transparency</span> regarding the underlying mechanisms of GPT-4’s MT capabilities. Additionally, data <span class="ltx_text ltx_font_bold" id="S4.SS6.p2.1.4">privacy</span> concerns arise when users opt for engines developed by commercial entities, e.g. when translating private texts such as the clinical domain as discussed by <cite class="ltx_cite ltx_citemacro_citep">(Han et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib20" title="">2024</a>)</cite>.
On the other hand, our models stand out as an open-source alternative, offering users the flexibility to fine-tune the model with their data further or integrate additional models, ensuring full confidentiality for users.</p>
</div>
<div class="ltx_para" id="S4.SS6.p3">
<p class="ltx_p" id="S4.SS6.p3.1">In comparison, translators from Bing and Baidu have performed similarly to our best system. Notably, Bing’s translator exhibits slightly superior performance over Baidu, particularly in lexical-based metrics like SacreBLEU and hLEPOR, highlighting its effectiveness in MT tasks.
More inspection of the specific translators against our best model can be seen in the next section, where human evaluation is conducted.
A table that combines all the automatic evaluation results can be seen in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#A2.SS3" title="B.3. Automatic Evaluation Results ‣ Appendix B Evaluation Details ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">B.3</span></a></p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS7">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.7. </span>Human Evaluation</h3>
<div class="ltx_para" id="S4.SS7.p1">
<p class="ltx_p" id="S4.SS7.p1.1">Based on the previous evaluation results, three models/translators are chosen for human evaluation, which is GPT4, the best-performing translator; Bing, the best-performing commercial translator; and NLLB-syn-1:1-mBART, the best model<span class="ltx_note ltx_role_footnote" id="footnote24"><sup class="ltx_note_mark">24</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">24</sup><span class="ltx_tag ltx_tag_note">24</span>The extra datasets have not been found when human evaluation is conducted</span></span></span> in our system.</p>
</div>
<section class="ltx_subsubsection" id="S4.SS7.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.7.1. </span>Text Degeneration</h4>
<div class="ltx_para" id="S4.SS7.SSS1.p1">
<p class="ltx_p" id="S4.SS7.SSS1.p1.1">Upon first glance at the synthetic data and test set translations, some interesting phenomena are happening, described as <span class="ltx_text ltx_font_italic" id="S4.SS7.SSS1.p1.1.1">neural text degeneration</span> <cite class="ltx_cite ltx_citemacro_citep">(Holtzman et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib24" title="">2020</a>)</cite>. Examples of text degeneration can be seen in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S4.T8" title="Table 8 ‣ 4.7.1. Text Degeneration ‣ 4.7. Human Evaluation ‣ 4. Experimental Evaluations ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">8</span></a>. From the example, “handwritten” has been repeated multiple times, indicating the models generate repetitive and dull loops. This could be another point of future work to adopt some methods for minimising these situations.
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="S4.SS7.SSS1.p1.1.2">{CJK*}</span>UTF8bkai</p>
</div>
<figure class="ltx_table" id="S4.T8">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T8.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T8.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T8.2.1.1.1">Source Sentence</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T8.2.1.1.2">佢踢住對人字拖噉行出嚟。</td>
</tr>
<tr class="ltx_tr" id="S4.T8.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S4.T8.2.2.2.1">Model Translation</th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T8.2.2.2.2">He walked out with a pair of handwritten handwritten handwritten.</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T8.3.1.1" style="font-size:90%;">Table 8</span>. </span><span class="ltx_text" id="S4.T8.4.2" style="font-size:90%;">Example of Text Degeneration</span></figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS7.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.7.2. </span>Results</h4>
<div class="ltx_para" id="S4.SS7.SSS2.p1">
<p class="ltx_p" id="S4.SS7.SSS2.p1.1">The results are then used to calculate inter-annotator agreement (IAA), via a quadratic-weighted Cohen’s Kappa metric <cite class="ltx_cite ltx_citemacro_citep">(Cohen, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib9" title="">1968</a>)</cite>, where the ratings are grouped into two individual raters. The results are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S4.T9" title="Table 9 ‣ 4.7.2. Results ‣ 4.7. Human Evaluation ‣ 4. Experimental Evaluations ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">9</span></a>.</p>
</div>
<figure class="ltx_table" id="S4.T9">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T9.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T9.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T9.2.1.1.1">Metric</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T9.2.1.1.2">NLLB</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T9.2.1.1.3">Bing</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T9.2.1.1.4">GPT4</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T9.2.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T9.2.2.1.1">MIS</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.2.2.1.2">0.6671</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.2.2.1.3">0.6102</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.2.2.1.4">0.5700</td>
</tr>
<tr class="ltx_tr" id="S4.T9.2.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T9.2.3.2.1">TERM</th>
<td class="ltx_td ltx_align_center" id="S4.T9.2.3.2.2">0.5700</td>
<td class="ltx_td ltx_align_center" id="S4.T9.2.3.2.3">0.4775</td>
<td class="ltx_td ltx_align_center" id="S4.T9.2.3.2.4">0.3874</td>
</tr>
<tr class="ltx_tr" id="S4.T9.2.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T9.2.4.3.1">STYLE</th>
<td class="ltx_td ltx_align_center" id="S4.T9.2.4.3.2">0.1123</td>
<td class="ltx_td ltx_align_center" id="S4.T9.2.4.3.3">0.3490</td>
<td class="ltx_td ltx_align_center" id="S4.T9.2.4.3.4">0.0348</td>
</tr>
<tr class="ltx_tr" id="S4.T9.2.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T9.2.5.4.1">GRAM</th>
<td class="ltx_td ltx_align_center" id="S4.T9.2.5.4.2">0.4212</td>
<td class="ltx_td ltx_align_center" id="S4.T9.2.5.4.3">0.2899</td>
<td class="ltx_td ltx_align_center" id="S4.T9.2.5.4.4">0.2850</td>
</tr>
<tr class="ltx_tr" id="S4.T9.2.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_b ltx_border_r ltx_border_t" id="S4.T9.2.6.5.1">Overall</th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_t" id="S4.T9.2.6.5.2">0.6230</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_t" id="S4.T9.2.6.5.3">0.6136</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_t" id="S4.T9.2.6.5.4">0.4935</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T9.3.1.1" style="font-size:90%;">Table 9</span>. </span><span class="ltx_text" id="S4.T9.4.2" style="font-size:90%;">Cohen’s Kappa for Different Models and Metrics</span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS7.SSS2.p2">
<p class="ltx_p" id="S4.SS7.SSS2.p2.1">The results show that the annotators have a substantial agreement level in the category of mistranslation <cite class="ltx_cite ltx_citemacro_citep">(Landis and Koch, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib28" title="">1977</a>)</cite> and the overall rating, which is calculated by adding all 4 metrics together. For the other metrics, terminology and grammar have shown a moderate agreement between annotators. However, there seems to be a low agreement level for style, which suggests that the guidelines might need more refinement and detailed explanations, or more likely, translation style is very personal and should not be a major contributing factor to whether or not the translation is good or not.</p>
</div>
<div class="ltx_para" id="S4.SS7.SSS2.p3">
<p class="ltx_p" id="S4.SS7.SSS2.p3.1">Since the annotators have shown some kind of agreement, the results shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S4.T10" title="Table 10 ‣ 4.7.2. Results ‣ 4.7. Human Evaluation ‣ 4. Experimental Evaluations ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">10</span></a> should have some indication of whether or not the translation is up-to-standard and can provide a better understanding of the models’ performance. Another table can be seen in Table <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#S4.T11" title="Table 11 ‣ 4.7.2. Results ‣ 4.7. Human Evaluation ‣ 4. Experimental Evaluations ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">11</span></a> for errors in individual models, where a major error is defined as a total score higher than 15 and a minor error is defined as lower than 15 but excluding 0. Translations with no errors in all 4 categories are defined as No error.</p>
</div>
<figure class="ltx_table" id="S4.T10">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T10.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T10.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T10.2.1.1.1">Metric</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T10.2.1.1.2">NLLB</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T10.2.1.1.3">Bing</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T10.2.1.1.4">GPT4</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T10.2.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T10.2.2.1.1">MIS</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T10.2.2.1.2">4.8025</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T10.2.2.1.3">2.9875</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T10.2.2.1.4">0.7025</td>
</tr>
<tr class="ltx_tr" id="S4.T10.2.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T10.2.3.2.1">TERM</th>
<td class="ltx_td ltx_align_center" id="S4.T10.2.3.2.2">3.62</td>
<td class="ltx_td ltx_align_center" id="S4.T10.2.3.2.3">2.1425</td>
<td class="ltx_td ltx_align_center" id="S4.T10.2.3.2.4">0.655</td>
</tr>
<tr class="ltx_tr" id="S4.T10.2.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T10.2.4.3.1">STYLE</th>
<td class="ltx_td ltx_align_center" id="S4.T10.2.4.3.2">3.01</td>
<td class="ltx_td ltx_align_center" id="S4.T10.2.4.3.3">2.3975</td>
<td class="ltx_td ltx_align_center" id="S4.T10.2.4.3.4">0.8425</td>
</tr>
<tr class="ltx_tr" id="S4.T10.2.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T10.2.5.4.1">GRAM</th>
<td class="ltx_td ltx_align_center" id="S4.T10.2.5.4.2">1.1475</td>
<td class="ltx_td ltx_align_center" id="S4.T10.2.5.4.3">0.82</td>
<td class="ltx_td ltx_align_center" id="S4.T10.2.5.4.4">0.1575</td>
</tr>
<tr class="ltx_tr" id="S4.T10.2.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_b ltx_border_r ltx_border_t" id="S4.T10.2.6.5.1">Overall</th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_t" id="S4.T10.2.6.5.2">12.58</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_t" id="S4.T10.2.6.5.3">8.3475</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_t" id="S4.T10.2.6.5.4">2.3575</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T10.3.1.1" style="font-size:90%;">Table 10</span>. </span><span class="ltx_text" id="S4.T10.4.2" style="font-size:90%;">Average Score for Different Models and Metrics</span></figcaption>
</figure>
<figure class="ltx_table" id="S4.T11">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T11.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T11.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T11.2.1.1.1">Errors</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T11.2.1.1.2">NLLB</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T11.2.1.1.3">Bing</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T11.2.1.1.4">GPT4</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T11.2.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T11.2.2.1.1">No Error</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T11.2.2.1.2">81</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T11.2.2.1.3">119</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T11.2.2.1.4">242</td>
</tr>
<tr class="ltx_tr" id="S4.T11.2.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T11.2.3.2.1">Minor Error</th>
<td class="ltx_td ltx_align_center" id="S4.T11.2.3.2.2">183</td>
<td class="ltx_td ltx_align_center" id="S4.T11.2.3.2.3">206</td>
<td class="ltx_td ltx_align_center" id="S4.T11.2.3.2.4">144</td>
</tr>
<tr class="ltx_tr" id="S4.T11.2.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_b ltx_border_r" id="S4.T11.2.4.3.1">Major Error</th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S4.T11.2.4.3.2">136</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S4.T11.2.4.3.3">75</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_b" id="S4.T11.2.4.3.4">14</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T11.3.1.1" style="font-size:90%;">Table 11</span>. </span><span class="ltx_text" id="S4.T11.4.2" style="font-size:90%;">Translation Errors for different models (200 sentences x 2 annotators for each model)</span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS7.SSS2.p4">
<p class="ltx_p" id="S4.SS7.SSS2.p4.1">The results have shown that fine-tuned GPT4 “CantoneseCompanion” is by far the best model for translation, where over half of the translations have shown no errors, and only 3% of translations have major errors according to the metric. Also, for the different metrics, GPT4 has shown similar performance except for grammar, which indicates that error types are quite diverse for GPT4.</p>
</div>
<div class="ltx_para" id="S4.SS7.SSS2.p5">
<p class="ltx_p" id="S4.SS7.SSS2.p5.1">Moreover, Bing performs better than the best model from NLLB, which is in line with the automatic metric. Nevertheless, both models have only around 25% translation, which is error-free. In the evaluation, it can be seen that there are quite a few cases for both models to translate the sentence literally, which leads to some slang not being correctly translated and, therefore, affects the quality of translation.</p>
</div>
<div class="ltx_para" id="S4.SS7.SSS2.p6">
<p class="ltx_p" id="S4.SS7.SSS2.p6.1">For our system, most errors stem from either mistranslation or terminology, which is often correlated since when a term is not correctly translated, it often causes meaning loss in the sentence. It can also be noticed that most of the sentences are often grammatically correct, which should be expected since the decoder part of the Transformers is trained with large amounts of English data and, therefore, should be well-versed in grammar knowledge.</p>
</div>
<div class="ltx_para" id="S4.SS7.SSS2.p7">
<p class="ltx_p" id="S4.SS7.SSS2.p7.1">The result here shows that additional effort will be needed to surpass one of the commercial translators, where there should be more effort put into improving the model’s knowledge of terminology and slang. For example, having a knowledge graph and knowledge base to represent different terminology and slang <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib53" title="">2020</a>; Han et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib21" title="">2020</a>)</cite> could potentially allow the model to understand more terminology in Cantonese. Further pre-training in Cantonese can potentially improve performance too.
Some example translations from our model can also be seen in the Appendix (Table <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#A2.T12" title="Table 12 ‣ B.1. Examples Output ‣ Appendix B Evaluation Details ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">12</span></a>).</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Conclusions and Future Work</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">This section combines the strategies and assessments covered, focusing on the central findings and contributions made to the NLP community. It acknowledges the limitations encountered along the way, setting the stage for subsequent efforts to enhance and expand upon the current milestones. Future work is proposed with the intent to capitalise on the progress made, address the shortcomings, and further research in this domain.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>Findings</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">The work focused on the investigation of data augmentation (via back- and forward-translation for synthetic data generation) and model-switch mechanism for Cantonese-to-English NMT, along with an open-sourced <span class="ltx_text ltx_font_smallcaps" id="S5.SS1.p1.1.1">CantonMT</span> toolkit release as well as the collected corpora.
The 4 main objectives that were outlined in the first section have been achieved:</p>
<ul class="ltx_itemize" id="S5.I1">
<li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i1.p1">
<p class="ltx_p" id="S5.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I1.i1.p1.1.1">Dataset Creation and Release</span> A new parallel dataset has been created by merging various existing corpora, which could serve as a valuable resource for researchers in the Cantonese Natural Language Processing (NLP) community for further exploration in this field.
Additionally, a substantial Cantonese monolingual dataset has been scraped and processed from an online forum, including anonymisation and data cleaning. This dataset could be extremely valuable for future research, such as Cantonese word embedding training for downstream NLP tasks, especially since, to the best of our knowledge, the data from the online forum is not publicly available.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i2.p1">
<p class="ltx_p" id="S5.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I1.i2.p1.1.1">Model Investigations: novel methods for Cantonese-English translation</span> Several models are developed and trained via back-translation to generate a synthetic parallel corpus for fine-tuning purposes, and the best models have reached comparable results against State-of-the-art commercial translators including Microsoft Bing and Baidu Translators, on the ground that we have very limited resources both computation and corpus wise. This work is the first to apply <span class="ltx_text ltx_font_italic" id="S5.I1.i2.p1.1.2">back-translation generated synthetic data</span> and <span class="ltx_text ltx_font_italic" id="S5.I1.i2.p1.1.3">model switch mechanisms</span> for augmenting Cantonese-English NMT in the field.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i3.p1">
<p class="ltx_p" id="S5.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I1.i3.p1.1.1">Experimental Evaluations: both automatic and human evaluations</span> Extensive experiments were conducted to evaluate the performances from trained models and the off-the-shelf translators, where multiple automatic evaluation metrics were used for comparison purposes, from both lexicon-based (BLER, hLEPOR) and embedding-space (COMET, BERTscore) categories. Furthermore, a standard human evaluation framework (HOPE) <cite class="ltx_cite ltx_citemacro_citep">(Gladkoff and Han, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib14" title="">2022</a>)</cite> has been modified and customised in this paper to compare different state-of-the-art translators against our best systems, where a clearer image of the models’ strengths and weaknesses can be seen.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i4.p1">
<p class="ltx_p" id="S5.I1.i4.p1.1"><span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="S5.I1.i4.p1.1.1">CantonMT<span class="ltx_text ltx_font_upright" id="S5.I1.i4.p1.1.1.1"> User Interface</span></span> A highly modular full-stack web application has been designed and developed as an open-sourced translation platform that can act as a toolkit for other researchers to add different models and language pairs to our platform and software packages. These have achieved the designed objectives of this investigation, where an open-sourced Cantonese-to-English translation tool has been developed.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>Challenges and Limitations</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">We list some limitations of our current investigation.</p>
<ul class="ltx_itemize" id="S5.I2">
<li class="ltx_item" id="S5.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I2.i1.p1">
<p class="ltx_p" id="S5.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I2.i1.p1.1.1">Data Restrictions</span> Even with a certain amount of data found during the investigation, we are aware that merely 60K data is not enough to train a model to reach expert-level performance for the Machine Translation task. It is hoped that in the future, there will be more resources in the realm of Cantonese Natural Language Processing, which could lead to a big improvement in different tasks related to Cantonese, including Automatic Speech Recognition, Machine Translation tasks, and others.</p>
</div>
</li>
<li class="ltx_item" id="S5.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I2.i2.p1">
<p class="ltx_p" id="S5.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I2.i2.p1.1.1">Computational Resources</span> Another major limitation that leads to only fine-tuning in the methodology is the lack of computing power. Training a Transformer to be fully capable of understanding the semantics and translating to a different language requires a substantial amount of computing power and data, which makes it impossible to take an existing model and conduct further pre-training.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3. </span>Future Work</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">Several areas can be further investigated to enhance the system’s translation quality and potentially increase the project’s impact.</p>
<ul class="ltx_itemize" id="S5.I3">
<li class="ltx_item" id="S5.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I3.i1.p1">
<p class="ltx_p" id="S5.I3.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I3.i1.p1.1.1">Enlarging Datasets</span> More datasets are found during the latter stages of the project. Due to the long training time needed for 1 full iteration of the model, there is not enough time to train the best model with a more data setup. It is hoped that in the future, a new model could be trained with the newly obtained dataset at the end of the full iteration, potentially reaching a new state-of-the-art performance compared to commercial translators.</p>
</div>
</li>
<li class="ltx_item" id="S5.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I3.i2.p1">
<p class="ltx_p" id="S5.I3.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I3.i2.p1.1.1">Data Cleaning</span> Another important aspect would be data cleaning. we strongly believe that with a better-quality monolingual dataset in Cantonese, there could be a significant improvement in building a better-performing model. Future work could be done where only high-quality sentences are extracted and used in the monolingual corpus rather than purely long sentences.</p>
</div>
</li>
<li class="ltx_item" id="S5.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I3.i3.p1">
<p class="ltx_p" id="S5.I3.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I3.i3.p1.1.1">Model Extensions</span> The investigation so far involves only fine-tuning of models, with more data available and different types of data which are not used in the current work, 2 approaches can be carried out to improve the system’s performance. a), as demonstrated in other papers, a potential way of building a better system could be connecting 2 BART models (Cantonese, English) with an additional layer in between, this approach would need huge computing power since additional training is needed to fine-tune BART as a Cantonese encoder rather than a Chinese encoder. b), during the pre-processing phase, we noticed that there could be a method to convert Cantonese characters to the romanisation of Cantonese (JyutPing), where studies in Chinese Machine Translation <cite class="ltx_cite ltx_citemacro_citep">(Du and Way, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib11" title="">2017</a>)</cite> have shown that with the romanisation of Chinese(PinYin), the performance of model could be improved.</p>
</div>
</li>
<li class="ltx_item" id="S5.I3.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I3.i4.p1">
<p class="ltx_p" id="S5.I3.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I3.i4.p1.1.1">User Interface Refinement</span> The existing user interface is still very raw and probably incapable of scaling if third parties wish to use the application for purposes other than local usage. The web application can be further developed to be more scalable for real-life deployment purposes.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
We thank Bernice Ko, Jasmine Chan, Anson Hong for their contributions to the human evaluation tasks.
We acknowledge the usage of open-source software NLLB, mBART, OpusMT; and the corpus from words.hk, Wenlin corpus, WMT2012, and LIHKG.
LH and GN are grateful for the grant “Integrating hospital outpatient letters into the healthcare data space” (EP/V047949/1; funder: UKRI/EPSRC).

</div>
</section>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bahdanau et al<span class="ltx_text" id="bib.bib2.2.2.1">.</span> (2015)</span>
<span class="ltx_bibblock">
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015.

</span>
<span class="ltx_bibblock">Neural Machine Translation by Jointly Learning to Align and Translate. In <em class="ltx_emph ltx_font_italic" id="bib.bib2.3.1">3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings</em>, Yoshua Bengio and Yann LeCun (Eds.).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1409.0473" title="">http://arxiv.org/abs/1409.0473</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bauer (2006)</span>
<span class="ltx_bibblock">
Robert S. Bauer. 2006.

</span>
<span class="ltx_bibblock">THE STRATIFICATION OF English LOANWORDS IN Cantonese.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Journal of Chinese Linguistics</em> 34, 2 (2006), 172–191.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://www.jstor.org/stable/23754122" title="">http://www.jstor.org/stable/23754122</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bojar and Tamchyna (2011)</span>
<span class="ltx_bibblock">
Ondřej Bojar and Aleš Tamchyna. 2011.

</span>
<span class="ltx_bibblock">Improving Translation Model by Monolingual Data. In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proceedings of the Sixth Workshop on Statistical Machine Translation</em>, Chris Callison-Burch, Philipp Koehn, Christof Monz, and Omar F. Zaidan (Eds.). Association for Computational Linguistics, Edinburgh, Scotland, 330–336.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/W11-2138" title="">https://aclanthology.org/W11-2138</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al<span class="ltx_text" id="bib.bib5.2.2.1">.</span> (1988)</span>
<span class="ltx_bibblock">
P. Brown, J. Cocke, S. Della Pietra, V. Della Pietra, F. Jelinek, R. Mercer, and P. Roossin. 1988.

</span>
<span class="ltx_bibblock">A statistical approach to language translation. In <em class="ltx_emph ltx_font_italic" id="bib.bib5.3.1">Proceedings of the 12th Conference on Computational Linguistics - Volume 1</em> (Budapest, Hungry) <em class="ltx_emph ltx_font_italic" id="bib.bib5.4.2">(COLING ’88)</em>. Association for Computational Linguistics, USA, 71–76.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.3115/991635.991651" title="">https://doi.org/10.3115/991635.991651</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Callison-Burch et al<span class="ltx_text" id="bib.bib6.2.2.1">.</span> (2012)</span>
<span class="ltx_bibblock">
Chris Callison-Burch, Philipp Koehn, Christof Monz, Matt Post, Radu Soricut, and Lucia Specia. 2012.

</span>
<span class="ltx_bibblock">Findings of the 2012 Workshop on Statistical Machine Translation. In <em class="ltx_emph ltx_font_italic" id="bib.bib6.3.1">Proceedings of the Seventh Workshop on Statistical Machine Translation</em>, Chris Callison-Burch, Philipp Koehn, Christof Monz, Matt Post, Radu Soricut, and Lucia Specia (Eds.). Association for Computational Linguistics, Montréal, Canada, 10–51.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/W12-3102" title="">https://aclanthology.org/W12-3102</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Callison-Burch et al<span class="ltx_text" id="bib.bib7.2.2.1">.</span> (2006)</span>
<span class="ltx_bibblock">
Chris Callison-Burch, Miles Osborne, and Philipp Koehn. 2006.

</span>
<span class="ltx_bibblock">Re-evaluating the Role of Bleu in Machine Translation Research. In <em class="ltx_emph ltx_font_italic" id="bib.bib7.3.1">11th Conference of the European Chapter of the Association for Computational Linguistics</em>, Diana McCarthy and Shuly Wintner (Eds.). Association for Computational Linguistics, Trento, Italy, 249–256.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/E06-1032" title="">https://aclanthology.org/E06-1032</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cho et al<span class="ltx_text" id="bib.bib8.2.2.1">.</span> (2014)</span>
<span class="ltx_bibblock">
Kyunghyun Cho, Bart van Merriënboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014.

</span>
<span class="ltx_bibblock">Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation. In <em class="ltx_emph ltx_font_italic" id="bib.bib8.3.1">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, Alessandro Moschitti, Bo Pang, and Walter Daelemans (Eds.). Association for Computational Linguistics, Doha, Qatar, 1724–1734.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.3115/v1/D14-1179" title="">https://doi.org/10.3115/v1/D14-1179</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cohen (1968)</span>
<span class="ltx_bibblock">
Jacob Cohen. 1968.

</span>
<span class="ltx_bibblock">Weighted Kappa - Nominal Scale Agreement with Provision for Scaled Disagreement Or Partial Credit.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Psychological bulletin</em> 70 (10 1968), 213–20.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1037/h0026256" title="">https://doi.org/10.1037/h0026256</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al<span class="ltx_text" id="bib.bib10.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.

</span>
<span class="ltx_bibblock">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In <em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>, Jill Burstein, Christy Doran, and Thamar Solorio (Eds.). Association for Computational Linguistics, Minneapolis, Minnesota, 4171–4186.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/N19-1423" title="">https://doi.org/10.18653/v1/N19-1423</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du and Way (2017)</span>
<span class="ltx_bibblock">
Jinhua Du and Andy Way. 2017.

</span>
<span class="ltx_bibblock">Pinyin as Subword Unit for Chinese-Sourced Neural Machine Translation. In <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Irish Conference on Artificial Intelligence and Cognitive Science</em>.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:19187847" title="">https://api.semanticscholar.org/CorpusID:19187847</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eberhard et al<span class="ltx_text" id="bib.bib12.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
David M. Eberhard, Gary F. Simons, and Charles D. Fennig. 2023.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.3.1">Ethnologue: Languages of the World</em> (26th ed.).

</span>
<span class="ltx_bibblock">SIL International.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Freitag et al<span class="ltx_text" id="bib.bib13.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Markus Freitag, Ricardo Rei, Nitika Mathur, Chi-kiu Lo, Craig Stewart, Eleftherios Avramidis, Tom Kocmi, George Foster, Alon Lavie, and André F. T. Martins. 2022.

</span>
<span class="ltx_bibblock">Results of WMT22 Metrics Shared Task: Stop Using BLEU – Neural Metrics Are Better and More Robust. In <em class="ltx_emph ltx_font_italic" id="bib.bib13.3.1">Proceedings of the Seventh Conference on Machine Translation (WMT)</em>, Philipp Koehn, Loïc Barrault, Ondřej Bojar, Fethi Bougares, Rajen Chatterjee, Marta R. Costa-jussà, Christian Federmann, Mark Fishel, Alexander Fraser, Markus Freitag, Yvette Graham, Roman Grundkiewicz, Paco Guzman, Barry Haddow, Matthias Huck, Antonio Jimeno Yepes, Tom Kocmi, André Martins, Makoto Morishita, Christof Monz, Masaaki Nagata, Toshiaki
Nakazawa, Matteo Negri, Aurélie Névéol, Mariana Neves, Martin Popel, Marco Turchi, and Marcos Zampieri (Eds.). Association for Computational Linguistics, Abu Dhabi, United Arab Emirates (Hybrid), 46–68.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2022.wmt-1.2" title="">https://aclanthology.org/2022.wmt-1.2</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gladkoff and Han (2022)</span>
<span class="ltx_bibblock">
Serge Gladkoff and Lifeng Han. 2022.

</span>
<span class="ltx_bibblock">HOPE: A Task-Oriented and Human-Centric Evaluation Framework Using Professional Post-Editing Towards More Effective MT Evaluation. In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of the Thirteenth Language Resources and Evaluation Conference</em>. European Language Resources Association, Marseille, France, 13–21.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2022.lrec-1.2" title="">https://aclanthology.org/2022.lrec-1.2</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gladkoff et al<span class="ltx_text" id="bib.bib15.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Serge Gladkoff, Irina Sorokina, Lifeng Han, and Alexandra Alekseeva. 2022.

</span>
<span class="ltx_bibblock">Measuring Uncertainty in Translation Quality Evaluation (TQE). In <em class="ltx_emph ltx_font_italic" id="bib.bib15.3.1">Proceedings of the Thirteenth Language Resources and Evaluation Conference</em>, Nicoletta Calzolari, Frédéric Béchet, Philippe Blache, Khalid Choukri, Christopher Cieri, Thierry Declerck, Sara Goggi, Hitoshi Isahara, Bente Maegaard, Joseph Mariani, Hélène Mazo, Jan Odijk, and Stelios Piperidis (Eds.). European Language Resources Association, Marseille, France, 1454–1461.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2022.lrec-1.156" title="">https://aclanthology.org/2022.lrec-1.156</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Graça et al<span class="ltx_text" id="bib.bib16.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Miguel Graça, Yunsu Kim, Julian Schamper, Shahram Khadivi, and Hermann Ney. 2019.

</span>
<span class="ltx_bibblock">Generalizing Back-Translation in Neural Machine Translation. In <em class="ltx_emph ltx_font_italic" id="bib.bib16.3.1">Proceedings of the Fourth Conference on Machine Translation (Volume 1: Research Papers)</em>, Ondřej Bojar, Rajen Chatterjee, Christian Federmann, Mark Fishel, Yvette Graham, Barry Haddow, Matthias Huck, Antonio Jimeno Yepes, Philipp Koehn, André Martins, Christof Monz, Matteo Negri, Aurélie Névéol, Mariana Neves, Matt Post, Marco Turchi, and Karin Verspoor (Eds.). Association for Computational Linguistics, Florence, Italy, 45–52.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/W19-5205" title="">https://doi.org/10.18653/v1/W19-5205</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et al<span class="ltx_text" id="bib.bib17.2.2.1">.</span> (2013a)</span>
<span class="ltx_bibblock">
Aaron Li-Feng Han, Derek F. Wong, Lidia S. Chao, Liangye He, Yi Lu, Junwen Xing, and Xiaodong Zeng. 2013a.

</span>
<span class="ltx_bibblock">Language-independent Model for Machine Translation Evaluation with Reinforced Factors. In <em class="ltx_emph ltx_font_italic" id="bib.bib17.3.1">Proceedings of Machine Translation Summit XIV: Posters</em>, Andy Way, Khalil Sima’an, and Mikel L. Forcada (Eds.). Nice, France.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2013.mtsummit-posters.3" title="">https://aclanthology.org/2013.mtsummit-posters.3</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et al<span class="ltx_text" id="bib.bib18.2.2.1">.</span> (2013b)</span>
<span class="ltx_bibblock">
Aaron Li-Feng Han, Derek F. Wong, Lidia S. Chao, Yi Lu, Liangye He, Yiming Wang, and Jiaji Zhou. 2013b.

</span>
<span class="ltx_bibblock">A Description of Tunable Machine Translation Evaluation Systems in WMT13 Metrics Task. In <em class="ltx_emph ltx_font_italic" id="bib.bib18.3.1">Proceedings of the Eighth Workshop on Statistical Machine Translation</em>, Ondrej Bojar, Christian Buck, Chris Callison-Burch, Barry Haddow, Philipp Koehn, Christof Monz, Matt Post, Herve Saint-Amand, Radu Soricut, and Lucia Specia (Eds.). Association for Computational Linguistics, Sofia, Bulgaria, 414–421.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/W13-2253" title="">https://aclanthology.org/W13-2253</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han (2022)</span>
<span class="ltx_bibblock">
Lifeng Han. 2022.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">An investigation into multi-word expressions in machine translation</em>.

</span>
<span class="ltx_bibblock">Ph. D. Dissertation. Dublin City University.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et al<span class="ltx_text" id="bib.bib20.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Lifeng Han, Serge Gladkoff, Gleb Erofeev, Irina Sorokina, Betty Galiano, and Goran Nenadic. 2024.

</span>
<span class="ltx_bibblock">Neural machine translation of clinical text: an empirical investigation into multilingual pre-trained language models and transfer-learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.3.1">Frontiers in Digital Health</em> 6 (2024), 1211564.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et al<span class="ltx_text" id="bib.bib21.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Lifeng Han, Gareth Jones, and Alan Smeaton. 2020.

</span>
<span class="ltx_bibblock">AlphaMWE: Construction of Multilingual Parallel Corpora with MWE Annotations. In <em class="ltx_emph ltx_font_italic" id="bib.bib21.3.1">Proceedings of the Joint Workshop on Multiword Expressions and Electronic Lexicons</em>, Stella Markantonatou, John McCrae, Jelena Mitrović, Carole Tiberius, Carlos Ramisch, Ashwini Vaidya, Petya Osenova, and Agata Savary (Eds.). Association for Computational Linguistics, online, 44–57.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2020.mwe-1.6" title="">https://aclanthology.org/2020.mwe-1.6</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ho and Or (2020)</span>
<span class="ltx_bibblock">
Justin Chun Ting Ho and Norman Hoi Kwan Or. 2020.

</span>
<span class="ltx_bibblock">LIHKGr.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/justinchuntingho/LIHKGr" title="">https://github.com/justinchuntingho/LIHKGr</a>.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">An application for scraping LIHKG.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hoang et al<span class="ltx_text" id="bib.bib23.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Vu Cong Duy Hoang, Philipp Koehn, Gholamreza Haffari, and Trevor Cohn. 2018.

</span>
<span class="ltx_bibblock">Iterative Back-Translation for Neural Machine Translation. In <em class="ltx_emph ltx_font_italic" id="bib.bib23.3.1">Proceedings of the 2nd Workshop on Neural Machine Translation and Generation</em>, Alexandra Birch, Andrew Finch, Thang Luong, Graham Neubig, and Yusuke Oda (Eds.). Association for Computational Linguistics, Melbourne, Australia, 18–24.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/W18-2703" title="">https://doi.org/10.18653/v1/W18-2703</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Holtzman et al<span class="ltx_text" id="bib.bib24.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. 2020.

</span>
<span class="ltx_bibblock">The Curious Case of Neural Text Degeneration. In <em class="ltx_emph ltx_font_italic" id="bib.bib24.3.1">International Conference on Learning Representations</em>.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=rygGQyrFvH" title="">https://openreview.net/forum?id=rygGQyrFvH</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hong et al<span class="ltx_text" id="bib.bib25.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Kung Yin Hong, Lifeng Han, Riza Batista-Navarro, and Goran Nenadic. 2024.

</span>
<span class="ltx_bibblock">CantonMT: Cantonese to English NMT Platform with Fine-Tuned Models Using Synthetic Back-Translation Data.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2403.11346 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma and Ba (2017)</span>
<span class="ltx_bibblock">
Diederik P. Kingma and Jimmy Ba. 2017.

</span>
<span class="ltx_bibblock">Adam: A Method for Stochastic Optimization.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1412.6980 [cs.LG]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koehn et al<span class="ltx_text" id="bib.bib27.2.2.1">.</span> (2003)</span>
<span class="ltx_bibblock">
Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003.

</span>
<span class="ltx_bibblock">Statistical phrase-based translation. In <em class="ltx_emph ltx_font_italic" id="bib.bib27.3.1">2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Langauge Technology (HLT-NAACL 2003)</em>. Association for Computational Linguistics, 48–54.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Landis and Koch (1977)</span>
<span class="ltx_bibblock">
J Richard Landis and Gary G. Koch. 1977.

</span>
<span class="ltx_bibblock">The measurement of observer agreement for categorical data.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Biometrics</em> 33 1 (1977), 159–74.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:11077516" title="">https://api.semanticscholar.org/CorpusID:11077516</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al<span class="ltx_text" id="bib.bib29.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Jackson L. Lee, Litong Chen, Charles Lam, Chaak Ming Lau, and Tsz-Him Tsui. 2022.

</span>
<span class="ltx_bibblock">PyCantonese: Cantonese Linguistics and NLP in Python. In <em class="ltx_emph ltx_font_italic" id="bib.bib29.3.1">Proceedings of The 13th Language Resources and Evaluation Conference</em>. European Language Resources Association.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et al<span class="ltx_text" id="bib.bib30.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020.

</span>
<span class="ltx_bibblock">BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension. In <em class="ltx_emph ltx_font_italic" id="bib.bib30.3.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, Dan Jurafsky, Joyce Chai, Natalie Schluter, and Joel Tetreault (Eds.). Association for Computational Linguistics, Online, 7871–7880.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2020.acl-main.703" title="">https://doi.org/10.18653/v1/2020.acl-main.703</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liang et al<span class="ltx_text" id="bib.bib31.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Guanqing Liang, Jingxin Zhao, Helena Yan Ping Lau, and Cane Wing-Ki Leung. 2021.

</span>
<span class="ltx_bibblock">Using Social Media to Analyze Public Concerns and Policy Responses to COVID-19 in Hong Kong.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.3.1">ACM Trans. Manage. Inf. Syst.</em> 12, 4, Article 30 (sep 2021), 20 pages.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3460124" title="">https://doi.org/10.1145/3460124</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu (2022)</span>
<span class="ltx_bibblock">
Evelyn Kai-Yan Liu. 2022.

</span>
<span class="ltx_bibblock">Low-Resource Neural Machine Translation: A Case Study of Cantonese. In <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Proceedings of the Ninth Workshop on NLP for Similar Languages, Varieties and Dialects</em>, Yves Scherrer, Tommi Jauhiainen, Nikola Ljubešić, Preslav Nakov, Jörg Tiedemann, and Marcos Zampieri (Eds.). Association for Computational Linguistics, Gyeongju, Republic of Korea, 28–40.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2022.vardial-1.4" title="">https://aclanthology.org/2022.vardial-1.4</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span class="ltx_text" id="bib.bib33.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, and Luke Zettlemoyer. 2020.

</span>
<span class="ltx_bibblock">Multilingual Denoising Pre-training for Neural Machine Translation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.3.1">Transactions of the Association for Computational Linguistics</em> 8 (2020), 726–742.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1162/tacl_a_00343" title="">https://doi.org/10.1162/tacl_a_00343</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">NLLB-Team et al<span class="ltx_text" id="bib.bib34.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
NLLB-Team, Marta R. Costa-jussà, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi, Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia Gonzalez, Prangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shannon Spruit, Chau Tran, Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela Fan,
Cynthia Gao, Vedanuj Goswami, Francisco Guzmán, Philipp Koehn, Alexandre Mourachko, Christophe Ropers, Safiyyah Saleem, Holger Schwenk, and Jeff Wang. 2022.

</span>
<span class="ltx_bibblock">No Language Left Behind: Scaling Human-Centered Machine Translation.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2207.04672 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2024)</span>
<span class="ltx_bibblock">
OpenAI. 2024.

</span>
<span class="ltx_bibblock">GPT-4 Technical Report.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2303.08774 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papineni et al<span class="ltx_text" id="bib.bib36.2.2.1">.</span> (2002)</span>
<span class="ltx_bibblock">
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002.

</span>
<span class="ltx_bibblock">Bleu: a Method for Automatic Evaluation of Machine Translation. In <em class="ltx_emph ltx_font_italic" id="bib.bib36.3.1">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</em>, Pierre Isabelle, Eugene Charniak, and Dekang Lin (Eds.). Association for Computational Linguistics, Philadelphia, Pennsylvania, USA, 311–318.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.3115/1073083.1073135" title="">https://doi.org/10.3115/1073083.1073135</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pham et al<span class="ltx_text" id="bib.bib37.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Nghia Luan Pham, Van Vinh Nguyen, and Thang Viet Pham. 2023.

</span>
<span class="ltx_bibblock">A Data Augmentation Method for English-Vietnamese Neural Machine Translation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.3.1">IEEE Access</em> 11 (2023), 28034–28044.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/ACCESS.2023.3252898" title="">https://doi.org/10.1109/ACCESS.2023.3252898</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Post (2018)</span>
<span class="ltx_bibblock">
Matt Post. 2018.

</span>
<span class="ltx_bibblock">A Call for Clarity in Reporting BLEU Scores. In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Proceedings of the Third Conference on Machine Translation: Research Papers</em>, Ondřej Bojar, Rajen Chatterjee, Christian Federmann, Mark Fishel, Yvette Graham, Barry Haddow, Matthias Huck, Antonio Jimeno Yepes, Philipp Koehn, Christof Monz, Matteo Negri, Aurélie Névéol, Mariana Neves, Matt Post, Lucia Specia, Marco Turchi, and Karin Verspoor (Eds.). Association for Computational Linguistics, Brussels, Belgium, 186–191.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/W18-6319" title="">https://doi.org/10.18653/v1/W18-6319</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sennrich et al<span class="ltx_text" id="bib.bib39.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016.

</span>
<span class="ltx_bibblock">Improving Neural Machine Translation Models with Monolingual Data. In <em class="ltx_emph ltx_font_italic" id="bib.bib39.3.1">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, Katrin Erk and Noah A. Smith (Eds.). Association for Computational Linguistics, Berlin, Germany, 86–96.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/P16-1009" title="">https://doi.org/10.18653/v1/P16-1009</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sugiyama and Yoshinaga (2019)</span>
<span class="ltx_bibblock">
Amane Sugiyama and Naoki Yoshinaga. 2019.

</span>
<span class="ltx_bibblock">Data augmentation using back-translation for context-aware neural machine translation. In <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">Proceedings of the Fourth Workshop on Discourse in Machine Translation (DiscoMT 2019)</em>, Andrei Popescu-Belis, Sharid Loáiciga, Christian Hardmeier, and Deyi Xiong (Eds.). Association for Computational Linguistics, Hong Kong, China, 35–44.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/D19-6504" title="">https://doi.org/10.18653/v1/D19-6504</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sutskever et al<span class="ltx_text" id="bib.bib41.2.2.1">.</span> (2014)</span>
<span class="ltx_bibblock">
Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014.

</span>
<span class="ltx_bibblock">Sequence to Sequence Learning with Neural Networks. In <em class="ltx_emph ltx_font_italic" id="bib.bib41.3.1">Proc. NIPS</em>. Montreal, CA.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1409.3215" title="">http://arxiv.org/abs/1409.3215</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et al<span class="ltx_text" id="bib.bib42.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Yuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu, and Angela Fan. 2020.

</span>
<span class="ltx_bibblock">Multilingual Translation with Extensible Multilingual Pretraining and Finetuning.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2008.00401 [cs.CL]

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tiedemann and Nygaard (2004)</span>
<span class="ltx_bibblock">
Jörg Tiedemann and Lars Nygaard. 2004.

</span>
<span class="ltx_bibblock">The OPUS Corpus - Parallel and Free: <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://logos.uio.no/opus" title="">http://logos.uio.no/opus</a>. In <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC’04)</em>, Maria Teresa Lino, Maria Francisca Xavier, Fátima Ferreira, Rute Costa, and Raquel Silva (Eds.). European Language Resources Association (ELRA), Lisbon, Portugal.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://www.lrec-conf.org/proceedings/lrec2004/pdf/320.pdf" title="">http://www.lrec-conf.org/proceedings/lrec2004/pdf/320.pdf</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tiedemann and Thottingal (2020)</span>
<span class="ltx_bibblock">
Jörg Tiedemann and Santhosh Thottingal. 2020.

</span>
<span class="ltx_bibblock">OPUS-MT — Building open translation services for the World. In <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">Proceedings of the 22nd Annual Conferenec of the European Association for Machine Translation (EAMT)</em>. Lisbon, Portugal.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al<span class="ltx_text" id="bib.bib45.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017.

</span>
<span class="ltx_bibblock">Attention is All You Need.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/pdf/1706.03762.pdf" title="">https://arxiv.org/pdf/1706.03762.pdf</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weaver (1952)</span>
<span class="ltx_bibblock">
Warren Weaver. 1952.

</span>
<span class="ltx_bibblock">Translation. In <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">Proceedings of the Conference on Mechanical Translation</em> (Massachusetts Institute of Technology).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/1952.earlymt-1.1" title="">https://aclanthology.org/1952.earlymt-1.1</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wiedenhof (2015)</span>
<span class="ltx_bibblock">
Jeroen Wiedenhof. 2015.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">A Grammar of Mandarin</em>.

</span>
<span class="ltx_bibblock">John Benjamins, Amsterdam.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wing (2020)</span>
<span class="ltx_bibblock">
Liu Hey Wing. 2020.

</span>
<span class="ltx_bibblock">Machine translation models for Cantonese-English translation Project Plan.

</span>
<span class="ltx_bibblock">(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wrigley (2023)</span>
<span class="ltx_bibblock">
Mckay Wrigley. 2023.

</span>
<span class="ltx_bibblock">ai-code-translator.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/mckaywrigley/ai-code-translator" title="">https://github.com/mckaywrigley/ai-code-translator</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span class="ltx_text" id="bib.bib50.2.2.1">.</span> (2006)</span>
<span class="ltx_bibblock">
Yan Wu, Xiukun Li, and Caesar Lun. 2006.

</span>
<span class="ltx_bibblock">A Structural-Based Approach to Cantonese-English Machine Translation. In <em class="ltx_emph ltx_font_italic" id="bib.bib50.3.1">International Journal of Computational Linguistics &amp; Chinese Language Processing, Volume 11, Number 2, June 2006</em>. 137–158.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/O06-3003" title="">https://aclanthology.org/O06-3003</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiang et al<span class="ltx_text" id="bib.bib51.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Rui Xiang, Hao Tan, Jian Li, Man Wan, and Kam-Fai Wong. 2022.

</span>
<span class="ltx_bibblock">When Cantonese NLP Meets Pre-training: Progress and Challenges. In <em class="ltx_emph ltx_font_italic" id="bib.bib51.3.1">Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing: Tutorial Abstracts</em>, Miguel A. Alonso and Zhi Wei (Eds.). Association for Computational Linguistics, 16–21.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2022.aacl-tutorials.3" title="">https://aclanthology.org/2022.aacl-tutorials.3</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yi Mak and Lee (2022)</span>
<span class="ltx_bibblock">
Hei Yi Mak and Tan Lee. 2022.

</span>
<span class="ltx_bibblock">Low-Resource NMT: A Case Study on the Written and Spoken Languages in Hong Kong. In <em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">Proceedings of the 2021 5th International Conference on Natural Language Processing and Information Retrieval</em> (Sanya, China) <em class="ltx_emph ltx_font_italic" id="bib.bib52.2.2">(NLPIR ’21)</em>. Association for Computing Machinery, New York, NY, USA, 81–87.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3508230.3508242" title="">https://doi.org/10.1145/3508230.3508242</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al<span class="ltx_text" id="bib.bib53.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Yang Zhao, Lu Xiang, Junnan Zhu, Jiajun Zhang, Yu Zhou, and Chengqing Zong. 2020.

</span>
<span class="ltx_bibblock">Knowledge Graph Enhanced Neural Machine Translation via Multi-task Learning on Sub-entity Granularity. In <em class="ltx_emph ltx_font_italic" id="bib.bib53.3.1">Proceedings of the 28th International Conference on Computational Linguistics</em>, Donia Scott, Nuria Bel, and Chengqing Zong (Eds.). International Committee on Computational Linguistics, Barcelona, Spain (Online), 4495–4505.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.18653/v1/2020.coling-main.397" title="">https://doi.org/10.18653/v1/2020.coling-main.397</a>
</span>
</li>
</ul>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span><span class="ltx_text ltx_font_smallcaps" id="A1.1.1">CantonMT</span> Open-sourced Toolkit</h2>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1. </span>Web Application</h3>
<div class="ltx_para" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.1">For potential users to evaluate between different models, a user interface was developed to allow users to choose between different trained models and different languages.</p>
</div>
<div class="ltx_para" id="A1.SS1.p2">
<p class="ltx_p" id="A1.SS1.p2.1">The web application contains two main parts, Interface and Server, and their interactions are described in the diagram and are detailed in the following subsections. Screenshots of the web application can also be seen in Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#A1.F10" title="Figure 10 ‣ A.1. Web Application ‣ Appendix A CantonMT Open-sourced Toolkit ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">10</span></a>.
<br class="ltx_break"/></p>
</div>
<figure class="ltx_figure" id="A1.F10"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="361" id="A1.F10.g1" src="extracted/5591987/Images/UserInterface.png" width="598"/>
<br class="ltx_break ltx_centering"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A1.F10.2.1.1" style="font-size:90%;">Figure 10</span>. </span><span class="ltx_text" id="A1.F10.3.2" style="font-size:90%;">Screenshots taken from Web Application</span></figcaption>
</figure>
<div class="ltx_para" id="A1.SS1.p3">
<p class="ltx_p" id="A1.SS1.p3.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#A1.F11" title="Figure 11 ‣ A.1. Web Application ‣ Appendix A CantonMT Open-sourced Toolkit ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">11</span></a> outlines the general data flow for the User Interface to aid readers in understanding the structure of the server and User Interface.</p>
</div>
<figure class="ltx_figure" id="A1.F11"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="314" id="A1.F11.g1" src="extracted/5591987/Images/User-Interface-Flow.png" width="592"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A1.F11.2.1.1" style="font-size:90%;">Figure 11</span>. </span><span class="ltx_text" id="A1.F11.3.2" style="font-size:90%;">Diagram for CantoMT User Interface Data Flow</span></figcaption>
</figure>
<section class="ltx_subsubsection" id="A1.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.1.1. </span>User Interface</h4>
<div class="ltx_para" id="A1.SS1.SSS1.p1">
<p class="ltx_p" id="A1.SS1.SSS1.p1.1">To test out the User Interface and different models for translation, users can choose different model types and languages, which dynamically capture the available model from the server and allow users to select different training methods for the model. One can then type the sentence in the input box and click the translate button for the translation output from the model.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="A1.SS1.SSS1.p2">
<p class="ltx_p" id="A1.SS1.SSS1.p2.1">The application layout is entirely modular in case different model types or languages are added to the system, which could potentially be used as a base framework for different translation systems and add more languages to the input and output if one wishes to expand the implementations.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="A1.SS1.SSS1.p3">
<p class="ltx_p" id="A1.SS1.SSS1.p3.1">This web application has taken a template <cite class="ltx_cite ltx_citemacro_citep">(Wrigley, <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#bib.bib49" title="">2023</a>)</cite> for an AI Code translator and modified it to fit the need, which is developed in TypeScript with the Next.js framework. The reason for choosing this framework is that it provides a very modern and minimalistic approach to web development.</p>
</div>
</section>
<section class="ltx_subsubsection" id="A1.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.1.2. </span>Server</h4>
<div class="ltx_para" id="A1.SS1.SSS2.p1">
<p class="ltx_p" id="A1.SS1.SSS2.p1.1">Users can easily run the server on their local machines, and it is well-documented in the Readme file in the code submission file. The server has two main functionalities, the first will output the list of model paths given the model type and source languages. The second one provides the translation, where one could provide the details of the model and the sentence in the specified language, and the server would respond with the translated sentence using the model output.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="A1.SS1.SSS2.p2">
<p class="ltx_p" id="A1.SS1.SSS2.p2.1">Due to a lack of memory space during the implementation, the server crashed multiple times on our local machine. To account for the potential crash, a model manager was produced, which implements an LRU cache for the different model loaders, where the least recently used model will be deleted from memory if it exceeds the limit of the number of models.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="A1.SS1.SSS2.p3">
<p class="ltx_p" id="A1.SS1.SSS2.p3.1">It can also be said that the code written is very modular, which could mean that in future work, which might be a completely new model type, one can add the class for the specific model type and expand on the base model loader with minimal effort.
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="A1.SS1.SSS2.p4">
<p class="ltx_p" id="A1.SS1.SSS2.p4.1">The server is built entirely on the Python Flask library. The Flask framework is chosen because the models can be run on the Python Transformers library, providing a seamless implementation without much additional effort.</p>
</div>
</section>
</section>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Evaluation Details</h2>
<section class="ltx_subsection" id="A2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1. </span>Examples Output</h3>
<div class="ltx_para" id="A2.SS1.p1">
<span class="ltx_ERROR undefined" id="A2.SS1.p1.1">{CJK*}</span>
<p class="ltx_p" id="A2.SS1.p1.2">UTF8bkai</p>
</div>
<figure class="ltx_table" id="A2.T12">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A2.T12.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T12.2.1.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="A2.T12.2.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A2.T12.2.1.1.1.1">
<span class="ltx_p" id="A2.T12.2.1.1.1.1.1" style="width:195.1pt;">Source Sentence</span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="A2.T12.2.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A2.T12.2.1.1.2.1">
<span class="ltx_p" id="A2.T12.2.1.1.2.1.1" style="width:195.1pt;">Model Translation</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T12.2.2.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A2.T12.2.2.1.1">
<span class="ltx_inline-block ltx_align_top" id="A2.T12.2.2.1.1.1">
<span class="ltx_p" id="A2.T12.2.2.1.1.1.1" style="width:195.1pt;">呢位小朋友智力發展遲緩。</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A2.T12.2.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="A2.T12.2.2.1.2.1">
<span class="ltx_p" id="A2.T12.2.2.1.2.1.1" style="width:195.1pt;">The intellectual development of this child is slow.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T12.2.3.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A2.T12.2.3.2.1">
<span class="ltx_inline-block ltx_align_top" id="A2.T12.2.3.2.1.1">
<span class="ltx_p" id="A2.T12.2.3.2.1.1.1" style="width:195.1pt;">我漏咗個銀包喺小巴度。</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A2.T12.2.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="A2.T12.2.3.2.2.1">
<span class="ltx_p" id="A2.T12.2.3.2.2.1.1" style="width:195.1pt;">I left my wallet in the minibus.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T12.2.4.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A2.T12.2.4.3.1">
<span class="ltx_inline-block ltx_align_top" id="A2.T12.2.4.3.1.1">
<span class="ltx_p" id="A2.T12.2.4.3.1.1.1" style="width:195.1pt;">嗰次交通意外令到佢變咗殘廢。</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A2.T12.2.4.3.2">
<span class="ltx_inline-block ltx_align_top" id="A2.T12.2.4.3.2.1">
<span class="ltx_p" id="A2.T12.2.4.3.2.1.1" style="width:195.1pt;">That traffic accident left him crippled.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T12.2.5.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A2.T12.2.5.4.1">
<span class="ltx_inline-block ltx_align_top" id="A2.T12.2.5.4.1.1">
<span class="ltx_p" id="A2.T12.2.5.4.1.1.1" style="width:195.1pt;">佢好爽快咁應承咗我。</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A2.T12.2.5.4.2">
<span class="ltx_inline-block ltx_align_top" id="A2.T12.2.5.4.2.1">
<span class="ltx_p" id="A2.T12.2.5.4.2.1.1" style="width:195.1pt;">He promised me so quickly.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T12.2.6.5">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A2.T12.2.6.5.1">
<span class="ltx_inline-block ltx_align_top" id="A2.T12.2.6.5.1.1">
<span class="ltx_p" id="A2.T12.2.6.5.1.1.1" style="width:195.1pt;">我買咗個大蛋糕慶賀亞爺七十大壽。</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A2.T12.2.6.5.2">
<span class="ltx_inline-block ltx_align_top" id="A2.T12.2.6.5.2.1">
<span class="ltx_p" id="A2.T12.2.6.5.2.1.1" style="width:195.1pt;">I bought a big cake to celebrate my grandfather’s 70th birthday.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T12.2.7.6">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A2.T12.2.7.6.1">
<span class="ltx_inline-block ltx_align_top" id="A2.T12.2.7.6.1.1">
<span class="ltx_p" id="A2.T12.2.7.6.1.1.1" style="width:195.1pt;">呢單嘢你一定要金睛火眼幫我睇住。</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A2.T12.2.7.6.2">
<span class="ltx_inline-block ltx_align_top" id="A2.T12.2.7.6.2.1">
<span class="ltx_p" id="A2.T12.2.7.6.2.1.1" style="width:195.1pt;">You must keep an eye on this matter for me.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T12.2.8.7">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" id="A2.T12.2.8.7.1">
<span class="ltx_inline-block ltx_align_top" id="A2.T12.2.8.7.1.1">
<span class="ltx_p" id="A2.T12.2.8.7.1.1.1" style="width:195.1pt;">我識咗佢十幾年喇，我地係生意上嘅好搭檔嚟。</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="A2.T12.2.8.7.2">
<span class="ltx_inline-block ltx_align_top" id="A2.T12.2.8.7.2.1">
<span class="ltx_p" id="A2.T12.2.8.7.2.1.1" style="width:195.1pt;">I’ve known him for over ten years. We are good business partners.</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A2.T12.3.1.1" style="font-size:90%;">Table 12</span>. </span><span class="ltx_text" id="A2.T12.4.2" style="font-size:90%;">Example Outputs from Best Model</span></figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2. </span>Human Annotation Guidelines</h3>
<figure class="ltx_figure" id="A2.SS2.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_portrait" height="1079" id="A2.SS2.1.g1" src="x1.png" width="764"/>
</figure>
</section>
<section class="ltx_subsection" id="A2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.3. </span>Automatic Evaluation Results</h3>
<figure class="ltx_table" id="A2.T13">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A2.T13.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T13.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="A2.T13.2.1.1.1">Model Name</th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T13.2.1.1.2">SacreBLEU</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T13.2.1.1.3">hLEPOR</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T13.2.1.1.4">BERTscore</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T13.2.1.1.5">COMET</td>
</tr>
<tr class="ltx_tr" id="A2.T13.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A2.T13.2.2.2.1">nllb-forward-bl</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T13.2.2.2.2">16.5117</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T13.2.2.2.3">0.5651</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T13.2.2.2.4">0.9248</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T13.2.2.2.5">0.7376</td>
</tr>
<tr class="ltx_tr" id="A2.T13.2.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A2.T13.2.3.3.1">nllb-forward-syn-h:h</th>
<td class="ltx_td ltx_align_center" id="A2.T13.2.3.3.2">15.7751</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.3.3.3">0.5616</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.3.3.4">0.9235</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.3.3.5">0.7342</td>
</tr>
<tr class="ltx_tr" id="A2.T13.2.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A2.T13.2.4.4.1">nllb-forward-syn-1:1</th>
<td class="ltx_td ltx_align_center" id="A2.T13.2.4.4.2"><span class="ltx_text ltx_font_bold" id="A2.T13.2.4.4.2.1">16.5901</span></td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.4.4.3">0.5686</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.4.4.4"><span class="ltx_text ltx_font_bold" id="A2.T13.2.4.4.4.1">0.925</span></td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.4.4.5"><span class="ltx_text ltx_font_bold" id="A2.T13.2.4.4.5.1">0.7409</span></td>
</tr>
<tr class="ltx_tr" id="A2.T13.2.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A2.T13.2.5.5.1">nllb-forward-syn-1:1-10E</th>
<td class="ltx_td ltx_align_center" id="A2.T13.2.5.5.2">16.5203</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.5.5.3"><span class="ltx_text ltx_font_bold" id="A2.T13.2.5.5.3.1">0.5689</span></td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.5.5.4">0.9247</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.5.5.5">0.738</td>
</tr>
<tr class="ltx_tr" id="A2.T13.2.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A2.T13.2.6.6.1">nllb-forward-syn-1:3</th>
<td class="ltx_td ltx_align_center" id="A2.T13.2.6.6.2">15.9175</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.6.6.3">0.5626</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.6.6.4">0.924</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.6.6.5">0.7376</td>
</tr>
<tr class="ltx_tr" id="A2.T13.2.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A2.T13.2.7.7.1">nllb-forward-syn-1:5</th>
<td class="ltx_td ltx_align_center" id="A2.T13.2.7.7.2">15.8074</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.7.7.3">0.562</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.7.7.4">0.9237</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.7.7.5">0.7386</td>
</tr>
<tr class="ltx_tr" id="A2.T13.2.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A2.T13.2.8.8.1">nllb-forward-syn-1:1-mbart</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T13.2.8.8.2"><span class="ltx_text ltx_font_bold" id="A2.T13.2.8.8.2.1">16.8077</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T13.2.8.8.3"><span class="ltx_text ltx_font_bold" id="A2.T13.2.8.8.3.1">0.571</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T13.2.8.8.4"><span class="ltx_text ltx_font_bold" id="A2.T13.2.8.8.4.1">0.9256</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T13.2.8.8.5"><span class="ltx_text ltx_font_bold" id="A2.T13.2.8.8.5.1">0.7425</span></td>
</tr>
<tr class="ltx_tr" id="A2.T13.2.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A2.T13.2.9.9.1">nllb-forward-syn-1:3-mbart</th>
<td class="ltx_td ltx_align_center" id="A2.T13.2.9.9.2">15.8621</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.9.9.3">0.5617</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.9.9.4">0.9246</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.9.9.5">0.7384</td>
</tr>
<tr class="ltx_tr" id="A2.T13.2.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A2.T13.2.10.10.1">nllb-forward-syn-1:1-opus</th>
<td class="ltx_td ltx_align_center" id="A2.T13.2.10.10.2">16.5537</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.10.10.3">0.5704</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.10.10.4">0.9254</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.10.10.5">0.7416</td>
</tr>
<tr class="ltx_tr" id="A2.T13.2.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A2.T13.2.11.11.1">nllb-forward-syn-1:3-opus</th>
<td class="ltx_td ltx_align_center" id="A2.T13.2.11.11.2">15.9348</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.11.11.3">0.5651</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.11.11.4">0.9242</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.11.11.5">0.7374</td>
</tr>
<tr class="ltx_tr" id="A2.T13.2.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A2.T13.2.12.12.1">mbart-forward-bl</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T13.2.12.12.2">15.7513</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T13.2.12.12.3">0.5623</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T13.2.12.12.4">0.9227</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T13.2.12.12.5">0.7314</td>
</tr>
<tr class="ltx_tr" id="A2.T13.2.13.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A2.T13.2.13.13.1">mbart-forward-syn-1:1-nllb</th>
<td class="ltx_td ltx_align_center" id="A2.T13.2.13.13.2"><span class="ltx_text ltx_font_bold" id="A2.T13.2.13.13.2.1">16.0358</span></td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.13.13.3"><span class="ltx_text ltx_font_bold" id="A2.T13.2.13.13.3.1">0.5681</span></td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.13.13.4"><span class="ltx_text ltx_font_bold" id="A2.T13.2.13.13.4.1">0.9241</span></td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.13.13.5"><span class="ltx_text ltx_font_bold" id="A2.T13.2.13.13.5.1">0.738</span></td>
</tr>
<tr class="ltx_tr" id="A2.T13.2.14.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A2.T13.2.14.14.1">mbart-forward-syn-1:3-nllb</th>
<td class="ltx_td ltx_align_center" id="A2.T13.2.14.14.2">15.326</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.14.14.3">0.5584</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.14.14.4">0.9225</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.14.14.5">0.7319</td>
</tr>
<tr class="ltx_tr" id="A2.T13.2.15.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A2.T13.2.15.15.1">opus-forward-bl-10E</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T13.2.15.15.2"><span class="ltx_text ltx_font_bold" id="A2.T13.2.15.15.2.1">15.0602</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T13.2.15.15.3"><span class="ltx_text ltx_font_bold" id="A2.T13.2.15.15.3.1">0.5581</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T13.2.15.15.4"><span class="ltx_text ltx_font_bold" id="A2.T13.2.15.15.4.1">0.9219</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T13.2.15.15.5"><span class="ltx_text ltx_font_bold" id="A2.T13.2.15.15.5.1">0.7193</span></td>
</tr>
<tr class="ltx_tr" id="A2.T13.2.16.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A2.T13.2.16.16.1">opus-forward-syn-1:1-10E-nllb</th>
<td class="ltx_td ltx_align_center" id="A2.T13.2.16.16.2">13.0623</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.16.16.3">0.5409</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.16.16.4">0.9164</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.16.16.5">0.6897</td>
</tr>
<tr class="ltx_tr" id="A2.T13.2.17.17">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A2.T13.2.17.17.1">opus-forward-syn-1:3-10E-nllb</th>
<td class="ltx_td ltx_align_center" id="A2.T13.2.17.17.2">13.3666</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.17.17.3">0.5442</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.17.17.4">0.9167</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.17.17.5">0.6957</td>
</tr>
<tr class="ltx_tr" id="A2.T13.2.18.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A2.T13.2.18.18.1">baidu</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T13.2.18.18.2">16.5669</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T13.2.18.18.3">0.5654</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T13.2.18.18.4">0.9243</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T13.2.18.18.5">0.7401</td>
</tr>
<tr class="ltx_tr" id="A2.T13.2.19.19">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A2.T13.2.19.19.1">bing</th>
<td class="ltx_td ltx_align_center" id="A2.T13.2.19.19.2">17.1098</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.19.19.3">0.5735</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.19.19.4">0.9258</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.19.19.5">0.7474</td>
</tr>
<tr class="ltx_tr" id="A2.T13.2.20.20">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A2.T13.2.20.20.1">gpt4-ft(CantoneseCompanion)</th>
<td class="ltx_td ltx_align_center" id="A2.T13.2.20.20.2"><span class="ltx_text ltx_font_bold" id="A2.T13.2.20.20.2.1">19.1622</span></td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.20.20.3"><span class="ltx_text ltx_font_bold" id="A2.T13.2.20.20.3.1">0.5917</span></td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.20.20.4"><span class="ltx_text ltx_font_bold" id="A2.T13.2.20.20.4.1">0.936</span></td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.20.20.5"><span class="ltx_text ltx_font_bold" id="A2.T13.2.20.20.5.1">0.805</span></td>
</tr>
<tr class="ltx_tr" id="A2.T13.2.21.21">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="A2.T13.2.21.21.1">nllb-forward-bl-plus-wenlin14.5k</th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T13.2.21.21.2"><span class="ltx_text ltx_font_italic" id="A2.T13.2.21.21.2.1">16.6662</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T13.2.21.21.3"><span class="ltx_text ltx_font_italic ltx_framed ltx_framed_underline" id="A2.T13.2.21.21.3.1">0.5828</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T13.2.21.21.4"><span class="ltx_text ltx_font_italic ltx_framed ltx_framed_underline" id="A2.T13.2.21.21.4.1">0.926</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T13.2.21.21.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="A2.T13.2.21.21.5.1">0.7496</span></td>
</tr>
<tr class="ltx_tr" id="A2.T13.2.22.22">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A2.T13.2.22.22.1">mbart-forward-bl-plus-wenlin14.5k</th>
<td class="ltx_td ltx_align_center" id="A2.T13.2.22.22.2">15.2404</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.22.22.3">0.5734</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.22.22.4">0.9238</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.22.22.5">0.7411</td>
</tr>
<tr class="ltx_tr" id="A2.T13.2.23.23">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A2.T13.2.23.23.1">opus-forward-bl-plus-wenlin14.5k</th>
<td class="ltx_td ltx_align_center" id="A2.T13.2.23.23.2">13.0172</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.23.23.3">0.5473</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.23.23.4">0.9157</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.23.23.5">0.6882</td>
</tr>
<tr class="ltx_tr" id="A2.T13.2.24.24">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="A2.T13.2.24.24.1">nllb-200-deploy-no-finetune</th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T13.2.24.24.2">11.1827</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T13.2.24.24.3">0.4925</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T13.2.24.24.4">0.9129</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T13.2.24.24.5">0.6863</td>
</tr>
<tr class="ltx_tr" id="A2.T13.2.25.25">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A2.T13.2.25.25.1">opus-deploy-no-finetune</th>
<td class="ltx_td ltx_align_center" id="A2.T13.2.25.25.2">10.4035</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.25.25.3">0.4773</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.25.25.4">0.9082</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.25.25.5">0.6584</td>
</tr>
<tr class="ltx_tr" id="A2.T13.2.26.26">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A2.T13.2.26.26.1">mbart-deploy-no-finetune</th>
<td class="ltx_td ltx_align_center" id="A2.T13.2.26.26.2">8.3157</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.26.26.3">0.4387</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.26.26.4">0.9005</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.26.26.5">0.6273</td>
</tr>
<tr class="ltx_tr" id="A2.T13.2.27.27">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="A2.T13.2.27.27.1">nllb-forward-all3corpus</th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T13.2.27.27.2"><span class="ltx_text ltx_font_italic ltx_framed ltx_framed_underline" id="A2.T13.2.27.27.2.1">16.9986</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T13.2.27.27.3"><span class="ltx_text ltx_font_italic ltx_framed ltx_framed_underline" id="A2.T13.2.27.27.3.1">0.583</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T13.2.27.27.4"><span class="ltx_text ltx_font_italic ltx_framed ltx_framed_underline" id="A2.T13.2.27.27.4.1">0.927</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A2.T13.2.27.27.5"><span class="ltx_text ltx_font_italic ltx_framed ltx_framed_underline" id="A2.T13.2.27.27.5.1">0.7549</span></td>
</tr>
<tr class="ltx_tr" id="A2.T13.2.28.28">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A2.T13.2.28.28.1">nllb-forward-all3corpus-10E</th>
<td class="ltx_td ltx_align_center" id="A2.T13.2.28.28.2">16.1749</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.28.28.3">0.5728</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.28.28.4">0.9254</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.28.28.5">0.7508</td>
</tr>
<tr class="ltx_tr" id="A2.T13.2.29.29">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A2.T13.2.29.29.1">mbart-forward-all3corpus</th>
<td class="ltx_td ltx_align_center" id="A2.T13.2.29.29.2">16.3204</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.29.29.3">0.5766</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.29.29.4">0.9253</td>
<td class="ltx_td ltx_align_center" id="A2.T13.2.29.29.5">0.7482</td>
</tr>
<tr class="ltx_tr" id="A2.T13.2.30.30">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="A2.T13.2.30.30.1">opus-forward-all3corpus-10E</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T13.2.30.30.2">14.4699</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T13.2.30.30.3">0.5621</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T13.2.30.30.4">0.9191</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T13.2.30.30.5">0.7074</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A2.T13.4.1.1" style="font-size:90%;">Table 13</span>. </span><span class="ltx_text" id="A2.T13.5.2" style="font-size:90%;">Automatic Evaluation Scores from Different Models of <span class="ltx_text ltx_font_smallcaps" id="A2.T13.5.2.1"> CantonMT</span>.
</span></figcaption>
</figure>
<div class="ltx_para" id="A2.SS3.p1">
<p class="ltx_p" id="A2.SS3.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2405.08172v1#A2.T13" title="Table 13 ‣ B.3. Automatic Evaluation Results ‣ Appendix B Evaluation Details ‣ CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation"><span class="ltx_text ltx_ref_tag">13</span></a> shows the
Automatic Evaluation Scores from Different Models in<span class="ltx_text ltx_font_smallcaps" id="A2.SS3.p1.1.1"> CantonMT</span> in one view, where
bl: bilingual real data; syn: synthetic data; h:h - half and half; 1:1/3/5 - 100% real + 100/300/500% synthetic; 10E: 10 epochs (default: 3); top-down second slot: model switch: model type using NLLB but synthetic data from other models (mBART and OpusMT); top-down third slot: including model switch for mBART fine-tuning using synthetic data generated from NLLB; similarly top-down forth slot: including model switch for OpusMT fine-tuning using synthetic data from NLLB. Bottom slot of Cluster 1: Bing/Baidu Translator and GPT4-finetuned Cantonese Companion; <span class="ltx_text ltx_font_bold" id="A2.SS3.p1.1.2">bold</span> case is the best score of the same slot among the same model categories.
Cluster 2: bilingual fine-tuned models using 38K words.hk data plus 14.5k Wenlin data; <span class="ltx_text ltx_font_italic" id="A2.SS3.p1.1.3">italic</span> indicates the number outperforms the same model fine-tuned with less data 38K.
Cluster 3: Deployed Model without fine-tuning.
Cluster 4: Finetuned with the previous 2 corpora and an additional 10K data from OPUS Corpora we managed to find in the end - it shows the evaluation improvement continues.</p>
</div>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon May 13 20:36:42 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
