<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2311.13043] FedCPC: an Effective Federated Contrastive Learning Method for Privacy Preserving Early-Stage Alzheimerâ€™s Speech Detection</title><meta property="og:description" content="The early-stage Alzheimerâ€™s disease (AD) detection has been considered an important field of medical studies. Like traditional machine learning methods, speech-based automatic detection also suffers from data privacy râ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="FedCPC: an Effective Federated Contrastive Learning Method for Privacy Preserving Early-Stage Alzheimerâ€™s Speech Detection">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="FedCPC: an Effective Federated Contrastive Learning Method for Privacy Preserving Early-Stage Alzheimerâ€™s Speech Detection">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2311.13043">

<!--Generated on Tue Feb 27 18:01:08 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">FedCPC: an Effective Federated Contrastive Learning Method for Privacy Preserving Early-Stage Alzheimerâ€™s Speech Detection</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">The early-stage Alzheimerâ€™s disease (AD) detection has been considered an important field of medical studies. Like traditional machine learning methods, speech-based automatic detection also suffers from data privacy risks because the data of specific patients are exclusive to each medical institution. A common practice is to use federated learning to protect the patientsâ€™ data privacy. However, its distributed learning process also causes performance reduction. To alleviate this problem while protecting user privacy, we propose a federated contrastive pre-training (FedCPC) performed before federated training for AD speech detection, which can learn a better representation from raw data and enables
different clients to share data in the pre-training and training stages. Experimental results demonstrate that the proposed methods can achieve satisfactory performance while preserving data privacy.</p>
</div>
<div id="p1" class="ltx_para ltx_noindent">
<p id="p1.1" class="ltx_p"><span id="p1.1.1" class="ltx_text ltx_font_bold">Index Terms</span>
Alzheimerâ€™s disease speech detection, federated learning, contrastive pre-training</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Alzheimerâ€™s disease (AD) has been a global problem, and the number of people affected by this kind of cognitive impairment is growing. Unfortunately, this disease still cannot be perfectly cured. Therefore, early-stage AD detection methods are required. Current bio-medical diagnoses require a comprehensive examination by medical experts, which is costly and time-consuming. Compared with these biochemical methods, machine learning-based methods from easily captured spoken language signals are much more direct and efficient.
Previous works have found speech changes in fluency <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, prosody <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, and rhythm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> in patients with AD.
Researchers have been motivated to study AD detection using state-of-the-art technologies, such as speech recognition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, speaker recognition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, natural language processing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, and multi-modeling <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Although such detection would be helpful, using patient data during model training might raise concerns about privacy issues <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. The data of specific patients are exclusive for each medical institution, which cannot support traditional machine learning methods where all the local data are uploaded to one central server for learning a global model. Under such a setting, each medical institution does not have sufficient training data for the model; in addition, different medical institutions cannot benefit from a larger training data scale, leading to significant performance degradation.
Existing methods focus on directly anonymizing speakersâ€™ identities <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> and achieve very good results. However, these approaches are neither cheap nor time-efficient.
Federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> is a machine learning technique that trains an algorithm across multiple decentralized edge devices or servers holding local data samples without the exchange of data to each other. It enables multiple clients to build a common and robust machine learning model without sharing data, thus preserving data privacy. Considering the advantages of the federated learning method, numerous works have recently used federated learning to protect user data privacy. Li et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> proposed ADDETECTOR, a privacy-preserving smart healthcare system, to realize low-cost AD.
Wang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> proposed a Blockchain-based Privacy-preserving Federated Learning scheme, which can enable the verifiability of the local models while protecting data privacy.
However, federated learning is a kind of distributed learning, so the training data on each client will be smaller than in centralized learning, which leads to performance degradation, especially for small dataset tasks.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Several substantial works have recently demonstrated that self-supervised representations are highly successful in downstream speech and language processing tasks through feature-based speech representation extraction or fine-tuning as part of the downstream model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. Oord et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> proposed contrastive predictive coding (CPC) that seeks to group samples that are alike while keeping samples that are different from one another apart from representation learning, which can accurately represent the data. Baevski et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> used adversarial training to train an unsupervised speech recognition model using the representations of the unlabeled speech audio data and the unlabeled phonemicized text data.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Inspired by these works, this paper proposes using federated contrastive learning to protect patient data privacy and enhance the modelâ€™s performance for each client by enabling data sharing while preserving privacy during the pre-training and training stages.
Specifically, each medical institution could be regarded as a client. The clients locally train an independent contrastive predictive coding pre-training model and then upload the model to a central server.
On the server side, the multiple models are then stacked up as a global model with federated averaging and hierarchical optimization, which cannot backtrack the parameters of individual models. After completing the Federated contrastive (FedCPC) pre-training process, we apply the FedCPC pre-training model as a feature extractor in each client to detect the AD speech with federated learning. Finally, this global model is sent to each client to benefit from more extensive data and guarantee strong anonymity and privacy.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Methods</h2>

<figure id="S2.F1" class="ltx_figure"><img src="/html/2311.13043/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="348" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.2.1.1" class="ltx_text ltx_font_bold">Fig.Â 1</span>: </span>The flowchart of the proposed method. The algorithm on the left side of the diagram will be applied to each client on the right side. </figcaption>
</figure>
<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Figure <a href="#S2.F1" title="Figure 1 â€£ 2 Methods â€£ FedCPC: an Effective Federated Contrastive Learning Method for Privacy Preserving Early-Stage Alzheimerâ€™s Speech Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> demonstrates the flowchart of the proposed method. Our method is divided into two steps. Step 1 is the proposed Federated CPC pre-training (FedCPC). The pre-training model for learning the representations of the speech data is CPC, and Federated learning is utilized for training the CPC model among the central server and the clients. After Federated CPC pre-training, Step 2 loads the pre-trained model and fine-tunes the classifier for the downstream Alzheimerâ€™s disease detection task. The details of the CPC Model and the Federated Learning module are described as follows:</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Contrastive Predictive Coding Pre-training</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Self-supervised learning obtains supervisory signals from the data, which provides supervisory signals beneficial for downstream tasks. CPC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> is a self-supervised learning approach, which involves predicting the future time step of data according to the context vector derived from past data. Its goal is to learn representations that allow long-term prediction of future time steps by maximizing mutual information between representations and predictions. Moreover, CPC captures high-level information from a signal (for example, global structures such as phonemes in speech <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>). This work adopts the CPC method for unsupervised representation pre-training of Alzheimerâ€™s speech.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.13" class="ltx_p">A convolutional encoder network produces a sequence of representation <math id="S2.SS1.p2.1.m1.1" class="ltx_Math" alttext="Z" display="inline"><semantics id="S2.SS1.p2.1.m1.1a"><mi id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml">Z</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><ci id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">Z</annotation></semantics></math> of a raw audio waveform. Subsequently, a recurrent context network summarizes the past information in the vector embedding sequence and produces corresponding contextual <math id="S2.SS1.p2.2.m2.4" class="ltx_Math" alttext="\mathbf{C}=\{\mathbf{c}_{1},\mathbf{c}_{2},...,\mathbf{c}_{t}\}" display="inline"><semantics id="S2.SS1.p2.2.m2.4a"><mrow id="S2.SS1.p2.2.m2.4.4" xref="S2.SS1.p2.2.m2.4.4.cmml"><mi id="S2.SS1.p2.2.m2.4.4.5" xref="S2.SS1.p2.2.m2.4.4.5.cmml">ğ‚</mi><mo id="S2.SS1.p2.2.m2.4.4.4" xref="S2.SS1.p2.2.m2.4.4.4.cmml">=</mo><mrow id="S2.SS1.p2.2.m2.4.4.3.3" xref="S2.SS1.p2.2.m2.4.4.3.4.cmml"><mo stretchy="false" id="S2.SS1.p2.2.m2.4.4.3.3.4" xref="S2.SS1.p2.2.m2.4.4.3.4.cmml">{</mo><msub id="S2.SS1.p2.2.m2.2.2.1.1.1" xref="S2.SS1.p2.2.m2.2.2.1.1.1.cmml"><mi id="S2.SS1.p2.2.m2.2.2.1.1.1.2" xref="S2.SS1.p2.2.m2.2.2.1.1.1.2.cmml">ğœ</mi><mn id="S2.SS1.p2.2.m2.2.2.1.1.1.3" xref="S2.SS1.p2.2.m2.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S2.SS1.p2.2.m2.4.4.3.3.5" xref="S2.SS1.p2.2.m2.4.4.3.4.cmml">,</mo><msub id="S2.SS1.p2.2.m2.3.3.2.2.2" xref="S2.SS1.p2.2.m2.3.3.2.2.2.cmml"><mi id="S2.SS1.p2.2.m2.3.3.2.2.2.2" xref="S2.SS1.p2.2.m2.3.3.2.2.2.2.cmml">ğœ</mi><mn id="S2.SS1.p2.2.m2.3.3.2.2.2.3" xref="S2.SS1.p2.2.m2.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S2.SS1.p2.2.m2.4.4.3.3.6" xref="S2.SS1.p2.2.m2.4.4.3.4.cmml">,</mo><mi mathvariant="normal" id="S2.SS1.p2.2.m2.1.1" xref="S2.SS1.p2.2.m2.1.1.cmml">â€¦</mi><mo id="S2.SS1.p2.2.m2.4.4.3.3.7" xref="S2.SS1.p2.2.m2.4.4.3.4.cmml">,</mo><msub id="S2.SS1.p2.2.m2.4.4.3.3.3" xref="S2.SS1.p2.2.m2.4.4.3.3.3.cmml"><mi id="S2.SS1.p2.2.m2.4.4.3.3.3.2" xref="S2.SS1.p2.2.m2.4.4.3.3.3.2.cmml">ğœ</mi><mi id="S2.SS1.p2.2.m2.4.4.3.3.3.3" xref="S2.SS1.p2.2.m2.4.4.3.3.3.3.cmml">t</mi></msub><mo stretchy="false" id="S2.SS1.p2.2.m2.4.4.3.3.8" xref="S2.SS1.p2.2.m2.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.2.m2.4b"><apply id="S2.SS1.p2.2.m2.4.4.cmml" xref="S2.SS1.p2.2.m2.4.4"><eq id="S2.SS1.p2.2.m2.4.4.4.cmml" xref="S2.SS1.p2.2.m2.4.4.4"></eq><ci id="S2.SS1.p2.2.m2.4.4.5.cmml" xref="S2.SS1.p2.2.m2.4.4.5">ğ‚</ci><set id="S2.SS1.p2.2.m2.4.4.3.4.cmml" xref="S2.SS1.p2.2.m2.4.4.3.3"><apply id="S2.SS1.p2.2.m2.2.2.1.1.1.cmml" xref="S2.SS1.p2.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.2.m2.2.2.1.1.1.1.cmml" xref="S2.SS1.p2.2.m2.2.2.1.1.1">subscript</csymbol><ci id="S2.SS1.p2.2.m2.2.2.1.1.1.2.cmml" xref="S2.SS1.p2.2.m2.2.2.1.1.1.2">ğœ</ci><cn type="integer" id="S2.SS1.p2.2.m2.2.2.1.1.1.3.cmml" xref="S2.SS1.p2.2.m2.2.2.1.1.1.3">1</cn></apply><apply id="S2.SS1.p2.2.m2.3.3.2.2.2.cmml" xref="S2.SS1.p2.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p2.2.m2.3.3.2.2.2.1.cmml" xref="S2.SS1.p2.2.m2.3.3.2.2.2">subscript</csymbol><ci id="S2.SS1.p2.2.m2.3.3.2.2.2.2.cmml" xref="S2.SS1.p2.2.m2.3.3.2.2.2.2">ğœ</ci><cn type="integer" id="S2.SS1.p2.2.m2.3.3.2.2.2.3.cmml" xref="S2.SS1.p2.2.m2.3.3.2.2.2.3">2</cn></apply><ci id="S2.SS1.p2.2.m2.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1">â€¦</ci><apply id="S2.SS1.p2.2.m2.4.4.3.3.3.cmml" xref="S2.SS1.p2.2.m2.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.SS1.p2.2.m2.4.4.3.3.3.1.cmml" xref="S2.SS1.p2.2.m2.4.4.3.3.3">subscript</csymbol><ci id="S2.SS1.p2.2.m2.4.4.3.3.3.2.cmml" xref="S2.SS1.p2.2.m2.4.4.3.3.3.2">ğœ</ci><ci id="S2.SS1.p2.2.m2.4.4.3.3.3.3.cmml" xref="S2.SS1.p2.2.m2.4.4.3.3.3.3">ğ‘¡</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.2.m2.4c">\mathbf{C}=\{\mathbf{c}_{1},\mathbf{c}_{2},...,\mathbf{c}_{t}\}</annotation></semantics></math> representations for audio.
The CPC pre-training model is trained to predict the future latent representation <math id="S2.SS1.p2.3.m3.1" class="ltx_Math" alttext="\mathbf{z}_{t+k}" display="inline"><semantics id="S2.SS1.p2.3.m3.1a"><msub id="S2.SS1.p2.3.m3.1.1" xref="S2.SS1.p2.3.m3.1.1.cmml"><mi id="S2.SS1.p2.3.m3.1.1.2" xref="S2.SS1.p2.3.m3.1.1.2.cmml">ğ³</mi><mrow id="S2.SS1.p2.3.m3.1.1.3" xref="S2.SS1.p2.3.m3.1.1.3.cmml"><mi id="S2.SS1.p2.3.m3.1.1.3.2" xref="S2.SS1.p2.3.m3.1.1.3.2.cmml">t</mi><mo id="S2.SS1.p2.3.m3.1.1.3.1" xref="S2.SS1.p2.3.m3.1.1.3.1.cmml">+</mo><mi id="S2.SS1.p2.3.m3.1.1.3.3" xref="S2.SS1.p2.3.m3.1.1.3.3.cmml">k</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.3.m3.1b"><apply id="S2.SS1.p2.3.m3.1.1.cmml" xref="S2.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.3.m3.1.1.1.cmml" xref="S2.SS1.p2.3.m3.1.1">subscript</csymbol><ci id="S2.SS1.p2.3.m3.1.1.2.cmml" xref="S2.SS1.p2.3.m3.1.1.2">ğ³</ci><apply id="S2.SS1.p2.3.m3.1.1.3.cmml" xref="S2.SS1.p2.3.m3.1.1.3"><plus id="S2.SS1.p2.3.m3.1.1.3.1.cmml" xref="S2.SS1.p2.3.m3.1.1.3.1"></plus><ci id="S2.SS1.p2.3.m3.1.1.3.2.cmml" xref="S2.SS1.p2.3.m3.1.1.3.2">ğ‘¡</ci><ci id="S2.SS1.p2.3.m3.1.1.3.3.cmml" xref="S2.SS1.p2.3.m3.1.1.3.3">ğ‘˜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.3.m3.1c">\mathbf{z}_{t+k}</annotation></semantics></math> (<math id="S2.SS1.p2.4.m4.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.SS1.p2.4.m4.1a"><mi id="S2.SS1.p2.4.m4.1.1" xref="S2.SS1.p2.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.4.m4.1b"><ci id="S2.SS1.p2.4.m4.1.1.cmml" xref="S2.SS1.p2.4.m4.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.4.m4.1c">k</annotation></semantics></math> is the predicted step) using the context-aware representation <math id="S2.SS1.p2.5.m5.1" class="ltx_Math" alttext="\mathbf{c}_{t}" display="inline"><semantics id="S2.SS1.p2.5.m5.1a"><msub id="S2.SS1.p2.5.m5.1.1" xref="S2.SS1.p2.5.m5.1.1.cmml"><mi id="S2.SS1.p2.5.m5.1.1.2" xref="S2.SS1.p2.5.m5.1.1.2.cmml">ğœ</mi><mi id="S2.SS1.p2.5.m5.1.1.3" xref="S2.SS1.p2.5.m5.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.5.m5.1b"><apply id="S2.SS1.p2.5.m5.1.1.cmml" xref="S2.SS1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.5.m5.1.1.1.cmml" xref="S2.SS1.p2.5.m5.1.1">subscript</csymbol><ci id="S2.SS1.p2.5.m5.1.1.2.cmml" xref="S2.SS1.p2.5.m5.1.1.2">ğœ</ci><ci id="S2.SS1.p2.5.m5.1.1.3.cmml" xref="S2.SS1.p2.5.m5.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.5.m5.1c">\mathbf{c}_{t}</annotation></semantics></math> at the <math id="S2.SS1.p2.6.m6.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SS1.p2.6.m6.1a"><mi id="S2.SS1.p2.6.m6.1.1" xref="S2.SS1.p2.6.m6.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.6.m6.1b"><ci id="S2.SS1.p2.6.m6.1.1.cmml" xref="S2.SS1.p2.6.m6.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.6.m6.1c">t</annotation></semantics></math>-th timestep of speech. At each step <math id="S2.SS1.p2.7.m7.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SS1.p2.7.m7.1a"><mi id="S2.SS1.p2.7.m7.1.1" xref="S2.SS1.p2.7.m7.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.7.m7.1b"><ci id="S2.SS1.p2.7.m7.1.1.cmml" xref="S2.SS1.p2.7.m7.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.7.m7.1c">t</annotation></semantics></math>, we adopt a contrastive estimation-based InfoNCE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> to maximize the mutual information lower bound between contextual representations <math id="S2.SS1.p2.8.m8.1" class="ltx_Math" alttext="\mathbf{c}_{t}" display="inline"><semantics id="S2.SS1.p2.8.m8.1a"><msub id="S2.SS1.p2.8.m8.1.1" xref="S2.SS1.p2.8.m8.1.1.cmml"><mi id="S2.SS1.p2.8.m8.1.1.2" xref="S2.SS1.p2.8.m8.1.1.2.cmml">ğœ</mi><mi id="S2.SS1.p2.8.m8.1.1.3" xref="S2.SS1.p2.8.m8.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.8.m8.1b"><apply id="S2.SS1.p2.8.m8.1.1.cmml" xref="S2.SS1.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.8.m8.1.1.1.cmml" xref="S2.SS1.p2.8.m8.1.1">subscript</csymbol><ci id="S2.SS1.p2.8.m8.1.1.2.cmml" xref="S2.SS1.p2.8.m8.1.1.2">ğœ</ci><ci id="S2.SS1.p2.8.m8.1.1.3.cmml" xref="S2.SS1.p2.8.m8.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.8.m8.1c">\mathbf{c}_{t}</annotation></semantics></math> and future latent representations <math id="S2.SS1.p2.9.m9.1" class="ltx_Math" alttext="\mathbf{z}_{t+k}" display="inline"><semantics id="S2.SS1.p2.9.m9.1a"><msub id="S2.SS1.p2.9.m9.1.1" xref="S2.SS1.p2.9.m9.1.1.cmml"><mi id="S2.SS1.p2.9.m9.1.1.2" xref="S2.SS1.p2.9.m9.1.1.2.cmml">ğ³</mi><mrow id="S2.SS1.p2.9.m9.1.1.3" xref="S2.SS1.p2.9.m9.1.1.3.cmml"><mi id="S2.SS1.p2.9.m9.1.1.3.2" xref="S2.SS1.p2.9.m9.1.1.3.2.cmml">t</mi><mo id="S2.SS1.p2.9.m9.1.1.3.1" xref="S2.SS1.p2.9.m9.1.1.3.1.cmml">+</mo><mi id="S2.SS1.p2.9.m9.1.1.3.3" xref="S2.SS1.p2.9.m9.1.1.3.3.cmml">k</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.9.m9.1b"><apply id="S2.SS1.p2.9.m9.1.1.cmml" xref="S2.SS1.p2.9.m9.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.9.m9.1.1.1.cmml" xref="S2.SS1.p2.9.m9.1.1">subscript</csymbol><ci id="S2.SS1.p2.9.m9.1.1.2.cmml" xref="S2.SS1.p2.9.m9.1.1.2">ğ³</ci><apply id="S2.SS1.p2.9.m9.1.1.3.cmml" xref="S2.SS1.p2.9.m9.1.1.3"><plus id="S2.SS1.p2.9.m9.1.1.3.1.cmml" xref="S2.SS1.p2.9.m9.1.1.3.1"></plus><ci id="S2.SS1.p2.9.m9.1.1.3.2.cmml" xref="S2.SS1.p2.9.m9.1.1.3.2">ğ‘¡</ci><ci id="S2.SS1.p2.9.m9.1.1.3.3.cmml" xref="S2.SS1.p2.9.m9.1.1.3.3">ğ‘˜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.9.m9.1c">\mathbf{z}_{t+k}</annotation></semantics></math>.
Here, given a set <math id="S2.SS1.p2.10.m10.4" class="ltx_Math" alttext="Z=\{\mathbf{z}_{1},\mathbf{z}_{2},...,\mathbf{z}_{N}\}" display="inline"><semantics id="S2.SS1.p2.10.m10.4a"><mrow id="S2.SS1.p2.10.m10.4.4" xref="S2.SS1.p2.10.m10.4.4.cmml"><mi id="S2.SS1.p2.10.m10.4.4.5" xref="S2.SS1.p2.10.m10.4.4.5.cmml">Z</mi><mo id="S2.SS1.p2.10.m10.4.4.4" xref="S2.SS1.p2.10.m10.4.4.4.cmml">=</mo><mrow id="S2.SS1.p2.10.m10.4.4.3.3" xref="S2.SS1.p2.10.m10.4.4.3.4.cmml"><mo stretchy="false" id="S2.SS1.p2.10.m10.4.4.3.3.4" xref="S2.SS1.p2.10.m10.4.4.3.4.cmml">{</mo><msub id="S2.SS1.p2.10.m10.2.2.1.1.1" xref="S2.SS1.p2.10.m10.2.2.1.1.1.cmml"><mi id="S2.SS1.p2.10.m10.2.2.1.1.1.2" xref="S2.SS1.p2.10.m10.2.2.1.1.1.2.cmml">ğ³</mi><mn id="S2.SS1.p2.10.m10.2.2.1.1.1.3" xref="S2.SS1.p2.10.m10.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S2.SS1.p2.10.m10.4.4.3.3.5" xref="S2.SS1.p2.10.m10.4.4.3.4.cmml">,</mo><msub id="S2.SS1.p2.10.m10.3.3.2.2.2" xref="S2.SS1.p2.10.m10.3.3.2.2.2.cmml"><mi id="S2.SS1.p2.10.m10.3.3.2.2.2.2" xref="S2.SS1.p2.10.m10.3.3.2.2.2.2.cmml">ğ³</mi><mn id="S2.SS1.p2.10.m10.3.3.2.2.2.3" xref="S2.SS1.p2.10.m10.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S2.SS1.p2.10.m10.4.4.3.3.6" xref="S2.SS1.p2.10.m10.4.4.3.4.cmml">,</mo><mi mathvariant="normal" id="S2.SS1.p2.10.m10.1.1" xref="S2.SS1.p2.10.m10.1.1.cmml">â€¦</mi><mo id="S2.SS1.p2.10.m10.4.4.3.3.7" xref="S2.SS1.p2.10.m10.4.4.3.4.cmml">,</mo><msub id="S2.SS1.p2.10.m10.4.4.3.3.3" xref="S2.SS1.p2.10.m10.4.4.3.3.3.cmml"><mi id="S2.SS1.p2.10.m10.4.4.3.3.3.2" xref="S2.SS1.p2.10.m10.4.4.3.3.3.2.cmml">ğ³</mi><mi id="S2.SS1.p2.10.m10.4.4.3.3.3.3" xref="S2.SS1.p2.10.m10.4.4.3.3.3.3.cmml">N</mi></msub><mo stretchy="false" id="S2.SS1.p2.10.m10.4.4.3.3.8" xref="S2.SS1.p2.10.m10.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.10.m10.4b"><apply id="S2.SS1.p2.10.m10.4.4.cmml" xref="S2.SS1.p2.10.m10.4.4"><eq id="S2.SS1.p2.10.m10.4.4.4.cmml" xref="S2.SS1.p2.10.m10.4.4.4"></eq><ci id="S2.SS1.p2.10.m10.4.4.5.cmml" xref="S2.SS1.p2.10.m10.4.4.5">ğ‘</ci><set id="S2.SS1.p2.10.m10.4.4.3.4.cmml" xref="S2.SS1.p2.10.m10.4.4.3.3"><apply id="S2.SS1.p2.10.m10.2.2.1.1.1.cmml" xref="S2.SS1.p2.10.m10.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.10.m10.2.2.1.1.1.1.cmml" xref="S2.SS1.p2.10.m10.2.2.1.1.1">subscript</csymbol><ci id="S2.SS1.p2.10.m10.2.2.1.1.1.2.cmml" xref="S2.SS1.p2.10.m10.2.2.1.1.1.2">ğ³</ci><cn type="integer" id="S2.SS1.p2.10.m10.2.2.1.1.1.3.cmml" xref="S2.SS1.p2.10.m10.2.2.1.1.1.3">1</cn></apply><apply id="S2.SS1.p2.10.m10.3.3.2.2.2.cmml" xref="S2.SS1.p2.10.m10.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p2.10.m10.3.3.2.2.2.1.cmml" xref="S2.SS1.p2.10.m10.3.3.2.2.2">subscript</csymbol><ci id="S2.SS1.p2.10.m10.3.3.2.2.2.2.cmml" xref="S2.SS1.p2.10.m10.3.3.2.2.2.2">ğ³</ci><cn type="integer" id="S2.SS1.p2.10.m10.3.3.2.2.2.3.cmml" xref="S2.SS1.p2.10.m10.3.3.2.2.2.3">2</cn></apply><ci id="S2.SS1.p2.10.m10.1.1.cmml" xref="S2.SS1.p2.10.m10.1.1">â€¦</ci><apply id="S2.SS1.p2.10.m10.4.4.3.3.3.cmml" xref="S2.SS1.p2.10.m10.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.SS1.p2.10.m10.4.4.3.3.3.1.cmml" xref="S2.SS1.p2.10.m10.4.4.3.3.3">subscript</csymbol><ci id="S2.SS1.p2.10.m10.4.4.3.3.3.2.cmml" xref="S2.SS1.p2.10.m10.4.4.3.3.3.2">ğ³</ci><ci id="S2.SS1.p2.10.m10.4.4.3.3.3.3.cmml" xref="S2.SS1.p2.10.m10.4.4.3.3.3.3">ğ‘</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.10.m10.4c">Z=\{\mathbf{z}_{1},\mathbf{z}_{2},...,\mathbf{z}_{N}\}</annotation></semantics></math> N random samples which contains one positive sample from <math id="S2.SS1.p2.11.m11.1" class="ltx_Math" alttext="p(\mathbf{z}_{t+k}|\mathbf{c}_{t})" display="inline"><semantics id="S2.SS1.p2.11.m11.1a"><mrow id="S2.SS1.p2.11.m11.1.1" xref="S2.SS1.p2.11.m11.1.1.cmml"><mi id="S2.SS1.p2.11.m11.1.1.3" xref="S2.SS1.p2.11.m11.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p2.11.m11.1.1.2" xref="S2.SS1.p2.11.m11.1.1.2.cmml">â€‹</mo><mrow id="S2.SS1.p2.11.m11.1.1.1.1" xref="S2.SS1.p2.11.m11.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.p2.11.m11.1.1.1.1.2" xref="S2.SS1.p2.11.m11.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS1.p2.11.m11.1.1.1.1.1" xref="S2.SS1.p2.11.m11.1.1.1.1.1.cmml"><msub id="S2.SS1.p2.11.m11.1.1.1.1.1.2" xref="S2.SS1.p2.11.m11.1.1.1.1.1.2.cmml"><mi id="S2.SS1.p2.11.m11.1.1.1.1.1.2.2" xref="S2.SS1.p2.11.m11.1.1.1.1.1.2.2.cmml">ğ³</mi><mrow id="S2.SS1.p2.11.m11.1.1.1.1.1.2.3" xref="S2.SS1.p2.11.m11.1.1.1.1.1.2.3.cmml"><mi id="S2.SS1.p2.11.m11.1.1.1.1.1.2.3.2" xref="S2.SS1.p2.11.m11.1.1.1.1.1.2.3.2.cmml">t</mi><mo id="S2.SS1.p2.11.m11.1.1.1.1.1.2.3.1" xref="S2.SS1.p2.11.m11.1.1.1.1.1.2.3.1.cmml">+</mo><mi id="S2.SS1.p2.11.m11.1.1.1.1.1.2.3.3" xref="S2.SS1.p2.11.m11.1.1.1.1.1.2.3.3.cmml">k</mi></mrow></msub><mo fence="false" id="S2.SS1.p2.11.m11.1.1.1.1.1.1" xref="S2.SS1.p2.11.m11.1.1.1.1.1.1.cmml">|</mo><msub id="S2.SS1.p2.11.m11.1.1.1.1.1.3" xref="S2.SS1.p2.11.m11.1.1.1.1.1.3.cmml"><mi id="S2.SS1.p2.11.m11.1.1.1.1.1.3.2" xref="S2.SS1.p2.11.m11.1.1.1.1.1.3.2.cmml">ğœ</mi><mi id="S2.SS1.p2.11.m11.1.1.1.1.1.3.3" xref="S2.SS1.p2.11.m11.1.1.1.1.1.3.3.cmml">t</mi></msub></mrow><mo stretchy="false" id="S2.SS1.p2.11.m11.1.1.1.1.3" xref="S2.SS1.p2.11.m11.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.11.m11.1b"><apply id="S2.SS1.p2.11.m11.1.1.cmml" xref="S2.SS1.p2.11.m11.1.1"><times id="S2.SS1.p2.11.m11.1.1.2.cmml" xref="S2.SS1.p2.11.m11.1.1.2"></times><ci id="S2.SS1.p2.11.m11.1.1.3.cmml" xref="S2.SS1.p2.11.m11.1.1.3">ğ‘</ci><apply id="S2.SS1.p2.11.m11.1.1.1.1.1.cmml" xref="S2.SS1.p2.11.m11.1.1.1.1"><csymbol cd="latexml" id="S2.SS1.p2.11.m11.1.1.1.1.1.1.cmml" xref="S2.SS1.p2.11.m11.1.1.1.1.1.1">conditional</csymbol><apply id="S2.SS1.p2.11.m11.1.1.1.1.1.2.cmml" xref="S2.SS1.p2.11.m11.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p2.11.m11.1.1.1.1.1.2.1.cmml" xref="S2.SS1.p2.11.m11.1.1.1.1.1.2">subscript</csymbol><ci id="S2.SS1.p2.11.m11.1.1.1.1.1.2.2.cmml" xref="S2.SS1.p2.11.m11.1.1.1.1.1.2.2">ğ³</ci><apply id="S2.SS1.p2.11.m11.1.1.1.1.1.2.3.cmml" xref="S2.SS1.p2.11.m11.1.1.1.1.1.2.3"><plus id="S2.SS1.p2.11.m11.1.1.1.1.1.2.3.1.cmml" xref="S2.SS1.p2.11.m11.1.1.1.1.1.2.3.1"></plus><ci id="S2.SS1.p2.11.m11.1.1.1.1.1.2.3.2.cmml" xref="S2.SS1.p2.11.m11.1.1.1.1.1.2.3.2">ğ‘¡</ci><ci id="S2.SS1.p2.11.m11.1.1.1.1.1.2.3.3.cmml" xref="S2.SS1.p2.11.m11.1.1.1.1.1.2.3.3">ğ‘˜</ci></apply></apply><apply id="S2.SS1.p2.11.m11.1.1.1.1.1.3.cmml" xref="S2.SS1.p2.11.m11.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p2.11.m11.1.1.1.1.1.3.1.cmml" xref="S2.SS1.p2.11.m11.1.1.1.1.1.3">subscript</csymbol><ci id="S2.SS1.p2.11.m11.1.1.1.1.1.3.2.cmml" xref="S2.SS1.p2.11.m11.1.1.1.1.1.3.2">ğœ</ci><ci id="S2.SS1.p2.11.m11.1.1.1.1.1.3.3.cmml" xref="S2.SS1.p2.11.m11.1.1.1.1.1.3.3">ğ‘¡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.11.m11.1c">p(\mathbf{z}_{t+k}|\mathbf{c}_{t})</annotation></semantics></math> and <math id="S2.SS1.p2.12.m12.1" class="ltx_Math" alttext="N-1" display="inline"><semantics id="S2.SS1.p2.12.m12.1a"><mrow id="S2.SS1.p2.12.m12.1.1" xref="S2.SS1.p2.12.m12.1.1.cmml"><mi id="S2.SS1.p2.12.m12.1.1.2" xref="S2.SS1.p2.12.m12.1.1.2.cmml">N</mi><mo id="S2.SS1.p2.12.m12.1.1.1" xref="S2.SS1.p2.12.m12.1.1.1.cmml">âˆ’</mo><mn id="S2.SS1.p2.12.m12.1.1.3" xref="S2.SS1.p2.12.m12.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.12.m12.1b"><apply id="S2.SS1.p2.12.m12.1.1.cmml" xref="S2.SS1.p2.12.m12.1.1"><minus id="S2.SS1.p2.12.m12.1.1.1.cmml" xref="S2.SS1.p2.12.m12.1.1.1"></minus><ci id="S2.SS1.p2.12.m12.1.1.2.cmml" xref="S2.SS1.p2.12.m12.1.1.2">ğ‘</ci><cn type="integer" id="S2.SS1.p2.12.m12.1.1.3.cmml" xref="S2.SS1.p2.12.m12.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.12.m12.1c">N-1</annotation></semantics></math> negative samples from â€œnoiseâ€ distribution <math id="S2.SS1.p2.13.m13.1" class="ltx_Math" alttext="p(\mathbf{z}_{t+k})" display="inline"><semantics id="S2.SS1.p2.13.m13.1a"><mrow id="S2.SS1.p2.13.m13.1.1" xref="S2.SS1.p2.13.m13.1.1.cmml"><mi id="S2.SS1.p2.13.m13.1.1.3" xref="S2.SS1.p2.13.m13.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p2.13.m13.1.1.2" xref="S2.SS1.p2.13.m13.1.1.2.cmml">â€‹</mo><mrow id="S2.SS1.p2.13.m13.1.1.1.1" xref="S2.SS1.p2.13.m13.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.p2.13.m13.1.1.1.1.2" xref="S2.SS1.p2.13.m13.1.1.1.1.1.cmml">(</mo><msub id="S2.SS1.p2.13.m13.1.1.1.1.1" xref="S2.SS1.p2.13.m13.1.1.1.1.1.cmml"><mi id="S2.SS1.p2.13.m13.1.1.1.1.1.2" xref="S2.SS1.p2.13.m13.1.1.1.1.1.2.cmml">ğ³</mi><mrow id="S2.SS1.p2.13.m13.1.1.1.1.1.3" xref="S2.SS1.p2.13.m13.1.1.1.1.1.3.cmml"><mi id="S2.SS1.p2.13.m13.1.1.1.1.1.3.2" xref="S2.SS1.p2.13.m13.1.1.1.1.1.3.2.cmml">t</mi><mo id="S2.SS1.p2.13.m13.1.1.1.1.1.3.1" xref="S2.SS1.p2.13.m13.1.1.1.1.1.3.1.cmml">+</mo><mi id="S2.SS1.p2.13.m13.1.1.1.1.1.3.3" xref="S2.SS1.p2.13.m13.1.1.1.1.1.3.3.cmml">k</mi></mrow></msub><mo stretchy="false" id="S2.SS1.p2.13.m13.1.1.1.1.3" xref="S2.SS1.p2.13.m13.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.13.m13.1b"><apply id="S2.SS1.p2.13.m13.1.1.cmml" xref="S2.SS1.p2.13.m13.1.1"><times id="S2.SS1.p2.13.m13.1.1.2.cmml" xref="S2.SS1.p2.13.m13.1.1.2"></times><ci id="S2.SS1.p2.13.m13.1.1.3.cmml" xref="S2.SS1.p2.13.m13.1.1.3">ğ‘</ci><apply id="S2.SS1.p2.13.m13.1.1.1.1.1.cmml" xref="S2.SS1.p2.13.m13.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.13.m13.1.1.1.1.1.1.cmml" xref="S2.SS1.p2.13.m13.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p2.13.m13.1.1.1.1.1.2.cmml" xref="S2.SS1.p2.13.m13.1.1.1.1.1.2">ğ³</ci><apply id="S2.SS1.p2.13.m13.1.1.1.1.1.3.cmml" xref="S2.SS1.p2.13.m13.1.1.1.1.1.3"><plus id="S2.SS1.p2.13.m13.1.1.1.1.1.3.1.cmml" xref="S2.SS1.p2.13.m13.1.1.1.1.1.3.1"></plus><ci id="S2.SS1.p2.13.m13.1.1.1.1.1.3.2.cmml" xref="S2.SS1.p2.13.m13.1.1.1.1.1.3.2">ğ‘¡</ci><ci id="S2.SS1.p2.13.m13.1.1.1.1.1.3.3.cmml" xref="S2.SS1.p2.13.m13.1.1.1.1.1.3.3">ğ‘˜</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.13.m13.1c">p(\mathbf{z}_{t+k})</annotation></semantics></math> are drawn for optimizing the loss.
And The formula is as follows:</p>
<table id="S6.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S2.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E1.m1.4" class="ltx_math_unparsed" alttext="\displaystyle\mathcal{L}^{NCE}_{tk}=-\mathbb{E}\left[\log\frac{\exp(\mathbf{c}^{T}_{t}\mathbf{W}_{k}\mathbf{z}_{t+k}))}{\frac{1}{N}\sum_{\tilde{\mathbf{z}}\in{Z}}\exp(\mathbf{c}^{T}_{t}\mathbf{W}_{k}\mathbf{\tilde{\mathbf{z}}})}\right]" display="inline"><semantics id="S2.E1.m1.4a"><mrow id="S2.E1.m1.4.4"><msubsup id="S2.E1.m1.4.4.3"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.4.4.3.2.2">â„’</mi><mrow id="S2.E1.m1.4.4.3.3"><mi id="S2.E1.m1.4.4.3.3.2">t</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.4.4.3.3.1">â€‹</mo><mi id="S2.E1.m1.4.4.3.3.3">k</mi></mrow><mrow id="S2.E1.m1.4.4.3.2.3"><mi id="S2.E1.m1.4.4.3.2.3.2">N</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.4.4.3.2.3.1">â€‹</mo><mi id="S2.E1.m1.4.4.3.2.3.3">C</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.4.4.3.2.3.1a">â€‹</mo><mi id="S2.E1.m1.4.4.3.2.3.4">E</mi></mrow></msubsup><mo id="S2.E1.m1.4.4.2">=</mo><mrow id="S2.E1.m1.4.4.1"><mo id="S2.E1.m1.4.4.1a">âˆ’</mo><mrow id="S2.E1.m1.4.4.1.1"><mi id="S2.E1.m1.4.4.1.1.3">ğ”¼</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.4.4.1.1.2">â€‹</mo><mrow id="S2.E1.m1.4.4.1.1.1.1"><mo id="S2.E1.m1.4.4.1.1.1.1.2">[</mo><mrow id="S2.E1.m1.4.4.1.1.1.1.1"><mi id="S2.E1.m1.4.4.1.1.1.1.1.1">log</mi><mo lspace="0.167em" id="S2.E1.m1.4.4.1.1.1.1.1a">â¡</mo><mstyle displaystyle="true" id="S2.E1.m1.3.3"><mfrac id="S2.E1.m1.3.3a"><mrow id="S2.E1.m1.1.1.1"><mi id="S2.E1.m1.1.1.1.1">exp</mi><mrow id="S2.E1.m1.1.1.1.2"><mo stretchy="false" id="S2.E1.m1.1.1.1.2.1">(</mo><msubsup id="S2.E1.m1.1.1.1.2.2"><mi id="S2.E1.m1.1.1.1.2.2.2.2">ğœ</mi><mi id="S2.E1.m1.1.1.1.2.2.3">t</mi><mi id="S2.E1.m1.1.1.1.2.2.2.3">T</mi></msubsup><msub id="S2.E1.m1.1.1.1.2.3"><mi id="S2.E1.m1.1.1.1.2.3.2">ğ–</mi><mi id="S2.E1.m1.1.1.1.2.3.3">k</mi></msub><msub id="S2.E1.m1.1.1.1.2.4"><mi id="S2.E1.m1.1.1.1.2.4.2">ğ³</mi><mrow id="S2.E1.m1.1.1.1.2.4.3"><mi id="S2.E1.m1.1.1.1.2.4.3.2">t</mi><mo id="S2.E1.m1.1.1.1.2.4.3.1">+</mo><mi id="S2.E1.m1.1.1.1.2.4.3.3">k</mi></mrow></msub><mo stretchy="false" id="S2.E1.m1.1.1.1.2.5">)</mo></mrow><mo stretchy="false" id="S2.E1.m1.1.1.1.3">)</mo></mrow><mrow id="S2.E1.m1.3.3.3"><mfrac id="S2.E1.m1.3.3.3.4"><mn id="S2.E1.m1.3.3.3.4.2">1</mn><mi id="S2.E1.m1.3.3.3.4.3">N</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.3.3">â€‹</mo><mrow id="S2.E1.m1.3.3.3.2"><msub id="S2.E1.m1.3.3.3.2.2"><mo id="S2.E1.m1.3.3.3.2.2.2">âˆ‘</mo><mrow id="S2.E1.m1.3.3.3.2.2.3"><mover accent="true" id="S2.E1.m1.3.3.3.2.2.3.2"><mi id="S2.E1.m1.3.3.3.2.2.3.2.2">ğ³</mi><mo id="S2.E1.m1.3.3.3.2.2.3.2.1">~</mo></mover><mo id="S2.E1.m1.3.3.3.2.2.3.1">âˆˆ</mo><mi id="S2.E1.m1.3.3.3.2.2.3.3">Z</mi></mrow></msub><mrow id="S2.E1.m1.3.3.3.2.1.1"><mi id="S2.E1.m1.2.2.2.1">exp</mi><mo id="S2.E1.m1.3.3.3.2.1.1a">â¡</mo><mrow id="S2.E1.m1.3.3.3.2.1.1.1"><mo stretchy="false" id="S2.E1.m1.3.3.3.2.1.1.1.2">(</mo><mrow id="S2.E1.m1.3.3.3.2.1.1.1.1"><msubsup id="S2.E1.m1.3.3.3.2.1.1.1.1.2"><mi id="S2.E1.m1.3.3.3.2.1.1.1.1.2.2.2">ğœ</mi><mi id="S2.E1.m1.3.3.3.2.1.1.1.1.2.3">t</mi><mi id="S2.E1.m1.3.3.3.2.1.1.1.1.2.2.3">T</mi></msubsup><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.3.2.1.1.1.1.1">â€‹</mo><msub id="S2.E1.m1.3.3.3.2.1.1.1.1.3"><mi id="S2.E1.m1.3.3.3.2.1.1.1.1.3.2">ğ–</mi><mi id="S2.E1.m1.3.3.3.2.1.1.1.1.3.3">k</mi></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.3.2.1.1.1.1.1a">â€‹</mo><mover accent="true" id="S2.E1.m1.3.3.3.2.1.1.1.1.4"><mi id="S2.E1.m1.3.3.3.2.1.1.1.1.4.2">ğ³</mi><mo id="S2.E1.m1.3.3.3.2.1.1.1.1.4.1">~</mo></mover></mrow><mo stretchy="false" id="S2.E1.m1.3.3.3.2.1.1.1.3">)</mo></mrow></mrow></mrow></mrow></mfrac></mstyle></mrow><mo id="S2.E1.m1.4.4.1.1.1.1.3">]</mo></mrow></mrow></mrow></mrow><annotation encoding="application/x-tex" id="S2.E1.m1.4b">\displaystyle\mathcal{L}^{NCE}_{tk}=-\mathbb{E}\left[\log\frac{\exp(\mathbf{c}^{T}_{t}\mathbf{W}_{k}\mathbf{z}_{t+k}))}{\frac{1}{N}\sum_{\tilde{\mathbf{z}}\in{Z}}\exp(\mathbf{c}^{T}_{t}\mathbf{W}_{k}\mathbf{\tilde{\mathbf{z}}})}\right]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Federated Learning</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">With the advent of the General Data Protection Regulation and increasing privacy concerns, sharing real-world AD speech data is facing significant challenges <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. Speech data contain the speakerâ€™s identifiable information represented as voiceprint used in many authentication systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. Exposing an individualâ€™s voiceprint may cause security risks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> to voice authentication systems. Several methods have been proposed to anonymize speakersâ€™ identities using state-of-the-art technologies, such as
speech synthesis <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, voice conversion <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, speaker embeddings <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, k-anonymity model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. However, these approaches are neither cost nor time-efficient and, therefore, do not meet the demands for big data on a global scale.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">Federated learning proposes a solution to privacy-preserving large-scale machine learning by first training models locally on an individual client device and then aggregating the updates of the local models on the central server. There are several proposed algorithms for solving the Federated Optimization problem. One of the most promising algorithms is federated averaging (FedAvg) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. The algorithm provides privacy by design and personalizes models to individual users. It also claims to be more resource-efficient in terms of communication rounds.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.14" class="ltx_p">This algorithm, firstly proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, relies on the stochastic gradient descent (SGD) optimization method since most of the most successful deep learning works were based on this. The available clients locally compute their average gradient on their local data at the parameters of the current model <math id="S2.SS2.p3.1.m1.1" class="ltx_Math" alttext="w_{s}" display="inline"><semantics id="S2.SS2.p3.1.m1.1a"><msub id="S2.SS2.p3.1.m1.1.1" xref="S2.SS2.p3.1.m1.1.1.cmml"><mi id="S2.SS2.p3.1.m1.1.1.2" xref="S2.SS2.p3.1.m1.1.1.2.cmml">w</mi><mi id="S2.SS2.p3.1.m1.1.1.3" xref="S2.SS2.p3.1.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.1.m1.1b"><apply id="S2.SS2.p3.1.m1.1.1.cmml" xref="S2.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.1.m1.1.1.1.cmml" xref="S2.SS2.p3.1.m1.1.1">subscript</csymbol><ci id="S2.SS2.p3.1.m1.1.1.2.cmml" xref="S2.SS2.p3.1.m1.1.1.2">ğ‘¤</ci><ci id="S2.SS2.p3.1.m1.1.1.3.cmml" xref="S2.SS2.p3.1.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.1.m1.1c">w_{s}</annotation></semantics></math>, where <math id="S2.SS2.p3.2.m2.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S2.SS2.p3.2.m2.1a"><mi id="S2.SS2.p3.2.m2.1.1" xref="S2.SS2.p3.2.m2.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.2.m2.1b"><ci id="S2.SS2.p3.2.m2.1.1.cmml" xref="S2.SS2.p3.2.m2.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.2.m2.1c">s</annotation></semantics></math> identifies the federated round. The central server aggregates these gradients and applies the update <math id="S2.SS2.p3.3.m3.1" class="ltx_Math" alttext="w_{s+1}\leftarrow w_{s}-\eta\sum_{m=1}^{M}\frac{n_{m}}{n}g^{m}_{s}" display="inline"><semantics id="S2.SS2.p3.3.m3.1a"><mrow id="S2.SS2.p3.3.m3.1.1" xref="S2.SS2.p3.3.m3.1.1.cmml"><msub id="S2.SS2.p3.3.m3.1.1.2" xref="S2.SS2.p3.3.m3.1.1.2.cmml"><mi id="S2.SS2.p3.3.m3.1.1.2.2" xref="S2.SS2.p3.3.m3.1.1.2.2.cmml">w</mi><mrow id="S2.SS2.p3.3.m3.1.1.2.3" xref="S2.SS2.p3.3.m3.1.1.2.3.cmml"><mi id="S2.SS2.p3.3.m3.1.1.2.3.2" xref="S2.SS2.p3.3.m3.1.1.2.3.2.cmml">s</mi><mo id="S2.SS2.p3.3.m3.1.1.2.3.1" xref="S2.SS2.p3.3.m3.1.1.2.3.1.cmml">+</mo><mn id="S2.SS2.p3.3.m3.1.1.2.3.3" xref="S2.SS2.p3.3.m3.1.1.2.3.3.cmml">1</mn></mrow></msub><mo stretchy="false" id="S2.SS2.p3.3.m3.1.1.1" xref="S2.SS2.p3.3.m3.1.1.1.cmml">â†</mo><mrow id="S2.SS2.p3.3.m3.1.1.3" xref="S2.SS2.p3.3.m3.1.1.3.cmml"><msub id="S2.SS2.p3.3.m3.1.1.3.2" xref="S2.SS2.p3.3.m3.1.1.3.2.cmml"><mi id="S2.SS2.p3.3.m3.1.1.3.2.2" xref="S2.SS2.p3.3.m3.1.1.3.2.2.cmml">w</mi><mi id="S2.SS2.p3.3.m3.1.1.3.2.3" xref="S2.SS2.p3.3.m3.1.1.3.2.3.cmml">s</mi></msub><mo id="S2.SS2.p3.3.m3.1.1.3.1" xref="S2.SS2.p3.3.m3.1.1.3.1.cmml">âˆ’</mo><mrow id="S2.SS2.p3.3.m3.1.1.3.3" xref="S2.SS2.p3.3.m3.1.1.3.3.cmml"><mi id="S2.SS2.p3.3.m3.1.1.3.3.2" xref="S2.SS2.p3.3.m3.1.1.3.3.2.cmml">Î·</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p3.3.m3.1.1.3.3.1" xref="S2.SS2.p3.3.m3.1.1.3.3.1.cmml">â€‹</mo><mrow id="S2.SS2.p3.3.m3.1.1.3.3.3" xref="S2.SS2.p3.3.m3.1.1.3.3.3.cmml"><msubsup id="S2.SS2.p3.3.m3.1.1.3.3.3.1" xref="S2.SS2.p3.3.m3.1.1.3.3.3.1.cmml"><mo id="S2.SS2.p3.3.m3.1.1.3.3.3.1.2.2" xref="S2.SS2.p3.3.m3.1.1.3.3.3.1.2.2.cmml">âˆ‘</mo><mrow id="S2.SS2.p3.3.m3.1.1.3.3.3.1.2.3" xref="S2.SS2.p3.3.m3.1.1.3.3.3.1.2.3.cmml"><mi id="S2.SS2.p3.3.m3.1.1.3.3.3.1.2.3.2" xref="S2.SS2.p3.3.m3.1.1.3.3.3.1.2.3.2.cmml">m</mi><mo id="S2.SS2.p3.3.m3.1.1.3.3.3.1.2.3.1" xref="S2.SS2.p3.3.m3.1.1.3.3.3.1.2.3.1.cmml">=</mo><mn id="S2.SS2.p3.3.m3.1.1.3.3.3.1.2.3.3" xref="S2.SS2.p3.3.m3.1.1.3.3.3.1.2.3.3.cmml">1</mn></mrow><mi id="S2.SS2.p3.3.m3.1.1.3.3.3.1.3" xref="S2.SS2.p3.3.m3.1.1.3.3.3.1.3.cmml">M</mi></msubsup><mrow id="S2.SS2.p3.3.m3.1.1.3.3.3.2" xref="S2.SS2.p3.3.m3.1.1.3.3.3.2.cmml"><mfrac id="S2.SS2.p3.3.m3.1.1.3.3.3.2.2" xref="S2.SS2.p3.3.m3.1.1.3.3.3.2.2.cmml"><msub id="S2.SS2.p3.3.m3.1.1.3.3.3.2.2.2" xref="S2.SS2.p3.3.m3.1.1.3.3.3.2.2.2.cmml"><mi id="S2.SS2.p3.3.m3.1.1.3.3.3.2.2.2.2" xref="S2.SS2.p3.3.m3.1.1.3.3.3.2.2.2.2.cmml">n</mi><mi id="S2.SS2.p3.3.m3.1.1.3.3.3.2.2.2.3" xref="S2.SS2.p3.3.m3.1.1.3.3.3.2.2.2.3.cmml">m</mi></msub><mi id="S2.SS2.p3.3.m3.1.1.3.3.3.2.2.3" xref="S2.SS2.p3.3.m3.1.1.3.3.3.2.2.3.cmml">n</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.SS2.p3.3.m3.1.1.3.3.3.2.1" xref="S2.SS2.p3.3.m3.1.1.3.3.3.2.1.cmml">â€‹</mo><msubsup id="S2.SS2.p3.3.m3.1.1.3.3.3.2.3" xref="S2.SS2.p3.3.m3.1.1.3.3.3.2.3.cmml"><mi id="S2.SS2.p3.3.m3.1.1.3.3.3.2.3.2.2" xref="S2.SS2.p3.3.m3.1.1.3.3.3.2.3.2.2.cmml">g</mi><mi id="S2.SS2.p3.3.m3.1.1.3.3.3.2.3.3" xref="S2.SS2.p3.3.m3.1.1.3.3.3.2.3.3.cmml">s</mi><mi id="S2.SS2.p3.3.m3.1.1.3.3.3.2.3.2.3" xref="S2.SS2.p3.3.m3.1.1.3.3.3.2.3.2.3.cmml">m</mi></msubsup></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.3.m3.1b"><apply id="S2.SS2.p3.3.m3.1.1.cmml" xref="S2.SS2.p3.3.m3.1.1"><ci id="S2.SS2.p3.3.m3.1.1.1.cmml" xref="S2.SS2.p3.3.m3.1.1.1">â†</ci><apply id="S2.SS2.p3.3.m3.1.1.2.cmml" xref="S2.SS2.p3.3.m3.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.p3.3.m3.1.1.2.1.cmml" xref="S2.SS2.p3.3.m3.1.1.2">subscript</csymbol><ci id="S2.SS2.p3.3.m3.1.1.2.2.cmml" xref="S2.SS2.p3.3.m3.1.1.2.2">ğ‘¤</ci><apply id="S2.SS2.p3.3.m3.1.1.2.3.cmml" xref="S2.SS2.p3.3.m3.1.1.2.3"><plus id="S2.SS2.p3.3.m3.1.1.2.3.1.cmml" xref="S2.SS2.p3.3.m3.1.1.2.3.1"></plus><ci id="S2.SS2.p3.3.m3.1.1.2.3.2.cmml" xref="S2.SS2.p3.3.m3.1.1.2.3.2">ğ‘ </ci><cn type="integer" id="S2.SS2.p3.3.m3.1.1.2.3.3.cmml" xref="S2.SS2.p3.3.m3.1.1.2.3.3">1</cn></apply></apply><apply id="S2.SS2.p3.3.m3.1.1.3.cmml" xref="S2.SS2.p3.3.m3.1.1.3"><minus id="S2.SS2.p3.3.m3.1.1.3.1.cmml" xref="S2.SS2.p3.3.m3.1.1.3.1"></minus><apply id="S2.SS2.p3.3.m3.1.1.3.2.cmml" xref="S2.SS2.p3.3.m3.1.1.3.2"><csymbol cd="ambiguous" id="S2.SS2.p3.3.m3.1.1.3.2.1.cmml" xref="S2.SS2.p3.3.m3.1.1.3.2">subscript</csymbol><ci id="S2.SS2.p3.3.m3.1.1.3.2.2.cmml" xref="S2.SS2.p3.3.m3.1.1.3.2.2">ğ‘¤</ci><ci id="S2.SS2.p3.3.m3.1.1.3.2.3.cmml" xref="S2.SS2.p3.3.m3.1.1.3.2.3">ğ‘ </ci></apply><apply id="S2.SS2.p3.3.m3.1.1.3.3.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3"><times id="S2.SS2.p3.3.m3.1.1.3.3.1.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.1"></times><ci id="S2.SS2.p3.3.m3.1.1.3.3.2.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.2">ğœ‚</ci><apply id="S2.SS2.p3.3.m3.1.1.3.3.3.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3"><apply id="S2.SS2.p3.3.m3.1.1.3.3.3.1.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3.1"><csymbol cd="ambiguous" id="S2.SS2.p3.3.m3.1.1.3.3.3.1.1.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3.1">superscript</csymbol><apply id="S2.SS2.p3.3.m3.1.1.3.3.3.1.2.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3.1"><csymbol cd="ambiguous" id="S2.SS2.p3.3.m3.1.1.3.3.3.1.2.1.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3.1">subscript</csymbol><sum id="S2.SS2.p3.3.m3.1.1.3.3.3.1.2.2.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3.1.2.2"></sum><apply id="S2.SS2.p3.3.m3.1.1.3.3.3.1.2.3.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3.1.2.3"><eq id="S2.SS2.p3.3.m3.1.1.3.3.3.1.2.3.1.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3.1.2.3.1"></eq><ci id="S2.SS2.p3.3.m3.1.1.3.3.3.1.2.3.2.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3.1.2.3.2">ğ‘š</ci><cn type="integer" id="S2.SS2.p3.3.m3.1.1.3.3.3.1.2.3.3.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3.1.2.3.3">1</cn></apply></apply><ci id="S2.SS2.p3.3.m3.1.1.3.3.3.1.3.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3.1.3">ğ‘€</ci></apply><apply id="S2.SS2.p3.3.m3.1.1.3.3.3.2.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3.2"><times id="S2.SS2.p3.3.m3.1.1.3.3.3.2.1.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3.2.1"></times><apply id="S2.SS2.p3.3.m3.1.1.3.3.3.2.2.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3.2.2"><divide id="S2.SS2.p3.3.m3.1.1.3.3.3.2.2.1.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3.2.2"></divide><apply id="S2.SS2.p3.3.m3.1.1.3.3.3.2.2.2.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.p3.3.m3.1.1.3.3.3.2.2.2.1.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3.2.2.2">subscript</csymbol><ci id="S2.SS2.p3.3.m3.1.1.3.3.3.2.2.2.2.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3.2.2.2.2">ğ‘›</ci><ci id="S2.SS2.p3.3.m3.1.1.3.3.3.2.2.2.3.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3.2.2.2.3">ğ‘š</ci></apply><ci id="S2.SS2.p3.3.m3.1.1.3.3.3.2.2.3.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3.2.2.3">ğ‘›</ci></apply><apply id="S2.SS2.p3.3.m3.1.1.3.3.3.2.3.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3.2.3"><csymbol cd="ambiguous" id="S2.SS2.p3.3.m3.1.1.3.3.3.2.3.1.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3.2.3">subscript</csymbol><apply id="S2.SS2.p3.3.m3.1.1.3.3.3.2.3.2.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3.2.3"><csymbol cd="ambiguous" id="S2.SS2.p3.3.m3.1.1.3.3.3.2.3.2.1.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3.2.3">superscript</csymbol><ci id="S2.SS2.p3.3.m3.1.1.3.3.3.2.3.2.2.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3.2.3.2.2">ğ‘”</ci><ci id="S2.SS2.p3.3.m3.1.1.3.3.3.2.3.2.3.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3.2.3.2.3">ğ‘š</ci></apply><ci id="S2.SS2.p3.3.m3.1.1.3.3.3.2.3.3.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3.2.3.3">ğ‘ </ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.3.m3.1c">w_{s+1}\leftarrow w_{s}-\eta\sum_{m=1}^{M}\frac{n_{m}}{n}g^{m}_{s}</annotation></semantics></math>, where <math id="S2.SS2.p3.4.m4.1" class="ltx_Math" alttext="g^{m}_{s}=\nabla F_{m}(w_{s})" display="inline"><semantics id="S2.SS2.p3.4.m4.1a"><mrow id="S2.SS2.p3.4.m4.1.1" xref="S2.SS2.p3.4.m4.1.1.cmml"><msubsup id="S2.SS2.p3.4.m4.1.1.3" xref="S2.SS2.p3.4.m4.1.1.3.cmml"><mi id="S2.SS2.p3.4.m4.1.1.3.2.2" xref="S2.SS2.p3.4.m4.1.1.3.2.2.cmml">g</mi><mi id="S2.SS2.p3.4.m4.1.1.3.3" xref="S2.SS2.p3.4.m4.1.1.3.3.cmml">s</mi><mi id="S2.SS2.p3.4.m4.1.1.3.2.3" xref="S2.SS2.p3.4.m4.1.1.3.2.3.cmml">m</mi></msubsup><mo id="S2.SS2.p3.4.m4.1.1.2" xref="S2.SS2.p3.4.m4.1.1.2.cmml">=</mo><mrow id="S2.SS2.p3.4.m4.1.1.1" xref="S2.SS2.p3.4.m4.1.1.1.cmml"><mrow id="S2.SS2.p3.4.m4.1.1.1.3" xref="S2.SS2.p3.4.m4.1.1.1.3.cmml"><mo rspace="0.167em" id="S2.SS2.p3.4.m4.1.1.1.3.1" xref="S2.SS2.p3.4.m4.1.1.1.3.1.cmml">âˆ‡</mo><msub id="S2.SS2.p3.4.m4.1.1.1.3.2" xref="S2.SS2.p3.4.m4.1.1.1.3.2.cmml"><mi id="S2.SS2.p3.4.m4.1.1.1.3.2.2" xref="S2.SS2.p3.4.m4.1.1.1.3.2.2.cmml">F</mi><mi id="S2.SS2.p3.4.m4.1.1.1.3.2.3" xref="S2.SS2.p3.4.m4.1.1.1.3.2.3.cmml">m</mi></msub></mrow><mo lspace="0em" rspace="0em" id="S2.SS2.p3.4.m4.1.1.1.2" xref="S2.SS2.p3.4.m4.1.1.1.2.cmml">â€‹</mo><mrow id="S2.SS2.p3.4.m4.1.1.1.1.1" xref="S2.SS2.p3.4.m4.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS2.p3.4.m4.1.1.1.1.1.2" xref="S2.SS2.p3.4.m4.1.1.1.1.1.1.cmml">(</mo><msub id="S2.SS2.p3.4.m4.1.1.1.1.1.1" xref="S2.SS2.p3.4.m4.1.1.1.1.1.1.cmml"><mi id="S2.SS2.p3.4.m4.1.1.1.1.1.1.2" xref="S2.SS2.p3.4.m4.1.1.1.1.1.1.2.cmml">w</mi><mi id="S2.SS2.p3.4.m4.1.1.1.1.1.1.3" xref="S2.SS2.p3.4.m4.1.1.1.1.1.1.3.cmml">s</mi></msub><mo stretchy="false" id="S2.SS2.p3.4.m4.1.1.1.1.1.3" xref="S2.SS2.p3.4.m4.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.4.m4.1b"><apply id="S2.SS2.p3.4.m4.1.1.cmml" xref="S2.SS2.p3.4.m4.1.1"><eq id="S2.SS2.p3.4.m4.1.1.2.cmml" xref="S2.SS2.p3.4.m4.1.1.2"></eq><apply id="S2.SS2.p3.4.m4.1.1.3.cmml" xref="S2.SS2.p3.4.m4.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.p3.4.m4.1.1.3.1.cmml" xref="S2.SS2.p3.4.m4.1.1.3">subscript</csymbol><apply id="S2.SS2.p3.4.m4.1.1.3.2.cmml" xref="S2.SS2.p3.4.m4.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.p3.4.m4.1.1.3.2.1.cmml" xref="S2.SS2.p3.4.m4.1.1.3">superscript</csymbol><ci id="S2.SS2.p3.4.m4.1.1.3.2.2.cmml" xref="S2.SS2.p3.4.m4.1.1.3.2.2">ğ‘”</ci><ci id="S2.SS2.p3.4.m4.1.1.3.2.3.cmml" xref="S2.SS2.p3.4.m4.1.1.3.2.3">ğ‘š</ci></apply><ci id="S2.SS2.p3.4.m4.1.1.3.3.cmml" xref="S2.SS2.p3.4.m4.1.1.3.3">ğ‘ </ci></apply><apply id="S2.SS2.p3.4.m4.1.1.1.cmml" xref="S2.SS2.p3.4.m4.1.1.1"><times id="S2.SS2.p3.4.m4.1.1.1.2.cmml" xref="S2.SS2.p3.4.m4.1.1.1.2"></times><apply id="S2.SS2.p3.4.m4.1.1.1.3.cmml" xref="S2.SS2.p3.4.m4.1.1.1.3"><ci id="S2.SS2.p3.4.m4.1.1.1.3.1.cmml" xref="S2.SS2.p3.4.m4.1.1.1.3.1">âˆ‡</ci><apply id="S2.SS2.p3.4.m4.1.1.1.3.2.cmml" xref="S2.SS2.p3.4.m4.1.1.1.3.2"><csymbol cd="ambiguous" id="S2.SS2.p3.4.m4.1.1.1.3.2.1.cmml" xref="S2.SS2.p3.4.m4.1.1.1.3.2">subscript</csymbol><ci id="S2.SS2.p3.4.m4.1.1.1.3.2.2.cmml" xref="S2.SS2.p3.4.m4.1.1.1.3.2.2">ğ¹</ci><ci id="S2.SS2.p3.4.m4.1.1.1.3.2.3.cmml" xref="S2.SS2.p3.4.m4.1.1.1.3.2.3">ğ‘š</ci></apply></apply><apply id="S2.SS2.p3.4.m4.1.1.1.1.1.1.cmml" xref="S2.SS2.p3.4.m4.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.4.m4.1.1.1.1.1.1.1.cmml" xref="S2.SS2.p3.4.m4.1.1.1.1.1">subscript</csymbol><ci id="S2.SS2.p3.4.m4.1.1.1.1.1.1.2.cmml" xref="S2.SS2.p3.4.m4.1.1.1.1.1.1.2">ğ‘¤</ci><ci id="S2.SS2.p3.4.m4.1.1.1.1.1.1.3.cmml" xref="S2.SS2.p3.4.m4.1.1.1.1.1.1.3">ğ‘ </ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.4.m4.1c">g^{m}_{s}=\nabla F_{m}(w_{s})</annotation></semantics></math> is the gradient of the client <math id="S2.SS2.p3.5.m5.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S2.SS2.p3.5.m5.1a"><mi id="S2.SS2.p3.5.m5.1.1" xref="S2.SS2.p3.5.m5.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.5.m5.1b"><ci id="S2.SS2.p3.5.m5.1.1.cmml" xref="S2.SS2.p3.5.m5.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.5.m5.1c">m</annotation></semantics></math> in <math id="S2.SS2.p3.6.m6.1" class="ltx_Math" alttext="s_{th}" display="inline"><semantics id="S2.SS2.p3.6.m6.1a"><msub id="S2.SS2.p3.6.m6.1.1" xref="S2.SS2.p3.6.m6.1.1.cmml"><mi id="S2.SS2.p3.6.m6.1.1.2" xref="S2.SS2.p3.6.m6.1.1.2.cmml">s</mi><mrow id="S2.SS2.p3.6.m6.1.1.3" xref="S2.SS2.p3.6.m6.1.1.3.cmml"><mi id="S2.SS2.p3.6.m6.1.1.3.2" xref="S2.SS2.p3.6.m6.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p3.6.m6.1.1.3.1" xref="S2.SS2.p3.6.m6.1.1.3.1.cmml">â€‹</mo><mi id="S2.SS2.p3.6.m6.1.1.3.3" xref="S2.SS2.p3.6.m6.1.1.3.3.cmml">h</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.6.m6.1b"><apply id="S2.SS2.p3.6.m6.1.1.cmml" xref="S2.SS2.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.6.m6.1.1.1.cmml" xref="S2.SS2.p3.6.m6.1.1">subscript</csymbol><ci id="S2.SS2.p3.6.m6.1.1.2.cmml" xref="S2.SS2.p3.6.m6.1.1.2">ğ‘ </ci><apply id="S2.SS2.p3.6.m6.1.1.3.cmml" xref="S2.SS2.p3.6.m6.1.1.3"><times id="S2.SS2.p3.6.m6.1.1.3.1.cmml" xref="S2.SS2.p3.6.m6.1.1.3.1"></times><ci id="S2.SS2.p3.6.m6.1.1.3.2.cmml" xref="S2.SS2.p3.6.m6.1.1.3.2">ğ‘¡</ci><ci id="S2.SS2.p3.6.m6.1.1.3.3.cmml" xref="S2.SS2.p3.6.m6.1.1.3.3">â„</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.6.m6.1c">s_{th}</annotation></semantics></math> federated round, <math id="S2.SS2.p3.7.m7.1" class="ltx_Math" alttext="\eta" display="inline"><semantics id="S2.SS2.p3.7.m7.1a"><mi id="S2.SS2.p3.7.m7.1.1" xref="S2.SS2.p3.7.m7.1.1.cmml">Î·</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.7.m7.1b"><ci id="S2.SS2.p3.7.m7.1.1.cmml" xref="S2.SS2.p3.7.m7.1.1">ğœ‚</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.7.m7.1c">\eta</annotation></semantics></math> is the learning rate, <math id="S2.SS2.p3.8.m8.1" class="ltx_Math" alttext="n_{m}" display="inline"><semantics id="S2.SS2.p3.8.m8.1a"><msub id="S2.SS2.p3.8.m8.1.1" xref="S2.SS2.p3.8.m8.1.1.cmml"><mi id="S2.SS2.p3.8.m8.1.1.2" xref="S2.SS2.p3.8.m8.1.1.2.cmml">n</mi><mi id="S2.SS2.p3.8.m8.1.1.3" xref="S2.SS2.p3.8.m8.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.8.m8.1b"><apply id="S2.SS2.p3.8.m8.1.1.cmml" xref="S2.SS2.p3.8.m8.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.8.m8.1.1.1.cmml" xref="S2.SS2.p3.8.m8.1.1">subscript</csymbol><ci id="S2.SS2.p3.8.m8.1.1.2.cmml" xref="S2.SS2.p3.8.m8.1.1.2">ğ‘›</ci><ci id="S2.SS2.p3.8.m8.1.1.3.cmml" xref="S2.SS2.p3.8.m8.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.8.m8.1c">n_{m}</annotation></semantics></math> is the number of samples at the client <math id="S2.SS2.p3.9.m9.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S2.SS2.p3.9.m9.1a"><mi id="S2.SS2.p3.9.m9.1.1" xref="S2.SS2.p3.9.m9.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.9.m9.1b"><ci id="S2.SS2.p3.9.m9.1.1.cmml" xref="S2.SS2.p3.9.m9.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.9.m9.1c">m</annotation></semantics></math>, <math id="S2.SS2.p3.10.m10.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S2.SS2.p3.10.m10.1a"><mi id="S2.SS2.p3.10.m10.1.1" xref="S2.SS2.p3.10.m10.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.10.m10.1b"><ci id="S2.SS2.p3.10.m10.1.1.cmml" xref="S2.SS2.p3.10.m10.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.10.m10.1c">n</annotation></semantics></math> is the total number of samples (sum over all the available clients), <math id="S2.SS2.p3.11.m11.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S2.SS2.p3.11.m11.1a"><mi id="S2.SS2.p3.11.m11.1.1" xref="S2.SS2.p3.11.m11.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.11.m11.1b"><ci id="S2.SS2.p3.11.m11.1.1.cmml" xref="S2.SS2.p3.11.m11.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.11.m11.1c">M</annotation></semantics></math> is the number of the clients. Equivalently, the update can be given by <math id="S2.SS2.p3.12.m12.1" class="ltx_Math" alttext="w_{s+1}\leftarrow\sum_{m=1}^{M}\frac{n_{m}}{n}w_{s+1}^{m}" display="inline"><semantics id="S2.SS2.p3.12.m12.1a"><mrow id="S2.SS2.p3.12.m12.1.1" xref="S2.SS2.p3.12.m12.1.1.cmml"><msub id="S2.SS2.p3.12.m12.1.1.2" xref="S2.SS2.p3.12.m12.1.1.2.cmml"><mi id="S2.SS2.p3.12.m12.1.1.2.2" xref="S2.SS2.p3.12.m12.1.1.2.2.cmml">w</mi><mrow id="S2.SS2.p3.12.m12.1.1.2.3" xref="S2.SS2.p3.12.m12.1.1.2.3.cmml"><mi id="S2.SS2.p3.12.m12.1.1.2.3.2" xref="S2.SS2.p3.12.m12.1.1.2.3.2.cmml">s</mi><mo id="S2.SS2.p3.12.m12.1.1.2.3.1" xref="S2.SS2.p3.12.m12.1.1.2.3.1.cmml">+</mo><mn id="S2.SS2.p3.12.m12.1.1.2.3.3" xref="S2.SS2.p3.12.m12.1.1.2.3.3.cmml">1</mn></mrow></msub><mo rspace="0.111em" stretchy="false" id="S2.SS2.p3.12.m12.1.1.1" xref="S2.SS2.p3.12.m12.1.1.1.cmml">â†</mo><mrow id="S2.SS2.p3.12.m12.1.1.3" xref="S2.SS2.p3.12.m12.1.1.3.cmml"><msubsup id="S2.SS2.p3.12.m12.1.1.3.1" xref="S2.SS2.p3.12.m12.1.1.3.1.cmml"><mo id="S2.SS2.p3.12.m12.1.1.3.1.2.2" xref="S2.SS2.p3.12.m12.1.1.3.1.2.2.cmml">âˆ‘</mo><mrow id="S2.SS2.p3.12.m12.1.1.3.1.2.3" xref="S2.SS2.p3.12.m12.1.1.3.1.2.3.cmml"><mi id="S2.SS2.p3.12.m12.1.1.3.1.2.3.2" xref="S2.SS2.p3.12.m12.1.1.3.1.2.3.2.cmml">m</mi><mo id="S2.SS2.p3.12.m12.1.1.3.1.2.3.1" xref="S2.SS2.p3.12.m12.1.1.3.1.2.3.1.cmml">=</mo><mn id="S2.SS2.p3.12.m12.1.1.3.1.2.3.3" xref="S2.SS2.p3.12.m12.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="S2.SS2.p3.12.m12.1.1.3.1.3" xref="S2.SS2.p3.12.m12.1.1.3.1.3.cmml">M</mi></msubsup><mrow id="S2.SS2.p3.12.m12.1.1.3.2" xref="S2.SS2.p3.12.m12.1.1.3.2.cmml"><mfrac id="S2.SS2.p3.12.m12.1.1.3.2.2" xref="S2.SS2.p3.12.m12.1.1.3.2.2.cmml"><msub id="S2.SS2.p3.12.m12.1.1.3.2.2.2" xref="S2.SS2.p3.12.m12.1.1.3.2.2.2.cmml"><mi id="S2.SS2.p3.12.m12.1.1.3.2.2.2.2" xref="S2.SS2.p3.12.m12.1.1.3.2.2.2.2.cmml">n</mi><mi id="S2.SS2.p3.12.m12.1.1.3.2.2.2.3" xref="S2.SS2.p3.12.m12.1.1.3.2.2.2.3.cmml">m</mi></msub><mi id="S2.SS2.p3.12.m12.1.1.3.2.2.3" xref="S2.SS2.p3.12.m12.1.1.3.2.2.3.cmml">n</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.SS2.p3.12.m12.1.1.3.2.1" xref="S2.SS2.p3.12.m12.1.1.3.2.1.cmml">â€‹</mo><msubsup id="S2.SS2.p3.12.m12.1.1.3.2.3" xref="S2.SS2.p3.12.m12.1.1.3.2.3.cmml"><mi id="S2.SS2.p3.12.m12.1.1.3.2.3.2.2" xref="S2.SS2.p3.12.m12.1.1.3.2.3.2.2.cmml">w</mi><mrow id="S2.SS2.p3.12.m12.1.1.3.2.3.2.3" xref="S2.SS2.p3.12.m12.1.1.3.2.3.2.3.cmml"><mi id="S2.SS2.p3.12.m12.1.1.3.2.3.2.3.2" xref="S2.SS2.p3.12.m12.1.1.3.2.3.2.3.2.cmml">s</mi><mo id="S2.SS2.p3.12.m12.1.1.3.2.3.2.3.1" xref="S2.SS2.p3.12.m12.1.1.3.2.3.2.3.1.cmml">+</mo><mn id="S2.SS2.p3.12.m12.1.1.3.2.3.2.3.3" xref="S2.SS2.p3.12.m12.1.1.3.2.3.2.3.3.cmml">1</mn></mrow><mi id="S2.SS2.p3.12.m12.1.1.3.2.3.3" xref="S2.SS2.p3.12.m12.1.1.3.2.3.3.cmml">m</mi></msubsup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.12.m12.1b"><apply id="S2.SS2.p3.12.m12.1.1.cmml" xref="S2.SS2.p3.12.m12.1.1"><ci id="S2.SS2.p3.12.m12.1.1.1.cmml" xref="S2.SS2.p3.12.m12.1.1.1">â†</ci><apply id="S2.SS2.p3.12.m12.1.1.2.cmml" xref="S2.SS2.p3.12.m12.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.p3.12.m12.1.1.2.1.cmml" xref="S2.SS2.p3.12.m12.1.1.2">subscript</csymbol><ci id="S2.SS2.p3.12.m12.1.1.2.2.cmml" xref="S2.SS2.p3.12.m12.1.1.2.2">ğ‘¤</ci><apply id="S2.SS2.p3.12.m12.1.1.2.3.cmml" xref="S2.SS2.p3.12.m12.1.1.2.3"><plus id="S2.SS2.p3.12.m12.1.1.2.3.1.cmml" xref="S2.SS2.p3.12.m12.1.1.2.3.1"></plus><ci id="S2.SS2.p3.12.m12.1.1.2.3.2.cmml" xref="S2.SS2.p3.12.m12.1.1.2.3.2">ğ‘ </ci><cn type="integer" id="S2.SS2.p3.12.m12.1.1.2.3.3.cmml" xref="S2.SS2.p3.12.m12.1.1.2.3.3">1</cn></apply></apply><apply id="S2.SS2.p3.12.m12.1.1.3.cmml" xref="S2.SS2.p3.12.m12.1.1.3"><apply id="S2.SS2.p3.12.m12.1.1.3.1.cmml" xref="S2.SS2.p3.12.m12.1.1.3.1"><csymbol cd="ambiguous" id="S2.SS2.p3.12.m12.1.1.3.1.1.cmml" xref="S2.SS2.p3.12.m12.1.1.3.1">superscript</csymbol><apply id="S2.SS2.p3.12.m12.1.1.3.1.2.cmml" xref="S2.SS2.p3.12.m12.1.1.3.1"><csymbol cd="ambiguous" id="S2.SS2.p3.12.m12.1.1.3.1.2.1.cmml" xref="S2.SS2.p3.12.m12.1.1.3.1">subscript</csymbol><sum id="S2.SS2.p3.12.m12.1.1.3.1.2.2.cmml" xref="S2.SS2.p3.12.m12.1.1.3.1.2.2"></sum><apply id="S2.SS2.p3.12.m12.1.1.3.1.2.3.cmml" xref="S2.SS2.p3.12.m12.1.1.3.1.2.3"><eq id="S2.SS2.p3.12.m12.1.1.3.1.2.3.1.cmml" xref="S2.SS2.p3.12.m12.1.1.3.1.2.3.1"></eq><ci id="S2.SS2.p3.12.m12.1.1.3.1.2.3.2.cmml" xref="S2.SS2.p3.12.m12.1.1.3.1.2.3.2">ğ‘š</ci><cn type="integer" id="S2.SS2.p3.12.m12.1.1.3.1.2.3.3.cmml" xref="S2.SS2.p3.12.m12.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="S2.SS2.p3.12.m12.1.1.3.1.3.cmml" xref="S2.SS2.p3.12.m12.1.1.3.1.3">ğ‘€</ci></apply><apply id="S2.SS2.p3.12.m12.1.1.3.2.cmml" xref="S2.SS2.p3.12.m12.1.1.3.2"><times id="S2.SS2.p3.12.m12.1.1.3.2.1.cmml" xref="S2.SS2.p3.12.m12.1.1.3.2.1"></times><apply id="S2.SS2.p3.12.m12.1.1.3.2.2.cmml" xref="S2.SS2.p3.12.m12.1.1.3.2.2"><divide id="S2.SS2.p3.12.m12.1.1.3.2.2.1.cmml" xref="S2.SS2.p3.12.m12.1.1.3.2.2"></divide><apply id="S2.SS2.p3.12.m12.1.1.3.2.2.2.cmml" xref="S2.SS2.p3.12.m12.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.p3.12.m12.1.1.3.2.2.2.1.cmml" xref="S2.SS2.p3.12.m12.1.1.3.2.2.2">subscript</csymbol><ci id="S2.SS2.p3.12.m12.1.1.3.2.2.2.2.cmml" xref="S2.SS2.p3.12.m12.1.1.3.2.2.2.2">ğ‘›</ci><ci id="S2.SS2.p3.12.m12.1.1.3.2.2.2.3.cmml" xref="S2.SS2.p3.12.m12.1.1.3.2.2.2.3">ğ‘š</ci></apply><ci id="S2.SS2.p3.12.m12.1.1.3.2.2.3.cmml" xref="S2.SS2.p3.12.m12.1.1.3.2.2.3">ğ‘›</ci></apply><apply id="S2.SS2.p3.12.m12.1.1.3.2.3.cmml" xref="S2.SS2.p3.12.m12.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.SS2.p3.12.m12.1.1.3.2.3.1.cmml" xref="S2.SS2.p3.12.m12.1.1.3.2.3">superscript</csymbol><apply id="S2.SS2.p3.12.m12.1.1.3.2.3.2.cmml" xref="S2.SS2.p3.12.m12.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.SS2.p3.12.m12.1.1.3.2.3.2.1.cmml" xref="S2.SS2.p3.12.m12.1.1.3.2.3">subscript</csymbol><ci id="S2.SS2.p3.12.m12.1.1.3.2.3.2.2.cmml" xref="S2.SS2.p3.12.m12.1.1.3.2.3.2.2">ğ‘¤</ci><apply id="S2.SS2.p3.12.m12.1.1.3.2.3.2.3.cmml" xref="S2.SS2.p3.12.m12.1.1.3.2.3.2.3"><plus id="S2.SS2.p3.12.m12.1.1.3.2.3.2.3.1.cmml" xref="S2.SS2.p3.12.m12.1.1.3.2.3.2.3.1"></plus><ci id="S2.SS2.p3.12.m12.1.1.3.2.3.2.3.2.cmml" xref="S2.SS2.p3.12.m12.1.1.3.2.3.2.3.2">ğ‘ </ci><cn type="integer" id="S2.SS2.p3.12.m12.1.1.3.2.3.2.3.3.cmml" xref="S2.SS2.p3.12.m12.1.1.3.2.3.2.3.3">1</cn></apply></apply><ci id="S2.SS2.p3.12.m12.1.1.3.2.3.3.cmml" xref="S2.SS2.p3.12.m12.1.1.3.2.3.3">ğ‘š</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.12.m12.1c">w_{s+1}\leftarrow\sum_{m=1}^{M}\frac{n_{m}}{n}w_{s+1}^{m}</annotation></semantics></math>, where <math id="S2.SS2.p3.13.m13.1" class="ltx_Math" alttext="w_{s+1}^{m}\leftarrow w_{s}-\eta g^{m}_{s}" display="inline"><semantics id="S2.SS2.p3.13.m13.1a"><mrow id="S2.SS2.p3.13.m13.1.1" xref="S2.SS2.p3.13.m13.1.1.cmml"><msubsup id="S2.SS2.p3.13.m13.1.1.2" xref="S2.SS2.p3.13.m13.1.1.2.cmml"><mi id="S2.SS2.p3.13.m13.1.1.2.2.2" xref="S2.SS2.p3.13.m13.1.1.2.2.2.cmml">w</mi><mrow id="S2.SS2.p3.13.m13.1.1.2.2.3" xref="S2.SS2.p3.13.m13.1.1.2.2.3.cmml"><mi id="S2.SS2.p3.13.m13.1.1.2.2.3.2" xref="S2.SS2.p3.13.m13.1.1.2.2.3.2.cmml">s</mi><mo id="S2.SS2.p3.13.m13.1.1.2.2.3.1" xref="S2.SS2.p3.13.m13.1.1.2.2.3.1.cmml">+</mo><mn id="S2.SS2.p3.13.m13.1.1.2.2.3.3" xref="S2.SS2.p3.13.m13.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S2.SS2.p3.13.m13.1.1.2.3" xref="S2.SS2.p3.13.m13.1.1.2.3.cmml">m</mi></msubsup><mo stretchy="false" id="S2.SS2.p3.13.m13.1.1.1" xref="S2.SS2.p3.13.m13.1.1.1.cmml">â†</mo><mrow id="S2.SS2.p3.13.m13.1.1.3" xref="S2.SS2.p3.13.m13.1.1.3.cmml"><msub id="S2.SS2.p3.13.m13.1.1.3.2" xref="S2.SS2.p3.13.m13.1.1.3.2.cmml"><mi id="S2.SS2.p3.13.m13.1.1.3.2.2" xref="S2.SS2.p3.13.m13.1.1.3.2.2.cmml">w</mi><mi id="S2.SS2.p3.13.m13.1.1.3.2.3" xref="S2.SS2.p3.13.m13.1.1.3.2.3.cmml">s</mi></msub><mo id="S2.SS2.p3.13.m13.1.1.3.1" xref="S2.SS2.p3.13.m13.1.1.3.1.cmml">âˆ’</mo><mrow id="S2.SS2.p3.13.m13.1.1.3.3" xref="S2.SS2.p3.13.m13.1.1.3.3.cmml"><mi id="S2.SS2.p3.13.m13.1.1.3.3.2" xref="S2.SS2.p3.13.m13.1.1.3.3.2.cmml">Î·</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p3.13.m13.1.1.3.3.1" xref="S2.SS2.p3.13.m13.1.1.3.3.1.cmml">â€‹</mo><msubsup id="S2.SS2.p3.13.m13.1.1.3.3.3" xref="S2.SS2.p3.13.m13.1.1.3.3.3.cmml"><mi id="S2.SS2.p3.13.m13.1.1.3.3.3.2.2" xref="S2.SS2.p3.13.m13.1.1.3.3.3.2.2.cmml">g</mi><mi id="S2.SS2.p3.13.m13.1.1.3.3.3.3" xref="S2.SS2.p3.13.m13.1.1.3.3.3.3.cmml">s</mi><mi id="S2.SS2.p3.13.m13.1.1.3.3.3.2.3" xref="S2.SS2.p3.13.m13.1.1.3.3.3.2.3.cmml">m</mi></msubsup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.13.m13.1b"><apply id="S2.SS2.p3.13.m13.1.1.cmml" xref="S2.SS2.p3.13.m13.1.1"><ci id="S2.SS2.p3.13.m13.1.1.1.cmml" xref="S2.SS2.p3.13.m13.1.1.1">â†</ci><apply id="S2.SS2.p3.13.m13.1.1.2.cmml" xref="S2.SS2.p3.13.m13.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.p3.13.m13.1.1.2.1.cmml" xref="S2.SS2.p3.13.m13.1.1.2">superscript</csymbol><apply id="S2.SS2.p3.13.m13.1.1.2.2.cmml" xref="S2.SS2.p3.13.m13.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.p3.13.m13.1.1.2.2.1.cmml" xref="S2.SS2.p3.13.m13.1.1.2">subscript</csymbol><ci id="S2.SS2.p3.13.m13.1.1.2.2.2.cmml" xref="S2.SS2.p3.13.m13.1.1.2.2.2">ğ‘¤</ci><apply id="S2.SS2.p3.13.m13.1.1.2.2.3.cmml" xref="S2.SS2.p3.13.m13.1.1.2.2.3"><plus id="S2.SS2.p3.13.m13.1.1.2.2.3.1.cmml" xref="S2.SS2.p3.13.m13.1.1.2.2.3.1"></plus><ci id="S2.SS2.p3.13.m13.1.1.2.2.3.2.cmml" xref="S2.SS2.p3.13.m13.1.1.2.2.3.2">ğ‘ </ci><cn type="integer" id="S2.SS2.p3.13.m13.1.1.2.2.3.3.cmml" xref="S2.SS2.p3.13.m13.1.1.2.2.3.3">1</cn></apply></apply><ci id="S2.SS2.p3.13.m13.1.1.2.3.cmml" xref="S2.SS2.p3.13.m13.1.1.2.3">ğ‘š</ci></apply><apply id="S2.SS2.p3.13.m13.1.1.3.cmml" xref="S2.SS2.p3.13.m13.1.1.3"><minus id="S2.SS2.p3.13.m13.1.1.3.1.cmml" xref="S2.SS2.p3.13.m13.1.1.3.1"></minus><apply id="S2.SS2.p3.13.m13.1.1.3.2.cmml" xref="S2.SS2.p3.13.m13.1.1.3.2"><csymbol cd="ambiguous" id="S2.SS2.p3.13.m13.1.1.3.2.1.cmml" xref="S2.SS2.p3.13.m13.1.1.3.2">subscript</csymbol><ci id="S2.SS2.p3.13.m13.1.1.3.2.2.cmml" xref="S2.SS2.p3.13.m13.1.1.3.2.2">ğ‘¤</ci><ci id="S2.SS2.p3.13.m13.1.1.3.2.3.cmml" xref="S2.SS2.p3.13.m13.1.1.3.2.3">ğ‘ </ci></apply><apply id="S2.SS2.p3.13.m13.1.1.3.3.cmml" xref="S2.SS2.p3.13.m13.1.1.3.3"><times id="S2.SS2.p3.13.m13.1.1.3.3.1.cmml" xref="S2.SS2.p3.13.m13.1.1.3.3.1"></times><ci id="S2.SS2.p3.13.m13.1.1.3.3.2.cmml" xref="S2.SS2.p3.13.m13.1.1.3.3.2">ğœ‚</ci><apply id="S2.SS2.p3.13.m13.1.1.3.3.3.cmml" xref="S2.SS2.p3.13.m13.1.1.3.3.3"><csymbol cd="ambiguous" id="S2.SS2.p3.13.m13.1.1.3.3.3.1.cmml" xref="S2.SS2.p3.13.m13.1.1.3.3.3">subscript</csymbol><apply id="S2.SS2.p3.13.m13.1.1.3.3.3.2.cmml" xref="S2.SS2.p3.13.m13.1.1.3.3.3"><csymbol cd="ambiguous" id="S2.SS2.p3.13.m13.1.1.3.3.3.2.1.cmml" xref="S2.SS2.p3.13.m13.1.1.3.3.3">superscript</csymbol><ci id="S2.SS2.p3.13.m13.1.1.3.3.3.2.2.cmml" xref="S2.SS2.p3.13.m13.1.1.3.3.3.2.2">ğ‘”</ci><ci id="S2.SS2.p3.13.m13.1.1.3.3.3.2.3.cmml" xref="S2.SS2.p3.13.m13.1.1.3.3.3.2.3">ğ‘š</ci></apply><ci id="S2.SS2.p3.13.m13.1.1.3.3.3.3.cmml" xref="S2.SS2.p3.13.m13.1.1.3.3.3.3">ğ‘ </ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.13.m13.1c">w_{s+1}^{m}\leftarrow w_{s}-\eta g^{m}_{s}</annotation></semantics></math>, <math id="S2.SS2.p3.14.m14.1" class="ltx_Math" alttext="\forall m" display="inline"><semantics id="S2.SS2.p3.14.m14.1a"><mrow id="S2.SS2.p3.14.m14.1.1" xref="S2.SS2.p3.14.m14.1.1.cmml"><mo rspace="0.167em" id="S2.SS2.p3.14.m14.1.1.1" xref="S2.SS2.p3.14.m14.1.1.1.cmml">âˆ€</mo><mi id="S2.SS2.p3.14.m14.1.1.2" xref="S2.SS2.p3.14.m14.1.1.2.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.14.m14.1b"><apply id="S2.SS2.p3.14.m14.1.1.cmml" xref="S2.SS2.p3.14.m14.1.1"><csymbol cd="latexml" id="S2.SS2.p3.14.m14.1.1.1.cmml" xref="S2.SS2.p3.14.m14.1.1.1">for-all</csymbol><ci id="S2.SS2.p3.14.m14.1.1.2.cmml" xref="S2.SS2.p3.14.m14.1.1.2">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.14.m14.1c">\forall m</annotation></semantics></math>. Finally, every client takes a complete gradient descent step, while the server only takes the weighted average of the resulting models.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Overview of proposal model</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.4" class="ltx_p">As described above, federated learning is used in both steps of our proposed FedCPC-based model. For the FedPCPC pre-training model proposed in step 1, <math id="S2.SS3.p1.1.m1.1" class="ltx_Math" alttext="w_{s}" display="inline"><semantics id="S2.SS3.p1.1.m1.1a"><msub id="S2.SS3.p1.1.m1.1.1" xref="S2.SS3.p1.1.m1.1.1.cmml"><mi id="S2.SS3.p1.1.m1.1.1.2" xref="S2.SS3.p1.1.m1.1.1.2.cmml">w</mi><mi id="S2.SS3.p1.1.m1.1.1.3" xref="S2.SS3.p1.1.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.1.m1.1b"><apply id="S2.SS3.p1.1.m1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.1.m1.1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SS3.p1.1.m1.1.1.2.cmml" xref="S2.SS3.p1.1.m1.1.1.2">ğ‘¤</ci><ci id="S2.SS3.p1.1.m1.1.1.3.cmml" xref="S2.SS3.p1.1.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.1.m1.1c">w_{s}</annotation></semantics></math> contains all the parameters of the FedPCPC pre-training model in the <math id="S2.SS3.p1.2.m2.1" class="ltx_Math" alttext="s_{th}" display="inline"><semantics id="S2.SS3.p1.2.m2.1a"><msub id="S2.SS3.p1.2.m2.1.1" xref="S2.SS3.p1.2.m2.1.1.cmml"><mi id="S2.SS3.p1.2.m2.1.1.2" xref="S2.SS3.p1.2.m2.1.1.2.cmml">s</mi><mrow id="S2.SS3.p1.2.m2.1.1.3" xref="S2.SS3.p1.2.m2.1.1.3.cmml"><mi id="S2.SS3.p1.2.m2.1.1.3.2" xref="S2.SS3.p1.2.m2.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p1.2.m2.1.1.3.1" xref="S2.SS3.p1.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S2.SS3.p1.2.m2.1.1.3.3" xref="S2.SS3.p1.2.m2.1.1.3.3.cmml">h</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.2.m2.1b"><apply id="S2.SS3.p1.2.m2.1.1.cmml" xref="S2.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.2.m2.1.1.1.cmml" xref="S2.SS3.p1.2.m2.1.1">subscript</csymbol><ci id="S2.SS3.p1.2.m2.1.1.2.cmml" xref="S2.SS3.p1.2.m2.1.1.2">ğ‘ </ci><apply id="S2.SS3.p1.2.m2.1.1.3.cmml" xref="S2.SS3.p1.2.m2.1.1.3"><times id="S2.SS3.p1.2.m2.1.1.3.1.cmml" xref="S2.SS3.p1.2.m2.1.1.3.1"></times><ci id="S2.SS3.p1.2.m2.1.1.3.2.cmml" xref="S2.SS3.p1.2.m2.1.1.3.2">ğ‘¡</ci><ci id="S2.SS3.p1.2.m2.1.1.3.3.cmml" xref="S2.SS3.p1.2.m2.1.1.3.3">â„</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.2.m2.1c">s_{th}</annotation></semantics></math> federated round. These parameters are shared through federated learning, which enables different clients to learn speech representation. For the downstream part of the FedCPC-based model of step 2, <math id="S2.SS3.p1.3.m3.1" class="ltx_Math" alttext="w_{s}" display="inline"><semantics id="S2.SS3.p1.3.m3.1a"><msub id="S2.SS3.p1.3.m3.1.1" xref="S2.SS3.p1.3.m3.1.1.cmml"><mi id="S2.SS3.p1.3.m3.1.1.2" xref="S2.SS3.p1.3.m3.1.1.2.cmml">w</mi><mi id="S2.SS3.p1.3.m3.1.1.3" xref="S2.SS3.p1.3.m3.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.3.m3.1b"><apply id="S2.SS3.p1.3.m3.1.1.cmml" xref="S2.SS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.3.m3.1.1.1.cmml" xref="S2.SS3.p1.3.m3.1.1">subscript</csymbol><ci id="S2.SS3.p1.3.m3.1.1.2.cmml" xref="S2.SS3.p1.3.m3.1.1.2">ğ‘¤</ci><ci id="S2.SS3.p1.3.m3.1.1.3.cmml" xref="S2.SS3.p1.3.m3.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.3.m3.1c">w_{s}</annotation></semantics></math> contains the CPC pre-training modelâ€™s encoder part and the downstream modelâ€™s parameters in <math id="S2.SS3.p1.4.m4.1" class="ltx_Math" alttext="s_{th}" display="inline"><semantics id="S2.SS3.p1.4.m4.1a"><msub id="S2.SS3.p1.4.m4.1.1" xref="S2.SS3.p1.4.m4.1.1.cmml"><mi id="S2.SS3.p1.4.m4.1.1.2" xref="S2.SS3.p1.4.m4.1.1.2.cmml">s</mi><mrow id="S2.SS3.p1.4.m4.1.1.3" xref="S2.SS3.p1.4.m4.1.1.3.cmml"><mi id="S2.SS3.p1.4.m4.1.1.3.2" xref="S2.SS3.p1.4.m4.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p1.4.m4.1.1.3.1" xref="S2.SS3.p1.4.m4.1.1.3.1.cmml">â€‹</mo><mi id="S2.SS3.p1.4.m4.1.1.3.3" xref="S2.SS3.p1.4.m4.1.1.3.3.cmml">h</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.4.m4.1b"><apply id="S2.SS3.p1.4.m4.1.1.cmml" xref="S2.SS3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.4.m4.1.1.1.cmml" xref="S2.SS3.p1.4.m4.1.1">subscript</csymbol><ci id="S2.SS3.p1.4.m4.1.1.2.cmml" xref="S2.SS3.p1.4.m4.1.1.2">ğ‘ </ci><apply id="S2.SS3.p1.4.m4.1.1.3.cmml" xref="S2.SS3.p1.4.m4.1.1.3"><times id="S2.SS3.p1.4.m4.1.1.3.1.cmml" xref="S2.SS3.p1.4.m4.1.1.3.1"></times><ci id="S2.SS3.p1.4.m4.1.1.3.2.cmml" xref="S2.SS3.p1.4.m4.1.1.3.2">ğ‘¡</ci><ci id="S2.SS3.p1.4.m4.1.1.3.3.cmml" xref="S2.SS3.p1.4.m4.1.1.3.3">â„</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.4.m4.1c">s_{th}</annotation></semantics></math> federated round.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experiments</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Data Description</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">The 2021 NCMMSC AD Recognition Challenge provides the dataset. Since we joined the short speech track, we segmented all the long sentences from the data provided by the organizers into short speech clips of 6 seconds. As shown in TableÂ <a href="#S3.T1" title="Table 1 â€£ 3.2.1 Baseline â€£ 3.2 System Implementation â€£ 3 Experiments â€£ FedCPC: an Effective Federated Contrastive Learning Method for Privacy Preserving Early-Stage Alzheimerâ€™s Speech Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we selected a 7.16-hour speech set from 39 male speakers and 54 female speakers as the training set (Training) and a 0.67-hour speech set from 15 male and 15 female speakers as the development set (Development). The test set is the official short speech track test set with a 1.92-hour speech set (Testing). All the sentences have labels in three kinds: Alzheimerâ€™s disease (AD), mild cognitive impairment (MCI), and health common (HC).</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>System Implementation</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">We construct the following models both with conventional centralized training and federated learning, and their implementations are described as follows:</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Baseline</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<ol id="S3.I1" class="ltx_enumerate">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">A 20-dimensional Mel frequency cepstral coefficients (MFCC) vector extracted with a 25ms window and 10ms frameshift is employed as the input feature of each frame. The CNN (convolutional neural network)-based system<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Available at https://github.com/THUsatlab/AD2021</span></span></span> has 259 <math id="S3.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.I1.i1.p1.1.m1.1a"><mo id="S3.I1.i1.p1.1.m1.1.1" xref="S3.I1.i1.p1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.1.m1.1b"><times id="S3.I1.i1.p1.1.m1.1.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.1.m1.1c">\times</annotation></semantics></math> 20 nodes as the input layer, three nodes as output, and five convolutional layers with one max-pooling layer following every layer. The convolutional filters of each layer are sequentially arranged as 32, 32, 32, 64, and 128. Finally, the last two layers are fully connected (FC) with 256 nodes before softmax output.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">CNN is mainly for learning local features. To consider contextual dependencies from local features, we construct a CNN-LSTM-based model. Two LSTM layers are put on top of the CNN-based model, and this model also has two FC layers before softmax output. The network configuration of the CNN and FC layers is the same as the CNN-based system.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p">Moreover, to compare with other pre-trained models, we adopt AST<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Available athttps://github.com/YuanGongND/ast</span></span></span> model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. It is transformer-based
model for audio classification with a larger database with a simple architecture and superior performance. For this reason, we use the AST model to compare with our CPC-base model.</p>
</div>
</li>
</ol>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.18.1.1" class="ltx_text ltx_font_bold">Table 1</span>: </span>Data Descriptions</figcaption>
<div id="S3.T1.16" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:268.9pt;height:90pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table id="S3.T1.16.16" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T1.16.16.17.1" class="ltx_tr">
<th id="S3.T1.16.16.17.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t"></th>
<td id="S3.T1.16.16.17.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.16.16.17.1.2.1" class="ltx_text ltx_font_bold">#speakers</span></td>
<td id="S3.T1.16.16.17.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.16.16.17.1.3.1" class="ltx_text ltx_font_bold">#utterance</span></td>
<td id="S3.T1.16.16.17.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.16.16.17.1.4.1" class="ltx_text ltx_font_bold">#hour</span></td>
</tr>
<tr id="S3.T1.16.16.18.2" class="ltx_tr">
<th id="S3.T1.16.16.18.2.1" class="ltx_td ltx_th ltx_th_row ltx_border_r"></th>
<td id="S3.T1.16.16.18.2.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T1.16.16.18.2.2.1" class="ltx_text ltx_font_bold">(Male/Female)</span></td>
<td id="S3.T1.16.16.18.2.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T1.16.16.18.2.3.1" class="ltx_text ltx_font_bold">(HC/MCI/AD)</span></td>
<td id="S3.T1.16.16.18.2.4" class="ltx_td"></td>
</tr>
<tr id="S3.T1.6.6.6" class="ltx_tr">
<th id="S3.T1.6.6.6.7" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Training</th>
<td id="S3.T1.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<math id="S3.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="39" display="inline"><semantics id="S3.T1.1.1.1.1.m1.1a"><mn id="S3.T1.1.1.1.1.m1.1.1" xref="S3.T1.1.1.1.1.m1.1.1.cmml">39</mn><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.1.m1.1b"><cn type="integer" id="S3.T1.1.1.1.1.m1.1.1.cmml" xref="S3.T1.1.1.1.1.m1.1.1">39</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.1.m1.1c">39</annotation></semantics></math> / <math id="S3.T1.2.2.2.2.m2.1" class="ltx_Math" alttext="54" display="inline"><semantics id="S3.T1.2.2.2.2.m2.1a"><mn id="S3.T1.2.2.2.2.m2.1.1" xref="S3.T1.2.2.2.2.m2.1.1.cmml">54</mn><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.2.2.m2.1b"><cn type="integer" id="S3.T1.2.2.2.2.m2.1.1.cmml" xref="S3.T1.2.2.2.2.m2.1.1">54</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.2.2.m2.1c">54</annotation></semantics></math>
</td>
<td id="S3.T1.5.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<math id="S3.T1.3.3.3.3.m1.1" class="ltx_Math" alttext="1712" display="inline"><semantics id="S3.T1.3.3.3.3.m1.1a"><mn id="S3.T1.3.3.3.3.m1.1.1" xref="S3.T1.3.3.3.3.m1.1.1.cmml">1712</mn><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.3.3.m1.1b"><cn type="integer" id="S3.T1.3.3.3.3.m1.1.1.cmml" xref="S3.T1.3.3.3.3.m1.1.1">1712</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.3.3.m1.1c">1712</annotation></semantics></math> / <math id="S3.T1.4.4.4.4.m2.1" class="ltx_Math" alttext="1380" display="inline"><semantics id="S3.T1.4.4.4.4.m2.1a"><mn id="S3.T1.4.4.4.4.m2.1.1" xref="S3.T1.4.4.4.4.m2.1.1.cmml">1380</mn><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.4.4.m2.1b"><cn type="integer" id="S3.T1.4.4.4.4.m2.1.1.cmml" xref="S3.T1.4.4.4.4.m2.1.1">1380</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.4.4.m2.1c">1380</annotation></semantics></math> / <math id="S3.T1.5.5.5.5.m3.1" class="ltx_Math" alttext="1208" display="inline"><semantics id="S3.T1.5.5.5.5.m3.1a"><mn id="S3.T1.5.5.5.5.m3.1.1" xref="S3.T1.5.5.5.5.m3.1.1.cmml">1208</mn><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.5.5.m3.1b"><cn type="integer" id="S3.T1.5.5.5.5.m3.1.1.cmml" xref="S3.T1.5.5.5.5.m3.1.1">1208</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.5.5.m3.1c">1208</annotation></semantics></math>
</td>
<td id="S3.T1.6.6.6.6" class="ltx_td ltx_align_center ltx_border_t"><math id="S3.T1.6.6.6.6.m1.1" class="ltx_Math" alttext="7.16" display="inline"><semantics id="S3.T1.6.6.6.6.m1.1a"><mn id="S3.T1.6.6.6.6.m1.1.1" xref="S3.T1.6.6.6.6.m1.1.1.cmml">7.16</mn><annotation-xml encoding="MathML-Content" id="S3.T1.6.6.6.6.m1.1b"><cn type="float" id="S3.T1.6.6.6.6.m1.1.1.cmml" xref="S3.T1.6.6.6.6.m1.1.1">7.16</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.6.6.6.m1.1c">7.16</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.12.12.12" class="ltx_tr">
<th id="S3.T1.12.12.12.7" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Develop.</th>
<td id="S3.T1.8.8.8.2" class="ltx_td ltx_align_center ltx_border_r">
<math id="S3.T1.7.7.7.1.m1.1" class="ltx_Math" alttext="15" display="inline"><semantics id="S3.T1.7.7.7.1.m1.1a"><mn id="S3.T1.7.7.7.1.m1.1.1" xref="S3.T1.7.7.7.1.m1.1.1.cmml">15</mn><annotation-xml encoding="MathML-Content" id="S3.T1.7.7.7.1.m1.1b"><cn type="integer" id="S3.T1.7.7.7.1.m1.1.1.cmml" xref="S3.T1.7.7.7.1.m1.1.1">15</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.7.7.7.1.m1.1c">15</annotation></semantics></math> / <math id="S3.T1.8.8.8.2.m2.1" class="ltx_Math" alttext="15" display="inline"><semantics id="S3.T1.8.8.8.2.m2.1a"><mn id="S3.T1.8.8.8.2.m2.1.1" xref="S3.T1.8.8.8.2.m2.1.1.cmml">15</mn><annotation-xml encoding="MathML-Content" id="S3.T1.8.8.8.2.m2.1b"><cn type="integer" id="S3.T1.8.8.8.2.m2.1.1.cmml" xref="S3.T1.8.8.8.2.m2.1.1">15</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.8.8.8.2.m2.1c">15</annotation></semantics></math>
</td>
<td id="S3.T1.11.11.11.5" class="ltx_td ltx_align_center ltx_border_r">
<math id="S3.T1.9.9.9.3.m1.1" class="ltx_Math" alttext="114" display="inline"><semantics id="S3.T1.9.9.9.3.m1.1a"><mn id="S3.T1.9.9.9.3.m1.1.1" xref="S3.T1.9.9.9.3.m1.1.1.cmml">114</mn><annotation-xml encoding="MathML-Content" id="S3.T1.9.9.9.3.m1.1b"><cn type="integer" id="S3.T1.9.9.9.3.m1.1.1.cmml" xref="S3.T1.9.9.9.3.m1.1.1">114</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.9.9.9.3.m1.1c">114</annotation></semantics></math> / <math id="S3.T1.10.10.10.4.m2.1" class="ltx_Math" alttext="145" display="inline"><semantics id="S3.T1.10.10.10.4.m2.1a"><mn id="S3.T1.10.10.10.4.m2.1.1" xref="S3.T1.10.10.10.4.m2.1.1.cmml">145</mn><annotation-xml encoding="MathML-Content" id="S3.T1.10.10.10.4.m2.1b"><cn type="integer" id="S3.T1.10.10.10.4.m2.1.1.cmml" xref="S3.T1.10.10.10.4.m2.1.1">145</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.10.10.10.4.m2.1c">145</annotation></semantics></math> / <math id="S3.T1.11.11.11.5.m3.1" class="ltx_Math" alttext="138" display="inline"><semantics id="S3.T1.11.11.11.5.m3.1a"><mn id="S3.T1.11.11.11.5.m3.1.1" xref="S3.T1.11.11.11.5.m3.1.1.cmml">138</mn><annotation-xml encoding="MathML-Content" id="S3.T1.11.11.11.5.m3.1b"><cn type="integer" id="S3.T1.11.11.11.5.m3.1.1.cmml" xref="S3.T1.11.11.11.5.m3.1.1">138</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.11.11.11.5.m3.1c">138</annotation></semantics></math>
</td>
<td id="S3.T1.12.12.12.6" class="ltx_td ltx_align_center"><math id="S3.T1.12.12.12.6.m1.1" class="ltx_Math" alttext="0.67" display="inline"><semantics id="S3.T1.12.12.12.6.m1.1a"><mn id="S3.T1.12.12.12.6.m1.1.1" xref="S3.T1.12.12.12.6.m1.1.1.cmml">0.67</mn><annotation-xml encoding="MathML-Content" id="S3.T1.12.12.12.6.m1.1b"><cn type="float" id="S3.T1.12.12.12.6.m1.1.1.cmml" xref="S3.T1.12.12.12.6.m1.1.1">0.67</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.12.12.12.6.m1.1c">0.67</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.16.16.16" class="ltx_tr">
<th id="S3.T1.16.16.16.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r">Testing</th>
<td id="S3.T1.16.16.16.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">/</td>
<td id="S3.T1.15.15.15.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">
<math id="S3.T1.13.13.13.1.m1.1" class="ltx_Math" alttext="432" display="inline"><semantics id="S3.T1.13.13.13.1.m1.1a"><mn id="S3.T1.13.13.13.1.m1.1.1" xref="S3.T1.13.13.13.1.m1.1.1.cmml">432</mn><annotation-xml encoding="MathML-Content" id="S3.T1.13.13.13.1.m1.1b"><cn type="integer" id="S3.T1.13.13.13.1.m1.1.1.cmml" xref="S3.T1.13.13.13.1.m1.1.1">432</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.13.13.13.1.m1.1c">432</annotation></semantics></math> / <math id="S3.T1.14.14.14.2.m2.1" class="ltx_Math" alttext="378" display="inline"><semantics id="S3.T1.14.14.14.2.m2.1a"><mn id="S3.T1.14.14.14.2.m2.1.1" xref="S3.T1.14.14.14.2.m2.1.1.cmml">378</mn><annotation-xml encoding="MathML-Content" id="S3.T1.14.14.14.2.m2.1b"><cn type="integer" id="S3.T1.14.14.14.2.m2.1.1.cmml" xref="S3.T1.14.14.14.2.m2.1.1">378</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.14.14.14.2.m2.1c">378</annotation></semantics></math> / <math id="S3.T1.15.15.15.3.m3.1" class="ltx_Math" alttext="343" display="inline"><semantics id="S3.T1.15.15.15.3.m3.1a"><mn id="S3.T1.15.15.15.3.m3.1.1" xref="S3.T1.15.15.15.3.m3.1.1.cmml">343</mn><annotation-xml encoding="MathML-Content" id="S3.T1.15.15.15.3.m3.1b"><cn type="integer" id="S3.T1.15.15.15.3.m3.1.1.cmml" xref="S3.T1.15.15.15.3.m3.1.1">343</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.15.15.15.3.m3.1c">343</annotation></semantics></math>
</td>
<td id="S3.T1.16.16.16.4" class="ltx_td ltx_align_center ltx_border_b"><math id="S3.T1.16.16.16.4.m1.1" class="ltx_Math" alttext="1.92" display="inline"><semantics id="S3.T1.16.16.16.4.m1.1a"><mn id="S3.T1.16.16.16.4.m1.1.1" xref="S3.T1.16.16.16.4.m1.1.1.cmml">1.92</mn><annotation-xml encoding="MathML-Content" id="S3.T1.16.16.16.4.m1.1b"><cn type="float" id="S3.T1.16.16.16.4.m1.1.1.cmml" xref="S3.T1.16.16.16.4.m1.1.1">1.92</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.16.16.16.4.m1.1c">1.92</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T2.2.1.1" class="ltx_text ltx_font_bold">Table 2</span>: </span>Major Experimental Settings</figcaption>
<table id="S3.T2.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T2.3.1.1" class="ltx_tr">
<td id="S3.T2.3.1.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T2.3.1.1.1.1" class="ltx_text ltx_font_bold">Training settings</span></td>
<td id="S3.T2.3.1.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">GPUs (3090)</td>
<td id="S3.T2.3.1.1.3" class="ltx_td ltx_align_left ltx_border_t">1</td>
</tr>
<tr id="S3.T2.3.2.2" class="ltx_tr">
<td id="S3.T2.3.2.2.1" class="ltx_td ltx_border_r"></td>
<td id="S3.T2.3.2.2.2" class="ltx_td ltx_align_left ltx_border_r">Batch-size</td>
<td id="S3.T2.3.2.2.3" class="ltx_td ltx_align_left">128</td>
</tr>
<tr id="S3.T2.3.3.3" class="ltx_tr">
<td id="S3.T2.3.3.3.1" class="ltx_td ltx_border_r"></td>
<td id="S3.T2.3.3.3.2" class="ltx_td ltx_align_left ltx_border_r">Epochs</td>
<td id="S3.T2.3.3.3.3" class="ltx_td ltx_align_left">100</td>
</tr>
<tr id="S3.T2.3.4.4" class="ltx_tr">
<td id="S3.T2.3.4.4.1" class="ltx_td ltx_border_r"></td>
<td id="S3.T2.3.4.4.2" class="ltx_td ltx_align_left ltx_border_r">Steps</td>
<td id="S3.T2.3.4.4.3" class="ltx_td ltx_align_left">34</td>
</tr>
<tr id="S3.T2.3.5.5" class="ltx_tr">
<td id="S3.T2.3.5.5.1" class="ltx_td ltx_border_r"></td>
<td id="S3.T2.3.5.5.2" class="ltx_td ltx_align_left ltx_border_r">Optimizer</td>
<td id="S3.T2.3.5.5.3" class="ltx_td ltx_align_left">Adam</td>
</tr>
<tr id="S3.T2.3.6.6" class="ltx_tr">
<td id="S3.T2.3.6.6.1" class="ltx_td ltx_border_r"></td>
<td id="S3.T2.3.6.6.2" class="ltx_td ltx_align_left ltx_border_r">Valid</td>
<td id="S3.T2.3.6.6.3" class="ltx_td ltx_align_left">Dev. Set</td>
</tr>
<tr id="S3.T2.3.7.7" class="ltx_tr">
<td id="S3.T2.3.7.7.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T2.3.7.7.1.1" class="ltx_text ltx_font_bold">Federated settings</span></td>
<td id="S3.T2.3.7.7.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Federated round</td>
<td id="S3.T2.3.7.7.3" class="ltx_td ltx_align_left ltx_border_t">50</td>
</tr>
<tr id="S3.T2.3.8.8" class="ltx_tr">
<td id="S3.T2.3.8.8.1" class="ltx_td ltx_border_r"></td>
<td id="S3.T2.3.8.8.2" class="ltx_td ltx_align_left ltx_border_r">Local epochs</td>
<td id="S3.T2.3.8.8.3" class="ltx_td ltx_align_left">4</td>
</tr>
<tr id="S3.T2.3.9.9" class="ltx_tr">
<td id="S3.T2.3.9.9.1" class="ltx_td ltx_border_r"></td>
<td id="S3.T2.3.9.9.2" class="ltx_td ltx_align_left ltx_border_r">Weighting Strategies</td>
<td id="S3.T2.3.9.9.3" class="ltx_td ltx_align_left">FedAvg</td>
</tr>
<tr id="S3.T2.3.10.10" class="ltx_tr">
<td id="S3.T2.3.10.10.1" class="ltx_td ltx_border_b ltx_border_r"></td>
<td id="S3.T2.3.10.10.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">#Clients</td>
<td id="S3.T2.3.10.10.3" class="ltx_td ltx_align_left ltx_border_b">3</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Self-Supervised Model</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p"><span id="S3.SS2.SSS2.p1.1.1" class="ltx_text ltx_font_bold">Pre-training model setup:</span> The implementation of CPC pre-training model is similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. Each training iteration randomly extracts a segment of about 20,480 frames from every utterance as the encoderâ€™s input. The encoder comprises five 1-dimensional CNN layers and a single-layer gated recurrent unit (GRU). In detail, each of the five layers has the same down-sampling rate of 1/160 to get the same frame rate and the same settings of the filter size, strides, and paddings ([10, 8, 4, 4, 4], [5, 4, 2, 2, 2] and [3, 2, 1, 1, 1]). All five layers have 512 hidden units. Moreover, the GRU layer is employed as the sequence model with 256 hidden units. Every frame of GRU output is used to predict the context <math id="S3.SS2.SSS2.p1.1.m1.1" class="ltx_Math" alttext="\mathbf{c}" display="inline"><semantics id="S3.SS2.SSS2.p1.1.m1.1a"><mi id="S3.SS2.SSS2.p1.1.m1.1.1" xref="S3.SS2.SSS2.p1.1.m1.1.1.cmml">ğœ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.1.m1.1b"><ci id="S3.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.1.m1.1c">\mathbf{c}</annotation></semantics></math> (12 future frames). Adam optimizer trains the model with a learning rate of 2e-4 and a minibatch size 8.</p>
</div>
<div id="S3.SS2.SSS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS2.p2.1" class="ltx_p"><span id="S3.SS2.SSS2.p2.1.1" class="ltx_text ltx_font_bold">Backbone classifier network:</span> As AST is a pre-trained model used to compare our proposed method, we only constructed CNN and CNN-LSTM models as downstream models in this work. The training parameters are the same as the baseline and the scheme above.</p>
</div>
<div id="S3.SS2.SSS2.p3" class="ltx_para">
<p id="S3.SS2.SSS2.p3.1" class="ltx_p">We used the open-sourced federated learning framework Flower <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> and PyTorch version-1.9.1<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>https://pytorch.org/</span></span></span> for all our experiments. Table <a href="#S3.T2" title="Table 2 â€£ 3.2.1 Baseline â€£ 3.2 System Implementation â€£ 3 Experiments â€£ FedCPC: an Effective Federated Contrastive Learning Method for Privacy Preserving Early-Stage Alzheimerâ€™s Speech Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> lists the training and test settings. Moreover, speakers of each clientâ€™s data are unique to ensure the independence of speakers from different clients in federated learning.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Reuslts and Discussions </h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Main results </h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.6" class="ltx_p">Using the centralized learning scenario, we first investigate whether the CPC pre-training model can improve performance. Table <a href="#S4.T3" title="Table 3 â€£ 4.1 Main results â€£ 4 Reuslts and Discussions â€£ FedCPC: an Effective Federated Contrastive Learning Method for Privacy Preserving Early-Stage Alzheimerâ€™s Speech Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the experimental results of the test set of centralized learning. Compared with the CNN model, the CNN-LSTM model shows better performances in both machine learning paradigms, especially outperforming the CNN system on precision, recall, and F1-score by 3.8<math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mo id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><csymbol cd="latexml" id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">\%</annotation></semantics></math>, 4.2<math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><mo id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><csymbol cd="latexml" id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">\%</annotation></semantics></math>, and 5.0<math id="S4.SS1.p1.3.m3.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS1.p1.3.m3.1a"><mo id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><csymbol cd="latexml" id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">\%</annotation></semantics></math> in centralized learning. Meanwhile, using CPC pre-training models leads to better performance than MFCC features. As shown in Table <a href="#S4.T3" title="Table 3 â€£ 4.1 Main results â€£ 4 Reuslts and Discussions â€£ FedCPC: an Effective Federated Contrastive Learning Method for Privacy Preserving Early-Stage Alzheimerâ€™s Speech Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, the macro F1-score achieved 8.5<math id="S4.SS1.p1.4.m4.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS1.p1.4.m4.1a"><mo id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><csymbol cd="latexml" id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">\%</annotation></semantics></math>, 3.6<math id="S4.SS1.p1.5.m5.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS1.p1.5.m5.1a"><mo id="S4.SS1.p1.5.m5.1.1" xref="S4.SS1.p1.5.m5.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.5.m5.1b"><csymbol cd="latexml" id="S4.SS1.p1.5.m5.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.5.m5.1c">\%</annotation></semantics></math> improvements in centralized learning by comparing CNN and CNN-LSTM models, and CPC-CNN almost got the same F1-score with CPC-LSTM-CNN.
Moreover, the paper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> utilizes the Wav2vec speech recognition pre-training model to predict Alzheimerâ€™s Disease on the same databases. In contrast, our proposed method leverages the CPC pre-training model without federated learning, specifically the CPC-CNN-LSTM model, and achieves a superior result (F1: 78.8%) compared to the best result obtained by Wav2vec2.0_3-2 (F1: 77.2<math id="S4.SS1.p1.6.m6.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS1.p1.6.m6.1a"><mo id="S4.SS1.p1.6.m6.1.1" xref="S4.SS1.p1.6.m6.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.6.m6.1b"><csymbol cd="latexml" id="S4.SS1.p1.6.m6.1.1.cmml" xref="S4.SS1.p1.6.m6.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.6.m6.1c">\%</annotation></semantics></math>) in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> on short audio tracks. These findings provide evidence that the CPC pre-training model captures structural information embedded in raw audio signals, enhancing AD detection performance. Figure <a href="#S4.F2" title="Figure 2 â€£ 4.1 Main results â€£ 4 Reuslts and Discussions â€£ FedCPC: an Effective Federated Contrastive Learning Method for Privacy Preserving Early-Stage Alzheimerâ€™s Speech Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> illustrates the visualization of representations learned by the pre-training model, indicating specific properties that can be utilized for clustering in this task.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.22.1.1" class="ltx_text ltx_font_bold">Table 3</span>: </span>Evaluation with centralized learning.</figcaption>
<div id="S4.T3.18" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:323.5pt;height:126pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table id="S4.T3.18.18" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.18.18.19.1" class="ltx_tr">
<th id="S4.T3.18.18.19.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"></th>
<th id="S4.T3.18.18.19.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T3.18.18.19.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Precision(%)</span></th>
<th id="S4.T3.18.18.19.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T3.18.18.19.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Recall(%)</span></th>
<th id="S4.T3.18.18.19.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T3.18.18.19.1.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">F1(%)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.3.3.3" class="ltx_tr">
<th id="S4.T3.3.3.3.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T3.3.3.3.4.1" class="ltx_text" style="font-size:90%;">CNN</span></th>
<td id="S4.T3.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S4.T3.1.1.1.1.m1.1" class="ltx_Math" alttext="71.3" display="inline"><semantics id="S4.T3.1.1.1.1.m1.1a"><mn mathsize="90%" id="S4.T3.1.1.1.1.m1.1.1" xref="S4.T3.1.1.1.1.m1.1.1.cmml">71.3</mn><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.1.m1.1b"><cn type="float" id="S4.T3.1.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.1.m1.1.1">71.3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.1.m1.1c">71.3</annotation></semantics></math></td>
<td id="S4.T3.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S4.T3.2.2.2.2.m1.1" class="ltx_Math" alttext="71.1" display="inline"><semantics id="S4.T3.2.2.2.2.m1.1a"><mn mathsize="90%" id="S4.T3.2.2.2.2.m1.1.1" xref="S4.T3.2.2.2.2.m1.1.1.cmml">71.1</mn><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.2.m1.1b"><cn type="float" id="S4.T3.2.2.2.2.m1.1.1.cmml" xref="S4.T3.2.2.2.2.m1.1.1">71.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.2.m1.1c">71.1</annotation></semantics></math></td>
<td id="S4.T3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t"><math id="S4.T3.3.3.3.3.m1.1" class="ltx_Math" alttext="70.2" display="inline"><semantics id="S4.T3.3.3.3.3.m1.1a"><mn mathsize="90%" id="S4.T3.3.3.3.3.m1.1.1" xref="S4.T3.3.3.3.3.m1.1.1.cmml">70.2</mn><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.3.m1.1b"><cn type="float" id="S4.T3.3.3.3.3.m1.1.1.cmml" xref="S4.T3.3.3.3.3.m1.1.1">70.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.3.3.m1.1c">70.2</annotation></semantics></math></td>
</tr>
<tr id="S4.T3.6.6.6" class="ltx_tr">
<th id="S4.T3.6.6.6.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T3.6.6.6.4.1" class="ltx_text" style="font-size:90%;">CNN-LSTM</span></th>
<td id="S4.T3.4.4.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S4.T3.4.4.4.1.m1.1" class="ltx_Math" alttext="75.1" display="inline"><semantics id="S4.T3.4.4.4.1.m1.1a"><mn mathsize="90%" id="S4.T3.4.4.4.1.m1.1.1" xref="S4.T3.4.4.4.1.m1.1.1.cmml">75.1</mn><annotation-xml encoding="MathML-Content" id="S4.T3.4.4.4.1.m1.1b"><cn type="float" id="S4.T3.4.4.4.1.m1.1.1.cmml" xref="S4.T3.4.4.4.1.m1.1.1">75.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.4.4.1.m1.1c">75.1</annotation></semantics></math></td>
<td id="S4.T3.5.5.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S4.T3.5.5.5.2.m1.1" class="ltx_Math" alttext="75.3" display="inline"><semantics id="S4.T3.5.5.5.2.m1.1a"><mn mathsize="90%" id="S4.T3.5.5.5.2.m1.1.1" xref="S4.T3.5.5.5.2.m1.1.1.cmml">75.3</mn><annotation-xml encoding="MathML-Content" id="S4.T3.5.5.5.2.m1.1b"><cn type="float" id="S4.T3.5.5.5.2.m1.1.1.cmml" xref="S4.T3.5.5.5.2.m1.1.1">75.3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.5.5.2.m1.1c">75.3</annotation></semantics></math></td>
<td id="S4.T3.6.6.6.3" class="ltx_td ltx_align_center ltx_border_t"><math id="S4.T3.6.6.6.3.m1.1" class="ltx_Math" alttext="75.2" display="inline"><semantics id="S4.T3.6.6.6.3.m1.1a"><mn mathsize="90%" id="S4.T3.6.6.6.3.m1.1.1" xref="S4.T3.6.6.6.3.m1.1.1.cmml">75.2</mn><annotation-xml encoding="MathML-Content" id="S4.T3.6.6.6.3.m1.1b"><cn type="float" id="S4.T3.6.6.6.3.m1.1.1.cmml" xref="S4.T3.6.6.6.3.m1.1.1">75.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.6.6.3.m1.1c">75.2</annotation></semantics></math></td>
</tr>
<tr id="S4.T3.9.9.9" class="ltx_tr">
<th id="S4.T3.9.9.9.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T3.9.9.9.4.1" class="ltx_text" style="font-size:90%;">CPC-CNN</span></th>
<td id="S4.T3.7.7.7.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S4.T3.7.7.7.1.m1.1" class="ltx_Math" alttext="80.3" display="inline"><semantics id="S4.T3.7.7.7.1.m1.1a"><mn mathsize="90%" id="S4.T3.7.7.7.1.m1.1.1" xref="S4.T3.7.7.7.1.m1.1.1.cmml">80.3</mn><annotation-xml encoding="MathML-Content" id="S4.T3.7.7.7.1.m1.1b"><cn type="float" id="S4.T3.7.7.7.1.m1.1.1.cmml" xref="S4.T3.7.7.7.1.m1.1.1">80.3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.7.7.7.1.m1.1c">80.3</annotation></semantics></math></td>
<td id="S4.T3.8.8.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S4.T3.8.8.8.2.m1.1" class="ltx_Math" alttext="78.4" display="inline"><semantics id="S4.T3.8.8.8.2.m1.1a"><mn mathsize="90%" id="S4.T3.8.8.8.2.m1.1.1" xref="S4.T3.8.8.8.2.m1.1.1.cmml">78.4</mn><annotation-xml encoding="MathML-Content" id="S4.T3.8.8.8.2.m1.1b"><cn type="float" id="S4.T3.8.8.8.2.m1.1.1.cmml" xref="S4.T3.8.8.8.2.m1.1.1">78.4</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.8.8.8.2.m1.1c">78.4</annotation></semantics></math></td>
<td id="S4.T3.9.9.9.3" class="ltx_td ltx_align_center ltx_border_t"><math id="S4.T3.9.9.9.3.m1.1" class="ltx_Math" alttext="78.7" display="inline"><semantics id="S4.T3.9.9.9.3.m1.1a"><mn mathsize="90%" id="S4.T3.9.9.9.3.m1.1.1" xref="S4.T3.9.9.9.3.m1.1.1.cmml">78.7</mn><annotation-xml encoding="MathML-Content" id="S4.T3.9.9.9.3.m1.1b"><cn type="float" id="S4.T3.9.9.9.3.m1.1.1.cmml" xref="S4.T3.9.9.9.3.m1.1.1">78.7</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.9.9.9.3.m1.1c">78.7</annotation></semantics></math></td>
</tr>
<tr id="S4.T3.12.12.12" class="ltx_tr">
<th id="S4.T3.12.12.12.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T3.12.12.12.4.1" class="ltx_text" style="font-size:90%;">CPC-CNN-LSTM</span></th>
<td id="S4.T3.10.10.10.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S4.T3.10.10.10.1.m1.1" class="ltx_Math" alttext="\bf{84.7}" display="inline"><semantics id="S4.T3.10.10.10.1.m1.1a"><mn class="ltx_mathvariant_bold" mathsize="90%" mathvariant="bold" id="S4.T3.10.10.10.1.m1.1.1" xref="S4.T3.10.10.10.1.m1.1.1.cmml">84.7</mn><annotation-xml encoding="MathML-Content" id="S4.T3.10.10.10.1.m1.1b"><cn type="float" id="S4.T3.10.10.10.1.m1.1.1.cmml" xref="S4.T3.10.10.10.1.m1.1.1">84.7</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.10.10.10.1.m1.1c">\bf{84.7}</annotation></semantics></math></td>
<td id="S4.T3.11.11.11.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S4.T3.11.11.11.2.m1.1" class="ltx_Math" alttext="\bf{78.4}" display="inline"><semantics id="S4.T3.11.11.11.2.m1.1a"><mn class="ltx_mathvariant_bold" mathsize="90%" mathvariant="bold" id="S4.T3.11.11.11.2.m1.1.1" xref="S4.T3.11.11.11.2.m1.1.1.cmml">78.4</mn><annotation-xml encoding="MathML-Content" id="S4.T3.11.11.11.2.m1.1b"><cn type="float" id="S4.T3.11.11.11.2.m1.1.1.cmml" xref="S4.T3.11.11.11.2.m1.1.1">78.4</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.11.11.11.2.m1.1c">\bf{78.4}</annotation></semantics></math></td>
<td id="S4.T3.12.12.12.3" class="ltx_td ltx_align_center ltx_border_t"><math id="S4.T3.12.12.12.3.m1.1" class="ltx_Math" alttext="\bf{78.8}" display="inline"><semantics id="S4.T3.12.12.12.3.m1.1a"><mn class="ltx_mathvariant_bold" mathsize="90%" mathvariant="bold" id="S4.T3.12.12.12.3.m1.1.1" xref="S4.T3.12.12.12.3.m1.1.1.cmml">78.8</mn><annotation-xml encoding="MathML-Content" id="S4.T3.12.12.12.3.m1.1b"><cn type="float" id="S4.T3.12.12.12.3.m1.1.1.cmml" xref="S4.T3.12.12.12.3.m1.1.1">78.8</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.12.12.12.3.m1.1c">\bf{78.8}</annotation></semantics></math></td>
</tr>
<tr id="S4.T3.15.15.15" class="ltx_tr">
<th id="S4.T3.15.15.15.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T3.15.15.15.4.1" class="ltx_text" style="font-size:90%;">AST</span></th>
<td id="S4.T3.13.13.13.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S4.T3.13.13.13.1.m1.1" class="ltx_Math" alttext="75.2" display="inline"><semantics id="S4.T3.13.13.13.1.m1.1a"><mn mathsize="90%" id="S4.T3.13.13.13.1.m1.1.1" xref="S4.T3.13.13.13.1.m1.1.1.cmml">75.2</mn><annotation-xml encoding="MathML-Content" id="S4.T3.13.13.13.1.m1.1b"><cn type="float" id="S4.T3.13.13.13.1.m1.1.1.cmml" xref="S4.T3.13.13.13.1.m1.1.1">75.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.13.13.13.1.m1.1c">75.2</annotation></semantics></math></td>
<td id="S4.T3.14.14.14.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S4.T3.14.14.14.2.m1.1" class="ltx_Math" alttext="74.3" display="inline"><semantics id="S4.T3.14.14.14.2.m1.1a"><mn mathsize="90%" id="S4.T3.14.14.14.2.m1.1.1" xref="S4.T3.14.14.14.2.m1.1.1.cmml">74.3</mn><annotation-xml encoding="MathML-Content" id="S4.T3.14.14.14.2.m1.1b"><cn type="float" id="S4.T3.14.14.14.2.m1.1.1.cmml" xref="S4.T3.14.14.14.2.m1.1.1">74.3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.14.14.14.2.m1.1c">74.3</annotation></semantics></math></td>
<td id="S4.T3.15.15.15.3" class="ltx_td ltx_align_center ltx_border_t"><math id="S4.T3.15.15.15.3.m1.1" class="ltx_Math" alttext="75.5" display="inline"><semantics id="S4.T3.15.15.15.3.m1.1a"><mn mathsize="90%" id="S4.T3.15.15.15.3.m1.1.1" xref="S4.T3.15.15.15.3.m1.1.1.cmml">75.5</mn><annotation-xml encoding="MathML-Content" id="S4.T3.15.15.15.3.m1.1b"><cn type="float" id="S4.T3.15.15.15.3.m1.1.1.cmml" xref="S4.T3.15.15.15.3.m1.1.1">75.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.15.15.15.3.m1.1c">75.5</annotation></semantics></math></td>
</tr>
<tr id="S4.T3.18.18.18" class="ltx_tr">
<th id="S4.T3.18.18.18.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t">
<span id="S4.T3.18.18.18.4.1" class="ltx_text" style="font-size:90%;">Wav2vec2.0_3-2 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T3.18.18.18.4.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib8" title="" class="ltx_ref">8</a><span id="S4.T3.18.18.18.4.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</th>
<td id="S4.T3.16.16.16.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="S4.T3.16.16.16.1.m1.1" class="ltx_Math" alttext="77.9" display="inline"><semantics id="S4.T3.16.16.16.1.m1.1a"><mn mathsize="90%" id="S4.T3.16.16.16.1.m1.1.1" xref="S4.T3.16.16.16.1.m1.1.1.cmml">77.9</mn><annotation-xml encoding="MathML-Content" id="S4.T3.16.16.16.1.m1.1b"><cn type="float" id="S4.T3.16.16.16.1.m1.1.1.cmml" xref="S4.T3.16.16.16.1.m1.1.1">77.9</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.16.16.16.1.m1.1c">77.9</annotation></semantics></math></td>
<td id="S4.T3.17.17.17.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="S4.T3.17.17.17.2.m1.1" class="ltx_Math" alttext="77.2" display="inline"><semantics id="S4.T3.17.17.17.2.m1.1a"><mn mathsize="90%" id="S4.T3.17.17.17.2.m1.1.1" xref="S4.T3.17.17.17.2.m1.1.1.cmml">77.2</mn><annotation-xml encoding="MathML-Content" id="S4.T3.17.17.17.2.m1.1b"><cn type="float" id="S4.T3.17.17.17.2.m1.1.1.cmml" xref="S4.T3.17.17.17.2.m1.1.1">77.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.17.17.17.2.m1.1c">77.2</annotation></semantics></math></td>
<td id="S4.T3.18.18.18.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><math id="S4.T3.18.18.18.3.m1.1" class="ltx_Math" alttext="77.2" display="inline"><semantics id="S4.T3.18.18.18.3.m1.1a"><mn mathsize="90%" id="S4.T3.18.18.18.3.m1.1.1" xref="S4.T3.18.18.18.3.m1.1.1.cmml">77.2</mn><annotation-xml encoding="MathML-Content" id="S4.T3.18.18.18.3.m1.1b"><cn type="float" id="S4.T3.18.18.18.3.m1.1.1.cmml" xref="S4.T3.18.18.18.3.m1.1.1">77.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.18.18.18.3.m1.1c">77.2</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.25.1.1" class="ltx_text ltx_font_bold">Table 4</span>: </span>Evaluation on the testing set with federated learning.</figcaption>
<div id="S4.T4.21" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:45.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(57.7pt,49.2pt) scale(1.3628331248156,0.316141658359104) ;">
<table id="S4.T4.21.21" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.21.21.22.1" class="ltx_tr">
<th id="S4.T4.21.21.22.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T4.21.21.22.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Method</span></th>
<th id="S4.T4.21.21.22.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T4.21.21.22.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Downstream Model</span></th>
<th id="S4.T4.21.21.22.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T4.21.21.22.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Precision(%)</span></th>
<th id="S4.T4.21.21.22.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T4.21.21.22.1.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Recall(%)</span></th>
<th id="S4.T4.21.21.22.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T4.21.21.22.1.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">F1(%)</span></th>
</tr>
<tr id="S4.T4.3.3.3" class="ltx_tr">
<th id="S4.T4.3.3.3.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T4.3.3.3.4.1" class="ltx_text" style="font-size:90%;">Fed-AST</span></th>
<th id="S4.T4.3.3.3.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T4.3.3.3.5.1" class="ltx_text" style="font-size:90%;">-</span></th>
<th id="S4.T4.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><math id="S4.T4.1.1.1.1.m1.1" class="ltx_Math" alttext="73.7" display="inline"><semantics id="S4.T4.1.1.1.1.m1.1a"><mn mathsize="90%" id="S4.T4.1.1.1.1.m1.1.1" xref="S4.T4.1.1.1.1.m1.1.1.cmml">73.7</mn><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.1.m1.1b"><cn type="float" id="S4.T4.1.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.1.m1.1.1">73.7</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.1.m1.1c">73.7</annotation></semantics></math></th>
<th id="S4.T4.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><math id="S4.T4.2.2.2.2.m1.1" class="ltx_Math" alttext="72.5" display="inline"><semantics id="S4.T4.2.2.2.2.m1.1a"><mn mathsize="90%" id="S4.T4.2.2.2.2.m1.1.1" xref="S4.T4.2.2.2.2.m1.1.1.cmml">72.5</mn><annotation-xml encoding="MathML-Content" id="S4.T4.2.2.2.2.m1.1b"><cn type="float" id="S4.T4.2.2.2.2.m1.1.1.cmml" xref="S4.T4.2.2.2.2.m1.1.1">72.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.2.2.2.m1.1c">72.5</annotation></semantics></math></th>
<th id="S4.T4.3.3.3.3" class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S4.T4.3.3.3.3.m1.1" class="ltx_Math" alttext="73.5" display="inline"><semantics id="S4.T4.3.3.3.3.m1.1a"><mn mathsize="90%" id="S4.T4.3.3.3.3.m1.1.1" xref="S4.T4.3.3.3.3.m1.1.1.cmml">73.5</mn><annotation-xml encoding="MathML-Content" id="S4.T4.3.3.3.3.m1.1b"><cn type="float" id="S4.T4.3.3.3.3.m1.1.1.cmml" xref="S4.T4.3.3.3.3.m1.1.1">73.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.3.3.3.m1.1c">73.5</annotation></semantics></math></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.6.6.6" class="ltx_tr">
<th id="S4.T4.6.6.6.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T4.6.6.6.4.1" class="ltx_text" style="font-size:90%;">Fed</span></th>
<th id="S4.T4.6.6.6.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T4.6.6.6.5.1" class="ltx_text" style="font-size:90%;">CNN</span></th>
<td id="S4.T4.4.4.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S4.T4.4.4.4.1.m1.1" class="ltx_Math" alttext="72.8" display="inline"><semantics id="S4.T4.4.4.4.1.m1.1a"><mn mathsize="90%" id="S4.T4.4.4.4.1.m1.1.1" xref="S4.T4.4.4.4.1.m1.1.1.cmml">72.8</mn><annotation-xml encoding="MathML-Content" id="S4.T4.4.4.4.1.m1.1b"><cn type="float" id="S4.T4.4.4.4.1.m1.1.1.cmml" xref="S4.T4.4.4.4.1.m1.1.1">72.8</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.4.4.4.1.m1.1c">72.8</annotation></semantics></math></td>
<td id="S4.T4.5.5.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S4.T4.5.5.5.2.m1.1" class="ltx_Math" alttext="70.2" display="inline"><semantics id="S4.T4.5.5.5.2.m1.1a"><mn mathsize="90%" id="S4.T4.5.5.5.2.m1.1.1" xref="S4.T4.5.5.5.2.m1.1.1.cmml">70.2</mn><annotation-xml encoding="MathML-Content" id="S4.T4.5.5.5.2.m1.1b"><cn type="float" id="S4.T4.5.5.5.2.m1.1.1.cmml" xref="S4.T4.5.5.5.2.m1.1.1">70.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.5.5.5.2.m1.1c">70.2</annotation></semantics></math></td>
<td id="S4.T4.6.6.6.3" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><math id="S4.T4.6.6.6.3.m1.1" class="ltx_Math" alttext="68.2" display="inline"><semantics id="S4.T4.6.6.6.3.m1.1a"><mn mathsize="90%" id="S4.T4.6.6.6.3.m1.1.1" xref="S4.T4.6.6.6.3.m1.1.1.cmml">68.2</mn><annotation-xml encoding="MathML-Content" id="S4.T4.6.6.6.3.m1.1b"><cn type="float" id="S4.T4.6.6.6.3.m1.1.1.cmml" xref="S4.T4.6.6.6.3.m1.1.1">68.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.6.6.6.3.m1.1c">68.2</annotation></semantics></math></td>
</tr>
<tr id="S4.T4.9.9.9" class="ltx_tr">
<th id="S4.T4.9.9.9.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span id="S4.T4.9.9.9.4.1" class="ltx_text" style="font-size:90%;">CPC-Client</span></th>
<th id="S4.T4.9.9.9.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S4.T4.9.9.9.5.1" class="ltx_text" style="font-size:90%;">CNN</span></th>
<td id="S4.T4.7.7.7.1" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T4.7.7.7.1.m1.1" class="ltx_Math" alttext="77.0" display="inline"><semantics id="S4.T4.7.7.7.1.m1.1a"><mn mathsize="90%" id="S4.T4.7.7.7.1.m1.1.1" xref="S4.T4.7.7.7.1.m1.1.1.cmml">77.0</mn><annotation-xml encoding="MathML-Content" id="S4.T4.7.7.7.1.m1.1b"><cn type="float" id="S4.T4.7.7.7.1.m1.1.1.cmml" xref="S4.T4.7.7.7.1.m1.1.1">77.0</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.7.7.7.1.m1.1c">77.0</annotation></semantics></math></td>
<td id="S4.T4.8.8.8.2" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T4.8.8.8.2.m1.1" class="ltx_Math" alttext="71.8" display="inline"><semantics id="S4.T4.8.8.8.2.m1.1a"><mn mathsize="90%" id="S4.T4.8.8.8.2.m1.1.1" xref="S4.T4.8.8.8.2.m1.1.1.cmml">71.8</mn><annotation-xml encoding="MathML-Content" id="S4.T4.8.8.8.2.m1.1b"><cn type="float" id="S4.T4.8.8.8.2.m1.1.1.cmml" xref="S4.T4.8.8.8.2.m1.1.1">71.8</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.8.8.8.2.m1.1c">71.8</annotation></semantics></math></td>
<td id="S4.T4.9.9.9.3" class="ltx_td ltx_nopad_r ltx_align_center"><math id="S4.T4.9.9.9.3.m1.1" class="ltx_Math" alttext="72.3" display="inline"><semantics id="S4.T4.9.9.9.3.m1.1a"><mn mathsize="90%" id="S4.T4.9.9.9.3.m1.1.1" xref="S4.T4.9.9.9.3.m1.1.1.cmml">72.3</mn><annotation-xml encoding="MathML-Content" id="S4.T4.9.9.9.3.m1.1b"><cn type="float" id="S4.T4.9.9.9.3.m1.1.1.cmml" xref="S4.T4.9.9.9.3.m1.1.1">72.3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.9.9.9.3.m1.1c">72.3</annotation></semantics></math></td>
</tr>
<tr id="S4.T4.12.12.12" class="ltx_tr">
<th id="S4.T4.12.12.12.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span id="S4.T4.12.12.12.4.1" class="ltx_text" style="font-size:90%;">FedCPC (Our)</span></th>
<th id="S4.T4.12.12.12.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S4.T4.12.12.12.5.1" class="ltx_text" style="font-size:90%;">CNN</span></th>
<td id="S4.T4.10.10.10.1" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T4.10.10.10.1.m1.1" class="ltx_Math" alttext="{\bf 79.3}" display="inline"><semantics id="S4.T4.10.10.10.1.m1.1a"><mn class="ltx_mathvariant_bold" mathsize="90%" mathvariant="bold" id="S4.T4.10.10.10.1.m1.1.1" xref="S4.T4.10.10.10.1.m1.1.1.cmml">79.3</mn><annotation-xml encoding="MathML-Content" id="S4.T4.10.10.10.1.m1.1b"><cn type="float" id="S4.T4.10.10.10.1.m1.1.1.cmml" xref="S4.T4.10.10.10.1.m1.1.1">79.3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.10.10.10.1.m1.1c">{\bf 79.3}</annotation></semantics></math></td>
<td id="S4.T4.11.11.11.2" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T4.11.11.11.2.m1.1" class="ltx_Math" alttext="{\bf 74.3}" display="inline"><semantics id="S4.T4.11.11.11.2.m1.1a"><mn class="ltx_mathvariant_bold" mathsize="90%" mathvariant="bold" id="S4.T4.11.11.11.2.m1.1.1" xref="S4.T4.11.11.11.2.m1.1.1.cmml">74.3</mn><annotation-xml encoding="MathML-Content" id="S4.T4.11.11.11.2.m1.1b"><cn type="float" id="S4.T4.11.11.11.2.m1.1.1.cmml" xref="S4.T4.11.11.11.2.m1.1.1">74.3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.11.11.11.2.m1.1c">{\bf 74.3}</annotation></semantics></math></td>
<td id="S4.T4.12.12.12.3" class="ltx_td ltx_nopad_r ltx_align_center"><math id="S4.T4.12.12.12.3.m1.1" class="ltx_Math" alttext="{\bf 74.8}" display="inline"><semantics id="S4.T4.12.12.12.3.m1.1a"><mn class="ltx_mathvariant_bold" mathsize="90%" mathvariant="bold" id="S4.T4.12.12.12.3.m1.1.1" xref="S4.T4.12.12.12.3.m1.1.1.cmml">74.8</mn><annotation-xml encoding="MathML-Content" id="S4.T4.12.12.12.3.m1.1b"><cn type="float" id="S4.T4.12.12.12.3.m1.1.1.cmml" xref="S4.T4.12.12.12.3.m1.1.1">74.8</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.12.12.12.3.m1.1c">{\bf 74.8}</annotation></semantics></math></td>
</tr>
<tr id="S4.T4.15.15.15" class="ltx_tr">
<th id="S4.T4.15.15.15.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T4.15.15.15.4.1" class="ltx_text" style="font-size:90%;">Fed</span></th>
<th id="S4.T4.15.15.15.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T4.15.15.15.5.1" class="ltx_text" style="font-size:90%;">CNN-LSTM</span></th>
<td id="S4.T4.13.13.13.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S4.T4.13.13.13.1.m1.1" class="ltx_Math" alttext="72.0" display="inline"><semantics id="S4.T4.13.13.13.1.m1.1a"><mn mathsize="90%" id="S4.T4.13.13.13.1.m1.1.1" xref="S4.T4.13.13.13.1.m1.1.1.cmml">72.0</mn><annotation-xml encoding="MathML-Content" id="S4.T4.13.13.13.1.m1.1b"><cn type="float" id="S4.T4.13.13.13.1.m1.1.1.cmml" xref="S4.T4.13.13.13.1.m1.1.1">72.0</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.13.13.13.1.m1.1c">72.0</annotation></semantics></math></td>
<td id="S4.T4.14.14.14.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S4.T4.14.14.14.2.m1.1" class="ltx_Math" alttext="72.1" display="inline"><semantics id="S4.T4.14.14.14.2.m1.1a"><mn mathsize="90%" id="S4.T4.14.14.14.2.m1.1.1" xref="S4.T4.14.14.14.2.m1.1.1.cmml">72.1</mn><annotation-xml encoding="MathML-Content" id="S4.T4.14.14.14.2.m1.1b"><cn type="float" id="S4.T4.14.14.14.2.m1.1.1.cmml" xref="S4.T4.14.14.14.2.m1.1.1">72.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.14.14.14.2.m1.1c">72.1</annotation></semantics></math></td>
<td id="S4.T4.15.15.15.3" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><math id="S4.T4.15.15.15.3.m1.1" class="ltx_Math" alttext="71.4" display="inline"><semantics id="S4.T4.15.15.15.3.m1.1a"><mn mathsize="90%" id="S4.T4.15.15.15.3.m1.1.1" xref="S4.T4.15.15.15.3.m1.1.1.cmml">71.4</mn><annotation-xml encoding="MathML-Content" id="S4.T4.15.15.15.3.m1.1b"><cn type="float" id="S4.T4.15.15.15.3.m1.1.1.cmml" xref="S4.T4.15.15.15.3.m1.1.1">71.4</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.15.15.15.3.m1.1c">71.4</annotation></semantics></math></td>
</tr>
<tr id="S4.T4.18.18.18" class="ltx_tr">
<th id="S4.T4.18.18.18.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span id="S4.T4.18.18.18.4.1" class="ltx_text" style="font-size:90%;">CPC-Client</span></th>
<th id="S4.T4.18.18.18.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S4.T4.18.18.18.5.1" class="ltx_text" style="font-size:90%;">CNN-LSTM</span></th>
<td id="S4.T4.16.16.16.1" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T4.16.16.16.1.m1.1" class="ltx_Math" alttext="76.4" display="inline"><semantics id="S4.T4.16.16.16.1.m1.1a"><mn mathsize="90%" id="S4.T4.16.16.16.1.m1.1.1" xref="S4.T4.16.16.16.1.m1.1.1.cmml">76.4</mn><annotation-xml encoding="MathML-Content" id="S4.T4.16.16.16.1.m1.1b"><cn type="float" id="S4.T4.16.16.16.1.m1.1.1.cmml" xref="S4.T4.16.16.16.1.m1.1.1">76.4</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.16.16.16.1.m1.1c">76.4</annotation></semantics></math></td>
<td id="S4.T4.17.17.17.2" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T4.17.17.17.2.m1.1" class="ltx_Math" alttext="72.9" display="inline"><semantics id="S4.T4.17.17.17.2.m1.1a"><mn mathsize="90%" id="S4.T4.17.17.17.2.m1.1.1" xref="S4.T4.17.17.17.2.m1.1.1.cmml">72.9</mn><annotation-xml encoding="MathML-Content" id="S4.T4.17.17.17.2.m1.1b"><cn type="float" id="S4.T4.17.17.17.2.m1.1.1.cmml" xref="S4.T4.17.17.17.2.m1.1.1">72.9</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.17.17.17.2.m1.1c">72.9</annotation></semantics></math></td>
<td id="S4.T4.18.18.18.3" class="ltx_td ltx_nopad_r ltx_align_center"><math id="S4.T4.18.18.18.3.m1.1" class="ltx_Math" alttext="73.5" display="inline"><semantics id="S4.T4.18.18.18.3.m1.1a"><mn mathsize="90%" id="S4.T4.18.18.18.3.m1.1.1" xref="S4.T4.18.18.18.3.m1.1.1.cmml">73.5</mn><annotation-xml encoding="MathML-Content" id="S4.T4.18.18.18.3.m1.1b"><cn type="float" id="S4.T4.18.18.18.3.m1.1.1.cmml" xref="S4.T4.18.18.18.3.m1.1.1">73.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.18.18.18.3.m1.1c">73.5</annotation></semantics></math></td>
</tr>
<tr id="S4.T4.21.21.21" class="ltx_tr">
<th id="S4.T4.21.21.21.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r"><span id="S4.T4.21.21.21.4.1" class="ltx_text" style="font-size:90%;">FedCPC (Our)</span></th>
<th id="S4.T4.21.21.21.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r"><span id="S4.T4.21.21.21.5.1" class="ltx_text" style="font-size:90%;">CNN-LSTM</span></th>
<td id="S4.T4.19.19.19.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><math id="S4.T4.19.19.19.1.m1.1" class="ltx_Math" alttext="{\bf 79.5}" display="inline"><semantics id="S4.T4.19.19.19.1.m1.1a"><mn class="ltx_mathvariant_bold" mathsize="90%" mathvariant="bold" id="S4.T4.19.19.19.1.m1.1.1" xref="S4.T4.19.19.19.1.m1.1.1.cmml">79.5</mn><annotation-xml encoding="MathML-Content" id="S4.T4.19.19.19.1.m1.1b"><cn type="float" id="S4.T4.19.19.19.1.m1.1.1.cmml" xref="S4.T4.19.19.19.1.m1.1.1">79.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.19.19.19.1.m1.1c">{\bf 79.5}</annotation></semantics></math></td>
<td id="S4.T4.20.20.20.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><math id="S4.T4.20.20.20.2.m1.1" class="ltx_Math" alttext="{\bf 74.7}" display="inline"><semantics id="S4.T4.20.20.20.2.m1.1a"><mn class="ltx_mathvariant_bold" mathsize="90%" mathvariant="bold" id="S4.T4.20.20.20.2.m1.1.1" xref="S4.T4.20.20.20.2.m1.1.1.cmml">74.7</mn><annotation-xml encoding="MathML-Content" id="S4.T4.20.20.20.2.m1.1b"><cn type="float" id="S4.T4.20.20.20.2.m1.1.1.cmml" xref="S4.T4.20.20.20.2.m1.1.1">74.7</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.20.20.20.2.m1.1c">{\bf 74.7}</annotation></semantics></math></td>
<td id="S4.T4.21.21.21.3" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_b"><math id="S4.T4.21.21.21.3.m1.1" class="ltx_Math" alttext="{\bf 75.3}" display="inline"><semantics id="S4.T4.21.21.21.3.m1.1a"><mn class="ltx_mathvariant_bold" mathsize="90%" mathvariant="bold" id="S4.T4.21.21.21.3.m1.1.1" xref="S4.T4.21.21.21.3.m1.1.1.cmml">75.3</mn><annotation-xml encoding="MathML-Content" id="S4.T4.21.21.21.3.m1.1b"><cn type="float" id="S4.T4.21.21.21.3.m1.1.1.cmml" xref="S4.T4.21.21.21.3.m1.1.1">75.3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.21.21.21.3.m1.1c">{\bf 75.3}</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="S4.F2" class="ltx_figure"><img src="/html/2311.13043/assets/x2.png" id="S4.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="247" height="168" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.2.1.1" class="ltx_text ltx_font_bold">Fig.Â 2</span>: </span>t-SNE visualization of audio with CPC pre-training.</figcaption>
</figure>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.2" class="ltx_p">We then verify the performance of our proposed FedCPC-based models. Table <a href="#S4.T4" title="Table 4 â€£ 4.1 Main results â€£ 4 Reuslts and Discussions â€£ FedCPC: an Effective Federated Contrastive Learning Method for Privacy Preserving Early-Stage Alzheimerâ€™s Speech Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> demonstrates the results of federated learning. The CPC-Client-based model used the pre-training models trained by different clients using data unique to each client. The FedCPC-based model used the pre-training models trained with federated learning. As shown in Table <a href="#S4.T4" title="Table 4 â€£ 4.1 Main results â€£ 4 Reuslts and Discussions â€£ FedCPC: an Effective Federated Contrastive Learning Method for Privacy Preserving Early-Stage Alzheimerâ€™s Speech Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, the FedCPC-based model outperforms the CPC-Client model. Our proposed FedCPC-CNN-LSTM model gets the best result in federated learning. Compared with the CNN-LSTM model, the FedCPC-CNN-LSTM model significantly improves from 71.4<math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mo id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><csymbol cd="latexml" id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">\%</annotation></semantics></math> to 75.3 <math id="S4.SS1.p2.2.m2.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS1.p2.2.m2.1a"><mo id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><csymbol cd="latexml" id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">\%</annotation></semantics></math> in the F1-score. For comparison, we also exploit a pre-training AST model on this task and notice that FedCPC-CNN-LSTM outperforms it.
Meanwhile, we check the results for different categories by using confusion matrices to explore the reasons for the improvement. The confusion matrices for Fed-CNN-LSTM and FedCPC-CNN-LSTM with features computed on the test set, as depicted in Figure <a href="#S4.F3" title="Figure 3 â€£ 4.1 Main results â€£ 4 Reuslts and Discussions â€£ FedCPC: an Effective Federated Contrastive Learning Method for Privacy Preserving Early-Stage Alzheimerâ€™s Speech Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. We found that Fed-CNN-LSTM tends to classify AD into the MCI and HC category incorrectly, while FedCPC-CNN-LSTM tends to classify AD into the MCI. It is consistent with the distribution of audio in Figure <a href="#S4.F2" title="Figure 2 â€£ 4.1 Main results â€£ 4 Reuslts and Discussions â€£ FedCPC: an Effective Federated Contrastive Learning Method for Privacy Preserving Early-Stage Alzheimerâ€™s Speech Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Moreover, FedCPC-CNN-LSTM performs better on AD and MCI.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2311.13043/assets/x3.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="253" height="124" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.2.1.1" class="ltx_text ltx_font_bold">Fig.Â 3</span>: </span>Confusion matrix of federated learning (a) Fed-CNN-LSTM, (b) FedCPC-CNN-LSTM.</figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Further Discussions</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.5" class="ltx_p">With the results in Tables <a href="#S4.T3" title="Table 3 â€£ 4.1 Main results â€£ 4 Reuslts and Discussions â€£ FedCPC: an Effective Federated Contrastive Learning Method for Privacy Preserving Early-Stage Alzheimerâ€™s Speech Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and <a href="#S4.T4" title="Table 4 â€£ 4.1 Main results â€£ 4 Reuslts and Discussions â€£ FedCPC: an Effective Federated Contrastive Learning Method for Privacy Preserving Early-Stage Alzheimerâ€™s Speech Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we found that the results of the federated-learning-based models have decreased compared with the traditional centralized learning results. The recall and F1-score of the CNN-LSTM system decreased by 3.1<math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mo id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><csymbol cd="latexml" id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">\%</annotation></semantics></math>, 3.2<math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><mo id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><csymbol cd="latexml" id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">\%</annotation></semantics></math>, and 3.8<math id="S4.SS2.p1.3.m3.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS2.p1.3.m3.1a"><mo id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><csymbol cd="latexml" id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">\%</annotation></semantics></math> after adopting federated learning. Moreover, the FedCPC-CNN-LSTM dropped by 1.8<math id="S4.SS2.p1.4.m4.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS2.p1.4.m4.1a"><mo id="S4.SS2.p1.4.m4.1.1" xref="S4.SS2.p1.4.m4.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.4.m4.1b"><csymbol cd="latexml" id="S4.SS2.p1.4.m4.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.4.m4.1c">\%</annotation></semantics></math> and 3.4<math id="S4.SS2.p1.5.m5.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS2.p1.5.m5.1a"><mo id="S4.SS2.p1.5.m5.1.1" xref="S4.SS2.p1.5.m5.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.5.m5.1b"><csymbol cd="latexml" id="S4.SS2.p1.5.m5.1.1.cmml" xref="S4.SS2.p1.5.m5.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.5.m5.1c">\%</annotation></semantics></math> in the recall and F1-score after adopting federated learning, respectively. This result is expected regarding each client sideâ€™s limited data and partial observations. This shows the inherent limitations of federated learning, which are worth investigating.
The AST cannot outperform the pre-trained small models in the experiments above. Considering its high cost, it is not applicable for memory-restricted clients.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">This paper uses federated learning to train models to detect AD in speech and protect privacy in the userâ€™s voice. Compared with centralized learning, federated learning is a distributed training mode, leading to performance degradation, especially in small databases.
To address this issue, we proposed the FedCPC-based pre-training method, which enables data sharing while preserving privacy during the pre-training and training stage. The experimental evaluation revealed that our proposed approach effectively preserves privacy while maintaining competitive performance compared to non-privacy-preserving methods.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Acknowledgement</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">This work was supported by JSPS KAKENHI Grant Numbers JP23K11227, JP23H03454, and NICT tenure-track funding.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:80%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:80%;">
Greta Szatloczki, Ildiko Hoffmann, Veronika Vincze, Janos Kalman, and Magdolna
Pakaski,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:80%;">â€œSpeaking in alzheimerâ€™s disease, is that an early sign?
importance of changes in language abilities in alzheimerâ€™s disease,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">Frontiers in aging neuroscience</span><span id="bib.bib1.4.2" class="ltx_text" style="font-size:80%;">, vol. 7, pp. 195, 2015.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:80%;">
Kaye Horley, Amanda Reid, and Denis Burnham,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:80%;">â€œEmotional prosody perception and production in dementia of the
alzheimerâ€™s type,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text" style="font-size:80%;">2010.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:80%;">
Anja Lowit, Bettina Brendel, Corinne Dobinson, and Peter Howell,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:80%;">â€œAn investigation into the influences of age, pathology and
cognition on speech production,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">Journal of medical speech-language pathology</span><span id="bib.bib3.4.2" class="ltx_text" style="font-size:80%;">, vol. 14, pp. 253,
2006.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:80%;">
Brian Roark, Margaret Mitchell, John-Paul Hosom, Kristy Hollingshead, and
Jeffrey Kaye,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:80%;">â€œSpoken language derived measures for detecting mild cognitive
impairment,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">IEEE transactions on audio, speech, and language processing</span><span id="bib.bib4.4.2" class="ltx_text" style="font-size:80%;">,
vol. 19, no. 7, pp. 2081â€“2090, 2011.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:80%;">
LÃ¡szlÃ³ TÃ³th, GÃ¡bor Gosztolya, Veronika Vincze, IldikÃ³
Hoffmann, GrÃ©ta SzatlÃ³czki, Edit BirÃ³, Fruzsina Zsura, Magdolna
PÃ¡kÃ¡ski, and JÃ¡nos KÃ¡lmÃ¡n,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:80%;">â€œAutomatic detection of mild cognitive impairment from spontaneous
speech using asr,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib5.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">INTERSPEECH</span><span id="bib.bib5.5.3" class="ltx_text" style="font-size:80%;">, 2015.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:80%;">
Yilin Pan, Bahman Mirheidari, Markus Reuber, Annalena Venneri, DanielÂ J.
Blackburn, and Heidi Christensen,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:80%;">â€œImproving detection of alzheimerâ€™s disease using automatic speech
recognition to identify high-quality segments for more robust feature
extraction,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib6.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">INTERSPEECH</span><span id="bib.bib6.5.3" class="ltx_text" style="font-size:80%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:80%;">
Luke Zhou, KathleenÂ C. Fraser, and Frank Rudzicz,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:80%;">â€œSpeech recognition in alzheimerâ€™s disease and in its assessment,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib7.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">INTERSPEECH</span><span id="bib.bib7.5.3" class="ltx_text" style="font-size:80%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:80%;">
Ying Qin, Wei Liu, Zhiyuan Peng, Si-Ioi Ng, Jingyu Li, Haibo Hu, and Tan Lee,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:80%;">â€œExploiting pre-trained asr models for alzheimerâ€™s disease
recognition through spontaneous speech,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:2110.01493</span><span id="bib.bib8.4.2" class="ltx_text" style="font-size:80%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:80%;">
RaghavendraÂ Reddy Pappagari, Jaejin Cho, Laureano Moro-VelÃ¡zquez, and Najim
Dehak,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:80%;">â€œUsing state of the art speaker recognition and natural language
processing technologies to detect alzheimerâ€™s disease and assess its
severity,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib9.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">INTERSPEECH</span><span id="bib.bib9.5.3" class="ltx_text" style="font-size:80%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:80%;">
Thomas Searle, ZinaÂ M. Ibrahim, and Richard J.Â B. Dobson,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:80%;">â€œComparing natural language processing techniques for alzheimerâ€™s
dementia prediction in spontaneous speech,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib10.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">INTERSPEECH</span><span id="bib.bib10.5.3" class="ltx_text" style="font-size:80%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:80%;">
Sebastian Wankerl, Elmar NÃ¶th, and Stefan Evert,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:80%;">â€œAn n-gram based approach to the automatic diagnosis of alzheimerâ€™s
disease from spoken language,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib11.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">INTERSPEECH</span><span id="bib.bib11.5.3" class="ltx_text" style="font-size:80%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:80%;">
Aparna Balagopalan, Benjamin Eyre, Frank Rudzicz, and Jekaterina Novikova,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:80%;">â€œTo bert or not to bert: Comparing speech and language-based
approaches for alzheimerâ€™s disease detection,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib12.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">INTERSPEECH</span><span id="bib.bib12.5.3" class="ltx_text" style="font-size:80%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:80%;">
Jiahong Yuan, Yuchen Bian, Xingyu Cai, Jiaji Huang, Zheng Ye, and Kenneth
Church,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:80%;">â€œDisfluencies and fine-tuning pre-trained language models for
detection of alzheimerâ€™s disease,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib13.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">INTERSPEECH</span><span id="bib.bib13.5.3" class="ltx_text" style="font-size:80%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:80%;">
Morteza Rohanian, J.Â Hough, and Matthew Purver,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:80%;">â€œMulti-modal fusion with gating using audio, lexical and disfluency
features for alzheimerâ€™s dementia recognition from spontaneous speech,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">ArXiv</span><span id="bib.bib14.4.2" class="ltx_text" style="font-size:80%;">, vol. abs/2106.09668, 2020.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:80%;">
A.Â Nautsch and etÂ al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:80%;">â€œThe GDPR &amp; speech data: Reflections of legal and technology
communities, first steps towards a common understanding,â€ 2019.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:80%;">
Z.Â Wu and etÂ al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:80%;">â€œSpoofing and countermeasures for speaker verification: A survey,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">Speech Communication</span><span id="bib.bib16.4.2" class="ltx_text" style="font-size:80%;">, vol. 66, pp. 130â€“153, 2015.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:80%;">
S.Â Suwajanakorn and etÂ al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:80%;">â€œSynthesizing obama: learning lip sync from audio,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">ACM Transactions on Graphics</span><span id="bib.bib17.4.2" class="ltx_text" style="font-size:80%;">, vol. 36, no. 4, pp. 95, 2017.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:80%;">
T.Â Justin and etÂ al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:80%;">â€œSpeaker de-identification using diphone recognition and speech
synthesis,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib18.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">11th IEEE International Conference and Workshops on Automatic
Face and Gesture Recognition</span><span id="bib.bib18.5.3" class="ltx_text" style="font-size:80%;">. IEEE, 2015, vol.Â 4, pp. 1â€“7.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:80%;">
J.Â Qian and etÂ al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:80%;">â€œHidebehind: Enjoy voice input with voiceprint unclonability and
anonymity,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib19.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proceedings of the 16th ACM Conference on Embedded Networked
Sensor Systems</span><span id="bib.bib19.5.3" class="ltx_text" style="font-size:80%;">. ACM, 2018, pp. 82â€“94.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:80%;">
Brij MohanÂ Lal Srivastava, Nathalie Vauquier, MdÂ Sahidullah, AurÃ©lien
Bellet, Marc Tommasi, and Emmanuel Vincent,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:80%;">â€œEvaluating voice conversion-based privacy protection against
informed attackers,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib20.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">ICASSP 2020-2020 IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP)</span><span id="bib.bib20.5.3" class="ltx_text" style="font-size:80%;">. IEEE, 2020, pp. 2802â€“2806.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:80%;">
F.Â Fang and etÂ al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:80%;">â€œSpeaker anonymization using X-vector and neural waveform
models,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib21.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proc. 10th ISCA Speech Synthesis Workshop</span><span id="bib.bib21.5.3" class="ltx_text" style="font-size:80%;">, 2019, pp.
155â€“160.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:80%;">
L.Â Sweeney,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:80%;">â€œK-anonymity: A model for protecting privacy,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">Int. J. Uncertain. Fuzziness Knowl.-Based Syst.</span><span id="bib.bib22.4.2" class="ltx_text" style="font-size:80%;">, vol. 10, no.
5, pp. 557â€“570, 2002.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:80%;">
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and BlaiseÂ Aguera
yÂ Arcas,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:80%;">â€œCommunication-efficient learning of deep networks from
decentralized data,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib23.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Artificial intelligence and statistics</span><span id="bib.bib23.5.3" class="ltx_text" style="font-size:80%;">. PMLR, 2017, pp.
1273â€“1282.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:80%;">
Jiachun Li, Yan Meng, Lichuan Ma, Suguo Du, Haojin Zhu, Qingqi Pei, and Xuemin
Shen,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:80%;">â€œA federated learning based privacy-preserving smart healthcare
system,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">IEEE Transactions on Industrial Informatics</span><span id="bib.bib24.4.2" class="ltx_text" style="font-size:80%;">, vol. 18, no. 3,
2021.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:80%;">
Yangpeng Wang, Ling Xiong, Xianhua Niu, Yunxiang Wang, and Dexin Liang,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:80%;">â€œA federated learning based privacy-preserving data sharing scheme
for internet of vehicles,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib25.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Frontiers in Cyber Security: 5th International Conference,
FCS 2022, Kumasi, Ghana, December 13â€“15, 2022, Proceedings</span><span id="bib.bib25.5.3" class="ltx_text" style="font-size:80%;">. Springer, 2022,
pp. 18â€“33.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:80%;">
Ashish Jaiswal and etÂ al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:80%;">â€œA survey on contrastive self-supervised learning,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">Technologies</span><span id="bib.bib26.4.2" class="ltx_text" style="font-size:80%;">, vol. 9, no. 1, pp. 2, 2020.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:80%;">
Aaron vanÂ den Oord, Yazhe Li, and Oriol Vinyals,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:80%;">â€œRepresentation learning with contrastive predictive coding,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:1807.03748</span><span id="bib.bib27.4.2" class="ltx_text" style="font-size:80%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:80%;">
Alexei Baevski, Wei-Ning Hsu, Alexis Conneau, and Michael Auli,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:80%;">â€œUnsupervised speech recognition,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">Advances in Neural Information Processing Systems</span><span id="bib.bib28.4.2" class="ltx_text" style="font-size:80%;">, vol. 34, pp.
27826â€“27839, 2021.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:80%;">
A.Â Boles and P.Â Rad,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:80%;">â€œVoice biometrics: Deep learning-based voiceprint authentication
system,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib29.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">12th System of Systems Engineering Conference</span><span id="bib.bib29.5.3" class="ltx_text" style="font-size:80%;">, 2017, pp.
1â€“6.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:80%;">
Tencent Inc.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:80%;">â€œThe new wechat password,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">https://blog.wechat.com/ tag/voiceprint/</span><span id="bib.bib30.4.2" class="ltx_text" style="font-size:80%;">, 2015.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:80%;">
Yuan Gong, Yu-An Chung, and James Glass,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.2.1" class="ltx_text" style="font-size:80%;">â€œAST: Audio Spectrogram Transformer,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib31.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proc. Interspeech 2021</span><span id="bib.bib31.5.3" class="ltx_text" style="font-size:80%;">, 2021, pp. 571â€“575.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:80%;">
DanielÂ J Beutel, Taner Topal, Akhil Mathur, Xinchi Qiu, Javier
Fernandez-Marques, Yan Gao, Lorenzo Sani, KwingÂ Hei Li, Titouan Parcollet,
Pedro PortoÂ Buarque deÂ GusmÃ£o, etÂ al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.2.1" class="ltx_text" style="font-size:80%;">â€œFlower: A friendly federated learning framework,â€
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.3.1" class="ltx_text" style="font-size:80%;">2022.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2311.13042" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2311.13043" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2311.13043">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2311.13043" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2311.13045" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 18:01:08 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
