<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2406.19237] FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts</title><meta property="og:description" content="Existing benchmarks for visual question answering lack in visual grounding and complexity, particularly in evaluating spatial reasoning skills. We introduce FlowVQA, a novel benchmark aimed at assessing the capabilitie…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2406.19237">

<!--Generated on Fri Jul  5 23:39:34 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line" lang="en">
<h1 class="ltx_title ltx_title_document">FlowVQA: Mapping Multimodal Logic in 
<br class="ltx_break">Visual Question Answering with Flowcharts</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Shubhankar Singh<sup id="id1.1.id1" class="ltx_sup">1</sup><sup id="id2.2.id2" class="ltx_sup">†</sup>,
Purvi Chaurasia<sup id="id3.3.id3" class="ltx_sup">2</sup><sup id="id4.4.id4" class="ltx_sup">†</sup>,
<span id="id5.5.id5" class="ltx_text ltx_font_bold">Yerram Varun<sup id="id5.5.id5.1" class="ltx_sup"><span id="id5.5.id5.1.1" class="ltx_text ltx_font_medium">3</span></sup></span> , <span id="id6.6.id6" class="ltx_text ltx_font_bold">Pranshu Pandya<sup id="id6.6.id6.1" class="ltx_sup"><span id="id6.6.id6.1.1" class="ltx_text ltx_font_medium">4</span></sup><sup id="id6.6.id6.2" class="ltx_sup"><span id="id6.6.id6.2.1" class="ltx_text ltx_font_medium">*</span></sup></span>,
<br class="ltx_break"><span id="id7.7.id7" class="ltx_text ltx_font_bold">Vatsal Gupta<sup id="id7.7.id7.1" class="ltx_sup"><span id="id7.7.id7.1.1" class="ltx_text ltx_font_medium">4</span></sup><sup id="id7.7.id7.2" class="ltx_sup"><span id="id7.7.id7.2.1" class="ltx_text ltx_font_medium">*</span></sup></span>,
<span id="id8.8.id8" class="ltx_text ltx_font_bold">Vivek Gupta<sup id="id8.8.id8.1" class="ltx_sup"><span id="id8.8.id8.1.1" class="ltx_text ltx_font_medium">5</span></sup><sup id="id8.8.id8.2" class="ltx_sup"><span id="id8.8.id8.2.1" class="ltx_text ltx_font_medium">‡</span></sup></span>, <span id="id9.9.id9" class="ltx_text ltx_font_bold">Dan Roth<sup id="id9.9.id9.1" class="ltx_sup"><span id="id9.9.id9.1.1" class="ltx_text ltx_font_medium">5</span></sup></span> 
<br class="ltx_break"><sup id="id10.10.id10" class="ltx_sup">1</sup>Mercer Mettl,
<sup id="id11.11.id11" class="ltx_sup">2</sup>IGDTUW New Delhi,
<sup id="id12.12.id12" class="ltx_sup">3</sup>Google Research
<br class="ltx_break"><sup id="id13.13.id13" class="ltx_sup">4</sup>Indian Institute of Technology Guwahati,
<sup id="id14.14.id14" class="ltx_sup">5</sup>University of Pennsylvania 
<br class="ltx_break"><span id="id15.15.id15" class="ltx_text ltx_font_typewriter">shubhankar.singh@mercer.com</span>, <span id="id16.16.id16" class="ltx_text ltx_font_typewriter">purvi069btcsai21@igdtuw.ac.in</span>, 
<br class="ltx_break"><span id="id17.17.id17" class="ltx_text ltx_font_typewriter">vyerram@google.com</span>, <span id="id18.18.id18" class="ltx_text ltx_font_typewriter">{p.pandya,g.vatsal}@iitg.ac.in</span>, 
<br class="ltx_break"><span id="id19.19.id19" class="ltx_text ltx_font_typewriter">{gvivek, danroth}@seas.upenn.edu</span> 
<br class="ltx_break">
</span><span class="ltx_author_notes"> , †  contributed equally, ‡ primary mentor &amp; corresponding author</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id20.id1" class="ltx_p"><span id="id20.id1.1" class="ltx_text">Existing benchmarks for visual question answering lack in visual grounding and complexity, particularly in evaluating spatial reasoning skills. We introduce FlowVQA, a novel benchmark aimed at assessing the capabilities of visual question-answering multimodal language models in reasoning with flowcharts as visual contexts. FlowVQA comprises 2,272 carefully generated and human-verified flowchart images from three distinct content sources, along with 22,413 diverse question-answer pairs, to test a spectrum of reasoning tasks, including information localization, decision-making, and logical progression. We conduct a thorough baseline evaluation on a suite of both open-source and proprietary multimodal language models using various strategies, followed by an analysis of directional bias. The results underscore the benchmark’s potential as a vital tool for advancing the field of multimodal modeling, providing a focused and challenging environment for enhancing model performance in visual and logical reasoning tasks.</span></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<figure id="S1.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2406.19237/assets/Figures/a.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_portrait" width="509" height="699" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S1.F1.tab1" class="ltx_table ltx_figure_panel ltx_align_center">
<table id="S1.F1.tab1.1" class="ltx_tabular ltx_align_middle">
<tr id="S1.F1.tab1.1.1" class="ltx_tr">
<td id="S1.F1.tab1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.F1.tab1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.F1.tab1.1.1.1.1.1" class="ltx_p" style="width:411.9pt;">Q. Derek wants to ensure that the sheet was successfully copied before reporting back to Melissa. What should Derek see or do next to ensure the task was completed correctly?</span>
<span id="S1.F1.tab1.1.1.1.1.2" class="ltx_p">A. He should look for a success message and dismiss the dialogue by clicking ’OK’.</span>
</span>
</td>
</tr>
</table>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>A zoomed-in section of a flowchart in our resource set along with a correspnding QA pair. wiki00203: "How To Convert an Old Google Spreadsheet to Google Sheets." A detailed example of a flowchart along with its question-answer pairs is outlined in Appendix <a href="#A1" title="Appendix A Flowchart QA Example ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a>. </figcaption>
</figure>
<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Since the inception of Vision Language Models (VLMs), tasks and benchmarks for visual question answering (VQA) and reasoning have received significant attention. Most benchmarks evaluate pre-trained model extraction capabilities, neglecting their ability to comprehend complex spatial relationships and visual logical reasoning. Research on spacial path following or visual sequential reasoning in VLMs is limited. Current benchmarks for assessing VLM reasoning abilities mainly fall under VQA, a task formalized by <cite class="ltx_cite ltx_citemacro_citet">Goyal et al. (<a href="#bib.bib7" title="" class="ltx_ref">2017</a>)</cite>, which involves generating responses to questions based on a given image. These works evaluate the spatial reasoning and visual information extraction abilities of VLMs.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Visual Grounding (VG) of a visual question-answering system evaluates models’ abilities to attribute their generations to different image regions referenced in the query <cite class="ltx_cite ltx_citemacro_cite">Reich et al. (<a href="#bib.bib29" title="" class="ltx_ref">2023</a>)</cite>. The absence of VG has been a frequent issue among the current VQA systems, manifesting in an over-reliance on irrelevant parts of images or a complete disregard for the visual modality. Existing benchmarks <cite class="ltx_cite ltx_citemacro_cite">Yue et al. (<a href="#bib.bib44" title="" class="ltx_ref">2023</a>)</cite> require models to rely on pre-trained knowledge to answer queries posed on image contexts. In this work, we aim to test the capabilities of VLMs in following visual information without any pre-existing knowledge.
To accomplish this, we delve into the realm of flowcharts, as depicted in figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, which entail intricate structural configurations and path reconstruction, a considerably more challenging task compared to mere image comprehension.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Flowcharts <span id="S1.p3.1.1" class="ltx_text ltx_font_bold">emphasize sequential and logical reasoning</span>, as they necessitate traversal of steps or decisions in a specific sequence. Flowcharts are <span id="S1.p3.1.2" class="ltx_text ltx_font_bold">inherently visual</span>, and provide a clear and structured method for representing processes, decision paths, and flows. Unlike traditional text, which flows linearly, flowcharts require an understanding of <span id="S1.p3.1.3" class="ltx_text ltx_font_bold">directional logic</span>; their flow is often multi-directional, representing various paths that can be taken based on certain conditions or decisions. Despite being long and complex, flowcharts have <em id="S1.p3.1.4" class="ltx_emph ltx_font_italic">compact</em>, <em id="S1.p3.1.5" class="ltx_emph ltx_font_italic">systematic</em> representations and provide insights regarding information in a step-by-step manner.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In this paper, we set out to answer a crucial question: <em id="S1.p4.1.1" class="ltx_emph ltx_font_italic">"Can modern Vision Language Models effectively handle challenges that demand understanding both structural and semantic aspects, along with capturing macroscopic and granular context within visually complex yet straightforward flowcharts?"</em> To tackle this question, we introduce <span id="S1.p4.1.2" class="ltx_text ltx_font_bold">FlowVQA</span>, a novel benchmark comprising intricate structural and path-based questions posed on lengthy flowchart images. We propose a novel approach to Visual Question Answering (VQA) on Flowchart tailored for VLM, with a focus on harnessing flowcharts as the primary contextual framework for visual logic and spatial reasoning.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p"><span id="S1.p5.1.1" class="ltx_text ltx_font_bold">FlowVQA</span> consists of 2,272 Mermaid.js flowchart scripts generated with human input, sourced from process workflow articles like Instructables and WikiHow, as well as Code. Accompanying these are 22,413 Q/A pairs covering various reasoning skills like information localization, fact retrieval, scenario deductions, flow reasoning, and topological understanding. The creation process involves a meticulous multi-step machine generation and human verification to discard up to 51% of samples, ensuring they meet high standards of challenge, coherence, and insightfulness. This rigorous process grounds the flowchart reasoning in textual domain, enriching the visual task complexity. Extensive experimentation revealed that both closed and open-source Vision Language Models (VLMs), equipped with a range of prompting strategies and fine-tuning techniques, struggled to execute visual and spatial reasoning tasks within the FlowVQA dataset. Moreover, our findings highlighted a directional bias and non-uniform performance pattern across flowcharts of varying lengths exhibited by these VLMs. Our contributions are the following:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">Introduction of VQA for FlowCharts, focusing on visual logic and spatial reasoning, filling a gap in previous benchmarks.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;padding-top:0.8pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Development of a detailed framework for generating intricate VQA samples transitioning from text to visual domains, ensuring quality, complexity, and accuracy via rigorous verification.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;padding-top:0.8pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Introducing the novel benchmark FlowVQA, consisting of 2,272 high-quality Flowchart Images and 22,413 Q/A samples spanning four distinct question types, created using the framework.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;padding-top:0.8pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">Thorough evaluation of closed and open-source VLMs, employing various prompting strategies and fine-tuning methods. An analysis of directional bias and non-uniform performance across different flowchart lengths.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">The FlowVQA dataset, along with modeling and evaluation scripts, generation pipeline and prompts, and the human verification platform, can be accessed at <a target="_blank" href="https://flowvqa.github.io/" title="" class="ltx_ref ltx_href">https://flowvqa.github.io/</a>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Proposed FlowVQA Resource</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In this section, we will see the details of the construction of <span id="S2.p1.1.1" class="ltx_text ltx_font_bold">FlowVQA</span>. We outline the process of collection of raw data from wild sources, multi-step generation of mermaid scripts and flowchart images and complex Q/A creation.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2406.19237/assets/Figures/flowchart_generation.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="509" height="362" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Our dataset’s generation pipeline encompasses the creation of flowcharts. As previously outlined, we employ a comprehensive two-step process to derive high-quality flowcharts from source texts. Additionally, to guarantee accurate generation, a cross-verification mechanism is implemented.</figcaption>
</figure>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Flowchart Sources</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">We draw input texts from three primary sources: <span id="S2.SS1.p1.1.1" class="ltx_text ltx_font_bold">WikiHow</span> articles, <span id="S2.SS1.p1.1.2" class="ltx_text ltx_font_bold">Instructables</span> DIY blogs, and <span id="S2.SS1.p1.1.3" class="ltx_text ltx_font_bold">FloCo</span> <cite class="ltx_cite ltx_citemacro_cite">Shukla et al. (<a href="#bib.bib30" title="" class="ltx_ref">2023a</a>)</cite> code snippets. WikiHow and Instructables provide <span id="S2.SS1.p1.1.4" class="ltx_text ltx_font_italic">step-by-step instructions</span> for everyday tasks, while the FloCo dataset, <span id="S2.SS1.p1.1.5" class="ltx_text ltx_font_italic">a flowchart-to-code</span> resource, features low-complexity code samples. We categorize all the WikiHow articles, Instructables DIY based on the domains of these articles. FloCo code snippets are categorized into <em id="S2.SS1.p1.1.6" class="ltx_emph ltx_font_italic">code</em> category. The distribution across categories is outlined in Appendix <a href="#A2" title="Appendix B Dataset Distribution ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">We manually select high-quality code snippets from FloCo to ensure uniformity in our pipeline across all text sources. FloCo image samples enable us to iteratively compare the generated flowcharts with the original samples. This step was crucial as it helped perfect our prompts and allow applicability to the WikiHow and Instructables set. We sample 1,268 WikiHow articles, 789 Instructables blogs, and 475 FloCo examples as an input to our human verification pipeline.</p>
</div>
<figure id="S2.T1" class="ltx_table">
<table id="S2.T1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S2.T1.1.1" class="ltx_tr">
<td id="S2.T1.1.1.1" class="ltx_td ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;"></td>
<td id="S2.T1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S2.T1.1.1.2.1" class="ltx_text ltx_font_bold">WikiHow</span></td>
<td id="S2.T1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S2.T1.1.1.3.1" class="ltx_text ltx_font_bold">Instructables</span></td>
<td id="S2.T1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S2.T1.1.1.4.1" class="ltx_text ltx_font_bold">FloCo</span></td>
</tr>
<tr id="S2.T1.1.2" class="ltx_tr">
<td id="S2.T1.1.2.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">Source Texts</td>
<td id="S2.T1.1.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">1,914</td>
<td id="S2.T1.1.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">943</td>
<td id="S2.T1.1.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">700</td>
</tr>
<tr id="S2.T1.1.3" class="ltx_tr">
<td id="S2.T1.1.3.1" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;">Mermaid.js Scripts</td>
<td id="S2.T1.1.3.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;">1,500</td>
<td id="S2.T1.1.3.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;">792</td>
<td id="S2.T1.1.3.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;">575</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>FlowVQA Generation resources.</figcaption>
</figure>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p"><span id="S2.SS1.p3.1.1" class="ltx_text ltx_font_bold">Generation and Filteration</span>. GPT-4 based data generation of data and benchmarks is prevalent <cite class="ltx_cite ltx_citemacro_cite">Han et al. (<a href="#bib.bib8" title="" class="ltx_ref">2023</a>)</cite> in prior works. Machine generation method for flowcharts and Q/A has several advantages to crowdsourcing: (i) The complex and intricate process of creating flowcharts and Q/A pairs constitutes a laborious, efficient and a time-intensive task for human workers, (ii) Using GPT-4 for the generation of structured representations and subsequent conversion into flowcharts and Q/A pairs enables rapid scaling, (iii) The Stochastic nature of LLMs helps in the creation of an unbiased and diverse Q/A dataset. To produce Flowchart and Q/A Samples, we employ an automated ’generate-and-test’ approach, where we exhaustively generate questions of multiple reasoning types and apply rigorous filtration to maintain the quality, hardness, and correctness of samples through effective prompting with GPT-4. Our meticulous verification through experts and rubrics, along with our custom-built annotation platform, ensures a thorough and impartial evaluation of both flowcharts and Q/A pairs.</p>
</div>
<figure id="S2.T2" class="ltx_table">
<table id="S2.T2.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S2.T2.1.1" class="ltx_tr">
<td id="S2.T2.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S2.T2.1.1.1.1" class="ltx_text ltx_font_bold">Source</span></td>
<td id="S2.T2.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T2.1.1.2.1" class="ltx_text ltx_font_bold"># Samples</span></td>
<td id="S2.T2.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T2.1.1.3.1" class="ltx_text ltx_font_bold">Avg. NPF</span></td>
<td id="S2.T2.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T2.1.1.4.1" class="ltx_text ltx_font_bold">Avg. EPF</span></td>
<td id="S2.T2.1.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T2.1.1.5.1" class="ltx_text ltx_font_bold">Avg. Width</span></td>
<td id="S2.T2.1.1.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T2.1.1.6.1" class="ltx_text ltx_font_bold">Avg. Height</span></td>
<td id="S2.T2.1.1.7" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T2.1.1.7.1" class="ltx_text ltx_font_bold">Ratio</span></td>
<td id="S2.T2.1.1.8" class="ltx_td ltx_align_center ltx_border_tt"># <span id="S2.T2.1.1.8.1" class="ltx_text ltx_font_bold">Qs.</span>
</td>
</tr>
<tr id="S2.T2.1.2" class="ltx_tr">
<td id="S2.T2.1.2.1" class="ltx_td ltx_align_left ltx_border_t">Wikihow</td>
<td id="S2.T2.1.2.2" class="ltx_td ltx_align_center ltx_border_t">1,121</td>
<td id="S2.T2.1.2.3" class="ltx_td ltx_align_center ltx_border_t">21.83</td>
<td id="S2.T2.1.2.4" class="ltx_td ltx_align_center ltx_border_t">24.04</td>
<td id="S2.T2.1.2.5" class="ltx_td ltx_align_center ltx_border_t">1568.0</td>
<td id="S2.T2.1.2.6" class="ltx_td ltx_align_center ltx_border_t">5551.81</td>
<td id="S2.T2.1.2.7" class="ltx_td ltx_align_center ltx_border_t">1 : 3.54</td>
<td id="S2.T2.1.2.8" class="ltx_td ltx_align_center ltx_border_t">11,957</td>
</tr>
<tr id="S2.T2.1.3" class="ltx_tr">
<td id="S2.T2.1.3.1" class="ltx_td ltx_align_left">Instructables</td>
<td id="S2.T2.1.3.2" class="ltx_td ltx_align_center">701</td>
<td id="S2.T2.1.3.3" class="ltx_td ltx_align_center">19.76</td>
<td id="S2.T2.1.3.4" class="ltx_td ltx_align_center">21.18</td>
<td id="S2.T2.1.3.5" class="ltx_td ltx_align_center">1568.0</td>
<td id="S2.T2.1.3.6" class="ltx_td ltx_align_center">6629.80</td>
<td id="S2.T2.1.3.7" class="ltx_td ltx_align_center">1 : 4.23</td>
<td id="S2.T2.1.3.8" class="ltx_td ltx_align_center">6,893</td>
</tr>
<tr id="S2.T2.1.4" class="ltx_tr">
<td id="S2.T2.1.4.1" class="ltx_td ltx_align_left">Code</td>
<td id="S2.T2.1.4.2" class="ltx_td ltx_align_center">450</td>
<td id="S2.T2.1.4.3" class="ltx_td ltx_align_center">9.87</td>
<td id="S2.T2.1.4.4" class="ltx_td ltx_align_center">10.85</td>
<td id="S2.T2.1.4.5" class="ltx_td ltx_align_center">1568.0</td>
<td id="S2.T2.1.4.6" class="ltx_td ltx_align_center">2738.15</td>
<td id="S2.T2.1.4.7" class="ltx_td ltx_align_center">1 : 1.75</td>
<td id="S2.T2.1.4.8" class="ltx_td ltx_align_center">3,563</td>
</tr>
<tr id="S2.T2.1.5" class="ltx_tr">
<td id="S2.T2.1.5.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">Full</td>
<td id="S2.T2.1.5.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">2,272</td>
<td id="S2.T2.1.5.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">18.82</td>
<td id="S2.T2.1.5.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">20.54</td>
<td id="S2.T2.1.5.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">1568.0</td>
<td id="S2.T2.1.5.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">5327.13</td>
<td id="S2.T2.1.5.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">1 : 3.40</td>
<td id="S2.T2.1.5.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">22,413</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>FlowVQA Source-wise Statistics: Number of Flowchart Samples, Average Nodes Per Flowchart, Average Edges per Flowchart, Average Image Width (Pixels), Average Image Height (Pixels), Aspect Ratio and Number of Questions. (The flowchart image render is set for a constant width factor)</figcaption>
</figure>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Flowchart Generation</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Our primary supposition for flowchart creation is that <span id="S2.SS2.p1.1.1" class="ltx_text ltx_font_italic">any process-based workflow, regardless of domain, can be converted to a flowchart which highlights key aspects of the process in a detailed step-by-step fashion.</span> We treat the conversion of source article to flowchart Mermaid Scripts as a two-step soft-syntax summarization task. Ideally, we would use real-world flowcharts from external sources such as books and documents, but the availability of such structured data is extremely sparse. Initially, we aimed to use real-life flowcharts, but the scarcity of standardized flowcharts and the lack of sufficient open-source examples made it unfeasible to create a dataset as comprehensive as ours. We decouple the structured summarization into a flowchart script to implement this two-step process.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p"><span id="S2.SS2.p2.1.1" class="ltx_text ltx_font_bold ltx_font_italic">First Step</span>. We query GPT-4 with the source text to generate a step-by-step structured representation of the text annotated with functional control tags (e.g., “START,” “PROCESS,” “DECISION”). This step converts the source text into a tagged textual representation suitable for converting into mermaid flowchart scripts. For FloCo-sourced texts, we generate pseudocode for the code scripts as the input to the next step.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p"><span id="S2.SS2.p3.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Second Step</span>. In this step, we generate the Mermaid.js flowchart script(top-down) using the output of the <em id="S2.SS2.p3.1.2" class="ltx_emph ltx_font_italic">first step</em> by querying GPT-4 with a template Mermaid.js script. The control tags facilitate mapping the steps to the node types used in the script. Constraining points are provided alongside both prompts for improved normalization. The Mermaid.js scripts are then compiled to create high-resolution PNG images.</p>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<p id="S2.SS2.p4.1" class="ltx_p">Table <a href="#S2.T1" title="Table 1 ‣ 2.1 Flowchart Sources ‣ 2 Proposed FlowVQA Resource ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> represents the number of samples after the two-step conversion process. We exclude the scripts and representations with minor syntactical and rendering errors. Figure <a href="#S2.F2" title="Figure 2 ‣ 2 Proposed FlowVQA Resource ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> showcases the generation pipeline of the flowcharts in our dataset. Appendix <a href="#A4.SS1" title="D.1 Flowchart Creation ‣ Appendix D Prompts for Generation ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">D.1</span></a>
lists the prompts used in <span id="S2.SS2.p4.1.1" class="ltx_text ltx_font_italic">first step</span> and <span id="S2.SS2.p4.1.2" class="ltx_text ltx_font_italic">second step</span>.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Question Answer Creation</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">We curate four question types designed to analyze and test different aspects: Fact Retrieval, Applied Scenario, Flow Referential and Topological Question and Answer. First three can be broadly categorized under granular flowchart comprehension while topological tests structural information.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p"><span id="S2.SS3.p2.1.1" class="ltx_text ltx_font_bold ltx_font_italic">T1. Fact Retrieval:</span> These simple questions involve the localization and retrieval of direct factual information from flowchart’s nodes. Despite being simple, they still necessitate image analysis and retrieving relevant cues that localize the final answer.</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<p id="S2.SS3.p3.1" class="ltx_p"><span id="S2.SS3.p3.1.1" class="ltx_text ltx_font_bold ltx_font_italic">T2. Applied Scenario:</span> These questions describe a real-life scenario and test the models’ application of the flowchart to a practical problem. These questions capture reasoning skills used by humans parsing flowcharts in day-to-day life. It leads to interesting puzzle-like word problems that test the understanding of decision steps, content, and reasoning in the presence of distractor context, which needs to be filtered to understand the question.</p>
</div>
<div id="S2.SS3.p4" class="ltx_para">
<p id="S2.SS3.p4.1" class="ltx_p"><span id="S2.SS3.p4.1.1" class="ltx_text ltx_font_bold ltx_font_italic">T3. Flow Referential:</span> In these questions, A random sub-graph/section of the flowchart, usually involving a decision node, is considered, and a question is formulated on backward-forward flow with decision-based logic. It assesses granular path dynamics in a flowchart.</p>
</div>
<div id="S2.SS3.p5" class="ltx_para">
<p id="S2.SS3.p5.1" class="ltx_p"><span id="S2.SS3.p5.1.1" class="ltx_text ltx_font_bold ltx_font_italic">T4. Topological:</span> This question type addresses the larger topology of a flowchart, requiring analysis of the flowchart at a more macroscopic level to give an answer related to the structural topology of the graph. These questions are created by parsing Mermaid.js scripts to convert them into an adjacency matrix representing the flowchart in the form of a graph. It generates template-based questions that usually have quantitative correct answers.</p>
</div>
<figure id="S2.F3" class="ltx_figure"><img src="/html/2406.19237/assets/Figures/QA_generation.png" id="S2.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="568" height="244" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Our dataset incorporates a question creation pipeline tailored to accommodate various question types. As previously noted, each question type undergoes generation via a carefully crafted prompt, meticulously designed to achieve the specific objectives associated with that type of question</figcaption>
</figure>
<figure id="S2.T3" class="ltx_table">
<table id="S2.T3.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S2.T3.1.1" class="ltx_tr">
<td id="S2.T3.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S2.T3.1.1.1.1" class="ltx_text ltx_font_bold">Statistics</span></td>
<td id="S2.T3.1.1.2" class="ltx_td ltx_border_tt"></td>
<td id="S2.T3.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T3.1.1.3.1" class="ltx_text ltx_font_bold">Train</span></td>
<td id="S2.T3.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T3.1.1.4.1" class="ltx_text ltx_font_bold">Test</span></td>
<td id="S2.T3.1.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T3.1.1.5.1" class="ltx_text ltx_font_bold">Total</span></td>
</tr>
<tr id="S2.T3.1.2" class="ltx_tr">
<td id="S2.T3.1.2.1" class="ltx_td ltx_align_left ltx_border_t" colspan="2"><span id="S2.T3.1.2.1.1" class="ltx_text ltx_font_bold">Total Flowcharts</span></td>
<td id="S2.T3.1.2.2" class="ltx_td ltx_align_center ltx_border_t">1,319</td>
<td id="S2.T3.1.2.3" class="ltx_td ltx_align_center ltx_border_t">953</td>
<td id="S2.T3.1.2.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">2,272</td>
</tr>
<tr id="S2.T3.1.3" class="ltx_tr">
<td id="S2.T3.1.3.1" class="ltx_td ltx_align_left" colspan="2"><span id="S2.T3.1.3.1.1" class="ltx_text ltx_font_bold">Avg. Nodes</span></td>
<td id="S2.T3.1.3.2" class="ltx_td ltx_align_center">18.63</td>
<td id="S2.T3.1.3.3" class="ltx_td ltx_align_center">19.09</td>
<td id="S2.T3.1.3.4" class="ltx_td ltx_nopad_r ltx_align_center">18.82</td>
</tr>
<tr id="S2.T3.1.4" class="ltx_tr">
<td id="S2.T3.1.4.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="4"><span id="S2.T3.1.4.1.1" class="ltx_text ltx_font_bold">QA</span></td>
<td id="S2.T3.1.4.2" class="ltx_td ltx_align_left ltx_border_t">Fact Retrieval</td>
<td id="S2.T3.1.4.3" class="ltx_td ltx_align_center ltx_border_t">2,654</td>
<td id="S2.T3.1.4.4" class="ltx_td ltx_align_center ltx_border_t">1,878</td>
<td id="S2.T3.1.4.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">4,532</td>
</tr>
<tr id="S2.T3.1.5" class="ltx_tr">
<td id="S2.T3.1.5.1" class="ltx_td ltx_align_left">Applied Scenario</td>
<td id="S2.T3.1.5.2" class="ltx_td ltx_align_center">2,640</td>
<td id="S2.T3.1.5.3" class="ltx_td ltx_align_center">1,936</td>
<td id="S2.T3.1.5.4" class="ltx_td ltx_nopad_r ltx_align_center">4,576</td>
</tr>
<tr id="S2.T3.1.6" class="ltx_tr">
<td id="S2.T3.1.6.1" class="ltx_td ltx_align_left">Flow Referential</td>
<td id="S2.T3.1.6.2" class="ltx_td ltx_align_center">2,128</td>
<td id="S2.T3.1.6.3" class="ltx_td ltx_align_center">1,585</td>
<td id="S2.T3.1.6.4" class="ltx_td ltx_nopad_r ltx_align_center">3,713</td>
</tr>
<tr id="S2.T3.1.7" class="ltx_tr">
<td id="S2.T3.1.7.1" class="ltx_td ltx_align_left">Topological</td>
<td id="S2.T3.1.7.2" class="ltx_td ltx_align_center">5,516</td>
<td id="S2.T3.1.7.3" class="ltx_td ltx_align_center">4,076</td>
<td id="S2.T3.1.7.4" class="ltx_td ltx_nopad_r ltx_align_center">9,592</td>
</tr>
<tr id="S2.T3.1.8" class="ltx_tr">
<td id="S2.T3.1.8.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" colspan="2"><span id="S2.T3.1.8.1.1" class="ltx_text ltx_font_bold">Total QA</span></td>
<td id="S2.T3.1.8.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">12,938</td>
<td id="S2.T3.1.8.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">9,475</td>
<td id="S2.T3.1.8.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t">22,413</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>QA Resource Split Statistics.</figcaption>
</figure>
<div id="S2.SS3.p6" class="ltx_para">
<p id="S2.SS3.p6.1" class="ltx_p"><span id="S2.SS3.p6.1.1" class="ltx_text ltx_font_bold">Q/A Generation</span>. We construct a prompt to query GPT-4 using the tagged textual representation, Mermaid.js script and text-only few-shot examples to generate high quality Q/A pairs of types, T1, T2 and T3 (listed in Appendix <a href="#A4.SS2" title="D.2 Question Generation ‣ Appendix D Prompts for Generation ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">D.2</span></a>). For each question, we generate three paraphrased gold answers, which allows us to evaluate models irrespective of their generation syntactics and semantics. As part of text-only few-shot examples we pass a variety of creative high-quality examples. Topological Q/A pairs (T4) are generated by parsing the Mermaid script, converting the graph into an adjacency matrix, and creating template-based questions. Answers are usually quantitative. After formulating the template-based answers, we obtain two additional paraphrased answers for each template answer to achieve three gold-standard answers, thus maintaining the standard with the other question type for three gold short answers.</p>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Human Verification Pipeline and Platform</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">To ensure strong validity of our work, we establish a robust human verification pipeline for our models and flowcharts. All generated outputs for flowcharts and subsequent Q/A pairs undergo a rigorous quality check by a team of five expert annotators. As we adhere to a "Generate-and-test" paradigm (section <a href="#S2" title="2 Proposed FlowVQA Resource ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>), we provide detailed rubrics for both flowchart and Q/A pair verification and annotation, with parameters such as logical flow, complexity, context alignment and more, for flowcharts and Q/A pairs which allow the annotators be strict and thorough. To assist with their work and eliminate any bias and stress, we also provide them with a detailed, custom-built annotation platform to provide scores, filter out, etc. This custom platform enables parallel viewing.</p>
</div>
<figure id="S2.T4" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<table id="S2.T4.1" class="ltx_tabular ltx_centering ltx_figure_panel ltx_align_middle">
<tr id="S2.T4.1.1" class="ltx_tr">
<td id="S2.T4.1.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S2.T4.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T4.1.1.2.1" class="ltx_text ltx_font_bold"># Samples</span></td>
<td id="S2.T4.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T4.1.1.3.1" class="ltx_text ltx_font_bold"># T1</span></td>
<td id="S2.T4.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T4.1.1.4.1" class="ltx_text ltx_font_bold"># T2</span></td>
<td id="S2.T4.1.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T4.1.1.5.1" class="ltx_text ltx_font_bold"># T3</span></td>
</tr>
<tr id="S2.T4.1.2" class="ltx_tr">
<td id="S2.T4.1.2.1" class="ltx_td ltx_align_left ltx_border_t">Pre</td>
<td id="S2.T4.1.2.2" class="ltx_td ltx_align_center ltx_border_t">2,532</td>
<td id="S2.T4.1.2.3" class="ltx_td ltx_align_center ltx_border_t">8,932</td>
<td id="S2.T4.1.2.4" class="ltx_td ltx_align_center ltx_border_t">9,138</td>
<td id="S2.T4.1.2.5" class="ltx_td ltx_align_center ltx_border_t">7,262</td>
</tr>
<tr id="S2.T4.1.3" class="ltx_tr">
<td id="S2.T4.1.3.1" class="ltx_td ltx_align_left">Post</td>
<td id="S2.T4.1.3.2" class="ltx_td ltx_align_center">2,272</td>
<td id="S2.T4.1.3.3" class="ltx_td ltx_align_center">4,532</td>
<td id="S2.T4.1.3.4" class="ltx_td ltx_align_center">4,576</td>
<td id="S2.T4.1.3.5" class="ltx_td ltx_align_center">3,713</td>
</tr>
<tr id="S2.T4.1.4" class="ltx_tr">
<td id="S2.T4.1.4.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">% drop</td>
<td id="S2.T4.1.4.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">10.3%</td>
<td id="S2.T4.1.4.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">49.3%</td>
<td id="S2.T4.1.4.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">50%</td>
<td id="S2.T4.1.4.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">48.9%</td>
</tr>
</table>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>FlowVQA Annotation-based filtering stats pre and post-verification and filtration for number of flowchart samples and QA Types <span id="S2.T4.5.1" class="ltx_text ltx_font_italic">T1</span>, <span id="S2.T4.6.2" class="ltx_text ltx_font_italic">T2</span> and <span id="S2.T4.7.3" class="ltx_text ltx_font_italic">T3</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S2.T4.8" class="ltx_p ltx_figure_panel ltx_align_center">.</p>
</div>
</div>
</figure>
<div id="S2.SS4.p2" class="ltx_para">
<p id="S2.SS4.p2.1" class="ltx_p"><span id="S2.SS4.p2.1.1" class="ltx_text ltx_font_bold">Annotation Platform</span>. Our custom-built annotation platform consists of UI, where we pass the flowchart and Q/A pairs together so they can be viewed simultaneously. The annotators provide quality scores<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>captures the consistency, correctness and complexity.</span></span></span> for all components of the dataset and a final holistic score<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>captures the relevancy between the components.</span></span></span>. We filter out flowcharts below a fixed quality threshold and Q/A pairs which rate below average. Topological questions are not passed into the platform as they are hard-template-based and obtained via scripting. All verification products are verified with two separate supervising experts who ensure the quality of annotations is consistent and scores remain unbiased. The verification lasts for ten days from start to end.</p>
</div>
<div id="S2.SS4.p3" class="ltx_para">
<p id="S2.SS4.p3.1" class="ltx_p">The final samples, see Appendix <a href="#A1" title="Appendix A Flowchart QA Example ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a>, ensure appropriate complexity and correctness of flowcharts, questions and corresponding answers. Figure <a href="#S2.F3" title="Figure 3 ‣ 2.3 Question Answer Creation ‣ 2 Proposed FlowVQA Resource ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> showcases the complete question-answer generation pipeline used to create the dataset.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experimental Evaluation</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We address the following research questions through our experiments:</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p"><span id="S3.p2.1.1" class="ltx_text ltx_font_bold ltx_font_italic">RQ1.</span> Does the introduced visual multimodal dataset present a significant challenge to current multimodal language learning models (VLMs), and can it provide valuable insights that could contribute to their future advancement?</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p"><span id="S3.p3.1.1" class="ltx_text ltx_font_bold ltx_font_italic">RQ2.</span> Is the efficacy of VLMs influenced by factors such as (a) the source of flowcharts, (b) the type of questions posed, and (c) the level of complexity inherent in the flowcharts?</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p"><span id="S3.p4.1.1" class="ltx_text ltx_font_bold ltx_font_italic">RQ3.</span> Are there ways to enhance the performance of visual question answering tasks related to flowcharts through the use of specific directives tailored to flowcharts? Moreover, does the process of fine-tuning these models with the train split of FlowVQA dataset improve their proficiency in handling questions tied to flowchart-based data?</p>
</div>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.1" class="ltx_p"><span id="S3.p5.1.1" class="ltx_text ltx_font_bold ltx_font_italic">RQ4.</span> Is there an observable directional bias in existing VLMs when they are applied to flowchart analysis?</p>
</div>
<div id="S3.p6" class="ltx_para">
<p id="S3.p6.1" class="ltx_p"><span id="S3.p6.1.1" class="ltx_text ltx_font_bold">Limitations of Smaller Models</span>. FlowVQA represents a complex multimodal challenge that requires visual logic and reasoning across large-scale high-resolution images. In our assessment of several widely utilized open-source multimodal language learning models (VLMs) – including <span id="S3.p6.1.2" class="ltx_text ltx_font_bold">LLaVA</span> <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a href="#bib.bib19" title="" class="ltx_ref">2023b</a>)</cite>, <span id="S3.p6.1.3" class="ltx_text ltx_font_bold">OpenFlamingo</span> <cite class="ltx_cite ltx_citemacro_cite">Awadalla et al. (<a href="#bib.bib2" title="" class="ltx_ref">2023</a>)</cite>, <span id="S3.p6.1.4" class="ltx_text ltx_font_bold">BLiPv2</span> <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a href="#bib.bib14" title="" class="ltx_ref">2023a</a>)</cite>, <span id="S3.p6.1.5" class="ltx_text ltx_font_bold">mPLUG-OWL</span> <cite class="ltx_cite ltx_citemacro_cite">Ye et al. (<a href="#bib.bib43" title="" class="ltx_ref">2023b</a>)</cite>, Sphinx <cite class="ltx_cite ltx_citemacro_cite">Lin et al. (<a href="#bib.bib17" title="" class="ltx_ref">2023</a>)</cite> — we observe that their performance on our test dataset <span id="S3.p6.1.6" class="ltx_text ltx_font_bold">is notably subpar (&lt;10%)</span>. These multimodal language learning models (VLMs) lack a sizable vision encoder, leading to the internal distortion of flowchart images with high aspect ratios when passed into the vision encoder. Furthermore, even if they can interpret the image a bit, their inadequate reasoning abilities render them extremely ineffective for any further analysis utilizing this resource.</p>
</div>
<div id="S3.p7" class="ltx_para">
<p id="S3.p7.1" class="ltx_p"><span id="S3.p7.1.1" class="ltx_text ltx_font_bold">Models for Comparison</span>. We perform evaluations on FlowVQA with <span id="S3.p7.1.2" class="ltx_text ltx_font_bold">five</span> different VLMs. We employ <span id="S3.p7.1.3" class="ltx_text ltx_font_bold">GPT-4V</span> <cite class="ltx_cite ltx_citemacro_cite">OpenAI (<a href="#bib.bib27" title="" class="ltx_ref">2023</a>)</cite> and <span id="S3.p7.1.4" class="ltx_text ltx_font_bold">Gemini Pro</span> <cite class="ltx_cite ltx_citemacro_cite">Anil et al. (<a href="#bib.bib1" title="" class="ltx_ref">2023</a>)</cite><span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>We use the preview version for Gemini Pro at Vertex API <cite class="ltx_cite ltx_citemacro_citep">(<a href="#bib.bib38" title="" class="ltx_ref">Vertex, </a>)</cite>. Gemini Ultra is/was not made public yet.</span></span></span> to test the visual understanding capabilities of best proprietary (closed) models available. We also employ three open-source models.
<span id="S3.p7.1.5" class="ltx_text ltx_font_bold">CogAgent-VQA</span> <cite class="ltx_cite ltx_citemacro_cite">Hong et al. (<a href="#bib.bib9" title="" class="ltx_ref">2023</a>)</cite> is an 18-
billion-parameter visual language model (VLM) specializing in GUI understanding and navigation (fine tuned on smaller VQA Tasks). This model supports inputs at the resolutions of 1120x1120, enabling it to recognize tiny page elements and text in the flowcharts.</p>
</div>
<figure id="S3.T5" class="ltx_table">
<table id="S3.T5.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T5.1.1" class="ltx_tr">
<td id="S3.T5.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T5.1.1.1.1" class="ltx_text ltx_font_bold">Open Model</span></td>
<td id="S3.T5.1.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T5.1.1.2.1" class="ltx_text ltx_font_bold">LM</span></td>
<td id="S3.T5.1.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T5.1.1.3.1" class="ltx_text ltx_font_bold">VM</span></td>
<td id="S3.T5.1.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T5.1.1.4.1" class="ltx_text ltx_font_bold">Norm. Res.</span></td>
</tr>
<tr id="S3.T5.1.2" class="ltx_tr">
<td id="S3.T5.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">CogAgent-VQA</td>
<td id="S3.T5.1.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Vicuna-7B</td>
<td id="S3.T5.1.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">ViT-4.4B</td>
<td id="S3.T5.1.2.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">1120x1120</td>
</tr>
<tr id="S3.T5.1.3" class="ltx_tr">
<td id="S3.T5.1.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:1.0pt;padding-right:1.0pt;">InternLM<sub id="S3.T5.1.3.1.1" class="ltx_sub">-X-Comp.2</sub>
</td>
<td id="S3.T5.1.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Intern-LM2-7B</td>
<td id="S3.T5.1.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">ViT-304M</td>
<td id="S3.T5.1.3.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">490x490</td>
</tr>
<tr id="S3.T5.1.4" class="ltx_tr">
<td id="S3.T5.1.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" style="padding-left:1.0pt;padding-right:1.0pt;">Qwen-VL-chat</td>
<td id="S3.T5.1.4.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:1.0pt;padding-right:1.0pt;">Qwen-VL-7B</td>
<td id="S3.T5.1.4.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:1.0pt;padding-right:1.0pt;">ViT-1.9B</td>
<td id="S3.T5.1.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:1.0pt;padding-right:1.0pt;">448x448</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Open Baseline Models. VLMs are composed of a Language model that encodes text and a visual model that encodes the images. LM: Language Model, VM: denotes vision model.</figcaption>
</figure>
<div id="S3.p8" class="ltx_para">
<p id="S3.p8.1" class="ltx_p"><span id="S3.p8.1.1" class="ltx_text ltx_font_bold">InternLM-X-Composer2</span> <cite class="ltx_cite ltx_citemacro_cite">Dong et al. (<a href="#bib.bib5" title="" class="ltx_ref">2024</a>)</cite> uses a novel approach (PLORA) that applies additional LoRA parameters exclusively to image tokens to ensure that linguistic abilities are not affected, striking a balance between precise vision understanding and text composition.
<span id="S3.p8.1.2" class="ltx_text ltx_font_bold">Qwen-VL-chat</span> <cite class="ltx_cite ltx_citemacro_cite">Bai et al. (<a href="#bib.bib3" title="" class="ltx_ref">2023</a>)</cite> is the instruction tuned model in the Qwen-VL series. Its <em id="S3.p8.1.3" class="ltx_emph ltx_font_italic">position-aware vision language adapter</em> ensures that, even though the images are resized to a fixed resolution long image feature contexts are captured effectively by the model. We summarize the base language models and visual models used in our baselines in Table <a href="#S3.T5" title="Table 5 ‣ 3 Experimental Evaluation ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Baseline Evaluation</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">We evaluate the baseline models under multiple settings:</p>
<ol id="S3.I1" class="ltx_enumerate">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p"><span id="S3.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Zero-Shot</span>: Given a flowchart, we prompt the VLM to answer the question with a small instruction and provide a short concise answer.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p"><span id="S3.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Zero-Shot CoT</span>: Given a flowchart, we prompt the VLM with the question to first elicit a rationale and then deduce the final answer <cite class="ltx_cite ltx_citemacro_cite">Wei et al. (<a href="#bib.bib39" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p"><span id="S3.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Text Only Few-Shot CoT with Reasoning Directives</span>: We create a custom prompt outlining the reasoning steps involved in answering questions specific to flowcharts. We scrutinize the areas where improved prompting is necessary for the models and draw inspiration from <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a href="#bib.bib46" title="" class="ltx_ref">2023</a>)</cite>, <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a href="#bib.bib15" title="" class="ltx_ref">2023b</a>)</cite>, and <cite class="ltx_cite ltx_citemacro_cite">Kojima et al. (<a href="#bib.bib13" title="" class="ltx_ref">2023</a>)</cite> to devise a text-only few-shot CoT approach with directional stimulus and step-by-step reasoning. The central objective is to deconstruct complex questions, identify which elements to map, and determine the answer. Each example, or "shot," encompasses four key components: The Question, Directional Stimulus Tags, Step-by-Step Rationale, and the Answer. These distinct parts aid in breaking down the question into relevant segments, offering a logical, step-by-step analysis, and concluding with an answer. We develop this strategy based on its potential effectiveness for flowcharts, with its actual efficacy demonstrated ahead. The few-shot samples we give are dynamic in nature, i.e the each question type gets more similar samples from our train set annotated samples samples for the method.</p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p id="S3.I1.i4.p1.1" class="ltx_p"><span id="S3.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Fine-Tuning</span>: We fine-tune the VLM on the train split of FlowVQA, and then prompt the VLM to answer the question.<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>Due to resource constraints we only Fine-Tune on Qwen-VL-Chat through LoRA Finetuning</span></span></span></p>
</div>
</li>
</ol>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Evaluation Method</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Our methodology adopts an <span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_italic">"AI as an Evaluator"</span> approach similar to <cite class="ltx_cite ltx_citemacro_citet">Fu et al. (<a href="#bib.bib6" title="" class="ltx_ref">2023</a>); Lin and Chen (<a href="#bib.bib16" title="" class="ltx_ref">2023</a>); Chiang and Lee (<a href="#bib.bib4" title="" class="ltx_ref">2023</a>)</cite>. We employ three evaluator models—GPT-3.5 <cite class="ltx_cite ltx_citemacro_cite">Ye et al. (<a href="#bib.bib42" title="" class="ltx_ref">2023a</a>)</cite>, Llama-2 70B <cite class="ltx_cite ltx_citemacro_cite">Touvron et al. (<a href="#bib.bib36" title="" class="ltx_ref">2023</a>)</cite>, and Mixtral 8*7B (Mixtral-of-Experts) <cite class="ltx_cite ltx_citemacro_cite">Jiang et al. (<a href="#bib.bib12" title="" class="ltx_ref">2024</a>)</cite> —to assess the model-generated responses, which are compared against three gold standard short answers and the question (context excluded). The evaluators’ task is to dissect and align the responses, eliciting a detailed rationale that demonstrates Chain of Thought behavior, and then assigning a binary label to indicate whether the response is correct or incorrect. This process essentially boils down the evaluation into a "length-invariant" paraphrase detection task for short text responses, surpassing traditional similarity metrics and rule-based matching in effectiveness. We determine the final label via a majority vote among the evaluator models.</p>
</div>
<figure id="S3.T6" class="ltx_table">
<table id="S3.T6.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T6.1.1" class="ltx_tr">
<td id="S3.T6.1.1.1" class="ltx_td ltx_align_left ltx_border_tt" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.1.1.1" class="ltx_text ltx_font_bold">Model</span></td>
<td id="S3.T6.1.1.2" class="ltx_td ltx_align_left ltx_border_tt" style="padding:0.75pt 3.0pt;">
<span id="S3.T6.1.1.2.1" class="ltx_text"></span> <span id="S3.T6.1.1.2.2" class="ltx_text">
<span id="S3.T6.1.1.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T6.1.1.2.2.1.1" class="ltx_tr">
<span id="S3.T6.1.1.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.1.2.2.1.1.1.1" class="ltx_text ltx_font_bold">Strategy</span></span></span>
</span></span><span id="S3.T6.1.1.2.3" class="ltx_text"></span></td>
<td id="S3.T6.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding:0.75pt 3.0pt;">
<span id="S3.T6.1.1.3.1" class="ltx_text"></span> <span id="S3.T6.1.1.3.2" class="ltx_text">
<span id="S3.T6.1.1.3.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T6.1.1.3.2.1.1" class="ltx_tr">
<span id="S3.T6.1.1.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.1.3.2.1.1.1.1" class="ltx_text ltx_font_bold">MV<sub id="S3.T6.1.1.3.2.1.1.1.1.1" class="ltx_sub">Total</sub></span></span></span>
</span></span><span id="S3.T6.1.1.3.3" class="ltx_text"></span></td>
<td id="S3.T6.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding:0.75pt 3.0pt;">
<span id="S3.T6.1.1.4.1" class="ltx_text"></span> <span id="S3.T6.1.1.4.2" class="ltx_text">
<span id="S3.T6.1.1.4.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T6.1.1.4.2.1.1" class="ltx_tr">
<span id="S3.T6.1.1.4.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.1.4.2.1.1.1.1" class="ltx_text ltx_font_bold">MV<sub id="S3.T6.1.1.4.2.1.1.1.1.1" class="ltx_sub">T1</sub></span></span></span>
</span></span><span id="S3.T6.1.1.4.3" class="ltx_text"></span></td>
<td id="S3.T6.1.1.5" class="ltx_td ltx_align_center ltx_border_tt" style="padding:0.75pt 3.0pt;">
<span id="S3.T6.1.1.5.1" class="ltx_text"></span> <span id="S3.T6.1.1.5.2" class="ltx_text">
<span id="S3.T6.1.1.5.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T6.1.1.5.2.1.1" class="ltx_tr">
<span id="S3.T6.1.1.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.1.5.2.1.1.1.1" class="ltx_text ltx_font_bold">MV<sub id="S3.T6.1.1.5.2.1.1.1.1.1" class="ltx_sub">T2</sub></span></span></span>
</span></span><span id="S3.T6.1.1.5.3" class="ltx_text"></span></td>
<td id="S3.T6.1.1.6" class="ltx_td ltx_align_center ltx_border_tt" style="padding:0.75pt 3.0pt;">
<span id="S3.T6.1.1.6.1" class="ltx_text"></span> <span id="S3.T6.1.1.6.2" class="ltx_text">
<span id="S3.T6.1.1.6.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T6.1.1.6.2.1.1" class="ltx_tr">
<span id="S3.T6.1.1.6.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.1.6.2.1.1.1.1" class="ltx_text ltx_font_bold">MV<sub id="S3.T6.1.1.6.2.1.1.1.1.1" class="ltx_sub">T3</sub></span></span></span>
</span></span><span id="S3.T6.1.1.6.3" class="ltx_text"></span></td>
<td id="S3.T6.1.1.7" class="ltx_td ltx_align_center ltx_border_tt" style="padding:0.75pt 3.0pt;">
<span id="S3.T6.1.1.7.1" class="ltx_text"></span> <span id="S3.T6.1.1.7.2" class="ltx_text">
<span id="S3.T6.1.1.7.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T6.1.1.7.2.1.1" class="ltx_tr">
<span id="S3.T6.1.1.7.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.1.7.2.1.1.1.1" class="ltx_text ltx_font_bold">MV<sub id="S3.T6.1.1.7.2.1.1.1.1.1" class="ltx_sub">T4</sub></span></span></span>
</span></span><span id="S3.T6.1.1.7.3" class="ltx_text"></span></td>
<td id="S3.T6.1.1.8" class="ltx_td ltx_align_center ltx_border_tt" style="padding:0.75pt 3.0pt;">
<span id="S3.T6.1.1.8.1" class="ltx_text"></span> <span id="S3.T6.1.1.8.2" class="ltx_text">
<span id="S3.T6.1.1.8.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T6.1.1.8.2.1.1" class="ltx_tr">
<span id="S3.T6.1.1.8.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.1.8.2.1.1.1.1" class="ltx_text ltx_font_bold">MV<sub id="S3.T6.1.1.8.2.1.1.1.1.1" class="ltx_sub">Wiki</sub></span></span></span>
</span></span><span id="S3.T6.1.1.8.3" class="ltx_text"></span></td>
<td id="S3.T6.1.1.9" class="ltx_td ltx_align_center ltx_border_tt" style="padding:0.75pt 3.0pt;">
<span id="S3.T6.1.1.9.1" class="ltx_text"></span> <span id="S3.T6.1.1.9.2" class="ltx_text">
<span id="S3.T6.1.1.9.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T6.1.1.9.2.1.1" class="ltx_tr">
<span id="S3.T6.1.1.9.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.1.9.2.1.1.1.1" class="ltx_text ltx_font_bold">MV<sub id="S3.T6.1.1.9.2.1.1.1.1.1" class="ltx_sub">Instruct</sub></span></span></span>
</span></span><span id="S3.T6.1.1.9.3" class="ltx_text"></span></td>
<td id="S3.T6.1.1.10" class="ltx_td ltx_align_center ltx_border_tt" style="padding:0.75pt 3.0pt;">
<span id="S3.T6.1.1.10.1" class="ltx_text"></span> <span id="S3.T6.1.1.10.2" class="ltx_text">
<span id="S3.T6.1.1.10.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T6.1.1.10.2.1.1" class="ltx_tr">
<span id="S3.T6.1.1.10.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.1.10.2.1.1.1.1" class="ltx_text ltx_font_bold">MV<sub id="S3.T6.1.1.10.2.1.1.1.1.1" class="ltx_sub">Code</sub></span></span></span>
</span></span><span id="S3.T6.1.1.10.3" class="ltx_text"></span></td>
</tr>
<tr id="S3.T6.1.2" class="ltx_tr">
<td id="S3.T6.1.2.1" class="ltx_td ltx_align_left ltx_border_t" style="padding:0.75pt 3.0pt;" rowspan="3"><span id="S3.T6.1.2.1.1" class="ltx_text">
<span id="S3.T6.1.2.1.1.1" class="ltx_inline-block">
<span id="S3.T6.1.2.1.1.1.1" class="ltx_p"><span id="S3.T6.1.2.1.1.1.1.1" class="ltx_text ltx_font_bold">GPT-4V</span></span>
</span></span></td>
<td id="S3.T6.1.2.2" class="ltx_td ltx_align_left ltx_border_t" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.2.2.1" class="ltx_text ltx_font_bold">Zero-Shot</span></td>
<td id="S3.T6.1.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">61.22</td>
<td id="S3.T6.1.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.2.4.1" class="ltx_text ltx_font_bold">90.72<sup id="S3.T6.1.2.4.1.1" class="ltx_sup"><span id="S3.T6.1.2.4.1.1.1" class="ltx_text ltx_font_medium">*</span></sup></span></td>
<td id="S3.T6.1.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">82.24</td>
<td id="S3.T6.1.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">63.79</td>
<td id="S3.T6.1.2.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">40.62</td>
<td id="S3.T6.1.2.8" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">60.98</td>
<td id="S3.T6.1.2.9" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">60.78</td>
<td id="S3.T6.1.2.10" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">62.65</td>
</tr>
<tr id="S3.T6.1.3" class="ltx_tr">
<td id="S3.T6.1.3.1" class="ltx_td ltx_align_left" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.3.1.1" class="ltx_text ltx_font_bold">Zero-Shot COT</span></td>
<td id="S3.T6.1.3.2" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">65.57</td>
<td id="S3.T6.1.3.3" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">72.79</td>
<td id="S3.T6.1.3.4" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">69.94</td>
<td id="S3.T6.1.3.5" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">73.50</td>
<td id="S3.T6.1.3.6" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.3.6.1" class="ltx_text ltx_font_bold">58.25<sup id="S3.T6.1.3.6.1.1" class="ltx_sup"><span id="S3.T6.1.3.6.1.1.1" class="ltx_text ltx_font_medium">*</span></sup></span></td>
<td id="S3.T6.1.3.7" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.3.7.1" class="ltx_text ltx_font_bold">67.84<sup id="S3.T6.1.3.7.1.1" class="ltx_sup"><span id="S3.T6.1.3.7.1.1.1" class="ltx_text ltx_font_medium">*</span></sup></span></td>
<td id="S3.T6.1.3.8" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">70.89</td>
<td id="S3.T6.1.3.9" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">47.71</td>
</tr>
<tr id="S3.T6.1.4" class="ltx_tr">
<td id="S3.T6.1.4.1" class="ltx_td ltx_align_left" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.4.1.1" class="ltx_text ltx_font_bold">Few-Shot COT<sub id="S3.T6.1.4.1.1.1" class="ltx_sub">D</sub></span></td>
<td id="S3.T6.1.4.2" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.4.2.1" class="ltx_text ltx_font_bold">68.42<sup id="S3.T6.1.4.2.1.1" class="ltx_sup"><span id="S3.T6.1.4.2.1.1.1" class="ltx_text ltx_font_medium">*</span></sup></span></td>
<td id="S3.T6.1.4.3" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">89.02</td>
<td id="S3.T6.1.4.4" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.4.4.1" class="ltx_text ltx_font_bold">89.92<sup id="S3.T6.1.4.4.1.1" class="ltx_sup"><span id="S3.T6.1.4.4.1.1.1" class="ltx_text ltx_font_medium">*</span></sup></span></td>
<td id="S3.T6.1.4.5" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.4.5.1" class="ltx_text ltx_font_bold">81.41<sup id="S3.T6.1.4.5.1.1" class="ltx_sup"><span id="S3.T6.1.4.5.1.1.1" class="ltx_text ltx_font_medium">*</span></sup></span></td>
<td id="S3.T6.1.4.6" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">46.72</td>
<td id="S3.T6.1.4.7" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">63.33</td>
<td id="S3.T6.1.4.8" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.4.8.1" class="ltx_text ltx_font_bold">72.25<sup id="S3.T6.1.4.8.1.1" class="ltx_sup"><span id="S3.T6.1.4.8.1.1.1" class="ltx_text ltx_font_medium">*</span></sup></span></td>
<td id="S3.T6.1.4.9" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.4.9.1" class="ltx_text ltx_font_bold">64.83<sup id="S3.T6.1.4.9.1.1" class="ltx_sup"><span id="S3.T6.1.4.9.1.1.1" class="ltx_text ltx_font_medium">*</span></sup></span></td>
</tr>
<tr id="S3.T6.1.5" class="ltx_tr">
<td id="S3.T6.1.5.1" class="ltx_td ltx_align_left ltx_border_t" style="padding:0.75pt 3.0pt;" rowspan="3"><span id="S3.T6.1.5.1.1" class="ltx_text">
<span id="S3.T6.1.5.1.1.1" class="ltx_inline-block">
<span id="S3.T6.1.5.1.1.1.1" class="ltx_p"><span id="S3.T6.1.5.1.1.1.1.1" class="ltx_text ltx_font_bold">Gemini-Pro-V</span></span>
</span></span></td>
<td id="S3.T6.1.5.2" class="ltx_td ltx_align_left ltx_border_t" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.5.2.1" class="ltx_text ltx_font_bold">Zero-Shot</span></td>
<td id="S3.T6.1.5.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">49.57</td>
<td id="S3.T6.1.5.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">80.08</td>
<td id="S3.T6.1.5.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">70.29</td>
<td id="S3.T6.1.5.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">35.34</td>
<td id="S3.T6.1.5.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">33.86</td>
<td id="S3.T6.1.5.8" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">48.84</td>
<td id="S3.T6.1.5.9" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">48.27</td>
<td id="S3.T6.1.5.10" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">54.36</td>
</tr>
<tr id="S3.T6.1.6" class="ltx_tr">
<td id="S3.T6.1.6.1" class="ltx_td ltx_align_left" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.6.1.1" class="ltx_text ltx_font_bold">Zero-Shot COT</span></td>
<td id="S3.T6.1.6.2" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">58.76</td>
<td id="S3.T6.1.6.3" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">81.21</td>
<td id="S3.T6.1.6.4" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">78.39</td>
<td id="S3.T6.1.6.5" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">62.14</td>
<td id="S3.T6.1.6.6" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">41.99</td>
<td id="S3.T6.1.6.7" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">54.23</td>
<td id="S3.T6.1.6.8" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">57.57</td>
<td id="S3.T6.1.6.9" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">63.81</td>
</tr>
<tr id="S3.T6.1.7" class="ltx_tr">
<td id="S3.T6.1.7.1" class="ltx_td ltx_align_left" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.7.1.1" class="ltx_text ltx_font_bold">Few-Shot COT<sub id="S3.T6.1.7.1.1.1" class="ltx_sub">D</sub></span></td>
<td id="S3.T6.1.7.2" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">61.41</td>
<td id="S3.T6.1.7.3" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">84.96</td>
<td id="S3.T6.1.7.4" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">81.83</td>
<td id="S3.T6.1.7.5" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">77.69</td>
<td id="S3.T6.1.7.6" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">43.60</td>
<td id="S3.T6.1.7.7" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">54.12</td>
<td id="S3.T6.1.7.8" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">60.12</td>
<td id="S3.T6.1.7.9" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">61.41</td>
</tr>
<tr id="S3.T6.1.8" class="ltx_tr">
<td id="S3.T6.1.8.1" class="ltx_td ltx_align_left ltx_border_t" style="padding:0.75pt 3.0pt;" rowspan="3"><span id="S3.T6.1.8.1.1" class="ltx_text">
<span id="S3.T6.1.8.1.1.1" class="ltx_inline-block">
<span id="S3.T6.1.8.1.1.1.1" class="ltx_p"><span id="S3.T6.1.8.1.1.1.1.1" class="ltx_text ltx_font_bold">CogAgent-VQA</span></span>
</span></span></td>
<td id="S3.T6.1.8.2" class="ltx_td ltx_align_left ltx_border_t" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.8.2.1" class="ltx_text ltx_font_bold">Zero-Shot</span></td>
<td id="S3.T6.1.8.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">37.17</td>
<td id="S3.T6.1.8.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">55.27</td>
<td id="S3.T6.1.8.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">52.68</td>
<td id="S3.T6.1.8.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">26.56</td>
<td id="S3.T6.1.8.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">27.23</td>
<td id="S3.T6.1.8.8" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">37.45</td>
<td id="S3.T6.1.8.9" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">36.80</td>
<td id="S3.T6.1.8.10" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">36.96</td>
</tr>
<tr id="S3.T6.1.9" class="ltx_tr">
<td id="S3.T6.1.9.1" class="ltx_td ltx_align_left" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.9.1.1" class="ltx_text ltx_font_bold">Zero-Shot COT</span></td>
<td id="S3.T6.1.9.2" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">38.84</td>
<td id="S3.T6.1.9.3" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">58.73</td>
<td id="S3.T6.1.9.4" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">57.95</td>
<td id="S3.T6.1.9.5" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">27.51</td>
<td id="S3.T6.1.9.6" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">26.98</td>
<td id="S3.T6.1.9.7" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">40.01</td>
<td id="S3.T6.1.9.8" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">37.47</td>
<td id="S3.T6.1.9.9" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">37.64</td>
</tr>
<tr id="S3.T6.1.10" class="ltx_tr">
<td id="S3.T6.1.10.1" class="ltx_td ltx_align_left" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.10.1.1" class="ltx_text ltx_font_bold">Few-Shot COT<sub id="S3.T6.1.10.1.1.1" class="ltx_sub">D</sub></span></td>
<td id="S3.T6.1.10.2" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">25.13</td>
<td id="S3.T6.1.10.3" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">33.93</td>
<td id="S3.T6.1.10.4" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">34.26</td>
<td id="S3.T6.1.10.5" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">16.76</td>
<td id="S3.T6.1.10.6" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">21.67</td>
<td id="S3.T6.1.10.7" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">34.62</td>
<td id="S3.T6.1.10.8" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">29.65</td>
<td id="S3.T6.1.10.9" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">22.37</td>
</tr>
<tr id="S3.T6.1.11" class="ltx_tr">
<td id="S3.T6.1.11.1" class="ltx_td ltx_align_left ltx_border_t" style="padding:0.75pt 3.0pt;" rowspan="3"><span id="S3.T6.1.11.1.1" class="ltx_text">
<span id="S3.T6.1.11.1.1.1" class="ltx_inline-block">
<span id="S3.T6.1.11.1.1.1.1" class="ltx_p"><span id="S3.T6.1.11.1.1.1.1.1" class="ltx_text ltx_font_bold">InternLM<sub id="S3.T6.1.11.1.1.1.1.1.1" class="ltx_sub">-X-Comp.2</sub></span></span>
</span></span></td>
<td id="S3.T6.1.11.2" class="ltx_td ltx_align_left ltx_border_t" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.11.2.1" class="ltx_text ltx_font_bold">Zero-Shot</span></td>
<td id="S3.T6.1.11.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">37.47</td>
<td id="S3.T6.1.11.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">49.47</td>
<td id="S3.T6.1.11.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">49.79</td>
<td id="S3.T6.1.11.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">24.16</td>
<td id="S3.T6.1.11.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">32.15</td>
<td id="S3.T6.1.11.8" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">35.67</td>
<td id="S3.T6.1.11.9" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">38.26</td>
<td id="S3.T6.1.11.10" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">41.90</td>
</tr>
<tr id="S3.T6.1.12" class="ltx_tr">
<td id="S3.T6.1.12.1" class="ltx_td ltx_align_left" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.12.1.1" class="ltx_text ltx_font_bold">Zero-Shot COT</span></td>
<td id="S3.T6.1.12.2" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">43.35</td>
<td id="S3.T6.1.12.3" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">58.85</td>
<td id="S3.T6.1.12.4" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.12.4.1" class="ltx_text ltx_font_bold">65.58<sup id="S3.T6.1.12.4.1.1" class="ltx_sup"><span id="S3.T6.1.12.4.1.1.1" class="ltx_text ltx_font_medium">#</span></sup></span></td>
<td id="S3.T6.1.12.5" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">33.86</td>
<td id="S3.T6.1.12.6" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">31.39</td>
<td id="S3.T6.1.12.7" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">43.24</td>
<td id="S3.T6.1.12.8" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">41.48</td>
<td id="S3.T6.1.12.9" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">47.16</td>
</tr>
<tr id="S3.T6.1.13" class="ltx_tr">
<td id="S3.T6.1.13.1" class="ltx_td ltx_align_left" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.13.1.1" class="ltx_text ltx_font_bold">Few-Shot COT<sub id="S3.T6.1.13.1.1.1" class="ltx_sub">D</sub></span></td>
<td id="S3.T6.1.13.2" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">45.09</td>
<td id="S3.T6.1.13.3" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">58.96</td>
<td id="S3.T6.1.13.4" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">64.80</td>
<td id="S3.T6.1.13.5" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">38.56</td>
<td id="S3.T6.1.13.6" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">32.64</td>
<td id="S3.T6.1.13.7" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">45.05</td>
<td id="S3.T6.1.13.8" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.13.8.1" class="ltx_text ltx_font_bold">43.03<sup id="S3.T6.1.13.8.1.1" class="ltx_sup"><span id="S3.T6.1.13.8.1.1.1" class="ltx_text ltx_font_medium">#</span></sup></span></td>
<td id="S3.T6.1.13.9" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.13.9.1" class="ltx_text ltx_font_bold">47.74<sup id="S3.T6.1.13.9.1.1" class="ltx_sup"><span id="S3.T6.1.13.9.1.1.1" class="ltx_text ltx_font_medium">#</span></sup></span></td>
</tr>
<tr id="S3.T6.1.14" class="ltx_tr">
<td id="S3.T6.1.14.1" class="ltx_td ltx_align_left ltx_border_t" style="padding:0.75pt 3.0pt;" rowspan="3"><span id="S3.T6.1.14.1.1" class="ltx_text">
<span id="S3.T6.1.14.1.1.1" class="ltx_inline-block">
<span id="S3.T6.1.14.1.1.1.1" class="ltx_p"><span id="S3.T6.1.14.1.1.1.1.1" class="ltx_text ltx_font_bold">Qwen-VL-chat</span></span>
</span></span></td>
<td id="S3.T6.1.14.2" class="ltx_td ltx_align_left ltx_border_t" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.14.2.1" class="ltx_text ltx_font_bold">Zero-Shot</span></td>
<td id="S3.T6.1.14.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">33.67</td>
<td id="S3.T6.1.14.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">48.83</td>
<td id="S3.T6.1.14.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">46.64</td>
<td id="S3.T6.1.14.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">20.19</td>
<td id="S3.T6.1.14.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">26.89</td>
<td id="S3.T6.1.14.8" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">32.92</td>
<td id="S3.T6.1.14.9" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">34.02</td>
<td id="S3.T6.1.14.10" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">35.47</td>
</tr>
<tr id="S3.T6.1.15" class="ltx_tr">
<td id="S3.T6.1.15.1" class="ltx_td ltx_align_left" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.15.1.1" class="ltx_text ltx_font_bold">Zero-Shot COT</span></td>
<td id="S3.T6.1.15.2" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">36.19</td>
<td id="S3.T6.1.15.3" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">49.84</td>
<td id="S3.T6.1.15.4" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">53.82</td>
<td id="S3.T6.1.15.5" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">22.65</td>
<td id="S3.T6.1.15.6" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">28.13</td>
<td id="S3.T6.1.15.7" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">36.01</td>
<td id="S3.T6.1.15.8" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">35.41</td>
<td id="S3.T6.1.15.9" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">38.32</td>
</tr>
<tr id="S3.T6.1.16" class="ltx_tr">
<td id="S3.T6.1.16.1" class="ltx_td ltx_align_left" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.16.1.1" class="ltx_text ltx_font_bold">Few-Shot COT<sub id="S3.T6.1.16.1.1.1" class="ltx_sub">D</sub></span></td>
<td id="S3.T6.1.16.2" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">38.44</td>
<td id="S3.T6.1.16.3" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">57.21</td>
<td id="S3.T6.1.16.4" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">57.00</td>
<td id="S3.T6.1.16.5" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">25.13</td>
<td id="S3.T6.1.16.6" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">27.98</td>
<td id="S3.T6.1.16.7" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">40.76</td>
<td id="S3.T6.1.16.8" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">37.75</td>
<td id="S3.T6.1.16.9" class="ltx_td ltx_align_center" style="padding:0.75pt 3.0pt;">32.94</td>
</tr>
<tr id="S3.T6.1.17" class="ltx_tr">
<td id="S3.T6.1.17.1" class="ltx_td ltx_align_left ltx_border_t" style="padding:0.75pt 3.0pt;">
<span id="S3.T6.1.17.1.1" class="ltx_text ltx_font_bold">Qwen-VL-chat</span> <sub id="S3.T6.1.17.1.2" class="ltx_sub">FT</sub>
</td>
<td id="S3.T6.1.17.2" class="ltx_td ltx_align_left ltx_border_t" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.17.2.1" class="ltx_text ltx_font_bold">Zero-Shot</span></td>
<td id="S3.T6.1.17.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">36.84</td>
<td id="S3.T6.1.17.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">56.95</td>
<td id="S3.T6.1.17.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">49.86</td>
<td id="S3.T6.1.17.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">25.75</td>
<td id="S3.T6.1.17.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">25.77</td>
<td id="S3.T6.1.17.8" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">39.64</td>
<td id="S3.T6.1.17.9" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">34.63</td>
<td id="S3.T6.1.17.10" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 3.0pt;">32.51</td>
</tr>
<tr id="S3.T6.1.18" class="ltx_tr">
<td id="S3.T6.1.18.1" class="ltx_td ltx_border_bb" style="padding:0.75pt 3.0pt;"></td>
<td id="S3.T6.1.18.2" class="ltx_td ltx_align_left ltx_border_bb" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.18.2.1" class="ltx_text ltx_font_bold">Zero-Shot COT</span></td>
<td id="S3.T6.1.18.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.18.3.1" class="ltx_text ltx_font_bold">47.13<sup id="S3.T6.1.18.3.1.1" class="ltx_sup"><span id="S3.T6.1.18.3.1.1.1" class="ltx_text ltx_font_medium">#</span></sup></span></td>
<td id="S3.T6.1.18.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.18.4.1" class="ltx_text ltx_font_bold">61.55<sup id="S3.T6.1.18.4.1.1" class="ltx_sup"><span id="S3.T6.1.18.4.1.1.1" class="ltx_text ltx_font_medium">#</span></sup></span></td>
<td id="S3.T6.1.18.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.75pt 3.0pt;">59.78</td>
<td id="S3.T6.1.18.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.18.6.1" class="ltx_text ltx_font_bold">43.34<sup id="S3.T6.1.18.6.1.1" class="ltx_sup"><span id="S3.T6.1.18.6.1.1.1" class="ltx_text ltx_font_medium">#</span></sup></span></td>
<td id="S3.T6.1.18.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.18.7.1" class="ltx_text ltx_font_bold">36.02<sup id="S3.T6.1.18.7.1.1" class="ltx_sup"><span id="S3.T6.1.18.7.1.1.1" class="ltx_text ltx_font_medium">#</span></sup></span></td>
<td id="S3.T6.1.18.8" class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.75pt 3.0pt;"><span id="S3.T6.1.18.8.1" class="ltx_text ltx_font_bold">50.10<sup id="S3.T6.1.18.8.1.1" class="ltx_sup"><span id="S3.T6.1.18.8.1.1.1" class="ltx_text ltx_font_medium">#</span></sup></span></td>
<td id="S3.T6.1.18.9" class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.75pt 3.0pt;">42.14</td>
<td id="S3.T6.1.18.10" class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.75pt 3.0pt;">47.67</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Majority Vote Accuracy on All Models and Strategies broken down Question Type Wise (<span id="S3.T6.3.1" class="ltx_text ltx_font_italic">T1, T2, T3, T4</span>) as in Sec <a href="#S2.SS3" title="2.3 Question Answer Creation ‣ 2 Proposed FlowVQA Resource ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a> and Source-Wise (Instruct, Wiki, Code) as in Table <a href="#S2.T2" title="Table 2 ‣ 2.1 Flowchart Sources ‣ 2 Proposed FlowVQA Resource ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The highest value for each column is highlighted and marked with * in Closed Source Models and with # in Open Source Models.</figcaption>
</figure>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p"><span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_bold">Fine-tuning Settings</span>. We fine-tune Qwen-VL-chat <sub id="S3.SS2.p2.1.2" class="ltx_sub">FT</sub> using LORA <cite class="ltx_cite ltx_citemacro_cite">Hu et al. (<a href="#bib.bib10" title="" class="ltx_ref">2022</a>)</cite> strategy on 2xNVIDIA A100 40GB GPUs. We train with an effective batch size of 8 using a cosine-based learning scheduler with a warmup. We set a higher warmup to ensure no loss of pretraining knowledge in the base model.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Baseline Results and Discussion</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Table <a href="#S3.T6" title="Table 6 ‣ 3.2 Evaluation Method ‣ 3 Experimental Evaluation ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> tabulates the results of model evaluations across multiple strategies, with the scores split across various question types and text sources. Figure <a href="#A3.F5" title="Figure 5 ‣ Appendix C Additonal Results ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> in Appendix <a href="#A3" title="Appendix C Additonal Results ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C</span></a> provides a horizontal bar chart that compiles the results from the table.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p"><span id="S3.SS3.p2.1.1" class="ltx_text ltx_font_bold">FlowVQA is sufficiently hard.</span> The dataset resource presents a challenging task, with all the models. The evaluations highlight a scope for improvement for all the models. Our Best performing model with the top performing strategy, i.e. GPT-4 prompted with Few-shot directive-based prompting achieves 68.42% Majority voting across all the evaluators.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p"><span id="S3.SS3.p3.1.1" class="ltx_text ltx_font_bold">Few-Shot Directives are helpful</span>. In the evaluation of most of our models, we observe that text-only few-shot CoT with reasoning directives outperforms other prompting strategies. We observe 7% improvement in GPT-4 evaluation and 12% improvement in Gemini-Pro with this strategy.
CogAgent-VQA , however does not show an improvement with few-shot directives. We observe in our initial experiments that it was unable to generate directives and hence it could not make use of reasoning directives.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para">
<p id="S3.SS3.p4.1" class="ltx_p"><span id="S3.SS3.p4.1.1" class="ltx_text ltx_font_bold">Proprietary models perform better than open-source models</span>. We observe that proprietary models heavily outperform the open-source models. GPT-4 with few-shot directives outperforms Qwen-VL-chat by a significant 30%.</p>
</div>
<div id="S3.SS3.p5" class="ltx_para">
<p id="S3.SS3.p5.1" class="ltx_p"><span id="S3.SS3.p5.1.1" class="ltx_text ltx_font_bold">Fine-tuning helps</span>. We fine-tune Qwen-VL-chat and evaluate by prompting with Zero-Shot and Zero-Shot CoT strategies. We see an improvement of 3% from Zero-Shot prompting and 11% improvement from Zero-Shot COT. This improvement emphasises the lack of flowchart understanding in original pretraining mixtures of these VLMs. The improvement in T2, T3 and T4 ( 10%) being more significant than T1 (5%), can be attributed to the fact that fact-retrieval is a simpler task and does not need in-depth understanding of the flowchart structure. The fine-tuned model outperforms all other existing open-source models, which highlights the fact that <span id="S3.SS3.p5.1.2" class="ltx_text ltx_font_italic">FlowVQA</span> can be effectively used to introduce visual logic and reasoning in existing VLMs.</p>
</div>
<div id="S3.SS3.p6" class="ltx_para">
<p id="S3.SS3.p6.1" class="ltx_p"><span id="S3.SS3.p6.1.1" class="ltx_text ltx_font_bold">Question Types.</span> We present the question-wise metrics in Table <a href="#S3.T5" title="Table 5 ‣ 3 Experimental Evaluation ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. It is evident from the table that all models consistently perform better on <span id="S3.SS3.p6.1.2" class="ltx_text ltx_font_italic">Fact Retrieval (T1)</span> and <span id="S3.SS3.p6.1.3" class="ltx_text ltx_font_italic">Applied Scenario (T2)</span> based based questions than on <span id="S3.SS3.p6.1.4" class="ltx_text ltx_font_italic">Flow-Referential (T3)</span> and <span id="S3.SS3.p6.1.5" class="ltx_text ltx_font_italic">Topological (T4)</span>. Outlined in Sec. <a href="#S2.SS3" title="2.3 Question Answer Creation ‣ 2 Proposed FlowVQA Resource ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>, <span id="S3.SS3.p6.1.6" class="ltx_text ltx_font_italic">T3</span> and <span id="S3.SS3.p6.1.7" class="ltx_text ltx_font_italic">T4</span> question types require thorough understanding of the flowchart and complex reasoning over the visual modality.</p>
</div>
<figure id="S3.T7" class="ltx_table">
<table id="S3.T7.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T7.1.1" class="ltx_tr">
<td id="S3.T7.1.1.1" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T7.1.1.1.1" class="ltx_text ltx_font_bold">Number of Nodes</span></td>
<td id="S3.T7.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T7.1.1.2.1" class="ltx_text ltx_font_bold">Average Accuracy</span></td>
</tr>
<tr id="S3.T7.1.2" class="ltx_tr">
<td id="S3.T7.1.2.1" class="ltx_td ltx_align_center ltx_border_t">0-8</td>
<td id="S3.T7.1.2.2" class="ltx_td ltx_align_center ltx_border_t">51.73</td>
</tr>
<tr id="S3.T7.1.3" class="ltx_tr">
<td id="S3.T7.1.3.1" class="ltx_td ltx_align_center">8-17</td>
<td id="S3.T7.1.3.2" class="ltx_td ltx_align_center">45.74</td>
</tr>
<tr id="S3.T7.1.4" class="ltx_tr">
<td id="S3.T7.1.4.1" class="ltx_td ltx_align_center">17-26</td>
<td id="S3.T7.1.4.2" class="ltx_td ltx_align_center">44.60</td>
</tr>
<tr id="S3.T7.1.5" class="ltx_tr">
<td id="S3.T7.1.5.1" class="ltx_td ltx_align_center">35-44</td>
<td id="S3.T7.1.5.2" class="ltx_td ltx_align_center">38.99</td>
</tr>
<tr id="S3.T7.1.6" class="ltx_tr">
<td id="S3.T7.1.6.1" class="ltx_td ltx_align_center ltx_border_bb">26-35</td>
<td id="S3.T7.1.6.2" class="ltx_td ltx_align_center ltx_border_bb">40.35</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Number of Nodes comparison (Average across all models and strategies). Performance decreases as number of nodes increases.</figcaption>
</figure>
<div id="S3.SS3.p7" class="ltx_para">
<p id="S3.SS3.p7.1" class="ltx_p"><span id="S3.SS3.p7.1.1" class="ltx_text ltx_font_bold">Number of Nodes</span>. Using the Mermaid.js scripts, we obtain the count of nodes in each flowchart. We categorize the flowchart by binning the number of nodes present in them. A Large number of nodes implies a more complex representation of visual information, and hence the flowchart is harder to reason upon. The results in the Table <a href="#S3.T7" title="Table 7 ‣ 3.3 Baseline Results and Discussion ‣ 3 Experimental Evaluation ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> confirms this fact. Figure <a href="#A3.F7" title="Figure 7 ‣ Appendix C Additonal Results ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> in Appendix <a href="#A3" title="Appendix C Additonal Results ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C</span></a> shows the decline of performance of models with increase in number of nodes.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Directional Bias</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">To study <span id="S3.SS4.p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">RQ4</span>, we parse the mermaid scripts of the FlowVQA flowcharts and systematically invert them to produce a inverted flowchart <span id="S3.SS4.p1.1.2" class="ltx_text ltx_font_bold">"Bottom Top"</span> set. Bottom Top analysis helps further evaluate the Visual and Sequential nature of our resource. The Bottom Top Flowcharts look directionally counter-intuitive with the start nodes at the bottom and end at the top. We perform this inversion on 1,500 flowchart-question pairs on which all evaluators evaluate to "True" (correct response for all). We evaluate a the top-performing models and strategies obtained in Section <a href="#S3.SS1" title="3.1 Baseline Evaluation ‣ 3 Experimental Evaluation ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a> on the inverted flowchart set to detect any presence of directional bias in the VLMs.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.1" class="ltx_p">Table <a href="#S3.T8" title="Table 8 ‣ 3.4 Directional Bias ‣ 3 Experimental Evaluation ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> highlights the fact that our best performing models do <span id="S3.SS4.p2.1.1" class="ltx_text ltx_font_italic">suffer from a directional bias</span> in understanding and reasoning over flowcharts. We see a significant 15% drop in majority voting accuracy thorough with GPT-4.</p>
</div>
<figure id="S3.T8" class="ltx_table">
<table id="S3.T8.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T8.1.1" class="ltx_tr">
<td id="S3.T8.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T8.1.1.1.1" class="ltx_text ltx_font_bold">Model (Strategy)</span></td>
<td id="S3.T8.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T8.1.1.2.1" class="ltx_text ltx_font_bold">Top-Down</span></td>
<td id="S3.T8.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T8.1.1.3.1" class="ltx_text ltx_font_bold">Bottom-Up</span></td>
</tr>
<tr id="S3.T8.1.2" class="ltx_tr">
<td id="S3.T8.1.2.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T8.1.2.1.1" class="ltx_text ltx_font_bold">GPT-4V</span> <sub id="S3.T8.1.2.1.2" class="ltx_sub">(CoT)</sub>
</td>
<td id="S3.T8.1.2.2" class="ltx_td ltx_align_center ltx_border_t">100.00</td>
<td id="S3.T8.1.2.3" class="ltx_td ltx_align_center ltx_border_t">85.71</td>
</tr>
<tr id="S3.T8.1.3" class="ltx_tr">
<td id="S3.T8.1.3.1" class="ltx_td ltx_align_left ltx_border_bb">
<span id="S3.T8.1.3.1.1" class="ltx_text ltx_font_bold">Qwen-VL-chat</span> <sub id="S3.T8.1.3.1.2" class="ltx_sub">(CoT)</sub>
</td>
<td id="S3.T8.1.3.2" class="ltx_td ltx_align_center ltx_border_bb">100.00</td>
<td id="S3.T8.1.3.3" class="ltx_td ltx_align_center ltx_border_bb">76.09</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Directional Bias test, we evaluate on two models using CoT approach on 1500 flowchart-QA pairs. </figcaption>
</figure>
<div id="S3.SS4.p3" class="ltx_para">
<p id="S3.SS4.p3.1" class="ltx_p"><span id="S3.SS4.p3.1.1" class="ltx_text ltx_font_bold">Analysis</span>. The directional bias evaluation underlines an important lacking of existing VLMs. They suffer from biases introduced in pretraining mixture and do not ground their inferences in the context images which leads to a significant drop in their evaluation performances. Strategies like augmenting pretraining mixtures with counterfactual examples might help alleviating these issues, which we leave for future study.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Related Work</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Vision language models have made large progress in diverse vision-language applications <cite class="ltx_cite ltx_citemacro_cite">Bai et al. (<a href="#bib.bib3" title="" class="ltx_ref">2023</a>); Liu et al. (<a href="#bib.bib18" title="" class="ltx_ref">2023a</a>); Xia et al. (<a href="#bib.bib40" title="" class="ltx_ref">2024</a>)</cite> with multiple benchmarks being proposed to aid effective evaluation of visual and textual grounding capabilities of these models. The MMMU benchmark <cite class="ltx_cite ltx_citemacro_cite">Yue et al. (<a href="#bib.bib44" title="" class="ltx_ref">2023</a>)</cite> is designed to assess the model’s inherent "subject-specific" knowledge and reasoning abilities across various subjects (such as Technology, Humanities, Health, and more).</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">Benchmarks like TextVQA and DocVQA <cite class="ltx_cite ltx_citemacro_citep">(Singh et al., <a href="#bib.bib32" title="" class="ltx_ref">2019</a>; Mathew et al., <a href="#bib.bib25" title="" class="ltx_ref">2021b</a>; Zellers et al., <a href="#bib.bib45" title="" class="ltx_ref">2019</a>; Park et al., <a href="#bib.bib28" title="" class="ltx_ref">2020</a>; Lu et al., <a href="#bib.bib22" title="" class="ltx_ref">2022</a>; Hudson and Manning, <a href="#bib.bib11" title="" class="ltx_ref">2019</a>)</cite> evaluate the models’ fine-grained transcription abilities on low-resolution images. More complex multimodal reasoning tasks, such as MathVista <cite class="ltx_cite ltx_citemacro_cite">Lu et al. (<a href="#bib.bib21" title="" class="ltx_ref">2024</a>)</cite>, examine the models’ abilities to integrate visual and mathematical logic. Benchmarks focusing on spatial multimodal reasoning include ChartQA <cite class="ltx_cite ltx_citemacro_cite">Masry et al. (<a href="#bib.bib23" title="" class="ltx_ref">2022</a>); Xu et al. (<a href="#bib.bib41" title="" class="ltx_ref">2023</a>); Methani et al. (<a href="#bib.bib26" title="" class="ltx_ref">2020</a>)</cite> and InfographicVQA <cite class="ltx_cite ltx_citemacro_cite">Mathew et al. (<a href="#bib.bib24" title="" class="ltx_ref">2021a</a>)</cite>. ChartQA is aimed at evaluating straightforward chart understanding and analysis, while InfographicQA poses direct logical questions about data visualizations and charts.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p"><span id="S4.p3.1.1" class="ltx_text ltx_font_bold">Prior Flowchart Works</span>. To our knowledge, there exists a study on Flowchart QA <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib34" title="" class="ltx_ref">Tannert et al. </a></cite>, that suffers from major limitations. (i) Synthetically generated flowcharts with randomized scripts, (ii) Primarily poses structural questions and (iii) Uses multiple choice-based questions to evaluate weaker existing models.
Other research in this domain addresses issues like Flowchart Object Recognition and Flowchart to Code/Script conversion, where a modest parallel flowchart resource is paired with corresponding code or script <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a href="#bib.bib20" title="" class="ltx_ref">2022</a>); Shukla et al. (<a href="#bib.bib31" title="" class="ltx_ref">2023b</a>); Thean et al. (<a href="#bib.bib35" title="" class="ltx_ref">2012</a>); Sun et al. (<a href="#bib.bib33" title="" class="ltx_ref">2022</a>)</cite>. However, notable limitations here include poor flowchart image quality, niche or overly complex context, structural imbalance (only linear or excessively complex), lack of ground truth scripts for flowcharts, and insufficient context for effective Q/A or practical tasks. In contrast to these works, we construct a complex benchmark suitable to test practical applicability of existing VLMs. The complex and diverse QA types ensure an effective and just evaluation over multi-modal visual and textual understanding.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion and Future Work</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In conclusion, this study evaluates the effectiveness of existing Multimodal Large Language Models (VLMs) in reasoning upon a complex visual, sequential logical reasoning based task, <em id="S5.p1.1.1" class="ltx_emph ltx_font_italic">FlowVQA</em>. We introduce the novel dataset resource, <em id="S5.p1.1.2" class="ltx_emph ltx_font_italic">FlowVQA</em>, consisting of 2,272 Flowchart images, Mermaid.js scripts, 22,413 Q/A pairs with gold standard answers. Our extensive evaluation on these models with multiple strategies and scenarios highlights the need for advancements in <span id="S5.p1.1.3" class="ltx_text ltx_font_bold">architecture</span> and <span id="S5.p1.1.4" class="ltx_text ltx_font_bold">prompting</span> strategies in existing VLMs.
We also study the presence of any <em id="S5.p1.1.5" class="ltx_emph ltx_font_italic">directional</em> bias in the flowcharts by re-evaluating the test sets with an inverted flowchart subset. We find that both proprietary and open-source models suffer from directional bias due to lack of visual grounding and complex structural reasoning required for flowchart reasoning.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.4" class="ltx_p"><span id="S5.p2.4.5" class="ltx_text ltx_font_bold">Future Work</span>. Our work and resources give rise to many research avenues in (a) <span id="S5.p2.4.6" class="ltx_text ltx_font_bold">Flowchart Reasoning</span>: <em id="S5.p2.4.7" class="ltx_emph ltx_font_italic">FlowVQA</em> can be used to enhance the visual logic and reasoning capabilities of the models. Constructing VLMs that are flowchart specific is also a encouraging research direction.
(b) <span id="S5.p2.4.8" class="ltx_text ltx_font_bold">Graph-Encoder Models</span>: In this study, we consider the graph nature of flowcharts solely to generate topological questions. This consideration can also be taken into account while designing model architectures and inference strategies to enhance structural reasoning in the base models.
(c) <span id="S5.p2.4.9" class="ltx_text ltx_font_bold">Adversarial and Counterfactual probes</span>: We provide questions of four different types which can be augmented with multiple probe sets like negative path following, counter-intuitive questions and noisy-graph based questions.
(d) <span id="S5.p2.4.10" class="ltx_text ltx_font_bold">Complex Subtasks</span>: The parallel nature of <em id="S5.p2.4.11" class="ltx_emph ltx_font_italic">FlowVQA</em> allows us to formulate multiple subtasks using the resource. Primary task of <em id="S5.p2.4.12" class="ltx_emph ltx_font_italic">FlowVQA</em> is the <span id="S5.p2.1.1" class="ltx_text ltx_font_italic">Flowchart<math id="S5.p2.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S5.p2.1.1.m1.1a"><mo stretchy="false" id="S5.p2.1.1.m1.1.1" xref="S5.p2.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.p2.1.1.m1.1b"><ci id="S5.p2.1.1.m1.1.1.cmml" xref="S5.p2.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.1.m1.1c">\rightarrow</annotation></semantics></math>Q/A</span>. We can create multitude of tasks: <span id="S5.p2.2.2" class="ltx_text ltx_font_italic">article<math id="S5.p2.2.2.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S5.p2.2.2.m1.1a"><mo stretchy="false" id="S5.p2.2.2.m1.1.1" xref="S5.p2.2.2.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.p2.2.2.m1.1b"><ci id="S5.p2.2.2.m1.1.1.cmml" xref="S5.p2.2.2.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.2.2.m1.1c">\rightarrow</annotation></semantics></math>Q/A</span>, <span id="S5.p2.3.3" class="ltx_text ltx_font_italic">Mermaid.js<math id="S5.p2.3.3.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S5.p2.3.3.m1.1a"><mo stretchy="false" id="S5.p2.3.3.m1.1.1" xref="S5.p2.3.3.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.p2.3.3.m1.1b"><ci id="S5.p2.3.3.m1.1.1.cmml" xref="S5.p2.3.3.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.3.3.m1.1c">\rightarrow</annotation></semantics></math>Q/A</span>, <span id="S5.p2.4.4" class="ltx_text ltx_font_italic">Flowchart<math id="S5.p2.4.4.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S5.p2.4.4.m1.1a"><mo stretchy="false" id="S5.p2.4.4.m1.1.1" xref="S5.p2.4.4.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.p2.4.4.m1.1b"><ci id="S5.p2.4.4.m1.1.1.cmml" xref="S5.p2.4.4.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.4.4.m1.1c">\rightarrow</annotation></semantics></math>Mermaid.js</span>. The tasks can then act as an additional resource for training LLMs and VLMs.
(e) <span id="S5.p2.4.13" class="ltx_text ltx_font_bold">NeuroSymbolic AI Approaches</span> like in <cite class="ltx_cite ltx_citemacro_citet">Trinh et al. (<a href="#bib.bib37" title="" class="ltx_ref">2024</a>)</cite> can also be considered to enhance performance and training on our resource as flowcharts are inherently symbolic and sequential structures.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Limitations</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">There are a few notable limitations to our work. Primarily, the inability to fine-tune all models under consideration due to financial and computational resource constraints has led to a potential under-representation of the capabilities of various NLP models beyond our primary focus. Moreover, the language limitations encountered in this research, particularly the focus on English for generating Visual Question Answering (VQA) methods, underscore the need for linguistic diversity in NLP applications to ensure broader applicability and inclusivity. Given the novelty of the task at hand, it is also important to acknowledge that the insights provided may not be exhaustive, highlighting the potential for future research.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Ethics Statement</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p">We, the authors of this work, confirm that our research adheres to the highest ethical standards in both research and publication. Throughout this study, we have diligently considered and addressed various ethical issues to ensure the responsible and equitable use of computational linguistics methodologies. To promote the reproducibility of our results, we provide comprehensive information, including sharing code, datasets (we use publicly available datasets and comply with the ethical standards set by their authors), and other relevant resources. This enables the research community to validate and extend our work. The claims presented in this paper are consistent with our experimental results. However, given the inherent stochasticity of <span id="Sx2.p1.1.1" class="ltx_text ltx_font_italic">black-box</span> large language models, we have minimized variability by maintaining a fixed temperature. We thoroughly detail the annotations, dataset splits, models used, and prompting methods employed, ensuring the reproducibility of our work.</p>
</div>
</section>
<section id="Sx3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx3.p1" class="ltx_para">
<p id="Sx3.p1.1" class="ltx_p">Research was sponsored by the Army Research Office and was accomplished under Grant Number W911NF-20-1-0080. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Army Research Office or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation herein. This work was partially funded by ONR Contract N00014-19-1-2620. We extend our gratitude to the annotators who verified our flowcharts and corresponding question answer pairs. Lastly, we extend our appreciation to the reviewing team for their insightful comments.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anil et al. (2023)</span>
<span class="ltx_bibblock">
Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M. Dai, Anja Hauth, Katie Millican, David Silver, Slav Petrov, Melvin Johnson, Ioannis Antonoglou, Julian Schrittwieser, Amelia Glaese, Jilin Chen, Emily Pitler, Timothy P. Lillicrap, Angeliki Lazaridou, Orhan Firat, James Molloy, Michael Isard, Paul Ronald Barham, Tom Hennigan, Benjamin Lee, Fabio Viola, Malcolm Reynolds, Yuanzhong Xu, Ryan Doherty, Eli Collins, Clemens Meyer, Eliza Rutherford, Erica Moreira, Kareem Ayoub, Megha Goel, George Tucker, Enrique Piqueras, Maxim Krikun, Iain Barr, Nikolay Savinov, Ivo Danihelka, Becca Roelofs, Anaïs White, Anders Andreassen, Tamara von Glehn, Lakshman Yagati, Mehran Kazemi, Lucas Gonzalez, Misha Khalman, Jakub Sygnowski, and et al. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2312.11805" title="" class="ltx_ref ltx_href">Gemini: A family of highly capable multimodal models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2312.11805.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Awadalla et al. (2023)</span>
<span class="ltx_bibblock">
Anas Awadalla, Irena Gao, Josh Gardner, Jack Hessel, Yusuf Hanafy, Wanrong Zhu, Kalyani Marathe, Yonatan Bitton, Samir Yitzhak Gadre, Shiori Sagawa, Jenia Jitsev, Simon Kornblith, Pang Wei Koh, Gabriel Ilharco, Mitchell Wortsman, and Ludwig Schmidt. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2308.01390" title="" class="ltx_ref ltx_href">Openflamingo: An open-source framework for training large autoregressive vision-language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2308.01390.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et al. (2023)</span>
<span class="ltx_bibblock">
Jinze Bai, Shuai Bai, Shusheng Yang, Shijie Wang, Sinan Tan, Peng Wang, Junyang Lin, Chang Zhou, and Jingren Zhou. 2023.

</span>
<span class="ltx_bibblock">Qwen-vl: A versatile vision-language model for understanding, localization, text reading, and beyond.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2308.12966</em>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chiang and Lee (2023)</span>
<span class="ltx_bibblock">
Cheng-Han Chiang and Hung-yi Lee. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.acl-long.870" title="" class="ltx_ref ltx_href">Can large language models be an alternative to human evaluations?</a>

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 15607–15631, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong et al. (2024)</span>
<span class="ltx_bibblock">
Xiaoyi Dong, Pan Zhang, Yuhang Zang, Yuhang Cao, Bin Wang, Linke Ouyang, Xilin Wei, Songyang Zhang, Haodong Duan, Maosong Cao, Wenwei Zhang, Yining Li, Hang Yan, Yang Gao, Xinyue Zhang, Wei Li, Jingwen Li, Kai Chen, Conghui He, Xingcheng Zhang, Yu Qiao, Dahua Lin, and Jiaqi Wang. 2024.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2401.16420" title="" class="ltx_ref ltx_href">Internlm-xcomposer2: Mastering free-form text-image composition and comprehension in vision-language large model</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2401.16420.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fu et al. (2023)</span>
<span class="ltx_bibblock">
Jinlan Fu, See-Kiong Ng, Zhengbao Jiang, and Pengfei Liu. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2302.04166" title="" class="ltx_ref ltx_href">Gptscore: Evaluate as you desire</a>.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goyal et al. (2017)</span>
<span class="ltx_bibblock">
Yash Goyal, Tejas Khot, Douglas Summers-Stay, Dhruv Batra, and Devi Parikh. 2017.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1612.00837" title="" class="ltx_ref ltx_href">Making the v in vqa matter: Elevating the role of image understanding in visual question answering</a>.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et al. (2023)</span>
<span class="ltx_bibblock">
Yucheng Han, Chi Zhang, Xin Chen, Xu Yang, Zhibin Wang, Gang Yu, Bin Fu, and Hanwang Zhang. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2311.16483" title="" class="ltx_ref ltx_href">Chartllama: A multimodal LLM for chart understanding and generation</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2311.16483.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hong et al. (2023)</span>
<span class="ltx_bibblock">
Wenyi Hong, Weihan Wang, Qingsong Lv, Jiazheng Xu, Wenmeng Yu, Junhui Ji, Yan Wang, Zihan Wang, Yuxuan Zhang, Juanzi Li, Bin Xu, Yuxiao Dong, Ming Ding, and Jie Tang. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2312.08914" title="" class="ltx_ref ltx_href">Cogagent: A visual language model for GUI agents</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2312.08914.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2022)</span>
<span class="ltx_bibblock">
Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=nZeVKeeFYf9" title="" class="ltx_ref ltx_href">Lora: Low-rank adaptation of large language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hudson and Manning (2019)</span>
<span class="ltx_bibblock">
Drew A. Hudson and Christopher D. Manning. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1902.09506" title="" class="ltx_ref ltx_href">Gqa: A new dataset for real-world visual reasoning and compositional question answering</a>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2024)</span>
<span class="ltx_bibblock">
Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand, Gianna Lengyel, Guillaume Bour, Guillaume Lample, Lélio Renard Lavaud, Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock, Sandeep Subramanian, Sophia Yang, Szymon Antoniak, Teven Le Scao, Théophile Gervet, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William El Sayed. 2024.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2401.04088" title="" class="ltx_ref ltx_href">Mixtral of experts</a>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kojima et al. (2023)</span>
<span class="ltx_bibblock">
Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2205.11916" title="" class="ltx_ref ltx_href">Large language models are zero-shot reasoners</a>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023a)</span>
<span class="ltx_bibblock">
Junnan Li, Dongxu Li, Silvio Savarese, and Steven C. H. Hoi. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://proceedings.mlr.press/v202/li23q.html" title="" class="ltx_ref ltx_href">BLIP-2: bootstrapping language-image pre-training with frozen image encoders and large language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA</em>, volume 202 of <em id="bib.bib14.2.2" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning Research</em>, pages 19730–19742. PMLR.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023b)</span>
<span class="ltx_bibblock">
Zekun Li, Baolin Peng, Pengcheng He, Michel Galley, Jianfeng Gao, and Xifeng Yan. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2302.11520" title="" class="ltx_ref ltx_href">Guiding large language models via directional stimulus prompting</a>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin and Chen (2023)</span>
<span class="ltx_bibblock">
Yen-Ting Lin and Yun-Nung Chen. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2305.13711" title="" class="ltx_ref ltx_href">Llm-eval: Unified multi-dimensional automatic evaluation for open-domain conversations with large language models</a>.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2023)</span>
<span class="ltx_bibblock">
Ziyi Lin, Chris Liu, Renrui Zhang, Peng Gao, Longtian Qiu, Han Xiao, Han Qiu, Chen Lin, Wenqi Shao, Keqin Chen, Jiaming Han, Siyuan Huang, Yichi Zhang, Xuming He, Hongsheng Li, and Yu Qiao. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2311.07575" title="" class="ltx_ref ltx_href">SPHINX: the joint mixing of weights, tasks, and visual embeddings for multi-modal large language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2311.07575.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2023a)</span>
<span class="ltx_bibblock">
Haotian Liu, Chunyuan Li, Yuheng Li, and Yong Jae Lee. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2310.03744" title="" class="ltx_ref ltx_href">Improved baselines with visual instruction tuning</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2310.03744.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2023b)</span>
<span class="ltx_bibblock">
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2304.08485" title="" class="ltx_ref ltx_href">Visual instruction tuning</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2304.08485.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2022)</span>
<span class="ltx_bibblock">
Zejie Liu, Xiaoyu Hu, Deyu Zhou, Lin Li, Xu Zhang, and Yanzheng Xiang. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2022.findings-emnlp.449" title="" class="ltx_ref ltx_href">Code generation from flowcharts with texts: A benchmark dataset and an approach</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: EMNLP 2022</em>, pages 6069–6077, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al. (2024)</span>
<span class="ltx_bibblock">
Pan Lu, Hritik Bansal, Tony Xia, Jiacheng Liu, Chunyuan Li, Hannaneh Hajishirzi, Hao Cheng, Kai-Wei Chang, Michel Galley, and Jianfeng Gao. 2024.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2310.02255" title="" class="ltx_ref ltx_href">Mathvista: Evaluating mathematical reasoning of foundation models in visual contexts</a>.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al. (2022)</span>
<span class="ltx_bibblock">
Pan Lu, Swaroop Mishra, Tanglin Xia, Liang Qiu, Kai-Wei Chang, Song-Chun Zhu, Oyvind Tafjord, Peter Clark, and Ashwin Kalyan. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://proceedings.neurips.cc/paper_files/paper/2022/file/11332b6b6cf4485b84afadb1352d3a9a-Paper-Conference.pdf" title="" class="ltx_ref ltx_href">Learn to explain: Multimodal reasoning via thought chains for science question answering</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, volume 35, pages 2507–2521. Curran Associates, Inc.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Masry et al. (2022)</span>
<span class="ltx_bibblock">
Ahmed Masry, Do Xuan Long, Jia Qing Tan, Shafiq Joty, and Enamul Hoque. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2203.10244" title="" class="ltx_ref ltx_href">Chartqa: A benchmark for question answering about charts with visual and logical reasoning</a>.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mathew et al. (2021a)</span>
<span class="ltx_bibblock">
Minesh Mathew, Viraj Bagal, Rubèn Pérez Tito, Dimosthenis Karatzas, Ernest Valveny, and C. V Jawahar. 2021a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2104.12756" title="" class="ltx_ref ltx_href">Infographicvqa</a>.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mathew et al. (2021b)</span>
<span class="ltx_bibblock">
Minesh Mathew, Dimosthenis Karatzas, and C. V. Jawahar. 2021b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2007.00398" title="" class="ltx_ref ltx_href">Docvqa: A dataset for vqa on document images</a>.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Methani et al. (2020)</span>
<span class="ltx_bibblock">
Nitesh Methani, Pritha Ganguly, Mitesh M. Khapra, and Pratyush Kumar. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/WACV45572.2020.9093523" title="" class="ltx_ref ltx_href">Plotqa: Reasoning over scientific plots</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">IEEE Winter Conference on Applications of Computer Vision, WACV 2020, Snowmass Village, CO, USA, March 1-5, 2020</em>, pages 1516–1525. IEEE.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2303.08774" title="" class="ltx_ref ltx_href">GPT-4 technical report</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2303.08774.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park et al. (2020)</span>
<span class="ltx_bibblock">
Jae Sung Park, Chandra Bhagavatula, Roozbeh Mottaghi, Ali Farhadi, and Yejin Choi. 2020.

</span>
<span class="ltx_bibblock">Visualcomet: Reasoning about the dynamic context of a still image.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Computer Vision – ECCV 2020</em>, pages 508–524, Cham. Springer International Publishing.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reich et al. (2023)</span>
<span class="ltx_bibblock">
Daniel Reich, Felix Putze, and Tanja Schultz. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.findings-emnlp.206" title="" class="ltx_ref ltx_href">Measuring faithful and plausible visual grounding in VQA</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: EMNLP 2023</em>, pages 3129–3144, Singapore. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shukla et al. (2023a)</span>
<span class="ltx_bibblock">
Shreya Shukla, Prajwal Gatti, Yogesh Kumar, Vikash Yadav, and Anand Mishra. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1007/978-3-031-41734-4_31" title="" class="ltx_ref ltx_href">Towards making flowchart images machine interpretable</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Document Analysis and Recognition - ICDAR 2023 - 17th International Conference, San José, CA, USA, August 21-26, 2023, Proceedings, Part V</em>, volume 14191 of <em id="bib.bib30.2.2" class="ltx_emph ltx_font_italic">Lecture Notes in Computer Science</em>, pages 505–521. Springer.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shukla et al. (2023b)</span>
<span class="ltx_bibblock">
Shreya Shukla, Prajwal Gatti, Yogesh Kumar, Vikash Yadav, and Anand Mishra. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1007/978-3-031-41734-4_31" title="" class="ltx_ref ltx_href">Towards making flowchart images machine interpretable</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Document Analysis and Recognition - ICDAR 2023: 17th International Conference, San José, CA, USA, August 21–26, 2023, Proceedings, Part V</em>, page 505–521, Berlin, Heidelberg. Springer-Verlag.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singh et al. (2019)</span>
<span class="ltx_bibblock">
Amanpreet Singh, Vivek Natarajan, Meet Shah, Yu Jiang, Xinlei Chen, Dhruv Batra, Devi Parikh, and Marcus Rohrbach. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1904.08920" title="" class="ltx_ref ltx_href">Towards vqa models that can read</a>.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2022)</span>
<span class="ltx_bibblock">
Lianshan Sun, Hanchao Du, and Tao Hou. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/ACCESS.2022.3183068" title="" class="ltx_ref ltx_href">Fr-detr: End-to-end flowchart recognition with precision and robustness</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, 10:64292–64301.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(34)</span>
<span class="ltx_bibblock">
Simon Tannert, Marcelo Feighelstein, Jasmina Bogojeska, and Joseph Shtok.

</span>
<span class="ltx_bibblock">Flowchartqa.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://document-intelligence.github.io/DI-2022/files/di-2022_final_11.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://document-intelligence.github.io/DI-2022/files/di-2022_final_11.pdf</a>.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thean et al. (2012)</span>
<span class="ltx_bibblock">
Andrew Thean, Jean-Marc Deltorn, Patrice Lopez, and Laurent Romary. 2012.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:7648486" title="" class="ltx_ref ltx_href">Textual summarisation of flowcharts in patent drawings for clef-ip 2012</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Conference and Labs of the Evaluation Forum</em>.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas
Scialom. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2307.09288" title="" class="ltx_ref ltx_href">Llama 2: Open foundation and fine-tuned chat models</a>.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Trinh et al. (2024)</span>
<span class="ltx_bibblock">
Trieu H. Trinh, Yuhuai Wu, Quoc V. Le, He He, and Thang Luong. 2024.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1038/s41586-023-06747-5" title="" class="ltx_ref ltx_href">Solving olympiad geometry without human demonstrations</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Nature</em>, 625(7995):476–482.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(38)</span>
<span class="ltx_bibblock">
Google Vertex.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://ai.google.dev/" title="" class="ltx_ref ltx_href">Gemini pro api</a>.

</span>
<span class="ltx_bibblock">Accessed on Feb 4, 2024.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2023)</span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2201.11903" title="" class="ltx_ref ltx_href">Chain-of-thought prompting elicits reasoning in large language models</a>.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xia et al. (2024)</span>
<span class="ltx_bibblock">
Renqiu Xia, Bo Zhang, Hancheng Ye, Xiangchao Yan, Qi Liu, Hongbin Zhou, Zijun Chen, Min Dou, Botian Shi, Junchi Yan, and Yu Qiao. 2024.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2402.12185" title="" class="ltx_ref ltx_href">Chartx &amp; chartvlm: A versatile benchmark and foundation model for complicated chart reasoning</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2402.12185.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2023)</span>
<span class="ltx_bibblock">
Zhengzhuo Xu, Sinan Du, Yiyan Qi, Chengjin Xu, Chun Yuan, and Jian Guo. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2312.15915" title="" class="ltx_ref ltx_href">Chartbench: A benchmark for complex visual reasoning in charts</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2312.15915.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et al. (2023a)</span>
<span class="ltx_bibblock">
Junjie Ye, Xuanting Chen, Nuo Xu, Can Zu, Zekai Shao, Shichun Liu, Yuhan Cui, Zeyang Zhou, Chao Gong, Yang Shen, Jie Zhou, Siming Chen, Tao Gui, Qi Zhang, and Xuanjing Huang. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2303.10420" title="" class="ltx_ref ltx_href">A comprehensive capability analysis of gpt-3 and gpt-3.5 series models</a>.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et al. (2023b)</span>
<span class="ltx_bibblock">
Qinghao Ye, Haiyang Xu, Guohai Xu, Jiabo Ye, Ming Yan, Yiyang Zhou, Junyang Wang, Anwen Hu, Pengcheng Shi, Yaya Shi, Chenliang Li, Yuanhong Xu, Hehong Chen, Junfeng Tian, Qian Qi, Ji Zhang, and Fei Huang. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2304.14178" title="" class="ltx_ref ltx_href">mplug-owl: Modularization empowers large language models with multimodality</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2304.14178.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yue et al. (2023)</span>
<span class="ltx_bibblock">
Xiang Yue, Yuansheng Ni, Kai Zhang, Tianyu Zheng, Ruoqi Liu, Ge Zhang, Samuel Stevens, Dongfu Jiang, Weiming Ren, Yuxuan Sun, Cong Wei, Botao Yu, Ruibin Yuan, Renliang Sun, Ming Yin, Boyuan Zheng, Zhenzhu Yang, Yibo Liu, Wenhao Huang, Huan Sun, Yu Su, and Wenhu Chen. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2311.16502" title="" class="ltx_ref ltx_href">Mmmu: A massive multi-discipline multimodal understanding and reasoning benchmark for expert agi</a>.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zellers et al. (2019)</span>
<span class="ltx_bibblock">
Rowan Zellers, Yonatan Bisk, Ali Farhadi, and Yejin Choi. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/CVPR.2019.00688" title="" class="ltx_ref ltx_href">From recognition to cognition: Visual commonsense reasoning</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, pages 6713–6724.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2023)</span>
<span class="ltx_bibblock">
Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2302.00923" title="" class="ltx_ref ltx_href">Multimodal chain-of-thought reasoning in language models</a>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Flowchart QA Example</h2>

<div id="A1.p1" class="ltx_para">
<table id="A1.p1.1" class="ltx_tabular ltx_align_middle">
<tr id="A1.p1.1.1" class="ltx_tr">
<td id="A1.p1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A1.p1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.p1.1.1.1.1.1" class="ltx_p" style="width:216.8pt;"><span id="A1.p1.1.1.1.1.1.1" class="ltx_text" style="position:relative; bottom:-0.4pt;"><img src="/html/2406.19237/assets/Figures/instruct00258.png" id="A1.p1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="299" height="721" alt="[Uncaptioned image]"></span></span>
</span>
</td>
<td id="A1.p1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A1.p1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.p1.1.1.2.1.1" class="ltx_p" style="width:216.8pt;">
<span id="A1.p1.1.1.2.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="A1.p1.1.1.2.1.1.1.1" class="ltx_tr">
<span id="A1.p1.1.1.2.1.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.1.1.1.1" class="ltx_p" style="width:469.8pt;"><span id="A1.p1.1.1.2.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">T1: Fact Retrieval</span></span>
</span></span></span>
<span id="A1.p1.1.1.2.1.1.1.2" class="ltx_tr">
<span id="A1.p1.1.1.2.1.1.1.2.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.2.1.1.1" class="ltx_p" style="width:469.8pt;"><span id="A1.p1.1.1.2.1.1.1.2.1.1.1.1" class="ltx_text ltx_font_italic">Q: What should be done if the glass jar is not frosted?</span></span>
</span></span></span>
<span id="A1.p1.1.1.2.1.1.1.3" class="ltx_tr">
<span id="A1.p1.1.1.2.1.1.1.3.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.3.1.1.1" class="ltx_p" style="width:469.8pt;"><span id="A1.p1.1.1.2.1.1.1.3.1.1.1.1" class="ltx_text ltx_font_italic">A</span>: Frost the jar with spray or insert tracing paper.</span>
</span></span></span>
<span id="A1.p1.1.1.2.1.1.1.4" class="ltx_tr">
<span id="A1.p1.1.1.2.1.1.1.4.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.4.1.1.1" class="ltx_p" style="width:469.8pt;"><span id="A1.p1.1.1.2.1.1.1.4.1.1.1.1" class="ltx_text ltx_font_italic">Q: What triggers the LED to light up in the solar jar?</span></span>
</span></span></span>
<span id="A1.p1.1.1.2.1.1.1.5" class="ltx_tr">
<span id="A1.p1.1.1.2.1.1.1.5.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.5.1.1.1" class="ltx_p" style="width:469.8pt;"><span id="A1.p1.1.1.2.1.1.1.5.1.1.1.1" class="ltx_text ltx_font_italic">A</span>: Low ambient light causes the LED to light up.</span>
</span></span></span>
<span id="A1.p1.1.1.2.1.1.1.6" class="ltx_tr">
<span id="A1.p1.1.1.2.1.1.1.6.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.6.1.1.1" class="ltx_p" style="width:469.8pt;"><span id="A1.p1.1.1.2.1.1.1.6.1.1.1.1" class="ltx_text ltx_font_bold">T2: Applied Scenario</span></span>
</span></span></span>
<span id="A1.p1.1.1.2.1.1.1.7" class="ltx_tr">
<span id="A1.p1.1.1.2.1.1.1.7.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.7.1.1.1" class="ltx_p" style="width:469.8pt;"><span id="A1.p1.1.1.2.1.1.1.7.1.1.1.1" class="ltx_text ltx_font_italic">Q: Jason is disassembling a solar garden light for a DIY project but is unsure about how to safely extract the internal components including the solar panel, circuitry, LED, and battery housing. What tools should he use and how should he proceed with the disassembly?</span></span>
</span></span></span>
<span id="A1.p1.1.1.2.1.1.1.8" class="ltx_tr">
<span id="A1.p1.1.1.2.1.1.1.8.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.8.1.1.1" class="ltx_p" style="width:469.8pt;"><span id="A1.p1.1.1.2.1.1.1.8.1.1.1.1" class="ltx_text ltx_font_italic">A</span>: Jason should use a utility knife and screwdriver to carefully disassemble the solar garden light and extract the necessary components.</span>
</span></span></span>
<span id="A1.p1.1.1.2.1.1.1.9" class="ltx_tr">
<span id="A1.p1.1.1.2.1.1.1.9.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.9.1.1.1" class="ltx_p" style="width:469.8pt;"><span id="A1.p1.1.1.2.1.1.1.9.1.1.1.1" class="ltx_text ltx_font_italic">Q: While attempting to create a homemade solar-powered LED lighted cookie jar, Michael realized he forgot to frost his Ikea glass jar. He doesn’t have any frosting spray on hand but remembers he has some tracing paper. How should he proceed to achieve the necessary frosted effect?</span></span>
</span></span></span>
<span id="A1.p1.1.1.2.1.1.1.10" class="ltx_tr">
<span id="A1.p1.1.1.2.1.1.1.10.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.10.1.1.1" class="ltx_p" style="width:469.8pt;"><span id="A1.p1.1.1.2.1.1.1.10.1.1.1.1" class="ltx_text ltx_font_italic">A</span>: Michael should cut a strip of tracing paper to fit inside the jar to achieve the frosted effect.</span>
</span></span></span>
<span id="A1.p1.1.1.2.1.1.1.11" class="ltx_tr">
<span id="A1.p1.1.1.2.1.1.1.11.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.11.1.1.1" class="ltx_p" style="width:469.8pt;"><span id="A1.p1.1.1.2.1.1.1.11.1.1.1.1" class="ltx_text ltx_font_bold">T3: Flow Referential</span></span>
</span></span></span>
<span id="A1.p1.1.1.2.1.1.1.12" class="ltx_tr">
<span id="A1.p1.1.1.2.1.1.1.12.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.12.1.1.1" class="ltx_p" style="width:469.8pt;"><span id="A1.p1.1.1.2.1.1.1.12.1.1.1.1" class="ltx_text ltx_font_italic">Q: Assuming the glass jar was already frosted, what are the next two steps I must take in sequence?</span></span>
</span></span></span>
<span id="A1.p1.1.1.2.1.1.1.13" class="ltx_tr">
<span id="A1.p1.1.1.2.1.1.1.13.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.13.1.1.1" class="ltx_p" style="width:469.8pt;"><span id="A1.p1.1.1.2.1.1.1.13.1.1.1.1" class="ltx_text ltx_font_italic">A</span>: You would place the internal components and then assemble the jar with solar components.</span>
</span></span></span>
<span id="A1.p1.1.1.2.1.1.1.14" class="ltx_tr">
<span id="A1.p1.1.1.2.1.1.1.14.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.14.1.1.1" class="ltx_p" style="width:469.8pt;"><span id="A1.p1.1.1.2.1.1.1.14.1.1.1.1" class="ltx_text ltx_font_italic">Q: If I have just completed frosting the jar with spray or inserting tracing paper, what is the next immediate step in the process?</span></span>
</span></span></span>
<span id="A1.p1.1.1.2.1.1.1.15" class="ltx_tr">
<span id="A1.p1.1.1.2.1.1.1.15.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.15.1.1.1" class="ltx_p" style="width:469.8pt;"><span id="A1.p1.1.1.2.1.1.1.15.1.1.1.1" class="ltx_text ltx_font_italic">A</span>: The next step is to assemble the jar with solar components.</span>
</span></span></span>
<span id="A1.p1.1.1.2.1.1.1.16" class="ltx_tr">
<span id="A1.p1.1.1.2.1.1.1.16.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.16.1.1.1" class="ltx_p" style="width:469.8pt;"><span id="A1.p1.1.1.2.1.1.1.16.1.1.1.1" class="ltx_text ltx_font_bold">T4: Topological</span></span>
</span></span></span>
<span id="A1.p1.1.1.2.1.1.1.17" class="ltx_tr">
<span id="A1.p1.1.1.2.1.1.1.17.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.17.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.17.1.1.1" class="ltx_p" style="width:469.8pt;"><span id="A1.p1.1.1.2.1.1.1.17.1.1.1.1" class="ltx_text ltx_font_italic">Q: How many nodes exist in the given flowchart?</span></span>
</span></span></span>
<span id="A1.p1.1.1.2.1.1.1.18" class="ltx_tr">
<span id="A1.p1.1.1.2.1.1.1.18.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.18.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.18.1.1.1" class="ltx_p" style="width:469.8pt;"><span id="A1.p1.1.1.2.1.1.1.18.1.1.1.1" class="ltx_text ltx_font_italic">A</span>: 15</span>
</span></span></span>
<span id="A1.p1.1.1.2.1.1.1.19" class="ltx_tr">
<span id="A1.p1.1.1.2.1.1.1.19.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.19.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.19.1.1.1" class="ltx_p" style="width:469.8pt;"><span id="A1.p1.1.1.2.1.1.1.19.1.1.1.1" class="ltx_text ltx_font_italic">Q: Is the node "Is ambient light low?" direct predecessor of the node "Place internal components"?</span></span>
</span></span></span>
<span id="A1.p1.1.1.2.1.1.1.20" class="ltx_tr">
<span id="A1.p1.1.1.2.1.1.1.20.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.20.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.p1.1.1.2.1.1.1.20.1.1.1" class="ltx_p" style="width:469.8pt;"><span id="A1.p1.1.1.2.1.1.1.20.1.1.1.1" class="ltx_text ltx_font_italic">A</span>: No</span>
</span></span></span>
</span></span>
</span>
</td>
</tr>
</table>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Dataset Distribution</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.1" class="ltx_p">Figure <a href="#A2.F4" title="Figure 4 ‣ Appendix B Dataset Distribution ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> illustrates how our data is distributed among various sources and types of questions.</p>
</div>
<figure id="A2.F4" class="ltx_figure"><img src="/html/2406.19237/assets/Figures/Dataset_distribution.png" id="A2.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="479" height="217" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>The figure shows the distribution of our data across different sources as well as across different types of questions.</figcaption>
</figure>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Additonal Results</h2>

<div id="A3.p1" class="ltx_para">
<p id="A3.p1.1" class="ltx_p">Figure <a href="#A3.F5" title="Figure 5 ‣ Appendix C Additonal Results ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>
shows the performance of FlowVQA dataset on various modelling strategies as outlined in Section <a href="#S3" title="3 Experimental Evaluation ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Table <a href="#A3.T9" title="Table 9 ‣ Appendix C Additonal Results ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>
shows VLMs across the three evaluator models - GPT, Llama and Mixtral over the various categories in the FlowVQA dataset. Figure <a href="#A3.F6" title="Figure 6 ‣ Appendix C Additonal Results ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> show category wise distribution of majority score for GPT-4V model. We also measure the average performance vs number of nodes in the flowcharts . The average is across all models and strategies and the graph is created after smoothening with an exponential weighted moving average (<math id="A3.p1.1.m1.1" class="ltx_Math" alttext="\alpha=0.4" display="inline"><semantics id="A3.p1.1.m1.1a"><mrow id="A3.p1.1.m1.1.1" xref="A3.p1.1.m1.1.1.cmml"><mi id="A3.p1.1.m1.1.1.2" xref="A3.p1.1.m1.1.1.2.cmml">α</mi><mo id="A3.p1.1.m1.1.1.1" xref="A3.p1.1.m1.1.1.1.cmml">=</mo><mn id="A3.p1.1.m1.1.1.3" xref="A3.p1.1.m1.1.1.3.cmml">0.4</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.p1.1.m1.1b"><apply id="A3.p1.1.m1.1.1.cmml" xref="A3.p1.1.m1.1.1"><eq id="A3.p1.1.m1.1.1.1.cmml" xref="A3.p1.1.m1.1.1.1"></eq><ci id="A3.p1.1.m1.1.1.2.cmml" xref="A3.p1.1.m1.1.1.2">𝛼</ci><cn type="float" id="A3.p1.1.m1.1.1.3.cmml" xref="A3.p1.1.m1.1.1.3">0.4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.1.m1.1c">\alpha=0.4</annotation></semantics></math>), as shown in figure <a href="#A3.F7" title="Figure 7 ‣ Appendix C Additonal Results ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
<figure id="A3.F5" class="ltx_figure"><img src="/html/2406.19237/assets/Figures/ExperimentalResultUpdate.png" id="A3.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="371" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>The horizontal bar chart shows the performance of FlowVQA dataset on various modelling strategies outlined in Section <a href="#S3" title="3 Experimental Evaluation ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</figcaption>
</figure>
<figure id="A3.T9" class="ltx_table">
<table id="A3.T9.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A3.T9.1.1" class="ltx_tr">
<td id="A3.T9.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Category</td>
<td id="A3.T9.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Majority</td>
<td id="A3.T9.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">GPT</td>
<td id="A3.T9.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">LLAMA</td>
<td id="A3.T9.1.1.5" class="ltx_td ltx_align_center ltx_border_t">Mixtral</td>
</tr>
<tr id="A3.T9.1.2" class="ltx_tr">
<td id="A3.T9.1.2.1" class="ltx_td ltx_border_r"></td>
<td id="A3.T9.1.2.2" class="ltx_td ltx_align_center ltx_border_r">Voting</td>
<td id="A3.T9.1.2.3" class="ltx_td ltx_border_r"></td>
<td id="A3.T9.1.2.4" class="ltx_td ltx_border_r"></td>
<td id="A3.T9.1.2.5" class="ltx_td"></td>
</tr>
<tr id="A3.T9.1.3" class="ltx_tr">
<td id="A3.T9.1.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Arts and Entertainment</td>
<td id="A3.T9.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.4</td>
<td id="A3.T9.1.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.4</td>
<td id="A3.T9.1.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">58.2</td>
<td id="A3.T9.1.3.5" class="ltx_td ltx_align_center ltx_border_t">59.3</td>
</tr>
<tr id="A3.T9.1.4" class="ltx_tr">
<td id="A3.T9.1.4.1" class="ltx_td ltx_align_center ltx_border_r">Cars &amp; Other Vehicles</td>
<td id="A3.T9.1.4.2" class="ltx_td ltx_align_center ltx_border_r">52.8</td>
<td id="A3.T9.1.4.3" class="ltx_td ltx_align_center ltx_border_r">54.3</td>
<td id="A3.T9.1.4.4" class="ltx_td ltx_align_center ltx_border_r">53.6</td>
<td id="A3.T9.1.4.5" class="ltx_td ltx_align_center">53.4</td>
</tr>
<tr id="A3.T9.1.5" class="ltx_tr">
<td id="A3.T9.1.5.1" class="ltx_td ltx_align_center ltx_border_r">Circuits</td>
<td id="A3.T9.1.5.2" class="ltx_td ltx_align_center ltx_border_r">56.3</td>
<td id="A3.T9.1.5.3" class="ltx_td ltx_align_center ltx_border_r">57.3</td>
<td id="A3.T9.1.5.4" class="ltx_td ltx_align_center ltx_border_r">57.0</td>
<td id="A3.T9.1.5.5" class="ltx_td ltx_align_center">61.1</td>
</tr>
<tr id="A3.T9.1.6" class="ltx_tr">
<td id="A3.T9.1.6.1" class="ltx_td ltx_align_center ltx_border_r">Computers and Electronics</td>
<td id="A3.T9.1.6.2" class="ltx_td ltx_align_center ltx_border_r">62.1</td>
<td id="A3.T9.1.6.3" class="ltx_td ltx_align_center ltx_border_r">61.8</td>
<td id="A3.T9.1.6.4" class="ltx_td ltx_align_center ltx_border_r">61.4</td>
<td id="A3.T9.1.6.5" class="ltx_td ltx_align_center">63.6</td>
</tr>
<tr id="A3.T9.1.7" class="ltx_tr">
<td id="A3.T9.1.7.1" class="ltx_td ltx_align_center ltx_border_r">Cooking</td>
<td id="A3.T9.1.7.2" class="ltx_td ltx_align_center ltx_border_r">61.3</td>
<td id="A3.T9.1.7.3" class="ltx_td ltx_align_center ltx_border_r">62.8</td>
<td id="A3.T9.1.7.4" class="ltx_td ltx_align_center ltx_border_r">60.4</td>
<td id="A3.T9.1.7.5" class="ltx_td ltx_align_center">64.2</td>
</tr>
<tr id="A3.T9.1.8" class="ltx_tr">
<td id="A3.T9.1.8.1" class="ltx_td ltx_align_center ltx_border_r">Craft</td>
<td id="A3.T9.1.8.2" class="ltx_td ltx_align_center ltx_border_r">62.3</td>
<td id="A3.T9.1.8.3" class="ltx_td ltx_align_center ltx_border_r">63.9</td>
<td id="A3.T9.1.8.4" class="ltx_td ltx_align_center ltx_border_r">62.6</td>
<td id="A3.T9.1.8.5" class="ltx_td ltx_align_center">64.5</td>
</tr>
<tr id="A3.T9.1.9" class="ltx_tr">
<td id="A3.T9.1.9.1" class="ltx_td ltx_align_center ltx_border_r">Education and Communications</td>
<td id="A3.T9.1.9.2" class="ltx_td ltx_align_center ltx_border_r">63.4</td>
<td id="A3.T9.1.9.3" class="ltx_td ltx_align_center ltx_border_r">64.4</td>
<td id="A3.T9.1.9.4" class="ltx_td ltx_align_center ltx_border_r">60.2</td>
<td id="A3.T9.1.9.5" class="ltx_td ltx_align_center">64.4</td>
</tr>
<tr id="A3.T9.1.10" class="ltx_tr">
<td id="A3.T9.1.10.1" class="ltx_td ltx_align_center ltx_border_r">Family Life</td>
<td id="A3.T9.1.10.2" class="ltx_td ltx_align_center ltx_border_r">56.4</td>
<td id="A3.T9.1.10.3" class="ltx_td ltx_align_center ltx_border_r">57.8</td>
<td id="A3.T9.1.10.4" class="ltx_td ltx_align_center ltx_border_r">57.1</td>
<td id="A3.T9.1.10.5" class="ltx_td ltx_align_center">58.4</td>
</tr>
<tr id="A3.T9.1.11" class="ltx_tr">
<td id="A3.T9.1.11.1" class="ltx_td ltx_align_center ltx_border_r">Finance and Business</td>
<td id="A3.T9.1.11.2" class="ltx_td ltx_align_center ltx_border_r">53.1</td>
<td id="A3.T9.1.11.3" class="ltx_td ltx_align_center ltx_border_r">54.6</td>
<td id="A3.T9.1.11.4" class="ltx_td ltx_align_center ltx_border_r">53.4</td>
<td id="A3.T9.1.11.5" class="ltx_td ltx_align_center">53.8</td>
</tr>
<tr id="A3.T9.1.12" class="ltx_tr">
<td id="A3.T9.1.12.1" class="ltx_td ltx_align_center ltx_border_r">Food and Entertaining</td>
<td id="A3.T9.1.12.2" class="ltx_td ltx_align_center ltx_border_r">58.7</td>
<td id="A3.T9.1.12.3" class="ltx_td ltx_align_center ltx_border_r">58.3</td>
<td id="A3.T9.1.12.4" class="ltx_td ltx_align_center ltx_border_r">56.4</td>
<td id="A3.T9.1.12.5" class="ltx_td ltx_align_center">61.4</td>
</tr>
<tr id="A3.T9.1.13" class="ltx_tr">
<td id="A3.T9.1.13.1" class="ltx_td ltx_align_center ltx_border_r">Health</td>
<td id="A3.T9.1.13.2" class="ltx_td ltx_align_center ltx_border_r">62.4</td>
<td id="A3.T9.1.13.3" class="ltx_td ltx_align_center ltx_border_r">64.8</td>
<td id="A3.T9.1.13.4" class="ltx_td ltx_align_center ltx_border_r">60.4</td>
<td id="A3.T9.1.13.5" class="ltx_td ltx_align_center">62.8</td>
</tr>
<tr id="A3.T9.1.14" class="ltx_tr">
<td id="A3.T9.1.14.1" class="ltx_td ltx_align_center ltx_border_r">Hobbies and Crafts</td>
<td id="A3.T9.1.14.2" class="ltx_td ltx_align_center ltx_border_r">60.1</td>
<td id="A3.T9.1.14.3" class="ltx_td ltx_align_center ltx_border_r">59.1</td>
<td id="A3.T9.1.14.4" class="ltx_td ltx_align_center ltx_border_r">59.5</td>
<td id="A3.T9.1.14.5" class="ltx_td ltx_align_center">62.1</td>
</tr>
<tr id="A3.T9.1.15" class="ltx_tr">
<td id="A3.T9.1.15.1" class="ltx_td ltx_align_center ltx_border_r">Holidays and Traditions</td>
<td id="A3.T9.1.15.2" class="ltx_td ltx_align_center ltx_border_r">58.6</td>
<td id="A3.T9.1.15.3" class="ltx_td ltx_align_center ltx_border_r">59.1</td>
<td id="A3.T9.1.15.4" class="ltx_td ltx_align_center ltx_border_r">60.3</td>
<td id="A3.T9.1.15.5" class="ltx_td ltx_align_center">60.3</td>
</tr>
<tr id="A3.T9.1.16" class="ltx_tr">
<td id="A3.T9.1.16.1" class="ltx_td ltx_align_center ltx_border_r">Home and Garden</td>
<td id="A3.T9.1.16.2" class="ltx_td ltx_align_center ltx_border_r">59.0</td>
<td id="A3.T9.1.16.3" class="ltx_td ltx_align_center ltx_border_r">59.8</td>
<td id="A3.T9.1.16.4" class="ltx_td ltx_align_center ltx_border_r">57.0</td>
<td id="A3.T9.1.16.5" class="ltx_td ltx_align_center">60.5</td>
</tr>
<tr id="A3.T9.1.17" class="ltx_tr">
<td id="A3.T9.1.17.1" class="ltx_td ltx_align_center ltx_border_r">Living</td>
<td id="A3.T9.1.17.2" class="ltx_td ltx_align_center ltx_border_r">60.5</td>
<td id="A3.T9.1.17.3" class="ltx_td ltx_align_center ltx_border_r">60.3</td>
<td id="A3.T9.1.17.4" class="ltx_td ltx_align_center ltx_border_r">60.3</td>
<td id="A3.T9.1.17.5" class="ltx_td ltx_align_center">63.4</td>
</tr>
<tr id="A3.T9.1.18" class="ltx_tr">
<td id="A3.T9.1.18.1" class="ltx_td ltx_align_center ltx_border_r">Outside</td>
<td id="A3.T9.1.18.2" class="ltx_td ltx_align_center ltx_border_r">58.8</td>
<td id="A3.T9.1.18.3" class="ltx_td ltx_align_center ltx_border_r">61.0</td>
<td id="A3.T9.1.18.4" class="ltx_td ltx_align_center ltx_border_r">56.5</td>
<td id="A3.T9.1.18.5" class="ltx_td ltx_align_center">61.5</td>
</tr>
<tr id="A3.T9.1.19" class="ltx_tr">
<td id="A3.T9.1.19.1" class="ltx_td ltx_align_center ltx_border_r">Personal Care and Style</td>
<td id="A3.T9.1.19.2" class="ltx_td ltx_align_center ltx_border_r">59.9</td>
<td id="A3.T9.1.19.3" class="ltx_td ltx_align_center ltx_border_r">59.9</td>
<td id="A3.T9.1.19.4" class="ltx_td ltx_align_center ltx_border_r">60.3</td>
<td id="A3.T9.1.19.5" class="ltx_td ltx_align_center">62.9</td>
</tr>
<tr id="A3.T9.1.20" class="ltx_tr">
<td id="A3.T9.1.20.1" class="ltx_td ltx_align_center ltx_border_r">Pets and Animals</td>
<td id="A3.T9.1.20.2" class="ltx_td ltx_align_center ltx_border_r">60.7</td>
<td id="A3.T9.1.20.3" class="ltx_td ltx_align_center ltx_border_r">62.1</td>
<td id="A3.T9.1.20.4" class="ltx_td ltx_align_center ltx_border_r">60.3</td>
<td id="A3.T9.1.20.5" class="ltx_td ltx_align_center">64.7</td>
</tr>
<tr id="A3.T9.1.21" class="ltx_tr">
<td id="A3.T9.1.21.1" class="ltx_td ltx_align_center ltx_border_r">Philosophy and Religion</td>
<td id="A3.T9.1.21.2" class="ltx_td ltx_align_center ltx_border_r">59.6</td>
<td id="A3.T9.1.21.3" class="ltx_td ltx_align_center ltx_border_r">58.2</td>
<td id="A3.T9.1.21.4" class="ltx_td ltx_align_center ltx_border_r">58.7</td>
<td id="A3.T9.1.21.5" class="ltx_td ltx_align_center">60.9</td>
</tr>
<tr id="A3.T9.1.22" class="ltx_tr">
<td id="A3.T9.1.22.1" class="ltx_td ltx_align_center ltx_border_r">Relationships</td>
<td id="A3.T9.1.22.2" class="ltx_td ltx_align_center ltx_border_r">56.1</td>
<td id="A3.T9.1.22.3" class="ltx_td ltx_align_center ltx_border_r">56.1</td>
<td id="A3.T9.1.22.4" class="ltx_td ltx_align_center ltx_border_r">54.8</td>
<td id="A3.T9.1.22.5" class="ltx_td ltx_align_center">59.2</td>
</tr>
<tr id="A3.T9.1.23" class="ltx_tr">
<td id="A3.T9.1.23.1" class="ltx_td ltx_align_center ltx_border_r">Sports and Fitness</td>
<td id="A3.T9.1.23.2" class="ltx_td ltx_align_center ltx_border_r">61.3</td>
<td id="A3.T9.1.23.3" class="ltx_td ltx_align_center ltx_border_r">62.9</td>
<td id="A3.T9.1.23.4" class="ltx_td ltx_align_center ltx_border_r">60.2</td>
<td id="A3.T9.1.23.5" class="ltx_td ltx_align_center">60.9</td>
</tr>
<tr id="A3.T9.1.24" class="ltx_tr">
<td id="A3.T9.1.24.1" class="ltx_td ltx_align_center ltx_border_r">Travel</td>
<td id="A3.T9.1.24.2" class="ltx_td ltx_align_center ltx_border_r">56.6</td>
<td id="A3.T9.1.24.3" class="ltx_td ltx_align_center ltx_border_r">57.0</td>
<td id="A3.T9.1.24.4" class="ltx_td ltx_align_center ltx_border_r">55.3</td>
<td id="A3.T9.1.24.5" class="ltx_td ltx_align_center">58.3</td>
</tr>
<tr id="A3.T9.1.25" class="ltx_tr">
<td id="A3.T9.1.25.1" class="ltx_td ltx_align_center ltx_border_r">Work World</td>
<td id="A3.T9.1.25.2" class="ltx_td ltx_align_center ltx_border_r">55.3</td>
<td id="A3.T9.1.25.3" class="ltx_td ltx_align_center ltx_border_r">54.3</td>
<td id="A3.T9.1.25.4" class="ltx_td ltx_align_center ltx_border_r">53.2</td>
<td id="A3.T9.1.25.5" class="ltx_td ltx_align_center">56.7</td>
</tr>
<tr id="A3.T9.1.26" class="ltx_tr">
<td id="A3.T9.1.26.1" class="ltx_td ltx_align_center ltx_border_r">Workshop</td>
<td id="A3.T9.1.26.2" class="ltx_td ltx_align_center ltx_border_r">60.9</td>
<td id="A3.T9.1.26.3" class="ltx_td ltx_align_center ltx_border_r">60.6</td>
<td id="A3.T9.1.26.4" class="ltx_td ltx_align_center ltx_border_r">57.7</td>
<td id="A3.T9.1.26.5" class="ltx_td ltx_align_center">65.4</td>
</tr>
<tr id="A3.T9.1.27" class="ltx_tr">
<td id="A3.T9.1.27.1" class="ltx_td ltx_align_center ltx_border_r">Youth</td>
<td id="A3.T9.1.27.2" class="ltx_td ltx_align_center ltx_border_r">59.3</td>
<td id="A3.T9.1.27.3" class="ltx_td ltx_align_center ltx_border_r">58.8</td>
<td id="A3.T9.1.27.4" class="ltx_td ltx_align_center ltx_border_r">58.8</td>
<td id="A3.T9.1.27.5" class="ltx_td ltx_align_center">59.3</td>
</tr>
<tr id="A3.T9.1.28" class="ltx_tr">
<td id="A3.T9.1.28.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">code</td>
<td id="A3.T9.1.28.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">61.7</td>
<td id="A3.T9.1.28.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">63.3</td>
<td id="A3.T9.1.28.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">62.9</td>
<td id="A3.T9.1.28.5" class="ltx_td ltx_align_center ltx_border_b">63.8</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>Baselines across the three evaluator models—GPT, Llama and Mixtral over the various categories in the FlowVQA dataset.</figcaption>
</figure>
<figure id="A3.F6" class="ltx_figure"><img src="/html/2406.19237/assets/Figures/barchartupd.png" id="A3.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="221" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Category wise distribution of majority score for GPT-4V</figcaption>
</figure>
<figure id="A3.F7" class="ltx_figure"><img src="/html/2406.19237/assets/Figures/numberofnodes.png" id="A3.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="309" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Average performance vs number of nodes.
We measure the average across all models and strategies and the grpah is created after smoothening with an exponential weighted moving average (<math id="A3.F7.2.m1.1" class="ltx_Math" alttext="\alpha=0.4" display="inline"><semantics id="A3.F7.2.m1.1b"><mrow id="A3.F7.2.m1.1.1" xref="A3.F7.2.m1.1.1.cmml"><mi id="A3.F7.2.m1.1.1.2" xref="A3.F7.2.m1.1.1.2.cmml">α</mi><mo id="A3.F7.2.m1.1.1.1" xref="A3.F7.2.m1.1.1.1.cmml">=</mo><mn id="A3.F7.2.m1.1.1.3" xref="A3.F7.2.m1.1.1.3.cmml">0.4</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.F7.2.m1.1c"><apply id="A3.F7.2.m1.1.1.cmml" xref="A3.F7.2.m1.1.1"><eq id="A3.F7.2.m1.1.1.1.cmml" xref="A3.F7.2.m1.1.1.1"></eq><ci id="A3.F7.2.m1.1.1.2.cmml" xref="A3.F7.2.m1.1.1.2">𝛼</ci><cn type="float" id="A3.F7.2.m1.1.1.3.cmml" xref="A3.F7.2.m1.1.1.3">0.4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.F7.2.m1.1d">\alpha=0.4</annotation></semantics></math>)</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Prompts for Generation</h2>

<div id="A4.p1" class="ltx_para">
<p id="A4.p1.1" class="ltx_p">In this section we lists the prompts we use to query GPT-4 in various steps outlined in Section <a href="#S2" title="2 Proposed FlowVQA Resource ‣ FlowVQA: Mapping Multimodal Logic in Visual Question Answering with Flowcharts" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a></p>
</div>
<section id="A4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.1 </span>Flowchart Creation</h3>

<figure id="A4.SS1.tab1" class="ltx_table">
<table id="A4.SS1.tab1.1" class="ltx_tabular ltx_align_middle">
<tr id="A4.SS1.tab1.1.1" class="ltx_tr">
<td id="A4.SS1.tab1.1.1.1" class="ltx_td ltx_align_left ltx_border_tt">
<span id="A4.SS1.tab1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab1.1.1.1.1.1" class="ltx_p"><span id="A4.SS1.tab1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">First Step: Breaking down source text to structured summaries</span></span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab1.1.2" class="ltx_tr">
<td id="A4.SS1.tab1.1.2.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="A4.SS1.tab1.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab1.1.2.1.1.1" class="ltx_p"><span id="A4.SS1.tab1.1.2.1.1.1.1" class="ltx_text ltx_font_italic">Please provide a comprehensive structured summary, detailed step-by-step representation of the blog post below. Each step in the representation summary should be labeled with specific control codes that define its nature in the system. These codes include:</span></span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab1.1.3" class="ltx_tr">
<td id="A4.SS1.tab1.1.3.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab1.1.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab1.1.3.1.1.1" class="ltx_p"><span id="A4.SS1.tab1.1.3.1.1.1.1" class="ltx_text ltx_font_italic">START</span>: Marks the first step. There must be only one start step and the whole summary representation must follow a single step-by-step structure.</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab1.1.4" class="ltx_tr">
<td id="A4.SS1.tab1.1.4.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab1.1.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab1.1.4.1.1.1" class="ltx_p"><span id="A4.SS1.tab1.1.4.1.1.1.1" class="ltx_text ltx_font_italic">PROCESS</span>: Indicates an ongoing process step.</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab1.1.5" class="ltx_tr">
<td id="A4.SS1.tab1.1.5.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab1.1.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab1.1.5.1.1.1" class="ltx_p"><span id="A4.SS1.tab1.1.5.1.1.1.1" class="ltx_text ltx_font_italic">DECISION [IF] [ELSE]</span>: Denotes a conditional decision-making step, with outcomes being either ’Yes’ or ’No’. For steps with multiple outcomes, break them down into smaller decision steps.</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab1.1.6" class="ltx_tr">
<td id="A4.SS1.tab1.1.6.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab1.1.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab1.1.6.1.1.1" class="ltx_p"><span id="A4.SS1.tab1.1.6.1.1.1.1" class="ltx_text ltx_font_italic">INPUT</span>: Introduces new variables or elements, like ingredients in a recipe.</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab1.1.7" class="ltx_tr">
<td id="A4.SS1.tab1.1.7.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab1.1.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab1.1.7.1.1.1" class="ltx_p"><span id="A4.SS1.tab1.1.7.1.1.1.1" class="ltx_text ltx_font_italic">OUTPUT</span>: Highlights the results, outputs or products of a step</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab1.1.8" class="ltx_tr">
<td id="A4.SS1.tab1.1.8.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab1.1.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab1.1.8.1.1.1" class="ltx_p"><span id="A4.SS1.tab1.1.8.1.1.1.1" class="ltx_text ltx_font_italic">END</span>: Marks all terminal points where the process ends or cannot go any further.</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab1.1.9" class="ltx_tr">
<td id="A4.SS1.tab1.1.9.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab1.1.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab1.1.9.1.1.1" class="ltx_p">! Treat the blog instructions as a system. The system has some inputs and some output. Describe the entire detailed summary in that particular format. Be it the working of an ATM machine or the steps to create pizza from raw ingredients everything can be looked at like a system or pseudocode. Make sure not to miss any critical points in processes.</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab1.1.10" class="ltx_tr">
<td id="A4.SS1.tab1.1.10.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab1.1.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab1.1.10.1.1.1" class="ltx_p">! Try to retain context and structure it well.</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab1.1.11" class="ltx_tr">
<td id="A4.SS1.tab1.1.11.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab1.1.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab1.1.11.1.1.1" class="ltx_p">! Important. Design the decision/conditional steps to have only ’Yes’ or ’No’ outcomes and treat their text like questions.</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab1.1.12" class="ltx_tr">
<td id="A4.SS1.tab1.1.12.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab1.1.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab1.1.12.1.1.1" class="ltx_p">! Start from a single start point, do not have multiple parallel starts, make sure things remain step-wise with conditionals, loops etc.</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab1.1.13" class="ltx_tr">
<td id="A4.SS1.tab1.1.13.1" class="ltx_td ltx_align_left ltx_border_bb">
<span id="A4.SS1.tab1.1.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab1.1.13.1.1.1" class="ltx_p"><span id="A4.SS1.tab1.1.13.1.1.1.1" class="ltx_text ltx_font_italic">Make the steps comprehensive and detailed, final output in markdown.</span></span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="A4.SS1.tab2" class="ltx_table">
<table id="A4.SS1.tab2.1" class="ltx_tabular ltx_align_middle">
<tr id="A4.SS1.tab2.1.1" class="ltx_tr">
<td id="A4.SS1.tab2.1.1.1" class="ltx_td ltx_align_left ltx_border_tt">
<span id="A4.SS1.tab2.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.1.1.1.1" class="ltx_p"><span id="A4.SS1.tab2.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Second step: Converting structured summaries to Mermaid Scripts</span></span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab2.1.2" class="ltx_tr">
<td id="A4.SS1.tab2.1.2.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="A4.SS1.tab2.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.2.1.1.1" class="ltx_p"><span id="A4.SS1.tab2.1.2.1.1.1.1" class="ltx_text ltx_font_italic">Here is a detailed step-by-step summary tagged with detailed control codes for a blog post. Treat the step-wise summary as a system or a detailed pipeline. For this create a Mermaid Live Flowchart Script (flowchart TD) that is detailed, does not miss any key points, and captures all integral nodes perfectly. Treat the blog instructions and the flowchart as a system representation. Be it the working of an ATM machine or the steps to create pizza from raw ingredients everything can be looked at like a system.</span></span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab2.1.3" class="ltx_tr">
<td id="A4.SS1.tab2.1.3.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab2.1.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.3.1.1.1" class="ltx_p"><span id="A4.SS1.tab2.1.3.1.1.1.1" class="ltx_text ltx_font_italic">Objective</span>: Convert Passed Structured Summary to detailed Mermaid Live Flowchart (flowchart TD)</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab2.1.4" class="ltx_tr">
<td id="A4.SS1.tab2.1.4.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab2.1.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.4.1.1.1" class="ltx_p">Control Codes for Assistance:</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab2.1.5" class="ltx_tr">
<td id="A4.SS1.tab2.1.5.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab2.1.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.5.1.1.1" class="ltx_p"><span id="A4.SS1.tab2.1.5.1.1.1.1" class="ltx_text ltx_font_italic">START</span>: Marks the first step. There must be only one start step and the whole summary representation must follow a single step-by-step structure.</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab2.1.6" class="ltx_tr">
<td id="A4.SS1.tab2.1.6.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab2.1.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.6.1.1.1" class="ltx_p"><span id="A4.SS1.tab2.1.6.1.1.1.1" class="ltx_text ltx_font_italic">PROCESS</span>: Indicates an ongoing procedure or action. Rectangle Shape.</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab2.1.7" class="ltx_tr">
<td id="A4.SS1.tab2.1.7.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab2.1.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.7.1.1.1" class="ltx_p"><span id="A4.SS1.tab2.1.7.1.1.1.1" class="ltx_text ltx_font_italic">DECISION [IF] [ELSE]</span>: Denotes a conditional decision-making step, with outcomes being either ’Yes’ or ’No’. For multiple outcomes, decompose into smaller decisions. Diamond Shape.</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab2.1.8" class="ltx_tr">
<td id="A4.SS1.tab2.1.8.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab2.1.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.8.1.1.1" class="ltx_p"><span id="A4.SS1.tab2.1.8.1.1.1.1" class="ltx_text ltx_font_italic">INPUT</span>: Introduces new elements or variables, akin to ingredients in a recipe. Parallelogram Shape.</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab2.1.9" class="ltx_tr">
<td id="A4.SS1.tab2.1.9.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab2.1.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.9.1.1.1" class="ltx_p"><span id="A4.SS1.tab2.1.9.1.1.1.1" class="ltx_text ltx_font_italic">OUTPUT</span>: Results, Outputs or end-products of a step. Parallelogram Shape.</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab2.1.10" class="ltx_tr">
<td id="A4.SS1.tab2.1.10.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab2.1.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.10.1.1.1" class="ltx_p"><span id="A4.SS1.tab2.1.10.1.1.1.1" class="ltx_text ltx_font_italic">END</span>: All points of no further go terminal. Oval Shape.</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab2.1.11" class="ltx_tr">
<td id="A4.SS1.tab2.1.11.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab2.1.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.11.1.1.1" class="ltx_p">Important Points</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab2.1.12" class="ltx_tr">
<td id="A4.SS1.tab2.1.12.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab2.1.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.12.1.1.1" class="ltx_p">1. Treat the blog post instructions as a single system workflow or pipeline.</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab2.1.13" class="ltx_tr">
<td id="A4.SS1.tab2.1.13.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab2.1.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.13.1.1.1" class="ltx_p">2. The system should include I/O, processes, decisions and terminals.</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab2.1.14" class="ltx_tr">
<td id="A4.SS1.tab2.1.14.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab2.1.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.14.1.1.1" class="ltx_p">3. Ensure that the flowchart accurately depicts a real-life system flowchart, it should be contextually rich and practical for reference.</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab2.1.15" class="ltx_tr">
<td id="A4.SS1.tab2.1.15.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab2.1.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.15.1.1.1" class="ltx_p">4. Maintain an optimal length for the flowchart not too long not too short, if there are multiple process steps in sequence you may consider combining them if the flowchart is too long.</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab2.1.16" class="ltx_tr">
<td id="A4.SS1.tab2.1.16.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab2.1.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.16.1.1.1" class="ltx_p">5. Important! Design the decision steps to have only ’Yes’ or ’No’ outcomes. For steps with multiple outcomes, break them down into smaller decision steps.</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab2.1.17" class="ltx_tr">
<td id="A4.SS1.tab2.1.17.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab2.1.17.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.17.1.1.1" class="ltx_p">6. Ensure a singular flow for the system, with all subroutines being direct components of the main system.</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab2.1.18" class="ltx_tr">
<td id="A4.SS1.tab2.1.18.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab2.1.18.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.18.1.1.1" class="ltx_p">7. Ensure use of all flowchart symbols like rectangles, ovals, diamonds, circle, arrows etc.</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab2.1.19" class="ltx_tr">
<td id="A4.SS1.tab2.1.19.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab2.1.19.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.19.1.1.1" class="ltx_p">8. Ensure the actual control codes are not mentioned in the flowchart nodes.</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab2.1.20" class="ltx_tr">
<td id="A4.SS1.tab2.1.20.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab2.1.20.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.20.1.1.1" class="ltx_p">9. Verify flowchart syntax carefully</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab2.1.21" class="ltx_tr">
<td id="A4.SS1.tab2.1.21.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab2.1.21.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.21.1.1.1" class="ltx_p"><span id="A4.SS1.tab2.1.21.1.1.1.1" class="ltx_text ltx_font_italic">Sample of a small mermaid flowchart TD for reference:</span></span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab2.1.22" class="ltx_tr">
<td id="A4.SS1.tab2.1.22.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab2.1.22.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.22.1.1.1" class="ltx_p">flowchart TD</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab2.1.23" class="ltx_tr">
<td id="A4.SS1.tab2.1.23.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab2.1.23.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.23.1.1.1" class="ltx_p">A(["Start"]) –&gt; B["Process 1"]</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab2.1.24" class="ltx_tr">
<td id="A4.SS1.tab2.1.24.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab2.1.24.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.24.1.1.1" class="ltx_p">B –&gt; C"Decision?"</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab2.1.25" class="ltx_tr">
<td id="A4.SS1.tab2.1.25.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab2.1.25.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.25.1.1.1" class="ltx_p">C –&gt;|"Yes"| D["Process 2"]</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab2.1.26" class="ltx_tr">
<td id="A4.SS1.tab2.1.26.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab2.1.26.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.26.1.1.1" class="ltx_p">D –&gt; E["Process 3"]</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab2.1.27" class="ltx_tr">
<td id="A4.SS1.tab2.1.27.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab2.1.27.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.27.1.1.1" class="ltx_p">E –&gt; C</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab2.1.28" class="ltx_tr">
<td id="A4.SS1.tab2.1.28.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab2.1.28.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.28.1.1.1" class="ltx_p">C –&gt;|"No"| F[/"Output or Input"/]</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab2.1.29" class="ltx_tr">
<td id="A4.SS1.tab2.1.29.1" class="ltx_td ltx_align_left">
<span id="A4.SS1.tab2.1.29.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.29.1.1.1" class="ltx_p">F –&gt; G(["End")</span>
</span>
</td>
</tr>
<tr id="A4.SS1.tab2.1.30" class="ltx_tr">
<td id="A4.SS1.tab2.1.30.1" class="ltx_td ltx_align_left ltx_border_bb">
<span id="A4.SS1.tab2.1.30.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS1.tab2.1.30.1.1.1" class="ltx_p"><span id="A4.SS1.tab2.1.30.1.1.1.1" class="ltx_text ltx_font_italic">Make sure to verify each point above before your output.</span></span>
</span>
</td>
</tr>
</table>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="A4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.2 </span>Question Generation</h3>

<figure id="A4.SS2.tab1" class="ltx_table">
<table id="A4.SS2.tab1.1" class="ltx_tabular ltx_align_middle">
<tr id="A4.SS2.tab1.1.1" class="ltx_tr">
<td id="A4.SS2.tab1.1.1.1" class="ltx_td ltx_align_left ltx_border_tt">
<span id="A4.SS2.tab1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.1.1.1.1" class="ltx_p"><span id="A4.SS2.tab1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Fact Retrieval</span></span>
</span>
</td>
<td id="A4.SS2.tab1.1.1.2" class="ltx_td ltx_align_justify ltx_border_tt"></td>
</tr>
<tr id="A4.SS2.tab1.1.2" class="ltx_tr">
<td id="A4.SS2.tab1.1.2.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="A4.SS2.tab1.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.2.1.1.1" class="ltx_p"><span id="A4.SS2.tab1.1.2.1.1.1.1" class="ltx_text ltx_font_italic">Task: You will analyze a step-by-step structured summary and Mermaid Flowchart Representation of a blog post or code script. The blog post includes specific steps for handling tasks.</span></span>
</span>
</td>
<td id="A4.SS2.tab1.1.2.2" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="A4.SS2.tab1.1.3" class="ltx_tr">
<td id="A4.SS2.tab1.1.3.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.3.1.1.1" class="ltx_p"><span id="A4.SS2.tab1.1.3.1.1.1.1" class="ltx_text ltx_font_italic">Your Role</span>: As a fact-extractor and question creator, your objective is to locate factual content within the summary. Your goal is to construct several question-answer pairs that each relate to distinct and critical facts presented in the summary.</span>
</span>
</td>
<td id="A4.SS2.tab1.1.3.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.4" class="ltx_tr">
<td id="A4.SS2.tab1.1.4.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.4.1.1.1" class="ltx_p"><span id="A4.SS2.tab1.1.4.1.1.1.1" class="ltx_text ltx_font_italic">Guidelines for Question Development:</span></span>
</span>
</td>
<td id="A4.SS2.tab1.1.4.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.5" class="ltx_tr">
<td id="A4.SS2.tab1.1.5.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.5.1.1.1" class="ltx_p">1. Begin by determining the presence and quantity of direct facts in the summary. If there are multiple concrete facts, especially quantitative ones, generate questions for each. If fewer facts are present, create fewer questions. The ideal question range is 2-4 questions. 2-3 for fewer facts and 3-4 for ones with more facts.</span>
</span>
</td>
<td id="A4.SS2.tab1.1.5.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.6" class="ltx_tr">
<td id="A4.SS2.tab1.1.6.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.6.1.1.1" class="ltx_p">2. Focus on specific and relevant facts, asking questions like Who? What? Why? How much? How many? Emphasize quantitative facts over qualitative ones.</span>
</span>
</td>
<td id="A4.SS2.tab1.1.6.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.7" class="ltx_tr">
<td id="A4.SS2.tab1.1.7.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.7.1.1.1" class="ltx_p">3. Questions should be straightforward, with answers in the summary. Avoid direct references to the summary or the blog post in your questions.</span>
</span>
</td>
<td id="A4.SS2.tab1.1.7.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.8" class="ltx_tr">
<td id="A4.SS2.tab1.1.8.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.8.1.1.1" class="ltx_p">4. Ensure each question highlights a different fact from the summary.</span>
</span>
</td>
<td id="A4.SS2.tab1.1.8.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.9" class="ltx_tr">
<td id="A4.SS2.tab1.1.9.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.9.1.1.1" class="ltx_p"><span id="A4.SS2.tab1.1.9.1.1.1.1" class="ltx_text ltx_font_italic">Answer Guidelines:</span></span>
</span>
</td>
<td id="A4.SS2.tab1.1.9.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.10" class="ltx_tr">
<td id="A4.SS2.tab1.1.10.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.10.1.1.1" class="ltx_p">1. Provide brief and clear answers.</span>
</span>
</td>
<td id="A4.SS2.tab1.1.10.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.11" class="ltx_tr">
<td id="A4.SS2.tab1.1.11.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.11.1.1.1" class="ltx_p">2. Answers must be definitive, avoiding open-endedness.</span>
</span>
</td>
<td id="A4.SS2.tab1.1.11.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.12" class="ltx_tr">
<td id="A4.SS2.tab1.1.12.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.12.1.1.1" class="ltx_p">3. Offer several paraphrased answers for each question. (A1, A2, A3)</span>
</span>
</td>
<td id="A4.SS2.tab1.1.12.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.13" class="ltx_tr">
<td id="A4.SS2.tab1.1.13.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.13.1.1.1" class="ltx_p"><span id="A4.SS2.tab1.1.13.1.1.1.1" class="ltx_text ltx_font_italic">Output Format:</span> Present your questions and answers in a structured JSON format, following the provided example.</span>
</span>
</td>
<td id="A4.SS2.tab1.1.13.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.14" class="ltx_tr">
<td id="A4.SS2.tab1.1.14.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.14.1.1.1" class="ltx_p">Example Structure:</span>
</span>
</td>
<td id="A4.SS2.tab1.1.14.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.15" class="ltx_tr">
<td id="A4.SS2.tab1.1.15.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.15.1.1.1" class="ltx_p">- Output JSON:</span>
</span>
</td>
<td id="A4.SS2.tab1.1.15.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.16" class="ltx_tr">
<td id="A4.SS2.tab1.1.16.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.16.1.1.1" class="ltx_p">{</span>
</span>
</td>
<td id="A4.SS2.tab1.1.16.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.17" class="ltx_tr">
<td id="A4.SS2.tab1.1.17.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.17.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.17.1.1.1" class="ltx_p">"1": {</span>
</span>
</td>
<td id="A4.SS2.tab1.1.17.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.18" class="ltx_tr">
<td id="A4.SS2.tab1.1.18.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.18.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.18.1.1.1" class="ltx_p">"Q": "First Fact-based Question here",</span>
</span>
</td>
<td id="A4.SS2.tab1.1.18.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.19" class="ltx_tr">
<td id="A4.SS2.tab1.1.19.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.19.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.19.1.1.1" class="ltx_p">"A1": "",</span>
</span>
</td>
<td id="A4.SS2.tab1.1.19.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.20" class="ltx_tr">
<td id="A4.SS2.tab1.1.20.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.20.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.20.1.1.1" class="ltx_p">"A2": "",</span>
</span>
</td>
<td id="A4.SS2.tab1.1.20.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.21" class="ltx_tr">
<td id="A4.SS2.tab1.1.21.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.21.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.21.1.1.1" class="ltx_p">"A3": "",</span>
</span>
</td>
<td id="A4.SS2.tab1.1.21.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.22" class="ltx_tr">
<td id="A4.SS2.tab1.1.22.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.22.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.22.1.1.1" class="ltx_p">},</span>
</span>
</td>
<td id="A4.SS2.tab1.1.22.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.23" class="ltx_tr">
<td id="A4.SS2.tab1.1.23.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.23.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.23.1.1.1" class="ltx_p">"2": {</span>
</span>
</td>
<td id="A4.SS2.tab1.1.23.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.24" class="ltx_tr">
<td id="A4.SS2.tab1.1.24.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.24.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.24.1.1.1" class="ltx_p">"Q": "",</span>
</span>
</td>
<td id="A4.SS2.tab1.1.24.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.25" class="ltx_tr">
<td id="A4.SS2.tab1.1.25.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.25.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.25.1.1.1" class="ltx_p">"A1": "",</span>
</span>
</td>
<td id="A4.SS2.tab1.1.25.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.26" class="ltx_tr">
<td id="A4.SS2.tab1.1.26.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.26.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.26.1.1.1" class="ltx_p">"A2": "",</span>
</span>
</td>
<td id="A4.SS2.tab1.1.26.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.27" class="ltx_tr">
<td id="A4.SS2.tab1.1.27.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.27.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.27.1.1.1" class="ltx_p">"A3": "",</span>
</span>
</td>
<td id="A4.SS2.tab1.1.27.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.28" class="ltx_tr">
<td id="A4.SS2.tab1.1.28.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.28.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.28.1.1.1" class="ltx_p">},</span>
</span>
</td>
<td id="A4.SS2.tab1.1.28.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.29" class="ltx_tr">
<td id="A4.SS2.tab1.1.29.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.29.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.29.1.1.1" class="ltx_p">}</span>
</span>
</td>
<td id="A4.SS2.tab1.1.29.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.30" class="ltx_tr">
<td id="A4.SS2.tab1.1.30.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.30.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.30.1.1.1" class="ltx_p"><span id="A4.SS2.tab1.1.30.1.1.1.1" class="ltx_text ltx_font_italic">Sample Question-Answer Pairs:</span></span>
</span>
</td>
<td id="A4.SS2.tab1.1.30.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.31" class="ltx_tr">
<td id="A4.SS2.tab1.1.31.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.31.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.31.1.1.1" class="ltx_p">1. What is the correct temperature for preheating the oven?</span>
</span>
</td>
<td id="A4.SS2.tab1.1.31.2" class="ltx_td ltx_align_justify"></td>
</tr>
<tr id="A4.SS2.tab1.1.32" class="ltx_tr">
<td id="A4.SS2.tab1.1.32.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.32.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.32.1.1.1" class="ltx_p">A1. 80 Degrees Celsius</span>
</span>
</td>
<td id="A4.SS2.tab1.1.32.2" class="ltx_td ltx_align_justify"></td>
</tr>
<tr id="A4.SS2.tab1.1.33" class="ltx_tr">
<td id="A4.SS2.tab1.1.33.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.33.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.33.1.1.1" class="ltx_p">A2. Preheat the oven to 80 degrees Celsius</span>
</span>
</td>
<td id="A4.SS2.tab1.1.33.2" class="ltx_td ltx_align_justify"></td>
</tr>
<tr id="A4.SS2.tab1.1.34" class="ltx_tr">
<td id="A4.SS2.tab1.1.34.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.34.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.34.1.1.1" class="ltx_p">A3. …</span>
</span>
</td>
<td id="A4.SS2.tab1.1.34.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.35" class="ltx_tr">
<td id="A4.SS2.tab1.1.35.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.35.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.35.1.1.1" class="ltx_p">2. How long should crayons be left in the oven to melt?</span>
</span>
</td>
<td id="A4.SS2.tab1.1.35.2" class="ltx_td ltx_align_justify"></td>
</tr>
<tr id="A4.SS2.tab1.1.36" class="ltx_tr">
<td id="A4.SS2.tab1.1.36.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.36.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.36.1.1.1" class="ltx_p">A1. 20 Minutes</span>
</span>
</td>
<td id="A4.SS2.tab1.1.36.2" class="ltx_td ltx_align_justify"></td>
</tr>
<tr id="A4.SS2.tab1.1.37" class="ltx_tr">
<td id="A4.SS2.tab1.1.37.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.37.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.37.1.1.1" class="ltx_p">A2. Leave the crayons in the oven for about 20 minutes</span>
</span>
</td>
<td id="A4.SS2.tab1.1.37.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.38" class="ltx_tr">
<td id="A4.SS2.tab1.1.38.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.38.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.38.1.1.1" class="ltx_p">3. What might tempt someone to peek?</span>
</span>
</td>
<td id="A4.SS2.tab1.1.38.2" class="ltx_td ltx_align_justify"></td>
</tr>
<tr id="A4.SS2.tab1.1.39" class="ltx_tr">
<td id="A4.SS2.tab1.1.39.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.39.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.39.1.1.1" class="ltx_p">A1. Gifts</span>
</span>
</td>
<td id="A4.SS2.tab1.1.39.2" class="ltx_td ltx_align_justify"></td>
</tr>
<tr id="A4.SS2.tab1.1.40" class="ltx_tr">
<td id="A4.SS2.tab1.1.40.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.40.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.40.1.1.1" class="ltx_p">A2. The temptation to peek at Christmas gifts</span>
</span>
</td>
<td id="A4.SS2.tab1.1.40.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.41" class="ltx_tr">
<td id="A4.SS2.tab1.1.41.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.41.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.41.1.1.1" class="ltx_p">4. At what angle should the target be struck for full extension?</span>
</span>
</td>
<td id="A4.SS2.tab1.1.41.2" class="ltx_td ltx_align_justify"></td>
</tr>
<tr id="A4.SS2.tab1.1.42" class="ltx_tr">
<td id="A4.SS2.tab1.1.42.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.42.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.42.1.1.1" class="ltx_p">A1. A 90-degree Angle</span>
</span>
</td>
<td id="A4.SS2.tab1.1.42.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.43" class="ltx_tr">
<td id="A4.SS2.tab1.1.43.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.43.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.43.1.1.1" class="ltx_p">5. How long should the cork be left to cure?</span>
</span>
</td>
<td id="A4.SS2.tab1.1.43.2" class="ltx_td ltx_align_justify"></td>
</tr>
<tr id="A4.SS2.tab1.1.44" class="ltx_tr">
<td id="A4.SS2.tab1.1.44.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.44.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.44.1.1.1" class="ltx_p">A1. Overnight</span>
</span>
</td>
<td id="A4.SS2.tab1.1.44.2" class="ltx_td ltx_align_justify"></td>
</tr>
<tr id="A4.SS2.tab1.1.45" class="ltx_tr">
<td id="A4.SS2.tab1.1.45.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.45.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.45.1.1.1" class="ltx_p">A2. Cure the cork overnight</span>
</span>
</td>
<td id="A4.SS2.tab1.1.45.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.46" class="ltx_tr">
<td id="A4.SS2.tab1.1.46.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab1.1.46.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.46.1.1.1" class="ltx_p"><span id="A4.SS2.tab1.1.46.1.1.1.1" class="ltx_text ltx_font_italic">PS: Your Answers should be BRIEF, definitive and must offer three paraphrased versions A1, A2, A3. Make sure the questions are not too open ended and concrete.</span></span>
</span>
</td>
<td id="A4.SS2.tab1.1.46.2" class="ltx_td"></td>
</tr>
<tr id="A4.SS2.tab1.1.47" class="ltx_tr">
<td id="A4.SS2.tab1.1.47.1" class="ltx_td ltx_align_left ltx_border_bb">
<span id="A4.SS2.tab1.1.47.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab1.1.47.1.1.1" class="ltx_p">Also DO NOT MENTION THE BLOG/STRUCTURED SUMMARY/SCRIPT IN THE QUESTION.</span>
</span>
</td>
<td id="A4.SS2.tab1.1.47.2" class="ltx_td ltx_border_bb"></td>
</tr>
</table>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<figure id="A4.SS2.tab2" class="ltx_table">
<table id="A4.SS2.tab2.1" class="ltx_tabular ltx_align_middle">
<tr id="A4.SS2.tab2.1.1" class="ltx_tr">
<td id="A4.SS2.tab2.1.1.1" class="ltx_td ltx_align_left ltx_border_tt">
<span id="A4.SS2.tab2.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.1.1.1.1" class="ltx_p"><span id="A4.SS2.tab2.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Applied Scenario</span></span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.2" class="ltx_tr">
<td id="A4.SS2.tab2.1.2.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="A4.SS2.tab2.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.2.1.1.1" class="ltx_p"><span id="A4.SS2.tab2.1.2.1.1.1.1" class="ltx_text ltx_font_italic">Task: You will analyze a step-by-step structured summary and Mermaid Flowchart Representation of a blog post or code script. The blog post includes specific steps for handling tasks.</span></span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.3" class="ltx_tr">
<td id="A4.SS2.tab2.1.3.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.3.1.1.1" class="ltx_p"><span id="A4.SS2.tab2.1.3.1.1.1.1" class="ltx_text ltx_font_italic">Your Role</span>: As a complex situational question-answer generator, your task is to focus on the most interesting parts of the blog post’s structured summary. Create 2-4 Complex Question-Answer Pairs. Each pair should correspond to a different, interesting area of the structured summary of the blog post.</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.4" class="ltx_tr">
<td id="A4.SS2.tab2.1.4.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.4.1.1.1" class="ltx_p"><span id="A4.SS2.tab2.1.4.1.1.1.1" class="ltx_text ltx_font_italic">Guidelines for Question Development:</span></span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.5" class="ltx_tr">
<td id="A4.SS2.tab2.1.5.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.5.1.1.1" class="ltx_p">- Focus on specific, relevant / crucial steps of the structured summary such as decisions, loops and other critical steps.</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.6" class="ltx_tr">
<td id="A4.SS2.tab2.1.6.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.6.1.1.1" class="ltx_p">- Craft situational questions that are creative, practical, and likely to occur in real life.</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.7" class="ltx_tr">
<td id="A4.SS2.tab2.1.7.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.7.1.1.1" class="ltx_p">- Ensure each question is directly related to a specific step mentioned in the blog post summary.</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.8" class="ltx_tr">
<td id="A4.SS2.tab2.1.8.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.8.1.1.1" class="ltx_p">- Important: The question must be created in a way that the answer to the question can be directly obtained or inferred from the structured summary but no logical thinking should be done to further process the information in steps. The blog post should only be used to construct the context of the situation, not to generate the question itself.</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.9" class="ltx_tr">
<td id="A4.SS2.tab2.1.9.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.9.1.1.1" class="ltx_p">- Important: Don’t explicitly mention the structured summary or blog post in the question. Assume the person answering can reference it. Create long complex situations and questions.</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.10" class="ltx_tr">
<td id="A4.SS2.tab2.1.10.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.10.1.1.1" class="ltx_p">- Provide suitable distractors in the question, complex stories, unique names, etc. Anything that makes the question more interesting, yet, answerable.</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.11" class="ltx_tr">
<td id="A4.SS2.tab2.1.11.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.11.1.1.1" class="ltx_p">- Make sure all questions attend separate parts of the structured summary.</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.12" class="ltx_tr">
<td id="A4.SS2.tab2.1.12.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.12.1.1.1" class="ltx_p"><span id="A4.SS2.tab2.1.12.1.1.1.1" class="ltx_text ltx_font_italic">Answer Guidelines:</span></span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.13" class="ltx_tr">
<td id="A4.SS2.tab2.1.13.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.13.1.1.1" class="ltx_p">- Provide short, concise answers.</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.14" class="ltx_tr">
<td id="A4.SS2.tab2.1.14.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.14.1.1.1" class="ltx_p">- Answers should be definitive and not open-ended.</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.15" class="ltx_tr">
<td id="A4.SS2.tab2.1.15.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.15.1.1.1" class="ltx_p">- Offer several paraphrased answers for each question. (A1, A2, A3)</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.16" class="ltx_tr">
<td id="A4.SS2.tab2.1.16.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.16.1.1.1" class="ltx_p"><span id="A4.SS2.tab2.1.16.1.1.1.1" class="ltx_text ltx_font_italic">Output Format:</span> Present your questions and answers in a structured JSON format, following the provided example.</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.17" class="ltx_tr">
<td id="A4.SS2.tab2.1.17.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.17.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.17.1.1.1" class="ltx_p">Example Structure:</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.18" class="ltx_tr">
<td id="A4.SS2.tab2.1.18.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.18.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.18.1.1.1" class="ltx_p">- Output JSON:</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.19" class="ltx_tr">
<td id="A4.SS2.tab2.1.19.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.19.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.19.1.1.1" class="ltx_p">{
"1": {</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.20" class="ltx_tr">
<td id="A4.SS2.tab2.1.20.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.20.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.20.1.1.1" class="ltx_p">"Q": "First Applied Scenario Based Question",</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.21" class="ltx_tr">
<td id="A4.SS2.tab2.1.21.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.21.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.21.1.1.1" class="ltx_p">"A1": "Concise Answer 1",</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.22" class="ltx_tr">
<td id="A4.SS2.tab2.1.22.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.22.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.22.1.1.1" class="ltx_p">"A2": "",</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.23" class="ltx_tr">
<td id="A4.SS2.tab2.1.23.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.23.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.23.1.1.1" class="ltx_p">"A3": "",</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.24" class="ltx_tr">
<td id="A4.SS2.tab2.1.24.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.24.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.24.1.1.1" class="ltx_p">},</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.25" class="ltx_tr">
<td id="A4.SS2.tab2.1.25.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.25.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.25.1.1.1" class="ltx_p">"2": {</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.26" class="ltx_tr">
<td id="A4.SS2.tab2.1.26.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.26.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.26.1.1.1" class="ltx_p">"Q": "",</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.27" class="ltx_tr">
<td id="A4.SS2.tab2.1.27.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.27.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.27.1.1.1" class="ltx_p">"A1": "",</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.28" class="ltx_tr">
<td id="A4.SS2.tab2.1.28.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.28.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.28.1.1.1" class="ltx_p">"A2": "",</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.29" class="ltx_tr">
<td id="A4.SS2.tab2.1.29.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.29.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.29.1.1.1" class="ltx_p">"A3": "",</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.30" class="ltx_tr">
<td id="A4.SS2.tab2.1.30.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.30.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.30.1.1.1" class="ltx_p">},</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.31" class="ltx_tr">
<td id="A4.SS2.tab2.1.31.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.31.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.31.1.1.1" class="ltx_p">… More Q/A Pairs here</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.32" class="ltx_tr">
<td id="A4.SS2.tab2.1.32.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.32.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.32.1.1.1" class="ltx_p">}</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.33" class="ltx_tr">
<td id="A4.SS2.tab2.1.33.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.33.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.33.1.1.1" class="ltx_p"><span id="A4.SS2.tab2.1.33.1.1.1.1" class="ltx_text ltx_font_italic">Sample Questions:</span></span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.34" class="ltx_tr">
<td id="A4.SS2.tab2.1.34.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.34.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.34.1.1.1" class="ltx_p">1. Ram, aged 45 years old, was going home from the office in his Minivan and his Minivan broke down on the way. He now wants to find a Minivan mechanic to get it repaired. He was trying to follow the given article, but being a little forgetful, he could not remember the age of his Minivan. He thought his warranty documents could help, Where should he try to find them?</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.35" class="ltx_tr">
<td id="A4.SS2.tab2.1.35.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.35.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.35.1.1.1" class="ltx_p">2. Alice has decided to make custom fabric paint for a set of cotton t-shirts. She mixed equal parts of acrylic paint and a transparent gloss medium, but after testing on a swatch of cotton, the paint soaked through. What adjustment should she make to the paint mixture?</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.36" class="ltx_tr">
<td id="A4.SS2.tab2.1.36.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.36.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.36.1.1.1" class="ltx_p">3. Selena has recurrent tonsil stones and her doctor has prescribed a course of antibiotics to address the issue. Unfortunately, the antibiotics weren’t successful and Selena hasn’t experienced any side effects or a relapse. What would her doctor’s advice likely be at this stage?</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.37" class="ltx_tr">
<td id="A4.SS2.tab2.1.37.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.37.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.37.1.1.1" class="ltx_p">4. Mark, an aspiring VFX artist, is enthusiastic about networking to enhance his opportunities in the field. He wants to join an industry group like the Visual Effects Society (VES). However, he is uncertain about the number of VES members and their global distribution. How can Mark find this information to ensure the group’s relevance to his networking goals?</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.38" class="ltx_tr">
<td id="A4.SS2.tab2.1.38.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab2.1.38.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.38.1.1.1" class="ltx_p"><span id="A4.SS2.tab2.1.38.1.1.1.1" class="ltx_text ltx_font_italic">PS: Your Answers should be BRIEF, definitive and must offer three paraphrased versions A1, A2, A3. Make sure the questions are not too open ended and concrete.</span></span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab2.1.39" class="ltx_tr">
<td id="A4.SS2.tab2.1.39.1" class="ltx_td ltx_align_left ltx_border_bb">
<span id="A4.SS2.tab2.1.39.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab2.1.39.1.1.1" class="ltx_p">Also DO NOT MENTION THE BLOG/STRUCTURED SUMMARY/SCRIPT IN THE QUESTION.</span>
</span>
</td>
</tr>
</table>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<figure id="A4.SS2.tab3" class="ltx_table">
<table id="A4.SS2.tab3.1" class="ltx_tabular ltx_align_middle">
<tr id="A4.SS2.tab3.1.1" class="ltx_tr">
<td id="A4.SS2.tab3.1.1.1" class="ltx_td ltx_align_left ltx_border_tt">
<span id="A4.SS2.tab3.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.1.1.1.1" class="ltx_p"><span id="A4.SS2.tab3.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Flow Referential</span></span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.2" class="ltx_tr">
<td id="A4.SS2.tab3.1.2.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="A4.SS2.tab3.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.2.1.1.1" class="ltx_p"><span id="A4.SS2.tab3.1.2.1.1.1.1" class="ltx_text ltx_font_italic">Task</span>: You will analyze a step-by-step structured summary and Mermaid Flowchart Representation of a blog post or code script. This post details specific steps to handle certain tasks.</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.3" class="ltx_tr">
<td id="A4.SS2.tab3.1.3.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.3.1.1.1" class="ltx_p"><span id="A4.SS2.tab3.1.3.1.1.1.1" class="ltx_text ltx_font_italic">Your Role</span>: As a capable flowchart path and flow analyzer your task is to focus on critical sub-areas of the processes and flowchart and create path-based questions from that subflowchart.</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.4" class="ltx_tr">
<td id="A4.SS2.tab3.1.4.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.4.1.1.1" class="ltx_p"><span id="A4.SS2.tab3.1.4.1.1.1.1" class="ltx_text ltx_font_italic">Guidelines for Question Development:</span></span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.5" class="ltx_tr">
<td id="A4.SS2.tab3.1.5.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.5.1.1.1" class="ltx_p">- The first step is to decide on how many questions to create: If the flowchart is long and complex, break it down into smaller areas and create more questions (3). If the flowchart is short create fewer (2-3) but still good quality questions that would not be easy to answer directly. Focus on specific, relevant / crucial paths of the structured flowchart script and summary.</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.6" class="ltx_tr">
<td id="A4.SS2.tab3.1.6.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.6.1.1.1" class="ltx_p">- Create questions based on node information looking FORWARD, BACKWARD, IN THE MIDDLE, etc. Questions about crucial decisions taken in a possible path.</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.7" class="ltx_tr">
<td id="A4.SS2.tab3.1.7.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.7.1.1.1" class="ltx_p">- Craft questions about paths that are creative and hard but MUST HAVE A SINGLE DEFINITIVE TRUE ANSWER.</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.8" class="ltx_tr">
<td id="A4.SS2.tab3.1.8.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.8.1.1.1" class="ltx_p">- Important: Don’t explicitly mention the structured summary or flowchart in the question. Assume the person answering can reference it. Create long complex situations and questions.</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.9" class="ltx_tr">
<td id="A4.SS2.tab3.1.9.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.9.1.1.1" class="ltx_p">- Create questions about backtracking, future paths, conditionals, nodes or steps in the middle, etc. Anything that is interesting in a flowchart path.</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.10" class="ltx_tr">
<td id="A4.SS2.tab3.1.10.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.10.1.1.1" class="ltx_p">- IMPORTANT! It is very important that the current node/step or the node/path in question later is mentioned clearly. The rules for counting must be clearly mentioned.</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.11" class="ltx_tr">
<td id="A4.SS2.tab3.1.11.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.11.1.1.1" class="ltx_p">Look at the sample questions below to create questions.</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.12" class="ltx_tr">
<td id="A4.SS2.tab3.1.12.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.12.1.1.1" class="ltx_p"><span id="A4.SS2.tab3.1.12.1.1.1.1" class="ltx_text ltx_font_italic">Answer Guidelines:</span></span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.13" class="ltx_tr">
<td id="A4.SS2.tab3.1.13.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.13.1.1.1" class="ltx_p">- Provide concise direct answers that are relevant to the question asked.</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.14" class="ltx_tr">
<td id="A4.SS2.tab3.1.14.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.14.1.1.1" class="ltx_p">- Answers should be definitive.</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.15" class="ltx_tr">
<td id="A4.SS2.tab3.1.15.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.15.1.1.1" class="ltx_p">- Offer several paraphrased answers for each question. (A1, A2, A3)</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.16" class="ltx_tr">
<td id="A4.SS2.tab3.1.16.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.16.1.1.1" class="ltx_p"><span id="A4.SS2.tab3.1.16.1.1.1.1" class="ltx_text ltx_font_italic">Output Format:</span> Present your questions and answers in a structured JSON format, following the provided example.</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.17" class="ltx_tr">
<td id="A4.SS2.tab3.1.17.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.17.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.17.1.1.1" class="ltx_p">Example Structure:</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.18" class="ltx_tr">
<td id="A4.SS2.tab3.1.18.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.18.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.18.1.1.1" class="ltx_p">- Output JSON:</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.19" class="ltx_tr">
<td id="A4.SS2.tab3.1.19.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.19.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.19.1.1.1" class="ltx_p">{</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.20" class="ltx_tr">
<td id="A4.SS2.tab3.1.20.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.20.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.20.1.1.1" class="ltx_p">"1": {</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.21" class="ltx_tr">
<td id="A4.SS2.tab3.1.21.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.21.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.21.1.1.1" class="ltx_p">"Q": "First Path Based Question",</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.22" class="ltx_tr">
<td id="A4.SS2.tab3.1.22.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.22.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.22.1.1.1" class="ltx_p">"A1": "Concise Answer 1",</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.23" class="ltx_tr">
<td id="A4.SS2.tab3.1.23.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.23.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.23.1.1.1" class="ltx_p">"A2": "",</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.24" class="ltx_tr">
<td id="A4.SS2.tab3.1.24.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.24.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.24.1.1.1" class="ltx_p">"A3": ""</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.25" class="ltx_tr">
<td id="A4.SS2.tab3.1.25.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.25.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.25.1.1.1" class="ltx_p">},</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.26" class="ltx_tr">
<td id="A4.SS2.tab3.1.26.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.26.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.26.1.1.1" class="ltx_p">"2": {</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.27" class="ltx_tr">
<td id="A4.SS2.tab3.1.27.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.27.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.27.1.1.1" class="ltx_p">"Q": "",</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.28" class="ltx_tr">
<td id="A4.SS2.tab3.1.28.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.28.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.28.1.1.1" class="ltx_p">"A1": "",</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.29" class="ltx_tr">
<td id="A4.SS2.tab3.1.29.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.29.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.29.1.1.1" class="ltx_p">"A2": "",</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.30" class="ltx_tr">
<td id="A4.SS2.tab3.1.30.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.30.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.30.1.1.1" class="ltx_p">"A3": ""</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.31" class="ltx_tr">
<td id="A4.SS2.tab3.1.31.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.31.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.31.1.1.1" class="ltx_p">},</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.32" class="ltx_tr">
<td id="A4.SS2.tab3.1.32.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.32.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.32.1.1.1" class="ltx_p">}</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.33" class="ltx_tr">
<td id="A4.SS2.tab3.1.33.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.33.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.33.1.1.1" class="ltx_p"><span id="A4.SS2.tab3.1.33.1.1.1.1" class="ltx_text ltx_font_italic">Sample Questions:</span></span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.34" class="ltx_tr">
<td id="A4.SS2.tab3.1.34.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.34.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.34.1.1.1" class="ltx_p">1. What is the second step, given my zeroeth step is taking a negative decision at "Bostik Spritzkork 3070 Available?"?</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.35" class="ltx_tr">
<td id="A4.SS2.tab3.1.35.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.35.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.35.1.1.1" class="ltx_p">2. If I currently have to fill the mold with plaster, what decision must have I taken a few steps back and what is the condition present at that node?</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.36" class="ltx_tr">
<td id="A4.SS2.tab3.1.36.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.36.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.36.1.1.1" class="ltx_p">3. What is the minimum number of steps required to reach ’Final Inspection’ from the "change job?" conditional?</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.37" class="ltx_tr">
<td id="A4.SS2.tab3.1.37.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.37.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.37.1.1.1" class="ltx_p">4. Given the current zeroeth step is to close the top of the lid, what is the fifth step that I will be completing if I take the affirmative decision at any conditional present in between?</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.38" class="ltx_tr">
<td id="A4.SS2.tab3.1.38.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.38.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.38.1.1.1" class="ltx_p">5. If at the current step the bathtub is not yet full and requires more water, what are the labels or descriptions of the fifth and seventh steps encountered when following the affirmative path from the current decision node?</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.39" class="ltx_tr">
<td id="A4.SS2.tab3.1.39.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.39.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.39.1.1.1" class="ltx_p">6. How many steps are there from the initial "Start" node up to, but not including, the first decision point? In this count, the "Start" node is to be considered as the initial node or the ’zeroeth’ step.</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.40" class="ltx_tr">
<td id="A4.SS2.tab3.1.40.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.40.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.40.1.1.1" class="ltx_p">7. Alice is preparing for a rock-themed party and recalls Scarlet’s unique style. She decides to start with a band T-shirt but is unsure whether to buy it online or at a concert. Given her limited budget, what should Alice’s decision be based on?</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.41" class="ltx_tr">
<td id="A4.SS2.tab3.1.41.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.41.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.41.1.1.1" class="ltx_p">8. If a patient’s eligibility for tonsillectomy is currently being evaluated and they proceed with tonsillectomy following a positive recommendation, what would be the immediate next step, and what decision must have been made directly prior to this step?</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.42" class="ltx_tr">
<td id="A4.SS2.tab3.1.42.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.42.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.42.1.1.1" class="ltx_p"><span id="A4.SS2.tab3.1.42.1.1.1.1" class="ltx_text ltx_font_italic">Answers:</span></span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.43" class="ltx_tr">
<td id="A4.SS2.tab3.1.43.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.43.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.43.1.1.1" class="ltx_p">9. If I am currently at the ’Choose Show Audio Animation or press Control-A’ step, what was the decision made at the first decision point, and what is the immediate next step?</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.44" class="ltx_tr">
<td id="A4.SS2.tab3.1.44.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.44.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.44.1.1.1" class="ltx_p">A1: "The decision made was ’Yes’ at the ’Decision to edit audio effects?’ node, and the immediate next step is ’Audio effects editing mode activated’.</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.45" class="ltx_tr">
<td id="A4.SS2.tab3.1.45.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.45.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.45.1.1.1" class="ltx_p">A2: "At the ’Decision to edit audio effects?’ node, a positive decision was taken, leading to the next step of activating the audio effects editing mode.</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.46" class="ltx_tr">
<td id="A4.SS2.tab3.1.46.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.46.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.46.1.1.1" class="ltx_p">A3: "The first decision point led to a ’Yes’ outcome, and the following step is to activate the audio effects editing mode.</span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.47" class="ltx_tr">
<td id="A4.SS2.tab3.1.47.1" class="ltx_td ltx_align_left">
<span id="A4.SS2.tab3.1.47.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.47.1.1.1" class="ltx_p"><span id="A4.SS2.tab3.1.47.1.1.1.1" class="ltx_text ltx_font_italic">PS: Your Answers should be BRIEF, definitive and must offer three paraphrased versions A1, A2, A3. Make sure the questions are not too open ended and concrete.</span></span>
</span>
</td>
</tr>
<tr id="A4.SS2.tab3.1.48" class="ltx_tr">
<td id="A4.SS2.tab3.1.48.1" class="ltx_td ltx_align_left ltx_border_bb">
<span id="A4.SS2.tab3.1.48.1.1" class="ltx_inline-block ltx_align_top">
<span id="A4.SS2.tab3.1.48.1.1.1" class="ltx_p">Also DO NOT MENTION THE BLOG/STRUCTURED SUMMARY/ FLOWCHART SCRIPT IN THE QUESTION.</span>
</span>
</td>
</tr>
</table>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="A5" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Prompts for Question-Answering</h2>

<div id="A5.p1" class="ltx_para">
<p id="A5.p1.1" class="ltx_p">In this section we lists the prompts we use to query models</p>
</div>
<section id="A5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.1 </span>Few-Shot-COT-with-Directives</h3>

<figure id="A5.SS1.2" class="ltx_table">
<table id="A5.SS1.2.2" class="ltx_tabular ltx_align_middle">
<tr id="A5.SS1.2.2.3" class="ltx_tr">
<td id="A5.SS1.2.2.3.1" class="ltx_td ltx_align_left ltx_border_tt">
<span id="A5.SS1.2.2.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="A5.SS1.2.2.3.1.1.1" class="ltx_p"><span id="A5.SS1.2.2.3.1.1.1.1" class="ltx_text ltx_font_bold">Few-Shot COT<sub id="A5.SS1.2.2.3.1.1.1.1.1" class="ltx_sub">D</sub></span></span>
</span>
</td>
</tr>
<tr id="A5.SS1.2.2.4" class="ltx_tr">
<td id="A5.SS1.2.2.4.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="A5.SS1.2.2.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="A5.SS1.2.2.4.1.1.1" class="ltx_p">Examine the provided flowchart to answer the given question below. Here are some illustrative examples accompanied by a sequence of reasoning directives intended to stimulate analytical thought and elicit a rationale. These guidelines should facilitate the development of a rationale. Once a rationale has been formulated, proceed to present a conclusive final answer as in the examples.</span>
</span>
</td>
</tr>
<tr id="A5.SS1.2.2.5" class="ltx_tr">
<td id="A5.SS1.2.2.5.1" class="ltx_td ltx_align_left">
<span id="A5.SS1.2.2.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="A5.SS1.2.2.5.1.1.1" class="ltx_p"><span id="A5.SS1.2.2.5.1.1.1.1" class="ltx_text ltx_font_italic">Question - Answer pairs with Tags. The exemplar questions given depend upon the type of question we are asking</span></span>
</span>
</td>
</tr>
<tr id="A5.SS1.2.2.6" class="ltx_tr">
<td id="A5.SS1.2.2.6.1" class="ltx_td ltx_align_left">
<span id="A5.SS1.2.2.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="A5.SS1.2.2.6.1.1.1" class="ltx_p"><span id="A5.SS1.2.2.6.1.1.1.1" class="ltx_text ltx_font_bold">(Fact Retrieval/Applied Scenario/Flow Referential/Topological)</span></span>
</span>
</td>
</tr>
<tr id="A5.SS1.2.2.7" class="ltx_tr">
<td id="A5.SS1.2.2.7.1" class="ltx_td ltx_align_left">
<span id="A5.SS1.2.2.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="A5.SS1.2.2.7.1.1.1" class="ltx_p">Example:</span>
</span>
</td>
</tr>
<tr id="A5.SS1.1.1.1" class="ltx_tr">
<td id="A5.SS1.1.1.1.1" class="ltx_td ltx_align_left">
<span id="A5.SS1.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="A5.SS1.1.1.1.1.1.1" class="ltx_p"><math id="A5.SS1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\vdots" display="inline"><semantics id="A5.SS1.1.1.1.1.1.1.m1.1a"><mi mathvariant="normal" id="A5.SS1.1.1.1.1.1.1.m1.1.1" xref="A5.SS1.1.1.1.1.1.1.m1.1.1.cmml">⋮</mi><annotation-xml encoding="MathML-Content" id="A5.SS1.1.1.1.1.1.1.m1.1b"><ci id="A5.SS1.1.1.1.1.1.1.m1.1.1.cmml" xref="A5.SS1.1.1.1.1.1.1.m1.1.1">⋮</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.SS1.1.1.1.1.1.1.m1.1c">\vdots</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="A5.SS1.2.2.8" class="ltx_tr">
<td id="A5.SS1.2.2.8.1" class="ltx_td ltx_align_left">
<span id="A5.SS1.2.2.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="A5.SS1.2.2.8.1.1.1" class="ltx_p">Q1. What temperature should the oven be preheated to for making the cake?</span>
</span>
</td>
</tr>
<tr id="A5.SS1.2.2.9" class="ltx_tr">
<td id="A5.SS1.2.2.9.1" class="ltx_td ltx_align_left">
<span id="A5.SS1.2.2.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="A5.SS1.2.2.9.1.1.1" class="ltx_p">Tags: Temperature, Oven, Preheating, Cake
Reasoning: Take it step-by-step. Look for a node or cluster of nodes, in the flowchart that mention preheating the oven. Identify node / nodes that mention a ’preheating’.
After locating relevant nodes extract final answer if already present or reason further to deduce the correct answer.</span>
</span>
</td>
</tr>
<tr id="A5.SS1.2.2.10" class="ltx_tr">
<td id="A5.SS1.2.2.10.1" class="ltx_td ltx_align_left">
<span id="A5.SS1.2.2.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="A5.SS1.2.2.10.1.1.1" class="ltx_p">A. 325 degrees Fahrenheit.</span>
</span>
</td>
</tr>
<tr id="A5.SS1.2.2.2" class="ltx_tr">
<td id="A5.SS1.2.2.2.1" class="ltx_td ltx_align_left">
<span id="A5.SS1.2.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="A5.SS1.2.2.2.1.1.1" class="ltx_p"><math id="A5.SS1.2.2.2.1.1.1.m1.1" class="ltx_Math" alttext="\vdots" display="inline"><semantics id="A5.SS1.2.2.2.1.1.1.m1.1a"><mi mathvariant="normal" id="A5.SS1.2.2.2.1.1.1.m1.1.1" xref="A5.SS1.2.2.2.1.1.1.m1.1.1.cmml">⋮</mi><annotation-xml encoding="MathML-Content" id="A5.SS1.2.2.2.1.1.1.m1.1b"><ci id="A5.SS1.2.2.2.1.1.1.m1.1.1.cmml" xref="A5.SS1.2.2.2.1.1.1.m1.1.1">⋮</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.SS1.2.2.2.1.1.1.m1.1c">\vdots</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="A5.SS1.2.2.11" class="ltx_tr">
<td id="A5.SS1.2.2.11.1" class="ltx_td ltx_align_left">
<span id="A5.SS1.2.2.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="A5.SS1.2.2.11.1.1.1" class="ltx_p"><span id="A5.SS1.2.2.11.1.1.1.1" class="ltx_text ltx_font_italic">Concerned Question to Ask</span></span>
</span>
</td>
</tr>
<tr id="A5.SS1.2.2.12" class="ltx_tr">
<td id="A5.SS1.2.2.12.1" class="ltx_td ltx_align_left">
<span id="A5.SS1.2.2.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="A5.SS1.2.2.12.1.1.1" class="ltx_p">Example:</span>
</span>
</td>
</tr>
<tr id="A5.SS1.2.2.13" class="ltx_tr">
<td id="A5.SS1.2.2.13.1" class="ltx_td ltx_align_left ltx_border_bb">
<span id="A5.SS1.2.2.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="A5.SS1.2.2.13.1.1.1" class="ltx_p">What action is taken when the ’file’ is found to be not empty?</span>
</span>
</td>
</tr>
</table>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2406.19236" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2406.19237" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2406.19237">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2406.19237" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2406.19238" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Jul  5 23:39:34 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
