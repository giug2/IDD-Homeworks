<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2106.00005] Quantum Federated Learning with Quantum Data</title><meta property="og:description" content="Quantum machine learning (QML) has emerged as a promising field that leans on the developments in quantum computing to explore large complex machine learning problems. Recently, some purely quantum machine learning mod…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Quantum Federated Learning with Quantum Data">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Quantum Federated Learning with Quantum Data">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2106.00005">

<!--Generated on Sat Mar  2 05:25:14 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Quantum Federated Learning with Quantum Data</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Mahdi Chehimi
<br class="ltx_break">Department of Electrical and Computer Engineering
<br class="ltx_break">Virginia Tech
<br class="ltx_break">Blacksburg, VA 24060 
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter">mahdic@vt.edu</span> 
<br class="ltx_break">&amp;Walid Saad
<br class="ltx_break">Department of Electrical and Computer Engineering
<br class="ltx_break">Virginia Tech
<br class="ltx_break">Blacksburg, VA 24060 
<br class="ltx_break"><span id="id2.2.id2" class="ltx_text ltx_font_typewriter">walids@vt.edu</span> 
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id3.id1" class="ltx_p">Quantum machine learning (QML) has emerged as a promising field that leans on the developments in quantum computing to explore large complex machine learning problems. Recently, some purely quantum machine learning models were proposed such as quantum convolutional neural networks (QCNN) to perform classification on quantum data. However, all of the existing QML models rely on centralized solutions that cannot scale well for large-scale and distributed quantum networks. Hence, it is apropos to consider more practical quantum federated learning (QFL) solutions tailored towards emerging quantum network architectures. Indeed, developing QFL frameworks for quantum networks is critical given the fragile nature of computing qubits and the difficulty of transferring them. On top of its practical momentousness, QFL allows for distributing quantum learning by leveraging existing wireless communication infrastructure. This paper proposes the first fully quantum federated learning framework that can operate over quantum data and, thus, share the learning of quantum circuit parameters in a decentralized manner. First, given the lack of existing quantum federated datasets in the literature, the proposed framework begins by generating the first quantum federated dataset, with a hierarchical data format, for distributed quantum networks. Then, clients sharing QCNN models are fed with the quantum data to perform a classification task. Subsequently, the server aggregates the learnable quantum circuit parameters from clients and performs federated averaging. Extensive experiments are conducted to evaluate and validate the effectiveness of the proposed QFL solution. This work is the first to combine Google’s TensorFlow Federated and TensorFlow Quantum in a practical implementation.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Recent advances in quantum computing have revolutionized the way computations are done and resulted in quantum computers that solve complex large-scale problems in an extremely faster manner compared to classical computers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. For instance, in 2019, Google claimed achieving quantum supremacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, as their quantum computers were able to solve a problem, that would require 10,000 years of computations on a classical computer, within about 200 seconds using a quantum computer. Moreover, IBM is actively developing larger quantum computers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> with a clear roadmap for scaling up quantum technologies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. These major advances in quantum computing are rapidly leading to the deployment of quantum computers in a wide range of applications including finance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, communication networks, artificial intelligence (AI), and machine learning (ML) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.</p>
</div>
<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span>Quantum Machine Learning</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p id="S1.SS1.p1.1" class="ltx_p">The ability of quantum computers to handle exponential growth in the dimensions of data and perform linear algebra faster and more efficiently than classical computers lead to the blossoming of the field of <em id="S1.SS1.p1.1.1" class="ltx_emph ltx_font_italic">quantum machine learning</em> (QML) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. For instance, various hybrid quantum-classical ML algorithms have emerged recently, and, when run on quantum computers, achieved superior performance over their corresponding purely classical counterparts. These hybrid algorithms covered different areas in ML such as supervised learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, quantum support vector machines <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, unsupervised learning such as clustering <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, and quantum recommender systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.</p>
</div>
<div id="S1.SS1.p2" class="ltx_para">
<p id="S1.SS1.p2.1" class="ltx_p">With the recent developments of advanced quantum hardware and simulation systems, problems concerned with quantum many-body systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> become of particular importance. However, these problems have an extremely complex nature and exponentially large Hilbert spaces which requires exponentially difficult quantum state tomography to translate them into a classical framework efficiently. Moreover, the theoretical analysis of such complex, intrinsically quantum problems is often intractable. All these complex features impose major challenges (see <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>) on classical ML and hybrid QML models, rendering them inefficient when addressing such challenging problems.</p>
</div>
<div id="S1.SS1.p3" class="ltx_para">
<p id="S1.SS1.p3.1" class="ltx_p">These challenges motivated the recent development of a number of <em id="S1.SS1.p3.1.1" class="ltx_emph ltx_font_italic">purely quantum ML</em> models that can, in contrast to non-quantum or hybrid schemes, handle the complex nature of quantum many-body systems. In particular, parametrized quantum circuits (PQC) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> were proposed as the quantum version of classical neural networks (NNs), forming what is known as <em id="S1.SS1.p3.1.2" class="ltx_emph ltx_font_italic">quantum neural networks</em> (QNN). QNNs are quantum circuits with tunable parameters that can be <span id="S1.SS1.p3.1.3" class="ltx_ERROR undefined">\say</span>learned in a similar fashion to classical NNs.</p>
</div>
<div id="S1.SS1.p4" class="ltx_para">
<p id="S1.SS1.p4.1" class="ltx_p">Several QNN architectures were developed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> with the goal of performing classification on near-term quantum computers and training QNNs. Moreover, <em id="S1.SS1.p4.1.1" class="ltx_emph ltx_font_italic">quantum convolutional neural networks</em> (QCNNs) were proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> and achieved a promising performance on classification tasks. Very recently, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> demonstrated, using actual quantum computers, the advantages of QNNs compared with classical NNs. They verified that, if designed effectively, QNNs achieve a higher effective dimension from an information geometry point of view, in addition to faster training capabilities compared to classical NNs. These findings highly motivate further investigation in the area of QNN given the great potential in this field.</p>
</div>
</section>
<section id="S1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.2 </span>Quantum Communication Networks</h3>

<div id="S1.SS2.p1" class="ltx_para">
<p id="S1.SS2.p1.1" class="ltx_p">Along with the advances in QML, integrating quantum computers in future communication systems is necessary to handle the challenges caused by the rapidly growing volume of data. Moreover, the emerging networks of quantum sensors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> and the envisioned quantum internet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> highly motivate designing large-scale distributed quantum networks. Such networks would allow for distributed quantum computing, large-scale quantum communications, and collaborations between quantum clients to perform common tasks.</p>
</div>
<div id="S1.SS2.p2" class="ltx_para">
<p id="S1.SS2.p2.1" class="ltx_p">In this context, existing quantum communication (QC) networks are particularly suitable for deploying secure communications using the so-called quantum key distribution (QKD) and its variants <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. However, such networks usually rely on photonic quantum hardware that cannot perform strong QML computations, and, thus, they are only suitable for QKD encryption. In fact, the type of quantum computers needed to perform strong computations and run QML frameworks rely on advanced hardware and different technologies such as trapped-ions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, quantum dots <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, superconducting qubits <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, among others. Such technologies require special conditions such as extremely low temperatures, and vibration-free environments to store qubits and effectively maintain their quantum states <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Thus, <em id="S1.SS2.p2.1.1" class="ltx_emph ltx_font_italic">it is much more difficult to transfer the quantum data of QML models using QC channels in an efficient manner</em>. This is particularly true given the inherent problem of decoherence whereby the quantum data sent in qubits decays gradually as it interacts with the environment, which shortens the lifetime of qubits <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>.</p>
</div>
<div id="S1.SS2.p3" class="ltx_para">
<p id="S1.SS2.p3.1" class="ltx_p">Thus, there is a natural need for distributed learning solutions such as federated learning (FL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> in those emerging quantum networks. However, performing a distributed exchange of qubits is not effective for collaborative learning of purely quantum data since it requires the development of extremely complex advanced hardware which will not be available before a few decades <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. Given these inherent challenges of distributed quantum systems, one natural research question emerges: <em id="S1.SS2.p3.1.1" class="ltx_emph ltx_font_italic">Can we still perform collaborative quantum learning over quantum computing clients while leveraging existing wireless technologies like 5G instead of relying on quantum channels?</em></p>
</div>
<div id="S1.SS2.p4" class="ltx_para">
<p id="S1.SS2.p4.1" class="ltx_p">Towards answering this question, we observe that one can exploit the fact that FL algorithms allow the exchange of model parameters, rather than the quantum data itself. As such, it is conceivable that FL can be used to operate over quantum data and, then, leverage classical wireless channels to exchange the model parameters, without the need for a full QC network that is not available. However, remarkably, to the best of our knowledge, no prior work has proposed a thorough, comprehensive framework for implementing FL over purely quantum communication networks, as will be evident from Section <a href="#S1.SS5" title="1.5 Related Works ‣ 1 Introduction ‣ Quantum Federated Learning with Quantum Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1.5</span></a>. As such, this is the key problem we address here.</p>
</div>
</section>
<section id="S1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.3 </span>Problem Statement</h3>

<div id="S1.SS3.p1" class="ltx_para">
<p id="S1.SS3.p1.1" class="ltx_p">As already noted, emerging large-scale QC networks will require collaborative learning between quantum clients. The qubits used for communication are fragile and susceptible for various losses which renders the efficient transmission of purely quantum data for QML applications a challenging task. Moreover, all of the existing QML models rely on centralized solutions that cannot scale well for future, large-scale and distributed quantum networks. Thus, there is a need for a comprehensive <em id="S1.SS3.p1.1.1" class="ltx_emph ltx_font_italic">quantum federated learning</em> (QFL) framework that allows for distributed quantum learning between purely quantum clients sharing a QML model without the need to transfer the quantum data itself. Such a QFL framework should allow integrating quantum clients in existing classical wireless communication systems. Developing such a QFL framework requires answering many challenging questions:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">How can we generate quantum federated datasets, which are non-existent in prior art, in order to practically implement QFL?</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Are existing classical FL algorithms capable of serializing and learning the quantum circuit parameters, or there is a need for new algorithms?</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">What are the practical challenges and constraints imposed by today’s state-of-the-art quantum hardware on applying the proposed QFL framework?</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">Can the proposed QFL framework handle quantum data with different underlying distributions (e.g., IID vs. non-IID) for different clients?</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S1.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.4 </span>Contributions</h3>

<div id="S1.SS4.p1" class="ltx_para">
<p id="S1.SS4.p1.1" class="ltx_p">The main contribution of this paper is to address the aforementioned challenges by developing a novel comprehensive federated learning framework that allows for distributing quantum learning collaboratively between clients with purely quantum data (e.g., quantum sensors) while leveraging existing classical wireless communication infrastructure. The effectiveness of the proposed approach is validated with extensive experiments and rigorous results that insightfully answer the fundamental challenges posed in Section <a href="#S1.SS3" title="1.3 Problem Statement ‣ 1 Introduction ‣ Quantum Federated Learning with Quantum Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1.3</span></a>. The contributions of this work can be summarized as follows:</p>
<ul id="S1.I2" class="ltx_itemize">
<li id="S1.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i1.p1" class="ltx_para">
<p id="S1.I2.i1.p1.1" class="ltx_p">We propose the first purely quantum QFL framework for clients with quantum computing capabilities that employ QCNN models to perform a classification task by decentralizing the learning of quantum circuit parameters and performing averaging on the server side.</p>
</div>
</li>
<li id="S1.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i2.p1" class="ltx_para">
<p id="S1.I2.i2.p1.1" class="ltx_p">The proposed QFL framework allows for integrating quantum computing clients with the state-of-the-art infrastructure in classical communication networks without relying on quantum channels. Thus, the proposed framework is amenable to practical implementations in existing communication networks.</p>
</div>
</li>
<li id="S1.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i3.p1" class="ltx_para">
<p id="S1.I2.i3.p1.1" class="ltx_p">We generate a novel quantum federated dataset which can be used for distributed learning in QC networks. The generated dataset has a hierarchical data format and is the first of its kind in the literature. This dataset can serve as a baseline for future QFL implementations with quantum sensors.</p>
</div>
</li>
<li id="S1.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i4.p1" class="ltx_para">
<p id="S1.I2.i4.p1.1" class="ltx_p">We conduct the first extensive experiments that combine Google’s TensorFlow Quantum (TFQ) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> and TensorFlow Federated (TFF) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. The developed experiments verify the applicability and effectiveness of the proposed approach. The results show that the proposed QFL framework achieves comparable, and in some cases superior, performance compared to the centralized, purely QML setup. Our results also show that the model can handle IID and non-IID quantum data. A key finding is that classical FL algorithms can be applied to decentralize the learning in purely quantum QML applications.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S1.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.5 </span>Related Works</h3>

<div id="S1.SS5.p1" class="ltx_para">
<p id="S1.SS5.p1.1" class="ltx_p">A handful of prior works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> exist on decentralized QML models, but those works neither address the previously posed challenges nor provide a solution to practically distribute quantum learning algorithms that are tailored towards emerging large-scale purely QC networks with purely quantum QML. First, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> proposed a protocol using which a single client that does not have enough quantum capabilities performs a classical ML task (vector classification) by communicating with a quantum server to run a small-scale QML model and send the learned parameters back to the client. The main objective of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> is to preserve privacy of the communication link while training the classical ML model. However, this work considers a single client, and it does not scale-up to emerging quantum networks that encompass multiple distributed clients as we consider here. Also, this prior art <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> does not consider the deployment of quantum computing clients nor the integration of quantum data-based QML networks which is a challenging task that we will address.</p>
</div>
<div id="S1.SS5.p2" class="ltx_para">
<p id="S1.SS5.p2.1" class="ltx_p">Meanwhile, a concise vision of a QFL architecture for general optimization in wireless communication networks is discussed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. This prior work considers a radically different scenario than the one treated here. In particular, it considers a wireless network of classical non-quantum mobile users, communicating with access points that run a shallow QNN model for optimizing the wireless network. The access points use FL and share the learning parameters with a server having another deeper QNN model. However, the work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> only discusses a conceptual architecture without any implementation, verification, or concrete results. Moreover, it does not consider quantum clients or quantum data in the communication network, and it relies solely on classical data.</p>
</div>
<div id="S1.SS5.p3" class="ltx_para">
<p id="S1.SS5.p3.1" class="ltx_p">Meanwhile, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> considered a vertical federated learning approach for decentralized feature extraction in automatic speech recognition tasks. Their model includes a quantum server that uses a QCNN for feature extraction. However, this approach is totally different from our proposed framework as it primarily studies the usage of QCNNs for extracting useful features from classical non-quantum data, and only assumes the server to have quantum capabilities in the communication network.</p>
</div>
<div id="S1.SS5.p4" class="ltx_para">
<p id="S1.SS5.p4.1" class="ltx_p">Finally, the most relevant prior work is the work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> which considered a hybrid quantum-classical ML model trained in a federated setup. The work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> is different from our proposed QFL framework since it adopts a transfer learning approach where a pre-trained CNN model is used to extract features from classical data and compress it into a vector passed to a QNN to make predictions. Although the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> discuss federating the QML models, their implementation uses classical data and has a very limited contribution to the purely quantum setup since it does not address the biggest challenges such as the lack of a purely quantum federated dataset in the literature and the lack of a holistic implementation.</p>
</div>
<div id="S1.SS5.p5" class="ltx_para">
<p id="S1.SS5.p5.1" class="ltx_p">Clearly, there is no prior work that addresses QFL while leveraging purely quantum data learning. This gap in the literature must be extensively addressed as it could provide a breakthrough in the way QC networks are looked at.</p>
</div>
<div id="S1.SS5.p6" class="ltx_para">
<p id="S1.SS5.p6.1" class="ltx_p">The rest of this paper is organized as follows. Section <a href="#S2" title="2 Problem Setup ‣ Quantum Federated Learning with Quantum Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> describes the problem setup and the adopted QFL model in details. Next, the proposed quantum federated dataset is developed and the proposed process to generate it is presented in Section <a href="#S3" title="3 Quantum Federated Dataset ‣ Quantum Federated Learning with Quantum Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. In Section <a href="#S4" title="4 Experiments ‣ Quantum Federated Learning with Quantum Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we conduct the experiments and discuss the key results. Conclusions are drawn in Section <a href="#S6" title="6 Conclusion ‣ Quantum Federated Learning with Quantum Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. Finally, insights on the challenges facing the proposed QFL framework and its broader impact are presented in Section <a href="#S5" title="5 Challenges and Future Outlook ‣ Quantum Federated Learning with Quantum Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Problem Setup</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.9" class="ltx_p">We consider a quantum network setup (Figure <a href="#S2.F1" title="Figure 1 ‣ 2 Problem Setup ‣ Quantum Federated Learning with Quantum Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) consisting of a server and a set <math id="S2.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{K}" display="inline"><semantics id="S2.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">𝒦</mi><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><ci id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">𝒦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">\mathcal{K}</annotation></semantics></math> of <math id="S2.p1.2.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.p1.2.m2.1a"><mi id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><ci id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">K</annotation></semantics></math> quantum computing clients sharing a QCNN model such as the one proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. Each client generates its own quantum data locally and trains a local QCNN model to perform binary classification. The generated data consists of excitations for an <math id="S2.p1.3.m3.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.p1.3.m3.1a"><mi id="S2.p1.3.m3.1.1" xref="S2.p1.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.p1.3.m3.1b"><ci id="S2.p1.3.m3.1.1.cmml" xref="S2.p1.3.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.3.m3.1c">N</annotation></semantics></math>-qubits quantum cluster state fed as labeled inputs in pairs <math id="S2.p1.4.m4.2" class="ltx_Math" alttext="(\ket{\psi_{m}},y_{m})" display="inline"><semantics id="S2.p1.4.m4.2a"><mrow id="S2.p1.4.m4.2.2.1" xref="S2.p1.4.m4.2.2.2.cmml"><mo stretchy="false" id="S2.p1.4.m4.2.2.1.2" xref="S2.p1.4.m4.2.2.2.cmml">(</mo><mrow id="S2.p1.4.m4.1.1.3" xref="S2.p1.4.m4.1.1.2.cmml"><mo stretchy="false" id="S2.p1.4.m4.1.1.3.1" xref="S2.p1.4.m4.1.1.2.1.cmml">|</mo><msub id="S2.p1.4.m4.1.1.1.1" xref="S2.p1.4.m4.1.1.1.1.cmml"><mi id="S2.p1.4.m4.1.1.1.1.2" xref="S2.p1.4.m4.1.1.1.1.2.cmml">ψ</mi><mi id="S2.p1.4.m4.1.1.1.1.3" xref="S2.p1.4.m4.1.1.1.1.3.cmml">m</mi></msub><mo stretchy="false" id="S2.p1.4.m4.1.1.3.2" xref="S2.p1.4.m4.1.1.2.1.cmml">⟩</mo></mrow><mo id="S2.p1.4.m4.2.2.1.3" xref="S2.p1.4.m4.2.2.2.cmml">,</mo><msub id="S2.p1.4.m4.2.2.1.1" xref="S2.p1.4.m4.2.2.1.1.cmml"><mi id="S2.p1.4.m4.2.2.1.1.2" xref="S2.p1.4.m4.2.2.1.1.2.cmml">y</mi><mi id="S2.p1.4.m4.2.2.1.1.3" xref="S2.p1.4.m4.2.2.1.1.3.cmml">m</mi></msub><mo stretchy="false" id="S2.p1.4.m4.2.2.1.4" xref="S2.p1.4.m4.2.2.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.4.m4.2b"><interval closure="open" id="S2.p1.4.m4.2.2.2.cmml" xref="S2.p1.4.m4.2.2.1"><apply id="S2.p1.4.m4.1.1.2.cmml" xref="S2.p1.4.m4.1.1.3"><csymbol cd="latexml" id="S2.p1.4.m4.1.1.2.1.cmml" xref="S2.p1.4.m4.1.1.3.1">ket</csymbol><apply id="S2.p1.4.m4.1.1.1.1.cmml" xref="S2.p1.4.m4.1.1.1.1"><csymbol cd="ambiguous" id="S2.p1.4.m4.1.1.1.1.1.cmml" xref="S2.p1.4.m4.1.1.1.1">subscript</csymbol><ci id="S2.p1.4.m4.1.1.1.1.2.cmml" xref="S2.p1.4.m4.1.1.1.1.2">𝜓</ci><ci id="S2.p1.4.m4.1.1.1.1.3.cmml" xref="S2.p1.4.m4.1.1.1.1.3">𝑚</ci></apply></apply><apply id="S2.p1.4.m4.2.2.1.1.cmml" xref="S2.p1.4.m4.2.2.1.1"><csymbol cd="ambiguous" id="S2.p1.4.m4.2.2.1.1.1.cmml" xref="S2.p1.4.m4.2.2.1.1">subscript</csymbol><ci id="S2.p1.4.m4.2.2.1.1.2.cmml" xref="S2.p1.4.m4.2.2.1.1.2">𝑦</ci><ci id="S2.p1.4.m4.2.2.1.1.3.cmml" xref="S2.p1.4.m4.2.2.1.1.3">𝑚</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.4.m4.2c">(\ket{\psi_{m}},y_{m})</annotation></semantics></math>: <math id="S2.p1.5.m5.4" class="ltx_Math" alttext="m=1,2,...,M" display="inline"><semantics id="S2.p1.5.m5.4a"><mrow id="S2.p1.5.m5.4.5" xref="S2.p1.5.m5.4.5.cmml"><mi id="S2.p1.5.m5.4.5.2" xref="S2.p1.5.m5.4.5.2.cmml">m</mi><mo id="S2.p1.5.m5.4.5.1" xref="S2.p1.5.m5.4.5.1.cmml">=</mo><mrow id="S2.p1.5.m5.4.5.3.2" xref="S2.p1.5.m5.4.5.3.1.cmml"><mn id="S2.p1.5.m5.1.1" xref="S2.p1.5.m5.1.1.cmml">1</mn><mo id="S2.p1.5.m5.4.5.3.2.1" xref="S2.p1.5.m5.4.5.3.1.cmml">,</mo><mn id="S2.p1.5.m5.2.2" xref="S2.p1.5.m5.2.2.cmml">2</mn><mo id="S2.p1.5.m5.4.5.3.2.2" xref="S2.p1.5.m5.4.5.3.1.cmml">,</mo><mi mathvariant="normal" id="S2.p1.5.m5.3.3" xref="S2.p1.5.m5.3.3.cmml">…</mi><mo id="S2.p1.5.m5.4.5.3.2.3" xref="S2.p1.5.m5.4.5.3.1.cmml">,</mo><mi id="S2.p1.5.m5.4.4" xref="S2.p1.5.m5.4.4.cmml">M</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.5.m5.4b"><apply id="S2.p1.5.m5.4.5.cmml" xref="S2.p1.5.m5.4.5"><eq id="S2.p1.5.m5.4.5.1.cmml" xref="S2.p1.5.m5.4.5.1"></eq><ci id="S2.p1.5.m5.4.5.2.cmml" xref="S2.p1.5.m5.4.5.2">𝑚</ci><list id="S2.p1.5.m5.4.5.3.1.cmml" xref="S2.p1.5.m5.4.5.3.2"><cn type="integer" id="S2.p1.5.m5.1.1.cmml" xref="S2.p1.5.m5.1.1">1</cn><cn type="integer" id="S2.p1.5.m5.2.2.cmml" xref="S2.p1.5.m5.2.2">2</cn><ci id="S2.p1.5.m5.3.3.cmml" xref="S2.p1.5.m5.3.3">…</ci><ci id="S2.p1.5.m5.4.4.cmml" xref="S2.p1.5.m5.4.4">𝑀</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.5.m5.4c">m=1,2,...,M</annotation></semantics></math>, where <math id="S2.p1.6.m6.1" class="ltx_Math" alttext="\ket{\psi_{m}}" display="inline"><semantics id="S2.p1.6.m6.1a"><mrow id="S2.p1.6.m6.1.1.3" xref="S2.p1.6.m6.1.1.2.cmml"><mo stretchy="false" id="S2.p1.6.m6.1.1.3.1" xref="S2.p1.6.m6.1.1.2.1.cmml">|</mo><msub id="S2.p1.6.m6.1.1.1.1" xref="S2.p1.6.m6.1.1.1.1.cmml"><mi id="S2.p1.6.m6.1.1.1.1.2" xref="S2.p1.6.m6.1.1.1.1.2.cmml">ψ</mi><mi id="S2.p1.6.m6.1.1.1.1.3" xref="S2.p1.6.m6.1.1.1.1.3.cmml">m</mi></msub><mo stretchy="false" id="S2.p1.6.m6.1.1.3.2" xref="S2.p1.6.m6.1.1.2.1.cmml">⟩</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.6.m6.1b"><apply id="S2.p1.6.m6.1.1.2.cmml" xref="S2.p1.6.m6.1.1.3"><csymbol cd="latexml" id="S2.p1.6.m6.1.1.2.1.cmml" xref="S2.p1.6.m6.1.1.3.1">ket</csymbol><apply id="S2.p1.6.m6.1.1.1.1.cmml" xref="S2.p1.6.m6.1.1.1.1"><csymbol cd="ambiguous" id="S2.p1.6.m6.1.1.1.1.1.cmml" xref="S2.p1.6.m6.1.1.1.1">subscript</csymbol><ci id="S2.p1.6.m6.1.1.1.1.2.cmml" xref="S2.p1.6.m6.1.1.1.1.2">𝜓</ci><ci id="S2.p1.6.m6.1.1.1.1.3.cmml" xref="S2.p1.6.m6.1.1.1.1.3">𝑚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.6.m6.1c">\ket{\psi_{m}}</annotation></semantics></math> represents the <math id="S2.p1.7.m7.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S2.p1.7.m7.1a"><mi id="S2.p1.7.m7.1.1" xref="S2.p1.7.m7.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S2.p1.7.m7.1b"><ci id="S2.p1.7.m7.1.1.cmml" xref="S2.p1.7.m7.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.7.m7.1c">m</annotation></semantics></math>-th sample input quantum state, <math id="S2.p1.8.m8.1" class="ltx_Math" alttext="y_{m}" display="inline"><semantics id="S2.p1.8.m8.1a"><msub id="S2.p1.8.m8.1.1" xref="S2.p1.8.m8.1.1.cmml"><mi id="S2.p1.8.m8.1.1.2" xref="S2.p1.8.m8.1.1.2.cmml">y</mi><mi id="S2.p1.8.m8.1.1.3" xref="S2.p1.8.m8.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p1.8.m8.1b"><apply id="S2.p1.8.m8.1.1.cmml" xref="S2.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S2.p1.8.m8.1.1.1.cmml" xref="S2.p1.8.m8.1.1">subscript</csymbol><ci id="S2.p1.8.m8.1.1.2.cmml" xref="S2.p1.8.m8.1.1.2">𝑦</ci><ci id="S2.p1.8.m8.1.1.3.cmml" xref="S2.p1.8.m8.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.8.m8.1c">y_{m}</annotation></semantics></math> is a binary label that classifies whether the cluster state is excited (takes value of 0) or not (takes value of 1), and <math id="S2.p1.9.m9.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S2.p1.9.m9.1a"><mi id="S2.p1.9.m9.1.1" xref="S2.p1.9.m9.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.p1.9.m9.1b"><ci id="S2.p1.9.m9.1.1.cmml" xref="S2.p1.9.m9.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.9.m9.1c">M</annotation></semantics></math> is the number of data samples. Such a setup is typical for quantum sensor networks and will be further analyzed in Section <a href="#S3" title="3 Quantum Federated Dataset ‣ Quantum Federated Learning with Quantum Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2106.00005/assets/system_model.jpg" id="S2.F1.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="448" height="252" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Problem Setup.</figcaption>
</figure>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">In an analogous manner to classical convolutional neural networks, and following a translationally invariant behavior, the QCNN model includes a sequence of quantum convolution layers followed by quantum pooling layers. After incorporating sufficient layers, a quantum fully connected layer is applied, and predictions are made by performing quantum measurement of qubits.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.7" class="ltx_p">More formally, each convolution layer <math id="S2.p3.1.m1.1" class="ltx_Math" alttext="C\in\mathcal{L}_{c}" display="inline"><semantics id="S2.p3.1.m1.1a"><mrow id="S2.p3.1.m1.1.1" xref="S2.p3.1.m1.1.1.cmml"><mi id="S2.p3.1.m1.1.1.2" xref="S2.p3.1.m1.1.1.2.cmml">C</mi><mo id="S2.p3.1.m1.1.1.1" xref="S2.p3.1.m1.1.1.1.cmml">∈</mo><msub id="S2.p3.1.m1.1.1.3" xref="S2.p3.1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p3.1.m1.1.1.3.2" xref="S2.p3.1.m1.1.1.3.2.cmml">ℒ</mi><mi id="S2.p3.1.m1.1.1.3.3" xref="S2.p3.1.m1.1.1.3.3.cmml">c</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.p3.1.m1.1b"><apply id="S2.p3.1.m1.1.1.cmml" xref="S2.p3.1.m1.1.1"><in id="S2.p3.1.m1.1.1.1.cmml" xref="S2.p3.1.m1.1.1.1"></in><ci id="S2.p3.1.m1.1.1.2.cmml" xref="S2.p3.1.m1.1.1.2">𝐶</ci><apply id="S2.p3.1.m1.1.1.3.cmml" xref="S2.p3.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.p3.1.m1.1.1.3.1.cmml" xref="S2.p3.1.m1.1.1.3">subscript</csymbol><ci id="S2.p3.1.m1.1.1.3.2.cmml" xref="S2.p3.1.m1.1.1.3.2">ℒ</ci><ci id="S2.p3.1.m1.1.1.3.3.cmml" xref="S2.p3.1.m1.1.1.3.3">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.1.m1.1c">C\in\mathcal{L}_{c}</annotation></semantics></math>, with <math id="S2.p3.2.m2.1" class="ltx_Math" alttext="\mathcal{L}_{c}" display="inline"><semantics id="S2.p3.2.m2.1a"><msub id="S2.p3.2.m2.1.1" xref="S2.p3.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p3.2.m2.1.1.2" xref="S2.p3.2.m2.1.1.2.cmml">ℒ</mi><mi id="S2.p3.2.m2.1.1.3" xref="S2.p3.2.m2.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p3.2.m2.1b"><apply id="S2.p3.2.m2.1.1.cmml" xref="S2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S2.p3.2.m2.1.1.1.cmml" xref="S2.p3.2.m2.1.1">subscript</csymbol><ci id="S2.p3.2.m2.1.1.2.cmml" xref="S2.p3.2.m2.1.1.2">ℒ</ci><ci id="S2.p3.2.m2.1.1.3.cmml" xref="S2.p3.2.m2.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.2.m2.1c">\mathcal{L}_{c}</annotation></semantics></math> being the set of convolution layers, is a single quasi-local unitary. This could represent any quantum gate, since unitarity is the main constraint that must be imposed on any matrix that is used to represent a quantum gate <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. In this regard, a given matrix <math id="S2.p3.3.m3.1" class="ltx_Math" alttext="\boldsymbol{U}" display="inline"><semantics id="S2.p3.3.m3.1a"><mi id="S2.p3.3.m3.1.1" xref="S2.p3.3.m3.1.1.cmml">𝑼</mi><annotation-xml encoding="MathML-Content" id="S2.p3.3.m3.1b"><ci id="S2.p3.3.m3.1.1.cmml" xref="S2.p3.3.m3.1.1">𝑼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.3.m3.1c">\boldsymbol{U}</annotation></semantics></math> corresponding to a single qubit gate is said to be <em id="S2.p3.7.1" class="ltx_emph ltx_font_italic">unitary</em> if <math id="S2.p3.4.m4.1" class="ltx_Math" alttext="\boldsymbol{U}^{\dagger}\boldsymbol{U}=\boldsymbol{I}" display="inline"><semantics id="S2.p3.4.m4.1a"><mrow id="S2.p3.4.m4.1.1" xref="S2.p3.4.m4.1.1.cmml"><mrow id="S2.p3.4.m4.1.1.2" xref="S2.p3.4.m4.1.1.2.cmml"><msup id="S2.p3.4.m4.1.1.2.2" xref="S2.p3.4.m4.1.1.2.2.cmml"><mi id="S2.p3.4.m4.1.1.2.2.2" xref="S2.p3.4.m4.1.1.2.2.2.cmml">𝑼</mi><mo id="S2.p3.4.m4.1.1.2.2.3" xref="S2.p3.4.m4.1.1.2.2.3.cmml">†</mo></msup><mo lspace="0em" rspace="0em" id="S2.p3.4.m4.1.1.2.1" xref="S2.p3.4.m4.1.1.2.1.cmml">​</mo><mi id="S2.p3.4.m4.1.1.2.3" xref="S2.p3.4.m4.1.1.2.3.cmml">𝑼</mi></mrow><mo id="S2.p3.4.m4.1.1.1" xref="S2.p3.4.m4.1.1.1.cmml">=</mo><mi id="S2.p3.4.m4.1.1.3" xref="S2.p3.4.m4.1.1.3.cmml">𝑰</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p3.4.m4.1b"><apply id="S2.p3.4.m4.1.1.cmml" xref="S2.p3.4.m4.1.1"><eq id="S2.p3.4.m4.1.1.1.cmml" xref="S2.p3.4.m4.1.1.1"></eq><apply id="S2.p3.4.m4.1.1.2.cmml" xref="S2.p3.4.m4.1.1.2"><times id="S2.p3.4.m4.1.1.2.1.cmml" xref="S2.p3.4.m4.1.1.2.1"></times><apply id="S2.p3.4.m4.1.1.2.2.cmml" xref="S2.p3.4.m4.1.1.2.2"><csymbol cd="ambiguous" id="S2.p3.4.m4.1.1.2.2.1.cmml" xref="S2.p3.4.m4.1.1.2.2">superscript</csymbol><ci id="S2.p3.4.m4.1.1.2.2.2.cmml" xref="S2.p3.4.m4.1.1.2.2.2">𝑼</ci><ci id="S2.p3.4.m4.1.1.2.2.3.cmml" xref="S2.p3.4.m4.1.1.2.2.3">†</ci></apply><ci id="S2.p3.4.m4.1.1.2.3.cmml" xref="S2.p3.4.m4.1.1.2.3">𝑼</ci></apply><ci id="S2.p3.4.m4.1.1.3.cmml" xref="S2.p3.4.m4.1.1.3">𝑰</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.4.m4.1c">\boldsymbol{U}^{\dagger}\boldsymbol{U}=\boldsymbol{I}</annotation></semantics></math>, where <math id="S2.p3.5.m5.1" class="ltx_Math" alttext="\boldsymbol{U}^{\dagger}" display="inline"><semantics id="S2.p3.5.m5.1a"><msup id="S2.p3.5.m5.1.1" xref="S2.p3.5.m5.1.1.cmml"><mi id="S2.p3.5.m5.1.1.2" xref="S2.p3.5.m5.1.1.2.cmml">𝑼</mi><mo id="S2.p3.5.m5.1.1.3" xref="S2.p3.5.m5.1.1.3.cmml">†</mo></msup><annotation-xml encoding="MathML-Content" id="S2.p3.5.m5.1b"><apply id="S2.p3.5.m5.1.1.cmml" xref="S2.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S2.p3.5.m5.1.1.1.cmml" xref="S2.p3.5.m5.1.1">superscript</csymbol><ci id="S2.p3.5.m5.1.1.2.cmml" xref="S2.p3.5.m5.1.1.2">𝑼</ci><ci id="S2.p3.5.m5.1.1.3.cmml" xref="S2.p3.5.m5.1.1.3">†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.5.m5.1c">\boldsymbol{U}^{\dagger}</annotation></semantics></math> is the adjoint of <math id="S2.p3.6.m6.1" class="ltx_Math" alttext="\boldsymbol{U}" display="inline"><semantics id="S2.p3.6.m6.1a"><mi id="S2.p3.6.m6.1.1" xref="S2.p3.6.m6.1.1.cmml">𝑼</mi><annotation-xml encoding="MathML-Content" id="S2.p3.6.m6.1b"><ci id="S2.p3.6.m6.1.1.cmml" xref="S2.p3.6.m6.1.1">𝑼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.6.m6.1c">\boldsymbol{U}</annotation></semantics></math>, and <math id="S2.p3.7.m7.1" class="ltx_Math" alttext="\boldsymbol{I}" display="inline"><semantics id="S2.p3.7.m7.1a"><mi id="S2.p3.7.m7.1.1" xref="S2.p3.7.m7.1.1.cmml">𝑰</mi><annotation-xml encoding="MathML-Content" id="S2.p3.7.m7.1b"><ci id="S2.p3.7.m7.1.1.cmml" xref="S2.p3.7.m7.1.1">𝑰</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.7.m7.1c">\boldsymbol{I}</annotation></semantics></math> is the identity matrix. A unitary is called quasi-local if a quasi-local Hamiltonian generated that unitary as explained in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.3" class="ltx_p">In a quantum pooling layer <math id="S2.p4.1.m1.1" class="ltx_Math" alttext="P\in\mathcal{L}_{p}" display="inline"><semantics id="S2.p4.1.m1.1a"><mrow id="S2.p4.1.m1.1.1" xref="S2.p4.1.m1.1.1.cmml"><mi id="S2.p4.1.m1.1.1.2" xref="S2.p4.1.m1.1.1.2.cmml">P</mi><mo id="S2.p4.1.m1.1.1.1" xref="S2.p4.1.m1.1.1.1.cmml">∈</mo><msub id="S2.p4.1.m1.1.1.3" xref="S2.p4.1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p4.1.m1.1.1.3.2" xref="S2.p4.1.m1.1.1.3.2.cmml">ℒ</mi><mi id="S2.p4.1.m1.1.1.3.3" xref="S2.p4.1.m1.1.1.3.3.cmml">p</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.p4.1.m1.1b"><apply id="S2.p4.1.m1.1.1.cmml" xref="S2.p4.1.m1.1.1"><in id="S2.p4.1.m1.1.1.1.cmml" xref="S2.p4.1.m1.1.1.1"></in><ci id="S2.p4.1.m1.1.1.2.cmml" xref="S2.p4.1.m1.1.1.2">𝑃</ci><apply id="S2.p4.1.m1.1.1.3.cmml" xref="S2.p4.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.p4.1.m1.1.1.3.1.cmml" xref="S2.p4.1.m1.1.1.3">subscript</csymbol><ci id="S2.p4.1.m1.1.1.3.2.cmml" xref="S2.p4.1.m1.1.1.3.2">ℒ</ci><ci id="S2.p4.1.m1.1.1.3.3.cmml" xref="S2.p4.1.m1.1.1.3.3">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.1.m1.1c">P\in\mathcal{L}_{p}</annotation></semantics></math>, with <math id="S2.p4.2.m2.1" class="ltx_Math" alttext="\mathcal{L}_{p}" display="inline"><semantics id="S2.p4.2.m2.1a"><msub id="S2.p4.2.m2.1.1" xref="S2.p4.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p4.2.m2.1.1.2" xref="S2.p4.2.m2.1.1.2.cmml">ℒ</mi><mi id="S2.p4.2.m2.1.1.3" xref="S2.p4.2.m2.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p4.2.m2.1b"><apply id="S2.p4.2.m2.1.1.cmml" xref="S2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S2.p4.2.m2.1.1.1.cmml" xref="S2.p4.2.m2.1.1">subscript</csymbol><ci id="S2.p4.2.m2.1.1.2.cmml" xref="S2.p4.2.m2.1.1.2">ℒ</ci><ci id="S2.p4.2.m2.1.1.3.cmml" xref="S2.p4.2.m2.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.2.m2.1c">\mathcal{L}_{p}</annotation></semantics></math> being the set of pooling layers, the system size (and the degrees of freedom) are reduced, resulting in non-linearities. This is done by measuring some qubits and using the measurements to determine unitary rotations and apply them to other close qubits. After obtaining a system size that is sufficiently small, a quantum fully connected layer <math id="S2.p4.3.m3.1" class="ltx_Math" alttext="F" display="inline"><semantics id="S2.p4.3.m3.1a"><mi id="S2.p4.3.m3.1.1" xref="S2.p4.3.m3.1.1.cmml">F</mi><annotation-xml encoding="MathML-Content" id="S2.p4.3.m3.1b"><ci id="S2.p4.3.m3.1.1.cmml" xref="S2.p4.3.m3.1.1">𝐹</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.3.m3.1c">F</annotation></semantics></math> is applied on the remaining qubits and is represented by a unitary. Finally, measurement is performed on a specific number of qubits at the output to produce the QCNN’s prediction.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.7" class="ltx_p">At each client, the learnable parameters are the entries of all unitaries ,i.e., the quantum circuit parameters which are classical values. Let <math id="S2.p5.1.m1.4" class="ltx_Math" alttext="\text{\boldmath$\theta$}^{k}=(C,P,F)" display="inline"><semantics id="S2.p5.1.m1.4a"><mrow id="S2.p5.1.m1.4.5" xref="S2.p5.1.m1.4.5.cmml"><msup id="S2.p5.1.m1.4.5.2" xref="S2.p5.1.m1.4.5.2.cmml"><mi id="S2.p5.1.m1.4.5.2.2" xref="S2.p5.1.m1.4.5.2.2.cmml">𝜽</mi><mi id="S2.p5.1.m1.4.5.2.3" xref="S2.p5.1.m1.4.5.2.3.cmml">k</mi></msup><mo id="S2.p5.1.m1.4.5.1" xref="S2.p5.1.m1.4.5.1.cmml">=</mo><mrow id="S2.p5.1.m1.4.5.3.2" xref="S2.p5.1.m1.4.5.3.1.cmml"><mo stretchy="false" id="S2.p5.1.m1.4.5.3.2.1" xref="S2.p5.1.m1.4.5.3.1.cmml">(</mo><mi id="S2.p5.1.m1.2.2" xref="S2.p5.1.m1.2.2.cmml">C</mi><mo id="S2.p5.1.m1.4.5.3.2.2" xref="S2.p5.1.m1.4.5.3.1.cmml">,</mo><mi id="S2.p5.1.m1.3.3" xref="S2.p5.1.m1.3.3.cmml">P</mi><mo id="S2.p5.1.m1.4.5.3.2.3" xref="S2.p5.1.m1.4.5.3.1.cmml">,</mo><mi id="S2.p5.1.m1.4.4" xref="S2.p5.1.m1.4.4.cmml">F</mi><mo stretchy="false" id="S2.p5.1.m1.4.5.3.2.4" xref="S2.p5.1.m1.4.5.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.1.m1.4b"><apply id="S2.p5.1.m1.4.5.cmml" xref="S2.p5.1.m1.4.5"><eq id="S2.p5.1.m1.4.5.1.cmml" xref="S2.p5.1.m1.4.5.1"></eq><apply id="S2.p5.1.m1.4.5.2.cmml" xref="S2.p5.1.m1.4.5.2"><csymbol cd="ambiguous" id="S2.p5.1.m1.4.5.2.1.cmml" xref="S2.p5.1.m1.4.5.2">superscript</csymbol><ci id="S2.p5.1.m1.4.5.2.2.cmml" xref="S2.p5.1.m1.4.5.2.2">𝜽</ci><ci id="S2.p5.1.m1.4.5.2.3.cmml" xref="S2.p5.1.m1.4.5.2.3">𝑘</ci></apply><vector id="S2.p5.1.m1.4.5.3.1.cmml" xref="S2.p5.1.m1.4.5.3.2"><ci id="S2.p5.1.m1.2.2.cmml" xref="S2.p5.1.m1.2.2">𝐶</ci><ci id="S2.p5.1.m1.3.3.cmml" xref="S2.p5.1.m1.3.3">𝑃</ci><ci id="S2.p5.1.m1.4.4.cmml" xref="S2.p5.1.m1.4.4">𝐹</ci></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.1.m1.4c">\text{\boldmath$\theta$}^{k}=(C,P,F)</annotation></semantics></math> where <math id="S2.p5.2.m2.1" class="ltx_Math" alttext="k\in\mathcal{K}" display="inline"><semantics id="S2.p5.2.m2.1a"><mrow id="S2.p5.2.m2.1.1" xref="S2.p5.2.m2.1.1.cmml"><mi id="S2.p5.2.m2.1.1.2" xref="S2.p5.2.m2.1.1.2.cmml">k</mi><mo id="S2.p5.2.m2.1.1.1" xref="S2.p5.2.m2.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.p5.2.m2.1.1.3" xref="S2.p5.2.m2.1.1.3.cmml">𝒦</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.2.m2.1b"><apply id="S2.p5.2.m2.1.1.cmml" xref="S2.p5.2.m2.1.1"><in id="S2.p5.2.m2.1.1.1.cmml" xref="S2.p5.2.m2.1.1.1"></in><ci id="S2.p5.2.m2.1.1.2.cmml" xref="S2.p5.2.m2.1.1.2">𝑘</ci><ci id="S2.p5.2.m2.1.1.3.cmml" xref="S2.p5.2.m2.1.1.3">𝒦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.2.m2.1c">k\in\mathcal{K}</annotation></semantics></math> be the vector of all QCNN’s model parameters for client <math id="S2.p5.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.p5.3.m3.1a"><mi id="S2.p5.3.m3.1.1" xref="S2.p5.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.p5.3.m3.1b"><ci id="S2.p5.3.m3.1.1.cmml" xref="S2.p5.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.3.m3.1c">k</annotation></semantics></math>, then the predicted output value by the QCNN model <math id="S2.p5.4.m4.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S2.p5.4.m4.1a"><mi id="S2.p5.4.m4.1.1" xref="S2.p5.4.m4.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S2.p5.4.m4.1b"><ci id="S2.p5.4.m4.1.1.cmml" xref="S2.p5.4.m4.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.4.m4.1c">f</annotation></semantics></math> to input quantum state <math id="S2.p5.5.m5.1" class="ltx_Math" alttext="\ket{\psi_{m}}" display="inline"><semantics id="S2.p5.5.m5.1a"><mrow id="S2.p5.5.m5.1.1.3" xref="S2.p5.5.m5.1.1.2.cmml"><mo stretchy="false" id="S2.p5.5.m5.1.1.3.1" xref="S2.p5.5.m5.1.1.2.1.cmml">|</mo><msub id="S2.p5.5.m5.1.1.1.1" xref="S2.p5.5.m5.1.1.1.1.cmml"><mi id="S2.p5.5.m5.1.1.1.1.2" xref="S2.p5.5.m5.1.1.1.1.2.cmml">ψ</mi><mi id="S2.p5.5.m5.1.1.1.1.3" xref="S2.p5.5.m5.1.1.1.1.3.cmml">m</mi></msub><mo stretchy="false" id="S2.p5.5.m5.1.1.3.2" xref="S2.p5.5.m5.1.1.2.1.cmml">⟩</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.5.m5.1b"><apply id="S2.p5.5.m5.1.1.2.cmml" xref="S2.p5.5.m5.1.1.3"><csymbol cd="latexml" id="S2.p5.5.m5.1.1.2.1.cmml" xref="S2.p5.5.m5.1.1.3.1">ket</csymbol><apply id="S2.p5.5.m5.1.1.1.1.cmml" xref="S2.p5.5.m5.1.1.1.1"><csymbol cd="ambiguous" id="S2.p5.5.m5.1.1.1.1.1.cmml" xref="S2.p5.5.m5.1.1.1.1">subscript</csymbol><ci id="S2.p5.5.m5.1.1.1.1.2.cmml" xref="S2.p5.5.m5.1.1.1.1.2">𝜓</ci><ci id="S2.p5.5.m5.1.1.1.1.3.cmml" xref="S2.p5.5.m5.1.1.1.1.3">𝑚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.5.m5.1c">\ket{\psi_{m}}</annotation></semantics></math> for client <math id="S2.p5.6.m6.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.p5.6.m6.1a"><mi id="S2.p5.6.m6.1.1" xref="S2.p5.6.m6.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.p5.6.m6.1b"><ci id="S2.p5.6.m6.1.1.cmml" xref="S2.p5.6.m6.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.6.m6.1c">k</annotation></semantics></math> is denoted by <math id="S2.p5.7.m7.2" class="ltx_Math" alttext="f_{\text{\boldmath$\theta$}^{k}}(\ket{\psi_{m}})" display="inline"><semantics id="S2.p5.7.m7.2a"><mrow id="S2.p5.7.m7.2.3" xref="S2.p5.7.m7.2.3.cmml"><msub id="S2.p5.7.m7.2.3.2" xref="S2.p5.7.m7.2.3.2.cmml"><mi id="S2.p5.7.m7.2.3.2.2" xref="S2.p5.7.m7.2.3.2.2.cmml">f</mi><msup id="S2.p5.7.m7.1.1.1" xref="S2.p5.7.m7.1.1.1.cmml"><mi id="S2.p5.7.m7.1.1.1.3" xref="S2.p5.7.m7.1.1.1.3.cmml">𝜽</mi><mi id="S2.p5.7.m7.1.1.1.4" xref="S2.p5.7.m7.1.1.1.4.cmml">k</mi></msup></msub><mo lspace="0em" rspace="0em" id="S2.p5.7.m7.2.3.1" xref="S2.p5.7.m7.2.3.1.cmml">​</mo><mrow id="S2.p5.7.m7.2.3.3.2" xref="S2.p5.7.m7.2.3.cmml"><mo stretchy="false" id="S2.p5.7.m7.2.3.3.2.1" xref="S2.p5.7.m7.2.3.cmml">(</mo><mrow id="S2.p5.7.m7.2.2.3" xref="S2.p5.7.m7.2.2.2.cmml"><mo stretchy="false" id="S2.p5.7.m7.2.2.3.1" xref="S2.p5.7.m7.2.2.2.1.cmml">|</mo><msub id="S2.p5.7.m7.2.2.1.1" xref="S2.p5.7.m7.2.2.1.1.cmml"><mi id="S2.p5.7.m7.2.2.1.1.2" xref="S2.p5.7.m7.2.2.1.1.2.cmml">ψ</mi><mi id="S2.p5.7.m7.2.2.1.1.3" xref="S2.p5.7.m7.2.2.1.1.3.cmml">m</mi></msub><mo stretchy="false" id="S2.p5.7.m7.2.2.3.2" xref="S2.p5.7.m7.2.2.2.1.cmml">⟩</mo></mrow><mo stretchy="false" id="S2.p5.7.m7.2.3.3.2.2" xref="S2.p5.7.m7.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.7.m7.2b"><apply id="S2.p5.7.m7.2.3.cmml" xref="S2.p5.7.m7.2.3"><times id="S2.p5.7.m7.2.3.1.cmml" xref="S2.p5.7.m7.2.3.1"></times><apply id="S2.p5.7.m7.2.3.2.cmml" xref="S2.p5.7.m7.2.3.2"><csymbol cd="ambiguous" id="S2.p5.7.m7.2.3.2.1.cmml" xref="S2.p5.7.m7.2.3.2">subscript</csymbol><ci id="S2.p5.7.m7.2.3.2.2.cmml" xref="S2.p5.7.m7.2.3.2.2">𝑓</ci><apply id="S2.p5.7.m7.1.1.1.cmml" xref="S2.p5.7.m7.1.1.1"><csymbol cd="ambiguous" id="S2.p5.7.m7.1.1.1.2.cmml" xref="S2.p5.7.m7.1.1.1">superscript</csymbol><ci id="S2.p5.7.m7.1.1.1.3.cmml" xref="S2.p5.7.m7.1.1.1.3">𝜽</ci><ci id="S2.p5.7.m7.1.1.1.4.cmml" xref="S2.p5.7.m7.1.1.1.4">𝑘</ci></apply></apply><apply id="S2.p5.7.m7.2.2.2.cmml" xref="S2.p5.7.m7.2.2.3"><csymbol cd="latexml" id="S2.p5.7.m7.2.2.2.1.cmml" xref="S2.p5.7.m7.2.2.3.1">ket</csymbol><apply id="S2.p5.7.m7.2.2.1.1.cmml" xref="S2.p5.7.m7.2.2.1.1"><csymbol cd="ambiguous" id="S2.p5.7.m7.2.2.1.1.1.cmml" xref="S2.p5.7.m7.2.2.1.1">subscript</csymbol><ci id="S2.p5.7.m7.2.2.1.1.2.cmml" xref="S2.p5.7.m7.2.2.1.1.2">𝜓</ci><ci id="S2.p5.7.m7.2.2.1.1.3.cmml" xref="S2.p5.7.m7.2.2.1.1.3">𝑚</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.7.m7.2c">f_{\text{\boldmath$\theta$}^{k}}(\ket{\psi_{m}})</annotation></semantics></math>. Initially, the model parameters are initialized, and, then, they are updated in order to minimize the following mean squared error (MSE) loss function:</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.2" class="ltx_Math" alttext="\operatorname*{arg\,min}_{\boldsymbol{\theta}^{k}}\mathcal{J}(\boldsymbol{\theta}^{k}):=\frac{1}{2M}\sum_{m=1}^{M}{(y_{m}-f_{\boldsymbol{\theta}^{k}}(\ket{\psi_{m}}))^{2}}." display="block"><semantics id="S2.E1.m1.2a"><mrow id="S2.E1.m1.2.2.1" xref="S2.E1.m1.2.2.1.1.cmml"><mrow id="S2.E1.m1.2.2.1.1" xref="S2.E1.m1.2.2.1.1.cmml"><mrow id="S2.E1.m1.2.2.1.1.1" xref="S2.E1.m1.2.2.1.1.1.cmml"><mrow id="S2.E1.m1.2.2.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.3.cmml"><munder id="S2.E1.m1.2.2.1.1.1.3.1" xref="S2.E1.m1.2.2.1.1.1.3.1.cmml"><mrow id="S2.E1.m1.2.2.1.1.1.3.1.2" xref="S2.E1.m1.2.2.1.1.1.3.1.2.cmml"><mi id="S2.E1.m1.2.2.1.1.1.3.1.2.2" xref="S2.E1.m1.2.2.1.1.1.3.1.2.2.cmml">arg</mi><mo lspace="0.170em" rspace="0em" id="S2.E1.m1.2.2.1.1.1.3.1.2.1" xref="S2.E1.m1.2.2.1.1.1.3.1.2.1.cmml">​</mo><mi id="S2.E1.m1.2.2.1.1.1.3.1.2.3" xref="S2.E1.m1.2.2.1.1.1.3.1.2.3.cmml">min</mi></mrow><msup id="S2.E1.m1.2.2.1.1.1.3.1.3" xref="S2.E1.m1.2.2.1.1.1.3.1.3.cmml"><mi id="S2.E1.m1.2.2.1.1.1.3.1.3.2" xref="S2.E1.m1.2.2.1.1.1.3.1.3.2.cmml">𝜽</mi><mi id="S2.E1.m1.2.2.1.1.1.3.1.3.3" xref="S2.E1.m1.2.2.1.1.1.3.1.3.3.cmml">k</mi></msup></munder><mo lspace="0.167em" id="S2.E1.m1.2.2.1.1.1.3a" xref="S2.E1.m1.2.2.1.1.1.3.cmml">⁡</mo><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.2.2.1.1.1.3.2" xref="S2.E1.m1.2.2.1.1.1.3.2.cmml">𝒥</mi></mrow><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.2.cmml">​</mo><mrow id="S2.E1.m1.2.2.1.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.2.2.1.1.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.1.1.1.cmml">(</mo><msup id="S2.E1.m1.2.2.1.1.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.2.2.1.1.1.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.1.1.1.2.cmml">𝜽</mi><mi id="S2.E1.m1.2.2.1.1.1.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.1.1.1.3.cmml">k</mi></msup><mo rspace="0.278em" stretchy="false" id="S2.E1.m1.2.2.1.1.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo rspace="0.278em" id="S2.E1.m1.2.2.1.1.3" xref="S2.E1.m1.2.2.1.1.3.cmml">:=</mo><mrow id="S2.E1.m1.2.2.1.1.2" xref="S2.E1.m1.2.2.1.1.2.cmml"><mfrac id="S2.E1.m1.2.2.1.1.2.3" xref="S2.E1.m1.2.2.1.1.2.3.cmml"><mn id="S2.E1.m1.2.2.1.1.2.3.2" xref="S2.E1.m1.2.2.1.1.2.3.2.cmml">1</mn><mrow id="S2.E1.m1.2.2.1.1.2.3.3" xref="S2.E1.m1.2.2.1.1.2.3.3.cmml"><mn id="S2.E1.m1.2.2.1.1.2.3.3.2" xref="S2.E1.m1.2.2.1.1.2.3.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.1.1.2.3.3.1" xref="S2.E1.m1.2.2.1.1.2.3.3.1.cmml">​</mo><mi id="S2.E1.m1.2.2.1.1.2.3.3.3" xref="S2.E1.m1.2.2.1.1.2.3.3.3.cmml">M</mi></mrow></mfrac><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.1.1.2.2" xref="S2.E1.m1.2.2.1.1.2.2.cmml">​</mo><mrow id="S2.E1.m1.2.2.1.1.2.1" xref="S2.E1.m1.2.2.1.1.2.1.cmml"><munderover id="S2.E1.m1.2.2.1.1.2.1.2" xref="S2.E1.m1.2.2.1.1.2.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S2.E1.m1.2.2.1.1.2.1.2.2.2" xref="S2.E1.m1.2.2.1.1.2.1.2.2.2.cmml">∑</mo><mrow id="S2.E1.m1.2.2.1.1.2.1.2.2.3" xref="S2.E1.m1.2.2.1.1.2.1.2.2.3.cmml"><mi id="S2.E1.m1.2.2.1.1.2.1.2.2.3.2" xref="S2.E1.m1.2.2.1.1.2.1.2.2.3.2.cmml">m</mi><mo id="S2.E1.m1.2.2.1.1.2.1.2.2.3.1" xref="S2.E1.m1.2.2.1.1.2.1.2.2.3.1.cmml">=</mo><mn id="S2.E1.m1.2.2.1.1.2.1.2.2.3.3" xref="S2.E1.m1.2.2.1.1.2.1.2.2.3.3.cmml">1</mn></mrow><mi id="S2.E1.m1.2.2.1.1.2.1.2.3" xref="S2.E1.m1.2.2.1.1.2.1.2.3.cmml">M</mi></munderover><msup id="S2.E1.m1.2.2.1.1.2.1.1" xref="S2.E1.m1.2.2.1.1.2.1.1.cmml"><mrow id="S2.E1.m1.2.2.1.1.2.1.1.1.1" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.2.2.1.1.2.1.1.1.1.2" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.cmml"><msub id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.2" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.2.cmml"><mi id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.2.2" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.2.2.cmml">y</mi><mi id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.2.3" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.2.3.cmml">m</mi></msub><mo id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.1" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.1.cmml">−</mo><mrow id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.cmml"><msub id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.2" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.2.cmml"><mi id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.2.2" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.2.2.cmml">f</mi><msup id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.2.3" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.2.3.cmml"><mi id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.2.3.2" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.2.3.2.cmml">𝜽</mi><mi id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.2.3.3" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.2.3.3.cmml">k</mi></msup></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.1" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.1.cmml">​</mo><mrow id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.3.2" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.cmml"><mo stretchy="false" id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.3.2.1" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.cmml">(</mo><mrow id="S2.E1.m1.1.1.3" xref="S2.E1.m1.1.1.2.cmml"><mo stretchy="false" id="S2.E1.m1.1.1.3.1" xref="S2.E1.m1.1.1.2.1.cmml">|</mo><msub id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.2.cmml">ψ</mi><mi id="S2.E1.m1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.3.cmml">m</mi></msub><mo stretchy="false" id="S2.E1.m1.1.1.3.2" xref="S2.E1.m1.1.1.2.1.cmml">⟩</mo></mrow><mo stretchy="false" id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.3.2.2" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S2.E1.m1.2.2.1.1.2.1.1.1.1.3" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.cmml">)</mo></mrow><mn id="S2.E1.m1.2.2.1.1.2.1.1.3" xref="S2.E1.m1.2.2.1.1.2.1.1.3.cmml">2</mn></msup></mrow></mrow></mrow><mo lspace="0em" id="S2.E1.m1.2.2.1.2" xref="S2.E1.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.2b"><apply id="S2.E1.m1.2.2.1.1.cmml" xref="S2.E1.m1.2.2.1"><csymbol cd="latexml" id="S2.E1.m1.2.2.1.1.3.cmml" xref="S2.E1.m1.2.2.1.1.3">assign</csymbol><apply id="S2.E1.m1.2.2.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1"><times id="S2.E1.m1.2.2.1.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.1.2"></times><apply id="S2.E1.m1.2.2.1.1.1.3.cmml" xref="S2.E1.m1.2.2.1.1.1.3"><apply id="S2.E1.m1.2.2.1.1.1.3.1.cmml" xref="S2.E1.m1.2.2.1.1.1.3.1"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.1.3.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1.3.1">subscript</csymbol><apply id="S2.E1.m1.2.2.1.1.1.3.1.2.cmml" xref="S2.E1.m1.2.2.1.1.1.3.1.2"><times id="S2.E1.m1.2.2.1.1.1.3.1.2.1.cmml" xref="S2.E1.m1.2.2.1.1.1.3.1.2.1"></times><ci id="S2.E1.m1.2.2.1.1.1.3.1.2.2.cmml" xref="S2.E1.m1.2.2.1.1.1.3.1.2.2">arg</ci><ci id="S2.E1.m1.2.2.1.1.1.3.1.2.3.cmml" xref="S2.E1.m1.2.2.1.1.1.3.1.2.3">min</ci></apply><apply id="S2.E1.m1.2.2.1.1.1.3.1.3.cmml" xref="S2.E1.m1.2.2.1.1.1.3.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.1.3.1.3.1.cmml" xref="S2.E1.m1.2.2.1.1.1.3.1.3">superscript</csymbol><ci id="S2.E1.m1.2.2.1.1.1.3.1.3.2.cmml" xref="S2.E1.m1.2.2.1.1.1.3.1.3.2">𝜽</ci><ci id="S2.E1.m1.2.2.1.1.1.3.1.3.3.cmml" xref="S2.E1.m1.2.2.1.1.1.3.1.3.3">𝑘</ci></apply></apply><ci id="S2.E1.m1.2.2.1.1.1.3.2.cmml" xref="S2.E1.m1.2.2.1.1.1.3.2">𝒥</ci></apply><apply id="S2.E1.m1.2.2.1.1.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1">superscript</csymbol><ci id="S2.E1.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.2">𝜽</ci><ci id="S2.E1.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.3">𝑘</ci></apply></apply><apply id="S2.E1.m1.2.2.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.2"><times id="S2.E1.m1.2.2.1.1.2.2.cmml" xref="S2.E1.m1.2.2.1.1.2.2"></times><apply id="S2.E1.m1.2.2.1.1.2.3.cmml" xref="S2.E1.m1.2.2.1.1.2.3"><divide id="S2.E1.m1.2.2.1.1.2.3.1.cmml" xref="S2.E1.m1.2.2.1.1.2.3"></divide><cn type="integer" id="S2.E1.m1.2.2.1.1.2.3.2.cmml" xref="S2.E1.m1.2.2.1.1.2.3.2">1</cn><apply id="S2.E1.m1.2.2.1.1.2.3.3.cmml" xref="S2.E1.m1.2.2.1.1.2.3.3"><times id="S2.E1.m1.2.2.1.1.2.3.3.1.cmml" xref="S2.E1.m1.2.2.1.1.2.3.3.1"></times><cn type="integer" id="S2.E1.m1.2.2.1.1.2.3.3.2.cmml" xref="S2.E1.m1.2.2.1.1.2.3.3.2">2</cn><ci id="S2.E1.m1.2.2.1.1.2.3.3.3.cmml" xref="S2.E1.m1.2.2.1.1.2.3.3.3">𝑀</ci></apply></apply><apply id="S2.E1.m1.2.2.1.1.2.1.cmml" xref="S2.E1.m1.2.2.1.1.2.1"><apply id="S2.E1.m1.2.2.1.1.2.1.2.cmml" xref="S2.E1.m1.2.2.1.1.2.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.2.1.2.1.cmml" xref="S2.E1.m1.2.2.1.1.2.1.2">superscript</csymbol><apply id="S2.E1.m1.2.2.1.1.2.1.2.2.cmml" xref="S2.E1.m1.2.2.1.1.2.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.2.1.2.2.1.cmml" xref="S2.E1.m1.2.2.1.1.2.1.2">subscript</csymbol><sum id="S2.E1.m1.2.2.1.1.2.1.2.2.2.cmml" xref="S2.E1.m1.2.2.1.1.2.1.2.2.2"></sum><apply id="S2.E1.m1.2.2.1.1.2.1.2.2.3.cmml" xref="S2.E1.m1.2.2.1.1.2.1.2.2.3"><eq id="S2.E1.m1.2.2.1.1.2.1.2.2.3.1.cmml" xref="S2.E1.m1.2.2.1.1.2.1.2.2.3.1"></eq><ci id="S2.E1.m1.2.2.1.1.2.1.2.2.3.2.cmml" xref="S2.E1.m1.2.2.1.1.2.1.2.2.3.2">𝑚</ci><cn type="integer" id="S2.E1.m1.2.2.1.1.2.1.2.2.3.3.cmml" xref="S2.E1.m1.2.2.1.1.2.1.2.2.3.3">1</cn></apply></apply><ci id="S2.E1.m1.2.2.1.1.2.1.2.3.cmml" xref="S2.E1.m1.2.2.1.1.2.1.2.3">𝑀</ci></apply><apply id="S2.E1.m1.2.2.1.1.2.1.1.cmml" xref="S2.E1.m1.2.2.1.1.2.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.2.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.2.1.1">superscript</csymbol><apply id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1"><minus id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.1"></minus><apply id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.2.1.cmml" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.2">subscript</csymbol><ci id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.2.2.cmml" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.2.2">𝑦</ci><ci id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.2.3.cmml" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.2.3">𝑚</ci></apply><apply id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.cmml" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3"><times id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.1"></times><apply id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.2.cmml" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.2.1.cmml" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.2">subscript</csymbol><ci id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.2.2.cmml" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.2.2">𝑓</ci><apply id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.2.3.cmml" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.2.3.1.cmml" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.2.3">superscript</csymbol><ci id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.2.3.2.cmml" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.2.3.2">𝜽</ci><ci id="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.2.3.3.cmml" xref="S2.E1.m1.2.2.1.1.2.1.1.1.1.1.3.2.3.3">𝑘</ci></apply></apply><apply id="S2.E1.m1.1.1.2.cmml" xref="S2.E1.m1.1.1.3"><csymbol cd="latexml" id="S2.E1.m1.1.1.2.1.cmml" xref="S2.E1.m1.1.1.3.1">ket</csymbol><apply id="S2.E1.m1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.2">𝜓</ci><ci id="S2.E1.m1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.3">𝑚</ci></apply></apply></apply></apply><cn type="integer" id="S2.E1.m1.2.2.1.1.2.1.1.3.cmml" xref="S2.E1.m1.2.2.1.1.2.1.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.2c">\operatorname*{arg\,min}_{\boldsymbol{\theta}^{k}}\mathcal{J}(\boldsymbol{\theta}^{k}):=\frac{1}{2M}\sum_{m=1}^{M}{(y_{m}-f_{\boldsymbol{\theta}^{k}}(\ket{\psi_{m}}))^{2}}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S2.p5.8" class="ltx_p">In order to benefit from each others experience and data, all <math id="S2.p5.8.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.p5.8.m1.1a"><mi id="S2.p5.8.m1.1.1" xref="S2.p5.8.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.p5.8.m1.1b"><ci id="S2.p5.8.m1.1.1.cmml" xref="S2.p5.8.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.8.m1.1c">K</annotation></semantics></math> clients will collaborate in training the same QCNN model. Such a collaboration can be beneficial for emerging applications such as large-scale quantum communication networks. To perform this collaboration, we use the proposed QFL framework. In this context, the general setup of QFL follows a similar structure to classical FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>. The collaborative learning is done by using existing wireless communication technologies such as the 5G cellular infrastructure to send the clients’ <span id="S2.p5.8.1" class="ltx_ERROR undefined">\say</span>classical model parameters to the server. This setup will, in turn, allow the system to perform decentralized quantum data learning while using existing classical wireless links, a task that is extremely difficult to achieve efficiently if the clients needed to send the quantum data itself to the server.</p>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.4" class="ltx_p">Each round <math id="S2.p6.1.m1.1" class="ltx_Math" alttext="h" display="inline"><semantics id="S2.p6.1.m1.1a"><mi id="S2.p6.1.m1.1.1" xref="S2.p6.1.m1.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="S2.p6.1.m1.1b"><ci id="S2.p6.1.m1.1.1.cmml" xref="S2.p6.1.m1.1.1">ℎ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p6.1.m1.1c">h</annotation></semantics></math> of the QFL training starts with the server sending its current version of the model parameters <math id="S2.p6.2.m2.1" class="ltx_Math" alttext="\text{\boldmath$\theta$}_{h}^{s}" display="inline"><semantics id="S2.p6.2.m2.1a"><msubsup id="S2.p6.2.m2.1.2" xref="S2.p6.2.m2.1.2.cmml"><mi id="S2.p6.2.m2.1.2.2.2" xref="S2.p6.2.m2.1.2.2.2.cmml">𝜽</mi><mi id="S2.p6.2.m2.1.2.2.3" xref="S2.p6.2.m2.1.2.2.3.cmml">h</mi><mi id="S2.p6.2.m2.1.2.3" xref="S2.p6.2.m2.1.2.3.cmml">s</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.p6.2.m2.1b"><apply id="S2.p6.2.m2.1.2.cmml" xref="S2.p6.2.m2.1.2"><csymbol cd="ambiguous" id="S2.p6.2.m2.1.2.1.cmml" xref="S2.p6.2.m2.1.2">superscript</csymbol><apply id="S2.p6.2.m2.1.2.2.cmml" xref="S2.p6.2.m2.1.2"><csymbol cd="ambiguous" id="S2.p6.2.m2.1.2.2.1.cmml" xref="S2.p6.2.m2.1.2">subscript</csymbol><ci id="S2.p6.2.m2.1.2.2.2.cmml" xref="S2.p6.2.m2.1.2.2.2">𝜽</ci><ci id="S2.p6.2.m2.1.2.2.3.cmml" xref="S2.p6.2.m2.1.2.2.3">ℎ</ci></apply><ci id="S2.p6.2.m2.1.2.3.cmml" xref="S2.p6.2.m2.1.2.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p6.2.m2.1c">\text{\boldmath$\theta$}_{h}^{s}</annotation></semantics></math> to all <math id="S2.p6.3.m3.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.p6.3.m3.1a"><mi id="S2.p6.3.m3.1.1" xref="S2.p6.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.p6.3.m3.1b"><ci id="S2.p6.3.m3.1.1.cmml" xref="S2.p6.3.m3.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p6.3.m3.1c">K</annotation></semantics></math> clients. Each client <math id="S2.p6.4.m4.1" class="ltx_Math" alttext="k\in\mathcal{K}" display="inline"><semantics id="S2.p6.4.m4.1a"><mrow id="S2.p6.4.m4.1.1" xref="S2.p6.4.m4.1.1.cmml"><mi id="S2.p6.4.m4.1.1.2" xref="S2.p6.4.m4.1.1.2.cmml">k</mi><mo id="S2.p6.4.m4.1.1.1" xref="S2.p6.4.m4.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.p6.4.m4.1.1.3" xref="S2.p6.4.m4.1.1.3.cmml">𝒦</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p6.4.m4.1b"><apply id="S2.p6.4.m4.1.1.cmml" xref="S2.p6.4.m4.1.1"><in id="S2.p6.4.m4.1.1.1.cmml" xref="S2.p6.4.m4.1.1.1"></in><ci id="S2.p6.4.m4.1.1.2.cmml" xref="S2.p6.4.m4.1.1.2">𝑘</ci><ci id="S2.p6.4.m4.1.1.3.cmml" xref="S2.p6.4.m4.1.1.3">𝒦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p6.4.m4.1c">k\in\mathcal{K}</annotation></semantics></math> uses its local quantum data to run an optimization algorithm such as stochastic gradient descent (SGD), in order to update its model parameters according to the following equation:</p>
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.1" class="ltx_Math" alttext="\boldsymbol{\theta}_{h}^{k}=\boldsymbol{\theta}_{h}^{s}-\eta\cdot\nabla_{\boldsymbol{\theta}_{h}^{k}}\mathcal{J}(\boldsymbol{\theta}_{h}^{k})," display="block"><semantics id="S2.E2.m1.1a"><mrow id="S2.E2.m1.1.1.1" xref="S2.E2.m1.1.1.1.1.cmml"><mrow id="S2.E2.m1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.cmml"><msubsup id="S2.E2.m1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.3.cmml"><mi id="S2.E2.m1.1.1.1.1.3.2.2" xref="S2.E2.m1.1.1.1.1.3.2.2.cmml">𝜽</mi><mi id="S2.E2.m1.1.1.1.1.3.2.3" xref="S2.E2.m1.1.1.1.1.3.2.3.cmml">h</mi><mi id="S2.E2.m1.1.1.1.1.3.3" xref="S2.E2.m1.1.1.1.1.3.3.cmml">k</mi></msubsup><mo id="S2.E2.m1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.2.cmml">=</mo><mrow id="S2.E2.m1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.cmml"><msubsup id="S2.E2.m1.1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.1.3.cmml"><mi id="S2.E2.m1.1.1.1.1.1.3.2.2" xref="S2.E2.m1.1.1.1.1.1.3.2.2.cmml">𝜽</mi><mi id="S2.E2.m1.1.1.1.1.1.3.2.3" xref="S2.E2.m1.1.1.1.1.1.3.2.3.cmml">h</mi><mi id="S2.E2.m1.1.1.1.1.1.3.3" xref="S2.E2.m1.1.1.1.1.1.3.3.cmml">s</mi></msubsup><mo id="S2.E2.m1.1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.1.2.cmml">−</mo><mrow id="S2.E2.m1.1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.cmml"><mrow id="S2.E2.m1.1.1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.1.1.3.cmml"><mi id="S2.E2.m1.1.1.1.1.1.1.3.2" xref="S2.E2.m1.1.1.1.1.1.1.3.2.cmml">η</mi><mo lspace="0.222em" rspace="0.222em" id="S2.E2.m1.1.1.1.1.1.1.3.1" xref="S2.E2.m1.1.1.1.1.1.1.3.1.cmml">⋅</mo><mrow id="S2.E2.m1.1.1.1.1.1.1.3.3" xref="S2.E2.m1.1.1.1.1.1.1.3.3.cmml"><msub id="S2.E2.m1.1.1.1.1.1.1.3.3.1" xref="S2.E2.m1.1.1.1.1.1.1.3.3.1.cmml"><mo rspace="0.167em" id="S2.E2.m1.1.1.1.1.1.1.3.3.1.2" xref="S2.E2.m1.1.1.1.1.1.1.3.3.1.2.cmml">∇</mo><msubsup id="S2.E2.m1.1.1.1.1.1.1.3.3.1.3" xref="S2.E2.m1.1.1.1.1.1.1.3.3.1.3.cmml"><mi id="S2.E2.m1.1.1.1.1.1.1.3.3.1.3.2.2" xref="S2.E2.m1.1.1.1.1.1.1.3.3.1.3.2.2.cmml">𝜽</mi><mi id="S2.E2.m1.1.1.1.1.1.1.3.3.1.3.2.3" xref="S2.E2.m1.1.1.1.1.1.1.3.3.1.3.2.3.cmml">h</mi><mi id="S2.E2.m1.1.1.1.1.1.1.3.3.1.3.3" xref="S2.E2.m1.1.1.1.1.1.1.3.3.1.3.3.cmml">k</mi></msubsup></msub><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.1.1.1.1.1.1.3.3.2" xref="S2.E2.m1.1.1.1.1.1.1.3.3.2.cmml">𝒥</mi></mrow></mrow><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S2.E2.m1.1.1.1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E2.m1.1.1.1.1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msubsup id="S2.E2.m1.1.1.1.1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E2.m1.1.1.1.1.1.1.1.1.1.2.2" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.2.2.cmml">𝜽</mi><mi id="S2.E2.m1.1.1.1.1.1.1.1.1.1.2.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.2.3.cmml">h</mi><mi id="S2.E2.m1.1.1.1.1.1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.3.cmml">k</mi></msubsup><mo stretchy="false" id="S2.E2.m1.1.1.1.1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S2.E2.m1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.1b"><apply id="S2.E2.m1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1"><eq id="S2.E2.m1.1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.2"></eq><apply id="S2.E2.m1.1.1.1.1.3.cmml" xref="S2.E2.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.3.1.cmml" xref="S2.E2.m1.1.1.1.1.3">superscript</csymbol><apply id="S2.E2.m1.1.1.1.1.3.2.cmml" xref="S2.E2.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.3.2.1.cmml" xref="S2.E2.m1.1.1.1.1.3">subscript</csymbol><ci id="S2.E2.m1.1.1.1.1.3.2.2.cmml" xref="S2.E2.m1.1.1.1.1.3.2.2">𝜽</ci><ci id="S2.E2.m1.1.1.1.1.3.2.3.cmml" xref="S2.E2.m1.1.1.1.1.3.2.3">ℎ</ci></apply><ci id="S2.E2.m1.1.1.1.1.3.3.cmml" xref="S2.E2.m1.1.1.1.1.3.3">𝑘</ci></apply><apply id="S2.E2.m1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1"><minus id="S2.E2.m1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.1.2"></minus><apply id="S2.E2.m1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.1.3.1.cmml" xref="S2.E2.m1.1.1.1.1.1.3">superscript</csymbol><apply id="S2.E2.m1.1.1.1.1.1.3.2.cmml" xref="S2.E2.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.1.3.2.1.cmml" xref="S2.E2.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E2.m1.1.1.1.1.1.3.2.2.cmml" xref="S2.E2.m1.1.1.1.1.1.3.2.2">𝜽</ci><ci id="S2.E2.m1.1.1.1.1.1.3.2.3.cmml" xref="S2.E2.m1.1.1.1.1.1.3.2.3">ℎ</ci></apply><ci id="S2.E2.m1.1.1.1.1.1.3.3.cmml" xref="S2.E2.m1.1.1.1.1.1.3.3">𝑠</ci></apply><apply id="S2.E2.m1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1"><times id="S2.E2.m1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.2"></times><apply id="S2.E2.m1.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.3"><ci id="S2.E2.m1.1.1.1.1.1.1.3.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.3.1">⋅</ci><ci id="S2.E2.m1.1.1.1.1.1.1.3.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.3.2">𝜂</ci><apply id="S2.E2.m1.1.1.1.1.1.1.3.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.3.3"><apply id="S2.E2.m1.1.1.1.1.1.1.3.3.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.3.3.1"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.1.1.3.3.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.3.3.1">subscript</csymbol><ci id="S2.E2.m1.1.1.1.1.1.1.3.3.1.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.3.3.1.2">∇</ci><apply id="S2.E2.m1.1.1.1.1.1.1.3.3.1.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.3.3.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.1.1.3.3.1.3.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.3.3.1.3">superscript</csymbol><apply id="S2.E2.m1.1.1.1.1.1.1.3.3.1.3.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.3.3.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.1.1.3.3.1.3.2.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.3.3.1.3">subscript</csymbol><ci id="S2.E2.m1.1.1.1.1.1.1.3.3.1.3.2.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.3.3.1.3.2.2">𝜽</ci><ci id="S2.E2.m1.1.1.1.1.1.1.3.3.1.3.2.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.3.3.1.3.2.3">ℎ</ci></apply><ci id="S2.E2.m1.1.1.1.1.1.1.3.3.1.3.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.3.3.1.3.3">𝑘</ci></apply></apply><ci id="S2.E2.m1.1.1.1.1.1.1.3.3.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.3.3.2">𝒥</ci></apply></apply><apply id="S2.E2.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S2.E2.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E2.m1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.2.2">𝜽</ci><ci id="S2.E2.m1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.2.3">ℎ</ci></apply><ci id="S2.E2.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.3">𝑘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.1c">\boldsymbol{\theta}_{h}^{k}=\boldsymbol{\theta}_{h}^{s}-\eta\cdot\nabla_{\boldsymbol{\theta}_{h}^{k}}\mathcal{J}(\boldsymbol{\theta}_{h}^{k}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S2.p6.7" class="ltx_p">for every <math id="S2.p6.5.m1.1" class="ltx_Math" alttext="k\in\mathcal{K}" display="inline"><semantics id="S2.p6.5.m1.1a"><mrow id="S2.p6.5.m1.1.1" xref="S2.p6.5.m1.1.1.cmml"><mi id="S2.p6.5.m1.1.1.2" xref="S2.p6.5.m1.1.1.2.cmml">k</mi><mo id="S2.p6.5.m1.1.1.1" xref="S2.p6.5.m1.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.p6.5.m1.1.1.3" xref="S2.p6.5.m1.1.1.3.cmml">𝒦</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p6.5.m1.1b"><apply id="S2.p6.5.m1.1.1.cmml" xref="S2.p6.5.m1.1.1"><in id="S2.p6.5.m1.1.1.1.cmml" xref="S2.p6.5.m1.1.1.1"></in><ci id="S2.p6.5.m1.1.1.2.cmml" xref="S2.p6.5.m1.1.1.2">𝑘</ci><ci id="S2.p6.5.m1.1.1.3.cmml" xref="S2.p6.5.m1.1.1.3">𝒦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p6.5.m1.1c">k\in\mathcal{K}</annotation></semantics></math> and with <math id="S2.p6.6.m2.1" class="ltx_Math" alttext="\eta" display="inline"><semantics id="S2.p6.6.m2.1a"><mi id="S2.p6.6.m2.1.1" xref="S2.p6.6.m2.1.1.cmml">η</mi><annotation-xml encoding="MathML-Content" id="S2.p6.6.m2.1b"><ci id="S2.p6.6.m2.1.1.cmml" xref="S2.p6.6.m2.1.1">𝜂</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p6.6.m2.1c">\eta</annotation></semantics></math> being the learning rate.
Next, each client <math id="S2.p6.7.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.p6.7.m3.1a"><mi id="S2.p6.7.m3.1.1" xref="S2.p6.7.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.p6.7.m3.1b"><ci id="S2.p6.7.m3.1.1.cmml" xref="S2.p6.7.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p6.7.m3.1c">k</annotation></semantics></math> sends its updated model parameters back to the server which aggregates the parameters from all clients. Then, the server applies the popular Federated Averaging<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Other advanced FL algorithms can also be accomodated as part of our framework.</span></span></span> FL algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> to estimate an average update of the model parameters and send the newly updated parameters to all clients according to the following rule:</p>
<table id="S2.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E3.m1.1" class="ltx_Math" alttext="\boldsymbol{\theta_{h+1}^{s}}=\sum_{k\in\mathcal{K}}{w_{k}\cdot\boldsymbol{\theta_{h}^{k}}}," display="block"><semantics id="S2.E3.m1.1a"><mrow id="S2.E3.m1.1.1.1" xref="S2.E3.m1.1.1.1.1.cmml"><mrow id="S2.E3.m1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.cmml"><msubsup id="S2.E3.m1.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.2.cmml"><mi id="S2.E3.m1.1.1.1.1.2.2.2" xref="S2.E3.m1.1.1.1.1.2.2.2.cmml">𝜽</mi><mrow id="S2.E3.m1.1.1.1.1.2.2.3" xref="S2.E3.m1.1.1.1.1.2.2.3.cmml"><mi id="S2.E3.m1.1.1.1.1.2.2.3.2" xref="S2.E3.m1.1.1.1.1.2.2.3.2.cmml">𝒉</mi><mo class="ltx_mathvariant_bold" mathvariant="bold" id="S2.E3.m1.1.1.1.1.2.2.3.1" xref="S2.E3.m1.1.1.1.1.2.2.3.1.cmml">+</mo><mn id="S2.E3.m1.1.1.1.1.2.2.3.3" xref="S2.E3.m1.1.1.1.1.2.2.3.3.cmml">𝟏</mn></mrow><mi id="S2.E3.m1.1.1.1.1.2.3" xref="S2.E3.m1.1.1.1.1.2.3.cmml">𝒔</mi></msubsup><mo rspace="0.111em" id="S2.E3.m1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.cmml">=</mo><mrow id="S2.E3.m1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.3.cmml"><munder id="S2.E3.m1.1.1.1.1.3.1" xref="S2.E3.m1.1.1.1.1.3.1.cmml"><mo movablelimits="false" id="S2.E3.m1.1.1.1.1.3.1.2" xref="S2.E3.m1.1.1.1.1.3.1.2.cmml">∑</mo><mrow id="S2.E3.m1.1.1.1.1.3.1.3" xref="S2.E3.m1.1.1.1.1.3.1.3.cmml"><mi id="S2.E3.m1.1.1.1.1.3.1.3.2" xref="S2.E3.m1.1.1.1.1.3.1.3.2.cmml">k</mi><mo id="S2.E3.m1.1.1.1.1.3.1.3.1" xref="S2.E3.m1.1.1.1.1.3.1.3.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.E3.m1.1.1.1.1.3.1.3.3" xref="S2.E3.m1.1.1.1.1.3.1.3.3.cmml">𝒦</mi></mrow></munder><mrow id="S2.E3.m1.1.1.1.1.3.2" xref="S2.E3.m1.1.1.1.1.3.2.cmml"><msub id="S2.E3.m1.1.1.1.1.3.2.2" xref="S2.E3.m1.1.1.1.1.3.2.2.cmml"><mi id="S2.E3.m1.1.1.1.1.3.2.2.2" xref="S2.E3.m1.1.1.1.1.3.2.2.2.cmml">w</mi><mi id="S2.E3.m1.1.1.1.1.3.2.2.3" xref="S2.E3.m1.1.1.1.1.3.2.2.3.cmml">k</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S2.E3.m1.1.1.1.1.3.2.1" xref="S2.E3.m1.1.1.1.1.3.2.1.cmml">⋅</mo><msubsup id="S2.E3.m1.1.1.1.1.3.2.3" xref="S2.E3.m1.1.1.1.1.3.2.3.cmml"><mi id="S2.E3.m1.1.1.1.1.3.2.3.2.2" xref="S2.E3.m1.1.1.1.1.3.2.3.2.2.cmml">𝜽</mi><mi id="S2.E3.m1.1.1.1.1.3.2.3.2.3" xref="S2.E3.m1.1.1.1.1.3.2.3.2.3.cmml">𝒉</mi><mi id="S2.E3.m1.1.1.1.1.3.2.3.3" xref="S2.E3.m1.1.1.1.1.3.2.3.3.cmml">𝒌</mi></msubsup></mrow></mrow></mrow><mo id="S2.E3.m1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.1b"><apply id="S2.E3.m1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1"><eq id="S2.E3.m1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1"></eq><apply id="S2.E3.m1.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.2.1.cmml" xref="S2.E3.m1.1.1.1.1.2">superscript</csymbol><apply id="S2.E3.m1.1.1.1.1.2.2.cmml" xref="S2.E3.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.2.2.1.cmml" xref="S2.E3.m1.1.1.1.1.2">subscript</csymbol><ci id="S2.E3.m1.1.1.1.1.2.2.2.cmml" xref="S2.E3.m1.1.1.1.1.2.2.2">𝜽</ci><apply id="S2.E3.m1.1.1.1.1.2.2.3.cmml" xref="S2.E3.m1.1.1.1.1.2.2.3"><plus id="S2.E3.m1.1.1.1.1.2.2.3.1.cmml" xref="S2.E3.m1.1.1.1.1.2.2.3.1"></plus><ci id="S2.E3.m1.1.1.1.1.2.2.3.2.cmml" xref="S2.E3.m1.1.1.1.1.2.2.3.2">𝒉</ci><cn type="integer" id="S2.E3.m1.1.1.1.1.2.2.3.3.cmml" xref="S2.E3.m1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S2.E3.m1.1.1.1.1.2.3.cmml" xref="S2.E3.m1.1.1.1.1.2.3">𝒔</ci></apply><apply id="S2.E3.m1.1.1.1.1.3.cmml" xref="S2.E3.m1.1.1.1.1.3"><apply id="S2.E3.m1.1.1.1.1.3.1.cmml" xref="S2.E3.m1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.3.1.1.cmml" xref="S2.E3.m1.1.1.1.1.3.1">subscript</csymbol><sum id="S2.E3.m1.1.1.1.1.3.1.2.cmml" xref="S2.E3.m1.1.1.1.1.3.1.2"></sum><apply id="S2.E3.m1.1.1.1.1.3.1.3.cmml" xref="S2.E3.m1.1.1.1.1.3.1.3"><in id="S2.E3.m1.1.1.1.1.3.1.3.1.cmml" xref="S2.E3.m1.1.1.1.1.3.1.3.1"></in><ci id="S2.E3.m1.1.1.1.1.3.1.3.2.cmml" xref="S2.E3.m1.1.1.1.1.3.1.3.2">𝑘</ci><ci id="S2.E3.m1.1.1.1.1.3.1.3.3.cmml" xref="S2.E3.m1.1.1.1.1.3.1.3.3">𝒦</ci></apply></apply><apply id="S2.E3.m1.1.1.1.1.3.2.cmml" xref="S2.E3.m1.1.1.1.1.3.2"><ci id="S2.E3.m1.1.1.1.1.3.2.1.cmml" xref="S2.E3.m1.1.1.1.1.3.2.1">⋅</ci><apply id="S2.E3.m1.1.1.1.1.3.2.2.cmml" xref="S2.E3.m1.1.1.1.1.3.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.3.2.2.1.cmml" xref="S2.E3.m1.1.1.1.1.3.2.2">subscript</csymbol><ci id="S2.E3.m1.1.1.1.1.3.2.2.2.cmml" xref="S2.E3.m1.1.1.1.1.3.2.2.2">𝑤</ci><ci id="S2.E3.m1.1.1.1.1.3.2.2.3.cmml" xref="S2.E3.m1.1.1.1.1.3.2.2.3">𝑘</ci></apply><apply id="S2.E3.m1.1.1.1.1.3.2.3.cmml" xref="S2.E3.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.3.2.3.1.cmml" xref="S2.E3.m1.1.1.1.1.3.2.3">superscript</csymbol><apply id="S2.E3.m1.1.1.1.1.3.2.3.2.cmml" xref="S2.E3.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.3.2.3.2.1.cmml" xref="S2.E3.m1.1.1.1.1.3.2.3">subscript</csymbol><ci id="S2.E3.m1.1.1.1.1.3.2.3.2.2.cmml" xref="S2.E3.m1.1.1.1.1.3.2.3.2.2">𝜽</ci><ci id="S2.E3.m1.1.1.1.1.3.2.3.2.3.cmml" xref="S2.E3.m1.1.1.1.1.3.2.3.2.3">𝒉</ci></apply><ci id="S2.E3.m1.1.1.1.1.3.2.3.3.cmml" xref="S2.E3.m1.1.1.1.1.3.2.3.3">𝒌</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.1c">\boldsymbol{\theta_{h+1}^{s}}=\sum_{k\in\mathcal{K}}{w_{k}\cdot\boldsymbol{\theta_{h}^{k}}},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S2.p6.8" class="ltx_p">where the weighting vector <math id="S2.p6.8.m1.4" class="ltx_Math" alttext="\boldsymbol{w}=(w_{1},w_{2},...,w_{k})" display="inline"><semantics id="S2.p6.8.m1.4a"><mrow id="S2.p6.8.m1.4.4" xref="S2.p6.8.m1.4.4.cmml"><mi id="S2.p6.8.m1.4.4.5" xref="S2.p6.8.m1.4.4.5.cmml">𝒘</mi><mo id="S2.p6.8.m1.4.4.4" xref="S2.p6.8.m1.4.4.4.cmml">=</mo><mrow id="S2.p6.8.m1.4.4.3.3" xref="S2.p6.8.m1.4.4.3.4.cmml"><mo stretchy="false" id="S2.p6.8.m1.4.4.3.3.4" xref="S2.p6.8.m1.4.4.3.4.cmml">(</mo><msub id="S2.p6.8.m1.2.2.1.1.1" xref="S2.p6.8.m1.2.2.1.1.1.cmml"><mi id="S2.p6.8.m1.2.2.1.1.1.2" xref="S2.p6.8.m1.2.2.1.1.1.2.cmml">w</mi><mn id="S2.p6.8.m1.2.2.1.1.1.3" xref="S2.p6.8.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S2.p6.8.m1.4.4.3.3.5" xref="S2.p6.8.m1.4.4.3.4.cmml">,</mo><msub id="S2.p6.8.m1.3.3.2.2.2" xref="S2.p6.8.m1.3.3.2.2.2.cmml"><mi id="S2.p6.8.m1.3.3.2.2.2.2" xref="S2.p6.8.m1.3.3.2.2.2.2.cmml">w</mi><mn id="S2.p6.8.m1.3.3.2.2.2.3" xref="S2.p6.8.m1.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S2.p6.8.m1.4.4.3.3.6" xref="S2.p6.8.m1.4.4.3.4.cmml">,</mo><mi mathvariant="normal" id="S2.p6.8.m1.1.1" xref="S2.p6.8.m1.1.1.cmml">…</mi><mo id="S2.p6.8.m1.4.4.3.3.7" xref="S2.p6.8.m1.4.4.3.4.cmml">,</mo><msub id="S2.p6.8.m1.4.4.3.3.3" xref="S2.p6.8.m1.4.4.3.3.3.cmml"><mi id="S2.p6.8.m1.4.4.3.3.3.2" xref="S2.p6.8.m1.4.4.3.3.3.2.cmml">w</mi><mi id="S2.p6.8.m1.4.4.3.3.3.3" xref="S2.p6.8.m1.4.4.3.3.3.3.cmml">k</mi></msub><mo stretchy="false" id="S2.p6.8.m1.4.4.3.3.8" xref="S2.p6.8.m1.4.4.3.4.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p6.8.m1.4b"><apply id="S2.p6.8.m1.4.4.cmml" xref="S2.p6.8.m1.4.4"><eq id="S2.p6.8.m1.4.4.4.cmml" xref="S2.p6.8.m1.4.4.4"></eq><ci id="S2.p6.8.m1.4.4.5.cmml" xref="S2.p6.8.m1.4.4.5">𝒘</ci><vector id="S2.p6.8.m1.4.4.3.4.cmml" xref="S2.p6.8.m1.4.4.3.3"><apply id="S2.p6.8.m1.2.2.1.1.1.cmml" xref="S2.p6.8.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.p6.8.m1.2.2.1.1.1.1.cmml" xref="S2.p6.8.m1.2.2.1.1.1">subscript</csymbol><ci id="S2.p6.8.m1.2.2.1.1.1.2.cmml" xref="S2.p6.8.m1.2.2.1.1.1.2">𝑤</ci><cn type="integer" id="S2.p6.8.m1.2.2.1.1.1.3.cmml" xref="S2.p6.8.m1.2.2.1.1.1.3">1</cn></apply><apply id="S2.p6.8.m1.3.3.2.2.2.cmml" xref="S2.p6.8.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.p6.8.m1.3.3.2.2.2.1.cmml" xref="S2.p6.8.m1.3.3.2.2.2">subscript</csymbol><ci id="S2.p6.8.m1.3.3.2.2.2.2.cmml" xref="S2.p6.8.m1.3.3.2.2.2.2">𝑤</ci><cn type="integer" id="S2.p6.8.m1.3.3.2.2.2.3.cmml" xref="S2.p6.8.m1.3.3.2.2.2.3">2</cn></apply><ci id="S2.p6.8.m1.1.1.cmml" xref="S2.p6.8.m1.1.1">…</ci><apply id="S2.p6.8.m1.4.4.3.3.3.cmml" xref="S2.p6.8.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.p6.8.m1.4.4.3.3.3.1.cmml" xref="S2.p6.8.m1.4.4.3.3.3">subscript</csymbol><ci id="S2.p6.8.m1.4.4.3.3.3.2.cmml" xref="S2.p6.8.m1.4.4.3.3.3.2">𝑤</ci><ci id="S2.p6.8.m1.4.4.3.3.3.3.cmml" xref="S2.p6.8.m1.4.4.3.3.3.3">𝑘</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p6.8.m1.4c">\boldsymbol{w}=(w_{1},w_{2},...,w_{k})</annotation></semantics></math> is assigned by the server to weigh different clients in the network. This process is repeated until convergence.</p>
</div>
<div id="S2.p7" class="ltx_para">
<p id="S2.p7.1" class="ltx_p">Given this setup, our key goal is to implement the QFL framework over a quantum network in which quantum learning is performed in a decentralized manner using classical wireless communication infrastructure. To do so, we next generate a novel quantum federated dataset, and, then, we implement the QFL framework. This will constitute the first implementation of such a system that combines Google’s TFQ and TFF.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Quantum Federated Dataset</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Given the lack of existing quantum federated dataset in literature, our proposed QFL framework must begin by generating the first quantum federated dataset that can be used for distributed learning in quantum networks. The generated dataset has a hierarchical data format and consists of purely quantum data. Next, we describe the proposed steps for generating the dataset.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Quantum Data</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">A variety of purely quantum data exists for different quantum many-body systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. The data is typically obtained using different quantum devices or complex simulations of quantum systems.<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Note that classical data can be encoded into quantum states and fed to quantum computers as quantum data as discussed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> This classical data encoding task is done by performing quantum state preparation functions or by utilizing quantum feature maps.</span></span></span> For instance, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> considered symmetry-protected topological phases <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> as input data to be classified by a QCNN model. We adopt the simpler, yet practical, form of quantum data consisting of quantum clusters inspired from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">The proposed quantum dataset consists of excitations of quantum cluster states <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>, labeled as either excited or not based on the rotations of the qubits. This type of data is of important use for quantum sensing networks like the ones applied for metrology <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>. In addition, quantum cluster states are particularly important for our tackled practical problem of QC networks. This is due to their applicability in distributed quantum computing networks, and their ability to teleport quantum states between quantum clients communicating through a quantum channel <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>. Thus, the adopted data type perfectly fits our targets and allows for future extensions to quantum networks incorporating both classical and quantum clients.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Federated Dataset Generation</h3>

<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Generating Single Client Data</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.2" class="ltx_p">We used TFQ and Google’s framework for quantum circuit programming: Cirq <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite> for generating the quantum data of each client. We begin by generating a rectangular grid of <math id="S3.SS2.SSS1.p1.1.m1.1" class="ltx_Math" alttext="1\times 8" display="inline"><semantics id="S3.SS2.SSS1.p1.1.m1.1a"><mrow id="S3.SS2.SSS1.p1.1.m1.1.1" xref="S3.SS2.SSS1.p1.1.m1.1.1.cmml"><mn id="S3.SS2.SSS1.p1.1.m1.1.1.2" xref="S3.SS2.SSS1.p1.1.m1.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.SSS1.p1.1.m1.1.1.1" xref="S3.SS2.SSS1.p1.1.m1.1.1.1.cmml">×</mo><mn id="S3.SS2.SSS1.p1.1.m1.1.1.3" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.1.m1.1b"><apply id="S3.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1"><times id="S3.SS2.SSS1.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.1"></times><cn type="integer" id="S3.SS2.SSS1.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.2">1</cn><cn type="integer" id="S3.SS2.SSS1.p1.1.m1.1.1.3.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.1.m1.1c">1\times 8</annotation></semantics></math> qubits using Cirq, such a size is reasonable for QML simulations and is sufficient for validating the proposed QFL framework. Then, we create cluster states as TFQ circuits consisting of the Hadamard and Controlled-Z quantum gates <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, and apply the circuit on the generated qubits. In order to define the excitations of cluster states, we observe that most quantum gates operating on a single qubit can be described as rotations around an axis in the Bloch Sphere <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>. Thus, they are usually referred to by their axis of rotation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>. As proposed by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>, we consider excitations to be represented by rotation gates around the x-axis of the Bloch Sphere (<math id="S3.SS2.SSS1.p1.2.m2.1" class="ltx_Math" alttext="R_{x}" display="inline"><semantics id="S3.SS2.SSS1.p1.2.m2.1a"><msub id="S3.SS2.SSS1.p1.2.m2.1.1" xref="S3.SS2.SSS1.p1.2.m2.1.1.cmml"><mi id="S3.SS2.SSS1.p1.2.m2.1.1.2" xref="S3.SS2.SSS1.p1.2.m2.1.1.2.cmml">R</mi><mi id="S3.SS2.SSS1.p1.2.m2.1.1.3" xref="S3.SS2.SSS1.p1.2.m2.1.1.3.cmml">x</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.2.m2.1b"><apply id="S3.SS2.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.2.m2.1.1.1.cmml" xref="S3.SS2.SSS1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p1.2.m2.1.1.2.cmml" xref="S3.SS2.SSS1.p1.2.m2.1.1.2">𝑅</ci><ci id="S3.SS2.SSS1.p1.2.m2.1.1.3.cmml" xref="S3.SS2.SSS1.p1.2.m2.1.1.3">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.2.m2.1c">R_{x}</annotation></semantics></math> quantum gates <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>). An excitation of the cluster state is declared if a large enough rotation is achieved and the state is labeled with 1. In case the rotation is not sufficiently large, the state is declared as unexcited, and is labeled with a 0.</p>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Generating Federated Data</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p">The previously described quantum data has input represented by quantum circuits. In order to be able to store the data, the quantum circuit is transformed into a tensor that is represented by strings. In fact, these strings represent an encoding of the serialized binary data of the quantum circuits with TensorFlow data type <span id="S3.SS2.SSS2.p1.1.1" class="ltx_ERROR undefined">\say</span>lS5000. We particularly generate a hierarchical data format version 5 (HDF5) federated dataset file which includes examples of 30 clients (Any number of clients can be considered, see Section <a href="#S4" title="4 Experiments ‣ Quantum Federated Learning with Quantum Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>). Each client has its own quantum dataset consisting of 160 serialized binary data input vector of a single feature, and a labels vector of integers of 0s and 1s.</p>
</div>
<div id="S3.SS2.SSS2.p2" class="ltx_para">
<p id="S3.SS2.SSS2.p2.1" class="ltx_p">Moreover, we generate a quantum federated dataset consisting of non-IID clients’ datasets. Then, we conduct key experiments on this setup to compare the performance with the IID case originally followed. The obtained results are discussed in the next section.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we present the experimental results for the proposed QFL framework. First, we provide thorough details of the experimental setup. Then, we conduct extensive experiments to verify the applicability and effectiveness of our proposed framework.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Experimental Setup</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p"><span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_bold">Implementation</span>. We use the TFQ and TFF frameworks to implement our proposed QFL framework, and we build upon the implementations in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>. We run our simulations on Google’s Cloud Platform known as <span id="S4.SS1.p1.1.2" class="ltx_ERROR undefined">\say</span>Google Colaboratory <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> using CPU computing nodes. The implementation begins with generating the quantum federated dataset described in Section <a href="#S3" title="3 Quantum Federated Dataset ‣ Quantum Federated Learning with Quantum Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">Compared to classical FL scenarios, it is natural to assume that the number of quantum computing clients in a quantum network will be in the range of tens of clients. It is typically assumed that, at a given point in time, only a subset of clients is available for training. However, for the ease of simulations and since the number of clients is small, we assume that all quantum clients available for training, and we reserve the data of a small portion of clients for testing. Since TFF is currently only available in simulation environments, then each client’s data is assumed to be available locally.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">As is typical in classical CNN models, the adopted QCNN architecture consists of quantum convolution layers, each followed by a quantum pooling layer. Then, a quantum fully connected layer is included, and finally, the measurement is performed on the last layer. The width of the QCNN is not an optimization parameter since it solely relies on the number of qubits in the system, due to the reduction in size that quantum pooling layers introduce to the input qubits. In our case, and since we consider 8 qubits in the QFL setup (this is a typical value for quantum sensing networks), we found that having three pairs of quantum convolution-pooling layers, with 64 learnable parameters, is the most suitable QCNN architecture that fits our setup.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p"><span id="S4.SS1.p4.1.1" class="ltx_text ltx_font_bold">Optimizers and hyperparameters</span>. We compare the performance of the QFL framework under various client optimizers (Adam, SGD, and RMSprop) while fixing the server’s optimizer to SGD with a learning parameter equals to 1, since it is only performing averaging. The learning rates of the clients are varied, and their impact on the performance is discussed in Section <a href="#S4.SS2.SSS3" title="4.2.3 Impact of Optimizers and Learning Rates ‣ 4.2 Results and Discussion ‣ 4 Experiments ‣ Quantum Federated Learning with Quantum Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2.3</span></a>.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para">
<p id="S4.SS1.p5.1" class="ltx_p"><span id="S4.SS1.p5.1.1" class="ltx_text ltx_font_bold">Validation metrics</span>. While it is typical in centralized ML models to use validation data when training, this sort of data is inaccessible in the QFL setup. Thus, a subset of clients will be specified for testing and validating the performance of the trained QFL framework. The validation metric used for the testing clients is the binary accuracy metric with a threshold of 0.5, which is typical for binary classification problems.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Results and Discussion</h3>

<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1 </span>Impact of Number of Clients</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.1" class="ltx_p">We begin our experiments by analyzing the impact of the number of available clients in the QFL network. In Figure <a href="#S4.F2" title="Figure 2 ‣ 4.2.1 Impact of Number of Clients ‣ 4.2 Results and Discussion ‣ 4 Experiments ‣ Quantum Federated Learning with Quantum Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we compare the achieved testing accuracy when the quantum federated dataset has 1 (centralized), 6 (4 for training, 2 for testing), 12 (9 for training, 3 for testing), 18 (14 for training, 4 for testing), 24 (19 for training, 5 for testing), and 30 (25 for training, 5 for testing) clients while fixing the number of data samples available to each client to 160 samples. We observe that, in general, as the number of participating clients in the QFL setup increases, a higher testing accuracy is achieved without overfitting the training data. The reason why the case of 6 clients achieves a smaller accuracy is because the number of clients in a federated setup must be large enough in order to achieve efficient learning.</p>
</div>
<figure id="S4.F2" class="ltx_figure"><img src="/html/2106.00005/assets/x1.png" id="S4.F2.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="293" height="152" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Evaluation of QFL accuracy as the number of clients varies.</figcaption>
</figure>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2 </span>Impact of the Size of Clients’ Data Samples</h4>

<div id="S4.SS2.SSS2.p1" class="ltx_para">
<p id="S4.SS2.SSS2.p1.1" class="ltx_p">In Figure <a href="#S4.F3" title="Figure 3 ‣ 4.2.2 Impact of the Size of Clients’ Data Samples ‣ 4.2 Results and Discussion ‣ 4 Experiments ‣ Quantum Federated Learning with Quantum Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we consider a QFL network of 30 active clients and compare the achieved testing accuracy with the centralized case (single client) while varying the size of the individual client’s datasets. Since the adopted QCNN is shallow and the number of trainable parameters is small (64), we observe that increasing the size of the dataset does not necessarily guarantee an improvement in the performance. In fact, as long as each client has enough data, increasing the size of the dataset may slightly increase or decrease the achieved testing accuracy. Another important observation is that, in this network, the federated framework achieves a superior performance compared to the centralized case. This is because each client in the federated setup benefits from the data of the other clients in the learning process, which enhances the performance.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2106.00005/assets/x2.png" id="S4.F3.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="293" height="152" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Size of client’s dataset vs testing accuracy.</figcaption>
</figure>
</section>
<section id="S4.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.3 </span>Impact of Optimizers and Learning Rates</h4>

<div id="S4.SS2.SSS3.p1" class="ltx_para">
<p id="S4.SS2.SSS3.p1.6" class="ltx_p">In Figure <a href="#S4.F4" title="Figure 4 ‣ 4.2.3 Impact of Optimizers and Learning Rates ‣ 4.2 Results and Discussion ‣ 4 Experiments ‣ Quantum Federated Learning with Quantum Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we compare the performance of the QFL framework with different optimizers and learning rates. We observe that the RMSprop optimizer with a learning rate of <math id="S4.SS2.SSS3.p1.1.m1.1" class="ltx_Math" alttext="0.002" display="inline"><semantics id="S4.SS2.SSS3.p1.1.m1.1a"><mn id="S4.SS2.SSS3.p1.1.m1.1.1" xref="S4.SS2.SSS3.p1.1.m1.1.1.cmml">0.002</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.1.m1.1b"><cn type="float" id="S4.SS2.SSS3.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS3.p1.1.m1.1.1">0.002</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.1.m1.1c">0.002</annotation></semantics></math> is slow compared to the other optimizers and converges at a smaller testing accuracy. For the SGD optimizer with a learning rate of <math id="S4.SS2.SSS3.p1.2.m2.1" class="ltx_Math" alttext="0.02" display="inline"><semantics id="S4.SS2.SSS3.p1.2.m2.1a"><mn id="S4.SS2.SSS3.p1.2.m2.1.1" xref="S4.SS2.SSS3.p1.2.m2.1.1.cmml">0.02</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.2.m2.1b"><cn type="float" id="S4.SS2.SSS3.p1.2.m2.1.1.cmml" xref="S4.SS2.SSS3.p1.2.m2.1.1">0.02</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.2.m2.1c">0.02</annotation></semantics></math>, we observe that it is the only one that achieves a high accuracy from the first epoch, and it converges to a value around <math id="S4.SS2.SSS3.p1.3.m3.1" class="ltx_Math" alttext="96.5\%" display="inline"><semantics id="S4.SS2.SSS3.p1.3.m3.1a"><mrow id="S4.SS2.SSS3.p1.3.m3.1.1" xref="S4.SS2.SSS3.p1.3.m3.1.1.cmml"><mn id="S4.SS2.SSS3.p1.3.m3.1.1.2" xref="S4.SS2.SSS3.p1.3.m3.1.1.2.cmml">96.5</mn><mo id="S4.SS2.SSS3.p1.3.m3.1.1.1" xref="S4.SS2.SSS3.p1.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.3.m3.1b"><apply id="S4.SS2.SSS3.p1.3.m3.1.1.cmml" xref="S4.SS2.SSS3.p1.3.m3.1.1"><csymbol cd="latexml" id="S4.SS2.SSS3.p1.3.m3.1.1.1.cmml" xref="S4.SS2.SSS3.p1.3.m3.1.1.1">percent</csymbol><cn type="float" id="S4.SS2.SSS3.p1.3.m3.1.1.2.cmml" xref="S4.SS2.SSS3.p1.3.m3.1.1.2">96.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.3.m3.1c">96.5\%</annotation></semantics></math>. However, the Adam optimizer with a learning rate of <math id="S4.SS2.SSS3.p1.4.m4.1" class="ltx_Math" alttext="0.02" display="inline"><semantics id="S4.SS2.SSS3.p1.4.m4.1a"><mn id="S4.SS2.SSS3.p1.4.m4.1.1" xref="S4.SS2.SSS3.p1.4.m4.1.1.cmml">0.02</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.4.m4.1b"><cn type="float" id="S4.SS2.SSS3.p1.4.m4.1.1.cmml" xref="S4.SS2.SSS3.p1.4.m4.1.1">0.02</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.4.m4.1c">0.02</annotation></semantics></math> converges to a higher testing accuracy after few training epochs. Finally, we observe that a learning rate of <math id="S4.SS2.SSS3.p1.5.m5.1" class="ltx_Math" alttext="0.2" display="inline"><semantics id="S4.SS2.SSS3.p1.5.m5.1a"><mn id="S4.SS2.SSS3.p1.5.m5.1.1" xref="S4.SS2.SSS3.p1.5.m5.1.1.cmml">0.2</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.5.m5.1b"><cn type="float" id="S4.SS2.SSS3.p1.5.m5.1.1.cmml" xref="S4.SS2.SSS3.p1.5.m5.1.1">0.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.5.m5.1c">0.2</annotation></semantics></math> for Adam optimizer is very large that it cannot learn, while a learning rate of <math id="S4.SS2.SSS3.p1.6.m6.1" class="ltx_Math" alttext="0.002" display="inline"><semantics id="S4.SS2.SSS3.p1.6.m6.1a"><mn id="S4.SS2.SSS3.p1.6.m6.1.1" xref="S4.SS2.SSS3.p1.6.m6.1.1.cmml">0.002</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.6.m6.1b"><cn type="float" id="S4.SS2.SSS3.p1.6.m6.1.1.cmml" xref="S4.SS2.SSS3.p1.6.m6.1.1">0.002</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.6.m6.1c">0.002</annotation></semantics></math> results in a smoother curve at the expense of a smaller accuracy.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2106.00005/assets/x3.png" id="S4.F4.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="293" height="152" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Evolution of the testing accuracy of different optimizers over the training epochs.</figcaption>
</figure>
</section>
<section id="S4.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.4 </span>Impact of Non-IID Data</h4>

<div id="S4.SS2.SSS4.p1" class="ltx_para">
<p id="S4.SS2.SSS4.p1.3" class="ltx_p">When generating the quantum cluster states from the input qubits, the rotation values fed to the <math id="S4.SS2.SSS4.p1.1.m1.1" class="ltx_Math" alttext="R_{x}" display="inline"><semantics id="S4.SS2.SSS4.p1.1.m1.1a"><msub id="S4.SS2.SSS4.p1.1.m1.1.1" xref="S4.SS2.SSS4.p1.1.m1.1.1.cmml"><mi id="S4.SS2.SSS4.p1.1.m1.1.1.2" xref="S4.SS2.SSS4.p1.1.m1.1.1.2.cmml">R</mi><mi id="S4.SS2.SSS4.p1.1.m1.1.1.3" xref="S4.SS2.SSS4.p1.1.m1.1.1.3.cmml">x</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p1.1.m1.1b"><apply id="S4.SS2.SSS4.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS4.p1.1.m1.1.1.1.cmml" xref="S4.SS2.SSS4.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.SSS4.p1.1.m1.1.1.2.cmml" xref="S4.SS2.SSS4.p1.1.m1.1.1.2">𝑅</ci><ci id="S4.SS2.SSS4.p1.1.m1.1.1.3.cmml" xref="S4.SS2.SSS4.p1.1.m1.1.1.3">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p1.1.m1.1c">R_{x}</annotation></semantics></math> gate were drawn from a uniform distribution between <math id="S4.SS2.SSS4.p1.2.m2.1" class="ltx_Math" alttext="-\pi" display="inline"><semantics id="S4.SS2.SSS4.p1.2.m2.1a"><mrow id="S4.SS2.SSS4.p1.2.m2.1.1" xref="S4.SS2.SSS4.p1.2.m2.1.1.cmml"><mo id="S4.SS2.SSS4.p1.2.m2.1.1a" xref="S4.SS2.SSS4.p1.2.m2.1.1.cmml">−</mo><mi id="S4.SS2.SSS4.p1.2.m2.1.1.2" xref="S4.SS2.SSS4.p1.2.m2.1.1.2.cmml">π</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p1.2.m2.1b"><apply id="S4.SS2.SSS4.p1.2.m2.1.1.cmml" xref="S4.SS2.SSS4.p1.2.m2.1.1"><minus id="S4.SS2.SSS4.p1.2.m2.1.1.1.cmml" xref="S4.SS2.SSS4.p1.2.m2.1.1"></minus><ci id="S4.SS2.SSS4.p1.2.m2.1.1.2.cmml" xref="S4.SS2.SSS4.p1.2.m2.1.1.2">𝜋</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p1.2.m2.1c">-\pi</annotation></semantics></math> and <math id="S4.SS2.SSS4.p1.3.m3.1" class="ltx_Math" alttext="\pi" display="inline"><semantics id="S4.SS2.SSS4.p1.3.m3.1a"><mi id="S4.SS2.SSS4.p1.3.m3.1.1" xref="S4.SS2.SSS4.p1.3.m3.1.1.cmml">π</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS4.p1.3.m3.1b"><ci id="S4.SS2.SSS4.p1.3.m3.1.1.cmml" xref="S4.SS2.SSS4.p1.3.m3.1.1">𝜋</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS4.p1.3.m3.1c">\pi</annotation></semantics></math>. In order to vary the underlying distribution of the clients’ data, we consider generating the data for half of the clients using a truncated normal distribution, so that we generate non-IID quantum data. After generating the new dataset, we compare the performance of the QFL framework on the IID and non-IID federated datasets for a network of 30 clients (25 for training, 5 for testing) with 160 data samples each. In Table <a href="#S4.T1" title="Table 1 ‣ 4.2.4 Impact of Non-IID Data ‣ 4.2 Results and Discussion ‣ 4 Experiments ‣ Quantum Federated Learning with Quantum Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we show the testing accuracy and MSE loss for both datasets and observe that the proposed QFL framework achieves a similar performance on both IID and non-IID quantum federated datasets.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Performance comparison between IID and non-IID data</figcaption>
<table id="S4.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.1.1.1" class="ltx_tr">
<th id="S4.T1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Dataset</th>
<th id="S4.T1.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Testing Accuracy</th>
<th id="S4.T1.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Testing MSE</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.1.2.1" class="ltx_tr">
<td id="S4.T1.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t">IID Data</td>
<td id="S4.T1.1.2.1.2" class="ltx_td ltx_align_left ltx_border_t">99.25</td>
<td id="S4.T1.1.2.1.3" class="ltx_td ltx_align_left ltx_border_t">5.66</td>
</tr>
<tr id="S4.T1.1.3.2" class="ltx_tr">
<td id="S4.T1.1.3.2.1" class="ltx_td ltx_align_left ltx_border_bb">Non-IID Data</td>
<td id="S4.T1.1.3.2.2" class="ltx_td ltx_align_left ltx_border_bb">98.625</td>
<td id="S4.T1.1.3.2.3" class="ltx_td ltx_align_left ltx_border_bb">6.57</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S4.SS2.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.5 </span>Error Bars</h4>

<div id="S4.SS2.SSS5.p1" class="ltx_para">
<p id="S4.SS2.SSS5.p1.1" class="ltx_p">In Figure <a href="#S4.F5" title="Figure 5 ‣ 4.2.5 Error Bars ‣ 4.2 Results and Discussion ‣ 4 Experiments ‣ Quantum Federated Learning with Quantum Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we show the error bars for the different performance metrics for both training and testing cases. The tested network consists of 30 clients each with a dataset of 160 samples and the data of 5 clients is used for testing. Figure <a href="#S4.F5" title="Figure 5 ‣ 4.2.5 Error Bars ‣ 4.2 Results and Discussion ‣ 4 Experiments ‣ Quantum Federated Learning with Quantum Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows the errors caused by the random seed after running multiple experiments for the same network, and we can see that the errors are below <math id="S4.SS2.SSS5.p1.1.m1.1" class="ltx_Math" alttext="5\%" display="inline"><semantics id="S4.SS2.SSS5.p1.1.m1.1a"><mrow id="S4.SS2.SSS5.p1.1.m1.1.1" xref="S4.SS2.SSS5.p1.1.m1.1.1.cmml"><mn id="S4.SS2.SSS5.p1.1.m1.1.1.2" xref="S4.SS2.SSS5.p1.1.m1.1.1.2.cmml">5</mn><mo id="S4.SS2.SSS5.p1.1.m1.1.1.1" xref="S4.SS2.SSS5.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS5.p1.1.m1.1b"><apply id="S4.SS2.SSS5.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS5.p1.1.m1.1.1"><csymbol cd="latexml" id="S4.SS2.SSS5.p1.1.m1.1.1.1.cmml" xref="S4.SS2.SSS5.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S4.SS2.SSS5.p1.1.m1.1.1.2.cmml" xref="S4.SS2.SSS5.p1.1.m1.1.1.2">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS5.p1.1.m1.1c">5\%</annotation></semantics></math> which is acceptable.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2106.00005/assets/x4.png" id="S4.F5.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="293" height="152" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Error bars from the random seed after running experiments multiple times.</figcaption>
</figure>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Challenges and Future Outlook</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">The state of the art near-term-intermediate-scale quantum (NISQ) hardware only allow for processing a small number of qubits because of the difficulty in performing quantum error correction to minimize the losses. This is a challenge that renders the practical deployment of large-scale purely quantum QML models, like our proposed QFL framework, a difficult task. Also, the variety of technologies and the different quantum capabilities of devices in a quantum network may make the adoption of a unified QML model difficult, and, thus, the practical implementation of our proposed QFL framework challenging.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">However, our proposed QFL framework paves the way for integrating quantum devices with quantum data with existing wireless networks. As a result, we anticipate that this can lead to a blossoming of new applications that are coupled with new research problems in the areas of networking, quantum hardware, and wireless sensing. This includes designing efficient optimization algorithms that account for networks including both quantum and classical computing clients. This is a great breakthrough that allows leveraging the powerful computing capabilities of quantum computers in today’s communication networks. Our proposed QFL framework allows for training the QML models inside future 6G communication networks which is very promising. Finally, in order to add a new layer of security to our porposed QFL framework, one can investigate the use of quantum cryptographic schemes to encrypt the classical learning parameters in the QFL setup before sending them to the server, and vice versa. Since the clients have quantum capabilities, integrating QFL with QKD is an inteteresting challenging problem that is worth investigation in the future.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this paper, we have proposed a novel framework for quantum federated learning that allows implementing scalable distributed quantum learning over quantum data without the need to send qubits, but by leveraging classical wireless networks. To implement this framework, we have generated the first quantum federated dataset in the literature and performed a unique implementation that combines TensorFlow Quantum and TensorFlow Federated. We have conducted extensive experiments to verify the applicability and effectiveness of our proposed framework. The experimental results validate the effective behavior of the proposed QFL framework using the federated averaging algorithm.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
M. A. Nielsen and I. L. Chuang, <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Quantum Computation and Quantum
Information: 10th Anniversary Edition</em>.   Cambridge University Press, 2010.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
F. Arute <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Quantum supremacy using a programmable
superconducting processor,” <em id="bib.bib2.2.2" class="ltx_emph ltx_font_italic">Nature</em>, vol. 574, no. 7779, pp. 505–510,
Oct 2019. [Online]. Available:
<a target="_blank" href="https://doi.org/10.1038/s41586-019-1666-5" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1038/s41586-019-1666-5</a>

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
“Ibm delivers its highest quantum volume to date, expanding the computational
power of its ibm cloud-accessible quantum computers,” Aug. 2020. [Online].
Available:
<a target="_blank" href="https://newsroom.ibm.com/2020-08-20-IBM-Delivers-Its-Highest-Quantum-Volume-to-Date-Expanding-the-Computational-Power-of-its-IBM-Cloud-Accessible-Quantum-Computers" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://newsroom.ibm.com/2020-08-20-IBM-Delivers-Its-Highest-Quantum-Volume-to-Date-Expanding-the-Computational-Power-of-its-IBM-Cloud-Accessible-Quantum-Computers</a>

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
E. Pednault, J. A. Gunnels, G. Nannicini, L. Horesh, and R. Wisnieff,
“Leveraging secondary storage to simulate deep 54-qubit sycamore circuits,”
2019.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
R. Orus, S. Mugel, and E. Lizaso, “Quantum computing for finance: Overview and
prospects,” <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Reviews in Physics</em>, vol. 4, p. 100028, 2019.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
J. Preskill, “Quantum computing in the nisq era and beyond,” <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Quantum</em>,
vol. 2, p. 79, 2018.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
M. Broughton, G. Verdon, T. McCourt, A. J. Martinez, J. H. Yoo, S. V. Isakov,
P. Massey, M. Y. Niu, R. Halavati, E. Peters, M. Leib, A. Skolik, M. Streif,
D. V. Dollen, J. R. McClean, S. Boixo, D. Bacon, A. K. Ho, H. Neven, and
M. Mohseni, “Tensorflow quantum: A software framework for quantum machine
learning,” 2020.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
M. Schuld, <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Supervised learning with quantum computers</em>.   Springer, 2018.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
P. Rebentrost, M. Mohseni, and S. Lloyd, “Quantum support vector machine for
big data classification,” <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Phys. Rev. Lett.</em>, vol. 113, p. 130503, Sep
2014. [Online]. Available:
<a target="_blank" href="https://link.aps.org/doi/10.1103/PhysRevLett.113.130503" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://link.aps.org/doi/10.1103/PhysRevLett.113.130503</a>

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
S. Lloyd, M. Mohseni, and P. Rebentrost, “Quantum algorithms for supervised
and unsupervised machine learning,” 2013.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
I. Kerenidis, J. Landman, A. Luongo, and A. Prakash, “q-means: A quantum
algorithm for unsupervised machine learning,” in <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Advances in Neural
Information Processing Systems 32</em>, H. Wallach, H. Larochelle,
A. Beygelzimer, F. d'Alché-Buc, E. Fox, and R. Garnett,
Eds.   Curran Associates, Inc., 2019,
pp. 4134–4144.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
I. Kerenidis and A. Prakash, “Quantum recommendation systems,” 2016.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
H. Tasaki, <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Physics and mathematics of quantum many-body systems</em>.   Springer, 2020.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
I. Cong, S. Choi, and M. D. Lukin, “Quantum convolutional neural networks,”
<em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Nature Physics</em>, vol. 15, no. 12, pp. 1273–1278, Dec 2019. [Online].
Available: <a target="_blank" href="https://doi.org/10.1038/s41567-019-0648-8" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1038/s41567-019-0648-8</a>

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
M. Benedetti, E. Lloyd, S. Sack, and M. Fiorentini, “Parameterized quantum
circuits as machine learning models,” <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Quantum Science and Technology</em>,
vol. 4, no. 4, p. 043001, Nov 2019. [Online]. Available:
<a target="_blank" href="http://dx.doi.org/10.1088/2058-9565/ab4eb5" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://dx.doi.org/10.1088/2058-9565/ab4eb5</a>

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
E. Farhi and H. Neven, “Classification with quantum neural networks on near
term processors,” 2018.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
K. Beer, D. Bondarenko, T. Farrelly, T. J. Osborne, R. Salzmann,
D. Scheiermann, and R. Wolf, “Training deep quantum neural networks,”
<em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Nature Communications</em>, vol. 11, no. 1, p. 808, Feb 2020. [Online].
Available: <a target="_blank" href="https://doi.org/10.1038/s41467-020-14454-2" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1038/s41467-020-14454-2</a>

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
A. Abbas, D. Sutter, C. Zoufal, A. Lucchi, A. Figalli, and S. Woerner, “The
power of quantum neural networks,” 2020.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
X. Guo, C. R. Breum, J. Borregaard, S. Izumi, M. V. Larsen, T. Gehring,
M. Christandl, J. S. Neergaard-Nielsen, and U. L. Andersen, “Distributed
quantum sensing in a continuous-variable entangled network,” <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Nature
Physics</em>, vol. 16, no. 3, pp. 281–284, 2020.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
S. Pirandola and S. L. Braunstein, “Physics: Unite to build a quantum
internet,” <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Nature News</em>, vol. 532, no. 7598, p. 169, 2016.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
M. Caleffi, A. S. Cacciapuoti, and G. Bianchi, “Quantum internet: From
communication to distributed computing!” in <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 5th ACM
International Conference on Nanoscale Computing and Communication</em>, 2018, pp.
1–4.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
C. H. Bennett and G. Brassard, “Quantum cryptography: Public key distribution
and coin tossing,” <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Theoretical Computer Science</em>, vol. 560, p. 7–11,
Dec 2014. [Online]. Available:
<a target="_blank" href="http://dx.doi.org/10.1016/j.tcs.2014.05.025" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://dx.doi.org/10.1016/j.tcs.2014.05.025</a>

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
J. I. Cirac and P. Zoller, “Quantum computations with cold trapped ions,”
<em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Physical review letters</em>, vol. 74, no. 20, p. 4091, 1995.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
D. Loss and D. P. DiVincenzo, “Quantum computation with quantum dots,”
<em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Physical Review A</em>, vol. 57, no. 1, p. 120, 1998.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
G. Wendin, “Quantum information processing with superconducting circuits: a
review,” <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Reports on Progress in Physics</em>, vol. 80, no. 10, p. 106001,
2017.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
P. Kairouz <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Advances and open problems in federated learning,”
2019.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
M. Dyakonov, “When will useful quantum computers be constructed? not in the
foreseeable future, this physicist argues. here’s why: The case against:
Quantum computing,” <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">IEEE Spectrum</em>, vol. 56, no. 3, pp. 24–29, 2019.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
A. Ingerman and K. Ostrowski, “Introducing tensorflow federated,” 2019.
[Online]. Available:
<a target="_blank" href="https://medium.com/tensorflow/introducing-tensorflow-federated-a4147aa20041" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://medium.com/tensorflow/introducing-tensorflow-federated-a4147aa20041</a>

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Y.-B. Sheng and L. Zhou, “Distributed secure quantum machine learning,”
<em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Science Bulletin</em>, vol. 62, no. 14, pp. 1025–1029, 06 2017.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
B. Narottama and S. Shin, “Quantum federated learning for wireless
communications,” in <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Journal of the Korean Institute of Communication
Sciences</em>, 2020.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
C.-H. H. Yang, J. Qi, S. Y.-C. Chen, P.-Y. Chen, S. M. Siniscalchi, X. Ma, and
C.-H. Lee, “Decentralizing feature extraction with quantum convolutional
neural network for automatic speech recognition,” 2020.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
S. Y.-C. Chen and S. Yoo, “Federated quantum machine learning,” 2021.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
M. Mariën, K. M. R. Audenaert, K. V. Acoleyen, and F. Verstraete,
“Entanglement rates and the stability of the area law for the entanglement
entropy,” 2014.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
F. X. Yu, A. S. Rawat, A. K. Menon, and S. Kumar, “Federated learning with
only positive labels,” 2020.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
H. B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-efficient learning of deep networks from decentralized
data,” 2017.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
M. Schuld, R. Sweke, and J. J. Meyer, “The effect of data encoding on the
expressive power of variational quantum machine learning models,” 2020.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Z.-C. Gu and X.-G. Wen, “Tensor-entanglement-filtering renormalization
approach and symmetry-protected topological order,” <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Physical Review
B</em>, vol. 80, no. 15, Oct 2009. [Online]. Available:
<a target="_blank" href="http://dx.doi.org/10.1103/PhysRevB.80.155131" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://dx.doi.org/10.1103/PhysRevB.80.155131</a>

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
N. Schuch, D. Pérez-García, and I. Cirac, “Classifying quantum phases using
matrix product states and projected entangled pair states,” <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Physical
Review B</em>, vol. 84, no. 16, Oct 2011. [Online]. Available:
<a target="_blank" href="http://dx.doi.org/10.1103/PhysRevB.84.165139" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://dx.doi.org/10.1103/PhysRevB.84.165139</a>

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
“Quantum convolutional neural network: Tensorflow quantum,” 2020. [Online].
Available: <a target="_blank" href="https://www.tensorflow.org/quantum/tutorials/qcnn" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.tensorflow.org/quantum/tutorials/qcnn</a>

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
M. A. Nielsen, “Cluster-state quantum computation,” <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">Reports on
Mathematical Physics</em>, vol. 57, no. 1, p. 147–161, Feb 2006. [Online].
Available: <a target="_blank" href="http://dx.doi.org/10.1016/S0034-4877(06)80014-5" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://dx.doi.org/10.1016/S0034-4877(06)80014-5</a>

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
H. J. Briegel, <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">Cluster States</em>.   Berlin, Heidelberg: Springer Berlin Heidelberg, 2009, pp. 96–105. [Online].
Available: <a target="_blank" href="https://doi.org/10.1007/978-3-540-70626-7_30" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/978-3-540-70626-7_30</a>

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
N. Friis, D. Orsucci, M. Skotiniotis, P. Sekatski, V. Dunjko, H. J. Briegel,
and W. Dür, “Flexible resources for quantum metrology,” <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">New Journal
of Physics</em>, vol. 19, no. 6, p. 063044, jun 2017. [Online]. Available:
<a target="_blank" href="https://doi.org/10.1088/1367-2630/aa7144" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1088/1367-2630/aa7144</a>

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
I. B. Djordjevic, “On global quantum communication networking,”
<em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">Entropy</em>, vol. 22, no. 8, 2020. [Online]. Available:
<a target="_blank" href="https://www.mdpi.com/1099-4300/22/8/831" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.mdpi.com/1099-4300/22/8/831</a>

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Q. A. team and collaborators, “Cirq,” Oct 2020. [Online]. Available:
<a target="_blank" href="https://doi.org/10.5281/zenodo.4062499" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.5281/zenodo.4062499</a>

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
T. Lu, X. Miao, and H. Metcalf, “Bloch theorem on the bloch sphere,”
<em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">Physical Review A</em>, vol. 71, no. 6, p. 061405, 2005.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
I. Glendinning, “The bloch sphere,” in <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">QIA Meeting. Vienna</em>, 2005.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
“Federated learning workshop using tensorflow federated,” July 2020.
[Online]. Available:
<a target="_blank" href="https://colab.research.google.com/drive/1kCSSFUCU_rxW7MElwZXENe50_VTnvGH1?usp=sharing" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://colab.research.google.com/drive/1kCSSFUCU_rxW7MElwZXENe50_VTnvGH1?usp=sharing</a>

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
E. Bisong, <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">Google Colaboratory</em>.   Berkeley, CA: Apress, 2019, pp. 59–64.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2106.00004" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2106.00005" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2106.00005">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2106.00005" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2106.00006" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar  2 05:25:14 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
