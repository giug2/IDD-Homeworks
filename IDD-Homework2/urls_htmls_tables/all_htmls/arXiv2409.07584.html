<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis</title>
<!--Generated on Wed Sep 11 17:45:11 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="
Cross-task learning,  Knowledge distillation,  3D computer vision,  Alzheimer’s early diagnosis
" lang="en" name="keywords"/>
<base href="/html/2409.07584v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#S1" title="In DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#S2" title="In DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">Related Works</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#S2.SS1" title="In II Related Works ‣ DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-A</span> </span><span class="ltx_text ltx_font_italic">Single Modality AD Diagnosis</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#S2.SS2" title="In II Related Works ‣ DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-B</span> </span><span class="ltx_text ltx_font_italic">Knowledge Distillation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#S2.SS3" title="In II Related Works ‣ DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-C</span> </span><span class="ltx_text ltx_font_italic">FastSurfer</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#S2.SS4" title="In II Related Works ‣ DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">II-D</span> </span><span class="ltx_text ltx_font_italic">ADAPT</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#S3" title="In DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">Methods</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#S3.SS1" title="In III Methods ‣ DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span> </span><span class="ltx_text ltx_font_italic">DS-ViT Pipeline</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#S3.SS1.SSS1" title="In III-A DS-ViT Pipeline ‣ III Methods ‣ DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span>1 </span>Dual-Stream Embedding</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#S3.SS1.SSS2" title="In III-A DS-ViT Pipeline ‣ III Methods ‣ DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span>2 </span>3D Feature Integration</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#S3.SS2" title="In III Methods ‣ DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span> </span><span class="ltx_text ltx_font_italic">Extension: Early Diagnosis of Alzheimer’s Disease</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#S3.SS3" title="In III Methods ‣ DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-C</span> </span><span class="ltx_text ltx_font_italic">DS-ViT for Early Diagnosis Pipeline</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#S3.SS4" title="In III Methods ‣ DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-D</span> </span><span class="ltx_text ltx_font_italic">Residual Temporal Attention Block (RTAB)</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#S4" title="In DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Experiments</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#S4.SS1" title="In IV Experiments ‣ DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-A</span> </span><span class="ltx_text ltx_font_italic">Dataset and Preprocessing</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#S4.SS2" title="In IV Experiments ‣ DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-B</span> </span><span class="ltx_text ltx_font_italic">Evaluation</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#S4.SS2.SSS1" title="In IV-B Evaluation ‣ IV Experiments ‣ DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-B</span>1 </span>Evaluation on DS-ViT Pipeline</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#S4.SS2.SSS2" title="In IV-B Evaluation ‣ IV Experiments ‣ DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-B</span>2 </span>Evaluation on Early Diagnosis</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#S5" title="In DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">V </span><span class="ltx_text ltx_font_smallcaps">Conclusions</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis
<br class="ltx_break"/>
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ke Chen
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id1.1.id1">School of Information Sciences</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="id2.2.id2">University of Illinois Urbana-Champaign
<br class="ltx_break"/></span>Urbana, USA 
<br class="ltx_break"/>kec10@illinois.edu
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yifeng Wang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id3.1.id1">Department of Electrical and
Computer Engineering   
<br class="ltx_break"/>Carnegie Mellon University   
<br class="ltx_break"/></span>Pittsburgh, USA   
<br class="ltx_break"/>yifengw3@andrew.cmu.edu   
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">         Yufei Zhou
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id4.1.id1">         Department of Economics</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="id5.2.id2">         Duke University
<br class="ltx_break"/></span>        Durham, USA 
<br class="ltx_break"/>        yz597@duke.edu.com
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">     Haohan Wang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id6.1.id1">     School of Information Sciences</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="id7.2.id2">     University of Illinois Urbana-Champaign
<br class="ltx_break"/></span>    Urbana, USA 
<br class="ltx_break"/>    haohanw@illinois.edu
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id8.id1">In the field of Alzheimer’s disease diagnosis, segmentation and classification tasks are inherently interconnected. Sharing knowledge between models for these tasks can significantly improve training efficiency, particularly when training data is scarce. However, traditional knowledge distillation techniques often struggle to bridge the gap between segmentation and classification due to the distinct nature of tasks and different model architectures. To address this challenge, we propose a dual-stream pipeline that facilitates cross-task and cross-architecture knowledge sharing. Our approach introduces a dual-stream embedding module that unifies feature representations from segmentation and classification models, enabling dimensional integration of these features to guide the classification model. We validated our method on multiple 3D datasets for Alzheimer’s disease diagnosis, demonstrating significant improvements in classification performance, especially on small datasets. Furthermore, we extended our pipeline with a residual temporal attention mechanism for early diagnosis, utilizing images taken before the atrophy of patients’ brain mass. This advancement shows promise in enabling diagnosis approximately six months earlier in mild and asymptomatic stages, offering critical time for intervention.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Cross-task learning, Knowledge distillation, 3D computer vision, Alzheimer’s early diagnosis

</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Alzheimer’s Disease (AD) remains one of the most challenging neurodegenerative disorders, primarily affecting the elderly. Despite extensive research, the current therapeutic approaches are largely symptomatic, aiming to manage cognitive and behavioral symptoms rather than offering a cure <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib1" title="">1</a>]</cite>. The primary drugs available, including donepezil, memantine, galantamine, and rivastigmine, target neurotransmitter systems to temporarily stabilize cognitive functions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib2" title="">2</a>]</cite>. However, their effectiveness is limited during the later stages of the disease when significant neurodegeneration has already occurred. This has led to a growing recognition of the need for early diagnosis and intervention in the early asymptomatic stage, which could potentially slow or halt the progression of AD by targeting the disease in its preclinical stages <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib3" title="">3</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Magnetic Resonance Imaging (MRI) is a crucial tool in the diagnosis of AD, providing high-resolution images that reveal structural changes in the brain, such as the atrophy of brain regions and the enlargement of the cerebral ventricles <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib4" title="">4</a>]</cite>. These changes are closely associated with the progression of AD and can serve as important biomarkers for early detection <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib3" title="">3</a>]</cite>. Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#S1.F1" title="Figure 1 ‣ I Introduction ‣ DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates the volumetric changes in the cerebral ventricle during the transition from Mild Cognitive Impairment (MCI) to AD, highlighting the potential of these biomarkers for AI-driven early diagnosis.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Traditional approaches in machine-learning-based AD diagnosis have often treated segmentation and classification as separate tasks. This separation overlooks the critical medical connection between the anatomical segmentation of brain structures and the subsequent classification of disease progression. Accurate segmentation provides essential insights into the structural changes associated with AD, such as atrophy in specific brain regions, which are directly linked to the severity and advancement of the disease <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib5" title="">5</a>]</cite>. However, when segmentation and classification are handled independently, it can lead to inefficiencies in training and suboptimal performance, particularly when high-quality AD imaging data is scarce and expensive to obtain.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">These limitations significantly hinder the application of ML in AD diagnosis. Without integrated segmentation and classification, ML models struggle to capture the full complexity of AD’s progression, resulting in less accurate predictions and a reduced ability to identify early-stage biomarkers. This is particularly problematic in clinical settings, where the ability to detect AD early is crucial for timely intervention and treatment. The lack of effective integration between segmentation and classification tasks in current ML approaches directly impacts the reliability and clinical applicability of these models.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">FastSurfer and ADAPT represent state-of-the-art models in brain MRI segmentation and classification, respectively, offering vast opportunities for improving AD diagnosis. FastSurfer, a well-established CNN-based MRI segmentation model trained on large-scale datasets, excels in detailed brain segmentation, which is crucial for identifying the structural changes associated with AD <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib6" title="">6</a>]</cite>. On the other hand, ADAPT, a Vision Transformer (ViT)-based model, has demonstrated remarkable performance in AD diagnosis with minimal parameters <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib7" title="">7</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">Given their complementary strengths, there is a significant potential for knowledge sharing between these models to enhance diagnostic accuracy. Knowledge distillation, a technique that transfers knowledge from a robust teacher model to a more efficient student model, could provide a direct pathway for this information exchange. However, traditional knowledge distillation methods, which rely heavily on soft labels <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib8" title="">8</a>]</cite>, are inadequate for tasks with fundamentally different objectives, such as segmentation and classification. Moreover, the architectural differences between FastSurfer and ADAPT pose additional challenges to effective knowledge transfer.</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">To overcome these challenges, we propose the Dual-Stream Vision Transformer (DS-ViT) pipeline, a novel approach that integrates segmentation and classification tasks to enhance training efficiency and model accuracy in the diagnosis of AD. Our approach utilizes FastSurfer as the teacher model to provide detailed brain segmentation, and ADAPT as the student model, leveraging its strong performance in AD diagnosis. To bridge the gap between these two tasks, we designed a Dual-Stream Embedding module that processes both pixel-level MRI image data and token-like segmentation data, embedding and integrating them through a 3D Bottleneck MLP structure. This innovative design facilitates effective cross-task knowledge sharing and improves the model’s ability to generalize from limited data.</p>
</div>
<div class="ltx_para" id="S1.p8">
<p class="ltx_p" id="S1.p8.1">As shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#S1.F1" title="Figure 1 ‣ I Introduction ‣ DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis"><span class="ltx_text ltx_ref_tag">1</span></a>, the progression from Mild Cognitive Impairment (MCI) to Alzheimer’s Disease (AD) is characterized by subtle yet critical changes in brain structure, such as the volumetric increase in the cerebral ventricle. These patterns, observable through sequential MRI scans, suggest that AI has the potential to detect early biomarkers of AD, thereby enabling timely intervention before significant symptoms emerge. The ability to predict disease progression at an early stage could significantly improve patient outcomes by allowing for preventive treatments.</p>
</div>
<div class="ltx_para" id="S1.p9">
<p class="ltx_p" id="S1.p9.1">To harness this potential and extend the application of our methods, we incorporated a Residual Temporal Attention Block (RTAB) into the DS-ViT pipeline. The RTAB is designed to capture temporal dynamics by analyzing differences between feature maps from sequential MRI scans. By aggregating these temporal features through an attention mechanism, the RTAB enables the model to predict the risk of disease progression, thereby supporting early intervention strategies aimed at delaying or preventing the onset of AD.</p>
</div>
<div class="ltx_para" id="S1.p10">
<p class="ltx_p" id="S1.p10.1">We rigorously evaluated the DS-ViT pipeline across multiple benchmarks, demonstrating its superiority over the baseline ADAPT model. Our results indicate a significant improvement in classification accuracy, particularly in scenarios with limited training data, where DS-ViT achieved an average accuracy increase of 7% and reduced convergence time by half. Furthermore, the RTAB-enhanced DS-ViT pipeline achieved a 70% overall prediction accuracy, with an accuracy of 86% for high-confidence samples, indicating not only enhanced diagnostic accuracy but also the potential for asymptomatic stage intervention in high-risk patients.</p>
</div>
<div class="ltx_para" id="S1.p11">
<p class="ltx_p" id="S1.p11.1">The contributions of this work are threefold: (1) We introduce the DS-ViT pipeline, which successfully integrates segmentation knowledge into a classification framework, (2) We demonstrate the effectiveness of the Dual-Stream Embedding and 3D Bottleneck MLP structure in enhancing model performance, and (3) We extend the model’s application to early diagnosis, offering a novel approach to predicting Alzheimer’s disease progression with clinically meaningful lead time.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="344" id="S1.F1.g1" src="extracted/5848706/trend.png" width="298"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>MRI scans illustrating the volumetric changes in the cerebral ventricle (highlighted in red) during the transition from Mild Cognitive Impairment (MCI) to Alzheimer’s Disease (AD) and Normal Case (NC). The progression from MCI to AD is characterized by a noticeable increase in ventricle size, while the reverse trend is observed in MCI to NC <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib3" title="">3</a>]</cite>. These structural alterations provide evidence of detectable early-stage biomarkers, supporting the feasibility of AI-driven early diagnosis of Alzheimer’s disease.
</figcaption>
</figure>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Related Works</span>
</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS1.4.1.1">II-A</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS1.5.2">Single Modality AD Diagnosis</span>
</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Single-modality approaches, particularly those utilizing Magnetic Resonance Imaging (MRI), have been extensively studied for Alzheimer’s Disease (AD) diagnosis. These methods focus on analyzing volumetric brain data to detect structural changes such as cortical atrophy and ventricular enlargement, which are hallmark features of AD <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib5" title="">5</a>]</cite>. Various deep learning models, including Uni4Eye, I3D, MedicalNet, 3D ResNet, and 3D DenseNet, have been developed to leverage MRI data for this purpose <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib14" title="">14</a>]</cite>. These models predominantly employ convolutional neural networks (CNNs) to capture spatial and temporal patterns in the brain, aiming to improve diagnostic accuracy and robustness.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">Despite the successes of these single-modality models, they often face limitations in fully capturing the complex and heterogeneous nature of AD, particularly when data is scarce or when subtle structural changes need to be detected early. The reliance solely on volumetric data may overlook critical contextual information that could enhance diagnosis. This has led to the exploration of multi-modality approaches, which integrate additional data sources—such as segmentation results or other imaging modalities—to improve performance.</p>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.1">The DS-ViT pipeline proposed in this work builds on these single-modality approaches by integrating segmentation knowledge from FastSurfer with traditional MRI-based classification. This integration aims to overcome some of the limitations of single-modality models, providing a more comprehensive and accurate diagnostic tool for AD, particularly in early-stage detection.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS2.4.1.1">II-B</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS2.5.2">Knowledge Distillation</span>
</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">In the field of visual AI, knowledge distillation methods are commonly employed to share knowledge between models, thereby enhancing the performance of the student model. Traditional knowledge distillation primarily relies on soft labels generated by the teacher model, which replace the conventional hard labels <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib8" title="">8</a>]</cite>. These soft labels reflect the probability distribution of each class as predicted by the teacher model, offering a more nuanced view than hard labels, which assign a binary classification. The student model learns from these soft labels to approximate the predictive capability of the teacher model. However, the fundamental differences between segmentation and classification tasks limit the applicability of traditional knowledge distillation methods. In segmentation tasks, the model’s output are pixel-level labels, whereas classification tasks focus on the label for the entire image. The differences in output format and task objectives make it difficult to apply soft label-based knowledge distillation directly to these tasks. Moreover, the challenge is exacerbated by the architectural differences between the teacher and student models. Common knowledge distillation variants, such as hint layer distillation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib15" title="">15</a>]</cite> and structural model distillation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib16" title="">16</a>]</cite>, usually assume a certain level of similarity in feature representation between the teacher and student models. In our task, this challenge is intensified by the distinct architectures of the teacher and student models (CNN and Transformer), making cross-task knowledge distillation even more complex.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">In this work, we address these limitations of traditional knowledge distillation by proposing the DS-ViT pipeline. Our approach achieves cross-task and cross-architecture knowledge sharing, breaking down the barriers between different tasks and model architectures.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS3.4.1.1">II-C</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS3.5.2">FastSurfer</span>
</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">In scenarios where training data is limited, leveraging knowledge from models trained on large-scale datasets can significantly enhance training efficiency and performance. FastSurfer, an extensively validated deep-learning pipeline, is designed for the fully automated processing of structural human brain MRIs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib6" title="">6</a>]</cite>. This pipeline is known for its robust performance and speed, processing each MRI scan in less than one minute. FastSurfer excels in two main areas: detailed brain segmentation and surface reconstruction.</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1">The brain segmentation component of FastSurfer is particularly noteworthy due to its precision. It divides the brain into 95 distinct anatomical regions, a level of detail that surpasses many other segmentation tools. This granularity is crucial for research and clinical applications, as understanding the structure and function of different brain areas is essential. FastSurfer’s segmentation results have been extensively validated against established neuroimaging protocols, demonstrating high accuracy and reliability across diverse datasets.</p>
</div>
<div class="ltx_para" id="S2.SS3.p3">
<p class="ltx_p" id="S2.SS3.p3.1">We believe that the detailed segmentation provided by FastSurfer is exceptionally well-suited to guide Alzheimer’s disease early diagnosis. Understanding the intricate differences between various brain regions is a critical prerequisite for accurate diagnosis. By incorporating FastSurfer’s segmentation outputs into our diagnostic pipeline, we can enrich the student model’s training with refined anatomical knowledge, thereby improving its predictive performance on smaller, disease-specific datasets.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S2.SS4.4.1.1">II-D</span> </span><span class="ltx_text ltx_font_italic" id="S2.SS4.5.2">ADAPT</span>
</h3>
<div class="ltx_para" id="S2.SS4.p1">
<p class="ltx_p" id="S2.SS4.p1.1">In our previous work, we developed Alzheimer’s Diagnosis through Adaptive Profiling Transformers (ADAPT), which efficiently detects Alzheimer’s disease by converting 3D brain MRIs into 2D slices along different planes (axial, coronal, and sagittal) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib7" title="">7</a>]</cite>. Using dimension-specific self-attention and cross-attention mechanisms, ADAPT captures critical spatial relationships within the data. Despite its small parameter size, ADAPT demonstrated exceptional performance in Alzheimer’s diagnosis, outperforming several state-of-the-art 3D image classification models, including MedicalNet and 3D DenseNet across various datasets.</p>
</div>
<div class="ltx_para" id="S2.SS4.p2">
<p class="ltx_p" id="S2.SS4.p2.1">In this work, we build upon ADAPT by integrating FastSurfer’s detailed brain segmentation knowledge, enhancing performance, especially with limited training data. This integration allows ADAPT to utilize anatomical insights crucial for early Alzheimer’s diagnosis, improving accuracy and extending the model’s applicability to more complex diagnostic tasks. Notably, the proposed enhancements are adaptable to other Transformer-based feature extractors, such as 3D Vision Transformer. This adaptability offers broader applicability in medical image analysis.</p>
</div>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="137" id="S2.F2.g1" src="extracted/5848706/DS-ViT.png" width="479"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The process starts with generating segmentation results from 3D MRI images using FastSurfer. These images and their segmentation maps are sliced along three orthogonal planes. Stream 1 processes pixel-based image data, while Stream 2 handles token-like embeddings from the segmentation results. The embedded features from both streams are integrated using separate trainable MLP modules across three dimensions, then concatenated into a comprehensive feature matrix. The matrix serves as the input to the AD diagnosis model, i.e. ADAPT in our setup, which performs feature extraction and diagnosis.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">Methods</span>
</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">DS-ViT is a 3D image classification pipeline built upon ADAPT, a baseline model known for its strong performance in small parameter size. Unlike conventional biomedical imaging models that rely solely on pathological images as input, DS-ViT is designed to process dual-stream inputs. One stream captures pixel-level information from the original MRI images, while the other incorporates segmentation results from FastSurfer. FastSurfer, a widely validated 3D MRI segmentation model trained on large-scale datasets, encodes extensive knowledge about brain regions that are crucial for the accurate diagnosis of Alzheimer’s disease. By leveraging FastSurfer as a teacher model, we aim to enhance the training efficiency and diagnostic accuracy of ADAPT in Alzheimer’s detection.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">Our approach consists of two main components. The first is the design of the DS-ViT structure, tailored for diagnosing Alzheimer’s disease from single 3D MRI images. The second component extends the functionality of DS-ViT by utilizing multiple time-point scans from the same patient to predict future disease risk. This extension enables the early detection and proactive treatment of Alzheimer’s disease, offering the possibility of earlier intervention for patients.</p>
</div>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="169" id="S3.F3.g1" src="extracted/5848706/ED.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The overview of the pipeline for DS-ViT + RTAB for Alzheimer’s Early Diagnosis. DS-ViT extracts high-dimensional feature maps from MRI scans at different time points. Residuals are computed between consecutive feature maps and fused with the current map to create residual fusion features. These features are aggregated by the Residual Temporal Attention Block (RTAB) to assess the risk of Alzheimer’s disease progression, outputting “At Risk” or “Safe” classifications for early intervention.</figcaption>
</figure>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS1.4.1.1">III-A</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS1.5.2">DS-ViT Pipeline</span>
</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">As shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#S2.F2" title="Figure 2 ‣ II-D ADAPT ‣ II Related Works ‣ DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis"><span class="ltx_text ltx_ref_tag">2</span></a>, we first process the 3D MRI images using FastSurfer to obtain segmentation results that contain detailed brain region information. The original MRI images and the corresponding segmentation maps are then sliced along three orthogonal planes, and embedded with the dual-stream embedding module, which will be detailed in section <a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#S3.SS1.SSS1" title="III-A1 Dual-Stream Embedding ‣ III-A DS-ViT Pipeline ‣ III Methods ‣ DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-A</span>1</span></a>. The resulting embedding vectors from both streams, across the three dimensions, are then integrated through three trainable MLP modules. These integrated features are concatenated to form the input for ADAPT, which subsequently learns from this fused matrix and make predictions.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S3.SS1.SSS1.4.1.1">III-A</span>1 </span>Dual-Stream Embedding</h4>
<div class="ltx_para" id="S3.SS1.SSS1.p1">
<p class="ltx_p" id="S3.SS1.SSS1.p1.1">Since ADAPT operates by slicing 3D MRI images along three orthogonal planes and then embedding and concatenating the slices, our Dual-Stream Embedding is essentially embedding these 2D slices.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS1.p2">
<p class="ltx_p" id="S3.SS1.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.SSS1.p2.1.1">Stream 1: Pixel-based Patch Embedding for MRI Images
<br class="ltx_break"/></span>This step is based on the traditional ViT approach to image embedding. The image is first divided into fixed-size patches. Each patch undergoes convolutional operations to extract features and resize them to a fixed dimension, which are then merged. To preserve spatial information, positional embeddings are added to each patch’s feature matrix, ensuring that the positional context is maintained during the embedding process.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS1.p3">
<p class="ltx_p" id="S3.SS1.SSS1.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.SSS1.p3.1.1">Stream 2: Token-like Patch Embedding for Segmentation Results
<br class="ltx_break"/></span>Unlike MRI images, where pixel values are continuous, segmentation results contain discrete class labels representing different brain regions. We have tested and proved that applying convolutional operations directly to these segmentation maps can lead to significant issues, where pixel-based patch embeddings proved ineffective. Recognizing the categorical nature of segmentation data, we treat each brain region label as a unique token, similar to tokens in Natural Language Processing (NLP).</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS1.p4">
<p class="ltx_p" id="S3.SS1.SSS1.p4.6">For each patch <math alttext="\mathbf{S}_{p}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p4.1.m1.1"><semantics id="S3.SS1.SSS1.p4.1.m1.1a"><msub id="S3.SS1.SSS1.p4.1.m1.1.1" xref="S3.SS1.SSS1.p4.1.m1.1.1.cmml"><mi id="S3.SS1.SSS1.p4.1.m1.1.1.2" xref="S3.SS1.SSS1.p4.1.m1.1.1.2.cmml">𝐒</mi><mi id="S3.SS1.SSS1.p4.1.m1.1.1.3" xref="S3.SS1.SSS1.p4.1.m1.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p4.1.m1.1b"><apply id="S3.SS1.SSS1.p4.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p4.1.m1.1.1.1.cmml" xref="S3.SS1.SSS1.p4.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p4.1.m1.1.1.2.cmml" xref="S3.SS1.SSS1.p4.1.m1.1.1.2">𝐒</ci><ci id="S3.SS1.SSS1.p4.1.m1.1.1.3.cmml" xref="S3.SS1.SSS1.p4.1.m1.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p4.1.m1.1c">\mathbf{S}_{p}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p4.1.m1.1d">bold_S start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math> in the segmentation map, let each pixel <math alttext="s_{i}\in\mathbf{S}_{p}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p4.2.m2.1"><semantics id="S3.SS1.SSS1.p4.2.m2.1a"><mrow id="S3.SS1.SSS1.p4.2.m2.1.1" xref="S3.SS1.SSS1.p4.2.m2.1.1.cmml"><msub id="S3.SS1.SSS1.p4.2.m2.1.1.2" xref="S3.SS1.SSS1.p4.2.m2.1.1.2.cmml"><mi id="S3.SS1.SSS1.p4.2.m2.1.1.2.2" xref="S3.SS1.SSS1.p4.2.m2.1.1.2.2.cmml">s</mi><mi id="S3.SS1.SSS1.p4.2.m2.1.1.2.3" xref="S3.SS1.SSS1.p4.2.m2.1.1.2.3.cmml">i</mi></msub><mo id="S3.SS1.SSS1.p4.2.m2.1.1.1" xref="S3.SS1.SSS1.p4.2.m2.1.1.1.cmml">∈</mo><msub id="S3.SS1.SSS1.p4.2.m2.1.1.3" xref="S3.SS1.SSS1.p4.2.m2.1.1.3.cmml"><mi id="S3.SS1.SSS1.p4.2.m2.1.1.3.2" xref="S3.SS1.SSS1.p4.2.m2.1.1.3.2.cmml">𝐒</mi><mi id="S3.SS1.SSS1.p4.2.m2.1.1.3.3" xref="S3.SS1.SSS1.p4.2.m2.1.1.3.3.cmml">p</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p4.2.m2.1b"><apply id="S3.SS1.SSS1.p4.2.m2.1.1.cmml" xref="S3.SS1.SSS1.p4.2.m2.1.1"><in id="S3.SS1.SSS1.p4.2.m2.1.1.1.cmml" xref="S3.SS1.SSS1.p4.2.m2.1.1.1"></in><apply id="S3.SS1.SSS1.p4.2.m2.1.1.2.cmml" xref="S3.SS1.SSS1.p4.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p4.2.m2.1.1.2.1.cmml" xref="S3.SS1.SSS1.p4.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS1.p4.2.m2.1.1.2.2.cmml" xref="S3.SS1.SSS1.p4.2.m2.1.1.2.2">𝑠</ci><ci id="S3.SS1.SSS1.p4.2.m2.1.1.2.3.cmml" xref="S3.SS1.SSS1.p4.2.m2.1.1.2.3">𝑖</ci></apply><apply id="S3.SS1.SSS1.p4.2.m2.1.1.3.cmml" xref="S3.SS1.SSS1.p4.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p4.2.m2.1.1.3.1.cmml" xref="S3.SS1.SSS1.p4.2.m2.1.1.3">subscript</csymbol><ci id="S3.SS1.SSS1.p4.2.m2.1.1.3.2.cmml" xref="S3.SS1.SSS1.p4.2.m2.1.1.3.2">𝐒</ci><ci id="S3.SS1.SSS1.p4.2.m2.1.1.3.3.cmml" xref="S3.SS1.SSS1.p4.2.m2.1.1.3.3">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p4.2.m2.1c">s_{i}\in\mathbf{S}_{p}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p4.2.m2.1d">italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ bold_S start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math> take a discrete value from a set of 95 classes, <math alttext="s_{i}\in\{1,2,\dots,95\}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p4.3.m3.4"><semantics id="S3.SS1.SSS1.p4.3.m3.4a"><mrow id="S3.SS1.SSS1.p4.3.m3.4.5" xref="S3.SS1.SSS1.p4.3.m3.4.5.cmml"><msub id="S3.SS1.SSS1.p4.3.m3.4.5.2" xref="S3.SS1.SSS1.p4.3.m3.4.5.2.cmml"><mi id="S3.SS1.SSS1.p4.3.m3.4.5.2.2" xref="S3.SS1.SSS1.p4.3.m3.4.5.2.2.cmml">s</mi><mi id="S3.SS1.SSS1.p4.3.m3.4.5.2.3" xref="S3.SS1.SSS1.p4.3.m3.4.5.2.3.cmml">i</mi></msub><mo id="S3.SS1.SSS1.p4.3.m3.4.5.1" xref="S3.SS1.SSS1.p4.3.m3.4.5.1.cmml">∈</mo><mrow id="S3.SS1.SSS1.p4.3.m3.4.5.3.2" xref="S3.SS1.SSS1.p4.3.m3.4.5.3.1.cmml"><mo id="S3.SS1.SSS1.p4.3.m3.4.5.3.2.1" stretchy="false" xref="S3.SS1.SSS1.p4.3.m3.4.5.3.1.cmml">{</mo><mn id="S3.SS1.SSS1.p4.3.m3.1.1" xref="S3.SS1.SSS1.p4.3.m3.1.1.cmml">1</mn><mo id="S3.SS1.SSS1.p4.3.m3.4.5.3.2.2" xref="S3.SS1.SSS1.p4.3.m3.4.5.3.1.cmml">,</mo><mn id="S3.SS1.SSS1.p4.3.m3.2.2" xref="S3.SS1.SSS1.p4.3.m3.2.2.cmml">2</mn><mo id="S3.SS1.SSS1.p4.3.m3.4.5.3.2.3" xref="S3.SS1.SSS1.p4.3.m3.4.5.3.1.cmml">,</mo><mi id="S3.SS1.SSS1.p4.3.m3.3.3" mathvariant="normal" xref="S3.SS1.SSS1.p4.3.m3.3.3.cmml">…</mi><mo id="S3.SS1.SSS1.p4.3.m3.4.5.3.2.4" xref="S3.SS1.SSS1.p4.3.m3.4.5.3.1.cmml">,</mo><mn id="S3.SS1.SSS1.p4.3.m3.4.4" xref="S3.SS1.SSS1.p4.3.m3.4.4.cmml">95</mn><mo id="S3.SS1.SSS1.p4.3.m3.4.5.3.2.5" stretchy="false" xref="S3.SS1.SSS1.p4.3.m3.4.5.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p4.3.m3.4b"><apply id="S3.SS1.SSS1.p4.3.m3.4.5.cmml" xref="S3.SS1.SSS1.p4.3.m3.4.5"><in id="S3.SS1.SSS1.p4.3.m3.4.5.1.cmml" xref="S3.SS1.SSS1.p4.3.m3.4.5.1"></in><apply id="S3.SS1.SSS1.p4.3.m3.4.5.2.cmml" xref="S3.SS1.SSS1.p4.3.m3.4.5.2"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p4.3.m3.4.5.2.1.cmml" xref="S3.SS1.SSS1.p4.3.m3.4.5.2">subscript</csymbol><ci id="S3.SS1.SSS1.p4.3.m3.4.5.2.2.cmml" xref="S3.SS1.SSS1.p4.3.m3.4.5.2.2">𝑠</ci><ci id="S3.SS1.SSS1.p4.3.m3.4.5.2.3.cmml" xref="S3.SS1.SSS1.p4.3.m3.4.5.2.3">𝑖</ci></apply><set id="S3.SS1.SSS1.p4.3.m3.4.5.3.1.cmml" xref="S3.SS1.SSS1.p4.3.m3.4.5.3.2"><cn id="S3.SS1.SSS1.p4.3.m3.1.1.cmml" type="integer" xref="S3.SS1.SSS1.p4.3.m3.1.1">1</cn><cn id="S3.SS1.SSS1.p4.3.m3.2.2.cmml" type="integer" xref="S3.SS1.SSS1.p4.3.m3.2.2">2</cn><ci id="S3.SS1.SSS1.p4.3.m3.3.3.cmml" xref="S3.SS1.SSS1.p4.3.m3.3.3">…</ci><cn id="S3.SS1.SSS1.p4.3.m3.4.4.cmml" type="integer" xref="S3.SS1.SSS1.p4.3.m3.4.4">95</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p4.3.m3.4c">s_{i}\in\{1,2,\dots,95\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p4.3.m3.4d">italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ { 1 , 2 , … , 95 }</annotation></semantics></math>. Each class <math alttext="s_{i}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p4.4.m4.1"><semantics id="S3.SS1.SSS1.p4.4.m4.1a"><msub id="S3.SS1.SSS1.p4.4.m4.1.1" xref="S3.SS1.SSS1.p4.4.m4.1.1.cmml"><mi id="S3.SS1.SSS1.p4.4.m4.1.1.2" xref="S3.SS1.SSS1.p4.4.m4.1.1.2.cmml">s</mi><mi id="S3.SS1.SSS1.p4.4.m4.1.1.3" xref="S3.SS1.SSS1.p4.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p4.4.m4.1b"><apply id="S3.SS1.SSS1.p4.4.m4.1.1.cmml" xref="S3.SS1.SSS1.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p4.4.m4.1.1.1.cmml" xref="S3.SS1.SSS1.p4.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p4.4.m4.1.1.2.cmml" xref="S3.SS1.SSS1.p4.4.m4.1.1.2">𝑠</ci><ci id="S3.SS1.SSS1.p4.4.m4.1.1.3.cmml" xref="S3.SS1.SSS1.p4.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p4.4.m4.1c">s_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p4.4.m4.1d">italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is mapped to a learnable embedding vector <math alttext="\mathbf{e}_{i}\in\mathbb{R}^{D}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p4.5.m5.1"><semantics id="S3.SS1.SSS1.p4.5.m5.1a"><mrow id="S3.SS1.SSS1.p4.5.m5.1.1" xref="S3.SS1.SSS1.p4.5.m5.1.1.cmml"><msub id="S3.SS1.SSS1.p4.5.m5.1.1.2" xref="S3.SS1.SSS1.p4.5.m5.1.1.2.cmml"><mi id="S3.SS1.SSS1.p4.5.m5.1.1.2.2" xref="S3.SS1.SSS1.p4.5.m5.1.1.2.2.cmml">𝐞</mi><mi id="S3.SS1.SSS1.p4.5.m5.1.1.2.3" xref="S3.SS1.SSS1.p4.5.m5.1.1.2.3.cmml">i</mi></msub><mo id="S3.SS1.SSS1.p4.5.m5.1.1.1" xref="S3.SS1.SSS1.p4.5.m5.1.1.1.cmml">∈</mo><msup id="S3.SS1.SSS1.p4.5.m5.1.1.3" xref="S3.SS1.SSS1.p4.5.m5.1.1.3.cmml"><mi id="S3.SS1.SSS1.p4.5.m5.1.1.3.2" xref="S3.SS1.SSS1.p4.5.m5.1.1.3.2.cmml">ℝ</mi><mi id="S3.SS1.SSS1.p4.5.m5.1.1.3.3" xref="S3.SS1.SSS1.p4.5.m5.1.1.3.3.cmml">D</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p4.5.m5.1b"><apply id="S3.SS1.SSS1.p4.5.m5.1.1.cmml" xref="S3.SS1.SSS1.p4.5.m5.1.1"><in id="S3.SS1.SSS1.p4.5.m5.1.1.1.cmml" xref="S3.SS1.SSS1.p4.5.m5.1.1.1"></in><apply id="S3.SS1.SSS1.p4.5.m5.1.1.2.cmml" xref="S3.SS1.SSS1.p4.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p4.5.m5.1.1.2.1.cmml" xref="S3.SS1.SSS1.p4.5.m5.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS1.p4.5.m5.1.1.2.2.cmml" xref="S3.SS1.SSS1.p4.5.m5.1.1.2.2">𝐞</ci><ci id="S3.SS1.SSS1.p4.5.m5.1.1.2.3.cmml" xref="S3.SS1.SSS1.p4.5.m5.1.1.2.3">𝑖</ci></apply><apply id="S3.SS1.SSS1.p4.5.m5.1.1.3.cmml" xref="S3.SS1.SSS1.p4.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p4.5.m5.1.1.3.1.cmml" xref="S3.SS1.SSS1.p4.5.m5.1.1.3">superscript</csymbol><ci id="S3.SS1.SSS1.p4.5.m5.1.1.3.2.cmml" xref="S3.SS1.SSS1.p4.5.m5.1.1.3.2">ℝ</ci><ci id="S3.SS1.SSS1.p4.5.m5.1.1.3.3.cmml" xref="S3.SS1.SSS1.p4.5.m5.1.1.3.3">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p4.5.m5.1c">\mathbf{e}_{i}\in\mathbb{R}^{D}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p4.5.m5.1d">bold_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT</annotation></semantics></math> using an embedding matrix <math alttext="\mathbf{E}\in\mathbb{R}^{K\times D}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p4.6.m6.1"><semantics id="S3.SS1.SSS1.p4.6.m6.1a"><mrow id="S3.SS1.SSS1.p4.6.m6.1.1" xref="S3.SS1.SSS1.p4.6.m6.1.1.cmml"><mi id="S3.SS1.SSS1.p4.6.m6.1.1.2" xref="S3.SS1.SSS1.p4.6.m6.1.1.2.cmml">𝐄</mi><mo id="S3.SS1.SSS1.p4.6.m6.1.1.1" xref="S3.SS1.SSS1.p4.6.m6.1.1.1.cmml">∈</mo><msup id="S3.SS1.SSS1.p4.6.m6.1.1.3" xref="S3.SS1.SSS1.p4.6.m6.1.1.3.cmml"><mi id="S3.SS1.SSS1.p4.6.m6.1.1.3.2" xref="S3.SS1.SSS1.p4.6.m6.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS1.SSS1.p4.6.m6.1.1.3.3" xref="S3.SS1.SSS1.p4.6.m6.1.1.3.3.cmml"><mi id="S3.SS1.SSS1.p4.6.m6.1.1.3.3.2" xref="S3.SS1.SSS1.p4.6.m6.1.1.3.3.2.cmml">K</mi><mo id="S3.SS1.SSS1.p4.6.m6.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.SSS1.p4.6.m6.1.1.3.3.1.cmml">×</mo><mi id="S3.SS1.SSS1.p4.6.m6.1.1.3.3.3" xref="S3.SS1.SSS1.p4.6.m6.1.1.3.3.3.cmml">D</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p4.6.m6.1b"><apply id="S3.SS1.SSS1.p4.6.m6.1.1.cmml" xref="S3.SS1.SSS1.p4.6.m6.1.1"><in id="S3.SS1.SSS1.p4.6.m6.1.1.1.cmml" xref="S3.SS1.SSS1.p4.6.m6.1.1.1"></in><ci id="S3.SS1.SSS1.p4.6.m6.1.1.2.cmml" xref="S3.SS1.SSS1.p4.6.m6.1.1.2">𝐄</ci><apply id="S3.SS1.SSS1.p4.6.m6.1.1.3.cmml" xref="S3.SS1.SSS1.p4.6.m6.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p4.6.m6.1.1.3.1.cmml" xref="S3.SS1.SSS1.p4.6.m6.1.1.3">superscript</csymbol><ci id="S3.SS1.SSS1.p4.6.m6.1.1.3.2.cmml" xref="S3.SS1.SSS1.p4.6.m6.1.1.3.2">ℝ</ci><apply id="S3.SS1.SSS1.p4.6.m6.1.1.3.3.cmml" xref="S3.SS1.SSS1.p4.6.m6.1.1.3.3"><times id="S3.SS1.SSS1.p4.6.m6.1.1.3.3.1.cmml" xref="S3.SS1.SSS1.p4.6.m6.1.1.3.3.1"></times><ci id="S3.SS1.SSS1.p4.6.m6.1.1.3.3.2.cmml" xref="S3.SS1.SSS1.p4.6.m6.1.1.3.3.2">𝐾</ci><ci id="S3.SS1.SSS1.p4.6.m6.1.1.3.3.3.cmml" xref="S3.SS1.SSS1.p4.6.m6.1.1.3.3.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p4.6.m6.1c">\mathbf{E}\in\mathbb{R}^{K\times D}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p4.6.m6.1d">bold_E ∈ blackboard_R start_POSTSUPERSCRIPT italic_K × italic_D end_POSTSUPERSCRIPT</annotation></semantics></math>:</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS1.p5">
<table class="ltx_equation ltx_eqn_table" id="S3.Ex1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathbf{z}_{i}=\mathbf{E}[s_{i}]" class="ltx_Math" display="block" id="S3.Ex1.m1.1"><semantics id="S3.Ex1.m1.1a"><mrow id="S3.Ex1.m1.1.1" xref="S3.Ex1.m1.1.1.cmml"><msub id="S3.Ex1.m1.1.1.3" xref="S3.Ex1.m1.1.1.3.cmml"><mi id="S3.Ex1.m1.1.1.3.2" xref="S3.Ex1.m1.1.1.3.2.cmml">𝐳</mi><mi id="S3.Ex1.m1.1.1.3.3" xref="S3.Ex1.m1.1.1.3.3.cmml">i</mi></msub><mo id="S3.Ex1.m1.1.1.2" xref="S3.Ex1.m1.1.1.2.cmml">=</mo><mrow id="S3.Ex1.m1.1.1.1" xref="S3.Ex1.m1.1.1.1.cmml"><mi id="S3.Ex1.m1.1.1.1.3" xref="S3.Ex1.m1.1.1.1.3.cmml">𝐄</mi><mo id="S3.Ex1.m1.1.1.1.2" xref="S3.Ex1.m1.1.1.1.2.cmml">⁢</mo><mrow id="S3.Ex1.m1.1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.2.cmml"><mo id="S3.Ex1.m1.1.1.1.1.1.2" stretchy="false" xref="S3.Ex1.m1.1.1.1.1.2.1.cmml">[</mo><msub id="S3.Ex1.m1.1.1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.1.1.cmml"><mi id="S3.Ex1.m1.1.1.1.1.1.1.2" xref="S3.Ex1.m1.1.1.1.1.1.1.2.cmml">s</mi><mi id="S3.Ex1.m1.1.1.1.1.1.1.3" xref="S3.Ex1.m1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.Ex1.m1.1.1.1.1.1.3" stretchy="false" xref="S3.Ex1.m1.1.1.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex1.m1.1b"><apply id="S3.Ex1.m1.1.1.cmml" xref="S3.Ex1.m1.1.1"><eq id="S3.Ex1.m1.1.1.2.cmml" xref="S3.Ex1.m1.1.1.2"></eq><apply id="S3.Ex1.m1.1.1.3.cmml" xref="S3.Ex1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.3.1.cmml" xref="S3.Ex1.m1.1.1.3">subscript</csymbol><ci id="S3.Ex1.m1.1.1.3.2.cmml" xref="S3.Ex1.m1.1.1.3.2">𝐳</ci><ci id="S3.Ex1.m1.1.1.3.3.cmml" xref="S3.Ex1.m1.1.1.3.3">𝑖</ci></apply><apply id="S3.Ex1.m1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1"><times id="S3.Ex1.m1.1.1.1.2.cmml" xref="S3.Ex1.m1.1.1.1.2"></times><ci id="S3.Ex1.m1.1.1.1.3.cmml" xref="S3.Ex1.m1.1.1.1.3">𝐄</ci><apply id="S3.Ex1.m1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S3.Ex1.m1.1.1.1.1.2.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S3.Ex1.m1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.Ex1.m1.1.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.2">𝑠</ci><ci id="S3.Ex1.m1.1.1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex1.m1.1c">\mathbf{z}_{i}=\mathbf{E}[s_{i}]</annotation><annotation encoding="application/x-llamapun" id="S3.Ex1.m1.1d">bold_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = bold_E [ italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS1.SSS1.p6">
<p class="ltx_p" id="S3.SS1.SSS1.p6.2">where <math alttext="\mathbf{z}_{i}\in\mathbb{R}^{D}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p6.1.m1.1"><semantics id="S3.SS1.SSS1.p6.1.m1.1a"><mrow id="S3.SS1.SSS1.p6.1.m1.1.1" xref="S3.SS1.SSS1.p6.1.m1.1.1.cmml"><msub id="S3.SS1.SSS1.p6.1.m1.1.1.2" xref="S3.SS1.SSS1.p6.1.m1.1.1.2.cmml"><mi id="S3.SS1.SSS1.p6.1.m1.1.1.2.2" xref="S3.SS1.SSS1.p6.1.m1.1.1.2.2.cmml">𝐳</mi><mi id="S3.SS1.SSS1.p6.1.m1.1.1.2.3" xref="S3.SS1.SSS1.p6.1.m1.1.1.2.3.cmml">i</mi></msub><mo id="S3.SS1.SSS1.p6.1.m1.1.1.1" xref="S3.SS1.SSS1.p6.1.m1.1.1.1.cmml">∈</mo><msup id="S3.SS1.SSS1.p6.1.m1.1.1.3" xref="S3.SS1.SSS1.p6.1.m1.1.1.3.cmml"><mi id="S3.SS1.SSS1.p6.1.m1.1.1.3.2" xref="S3.SS1.SSS1.p6.1.m1.1.1.3.2.cmml">ℝ</mi><mi id="S3.SS1.SSS1.p6.1.m1.1.1.3.3" xref="S3.SS1.SSS1.p6.1.m1.1.1.3.3.cmml">D</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p6.1.m1.1b"><apply id="S3.SS1.SSS1.p6.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p6.1.m1.1.1"><in id="S3.SS1.SSS1.p6.1.m1.1.1.1.cmml" xref="S3.SS1.SSS1.p6.1.m1.1.1.1"></in><apply id="S3.SS1.SSS1.p6.1.m1.1.1.2.cmml" xref="S3.SS1.SSS1.p6.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p6.1.m1.1.1.2.1.cmml" xref="S3.SS1.SSS1.p6.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS1.p6.1.m1.1.1.2.2.cmml" xref="S3.SS1.SSS1.p6.1.m1.1.1.2.2">𝐳</ci><ci id="S3.SS1.SSS1.p6.1.m1.1.1.2.3.cmml" xref="S3.SS1.SSS1.p6.1.m1.1.1.2.3">𝑖</ci></apply><apply id="S3.SS1.SSS1.p6.1.m1.1.1.3.cmml" xref="S3.SS1.SSS1.p6.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p6.1.m1.1.1.3.1.cmml" xref="S3.SS1.SSS1.p6.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS1.SSS1.p6.1.m1.1.1.3.2.cmml" xref="S3.SS1.SSS1.p6.1.m1.1.1.3.2">ℝ</ci><ci id="S3.SS1.SSS1.p6.1.m1.1.1.3.3.cmml" xref="S3.SS1.SSS1.p6.1.m1.1.1.3.3">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p6.1.m1.1c">\mathbf{z}_{i}\in\mathbb{R}^{D}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p6.1.m1.1d">bold_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT</annotation></semantics></math> is the embedding vector for the pixel <math alttext="s_{i}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p6.2.m2.1"><semantics id="S3.SS1.SSS1.p6.2.m2.1a"><msub id="S3.SS1.SSS1.p6.2.m2.1.1" xref="S3.SS1.SSS1.p6.2.m2.1.1.cmml"><mi id="S3.SS1.SSS1.p6.2.m2.1.1.2" xref="S3.SS1.SSS1.p6.2.m2.1.1.2.cmml">s</mi><mi id="S3.SS1.SSS1.p6.2.m2.1.1.3" xref="S3.SS1.SSS1.p6.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p6.2.m2.1b"><apply id="S3.SS1.SSS1.p6.2.m2.1.1.cmml" xref="S3.SS1.SSS1.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p6.2.m2.1.1.1.cmml" xref="S3.SS1.SSS1.p6.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p6.2.m2.1.1.2.cmml" xref="S3.SS1.SSS1.p6.2.m2.1.1.2">𝑠</ci><ci id="S3.SS1.SSS1.p6.2.m2.1.1.3.cmml" xref="S3.SS1.SSS1.p6.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p6.2.m2.1c">s_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p6.2.m2.1d">italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS1.p7">
<p class="ltx_p" id="S3.SS1.SSS1.p7.1">To obtain the feature representation for the entire patch <math alttext="\mathbf{S}_{p}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p7.1.m1.1"><semantics id="S3.SS1.SSS1.p7.1.m1.1a"><msub id="S3.SS1.SSS1.p7.1.m1.1.1" xref="S3.SS1.SSS1.p7.1.m1.1.1.cmml"><mi id="S3.SS1.SSS1.p7.1.m1.1.1.2" xref="S3.SS1.SSS1.p7.1.m1.1.1.2.cmml">𝐒</mi><mi id="S3.SS1.SSS1.p7.1.m1.1.1.3" xref="S3.SS1.SSS1.p7.1.m1.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p7.1.m1.1b"><apply id="S3.SS1.SSS1.p7.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p7.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p7.1.m1.1.1.1.cmml" xref="S3.SS1.SSS1.p7.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p7.1.m1.1.1.2.cmml" xref="S3.SS1.SSS1.p7.1.m1.1.1.2">𝐒</ci><ci id="S3.SS1.SSS1.p7.1.m1.1.1.3.cmml" xref="S3.SS1.SSS1.p7.1.m1.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p7.1.m1.1c">\mathbf{S}_{p}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p7.1.m1.1d">bold_S start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math>, we first aggregate the embeddings of all pixels within the patch through feature concatenation and then apply average pooling:</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS1.p8">
<table class="ltx_equation ltx_eqn_table" id="S3.Ex2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathbf{z}_{p}=\frac{1}{|\mathbf{S}_{p}|}\sum_{i=1}^{|\mathbf{S}_{p}|}\mathbf{%
z}_{i}" class="ltx_Math" display="block" id="S3.Ex2.m1.2"><semantics id="S3.Ex2.m1.2a"><mrow id="S3.Ex2.m1.2.3" xref="S3.Ex2.m1.2.3.cmml"><msub id="S3.Ex2.m1.2.3.2" xref="S3.Ex2.m1.2.3.2.cmml"><mi id="S3.Ex2.m1.2.3.2.2" xref="S3.Ex2.m1.2.3.2.2.cmml">𝐳</mi><mi id="S3.Ex2.m1.2.3.2.3" xref="S3.Ex2.m1.2.3.2.3.cmml">p</mi></msub><mo id="S3.Ex2.m1.2.3.1" xref="S3.Ex2.m1.2.3.1.cmml">=</mo><mrow id="S3.Ex2.m1.2.3.3" xref="S3.Ex2.m1.2.3.3.cmml"><mfrac id="S3.Ex2.m1.1.1" xref="S3.Ex2.m1.1.1.cmml"><mn id="S3.Ex2.m1.1.1.3" xref="S3.Ex2.m1.1.1.3.cmml">1</mn><mrow id="S3.Ex2.m1.1.1.1.1" xref="S3.Ex2.m1.1.1.1.2.cmml"><mo id="S3.Ex2.m1.1.1.1.1.2" stretchy="false" xref="S3.Ex2.m1.1.1.1.2.1.cmml">|</mo><msub id="S3.Ex2.m1.1.1.1.1.1" xref="S3.Ex2.m1.1.1.1.1.1.cmml"><mi id="S3.Ex2.m1.1.1.1.1.1.2" xref="S3.Ex2.m1.1.1.1.1.1.2.cmml">𝐒</mi><mi id="S3.Ex2.m1.1.1.1.1.1.3" xref="S3.Ex2.m1.1.1.1.1.1.3.cmml">p</mi></msub><mo id="S3.Ex2.m1.1.1.1.1.3" stretchy="false" xref="S3.Ex2.m1.1.1.1.2.1.cmml">|</mo></mrow></mfrac><mo id="S3.Ex2.m1.2.3.3.1" xref="S3.Ex2.m1.2.3.3.1.cmml">⁢</mo><mrow id="S3.Ex2.m1.2.3.3.2" xref="S3.Ex2.m1.2.3.3.2.cmml"><munderover id="S3.Ex2.m1.2.3.3.2.1" xref="S3.Ex2.m1.2.3.3.2.1.cmml"><mo id="S3.Ex2.m1.2.3.3.2.1.2.2" movablelimits="false" xref="S3.Ex2.m1.2.3.3.2.1.2.2.cmml">∑</mo><mrow id="S3.Ex2.m1.2.3.3.2.1.2.3" xref="S3.Ex2.m1.2.3.3.2.1.2.3.cmml"><mi id="S3.Ex2.m1.2.3.3.2.1.2.3.2" xref="S3.Ex2.m1.2.3.3.2.1.2.3.2.cmml">i</mi><mo id="S3.Ex2.m1.2.3.3.2.1.2.3.1" xref="S3.Ex2.m1.2.3.3.2.1.2.3.1.cmml">=</mo><mn id="S3.Ex2.m1.2.3.3.2.1.2.3.3" xref="S3.Ex2.m1.2.3.3.2.1.2.3.3.cmml">1</mn></mrow><mrow id="S3.Ex2.m1.2.2.1.1" xref="S3.Ex2.m1.2.2.1.2.cmml"><mo id="S3.Ex2.m1.2.2.1.1.2" stretchy="false" xref="S3.Ex2.m1.2.2.1.2.1.cmml">|</mo><msub id="S3.Ex2.m1.2.2.1.1.1" xref="S3.Ex2.m1.2.2.1.1.1.cmml"><mi id="S3.Ex2.m1.2.2.1.1.1.2" xref="S3.Ex2.m1.2.2.1.1.1.2.cmml">𝐒</mi><mi id="S3.Ex2.m1.2.2.1.1.1.3" xref="S3.Ex2.m1.2.2.1.1.1.3.cmml">p</mi></msub><mo id="S3.Ex2.m1.2.2.1.1.3" stretchy="false" xref="S3.Ex2.m1.2.2.1.2.1.cmml">|</mo></mrow></munderover><msub id="S3.Ex2.m1.2.3.3.2.2" xref="S3.Ex2.m1.2.3.3.2.2.cmml"><mi id="S3.Ex2.m1.2.3.3.2.2.2" xref="S3.Ex2.m1.2.3.3.2.2.2.cmml">𝐳</mi><mi id="S3.Ex2.m1.2.3.3.2.2.3" xref="S3.Ex2.m1.2.3.3.2.2.3.cmml">i</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex2.m1.2b"><apply id="S3.Ex2.m1.2.3.cmml" xref="S3.Ex2.m1.2.3"><eq id="S3.Ex2.m1.2.3.1.cmml" xref="S3.Ex2.m1.2.3.1"></eq><apply id="S3.Ex2.m1.2.3.2.cmml" xref="S3.Ex2.m1.2.3.2"><csymbol cd="ambiguous" id="S3.Ex2.m1.2.3.2.1.cmml" xref="S3.Ex2.m1.2.3.2">subscript</csymbol><ci id="S3.Ex2.m1.2.3.2.2.cmml" xref="S3.Ex2.m1.2.3.2.2">𝐳</ci><ci id="S3.Ex2.m1.2.3.2.3.cmml" xref="S3.Ex2.m1.2.3.2.3">𝑝</ci></apply><apply id="S3.Ex2.m1.2.3.3.cmml" xref="S3.Ex2.m1.2.3.3"><times id="S3.Ex2.m1.2.3.3.1.cmml" xref="S3.Ex2.m1.2.3.3.1"></times><apply id="S3.Ex2.m1.1.1.cmml" xref="S3.Ex2.m1.1.1"><divide id="S3.Ex2.m1.1.1.2.cmml" xref="S3.Ex2.m1.1.1"></divide><cn id="S3.Ex2.m1.1.1.3.cmml" type="integer" xref="S3.Ex2.m1.1.1.3">1</cn><apply id="S3.Ex2.m1.1.1.1.2.cmml" xref="S3.Ex2.m1.1.1.1.1"><abs id="S3.Ex2.m1.1.1.1.2.1.cmml" xref="S3.Ex2.m1.1.1.1.1.2"></abs><apply id="S3.Ex2.m1.1.1.1.1.1.cmml" xref="S3.Ex2.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex2.m1.1.1.1.1.1.1.cmml" xref="S3.Ex2.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.Ex2.m1.1.1.1.1.1.2.cmml" xref="S3.Ex2.m1.1.1.1.1.1.2">𝐒</ci><ci id="S3.Ex2.m1.1.1.1.1.1.3.cmml" xref="S3.Ex2.m1.1.1.1.1.1.3">𝑝</ci></apply></apply></apply><apply id="S3.Ex2.m1.2.3.3.2.cmml" xref="S3.Ex2.m1.2.3.3.2"><apply id="S3.Ex2.m1.2.3.3.2.1.cmml" xref="S3.Ex2.m1.2.3.3.2.1"><csymbol cd="ambiguous" id="S3.Ex2.m1.2.3.3.2.1.1.cmml" xref="S3.Ex2.m1.2.3.3.2.1">superscript</csymbol><apply id="S3.Ex2.m1.2.3.3.2.1.2.cmml" xref="S3.Ex2.m1.2.3.3.2.1"><csymbol cd="ambiguous" id="S3.Ex2.m1.2.3.3.2.1.2.1.cmml" xref="S3.Ex2.m1.2.3.3.2.1">subscript</csymbol><sum id="S3.Ex2.m1.2.3.3.2.1.2.2.cmml" xref="S3.Ex2.m1.2.3.3.2.1.2.2"></sum><apply id="S3.Ex2.m1.2.3.3.2.1.2.3.cmml" xref="S3.Ex2.m1.2.3.3.2.1.2.3"><eq id="S3.Ex2.m1.2.3.3.2.1.2.3.1.cmml" xref="S3.Ex2.m1.2.3.3.2.1.2.3.1"></eq><ci id="S3.Ex2.m1.2.3.3.2.1.2.3.2.cmml" xref="S3.Ex2.m1.2.3.3.2.1.2.3.2">𝑖</ci><cn id="S3.Ex2.m1.2.3.3.2.1.2.3.3.cmml" type="integer" xref="S3.Ex2.m1.2.3.3.2.1.2.3.3">1</cn></apply></apply><apply id="S3.Ex2.m1.2.2.1.2.cmml" xref="S3.Ex2.m1.2.2.1.1"><abs id="S3.Ex2.m1.2.2.1.2.1.cmml" xref="S3.Ex2.m1.2.2.1.1.2"></abs><apply id="S3.Ex2.m1.2.2.1.1.1.cmml" xref="S3.Ex2.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.Ex2.m1.2.2.1.1.1.1.cmml" xref="S3.Ex2.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.Ex2.m1.2.2.1.1.1.2.cmml" xref="S3.Ex2.m1.2.2.1.1.1.2">𝐒</ci><ci id="S3.Ex2.m1.2.2.1.1.1.3.cmml" xref="S3.Ex2.m1.2.2.1.1.1.3">𝑝</ci></apply></apply></apply><apply id="S3.Ex2.m1.2.3.3.2.2.cmml" xref="S3.Ex2.m1.2.3.3.2.2"><csymbol cd="ambiguous" id="S3.Ex2.m1.2.3.3.2.2.1.cmml" xref="S3.Ex2.m1.2.3.3.2.2">subscript</csymbol><ci id="S3.Ex2.m1.2.3.3.2.2.2.cmml" xref="S3.Ex2.m1.2.3.3.2.2.2">𝐳</ci><ci id="S3.Ex2.m1.2.3.3.2.2.3.cmml" xref="S3.Ex2.m1.2.3.3.2.2.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex2.m1.2c">\mathbf{z}_{p}=\frac{1}{|\mathbf{S}_{p}|}\sum_{i=1}^{|\mathbf{S}_{p}|}\mathbf{%
z}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.Ex2.m1.2d">bold_z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG | bold_S start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT | end_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT | bold_S start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT | end_POSTSUPERSCRIPT bold_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS1.SSS1.p9">
<p class="ltx_p" id="S3.SS1.SSS1.p9.2">where <math alttext="|\mathbf{S}_{p}|" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p9.1.m1.1"><semantics id="S3.SS1.SSS1.p9.1.m1.1a"><mrow id="S3.SS1.SSS1.p9.1.m1.1.1.1" xref="S3.SS1.SSS1.p9.1.m1.1.1.2.cmml"><mo id="S3.SS1.SSS1.p9.1.m1.1.1.1.2" stretchy="false" xref="S3.SS1.SSS1.p9.1.m1.1.1.2.1.cmml">|</mo><msub id="S3.SS1.SSS1.p9.1.m1.1.1.1.1" xref="S3.SS1.SSS1.p9.1.m1.1.1.1.1.cmml"><mi id="S3.SS1.SSS1.p9.1.m1.1.1.1.1.2" xref="S3.SS1.SSS1.p9.1.m1.1.1.1.1.2.cmml">𝐒</mi><mi id="S3.SS1.SSS1.p9.1.m1.1.1.1.1.3" xref="S3.SS1.SSS1.p9.1.m1.1.1.1.1.3.cmml">p</mi></msub><mo id="S3.SS1.SSS1.p9.1.m1.1.1.1.3" stretchy="false" xref="S3.SS1.SSS1.p9.1.m1.1.1.2.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p9.1.m1.1b"><apply id="S3.SS1.SSS1.p9.1.m1.1.1.2.cmml" xref="S3.SS1.SSS1.p9.1.m1.1.1.1"><abs id="S3.SS1.SSS1.p9.1.m1.1.1.2.1.cmml" xref="S3.SS1.SSS1.p9.1.m1.1.1.1.2"></abs><apply id="S3.SS1.SSS1.p9.1.m1.1.1.1.1.cmml" xref="S3.SS1.SSS1.p9.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p9.1.m1.1.1.1.1.1.cmml" xref="S3.SS1.SSS1.p9.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p9.1.m1.1.1.1.1.2.cmml" xref="S3.SS1.SSS1.p9.1.m1.1.1.1.1.2">𝐒</ci><ci id="S3.SS1.SSS1.p9.1.m1.1.1.1.1.3.cmml" xref="S3.SS1.SSS1.p9.1.m1.1.1.1.1.3">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p9.1.m1.1c">|\mathbf{S}_{p}|</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p9.1.m1.1d">| bold_S start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT |</annotation></semantics></math> is the number of pixels in the patch. The resulting <math alttext="\mathbf{z}_{p}\in\mathbb{R}^{D}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p9.2.m2.1"><semantics id="S3.SS1.SSS1.p9.2.m2.1a"><mrow id="S3.SS1.SSS1.p9.2.m2.1.1" xref="S3.SS1.SSS1.p9.2.m2.1.1.cmml"><msub id="S3.SS1.SSS1.p9.2.m2.1.1.2" xref="S3.SS1.SSS1.p9.2.m2.1.1.2.cmml"><mi id="S3.SS1.SSS1.p9.2.m2.1.1.2.2" xref="S3.SS1.SSS1.p9.2.m2.1.1.2.2.cmml">𝐳</mi><mi id="S3.SS1.SSS1.p9.2.m2.1.1.2.3" xref="S3.SS1.SSS1.p9.2.m2.1.1.2.3.cmml">p</mi></msub><mo id="S3.SS1.SSS1.p9.2.m2.1.1.1" xref="S3.SS1.SSS1.p9.2.m2.1.1.1.cmml">∈</mo><msup id="S3.SS1.SSS1.p9.2.m2.1.1.3" xref="S3.SS1.SSS1.p9.2.m2.1.1.3.cmml"><mi id="S3.SS1.SSS1.p9.2.m2.1.1.3.2" xref="S3.SS1.SSS1.p9.2.m2.1.1.3.2.cmml">ℝ</mi><mi id="S3.SS1.SSS1.p9.2.m2.1.1.3.3" xref="S3.SS1.SSS1.p9.2.m2.1.1.3.3.cmml">D</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p9.2.m2.1b"><apply id="S3.SS1.SSS1.p9.2.m2.1.1.cmml" xref="S3.SS1.SSS1.p9.2.m2.1.1"><in id="S3.SS1.SSS1.p9.2.m2.1.1.1.cmml" xref="S3.SS1.SSS1.p9.2.m2.1.1.1"></in><apply id="S3.SS1.SSS1.p9.2.m2.1.1.2.cmml" xref="S3.SS1.SSS1.p9.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p9.2.m2.1.1.2.1.cmml" xref="S3.SS1.SSS1.p9.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS1.p9.2.m2.1.1.2.2.cmml" xref="S3.SS1.SSS1.p9.2.m2.1.1.2.2">𝐳</ci><ci id="S3.SS1.SSS1.p9.2.m2.1.1.2.3.cmml" xref="S3.SS1.SSS1.p9.2.m2.1.1.2.3">𝑝</ci></apply><apply id="S3.SS1.SSS1.p9.2.m2.1.1.3.cmml" xref="S3.SS1.SSS1.p9.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p9.2.m2.1.1.3.1.cmml" xref="S3.SS1.SSS1.p9.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS1.SSS1.p9.2.m2.1.1.3.2.cmml" xref="S3.SS1.SSS1.p9.2.m2.1.1.3.2">ℝ</ci><ci id="S3.SS1.SSS1.p9.2.m2.1.1.3.3.cmml" xref="S3.SS1.SSS1.p9.2.m2.1.1.3.3">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p9.2.m2.1c">\mathbf{z}_{p}\in\mathbb{R}^{D}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p9.2.m2.1d">bold_z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT</annotation></semantics></math> represents the token-like embedding vector for the patch.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS1.p10">
<p class="ltx_p" id="S3.SS1.SSS1.p10.1">To maintain the effectiveness and consistency of positional information, the same patch division mechanism is used as in the pixel-based embedding, and positional embeddings are shared with those used for the MRI images. This ensures that spatial context is preserved across both streams.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S3.SS1.SSS2.4.1.1">III-A</span>2 </span>3D Feature Integration</h4>
<div class="ltx_para" id="S3.SS1.SSS2.p1">
<p class="ltx_p" id="S3.SS1.SSS2.p1.1">To effectively fuse the features from the two streams, we employ a trainable Bottleneck MLP structure. This structure consists of multiple fully connected layers, which first reduce the dimensionality of the features and then restore them to a specified size. Given that ADAPT processes slices from three orthogonal dimensions independently, and considering the significant differences between slices from different orientations, we initialize a separate MLP module for each dimension. This approach ensures the independent training of MLPs across the three dimensions, preserving the distinct characteristics of each slice orientation.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS2.p2">
<p class="ltx_p" id="S3.SS1.SSS2.p2.1">After the features are integrated within each dimension, they are concatenated along the three dimensions to form a complete feature matrix. This fused matrix serves as the input to the ADAPT encoder, where ADAPT completes the subsequent high-dimensional feature extraction and classification tasks.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS2.4.1.1">III-B</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS2.5.2">Extension: Early Diagnosis of Alzheimer’s Disease</span>
</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">The basic DS-ViT Pipeline is designed to diagnose whether a patient is already afflicted with Alzheimer’s disease, meaning that diagnosis only occurs once the disease is present, offering no possibility for early intervention. To extend the application of our work and provide greater benefits to patients, we have enhanced DS-ViT with a Residual Temporal Attention Mechanism. This addition enables our method to predict future disease risk based on a series of early MRI images from a patient, thus allowing for the possibility of preventive measures and earlier intervention.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS3.4.1.1">III-C</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS3.5.2">DS-ViT for Early Diagnosis Pipeline</span>
</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.7">In the Early Diagnosis process, we retain most of the DS-ViT structure but replace the classification head with a Residual Temporal Attention Block (RTAB), as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#S3.F3" title="Figure 3 ‣ III Methods ‣ DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis"><span class="ltx_text ltx_ref_tag">3</span></a>. In this setup, DS-ViT functions as a feature extractor, processing multiple MRI images taken at different time points to generate a sequence of high-dimensional feature maps. Each feature map <math alttext="M_{t}" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><msub id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mi id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">M</mi><mi id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2">𝑀</ci><ci id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">M_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">italic_M start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> is subtracted from the feature map <math alttext="M_{t-1}" class="ltx_Math" display="inline" id="S3.SS3.p1.2.m2.1"><semantics id="S3.SS3.p1.2.m2.1a"><msub id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml"><mi id="S3.SS3.p1.2.m2.1.1.2" xref="S3.SS3.p1.2.m2.1.1.2.cmml">M</mi><mrow id="S3.SS3.p1.2.m2.1.1.3" xref="S3.SS3.p1.2.m2.1.1.3.cmml"><mi id="S3.SS3.p1.2.m2.1.1.3.2" xref="S3.SS3.p1.2.m2.1.1.3.2.cmml">t</mi><mo id="S3.SS3.p1.2.m2.1.1.3.1" xref="S3.SS3.p1.2.m2.1.1.3.1.cmml">−</mo><mn id="S3.SS3.p1.2.m2.1.1.3.3" xref="S3.SS3.p1.2.m2.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2">𝑀</ci><apply id="S3.SS3.p1.2.m2.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3"><minus id="S3.SS3.p1.2.m2.1.1.3.1.cmml" xref="S3.SS3.p1.2.m2.1.1.3.1"></minus><ci id="S3.SS3.p1.2.m2.1.1.3.2.cmml" xref="S3.SS3.p1.2.m2.1.1.3.2">𝑡</ci><cn id="S3.SS3.p1.2.m2.1.1.3.3.cmml" type="integer" xref="S3.SS3.p1.2.m2.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">M_{t-1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.2.m2.1d">italic_M start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT</annotation></semantics></math> from the previous time point to obtain the residual <math alttext="R_{t}" class="ltx_Math" display="inline" id="S3.SS3.p1.3.m3.1"><semantics id="S3.SS3.p1.3.m3.1a"><msub id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml"><mi id="S3.SS3.p1.3.m3.1.1.2" xref="S3.SS3.p1.3.m3.1.1.2.cmml">R</mi><mi id="S3.SS3.p1.3.m3.1.1.3" xref="S3.SS3.p1.3.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><apply id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m3.1.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p1.3.m3.1.1.2.cmml" xref="S3.SS3.p1.3.m3.1.1.2">𝑅</ci><ci id="S3.SS3.p1.3.m3.1.1.3.cmml" xref="S3.SS3.p1.3.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">R_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.3.m3.1d">italic_R start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>. This residual is then fused with <math alttext="M_{t}" class="ltx_Math" display="inline" id="S3.SS3.p1.4.m4.1"><semantics id="S3.SS3.p1.4.m4.1a"><msub id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml"><mi id="S3.SS3.p1.4.m4.1.1.2" xref="S3.SS3.p1.4.m4.1.1.2.cmml">M</mi><mi id="S3.SS3.p1.4.m4.1.1.3" xref="S3.SS3.p1.4.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><apply id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m4.1.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS3.p1.4.m4.1.1.2.cmml" xref="S3.SS3.p1.4.m4.1.1.2">𝑀</ci><ci id="S3.SS3.p1.4.m4.1.1.3.cmml" xref="S3.SS3.p1.4.m4.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">M_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.4.m4.1d">italic_M start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> through an MLP to produce the residual fusion feature <math alttext="M_{t}^{\prime}" class="ltx_Math" display="inline" id="S3.SS3.p1.5.m5.1"><semantics id="S3.SS3.p1.5.m5.1a"><msubsup id="S3.SS3.p1.5.m5.1.1" xref="S3.SS3.p1.5.m5.1.1.cmml"><mi id="S3.SS3.p1.5.m5.1.1.2.2" xref="S3.SS3.p1.5.m5.1.1.2.2.cmml">M</mi><mi id="S3.SS3.p1.5.m5.1.1.2.3" xref="S3.SS3.p1.5.m5.1.1.2.3.cmml">t</mi><mo id="S3.SS3.p1.5.m5.1.1.3" xref="S3.SS3.p1.5.m5.1.1.3.cmml">′</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m5.1b"><apply id="S3.SS3.p1.5.m5.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.5.m5.1.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1">superscript</csymbol><apply id="S3.SS3.p1.5.m5.1.1.2.cmml" xref="S3.SS3.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.5.m5.1.1.2.1.cmml" xref="S3.SS3.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS3.p1.5.m5.1.1.2.2.cmml" xref="S3.SS3.p1.5.m5.1.1.2.2">𝑀</ci><ci id="S3.SS3.p1.5.m5.1.1.2.3.cmml" xref="S3.SS3.p1.5.m5.1.1.2.3">𝑡</ci></apply><ci id="S3.SS3.p1.5.m5.1.1.3.cmml" xref="S3.SS3.p1.5.m5.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m5.1c">M_{t}^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.5.m5.1d">italic_M start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math>. For the earliest feature map <math alttext="M_{1}" class="ltx_Math" display="inline" id="S3.SS3.p1.6.m6.1"><semantics id="S3.SS3.p1.6.m6.1a"><msub id="S3.SS3.p1.6.m6.1.1" xref="S3.SS3.p1.6.m6.1.1.cmml"><mi id="S3.SS3.p1.6.m6.1.1.2" xref="S3.SS3.p1.6.m6.1.1.2.cmml">M</mi><mn id="S3.SS3.p1.6.m6.1.1.3" xref="S3.SS3.p1.6.m6.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.6.m6.1b"><apply id="S3.SS3.p1.6.m6.1.1.cmml" xref="S3.SS3.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.6.m6.1.1.1.cmml" xref="S3.SS3.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS3.p1.6.m6.1.1.2.cmml" xref="S3.SS3.p1.6.m6.1.1.2">𝑀</ci><cn id="S3.SS3.p1.6.m6.1.1.3.cmml" type="integer" xref="S3.SS3.p1.6.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.6.m6.1c">M_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.6.m6.1d">italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>, since there is no prior feature map to compute the residual, we define its residual fusion feature as itself, i.e., <math alttext="M_{1}^{\prime}=M_{1}" class="ltx_Math" display="inline" id="S3.SS3.p1.7.m7.1"><semantics id="S3.SS3.p1.7.m7.1a"><mrow id="S3.SS3.p1.7.m7.1.1" xref="S3.SS3.p1.7.m7.1.1.cmml"><msubsup id="S3.SS3.p1.7.m7.1.1.2" xref="S3.SS3.p1.7.m7.1.1.2.cmml"><mi id="S3.SS3.p1.7.m7.1.1.2.2.2" xref="S3.SS3.p1.7.m7.1.1.2.2.2.cmml">M</mi><mn id="S3.SS3.p1.7.m7.1.1.2.2.3" xref="S3.SS3.p1.7.m7.1.1.2.2.3.cmml">1</mn><mo id="S3.SS3.p1.7.m7.1.1.2.3" xref="S3.SS3.p1.7.m7.1.1.2.3.cmml">′</mo></msubsup><mo id="S3.SS3.p1.7.m7.1.1.1" xref="S3.SS3.p1.7.m7.1.1.1.cmml">=</mo><msub id="S3.SS3.p1.7.m7.1.1.3" xref="S3.SS3.p1.7.m7.1.1.3.cmml"><mi id="S3.SS3.p1.7.m7.1.1.3.2" xref="S3.SS3.p1.7.m7.1.1.3.2.cmml">M</mi><mn id="S3.SS3.p1.7.m7.1.1.3.3" xref="S3.SS3.p1.7.m7.1.1.3.3.cmml">1</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.7.m7.1b"><apply id="S3.SS3.p1.7.m7.1.1.cmml" xref="S3.SS3.p1.7.m7.1.1"><eq id="S3.SS3.p1.7.m7.1.1.1.cmml" xref="S3.SS3.p1.7.m7.1.1.1"></eq><apply id="S3.SS3.p1.7.m7.1.1.2.cmml" xref="S3.SS3.p1.7.m7.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p1.7.m7.1.1.2.1.cmml" xref="S3.SS3.p1.7.m7.1.1.2">superscript</csymbol><apply id="S3.SS3.p1.7.m7.1.1.2.2.cmml" xref="S3.SS3.p1.7.m7.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p1.7.m7.1.1.2.2.1.cmml" xref="S3.SS3.p1.7.m7.1.1.2">subscript</csymbol><ci id="S3.SS3.p1.7.m7.1.1.2.2.2.cmml" xref="S3.SS3.p1.7.m7.1.1.2.2.2">𝑀</ci><cn id="S3.SS3.p1.7.m7.1.1.2.2.3.cmml" type="integer" xref="S3.SS3.p1.7.m7.1.1.2.2.3">1</cn></apply><ci id="S3.SS3.p1.7.m7.1.1.2.3.cmml" xref="S3.SS3.p1.7.m7.1.1.2.3">′</ci></apply><apply id="S3.SS3.p1.7.m7.1.1.3.cmml" xref="S3.SS3.p1.7.m7.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p1.7.m7.1.1.3.1.cmml" xref="S3.SS3.p1.7.m7.1.1.3">subscript</csymbol><ci id="S3.SS3.p1.7.m7.1.1.3.2.cmml" xref="S3.SS3.p1.7.m7.1.1.3.2">𝑀</ci><cn id="S3.SS3.p1.7.m7.1.1.3.3.cmml" type="integer" xref="S3.SS3.p1.7.m7.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.7.m7.1c">M_{1}^{\prime}=M_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.7.m7.1d">italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>. These temporally sequenced residual fusion features are then input into the RTAB, which synthesizes the early features and trends to predict the risk of deterioration at a future examination time point.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Comparison of Models Across Data-Sufficient and Data-Scarce Scenarios</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S3.T1.1.1.1.1" rowspan="2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.1">Model Name</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4" id="S3.T1.1.1.1.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.2.1">Data-Sufficient Scenario</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S3.T1.1.1.1.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.3.1">Data-Scarce Scenario</span></th>
</tr>
<tr class="ltx_tr" id="S3.T1.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T1.1.2.2.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.2.2.1.1">ADNI (val)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T1.1.2.2.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.2.2.2.1">MIRIAD</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T1.1.2.2.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.2.2.3.1">AIBL</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T1.1.2.2.4" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.2.2.4.1">OASIS</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T1.1.2.2.5" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.2.2.5.1">MIRIAD (val)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T1.1.2.2.6" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.2.2.6.1">AIBL</span></th>
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S3.T1.1.2.2.7" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.2.2.7.1">OASIS</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T1.1.3.1.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.3.1.1.1">DS-ViT</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.3.1.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.3.1.2.1">0.933</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.3.1.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.3.1.3.1">0.941</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.3.1.4" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.3.1.4.1">0.914</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.3.1.5" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.3.1.5.1">0.859</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.3.1.6" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.3.1.6.1">0.899</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.3.1.7" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.3.1.7.1">0.892</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S3.T1.1.3.1.8" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.3.1.8.1">0.823</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.4.2.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.4.2.1.1">ADAPT</span></th>
<td class="ltx_td ltx_align_center" id="S3.T1.1.4.2.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.924</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.4.2.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.903</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.4.2.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.910</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.4.2.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.817</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.4.2.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.829</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.4.2.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.815</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.4.2.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.761</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.5.3.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.5.3.1.1">Uni4Eye</span></th>
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.3.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.646</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.3.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.647</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.3.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.697</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.3.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.688</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.3.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.617</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.3.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.626</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.5.3.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.583</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.6.4.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.6.4.1.1">I3D</span></th>
<td class="ltx_td ltx_align_center" id="S3.T1.1.6.4.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.629</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.6.4.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.448</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.6.4.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.674</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.6.4.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.607</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.6.4.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.549</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.6.4.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.513</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.6.4.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.472</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.7.5.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.7.5.1.1">MedicalNet-10</span></th>
<td class="ltx_td ltx_align_center" id="S3.T1.1.7.5.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.843</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.7.5.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.847</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.7.5.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.856</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.7.5.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.793</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.7.5.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.802</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.7.5.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.782</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.7.5.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.694</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.8.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.8.6.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.8.6.1.1">MedicalNet-34</span></th>
<td class="ltx_td ltx_align_center" id="S3.T1.1.8.6.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.669</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.8.6.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.782</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.8.6.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.847</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.8.6.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.585</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.8.6.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.592</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.8.6.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.643</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.8.6.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.551</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.9.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.9.7.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.9.7.1.1">MedicalNet-101</span></th>
<td class="ltx_td ltx_align_center" id="S3.T1.1.9.7.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.425</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.9.7.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.656</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.9.7.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.320</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.9.7.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.291</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.9.7.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.547</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.9.7.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.592</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.9.7.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.415</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.10.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.10.8.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.10.8.1.1">3D ResNet-34</span></th>
<td class="ltx_td ltx_align_center" id="S3.T1.1.10.8.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.618</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.10.8.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.453</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.10.8.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.779</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.10.8.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.745</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.10.8.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.581</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.10.8.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.647</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.10.8.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.422</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.11.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.11.9.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.11.9.1.1">3D ResNet-50</span></th>
<td class="ltx_td ltx_align_center" id="S3.T1.1.11.9.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.618</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.11.9.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.657</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.11.9.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.776</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.11.9.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.720</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.11.9.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.543</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.11.9.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.483</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.11.9.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.621</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.12.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.12.10.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.12.10.1.1">3D ResNet-101</span></th>
<td class="ltx_td ltx_align_center" id="S3.T1.1.12.10.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.526</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.12.10.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.426</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.12.10.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.601</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.12.10.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.433</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.12.10.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.505</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.12.10.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.574</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.12.10.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.450</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.13.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.13.11.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.13.11.1.1">3D DenseNet-121</span></th>
<td class="ltx_td ltx_align_center" id="S3.T1.1.13.11.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.675</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.13.11.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.408</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.13.11.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.816</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.13.11.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.772</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.13.11.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.724</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.13.11.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.398</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.1.13.11.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.536</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.14.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S3.T1.1.14.12.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.14.12.1.1">3D DenseNet-201</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.14.12.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.612</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.14.12.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.553</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.14.12.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.672</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.14.12.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.671</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.14.12.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.578</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.14.12.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.630</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S3.T1.1.14.12.8" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.427</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS4.4.1.1">III-D</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS4.5.2">Residual Temporal Attention Block (RTAB)</span>
</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">To effectively aggregate these temporal features, we propose an attention-based feature aggregation module. This module utilizes an AttentionPooling mechanism to perform weighted aggregation of the residual fusion features across different time points.</p>
</div>
<div class="ltx_para" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.4">Given an input sequence of residual fusion features <math alttext="X=[\mathbf{M}_{1}^{\prime},\mathbf{M}_{2}^{\prime},\dots,\mathbf{M}_{T}^{%
\prime}]" class="ltx_Math" display="inline" id="S3.SS4.p2.1.m1.4"><semantics id="S3.SS4.p2.1.m1.4a"><mrow id="S3.SS4.p2.1.m1.4.4" xref="S3.SS4.p2.1.m1.4.4.cmml"><mi id="S3.SS4.p2.1.m1.4.4.5" xref="S3.SS4.p2.1.m1.4.4.5.cmml">X</mi><mo id="S3.SS4.p2.1.m1.4.4.4" xref="S3.SS4.p2.1.m1.4.4.4.cmml">=</mo><mrow id="S3.SS4.p2.1.m1.4.4.3.3" xref="S3.SS4.p2.1.m1.4.4.3.4.cmml"><mo id="S3.SS4.p2.1.m1.4.4.3.3.4" stretchy="false" xref="S3.SS4.p2.1.m1.4.4.3.4.cmml">[</mo><msubsup id="S3.SS4.p2.1.m1.2.2.1.1.1" xref="S3.SS4.p2.1.m1.2.2.1.1.1.cmml"><mi id="S3.SS4.p2.1.m1.2.2.1.1.1.2.2" xref="S3.SS4.p2.1.m1.2.2.1.1.1.2.2.cmml">𝐌</mi><mn id="S3.SS4.p2.1.m1.2.2.1.1.1.2.3" xref="S3.SS4.p2.1.m1.2.2.1.1.1.2.3.cmml">1</mn><mo id="S3.SS4.p2.1.m1.2.2.1.1.1.3" xref="S3.SS4.p2.1.m1.2.2.1.1.1.3.cmml">′</mo></msubsup><mo id="S3.SS4.p2.1.m1.4.4.3.3.5" xref="S3.SS4.p2.1.m1.4.4.3.4.cmml">,</mo><msubsup id="S3.SS4.p2.1.m1.3.3.2.2.2" xref="S3.SS4.p2.1.m1.3.3.2.2.2.cmml"><mi id="S3.SS4.p2.1.m1.3.3.2.2.2.2.2" xref="S3.SS4.p2.1.m1.3.3.2.2.2.2.2.cmml">𝐌</mi><mn id="S3.SS4.p2.1.m1.3.3.2.2.2.2.3" xref="S3.SS4.p2.1.m1.3.3.2.2.2.2.3.cmml">2</mn><mo id="S3.SS4.p2.1.m1.3.3.2.2.2.3" xref="S3.SS4.p2.1.m1.3.3.2.2.2.3.cmml">′</mo></msubsup><mo id="S3.SS4.p2.1.m1.4.4.3.3.6" xref="S3.SS4.p2.1.m1.4.4.3.4.cmml">,</mo><mi id="S3.SS4.p2.1.m1.1.1" mathvariant="normal" xref="S3.SS4.p2.1.m1.1.1.cmml">…</mi><mo id="S3.SS4.p2.1.m1.4.4.3.3.7" xref="S3.SS4.p2.1.m1.4.4.3.4.cmml">,</mo><msubsup id="S3.SS4.p2.1.m1.4.4.3.3.3" xref="S3.SS4.p2.1.m1.4.4.3.3.3.cmml"><mi id="S3.SS4.p2.1.m1.4.4.3.3.3.2.2" xref="S3.SS4.p2.1.m1.4.4.3.3.3.2.2.cmml">𝐌</mi><mi id="S3.SS4.p2.1.m1.4.4.3.3.3.2.3" xref="S3.SS4.p2.1.m1.4.4.3.3.3.2.3.cmml">T</mi><mo id="S3.SS4.p2.1.m1.4.4.3.3.3.3" xref="S3.SS4.p2.1.m1.4.4.3.3.3.3.cmml">′</mo></msubsup><mo id="S3.SS4.p2.1.m1.4.4.3.3.8" stretchy="false" xref="S3.SS4.p2.1.m1.4.4.3.4.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.1.m1.4b"><apply id="S3.SS4.p2.1.m1.4.4.cmml" xref="S3.SS4.p2.1.m1.4.4"><eq id="S3.SS4.p2.1.m1.4.4.4.cmml" xref="S3.SS4.p2.1.m1.4.4.4"></eq><ci id="S3.SS4.p2.1.m1.4.4.5.cmml" xref="S3.SS4.p2.1.m1.4.4.5">𝑋</ci><list id="S3.SS4.p2.1.m1.4.4.3.4.cmml" xref="S3.SS4.p2.1.m1.4.4.3.3"><apply id="S3.SS4.p2.1.m1.2.2.1.1.1.cmml" xref="S3.SS4.p2.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS4.p2.1.m1.2.2.1.1.1">superscript</csymbol><apply id="S3.SS4.p2.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS4.p2.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.1.m1.2.2.1.1.1.2.1.cmml" xref="S3.SS4.p2.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.SS4.p2.1.m1.2.2.1.1.1.2.2.cmml" xref="S3.SS4.p2.1.m1.2.2.1.1.1.2.2">𝐌</ci><cn id="S3.SS4.p2.1.m1.2.2.1.1.1.2.3.cmml" type="integer" xref="S3.SS4.p2.1.m1.2.2.1.1.1.2.3">1</cn></apply><ci id="S3.SS4.p2.1.m1.2.2.1.1.1.3.cmml" xref="S3.SS4.p2.1.m1.2.2.1.1.1.3">′</ci></apply><apply id="S3.SS4.p2.1.m1.3.3.2.2.2.cmml" xref="S3.SS4.p2.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS4.p2.1.m1.3.3.2.2.2.1.cmml" xref="S3.SS4.p2.1.m1.3.3.2.2.2">superscript</csymbol><apply id="S3.SS4.p2.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS4.p2.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS4.p2.1.m1.3.3.2.2.2.2.1.cmml" xref="S3.SS4.p2.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.SS4.p2.1.m1.3.3.2.2.2.2.2.cmml" xref="S3.SS4.p2.1.m1.3.3.2.2.2.2.2">𝐌</ci><cn id="S3.SS4.p2.1.m1.3.3.2.2.2.2.3.cmml" type="integer" xref="S3.SS4.p2.1.m1.3.3.2.2.2.2.3">2</cn></apply><ci id="S3.SS4.p2.1.m1.3.3.2.2.2.3.cmml" xref="S3.SS4.p2.1.m1.3.3.2.2.2.3">′</ci></apply><ci id="S3.SS4.p2.1.m1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1">…</ci><apply id="S3.SS4.p2.1.m1.4.4.3.3.3.cmml" xref="S3.SS4.p2.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS4.p2.1.m1.4.4.3.3.3.1.cmml" xref="S3.SS4.p2.1.m1.4.4.3.3.3">superscript</csymbol><apply id="S3.SS4.p2.1.m1.4.4.3.3.3.2.cmml" xref="S3.SS4.p2.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS4.p2.1.m1.4.4.3.3.3.2.1.cmml" xref="S3.SS4.p2.1.m1.4.4.3.3.3">subscript</csymbol><ci id="S3.SS4.p2.1.m1.4.4.3.3.3.2.2.cmml" xref="S3.SS4.p2.1.m1.4.4.3.3.3.2.2">𝐌</ci><ci id="S3.SS4.p2.1.m1.4.4.3.3.3.2.3.cmml" xref="S3.SS4.p2.1.m1.4.4.3.3.3.2.3">𝑇</ci></apply><ci id="S3.SS4.p2.1.m1.4.4.3.3.3.3.cmml" xref="S3.SS4.p2.1.m1.4.4.3.3.3.3">′</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.1.m1.4c">X=[\mathbf{M}_{1}^{\prime},\mathbf{M}_{2}^{\prime},\dots,\mathbf{M}_{T}^{%
\prime}]</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.1.m1.4d">italic_X = [ bold_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT , bold_M start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT , … , bold_M start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ]</annotation></semantics></math> with <math alttext="T" class="ltx_Math" display="inline" id="S3.SS4.p2.2.m2.1"><semantics id="S3.SS4.p2.2.m2.1a"><mi id="S3.SS4.p2.2.m2.1.1" xref="S3.SS4.p2.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.2.m2.1b"><ci id="S3.SS4.p2.2.m2.1.1.cmml" xref="S3.SS4.p2.2.m2.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.2.m2.1c">T</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.2.m2.1d">italic_T</annotation></semantics></math> time steps, each feature <math alttext="\mathbf{M}_{t}^{\prime}\in\mathbb{R}^{d}" class="ltx_Math" display="inline" id="S3.SS4.p2.3.m3.1"><semantics id="S3.SS4.p2.3.m3.1a"><mrow id="S3.SS4.p2.3.m3.1.1" xref="S3.SS4.p2.3.m3.1.1.cmml"><msubsup id="S3.SS4.p2.3.m3.1.1.2" xref="S3.SS4.p2.3.m3.1.1.2.cmml"><mi id="S3.SS4.p2.3.m3.1.1.2.2.2" xref="S3.SS4.p2.3.m3.1.1.2.2.2.cmml">𝐌</mi><mi id="S3.SS4.p2.3.m3.1.1.2.2.3" xref="S3.SS4.p2.3.m3.1.1.2.2.3.cmml">t</mi><mo id="S3.SS4.p2.3.m3.1.1.2.3" xref="S3.SS4.p2.3.m3.1.1.2.3.cmml">′</mo></msubsup><mo id="S3.SS4.p2.3.m3.1.1.1" xref="S3.SS4.p2.3.m3.1.1.1.cmml">∈</mo><msup id="S3.SS4.p2.3.m3.1.1.3" xref="S3.SS4.p2.3.m3.1.1.3.cmml"><mi id="S3.SS4.p2.3.m3.1.1.3.2" xref="S3.SS4.p2.3.m3.1.1.3.2.cmml">ℝ</mi><mi id="S3.SS4.p2.3.m3.1.1.3.3" xref="S3.SS4.p2.3.m3.1.1.3.3.cmml">d</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.3.m3.1b"><apply id="S3.SS4.p2.3.m3.1.1.cmml" xref="S3.SS4.p2.3.m3.1.1"><in id="S3.SS4.p2.3.m3.1.1.1.cmml" xref="S3.SS4.p2.3.m3.1.1.1"></in><apply id="S3.SS4.p2.3.m3.1.1.2.cmml" xref="S3.SS4.p2.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS4.p2.3.m3.1.1.2.1.cmml" xref="S3.SS4.p2.3.m3.1.1.2">superscript</csymbol><apply id="S3.SS4.p2.3.m3.1.1.2.2.cmml" xref="S3.SS4.p2.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS4.p2.3.m3.1.1.2.2.1.cmml" xref="S3.SS4.p2.3.m3.1.1.2">subscript</csymbol><ci id="S3.SS4.p2.3.m3.1.1.2.2.2.cmml" xref="S3.SS4.p2.3.m3.1.1.2.2.2">𝐌</ci><ci id="S3.SS4.p2.3.m3.1.1.2.2.3.cmml" xref="S3.SS4.p2.3.m3.1.1.2.2.3">𝑡</ci></apply><ci id="S3.SS4.p2.3.m3.1.1.2.3.cmml" xref="S3.SS4.p2.3.m3.1.1.2.3">′</ci></apply><apply id="S3.SS4.p2.3.m3.1.1.3.cmml" xref="S3.SS4.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS4.p2.3.m3.1.1.3.1.cmml" xref="S3.SS4.p2.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS4.p2.3.m3.1.1.3.2.cmml" xref="S3.SS4.p2.3.m3.1.1.3.2">ℝ</ci><ci id="S3.SS4.p2.3.m3.1.1.3.3.cmml" xref="S3.SS4.p2.3.m3.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.3.m3.1c">\mathbf{M}_{t}^{\prime}\in\mathbb{R}^{d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.3.m3.1d">bold_M start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT</annotation></semantics></math> where <math alttext="d" class="ltx_Math" display="inline" id="S3.SS4.p2.4.m4.1"><semantics id="S3.SS4.p2.4.m4.1a"><mi id="S3.SS4.p2.4.m4.1.1" xref="S3.SS4.p2.4.m4.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.4.m4.1b"><ci id="S3.SS4.p2.4.m4.1.1.cmml" xref="S3.SS4.p2.4.m4.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.4.m4.1c">d</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.4.m4.1d">italic_d</annotation></semantics></math> is the dimensionality of the features, the input sequence is first reshaped to separate the batch size and sequence length. This reshaped sequence is represented as:</p>
</div>
<div class="ltx_para" id="S3.SS4.p3">
<table class="ltx_equation ltx_eqn_table" id="S3.Ex3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="X\in\mathbb{R}^{\text{batch\_size}\times T\times d}" class="ltx_Math" display="block" id="S3.Ex3.m1.1"><semantics id="S3.Ex3.m1.1a"><mrow id="S3.Ex3.m1.1.1" xref="S3.Ex3.m1.1.1.cmml"><mi id="S3.Ex3.m1.1.1.2" xref="S3.Ex3.m1.1.1.2.cmml">X</mi><mo id="S3.Ex3.m1.1.1.1" xref="S3.Ex3.m1.1.1.1.cmml">∈</mo><msup id="S3.Ex3.m1.1.1.3" xref="S3.Ex3.m1.1.1.3.cmml"><mi id="S3.Ex3.m1.1.1.3.2" xref="S3.Ex3.m1.1.1.3.2.cmml">ℝ</mi><mrow id="S3.Ex3.m1.1.1.3.3" xref="S3.Ex3.m1.1.1.3.3.cmml"><mtext id="S3.Ex3.m1.1.1.3.3.2" xref="S3.Ex3.m1.1.1.3.3.2a.cmml">batch_size</mtext><mo id="S3.Ex3.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.Ex3.m1.1.1.3.3.1.cmml">×</mo><mi id="S3.Ex3.m1.1.1.3.3.3" xref="S3.Ex3.m1.1.1.3.3.3.cmml">T</mi><mo id="S3.Ex3.m1.1.1.3.3.1a" lspace="0.222em" rspace="0.222em" xref="S3.Ex3.m1.1.1.3.3.1.cmml">×</mo><mi id="S3.Ex3.m1.1.1.3.3.4" xref="S3.Ex3.m1.1.1.3.3.4.cmml">d</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex3.m1.1b"><apply id="S3.Ex3.m1.1.1.cmml" xref="S3.Ex3.m1.1.1"><in id="S3.Ex3.m1.1.1.1.cmml" xref="S3.Ex3.m1.1.1.1"></in><ci id="S3.Ex3.m1.1.1.2.cmml" xref="S3.Ex3.m1.1.1.2">𝑋</ci><apply id="S3.Ex3.m1.1.1.3.cmml" xref="S3.Ex3.m1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex3.m1.1.1.3.1.cmml" xref="S3.Ex3.m1.1.1.3">superscript</csymbol><ci id="S3.Ex3.m1.1.1.3.2.cmml" xref="S3.Ex3.m1.1.1.3.2">ℝ</ci><apply id="S3.Ex3.m1.1.1.3.3.cmml" xref="S3.Ex3.m1.1.1.3.3"><times id="S3.Ex3.m1.1.1.3.3.1.cmml" xref="S3.Ex3.m1.1.1.3.3.1"></times><ci id="S3.Ex3.m1.1.1.3.3.2a.cmml" xref="S3.Ex3.m1.1.1.3.3.2"><mtext id="S3.Ex3.m1.1.1.3.3.2.cmml" mathsize="70%" xref="S3.Ex3.m1.1.1.3.3.2">batch_size</mtext></ci><ci id="S3.Ex3.m1.1.1.3.3.3.cmml" xref="S3.Ex3.m1.1.1.3.3.3">𝑇</ci><ci id="S3.Ex3.m1.1.1.3.3.4.cmml" xref="S3.Ex3.m1.1.1.3.3.4">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex3.m1.1c">X\in\mathbb{R}^{\text{batch\_size}\times T\times d}</annotation><annotation encoding="application/x-llamapun" id="S3.Ex3.m1.1d">italic_X ∈ blackboard_R start_POSTSUPERSCRIPT batch_size × italic_T × italic_d end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS4.p4">
<p class="ltx_p" id="S3.SS4.p4.1">Next, the attention weights for each time step are computed using a linear transformation:</p>
</div>
<div class="ltx_para" id="S3.SS4.p5">
<table class="ltx_equation ltx_eqn_table" id="S3.Ex4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathbf{w}_{t}=\text{softmax}\left(\mathbf{W}_{a}\mathbf{M}_{t}^{\prime}\right)" class="ltx_Math" display="block" id="S3.Ex4.m1.1"><semantics id="S3.Ex4.m1.1a"><mrow id="S3.Ex4.m1.1.1" xref="S3.Ex4.m1.1.1.cmml"><msub id="S3.Ex4.m1.1.1.3" xref="S3.Ex4.m1.1.1.3.cmml"><mi id="S3.Ex4.m1.1.1.3.2" xref="S3.Ex4.m1.1.1.3.2.cmml">𝐰</mi><mi id="S3.Ex4.m1.1.1.3.3" xref="S3.Ex4.m1.1.1.3.3.cmml">t</mi></msub><mo id="S3.Ex4.m1.1.1.2" xref="S3.Ex4.m1.1.1.2.cmml">=</mo><mrow id="S3.Ex4.m1.1.1.1" xref="S3.Ex4.m1.1.1.1.cmml"><mtext id="S3.Ex4.m1.1.1.1.3" xref="S3.Ex4.m1.1.1.1.3a.cmml">softmax</mtext><mo id="S3.Ex4.m1.1.1.1.2" xref="S3.Ex4.m1.1.1.1.2.cmml">⁢</mo><mrow id="S3.Ex4.m1.1.1.1.1.1" xref="S3.Ex4.m1.1.1.1.1.1.1.cmml"><mo id="S3.Ex4.m1.1.1.1.1.1.2" xref="S3.Ex4.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.Ex4.m1.1.1.1.1.1.1" xref="S3.Ex4.m1.1.1.1.1.1.1.cmml"><msub id="S3.Ex4.m1.1.1.1.1.1.1.2" xref="S3.Ex4.m1.1.1.1.1.1.1.2.cmml"><mi id="S3.Ex4.m1.1.1.1.1.1.1.2.2" xref="S3.Ex4.m1.1.1.1.1.1.1.2.2.cmml">𝐖</mi><mi id="S3.Ex4.m1.1.1.1.1.1.1.2.3" xref="S3.Ex4.m1.1.1.1.1.1.1.2.3.cmml">a</mi></msub><mo id="S3.Ex4.m1.1.1.1.1.1.1.1" xref="S3.Ex4.m1.1.1.1.1.1.1.1.cmml">⁢</mo><msubsup id="S3.Ex4.m1.1.1.1.1.1.1.3" xref="S3.Ex4.m1.1.1.1.1.1.1.3.cmml"><mi id="S3.Ex4.m1.1.1.1.1.1.1.3.2.2" xref="S3.Ex4.m1.1.1.1.1.1.1.3.2.2.cmml">𝐌</mi><mi id="S3.Ex4.m1.1.1.1.1.1.1.3.2.3" xref="S3.Ex4.m1.1.1.1.1.1.1.3.2.3.cmml">t</mi><mo id="S3.Ex4.m1.1.1.1.1.1.1.3.3" xref="S3.Ex4.m1.1.1.1.1.1.1.3.3.cmml">′</mo></msubsup></mrow><mo id="S3.Ex4.m1.1.1.1.1.1.3" xref="S3.Ex4.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex4.m1.1b"><apply id="S3.Ex4.m1.1.1.cmml" xref="S3.Ex4.m1.1.1"><eq id="S3.Ex4.m1.1.1.2.cmml" xref="S3.Ex4.m1.1.1.2"></eq><apply id="S3.Ex4.m1.1.1.3.cmml" xref="S3.Ex4.m1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex4.m1.1.1.3.1.cmml" xref="S3.Ex4.m1.1.1.3">subscript</csymbol><ci id="S3.Ex4.m1.1.1.3.2.cmml" xref="S3.Ex4.m1.1.1.3.2">𝐰</ci><ci id="S3.Ex4.m1.1.1.3.3.cmml" xref="S3.Ex4.m1.1.1.3.3">𝑡</ci></apply><apply id="S3.Ex4.m1.1.1.1.cmml" xref="S3.Ex4.m1.1.1.1"><times id="S3.Ex4.m1.1.1.1.2.cmml" xref="S3.Ex4.m1.1.1.1.2"></times><ci id="S3.Ex4.m1.1.1.1.3a.cmml" xref="S3.Ex4.m1.1.1.1.3"><mtext id="S3.Ex4.m1.1.1.1.3.cmml" xref="S3.Ex4.m1.1.1.1.3">softmax</mtext></ci><apply id="S3.Ex4.m1.1.1.1.1.1.1.cmml" xref="S3.Ex4.m1.1.1.1.1.1"><times id="S3.Ex4.m1.1.1.1.1.1.1.1.cmml" xref="S3.Ex4.m1.1.1.1.1.1.1.1"></times><apply id="S3.Ex4.m1.1.1.1.1.1.1.2.cmml" xref="S3.Ex4.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.Ex4.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.Ex4.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.Ex4.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.Ex4.m1.1.1.1.1.1.1.2.2">𝐖</ci><ci id="S3.Ex4.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.Ex4.m1.1.1.1.1.1.1.2.3">𝑎</ci></apply><apply id="S3.Ex4.m1.1.1.1.1.1.1.3.cmml" xref="S3.Ex4.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex4.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.Ex4.m1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S3.Ex4.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.Ex4.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex4.m1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.Ex4.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.Ex4.m1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.Ex4.m1.1.1.1.1.1.1.3.2.2">𝐌</ci><ci id="S3.Ex4.m1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.Ex4.m1.1.1.1.1.1.1.3.2.3">𝑡</ci></apply><ci id="S3.Ex4.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.Ex4.m1.1.1.1.1.1.1.3.3">′</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex4.m1.1c">\mathbf{w}_{t}=\text{softmax}\left(\mathbf{W}_{a}\mathbf{M}_{t}^{\prime}\right)</annotation><annotation encoding="application/x-llamapun" id="S3.Ex4.m1.1d">bold_w start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = softmax ( bold_W start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT bold_M start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS4.p6">
<p class="ltx_p" id="S3.SS4.p6.3">where <math alttext="\mathbf{W}_{a}\in\mathbb{R}^{d\times 1}" class="ltx_Math" display="inline" id="S3.SS4.p6.1.m1.1"><semantics id="S3.SS4.p6.1.m1.1a"><mrow id="S3.SS4.p6.1.m1.1.1" xref="S3.SS4.p6.1.m1.1.1.cmml"><msub id="S3.SS4.p6.1.m1.1.1.2" xref="S3.SS4.p6.1.m1.1.1.2.cmml"><mi id="S3.SS4.p6.1.m1.1.1.2.2" xref="S3.SS4.p6.1.m1.1.1.2.2.cmml">𝐖</mi><mi id="S3.SS4.p6.1.m1.1.1.2.3" xref="S3.SS4.p6.1.m1.1.1.2.3.cmml">a</mi></msub><mo id="S3.SS4.p6.1.m1.1.1.1" xref="S3.SS4.p6.1.m1.1.1.1.cmml">∈</mo><msup id="S3.SS4.p6.1.m1.1.1.3" xref="S3.SS4.p6.1.m1.1.1.3.cmml"><mi id="S3.SS4.p6.1.m1.1.1.3.2" xref="S3.SS4.p6.1.m1.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS4.p6.1.m1.1.1.3.3" xref="S3.SS4.p6.1.m1.1.1.3.3.cmml"><mi id="S3.SS4.p6.1.m1.1.1.3.3.2" xref="S3.SS4.p6.1.m1.1.1.3.3.2.cmml">d</mi><mo id="S3.SS4.p6.1.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS4.p6.1.m1.1.1.3.3.1.cmml">×</mo><mn id="S3.SS4.p6.1.m1.1.1.3.3.3" xref="S3.SS4.p6.1.m1.1.1.3.3.3.cmml">1</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p6.1.m1.1b"><apply id="S3.SS4.p6.1.m1.1.1.cmml" xref="S3.SS4.p6.1.m1.1.1"><in id="S3.SS4.p6.1.m1.1.1.1.cmml" xref="S3.SS4.p6.1.m1.1.1.1"></in><apply id="S3.SS4.p6.1.m1.1.1.2.cmml" xref="S3.SS4.p6.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS4.p6.1.m1.1.1.2.1.cmml" xref="S3.SS4.p6.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS4.p6.1.m1.1.1.2.2.cmml" xref="S3.SS4.p6.1.m1.1.1.2.2">𝐖</ci><ci id="S3.SS4.p6.1.m1.1.1.2.3.cmml" xref="S3.SS4.p6.1.m1.1.1.2.3">𝑎</ci></apply><apply id="S3.SS4.p6.1.m1.1.1.3.cmml" xref="S3.SS4.p6.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS4.p6.1.m1.1.1.3.1.cmml" xref="S3.SS4.p6.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS4.p6.1.m1.1.1.3.2.cmml" xref="S3.SS4.p6.1.m1.1.1.3.2">ℝ</ci><apply id="S3.SS4.p6.1.m1.1.1.3.3.cmml" xref="S3.SS4.p6.1.m1.1.1.3.3"><times id="S3.SS4.p6.1.m1.1.1.3.3.1.cmml" xref="S3.SS4.p6.1.m1.1.1.3.3.1"></times><ci id="S3.SS4.p6.1.m1.1.1.3.3.2.cmml" xref="S3.SS4.p6.1.m1.1.1.3.3.2">𝑑</ci><cn id="S3.SS4.p6.1.m1.1.1.3.3.3.cmml" type="integer" xref="S3.SS4.p6.1.m1.1.1.3.3.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p6.1.m1.1c">\mathbf{W}_{a}\in\mathbb{R}^{d\times 1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p6.1.m1.1d">bold_W start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_d × 1 end_POSTSUPERSCRIPT</annotation></semantics></math> is a learnable weight matrix, and <math alttext="\mathbf{w}_{t}\in\mathbb{R}" class="ltx_Math" display="inline" id="S3.SS4.p6.2.m2.1"><semantics id="S3.SS4.p6.2.m2.1a"><mrow id="S3.SS4.p6.2.m2.1.1" xref="S3.SS4.p6.2.m2.1.1.cmml"><msub id="S3.SS4.p6.2.m2.1.1.2" xref="S3.SS4.p6.2.m2.1.1.2.cmml"><mi id="S3.SS4.p6.2.m2.1.1.2.2" xref="S3.SS4.p6.2.m2.1.1.2.2.cmml">𝐰</mi><mi id="S3.SS4.p6.2.m2.1.1.2.3" xref="S3.SS4.p6.2.m2.1.1.2.3.cmml">t</mi></msub><mo id="S3.SS4.p6.2.m2.1.1.1" xref="S3.SS4.p6.2.m2.1.1.1.cmml">∈</mo><mi id="S3.SS4.p6.2.m2.1.1.3" xref="S3.SS4.p6.2.m2.1.1.3.cmml">ℝ</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p6.2.m2.1b"><apply id="S3.SS4.p6.2.m2.1.1.cmml" xref="S3.SS4.p6.2.m2.1.1"><in id="S3.SS4.p6.2.m2.1.1.1.cmml" xref="S3.SS4.p6.2.m2.1.1.1"></in><apply id="S3.SS4.p6.2.m2.1.1.2.cmml" xref="S3.SS4.p6.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS4.p6.2.m2.1.1.2.1.cmml" xref="S3.SS4.p6.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS4.p6.2.m2.1.1.2.2.cmml" xref="S3.SS4.p6.2.m2.1.1.2.2">𝐰</ci><ci id="S3.SS4.p6.2.m2.1.1.2.3.cmml" xref="S3.SS4.p6.2.m2.1.1.2.3">𝑡</ci></apply><ci id="S3.SS4.p6.2.m2.1.1.3.cmml" xref="S3.SS4.p6.2.m2.1.1.3">ℝ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p6.2.m2.1c">\mathbf{w}_{t}\in\mathbb{R}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p6.2.m2.1d">bold_w start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ∈ blackboard_R</annotation></semantics></math> represents the attention weight for the <math alttext="t" class="ltx_Math" display="inline" id="S3.SS4.p6.3.m3.1"><semantics id="S3.SS4.p6.3.m3.1a"><mi id="S3.SS4.p6.3.m3.1.1" xref="S3.SS4.p6.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p6.3.m3.1b"><ci id="S3.SS4.p6.3.m3.1.1.cmml" xref="S3.SS4.p6.3.m3.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p6.3.m3.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p6.3.m3.1d">italic_t</annotation></semantics></math>-th time step. The softmax function ensures that the attention weights sum to 1 across all time steps.</p>
</div>
<div class="ltx_para" id="S3.SS4.p7">
<p class="ltx_p" id="S3.SS4.p7.1">These attention weights are then used to compute a weighted sum of the input features:</p>
</div>
<div class="ltx_para" id="S3.SS4.p8">
<table class="ltx_equation ltx_eqn_table" id="S3.Ex5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathbf{P}=\sum_{t=1}^{T}\mathbf{w}_{t}\mathbf{M}_{t}^{\prime}" class="ltx_Math" display="block" id="S3.Ex5.m1.1"><semantics id="S3.Ex5.m1.1a"><mrow id="S3.Ex5.m1.1.1" xref="S3.Ex5.m1.1.1.cmml"><mi id="S3.Ex5.m1.1.1.2" xref="S3.Ex5.m1.1.1.2.cmml">𝐏</mi><mo id="S3.Ex5.m1.1.1.1" rspace="0.111em" xref="S3.Ex5.m1.1.1.1.cmml">=</mo><mrow id="S3.Ex5.m1.1.1.3" xref="S3.Ex5.m1.1.1.3.cmml"><munderover id="S3.Ex5.m1.1.1.3.1" xref="S3.Ex5.m1.1.1.3.1.cmml"><mo id="S3.Ex5.m1.1.1.3.1.2.2" movablelimits="false" xref="S3.Ex5.m1.1.1.3.1.2.2.cmml">∑</mo><mrow id="S3.Ex5.m1.1.1.3.1.2.3" xref="S3.Ex5.m1.1.1.3.1.2.3.cmml"><mi id="S3.Ex5.m1.1.1.3.1.2.3.2" xref="S3.Ex5.m1.1.1.3.1.2.3.2.cmml">t</mi><mo id="S3.Ex5.m1.1.1.3.1.2.3.1" xref="S3.Ex5.m1.1.1.3.1.2.3.1.cmml">=</mo><mn id="S3.Ex5.m1.1.1.3.1.2.3.3" xref="S3.Ex5.m1.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="S3.Ex5.m1.1.1.3.1.3" xref="S3.Ex5.m1.1.1.3.1.3.cmml">T</mi></munderover><mrow id="S3.Ex5.m1.1.1.3.2" xref="S3.Ex5.m1.1.1.3.2.cmml"><msub id="S3.Ex5.m1.1.1.3.2.2" xref="S3.Ex5.m1.1.1.3.2.2.cmml"><mi id="S3.Ex5.m1.1.1.3.2.2.2" xref="S3.Ex5.m1.1.1.3.2.2.2.cmml">𝐰</mi><mi id="S3.Ex5.m1.1.1.3.2.2.3" xref="S3.Ex5.m1.1.1.3.2.2.3.cmml">t</mi></msub><mo id="S3.Ex5.m1.1.1.3.2.1" xref="S3.Ex5.m1.1.1.3.2.1.cmml">⁢</mo><msubsup id="S3.Ex5.m1.1.1.3.2.3" xref="S3.Ex5.m1.1.1.3.2.3.cmml"><mi id="S3.Ex5.m1.1.1.3.2.3.2.2" xref="S3.Ex5.m1.1.1.3.2.3.2.2.cmml">𝐌</mi><mi id="S3.Ex5.m1.1.1.3.2.3.2.3" xref="S3.Ex5.m1.1.1.3.2.3.2.3.cmml">t</mi><mo id="S3.Ex5.m1.1.1.3.2.3.3" xref="S3.Ex5.m1.1.1.3.2.3.3.cmml">′</mo></msubsup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex5.m1.1b"><apply id="S3.Ex5.m1.1.1.cmml" xref="S3.Ex5.m1.1.1"><eq id="S3.Ex5.m1.1.1.1.cmml" xref="S3.Ex5.m1.1.1.1"></eq><ci id="S3.Ex5.m1.1.1.2.cmml" xref="S3.Ex5.m1.1.1.2">𝐏</ci><apply id="S3.Ex5.m1.1.1.3.cmml" xref="S3.Ex5.m1.1.1.3"><apply id="S3.Ex5.m1.1.1.3.1.cmml" xref="S3.Ex5.m1.1.1.3.1"><csymbol cd="ambiguous" id="S3.Ex5.m1.1.1.3.1.1.cmml" xref="S3.Ex5.m1.1.1.3.1">superscript</csymbol><apply id="S3.Ex5.m1.1.1.3.1.2.cmml" xref="S3.Ex5.m1.1.1.3.1"><csymbol cd="ambiguous" id="S3.Ex5.m1.1.1.3.1.2.1.cmml" xref="S3.Ex5.m1.1.1.3.1">subscript</csymbol><sum id="S3.Ex5.m1.1.1.3.1.2.2.cmml" xref="S3.Ex5.m1.1.1.3.1.2.2"></sum><apply id="S3.Ex5.m1.1.1.3.1.2.3.cmml" xref="S3.Ex5.m1.1.1.3.1.2.3"><eq id="S3.Ex5.m1.1.1.3.1.2.3.1.cmml" xref="S3.Ex5.m1.1.1.3.1.2.3.1"></eq><ci id="S3.Ex5.m1.1.1.3.1.2.3.2.cmml" xref="S3.Ex5.m1.1.1.3.1.2.3.2">𝑡</ci><cn id="S3.Ex5.m1.1.1.3.1.2.3.3.cmml" type="integer" xref="S3.Ex5.m1.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="S3.Ex5.m1.1.1.3.1.3.cmml" xref="S3.Ex5.m1.1.1.3.1.3">𝑇</ci></apply><apply id="S3.Ex5.m1.1.1.3.2.cmml" xref="S3.Ex5.m1.1.1.3.2"><times id="S3.Ex5.m1.1.1.3.2.1.cmml" xref="S3.Ex5.m1.1.1.3.2.1"></times><apply id="S3.Ex5.m1.1.1.3.2.2.cmml" xref="S3.Ex5.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.Ex5.m1.1.1.3.2.2.1.cmml" xref="S3.Ex5.m1.1.1.3.2.2">subscript</csymbol><ci id="S3.Ex5.m1.1.1.3.2.2.2.cmml" xref="S3.Ex5.m1.1.1.3.2.2.2">𝐰</ci><ci id="S3.Ex5.m1.1.1.3.2.2.3.cmml" xref="S3.Ex5.m1.1.1.3.2.2.3">𝑡</ci></apply><apply id="S3.Ex5.m1.1.1.3.2.3.cmml" xref="S3.Ex5.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.Ex5.m1.1.1.3.2.3.1.cmml" xref="S3.Ex5.m1.1.1.3.2.3">superscript</csymbol><apply id="S3.Ex5.m1.1.1.3.2.3.2.cmml" xref="S3.Ex5.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.Ex5.m1.1.1.3.2.3.2.1.cmml" xref="S3.Ex5.m1.1.1.3.2.3">subscript</csymbol><ci id="S3.Ex5.m1.1.1.3.2.3.2.2.cmml" xref="S3.Ex5.m1.1.1.3.2.3.2.2">𝐌</ci><ci id="S3.Ex5.m1.1.1.3.2.3.2.3.cmml" xref="S3.Ex5.m1.1.1.3.2.3.2.3">𝑡</ci></apply><ci id="S3.Ex5.m1.1.1.3.2.3.3.cmml" xref="S3.Ex5.m1.1.1.3.2.3.3">′</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex5.m1.1c">\mathbf{P}=\sum_{t=1}^{T}\mathbf{w}_{t}\mathbf{M}_{t}^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.Ex5.m1.1d">bold_P = ∑ start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT bold_w start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT bold_M start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS4.p9">
<p class="ltx_p" id="S3.SS4.p9.1">where <math alttext="\mathbf{P}\in\mathbb{R}^{d}" class="ltx_Math" display="inline" id="S3.SS4.p9.1.m1.1"><semantics id="S3.SS4.p9.1.m1.1a"><mrow id="S3.SS4.p9.1.m1.1.1" xref="S3.SS4.p9.1.m1.1.1.cmml"><mi id="S3.SS4.p9.1.m1.1.1.2" xref="S3.SS4.p9.1.m1.1.1.2.cmml">𝐏</mi><mo id="S3.SS4.p9.1.m1.1.1.1" xref="S3.SS4.p9.1.m1.1.1.1.cmml">∈</mo><msup id="S3.SS4.p9.1.m1.1.1.3" xref="S3.SS4.p9.1.m1.1.1.3.cmml"><mi id="S3.SS4.p9.1.m1.1.1.3.2" xref="S3.SS4.p9.1.m1.1.1.3.2.cmml">ℝ</mi><mi id="S3.SS4.p9.1.m1.1.1.3.3" xref="S3.SS4.p9.1.m1.1.1.3.3.cmml">d</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p9.1.m1.1b"><apply id="S3.SS4.p9.1.m1.1.1.cmml" xref="S3.SS4.p9.1.m1.1.1"><in id="S3.SS4.p9.1.m1.1.1.1.cmml" xref="S3.SS4.p9.1.m1.1.1.1"></in><ci id="S3.SS4.p9.1.m1.1.1.2.cmml" xref="S3.SS4.p9.1.m1.1.1.2">𝐏</ci><apply id="S3.SS4.p9.1.m1.1.1.3.cmml" xref="S3.SS4.p9.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS4.p9.1.m1.1.1.3.1.cmml" xref="S3.SS4.p9.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS4.p9.1.m1.1.1.3.2.cmml" xref="S3.SS4.p9.1.m1.1.1.3.2">ℝ</ci><ci id="S3.SS4.p9.1.m1.1.1.3.3.cmml" xref="S3.SS4.p9.1.m1.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p9.1.m1.1c">\mathbf{P}\in\mathbb{R}^{d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p9.1.m1.1d">bold_P ∈ blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT</annotation></semantics></math> is the pooled feature vector, effectively capturing the temporal dynamics of the input sequence.</p>
</div>
<div class="ltx_para" id="S3.SS4.p10">
<p class="ltx_p" id="S3.SS4.p10.1">This pooled feature vector <math alttext="\mathbf{P}" class="ltx_Math" display="inline" id="S3.SS4.p10.1.m1.1"><semantics id="S3.SS4.p10.1.m1.1a"><mi id="S3.SS4.p10.1.m1.1.1" xref="S3.SS4.p10.1.m1.1.1.cmml">𝐏</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p10.1.m1.1b"><ci id="S3.SS4.p10.1.m1.1.1.cmml" xref="S3.SS4.p10.1.m1.1.1">𝐏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p10.1.m1.1c">\mathbf{P}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p10.1.m1.1d">bold_P</annotation></semantics></math> is then passed through a classification head, implemented as a fully connected layer, to produce the final prediction logits:</p>
</div>
<div class="ltx_para" id="S3.SS4.p11">
<table class="ltx_equation ltx_eqn_table" id="S3.Ex6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{logits}=\mathbf{W}_{c}\mathbf{P}+\mathbf{b}_{c}" class="ltx_Math" display="block" id="S3.Ex6.m1.1"><semantics id="S3.Ex6.m1.1a"><mrow id="S3.Ex6.m1.1.1" xref="S3.Ex6.m1.1.1.cmml"><mtext id="S3.Ex6.m1.1.1.2" xref="S3.Ex6.m1.1.1.2a.cmml">logits</mtext><mo id="S3.Ex6.m1.1.1.1" xref="S3.Ex6.m1.1.1.1.cmml">=</mo><mrow id="S3.Ex6.m1.1.1.3" xref="S3.Ex6.m1.1.1.3.cmml"><mrow id="S3.Ex6.m1.1.1.3.2" xref="S3.Ex6.m1.1.1.3.2.cmml"><msub id="S3.Ex6.m1.1.1.3.2.2" xref="S3.Ex6.m1.1.1.3.2.2.cmml"><mi id="S3.Ex6.m1.1.1.3.2.2.2" xref="S3.Ex6.m1.1.1.3.2.2.2.cmml">𝐖</mi><mi id="S3.Ex6.m1.1.1.3.2.2.3" xref="S3.Ex6.m1.1.1.3.2.2.3.cmml">c</mi></msub><mo id="S3.Ex6.m1.1.1.3.2.1" xref="S3.Ex6.m1.1.1.3.2.1.cmml">⁢</mo><mi id="S3.Ex6.m1.1.1.3.2.3" xref="S3.Ex6.m1.1.1.3.2.3.cmml">𝐏</mi></mrow><mo id="S3.Ex6.m1.1.1.3.1" xref="S3.Ex6.m1.1.1.3.1.cmml">+</mo><msub id="S3.Ex6.m1.1.1.3.3" xref="S3.Ex6.m1.1.1.3.3.cmml"><mi id="S3.Ex6.m1.1.1.3.3.2" xref="S3.Ex6.m1.1.1.3.3.2.cmml">𝐛</mi><mi id="S3.Ex6.m1.1.1.3.3.3" xref="S3.Ex6.m1.1.1.3.3.3.cmml">c</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex6.m1.1b"><apply id="S3.Ex6.m1.1.1.cmml" xref="S3.Ex6.m1.1.1"><eq id="S3.Ex6.m1.1.1.1.cmml" xref="S3.Ex6.m1.1.1.1"></eq><ci id="S3.Ex6.m1.1.1.2a.cmml" xref="S3.Ex6.m1.1.1.2"><mtext id="S3.Ex6.m1.1.1.2.cmml" xref="S3.Ex6.m1.1.1.2">logits</mtext></ci><apply id="S3.Ex6.m1.1.1.3.cmml" xref="S3.Ex6.m1.1.1.3"><plus id="S3.Ex6.m1.1.1.3.1.cmml" xref="S3.Ex6.m1.1.1.3.1"></plus><apply id="S3.Ex6.m1.1.1.3.2.cmml" xref="S3.Ex6.m1.1.1.3.2"><times id="S3.Ex6.m1.1.1.3.2.1.cmml" xref="S3.Ex6.m1.1.1.3.2.1"></times><apply id="S3.Ex6.m1.1.1.3.2.2.cmml" xref="S3.Ex6.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.Ex6.m1.1.1.3.2.2.1.cmml" xref="S3.Ex6.m1.1.1.3.2.2">subscript</csymbol><ci id="S3.Ex6.m1.1.1.3.2.2.2.cmml" xref="S3.Ex6.m1.1.1.3.2.2.2">𝐖</ci><ci id="S3.Ex6.m1.1.1.3.2.2.3.cmml" xref="S3.Ex6.m1.1.1.3.2.2.3">𝑐</ci></apply><ci id="S3.Ex6.m1.1.1.3.2.3.cmml" xref="S3.Ex6.m1.1.1.3.2.3">𝐏</ci></apply><apply id="S3.Ex6.m1.1.1.3.3.cmml" xref="S3.Ex6.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.Ex6.m1.1.1.3.3.1.cmml" xref="S3.Ex6.m1.1.1.3.3">subscript</csymbol><ci id="S3.Ex6.m1.1.1.3.3.2.cmml" xref="S3.Ex6.m1.1.1.3.3.2">𝐛</ci><ci id="S3.Ex6.m1.1.1.3.3.3.cmml" xref="S3.Ex6.m1.1.1.3.3.3">𝑐</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex6.m1.1c">\text{logits}=\mathbf{W}_{c}\mathbf{P}+\mathbf{b}_{c}</annotation><annotation encoding="application/x-llamapun" id="S3.Ex6.m1.1d">logits = bold_W start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT bold_P + bold_b start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS4.p12">
<p class="ltx_p" id="S3.SS4.p12.2">where <math alttext="\mathbf{W}_{c}\in\mathbb{R}^{\text{num\_classes}\times d}" class="ltx_Math" display="inline" id="S3.SS4.p12.1.m1.1"><semantics id="S3.SS4.p12.1.m1.1a"><mrow id="S3.SS4.p12.1.m1.1.1" xref="S3.SS4.p12.1.m1.1.1.cmml"><msub id="S3.SS4.p12.1.m1.1.1.2" xref="S3.SS4.p12.1.m1.1.1.2.cmml"><mi id="S3.SS4.p12.1.m1.1.1.2.2" xref="S3.SS4.p12.1.m1.1.1.2.2.cmml">𝐖</mi><mi id="S3.SS4.p12.1.m1.1.1.2.3" xref="S3.SS4.p12.1.m1.1.1.2.3.cmml">c</mi></msub><mo id="S3.SS4.p12.1.m1.1.1.1" xref="S3.SS4.p12.1.m1.1.1.1.cmml">∈</mo><msup id="S3.SS4.p12.1.m1.1.1.3" xref="S3.SS4.p12.1.m1.1.1.3.cmml"><mi id="S3.SS4.p12.1.m1.1.1.3.2" xref="S3.SS4.p12.1.m1.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS4.p12.1.m1.1.1.3.3" xref="S3.SS4.p12.1.m1.1.1.3.3.cmml"><mtext id="S3.SS4.p12.1.m1.1.1.3.3.2" xref="S3.SS4.p12.1.m1.1.1.3.3.2a.cmml">num_classes</mtext><mo id="S3.SS4.p12.1.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS4.p12.1.m1.1.1.3.3.1.cmml">×</mo><mi id="S3.SS4.p12.1.m1.1.1.3.3.3" xref="S3.SS4.p12.1.m1.1.1.3.3.3.cmml">d</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p12.1.m1.1b"><apply id="S3.SS4.p12.1.m1.1.1.cmml" xref="S3.SS4.p12.1.m1.1.1"><in id="S3.SS4.p12.1.m1.1.1.1.cmml" xref="S3.SS4.p12.1.m1.1.1.1"></in><apply id="S3.SS4.p12.1.m1.1.1.2.cmml" xref="S3.SS4.p12.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS4.p12.1.m1.1.1.2.1.cmml" xref="S3.SS4.p12.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS4.p12.1.m1.1.1.2.2.cmml" xref="S3.SS4.p12.1.m1.1.1.2.2">𝐖</ci><ci id="S3.SS4.p12.1.m1.1.1.2.3.cmml" xref="S3.SS4.p12.1.m1.1.1.2.3">𝑐</ci></apply><apply id="S3.SS4.p12.1.m1.1.1.3.cmml" xref="S3.SS4.p12.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS4.p12.1.m1.1.1.3.1.cmml" xref="S3.SS4.p12.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS4.p12.1.m1.1.1.3.2.cmml" xref="S3.SS4.p12.1.m1.1.1.3.2">ℝ</ci><apply id="S3.SS4.p12.1.m1.1.1.3.3.cmml" xref="S3.SS4.p12.1.m1.1.1.3.3"><times id="S3.SS4.p12.1.m1.1.1.3.3.1.cmml" xref="S3.SS4.p12.1.m1.1.1.3.3.1"></times><ci id="S3.SS4.p12.1.m1.1.1.3.3.2a.cmml" xref="S3.SS4.p12.1.m1.1.1.3.3.2"><mtext id="S3.SS4.p12.1.m1.1.1.3.3.2.cmml" mathsize="70%" xref="S3.SS4.p12.1.m1.1.1.3.3.2">num_classes</mtext></ci><ci id="S3.SS4.p12.1.m1.1.1.3.3.3.cmml" xref="S3.SS4.p12.1.m1.1.1.3.3.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p12.1.m1.1c">\mathbf{W}_{c}\in\mathbb{R}^{\text{num\_classes}\times d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p12.1.m1.1d">bold_W start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT num_classes × italic_d end_POSTSUPERSCRIPT</annotation></semantics></math> is the weight matrix and <math alttext="\mathbf{b}_{c}\in\mathbb{R}^{\text{num\_classes}}" class="ltx_Math" display="inline" id="S3.SS4.p12.2.m2.1"><semantics id="S3.SS4.p12.2.m2.1a"><mrow id="S3.SS4.p12.2.m2.1.1" xref="S3.SS4.p12.2.m2.1.1.cmml"><msub id="S3.SS4.p12.2.m2.1.1.2" xref="S3.SS4.p12.2.m2.1.1.2.cmml"><mi id="S3.SS4.p12.2.m2.1.1.2.2" xref="S3.SS4.p12.2.m2.1.1.2.2.cmml">𝐛</mi><mi id="S3.SS4.p12.2.m2.1.1.2.3" xref="S3.SS4.p12.2.m2.1.1.2.3.cmml">c</mi></msub><mo id="S3.SS4.p12.2.m2.1.1.1" xref="S3.SS4.p12.2.m2.1.1.1.cmml">∈</mo><msup id="S3.SS4.p12.2.m2.1.1.3" xref="S3.SS4.p12.2.m2.1.1.3.cmml"><mi id="S3.SS4.p12.2.m2.1.1.3.2" xref="S3.SS4.p12.2.m2.1.1.3.2.cmml">ℝ</mi><mtext id="S3.SS4.p12.2.m2.1.1.3.3" xref="S3.SS4.p12.2.m2.1.1.3.3a.cmml">num_classes</mtext></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p12.2.m2.1b"><apply id="S3.SS4.p12.2.m2.1.1.cmml" xref="S3.SS4.p12.2.m2.1.1"><in id="S3.SS4.p12.2.m2.1.1.1.cmml" xref="S3.SS4.p12.2.m2.1.1.1"></in><apply id="S3.SS4.p12.2.m2.1.1.2.cmml" xref="S3.SS4.p12.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS4.p12.2.m2.1.1.2.1.cmml" xref="S3.SS4.p12.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS4.p12.2.m2.1.1.2.2.cmml" xref="S3.SS4.p12.2.m2.1.1.2.2">𝐛</ci><ci id="S3.SS4.p12.2.m2.1.1.2.3.cmml" xref="S3.SS4.p12.2.m2.1.1.2.3">𝑐</ci></apply><apply id="S3.SS4.p12.2.m2.1.1.3.cmml" xref="S3.SS4.p12.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS4.p12.2.m2.1.1.3.1.cmml" xref="S3.SS4.p12.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS4.p12.2.m2.1.1.3.2.cmml" xref="S3.SS4.p12.2.m2.1.1.3.2">ℝ</ci><ci id="S3.SS4.p12.2.m2.1.1.3.3a.cmml" xref="S3.SS4.p12.2.m2.1.1.3.3"><mtext id="S3.SS4.p12.2.m2.1.1.3.3.cmml" mathsize="70%" xref="S3.SS4.p12.2.m2.1.1.3.3">num_classes</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p12.2.m2.1c">\mathbf{b}_{c}\in\mathbb{R}^{\text{num\_classes}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p12.2.m2.1d">bold_b start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT num_classes end_POSTSUPERSCRIPT</annotation></semantics></math> is the bias term.</p>
</div>
<div class="ltx_para" id="S3.SS4.p13">
<p class="ltx_p" id="S3.SS4.p13.1">The RTAB module leverages the temporal variation in patient features, helping the model to more accurately predict the risk of future deterioration. The attention-based feature aggregation plays a crucial role in our method, significantly enhancing classification performance, especially in scenarios with limited data.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Experiments</span>
</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS1.4.1.1">IV-A</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS1.5.2">Dataset and Preprocessing</span>
</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">To validate the effectiveness of the DS-ViT Pipeline, we designed two experimental scenarios. The first scenario simulates a situation with ample training data, using the Alzheimer’s Disease Neuroimaging Initiative (ADNI) dataset for training and the Minimal Interval Resonance Imaging in Alzheimer’s Disease (MIRIAD) , Open Access Series of Imaging Studies (OASIS), and Australian Imaging, Biomarker and Lifestyle Flagship Study of Ageing (AIBL) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib17" title="">17</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib18" title="">18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib20" title="">20</a>]</cite> datasets for testing. The second scenario simulates a data-scarce environment, using the MIRIAD dataset for training and the OASIS and AIBL datasets for testing.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">We framed the task as a binary classification task. In certain datasets where three categories are present—Alzheimer’s Disease (AD), Mild Cognitive Impairment (MCI), and Normal Controls (NC)—we excluded the MCI samples, focusing only on AD and NC cases. Evatually, the large training dataset, ADNI, comprises 1,216 NC and 1,110 AD samples. In the small training dataset, MIRIAD, after balancing, we retained 354 NC and 346 AD samples. Since the MIRIAD dataset includes multiple scans from the same patients with identical diagnostic outcomes, we partitioned the training and validation sets at the patient level to mitigate the risk of overfitting and data leakage due to individual patient variability. For the test datasets, AIBL contains 363 NC and 50 AD samples, while OASIS includes 1,692 NC and 465 AD samples.</p>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.4">In the context of the early diagnosis task, due to the constraints of computational resources, we initially set the temporal sequence length to 2, meaning each subject contributes two prior MRI scans. However, this sequence length can be extended to improve accuracy if computational resources allow. All patients for this task were selected from the ADNI dataset. If a patient, initially diagnosed as non-AD, exhibited disease progression in subsequent scans (e.g., NC<math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.SS1.p3.1.m1.1"><semantics id="S4.SS1.p3.1.m1.1a"><mo id="S4.SS1.p3.1.m1.1.1" stretchy="false" xref="S4.SS1.p3.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><ci id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.1.m1.1d">→</annotation></semantics></math>MCI, NC<math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.SS1.p3.2.m2.1"><semantics id="S4.SS1.p3.2.m2.1a"><mo id="S4.SS1.p3.2.m2.1.1" stretchy="false" xref="S4.SS1.p3.2.m2.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.2.m2.1b"><ci id="S4.SS1.p3.2.m2.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.2.m2.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.2.m2.1d">→</annotation></semantics></math>AD, MCI<math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.SS1.p3.3.m3.1"><semantics id="S4.SS1.p3.3.m3.1a"><mo id="S4.SS1.p3.3.m3.1.1" stretchy="false" xref="S4.SS1.p3.3.m3.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.3.m3.1b"><ci id="S4.SS1.p3.3.m3.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.3.m3.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.3.m3.1d">→</annotation></semantics></math>AD), they were classified as at-risk. Conversely, if there was no disease progression (e.g., consistently NC, consistently MCI, or MCI<math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.SS1.p3.4.m4.1"><semantics id="S4.SS1.p3.4.m4.1a"><mo id="S4.SS1.p3.4.m4.1.1" stretchy="false" xref="S4.SS1.p3.4.m4.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.4.m4.1b"><ci id="S4.SS1.p3.4.m4.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.4.m4.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.4.m4.1d">→</annotation></semantics></math>NC), they were classified as safe. After filtering and balancing, we obtained 279 AD and 276 NC patients, with each patient contributing two sequential MRI scans.</p>
</div>
<div class="ltx_para" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1">All MRI images mentioned above underwent consistent data preprocessing techniques to ensure data quality and format uniformity. Specifically, each MRI image was first subjected to bias field correction using the N4ITK algorithm to address intensity inconsistencies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib21" title="">21</a>]</cite>. The images were then aligned to the MNI space via affine registration, using the SyN algorithm from ANTs with the ICBM 2009c nonlinear symmetric template <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib22" title="">22</a>]</cite>. Background regions were removed from the registered images, resulting in a consistent voxel size of 1 mm isotropic. A deep quality control system was employed to verify the registration accuracy, and images with an accuracy below 0.5 were excluded from further analysis <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib23" title="">23</a>]</cite>.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Ablation Study Results in Data-Scarce Scenario</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T2.1.1.1.1" rowspan="2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.1">Model Name</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S4.T2.1.1.1.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.2.1">MIRIAD (val)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S4.T2.1.1.1.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.3.1">AIBL</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S4.T2.1.1.1.4" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.4.1">OASIS</span></th>
</tr>
<tr class="ltx_tr" id="S4.T2.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.2.2.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.2.2.1.1">Acc</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.2.2.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.2.2.2.1">Recall</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.2.2.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.2.2.3.1">Acc</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.2.2.4" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.2.2.4.1">Recall</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.2.2.5" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.2.2.5.1">Acc</span></th>
<th class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.2.2.6" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.2.2.6.1">Recall</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.1.3.1.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.3.1.1.1">DS-ViT</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.3.1.2" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.3.1.2.1">0.899</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.3.1.3" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.3.1.3.1">0.917</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.3.1.4" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.3.1.4.1">0.892</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.3.1.5" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.3.1.5.1">0.879</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.3.1.6" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.3.1.6.1">0.823</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T2.1.3.1.7" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.3.1.7.1">0.847</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.1.4.2.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.4.2.1.1">Hint Layer Distillation</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.1.4.2.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.583</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.4.2.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.539</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.4.2.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.443</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.4.2.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.466</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.4.2.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.315</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.1.4.2.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.404</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.1.5.3.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.5.3.1.1">ADAPT (W/O Seg Stream)</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.1.5.3.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.829</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.5.3.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.856</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.5.3.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.815</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.5.3.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.824</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.5.3.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.761</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.1.5.3.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.802</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.1.6.4.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.6.4.1.1">W/O MRI Stream</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.1.6.4.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.794</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.6.4.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.824</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.6.4.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.733</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.6.4.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.790</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.6.4.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.702</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.1.6.4.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.684</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T2.1.7.5.1" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.1.7.5.1.1">W/O Dual-stream Emb</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.7.5.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.647</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.7.5.3" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.661</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.7.5.4" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.638</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.7.5.5" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.644</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.7.5.6" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.572</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="S4.T2.1.7.5.7" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.508</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS2.4.1.1">IV-B</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS2.5.2">Evaluation</span>
</h3>
<section class="ltx_subsubsection" id="S4.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S4.SS2.SSS1.4.1.1">IV-B</span>1 </span>Evaluation on DS-ViT Pipeline</h4>
<div class="ltx_para" id="S4.SS2.SSS1.p1">
<p class="ltx_p" id="S4.SS2.SSS1.p1.1">We conducted a series of experiments to assess the performance improvements of the DS-ViT pipeline over baseline models and to validate the effectiveness of each component within our approach. Two sets of experiments were designed to evaluate the model under data-sufficient and data-scarce scenarios.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p2">
<p class="ltx_p" id="S4.SS2.SSS1.p2.1">In the first set of comparative experiments, we evaluated the performance of DS-ViT against several baseline models, including ADAPT, Uni4Eye, I3D, MedicalNet, 3D ResNet, and 3D DenseNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#bib.bib14" title="">14</a>]</cite>. These models were tested under two conditions: a data-sufficient scenario where the models were trained on the ADNI dataset, and a data-scarce scenario where the models were trained on the MIRIAD dataset. The results of these experiments are presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#S3.T1" title="TABLE I ‣ III-C DS-ViT for Early Diagnosis Pipeline ‣ III Methods ‣ DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis"><span class="ltx_text ltx_ref_tag">I</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p3">
<p class="ltx_p" id="S4.SS2.SSS1.p3.1">In the second set of ablation studies, five experiments were conducted to determine the necessity of each component in our proposed approach:</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p4">
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i1.p1.1.1">DS-ViT</span>: The control group, used to evaluate the performance improvements achieved by DS-ViT.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i2.p1.1.1">Hint Layer Distillation</span>: Applied a traditional distillation method to assess the necessity of our innovations.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i3.p1.1.1">ADAPT</span>: Simulated a single-stream input scenario without the segmentation input, to evaluate the impact of excluding segmentation data.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i4.p1">
<p class="ltx_p" id="S4.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i4.p1.1.1">W/O MRI Stream</span>: Simulated a single-stream input scenario without the MRI image input, to test the importance of including MRI data.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i5.p1">
<p class="ltx_p" id="S4.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i5.p1.1.1">W/O Dual-Stream Embedding</span>: Applied pixel-based embedding to both streams before feature fusion, to validate the advantages of the dual-stream embedding strategy.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p5">
<p class="ltx_p" id="S4.SS2.SSS1.p5.1">Accuracy and recall were used as the primary evaluation metrics, reflecting the overall classification performance and the model’s sensitivity to detecting diseased samples, respectively. The results of these experiments are detailed in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#S4.T2" title="TABLE II ‣ IV-A Dataset and Preprocessing ‣ IV Experiments ‣ DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis"><span class="ltx_text ltx_ref_tag">II</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p6">
<p class="ltx_p" id="S4.SS2.SSS1.p6.1">From the data presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#S3.T1" title="TABLE I ‣ III-C DS-ViT for Early Diagnosis Pipeline ‣ III Methods ‣ DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis"><span class="ltx_text ltx_ref_tag">I</span></a>, it is evident that DS-ViT consistently outperforms the baseline models across all datasets, demonstrating the effectiveness of our approach. Notably, when trained on small datasets (e.g., MIRIAD), DS-ViT achieved a performance improvement of 7% over its base model, ADAPT. Additionally, DS-ViT typically converges within approximately 15 epochs, whereas ADAPT requires 30 to 60 epochs to reach convergence. These results suggest that the DS-ViT pipeline significantly enhances both the accuracy and training efficiency of the baseline model, with the improvements being particularly pronounced under conditions of limited training data.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p7">
<p class="ltx_p" id="S4.SS2.SSS1.p7.1">Furthermore, as shown in the ablation study results in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#S4.T2" title="TABLE II ‣ IV-A Dataset and Preprocessing ‣ IV Experiments ‣ DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis"><span class="ltx_text ltx_ref_tag">II</span></a>, DS-ViT achieved a 33% higher accuracy compared to the traditional distillation method (Hint Layer Distillation), highlighting the effectiveness of our innovation. The comparison between DS-ViT and the single-stream input groups (W/O MRI Stream and W/O Segmentation Stream) indicates that the dual-stream fusion consistently yields better results than using either stream alone, thereby validating the necessity of cross-task learning through dual-stream input. Similarly, the comparison between DS-ViT and the W/O Dual-Stream Embedding experiment confirms that our dual-stream embedding strategy, specifically designed for handling different types of inputs, is highly effective.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S4.SS2.SSS2.4.1.1">IV-B</span>2 </span>Evaluation on Early Diagnosis</h4>
<div class="ltx_para" id="S4.SS2.SSS2.p1">
<p class="ltx_p" id="S4.SS2.SSS2.p1.1">For the early diagnosis task, since no existing models have been designed to incorporate temporal sequences of multiple MRI images for this purpose, we primarily rely on our experimental results to assess the performance. We conducted four experiments:</p>
<ul class="ltx_itemize" id="S4.I2">
<li class="ltx_item" id="S4.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i1.p1">
<p class="ltx_p" id="S4.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i1.p1.1.1">DS-ViT+RTAB (Experimental Group)</span>: This configuration combines DS-ViT with RTAB to evaluate the performance of our enhanced pipeline.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i2.p1">
<p class="ltx_p" id="S4.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i2.p1.1.1">DS-ViT (Single-Timepoint)</span>: This variant uses only the most recent MRI scan to predict the diagnosis of the next examination, allowing us to assess the necessity of incorporating multiple time-point inputs.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i3.p1">
<p class="ltx_p" id="S4.I2.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i3.p1.1.1">DS-ViT+SVM</span>: DS-ViT is used as the feature extractor, with the extracted high-dimensional features classified using a Support Vector Machine (SVM), to validate the superiority of RTAB over traditional classifiers.</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i4.p1">
<p class="ltx_p" id="S4.I2.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i4.p1.1.1">DS-ViT+ResNet</span>: Similarly, DS-ViT is used as the feature extractor, but the extracted features are classified using a ResNet model, further testing the effectiveness of RTAB.</p>
</div>
</li>
</ul>
</div>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE III: </span>Ablation Experiments to Validate the Superiority of RTAB</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T3.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.1">Model Name</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T3.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.2.1">Accuracy</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T3.1.2.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.2.1.1.1">DS-ViT+RTAB</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.1.2.1.2"><span class="ltx_text ltx_font_bold" id="S4.T3.1.2.1.2.1">0.704</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T3.1.3.2.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.3.2.1.1">DS-ViT</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.1.3.2.2">0.560</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T3.1.4.3.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.4.3.1.1">DS-ViT+SVM</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.1.4.3.2">0.603</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S4.T3.1.5.4.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.5.4.1.1">DS-ViT+ResNet</span></th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.1.5.4.2">0.614</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S4.SS2.SSS2.p2">
<p class="ltx_p" id="S4.SS2.SSS2.p2.1">As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.07584v1#S4.T3" title="TABLE III ‣ IV-B2 Evaluation on Early Diagnosis ‣ IV-B Evaluation ‣ IV Experiments ‣ DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer’s Early Diagnosis"><span class="ltx_text ltx_ref_tag">III</span></a>, the DS-ViT+RTAB configuration achieved the highest accuracy among all tested methods and ablation experiments, demonstrating the superiority of the DS-ViT pipeline when combined with the RTAB module, as well as the potential for early prediction of Alzheimer’s disease. However, the overall accuracy was only 70.4%, prompting a deeper analysis of the DS-ViT+RTAB results. We found that the majority of misclassifications occurred in samples where the model’s confidence was relatively low. When we focused on high-confidence samples—those with predicted probabilities of 70–100% for one class and 0–30% for the other—the accuracy increased to 86%. This suggests that our model can provide reliable recommendations for patients in cases where it exhibits high confidence.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.p3">
<p class="ltx_p" id="S4.SS2.SSS2.p3.1">Upon further analysis, we found that for the selected 555 patients, the average interval between the two MRI scans used was approximately 6 months. This indicates that when our model confidently identifies a patient as at risk, it offers the possibility of initiating treatment up to 6 months earlier, allowing for preventive measures and interventions before the disease significantly progresses.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Conclusions</span>
</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this paper, we proposed the Dual-Stream Vision Transformer (DS-ViT) pipeline, a novel approach designed to integrate segmentation and classification tasks for enhanced performance in Alzheimer’s disease diagnosis. By leveraging the robust segmentation capabilities of FastSurfer and incorporating a dual-stream embedding mechanism, our approach successfully bridges the gap between distinct tasks and architectures, resulting in improved classification accuracy and training efficiency, particularly in data-scarce scenarios.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">Our experiments demonstrated that DS-ViT consistently outperforms the baseline models across various datasets, achieving significant gains in accuracy while reducing convergence time. The introduction of the Residual Temporal Attention Block (RTAB) further extends the application of DS-ViT to early diagnosis, offering a clinically valuable tool for predicting Alzheimer’s disease progression up to 6 months in advance. Our methods not only improve diagnostic accuracy but also provide a critical window for early intervention, potentially altering the course of the disease for high-risk patients.</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">The contributions of this work are multifaceted: (1) the successful integration of segmentation knowledge into a classification framework, (2) the validation of dual-stream embedding and 3D Bottleneck MLP structures as effective components for cross-task knowledge sharing, and (3) the extension of these techniques to the early diagnosis of Alzheimer’s disease, providing the opportunities for prevention and early treatment.</p>
</div>
<div class="ltx_para" id="S5.p4">
<p class="ltx_p" id="S5.p4.1">Future work will focus on further enhancing the temporal modeling capabilities of DS-ViT by increasing the sequence length of input MRI scans and exploring the application of our pipeline to other neurodegenerative diseases. Additionally, we aim to refine our attention mechanisms to better handle low-confidence cases, thus broadening the practical applicability of our model in diverse clinical settings.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"> E. Passeri, K. Elkhoury, M. Morsink, K. Broersen, M. Linder, A. Tamayol, C. Malaplate, F. T. Yen, and E. Arab-Tehrany, “Alzheimer’s disease: Treatment strategies and their limitations,” <span class="ltx_text ltx_font_italic" id="bib.bib1.1.1">International Journal of Molecular Sciences</span>, vol. 23, no. 22, p. 13954, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"> J. L. Cummings, G. Tong, and C. Ballard, “Treatment combinations for Alzheimer’s disease: Current and future pharmacotherapy options,” <span class="ltx_text ltx_font_italic" id="bib.bib2.1.1">Journal of Alzheimer’s Disease</span>, vol. 67, no. 3, pp. 779–794, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"> D. Bertens, D. L. Knol, P. Scheltens, P. J. Visser, et al. “Temporal evolution of biomarkers and cognitive markers in the asymptomatic, MCI, and dementia stage of Alzheimer’s disease,” <span class="ltx_text ltx_font_italic" id="bib.bib3.1.1">Alzheimer’s &amp; Dementia</span>, vol. 11, no. 5, pp. 511–522, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"> Y. Zhou, Y. Li, F. Zhou, Y. Liu, and L. Tu, “Learning with domain-knowledge for generalizable prediction of Alzheimer’s disease from multi-site structural MRI,” in <span class="ltx_text ltx_font_italic" id="bib.bib4.1.1">Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent.</span>, 2023, pp. 452–461.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"> K. A. Johnson, N. C. Fox, R. A. Sperling, and W. E. Klunk, “Brain imaging in Alzheimer disease,” <span class="ltx_text ltx_font_italic" id="bib.bib5.1.1">Cold Spring Harbor Perspectives in Medicine</span>, vol. 2, no. 4, p. a006213, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"> L. Henschel, S. Conjeti, S. Estrada, K. Diers, B. Fischl, and M. Reuter, “Fastsurfer—a fast and accurate deep learning based neuroimaging pipeline,” <span class="ltx_text ltx_font_italic" id="bib.bib6.1.1">NeuroImage</span>, vol. 219, p. 117012, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"> Y. Wang, K. Chen and H. Wang. “ADAPT: Alzheimer’s Diagnosis through Adaptive Profiling Transformers.” arXiv preprint arXiv: Jan 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"> H. Touvron, M. Cord, M. Douze, F. Massa, A. Sablayrolles, and H. Jégou, “Training data-efficient image transformers &amp; distillation through attention,” in <span class="ltx_text ltx_font_italic" id="bib.bib8.1.1">Proc. Int. Conf. Mach. Learn.</span>, 2021, pp. 10347–10357.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"> M. F. Mendez, M. Ghajarania, and K. M. Perryman, “Posterior cortical atrophy: Clinical characteristics and differences compared to Alzheimer’s disease,” <span class="ltx_text ltx_font_italic" id="bib.bib9.1.1">Dementia and Geriatric Cognitive Disorders</span>, vol. 14, no. 1, pp. 33–40, 2002.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"> Z. Cai, L. Lin, H. He, and X. Tang, “Uni4Eye: Unified 2D and 3D self-supervised pre-training via masked image modeling transformer for ophthalmic image classification,” in <span class="ltx_text ltx_font_italic" id="bib.bib10.1.1">Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent.</span>, 2022, pp. 88–98.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"> J. Carreira and A. Zisserman, “Quo vadis, action recognition? A new model and the Kinetics dataset,” in <span class="ltx_text ltx_font_italic" id="bib.bib11.1.1">Proc. IEEE Conf. Comput. Vis. Pattern Recognit.</span>, 2017, pp. 6299–6308.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"> S. Chen, K. Ma, and Y. Zheng, “Med3D: Transfer learning for 3D medical image analysis,” <span class="ltx_text ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:1904.00625</span>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"> K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image recognition,” in <span class="ltx_text ltx_font_italic" id="bib.bib13.1.1">Proc. IEEE Conf. Comput. Vis. Pattern Recognit.</span>, 2016, pp. 770–778.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"> G. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger, “Densely connected convolutional networks,” in <span class="ltx_text ltx_font_italic" id="bib.bib14.1.1">Proc. IEEE Conf. Comput. Vis. Pattern Recognit.</span>, 2017, pp. 4700–4708.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"> G. Aguilar, Y. Ling, Y. Zhang, B. Yao, X. Fan, and C. Guo, “Knowledge distillation from internal representations,” in <span class="ltx_text ltx_font_italic" id="bib.bib15.1.1">Proc. AAAI Conf. Artif. Intell.</span>, vol. 34, no. 05, pp. 7350–7357, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"> Z. Liu, J. Li, Z. Shen, G. Huang, S. Yan, and C. Zhang, “Learning efficient convolutional networks through network slimming,” in <span class="ltx_text ltx_font_italic" id="bib.bib16.1.1">Proc. IEEE Int. Conf. Comput. Vis.</span>, 2017, pp. 2736–2744.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"> C. R. Jack Jr, M. A. Bernstein, N. C. Fox, P. Thompson, G. Alexander, D. Harvey, B. Borowski, P. J. Britson, J. L. Whitwell, C. Ward, <span class="ltx_text ltx_font_italic" id="bib.bib17.1.1">et al.</span>, “The Alzheimer’s disease neuroimaging initiative (ADNI): MRI methods,” <span class="ltx_text ltx_font_italic" id="bib.bib17.2.2">Journal of Magnetic Resonance Imaging</span>, vol. 27, no. 4, pp. 685–691, 2008.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"> I. B. Malone, D. Cash, G. R. Ridgway, D. G. MacManus, S. Ourselin, N. C. Fox, and J. M. Schott, “MIRIAD—Public release of a multiple time point Alzheimer’s MR imaging dataset,” <span class="ltx_text ltx_font_italic" id="bib.bib18.1.1">NeuroImage</span>, vol. 70, pp. 33–36, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"> P. J. LaMontagne, T. L. S. Benzinger, J. C. Morris, S. Keefe, R. Hornbeck, C. Xiong, E. Grant, J. Hassenstab, K. Moulder, A. G. Vlassenko, <span class="ltx_text ltx_font_italic" id="bib.bib19.1.1">et al.</span>, “OASIS-3: Longitudinal neuroimaging, clinical, and cognitive dataset for normal aging and Alzheimer disease,” <span class="ltx_text ltx_font_italic" id="bib.bib19.2.2">medRxiv</span>, p. 2019.12, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"> K. A. Ellis, A. I. Bush, D. Darby, D. De Fazio, J. Foster, P. Hudson, N. T. Lautenschlager, N. Lenzo, R. N. Martins, P. Maruff, <span class="ltx_text ltx_font_italic" id="bib.bib20.1.1">et al.</span>, “The Australian Imaging, Biomarkers and Lifestyle (AIBL) study of aging: Methodology and baseline characteristics of 1112 individuals recruited for a longitudinal study of Alzheimer’s disease,” <span class="ltx_text ltx_font_italic" id="bib.bib20.2.2">International Psychogeriatrics</span>, vol. 21, no. 4, pp. 672–687, 2009.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"> N. J. Tustison, B. B. Avants, P. A. Cook, Y. Zheng, A. Egan, P. A. Yushkevich, and J. C. Gee, “N4ITK: Improved N3 bias correction,” <span class="ltx_text ltx_font_italic" id="bib.bib21.1.1">IEEE Transactions on Medical Imaging</span>, vol. 29, no. 6, pp. 1310–1320, 2010.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"> B. B. Avants, N. J. Tustison, M. Stauffer, G. Song, B. Wu, and J. C. Gee, “The Insight ToolKit image registration framework,” <span class="ltx_text ltx_font_italic" id="bib.bib22.1.1">Frontiers in Neuroinformatics</span>, vol. 8, p. 44, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"> V. S. Fonov, M. Dadar, Prevent-Ad Research Group, and D. L. Collins, “Deep learning of quality control for stereotaxic registration of human brain MRI,” <span class="ltx_text ltx_font_italic" id="bib.bib23.1.1">bioRxiv</span>, p. 303487, 2018.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Sep 11 17:45:11 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
