<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2310.00109] FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things</title><meta property="og:description" content="There is a significant relevance of federated learning (FL) in the realm of Artificial Intelligence of Things (AIoT). However, most of existing FL works are not conducted on datasets collected from authentic IoT device…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2310.00109">

<!--Generated on Wed Feb 28 03:27:36 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Samiul Alam<sup id="id17.17.id1" class="ltx_sup"><span id="id17.17.id1.1" class="ltx_text ltx_font_italic">1,2</span></sup>, Tuo Zhang<sup id="id18.18.id2" class="ltx_sup"><span id="id18.18.id2.1" class="ltx_text ltx_font_italic">3</span></sup>, Tiantian Feng<sup id="id19.19.id3" class="ltx_sup"><span id="id19.19.id3.1" class="ltx_text ltx_font_italic">3</span></sup>, Hui Shen<sup id="id20.20.id4" class="ltx_sup"><span id="id20.20.id4.1" class="ltx_text ltx_font_italic">1</span></sup>, 
<br class="ltx_break"><span id="id8.8.4" class="ltx_text ltx_font_bold">Zhichao Cao<sup id="id8.8.4.1" class="ltx_sup"><span id="id8.8.4.1.1" class="ltx_text ltx_font_medium ltx_font_italic">2</span></sup>, Dong Zhao<sup id="id8.8.4.2" class="ltx_sup"><span id="id8.8.4.2.1" class="ltx_text ltx_font_medium ltx_font_italic">2</span></sup>, JeongGil Ko<sup id="id8.8.4.3" class="ltx_sup"><span id="id8.8.4.3.1" class="ltx_text ltx_font_medium ltx_font_italic">4</span></sup>, Kiran Somasundaram<sup id="id8.8.4.4" class="ltx_sup"><span id="id8.8.4.4.1" class="ltx_text ltx_font_medium ltx_font_italic">5</span></sup>,</span> 
<br class="ltx_break"><span id="id11.11.7" class="ltx_text ltx_font_bold">Shrikanth S. Narayanan<sup id="id11.11.7.1" class="ltx_sup"><span id="id11.11.7.1.1" class="ltx_text ltx_font_medium ltx_font_italic">3</span></sup>, Salman Avestimehr<sup id="id11.11.7.2" class="ltx_sup"><span id="id11.11.7.2.1" class="ltx_text ltx_font_medium ltx_font_italic">3</span></sup>, Mi Zhang<sup id="id11.11.7.3" class="ltx_sup"><span id="id11.11.7.3.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup></span>

<br class="ltx_break"> <sup id="id21.21.id5" class="ltx_sup">1</sup>The Ohio State University, <sup id="id22.22.id6" class="ltx_sup">2</sup>Michigan State University, 
<br class="ltx_break"> <sup id="id23.23.id7" class="ltx_sup">3</sup>University of Southern California, <sup id="id24.24.id8" class="ltx_sup">4</sup>Yonsei University, <sup id="id25.25.id9" class="ltx_sup">5</sup>Meta 
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id26.id1" class="ltx_p">There is a significant relevance of federated learning (FL) in the realm of Artificial Intelligence of Things (AIoT). However, most of existing FL works are not conducted on datasets collected from authentic IoT devices that capture unique modalities and inherent challenges of IoT data.
In this work, we introduce <span id="id26.id1.1" class="ltx_text ltx_font_typewriter">FedAIoT</span>, an FL benchmark for AIoT to fill this critical gap. <span id="id26.id1.2" class="ltx_text ltx_font_typewriter">FedAIoT</span> includes eight datatsets collected from a wide range of IoT devices. These datasets cover unique IoT modalities and target representative applications of AIoT. <span id="id26.id1.3" class="ltx_text ltx_font_typewriter">FedAIoT</span> also includes a unified end-to-end FL framework for AIoT that simplifies benchmarking the performance of the datasets. Our benchmark results shed light on the opportunities and challenges of FL for AIoT. We hope <span id="id26.id1.4" class="ltx_text ltx_font_typewriter">FedAIoT</span> could serve as an invaluable resource to foster advancements in the important field of FL for AIoT.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The proliferation of the Internet of Things (IoT) such as smartphones, smartwatches, drones, and sensors deployed at homes, and the gigantic amount of data they collect have revolutionized the way we work, live, and interact with the world <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">nizetic2020iot</span>]</cite>.
The advances in Artificial Intelligence (AI) have boosted the integration of IoT and AI that turns Artificial Intelligence of Things (AIoT) into reality.
However, data collected by IoT devices usually contain privacy-sensitive information.
In recent years, federated learning (FL) has emerged as a privacy-preserving solution that enables extracting knowledge from the collected data while keeping the data on the devices <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mcmahan2017communication</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Zhang2021FederatedLF</span>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Despite the significant relevance of FL in the realm of AIoT, a majority of existing FL works are conducted on well-known datasets such as CIFAR-10 and CIFAR-100. <span id="S1.p2.1.1" class="ltx_text ltx_font_italic">These datasets, however, do not originate from authentic IoT devices and thus fail to capture the unique modalities and inherent challenges associated with real-world IoT data</span>. This notable discrepancy underscores a strong need for an IoT-oriented FL benchmark to fill this critical gap.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2310.00109/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="160" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.3.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.4.2" class="ltx_text" style="font-size:90%;">Overview of <span id="S1.F1.4.2.1" class="ltx_text ltx_font_typewriter">FedAIoT</span>.</span></figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In this paper, we present <span id="S1.p3.1.1" class="ltx_text ltx_font_typewriter">FedAIoT</span>, an FL benchmark for AIoT.
At its core, <span id="S1.p3.1.2" class="ltx_text ltx_font_typewriter">FedAIoT</span> includes eight well-chosen datasets collected from a wide range of <span id="S1.p3.1.3" class="ltx_text ltx_font_italic">authentic IoT devices</span> from smartwatch, smartphone and Wi-Fi routers, to drones, smart home sensors, and head-mounted device that either have already become an indispensable part of people’s daily lives or are driving emerging applications.
These datasets encapsulate a variety of <span id="S1.p3.1.4" class="ltx_text ltx_font_italic">unique modalities</span> from drone images and audios captured from head-mounted devices to wireless signals and smart home sensors that have not been explored in existing FL benchmarks.
Moreover, these datasets target some of the <span id="S1.p3.1.5" class="ltx_text ltx_font_italic">most representative applications</span> of AIoT as well as <span id="S1.p3.1.6" class="ltx_text ltx_font_italic">innovative use cases</span> of AIoT that are not possible with other technologies.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">To facilitate the community benchmark the performance of the datasets and ensure reproducibility, <span id="S1.p4.1.1" class="ltx_text ltx_font_typewriter">FedAIoT</span> includes a <span id="S1.p4.1.2" class="ltx_text ltx_font_italic">unified end-to-end FL framework for AIoT</span> that covers the complete FL-for-AIoT pipeline: from non-IID data partitioning, data preprocessing, to AIoT-friendly models, FL hyperparameters, and IoT-factor emulator.
Our framework also includes the <span id="S1.p4.1.3" class="ltx_text ltx_font_italic">implementations</span> of popular schemes, models, and techniques involved in each stage of the FL-for-AIoT pipeline.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">We have conducted a systematic benchmarking on the eight datasets using the end-to-end framework.
Specifically, we examine the impact of varying degrees of non-IID data distributions, FL optimizers, and client sampling ratios on the performance of FL.
We also evaluate the impact of erroneous labels, a prevalent challenge in IoT datasets, as well as the effects of quantized training, a technique that tackles the practical limitation of resource-constrained IoT devices.
Our benchmark results provide valuable insights on both the opportunities and challenges of FL for AIoT.
Given the significant relevance of FL in the realm of AIoT, we hope <span id="S1.p5.1.1" class="ltx_text ltx_font_typewriter">FedAIoT</span> could act as a valuable tool to foster advancements in the important area of FL for AIoT.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">The importance of data to FL research pushes the development of FL benchmarks on a variety of data modalities.
Existing FL benchmarks, however, predominantly center around curating federated datasets in the domain of computer vision (CV) <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">he2021fedcv</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">caldas2018leaf</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Song2022FLAIRFL</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">lai2022fedscale</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Dimitriadis2022FLUTEAS</span>]</cite>, natural language processing (NLP) <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">lin2021fednlp</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">caldas2018leaf</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">lai2022fedscale</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Dimitriadis2022FLUTEAS</span>]</cite>, medical imaging <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">terrail2022flamby</span>]</cite>, speech and audio <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2023fedaudio</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Dimitriadis2022FLUTEAS</span>]</cite>, and graph neural networks <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">he2021fedgraphnn</span>]</cite>.
For example, LEAF <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">caldas2018leaf</span>]</cite> is one of the earliest FL benchmarks which comprises six datasets dedicated to CV and NLP; FedCV <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">he2021fedcv</span>]</cite>, FedNLP <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">lin2021fednlp</span>]</cite>, and FedAudio <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2023fedaudio</span>]</cite> focuses on CV, NLP, and audio-related datasets and tasks respectively; FedScale <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">lai2022fedscale</span>]</cite> provides an assortment of <math id="S2.p1.1.m1.1" class="ltx_Math" alttext="20" display="inline"><semantics id="S2.p1.1.m1.1a"><mn id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><cn type="integer" id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">20</annotation></semantics></math> federated datasets mainly in CV and NLP applications, placing a distinct emphasis on system-related aspects; FLUTE <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Dimitriadis2022FLUTEAS</span>]</cite> covers a mix of datasets from CV, NLP, and audio; and FLamby <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">terrail2022flamby</span>]</cite> presents seven healthcare-related datasets including five medical imaging datasets.
Although these benchmarks have significantly contributed to FL research, a dedicated FL benchmark explicitly tailored for IoT data is absent.
<span id="S2.p1.1.1" class="ltx_text ltx_font_typewriter">FedAIoT</span> is specifically designed to fill this critical gap by providing a dedicated benchmark that focuses on data collected by a wide range of authentic IoT devices.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Design of FedAIoT</h2>

<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.19.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S3.T1.20.2" class="ltx_text" style="font-size:90%;">Overview of the datasets included in <span id="S3.T1.20.2.1" class="ltx_text ltx_font_typewriter">FedAIoT</span>.</span></figcaption>
<div id="S3.T1.16" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:228.2pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-143.6pt,75.4pt) scale(0.601575848733492,0.601575848733492) ;">
<table id="S3.T1.16.16" class="ltx_tabular ltx_align_middle">
<tr id="S3.T1.16.16.17" class="ltx_tr">
<td id="S3.T1.16.16.17.1" class="ltx_td ltx_align_center"><span id="S3.T1.16.16.17.1.1" class="ltx_text ltx_font_bold">Dataset</span></td>
<td id="S3.T1.16.16.17.2" class="ltx_td ltx_align_left"><span id="S3.T1.16.16.17.2.1" class="ltx_text ltx_font_bold">IoT Platform</span></td>
<td id="S3.T1.16.16.17.3" class="ltx_td ltx_align_left"><span id="S3.T1.16.16.17.3.1" class="ltx_text ltx_font_bold">Data Modality</span></td>
<td id="S3.T1.16.16.17.4" class="ltx_td ltx_align_center"><span id="S3.T1.16.16.17.4.1" class="ltx_text ltx_font_bold">Data Dimension</span></td>
<td id="S3.T1.16.16.17.5" class="ltx_td ltx_align_center"><span id="S3.T1.16.16.17.5.1" class="ltx_text ltx_font_bold">Dataset Size</span></td>
<td id="S3.T1.16.16.17.6" class="ltx_td ltx_align_left"><span id="S3.T1.16.16.17.6.1" class="ltx_text ltx_font_bold"># Training Samples</span></td>
<td id="S3.T1.16.16.17.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:0.0pt;">
<span id="S3.T1.16.16.17.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.16.16.17.7.1.1" class="ltx_p"><span id="S3.T1.16.16.17.7.1.1.1" class="ltx_text ltx_font_bold"># Clients</span></span>
</span>
</td>
</tr>
<tr id="S3.T1.16.16.18" class="ltx_tr">
<td id="S3.T1.16.16.18.1" class="ltx_td ltx_align_center">WISDM-W <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">weiss2019wisdm</span>]</cite>
</td>
<td id="S3.T1.16.16.18.2" class="ltx_td ltx_align_left">Smartwatch</td>
<td id="S3.T1.16.16.18.3" class="ltx_td ltx_align_left">Accelerometer</td>
<td id="S3.T1.16.16.18.4" class="ltx_td"></td>
<td id="S3.T1.16.16.18.5" class="ltx_td"></td>
<td id="S3.T1.16.16.18.6" class="ltx_td"></td>
<td id="S3.T1.16.16.18.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:0.0pt;"></td>
</tr>
<tr id="S3.T1.2.2.2" class="ltx_tr">
<td id="S3.T1.2.2.2.3" class="ltx_td ltx_align_right">Gyroscope</td>
<td id="S3.T1.1.1.1.1" class="ltx_td ltx_align_left"><math id="S3.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="200\times 6" display="inline"><semantics id="S3.T1.1.1.1.1.m1.1a"><mrow id="S3.T1.1.1.1.1.m1.1.1" xref="S3.T1.1.1.1.1.m1.1.1.cmml"><mn id="S3.T1.1.1.1.1.m1.1.1.2" xref="S3.T1.1.1.1.1.m1.1.1.2.cmml">200</mn><mo lspace="0.222em" rspace="0.222em" id="S3.T1.1.1.1.1.m1.1.1.1" xref="S3.T1.1.1.1.1.m1.1.1.1.cmml">×</mo><mn id="S3.T1.1.1.1.1.m1.1.1.3" xref="S3.T1.1.1.1.1.m1.1.1.3.cmml">6</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.1.m1.1b"><apply id="S3.T1.1.1.1.1.m1.1.1.cmml" xref="S3.T1.1.1.1.1.m1.1.1"><times id="S3.T1.1.1.1.1.m1.1.1.1.cmml" xref="S3.T1.1.1.1.1.m1.1.1.1"></times><cn type="integer" id="S3.T1.1.1.1.1.m1.1.1.2.cmml" xref="S3.T1.1.1.1.1.m1.1.1.2">200</cn><cn type="integer" id="S3.T1.1.1.1.1.m1.1.1.3.cmml" xref="S3.T1.1.1.1.1.m1.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.1.m1.1c">200\times 6</annotation></semantics></math></td>
<td id="S3.T1.2.2.2.4" class="ltx_td ltx_align_left">294 MB</td>
<td id="S3.T1.2.2.2.2" class="ltx_td ltx_align_center"><math id="S3.T1.2.2.2.2.m1.2" class="ltx_Math" alttext="16,569" display="inline"><semantics id="S3.T1.2.2.2.2.m1.2a"><mrow id="S3.T1.2.2.2.2.m1.2.3.2" xref="S3.T1.2.2.2.2.m1.2.3.1.cmml"><mn id="S3.T1.2.2.2.2.m1.1.1" xref="S3.T1.2.2.2.2.m1.1.1.cmml">16</mn><mo id="S3.T1.2.2.2.2.m1.2.3.2.1" xref="S3.T1.2.2.2.2.m1.2.3.1.cmml">,</mo><mn id="S3.T1.2.2.2.2.m1.2.2" xref="S3.T1.2.2.2.2.m1.2.2.cmml">569</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.2.2.m1.2b"><list id="S3.T1.2.2.2.2.m1.2.3.1.cmml" xref="S3.T1.2.2.2.2.m1.2.3.2"><cn type="integer" id="S3.T1.2.2.2.2.m1.1.1.cmml" xref="S3.T1.2.2.2.2.m1.1.1">16</cn><cn type="integer" id="S3.T1.2.2.2.2.m1.2.2.cmml" xref="S3.T1.2.2.2.2.m1.2.2">569</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.2.2.m1.2c">16,569</annotation></semantics></math></td>
<td id="S3.T1.2.2.2.5" class="ltx_td ltx_align_center">80</td>
<td id="S3.T1.2.2.2.6" class="ltx_td"></td>
<td id="S3.T1.2.2.2.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:0.0pt;"></td>
</tr>
<tr id="S3.T1.16.16.19" class="ltx_tr">
<td id="S3.T1.16.16.19.1" class="ltx_td ltx_align_center">WISDM-P <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">weiss2019wisdm</span>]</cite>
</td>
<td id="S3.T1.16.16.19.2" class="ltx_td ltx_align_left">Smartphone</td>
<td id="S3.T1.16.16.19.3" class="ltx_td ltx_align_left">Accelerometer</td>
<td id="S3.T1.16.16.19.4" class="ltx_td"></td>
<td id="S3.T1.16.16.19.5" class="ltx_td"></td>
<td id="S3.T1.16.16.19.6" class="ltx_td"></td>
<td id="S3.T1.16.16.19.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:0.0pt;"></td>
</tr>
<tr id="S3.T1.4.4.4" class="ltx_tr">
<td id="S3.T1.4.4.4.3" class="ltx_td ltx_align_right">Gyroscope</td>
<td id="S3.T1.3.3.3.1" class="ltx_td ltx_align_left"><math id="S3.T1.3.3.3.1.m1.1" class="ltx_Math" alttext="200\times 6" display="inline"><semantics id="S3.T1.3.3.3.1.m1.1a"><mrow id="S3.T1.3.3.3.1.m1.1.1" xref="S3.T1.3.3.3.1.m1.1.1.cmml"><mn id="S3.T1.3.3.3.1.m1.1.1.2" xref="S3.T1.3.3.3.1.m1.1.1.2.cmml">200</mn><mo lspace="0.222em" rspace="0.222em" id="S3.T1.3.3.3.1.m1.1.1.1" xref="S3.T1.3.3.3.1.m1.1.1.1.cmml">×</mo><mn id="S3.T1.3.3.3.1.m1.1.1.3" xref="S3.T1.3.3.3.1.m1.1.1.3.cmml">6</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.3.1.m1.1b"><apply id="S3.T1.3.3.3.1.m1.1.1.cmml" xref="S3.T1.3.3.3.1.m1.1.1"><times id="S3.T1.3.3.3.1.m1.1.1.1.cmml" xref="S3.T1.3.3.3.1.m1.1.1.1"></times><cn type="integer" id="S3.T1.3.3.3.1.m1.1.1.2.cmml" xref="S3.T1.3.3.3.1.m1.1.1.2">200</cn><cn type="integer" id="S3.T1.3.3.3.1.m1.1.1.3.cmml" xref="S3.T1.3.3.3.1.m1.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.3.1.m1.1c">200\times 6</annotation></semantics></math></td>
<td id="S3.T1.4.4.4.4" class="ltx_td ltx_align_left">253 MB</td>
<td id="S3.T1.4.4.4.2" class="ltx_td ltx_align_center"><math id="S3.T1.4.4.4.2.m1.2" class="ltx_Math" alttext="13,714" display="inline"><semantics id="S3.T1.4.4.4.2.m1.2a"><mrow id="S3.T1.4.4.4.2.m1.2.3.2" xref="S3.T1.4.4.4.2.m1.2.3.1.cmml"><mn id="S3.T1.4.4.4.2.m1.1.1" xref="S3.T1.4.4.4.2.m1.1.1.cmml">13</mn><mo id="S3.T1.4.4.4.2.m1.2.3.2.1" xref="S3.T1.4.4.4.2.m1.2.3.1.cmml">,</mo><mn id="S3.T1.4.4.4.2.m1.2.2" xref="S3.T1.4.4.4.2.m1.2.2.cmml">714</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.4.2.m1.2b"><list id="S3.T1.4.4.4.2.m1.2.3.1.cmml" xref="S3.T1.4.4.4.2.m1.2.3.2"><cn type="integer" id="S3.T1.4.4.4.2.m1.1.1.cmml" xref="S3.T1.4.4.4.2.m1.1.1">13</cn><cn type="integer" id="S3.T1.4.4.4.2.m1.2.2.cmml" xref="S3.T1.4.4.4.2.m1.2.2">714</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.4.2.m1.2c">13,714</annotation></semantics></math></td>
<td id="S3.T1.4.4.4.5" class="ltx_td ltx_align_center">80</td>
<td id="S3.T1.4.4.4.6" class="ltx_td"></td>
<td id="S3.T1.4.4.4.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:0.0pt;"></td>
</tr>
<tr id="S3.T1.6.6.6" class="ltx_tr">
<td id="S3.T1.6.6.6.3" class="ltx_td ltx_align_center">UT-HAR <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yousefi2017uthar</span>]</cite>
</td>
<td id="S3.T1.6.6.6.4" class="ltx_td ltx_align_left">Wi-Fi Router</td>
<td id="S3.T1.6.6.6.5" class="ltx_td ltx_align_left">Wireless Signal</td>
<td id="S3.T1.5.5.5.1" class="ltx_td ltx_align_center"><math id="S3.T1.5.5.5.1.m1.1" class="ltx_Math" alttext="3\times 30\times 250" display="inline"><semantics id="S3.T1.5.5.5.1.m1.1a"><mrow id="S3.T1.5.5.5.1.m1.1.1" xref="S3.T1.5.5.5.1.m1.1.1.cmml"><mn id="S3.T1.5.5.5.1.m1.1.1.2" xref="S3.T1.5.5.5.1.m1.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S3.T1.5.5.5.1.m1.1.1.1" xref="S3.T1.5.5.5.1.m1.1.1.1.cmml">×</mo><mn id="S3.T1.5.5.5.1.m1.1.1.3" xref="S3.T1.5.5.5.1.m1.1.1.3.cmml">30</mn><mo lspace="0.222em" rspace="0.222em" id="S3.T1.5.5.5.1.m1.1.1.1a" xref="S3.T1.5.5.5.1.m1.1.1.1.cmml">×</mo><mn id="S3.T1.5.5.5.1.m1.1.1.4" xref="S3.T1.5.5.5.1.m1.1.1.4.cmml">250</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.5.1.m1.1b"><apply id="S3.T1.5.5.5.1.m1.1.1.cmml" xref="S3.T1.5.5.5.1.m1.1.1"><times id="S3.T1.5.5.5.1.m1.1.1.1.cmml" xref="S3.T1.5.5.5.1.m1.1.1.1"></times><cn type="integer" id="S3.T1.5.5.5.1.m1.1.1.2.cmml" xref="S3.T1.5.5.5.1.m1.1.1.2">3</cn><cn type="integer" id="S3.T1.5.5.5.1.m1.1.1.3.cmml" xref="S3.T1.5.5.5.1.m1.1.1.3">30</cn><cn type="integer" id="S3.T1.5.5.5.1.m1.1.1.4.cmml" xref="S3.T1.5.5.5.1.m1.1.1.4">250</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.5.1.m1.1c">3\times 30\times 250</annotation></semantics></math></td>
<td id="S3.T1.6.6.6.6" class="ltx_td ltx_align_center">854 MB</td>
<td id="S3.T1.6.6.6.2" class="ltx_td ltx_align_left"><math id="S3.T1.6.6.6.2.m1.2" class="ltx_Math" alttext="3,977" display="inline"><semantics id="S3.T1.6.6.6.2.m1.2a"><mrow id="S3.T1.6.6.6.2.m1.2.3.2" xref="S3.T1.6.6.6.2.m1.2.3.1.cmml"><mn id="S3.T1.6.6.6.2.m1.1.1" xref="S3.T1.6.6.6.2.m1.1.1.cmml">3</mn><mo id="S3.T1.6.6.6.2.m1.2.3.2.1" xref="S3.T1.6.6.6.2.m1.2.3.1.cmml">,</mo><mn id="S3.T1.6.6.6.2.m1.2.2" xref="S3.T1.6.6.6.2.m1.2.2.cmml">977</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.6.6.6.2.m1.2b"><list id="S3.T1.6.6.6.2.m1.2.3.1.cmml" xref="S3.T1.6.6.6.2.m1.2.3.2"><cn type="integer" id="S3.T1.6.6.6.2.m1.1.1.cmml" xref="S3.T1.6.6.6.2.m1.1.1">3</cn><cn type="integer" id="S3.T1.6.6.6.2.m1.2.2.cmml" xref="S3.T1.6.6.6.2.m1.2.2">977</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.6.6.2.m1.2c">3,977</annotation></semantics></math></td>
<td id="S3.T1.6.6.6.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:0.0pt;">
<span id="S3.T1.6.6.6.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.6.6.6.7.1.1" class="ltx_p">20</span>
</span>
</td>
</tr>
<tr id="S3.T1.8.8.8" class="ltx_tr">
<td id="S3.T1.8.8.8.3" class="ltx_td ltx_align_center">Widar <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zheng2020widardata</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zheng2019zero</span>]</cite>
</td>
<td id="S3.T1.8.8.8.4" class="ltx_td ltx_align_left">Wi-Fi Router</td>
<td id="S3.T1.8.8.8.5" class="ltx_td ltx_align_left">Wireless Signal</td>
<td id="S3.T1.7.7.7.1" class="ltx_td ltx_align_center"><math id="S3.T1.7.7.7.1.m1.1" class="ltx_Math" alttext="22\times 20\times 20" display="inline"><semantics id="S3.T1.7.7.7.1.m1.1a"><mrow id="S3.T1.7.7.7.1.m1.1.1" xref="S3.T1.7.7.7.1.m1.1.1.cmml"><mn id="S3.T1.7.7.7.1.m1.1.1.2" xref="S3.T1.7.7.7.1.m1.1.1.2.cmml">22</mn><mo lspace="0.222em" rspace="0.222em" id="S3.T1.7.7.7.1.m1.1.1.1" xref="S3.T1.7.7.7.1.m1.1.1.1.cmml">×</mo><mn id="S3.T1.7.7.7.1.m1.1.1.3" xref="S3.T1.7.7.7.1.m1.1.1.3.cmml">20</mn><mo lspace="0.222em" rspace="0.222em" id="S3.T1.7.7.7.1.m1.1.1.1a" xref="S3.T1.7.7.7.1.m1.1.1.1.cmml">×</mo><mn id="S3.T1.7.7.7.1.m1.1.1.4" xref="S3.T1.7.7.7.1.m1.1.1.4.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.7.7.7.1.m1.1b"><apply id="S3.T1.7.7.7.1.m1.1.1.cmml" xref="S3.T1.7.7.7.1.m1.1.1"><times id="S3.T1.7.7.7.1.m1.1.1.1.cmml" xref="S3.T1.7.7.7.1.m1.1.1.1"></times><cn type="integer" id="S3.T1.7.7.7.1.m1.1.1.2.cmml" xref="S3.T1.7.7.7.1.m1.1.1.2">22</cn><cn type="integer" id="S3.T1.7.7.7.1.m1.1.1.3.cmml" xref="S3.T1.7.7.7.1.m1.1.1.3">20</cn><cn type="integer" id="S3.T1.7.7.7.1.m1.1.1.4.cmml" xref="S3.T1.7.7.7.1.m1.1.1.4">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.7.7.7.1.m1.1c">22\times 20\times 20</annotation></semantics></math></td>
<td id="S3.T1.8.8.8.6" class="ltx_td ltx_align_center">3.3 GB</td>
<td id="S3.T1.8.8.8.2" class="ltx_td ltx_align_left"><math id="S3.T1.8.8.8.2.m1.2" class="ltx_Math" alttext="11,372" display="inline"><semantics id="S3.T1.8.8.8.2.m1.2a"><mrow id="S3.T1.8.8.8.2.m1.2.3.2" xref="S3.T1.8.8.8.2.m1.2.3.1.cmml"><mn id="S3.T1.8.8.8.2.m1.1.1" xref="S3.T1.8.8.8.2.m1.1.1.cmml">11</mn><mo id="S3.T1.8.8.8.2.m1.2.3.2.1" xref="S3.T1.8.8.8.2.m1.2.3.1.cmml">,</mo><mn id="S3.T1.8.8.8.2.m1.2.2" xref="S3.T1.8.8.8.2.m1.2.2.cmml">372</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.8.8.8.2.m1.2b"><list id="S3.T1.8.8.8.2.m1.2.3.1.cmml" xref="S3.T1.8.8.8.2.m1.2.3.2"><cn type="integer" id="S3.T1.8.8.8.2.m1.1.1.cmml" xref="S3.T1.8.8.8.2.m1.1.1">11</cn><cn type="integer" id="S3.T1.8.8.8.2.m1.2.2.cmml" xref="S3.T1.8.8.8.2.m1.2.2">372</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.8.8.8.2.m1.2c">11,372</annotation></semantics></math></td>
<td id="S3.T1.8.8.8.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:0.0pt;">
<span id="S3.T1.8.8.8.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.8.8.8.7.1.1" class="ltx_p">40</span>
</span>
</td>
</tr>
<tr id="S3.T1.10.10.10" class="ltx_tr">
<td id="S3.T1.10.10.10.3" class="ltx_td ltx_align_center">VisDrone <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">pengfei2021visdrone</span>]</cite>
</td>
<td id="S3.T1.10.10.10.4" class="ltx_td ltx_align_left">Drone</td>
<td id="S3.T1.10.10.10.5" class="ltx_td ltx_align_left">Images</td>
<td id="S3.T1.9.9.9.1" class="ltx_td ltx_align_center"><math id="S3.T1.9.9.9.1.m1.1" class="ltx_Math" alttext="3\times 224\times 224" display="inline"><semantics id="S3.T1.9.9.9.1.m1.1a"><mrow id="S3.T1.9.9.9.1.m1.1.1" xref="S3.T1.9.9.9.1.m1.1.1.cmml"><mn id="S3.T1.9.9.9.1.m1.1.1.2" xref="S3.T1.9.9.9.1.m1.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S3.T1.9.9.9.1.m1.1.1.1" xref="S3.T1.9.9.9.1.m1.1.1.1.cmml">×</mo><mn id="S3.T1.9.9.9.1.m1.1.1.3" xref="S3.T1.9.9.9.1.m1.1.1.3.cmml">224</mn><mo lspace="0.222em" rspace="0.222em" id="S3.T1.9.9.9.1.m1.1.1.1a" xref="S3.T1.9.9.9.1.m1.1.1.1.cmml">×</mo><mn id="S3.T1.9.9.9.1.m1.1.1.4" xref="S3.T1.9.9.9.1.m1.1.1.4.cmml">224</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.9.9.9.1.m1.1b"><apply id="S3.T1.9.9.9.1.m1.1.1.cmml" xref="S3.T1.9.9.9.1.m1.1.1"><times id="S3.T1.9.9.9.1.m1.1.1.1.cmml" xref="S3.T1.9.9.9.1.m1.1.1.1"></times><cn type="integer" id="S3.T1.9.9.9.1.m1.1.1.2.cmml" xref="S3.T1.9.9.9.1.m1.1.1.2">3</cn><cn type="integer" id="S3.T1.9.9.9.1.m1.1.1.3.cmml" xref="S3.T1.9.9.9.1.m1.1.1.3">224</cn><cn type="integer" id="S3.T1.9.9.9.1.m1.1.1.4.cmml" xref="S3.T1.9.9.9.1.m1.1.1.4">224</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.9.9.9.1.m1.1c">3\times 224\times 224</annotation></semantics></math></td>
<td id="S3.T1.10.10.10.6" class="ltx_td ltx_align_center">1.8 GB</td>
<td id="S3.T1.10.10.10.2" class="ltx_td ltx_align_left"><math id="S3.T1.10.10.10.2.m1.2" class="ltx_Math" alttext="6,471" display="inline"><semantics id="S3.T1.10.10.10.2.m1.2a"><mrow id="S3.T1.10.10.10.2.m1.2.3.2" xref="S3.T1.10.10.10.2.m1.2.3.1.cmml"><mn id="S3.T1.10.10.10.2.m1.1.1" xref="S3.T1.10.10.10.2.m1.1.1.cmml">6</mn><mo id="S3.T1.10.10.10.2.m1.2.3.2.1" xref="S3.T1.10.10.10.2.m1.2.3.1.cmml">,</mo><mn id="S3.T1.10.10.10.2.m1.2.2" xref="S3.T1.10.10.10.2.m1.2.2.cmml">471</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.10.10.10.2.m1.2b"><list id="S3.T1.10.10.10.2.m1.2.3.1.cmml" xref="S3.T1.10.10.10.2.m1.2.3.2"><cn type="integer" id="S3.T1.10.10.10.2.m1.1.1.cmml" xref="S3.T1.10.10.10.2.m1.1.1">6</cn><cn type="integer" id="S3.T1.10.10.10.2.m1.2.2.cmml" xref="S3.T1.10.10.10.2.m1.2.2">471</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.10.10.10.2.m1.2c">6,471</annotation></semantics></math></td>
<td id="S3.T1.10.10.10.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:0.0pt;">
<span id="S3.T1.10.10.10.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.10.10.10.7.1.1" class="ltx_p">30</span>
</span>
</td>
</tr>
<tr id="S3.T1.16.16.20" class="ltx_tr">
<td id="S3.T1.16.16.20.1" class="ltx_td ltx_align_center">CASAS <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">schmitteredgecombe2009assesssing</span>]</cite>
</td>
<td id="S3.T1.16.16.20.2" class="ltx_td ltx_align_left">Smart Home</td>
<td id="S3.T1.16.16.20.3" class="ltx_td ltx_align_left">Motion Sensor</td>
<td id="S3.T1.16.16.20.4" class="ltx_td"></td>
<td id="S3.T1.16.16.20.5" class="ltx_td"></td>
<td id="S3.T1.16.16.20.6" class="ltx_td"></td>
<td id="S3.T1.16.16.20.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:0.0pt;"></td>
</tr>
<tr id="S3.T1.16.16.21" class="ltx_tr">
<td id="S3.T1.16.16.21.1" class="ltx_td ltx_align_center">Door Sensor</td>
<td id="S3.T1.16.16.21.2" class="ltx_td"></td>
<td id="S3.T1.16.16.21.3" class="ltx_td"></td>
<td id="S3.T1.16.16.21.4" class="ltx_td"></td>
<td id="S3.T1.16.16.21.5" class="ltx_td"></td>
<td id="S3.T1.16.16.21.6" class="ltx_td"></td>
<td id="S3.T1.16.16.21.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:0.0pt;"></td>
</tr>
<tr id="S3.T1.12.12.12" class="ltx_tr">
<td id="S3.T1.12.12.12.3" class="ltx_td ltx_align_right">Thermostat</td>
<td id="S3.T1.11.11.11.1" class="ltx_td ltx_align_left"><math id="S3.T1.11.11.11.1.m1.1" class="ltx_Math" alttext="2000\times 1" display="inline"><semantics id="S3.T1.11.11.11.1.m1.1a"><mrow id="S3.T1.11.11.11.1.m1.1.1" xref="S3.T1.11.11.11.1.m1.1.1.cmml"><mn id="S3.T1.11.11.11.1.m1.1.1.2" xref="S3.T1.11.11.11.1.m1.1.1.2.cmml">2000</mn><mo lspace="0.222em" rspace="0.222em" id="S3.T1.11.11.11.1.m1.1.1.1" xref="S3.T1.11.11.11.1.m1.1.1.1.cmml">×</mo><mn id="S3.T1.11.11.11.1.m1.1.1.3" xref="S3.T1.11.11.11.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.11.11.11.1.m1.1b"><apply id="S3.T1.11.11.11.1.m1.1.1.cmml" xref="S3.T1.11.11.11.1.m1.1.1"><times id="S3.T1.11.11.11.1.m1.1.1.1.cmml" xref="S3.T1.11.11.11.1.m1.1.1.1"></times><cn type="integer" id="S3.T1.11.11.11.1.m1.1.1.2.cmml" xref="S3.T1.11.11.11.1.m1.1.1.2">2000</cn><cn type="integer" id="S3.T1.11.11.11.1.m1.1.1.3.cmml" xref="S3.T1.11.11.11.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.11.11.11.1.m1.1c">2000\times 1</annotation></semantics></math></td>
<td id="S3.T1.12.12.12.4" class="ltx_td ltx_align_left">233 MB</td>
<td id="S3.T1.12.12.12.2" class="ltx_td ltx_align_center"><math id="S3.T1.12.12.12.2.m1.2" class="ltx_Math" alttext="12,190" display="inline"><semantics id="S3.T1.12.12.12.2.m1.2a"><mrow id="S3.T1.12.12.12.2.m1.2.3.2" xref="S3.T1.12.12.12.2.m1.2.3.1.cmml"><mn id="S3.T1.12.12.12.2.m1.1.1" xref="S3.T1.12.12.12.2.m1.1.1.cmml">12</mn><mo id="S3.T1.12.12.12.2.m1.2.3.2.1" xref="S3.T1.12.12.12.2.m1.2.3.1.cmml">,</mo><mn id="S3.T1.12.12.12.2.m1.2.2" xref="S3.T1.12.12.12.2.m1.2.2.cmml">190</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.12.12.12.2.m1.2b"><list id="S3.T1.12.12.12.2.m1.2.3.1.cmml" xref="S3.T1.12.12.12.2.m1.2.3.2"><cn type="integer" id="S3.T1.12.12.12.2.m1.1.1.cmml" xref="S3.T1.12.12.12.2.m1.1.1">12</cn><cn type="integer" id="S3.T1.12.12.12.2.m1.2.2.cmml" xref="S3.T1.12.12.12.2.m1.2.2">190</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.12.12.12.2.m1.2c">12,190</annotation></semantics></math></td>
<td id="S3.T1.12.12.12.5" class="ltx_td ltx_align_center">60</td>
<td id="S3.T1.12.12.12.6" class="ltx_td"></td>
<td id="S3.T1.12.12.12.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:0.0pt;"></td>
</tr>
<tr id="S3.T1.16.16.22" class="ltx_tr">
<td id="S3.T1.16.16.22.1" class="ltx_td ltx_align_center">AEP <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">candanedo2017datadriven</span>]</cite>
</td>
<td id="S3.T1.16.16.22.2" class="ltx_td ltx_align_left">Smart Home</td>
<td id="S3.T1.16.16.22.3" class="ltx_td ltx_align_left">Energy, Humidity</td>
<td id="S3.T1.16.16.22.4" class="ltx_td"></td>
<td id="S3.T1.16.16.22.5" class="ltx_td"></td>
<td id="S3.T1.16.16.22.6" class="ltx_td"></td>
<td id="S3.T1.16.16.22.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:0.0pt;"></td>
</tr>
<tr id="S3.T1.14.14.14" class="ltx_tr">
<td id="S3.T1.14.14.14.3" class="ltx_td ltx_align_right">Temperature</td>
<td id="S3.T1.13.13.13.1" class="ltx_td ltx_align_left"><math id="S3.T1.13.13.13.1.m1.1" class="ltx_Math" alttext="18\times 1" display="inline"><semantics id="S3.T1.13.13.13.1.m1.1a"><mrow id="S3.T1.13.13.13.1.m1.1.1" xref="S3.T1.13.13.13.1.m1.1.1.cmml"><mn id="S3.T1.13.13.13.1.m1.1.1.2" xref="S3.T1.13.13.13.1.m1.1.1.2.cmml">18</mn><mo lspace="0.222em" rspace="0.222em" id="S3.T1.13.13.13.1.m1.1.1.1" xref="S3.T1.13.13.13.1.m1.1.1.1.cmml">×</mo><mn id="S3.T1.13.13.13.1.m1.1.1.3" xref="S3.T1.13.13.13.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.13.13.13.1.m1.1b"><apply id="S3.T1.13.13.13.1.m1.1.1.cmml" xref="S3.T1.13.13.13.1.m1.1.1"><times id="S3.T1.13.13.13.1.m1.1.1.1.cmml" xref="S3.T1.13.13.13.1.m1.1.1.1"></times><cn type="integer" id="S3.T1.13.13.13.1.m1.1.1.2.cmml" xref="S3.T1.13.13.13.1.m1.1.1.2">18</cn><cn type="integer" id="S3.T1.13.13.13.1.m1.1.1.3.cmml" xref="S3.T1.13.13.13.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.13.13.13.1.m1.1c">18\times 1</annotation></semantics></math></td>
<td id="S3.T1.14.14.14.4" class="ltx_td ltx_align_left">12 MB</td>
<td id="S3.T1.14.14.14.2" class="ltx_td ltx_align_center"><math id="S3.T1.14.14.14.2.m1.2" class="ltx_Math" alttext="15,788" display="inline"><semantics id="S3.T1.14.14.14.2.m1.2a"><mrow id="S3.T1.14.14.14.2.m1.2.3.2" xref="S3.T1.14.14.14.2.m1.2.3.1.cmml"><mn id="S3.T1.14.14.14.2.m1.1.1" xref="S3.T1.14.14.14.2.m1.1.1.cmml">15</mn><mo id="S3.T1.14.14.14.2.m1.2.3.2.1" xref="S3.T1.14.14.14.2.m1.2.3.1.cmml">,</mo><mn id="S3.T1.14.14.14.2.m1.2.2" xref="S3.T1.14.14.14.2.m1.2.2.cmml">788</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.14.14.14.2.m1.2b"><list id="S3.T1.14.14.14.2.m1.2.3.1.cmml" xref="S3.T1.14.14.14.2.m1.2.3.2"><cn type="integer" id="S3.T1.14.14.14.2.m1.1.1.cmml" xref="S3.T1.14.14.14.2.m1.1.1">15</cn><cn type="integer" id="S3.T1.14.14.14.2.m1.2.2.cmml" xref="S3.T1.14.14.14.2.m1.2.2">788</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.14.14.14.2.m1.2c">15,788</annotation></semantics></math></td>
<td id="S3.T1.14.14.14.5" class="ltx_td ltx_align_center">80</td>
<td id="S3.T1.14.14.14.6" class="ltx_td"></td>
<td id="S3.T1.14.14.14.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:0.0pt;"></td>
</tr>
<tr id="S3.T1.16.16.16" class="ltx_tr">
<td id="S3.T1.16.16.16.3" class="ltx_td ltx_align_center">EPIC-SOUNDS <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">epicsounds2023</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">damen2022rescaling</span>]</cite>
</td>
<td id="S3.T1.16.16.16.4" class="ltx_td ltx_align_left">Augmented Reality</td>
<td id="S3.T1.16.16.16.5" class="ltx_td ltx_align_left">Acoustics</td>
<td id="S3.T1.15.15.15.1" class="ltx_td ltx_align_center"><math id="S3.T1.15.15.15.1.m1.1" class="ltx_Math" alttext="400\times 128" display="inline"><semantics id="S3.T1.15.15.15.1.m1.1a"><mrow id="S3.T1.15.15.15.1.m1.1.1" xref="S3.T1.15.15.15.1.m1.1.1.cmml"><mn id="S3.T1.15.15.15.1.m1.1.1.2" xref="S3.T1.15.15.15.1.m1.1.1.2.cmml">400</mn><mo lspace="0.222em" rspace="0.222em" id="S3.T1.15.15.15.1.m1.1.1.1" xref="S3.T1.15.15.15.1.m1.1.1.1.cmml">×</mo><mn id="S3.T1.15.15.15.1.m1.1.1.3" xref="S3.T1.15.15.15.1.m1.1.1.3.cmml">128</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.15.15.15.1.m1.1b"><apply id="S3.T1.15.15.15.1.m1.1.1.cmml" xref="S3.T1.15.15.15.1.m1.1.1"><times id="S3.T1.15.15.15.1.m1.1.1.1.cmml" xref="S3.T1.15.15.15.1.m1.1.1.1"></times><cn type="integer" id="S3.T1.15.15.15.1.m1.1.1.2.cmml" xref="S3.T1.15.15.15.1.m1.1.1.2">400</cn><cn type="integer" id="S3.T1.15.15.15.1.m1.1.1.3.cmml" xref="S3.T1.15.15.15.1.m1.1.1.3">128</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.15.15.15.1.m1.1c">400\times 128</annotation></semantics></math></td>
<td id="S3.T1.16.16.16.6" class="ltx_td ltx_align_center">34 GB</td>
<td id="S3.T1.16.16.16.2" class="ltx_td ltx_align_left"><math id="S3.T1.16.16.16.2.m1.2" class="ltx_Math" alttext="60,055" display="inline"><semantics id="S3.T1.16.16.16.2.m1.2a"><mrow id="S3.T1.16.16.16.2.m1.2.3.2" xref="S3.T1.16.16.16.2.m1.2.3.1.cmml"><mn id="S3.T1.16.16.16.2.m1.1.1" xref="S3.T1.16.16.16.2.m1.1.1.cmml">60</mn><mo id="S3.T1.16.16.16.2.m1.2.3.2.1" xref="S3.T1.16.16.16.2.m1.2.3.1.cmml">,</mo><mn id="S3.T1.16.16.16.2.m1.2.2" xref="S3.T1.16.16.16.2.m1.2.2.cmml">055</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.16.16.16.2.m1.2b"><list id="S3.T1.16.16.16.2.m1.2.3.1.cmml" xref="S3.T1.16.16.16.2.m1.2.3.2"><cn type="integer" id="S3.T1.16.16.16.2.m1.1.1.cmml" xref="S3.T1.16.16.16.2.m1.1.1">60</cn><cn type="integer" id="S3.T1.16.16.16.2.m1.2.2.cmml" xref="S3.T1.16.16.16.2.m1.2.2">055</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.16.16.16.2.m1.2c">60,055</annotation></semantics></math></td>
<td id="S3.T1.16.16.16.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:0.0pt;">
<span id="S3.T1.16.16.16.7.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.16.16.16.7.1.1" class="ltx_p">210</span>
</span>
</td>
</tr>
</table>
</span></div>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Datasets</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Table <a href="#S3.T1" title="Table 1 ‣ 3 Design of FedAIoT ‣ FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> provides an overview of the eight datasets included in <span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_typewriter">FedAIoT</span>. In this section, we provide a brief overview of each included dataset.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.9" class="ltx_p"><span id="S3.SS1.p2.9.1" class="ltx_text ltx_font_bold">WISDM:</span>
The Wireless Sensor Data Mining (WISDM) dataset <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">weiss2019wisdm</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wisdm2</span>]</cite> is one of the widely used datasets for the task of daily activity recognition using accelerometer and gyroscope sensor data collected from smartphones and smartwatches.
WISDM includes data collected from <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="51" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mn id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">51</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><cn type="integer" id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">51</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">51</annotation></semantics></math> participants performing <math id="S3.SS1.p2.2.m2.1" class="ltx_Math" alttext="18" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><mn id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">18</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><cn type="integer" id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">18</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">18</annotation></semantics></math> daily activities, each in a <math id="S3.SS1.p2.3.m3.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S3.SS1.p2.3.m3.1a"><mn id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><cn type="integer" id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">3</annotation></semantics></math>-minute session.
We combined activities such as eating soup, chips, pasta, and sandwiches into a single category called "eating", and removed uncommon activities related to playing with balls, such as kicking, catching, or dribbling.
We randomly selected <math id="S3.SS1.p2.4.m4.1" class="ltx_Math" alttext="45" display="inline"><semantics id="S3.SS1.p2.4.m4.1a"><mn id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml">45</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><cn type="integer" id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">45</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">45</annotation></semantics></math> participants as the training set and the rest of the <math id="S3.SS1.p2.5.m5.1" class="ltx_Math" alttext="6" display="inline"><semantics id="S3.SS1.p2.5.m5.1a"><mn id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><cn type="integer" id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">6</annotation></semantics></math> participants were assigned to the test set. Given that in real-life settings individuals may not carry a smartphone and wear a smartwatch at the same time, we partition WISDM into two separate datasets: <span id="S3.SS1.p2.9.2" class="ltx_text ltx_font_bold">WISDM-W</span> with smartwatch data only and <span id="S3.SS1.p2.9.3" class="ltx_text ltx_font_bold">WISDM-P</span> with smartphone data only.
The total number of samples in the training and test set is <math id="S3.SS1.p2.6.m6.2" class="ltx_Math" alttext="16,569" display="inline"><semantics id="S3.SS1.p2.6.m6.2a"><mrow id="S3.SS1.p2.6.m6.2.3.2" xref="S3.SS1.p2.6.m6.2.3.1.cmml"><mn id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml">16</mn><mo id="S3.SS1.p2.6.m6.2.3.2.1" xref="S3.SS1.p2.6.m6.2.3.1.cmml">,</mo><mn id="S3.SS1.p2.6.m6.2.2" xref="S3.SS1.p2.6.m6.2.2.cmml">569</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.2b"><list id="S3.SS1.p2.6.m6.2.3.1.cmml" xref="S3.SS1.p2.6.m6.2.3.2"><cn type="integer" id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1">16</cn><cn type="integer" id="S3.SS1.p2.6.m6.2.2.cmml" xref="S3.SS1.p2.6.m6.2.2">569</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.2c">16,569</annotation></semantics></math> and <math id="S3.SS1.p2.7.m7.2" class="ltx_Math" alttext="4,103" display="inline"><semantics id="S3.SS1.p2.7.m7.2a"><mrow id="S3.SS1.p2.7.m7.2.3.2" xref="S3.SS1.p2.7.m7.2.3.1.cmml"><mn id="S3.SS1.p2.7.m7.1.1" xref="S3.SS1.p2.7.m7.1.1.cmml">4</mn><mo id="S3.SS1.p2.7.m7.2.3.2.1" xref="S3.SS1.p2.7.m7.2.3.1.cmml">,</mo><mn id="S3.SS1.p2.7.m7.2.2" xref="S3.SS1.p2.7.m7.2.2.cmml">103</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.7.m7.2b"><list id="S3.SS1.p2.7.m7.2.3.1.cmml" xref="S3.SS1.p2.7.m7.2.3.2"><cn type="integer" id="S3.SS1.p2.7.m7.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1">4</cn><cn type="integer" id="S3.SS1.p2.7.m7.2.2.cmml" xref="S3.SS1.p2.7.m7.2.2">103</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.7.m7.2c">4,103</annotation></semantics></math> for WISDP-W and <math id="S3.SS1.p2.8.m8.2" class="ltx_Math" alttext="13,714" display="inline"><semantics id="S3.SS1.p2.8.m8.2a"><mrow id="S3.SS1.p2.8.m8.2.3.2" xref="S3.SS1.p2.8.m8.2.3.1.cmml"><mn id="S3.SS1.p2.8.m8.1.1" xref="S3.SS1.p2.8.m8.1.1.cmml">13</mn><mo id="S3.SS1.p2.8.m8.2.3.2.1" xref="S3.SS1.p2.8.m8.2.3.1.cmml">,</mo><mn id="S3.SS1.p2.8.m8.2.2" xref="S3.SS1.p2.8.m8.2.2.cmml">714</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.8.m8.2b"><list id="S3.SS1.p2.8.m8.2.3.1.cmml" xref="S3.SS1.p2.8.m8.2.3.2"><cn type="integer" id="S3.SS1.p2.8.m8.1.1.cmml" xref="S3.SS1.p2.8.m8.1.1">13</cn><cn type="integer" id="S3.SS1.p2.8.m8.2.2.cmml" xref="S3.SS1.p2.8.m8.2.2">714</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.8.m8.2c">13,714</annotation></semantics></math> and <math id="S3.SS1.p2.9.m9.2" class="ltx_Math" alttext="4,073" display="inline"><semantics id="S3.SS1.p2.9.m9.2a"><mrow id="S3.SS1.p2.9.m9.2.3.2" xref="S3.SS1.p2.9.m9.2.3.1.cmml"><mn id="S3.SS1.p2.9.m9.1.1" xref="S3.SS1.p2.9.m9.1.1.cmml">4</mn><mo id="S3.SS1.p2.9.m9.2.3.2.1" xref="S3.SS1.p2.9.m9.2.3.1.cmml">,</mo><mn id="S3.SS1.p2.9.m9.2.2" xref="S3.SS1.p2.9.m9.2.2.cmml">073</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.9.m9.2b"><list id="S3.SS1.p2.9.m9.2.3.1.cmml" xref="S3.SS1.p2.9.m9.2.3.2"><cn type="integer" id="S3.SS1.p2.9.m9.1.1.cmml" xref="S3.SS1.p2.9.m9.1.1">4</cn><cn type="integer" id="S3.SS1.p2.9.m9.2.2.cmml" xref="S3.SS1.p2.9.m9.2.2">073</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.9.m9.2c">4,073</annotation></semantics></math> for WISDP-P respectively. No Licence was explicitly mentioned on the dataset homepage.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.3" class="ltx_p"><span id="S3.SS1.p3.3.1" class="ltx_text ltx_font_bold">UT-HAR:</span>
The UT-HAR dataset <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yousefi2017uthar</span>]</cite> is a Wi-Fi dataset for the task of contactless activity recognition. The Wi-Fi data are in the form of Channel State Information (CSI) collected using three pairs of antennas and an Intel 5300 Network Interface Card (NIC), with each antenna pair capable of capturing <math id="S3.SS1.p3.1.m1.1" class="ltx_Math" alttext="30" display="inline"><semantics id="S3.SS1.p3.1.m1.1a"><mn id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><cn type="integer" id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">30</annotation></semantics></math> subcarriers of CSI.
UT-HAR comprises data collected from participants performing seven activities such as walking and running.
UT-HAR contains a pre-determined training and test set.
The total number of training and test samples is <math id="S3.SS1.p3.2.m2.2" class="ltx_Math" alttext="3,977" display="inline"><semantics id="S3.SS1.p3.2.m2.2a"><mrow id="S3.SS1.p3.2.m2.2.3.2" xref="S3.SS1.p3.2.m2.2.3.1.cmml"><mn id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml">3</mn><mo id="S3.SS1.p3.2.m2.2.3.2.1" xref="S3.SS1.p3.2.m2.2.3.1.cmml">,</mo><mn id="S3.SS1.p3.2.m2.2.2" xref="S3.SS1.p3.2.m2.2.2.cmml">977</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.2b"><list id="S3.SS1.p3.2.m2.2.3.1.cmml" xref="S3.SS1.p3.2.m2.2.3.2"><cn type="integer" id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">3</cn><cn type="integer" id="S3.SS1.p3.2.m2.2.2.cmml" xref="S3.SS1.p3.2.m2.2.2">977</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.2c">3,977</annotation></semantics></math> and <math id="S3.SS1.p3.3.m3.1" class="ltx_Math" alttext="500" display="inline"><semantics id="S3.SS1.p3.3.m3.1a"><mn id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><cn type="integer" id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">500</annotation></semantics></math> respectively.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.6" class="ltx_p"><span id="S3.SS1.p4.6.1" class="ltx_text ltx_font_bold">Widar:</span>
The Widar dataset <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zheng2020widardata</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zheng2019zero</span>]</cite> is another Wi-Fi dataset but designed for the task of contactless gesture recognition. The Wi-Fi data are in the form of Wi-Fi signal strength measurements collected using Wi-Fi access points placed strategically in a room. The data collection system employs an Intel <math id="S3.SS1.p4.1.m1.1" class="ltx_Math" alttext="5300" display="inline"><semantics id="S3.SS1.p4.1.m1.1a"><mn id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml">5300</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><cn type="integer" id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1">5300</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">5300</annotation></semantics></math> NIC equipped with <math id="S3.SS1.p4.2.m2.1" class="ltx_Math" alttext="3\times 3" display="inline"><semantics id="S3.SS1.p4.2.m2.1a"><mrow id="S3.SS1.p4.2.m2.1.1" xref="S3.SS1.p4.2.m2.1.1.cmml"><mn id="S3.SS1.p4.2.m2.1.1.2" xref="S3.SS1.p4.2.m2.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p4.2.m2.1.1.1" xref="S3.SS1.p4.2.m2.1.1.1.cmml">×</mo><mn id="S3.SS1.p4.2.m2.1.1.3" xref="S3.SS1.p4.2.m2.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m2.1b"><apply id="S3.SS1.p4.2.m2.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1"><times id="S3.SS1.p4.2.m2.1.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1.1"></times><cn type="integer" id="S3.SS1.p4.2.m2.1.1.2.cmml" xref="S3.SS1.p4.2.m2.1.1.2">3</cn><cn type="integer" id="S3.SS1.p4.2.m2.1.1.3.cmml" xref="S3.SS1.p4.2.m2.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m2.1c">3\times 3</annotation></semantics></math> pairs of antennas.
Widar contains data collected from <math id="S3.SS1.p4.3.m3.1" class="ltx_Math" alttext="17" display="inline"><semantics id="S3.SS1.p4.3.m3.1a"><mn id="S3.SS1.p4.3.m3.1.1" xref="S3.SS1.p4.3.m3.1.1.cmml">17</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.3.m3.1b"><cn type="integer" id="S3.SS1.p4.3.m3.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1">17</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.3.m3.1c">17</annotation></semantics></math> participants performing <math id="S3.SS1.p4.4.m4.1" class="ltx_Math" alttext="22" display="inline"><semantics id="S3.SS1.p4.4.m4.1a"><mn id="S3.SS1.p4.4.m4.1.1" xref="S3.SS1.p4.4.m4.1.1.cmml">22</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.4.m4.1b"><cn type="integer" id="S3.SS1.p4.4.m4.1.1.cmml" xref="S3.SS1.p4.4.m4.1.1">22</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.4.m4.1c">22</annotation></semantics></math> distinct gestures including gestures such as push &amp; pull, sweeping, clapping, and drawing various shapes and numbers.
However, not all the gestures are uniformly represented across all users whereas some gestures were only performed by a single user. To ensure consistency between training and test sets, only those gestures that were recorded by more than three users are included in the experimental dataset.
This yields a more balanced dataset, encompassing nine gestures with a total sample count of <math id="S3.SS1.p4.5.m5.2" class="ltx_Math" alttext="11,372" display="inline"><semantics id="S3.SS1.p4.5.m5.2a"><mrow id="S3.SS1.p4.5.m5.2.3.2" xref="S3.SS1.p4.5.m5.2.3.1.cmml"><mn id="S3.SS1.p4.5.m5.1.1" xref="S3.SS1.p4.5.m5.1.1.cmml">11</mn><mo id="S3.SS1.p4.5.m5.2.3.2.1" xref="S3.SS1.p4.5.m5.2.3.1.cmml">,</mo><mn id="S3.SS1.p4.5.m5.2.2" xref="S3.SS1.p4.5.m5.2.2.cmml">372</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.5.m5.2b"><list id="S3.SS1.p4.5.m5.2.3.1.cmml" xref="S3.SS1.p4.5.m5.2.3.2"><cn type="integer" id="S3.SS1.p4.5.m5.1.1.cmml" xref="S3.SS1.p4.5.m5.1.1">11</cn><cn type="integer" id="S3.SS1.p4.5.m5.2.2.cmml" xref="S3.SS1.p4.5.m5.2.2">372</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.5.m5.2c">11,372</annotation></semantics></math> in the training set and <math id="S3.SS1.p4.6.m6.2" class="ltx_Math" alttext="5,222" display="inline"><semantics id="S3.SS1.p4.6.m6.2a"><mrow id="S3.SS1.p4.6.m6.2.3.2" xref="S3.SS1.p4.6.m6.2.3.1.cmml"><mn id="S3.SS1.p4.6.m6.1.1" xref="S3.SS1.p4.6.m6.1.1.cmml">5</mn><mo id="S3.SS1.p4.6.m6.2.3.2.1" xref="S3.SS1.p4.6.m6.2.3.1.cmml">,</mo><mn id="S3.SS1.p4.6.m6.2.2" xref="S3.SS1.p4.6.m6.2.2.cmml">222</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.6.m6.2b"><list id="S3.SS1.p4.6.m6.2.3.1.cmml" xref="S3.SS1.p4.6.m6.2.3.2"><cn type="integer" id="S3.SS1.p4.6.m6.1.1.cmml" xref="S3.SS1.p4.6.m6.1.1">5</cn><cn type="integer" id="S3.SS1.p4.6.m6.2.2.cmml" xref="S3.SS1.p4.6.m6.2.2">222</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.6.m6.2c">5,222</annotation></semantics></math> in the test set.
The dataset is under Creative Commons Attribution-NonCommercial 4.0 International Licence (CC BY 4).</p>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p id="S3.SS1.p5.1" class="ltx_p"><span id="S3.SS1.p5.1.1" class="ltx_text ltx_font_bold">VisDrone:</span></p>
</div>
<div id="S3.SS1.p6" class="ltx_para">
<p id="S3.SS1.p6.6" class="ltx_p">The VisDrone dataset <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">pengfei2021visdrone</span>]</cite> is a large-scale dataset dedicated to the task of object detection in aerial images captured by drone cameras.
VisDrone includes a total of <math id="S3.SS1.p6.1.m1.1" class="ltx_Math" alttext="263" display="inline"><semantics id="S3.SS1.p6.1.m1.1a"><mn id="S3.SS1.p6.1.m1.1.1" xref="S3.SS1.p6.1.m1.1.1.cmml">263</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.1.m1.1b"><cn type="integer" id="S3.SS1.p6.1.m1.1.1.cmml" xref="S3.SS1.p6.1.m1.1.1">263</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.1.m1.1c">263</annotation></semantics></math> video clips, containing in <math id="S3.SS1.p6.2.m2.2" class="ltx_Math" alttext="179,264" display="inline"><semantics id="S3.SS1.p6.2.m2.2a"><mrow id="S3.SS1.p6.2.m2.2.3.2" xref="S3.SS1.p6.2.m2.2.3.1.cmml"><mn id="S3.SS1.p6.2.m2.1.1" xref="S3.SS1.p6.2.m2.1.1.cmml">179</mn><mo id="S3.SS1.p6.2.m2.2.3.2.1" xref="S3.SS1.p6.2.m2.2.3.1.cmml">,</mo><mn id="S3.SS1.p6.2.m2.2.2" xref="S3.SS1.p6.2.m2.2.2.cmml">264</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.2.m2.2b"><list id="S3.SS1.p6.2.m2.2.3.1.cmml" xref="S3.SS1.p6.2.m2.2.3.2"><cn type="integer" id="S3.SS1.p6.2.m2.1.1.cmml" xref="S3.SS1.p6.2.m2.1.1">179</cn><cn type="integer" id="S3.SS1.p6.2.m2.2.2.cmml" xref="S3.SS1.p6.2.m2.2.2">264</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.2.m2.2c">179,264</annotation></semantics></math> frames and <math id="S3.SS1.p6.3.m3.3" class="ltx_Math" alttext="2,512,357" display="inline"><semantics id="S3.SS1.p6.3.m3.3a"><mrow id="S3.SS1.p6.3.m3.3.4.2" xref="S3.SS1.p6.3.m3.3.4.1.cmml"><mn id="S3.SS1.p6.3.m3.1.1" xref="S3.SS1.p6.3.m3.1.1.cmml">2</mn><mo id="S3.SS1.p6.3.m3.3.4.2.1" xref="S3.SS1.p6.3.m3.3.4.1.cmml">,</mo><mn id="S3.SS1.p6.3.m3.2.2" xref="S3.SS1.p6.3.m3.2.2.cmml">512</mn><mo id="S3.SS1.p6.3.m3.3.4.2.2" xref="S3.SS1.p6.3.m3.3.4.1.cmml">,</mo><mn id="S3.SS1.p6.3.m3.3.3" xref="S3.SS1.p6.3.m3.3.3.cmml">357</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.3.m3.3b"><list id="S3.SS1.p6.3.m3.3.4.1.cmml" xref="S3.SS1.p6.3.m3.3.4.2"><cn type="integer" id="S3.SS1.p6.3.m3.1.1.cmml" xref="S3.SS1.p6.3.m3.1.1">2</cn><cn type="integer" id="S3.SS1.p6.3.m3.2.2.cmml" xref="S3.SS1.p6.3.m3.2.2">512</cn><cn type="integer" id="S3.SS1.p6.3.m3.3.3.cmml" xref="S3.SS1.p6.3.m3.3.3">357</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.3.m3.3c">2,512,357</annotation></semantics></math> labeled objects. The labeled objects fall into <math id="S3.SS1.p6.4.m4.1" class="ltx_Math" alttext="12" display="inline"><semantics id="S3.SS1.p6.4.m4.1a"><mn id="S3.SS1.p6.4.m4.1.1" xref="S3.SS1.p6.4.m4.1.1.cmml">12</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.4.m4.1b"><cn type="integer" id="S3.SS1.p6.4.m4.1.1.cmml" xref="S3.SS1.p6.4.m4.1.1">12</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.4.m4.1c">12</annotation></semantics></math> categories (e.g., ‘pedestrian’, ‘bicycle’, and ‘car’), recorded under a variety of scenarios such as crowded urban areas, highways, and parks.
The dataset contains a pre-determined training and test set.
The total number of samples in the training and test set is <math id="S3.SS1.p6.5.m5.2" class="ltx_Math" alttext="6,471" display="inline"><semantics id="S3.SS1.p6.5.m5.2a"><mrow id="S3.SS1.p6.5.m5.2.3.2" xref="S3.SS1.p6.5.m5.2.3.1.cmml"><mn id="S3.SS1.p6.5.m5.1.1" xref="S3.SS1.p6.5.m5.1.1.cmml">6</mn><mo id="S3.SS1.p6.5.m5.2.3.2.1" xref="S3.SS1.p6.5.m5.2.3.1.cmml">,</mo><mn id="S3.SS1.p6.5.m5.2.2" xref="S3.SS1.p6.5.m5.2.2.cmml">471</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.5.m5.2b"><list id="S3.SS1.p6.5.m5.2.3.1.cmml" xref="S3.SS1.p6.5.m5.2.3.2"><cn type="integer" id="S3.SS1.p6.5.m5.1.1.cmml" xref="S3.SS1.p6.5.m5.1.1">6</cn><cn type="integer" id="S3.SS1.p6.5.m5.2.2.cmml" xref="S3.SS1.p6.5.m5.2.2">471</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.5.m5.2c">6,471</annotation></semantics></math> and <math id="S3.SS1.p6.6.m6.2" class="ltx_Math" alttext="1,610" display="inline"><semantics id="S3.SS1.p6.6.m6.2a"><mrow id="S3.SS1.p6.6.m6.2.3.2" xref="S3.SS1.p6.6.m6.2.3.1.cmml"><mn id="S3.SS1.p6.6.m6.1.1" xref="S3.SS1.p6.6.m6.1.1.cmml">1</mn><mo id="S3.SS1.p6.6.m6.2.3.2.1" xref="S3.SS1.p6.6.m6.2.3.1.cmml">,</mo><mn id="S3.SS1.p6.6.m6.2.2" xref="S3.SS1.p6.6.m6.2.2.cmml">610</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.6.m6.2b"><list id="S3.SS1.p6.6.m6.2.3.1.cmml" xref="S3.SS1.p6.6.m6.2.3.2"><cn type="integer" id="S3.SS1.p6.6.m6.1.1.cmml" xref="S3.SS1.p6.6.m6.1.1">1</cn><cn type="integer" id="S3.SS1.p6.6.m6.2.2.cmml" xref="S3.SS1.p6.6.m6.2.2">610</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.6.m6.2c">1,610</annotation></semantics></math> respectively.
The dataset is licenced under Creative Commons Attribution-NonCommercial-ShareAlike 3.0 License
<span id="S3.SS1.p6.6.1" class="ltx_text ltx_font_bold">CASAS:</span></p>
</div>
<div id="S3.SS1.p7" class="ltx_para">
<p id="S3.SS1.p7.4" class="ltx_p">The CASAS dataset <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">schmitteredgecombe2009assesssing</span>]</cite>, derived from the CASAS smart home project, is a smart home sensor dataset for the task of recognizing activities of daily living (ADL) based on sequences of sensor states over time to support the application of independent living. The data were collected from three distinct apartments, each equipped with three types of sensors: motion sensors, temperature sensors, and door sensors. Five specific datasets, named ‘Milan’, ‘Cairo’, ‘Kyoto2’, ‘Kyoto3’, and ‘Kyoto4’, were selected based on the uniformity of their sensor data representation. The original activity classifications within each dataset have been consolidated into <math id="S3.SS1.p7.1.m1.1" class="ltx_Math" alttext="11" display="inline"><semantics id="S3.SS1.p7.1.m1.1a"><mn id="S3.SS1.p7.1.m1.1.1" xref="S3.SS1.p7.1.m1.1.1.cmml">11</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p7.1.m1.1b"><cn type="integer" id="S3.SS1.p7.1.m1.1.1.cmml" xref="S3.SS1.p7.1.m1.1.1">11</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p7.1.m1.1c">11</annotation></semantics></math> categories related to home activities such as Sleep, Eating, and Bathing. Activities not fitting within these categories were collectively classified as Other.
The training and test set was made using an 80-20 split.
Each data sample is a categorical time series of length <math id="S3.SS1.p7.2.m2.2" class="ltx_Math" alttext="2,000" display="inline"><semantics id="S3.SS1.p7.2.m2.2a"><mrow id="S3.SS1.p7.2.m2.2.3.2" xref="S3.SS1.p7.2.m2.2.3.1.cmml"><mn id="S3.SS1.p7.2.m2.1.1" xref="S3.SS1.p7.2.m2.1.1.cmml">2</mn><mo id="S3.SS1.p7.2.m2.2.3.2.1" xref="S3.SS1.p7.2.m2.2.3.1.cmml">,</mo><mn id="S3.SS1.p7.2.m2.2.2" xref="S3.SS1.p7.2.m2.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p7.2.m2.2b"><list id="S3.SS1.p7.2.m2.2.3.1.cmml" xref="S3.SS1.p7.2.m2.2.3.2"><cn type="integer" id="S3.SS1.p7.2.m2.1.1.cmml" xref="S3.SS1.p7.2.m2.1.1">2</cn><cn type="integer" id="S3.SS1.p7.2.m2.2.2.cmml" xref="S3.SS1.p7.2.m2.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p7.2.m2.2c">2,000</annotation></semantics></math>, representing sensor states over a certain period of time.
The total number of samples in the training and test set is <math id="S3.SS1.p7.3.m3.2" class="ltx_Math" alttext="12,190" display="inline"><semantics id="S3.SS1.p7.3.m3.2a"><mrow id="S3.SS1.p7.3.m3.2.3.2" xref="S3.SS1.p7.3.m3.2.3.1.cmml"><mn id="S3.SS1.p7.3.m3.1.1" xref="S3.SS1.p7.3.m3.1.1.cmml">12</mn><mo id="S3.SS1.p7.3.m3.2.3.2.1" xref="S3.SS1.p7.3.m3.2.3.1.cmml">,</mo><mn id="S3.SS1.p7.3.m3.2.2" xref="S3.SS1.p7.3.m3.2.2.cmml">190</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p7.3.m3.2b"><list id="S3.SS1.p7.3.m3.2.3.1.cmml" xref="S3.SS1.p7.3.m3.2.3.2"><cn type="integer" id="S3.SS1.p7.3.m3.1.1.cmml" xref="S3.SS1.p7.3.m3.1.1">12</cn><cn type="integer" id="S3.SS1.p7.3.m3.2.2.cmml" xref="S3.SS1.p7.3.m3.2.2">190</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p7.3.m3.2c">12,190</annotation></semantics></math> and <math id="S3.SS1.p7.4.m4.2" class="ltx_Math" alttext="3,048" display="inline"><semantics id="S3.SS1.p7.4.m4.2a"><mrow id="S3.SS1.p7.4.m4.2.3.2" xref="S3.SS1.p7.4.m4.2.3.1.cmml"><mn id="S3.SS1.p7.4.m4.1.1" xref="S3.SS1.p7.4.m4.1.1.cmml">3</mn><mo id="S3.SS1.p7.4.m4.2.3.2.1" xref="S3.SS1.p7.4.m4.2.3.1.cmml">,</mo><mn id="S3.SS1.p7.4.m4.2.2" xref="S3.SS1.p7.4.m4.2.2.cmml">048</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p7.4.m4.2b"><list id="S3.SS1.p7.4.m4.2.3.1.cmml" xref="S3.SS1.p7.4.m4.2.3.2"><cn type="integer" id="S3.SS1.p7.4.m4.1.1.cmml" xref="S3.SS1.p7.4.m4.1.1">3</cn><cn type="integer" id="S3.SS1.p7.4.m4.2.2.cmml" xref="S3.SS1.p7.4.m4.2.2">048</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p7.4.m4.2c">3,048</annotation></semantics></math> respectively.
No Licence was explicitly mentioned on the dataset homepage.</p>
</div>
<div id="S3.SS1.p8" class="ltx_para">
<p id="S3.SS1.p8.4" class="ltx_p"><span id="S3.SS1.p8.4.1" class="ltx_text ltx_font_bold">AEP:</span>
The Appliances Energy Prediction (AEP) dataset <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">candanedo2017datadriven</span>]</cite> is another smart home
sensor dataset but designed for the task of predicting home energy usage. The data were collected from energy sensors, temperature sensors, and humidity sensors installed inside a home every <math id="S3.SS1.p8.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S3.SS1.p8.1.m1.1a"><mn id="S3.SS1.p8.1.m1.1.1" xref="S3.SS1.p8.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p8.1.m1.1b"><cn type="integer" id="S3.SS1.p8.1.m1.1.1.cmml" xref="S3.SS1.p8.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p8.1.m1.1c">10</annotation></semantics></math> minutes over <math id="S3.SS1.p8.2.m2.1" class="ltx_Math" alttext="4.5" display="inline"><semantics id="S3.SS1.p8.2.m2.1a"><mn id="S3.SS1.p8.2.m2.1.1" xref="S3.SS1.p8.2.m2.1.1.cmml">4.5</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p8.2.m2.1b"><cn type="float" id="S3.SS1.p8.2.m2.1.1.cmml" xref="S3.SS1.p8.2.m2.1.1">4.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p8.2.m2.1c">4.5</annotation></semantics></math> months.
The total number of samples in the training and test set is <math id="S3.SS1.p8.3.m3.2" class="ltx_Math" alttext="15,788" display="inline"><semantics id="S3.SS1.p8.3.m3.2a"><mrow id="S3.SS1.p8.3.m3.2.3.2" xref="S3.SS1.p8.3.m3.2.3.1.cmml"><mn id="S3.SS1.p8.3.m3.1.1" xref="S3.SS1.p8.3.m3.1.1.cmml">15</mn><mo id="S3.SS1.p8.3.m3.2.3.2.1" xref="S3.SS1.p8.3.m3.2.3.1.cmml">,</mo><mn id="S3.SS1.p8.3.m3.2.2" xref="S3.SS1.p8.3.m3.2.2.cmml">788</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p8.3.m3.2b"><list id="S3.SS1.p8.3.m3.2.3.1.cmml" xref="S3.SS1.p8.3.m3.2.3.2"><cn type="integer" id="S3.SS1.p8.3.m3.1.1.cmml" xref="S3.SS1.p8.3.m3.1.1">15</cn><cn type="integer" id="S3.SS1.p8.3.m3.2.2.cmml" xref="S3.SS1.p8.3.m3.2.2">788</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p8.3.m3.2c">15,788</annotation></semantics></math> and <math id="S3.SS1.p8.4.m4.2" class="ltx_Math" alttext="3,947" display="inline"><semantics id="S3.SS1.p8.4.m4.2a"><mrow id="S3.SS1.p8.4.m4.2.3.2" xref="S3.SS1.p8.4.m4.2.3.1.cmml"><mn id="S3.SS1.p8.4.m4.1.1" xref="S3.SS1.p8.4.m4.1.1.cmml">3</mn><mo id="S3.SS1.p8.4.m4.2.3.2.1" xref="S3.SS1.p8.4.m4.2.3.1.cmml">,</mo><mn id="S3.SS1.p8.4.m4.2.2" xref="S3.SS1.p8.4.m4.2.2.cmml">947</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p8.4.m4.2b"><list id="S3.SS1.p8.4.m4.2.3.1.cmml" xref="S3.SS1.p8.4.m4.2.3.2"><cn type="integer" id="S3.SS1.p8.4.m4.1.1.cmml" xref="S3.SS1.p8.4.m4.1.1">3</cn><cn type="integer" id="S3.SS1.p8.4.m4.2.2.cmml" xref="S3.SS1.p8.4.m4.2.2">947</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p8.4.m4.2c">3,947</annotation></semantics></math> respectively.
No Licence was explicitly mentioned on the dataset homepage.</p>
</div>
<div id="S3.SS1.p9" class="ltx_para">
<p id="S3.SS1.p9.4" class="ltx_p"><span id="S3.SS1.p9.4.1" class="ltx_text ltx_font_bold">EPIC-SOUNDS:</span>
The EPIC-SOUNDS dataset <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">epicsounds2023</span>]</cite> is a large-scale collection of audio recordings for the task of audio-based human activity recognition in Augmented Reality applications. The audio data were collected from a head-mounted microphone including more than <math id="S3.SS1.p9.1.m1.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S3.SS1.p9.1.m1.1a"><mn id="S3.SS1.p9.1.m1.1.1" xref="S3.SS1.p9.1.m1.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p9.1.m1.1b"><cn type="integer" id="S3.SS1.p9.1.m1.1.1.cmml" xref="S3.SS1.p9.1.m1.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p9.1.m1.1c">100</annotation></semantics></math>k categorized segments distributed across <math id="S3.SS1.p9.2.m2.1" class="ltx_Math" alttext="44" display="inline"><semantics id="S3.SS1.p9.2.m2.1a"><mn id="S3.SS1.p9.2.m2.1.1" xref="S3.SS1.p9.2.m2.1.1.cmml">44</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p9.2.m2.1b"><cn type="integer" id="S3.SS1.p9.2.m2.1.1.cmml" xref="S3.SS1.p9.2.m2.1.1">44</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p9.2.m2.1c">44</annotation></semantics></math> distinct classes.
The dataset contains a pre-determined training and test set.
The total number of training and test samples is <math id="S3.SS1.p9.3.m3.2" class="ltx_Math" alttext="60,055" display="inline"><semantics id="S3.SS1.p9.3.m3.2a"><mrow id="S3.SS1.p9.3.m3.2.3.2" xref="S3.SS1.p9.3.m3.2.3.1.cmml"><mn id="S3.SS1.p9.3.m3.1.1" xref="S3.SS1.p9.3.m3.1.1.cmml">60</mn><mo id="S3.SS1.p9.3.m3.2.3.2.1" xref="S3.SS1.p9.3.m3.2.3.1.cmml">,</mo><mn id="S3.SS1.p9.3.m3.2.2" xref="S3.SS1.p9.3.m3.2.2.cmml">055</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p9.3.m3.2b"><list id="S3.SS1.p9.3.m3.2.3.1.cmml" xref="S3.SS1.p9.3.m3.2.3.2"><cn type="integer" id="S3.SS1.p9.3.m3.1.1.cmml" xref="S3.SS1.p9.3.m3.1.1">60</cn><cn type="integer" id="S3.SS1.p9.3.m3.2.2.cmml" xref="S3.SS1.p9.3.m3.2.2">055</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p9.3.m3.2c">60,055</annotation></semantics></math> and <math id="S3.SS1.p9.4.m4.2" class="ltx_Math" alttext="40,175" display="inline"><semantics id="S3.SS1.p9.4.m4.2a"><mrow id="S3.SS1.p9.4.m4.2.3.2" xref="S3.SS1.p9.4.m4.2.3.1.cmml"><mn id="S3.SS1.p9.4.m4.1.1" xref="S3.SS1.p9.4.m4.1.1.cmml">40</mn><mo id="S3.SS1.p9.4.m4.2.3.2.1" xref="S3.SS1.p9.4.m4.2.3.1.cmml">,</mo><mn id="S3.SS1.p9.4.m4.2.2" xref="S3.SS1.p9.4.m4.2.2.cmml">175</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p9.4.m4.2b"><list id="S3.SS1.p9.4.m4.2.3.1.cmml" xref="S3.SS1.p9.4.m4.2.3.2"><cn type="integer" id="S3.SS1.p9.4.m4.1.1.cmml" xref="S3.SS1.p9.4.m4.1.1">40</cn><cn type="integer" id="S3.SS1.p9.4.m4.2.2.cmml" xref="S3.SS1.p9.4.m4.2.2">175</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p9.4.m4.2c">40,175</annotation></semantics></math> respectively. The dataset is under CC BY 4 Licence.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2310.00109/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="438" height="151" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.3.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S3.F2.4.2" class="ltx_text" style="font-size:90%;">Architecture of the end-to-end FL framework for AIoT incorporated in <span id="S3.F2.4.2.1" class="ltx_text ltx_font_typewriter">FedAIoT</span>.</span></figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>End-to-End Federated Learning Framework for AIoT</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">To benchmark the performance of the datasets and facilitate future research in FL for AIoT, we have designed and developed an end-to-end FL framework for AIoT as another key part of <span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_typewriter">FedAIoT</span>.
As illustrated in Figure <a href="#S3.F2" title="Figure 2 ‣ 3.1 Datasets ‣ 3 Design of FedAIoT ‣ FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, our framework covers the complete FL-for-AIoT pipeline, which includes five components: (1) non-IID data partitioning, (2) data preprocessing, (3) AIoT-friendly models, (4) FL hyperparameters, and (5) IoT-factor emulator.
In this section, we describe each component within the framework in detail.</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Non-IID Data Partitioning</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p">The objective of non-IID data partitioning is to partition the training set such that data allocated to different clients follow the non-IID distribution. The eight datasets included in <span id="S3.SS2.SSS1.p1.1.1" class="ltx_text ltx_font_typewriter">FedAIoT</span> cover three fundamental tasks (classification, regression, object detection). <span id="S3.SS2.SSS1.p1.1.2" class="ltx_text ltx_font_typewriter">FedAIoT</span> incorporates three different non-IID data partitioning schemes that are designed for the three tasks respectively.</p>
</div>
<div id="S3.SS2.SSS1.p2" class="ltx_para">
<p id="S3.SS2.SSS1.p2.8" class="ltx_p"><span id="S3.SS2.SSS1.p2.8.1" class="ltx_text ltx_font_bold">Scheme#1: Non-IID Partition over Output Labels</span>.
For the task of classification (WISDM-W, WISDM-P, UT-HAR, Widar, CASAS, EPIC-SOUNDS) with <math id="S3.SS2.SSS1.p2.1.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS2.SSS1.p2.1.m1.1a"><mi id="S3.SS2.SSS1.p2.1.m1.1.1" xref="S3.SS2.SSS1.p2.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.1.m1.1b"><ci id="S3.SS2.SSS1.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p2.1.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.1.m1.1c">C</annotation></semantics></math> classes, we first generate a distribution over the classes for each client by drawing from a Dirichlet Distribution with parameter <math id="S3.SS2.SSS1.p2.2.m2.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS2.SSS1.p2.2.m2.1a"><mi id="S3.SS2.SSS1.p2.2.m2.1.1" xref="S3.SS2.SSS1.p2.2.m2.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.2.m2.1b"><ci id="S3.SS2.SSS1.p2.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.2.m2.1c">\alpha</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">hsu2019measuring</span>]</cite>, where lower values of <math id="S3.SS2.SSS1.p2.3.m3.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS2.SSS1.p2.3.m3.1a"><mi id="S3.SS2.SSS1.p2.3.m3.1.1" xref="S3.SS2.SSS1.p2.3.m3.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.3.m3.1b"><ci id="S3.SS2.SSS1.p2.3.m3.1.1.cmml" xref="S3.SS2.SSS1.p2.3.m3.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.3.m3.1c">\alpha</annotation></semantics></math> generated more skewed distribution favoring a few classes whereas higher values of <math id="S3.SS2.SSS1.p2.4.m4.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS2.SSS1.p2.4.m4.1a"><mi id="S3.SS2.SSS1.p2.4.m4.1.1" xref="S3.SS2.SSS1.p2.4.m4.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.4.m4.1b"><ci id="S3.SS2.SSS1.p2.4.m4.1.1.cmml" xref="S3.SS2.SSS1.p2.4.m4.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.4.m4.1c">\alpha</annotation></semantics></math> result in more balanced class distribution. We use the same <math id="S3.SS2.SSS1.p2.5.m5.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS2.SSS1.p2.5.m5.1a"><mi id="S3.SS2.SSS1.p2.5.m5.1.1" xref="S3.SS2.SSS1.p2.5.m5.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.5.m5.1b"><ci id="S3.SS2.SSS1.p2.5.m5.1.1.cmml" xref="S3.SS2.SSS1.p2.5.m5.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.5.m5.1c">\alpha</annotation></semantics></math> to determine the number of samples each client receives. In addition, by drawing from a Dirichlet Distribution with parameter <math id="S3.SS2.SSS1.p2.6.m6.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS2.SSS1.p2.6.m6.1a"><mi id="S3.SS2.SSS1.p2.6.m6.1.1" xref="S3.SS2.SSS1.p2.6.m6.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.6.m6.1b"><ci id="S3.SS2.SSS1.p2.6.m6.1.1.cmml" xref="S3.SS2.SSS1.p2.6.m6.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.6.m6.1c">\alpha</annotation></semantics></math>, we create a distribution over the total number of samples, which is then used to allocate a varying number of samples to each client, where lower values of <math id="S3.SS2.SSS1.p2.7.m7.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS2.SSS1.p2.7.m7.1a"><mi id="S3.SS2.SSS1.p2.7.m7.1.1" xref="S3.SS2.SSS1.p2.7.m7.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.7.m7.1b"><ci id="S3.SS2.SSS1.p2.7.m7.1.1.cmml" xref="S3.SS2.SSS1.p2.7.m7.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.7.m7.1c">\alpha</annotation></semantics></math> lead to a few clients holding a majority of the samples whereas higher values of <math id="S3.SS2.SSS1.p2.8.m8.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS2.SSS1.p2.8.m8.1a"><mi id="S3.SS2.SSS1.p2.8.m8.1.1" xref="S3.SS2.SSS1.p2.8.m8.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.8.m8.1b"><ci id="S3.SS2.SSS1.p2.8.m8.1.1.cmml" xref="S3.SS2.SSS1.p2.8.m8.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.8.m8.1c">\alpha</annotation></semantics></math> create a more balanced distribution of samples across clients.
This approach allows us to generate non-IID data partitions that better mimic real-world scenarios, where both the class distribution and the number of samples can vary across the clients.</p>
</div>
<div id="S3.SS2.SSS1.p3" class="ltx_para">
<p id="S3.SS2.SSS1.p3.1" class="ltx_p"><span id="S3.SS2.SSS1.p3.1.1" class="ltx_text ltx_font_bold">Scheme#2: Non-IID Partition over Input Features</span>.
The task of object detection (VisDrone) does not have specific classes. In such cases, we use the input features to create non-IID partitions. Specifically, similar to <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">he2021fedcv</span>]</cite>, we first used ImageNet <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">russakovsky2015imagenet</span>]</cite> features generated from a VGG19 model <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2015vgg19</span>]</cite>, which encapsulate crucial visual information required for subsequent analysis.
With these ImageNet features as inputs, we performed clustering in the feature space using <math id="S3.SS2.SSS1.p3.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS2.SSS1.p3.1.m1.1a"><mi id="S3.SS2.SSS1.p3.1.m1.1.1" xref="S3.SS2.SSS1.p3.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.1.m1.1b"><ci id="S3.SS2.SSS1.p3.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.1.m1.1c">K</annotation></semantics></math>-nearest neighbors to partition the dataset into ten distinct clusters. Each cluster is a pseudo-class, representing a set of images sharing common visual characteristics as per the extracted ImageNet features.
Lastly, Dirichlet Allocation was subsequently applied on top of the pseudo-classes to create the non-IID distribution across different clients.</p>
</div>
<div id="S3.SS2.SSS1.p4" class="ltx_para">
<p id="S3.SS2.SSS1.p4.1" class="ltx_p"><span id="S3.SS2.SSS1.p4.1.1" class="ltx_text ltx_font_bold">Scheme#3: Non-IID Partition over Output Distribution</span>.
For the task of regression (e.g., AEP dataset) where the output is characterized as a continuous variable,
we utilize Quantile Binning, a technique that transforms a continuous variable into a categorical one. Specifically, we divide the range of the output variable into ten equal groups or quantiles, ensuring that each bin accommodates roughly the same number of samples. Each category or bin is treated as a pseudo-class.
Once the continuous output has been converted into ten categories, we apply Dirichlet Allocation to generate a non-IID distribution of data across the clients.</p>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Data Preprocessing</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p">The eight datasets included in <span id="S3.SS2.SSS2.p1.1.1" class="ltx_text ltx_font_typewriter">FedAIoT</span> cover diverse data modalities. <span id="S3.SS2.SSS2.p1.1.2" class="ltx_text ltx_font_typewriter">FedAIoT</span> incorporates different data preprocessing techniques for different data modalities accordingly. Because of the diversity in sensor and data modality, pre-processing techniques need to be tailored accordingly to remove outliers and minimize noise.</p>
</div>
<div id="S3.SS2.SSS2.p2" class="ltx_para">
<p id="S3.SS2.SSS2.p2.3" class="ltx_p"><span id="S3.SS2.SSS2.p2.3.1" class="ltx_text ltx_font_bold">WISDM:</span>
We followed the standard preprocessing techniques used in accelerometer and gyroscope-based activity recognition for WISDM.
Specifically, for each <math id="S3.SS2.SSS2.p2.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S3.SS2.SSS2.p2.1.m1.1a"><mn id="S3.SS2.SSS2.p2.1.m1.1.1" xref="S3.SS2.SSS2.p2.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.1.m1.1b"><cn type="integer" id="S3.SS2.SSS2.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.1.m1.1c">3</annotation></semantics></math>-minute session, we used a <math id="S3.SS2.SSS2.p2.2.m2.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S3.SS2.SSS2.p2.2.m2.1a"><mn id="S3.SS2.SSS2.p2.2.m2.1.1" xref="S3.SS2.SSS2.p2.2.m2.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.2.m2.1b"><cn type="integer" id="S3.SS2.SSS2.p2.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.2.m2.1c">10</annotation></semantics></math>-second sliding window with <math id="S3.SS2.SSS2.p2.3.m3.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S3.SS2.SSS2.p2.3.m3.1a"><mn id="S3.SS2.SSS2.p2.3.m3.1.1" xref="S3.SS2.SSS2.p2.3.m3.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.3.m3.1b"><cn type="integer" id="S3.SS2.SSS2.p2.3.m3.1.1.cmml" xref="S3.SS2.SSS2.p2.3.m3.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.3.m3.1c">50</annotation></semantics></math>% overlap to extract samples from the raw accelerometer and gyroscope data sequences.
We then normalize each dimension of the extracted samples by removing the mean and scaling to unit variance.</p>
</div>
<div id="S3.SS2.SSS2.p3" class="ltx_para">
<p id="S3.SS2.SSS2.p3.2" class="ltx_p"><span id="S3.SS2.SSS2.p3.2.1" class="ltx_text ltx_font_bold">UT-HAR:</span> We followed <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yang2023sensefi</span>]</cite> and applied a sliding window of <math id="S3.SS2.SSS2.p3.1.m1.1" class="ltx_Math" alttext="250" display="inline"><semantics id="S3.SS2.SSS2.p3.1.m1.1a"><mn id="S3.SS2.SSS2.p3.1.m1.1.1" xref="S3.SS2.SSS2.p3.1.m1.1.1.cmml">250</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.1.m1.1b"><cn type="integer" id="S3.SS2.SSS2.p3.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1">250</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.1.m1.1c">250</annotation></semantics></math> packets with <math id="S3.SS2.SSS2.p3.2.m2.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S3.SS2.SSS2.p3.2.m2.1a"><mn id="S3.SS2.SSS2.p3.2.m2.1.1" xref="S3.SS2.SSS2.p3.2.m2.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.2.m2.1b"><cn type="integer" id="S3.SS2.SSS2.p3.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.2.m2.1c">50</annotation></semantics></math>% overlap to the raw Wi-Fi data from all three antennas to extract samples. We then normalize each dimension of the extracted samples by removing the mean and scaling to unit variance.</p>
</div>
<div id="S3.SS2.SSS2.p4" class="ltx_para">
<p id="S3.SS2.SSS2.p4.3" class="ltx_p"><span id="S3.SS2.SSS2.p4.3.1" class="ltx_text ltx_font_bold">Widar:</span>
We adopt the body velocity profile (BVP) processing technique as outlined in <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yang2023sensefi</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zheng2019zero</span>]</cite> in order to effectively handle and remove environmental variations from the data. We then apply standard scalar normalization to further refine the data.
This creates data samples with the shape (<math id="S3.SS2.SSS2.p4.1.m1.1" class="ltx_Math" alttext="22\times 20\times 20" display="inline"><semantics id="S3.SS2.SSS2.p4.1.m1.1a"><mrow id="S3.SS2.SSS2.p4.1.m1.1.1" xref="S3.SS2.SSS2.p4.1.m1.1.1.cmml"><mn id="S3.SS2.SSS2.p4.1.m1.1.1.2" xref="S3.SS2.SSS2.p4.1.m1.1.1.2.cmml">22</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.SSS2.p4.1.m1.1.1.1" xref="S3.SS2.SSS2.p4.1.m1.1.1.1.cmml">×</mo><mn id="S3.SS2.SSS2.p4.1.m1.1.1.3" xref="S3.SS2.SSS2.p4.1.m1.1.1.3.cmml">20</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.SSS2.p4.1.m1.1.1.1a" xref="S3.SS2.SSS2.p4.1.m1.1.1.1.cmml">×</mo><mn id="S3.SS2.SSS2.p4.1.m1.1.1.4" xref="S3.SS2.SSS2.p4.1.m1.1.1.4.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p4.1.m1.1b"><apply id="S3.SS2.SSS2.p4.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p4.1.m1.1.1"><times id="S3.SS2.SSS2.p4.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p4.1.m1.1.1.1"></times><cn type="integer" id="S3.SS2.SSS2.p4.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p4.1.m1.1.1.2">22</cn><cn type="integer" id="S3.SS2.SSS2.p4.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p4.1.m1.1.1.3">20</cn><cn type="integer" id="S3.SS2.SSS2.p4.1.m1.1.1.4.cmml" xref="S3.SS2.SSS2.p4.1.m1.1.1.4">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p4.1.m1.1c">22\times 20\times 20</annotation></semantics></math>) reflecting time axis, <math id="S3.SS2.SSS2.p4.2.m2.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS2.SSS2.p4.2.m2.1a"><mi id="S3.SS2.SSS2.p4.2.m2.1.1" xref="S3.SS2.SSS2.p4.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p4.2.m2.1b"><ci id="S3.SS2.SSS2.p4.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p4.2.m2.1c">x</annotation></semantics></math>, and <math id="S3.SS2.SSS2.p4.3.m3.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S3.SS2.SSS2.p4.3.m3.1a"><mi id="S3.SS2.SSS2.p4.3.m3.1.1" xref="S3.SS2.SSS2.p4.3.m3.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p4.3.m3.1b"><ci id="S3.SS2.SSS2.p4.3.m3.1.1.cmml" xref="S3.SS2.SSS2.p4.3.m3.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p4.3.m3.1c">y</annotation></semantics></math> velocity features respectively.</p>
</div>
<div id="S3.SS2.SSS2.p5" class="ltx_para">
<p id="S3.SS2.SSS2.p5.1" class="ltx_p"><span id="S3.SS2.SSS2.p5.1.1" class="ltx_text ltx_font_bold">VisDrone:</span> We first normalized the images within a range of 0 to 1 to standardize the pixel values. Data augmentation techniques including random shifts in Hue, Saturation, and Value color space, image compression, shearing transformations, scaling transformations, horizontal and vertical flipping, and MixUp were applied to increase the diversity and generalizability of the dataset.</p>
</div>
<div id="S3.SS2.SSS2.p6" class="ltx_para">
<p id="S3.SS2.SSS2.p6.1" class="ltx_p"><span id="S3.SS2.SSS2.p6.1.1" class="ltx_text ltx_font_bold">CASAS:</span> We followed <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">liciotti2019sequential</span>]</cite> to transform the sensor readings into categorical sequences, creating a form of semantic encoding. Each unique temperature setting is assigned a distinct categorical value, as are individual instances of motion sensors and door sensors being activated. For each recorded activity, we then extract a sequence of the 2000 previous sensor activations which is used for modeling and prediction activity.</p>
</div>
<div id="S3.SS2.SSS2.p7" class="ltx_para">
<p id="S3.SS2.SSS2.p7.1" class="ltx_p"><span id="S3.SS2.SSS2.p7.1.1" class="ltx_text ltx_font_bold">AEP:</span>
Temperature data were log-transformed for skewness, and ‘visibility’ was binarized. Outliers below the <span id="S3.SS2.SSS2.p7.1.2" class="ltx_ERROR undefined">\nth</span>10 or above the <span id="S3.SS2.SSS2.p7.1.3" class="ltx_ERROR undefined">\nth</span>90 percentile were replaced with corresponding percentile values. Central tendency and date features were added for time-related patterns. Principal component analysis was used for data reduction, and the output was normalized using a standard scaler.</p>
</div>
<div id="S3.SS2.SSS2.p8" class="ltx_para">
<p id="S3.SS2.SSS2.p8.2" class="ltx_p"><span id="S3.SS2.SSS2.p8.2.1" class="ltx_text ltx_font_bold">EPIC-SOUNDS:</span> We first performed Short-Time Fourier Transform on raw audio segments followed by applying a Hann window of 10ms duration and a step size of 5ms to ensure optimal spectral resolution. We then extracted <math id="S3.SS2.SSS2.p8.1.m1.1" class="ltx_Math" alttext="128" display="inline"><semantics id="S3.SS2.SSS2.p8.1.m1.1a"><mn id="S3.SS2.SSS2.p8.1.m1.1.1" xref="S3.SS2.SSS2.p8.1.m1.1.1.cmml">128</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p8.1.m1.1b"><cn type="integer" id="S3.SS2.SSS2.p8.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p8.1.m1.1.1">128</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p8.1.m1.1c">128</annotation></semantics></math> Mel Spectrogram features, a popular choice for audio classification tasks due to their ability to mimic human auditory system characteristics. To further enhance the data, we applied a natural logarithm scaling to the Mel Spectrogram output. Lastly, to enforce uniform input size across all samples, we padded each segment to reach a consistent length of <math id="S3.SS2.SSS2.p8.2.m2.1" class="ltx_Math" alttext="400" display="inline"><semantics id="S3.SS2.SSS2.p8.2.m2.1a"><mn id="S3.SS2.SSS2.p8.2.m2.1.1" xref="S3.SS2.SSS2.p8.2.m2.1.1.cmml">400</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p8.2.m2.1b"><cn type="integer" id="S3.SS2.SSS2.p8.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p8.2.m2.1.1">400</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p8.2.m2.1c">400</annotation></semantics></math>.</p>
</div>
</section>
<section id="S3.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3 </span>AIoT-friendly Models</h4>

<div id="S3.SS2.SSS3.p1" class="ltx_para">
<p id="S3.SS2.SSS3.p1.1" class="ltx_p">Our choice of models is informed by a combination of state-of-the-art results, as referenced in <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wisdmmodel</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yang2023sensefi</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">terven2023comprehensive</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liciotti2019sequential</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">seyedzadeh2018energy</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">sholahudin2016prediction</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">epicsounds2023</span>]</cite>, and the resource constraints of the IoT platforms. For example, it is unrealistic to assume that IoT platforms could load and run large Transformer-based models for FL. Hence, we focus on AIoT-friendly models in <span id="S3.SS2.SSS3.p1.1.1" class="ltx_text ltx_font_typewriter">FedAIoT</span>. Table <a href="#S3.T2" title="Table 2 ‣ 3.2.3 AIoT-friendly Models ‣ 3.2 End-to-End Federated Learning Framework for AIoT ‣ 3 Design of FedAIoT ‣ FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> presents the list of the selected models. A detailed breakdown of each model’s architecture can be found in Appendix <a href="#A1.SS3" title="A.3 Model Architectures ‣ Appendix A Appendix ‣ Checklist ‣ 5 Conclusion ‣ 4.5 Insights from Benchmark Results ‣ 4.4 Performance on Quantized Training ‣ 4.3 Impact of Erroneous Labels ‣ 4 Experiments and Analysis ‣ FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.3</span></a>. Furthermore, a list of models supported for each dataset is also provided in Appendix.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T2.10.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S3.T2.11.2" class="ltx_text" style="font-size:90%;">Non-IID data partitioning schemes and models used for each dataset.</span></figcaption>
<div id="S3.T2.8" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:192.4pt;vertical-align:-0.5pt;"><span class="ltx_transformed_inner" style="transform:translate(-190.1pt,84.1pt) scale(0.532856101971265,0.532856101971265) ;">
<table id="S3.T2.8.8" class="ltx_tabular ltx_align_middle">
<tr id="S3.T2.8.8.9" class="ltx_tr">
<td id="S3.T2.8.8.9.1" class="ltx_td ltx_align_center"><span id="S3.T2.8.8.9.1.1" class="ltx_text ltx_font_bold">Dataset</span></td>
<td id="S3.T2.8.8.9.2" class="ltx_td ltx_align_left"><span id="S3.T2.8.8.9.2.1" class="ltx_text ltx_font_bold">WISDM-W</span></td>
<td id="S3.T2.8.8.9.3" class="ltx_td ltx_align_left"><span id="S3.T2.8.8.9.3.1" class="ltx_text ltx_font_bold">WISDM-P</span></td>
<td id="S3.T2.8.8.9.4" class="ltx_td ltx_align_center"><span id="S3.T2.8.8.9.4.1" class="ltx_text ltx_font_bold">UT-HAR</span></td>
<td id="S3.T2.8.8.9.5" class="ltx_td ltx_align_right"><span id="S3.T2.8.8.9.5.1" class="ltx_text ltx_font_bold">Widar</span></td>
<td id="S3.T2.8.8.9.6" class="ltx_td ltx_align_center">
<span id="S3.T2.8.8.9.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.8.8.9.6.1.1" class="ltx_p"><span id="S3.T2.8.8.9.6.1.1.1" class="ltx_text ltx_font_bold">VisDrone</span></span>
</span>
</td>
<td id="S3.T2.8.8.9.7" class="ltx_td ltx_align_left"><span id="S3.T2.8.8.9.7.1" class="ltx_text ltx_font_bold">CASAS</span></td>
<td id="S3.T2.8.8.9.8" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T2.8.8.9.8.1" class="ltx_text ltx_font_bold">AEP</span></td>
<td id="S3.T2.8.8.9.9" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T2.8.8.9.9.1" class="ltx_text ltx_font_bold">EPIC-SOUNDS</span></td>
</tr>
<tr id="S3.T2.8.8.10" class="ltx_tr">
<td id="S3.T2.8.8.10.1" class="ltx_td ltx_align_center"><span id="S3.T2.8.8.10.1.1" class="ltx_text ltx_font_bold">Partition</span></td>
<td id="S3.T2.8.8.10.2" class="ltx_td ltx_align_left">Output Labels</td>
<td id="S3.T2.8.8.10.3" class="ltx_td ltx_align_left">Output Labels</td>
<td id="S3.T2.8.8.10.4" class="ltx_td ltx_align_center">Output Labels</td>
<td id="S3.T2.8.8.10.5" class="ltx_td ltx_align_right">Output Labels</td>
<td id="S3.T2.8.8.10.6" class="ltx_td ltx_align_center">
<span id="S3.T2.8.8.10.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.8.8.10.6.1.1" class="ltx_p">Input Features</span>
</span>
</td>
<td id="S3.T2.8.8.10.7" class="ltx_td ltx_align_left">Output Labels</td>
<td id="S3.T2.8.8.10.8" class="ltx_td ltx_nopad_r ltx_align_center">Output Distribution</td>
<td id="S3.T2.8.8.10.9" class="ltx_td ltx_nopad_r ltx_align_center">Output Labels</td>
</tr>
<tr id="S3.T2.8.8.11" class="ltx_tr">
<td id="S3.T2.8.8.11.1" class="ltx_td ltx_align_center"><span id="S3.T2.8.8.11.1.1" class="ltx_text ltx_font_bold">Model</span></td>
<td id="S3.T2.8.8.11.2" class="ltx_td ltx_align_left">LSTM</td>
<td id="S3.T2.8.8.11.3" class="ltx_td ltx_align_left">LSTM</td>
<td id="S3.T2.8.8.11.4" class="ltx_td ltx_align_center">ResNet18</td>
<td id="S3.T2.8.8.11.5" class="ltx_td ltx_align_right">ResNet18</td>
<td id="S3.T2.8.8.11.6" class="ltx_td ltx_align_center">
<span id="S3.T2.8.8.11.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.8.8.11.6.1.1" class="ltx_p">YOLOv8n</span>
</span>
</td>
<td id="S3.T2.8.8.11.7" class="ltx_td ltx_align_left">BiLSTM</td>
<td id="S3.T2.8.8.11.8" class="ltx_td ltx_nopad_r ltx_align_center">MLP</td>
<td id="S3.T2.8.8.11.9" class="ltx_td ltx_nopad_r ltx_align_center">ResNet18</td>
</tr>
<tr id="S3.T2.8.8.8" class="ltx_tr">
<td id="S3.T2.8.8.8.9" class="ltx_td"></td>
<td id="S3.T2.1.1.1.1" class="ltx_td ltx_align_left"><math id="S3.T2.1.1.1.1.m1.1" class="ltx_Math" alttext="{}^{\cite[cite]{[\@@bibref{}{wisdmmodel}{}{}]}}" display="inline"><semantics id="S3.T2.1.1.1.1.m1.1a"><msup id="S3.T2.1.1.1.1.m1.1.1" xref="S3.T2.1.1.1.1.m1.1.1.cmml"><mi id="S3.T2.1.1.1.1.m1.1.1a" xref="S3.T2.1.1.1.1.m1.1.1.cmml"></mi><mtext class="ltx_citemacro_cite" mathsize="142%" id="S3.T2.1.1.1.1.m1.1.1.1" xref="S3.T2.1.1.1.1.m1.1.1.1e.cmml"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.1.1.1.1.m1.1.1.1.1.1nest" class="ltx_text" style="font-size:70%;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">wisdmmodel</span><span id="S3.T2.1.1.1.1.m1.1.1.1.2.2nest" class="ltx_text" style="font-size:70%;">]</span></cite></mtext></msup><annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.1.m1.1b"><apply id="S3.T2.1.1.1.1.m1.1.1.cmml" xref="S3.T2.1.1.1.1.m1.1.1"><ci id="S3.T2.1.1.1.1.m1.1.1.1e.cmml" xref="S3.T2.1.1.1.1.m1.1.1.1"><mtext class="ltx_citemacro_cite" id="S3.T2.1.1.1.1.m1.1.1.1.cmml" xref="S3.T2.1.1.1.1.m1.1.1.1"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.1.1.1.1.m1.1.1.1.1.1anest" class="ltx_text" style="font-size:70%;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">wisdmmodel</span><span id="S3.T2.1.1.1.1.m1.1.1.1.2.2anest" class="ltx_text" style="font-size:70%;">]</span></cite></mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.1.1.1.m1.1c">{}^{\cite[cite]{[\@@bibref{}{wisdmmodel}{}{}]}}</annotation></semantics></math></td>
<td id="S3.T2.2.2.2.2" class="ltx_td ltx_align_left"><math id="S3.T2.2.2.2.2.m1.1" class="ltx_Math" alttext="{}^{\cite[cite]{[\@@bibref{}{wisdmmodel}{}{}]}}" display="inline"><semantics id="S3.T2.2.2.2.2.m1.1a"><msup id="S3.T2.2.2.2.2.m1.1.1" xref="S3.T2.2.2.2.2.m1.1.1.cmml"><mi id="S3.T2.2.2.2.2.m1.1.1a" xref="S3.T2.2.2.2.2.m1.1.1.cmml"></mi><mtext class="ltx_citemacro_cite" mathsize="142%" id="S3.T2.2.2.2.2.m1.1.1.1" xref="S3.T2.2.2.2.2.m1.1.1.1e.cmml"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.2.2.2.2.m1.1.1.1.1.1nest" class="ltx_text" style="font-size:70%;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">wisdmmodel</span><span id="S3.T2.2.2.2.2.m1.1.1.1.2.2nest" class="ltx_text" style="font-size:70%;">]</span></cite></mtext></msup><annotation-xml encoding="MathML-Content" id="S3.T2.2.2.2.2.m1.1b"><apply id="S3.T2.2.2.2.2.m1.1.1.cmml" xref="S3.T2.2.2.2.2.m1.1.1"><ci id="S3.T2.2.2.2.2.m1.1.1.1e.cmml" xref="S3.T2.2.2.2.2.m1.1.1.1"><mtext class="ltx_citemacro_cite" id="S3.T2.2.2.2.2.m1.1.1.1.cmml" xref="S3.T2.2.2.2.2.m1.1.1.1"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.2.2.2.2.m1.1.1.1.1.1anest" class="ltx_text" style="font-size:70%;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">wisdmmodel</span><span id="S3.T2.2.2.2.2.m1.1.1.1.2.2anest" class="ltx_text" style="font-size:70%;">]</span></cite></mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.2.2.2.m1.1c">{}^{\cite[cite]{[\@@bibref{}{wisdmmodel}{}{}]}}</annotation></semantics></math></td>
<td id="S3.T2.3.3.3.3" class="ltx_td ltx_align_center"><math id="S3.T2.3.3.3.3.m1.1" class="ltx_Math" alttext="{}^{\cite[cite]{[\@@bibref{}{he2016residual, yang2023sensefi, hsieh2020data}{}{}]}}" display="inline"><semantics id="S3.T2.3.3.3.3.m1.1a"><msup id="S3.T2.3.3.3.3.m1.1.1" xref="S3.T2.3.3.3.3.m1.1.1.cmml"><mi id="S3.T2.3.3.3.3.m1.1.1a" xref="S3.T2.3.3.3.3.m1.1.1.cmml"></mi><mtext class="ltx_citemacro_cite" mathsize="142%" id="S3.T2.3.3.3.3.m1.1.1.1" xref="S3.T2.3.3.3.3.m1.1.1.1g.cmml"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.3.3.3.m1.1.1.1.1.1nest" class="ltx_text" style="font-size:70%;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">he2016residual</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yang2023sensefi</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">hsieh2020data</span><span id="S3.T2.3.3.3.3.m1.1.1.1.2.2nest" class="ltx_text" style="font-size:70%;">]</span></cite></mtext></msup><annotation-xml encoding="MathML-Content" id="S3.T2.3.3.3.3.m1.1b"><apply id="S3.T2.3.3.3.3.m1.1.1.cmml" xref="S3.T2.3.3.3.3.m1.1.1"><ci id="S3.T2.3.3.3.3.m1.1.1.1g.cmml" xref="S3.T2.3.3.3.3.m1.1.1.1"><mtext class="ltx_citemacro_cite" id="S3.T2.3.3.3.3.m1.1.1.1.cmml" xref="S3.T2.3.3.3.3.m1.1.1.1"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.3.3.3.3.m1.1.1.1.1.1anest" class="ltx_text" style="font-size:70%;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">he2016residual</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yang2023sensefi</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">hsieh2020data</span><span id="S3.T2.3.3.3.3.m1.1.1.1.2.2anest" class="ltx_text" style="font-size:70%;">]</span></cite></mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.3.3.3.3.m1.1c">{}^{\cite[cite]{[\@@bibref{}{he2016residual, yang2023sensefi, hsieh2020data}{}{}]}}</annotation></semantics></math></td>
<td id="S3.T2.4.4.4.4" class="ltx_td ltx_align_right"><math id="S3.T2.4.4.4.4.m1.1" class="ltx_Math" alttext="{}^{\cite[cite]{[\@@bibref{}{he2016residual, yang2023sensefi, hsieh2020data}{}{}]}}" display="inline"><semantics id="S3.T2.4.4.4.4.m1.1a"><msup id="S3.T2.4.4.4.4.m1.1.1" xref="S3.T2.4.4.4.4.m1.1.1.cmml"><mi id="S3.T2.4.4.4.4.m1.1.1a" xref="S3.T2.4.4.4.4.m1.1.1.cmml"></mi><mtext class="ltx_citemacro_cite" mathsize="142%" id="S3.T2.4.4.4.4.m1.1.1.1" xref="S3.T2.4.4.4.4.m1.1.1.1g.cmml"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.4.4.4.4.m1.1.1.1.1.1nest" class="ltx_text" style="font-size:70%;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">he2016residual</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yang2023sensefi</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">hsieh2020data</span><span id="S3.T2.4.4.4.4.m1.1.1.1.2.2nest" class="ltx_text" style="font-size:70%;">]</span></cite></mtext></msup><annotation-xml encoding="MathML-Content" id="S3.T2.4.4.4.4.m1.1b"><apply id="S3.T2.4.4.4.4.m1.1.1.cmml" xref="S3.T2.4.4.4.4.m1.1.1"><ci id="S3.T2.4.4.4.4.m1.1.1.1g.cmml" xref="S3.T2.4.4.4.4.m1.1.1.1"><mtext class="ltx_citemacro_cite" id="S3.T2.4.4.4.4.m1.1.1.1.cmml" xref="S3.T2.4.4.4.4.m1.1.1.1"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.4.4.4.4.m1.1.1.1.1.1anest" class="ltx_text" style="font-size:70%;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">he2016residual</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yang2023sensefi</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">hsieh2020data</span><span id="S3.T2.4.4.4.4.m1.1.1.1.2.2anest" class="ltx_text" style="font-size:70%;">]</span></cite></mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.4.4.4.4.m1.1c">{}^{\cite[cite]{[\@@bibref{}{he2016residual, yang2023sensefi, hsieh2020data}{}{}]}}</annotation></semantics></math></td>
<td id="S3.T2.5.5.5.5" class="ltx_td ltx_align_center">
<span id="S3.T2.5.5.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.5.5.5.5.1.1" class="ltx_p"><math id="S3.T2.5.5.5.5.1.1.m1.1" class="ltx_Math" alttext="{}^{\cite[cite]{[\@@bibref{}{terven2023comprehensive}{}{}]}}" display="inline"><semantics id="S3.T2.5.5.5.5.1.1.m1.1a"><msup id="S3.T2.5.5.5.5.1.1.m1.1.1" xref="S3.T2.5.5.5.5.1.1.m1.1.1.cmml"><mi id="S3.T2.5.5.5.5.1.1.m1.1.1a" xref="S3.T2.5.5.5.5.1.1.m1.1.1.cmml"></mi><mtext class="ltx_citemacro_cite" mathsize="142%" id="S3.T2.5.5.5.5.1.1.m1.1.1.1" xref="S3.T2.5.5.5.5.1.1.m1.1.1.1e.cmml"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.5.5.5.5.1.1.m1.1.1.1.1.1nest" class="ltx_text" style="font-size:70%;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">terven2023comprehensive</span><span id="S3.T2.5.5.5.5.1.1.m1.1.1.1.2.2nest" class="ltx_text" style="font-size:70%;">]</span></cite></mtext></msup><annotation-xml encoding="MathML-Content" id="S3.T2.5.5.5.5.1.1.m1.1b"><apply id="S3.T2.5.5.5.5.1.1.m1.1.1.cmml" xref="S3.T2.5.5.5.5.1.1.m1.1.1"><ci id="S3.T2.5.5.5.5.1.1.m1.1.1.1e.cmml" xref="S3.T2.5.5.5.5.1.1.m1.1.1.1"><mtext class="ltx_citemacro_cite" id="S3.T2.5.5.5.5.1.1.m1.1.1.1.cmml" xref="S3.T2.5.5.5.5.1.1.m1.1.1.1"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.5.5.5.5.1.1.m1.1.1.1.1.1anest" class="ltx_text" style="font-size:70%;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">terven2023comprehensive</span><span id="S3.T2.5.5.5.5.1.1.m1.1.1.1.2.2anest" class="ltx_text" style="font-size:70%;">]</span></cite></mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.5.5.5.5.1.1.m1.1c">{}^{\cite[cite]{[\@@bibref{}{terven2023comprehensive}{}{}]}}</annotation></semantics></math></span>
</span>
</td>
<td id="S3.T2.6.6.6.6" class="ltx_td ltx_align_left"><math id="S3.T2.6.6.6.6.m1.1" class="ltx_Math" alttext="{}^{\cite[cite]{[\@@bibref{}{liciotti2019sequential}{}{}]}}" display="inline"><semantics id="S3.T2.6.6.6.6.m1.1a"><msup id="S3.T2.6.6.6.6.m1.1.1" xref="S3.T2.6.6.6.6.m1.1.1.cmml"><mi id="S3.T2.6.6.6.6.m1.1.1a" xref="S3.T2.6.6.6.6.m1.1.1.cmml"></mi><mtext class="ltx_citemacro_cite" mathsize="142%" id="S3.T2.6.6.6.6.m1.1.1.1" xref="S3.T2.6.6.6.6.m1.1.1.1e.cmml"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.6.6.6.6.m1.1.1.1.1.1nest" class="ltx_text" style="font-size:70%;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">liciotti2019sequential</span><span id="S3.T2.6.6.6.6.m1.1.1.1.2.2nest" class="ltx_text" style="font-size:70%;">]</span></cite></mtext></msup><annotation-xml encoding="MathML-Content" id="S3.T2.6.6.6.6.m1.1b"><apply id="S3.T2.6.6.6.6.m1.1.1.cmml" xref="S3.T2.6.6.6.6.m1.1.1"><ci id="S3.T2.6.6.6.6.m1.1.1.1e.cmml" xref="S3.T2.6.6.6.6.m1.1.1.1"><mtext class="ltx_citemacro_cite" id="S3.T2.6.6.6.6.m1.1.1.1.cmml" xref="S3.T2.6.6.6.6.m1.1.1.1"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.6.6.6.6.m1.1.1.1.1.1anest" class="ltx_text" style="font-size:70%;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">liciotti2019sequential</span><span id="S3.T2.6.6.6.6.m1.1.1.1.2.2anest" class="ltx_text" style="font-size:70%;">]</span></cite></mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.6.6.6.6.m1.1c">{}^{\cite[cite]{[\@@bibref{}{liciotti2019sequential}{}{}]}}</annotation></semantics></math></td>
<td id="S3.T2.7.7.7.7" class="ltx_td ltx_nopad_r ltx_align_center"><math id="S3.T2.7.7.7.7.m1.1" class="ltx_Math" alttext="{}^{\cite[cite]{[\@@bibref{}{seyedzadeh2018energy}{}{}]}}" display="inline"><semantics id="S3.T2.7.7.7.7.m1.1a"><msup id="S3.T2.7.7.7.7.m1.1.1" xref="S3.T2.7.7.7.7.m1.1.1.cmml"><mi id="S3.T2.7.7.7.7.m1.1.1a" xref="S3.T2.7.7.7.7.m1.1.1.cmml"></mi><mtext class="ltx_citemacro_cite" mathsize="142%" id="S3.T2.7.7.7.7.m1.1.1.1" xref="S3.T2.7.7.7.7.m1.1.1.1e.cmml"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.7.7.7.7.m1.1.1.1.1.1nest" class="ltx_text" style="font-size:70%;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">seyedzadeh2018energy</span><span id="S3.T2.7.7.7.7.m1.1.1.1.2.2nest" class="ltx_text" style="font-size:70%;">]</span></cite></mtext></msup><annotation-xml encoding="MathML-Content" id="S3.T2.7.7.7.7.m1.1b"><apply id="S3.T2.7.7.7.7.m1.1.1.cmml" xref="S3.T2.7.7.7.7.m1.1.1"><ci id="S3.T2.7.7.7.7.m1.1.1.1e.cmml" xref="S3.T2.7.7.7.7.m1.1.1.1"><mtext class="ltx_citemacro_cite" id="S3.T2.7.7.7.7.m1.1.1.1.cmml" xref="S3.T2.7.7.7.7.m1.1.1.1"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.7.7.7.7.m1.1.1.1.1.1anest" class="ltx_text" style="font-size:70%;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">seyedzadeh2018energy</span><span id="S3.T2.7.7.7.7.m1.1.1.1.2.2anest" class="ltx_text" style="font-size:70%;">]</span></cite></mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.7.7.7.7.m1.1c">{}^{\cite[cite]{[\@@bibref{}{seyedzadeh2018energy}{}{}]}}</annotation></semantics></math></td>
<td id="S3.T2.8.8.8.8" class="ltx_td ltx_nopad_r ltx_align_center"><math id="S3.T2.8.8.8.8.m1.1" class="ltx_Math" alttext="{}^{\cite[cite]{[\@@bibref{}{epicsounds2023}{}{}]}}" display="inline"><semantics id="S3.T2.8.8.8.8.m1.1a"><msup id="S3.T2.8.8.8.8.m1.1.1" xref="S3.T2.8.8.8.8.m1.1.1.cmml"><mi id="S3.T2.8.8.8.8.m1.1.1a" xref="S3.T2.8.8.8.8.m1.1.1.cmml"></mi><mtext class="ltx_citemacro_cite" mathsize="142%" id="S3.T2.8.8.8.8.m1.1.1.1" xref="S3.T2.8.8.8.8.m1.1.1.1e.cmml"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.8.8.8.8.m1.1.1.1.1.1nest" class="ltx_text" style="font-size:70%;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">epicsounds2023</span><span id="S3.T2.8.8.8.8.m1.1.1.1.2.2nest" class="ltx_text" style="font-size:70%;">]</span></cite></mtext></msup><annotation-xml encoding="MathML-Content" id="S3.T2.8.8.8.8.m1.1b"><apply id="S3.T2.8.8.8.8.m1.1.1.cmml" xref="S3.T2.8.8.8.8.m1.1.1"><ci id="S3.T2.8.8.8.8.m1.1.1.1e.cmml" xref="S3.T2.8.8.8.8.m1.1.1.1"><mtext class="ltx_citemacro_cite" id="S3.T2.8.8.8.8.m1.1.1.1.cmml" xref="S3.T2.8.8.8.8.m1.1.1.1"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.8.8.8.8.m1.1.1.1.1.1anest" class="ltx_text" style="font-size:70%;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">epicsounds2023</span><span id="S3.T2.8.8.8.8.m1.1.1.1.2.2anest" class="ltx_text" style="font-size:70%;">]</span></cite></mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.8.8.8.8.m1.1c">{}^{\cite[cite]{[\@@bibref{}{epicsounds2023}{}{}]}}</annotation></semantics></math></td>
</tr>
</table>
</span></div>
</figure>
</section>
<section id="S3.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.4 </span>FL Hyperparameters</h4>

<div id="S3.SS2.SSS4.p1" class="ltx_para">
<p id="S3.SS2.SSS4.p1.1" class="ltx_p"><span id="S3.SS2.SSS4.p1.1.1" class="ltx_text ltx_font_bold">Data Heterogeneity Level.</span> Non-IIDness is a fundamental challenge in FL training, creating artifacts like gradient drifting that negatively impact the final model performance. As outlined in Section <a href="#S3.SS2.SSS1" title="3.2.1 Non-IID Data Partitioning ‣ 3.2 End-to-End Federated Learning Framework for AIoT ‣ 3 Design of FedAIoT ‣ FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.1</span></a>, <span id="S3.SS2.SSS4.p1.1.2" class="ltx_text ltx_font_typewriter">FedAIoT</span> facilitates the creation of diverse data partitions, allowing for the simulation of varying levels of data heterogeneity to meet experimental requirements.</p>
</div>
<div id="S3.SS2.SSS4.p2" class="ltx_para">
<p id="S3.SS2.SSS4.p2.1" class="ltx_p"><span id="S3.SS2.SSS4.p2.1.1" class="ltx_text ltx_font_bold">FL Optimizer.</span> <span id="S3.SS2.SSS4.p2.1.2" class="ltx_text ltx_font_typewriter">FedAIoT</span> supports a handful of commonly used FL optimizers. In the experiment section, we showcase the benchmark results of two FL optimizers: FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mcmahan2017communication</span>]</cite> and FedOPT <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">reddi2020adaptive</span>]</cite>.</p>
</div>
<div id="S3.SS2.SSS4.p3" class="ltx_para">
<p id="S3.SS2.SSS4.p3.1" class="ltx_p"><span id="S3.SS2.SSS4.p3.1.1" class="ltx_text ltx_font_bold">Client Sampling Ratio.</span> Client sampling ratio denotes the proportion of clients selected for local training in each round of FL. This hyperparameter plays a crucial role as it directly influences the computation and communication costs associated with FL training. <span id="S3.SS2.SSS4.p3.1.2" class="ltx_text ltx_font_typewriter">FedAIoT</span> facilitates the creation of diverse client sampling ratios and the examination of its impact on both model performance and convergence speed during FL training.</p>
</div>
</section>
<section id="S3.SS2.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.5 </span>IoT Factors</h4>

<div id="S3.SS2.SSS5.p1" class="ltx_para">
<p id="S3.SS2.SSS5.p1.13" class="ltx_p"><span id="S3.SS2.SSS5.p1.13.1" class="ltx_text ltx_font_bold">Real-world Erroneous Label Emulation.</span>

Real-world FL deployments on IoT devices often encounter label noise resulting from various sources such as bias, skill differences, and labeling errors introduced by annotators. To effectively emulate label errors in FL, we propose augmenting the ground truth labels of a dataset with a confusion matrix, denoted as <math id="S3.SS2.SSS5.p1.1.m1.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.SS2.SSS5.p1.1.m1.1a"><mi id="S3.SS2.SSS5.p1.1.m1.1.1" xref="S3.SS2.SSS5.p1.1.m1.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.p1.1.m1.1b"><ci id="S3.SS2.SSS5.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS5.p1.1.m1.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.p1.1.m1.1c">Q</annotation></semantics></math>. Here, <math id="S3.SS2.SSS5.p1.2.m2.1" class="ltx_Math" alttext="Q_{ij}" display="inline"><semantics id="S3.SS2.SSS5.p1.2.m2.1a"><msub id="S3.SS2.SSS5.p1.2.m2.1.1" xref="S3.SS2.SSS5.p1.2.m2.1.1.cmml"><mi id="S3.SS2.SSS5.p1.2.m2.1.1.2" xref="S3.SS2.SSS5.p1.2.m2.1.1.2.cmml">Q</mi><mrow id="S3.SS2.SSS5.p1.2.m2.1.1.3" xref="S3.SS2.SSS5.p1.2.m2.1.1.3.cmml"><mi id="S3.SS2.SSS5.p1.2.m2.1.1.3.2" xref="S3.SS2.SSS5.p1.2.m2.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS5.p1.2.m2.1.1.3.1" xref="S3.SS2.SSS5.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS2.SSS5.p1.2.m2.1.1.3.3" xref="S3.SS2.SSS5.p1.2.m2.1.1.3.3.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.p1.2.m2.1b"><apply id="S3.SS2.SSS5.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS5.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS5.p1.2.m2.1.1.1.cmml" xref="S3.SS2.SSS5.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS5.p1.2.m2.1.1.2.cmml" xref="S3.SS2.SSS5.p1.2.m2.1.1.2">𝑄</ci><apply id="S3.SS2.SSS5.p1.2.m2.1.1.3.cmml" xref="S3.SS2.SSS5.p1.2.m2.1.1.3"><times id="S3.SS2.SSS5.p1.2.m2.1.1.3.1.cmml" xref="S3.SS2.SSS5.p1.2.m2.1.1.3.1"></times><ci id="S3.SS2.SSS5.p1.2.m2.1.1.3.2.cmml" xref="S3.SS2.SSS5.p1.2.m2.1.1.3.2">𝑖</ci><ci id="S3.SS2.SSS5.p1.2.m2.1.1.3.3.cmml" xref="S3.SS2.SSS5.p1.2.m2.1.1.3.3">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.p1.2.m2.1c">Q_{ij}</annotation></semantics></math> represents the probability that the ground truth label <math id="S3.SS2.SSS5.p1.3.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS2.SSS5.p1.3.m3.1a"><mi id="S3.SS2.SSS5.p1.3.m3.1.1" xref="S3.SS2.SSS5.p1.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.p1.3.m3.1b"><ci id="S3.SS2.SSS5.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS5.p1.3.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.p1.3.m3.1c">i</annotation></semantics></math> is changed to a different label <math id="S3.SS2.SSS5.p1.4.m4.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S3.SS2.SSS5.p1.4.m4.1a"><mi id="S3.SS2.SSS5.p1.4.m4.1.1" xref="S3.SS2.SSS5.p1.4.m4.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.p1.4.m4.1b"><ci id="S3.SS2.SSS5.p1.4.m4.1.1.cmml" xref="S3.SS2.SSS5.p1.4.m4.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.p1.4.m4.1c">j</annotation></semantics></math>, i.e., <math id="S3.SS2.SSS5.p1.5.m5.1" class="ltx_Math" alttext="P(\hat{y}=j\mid y=i)" display="inline"><semantics id="S3.SS2.SSS5.p1.5.m5.1a"><mrow id="S3.SS2.SSS5.p1.5.m5.1.1" xref="S3.SS2.SSS5.p1.5.m5.1.1.cmml"><mi id="S3.SS2.SSS5.p1.5.m5.1.1.3" xref="S3.SS2.SSS5.p1.5.m5.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS5.p1.5.m5.1.1.2" xref="S3.SS2.SSS5.p1.5.m5.1.1.2.cmml">​</mo><mrow id="S3.SS2.SSS5.p1.5.m5.1.1.1.1" xref="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.SSS5.p1.5.m5.1.1.1.1.2" xref="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1" xref="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.cmml"><mover accent="true" id="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.2" xref="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.2.cmml"><mi id="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.2.2" xref="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.2.2.cmml">y</mi><mo id="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.2.1" xref="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.2.1.cmml">^</mo></mover><mo id="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.3" xref="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.3.cmml">=</mo><mrow id="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.4" xref="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.4.cmml"><mi id="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.4.2" xref="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.4.2.cmml">j</mi><mo id="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.4.1" xref="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.4.1.cmml">∣</mo><mi id="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.4.3" xref="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.4.3.cmml">y</mi></mrow><mo id="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.5" xref="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.5.cmml">=</mo><mi id="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.6" xref="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.6.cmml">i</mi></mrow><mo stretchy="false" id="S3.SS2.SSS5.p1.5.m5.1.1.1.1.3" xref="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.p1.5.m5.1b"><apply id="S3.SS2.SSS5.p1.5.m5.1.1.cmml" xref="S3.SS2.SSS5.p1.5.m5.1.1"><times id="S3.SS2.SSS5.p1.5.m5.1.1.2.cmml" xref="S3.SS2.SSS5.p1.5.m5.1.1.2"></times><ci id="S3.SS2.SSS5.p1.5.m5.1.1.3.cmml" xref="S3.SS2.SSS5.p1.5.m5.1.1.3">𝑃</ci><apply id="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.cmml" xref="S3.SS2.SSS5.p1.5.m5.1.1.1.1"><and id="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1a.cmml" xref="S3.SS2.SSS5.p1.5.m5.1.1.1.1"></and><apply id="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1b.cmml" xref="S3.SS2.SSS5.p1.5.m5.1.1.1.1"><eq id="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.3.cmml" xref="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.3"></eq><apply id="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.2"><ci id="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.2.1.cmml" xref="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.2.1">^</ci><ci id="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.2.2.cmml" xref="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.2.2">𝑦</ci></apply><apply id="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.4.cmml" xref="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.4"><csymbol cd="latexml" id="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.4.1.cmml" xref="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.4.1">conditional</csymbol><ci id="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.4.2.cmml" xref="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.4.2">𝑗</ci><ci id="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.4.3.cmml" xref="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.4.3">𝑦</ci></apply></apply><apply id="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1c.cmml" xref="S3.SS2.SSS5.p1.5.m5.1.1.1.1"><eq id="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.5.cmml" xref="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.5"></eq><share href="#S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.4.cmml" id="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1d.cmml" xref="S3.SS2.SSS5.p1.5.m5.1.1.1.1"></share><ci id="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.6.cmml" xref="S3.SS2.SSS5.p1.5.m5.1.1.1.1.1.6">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.p1.5.m5.1c">P(\hat{y}=j\mid y=i)</annotation></semantics></math>. Unlike previous benchmark work <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2023fedaudio</span>]</cite>, where the confusion matrix <math id="S3.SS2.SSS5.p1.6.m6.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.SS2.SSS5.p1.6.m6.1a"><mi id="S3.SS2.SSS5.p1.6.m6.1.1" xref="S3.SS2.SSS5.p1.6.m6.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.p1.6.m6.1b"><ci id="S3.SS2.SSS5.p1.6.m6.1.1.cmml" xref="S3.SS2.SSS5.p1.6.m6.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.p1.6.m6.1c">Q</annotation></semantics></math> was randomly constructed, our approach involves constructing the confusion matrix based on centralized training results.
Specifically, we determine the elements of <math id="S3.SS2.SSS5.p1.7.m7.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.SS2.SSS5.p1.7.m7.1a"><mi id="S3.SS2.SSS5.p1.7.m7.1.1" xref="S3.SS2.SSS5.p1.7.m7.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.p1.7.m7.1b"><ci id="S3.SS2.SSS5.p1.7.m7.1.1.cmml" xref="S3.SS2.SSS5.p1.7.m7.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.p1.7.m7.1c">Q</annotation></semantics></math> (i.e., <math id="S3.SS2.SSS5.p1.8.m8.1" class="ltx_Math" alttext="Q_{ij}" display="inline"><semantics id="S3.SS2.SSS5.p1.8.m8.1a"><msub id="S3.SS2.SSS5.p1.8.m8.1.1" xref="S3.SS2.SSS5.p1.8.m8.1.1.cmml"><mi id="S3.SS2.SSS5.p1.8.m8.1.1.2" xref="S3.SS2.SSS5.p1.8.m8.1.1.2.cmml">Q</mi><mrow id="S3.SS2.SSS5.p1.8.m8.1.1.3" xref="S3.SS2.SSS5.p1.8.m8.1.1.3.cmml"><mi id="S3.SS2.SSS5.p1.8.m8.1.1.3.2" xref="S3.SS2.SSS5.p1.8.m8.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS5.p1.8.m8.1.1.3.1" xref="S3.SS2.SSS5.p1.8.m8.1.1.3.1.cmml">​</mo><mi id="S3.SS2.SSS5.p1.8.m8.1.1.3.3" xref="S3.SS2.SSS5.p1.8.m8.1.1.3.3.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.p1.8.m8.1b"><apply id="S3.SS2.SSS5.p1.8.m8.1.1.cmml" xref="S3.SS2.SSS5.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS5.p1.8.m8.1.1.1.cmml" xref="S3.SS2.SSS5.p1.8.m8.1.1">subscript</csymbol><ci id="S3.SS2.SSS5.p1.8.m8.1.1.2.cmml" xref="S3.SS2.SSS5.p1.8.m8.1.1.2">𝑄</ci><apply id="S3.SS2.SSS5.p1.8.m8.1.1.3.cmml" xref="S3.SS2.SSS5.p1.8.m8.1.1.3"><times id="S3.SS2.SSS5.p1.8.m8.1.1.3.1.cmml" xref="S3.SS2.SSS5.p1.8.m8.1.1.3.1"></times><ci id="S3.SS2.SSS5.p1.8.m8.1.1.3.2.cmml" xref="S3.SS2.SSS5.p1.8.m8.1.1.3.2">𝑖</ci><ci id="S3.SS2.SSS5.p1.8.m8.1.1.3.3.cmml" xref="S3.SS2.SSS5.p1.8.m8.1.1.3.3">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.p1.8.m8.1c">Q_{ij}</annotation></semantics></math>) by calculating the ratio of the number of samples labeled as <math id="S3.SS2.SSS5.p1.9.m9.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S3.SS2.SSS5.p1.9.m9.1a"><mi id="S3.SS2.SSS5.p1.9.m9.1.1" xref="S3.SS2.SSS5.p1.9.m9.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.p1.9.m9.1b"><ci id="S3.SS2.SSS5.p1.9.m9.1.1.cmml" xref="S3.SS2.SSS5.p1.9.m9.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.p1.9.m9.1c">j</annotation></semantics></math> by the centrally trained machine learning model to the total number of samples with the ground truth label <math id="S3.SS2.SSS5.p1.10.m10.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS2.SSS5.p1.10.m10.1a"><mi id="S3.SS2.SSS5.p1.10.m10.1.1" xref="S3.SS2.SSS5.p1.10.m10.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.p1.10.m10.1b"><ci id="S3.SS2.SSS5.p1.10.m10.1.1.cmml" xref="S3.SS2.SSS5.p1.10.m10.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.p1.10.m10.1c">i</annotation></semantics></math>. This construction method ensures that the confusion matrix accurately reflects the labeling patterns observed during centralized training.
We employ the confusion matrix <math id="S3.SS2.SSS5.p1.11.m11.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.SS2.SSS5.p1.11.m11.1a"><mi id="S3.SS2.SSS5.p1.11.m11.1.1" xref="S3.SS2.SSS5.p1.11.m11.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.p1.11.m11.1b"><ci id="S3.SS2.SSS5.p1.11.m11.1.1.cmml" xref="S3.SS2.SSS5.p1.11.m11.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.p1.11.m11.1c">Q</annotation></semantics></math> as a guiding tool for generating error labels. To introduce different levels of erroneous label ratio <math id="S3.SS2.SSS5.p1.12.m12.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.SS2.SSS5.p1.12.m12.1a"><mi id="S3.SS2.SSS5.p1.12.m12.1.1" xref="S3.SS2.SSS5.p1.12.m12.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.p1.12.m12.1b"><ci id="S3.SS2.SSS5.p1.12.m12.1.1.cmml" xref="S3.SS2.SSS5.p1.12.m12.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.p1.12.m12.1c">\epsilon</annotation></semantics></math>, we randomly select the required number of data samples and apply the label changes based on the probabilities specified in the confusion matrix <math id="S3.SS2.SSS5.p1.13.m13.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.SS2.SSS5.p1.13.m13.1a"><mi id="S3.SS2.SSS5.p1.13.m13.1.1" xref="S3.SS2.SSS5.p1.13.m13.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.p1.13.m13.1b"><ci id="S3.SS2.SSS5.p1.13.m13.1.1.cmml" xref="S3.SS2.SSS5.p1.13.m13.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.p1.13.m13.1c">Q</annotation></semantics></math>.
By incorporating such realistic label errors in our FL simulations, we aim to provide a more reliable evaluation of FL algorithms under challenging real-world conditions.</p>
</div>
<div id="S3.SS2.SSS5.p2" class="ltx_para">
<p id="S3.SS2.SSS5.p2.1" class="ltx_p"><span id="S3.SS2.SSS5.p2.1.1" class="ltx_text ltx_font_bold">Quantized Training.</span>

IoT devices often operate under significant resource constraints. In such case, model quantization becomes essential. This technique, involving the reduction of numerical precision in computations and data of AI models, optimizes memory use and computational efficiency.
In <span id="S3.SS2.SSS5.p2.1.2" class="ltx_text ltx_font_typewriter">FedAIoT</span>, we incorporate two levels of precision, full (float32) and half (float16). While prior research has predominantly focused on the application of quantization during inference, it becomes equally crucial to examine the implications of training models under quantized conditions in the task of FL.
Our models were thus trained under both precision formats. The objective was to investigate the balance between computational efficiency and model accuracy. This understanding is key in navigating the resource constraints of IoT devices and enabling FL for AIoT.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments and Analysis</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.5" class="ltx_p">We implemented <span id="S4.p1.5.1" class="ltx_text ltx_font_typewriter">FedAIoT</span> using PyTorch <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">pytorch</span>]</cite> and Ray <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ray</span>]</cite>, and conducted our experiments on a combination 8<math id="S4.p1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.p1.1.m1.1a"><mo id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><times id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">\times</annotation></semantics></math>NVIDIA A6000 GPU cluster, 8<math id="S4.p1.2.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.p1.2.m2.1a"><mo id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><times id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">\times</annotation></semantics></math>NVIDIA RTX8000 GPU, 8<math id="S4.p1.3.m3.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.p1.3.m3.1a"><mo id="S4.p1.3.m3.1.1" xref="S4.p1.3.m3.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.p1.3.m3.1b"><times id="S4.p1.3.m3.1.1.cmml" xref="S4.p1.3.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.3.m3.1c">\times</annotation></semantics></math>NVIDIA A6000 GPU, 8<math id="S4.p1.4.m4.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.p1.4.m4.1a"><mo id="S4.p1.4.m4.1.1" xref="S4.p1.4.m4.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.p1.4.m4.1b"><times id="S4.p1.4.m4.1.1.cmml" xref="S4.p1.4.m4.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.4.m4.1c">\times</annotation></semantics></math>NVIDIA RTX3090 GPU and 10<math id="S4.p1.5.m5.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.p1.5.m5.1a"><mo id="S4.p1.5.m5.1.1" xref="S4.p1.5.m5.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.p1.5.m5.1b"><times id="S4.p1.5.m5.1.1.cmml" xref="S4.p1.5.m5.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.5.m5.1c">\times</annotation></semantics></math>NVIDIA A100 GPU clusters as needed.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Overall Performance</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.2" class="ltx_p">First, we benchmark the FL performance under two FL optimizers, FedAvg and FedOPT, under low (<math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="\alpha=0.5" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mrow id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><mi id="S4.SS1.p1.1.m1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.2.cmml">α</mi><mo id="S4.SS1.p1.1.m1.1.1.1" xref="S4.SS1.p1.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS1.p1.1.m1.1.1.3" xref="S4.SS1.p1.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><eq id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1.1"></eq><ci id="S4.SS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2">𝛼</ci><cn type="float" id="S4.SS1.p1.1.m1.1.1.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">\alpha=0.5</annotation></semantics></math>) and high (<math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="\alpha=0.1" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><mrow id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml"><mi id="S4.SS1.p1.2.m2.1.1.2" xref="S4.SS1.p1.2.m2.1.1.2.cmml">α</mi><mo id="S4.SS1.p1.2.m2.1.1.1" xref="S4.SS1.p1.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS1.p1.2.m2.1.1.3" xref="S4.SS1.p1.2.m2.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><apply id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1"><eq id="S4.SS1.p1.2.m2.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1.1"></eq><ci id="S4.SS1.p1.2.m2.1.1.2.cmml" xref="S4.SS1.p1.2.m2.1.1.2">𝛼</ci><cn type="float" id="S4.SS1.p1.2.m2.1.1.3.cmml" xref="S4.SS1.p1.2.m2.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">\alpha=0.1</annotation></semantics></math>) data heterogeneity levels, and compare it against centralized training.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.5.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S4.T3.6.2" class="ltx_text" style="font-size:90%;">Overall performance.</span></figcaption>
<div id="S4.T3.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:184.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(5.0pt,-2.1pt) scale(1.02342465580263,1.02342465580263) ;">
<table id="S4.T3.3.3" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.2.2.2" class="ltx_tr">
<td id="S4.T3.2.2.2.3" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T3.2.2.2.3.1" class="ltx_text ltx_font_bold">Dataset</span></td>
<td id="S4.T3.2.2.2.4" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T3.2.2.2.4.1" class="ltx_text ltx_font_bold">Metric</span></td>
<td id="S4.T3.2.2.2.5" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T3.2.2.2.5.1" class="ltx_text ltx_font_bold">Centralized</span></td>
<td id="S4.T3.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">
<span id="S4.T3.1.1.1.1.1" class="ltx_text ltx_font_bold">Low Data Heterogeneity</span> (<math id="S4.T3.1.1.1.1.m1.1" class="ltx_Math" alttext="\mathbf{\alpha=0.5}" display="inline"><semantics id="S4.T3.1.1.1.1.m1.1a"><mrow id="S4.T3.1.1.1.1.m1.1.1" xref="S4.T3.1.1.1.1.m1.1.1.cmml"><mi id="S4.T3.1.1.1.1.m1.1.1.2" xref="S4.T3.1.1.1.1.m1.1.1.2.cmml">α</mi><mo id="S4.T3.1.1.1.1.m1.1.1.1" xref="S4.T3.1.1.1.1.m1.1.1.1.cmml">=</mo><mn class="ltx_mathvariant_bold" mathvariant="bold" id="S4.T3.1.1.1.1.m1.1.1.3" xref="S4.T3.1.1.1.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.1.m1.1b"><apply id="S4.T3.1.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.1.m1.1.1"><eq id="S4.T3.1.1.1.1.m1.1.1.1.cmml" xref="S4.T3.1.1.1.1.m1.1.1.1"></eq><ci id="S4.T3.1.1.1.1.m1.1.1.2.cmml" xref="S4.T3.1.1.1.1.m1.1.1.2">𝛼</ci><cn type="float" id="S4.T3.1.1.1.1.m1.1.1.3.cmml" xref="S4.T3.1.1.1.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.1.m1.1c">\mathbf{\alpha=0.5}</annotation></semantics></math>)</td>
<td id="S4.T3.2.2.2.6" class="ltx_td ltx_border_tt"></td>
<td id="S4.T3.2.2.2.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">
<span id="S4.T3.2.2.2.2.1" class="ltx_text ltx_font_bold">High Data Heterogeneity</span> (<math id="S4.T3.2.2.2.2.m1.1" class="ltx_Math" alttext="\mathbf{\alpha=0.1}" display="inline"><semantics id="S4.T3.2.2.2.2.m1.1a"><mrow id="S4.T3.2.2.2.2.m1.1.1" xref="S4.T3.2.2.2.2.m1.1.1.cmml"><mi id="S4.T3.2.2.2.2.m1.1.1.2" xref="S4.T3.2.2.2.2.m1.1.1.2.cmml">α</mi><mo id="S4.T3.2.2.2.2.m1.1.1.1" xref="S4.T3.2.2.2.2.m1.1.1.1.cmml">=</mo><mn class="ltx_mathvariant_bold" mathvariant="bold" id="S4.T3.2.2.2.2.m1.1.1.3" xref="S4.T3.2.2.2.2.m1.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.2.m1.1b"><apply id="S4.T3.2.2.2.2.m1.1.1.cmml" xref="S4.T3.2.2.2.2.m1.1.1"><eq id="S4.T3.2.2.2.2.m1.1.1.1.cmml" xref="S4.T3.2.2.2.2.m1.1.1.1"></eq><ci id="S4.T3.2.2.2.2.m1.1.1.2.cmml" xref="S4.T3.2.2.2.2.m1.1.1.2">𝛼</ci><cn type="float" id="S4.T3.2.2.2.2.m1.1.1.3.cmml" xref="S4.T3.2.2.2.2.m1.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.2.m1.1c">\mathbf{\alpha=0.1}</annotation></semantics></math>)</td>
</tr>
<tr id="S4.T3.3.3.4" class="ltx_tr">
<td id="S4.T3.3.3.4.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.3.4.1.1" class="ltx_text ltx_font_bold">FedAvg</span></td>
<td id="S4.T3.3.3.4.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.3.4.2.1" class="ltx_text ltx_font_bold">FedOPT</span></td>
<td id="S4.T3.3.3.4.3" class="ltx_td ltx_border_t"></td>
<td id="S4.T3.3.3.4.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.3.4.4.1" class="ltx_text ltx_font_bold">FedAvg</span></td>
<td id="S4.T3.3.3.4.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.3.4.5.1" class="ltx_text ltx_font_bold">FedOPT</span></td>
</tr>
<tr id="S4.T3.3.3.5" class="ltx_tr">
<td id="S4.T3.3.3.5.1" class="ltx_td ltx_align_center ltx_border_t">WISDM-W</td>
<td id="S4.T3.3.3.5.2" class="ltx_td ltx_align_center ltx_border_t">Accuracy (%)</td>
<td id="S4.T3.3.3.5.3" class="ltx_td ltx_align_center ltx_border_t">71.47</td>
<td id="S4.T3.3.3.5.4" class="ltx_td ltx_align_center ltx_border_t">68.60</td>
<td id="S4.T3.3.3.5.5" class="ltx_td ltx_align_center ltx_border_t">67.93</td>
<td id="S4.T3.3.3.5.6" class="ltx_td ltx_border_t"></td>
<td id="S4.T3.3.3.5.7" class="ltx_td ltx_align_center ltx_border_t">65.97</td>
<td id="S4.T3.3.3.5.8" class="ltx_td ltx_align_center ltx_border_t">59.03</td>
</tr>
<tr id="S4.T3.3.3.6" class="ltx_tr">
<td id="S4.T3.3.3.6.1" class="ltx_td ltx_align_center">WISDM-P</td>
<td id="S4.T3.3.3.6.2" class="ltx_td ltx_align_center">Accuracy (%)</td>
<td id="S4.T3.3.3.6.3" class="ltx_td ltx_align_center">35.76</td>
<td id="S4.T3.3.3.6.4" class="ltx_td ltx_align_center">33.74</td>
<td id="S4.T3.3.3.6.5" class="ltx_td ltx_align_center">31.67</td>
<td id="S4.T3.3.3.6.6" class="ltx_td"></td>
<td id="S4.T3.3.3.6.7" class="ltx_td ltx_align_center">32.26</td>
<td id="S4.T3.3.3.6.8" class="ltx_td ltx_align_center">28.72</td>
</tr>
<tr id="S4.T3.3.3.7" class="ltx_tr">
<td id="S4.T3.3.3.7.1" class="ltx_td ltx_align_center">UT-HAR</td>
<td id="S4.T3.3.3.7.2" class="ltx_td ltx_align_center">Accuracy (%)</td>
<td id="S4.T3.3.3.7.3" class="ltx_td ltx_align_center">95.79</td>
<td id="S4.T3.3.3.7.4" class="ltx_td ltx_align_center">94.57</td>
<td id="S4.T3.3.3.7.5" class="ltx_td ltx_align_center">76.96</td>
<td id="S4.T3.3.3.7.6" class="ltx_td"></td>
<td id="S4.T3.3.3.7.7" class="ltx_td ltx_align_center">76.04</td>
<td id="S4.T3.3.3.7.8" class="ltx_td ltx_align_center">66.04</td>
</tr>
<tr id="S4.T3.3.3.8" class="ltx_tr">
<td id="S4.T3.3.3.8.1" class="ltx_td ltx_align_center">Widar</td>
<td id="S4.T3.3.3.8.2" class="ltx_td ltx_align_center">Accuracy (%)</td>
<td id="S4.T3.3.3.8.3" class="ltx_td ltx_align_center">61.14</td>
<td id="S4.T3.3.3.8.4" class="ltx_td ltx_align_center">60.19</td>
<td id="S4.T3.3.3.8.5" class="ltx_td ltx_align_center">59.83</td>
<td id="S4.T3.3.3.8.6" class="ltx_td"></td>
<td id="S4.T3.3.3.8.7" class="ltx_td ltx_align_center">54.95</td>
<td id="S4.T3.3.3.8.8" class="ltx_td ltx_align_center">50.32</td>
</tr>
<tr id="S4.T3.3.3.9" class="ltx_tr">
<td id="S4.T3.3.3.9.1" class="ltx_td ltx_align_center">VisDrone</td>
<td id="S4.T3.3.3.9.2" class="ltx_td ltx_align_center">MAP-50 (%)</td>
<td id="S4.T3.3.3.9.3" class="ltx_td ltx_align_center">35.50</td>
<td id="S4.T3.3.3.9.4" class="ltx_td ltx_align_center">34.04</td>
<td id="S4.T3.3.3.9.5" class="ltx_td ltx_align_center">32.40</td>
<td id="S4.T3.3.3.9.6" class="ltx_td"></td>
<td id="S4.T3.3.3.9.7" class="ltx_td ltx_align_center">31.55</td>
<td id="S4.T3.3.3.9.8" class="ltx_td ltx_align_center">29.39</td>
</tr>
<tr id="S4.T3.3.3.10" class="ltx_tr">
<td id="S4.T3.3.3.10.1" class="ltx_td ltx_align_center">CASAS</td>
<td id="S4.T3.3.3.10.2" class="ltx_td ltx_align_center">Accuracy (%)</td>
<td id="S4.T3.3.3.10.3" class="ltx_td ltx_align_center">86.24</td>
<td id="S4.T3.3.3.10.4" class="ltx_td ltx_align_center">73.26</td>
<td id="S4.T3.3.3.10.5" class="ltx_td ltx_align_center">72.27</td>
<td id="S4.T3.3.3.10.6" class="ltx_td"></td>
<td id="S4.T3.3.3.10.7" class="ltx_td ltx_align_center">70.72</td>
<td id="S4.T3.3.3.10.8" class="ltx_td ltx_align_center">69.80</td>
</tr>
<tr id="S4.T3.3.3.3" class="ltx_tr">
<td id="S4.T3.3.3.3.2" class="ltx_td ltx_align_center">AEP</td>
<td id="S4.T3.3.3.3.1" class="ltx_td ltx_align_center"><math id="S4.T3.3.3.3.1.m1.1" class="ltx_Math" alttext="R^{2}" display="inline"><semantics id="S4.T3.3.3.3.1.m1.1a"><msup id="S4.T3.3.3.3.1.m1.1.1" xref="S4.T3.3.3.3.1.m1.1.1.cmml"><mi id="S4.T3.3.3.3.1.m1.1.1.2" xref="S4.T3.3.3.3.1.m1.1.1.2.cmml">R</mi><mn id="S4.T3.3.3.3.1.m1.1.1.3" xref="S4.T3.3.3.3.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.1.m1.1b"><apply id="S4.T3.3.3.3.1.m1.1.1.cmml" xref="S4.T3.3.3.3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.3.3.3.1.m1.1.1.1.cmml" xref="S4.T3.3.3.3.1.m1.1.1">superscript</csymbol><ci id="S4.T3.3.3.3.1.m1.1.1.2.cmml" xref="S4.T3.3.3.3.1.m1.1.1.2">𝑅</ci><cn type="integer" id="S4.T3.3.3.3.1.m1.1.1.3.cmml" xref="S4.T3.3.3.3.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.3.1.m1.1c">R^{2}</annotation></semantics></math></td>
<td id="S4.T3.3.3.3.3" class="ltx_td ltx_align_center">0.58</td>
<td id="S4.T3.3.3.3.4" class="ltx_td ltx_align_center">0.51</td>
<td id="S4.T3.3.3.3.5" class="ltx_td ltx_align_center">0.48</td>
<td id="S4.T3.3.3.3.6" class="ltx_td"></td>
<td id="S4.T3.3.3.3.7" class="ltx_td ltx_align_center">0.41</td>
<td id="S4.T3.3.3.3.8" class="ltx_td ltx_align_center">0.39</td>
</tr>
<tr id="S4.T3.3.3.11" class="ltx_tr">
<td id="S4.T3.3.3.11.1" class="ltx_td ltx_align_center ltx_border_bb">EPIC-SOUNDS</td>
<td id="S4.T3.3.3.11.2" class="ltx_td ltx_align_center ltx_border_bb">Accuracy (%)</td>
<td id="S4.T3.3.3.11.3" class="ltx_td ltx_align_center ltx_border_bb">42.67</td>
<td id="S4.T3.3.3.11.4" class="ltx_td ltx_align_center ltx_border_bb">34.82</td>
<td id="S4.T3.3.3.11.5" class="ltx_td ltx_align_center ltx_border_bb">29.10</td>
<td id="S4.T3.3.3.11.6" class="ltx_td ltx_border_bb"></td>
<td id="S4.T3.3.3.11.7" class="ltx_td ltx_align_center ltx_border_bb">26.71</td>
<td id="S4.T3.3.3.11.8" class="ltx_td ltx_align_center ltx_border_bb">20.01</td>
</tr>
</table>
</span></div>
</figure>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">Benchmark Results:</span>
Table <a href="#S4.T3" title="Table 3 ‣ 4.1 Overall Performance ‣ 4 Experiments and Analysis ‣ FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> summarizes our results. We make three observations.
(1) Data heterogeneity level and FL optimizer have different impacts on different datasets. In particular, the performance of UT-HAR and Widar are very sensitive to the data heterogeneity level. In contrast, WISDM-P does not show noticeably accuracy difference under FedAvg at different data heterogeneity levels.
(2) Under low data heterogeneity, FedAvg provides a more stable performance compared to FedOPT and consistently achieves performance closer to centralized training across diverse data modalities.
(3) Compared to the other datasets, CASAS, AEP, and EPIC-SOUNDS have higher accuracy margins between centralized training and low data heterogeneity. This indicates the need for more advanced FL algorithms for CASAS, AEP, and EPIC-SOUNDS datasets.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Impact of Client Sampling Ratio</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.5" class="ltx_p">IoT devices usually have significant communication restrictions and hence the client sampling ratio is a critical hyperparameter for FL systems operating AIoT devices. In this experiment, we focus on two client sampling ratios: <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mn id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><cn type="integer" id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">10</annotation></semantics></math>% and <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="30" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><mn id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><cn type="integer" id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">30</annotation></semantics></math>%. Our exploration involved recording the maximum accuracy reached after completing <math id="S4.SS2.p1.3.m3.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S4.SS2.p1.3.m3.1a"><mn id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><cn type="integer" id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">50</annotation></semantics></math>%, <math id="S4.SS2.p1.4.m4.1" class="ltx_Math" alttext="80" display="inline"><semantics id="S4.SS2.p1.4.m4.1a"><mn id="S4.SS2.p1.4.m4.1.1" xref="S4.SS2.p1.4.m4.1.1.cmml">80</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.4.m4.1b"><cn type="integer" id="S4.SS2.p1.4.m4.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1">80</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.4.m4.1c">80</annotation></semantics></math>%, and <math id="S4.SS2.p1.5.m5.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S4.SS2.p1.5.m5.1a"><mn id="S4.SS2.p1.5.m5.1.1" xref="S4.SS2.p1.5.m5.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.5.m5.1b"><cn type="integer" id="S4.SS2.p1.5.m5.1.1.cmml" xref="S4.SS2.p1.5.m5.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.5.m5.1c">100</annotation></semantics></math>% of the total training rounds for both these ratios under high data heterogeneity, thereby offering empirical evidence of how the model’s performance and convergence rate are affected by the client sampling ratio.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.4.1.1" class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span id="S4.T4.5.2" class="ltx_text" style="font-size:90%;">Impact of client sampling ratio.</span></figcaption>
<div id="S4.T4.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:134pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-76.1pt,23.4pt) scale(0.740280389756334,0.740280389756334) ;">
<table id="S4.T4.2.2" class="ltx_tabular ltx_align_middle">
<tr id="S4.T4.2.2.2" class="ltx_tr">
<td id="S4.T4.2.2.2.3" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T4.2.2.2.3.1" class="ltx_text ltx_font_bold">Dataset</span></td>
<td id="S4.T4.2.2.2.4" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T4.2.2.2.4.1" class="ltx_text ltx_font_bold">Training Rounds</span></td>
<td id="S4.T4.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S4.T4.1.1.1.1.1" class="ltx_text ltx_font_bold">Low Client Sampling Ratio (<math id="S4.T4.1.1.1.1.1.m1.1" class="ltx_Math" alttext="10\%" display="inline"><semantics id="S4.T4.1.1.1.1.1.m1.1a"><mrow id="S4.T4.1.1.1.1.1.m1.1.1" xref="S4.T4.1.1.1.1.1.m1.1.1.cmml"><mn id="S4.T4.1.1.1.1.1.m1.1.1.2" xref="S4.T4.1.1.1.1.1.m1.1.1.2.cmml">10</mn><mo id="S4.T4.1.1.1.1.1.m1.1.1.1" xref="S4.T4.1.1.1.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.1.1.m1.1b"><apply id="S4.T4.1.1.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.1.1.m1.1.1"><csymbol cd="latexml" id="S4.T4.1.1.1.1.1.m1.1.1.1.cmml" xref="S4.T4.1.1.1.1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S4.T4.1.1.1.1.1.m1.1.1.2.cmml" xref="S4.T4.1.1.1.1.1.m1.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.1.1.m1.1c">10\%</annotation></semantics></math>)</span></td>
<td id="S4.T4.2.2.2.5" class="ltx_td ltx_border_tt"></td>
<td id="S4.T4.2.2.2.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S4.T4.2.2.2.2.1" class="ltx_text ltx_font_bold">High Client Sampling Ratio (<math id="S4.T4.2.2.2.2.1.m1.1" class="ltx_Math" alttext="30\%" display="inline"><semantics id="S4.T4.2.2.2.2.1.m1.1a"><mrow id="S4.T4.2.2.2.2.1.m1.1.1" xref="S4.T4.2.2.2.2.1.m1.1.1.cmml"><mn id="S4.T4.2.2.2.2.1.m1.1.1.2" xref="S4.T4.2.2.2.2.1.m1.1.1.2.cmml">30</mn><mo id="S4.T4.2.2.2.2.1.m1.1.1.1" xref="S4.T4.2.2.2.2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.2.2.2.2.1.m1.1b"><apply id="S4.T4.2.2.2.2.1.m1.1.1.cmml" xref="S4.T4.2.2.2.2.1.m1.1.1"><csymbol cd="latexml" id="S4.T4.2.2.2.2.1.m1.1.1.1.cmml" xref="S4.T4.2.2.2.2.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S4.T4.2.2.2.2.1.m1.1.1.2.cmml" xref="S4.T4.2.2.2.2.1.m1.1.1.2">30</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.2.2.2.1.m1.1c">30\%</annotation></semantics></math>)</span></td>
</tr>
<tr id="S4.T4.2.2.3" class="ltx_tr">
<td id="S4.T4.2.2.3.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.2.2.3.1.1" class="ltx_text ltx_font_bold">50% Rounds</span></td>
<td id="S4.T4.2.2.3.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.2.2.3.2.1" class="ltx_text ltx_font_bold">80% Rounds</span></td>
<td id="S4.T4.2.2.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.2.2.3.3.1" class="ltx_text ltx_font_bold">100% Rounds</span></td>
<td id="S4.T4.2.2.3.4" class="ltx_td ltx_border_t"></td>
<td id="S4.T4.2.2.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.2.2.3.5.1" class="ltx_text ltx_font_bold">50% Rounds</span></td>
<td id="S4.T4.2.2.3.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.2.2.3.6.1" class="ltx_text ltx_font_bold">80% Rounds</span></td>
<td id="S4.T4.2.2.3.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S4.T4.2.2.3.7.1" class="ltx_text ltx_font_bold">100% Rounds</span></td>
</tr>
<tr id="S4.T4.2.2.4" class="ltx_tr">
<td id="S4.T4.2.2.4.1" class="ltx_td ltx_align_center ltx_border_t">WISDM-W</td>
<td id="S4.T4.2.2.4.2" class="ltx_td ltx_align_center ltx_border_t">400</td>
<td id="S4.T4.2.2.4.3" class="ltx_td ltx_align_center ltx_border_t">57.15</td>
<td id="S4.T4.2.2.4.4" class="ltx_td ltx_align_center ltx_border_t">63.40</td>
<td id="S4.T4.2.2.4.5" class="ltx_td ltx_align_center ltx_border_t">65.97</td>
<td id="S4.T4.2.2.4.6" class="ltx_td ltx_border_t"></td>
<td id="S4.T4.2.2.4.7" class="ltx_td ltx_align_center ltx_border_t">59.17</td>
<td id="S4.T4.2.2.4.8" class="ltx_td ltx_align_center ltx_border_t">65.85</td>
<td id="S4.T4.2.2.4.9" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">66.78</td>
</tr>
<tr id="S4.T4.2.2.5" class="ltx_tr">
<td id="S4.T4.2.2.5.1" class="ltx_td ltx_align_center">WISDM-P</td>
<td id="S4.T4.2.2.5.2" class="ltx_td ltx_align_center">400</td>
<td id="S4.T4.2.2.5.3" class="ltx_td ltx_align_center">32.26</td>
<td id="S4.T4.2.2.5.4" class="ltx_td ltx_align_center">32.26</td>
<td id="S4.T4.2.2.5.5" class="ltx_td ltx_align_center">32.26</td>
<td id="S4.T4.2.2.5.6" class="ltx_td"></td>
<td id="S4.T4.2.2.5.7" class="ltx_td ltx_align_center">31.05</td>
<td id="S4.T4.2.2.5.8" class="ltx_td ltx_align_center">32.73</td>
<td id="S4.T4.2.2.5.9" class="ltx_td ltx_nopad_r ltx_align_center">32.73</td>
</tr>
<tr id="S4.T4.2.2.6" class="ltx_tr">
<td id="S4.T4.2.2.6.1" class="ltx_td ltx_align_center">UT-HAR</td>
<td id="S4.T4.2.2.6.2" class="ltx_td ltx_align_center">1200</td>
<td id="S4.T4.2.2.6.3" class="ltx_td ltx_align_center">53.3</td>
<td id="S4.T4.2.2.6.4" class="ltx_td ltx_align_center">71.46</td>
<td id="S4.T4.2.2.6.5" class="ltx_td ltx_align_center">76.04</td>
<td id="S4.T4.2.2.6.6" class="ltx_td"></td>
<td id="S4.T4.2.2.6.7" class="ltx_td ltx_align_center">60.12</td>
<td id="S4.T4.2.2.6.8" class="ltx_td ltx_align_center">77.92</td>
<td id="S4.T4.2.2.6.9" class="ltx_td ltx_nopad_r ltx_align_center">81.67</td>
</tr>
<tr id="S4.T4.2.2.7" class="ltx_tr">
<td id="S4.T4.2.2.7.1" class="ltx_td ltx_align_center">Widar</td>
<td id="S4.T4.2.2.7.2" class="ltx_td ltx_align_center">900</td>
<td id="S4.T4.2.2.7.3" class="ltx_td ltx_align_center">47.09</td>
<td id="S4.T4.2.2.7.4" class="ltx_td ltx_align_center">54.91</td>
<td id="S4.T4.2.2.7.5" class="ltx_td ltx_align_center">54.94</td>
<td id="S4.T4.2.2.7.6" class="ltx_td"></td>
<td id="S4.T4.2.2.7.7" class="ltx_td ltx_align_center">37.69</td>
<td id="S4.T4.2.2.7.8" class="ltx_td ltx_align_center">51.88</td>
<td id="S4.T4.2.2.7.9" class="ltx_td ltx_nopad_r ltx_align_center">55.25</td>
</tr>
<tr id="S4.T4.2.2.8" class="ltx_tr">
<td id="S4.T4.2.2.8.1" class="ltx_td ltx_align_center">VisDrone</td>
<td id="S4.T4.2.2.8.2" class="ltx_td ltx_align_center">600</td>
<td id="S4.T4.2.2.8.3" class="ltx_td ltx_align_center">30.61</td>
<td id="S4.T4.2.2.8.4" class="ltx_td ltx_align_center">31.55</td>
<td id="S4.T4.2.2.8.5" class="ltx_td ltx_align_center">31.55</td>
<td id="S4.T4.2.2.8.6" class="ltx_td"></td>
<td id="S4.T4.2.2.8.7" class="ltx_td ltx_align_center">33.02</td>
<td id="S4.T4.2.2.8.8" class="ltx_td ltx_align_center">35.80</td>
<td id="S4.T4.2.2.8.9" class="ltx_td ltx_nopad_r ltx_align_center">35.80</td>
</tr>
<tr id="S4.T4.2.2.9" class="ltx_tr">
<td id="S4.T4.2.2.9.1" class="ltx_td ltx_align_center">CASAS</td>
<td id="S4.T4.2.2.9.2" class="ltx_td ltx_align_center">400</td>
<td id="S4.T4.2.2.9.3" class="ltx_td ltx_align_center">70.72</td>
<td id="S4.T4.2.2.9.4" class="ltx_td ltx_align_center">70.72</td>
<td id="S4.T4.2.2.9.5" class="ltx_td ltx_align_center">70.72</td>
<td id="S4.T4.2.2.9.6" class="ltx_td"></td>
<td id="S4.T4.2.2.9.7" class="ltx_td ltx_align_center">75.13</td>
<td id="S4.T4.2.2.9.8" class="ltx_td ltx_align_center">76.05</td>
<td id="S4.T4.2.2.9.9" class="ltx_td ltx_nopad_r ltx_align_center">76.68</td>
</tr>
<tr id="S4.T4.2.2.10" class="ltx_tr">
<td id="S4.T4.2.2.10.1" class="ltx_td ltx_align_center">AEP</td>
<td id="S4.T4.2.2.10.2" class="ltx_td ltx_align_center">2000</td>
<td id="S4.T4.2.2.10.3" class="ltx_td ltx_align_center">0.39</td>
<td id="S4.T4.2.2.10.4" class="ltx_td ltx_align_center">0.40</td>
<td id="S4.T4.2.2.10.5" class="ltx_td ltx_align_center">0.41</td>
<td id="S4.T4.2.2.10.6" class="ltx_td"></td>
<td id="S4.T4.2.2.10.7" class="ltx_td ltx_align_center">0.51</td>
<td id="S4.T4.2.2.10.8" class="ltx_td ltx_align_center">0.52</td>
<td id="S4.T4.2.2.10.9" class="ltx_td ltx_nopad_r ltx_align_center">0.53</td>
</tr>
<tr id="S4.T4.2.2.11" class="ltx_tr">
<td id="S4.T4.2.2.11.1" class="ltx_td ltx_align_center ltx_border_bb">EPIC-SOUNDS</td>
<td id="S4.T4.2.2.11.2" class="ltx_td ltx_align_center ltx_border_bb">400</td>
<td id="S4.T4.2.2.11.3" class="ltx_td ltx_align_center ltx_border_bb">16.28</td>
<td id="S4.T4.2.2.11.4" class="ltx_td ltx_align_center ltx_border_bb">23.93</td>
<td id="S4.T4.2.2.11.5" class="ltx_td ltx_align_center ltx_border_bb">26.71</td>
<td id="S4.T4.2.2.11.6" class="ltx_td ltx_border_bb"></td>
<td id="S4.T4.2.2.11.7" class="ltx_td ltx_align_center ltx_border_bb">15.54</td>
<td id="S4.T4.2.2.11.8" class="ltx_td ltx_align_center ltx_border_bb">24.01</td>
<td id="S4.T4.2.2.11.9" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb">26.87</td>
</tr>
</table>
</span></div>
</figure>
<div id="S4.SS2.p2" class="ltx_para ltx_noindent">
<p id="S4.SS2.p2.1" class="ltx_p"><span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_bold">Benchmark Results:</span>
Table <a href="#S4.T4" title="Table 4 ‣ 4.2 Impact of Client Sampling Ratio ‣ 4 Experiments and Analysis ‣ FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> summarizes our results. We make two observations.
(1) An increased client sampling ratio is highly correlated with superior model accuracy (i.e., highest accuracy within 100% training rounds) across different IoT data modalities. This demonstrates the importance of the client sampling ratio to the final model performance at the end of FL.
(2) However, a higher sampling ratio does not inherently guarantee faster model convergence. For example, WISDM-P, Widar, and EPIC-SOUNDS achieve higher model performance with a lower client sampling ratio at 50% training rounds compared to a higher client sampling ratio. This result underscores the complex dynamics between client participation and learning efficiency for different IoT data modalities.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Impact of Erroneous Labels</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.2" class="ltx_p">As elaborated in Section <a href="#S3.SS2.SSS5" title="3.2.5 IoT Factors ‣ 3.2 End-to-End Federated Learning Framework for AIoT ‣ 3 Design of FedAIoT ‣ FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.5</span></a>, we investigate the implications of erroneous labels. We assess the performance of our models under circumstances where the label error ratio is set at <math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><mn id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><cn type="integer" id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">10</annotation></semantics></math>% and <math id="S4.SS3.p1.2.m2.1" class="ltx_Math" alttext="30" display="inline"><semantics id="S4.SS3.p1.2.m2.1a"><mn id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><cn type="integer" id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">30</annotation></semantics></math>%, juxtaposing these results with the control scenario that involves no label errors. Note that we only showcase this for ‘WISDM’, ‘UT-HAR’, ‘WIDAR’, ‘CASAS’, and ‘EPIC-SOUNDS’ as these are classification tasks, and the concept of erroneous labels only apply to classification tasks.</p>
</div>
<figure id="S4.SS3.7" class="ltx_table">

<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.SS3.7.8.1.1" class="ltx_text" style="font-size:90%;">Table 5</span>: </span><span id="S4.SS3.7.9.2" class="ltx_text" style="font-size:90%;">Impact of erroneous labels.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S4.SS3.7.10" class="ltx_inline-block ltx_figure_panel ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(22734262,22734262) ;">
</span></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S4.SS3.7.7" class="ltx_p ltx_figure_panel"><span id="S4.SS3.7.7.1" class="ltx_text ltx_font_bold">Benchmark Results:</span>
Table <a href="#S4.SS3" title="4.3 Impact of Erroneous Labels ‣ 4 Experiments and Analysis ‣ FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a> summarizes our results. We make two observations.
(1) As the ratio of erroneous labels increases, the performance of the models decreases across all the datasets, and the impact of erroneous labels varies across different datasets. For example, WISDM-W only experiences a little performance drop at <math id="S4.SS3.1.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS3.1.1.m1.1a"><mn id="S4.SS3.1.1.m1.1.1" xref="S4.SS3.1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.1.1.m1.1b"><cn type="integer" id="S4.SS3.1.1.m1.1.1.cmml" xref="S4.SS3.1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.1.1.m1.1c">10</annotation></semantics></math>% label error ratio, but its performance significantly drops when the label error ratio increases to <math id="S4.SS3.2.2.m2.1" class="ltx_Math" alttext="30" display="inline"><semantics id="S4.SS3.2.2.m2.1a"><mn id="S4.SS3.2.2.m2.1.1" xref="S4.SS3.2.2.m2.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.2.2.m2.1b"><cn type="integer" id="S4.SS3.2.2.m2.1.1.cmml" xref="S4.SS3.2.2.m2.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.2.2.m2.1c">30</annotation></semantics></math>%. In contrast, CASAS exhibits a more gradual decline in performance as the error ratio increases from <math id="S4.SS3.3.3.m3.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S4.SS3.3.3.m3.1a"><mn id="S4.SS3.3.3.m3.1.1" xref="S4.SS3.3.3.m3.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.3.3.m3.1b"><cn type="integer" id="S4.SS3.3.3.m3.1.1.cmml" xref="S4.SS3.3.3.m3.1.1">0</cn></annotation-xml></semantics></math>% to <math id="S4.SS3.4.4.m4.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS3.4.4.m4.1a"><mn id="S4.SS3.4.4.m4.1.1" xref="S4.SS3.4.4.m4.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.4.4.m4.1b"><cn type="integer" id="S4.SS3.4.4.m4.1.1.cmml" xref="S4.SS3.4.4.m4.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.4.4.m4.1c">10</annotation></semantics></math>% and from <math id="S4.SS3.5.5.m5.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS3.5.5.m5.1a"><mn id="S4.SS3.5.5.m5.1.1" xref="S4.SS3.5.5.m5.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.5.5.m5.1b"><cn type="integer" id="S4.SS3.5.5.m5.1.1.cmml" xref="S4.SS3.5.5.m5.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.5.5.m5.1c">10</annotation></semantics></math>% to <math id="S4.SS3.6.6.m6.1" class="ltx_Math" alttext="30" display="inline"><semantics id="S4.SS3.6.6.m6.1a"><mn id="S4.SS3.6.6.m6.1.1" xref="S4.SS3.6.6.m6.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.6.6.m6.1b"><cn type="integer" id="S4.SS3.6.6.m6.1.1.cmml" xref="S4.SS3.6.6.m6.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.6.6.m6.1c">30</annotation></semantics></math>%.
(2) UT-HAR and EPIC-SOUNDS are very sensitive to label error and show significant accuracy drop even at <math id="S4.SS3.7.7.m7.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS3.7.7.m7.1a"><mn id="S4.SS3.7.7.m7.1.1" xref="S4.SS3.7.7.m7.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.7.7.m7.1b"><cn type="integer" id="S4.SS3.7.7.m7.1.1.cmml" xref="S4.SS3.7.7.m7.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.7.7.m7.1c">10</annotation></semantics></math>% label error ratio.</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<section id="S4.SS4" class="ltx_subsection ltx_figure_panel">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Performance on Quantized Training</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">Lastly, we examine the impact of model quantization on federated learning, specifically using half-precision (FP16). We assess the models’ accuracy and memory usage under this quantization, comparing these results to those from the full-precision (FP32) models. Memory is measured by analyzing the GPU memory usage of a model when trained with the same batch size under a centralized setting.</p>
</div>
<figure id="S4.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T6.11.1.1" class="ltx_text" style="font-size:90%;">Table 6</span>: </span><span id="S4.T6.12.2" class="ltx_text" style="font-size:90%;">Performance on quantized training.</span></figcaption>
<div id="S4.T6.9" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:147.6pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-49.0pt,16.6pt) scale(0.815755272155295,0.815755272155295) ;">
<table id="S4.T6.9.9" class="ltx_tabular ltx_align_middle">
<tr id="S4.T6.9.9.10" class="ltx_tr">
<td id="S4.T6.9.9.10.1" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T6.9.9.10.1.1" class="ltx_text ltx_font_bold">Dataset</span></td>
<td id="S4.T6.9.9.10.2" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T6.9.9.10.2.1" class="ltx_text ltx_font_bold">Metric</span></td>
<td id="S4.T6.9.9.10.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S4.T6.9.9.10.3.1" class="ltx_text ltx_font_bold">FP32</span></td>
<td id="S4.T6.9.9.10.4" class="ltx_td ltx_border_tt"></td>
<td id="S4.T6.9.9.10.5" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S4.T6.9.9.10.5.1" class="ltx_text ltx_font_bold">FP16</span></td>
</tr>
<tr id="S4.T6.9.9.11" class="ltx_tr">
<td id="S4.T6.9.9.11.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T6.9.9.11.1.1" class="ltx_text ltx_font_bold">Model Performance</span></td>
<td id="S4.T6.9.9.11.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T6.9.9.11.2.1" class="ltx_text ltx_font_bold">Memory Usage</span></td>
<td id="S4.T6.9.9.11.3" class="ltx_td"></td>
<td id="S4.T6.9.9.11.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T6.9.9.11.4.1" class="ltx_text ltx_font_bold">Model Performance</span></td>
<td id="S4.T6.9.9.11.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S4.T6.9.9.11.5.1" class="ltx_text ltx_font_bold">Memory Usage</span></td>
</tr>
<tr id="S4.T6.1.1.1" class="ltx_tr">
<td id="S4.T6.1.1.1.2" class="ltx_td ltx_align_center ltx_border_t">WISDM-W</td>
<td id="S4.T6.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t">Accuracy (%)</td>
<td id="S4.T6.1.1.1.4" class="ltx_td ltx_align_center ltx_border_t">65.97</td>
<td id="S4.T6.1.1.1.5" class="ltx_td ltx_align_center ltx_border_t">1444 MB</td>
<td id="S4.T6.1.1.1.6" class="ltx_td"></td>
<td id="S4.T6.1.1.1.7" class="ltx_td ltx_align_center ltx_border_t">65.97</td>
<td id="S4.T6.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">564 MB (<math id="S4.T6.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T6.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T6.1.1.1.1.m1.1.1" xref="S4.T6.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T6.1.1.1.1.m1.1b"><ci id="S4.T6.1.1.1.1.m1.1.1.cmml" xref="S4.T6.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math> 60.9%)</td>
</tr>
<tr id="S4.T6.2.2.2" class="ltx_tr">
<td id="S4.T6.2.2.2.2" class="ltx_td ltx_align_center">WISDM-P</td>
<td id="S4.T6.2.2.2.3" class="ltx_td ltx_align_center">Accuracy (%)</td>
<td id="S4.T6.2.2.2.4" class="ltx_td ltx_align_center">32.26</td>
<td id="S4.T6.2.2.2.5" class="ltx_td ltx_align_center">1444 MB</td>
<td id="S4.T6.2.2.2.6" class="ltx_td"></td>
<td id="S4.T6.2.2.2.7" class="ltx_td ltx_align_center">31.91</td>
<td id="S4.T6.2.2.2.1" class="ltx_td ltx_nopad_r ltx_align_center">564 MB (<math id="S4.T6.2.2.2.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T6.2.2.2.1.m1.1a"><mo stretchy="false" id="S4.T6.2.2.2.1.m1.1.1" xref="S4.T6.2.2.2.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T6.2.2.2.1.m1.1b"><ci id="S4.T6.2.2.2.1.m1.1.1.cmml" xref="S4.T6.2.2.2.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.2.2.2.1.m1.1c">\downarrow</annotation></semantics></math> 60.9%)</td>
</tr>
<tr id="S4.T6.3.3.3" class="ltx_tr">
<td id="S4.T6.3.3.3.2" class="ltx_td ltx_align_center">UT-HAR</td>
<td id="S4.T6.3.3.3.3" class="ltx_td ltx_align_center">Accuracy (%)</td>
<td id="S4.T6.3.3.3.4" class="ltx_td ltx_align_center">76.04</td>
<td id="S4.T6.3.3.3.5" class="ltx_td ltx_align_center">1716 MB</td>
<td id="S4.T6.3.3.3.6" class="ltx_td"></td>
<td id="S4.T6.3.3.3.7" class="ltx_td ltx_align_center">72.06</td>
<td id="S4.T6.3.3.3.1" class="ltx_td ltx_nopad_r ltx_align_center">639 MB (<math id="S4.T6.3.3.3.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T6.3.3.3.1.m1.1a"><mo stretchy="false" id="S4.T6.3.3.3.1.m1.1.1" xref="S4.T6.3.3.3.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T6.3.3.3.1.m1.1b"><ci id="S4.T6.3.3.3.1.m1.1.1.cmml" xref="S4.T6.3.3.3.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.3.3.3.1.m1.1c">\downarrow</annotation></semantics></math> 62.8%)</td>
</tr>
<tr id="S4.T6.4.4.4" class="ltx_tr">
<td id="S4.T6.4.4.4.2" class="ltx_td ltx_align_center">Widar</td>
<td id="S4.T6.4.4.4.3" class="ltx_td ltx_align_center">Accuracy (%)</td>
<td id="S4.T6.4.4.4.4" class="ltx_td ltx_align_center">54.95</td>
<td id="S4.T6.4.4.4.5" class="ltx_td ltx_align_center">1734 MB</td>
<td id="S4.T6.4.4.4.6" class="ltx_td"></td>
<td id="S4.T6.4.4.4.7" class="ltx_td ltx_align_center">39.55</td>
<td id="S4.T6.4.4.4.1" class="ltx_td ltx_nopad_r ltx_align_center">636 MB (<math id="S4.T6.4.4.4.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T6.4.4.4.1.m1.1a"><mo stretchy="false" id="S4.T6.4.4.4.1.m1.1.1" xref="S4.T6.4.4.4.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T6.4.4.4.1.m1.1b"><ci id="S4.T6.4.4.4.1.m1.1.1.cmml" xref="S4.T6.4.4.4.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.4.4.4.1.m1.1c">\downarrow</annotation></semantics></math> 63.3%)</td>
</tr>
<tr id="S4.T6.5.5.5" class="ltx_tr">
<td id="S4.T6.5.5.5.2" class="ltx_td ltx_align_center">VisDrone</td>
<td id="S4.T6.5.5.5.3" class="ltx_td ltx_align_center">MAP-50 (%)</td>
<td id="S4.T6.5.5.5.4" class="ltx_td ltx_align_center">32.09</td>
<td id="S4.T6.5.5.5.5" class="ltx_td ltx_align_center">8369 MB</td>
<td id="S4.T6.5.5.5.6" class="ltx_td"></td>
<td id="S4.T6.5.5.5.7" class="ltx_td ltx_align_center">24.07</td>
<td id="S4.T6.5.5.5.1" class="ltx_td ltx_nopad_r ltx_align_center">3515 MB (<math id="S4.T6.5.5.5.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T6.5.5.5.1.m1.1a"><mo stretchy="false" id="S4.T6.5.5.5.1.m1.1.1" xref="S4.T6.5.5.5.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T6.5.5.5.1.m1.1b"><ci id="S4.T6.5.5.5.1.m1.1.1.cmml" xref="S4.T6.5.5.5.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.5.5.5.1.m1.1c">\downarrow</annotation></semantics></math> 60.0%)</td>
</tr>
<tr id="S4.T6.6.6.6" class="ltx_tr">
<td id="S4.T6.6.6.6.2" class="ltx_td ltx_align_center">CASAS</td>
<td id="S4.T6.6.6.6.3" class="ltx_td ltx_align_center">Accuracy (%)</td>
<td id="S4.T6.6.6.6.4" class="ltx_td ltx_align_center">70.72</td>
<td id="S4.T6.6.6.6.5" class="ltx_td ltx_align_center">1834 MB</td>
<td id="S4.T6.6.6.6.6" class="ltx_td"></td>
<td id="S4.T6.6.6.6.7" class="ltx_td ltx_align_center">77.99</td>
<td id="S4.T6.6.6.6.1" class="ltx_td ltx_nopad_r ltx_align_center">732 MB (<math id="S4.T6.6.6.6.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T6.6.6.6.1.m1.1a"><mo stretchy="false" id="S4.T6.6.6.6.1.m1.1.1" xref="S4.T6.6.6.6.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T6.6.6.6.1.m1.1b"><ci id="S4.T6.6.6.6.1.m1.1.1.cmml" xref="S4.T6.6.6.6.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.6.6.6.1.m1.1c">\downarrow</annotation></semantics></math> 60.1%)</td>
</tr>
<tr id="S4.T6.8.8.8" class="ltx_tr">
<td id="S4.T6.8.8.8.3" class="ltx_td ltx_align_center">AEP</td>
<td id="S4.T6.7.7.7.1" class="ltx_td ltx_align_center"><math id="S4.T6.7.7.7.1.m1.1" class="ltx_Math" alttext="R^{2}" display="inline"><semantics id="S4.T6.7.7.7.1.m1.1a"><msup id="S4.T6.7.7.7.1.m1.1.1" xref="S4.T6.7.7.7.1.m1.1.1.cmml"><mi id="S4.T6.7.7.7.1.m1.1.1.2" xref="S4.T6.7.7.7.1.m1.1.1.2.cmml">R</mi><mn id="S4.T6.7.7.7.1.m1.1.1.3" xref="S4.T6.7.7.7.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S4.T6.7.7.7.1.m1.1b"><apply id="S4.T6.7.7.7.1.m1.1.1.cmml" xref="S4.T6.7.7.7.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T6.7.7.7.1.m1.1.1.1.cmml" xref="S4.T6.7.7.7.1.m1.1.1">superscript</csymbol><ci id="S4.T6.7.7.7.1.m1.1.1.2.cmml" xref="S4.T6.7.7.7.1.m1.1.1.2">𝑅</ci><cn type="integer" id="S4.T6.7.7.7.1.m1.1.1.3.cmml" xref="S4.T6.7.7.7.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.7.7.7.1.m1.1c">R^{2}</annotation></semantics></math></td>
<td id="S4.T6.8.8.8.4" class="ltx_td ltx_align_center">0.41</td>
<td id="S4.T6.8.8.8.5" class="ltx_td ltx_align_center">1201 MB</td>
<td id="S4.T6.8.8.8.6" class="ltx_td"></td>
<td id="S4.T6.8.8.8.7" class="ltx_td ltx_align_center">0.279</td>
<td id="S4.T6.8.8.8.2" class="ltx_td ltx_nopad_r ltx_align_center">500 MB (<math id="S4.T6.8.8.8.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T6.8.8.8.2.m1.1a"><mo stretchy="false" id="S4.T6.8.8.8.2.m1.1.1" xref="S4.T6.8.8.8.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T6.8.8.8.2.m1.1b"><ci id="S4.T6.8.8.8.2.m1.1.1.cmml" xref="S4.T6.8.8.8.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.8.8.8.2.m1.1c">\downarrow</annotation></semantics></math> 58.4%)</td>
</tr>
<tr id="S4.T6.9.9.9" class="ltx_tr">
<td id="S4.T6.9.9.9.2" class="ltx_td ltx_align_center ltx_border_bb">EPIC-SOUNDS</td>
<td id="S4.T6.9.9.9.3" class="ltx_td ltx_align_center ltx_border_bb">Accuracy (%)</td>
<td id="S4.T6.9.9.9.4" class="ltx_td ltx_align_center ltx_border_bb">26.71</td>
<td id="S4.T6.9.9.9.5" class="ltx_td ltx_align_center ltx_border_bb">2176 MB</td>
<td id="S4.T6.9.9.9.6" class="ltx_td ltx_border_bb"></td>
<td id="S4.T6.9.9.9.7" class="ltx_td ltx_align_center ltx_border_bb">27.88</td>
<td id="S4.T6.9.9.9.1" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb">936 MB (<math id="S4.T6.9.9.9.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T6.9.9.9.1.m1.1a"><mo stretchy="false" id="S4.T6.9.9.9.1.m1.1.1" xref="S4.T6.9.9.9.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T6.9.9.9.1.m1.1b"><ci id="S4.T6.9.9.9.1.m1.1.1.cmml" xref="S4.T6.9.9.9.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.9.9.9.1.m1.1c">\downarrow</annotation></semantics></math> 57.0%)</td>
</tr>
</table>
</span></div>
</figure>
<div id="S4.SS4.p2" class="ltx_para ltx_noindent">
<p id="S4.SS4.p2.2" class="ltx_p"><span id="S4.SS4.p2.2.1" class="ltx_text ltx_font_bold">Benchmark Results:</span>
Table <a href="#S4.T6" title="Table 6 ‣ 4.4 Performance on Quantized Training ‣ 4.3 Impact of Erroneous Labels ‣ 4 Experiments and Analysis ‣ FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> summarizes the model performance and memory usage at two precision levels. We make three observations:
(1) As expected, the memory usage significantly decreases when using FP16 precision, ranging from <math id="S4.SS4.p2.1.m1.1" class="ltx_Math" alttext="57.0" display="inline"><semantics id="S4.SS4.p2.1.m1.1a"><mn id="S4.SS4.p2.1.m1.1.1" xref="S4.SS4.p2.1.m1.1.1.cmml">57.0</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.1.m1.1b"><cn type="float" id="S4.SS4.p2.1.m1.1.1.cmml" xref="S4.SS4.p2.1.m1.1.1">57.0</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.1.m1.1c">57.0</annotation></semantics></math>% to <math id="S4.SS4.p2.2.m2.1" class="ltx_Math" alttext="63.3" display="inline"><semantics id="S4.SS4.p2.2.m2.1a"><mn id="S4.SS4.p2.2.m2.1.1" xref="S4.SS4.p2.2.m2.1.1.cmml">63.3</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.2.m2.1b"><cn type="float" id="S4.SS4.p2.2.m2.1.1.cmml" xref="S4.SS4.p2.2.m2.1.1">63.3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.2.m2.1c">63.3</annotation></semantics></math>% reduction across different datasets.
(2) As shown in the previous work <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Micikevicius2017MixedPT</span>]</cite>, the model performance associated with the precision levels varies depending on the dataset. For WISDM-W, CASAS, and EPIC-SOUNDS, the FP16 models maintain or even improve the performance compared to the FP32 models.
(3) Widar, VisDrone, and AEP have a significant decline in performance when quantized to FP16 precision.</p>
</div>
<figure id="S4.T7" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T7.2.1.1" class="ltx_text" style="font-size:90%;">Table 7</span>: </span><span id="S4.T7.3.2" class="ltx_text" style="font-size:90%;">Analysis of quantization demands.</span></figcaption>
<div id="S4.T7.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:111.1pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-101.4pt,25.8pt) scale(0.681285496605514,0.681285496605514) ;">
<table id="S4.T7.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T7.4.1.1" class="ltx_tr">
<td id="S4.T7.4.1.1.1" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T7.4.1.1.1.1" class="ltx_text ltx_font_bold">Application</span></td>
<td id="S4.T7.4.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T7.4.1.1.2.1" class="ltx_text ltx_font_bold">Dataset</span></td>
<td id="S4.T7.4.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T7.4.1.1.3.1" class="ltx_text ltx_font_bold">IoT Platform</span></td>
<td id="S4.T7.4.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T7.4.1.1.4.1" class="ltx_text ltx_font_bold">Representative Devices</span></td>
<td id="S4.T7.4.1.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T7.4.1.1.5.1" class="ltx_text ltx_font_bold">Hardware RAM Size</span></td>
<td id="S4.T7.4.1.1.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T7.4.1.1.6.1" class="ltx_text ltx_font_bold">Need Quantization</span></td>
</tr>
<tr id="S4.T7.4.1.2" class="ltx_tr">
<td id="S4.T7.4.1.2.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S4.T7.4.1.2.1.1" class="ltx_text">Activity Recognition</span></td>
<td id="S4.T7.4.1.2.2" class="ltx_td ltx_align_center ltx_border_t">WISDM-W</td>
<td id="S4.T7.4.1.2.3" class="ltx_td ltx_align_center ltx_border_t">Smartwatch</td>
<td id="S4.T7.4.1.2.4" class="ltx_td ltx_align_center ltx_border_t">Apple Watch 8</td>
<td id="S4.T7.4.1.2.5" class="ltx_td ltx_align_center ltx_border_t">512 MB to 1 GB</td>
<td id="S4.T7.4.1.2.6" class="ltx_td ltx_align_center ltx_border_t">Yes</td>
</tr>
<tr id="S4.T7.4.1.3" class="ltx_tr">
<td id="S4.T7.4.1.3.1" class="ltx_td ltx_align_center">WISDM-P</td>
<td id="S4.T7.4.1.3.2" class="ltx_td ltx_align_center">Smartphone</td>
<td id="S4.T7.4.1.3.3" class="ltx_td ltx_align_center">iPhone 14</td>
<td id="S4.T7.4.1.3.4" class="ltx_td ltx_align_center">6 GB</td>
<td id="S4.T7.4.1.3.5" class="ltx_td ltx_align_center">No</td>
</tr>
<tr id="S4.T7.4.1.4" class="ltx_tr">
<td id="S4.T7.4.1.4.1" class="ltx_td ltx_align_center">UT-HAR</td>
<td id="S4.T7.4.1.4.2" class="ltx_td ltx_align_center">Wi-Fi Router</td>
<td id="S4.T7.4.1.4.3" class="ltx_td ltx_align_center">TP-Link AX1800</td>
<td id="S4.T7.4.1.4.4" class="ltx_td ltx_align_center">64 MB to 1 GB</td>
<td id="S4.T7.4.1.4.5" class="ltx_td ltx_align_center">Yes</td>
</tr>
<tr id="S4.T7.4.1.5" class="ltx_tr">
<td id="S4.T7.4.1.5.1" class="ltx_td ltx_align_center ltx_border_t">Gesture Recognition</td>
<td id="S4.T7.4.1.5.2" class="ltx_td ltx_align_center ltx_border_t">Widar</td>
<td id="S4.T7.4.1.5.3" class="ltx_td ltx_align_center ltx_border_t">Wi-Fi Router</td>
<td id="S4.T7.4.1.5.4" class="ltx_td ltx_align_center ltx_border_t">TP-Link AX1800</td>
<td id="S4.T7.4.1.5.5" class="ltx_td ltx_align_center ltx_border_t">64 MB to 1 GB</td>
<td id="S4.T7.4.1.5.6" class="ltx_td ltx_align_center ltx_border_t">Yes</td>
</tr>
<tr id="S4.T7.4.1.6" class="ltx_tr">
<td id="S4.T7.4.1.6.1" class="ltx_td ltx_align_center ltx_border_t">Independent Living</td>
<td id="S4.T7.4.1.6.2" class="ltx_td ltx_align_center ltx_border_t">CASAS</td>
<td id="S4.T7.4.1.6.3" class="ltx_td ltx_align_center ltx_border_t">Smart Home</td>
<td id="S4.T7.4.1.6.4" class="ltx_td ltx_align_center ltx_border_t">Raspberry Pi 4</td>
<td id="S4.T7.4.1.6.5" class="ltx_td ltx_align_center ltx_border_t">1 GB to 8 GB</td>
<td id="S4.T7.4.1.6.6" class="ltx_td ltx_align_center ltx_border_t">No</td>
</tr>
<tr id="S4.T7.4.1.7" class="ltx_tr">
<td id="S4.T7.4.1.7.1" class="ltx_td ltx_align_center ltx_border_t">Energy Prediction</td>
<td id="S4.T7.4.1.7.2" class="ltx_td ltx_align_center ltx_border_t">AEP</td>
<td id="S4.T7.4.1.7.3" class="ltx_td ltx_align_center ltx_border_t">Smart Home</td>
<td id="S4.T7.4.1.7.4" class="ltx_td ltx_align_center ltx_border_t">Raspberry Pi 4</td>
<td id="S4.T7.4.1.7.5" class="ltx_td ltx_align_center ltx_border_t">1 GB to 8 GB</td>
<td id="S4.T7.4.1.7.6" class="ltx_td ltx_align_center ltx_border_t">No</td>
</tr>
<tr id="S4.T7.4.1.8" class="ltx_tr">
<td id="S4.T7.4.1.8.1" class="ltx_td ltx_align_center ltx_border_t">Objective Detection</td>
<td id="S4.T7.4.1.8.2" class="ltx_td ltx_align_center ltx_border_t">VisDrone</td>
<td id="S4.T7.4.1.8.3" class="ltx_td ltx_align_center ltx_border_t">Drone</td>
<td id="S4.T7.4.1.8.4" class="ltx_td ltx_align_center ltx_border_t">Dji Mavic 3 + Raspberry Pi 4</td>
<td id="S4.T7.4.1.8.5" class="ltx_td ltx_align_center ltx_border_t">1 GB to 8 GB</td>
<td id="S4.T7.4.1.8.6" class="ltx_td ltx_align_center ltx_border_t">Yes</td>
</tr>
<tr id="S4.T7.4.1.9" class="ltx_tr">
<td id="S4.T7.4.1.9.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">Augmented Reality</td>
<td id="S4.T7.4.1.9.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">EPIC-SOUNDS</td>
<td id="S4.T7.4.1.9.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">Head-mounted Device</td>
<td id="S4.T7.4.1.9.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">GoPro / AR Headset</td>
<td id="S4.T7.4.1.9.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">1 GB to 8 GB</td>
<td id="S4.T7.4.1.9.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">No</td>
</tr>
</table>
</span></div>
</figure>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Insights from Benchmark Results</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p"><span id="S4.SS5.p1.1.1" class="ltx_text ltx_font_bold">Need for Resilience on High Data Heterogeneity:</span>
As presented in Table <a href="#S4.T3" title="Table 3 ‣ 4.1 Overall Performance ‣ 4 Experiments and Analysis ‣ FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, datasets can exhibit a notable response to changes in data heterogeneity. We observe that CASAS, AEP, and EPIC-SOUNDS show a significant impact even at a low data heterogeneity. UT-HAR and Widar see a drastic decline in high data heterogeneity.
These findings emphasize the need for developing advanced FL algorithms for data modalities that are sensitive to high data heterogeneity.</p>
</div>
<div id="S4.SS5.p2" class="ltx_para">
<p id="S4.SS5.p2.1" class="ltx_p"><span id="S4.SS5.p2.1.1" class="ltx_text ltx_font_bold">Need for Balancing between Client Sampling Ratio and Resource Consumption of IoT Devices:</span>
Table <a href="#S4.T4" title="Table 4 ‣ 4.2 Impact of Client Sampling Ratio ‣ 4 Experiments and Analysis ‣ FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> reveals that a higher sampling ratio can lead to improved performance in the long run. However, higher client sampling ratios generally entail increased communication bandwidth and energy consumption, which may not be desirable for IoT devices. Therefore, it is crucial to identify the sweet spot that strikes a balance between the client sampling ratio and resource consumption.</p>
</div>
<div id="S4.SS5.p3" class="ltx_para">
<p id="S4.SS5.p3.1" class="ltx_p"><span id="S4.SS5.p3.1.1" class="ltx_text ltx_font_bold">Need for Resilience on Erroneous Labels:</span>
As demonstrated in Table <a href="#S4.SS3" title="4.3 Impact of Erroneous Labels ‣ 4 Experiments and Analysis ‣ FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>, certain datasets exhibit high sensitivity to label errors, resulting in a significant drop in FL performance. Notably, both UT-HAR and EPIC-SOUNDS experience a drastic decrease in accuracy when faced with a 10% erroneous label ratio. Given the inevitability of label errors in real FL deployments, where private data remains unmonitored and uncalibrated except by the respective data owners, the development of label error resilient techniques becomes crucial for achieving reliable FL performance.</p>
</div>
<div id="S4.SS5.p4" class="ltx_para">
<p id="S4.SS5.p4.1" class="ltx_p"><span id="S4.SS5.p4.1.1" class="ltx_text ltx_font_bold">Need for Quantization:</span> Table <a href="#S4.T7" title="Table 7 ‣ 4.4 Performance on Quantized Training ‣ 4.3 Impact of Erroneous Labels ‣ 4 Experiments and Analysis ‣ FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> highlights the importance of quantization in FL for all eight datasets.
Notably, certain IoT devices, such as drones, lack sufficient RAM storage capacity for FL. Hence, external hardware interfaces like Raspberry Pi 4 has to be incorporated as assistive computing platforms. Analysis from Table <a href="#S4.T6" title="Table 6 ‣ 4.4 Performance on Quantized Training ‣ 4.3 Impact of Erroneous Labels ‣ 4 Experiments and Analysis ‣ FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> reveals that the performance of VisDrone drops significantly from 32FP precision to 16FP precision, and WISDM-W, UT-HAR, and VisDrone require computing memory size that exceeds the representative hardware RAM limits when using 32FP precision, underscoring the necessity of quantized training.</p>
</div>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper, we presented <span id="S5.p1.1.1" class="ltx_text ltx_font_typewriter">FedAIoT</span>, a FL benchmark for AIoT. <span id="S5.p1.1.2" class="ltx_text ltx_font_typewriter">FedAIoT</span> includes eight datasets collected from a wide range of authentic IoT devices as well as a unified end-to-end FL framework for AIoT that covers the complete FL-for-AIoT pipeline.
We have benchmarked the performance of the datasets and provided insights on the opportunities and challenges of FL for AIoT.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p"><span id="S5.p2.1.1" class="ltx_text ltx_font_bold">Limitations and Future works.</span>
While the benchmark presented is instrumental in elucidating the role of different factors on model accuracy, the scope of AIoT extends further. A holistic understanding of AIoT also necessitates an examination of its infrastructural facets. These encompass the computational prowess and energy utilization of IoT platforms, along with the efficiency and security of their communication protocols, which are equally vital dimensions in the AIoT landscape.
Moving forward, our plan is to establish an open-source repository that hosts and maintains this benchmark. This endeavor will be guided by the invaluable insights we receive from the broader community and users of the benchmark framework. As a part of our ongoing commitment, we intend to continually expand the benchmark’s scope by incorporating additional datasets from a more diverse set of applications, integrating new algorithms, and conducting deeper analytical validations.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Checklist</h2>

<div id="Sx1.p1" class="ltx_para">
<ol id="Sx1.I1" class="ltx_enumerate">
<li id="Sx1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="Sx1.I1.i1.p1" class="ltx_para">
<p id="Sx1.I1.i1.p1.1" class="ltx_p">For all authors…</p>
<ol id="Sx1.I1.i1.I1" class="ltx_enumerate">
<li id="Sx1.I1.i1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(a)</span> 
<div id="Sx1.I1.i1.I1.i1.p1" class="ltx_para">
<p id="Sx1.I1.i1.I1.i1.p1.1" class="ltx_p">Do the main claims made in the abstract and introduction accurately reflect the paper’s contributions and scope?
<span id="Sx1.I1.i1.I1.i1.p1.1.1" class="ltx_ERROR undefined">\answerYes</span></p>
</div>
</li>
<li id="Sx1.I1.i1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(b)</span> 
<div id="Sx1.I1.i1.I1.i2.p1" class="ltx_para">
<p id="Sx1.I1.i1.I1.i2.p1.1" class="ltx_p">Did you describe the limitations of your work?
<span id="Sx1.I1.i1.I1.i2.p1.1.1" class="ltx_ERROR undefined">\answerYes</span></p>
</div>
</li>
<li id="Sx1.I1.i1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(c)</span> 
<div id="Sx1.I1.i1.I1.i3.p1" class="ltx_para">
<p id="Sx1.I1.i1.I1.i3.p1.1" class="ltx_p">Did you discuss any potential negative societal impacts of your work?
<span id="Sx1.I1.i1.I1.i3.p1.1.1" class="ltx_ERROR undefined">\answerNA</span></p>
</div>
</li>
<li id="Sx1.I1.i1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(d)</span> 
<div id="Sx1.I1.i1.I1.i4.p1" class="ltx_para">
<p id="Sx1.I1.i1.I1.i4.p1.1" class="ltx_p">Have you read the ethics review guidelines and ensured that your paper conforms to them?
<span id="Sx1.I1.i1.I1.i4.p1.1.1" class="ltx_ERROR undefined">\answerYes</span></p>
</div>
</li>
</ol>
</div>
</li>
<li id="Sx1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="Sx1.I1.i2.p1" class="ltx_para">
<p id="Sx1.I1.i2.p1.1" class="ltx_p">If you are including theoretical results…</p>
<ol id="Sx1.I1.i2.I1" class="ltx_enumerate">
<li id="Sx1.I1.i2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(a)</span> 
<div id="Sx1.I1.i2.I1.i1.p1" class="ltx_para">
<p id="Sx1.I1.i2.I1.i1.p1.1" class="ltx_p">Did you state the full set of assumptions of all theoretical results?
<span id="Sx1.I1.i2.I1.i1.p1.1.1" class="ltx_ERROR undefined">\answerNA</span></p>
</div>
</li>
<li id="Sx1.I1.i2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(b)</span> 
<div id="Sx1.I1.i2.I1.i2.p1" class="ltx_para">
<p id="Sx1.I1.i2.I1.i2.p1.1" class="ltx_p">Did you include complete proofs of all theoretical results?
<span id="Sx1.I1.i2.I1.i2.p1.1.1" class="ltx_ERROR undefined">\answerNA</span></p>
</div>
</li>
</ol>
</div>
</li>
<li id="Sx1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="Sx1.I1.i3.p1" class="ltx_para">
<p id="Sx1.I1.i3.p1.1" class="ltx_p">If you ran experiments (e.g. for benchmarks)…</p>
<ol id="Sx1.I1.i3.I1" class="ltx_enumerate">
<li id="Sx1.I1.i3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(a)</span> 
<div id="Sx1.I1.i3.I1.i1.p1" class="ltx_para">
<p id="Sx1.I1.i3.I1.i1.p1.1" class="ltx_p">Did you include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL)?
<span id="Sx1.I1.i3.I1.i1.p1.1.1" class="ltx_ERROR undefined">\answerYes</span></p>
</div>
</li>
<li id="Sx1.I1.i3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(b)</span> 
<div id="Sx1.I1.i3.I1.i2.p1" class="ltx_para">
<p id="Sx1.I1.i3.I1.i2.p1.1" class="ltx_p">Did you specify all the training details (e.g., data splits, hyperparameters, how they were chosen)?
<span id="Sx1.I1.i3.I1.i2.p1.1.1" class="ltx_ERROR undefined">\answerYes</span></p>
</div>
</li>
<li id="Sx1.I1.i3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(c)</span> 
<div id="Sx1.I1.i3.I1.i3.p1" class="ltx_para">
<p id="Sx1.I1.i3.I1.i3.p1.1" class="ltx_p">Did you report error bars (e.g., with respect to the random seed after running experiments multiple times)?
<span id="Sx1.I1.i3.I1.i3.p1.1.1" class="ltx_ERROR undefined">\answerNA</span></p>
</div>
</li>
<li id="Sx1.I1.i3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(d)</span> 
<div id="Sx1.I1.i3.I1.i4.p1" class="ltx_para">
<p id="Sx1.I1.i3.I1.i4.p1.1" class="ltx_p">Did you include the total amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)?
<span id="Sx1.I1.i3.I1.i4.p1.1.1" class="ltx_ERROR undefined">\answerYes</span></p>
</div>
</li>
</ol>
</div>
</li>
<li id="Sx1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="Sx1.I1.i4.p1" class="ltx_para">
<p id="Sx1.I1.i4.p1.1" class="ltx_p">If you are using existing assets (e.g., code, data, models) or curating/releasing new assets…</p>
<ol id="Sx1.I1.i4.I1" class="ltx_enumerate">
<li id="Sx1.I1.i4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(a)</span> 
<div id="Sx1.I1.i4.I1.i1.p1" class="ltx_para">
<p id="Sx1.I1.i4.I1.i1.p1.1" class="ltx_p">If your work uses existing assets, did you cite the creators?
<span id="Sx1.I1.i4.I1.i1.p1.1.1" class="ltx_ERROR undefined">\answerYes</span></p>
</div>
</li>
<li id="Sx1.I1.i4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(b)</span> 
<div id="Sx1.I1.i4.I1.i2.p1" class="ltx_para">
<p id="Sx1.I1.i4.I1.i2.p1.1" class="ltx_p">Did you mention the license of the assets?
<span id="Sx1.I1.i4.I1.i2.p1.1.1" class="ltx_ERROR undefined">\answerYes</span>Mentioned when available</p>
</div>
</li>
<li id="Sx1.I1.i4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(c)</span> 
<div id="Sx1.I1.i4.I1.i3.p1" class="ltx_para">
<p id="Sx1.I1.i4.I1.i3.p1.1" class="ltx_p">Did you include any new assets either in the supplemental material or as a URL?
<span id="Sx1.I1.i4.I1.i3.p1.1.1" class="ltx_ERROR undefined">\answerYes</span></p>
</div>
</li>
<li id="Sx1.I1.i4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(d)</span> 
<div id="Sx1.I1.i4.I1.i4.p1" class="ltx_para">
<p id="Sx1.I1.i4.I1.i4.p1.1" class="ltx_p">Did you discuss whether and how consent was obtained from people whose data you’re using/curating?
<span id="Sx1.I1.i4.I1.i4.p1.1.1" class="ltx_ERROR undefined">\answerNA</span></p>
</div>
</li>
<li id="Sx1.I1.i4.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(e)</span> 
<div id="Sx1.I1.i4.I1.i5.p1" class="ltx_para">
<p id="Sx1.I1.i4.I1.i5.p1.1" class="ltx_p">Did you discuss whether the data you are using/curating contains personally identifiable information or offensive content?
<span id="Sx1.I1.i4.I1.i5.p1.1.1" class="ltx_ERROR undefined">\answerNA</span></p>
</div>
</li>
</ol>
</div>
</li>
<li id="Sx1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="Sx1.I1.i5.p1" class="ltx_para">
<p id="Sx1.I1.i5.p1.1" class="ltx_p">If you used crowdsourcing or conducted research with human subjects…</p>
<ol id="Sx1.I1.i5.I1" class="ltx_enumerate">
<li id="Sx1.I1.i5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(a)</span> 
<div id="Sx1.I1.i5.I1.i1.p1" class="ltx_para">
<p id="Sx1.I1.i5.I1.i1.p1.1" class="ltx_p">Did you include the full text of instructions given to participants and screenshots, if applicable?
<span id="Sx1.I1.i5.I1.i1.p1.1.1" class="ltx_ERROR undefined">\answerNA</span></p>
</div>
</li>
<li id="Sx1.I1.i5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(b)</span> 
<div id="Sx1.I1.i5.I1.i2.p1" class="ltx_para">
<p id="Sx1.I1.i5.I1.i2.p1.1" class="ltx_p">Did you describe any potential participant risks, with links to Institutional Review Board (IRB) approvals, if applicable?
<span id="Sx1.I1.i5.I1.i2.p1.1.1" class="ltx_ERROR undefined">\answerNA</span></p>
</div>
</li>
<li id="Sx1.I1.i5.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(c)</span> 
<div id="Sx1.I1.i5.I1.i3.p1" class="ltx_para">
<p id="Sx1.I1.i5.I1.i3.p1.1" class="ltx_p">Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation?
<span id="Sx1.I1.i5.I1.i3.p1.1.1" class="ltx_ERROR undefined">\answerNA</span></p>
</div>
</li>
</ol>
</div>
</li>
</ol>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2>

<section id="A1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Supplementary Dataset Details</h3>

<section id="A1.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.1.1 </span>WISDM</h4>

<div id="A1.SS1.SSS1.p1" class="ltx_para">
<p id="A1.SS1.SSS1.p1.1" class="ltx_p">The WISDM dataset comprises raw accelerometer and gyroscope data collected from 51 subjects performing 18 activities for three minutes each. Data were gathered at a 20Hz sampling rate from both a smartphone (Google Nexus 5/5x or
Samsung Galaxy S5) and a smartwatch (LG G Watch). Data for each device and sensor type are stored in different directories, resulting in four directories overall. Each directory contains 51 files, each corresponding to a subject. The data entry format is: &lt;subject-id, activity-code, timestamp, x, y, z&gt;. Separate files for the gyroscope and accelerometer readings are provided and are later combined by matching timestamps.
Subject ID is given from 1600 to 1650 and the activity code is an alphabetical character between ‘A’ and ‘S’ excluding ‘N’. The timestamp is in Unix time. The code to read and partition the data into 10s segments is provided by our benchmark. The input shape of the processed data is <math id="A1.SS1.SSS1.p1.1.m1.1" class="ltx_Math" alttext="200\times 6" display="inline"><semantics id="A1.SS1.SSS1.p1.1.m1.1a"><mrow id="A1.SS1.SSS1.p1.1.m1.1.1" xref="A1.SS1.SSS1.p1.1.m1.1.1.cmml"><mn id="A1.SS1.SSS1.p1.1.m1.1.1.2" xref="A1.SS1.SSS1.p1.1.m1.1.1.2.cmml">200</mn><mo lspace="0.222em" rspace="0.222em" id="A1.SS1.SSS1.p1.1.m1.1.1.1" xref="A1.SS1.SSS1.p1.1.m1.1.1.1.cmml">×</mo><mn id="A1.SS1.SSS1.p1.1.m1.1.1.3" xref="A1.SS1.SSS1.p1.1.m1.1.1.3.cmml">6</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS1.p1.1.m1.1b"><apply id="A1.SS1.SSS1.p1.1.m1.1.1.cmml" xref="A1.SS1.SSS1.p1.1.m1.1.1"><times id="A1.SS1.SSS1.p1.1.m1.1.1.1.cmml" xref="A1.SS1.SSS1.p1.1.m1.1.1.1"></times><cn type="integer" id="A1.SS1.SSS1.p1.1.m1.1.1.2.cmml" xref="A1.SS1.SSS1.p1.1.m1.1.1.2">200</cn><cn type="integer" id="A1.SS1.SSS1.p1.1.m1.1.1.3.cmml" xref="A1.SS1.SSS1.p1.1.m1.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS1.p1.1.m1.1c">200\times 6</annotation></semantics></math>. The original dataset is available at <a target="_blank" href="https://archive.ics.uci.edu/dataset/507/wisdm+smartphone+and+smartwatch+activity+and+biometrics+dataset" title="" class="ltx_ref ltx_href">https://archive.ics.uci.edu/dataset/507/wisdm+smartphone+and+smartwatch+activity+and+biometrics+dataset</a>.</p>
</div>
</section>
<section id="A1.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.1.2 </span>UT-HAR</h4>

<div id="A1.SS1.SSS2.p1" class="ltx_para">
<p id="A1.SS1.SSS2.p1.2" class="ltx_p">The UT-HAR dataset was collected using the Linux 802.11n Channel State Information (CSI) Tool for the task of Human Activity Recognition (HAR). The original data consist of two file types: “input" and “annotation".
“input" files contain Wi-Fi CSI data. The first column indicates the timestamp in Unix. Columns 2-91 represent amplitude data for 30 subcarriers across three antennas, and columns 92-181 contain the corresponding phase information. “annotation" files provide the corresponding activity labels, serving as the ground truth for HAR. In our benchmark, only amplitude is used. The final samples are created by taking a sliding window of size <math id="A1.SS1.SSS2.p1.1.m1.1" class="ltx_Math" alttext="250" display="inline"><semantics id="A1.SS1.SSS2.p1.1.m1.1a"><mn id="A1.SS1.SSS2.p1.1.m1.1.1" xref="A1.SS1.SSS2.p1.1.m1.1.1.cmml">250</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS2.p1.1.m1.1b"><cn type="integer" id="A1.SS1.SSS2.p1.1.m1.1.1.cmml" xref="A1.SS1.SSS2.p1.1.m1.1.1">250</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS2.p1.1.m1.1c">250</annotation></semantics></math> where each sample consists of amplitude information across three antennas and from 30 subcarriers and has shape <math id="A1.SS1.SSS2.p1.2.m2.1" class="ltx_Math" alttext="3\times 30\times 250" display="inline"><semantics id="A1.SS1.SSS2.p1.2.m2.1a"><mrow id="A1.SS1.SSS2.p1.2.m2.1.1" xref="A1.SS1.SSS2.p1.2.m2.1.1.cmml"><mn id="A1.SS1.SSS2.p1.2.m2.1.1.2" xref="A1.SS1.SSS2.p1.2.m2.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="A1.SS1.SSS2.p1.2.m2.1.1.1" xref="A1.SS1.SSS2.p1.2.m2.1.1.1.cmml">×</mo><mn id="A1.SS1.SSS2.p1.2.m2.1.1.3" xref="A1.SS1.SSS2.p1.2.m2.1.1.3.cmml">30</mn><mo lspace="0.222em" rspace="0.222em" id="A1.SS1.SSS2.p1.2.m2.1.1.1a" xref="A1.SS1.SSS2.p1.2.m2.1.1.1.cmml">×</mo><mn id="A1.SS1.SSS2.p1.2.m2.1.1.4" xref="A1.SS1.SSS2.p1.2.m2.1.1.4.cmml">250</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS2.p1.2.m2.1b"><apply id="A1.SS1.SSS2.p1.2.m2.1.1.cmml" xref="A1.SS1.SSS2.p1.2.m2.1.1"><times id="A1.SS1.SSS2.p1.2.m2.1.1.1.cmml" xref="A1.SS1.SSS2.p1.2.m2.1.1.1"></times><cn type="integer" id="A1.SS1.SSS2.p1.2.m2.1.1.2.cmml" xref="A1.SS1.SSS2.p1.2.m2.1.1.2">3</cn><cn type="integer" id="A1.SS1.SSS2.p1.2.m2.1.1.3.cmml" xref="A1.SS1.SSS2.p1.2.m2.1.1.3">30</cn><cn type="integer" id="A1.SS1.SSS2.p1.2.m2.1.1.4.cmml" xref="A1.SS1.SSS2.p1.2.m2.1.1.4">250</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS2.p1.2.m2.1c">3\times 30\times 250</annotation></semantics></math>. The original dataset is available at <a target="_blank" href="https://github.com/ermongroup/Wifi_Activity_Recognition/tree/master" title="" class="ltx_ref ltx_href">https://github.com/ermongroup/Wifi_Activity_Recognition/tree/master</a>.</p>
</div>
</section>
<section id="A1.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.1.3 </span>Widar</h4>

<div id="A1.SS1.SSS3.p1" class="ltx_para">
<p id="A1.SS1.SSS3.p1.6" class="ltx_p">The Widar dataset (Widar3.0) was collected with a system comprising one transmitter and three receivers, all equipped with Intel 5300 wireless NICs. The system uses the Linux CSI Tool to record the Wi-Fi data. Devices operate in monitor mode on channel 165 at 5.825 GHz. The transmitter broadcasts <math id="A1.SS1.SSS3.p1.1.m1.2" class="ltx_Math" alttext="1,000" display="inline"><semantics id="A1.SS1.SSS3.p1.1.m1.2a"><mrow id="A1.SS1.SSS3.p1.1.m1.2.3.2" xref="A1.SS1.SSS3.p1.1.m1.2.3.1.cmml"><mn id="A1.SS1.SSS3.p1.1.m1.1.1" xref="A1.SS1.SSS3.p1.1.m1.1.1.cmml">1</mn><mo id="A1.SS1.SSS3.p1.1.m1.2.3.2.1" xref="A1.SS1.SSS3.p1.1.m1.2.3.1.cmml">,</mo><mn id="A1.SS1.SSS3.p1.1.m1.2.2" xref="A1.SS1.SSS3.p1.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS3.p1.1.m1.2b"><list id="A1.SS1.SSS3.p1.1.m1.2.3.1.cmml" xref="A1.SS1.SSS3.p1.1.m1.2.3.2"><cn type="integer" id="A1.SS1.SSS3.p1.1.m1.1.1.cmml" xref="A1.SS1.SSS3.p1.1.m1.1.1">1</cn><cn type="integer" id="A1.SS1.SSS3.p1.1.m1.2.2.cmml" xref="A1.SS1.SSS3.p1.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS3.p1.1.m1.2c">1,000</annotation></semantics></math> Wi-Fi packets per second while receivers capture data using their three linearly arranged antennas. In our benchmark, we use the processed body velocity profile (BVP) features extracted from the dataset. The size of each data sample after processing is <math id="A1.SS1.SSS3.p1.2.m2.1" class="ltx_Math" alttext="22\times 20\times 20" display="inline"><semantics id="A1.SS1.SSS3.p1.2.m2.1a"><mrow id="A1.SS1.SSS3.p1.2.m2.1.1" xref="A1.SS1.SSS3.p1.2.m2.1.1.cmml"><mn id="A1.SS1.SSS3.p1.2.m2.1.1.2" xref="A1.SS1.SSS3.p1.2.m2.1.1.2.cmml">22</mn><mo lspace="0.222em" rspace="0.222em" id="A1.SS1.SSS3.p1.2.m2.1.1.1" xref="A1.SS1.SSS3.p1.2.m2.1.1.1.cmml">×</mo><mn id="A1.SS1.SSS3.p1.2.m2.1.1.3" xref="A1.SS1.SSS3.p1.2.m2.1.1.3.cmml">20</mn><mo lspace="0.222em" rspace="0.222em" id="A1.SS1.SSS3.p1.2.m2.1.1.1a" xref="A1.SS1.SSS3.p1.2.m2.1.1.1.cmml">×</mo><mn id="A1.SS1.SSS3.p1.2.m2.1.1.4" xref="A1.SS1.SSS3.p1.2.m2.1.1.4.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS3.p1.2.m2.1b"><apply id="A1.SS1.SSS3.p1.2.m2.1.1.cmml" xref="A1.SS1.SSS3.p1.2.m2.1.1"><times id="A1.SS1.SSS3.p1.2.m2.1.1.1.cmml" xref="A1.SS1.SSS3.p1.2.m2.1.1.1"></times><cn type="integer" id="A1.SS1.SSS3.p1.2.m2.1.1.2.cmml" xref="A1.SS1.SSS3.p1.2.m2.1.1.2">22</cn><cn type="integer" id="A1.SS1.SSS3.p1.2.m2.1.1.3.cmml" xref="A1.SS1.SSS3.p1.2.m2.1.1.3">20</cn><cn type="integer" id="A1.SS1.SSS3.p1.2.m2.1.1.4.cmml" xref="A1.SS1.SSS3.p1.2.m2.1.1.4">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS3.p1.2.m2.1c">22\times 20\times 20</annotation></semantics></math> consisting of <math id="A1.SS1.SSS3.p1.3.m3.1" class="ltx_Math" alttext="22" display="inline"><semantics id="A1.SS1.SSS3.p1.3.m3.1a"><mn id="A1.SS1.SSS3.p1.3.m3.1.1" xref="A1.SS1.SSS3.p1.3.m3.1.1.cmml">22</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS3.p1.3.m3.1b"><cn type="integer" id="A1.SS1.SSS3.p1.3.m3.1.1.cmml" xref="A1.SS1.SSS3.p1.3.m3.1.1">22</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS3.p1.3.m3.1c">22</annotation></semantics></math> samples over time each having <math id="A1.SS1.SSS3.p1.4.m4.1" class="ltx_Math" alttext="20" display="inline"><semantics id="A1.SS1.SSS3.p1.4.m4.1a"><mn id="A1.SS1.SSS3.p1.4.m4.1.1" xref="A1.SS1.SSS3.p1.4.m4.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS3.p1.4.m4.1b"><cn type="integer" id="A1.SS1.SSS3.p1.4.m4.1.1.cmml" xref="A1.SS1.SSS3.p1.4.m4.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS3.p1.4.m4.1c">20</annotation></semantics></math> BVP features each in both <math id="A1.SS1.SSS3.p1.5.m5.1" class="ltx_Math" alttext="x" display="inline"><semantics id="A1.SS1.SSS3.p1.5.m5.1a"><mi id="A1.SS1.SSS3.p1.5.m5.1.1" xref="A1.SS1.SSS3.p1.5.m5.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS3.p1.5.m5.1b"><ci id="A1.SS1.SSS3.p1.5.m5.1.1.cmml" xref="A1.SS1.SSS3.p1.5.m5.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS3.p1.5.m5.1c">x</annotation></semantics></math> and <math id="A1.SS1.SSS3.p1.6.m6.1" class="ltx_Math" alttext="y" display="inline"><semantics id="A1.SS1.SSS3.p1.6.m6.1a"><mi id="A1.SS1.SSS3.p1.6.m6.1.1" xref="A1.SS1.SSS3.p1.6.m6.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS3.p1.6.m6.1b"><ci id="A1.SS1.SSS3.p1.6.m6.1.1.cmml" xref="A1.SS1.SSS3.p1.6.m6.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS3.p1.6.m6.1c">y</annotation></semantics></math> directions. The raw dataset is available for download at <a target="_blank" href="http://tns.thss.tsinghua.edu.cn/widar3.0/index.html" title="" class="ltx_ref ltx_href">http://tns.thss.tsinghua.edu.cn/widar3.0/index.html</a>.</p>
</div>
</section>
<section id="A1.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.1.4 </span>VisDrone</h4>

<div id="A1.SS1.SSS4.p1" class="ltx_para">
<p id="A1.SS1.SSS4.p1.1" class="ltx_p">The VisDrone dataset was collected by the AISKYEYE team at Tianjin University, China. It comprises 288 video clips with 261,908 frames and 10,209 static images captured by cameras mounted on drones at 14 different cities in China in diverse environments, scenarios, weather, and lighting conditions. The frames were manually annotated with over 2.6 million bounding boxes of common targets like pedestrians, cars, and bicycles. Additional attributes like scene visibility, object class, and occlusion are also provided for enhanced data utilization.
The dataset is available at <a target="_blank" href="https://github.com/VisDrone/VisDrone-Dataset" title="" class="ltx_ref ltx_href">https://github.com/VisDrone/VisDrone-Dataset</a>.</p>
</div>
</section>
<section id="A1.SS1.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.1.5 </span>CASAS</h4>

<div id="A1.SS1.SSS5.p1" class="ltx_para">
<p id="A1.SS1.SSS5.p1.1" class="ltx_p">The CASAS dataset is a collection of data generated in smart home environments, where intelligent software uses sensors deployed at homes to monitor resident activities and conditions within the space.
The CASAS project considers environments as intelligent agents and employs custom IoT hardware known as Smart Home in a Box (SHiB), which encompasses the necessary sensors, devices, and software. The sensors in SHiB perceive the status of residents and their surroundings, and through controllers, the system acts to enhance living conditions by optimizing comfort, safety, and productivity.
The CASAS dataset includes the date (in yyyy-mm-dd format), time (in hh:mm:ss.ms format), sensor name, sensor readings, and an activity label in string format. The data were collected in real-time as residents go about their daily activities. The code to extract categorical sensor readings to create input sequences and labels is provided in our benchmark. The CASAS dataset can be downloaded from <a target="_blank" href="https://casas.wsu.edu/datasets/" title="" class="ltx_ref ltx_href">https://casas.wsu.edu/datasets/</a>.</p>
</div>
</section>
<section id="A1.SS1.SSS6" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.1.6 </span>AEP</h4>

<div id="A1.SS1.SSS6.p1" class="ltx_para">
<p id="A1.SS1.SSS6.p1.20" class="ltx_p">The AEP dataset, collected over 4.5 months, comprises readings taken every 10 minutes from a ZigBee wireless sensor network monitoring house temperature and humidity. Each wireless node transmitted data around every 3.3 minutes, which were then averaged over 10-minute periods. Additionally, energy data was logged every 10 minutes via m-bus energy meters. The dataset includes attributes such as date and time (in year-month-day hour:minute:second format), the energy usage of appliances and lights (in Wh), temperature and humidity in various rooms including the kitchen (<math id="A1.SS1.SSS6.p1.1.m1.1" class="ltx_Math" alttext="T_{1}" display="inline"><semantics id="A1.SS1.SSS6.p1.1.m1.1a"><msub id="A1.SS1.SSS6.p1.1.m1.1.1" xref="A1.SS1.SSS6.p1.1.m1.1.1.cmml"><mi id="A1.SS1.SSS6.p1.1.m1.1.1.2" xref="A1.SS1.SSS6.p1.1.m1.1.1.2.cmml">T</mi><mn id="A1.SS1.SSS6.p1.1.m1.1.1.3" xref="A1.SS1.SSS6.p1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS6.p1.1.m1.1b"><apply id="A1.SS1.SSS6.p1.1.m1.1.1.cmml" xref="A1.SS1.SSS6.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS1.SSS6.p1.1.m1.1.1.1.cmml" xref="A1.SS1.SSS6.p1.1.m1.1.1">subscript</csymbol><ci id="A1.SS1.SSS6.p1.1.m1.1.1.2.cmml" xref="A1.SS1.SSS6.p1.1.m1.1.1.2">𝑇</ci><cn type="integer" id="A1.SS1.SSS6.p1.1.m1.1.1.3.cmml" xref="A1.SS1.SSS6.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS6.p1.1.m1.1c">T_{1}</annotation></semantics></math>, <math id="A1.SS1.SSS6.p1.2.m2.1" class="ltx_Math" alttext="RH_{1}" display="inline"><semantics id="A1.SS1.SSS6.p1.2.m2.1a"><mrow id="A1.SS1.SSS6.p1.2.m2.1.1" xref="A1.SS1.SSS6.p1.2.m2.1.1.cmml"><mi id="A1.SS1.SSS6.p1.2.m2.1.1.2" xref="A1.SS1.SSS6.p1.2.m2.1.1.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="A1.SS1.SSS6.p1.2.m2.1.1.1" xref="A1.SS1.SSS6.p1.2.m2.1.1.1.cmml">​</mo><msub id="A1.SS1.SSS6.p1.2.m2.1.1.3" xref="A1.SS1.SSS6.p1.2.m2.1.1.3.cmml"><mi id="A1.SS1.SSS6.p1.2.m2.1.1.3.2" xref="A1.SS1.SSS6.p1.2.m2.1.1.3.2.cmml">H</mi><mn id="A1.SS1.SSS6.p1.2.m2.1.1.3.3" xref="A1.SS1.SSS6.p1.2.m2.1.1.3.3.cmml">1</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS6.p1.2.m2.1b"><apply id="A1.SS1.SSS6.p1.2.m2.1.1.cmml" xref="A1.SS1.SSS6.p1.2.m2.1.1"><times id="A1.SS1.SSS6.p1.2.m2.1.1.1.cmml" xref="A1.SS1.SSS6.p1.2.m2.1.1.1"></times><ci id="A1.SS1.SSS6.p1.2.m2.1.1.2.cmml" xref="A1.SS1.SSS6.p1.2.m2.1.1.2">𝑅</ci><apply id="A1.SS1.SSS6.p1.2.m2.1.1.3.cmml" xref="A1.SS1.SSS6.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="A1.SS1.SSS6.p1.2.m2.1.1.3.1.cmml" xref="A1.SS1.SSS6.p1.2.m2.1.1.3">subscript</csymbol><ci id="A1.SS1.SSS6.p1.2.m2.1.1.3.2.cmml" xref="A1.SS1.SSS6.p1.2.m2.1.1.3.2">𝐻</ci><cn type="integer" id="A1.SS1.SSS6.p1.2.m2.1.1.3.3.cmml" xref="A1.SS1.SSS6.p1.2.m2.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS6.p1.2.m2.1c">RH_{1}</annotation></semantics></math>), living room (<math id="A1.SS1.SSS6.p1.3.m3.1" class="ltx_Math" alttext="T_{2}" display="inline"><semantics id="A1.SS1.SSS6.p1.3.m3.1a"><msub id="A1.SS1.SSS6.p1.3.m3.1.1" xref="A1.SS1.SSS6.p1.3.m3.1.1.cmml"><mi id="A1.SS1.SSS6.p1.3.m3.1.1.2" xref="A1.SS1.SSS6.p1.3.m3.1.1.2.cmml">T</mi><mn id="A1.SS1.SSS6.p1.3.m3.1.1.3" xref="A1.SS1.SSS6.p1.3.m3.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS6.p1.3.m3.1b"><apply id="A1.SS1.SSS6.p1.3.m3.1.1.cmml" xref="A1.SS1.SSS6.p1.3.m3.1.1"><csymbol cd="ambiguous" id="A1.SS1.SSS6.p1.3.m3.1.1.1.cmml" xref="A1.SS1.SSS6.p1.3.m3.1.1">subscript</csymbol><ci id="A1.SS1.SSS6.p1.3.m3.1.1.2.cmml" xref="A1.SS1.SSS6.p1.3.m3.1.1.2">𝑇</ci><cn type="integer" id="A1.SS1.SSS6.p1.3.m3.1.1.3.cmml" xref="A1.SS1.SSS6.p1.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS6.p1.3.m3.1c">T_{2}</annotation></semantics></math>, <math id="A1.SS1.SSS6.p1.4.m4.1" class="ltx_Math" alttext="RH_{2}" display="inline"><semantics id="A1.SS1.SSS6.p1.4.m4.1a"><mrow id="A1.SS1.SSS6.p1.4.m4.1.1" xref="A1.SS1.SSS6.p1.4.m4.1.1.cmml"><mi id="A1.SS1.SSS6.p1.4.m4.1.1.2" xref="A1.SS1.SSS6.p1.4.m4.1.1.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="A1.SS1.SSS6.p1.4.m4.1.1.1" xref="A1.SS1.SSS6.p1.4.m4.1.1.1.cmml">​</mo><msub id="A1.SS1.SSS6.p1.4.m4.1.1.3" xref="A1.SS1.SSS6.p1.4.m4.1.1.3.cmml"><mi id="A1.SS1.SSS6.p1.4.m4.1.1.3.2" xref="A1.SS1.SSS6.p1.4.m4.1.1.3.2.cmml">H</mi><mn id="A1.SS1.SSS6.p1.4.m4.1.1.3.3" xref="A1.SS1.SSS6.p1.4.m4.1.1.3.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS6.p1.4.m4.1b"><apply id="A1.SS1.SSS6.p1.4.m4.1.1.cmml" xref="A1.SS1.SSS6.p1.4.m4.1.1"><times id="A1.SS1.SSS6.p1.4.m4.1.1.1.cmml" xref="A1.SS1.SSS6.p1.4.m4.1.1.1"></times><ci id="A1.SS1.SSS6.p1.4.m4.1.1.2.cmml" xref="A1.SS1.SSS6.p1.4.m4.1.1.2">𝑅</ci><apply id="A1.SS1.SSS6.p1.4.m4.1.1.3.cmml" xref="A1.SS1.SSS6.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="A1.SS1.SSS6.p1.4.m4.1.1.3.1.cmml" xref="A1.SS1.SSS6.p1.4.m4.1.1.3">subscript</csymbol><ci id="A1.SS1.SSS6.p1.4.m4.1.1.3.2.cmml" xref="A1.SS1.SSS6.p1.4.m4.1.1.3.2">𝐻</ci><cn type="integer" id="A1.SS1.SSS6.p1.4.m4.1.1.3.3.cmml" xref="A1.SS1.SSS6.p1.4.m4.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS6.p1.4.m4.1c">RH_{2}</annotation></semantics></math>), laundry room (<math id="A1.SS1.SSS6.p1.5.m5.1" class="ltx_Math" alttext="T_{3}" display="inline"><semantics id="A1.SS1.SSS6.p1.5.m5.1a"><msub id="A1.SS1.SSS6.p1.5.m5.1.1" xref="A1.SS1.SSS6.p1.5.m5.1.1.cmml"><mi id="A1.SS1.SSS6.p1.5.m5.1.1.2" xref="A1.SS1.SSS6.p1.5.m5.1.1.2.cmml">T</mi><mn id="A1.SS1.SSS6.p1.5.m5.1.1.3" xref="A1.SS1.SSS6.p1.5.m5.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS6.p1.5.m5.1b"><apply id="A1.SS1.SSS6.p1.5.m5.1.1.cmml" xref="A1.SS1.SSS6.p1.5.m5.1.1"><csymbol cd="ambiguous" id="A1.SS1.SSS6.p1.5.m5.1.1.1.cmml" xref="A1.SS1.SSS6.p1.5.m5.1.1">subscript</csymbol><ci id="A1.SS1.SSS6.p1.5.m5.1.1.2.cmml" xref="A1.SS1.SSS6.p1.5.m5.1.1.2">𝑇</ci><cn type="integer" id="A1.SS1.SSS6.p1.5.m5.1.1.3.cmml" xref="A1.SS1.SSS6.p1.5.m5.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS6.p1.5.m5.1c">T_{3}</annotation></semantics></math>, <math id="A1.SS1.SSS6.p1.6.m6.1" class="ltx_Math" alttext="RH_{3}" display="inline"><semantics id="A1.SS1.SSS6.p1.6.m6.1a"><mrow id="A1.SS1.SSS6.p1.6.m6.1.1" xref="A1.SS1.SSS6.p1.6.m6.1.1.cmml"><mi id="A1.SS1.SSS6.p1.6.m6.1.1.2" xref="A1.SS1.SSS6.p1.6.m6.1.1.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="A1.SS1.SSS6.p1.6.m6.1.1.1" xref="A1.SS1.SSS6.p1.6.m6.1.1.1.cmml">​</mo><msub id="A1.SS1.SSS6.p1.6.m6.1.1.3" xref="A1.SS1.SSS6.p1.6.m6.1.1.3.cmml"><mi id="A1.SS1.SSS6.p1.6.m6.1.1.3.2" xref="A1.SS1.SSS6.p1.6.m6.1.1.3.2.cmml">H</mi><mn id="A1.SS1.SSS6.p1.6.m6.1.1.3.3" xref="A1.SS1.SSS6.p1.6.m6.1.1.3.3.cmml">3</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS6.p1.6.m6.1b"><apply id="A1.SS1.SSS6.p1.6.m6.1.1.cmml" xref="A1.SS1.SSS6.p1.6.m6.1.1"><times id="A1.SS1.SSS6.p1.6.m6.1.1.1.cmml" xref="A1.SS1.SSS6.p1.6.m6.1.1.1"></times><ci id="A1.SS1.SSS6.p1.6.m6.1.1.2.cmml" xref="A1.SS1.SSS6.p1.6.m6.1.1.2">𝑅</ci><apply id="A1.SS1.SSS6.p1.6.m6.1.1.3.cmml" xref="A1.SS1.SSS6.p1.6.m6.1.1.3"><csymbol cd="ambiguous" id="A1.SS1.SSS6.p1.6.m6.1.1.3.1.cmml" xref="A1.SS1.SSS6.p1.6.m6.1.1.3">subscript</csymbol><ci id="A1.SS1.SSS6.p1.6.m6.1.1.3.2.cmml" xref="A1.SS1.SSS6.p1.6.m6.1.1.3.2">𝐻</ci><cn type="integer" id="A1.SS1.SSS6.p1.6.m6.1.1.3.3.cmml" xref="A1.SS1.SSS6.p1.6.m6.1.1.3.3">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS6.p1.6.m6.1c">RH_{3}</annotation></semantics></math>), office room (<math id="A1.SS1.SSS6.p1.7.m7.1" class="ltx_Math" alttext="T4" display="inline"><semantics id="A1.SS1.SSS6.p1.7.m7.1a"><mrow id="A1.SS1.SSS6.p1.7.m7.1.1" xref="A1.SS1.SSS6.p1.7.m7.1.1.cmml"><mi id="A1.SS1.SSS6.p1.7.m7.1.1.2" xref="A1.SS1.SSS6.p1.7.m7.1.1.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="A1.SS1.SSS6.p1.7.m7.1.1.1" xref="A1.SS1.SSS6.p1.7.m7.1.1.1.cmml">​</mo><mn id="A1.SS1.SSS6.p1.7.m7.1.1.3" xref="A1.SS1.SSS6.p1.7.m7.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS6.p1.7.m7.1b"><apply id="A1.SS1.SSS6.p1.7.m7.1.1.cmml" xref="A1.SS1.SSS6.p1.7.m7.1.1"><times id="A1.SS1.SSS6.p1.7.m7.1.1.1.cmml" xref="A1.SS1.SSS6.p1.7.m7.1.1.1"></times><ci id="A1.SS1.SSS6.p1.7.m7.1.1.2.cmml" xref="A1.SS1.SSS6.p1.7.m7.1.1.2">𝑇</ci><cn type="integer" id="A1.SS1.SSS6.p1.7.m7.1.1.3.cmml" xref="A1.SS1.SSS6.p1.7.m7.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS6.p1.7.m7.1c">T4</annotation></semantics></math>, <math id="A1.SS1.SSS6.p1.8.m8.1" class="ltx_Math" alttext="RH_{4}" display="inline"><semantics id="A1.SS1.SSS6.p1.8.m8.1a"><mrow id="A1.SS1.SSS6.p1.8.m8.1.1" xref="A1.SS1.SSS6.p1.8.m8.1.1.cmml"><mi id="A1.SS1.SSS6.p1.8.m8.1.1.2" xref="A1.SS1.SSS6.p1.8.m8.1.1.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="A1.SS1.SSS6.p1.8.m8.1.1.1" xref="A1.SS1.SSS6.p1.8.m8.1.1.1.cmml">​</mo><msub id="A1.SS1.SSS6.p1.8.m8.1.1.3" xref="A1.SS1.SSS6.p1.8.m8.1.1.3.cmml"><mi id="A1.SS1.SSS6.p1.8.m8.1.1.3.2" xref="A1.SS1.SSS6.p1.8.m8.1.1.3.2.cmml">H</mi><mn id="A1.SS1.SSS6.p1.8.m8.1.1.3.3" xref="A1.SS1.SSS6.p1.8.m8.1.1.3.3.cmml">4</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS6.p1.8.m8.1b"><apply id="A1.SS1.SSS6.p1.8.m8.1.1.cmml" xref="A1.SS1.SSS6.p1.8.m8.1.1"><times id="A1.SS1.SSS6.p1.8.m8.1.1.1.cmml" xref="A1.SS1.SSS6.p1.8.m8.1.1.1"></times><ci id="A1.SS1.SSS6.p1.8.m8.1.1.2.cmml" xref="A1.SS1.SSS6.p1.8.m8.1.1.2">𝑅</ci><apply id="A1.SS1.SSS6.p1.8.m8.1.1.3.cmml" xref="A1.SS1.SSS6.p1.8.m8.1.1.3"><csymbol cd="ambiguous" id="A1.SS1.SSS6.p1.8.m8.1.1.3.1.cmml" xref="A1.SS1.SSS6.p1.8.m8.1.1.3">subscript</csymbol><ci id="A1.SS1.SSS6.p1.8.m8.1.1.3.2.cmml" xref="A1.SS1.SSS6.p1.8.m8.1.1.3.2">𝐻</ci><cn type="integer" id="A1.SS1.SSS6.p1.8.m8.1.1.3.3.cmml" xref="A1.SS1.SSS6.p1.8.m8.1.1.3.3">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS6.p1.8.m8.1c">RH_{4}</annotation></semantics></math>), bathroom (<math id="A1.SS1.SSS6.p1.9.m9.1" class="ltx_Math" alttext="T_{5}" display="inline"><semantics id="A1.SS1.SSS6.p1.9.m9.1a"><msub id="A1.SS1.SSS6.p1.9.m9.1.1" xref="A1.SS1.SSS6.p1.9.m9.1.1.cmml"><mi id="A1.SS1.SSS6.p1.9.m9.1.1.2" xref="A1.SS1.SSS6.p1.9.m9.1.1.2.cmml">T</mi><mn id="A1.SS1.SSS6.p1.9.m9.1.1.3" xref="A1.SS1.SSS6.p1.9.m9.1.1.3.cmml">5</mn></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS6.p1.9.m9.1b"><apply id="A1.SS1.SSS6.p1.9.m9.1.1.cmml" xref="A1.SS1.SSS6.p1.9.m9.1.1"><csymbol cd="ambiguous" id="A1.SS1.SSS6.p1.9.m9.1.1.1.cmml" xref="A1.SS1.SSS6.p1.9.m9.1.1">subscript</csymbol><ci id="A1.SS1.SSS6.p1.9.m9.1.1.2.cmml" xref="A1.SS1.SSS6.p1.9.m9.1.1.2">𝑇</ci><cn type="integer" id="A1.SS1.SSS6.p1.9.m9.1.1.3.cmml" xref="A1.SS1.SSS6.p1.9.m9.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS6.p1.9.m9.1c">T_{5}</annotation></semantics></math>, <math id="A1.SS1.SSS6.p1.10.m10.1" class="ltx_Math" alttext="RH_{5}" display="inline"><semantics id="A1.SS1.SSS6.p1.10.m10.1a"><mrow id="A1.SS1.SSS6.p1.10.m10.1.1" xref="A1.SS1.SSS6.p1.10.m10.1.1.cmml"><mi id="A1.SS1.SSS6.p1.10.m10.1.1.2" xref="A1.SS1.SSS6.p1.10.m10.1.1.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="A1.SS1.SSS6.p1.10.m10.1.1.1" xref="A1.SS1.SSS6.p1.10.m10.1.1.1.cmml">​</mo><msub id="A1.SS1.SSS6.p1.10.m10.1.1.3" xref="A1.SS1.SSS6.p1.10.m10.1.1.3.cmml"><mi id="A1.SS1.SSS6.p1.10.m10.1.1.3.2" xref="A1.SS1.SSS6.p1.10.m10.1.1.3.2.cmml">H</mi><mn id="A1.SS1.SSS6.p1.10.m10.1.1.3.3" xref="A1.SS1.SSS6.p1.10.m10.1.1.3.3.cmml">5</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS6.p1.10.m10.1b"><apply id="A1.SS1.SSS6.p1.10.m10.1.1.cmml" xref="A1.SS1.SSS6.p1.10.m10.1.1"><times id="A1.SS1.SSS6.p1.10.m10.1.1.1.cmml" xref="A1.SS1.SSS6.p1.10.m10.1.1.1"></times><ci id="A1.SS1.SSS6.p1.10.m10.1.1.2.cmml" xref="A1.SS1.SSS6.p1.10.m10.1.1.2">𝑅</ci><apply id="A1.SS1.SSS6.p1.10.m10.1.1.3.cmml" xref="A1.SS1.SSS6.p1.10.m10.1.1.3"><csymbol cd="ambiguous" id="A1.SS1.SSS6.p1.10.m10.1.1.3.1.cmml" xref="A1.SS1.SSS6.p1.10.m10.1.1.3">subscript</csymbol><ci id="A1.SS1.SSS6.p1.10.m10.1.1.3.2.cmml" xref="A1.SS1.SSS6.p1.10.m10.1.1.3.2">𝐻</ci><cn type="integer" id="A1.SS1.SSS6.p1.10.m10.1.1.3.3.cmml" xref="A1.SS1.SSS6.p1.10.m10.1.1.3.3">5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS6.p1.10.m10.1c">RH_{5}</annotation></semantics></math>), ironing room (<math id="A1.SS1.SSS6.p1.11.m11.1" class="ltx_Math" alttext="T_{7}" display="inline"><semantics id="A1.SS1.SSS6.p1.11.m11.1a"><msub id="A1.SS1.SSS6.p1.11.m11.1.1" xref="A1.SS1.SSS6.p1.11.m11.1.1.cmml"><mi id="A1.SS1.SSS6.p1.11.m11.1.1.2" xref="A1.SS1.SSS6.p1.11.m11.1.1.2.cmml">T</mi><mn id="A1.SS1.SSS6.p1.11.m11.1.1.3" xref="A1.SS1.SSS6.p1.11.m11.1.1.3.cmml">7</mn></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS6.p1.11.m11.1b"><apply id="A1.SS1.SSS6.p1.11.m11.1.1.cmml" xref="A1.SS1.SSS6.p1.11.m11.1.1"><csymbol cd="ambiguous" id="A1.SS1.SSS6.p1.11.m11.1.1.1.cmml" xref="A1.SS1.SSS6.p1.11.m11.1.1">subscript</csymbol><ci id="A1.SS1.SSS6.p1.11.m11.1.1.2.cmml" xref="A1.SS1.SSS6.p1.11.m11.1.1.2">𝑇</ci><cn type="integer" id="A1.SS1.SSS6.p1.11.m11.1.1.3.cmml" xref="A1.SS1.SSS6.p1.11.m11.1.1.3">7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS6.p1.11.m11.1c">T_{7}</annotation></semantics></math>, <math id="A1.SS1.SSS6.p1.12.m12.1" class="ltx_Math" alttext="RH_{7}" display="inline"><semantics id="A1.SS1.SSS6.p1.12.m12.1a"><mrow id="A1.SS1.SSS6.p1.12.m12.1.1" xref="A1.SS1.SSS6.p1.12.m12.1.1.cmml"><mi id="A1.SS1.SSS6.p1.12.m12.1.1.2" xref="A1.SS1.SSS6.p1.12.m12.1.1.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="A1.SS1.SSS6.p1.12.m12.1.1.1" xref="A1.SS1.SSS6.p1.12.m12.1.1.1.cmml">​</mo><msub id="A1.SS1.SSS6.p1.12.m12.1.1.3" xref="A1.SS1.SSS6.p1.12.m12.1.1.3.cmml"><mi id="A1.SS1.SSS6.p1.12.m12.1.1.3.2" xref="A1.SS1.SSS6.p1.12.m12.1.1.3.2.cmml">H</mi><mn id="A1.SS1.SSS6.p1.12.m12.1.1.3.3" xref="A1.SS1.SSS6.p1.12.m12.1.1.3.3.cmml">7</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS6.p1.12.m12.1b"><apply id="A1.SS1.SSS6.p1.12.m12.1.1.cmml" xref="A1.SS1.SSS6.p1.12.m12.1.1"><times id="A1.SS1.SSS6.p1.12.m12.1.1.1.cmml" xref="A1.SS1.SSS6.p1.12.m12.1.1.1"></times><ci id="A1.SS1.SSS6.p1.12.m12.1.1.2.cmml" xref="A1.SS1.SSS6.p1.12.m12.1.1.2">𝑅</ci><apply id="A1.SS1.SSS6.p1.12.m12.1.1.3.cmml" xref="A1.SS1.SSS6.p1.12.m12.1.1.3"><csymbol cd="ambiguous" id="A1.SS1.SSS6.p1.12.m12.1.1.3.1.cmml" xref="A1.SS1.SSS6.p1.12.m12.1.1.3">subscript</csymbol><ci id="A1.SS1.SSS6.p1.12.m12.1.1.3.2.cmml" xref="A1.SS1.SSS6.p1.12.m12.1.1.3.2">𝐻</ci><cn type="integer" id="A1.SS1.SSS6.p1.12.m12.1.1.3.3.cmml" xref="A1.SS1.SSS6.p1.12.m12.1.1.3.3">7</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS6.p1.12.m12.1c">RH_{7}</annotation></semantics></math>), teenager room (<math id="A1.SS1.SSS6.p1.13.m13.1" class="ltx_Math" alttext="T_{8}" display="inline"><semantics id="A1.SS1.SSS6.p1.13.m13.1a"><msub id="A1.SS1.SSS6.p1.13.m13.1.1" xref="A1.SS1.SSS6.p1.13.m13.1.1.cmml"><mi id="A1.SS1.SSS6.p1.13.m13.1.1.2" xref="A1.SS1.SSS6.p1.13.m13.1.1.2.cmml">T</mi><mn id="A1.SS1.SSS6.p1.13.m13.1.1.3" xref="A1.SS1.SSS6.p1.13.m13.1.1.3.cmml">8</mn></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS6.p1.13.m13.1b"><apply id="A1.SS1.SSS6.p1.13.m13.1.1.cmml" xref="A1.SS1.SSS6.p1.13.m13.1.1"><csymbol cd="ambiguous" id="A1.SS1.SSS6.p1.13.m13.1.1.1.cmml" xref="A1.SS1.SSS6.p1.13.m13.1.1">subscript</csymbol><ci id="A1.SS1.SSS6.p1.13.m13.1.1.2.cmml" xref="A1.SS1.SSS6.p1.13.m13.1.1.2">𝑇</ci><cn type="integer" id="A1.SS1.SSS6.p1.13.m13.1.1.3.cmml" xref="A1.SS1.SSS6.p1.13.m13.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS6.p1.13.m13.1c">T_{8}</annotation></semantics></math>, <math id="A1.SS1.SSS6.p1.14.m14.1" class="ltx_Math" alttext="RH_{8}" display="inline"><semantics id="A1.SS1.SSS6.p1.14.m14.1a"><mrow id="A1.SS1.SSS6.p1.14.m14.1.1" xref="A1.SS1.SSS6.p1.14.m14.1.1.cmml"><mi id="A1.SS1.SSS6.p1.14.m14.1.1.2" xref="A1.SS1.SSS6.p1.14.m14.1.1.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="A1.SS1.SSS6.p1.14.m14.1.1.1" xref="A1.SS1.SSS6.p1.14.m14.1.1.1.cmml">​</mo><msub id="A1.SS1.SSS6.p1.14.m14.1.1.3" xref="A1.SS1.SSS6.p1.14.m14.1.1.3.cmml"><mi id="A1.SS1.SSS6.p1.14.m14.1.1.3.2" xref="A1.SS1.SSS6.p1.14.m14.1.1.3.2.cmml">H</mi><mn id="A1.SS1.SSS6.p1.14.m14.1.1.3.3" xref="A1.SS1.SSS6.p1.14.m14.1.1.3.3.cmml">8</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS6.p1.14.m14.1b"><apply id="A1.SS1.SSS6.p1.14.m14.1.1.cmml" xref="A1.SS1.SSS6.p1.14.m14.1.1"><times id="A1.SS1.SSS6.p1.14.m14.1.1.1.cmml" xref="A1.SS1.SSS6.p1.14.m14.1.1.1"></times><ci id="A1.SS1.SSS6.p1.14.m14.1.1.2.cmml" xref="A1.SS1.SSS6.p1.14.m14.1.1.2">𝑅</ci><apply id="A1.SS1.SSS6.p1.14.m14.1.1.3.cmml" xref="A1.SS1.SSS6.p1.14.m14.1.1.3"><csymbol cd="ambiguous" id="A1.SS1.SSS6.p1.14.m14.1.1.3.1.cmml" xref="A1.SS1.SSS6.p1.14.m14.1.1.3">subscript</csymbol><ci id="A1.SS1.SSS6.p1.14.m14.1.1.3.2.cmml" xref="A1.SS1.SSS6.p1.14.m14.1.1.3.2">𝐻</ci><cn type="integer" id="A1.SS1.SSS6.p1.14.m14.1.1.3.3.cmml" xref="A1.SS1.SSS6.p1.14.m14.1.1.3.3">8</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS6.p1.14.m14.1c">RH_{8}</annotation></semantics></math>), and parents room (<math id="A1.SS1.SSS6.p1.15.m15.1" class="ltx_Math" alttext="T_{9}" display="inline"><semantics id="A1.SS1.SSS6.p1.15.m15.1a"><msub id="A1.SS1.SSS6.p1.15.m15.1.1" xref="A1.SS1.SSS6.p1.15.m15.1.1.cmml"><mi id="A1.SS1.SSS6.p1.15.m15.1.1.2" xref="A1.SS1.SSS6.p1.15.m15.1.1.2.cmml">T</mi><mn id="A1.SS1.SSS6.p1.15.m15.1.1.3" xref="A1.SS1.SSS6.p1.15.m15.1.1.3.cmml">9</mn></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS6.p1.15.m15.1b"><apply id="A1.SS1.SSS6.p1.15.m15.1.1.cmml" xref="A1.SS1.SSS6.p1.15.m15.1.1"><csymbol cd="ambiguous" id="A1.SS1.SSS6.p1.15.m15.1.1.1.cmml" xref="A1.SS1.SSS6.p1.15.m15.1.1">subscript</csymbol><ci id="A1.SS1.SSS6.p1.15.m15.1.1.2.cmml" xref="A1.SS1.SSS6.p1.15.m15.1.1.2">𝑇</ci><cn type="integer" id="A1.SS1.SSS6.p1.15.m15.1.1.3.cmml" xref="A1.SS1.SSS6.p1.15.m15.1.1.3">9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS6.p1.15.m15.1c">T_{9}</annotation></semantics></math>, <math id="A1.SS1.SSS6.p1.16.m16.1" class="ltx_Math" alttext="RH_{9}" display="inline"><semantics id="A1.SS1.SSS6.p1.16.m16.1a"><mrow id="A1.SS1.SSS6.p1.16.m16.1.1" xref="A1.SS1.SSS6.p1.16.m16.1.1.cmml"><mi id="A1.SS1.SSS6.p1.16.m16.1.1.2" xref="A1.SS1.SSS6.p1.16.m16.1.1.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="A1.SS1.SSS6.p1.16.m16.1.1.1" xref="A1.SS1.SSS6.p1.16.m16.1.1.1.cmml">​</mo><msub id="A1.SS1.SSS6.p1.16.m16.1.1.3" xref="A1.SS1.SSS6.p1.16.m16.1.1.3.cmml"><mi id="A1.SS1.SSS6.p1.16.m16.1.1.3.2" xref="A1.SS1.SSS6.p1.16.m16.1.1.3.2.cmml">H</mi><mn id="A1.SS1.SSS6.p1.16.m16.1.1.3.3" xref="A1.SS1.SSS6.p1.16.m16.1.1.3.3.cmml">9</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS6.p1.16.m16.1b"><apply id="A1.SS1.SSS6.p1.16.m16.1.1.cmml" xref="A1.SS1.SSS6.p1.16.m16.1.1"><times id="A1.SS1.SSS6.p1.16.m16.1.1.1.cmml" xref="A1.SS1.SSS6.p1.16.m16.1.1.1"></times><ci id="A1.SS1.SSS6.p1.16.m16.1.1.2.cmml" xref="A1.SS1.SSS6.p1.16.m16.1.1.2">𝑅</ci><apply id="A1.SS1.SSS6.p1.16.m16.1.1.3.cmml" xref="A1.SS1.SSS6.p1.16.m16.1.1.3"><csymbol cd="ambiguous" id="A1.SS1.SSS6.p1.16.m16.1.1.3.1.cmml" xref="A1.SS1.SSS6.p1.16.m16.1.1.3">subscript</csymbol><ci id="A1.SS1.SSS6.p1.16.m16.1.1.3.2.cmml" xref="A1.SS1.SSS6.p1.16.m16.1.1.3.2">𝐻</ci><cn type="integer" id="A1.SS1.SSS6.p1.16.m16.1.1.3.3.cmml" xref="A1.SS1.SSS6.p1.16.m16.1.1.3.3">9</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS6.p1.16.m16.1c">RH_{9}</annotation></semantics></math>), and temperature and humidity outside the building (<math id="A1.SS1.SSS6.p1.17.m17.1" class="ltx_Math" alttext="T_{6}" display="inline"><semantics id="A1.SS1.SSS6.p1.17.m17.1a"><msub id="A1.SS1.SSS6.p1.17.m17.1.1" xref="A1.SS1.SSS6.p1.17.m17.1.1.cmml"><mi id="A1.SS1.SSS6.p1.17.m17.1.1.2" xref="A1.SS1.SSS6.p1.17.m17.1.1.2.cmml">T</mi><mn id="A1.SS1.SSS6.p1.17.m17.1.1.3" xref="A1.SS1.SSS6.p1.17.m17.1.1.3.cmml">6</mn></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS6.p1.17.m17.1b"><apply id="A1.SS1.SSS6.p1.17.m17.1.1.cmml" xref="A1.SS1.SSS6.p1.17.m17.1.1"><csymbol cd="ambiguous" id="A1.SS1.SSS6.p1.17.m17.1.1.1.cmml" xref="A1.SS1.SSS6.p1.17.m17.1.1">subscript</csymbol><ci id="A1.SS1.SSS6.p1.17.m17.1.1.2.cmml" xref="A1.SS1.SSS6.p1.17.m17.1.1.2">𝑇</ci><cn type="integer" id="A1.SS1.SSS6.p1.17.m17.1.1.3.cmml" xref="A1.SS1.SSS6.p1.17.m17.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS6.p1.17.m17.1c">T_{6}</annotation></semantics></math>, <math id="A1.SS1.SSS6.p1.18.m18.1" class="ltx_Math" alttext="RH_{6}" display="inline"><semantics id="A1.SS1.SSS6.p1.18.m18.1a"><mrow id="A1.SS1.SSS6.p1.18.m18.1.1" xref="A1.SS1.SSS6.p1.18.m18.1.1.cmml"><mi id="A1.SS1.SSS6.p1.18.m18.1.1.2" xref="A1.SS1.SSS6.p1.18.m18.1.1.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="A1.SS1.SSS6.p1.18.m18.1.1.1" xref="A1.SS1.SSS6.p1.18.m18.1.1.1.cmml">​</mo><msub id="A1.SS1.SSS6.p1.18.m18.1.1.3" xref="A1.SS1.SSS6.p1.18.m18.1.1.3.cmml"><mi id="A1.SS1.SSS6.p1.18.m18.1.1.3.2" xref="A1.SS1.SSS6.p1.18.m18.1.1.3.2.cmml">H</mi><mn id="A1.SS1.SSS6.p1.18.m18.1.1.3.3" xref="A1.SS1.SSS6.p1.18.m18.1.1.3.3.cmml">6</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS6.p1.18.m18.1b"><apply id="A1.SS1.SSS6.p1.18.m18.1.1.cmml" xref="A1.SS1.SSS6.p1.18.m18.1.1"><times id="A1.SS1.SSS6.p1.18.m18.1.1.1.cmml" xref="A1.SS1.SSS6.p1.18.m18.1.1.1"></times><ci id="A1.SS1.SSS6.p1.18.m18.1.1.2.cmml" xref="A1.SS1.SSS6.p1.18.m18.1.1.2">𝑅</ci><apply id="A1.SS1.SSS6.p1.18.m18.1.1.3.cmml" xref="A1.SS1.SSS6.p1.18.m18.1.1.3"><csymbol cd="ambiguous" id="A1.SS1.SSS6.p1.18.m18.1.1.3.1.cmml" xref="A1.SS1.SSS6.p1.18.m18.1.1.3">subscript</csymbol><ci id="A1.SS1.SSS6.p1.18.m18.1.1.3.2.cmml" xref="A1.SS1.SSS6.p1.18.m18.1.1.3.2">𝐻</ci><cn type="integer" id="A1.SS1.SSS6.p1.18.m18.1.1.3.3.cmml" xref="A1.SS1.SSS6.p1.18.m18.1.1.3.3">6</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS6.p1.18.m18.1c">RH_{6}</annotation></semantics></math>) - all with temperatures in Celsius and humidity in percentages. Additionally, weather data from Chievres Airport, Belgium was incorporated, consisting of outside temperature (To in Celsius), pressure (in mm Hg), humidity (<math id="A1.SS1.SSS6.p1.19.m19.1" class="ltx_Math" alttext="RH_{out}" display="inline"><semantics id="A1.SS1.SSS6.p1.19.m19.1a"><mrow id="A1.SS1.SSS6.p1.19.m19.1.1" xref="A1.SS1.SSS6.p1.19.m19.1.1.cmml"><mi id="A1.SS1.SSS6.p1.19.m19.1.1.2" xref="A1.SS1.SSS6.p1.19.m19.1.1.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="A1.SS1.SSS6.p1.19.m19.1.1.1" xref="A1.SS1.SSS6.p1.19.m19.1.1.1.cmml">​</mo><msub id="A1.SS1.SSS6.p1.19.m19.1.1.3" xref="A1.SS1.SSS6.p1.19.m19.1.1.3.cmml"><mi id="A1.SS1.SSS6.p1.19.m19.1.1.3.2" xref="A1.SS1.SSS6.p1.19.m19.1.1.3.2.cmml">H</mi><mrow id="A1.SS1.SSS6.p1.19.m19.1.1.3.3" xref="A1.SS1.SSS6.p1.19.m19.1.1.3.3.cmml"><mi id="A1.SS1.SSS6.p1.19.m19.1.1.3.3.2" xref="A1.SS1.SSS6.p1.19.m19.1.1.3.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="A1.SS1.SSS6.p1.19.m19.1.1.3.3.1" xref="A1.SS1.SSS6.p1.19.m19.1.1.3.3.1.cmml">​</mo><mi id="A1.SS1.SSS6.p1.19.m19.1.1.3.3.3" xref="A1.SS1.SSS6.p1.19.m19.1.1.3.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="A1.SS1.SSS6.p1.19.m19.1.1.3.3.1a" xref="A1.SS1.SSS6.p1.19.m19.1.1.3.3.1.cmml">​</mo><mi id="A1.SS1.SSS6.p1.19.m19.1.1.3.3.4" xref="A1.SS1.SSS6.p1.19.m19.1.1.3.3.4.cmml">t</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS6.p1.19.m19.1b"><apply id="A1.SS1.SSS6.p1.19.m19.1.1.cmml" xref="A1.SS1.SSS6.p1.19.m19.1.1"><times id="A1.SS1.SSS6.p1.19.m19.1.1.1.cmml" xref="A1.SS1.SSS6.p1.19.m19.1.1.1"></times><ci id="A1.SS1.SSS6.p1.19.m19.1.1.2.cmml" xref="A1.SS1.SSS6.p1.19.m19.1.1.2">𝑅</ci><apply id="A1.SS1.SSS6.p1.19.m19.1.1.3.cmml" xref="A1.SS1.SSS6.p1.19.m19.1.1.3"><csymbol cd="ambiguous" id="A1.SS1.SSS6.p1.19.m19.1.1.3.1.cmml" xref="A1.SS1.SSS6.p1.19.m19.1.1.3">subscript</csymbol><ci id="A1.SS1.SSS6.p1.19.m19.1.1.3.2.cmml" xref="A1.SS1.SSS6.p1.19.m19.1.1.3.2">𝐻</ci><apply id="A1.SS1.SSS6.p1.19.m19.1.1.3.3.cmml" xref="A1.SS1.SSS6.p1.19.m19.1.1.3.3"><times id="A1.SS1.SSS6.p1.19.m19.1.1.3.3.1.cmml" xref="A1.SS1.SSS6.p1.19.m19.1.1.3.3.1"></times><ci id="A1.SS1.SSS6.p1.19.m19.1.1.3.3.2.cmml" xref="A1.SS1.SSS6.p1.19.m19.1.1.3.3.2">𝑜</ci><ci id="A1.SS1.SSS6.p1.19.m19.1.1.3.3.3.cmml" xref="A1.SS1.SSS6.p1.19.m19.1.1.3.3.3">𝑢</ci><ci id="A1.SS1.SSS6.p1.19.m19.1.1.3.3.4.cmml" xref="A1.SS1.SSS6.p1.19.m19.1.1.3.3.4">𝑡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS6.p1.19.m19.1c">RH_{out}</annotation></semantics></math> in %), wind speed (in m/s), visibility (in km), and dew point (<math id="A1.SS1.SSS6.p1.20.m20.1" class="ltx_Math" alttext="T_{dewpoint}" display="inline"><semantics id="A1.SS1.SSS6.p1.20.m20.1a"><msub id="A1.SS1.SSS6.p1.20.m20.1.1" xref="A1.SS1.SSS6.p1.20.m20.1.1.cmml"><mi id="A1.SS1.SSS6.p1.20.m20.1.1.2" xref="A1.SS1.SSS6.p1.20.m20.1.1.2.cmml">T</mi><mrow id="A1.SS1.SSS6.p1.20.m20.1.1.3" xref="A1.SS1.SSS6.p1.20.m20.1.1.3.cmml"><mi id="A1.SS1.SSS6.p1.20.m20.1.1.3.2" xref="A1.SS1.SSS6.p1.20.m20.1.1.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="A1.SS1.SSS6.p1.20.m20.1.1.3.1" xref="A1.SS1.SSS6.p1.20.m20.1.1.3.1.cmml">​</mo><mi id="A1.SS1.SSS6.p1.20.m20.1.1.3.3" xref="A1.SS1.SSS6.p1.20.m20.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="A1.SS1.SSS6.p1.20.m20.1.1.3.1a" xref="A1.SS1.SSS6.p1.20.m20.1.1.3.1.cmml">​</mo><mi id="A1.SS1.SSS6.p1.20.m20.1.1.3.4" xref="A1.SS1.SSS6.p1.20.m20.1.1.3.4.cmml">w</mi><mo lspace="0em" rspace="0em" id="A1.SS1.SSS6.p1.20.m20.1.1.3.1b" xref="A1.SS1.SSS6.p1.20.m20.1.1.3.1.cmml">​</mo><mi id="A1.SS1.SSS6.p1.20.m20.1.1.3.5" xref="A1.SS1.SSS6.p1.20.m20.1.1.3.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="A1.SS1.SSS6.p1.20.m20.1.1.3.1c" xref="A1.SS1.SSS6.p1.20.m20.1.1.3.1.cmml">​</mo><mi id="A1.SS1.SSS6.p1.20.m20.1.1.3.6" xref="A1.SS1.SSS6.p1.20.m20.1.1.3.6.cmml">o</mi><mo lspace="0em" rspace="0em" id="A1.SS1.SSS6.p1.20.m20.1.1.3.1d" xref="A1.SS1.SSS6.p1.20.m20.1.1.3.1.cmml">​</mo><mi id="A1.SS1.SSS6.p1.20.m20.1.1.3.7" xref="A1.SS1.SSS6.p1.20.m20.1.1.3.7.cmml">i</mi><mo lspace="0em" rspace="0em" id="A1.SS1.SSS6.p1.20.m20.1.1.3.1e" xref="A1.SS1.SSS6.p1.20.m20.1.1.3.1.cmml">​</mo><mi id="A1.SS1.SSS6.p1.20.m20.1.1.3.8" xref="A1.SS1.SSS6.p1.20.m20.1.1.3.8.cmml">n</mi><mo lspace="0em" rspace="0em" id="A1.SS1.SSS6.p1.20.m20.1.1.3.1f" xref="A1.SS1.SSS6.p1.20.m20.1.1.3.1.cmml">​</mo><mi id="A1.SS1.SSS6.p1.20.m20.1.1.3.9" xref="A1.SS1.SSS6.p1.20.m20.1.1.3.9.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS6.p1.20.m20.1b"><apply id="A1.SS1.SSS6.p1.20.m20.1.1.cmml" xref="A1.SS1.SSS6.p1.20.m20.1.1"><csymbol cd="ambiguous" id="A1.SS1.SSS6.p1.20.m20.1.1.1.cmml" xref="A1.SS1.SSS6.p1.20.m20.1.1">subscript</csymbol><ci id="A1.SS1.SSS6.p1.20.m20.1.1.2.cmml" xref="A1.SS1.SSS6.p1.20.m20.1.1.2">𝑇</ci><apply id="A1.SS1.SSS6.p1.20.m20.1.1.3.cmml" xref="A1.SS1.SSS6.p1.20.m20.1.1.3"><times id="A1.SS1.SSS6.p1.20.m20.1.1.3.1.cmml" xref="A1.SS1.SSS6.p1.20.m20.1.1.3.1"></times><ci id="A1.SS1.SSS6.p1.20.m20.1.1.3.2.cmml" xref="A1.SS1.SSS6.p1.20.m20.1.1.3.2">𝑑</ci><ci id="A1.SS1.SSS6.p1.20.m20.1.1.3.3.cmml" xref="A1.SS1.SSS6.p1.20.m20.1.1.3.3">𝑒</ci><ci id="A1.SS1.SSS6.p1.20.m20.1.1.3.4.cmml" xref="A1.SS1.SSS6.p1.20.m20.1.1.3.4">𝑤</ci><ci id="A1.SS1.SSS6.p1.20.m20.1.1.3.5.cmml" xref="A1.SS1.SSS6.p1.20.m20.1.1.3.5">𝑝</ci><ci id="A1.SS1.SSS6.p1.20.m20.1.1.3.6.cmml" xref="A1.SS1.SSS6.p1.20.m20.1.1.3.6">𝑜</ci><ci id="A1.SS1.SSS6.p1.20.m20.1.1.3.7.cmml" xref="A1.SS1.SSS6.p1.20.m20.1.1.3.7">𝑖</ci><ci id="A1.SS1.SSS6.p1.20.m20.1.1.3.8.cmml" xref="A1.SS1.SSS6.p1.20.m20.1.1.3.8">𝑛</ci><ci id="A1.SS1.SSS6.p1.20.m20.1.1.3.9.cmml" xref="A1.SS1.SSS6.p1.20.m20.1.1.3.9">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS6.p1.20.m20.1c">T_{dewpoint}</annotation></semantics></math> in °C). The dataset is available at <a target="_blank" href="https://archive.ics.uci.edu/dataset/374/appliances+energy+prediction" title="" class="ltx_ref ltx_href">https://archive.ics.uci.edu/dataset/374/appliances+energy+prediction</a>.</p>
</div>
</section>
<section id="A1.SS1.SSS7" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.1.7 </span>EPIC-SOUNDS</h4>

<div id="A1.SS1.SSS7.p1" class="ltx_para">
<p id="A1.SS1.SSS7.p1.1" class="ltx_p">As an extension of the EPIC-KITCHENS-100 dataset, the EPIC-SOUNDS dataset focuses on annotating distinct audio events in the videos of EPIC-KITCHENS-100. The annotations include the time intervals during which each audio event occurs, along with a text description explaining the nature of the sound.
Given the variation in video lengths in the dataset, which range from 30 seconds to 1.5 hours, the videos are segmented into clips of 3-4 minutes each to make the annotation process more manageable.
In order to ensure that annotators concentrate solely on the audio aspects, only the audio stream is provided to them. This decision is taken to prevent bias that could be introduced by the visual and contextual elements in the videos.
Additionally, annotators are given access to the plotted audio waveforms. These visual representations of the audio data help the annotators by guiding them in pinpointing specific sound patterns, thus making the annotation process more efficient and targeted.
The EPIC-SOUNDS dataset can be extracted from the EPIC-KITHENS-100 dataset with the GitHub repo at <a target="_blank" href="https://github.com/epic-kitchens/epic-sounds-annotations" title="" class="ltx_ref ltx_href">https://github.com/epic-kitchens/epic-sounds-annotations</a>. The extracted audio data in the form of HDF5 file format can also be requested from <a href="mailto:uob-epic-kitchens@bristol.ac.uk" title="" class="ltx_ref ltx_href">uob-epic-kitchens@bristol.ac.uk</a>.</p>
</div>
</section>
</section>
<section id="A1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Hyperparameters</h3>

<div id="A1.SS2.p1" class="ltx_para">
<p id="A1.SS2.p1.1" class="ltx_p"><span id="A1.SS2.p1.1.1" class="ltx_text ltx_font_bold">Hyperparameters for Table <a href="#S4.T3" title="Table 3 ‣ 4.1 Overall Performance ‣ 4 Experiments and Analysis ‣ FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</span> For WISDM-W, the learning rate for centralized training was 0.01 and we trained for 200 epochs with batch size 64. For FedAvg, in both low and high data heterogeneity scenarios, we used a client learning rate of 0.01 and trained for 400 communication rounds with batch size 32. For FedOPT, in both low and high data heterogeneity scenarios, we used a client learning rate of 0.01 and a server learning rate of 0.01. We also trained for 400 communication rounds. For WISDM-P, the learning rate for centralized training was 0.01 and we trained for 200 epochs with batch size 128. For FedAvg, in both low and high data heterogeneity scenarios, we used a client learning rate of 0.008 and trained for 400 communication rounds with batch size 32. For FedOPT, in both low and high data heterogeneity scenarios, we used a client learning rate of 0.01 and a server learning rate of 0.01. We also trained for 400 communication rounds. For UT-HAR and Widar, the learning rate for centralized training was 0.001 and the number of epochs was 500 and 200 for UT-HAR and Widar respectively with a batch size of 32. For both low and high data heterogeneity in both FedAvg and FedOPT, the client learning rate was 0.01 and the server learning rate for FedAvg and FedOPT was 1 and 0.01 respectively. The number of communication rounds was 1200 and 900 for UT-HAR and Widar respectively with a batch size of 32. For VisDrone, we used a cosine learning rate scheduler with <math id="A1.SS2.p1.1.m1.2" class="ltx_Math" alttext="T_{0}=10,T_{mult}=2" display="inline"><semantics id="A1.SS2.p1.1.m1.2a"><mrow id="A1.SS2.p1.1.m1.2.2.2" xref="A1.SS2.p1.1.m1.2.2.3.cmml"><mrow id="A1.SS2.p1.1.m1.1.1.1.1" xref="A1.SS2.p1.1.m1.1.1.1.1.cmml"><msub id="A1.SS2.p1.1.m1.1.1.1.1.2" xref="A1.SS2.p1.1.m1.1.1.1.1.2.cmml"><mi id="A1.SS2.p1.1.m1.1.1.1.1.2.2" xref="A1.SS2.p1.1.m1.1.1.1.1.2.2.cmml">T</mi><mn id="A1.SS2.p1.1.m1.1.1.1.1.2.3" xref="A1.SS2.p1.1.m1.1.1.1.1.2.3.cmml">0</mn></msub><mo id="A1.SS2.p1.1.m1.1.1.1.1.1" xref="A1.SS2.p1.1.m1.1.1.1.1.1.cmml">=</mo><mn id="A1.SS2.p1.1.m1.1.1.1.1.3" xref="A1.SS2.p1.1.m1.1.1.1.1.3.cmml">10</mn></mrow><mo id="A1.SS2.p1.1.m1.2.2.2.3" xref="A1.SS2.p1.1.m1.2.2.3a.cmml">,</mo><mrow id="A1.SS2.p1.1.m1.2.2.2.2" xref="A1.SS2.p1.1.m1.2.2.2.2.cmml"><msub id="A1.SS2.p1.1.m1.2.2.2.2.2" xref="A1.SS2.p1.1.m1.2.2.2.2.2.cmml"><mi id="A1.SS2.p1.1.m1.2.2.2.2.2.2" xref="A1.SS2.p1.1.m1.2.2.2.2.2.2.cmml">T</mi><mrow id="A1.SS2.p1.1.m1.2.2.2.2.2.3" xref="A1.SS2.p1.1.m1.2.2.2.2.2.3.cmml"><mi id="A1.SS2.p1.1.m1.2.2.2.2.2.3.2" xref="A1.SS2.p1.1.m1.2.2.2.2.2.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="A1.SS2.p1.1.m1.2.2.2.2.2.3.1" xref="A1.SS2.p1.1.m1.2.2.2.2.2.3.1.cmml">​</mo><mi id="A1.SS2.p1.1.m1.2.2.2.2.2.3.3" xref="A1.SS2.p1.1.m1.2.2.2.2.2.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="A1.SS2.p1.1.m1.2.2.2.2.2.3.1a" xref="A1.SS2.p1.1.m1.2.2.2.2.2.3.1.cmml">​</mo><mi id="A1.SS2.p1.1.m1.2.2.2.2.2.3.4" xref="A1.SS2.p1.1.m1.2.2.2.2.2.3.4.cmml">l</mi><mo lspace="0em" rspace="0em" id="A1.SS2.p1.1.m1.2.2.2.2.2.3.1b" xref="A1.SS2.p1.1.m1.2.2.2.2.2.3.1.cmml">​</mo><mi id="A1.SS2.p1.1.m1.2.2.2.2.2.3.5" xref="A1.SS2.p1.1.m1.2.2.2.2.2.3.5.cmml">t</mi></mrow></msub><mo id="A1.SS2.p1.1.m1.2.2.2.2.1" xref="A1.SS2.p1.1.m1.2.2.2.2.1.cmml">=</mo><mn id="A1.SS2.p1.1.m1.2.2.2.2.3" xref="A1.SS2.p1.1.m1.2.2.2.2.3.cmml">2</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.1.m1.2b"><apply id="A1.SS2.p1.1.m1.2.2.3.cmml" xref="A1.SS2.p1.1.m1.2.2.2"><csymbol cd="ambiguous" id="A1.SS2.p1.1.m1.2.2.3a.cmml" xref="A1.SS2.p1.1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="A1.SS2.p1.1.m1.1.1.1.1.cmml" xref="A1.SS2.p1.1.m1.1.1.1.1"><eq id="A1.SS2.p1.1.m1.1.1.1.1.1.cmml" xref="A1.SS2.p1.1.m1.1.1.1.1.1"></eq><apply id="A1.SS2.p1.1.m1.1.1.1.1.2.cmml" xref="A1.SS2.p1.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="A1.SS2.p1.1.m1.1.1.1.1.2.1.cmml" xref="A1.SS2.p1.1.m1.1.1.1.1.2">subscript</csymbol><ci id="A1.SS2.p1.1.m1.1.1.1.1.2.2.cmml" xref="A1.SS2.p1.1.m1.1.1.1.1.2.2">𝑇</ci><cn type="integer" id="A1.SS2.p1.1.m1.1.1.1.1.2.3.cmml" xref="A1.SS2.p1.1.m1.1.1.1.1.2.3">0</cn></apply><cn type="integer" id="A1.SS2.p1.1.m1.1.1.1.1.3.cmml" xref="A1.SS2.p1.1.m1.1.1.1.1.3">10</cn></apply><apply id="A1.SS2.p1.1.m1.2.2.2.2.cmml" xref="A1.SS2.p1.1.m1.2.2.2.2"><eq id="A1.SS2.p1.1.m1.2.2.2.2.1.cmml" xref="A1.SS2.p1.1.m1.2.2.2.2.1"></eq><apply id="A1.SS2.p1.1.m1.2.2.2.2.2.cmml" xref="A1.SS2.p1.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="A1.SS2.p1.1.m1.2.2.2.2.2.1.cmml" xref="A1.SS2.p1.1.m1.2.2.2.2.2">subscript</csymbol><ci id="A1.SS2.p1.1.m1.2.2.2.2.2.2.cmml" xref="A1.SS2.p1.1.m1.2.2.2.2.2.2">𝑇</ci><apply id="A1.SS2.p1.1.m1.2.2.2.2.2.3.cmml" xref="A1.SS2.p1.1.m1.2.2.2.2.2.3"><times id="A1.SS2.p1.1.m1.2.2.2.2.2.3.1.cmml" xref="A1.SS2.p1.1.m1.2.2.2.2.2.3.1"></times><ci id="A1.SS2.p1.1.m1.2.2.2.2.2.3.2.cmml" xref="A1.SS2.p1.1.m1.2.2.2.2.2.3.2">𝑚</ci><ci id="A1.SS2.p1.1.m1.2.2.2.2.2.3.3.cmml" xref="A1.SS2.p1.1.m1.2.2.2.2.2.3.3">𝑢</ci><ci id="A1.SS2.p1.1.m1.2.2.2.2.2.3.4.cmml" xref="A1.SS2.p1.1.m1.2.2.2.2.2.3.4">𝑙</ci><ci id="A1.SS2.p1.1.m1.2.2.2.2.2.3.5.cmml" xref="A1.SS2.p1.1.m1.2.2.2.2.2.3.5">𝑡</ci></apply></apply><cn type="integer" id="A1.SS2.p1.1.m1.2.2.2.2.3.cmml" xref="A1.SS2.p1.1.m1.2.2.2.2.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.1.m1.2c">T_{0}=10,T_{mult}=2</annotation></semantics></math> and trained for 200 epochs with a learning rate of 0.1 and batch size 12. For all the experiments on VisDrone, the client learning rate was also
0.1 and the batch size was 12. For FedOPT, the server learning rate was 0.1.
For CASAS, the centralized learning rate was 0.1 with batch size 128. For the federated setting, the client learning rate was 0.005, and the batch size was 32. We trained for 400 rounds. For FedOPT, the server learning rate was 0.01. For AEP, the learning rate for centralized training was 0.001 and the batch size was 32 and it was trained for 1200 epochs. For federated experiments, the client learning rate was 0.01, and the batch size was 32. For FedOPT, the server learning rate was 0.1.
For EPIC-SOUNDS, for centralized training, the learning rate was 0.1 with batch size 512. The number of epochs was 120. For federated settings, we used a client learning rate of 0.1 and batch size 32. For FedOPT, the server learning rate was 0.01.</p>
</div>
<div id="A1.SS2.p2" class="ltx_para">
<p id="A1.SS2.p2.3" class="ltx_p"><span id="A1.SS2.p2.3.1" class="ltx_text ltx_font_bold">Hyperparameters for Table <a href="#S4.T4" title="Table 4 ‣ 4.2 Impact of Client Sampling Ratio ‣ 4 Experiments and Analysis ‣ FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</span> The setup for all the datasets with <math id="A1.SS2.p2.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A1.SS2.p2.1.m1.1a"><mn id="A1.SS2.p2.1.m1.1.1" xref="A1.SS2.p2.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.p2.1.m1.1b"><cn type="integer" id="A1.SS2.p2.1.m1.1.1.cmml" xref="A1.SS2.p2.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p2.1.m1.1c">10</annotation></semantics></math>% client sampling rate is the same as that of Table <a href="#S4.T3" title="Table 3 ‣ 4.1 Overall Performance ‣ 4 Experiments and Analysis ‣ FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> under high data heterogeneity. For the <math id="A1.SS2.p2.2.m2.1" class="ltx_Math" alttext="30" display="inline"><semantics id="A1.SS2.p2.2.m2.1a"><mn id="A1.SS2.p2.2.m2.1.1" xref="A1.SS2.p2.2.m2.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.p2.2.m2.1b"><cn type="integer" id="A1.SS2.p2.2.m2.1.1.cmml" xref="A1.SS2.p2.2.m2.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p2.2.m2.1c">30</annotation></semantics></math>% client sampling rate, the hyperparameters were kept the same as that of the <math id="A1.SS2.p2.3.m3.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A1.SS2.p2.3.m3.1a"><mn id="A1.SS2.p2.3.m3.1.1" xref="A1.SS2.p2.3.m3.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.p2.3.m3.1b"><cn type="integer" id="A1.SS2.p2.3.m3.1.1.cmml" xref="A1.SS2.p2.3.m3.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p2.3.m3.1c">10</annotation></semantics></math>% client sampling rate experiments, with the exception of CASAS, where the learning rate was set to 0.15.</p>
</div>
<div id="A1.SS2.p3" class="ltx_para">
<p id="A1.SS2.p3.1" class="ltx_p"><span id="A1.SS2.p3.1.1" class="ltx_text ltx_font_bold">Hyperparameters for Table <a href="#S4.SS3" title="4.3 Impact of Erroneous Labels ‣ 4 Experiments and Analysis ‣ FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>.</span>
The hyperparameters were the same as that of Table <a href="#S4.T3" title="Table 3 ‣ 4.1 Overall Performance ‣ 4 Experiments and Analysis ‣ FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> with <math id="A1.SS2.p3.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A1.SS2.p3.1.m1.1a"><mn id="A1.SS2.p3.1.m1.1.1" xref="A1.SS2.p3.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.p3.1.m1.1b"><cn type="integer" id="A1.SS2.p3.1.m1.1.1.cmml" xref="A1.SS2.p3.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p3.1.m1.1c">10</annotation></semantics></math>% sampling rate under high data heterogeneity scenario.</p>
</div>
<div id="A1.SS2.p4" class="ltx_para">
<p id="A1.SS2.p4.1" class="ltx_p"><span id="A1.SS2.p4.1.1" class="ltx_text ltx_font_bold">Hyperparameters for Table <a href="#S4.T6" title="Table 6 ‣ 4.4 Performance on Quantized Training ‣ 4.3 Impact of Erroneous Labels ‣ 4 Experiments and Analysis ‣ FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.</span> The hyperparameters were same as that of Table <a href="#S4.T3" title="Table 3 ‣ 4.1 Overall Performance ‣ 4 Experiments and Analysis ‣ FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> with <math id="A1.SS2.p4.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A1.SS2.p4.1.m1.1a"><mn id="A1.SS2.p4.1.m1.1.1" xref="A1.SS2.p4.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A1.SS2.p4.1.m1.1b"><cn type="integer" id="A1.SS2.p4.1.m1.1.1.cmml" xref="A1.SS2.p4.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p4.1.m1.1c">10</annotation></semantics></math>% client sampling rate under high data heterogeneity scenario.</p>
</div>
</section>
<section id="A1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Model Architectures </h3>

<section id="A1.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.3.1 </span>WISDM</h4>

<div id="A1.SS3.SSS1.p1" class="ltx_para">
<p id="A1.SS3.SSS1.p1.1" class="ltx_p">For WISDM, we use a custom LSTM model that consists of an LSTM layer followed by a feed-forward neural network. The LSTM layer has an input dimension of 6 and a hidden dimension of 6. After the LSTM layer, the output is flattened and passed through a dropout layer with a rate of 0.2 for regularization. It then goes through a fully connected linear layer with an input size of <math id="A1.SS3.SSS1.p1.1.m1.2" class="ltx_Math" alttext="1,200" display="inline"><semantics id="A1.SS3.SSS1.p1.1.m1.2a"><mrow id="A1.SS3.SSS1.p1.1.m1.2.3.2" xref="A1.SS3.SSS1.p1.1.m1.2.3.1.cmml"><mn id="A1.SS3.SSS1.p1.1.m1.1.1" xref="A1.SS3.SSS1.p1.1.m1.1.1.cmml">1</mn><mo id="A1.SS3.SSS1.p1.1.m1.2.3.2.1" xref="A1.SS3.SSS1.p1.1.m1.2.3.1.cmml">,</mo><mn id="A1.SS3.SSS1.p1.1.m1.2.2" xref="A1.SS3.SSS1.p1.1.m1.2.2.cmml">200</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS1.p1.1.m1.2b"><list id="A1.SS3.SSS1.p1.1.m1.2.3.1.cmml" xref="A1.SS3.SSS1.p1.1.m1.2.3.2"><cn type="integer" id="A1.SS3.SSS1.p1.1.m1.1.1.cmml" xref="A1.SS3.SSS1.p1.1.m1.1.1">1</cn><cn type="integer" id="A1.SS3.SSS1.p1.1.m1.2.2.cmml" xref="A1.SS3.SSS1.p1.1.m1.2.2">200</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS1.p1.1.m1.2c">1,200</annotation></semantics></math> (6 hidden units * 200 timesteps) and an output size of 128, followed by a ReLU activation function. Another dropout layer with a rate of 0.2 is applied before the final fully connected linear layer with an input size of 128 and an output size of 12.</p>
</div>
</section>
<section id="A1.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.3.2 </span>UT-HAR</h4>

<div id="A1.SS3.SSS2.p1" class="ltx_para">
<p id="A1.SS3.SSS2.p1.1" class="ltx_p">For UT-HAR, we use a ResNet-18 model with custom architecture designed for the Wi-Fi based Human Activity Recognition (HAR) task. The model consists of an initial convolutional layer that reshapes the input into a 3-channel tensor followed by the main ResNet architecture with 18 layers. This main architecture includes a series of convolutional blocks with residual connections, Group Normalization layers, ReLU activations, and max-pooling. Finally, there is an adaptive average pooling layer followed by a fully connected layer that outputs the class probabilities. The model utilizes 64 output channels in the initial layer and doubles the number of channels as it goes deeper. The last fully connected layer has 7 output units corresponding to the number of classes for the UT-HAR task.</p>
</div>
</section>
<section id="A1.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.3.3 </span>Widar</h4>

<div id="A1.SS3.SSS3.p1" class="ltx_para">
<p id="A1.SS3.SSS3.p1.1" class="ltx_p">For Widar, we also use a custom ResNet-18 model tailored for the Widar dataset. The model starts by reshaping the 22-channel input to 3 channels using two convolutional transpose layers, followed by a convolutional layer with 64 filters, Group Normalization, ReLU activation, and max-pooling. The core of the model consists of four layers of residual blocks (similar to the standard ResNet18) with 64, 128, 256, and 512 filters. Each basic block within these layers contains two convolutional layers, Group Normalization, and ReLU activations. Finally, an adaptive average pooling layer reduces spatial dimensions to <math id="A1.SS3.SSS3.p1.1.m1.1" class="ltx_Math" alttext="1\times 1" display="inline"><semantics id="A1.SS3.SSS3.p1.1.m1.1a"><mrow id="A1.SS3.SSS3.p1.1.m1.1.1" xref="A1.SS3.SSS3.p1.1.m1.1.1.cmml"><mn id="A1.SS3.SSS3.p1.1.m1.1.1.2" xref="A1.SS3.SSS3.p1.1.m1.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="A1.SS3.SSS3.p1.1.m1.1.1.1" xref="A1.SS3.SSS3.p1.1.m1.1.1.1.cmml">×</mo><mn id="A1.SS3.SSS3.p1.1.m1.1.1.3" xref="A1.SS3.SSS3.p1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS3.p1.1.m1.1b"><apply id="A1.SS3.SSS3.p1.1.m1.1.1.cmml" xref="A1.SS3.SSS3.p1.1.m1.1.1"><times id="A1.SS3.SSS3.p1.1.m1.1.1.1.cmml" xref="A1.SS3.SSS3.p1.1.m1.1.1.1"></times><cn type="integer" id="A1.SS3.SSS3.p1.1.m1.1.1.2.cmml" xref="A1.SS3.SSS3.p1.1.m1.1.1.2">1</cn><cn type="integer" id="A1.SS3.SSS3.p1.1.m1.1.1.3.cmml" xref="A1.SS3.SSS3.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS3.p1.1.m1.1c">1\times 1</annotation></semantics></math>, followed by a fully connected layer to output class scores.</p>
</div>
</section>
<section id="A1.SS3.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.3.4 </span>VisDrone</h4>

<div id="A1.SS3.SSS4.p1" class="ltx_para">
<p id="A1.SS3.SSS4.p1.1" class="ltx_p">For VisDrone, we use the default YOLOv8n model from <a target="_blank" href="https://github.com/ultralytics/ultralytics" title="" class="ltx_ref ltx_href">Ultralytics library</a>. YOLOv8n is the smallest YOLOv8 model variant with the three scale parameters: depth, width, and the maximum number of channels set to 0.33, 0.25, and 1024 respectively.</p>
</div>
</section>
<section id="A1.SS3.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.3.5 </span>CASAS</h4>

<div id="A1.SS3.SSS5.p1" class="ltx_para">
<p id="A1.SS3.SSS5.p1.1" class="ltx_p">For CASAS, we use a BiLSTM neural network which is composed of an embedding layer, a bidirectional LSTM, and a fully connected layer. The embedding layer takes input sequences with dimensions equal to the input dimension and converts them to dense vectors of size 64. The bidirectional LSTM layer has an input size equal to 64, the same number of hidden units, and processes the embedded sequences in both forward and backward directions. The output of the LSTM layer is connected to a fully connected layer with an input size of 128 (to account for the bidirectional LSTM concatenation) and outputs the logits for 12 activities in the CASAS dataset.</p>
</div>
</section>
<section id="A1.SS3.SSS6" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.3.6 </span>AEP</h4>

<div id="A1.SS3.SSS6.p1" class="ltx_para">
<p id="A1.SS3.SSS6.p1.1" class="ltx_p">For AEP, we use a custom multi-layer perceptron (MLP) neural network with an architecture comprising five hidden layers and an output layer. The input layer accepts 18 features and passes them through a linear transformation to the first hidden layer with 210 units. Each of the following hidden layers progressively scales the number of units by factors of 2 and 4 and then scales down. Specifically, the sizes of the hidden layers are 210, 420, 840, 420, and 210 units respectively. Each hidden layer uses a ReLU activation function followed by a dropout layer with a dropout rate of 0.3 for regularization. The output layer has a single unit, and the output of the network is obtained by passing the activations of the last hidden layer through a final linear transformation.</p>
</div>
</section>
<section id="A1.SS3.SSS7" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.3.7 </span>EPIC-SOUNDS</h4>

<div id="A1.SS3.SSS7.p1" class="ltx_para">
<p id="A1.SS3.SSS7.p1.1" class="ltx_p">For EPIC-SOUNDS, we again use a custom ResNet-18 model which consists of a stack of convolutional layers followed by batch normalization and ReLU activation. The architecture begins with a <math id="A1.SS3.SSS7.p1.1.m1.1" class="ltx_Math" alttext="7\times 7" display="inline"><semantics id="A1.SS3.SSS7.p1.1.m1.1a"><mrow id="A1.SS3.SSS7.p1.1.m1.1.1" xref="A1.SS3.SSS7.p1.1.m1.1.1.cmml"><mn id="A1.SS3.SSS7.p1.1.m1.1.1.2" xref="A1.SS3.SSS7.p1.1.m1.1.1.2.cmml">7</mn><mo lspace="0.222em" rspace="0.222em" id="A1.SS3.SSS7.p1.1.m1.1.1.1" xref="A1.SS3.SSS7.p1.1.m1.1.1.1.cmml">×</mo><mn id="A1.SS3.SSS7.p1.1.m1.1.1.3" xref="A1.SS3.SSS7.p1.1.m1.1.1.3.cmml">7</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS7.p1.1.m1.1b"><apply id="A1.SS3.SSS7.p1.1.m1.1.1.cmml" xref="A1.SS3.SSS7.p1.1.m1.1.1"><times id="A1.SS3.SSS7.p1.1.m1.1.1.1.cmml" xref="A1.SS3.SSS7.p1.1.m1.1.1.1"></times><cn type="integer" id="A1.SS3.SSS7.p1.1.m1.1.1.2.cmml" xref="A1.SS3.SSS7.p1.1.m1.1.1.2">7</cn><cn type="integer" id="A1.SS3.SSS7.p1.1.m1.1.1.3.cmml" xref="A1.SS3.SSS7.p1.1.m1.1.1.3">7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS7.p1.1.m1.1c">7\times 7</annotation></semantics></math> convolutional layer with stride 2, followed by a max pooling layer. Then, it contains four blocks, each comprising a sequence of basic blocks with a residual connection; specifically, each block contains two basic blocks, with output channel sizes of 64, 128, 256, and 512 respectively. Each basic block comprises two sets of 3x3 convolutional layers, each followed by batch normalization and ReLU activation. The first convolutional layer in the basic block has a stride of 2 in the second, third, and fourth blocks. Finally, the model has an adaptive average pooling layer, which reduces the spatial dimensions to 1x1, followed by a fully connected layer with an output size of 44 classes.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</section>
</section>
</section>
</section>
</section>
</div>
</div>
</figure>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2310.00108" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2310.00109" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2310.00109">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2310.00109" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2310.00110" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Feb 28 03:27:36 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
