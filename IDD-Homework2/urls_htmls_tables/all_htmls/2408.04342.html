<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Towards Explainable Network Intrusion Detection using Large Language Models</title>
<!--Generated on Thu Aug  8 09:55:26 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2408.04342v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#S1" title="In Towards Explainable Network Intrusion Detection using Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#S2" title="In Towards Explainable Network Intrusion Detection using Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#S2.SS1" title="In 2. Related Work ‣ Towards Explainable Network Intrusion Detection using Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Malicious NetFlow Detection</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#S2.SS2" title="In 2. Related Work ‣ Towards Explainable Network Intrusion Detection using Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Explainable NIDS</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#S3" title="In Towards Explainable Network Intrusion Detection using Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#S3.SS1" title="In 3. Methodology ‣ Towards Explainable Network Intrusion Detection using Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Domain Specific Performance</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#S3.SS1.SSS0.Px1" title="In 3.1. Domain Specific Performance ‣ 3. Methodology ‣ Towards Explainable Network Intrusion Detection using Large Language Models"><span class="ltx_text ltx_ref_title">Zero-shot Learning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#S3.SS1.SSS0.Px2" title="In 3.1. Domain Specific Performance ‣ 3. Methodology ‣ Towards Explainable Network Intrusion Detection using Large Language Models"><span class="ltx_text ltx_ref_title">Fine-tuning</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#S3.SS2" title="In 3. Methodology ‣ Towards Explainable Network Intrusion Detection using Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Explainability</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#S3.SS3" title="In 3. Methodology ‣ Towards Explainable Network Intrusion Detection using Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Computational Complexity</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#S4" title="In Towards Explainable Network Intrusion Detection using Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Empirical Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#S4.SS1" title="In 4. Empirical Results ‣ Towards Explainable Network Intrusion Detection using Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Domain Specific Performance</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#S4.SS1.SSS0.Px1" title="In 4.1. Domain Specific Performance ‣ 4. Empirical Results ‣ Towards Explainable Network Intrusion Detection using Large Language Models"><span class="ltx_text ltx_ref_title">Zero-shot Learning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#S4.SS1.SSS0.Px2" title="In 4.1. Domain Specific Performance ‣ 4. Empirical Results ‣ Towards Explainable Network Intrusion Detection using Large Language Models"><span class="ltx_text ltx_ref_title">Fine-tuning</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#S4.SS2" title="In 4. Empirical Results ‣ Towards Explainable Network Intrusion Detection using Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Explainability</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#S4.SS3" title="In 4. Empirical Results ‣ Towards Explainable Network Intrusion Detection using Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Computational Complexity</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#S5" title="In Towards Explainable Network Intrusion Detection using Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Discussion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#S6" title="In Towards Explainable Network Intrusion Detection using Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Towards Explainable Network Intrusion Detection using Large Language Models</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Paul R. B. Houssel
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:p.houssel@uq.edu.au">p.houssel@uq.edu.au</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">The University of Queensland</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Priyanka Singh
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:priyanka.singh@uq.edu.au">priyanka.singh@uq.edu.au</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id2.1.id1">The University of Queensland</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Siamak Layeghy
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:siamak.layeghy@uq.net.au">siamak.layeghy@uq.net.au</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id3.1.id1">The University of Queensland</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Marius Portmann
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:marius@ieee.org">marius@ieee.org</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id4.1.id1">The University of Queensland</span>
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id5.id1">Large Language Models (LLMs) have revolutionised natural language processing tasks, particularly as chat agents. However, their applicability to threat detection problems remains unclear. This paper examines the feasibility of employing LLMs as a Network Intrusion Detection System (NIDS), despite their high computational requirements, primarily for the sake of explainability. Furthermore, considerable resources have been invested in developing LLMs, and they may offer utility for NIDS. Current state-of-the-art NIDS rely on artificial benchmarking datasets, resulting in skewed performance when applied to real-world networking environments. Therefore, we compare the <span class="ltx_text ltx_font_italic" id="id5.id1.1">GPT-4</span> and <span class="ltx_text ltx_font_italic" id="id5.id1.2">LLama3</span> models against traditional architectures and transformer-based models to assess their ability to detect malicious NetFlows without depending on artificially skewed datasets, but solely on their vast pre-trained acquired knowledge. Our results reveal that, although LLMs struggle with precise attack detection, they hold significant potential for a path towards explainable NIDS. Our preliminary exploration shows that LLMs are unfit for the detection of Malicious NetFlows. Most promisingly, however, these exhibit significant potential as complementary agents in NIDS, particularly in providing explanations and aiding in threat response when integrated with Retrieval Augmented Generation (RAG) and function calling capabilities.</p>
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>none</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span></span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_isbn" id="id3"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span></span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id4"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>;  2024</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id5"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>;</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Large Language Models (LLMs) have recently emerged as a transformative force in natural language processing, showcasing proficiency in handling unstructured data. With the ability to generate text and comprehend context, LLMs have found widespread application in various domains, ranging from conversational chat agents to code generation and translation tasks. Despite these advances, the application of LLMs to cybersecurity, particularly Network Intrusion Detection Systems (NIDS), remains largely unexplored.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">NIDS are critical for monitoring and analysing network traffic to detect malicious activities and security breaches. Existing NIDS employ a combination of signature-based and anomaly-based detection techniques. Signature-based methods rely on predefined patterns of known attacks, while anomaly-based methods identify deviations from established norms in network behaviour. Although deep learning-based NIDS have demonstrated near-perfect performance on benchmark datasets, their efficacy in real-world environments is often questioned due to the prevalence of synthetic and misrepresentative datasets used in academic research <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib1" title="">layeghy_benchmarking_2021, </a>)</cite>. Additionally, these models lack explainability <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib2" title="">neupane_explainable_2022, </a>)</cite>, making it difficult for security professionals to understand and trust their predictions and respond to the detected threat. It thus remains important to investigate if LLMs are a potential solution to these.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Several studies have used transformers and LLMs to directly detect threats or as complementary solutions for NIDS. However, no previous work has thoroughly investigated LLMs’ adaptivity to the domain of NetFlows. Previous studies replace LLM’s sequence-to-sequence layers with a classification head, thus losing the potential for using the same model to provide explanations. Using LLMs and their natural language output, both detection by classification and explainability can be achieved. It remains to be seen if performance is degraded when using these text prediction models as threat classifiers, a use case very different from their original design purpose. LLMs have shown the ability to analyse long-term dependencies and be adaptive to the applied domains <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib3" title="">xu_large_2024, </a>)</cite>. Furthermore, their pre-training on large amounts of natural language data might incorporate the knowledge required to detect malicious NetFlows without relying on skewed artificial datasets. This paper explores the capability of LLMs to detect network attacks based on network flows while contrasting their benefits and limitations with traditional Machine Learning (ML) solutions.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">We empirically assess the pre-trained OpenAI’s<span class="ltx_text ltx_font_italic" id="S1.p4.1.1">GPT-4</span> and Meta’s<span class="ltx_text ltx_font_italic" id="S1.p4.1.2">LLama3</span> models, in the context of zero-shot learning and fine-tuning on standardised NetFlow datasets. Our initial experiments investigate the performance capabilities of LLMs to detect threats, a trait which traditional more lightweight ML solutions have already been proven to possess with near perfection <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib4" title="">sarhan_netflow_2021, </a>)</cite>. We will evaluate our model variants on the <span class="ltx_text ltx_font_italic" id="S1.p4.1.3">NF-UNSW-NB15-v2</span> and <span class="ltx_text ltx_font_italic" id="S1.p4.1.4">NF-CSE-CIC-IDS2018-v2</span> datasets <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib5" title="">sarhan_towards_2022, </a>)</cite>. Finally, we investigate the capacity to explain the detection of threats and their computational cost of inference to fuel a discussion on the advantages and drawbacks of using LLMs for NIDS versus more lightweight solutions incorporating LLMs as a complementary solution to existing NIDS.
Our findings aim to provide a first exploratory evaluation of LLMs in the context of NIDS, offering insights into potential future research directions and use cases. We do not aim for a comprehensive benchmark of models and parameters of LLMs for detecting malicious NetFlows.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related Work</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Malicious NetFlow Detection</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">In contrast to NIDS, Host-based Intrusion Detection Systems (HIDS) typically deal with textual data such as system calls, logs, or application and memory traces. Natural Language Processing (NLP) techniques are employed to examine the semantic interactions and sequences of system calls and contextual data, enabling the effective identification of suspicious activities. This facilitates precise, real-time intrusion detection by analysing text data streams. Many solutions relying on NLP have been developed even before the advent of LLMs <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib6" title="">sworna_nlp_2022, </a>)</cite>. Natural language is less present in the NIDS domain, but surprisingly more literature exists.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">For detection based on network traffic, the application of LLMs has started to gain traction, although the solutions often modify the standard LLM architecture. Specifically, these models typically strip the sequence-to-sequence head and replace it with a classification head to obtain a deterministic output to evaluate the model. The initial textual output head, which predicts the next textual token, is replaced by a classification head vector which has a dimension equivalent to the number of prediction classes, <span class="ltx_text ltx_font_italic" id="S2.SS1.p2.1.1">e.g</span> two for a binary classification. Lira et al. <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib7" title="">g_lira_harnessing_2024, </a>)</cite> investigated the capabilities of LLMs such as <span class="ltx_text ltx_font_italic" id="S2.SS1.p2.1.2">GPT-3.5</span>, <span class="ltx_text ltx_font_italic" id="S2.SS1.p2.1.3">GPT-4</span>, and <span class="ltx_text ltx_font_italic" id="S2.SS1.p2.1.4">ADA</span> to detect Distributed Denial of Service (DDoS) attacks on the <span class="ltx_text ltx_font_italic" id="S2.SS1.p2.1.5">CICIDS2017</span> <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib8" title="">sharafaldin_toward_2018, </a>)</cite> and <span class="ltx_text ltx_font_italic" id="S2.SS1.p2.1.6">Urban IoT</span> <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib9" title="">hekmati_correlation-aware_2023, </a>)</cite> datasets. Their findings indicate that LLMs, when fine-tuned or employed in few-shot learning scenarios, could detect DDoS attacks with significant accuracy proving their adaptivity trait. Manocchio et al. <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib10" title="">manocchio_flowtransformer_2024, </a>)</cite> explored various encoding and classification methods on different transformer architectures, including <span class="ltx_text ltx_font_italic" id="S2.SS1.p2.1.7">GPT</span>’s and <span class="ltx_text ltx_font_italic" id="S2.SS1.p2.1.8">BERT</span>’s to enhance network analysis. Ferrag et al. <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib11" title="">ferrag_revolutionizing_2024, </a>)</cite> used <span class="ltx_text ltx_font_italic" id="S2.SS1.p2.1.9">BERT</span> for threat detection in Internet of Things (IoT) networks, outperforming existing ML solutions by distinguishing between 14 attack classes and benign traffic using <span class="ltx_text ltx_font_italic" id="S2.SS1.p2.1.10">PCAP</span> files. Alkhatib et al. <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib12" title="">alkhatib_can-bert_2022, </a>)</cite> explored the usage of <span class="ltx_text ltx_font_italic" id="S2.SS1.p2.1.11">BERT</span> for detecting threats on Controller Area Networks (CAN), showcasing the model’s versatility across different cybersecurity applications. Among these, Chen et al. <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib13" title="">guastalla_application_2024, </a>)</cite> is the only study which employed LLMs, which are pre-trained on natural language and possess a sequence-to-sequence head producing sequences of natural text tokens, to detect DDoS attacks by fine-tuning <span class="ltx_text ltx_font_italic" id="S2.SS1.p2.1.12">BERT</span>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Explainable NIDS</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Studies aiming to render NIDS explainable typically employ existing explainable AI methods. These methods assign an importance factor to each input feature, indicating their influence on the model’s output label <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib2" title="">neupane_explainable_2022, </a>)</cite>. For instance, Mallampati et al. <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib14" title="">mallampati_enhancing_2024, </a>)</cite>, Senevirathna et al. <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib15" title="">senevirathna_deceiving_2024, </a>)</cite>, and Zebin et al. <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib16" title="">zebin_explainable_2022, </a>)</cite> utilise the SHapley Additive exPlanation (SHAP) method across various network domains. This approach expresses explainability as the weight of each feature and its impact on the output class, enabling the development of algorithms to respond to threats in real time. Wei et al. <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib17" title="">wei_xnids_2023, </a>)</cite> propose a framework that leverages this feature’s importance to design rules for active intrusion responses. Their XNIDS framework identifies features critical to the prediction class and generates actionable defence rules, which aid in understanding DL-NIDS behaviours and troubleshooting detection errors.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">LLMs could potentially provide natural language explanations for human operators, not only limiting the explanations to features which statistically appear anomalous to the NIDS. This will allow to facilitate threat response and a better understanding of their NIDS functionality or potential malfunctioning. In this study, we further investigate the capability of LLMs to detect malicious NetFlows while explaining their reasoning. These could potentially be employed as a complementary solution, aiming to enhance the explainability of NIDS.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Methodology</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">This section outlines the methodology employed to investigate the potential of LLMs for NIDS. Our approach is based on the open-source <span class="ltx_text ltx_font_italic" id="S3.p1.1.1">LLama3-8B-Instruct</span> and <span class="ltx_text ltx_font_italic" id="S3.p1.1.2">GPT-4</span> model, designed to better handle instruction-based tasks compared to the foundational model. In contrast with foundational model’s difficulties in answering in the required format, as it was not trained to understand instructions but simply to predict sequences of words. We focus on the network traffic under the format of flows, which are currently the most prominent and efficient source of network telemetry for threat detection due to their scalability <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib1" title="">layeghy_benchmarking_2021, </a>)</cite>. They summarise network traffic which shares destination and source port and IP addresses by aggregating packets into flows, making them ideal for detecting patterns indicative of malicious activities. Sarhan et al. <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib5" title="">sarhan_towards_2022, </a>)</cite> proposes a set of standardised NetFlow datasets, with a common set of overlapping features, to address the limited ability to evaluate ML-based NIDS across different network environments and attack scenarios. Among these, we solely consider the datasets outside of the IoT domain: <span class="ltx_text ltx_font_italic" id="S3.p1.1.3">NF-UNSW-NB15-v2</span> and <span class="ltx_text ltx_font_italic" id="S3.p1.1.4">NF-CSE-CIC-IDS2018-v2</span>.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Domain Specific Performance</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">To measure the performance on specific network environments, we built two baseline models using the <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.1">LLama3-8B-Instruct</span> and <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.2">GPT-4-0613</span> model by applying the zero-shot learning paradigm. Additionally, we will investigate two fine-tuning methods only on the <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.3">LLama3</span> model due to the inherited cost associated with fine-tuning using the <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.4">OpenAI</span> API. For this series of experiments, all datasets are split into training and testing sets with a 95% to 5% ratio while stratifying the attack type. All evaluations are performed following a 10-fold cross-validation method. We only consider a small testing set due to the sheer computational cost of LLM inference. All prediction results from our experiments are evaluated using the macro average of Precision and Recall for both the benign and malicious classes. The macro average is the unweighted sum of the individual performance scores for each class, representing each class equally. We provide the pre-trained LLM with an instruction to detect network attacks based on NetFlows, requesting it to output either <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.5">”1”</span> or <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.6">”0”</span> to indicate whether the provided flow is malicious or benign. After ingesting the instruction prompt, the model will take as an input a tabular NetFlow entry encoded as text using key-value pairs separated by commas to represent the feature name and value pairs. For instance, a network flow originally represented as a row within the CSV table of the dataset is transformed into text as follows: ”<span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.7">L4_DST_PORT: 80</span>”. To ensure consistency and reduce variability in outputs, we set the model’s temperature parameter to <math alttext="10^{-1}" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><msup id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mn id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">10</mn><mrow id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml"><mo id="S3.SS1.p1.1.m1.1.1.3a" xref="S3.SS1.p1.1.m1.1.1.3.cmml">−</mo><mn id="S3.SS1.p1.1.m1.1.1.3.2" xref="S3.SS1.p1.1.m1.1.1.3.2.cmml">1</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">superscript</csymbol><cn id="S3.SS1.p1.1.m1.1.1.2.cmml" type="integer" xref="S3.SS1.p1.1.m1.1.1.2">10</cn><apply id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3"><minus id="S3.SS1.p1.1.m1.1.1.3.1.cmml" xref="S3.SS1.p1.1.m1.1.1.3"></minus><cn id="S3.SS1.p1.1.m1.1.1.3.2.cmml" type="integer" xref="S3.SS1.p1.1.m1.1.1.3.2">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">10^{-1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">10 start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT</annotation></semantics></math>. The temperature parameter, ranging from 0 to 1, influences the probabilities generated by the softmax output function. A low-temperature setting makes the model’s outputs more deterministic by prioritising the most likely tokens, important for binary classification tasks <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib18" title="">minaee_large_2024, </a>)</cite>. Together with prompt engineering, it allows us to constrain the response of the model to a binary output without any exceptions.</p>
</div>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Zero-shot Learning</h4>
<div class="ltx_para" id="S3.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS1.SSS0.Px1.p1.1">Zero-shot learning consists of a pre-trained model tasked with making predictions on yet explicitly unseen data. In the context of a pre-trained LLM, zero-shot learning leverages the knowledge and understanding embedded in the model from its training on a vast amount of natural language. When applied to zero-shot learning, the LLM can make informed predictions to identify malicious network traffic by understanding the provided instructions and applying its broad contextual knowledge to classify the traffic as either malicious or benign, even though it hasn’t been specifically trained on labelled examples of network attacks.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Fine-tuning</h4>
<div class="ltx_para" id="S3.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS1.SSS0.Px2.p1.1">Fine-tuning LLMs for specific tasks is a crucial step to enhance their performance and adapt them to domain-specific requirements. In our investigation, we focus on two state-of-the-art fine-tuning methods: Odds Ratio Preference Optimisation (ORPO) <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib19" title="">hong_orpo_2024, </a>)</cite> and Kahneman-Tversky Optimisation (KTO) <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib20" title="">ethayarajh_kto_2024, </a>)</cite>. These methods have shown significant promise and represent the current state of the art <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib18" title="">minaee_large_2024, </a>)</cite>. ORPO <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib19" title="">hong_orpo_2024, </a>)</cite>, requires preference data in the format of prompts paired with rejected and accepted answers. For the task of NIDS binary classification, we can adapt these methods by treating the true label as the accepted prompt and the inverse of the label as the rejected prompt. In contrast, KTO <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib20" title="">ethayarajh_kto_2024, </a>)</cite> does not require paired preference data and instead relies on a series of prompts and corresponding responses along with a series of binary labels indicating wherever the provided response is relevant. In our case, we use the true label as the accepted response. Half of the prompts are randomly sampled with relevant responses using the label and the other half are samples as irrelevant by using the inverse of the label.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Explainability</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">To investigate and grasp the LLM’s ability to explain the reasons for predicting a network flow as benign or malicious, we manually analyse the models’ responses to find patterns and inconsistencies. More specifically, we analysed the explanations provided by our baseline model for the cases of True Positives (TP), False Positives (FP), True Negatives (TN), and False Negatives (FN) samples, as these will offer variability in answering. This analysis is not a quantitative evaluation of the quality of explanations but serves as an initial exploration to assess the importance of future research into making LLMs explainable for NIDS.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Computational Complexity</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">To assess the computational cost, we compared our baseline with the most common architectures with the default parameters, used in related work and industrial application of NIDS. All experiments were conducted on a machine equipped with an NVIDIA RTX3090 GPU and a 3.50 GHz CPU. The measured time for sequential inference corresponds to the average time taken to predict a single NetFlow sample. This time was measured by calculating the average time to predict a single sample when processing the entire testing set as a batch, computing the average over 10 runs.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Empirical Results</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Domain Specific Performance</h3>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Zero-shot Learning</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.1">The results of these empirical experiments under the zero-shot evaluation (Table <a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#S4.T1" title="Table 1 ‣ Zero-shot Learning ‣ 4.1. Domain Specific Performance ‣ 4. Empirical Results ‣ Towards Explainable Network Intrusion Detection using Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#S4.T2" title="Table 2 ‣ Zero-shot Learning ‣ 4.1. Domain Specific Performance ‣ 4. Empirical Results ‣ Towards Explainable Network Intrusion Detection using Large Language Models"><span class="ltx_text ltx_ref_tag">2</span></a>) reveal several important insights. Unsurprisingly, the performance of the pre-trained <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS0.Px1.p1.1.1">LLama3</span> model is worse than random selection, which would have been, considering the macro average, 50% for all metrics, while <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS0.Px1.p1.1.2">GPT-4</span> is slightly better. This outcome is expected because pre-trained LLMs are primarily designed for natural language tasks and not for the specific task of network classification. In contrast, classical ML models demonstrate near-perfect performance. For instance, on the <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS0.Px1.p1.1.3">NF-UNSW-NB15-v2</span> dataset, a Random Forest and an LSTM neural network respectively achieve a weighted F1-score of 92.17% and 92.82% <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib21" title="">layeghy_explainable_2023, </a>)</cite> while a <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS0.Px1.p1.1.4">DANN</span> model achieves 97.81% <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib22" title="">layeghy_di-nids_2023, </a>)</cite>.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T1.4.1.1" style="font-size:90%;">Table 1</span>. </span><span class="ltx_text" id="S4.T1.5.2" style="font-size:90%;">Domain-specific zero-shot performance of the model on the <span class="ltx_text ltx_font_italic" id="S4.T1.5.2.1">NF-UNSW-NB15-v2</span> dataset.</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.1.1">
<td class="ltx_td ltx_align_center ltx_border_tt ltx_border_t" id="S4.T1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.2.1">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt ltx_border_t" colspan="2" id="S4.T1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.1">Macro Avg. Perf. Metrics<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.1.1.1.1.m1.1"><semantics id="S4.T1.1.1.1.1.m1.1a"><mo id="S4.T1.1.1.1.1.m1.1.1" stretchy="false" xref="S4.T1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.1.1.1.1.m1.1d">↑</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.2.1">
<td class="ltx_td" id="S4.T1.1.2.1.1"></td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.2.1.2">Precision</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.2.1.3">Recall</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.3.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.3.2.1"><span class="ltx_text ltx_font_italic" id="S4.T1.1.3.2.1.1">LLama3-8b-Instruct</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.3.2.2">48.56%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.3.2.3">40.56%</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.4.3">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.1.4.3.1"><span class="ltx_text ltx_font_italic" id="S4.T1.1.4.3.1.1">GPT-4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.1.4.3.2">50.85%</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T1.1.4.3.3">53.47%</td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T2.4.1.1" style="font-size:90%;">Table 2</span>. </span><span class="ltx_text" id="S4.T2.5.2" style="font-size:90%;">Domain specific zero-shot performance on the <span class="ltx_text ltx_font_italic" id="S4.T2.5.2.1">NF-CSE-CIC-IDS2018-v2</span> dataset.</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T2.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.1.1">
<td class="ltx_td ltx_align_center ltx_border_tt ltx_border_t" id="S4.T2.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.2.1">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt ltx_border_t" colspan="2" id="S4.T2.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1">Macro Avg. Perf. Metrics<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T2.1.1.1.1.m1.1"><semantics id="S4.T2.1.1.1.1.m1.1a"><mo id="S4.T2.1.1.1.1.m1.1.1" stretchy="false" xref="S4.T2.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.m1.1b"><ci id="S4.T2.1.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.1.1.1.1.m1.1d">↑</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.2.1">
<td class="ltx_td" id="S4.T2.1.2.1.1"></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.2.1.2">Precision</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.2.1.3">Recall</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.3.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.3.2.1"><span class="ltx_text ltx_font_italic" id="S4.T2.1.3.2.1.1">LLama3-8b-Instruct</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.3.2.2">49.66%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.3.2.3">49.73%</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.4.3">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.1.4.3.1"><span class="ltx_text ltx_font_italic" id="S4.T2.1.4.3.1.1">GPT-4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.1.4.3.2">50.25%</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.1.4.3.3">51.02%</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Fine-tuning</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p1.1">In comparison to the zero-shot learning results, both fine-tuning methods showed slight improvements but still failed to significantly outperform random selection or approach the performance of related works (Table. <a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#S4.T3" title="Table 3 ‣ Fine-tuning ‣ 4.1. Domain Specific Performance ‣ 4. Empirical Results ‣ Towards Explainable Network Intrusion Detection using Large Language Models"><span class="ltx_text ltx_ref_tag">3</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#S4.T4" title="Table 4 ‣ Fine-tuning ‣ 4.1. Domain Specific Performance ‣ 4. Empirical Results ‣ Towards Explainable Network Intrusion Detection using Large Language Models"><span class="ltx_text ltx_ref_tag">4</span></a>). Overall, <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS0.Px2.p1.1.1">KTO</span> performed slightly better, indicating that the choice of fine-tuning method is an important parameter for future research. We see that fine-tuning can enhance performance with increased training, but the improvements observed were minimal. Fine-tuning tends to adjust the model’s responses to fit a desired style but is insufficient to significantly alter the weights for the binary classification of network attacks. Pre-trained natural language models, which are trained on extensive natural language corpora, may not be capable of recognising the subtle patterns that indicate malicious NetFlows. They are more adept at generating appropriate responses to natural language queries without any further deep understanding.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS0.Px2.p2">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p2.1">Fine-tuning LLMs for detecting malicious NetFlows is unnecessary; instead, transformer-based models can be trained directly on entire datasets. Manocchio et al., through their proposed <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS0.Px2.p2.1.1">FlowTransformer</span> framework <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib10" title="">manocchio_flowtransformer_2024, </a>)</cite>, have shown that transformer architectures perform well on binary NetFlow classification tasks when trained on complete datasets. This performance is achieved without the need pre-training on natural language datasets. For instance, their model, using GPT’s architecture achieves an 89.98% F1-score.</p>
</div>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T3.5.1.1" style="font-size:90%;">Table 3</span>. </span><span class="ltx_text" id="S4.T3.6.2" style="font-size:90%;">Domain specific performance of the <span class="ltx_text ltx_font_italic" id="S4.T3.6.2.1">LLama3-8b-Instruct</span> model on the <span class="ltx_text ltx_font_italic" id="S4.T3.6.2.2">NF-UNSW-NB15-v2</span> dataset.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T3.1" style="width:216.8pt;height:141.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-15.7pt,10.2pt) scale(0.873840838000034,0.873840838000034) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T3.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt ltx_border_t" id="S4.T3.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.2.1">Learning</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_t" id="S4.T3.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.3.1"># Training</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_t" colspan="2" id="S4.T3.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.1">Macro Avg. Perf. Metrics<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T3.1.1.1.1.1.m1.1"><semantics id="S4.T3.1.1.1.1.1.m1.1a"><mo id="S4.T3.1.1.1.1.1.m1.1.1" stretchy="false" xref="S4.T3.1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.1.1.m1.1b"><ci id="S4.T3.1.1.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.1.1.1.1.1.m1.1d">↑</annotation></semantics></math></span></th>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row" id="S4.T3.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.2.1.1.1">Paradigm</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.1.1.2.1.2"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.2.1.2.1">Samples</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.1.1.2.1.3">Precision</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.1.1.2.1.4">Recall</th>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.3.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S4.T3.1.1.3.2.1">zero-shot</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.1.1.3.2.2">0</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.1.1.3.2.3">48.56%</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.1.1.3.2.4">40.56%</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.1.1.4.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T3.1.1.4.1.1" rowspan="3"><span class="ltx_text" id="S4.T3.1.1.4.1.1.1"><span class="ltx_text ltx_font_italic" id="S4.T3.1.1.4.1.1.1.1">KTO</span> Finetuned</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.4.1.2">1,000</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.4.1.3">52.69%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.4.1.4">50.22%</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.5.2">
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.2.1">10,000</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.2.2">53.98%</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.2.3">50.36%</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.6.3">
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.6.3.1">50,000</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.6.3.2">55.18%</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.6.3.3">51.67%</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.7.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S4.T3.1.1.7.4.1" rowspan="3"><span class="ltx_text" id="S4.T3.1.1.7.4.1.1"><span class="ltx_text ltx_font_italic" id="S4.T3.1.1.7.4.1.1.1">ORPO</span> Finetuned</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.7.4.2">1,000</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.7.4.3">48.88%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.7.4.4">40.76%</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.8.5">
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.8.5.1">10,000</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.8.5.2">49.25%</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.8.5.3">42.40%</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.9.6">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.1.9.6.1">50,000</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.1.9.6.2">52.00%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.1.9.6.3">43.50%</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="S4.T4">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T4.5.1.1" style="font-size:90%;">Table 4</span>. </span><span class="ltx_text" id="S4.T4.6.2" style="font-size:90%;">Domain specific performance of the <span class="ltx_text ltx_font_italic" id="S4.T4.6.2.1">LLama3-8b-Instruct</span> model on the <span class="ltx_text ltx_font_italic" id="S4.T4.6.2.2">NF-CSE-CIC-IDS2018-v2</span> dataset.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T4.1" style="width:216.8pt;height:141.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-15.7pt,10.2pt) scale(0.873840838000034,0.873840838000034) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T4.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T4.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt ltx_border_t" id="S4.T4.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T4.1.1.1.2.1">Learning</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_t" id="S4.T4.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T4.1.1.1.3.1"># Training</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_t" colspan="2" id="S4.T4.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T4.1.1.1.1.1">Macro Avg. Perf. Metrics<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T4.1.1.1.1.1.m1.1"><semantics id="S4.T4.1.1.1.1.1.m1.1a"><mo id="S4.T4.1.1.1.1.1.m1.1.1" stretchy="false" xref="S4.T4.1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.1.1.m1.1b"><ci id="S4.T4.1.1.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T4.1.1.1.1.1.m1.1d">↑</annotation></semantics></math></span></th>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row" id="S4.T4.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="S4.T4.1.1.2.1.1.1">Paradigm</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T4.1.1.2.1.2"><span class="ltx_text ltx_font_bold" id="S4.T4.1.1.2.1.2.1">Samples</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T4.1.1.2.1.3">Precision</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T4.1.1.2.1.4">Recall</th>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1.3.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S4.T4.1.1.3.2.1">zero-shot</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.1.1.3.2.2">0</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.1.1.3.2.3">49.66%</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.1.1.3.2.4">49.73%</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.1.1.4.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T4.1.1.4.1.1" rowspan="3"><span class="ltx_text" id="S4.T4.1.1.4.1.1.1"><span class="ltx_text ltx_font_italic" id="S4.T4.1.1.4.1.1.1.1">KTO</span> Finetuned</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.4.1.2">1,000</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.4.1.3">50.02%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.4.1.4">50.09%</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1.5.2">
<td class="ltx_td ltx_align_center" id="S4.T4.1.1.5.2.1">10,000</td>
<td class="ltx_td ltx_align_center" id="S4.T4.1.1.5.2.2">52.22%</td>
<td class="ltx_td ltx_align_center" id="S4.T4.1.1.5.2.3">55.13%</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1.6.3">
<td class="ltx_td ltx_align_center" id="S4.T4.1.1.6.3.1">50,000</td>
<td class="ltx_td ltx_align_center" id="S4.T4.1.1.6.3.2">55.02%</td>
<td class="ltx_td ltx_align_center" id="S4.T4.1.1.6.3.3">58.79%</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1.7.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S4.T4.1.1.7.4.1" rowspan="3"><span class="ltx_text" id="S4.T4.1.1.7.4.1.1"><span class="ltx_text ltx_font_italic" id="S4.T4.1.1.7.4.1.1.1">ORPO</span> Finetuned</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.7.4.2">1,000</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.7.4.3">50.43%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.7.4.4">50.95%</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1.8.5">
<td class="ltx_td ltx_align_center" id="S4.T4.1.1.8.5.1">10,000</td>
<td class="ltx_td ltx_align_center" id="S4.T4.1.1.8.5.2">50.89%</td>
<td class="ltx_td ltx_align_center" id="S4.T4.1.1.8.5.3">51.01%</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1.9.6">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.1.1.9.6.1">50,000</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.1.1.9.6.2">53.60%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.1.1.9.6.3">51.58%</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Explainability</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">The analysis of LLama3 generated explanations for various
prediction cases reveal unique benefits and notable limitations
to enrich future NIDS applications with explainability,
a unique feature proper to LLMs. These sample prompts
demonstrate that LLMs can provide detailed and contextually
relevant explanations for their classifications of network flows
but with notable limitations.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">When asked about a TN sample (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#S4.F1" title="Figure 1 ‣ 4.2. Explainability ‣ 4. Empirical Results ‣ Towards Explainable Network Intrusion Detection using Large Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>), the model correctly identifies the network flow as a DNS query. However, it inaccurately claims the source IP address is from China, whereas it is actually from Japan, and misidentifies the destination address as being in the USA, although it belongs to the University of New South Wales (UNSW), the dataset’s creator. Despite these errors, the LLM correctly identifies the byte size range of all packets in the flow as typical for a DNS query. These inaccuracies highlight the LLM’s tendency to hallucinate or generate incorrect information, particularly regarding geographical locations.</p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">On a TP case, the LLM mistakenly states that protocol 139 corresponds to the <span class="ltx_text ltx_font_italic" id="S4.SS2.p3.1.1">NetBIOS</span> protocol, whereas it corresponds to the <span class="ltx_text ltx_font_italic" id="S4.SS2.p3.1.2">Host Identity Protocol</span>. Its confusion is evident as NetBIOS uses port 139. Most importantly, it operates at Layer 5, while the <span class="ltx_text ltx_font_italic" id="S4.SS2.p3.1.3">protocol</span> feature identifies those of Layer 4. Additionally, the LLM incorrectly assumes that the use of ports with the value 0 indicates malicious activity. While unusual, ports set to 0 can occur in protocols not using port numbers, like <span class="ltx_text ltx_font_italic" id="S4.SS2.p3.1.4">ICMP</span>. These errors show that the LLM has gaps in its understanding of protocol specifics and port usage, leading to incorrect conclusions about malicious behaviour.</p>
</div>
<div class="ltx_para" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.1">In the FP scenario, unusual patterns, such as atypical ports and large file transfers are identified leading to the conclusion that these imply maliciousness. While the reasoning is plausible, it cannot correlate these features to specific attack signatures accurately.</p>
</div>
<div class="ltx_para" id="S4.SS2.p5">
<p class="ltx_p" id="S4.SS2.p5.1">For the FN sample, the model’s explanation is mostly consistent. However, it incorrectly identifies the main Layer 7 protocol user and mistakenly states that Layer 7 protocol number 7 corresponds to HTTP when it indicates the Internet Printing Protocol (IPP). The model classifies the network flow as benign due to small packet lengths and a low number of retransmitted packets, correctly identifying the traffic as typical HTTP traffic. While the model can accurately explain benign traffic by recognising common patterns, it fails to identify the malicious aspects of the sample.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p6">
<svg class="ltx_picture" height="139.64" id="S4.SS2.p6.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,139.64) matrix(1 0 0 -1 0 0)"><g fill="#0000BF" fill-opacity="1.0"><path d="M 0 5.91 L 0 133.73 C 0 136.99 2.64 139.64 5.91 139.64 L 594.09 139.64 C 597.36 139.64 600 136.99 600 133.73 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2FF" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 133.73 C 1.97 135.91 3.73 137.67 5.91 137.67 L 594.09 137.67 C 596.27 137.67 598.03 135.91 598.03 133.73 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="112.08" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S4.SS2.p6.pic1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_itemize" id="S4.I1">
<span class="ltx_item" id="S4.I1.i1" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S4.I1.i1.p1">
<span class="ltx_p" id="S4.I1.i1.p1.1"><span class="ltx_text" id="S4.I1.i1.p1.1.1" style="font-size:90%;">Protocol: The protocol used is UDP (17), which is commonly used for DNS queries. This suggests that the flow may be related to a legitimate DNS request.</span></span>
</span></span>
<span class="ltx_item" id="S4.I1.i2" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S4.I1.i2.p1">
<span class="ltx_p" id="S4.I1.i2.p1.1"><span class="ltx_text" id="S4.I1.i2.p1.1.1" style="font-size:90%;">Destination port: The destination port is 53, which is the standard port for DNS traffic.</span></span>
</span></span>
<span class="ltx_item" id="S4.I1.i3" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S4.I1.i3.p1">
<span class="ltx_p" id="S4.I1.i3.p1.1"><span class="ltx_text" id="S4.I1.i3.p1.1.1" style="font-size:90%;">Source and destination addresses: The source address is an IP address in China, while the destination address is an IP address in the United States. This could indicate that the flow is related to a legitimate DNS query from a Chinese user to a US-based DNS server.</span></span>
</span></span>
<span class="ltx_item" id="S4.I1.i4" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S4.I1.i4.p1">
<span class="ltx_p" id="S4.I1.i4.p1.1"><span class="ltx_text" id="S4.I1.i4.p1.1.1" style="font-size:90%;">Packet sizes and lengths: The packet sizes are relatively small (73-89 bytes), which is typical for DNS.</span></span>
</span></span>
<span class="ltx_item" id="S4.I1.i5" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S4.I1.i5.p1">
<span class="ltx_p" id="S4.I1.i5.p1.1"><span class="ltx_text" id="S4.I1.i5.p1.1.1" style="font-size:90%;">Flow duration: The flow duration is 0 milliseconds, indicating that this was likely a single, brief request-response exchange.</span></span>
</span></span>
</span>
</span></foreignobject></g></g></svg>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p7">
<div class="ltx_logical-block ltx_minipage ltx_align_middle" id="S4.SS2.p7.1" style="width:203.8pt;">
<figure class="ltx_figure" id="S4.F1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F1.2.1.1" style="font-size:90%;">Figure 1</span>. </span><span class="ltx_text" id="S4.F1.3.2" style="font-size:90%;">Explanation provided for a True Negative NetFlow.</span></figcaption>
</figure>
</div>
</div>
<div class="ltx_para" id="S4.SS2.p8">
<p class="ltx_p" id="S4.SS2.p8.1">Overall, from these manual experiments, we learned that LLM’s explanations are convincing and correctly retrieve information from the NetFlow data, being consistent with the presented features. However, they often fail to reason logically and augment the information with factual accuracy. The LLM tends to puzzle feature values together to identify traffic types (e.g., <span class="ltx_text ltx_font_italic" id="S4.SS2.p8.1.1">HTTP</span> traffic, <span class="ltx_text ltx_font_italic" id="S4.SS2.p8.1.2">DNS</span> queries) effectively, which can be useful for network operators. However, it struggles to correlate multiple features to identify attack signatures accurately, instead treating individual suspicious features as independent clues of malicious activity. One significant problem is their tendency to generate nonsensical or unfaithful content, known as “hallucination“ <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib18" title="">minaee_large_2024, </a>)</cite>. These models lack a true comprehension of facts or logical reasoning, relying on learned patterns of word succession within context. This is even more evident in further prompts. When questioned about the units of measurement used in network flows, the LLM failed to provide a coherent answer. When provided with a malformed NetFlow, the LLM was unable to determine its soundness. Additionally, the LLM failed to explain a SYN flood attack, a straightforward task for signature-based detectors like <span class="ltx_text ltx_font_italic" id="S4.SS2.p8.1.3">Cisco Snort</span>.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Computational Complexity</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">The feasibility of using LLMs for NIDS not only relies on detection performance but as importantly on inference time. Given that NIDS must handle hundreds, if not thousands, of NetFlows per second, these models must keep up with the network traffic and be able to report incidents promptly. Delays in inference can result in missed or late alerts, compromising network security.</p>
</div>
<figure class="ltx_table" id="S4.T5">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T5.3.1.1" style="font-size:90%;">Table 5</span>. </span><span class="ltx_text" id="S4.T5.4.2" style="font-size:90%;">Complexity of benchmarked model compared to traditional NIDS architectures.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T5.1" style="width:208.1pt;height:45.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-145.3pt,31.5pt) scale(0.417301455377397,0.417301455377397) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T5.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T5.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_t" id="S4.T5.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T5.1.1.1.2.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_t" id="S4.T5.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T5.1.1.1.1.1">Inference Time (<math alttext="\mu s" class="ltx_Math" display="inline" id="S4.T5.1.1.1.1.1.m1.1"><semantics id="S4.T5.1.1.1.1.1.m1.1a"><mrow id="S4.T5.1.1.1.1.1.m1.1.1" xref="S4.T5.1.1.1.1.1.m1.1.1.cmml"><mi id="S4.T5.1.1.1.1.1.m1.1.1.2" xref="S4.T5.1.1.1.1.1.m1.1.1.2.cmml">μ</mi><mo id="S4.T5.1.1.1.1.1.m1.1.1.1" xref="S4.T5.1.1.1.1.1.m1.1.1.1.cmml">⁢</mo><mi id="S4.T5.1.1.1.1.1.m1.1.1.3" xref="S4.T5.1.1.1.1.1.m1.1.1.3.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.1.1.1.1.1.m1.1b"><apply id="S4.T5.1.1.1.1.1.m1.1.1.cmml" xref="S4.T5.1.1.1.1.1.m1.1.1"><times id="S4.T5.1.1.1.1.1.m1.1.1.1.cmml" xref="S4.T5.1.1.1.1.1.m1.1.1.1"></times><ci id="S4.T5.1.1.1.1.1.m1.1.1.2.cmml" xref="S4.T5.1.1.1.1.1.m1.1.1.2">𝜇</ci><ci id="S4.T5.1.1.1.1.1.m1.1.1.3.cmml" xref="S4.T5.1.1.1.1.1.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.1.1.1.1.1.m1.1c">\mu s</annotation><annotation encoding="application/x-llamapun" id="S4.T5.1.1.1.1.1.m1.1d">italic_μ italic_s</annotation></semantics></math>)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_t" id="S4.T5.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T5.1.1.1.3.1">#Parameters</span></th>
</tr>
<tr class="ltx_tr" id="S4.T5.1.1.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T5.1.1.2.1.1"><span class="ltx_text ltx_font_italic" id="S4.T5.1.1.2.1.1.1">LLama3-8B-Instruct</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T5.1.1.2.1.2">14,000.01</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T5.1.1.2.1.3">8,030,000,000</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T5.1.1.3.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.1.3.1.1">Random Forest</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.1.3.1.2">2.03</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.1.3.1.3">867,614 (nodes)</td>
</tr>
<tr class="ltx_tr" id="S4.T5.1.1.4.2">
<td class="ltx_td ltx_align_center" id="S4.T5.1.1.4.2.1">Decision Tree <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib23" title="">manocchio_network_2022, </a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.1.4.2.2">1.53</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.1.4.2.3">–</td>
</tr>
<tr class="ltx_tr" id="S4.T5.1.1.5.3">
<td class="ltx_td ltx_align_center" id="S4.T5.1.1.5.3.1">LSTM NN</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.1.5.3.2">25.02</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.1.5.3.3">56,555</td>
</tr>
<tr class="ltx_tr" id="S4.T5.1.1.6.4">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.1.1.6.4.1">DANN</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.1.1.6.4.2">28.40</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.1.1.6.4.3">67,208</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">Our comparison in Table. <a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#S4.T5" title="Table 5 ‣ 4.3. Computational Complexity ‣ 4. Empirical Results ‣ Towards Explainable Network Intrusion Detection using Large Language Models"><span class="ltx_text ltx_ref_tag">5</span></a>, highlights the significant difference in computational complexity among the models. The <span class="ltx_text ltx_font_italic" id="S4.SS3.p2.1.1">LLama3</span> model exhibited significantly higher inference times due to its complex architecture and a large number of parameters. As <span class="ltx_text ltx_font_italic" id="S4.SS3.p2.1.2">GPT-4</span> is closed-source and runs on the server side, we were unable to obtain statistics about its inference times and parameter count, which are in a similar range to those of <span class="ltx_text ltx_font_italic" id="S4.SS3.p2.1.3">LLama3</span>.
In contrast, traditional ML models like the Random Forest and the Decision Tree demonstrated swift inference times, making them more suitable for real-time NIDS applications. For instance, DL models can still offer a reasonable trade-off compromise, with costs potentially being manageable. However, considering the near 7000-fold slower inference time of LLMs compared to lightweight models, it is not feasible to implement LLMs in a real-time NIDS.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Discussion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Current fine-tuning approaches have not significantly improved performance, highlighting the need for more effective methods tailored to classification tasks.
Parameters such as temperature, data encoding and prompt formulation can also affect performance and need to be studied comprehensively for their impact on classification.
Furthermore, as demonstrated by the cross-domain performance limitations of existing NIDS models <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib21" title="">layeghy_explainable_2023, </a>)</cite>, there is a need for more robust and adaptable architectures. Comparing LLMs, known for their adaptability, with other ML architectures in terms of their performance on unseen network behaviours could offer insights for future development in this field.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">To improve explainability, the integration of a Retrieval-Augmented Generation (RAG) system <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib24" title="">lewis_retrieval-augmented_2020, </a>)</cite>, linked with a Cyber Threat Intelligence (CTI) source, could significantly enhance the reliability of LLMs. RAG can ground LLMs in accurate, up-to-date information, potentially reducing or eliminating hallucinations. Expanding RAG beyond CTI to include specifications of observed systems, such as endpoints, operating systems, SBOM, and firewall rules, could enhance both detection rates and response effectiveness. On the other hand, to provide explainable threat response, deployed LLMs should be equipped with access to function calls. Function calling, also known as tool use or API calling, enables LLMs to interact with external systems <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib25" title="">liang_taskmatrixai_2023, </a>)</cite>. By providing the LLM with a predefined set of functions or tools along with usage instructions, it can intelligently select and invoke appropriate functions to address a given threat scenario. For instance, it could propose specific functions with parameters to temporarily modify firewall rules. To evaluate the progress of future research in this area, it is essential to develop a methodology for quantitatively assessing the explainability of LLMs to reason on NIDS alerts. Currently, datasets necessary to fuel this methodology do not exist, highlighting future research.</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">While LLMs show promise as assistants for providing explanations, they require further research and development before they can be considered reliable in this capacity. Future work shall also focus on LLMs’ understanding of network traffic, as it is crucial for their potential role as a virtual system administrator, complementing NIDS. This research would build upon the work of Donadel et al. <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2408.04342v1#bib.bib26" title="">donadel_can_2024, </a>)</cite>, evaluating their understanding of network topology.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">Our investigation into the application of LLMs for NIDS has revealed notable limitations in their performance as primary solutions. If used as a solution to detect threats based on NetFlows, future research shall rather focus on transformer-based architectures without relying on pre-trained LLMs. LLMs currently struggle to effectively detect domain-specific malicious NetFlows and have high inference time complexity, making them impractical as standalone NIDS solutions. Given these findings, we propose that LLMs should be harnessed as complementary solutions to existing state-of-the-art NIDS. Specifically, their strengths in providing explainability make them valuable when integrated with traditional ML-based systems, particularly for generating detailed and contextually relevant explanations when alerts are raised. This approach leverages the potential of LLMs to enhance the interpretability and transparency of NIDS, thus aiding in threat response and decision-making processes. While challenges such as hallucination and logical reasoning limitations persist, the promising results in explainability underscore the importance of further exploring LLMs to finally render NIDS explainable.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
S. Layeghy, M. Gallagher, and M. Portmann, “Benchmarking the Benchmark – Analysis of Synthetic NIDS Datasets,” Apr. 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(2)</span>
<span class="ltx_bibblock">
S. Neupane, J. Ables, W. Anderson, S. Mittal, S. Rahimi, I. Banicescu, and M. Seale, “Explainable Intrusion Detection Systems (X-IDS): A Survey of Current Methods, Challenges, and Opportunities,” <span class="ltx_text ltx_font_italic" id="bib.bib2.1.1">IEEE Access</span>, vol. 10, pp. 112392–112415, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(3)</span>
<span class="ltx_bibblock">
H. Xu, S. Wang, N. Li, K. Wang, Y. Zhao, K. Chen, T. Yu, Y. Liu, and H. Wang, “Large Language Models for Cyber Security: A Systematic Literature Review,” <span class="ltx_text ltx_font_italic" id="bib.bib3.1.1">arXiv:2405.04760</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(4)</span>
<span class="ltx_bibblock">
M. Sarhan, S. Layeghy, N. Moustafa, and M. Portmann, “NetFlow Datasets for Machine Learning-Based Network Intrusion Detection Systems,” in <span class="ltx_text ltx_font_italic" id="bib.bib4.1.1">Big Data Technologies and Applications</span> (Z. Deze, H. Huang, R. Hou, S. Rho, and N. Chilamkurti, eds.), (Cham), pp. 117–135, Springer International Publishing, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(5)</span>
<span class="ltx_bibblock">
M. Sarhan, S. Layeghy, and M. Portmann, “Towards a Standard Feature Set for Network Intrusion Detection System Datasets,” <span class="ltx_text ltx_font_italic" id="bib.bib5.1.1">Mobile Networks and Applications</span>, vol. 27, pp. 357–370, Feb. 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(6)</span>
<span class="ltx_bibblock">
Z. T. Sworna, Z. Mousavi, and M. A. Babar, “NLP Methods in Host-based Intrusion Detection Systems: A Systematic Review and Future Directions,” Nov. 2022.

</span>
<span class="ltx_bibblock">arXiv:2201.08066 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(7)</span>
<span class="ltx_bibblock">
O. G. Lira, A. Marroquin, and M. A. To, “Harnessing the Advanced Capabilities of LLM for Adaptive Intrusion Detection Systems,” in <span class="ltx_text ltx_font_italic" id="bib.bib7.1.1">Advanced Information Networking and Applications</span> (L. Barolli, ed.), (Cham), pp. 453–464, Springer Nature Switzerland, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(8)</span>
<span class="ltx_bibblock">
I. Sharafaldin, A. Habibi Lashkari, and A. A. Ghorbani, “Toward Generating a New Intrusion Detection Dataset and Intrusion Traffic Characterization:,” in <span class="ltx_text ltx_font_italic" id="bib.bib8.1.1">Proceedings of the 4th International Conference on Information Systems Security and Privacy</span>, (Funchal, Madeira, Portugal), pp. 108–116, SCITEPRESS - Science and Technology Publications, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(9)</span>
<span class="ltx_bibblock">
A. Hekmati, N. Jethwa, E. Grippo, and B. Krishnamachari, “Correlation-Aware Neural Networks for DDoS Attack Detection In IoT Systems,” Feb. 2023.

</span>
<span class="ltx_bibblock">arXiv:2302.07982 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(10)</span>
<span class="ltx_bibblock">
L. D. Manocchio, S. Layeghy, W. W. Lo, G. K. Kulatilleke, M. Sarhan, and M. Portmann, “FlowTransformer: A transformer framework for flow-based network intrusion detection systems,” <span class="ltx_text ltx_font_italic" id="bib.bib10.1.1">Expert Systems with Applications</span>, vol. 241, p. 122564, May 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(11)</span>
<span class="ltx_bibblock">
M. A. Ferrag, M. Ndhlovu, N. Tihanyi, L. C. Cordeiro, M. Debbah, T. Lestable, and N. S. Thandi, “Revolutionizing Cyber Threat Detection with Large Language Models: A privacy-preserving BERT-based Lightweight Model for IoT/IIoT Devices,” Feb. 2024.

</span>
<span class="ltx_bibblock">arXiv:2306.14263 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(12)</span>
<span class="ltx_bibblock">
N. Alkhatib, M. Mushtaq, H. Ghauch, and J.-L. Danger, “CAN-BERT do it? Controller Area Network Intrusion Detection System based on BERT Language Model,” in <span class="ltx_text ltx_font_italic" id="bib.bib12.1.1">2022 IEEE/ACS 19th International Conference on Computer Systems and Applications (AICCSA)</span>, (Abu Dhabi, United Arab Emirates), pp. 1–8, IEEE, Dec. 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(13)</span>
<span class="ltx_bibblock">
M. Guastalla, Y. Li, A. Hekmati, and B. Krishnamachari, “Application of Large Language Models to DDoS Attack Detection,” in <span class="ltx_text ltx_font_italic" id="bib.bib13.1.1">Security and Privacy in Cyber-Physical Systems and Smart Vehicles</span>, vol. 552, pp. 83–99, Cham: Springer Nature Switzerland, 2024.

</span>
<span class="ltx_bibblock">Series Title: Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(14)</span>
<span class="ltx_bibblock">
S. B. Mallampati and H. Seetha, “Enhancing Intrusion Detection with Explainable AI: A Transparent Approach to Network Security,” <span class="ltx_text ltx_font_italic" id="bib.bib14.1.1">Cybernetics and Information Technologies</span>, vol. 24, pp. 98–117, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(15)</span>
<span class="ltx_bibblock">
T. Senevirathna, B. Siniarski, M. Liyanage, and S. Wang, “Deceiving Post-Hoc Explainable AI (XAI) Methods in Network Intrusion Detection,” in <span class="ltx_text ltx_font_italic" id="bib.bib15.1.1">2024 IEEE 21st Consumer Communications &amp; Networking Conference (CCNC)</span>, pp. 107–112, Jan. 2024.

</span>
<span class="ltx_bibblock">ISSN: 2331-9860.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(16)</span>
<span class="ltx_bibblock">
T. Zebin, S. Rezvy, and Y. Luo, “An Explainable AI-Based Intrusion Detection System for DNS Over HTTPS (DoH) Attacks,” <span class="ltx_text ltx_font_italic" id="bib.bib16.1.1">IEEE Transactions on Information Forensics and Security</span>, vol. 17, pp. 2339–2349, 2022.

</span>
<span class="ltx_bibblock">Conference Name: IEEE Transactions on Information Forensics and Security.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(17)</span>
<span class="ltx_bibblock">
F. Wei, H. Li, Z. Zhao, and H. Hu, “XNIDS: Explaining Deep Learning-based Network Intrusion Detection Systems for Active Intrusion Responses,” in <span class="ltx_text ltx_font_italic" id="bib.bib17.1.1">Proceedings of the 32nd USENIX Security Symposium</span>, (Anaheim, CA, USA), 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(18)</span>
<span class="ltx_bibblock">
S. Minaee, T. Mikolov, N. Nikzad, M. Chenaghlu, R. Socher, X. Amatriain, and J. Gao, “Large Language Models: A Survey,” Feb. 2024.

</span>
<span class="ltx_bibblock">arXiv:2402.06196 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(19)</span>
<span class="ltx_bibblock">
J. Hong, N. Lee, and J. Thorne, “ORPO: Monolithic Preference Optimization without Reference Model,” 2024.

</span>
<span class="ltx_bibblock">arXiv:2403.07691 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(20)</span>
<span class="ltx_bibblock">
K. Ethayarajh, W. Xu, N. Muennighoff, D. Jurafsky, and D. Kiela, “KTO: Model Alignment as Prospect Theoretic Optimization,” <span class="ltx_text ltx_font_italic" id="bib.bib20.1.1">arXiv:2402.01306</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(21)</span>
<span class="ltx_bibblock">
S. Layeghy and M. Portmann, “Explainable Cross-domain Evaluation of ML-based Network Intrusion Detection Systems,” <span class="ltx_text ltx_font_italic" id="bib.bib21.1.1">Computers and Electrical Engineering</span>, vol. 108, p. 108692, May 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(22)</span>
<span class="ltx_bibblock">
S. Layeghy, M. Baktashmotlagh, and M. Portmann, “DI-NIDS: Domain invariant network intrusion detection system,” <span class="ltx_text ltx_font_italic" id="bib.bib22.1.1">Knowledge-Based Systems</span>, vol. 273, p. 110626, Aug. 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(23)</span>
<span class="ltx_bibblock">
L. D. Manocchio, S. Layeghy, and M. Portmann, “Network Intrusion Detection System in a Light Bulb,” in <span class="ltx_text ltx_font_italic" id="bib.bib23.1.1">2022 32nd International Telecommunication Networks and Applications Conference (ITNAC)</span>, pp. 1–8, IEEE, Nov. 2022.

</span>
<span class="ltx_bibblock">ISSN: 2474-154X.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(24)</span>
<span class="ltx_bibblock">
P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Küttler, M. Lewis, W.-t. Yih, T. Rocktäschel, S. Riedel, and D. Kiela, “Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks,” in <span class="ltx_text ltx_font_italic" id="bib.bib24.1.1">Advances in Neural Information Processing Systems</span>, vol. 33, (Online), pp. 9459–9474, Curran Associates, Inc., 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(25)</span>
<span class="ltx_bibblock">
Y. Liang, C. Wu, T. Song, W. Wu, Y. Xia, Y. Liu, Y. Ou, S. Lu, L. Ji, S. Mao, Y. Wang, L. Shou, M. Gong, and N. Duan, “TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs,” Mar. 2023.

</span>
<span class="ltx_bibblock">arXiv:2303.16434 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(26)</span>
<span class="ltx_bibblock">
D. Donadel, F. Marchiori, L. Pajola, and M. Conti, “Can LLMs Understand Computer Networks? Towards a Virtual System Administrator,” Apr. 2024.

</span>
<span class="ltx_bibblock">arXiv:2404.12689 [cs].

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Aug  8 09:55:26 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
