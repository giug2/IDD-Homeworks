<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2406.13130] Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data</title><meta property="og:description" content="The evaluation of synthetic data generation is crucial, especially in the retail sector where data accuracy is paramount. This paper introduces a comprehensive framework for assessing synthetic retail data, focusing on…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2406.13130">

<!--Generated on Fri Jul  5 17:29:14 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_font_bold ltx_title_document">Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Yu Xia ,
Chi-Hua Wang ,
Joshua Mabry ,
Guang Cheng
</span><span class="ltx_author_notes">Machine Learning Engineer, Bain &amp; Company, CA, 94158. Email: yu.xia@bain.comPostdoctoral Scholar, Department of Statistics &amp; Data Science, UCLA, CA, 90095. Email: chihuawang@ucla.eduSr. Director of Data Science &amp; ML Engineering, Bain &amp; Company, CA, 94158. Email: joshua.mabry@bain.comProfessor, Department of Statistics and Data Science, UCLA, CA, 90095. Email: guangcheng@ucla.edu</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">The evaluation of synthetic data generation is crucial, especially in the retail sector where data accuracy is paramount. This paper introduces a comprehensive framework for assessing synthetic retail data, focusing on fidelity, utility, and privacy. Our approach differentiates between continuous and discrete data attributes, providing precise evaluation criteria.
Fidelity is measured through stability and generalizability. Stability ensures synthetic data accurately replicates known data distributions, while generalizability confirms its robustness in novel scenarios. Utility is demonstrated through the synthetic data’s effectiveness in critical retail tasks such as demand forecasting and dynamic pricing, proving its value in predictive analytics and strategic planning. Privacy is safeguarded using Differential Privacy, ensuring synthetic data maintains a perfect balance between resembling training and holdout datasets without compromising security.
Our findings validate that this framework provides reliable and scalable evaluation for synthetic retail data. It ensures high fidelity, utility, and privacy, making it an essential tool for advancing retail data science. This framework meets the evolving needs of the retail industry with precision and confidence, paving the way for future advancements in synthetic data methodologies.</p>
</div>
<div id="p1" class="ltx_para ltx_noindent">
<br class="ltx_break">
<p id="p1.1" class="ltx_p"><span id="p1.1.1" class="ltx_text ltx_font_bold">Key Words:</span> Tabular Generative Models, Synthetic Data Fidelity, Machine Learning Utility, Synthetic Data Privacy, Retail Synthetic Data</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">In the rapidly evolving field of data science, the evaluation of synthetic data generation frameworks has become paramount, especially within the retail sector. This paper introduces a comprehensive framework for assessing synthetic retail data, focusing on three critical dimensions: fidelity, utility, and privacy. Our framework distinguishes between continuous and discrete attributes within retail datasets, providing clear methodologies for their evaluation.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Firstly, fidelity is evaluated through stability and generalizability <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>. Stability measures how well synthetic retail data replicates known data distributions, highlighting the robustness of models in familiar scenarios. Generalizability, on the other hand, assesses the performance of synthetic data in novel contexts, ensuring that the generated data can effectively extend beyond its training parameters. This is particularly important in retail, where market trends and consumer behavior can shift rapidly.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Secondly, the utility of synthetic retail data is scrutinized by its applicability to real-world tasks. In the retail sector, accurate demand forecasting and dynamic pricing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> are pivotal for operational efficiency and profitability. Our evaluation framework demonstrates how synthetic datasets can effectively support these core functions, making them indispensable for predictive analytics and strategic decision-making in retail.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Finally, privacy is assessed using Differential Privacy and related metrics. We compare the proximity of synthetic datasets to both training and holdout datasets to ensure balanced privacy guarantees. A well-balanced synthetic dataset should approximate both datasets equally, indicating robust privacy protection without compromising data utility. This aspect is critical in retail, where customer data privacy is a significant concern.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">We apply our framework to evaluate generative AI models trained with the Complete Journey dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. Our results affirm that our evaluation framework provides a robust pipeline for large-scale assessments of synthetic retail data generation models. This framework not only ensures high fidelity and utility but also maintains stringent privacy standards. Consequently, it offers a solid foundation for future improvements in synthetic data generation and evaluation methodologies within the retail sector.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">This paper concludes that with our framework, synthetic retail data can be reliably utilized for various applications, offering a scalable solution for the ever-growing demands of data privacy and utility in retail data science.</p>
</div>
<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span>Background and Motivation</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p id="S1.SS1.p1.1" class="ltx_p">In the retail industry, the challenges of data privacy and availability are significant obstacles. Synthetic data, which is artificially generated rather than obtained from real-world events, provides a compelling solution to these issues. One primary challenge in retail is protecting customer privacy while leveraging data for analysis and decision-making. Synthetic data addresses this by mimicking real data without exposing sensitive customer information, and maintaining statistical properties and patterns found in actual data. This allows retailers to perform robust analyses and model training without risking data breaches or violating privacy regulations.</p>
</div>
<div id="S1.SS1.p2" class="ltx_para">
<p id="S1.SS1.p2.1" class="ltx_p">Moreover, obtaining large volumes of high-quality data can be difficult, especially when dealing with new products or services where historical data is sparse or non-existent. Public datasets are notably smaller than standard industry datasets. They are generally collected under biased and often undisclosed marketing policies, and they lack many critical fields needed for accurate customer behavior modeling<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. Moreover, business constraints and fairness concerns restrict the potential for aggressive experimentation across the marketing mix. Synthetic data generation overcomes these by creating abundant and varied datasets that reflect potential future scenarios or underrepresented cases. This capability is crucial for training machine learning models, which require large datasets to perform effectively. Additionally, synthetic data can help mitigate biases present in real data, leading to more fair and accurate models.</p>
</div>
</section>
<section id="S1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.2 </span>Objectives and Contributions</h3>

<div id="S1.SS2.p1" class="ltx_para">
<p id="S1.SS2.p1.1" class="ltx_p">Developing a robust evaluation framework for synthetic data in retail is essential to ensure the validity and utility of the data. Without rigorous evaluation, synthetic data may fail to accurately reflect the complexities of real-world scenarios, leading to misleading insights and poor decision-making. A strong evaluation framework involves several critical components: assessing the statistical similarity between synthetic and real data, evaluating the impact on model performance, and ensuring that synthetic data preserves essential patterns and relationships. Thus, we propose a standardized evaluation framework for retail synthetic datasets from three aspects: fidelity, utility, and privacy.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2406.13130/assets/assets/workflow.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="509" height="170" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The framework diagram of our synthetic retail data evaluation pipeline. Section <a href="#S3.SS1" title="3.1 Train-Holdout-Eval Split ‣ 3 The Evaluation Framework ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a> explains the purpose and method to split transaction data. Section <a href="#S3.SS2" title="3.2 Measuring Synthetic Data Fidelity ‣ 3 The Evaluation Framework ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a> defines detailed metrics for fidelity assessment, i.e. Wasserstein distance, Pearson correlation, etc. Section <a href="#S3.SS3" title="3.3 Measuring Synthetic Data Utility ‣ 3 The Evaluation Framework ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a> defines the tasks for utility assessment, i.e. classification accuracy, product association, etc. Section<a href="#S3.SS4" title="3.4 Measuring Synthetic Data Privacy ‣ 3 The Evaluation Framework ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4</span></a> explains the metrics for privacy assessment, i.e. distance to the closest record.</figcaption>
</figure>
<div id="S1.SS2.p2" class="ltx_para">
<p id="S1.SS2.p2.1" class="ltx_p">Such a framework (Figure <a href="#S1.F1" title="Figure 1 ‣ 1.2 Objectives and Contributions ‣ 1 Introduction ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) ensures that synthetic data is not only statistically similar to real data but also useful for practical applications in the retail sector. This process helps identify any discrepancies and areas where synthetic data may fall short, guiding improvements in data generation methods. Ultimately, a robust evaluation framework builds trust in synthetic data, making it a reliable resource for retailers. In this way, we ensure a safe and scalable way to generate high-quality synthetic data while maintaining privacy compliance.</p>
</div>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Existing Evaluation Frameworks</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Several general frameworks have been proposed to gauge the efficacy of synthetic data previously. A sample-level metric framework evaluates generative models through fidelity and utility lenses, facilitating the identification of discrepancies and similarities between real and synthetic datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Another methodology emphasizes auditing and generating synthetic data with controllable trust trade-offs, allowing customization based on specific requirements <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. Further exploration of synthetic data generation discusses its benefits and limitations across various contexts, particularly in creating a practical approach for deployment <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Fidelity assessment ensures synthetic data retains the essential characteristics and patterns of real data. Previous work proposed a holdout-based empirical assessment method for mixed-type synthetic data, highlighting the importance of maintaining the statistical properties and variability inherent in the original dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>. On the metric aspect, Sajjadi et al introduced a definition of precision and recall for distribution and quantified distribution similarity not just with one-dimensional score, like total variation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">Utility evaluation focuses on the synthetic data’s performance in downstream tasks. Xu et al. established a basis of relevant utility theory in a statistical learning framework and introduced metrics of generalization and ranking of models trained on synthetic data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>. It considers two utility metrics: generalization and ranking of models trained on synthetic data. There was also empirical work, for example, emphasizing generative model selection based on performance in fraud detection<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. Additionally, Hsieh et al. (2024) adopted a data-centric perspective to improve both the fidelity and utility of synthetic credit card transaction time series <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. Liu et al. explore utility in dynamic pricing models, demonstrating how synthetic data can support robust pricing strategies in fluctuating market conditions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.1" class="ltx_p">Privacy is a central concern in synthetic data generation. A formal framework for detecting data-copying in generative models ensures synthetic data does not replicate real data points <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, where the author also provides the requirement of minimum sample size for reliable detection. Meehan’s work proposed a three-sample test to solve the same issue of data-copying in generative models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. BadGD addresses the vulnerabilities of gradient descent algorithms through strategic backdoor attacks to safeguard data privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>. Furthermore, Chen et al. systematically summarize all approaches for differentially private data publishing to conduct reproducible downstream analysis while preserving data privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. Tools like TAPAS provide adversarial privacy auditing. A review of privacy measurement practices for tabular synthetic data includes a comprehensive list of privacy metrics <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, such as Differential Privacy, k-Anonymity, Plausible Deniability, etc.</p>
</div>
<div id="S2.SS1.p5" class="ltx_para">
<p id="S2.SS1.p5.1" class="ltx_p">However, to our knowledge, there is no empirical work conducting a full set of fidelity, utility, and privacy assessments on generative AI models with retail transaction data.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Synthetic Data in Retail</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Synthetic data can transform the retail industry by enhancing various operational and analytical processes while ensuring customer privacy. It enables comprehensive customer analytics and segmentation without compromising personal data, aiding in the development of targeted marketing strategies. In supply chain optimization, synthetic data simulates different scenarios to help forecast demand, optimize inventory, and improve logistics. Product recommendation systems can benefit from data augmentation with synthetic datasets for extensive training, ensuring accurate and relevant recommendations that enhance customer experience. Furthermore, synthetic data allows safe data sharing with third parties and partners under privacy regulations, facilitating collaborative projects and compliance checks without using real data, thus fostering innovation while safeguarding privacy.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">Data practitioners have widely recognized the value of synthetic data for accelerating the development of AI systems and started to emphasize building generative models of the data in its raw tabular forms, instead of modeling features derived from transformed data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. Researchers identify two different paths for synthetic data generation. One is the black-box style of privacy-preserving modeling techniques (such as Generative Adversarial Networks, Variational Autoencoders, and Bayesian Networks) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>. For example, Athey generated synthetic data for the evaluation of causal effects estimators with Wasserstein Generative Adversarial Networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. These privacy-preserving modeling techniques are powerful when sufficient historical data is available to learn an accurate data-generating process. However, when public retail datasets are rather scarce, the other style that needs domain knowledge in retail shines. Statisticians simplify the complexity of real-world data and specify structural causal models to generate synthetic data. For example, prior work simulated either category choice or the full life-cycle of customer shopping decisions based on a nested logit model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p">However, no matter which technique is used for synthetic data generation, there is currently no well-defined evaluation framework specifically designed to assess synthetic retail data, highlighting a crucial gap in ensuring data fidelity, utility, and privacy. The retail industry particularly requires effective data to conduct analysis, such as price optimization<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, basket analysis <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, customer lifetime value <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, and demand forecasting <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. Given the complexity and importance of these tasks, careful evaluation of synthetic data is essential to preserve the quality of insights derived from these analyses, ensuring that strategic decisions are based on accurate and reliable information.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Complete Journey Dataset</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">The Dunnhumby Complete Journey Dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> represents a comprehensive and meticulously curated collection of retail transaction data, providing deep insights into consumer purchase behaviors and patterns. Compiled from a vast array of shopping experiences, this dataset encompasses detailed records of customer interactions, including basket-level transaction details, promotional influences, and loyalty program participation. We utilize three main tables in our paper from the dataset: (1) transaction table, (2) customer demographics table, and (3) product hierarchy table. We merge these three tables with schema explained in Table <a href="#S2.T1" title="Table 1 ‣ 2.3 Complete Journey Dataset ‣ 2 Related Work ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> to build the raw data input to the proposed framework in Figure <a href="#S1.F1" title="Figure 1 ‣ 1.2 Objectives and Contributions ‣ 1 Introduction ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, and cover the pre-processing details in section <a href="#S4.SS1" title="4.1 Data Description and Analysis ‣ 4 Evaluation Results ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>.</p>
</div>
<figure id="S2.T1" class="ltx_table">
<table id="S2.T1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S2.T1.1.1" class="ltx_tr">
<td id="S2.T1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt">Variable</td>
<td id="S2.T1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt">Type</td>
<td id="S2.T1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">Description</td>
<td id="S2.T1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">Source</td>
</tr>
<tr id="S2.T1.1.2" class="ltx_tr">
<td id="S2.T1.1.2.1" class="ltx_td ltx_align_center ltx_border_t">household_id</td>
<td id="S2.T1.1.2.2" class="ltx_td ltx_align_center ltx_border_t">integer</td>
<td id="S2.T1.1.2.3" class="ltx_td ltx_align_center ltx_border_t">Customer unique identifier</td>
<td id="S2.T1.1.2.4" class="ltx_td ltx_align_center ltx_border_t">1 &amp; 2</td>
</tr>
<tr id="S2.T1.1.3" class="ltx_tr">
<td id="S2.T1.1.3.1" class="ltx_td ltx_align_center">product_id</td>
<td id="S2.T1.1.3.2" class="ltx_td ltx_align_center">integer</td>
<td id="S2.T1.1.3.3" class="ltx_td ltx_align_center">Product unique identifier</td>
<td id="S2.T1.1.3.4" class="ltx_td ltx_align_center">1 &amp; 3</td>
</tr>
<tr id="S2.T1.1.4" class="ltx_tr">
<td id="S2.T1.1.4.1" class="ltx_td ltx_align_center">day</td>
<td id="S2.T1.1.4.2" class="ltx_td ltx_align_center">integer</td>
<td id="S2.T1.1.4.3" class="ltx_td ltx_align_center">Transaction day</td>
<td id="S2.T1.1.4.4" class="ltx_td ltx_align_center">1</td>
</tr>
<tr id="S2.T1.1.5" class="ltx_tr">
<td id="S2.T1.1.5.1" class="ltx_td ltx_align_center">week</td>
<td id="S2.T1.1.5.2" class="ltx_td ltx_align_center">integer</td>
<td id="S2.T1.1.5.3" class="ltx_td ltx_align_center">Transaction week</td>
<td id="S2.T1.1.5.4" class="ltx_td ltx_align_center">1</td>
</tr>
<tr id="S2.T1.1.6" class="ltx_tr">
<td id="S2.T1.1.6.1" class="ltx_td ltx_align_center">quantity</td>
<td id="S2.T1.1.6.2" class="ltx_td ltx_align_center">integer</td>
<td id="S2.T1.1.6.3" class="ltx_td ltx_align_center">Purchased units</td>
<td id="S2.T1.1.6.4" class="ltx_td ltx_align_center">1</td>
</tr>
<tr id="S2.T1.1.7" class="ltx_tr">
<td id="S2.T1.1.7.1" class="ltx_td ltx_align_center">sales_value</td>
<td id="S2.T1.1.7.2" class="ltx_td ltx_align_center">float</td>
<td id="S2.T1.1.7.3" class="ltx_td ltx_align_center">Revenue</td>
<td id="S2.T1.1.7.4" class="ltx_td ltx_align_center">1</td>
</tr>
<tr id="S2.T1.1.8" class="ltx_tr">
<td id="S2.T1.1.8.1" class="ltx_td ltx_align_center">…</td>
<td id="S2.T1.1.8.2" class="ltx_td ltx_align_center">…</td>
<td id="S2.T1.1.8.3" class="ltx_td ltx_align_center">…</td>
<td id="S2.T1.1.8.4" class="ltx_td"></td>
</tr>
<tr id="S2.T1.1.9" class="ltx_tr">
<td id="S2.T1.1.9.1" class="ltx_td ltx_align_center ltx_border_t">age</td>
<td id="S2.T1.1.9.2" class="ltx_td ltx_align_center ltx_border_t">string</td>
<td id="S2.T1.1.9.3" class="ltx_td ltx_align_center ltx_border_t">Customer age group</td>
<td id="S2.T1.1.9.4" class="ltx_td ltx_align_center ltx_border_t">2</td>
</tr>
<tr id="S2.T1.1.10" class="ltx_tr">
<td id="S2.T1.1.10.1" class="ltx_td ltx_align_center">household_size</td>
<td id="S2.T1.1.10.2" class="ltx_td ltx_align_center">string</td>
<td id="S2.T1.1.10.3" class="ltx_td ltx_align_center">Number of family members</td>
<td id="S2.T1.1.10.4" class="ltx_td ltx_align_center">2</td>
</tr>
<tr id="S2.T1.1.11" class="ltx_tr">
<td id="S2.T1.1.11.1" class="ltx_td ltx_align_center">…</td>
<td id="S2.T1.1.11.2" class="ltx_td ltx_align_center">…</td>
<td id="S2.T1.1.11.3" class="ltx_td ltx_align_center">…</td>
<td id="S2.T1.1.11.4" class="ltx_td"></td>
</tr>
<tr id="S2.T1.1.12" class="ltx_tr">
<td id="S2.T1.1.12.1" class="ltx_td ltx_align_center ltx_border_t">department</td>
<td id="S2.T1.1.12.2" class="ltx_td ltx_align_center ltx_border_t">string</td>
<td id="S2.T1.1.12.3" class="ltx_td ltx_align_center ltx_border_t">Product department</td>
<td id="S2.T1.1.12.4" class="ltx_td ltx_align_center ltx_border_t">3</td>
</tr>
<tr id="S2.T1.1.13" class="ltx_tr">
<td id="S2.T1.1.13.1" class="ltx_td ltx_align_center">brand</td>
<td id="S2.T1.1.13.2" class="ltx_td ltx_align_center">string</td>
<td id="S2.T1.1.13.3" class="ltx_td ltx_align_center">”national” or ”private”</td>
<td id="S2.T1.1.13.4" class="ltx_td ltx_align_center">3</td>
</tr>
<tr id="S2.T1.1.14" class="ltx_tr">
<td id="S2.T1.1.14.1" class="ltx_td ltx_align_center ltx_border_bb">…</td>
<td id="S2.T1.1.14.2" class="ltx_td ltx_align_center ltx_border_bb">…</td>
<td id="S2.T1.1.14.3" class="ltx_td ltx_align_center ltx_border_bb">…</td>
<td id="S2.T1.1.14.4" class="ltx_td ltx_border_bb"></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Partial schema of merged Complete Journey dataset as an example, where (1) in the source column represent the transactions table, (2) for the customer demographics table, and (3) for the product hierarchy table. See Sec. <a href="#S2.SS3" title="2.3 Complete Journey Dataset ‣ 2 Related Work ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a> for full details.</figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>The Evaluation Framework</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this session, we propose an empirical assessment framework to evaluate generative AI models for retail synthetic data generation. Our evaluation method is distinguished by its tripartite composition of synthetic data <span id="S3.p1.1.1" class="ltx_text ltx_font_bold">Fidelity</span>, <span id="S3.p1.1.2" class="ltx_text ltx_font_bold">Utility</span>, and <span id="S3.p1.1.3" class="ltx_text ltx_font_bold">Privacy</span> metrics. The defining characteristic of this method is its adaptability and model-free nature, allowing it to be deployed independently of domain-specific knowledge or preconceived notions. Utilizing non-parametric measures, our data-centric evaluation provides a systematic review of an array of black-box synthetic data solutions, examining whether generated data is practical, safe, and broadly applicable. The objective underlining this methodology is to build transparency, enhance confidence in data generators, and further incentivize industries to leverage synthetic data for innovation in the modern data-driven world.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Train-Holdout-Eval Split</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.10" class="ltx_p">To robustly evaluate the generalizability of a data synthesizer, we employ a random split of the available records into three distinct datasets: a training dataset <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">T</annotation></semantics></math>, a holdout dataset <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">H</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>, and an additional evaluation dataset <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">E</annotation></semantics></math>, where the evaluation dataset <math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><mi id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><ci id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">E</annotation></semantics></math> is only used for assessing model utility as a evaluation set (Figure <a href="#S1.F1" title="Figure 1 ‣ 1.2 Objectives and Contributions ‣ 1 Introduction ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). The training dataset <math id="S3.SS1.p1.5.m5.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.p1.5.m5.1a"><mi id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><ci id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">T</annotation></semantics></math> is exclusively used to train the synthesizer, while the holdout dataset <math id="S3.SS1.p1.6.m6.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S3.SS1.p1.6.m6.1a"><mi id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><ci id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">H</annotation></semantics></math> remains untouched during the synthetic data generation process. By exposing only the training dataset <math id="S3.SS1.p1.7.m7.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.p1.7.m7.1a"><mi id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><ci id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">T</annotation></semantics></math> to the synthesizer, we generate a synthetic dataset <math id="S3.SS1.p1.8.m8.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.SS1.p1.8.m8.1a"><mi id="S3.SS1.p1.8.m8.1.1" xref="S3.SS1.p1.8.m8.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m8.1b"><ci id="S3.SS1.p1.8.m8.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m8.1c">S</annotation></semantics></math> of the same size as <math id="S3.SS1.p1.9.m9.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.p1.9.m9.1a"><mi id="S3.SS1.p1.9.m9.1.1" xref="S3.SS1.p1.9.m9.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m9.1b"><ci id="S3.SS1.p1.9.m9.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m9.1c">T</annotation></semantics></math>. The isolated holdout dataset <math id="S3.SS1.p1.10.m10.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S3.SS1.p1.10.m10.1a"><mi id="S3.SS1.p1.10.m10.1.1" xref="S3.SS1.p1.10.m10.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m10.1b"><ci id="S3.SS1.p1.10.m10.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m10.1c">H</annotation></semantics></math> can then serve as a benchmark to assess the synthesizer’s ability to generalize beyond the data it was trained on.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.5" class="ltx_p">To demonstrate the model generalizability, we compare the metrics obtained from both the holdout dataset <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mi id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">H</annotation></semantics></math> and the synthetic dataset <math id="S3.SS1.p2.2.m2.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><mi id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">S</annotation></semantics></math>. If the holdout dataset <math id="S3.SS1.p2.3.m3.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S3.SS1.p2.3.m3.1a"><mi id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><ci id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">H</annotation></semantics></math> attains better metrics than the synthetic dataset <math id="S3.SS1.p2.4.m4.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.SS1.p2.4.m4.1a"><mi id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><ci id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">S</annotation></semantics></math>, the synthesizer has missed some underlying patterns presented in the data. Conversely, suppose the synthetic dataset S achieves superior metrics. In that case, this indicates potential overfitting by the synthesizer to the training dataset <math id="S3.SS1.p2.5.m5.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.p2.5.m5.1a"><mi id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><ci id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">T</annotation></semantics></math>. Ideally, we aim for the metrics from both datasets to be as close as possible, reflecting balanced generalization and reliable synthetic data generation.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Measuring Synthetic Data Fidelity</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">We treat holdout and synthetic datasets as separate data sources to evaluate fidelity metrics against the training dataset. The design of fidelity measurement is motivated by visualizing joint distributions and marginal distributions to discover patterns.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p"><span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_bold">Similarity of Marginal Distribution</span> One critical part of exploratory data analysis is to demonstrate the distribution of numerical features. This involves plotting histograms, density plots, and cumulative distribution functions to visualize how numerical data is spread across different ranges. A robust generative synthesizer must accurately learn and replicate these numerical distributions, ensuring that the synthetic data mirrors the real-world data in terms of central tendencies, variability, and distribution shape. Furthermore, we can also derive additional features from primitive columns and test their distribution similarities. This includes calculating ratios, differences, and other mathematical transformations to extract business insights. By assessing the distribution of these derived features, we can further evaluate the synthesizer’s stability and robustness, ensuring that it captures intricate relationships and patterns within the data. For both primitive numerical features and derived numerical features, we report Wasserstein distance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> to measure distribution similarities, where the small value indicates the synthetic dataset is closely attached to the real dataset.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">Another important aspect is to check the distribution of categorical features. This involves visualizing the frequency of each category, cross-tabulations, and bar plots to understand the distribution of categorical data. A competent generative synthesizer must also learn these categorical distributions accurately. It should preserve the proportions and relationships among categories, ensuring that the synthetic data accurately represents the categorical structures observed in the real dataset. To quantify the degree of similarity, we compute the Jensen-Shannon distance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> and expect a small value as an indicator of an excellent synthesizer.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p"><span id="S3.SS2.p4.1.1" class="ltx_text ltx_font_bold">Similarity of Joint Distribution</span> Besides capturing the distribution of a single attribute, a synthesizer with high fidelity should also be able to identify multivariate combinations and relationships among the set of attributes, assessing how pairs of features interact and co-vary. We compute the Pearson correlation matrix for number-to-number interaction, Theil’s U matrix for category-to-category interaction, and the correlation ratio matrix for number-to-category interactions. To verify if the synthesizer understands feature interactions and dependencies, we compute the L2 distance of flattened correlation arrays between the training dataset and the synthetic dataset or the holdout dataset. This step is vital for applications where the relationship between variables significantly impacts outcomes, such as customer segmentation and market basket analysis in the retail industry. Ensuring that these joint distributions are faithfully replicated in the synthetic data guarantees that the model maintains the integrity of multivariate relationships, providing a more comprehensive and realistic representation of the underlying data structure.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Measuring Synthetic Data
Utility</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">In evaluating the efficacy of generative models for retail synthetic data generation, a critical consideration is the preservation of Machine Learning (ML) utility. This step entails formulating a classification task <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="f:X\rightarrow Y" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mrow id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mi id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">f</mi><mo lspace="0.278em" rspace="0.278em" id="S3.SS3.p1.1.m1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.1.cmml">:</mo><mrow id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml"><mi id="S3.SS3.p1.1.m1.1.1.3.2" xref="S3.SS3.p1.1.m1.1.1.3.2.cmml">X</mi><mo stretchy="false" id="S3.SS3.p1.1.m1.1.1.3.1" xref="S3.SS3.p1.1.m1.1.1.3.1.cmml">→</mo><mi id="S3.SS3.p1.1.m1.1.1.3.3" xref="S3.SS3.p1.1.m1.1.1.3.3.cmml">Y</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><ci id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1">:</ci><ci id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2">𝑓</ci><apply id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3"><ci id="S3.SS3.p1.1.m1.1.1.3.1.cmml" xref="S3.SS3.p1.1.m1.1.1.3.1">→</ci><ci id="S3.SS3.p1.1.m1.1.1.3.2.cmml" xref="S3.SS3.p1.1.m1.1.1.3.2">𝑋</ci><ci id="S3.SS3.p1.1.m1.1.1.3.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3">𝑌</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">f:X\rightarrow Y</annotation></semantics></math> using a predefined dataset, enabling a comprehensive assessment of how well-synthesized data can replicate real-world data’s utility in predictive modeling. The evaluation framework is meticulously designed to ensure a robust comparison of model performance on both utility and generalizability.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.10" class="ltx_p">To achieve this, we train machine learning models separately using the training dataset <math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><mi id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><ci id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">T</annotation></semantics></math>, holdout dataset <math id="S3.SS3.p2.2.m2.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S3.SS3.p2.2.m2.1a"><mi id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><ci id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">H</annotation></semantics></math>, and synthetic dataset <math id="S3.SS3.p2.3.m3.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.SS3.p2.3.m3.1a"><mi id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><ci id="S3.SS3.p2.3.m3.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">S</annotation></semantics></math>. This approach allows us to systematically assess the performance of each model on the same evaluation set, referred to as evaluation dataset <math id="S3.SS3.p2.4.m4.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S3.SS3.p2.4.m4.1a"><mi id="S3.SS3.p2.4.m4.1.1" xref="S3.SS3.p2.4.m4.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m4.1b"><ci id="S3.SS3.p2.4.m4.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m4.1c">E</annotation></semantics></math>. The model trained with <math id="S3.SS3.p2.5.m5.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS3.p2.5.m5.1a"><mi id="S3.SS3.p2.5.m5.1.1" xref="S3.SS3.p2.5.m5.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.5.m5.1b"><ci id="S3.SS3.p2.5.m5.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.5.m5.1c">T</annotation></semantics></math>, <math id="S3.SS3.p2.6.m6.1" class="ltx_Math" alttext="f_{T}" display="inline"><semantics id="S3.SS3.p2.6.m6.1a"><msub id="S3.SS3.p2.6.m6.1.1" xref="S3.SS3.p2.6.m6.1.1.cmml"><mi id="S3.SS3.p2.6.m6.1.1.2" xref="S3.SS3.p2.6.m6.1.1.2.cmml">f</mi><mi id="S3.SS3.p2.6.m6.1.1.3" xref="S3.SS3.p2.6.m6.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.6.m6.1b"><apply id="S3.SS3.p2.6.m6.1.1.cmml" xref="S3.SS3.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.6.m6.1.1.1.cmml" xref="S3.SS3.p2.6.m6.1.1">subscript</csymbol><ci id="S3.SS3.p2.6.m6.1.1.2.cmml" xref="S3.SS3.p2.6.m6.1.1.2">𝑓</ci><ci id="S3.SS3.p2.6.m6.1.1.3.cmml" xref="S3.SS3.p2.6.m6.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.6.m6.1c">f_{T}</annotation></semantics></math>, provides a baseline for understanding performance metrics under standard conditions. Conversely, the model trained with <math id="S3.SS3.p2.7.m7.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S3.SS3.p2.7.m7.1a"><mi id="S3.SS3.p2.7.m7.1.1" xref="S3.SS3.p2.7.m7.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.7.m7.1b"><ci id="S3.SS3.p2.7.m7.1.1.cmml" xref="S3.SS3.p2.7.m7.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.7.m7.1c">H</annotation></semantics></math>, <math id="S3.SS3.p2.8.m8.1" class="ltx_Math" alttext="f_{H}" display="inline"><semantics id="S3.SS3.p2.8.m8.1a"><msub id="S3.SS3.p2.8.m8.1.1" xref="S3.SS3.p2.8.m8.1.1.cmml"><mi id="S3.SS3.p2.8.m8.1.1.2" xref="S3.SS3.p2.8.m8.1.1.2.cmml">f</mi><mi id="S3.SS3.p2.8.m8.1.1.3" xref="S3.SS3.p2.8.m8.1.1.3.cmml">H</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.8.m8.1b"><apply id="S3.SS3.p2.8.m8.1.1.cmml" xref="S3.SS3.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.8.m8.1.1.1.cmml" xref="S3.SS3.p2.8.m8.1.1">subscript</csymbol><ci id="S3.SS3.p2.8.m8.1.1.2.cmml" xref="S3.SS3.p2.8.m8.1.1.2">𝑓</ci><ci id="S3.SS3.p2.8.m8.1.1.3.cmml" xref="S3.SS3.p2.8.m8.1.1.3">𝐻</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.8.m8.1c">f_{H}</annotation></semantics></math>, offers insights into the model’s behavior when exposed to unseen real-world data, thereby indicating its generalizability. Furthermore, the model trained with <math id="S3.SS3.p2.9.m9.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.SS3.p2.9.m9.1a"><mi id="S3.SS3.p2.9.m9.1.1" xref="S3.SS3.p2.9.m9.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.9.m9.1b"><ci id="S3.SS3.p2.9.m9.1.1.cmml" xref="S3.SS3.p2.9.m9.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.9.m9.1c">S</annotation></semantics></math>, <math id="S3.SS3.p2.10.m10.1" class="ltx_Math" alttext="f_{S}" display="inline"><semantics id="S3.SS3.p2.10.m10.1a"><msub id="S3.SS3.p2.10.m10.1.1" xref="S3.SS3.p2.10.m10.1.1.cmml"><mi id="S3.SS3.p2.10.m10.1.1.2" xref="S3.SS3.p2.10.m10.1.1.2.cmml">f</mi><mi id="S3.SS3.p2.10.m10.1.1.3" xref="S3.SS3.p2.10.m10.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.10.m10.1b"><apply id="S3.SS3.p2.10.m10.1.1.cmml" xref="S3.SS3.p2.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.10.m10.1.1.1.cmml" xref="S3.SS3.p2.10.m10.1.1">subscript</csymbol><ci id="S3.SS3.p2.10.m10.1.1.2.cmml" xref="S3.SS3.p2.10.m10.1.1.2">𝑓</ci><ci id="S3.SS3.p2.10.m10.1.1.3.cmml" xref="S3.SS3.p2.10.m10.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.10.m10.1c">f_{S}</annotation></semantics></math>, in this evaluative procedure enables a direct comparison of how well the generative models could replicate actual data characteristics and maintain predictive accuracy.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.2" class="ltx_p">By testing <math id="S3.SS3.p3.1.m1.3" class="ltx_Math" alttext="f_{T},f_{H},f_{S}" display="inline"><semantics id="S3.SS3.p3.1.m1.3a"><mrow id="S3.SS3.p3.1.m1.3.3.3" xref="S3.SS3.p3.1.m1.3.3.4.cmml"><msub id="S3.SS3.p3.1.m1.1.1.1.1" xref="S3.SS3.p3.1.m1.1.1.1.1.cmml"><mi id="S3.SS3.p3.1.m1.1.1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.1.1.2.cmml">f</mi><mi id="S3.SS3.p3.1.m1.1.1.1.1.3" xref="S3.SS3.p3.1.m1.1.1.1.1.3.cmml">T</mi></msub><mo id="S3.SS3.p3.1.m1.3.3.3.4" xref="S3.SS3.p3.1.m1.3.3.4.cmml">,</mo><msub id="S3.SS3.p3.1.m1.2.2.2.2" xref="S3.SS3.p3.1.m1.2.2.2.2.cmml"><mi id="S3.SS3.p3.1.m1.2.2.2.2.2" xref="S3.SS3.p3.1.m1.2.2.2.2.2.cmml">f</mi><mi id="S3.SS3.p3.1.m1.2.2.2.2.3" xref="S3.SS3.p3.1.m1.2.2.2.2.3.cmml">H</mi></msub><mo id="S3.SS3.p3.1.m1.3.3.3.5" xref="S3.SS3.p3.1.m1.3.3.4.cmml">,</mo><msub id="S3.SS3.p3.1.m1.3.3.3.3" xref="S3.SS3.p3.1.m1.3.3.3.3.cmml"><mi id="S3.SS3.p3.1.m1.3.3.3.3.2" xref="S3.SS3.p3.1.m1.3.3.3.3.2.cmml">f</mi><mi id="S3.SS3.p3.1.m1.3.3.3.3.3" xref="S3.SS3.p3.1.m1.3.3.3.3.3.cmml">S</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.3b"><list id="S3.SS3.p3.1.m1.3.3.4.cmml" xref="S3.SS3.p3.1.m1.3.3.3"><apply id="S3.SS3.p3.1.m1.1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.1.1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p3.1.m1.1.1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.1.1.2">𝑓</ci><ci id="S3.SS3.p3.1.m1.1.1.1.1.3.cmml" xref="S3.SS3.p3.1.m1.1.1.1.1.3">𝑇</ci></apply><apply id="S3.SS3.p3.1.m1.2.2.2.2.cmml" xref="S3.SS3.p3.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.2.2.2.2.1.cmml" xref="S3.SS3.p3.1.m1.2.2.2.2">subscript</csymbol><ci id="S3.SS3.p3.1.m1.2.2.2.2.2.cmml" xref="S3.SS3.p3.1.m1.2.2.2.2.2">𝑓</ci><ci id="S3.SS3.p3.1.m1.2.2.2.2.3.cmml" xref="S3.SS3.p3.1.m1.2.2.2.2.3">𝐻</ci></apply><apply id="S3.SS3.p3.1.m1.3.3.3.3.cmml" xref="S3.SS3.p3.1.m1.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.3.3.3.3.1.cmml" xref="S3.SS3.p3.1.m1.3.3.3.3">subscript</csymbol><ci id="S3.SS3.p3.1.m1.3.3.3.3.2.cmml" xref="S3.SS3.p3.1.m1.3.3.3.3.2">𝑓</ci><ci id="S3.SS3.p3.1.m1.3.3.3.3.3.cmml" xref="S3.SS3.p3.1.m1.3.3.3.3.3">𝑆</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.3c">f_{T},f_{H},f_{S}</annotation></semantics></math> on evaluation dataset <math id="S3.SS3.p3.2.m2.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S3.SS3.p3.2.m2.1a"><mi id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b"><ci id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">E</annotation></semantics></math> and computing metrics like accuracy, F1, ROC, precision, and recall, we are able to systematically quantify and compare the utility of data generated by various generative AI models. This empirical assessment framework not only facilitates a granular understanding of each model’s performance but also highlights the strengths and limitations of generative AI in capturing complex data patterns crucial for prediction tasks in the retail sector.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Measuring Synthetic Data Privacy</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.4" class="ltx_p">Privacy is a paramount concern in the realm of synthetic tabular data generation, primarily due to the sensitive nature of information often contained within retail datasets. The generation of synthetic data aims to mitigate the risk of disclosing private or proprietary information while still enabling valuable data-driven insights. To rigorously evaluate the privacy-preserving capabilities of generative AI models, we compute the Distance to Closest Record (DCR) , with L1 distance as the definition of distance between two records. Specifically, we assess the DCR from the synthetic data <math id="S3.SS4.p1.1.m1.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.SS4.p1.1.m1.1a"><mi id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><ci id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">S</annotation></semantics></math> to the training data <math id="S3.SS4.p1.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS4.p1.2.m2.1a"><mi id="S3.SS4.p1.2.m2.1.1" xref="S3.SS4.p1.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.2.m2.1b"><ci id="S3.SS4.p1.2.m2.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.2.m2.1c">T</annotation></semantics></math>, and from the holdout data <math id="S3.SS4.p1.3.m3.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S3.SS4.p1.3.m3.1a"><mi id="S3.SS4.p1.3.m3.1.1" xref="S3.SS4.p1.3.m3.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.3.m3.1b"><ci id="S3.SS4.p1.3.m3.1.1.cmml" xref="S3.SS4.p1.3.m3.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.3.m3.1c">H</annotation></semantics></math> to the training data <math id="S3.SS4.p1.4.m4.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS4.p1.4.m4.1a"><mi id="S3.SS4.p1.4.m4.1.1" xref="S3.SS4.p1.4.m4.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.4.m4.1b"><ci id="S3.SS4.p1.4.m4.1.1.cmml" xref="S3.SS4.p1.4.m4.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.4.m4.1c">T</annotation></semantics></math>. The DCR quantifies the likelihood of synthetic data points being too similar to actual data points, thereby posing a privacy threat. A high DCR value indicates effective anonymization.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.1" class="ltx_p">Additionally, we introduce a metric termed the <span id="S3.SS4.p2.1.1" class="ltx_text ltx_font_bold">Closest Cluster Ratio (CCR)</span> further to scrutinize the privacy and generalizability of synthetic data. The CCR measures the proportion of synthetic data points that are closer to the training dataset compared to the holdout dataset, ranging from <math id="S3.SS4.p2.1.m1.2" class="ltx_Math" alttext="[0,1]" display="inline"><semantics id="S3.SS4.p2.1.m1.2a"><mrow id="S3.SS4.p2.1.m1.2.3.2" xref="S3.SS4.p2.1.m1.2.3.1.cmml"><mo stretchy="false" id="S3.SS4.p2.1.m1.2.3.2.1" xref="S3.SS4.p2.1.m1.2.3.1.cmml">[</mo><mn id="S3.SS4.p2.1.m1.1.1" xref="S3.SS4.p2.1.m1.1.1.cmml">0</mn><mo id="S3.SS4.p2.1.m1.2.3.2.2" xref="S3.SS4.p2.1.m1.2.3.1.cmml">,</mo><mn id="S3.SS4.p2.1.m1.2.2" xref="S3.SS4.p2.1.m1.2.2.cmml">1</mn><mo stretchy="false" id="S3.SS4.p2.1.m1.2.3.2.3" xref="S3.SS4.p2.1.m1.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.1.m1.2b"><interval closure="closed" id="S3.SS4.p2.1.m1.2.3.1.cmml" xref="S3.SS4.p2.1.m1.2.3.2"><cn type="integer" id="S3.SS4.p2.1.m1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1">0</cn><cn type="integer" id="S3.SS4.p2.1.m1.2.2.cmml" xref="S3.SS4.p2.1.m1.2.2">1</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.1.m1.2c">[0,1]</annotation></semantics></math>. Ideally, the values of CCR should be as low as possible, indicating that synthetic data points are not a close copy of the training dataset. A CCR close to 1 signals an overfitting generative model, highlighting the necessity for continuous refinement in synthetic data generation techniques.</p>
</div>
<div id="S3.SS4.p3" class="ltx_para">
<p id="S3.SS4.p3.1" class="ltx_p">By combining DCR and CCR metrics, we can provide deep insights into how effectively synthetic data can protect sensitive information, thereby fostering trust and reliability in the deployment of generative AI solutions in real-world retail scenarios.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Evaluation Results</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">To demonstrate the proposed framework (Figure <a href="#S1.F1" title="Figure 1 ‣ 1.2 Objectives and Contributions ‣ 1 Introduction ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>), we conducted an empirical assessment on the open-source Complete Journey dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> of retail transactions from frequent customers in a retail grocery store (accessed from <span id="S4.p1.1.1" class="ltx_text ltx_font_italic">completejourney-py</span> <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://pypi.org/project/completejourney-py/</span></span></span>). The dataset documents the purchasing patterns of more than two thousand households over a one-year period, who frequently shop at the retailer.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">We examined 5 generative models to produce the synthetic datasets: GAN-based tabular generative models ((1) CTGAN<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>, (2) AutoGAN) and Diffusion-based tabular generative models ((3) TabDDPM<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, (4) StasyAutoDiff<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>, (5) TabAutoDiff<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>). Specifically, we implemented AutoGAN by preparing input features with AutoDiff <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> and training a GAN<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> using Torch <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. Unless otherwise specified, models are cloned from the cited repositories and the training features are prepared according to encoding methods stated in the corresponding paper.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Data Description and Analysis</h3>

<section id="S4.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Data Preprocess</h4>

<div id="S4.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.p1.1" class="ltx_p">The raw transaction data includes approximately 1.47 million transactions and a wide range of about 92,000 products. The dataset presents a detailed category hierarchy that includes product department, product category, and product type. It also offers comprehensive customer demographics, such as age, income, household size, and marital status. Key transaction information, like item quantity, transaction sales amount, and discounts, are documented, enabling the calculation of unit prices and discounts <a href="#S2.T1" title="Table 1 ‣ 2.3 Complete Journey Dataset ‣ 2 Related Work ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. We followed the same pre-process procedure shown in RetailSynth <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> to remove seasonality effects, by cleaning out unregistered customers, excluding transactions with non-positive transactions, de-duplicating the product catalog, removing infrequent products, and aggregating weekly transactions for each customer. This is a typical procedure for optimizing marketing spend, customer lifetime value calculation, etc. To further increase the effective data points for each customer, we clustered customers by their demographic information and ended up with a weekly retail transaction with about 251,000 records from 6000 products and 400 customer clusters.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Data Analysis</h4>

<div id="S4.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px2.p1.1" class="ltx_p">To generate more customer- and product-level insights, we calculated derived features from the processed dataset, such as product purchase probability, store visit probability, basket size, etc. Figure <a href="#S4.F2" title="Figure 2 ‣ Data Analysis ‣ 4.1 Data Description and Analysis ‣ 4 Evaluation Results ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> exhibits two numeric columns on the top row, showing the skewed distributions of native feature, quantity, and derived feature, basket size, in the real-world retail transaction dataset. The distribution of quantities purchased tends to be positively skewed because most customers typically buy products in small quantities. Bulk purchases are less frequent, leading to a long tail on the right side of the distribution. The ”Basket Size” subplot shows the probability distribution of the total number of items in a customer’s basket. The distribution is right-skewed, indicating that while most transactions have a lower total basket size, a few transactions involve significantly higher total purchases. This is typical in retail, where a small number of premium customers can drive a substantial portion of revenue.</p>
</div>
<figure id="S4.F2" class="ltx_figure"><img src="/html/2406.13130/assets/assets/eda.png" id="S4.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="419" height="264" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Selected univariate distributions for dataset “Complete Journey” illustrate diverse distributional patterns encountered in real-world datasets (see section <a href="#S4.SS1.SSS0.Px2" title="Data Analysis ‣ 4.1 Data Description and Analysis ‣ 4 Evaluation Results ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>).</figcaption>
</figure>
<div id="S4.SS1.SSS0.Px2.p2" class="ltx_para">
<p id="S4.SS1.SSS0.Px2.p2.1" class="ltx_p">Similarly, the bottom row details categorical distributions for ”Customer Age”, and ”Household Size”. Our dataset has a slight concentration of customers in the middle age groups (e.g., 35-44 and 45-54), suggesting that middle-aged consumers form a large portion of the customer base. However, younger (19-24, 25-34) age groups are also well-represented. Household size describes the number of members per household. The distribution peaks at household sizes of 2 and 3, indicating that most customers come from small to medium-sized households.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2406.13130/assets/assets/basket_size_by_household_sze.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="419" height="240" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Marginal distribution of basket size by different household sizes. Customers with more family members in the household tend to buy more products in one visit (see section <a href="#S4.F3" title="Figure 3 ‣ Data Analysis ‣ 4.1 Data Description and Analysis ‣ 4 Evaluation Results ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>).</figcaption>
</figure>
<div id="S4.SS1.SSS0.Px2.p3" class="ltx_para">
<p id="S4.SS1.SSS0.Px2.p3.1" class="ltx_p">We also looked into multivariate combinations to explore relationships among the pair of columns. For example, Figure <a href="#S4.F3" title="Figure 3 ‣ Data Analysis ‣ 4.1 Data Description and Analysis ‣ 4 Evaluation Results ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> demonstrates that as household size increases, the distribution of basket sizes progressively shifts to the right. In single-member households, purchases predominantly consist of smaller basket sizes. As household size grows from two to three and onward to five plus members, the distribution begins to show a higher density of larger basket sizes. This shift to the right indicates that larger households tend to buy more in a single transaction, reflecting their greater consumption needs.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2406.13130/assets/assets/feature_correlation.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="509" height="167" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Correlation of selected numeric and categorical distributions for dataset “Complete Journey” illustrating contextual relationships observed in the real-world dataset (see Sec. <a href="#S4.F4" title="Figure 4 ‣ Data Analysis ‣ 4.1 Data Description and Analysis ‣ 4 Evaluation Results ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>).</figcaption>
</figure>
<div id="S4.SS1.SSS0.Px2.p4" class="ltx_para">
<p id="S4.SS1.SSS0.Px2.p4.1" class="ltx_p">Figure <a href="#S4.F4" title="Figure 4 ‣ Data Analysis ‣ 4.1 Data Description and Analysis ‣ 4 Evaluation Results ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows a more comprehensive view on the Pearson correlation coefficient for numerical-numerical feature relationships, Theil’s U statistic for assessing dependence between categorical-categorical features, and the correlation ratio for categorical-numerical feature associations. For example, a high positive correlation between manufacturer id (C3) and department (C4), see appendix <a href="#A1" title="Appendix A Column name mapping ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a> for a full list column mapping. Department, manufacturer, product category, product type, and package size are strongly associated with indicating a given product.</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Synthetic Data Fidelity Assessment</h3>

<section id="S4.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Distributional similarity overview</h4>

<div id="S4.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px1.p1.1" class="ltx_p">For the holdout dataset and synthetic datasets, we computed the average Wasserstein distance for numerical columns, the average Jensen-Shannon distance for categorical columns, and Euclidean distances of the Pearson correlation matrix, Theil’s U matrix, and correlation ratio matrix against the training dataset. Table <a href="#S4.T2" title="Table 2 ‣ Distributional similarity overview ‣ 4.2 Synthetic Data Fidelity Assessment ‣ 4 Evaluation Results ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> presents a comprehensive evaluation of various generative AI models for retail synthetic data generation, highlighting the diverse strengths and weaknesses of each model.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<table id="S4.T2.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T2.1.1" class="ltx_tr">
<td id="S4.T2.1.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S4.T2.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">Marginal</td>
<td id="S4.T2.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="3">Joint</td>
</tr>
<tr id="S4.T2.1.2" class="ltx_tr">
<td id="S4.T2.1.2.1" class="ltx_td"></td>
<td id="S4.T2.1.2.2" class="ltx_td ltx_align_left ltx_border_t">Num</td>
<td id="S4.T2.1.2.3" class="ltx_td ltx_align_left ltx_border_t">Cat</td>
<td id="S4.T2.1.2.4" class="ltx_td ltx_align_left ltx_border_t">Num-Num</td>
<td id="S4.T2.1.2.5" class="ltx_td ltx_align_left ltx_border_t">Cat-Cat</td>
<td id="S4.T2.1.2.6" class="ltx_td ltx_align_left ltx_border_t">Num-Cat</td>
</tr>
<tr id="S4.T2.1.3" class="ltx_tr">
<td id="S4.T2.1.3.1" class="ltx_td ltx_align_center ltx_border_t">Holdout</td>
<td id="S4.T2.1.3.2" class="ltx_td ltx_align_left ltx_border_t">0.04</td>
<td id="S4.T2.1.3.3" class="ltx_td ltx_align_left ltx_border_t">0.38</td>
<td id="S4.T2.1.3.4" class="ltx_td ltx_align_left ltx_border_t">0.45</td>
<td id="S4.T2.1.3.5" class="ltx_td ltx_align_left ltx_border_t">0.04</td>
<td id="S4.T2.1.3.6" class="ltx_td ltx_align_left ltx_border_t">0.04</td>
</tr>
<tr id="S4.T2.1.4" class="ltx_tr">
<td id="S4.T2.1.4.1" class="ltx_td ltx_align_center ltx_border_t">CTGAN</td>
<td id="S4.T2.1.4.2" class="ltx_td ltx_align_left ltx_border_t">2.24</td>
<td id="S4.T2.1.4.3" class="ltx_td ltx_align_left ltx_border_t">0.46</td>
<td id="S4.T2.1.4.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T2.1.4.4.1" class="ltx_text ltx_font_bold">0.49</span></td>
<td id="S4.T2.1.4.5" class="ltx_td ltx_align_left ltx_border_t">4.06</td>
<td id="S4.T2.1.4.6" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T2.1.4.6.1" class="ltx_text ltx_font_bold">0.75</span></td>
</tr>
<tr id="S4.T2.1.5" class="ltx_tr">
<td id="S4.T2.1.5.1" class="ltx_td ltx_align_center">AutoGAN</td>
<td id="S4.T2.1.5.2" class="ltx_td ltx_align_left">1646.88</td>
<td id="S4.T2.1.5.3" class="ltx_td ltx_align_left">0.41</td>
<td id="S4.T2.1.5.4" class="ltx_td ltx_align_left">2.13</td>
<td id="S4.T2.1.5.5" class="ltx_td ltx_align_left">8.15</td>
<td id="S4.T2.1.5.6" class="ltx_td ltx_align_left">4.28</td>
</tr>
<tr id="S4.T2.1.6" class="ltx_tr">
<td id="S4.T2.1.6.1" class="ltx_td ltx_align_center">TabDDPM</td>
<td id="S4.T2.1.6.2" class="ltx_td ltx_align_left">5.36</td>
<td id="S4.T2.1.6.3" class="ltx_td ltx_align_left"><span id="S4.T2.1.6.3.1" class="ltx_text ltx_font_bold">0.38</span></td>
<td id="S4.T2.1.6.4" class="ltx_td ltx_align_left">0.85</td>
<td id="S4.T2.1.6.5" class="ltx_td ltx_align_left">3.79</td>
<td id="S4.T2.1.6.6" class="ltx_td ltx_align_left">1.22</td>
</tr>
<tr id="S4.T2.1.7" class="ltx_tr">
<td id="S4.T2.1.7.1" class="ltx_td ltx_align_center">StasyAutoDiff</td>
<td id="S4.T2.1.7.2" class="ltx_td ltx_align_left">7.55</td>
<td id="S4.T2.1.7.3" class="ltx_td ltx_align_left"><span id="S4.T2.1.7.3.1" class="ltx_text ltx_font_bold">0.38</span></td>
<td id="S4.T2.1.7.4" class="ltx_td ltx_align_left">1.18</td>
<td id="S4.T2.1.7.5" class="ltx_td ltx_align_left">3.89</td>
<td id="S4.T2.1.7.6" class="ltx_td ltx_align_left">1.59</td>
</tr>
<tr id="S4.T2.1.8" class="ltx_tr">
<td id="S4.T2.1.8.1" class="ltx_td ltx_align_center ltx_border_bb">TabAutoDiff</td>
<td id="S4.T2.1.8.2" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T2.1.8.2.1" class="ltx_text ltx_font_bold">2.04</span></td>
<td id="S4.T2.1.8.3" class="ltx_td ltx_align_left ltx_border_bb">0.42</td>
<td id="S4.T2.1.8.4" class="ltx_td ltx_align_left ltx_border_bb">0.63</td>
<td id="S4.T2.1.8.5" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T2.1.8.5.1" class="ltx_text ltx_font_bold">3.65</span></td>
<td id="S4.T2.1.8.6" class="ltx_td ltx_align_left ltx_border_bb">0.81</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Fidelity metrics of similarities on marginal distributions and joint distributions, analyzed in <a href="#S4.T2" title="Table 2 ‣ Distributional similarity overview ‣ 4.2 Synthetic Data Fidelity Assessment ‣ 4 Evaluation Results ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Different models have different strengths, with the best-performed model being highlighted for each metric. CTGAN and TabAutoDiff show more balanced performance from the fidelity aspect (see section <a href="#S4.T2" title="Table 2 ‣ Distributional similarity overview ‣ 4.2 Synthetic Data Fidelity Assessment ‣ 4 Evaluation Results ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).</figcaption>
</figure>
<div id="S4.SS2.SSS0.Px1.p2" class="ltx_para">
<p id="S4.SS2.SSS0.Px1.p2.1" class="ltx_p">Among the models evaluated, TabAutoDiff and CTGAN emerge as standout performers. TabAutoDiff demonstrates a consistently balanced performance across all metrics, excelling in capturing numerical marginal distributions and category-to-category joint distributions. This balanced prowess suggests TabAutoDiff’s ability to effectively replicate retail datasets’ complex, inherent patterns. CTGAN, on the other hand, excels particularly in learning number-to-number and number-to-category interactions. Both TabDDPM and SatAutoDiff models showed their strengths in learning categorical marginal distribution but failed to prove their intelligence in other distributions. We would not recommend AutoGAN from the fidelity perspective, because it did not stand out from any type of distribution examinations. . GAN models can lead to poor representation of the relationships and correlations among columns when the generator fails to capture the full diversity and complexity of the original dataset because of Mode Collapse. This can happen especially when the category columns present imbalanced distributions. However, CTGAN employs techniques like mode-specific normalization to stabilize the learning process.</p>
</div>
</section>
<section id="S4.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Marginal Distribution Visualization</h4>

<div id="S4.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px2.p1.1" class="ltx_p">We brought back features from Figure <a href="#S4.F2" title="Figure 2 ‣ Data Analysis ‣ 4.1 Data Description and Analysis ‣ 4 Evaluation Results ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and presented learned distributions from various generative models in Figure <a href="#S4.F5" title="Figure 5 ‣ Marginal Distribution Visualization ‣ 4.2 Synthetic Data Fidelity Assessment ‣ 4 Evaluation Results ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, plotting not only the feature distribution but also distributional differences between the real training data and the synthetic data. When it came to numerical features, quantity and basket size, TabAutoDiff and CTGAN were the only models that replicated the skewed distribution, though TabAutoDiff generated a small spike at the tail unexpectedly for the quantity distribution and CTGAN learned much fatter tails for both distributions. The diff plot proved These models’ robustness again, where distributional difference histograms presented bars with height near 0. All models, except StasyAutoDiff and AutoGAN, were all capable to capture the right shape of category distributions, especially when the number of unique values in one category is low. However, if the dataset contains categorical columns with dramatic variation, we should expect a more concerning model performance.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2406.13130/assets/assets/dist.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="445" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Distribution of feature columns from the training dataset, holdout dataset, and synthetic datasets, as well as the corresponding distribution difference to the one observed in the training dataset. The figure contains a primitive numerical column (Quantity), a derived numerical column (Basket Size), and primitive categorical columns (Age, Household Size), see <a href="#S4.SS2.SSS0.Px2" title="Marginal Distribution Visualization ‣ 4.2 Synthetic Data Fidelity Assessment ‣ 4 Evaluation Results ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>. Synthetic data generated by TabAutoDiff demonstrates feature distributions that closely mirror the ones of the original training dataset.</figcaption>
</figure>
</section>
<section id="S4.SS2.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Correlation Matrix Visualization</h4>

<div id="S4.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px3.p1.1" class="ltx_p">To build a more informative presentation, we specifically provided a more detailed presentation on CTGAN, which performed the best in replicating joint distributions. Though the real dataset shows a weak correlation between features, CTGAN exhibits remarkable strength in capturing both numerical interactions and mixed-type interactions in Figure <a href="#S4.F6" title="Figure 6 ‣ Correlation Matrix Visualization ‣ 4.2 Synthetic Data Fidelity Assessment ‣ 4 Evaluation Results ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, highlighting its capability to generate coherent and realistic relationships within the data. This makes CTGAN a top choice for applications where high fidelity in interaction data is critical.</p>
</div>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2406.13130/assets/assets/interaction.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="419" height="282" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Heatmap of correlation metrics for Num-Num and Num-Cat interactions in the training, holdout, and CTGAN synthetic dataset. CTGAN model can replicate the feature interaction observed in the training dataset (see section <a href="#S4.SS2.SSS0.Px3" title="Correlation Matrix Visualization ‣ 4.2 Synthetic Data Fidelity Assessment ‣ 4 Evaluation Results ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>)</figcaption>
</figure>
<div id="S4.SS2.SSS0.Px3.p2" class="ltx_para">
<p id="S4.SS2.SSS0.Px3.p2.1" class="ltx_p">Though we recommended TabAutoDiff and CTGAN from the fidelity perspective, all generative models have metrics larger than the corresponding values from the holdout dataset. This indicates that there are still hidden patterns in the training dataset that these models are not fully replicating. Synthetic data generation for retail is inherently challenging due to the high degree of heterogeneity and the dynamic nature of customer shopping preferences. Due to the complexity and challenges in synthetic data generation, generative models still have further headroom to capture the latent structure of retail datasets fully. The proposed evaluation framework is pivotal in this regard, as it provides a standardized approach to assess model stability and performance. By enabling a consistent comparison across different models and metrics, this framework aids in understanding the nuances of each model’s strengths and areas for improvement.</p>
</div>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Synthetic Data Utility Assessment</h3>

<section id="S4.SS3.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Classification Task</h4>

<div id="S4.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px1.p1.1" class="ltx_p">To evaluate the model utility, we formulate two tasks. One is a classification task to identify premium customers who buy more products in one visit, predicting whether a customer will purchase more than 10 products based on their demographics and average unit price. We trained all classifiers supported by scikit-learn <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> and reported accuracy, F1, ROC, precision and recall of the model produces the highest accuracy, Bagging Classifier <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, in Table <a href="#S4.T3" title="Table 3 ‣ Classification Task ‣ 4.3 Synthetic Data Utility Assessment ‣ 4 Evaluation Results ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Among the synthetic data models evaluated, TabAutoDiff emerges as the best-performing model for the classification task, indicating TabAutoDiff’s superior performance in generating useful synthetic data that can effectively train classification models. When comparing the utility metrics of the synthetic data generated by TabAutoDiff to those of the train and holdout datasets, it is evident that the model trained with synthetic data achieved similar performance on all metrics, which indicates the capability of synthetic data to generalize well to real data scenarios and serve as an effective proxy for real data. In this way, retailers can test marketing algorithms using synthetic data, eliminating the costs and risks of live A/B testing on real customers.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<table id="S4.T3.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T3.1.1" class="ltx_tr">
<td id="S4.T3.1.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S4.T3.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="5"><span id="S4.T3.1.1.2.1" class="ltx_text" style="font-size:90%;">Classification</span></td>
</tr>
<tr id="S4.T3.1.2" class="ltx_tr">
<td id="S4.T3.1.2.1" class="ltx_td"></td>
<td id="S4.T3.1.2.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T3.1.2.2.1" class="ltx_text" style="font-size:90%;">Accuracy</span></td>
<td id="S4.T3.1.2.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T3.1.2.3.1" class="ltx_text" style="font-size:90%;">F1</span></td>
<td id="S4.T3.1.2.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T3.1.2.4.1" class="ltx_text" style="font-size:90%;">ROC</span></td>
<td id="S4.T3.1.2.5" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T3.1.2.5.1" class="ltx_text" style="font-size:90%;">Precision</span></td>
<td id="S4.T3.1.2.6" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T3.1.2.6.1" class="ltx_text" style="font-size:90%;">Recall</span></td>
</tr>
<tr id="S4.T3.1.3" class="ltx_tr">
<td id="S4.T3.1.3.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.1.3.1.1" class="ltx_text" style="font-size:90%;">Train</span></td>
<td id="S4.T3.1.3.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T3.1.3.2.1" class="ltx_text" style="font-size:90%;">0.65</span></td>
<td id="S4.T3.1.3.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T3.1.3.3.1" class="ltx_text" style="font-size:90%;">0.62</span></td>
<td id="S4.T3.1.3.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T3.1.3.4.1" class="ltx_text" style="font-size:90%;">0.67</span></td>
<td id="S4.T3.1.3.5" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T3.1.3.5.1" class="ltx_text" style="font-size:90%;">0.52</span></td>
<td id="S4.T3.1.3.6" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T3.1.3.6.1" class="ltx_text" style="font-size:90%;">0.76</span></td>
</tr>
<tr id="S4.T3.1.4" class="ltx_tr">
<td id="S4.T3.1.4.1" class="ltx_td ltx_align_center"><span id="S4.T3.1.4.1.1" class="ltx_text" style="font-size:90%;">Holdout</span></td>
<td id="S4.T3.1.4.2" class="ltx_td ltx_align_left"><span id="S4.T3.1.4.2.1" class="ltx_text" style="font-size:90%;">0.66</span></td>
<td id="S4.T3.1.4.3" class="ltx_td ltx_align_left"><span id="S4.T3.1.4.3.1" class="ltx_text" style="font-size:90%;">0.62</span></td>
<td id="S4.T3.1.4.4" class="ltx_td ltx_align_left"><span id="S4.T3.1.4.4.1" class="ltx_text" style="font-size:90%;">0.68</span></td>
<td id="S4.T3.1.4.5" class="ltx_td ltx_align_left"><span id="S4.T3.1.4.5.1" class="ltx_text" style="font-size:90%;">0.52</span></td>
<td id="S4.T3.1.4.6" class="ltx_td ltx_align_left"><span id="S4.T3.1.4.6.1" class="ltx_text" style="font-size:90%;">0.77</span></td>
</tr>
<tr id="S4.T3.1.5" class="ltx_tr">
<td id="S4.T3.1.5.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.1.5.1.1" class="ltx_text" style="font-size:90%;">CTGAN</span></td>
<td id="S4.T3.1.5.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T3.1.5.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.68</span></td>
<td id="S4.T3.1.5.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T3.1.5.3.1" class="ltx_text" style="font-size:90%;">0.40</span></td>
<td id="S4.T3.1.5.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T3.1.5.4.1" class="ltx_text" style="font-size:90%;">0.60</span></td>
<td id="S4.T3.1.5.5" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T3.1.5.5.1" class="ltx_text" style="font-size:90%;">0.63</span></td>
<td id="S4.T3.1.5.6" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T3.1.5.6.1" class="ltx_text" style="font-size:90%;">0.29</span></td>
</tr>
<tr id="S4.T3.1.6" class="ltx_tr">
<td id="S4.T3.1.6.1" class="ltx_td ltx_align_center"><span id="S4.T3.1.6.1.1" class="ltx_text" style="font-size:90%;">AutoGAN</span></td>
<td id="S4.T3.1.6.2" class="ltx_td ltx_align_left"><span id="S4.T3.1.6.2.1" class="ltx_text" style="font-size:90%;">0.38</span></td>
<td id="S4.T3.1.6.3" class="ltx_td ltx_align_left"><span id="S4.T3.1.6.3.1" class="ltx_text" style="font-size:90%;">0.53</span></td>
<td id="S4.T3.1.6.4" class="ltx_td ltx_align_left"><span id="S4.T3.1.6.4.1" class="ltx_text" style="font-size:90%;">0.50</span></td>
<td id="S4.T3.1.6.5" class="ltx_td ltx_align_left"><span id="S4.T3.1.6.5.1" class="ltx_text" style="font-size:90%;">0.37</span></td>
<td id="S4.T3.1.6.6" class="ltx_td ltx_align_left"><span id="S4.T3.1.6.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.96</span></td>
</tr>
<tr id="S4.T3.1.7" class="ltx_tr">
<td id="S4.T3.1.7.1" class="ltx_td ltx_align_center"><span id="S4.T3.1.7.1.1" class="ltx_text" style="font-size:90%;">TabDDPM</span></td>
<td id="S4.T3.1.7.2" class="ltx_td ltx_align_left"><span id="S4.T3.1.7.2.1" class="ltx_text" style="font-size:90%;">0.63</span></td>
<td id="S4.T3.1.7.3" class="ltx_td ltx_align_left"><span id="S4.T3.1.7.3.1" class="ltx_text" style="font-size:90%;">0.11</span></td>
<td id="S4.T3.1.7.4" class="ltx_td ltx_align_left"><span id="S4.T3.1.7.4.1" class="ltx_text" style="font-size:90%;">0.51</span></td>
<td id="S4.T3.1.7.5" class="ltx_td ltx_align_left"><span id="S4.T3.1.7.5.1" class="ltx_text" style="font-size:90%;">0.52</span></td>
<td id="S4.T3.1.7.6" class="ltx_td ltx_align_left"><span id="S4.T3.1.7.6.1" class="ltx_text" style="font-size:90%;">0.06</span></td>
</tr>
<tr id="S4.T3.1.8" class="ltx_tr">
<td id="S4.T3.1.8.1" class="ltx_td ltx_align_center"><span id="S4.T3.1.8.1.1" class="ltx_text" style="font-size:90%;">StasyAutoDiff</span></td>
<td id="S4.T3.1.8.2" class="ltx_td ltx_align_left"><span id="S4.T3.1.8.2.1" class="ltx_text" style="font-size:90%;">0.62</span></td>
<td id="S4.T3.1.8.3" class="ltx_td ltx_align_left"><span id="S4.T3.1.8.3.1" class="ltx_text" style="font-size:90%;">0.16</span></td>
<td id="S4.T3.1.8.4" class="ltx_td ltx_align_left"><span id="S4.T3.1.8.4.1" class="ltx_text" style="font-size:90%;">0.51</span></td>
<td id="S4.T3.1.8.5" class="ltx_td ltx_align_left"><span id="S4.T3.1.8.5.1" class="ltx_text" style="font-size:90%;">0.45</span></td>
<td id="S4.T3.1.8.6" class="ltx_td ltx_align_left"><span id="S4.T3.1.8.6.1" class="ltx_text" style="font-size:90%;">0.10</span></td>
</tr>
<tr id="S4.T3.1.9" class="ltx_tr">
<td id="S4.T3.1.9.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.1.9.1.1" class="ltx_text" style="font-size:90%;">TabAutoDiff</span></td>
<td id="S4.T3.1.9.2" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T3.1.9.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.68</span></td>
<td id="S4.T3.1.9.3" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T3.1.9.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.52</span></td>
<td id="S4.T3.1.9.4" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T3.1.9.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.64</span></td>
<td id="S4.T3.1.9.5" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T3.1.9.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.59</span></td>
<td id="S4.T3.1.9.6" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T3.1.9.6.1" class="ltx_text" style="font-size:90%;">0.47</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 3: </span>Utility metrics on a classification task. TabAutoDiff model achieves the best performance from the utility aspect as it scores high on accuracy, F1, ROC, and precision. See detailed description in Sec.<a href="#S4.SS3.SSS0.Px1" title="Classification Task ‣ 4.3 Synthetic Data Utility Assessment ‣ 4 Evaluation Results ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a></figcaption>
</figure>
</section>
<section id="S4.SS3.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Product Association Analysis</h4>

<div id="S4.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px2.p1.1" class="ltx_p">The other task is to analyze product association in the training, holdout and synthetic datasets. We performed market basket analysis at the product level to see if there is a significant affinity for products to be purchased together using the Apriori algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>, a popular method used in data mining for extracting such association rules. Table <a href="#S4.T4" title="Table 4 ‣ Product Association Analysis ‣ 4.3 Synthetic Data Utility Assessment ‣ 4 Evaluation Results ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> presents the Lift metric, a measure of the likelihood that product B is bought when product A is bought, and the Conviction metric, which compares the probability that A appears without B if they were independent vs the actual frequency of A’s appearance without B.</p>
</div>
<div id="S4.SS3.SSS0.Px2.p2" class="ltx_para">
<table id="A1.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S4.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.E1.m1.1" class="ltx_Math" alttext="\displaystyle Confidence(A\rightarrow B)" display="inline"><semantics id="S4.E1.m1.1a"><mrow id="S4.E1.m1.1.1" xref="S4.E1.m1.1.1.cmml"><mi id="S4.E1.m1.1.1.3" xref="S4.E1.m1.1.1.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.2" xref="S4.E1.m1.1.1.2.cmml">​</mo><mi id="S4.E1.m1.1.1.4" xref="S4.E1.m1.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.2a" xref="S4.E1.m1.1.1.2.cmml">​</mo><mi id="S4.E1.m1.1.1.5" xref="S4.E1.m1.1.1.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.2b" xref="S4.E1.m1.1.1.2.cmml">​</mo><mi id="S4.E1.m1.1.1.6" xref="S4.E1.m1.1.1.6.cmml">f</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.2c" xref="S4.E1.m1.1.1.2.cmml">​</mo><mi id="S4.E1.m1.1.1.7" xref="S4.E1.m1.1.1.7.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.2d" xref="S4.E1.m1.1.1.2.cmml">​</mo><mi id="S4.E1.m1.1.1.8" xref="S4.E1.m1.1.1.8.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.2e" xref="S4.E1.m1.1.1.2.cmml">​</mo><mi id="S4.E1.m1.1.1.9" xref="S4.E1.m1.1.1.9.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.2f" xref="S4.E1.m1.1.1.2.cmml">​</mo><mi id="S4.E1.m1.1.1.10" xref="S4.E1.m1.1.1.10.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.2g" xref="S4.E1.m1.1.1.2.cmml">​</mo><mi id="S4.E1.m1.1.1.11" xref="S4.E1.m1.1.1.11.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.2h" xref="S4.E1.m1.1.1.2.cmml">​</mo><mi id="S4.E1.m1.1.1.12" xref="S4.E1.m1.1.1.12.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.2i" xref="S4.E1.m1.1.1.2.cmml">​</mo><mrow id="S4.E1.m1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E1.m1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E1.m1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.cmml"><mi id="S4.E1.m1.1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.1.1.2.cmml">A</mi><mo stretchy="false" id="S4.E1.m1.1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.1.cmml">→</mo><mi id="S4.E1.m1.1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.1.1.3.cmml">B</mi></mrow><mo stretchy="false" id="S4.E1.m1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m1.1b"><apply id="S4.E1.m1.1.1.cmml" xref="S4.E1.m1.1.1"><times id="S4.E1.m1.1.1.2.cmml" xref="S4.E1.m1.1.1.2"></times><ci id="S4.E1.m1.1.1.3.cmml" xref="S4.E1.m1.1.1.3">𝐶</ci><ci id="S4.E1.m1.1.1.4.cmml" xref="S4.E1.m1.1.1.4">𝑜</ci><ci id="S4.E1.m1.1.1.5.cmml" xref="S4.E1.m1.1.1.5">𝑛</ci><ci id="S4.E1.m1.1.1.6.cmml" xref="S4.E1.m1.1.1.6">𝑓</ci><ci id="S4.E1.m1.1.1.7.cmml" xref="S4.E1.m1.1.1.7">𝑖</ci><ci id="S4.E1.m1.1.1.8.cmml" xref="S4.E1.m1.1.1.8">𝑑</ci><ci id="S4.E1.m1.1.1.9.cmml" xref="S4.E1.m1.1.1.9">𝑒</ci><ci id="S4.E1.m1.1.1.10.cmml" xref="S4.E1.m1.1.1.10">𝑛</ci><ci id="S4.E1.m1.1.1.11.cmml" xref="S4.E1.m1.1.1.11">𝑐</ci><ci id="S4.E1.m1.1.1.12.cmml" xref="S4.E1.m1.1.1.12">𝑒</ci><apply id="S4.E1.m1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1"><ci id="S4.E1.m1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1">→</ci><ci id="S4.E1.m1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.1.1.2">𝐴</ci><ci id="S4.E1.m1.1.1.1.1.1.3.cmml" xref="S4.E1.m1.1.1.1.1.1.3">𝐵</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.1c">\displaystyle Confidence(A\rightarrow B)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S4.E1.m2.2" class="ltx_Math" alttext="\displaystyle={P(A\cap B)}\Big{/}P(A)" display="inline"><semantics id="S4.E1.m2.2a"><mrow id="S4.E1.m2.2.2" xref="S4.E1.m2.2.2.cmml"><mi id="S4.E1.m2.2.2.3" xref="S4.E1.m2.2.2.3.cmml"></mi><mo id="S4.E1.m2.2.2.2" xref="S4.E1.m2.2.2.2.cmml">=</mo><mrow id="S4.E1.m2.2.2.1" xref="S4.E1.m2.2.2.1.cmml"><mrow id="S4.E1.m2.2.2.1.1" xref="S4.E1.m2.2.2.1.1.cmml"><mrow id="S4.E1.m2.2.2.1.1.1" xref="S4.E1.m2.2.2.1.1.1.cmml"><mi id="S4.E1.m2.2.2.1.1.1.3" xref="S4.E1.m2.2.2.1.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S4.E1.m2.2.2.1.1.1.2" xref="S4.E1.m2.2.2.1.1.1.2.cmml">​</mo><mrow id="S4.E1.m2.2.2.1.1.1.1.1" xref="S4.E1.m2.2.2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E1.m2.2.2.1.1.1.1.1.2" xref="S4.E1.m2.2.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E1.m2.2.2.1.1.1.1.1.1" xref="S4.E1.m2.2.2.1.1.1.1.1.1.cmml"><mi id="S4.E1.m2.2.2.1.1.1.1.1.1.2" xref="S4.E1.m2.2.2.1.1.1.1.1.1.2.cmml">A</mi><mo id="S4.E1.m2.2.2.1.1.1.1.1.1.1" xref="S4.E1.m2.2.2.1.1.1.1.1.1.1.cmml">∩</mo><mi id="S4.E1.m2.2.2.1.1.1.1.1.1.3" xref="S4.E1.m2.2.2.1.1.1.1.1.1.3.cmml">B</mi></mrow><mo stretchy="false" id="S4.E1.m2.2.2.1.1.1.1.1.3" xref="S4.E1.m2.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo maxsize="160%" minsize="160%" stretchy="true" symmetric="true" id="S4.E1.m2.2.2.1.1.2" xref="S4.E1.m2.2.2.1.1.2.cmml">/</mo><mi id="S4.E1.m2.2.2.1.1.3" xref="S4.E1.m2.2.2.1.1.3.cmml">P</mi></mrow><mo lspace="0em" rspace="0em" id="S4.E1.m2.2.2.1.2" xref="S4.E1.m2.2.2.1.2.cmml">​</mo><mrow id="S4.E1.m2.2.2.1.3.2" xref="S4.E1.m2.2.2.1.cmml"><mo stretchy="false" id="S4.E1.m2.2.2.1.3.2.1" xref="S4.E1.m2.2.2.1.cmml">(</mo><mi id="S4.E1.m2.1.1" xref="S4.E1.m2.1.1.cmml">A</mi><mo stretchy="false" id="S4.E1.m2.2.2.1.3.2.2" xref="S4.E1.m2.2.2.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m2.2b"><apply id="S4.E1.m2.2.2.cmml" xref="S4.E1.m2.2.2"><eq id="S4.E1.m2.2.2.2.cmml" xref="S4.E1.m2.2.2.2"></eq><csymbol cd="latexml" id="S4.E1.m2.2.2.3.cmml" xref="S4.E1.m2.2.2.3">absent</csymbol><apply id="S4.E1.m2.2.2.1.cmml" xref="S4.E1.m2.2.2.1"><times id="S4.E1.m2.2.2.1.2.cmml" xref="S4.E1.m2.2.2.1.2"></times><apply id="S4.E1.m2.2.2.1.1.cmml" xref="S4.E1.m2.2.2.1.1"><divide id="S4.E1.m2.2.2.1.1.2.cmml" xref="S4.E1.m2.2.2.1.1.2"></divide><apply id="S4.E1.m2.2.2.1.1.1.cmml" xref="S4.E1.m2.2.2.1.1.1"><times id="S4.E1.m2.2.2.1.1.1.2.cmml" xref="S4.E1.m2.2.2.1.1.1.2"></times><ci id="S4.E1.m2.2.2.1.1.1.3.cmml" xref="S4.E1.m2.2.2.1.1.1.3">𝑃</ci><apply id="S4.E1.m2.2.2.1.1.1.1.1.1.cmml" xref="S4.E1.m2.2.2.1.1.1.1.1"><intersect id="S4.E1.m2.2.2.1.1.1.1.1.1.1.cmml" xref="S4.E1.m2.2.2.1.1.1.1.1.1.1"></intersect><ci id="S4.E1.m2.2.2.1.1.1.1.1.1.2.cmml" xref="S4.E1.m2.2.2.1.1.1.1.1.1.2">𝐴</ci><ci id="S4.E1.m2.2.2.1.1.1.1.1.1.3.cmml" xref="S4.E1.m2.2.2.1.1.1.1.1.1.3">𝐵</ci></apply></apply><ci id="S4.E1.m2.2.2.1.1.3.cmml" xref="S4.E1.m2.2.2.1.1.3">𝑃</ci></apply><ci id="S4.E1.m2.1.1.cmml" xref="S4.E1.m2.1.1">𝐴</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m2.2c">\displaystyle={P(A\cap B)}\Big{/}P(A)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
<tbody id="S4.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.E2.m1.1" class="ltx_Math" alttext="\displaystyle Lift(A\rightarrow B)" display="inline"><semantics id="S4.E2.m1.1a"><mrow id="S4.E2.m1.1.1" xref="S4.E2.m1.1.1.cmml"><mi id="S4.E2.m1.1.1.3" xref="S4.E2.m1.1.1.3.cmml">L</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.2" xref="S4.E2.m1.1.1.2.cmml">​</mo><mi id="S4.E2.m1.1.1.4" xref="S4.E2.m1.1.1.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.2a" xref="S4.E2.m1.1.1.2.cmml">​</mo><mi id="S4.E2.m1.1.1.5" xref="S4.E2.m1.1.1.5.cmml">f</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.2b" xref="S4.E2.m1.1.1.2.cmml">​</mo><mi id="S4.E2.m1.1.1.6" xref="S4.E2.m1.1.1.6.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.2c" xref="S4.E2.m1.1.1.2.cmml">​</mo><mrow id="S4.E2.m1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E2.m1.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E2.m1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.cmml"><mi id="S4.E2.m1.1.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.1.2.cmml">A</mi><mo stretchy="false" id="S4.E2.m1.1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.1.cmml">→</mo><mi id="S4.E2.m1.1.1.1.1.1.3" xref="S4.E2.m1.1.1.1.1.1.3.cmml">B</mi></mrow><mo stretchy="false" id="S4.E2.m1.1.1.1.1.3" xref="S4.E2.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.1b"><apply id="S4.E2.m1.1.1.cmml" xref="S4.E2.m1.1.1"><times id="S4.E2.m1.1.1.2.cmml" xref="S4.E2.m1.1.1.2"></times><ci id="S4.E2.m1.1.1.3.cmml" xref="S4.E2.m1.1.1.3">𝐿</ci><ci id="S4.E2.m1.1.1.4.cmml" xref="S4.E2.m1.1.1.4">𝑖</ci><ci id="S4.E2.m1.1.1.5.cmml" xref="S4.E2.m1.1.1.5">𝑓</ci><ci id="S4.E2.m1.1.1.6.cmml" xref="S4.E2.m1.1.1.6">𝑡</ci><apply id="S4.E2.m1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1"><ci id="S4.E2.m1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1">→</ci><ci id="S4.E2.m1.1.1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.1.1.2">𝐴</ci><ci id="S4.E2.m1.1.1.1.1.1.3.cmml" xref="S4.E2.m1.1.1.1.1.1.3">𝐵</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.1c">\displaystyle Lift(A\rightarrow B)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S4.E2.m2.2" class="ltx_Math" alttext="\displaystyle={Confidence(A\rightarrow B)}\Big{/}P(B)" display="inline"><semantics id="S4.E2.m2.2a"><mrow id="S4.E2.m2.2.2" xref="S4.E2.m2.2.2.cmml"><mi id="S4.E2.m2.2.2.3" xref="S4.E2.m2.2.2.3.cmml"></mi><mo id="S4.E2.m2.2.2.2" xref="S4.E2.m2.2.2.2.cmml">=</mo><mrow id="S4.E2.m2.2.2.1" xref="S4.E2.m2.2.2.1.cmml"><mrow id="S4.E2.m2.2.2.1.1" xref="S4.E2.m2.2.2.1.1.cmml"><mrow id="S4.E2.m2.2.2.1.1.1" xref="S4.E2.m2.2.2.1.1.1.cmml"><mi id="S4.E2.m2.2.2.1.1.1.3" xref="S4.E2.m2.2.2.1.1.1.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S4.E2.m2.2.2.1.1.1.2" xref="S4.E2.m2.2.2.1.1.1.2.cmml">​</mo><mi id="S4.E2.m2.2.2.1.1.1.4" xref="S4.E2.m2.2.2.1.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.E2.m2.2.2.1.1.1.2a" xref="S4.E2.m2.2.2.1.1.1.2.cmml">​</mo><mi id="S4.E2.m2.2.2.1.1.1.5" xref="S4.E2.m2.2.2.1.1.1.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.E2.m2.2.2.1.1.1.2b" xref="S4.E2.m2.2.2.1.1.1.2.cmml">​</mo><mi id="S4.E2.m2.2.2.1.1.1.6" xref="S4.E2.m2.2.2.1.1.1.6.cmml">f</mi><mo lspace="0em" rspace="0em" id="S4.E2.m2.2.2.1.1.1.2c" xref="S4.E2.m2.2.2.1.1.1.2.cmml">​</mo><mi id="S4.E2.m2.2.2.1.1.1.7" xref="S4.E2.m2.2.2.1.1.1.7.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.E2.m2.2.2.1.1.1.2d" xref="S4.E2.m2.2.2.1.1.1.2.cmml">​</mo><mi id="S4.E2.m2.2.2.1.1.1.8" xref="S4.E2.m2.2.2.1.1.1.8.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.E2.m2.2.2.1.1.1.2e" xref="S4.E2.m2.2.2.1.1.1.2.cmml">​</mo><mi id="S4.E2.m2.2.2.1.1.1.9" xref="S4.E2.m2.2.2.1.1.1.9.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.E2.m2.2.2.1.1.1.2f" xref="S4.E2.m2.2.2.1.1.1.2.cmml">​</mo><mi id="S4.E2.m2.2.2.1.1.1.10" xref="S4.E2.m2.2.2.1.1.1.10.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.E2.m2.2.2.1.1.1.2g" xref="S4.E2.m2.2.2.1.1.1.2.cmml">​</mo><mi id="S4.E2.m2.2.2.1.1.1.11" xref="S4.E2.m2.2.2.1.1.1.11.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.E2.m2.2.2.1.1.1.2h" xref="S4.E2.m2.2.2.1.1.1.2.cmml">​</mo><mi id="S4.E2.m2.2.2.1.1.1.12" xref="S4.E2.m2.2.2.1.1.1.12.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.E2.m2.2.2.1.1.1.2i" xref="S4.E2.m2.2.2.1.1.1.2.cmml">​</mo><mrow id="S4.E2.m2.2.2.1.1.1.1.1" xref="S4.E2.m2.2.2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E2.m2.2.2.1.1.1.1.1.2" xref="S4.E2.m2.2.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E2.m2.2.2.1.1.1.1.1.1" xref="S4.E2.m2.2.2.1.1.1.1.1.1.cmml"><mi id="S4.E2.m2.2.2.1.1.1.1.1.1.2" xref="S4.E2.m2.2.2.1.1.1.1.1.1.2.cmml">A</mi><mo stretchy="false" id="S4.E2.m2.2.2.1.1.1.1.1.1.1" xref="S4.E2.m2.2.2.1.1.1.1.1.1.1.cmml">→</mo><mi id="S4.E2.m2.2.2.1.1.1.1.1.1.3" xref="S4.E2.m2.2.2.1.1.1.1.1.1.3.cmml">B</mi></mrow><mo stretchy="false" id="S4.E2.m2.2.2.1.1.1.1.1.3" xref="S4.E2.m2.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo maxsize="160%" minsize="160%" stretchy="true" symmetric="true" id="S4.E2.m2.2.2.1.1.2" xref="S4.E2.m2.2.2.1.1.2.cmml">/</mo><mi id="S4.E2.m2.2.2.1.1.3" xref="S4.E2.m2.2.2.1.1.3.cmml">P</mi></mrow><mo lspace="0em" rspace="0em" id="S4.E2.m2.2.2.1.2" xref="S4.E2.m2.2.2.1.2.cmml">​</mo><mrow id="S4.E2.m2.2.2.1.3.2" xref="S4.E2.m2.2.2.1.cmml"><mo stretchy="false" id="S4.E2.m2.2.2.1.3.2.1" xref="S4.E2.m2.2.2.1.cmml">(</mo><mi id="S4.E2.m2.1.1" xref="S4.E2.m2.1.1.cmml">B</mi><mo stretchy="false" id="S4.E2.m2.2.2.1.3.2.2" xref="S4.E2.m2.2.2.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m2.2b"><apply id="S4.E2.m2.2.2.cmml" xref="S4.E2.m2.2.2"><eq id="S4.E2.m2.2.2.2.cmml" xref="S4.E2.m2.2.2.2"></eq><csymbol cd="latexml" id="S4.E2.m2.2.2.3.cmml" xref="S4.E2.m2.2.2.3">absent</csymbol><apply id="S4.E2.m2.2.2.1.cmml" xref="S4.E2.m2.2.2.1"><times id="S4.E2.m2.2.2.1.2.cmml" xref="S4.E2.m2.2.2.1.2"></times><apply id="S4.E2.m2.2.2.1.1.cmml" xref="S4.E2.m2.2.2.1.1"><divide id="S4.E2.m2.2.2.1.1.2.cmml" xref="S4.E2.m2.2.2.1.1.2"></divide><apply id="S4.E2.m2.2.2.1.1.1.cmml" xref="S4.E2.m2.2.2.1.1.1"><times id="S4.E2.m2.2.2.1.1.1.2.cmml" xref="S4.E2.m2.2.2.1.1.1.2"></times><ci id="S4.E2.m2.2.2.1.1.1.3.cmml" xref="S4.E2.m2.2.2.1.1.1.3">𝐶</ci><ci id="S4.E2.m2.2.2.1.1.1.4.cmml" xref="S4.E2.m2.2.2.1.1.1.4">𝑜</ci><ci id="S4.E2.m2.2.2.1.1.1.5.cmml" xref="S4.E2.m2.2.2.1.1.1.5">𝑛</ci><ci id="S4.E2.m2.2.2.1.1.1.6.cmml" xref="S4.E2.m2.2.2.1.1.1.6">𝑓</ci><ci id="S4.E2.m2.2.2.1.1.1.7.cmml" xref="S4.E2.m2.2.2.1.1.1.7">𝑖</ci><ci id="S4.E2.m2.2.2.1.1.1.8.cmml" xref="S4.E2.m2.2.2.1.1.1.8">𝑑</ci><ci id="S4.E2.m2.2.2.1.1.1.9.cmml" xref="S4.E2.m2.2.2.1.1.1.9">𝑒</ci><ci id="S4.E2.m2.2.2.1.1.1.10.cmml" xref="S4.E2.m2.2.2.1.1.1.10">𝑛</ci><ci id="S4.E2.m2.2.2.1.1.1.11.cmml" xref="S4.E2.m2.2.2.1.1.1.11">𝑐</ci><ci id="S4.E2.m2.2.2.1.1.1.12.cmml" xref="S4.E2.m2.2.2.1.1.1.12">𝑒</ci><apply id="S4.E2.m2.2.2.1.1.1.1.1.1.cmml" xref="S4.E2.m2.2.2.1.1.1.1.1"><ci id="S4.E2.m2.2.2.1.1.1.1.1.1.1.cmml" xref="S4.E2.m2.2.2.1.1.1.1.1.1.1">→</ci><ci id="S4.E2.m2.2.2.1.1.1.1.1.1.2.cmml" xref="S4.E2.m2.2.2.1.1.1.1.1.1.2">𝐴</ci><ci id="S4.E2.m2.2.2.1.1.1.1.1.1.3.cmml" xref="S4.E2.m2.2.2.1.1.1.1.1.1.3">𝐵</ci></apply></apply><ci id="S4.E2.m2.2.2.1.1.3.cmml" xref="S4.E2.m2.2.2.1.1.3">𝑃</ci></apply><ci id="S4.E2.m2.1.1.cmml" xref="S4.E2.m2.1.1">𝐵</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m2.2c">\displaystyle={Confidence(A\rightarrow B)}\Big{/}P(B)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
<tbody id="S4.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.E3.m1.1" class="ltx_Math" alttext="\displaystyle Conviction(A\rightarrow B)" display="inline"><semantics id="S4.E3.m1.1a"><mrow id="S4.E3.m1.1.1" xref="S4.E3.m1.1.1.cmml"><mi id="S4.E3.m1.1.1.3" xref="S4.E3.m1.1.1.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.1.1.2" xref="S4.E3.m1.1.1.2.cmml">​</mo><mi id="S4.E3.m1.1.1.4" xref="S4.E3.m1.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.1.1.2a" xref="S4.E3.m1.1.1.2.cmml">​</mo><mi id="S4.E3.m1.1.1.5" xref="S4.E3.m1.1.1.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.1.1.2b" xref="S4.E3.m1.1.1.2.cmml">​</mo><mi id="S4.E3.m1.1.1.6" xref="S4.E3.m1.1.1.6.cmml">v</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.1.1.2c" xref="S4.E3.m1.1.1.2.cmml">​</mo><mi id="S4.E3.m1.1.1.7" xref="S4.E3.m1.1.1.7.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.1.1.2d" xref="S4.E3.m1.1.1.2.cmml">​</mo><mi id="S4.E3.m1.1.1.8" xref="S4.E3.m1.1.1.8.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.1.1.2e" xref="S4.E3.m1.1.1.2.cmml">​</mo><mi id="S4.E3.m1.1.1.9" xref="S4.E3.m1.1.1.9.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.1.1.2f" xref="S4.E3.m1.1.1.2.cmml">​</mo><mi id="S4.E3.m1.1.1.10" xref="S4.E3.m1.1.1.10.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.1.1.2g" xref="S4.E3.m1.1.1.2.cmml">​</mo><mi id="S4.E3.m1.1.1.11" xref="S4.E3.m1.1.1.11.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.1.1.2h" xref="S4.E3.m1.1.1.2.cmml">​</mo><mi id="S4.E3.m1.1.1.12" xref="S4.E3.m1.1.1.12.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.1.1.2i" xref="S4.E3.m1.1.1.2.cmml">​</mo><mrow id="S4.E3.m1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E3.m1.1.1.1.1.2" xref="S4.E3.m1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E3.m1.1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.1.cmml"><mi id="S4.E3.m1.1.1.1.1.1.2" xref="S4.E3.m1.1.1.1.1.1.2.cmml">A</mi><mo stretchy="false" id="S4.E3.m1.1.1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.1.1.cmml">→</mo><mi id="S4.E3.m1.1.1.1.1.1.3" xref="S4.E3.m1.1.1.1.1.1.3.cmml">B</mi></mrow><mo stretchy="false" id="S4.E3.m1.1.1.1.1.3" xref="S4.E3.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E3.m1.1b"><apply id="S4.E3.m1.1.1.cmml" xref="S4.E3.m1.1.1"><times id="S4.E3.m1.1.1.2.cmml" xref="S4.E3.m1.1.1.2"></times><ci id="S4.E3.m1.1.1.3.cmml" xref="S4.E3.m1.1.1.3">𝐶</ci><ci id="S4.E3.m1.1.1.4.cmml" xref="S4.E3.m1.1.1.4">𝑜</ci><ci id="S4.E3.m1.1.1.5.cmml" xref="S4.E3.m1.1.1.5">𝑛</ci><ci id="S4.E3.m1.1.1.6.cmml" xref="S4.E3.m1.1.1.6">𝑣</ci><ci id="S4.E3.m1.1.1.7.cmml" xref="S4.E3.m1.1.1.7">𝑖</ci><ci id="S4.E3.m1.1.1.8.cmml" xref="S4.E3.m1.1.1.8">𝑐</ci><ci id="S4.E3.m1.1.1.9.cmml" xref="S4.E3.m1.1.1.9">𝑡</ci><ci id="S4.E3.m1.1.1.10.cmml" xref="S4.E3.m1.1.1.10">𝑖</ci><ci id="S4.E3.m1.1.1.11.cmml" xref="S4.E3.m1.1.1.11">𝑜</ci><ci id="S4.E3.m1.1.1.12.cmml" xref="S4.E3.m1.1.1.12">𝑛</ci><apply id="S4.E3.m1.1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1.1"><ci id="S4.E3.m1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1.1.1.1">→</ci><ci id="S4.E3.m1.1.1.1.1.1.2.cmml" xref="S4.E3.m1.1.1.1.1.1.2">𝐴</ci><ci id="S4.E3.m1.1.1.1.1.1.3.cmml" xref="S4.E3.m1.1.1.1.1.1.3">𝐵</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E3.m1.1c">\displaystyle Conviction(A\rightarrow B)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S4.E3.m2.3" class="ltx_Math" alttext="\displaystyle=(1-P(B))/(1-Confidence(A\rightarrow B))" display="inline"><semantics id="S4.E3.m2.3a"><mrow id="S4.E3.m2.3.3" xref="S4.E3.m2.3.3.cmml"><mi id="S4.E3.m2.3.3.4" xref="S4.E3.m2.3.3.4.cmml"></mi><mo id="S4.E3.m2.3.3.3" xref="S4.E3.m2.3.3.3.cmml">=</mo><mrow id="S4.E3.m2.3.3.2" xref="S4.E3.m2.3.3.2.cmml"><mrow id="S4.E3.m2.2.2.1.1.1" xref="S4.E3.m2.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S4.E3.m2.2.2.1.1.1.2" xref="S4.E3.m2.2.2.1.1.1.1.cmml">(</mo><mrow id="S4.E3.m2.2.2.1.1.1.1" xref="S4.E3.m2.2.2.1.1.1.1.cmml"><mn id="S4.E3.m2.2.2.1.1.1.1.2" xref="S4.E3.m2.2.2.1.1.1.1.2.cmml">1</mn><mo id="S4.E3.m2.2.2.1.1.1.1.1" xref="S4.E3.m2.2.2.1.1.1.1.1.cmml">−</mo><mrow id="S4.E3.m2.2.2.1.1.1.1.3" xref="S4.E3.m2.2.2.1.1.1.1.3.cmml"><mi id="S4.E3.m2.2.2.1.1.1.1.3.2" xref="S4.E3.m2.2.2.1.1.1.1.3.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S4.E3.m2.2.2.1.1.1.1.3.1" xref="S4.E3.m2.2.2.1.1.1.1.3.1.cmml">​</mo><mrow id="S4.E3.m2.2.2.1.1.1.1.3.3.2" xref="S4.E3.m2.2.2.1.1.1.1.3.cmml"><mo stretchy="false" id="S4.E3.m2.2.2.1.1.1.1.3.3.2.1" xref="S4.E3.m2.2.2.1.1.1.1.3.cmml">(</mo><mi id="S4.E3.m2.1.1" xref="S4.E3.m2.1.1.cmml">B</mi><mo stretchy="false" id="S4.E3.m2.2.2.1.1.1.1.3.3.2.2" xref="S4.E3.m2.2.2.1.1.1.1.3.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S4.E3.m2.2.2.1.1.1.3" xref="S4.E3.m2.2.2.1.1.1.1.cmml">)</mo></mrow><mo id="S4.E3.m2.3.3.2.3" xref="S4.E3.m2.3.3.2.3.cmml">/</mo><mrow id="S4.E3.m2.3.3.2.2.1" xref="S4.E3.m2.3.3.2.2.1.1.cmml"><mo stretchy="false" id="S4.E3.m2.3.3.2.2.1.2" xref="S4.E3.m2.3.3.2.2.1.1.cmml">(</mo><mrow id="S4.E3.m2.3.3.2.2.1.1" xref="S4.E3.m2.3.3.2.2.1.1.cmml"><mn id="S4.E3.m2.3.3.2.2.1.1.3" xref="S4.E3.m2.3.3.2.2.1.1.3.cmml">1</mn><mo id="S4.E3.m2.3.3.2.2.1.1.2" xref="S4.E3.m2.3.3.2.2.1.1.2.cmml">−</mo><mrow id="S4.E3.m2.3.3.2.2.1.1.1" xref="S4.E3.m2.3.3.2.2.1.1.1.cmml"><mi id="S4.E3.m2.3.3.2.2.1.1.1.3" xref="S4.E3.m2.3.3.2.2.1.1.1.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S4.E3.m2.3.3.2.2.1.1.1.2" xref="S4.E3.m2.3.3.2.2.1.1.1.2.cmml">​</mo><mi id="S4.E3.m2.3.3.2.2.1.1.1.4" xref="S4.E3.m2.3.3.2.2.1.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.E3.m2.3.3.2.2.1.1.1.2a" xref="S4.E3.m2.3.3.2.2.1.1.1.2.cmml">​</mo><mi id="S4.E3.m2.3.3.2.2.1.1.1.5" xref="S4.E3.m2.3.3.2.2.1.1.1.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.E3.m2.3.3.2.2.1.1.1.2b" xref="S4.E3.m2.3.3.2.2.1.1.1.2.cmml">​</mo><mi id="S4.E3.m2.3.3.2.2.1.1.1.6" xref="S4.E3.m2.3.3.2.2.1.1.1.6.cmml">f</mi><mo lspace="0em" rspace="0em" id="S4.E3.m2.3.3.2.2.1.1.1.2c" xref="S4.E3.m2.3.3.2.2.1.1.1.2.cmml">​</mo><mi id="S4.E3.m2.3.3.2.2.1.1.1.7" xref="S4.E3.m2.3.3.2.2.1.1.1.7.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.E3.m2.3.3.2.2.1.1.1.2d" xref="S4.E3.m2.3.3.2.2.1.1.1.2.cmml">​</mo><mi id="S4.E3.m2.3.3.2.2.1.1.1.8" xref="S4.E3.m2.3.3.2.2.1.1.1.8.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.E3.m2.3.3.2.2.1.1.1.2e" xref="S4.E3.m2.3.3.2.2.1.1.1.2.cmml">​</mo><mi id="S4.E3.m2.3.3.2.2.1.1.1.9" xref="S4.E3.m2.3.3.2.2.1.1.1.9.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.E3.m2.3.3.2.2.1.1.1.2f" xref="S4.E3.m2.3.3.2.2.1.1.1.2.cmml">​</mo><mi id="S4.E3.m2.3.3.2.2.1.1.1.10" xref="S4.E3.m2.3.3.2.2.1.1.1.10.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.E3.m2.3.3.2.2.1.1.1.2g" xref="S4.E3.m2.3.3.2.2.1.1.1.2.cmml">​</mo><mi id="S4.E3.m2.3.3.2.2.1.1.1.11" xref="S4.E3.m2.3.3.2.2.1.1.1.11.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.E3.m2.3.3.2.2.1.1.1.2h" xref="S4.E3.m2.3.3.2.2.1.1.1.2.cmml">​</mo><mi id="S4.E3.m2.3.3.2.2.1.1.1.12" xref="S4.E3.m2.3.3.2.2.1.1.1.12.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.E3.m2.3.3.2.2.1.1.1.2i" xref="S4.E3.m2.3.3.2.2.1.1.1.2.cmml">​</mo><mrow id="S4.E3.m2.3.3.2.2.1.1.1.1.1" xref="S4.E3.m2.3.3.2.2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E3.m2.3.3.2.2.1.1.1.1.1.2" xref="S4.E3.m2.3.3.2.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E3.m2.3.3.2.2.1.1.1.1.1.1" xref="S4.E3.m2.3.3.2.2.1.1.1.1.1.1.cmml"><mi id="S4.E3.m2.3.3.2.2.1.1.1.1.1.1.2" xref="S4.E3.m2.3.3.2.2.1.1.1.1.1.1.2.cmml">A</mi><mo stretchy="false" id="S4.E3.m2.3.3.2.2.1.1.1.1.1.1.1" xref="S4.E3.m2.3.3.2.2.1.1.1.1.1.1.1.cmml">→</mo><mi id="S4.E3.m2.3.3.2.2.1.1.1.1.1.1.3" xref="S4.E3.m2.3.3.2.2.1.1.1.1.1.1.3.cmml">B</mi></mrow><mo stretchy="false" id="S4.E3.m2.3.3.2.2.1.1.1.1.1.3" xref="S4.E3.m2.3.3.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S4.E3.m2.3.3.2.2.1.3" xref="S4.E3.m2.3.3.2.2.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E3.m2.3b"><apply id="S4.E3.m2.3.3.cmml" xref="S4.E3.m2.3.3"><eq id="S4.E3.m2.3.3.3.cmml" xref="S4.E3.m2.3.3.3"></eq><csymbol cd="latexml" id="S4.E3.m2.3.3.4.cmml" xref="S4.E3.m2.3.3.4">absent</csymbol><apply id="S4.E3.m2.3.3.2.cmml" xref="S4.E3.m2.3.3.2"><divide id="S4.E3.m2.3.3.2.3.cmml" xref="S4.E3.m2.3.3.2.3"></divide><apply id="S4.E3.m2.2.2.1.1.1.1.cmml" xref="S4.E3.m2.2.2.1.1.1"><minus id="S4.E3.m2.2.2.1.1.1.1.1.cmml" xref="S4.E3.m2.2.2.1.1.1.1.1"></minus><cn type="integer" id="S4.E3.m2.2.2.1.1.1.1.2.cmml" xref="S4.E3.m2.2.2.1.1.1.1.2">1</cn><apply id="S4.E3.m2.2.2.1.1.1.1.3.cmml" xref="S4.E3.m2.2.2.1.1.1.1.3"><times id="S4.E3.m2.2.2.1.1.1.1.3.1.cmml" xref="S4.E3.m2.2.2.1.1.1.1.3.1"></times><ci id="S4.E3.m2.2.2.1.1.1.1.3.2.cmml" xref="S4.E3.m2.2.2.1.1.1.1.3.2">𝑃</ci><ci id="S4.E3.m2.1.1.cmml" xref="S4.E3.m2.1.1">𝐵</ci></apply></apply><apply id="S4.E3.m2.3.3.2.2.1.1.cmml" xref="S4.E3.m2.3.3.2.2.1"><minus id="S4.E3.m2.3.3.2.2.1.1.2.cmml" xref="S4.E3.m2.3.3.2.2.1.1.2"></minus><cn type="integer" id="S4.E3.m2.3.3.2.2.1.1.3.cmml" xref="S4.E3.m2.3.3.2.2.1.1.3">1</cn><apply id="S4.E3.m2.3.3.2.2.1.1.1.cmml" xref="S4.E3.m2.3.3.2.2.1.1.1"><times id="S4.E3.m2.3.3.2.2.1.1.1.2.cmml" xref="S4.E3.m2.3.3.2.2.1.1.1.2"></times><ci id="S4.E3.m2.3.3.2.2.1.1.1.3.cmml" xref="S4.E3.m2.3.3.2.2.1.1.1.3">𝐶</ci><ci id="S4.E3.m2.3.3.2.2.1.1.1.4.cmml" xref="S4.E3.m2.3.3.2.2.1.1.1.4">𝑜</ci><ci id="S4.E3.m2.3.3.2.2.1.1.1.5.cmml" xref="S4.E3.m2.3.3.2.2.1.1.1.5">𝑛</ci><ci id="S4.E3.m2.3.3.2.2.1.1.1.6.cmml" xref="S4.E3.m2.3.3.2.2.1.1.1.6">𝑓</ci><ci id="S4.E3.m2.3.3.2.2.1.1.1.7.cmml" xref="S4.E3.m2.3.3.2.2.1.1.1.7">𝑖</ci><ci id="S4.E3.m2.3.3.2.2.1.1.1.8.cmml" xref="S4.E3.m2.3.3.2.2.1.1.1.8">𝑑</ci><ci id="S4.E3.m2.3.3.2.2.1.1.1.9.cmml" xref="S4.E3.m2.3.3.2.2.1.1.1.9">𝑒</ci><ci id="S4.E3.m2.3.3.2.2.1.1.1.10.cmml" xref="S4.E3.m2.3.3.2.2.1.1.1.10">𝑛</ci><ci id="S4.E3.m2.3.3.2.2.1.1.1.11.cmml" xref="S4.E3.m2.3.3.2.2.1.1.1.11">𝑐</ci><ci id="S4.E3.m2.3.3.2.2.1.1.1.12.cmml" xref="S4.E3.m2.3.3.2.2.1.1.1.12">𝑒</ci><apply id="S4.E3.m2.3.3.2.2.1.1.1.1.1.1.cmml" xref="S4.E3.m2.3.3.2.2.1.1.1.1.1"><ci id="S4.E3.m2.3.3.2.2.1.1.1.1.1.1.1.cmml" xref="S4.E3.m2.3.3.2.2.1.1.1.1.1.1.1">→</ci><ci id="S4.E3.m2.3.3.2.2.1.1.1.1.1.1.2.cmml" xref="S4.E3.m2.3.3.2.2.1.1.1.1.1.1.2">𝐴</ci><ci id="S4.E3.m2.3.3.2.2.1.1.1.1.1.1.3.cmml" xref="S4.E3.m2.3.3.2.2.1.1.1.1.1.1.3">𝐵</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E3.m2.3c">\displaystyle=(1-P(B))/(1-Confidence(A\rightarrow B))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div id="S4.SS3.SSS0.Px2.p3" class="ltx_para">
<p id="S4.SS3.SSS0.Px2.p3.2" class="ltx_p">where <math id="S4.SS3.SSS0.Px2.p3.1.m1.1" class="ltx_Math" alttext="P(A\cap B)" display="inline"><semantics id="S4.SS3.SSS0.Px2.p3.1.m1.1a"><mrow id="S4.SS3.SSS0.Px2.p3.1.m1.1.1" xref="S4.SS3.SSS0.Px2.p3.1.m1.1.1.cmml"><mi id="S4.SS3.SSS0.Px2.p3.1.m1.1.1.3" xref="S4.SS3.SSS0.Px2.p3.1.m1.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS0.Px2.p3.1.m1.1.1.2" xref="S4.SS3.SSS0.Px2.p3.1.m1.1.1.2.cmml">​</mo><mrow id="S4.SS3.SSS0.Px2.p3.1.m1.1.1.1.1" xref="S4.SS3.SSS0.Px2.p3.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS3.SSS0.Px2.p3.1.m1.1.1.1.1.2" xref="S4.SS3.SSS0.Px2.p3.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS3.SSS0.Px2.p3.1.m1.1.1.1.1.1" xref="S4.SS3.SSS0.Px2.p3.1.m1.1.1.1.1.1.cmml"><mi id="S4.SS3.SSS0.Px2.p3.1.m1.1.1.1.1.1.2" xref="S4.SS3.SSS0.Px2.p3.1.m1.1.1.1.1.1.2.cmml">A</mi><mo id="S4.SS3.SSS0.Px2.p3.1.m1.1.1.1.1.1.1" xref="S4.SS3.SSS0.Px2.p3.1.m1.1.1.1.1.1.1.cmml">∩</mo><mi id="S4.SS3.SSS0.Px2.p3.1.m1.1.1.1.1.1.3" xref="S4.SS3.SSS0.Px2.p3.1.m1.1.1.1.1.1.3.cmml">B</mi></mrow><mo stretchy="false" id="S4.SS3.SSS0.Px2.p3.1.m1.1.1.1.1.3" xref="S4.SS3.SSS0.Px2.p3.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p3.1.m1.1b"><apply id="S4.SS3.SSS0.Px2.p3.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p3.1.m1.1.1"><times id="S4.SS3.SSS0.Px2.p3.1.m1.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p3.1.m1.1.1.2"></times><ci id="S4.SS3.SSS0.Px2.p3.1.m1.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p3.1.m1.1.1.3">𝑃</ci><apply id="S4.SS3.SSS0.Px2.p3.1.m1.1.1.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p3.1.m1.1.1.1.1"><intersect id="S4.SS3.SSS0.Px2.p3.1.m1.1.1.1.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p3.1.m1.1.1.1.1.1.1"></intersect><ci id="S4.SS3.SSS0.Px2.p3.1.m1.1.1.1.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p3.1.m1.1.1.1.1.1.2">𝐴</ci><ci id="S4.SS3.SSS0.Px2.p3.1.m1.1.1.1.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p3.1.m1.1.1.1.1.1.3">𝐵</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p3.1.m1.1c">P(A\cap B)</annotation></semantics></math> is probability both products being purchased, and<math id="S4.SS3.SSS0.Px2.p3.2.m2.4" class="ltx_Math" alttext="P(A),P(B)" display="inline"><semantics id="S4.SS3.SSS0.Px2.p3.2.m2.4a"><mrow id="S4.SS3.SSS0.Px2.p3.2.m2.4.4.2" xref="S4.SS3.SSS0.Px2.p3.2.m2.4.4.3.cmml"><mrow id="S4.SS3.SSS0.Px2.p3.2.m2.3.3.1.1" xref="S4.SS3.SSS0.Px2.p3.2.m2.3.3.1.1.cmml"><mi id="S4.SS3.SSS0.Px2.p3.2.m2.3.3.1.1.2" xref="S4.SS3.SSS0.Px2.p3.2.m2.3.3.1.1.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS0.Px2.p3.2.m2.3.3.1.1.1" xref="S4.SS3.SSS0.Px2.p3.2.m2.3.3.1.1.1.cmml">​</mo><mrow id="S4.SS3.SSS0.Px2.p3.2.m2.3.3.1.1.3.2" xref="S4.SS3.SSS0.Px2.p3.2.m2.3.3.1.1.cmml"><mo stretchy="false" id="S4.SS3.SSS0.Px2.p3.2.m2.3.3.1.1.3.2.1" xref="S4.SS3.SSS0.Px2.p3.2.m2.3.3.1.1.cmml">(</mo><mi id="S4.SS3.SSS0.Px2.p3.2.m2.1.1" xref="S4.SS3.SSS0.Px2.p3.2.m2.1.1.cmml">A</mi><mo stretchy="false" id="S4.SS3.SSS0.Px2.p3.2.m2.3.3.1.1.3.2.2" xref="S4.SS3.SSS0.Px2.p3.2.m2.3.3.1.1.cmml">)</mo></mrow></mrow><mo id="S4.SS3.SSS0.Px2.p3.2.m2.4.4.2.3" xref="S4.SS3.SSS0.Px2.p3.2.m2.4.4.3.cmml">,</mo><mrow id="S4.SS3.SSS0.Px2.p3.2.m2.4.4.2.2" xref="S4.SS3.SSS0.Px2.p3.2.m2.4.4.2.2.cmml"><mi id="S4.SS3.SSS0.Px2.p3.2.m2.4.4.2.2.2" xref="S4.SS3.SSS0.Px2.p3.2.m2.4.4.2.2.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS0.Px2.p3.2.m2.4.4.2.2.1" xref="S4.SS3.SSS0.Px2.p3.2.m2.4.4.2.2.1.cmml">​</mo><mrow id="S4.SS3.SSS0.Px2.p3.2.m2.4.4.2.2.3.2" xref="S4.SS3.SSS0.Px2.p3.2.m2.4.4.2.2.cmml"><mo stretchy="false" id="S4.SS3.SSS0.Px2.p3.2.m2.4.4.2.2.3.2.1" xref="S4.SS3.SSS0.Px2.p3.2.m2.4.4.2.2.cmml">(</mo><mi id="S4.SS3.SSS0.Px2.p3.2.m2.2.2" xref="S4.SS3.SSS0.Px2.p3.2.m2.2.2.cmml">B</mi><mo stretchy="false" id="S4.SS3.SSS0.Px2.p3.2.m2.4.4.2.2.3.2.2" xref="S4.SS3.SSS0.Px2.p3.2.m2.4.4.2.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p3.2.m2.4b"><list id="S4.SS3.SSS0.Px2.p3.2.m2.4.4.3.cmml" xref="S4.SS3.SSS0.Px2.p3.2.m2.4.4.2"><apply id="S4.SS3.SSS0.Px2.p3.2.m2.3.3.1.1.cmml" xref="S4.SS3.SSS0.Px2.p3.2.m2.3.3.1.1"><times id="S4.SS3.SSS0.Px2.p3.2.m2.3.3.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p3.2.m2.3.3.1.1.1"></times><ci id="S4.SS3.SSS0.Px2.p3.2.m2.3.3.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p3.2.m2.3.3.1.1.2">𝑃</ci><ci id="S4.SS3.SSS0.Px2.p3.2.m2.1.1.cmml" xref="S4.SS3.SSS0.Px2.p3.2.m2.1.1">𝐴</ci></apply><apply id="S4.SS3.SSS0.Px2.p3.2.m2.4.4.2.2.cmml" xref="S4.SS3.SSS0.Px2.p3.2.m2.4.4.2.2"><times id="S4.SS3.SSS0.Px2.p3.2.m2.4.4.2.2.1.cmml" xref="S4.SS3.SSS0.Px2.p3.2.m2.4.4.2.2.1"></times><ci id="S4.SS3.SSS0.Px2.p3.2.m2.4.4.2.2.2.cmml" xref="S4.SS3.SSS0.Px2.p3.2.m2.4.4.2.2.2">𝑃</ci><ci id="S4.SS3.SSS0.Px2.p3.2.m2.2.2.cmml" xref="S4.SS3.SSS0.Px2.p3.2.m2.2.2">𝐵</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p3.2.m2.4c">P(A),P(B)</annotation></semantics></math> is the individual probability of purchasing product A or B accordingly.</p>
</div>
<div id="S4.SS3.SSS0.Px2.p4" class="ltx_para">
<p id="S4.SS3.SSS0.Px2.p4.1" class="ltx_p">If Lift and Conviction much larger than 1, it means that product B is likely to be bought if product A is bought. In Table <a href="#S4.T4" title="Table 4 ‣ Product Association Analysis ‣ 4.3 Synthetic Data Utility Assessment ‣ 4 Evaluation Results ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, both values for the synthetic datasets generated by AutoGAN and TabAutoDiff are significantly different from those of the Train and Holdout datasets. AutoGAN shows an exceptionally high lift and conviction values, indicating an overestimation of product pair occurrences, whereas TabAutoDiff’s lift, although lower, still does not align closely with the real datasets. The synthetic data generated by CTGAN, TabDDPM, and StasyAutoDiff did not observe any frequently purchased product pairs, indicating a fundamental gap in learning the essential co-occurrence relationships of products. This metric is invaluable for retailers as it helps identify product bundles, optimize placement strategies, and enhance cross-selling opportunities, thus leveraging consumer purchasing patterns to drive sales and customer satisfaction. By incorporating lift values, retailers can make data-driven decisions to refine their marketing and inventory strategies effectively. The evident difficulties reveal that existing generative models struggle in this aspect, which highlights the need for further refinement in replicating complex pairwise and higher-order relationships between products.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<table id="S4.T4.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T4.1.1" class="ltx_tr">
<td id="S4.T4.1.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S4.T4.1.1.2" class="ltx_td ltx_align_left ltx_border_tt">Train</td>
<td id="S4.T4.1.1.3" class="ltx_td ltx_align_left ltx_border_tt">Holdout</td>
<td id="S4.T4.1.1.4" class="ltx_td ltx_align_left ltx_border_tt">AutoGAN</td>
<td id="S4.T4.1.1.5" class="ltx_td ltx_align_left ltx_border_tt">TabAutoDiff</td>
</tr>
<tr id="S4.T4.1.2" class="ltx_tr">
<td id="S4.T4.1.2.1" class="ltx_td ltx_align_center ltx_border_t">Confidence</td>
<td id="S4.T4.1.2.2" class="ltx_td ltx_align_left ltx_border_t">0.18</td>
<td id="S4.T4.1.2.3" class="ltx_td ltx_align_left ltx_border_t">0.18</td>
<td id="S4.T4.1.2.4" class="ltx_td ltx_align_left ltx_border_t">0.99</td>
<td id="S4.T4.1.2.5" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T4.1.2.5.1" class="ltx_text ltx_font_bold">0.26</span></td>
</tr>
<tr id="S4.T4.1.3" class="ltx_tr">
<td id="S4.T4.1.3.1" class="ltx_td ltx_align_center">Lift</td>
<td id="S4.T4.1.3.2" class="ltx_td ltx_align_left">1.73</td>
<td id="S4.T4.1.3.3" class="ltx_td ltx_align_left">1.72</td>
<td id="S4.T4.1.3.4" class="ltx_td ltx_align_left">20.89</td>
<td id="S4.T4.1.3.5" class="ltx_td ltx_align_left"><span id="S4.T4.1.3.5.1" class="ltx_text ltx_font_bold">4.83</span></td>
</tr>
<tr id="S4.T4.1.4" class="ltx_tr">
<td id="S4.T4.1.4.1" class="ltx_td ltx_align_center ltx_border_bb">Conviction</td>
<td id="S4.T4.1.4.2" class="ltx_td ltx_align_left ltx_border_bb">1.10</td>
<td id="S4.T4.1.4.3" class="ltx_td ltx_align_left ltx_border_bb">1.09</td>
<td id="S4.T4.1.4.4" class="ltx_td ltx_align_left ltx_border_bb">inf</td>
<td id="S4.T4.1.4.5" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T4.1.4.5.1" class="ltx_text ltx_font_bold">1.30</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Product association analysis for the listed synthetic data. Neither of the reported models can identify a similar product association rule observed in the training dataset. See analysis for each metric in Sec.<a href="#S4.SS3.SSS0.Px2" title="Product Association Analysis ‣ 4.3 Synthetic Data Utility Assessment ‣ 4 Evaluation Results ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a></figcaption>
</figure>
</section>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Synthetic Data Privacy Assessment</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">Among the models we evaluated, TabAutoDiff showed a balanced performance in data privacy protection and model generalization. Table <a href="#S4.T5" title="Table 5 ‣ 4.4 Synthetic Data Privacy Assessment ‣ 4 Evaluation Results ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> presents privacy metrics for synthetic datasets generated by various models, focusing on the Distance to Closest Record (DCR) and the Closest Record Ratio (CCR). These metrics are crucial for assessing the privacy preservation capabilities of synthetic data, as they indicate how closely synthetic records resemble real training data points and the distribution balance, respectively.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">Analyzing the DCR metric, the holdout set has the lowest DCR value, representing the benchmark distance within the real dataset. A larger DCR is preferred as it signifies that synthetic data points are not too close to any specific real training data points, thereby enhancing privacy. Among the models evaluated, TabAutoDiff demonstrates one of the higher DCR values. This indicates that its synthetic data maintains a significant privacy distance from the real data compared to other models, and stays at a lower risk of privacy leaking compared to the holdout dataset. TabAutoDiff also achieves the lowest CCR value, suggesting that the model did not overfit with the training data, thus providing good generalizability.</p>
</div>
<figure id="S4.T5" class="ltx_table">
<table id="S4.T5.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T5.1.1" class="ltx_tr">
<td id="S4.T5.1.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S4.T5.1.1.2" class="ltx_td ltx_align_center ltx_border_tt">DCR</td>
<td id="S4.T5.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">CCR</td>
</tr>
<tr id="S4.T5.1.2" class="ltx_tr">
<td id="S4.T5.1.2.1" class="ltx_td ltx_align_center ltx_border_t">Holdout</td>
<td id="S4.T5.1.2.2" class="ltx_td ltx_align_center ltx_border_t">1.0</td>
<td id="S4.T5.1.2.3" class="ltx_td ltx_align_center ltx_border_t">-</td>
</tr>
<tr id="S4.T5.1.3" class="ltx_tr">
<td id="S4.T5.1.3.1" class="ltx_td ltx_align_center ltx_border_t">CTGAN</td>
<td id="S4.T5.1.3.2" class="ltx_td ltx_align_center ltx_border_t">4.24</td>
<td id="S4.T5.1.3.3" class="ltx_td ltx_align_center ltx_border_t">0.48</td>
</tr>
<tr id="S4.T5.1.4" class="ltx_tr">
<td id="S4.T5.1.4.1" class="ltx_td ltx_align_center">AutoGAN</td>
<td id="S4.T5.1.4.2" class="ltx_td ltx_align_center">8.82</td>
<td id="S4.T5.1.4.3" class="ltx_td ltx_align_center">0.51</td>
</tr>
<tr id="S4.T5.1.5" class="ltx_tr">
<td id="S4.T5.1.5.1" class="ltx_td ltx_align_center">TabDDPM</td>
<td id="S4.T5.1.5.2" class="ltx_td ltx_align_center">4.52</td>
<td id="S4.T5.1.5.3" class="ltx_td ltx_align_center">0.72</td>
</tr>
<tr id="S4.T5.1.6" class="ltx_tr">
<td id="S4.T5.1.6.1" class="ltx_td ltx_align_center">StasyAutoDiff</td>
<td id="S4.T5.1.6.2" class="ltx_td ltx_align_center">4.02</td>
<td id="S4.T5.1.6.3" class="ltx_td ltx_align_center">0.54</td>
</tr>
<tr id="S4.T5.1.7" class="ltx_tr">
<td id="S4.T5.1.7.1" class="ltx_td ltx_align_center ltx_border_bb">TabAutoDiff</td>
<td id="S4.T5.1.7.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T5.1.7.2.1" class="ltx_text ltx_font_bold">10.86</span></td>
<td id="S4.T5.1.7.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T5.1.7.3.1" class="ltx_text ltx_font_bold">0.45</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Privacy metrics of all tested models. TabAutoDiff stands out from the privacy aspect as it obtains the best performance in DCR and CCR. See detailed description in Sec.<a href="#S4.SS4" title="4.4 Synthetic Data Privacy Assessment ‣ 4 Evaluation Results ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a></figcaption>
</figure>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.1" class="ltx_p">The retail industry is particularly cautious with customer data due to the sensitivity and privacy issues associated with handling such information. Strict regulations and the potential for reputational damage necessitate robust privacy preservation measures. The mixed performance of different models in terms of DCR and CCR highlights the need for a nuanced choice in synthetic data generation. While DCR is critical for ensuring individual data points are not too closely replicated, CCR helps ensure data generalizability, crucial for practical use in retail analytics. Thus, TabAutodiff is the best among evaluated models from the privacy perspective.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussions</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Our comprehensive evaluation framework revealed distinct performances across various generative AI models in terms of fidelity, utility, and privacy for synthetic retail data. For fidelity, TabAutoDiff and CTGAN stood out, with TabAutoDiff demonstrating balanced performance across all metrics and CTGAN excelling in capturing joint distribution metrics, though all models showed room for improvement. In utility assessment, TabAutoDiff emerged as the top performer, effectively replicating the utility of real data in the classification task. However, none of the tested models demonstrate even a minimally acceptable performance in the product association analysis, indicating that further refinement of the model structure is necessary to achieve satisfactory results. For privacy, Distance to Closest Record (DCR) and Closest Cluster Ratio (CCR) metrics highlighted the models’ ability to anonymize data effectively and balance generalization and identified TabAutoDiff again as the best one among the tested models. The proposed evaluation framework successfully highlighted the strengths and areas for improvement of each model, promoting the development of more effective and reliable synthetic data generation techniques for the retail sector.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">Overall, our evaluation framework offers a standardized approach to assessing synthetic data generation models, facilitating consistent and transparent benchmarking. This can drive further research and development in the field, encouraging the creation of more sophisticated models capable of better capturing the complexities of retail data. To improve the evaluation framework, future research could focus on developing domain-specific metrics that capture the unique characteristics and complexities of various retail datasets, such as transactional data, inventory data, etc. Expanding the diversity and size of the datasets used for evaluation, possibly through collaboration with industry partners or data-sharing initiatives, would enhance the robustness and generalizability of the evaluation framework’s findings.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">Anticipated advancements in synthetic data generation and evaluation include the development of more sophisticated generative models or LLM models capable of capturing higher-order dependencies and dynamic patterns presented in retail data. As these models evolve, they will not only improve in faithfully replicating the complexities of consumer behaviors but also in their ability to fill gaps where real-world data might be sparse or biased. Once the model reaches a mature level of learning all the patterns that retailers care about, we can confidently say that the generative model mirrors real customer purchase behavior. This validation would open up a multitude of applications, allowing the model to be used for inference such as demand forecasting and dynamic pricing. Furthermore, the robust nature of such advanced models could be leveraged within simulation environments to develop simulated A/B testing and test variations of a product or service in a controlled and cost-effective manner. A simulation environment with reliable generative models can also bridge the gap of reinforcement learning (RL) agents deployment aimed at personalized coupon-targeting strategies and optimizing customer engagement <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. By aligning synthetic data generation advancements with these application areas, businesses can not only gain deeper insights but also implement more dynamic and responsive retail strategies</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Ahmed Alaa, Boris Van Breugel, Evgeny S Saveliev, and Mihaela van der Schaar.

</span>
<span class="ltx_bibblock">How faithful is your synthetic data? sample-level metrics for evaluating and auditing generative models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages 290–306. PMLR, 2022.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Rick L. Andrews, Imran S. Currim, and Peter S. H. Leeflang.

</span>
<span class="ltx_bibblock">A Comparison of Sales Response Predictions From Demand Models Applied to Store-Level versus Panel Data.

</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">Journal of Business &amp; Economic Statistics</span>, 29(2):319–326, April 2011.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Jason Ansel, Edward Yang, Horace He, Natalia Gimelshein, Animesh Jain, Michael Voznesensky, Bin Bao, Peter Bell, David Berard, Evgeni Burovski, Geeta Chauhan, Anjali Chourdia, Will Constable, Alban Desmaison, Zachary DeVito, Elias Ellison, Will Feng, Jiong Gong, Michael Gschwind, Brian Hirsh, Sherlock Huang, Kshiteej Kalambarkar, Laurent Kirsch, Michael Lazos, Mario Lezcano, Yanbo Liang, Jason Liang, Yinghai Lu, CK Luk, Bert Maher, Yunjie Pan, Christian Puhrsch, Matthias Reso, Mark Saroufim, Marcos Yukio Siraichi, Helen Suk, Michael Suo, Phil Tillet, Eikan Wang, Xiaodong Wang, William Wen, Shunting Zhang, Xu Zhao, Keren Zhou, Richard Zou, Ajit Mathews, Gregory Chanan, Peng Wu, and Soumith Chintala.

</span>
<span class="ltx_bibblock">PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2 (ASPLOS ’24)</span>. ACM, April 2024.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Susan Athey, Raj Chetty, Guido Imbens, and Hyunseung Kang.

</span>
<span class="ltx_bibblock">Estimating Treatment Effects using Multiple Surrogates: The Role of the Surrogate Score and the Surrogate Index, February 2020.

</span>
<span class="ltx_bibblock">arXiv:1603.09326 [econ, stat].

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Brian Belgodere, Pierre Dognin, Adam Ivankay, Igor Melnyk, Youssef Mroueh, Aleksandra Mojsilovic, Jiri Navratil, Apoorva Nitsure, Inkit Padhi, Mattia Rigotti, et al.

</span>
<span class="ltx_bibblock">Auditing and generating synthetic data with controllable trust trade-offs.

</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2304.10819</span>, 2023.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Robi Bhattacharjee, Sanjoy Dasgupta, and Kamalika Chaudhuri.

</span>
<span class="ltx_bibblock">Data-copying in generative models: a formal framework.

</span>
<span class="ltx_bibblock">In <span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages 2364–2396. PMLR, 2023.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Alexander Theodorus Petrus Boudewijn, Andrea Filippo Ferraris, Daniele Panfilo, Vanessa Cocca, Sabrina Zinutti, Karel De Schepper, and Carlo Rossi Chauvenet.

</span>
<span class="ltx_bibblock">Privacy measurements in tabular synthetic data: State of the art and future research directions.

</span>
<span class="ltx_bibblock">In <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">NeurIPS 2023 Workshop on Synthetic Data Generation with Generative AI</span>, 2023.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Leo Breiman.

</span>
<span class="ltx_bibblock">Bagging predictors.

</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">Machine learning</span>, 24:123–140, 1996.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Jop Briët and Peter Harremoës.

</span>
<span class="ltx_bibblock">Properties of classical and quantum jensen-shannon divergence.

</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">Physical review A</span>, 79(5):052311, 2009.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Dingfan Chen, Raouf Kerkouche, and Mario Fritz.

</span>
<span class="ltx_bibblock">A unified view of differentially private deep generative modeling.

</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2309.15696</span>, 2023.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Xi Chen, Zachary Owen, Clark Pixton, and David Simchi-Levi.

</span>
<span class="ltx_bibblock">A statistical learning approach to personalization in revenue management.

</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">Management Science</span>, 68(3):1923–1937, 2022.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Xi Chen, David Simchi-Levi, and Yining Wang.

</span>
<span class="ltx_bibblock">Privacy-preserving dynamic personalized pricing with demand learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">SSRN Electronic Journal</span>, 2020.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Yinan Cheng, Chi-Hua Wang, Vamsi K Potluru, Tucker Balch, and Guang Cheng.

</span>
<span class="ltx_bibblock">Downstream task-oriented generative model selections on synthetic data training for fraud detection models.

</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2401.00974</span>, 2024.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Alvise De Biasio, Andrea Montagna, Fabio Aiolli, and Nicolò Navarin.

</span>
<span class="ltx_bibblock">A systematic review of value-aware recommender systems.

</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">Expert Systems with Applications</span>, 226:120131, September 2023.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Dunnhumby.

</span>
<span class="ltx_bibblock">The Complete Journey, 2014.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Yeliz Ekinci, Füsun Ulengin, and Nimet Uray.

</span>
<span class="ltx_bibblock">Using customer lifetime value to plan optimal promotions.

</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">The Service Industries Journal</span>, 34(2):103–122, January 2014.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Sebastian Gabel and Artem Timoshenko.

</span>
<span class="ltx_bibblock">Product choice with large assortments: A scalable deep-learning model.

</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">Management Science</span>, 68(3):1808–1827, 2022.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Generative adversarial networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">Communications of the ACM</span>, 63(11):139–144, 2020.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Florimond Houssiau, James Jordon, Samuel N Cohen, Owen Daniel, Andrew Elliott, James Geddes, Callum Mole, Camila Rangel-Smith, and Lukasz Szpruch.

</span>
<span class="ltx_bibblock">Tapas: a toolbox for adversarial privacy auditing of synthetic data.

</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2211.06550</span>, 2022.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Din-Yin Hsieh, Chi-Hua Wang, and Guang Cheng.

</span>
<span class="ltx_bibblock">Improve fidelity and utility of synthetic credit card transaction time series from data-centric perspective.

</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2401.00965</span>, 2024.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Eugene Ie, Chih-wei Hsu, Martin Mladenov, Vihan Jain, Sanmit Narvekar, Jing Wang, Rui Wu, and Craig Boutilier.

</span>
<span class="ltx_bibblock">RecSim: A Configurable Simulation Platform for Recommender Systems, September 2019.

</span>
<span class="ltx_bibblock">arXiv:1909.04847 [cs, stat].

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
James Jordon, Lukasz Szpruch, Florimond Houssiau, Mirko Bottarelli, Giovanni Cherubin, Carsten Maple, Samuel N. Cohen, and Adrian Weller.

</span>
<span class="ltx_bibblock">Synthetic Data – what, why and how?, May 2022.

</span>
<span class="ltx_bibblock">arXiv:2205.03257 [cs].

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Akim Kotelnikov, Dmitry Baranchuk, Ivan Rubachev, and Artem Babenko.

</span>
<span class="ltx_bibblock">Tabddpm: Modelling tabular data with diffusion models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages 17564–17579. PMLR, 2023.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Yuantong Li, Guang Cheng, and Xiaowu Dai.

</span>
<span class="ltx_bibblock">Two-sided competing matching recommendation markets with quota and complementary preferences constraints.

</span>
<span class="ltx_bibblock">In <span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">Forty-first International Conference on Machine Learning</span>.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Yuantong Li, Guang Cheng, and Xiaowu Dai.

</span>
<span class="ltx_bibblock">Dynamic online recommendation for two-sided market with bayesian incentive compatibility.

</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2406.04374</span>, 2024.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Yuantong Li, Chi-hua Wang, Guang Cheng, and Will Wei Sun.

</span>
<span class="ltx_bibblock">Rate-optimal contextual online matching bandit.

</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2205.03699</span>, 2022.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Po-Yi Liu, Chi-Hua Wang, and Henghsiu Tsai.

</span>
<span class="ltx_bibblock">Non-stationary dynamic pricing via actor-critic information-directed pricing.

</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2208.09372</span>, 2022.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Yucong Liu, Chi-Hua Wang, and Guang Cheng.

</span>
<span class="ltx_bibblock">On the utility recovery incapability of neural net-based differential private tabular training data synthesizer under privacy deregulation.

</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2211.15809</span>, 2022.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Casey Meehan, Kamalika Chaudhuri, and Sanjoy Dasgupta.

</span>
<span class="ltx_bibblock">A three sample hypothesis test for evaluating generative models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">International Conference on Artificial Intelligence and Statistics</span>, pages 3546–3556. PMLR, 2020.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Neha Patki, Roy Wedge, and Kalyan Veeramachaneni.

</span>
<span class="ltx_bibblock">The Synthetic Data Vault.

</span>
<span class="ltx_bibblock">In <span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">2016 IEEE International Conference on Data Science and Advanced Analytics (DSAA)</span>, pages 399–410, October 2016.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay.

</span>
<span class="ltx_bibblock">Scikit-learn: Machine learning in Python.

</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">Journal of Machine Learning Research</span>, 12:2825–2830, 2011.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Michael Platzer and Thomas Reutterer.

</span>
<span class="ltx_bibblock">Holdout-based empirical assessment of mixed-type synthetic data.

</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">Frontiers in big Data</span>, 4:679939, 2021.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Pratik Ramprasad, Yuantong Li, Zhuoran Yang, Zhaoran Wang, Will Wei Sun, and Guang Cheng.

</span>
<span class="ltx_bibblock">Online bootstrap inference for policy evaluation in reinforcement learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">Journal of the American Statistical Association</span>, 118(544):2901–2914, 2023.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Sebastian Raschka.

</span>
<span class="ltx_bibblock">Mlxtend: Providing machine learning and data science utilities and extensions to python’s scientific computing stack.

</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">The Journal of Open Source Software</span>, 3(24), April 2018.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Jaime Romero, Ralf van der Lans, and Berend Wierenga.

</span>
<span class="ltx_bibblock">A Partially Hidden Markov Model of Customer Dynamics for CLV Measurement.

</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">Journal of Interactive Marketing</span>, 27(3):185–208, August 2013.

</span>
<span class="ltx_bibblock">Publisher: SAGE Publications.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Francisco J. R. Ruiz, Susan Athey, and David M. Blei.

</span>
<span class="ltx_bibblock">Shopper: A probabilistic model of consumer choice with substitutes and complements.

</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text ltx_font_italic">The Annals of Applied Statistics</span>, 14(1), March 2020.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Ludger Rüschendorf.

</span>
<span class="ltx_bibblock">The wasserstein distance and approximation theorems.

</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text ltx_font_italic">Probability Theory and Related Fields</span>, 70(1):117–129, 1985.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Mehdi SM Sajjadi, Olivier Bachem, Mario Lucic, Olivier Bousquet, and Sylvain Gelly.

</span>
<span class="ltx_bibblock">Assessing generative models via precision and recall.

</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, 31, 2018.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Marlesson R. O. Santana, Luckeciano C. Melo, Fernando H. F. Camargo, Bruno Brandão, Anderson Soares, Renan M. Oliveira, and Sandor Caetano.

</span>
<span class="ltx_bibblock">MARS-Gym: A Gym framework to model, train, and evaluate Recommender Systems for Marketplaces, September 2020.

</span>
<span class="ltx_bibblock">arXiv:2010.07035 [cs, stat].

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Sebastian Serth, Nikolai Podlesny, Marvin Bornstein, Jan Lindemann, Johanna Latt, Jan Selke, Rainer Schlosser, Martin Boissier, and Matthias Uflacker.

</span>
<span class="ltx_bibblock">An Interactive Platform to Simulate Dynamic Pricing Competition on Online Marketplaces.

</span>
<span class="ltx_bibblock">In <span id="bib.bib40.1.1" class="ltx_text ltx_font_italic">2017 IEEE 21st International Enterprise Distributed Object Computing Conference (EDOC)</span>, pages 61–66, October 2017.

</span>
<span class="ltx_bibblock">ISSN: 2325-6362.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Namjoon Suh, Xiaofeng Lin, Din-Yin Hsieh, Merhdad Honarkhah, and Guang Cheng.

</span>
<span class="ltx_bibblock">Autodiff: combining auto-encoder and diffusion model for tabular data synthesizing, 2023.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Lan Tao, Shirong Xu, Chi-Hua Wang, Namjoon Suh, and Guang Cheng.

</span>
<span class="ltx_bibblock">Discriminative estimation of total variation distance: A fidelity auditor for generative data.

</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2405.15337</span>, 2024.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Luuk Van Maasakkers, Dennis Fok, and Bas Donkers.

</span>
<span class="ltx_bibblock">Next-basket prediction in a high-dimensional setting using gated recurrent units.

</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text ltx_font_italic">Expert Systems with Applications</span>, 212:118795, 2023.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Mengting Wan, Di Wang, Matt Goldman, Matt Taddy, Justin Rao, Jie Liu, Dimitrios Lymberopoulos, and Julian McAuley.

</span>
<span class="ltx_bibblock">Modeling Consumer Preferences and Price Sensitivities from Large-Scale Grocery Shopping Transaction Logs.

</span>
<span class="ltx_bibblock">In <span id="bib.bib44.1.1" class="ltx_text ltx_font_italic">Proceedings of the 26th International Conference on World Wide Web</span>, pages 1103–1112, Perth Australia, April 2017. International World Wide Web Conferences Steering Committee.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Chi-Hua Wang and Guang Cheng.

</span>
<span class="ltx_bibblock">Badgd: A unified data-centric framework to identify gradient descent vulnerabilities.

</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2405.15979</span>, 2024.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Chi-Hua Wang, Zhanyu Wang, Will Wei Sun, and Guang Cheng.

</span>
<span class="ltx_bibblock">Online regularization toward always-valid high-dimensional dynamic pricing.

</span>
<span class="ltx_bibblock"><span id="bib.bib46.1.1" class="ltx_text ltx_font_italic">Journal of the American Statistical Association</span>, pages 1–13, 2023.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Harrison Wilde, Jack Jewson, Sebastian Vollmer, and Chris Holmes.

</span>
<span class="ltx_bibblock">Foundations of Bayesian Learning from Synthetic Data.

</span>
<span class="ltx_bibblock">In <span id="bib.bib47.1.1" class="ltx_text ltx_font_italic">Proceedings of The 24th International Conference on Artificial Intelligence and Statistics</span>, pages 541–549. PMLR, March 2021.

</span>
<span class="ltx_bibblock">ISSN: 2640-3498.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Yu Xia, Ali Arian, Sriram Narayanamoorthy, and Joshua Mabry.

</span>
<span class="ltx_bibblock">RetailSynth: Synthetic Data Generation for Retail AI Systems Evaluation, December 2023.

</span>
<span class="ltx_bibblock">arXiv:2312.14095 [cs, econ, stat].

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Yu Xia, Sriram Narayanamoorthy, Zhengyuan Zhou, and Joshua Mabry.

</span>
<span class="ltx_bibblock">Simulation-based benchmarking of reinforcement learning agents for personalized retail promotions, 2024.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Lei Xu, Maria Skoularidou, Alfredo Cuesta-Infante, and Kalyan Veeramachaneni.

</span>
<span class="ltx_bibblock">Modeling tabular data using conditional gan.

</span>
<span class="ltx_bibblock">In <span id="bib.bib50.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 2019.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Shirong Xu, Will Wei Sun, and Guang Cheng.

</span>
<span class="ltx_bibblock">Utility theory of synthetic data generation.

</span>
<span class="ltx_bibblock"><span id="bib.bib51.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.10015</span>, 2023.

</span>
</li>
</ul>
</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Column name mapping</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p">The complete journey data has relative long names for each column. For a succinct presentation of the correlation heatmap in figure <a href="#S4.F4" title="Figure 4 ‣ Data Analysis ‣ 4.1 Data Description and Analysis ‣ 4 Evaluation Results ‣ Advancing Retail Data Science: Comprehensive Evaluation of Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we created a column mapping to label numerical columns and categorical columns.</p>
</div>
<figure id="A1.T6" class="ltx_table">
<table id="A1.T6.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T6.1.1" class="ltx_tr">
<td id="A1.T6.1.1.1" class="ltx_td ltx_align_left ltx_border_tt">Raw name</td>
<td id="A1.T6.1.1.2" class="ltx_td ltx_align_center ltx_border_tt">Type</td>
<td id="A1.T6.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">Label</td>
</tr>
<tr id="A1.T6.1.2" class="ltx_tr">
<td id="A1.T6.1.2.1" class="ltx_td ltx_align_left ltx_border_t">product_id</td>
<td id="A1.T6.1.2.2" class="ltx_td ltx_align_center ltx_border_t">categorical</td>
<td id="A1.T6.1.2.3" class="ltx_td ltx_align_center ltx_border_t">C1</td>
</tr>
<tr id="A1.T6.1.3" class="ltx_tr">
<td id="A1.T6.1.3.1" class="ltx_td ltx_align_left">household_id</td>
<td id="A1.T6.1.3.2" class="ltx_td ltx_align_center">categorical</td>
<td id="A1.T6.1.3.3" class="ltx_td ltx_align_center">C2</td>
</tr>
<tr id="A1.T6.1.4" class="ltx_tr">
<td id="A1.T6.1.4.1" class="ltx_td ltx_align_left">week</td>
<td id="A1.T6.1.4.2" class="ltx_td ltx_align_center">categorical</td>
<td id="A1.T6.1.4.3" class="ltx_td ltx_align_center">C3</td>
</tr>
<tr id="A1.T6.1.5" class="ltx_tr">
<td id="A1.T6.1.5.1" class="ltx_td ltx_align_left">manufacturer_id</td>
<td id="A1.T6.1.5.2" class="ltx_td ltx_align_center">categorical</td>
<td id="A1.T6.1.5.3" class="ltx_td ltx_align_center">C4</td>
</tr>
<tr id="A1.T6.1.6" class="ltx_tr">
<td id="A1.T6.1.6.1" class="ltx_td ltx_align_left">department</td>
<td id="A1.T6.1.6.2" class="ltx_td ltx_align_center">categorical</td>
<td id="A1.T6.1.6.3" class="ltx_td ltx_align_center">C5</td>
</tr>
<tr id="A1.T6.1.7" class="ltx_tr">
<td id="A1.T6.1.7.1" class="ltx_td ltx_align_left">brand</td>
<td id="A1.T6.1.7.2" class="ltx_td ltx_align_center">categorical</td>
<td id="A1.T6.1.7.3" class="ltx_td ltx_align_center">C6</td>
</tr>
<tr id="A1.T6.1.8" class="ltx_tr">
<td id="A1.T6.1.8.1" class="ltx_td ltx_align_left">product_category</td>
<td id="A1.T6.1.8.2" class="ltx_td ltx_align_center">categorical</td>
<td id="A1.T6.1.8.3" class="ltx_td ltx_align_center">C7</td>
</tr>
<tr id="A1.T6.1.9" class="ltx_tr">
<td id="A1.T6.1.9.1" class="ltx_td ltx_align_left">product_type</td>
<td id="A1.T6.1.9.2" class="ltx_td ltx_align_center">categorical</td>
<td id="A1.T6.1.9.3" class="ltx_td ltx_align_center">C8</td>
</tr>
<tr id="A1.T6.1.10" class="ltx_tr">
<td id="A1.T6.1.10.1" class="ltx_td ltx_align_left">package_size</td>
<td id="A1.T6.1.10.2" class="ltx_td ltx_align_center">categorical</td>
<td id="A1.T6.1.10.3" class="ltx_td ltx_align_center">C9</td>
</tr>
<tr id="A1.T6.1.11" class="ltx_tr">
<td id="A1.T6.1.11.1" class="ltx_td ltx_align_left">age</td>
<td id="A1.T6.1.11.2" class="ltx_td ltx_align_center">categorical</td>
<td id="A1.T6.1.11.3" class="ltx_td ltx_align_center">C10</td>
</tr>
<tr id="A1.T6.1.12" class="ltx_tr">
<td id="A1.T6.1.12.1" class="ltx_td ltx_align_left">homeownership</td>
<td id="A1.T6.1.12.2" class="ltx_td ltx_align_center">categorical</td>
<td id="A1.T6.1.12.3" class="ltx_td ltx_align_center">C11</td>
</tr>
<tr id="A1.T6.1.13" class="ltx_tr">
<td id="A1.T6.1.13.1" class="ltx_td ltx_align_left">marital_status</td>
<td id="A1.T6.1.13.2" class="ltx_td ltx_align_center">categorical</td>
<td id="A1.T6.1.13.3" class="ltx_td ltx_align_center">C12</td>
</tr>
<tr id="A1.T6.1.14" class="ltx_tr">
<td id="A1.T6.1.14.1" class="ltx_td ltx_align_left">household_size</td>
<td id="A1.T6.1.14.2" class="ltx_td ltx_align_center">categorical</td>
<td id="A1.T6.1.14.3" class="ltx_td ltx_align_center">C13</td>
</tr>
<tr id="A1.T6.1.15" class="ltx_tr">
<td id="A1.T6.1.15.1" class="ltx_td ltx_align_left">household_comp</td>
<td id="A1.T6.1.15.2" class="ltx_td ltx_align_center">categorical</td>
<td id="A1.T6.1.15.3" class="ltx_td ltx_align_center">C14</td>
</tr>
<tr id="A1.T6.1.16" class="ltx_tr">
<td id="A1.T6.1.16.1" class="ltx_td ltx_align_left">kids_count</td>
<td id="A1.T6.1.16.2" class="ltx_td ltx_align_center">categorical</td>
<td id="A1.T6.1.16.3" class="ltx_td ltx_align_center">C15</td>
</tr>
<tr id="A1.T6.1.17" class="ltx_tr">
<td id="A1.T6.1.17.1" class="ltx_td ltx_align_left ltx_border_t">quantity</td>
<td id="A1.T6.1.17.2" class="ltx_td ltx_align_center ltx_border_t">numerical</td>
<td id="A1.T6.1.17.3" class="ltx_td ltx_align_center ltx_border_t">N1</td>
</tr>
<tr id="A1.T6.1.18" class="ltx_tr">
<td id="A1.T6.1.18.1" class="ltx_td ltx_align_left">sales_value</td>
<td id="A1.T6.1.18.2" class="ltx_td ltx_align_center">numerical</td>
<td id="A1.T6.1.18.3" class="ltx_td ltx_align_center">N2</td>
</tr>
<tr id="A1.T6.1.19" class="ltx_tr">
<td id="A1.T6.1.19.1" class="ltx_td ltx_align_left">retail_disc</td>
<td id="A1.T6.1.19.2" class="ltx_td ltx_align_center">numerical</td>
<td id="A1.T6.1.19.3" class="ltx_td ltx_align_center">N3</td>
</tr>
<tr id="A1.T6.1.20" class="ltx_tr">
<td id="A1.T6.1.20.1" class="ltx_td ltx_align_left">coupon_disc</td>
<td id="A1.T6.1.20.2" class="ltx_td ltx_align_center">numerical</td>
<td id="A1.T6.1.20.3" class="ltx_td ltx_align_center">N4</td>
</tr>
<tr id="A1.T6.1.21" class="ltx_tr">
<td id="A1.T6.1.21.1" class="ltx_td ltx_align_left">coupon_match_disc</td>
<td id="A1.T6.1.21.2" class="ltx_td ltx_align_center">numerical</td>
<td id="A1.T6.1.21.3" class="ltx_td ltx_align_center">N5</td>
</tr>
<tr id="A1.T6.1.22" class="ltx_tr">
<td id="A1.T6.1.22.1" class="ltx_td ltx_align_left ltx_border_bb">unit_price</td>
<td id="A1.T6.1.22.2" class="ltx_td ltx_align_center ltx_border_bb">numerical</td>
<td id="A1.T6.1.22.3" class="ltx_td ltx_align_center ltx_border_bb">N6</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Column name mapping to the shortened label.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<div id="A1.p2" class="ltx_para">
<p id="A1.p2.1" class="ltx_p"></p>
</div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2406.13129" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2406.13130" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2406.13130">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2406.13130" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2406.13131" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Jul  5 17:29:14 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
