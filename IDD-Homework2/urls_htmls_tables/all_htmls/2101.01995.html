<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2101.01995] Federated Learning at the Network Edge: When Not All Nodes are Created Equal</title><meta property="og:description" content="Under the federated learning paradigm, a set of nodes
can cooperatively train a machine learning model with the help of a
centralized server. Such a server is also tasked with assigning a weight
to the information rece…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Federated Learning at the Network Edge: When Not All Nodes are Created Equal">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Federated Learning at the Network Edge: When Not All Nodes are Created Equal">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2101.01995">

<!--Generated on Fri Mar  1 14:14:14 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Federated Learning at the Network Edge:
<br class="ltx_break">When Not All Nodes are
Created Equal</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Francesco Malandrino, Carla Fabiana Chiasserini
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Under the federated learning paradigm, a set of nodes
can cooperatively train a machine learning model with the help of a
centralized server. Such a server is also tasked with assigning a weight
to the information received from each node, and often also to drop
too-slow nodes from the learning process. Both decisions have major
impact on the resulting learning performance, and can interfere with
each other in counter-intuitive ways. In this paper, we focus on edge
networking scenarios and investigate existing and novel
approaches to such <span id="id1.id1.1" class="ltx_text ltx_font_italic">model-weighting</span> and <span id="id1.id1.2" class="ltx_text ltx_font_italic">node-dropping</span>
decisions. Leveraging a set of real-world experiments, we find that
popular, straightforward decision-making approaches may yield poor
performance, and that considering the quality of data in addition to its
quantity can substantially improve learning.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Federated learning (FL) is a distributed machine learning paradigm
whereby a set of <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">learning nodes</span> cooperate in training a model
(e.g., a neural network) with the assistance of a centralized <span id="S1.p1.1.2" class="ltx_text ltx_font_italic">model
server</span> and without the need to share their local data.
FL has been introduced <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> in 2015 by
Google, with the goal of leveraging the computational power of end-user
devices – most notably, smartphones – without the privacy and security
concerns arising from sharing the potentially sensitive information they
own. As discussed in Sec. <a href="#S2" title="II Federated Learning in Edge Scenarios ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>, it has since been widely adopted in
edge computing scenarios, owing to its ability to
blend device- and server-based computation, and to enable cooperation
between devices regardless of their location.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">FL includes the following high-level steps, summarized in
Fig. <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>:</p>
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">learning nodes train a local
model based on local, on-device data;</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">learning nodes send the model
parameters – and nothing else – to the server;</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">the server combines the parameters coming from different learning nodes;</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">the server sends the combined, <span id="S1.I1.i4.p1.1.1" class="ltx_text ltx_font_italic">global</span> parameters back to the learning nodes;</p>
</div>
</li>
<li id="S1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="S1.I1.i5.p1" class="ltx_para">
<p id="S1.I1.i5.p1.1" class="ltx_p">the learning nodes replace their local parameters with the global ones, and move to
a new training iteration (step 1),
till the desired accuracy is achieved.</p>
</div>
</li>
</ol>
<p id="S1.p2.2" class="ltx_p">Step 3 usually takes the
form of a <span id="S1.p2.2.1" class="ltx_text ltx_font_italic">weighted averaging</span> of the local
parameters <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>.
Weights are
assigned to individual learners and reflect the magnitude of their
(expected) contribution to the learning process; indeed, as discussed
next, properly assigned model weights is one of the main decisions
learning servers can make.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2101.01995/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="392" height="292" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Main steps of each
iteration of the federated learning paradigm:
learning nodes train their local model (1) and send the local
parameters to the server (2); the server performs a weighted averaging
of the model (3) and sends the global parameters back to the learning
nodes (4).
 </figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Originally envisioned for homogeneous nodes dealing with homogeneous datasets
(e.g., in a classification problem, datasets adequately representing all
classes), FL has also the potential to deal with <span id="S1.p3.1.1" class="ltx_text ltx_font_italic">heterogeneity</span>,
both in the capabilities of learning
nodes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> and in their local
data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. In both cases, the key is
to endow the model server with additional responsibilities: the <span id="S1.p3.1.2" class="ltx_text ltx_font_italic">weights</span> given to different local models in the averaging phase (step 3
in Fig. <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) can account for the quantity of data they are trained
upon; at the same time, if some nodes are consistently slower than
others, they can be <span id="S1.p3.1.3" class="ltx_text ltx_font_italic">dropped</span> from the learning
process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Our key observation is that these two decisions, <span id="S1.p4.1.1" class="ltx_text ltx_font_italic">model-weighting</span>
and <span id="S1.p4.1.2" class="ltx_text ltx_font_italic">node-dropping</span>, are deceptively simple, and their impact on the
overall learning process is often misunderstood and underestimated.
Many state-of-the-art works take straightforward approaches to these decisions,
which may result in poor performance under richer, more complex scenarios.
Our contribution is therefore to shed a light on the model-weighting and node-dropping decisions,
studying how they should account for the quantity <span id="S1.p4.1.3" class="ltx_text ltx_font_italic">and quality, e.g., variety,</span>
of data available to local nodes, as well as for the data processing time.
In so doing, we focus on an edge network scenario and
leverage a set of experiments using
the popular <span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter ltx_ref_self">tensorflow</span> library and the recent
Fashion-MNIST dataset.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">In the remainder of the paper, we describe federated learning in edge
scenarios and the associated challenges in Sec. <a href="#S2" title="II Federated Learning in Edge Scenarios ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>, before narrowing
the focus on model-weighting and node-dropping strategies in
Sec. <a href="#S3" title="III Model-weighting and Node-dropping Strategies in Federated Learning ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>. We then describe our experiments and results in Sec. <a href="#S4" title="IV Experiment Design and Results ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>, and
the main lessons learned in Sec. <a href="#S5" title="V Take-away Messages and Challenges ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a>, along with pointers to
further promising research directions. Finally, Sec. <a href="#S6" title="VI Conclusion ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a>
concludes the paper.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Federated Learning in Edge Scenarios</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Edge computing is a distributed paradigm
predicated upon performing the computation as close as possible to the
user nodes requesting it, i.e., at servers located at the <span id="S2.p1.1.1" class="ltx_text ltx_font_italic">edge</span> of
the network infrastructure. It also includes scenarios where user nodes themselves have
computational and/or storage capabilities, and require edge support for
coordination, or to offload the heaviest computation tasks. FL has
long been identified as an excellent match for edge computing scenarios, and many
research works aim at making it in such scenarios as efficient as
possible.
At the same time, <span id="S2.p1.1.2" class="ltx_text ltx_font_italic">communication</span> is a major issue for FL in edge scenarios. Nodes can be connected with the edge-based server in many ways and through different technologies; thus, their connectivity has a major impact on the latency incurred when sending model updates – and, indeed, on whether or not such updates are received in the first place.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Specifically, as detailed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>,
edge computing is more effective than fully-distributed, device-to-device
networks at tackling the main factors hindering the performance of FL, namely, the
different node capabilities, available data, and
unpredictable communication delays and shortages.
Narrowing its focus to node capabilities, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> aims
at choosing the set of learning nodes that results in the shortest
learning time, solving a double-edged conundrum. On the one hand, more
nodes mean that convergence can be reached in fewer iterations; on the
other hand, the duration of each iteration is determined by the slowest
node <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. In a similar spirit, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> addresses
the problem of jointly selecting the learning nodes to use for the
learning process and assigning them the wireless resources they need to
communicate effectively. Setting in a fully-decentralized <span id="S2.p2.1.1" class="ltx_text ltx_font_italic">fog</span>
scenario where no learning server may be present,
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> tackles many issues relevant to edge computing, including
device mobility and the possibility of offloading computation from a
node to another.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Shifting the focus towards the major issue of communication between FL nodes and server,
the authors of
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> seek to reduce the communication overhead of FL
by proposing a compression algorithm suited for federated learning
settings. Their algorithm outperforms existing schemes when local
datasets are heterogeneous, thus making the high-frequency communication
required by FL viable in low-bandwidth scenarios. Heterogeneous datasets
are also identified as a major problem in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, which
envisions extracting a homogeneous subset from each local dataset in
order to avoid bias and training errors.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">Following an orthogonal, more theoretical approach, several
works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> aim at characterizing the learning
performance, deriving closed-form expressions for their (expected)
training time. Such a characterization is then exploited to make optimal
or near-optimal decisions on the cooperation among nodes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>
and the equilibrium between local learning and global
updates <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. In order to obtain manageable
closed-form expressions, some of these works make simplifying
assumptions (e.g., that local datasets be homogeneous), or target
specific parameter optimization algorithms (e.g., stochastic gradient
descent).</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p">One scenario where nontrivial model-weighting decisions are routinely used is <span id="S2.p5.1.1" class="ltx_text ltx_font_italic">asynchronous</span>
FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, where nodes may join the learning process at different times and
model-weighting serves the purpose of quickly including newly-arrived nodes in the learning process.
In our case, the purpose is different, namely, to adapt model weights to the contribution each
node can give to the overall learning process, and weed out those nodes that may
have a negative impact on the learning performance.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Model-weighting and Node-dropping Strategies in Federated
Learning</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Model-weighting and node-dropping are the most fundamental decisions the
learning server can make, and arguably among the simplest to enact. At
the same time, as discussed in the following, these decisions can be
leveraged to address all the main issues of FL, either in combination
with the strategies reviewed in Sec. <a href="#S2" title="II Federated Learning in Edge Scenarios ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>, or as an alternative to them.</p>
</div>
<section id="S3.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Insufficient quantity of data</h4>

<div id="S3.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px1.p1.1" class="ltx_p">In many FL scenarios, some
learning nodes may not have enough
local data, thus
being unable to properly train their local models;
in this case,
a popular solution is <span id="S3.SS0.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_italic">augmenting</span> local
datasets. As an example,
the authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> propose to
combine actual data samples from other learning nodes in a
privacy-preserving way, and adding them to the local dataset.</p>
</div>
<div id="S3.SS0.SSS0.Px1.p2" class="ltx_para">
<p id="S3.SS0.SSS0.Px1.p2.1" class="ltx_p">In both cases, data augmentation is able to increase the quantity of
data available to learning nodes, without jeopardizing FL’s privacy
properties. On the negative side, it may increase the complexity of the
system and its overhead; furthermore, the augmented samples come from
processing of already-existing ones, hence, do not increase the total
quantity of information.</p>
</div>
<div id="S3.SS0.SSS0.Px1.p3" class="ltx_para">
<p id="S3.SS0.SSS0.Px1.p3.1" class="ltx_p">Model-weighting decisions represent an additional, simpler way to deal
with learning nodes with small local datasets. The basic
idea <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> is that model
weights shall account for the quantity of data local models are based
upon; however, as we will demonstrate next, also accounting for the
variety of such data yields even better results. In both cases, relying
on model-weighting to tackle insufficient dataset sizes has the benefit
of reducing complexity and avoid tampering with the nodes’ own data.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Non-homogeneous data</h4>

<div id="S3.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px2.p1.1" class="ltx_p">When it comes to training machine-learning algorithms, the quality of
data is as important as its quantity.
There is no universally-acknowledged definition of data quality, as it is scenario- and application-dependent. For classification applications, a high-quality dataset is expected to adequately represent all existing classes, so that the classifier can be properly trained. In this sense, quality can be expressed as the number of classes existing in a given dataset or, more formally, through entropy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.</p>
</div>
<div id="S3.SS0.SSS0.Px2.p2" class="ltx_para">
<p id="S3.SS0.SSS0.Px2.p2.1" class="ltx_p">On the other hand, non-i.i.d. data, where classes are under- or over-represented, is universally characterized as low-quality, and
has immediately been identified as one of the primary
threats to successful FL. In addition to the augmentation approaches described
earlier <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, several works propose
training the local model on a subset of the local
data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, chosen in such a way to be i.i.d.
An alternative to ignoring data is allowing all
learning nodes to use all their data, and then weight their local models
accounting for the quality of such data. Examples of this approach
include entropy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, but simpler approaches, e.g.,
counting the labels observed, can yield similarly good performance.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Nodes with different capabilities</h4>

<div id="S3.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px3.p1.1" class="ltx_p">As with other distributed learning schemes, in FL it is possible to
proceed from an iteration to the next one only when <span id="S3.SS0.SSS0.Px3.p1.1.1" class="ltx_text ltx_font_italic">all</span> learning
nodes have sent their local models, i.e., have performed step 2 in
Fig. <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. It follows that the pace of the learning process as a
whole is determined by the <span id="S3.SS0.SSS0.Px3.p1.1.2" class="ltx_text ltx_font_italic">slowest</span> learning node, which becomes an
issue when different learning nodes take very different times to perform
their iterations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Owing to the limited amount of control
that can be exerted on FL nodes, the most viable solution is often to
exclude overly-slow nodes from the learning
process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.</p>
</div>
<div id="S3.SS0.SSS0.Px3.p2" class="ltx_para">
<p id="S3.SS0.SSS0.Px3.p2.1" class="ltx_p">However, making such node-dropping decisions solely on the basis of
their response times may actually hurt the learning process; indeed,
longer response times can be associated with larger, higher-quality
local datasets, hence, with the nodes that may contribute the most to
the learning. A way to decrease the likelihood of this unwanted outcome
is to consider additional aspects in making node-dropping decisions,
e.g., the quantity and quality or variety of local data. By so doing, it
is possible to differentiate between nodes that are slow due to limited
capabilities (or poor
connectivity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>) and those that have
simply more data to process.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Experiment Design and Results</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we demonstrate how model-weighting and node-dropping
decisions can deal with heterogeneity in the quality and quantity of the
local datasets at learning nodes. Using the set of real-world
experiments described in Sec. <a href="#S4.SS1" title="IV-A Experiment setup ‣ IV Experiment Design and Results ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-A</span></span></a>, we obtain the results described
in Sec. <a href="#S4.SS2" title="IV-B Experiment results ‣ IV Experiment Design and Results ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-B</span></span></a>.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.4.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.5.2" class="ltx_text ltx_font_italic">Experiment setup</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.3" class="ltx_p"><span id="S4.SS1.p1.3.1" class="ltx_text ltx_font_bold">Dataset and neural network structure.</span>
Fashion-MNIST is a dataset released by Zalando
research and aimed at providing a more challenging, drop-in replacement
for the classic MNIST handwritten digits dataset.
Owing to the relative simplicity of the dataset, we use a relatively
small neural network for classification. Specifically, we create a dense
network with four layers, with sizes <math id="S4.SS1.p1.1.m1.4" class="ltx_Math" alttext="[28^{2},200,100,200]" display="inline"><semantics id="S4.SS1.p1.1.m1.4a"><mrow id="S4.SS1.p1.1.m1.4.4.1" xref="S4.SS1.p1.1.m1.4.4.2.cmml"><mo stretchy="false" id="S4.SS1.p1.1.m1.4.4.1.2" xref="S4.SS1.p1.1.m1.4.4.2.cmml">[</mo><msup id="S4.SS1.p1.1.m1.4.4.1.1" xref="S4.SS1.p1.1.m1.4.4.1.1.cmml"><mn id="S4.SS1.p1.1.m1.4.4.1.1.2" xref="S4.SS1.p1.1.m1.4.4.1.1.2.cmml">28</mn><mn id="S4.SS1.p1.1.m1.4.4.1.1.3" xref="S4.SS1.p1.1.m1.4.4.1.1.3.cmml">2</mn></msup><mo id="S4.SS1.p1.1.m1.4.4.1.3" xref="S4.SS1.p1.1.m1.4.4.2.cmml">,</mo><mn id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">200</mn><mo id="S4.SS1.p1.1.m1.4.4.1.4" xref="S4.SS1.p1.1.m1.4.4.2.cmml">,</mo><mn id="S4.SS1.p1.1.m1.2.2" xref="S4.SS1.p1.1.m1.2.2.cmml">100</mn><mo id="S4.SS1.p1.1.m1.4.4.1.5" xref="S4.SS1.p1.1.m1.4.4.2.cmml">,</mo><mn id="S4.SS1.p1.1.m1.3.3" xref="S4.SS1.p1.1.m1.3.3.cmml">200</mn><mo stretchy="false" id="S4.SS1.p1.1.m1.4.4.1.6" xref="S4.SS1.p1.1.m1.4.4.2.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.4b"><list id="S4.SS1.p1.1.m1.4.4.2.cmml" xref="S4.SS1.p1.1.m1.4.4.1"><apply id="S4.SS1.p1.1.m1.4.4.1.1.cmml" xref="S4.SS1.p1.1.m1.4.4.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.4.4.1.1.1.cmml" xref="S4.SS1.p1.1.m1.4.4.1.1">superscript</csymbol><cn type="integer" id="S4.SS1.p1.1.m1.4.4.1.1.2.cmml" xref="S4.SS1.p1.1.m1.4.4.1.1.2">28</cn><cn type="integer" id="S4.SS1.p1.1.m1.4.4.1.1.3.cmml" xref="S4.SS1.p1.1.m1.4.4.1.1.3">2</cn></apply><cn type="integer" id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">200</cn><cn type="integer" id="S4.SS1.p1.1.m1.2.2.cmml" xref="S4.SS1.p1.1.m1.2.2">100</cn><cn type="integer" id="S4.SS1.p1.1.m1.3.3.cmml" xref="S4.SS1.p1.1.m1.3.3">200</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.4c">[28^{2},200,100,200]</annotation></semantics></math> neurons
(notice that the size of the first layer must match the size of the
input, i.e., <math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="28\times 28" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><mrow id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml"><mn id="S4.SS1.p1.2.m2.1.1.2" xref="S4.SS1.p1.2.m2.1.1.2.cmml">28</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p1.2.m2.1.1.1" xref="S4.SS1.p1.2.m2.1.1.1.cmml">×</mo><mn id="S4.SS1.p1.2.m2.1.1.3" xref="S4.SS1.p1.2.m2.1.1.3.cmml">28</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><apply id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1"><times id="S4.SS1.p1.2.m2.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1.1"></times><cn type="integer" id="S4.SS1.p1.2.m2.1.1.2.cmml" xref="S4.SS1.p1.2.m2.1.1.2">28</cn><cn type="integer" id="S4.SS1.p1.2.m2.1.1.3.cmml" xref="S4.SS1.p1.2.m2.1.1.3">28</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">28\times 28</annotation></semantics></math> pixels). Neurons use the <span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter ltx_ref_self">softmax</span>
activation function, and parameters are optimized using stochastic
gradient descent (SGD), with a learning rate of <math id="S4.SS1.p1.3.m3.1" class="ltx_Math" alttext="10^{-2}" display="inline"><semantics id="S4.SS1.p1.3.m3.1a"><msup id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml"><mn id="S4.SS1.p1.3.m3.1.1.2" xref="S4.SS1.p1.3.m3.1.1.2.cmml">10</mn><mrow id="S4.SS1.p1.3.m3.1.1.3" xref="S4.SS1.p1.3.m3.1.1.3.cmml"><mo id="S4.SS1.p1.3.m3.1.1.3a" xref="S4.SS1.p1.3.m3.1.1.3.cmml">−</mo><mn id="S4.SS1.p1.3.m3.1.1.3.2" xref="S4.SS1.p1.3.m3.1.1.3.2.cmml">2</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><apply id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.3.m3.1.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1">superscript</csymbol><cn type="integer" id="S4.SS1.p1.3.m3.1.1.2.cmml" xref="S4.SS1.p1.3.m3.1.1.2">10</cn><apply id="S4.SS1.p1.3.m3.1.1.3.cmml" xref="S4.SS1.p1.3.m3.1.1.3"><minus id="S4.SS1.p1.3.m3.1.1.3.1.cmml" xref="S4.SS1.p1.3.m3.1.1.3"></minus><cn type="integer" id="S4.SS1.p1.3.m3.1.1.3.2.cmml" xref="S4.SS1.p1.3.m3.1.1.3.2">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">10^{-2}</annotation></semantics></math>. The network
is implemented using the popular <span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter ltx_ref_self">tensorflow</span> library, originally
developed by Google.</p>
</div>
<figure id="S4.F2" class="ltx_figure"><img src="/html/2101.01995/assets/x2.png" id="S4.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="437" height="292" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Relationship between elapsed time and global accuracy for
different model-weighting strategies, when no nodes are dropped from the
learning process.
The color of markers corresponds to the category
of the slowest node in that particular iteration
(gold: yellow, bronze: orange, no other category appears).


</figcaption>
</figure>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">Network scenario and local datasets.</span>
Our experiments feature a typical medium-scale edge scenario <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>,
with 20 learning nodes connected with, and coordinated by, an edge-based server.
Five out of 20 nodes belong to each of the following
four categories so that the total amount of data remains constant:</p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p"><span id="S4.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">gold</span>, having 500 samples each,
representing all 10 classes (i.e., articles of clothing) present in the
Fashion-MNIST dataset;</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p"><span id="S4.I1.i2.p1.1.1" class="ltx_text ltx_font_italic">silver</span>, with 200 samples each, still
belonging to all classes;</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p"><span id="S4.I1.i3.p1.1.1" class="ltx_text ltx_font_italic">bronze</span>, with 500 samples each,
belonging to only two classes per node;</p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p id="S4.I1.i4.p1.1" class="ltx_p"><span id="S4.I1.i4.p1.1.1" class="ltx_text ltx_font_italic">garbage</span>, with
200 samples each, belonging to two classes.</p>
</div>
</li>
</ul>
<p id="S4.SS1.p2.2" class="ltx_p">With the exception of “gold” ones, nodes suffer from either low quantity or
low diversity, hence, low quality,
of local data. Our experiments establish a correlation between
the category of each node and its contribution to the learning process,
thus allowing us to identify the best strategies to decide whether and how to
integrate each node in the learning process.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p"><span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_bold">Model-weighting and node-dropping strategies.</span>
As discussed in Sec. <a href="#S3" title="III Model-weighting and Node-dropping Strategies in Federated Learning ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>, the weights assigned to local models
during the averaging phase (step 3 of Fig. <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) can account for
the quality and/or quantity of their local data. Specifically, we
consider the following options:</p>
<ul id="S4.I2" class="ltx_itemize">
<li id="S4.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i1.p1" class="ltx_para">
<p id="S4.I2.i1.p1.1" class="ltx_p"><span id="S4.I2.i1.p1.1.1" class="ltx_text ltx_font_italic">uniform</span>: all
local models are given equal weight;</p>
</div>
</li>
<li id="S4.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i2.p1" class="ltx_para">
<p id="S4.I2.i2.p1.1" class="ltx_p"><span id="S4.I2.i2.p1.1.1" class="ltx_text ltx_font_italic">no. samples</span>: weights
are proportional to the number of samples in each local dataset;</p>
</div>
</li>
<li id="S4.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i3.p1" class="ltx_para">
<p id="S4.I2.i3.p1.1" class="ltx_p"><span id="S4.I2.i3.p1.1.1" class="ltx_text ltx_font_italic">no. classes</span>: weights are proportional to the number of classes in
each local dataset;</p>
</div>
</li>
<li id="S4.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i4.p1" class="ltx_para">
<p id="S4.I2.i4.p1.1" class="ltx_p"><span id="S4.I2.i4.p1.1.1" class="ltx_text ltx_font_italic">entropy</span>:
weights are proportional to the <span id="S4.I2.i4.p1.1.2" class="ltx_text ltx_font_italic">entropy</span> of local data, an information-theoretic metric expressing, intuitively, how difficult it is to predict the class of a randomly-chosen local sample.</p>
</div>
</li>
</ul>
<p id="S4.SS1.p3.2" class="ltx_p">The “samples” strategy
accounts for the quantity of local data, the “classes” one for its
quality, and the “entropy” one for both. “Uniform”, where all
weights are equal, is added as a benchmark.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p">For node-dropping, we assume that five learning nodes are dropped after
iteration 1, and compare the state-of-the-art strategy of dropping the
slowest nodes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> against the
alternative one of dropping the nodes with the lowest weight. The
rationale behind the latter strategy is that weights are linked to how
significant the contribution that nodes can give to the learning process is, thus,
dropping the lowest-weight nodes can reduce learning times without
impairing the learning quality.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2101.01995/assets/x3.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="437" height="280" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Relationship between the average per-node learning time and
the local accuracy gain for different categories of nodes (identified by
the color of markers), under different model-weighting strategies (identified
by the shape of markers).</figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.4.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.5.2" class="ltx_text ltx_font_italic">Experiment results</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">The first aspect of interest is the progress of the overall learning,
i.e., the accuracy of the <span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_italic">global</span>, averaged model (step 3 of Fig. <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>),
portrayed in Fig. <a href="#S4.F2" title="Figure 2 ‣ IV-A Experiment setup ‣ IV Experiment Design and Results ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Each marker therein represents the state of
the learning process after an iteration: its position along the x- and
y-axis represent (respectively) the elapsed time and the global
classification accuracy, while its color corresponds to the category of the
slowest node in that particular iteration. Different lines correspond to
different model-weighting strategies.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">We can immediately observe that iteration times do not differ
substantially across model-weighting strategies, and that they are
usually determined by “gold” or “bronze” nodes – which makes
intuitive sense, as those nodes have the largest local datasets. Even
more interestingly, we can observe a clear difference in the
classification accuracy obtained by different weighting strategies:
giving the same weight to all nodes, or only accounting for the size of
the local datasets, results in a lower accuracy than accounting for data
quality. Furthermore, there is little difference between the “no.
classes” and “entropy” strategies, suggesting that simply counting
the observed classes can be as effective as adopting more complex
metrics.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">Next, Fig. <a href="#S4.F3" title="Figure 3 ‣ IV-A Experiment setup ‣ IV Experiment Design and Results ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> displays the relationship between the time taken by
local learning iterations and the
local accuracy gain, i.e., the improvement in classification accuracy obtained during local training (step 1 in Fig. <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).
The latter metric can be seen as
a measure of how much individual nodes contribute to the global learning
process.
In the plot, the <span id="S4.SS2.p3.1.1" class="ltx_text ltx_font_italic">color</span> of each marker represents the category of the corresponding node, while the <span id="S4.SS2.p3.1.2" class="ltx_text ltx_font_italic">shape</span> of each marker represents the model-weighting strategy.
It is clear that, for all model-weighting strategies, local
learning times are strongly correlated with the quantity of local data,
while local accuracy gains are more strongly linked with the number of
classes, i.e., the data quality. These results also suggest that only
relying on local learning times for node-dropping decisions may result
in removing nodes with large, hence, potentially valuable, datasets.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2101.01995/assets/x4.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="437" height="277" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Relationship between the weight assigned to local models and
the local accuracy gain for different categories of nodes (identified by
the color of markers), under different model-weighting strategies (identified
by the shape of markers). Correlation coefficients for the “uniform”, “no.
samples”, “no. classes” and “entropy” strategies are, respectively,
<math id="S4.F4.5.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S4.F4.5.m1.1b"><mn id="S4.F4.5.m1.1.1" xref="S4.F4.5.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.F4.5.m1.1c"><cn type="integer" id="S4.F4.5.m1.1.1.cmml" xref="S4.F4.5.m1.1.1">0</cn></annotation-xml></semantics></math>, <math id="S4.F4.6.m2.1" class="ltx_Math" alttext="0.07" display="inline"><semantics id="S4.F4.6.m2.1b"><mn id="S4.F4.6.m2.1.1" xref="S4.F4.6.m2.1.1.cmml">0.07</mn><annotation-xml encoding="MathML-Content" id="S4.F4.6.m2.1c"><cn type="float" id="S4.F4.6.m2.1.1.cmml" xref="S4.F4.6.m2.1.1">0.07</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.6.m2.1d">0.07</annotation></semantics></math>, <math id="S4.F4.7.m3.1" class="ltx_Math" alttext="0.98" display="inline"><semantics id="S4.F4.7.m3.1b"><mn id="S4.F4.7.m3.1.1" xref="S4.F4.7.m3.1.1.cmml">0.98</mn><annotation-xml encoding="MathML-Content" id="S4.F4.7.m3.1c"><cn type="float" id="S4.F4.7.m3.1.1.cmml" xref="S4.F4.7.m3.1.1">0.98</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.7.m3.1d">0.98</annotation></semantics></math> and <math id="S4.F4.8.m4.1" class="ltx_Math" alttext="0.99" display="inline"><semantics id="S4.F4.8.m4.1b"><mn id="S4.F4.8.m4.1.1" xref="S4.F4.8.m4.1.1.cmml">0.99</mn><annotation-xml encoding="MathML-Content" id="S4.F4.8.m4.1c"><cn type="float" id="S4.F4.8.m4.1.1.cmml" xref="S4.F4.8.m4.1.1">0.99</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.8.m4.1d">0.99</annotation></semantics></math>.</figcaption>
</figure>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.2" class="ltx_p">Fig. <a href="#S4.F4" title="Figure 4 ‣ IV-B Experiment results ‣ IV Experiment Design and Results ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the relationship between the weight assigned to
each local model and the corresponding local accuracy gain.
Similar to Fig. <a href="#S4.F3" title="Figure 3 ‣ IV-A Experiment setup ‣ IV Experiment Design and Results ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, the color and shape of markers represent, respectively, the node category and model-weighting strategy.
We quantify the relationship between weights and accuracy gains, by <span id="S4.SS2.p4.2.1" class="ltx_text ltx_font_italic">correlation coefficients</span>,
expressing to which extent changes in one quantity are reflected by changes in the other:
values close to <math id="S4.SS2.p4.1.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S4.SS2.p4.1.m1.1a"><mn id="S4.SS2.p4.1.m1.1.1" xref="S4.SS2.p4.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.1.m1.1b"><cn type="integer" id="S4.SS2.p4.1.m1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.1.m1.1c">1</annotation></semantics></math> indicate strong correlation, values close to <math id="S4.SS2.p4.2.m2.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S4.SS2.p4.2.m2.1a"><mn id="S4.SS2.p4.2.m2.1.1" xref="S4.SS2.p4.2.m2.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.2.m2.1b"><cn type="integer" id="S4.SS2.p4.2.m2.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1">0</cn></annotation-xml></semantics></math> little to no correlation.</p>
</div>
<div id="S4.SS2.p5" class="ltx_para">
<p id="S4.SS2.p5.1" class="ltx_p">In our case,
it is clear that
weights only considering the quantity of data (i.e., the “no. samples”
strategy) may not be able to identify the nodes that can contribute the
most to the learning process, e.g., it gives similar weights to the
“silver” and “garbage” nodes. On the other hand, “no. classes” and
“entropy” weights are very well correlated with accuracy gains, which
again suggests how the quality of data has a high impact on
the learning effectiveness.
From both Fig. <a href="#S4.F3" title="Figure 3 ‣ IV-A Experiment setup ‣ IV Experiment Design and Results ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and Fig. <a href="#S4.F4" title="Figure 4 ‣ IV-B Experiment results ‣ IV Experiment Design and Results ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, it is also possible to see how better local accuracy gains do not necessarily coincide with better global classification accuracy. Indeed, good model-weighting decisions are necessary to consolidate local learning from different nodes into a consistent, high-quality global model.</p>
</div>
<figure id="S4.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2101.01995/assets/x5.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="437" height="292" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2101.01995/assets/x6.png" id="S4.F5.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="437" height="292" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Relationship between elapsed time and global accuracy for
different node-dropping schemes, under the “no. samples” (top) and
“no. classes” (bottom) model-weighting strategies.


</figcaption>
</figure>
<div id="S4.SS2.p6" class="ltx_para">
<p id="S4.SS2.p6.1" class="ltx_p">Last, Fig. <a href="#S4.F5" title="Figure 5 ‣ IV-B Experiment results ‣ IV Experiment Design and Results ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows the effect of different node-dropping strategies
on the learning process, for the “no. samples’ and “no. classes”
model-weighting strategies.
Specifically, we wait for the first five iterations, and then drop the five nodes with the lowest score, computed according to each node-dropping strategy.
We can observe that, when weights only
reflect the quantity of local data, dropping the slowest nodes
significantly hurts the learning accuracy. On the other hand, more
sophisticate model-weighting <span id="S4.SS2.p6.1.1" class="ltx_text ltx_font_italic">or</span> node-dropping strategies yield
virtually the same accuracy as keeping all nodes. This also highlights
how model-weighting and node-dropping decisions interact with one
another, and can represent different, complementary ways to achieve the
same goals.</p>
</div>
<div id="S4.SS2.p7" class="ltx_para">
<p id="S4.SS2.p7.1" class="ltx_p"><span id="S4.SS2.p7.1.1" class="ltx_text ltx_font_bold">Summary.</span>
In conclusion, our results show that the <span id="S4.SS2.p7.1.2" class="ltx_text ltx_font_italic">quantity</span> of data drives the computation
time of local nodes; however, it is the <span id="S4.SS2.p7.1.3" class="ltx_text ltx_font_italic">quality</span> of data that determines
its usefulness to the global learning process.
It is thus of paramount importance that model-weighting decisions do not solely account
for data quantity or computation time, as that may adversely impact performance.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Take-away Messages and Challenges</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Based on both the existing works discussed in Sec. <a href="#S2" title="II Federated Learning in Edge Scenarios ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> and Sec. <a href="#S3" title="III Model-weighting and Node-dropping Strategies in Federated Learning ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>
and the experiments reported in Sec. <a href="#S4" title="IV Experiment Design and Results ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>, we can highlight the
following high-level lessons learned, which also point at interesting
directions for future research.</p>
</div>
<section id="S5.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Model weights matter</h4>

<div id="S5.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px1.p1.1" class="ltx_p">Assigning the right weights to local nodes during the averaging phase
can have a very significant impact on the learning process, as
highlighted in Fig. <a href="#S4.F2" title="Figure 2 ‣ IV-A Experiment setup ‣ IV Experiment Design and Results ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and Fig. <a href="#S4.F5" title="Figure 5 ‣ IV-B Experiment results ‣ IV Experiment Design and Results ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.
Although few works in the literature have explored this option, Fig. <a href="#S4.F4" title="Figure 4 ‣ IV-B Experiment results ‣ IV Experiment Design and Results ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows how
weights accounting for the
quality of data as well as its quantity are much more likely to
identify the nodes that can contribute the most to the learning process.
Importantly, the information needed to compute such weights is either
already available or easy to collect for the learning server, and does
not jeopardize the privacy properties of FL.</p>
</div>
</section>
<section id="S5.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Data quality matters</h4>

<div id="S5.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px2.p1.1" class="ltx_p">Our experiments strongly underline the importance of dataset quality.
An example is provided in Fig. <a href="#S4.F3" title="Figure 3 ‣ IV-A Experiment setup ‣ IV Experiment Design and Results ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and
Fig. <a href="#S4.F4" title="Figure 4 ‣ IV-B Experiment results ‣ IV Experiment Design and Results ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, showing how nodes with more diverse data (“gold” and
“silver”) are able to offer much greater contributions to the overall
learning process.
Quantifying data quality is not a trivial task, however, our experiments show that even simple definitions based on counting the classes present in a given dataset yield very good results. Further research can explore additional
aspects of data quality, e.g., its freshness <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>.</p>
</div>
</section>
<section id="S5.SS0.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Check why nodes straggle before dropping them</h4>

<div id="S5.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px3.p1.1" class="ltx_p">The global learning time of FL depends on the slowest node in each
iteration; therefore, it is often tempting to try and speed learning up
by dropping the slowest nodes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Such a strategy is
appropriate when the slowest nodes are indeed stragglers, with limited
computational capabilities or poor
connectivity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>; however, this may
result in unduly excluding nodes with valuable, rich datasets.
Privacy concerns often prevent the server from obtaining additional
information on individual learning nodes; however, already-available
data like the size of local datasets can provide significant help to
tell genuine stragglers apart from nodes that simply have a lot of
data. If warranted, the latter can be directed to sample their own
datasets, in a similar spirit to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, so as to
provide good contributions to the learning process with a smaller
latency. This also points at the exciting research direction of
extending the FL paradigm by allowing additional interaction between the
learning server and learning nodes, striking the right balance between
simplicity, privacy, and effectiveness.</p>
</div>
</section>
<section id="S5.SS0.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">FL is robust</h4>

<div id="S5.SS0.SSS0.Px4.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px4.p1.1" class="ltx_p">This is not very surprising, since FL has been introduced for the very
purpose of exploiting local, potentially heterogeneous, data from
devices that cannot be centrally controlled. It is however interesting
to highlight how the robustness of FL extends beyond tackling
low-quality data, to tackling suboptimal configurations. An example is
provided in Fig. <a href="#S4.F5" title="Figure 5 ‣ IV-B Experiment results ‣ IV Experiment Design and Results ‣ Federated Learning at the Network Edge: When Not All Nodes are Created Equal" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, where it is sufficient to make high-quality
model-weighting <span id="S5.SS0.SSS0.Px4.p1.1.1" class="ltx_text ltx_font_italic">or</span> node-dropping decisions to obtain very good
learning performance. This suggests that FL is indeed a viable choice in
those environments and scenarios where there is a significant likelihood
that configuration decisions be suboptimal. Robustness to incorrect
configuration is a relevant research area in distributed computing
scenarios, and – so far – a neglected one.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In the context of federated learning, we have considered the problems of
model-weighting, i.e., assigning weights to local models during the
averaging phase, and node-dropping, i.e., selecting the nodes to exclude
from the learning process.
After observing how those two decisions can
tackle most of the issues and hurdles of FL, we have reviewed existing
approaches thereto and found them to seldom depart from straightforward
solutions based on the quantity of local data learning nodes have and
their response time. Leveraging a set of real-world experiments, we have
observed how more comprehensive approaches, accounting for the quality
of local data and for the reasons behind longer node latency, can yield
substantially better learning performance.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
J. Konečný, B. McMahan, and D. Ramage, “Federated optimization: Distributed
optimization beyond the datacenter,” <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1511.03575</em>,
2015.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
M. Chen, Z. Yang, W. Saad, C. Yin, H. V. Poor, and S. Cui, “A
joint learning and communications framework for federated learning over
wireless networks,” <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Wireless Communications</em>,
vol. 20, no. 1, pp. 269–283, 2020.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
J. Kang, Z. Xiong, D. Niyato, Y. Zou, Y. Zhang, and M. Guizani, “Reliable
federated learning for mobile networks,” <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">IEEE Wireless
Communications</em>, vol. 27, no. 2, pp. 72–80, 2020.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
H. Wang, Z. Kaplan, D. Niu, and B. Li, “Optimizing federated learning on
non-iid data with reinforcement learning,” in <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">IEEE INFOCOM</em>, 2020.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
T. Nishio and R. Yonetani, “Client Selection for Federated Learning with
Heterogeneous Resources in Mobile Edge,” in <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">IEEE ICC 2019</em>, 2019.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
X. Wang, Y. Han, C. Wang, Q. Zhao, X. Chen, and M. Chen, “In-Edge
AI: Intelligentizing Mobile Edge Computing, Caching and Communication by
Federated Learning,” <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">IEEE Network</em>, vol. 33, no. 5, pp. 156–165,
2019.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
G. Neglia, G. Calbi, D. Towsley, and G. Vardoyan, “The role of network
topology for distributed machine learning,” in <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">IEEE INFOCOM</em>, 2019.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Y. Tu, Y. Ruan, S. Wagle, C. G. Brinton, and C. Joe-Wong,
“Network-Aware Optimization of Distributed Learning for Fog Computing,”
in <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">IEEE INFOCOM</em>, 2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
F. Sattler, S. Wiedemann, K.-R. Müller, and W. Samek, “Robust and
Communication-Efficient Federated Learning From Non-i.i.d. Data,”
<em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Neural Networks and Learning Systems</em>, vol. 31,
no. 9, pp. 3400–3413, 2020.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
S. Wang, T. Tuor, T. Salonidis, K. K. Leung, C. Makaya, T. He, and K. Chan,
“Adaptive federated learning in resource constrained edge computing
systems,” <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">IEEE Journal on Selected Areas in Communications</em>, vol. 37,
no. 6, pp. 1205–1221, 2019.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Y. Lu, X. Huang, Y. Dai, S. Maharjan, and Y. Zhang, “Differentially private
asynchronous federated learning for mobile edge computing in urban
informatics,” <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Industrial Informatics</em>, vol. 16,
no. 3, pp. 2134–2143, 2019.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
M. Shin, C. Hwang, J. Kim, J. Park, M. Bennis, and S.-L. Kim, “XOR Mixup:
Privacy-Preserving Data Augmentation for One-Shot Federated Learning,”
<em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2006.05148</em>, 2020.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
H. Huang, J. Huang, Y. Feng, J. Zhang, Z. Liu, Q. Wang, and L. Chen, “On the
improvement of reinforcement active learning with the involvement of cross
entropy to address one-shot learning problem,” <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">PloS one</em>, vol. 14,
no. 6, p. e0217408, 2019.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
A. A. Abdellatif, C. F. Chiasserini, and F. Malandrino, “Active learning-based
classification in automated connected vehicles,” in <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">IEEE INFOCOM
PERSIST-IoT Workshop</em>, 2020.

</span>
</li>
</ul>
</section>
<figure id="tab1" class="ltx_float biography">
<table id="tab1.1" class="ltx_tabular">
<tr id="tab1.1.1" class="ltx_tr">
<td id="tab1.1.1.1" class="ltx_td">
<span id="tab1.1.1.1.1" class="ltx_inline-block">
<span id="tab1.1.1.1.1.1" class="ltx_p"><span id="tab1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Francesco Malandrino</span> 
(M’09, SM’19) earned his Ph.D. degree from Politecnico di Torino in 2012
and is now a researcher at the National Research Council of Italy
(CNR-IEIIT). His research interests include the architecture and
management of wireless, cellular, and vehicular networks.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="tab2" class="ltx_float biography">
<table id="tab2.1" class="ltx_tabular">
<tr id="tab2.1.1" class="ltx_tr">
<td id="tab2.1.1.1" class="ltx_td">
<span id="tab2.1.1.1.1" class="ltx_inline-block">
<span id="tab2.1.1.1.1.1" class="ltx_p"><span id="tab2.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Carla Fabiana Chiasserini</span> 
(M’98, SM’09, F’18) received her Ph.D. from Politecnico di Torino in
2000. She is currently a Full Professor with the Department of
Electronic Engineering and Telecommunications at Politecnico di
Torino, as well as the Vice Rector for Alumni and Career Orientation.
Her research interests include architectures, protocols, and performance
analysis of wireless networks.</span>
</span>
</td>
</tr>
</table>
</figure>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2101.01994" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2101.01995" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2101.01995">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2101.01995" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2101.01996" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  1 14:14:14 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
