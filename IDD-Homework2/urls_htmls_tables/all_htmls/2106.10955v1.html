<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2106.10955] Extractive approach for text summarization using graphs</title><meta property="og:description" content="Natural language processing is an important discipline with the aim of understanding text by its digital representation, that due to the diverse way we write and speak, is often not accurate enough. Our paper explores …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Extractive approach for text summarization using graphs">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Extractive approach for text summarization using graphs">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2106.10955">

<!--Generated on Fri Mar  8 13:31:44 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\templatetype</span>
<p id="p1.2" class="ltx_p">pnasresearcharticle




<span id="p1.2.1" class="ltx_ERROR undefined">\leadauthor</span>Kadriu
<span id="p1.2.2" class="ltx_ERROR undefined">\authordeclaration</span>All authors contributed equally to this work.
<span id="p1.2.3" class="ltx_ERROR undefined">\correspondingauthor</span><sup id="p1.2.4" class="ltx_sup">1</sup>To whom correspondence should be addressed. E-mail: kk5222@student.uni-lj.si.</p>
</div>
<h1 class="ltx_title ltx_title_document">Extractive approach for text summarization using graphs</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Kastriot Kadriu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">University of Ljubljana, Faculty of Computer and Information Science, Večna pot 113, SI-1000 Ljubljana, Slovenia
</span>
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Milenko Obradovic
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">University of Ljubljana, Faculty of Computer and Information Science, Večna pot 113, SI-1000 Ljubljana, Slovenia
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Natural language processing is an important discipline with the aim of understanding text by its digital representation, that due to the diverse way we write and speak, is often not accurate enough. Our paper explores different graph related algorithms that can be used in solving the text summarization problem using an extractive approach. We consider two metrics: sentence overlap and edit distance for measuring sentence similiarity. Relevant structures have been implemented and the code can be obtained in this link <cite class="ltx_cite ltx_citemacro_cite">(<a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">1</span></a>)</cite>.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">doi: </h6>
<a target="_blank" href="https://ucilnica.fri.uni-lj.si/course/view.php?id=183" title="" class="ltx_ref ltx_href">Introduction to Network Analysis</a> 2020/21
</div>
<div id="p2" class="ltx_para">
<span id="p2.1" class="ltx_ERROR undefined">\dates</span>
<p id="p2.2" class="ltx_p">The manuscript was compiled on 

<span id="p2.2.1" class="ltx_text" lang="en"></span></p>
</div>
<div id="p3" class="ltx_para">
<span id="p3.1" class="ltx_ERROR undefined" lang="en">\dropcap</span>
<p id="p3.2" class="ltx_p"><span id="p3.2.1" class="ltx_text" lang="en">While the quantity of information is growing exponentially, there’s a need to compress the content in condensed versions. The summarization of information is a problem that deals with presenting the main idea of the text without the need to read all the content of the text. Such task is heavily relied on the calculation of sentence similiarity, and in that regard, various methods have been tried. 
<br class="ltx_break">Two methods for automatic text summarization are considered: extractive and abstractive. Extractive summarization is based on the identification of important sections of the text and producing a subset of the sentences from the original text, whereas abstractive summarization tries to reproduce the important content in a new way after interpretation and examination of text using more advenced techniques. 
<br class="ltx_break">Supervised summarization models are built by treating the problem as a classification task, and by classifying which features in a sentence are relevant for summarization. 
<br class="ltx_break">Those models aren’t very reliable because of the unpredictable nature of language, from which it is not easy to generate a classification pattern. In addition, such models require training data which worsen the data acquisition problem which is already a challenge on its own. 
<br class="ltx_break">Task summarization problem concerns itself with representing data in such way that the importance of each sentence and their terms is properly considered. Text should be represented in such ways that the inter-word and inter-sentence dependency is kept.
<br class="ltx_break">The task is challenged by a sustainable data source for validation and subsequently, an efficient metric for evaluating it and other text-understanding tasks. The challenges are topics of Document Understanding Conference, which later became Text Analaysis Conference. A domain-independent evaluation is also complex to be achieved. For example, a model reporting a high accuracy in summarizing news articles might not perform with the same accuracy when summarizing, let’s say, Reddit posts. 
<br class="ltx_break">Generally, best performing models are deep learning based. The construction of such models is faced with challenges of its own mainly regarded with computational resources. For that reason, it’s important to consider more simpler approaches like the ones that are presented in this paper. 
<br class="ltx_break">Our contribution includes a direct implementation of graph-based algorithms for computing relevant data that could summarize the test documents the best. The respective algorithms help us extract the most important sentences that will constitute the summary. We test two different metrics for computing sentence similiarity, and in one of them we employ a notion of graph similiarity - edit distance - Figure <a href="#S0.F1" title="Figure 1 ‣ Extractive approach for text summarization using graphs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</span></p>
</div>
<figure id="S0.F1" class="ltx_figure" lang="en"><img src="/html/2106.10955/assets/pipeline.png" id="S0.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="145" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Pipeline of our model</figcaption>
</figure>
<section id="Sx1" class="ltx_section" lang="en">
<h2 class="ltx_title ltx_title_section">Related work</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">Text summarization is an open problem. There hasn’t been report of an official model who can achieve a decent data-independent accuracy. Current state-of-art models achieve accuracy of around 50% percent. Those models are usually deep learning models. <cite class="ltx_cite ltx_citemacro_cite">(<a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>)</cite> achieves state-of-the-art results on the CNN/Daily mail dataset. The model presented there is the Reinforced Neural Extractive Summarization (RNES) model. <cite class="ltx_cite ltx_citemacro_cite">(<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a>)</cite> presents a general overview of two ranking algorithms - PageRank and HITS, and an agnostic overview of building a graph representation of text to be used for summarization by extraction. In addition, for smooth-er outputs, shortest path algorithm is suggested. This paper lacks concrete results tested on some dataset. 
<br class="ltx_break"><cite class="ltx_cite ltx_citemacro_cite">(<a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2</span></a>, <a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">15</span></a>)</cite> dive deeper in the use of PageRank algorithm for text summarization, whose use in such cases is referred to as TextRank.
Sentences are extracted using the respective algorithm in a weighted graph built with nodes representing the sentences to be summarized, and weighted edges represent the similarity those sentences have with each other. Similiarity between sentences is calculated as their overlap which can be determined as the number of common words between their lexical representation. The resulting model is an unsupervised model that has achieved 47% accuracy, as evaluted by the ROGUE metric, on 567 news articles provided by the Document Understanding Evaluations (DUC) 2002. The paper also explores the use of TextRank in keyword extraction. The paper introduces the respective algorithm very well but could benefit by the computation of a larger batch of test data. 
<br class="ltx_break"></p>
</div>
<div id="Sx1.p2" class="ltx_para">
<p id="Sx1.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite">(<a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">8</span></a>)</cite> implements the TextRank algorithm and expands on the pre and post-processing part. The data (sentences) is encoded and different methods are considered such as tf-idf and Word2vec. Moreover, the implementation is tested on Malayaian content, demonstrating the domain independence of the algorithm.
Another extractive text summarization algorithm is LexRank, which is based on computing the importance of a sentence by the concept of eigenvector centrality presented in <cite class="ltx_cite ltx_citemacro_cite">(<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">10</span></a>)</cite>. The similiarity between sentences, also represented as nodes, is calculated as the cosine similiarity between the vector of their words mapped as their <span id="Sx1.p2.1.1" class="ltx_text ltx_font_italic">idf</span> values. 
<br class="ltx_break">Topic based approaches are seen on <cite class="ltx_cite ltx_citemacro_cite">(<a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">11</span></a>, <a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">13</span></a>, <a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">14</span></a>)</cite>. They are based on the distribution of words accross documents from which it is possible to derive <span id="Sx1.p2.1.2" class="ltx_text ltx_font_italic">topics</span> that later constitute summaries.
<cite class="ltx_cite ltx_citemacro_cite">(<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>)</cite> treats the problem of summarization as a compression problem that could be integrated in both extractive and abstractive summarization approaches, and <cite class="ltx_cite ltx_citemacro_cite">(<a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">4</span></a>)</cite> builds a small world network to summarize biomedical articles.</p>
</div>
</section>
<section id="Sx2" class="ltx_section" lang="en">
<h2 class="ltx_title ltx_title_section">Results</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p">Native structures have been implemented with the aim of supporting experiments. Graphs have been created using NetworkX <cite class="ltx_cite ltx_citemacro_cite">(<a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">23</span></a>)</cite>, whereas linguistic processing has been done with nltk <cite class="ltx_cite ltx_citemacro_cite">(<a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">22</span></a>)</cite> and stanza <cite class="ltx_cite ltx_citemacro_cite">(<a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>)</cite>. 
<br class="ltx_break">The aim of our experiments was to test how well different centrality measures are able to identify the most important parts of the text. For that reason, we consider pagerank, hits, closeness, betweenness and degree measures. In addition, when construction the edges of the graph, we use two different metrics for measuring how similar two sentences are, thus determing the weight of the link between those two nodes: word overlap and edit distance. The edge candidates are then ranked based on their weight, and then, by a threshold value, the edges with the top weights are created. 
<br class="ltx_break">The model has been evaluated using <span id="Sx2.p1.1.1" class="ltx_text ltx_font_bold">3500</span> documents from the CNN/Dailymail <cite class="ltx_cite ltx_citemacro_cite">(<a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">18</span></a>, <a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">19</span></a>)</cite> dataset - Table <a href="#Sx2.T1" title="Table 1 ‣ Results ‣ Extractive approach for text summarization using graphs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, which is a collection of news articles with their highlights serving as our summarization tests.</p>
</div>
<figure id="Sx2.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>CNN/Dailymail dataset statistics.</figcaption>
<table id="Sx2.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Sx2.T1.1.1.1" class="ltx_tr">
<th id="Sx2.T1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Number of test documents</th>
<th id="Sx2.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">3500</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Sx2.T1.1.2.1" class="ltx_tr">
<th id="Sx2.T1.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Average document length</th>
<td id="Sx2.T1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">33 sentences</td>
</tr>
<tr id="Sx2.T1.1.3.2" class="ltx_tr">
<th id="Sx2.T1.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Average summary length</th>
<td id="Sx2.T1.1.3.2.2" class="ltx_td ltx_align_center ltx_border_t">5 sentences</td>
</tr>
<tr id="Sx2.T1.1.4.3" class="ltx_tr">
<th id="Sx2.T1.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t">Average document-summary compression</th>
<td id="Sx2.T1.1.4.3.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.85</td>
</tr>
</tbody>
</table>
</figure>
<div id="Sx2.p2" class="ltx_para">
<p id="Sx2.p2.1" class="ltx_p">Various methods have been tested with two different metrics: sentences overlap and sentences edit distance (TED). After employing strategies described in the Methods section, top five sentences, number which is based on the average summary length, are extracted that represent the generated summary with our method(s). The summary is then compared with the ground truth summary provided in the dataset using the ROGUE metric. 
<br class="ltx_break">Edit distance for sentence similiarity is more time consuming because it adds three extra steps in our pipeline: word dependency parsing, tree construction and edit distance calculation. 
<br class="ltx_break">We report on recall and F1 score values. We are using recall to evaluate how much of the ’correct’ content is included in summaries, and F1 score to give a balanced evaluation score that is not based on the attributes that recall takes into account such as the summary length.</p>
</div>
<figure id="Sx2.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Recall values of the evaluation using the sentence overlap metric and t=0.5.</figcaption>
<table id="Sx2.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="Sx2.T2.1.1.1" class="ltx_tr">
<th id="Sx2.T2.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt"><span id="Sx2.T2.1.1.1.1.1" class="ltx_text ltx_font_bold">Method</span></th>
<td id="Sx2.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="Sx2.T2.1.1.1.2.1" class="ltx_text ltx_font_bold">Rogue-1</span></td>
<td id="Sx2.T2.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="Sx2.T2.1.1.1.3.1" class="ltx_text ltx_font_bold">Rogue-2</span></td>
<td id="Sx2.T2.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="Sx2.T2.1.1.1.4.1" class="ltx_text ltx_font_bold">Rogue-L</span></td>
</tr>
<tr id="Sx2.T2.1.2.2" class="ltx_tr">
<th id="Sx2.T2.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Pagerank</th>
<td id="Sx2.T2.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t">0.50</td>
<td id="Sx2.T2.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t">0.19</td>
<td id="Sx2.T2.1.2.2.4" class="ltx_td ltx_align_center ltx_border_t">0.44</td>
</tr>
<tr id="Sx2.T2.1.3.3" class="ltx_tr">
<th id="Sx2.T2.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Hits</th>
<td id="Sx2.T2.1.3.3.2" class="ltx_td ltx_align_center ltx_border_t">0.48</td>
<td id="Sx2.T2.1.3.3.3" class="ltx_td ltx_align_center ltx_border_t">0.19</td>
<td id="Sx2.T2.1.3.3.4" class="ltx_td ltx_align_center ltx_border_t">0.42</td>
</tr>
<tr id="Sx2.T2.1.4.4" class="ltx_tr">
<th id="Sx2.T2.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Closeness</th>
<td id="Sx2.T2.1.4.4.2" class="ltx_td ltx_align_center ltx_border_t">0.50</td>
<td id="Sx2.T2.1.4.4.3" class="ltx_td ltx_align_center ltx_border_t">0.20</td>
<td id="Sx2.T2.1.4.4.4" class="ltx_td ltx_align_center ltx_border_t">0.45</td>
</tr>
<tr id="Sx2.T2.1.5.5" class="ltx_tr">
<th id="Sx2.T2.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Betweenness</th>
<td id="Sx2.T2.1.5.5.2" class="ltx_td ltx_align_center ltx_border_t">0.50</td>
<td id="Sx2.T2.1.5.5.3" class="ltx_td ltx_align_center ltx_border_t">0.20</td>
<td id="Sx2.T2.1.5.5.4" class="ltx_td ltx_align_center ltx_border_t">0.44</td>
</tr>
<tr id="Sx2.T2.1.6.6" class="ltx_tr">
<th id="Sx2.T2.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Degree</th>
<td id="Sx2.T2.1.6.6.2" class="ltx_td ltx_align_center ltx_border_t">0.50</td>
<td id="Sx2.T2.1.6.6.3" class="ltx_td ltx_align_center ltx_border_t">20</td>
<td id="Sx2.T2.1.6.6.4" class="ltx_td ltx_align_center ltx_border_t">0.45</td>
</tr>
<tr id="Sx2.T2.1.7.7" class="ltx_tr">
<th id="Sx2.T2.1.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t">Clusters</th>
<td id="Sx2.T2.1.7.7.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.47</td>
<td id="Sx2.T2.1.7.7.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.18</td>
<td id="Sx2.T2.1.7.7.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.42</td>
</tr>
</tbody>
</table>
</figure>
<figure id="Sx2.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Recall values of the evaluation using TED metric and t=0.5.</figcaption>
<table id="Sx2.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Sx2.T3.1.1.1" class="ltx_tr">
<th id="Sx2.T3.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="Sx2.T3.1.1.1.1.1" class="ltx_text ltx_font_bold">Method</span></th>
<th id="Sx2.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="Sx2.T3.1.1.1.2.1" class="ltx_text ltx_font_bold">Rogue-1</span></th>
<th id="Sx2.T3.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="Sx2.T3.1.1.1.3.1" class="ltx_text ltx_font_bold">Rogue-2</span></th>
<th id="Sx2.T3.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="Sx2.T3.1.1.1.4.1" class="ltx_text ltx_font_bold">Rogue-L</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Sx2.T3.1.2.1" class="ltx_tr">
<th id="Sx2.T3.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Pagerank</th>
<td id="Sx2.T3.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">0.48</td>
<td id="Sx2.T3.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">0.17</td>
<td id="Sx2.T3.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">0.426</td>
</tr>
<tr id="Sx2.T3.1.3.2" class="ltx_tr">
<th id="Sx2.T3.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Hits</th>
<td id="Sx2.T3.1.3.2.2" class="ltx_td ltx_align_center ltx_border_t">0.48</td>
<td id="Sx2.T3.1.3.2.3" class="ltx_td ltx_align_center ltx_border_t">0.17</td>
<td id="Sx2.T3.1.3.2.4" class="ltx_td ltx_align_center ltx_border_t">0.423</td>
</tr>
<tr id="Sx2.T3.1.4.3" class="ltx_tr">
<th id="Sx2.T3.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Closeness</th>
<td id="Sx2.T3.1.4.3.2" class="ltx_td ltx_align_center ltx_border_t">0.51</td>
<td id="Sx2.T3.1.4.3.3" class="ltx_td ltx_align_center ltx_border_t">0.19</td>
<td id="Sx2.T3.1.4.3.4" class="ltx_td ltx_align_center ltx_border_t">0.45</td>
</tr>
<tr id="Sx2.T3.1.5.4" class="ltx_tr">
<th id="Sx2.T3.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Betweenness</th>
<td id="Sx2.T3.1.5.4.2" class="ltx_td ltx_align_center ltx_border_t">0.51</td>
<td id="Sx2.T3.1.5.4.3" class="ltx_td ltx_align_center ltx_border_t">0.19</td>
<td id="Sx2.T3.1.5.4.4" class="ltx_td ltx_align_center ltx_border_t">0.45</td>
</tr>
<tr id="Sx2.T3.1.6.5" class="ltx_tr">
<th id="Sx2.T3.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Degree</th>
<td id="Sx2.T3.1.6.5.2" class="ltx_td ltx_align_center ltx_border_t">0.51</td>
<td id="Sx2.T3.1.6.5.3" class="ltx_td ltx_align_center ltx_border_t">0.19</td>
<td id="Sx2.T3.1.6.5.4" class="ltx_td ltx_align_center ltx_border_t">0.45</td>
</tr>
<tr id="Sx2.T3.1.7.6" class="ltx_tr">
<th id="Sx2.T3.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t">Clusters</th>
<td id="Sx2.T3.1.7.6.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.43</td>
<td id="Sx2.T3.1.7.6.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.14</td>
<td id="Sx2.T3.1.7.6.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.38</td>
</tr>
</tbody>
</table>
</figure>
<figure id="Sx2.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>F score values of the evaluation using the sentence overlap metric and t=0.5.</figcaption>
<table id="Sx2.T4.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Sx2.T4.1.1.1" class="ltx_tr">
<th id="Sx2.T4.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="Sx2.T4.1.1.1.1.1" class="ltx_text ltx_font_bold">Method</span></th>
<th id="Sx2.T4.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="Sx2.T4.1.1.1.2.1" class="ltx_text ltx_font_bold">Rogue-1</span></th>
<th id="Sx2.T4.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="Sx2.T4.1.1.1.3.1" class="ltx_text ltx_font_bold">Rogue-2</span></th>
<th id="Sx2.T4.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="Sx2.T4.1.1.1.4.1" class="ltx_text ltx_font_bold">Rogue-L</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Sx2.T4.1.2.1" class="ltx_tr">
<th id="Sx2.T4.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Pagerank</th>
<td id="Sx2.T4.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">0.26</td>
<td id="Sx2.T4.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">0.10</td>
<td id="Sx2.T4.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">0.28</td>
</tr>
<tr id="Sx2.T4.1.3.2" class="ltx_tr">
<th id="Sx2.T4.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Hits</th>
<td id="Sx2.T4.1.3.2.2" class="ltx_td ltx_align_center ltx_border_t">0.26</td>
<td id="Sx2.T4.1.3.2.3" class="ltx_td ltx_align_center ltx_border_t">0.10</td>
<td id="Sx2.T4.1.3.2.4" class="ltx_td ltx_align_center ltx_border_t">0.28</td>
</tr>
<tr id="Sx2.T4.1.4.3" class="ltx_tr">
<th id="Sx2.T4.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Closeness</th>
<td id="Sx2.T4.1.4.3.2" class="ltx_td ltx_align_center ltx_border_t">0.28</td>
<td id="Sx2.T4.1.4.3.3" class="ltx_td ltx_align_center ltx_border_t">0.12</td>
<td id="Sx2.T4.1.4.3.4" class="ltx_td ltx_align_center ltx_border_t">0.30</td>
</tr>
<tr id="Sx2.T4.1.5.4" class="ltx_tr">
<th id="Sx2.T4.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Betweenness</th>
<td id="Sx2.T4.1.5.4.2" class="ltx_td ltx_align_center ltx_border_t">0.28</td>
<td id="Sx2.T4.1.5.4.3" class="ltx_td ltx_align_center ltx_border_t">0.11</td>
<td id="Sx2.T4.1.5.4.4" class="ltx_td ltx_align_center ltx_border_t">0.29</td>
</tr>
<tr id="Sx2.T4.1.6.5" class="ltx_tr">
<th id="Sx2.T4.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Degree</th>
<td id="Sx2.T4.1.6.5.2" class="ltx_td ltx_align_center ltx_border_t">0.28</td>
<td id="Sx2.T4.1.6.5.3" class="ltx_td ltx_align_center ltx_border_t">0.11</td>
<td id="Sx2.T4.1.6.5.4" class="ltx_td ltx_align_center ltx_border_t">0.29</td>
</tr>
<tr id="Sx2.T4.1.7.6" class="ltx_tr">
<th id="Sx2.T4.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t">Clusters</th>
<td id="Sx2.T4.1.7.6.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.27</td>
<td id="Sx2.T4.1.7.6.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.10</td>
<td id="Sx2.T4.1.7.6.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.27</td>
</tr>
</tbody>
</table>
</figure>
<figure id="Sx2.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>F score values of the evaluation using TED metric and t=0.5.</figcaption>
<table id="Sx2.T5.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Sx2.T5.1.1.1" class="ltx_tr">
<th id="Sx2.T5.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="Sx2.T5.1.1.1.1.1" class="ltx_text ltx_font_bold">Method</span></th>
<th id="Sx2.T5.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="Sx2.T5.1.1.1.2.1" class="ltx_text ltx_font_bold">Rogue-1</span></th>
<th id="Sx2.T5.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="Sx2.T5.1.1.1.3.1" class="ltx_text ltx_font_bold">Rogue-2</span></th>
<th id="Sx2.T5.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="Sx2.T5.1.1.1.4.1" class="ltx_text ltx_font_bold">Rogue-L</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Sx2.T5.1.2.1" class="ltx_tr">
<th id="Sx2.T5.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Pagerank</th>
<td id="Sx2.T5.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">0.24</td>
<td id="Sx2.T5.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">0.08</td>
<td id="Sx2.T5.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">0.244</td>
</tr>
<tr id="Sx2.T5.1.3.2" class="ltx_tr">
<th id="Sx2.T5.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Hits</th>
<td id="Sx2.T5.1.3.2.2" class="ltx_td ltx_align_center ltx_border_t">0.24</td>
<td id="Sx2.T5.1.3.2.3" class="ltx_td ltx_align_center ltx_border_t">0.08</td>
<td id="Sx2.T5.1.3.2.4" class="ltx_td ltx_align_center ltx_border_t">0.246</td>
</tr>
<tr id="Sx2.T5.1.4.3" class="ltx_tr">
<th id="Sx2.T5.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Closeness</th>
<td id="Sx2.T5.1.4.3.2" class="ltx_td ltx_align_center ltx_border_t">0.24</td>
<td id="Sx2.T5.1.4.3.3" class="ltx_td ltx_align_center ltx_border_t">0.09</td>
<td id="Sx2.T5.1.4.3.4" class="ltx_td ltx_align_center ltx_border_t">0.25</td>
</tr>
<tr id="Sx2.T5.1.5.4" class="ltx_tr">
<th id="Sx2.T5.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Betweenness</th>
<td id="Sx2.T5.1.5.4.2" class="ltx_td ltx_align_center ltx_border_t">0.24</td>
<td id="Sx2.T5.1.5.4.3" class="ltx_td ltx_align_center ltx_border_t">0.09</td>
<td id="Sx2.T5.1.5.4.4" class="ltx_td ltx_align_center ltx_border_t">0.25</td>
</tr>
<tr id="Sx2.T5.1.6.5" class="ltx_tr">
<th id="Sx2.T5.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Degree</th>
<td id="Sx2.T5.1.6.5.2" class="ltx_td ltx_align_center ltx_border_t">0.24</td>
<td id="Sx2.T5.1.6.5.3" class="ltx_td ltx_align_center ltx_border_t">0.09</td>
<td id="Sx2.T5.1.6.5.4" class="ltx_td ltx_align_center ltx_border_t">0.25</td>
</tr>
<tr id="Sx2.T5.1.7.6" class="ltx_tr">
<th id="Sx2.T5.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t">Clusters</th>
<td id="Sx2.T5.1.7.6.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.25</td>
<td id="Sx2.T5.1.7.6.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.08</td>
<td id="Sx2.T5.1.7.6.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.25</td>
</tr>
</tbody>
</table>
</figure>
<div id="Sx2.p3" class="ltx_para">
<p id="Sx2.p3.1" class="ltx_p">The results from Table <a href="#Sx2.T2" title="Table 2 ‣ Results ‣ Extractive approach for text summarization using graphs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, <a href="#Sx2.T3" title="Table 3 ‣ Results ‣ Extractive approach for text summarization using graphs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, <a href="#Sx2.T4" title="Table 4 ‣ Results ‣ Extractive approach for text summarization using graphs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> and <a href="#Sx2.T5" title="Table 5 ‣ Results ‣ Extractive approach for text summarization using graphs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> might not have very seductive numbers but they are standard numbers across summarization models and are actually comparable with the state-of-the-art models, like the one in <cite class="ltx_cite ltx_citemacro_cite">(<a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>)</cite>, although we can not make direct comparisons because their model has been tested in a greater batch of testing data than ours.
Rogue-1 tells us the number of golden tokens found in the summary. Rogue-2 tells us the number of bigrams that were matched between test and ground truth summary but the values here aren’t expected to be high as the ordering of the sentences (and words, although since our approach is extractive, that’s not a big issue for our case) matters. Rouge-L is an important value to consider as it measures the relation of the two contents in a wider context.</p>
</div>
</section>
<section id="Sx3" class="ltx_section" lang="en">
<h2 class="ltx_title ltx_title_section">Discussion</h2>

<div id="Sx3.p1" class="ltx_para">
<p id="Sx3.p1.1" class="ltx_p">The performance of closeness, betweenness and degree centrality measures is approximate with each other. It is completely affected by the threshold value that determines the number of edges to be created. Hypothetically, if the threshold is 1, the output of the summary would be the first 5 lines of the article. In addition, using those methods, there is a limitation on the possibilities for fine tuning the results. 
<br class="ltx_break">Pagerank and hits perform the most consistently, and that is based on the fact that those algorithms take into account the weight of the edges. Those methods aren’t affected by the number of generated edges, as long as the weights are properly accounted for. Those methods are in the same spirit, they both formalise link analysis as eigenvector problems. Pagerank reports higher accuracy because it is able to operate in the complete graph, unlike Hits which operates on a smaller subgraph. In addition, those methods work well because they do not rely on the isolated information regarding the node but instead, they take into account the entire graph and the relationships within. 
<br class="ltx_break">The clustering method offers more room for tuning the results. The clustering process is based on finding cliques which is a hard problem. It is more computationally expensive compared to other algorithms. It performs best with the tree edit distance as this measure is able to represent the similiarity of sentences for clustering purposes. It is affected by the threshold parameter. 
<br class="ltx_break">The lack of higher numbers in the results is not neccessarily because of the actual quality of our summaries, rather than the limitation that ROGUE metric has. ROGUE address content selection between the test and the grouth truth content without accounting for other quality aspects such as coherence, gramamaticality or fluency. The content selection is relied on lexical overlap but a good summary isn’t always expressed with the same lexical links, and this happens especially in abstractive summarization. It would have been nice if there were more ground truth summaries to compare our generated summaries with, as they could constitute a more leveled evaluation. The dataset we used, however, provided only one summary per article. 
<br class="ltx_break">Our paper offers an overview in using graphs to represent the relation that sentences have, relevant algorithms for detecting the relationships within the graph and presenting them but it could be improved in several ways.
First, a more natural way of picking the top relevant sentences for summary can be integrated, instead of arbitrary picking top <math id="Sx3.p1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="Sx3.p1.1.m1.1a"><mi id="Sx3.p1.1.m1.1.1" xref="Sx3.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="Sx3.p1.1.m1.1b"><ci id="Sx3.p1.1.m1.1.1.cmml" xref="Sx3.p1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx3.p1.1.m1.1c">N</annotation></semantics></math> sentences.
Then, to have results tailored for specific purposes, the sentence similiarity metrics could have been modified to report higher scores for the presence of certain structures in the sentences, such as noun, verbs or adjectives. 
<br class="ltx_break">The clustering method could be favorable as we can incorporate a hybrid approach towards summarization by turning the problem into a graph compression problem after finding the relevant clusters, where for each cluster we try to compress it into a single sentence by linking the most important part of sentences.
Other than text summarization, the findings in this paper can also be referenced as proposals for solving classification problems using graphs. 
<br class="ltx_break">The work on text summarization problem needs to be supported by a standard dataset that covers a more diverse textual content. Future work should also approach new metrics for content evaluation that could overcome ROGUE limitations. Such metrics should account for the relation that words have with each other, preferrably through an embedding methodology and based on an external corpus, although in the first sight this already looks computationally heavy and that’s another issue that would need to be taken care off.</p>
</div>
</section>
<section id="Sx4" class="ltx_section" lang="en">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">Methods</h2>

<section id="Sx4.SSx1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">Pre-processing</h3>

<div id="Sx4.SSx1.p1" class="ltx_para">
<p id="Sx4.SSx1.p1.1" class="ltx_p"><span id="Sx4.SSx1.p1.1.1" class="ltx_text" style="font-size:90%;">Sentences of a document have been tokenized, cleaned up and the next processes have been executed depending on the metric. For the sentence similiarity, the words in sentences are represented by their lemmas so that the context is not missed even if words are in different forms. For the edit distance, we build dependency parsed trees for each sentence using the stanford parser (stanza).</span></p>
</div>
</section>
<section id="Sx4.SSx2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">Metrics</h3>

<div id="Sx4.SSx2.p1" class="ltx_para">
<p id="Sx4.SSx2.p1.1" class="ltx_p"><span id="Sx4.SSx2.p1.1.1" class="ltx_text" style="font-size:90%;">One metric used for measure sentence similiarity is by checking their overlapping words </span><cite class="ltx_cite ltx_citemacro_cite"><span id="Sx4.SSx2.p1.1.2.1" class="ltx_text" style="font-size:90%;">(</span><a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2</span></a><span id="Sx4.SSx2.p1.1.3.2" class="ltx_text" style="font-size:90%;">)</span></cite><span id="Sx4.SSx2.p1.1.4" class="ltx_text" style="font-size:90%;">. To avoid bias on long sentences, the number of overlapping words is normalised by the lengths of both sentences.</span></p>
<table id="Sx4.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="Sx4.Ex1.m1.4" class="ltx_Math" alttext="Sim(S_{i},S_{j})=\frac{|\{w_{k}|w_{k}\in S_{i}\&amp;w_{k}\in S_{j}\}|}{log(|S_{i}|+log(|S_{j}|))}" display="block"><semantics id="Sx4.Ex1.m1.4a"><mrow id="Sx4.Ex1.m1.4.4" xref="Sx4.Ex1.m1.4.4.cmml"><mrow id="Sx4.Ex1.m1.4.4.2" xref="Sx4.Ex1.m1.4.4.2.cmml"><mi mathsize="90%" id="Sx4.Ex1.m1.4.4.2.4" xref="Sx4.Ex1.m1.4.4.2.4.cmml">S</mi><mo lspace="0em" rspace="0em" id="Sx4.Ex1.m1.4.4.2.3" xref="Sx4.Ex1.m1.4.4.2.3.cmml">​</mo><mi mathsize="90%" id="Sx4.Ex1.m1.4.4.2.5" xref="Sx4.Ex1.m1.4.4.2.5.cmml">i</mi><mo lspace="0em" rspace="0em" id="Sx4.Ex1.m1.4.4.2.3a" xref="Sx4.Ex1.m1.4.4.2.3.cmml">​</mo><mi mathsize="90%" id="Sx4.Ex1.m1.4.4.2.6" xref="Sx4.Ex1.m1.4.4.2.6.cmml">m</mi><mo lspace="0em" rspace="0em" id="Sx4.Ex1.m1.4.4.2.3b" xref="Sx4.Ex1.m1.4.4.2.3.cmml">​</mo><mrow id="Sx4.Ex1.m1.4.4.2.2.2" xref="Sx4.Ex1.m1.4.4.2.2.3.cmml"><mo maxsize="90%" minsize="90%" id="Sx4.Ex1.m1.4.4.2.2.2.3" xref="Sx4.Ex1.m1.4.4.2.2.3.cmml">(</mo><msub id="Sx4.Ex1.m1.3.3.1.1.1.1" xref="Sx4.Ex1.m1.3.3.1.1.1.1.cmml"><mi mathsize="90%" id="Sx4.Ex1.m1.3.3.1.1.1.1.2" xref="Sx4.Ex1.m1.3.3.1.1.1.1.2.cmml">S</mi><mi mathsize="90%" id="Sx4.Ex1.m1.3.3.1.1.1.1.3" xref="Sx4.Ex1.m1.3.3.1.1.1.1.3.cmml">i</mi></msub><mo mathsize="90%" id="Sx4.Ex1.m1.4.4.2.2.2.4" xref="Sx4.Ex1.m1.4.4.2.2.3.cmml">,</mo><msub id="Sx4.Ex1.m1.4.4.2.2.2.2" xref="Sx4.Ex1.m1.4.4.2.2.2.2.cmml"><mi mathsize="90%" id="Sx4.Ex1.m1.4.4.2.2.2.2.2" xref="Sx4.Ex1.m1.4.4.2.2.2.2.2.cmml">S</mi><mi mathsize="90%" id="Sx4.Ex1.m1.4.4.2.2.2.2.3" xref="Sx4.Ex1.m1.4.4.2.2.2.2.3.cmml">j</mi></msub><mo maxsize="90%" minsize="90%" id="Sx4.Ex1.m1.4.4.2.2.2.5" xref="Sx4.Ex1.m1.4.4.2.2.3.cmml">)</mo></mrow></mrow><mo mathsize="90%" id="Sx4.Ex1.m1.4.4.3" xref="Sx4.Ex1.m1.4.4.3.cmml">=</mo><mfrac id="Sx4.Ex1.m1.2.2" xref="Sx4.Ex1.m1.2.2.cmml"><mrow id="Sx4.Ex1.m1.1.1.1.1" xref="Sx4.Ex1.m1.1.1.1.2.cmml"><mo maxsize="90%" minsize="90%" id="Sx4.Ex1.m1.1.1.1.1.2" xref="Sx4.Ex1.m1.1.1.1.2.1.cmml">|</mo><mrow id="Sx4.Ex1.m1.1.1.1.1.1.2" xref="Sx4.Ex1.m1.1.1.1.1.1.3.cmml"><mo maxsize="90%" minsize="90%" id="Sx4.Ex1.m1.1.1.1.1.1.2.3" xref="Sx4.Ex1.m1.1.1.1.1.1.3.1.cmml">{</mo><msub id="Sx4.Ex1.m1.1.1.1.1.1.1.1" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.cmml"><mi mathsize="90%" id="Sx4.Ex1.m1.1.1.1.1.1.1.1.2" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.2.cmml">w</mi><mi mathsize="90%" id="Sx4.Ex1.m1.1.1.1.1.1.1.1.3" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.3.cmml">k</mi></msub><mo lspace="0em" mathsize="90%" rspace="0em" id="Sx4.Ex1.m1.1.1.1.1.1.2.4" xref="Sx4.Ex1.m1.1.1.1.1.1.3.1.cmml">|</mo><mrow id="Sx4.Ex1.m1.1.1.1.1.1.2.2" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.cmml"><msub id="Sx4.Ex1.m1.1.1.1.1.1.2.2.2" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.2.cmml"><mi mathsize="90%" id="Sx4.Ex1.m1.1.1.1.1.1.2.2.2.2" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.2.2.cmml">w</mi><mi mathsize="90%" id="Sx4.Ex1.m1.1.1.1.1.1.2.2.2.3" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.2.3.cmml">k</mi></msub><mo mathsize="90%" id="Sx4.Ex1.m1.1.1.1.1.1.2.2.3" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.3.cmml">∈</mo><mrow id="Sx4.Ex1.m1.1.1.1.1.1.2.2.4" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.cmml"><msub id="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.2" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.2.cmml"><mi mathsize="90%" id="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.2.2" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.2.2.cmml">S</mi><mi mathsize="90%" id="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.2.3" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.2.3.cmml">i</mi></msub><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.1" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.1.cmml">&amp;</mo><msub id="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.3" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.3.cmml"><mi mathsize="90%" id="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.3.2" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.3.2.cmml">w</mi><mi mathsize="90%" id="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.3.3" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.3.3.cmml">k</mi></msub></mrow><mo mathsize="90%" id="Sx4.Ex1.m1.1.1.1.1.1.2.2.5" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.5.cmml">∈</mo><msub id="Sx4.Ex1.m1.1.1.1.1.1.2.2.6" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.6.cmml"><mi mathsize="90%" id="Sx4.Ex1.m1.1.1.1.1.1.2.2.6.2" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.6.2.cmml">S</mi><mi mathsize="90%" id="Sx4.Ex1.m1.1.1.1.1.1.2.2.6.3" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.6.3.cmml">j</mi></msub></mrow><mo maxsize="90%" minsize="90%" id="Sx4.Ex1.m1.1.1.1.1.1.2.5" xref="Sx4.Ex1.m1.1.1.1.1.1.3.1.cmml">}</mo></mrow><mo maxsize="90%" minsize="90%" id="Sx4.Ex1.m1.1.1.1.1.3" xref="Sx4.Ex1.m1.1.1.1.2.1.cmml">|</mo></mrow><mrow id="Sx4.Ex1.m1.2.2.2" xref="Sx4.Ex1.m1.2.2.2.cmml"><mi mathsize="90%" id="Sx4.Ex1.m1.2.2.2.3" xref="Sx4.Ex1.m1.2.2.2.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="Sx4.Ex1.m1.2.2.2.2" xref="Sx4.Ex1.m1.2.2.2.2.cmml">​</mo><mi mathsize="90%" id="Sx4.Ex1.m1.2.2.2.4" xref="Sx4.Ex1.m1.2.2.2.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="Sx4.Ex1.m1.2.2.2.2a" xref="Sx4.Ex1.m1.2.2.2.2.cmml">​</mo><mi mathsize="90%" id="Sx4.Ex1.m1.2.2.2.5" xref="Sx4.Ex1.m1.2.2.2.5.cmml">g</mi><mo lspace="0em" rspace="0em" id="Sx4.Ex1.m1.2.2.2.2b" xref="Sx4.Ex1.m1.2.2.2.2.cmml">​</mo><mrow id="Sx4.Ex1.m1.2.2.2.1.1" xref="Sx4.Ex1.m1.2.2.2.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="Sx4.Ex1.m1.2.2.2.1.1.2" xref="Sx4.Ex1.m1.2.2.2.1.1.1.cmml">(</mo><mrow id="Sx4.Ex1.m1.2.2.2.1.1.1" xref="Sx4.Ex1.m1.2.2.2.1.1.1.cmml"><mrow id="Sx4.Ex1.m1.2.2.2.1.1.1.1.1" xref="Sx4.Ex1.m1.2.2.2.1.1.1.1.2.cmml"><mo maxsize="90%" minsize="90%" id="Sx4.Ex1.m1.2.2.2.1.1.1.1.1.2" xref="Sx4.Ex1.m1.2.2.2.1.1.1.1.2.1.cmml">|</mo><msub id="Sx4.Ex1.m1.2.2.2.1.1.1.1.1.1" xref="Sx4.Ex1.m1.2.2.2.1.1.1.1.1.1.cmml"><mi mathsize="90%" id="Sx4.Ex1.m1.2.2.2.1.1.1.1.1.1.2" xref="Sx4.Ex1.m1.2.2.2.1.1.1.1.1.1.2.cmml">S</mi><mi mathsize="90%" id="Sx4.Ex1.m1.2.2.2.1.1.1.1.1.1.3" xref="Sx4.Ex1.m1.2.2.2.1.1.1.1.1.1.3.cmml">i</mi></msub><mo maxsize="90%" minsize="90%" id="Sx4.Ex1.m1.2.2.2.1.1.1.1.1.3" xref="Sx4.Ex1.m1.2.2.2.1.1.1.1.2.1.cmml">|</mo></mrow><mo mathsize="90%" id="Sx4.Ex1.m1.2.2.2.1.1.1.3" xref="Sx4.Ex1.m1.2.2.2.1.1.1.3.cmml">+</mo><mrow id="Sx4.Ex1.m1.2.2.2.1.1.1.2" xref="Sx4.Ex1.m1.2.2.2.1.1.1.2.cmml"><mi mathsize="90%" id="Sx4.Ex1.m1.2.2.2.1.1.1.2.3" xref="Sx4.Ex1.m1.2.2.2.1.1.1.2.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="Sx4.Ex1.m1.2.2.2.1.1.1.2.2" xref="Sx4.Ex1.m1.2.2.2.1.1.1.2.2.cmml">​</mo><mi mathsize="90%" id="Sx4.Ex1.m1.2.2.2.1.1.1.2.4" xref="Sx4.Ex1.m1.2.2.2.1.1.1.2.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="Sx4.Ex1.m1.2.2.2.1.1.1.2.2a" xref="Sx4.Ex1.m1.2.2.2.1.1.1.2.2.cmml">​</mo><mi mathsize="90%" id="Sx4.Ex1.m1.2.2.2.1.1.1.2.5" xref="Sx4.Ex1.m1.2.2.2.1.1.1.2.5.cmml">g</mi><mo lspace="0em" rspace="0em" id="Sx4.Ex1.m1.2.2.2.1.1.1.2.2b" xref="Sx4.Ex1.m1.2.2.2.1.1.1.2.2.cmml">​</mo><mrow id="Sx4.Ex1.m1.2.2.2.1.1.1.2.1.1" xref="Sx4.Ex1.m1.2.2.2.1.1.1.2.cmml"><mo maxsize="90%" minsize="90%" id="Sx4.Ex1.m1.2.2.2.1.1.1.2.1.1.2" xref="Sx4.Ex1.m1.2.2.2.1.1.1.2.cmml">(</mo><mrow id="Sx4.Ex1.m1.2.2.2.1.1.1.2.1.1.1.1" xref="Sx4.Ex1.m1.2.2.2.1.1.1.2.1.1.1.2.cmml"><mo maxsize="90%" minsize="90%" id="Sx4.Ex1.m1.2.2.2.1.1.1.2.1.1.1.1.2" xref="Sx4.Ex1.m1.2.2.2.1.1.1.2.1.1.1.2.1.cmml">|</mo><msub id="Sx4.Ex1.m1.2.2.2.1.1.1.2.1.1.1.1.1" xref="Sx4.Ex1.m1.2.2.2.1.1.1.2.1.1.1.1.1.cmml"><mi mathsize="90%" id="Sx4.Ex1.m1.2.2.2.1.1.1.2.1.1.1.1.1.2" xref="Sx4.Ex1.m1.2.2.2.1.1.1.2.1.1.1.1.1.2.cmml">S</mi><mi mathsize="90%" id="Sx4.Ex1.m1.2.2.2.1.1.1.2.1.1.1.1.1.3" xref="Sx4.Ex1.m1.2.2.2.1.1.1.2.1.1.1.1.1.3.cmml">j</mi></msub><mo maxsize="90%" minsize="90%" id="Sx4.Ex1.m1.2.2.2.1.1.1.2.1.1.1.1.3" xref="Sx4.Ex1.m1.2.2.2.1.1.1.2.1.1.1.2.1.cmml">|</mo></mrow><mo maxsize="90%" minsize="90%" id="Sx4.Ex1.m1.2.2.2.1.1.1.2.1.1.3" xref="Sx4.Ex1.m1.2.2.2.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo maxsize="90%" minsize="90%" id="Sx4.Ex1.m1.2.2.2.1.1.3" xref="Sx4.Ex1.m1.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="Sx4.Ex1.m1.4b"><apply id="Sx4.Ex1.m1.4.4.cmml" xref="Sx4.Ex1.m1.4.4"><eq id="Sx4.Ex1.m1.4.4.3.cmml" xref="Sx4.Ex1.m1.4.4.3"></eq><apply id="Sx4.Ex1.m1.4.4.2.cmml" xref="Sx4.Ex1.m1.4.4.2"><times id="Sx4.Ex1.m1.4.4.2.3.cmml" xref="Sx4.Ex1.m1.4.4.2.3"></times><ci id="Sx4.Ex1.m1.4.4.2.4.cmml" xref="Sx4.Ex1.m1.4.4.2.4">𝑆</ci><ci id="Sx4.Ex1.m1.4.4.2.5.cmml" xref="Sx4.Ex1.m1.4.4.2.5">𝑖</ci><ci id="Sx4.Ex1.m1.4.4.2.6.cmml" xref="Sx4.Ex1.m1.4.4.2.6">𝑚</ci><interval closure="open" id="Sx4.Ex1.m1.4.4.2.2.3.cmml" xref="Sx4.Ex1.m1.4.4.2.2.2"><apply id="Sx4.Ex1.m1.3.3.1.1.1.1.cmml" xref="Sx4.Ex1.m1.3.3.1.1.1.1"><csymbol cd="ambiguous" id="Sx4.Ex1.m1.3.3.1.1.1.1.1.cmml" xref="Sx4.Ex1.m1.3.3.1.1.1.1">subscript</csymbol><ci id="Sx4.Ex1.m1.3.3.1.1.1.1.2.cmml" xref="Sx4.Ex1.m1.3.3.1.1.1.1.2">𝑆</ci><ci id="Sx4.Ex1.m1.3.3.1.1.1.1.3.cmml" xref="Sx4.Ex1.m1.3.3.1.1.1.1.3">𝑖</ci></apply><apply id="Sx4.Ex1.m1.4.4.2.2.2.2.cmml" xref="Sx4.Ex1.m1.4.4.2.2.2.2"><csymbol cd="ambiguous" id="Sx4.Ex1.m1.4.4.2.2.2.2.1.cmml" xref="Sx4.Ex1.m1.4.4.2.2.2.2">subscript</csymbol><ci id="Sx4.Ex1.m1.4.4.2.2.2.2.2.cmml" xref="Sx4.Ex1.m1.4.4.2.2.2.2.2">𝑆</ci><ci id="Sx4.Ex1.m1.4.4.2.2.2.2.3.cmml" xref="Sx4.Ex1.m1.4.4.2.2.2.2.3">𝑗</ci></apply></interval></apply><apply id="Sx4.Ex1.m1.2.2.cmml" xref="Sx4.Ex1.m1.2.2"><divide id="Sx4.Ex1.m1.2.2.3.cmml" xref="Sx4.Ex1.m1.2.2"></divide><apply id="Sx4.Ex1.m1.1.1.1.2.cmml" xref="Sx4.Ex1.m1.1.1.1.1"><abs id="Sx4.Ex1.m1.1.1.1.2.1.cmml" xref="Sx4.Ex1.m1.1.1.1.1.2"></abs><apply id="Sx4.Ex1.m1.1.1.1.1.1.3.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.2"><csymbol cd="latexml" id="Sx4.Ex1.m1.1.1.1.1.1.3.1.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.2.3">conditional-set</csymbol><apply id="Sx4.Ex1.m1.1.1.1.1.1.1.1.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="Sx4.Ex1.m1.1.1.1.1.1.1.1.1.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="Sx4.Ex1.m1.1.1.1.1.1.1.1.2.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.2">𝑤</ci><ci id="Sx4.Ex1.m1.1.1.1.1.1.1.1.3.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.1.1.3">𝑘</ci></apply><apply id="Sx4.Ex1.m1.1.1.1.1.1.2.2.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2"><and id="Sx4.Ex1.m1.1.1.1.1.1.2.2a.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2"></and><apply id="Sx4.Ex1.m1.1.1.1.1.1.2.2b.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2"><in id="Sx4.Ex1.m1.1.1.1.1.1.2.2.3.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.3"></in><apply id="Sx4.Ex1.m1.1.1.1.1.1.2.2.2.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="Sx4.Ex1.m1.1.1.1.1.1.2.2.2.1.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="Sx4.Ex1.m1.1.1.1.1.1.2.2.2.2.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.2.2">𝑤</ci><ci id="Sx4.Ex1.m1.1.1.1.1.1.2.2.2.3.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.2.3">𝑘</ci></apply><apply id="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.4"><and id="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.1.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.1"></and><apply id="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.2.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.2"><csymbol cd="ambiguous" id="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.2.1.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.2">subscript</csymbol><ci id="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.2.2.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.2.2">𝑆</ci><ci id="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.2.3.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.2.3">𝑖</ci></apply><apply id="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.3.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.3"><csymbol cd="ambiguous" id="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.3.1.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.3">subscript</csymbol><ci id="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.3.2.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.3.2">𝑤</ci><ci id="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.3.3.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.4.3.3">𝑘</ci></apply></apply></apply><apply id="Sx4.Ex1.m1.1.1.1.1.1.2.2c.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2"><in id="Sx4.Ex1.m1.1.1.1.1.1.2.2.5.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.5"></in><share href="#Sx4.Ex1.m1.1.1.1.1.1.2.2.4.cmml" id="Sx4.Ex1.m1.1.1.1.1.1.2.2d.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2"></share><apply id="Sx4.Ex1.m1.1.1.1.1.1.2.2.6.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.6"><csymbol cd="ambiguous" id="Sx4.Ex1.m1.1.1.1.1.1.2.2.6.1.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.6">subscript</csymbol><ci id="Sx4.Ex1.m1.1.1.1.1.1.2.2.6.2.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.6.2">𝑆</ci><ci id="Sx4.Ex1.m1.1.1.1.1.1.2.2.6.3.cmml" xref="Sx4.Ex1.m1.1.1.1.1.1.2.2.6.3">𝑗</ci></apply></apply></apply></apply></apply><apply id="Sx4.Ex1.m1.2.2.2.cmml" xref="Sx4.Ex1.m1.2.2.2"><times id="Sx4.Ex1.m1.2.2.2.2.cmml" xref="Sx4.Ex1.m1.2.2.2.2"></times><ci id="Sx4.Ex1.m1.2.2.2.3.cmml" xref="Sx4.Ex1.m1.2.2.2.3">𝑙</ci><ci id="Sx4.Ex1.m1.2.2.2.4.cmml" xref="Sx4.Ex1.m1.2.2.2.4">𝑜</ci><ci id="Sx4.Ex1.m1.2.2.2.5.cmml" xref="Sx4.Ex1.m1.2.2.2.5">𝑔</ci><apply id="Sx4.Ex1.m1.2.2.2.1.1.1.cmml" xref="Sx4.Ex1.m1.2.2.2.1.1"><plus id="Sx4.Ex1.m1.2.2.2.1.1.1.3.cmml" xref="Sx4.Ex1.m1.2.2.2.1.1.1.3"></plus><apply id="Sx4.Ex1.m1.2.2.2.1.1.1.1.2.cmml" xref="Sx4.Ex1.m1.2.2.2.1.1.1.1.1"><abs id="Sx4.Ex1.m1.2.2.2.1.1.1.1.2.1.cmml" xref="Sx4.Ex1.m1.2.2.2.1.1.1.1.1.2"></abs><apply id="Sx4.Ex1.m1.2.2.2.1.1.1.1.1.1.cmml" xref="Sx4.Ex1.m1.2.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="Sx4.Ex1.m1.2.2.2.1.1.1.1.1.1.1.cmml" xref="Sx4.Ex1.m1.2.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="Sx4.Ex1.m1.2.2.2.1.1.1.1.1.1.2.cmml" xref="Sx4.Ex1.m1.2.2.2.1.1.1.1.1.1.2">𝑆</ci><ci id="Sx4.Ex1.m1.2.2.2.1.1.1.1.1.1.3.cmml" xref="Sx4.Ex1.m1.2.2.2.1.1.1.1.1.1.3">𝑖</ci></apply></apply><apply id="Sx4.Ex1.m1.2.2.2.1.1.1.2.cmml" xref="Sx4.Ex1.m1.2.2.2.1.1.1.2"><times id="Sx4.Ex1.m1.2.2.2.1.1.1.2.2.cmml" xref="Sx4.Ex1.m1.2.2.2.1.1.1.2.2"></times><ci id="Sx4.Ex1.m1.2.2.2.1.1.1.2.3.cmml" xref="Sx4.Ex1.m1.2.2.2.1.1.1.2.3">𝑙</ci><ci id="Sx4.Ex1.m1.2.2.2.1.1.1.2.4.cmml" xref="Sx4.Ex1.m1.2.2.2.1.1.1.2.4">𝑜</ci><ci id="Sx4.Ex1.m1.2.2.2.1.1.1.2.5.cmml" xref="Sx4.Ex1.m1.2.2.2.1.1.1.2.5">𝑔</ci><apply id="Sx4.Ex1.m1.2.2.2.1.1.1.2.1.1.1.2.cmml" xref="Sx4.Ex1.m1.2.2.2.1.1.1.2.1.1.1.1"><abs id="Sx4.Ex1.m1.2.2.2.1.1.1.2.1.1.1.2.1.cmml" xref="Sx4.Ex1.m1.2.2.2.1.1.1.2.1.1.1.1.2"></abs><apply id="Sx4.Ex1.m1.2.2.2.1.1.1.2.1.1.1.1.1.cmml" xref="Sx4.Ex1.m1.2.2.2.1.1.1.2.1.1.1.1.1"><csymbol cd="ambiguous" id="Sx4.Ex1.m1.2.2.2.1.1.1.2.1.1.1.1.1.1.cmml" xref="Sx4.Ex1.m1.2.2.2.1.1.1.2.1.1.1.1.1">subscript</csymbol><ci id="Sx4.Ex1.m1.2.2.2.1.1.1.2.1.1.1.1.1.2.cmml" xref="Sx4.Ex1.m1.2.2.2.1.1.1.2.1.1.1.1.1.2">𝑆</ci><ci id="Sx4.Ex1.m1.2.2.2.1.1.1.2.1.1.1.1.1.3.cmml" xref="Sx4.Ex1.m1.2.2.2.1.1.1.2.1.1.1.1.1.3">𝑗</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.Ex1.m1.4c">Sim(S_{i},S_{j})=\frac{|\{w_{k}|w_{k}\in S_{i}\&amp;w_{k}\in S_{j}\}|}{log(|S_{i}|+log(|S_{j}|))}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="Sx4.SSx2.p1.2" class="ltx_p"><span id="Sx4.SSx2.p1.2.1" class="ltx_text" style="font-size:90%;">The other metric used to measure how similar two sentences are is the edit distance, in our case since the sentences are represented as tree, we work with tree edit distance. The tree edit distance (TED) </span><cite class="ltx_cite ltx_citemacro_cite"><span id="Sx4.SSx2.p1.2.2.1" class="ltx_text" style="font-size:90%;">(</span><a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">21</span></a><span id="Sx4.SSx2.p1.2.3.2" class="ltx_text" style="font-size:90%;">)</span></cite><span id="Sx4.SSx2.p1.2.4" class="ltx_text" style="font-size:90%;"> is calculated using the algorithm proposed by Zhang and Shasha in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="Sx4.SSx2.p1.2.5.1" class="ltx_text" style="font-size:90%;">(</span><a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">20</span></a><span id="Sx4.SSx2.p1.2.6.2" class="ltx_text" style="font-size:90%;">)</span></cite><span id="Sx4.SSx2.p1.2.7" class="ltx_text" style="font-size:90%;">. TED is a more accurate metric because it is able to account for the number of words in a sentence needed to be changed to match the other sentence, as compared to string based distance metrics that report on character changes, and such metric would be totally incorrect when comparing sentences of different lengths. The similarity of two sentences based on their distance is calculated as:</span></p>
<table id="Sx4.Ex2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="Sx4.Ex2.m1.4" class="ltx_Math" alttext="Sim(i,j)=\frac{1}{1+d(T_{i},T_{j})}" display="block"><semantics id="Sx4.Ex2.m1.4a"><mrow id="Sx4.Ex2.m1.4.5" xref="Sx4.Ex2.m1.4.5.cmml"><mrow id="Sx4.Ex2.m1.4.5.2" xref="Sx4.Ex2.m1.4.5.2.cmml"><mi mathsize="90%" id="Sx4.Ex2.m1.4.5.2.2" xref="Sx4.Ex2.m1.4.5.2.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="Sx4.Ex2.m1.4.5.2.1" xref="Sx4.Ex2.m1.4.5.2.1.cmml">​</mo><mi mathsize="90%" id="Sx4.Ex2.m1.4.5.2.3" xref="Sx4.Ex2.m1.4.5.2.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="Sx4.Ex2.m1.4.5.2.1a" xref="Sx4.Ex2.m1.4.5.2.1.cmml">​</mo><mi mathsize="90%" id="Sx4.Ex2.m1.4.5.2.4" xref="Sx4.Ex2.m1.4.5.2.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="Sx4.Ex2.m1.4.5.2.1b" xref="Sx4.Ex2.m1.4.5.2.1.cmml">​</mo><mrow id="Sx4.Ex2.m1.4.5.2.5.2" xref="Sx4.Ex2.m1.4.5.2.5.1.cmml"><mo maxsize="90%" minsize="90%" id="Sx4.Ex2.m1.4.5.2.5.2.1" xref="Sx4.Ex2.m1.4.5.2.5.1.cmml">(</mo><mi mathsize="90%" id="Sx4.Ex2.m1.3.3" xref="Sx4.Ex2.m1.3.3.cmml">i</mi><mo mathsize="90%" id="Sx4.Ex2.m1.4.5.2.5.2.2" xref="Sx4.Ex2.m1.4.5.2.5.1.cmml">,</mo><mi mathsize="90%" id="Sx4.Ex2.m1.4.4" xref="Sx4.Ex2.m1.4.4.cmml">j</mi><mo maxsize="90%" minsize="90%" id="Sx4.Ex2.m1.4.5.2.5.2.3" xref="Sx4.Ex2.m1.4.5.2.5.1.cmml">)</mo></mrow></mrow><mo mathsize="90%" id="Sx4.Ex2.m1.4.5.1" xref="Sx4.Ex2.m1.4.5.1.cmml">=</mo><mfrac id="Sx4.Ex2.m1.2.2" xref="Sx4.Ex2.m1.2.2.cmml"><mn mathsize="90%" id="Sx4.Ex2.m1.2.2.4" xref="Sx4.Ex2.m1.2.2.4.cmml">1</mn><mrow id="Sx4.Ex2.m1.2.2.2" xref="Sx4.Ex2.m1.2.2.2.cmml"><mn mathsize="90%" id="Sx4.Ex2.m1.2.2.2.4" xref="Sx4.Ex2.m1.2.2.2.4.cmml">1</mn><mo mathsize="90%" id="Sx4.Ex2.m1.2.2.2.3" xref="Sx4.Ex2.m1.2.2.2.3.cmml">+</mo><mrow id="Sx4.Ex2.m1.2.2.2.2" xref="Sx4.Ex2.m1.2.2.2.2.cmml"><mi mathsize="90%" id="Sx4.Ex2.m1.2.2.2.2.4" xref="Sx4.Ex2.m1.2.2.2.2.4.cmml">d</mi><mo lspace="0em" rspace="0em" id="Sx4.Ex2.m1.2.2.2.2.3" xref="Sx4.Ex2.m1.2.2.2.2.3.cmml">​</mo><mrow id="Sx4.Ex2.m1.2.2.2.2.2.2" xref="Sx4.Ex2.m1.2.2.2.2.2.3.cmml"><mo maxsize="90%" minsize="90%" id="Sx4.Ex2.m1.2.2.2.2.2.2.3" xref="Sx4.Ex2.m1.2.2.2.2.2.3.cmml">(</mo><msub id="Sx4.Ex2.m1.1.1.1.1.1.1.1" xref="Sx4.Ex2.m1.1.1.1.1.1.1.1.cmml"><mi mathsize="90%" id="Sx4.Ex2.m1.1.1.1.1.1.1.1.2" xref="Sx4.Ex2.m1.1.1.1.1.1.1.1.2.cmml">T</mi><mi mathsize="90%" id="Sx4.Ex2.m1.1.1.1.1.1.1.1.3" xref="Sx4.Ex2.m1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo mathsize="90%" id="Sx4.Ex2.m1.2.2.2.2.2.2.4" xref="Sx4.Ex2.m1.2.2.2.2.2.3.cmml">,</mo><msub id="Sx4.Ex2.m1.2.2.2.2.2.2.2" xref="Sx4.Ex2.m1.2.2.2.2.2.2.2.cmml"><mi mathsize="90%" id="Sx4.Ex2.m1.2.2.2.2.2.2.2.2" xref="Sx4.Ex2.m1.2.2.2.2.2.2.2.2.cmml">T</mi><mi mathsize="90%" id="Sx4.Ex2.m1.2.2.2.2.2.2.2.3" xref="Sx4.Ex2.m1.2.2.2.2.2.2.2.3.cmml">j</mi></msub><mo maxsize="90%" minsize="90%" id="Sx4.Ex2.m1.2.2.2.2.2.2.5" xref="Sx4.Ex2.m1.2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="Sx4.Ex2.m1.4b"><apply id="Sx4.Ex2.m1.4.5.cmml" xref="Sx4.Ex2.m1.4.5"><eq id="Sx4.Ex2.m1.4.5.1.cmml" xref="Sx4.Ex2.m1.4.5.1"></eq><apply id="Sx4.Ex2.m1.4.5.2.cmml" xref="Sx4.Ex2.m1.4.5.2"><times id="Sx4.Ex2.m1.4.5.2.1.cmml" xref="Sx4.Ex2.m1.4.5.2.1"></times><ci id="Sx4.Ex2.m1.4.5.2.2.cmml" xref="Sx4.Ex2.m1.4.5.2.2">𝑆</ci><ci id="Sx4.Ex2.m1.4.5.2.3.cmml" xref="Sx4.Ex2.m1.4.5.2.3">𝑖</ci><ci id="Sx4.Ex2.m1.4.5.2.4.cmml" xref="Sx4.Ex2.m1.4.5.2.4">𝑚</ci><interval closure="open" id="Sx4.Ex2.m1.4.5.2.5.1.cmml" xref="Sx4.Ex2.m1.4.5.2.5.2"><ci id="Sx4.Ex2.m1.3.3.cmml" xref="Sx4.Ex2.m1.3.3">𝑖</ci><ci id="Sx4.Ex2.m1.4.4.cmml" xref="Sx4.Ex2.m1.4.4">𝑗</ci></interval></apply><apply id="Sx4.Ex2.m1.2.2.cmml" xref="Sx4.Ex2.m1.2.2"><divide id="Sx4.Ex2.m1.2.2.3.cmml" xref="Sx4.Ex2.m1.2.2"></divide><cn type="integer" id="Sx4.Ex2.m1.2.2.4.cmml" xref="Sx4.Ex2.m1.2.2.4">1</cn><apply id="Sx4.Ex2.m1.2.2.2.cmml" xref="Sx4.Ex2.m1.2.2.2"><plus id="Sx4.Ex2.m1.2.2.2.3.cmml" xref="Sx4.Ex2.m1.2.2.2.3"></plus><cn type="integer" id="Sx4.Ex2.m1.2.2.2.4.cmml" xref="Sx4.Ex2.m1.2.2.2.4">1</cn><apply id="Sx4.Ex2.m1.2.2.2.2.cmml" xref="Sx4.Ex2.m1.2.2.2.2"><times id="Sx4.Ex2.m1.2.2.2.2.3.cmml" xref="Sx4.Ex2.m1.2.2.2.2.3"></times><ci id="Sx4.Ex2.m1.2.2.2.2.4.cmml" xref="Sx4.Ex2.m1.2.2.2.2.4">𝑑</ci><interval closure="open" id="Sx4.Ex2.m1.2.2.2.2.2.3.cmml" xref="Sx4.Ex2.m1.2.2.2.2.2.2"><apply id="Sx4.Ex2.m1.1.1.1.1.1.1.1.cmml" xref="Sx4.Ex2.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="Sx4.Ex2.m1.1.1.1.1.1.1.1.1.cmml" xref="Sx4.Ex2.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="Sx4.Ex2.m1.1.1.1.1.1.1.1.2.cmml" xref="Sx4.Ex2.m1.1.1.1.1.1.1.1.2">𝑇</ci><ci id="Sx4.Ex2.m1.1.1.1.1.1.1.1.3.cmml" xref="Sx4.Ex2.m1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="Sx4.Ex2.m1.2.2.2.2.2.2.2.cmml" xref="Sx4.Ex2.m1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="Sx4.Ex2.m1.2.2.2.2.2.2.2.1.cmml" xref="Sx4.Ex2.m1.2.2.2.2.2.2.2">subscript</csymbol><ci id="Sx4.Ex2.m1.2.2.2.2.2.2.2.2.cmml" xref="Sx4.Ex2.m1.2.2.2.2.2.2.2.2">𝑇</ci><ci id="Sx4.Ex2.m1.2.2.2.2.2.2.2.3.cmml" xref="Sx4.Ex2.m1.2.2.2.2.2.2.2.3">𝑗</ci></apply></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Sx4.Ex2.m1.4c">Sim(i,j)=\frac{1}{1+d(T_{i},T_{j})}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
</section>
<section id="Sx4.SSx3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">Graph construction</h3>

<div id="Sx4.SSx3.p1" class="ltx_para">
<p id="Sx4.SSx3.p1.2" class="ltx_p"><span id="Sx4.SSx3.p1.2.1" class="ltx_text" style="font-size:90%;">After the document has been processed into sentences, we construct the undirected graph by generating a node for each sentence. Then, similiarities between each pair of sentences is calculated. Afterwards, the similiarities are sorted from highest to lowest, and based on a user defined threshold </span><math id="Sx4.SSx3.p1.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="Sx4.SSx3.p1.1.m1.1a"><mi mathsize="90%" id="Sx4.SSx3.p1.1.m1.1.1" xref="Sx4.SSx3.p1.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="Sx4.SSx3.p1.1.m1.1b"><ci id="Sx4.SSx3.p1.1.m1.1.1.cmml" xref="Sx4.SSx3.p1.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx3.p1.1.m1.1c">t</annotation></semantics></math><span id="Sx4.SSx3.p1.2.2" class="ltx_text" style="font-size:90%;">, we pick the top </span><math id="Sx4.SSx3.p1.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="Sx4.SSx3.p1.2.m2.1a"><mi mathsize="90%" id="Sx4.SSx3.p1.2.m2.1.1" xref="Sx4.SSx3.p1.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="Sx4.SSx3.p1.2.m2.1b"><ci id="Sx4.SSx3.p1.2.m2.1.1.cmml" xref="Sx4.SSx3.p1.2.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx3.p1.2.m2.1c">t</annotation></semantics></math><span id="Sx4.SSx3.p1.2.3" class="ltx_text" style="font-size:90%;"> percent of similiar pairs to serve as the edges of the graph.</span></p>
</div>
<figure id="Sx4.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2106.10955/assets/sent_sim_01.png" id="Sx4.F2.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="240" height="182" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2106.10955/assets/sent_sim_05.png" id="Sx4.F2.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="240" height="182" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Sentence similiarity graphs generated using t=0.1 and t=0.5 respectively.</figcaption>
</figure>
</section>
<section id="Sx4.SSx4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">Algorithms</h3>

<div id="Sx4.SSx4.p1" class="ltx_para">
<p id="Sx4.SSx4.p1.1" class="ltx_p"><span id="Sx4.SSx4.p1.1.1" class="ltx_text" style="font-size:90%;">The implementation of PageRank, Hits, Closeness, Betweenness and degree measures is straight forward - after the scores for each node(sentence) have been computed, they are ranked and top N sentences are picked where </span><math id="Sx4.SSx4.p1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="Sx4.SSx4.p1.1.m1.1a"><mi mathsize="90%" id="Sx4.SSx4.p1.1.m1.1.1" xref="Sx4.SSx4.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="Sx4.SSx4.p1.1.m1.1b"><ci id="Sx4.SSx4.p1.1.m1.1.1.cmml" xref="Sx4.SSx4.p1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="Sx4.SSx4.p1.1.m1.1c">N</annotation></semantics></math><span id="Sx4.SSx4.p1.1.2" class="ltx_text" style="font-size:90%;"> is a user defined parameter symbolizing the desired summary length. Whereas, for the clustering method, after the cliques in the graph have been found we process them in the following way:</span></p>
<ul id="Sx4.I1" class="ltx_itemize">
<li id="Sx4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx4.I1.i1.p1" class="ltx_para">
<p id="Sx4.I1.i1.p1.1" class="ltx_p"><span id="Sx4.I1.i1.p1.1.1" class="ltx_text" style="font-size:90%;">we ignore cliques with one item</span></p>
</div>
</li>
<li id="Sx4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx4.I1.i2.p1" class="ltx_para">
<p id="Sx4.I1.i2.p1.1" class="ltx_p"><span id="Sx4.I1.i2.p1.1.1" class="ltx_text" style="font-size:90%;">for cliques with more than two items, we consider their closeness scores from which we pick the one item with the highest scores</span></p>
</div>
</li>
<li id="Sx4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx4.I1.i3.p1" class="ltx_para">
<p id="Sx4.I1.i3.p1.1" class="ltx_p"><span id="Sx4.I1.i3.p1.1.1" class="ltx_text" style="font-size:90%;">in case one item is found to be the highest scoring item in more than one clique, we pick that as the representive for the cluster with the bigger clique, and the selection moves onto the second highest scoring item in the remaining clique</span></p>
</div>
</li>
</ul>
</div>
</section>
<section id="Sx4.SSx5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">Evaluation</h3>

<div id="Sx4.SSx5.p1" class="ltx_para">
<p id="Sx4.SSx5.p1.1" class="ltx_p"><span id="Sx4.SSx5.p1.1.1" class="ltx_text" style="font-size:90%;">Our extracted summaries are evaluated using the Recall-Oriented Understudy for Gisting Evaluation - ROGUE metric. We have incorporated three types of ROGUE evaluation metric. Rogue-1, the overlap of unigrams (each word) between extracted summary and ground truth summary provided in the dataset, Rogue-2, the overlap of bigrams in the respective relation, and Rogue-L which reports on the longest common subsequence statistics.
</span><span id="Sx4.SSx5.p1.1.2" class="ltx_ERROR undefined">\acknow</span><span id="Sx4.SSx5.p1.1.3" class="ltx_text" style="font-size:90%;">The authors would like to acknowledge these works:</span></p>
</div>
<div id="Sx4.SSx5.p2" class="ltx_para">
<span id="Sx4.SSx5.p2.1" class="ltx_ERROR undefined">\showacknow</span>
</div>
</section>
</section>
<section id="bib" class="ltx_bibliography" lang="en">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib1.4.4.1" class="ltx_text" style="font-size:90%;">Kastriot (2021)</span></span>
<span class="ltx_bibblock"><span id="bib.bib1.6.1" class="ltx_text" style="font-size:90%;">
Kadriu Kastriot, 2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.7.1" class="ltx_text" style="font-size:90%;">URL </span><a target="_blank" href="https://github.com/tot98git/text-summ" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://github.com/tot98git/text-summ</a><span id="bib.bib1.8.2" class="ltx_text" style="font-size:90%;">.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib2.4.4.1" class="ltx_text" style="font-size:90%;">Mihalcea and Tarau (2016)</span></span>
<span class="ltx_bibblock"><span id="bib.bib2.6.1" class="ltx_text" style="font-size:90%;">
Rada Mihalcea and Paul Tarau.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.7.1" class="ltx_text" style="font-size:90%;">Textrank: Bringing order into texts.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.8.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib2.9.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the International Conference on
Advances in Social Networks Analysis and Mining</em><span id="bib.bib2.10.3" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib3.5.5.1" class="ltx_text" style="font-size:90%;">Liu et al. (2018)</span></span>
<span class="ltx_bibblock"><span id="bib.bib3.7.1" class="ltx_text" style="font-size:90%;">
Yike Liu, Tara Safavi, Neil Shah, and Danai. Koutra.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.8.1" class="ltx_text" style="font-size:90%;">Reducing large graphs to small supergraphs: A unified approach.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib3.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the Social Network Analysis and Mining
journal.</em><span id="bib.bib3.11.3" class="ltx_text" style="font-size:90%;">, San Francisco, CA, USA, 2018.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib4.4.4.1" class="ltx_text" style="font-size:90%;">Moradi (2019)</span></span>
<span class="ltx_bibblock"><span id="bib.bib4.6.1" class="ltx_text" style="font-size:90%;">
Milad Moradi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.7.1" class="ltx_text" style="font-size:90%;">Small-world networks for summarization of biomedical articles.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.8.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib4.9.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Section for Artificial Intelligence and Decision Support,
Medical University of Vienna, Austria</em><span id="bib.bib4.10.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib5.5.5.1" class="ltx_text" style="font-size:90%;">Thakkar S. et al. (2010)</span></span>
<span class="ltx_bibblock"><span id="bib.bib5.7.1" class="ltx_text" style="font-size:90%;">
Khushboo Thakkar S., R Dharaskar V., and B. Chandak.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.8.1" class="ltx_text" style="font-size:90%;">Graph-based algorithms for text summarization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib5.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of Third International Conference on Emerging
Trends in Engineering and Technology</em><span id="bib.bib5.11.3" class="ltx_text" style="font-size:90%;">, 2010.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib6.4.4.1" class="ltx_text" style="font-size:90%;">Wu and Hu (2018)</span></span>
<span class="ltx_bibblock"><span id="bib.bib6.6.1" class="ltx_text" style="font-size:90%;">
Yuxiang Wu and Baotian Hu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.7.1" class="ltx_text" style="font-size:90%;">Learning to extract coherent summary via deep reinforcement learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.8.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib6.9.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of The Thirty-Second AAAI Conference on
Artificial Intelligence</em><span id="bib.bib6.10.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib7.5.5.1" class="ltx_text" style="font-size:90%;">Gehrmann et al. (2019)</span></span>
<span class="ltx_bibblock"><span id="bib.bib7.7.1" class="ltx_text" style="font-size:90%;">
Sebsatian Gehrmann, Zachary Ziegler, and Alexander. Rush.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.8.1" class="ltx_text" style="font-size:90%;">Generating abstractive summaries with finetuned language models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib7.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the 12th International Conference on Natural
Language Generation</em><span id="bib.bib7.11.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib8.5.5.1" class="ltx_text" style="font-size:90%;">Manju et al. (2021)</span></span>
<span class="ltx_bibblock"><span id="bib.bib8.7.1" class="ltx_text" style="font-size:90%;">
K. Manju, S. Peter David, and Sumam Idicula Mary.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.8.1" class="ltx_text" style="font-size:90%;">A framework for generating extractive summary from multiple malayalam
documents, 2021.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib9.4.4.1" class="ltx_text" style="font-size:90%;">Banko and Vanderwede (2004)</span></span>
<span class="ltx_bibblock"><span id="bib.bib9.6.1" class="ltx_text" style="font-size:90%;">
Michele Banko and Lucy Vanderwede.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.7.1" class="ltx_text" style="font-size:90%;">Using n-grams to understand the nature of summaries, 2004.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib10.4.4.1" class="ltx_text" style="font-size:90%;">Erkan and Radev R. (2004)</span></span>
<span class="ltx_bibblock"><span id="bib.bib10.6.1" class="ltx_text" style="font-size:90%;">
Günes Erkan and Dragomir Radev R.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.7.1" class="ltx_text" style="font-size:90%;">Lexpagerank: Prestige in multi-document text summarization, 2004.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib11.5.5.1" class="ltx_text" style="font-size:90%;">Abdul Rasheed Issam et al. (2020)</span></span>
<span class="ltx_bibblock"><span id="bib.bib11.7.1" class="ltx_text" style="font-size:90%;">
Kalliath Abdul Rasheed Issam, Shivam Patel, and Subalalitha C. N.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.8.1" class="ltx_text" style="font-size:90%;">Topic modeling based extractive text summarization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib11.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the International Journal of Innovative
Technology and Exploring Engineering (IJITEE) ISSN: 2278-3075, Volume-9
Issue-6, April 2020</em><span id="bib.bib11.11.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib12.5.5.1" class="ltx_text" style="font-size:90%;">Rush et al. (2015)</span></span>
<span class="ltx_bibblock"><span id="bib.bib12.7.1" class="ltx_text" style="font-size:90%;">
Alexander M. Rush, Sumit Chopra, and Jason Weston.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.8.1" class="ltx_text" style="font-size:90%;">A neural attention model for abstractive sentence summarization.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib12.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the 2015 Conference on Empirical Methods in
Natural Language Processing</em><span id="bib.bib12.10.2" class="ltx_text" style="font-size:90%;">, 2015.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https:/doi.org/10.18653/v1/d15-1044" title="" class="ltx_ref" style="font-size:90%;">10.18653/v1/d15-1044</a><span id="bib.bib12.11.1" class="ltx_text" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.12.1" class="ltx_text" style="font-size:90%;">URL </span><a target="_blank" href="http://dx.doi.org/10.18653/v1/D15-1044" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">http://dx.doi.org/10.18653/v1/D15-1044</a><span id="bib.bib12.13.2" class="ltx_text" style="font-size:90%;">.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib13.5.5.1" class="ltx_text" style="font-size:90%;">Gialitsis et al. (2019)</span></span>
<span class="ltx_bibblock"><span id="bib.bib13.7.1" class="ltx_text" style="font-size:90%;">
Nikolaos Gialitsis, Nikiforos Pittaras, and Panagiotis Stamatopoulos.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.8.1" class="ltx_text" style="font-size:90%;">A topic-based sentence representation for extractive text
summarization.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib13.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the Multiling 2019 Workshop, co-located with the
RANLP 2019 conference</em><span id="bib.bib13.10.2" class="ltx_text" style="font-size:90%;">, 1(Pages 26-34), 2019.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib14.5.5.1" class="ltx_text" style="font-size:90%;">Hafeez et al. (2018)</span></span>
<span class="ltx_bibblock"><span id="bib.bib14.7.1" class="ltx_text" style="font-size:90%;">
Rubab Hafeez, Sharifullah Khan, Muhammad Azem Abbas, and Fahad Maqbool.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.8.1" class="ltx_text" style="font-size:90%;">Topic based summarization of multiple documents using semantic
analysis and clustering.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib14.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">2018 15th International Conference on Smart Cities: Improving
Quality of Life Using ICT and IoT (HONET-ICT)</em><span id="bib.bib14.10.2" class="ltx_text" style="font-size:90%;">, 1(Page 18), 2018.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib15.5.5.1" class="ltx_text" style="font-size:90%;">Mallick et al. (2018)</span></span>
<span class="ltx_bibblock"><span id="bib.bib15.7.1" class="ltx_text" style="font-size:90%;">
Chirantana Mallick, Ajit Kumar Das, Madhurima Dutta, and Apurba Sarkar.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.8.1" class="ltx_text" style="font-size:90%;">Graph-based text summarization using modified textrank.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib15.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in Intelligent Systems and Computing</em><span id="bib.bib15.10.2" class="ltx_text" style="font-size:90%;">, 758, 2018.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib16.5.5.1" class="ltx_text" style="font-size:90%;">Qi et al. (2020)</span></span>
<span class="ltx_bibblock"><span id="bib.bib16.7.1" class="ltx_text" style="font-size:90%;">
Peng Qi, Yuhao Zhang, Yuhui Zhang, Jason Bolton, and Christopher D. Manning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.8.1" class="ltx_text" style="font-size:90%;">Stanza: A Python natural language processing toolkit for many human
languages.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib16.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics: System Demonstrations</em><span id="bib.bib16.11.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib17.4.4.1" class="ltx_text" style="font-size:90%;">Filippova (2010)</span></span>
<span class="ltx_bibblock"><span id="bib.bib17.6.1" class="ltx_text" style="font-size:90%;">
Katja Filippova.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.7.1" class="ltx_text" style="font-size:90%;">Multi-sentence compression: Finding shortest paths in word graphs.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.8.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib17.9.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the 23rd International Conference on
Computational Linguistics (Coling 2010), pages 322–330,</em><span id="bib.bib17.10.3" class="ltx_text" style="font-size:90%;">, 2010.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib18.5.5.1" class="ltx_text" style="font-size:90%;">See et al. (2017)</span></span>
<span class="ltx_bibblock"><span id="bib.bib18.7.1" class="ltx_text" style="font-size:90%;">
Abigail See, Peter J. Liu, and Christopher D. Manning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.8.1" class="ltx_text" style="font-size:90%;">Get to the point: Summarization with pointer-generator networks.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib18.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">CoRR</em><span id="bib.bib18.10.2" class="ltx_text" style="font-size:90%;">, abs/1704.04368, 2017.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.11.1" class="ltx_text" style="font-size:90%;">URL </span><a target="_blank" href="http://arxiv.org/abs/1704.04368" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">http://arxiv.org/abs/1704.04368</a><span id="bib.bib18.12.2" class="ltx_text" style="font-size:90%;">.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib19.5.5.1" class="ltx_text" style="font-size:90%;">Hermann et al. (2015)</span></span>
<span class="ltx_bibblock"><span id="bib.bib19.7.1" class="ltx_text" style="font-size:90%;">
Karl Moritz Hermann, Tomas Kocisky, Edward Grefenstette, Lasse Espeholt, Will
Kay, Mustafa Suleyman, and Phil Blunsom.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.8.1" class="ltx_text" style="font-size:90%;">Teaching machines to read and comprehend.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib19.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</em><span id="bib.bib19.11.3" class="ltx_text" style="font-size:90%;">, pages
1693–1701, 2015.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib20.4.4.1" class="ltx_text" style="font-size:90%;">Zhang and Shasha (1989)</span></span>
<span class="ltx_bibblock"><span id="bib.bib20.6.1" class="ltx_text" style="font-size:90%;">
K Zhang and D Shasha.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.7.1" class="ltx_text" style="font-size:90%;">Simple fast algorithms for the editing distance between trees and
related problems.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.8.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib20.9.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">SIAMJ.Comput.</em><span id="bib.bib20.10.3" class="ltx_text" style="font-size:90%;">, 1989.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib21.5.5.1" class="ltx_text" style="font-size:90%;">Sidorov et al. (2015)</span></span>
<span class="ltx_bibblock"><span id="bib.bib21.7.1" class="ltx_text" style="font-size:90%;">
Grigori Sidorov, Helena Gomez-Adorno, Ilia Markov, David Pinto, and Nahun Loya.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.8.1" class="ltx_text" style="font-size:90%;">Computing text similarity using tree edit distance, 2015.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib22.4.4.1" class="ltx_text" style="font-size:90%;">Loper and Bird (2002)</span></span>
<span class="ltx_bibblock"><span id="bib.bib22.6.1" class="ltx_text" style="font-size:90%;">
Edward Loper and Steven Bird.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.7.1" class="ltx_text" style="font-size:90%;">Nltk: the natural language toolkit.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib22.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the ACL-02 Workshop on Effective tools and
methodologies for teaching natura language processing and computational
linguistics</em><span id="bib.bib22.9.2" class="ltx_text" style="font-size:90%;">, 2(63-70), 2002.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib23.5.5.1" class="ltx_text" style="font-size:90%;">Hagber A. et al. (2008)</span></span>
<span class="ltx_bibblock"><span id="bib.bib23.7.1" class="ltx_text" style="font-size:90%;">
Aric Hagber A., Daniel Schult A., and Pieter Swart J.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.8.1" class="ltx_text" style="font-size:90%;">Exploring network structure, dynamics, and function using networkx.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib23.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the 7th Python in Science Conference
(SciPy2008),</em><span id="bib.bib23.10.2" class="ltx_text" style="font-size:90%;">, 1(11-15), 2008.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<div id="p4" class="ltx_para">
<p id="p4.1" class="ltx_p"></p>
</div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2106.10954" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2106.10955" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2106.10955">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2106.10955" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2106.10957" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  8 13:31:44 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
