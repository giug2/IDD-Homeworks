<article class="ltx_document ltx_authors_1line">
 <h1 class="ltx_title ltx_title_document">
  OPEx: A Component-Wise Analysis of LLM-Centric Agents
  <br class="ltx_break"/>
  in Embodied Instruction Following
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Haochen Shi
    <sup class="ltx_sup" id="id8.8.id1">
     1
    </sup>
    , Zhiyuan Sun
    <sup class="ltx_sup" id="id9.9.id2">
     1
    </sup>
    , Xingdi Yuan
    <sup class="ltx_sup" id="id10.10.id3">
     2
    </sup>
    , Marc-Alexandre Côté
    <sup class="ltx_sup" id="id11.11.id4">
     2
    </sup>
    , Bang Liu
    <sup class="ltx_sup" id="id12.12.id5">
     1
    </sup>
    <span class="ltx_note ltx_role_footnotemark" id="footnotex1">
     <sup class="ltx_note_mark">
      1
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        1
       </sup>
       <span class="ltx_note_type">
        footnotemark:
       </span>
       <span class="ltx_tag ltx_tag_note">
        1
       </span>
      </span>
     </span>
    </span>
    <br class="ltx_break"/>
    <sup class="ltx_sup" id="id13.13.id6">
     1
    </sup>
    Université de Montréal &amp; Mila, Montréal, Canada
    <br class="ltx_break"/>
    <sup class="ltx_sup" id="id14.14.id7">
     2
    </sup>
    Microsoft Research, Montréal, Canada
    <br class="ltx_break"/>
    {haochen.shi, zhiyuan.sun, bang.liu}@umontreal.ca,
    <br class="ltx_break"/>
    {eric.yuan, macote}@microsoft.com
   </span>
   <span class="ltx_author_notes">
    Equal advising.  Canada CIFAR AI Chair.
   </span>
  </span>
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract
  </h6>
  <p class="ltx_p" id="id15.id1">
   Embodied Instruction Following (EIF) is a crucial task in embodied learning, requiring agents to interact with their environment through egocentric observations to fulfill natural language instructions. Recent advancements have seen a surge in employing large language models (LLMs) within a framework-centric approach to enhance performance in embodied learning tasks, including EIF. Despite these efforts, there exists a lack of a unified understanding regarding the impact of various components—ranging from visual perception to action execution—on task performance. To address this gap, we introduce OPEx, a comprehensive framework that delineates the core components essential for solving embodied learning tasks: Observer, Planner, and Executor. Through extensive evaluations, we provide a deep analysis of how each component influences EIF task performance. Furthermore, we innovate within this space by deploying a multi-agent dialogue strategy on a TextWorld counterpart, further enhancing task performance. Our findings reveal that LLM-centric design markedly improves EIF outcomes, identify visual perception and low-level action execution as critical bottlenecks, and demonstrate that augmenting LLMs with a multi-agent framework further elevates performance.
  </p>
 </div>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    1
   </span>
   Introduction
  </h2>
  <div class="ltx_para" id="S1.p1">
   <p class="ltx_p" id="S1.p1.1">
    Embodied learning, particularly through tasks like Embodied Instruction Following (EIF)
    <cite class="ltx_cite ltx_citemacro_cite">
     Shridhar et al. (
     <a class="ltx_ref" href="#bib.bib33" title="">
      2020a
     </a>
     )
    </cite>
    , stands at the forefront of artificial intelligence research. EIF, where agents must interpret natural language instructions to navigate and act within their environment using egocentric observations, epitomizes the challenge of integrating cognitive understanding with physical action. This intersection is crucial for developing autonomous agents capable of nuanced interaction with complex, real-world environments, marking a significant stride towards more advanced and versatile AI systems. As the research community harnesses advancements in deep learning, we edge closer to this ambition
    <cite class="ltx_cite ltx_citemacro_cite">
     Baker et al. (
     <a class="ltx_ref" href="#bib.bib1" title="">
      2022
     </a>
     ); Min et al. (
     <a class="ltx_ref" href="#bib.bib21" title="">
      2021
     </a>
     ); Inoue and Ohashi (
     <a class="ltx_ref" href="#bib.bib13" title="">
      2022
     </a>
     ); Huang et al. (
     <a class="ltx_ref" href="#bib.bib11" title="">
      2022a
     </a>
     )
    </cite>
    .
   </p>
  </div>
  <div class="ltx_para" id="S1.p2">
   <p class="ltx_p" id="S1.p2.1">
    Traditional approaches to Embodied Instruction Following (EIF) often rely on expert-generated annotations, a process that can be both expensive and challenging to scale for real-world applications. In contrast, Large Language Models (LLMs), such as those cited in recent studies
    <cite class="ltx_cite ltx_citemacro_cite">
     Inoue and Ohashi (
     <a class="ltx_ref" href="#bib.bib13" title="">
      2022
     </a>
     ); OpenAI (
     <a class="ltx_ref" href="#bib.bib25" title="">
      2023
     </a>
     ); Wei et al. (
     <a class="ltx_ref" href="#bib.bib43" title="">
      2022a
     </a>
     ); Driess et al. (
     <a class="ltx_ref" href="#bib.bib7" title="">
      2023
     </a>
     ); Touvron et al. (
     <a class="ltx_ref" href="#bib.bib39" title="">
      2023
     </a>
     ); Huang et al. (
     <a class="ltx_ref" href="#bib.bib11" title="">
      2022a
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib12" title="">
      b
     </a>
     ); Liang et al. (
     <a class="ltx_ref" href="#bib.bib15" title="">
      2022
     </a>
     ); Wang et al. (
     <a class="ltx_ref" href="#bib.bib40" title="">
      2023a
     </a>
     ); Shinn et al. (
     <a class="ltx_ref" href="#bib.bib32" title="">
      2023
     </a>
     ); Song et al. (
     <a class="ltx_ref" href="#bib.bib37" title="">
      2023
     </a>
     )
    </cite>
    , have emerged as a potent alternative, showcasing exceptional capabilities in natural language understanding and generation. These models, enriched by extensive textual datasets, demonstrate significant common-sense reasoning abilities. As a result, there’s a growing trend towards leveraging LLM-centric architectures for embodied learning tasks including EIF, which promise to simplify planning and execution tasks through a few-shot learning paradigm. However, despite their potential, the implementations of
EIF systems introduce a variety of designs and components across different studies
    <cite class="ltx_cite ltx_citemacro_cite">
     Min et al. (
     <a class="ltx_ref" href="#bib.bib21" title="">
      2021
     </a>
     ); Inoue and Ohashi (
     <a class="ltx_ref" href="#bib.bib13" title="">
      2022
     </a>
     ); Song et al. (
     <a class="ltx_ref" href="#bib.bib37" title="">
      2023
     </a>
     ); Blukis et al. (
     <a class="ltx_ref" href="#bib.bib3" title="">
      2022
     </a>
     ); Wang et al. (
     <a class="ltx_ref" href="#bib.bib40" title="">
      2023a
     </a>
     ); Zhu et al. (
     <a class="ltx_ref" href="#bib.bib47" title="">
      2023
     </a>
     )
    </cite>
    . There remains a notable gap in systematically understanding how these disparate elements influence overall task performance, underscoring the need for a thorough analysis of LLM-centric methods within the context of EIF.
   </p>
  </div>
  <div class="ltx_para" id="S1.p3">
   <p class="ltx_p" id="S1.p3.1">
    In addressing the complexities of Embodied Instruction Following (EIF), we introduce OPEx, a novel framework designed to systematically outline the essential components for mastering embodied learning tasks. OPEx is segmented into three core parts: Observer, Planner, and Executor. The Observer component is tasked with processing and interpreting sensory inputs, primarily visual, to construct an actionable understanding of the agent’s immediate environment. The Planner dynamically devises strategic plans as subtasks to complete the tasks based on perceptual inputs, effectively bridging the gap between perception and action. Lastly, the Executor is responsible for implementing these plans with a skill library, which translates several re-useable skills into precise, context-aware actions within the environment, ensuring the agent’s interactions are both relevant and goal-oriented. This tripartite structure provides a clear delineation of roles within the system, facilitating a granular analysis of how each contributes to the overarching performance of EIF tasks.
   </p>
  </div>
  <div class="ltx_para" id="S1.p4">
   <p class="ltx_p" id="S1.p4.1">
    To understand the impact of each OPEx component on performance in EIF tasks, we conducted an in-depth analysis. By experimenting with different versions of the Observer, Planner, and Executor components, we assessed how each contributes to and influences overall success. This approach allowed us to identify the key attributes and design choices that enhance the system’s ability to tackle complex embodied tasks, providing clear insights into optimizing embodied learning agents.
   </p>
  </div>
  <div class="ltx_para" id="S1.p5">
   <p class="ltx_p" id="S1.p5.1">
    To further unlock the potential of LLMs in embodied learning, we eliminate the influence of visual perception and low-level action execution of the system utilizing a pure-text counterpart environment
    <cite class="ltx_cite ltx_citemacro_cite">
     Shridhar et al. (
     <a class="ltx_ref" href="#bib.bib34" title="">
      2020b
     </a>
     )
    </cite>
    and further adopt a multi-agent dialogue strategy, splitting the instruction-following challenge into distinct reasoning and grounding roles handled by a reasoner agent and an actor agent, respectively. This dialogue-driven approach simplifies the task into decision-making processes, where both agents utilize world knowledge obtained from an explorer. This explorer gathers insights either through direct interaction with the environment or from human contributions, thereby enriching the collaborative problem-solving capabilities of the reasoner and actor with more grounded and informed decision-making.
   </p>
  </div>
  <div class="ltx_para" id="S1.p6">
   <p class="ltx_p" id="S1.p6.1">
    Our experimental evaluation was conducted using the ALFRED
    <cite class="ltx_cite ltx_citemacro_cite">
     Shridhar et al. (
     <a class="ltx_ref" href="#bib.bib33" title="">
      2020a
     </a>
     )
    </cite>
    and ALFWorld
    <cite class="ltx_cite ltx_citemacro_cite">
     Shridhar et al. (
     <a class="ltx_ref" href="#bib.bib34" title="">
      2020b
     </a>
     )
    </cite>
    benchmarks, providing a comprehensive testing ground for our extensive evaluation. The core analysis of our experiments underscores significant advancements: the LLM-centric approach notably enhances performance in EIF tasks. We pinpoint visual perception and low-level action execution as pivotal bottlenecks. Moreover, our results affirm that incorporating a multi-agent dialogue strategy into an LLM-centric task solver significantly boosts overall task performance on AFLWorld, showcasing the effectiveness of our proposed methodology in addressing the complexities of embodied learning tasks.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    2
   </span>
   Task Formulation
  </h2>
  <div class="ltx_para" id="S2.p1">
   <p class="ltx_p" id="S2.p1.7">
    We benchmark our method with ALFRED
    <cite class="ltx_cite ltx_citemacro_cite">
     Shridhar et al. (
     <a class="ltx_ref" href="#bib.bib33" title="">
      2020a
     </a>
     )
    </cite>
    and its TextWorld counterpart ALFWorld
    <cite class="ltx_cite ltx_citemacro_cite">
     Shridhar et al. (
     <a class="ltx_ref" href="#bib.bib34" title="">
      2020b
     </a>
     )
    </cite>
    . Both contain a set of environments associated with long-horizon household tasks specified by natural language instructions.
The language instruction
    <math alttext="L=\{L_{\text{high}},L_{\text{low}}\}" class="ltx_Math" display="inline" id="S2.p1.1.m1.2">
     <semantics id="S2.p1.1.m1.2a">
      <mrow id="S2.p1.1.m1.2.2" xref="S2.p1.1.m1.2.2.cmml">
       <mi id="S2.p1.1.m1.2.2.4" xref="S2.p1.1.m1.2.2.4.cmml">
        L
       </mi>
       <mo id="S2.p1.1.m1.2.2.3" xref="S2.p1.1.m1.2.2.3.cmml">
        =
       </mo>
       <mrow id="S2.p1.1.m1.2.2.2.2" xref="S2.p1.1.m1.2.2.2.3.cmml">
        <mo id="S2.p1.1.m1.2.2.2.2.3" stretchy="false" xref="S2.p1.1.m1.2.2.2.3.cmml">
         {
        </mo>
        <msub id="S2.p1.1.m1.1.1.1.1.1" xref="S2.p1.1.m1.1.1.1.1.1.cmml">
         <mi id="S2.p1.1.m1.1.1.1.1.1.2" xref="S2.p1.1.m1.1.1.1.1.1.2.cmml">
          L
         </mi>
         <mtext id="S2.p1.1.m1.1.1.1.1.1.3" xref="S2.p1.1.m1.1.1.1.1.1.3a.cmml">
          high
         </mtext>
        </msub>
        <mo id="S2.p1.1.m1.2.2.2.2.4" xref="S2.p1.1.m1.2.2.2.3.cmml">
         ,
        </mo>
        <msub id="S2.p1.1.m1.2.2.2.2.2" xref="S2.p1.1.m1.2.2.2.2.2.cmml">
         <mi id="S2.p1.1.m1.2.2.2.2.2.2" xref="S2.p1.1.m1.2.2.2.2.2.2.cmml">
          L
         </mi>
         <mtext id="S2.p1.1.m1.2.2.2.2.2.3" xref="S2.p1.1.m1.2.2.2.2.2.3a.cmml">
          low
         </mtext>
        </msub>
        <mo id="S2.p1.1.m1.2.2.2.2.5" stretchy="false" xref="S2.p1.1.m1.2.2.2.3.cmml">
         }
        </mo>
       </mrow>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.2b">
       <apply id="S2.p1.1.m1.2.2.cmml" xref="S2.p1.1.m1.2.2">
        <eq id="S2.p1.1.m1.2.2.3.cmml" xref="S2.p1.1.m1.2.2.3">
        </eq>
        <ci id="S2.p1.1.m1.2.2.4.cmml" xref="S2.p1.1.m1.2.2.4">
         𝐿
        </ci>
        <set id="S2.p1.1.m1.2.2.2.3.cmml" xref="S2.p1.1.m1.2.2.2.2">
         <apply id="S2.p1.1.m1.1.1.1.1.1.cmml" xref="S2.p1.1.m1.1.1.1.1.1">
          <csymbol cd="ambiguous" id="S2.p1.1.m1.1.1.1.1.1.1.cmml" xref="S2.p1.1.m1.1.1.1.1.1">
           subscript
          </csymbol>
          <ci id="S2.p1.1.m1.1.1.1.1.1.2.cmml" xref="S2.p1.1.m1.1.1.1.1.1.2">
           𝐿
          </ci>
          <ci id="S2.p1.1.m1.1.1.1.1.1.3a.cmml" xref="S2.p1.1.m1.1.1.1.1.1.3">
           <mtext id="S2.p1.1.m1.1.1.1.1.1.3.cmml" mathsize="70%" xref="S2.p1.1.m1.1.1.1.1.1.3">
            high
           </mtext>
          </ci>
         </apply>
         <apply id="S2.p1.1.m1.2.2.2.2.2.cmml" xref="S2.p1.1.m1.2.2.2.2.2">
          <csymbol cd="ambiguous" id="S2.p1.1.m1.2.2.2.2.2.1.cmml" xref="S2.p1.1.m1.2.2.2.2.2">
           subscript
          </csymbol>
          <ci id="S2.p1.1.m1.2.2.2.2.2.2.cmml" xref="S2.p1.1.m1.2.2.2.2.2.2">
           𝐿
          </ci>
          <ci id="S2.p1.1.m1.2.2.2.2.2.3a.cmml" xref="S2.p1.1.m1.2.2.2.2.2.3">
           <mtext id="S2.p1.1.m1.2.2.2.2.2.3.cmml" mathsize="70%" xref="S2.p1.1.m1.2.2.2.2.2.3">
            low
           </mtext>
          </ci>
         </apply>
        </set>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p1.1.m1.2c">
       L=\{L_{\text{high}},L_{\text{low}}\}
      </annotation>
     </semantics>
    </math>
    consists of instructions at two different levels: a high-level instruction goal
    <math alttext="L_{\text{high}}" class="ltx_Math" display="inline" id="S2.p1.2.m2.1">
     <semantics id="S2.p1.2.m2.1a">
      <msub id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml">
       <mi id="S2.p1.2.m2.1.1.2" xref="S2.p1.2.m2.1.1.2.cmml">
        L
       </mi>
       <mtext id="S2.p1.2.m2.1.1.3" xref="S2.p1.2.m2.1.1.3a.cmml">
        high
       </mtext>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b">
       <apply id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1">
        <csymbol cd="ambiguous" id="S2.p1.2.m2.1.1.1.cmml" xref="S2.p1.2.m2.1.1">
         subscript
        </csymbol>
        <ci id="S2.p1.2.m2.1.1.2.cmml" xref="S2.p1.2.m2.1.1.2">
         𝐿
        </ci>
        <ci id="S2.p1.2.m2.1.1.3a.cmml" xref="S2.p1.2.m2.1.1.3">
         <mtext id="S2.p1.2.m2.1.1.3.cmml" mathsize="70%" xref="S2.p1.2.m2.1.1.3">
          high
         </mtext>
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">
       L_{\text{high}}
      </annotation>
     </semantics>
    </math>
    that summarizes the task and a sequence of low-level instructions
    <math alttext="L_{\text{low}}" class="ltx_Math" display="inline" id="S2.p1.3.m3.1">
     <semantics id="S2.p1.3.m3.1a">
      <msub id="S2.p1.3.m3.1.1" xref="S2.p1.3.m3.1.1.cmml">
       <mi id="S2.p1.3.m3.1.1.2" xref="S2.p1.3.m3.1.1.2.cmml">
        L
       </mi>
       <mtext id="S2.p1.3.m3.1.1.3" xref="S2.p1.3.m3.1.1.3a.cmml">
        low
       </mtext>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S2.p1.3.m3.1b">
       <apply id="S2.p1.3.m3.1.1.cmml" xref="S2.p1.3.m3.1.1">
        <csymbol cd="ambiguous" id="S2.p1.3.m3.1.1.1.cmml" xref="S2.p1.3.m3.1.1">
         subscript
        </csymbol>
        <ci id="S2.p1.3.m3.1.1.2.cmml" xref="S2.p1.3.m3.1.1.2">
         𝐿
        </ci>
        <ci id="S2.p1.3.m3.1.1.3a.cmml" xref="S2.p1.3.m3.1.1.3">
         <mtext id="S2.p1.3.m3.1.1.3.cmml" mathsize="70%" xref="S2.p1.3.m3.1.1.3">
          low
         </mtext>
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p1.3.m3.1c">
       L_{\text{low}}
      </annotation>
     </semantics>
    </math>
    that depict the specific actions required.
At the time step
    <math alttext="t" class="ltx_Math" display="inline" id="S2.p1.4.m4.1">
     <semantics id="S2.p1.4.m4.1a">
      <mi id="S2.p1.4.m4.1.1" xref="S2.p1.4.m4.1.1.cmml">
       t
      </mi>
      <annotation-xml encoding="MathML-Content" id="S2.p1.4.m4.1b">
       <ci id="S2.p1.4.m4.1.1.cmml" xref="S2.p1.4.m4.1.1">
        𝑡
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p1.4.m4.1c">
       t
      </annotation>
     </semantics>
    </math>
    , ALFRED also provides a visual egocentric observation
    <math alttext="V_{t}" class="ltx_Math" display="inline" id="S2.p1.5.m5.1">
     <semantics id="S2.p1.5.m5.1a">
      <msub id="S2.p1.5.m5.1.1" xref="S2.p1.5.m5.1.1.cmml">
       <mi id="S2.p1.5.m5.1.1.2" xref="S2.p1.5.m5.1.1.2.cmml">
        V
       </mi>
       <mi id="S2.p1.5.m5.1.1.3" xref="S2.p1.5.m5.1.1.3.cmml">
        t
       </mi>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S2.p1.5.m5.1b">
       <apply id="S2.p1.5.m5.1.1.cmml" xref="S2.p1.5.m5.1.1">
        <csymbol cd="ambiguous" id="S2.p1.5.m5.1.1.1.cmml" xref="S2.p1.5.m5.1.1">
         subscript
        </csymbol>
        <ci id="S2.p1.5.m5.1.1.2.cmml" xref="S2.p1.5.m5.1.1.2">
         𝑉
        </ci>
        <ci id="S2.p1.5.m5.1.1.3.cmml" xref="S2.p1.5.m5.1.1.3">
         𝑡
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p1.5.m5.1c">
       V_{t}
      </annotation>
     </semantics>
    </math>
    (text observation
    <math alttext="\mathcal{L}_{t}" class="ltx_Math" display="inline" id="S2.p1.6.m6.1">
     <semantics id="S2.p1.6.m6.1a">
      <msub id="S2.p1.6.m6.1.1" xref="S2.p1.6.m6.1.1.cmml">
       <mi class="ltx_font_mathcaligraphic" id="S2.p1.6.m6.1.1.2" xref="S2.p1.6.m6.1.1.2.cmml">
        ℒ
       </mi>
       <mi id="S2.p1.6.m6.1.1.3" xref="S2.p1.6.m6.1.1.3.cmml">
        t
       </mi>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S2.p1.6.m6.1b">
       <apply id="S2.p1.6.m6.1.1.cmml" xref="S2.p1.6.m6.1.1">
        <csymbol cd="ambiguous" id="S2.p1.6.m6.1.1.1.cmml" xref="S2.p1.6.m6.1.1">
         subscript
        </csymbol>
        <ci id="S2.p1.6.m6.1.1.2.cmml" xref="S2.p1.6.m6.1.1.2">
         ℒ
        </ci>
        <ci id="S2.p1.6.m6.1.1.3.cmml" xref="S2.p1.6.m6.1.1.3">
         𝑡
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p1.6.m6.1c">
       \mathcal{L}_{t}
      </annotation>
     </semantics>
    </math>
    if on ALFWorld) represents the world state
    <math alttext="\mathcal{W}_{t}" class="ltx_Math" display="inline" id="S2.p1.7.m7.1">
     <semantics id="S2.p1.7.m7.1a">
      <msub id="S2.p1.7.m7.1.1" xref="S2.p1.7.m7.1.1.cmml">
       <mi class="ltx_font_mathcaligraphic" id="S2.p1.7.m7.1.1.2" xref="S2.p1.7.m7.1.1.2.cmml">
        𝒲
       </mi>
       <mi id="S2.p1.7.m7.1.1.3" xref="S2.p1.7.m7.1.1.3.cmml">
        t
       </mi>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S2.p1.7.m7.1b">
       <apply id="S2.p1.7.m7.1.1.cmml" xref="S2.p1.7.m7.1.1">
        <csymbol cd="ambiguous" id="S2.p1.7.m7.1.1.1.cmml" xref="S2.p1.7.m7.1.1">
         subscript
        </csymbol>
        <ci id="S2.p1.7.m7.1.1.2.cmml" xref="S2.p1.7.m7.1.1.2">
         𝒲
        </ci>
        <ci id="S2.p1.7.m7.1.1.3.cmml" xref="S2.p1.7.m7.1.1.3">
         𝑡
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p1.7.m7.1c">
       \mathcal{W}_{t}
      </annotation>
     </semantics>
    </math>
    .
   </p>
  </div>
  <div class="ltx_para" id="S2.p2">
   <p class="ltx_p" id="S2.p2.14">
    Given the language instruction
    <math alttext="L" class="ltx_Math" display="inline" id="S2.p2.1.m1.1">
     <semantics id="S2.p2.1.m1.1a">
      <mi id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml">
       L
      </mi>
      <annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.1b">
       <ci id="S2.p2.1.m1.1.1.cmml" xref="S2.p2.1.m1.1.1">
        𝐿
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p2.1.m1.1c">
       L
      </annotation>
     </semantics>
    </math>
    and an initial observation
    <math alttext="V_{0}" class="ltx_Math" display="inline" id="S2.p2.2.m2.1">
     <semantics id="S2.p2.2.m2.1a">
      <msub id="S2.p2.2.m2.1.1" xref="S2.p2.2.m2.1.1.cmml">
       <mi id="S2.p2.2.m2.1.1.2" xref="S2.p2.2.m2.1.1.2.cmml">
        V
       </mi>
       <mn id="S2.p2.2.m2.1.1.3" xref="S2.p2.2.m2.1.1.3.cmml">
        0
       </mn>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S2.p2.2.m2.1b">
       <apply id="S2.p2.2.m2.1.1.cmml" xref="S2.p2.2.m2.1.1">
        <csymbol cd="ambiguous" id="S2.p2.2.m2.1.1.1.cmml" xref="S2.p2.2.m2.1.1">
         subscript
        </csymbol>
        <ci id="S2.p2.2.m2.1.1.2.cmml" xref="S2.p2.2.m2.1.1.2">
         𝑉
        </ci>
        <cn id="S2.p2.2.m2.1.1.3.cmml" type="integer" xref="S2.p2.2.m2.1.1.3">
         0
        </cn>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p2.2.m2.1c">
       V_{0}
      </annotation>
     </semantics>
    </math>
    (
    <math alttext="\mathcal{L}_{0}" class="ltx_Math" display="inline" id="S2.p2.3.m3.1">
     <semantics id="S2.p2.3.m3.1a">
      <msub id="S2.p2.3.m3.1.1" xref="S2.p2.3.m3.1.1.cmml">
       <mi class="ltx_font_mathcaligraphic" id="S2.p2.3.m3.1.1.2" xref="S2.p2.3.m3.1.1.2.cmml">
        ℒ
       </mi>
       <mn id="S2.p2.3.m3.1.1.3" xref="S2.p2.3.m3.1.1.3.cmml">
        0
       </mn>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S2.p2.3.m3.1b">
       <apply id="S2.p2.3.m3.1.1.cmml" xref="S2.p2.3.m3.1.1">
        <csymbol cd="ambiguous" id="S2.p2.3.m3.1.1.1.cmml" xref="S2.p2.3.m3.1.1">
         subscript
        </csymbol>
        <ci id="S2.p2.3.m3.1.1.2.cmml" xref="S2.p2.3.m3.1.1.2">
         ℒ
        </ci>
        <cn id="S2.p2.3.m3.1.1.3.cmml" type="integer" xref="S2.p2.3.m3.1.1.3">
         0
        </cn>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p2.3.m3.1c">
       \mathcal{L}_{0}
      </annotation>
     </semantics>
    </math>
    if on ALFWorld), the agent’s objective is to generate an execution trajectory
    <math alttext="\mathcal{T}=\left\langle V_{0},a_{0},V_{1},a_{1},\ldots,V_{T},a_{T}\right\rangle" class="ltx_Math" display="inline" id="S2.p2.4.m4.7">
     <semantics id="S2.p2.4.m4.7a">
      <mrow id="S2.p2.4.m4.7.7" xref="S2.p2.4.m4.7.7.cmml">
       <mi class="ltx_font_mathcaligraphic" id="S2.p2.4.m4.7.7.8" xref="S2.p2.4.m4.7.7.8.cmml">
        𝒯
       </mi>
       <mo id="S2.p2.4.m4.7.7.7" xref="S2.p2.4.m4.7.7.7.cmml">
        =
       </mo>
       <mrow id="S2.p2.4.m4.7.7.6.6" xref="S2.p2.4.m4.7.7.6.7.cmml">
        <mo id="S2.p2.4.m4.7.7.6.6.7" xref="S2.p2.4.m4.7.7.6.7.cmml">
         ⟨
        </mo>
        <msub id="S2.p2.4.m4.2.2.1.1.1" xref="S2.p2.4.m4.2.2.1.1.1.cmml">
         <mi id="S2.p2.4.m4.2.2.1.1.1.2" xref="S2.p2.4.m4.2.2.1.1.1.2.cmml">
          V
         </mi>
         <mn id="S2.p2.4.m4.2.2.1.1.1.3" xref="S2.p2.4.m4.2.2.1.1.1.3.cmml">
          0
         </mn>
        </msub>
        <mo id="S2.p2.4.m4.7.7.6.6.8" xref="S2.p2.4.m4.7.7.6.7.cmml">
         ,
        </mo>
        <msub id="S2.p2.4.m4.3.3.2.2.2" xref="S2.p2.4.m4.3.3.2.2.2.cmml">
         <mi id="S2.p2.4.m4.3.3.2.2.2.2" xref="S2.p2.4.m4.3.3.2.2.2.2.cmml">
          a
         </mi>
         <mn id="S2.p2.4.m4.3.3.2.2.2.3" xref="S2.p2.4.m4.3.3.2.2.2.3.cmml">
          0
         </mn>
        </msub>
        <mo id="S2.p2.4.m4.7.7.6.6.9" xref="S2.p2.4.m4.7.7.6.7.cmml">
         ,
        </mo>
        <msub id="S2.p2.4.m4.4.4.3.3.3" xref="S2.p2.4.m4.4.4.3.3.3.cmml">
         <mi id="S2.p2.4.m4.4.4.3.3.3.2" xref="S2.p2.4.m4.4.4.3.3.3.2.cmml">
          V
         </mi>
         <mn id="S2.p2.4.m4.4.4.3.3.3.3" xref="S2.p2.4.m4.4.4.3.3.3.3.cmml">
          1
         </mn>
        </msub>
        <mo id="S2.p2.4.m4.7.7.6.6.10" xref="S2.p2.4.m4.7.7.6.7.cmml">
         ,
        </mo>
        <msub id="S2.p2.4.m4.5.5.4.4.4" xref="S2.p2.4.m4.5.5.4.4.4.cmml">
         <mi id="S2.p2.4.m4.5.5.4.4.4.2" xref="S2.p2.4.m4.5.5.4.4.4.2.cmml">
          a
         </mi>
         <mn id="S2.p2.4.m4.5.5.4.4.4.3" xref="S2.p2.4.m4.5.5.4.4.4.3.cmml">
          1
         </mn>
        </msub>
        <mo id="S2.p2.4.m4.7.7.6.6.11" xref="S2.p2.4.m4.7.7.6.7.cmml">
         ,
        </mo>
        <mi id="S2.p2.4.m4.1.1" mathvariant="normal" xref="S2.p2.4.m4.1.1.cmml">
         …
        </mi>
        <mo id="S2.p2.4.m4.7.7.6.6.12" xref="S2.p2.4.m4.7.7.6.7.cmml">
         ,
        </mo>
        <msub id="S2.p2.4.m4.6.6.5.5.5" xref="S2.p2.4.m4.6.6.5.5.5.cmml">
         <mi id="S2.p2.4.m4.6.6.5.5.5.2" xref="S2.p2.4.m4.6.6.5.5.5.2.cmml">
          V
         </mi>
         <mi id="S2.p2.4.m4.6.6.5.5.5.3" xref="S2.p2.4.m4.6.6.5.5.5.3.cmml">
          T
         </mi>
        </msub>
        <mo id="S2.p2.4.m4.7.7.6.6.13" xref="S2.p2.4.m4.7.7.6.7.cmml">
         ,
        </mo>
        <msub id="S2.p2.4.m4.7.7.6.6.6" xref="S2.p2.4.m4.7.7.6.6.6.cmml">
         <mi id="S2.p2.4.m4.7.7.6.6.6.2" xref="S2.p2.4.m4.7.7.6.6.6.2.cmml">
          a
         </mi>
         <mi id="S2.p2.4.m4.7.7.6.6.6.3" xref="S2.p2.4.m4.7.7.6.6.6.3.cmml">
          T
         </mi>
        </msub>
        <mo id="S2.p2.4.m4.7.7.6.6.14" xref="S2.p2.4.m4.7.7.6.7.cmml">
         ⟩
        </mo>
       </mrow>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S2.p2.4.m4.7b">
       <apply id="S2.p2.4.m4.7.7.cmml" xref="S2.p2.4.m4.7.7">
        <eq id="S2.p2.4.m4.7.7.7.cmml" xref="S2.p2.4.m4.7.7.7">
        </eq>
        <ci id="S2.p2.4.m4.7.7.8.cmml" xref="S2.p2.4.m4.7.7.8">
         𝒯
        </ci>
        <list id="S2.p2.4.m4.7.7.6.7.cmml" xref="S2.p2.4.m4.7.7.6.6">
         <apply id="S2.p2.4.m4.2.2.1.1.1.cmml" xref="S2.p2.4.m4.2.2.1.1.1">
          <csymbol cd="ambiguous" id="S2.p2.4.m4.2.2.1.1.1.1.cmml" xref="S2.p2.4.m4.2.2.1.1.1">
           subscript
          </csymbol>
          <ci id="S2.p2.4.m4.2.2.1.1.1.2.cmml" xref="S2.p2.4.m4.2.2.1.1.1.2">
           𝑉
          </ci>
          <cn id="S2.p2.4.m4.2.2.1.1.1.3.cmml" type="integer" xref="S2.p2.4.m4.2.2.1.1.1.3">
           0
          </cn>
         </apply>
         <apply id="S2.p2.4.m4.3.3.2.2.2.cmml" xref="S2.p2.4.m4.3.3.2.2.2">
          <csymbol cd="ambiguous" id="S2.p2.4.m4.3.3.2.2.2.1.cmml" xref="S2.p2.4.m4.3.3.2.2.2">
           subscript
          </csymbol>
          <ci id="S2.p2.4.m4.3.3.2.2.2.2.cmml" xref="S2.p2.4.m4.3.3.2.2.2.2">
           𝑎
          </ci>
          <cn id="S2.p2.4.m4.3.3.2.2.2.3.cmml" type="integer" xref="S2.p2.4.m4.3.3.2.2.2.3">
           0
          </cn>
         </apply>
         <apply id="S2.p2.4.m4.4.4.3.3.3.cmml" xref="S2.p2.4.m4.4.4.3.3.3">
          <csymbol cd="ambiguous" id="S2.p2.4.m4.4.4.3.3.3.1.cmml" xref="S2.p2.4.m4.4.4.3.3.3">
           subscript
          </csymbol>
          <ci id="S2.p2.4.m4.4.4.3.3.3.2.cmml" xref="S2.p2.4.m4.4.4.3.3.3.2">
           𝑉
          </ci>
          <cn id="S2.p2.4.m4.4.4.3.3.3.3.cmml" type="integer" xref="S2.p2.4.m4.4.4.3.3.3.3">
           1
          </cn>
         </apply>
         <apply id="S2.p2.4.m4.5.5.4.4.4.cmml" xref="S2.p2.4.m4.5.5.4.4.4">
          <csymbol cd="ambiguous" id="S2.p2.4.m4.5.5.4.4.4.1.cmml" xref="S2.p2.4.m4.5.5.4.4.4">
           subscript
          </csymbol>
          <ci id="S2.p2.4.m4.5.5.4.4.4.2.cmml" xref="S2.p2.4.m4.5.5.4.4.4.2">
           𝑎
          </ci>
          <cn id="S2.p2.4.m4.5.5.4.4.4.3.cmml" type="integer" xref="S2.p2.4.m4.5.5.4.4.4.3">
           1
          </cn>
         </apply>
         <ci id="S2.p2.4.m4.1.1.cmml" xref="S2.p2.4.m4.1.1">
          …
         </ci>
         <apply id="S2.p2.4.m4.6.6.5.5.5.cmml" xref="S2.p2.4.m4.6.6.5.5.5">
          <csymbol cd="ambiguous" id="S2.p2.4.m4.6.6.5.5.5.1.cmml" xref="S2.p2.4.m4.6.6.5.5.5">
           subscript
          </csymbol>
          <ci id="S2.p2.4.m4.6.6.5.5.5.2.cmml" xref="S2.p2.4.m4.6.6.5.5.5.2">
           𝑉
          </ci>
          <ci id="S2.p2.4.m4.6.6.5.5.5.3.cmml" xref="S2.p2.4.m4.6.6.5.5.5.3">
           𝑇
          </ci>
         </apply>
         <apply id="S2.p2.4.m4.7.7.6.6.6.cmml" xref="S2.p2.4.m4.7.7.6.6.6">
          <csymbol cd="ambiguous" id="S2.p2.4.m4.7.7.6.6.6.1.cmml" xref="S2.p2.4.m4.7.7.6.6.6">
           subscript
          </csymbol>
          <ci id="S2.p2.4.m4.7.7.6.6.6.2.cmml" xref="S2.p2.4.m4.7.7.6.6.6.2">
           𝑎
          </ci>
          <ci id="S2.p2.4.m4.7.7.6.6.6.3.cmml" xref="S2.p2.4.m4.7.7.6.6.6.3">
           𝑇
          </ci>
         </apply>
        </list>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p2.4.m4.7c">
       \mathcal{T}=\left\langle V_{0},a_{0},V_{1},a_{1},\ldots,V_{T},a_{T}\right\rangle
      </annotation>
     </semantics>
    </math>
    , where
    <math alttext="a_{t}" class="ltx_Math" display="inline" id="S2.p2.5.m5.1">
     <semantics id="S2.p2.5.m5.1a">
      <msub id="S2.p2.5.m5.1.1" xref="S2.p2.5.m5.1.1.cmml">
       <mi id="S2.p2.5.m5.1.1.2" xref="S2.p2.5.m5.1.1.2.cmml">
        a
       </mi>
       <mi id="S2.p2.5.m5.1.1.3" xref="S2.p2.5.m5.1.1.3.cmml">
        t
       </mi>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S2.p2.5.m5.1b">
       <apply id="S2.p2.5.m5.1.1.cmml" xref="S2.p2.5.m5.1.1">
        <csymbol cd="ambiguous" id="S2.p2.5.m5.1.1.1.cmml" xref="S2.p2.5.m5.1.1">
         subscript
        </csymbol>
        <ci id="S2.p2.5.m5.1.1.2.cmml" xref="S2.p2.5.m5.1.1.2">
         𝑎
        </ci>
        <ci id="S2.p2.5.m5.1.1.3.cmml" xref="S2.p2.5.m5.1.1.3">
         𝑡
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p2.5.m5.1c">
       a_{t}
      </annotation>
     </semantics>
    </math>
    is the action taken by the agent at time step
    <math alttext="t" class="ltx_Math" display="inline" id="S2.p2.6.m6.1">
     <semantics id="S2.p2.6.m6.1a">
      <mi id="S2.p2.6.m6.1.1" xref="S2.p2.6.m6.1.1.cmml">
       t
      </mi>
      <annotation-xml encoding="MathML-Content" id="S2.p2.6.m6.1b">
       <ci id="S2.p2.6.m6.1.1.cmml" xref="S2.p2.6.m6.1.1">
        𝑡
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p2.6.m6.1c">
       t
      </annotation>
     </semantics>
    </math>
    , and
    <math alttext="V_{t+1}" class="ltx_Math" display="inline" id="S2.p2.7.m7.1">
     <semantics id="S2.p2.7.m7.1a">
      <msub id="S2.p2.7.m7.1.1" xref="S2.p2.7.m7.1.1.cmml">
       <mi id="S2.p2.7.m7.1.1.2" xref="S2.p2.7.m7.1.1.2.cmml">
        V
       </mi>
       <mrow id="S2.p2.7.m7.1.1.3" xref="S2.p2.7.m7.1.1.3.cmml">
        <mi id="S2.p2.7.m7.1.1.3.2" xref="S2.p2.7.m7.1.1.3.2.cmml">
         t
        </mi>
        <mo id="S2.p2.7.m7.1.1.3.1" xref="S2.p2.7.m7.1.1.3.1.cmml">
         +
        </mo>
        <mn id="S2.p2.7.m7.1.1.3.3" xref="S2.p2.7.m7.1.1.3.3.cmml">
         1
        </mn>
       </mrow>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S2.p2.7.m7.1b">
       <apply id="S2.p2.7.m7.1.1.cmml" xref="S2.p2.7.m7.1.1">
        <csymbol cd="ambiguous" id="S2.p2.7.m7.1.1.1.cmml" xref="S2.p2.7.m7.1.1">
         subscript
        </csymbol>
        <ci id="S2.p2.7.m7.1.1.2.cmml" xref="S2.p2.7.m7.1.1.2">
         𝑉
        </ci>
        <apply id="S2.p2.7.m7.1.1.3.cmml" xref="S2.p2.7.m7.1.1.3">
         <plus id="S2.p2.7.m7.1.1.3.1.cmml" xref="S2.p2.7.m7.1.1.3.1">
         </plus>
         <ci id="S2.p2.7.m7.1.1.3.2.cmml" xref="S2.p2.7.m7.1.1.3.2">
          𝑡
         </ci>
         <cn id="S2.p2.7.m7.1.1.3.3.cmml" type="integer" xref="S2.p2.7.m7.1.1.3.3">
          1
         </cn>
        </apply>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p2.7.m7.1c">
       V_{t+1}
      </annotation>
     </semantics>
    </math>
    is the observation of the world state
    <math alttext="\mathcal{W}_{t+1}" class="ltx_Math" display="inline" id="S2.p2.8.m8.1">
     <semantics id="S2.p2.8.m8.1a">
      <msub id="S2.p2.8.m8.1.1" xref="S2.p2.8.m8.1.1.cmml">
       <mi class="ltx_font_mathcaligraphic" id="S2.p2.8.m8.1.1.2" xref="S2.p2.8.m8.1.1.2.cmml">
        𝒲
       </mi>
       <mrow id="S2.p2.8.m8.1.1.3" xref="S2.p2.8.m8.1.1.3.cmml">
        <mi id="S2.p2.8.m8.1.1.3.2" xref="S2.p2.8.m8.1.1.3.2.cmml">
         t
        </mi>
        <mo id="S2.p2.8.m8.1.1.3.1" xref="S2.p2.8.m8.1.1.3.1.cmml">
         +
        </mo>
        <mn id="S2.p2.8.m8.1.1.3.3" xref="S2.p2.8.m8.1.1.3.3.cmml">
         1
        </mn>
       </mrow>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S2.p2.8.m8.1b">
       <apply id="S2.p2.8.m8.1.1.cmml" xref="S2.p2.8.m8.1.1">
        <csymbol cd="ambiguous" id="S2.p2.8.m8.1.1.1.cmml" xref="S2.p2.8.m8.1.1">
         subscript
        </csymbol>
        <ci id="S2.p2.8.m8.1.1.2.cmml" xref="S2.p2.8.m8.1.1.2">
         𝒲
        </ci>
        <apply id="S2.p2.8.m8.1.1.3.cmml" xref="S2.p2.8.m8.1.1.3">
         <plus id="S2.p2.8.m8.1.1.3.1.cmml" xref="S2.p2.8.m8.1.1.3.1">
         </plus>
         <ci id="S2.p2.8.m8.1.1.3.2.cmml" xref="S2.p2.8.m8.1.1.3.2">
          𝑡
         </ci>
         <cn id="S2.p2.8.m8.1.1.3.3.cmml" type="integer" xref="S2.p2.8.m8.1.1.3.3">
          1
         </cn>
        </apply>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p2.8.m8.1c">
       \mathcal{W}_{t+1}
      </annotation>
     </semantics>
    </math>
    caused by that action. The action space
    <math alttext="A" class="ltx_Math" display="inline" id="S2.p2.9.m9.1">
     <semantics id="S2.p2.9.m9.1a">
      <mi id="S2.p2.9.m9.1.1" xref="S2.p2.9.m9.1.1.cmml">
       A
      </mi>
      <annotation-xml encoding="MathML-Content" id="S2.p2.9.m9.1b">
       <ci id="S2.p2.9.m9.1.1.cmml" xref="S2.p2.9.m9.1.1">
        𝐴
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p2.9.m9.1c">
       A
      </annotation>
     </semantics>
    </math>
    can be categorized into two classes: navigation actions
    <math alttext="A_{N}" class="ltx_Math" display="inline" id="S2.p2.10.m10.1">
     <semantics id="S2.p2.10.m10.1a">
      <msub id="S2.p2.10.m10.1.1" xref="S2.p2.10.m10.1.1.cmml">
       <mi id="S2.p2.10.m10.1.1.2" xref="S2.p2.10.m10.1.1.2.cmml">
        A
       </mi>
       <mi id="S2.p2.10.m10.1.1.3" xref="S2.p2.10.m10.1.1.3.cmml">
        N
       </mi>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S2.p2.10.m10.1b">
       <apply id="S2.p2.10.m10.1.1.cmml" xref="S2.p2.10.m10.1.1">
        <csymbol cd="ambiguous" id="S2.p2.10.m10.1.1.1.cmml" xref="S2.p2.10.m10.1.1">
         subscript
        </csymbol>
        <ci id="S2.p2.10.m10.1.1.2.cmml" xref="S2.p2.10.m10.1.1.2">
         𝐴
        </ci>
        <ci id="S2.p2.10.m10.1.1.3.cmml" xref="S2.p2.10.m10.1.1.3">
         𝑁
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p2.10.m10.1c">
       A_{N}
      </annotation>
     </semantics>
    </math>
    and interaction actions
    <math alttext="A_{I}" class="ltx_Math" display="inline" id="S2.p2.11.m11.1">
     <semantics id="S2.p2.11.m11.1a">
      <msub id="S2.p2.11.m11.1.1" xref="S2.p2.11.m11.1.1.cmml">
       <mi id="S2.p2.11.m11.1.1.2" xref="S2.p2.11.m11.1.1.2.cmml">
        A
       </mi>
       <mi id="S2.p2.11.m11.1.1.3" xref="S2.p2.11.m11.1.1.3.cmml">
        I
       </mi>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S2.p2.11.m11.1b">
       <apply id="S2.p2.11.m11.1.1.cmml" xref="S2.p2.11.m11.1.1">
        <csymbol cd="ambiguous" id="S2.p2.11.m11.1.1.1.cmml" xref="S2.p2.11.m11.1.1">
         subscript
        </csymbol>
        <ci id="S2.p2.11.m11.1.1.2.cmml" xref="S2.p2.11.m11.1.1.2">
         𝐴
        </ci>
        <ci id="S2.p2.11.m11.1.1.3.cmml" xref="S2.p2.11.m11.1.1.3">
         𝐼
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p2.11.m11.1c">
       A_{I}
      </annotation>
     </semantics>
    </math>
    , respectively
    <span class="ltx_note ltx_role_footnote" id="footnote1">
     <sup class="ltx_note_mark">
      1
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        1
       </sup>
       <span class="ltx_tag ltx_tag_note">
        1
       </span>
       <math alttext="A_{N}\in\{" class="ltx_math_unparsed" display="inline" id="footnote1.m1.1">
        <semantics id="footnote1.m1.1b">
         <mrow id="footnote1.m1.1c">
          <msub id="footnote1.m1.1.1">
           <mi id="footnote1.m1.1.1.2">
            A
           </mi>
           <mi id="footnote1.m1.1.1.3">
            N
           </mi>
          </msub>
          <mo id="footnote1.m1.1.2">
           ∈
          </mo>
          <mo id="footnote1.m1.1.3" stretchy="false">
           {
          </mo>
         </mrow>
         <annotation encoding="application/x-tex" id="footnote1.m1.1d">
          A_{N}\in\{
         </annotation>
        </semantics>
       </math>
       <span class="ltx_text ltx_font_italic" id="footnote1.3">
        RotateRight
       </span>
       ,
       <span class="ltx_text ltx_font_italic" id="footnote1.4">
        RotateLeft
       </span>
       ,
       <span class="ltx_text ltx_font_italic" id="footnote1.5">
        MoveAhead
       </span>
       ,
       <span class="ltx_text ltx_font_italic" id="footnote1.6">
        LookUp
       </span>
       ,
       <span class="ltx_text ltx_font_italic" id="footnote1.1">
        LookDown
        <math alttext="\}" class="ltx_Math" display="inline" id="footnote1.1.m1.1">
         <semantics id="footnote1.1.m1.1b">
          <mo id="footnote1.1.m1.1.1" stretchy="false" xref="footnote1.1.m1.1.1.cmml">
           }
          </mo>
          <annotation-xml encoding="MathML-Content" id="footnote1.1.m1.1c">
           <ci id="footnote1.1.m1.1.1.cmml" xref="footnote1.1.m1.1.1">
            }
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="footnote1.1.m1.1d">
           \}
          </annotation>
         </semantics>
        </math>
       </span>
       ,
       <math alttext="A_{I}\in\{" class="ltx_math_unparsed" display="inline" id="footnote1.m2.1">
        <semantics id="footnote1.m2.1b">
         <mrow id="footnote1.m2.1c">
          <msub id="footnote1.m2.1.1">
           <mi id="footnote1.m2.1.1.2">
            A
           </mi>
           <mi id="footnote1.m2.1.1.3">
            I
           </mi>
          </msub>
          <mo id="footnote1.m2.1.2">
           ∈
          </mo>
          <mo id="footnote1.m2.1.3" stretchy="false">
           {
          </mo>
         </mrow>
         <annotation encoding="application/x-tex" id="footnote1.m2.1d">
          A_{I}\in\{
         </annotation>
        </semantics>
       </math>
       <span class="ltx_text ltx_font_italic" id="footnote1.7">
        PickupObject
       </span>
       ,
       <span class="ltx_text ltx_font_italic" id="footnote1.8">
        PutObject
       </span>
       ,
       <span class="ltx_text ltx_font_italic" id="footnote1.9">
        OpenObject
       </span>
       ,
       <span class="ltx_text ltx_font_italic" id="footnote1.10">
        CloseObject
       </span>
       ,
       <span class="ltx_text ltx_font_italic" id="footnote1.11">
        ToggleObjectOn
       </span>
       ,
       <span class="ltx_text ltx_font_italic" id="footnote1.12">
        ToggleObjectOff
       </span>
       ,
       <span class="ltx_text ltx_font_italic" id="footnote1.2">
        SliceObject
        <math alttext="\}" class="ltx_Math" display="inline" id="footnote1.2.m1.1">
         <semantics id="footnote1.2.m1.1b">
          <mo id="footnote1.2.m1.1.1" stretchy="false" xref="footnote1.2.m1.1.1.cmml">
           }
          </mo>
          <annotation-xml encoding="MathML-Content" id="footnote1.2.m1.1c">
           <ci id="footnote1.2.m1.1.1.cmml" xref="footnote1.2.m1.1.1">
            }
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="footnote1.2.m1.1d">
           \}
          </annotation>
         </semantics>
        </math>
       </span>
       .
      </span>
     </span>
    </span>
    . In practice, we follow the setting of FILM
    <cite class="ltx_cite ltx_citemacro_cite">
     Min et al. (
     <a class="ltx_ref" href="#bib.bib21" title="">
      2021
     </a>
     )
    </cite>
    , where the navigation actions
    <math alttext="A_{N}" class="ltx_Math" display="inline" id="S2.p2.12.m12.1">
     <semantics id="S2.p2.12.m12.1a">
      <msub id="S2.p2.12.m12.1.1" xref="S2.p2.12.m12.1.1.cmml">
       <mi id="S2.p2.12.m12.1.1.2" xref="S2.p2.12.m12.1.1.2.cmml">
        A
       </mi>
       <mi id="S2.p2.12.m12.1.1.3" xref="S2.p2.12.m12.1.1.3.cmml">
        N
       </mi>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S2.p2.12.m12.1b">
       <apply id="S2.p2.12.m12.1.1.cmml" xref="S2.p2.12.m12.1.1">
        <csymbol cd="ambiguous" id="S2.p2.12.m12.1.1.1.cmml" xref="S2.p2.12.m12.1.1">
         subscript
        </csymbol>
        <ci id="S2.p2.12.m12.1.1.2.cmml" xref="S2.p2.12.m12.1.1.2">
         𝐴
        </ci>
        <ci id="S2.p2.12.m12.1.1.3.cmml" xref="S2.p2.12.m12.1.1.3">
         𝑁
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p2.12.m12.1c">
       A_{N}
      </annotation>
     </semantics>
    </math>
    are constrained to discrete values, and a pixel-wise interaction mask of the target object must be specified for interaction actions
    <math alttext="A_{I}" class="ltx_Math" display="inline" id="S2.p2.13.m13.1">
     <semantics id="S2.p2.13.m13.1a">
      <msub id="S2.p2.13.m13.1.1" xref="S2.p2.13.m13.1.1.cmml">
       <mi id="S2.p2.13.m13.1.1.2" xref="S2.p2.13.m13.1.1.2.cmml">
        A
       </mi>
       <mi id="S2.p2.13.m13.1.1.3" xref="S2.p2.13.m13.1.1.3.cmml">
        I
       </mi>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S2.p2.13.m13.1b">
       <apply id="S2.p2.13.m13.1.1.cmml" xref="S2.p2.13.m13.1.1">
        <csymbol cd="ambiguous" id="S2.p2.13.m13.1.1.1.cmml" xref="S2.p2.13.m13.1.1">
         subscript
        </csymbol>
        <ci id="S2.p2.13.m13.1.1.2.cmml" xref="S2.p2.13.m13.1.1.2">
         𝐴
        </ci>
        <ci id="S2.p2.13.m13.1.1.3.cmml" xref="S2.p2.13.m13.1.1.3">
         𝐼
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p2.13.m13.1c">
       A_{I}
      </annotation>
     </semantics>
    </math>
    . There are seven types of household tasks, of which each episode is terminated either if an agent meets the goal conditions specified in
    <math alttext="L" class="ltx_Math" display="inline" id="S2.p2.14.m14.1">
     <semantics id="S2.p2.14.m14.1a">
      <mi id="S2.p2.14.m14.1.1" xref="S2.p2.14.m14.1.1.cmml">
       L
      </mi>
      <annotation-xml encoding="MathML-Content" id="S2.p2.14.m14.1b">
       <ci id="S2.p2.14.m14.1.1.cmml" xref="S2.p2.14.m14.1.1">
        𝐿
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S2.p2.14.m14.1c">
       L
      </annotation>
     </semantics>
    </math>
    (success) or reaches the maximum number of steps (fail).
See Appendix.
    <a class="ltx_ref" href="#A1" title="Appendix A Task Example in ALFRED ‣ OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied Instruction Following">
     <span class="ltx_text ltx_ref_tag">
      A
     </span>
    </a>
    for a task example in ALFRED.
   </p>
  </div>
  <figure class="ltx_figure" id="S2.F1">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="326" id="S2.F1.g1" src="/html/2403.03017/assets/x1.png" width="230"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 1:
    </span>
    Overview of our OPEx framework. We will open-source the code after acceptance.
   </figcaption>
  </figure>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    3
   </span>
   Methodology
  </h2>
  <div class="ltx_para" id="S3.p1">
   <p class="ltx_p" id="S3.p1.8">
    We first provide an overview of the proposed LLM-centric framework (OPEx) in Figure
    <a class="ltx_ref" href="#S2.F1" title="Figure 1 ‣ 2 Task Formulation ‣ OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied Instruction Following">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    .
OPEx consists of six components: (1) A
    <span class="ltx_text ltx_font_italic" id="S3.p1.8.1">
     semantic mapping module
    </span>
    to transform the egocentric visual observation into a semantic map; (2) An
    <span class="ltx_text ltx_font_italic" id="S3.p1.8.2">
     LLM-based planner
    </span>
    to decompose the specified language task instruction
    <math alttext="L" class="ltx_Math" display="inline" id="S3.p1.1.m1.1">
     <semantics id="S3.p1.1.m1.1a">
      <mi id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">
       L
      </mi>
      <annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b">
       <ci id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">
        𝐿
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">
       L
      </annotation>
     </semantics>
    </math>
    into subtasks
    <math alttext="S=[S_{0},S_{1},...,S_{n}]" class="ltx_Math" display="inline" id="S3.p1.2.m2.4">
     <semantics id="S3.p1.2.m2.4a">
      <mrow id="S3.p1.2.m2.4.4" xref="S3.p1.2.m2.4.4.cmml">
       <mi id="S3.p1.2.m2.4.4.5" xref="S3.p1.2.m2.4.4.5.cmml">
        S
       </mi>
       <mo id="S3.p1.2.m2.4.4.4" xref="S3.p1.2.m2.4.4.4.cmml">
        =
       </mo>
       <mrow id="S3.p1.2.m2.4.4.3.3" xref="S3.p1.2.m2.4.4.3.4.cmml">
        <mo id="S3.p1.2.m2.4.4.3.3.4" stretchy="false" xref="S3.p1.2.m2.4.4.3.4.cmml">
         [
        </mo>
        <msub id="S3.p1.2.m2.2.2.1.1.1" xref="S3.p1.2.m2.2.2.1.1.1.cmml">
         <mi id="S3.p1.2.m2.2.2.1.1.1.2" xref="S3.p1.2.m2.2.2.1.1.1.2.cmml">
          S
         </mi>
         <mn id="S3.p1.2.m2.2.2.1.1.1.3" xref="S3.p1.2.m2.2.2.1.1.1.3.cmml">
          0
         </mn>
        </msub>
        <mo id="S3.p1.2.m2.4.4.3.3.5" xref="S3.p1.2.m2.4.4.3.4.cmml">
         ,
        </mo>
        <msub id="S3.p1.2.m2.3.3.2.2.2" xref="S3.p1.2.m2.3.3.2.2.2.cmml">
         <mi id="S3.p1.2.m2.3.3.2.2.2.2" xref="S3.p1.2.m2.3.3.2.2.2.2.cmml">
          S
         </mi>
         <mn id="S3.p1.2.m2.3.3.2.2.2.3" xref="S3.p1.2.m2.3.3.2.2.2.3.cmml">
          1
         </mn>
        </msub>
        <mo id="S3.p1.2.m2.4.4.3.3.6" xref="S3.p1.2.m2.4.4.3.4.cmml">
         ,
        </mo>
        <mi id="S3.p1.2.m2.1.1" mathvariant="normal" xref="S3.p1.2.m2.1.1.cmml">
         …
        </mi>
        <mo id="S3.p1.2.m2.4.4.3.3.7" xref="S3.p1.2.m2.4.4.3.4.cmml">
         ,
        </mo>
        <msub id="S3.p1.2.m2.4.4.3.3.3" xref="S3.p1.2.m2.4.4.3.3.3.cmml">
         <mi id="S3.p1.2.m2.4.4.3.3.3.2" xref="S3.p1.2.m2.4.4.3.3.3.2.cmml">
          S
         </mi>
         <mi id="S3.p1.2.m2.4.4.3.3.3.3" xref="S3.p1.2.m2.4.4.3.3.3.3.cmml">
          n
         </mi>
        </msub>
        <mo id="S3.p1.2.m2.4.4.3.3.8" stretchy="false" xref="S3.p1.2.m2.4.4.3.4.cmml">
         ]
        </mo>
       </mrow>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.4b">
       <apply id="S3.p1.2.m2.4.4.cmml" xref="S3.p1.2.m2.4.4">
        <eq id="S3.p1.2.m2.4.4.4.cmml" xref="S3.p1.2.m2.4.4.4">
        </eq>
        <ci id="S3.p1.2.m2.4.4.5.cmml" xref="S3.p1.2.m2.4.4.5">
         𝑆
        </ci>
        <list id="S3.p1.2.m2.4.4.3.4.cmml" xref="S3.p1.2.m2.4.4.3.3">
         <apply id="S3.p1.2.m2.2.2.1.1.1.cmml" xref="S3.p1.2.m2.2.2.1.1.1">
          <csymbol cd="ambiguous" id="S3.p1.2.m2.2.2.1.1.1.1.cmml" xref="S3.p1.2.m2.2.2.1.1.1">
           subscript
          </csymbol>
          <ci id="S3.p1.2.m2.2.2.1.1.1.2.cmml" xref="S3.p1.2.m2.2.2.1.1.1.2">
           𝑆
          </ci>
          <cn id="S3.p1.2.m2.2.2.1.1.1.3.cmml" type="integer" xref="S3.p1.2.m2.2.2.1.1.1.3">
           0
          </cn>
         </apply>
         <apply id="S3.p1.2.m2.3.3.2.2.2.cmml" xref="S3.p1.2.m2.3.3.2.2.2">
          <csymbol cd="ambiguous" id="S3.p1.2.m2.3.3.2.2.2.1.cmml" xref="S3.p1.2.m2.3.3.2.2.2">
           subscript
          </csymbol>
          <ci id="S3.p1.2.m2.3.3.2.2.2.2.cmml" xref="S3.p1.2.m2.3.3.2.2.2.2">
           𝑆
          </ci>
          <cn id="S3.p1.2.m2.3.3.2.2.2.3.cmml" type="integer" xref="S3.p1.2.m2.3.3.2.2.2.3">
           1
          </cn>
         </apply>
         <ci id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1">
          …
         </ci>
         <apply id="S3.p1.2.m2.4.4.3.3.3.cmml" xref="S3.p1.2.m2.4.4.3.3.3">
          <csymbol cd="ambiguous" id="S3.p1.2.m2.4.4.3.3.3.1.cmml" xref="S3.p1.2.m2.4.4.3.3.3">
           subscript
          </csymbol>
          <ci id="S3.p1.2.m2.4.4.3.3.3.2.cmml" xref="S3.p1.2.m2.4.4.3.3.3.2">
           𝑆
          </ci>
          <ci id="S3.p1.2.m2.4.4.3.3.3.3.cmml" xref="S3.p1.2.m2.4.4.3.3.3.3">
           𝑛
          </ci>
         </apply>
        </list>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.p1.2.m2.4c">
       S=[S_{0},S_{1},...,S_{n}]
      </annotation>
     </semantics>
    </math>
    ; (3) An
    <span class="ltx_text ltx_font_italic" id="S3.p1.8.3">
     LLM-based observer
    </span>
    to gather information from the environment and depict the partially observed world state
    <math alttext="\mathcal{W}_{t}" class="ltx_Math" display="inline" id="S3.p1.3.m3.1">
     <semantics id="S3.p1.3.m3.1a">
      <msub id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml">
       <mi class="ltx_font_mathcaligraphic" id="S3.p1.3.m3.1.1.2" xref="S3.p1.3.m3.1.1.2.cmml">
        𝒲
       </mi>
       <mi id="S3.p1.3.m3.1.1.3" xref="S3.p1.3.m3.1.1.3.cmml">
        t
       </mi>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.1b">
       <apply id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1">
        <csymbol cd="ambiguous" id="S3.p1.3.m3.1.1.1.cmml" xref="S3.p1.3.m3.1.1">
         subscript
        </csymbol>
        <ci id="S3.p1.3.m3.1.1.2.cmml" xref="S3.p1.3.m3.1.1.2">
         𝒲
        </ci>
        <ci id="S3.p1.3.m3.1.1.3.cmml" xref="S3.p1.3.m3.1.1.3">
         𝑡
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.p1.3.m3.1c">
       \mathcal{W}_{t}
      </annotation>
     </semantics>
    </math>
    at the current time step
    <math alttext="t" class="ltx_Math" display="inline" id="S3.p1.4.m4.1">
     <semantics id="S3.p1.4.m4.1a">
      <mi id="S3.p1.4.m4.1.1" xref="S3.p1.4.m4.1.1.cmml">
       t
      </mi>
      <annotation-xml encoding="MathML-Content" id="S3.p1.4.m4.1b">
       <ci id="S3.p1.4.m4.1.1.cmml" xref="S3.p1.4.m4.1.1">
        𝑡
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.p1.4.m4.1c">
       t
      </annotation>
     </semantics>
    </math>
    as natural language description
    <math alttext="O^{L}_{t}" class="ltx_Math" display="inline" id="S3.p1.5.m5.1">
     <semantics id="S3.p1.5.m5.1a">
      <msubsup id="S3.p1.5.m5.1.1" xref="S3.p1.5.m5.1.1.cmml">
       <mi id="S3.p1.5.m5.1.1.2.2" xref="S3.p1.5.m5.1.1.2.2.cmml">
        O
       </mi>
       <mi id="S3.p1.5.m5.1.1.3" xref="S3.p1.5.m5.1.1.3.cmml">
        t
       </mi>
       <mi id="S3.p1.5.m5.1.1.2.3" xref="S3.p1.5.m5.1.1.2.3.cmml">
        L
       </mi>
      </msubsup>
      <annotation-xml encoding="MathML-Content" id="S3.p1.5.m5.1b">
       <apply id="S3.p1.5.m5.1.1.cmml" xref="S3.p1.5.m5.1.1">
        <csymbol cd="ambiguous" id="S3.p1.5.m5.1.1.1.cmml" xref="S3.p1.5.m5.1.1">
         subscript
        </csymbol>
        <apply id="S3.p1.5.m5.1.1.2.cmml" xref="S3.p1.5.m5.1.1">
         <csymbol cd="ambiguous" id="S3.p1.5.m5.1.1.2.1.cmml" xref="S3.p1.5.m5.1.1">
          superscript
         </csymbol>
         <ci id="S3.p1.5.m5.1.1.2.2.cmml" xref="S3.p1.5.m5.1.1.2.2">
          𝑂
         </ci>
         <ci id="S3.p1.5.m5.1.1.2.3.cmml" xref="S3.p1.5.m5.1.1.2.3">
          𝐿
         </ci>
        </apply>
        <ci id="S3.p1.5.m5.1.1.3.cmml" xref="S3.p1.5.m5.1.1.3">
         𝑡
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.p1.5.m5.1c">
       O^{L}_{t}
      </annotation>
     </semantics>
    </math>
    ; (4) An
    <span class="ltx_text ltx_font_italic" id="S3.p1.8.4">
     LLM-based executor
    </span>
    to receive the world state description
    <math alttext="O^{L}_{t}" class="ltx_Math" display="inline" id="S3.p1.6.m6.1">
     <semantics id="S3.p1.6.m6.1a">
      <msubsup id="S3.p1.6.m6.1.1" xref="S3.p1.6.m6.1.1.cmml">
       <mi id="S3.p1.6.m6.1.1.2.2" xref="S3.p1.6.m6.1.1.2.2.cmml">
        O
       </mi>
       <mi id="S3.p1.6.m6.1.1.3" xref="S3.p1.6.m6.1.1.3.cmml">
        t
       </mi>
       <mi id="S3.p1.6.m6.1.1.2.3" xref="S3.p1.6.m6.1.1.2.3.cmml">
        L
       </mi>
      </msubsup>
      <annotation-xml encoding="MathML-Content" id="S3.p1.6.m6.1b">
       <apply id="S3.p1.6.m6.1.1.cmml" xref="S3.p1.6.m6.1.1">
        <csymbol cd="ambiguous" id="S3.p1.6.m6.1.1.1.cmml" xref="S3.p1.6.m6.1.1">
         subscript
        </csymbol>
        <apply id="S3.p1.6.m6.1.1.2.cmml" xref="S3.p1.6.m6.1.1">
         <csymbol cd="ambiguous" id="S3.p1.6.m6.1.1.2.1.cmml" xref="S3.p1.6.m6.1.1">
          superscript
         </csymbol>
         <ci id="S3.p1.6.m6.1.1.2.2.cmml" xref="S3.p1.6.m6.1.1.2.2">
          𝑂
         </ci>
         <ci id="S3.p1.6.m6.1.1.2.3.cmml" xref="S3.p1.6.m6.1.1.2.3">
          𝐿
         </ci>
        </apply>
        <ci id="S3.p1.6.m6.1.1.3.cmml" xref="S3.p1.6.m6.1.1.3">
         𝑡
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.p1.6.m6.1c">
       O^{L}_{t}
      </annotation>
     </semantics>
    </math>
    and select skill from a set of pre-defined skills to complete the current subtask
    <math alttext="S_{i}" class="ltx_Math" display="inline" id="S3.p1.7.m7.1">
     <semantics id="S3.p1.7.m7.1a">
      <msub id="S3.p1.7.m7.1.1" xref="S3.p1.7.m7.1.1.cmml">
       <mi id="S3.p1.7.m7.1.1.2" xref="S3.p1.7.m7.1.1.2.cmml">
        S
       </mi>
       <mi id="S3.p1.7.m7.1.1.3" xref="S3.p1.7.m7.1.1.3.cmml">
        i
       </mi>
      </msub>
      <annotation-xml encoding="MathML-Content" id="S3.p1.7.m7.1b">
       <apply id="S3.p1.7.m7.1.1.cmml" xref="S3.p1.7.m7.1.1">
        <csymbol cd="ambiguous" id="S3.p1.7.m7.1.1.1.cmml" xref="S3.p1.7.m7.1.1">
         subscript
        </csymbol>
        <ci id="S3.p1.7.m7.1.1.2.cmml" xref="S3.p1.7.m7.1.1.2">
         𝑆
        </ci>
        <ci id="S3.p1.7.m7.1.1.3.cmml" xref="S3.p1.7.m7.1.1.3">
         𝑖
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.p1.7.m7.1c">
       S_{i}
      </annotation>
     </semantics>
    </math>
    ; (5) A
    <span class="ltx_text ltx_font_italic" id="S3.p1.8.5">
     skill library
    </span>
    <math alttext="\mathcal{SL}=\{sl_{0},sl_{1},...\}" class="ltx_Math" display="inline" id="S3.p1.8.m8.3">
     <semantics id="S3.p1.8.m8.3a">
      <mrow id="S3.p1.8.m8.3.3" xref="S3.p1.8.m8.3.3.cmml">
       <mrow id="S3.p1.8.m8.3.3.4" xref="S3.p1.8.m8.3.3.4.cmml">
        <mi class="ltx_font_mathcaligraphic" id="S3.p1.8.m8.3.3.4.2" xref="S3.p1.8.m8.3.3.4.2.cmml">
         𝒮
        </mi>
        <mo id="S3.p1.8.m8.3.3.4.1" lspace="0em" rspace="0em" xref="S3.p1.8.m8.3.3.4.1.cmml">
         ​
        </mo>
        <mi class="ltx_font_mathcaligraphic" id="S3.p1.8.m8.3.3.4.3" xref="S3.p1.8.m8.3.3.4.3.cmml">
         ℒ
        </mi>
       </mrow>
       <mo id="S3.p1.8.m8.3.3.3" xref="S3.p1.8.m8.3.3.3.cmml">
        =
       </mo>
       <mrow id="S3.p1.8.m8.3.3.2.2" xref="S3.p1.8.m8.3.3.2.3.cmml">
        <mo id="S3.p1.8.m8.3.3.2.2.3" stretchy="false" xref="S3.p1.8.m8.3.3.2.3.cmml">
         {
        </mo>
        <mrow id="S3.p1.8.m8.2.2.1.1.1" xref="S3.p1.8.m8.2.2.1.1.1.cmml">
         <mi id="S3.p1.8.m8.2.2.1.1.1.2" xref="S3.p1.8.m8.2.2.1.1.1.2.cmml">
          s
         </mi>
         <mo id="S3.p1.8.m8.2.2.1.1.1.1" lspace="0em" rspace="0em" xref="S3.p1.8.m8.2.2.1.1.1.1.cmml">
          ​
         </mo>
         <msub id="S3.p1.8.m8.2.2.1.1.1.3" xref="S3.p1.8.m8.2.2.1.1.1.3.cmml">
          <mi id="S3.p1.8.m8.2.2.1.1.1.3.2" xref="S3.p1.8.m8.2.2.1.1.1.3.2.cmml">
           l
          </mi>
          <mn id="S3.p1.8.m8.2.2.1.1.1.3.3" xref="S3.p1.8.m8.2.2.1.1.1.3.3.cmml">
           0
          </mn>
         </msub>
        </mrow>
        <mo id="S3.p1.8.m8.3.3.2.2.4" xref="S3.p1.8.m8.3.3.2.3.cmml">
         ,
        </mo>
        <mrow id="S3.p1.8.m8.3.3.2.2.2" xref="S3.p1.8.m8.3.3.2.2.2.cmml">
         <mi id="S3.p1.8.m8.3.3.2.2.2.2" xref="S3.p1.8.m8.3.3.2.2.2.2.cmml">
          s
         </mi>
         <mo id="S3.p1.8.m8.3.3.2.2.2.1" lspace="0em" rspace="0em" xref="S3.p1.8.m8.3.3.2.2.2.1.cmml">
          ​
         </mo>
         <msub id="S3.p1.8.m8.3.3.2.2.2.3" xref="S3.p1.8.m8.3.3.2.2.2.3.cmml">
          <mi id="S3.p1.8.m8.3.3.2.2.2.3.2" xref="S3.p1.8.m8.3.3.2.2.2.3.2.cmml">
           l
          </mi>
          <mn id="S3.p1.8.m8.3.3.2.2.2.3.3" xref="S3.p1.8.m8.3.3.2.2.2.3.3.cmml">
           1
          </mn>
         </msub>
        </mrow>
        <mo id="S3.p1.8.m8.3.3.2.2.5" xref="S3.p1.8.m8.3.3.2.3.cmml">
         ,
        </mo>
        <mi id="S3.p1.8.m8.1.1" mathvariant="normal" xref="S3.p1.8.m8.1.1.cmml">
         …
        </mi>
        <mo id="S3.p1.8.m8.3.3.2.2.6" stretchy="false" xref="S3.p1.8.m8.3.3.2.3.cmml">
         }
        </mo>
       </mrow>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="S3.p1.8.m8.3b">
       <apply id="S3.p1.8.m8.3.3.cmml" xref="S3.p1.8.m8.3.3">
        <eq id="S3.p1.8.m8.3.3.3.cmml" xref="S3.p1.8.m8.3.3.3">
        </eq>
        <apply id="S3.p1.8.m8.3.3.4.cmml" xref="S3.p1.8.m8.3.3.4">
         <times id="S3.p1.8.m8.3.3.4.1.cmml" xref="S3.p1.8.m8.3.3.4.1">
         </times>
         <ci id="S3.p1.8.m8.3.3.4.2.cmml" xref="S3.p1.8.m8.3.3.4.2">
          𝒮
         </ci>
         <ci id="S3.p1.8.m8.3.3.4.3.cmml" xref="S3.p1.8.m8.3.3.4.3">
          ℒ
         </ci>
        </apply>
        <set id="S3.p1.8.m8.3.3.2.3.cmml" xref="S3.p1.8.m8.3.3.2.2">
         <apply id="S3.p1.8.m8.2.2.1.1.1.cmml" xref="S3.p1.8.m8.2.2.1.1.1">
          <times id="S3.p1.8.m8.2.2.1.1.1.1.cmml" xref="S3.p1.8.m8.2.2.1.1.1.1">
          </times>
          <ci id="S3.p1.8.m8.2.2.1.1.1.2.cmml" xref="S3.p1.8.m8.2.2.1.1.1.2">
           𝑠
          </ci>
          <apply id="S3.p1.8.m8.2.2.1.1.1.3.cmml" xref="S3.p1.8.m8.2.2.1.1.1.3">
           <csymbol cd="ambiguous" id="S3.p1.8.m8.2.2.1.1.1.3.1.cmml" xref="S3.p1.8.m8.2.2.1.1.1.3">
            subscript
           </csymbol>
           <ci id="S3.p1.8.m8.2.2.1.1.1.3.2.cmml" xref="S3.p1.8.m8.2.2.1.1.1.3.2">
            𝑙
           </ci>
           <cn id="S3.p1.8.m8.2.2.1.1.1.3.3.cmml" type="integer" xref="S3.p1.8.m8.2.2.1.1.1.3.3">
            0
           </cn>
          </apply>
         </apply>
         <apply id="S3.p1.8.m8.3.3.2.2.2.cmml" xref="S3.p1.8.m8.3.3.2.2.2">
          <times id="S3.p1.8.m8.3.3.2.2.2.1.cmml" xref="S3.p1.8.m8.3.3.2.2.2.1">
          </times>
          <ci id="S3.p1.8.m8.3.3.2.2.2.2.cmml" xref="S3.p1.8.m8.3.3.2.2.2.2">
           𝑠
          </ci>
          <apply id="S3.p1.8.m8.3.3.2.2.2.3.cmml" xref="S3.p1.8.m8.3.3.2.2.2.3">
           <csymbol cd="ambiguous" id="S3.p1.8.m8.3.3.2.2.2.3.1.cmml" xref="S3.p1.8.m8.3.3.2.2.2.3">
            subscript
           </csymbol>
           <ci id="S3.p1.8.m8.3.3.2.2.2.3.2.cmml" xref="S3.p1.8.m8.3.3.2.2.2.3.2">
            𝑙
           </ci>
           <cn id="S3.p1.8.m8.3.3.2.2.2.3.3.cmml" type="integer" xref="S3.p1.8.m8.3.3.2.2.2.3.3">
            1
           </cn>
          </apply>
         </apply>
         <ci id="S3.p1.8.m8.1.1.cmml" xref="S3.p1.8.m8.1.1">
          …
         </ci>
        </set>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="S3.p1.8.m8.3c">
       \mathcal{SL}=\{sl_{0},sl_{1},...\}
      </annotation>
     </semantics>
    </math>
    to store the skills manipulating the agent in the simulated environment (e.g,
    <span class="ltx_text ltx_font_italic" id="S3.p1.8.6">
     NavigateTo
    </span>
    ,
    <span class="ltx_text ltx_font_italic" id="S3.p1.8.7">
     LookAround
    </span>
    , and
    <span class="ltx_text ltx_font_italic" id="S3.p1.8.8">
     Explore
    </span>
    ); (6) A
    <span class="ltx_text ltx_font_italic" id="S3.p1.8.9">
     deterministic action policy
    </span>
    to convert the skills into low-level actions (e.g.,
    <span class="ltx_text ltx_font_italic" id="S3.p1.8.10">
     RotateRight
    </span>
    ).
   </p>
  </div>
  <section class="ltx_paragraph" id="S3.SS0.SSS0.Px1">
   <h4 class="ltx_title ltx_title_paragraph">
    Semantic Mapping Module
   </h4>
   <div class="ltx_para" id="S3.SS0.SSS0.Px1.p1">
    <p class="ltx_p" id="S3.SS0.SSS0.Px1.p1.11">
     The goal of the semantic mapping module is to create a 2D semantic map
     <math alttext="M_{t}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.1.m1.1">
      <semantics id="S3.SS0.SSS0.Px1.p1.1.m1.1a">
       <msub id="S3.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.cmml">
        <mi id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.2" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.2.cmml">
         M
        </mi>
        <mi id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.cmml">
         t
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.1.m1.1b">
        <apply id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1">
         <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.2">
          𝑀
         </ci>
         <ci id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3">
          𝑡
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.1.m1.1c">
        M_{t}
       </annotation>
      </semantics>
     </math>
     from a top-down perspective (i.e., a map of explored areas, obstacles, and detected objects). At each time step
     <math alttext="t" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.2.m2.1">
      <semantics id="S3.SS0.SSS0.Px1.p1.2.m2.1a">
       <mi id="S3.SS0.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS0.SSS0.Px1.p1.2.m2.1.1.cmml">
        t
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.2.m2.1b">
        <ci id="S3.SS0.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.2.m2.1.1">
         𝑡
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.2.m2.1c">
        t
       </annotation>
      </semantics>
     </math>
     , this module receives the egocentric visual observation
     <math alttext="V_{t}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.3.m3.1">
      <semantics id="S3.SS0.SSS0.Px1.p1.3.m3.1a">
       <msub id="S3.SS0.SSS0.Px1.p1.3.m3.1.1" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1.cmml">
        <mi id="S3.SS0.SSS0.Px1.p1.3.m3.1.1.2" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1.2.cmml">
         V
        </mi>
        <mi id="S3.SS0.SSS0.Px1.p1.3.m3.1.1.3" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1.3.cmml">
         t
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.3.m3.1b">
        <apply id="S3.SS0.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1">
         <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS0.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1.2">
          𝑉
         </ci>
         <ci id="S3.SS0.SSS0.Px1.p1.3.m3.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1.3">
          𝑡
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.3.m3.1c">
        V_{t}
       </annotation>
      </semantics>
     </math>
     of the world state
     <math alttext="\mathcal{W}_{t}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.4.m4.1">
      <semantics id="S3.SS0.SSS0.Px1.p1.4.m4.1a">
       <msub id="S3.SS0.SSS0.Px1.p1.4.m4.1.1" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.1.cmml">
        <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px1.p1.4.m4.1.1.2" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.1.2.cmml">
         𝒲
        </mi>
        <mi id="S3.SS0.SSS0.Px1.p1.4.m4.1.1.3" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.1.3.cmml">
         t
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.4.m4.1b">
        <apply id="S3.SS0.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.1">
         <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.4.m4.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS0.SSS0.Px1.p1.4.m4.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.1.2">
          𝒲
         </ci>
         <ci id="S3.SS0.SSS0.Px1.p1.4.m4.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.1.3">
          𝑡
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.4.m4.1c">
        \mathcal{W}_{t}
       </annotation>
      </semantics>
     </math>
     as input, which is then processed into a depth map and instance segmentation using a UNet
     <cite class="ltx_cite ltx_citemacro_cite">
      Ronneberger et al. (
      <a class="ltx_ref" href="#bib.bib28" title="">
       2015
      </a>
      )
     </cite>
     and
a MaskRCNN
     <cite class="ltx_cite ltx_citemacro_cite">
      He et al. (
      <a class="ltx_ref" href="#bib.bib10" title="">
       2017
      </a>
      )
     </cite>
     (or ZoeDepth
     <cite class="ltx_cite ltx_citemacro_cite">
      Bhat et al. (
      <a class="ltx_ref" href="#bib.bib2" title="">
       2023
      </a>
      )
     </cite>
     and SOLQ
     <cite class="ltx_cite ltx_citemacro_cite">
      Dong et al. (
      <a class="ltx_ref" href="#bib.bib6" title="">
       2021
      </a>
      )
     </cite>
     as stronger perception models). Following FILM
     <cite class="ltx_cite ltx_citemacro_cite">
      Min et al. (
      <a class="ltx_ref" href="#bib.bib21" title="">
       2021
      </a>
      )
     </cite>
     , we use the implementation from
     <cite class="ltx_cite ltx_citemacro_cite">
      Blukis et al. (
      <a class="ltx_ref" href="#bib.bib3" title="">
       2022
      </a>
      )
     </cite>
     for UNet-based depth estimation and
     <cite class="ltx_cite ltx_citemacro_cite">
      Shridhar et al. (
      <a class="ltx_ref" href="#bib.bib34" title="">
       2020b
      </a>
      )
     </cite>
     for MaskRCNN-based instance segmentation. Then, a point cloud is constructed from the depth prediction and instance segmentation. Finally, the point cloud is binned into a voxel representation and then transformed into the 2D semantic map
     <math alttext="M_{t}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.5.m5.1">
      <semantics id="S3.SS0.SSS0.Px1.p1.5.m5.1a">
       <msub id="S3.SS0.SSS0.Px1.p1.5.m5.1.1" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1.cmml">
        <mi id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2.cmml">
         M
        </mi>
        <mi id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.3" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1.3.cmml">
         t
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.5.m5.1b">
        <apply id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1">
         <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2">
          𝑀
         </ci>
         <ci id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1.3">
          𝑡
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.5.m5.1c">
        M_{t}
       </annotation>
      </semantics>
     </math>
     by summing over the height of the voxel representation, which is updated and aggregated over time steps.
Due to the inherent difficulty in achieving a flawless perceptual model, the resulting semantic map
     <math alttext="M_{t}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.6.m6.1">
      <semantics id="S3.SS0.SSS0.Px1.p1.6.m6.1a">
       <msub id="S3.SS0.SSS0.Px1.p1.6.m6.1.1" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.cmml">
        <mi id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.2" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.2.cmml">
         M
        </mi>
        <mi id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.cmml">
         t
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.6.m6.1b">
        <apply id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1">
         <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.2">
          𝑀
         </ci>
         <ci id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3">
          𝑡
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.6.m6.1c">
        M_{t}
       </annotation>
      </semantics>
     </math>
     often includes noise. This noise has the potential to exacerbate the challenges associated with locating navigational targets and subsequently affect the performance. To address such kind of issues, we introduce a supplementary semantic map denoted as
     <math alttext="M_{t}^{\prime}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.7.m7.1">
      <semantics id="S3.SS0.SSS0.Px1.p1.7.m7.1a">
       <msubsup id="S3.SS0.SSS0.Px1.p1.7.m7.1.1" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1.cmml">
        <mi id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.2.2" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1.2.2.cmml">
         M
        </mi>
        <mi id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.2.3" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1.2.3.cmml">
         t
        </mi>
        <mo id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.3" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1.3.cmml">
         ′
        </mo>
       </msubsup>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.7.m7.1b">
        <apply id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1">
         <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1">
          superscript
         </csymbol>
         <apply id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1">
          <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.2.1.cmml" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1">
           subscript
          </csymbol>
          <ci id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.2.2.cmml" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1.2.2">
           𝑀
          </ci>
          <ci id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.2.3.cmml" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1.2.3">
           𝑡
          </ci>
         </apply>
         <ci id="S3.SS0.SSS0.Px1.p1.7.m7.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.7.m7.1.1.3">
          ′
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.7.m7.1c">
        M_{t}^{\prime}
       </annotation>
      </semantics>
     </math>
     , which aggregates the information from
     <math alttext="M_{t}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.8.m8.1">
      <semantics id="S3.SS0.SSS0.Px1.p1.8.m8.1a">
       <msub id="S3.SS0.SSS0.Px1.p1.8.m8.1.1" xref="S3.SS0.SSS0.Px1.p1.8.m8.1.1.cmml">
        <mi id="S3.SS0.SSS0.Px1.p1.8.m8.1.1.2" xref="S3.SS0.SSS0.Px1.p1.8.m8.1.1.2.cmml">
         M
        </mi>
        <mi id="S3.SS0.SSS0.Px1.p1.8.m8.1.1.3" xref="S3.SS0.SSS0.Px1.p1.8.m8.1.1.3.cmml">
         t
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.8.m8.1b">
        <apply id="S3.SS0.SSS0.Px1.p1.8.m8.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.1.1">
         <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.8.m8.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS0.SSS0.Px1.p1.8.m8.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.1.1.2">
          𝑀
         </ci>
         <ci id="S3.SS0.SSS0.Px1.p1.8.m8.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.8.m8.1.1.3">
          𝑡
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.8.m8.1c">
        M_{t}
       </annotation>
      </semantics>
     </math>
     over successive time steps. The intuition resembles a form of majority voting: when an object is recognized as a fridge across more viewpoints than as a wall, its likelihood of being a fridge over a wall should be proportionally increased. The two semantic maps work in a cascading manner: when the agent tries to identify an object from the maps, the initial search is conducted within
     <math alttext="M_{t}^{\prime}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.9.m9.1">
      <semantics id="S3.SS0.SSS0.Px1.p1.9.m9.1a">
       <msubsup id="S3.SS0.SSS0.Px1.p1.9.m9.1.1" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1.cmml">
        <mi id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.2.2" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1.2.2.cmml">
         M
        </mi>
        <mi id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.2.3" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1.2.3.cmml">
         t
        </mi>
        <mo id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.3" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1.3.cmml">
         ′
        </mo>
       </msubsup>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.9.m9.1b">
        <apply id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1">
         <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1">
          superscript
         </csymbol>
         <apply id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1">
          <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.2.1.cmml" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1">
           subscript
          </csymbol>
          <ci id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.2.2.cmml" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1.2.2">
           𝑀
          </ci>
          <ci id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.2.3.cmml" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1.2.3">
           𝑡
          </ci>
         </apply>
         <ci id="S3.SS0.SSS0.Px1.p1.9.m9.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.9.m9.1.1.3">
          ′
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.9.m9.1c">
        M_{t}^{\prime}
       </annotation>
      </semantics>
     </math>
     .
     <math alttext="M_{t}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.10.m10.1">
      <semantics id="S3.SS0.SSS0.Px1.p1.10.m10.1a">
       <msub id="S3.SS0.SSS0.Px1.p1.10.m10.1.1" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.cmml">
        <mi id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.2" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.2.cmml">
         M
        </mi>
        <mi id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.3" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.3.cmml">
         t
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.10.m10.1b">
        <apply id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1">
         <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.2">
          𝑀
         </ci>
         <ci id="S3.SS0.SSS0.Px1.p1.10.m10.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.10.m10.1.1.3">
          𝑡
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.10.m10.1c">
        M_{t}
       </annotation>
      </semantics>
     </math>
     is only utilized if the object cannot be located within
     <math alttext="M_{t}^{\prime}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.11.m11.1">
      <semantics id="S3.SS0.SSS0.Px1.p1.11.m11.1a">
       <msubsup id="S3.SS0.SSS0.Px1.p1.11.m11.1.1" xref="S3.SS0.SSS0.Px1.p1.11.m11.1.1.cmml">
        <mi id="S3.SS0.SSS0.Px1.p1.11.m11.1.1.2.2" xref="S3.SS0.SSS0.Px1.p1.11.m11.1.1.2.2.cmml">
         M
        </mi>
        <mi id="S3.SS0.SSS0.Px1.p1.11.m11.1.1.2.3" xref="S3.SS0.SSS0.Px1.p1.11.m11.1.1.2.3.cmml">
         t
        </mi>
        <mo id="S3.SS0.SSS0.Px1.p1.11.m11.1.1.3" xref="S3.SS0.SSS0.Px1.p1.11.m11.1.1.3.cmml">
         ′
        </mo>
       </msubsup>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.11.m11.1b">
        <apply id="S3.SS0.SSS0.Px1.p1.11.m11.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.11.m11.1.1">
         <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.11.m11.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.11.m11.1.1">
          superscript
         </csymbol>
         <apply id="S3.SS0.SSS0.Px1.p1.11.m11.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.11.m11.1.1">
          <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.11.m11.1.1.2.1.cmml" xref="S3.SS0.SSS0.Px1.p1.11.m11.1.1">
           subscript
          </csymbol>
          <ci id="S3.SS0.SSS0.Px1.p1.11.m11.1.1.2.2.cmml" xref="S3.SS0.SSS0.Px1.p1.11.m11.1.1.2.2">
           𝑀
          </ci>
          <ci id="S3.SS0.SSS0.Px1.p1.11.m11.1.1.2.3.cmml" xref="S3.SS0.SSS0.Px1.p1.11.m11.1.1.2.3">
           𝑡
          </ci>
         </apply>
         <ci id="S3.SS0.SSS0.Px1.p1.11.m11.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.11.m11.1.1.3">
          ′
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.11.m11.1c">
        M_{t}^{\prime}
       </annotation>
      </semantics>
     </math>
     .
    </p>
   </div>
  </section>
  <section class="ltx_paragraph" id="S3.SS0.SSS0.Px2">
   <h4 class="ltx_title ltx_title_paragraph">
    LLM-based Planner
   </h4>
   <div class="ltx_para" id="S3.SS0.SSS0.Px2.p1">
    <p class="ltx_p" id="S3.SS0.SSS0.Px2.p1.2">
     The goal of the LLM-based planner is to decompose a specified language instruction
     <math alttext="L" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px2.p1.1.m1.1">
      <semantics id="S3.SS0.SSS0.Px2.p1.1.m1.1a">
       <mi id="S3.SS0.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.cmml">
        L
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p1.1.m1.1b">
        <ci id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1">
         𝐿
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p1.1.m1.1c">
        L
       </annotation>
      </semantics>
     </math>
     into a sequence of subtasks
     <math alttext="S=[S_{0},S_{1},...,S_{n}]" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px2.p1.2.m2.4">
      <semantics id="S3.SS0.SSS0.Px2.p1.2.m2.4a">
       <mrow id="S3.SS0.SSS0.Px2.p1.2.m2.4.4" xref="S3.SS0.SSS0.Px2.p1.2.m2.4.4.cmml">
        <mi id="S3.SS0.SSS0.Px2.p1.2.m2.4.4.5" xref="S3.SS0.SSS0.Px2.p1.2.m2.4.4.5.cmml">
         S
        </mi>
        <mo id="S3.SS0.SSS0.Px2.p1.2.m2.4.4.4" xref="S3.SS0.SSS0.Px2.p1.2.m2.4.4.4.cmml">
         =
        </mo>
        <mrow id="S3.SS0.SSS0.Px2.p1.2.m2.4.4.3.3" xref="S3.SS0.SSS0.Px2.p1.2.m2.4.4.3.4.cmml">
         <mo id="S3.SS0.SSS0.Px2.p1.2.m2.4.4.3.3.4" stretchy="false" xref="S3.SS0.SSS0.Px2.p1.2.m2.4.4.3.4.cmml">
          [
         </mo>
         <msub id="S3.SS0.SSS0.Px2.p1.2.m2.2.2.1.1.1" xref="S3.SS0.SSS0.Px2.p1.2.m2.2.2.1.1.1.cmml">
          <mi id="S3.SS0.SSS0.Px2.p1.2.m2.2.2.1.1.1.2" xref="S3.SS0.SSS0.Px2.p1.2.m2.2.2.1.1.1.2.cmml">
           S
          </mi>
          <mn id="S3.SS0.SSS0.Px2.p1.2.m2.2.2.1.1.1.3" xref="S3.SS0.SSS0.Px2.p1.2.m2.2.2.1.1.1.3.cmml">
           0
          </mn>
         </msub>
         <mo id="S3.SS0.SSS0.Px2.p1.2.m2.4.4.3.3.5" xref="S3.SS0.SSS0.Px2.p1.2.m2.4.4.3.4.cmml">
          ,
         </mo>
         <msub id="S3.SS0.SSS0.Px2.p1.2.m2.3.3.2.2.2" xref="S3.SS0.SSS0.Px2.p1.2.m2.3.3.2.2.2.cmml">
          <mi id="S3.SS0.SSS0.Px2.p1.2.m2.3.3.2.2.2.2" xref="S3.SS0.SSS0.Px2.p1.2.m2.3.3.2.2.2.2.cmml">
           S
          </mi>
          <mn id="S3.SS0.SSS0.Px2.p1.2.m2.3.3.2.2.2.3" xref="S3.SS0.SSS0.Px2.p1.2.m2.3.3.2.2.2.3.cmml">
           1
          </mn>
         </msub>
         <mo id="S3.SS0.SSS0.Px2.p1.2.m2.4.4.3.3.6" xref="S3.SS0.SSS0.Px2.p1.2.m2.4.4.3.4.cmml">
          ,
         </mo>
         <mi id="S3.SS0.SSS0.Px2.p1.2.m2.1.1" mathvariant="normal" xref="S3.SS0.SSS0.Px2.p1.2.m2.1.1.cmml">
          …
         </mi>
         <mo id="S3.SS0.SSS0.Px2.p1.2.m2.4.4.3.3.7" xref="S3.SS0.SSS0.Px2.p1.2.m2.4.4.3.4.cmml">
          ,
         </mo>
         <msub id="S3.SS0.SSS0.Px2.p1.2.m2.4.4.3.3.3" xref="S3.SS0.SSS0.Px2.p1.2.m2.4.4.3.3.3.cmml">
          <mi id="S3.SS0.SSS0.Px2.p1.2.m2.4.4.3.3.3.2" xref="S3.SS0.SSS0.Px2.p1.2.m2.4.4.3.3.3.2.cmml">
           S
          </mi>
          <mi id="S3.SS0.SSS0.Px2.p1.2.m2.4.4.3.3.3.3" xref="S3.SS0.SSS0.Px2.p1.2.m2.4.4.3.3.3.3.cmml">
           n
          </mi>
         </msub>
         <mo id="S3.SS0.SSS0.Px2.p1.2.m2.4.4.3.3.8" stretchy="false" xref="S3.SS0.SSS0.Px2.p1.2.m2.4.4.3.4.cmml">
          ]
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p1.2.m2.4b">
        <apply id="S3.SS0.SSS0.Px2.p1.2.m2.4.4.cmml" xref="S3.SS0.SSS0.Px2.p1.2.m2.4.4">
         <eq id="S3.SS0.SSS0.Px2.p1.2.m2.4.4.4.cmml" xref="S3.SS0.SSS0.Px2.p1.2.m2.4.4.4">
         </eq>
         <ci id="S3.SS0.SSS0.Px2.p1.2.m2.4.4.5.cmml" xref="S3.SS0.SSS0.Px2.p1.2.m2.4.4.5">
          𝑆
         </ci>
         <list id="S3.SS0.SSS0.Px2.p1.2.m2.4.4.3.4.cmml" xref="S3.SS0.SSS0.Px2.p1.2.m2.4.4.3.3">
          <apply id="S3.SS0.SSS0.Px2.p1.2.m2.2.2.1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.2.m2.2.2.1.1.1">
           <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px2.p1.2.m2.2.2.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.2.m2.2.2.1.1.1">
            subscript
           </csymbol>
           <ci id="S3.SS0.SSS0.Px2.p1.2.m2.2.2.1.1.1.2.cmml" xref="S3.SS0.SSS0.Px2.p1.2.m2.2.2.1.1.1.2">
            𝑆
           </ci>
           <cn id="S3.SS0.SSS0.Px2.p1.2.m2.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS0.SSS0.Px2.p1.2.m2.2.2.1.1.1.3">
            0
           </cn>
          </apply>
          <apply id="S3.SS0.SSS0.Px2.p1.2.m2.3.3.2.2.2.cmml" xref="S3.SS0.SSS0.Px2.p1.2.m2.3.3.2.2.2">
           <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px2.p1.2.m2.3.3.2.2.2.1.cmml" xref="S3.SS0.SSS0.Px2.p1.2.m2.3.3.2.2.2">
            subscript
           </csymbol>
           <ci id="S3.SS0.SSS0.Px2.p1.2.m2.3.3.2.2.2.2.cmml" xref="S3.SS0.SSS0.Px2.p1.2.m2.3.3.2.2.2.2">
            𝑆
           </ci>
           <cn id="S3.SS0.SSS0.Px2.p1.2.m2.3.3.2.2.2.3.cmml" type="integer" xref="S3.SS0.SSS0.Px2.p1.2.m2.3.3.2.2.2.3">
            1
           </cn>
          </apply>
          <ci id="S3.SS0.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.2.m2.1.1">
           …
          </ci>
          <apply id="S3.SS0.SSS0.Px2.p1.2.m2.4.4.3.3.3.cmml" xref="S3.SS0.SSS0.Px2.p1.2.m2.4.4.3.3.3">
           <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px2.p1.2.m2.4.4.3.3.3.1.cmml" xref="S3.SS0.SSS0.Px2.p1.2.m2.4.4.3.3.3">
            subscript
           </csymbol>
           <ci id="S3.SS0.SSS0.Px2.p1.2.m2.4.4.3.3.3.2.cmml" xref="S3.SS0.SSS0.Px2.p1.2.m2.4.4.3.3.3.2">
            𝑆
           </ci>
           <ci id="S3.SS0.SSS0.Px2.p1.2.m2.4.4.3.3.3.3.cmml" xref="S3.SS0.SSS0.Px2.p1.2.m2.4.4.3.3.3.3">
            𝑛
           </ci>
          </apply>
         </list>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p1.2.m2.4c">
        S=[S_{0},S_{1},...,S_{n}]
       </annotation>
      </semantics>
     </math>
     . In practice, we utilize Chain-of-Though (CoT)
     <cite class="ltx_cite ltx_citemacro_cite">
      Wei et al. (
      <a class="ltx_ref" href="#bib.bib44" title="">
       2022b
      </a>
      )
     </cite>
     to prompt GPT-4
     <cite class="ltx_cite ltx_citemacro_cite">
      OpenAI (
      <a class="ltx_ref" href="#bib.bib25" title="">
       2023
      </a>
      )
     </cite>
     with in-context learning. The corresponding prompt examples are demonstrated in the Appendix.
    </p>
   </div>
  </section>
  <section class="ltx_paragraph" id="S3.SS0.SSS0.Px3">
   <h4 class="ltx_title ltx_title_paragraph">
    Example Selector
   </h4>
   <div class="ltx_para" id="S3.SS0.SSS0.Px3.p1">
    <p class="ltx_p" id="S3.SS0.SSS0.Px3.p1.1">
     We have collected a set of prompt examples from 10 episodes within the training split for each of the 7 task types, amounting to a total of 70 episodes. As shown in
     <cite class="ltx_cite ltx_citemacro_cite">
      Liu et al. (
      <a class="ltx_ref" href="#bib.bib18" title="">
       2022b
      </a>
      )
     </cite>
     , choosing which in-context examples to add to the prompt can impact the overall performance. Therefore, we further apply an example selector to provide the LLM-based planner with the most relevant examples by ranking the examples based on the similarity of the input test case and the examples. In practice, we employ the example selector from LangChain
     <cite class="ltx_cite ltx_citemacro_cite">
      Chase (
      <a class="ltx_ref" href="#bib.bib4" title="">
       2022
      </a>
      )
     </cite>
     , which first ranks the examples based on the corresponding embeddings
     <span class="ltx_note ltx_role_footnote" id="footnote2">
      <sup class="ltx_note_mark">
       2
      </sup>
      <span class="ltx_note_outer">
       <span class="ltx_note_content">
        <sup class="ltx_note_mark">
         2
        </sup>
        <span class="ltx_tag ltx_tag_note">
         2
        </span>
        We adopt the
        <span class="ltx_text ltx_font_italic" id="footnote2.1">
         text-embedding-ada-002
        </span>
        embeddings provided by OpenAI.
       </span>
      </span>
     </span>
     that have the greatest cosine similarity with the inputs, then select top-
     <math alttext="K" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px3.p1.1.m1.1">
      <semantics id="S3.SS0.SSS0.Px3.p1.1.m1.1a">
       <mi id="S3.SS0.SSS0.Px3.p1.1.m1.1.1" xref="S3.SS0.SSS0.Px3.p1.1.m1.1.1.cmml">
        K
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px3.p1.1.m1.1b">
        <ci id="S3.SS0.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px3.p1.1.m1.1.1">
         𝐾
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px3.p1.1.m1.1c">
        K
       </annotation>
      </semantics>
     </math>
     examples for in-context learning.
    </p>
   </div>
  </section>
  <section class="ltx_paragraph" id="S3.SS0.SSS0.Px4">
   <h4 class="ltx_title ltx_title_paragraph">
    LLM-based Observer
   </h4>
   <div class="ltx_para" id="S3.SS0.SSS0.Px4.p1">
    <p class="ltx_p" id="S3.SS0.SSS0.Px4.p1.1">
     The goal of the LLM-based observer is to extract information from the environment feedback and the agent state, and present it in the form of a natural language description
     <math alttext="O_{t}^{L}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px4.p1.1.m1.1">
      <semantics id="S3.SS0.SSS0.Px4.p1.1.m1.1a">
       <msubsup id="S3.SS0.SSS0.Px4.p1.1.m1.1.1" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1.cmml">
        <mi id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.2.2" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1.2.2.cmml">
         O
        </mi>
        <mi id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.2.3" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1.2.3.cmml">
         t
        </mi>
        <mi id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.3" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1.3.cmml">
         L
        </mi>
       </msubsup>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px4.p1.1.m1.1b">
        <apply id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1">
         <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.1.cmml" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1">
          superscript
         </csymbol>
         <apply id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.2.cmml" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1">
          <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.2.1.cmml" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1">
           subscript
          </csymbol>
          <ci id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.2.2.cmml" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1.2.2">
           𝑂
          </ci>
          <ci id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.2.3.cmml" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1.2.3">
           𝑡
          </ci>
         </apply>
         <ci id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.3.cmml" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1.3">
          𝐿
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px4.p1.1.m1.1c">
        O_{t}^{L}
       </annotation>
      </semantics>
     </math>
     in a zero-shot manner. The rationale behind the design of the LLM-based observer is twofold: (1) to gather and render the state of the environment, enabling the tracking of environment dynamics across time steps and facilitating dynamic planning and acting; and (2) to summarize the information into a task-centric description, thereby safeguarding the LLM-based executor against distractions and hallucinations. The LLM-based observer is querying
     <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px4.p1.1.1">
      GPT-3.5-turbo
     </span>
     with the prompt format shown in the Appendix.
    </p>
   </div>
  </section>
  <section class="ltx_paragraph" id="S3.SS0.SSS0.Px5">
   <h4 class="ltx_title ltx_title_paragraph">
    LLM-based Executor
   </h4>
   <div class="ltx_para" id="S3.SS0.SSS0.Px5.p1">
    <p class="ltx_p" id="S3.SS0.SSS0.Px5.p1.15">
     Given the current subtask
     <math alttext="S_{i}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px5.p1.1.m1.1">
      <semantics id="S3.SS0.SSS0.Px5.p1.1.m1.1a">
       <msub id="S3.SS0.SSS0.Px5.p1.1.m1.1.1" xref="S3.SS0.SSS0.Px5.p1.1.m1.1.1.cmml">
        <mi id="S3.SS0.SSS0.Px5.p1.1.m1.1.1.2" xref="S3.SS0.SSS0.Px5.p1.1.m1.1.1.2.cmml">
         S
        </mi>
        <mi id="S3.SS0.SSS0.Px5.p1.1.m1.1.1.3" xref="S3.SS0.SSS0.Px5.p1.1.m1.1.1.3.cmml">
         i
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px5.p1.1.m1.1b">
        <apply id="S3.SS0.SSS0.Px5.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.1.m1.1.1">
         <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px5.p1.1.m1.1.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.1.m1.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS0.SSS0.Px5.p1.1.m1.1.1.2.cmml" xref="S3.SS0.SSS0.Px5.p1.1.m1.1.1.2">
          𝑆
         </ci>
         <ci id="S3.SS0.SSS0.Px5.p1.1.m1.1.1.3.cmml" xref="S3.SS0.SSS0.Px5.p1.1.m1.1.1.3">
          𝑖
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px5.p1.1.m1.1c">
        S_{i}
       </annotation>
      </semantics>
     </math>
     , the language description of the world state
     <math alttext="O_{t}^{L}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px5.p1.2.m2.1">
      <semantics id="S3.SS0.SSS0.Px5.p1.2.m2.1a">
       <msubsup id="S3.SS0.SSS0.Px5.p1.2.m2.1.1" xref="S3.SS0.SSS0.Px5.p1.2.m2.1.1.cmml">
        <mi id="S3.SS0.SSS0.Px5.p1.2.m2.1.1.2.2" xref="S3.SS0.SSS0.Px5.p1.2.m2.1.1.2.2.cmml">
         O
        </mi>
        <mi id="S3.SS0.SSS0.Px5.p1.2.m2.1.1.2.3" xref="S3.SS0.SSS0.Px5.p1.2.m2.1.1.2.3.cmml">
         t
        </mi>
        <mi id="S3.SS0.SSS0.Px5.p1.2.m2.1.1.3" xref="S3.SS0.SSS0.Px5.p1.2.m2.1.1.3.cmml">
         L
        </mi>
       </msubsup>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px5.p1.2.m2.1b">
        <apply id="S3.SS0.SSS0.Px5.p1.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.2.m2.1.1">
         <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px5.p1.2.m2.1.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.2.m2.1.1">
          superscript
         </csymbol>
         <apply id="S3.SS0.SSS0.Px5.p1.2.m2.1.1.2.cmml" xref="S3.SS0.SSS0.Px5.p1.2.m2.1.1">
          <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px5.p1.2.m2.1.1.2.1.cmml" xref="S3.SS0.SSS0.Px5.p1.2.m2.1.1">
           subscript
          </csymbol>
          <ci id="S3.SS0.SSS0.Px5.p1.2.m2.1.1.2.2.cmml" xref="S3.SS0.SSS0.Px5.p1.2.m2.1.1.2.2">
           𝑂
          </ci>
          <ci id="S3.SS0.SSS0.Px5.p1.2.m2.1.1.2.3.cmml" xref="S3.SS0.SSS0.Px5.p1.2.m2.1.1.2.3">
           𝑡
          </ci>
         </apply>
         <ci id="S3.SS0.SSS0.Px5.p1.2.m2.1.1.3.cmml" xref="S3.SS0.SSS0.Px5.p1.2.m2.1.1.3">
          𝐿
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px5.p1.2.m2.1c">
        O_{t}^{L}
       </annotation>
      </semantics>
     </math>
     at time step
     <math alttext="t" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px5.p1.3.m3.1">
      <semantics id="S3.SS0.SSS0.Px5.p1.3.m3.1a">
       <mi id="S3.SS0.SSS0.Px5.p1.3.m3.1.1" xref="S3.SS0.SSS0.Px5.p1.3.m3.1.1.cmml">
        t
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px5.p1.3.m3.1b">
        <ci id="S3.SS0.SSS0.Px5.p1.3.m3.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.3.m3.1.1">
         𝑡
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px5.p1.3.m3.1c">
        t
       </annotation>
      </semantics>
     </math>
     , the goal of the LLM-based executor is to complete the subtask
     <math alttext="S_{i}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px5.p1.4.m4.1">
      <semantics id="S3.SS0.SSS0.Px5.p1.4.m4.1a">
       <msub id="S3.SS0.SSS0.Px5.p1.4.m4.1.1" xref="S3.SS0.SSS0.Px5.p1.4.m4.1.1.cmml">
        <mi id="S3.SS0.SSS0.Px5.p1.4.m4.1.1.2" xref="S3.SS0.SSS0.Px5.p1.4.m4.1.1.2.cmml">
         S
        </mi>
        <mi id="S3.SS0.SSS0.Px5.p1.4.m4.1.1.3" xref="S3.SS0.SSS0.Px5.p1.4.m4.1.1.3.cmml">
         i
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px5.p1.4.m4.1b">
        <apply id="S3.SS0.SSS0.Px5.p1.4.m4.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.4.m4.1.1">
         <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px5.p1.4.m4.1.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.4.m4.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS0.SSS0.Px5.p1.4.m4.1.1.2.cmml" xref="S3.SS0.SSS0.Px5.p1.4.m4.1.1.2">
          𝑆
         </ci>
         <ci id="S3.SS0.SSS0.Px5.p1.4.m4.1.1.3.cmml" xref="S3.SS0.SSS0.Px5.p1.4.m4.1.1.3">
          𝑖
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px5.p1.4.m4.1c">
        S_{i}
       </annotation>
      </semantics>
     </math>
     by iteratively manipulating the agent in the environment with a set of pre-defined skills from a skill library
     <math alttext="\mathcal{SL}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px5.p1.5.m5.1">
      <semantics id="S3.SS0.SSS0.Px5.p1.5.m5.1a">
       <mrow id="S3.SS0.SSS0.Px5.p1.5.m5.1.1" xref="S3.SS0.SSS0.Px5.p1.5.m5.1.1.cmml">
        <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px5.p1.5.m5.1.1.2" xref="S3.SS0.SSS0.Px5.p1.5.m5.1.1.2.cmml">
         𝒮
        </mi>
        <mo id="S3.SS0.SSS0.Px5.p1.5.m5.1.1.1" lspace="0em" rspace="0em" xref="S3.SS0.SSS0.Px5.p1.5.m5.1.1.1.cmml">
         ​
        </mo>
        <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px5.p1.5.m5.1.1.3" xref="S3.SS0.SSS0.Px5.p1.5.m5.1.1.3.cmml">
         ℒ
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px5.p1.5.m5.1b">
        <apply id="S3.SS0.SSS0.Px5.p1.5.m5.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.5.m5.1.1">
         <times id="S3.SS0.SSS0.Px5.p1.5.m5.1.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.5.m5.1.1.1">
         </times>
         <ci id="S3.SS0.SSS0.Px5.p1.5.m5.1.1.2.cmml" xref="S3.SS0.SSS0.Px5.p1.5.m5.1.1.2">
          𝒮
         </ci>
         <ci id="S3.SS0.SSS0.Px5.p1.5.m5.1.1.3.cmml" xref="S3.SS0.SSS0.Px5.p1.5.m5.1.1.3">
          ℒ
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px5.p1.5.m5.1c">
        \mathcal{SL}
       </annotation>
      </semantics>
     </math>
     . In contrast to the LLM-based planner, which predominantly depends on the reasoning prowess of LLMs, the LLM-based executor is tasked with active engagement within the environment and acquiring an understanding of the environment dynamics (for instance, in ALFRED, objects can be cleaned by placing them into a sink basin and toggling on the faucet) from the feedback. To this end, inspired by ReAct
     <cite class="ltx_cite ltx_citemacro_cite">
      Yao et al. (
      <a class="ltx_ref" href="#bib.bib46" title="">
       2022
      </a>
      )
     </cite>
     , we prompt the LLM-based executor (a
     <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px5.p1.15.1">
      GPT-4
     </span>
     model) to generate both reasoning traces and action plans (composed of skills in
     <math alttext="\mathcal{SL}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px5.p1.6.m6.1">
      <semantics id="S3.SS0.SSS0.Px5.p1.6.m6.1a">
       <mrow id="S3.SS0.SSS0.Px5.p1.6.m6.1.1" xref="S3.SS0.SSS0.Px5.p1.6.m6.1.1.cmml">
        <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px5.p1.6.m6.1.1.2" xref="S3.SS0.SSS0.Px5.p1.6.m6.1.1.2.cmml">
         𝒮
        </mi>
        <mo id="S3.SS0.SSS0.Px5.p1.6.m6.1.1.1" lspace="0em" rspace="0em" xref="S3.SS0.SSS0.Px5.p1.6.m6.1.1.1.cmml">
         ​
        </mo>
        <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px5.p1.6.m6.1.1.3" xref="S3.SS0.SSS0.Px5.p1.6.m6.1.1.3.cmml">
         ℒ
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px5.p1.6.m6.1b">
        <apply id="S3.SS0.SSS0.Px5.p1.6.m6.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.6.m6.1.1">
         <times id="S3.SS0.SSS0.Px5.p1.6.m6.1.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.6.m6.1.1.1">
         </times>
         <ci id="S3.SS0.SSS0.Px5.p1.6.m6.1.1.2.cmml" xref="S3.SS0.SSS0.Px5.p1.6.m6.1.1.2">
          𝒮
         </ci>
         <ci id="S3.SS0.SSS0.Px5.p1.6.m6.1.1.3.cmml" xref="S3.SS0.SSS0.Px5.p1.6.m6.1.1.3">
          ℒ
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px5.p1.6.m6.1c">
        \mathcal{SL}
       </annotation>
      </semantics>
     </math>
     ), allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with and gather additional information from the environment.
The input for LLM-based Executor’s prompt template is generally composed of the language-based observation
     <math alttext="O_{t}^{L}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px5.p1.7.m7.1">
      <semantics id="S3.SS0.SSS0.Px5.p1.7.m7.1a">
       <msubsup id="S3.SS0.SSS0.Px5.p1.7.m7.1.1" xref="S3.SS0.SSS0.Px5.p1.7.m7.1.1.cmml">
        <mi id="S3.SS0.SSS0.Px5.p1.7.m7.1.1.2.2" xref="S3.SS0.SSS0.Px5.p1.7.m7.1.1.2.2.cmml">
         O
        </mi>
        <mi id="S3.SS0.SSS0.Px5.p1.7.m7.1.1.2.3" xref="S3.SS0.SSS0.Px5.p1.7.m7.1.1.2.3.cmml">
         t
        </mi>
        <mi id="S3.SS0.SSS0.Px5.p1.7.m7.1.1.3" xref="S3.SS0.SSS0.Px5.p1.7.m7.1.1.3.cmml">
         L
        </mi>
       </msubsup>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px5.p1.7.m7.1b">
        <apply id="S3.SS0.SSS0.Px5.p1.7.m7.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.7.m7.1.1">
         <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px5.p1.7.m7.1.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.7.m7.1.1">
          superscript
         </csymbol>
         <apply id="S3.SS0.SSS0.Px5.p1.7.m7.1.1.2.cmml" xref="S3.SS0.SSS0.Px5.p1.7.m7.1.1">
          <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px5.p1.7.m7.1.1.2.1.cmml" xref="S3.SS0.SSS0.Px5.p1.7.m7.1.1">
           subscript
          </csymbol>
          <ci id="S3.SS0.SSS0.Px5.p1.7.m7.1.1.2.2.cmml" xref="S3.SS0.SSS0.Px5.p1.7.m7.1.1.2.2">
           𝑂
          </ci>
          <ci id="S3.SS0.SSS0.Px5.p1.7.m7.1.1.2.3.cmml" xref="S3.SS0.SSS0.Px5.p1.7.m7.1.1.2.3">
           𝑡
          </ci>
         </apply>
         <ci id="S3.SS0.SSS0.Px5.p1.7.m7.1.1.3.cmml" xref="S3.SS0.SSS0.Px5.p1.7.m7.1.1.3">
          𝐿
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px5.p1.7.m7.1c">
        O_{t}^{L}
       </annotation>
      </semantics>
     </math>
     , found objects, objects detected in the current view, short-term memory of the action plan for the current subtask, which is cleared once the current subtask is finished, and the current subtask
     <math alttext="S_{i}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px5.p1.8.m8.1">
      <semantics id="S3.SS0.SSS0.Px5.p1.8.m8.1a">
       <msub id="S3.SS0.SSS0.Px5.p1.8.m8.1.1" xref="S3.SS0.SSS0.Px5.p1.8.m8.1.1.cmml">
        <mi id="S3.SS0.SSS0.Px5.p1.8.m8.1.1.2" xref="S3.SS0.SSS0.Px5.p1.8.m8.1.1.2.cmml">
         S
        </mi>
        <mi id="S3.SS0.SSS0.Px5.p1.8.m8.1.1.3" xref="S3.SS0.SSS0.Px5.p1.8.m8.1.1.3.cmml">
         i
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px5.p1.8.m8.1b">
        <apply id="S3.SS0.SSS0.Px5.p1.8.m8.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.8.m8.1.1">
         <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px5.p1.8.m8.1.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.8.m8.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS0.SSS0.Px5.p1.8.m8.1.1.2.cmml" xref="S3.SS0.SSS0.Px5.p1.8.m8.1.1.2">
          𝑆
         </ci>
         <ci id="S3.SS0.SSS0.Px5.p1.8.m8.1.1.3.cmml" xref="S3.SS0.SSS0.Px5.p1.8.m8.1.1.3">
          𝑖
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px5.p1.8.m8.1c">
        S_{i}
       </annotation>
      </semantics>
     </math>
     . The LLM-based executor is required to generate both the reasoning traces (the “Thought” part in the Executor’s output) and the action plans. The action space of the LLM-based executor is {
     <em class="ltx_emph ltx_font_italic" id="S3.SS0.SSS0.Px5.p1.15.2">
      Play
     </em>
     ,
     <em class="ltx_emph ltx_font_italic" id="S3.SS0.SSS0.Px5.p1.15.3">
      Finish
     </em>
     }, where the action
     <em class="ltx_emph ltx_font_italic" id="S3.SS0.SSS0.Px5.p1.15.4">
      Play
     </em>
     is utilized to interact with the environment or request re-planning of the current plan
     <math alttext="S" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px5.p1.9.m9.1">
      <semantics id="S3.SS0.SSS0.Px5.p1.9.m9.1a">
       <mi id="S3.SS0.SSS0.Px5.p1.9.m9.1.1" xref="S3.SS0.SSS0.Px5.p1.9.m9.1.1.cmml">
        S
       </mi>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px5.p1.9.m9.1b">
        <ci id="S3.SS0.SSS0.Px5.p1.9.m9.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.9.m9.1.1">
         𝑆
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px5.p1.9.m9.1c">
        S
       </annotation>
      </semantics>
     </math>
     , and the action
     <em class="ltx_emph ltx_font_italic" id="S3.SS0.SSS0.Px5.p1.15.5">
      Finish
     </em>
     is used for finishing the action planning for the current subtask
     <math alttext="S_{i}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px5.p1.10.m10.1">
      <semantics id="S3.SS0.SSS0.Px5.p1.10.m10.1a">
       <msub id="S3.SS0.SSS0.Px5.p1.10.m10.1.1" xref="S3.SS0.SSS0.Px5.p1.10.m10.1.1.cmml">
        <mi id="S3.SS0.SSS0.Px5.p1.10.m10.1.1.2" xref="S3.SS0.SSS0.Px5.p1.10.m10.1.1.2.cmml">
         S
        </mi>
        <mi id="S3.SS0.SSS0.Px5.p1.10.m10.1.1.3" xref="S3.SS0.SSS0.Px5.p1.10.m10.1.1.3.cmml">
         i
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px5.p1.10.m10.1b">
        <apply id="S3.SS0.SSS0.Px5.p1.10.m10.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.10.m10.1.1">
         <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px5.p1.10.m10.1.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.10.m10.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS0.SSS0.Px5.p1.10.m10.1.1.2.cmml" xref="S3.SS0.SSS0.Px5.p1.10.m10.1.1.2">
          𝑆
         </ci>
         <ci id="S3.SS0.SSS0.Px5.p1.10.m10.1.1.3.cmml" xref="S3.SS0.SSS0.Px5.p1.10.m10.1.1.3">
          𝑖
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px5.p1.10.m10.1c">
        S_{i}
       </annotation>
      </semantics>
     </math>
     . The action
     <em class="ltx_emph ltx_font_italic" id="S3.SS0.SSS0.Px5.p1.15.6">
      Play
     </em>
     receives two arguments as the inputs: [
     <math alttext="\mathcal{SL}_{i}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px5.p1.11.m11.1">
      <semantics id="S3.SS0.SSS0.Px5.p1.11.m11.1a">
       <mrow id="S3.SS0.SSS0.Px5.p1.11.m11.1.1" xref="S3.SS0.SSS0.Px5.p1.11.m11.1.1.cmml">
        <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px5.p1.11.m11.1.1.2" xref="S3.SS0.SSS0.Px5.p1.11.m11.1.1.2.cmml">
         𝒮
        </mi>
        <mo id="S3.SS0.SSS0.Px5.p1.11.m11.1.1.1" lspace="0em" rspace="0em" xref="S3.SS0.SSS0.Px5.p1.11.m11.1.1.1.cmml">
         ​
        </mo>
        <msub id="S3.SS0.SSS0.Px5.p1.11.m11.1.1.3" xref="S3.SS0.SSS0.Px5.p1.11.m11.1.1.3.cmml">
         <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px5.p1.11.m11.1.1.3.2" xref="S3.SS0.SSS0.Px5.p1.11.m11.1.1.3.2.cmml">
          ℒ
         </mi>
         <mi id="S3.SS0.SSS0.Px5.p1.11.m11.1.1.3.3" xref="S3.SS0.SSS0.Px5.p1.11.m11.1.1.3.3.cmml">
          i
         </mi>
        </msub>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px5.p1.11.m11.1b">
        <apply id="S3.SS0.SSS0.Px5.p1.11.m11.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.11.m11.1.1">
         <times id="S3.SS0.SSS0.Px5.p1.11.m11.1.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.11.m11.1.1.1">
         </times>
         <ci id="S3.SS0.SSS0.Px5.p1.11.m11.1.1.2.cmml" xref="S3.SS0.SSS0.Px5.p1.11.m11.1.1.2">
          𝒮
         </ci>
         <apply id="S3.SS0.SSS0.Px5.p1.11.m11.1.1.3.cmml" xref="S3.SS0.SSS0.Px5.p1.11.m11.1.1.3">
          <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px5.p1.11.m11.1.1.3.1.cmml" xref="S3.SS0.SSS0.Px5.p1.11.m11.1.1.3">
           subscript
          </csymbol>
          <ci id="S3.SS0.SSS0.Px5.p1.11.m11.1.1.3.2.cmml" xref="S3.SS0.SSS0.Px5.p1.11.m11.1.1.3.2">
           ℒ
          </ci>
          <ci id="S3.SS0.SSS0.Px5.p1.11.m11.1.1.3.3.cmml" xref="S3.SS0.SSS0.Px5.p1.11.m11.1.1.3.3">
           𝑖
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px5.p1.11.m11.1c">
        \mathcal{SL}_{i}
       </annotation>
      </semantics>
     </math>
     ,
     <math alttext="\mathcal{ST}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px5.p1.12.m12.1">
      <semantics id="S3.SS0.SSS0.Px5.p1.12.m12.1a">
       <mrow id="S3.SS0.SSS0.Px5.p1.12.m12.1.1" xref="S3.SS0.SSS0.Px5.p1.12.m12.1.1.cmml">
        <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px5.p1.12.m12.1.1.2" xref="S3.SS0.SSS0.Px5.p1.12.m12.1.1.2.cmml">
         𝒮
        </mi>
        <mo id="S3.SS0.SSS0.Px5.p1.12.m12.1.1.1" lspace="0em" rspace="0em" xref="S3.SS0.SSS0.Px5.p1.12.m12.1.1.1.cmml">
         ​
        </mo>
        <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px5.p1.12.m12.1.1.3" xref="S3.SS0.SSS0.Px5.p1.12.m12.1.1.3.cmml">
         𝒯
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px5.p1.12.m12.1b">
        <apply id="S3.SS0.SSS0.Px5.p1.12.m12.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.12.m12.1.1">
         <times id="S3.SS0.SSS0.Px5.p1.12.m12.1.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.12.m12.1.1.1">
         </times>
         <ci id="S3.SS0.SSS0.Px5.p1.12.m12.1.1.2.cmml" xref="S3.SS0.SSS0.Px5.p1.12.m12.1.1.2">
          𝒮
         </ci>
         <ci id="S3.SS0.SSS0.Px5.p1.12.m12.1.1.3.cmml" xref="S3.SS0.SSS0.Px5.p1.12.m12.1.1.3">
          𝒯
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px5.p1.12.m12.1c">
        \mathcal{ST}
       </annotation>
      </semantics>
     </math>
     ] (e.g., Play[
     <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px5.p1.15.7">
      NavigateToObject
     </span>
     ,
     <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px5.p1.15.8">
      Table
     </span>
     ]), where
     <math alttext="\mathcal{SL}_{i}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px5.p1.13.m13.1">
      <semantics id="S3.SS0.SSS0.Px5.p1.13.m13.1a">
       <mrow id="S3.SS0.SSS0.Px5.p1.13.m13.1.1" xref="S3.SS0.SSS0.Px5.p1.13.m13.1.1.cmml">
        <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px5.p1.13.m13.1.1.2" xref="S3.SS0.SSS0.Px5.p1.13.m13.1.1.2.cmml">
         𝒮
        </mi>
        <mo id="S3.SS0.SSS0.Px5.p1.13.m13.1.1.1" lspace="0em" rspace="0em" xref="S3.SS0.SSS0.Px5.p1.13.m13.1.1.1.cmml">
         ​
        </mo>
        <msub id="S3.SS0.SSS0.Px5.p1.13.m13.1.1.3" xref="S3.SS0.SSS0.Px5.p1.13.m13.1.1.3.cmml">
         <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px5.p1.13.m13.1.1.3.2" xref="S3.SS0.SSS0.Px5.p1.13.m13.1.1.3.2.cmml">
          ℒ
         </mi>
         <mi id="S3.SS0.SSS0.Px5.p1.13.m13.1.1.3.3" xref="S3.SS0.SSS0.Px5.p1.13.m13.1.1.3.3.cmml">
          i
         </mi>
        </msub>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px5.p1.13.m13.1b">
        <apply id="S3.SS0.SSS0.Px5.p1.13.m13.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.13.m13.1.1">
         <times id="S3.SS0.SSS0.Px5.p1.13.m13.1.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.13.m13.1.1.1">
         </times>
         <ci id="S3.SS0.SSS0.Px5.p1.13.m13.1.1.2.cmml" xref="S3.SS0.SSS0.Px5.p1.13.m13.1.1.2">
          𝒮
         </ci>
         <apply id="S3.SS0.SSS0.Px5.p1.13.m13.1.1.3.cmml" xref="S3.SS0.SSS0.Px5.p1.13.m13.1.1.3">
          <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px5.p1.13.m13.1.1.3.1.cmml" xref="S3.SS0.SSS0.Px5.p1.13.m13.1.1.3">
           subscript
          </csymbol>
          <ci id="S3.SS0.SSS0.Px5.p1.13.m13.1.1.3.2.cmml" xref="S3.SS0.SSS0.Px5.p1.13.m13.1.1.3.2">
           ℒ
          </ci>
          <ci id="S3.SS0.SSS0.Px5.p1.13.m13.1.1.3.3.cmml" xref="S3.SS0.SSS0.Px5.p1.13.m13.1.1.3.3">
           𝑖
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px5.p1.13.m13.1c">
        \mathcal{SL}_{i}
       </annotation>
      </semantics>
     </math>
     is the pre-defined skills in the skill library, and
     <math alttext="\mathcal{ST}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px5.p1.14.m14.1">
      <semantics id="S3.SS0.SSS0.Px5.p1.14.m14.1a">
       <mrow id="S3.SS0.SSS0.Px5.p1.14.m14.1.1" xref="S3.SS0.SSS0.Px5.p1.14.m14.1.1.cmml">
        <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px5.p1.14.m14.1.1.2" xref="S3.SS0.SSS0.Px5.p1.14.m14.1.1.2.cmml">
         𝒮
        </mi>
        <mo id="S3.SS0.SSS0.Px5.p1.14.m14.1.1.1" lspace="0em" rspace="0em" xref="S3.SS0.SSS0.Px5.p1.14.m14.1.1.1.cmml">
         ​
        </mo>
        <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px5.p1.14.m14.1.1.3" xref="S3.SS0.SSS0.Px5.p1.14.m14.1.1.3.cmml">
         𝒯
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px5.p1.14.m14.1b">
        <apply id="S3.SS0.SSS0.Px5.p1.14.m14.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.14.m14.1.1">
         <times id="S3.SS0.SSS0.Px5.p1.14.m14.1.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.14.m14.1.1.1">
         </times>
         <ci id="S3.SS0.SSS0.Px5.p1.14.m14.1.1.2.cmml" xref="S3.SS0.SSS0.Px5.p1.14.m14.1.1.2">
          𝒮
         </ci>
         <ci id="S3.SS0.SSS0.Px5.p1.14.m14.1.1.3.cmml" xref="S3.SS0.SSS0.Px5.p1.14.m14.1.1.3">
          𝒯
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px5.p1.14.m14.1c">
        \mathcal{ST}
       </annotation>
      </semantics>
     </math>
     is the target argument of the corresponding skill action
     <math alttext="\mathcal{SL}_{i}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px5.p1.15.m15.1">
      <semantics id="S3.SS0.SSS0.Px5.p1.15.m15.1a">
       <mrow id="S3.SS0.SSS0.Px5.p1.15.m15.1.1" xref="S3.SS0.SSS0.Px5.p1.15.m15.1.1.cmml">
        <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px5.p1.15.m15.1.1.2" xref="S3.SS0.SSS0.Px5.p1.15.m15.1.1.2.cmml">
         𝒮
        </mi>
        <mo id="S3.SS0.SSS0.Px5.p1.15.m15.1.1.1" lspace="0em" rspace="0em" xref="S3.SS0.SSS0.Px5.p1.15.m15.1.1.1.cmml">
         ​
        </mo>
        <msub id="S3.SS0.SSS0.Px5.p1.15.m15.1.1.3" xref="S3.SS0.SSS0.Px5.p1.15.m15.1.1.3.cmml">
         <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px5.p1.15.m15.1.1.3.2" xref="S3.SS0.SSS0.Px5.p1.15.m15.1.1.3.2.cmml">
          ℒ
         </mi>
         <mi id="S3.SS0.SSS0.Px5.p1.15.m15.1.1.3.3" xref="S3.SS0.SSS0.Px5.p1.15.m15.1.1.3.3.cmml">
          i
         </mi>
        </msub>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px5.p1.15.m15.1b">
        <apply id="S3.SS0.SSS0.Px5.p1.15.m15.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.15.m15.1.1">
         <times id="S3.SS0.SSS0.Px5.p1.15.m15.1.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.15.m15.1.1.1">
         </times>
         <ci id="S3.SS0.SSS0.Px5.p1.15.m15.1.1.2.cmml" xref="S3.SS0.SSS0.Px5.p1.15.m15.1.1.2">
          𝒮
         </ci>
         <apply id="S3.SS0.SSS0.Px5.p1.15.m15.1.1.3.cmml" xref="S3.SS0.SSS0.Px5.p1.15.m15.1.1.3">
          <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px5.p1.15.m15.1.1.3.1.cmml" xref="S3.SS0.SSS0.Px5.p1.15.m15.1.1.3">
           subscript
          </csymbol>
          <ci id="S3.SS0.SSS0.Px5.p1.15.m15.1.1.3.2.cmml" xref="S3.SS0.SSS0.Px5.p1.15.m15.1.1.3.2">
           ℒ
          </ci>
          <ci id="S3.SS0.SSS0.Px5.p1.15.m15.1.1.3.3.cmml" xref="S3.SS0.SSS0.Px5.p1.15.m15.1.1.3.3">
           𝑖
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px5.p1.15.m15.1c">
        \mathcal{SL}_{i}
       </annotation>
      </semantics>
     </math>
     .
    </p>
   </div>
  </section>
  <section class="ltx_paragraph" id="S3.SS0.SSS0.Px6">
   <h4 class="ltx_title ltx_title_paragraph">
    Skill Library
   </h4>
   <div class="ltx_para" id="S3.SS0.SSS0.Px6.p1">
    <p class="ltx_p" id="S3.SS0.SSS0.Px6.p1.2">
     We design a skill library to empower the LLM-based executor with the following capabilities: (1) reasoning over language to track progress, handle exceptions or adjust the plan according to the situation; (2) acting to support the reasoning and collect information about the environment dynamics by controlling the agent. Apart from all the interaction actions
     <math alttext="A_{I}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px6.p1.1.m1.1">
      <semantics id="S3.SS0.SSS0.Px6.p1.1.m1.1a">
       <msub id="S3.SS0.SSS0.Px6.p1.1.m1.1.1" xref="S3.SS0.SSS0.Px6.p1.1.m1.1.1.cmml">
        <mi id="S3.SS0.SSS0.Px6.p1.1.m1.1.1.2" xref="S3.SS0.SSS0.Px6.p1.1.m1.1.1.2.cmml">
         A
        </mi>
        <mi id="S3.SS0.SSS0.Px6.p1.1.m1.1.1.3" xref="S3.SS0.SSS0.Px6.p1.1.m1.1.1.3.cmml">
         I
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px6.p1.1.m1.1b">
        <apply id="S3.SS0.SSS0.Px6.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px6.p1.1.m1.1.1">
         <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px6.p1.1.m1.1.1.1.cmml" xref="S3.SS0.SSS0.Px6.p1.1.m1.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS0.SSS0.Px6.p1.1.m1.1.1.2.cmml" xref="S3.SS0.SSS0.Px6.p1.1.m1.1.1.2">
          𝐴
         </ci>
         <ci id="S3.SS0.SSS0.Px6.p1.1.m1.1.1.3.cmml" xref="S3.SS0.SSS0.Px6.p1.1.m1.1.1.3">
          𝐼
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px6.p1.1.m1.1c">
        A_{I}
       </annotation>
      </semantics>
     </math>
     , we have designed several additional skills, including
     <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px6.p1.2.1">
      NavigateToObject
     </span>
     ,
     <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px6.p1.2.2">
      Explore
     </span>
     ,
     <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px6.p1.2.3">
      LookAround
     </span>
     , and
     <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px6.p1.2.4">
      RequireReplan
     </span>
     . The
     <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px6.p1.2.5">
      NavigateToObject
     </span>
     skill empowers the LLM-based executor with the capability to set the landmark-based navigation goal, it takes a found object in the room as the skill action target
     <math alttext="\mathcal{ST}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px6.p1.2.m2.1">
      <semantics id="S3.SS0.SSS0.Px6.p1.2.m2.1a">
       <mrow id="S3.SS0.SSS0.Px6.p1.2.m2.1.1" xref="S3.SS0.SSS0.Px6.p1.2.m2.1.1.cmml">
        <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px6.p1.2.m2.1.1.2" xref="S3.SS0.SSS0.Px6.p1.2.m2.1.1.2.cmml">
         𝒮
        </mi>
        <mo id="S3.SS0.SSS0.Px6.p1.2.m2.1.1.1" lspace="0em" rspace="0em" xref="S3.SS0.SSS0.Px6.p1.2.m2.1.1.1.cmml">
         ​
        </mo>
        <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px6.p1.2.m2.1.1.3" xref="S3.SS0.SSS0.Px6.p1.2.m2.1.1.3.cmml">
         𝒯
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px6.p1.2.m2.1b">
        <apply id="S3.SS0.SSS0.Px6.p1.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px6.p1.2.m2.1.1">
         <times id="S3.SS0.SSS0.Px6.p1.2.m2.1.1.1.cmml" xref="S3.SS0.SSS0.Px6.p1.2.m2.1.1.1">
         </times>
         <ci id="S3.SS0.SSS0.Px6.p1.2.m2.1.1.2.cmml" xref="S3.SS0.SSS0.Px6.p1.2.m2.1.1.2">
          𝒮
         </ci>
         <ci id="S3.SS0.SSS0.Px6.p1.2.m2.1.1.3.cmml" xref="S3.SS0.SSS0.Px6.p1.2.m2.1.1.3">
          𝒯
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px6.p1.2.m2.1c">
        \mathcal{ST}
       </annotation>
      </semantics>
     </math>
     . The
     <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px6.p1.2.6">
      Explore
     </span>
     skill enhances the LLM-based executor’s ability to guide the agent in room exploration by sampling navigation goals from traversable areas, and it requires no skill action target. It is worth noting that we have an initial exploration heuristic for the first four calls of the
     <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px6.p1.2.7">
      Explore
     </span>
     skill, we set the four corners of the room with a higher exploration priority. The
     <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px6.p1.2.8">
      RequireReplan
     </span>
     provides the LLM-based executor with the capability to dynamically adjust the plan, improving the robustness to exceptions and producing more probability for it to learn from the environment dynamics. The
     <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px6.p1.2.9">
      LookAround
     </span>
     skill enables the LLM-based executor to manipulate the agent to look around the environment to get a more comprehensive observation of the room.
    </p>
   </div>
  </section>
  <section class="ltx_paragraph" id="S3.SS0.SSS0.Px7">
   <h4 class="ltx_title ltx_title_paragraph">
    Deterministic Action Policy
   </h4>
   <div class="ltx_para" id="S3.SS0.SSS0.Px7.p1">
    <p class="ltx_p" id="S3.SS0.SSS0.Px7.p1.7">
     Given the current instruction specified by the action plan [
     <math alttext="\mathcal{SL}_{i}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px7.p1.1.m1.1">
      <semantics id="S3.SS0.SSS0.Px7.p1.1.m1.1a">
       <mrow id="S3.SS0.SSS0.Px7.p1.1.m1.1.1" xref="S3.SS0.SSS0.Px7.p1.1.m1.1.1.cmml">
        <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px7.p1.1.m1.1.1.2" xref="S3.SS0.SSS0.Px7.p1.1.m1.1.1.2.cmml">
         𝒮
        </mi>
        <mo id="S3.SS0.SSS0.Px7.p1.1.m1.1.1.1" lspace="0em" rspace="0em" xref="S3.SS0.SSS0.Px7.p1.1.m1.1.1.1.cmml">
         ​
        </mo>
        <msub id="S3.SS0.SSS0.Px7.p1.1.m1.1.1.3" xref="S3.SS0.SSS0.Px7.p1.1.m1.1.1.3.cmml">
         <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px7.p1.1.m1.1.1.3.2" xref="S3.SS0.SSS0.Px7.p1.1.m1.1.1.3.2.cmml">
          ℒ
         </mi>
         <mi id="S3.SS0.SSS0.Px7.p1.1.m1.1.1.3.3" xref="S3.SS0.SSS0.Px7.p1.1.m1.1.1.3.3.cmml">
          i
         </mi>
        </msub>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px7.p1.1.m1.1b">
        <apply id="S3.SS0.SSS0.Px7.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px7.p1.1.m1.1.1">
         <times id="S3.SS0.SSS0.Px7.p1.1.m1.1.1.1.cmml" xref="S3.SS0.SSS0.Px7.p1.1.m1.1.1.1">
         </times>
         <ci id="S3.SS0.SSS0.Px7.p1.1.m1.1.1.2.cmml" xref="S3.SS0.SSS0.Px7.p1.1.m1.1.1.2">
          𝒮
         </ci>
         <apply id="S3.SS0.SSS0.Px7.p1.1.m1.1.1.3.cmml" xref="S3.SS0.SSS0.Px7.p1.1.m1.1.1.3">
          <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px7.p1.1.m1.1.1.3.1.cmml" xref="S3.SS0.SSS0.Px7.p1.1.m1.1.1.3">
           subscript
          </csymbol>
          <ci id="S3.SS0.SSS0.Px7.p1.1.m1.1.1.3.2.cmml" xref="S3.SS0.SSS0.Px7.p1.1.m1.1.1.3.2">
           ℒ
          </ci>
          <ci id="S3.SS0.SSS0.Px7.p1.1.m1.1.1.3.3.cmml" xref="S3.SS0.SSS0.Px7.p1.1.m1.1.1.3.3">
           𝑖
          </ci>
         </apply>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px7.p1.1.m1.1c">
        \mathcal{SL}_{i}
       </annotation>
      </semantics>
     </math>
     <math alttext="\mathcal{ST}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px7.p1.2.m2.1">
      <semantics id="S3.SS0.SSS0.Px7.p1.2.m2.1a">
       <mrow id="S3.SS0.SSS0.Px7.p1.2.m2.1.1" xref="S3.SS0.SSS0.Px7.p1.2.m2.1.1.cmml">
        <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px7.p1.2.m2.1.1.2" xref="S3.SS0.SSS0.Px7.p1.2.m2.1.1.2.cmml">
         𝒮
        </mi>
        <mo id="S3.SS0.SSS0.Px7.p1.2.m2.1.1.1" lspace="0em" rspace="0em" xref="S3.SS0.SSS0.Px7.p1.2.m2.1.1.1.cmml">
         ​
        </mo>
        <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px7.p1.2.m2.1.1.3" xref="S3.SS0.SSS0.Px7.p1.2.m2.1.1.3.cmml">
         𝒯
        </mi>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px7.p1.2.m2.1b">
        <apply id="S3.SS0.SSS0.Px7.p1.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px7.p1.2.m2.1.1">
         <times id="S3.SS0.SSS0.Px7.p1.2.m2.1.1.1.cmml" xref="S3.SS0.SSS0.Px7.p1.2.m2.1.1.1">
         </times>
         <ci id="S3.SS0.SSS0.Px7.p1.2.m2.1.1.2.cmml" xref="S3.SS0.SSS0.Px7.p1.2.m2.1.1.2">
          𝒮
         </ci>
         <ci id="S3.SS0.SSS0.Px7.p1.2.m2.1.1.3.cmml" xref="S3.SS0.SSS0.Px7.p1.2.m2.1.1.3">
          𝒯
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px7.p1.2.m2.1c">
        \mathcal{ST}
       </annotation>
      </semantics>
     </math>
     ] from the LLM-based executor, the deterministic action policy of OPEx outputs a navigation or interaction action based on a set of heuristics, which is quite similar to that of FILM. Both policies generally follow the following procedure: if the target object is observed in the semantic map, the closest instance is selected as the final navigation goal. Otherwise, the final navigation goal is set as the exploration navigation goal.
After goal determination, the agent employs the Fast Marching Method
     <cite class="ltx_cite ltx_citemacro_cite">
      Sethian (
      <a class="ltx_ref" href="#bib.bib30" title="">
       1996
      </a>
      )
     </cite>
     to navigate towards the navigation goal. Additionally, when the target object is within the agent’s egocentric visual range, the policy will try to conduct the interaction or adjust the position to prepare for the interaction action. The deterministic action policy of OPEx mainly differs from that of FILM in three aspects. Firstly, the deterministic action policy of OPEx is equipped with a slice replay heuristic, which tracks the location of successful execution of
     <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px7.p1.7.1">
      SliceObject
     </span>
     for easier going back. Secondly, instead of directly setting the location of the target object as the navigation goal, we sample a traversable location based on the distance to the target object as the navigation goal (noted as “traversable goal heuristic”). Thirdly, instead of directly utilizing the semantic map
     <math alttext="M_{t}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px7.p1.3.m3.1">
      <semantics id="S3.SS0.SSS0.Px7.p1.3.m3.1a">
       <msub id="S3.SS0.SSS0.Px7.p1.3.m3.1.1" xref="S3.SS0.SSS0.Px7.p1.3.m3.1.1.cmml">
        <mi id="S3.SS0.SSS0.Px7.p1.3.m3.1.1.2" xref="S3.SS0.SSS0.Px7.p1.3.m3.1.1.2.cmml">
         M
        </mi>
        <mi id="S3.SS0.SSS0.Px7.p1.3.m3.1.1.3" xref="S3.SS0.SSS0.Px7.p1.3.m3.1.1.3.cmml">
         t
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px7.p1.3.m3.1b">
        <apply id="S3.SS0.SSS0.Px7.p1.3.m3.1.1.cmml" xref="S3.SS0.SSS0.Px7.p1.3.m3.1.1">
         <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px7.p1.3.m3.1.1.1.cmml" xref="S3.SS0.SSS0.Px7.p1.3.m3.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS0.SSS0.Px7.p1.3.m3.1.1.2.cmml" xref="S3.SS0.SSS0.Px7.p1.3.m3.1.1.2">
          𝑀
         </ci>
         <ci id="S3.SS0.SSS0.Px7.p1.3.m3.1.1.3.cmml" xref="S3.SS0.SSS0.Px7.p1.3.m3.1.1.3">
          𝑡
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px7.p1.3.m3.1c">
        M_{t}
       </annotation>
      </semantics>
     </math>
     to determine whether the target object is found and get the navigation goal for that object, we adopt the additional semantic map
     <math alttext="M_{t}^{\prime}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px7.p1.4.m4.1">
      <semantics id="S3.SS0.SSS0.Px7.p1.4.m4.1a">
       <msubsup id="S3.SS0.SSS0.Px7.p1.4.m4.1.1" xref="S3.SS0.SSS0.Px7.p1.4.m4.1.1.cmml">
        <mi id="S3.SS0.SSS0.Px7.p1.4.m4.1.1.2.2" xref="S3.SS0.SSS0.Px7.p1.4.m4.1.1.2.2.cmml">
         M
        </mi>
        <mi id="S3.SS0.SSS0.Px7.p1.4.m4.1.1.2.3" xref="S3.SS0.SSS0.Px7.p1.4.m4.1.1.2.3.cmml">
         t
        </mi>
        <mo id="S3.SS0.SSS0.Px7.p1.4.m4.1.1.3" xref="S3.SS0.SSS0.Px7.p1.4.m4.1.1.3.cmml">
         ′
        </mo>
       </msubsup>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px7.p1.4.m4.1b">
        <apply id="S3.SS0.SSS0.Px7.p1.4.m4.1.1.cmml" xref="S3.SS0.SSS0.Px7.p1.4.m4.1.1">
         <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px7.p1.4.m4.1.1.1.cmml" xref="S3.SS0.SSS0.Px7.p1.4.m4.1.1">
          superscript
         </csymbol>
         <apply id="S3.SS0.SSS0.Px7.p1.4.m4.1.1.2.cmml" xref="S3.SS0.SSS0.Px7.p1.4.m4.1.1">
          <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px7.p1.4.m4.1.1.2.1.cmml" xref="S3.SS0.SSS0.Px7.p1.4.m4.1.1">
           subscript
          </csymbol>
          <ci id="S3.SS0.SSS0.Px7.p1.4.m4.1.1.2.2.cmml" xref="S3.SS0.SSS0.Px7.p1.4.m4.1.1.2.2">
           𝑀
          </ci>
          <ci id="S3.SS0.SSS0.Px7.p1.4.m4.1.1.2.3.cmml" xref="S3.SS0.SSS0.Px7.p1.4.m4.1.1.2.3">
           𝑡
          </ci>
         </apply>
         <ci id="S3.SS0.SSS0.Px7.p1.4.m4.1.1.3.cmml" xref="S3.SS0.SSS0.Px7.p1.4.m4.1.1.3">
          ′
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px7.p1.4.m4.1c">
        M_{t}^{\prime}
       </annotation>
      </semantics>
     </math>
     to achieve this in the first place. If the target is not found in
     <math alttext="M_{t}^{\prime}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px7.p1.5.m5.1">
      <semantics id="S3.SS0.SSS0.Px7.p1.5.m5.1a">
       <msubsup id="S3.SS0.SSS0.Px7.p1.5.m5.1.1" xref="S3.SS0.SSS0.Px7.p1.5.m5.1.1.cmml">
        <mi id="S3.SS0.SSS0.Px7.p1.5.m5.1.1.2.2" xref="S3.SS0.SSS0.Px7.p1.5.m5.1.1.2.2.cmml">
         M
        </mi>
        <mi id="S3.SS0.SSS0.Px7.p1.5.m5.1.1.2.3" xref="S3.SS0.SSS0.Px7.p1.5.m5.1.1.2.3.cmml">
         t
        </mi>
        <mo id="S3.SS0.SSS0.Px7.p1.5.m5.1.1.3" xref="S3.SS0.SSS0.Px7.p1.5.m5.1.1.3.cmml">
         ′
        </mo>
       </msubsup>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px7.p1.5.m5.1b">
        <apply id="S3.SS0.SSS0.Px7.p1.5.m5.1.1.cmml" xref="S3.SS0.SSS0.Px7.p1.5.m5.1.1">
         <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px7.p1.5.m5.1.1.1.cmml" xref="S3.SS0.SSS0.Px7.p1.5.m5.1.1">
          superscript
         </csymbol>
         <apply id="S3.SS0.SSS0.Px7.p1.5.m5.1.1.2.cmml" xref="S3.SS0.SSS0.Px7.p1.5.m5.1.1">
          <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px7.p1.5.m5.1.1.2.1.cmml" xref="S3.SS0.SSS0.Px7.p1.5.m5.1.1">
           subscript
          </csymbol>
          <ci id="S3.SS0.SSS0.Px7.p1.5.m5.1.1.2.2.cmml" xref="S3.SS0.SSS0.Px7.p1.5.m5.1.1.2.2">
           𝑀
          </ci>
          <ci id="S3.SS0.SSS0.Px7.p1.5.m5.1.1.2.3.cmml" xref="S3.SS0.SSS0.Px7.p1.5.m5.1.1.2.3">
           𝑡
          </ci>
         </apply>
         <ci id="S3.SS0.SSS0.Px7.p1.5.m5.1.1.3.cmml" xref="S3.SS0.SSS0.Px7.p1.5.m5.1.1.3">
          ′
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px7.p1.5.m5.1c">
        M_{t}^{\prime}
       </annotation>
      </semantics>
     </math>
     , the original semantic map
     <math alttext="M_{t}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px7.p1.6.m6.1">
      <semantics id="S3.SS0.SSS0.Px7.p1.6.m6.1a">
       <msub id="S3.SS0.SSS0.Px7.p1.6.m6.1.1" xref="S3.SS0.SSS0.Px7.p1.6.m6.1.1.cmml">
        <mi id="S3.SS0.SSS0.Px7.p1.6.m6.1.1.2" xref="S3.SS0.SSS0.Px7.p1.6.m6.1.1.2.cmml">
         M
        </mi>
        <mi id="S3.SS0.SSS0.Px7.p1.6.m6.1.1.3" xref="S3.SS0.SSS0.Px7.p1.6.m6.1.1.3.cmml">
         t
        </mi>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px7.p1.6.m6.1b">
        <apply id="S3.SS0.SSS0.Px7.p1.6.m6.1.1.cmml" xref="S3.SS0.SSS0.Px7.p1.6.m6.1.1">
         <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px7.p1.6.m6.1.1.1.cmml" xref="S3.SS0.SSS0.Px7.p1.6.m6.1.1">
          subscript
         </csymbol>
         <ci id="S3.SS0.SSS0.Px7.p1.6.m6.1.1.2.cmml" xref="S3.SS0.SSS0.Px7.p1.6.m6.1.1.2">
          𝑀
         </ci>
         <ci id="S3.SS0.SSS0.Px7.p1.6.m6.1.1.3.cmml" xref="S3.SS0.SSS0.Px7.p1.6.m6.1.1.3">
          𝑡
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px7.p1.6.m6.1c">
        M_{t}
       </annotation>
      </semantics>
     </math>
     is then utilized. We prioritize
     <math alttext="M_{t}^{\prime}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px7.p1.7.m7.1">
      <semantics id="S3.SS0.SSS0.Px7.p1.7.m7.1a">
       <msubsup id="S3.SS0.SSS0.Px7.p1.7.m7.1.1" xref="S3.SS0.SSS0.Px7.p1.7.m7.1.1.cmml">
        <mi id="S3.SS0.SSS0.Px7.p1.7.m7.1.1.2.2" xref="S3.SS0.SSS0.Px7.p1.7.m7.1.1.2.2.cmml">
         M
        </mi>
        <mi id="S3.SS0.SSS0.Px7.p1.7.m7.1.1.2.3" xref="S3.SS0.SSS0.Px7.p1.7.m7.1.1.2.3.cmml">
         t
        </mi>
        <mo id="S3.SS0.SSS0.Px7.p1.7.m7.1.1.3" xref="S3.SS0.SSS0.Px7.p1.7.m7.1.1.3.cmml">
         ′
        </mo>
       </msubsup>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px7.p1.7.m7.1b">
        <apply id="S3.SS0.SSS0.Px7.p1.7.m7.1.1.cmml" xref="S3.SS0.SSS0.Px7.p1.7.m7.1.1">
         <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px7.p1.7.m7.1.1.1.cmml" xref="S3.SS0.SSS0.Px7.p1.7.m7.1.1">
          superscript
         </csymbol>
         <apply id="S3.SS0.SSS0.Px7.p1.7.m7.1.1.2.cmml" xref="S3.SS0.SSS0.Px7.p1.7.m7.1.1">
          <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px7.p1.7.m7.1.1.2.1.cmml" xref="S3.SS0.SSS0.Px7.p1.7.m7.1.1">
           subscript
          </csymbol>
          <ci id="S3.SS0.SSS0.Px7.p1.7.m7.1.1.2.2.cmml" xref="S3.SS0.SSS0.Px7.p1.7.m7.1.1.2.2">
           𝑀
          </ci>
          <ci id="S3.SS0.SSS0.Px7.p1.7.m7.1.1.2.3.cmml" xref="S3.SS0.SSS0.Px7.p1.7.m7.1.1.2.3">
           𝑡
          </ci>
         </apply>
         <ci id="S3.SS0.SSS0.Px7.p1.7.m7.1.1.3.cmml" xref="S3.SS0.SSS0.Px7.p1.7.m7.1.1.3">
          ′
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px7.p1.7.m7.1c">
        M_{t}^{\prime}
       </annotation>
      </semantics>
     </math>
     as it is supposed to be more robust to the errors from the perception models.
    </p>
   </div>
  </section>
  <section class="ltx_paragraph" id="S3.SS0.SSS0.Px8">
   <h4 class="ltx_title ltx_title_paragraph">
    Prior Knowledge Integration
   </h4>
   <div class="ltx_para" id="S3.SS0.SSS0.Px8.p1">
    <p class="ltx_p" id="S3.SS0.SSS0.Px8.p1.7">
     Due to the lack of prior knowledge of the specific environment, OPEx frequently fails even on ALFWorld where the impact of perception and action modules are ablated. For instance, OPEx may continuously fail for trying to pick up objects across various episodes due to the lack of the knowledge that agent can not directly hold more than 1 object in ALFRED. Furthermore, a system with a single agent trying to handle planning and grounding simultaneously often struggles to learn the optimal timing for switching between planning and grounding. To bridge the gap, we propose improving OPEx by splitting the reasoning and grounding issues with a multi-agent dialogue strategy and marrying it with the world knowledge, which is obtained from an explorer by interacting with the environment or collecting human contributions. Specifically, we first deploy the agent to explore the ALFWorld environment and collect action-observation sequences
     <math alttext="\{\mathcal{AO}_{i}\}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px8.p1.1.m1.1">
      <semantics id="S3.SS0.SSS0.Px8.p1.1.m1.1a">
       <mrow id="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1" xref="S3.SS0.SSS0.Px8.p1.1.m1.1.1.2.cmml">
        <mo id="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1.2" stretchy="false" xref="S3.SS0.SSS0.Px8.p1.1.m1.1.1.2.cmml">
         {
        </mo>
        <mrow id="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1.1" xref="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1.1.cmml">
         <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1.1.2" xref="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1.1.2.cmml">
          𝒜
         </mi>
         <mo id="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1.1.1" lspace="0em" rspace="0em" xref="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1.1.1.cmml">
          ​
         </mo>
         <msub id="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1.1.3" xref="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1.1.3.cmml">
          <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1.1.3.2" xref="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1.1.3.2.cmml">
           𝒪
          </mi>
          <mi id="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1.1.3.3" xref="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1.1.3.3.cmml">
           i
          </mi>
         </msub>
        </mrow>
        <mo id="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1.3" stretchy="false" xref="S3.SS0.SSS0.Px8.p1.1.m1.1.1.2.cmml">
         }
        </mo>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px8.p1.1.m1.1b">
        <set id="S3.SS0.SSS0.Px8.p1.1.m1.1.1.2.cmml" xref="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1">
         <apply id="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1.1">
          <times id="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1.1.1">
          </times>
          <ci id="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1.1.2.cmml" xref="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1.1.2">
           𝒜
          </ci>
          <apply id="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1.1.3.cmml" xref="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1.1.3">
           <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1.1.3.1.cmml" xref="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1.1.3">
            subscript
           </csymbol>
           <ci id="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1.1.3.2.cmml" xref="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1.1.3.2">
            𝒪
           </ci>
           <ci id="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1.1.3.3.cmml" xref="S3.SS0.SSS0.Px8.p1.1.m1.1.1.1.1.3.3">
            𝑖
           </ci>
          </apply>
         </apply>
        </set>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px8.p1.1.m1.1c">
        \{\mathcal{AO}_{i}\}
       </annotation>
      </semantics>
     </math>
     , where
     <math alttext="\mathcal{AO}_{i}=[\mathcal{L}_{0},a_{0},\mathcal{L}_{1},a_{1},...,\mathcal{L}_{T}]" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px8.p1.2.m2.6">
      <semantics id="S3.SS0.SSS0.Px8.p1.2.m2.6a">
       <mrow id="S3.SS0.SSS0.Px8.p1.2.m2.6.6" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.cmml">
        <mrow id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.7" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.7.cmml">
         <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.7.2" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.7.2.cmml">
          𝒜
         </mi>
         <mo id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.7.1" lspace="0em" rspace="0em" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.7.1.cmml">
          ​
         </mo>
         <msub id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.7.3" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.7.3.cmml">
          <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.7.3.2" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.7.3.2.cmml">
           𝒪
          </mi>
          <mi id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.7.3.3" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.7.3.3.cmml">
           i
          </mi>
         </msub>
        </mrow>
        <mo id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.6" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.6.cmml">
         =
        </mo>
        <mrow id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.5" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.6.cmml">
         <mo id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.5.6" stretchy="false" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.6.cmml">
          [
         </mo>
         <msub id="S3.SS0.SSS0.Px8.p1.2.m2.2.2.1.1.1" xref="S3.SS0.SSS0.Px8.p1.2.m2.2.2.1.1.1.cmml">
          <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px8.p1.2.m2.2.2.1.1.1.2" xref="S3.SS0.SSS0.Px8.p1.2.m2.2.2.1.1.1.2.cmml">
           ℒ
          </mi>
          <mn id="S3.SS0.SSS0.Px8.p1.2.m2.2.2.1.1.1.3" xref="S3.SS0.SSS0.Px8.p1.2.m2.2.2.1.1.1.3.cmml">
           0
          </mn>
         </msub>
         <mo id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.5.7" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.6.cmml">
          ,
         </mo>
         <msub id="S3.SS0.SSS0.Px8.p1.2.m2.3.3.2.2.2" xref="S3.SS0.SSS0.Px8.p1.2.m2.3.3.2.2.2.cmml">
          <mi id="S3.SS0.SSS0.Px8.p1.2.m2.3.3.2.2.2.2" xref="S3.SS0.SSS0.Px8.p1.2.m2.3.3.2.2.2.2.cmml">
           a
          </mi>
          <mn id="S3.SS0.SSS0.Px8.p1.2.m2.3.3.2.2.2.3" xref="S3.SS0.SSS0.Px8.p1.2.m2.3.3.2.2.2.3.cmml">
           0
          </mn>
         </msub>
         <mo id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.5.8" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.6.cmml">
          ,
         </mo>
         <msub id="S3.SS0.SSS0.Px8.p1.2.m2.4.4.3.3.3" xref="S3.SS0.SSS0.Px8.p1.2.m2.4.4.3.3.3.cmml">
          <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px8.p1.2.m2.4.4.3.3.3.2" xref="S3.SS0.SSS0.Px8.p1.2.m2.4.4.3.3.3.2.cmml">
           ℒ
          </mi>
          <mn id="S3.SS0.SSS0.Px8.p1.2.m2.4.4.3.3.3.3" xref="S3.SS0.SSS0.Px8.p1.2.m2.4.4.3.3.3.3.cmml">
           1
          </mn>
         </msub>
         <mo id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.5.9" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.6.cmml">
          ,
         </mo>
         <msub id="S3.SS0.SSS0.Px8.p1.2.m2.5.5.4.4.4" xref="S3.SS0.SSS0.Px8.p1.2.m2.5.5.4.4.4.cmml">
          <mi id="S3.SS0.SSS0.Px8.p1.2.m2.5.5.4.4.4.2" xref="S3.SS0.SSS0.Px8.p1.2.m2.5.5.4.4.4.2.cmml">
           a
          </mi>
          <mn id="S3.SS0.SSS0.Px8.p1.2.m2.5.5.4.4.4.3" xref="S3.SS0.SSS0.Px8.p1.2.m2.5.5.4.4.4.3.cmml">
           1
          </mn>
         </msub>
         <mo id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.5.10" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.6.cmml">
          ,
         </mo>
         <mi id="S3.SS0.SSS0.Px8.p1.2.m2.1.1" mathvariant="normal" xref="S3.SS0.SSS0.Px8.p1.2.m2.1.1.cmml">
          …
         </mi>
         <mo id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.5.11" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.6.cmml">
          ,
         </mo>
         <msub id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.5.5" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.5.5.cmml">
          <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.5.5.2" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.5.5.2.cmml">
           ℒ
          </mi>
          <mi id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.5.5.3" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.5.5.3.cmml">
           T
          </mi>
         </msub>
         <mo id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.5.12" stretchy="false" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.6.cmml">
          ]
         </mo>
        </mrow>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px8.p1.2.m2.6b">
        <apply id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.cmml" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6">
         <eq id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.6.cmml" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.6">
         </eq>
         <apply id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.7.cmml" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.7">
          <times id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.7.1.cmml" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.7.1">
          </times>
          <ci id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.7.2.cmml" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.7.2">
           𝒜
          </ci>
          <apply id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.7.3.cmml" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.7.3">
           <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.7.3.1.cmml" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.7.3">
            subscript
           </csymbol>
           <ci id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.7.3.2.cmml" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.7.3.2">
            𝒪
           </ci>
           <ci id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.7.3.3.cmml" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.7.3.3">
            𝑖
           </ci>
          </apply>
         </apply>
         <list id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.6.cmml" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.5">
          <apply id="S3.SS0.SSS0.Px8.p1.2.m2.2.2.1.1.1.cmml" xref="S3.SS0.SSS0.Px8.p1.2.m2.2.2.1.1.1">
           <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px8.p1.2.m2.2.2.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px8.p1.2.m2.2.2.1.1.1">
            subscript
           </csymbol>
           <ci id="S3.SS0.SSS0.Px8.p1.2.m2.2.2.1.1.1.2.cmml" xref="S3.SS0.SSS0.Px8.p1.2.m2.2.2.1.1.1.2">
            ℒ
           </ci>
           <cn id="S3.SS0.SSS0.Px8.p1.2.m2.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS0.SSS0.Px8.p1.2.m2.2.2.1.1.1.3">
            0
           </cn>
          </apply>
          <apply id="S3.SS0.SSS0.Px8.p1.2.m2.3.3.2.2.2.cmml" xref="S3.SS0.SSS0.Px8.p1.2.m2.3.3.2.2.2">
           <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px8.p1.2.m2.3.3.2.2.2.1.cmml" xref="S3.SS0.SSS0.Px8.p1.2.m2.3.3.2.2.2">
            subscript
           </csymbol>
           <ci id="S3.SS0.SSS0.Px8.p1.2.m2.3.3.2.2.2.2.cmml" xref="S3.SS0.SSS0.Px8.p1.2.m2.3.3.2.2.2.2">
            𝑎
           </ci>
           <cn id="S3.SS0.SSS0.Px8.p1.2.m2.3.3.2.2.2.3.cmml" type="integer" xref="S3.SS0.SSS0.Px8.p1.2.m2.3.3.2.2.2.3">
            0
           </cn>
          </apply>
          <apply id="S3.SS0.SSS0.Px8.p1.2.m2.4.4.3.3.3.cmml" xref="S3.SS0.SSS0.Px8.p1.2.m2.4.4.3.3.3">
           <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px8.p1.2.m2.4.4.3.3.3.1.cmml" xref="S3.SS0.SSS0.Px8.p1.2.m2.4.4.3.3.3">
            subscript
           </csymbol>
           <ci id="S3.SS0.SSS0.Px8.p1.2.m2.4.4.3.3.3.2.cmml" xref="S3.SS0.SSS0.Px8.p1.2.m2.4.4.3.3.3.2">
            ℒ
           </ci>
           <cn id="S3.SS0.SSS0.Px8.p1.2.m2.4.4.3.3.3.3.cmml" type="integer" xref="S3.SS0.SSS0.Px8.p1.2.m2.4.4.3.3.3.3">
            1
           </cn>
          </apply>
          <apply id="S3.SS0.SSS0.Px8.p1.2.m2.5.5.4.4.4.cmml" xref="S3.SS0.SSS0.Px8.p1.2.m2.5.5.4.4.4">
           <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px8.p1.2.m2.5.5.4.4.4.1.cmml" xref="S3.SS0.SSS0.Px8.p1.2.m2.5.5.4.4.4">
            subscript
           </csymbol>
           <ci id="S3.SS0.SSS0.Px8.p1.2.m2.5.5.4.4.4.2.cmml" xref="S3.SS0.SSS0.Px8.p1.2.m2.5.5.4.4.4.2">
            𝑎
           </ci>
           <cn id="S3.SS0.SSS0.Px8.p1.2.m2.5.5.4.4.4.3.cmml" type="integer" xref="S3.SS0.SSS0.Px8.p1.2.m2.5.5.4.4.4.3">
            1
           </cn>
          </apply>
          <ci id="S3.SS0.SSS0.Px8.p1.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px8.p1.2.m2.1.1">
           …
          </ci>
          <apply id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.5.5.cmml" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.5.5">
           <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.5.5.1.cmml" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.5.5">
            subscript
           </csymbol>
           <ci id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.5.5.2.cmml" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.5.5.2">
            ℒ
           </ci>
           <ci id="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.5.5.3.cmml" xref="S3.SS0.SSS0.Px8.p1.2.m2.6.6.5.5.5.3">
            𝑇
           </ci>
          </apply>
         </list>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px8.p1.2.m2.6c">
        \mathcal{AO}_{i}=[\mathcal{L}_{0},a_{0},\mathcal{L}_{1},a_{1},...,\mathcal{L}_{T}]
       </annotation>
      </semantics>
     </math>
     . Then an LLM-based module or human is required to observe the action-observation sequences and summarize the world knowledge learned from
     <math alttext="\{\mathcal{AO}_{i}\}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px8.p1.3.m3.1">
      <semantics id="S3.SS0.SSS0.Px8.p1.3.m3.1a">
       <mrow id="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1" xref="S3.SS0.SSS0.Px8.p1.3.m3.1.1.2.cmml">
        <mo id="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1.2" stretchy="false" xref="S3.SS0.SSS0.Px8.p1.3.m3.1.1.2.cmml">
         {
        </mo>
        <mrow id="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1.1" xref="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1.1.cmml">
         <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1.1.2" xref="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1.1.2.cmml">
          𝒜
         </mi>
         <mo id="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1.1.1" lspace="0em" rspace="0em" xref="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1.1.1.cmml">
          ​
         </mo>
         <msub id="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1.1.3" xref="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1.1.3.cmml">
          <mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1.1.3.2" xref="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1.1.3.2.cmml">
           𝒪
          </mi>
          <mi id="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1.1.3.3" xref="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1.1.3.3.cmml">
           i
          </mi>
         </msub>
        </mrow>
        <mo id="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1.3" stretchy="false" xref="S3.SS0.SSS0.Px8.p1.3.m3.1.1.2.cmml">
         }
        </mo>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px8.p1.3.m3.1b">
        <set id="S3.SS0.SSS0.Px8.p1.3.m3.1.1.2.cmml" xref="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1">
         <apply id="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1.1">
          <times id="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1.1.1">
          </times>
          <ci id="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1.1.2.cmml" xref="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1.1.2">
           𝒜
          </ci>
          <apply id="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1.1.3.cmml" xref="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1.1.3">
           <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1.1.3.1.cmml" xref="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1.1.3">
            subscript
           </csymbol>
           <ci id="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1.1.3.2.cmml" xref="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1.1.3.2">
            𝒪
           </ci>
           <ci id="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1.1.3.3.cmml" xref="S3.SS0.SSS0.Px8.p1.3.m3.1.1.1.1.3.3">
            𝑖
           </ci>
          </apply>
         </apply>
        </set>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px8.p1.3.m3.1c">
        \{\mathcal{AO}_{i}\}
       </annotation>
      </semantics>
     </math>
     as prior knowledge candidates
     <math alttext="\{P_{j}\}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px8.p1.4.m4.1">
      <semantics id="S3.SS0.SSS0.Px8.p1.4.m4.1a">
       <mrow id="S3.SS0.SSS0.Px8.p1.4.m4.1.1.1" xref="S3.SS0.SSS0.Px8.p1.4.m4.1.1.2.cmml">
        <mo id="S3.SS0.SSS0.Px8.p1.4.m4.1.1.1.2" stretchy="false" xref="S3.SS0.SSS0.Px8.p1.4.m4.1.1.2.cmml">
         {
        </mo>
        <msub id="S3.SS0.SSS0.Px8.p1.4.m4.1.1.1.1" xref="S3.SS0.SSS0.Px8.p1.4.m4.1.1.1.1.cmml">
         <mi id="S3.SS0.SSS0.Px8.p1.4.m4.1.1.1.1.2" xref="S3.SS0.SSS0.Px8.p1.4.m4.1.1.1.1.2.cmml">
          P
         </mi>
         <mi id="S3.SS0.SSS0.Px8.p1.4.m4.1.1.1.1.3" xref="S3.SS0.SSS0.Px8.p1.4.m4.1.1.1.1.3.cmml">
          j
         </mi>
        </msub>
        <mo id="S3.SS0.SSS0.Px8.p1.4.m4.1.1.1.3" stretchy="false" xref="S3.SS0.SSS0.Px8.p1.4.m4.1.1.2.cmml">
         }
        </mo>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px8.p1.4.m4.1b">
        <set id="S3.SS0.SSS0.Px8.p1.4.m4.1.1.2.cmml" xref="S3.SS0.SSS0.Px8.p1.4.m4.1.1.1">
         <apply id="S3.SS0.SSS0.Px8.p1.4.m4.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px8.p1.4.m4.1.1.1.1">
          <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px8.p1.4.m4.1.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px8.p1.4.m4.1.1.1.1">
           subscript
          </csymbol>
          <ci id="S3.SS0.SSS0.Px8.p1.4.m4.1.1.1.1.2.cmml" xref="S3.SS0.SSS0.Px8.p1.4.m4.1.1.1.1.2">
           𝑃
          </ci>
          <ci id="S3.SS0.SSS0.Px8.p1.4.m4.1.1.1.1.3.cmml" xref="S3.SS0.SSS0.Px8.p1.4.m4.1.1.1.1.3">
           𝑗
          </ci>
         </apply>
        </set>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px8.p1.4.m4.1c">
        \{P_{j}\}
       </annotation>
      </semantics>
     </math>
     . After that, an LLM-based filter is applied on
     <math alttext="\{P_{j}\}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px8.p1.5.m5.1">
      <semantics id="S3.SS0.SSS0.Px8.p1.5.m5.1a">
       <mrow id="S3.SS0.SSS0.Px8.p1.5.m5.1.1.1" xref="S3.SS0.SSS0.Px8.p1.5.m5.1.1.2.cmml">
        <mo id="S3.SS0.SSS0.Px8.p1.5.m5.1.1.1.2" stretchy="false" xref="S3.SS0.SSS0.Px8.p1.5.m5.1.1.2.cmml">
         {
        </mo>
        <msub id="S3.SS0.SSS0.Px8.p1.5.m5.1.1.1.1" xref="S3.SS0.SSS0.Px8.p1.5.m5.1.1.1.1.cmml">
         <mi id="S3.SS0.SSS0.Px8.p1.5.m5.1.1.1.1.2" xref="S3.SS0.SSS0.Px8.p1.5.m5.1.1.1.1.2.cmml">
          P
         </mi>
         <mi id="S3.SS0.SSS0.Px8.p1.5.m5.1.1.1.1.3" xref="S3.SS0.SSS0.Px8.p1.5.m5.1.1.1.1.3.cmml">
          j
         </mi>
        </msub>
        <mo id="S3.SS0.SSS0.Px8.p1.5.m5.1.1.1.3" stretchy="false" xref="S3.SS0.SSS0.Px8.p1.5.m5.1.1.2.cmml">
         }
        </mo>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px8.p1.5.m5.1b">
        <set id="S3.SS0.SSS0.Px8.p1.5.m5.1.1.2.cmml" xref="S3.SS0.SSS0.Px8.p1.5.m5.1.1.1">
         <apply id="S3.SS0.SSS0.Px8.p1.5.m5.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px8.p1.5.m5.1.1.1.1">
          <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px8.p1.5.m5.1.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px8.p1.5.m5.1.1.1.1">
           subscript
          </csymbol>
          <ci id="S3.SS0.SSS0.Px8.p1.5.m5.1.1.1.1.2.cmml" xref="S3.SS0.SSS0.Px8.p1.5.m5.1.1.1.1.2">
           𝑃
          </ci>
          <ci id="S3.SS0.SSS0.Px8.p1.5.m5.1.1.1.1.3.cmml" xref="S3.SS0.SSS0.Px8.p1.5.m5.1.1.1.1.3">
           𝑗
          </ci>
         </apply>
        </set>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px8.p1.5.m5.1c">
        \{P_{j}\}
       </annotation>
      </semantics>
     </math>
     to eliminate contradictory and duplicated world knowledge, which results in the final set of world knowledge
     <math alttext="\{P^{\prime}_{i}\}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px8.p1.6.m6.1">
      <semantics id="S3.SS0.SSS0.Px8.p1.6.m6.1a">
       <mrow id="S3.SS0.SSS0.Px8.p1.6.m6.1.1.1" xref="S3.SS0.SSS0.Px8.p1.6.m6.1.1.2.cmml">
        <mo id="S3.SS0.SSS0.Px8.p1.6.m6.1.1.1.2" stretchy="false" xref="S3.SS0.SSS0.Px8.p1.6.m6.1.1.2.cmml">
         {
        </mo>
        <msubsup id="S3.SS0.SSS0.Px8.p1.6.m6.1.1.1.1" xref="S3.SS0.SSS0.Px8.p1.6.m6.1.1.1.1.cmml">
         <mi id="S3.SS0.SSS0.Px8.p1.6.m6.1.1.1.1.2.2" xref="S3.SS0.SSS0.Px8.p1.6.m6.1.1.1.1.2.2.cmml">
          P
         </mi>
         <mi id="S3.SS0.SSS0.Px8.p1.6.m6.1.1.1.1.3" xref="S3.SS0.SSS0.Px8.p1.6.m6.1.1.1.1.3.cmml">
          i
         </mi>
         <mo id="S3.SS0.SSS0.Px8.p1.6.m6.1.1.1.1.2.3" xref="S3.SS0.SSS0.Px8.p1.6.m6.1.1.1.1.2.3.cmml">
          ′
         </mo>
        </msubsup>
        <mo id="S3.SS0.SSS0.Px8.p1.6.m6.1.1.1.3" stretchy="false" xref="S3.SS0.SSS0.Px8.p1.6.m6.1.1.2.cmml">
         }
        </mo>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px8.p1.6.m6.1b">
        <set id="S3.SS0.SSS0.Px8.p1.6.m6.1.1.2.cmml" xref="S3.SS0.SSS0.Px8.p1.6.m6.1.1.1">
         <apply id="S3.SS0.SSS0.Px8.p1.6.m6.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px8.p1.6.m6.1.1.1.1">
          <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px8.p1.6.m6.1.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px8.p1.6.m6.1.1.1.1">
           subscript
          </csymbol>
          <apply id="S3.SS0.SSS0.Px8.p1.6.m6.1.1.1.1.2.cmml" xref="S3.SS0.SSS0.Px8.p1.6.m6.1.1.1.1">
           <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px8.p1.6.m6.1.1.1.1.2.1.cmml" xref="S3.SS0.SSS0.Px8.p1.6.m6.1.1.1.1">
            superscript
           </csymbol>
           <ci id="S3.SS0.SSS0.Px8.p1.6.m6.1.1.1.1.2.2.cmml" xref="S3.SS0.SSS0.Px8.p1.6.m6.1.1.1.1.2.2">
            𝑃
           </ci>
           <ci id="S3.SS0.SSS0.Px8.p1.6.m6.1.1.1.1.2.3.cmml" xref="S3.SS0.SSS0.Px8.p1.6.m6.1.1.1.1.2.3">
            ′
           </ci>
          </apply>
          <ci id="S3.SS0.SSS0.Px8.p1.6.m6.1.1.1.1.3.cmml" xref="S3.SS0.SSS0.Px8.p1.6.m6.1.1.1.1.3">
           𝑖
          </ci>
         </apply>
        </set>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px8.p1.6.m6.1c">
        \{P^{\prime}_{i}\}
       </annotation>
      </semantics>
     </math>
     . Finally, the world knowledge
     <math alttext="\{P^{\prime}_{i}\}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px8.p1.7.m7.1">
      <semantics id="S3.SS0.SSS0.Px8.p1.7.m7.1a">
       <mrow id="S3.SS0.SSS0.Px8.p1.7.m7.1.1.1" xref="S3.SS0.SSS0.Px8.p1.7.m7.1.1.2.cmml">
        <mo id="S3.SS0.SSS0.Px8.p1.7.m7.1.1.1.2" stretchy="false" xref="S3.SS0.SSS0.Px8.p1.7.m7.1.1.2.cmml">
         {
        </mo>
        <msubsup id="S3.SS0.SSS0.Px8.p1.7.m7.1.1.1.1" xref="S3.SS0.SSS0.Px8.p1.7.m7.1.1.1.1.cmml">
         <mi id="S3.SS0.SSS0.Px8.p1.7.m7.1.1.1.1.2.2" xref="S3.SS0.SSS0.Px8.p1.7.m7.1.1.1.1.2.2.cmml">
          P
         </mi>
         <mi id="S3.SS0.SSS0.Px8.p1.7.m7.1.1.1.1.3" xref="S3.SS0.SSS0.Px8.p1.7.m7.1.1.1.1.3.cmml">
          i
         </mi>
         <mo id="S3.SS0.SSS0.Px8.p1.7.m7.1.1.1.1.2.3" xref="S3.SS0.SSS0.Px8.p1.7.m7.1.1.1.1.2.3.cmml">
          ′
         </mo>
        </msubsup>
        <mo id="S3.SS0.SSS0.Px8.p1.7.m7.1.1.1.3" stretchy="false" xref="S3.SS0.SSS0.Px8.p1.7.m7.1.1.2.cmml">
         }
        </mo>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px8.p1.7.m7.1b">
        <set id="S3.SS0.SSS0.Px8.p1.7.m7.1.1.2.cmml" xref="S3.SS0.SSS0.Px8.p1.7.m7.1.1.1">
         <apply id="S3.SS0.SSS0.Px8.p1.7.m7.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px8.p1.7.m7.1.1.1.1">
          <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px8.p1.7.m7.1.1.1.1.1.cmml" xref="S3.SS0.SSS0.Px8.p1.7.m7.1.1.1.1">
           subscript
          </csymbol>
          <apply id="S3.SS0.SSS0.Px8.p1.7.m7.1.1.1.1.2.cmml" xref="S3.SS0.SSS0.Px8.p1.7.m7.1.1.1.1">
           <csymbol cd="ambiguous" id="S3.SS0.SSS0.Px8.p1.7.m7.1.1.1.1.2.1.cmml" xref="S3.SS0.SSS0.Px8.p1.7.m7.1.1.1.1">
            superscript
           </csymbol>
           <ci id="S3.SS0.SSS0.Px8.p1.7.m7.1.1.1.1.2.2.cmml" xref="S3.SS0.SSS0.Px8.p1.7.m7.1.1.1.1.2.2">
            𝑃
           </ci>
           <ci id="S3.SS0.SSS0.Px8.p1.7.m7.1.1.1.1.2.3.cmml" xref="S3.SS0.SSS0.Px8.p1.7.m7.1.1.1.1.2.3">
            ′
           </ci>
          </apply>
          <ci id="S3.SS0.SSS0.Px8.p1.7.m7.1.1.1.1.3.cmml" xref="S3.SS0.SSS0.Px8.p1.7.m7.1.1.1.1.3">
           𝑖
          </ci>
         </apply>
        </set>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px8.p1.7.m7.1c">
        \{P^{\prime}_{i}\}
       </annotation>
      </semantics>
     </math>
     is integrated into the prompt templates of the multi-agent dialogue strategy, where a reasoner depicts general plans solving the task and the actor ground the plans as executable actions in the environment.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    4
   </span>
   Experiments and Discussion
  </h2>
  <section class="ltx_subsection" id="S4.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.1
    </span>
    Experiment Setup
   </h3>
   <section class="ltx_paragraph" id="S4.SS1.SSS0.Px1">
    <h4 class="ltx_title ltx_title_paragraph">
     Evaluation Splits
    </h4>
    <div class="ltx_para" id="S4.SS1.SSS0.Px1.p1">
     <p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.1">
      The ALFRED benchmark consists of training, valid, and test sets. Both valid and test sets are composed of seen and unseen splits, where the unseen splits consist of rooms that do not appear in the training set. Following
      <cite class="ltx_cite ltx_citemacro_cite">
       Yao et al. (
       <a class="ltx_ref" href="#bib.bib46" title="">
        2022
       </a>
       )
      </cite>
      , we evaluate our methods on 134 unseen evaluation games for the ALFWorld benchmark.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S4.SS1.SSS0.Px2">
    <h4 class="ltx_title ltx_title_paragraph">
     Evaluation Metrics
    </h4>
    <div class="ltx_para" id="S4.SS1.SSS0.Px2.p1">
     <p class="ltx_p" id="S4.SS1.SSS0.Px2.p1.1">
      Following
      <cite class="ltx_cite ltx_citemacro_cite">
       Shridhar et al. (
       <a class="ltx_ref" href="#bib.bib33" title="">
        2020a
       </a>
       ); Min et al. (
       <a class="ltx_ref" href="#bib.bib21" title="">
        2021
       </a>
       )
      </cite>
      , we report four evaluation metrics on AFLRED: (1) Success Rate (SR);
(2) Goal Condition (GC), the ratio of goal conditions completed at the end of an episode;
(3) path length weighted SR (PLWSR), the SR weighted by (path length of the expert trajectory)/(path length taken by the agent);
(4) path length weighted GC (PLWGC), the GC weighted by the same factor. Following
      <cite class="ltx_cite ltx_citemacro_cite">
       Yao et al. (
       <a class="ltx_ref" href="#bib.bib46" title="">
        2022
       </a>
       )
      </cite>
      , we report SR on ALFWorld.
     </p>
    </div>
    <figure class="ltx_table" id="S4.T1">
     <table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T1.1">
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="S4.T1.1.1.1">
        <td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T1.1.1.1.1" rowspan="2">
         <span class="ltx_text" id="S4.T1.1.1.1.1.1">
          Method
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S4.T1.1.1.1.2">
         Test Seen
        </td>
        <td class="ltx_td ltx_border_tt" id="S4.T1.1.1.1.3">
        </td>
        <td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S4.T1.1.1.1.4">
         Test Unseen
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T1.1.2.2">
        <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.2.2.1">
         PLWGC
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.2.2.2">
         GC
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.2.2.3">
         PLWSR
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.2.2.4">
         SR
        </td>
        <td class="ltx_td" id="S4.T1.1.2.2.5">
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.2.2.6">
         PLWGC
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.2.2.7">
         GC
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.2.2.8">
         PLWSR
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.2.2.9">
         SR
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T1.1.3.3">
        <td class="ltx_td ltx_align_left ltx_border_t" colspan="9" id="S4.T1.1.3.3.1">
         <span class="ltx_text ltx_font_bold" id="S4.T1.1.3.3.1.1">
          ALFRED (High-level goal instructions only)
         </span>
        </td>
        <td class="ltx_td ltx_border_t" id="S4.T1.1.3.3.2">
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T1.1.4.4">
        <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.4.4.1">
         LAV
         <cite class="ltx_cite ltx_citemacro_cite">
          Nottingham et al. (
          <a class="ltx_ref" href="#bib.bib24" title="">
           2021
          </a>
          )
         </cite>
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.4.4.2">
         13.18
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.4.4.3">
         23.21
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.4.4.4">
         6.31
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.4.4.5">
         13.35
        </td>
        <td class="ltx_td ltx_border_t" id="S4.T1.1.4.4.6">
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.4.4.7">
         10.47
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.4.4.8">
         17.27
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.4.4.9">
         3.12
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.1.4.4.10">
         6.38
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T1.1.5.5">
        <td class="ltx_td ltx_align_left" id="S4.T1.1.5.5.1">
         HLSM
         <cite class="ltx_cite ltx_citemacro_cite">
          Blukis et al. (
          <a class="ltx_ref" href="#bib.bib3" title="">
           2022
          </a>
          )
         </cite>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.5.5.2">
         11.53
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.5.5.3">
         35.79
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.5.5.4">
         6.69
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.5.5.5">
         25.11
        </td>
        <td class="ltx_td" id="S4.T1.1.5.5.6">
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.5.5.7">
         8.45
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.5.5.8">
         27.24
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.5.5.9">
         4.34
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.5.5.10">
         16.29
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T1.1.6.6">
        <td class="ltx_td ltx_align_left" id="S4.T1.1.6.6.1">
         LGS-RPA
         <cite class="ltx_cite ltx_citemacro_cite">
          Murray and Cakmak (
          <a class="ltx_ref" href="#bib.bib22" title="">
           2022
          </a>
          )
         </cite>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.6.6.2">
         <span class="ltx_text ltx_font_bold" id="S4.T1.1.6.6.2.1">
          24.49
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.6.6.3">
         41.71
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.6.6.4">
         <span class="ltx_text ltx_font_bold" id="S4.T1.1.6.6.4.1">
          16.65
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.6.6.5">
         33.01
        </td>
        <td class="ltx_td" id="S4.T1.1.6.6.6">
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.6.6.7">
         <span class="ltx_text ltx_font_bold" id="S4.T1.1.6.6.7.1">
          20.01
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.6.6.8">
         38.55
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.6.6.9">
         <span class="ltx_text ltx_font_bold" id="S4.T1.1.6.6.9.1">
          12.92
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.6.6.10">
         27.80
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T1.1.7.7">
        <td class="ltx_td ltx_align_left" id="S4.T1.1.7.7.1">
         EPA
         <cite class="ltx_cite ltx_citemacro_cite">
          Liu et al. (
          <a class="ltx_ref" href="#bib.bib19" title="">
           2022c
          </a>
          )
         </cite>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.7.7.2">
         3.47
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.7.7.3">
         44.14
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.7.7.4">
         2.56
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.7.7.5">
         39.96
        </td>
        <td class="ltx_td" id="S4.T1.1.7.7.6">
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.7.7.7">
         3.91
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.7.7.8">
         39.54
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.7.7.9">
         2.92
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.7.7.10">
         36.07
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T1.1.8.8">
        <td class="ltx_td ltx_align_left" id="S4.T1.1.8.8.1">
         LLM-Planner
         <cite class="ltx_cite ltx_citemacro_cite">
          Song et al. (
          <a class="ltx_ref" href="#bib.bib37" title="">
           2023
          </a>
          )
         </cite>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.8.8.2">
         -
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.8.8.3">
         24.57
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.8.8.4">
         -
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.8.8.5">
         15.33
        </td>
        <td class="ltx_td" id="S4.T1.1.8.8.6">
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.8.8.7">
         -
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.8.8.8">
         22.89
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.8.8.9">
         -
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.8.8.10">
         13.41
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T1.1.9.9">
        <td class="ltx_td ltx_align_left" id="S4.T1.1.9.9.1">
         FILM
         <cite class="ltx_cite ltx_citemacro_cite">
          Min et al. (
          <a class="ltx_ref" href="#bib.bib21" title="">
           2021
          </a>
          )
         </cite>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.9.9.2">
         14.17
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.9.9.3">
         36.15
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.9.9.4">
         10.39
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.9.9.5">
         25.77
        </td>
        <td class="ltx_td" id="S4.T1.1.9.9.6">
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.9.9.7">
         13.13
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.9.9.8">
         34.75
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.9.9.9">
         9.67
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T1.1.9.9.10">
         24.46
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T1.1.10.10">
        <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T1.1.10.10.1">
         OPEx-S
        </td>
        <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T1.1.10.10.2">
         20.13
        </td>
        <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T1.1.10.10.3">
         <span class="ltx_text ltx_font_bold" id="S4.T1.1.10.10.3.1">
          54.27
         </span>
        </td>
        <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T1.1.10.10.4">
         13.64
        </td>
        <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T1.1.10.10.5">
         <span class="ltx_text ltx_font_bold" id="S4.T1.1.10.10.5.1">
          43.51
         </span>
        </td>
        <td class="ltx_td ltx_border_bb" id="S4.T1.1.10.10.6">
        </td>
        <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T1.1.10.10.7">
         18.46
        </td>
        <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T1.1.10.10.8">
         <span class="ltx_text ltx_font_bold" id="S4.T1.1.10.10.8.1">
          53.82
         </span>
        </td>
        <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T1.1.10.10.9">
         12.57
        </td>
        <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T1.1.10.10.10">
         <span class="ltx_text ltx_font_bold" id="S4.T1.1.10.10.10.1">
          41.27
         </span>
        </td>
       </tr>
      </tbody>
     </table>
     <figcaption class="ltx_caption ltx_centering">
      <span class="ltx_tag ltx_tag_table">
       Table 1:
      </span>
      Main Results on the test splits of ALFRED benchmark.
     </figcaption>
    </figure>
   </section>
   <section class="ltx_paragraph" id="S4.SS1.SSS0.Px3">
    <h4 class="ltx_title ltx_title_paragraph">
     Compared Methods
    </h4>
    <div class="ltx_para" id="S4.SS1.SSS0.Px3.p1">
     <p class="ltx_p" id="S4.SS1.SSS0.Px3.p1.1">
      The compared methods on ALFRED include LAV
      <cite class="ltx_cite ltx_citemacro_cite">
       Nottingham et al. (
       <a class="ltx_ref" href="#bib.bib24" title="">
        2021
       </a>
       )
      </cite>
      , where the raw language and visual inputs are transformed into structured forms, with a separate “action prediction module” predicting the low-level actions; HLSM
      <cite class="ltx_cite ltx_citemacro_cite">
       Blukis et al. (
       <a class="ltx_ref" href="#bib.bib3" title="">
        2022
       </a>
       )
      </cite>
      , a hierarchical approach that uses semantic voxel map state representation as a long-term
memory to solve long-horizon tasks; LGS-RPA
      <cite class="ltx_cite ltx_citemacro_cite">
       Murray and Cakmak (
       <a class="ltx_ref" href="#bib.bib22" title="">
        2022
       </a>
       )
      </cite>
      , which utilizes a Djikstra-based deterministic planner for navigation action generation and introduces landmark-guided search along with the reinforced pose adjustment for navigation goal searching and interaction action preparation respectively; EPA
      <cite class="ltx_cite ltx_citemacro_cite">
       Liu et al. (
       <a class="ltx_ref" href="#bib.bib19" title="">
        2022c
       </a>
       )
      </cite>
      , a neural-symbolic approach with symbolic planning; LLM-Planner
      <cite class="ltx_cite ltx_citemacro_cite">
       Song et al. (
       <a class="ltx_ref" href="#bib.bib37" title="">
        2023
       </a>
       )
      </cite>
      , which simply prompts LLMs for task decomposition; FILM
      <cite class="ltx_cite ltx_citemacro_cite">
       Min et al. (
       <a class="ltx_ref" href="#bib.bib21" title="">
        2021
       </a>
       )
      </cite>
      , which builds 2D semantic map and performs exploration with a semantic search policy. It is worth noting that there are also several works on the leaderboard reporting high performance that are not included in the comparison
      <cite class="ltx_cite ltx_citemacro_cite">
       Inoue and Ohashi (
       <a class="ltx_ref" href="#bib.bib13" title="">
        2022
       </a>
       ); Shridhar et al. (
       <a class="ltx_ref" href="#bib.bib33" title="">
        2020a
       </a>
       ); Chen et al. (
       <a class="ltx_ref" href="#bib.bib5" title="">
        2023
       </a>
       )
      </cite>
      , this is mainly because we focus on systematically outlining and evaluating the essential components for mastering EIF tasks, while we cannot find the description or available open-source resources of these works when we conduct the experiments. On the ALFWorld benchmark, apart from the variants of OPEx, we also introduce ReAct
      <cite class="ltx_cite ltx_citemacro_cite">
       Yao et al. (
       <a class="ltx_ref" href="#bib.bib46" title="">
        2022
       </a>
       )
      </cite>
      for comparison to demonstrate the effectiveness of the proposed method.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S4.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.2
    </span>
    Experimental Results
   </h3>
   <div class="ltx_para" id="S4.SS2.p1">
    <p class="ltx_p" id="S4.SS2.p1.1">
     The main results are illustrated in Table
     <a class="ltx_ref" href="#S4.T1" title="Table 1 ‣ Evaluation Metrics ‣ 4.1 Experiment Setup ‣ 4 Experiments and Discussion ‣ OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied Instruction Following">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     . When contrasting OPEx with the baseline FILM, it becomes evident that OPEx exhibits substantial improvement across two distinct environmental settings, encompassing both the goal condition (GC) and the success rate (SR). Notably, OPEx utilizes in-context learning on less than 10% data used for FILMs’ planner (Language Processor) training, while OPEx still significantly outperforms FILM. The observation that OPEx achieves 17.74% and 16.78% absolute gain in SR on test seen and unseen split respectively empirically demonstrates the effectiveness of the OPEx framework. However, it is also worth noting that the OPEx is inferior to FILM concerning the path length weighted metrics. This phenomenon could potentially be attributed to the deliberate choice of assigning a higher maximum number of failures to OPEx as compared to FILM. This choice typically leads to the average length of the resulting episodes. The rationale behind this decision was to encourage OPEx to undertake a more extensive exploration, thereby fostering the acquisition of skills in handling a broader range of exceptions arising from both uncommon scenarios and failures. On the other hand, the FILM utilizes two BERT models trained on the whole training set with the template assumption to conduct the task decomposition, while the LLM-based planner can achieve this goal with only a bunch of examples. This phenomenon shows that OPEx works with a much lower demand for in-domain data, making it more feasible in real-world scenarios, where the data collection could be more time-consuming and expensive. Furthermore, the FILM outputs low-level navigation and interaction actions solely with a deterministic policy, while OPEx introduces an LLM-based executor accompanying the deterministic policy to release LLMs’ potential for robust language grounding and exception handling in the embodiment environment. Overall, the main results empirically demonstrate that it could be feasible to develop embodied experts with low demand for in-domain data by mining LLMs’ potential for grounded planning and acting.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.3
    </span>
    Ablation Study and Analysis
   </h3>
   <div class="ltx_para" id="S4.SS3.p1">
    <p class="ltx_p" id="S4.SS3.p1.1">
     To further investigate the bottleneck of the system and the influence of different modules, we conduct several additional ablation studies.
    </p>
   </div>
   <section class="ltx_paragraph" id="S4.SS3.SSS0.Px1">
    <h4 class="ltx_title ltx_title_paragraph">
     Influence of perception models
    </h4>
    <div class="ltx_para" id="S4.SS3.SSS0.Px1.p1">
     <p class="ltx_p" id="S4.SS3.SSS0.Px1.p1.1">
      We first conduct controlled experiments on the valid unseen split of the AFLRED dataset to study the influence of perception models. The corresponding results are illustrated in the first section of Table
      <a class="ltx_ref" href="#S4.T2" title="Table 2 ‣ Influence of prior knowledge ‣ 4.3 Ablation Study and Analysis ‣ 4 Experiments and Discussion ‣ OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied Instruction Following">
       <span class="ltx_text ltx_ref_tag">
        2
       </span>
      </a>
      , where OPEx-S denotes the OPEx with stronger perception models (fine-tuned ZoeDepth
      <cite class="ltx_cite ltx_citemacro_cite">
       Bhat et al. (
       <a class="ltx_ref" href="#bib.bib2" title="">
        2023
       </a>
       )
      </cite>
      for depth prediction and SOLQ
      <cite class="ltx_cite ltx_citemacro_cite">
       Dong et al. (
       <a class="ltx_ref" href="#bib.bib6" title="">
        2021
       </a>
       )
      </cite>
      for instance segmentation), OPEx-P denotes the OPEx with perfect ground-truth depth prediction and instance segmentation. The performance gain from the improvement of perception models is very significant, indicating there is much room for improvement regarding the perception models in ALFRED.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S4.SS3.SSS0.Px2">
    <h4 class="ltx_title ltx_title_paragraph">
     Influence of action policies
    </h4>
    <div class="ltx_para" id="S4.SS3.SSS0.Px2.p1">
     <p class="ltx_p" id="S4.SS3.SSS0.Px2.p1.1">
      As shown in the second section of Table
      <a class="ltx_ref" href="#S4.T2" title="Table 2 ‣ Influence of prior knowledge ‣ 4.3 Ablation Study and Analysis ‣ 4 Experiments and Discussion ‣ OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied Instruction Following">
       <span class="ltx_text ltx_ref_tag">
        2
       </span>
      </a>
      , we design and conduct another set of controlled experiments to study the influence of distinct deterministic action heuristics introduced. It can be seen from the table that setting the navigation goal inside the traversable area brings the most significant performance improvement, while slice replay brings marginal improvement. Besides, introducing the additional semantic map for robust landmark-based navigation goal searching brings moderate performance gain.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S4.SS3.SSS0.Px3">
    <h4 class="ltx_title ltx_title_paragraph">
     Influence of LLM-based modules
    </h4>
    <div class="ltx_para" id="S4.SS3.SSS0.Px3.p1">
     <p class="ltx_p" id="S4.SS3.SSS0.Px3.p1.1">
      We first conduct controlled experiments on the validation unseen split of the dataset to study the influence of different modules. The corresponding results are illustrated in Table
      <a class="ltx_ref" href="#S4.T2" title="Table 2 ‣ Influence of prior knowledge ‣ 4.3 Ablation Study and Analysis ‣ 4 Experiments and Discussion ‣ OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied Instruction Following">
       <span class="ltx_text ltx_ref_tag">
        2
       </span>
      </a>
      . Significant performance degradation can be observed when the LLM-based planner is removed from the OPEx. This is probably attributed to the fact that the LLM-based executor is required to solely perform implicit long-term planning and grounded interaction simultaneously under this setting. The LLM-based observer is designed to gather information and help the LLM-based executor to focus on task-relevant information by summarizing collected information and filtering out the task-irrelevant counterparts. However, the ablation study shows that the performance gain brought by the LLM-based observer is marginal. This observation can be caused by several possible reasons, including (1) GPT-4’s strong long text processing capability mitigates the needs of such kind of LLM-based observer; (2) the collected information from ALFRED is typically not too large/complex to cause severe distraction or hallucination of the LLM-based executor; (3) the observer utilizes zero-shot prompt, better prompts may need to be designed.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S4.SS3.SSS0.Px4">
    <h4 class="ltx_title ltx_title_paragraph">
     Influence of prior knowledge
    </h4>
    <div class="ltx_para" id="S4.SS3.SSS0.Px4.p1">
     <p class="ltx_p" id="S4.SS3.SSS0.Px4.p1.1">
      To further investigate the role of decision-making modules in EIF agents, we conduct experiments on ALFWorld to eliminate the impact of perception models and action policies. The corresponding results are illustrated in the fourth section of Tabel
      <a class="ltx_ref" href="#S4.T2" title="Table 2 ‣ Influence of prior knowledge ‣ 4.3 Ablation Study and Analysis ‣ 4 Experiments and Discussion ‣ OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied Instruction Following">
       <span class="ltx_text ltx_ref_tag">
        2
       </span>
      </a>
      , where OPEx-L denotes the OPEx with prior knowledge learned from the environment and OPEx-H denotes the OPEx with prior knowledge provided by humans. With the observation that the system performance grows as the quality of the prior knowledge increases, this can be empirically explained by the intuition that decomposing EIF tasks via a collaborative multi-agent dialogue strategy helps intra-agent specialization and inter-agent cooperation. Besides, the intuition that the grounded prior knowledge prevents the agents from repetitive errors and facilitates grounded exception handling might also contribute to the results. Furthermore, the performance improvement of ReAct also empirically demonstrates the effectiveness of the proposed method.
     </p>
    </div>
    <figure class="ltx_table" id="S4.T2">
     <table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T2.1">
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="S4.T2.1.2.1">
        <td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T2.1.2.1.1" rowspan="2">
         <span class="ltx_text" id="S4.T2.1.2.1.1.1">
          Method
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S4.T2.1.2.1.2">
         Valid Uneen
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T2.1.3.2">
        <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.3.2.1">
         PLWGC
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.3.2.2">
         GC
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.3.2.3">
         PLWSR
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.3.2.4">
         SR
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T2.1.4.3" style="background-color:#CCFFCC;">
        <td class="ltx_td ltx_align_left ltx_border_t" colspan="5" id="S4.T2.1.4.3.1">
         <span class="ltx_text ltx_font_bold" id="S4.T2.1.4.3.1.1" style="background-color:#CCFFCC;">
          Influence of perception models
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T2.1.5.4" style="background-color:#CCFFCC;">
        <td class="ltx_td ltx_align_left" id="S4.T2.1.5.4.1">
         <span class="ltx_text" id="S4.T2.1.5.4.1.1" style="background-color:#CCFFCC;">
          OPEx
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.5.4.2">
         <span class="ltx_text" id="S4.T2.1.5.4.2.1" style="background-color:#CCFFCC;">
          13.48
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.5.4.3">
         <span class="ltx_text" id="S4.T2.1.5.4.3.1" style="background-color:#CCFFCC;">
          48.61
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.5.4.4">
         <span class="ltx_text" id="S4.T2.1.5.4.4.1" style="background-color:#CCFFCC;">
          9.08
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.5.4.5">
         <span class="ltx_text" id="S4.T2.1.5.4.5.1" style="background-color:#CCFFCC;">
          35.91
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T2.1.6.5" style="background-color:#CCFFCC;">
        <td class="ltx_td ltx_align_left" id="S4.T2.1.6.5.1">
         <span class="ltx_text" id="S4.T2.1.6.5.1.1" style="background-color:#CCFFCC;">
          OPEx-S
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.6.5.2">
         <span class="ltx_text" id="S4.T2.1.6.5.2.1" style="background-color:#CCFFCC;">
          16.52
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.6.5.3">
         <span class="ltx_text" id="S4.T2.1.6.5.3.1" style="background-color:#CCFFCC;">
          51.28
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.6.5.4">
         <span class="ltx_text" id="S4.T2.1.6.5.4.1" style="background-color:#CCFFCC;">
          11.38
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.6.5.5">
         <span class="ltx_text" id="S4.T2.1.6.5.5.1" style="background-color:#CCFFCC;">
          40.80
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T2.1.7.6" style="background-color:#CCFFCC;">
        <td class="ltx_td ltx_align_left" id="S4.T2.1.7.6.1">
         <span class="ltx_text" id="S4.T2.1.7.6.1.1" style="background-color:#CCFFCC;">
          OPEX-P
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.7.6.2">
         <span class="ltx_text" id="S4.T2.1.7.6.2.1" style="background-color:#CCFFCC;">
          23.72
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.7.6.3">
         <span class="ltx_text" id="S4.T2.1.7.6.3.1" style="background-color:#CCFFCC;">
          66.17
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.7.6.4">
         <span class="ltx_text" id="S4.T2.1.7.6.4.1" style="background-color:#CCFFCC;">
          17.43
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.7.6.5">
         <span class="ltx_text" id="S4.T2.1.7.6.5.1" style="background-color:#CCFFCC;">
          59.43
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T2.1.8.7" style="background-color:#FFFFCC;">
        <td class="ltx_td ltx_align_left ltx_border_t" colspan="5" id="S4.T2.1.8.7.1">
         <span class="ltx_text ltx_font_bold" id="S4.T2.1.8.7.1.1" style="background-color:#FFFFCC;">
          Influence of action policies
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T2.1.9.8" style="background-color:#FFFFCC;">
        <td class="ltx_td ltx_align_left" id="S4.T2.1.9.8.1">
         <span class="ltx_text" id="S4.T2.1.9.8.1.1" style="background-color:#FFFFCC;">
          OPEx
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.9.8.2">
         <span class="ltx_text" id="S4.T2.1.9.8.2.1" style="background-color:#FFFFCC;">
          13.48
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.9.8.3">
         <span class="ltx_text" id="S4.T2.1.9.8.3.1" style="background-color:#FFFFCC;">
          48.61
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.9.8.4">
         <span class="ltx_text" id="S4.T2.1.9.8.4.1" style="background-color:#FFFFCC;">
          9.08
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.9.8.5">
         <span class="ltx_text" id="S4.T2.1.9.8.5.1" style="background-color:#FFFFCC;">
          35.91
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T2.1.1" style="background-color:#FFFFCC;">
        <td class="ltx_td ltx_align_left" id="S4.T2.1.1.1">
         <span class="ltx_text" id="S4.T2.1.1.1.1" style="background-color:#FFFFCC;">
          -semantic map
          <math alttext="M^{\prime}_{t}" class="ltx_Math" display="inline" id="S4.T2.1.1.1.1.m1.1" style="background-color:#FFFFCC;">
           <semantics id="S4.T2.1.1.1.1.m1.1a">
            <msubsup id="S4.T2.1.1.1.1.m1.1.1" xref="S4.T2.1.1.1.1.m1.1.1.cmml">
             <mi id="S4.T2.1.1.1.1.m1.1.1.2.2" mathbackground="#FFFFCC" xref="S4.T2.1.1.1.1.m1.1.1.2.2.cmml">
              M
             </mi>
             <mi id="S4.T2.1.1.1.1.m1.1.1.3" mathbackground="#FFFFCC" xref="S4.T2.1.1.1.1.m1.1.1.3.cmml">
              t
             </mi>
             <mo id="S4.T2.1.1.1.1.m1.1.1.2.3" mathbackground="#FFFFCC" xref="S4.T2.1.1.1.1.m1.1.1.2.3.cmml">
              ′
             </mo>
            </msubsup>
            <annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.m1.1b">
             <apply id="S4.T2.1.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.1.m1.1.1">
              <csymbol cd="ambiguous" id="S4.T2.1.1.1.1.m1.1.1.1.cmml" xref="S4.T2.1.1.1.1.m1.1.1">
               subscript
              </csymbol>
              <apply id="S4.T2.1.1.1.1.m1.1.1.2.cmml" xref="S4.T2.1.1.1.1.m1.1.1">
               <csymbol cd="ambiguous" id="S4.T2.1.1.1.1.m1.1.1.2.1.cmml" xref="S4.T2.1.1.1.1.m1.1.1">
                superscript
               </csymbol>
               <ci id="S4.T2.1.1.1.1.m1.1.1.2.2.cmml" xref="S4.T2.1.1.1.1.m1.1.1.2.2">
                𝑀
               </ci>
               <ci id="S4.T2.1.1.1.1.m1.1.1.2.3.cmml" xref="S4.T2.1.1.1.1.m1.1.1.2.3">
                ′
               </ci>
              </apply>
              <ci id="S4.T2.1.1.1.1.m1.1.1.3.cmml" xref="S4.T2.1.1.1.1.m1.1.1.3">
               𝑡
              </ci>
             </apply>
            </annotation-xml>
            <annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.m1.1c">
             M^{\prime}_{t}
            </annotation>
           </semantics>
          </math>
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.1.2">
         <span class="ltx_text" id="S4.T2.1.1.2.1" style="background-color:#FFFFCC;">
          12.37
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.1.3">
         <span class="ltx_text" id="S4.T2.1.1.3.1" style="background-color:#FFFFCC;">
          45.41
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.1.4">
         <span class="ltx_text" id="S4.T2.1.1.4.1" style="background-color:#FFFFCC;">
          8.06
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.1.5">
         <span class="ltx_text" id="S4.T2.1.1.5.1" style="background-color:#FFFFCC;">
          36.17
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T2.1.10.9" style="background-color:#FFFFCC;">
        <td class="ltx_td ltx_align_left" id="S4.T2.1.10.9.1">
         <span class="ltx_text" id="S4.T2.1.10.9.1.1" style="background-color:#FFFFCC;">
          -slice replay
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.10.9.2">
         <span class="ltx_text" id="S4.T2.1.10.9.2.1" style="background-color:#FFFFCC;">
          12.64
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.10.9.3">
         <span class="ltx_text" id="S4.T2.1.10.9.3.1" style="background-color:#FFFFCC;">
          45.25
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.10.9.4">
         <span class="ltx_text" id="S4.T2.1.10.9.4.1" style="background-color:#FFFFCC;">
          8.35
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.10.9.5">
         <span class="ltx_text" id="S4.T2.1.10.9.5.1" style="background-color:#FFFFCC;">
          37.39
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T2.1.11.10" style="background-color:#FFFFCC;">
        <td class="ltx_td ltx_align_left" id="S4.T2.1.11.10.1">
         <span class="ltx_text" id="S4.T2.1.11.10.1.1" style="background-color:#FFFFCC;">
          -traversable goal
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.11.10.2">
         <span class="ltx_text" id="S4.T2.1.11.10.2.1" style="background-color:#FFFFCC;">
          11.77
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.11.10.3">
         <span class="ltx_text" id="S4.T2.1.11.10.3.1" style="background-color:#FFFFCC;">
          43.49
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.11.10.4">
         <span class="ltx_text" id="S4.T2.1.11.10.4.1" style="background-color:#FFFFCC;">
          7.09
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.11.10.5">
         <span class="ltx_text" id="S4.T2.1.11.10.5.1" style="background-color:#FFFFCC;">
          34.50
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T2.1.12.11" style="background-color:#FFE6CC;">
        <td class="ltx_td ltx_align_left ltx_border_t" colspan="5" id="S4.T2.1.12.11.1">
         <span class="ltx_text ltx_font_bold" id="S4.T2.1.12.11.1.1" style="background-color:#FFE6CC;">
          Influence of LLM-based modules
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T2.1.13.12" style="background-color:#FFE6CC;">
        <td class="ltx_td ltx_align_left" id="S4.T2.1.13.12.1">
         <span class="ltx_text" id="S4.T2.1.13.12.1.1" style="background-color:#FFE6CC;">
          OPEx
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.13.12.2">
         <span class="ltx_text" id="S4.T2.1.13.12.2.1" style="background-color:#FFE6CC;">
          13.48
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.13.12.3">
         <span class="ltx_text" id="S4.T2.1.13.12.3.1" style="background-color:#FFE6CC;">
          48.61
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.13.12.4">
         <span class="ltx_text" id="S4.T2.1.13.12.4.1" style="background-color:#FFE6CC;">
          9.08
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.13.12.5">
         <span class="ltx_text" id="S4.T2.1.13.12.5.1" style="background-color:#FFE6CC;">
          35.91
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T2.1.14.13" style="background-color:#FFE6CC;">
        <td class="ltx_td ltx_align_left" id="S4.T2.1.14.13.1">
         <span class="ltx_text" id="S4.T2.1.14.13.1.1" style="background-color:#FFE6CC;">
          -Planner
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.14.13.2">
         <span class="ltx_text" id="S4.T2.1.14.13.2.1" style="background-color:#FFE6CC;">
          8.10
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.14.13.3">
         <span class="ltx_text" id="S4.T2.1.14.13.3.1" style="background-color:#FFE6CC;">
          40.16
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.14.13.4">
         <span class="ltx_text" id="S4.T2.1.14.13.4.1" style="background-color:#FFE6CC;">
          5.72
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.14.13.5">
         <span class="ltx_text" id="S4.T2.1.14.13.5.1" style="background-color:#FFE6CC;">
          30.57
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T2.1.15.14" style="background-color:#FFE6CC;">
        <td class="ltx_td ltx_align_left" id="S4.T2.1.15.14.1">
         <span class="ltx_text" id="S4.T2.1.15.14.1.1" style="background-color:#FFE6CC;">
          -Observer
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.15.14.2">
         <span class="ltx_text" id="S4.T2.1.15.14.2.1" style="background-color:#FFE6CC;">
          13.41
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.15.14.3">
         <span class="ltx_text" id="S4.T2.1.15.14.3.1" style="background-color:#FFE6CC;">
          45.62
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.15.14.4">
         <span class="ltx_text" id="S4.T2.1.15.14.4.1" style="background-color:#FFE6CC;">
          8.58
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.15.14.5">
         <span class="ltx_text" id="S4.T2.1.15.14.5.1" style="background-color:#FFE6CC;">
          37.76
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T2.1.16.15" style="background-color:#E6E6FF;">
        <td class="ltx_td ltx_align_left ltx_border_t" colspan="5" id="S4.T2.1.16.15.1">
         <span class="ltx_text ltx_font_bold" id="S4.T2.1.16.15.1.1" style="background-color:#E6E6FF;">
          Influence of prior knowledge (On ALFWorld)
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T2.1.17.16" style="background-color:#E6E6FF;">
        <td class="ltx_td ltx_align_left" id="S4.T2.1.17.16.1">
         <span class="ltx_text" id="S4.T2.1.17.16.1.1" style="background-color:#E6E6FF;">
          ReAct
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.17.16.2">
         <span class="ltx_text" id="S4.T2.1.17.16.2.1" style="background-color:#E6E6FF;">
          -
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.17.16.3">
         <span class="ltx_text" id="S4.T2.1.17.16.3.1" style="background-color:#E6E6FF;">
          -
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.17.16.4">
         <span class="ltx_text" id="S4.T2.1.17.16.4.1" style="background-color:#E6E6FF;">
          -
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.17.16.5">
         <span class="ltx_text" id="S4.T2.1.17.16.5.1" style="background-color:#E6E6FF;">
          66
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T2.1.18.17" style="background-color:#E6E6FF;">
        <td class="ltx_td ltx_align_left" id="S4.T2.1.18.17.1">
         <span class="ltx_text" id="S4.T2.1.18.17.1.1" style="background-color:#E6E6FF;">
          OPEx
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.18.17.2">
         <span class="ltx_text" id="S4.T2.1.18.17.2.1" style="background-color:#E6E6FF;">
          -
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.18.17.3">
         <span class="ltx_text" id="S4.T2.1.18.17.3.1" style="background-color:#E6E6FF;">
          -
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.18.17.4">
         <span class="ltx_text" id="S4.T2.1.18.17.4.1" style="background-color:#E6E6FF;">
          -
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.18.17.5">
         <span class="ltx_text" id="S4.T2.1.18.17.5.1" style="background-color:#E6E6FF;">
          73
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T2.1.19.18" style="background-color:#E6E6FF;">
        <td class="ltx_td ltx_align_left" id="S4.T2.1.19.18.1">
         <span class="ltx_text" id="S4.T2.1.19.18.1.1" style="background-color:#E6E6FF;">
          OPEx-L
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.19.18.2">
         <span class="ltx_text" id="S4.T2.1.19.18.2.1" style="background-color:#E6E6FF;">
          -
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.19.18.3">
         <span class="ltx_text" id="S4.T2.1.19.18.3.1" style="background-color:#E6E6FF;">
          -
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.19.18.4">
         <span class="ltx_text" id="S4.T2.1.19.18.4.1" style="background-color:#E6E6FF;">
          -
         </span>
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T2.1.19.18.5">
         <span class="ltx_text" id="S4.T2.1.19.18.5.1" style="background-color:#E6E6FF;">
          78
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T2.1.20.19" style="background-color:#E6E6FF;">
        <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T2.1.20.19.1">
         <span class="ltx_text" id="S4.T2.1.20.19.1.1" style="background-color:#E6E6FF;">
          OPEx-H
         </span>
        </td>
        <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T2.1.20.19.2">
         <span class="ltx_text" id="S4.T2.1.20.19.2.1" style="background-color:#E6E6FF;">
          -
         </span>
        </td>
        <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T2.1.20.19.3">
         <span class="ltx_text" id="S4.T2.1.20.19.3.1" style="background-color:#E6E6FF;">
          -
         </span>
        </td>
        <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T2.1.20.19.4">
         <span class="ltx_text" id="S4.T2.1.20.19.4.1" style="background-color:#E6E6FF;">
          -
         </span>
        </td>
        <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T2.1.20.19.5">
         <span class="ltx_text" id="S4.T2.1.20.19.5.1" style="background-color:#E6E6FF;">
          84
         </span>
        </td>
       </tr>
      </tbody>
     </table>
     <figcaption class="ltx_caption ltx_centering">
      <span class="ltx_tag ltx_tag_table">
       Table 2:
      </span>
      Ablation Studies of OPEx. OPEx-S denotes the OPEx with stronger perception models, OPEx-P denotes the OPEx with perfect ground-truth depth prediction and instance segmentation, OPEx-L denotes the OPEx with prior knowledge learned from the environment, and OPEx-H denotes the OPEx with prior knowledge provided by humans.
     </figcaption>
    </figure>
    <figure class="ltx_table" id="S4.T3">
     <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T3.1">
      <thead class="ltx_thead">
       <tr class="ltx_tr" id="S4.T3.1.1.1">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.1">
         Method
        </th>
        <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.2">
         SR
        </th>
        <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.3">
         GC
        </th>
        <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.4">
         PLWSR
        </th>
        <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.5">
         PLWGC
        </th>
       </tr>
      </thead>
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="S4.T3.1.2.1">
        <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.2.1.1">
         OPEx
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.2.1.2">
         38.12
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.2.1.3">
         46.13
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.2.1.4">
         9.03
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.2.1.5">
         13.45
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T3.1.3.2">
        <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T3.1.3.2.1">
         FILM
        </td>
        <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T3.1.3.2.2">
         0.00
        </td>
        <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T3.1.3.2.3">
         12.18
        </td>
        <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T3.1.3.2.4">
         0.00
        </td>
        <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T3.1.3.2.5">
         2.78
        </td>
       </tr>
      </tbody>
     </table>
     <figcaption class="ltx_caption ltx_centering">
      <span class="ltx_tag ltx_tag_table">
       Table 3:
      </span>
      Performance comparison with the baseline trained on same amount of data.
     </figcaption>
    </figure>
   </section>
   <section class="ltx_paragraph" id="S4.SS3.SSS0.Px5">
    <h4 class="ltx_title ltx_title_paragraph">
     Low demand for in-domain data
    </h4>
    <div class="ltx_para" id="S4.SS3.SSS0.Px5.p1">
     <p class="ltx_p" id="S4.SS3.SSS0.Px5.p1.1">
      To assess the efficiency of in-domain data usage, we conducted experiments comparing OPEx with the baseline FILM. The FILM is trained on identical data used for in-context learning of OPEx. The corresponding results are presented in Table
      <a class="ltx_ref" href="#S4.T3" title="Table 3 ‣ Influence of prior knowledge ‣ 4.3 Ablation Study and Analysis ‣ 4 Experiments and Discussion ‣ OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied Instruction Following">
       <span class="ltx_text ltx_ref_tag">
        3
       </span>
      </a>
      . Our findings indicate that OPEx markedly outperforms FILM across all evaluation metrics in the unseen validation split. Empirically, this suggests that OPEx requires significantly less in-domain data compared to FILM. This controlled study underscores the potential of addressing embodied tasks through an LLM-based framework. This framework achieves low in-domain data demand EIF by integrating feedback mechanisms, closed-loop grounded planning, and action, harmonized with the reasoning and common sense capabilities of Large Language Models (LLMs). Moreover, it also prompts our further exploration into the trade-off between in-domain data efficiency and inference overhead, inspiring future directions, such as devising agents that adeptly integrate both common sense and in-domain knowledge in a data-efficient manner.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S4.SS3.SSS0.Px6">
    <h4 class="ltx_title ltx_title_paragraph">
     Error mode analysis
    </h4>
    <div class="ltx_para" id="S4.SS3.SSS0.Px6.p1">
     <p class="ltx_p" id="S4.SS3.SSS0.Px6.p1.1">
      We conduct the error mode analysis of OPEx on the valid unseen split. The corresponding statics are shown in Table
      <a class="ltx_ref" href="#S4.T4" title="Table 4 ‣ Error mode analysis ‣ 4.3 Ablation Study and Analysis ‣ 4 Experiments and Discussion ‣ OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied Instruction Following">
       <span class="ltx_text ltx_ref_tag">
        4
       </span>
      </a>
      . While our approach to calculate the statistics may vary from that of FILM, we have also incorporated FILM’s statistics from the original paper
      <cite class="ltx_cite ltx_citemacro_cite">
       Min et al. (
       <a class="ltx_ref" href="#bib.bib21" title="">
        2021
       </a>
       )
      </cite>
      for reference. Since we conduct the task decomposition with the LLM-based planner, which does not follow the template assumption, we don’t have statistics on language processing errors. As shown in the table, the goal object not found error typically account for a great ratio of all kinds of error, indicating both FILM and OPEx suffer from imperfect perception models. Besides, the interactive exploration of the LLM-based executor and the deterministic heuristics probably brings a lower error rate of collisions and the error caused by the target object in a closed receptacle.
     </p>
    </div>
    <figure class="ltx_table" id="S4.T4">
     <table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T4.1">
      <thead class="ltx_thead">
       <tr class="ltx_tr" id="S4.T4.1.1.1">
        <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T4.1.1.1.1">
         Error mode
        </th>
        <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T4.1.1.1.2">
         FILM
        </th>
        <th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T4.1.1.1.3">
         OPEx
        </th>
       </tr>
      </thead>
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="S4.T4.1.2.1">
        <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.1.2.1.1">
         Goal object not found
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.1.2.1.2">
         26.07
        </td>
        <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.1.2.1.3">
         27.36
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T4.1.3.2">
        <td class="ltx_td ltx_align_left" id="S4.T4.1.3.2.1">
         Interaction failures
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T4.1.3.2.2">
         8.54
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T4.1.3.2.3">
         12.80
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T4.1.4.3">
        <td class="ltx_td ltx_align_left" id="S4.T4.1.4.3.1">
         Collisions
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T4.1.4.3.2">
         11.00
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T4.1.4.3.3">
         9.84
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T4.1.5.4">
        <td class="ltx_td ltx_align_left" id="S4.T4.1.5.4.1">
         Object in closed receptacle
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T4.1.5.4.2">
         16.16
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T4.1.5.4.3">
         11.61
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T4.1.6.5">
        <td class="ltx_td ltx_align_left" id="S4.T4.1.6.5.1">
         Language processing error
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T4.1.6.5.2">
         24.54
        </td>
        <td class="ltx_td ltx_align_left" id="S4.T4.1.6.5.3">
         -
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T4.1.7.6">
        <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T4.1.7.6.1">
         Others
        </td>
        <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T4.1.7.6.2">
         13.69
        </td>
        <td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T4.1.7.6.3">
         38.39
        </td>
       </tr>
      </tbody>
     </table>
     <figcaption class="ltx_caption ltx_centering">
      <span class="ltx_tag ltx_tag_table">
       Table 4:
      </span>
      Error mode analysis of OPEx on the valid unseen split.
     </figcaption>
    </figure>
   </section>
  </section>
 </section>
 <section class="ltx_section" id="S5">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    5
   </span>
   Related Work
  </h2>
  <section class="ltx_paragraph" id="S5.SS0.SSS0.Px1">
   <h4 class="ltx_title ltx_title_paragraph">
    LLM-based Agents
   </h4>
   <div class="ltx_para" id="S5.SS0.SSS0.Px1.p1">
    <p class="ltx_p" id="S5.SS0.SSS0.Px1.p1.1">
     Significant progress has been made for LLM-based agents, which mainly focus on the following three aspects.
     <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.1.1">
      LLM-centric Planning
     </span>
     utilizes LLMs to generate plans in dynamic environments. It can be further categorized into methods planning without feedback
     <cite class="ltx_cite ltx_citemacro_cite">
      Huang et al. (
      <a class="ltx_ref" href="#bib.bib11" title="">
       2022a
      </a>
      ); Fan et al. (
      <a class="ltx_ref" href="#bib.bib8" title="">
       2022
      </a>
      ); Yao et al. (
      <a class="ltx_ref" href="#bib.bib46" title="">
       2022
      </a>
      ); Huang et al. (
      <a class="ltx_ref" href="#bib.bib12" title="">
       2022b
      </a>
      ); Xiang et al. (
      <a class="ltx_ref" href="#bib.bib45" title="">
       2023
      </a>
      ); Lin et al. (
      <a class="ltx_ref" href="#bib.bib16" title="">
       2023
      </a>
      )
     </cite>
     and approaches planning with feedback from environment, human, and model
     <cite class="ltx_cite ltx_citemacro_cite">
      Wang et al. (
      <a class="ltx_ref" href="#bib.bib40" title="">
       2023a
      </a>
      ); Zhu et al. (
      <a class="ltx_ref" href="#bib.bib47" title="">
       2023
      </a>
      ); Shinn et al. (
      <a class="ltx_ref" href="#bib.bib32" title="">
       2023
      </a>
      ); Wang et al. (
      <a class="ltx_ref" href="#bib.bib42" title="">
       2023c
      </a>
      ); Rana et al. (
      <a class="ltx_ref" href="#bib.bib27" title="">
       2023
      </a>
      ); Guan et al. (
      <a class="ltx_ref" href="#bib.bib9" title="">
       2023
      </a>
      ); Kim et al. (
      <a class="ltx_ref" href="#bib.bib14" title="">
       2023
      </a>
      )
     </cite>
     .
     <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.1.2">
      LLM-oriented Memory
     </span>
     stores information from the environment and boosts agents’ capabilities of experience accumulation and self-evolving to facilitate future actions.
     <cite class="ltx_cite ltx_citemacro_cite">
      Significant-gravitas et al. (
      <a class="ltx_ref" href="#bib.bib35" title="">
       2023
      </a>
      ); Shinn et al. (
      <a class="ltx_ref" href="#bib.bib32" title="">
       2023
      </a>
      ); Wang et al. (
      <a class="ltx_ref" href="#bib.bib40" title="">
       2023a
      </a>
      ); Majumder et al. (
      <a class="ltx_ref" href="#bib.bib20" title="">
       2023
      </a>
      ); Wang et al. (
      <a class="ltx_ref" href="#bib.bib41" title="">
       2023b
      </a>
      )
     </cite>
     <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.1.3">
      LLM-centric Action Policy
     </span>
     grounds the plans made by the agent into feasible action space
     <cite class="ltx_cite ltx_citemacro_cite">
      Huang et al. (
      <a class="ltx_ref" href="#bib.bib11" title="">
       2022a
      </a>
      ); Schick et al. (
      <a class="ltx_ref" href="#bib.bib29" title="">
       2023
      </a>
      )
     </cite>
     Notably, our LLM-centric agent differs from Voyager
     <cite class="ltx_cite ltx_citemacro_cite">
      Wang et al. (
      <a class="ltx_ref" href="#bib.bib40" title="">
       2023a
      </a>
      )
     </cite>
     and GITM
     <cite class="ltx_cite ltx_citemacro_cite">
      Zhu et al. (
      <a class="ltx_ref" href="#bib.bib47" title="">
       2023
      </a>
      )
     </cite>
     by mitigating the instruction grounding problem with dynamically adjusted plans from various granularity based on task-centric feedback from the environment.
    </p>
   </div>
  </section>
  <section class="ltx_paragraph" id="S5.SS0.SSS0.Px2">
   <h4 class="ltx_title ltx_title_paragraph">
    Instruction Following in Embodied Environment
   </h4>
   <div class="ltx_para" id="S5.SS0.SSS0.Px2.p1">
    <p class="ltx_p" id="S5.SS0.SSS0.Px2.p1.1">
     Prior work on EIF in embodied environments can be categorized into two classes:
     <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.1.1">
      Supervisely trained end-to-end or modular-based methods
     </span>
     that are eager for supervision signals from training data and hard to generalize due to the lack of abstraction and reasoning abilities
     <cite class="ltx_cite ltx_citemacro_cite">
      Shridhar et al. (
      <a class="ltx_ref" href="#bib.bib33" title="">
       2020a
      </a>
      ); Suglia et al. (
      <a class="ltx_ref" href="#bib.bib38" title="">
       2021
      </a>
      ); Pashevich et al. (
      <a class="ltx_ref" href="#bib.bib26" title="">
       2021
      </a>
      ); Blukis et al. (
      <a class="ltx_ref" href="#bib.bib3" title="">
       2022
      </a>
      ); Singh et al. (
      <a class="ltx_ref" href="#bib.bib36" title="">
       2020
      </a>
      ); Liu et al. (
      <a class="ltx_ref" href="#bib.bib17" title="">
       2022a
      </a>
      ); Min et al. (
      <a class="ltx_ref" href="#bib.bib21" title="">
       2021
      </a>
      ); Sharma et al. (
      <a class="ltx_ref" href="#bib.bib31" title="">
       2021
      </a>
      )
     </cite>
     , and
     <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.1.2">
      LLM-based methods
     </span>
     that utilizes LLMs’ reasoning capability
     <cite class="ltx_cite ltx_citemacro_cite">
      Inoue and Ohashi (
      <a class="ltx_ref" href="#bib.bib13" title="">
       2022
      </a>
      ); Song et al. (
      <a class="ltx_ref" href="#bib.bib37" title="">
       2023
      </a>
      )
     </cite>
     . Different from Prompter
     <cite class="ltx_cite ltx_citemacro_cite">
      Inoue and Ohashi (
      <a class="ltx_ref" href="#bib.bib13" title="">
       2022
      </a>
      )
     </cite>
     and LLM-Planner
     <cite class="ltx_cite ltx_citemacro_cite">
      Song et al. (
      <a class="ltx_ref" href="#bib.bib37" title="">
       2023
      </a>
      )
     </cite>
     , which introduce LLMs only for target location finding and dynamic task decomposition, our method is an LLM-centric framework and decouples reasoning tasks for decision masking problem with multiple LLM-based roles, where the LLMs build the plan, adjust the plan, and ground the plan into structured action spaces. Besides, our method evolves based on the feedback, providing promising future research directions, including human-in-the-loop learning, multi-source feedback mixing and refining, etc.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S6">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    6
   </span>
   Conclusion
  </h2>
  <div class="ltx_para" id="S6.p1">
   <p class="ltx_p" id="S6.p1.1">
    We introduce OPEx, an LLM-centric framework tailored for Embodied Instruction Following (EIF), and undertake extensive evaluations to dissect the influence of its distinct components. Building on this foundation, we further improve OPEx by integrating world knowledge with a multi-agent dialogue strategy to further harness LLMs’ potential in addressing EIF challenges. Our comprehensive analysis reveals that an LLM-centric design significantly enhances EIF performance, pinpointing visual perception and low-level action execution as crucial bottlenecks. Additionally, our findings demonstrate that integrating a multi-agent dialogue mechanism within LLMs markedly boosts their effectiveness, offering promising directions for future research in embodied learning.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="Sx1">
  <h2 class="ltx_title ltx_title_section">
   Limitations
  </h2>
  <div class="ltx_para" id="Sx1.p1">
   <p class="ltx_p" id="Sx1.p1.1">
    While our study introduces the OPEx framework and a dialogue-based mechanism for solving EIF tasks, it is not without its limitations. First, the reliance on large language models (LLMs) and the complexity of the multi-agent system introduce challenges in interpretability and computational efficiency. These models demand considerable resources by extensively communicating with ChatGPT, which might limit their applicability in resource-constrained environments. Second, our experiments are conducted within the confines of the ALFRED and ALFWORLD benchmarks, which, while comprehensive, may not encompass all possible real-world scenarios an embodied agent might encounter. Third, the integration of visual perception and action execution as identified bottlenecks suggests that further refinement in these areas is necessary to achieve truly seamless and adaptive embodied AI systems. Future work should aim to address these limitations, exploring more efficient model architectures, broader applicability across diverse environments, and enhanced methods for achieving naturalistic human-agent interaction.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="Sx2">
  <h2 class="ltx_title ltx_title_section">
   Ethical Concerns
  </h2>
  <div class="ltx_para" id="Sx2.p1">
   <p class="ltx_p" id="Sx2.p1.1">
    We do not foresee an immediate ethical or societal impact resulting from our work.
However, as an LLM application, we acknowledge that OPEx could in some way be affected by various types of hallucinations introduced by the LLMs.
We therefore urge researchers and practitioners to use our proposed framework in a mindful way, especially when deploying such LLM-centric agents in real world applications..
   </p>
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Baker et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Bowen Baker, Ilge Akkaya, Peter Zhokov, Joost Huizinga, Jie Tang, Adrien Ecoffet, Brandon Houghton, Raul Sampedro, and Jeff Clune. 2022.
    </span>
    <span class="ltx_bibblock">
     Video pretraining (vpt): Learning to act by watching unlabeled online videos.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">
      Advances in Neural Information Processing Systems
     </em>
     , 35:24639–24654.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Bhat et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Shariq Farooq Bhat, Reiner Birkl, Diana Wofk, Peter Wonka, and Matthias Müller. 2023.
    </span>
    <span class="ltx_bibblock">
     Zoedepth: Zero-shot transfer by combining relative and metric depth.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">
      arXiv preprint arXiv:2302.12288
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Blukis et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Valts Blukis, Chris Paxton, Dieter Fox, Animesh Garg, and Yoav Artzi. 2022.
    </span>
    <span class="ltx_bibblock">
     A persistent spatial semantic representation for high-level natural language instruction execution.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">
      Conference on Robot Learning
     </em>
     , pages 706–717. PMLR.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chase (2022)
    </span>
    <span class="ltx_bibblock">
     Harrison Chase. 2022.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://github.com/hwchase17/langchain" target="_blank" title="">
      LangChain
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Yaran Chen, Wenbo Cui, Yuanwen Chen, Mining Tan, Xinyao Zhang, Dongbin Zhao, and He Wang. 2023.
    </span>
    <span class="ltx_bibblock">
     Robogpt: an intelligent agent of making embodied long-term decisions for daily instruction tasks.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">
      arXiv preprint arXiv:2311.15649
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Dong et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Bin Dong, Fangao Zeng, Tiancai Wang, Xiangyu Zhang, and Yichen Wei. 2021.
    </span>
    <span class="ltx_bibblock">
     Solq: Segmenting objects by learning queries.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">
      Advances in Neural Information Processing Systems
     </em>
     , 34:21898–21909.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Driess et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Danny Driess, Fei Xia, Mehdi SM Sajjadi, Corey Lynch, Aakanksha Chowdhery, Brian Ichter, Ayzaan Wahid, Jonathan Tompson, Quan Vuong, Tianhe Yu, et al. 2023.
    </span>
    <span class="ltx_bibblock">
     Palm-e: An embodied multimodal language model.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">
      arXiv preprint arXiv:2303.03378
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Fan et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Linxi Fan, Guanzhi Wang, Yunfan Jiang, Ajay Mandlekar, Yuncong Yang, Haoyi Zhu, Andrew Tang, De-An Huang, Yuke Zhu, and Anima Anandkumar. 2022.
    </span>
    <span class="ltx_bibblock">
     Minedojo: Building open-ended embodied agents with internet-scale knowledge.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">
      arXiv preprint arXiv:2206.08853
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Guan et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Lin Guan, Karthik Valmeekam, Sarath Sreedharan, and Subbarao Kambhampati. 2023.
    </span>
    <span class="ltx_bibblock">
     Leveraging pre-trained large language models to construct and utilize world models for model-based task planning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">
      arXiv preprint arXiv:2305.14909
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     He et al. (2017)
    </span>
    <span class="ltx_bibblock">
     Kaiming He, Georgia Gkioxari, Piotr Dollár, and Ross Girshick. 2017.
    </span>
    <span class="ltx_bibblock">
     Mask r-cnn.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">
      Proceedings of the IEEE international conference on computer vision
     </em>
     , pages 2961–2969.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Huang et al. (2022a)
    </span>
    <span class="ltx_bibblock">
     Wenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch. 2022a.
    </span>
    <span class="ltx_bibblock">
     Language models as zero-shot planners: Extracting actionable knowledge for embodied agents.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">
      International Conference on Machine Learning
     </em>
     , pages 9118–9147. PMLR.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Huang et al. (2022b)
    </span>
    <span class="ltx_bibblock">
     Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, et al. 2022b.
    </span>
    <span class="ltx_bibblock">
     Inner monologue: Embodied reasoning through planning with language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">
      arXiv preprint arXiv:2207.05608
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Inoue and Ohashi (2022)
    </span>
    <span class="ltx_bibblock">
     Yuki Inoue and Hiroki Ohashi. 2022.
    </span>
    <span class="ltx_bibblock">
     Prompter: Utilizing large language model prompting for a data efficient embodied instruction following.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">
      arXiv preprint arXiv:2211.03267
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kim et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Geunwoo Kim, Pierre Baldi, and Stephen McAleer. 2023.
    </span>
    <span class="ltx_bibblock">
     Language models can solve computer tasks.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">
      arXiv preprint arXiv:2303.17491
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liang et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Jacky Liang, Wenlong Huang, Fei Xia, Peng Xu, Karol Hausman, Brian Ichter, Pete Florence, and Andy Zeng. 2022.
    </span>
    <span class="ltx_bibblock">
     Code as policies: Language model programs for embodied control.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">
      arXiv preprint arXiv:2209.07753
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lin et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Bill Yuchen Lin, Yicheng Fu, Karina Yang, Faeze Brahman, Shiyu Huang, Chandra Bhagavatula, Prithviraj Ammanabrolu, Yejin Choi, and Xiang Ren. 2023.
    </span>
    <span class="ltx_bibblock">
     Swiftsage: A generative agent with fast and slow thinking for complex interactive tasks.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">
      arXiv preprint arXiv:2305.17390
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. (2022a)
    </span>
    <span class="ltx_bibblock">
     Haoyu Liu, Yang Liu, Hongkai He, and Hangfang Yang. 2022a.
    </span>
    <span class="ltx_bibblock">
     Lebp–language expectation &amp; binding policy: A two-stream framework for embodied vision-and-language interaction task learning agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">
      arXiv preprint arXiv:2203.04637
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. (2022b)
    </span>
    <span class="ltx_bibblock">
     Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2022b.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.deelio-1.10" target="_blank" title="">
      What makes good in-context examples for gpt-3?
     </a>
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">
      Proceedings of Deep Learning Inside Out (DeeLIO 2022): The 3rd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. (2022c)
    </span>
    <span class="ltx_bibblock">
     Xiaotian Liu, Hector Palacios, and Christian Muise. 2022c.
    </span>
    <span class="ltx_bibblock">
     A planning based neural-symbolic approach for embodied instruction following.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">
      Interactions
     </em>
     , 9(8):17.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Majumder et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Bodhisattwa Prasad Majumder, Bhavana Dalvi Mishra, Peter Jansen, Oyvind Tafjord, Niket Tandon, Li Zhang, Chris Callison-Burch, and Peter Clark. 2023.
    </span>
    <span class="ltx_bibblock">
     Clin: A continually learning language agent for rapid task adaptation and generalization.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">
      arXiv preprint arXiv:2310.10134
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Min et al. (2021)
    </span>
    <span class="ltx_bibblock">
     So Yeon Min, Devendra Singh Chaplot, Pradeep Ravikumar, Yonatan Bisk, and Ruslan Salakhutdinov. 2021.
    </span>
    <span class="ltx_bibblock">
     Film: Following instructions in language with modular methods.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">
      arXiv preprint arXiv:2110.07342
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Murray and Cakmak (2022)
    </span>
    <span class="ltx_bibblock">
     Michael Murray and Maya Cakmak. 2022.
    </span>
    <span class="ltx_bibblock">
     Following natural language instructions for household tasks with landmark guided search and reinforced pose adjustment.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">
      IEEE Robotics and Automation Letters
     </em>
     , 7(3):6870–6877.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Nguyen et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Van-Quang Nguyen, Masanori Suganuma, and Takayuki Okatani. 2021.
    </span>
    <span class="ltx_bibblock">
     Look wide and interpret twice: Improving performance on interactive instruction-following tasks.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">
      arXiv preprint arXiv:2106.00596
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib24">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Nottingham et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Kolby Nottingham, Litian Liang, Daeyun Shin, Charless C Fowlkes, Roy Fox, and Sameer Singh. 2021.
    </span>
    <span class="ltx_bibblock">
     Modular framework for visuomotor language grounding.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">
      arXiv preprint arXiv:2109.02161
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib25">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     OpenAI (2023)
    </span>
    <span class="ltx_bibblock">
     R OpenAI. 2023.
    </span>
    <span class="ltx_bibblock">
     Gpt-4 technical report.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">
      arXiv
     </em>
     , pages 2303–08774.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib26">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Pashevich et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Alexander Pashevich, Cordelia Schmid, and Chen Sun. 2021.
    </span>
    <span class="ltx_bibblock">
     Episodic transformer for vision-and-language navigation.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">
      Proceedings of the IEEE/CVF International Conference on Computer Vision
     </em>
     , pages 15942–15952.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib27">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Rana et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Krishan Rana, Jesse Haviland, Sourav Garg, Jad Abou-Chakra, Ian Reid, and Niko Suenderhauf. 2023.
    </span>
    <span class="ltx_bibblock">
     Sayplan: Grounding large language models using 3d scene graphs for scalable task planning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">
      arXiv preprint arXiv:2307.06135
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib28">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ronneberger et al. (2015)
    </span>
    <span class="ltx_bibblock">
     Olaf Ronneberger, Philipp Fischer, and Thomas Brox. 2015.
    </span>
    <span class="ltx_bibblock">
     U-net: Convolutional networks for biomedical image segmentation.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">
      Medical Image Computing and Computer-Assisted Intervention–MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18
     </em>
     , pages 234–241. Springer.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib29">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Schick et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. 2023.
    </span>
    <span class="ltx_bibblock">
     Toolformer: Language models can teach themselves to use tools.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">
      arXiv preprint arXiv:2302.04761
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib30">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sethian (1996)
    </span>
    <span class="ltx_bibblock">
     James A Sethian. 1996.
    </span>
    <span class="ltx_bibblock">
     A fast marching level set method for monotonically advancing fronts.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">
      proceedings of the National Academy of Sciences
     </em>
     , 93(4):1591–1595.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib31">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sharma et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Pratyusha Sharma, Antonio Torralba, and Jacob Andreas. 2021.
    </span>
    <span class="ltx_bibblock">
     Skill induction and planning with latent language.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">
      arXiv preprint arXiv:2110.01517
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib32">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shinn et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Noah Shinn, Federico Cassano, Beck Labash, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. 2023.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2303.11366" target="_blank" title="">
      Reflexion: Language agents with verbal reinforcement learning
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib33">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shridhar et al. (2020a)
    </span>
    <span class="ltx_bibblock">
     Mohit Shridhar, Jesse Thomason, Daniel Gordon, Yonatan Bisk, Winson Han, Roozbeh Mottaghi, Luke Zettlemoyer, and Dieter Fox. 2020a.
    </span>
    <span class="ltx_bibblock">
     Alfred: A benchmark for interpreting grounded instructions for everyday tasks.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">
      Proceedings of the IEEE/CVF conference on computer vision and pattern recognition
     </em>
     , pages 10740–10749.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib34">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shridhar et al. (2020b)
    </span>
    <span class="ltx_bibblock">
     Mohit Shridhar, Xingdi Yuan, Marc-Alexandre Côté, Yonatan Bisk, Adam Trischler, and Matthew Hausknecht. 2020b.
    </span>
    <span class="ltx_bibblock">
     Alfworld: Aligning text and embodied environments for interactive learning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">
      arXiv preprint arXiv:2010.03768
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib35">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Significant-gravitas et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Significant-gravitas et al. 2023.
    </span>
    <span class="ltx_bibblock">
     Significant-gravitas/auto-gpt: An experimental open-source attempt to make gpt-4 fully autonomous.
    </span>
    <span class="ltx_bibblock">
     https://github.com/Significant-Gravitas/Auto-GPT.
    </span>
    <span class="ltx_bibblock">
     Open-Source Software.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib36">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Singh et al. (2020)
    </span>
    <span class="ltx_bibblock">
     Kunal Pratap Singh, Suvaansh Bhambri, Byeonghwi Kim, Roozbeh Mottaghi, and Jonghyun Choi. 2020.
    </span>
    <span class="ltx_bibblock">
     Factorizing perception and policy for interactive instruction following.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">
      arXiv preprint arXiv:2012.03208
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib37">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Song et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Chan Hee Song, Jiaman Wu, Clayton Washington, Brian M Sadler, Wei-Lun Chao, and Yu Su. 2023.
    </span>
    <span class="ltx_bibblock">
     Llm-planner: Few-shot grounded planning for embodied agents with large language models.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">
      Proceedings of the IEEE/CVF International Conference on Computer Vision
     </em>
     , pages 2998–3009.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib38">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Suglia et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Alessandro Suglia, Qiaozi Gao, Jesse Thomason, Govind Thattai, and Gaurav Sukhatme. 2021.
    </span>
    <span class="ltx_bibblock">
     Embodied bert: A transformer model for embodied, language-guided visual task completion.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">
      arXiv preprint arXiv:2108.04927
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib39">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Touvron et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023.
    </span>
    <span class="ltx_bibblock">
     Llama: Open and efficient foundation language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">
      arXiv preprint arXiv:2302.13971
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib40">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. 2023a.
    </span>
    <span class="ltx_bibblock">
     Voyager: An open-ended embodied agent with large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">
      arXiv preprint arXiv:2305.16291
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib41">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Zihao Wang, Shaofei Cai, Anji Liu, Yonggang Jin, Jinbing Hou, Bowei Zhang, Haowei Lin, Zhaofeng He, Zilong Zheng, Yaodong Yang, et al. 2023b.
    </span>
    <span class="ltx_bibblock">
     Jarvis-1: Open-world multi-task agents with memory-augmented multimodal language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">
      arXiv preprint arXiv:2311.05997
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib42">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2023c)
    </span>
    <span class="ltx_bibblock">
     Zihao Wang, Shaofei Cai, Anji Liu, Xiaojian Ma, and Yitao Liang. 2023c.
    </span>
    <span class="ltx_bibblock">
     Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">
      arXiv preprint arXiv:2302.01560
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib43">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wei et al. (2022a)
    </span>
    <span class="ltx_bibblock">
     Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. 2022a.
    </span>
    <span class="ltx_bibblock">
     Emergent abilities of large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">
      arXiv preprint arXiv:2206.07682
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib44">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wei et al. (2022b)
    </span>
    <span class="ltx_bibblock">
     Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022b.
    </span>
    <span class="ltx_bibblock">
     Chain-of-thought prompting elicits reasoning in large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">
      Advances in Neural Information Processing Systems
     </em>
     , 35:24824–24837.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib45">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xiang et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Jiannan Xiang, Tianhua Tao, Yi Gu, Tianmin Shu, Zirui Wang, Zichao Yang, and Zhiting Hu. 2023.
    </span>
    <span class="ltx_bibblock">
     Language models meet world models: Embodied experiences enhance language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">
      arXiv preprint arXiv:2305.10626
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib46">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yao et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2022.
    </span>
    <span class="ltx_bibblock">
     React: Synergizing reasoning and acting in language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">
      arXiv preprint arXiv:2210.03629
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib47">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhu et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su, Chenyu Yang, Gao Huang, Bin Li, Lewei Lu, Xiaogang Wang, et al. 2023.
    </span>
    <span class="ltx_bibblock">
     Ghost in the minecraft: Generally capable agents for open-world enviroments via large language models with text-based knowledge and memory.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">
      arXiv preprint arXiv:2305.17144
     </em>
     .
    </span>
   </li>
  </ul>
 </section>
 <div class="ltx_pagination ltx_role_newpage">
 </div>
 <div class="ltx_pagination ltx_role_newpage">
 </div>
 <section class="ltx_appendix" id="A1">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix A
   </span>
   Task Example in ALFRED
  </h2>
  <div class="ltx_para" id="A1.p1">
   <p class="ltx_p" id="A1.p1.7">
    As shown in Figure
    <a class="ltx_ref" href="#A1.F2" title="Figure 2 ‣ Appendix A Task Example in ALFRED ‣ OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied Instruction Following">
     <span class="ltx_text ltx_ref_tag">
      2
     </span>
    </a>
    , the ALFRED benchmark
    <cite class="ltx_cite ltx_citemacro_cite">
     Shridhar et al. (
     <a class="ltx_ref" href="#bib.bib33" title="">
      2020a
     </a>
     )
    </cite>
    contains a set of environments associated with long-horizon household tasks specified by natural language instructions.
As shown in Figure
    <a class="ltx_ref" href="#A1.F2" title="Figure 2 ‣ Appendix A Task Example in ALFRED ‣ OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied Instruction Following">
     <span class="ltx_text ltx_ref_tag">
      2
     </span>
    </a>
    , the language instruction
    <math alttext="L=\{L_{\text{high}},L_{\text{low}}\}" class="ltx_Math" display="inline" id="A1.p1.1.m1.2">
     <semantics id="A1.p1.1.m1.2a">
      <mrow id="A1.p1.1.m1.2.2" xref="A1.p1.1.m1.2.2.cmml">
       <mi id="A1.p1.1.m1.2.2.4" xref="A1.p1.1.m1.2.2.4.cmml">
        L
       </mi>
       <mo id="A1.p1.1.m1.2.2.3" xref="A1.p1.1.m1.2.2.3.cmml">
        =
       </mo>
       <mrow id="A1.p1.1.m1.2.2.2.2" xref="A1.p1.1.m1.2.2.2.3.cmml">
        <mo id="A1.p1.1.m1.2.2.2.2.3" stretchy="false" xref="A1.p1.1.m1.2.2.2.3.cmml">
         {
        </mo>
        <msub id="A1.p1.1.m1.1.1.1.1.1" xref="A1.p1.1.m1.1.1.1.1.1.cmml">
         <mi id="A1.p1.1.m1.1.1.1.1.1.2" xref="A1.p1.1.m1.1.1.1.1.1.2.cmml">
          L
         </mi>
         <mtext id="A1.p1.1.m1.1.1.1.1.1.3" xref="A1.p1.1.m1.1.1.1.1.1.3a.cmml">
          high
         </mtext>
        </msub>
        <mo id="A1.p1.1.m1.2.2.2.2.4" xref="A1.p1.1.m1.2.2.2.3.cmml">
         ,
        </mo>
        <msub id="A1.p1.1.m1.2.2.2.2.2" xref="A1.p1.1.m1.2.2.2.2.2.cmml">
         <mi id="A1.p1.1.m1.2.2.2.2.2.2" xref="A1.p1.1.m1.2.2.2.2.2.2.cmml">
          L
         </mi>
         <mtext id="A1.p1.1.m1.2.2.2.2.2.3" xref="A1.p1.1.m1.2.2.2.2.2.3a.cmml">
          low
         </mtext>
        </msub>
        <mo id="A1.p1.1.m1.2.2.2.2.5" stretchy="false" xref="A1.p1.1.m1.2.2.2.3.cmml">
         }
        </mo>
       </mrow>
      </mrow>
      <annotation-xml encoding="MathML-Content" id="A1.p1.1.m1.2b">
       <apply id="A1.p1.1.m1.2.2.cmml" xref="A1.p1.1.m1.2.2">
        <eq id="A1.p1.1.m1.2.2.3.cmml" xref="A1.p1.1.m1.2.2.3">
        </eq>
        <ci id="A1.p1.1.m1.2.2.4.cmml" xref="A1.p1.1.m1.2.2.4">
         𝐿
        </ci>
        <set id="A1.p1.1.m1.2.2.2.3.cmml" xref="A1.p1.1.m1.2.2.2.2">
         <apply id="A1.p1.1.m1.1.1.1.1.1.cmml" xref="A1.p1.1.m1.1.1.1.1.1">
          <csymbol cd="ambiguous" id="A1.p1.1.m1.1.1.1.1.1.1.cmml" xref="A1.p1.1.m1.1.1.1.1.1">
           subscript
          </csymbol>
          <ci id="A1.p1.1.m1.1.1.1.1.1.2.cmml" xref="A1.p1.1.m1.1.1.1.1.1.2">
           𝐿
          </ci>
          <ci id="A1.p1.1.m1.1.1.1.1.1.3a.cmml" xref="A1.p1.1.m1.1.1.1.1.1.3">
           <mtext id="A1.p1.1.m1.1.1.1.1.1.3.cmml" mathsize="70%" xref="A1.p1.1.m1.1.1.1.1.1.3">
            high
           </mtext>
          </ci>
         </apply>
         <apply id="A1.p1.1.m1.2.2.2.2.2.cmml" xref="A1.p1.1.m1.2.2.2.2.2">
          <csymbol cd="ambiguous" id="A1.p1.1.m1.2.2.2.2.2.1.cmml" xref="A1.p1.1.m1.2.2.2.2.2">
           subscript
          </csymbol>
          <ci id="A1.p1.1.m1.2.2.2.2.2.2.cmml" xref="A1.p1.1.m1.2.2.2.2.2.2">
           𝐿
          </ci>
          <ci id="A1.p1.1.m1.2.2.2.2.2.3a.cmml" xref="A1.p1.1.m1.2.2.2.2.2.3">
           <mtext id="A1.p1.1.m1.2.2.2.2.2.3.cmml" mathsize="70%" xref="A1.p1.1.m1.2.2.2.2.2.3">
            low
           </mtext>
          </ci>
         </apply>
        </set>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="A1.p1.1.m1.2c">
       L=\{L_{\text{high}},L_{\text{low}}\}
      </annotation>
     </semantics>
    </math>
    consists of instructions at two different levels: a high-level instruction goal
    <math alttext="L_{\text{high}}" class="ltx_Math" display="inline" id="A1.p1.2.m2.1">
     <semantics id="A1.p1.2.m2.1a">
      <msub id="A1.p1.2.m2.1.1" xref="A1.p1.2.m2.1.1.cmml">
       <mi id="A1.p1.2.m2.1.1.2" xref="A1.p1.2.m2.1.1.2.cmml">
        L
       </mi>
       <mtext id="A1.p1.2.m2.1.1.3" xref="A1.p1.2.m2.1.1.3a.cmml">
        high
       </mtext>
      </msub>
      <annotation-xml encoding="MathML-Content" id="A1.p1.2.m2.1b">
       <apply id="A1.p1.2.m2.1.1.cmml" xref="A1.p1.2.m2.1.1">
        <csymbol cd="ambiguous" id="A1.p1.2.m2.1.1.1.cmml" xref="A1.p1.2.m2.1.1">
         subscript
        </csymbol>
        <ci id="A1.p1.2.m2.1.1.2.cmml" xref="A1.p1.2.m2.1.1.2">
         𝐿
        </ci>
        <ci id="A1.p1.2.m2.1.1.3a.cmml" xref="A1.p1.2.m2.1.1.3">
         <mtext id="A1.p1.2.m2.1.1.3.cmml" mathsize="70%" xref="A1.p1.2.m2.1.1.3">
          high
         </mtext>
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="A1.p1.2.m2.1c">
       L_{\text{high}}
      </annotation>
     </semantics>
    </math>
    that summarizes the task and a sequence of low-level instructions
    <math alttext="L_{\text{low}}" class="ltx_Math" display="inline" id="A1.p1.3.m3.1">
     <semantics id="A1.p1.3.m3.1a">
      <msub id="A1.p1.3.m3.1.1" xref="A1.p1.3.m3.1.1.cmml">
       <mi id="A1.p1.3.m3.1.1.2" xref="A1.p1.3.m3.1.1.2.cmml">
        L
       </mi>
       <mtext id="A1.p1.3.m3.1.1.3" xref="A1.p1.3.m3.1.1.3a.cmml">
        low
       </mtext>
      </msub>
      <annotation-xml encoding="MathML-Content" id="A1.p1.3.m3.1b">
       <apply id="A1.p1.3.m3.1.1.cmml" xref="A1.p1.3.m3.1.1">
        <csymbol cd="ambiguous" id="A1.p1.3.m3.1.1.1.cmml" xref="A1.p1.3.m3.1.1">
         subscript
        </csymbol>
        <ci id="A1.p1.3.m3.1.1.2.cmml" xref="A1.p1.3.m3.1.1.2">
         𝐿
        </ci>
        <ci id="A1.p1.3.m3.1.1.3a.cmml" xref="A1.p1.3.m3.1.1.3">
         <mtext id="A1.p1.3.m3.1.1.3.cmml" mathsize="70%" xref="A1.p1.3.m3.1.1.3">
          low
         </mtext>
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="A1.p1.3.m3.1c">
       L_{\text{low}}
      </annotation>
     </semantics>
    </math>
    that depict the specific actions required.
At the time step
    <math alttext="t" class="ltx_Math" display="inline" id="A1.p1.4.m4.1">
     <semantics id="A1.p1.4.m4.1a">
      <mi id="A1.p1.4.m4.1.1" xref="A1.p1.4.m4.1.1.cmml">
       t
      </mi>
      <annotation-xml encoding="MathML-Content" id="A1.p1.4.m4.1b">
       <ci id="A1.p1.4.m4.1.1.cmml" xref="A1.p1.4.m4.1.1">
        𝑡
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="A1.p1.4.m4.1c">
       t
      </annotation>
     </semantics>
    </math>
    , ALFRED also provides a visual egocentric observation
    <math alttext="V_{t}" class="ltx_Math" display="inline" id="A1.p1.5.m5.1">
     <semantics id="A1.p1.5.m5.1a">
      <msub id="A1.p1.5.m5.1.1" xref="A1.p1.5.m5.1.1.cmml">
       <mi id="A1.p1.5.m5.1.1.2" xref="A1.p1.5.m5.1.1.2.cmml">
        V
       </mi>
       <mi id="A1.p1.5.m5.1.1.3" xref="A1.p1.5.m5.1.1.3.cmml">
        t
       </mi>
      </msub>
      <annotation-xml encoding="MathML-Content" id="A1.p1.5.m5.1b">
       <apply id="A1.p1.5.m5.1.1.cmml" xref="A1.p1.5.m5.1.1">
        <csymbol cd="ambiguous" id="A1.p1.5.m5.1.1.1.cmml" xref="A1.p1.5.m5.1.1">
         subscript
        </csymbol>
        <ci id="A1.p1.5.m5.1.1.2.cmml" xref="A1.p1.5.m5.1.1.2">
         𝑉
        </ci>
        <ci id="A1.p1.5.m5.1.1.3.cmml" xref="A1.p1.5.m5.1.1.3">
         𝑡
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="A1.p1.5.m5.1c">
       V_{t}
      </annotation>
     </semantics>
    </math>
    represents the world state
    <math alttext="\mathcal{W}_{t}" class="ltx_Math" display="inline" id="A1.p1.6.m6.1">
     <semantics id="A1.p1.6.m6.1a">
      <msub id="A1.p1.6.m6.1.1" xref="A1.p1.6.m6.1.1.cmml">
       <mi class="ltx_font_mathcaligraphic" id="A1.p1.6.m6.1.1.2" xref="A1.p1.6.m6.1.1.2.cmml">
        𝒲
       </mi>
       <mi id="A1.p1.6.m6.1.1.3" xref="A1.p1.6.m6.1.1.3.cmml">
        t
       </mi>
      </msub>
      <annotation-xml encoding="MathML-Content" id="A1.p1.6.m6.1b">
       <apply id="A1.p1.6.m6.1.1.cmml" xref="A1.p1.6.m6.1.1">
        <csymbol cd="ambiguous" id="A1.p1.6.m6.1.1.1.cmml" xref="A1.p1.6.m6.1.1">
         subscript
        </csymbol>
        <ci id="A1.p1.6.m6.1.1.2.cmml" xref="A1.p1.6.m6.1.1.2">
         𝒲
        </ci>
        <ci id="A1.p1.6.m6.1.1.3.cmml" xref="A1.p1.6.m6.1.1.3">
         𝑡
        </ci>
       </apply>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="A1.p1.6.m6.1c">
       \mathcal{W}_{t}
      </annotation>
     </semantics>
    </math>
    .
There are seven types of household tasks in ALFRED, namely Pick &amp; Place, Stack &amp; Place, Pick Two &amp; Place, Clean &amp; Place, Heat &amp; Place, Cool &amp; Place, and Examine in Light. An episode is terminated either if an agent meets the goal conditions specified in
    <math alttext="L" class="ltx_Math" display="inline" id="A1.p1.7.m7.1">
     <semantics id="A1.p1.7.m7.1a">
      <mi id="A1.p1.7.m7.1.1" xref="A1.p1.7.m7.1.1.cmml">
       L
      </mi>
      <annotation-xml encoding="MathML-Content" id="A1.p1.7.m7.1b">
       <ci id="A1.p1.7.m7.1.1.cmml" xref="A1.p1.7.m7.1.1">
        𝐿
       </ci>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="A1.p1.7.m7.1c">
       L
      </annotation>
     </semantics>
    </math>
    (success) or reaches the maximum number of steps (fail).
   </p>
  </div>
  <figure class="ltx_figure" id="A1.F2">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="268" id="A1.F2.g1" src="/html/2403.03017/assets/x2.png" width="221"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 2:
    </span>
    Example of a Clean &amp; Place task in ALFRED.
   </figcaption>
  </figure>
 </section>
 <section class="ltx_appendix" id="A2">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix B
   </span>
   Full Results on AFLRED
  </h2>
  <div class="ltx_para" id="A2.p1">
   <p class="ltx_p" id="A2.p1.1">
    The experiment on ALFRED under two different settings are illustrated in Table
    <a class="ltx_ref" href="#A2.T5" title="Table 5 ‣ Appendix B Full Results on AFLRED ‣ OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied Instruction Following">
     <span class="ltx_text ltx_ref_tag">
      5
     </span>
    </a>
    .
   </p>
  </div>
  <figure class="ltx_table" id="A2.T5">
   <table class="ltx_tabular ltx_centering ltx_align_middle" id="A2.T5.1">
    <tbody class="ltx_tbody">
     <tr class="ltx_tr" id="A2.T5.1.1.1">
      <td class="ltx_td ltx_align_left ltx_border_tt" id="A2.T5.1.1.1.1" rowspan="2">
       <span class="ltx_text" id="A2.T5.1.1.1.1.1">
        Method
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="A2.T5.1.1.1.2">
       Test Seen
      </td>
      <td class="ltx_td ltx_border_tt" id="A2.T5.1.1.1.3">
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="A2.T5.1.1.1.4">
       Test Unseen
      </td>
     </tr>
     <tr class="ltx_tr" id="A2.T5.1.2.2">
      <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.2.2.1">
       PLWGC
      </td>
      <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.2.2.2">
       GC
      </td>
      <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.2.2.3">
       PLWSR
      </td>
      <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.2.2.4">
       SR
      </td>
      <td class="ltx_td" id="A2.T5.1.2.2.5">
      </td>
      <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.2.2.6">
       PLWGC
      </td>
      <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.2.2.7">
       GC
      </td>
      <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.2.2.8">
       PLWSR
      </td>
      <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.2.2.9">
       SR
      </td>
     </tr>
     <tr class="ltx_tr" id="A2.T5.1.3.3">
      <td class="ltx_td ltx_align_left ltx_border_t" colspan="9" id="A2.T5.1.3.3.1">
       <span class="ltx_text ltx_font_bold" id="A2.T5.1.3.3.1.1">
        High-level Goal Instruction + Low-level step-by-step instructions
       </span>
      </td>
      <td class="ltx_td ltx_border_t" id="A2.T5.1.3.3.2">
      </td>
     </tr>
     <tr class="ltx_tr" id="A2.T5.1.4.4">
      <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.4.4.1">
       Seq2Seq
       <cite class="ltx_cite ltx_citemacro_cite">
        Shridhar et al. (
        <a class="ltx_ref" href="#bib.bib33" title="">
         2020a
        </a>
        )
       </cite>
      </td>
      <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.4.4.2">
       6.27
      </td>
      <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.4.4.3">
       9.42
      </td>
      <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.4.4.4">
       2.02
      </td>
      <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.4.4.5">
       3.98
      </td>
      <td class="ltx_td ltx_border_t" id="A2.T5.1.4.4.6">
      </td>
      <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.4.4.7">
       4.26
      </td>
      <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.4.4.8">
       7.03
      </td>
      <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.4.4.9">
       0.08
      </td>
      <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.4.4.10">
       3.90
      </td>
     </tr>
     <tr class="ltx_tr" id="A2.T5.1.5.5">
      <td class="ltx_td ltx_align_left" id="A2.T5.1.5.5.1">
       MOCA
       <cite class="ltx_cite ltx_citemacro_cite">
        Singh et al. (
        <a class="ltx_ref" href="#bib.bib36" title="">
         2020
        </a>
        )
       </cite>
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.5.5.2">
       22.05
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.5.5.3">
       28.29
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.5.5.4">
       15.10
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.5.5.5">
       22.05
      </td>
      <td class="ltx_td" id="A2.T5.1.5.5.6">
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.5.5.7">
       9.99
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.5.5.8">
       14.28
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.5.5.9">
       2.72
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.5.5.10">
       5.30
      </td>
     </tr>
     <tr class="ltx_tr" id="A2.T5.1.6.6">
      <td class="ltx_td ltx_align_left" id="A2.T5.1.6.6.1">
       E.T.
       <cite class="ltx_cite ltx_citemacro_cite">
        Pashevich et al. (
        <a class="ltx_ref" href="#bib.bib26" title="">
         2021
        </a>
        )
       </cite>
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.6.6.2">
       <span class="ltx_text ltx_font_bold" id="A2.T5.1.6.6.2.1">
        34.93
       </span>
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.6.6.3">
       45.44
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.6.6.4">
       27.78
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.6.6.5">
       38.42
      </td>
      <td class="ltx_td" id="A2.T5.1.6.6.6">
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.6.6.7">
       11.46
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.6.6.8">
       18.56
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.6.6.9">
       4.10
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.6.6.10">
       8.57
      </td>
     </tr>
     <tr class="ltx_tr" id="A2.T5.1.7.7">
      <td class="ltx_td ltx_align_left" id="A2.T5.1.7.7.1">
       LWIT
       <cite class="ltx_cite ltx_citemacro_cite">
        Nguyen et al. (
        <a class="ltx_ref" href="#bib.bib23" title="">
         2021
        </a>
        )
       </cite>
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.7.7.2">
       23.10
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.7.7.3">
       40.53
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.7.7.4">
       <span class="ltx_text ltx_font_bold" id="A2.T5.1.7.7.4.1">
        43.10
       </span>
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.7.7.5">
       30.92
      </td>
      <td class="ltx_td" id="A2.T5.1.7.7.6">
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.7.7.7">
       <span class="ltx_text ltx_font_bold" id="A2.T5.1.7.7.7.1">
        16.34
       </span>
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.7.7.8">
       20.91
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.7.7.9">
       5.60
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.7.7.10">
       9.42
      </td>
     </tr>
     <tr class="ltx_tr" id="A2.T5.1.8.8">
      <td class="ltx_td ltx_align_left" id="A2.T5.1.8.8.1">
       FILM
       <cite class="ltx_cite ltx_citemacro_cite">
        Min et al. (
        <a class="ltx_ref" href="#bib.bib21" title="">
         2021
        </a>
        )
       </cite>
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.8.8.2">
       15.06
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.8.8.3">
       38.51
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.8.8.4">
       11.23
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.8.8.5">
       27.67
      </td>
      <td class="ltx_td" id="A2.T5.1.8.8.6">
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.8.8.7">
       14.30
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.8.8.8">
       36.37
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.8.8.9">
       <span class="ltx_text ltx_font_bold" id="A2.T5.1.8.8.9.1">
        10.55
       </span>
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.8.8.10">
       26.49
      </td>
     </tr>
     <tr class="ltx_tr" id="A2.T5.1.9.9">
      <td class="ltx_td ltx_align_left" id="A2.T5.1.9.9.1">
       OPEx
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.9.9.2">
       22.08
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.9.9.3">
       <span class="ltx_text ltx_font_bold" id="A2.T5.1.9.9.3.1">
        54.81
       </span>
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.9.9.4">
       14.52
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.9.9.5">
       <span class="ltx_text ltx_font_bold" id="A2.T5.1.9.9.5.1">
        44.03
       </span>
      </td>
      <td class="ltx_td" id="A2.T5.1.9.9.6">
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.9.9.7">
       15.27
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.9.9.8">
       54.18
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.9.9.9">
       13.48
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.9.9.10">
       <span class="ltx_text ltx_font_bold" id="A2.T5.1.9.9.10.1">
        41.85
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A2.T5.1.10.10">
      <td class="ltx_td ltx_align_left ltx_border_t" colspan="9" id="A2.T5.1.10.10.1">
       <span class="ltx_text ltx_font_bold" id="A2.T5.1.10.10.1.1">
        High-level goal instructions only
       </span>
      </td>
      <td class="ltx_td ltx_border_t" id="A2.T5.1.10.10.2">
      </td>
     </tr>
     <tr class="ltx_tr" id="A2.T5.1.11.11">
      <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.11.11.1">
       LAV
       <cite class="ltx_cite ltx_citemacro_cite">
        Nottingham et al. (
        <a class="ltx_ref" href="#bib.bib24" title="">
         2021
        </a>
        )
       </cite>
      </td>
      <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.11.11.2">
       13.18
      </td>
      <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.11.11.3">
       23.21
      </td>
      <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.11.11.4">
       6.31
      </td>
      <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.11.11.5">
       13.35
      </td>
      <td class="ltx_td ltx_border_t" id="A2.T5.1.11.11.6">
      </td>
      <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.11.11.7">
       10.47
      </td>
      <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.11.11.8">
       17.27
      </td>
      <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.11.11.9">
       3.12
      </td>
      <td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.11.11.10">
       6.38
      </td>
     </tr>
     <tr class="ltx_tr" id="A2.T5.1.12.12">
      <td class="ltx_td ltx_align_left" id="A2.T5.1.12.12.1">
       HLSM
       <cite class="ltx_cite ltx_citemacro_cite">
        Blukis et al. (
        <a class="ltx_ref" href="#bib.bib3" title="">
         2022
        </a>
        )
       </cite>
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.12.12.2">
       11.53
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.12.12.3">
       35.79
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.12.12.4">
       6.69
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.12.12.5">
       25.11
      </td>
      <td class="ltx_td" id="A2.T5.1.12.12.6">
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.12.12.7">
       8.45
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.12.12.8">
       27.24
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.12.12.9">
       4.34
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.12.12.10">
       16.29
      </td>
     </tr>
     <tr class="ltx_tr" id="A2.T5.1.13.13">
      <td class="ltx_td ltx_align_left" id="A2.T5.1.13.13.1">
       LGS-RPA
       <cite class="ltx_cite ltx_citemacro_cite">
        Murray and Cakmak (
        <a class="ltx_ref" href="#bib.bib22" title="">
         2022
        </a>
        )
       </cite>
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.13.13.2">
       <span class="ltx_text ltx_font_bold" id="A2.T5.1.13.13.2.1">
        24.49
       </span>
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.13.13.3">
       41.71
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.13.13.4">
       <span class="ltx_text ltx_font_bold" id="A2.T5.1.13.13.4.1">
        16.65
       </span>
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.13.13.5">
       33.01
      </td>
      <td class="ltx_td" id="A2.T5.1.13.13.6">
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.13.13.7">
       <span class="ltx_text ltx_font_bold" id="A2.T5.1.13.13.7.1">
        20.01
       </span>
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.13.13.8">
       38.55
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.13.13.9">
       <span class="ltx_text ltx_font_bold" id="A2.T5.1.13.13.9.1">
        12.92
       </span>
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.13.13.10">
       27.80
      </td>
     </tr>
     <tr class="ltx_tr" id="A2.T5.1.14.14">
      <td class="ltx_td ltx_align_left" id="A2.T5.1.14.14.1">
       EPA
       <cite class="ltx_cite ltx_citemacro_cite">
        Liu et al. (
        <a class="ltx_ref" href="#bib.bib19" title="">
         2022c
        </a>
        )
       </cite>
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.14.14.2">
       3.47
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.14.14.3">
       44.14
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.14.14.4">
       2.56
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.14.14.5">
       39.96
      </td>
      <td class="ltx_td" id="A2.T5.1.14.14.6">
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.14.14.7">
       3.91
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.14.14.8">
       39.54
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.14.14.9">
       2.92
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.14.14.10">
       36.07
      </td>
     </tr>
     <tr class="ltx_tr" id="A2.T5.1.15.15">
      <td class="ltx_td ltx_align_left" id="A2.T5.1.15.15.1">
       LLM-Planner
       <cite class="ltx_cite ltx_citemacro_cite">
        Song et al. (
        <a class="ltx_ref" href="#bib.bib37" title="">
         2023
        </a>
        )
       </cite>
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.15.15.2">
       -
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.15.15.3">
       24.57
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.15.15.4">
       -
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.15.15.5">
       15.33
      </td>
      <td class="ltx_td" id="A2.T5.1.15.15.6">
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.15.15.7">
       -
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.15.15.8">
       22.89
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.15.15.9">
       -
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.15.15.10">
       13.41
      </td>
     </tr>
     <tr class="ltx_tr" id="A2.T5.1.16.16">
      <td class="ltx_td ltx_align_left" id="A2.T5.1.16.16.1">
       FILM
       <cite class="ltx_cite ltx_citemacro_cite">
        Min et al. (
        <a class="ltx_ref" href="#bib.bib21" title="">
         2021
        </a>
        )
       </cite>
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.16.16.2">
       14.17
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.16.16.3">
       36.15
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.16.16.4">
       10.39
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.16.16.5">
       25.77
      </td>
      <td class="ltx_td" id="A2.T5.1.16.16.6">
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.16.16.7">
       13.13
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.16.16.8">
       34.75
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.16.16.9">
       9.67
      </td>
      <td class="ltx_td ltx_align_left" id="A2.T5.1.16.16.10">
       24.46
      </td>
     </tr>
     <tr class="ltx_tr" id="A2.T5.1.17.17">
      <td class="ltx_td ltx_align_left ltx_border_bb" id="A2.T5.1.17.17.1">
       OPEx-S
      </td>
      <td class="ltx_td ltx_align_left ltx_border_bb" id="A2.T5.1.17.17.2">
       20.13
      </td>
      <td class="ltx_td ltx_align_left ltx_border_bb" id="A2.T5.1.17.17.3">
       <span class="ltx_text ltx_font_bold" id="A2.T5.1.17.17.3.1">
        54.27
       </span>
      </td>
      <td class="ltx_td ltx_align_left ltx_border_bb" id="A2.T5.1.17.17.4">
       13.64
      </td>
      <td class="ltx_td ltx_align_left ltx_border_bb" id="A2.T5.1.17.17.5">
       <span class="ltx_text ltx_font_bold" id="A2.T5.1.17.17.5.1">
        43.51
       </span>
      </td>
      <td class="ltx_td ltx_border_bb" id="A2.T5.1.17.17.6">
      </td>
      <td class="ltx_td ltx_align_left ltx_border_bb" id="A2.T5.1.17.17.7">
       18.46
      </td>
      <td class="ltx_td ltx_align_left ltx_border_bb" id="A2.T5.1.17.17.8">
       <span class="ltx_text ltx_font_bold" id="A2.T5.1.17.17.8.1">
        53.82
       </span>
      </td>
      <td class="ltx_td ltx_align_left ltx_border_bb" id="A2.T5.1.17.17.9">
       12.57
      </td>
      <td class="ltx_td ltx_align_left ltx_border_bb" id="A2.T5.1.17.17.10">
       <span class="ltx_text ltx_font_bold" id="A2.T5.1.17.17.10.1">
        41.27
       </span>
      </td>
     </tr>
    </tbody>
   </table>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_table">
     Table 5:
    </span>
    Main Results on the test splits of ALFRED benchmark.
   </figcaption>
  </figure>
 </section>
 <section class="ltx_appendix" id="A3">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix C
   </span>
   Prompt Examples
  </h2>
  <div class="ltx_para" id="A3.p1">
   <p class="ltx_p" id="A3.p1.1">
    In this section, we provide three prompt examples for the LLM-based planner, LLM-based observer, and LLM-based executor respectively.
   </p>
  </div>
  <section class="ltx_paragraph" id="A3.SS0.SSS0.Px1">
   <h4 class="ltx_title ltx_title_paragraph">
    LLM-based Planner.
   </h4>
   <div class="ltx_para" id="A3.SS0.SSS0.Px1.p1">
    <p class="ltx_p" id="A3.SS0.SSS0.Px1.p1.1">
     In Figure
     <a class="ltx_ref" href="#A3.F3" title="Figure 3 ‣ LLM-based Executor. ‣ Appendix C Prompt Examples ‣ OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied Instruction Following">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     , we present an illustrative prompt example of the LLM-based planner. The high-level instruction for this instance is "place a washed bowl into a kitchen cabinet." The prompt for the LLM-based planner is constructed to establish the planning task and define the desired output format. Specifically, the input provided to the planner is: "
     <span class="ltx_text ltx_font_bold" id="A3.SS0.SSS0.Px1.p1.1.1" style="color:#00E000;">
      Task:
     </span>
     place a washed bowl into a kitchen cabinet." The resulting output encapsulates both the reasoning stages and the path of reasoning undertaken by the LLM-based planner. Given that the foundation of the planner’s reasoning prowess lies in its comprehension, we initially expect it to demonstrate a fundamental understanding of the task. This is manifested through the presentation of the task’s
     <span class="ltx_text ltx_font_bold" id="A3.SS0.SSS0.Px1.p1.1.2" style="color:#C20300;">
      Task type
     </span>
     (in this instance, "PICK_CLEAN_THEN_PLACE_IN_RECEP"). Subsequently, drawing inspiration from the concept of Chain-of-Thought Prompting, we introduce a two-step requirement. Firstly, the planner is prompted to generate its
     <span class="ltx_text ltx_font_bold" id="A3.SS0.SSS0.Px1.p1.1.3" style="color:#C20300;">
      Thought process
     </span>
     in achieving the task, followed by the presentation of the ultimate
     <span class="ltx_text ltx_font_bold" id="A3.SS0.SSS0.Px1.p1.1.4" style="color:#C20300;">
      Plan
     </span>
     to accomplish the specified task.
    </p>
   </div>
  </section>
  <section class="ltx_paragraph" id="A3.SS0.SSS0.Px2">
   <h4 class="ltx_title ltx_title_paragraph">
    LLM-based Observer.
   </h4>
   <div class="ltx_para" id="A3.SS0.SSS0.Px2.p1">
    <p class="ltx_p" id="A3.SS0.SSS0.Px2.p1.1">
     Fig.
     <a class="ltx_ref" href="#A3.F4" title="Figure 4 ‣ LLM-based Executor. ‣ Appendix C Prompt Examples ‣ OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied Instruction Following">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     demonstrates two prompt examples for the LLM-based observer. Similar to the prompt design of the LLM-based planner, the prompt for the LLM-based observer also starts with a setup that establishes the observation task. The input to the observer is a set of information collected from the environment, including
     <span class="ltx_text ltx_font_bold" id="A3.SS0.SSS0.Px2.p1.1.1" style="color:#00E000;">
      Room type:
     </span>
     indicating which kind of the room the agent is currently in (kitchen, living room, bedroom, or bathroom),
     <span class="ltx_text ltx_font_bold" id="A3.SS0.SSS0.Px2.p1.1.2" style="color:#00E000;">
      Task description:
     </span>
     specifying the current subtask (which is generated by the LLM-based planner) to complete,
     <span class="ltx_text ltx_font_bold" id="A3.SS0.SSS0.Px2.p1.1.3" style="color:#00E000;">
      Previously found objects:
     </span>
     storing all the objects detected by the agent from the start of the episode to current time step,
     <span class="ltx_text ltx_font_bold" id="A3.SS0.SSS0.Px2.p1.1.4" style="color:#00E000;">
      Objects seen in current observation:
     </span>
     pointing out the objects detected in the agent’s current egocentric view,
     <span class="ltx_text ltx_font_bold" id="A3.SS0.SSS0.Px2.p1.1.5" style="color:#00E000;">
      Holding object:
     </span>
     tracking the object that is currently holden by the agent, and
     <span class="ltx_text ltx_font_bold" id="A3.SS0.SSS0.Px2.p1.1.6" style="color:#00E000;">
      Error message:
     </span>
     tracking the error that causes action failures to facilitate exception handling capability of agent. Since successful action in the simulator typically results in the RGB change of the egocentric observation, we can detect action failures by comparing the egocentric observations before and after the execution of the action. If one kind of action failure is detected, then the error message of the corresponding action failure will be gathered by the LLM-centric observer. The designing purpose of the LLM-based observer is not only to gather information but also to serve as a “information gate” which filters out task-irrelevant information and effectively organizes the task-relevant information for better grounded planning and acting.
    </p>
   </div>
  </section>
  <section class="ltx_paragraph" id="A3.SS0.SSS0.Px3">
   <h4 class="ltx_title ltx_title_paragraph">
    LLM-based Executor.
   </h4>
   <div class="ltx_para" id="A3.SS0.SSS0.Px3.p1">
    <p class="ltx_p" id="A3.SS0.SSS0.Px3.p1.1">
     A prompt example of completing “Explore the room to have a general idea of the environment” is illustrated in Fig.
     <a class="ltx_ref" href="#A3.F5" title="Figure 5 ‣ LLM-based Executor. ‣ Appendix C Prompt Examples ‣ OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied Instruction Following">
      <span class="ltx_text ltx_ref_tag">
       5
      </span>
     </a>
     . Specifically, the prompt of the LLM-based executor also starts with a setup establishing the execution task and indicating the desired output format. Afterward, the setup is followed by the input to the LLM-centric executor, which consists of
     <span class="ltx_text ltx_font_bold" id="A3.SS0.SSS0.Px3.p1.1.1" style="color:#00E000;">
      Observation:
     </span>
     presenting the current language description of the word state generated by the LLM-based observer,
     <span class="ltx_text ltx_font_bold" id="A3.SS0.SSS0.Px3.p1.1.2" style="color:#00E000;">
      Found objects:
     </span>
     tracking all the objects detected by the agents,
     <span class="ltx_text ltx_font_bold" id="A3.SS0.SSS0.Px3.p1.1.3" style="color:#00E000;">
      Objects seeing in current observation:
     </span>
     noting the objects detected from current egocentric visual observation,
     <span class="ltx_text ltx_font_bold" id="A3.SS0.SSS0.Px3.p1.1.4" style="color:#00E000;">
      Previous steps:
     </span>
     tracking the steps taken for the current subtask, and
     <span class="ltx_text ltx_font_bold" id="A3.SS0.SSS0.Px3.p1.1.5">
      Current objective:
     </span>
     specifying the current subtask to complete. Inspired by ReAct, we require the LLM-based executor to generate not only the final skill action plan
     <span class="ltx_text ltx_font_bold" id="A3.SS0.SSS0.Px3.p1.1.6" style="color:#C20300;">
      Action
     </span>
     but also the reasoning paths
     <span class="ltx_text ltx_font_bold" id="A3.SS0.SSS0.Px3.p1.1.7" style="color:#C20300;">
      Thought
     </span>
     in the first place.
    </p>
   </div>
   <figure class="ltx_figure" id="A3.F3">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="248" id="A3.F3.g1" src="/html/2403.03017/assets/x3.png" width="230"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 3:
     </span>
     Prompt example of the LLM-based Planner.
     <span class="ltx_text ltx_font_bold" id="A3.F3.6.1">
      Setup
     </span>
     is fixed for all the input test cases,
     <span class="ltx_text ltx_font_bold" id="A3.F3.7.2" style="color:#00E000;">
      Task
     </span>
     is the input to the LLM-based planner that varies for distinct input test cases,
     <span class="ltx_text ltx_font_bold" id="A3.F3.8.3" style="color:#C20300;">
      Task type
     </span>
     ,
     <span class="ltx_text ltx_font_bold" id="A3.F3.9.4" style="color:#C20300;">
      Tought
     </span>
     , and
     <span class="ltx_text ltx_font_bold" id="A3.F3.10.5" style="color:#C20300;">
      Plan
     </span>
     are the content required to be generated by the LLM-based planner. The same color mode applies to other figures.
    </figcaption>
   </figure>
   <figure class="ltx_figure" id="A3.F4">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="248" id="A3.F4.g1" src="/html/2403.03017/assets/x4.png" width="230"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 4:
     </span>
     Prompt example of the LLM-based Observer.
    </figcaption>
   </figure>
   <figure class="ltx_figure" id="A3.F5">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="280" id="A3.F5.g1" src="/html/2403.03017/assets/x5.png" width="230"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 5:
     </span>
     Prompt example of the LLM-based Executor.
    </figcaption>
   </figure>
  </section>
 </section>
</article>
