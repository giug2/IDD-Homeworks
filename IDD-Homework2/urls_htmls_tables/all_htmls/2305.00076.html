<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2305.00076] HausaNLP at SemEval-2023 Task 10: Transfer Learning, Synthetic Data and Side-Information for Multi-Level Sexism Classification</title><meta property="og:description" content="We present the findings of our participation in the SemEval-2023 Task 10: Explainable Detection of Online Sexism (EDOS) task, a shared task on offensive language (sexism) detection on English Gab and Reddit dataset.
We…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="HausaNLP at SemEval-2023 Task 10: Transfer Learning, Synthetic Data and Side-Information for Multi-Level Sexism Classification">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="HausaNLP at SemEval-2023 Task 10: Transfer Learning, Synthetic Data and Side-Information for Multi-Level Sexism Classification">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2305.00076">

<!--Generated on Thu Feb 29 10:31:22 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">HausaNLP at SemEval-2023 Task 10: Transfer Learning, Synthetic Data and Side-Information for Multi-Level Sexism Classification</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Saminu Mohammad Aliyu<sup id="id14.13.id1" class="ltx_sup"><span id="id14.13.id1.1" class="ltx_text ltx_font_italic">1+</span></sup>, Idris Abdulmumin<sup id="id15.14.id2" class="ltx_sup"><span id="id15.14.id2.1" class="ltx_text ltx_font_italic">2+</span></sup>, Shamsuddeen Hassan Muhammad<sup id="id16.15.id3" class="ltx_sup"><span id="id16.15.id3.1" class="ltx_text ltx_font_italic">1+</span></sup>, 
<br class="ltx_break"><span id="id8.8.5" class="ltx_text ltx_font_bold">Ibrahim Said Ahmad<sup id="id8.8.5.1" class="ltx_sup"><span id="id8.8.5.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1+</span></sup>, Saheed Abdullahi Salahudeen<sup id="id8.8.5.2" class="ltx_sup"><span id="id8.8.5.2.1" class="ltx_text ltx_font_medium ltx_font_italic">3+</span></sup>, Aliyu Yusuf<sup id="id8.8.5.3" class="ltx_sup"><span id="id8.8.5.3.1" class="ltx_text ltx_font_medium">4</span></sup>,
<br class="ltx_break">Falalu Ibrahim Lawan<sup id="id8.8.5.4" class="ltx_sup"><span id="id8.8.5.4.1" class="ltx_text ltx_font_medium ltx_font_italic">3+</span></sup>
<br class="ltx_break"><sup id="id8.8.5.5" class="ltx_sup"><span id="id8.8.5.5.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup></span>Bayero University, Kano, <sup id="id17.16.id4" class="ltx_sup"><span id="id17.16.id4.1" class="ltx_text ltx_font_italic">2</span></sup>Ahmad Bello University, Zaria, <sup id="id18.17.id5" class="ltx_sup"><span id="id18.17.id5.1" class="ltx_text ltx_font_italic">3</span></sup>Kaduna State University, 
<br class="ltx_break"><sup id="id19.18.id6" class="ltx_sup"><span id="id19.18.id6.1" class="ltx_text ltx_font_italic">4</span></sup>Universiti Teknologi PETRONAS,
<br class="ltx_break"><sup id="id20.19.id7" class="ltx_sup"><span id="id20.19.id7.1" class="ltx_text ltx_font_italic">+</span></sup>HausaNLP
<br class="ltx_break"><span id="id21.20.id8" class="ltx_text ltx_font_typewriter">smaliyu.cs@buk.edu.ng</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id13.1" class="ltx_p">We present the findings of our participation in the SemEval-2023 Task 10: Explainable Detection of Online Sexism (EDOS) task, a shared task on offensive language (sexism) detection on English Gab and Reddit dataset.
We investigated the effects of transferring two language models: XLM-T (sentiment classification) and HateBERT (same domain - Reddit) for multi-level classification into Sexist or not Sexist, and other subsequent sub-classifications of the sexist data. We also use synthetic classification of unlabelled dataset and intermediary class information to maximize the performance of our models. We submitted a system in Task A, and it ranked 49<sup id="id13.1.1" class="ltx_sup"><span id="id13.1.1.1" class="ltx_text ltx_font_italic">th</span></sup> with F1-score of 0.82. This result showed to be competitive as it only under-performed the best system by 0.052% F1-score.</p>
<p id="id22.id1" class="ltx_p"><span id="id22.id1.1" class="ltx_text ltx_font_bold">Content warning: All examples of sexism comments used are for illustrative purpose only.</span></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Sexism is a form of written or verbal attack on women based on their gender and other identity <cite class="ltx_cite ltx_citemacro_cite">Kirk et al. (<a href="#bib.bib10" title="" class="ltx_ref">2023</a>)</cite>. In general, there is a global concern about the prevalence of hate on social media. Consequently, many studies have attempted to ensure that the social media remain safe for everyone <cite class="ltx_cite ltx_citemacro_cite">Jiang et al. (<a href="#bib.bib8" title="" class="ltx_ref">2022</a>)</cite>. In this paper, we described our experiments for the SemEval-2023 Task 10: Explainable Detection of Online Sexism (EDOS). The shared task was divided into 3 sub-tasks that are all aimed at predicting fine-grained information about the type of sexism that exists on social media sites of Gab and Reddit. More information is provided in <a href="#S3" title="3 Task Overview ‣ HausaNLP at SemEval-2023 Task 10: Transfer Learning, Synthetic Data and Side-Information for Multi-Level Sexism Classification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3</span></a> and the task description paper <cite class="ltx_cite ltx_citemacro_cite">Kirk et al. (<a href="#bib.bib10" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Our models were fine-tuned on two pre-trained language models, namely XLM-T <cite class="ltx_cite ltx_citemacro_cite">Barbieri et al. (<a href="#bib.bib2" title="" class="ltx_ref">2022</a>)</cite> and HateBERT <cite class="ltx_cite ltx_citemacro_cite">Caselli et al. (<a href="#bib.bib4" title="" class="ltx_ref">2020</a>)</cite>. While XLM-T is a pretrained language model trained on 198 million tweets, the HateBERT on the other hand is a pretrained language model based on BERT <cite class="ltx_cite ltx_citemacro_cite">Devlin et al. (<a href="#bib.bib6" title="" class="ltx_ref">2018</a>)</cite> that was pretrained on a large scale English Reddit dataset for the detection of abusive language. We used only the dataset used by the task organizers in our experiment. See <cite class="ltx_cite ltx_citemacro_citet">Kirk et al. (<a href="#bib.bib10" title="" class="ltx_ref">2023</a>)</cite> for a description of the dataset. We made submission only to the Task A during the competition phase, and our system achieved a competitive performance of 0.82 F1-score. However, we also described our attempts at creating competitive models for Tasks B and C.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">The main contributions of this paper are as follows:</p>
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We investigated the effectiveness of transferring two language models, namely, XLM-T and HateBERT for binary sexism classification.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We explore the use of synthetic classification of unlabelled dataset and intermediary class information for maximizing the performances multi-level sexism classification models.</p>
</div>
</li>
</ol>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2305.00076/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="392" height="187" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Different level of classification as provided in the shared task</figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Works</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">There is an abundance of literature on the detection of hate speech online. However, only a fraction of such studies focused on sexism detection <cite class="ltx_cite ltx_citemacro_cite">Aliyu et al. (<a href="#bib.bib1" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Jiang et al. (<a href="#bib.bib8" title="" class="ltx_ref">2022</a>)</cite> proposed a Chinese dataset and lexicon for the detection of sexism on social media. The proposed dataset and lexicon were created from comments and posts collected on the Sina Weibo Chinese microbloging site and annotated into sexism or non-sexism. Those labelled as sexism were further annotated into four categories. Finally, each of these categories was labelled according to the target. Preliminary results show that context-based models outperform linguistics-based models. <cite class="ltx_cite ltx_citemacro_citet">Waseem and Hovy (<a href="#bib.bib13" title="" class="ltx_ref">2016</a>)</cite> created a dataset of 16,000 tweets, of which 3,383 tweets were sexist. Character n-gram feature was investigated alongside others such as gender and location. The best result was obtained with the combination of char n-gram and gender.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">At the IberEval 2018 task for the identification of misogyny from Spanish and English corpora, <cite class="ltx_cite ltx_citemacro_citet">Canós (<a href="#bib.bib3" title="" class="ltx_ref">2018</a>)</cite> used TF-IDF features vectors and SVM with a linear kernel to develop a system that classifies tweets as misogynistic or not misogynistic for subtask A, and the type and target of the misogynistic tweet for subtask B. The best result was obtained from the Spanish dataset for both tasks. Another study used TF-IDF, user-based, network-based, and text-based features together with classical and deep learning algorithms to automatically detect sexism in tweets. Logistic regression (LR), support vector machine (SVM) and random forest (RF) were used for the classical machine learning. Bidirectional long-short-term memory (Bi-LSTM) and multilingual bidirectional encoder representation from transformers (mBERT) from the deep learning algorithms. The mBERT with text features gave the best performance with an accuracy of 0.74.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite">Rodríguez-Sánchez et al. (<a href="#bib.bib11" title="" class="ltx_ref">2020</a>)</cite> conducted a review on racist and sexist hate speech detection, with special emphasis on datasets, features and approach used. According to their findings, <cite class="ltx_cite ltx_citemacro_citet">Waseem and Hovy (<a href="#bib.bib13" title="" class="ltx_ref">2016</a>)</cite> dataset was found to be the most used. Deep learning features perform best, and deep learning algorithms outperform the classical algorithms. <cite class="ltx_cite ltx_citemacro_citet">Istaiteh et al. (<a href="#bib.bib7" title="" class="ltx_ref">2020</a>)</cite> reviewed studies on the detection of racist and sexist hate speech detection with special emphasis on datasets, features and approach used. The study concluded that the <cite class="ltx_cite ltx_citemacro_citet">Waseem and Hovy (<a href="#bib.bib13" title="" class="ltx_ref">2016</a>)</cite> dataset is the most widely used dataset and deep learning achieves better performance for the classification task.</p>
</div>
<figure id="S2.T1" class="ltx_table">
<table id="S2.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T1.1.1.1" class="ltx_tr">
<th id="S2.T1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.1.1.1.1.1" class="ltx_text ltx_font_bold">Sentiment</span></th>
<th id="S2.T1.1.1.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.1.1.1.2.1" class="ltx_text ltx_font_bold">#Dev</span></th>
<th id="S2.T1.1.1.1.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.1.1.1.3.1" class="ltx_text ltx_font_bold">#Train</span></th>
<th id="S2.T1.1.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S2.T1.1.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.1.4.1.1" class="ltx_p" style="width:274.6pt;"><span id="S2.T1.1.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Example</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T1.1.2.1" class="ltx_tr">
<td id="S2.T1.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t">Sexist</td>
<td id="S2.T1.1.2.1.2" class="ltx_td ltx_align_right ltx_border_t">340</td>
<td id="S2.T1.1.2.1.3" class="ltx_td ltx_align_right ltx_border_t">3,544</td>
<td id="S2.T1.1.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.2.1.4.1.1" class="ltx_p" style="width:274.6pt;">Western women are truly the most entitled people to have ever lived on this earth.</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.3.2" class="ltx_tr">
<td id="S2.T1.1.3.2.1" class="ltx_td ltx_align_left ltx_border_bb">Not Sexist</td>
<td id="S2.T1.1.3.2.2" class="ltx_td ltx_align_right ltx_border_bb">1,060</td>
<td id="S2.T1.1.3.2.3" class="ltx_td ltx_align_right ltx_border_bb">11,056</td>
<td id="S2.T1.1.3.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S2.T1.1.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.3.2.4.1.1" class="ltx_p" style="width:274.6pt;">Our daughter was murdered, but at least we’re not racists!</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Dataset Description and Distribution of Sentiment Labels</figcaption>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Task Overview</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">The SemEval-2023 subtasks aim to create models for the detection of sexist post from Gab and Reddit. There are three subtask which include: Task A - a binary classification of statements as either sexist or not; Task B - classifies sexist statements into four groups namely, threats, derogation, animosity and prejudiced discussions; Task C - involves classification of the sexist statements into 11 fine-grained vectors. This is illustrated in <a href="#S1.F1" title="In 1 Introduction ‣ HausaNLP at SemEval-2023 Task 10: Transfer Learning, Synthetic Data and Side-Information for Multi-Level Sexism Classification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Train and development datasets</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">It can be observed from <a href="#S2.T1" title="In 2 Related Works ‣ HausaNLP at SemEval-2023 Task 10: Transfer Learning, Synthetic Data and Side-Information for Multi-Level Sexism Classification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">1</span></a> that the dataset is imbalanced, with "Not Sexist" having more than 75% in both train and dev splits. Both the train and dev datasets have similar distributions, with each having a minimum, maximum and average token counts of 1, 55 and about 23.5 respectively, based on space character (" ") tokenization.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2305.00076/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="415" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Task B. Using authentic and synthetic training datasets.</figcaption>
</figure>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2305.00076/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="181" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Task C. Each input sentence is paired with its parent class <span id="S3.F3.2.1" class="ltx_text ltx_font_bold">["Threats", "Derogation", "Animosity", "Prejudiced Discussion"]</span> before tokenization.</figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>System Overview</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we will elaborate on the main methods for the binary sexism task.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Pre-trained language models</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">For all the models, we fine-tuned two pre-trained language models (PLMs): XLM-T <cite class="ltx_cite ltx_citemacro_cite">Barbieri et al. (<a href="#bib.bib2" title="" class="ltx_ref">2022</a>)</cite> and HateBERT <cite class="ltx_cite ltx_citemacro_cite">Caselli et al. (<a href="#bib.bib4" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<section id="S4.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">XLM-T</h4>

<div id="S4.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.p1.1" class="ltx_p">This model was trained on 198 million tweets that were collected over a 2-year period starting from May 2018. The model was trained from a checkpoint of the base model, XLM-R <cite class="ltx_cite ltx_citemacro_cite">Conneau et al. (<a href="#bib.bib5" title="" class="ltx_ref">2019</a>)</cite>, until convergence<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://github.com/cardiffnlp/xlm-t" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/cardiffnlp/xlm-t</a></span></span></span>. This model was selected based on its excellent performance on sentiment analysis on social media datasets <cite class="ltx_cite ltx_citemacro_cite">Barbieri et al. (<a href="#bib.bib2" title="" class="ltx_ref">2022</a>); Aliyu et al. (<a href="#bib.bib1" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">HateBERT</h4>

<div id="S4.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px2.p1.1" class="ltx_p">This model is a BERT <cite class="ltx_cite ltx_citemacro_cite">Devlin et al. (<a href="#bib.bib6" title="" class="ltx_ref">2018</a>)</cite> model that was retrained on a large scale English Reddit dataset<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://huggingface.co/GroNLP/hateBERT" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/GroNLP/hateBERT</a></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">Caselli et al. (<a href="#bib.bib4" title="" class="ltx_ref">2020</a>)</cite> for the detection of abusive language. The dataset consisted of banned abusive, hateful and offensive words. We used this model because sexism is a form of offensive and hateful language, but also because the re-training dataset was from the same social platform as the provided training dataset.</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Training Strategies</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">For Task A - the binary classification task, two models were trained by fine-tuning the pre-trained language models (PLM) mentioned above. We used the best model in this task to select sentences that are potentially sexist from the provided unlabeled. In Task B, we first used the training data provided to fine-tune the XLM-T PLM. Subsequently, we used the fine-tuned model to generate the automatic classification of the potentially sexist sentences that were generated using the model in Task A. We then mixed this bigger synthetic dataset with the authentic data to train another classification model. This is illustrated in <a href="#S3.F2" title="In 3.1 Train and development datasets ‣ 3 Task Overview ‣ HausaNLP at SemEval-2023 Task 10: Transfer Learning, Synthetic Data and Side-Information for Multi-Level Sexism Classification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">Finally, for Task C, we leveraged the parent classification of the input sentence as provided for Task B to help the model narrow the expected final sexism classification, as illustrated in <a href="#S3.F3" title="In 3.1 Train and development datasets ‣ 3 Task Overview ‣ HausaNLP at SemEval-2023 Task 10: Transfer Learning, Synthetic Data and Side-Information for Multi-Level Sexism Classification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">3</span></a>. We utilized this information because it is provided in the shared task. For real-world application, we understand that this information may not be available. For this, we anticipate using a model to predict the parent classes, before using the synthetic data as the side information.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experimental Setup and Results</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Dataset</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">For this task, we only used the dataset provided by the organizers. We used a subset of training data (10%) to develop the systems and maintained the same set during the competition phase. We added the released development data to the other 90% of the training dataset to create a new train set, while maintaining the original development split. Some useful statistics of these datasets are provided in <a href="#S5.T2" title="In 5.1 Dataset ‣ 5 Experimental Setup and Results ‣ HausaNLP at SemEval-2023 Task 10: Transfer Learning, Synthetic Data and Side-Information for Multi-Level Sexism Classification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">2</span></a>. For the test set, a total of 4,000 provided for the competition, and we used them as they are to evaluate the performances of the various models.</p>
</div>
<figure id="S5.T2" class="ltx_table">
<table id="S5.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T2.1.1.1" class="ltx_tr">
<th id="S5.T2.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S5.T2.1.1.1.1.1" class="ltx_text ltx_font_bold">data</span></th>
<th id="S5.T2.1.1.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt"><span id="S5.T2.1.1.1.2.1" class="ltx_text ltx_font_bold"># sentences</span></th>
<th id="S5.T2.1.1.1.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt"><span id="S5.T2.1.1.1.3.1" class="ltx_text ltx_font_bold"># tokens</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T2.1.2.1" class="ltx_tr">
<th id="S5.T2.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">train</th>
<td id="S5.T2.1.2.1.2" class="ltx_td ltx_align_right ltx_border_t">14,600</td>
<td id="S5.T2.1.2.1.3" class="ltx_td ltx_align_right ltx_border_t">407,857</td>
</tr>
<tr id="S5.T2.1.3.2" class="ltx_tr">
<th id="S5.T2.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">dev</th>
<td id="S5.T2.1.3.2.2" class="ltx_td ltx_align_right">1,400</td>
<td id="S5.T2.1.3.2.3" class="ltx_td ltx_align_right">39,326</td>
</tr>
<tr id="S5.T2.1.4.3" class="ltx_tr">
<th id="S5.T2.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">test</th>
<td id="S5.T2.1.4.3.2" class="ltx_td ltx_align_right ltx_border_bb">4,000</td>
<td id="S5.T2.1.4.3.3" class="ltx_td ltx_align_right ltx_border_bb">110,282</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Data split</figcaption>
</figure>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Models</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.3" class="ltx_p">For the models, we used the publicly available checkpoints in Huggingface,<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://huggingface.co/GroNLP/hateBERT" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/GroNLP/hateBERT</a></span></span></span><sup id="S5.SS2.p1.3.1" class="ltx_sup">,</sup><span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a target="_blank" href="https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment</a></span></span></span> training them for 20 epochs using a training batch size of 32 and a maximum sequence length of 128. We use the code<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a target="_blank" href="https://github.com/IyanuSh/YOSM" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/IyanuSh/YOSM</a></span></span></span> and default model hyper-parameters as provided in <cite class="ltx_cite ltx_citemacro_citet">Shode et al. (<a href="#bib.bib12" title="" class="ltx_ref">2022</a>)</cite> to train the models. The configuration uses Adam <cite class="ltx_cite ltx_citemacro_cite">Kingma and Ba (<a href="#bib.bib9" title="" class="ltx_ref">2015</a>)</cite> for optimization, an initial learning rate of <math id="S5.SS2.p1.2.m2.1" class="ltx_Math" alttext="5e-5" display="inline"><semantics id="S5.SS2.p1.2.m2.1a"><mrow id="S5.SS2.p1.2.m2.1.1" xref="S5.SS2.p1.2.m2.1.1.cmml"><mrow id="S5.SS2.p1.2.m2.1.1.2" xref="S5.SS2.p1.2.m2.1.1.2.cmml"><mn id="S5.SS2.p1.2.m2.1.1.2.2" xref="S5.SS2.p1.2.m2.1.1.2.2.cmml">5</mn><mo lspace="0em" rspace="0em" id="S5.SS2.p1.2.m2.1.1.2.1" xref="S5.SS2.p1.2.m2.1.1.2.1.cmml">​</mo><mi id="S5.SS2.p1.2.m2.1.1.2.3" xref="S5.SS2.p1.2.m2.1.1.2.3.cmml">e</mi></mrow><mo id="S5.SS2.p1.2.m2.1.1.1" xref="S5.SS2.p1.2.m2.1.1.1.cmml">−</mo><mn id="S5.SS2.p1.2.m2.1.1.3" xref="S5.SS2.p1.2.m2.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.2.m2.1b"><apply id="S5.SS2.p1.2.m2.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1"><minus id="S5.SS2.p1.2.m2.1.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1.1"></minus><apply id="S5.SS2.p1.2.m2.1.1.2.cmml" xref="S5.SS2.p1.2.m2.1.1.2"><times id="S5.SS2.p1.2.m2.1.1.2.1.cmml" xref="S5.SS2.p1.2.m2.1.1.2.1"></times><cn type="integer" id="S5.SS2.p1.2.m2.1.1.2.2.cmml" xref="S5.SS2.p1.2.m2.1.1.2.2">5</cn><ci id="S5.SS2.p1.2.m2.1.1.2.3.cmml" xref="S5.SS2.p1.2.m2.1.1.2.3">𝑒</ci></apply><cn type="integer" id="S5.SS2.p1.2.m2.1.1.3.cmml" xref="S5.SS2.p1.2.m2.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.2.m2.1c">5e-5</annotation></semantics></math>, and <math id="S5.SS2.p1.3.m3.1" class="ltx_Math" alttext="1e-8" display="inline"><semantics id="S5.SS2.p1.3.m3.1a"><mrow id="S5.SS2.p1.3.m3.1.1" xref="S5.SS2.p1.3.m3.1.1.cmml"><mrow id="S5.SS2.p1.3.m3.1.1.2" xref="S5.SS2.p1.3.m3.1.1.2.cmml"><mn id="S5.SS2.p1.3.m3.1.1.2.2" xref="S5.SS2.p1.3.m3.1.1.2.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S5.SS2.p1.3.m3.1.1.2.1" xref="S5.SS2.p1.3.m3.1.1.2.1.cmml">​</mo><mi id="S5.SS2.p1.3.m3.1.1.2.3" xref="S5.SS2.p1.3.m3.1.1.2.3.cmml">e</mi></mrow><mo id="S5.SS2.p1.3.m3.1.1.1" xref="S5.SS2.p1.3.m3.1.1.1.cmml">−</mo><mn id="S5.SS2.p1.3.m3.1.1.3" xref="S5.SS2.p1.3.m3.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.3.m3.1b"><apply id="S5.SS2.p1.3.m3.1.1.cmml" xref="S5.SS2.p1.3.m3.1.1"><minus id="S5.SS2.p1.3.m3.1.1.1.cmml" xref="S5.SS2.p1.3.m3.1.1.1"></minus><apply id="S5.SS2.p1.3.m3.1.1.2.cmml" xref="S5.SS2.p1.3.m3.1.1.2"><times id="S5.SS2.p1.3.m3.1.1.2.1.cmml" xref="S5.SS2.p1.3.m3.1.1.2.1"></times><cn type="integer" id="S5.SS2.p1.3.m3.1.1.2.2.cmml" xref="S5.SS2.p1.3.m3.1.1.2.2">1</cn><ci id="S5.SS2.p1.3.m3.1.1.2.3.cmml" xref="S5.SS2.p1.3.m3.1.1.2.3">𝑒</ci></apply><cn type="integer" id="S5.SS2.p1.3.m3.1.1.3.cmml" xref="S5.SS2.p1.3.m3.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.3.m3.1c">1e-8</annotation></semantics></math> epsilon for the Adam optimizer.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Results</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">Our experimental results are presented in <a href="#S5.T3" title="In 5.3 Results ‣ 5 Experimental Setup and Results ‣ HausaNLP at SemEval-2023 Task 10: Transfer Learning, Synthetic Data and Side-Information for Multi-Level Sexism Classification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">3</span></a>. From these results, we found that the XLM-T model achieved the best performance on the binary classification task. Even though the HateBERT model was fine-tuned on the abusive and banned data from Reddit (same domain as some of the training and evaluation data), the model was not able to outperform the XLM-T. We will conduct more in-depth experiments to determine the actual reason for this anomaly.</p>
</div>
<figure id="S5.T3" class="ltx_table">
<table id="S5.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T3.1.1.1" class="ltx_tr">
<th id="S5.T3.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Task</th>
<th id="S5.T3.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Method</th>
<th id="S5.T3.1.1.1.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">F1</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T3.1.2.1" class="ltx_tr">
<td id="S5.T3.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t">A</td>
<td id="S5.T3.1.2.1.2" class="ltx_td ltx_align_left ltx_border_t">XLM-T</td>
<td id="S5.T3.1.2.1.3" class="ltx_td ltx_align_right ltx_border_t">0.8228</td>
</tr>
<tr id="S5.T3.1.3.2" class="ltx_tr">
<td id="S5.T3.1.3.2.1" class="ltx_td ltx_align_left">A</td>
<td id="S5.T3.1.3.2.2" class="ltx_td ltx_align_left">HateBERT</td>
<td id="S5.T3.1.3.2.3" class="ltx_td ltx_align_right">0.8172</td>
</tr>
<tr id="S5.T3.1.4.3" class="ltx_tr">
<td id="S5.T3.1.4.3.1" class="ltx_td ltx_align_left ltx_border_t">B</td>
<td id="S5.T3.1.4.3.2" class="ltx_td ltx_align_left ltx_border_t">XLM-T</td>
<td id="S5.T3.1.4.3.3" class="ltx_td ltx_align_right ltx_border_t">0.5981</td>
</tr>
<tr id="S5.T3.1.5.4" class="ltx_tr">
<td id="S5.T3.1.5.4.1" class="ltx_td ltx_align_left">B</td>
<td id="S5.T3.1.5.4.2" class="ltx_td ltx_align_left">XLM-T+synth</td>
<td id="S5.T3.1.5.4.3" class="ltx_td ltx_align_right">0.6012</td>
</tr>
<tr id="S5.T3.1.6.5" class="ltx_tr">
<td id="S5.T3.1.6.5.1" class="ltx_td ltx_align_left ltx_border_t">C</td>
<td id="S5.T3.1.6.5.2" class="ltx_td ltx_align_left ltx_border_t">XLM-T</td>
<td id="S5.T3.1.6.5.3" class="ltx_td ltx_align_right ltx_border_t">0.3565</td>
</tr>
<tr id="S5.T3.1.7.6" class="ltx_tr">
<td id="S5.T3.1.7.6.1" class="ltx_td ltx_align_left ltx_border_bb">C</td>
<td id="S5.T3.1.7.6.2" class="ltx_td ltx_align_left ltx_border_bb">XLM-T+parent class</td>
<td id="S5.T3.1.7.6.3" class="ltx_td ltx_align_right ltx_border_bb">0.4151</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Result of the different tasks.</figcaption>
</figure>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.1" class="ltx_p">For Task B, a slight performance was realized after adding the synthetic data, even though the quality of such data is less than the labelled data. This further reinforces the fact that more data is more often than not beneficial to neural models.</p>
</div>
<div id="S5.SS3.p3" class="ltx_para">
<p id="S5.SS3.p3.1" class="ltx_p">For Task C, we recorded a substantial improvement in the performance of the model after supplementing the side information (the parent class) to influence its prediction. Rather than just passing a sentence and expecting the model to predict over 11 classes, the model performed better when its parent class is known to it at the tokenization stage. We anticipate a slight drop in performance if the parent class information is synthetic rather than, in this case, authentic. However, we cannot substantiate the truthfulness or not of this claim, or the extent of the effect, without conducting further experiments.</p>
</div>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Competition rank</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">We submitted only the XLM-T model in Task A to the competition and although our model ranked 49<sup id="S5.SS4.p1.1.1" class="ltx_sup"><span id="S5.SS4.p1.1.1.1" class="ltx_text ltx_font_italic">th</span></sup>, the best model in the competition track only outperformed our model by 0.052%, as indicated in <a href="#S5.T4" title="In 5.4 Competition rank ‣ 5 Experimental Setup and Results ‣ HausaNLP at SemEval-2023 Task 10: Transfer Learning, Synthetic Data and Side-Information for Multi-Level Sexism Classification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure id="S5.T4" class="ltx_table">
<table id="S5.T4.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T4.1.1.1" class="ltx_tr">
<th id="S5.T4.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S5.T4.1.1.1.1.1" class="ltx_text ltx_font_bold">#</span></th>
<th id="S5.T4.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Team</th>
<th id="S5.T4.1.1.1.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">F1</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T4.1.2.1" class="ltx_tr">
<td id="S5.T4.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t">1</td>
<td id="S5.T4.1.2.1.2" class="ltx_td ltx_align_left ltx_border_t">PingAnLifeInsurance</td>
<td id="S5.T4.1.2.1.3" class="ltx_td ltx_align_right ltx_border_t">0.8746</td>
</tr>
<tr id="S5.T4.1.3.2" class="ltx_tr">
<td id="S5.T4.1.3.2.1" class="ltx_td ltx_align_left">2</td>
<td id="S5.T4.1.3.2.2" class="ltx_td ltx_align_left">stce</td>
<td id="S5.T4.1.3.2.3" class="ltx_td ltx_align_right">0.8740</td>
</tr>
<tr id="S5.T4.1.4.3" class="ltx_tr">
<td id="S5.T4.1.4.3.1" class="ltx_td ltx_align_left">3</td>
<td id="S5.T4.1.4.3.2" class="ltx_td ltx_align_left">FiRC-NLP</td>
<td id="S5.T4.1.4.3.3" class="ltx_td ltx_align_right">0.8740</td>
</tr>
<tr id="S5.T4.1.5.4" class="ltx_tr">
<td id="S5.T4.1.5.4.1" class="ltx_td ltx_align_left">4</td>
<td id="S5.T4.1.5.4.2" class="ltx_td ltx_align_left">PALI</td>
<td id="S5.T4.1.5.4.3" class="ltx_td ltx_align_right">0.8717</td>
</tr>
<tr id="S5.T4.1.6.5" class="ltx_tr">
<td id="S5.T4.1.6.5.1" class="ltx_td ltx_align_left">5</td>
<td id="S5.T4.1.6.5.2" class="ltx_td ltx_align_left">GZHU / UCAS-IIE</td>
<td id="S5.T4.1.6.5.3" class="ltx_td ltx_align_right">0.8692</td>
</tr>
<tr id="S5.T4.1.7.6" class="ltx_tr">
<td id="S5.T4.1.7.6.1" class="ltx_td ltx_align_left">⋮</td>
<td id="S5.T4.1.7.6.2" class="ltx_td ltx_align_left">⋮</td>
<td id="S5.T4.1.7.6.3" class="ltx_td ltx_align_right">⋮</td>
</tr>
<tr id="S5.T4.1.8.7" class="ltx_tr">
<td id="S5.T4.1.8.7.1" class="ltx_td ltx_align_left">49</td>
<td id="S5.T4.1.8.7.2" class="ltx_td ltx_align_left">HausaNLP</td>
<td id="S5.T4.1.8.7.3" class="ltx_td ltx_align_right">0.8228</td>
</tr>
<tr id="S5.T4.1.9.8" class="ltx_tr">
<td id="S5.T4.1.9.8.1" class="ltx_td ltx_align_left">⋮</td>
<td id="S5.T4.1.9.8.2" class="ltx_td ltx_align_left">⋮</td>
<td id="S5.T4.1.9.8.3" class="ltx_td ltx_align_right">⋮</td>
</tr>
<tr id="S5.T4.1.10.9" class="ltx_tr">
<td id="S5.T4.1.10.9.1" class="ltx_td ltx_align_left ltx_border_bb">84</td>
<td id="S5.T4.1.10.9.2" class="ltx_td ltx_align_left ltx_border_bb">NLP_CHRISTINE</td>
<td id="S5.T4.1.10.9.3" class="ltx_td ltx_align_right ltx_border_bb">0.5029</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Task A official ranking</figcaption>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this system description paper, we describe our submission for the subtask A binary classification of comments into sexist and not sexist submitted to the SemEval-2023 Task 10 - Explainable Detection of Online Sexism (EDOS). We implemented pretrained models using XLM-T and HateBERT on the English Language Twitter. Our model achieved competitive result of 82% using F1 score, slightly below the leader with 87%. However, this performance is not exhaustive as we observe great imbalance in the distribution of the dataset and this could have influenced the results. Furthermore, we described our attempts at building competitive models for Tasks B and C (which we did not submit to the competition). We utilised synthetic data and parent class information to improve the performances of the two models in the respective tasks, and some improvements were observed. Finally, we intend to improve the performances of these models by targeting the data imbalance constraint using data augmentation strategies.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aliyu et al. (2022)</span>
<span class="ltx_bibblock">
Saminu Mohammad Aliyu, Gregory Maksha Wajiga, Muhammad Murtala,
Shamsuddeen Hassan Muhammad, Idris Abdulmumin, and Ibrahim Said Ahmad. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2211.15262" title="" class="ltx_ref ltx_href">HERDPhobia: A
Dataset for Hate Speech against Fulani in Nigeria</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proceedings of the The Sixth Widening NLP Workshop (WiNLP)</em>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Barbieri et al. (2022)</span>
<span class="ltx_bibblock">
Francesco Barbieri, Luis Espinosa Anke, and Jose Camacho-Collados. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2022.lrec-1.27" title="" class="ltx_ref ltx_href">XLM-T:
Multilingual language models in Twitter for sentiment analysis and beyond</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Thirteenth Language Resources and
Evaluation Conference</em>, pages 258–266, Marseille, France. European Language
Resources Association.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Canós (2018)</span>
<span class="ltx_bibblock">
Jose Sebastián Canós. 2018.

</span>
<span class="ltx_bibblock">Misogyny identification through svm at ibereval 2018.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Ibereval@ sepln</em>, pages 229–233.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caselli et al. (2020)</span>
<span class="ltx_bibblock">
Tommaso Caselli, Valerio Basile, Jelena Mitrović, and Michael Granitzer.
2020.

</span>
<span class="ltx_bibblock">Hatebert: Retraining bert for abusive language detection in english.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.12472</em>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conneau et al. (2019)</span>
<span class="ltx_bibblock">
Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume
Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, and
Veselin Stoyanov. 2019.

</span>
<span class="ltx_bibblock">Unsupervised cross-lingual representation learning at scale.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1911.02116</em>.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al. (2018)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018.

</span>
<span class="ltx_bibblock">Bert: Pre-training of deep bidirectional transformers for language
understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1810.04805</em>.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Istaiteh et al. (2020)</span>
<span class="ltx_bibblock">
Othman Istaiteh, Razan Al-Omoush, and Sara Tedmori. 2020.

</span>
<span class="ltx_bibblock">Racist and sexist hate speech detection: Literature review.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">2020 International Conference on Intelligent Data Science
Technologies and Applications (IDSTA)</em>, pages 95–99. IEEE.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2022)</span>
<span class="ltx_bibblock">
Aiqi Jiang, Xiaohan Yang, Yang Liu, and Arkaitz Zubiaga. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/https://doi.org/10.1016/j.osnem.2021.100182" title="" class="ltx_ref ltx_href">Swsr: A chinese dataset and lexicon for online sexism detection</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Online Social Networks and Media</em>, 27:100182.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma and Ba (2015)</span>
<span class="ltx_bibblock">
Diederik P. Kingma and Jimmy Ba. 2015.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1412.6980" title="" class="ltx_ref ltx_href">Adam: A method for
stochastic optimization</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">3rd International Conference on Learning Representations,
ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track
Proceedings</em>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kirk et al. (2023)</span>
<span class="ltx_bibblock">
Hannah Rose Kirk, Wenjie Yin, Bertie Vidgen, and Paul Röttger. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2303.04222" title="" class="ltx_ref ltx_href">SemEval-2023
Task 10: Explainable Detection of Online Sexism</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 17th International Workshop on Semantic
Evaluation</em>, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rodríguez-Sánchez et al. (2020)</span>
<span class="ltx_bibblock">
Francisco Rodríguez-Sánchez, Jorge Carrillo-de Albornoz, and Laura
Plaza. 2020.

</span>
<span class="ltx_bibblock">Automatic classification of sexism in social networks: An empirical
study on twitter data.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, 8:219563–219576.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shode et al. (2022)</span>
<span class="ltx_bibblock">
Iyanuoluwa Shode, David Ifeoluwa Adelani, and Anna Feldman. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=rRzx5qzVIb9" title="" class="ltx_ref ltx_href">YOSM: A new
Yorùbá Sentiment Corpus for Movie Reviews</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">AfricaNLP 2022 @ICLR</em>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Waseem and Hovy (2016)</span>
<span class="ltx_bibblock">
Zeerak Waseem and Dirk Hovy. 2016.

</span>
<span class="ltx_bibblock">Hateful symbols or hateful people? predictive features for hate
speech detection on twitter.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proceedings of the NAACL student research workshop</em>, pages
88–93.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2305.00075" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2305.00076" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2305.00076">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2305.00076" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2305.00077" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Feb 29 10:31:22 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
