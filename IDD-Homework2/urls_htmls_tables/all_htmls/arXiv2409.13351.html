<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Comparative Analysis of Data Augmentation for Retinal OCT Biomarker Segmentation</title>
<!--Generated on Fri Sep 20 09:23:35 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Machine Learning Data Augmentation Retinal OCT fluid segmentation" lang="en" name="keywords"/>
<base href="/html/2409.13351v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#S1" title="In Comparative Analysis of Data Augmentation for Retinal OCT Biomarker Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#S1.SS0.SSS0.Px1" title="In 1 Introduction ‣ Comparative Analysis of Data Augmentation for Retinal OCT Biomarker Segmentation"><span class="ltx_text ltx_ref_title">Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#S1.SS0.SSS0.Px2" title="In 1 Introduction ‣ Comparative Analysis of Data Augmentation for Retinal OCT Biomarker Segmentation"><span class="ltx_text ltx_ref_title">Contributions:</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#S2" title="In Comparative Analysis of Data Augmentation for Retinal OCT Biomarker Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Materials and Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#S2.SS0.SSS0.Px1" title="In 2 Materials and Methodology ‣ Comparative Analysis of Data Augmentation for Retinal OCT Biomarker Segmentation"><span class="ltx_text ltx_ref_title">Datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#S2.SS1" title="In 2 Materials and Methodology ‣ Comparative Analysis of Data Augmentation for Retinal OCT Biomarker Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Acquisition-related Scan Characterization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#S2.SS2" title="In 2 Materials and Methodology ‣ Comparative Analysis of Data Augmentation for Retinal OCT Biomarker Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Data Augmentation techniques</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#S3" title="In Comparative Analysis of Data Augmentation for Retinal OCT Biomarker Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Experiments and Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#S3.SS0.SSS0.Px1" title="In 3 Experiments and Results ‣ Comparative Analysis of Data Augmentation for Retinal OCT Biomarker Segmentation"><span class="ltx_text ltx_ref_title">Segmentation architecture</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#S3.SS0.SSS0.Px2" title="In 3 Experiments and Results ‣ Comparative Analysis of Data Augmentation for Retinal OCT Biomarker Segmentation"><span class="ltx_text ltx_ref_title">Layer segmentation task</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#S3.SS0.SSS0.Px3" title="In 3 Experiments and Results ‣ Comparative Analysis of Data Augmentation for Retinal OCT Biomarker Segmentation"><span class="ltx_text ltx_ref_title">Fluid segmentation task</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#S4" title="In Comparative Analysis of Data Augmentation for Retinal OCT Biomarker Segmentation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\useunder</span>
<p class="ltx_p" id="p1.2"><span class="ltx_text ltx_ulem_uline" id="p1.2.1"></span><span class="ltx_text ltx_framed ltx_framed_underline" id="p1.2.2"></span>
</p>
</div>
<span class="ltx_note ltx_role_institutetext" id="id1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>Christian Doppler Laboratory for Artificial Intelligence in Retina, Department of Ophthalmology and Optometry, Medical University of Vienna, Austria
<br class="ltx_break"/><span class="ltx_note ltx_role_email" id="id1.1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">email: </span>m.unterdechler@gmx.at, hrvoje.bogunovic@meduniwien.ac.at</span></span></span></span></span></span>
<h1 class="ltx_title ltx_title_document">Comparative Analysis of Data Augmentation 
<br class="ltx_break"/>for Retinal OCT Biomarker Segmentation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Markus Unterdechler
</span><span class="ltx_author_notes">Correspondence to Markus Unterdechler</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Botond Fazekas
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Guilherme Aresta
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<br class="ltx_break"/>and Hrvoje Bogunović
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">Data augmentation plays a crucial role in addressing the challenge of limited expert-annotated datasets in deep learning applications for retinal Optical Coherence Tomography (OCT) scans. This work exhaustively investigates the impact of various data augmentation techniques on retinal layer boundary and fluid segmentation. Our results reveal that their effectiveness significantly varies based on the dataset’s characteristics and the amount of available labeled data. While the benefits of augmentation are not uniform—being more pronounced in scenarios with scarce data, particularly for transformation-based methods—the findings highlight the necessity of a strategic approach to data augmentation. It is essential to note that the effectiveness of data augmentation varies significantly depending on the characteristics of the dataset. The findings emphasize the need for a nuanced approach, considering factors like dataset characteristics, the amount of labelled data, and the choice of model architecture.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>Machine Learning Data Augmentation Retinal OCT fluid segmentation
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Optical coherence tomography (OCT) is a widely used 3D retinal imaging modality, aiding in the assessment of biomarkers like retinal layer thickness and fluid volume, key for diagnosing and treating retinal diseases such as age-related macular degeneration (AMD), retinal vein occlusion (RVO), and diabetic macular edema (DME), the leading causes of blindness. In particular, accurate detection and quantification of fluid accumulations, such as intraretinal fluid (IRF), subretinal fluid (SRF), and pigment epithelial detachment (PED), are important for clinical decision-making due to their direct relation to disease activity. Automated OCT segmentation algorithms offer potential but their development and validation is limited.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Data augmentation enriches labeled datasets through a variety of transformations, from rotations and scalings to more advanced techniques such as introducing specialized noise, specific to OCT scans or using Generative Adversarial Networks (GANs) to generate synthetic data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#bib.bib17" title="">17</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#bib.bib4" title="">4</a>]</cite>. This process enhances model resilience against image variation and improves generalization <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#bib.bib19" title="">19</a>]</cite>. However, the effectiveness of augmentation varies with data characteristics, necessitating thorough comparative analysis to optimize its application across diverse domains.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">In the field of retinal fluid segmentation on OCT scans, researchers use a plethora of methods for data augmentation. However, the absence of a standardised comparative study has resulted in a lack of understanding of the most effective approach. In this study we evaluate different data augmentation techniques to assess their influence on training performance relative to dataset characteristics. The results will be used to guide the selection of appropriate strategies for specific use cases.</p>
</div>
<section class="ltx_paragraph" id="S1.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Related Work</h4>
<div class="ltx_para" id="S1.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S1.SS0.SSS0.Px1.p1.1">Chlap <span class="ltx_text ltx_font_italic" id="S1.SS0.SSS0.Px1.p1.1.1">et al.<cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text ltx_font_upright" id="S1.SS0.SSS0.Px1.p1.1.1.1.1">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#bib.bib4" title="">4</a><span class="ltx_text ltx_font_upright" id="S1.SS0.SSS0.Px1.p1.1.1.2.2">]</span></cite></span> categorised data augmentation methods for deep learning-based medical imaging applications (Supplement Fig. S1). Augmentation techniques were categorized into four groups: <em class="ltx_emph ltx_font_italic" id="S1.SS0.SSS0.Px1.p1.1.2">Basic</em>, <em class="ltx_emph ltx_font_italic" id="S1.SS0.SSS0.Px1.p1.1.3">Deformation</em>, <em class="ltx_emph ltx_font_italic" id="S1.SS0.SSS0.Px1.p1.1.4">Deep Learning</em> and <em class="ltx_emph ltx_font_italic" id="S1.SS0.SSS0.Px1.p1.1.5">Other</em>. The Basic transformations include linear affine transformations and any adjustments to pixel intensity levels. Deformation covers various elastic transformations, while the Deep Learning category refers to augmentation techniques that generate synthetic data using deep learning techniques. They found that the basic transformations are the most prevalent due to their simplicity and rapid implementation during training <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#bib.bib3" title="">3</a>]</cite>.
For instance, Bar-David <span class="ltx_text ltx_font_italic" id="S1.SS0.SSS0.Px1.p1.1.6">et al.<cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text ltx_font_upright" id="S1.SS0.SSS0.Px1.p1.1.6.1.1">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#bib.bib1" title="">1</a><span class="ltx_text ltx_font_upright" id="S1.SS0.SSS0.Px1.p1.1.6.2.2">]</span></cite></span> showed that shallow networks can outperform deeper networks by using data augmentation in a pixel-wise segmentation task. They used various augmentation techniques, such as affine transformations, flipping, noise induction, contrast saturation, and elastic transformations.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="298" id="S1.F1.g1" src="x1.png" width="664"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overview of the number of papers found that use certain data augmentation techniques in retinal OCT segmentation studies.</figcaption>
</figure>
<div class="ltx_para" id="S1.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="S1.SS0.SSS0.Px1.p2.1">Currently, there is no standard data augmentation approach for retinal OCT. Reviewing 33 works on this topic (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#S1.F1" title="Figure 1 ‣ Related Work ‣ 1 Introduction ‣ Comparative Analysis of Data Augmentation for Retinal OCT Biomarker Segmentation"><span class="ltx_text ltx_ref_tag">1</span></a>), the most common augmentations were methods such as random horizontal flipping and linear affine transformations, due to their computational efficiency and effectiveness in reflecting biological structures (e.g., <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#bib.bib6" title="">6</a>]</cite>). These methods have demonstrated their capability in effectively decreasing overfitting <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#bib.bib13" title="">13</a>]</cite>. Cropping reduces the input size but has a comparable effect to affine translations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#bib.bib19" title="">19</a>]</cite>. Some studies have focused on dataset standardization rather than augmentation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#bib.bib18" title="">18</a>]</cite>. Noise-related augmentations, primarily Gaussian noise <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#bib.bib21" title="">21</a>]</cite>, but also speckle noise <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#bib.bib12" title="">12</a>]</cite>, blurring, and sharpening effects, were observed, along with intensity adjustments like brightness, contrast, and HSV color space alterations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#bib.bib14" title="">14</a>]</cite>. Deformation-related augmentations were less common <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#bib.bib9" title="">9</a>]</cite>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S1.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Contributions:</h4>
<div class="ltx_para" id="S1.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S1.SS0.SSS0.Px2.p1.1">There are significant differences in augmentation choices among studies addressing the same domain and tasks, underscoring the need for a comprehensive assessment to establish a state-of-the-art approach. This foundational study contribute to the field of automated retinal OCT analysis by conducting exhaustive evaluation on the influence of traditional data augmentation techniques on the two clinically most relevant tasks of retinal layer boundary and fluid segmentation. We propose metrics that can be used to describe the intrinsic characteristics of the dataset, and use them to support the hypothesis of when augmentation types should be used. Furthermore, we demonstrate techniques to improve generalization across different scanner types. Thus, we provide <em class="ltx_emph ltx_font_italic" id="S1.SS0.SSS0.Px2.p1.1.1">guidelines</em>, which data augmentation techniques to use, taking into account the objective of the task and the characteristics of the datasets. We focus on traditional augmentation techniques as these techniques are the most widely used in the literature, so a comparative study of these techniques will have the greatest impact in this area.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Materials and Methodology</h2>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Datasets</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.1">The effect of data augmentation on retinal segmentation tasks were evaluated on two publicly available retinal OCT datasets and on a private one.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p2.1">The public <em class="ltx_emph ltx_font_italic" id="S2.SS0.SSS0.Px1.p2.1.1">MSHC</em> dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#bib.bib6" title="">6</a>]</cite> comprises of 14 volumes from healthy controls (HCs) and 21 with multiple sclerosis (MS). Each volume has 49 B-scans obtained with a Spectralis (Heidelberg Engineering, Germany) scanner, with 9 manually annotated surfaces.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p3">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p3.1">The public <em class="ltx_emph ltx_font_italic" id="S2.SS0.SSS0.Px1.p3.1.1">RETOUCH</em> dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#bib.bib2" title="">2</a>]</cite> comprises of 112 OCT volumes gathered from patients with macular edema due to AMD or RVO. It contains manual annotations for intraretinal fluid (IRF), subretinal fluid (SRF), and pigment epithelial detachment (PED). The training set includes 70 OCT volumes and the test set consists of 42 scans, which were captured in approximately equal numbers using three different devices: Spectralis, and the considerably noisier Cirrus HD-OCT (Zeiss Meditec, Germany) and T-1000/T-2000 (Topcon, Japan).</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p4">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p4.1">The private <em class="ltx_emph ltx_font_italic" id="S2.SS0.SSS0.Px1.p4.1.1">Multibiomarker</em> dataset has 85 macula-centered Spectralis OCT scans from different patients, ranging from 18 to 97 B-scans in resolution. It was obtained during routine clinical check-ups of patients with neovascular AMD patients undergoing treatment, providing insights into real-world clinical situations, with 11 manually annotated layers.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Acquisition-related Scan Characterization</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">We hypothesise that the impact of different data augmentation techniques depends on acquisition-related characteristics of retinal OCTs, namely <em class="ltx_emph ltx_font_italic" id="S2.SS1.p1.1.1">Symmetry</em>, <em class="ltx_emph ltx_font_italic" id="S2.SS1.p1.1.2">Contrast</em>, <em class="ltx_emph ltx_font_italic" id="S2.SS1.p1.1.3">Signal-to-noise-ratio</em> and <em class="ltx_emph ltx_font_italic" id="S2.SS1.p1.1.4">Alignment</em>.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1"><em class="ltx_emph ltx_font_italic" id="S2.SS1.p2.1.1">Alignment</em> measures the degree of the horizontal alignment of the retina within OCT scans. It is calculated based on the highest pixel value per column in the scan image, corresponding to the high intensity of the RPE layer. <em class="ltx_emph ltx_font_italic" id="S2.SS1.p2.1.2">Symmetry</em> addresses the retinal structure similarity between the left and right portions of a B-scan. First, the retina is flattened, by rotating the image such the RPE layer becomes horizontally, and then the left and right halves are compared using the Normalised Cross-Correlation Coefficient. To reduce sensitivity to noise, a small Gaussian blur filter is applied. <em class="ltx_emph ltx_font_italic" id="S2.SS1.p2.1.3">Contrast</em> relates to the difference in luminance between different parts of the image, which significantly affects the ability to assess different biomarkers. As a measurement, the standard deviation of the intensity histogram was used. The Signal-to-Noise ratio (SNR) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#bib.bib8" title="">8</a>]</cite> is used to quantify the <em class="ltx_emph ltx_font_italic" id="S2.SS1.p2.1.4">Noise</em> level in OCT scans. Each metric provides a float value. Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#S2.F2" title="Figure 2 ‣ 2.1 Acquisition-related Scan Characterization ‣ 2 Materials and Methodology ‣ Comparative Analysis of Data Augmentation for Retinal OCT Biomarker Segmentation"><span class="ltx_text ltx_ref_tag">2</span></a> illustrates extreme cases.</p>
</div>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="200" id="S2.F2.g1" src="x2.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>High and low value examples of OCT scans per metric.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Data Augmentation techniques</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">We assess data augmentation techniques from five distinct groups: Transformation, Deformation, Intensity, Noise, and Domain Specific (Table <a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#S2.T1" title="Table 1 ‣ 2.2 Data Augmentation techniques ‣ 2 Materials and Methodology ‣ Comparative Analysis of Data Augmentation for Retinal OCT Biomarker Segmentation"><span class="ltx_text ltx_ref_tag">1</span></a>). The evaluated hyperparameters ranges are displayed in Table S1 in the Supplement.</p>
</div>
<figure class="ltx_table" id="S2.T1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S2.T1.1" style="width:433.6pt;height:117.3pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-0.8pt,0.2pt) scale(0.99639,0.99639) ;">
<p class="ltx_p" id="S2.T1.1.1"><span class="ltx_text" id="S2.T1.1.1.1">
<span class="ltx_inline-block ltx_transformed_outer" id="S2.T1.1.1.1.1" style="width:435.2pt;height:117.8pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span class="ltx_p" id="S2.T1.1.1.1.1.1"><span class="ltx_text" id="S2.T1.1.1.1.1.1.1">
<span class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S2.T1.1.1.1.1.1.1.1">
<span class="ltx_thead">
<span class="ltx_tr" id="S2.T1.1.1.1.1.1.1.1.2.1">
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S2.T1.1.1.1.1.1.1.1.2.1.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.1.1.1.1.2.1.1.1" style="font-size:90%;">Transformation</span></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S2.T1.1.1.1.1.1.1.1.2.1.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.1.1.1.1.2.1.2.1" style="font-size:90%;">Deformation</span></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S2.T1.1.1.1.1.1.1.1.2.1.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.1.1.1.1.2.1.3.1" style="font-size:90%;">Intensity</span></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S2.T1.1.1.1.1.1.1.1.2.1.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.1.1.1.1.2.1.4.1" style="font-size:90%;">Noise</span></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S2.T1.1.1.1.1.1.1.1.2.1.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.1.1.1.1.2.1.5.1" style="font-size:90%;">Domain Specific</span></span></span>
</span>
<span class="ltx_tbody">
<span class="ltx_tr" id="S2.T1.1.1.1.1.1.1.1.1">
<span class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.1.1.1.1.1.1.1.1.1" style="padding-bottom:0.0pt;padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_ERROR undefined" id="S2.T1.1.1.1.1.1.1.1.1.1.1">\vcell</span><span class="ltx_text" id="S2.T1.1.1.1.1.1.1.1.1.1.2" style="font-size:90%;">
</span><math alttext="\left.\begin{tabular}[p]{@{}c@{}}Rotation\\
Shear\\
Scale\\
Translate\end{tabular}\right\}" class="ltx_math_unparsed" display="inline" id="S2.T1.1.1.1.1.1.1.1.1.1.m1.1"><semantics id="S2.T1.1.1.1.1.1.1.1.1.1.m1.1a"><mrow id="S2.T1.1.1.1.1.1.1.1.1.1.m1.1b"><mtable id="S2.T1.1.1.1.1.1.1.1.1.1.m1.1.1" rowspacing="0pt"><mtr id="S2.T1.1.1.1.1.1.1.1.1.1.m1.1.1a"><mtd class="ltx_nopad_r" id="S2.T1.1.1.1.1.1.1.1.1.1.m1.1.1b"><mtext id="S2.T1.1.1.1.1.1.1.1.1.1.m1.1.1.1.1.1" mathsize="90%">Rotation</mtext></mtd></mtr><mtr id="S2.T1.1.1.1.1.1.1.1.1.1.m1.1.1c"><mtd class="ltx_nopad_r" id="S2.T1.1.1.1.1.1.1.1.1.1.m1.1.1d"><mtext id="S2.T1.1.1.1.1.1.1.1.1.1.m1.1.1.2.1.1" mathsize="90%">Shear</mtext></mtd></mtr><mtr id="S2.T1.1.1.1.1.1.1.1.1.1.m1.1.1e"><mtd class="ltx_nopad_r" id="S2.T1.1.1.1.1.1.1.1.1.1.m1.1.1f"><mtext id="S2.T1.1.1.1.1.1.1.1.1.1.m1.1.1.3.1.1" mathsize="90%">Scale</mtext></mtd></mtr><mtr id="S2.T1.1.1.1.1.1.1.1.1.1.m1.1.1g"><mtd class="ltx_nopad_r" id="S2.T1.1.1.1.1.1.1.1.1.1.m1.1.1h"><mtext id="S2.T1.1.1.1.1.1.1.1.1.1.m1.1.1.4.1.1" mathsize="90%">Translate</mtext></mtd></mtr></mtable><mo id="S2.T1.1.1.1.1.1.1.1.1.1.m1.1.2">}</mo></mrow><annotation encoding="application/x-tex" id="S2.T1.1.1.1.1.1.1.1.1.1.m1.1c">\left.\begin{tabular}[p]{@{}c@{}}Rotation\\
Shear\\
Scale\\
Translate\end{tabular}\right\}</annotation><annotation encoding="application/x-llamapun" id="S2.T1.1.1.1.1.1.1.1.1.1.m1.1d">start_ROW start_CELL Rotation end_CELL end_ROW start_ROW start_CELL Shear end_CELL end_ROW start_ROW start_CELL Scale end_CELL end_ROW start_ROW start_CELL Translate end_CELL end_ROW }</annotation></semantics></math><span class="ltx_text" id="S2.T1.1.1.1.1.1.1.1.1.1.3" style="font-size:90%;"> </span>
<span class="ltx_inline-block ltx_transformed_outer" id="S2.T1.1.1.1.1.1.1.1.1.1.4" style="width:6.3pt;height:23.8pt;vertical-align:-8.8pt;"><span class="ltx_transformed_inner" style="width:23.8pt;transform:translate(-8.75pt,0pt) rotate(-90deg) ;">
<span class="ltx_p" id="S2.T1.1.1.1.1.1.1.1.1.1.4.1"><span class="ltx_text" id="S2.T1.1.1.1.1.1.1.1.1.1.4.1.1" style="font-size:90%;">Affine</span></span>
</span></span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.1.1.1.1.1.1.1.1.2" style="padding-bottom:0.0pt;padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_ERROR undefined" id="S2.T1.1.1.1.1.1.1.1.1.2.1">\vcell</span>
<span class="ltx_tabular ltx_align_bottom" id="S2.T1.1.1.1.1.1.1.1.1.2.2">
<span class="ltx_tr" id="S2.T1.1.1.1.1.1.1.1.1.2.2.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S2.T1.1.1.1.1.1.1.1.1.2.2.1.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S2.T1.1.1.1.1.1.1.1.1.2.2.1.1.1" style="font-size:90%;">Short Elastic</span></span></span>
<span class="ltx_tr" id="S2.T1.1.1.1.1.1.1.1.1.2.2.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S2.T1.1.1.1.1.1.1.1.1.2.2.2.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S2.T1.1.1.1.1.1.1.1.1.2.2.2.1.1" style="font-size:90%;">Long Elastic</span></span></span>
</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.1.1.1.1.1.1.1.1.3" style="padding-bottom:0.0pt;padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_ERROR undefined" id="S2.T1.1.1.1.1.1.1.1.1.3.1">\vcell</span>
<span class="ltx_tabular ltx_align_bottom" id="S2.T1.1.1.1.1.1.1.1.1.3.2">
<span class="ltx_tr" id="S2.T1.1.1.1.1.1.1.1.1.3.2.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S2.T1.1.1.1.1.1.1.1.1.3.2.1.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S2.T1.1.1.1.1.1.1.1.1.3.2.1.1.1" style="font-size:90%;">Contrast Adjustment</span></span></span>
<span class="ltx_tr" id="S2.T1.1.1.1.1.1.1.1.1.3.2.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S2.T1.1.1.1.1.1.1.1.1.3.2.2.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S2.T1.1.1.1.1.1.1.1.1.3.2.2.1.1" style="font-size:90%;">Histogram Matching</span></span></span>
</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.1.1.1.1.1.1.1.1.4" style="padding-bottom:0.0pt;padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_ERROR undefined" id="S2.T1.1.1.1.1.1.1.1.1.4.1">\vcell</span>
<span class="ltx_tabular ltx_align_bottom" id="S2.T1.1.1.1.1.1.1.1.1.4.2">
<span class="ltx_tr" id="S2.T1.1.1.1.1.1.1.1.1.4.2.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S2.T1.1.1.1.1.1.1.1.1.4.2.1.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S2.T1.1.1.1.1.1.1.1.1.4.2.1.1.1" style="font-size:90%;">Gaussian Noise</span></span></span>
<span class="ltx_tr" id="S2.T1.1.1.1.1.1.1.1.1.4.2.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S2.T1.1.1.1.1.1.1.1.1.4.2.2.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S2.T1.1.1.1.1.1.1.1.1.4.2.2.1.1" style="font-size:90%;">Speckle Noise</span></span></span>
<span class="ltx_tr" id="S2.T1.1.1.1.1.1.1.1.1.4.2.3">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S2.T1.1.1.1.1.1.1.1.1.4.2.3.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S2.T1.1.1.1.1.1.1.1.1.4.2.3.1.1" style="font-size:90%;">SVD Noise Transfer</span></span></span>
</span></span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.1.1.1.1.1.1.1.1.5" style="padding-bottom:0.0pt;padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_ERROR undefined" id="S2.T1.1.1.1.1.1.1.1.1.5.1">\vcell</span><span class="ltx_text" id="S2.T1.1.1.1.1.1.1.1.1.5.2" style="font-size:90%;">Vessel Simulation</span></span></span>
<span class="ltx_tr" id="S2.T1.1.1.1.1.1.1.1.3.1">
<span class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.1.1.1.1.1.1.1.3.1.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_ERROR undefined" id="S2.T1.1.1.1.1.1.1.1.3.1.1.1">\printcelltop</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.1.1.1.1.1.1.1.3.1.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_ERROR undefined" id="S2.T1.1.1.1.1.1.1.1.3.1.2.1">\printcelltop</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.1.1.1.1.1.1.1.3.1.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_ERROR undefined" id="S2.T1.1.1.1.1.1.1.1.3.1.3.1">\printcelltop</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.1.1.1.1.1.1.1.3.1.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_ERROR undefined" id="S2.T1.1.1.1.1.1.1.1.3.1.4.1">\printcelltop</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.1.1.1.1.1.1.1.3.1.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_ERROR undefined" id="S2.T1.1.1.1.1.1.1.1.3.1.5.1">\printcelltop</span></span></span>
</span>
</span><span class="ltx_text" id="S2.T1.1.1.1.1.1.1.2" style="font-size:90%;"></span></span></span>
</span></span></span></p>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Overview of the data augmentation categories</figcaption>
</figure>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p2.1.1">Transformation</span>-based techniques, encapsulated under the term <span class="ltx_text ltx_font_italic" id="S2.SS2.p2.1.2">Affine transformations</span>, introduce geometric variations, e.g., rotation, translation, scaling, and shearing to mimic real-world data fluctuations. This approach ensures model robustness against orientation, position, scale, and shape variations by applying transformations uniformly to images and labels.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p3.1.1">Deformation</span> augmentations utilize 2D elastic transformations to introduce distortions to the data. This technique can simulate local non-linear, wave-like deformations that reflect anatomical variability observed in patients. Two settings are explored: <span class="ltx_text ltx_font_italic" id="S2.SS2.p3.1.2">Long Elastic</span> with wider spacing and <span class="ltx_text ltx_font_italic" id="S2.SS2.p3.1.3">Short Elastic</span> with finer granular deformations.</p>
</div>
<div class="ltx_para" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p4.1.1">Intensity</span>-related augmentation methods, such as <em class="ltx_emph ltx_font_italic" id="S2.SS2.p4.1.2">Contrast Adjustment</em> and <em class="ltx_emph ltx_font_italic" id="S2.SS2.p4.1.3">Random Histogram Matching</em>, change pixel values without altering spatial arrangement. <em class="ltx_emph ltx_font_italic" id="S2.SS2.p4.1.4">Contrast Adjustment</em> changes contrast to delineate light and dark areas more or less distinctly, whereas <em class="ltx_emph ltx_font_italic" id="S2.SS2.p4.1.5">Random Histogram Matching (RH Matching)</em> aligns the pixel value distribution of a target image with that of a randomly chosen source image. This ensures similar contrast and brightness characteristics between the target and source images, to reduce the model’s sensitivity to illumination variations.</p>
</div>
<div class="ltx_para" id="S2.SS2.p5">
<p class="ltx_p" id="S2.SS2.p5.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p5.1.1">Noise</span> augmentations add artificial noise to OCT scans, enhancing model robustness by training on data mimicking real-world imperfections. <span class="ltx_text ltx_font_italic" id="S2.SS2.p5.1.2">Gaussian noise</span> introduces random variations to pixel values based on a Gaussian distribution, adjusting image brightness and texture. <span class="ltx_text ltx_font_italic" id="S2.SS2.p5.1.3">Speckle noise</span>, characteristic of OCT due to coherent light interference, is simulated through granular pixel fluctuations corresponding to the Poission distribution. <span class="ltx_text ltx_font_italic" id="S2.SS2.p5.1.4">Singular Value Decomposition Noise Transfer (SVD Noise Transfer)</span> proposed by Koch <span class="ltx_text ltx_font_italic" id="S2.SS2.p5.1.5">et al.<cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text ltx_font_upright" id="S2.SS2.p5.1.5.1.1">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#bib.bib10" title="">10</a><span class="ltx_text ltx_font_upright" id="S2.SS2.p5.1.5.2.2">]</span></cite></span> transfers noise characteristics between OCT scans via singular value decomposition, enriching training data with realistic noise patterns.</p>
</div>
<div class="ltx_para" id="S2.SS2.p6">
<p class="ltx_p" id="S2.SS2.p6.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p6.1.1">Domain-Specific</span> augmentation leverages specialized knowledge to tailor data enhancement for specific applications. In retinal OCT scans, the model’s robustness against variations caused by vessel shadows can be improved by simulating them during training. <span class="ltx_text ltx_font_italic" id="S2.SS2.p6.1.2">Vessel Simulation</span> randomly sets the count, dimensions, and placement of simulated shadows within predefined limits and applies corresponding shading to image columns to replicate vessel appearances. This process helps the model learn to recognize and adapt to vessel-related variations in OCT images.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experiments and Results</h2>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Segmentation architecture</h4>
<div class="ltx_para" id="S3.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px1.p1.1">The layer and fluid segmentation was performed using a U-Net-based retinal biomarker segmentation architecture proposed by He <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p1.1.1">et al.<cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text ltx_font_upright" id="S3.SS0.SSS0.Px1.p1.1.1.1.1">[</span><a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#bib.bib7" title="">7</a><span class="ltx_text ltx_font_upright" id="S3.SS0.SSS0.Px1.p1.1.1.2.2">]</span></cite></span>, with the encoder replaced by a ResNet-34.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Layer segmentation task</h4>
<div class="ltx_para" id="S3.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px2.p1.5">In the layer segmentation experiments, augmentation types were applied to every scan with varying intensity and evaluated under three scenarios: using all volumes, training with 4 patient volumes containing 7 slices each, and with 2 patient volumes of 7 slices. The training was conducted using a batch size of 4 and lasted for 200 epochs. A learning rate of 1e-3 was utilized, with a warm-up period of 20 epochs and cosine decay. The Adam optimizer was employed for optimization during training. A combination of DiceCE, KL and L1 loss was used as proposed by He <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px2.p1.5.1">et al.</span>. The 5-fold cross-validation outcomes for these tasks on the <em class="ltx_emph ltx_font_italic" id="S3.SS0.SSS0.Px2.p1.5.2">MSHC</em> and <em class="ltx_emph ltx_font_italic" id="S3.SS0.SSS0.Px2.p1.5.3">Multibiomarker</em> datasets are detailed in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#S3.F3" title="Figure 3 ‣ Layer segmentation task ‣ 3 Experiments and Results ‣ Comparative Analysis of Data Augmentation for Retinal OCT Biomarker Segmentation"><span class="ltx_text ltx_ref_tag">3</span></a>, with per-layer results in the Supplement (Tables S2-4 and  S5-7). The <math alttext="\Delta" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px2.p1.1.m1.1"><semantics id="S3.SS0.SSS0.Px2.p1.1.m1.1a"><mi id="S3.SS0.SSS0.Px2.p1.1.m1.1.1" mathvariant="normal" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p1.1.m1.1b"><ci id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p1.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px2.p1.1.m1.1d">roman_Δ</annotation></semantics></math>RMSE, representing the signed difference between augmented and baseline results, reveals either an improvement (<math alttext="\Delta" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px2.p1.2.m2.1"><semantics id="S3.SS0.SSS0.Px2.p1.2.m2.1a"><mi id="S3.SS0.SSS0.Px2.p1.2.m2.1.1" mathvariant="normal" xref="S3.SS0.SSS0.Px2.p1.2.m2.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p1.2.m2.1b"><ci id="S3.SS0.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.2.m2.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p1.2.m2.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px2.p1.2.m2.1d">roman_Δ</annotation></semantics></math>RMSE <math alttext="&lt;0" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px2.p1.3.m3.1"><semantics id="S3.SS0.SSS0.Px2.p1.3.m3.1a"><mrow id="S3.SS0.SSS0.Px2.p1.3.m3.1.1" xref="S3.SS0.SSS0.Px2.p1.3.m3.1.1.cmml"><mi id="S3.SS0.SSS0.Px2.p1.3.m3.1.1.2" xref="S3.SS0.SSS0.Px2.p1.3.m3.1.1.2.cmml"></mi><mo id="S3.SS0.SSS0.Px2.p1.3.m3.1.1.1" xref="S3.SS0.SSS0.Px2.p1.3.m3.1.1.1.cmml">&lt;</mo><mn id="S3.SS0.SSS0.Px2.p1.3.m3.1.1.3" xref="S3.SS0.SSS0.Px2.p1.3.m3.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p1.3.m3.1b"><apply id="S3.SS0.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.3.m3.1.1"><lt id="S3.SS0.SSS0.Px2.p1.3.m3.1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.3.m3.1.1.1"></lt><csymbol cd="latexml" id="S3.SS0.SSS0.Px2.p1.3.m3.1.1.2.cmml" xref="S3.SS0.SSS0.Px2.p1.3.m3.1.1.2">absent</csymbol><cn id="S3.SS0.SSS0.Px2.p1.3.m3.1.1.3.cmml" type="integer" xref="S3.SS0.SSS0.Px2.p1.3.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p1.3.m3.1c">&lt;0</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px2.p1.3.m3.1d">&lt; 0</annotation></semantics></math>) or a deterioration (<math alttext="\Delta" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px2.p1.4.m4.1"><semantics id="S3.SS0.SSS0.Px2.p1.4.m4.1a"><mi id="S3.SS0.SSS0.Px2.p1.4.m4.1.1" mathvariant="normal" xref="S3.SS0.SSS0.Px2.p1.4.m4.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p1.4.m4.1b"><ci id="S3.SS0.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.4.m4.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p1.4.m4.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px2.p1.4.m4.1d">roman_Δ</annotation></semantics></math>RMSE <math alttext="&gt;0" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px2.p1.5.m5.1"><semantics id="S3.SS0.SSS0.Px2.p1.5.m5.1a"><mrow id="S3.SS0.SSS0.Px2.p1.5.m5.1.1" xref="S3.SS0.SSS0.Px2.p1.5.m5.1.1.cmml"><mi id="S3.SS0.SSS0.Px2.p1.5.m5.1.1.2" xref="S3.SS0.SSS0.Px2.p1.5.m5.1.1.2.cmml"></mi><mo id="S3.SS0.SSS0.Px2.p1.5.m5.1.1.1" xref="S3.SS0.SSS0.Px2.p1.5.m5.1.1.1.cmml">&gt;</mo><mn id="S3.SS0.SSS0.Px2.p1.5.m5.1.1.3" xref="S3.SS0.SSS0.Px2.p1.5.m5.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p1.5.m5.1b"><apply id="S3.SS0.SSS0.Px2.p1.5.m5.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.5.m5.1.1"><gt id="S3.SS0.SSS0.Px2.p1.5.m5.1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.5.m5.1.1.1"></gt><csymbol cd="latexml" id="S3.SS0.SSS0.Px2.p1.5.m5.1.1.2.cmml" xref="S3.SS0.SSS0.Px2.p1.5.m5.1.1.2">absent</csymbol><cn id="S3.SS0.SSS0.Px2.p1.5.m5.1.1.3.cmml" type="integer" xref="S3.SS0.SSS0.Px2.p1.5.m5.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p1.5.m5.1c">&gt;0</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px2.p1.5.m5.1d">&gt; 0</annotation></semantics></math>) compared to no augmentation scenarios. The Wilcoxon signed-rank test was used to test statistical significance.</p>
</div>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="498" id="S3.F3.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>RMSE between augmentation types compared to ’No Augmentation’ augmentation.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="S3.SS0.SSS0.Px2.p2.1"><em class="ltx_emph ltx_font_italic" id="S3.SS0.SSS0.Px2.p2.1.1">MSHC</em>, being more standardized and of higher quality, facilitates easier segmentation of retinal layers compared to the diverse <em class="ltx_emph ltx_font_italic" id="S3.SS0.SSS0.Px2.p2.1.2">Multibiomarker</em>, which exhibits structural abnormalities and noise. This difference in dataset characteristics leads to better segmentation performance on <em class="ltx_emph ltx_font_italic" id="S3.SS0.SSS0.Px2.p2.1.3">MSHC</em>. Deformation-based augmentation adversely affects the structurally intact <em class="ltx_emph ltx_font_italic" id="S3.SS0.SSS0.Px2.p2.1.4">MSHC</em> but benefits the diverse <em class="ltx_emph ltx_font_italic" id="S3.SS0.SSS0.Px2.p2.1.5">Multibiomarker</em> dataset.</p>
</div>
<div class="ltx_para" id="S3.SS0.SSS0.Px2.p3">
<p class="ltx_p" id="S3.SS0.SSS0.Px2.p3.1">The impact of data augmentation on the <em class="ltx_emph ltx_font_italic" id="S3.SS0.SSS0.Px2.p3.1.1">MSHC</em> is minimal with a full training set but grows as the dataset size decreases, with Random Affine Transformations becoming particularly vital for smaller samples, a trend also observed in the <em class="ltx_emph ltx_font_italic" id="S3.SS0.SSS0.Px2.p3.1.2">Multibiomarker</em> dataset.</p>
</div>
<div class="ltx_para" id="S3.SS0.SSS0.Px2.p4">
<p class="ltx_p" id="S3.SS0.SSS0.Px2.p4.1">The influence of data augmentation, analyzed based on <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px2.p4.1.1">Symmetry</span>, <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px2.p4.1.2">Contrast</span>, <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px2.p4.1.3">Noise</span>, and <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px2.p4.1.4">Alignment</span>, is detailed in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#S3.F4" title="Figure 4 ‣ Layer segmentation task ‣ 3 Experiments and Results ‣ Comparative Analysis of Data Augmentation for Retinal OCT Biomarker Segmentation"><span class="ltx_text ltx_ref_tag">4</span></a> for <em class="ltx_emph ltx_font_italic" id="S3.SS0.SSS0.Px2.p4.1.5">MSHC</em>, with comprehensive results in the Supplement (Fig. S2).
The <em class="ltx_emph ltx_font_italic" id="S3.SS0.SSS0.Px2.p4.1.6">Transformation</em> and <em class="ltx_emph ltx_font_italic" id="S3.SS0.SSS0.Px2.p4.1.7">Deformation</em>-based augmentations enhances segmentation performance on unsymmetrical and unaligned samples, with a marginal decline observed on symmetric and aligned samples, where Affine Transformations exhibit minimal adverse effects.</p>
</div>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="242" id="S3.F4.g1" src="x4.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span><em class="ltx_emph ltx_font_italic" id="S3.F4.2.1">MSHC</em>-Dataset Full: RMSE distance with respect to OCT Scan metrics.</figcaption>
</figure>
<figure class="ltx_figure" id="S3.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="242" id="S3.F5.g1" src="x5.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span><em class="ltx_emph ltx_font_italic" id="S3.F5.2.1">Multibiomarker</em>: RMSE distance with respect to OCT Scan metrics.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS0.SSS0.Px2.p5">
<p class="ltx_p" id="S3.SS0.SSS0.Px2.p5.1">The analysis of the <em class="ltx_emph ltx_font_italic" id="S3.SS0.SSS0.Px2.p5.1.1">Multibiomarker</em> dataset (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#S3.F5" title="Figure 5 ‣ Layer segmentation task ‣ 3 Experiments and Results ‣ Comparative Analysis of Data Augmentation for Retinal OCT Biomarker Segmentation"><span class="ltx_text ltx_ref_tag">5</span></a>), reveals different outcomes compared to <em class="ltx_emph ltx_font_italic" id="S3.SS0.SSS0.Px2.p5.1.2">MSHC</em>. Here, <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px2.p5.1.3">Deformation</span>-based augmentations not only benefit symmetrical samples but also demonstrate a slight drawback on straight retinal structures, emphasizing their advantage for structural irregularities. In contrast, <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px2.p5.1.4">Noise</span>-related augmentations do not enhance segmentation for noisier scans within this dataset, suggesting a universal detrimental effect due to the already prevalent noise in the scans.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Fluid segmentation task</h4>
<div class="ltx_para" id="S3.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px3.p1.1">In fluid segmentation experiments trained on the <em class="ltx_emph ltx_font_italic" id="S3.SS0.SSS0.Px3.p1.1.1">RETOUCH</em> using Spectralis scans, most augmentation methods enhanced the segmentation performance (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#S3.F6" title="Figure 6 ‣ Fluid segmentation task ‣ 3 Experiments and Results ‣ Comparative Analysis of Data Augmentation for Retinal OCT Biomarker Segmentation"><span class="ltx_text ltx_ref_tag">6</span></a>). The training lasted for 600 epochs and used a batch size of 8, with augmentations applied at a probability of 0.33. A learning rate of 1e-3 was applied, along with a 20-epoch warm-up period and cosine decay. The Adam optimizer, paired with the Dice loss, was used for optimization during training. While outcomes generally improved, specific augmentations like <em class="ltx_emph ltx_font_italic" id="S3.SS0.SSS0.Px3.p1.1.2">Vessel Simulation</em>, despite scoring highest overall, had a unique negative impact on IRF segmentation, underscoring the nuanced effect of different augmentations on segmentation accuracy.</p>
</div>
<figure class="ltx_figure" id="S3.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="232" id="S3.F6.g1" src="x6.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Dice Score difference between augmentation types compared to ’No Augmentation’ for fluid segmentation on Spectralis scans.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS0.SSS0.Px3.p2">
<p class="ltx_p" id="S3.SS0.SSS0.Px3.p2.1">The cross-device generalization capability was investigated by evaluating the models, which were trained on Spectralis, on Topcon and Cirrus scans (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.13351v1#S3.F7" title="Figure 7 ‣ Fluid segmentation task ‣ 3 Experiments and Results ‣ Comparative Analysis of Data Augmentation for Retinal OCT Biomarker Segmentation"><span class="ltx_text ltx_ref_tag">7</span></a>). In particular, noise-related augmentations such as SVD Noise Adaptation were shown to significantly improve these segmentation results. On the other hand, Affine transformations had a negative impact when evaluated on Cirrus and Topcon scans, an effect not seen in the Spectralis results.</p>
</div>
<figure class="ltx_figure" id="S3.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="498" id="S3.F7.g1" src="x7.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Dice Score difference between augmentation types for fluid segmentation cross-device <em class="ltx_emph ltx_font_italic" id="S3.F7.2.1">generalization</em> performance on Topcon- and Cirrus-scans.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Conclusion</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">We comprehensively assessed the effect of data augmentation on retinal biomarker segmentation on OCT scans. The experiments highlight the importance of spatial transformation-based techniques, including affine transformations and elastic deformations on retinal OCT scans. While noise-related augmentations are relatively common in the literature, we found that they can have a strongly detrimental effect on already noisy datasets, while providing benefits only in a few cases. Data augmentation, especially SVD Noise Adaption, has demonstrated its ability to boost generalization across different scanner types. Future research aims to improve the value of augmentation strategies by focusing on adaptive techniques tailored to the dataset characteristics.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Bar-David, D., Bar-David, L., Shoudry, S., Fischer, A.: Impact of data augmentation on retinal oct image segmentation for diabetic macular edema analysis. In: Ophthalmic Medical Image Analysis: 8th International Workshop, OMIA 2021, Held in Conjunction with MICCAI 2021, Strasbourg, France, September 27, 2021, Proceedings 8. pp. 148–158. Springer (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Bogunovic, H., Venhuizen, F., Klimscha, S., Apostolopoulos, S., Bab-Hadiashar, A., Bagci, U., Beg, M.F., Bekalo, L., Chen, Q., Ciller, C., Gopinath, K., Gostar, A.K., Jeon, K., Ji, Z., Kang, S.H., Koozekanani, D.D., Lu, D., Morley, D., Parhi, K.K., Park, H.S., Rashno, A., Sarunic, M., Shaikh, S., Sivaswamy, J., Tennakoon, R., Yadav, S., De Zanet, S., Waldstein, S.M., Gerendas, B.S., Klaver, C., Sánchez, C.I., Schmidt-Erfurth, U.: RETOUCH: The Retinal OCT Fluid Detection and Segmentation Benchmark and Challenge. IEEE Transactions on Medical Imaging <span class="ltx_text ltx_font_bold" id="bib.bib2.1.1">38</span>(8), 1858–1874 (Aug 2019). https://doi.org/10.1109/TMI.2019.2901398

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Buslaev, A., Iglovikov, V.I., Khvedchenya, E., Parinov, A., Druzhinin, M., Kalinin, A.A.: Albumentations: fast and flexible image augmentations. Information <span class="ltx_text ltx_font_bold" id="bib.bib3.1.1">11</span>(2),  125 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Chlap, P., Min, H., Vandenberg, N., Dowling, J., Holloway, L., Haworth, A.: A review of medical image data augmentation techniques for deep learning applications. Journal of Medical Imaging and Radiation Oncology <span class="ltx_text ltx_font_bold" id="bib.bib4.1.1">65</span>(5), 545–563 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
He, Y., Carass, A., Liu, Y., Calabresi, P.A., Saidha, S., Prince, J.L.: Longitudinal deep network for consistent oct layer segmentation. Biomedical Optics Express <span class="ltx_text ltx_font_bold" id="bib.bib5.1.1">14</span>(5), 1874–1893 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
He, Y., Carass, A., Liu, Y., Jedynak, B.M., Solomon, S.D., Saidha, S., Calabresi, P.A., Prince, J.L.: Fully convolutional boundary regression for retina oct segmentation. In: Medical Image Computing and Computer Assisted Intervention–MICCAI 2019: 22nd International Conference, Shenzhen, China, October 13–17, 2019, Proceedings, Part I 22. pp. 120–128. Springer (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
He, Y., Carass, A., Liu, Y., Jedynak, B.M., Solomon, S.D., Saidha, S., Calabresi, P.A., Prince, J.L.: Structured layer surface segmentation for retina oct using fully convolutional regression networks. Medical image analysis <span class="ltx_text ltx_font_bold" id="bib.bib7.1.1">68</span>, 101856 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Johnson, D.H.: Signal-to-noise ratio. Scholarpedia <span class="ltx_text ltx_font_bold" id="bib.bib8.1.1">1</span>(12),  2088 (2006)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Kepp, T., Ehrhardt, J., Heinrich, M.P., Hüttmann, G., Handels, H.: Topology-preserving shape-based regression of retinal layers in oct image data using convolutional neural networks. In: 2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019). pp. 1437–1440. IEEE (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Koch, V., Holmberg, O., Spitzer, H., Schiefelbein, J., Asani, B., Hafner, M., Theis, F.J.: Noise transfer for unsupervised domain adaptation of retinal oct images. In: International Conference on Medical Image Computing and Computer-Assisted Intervention. pp. 699–708. Springer (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Konidaris, F., Tagaris, T., Sdraka, M., Stafylopatis, A.: Generative adversarial networks as an advanced data augmentation technique for mri data. In: VISIGRAPP (5: VISAPP). pp. 48–59 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Lazaridis, G., Xu, M., Afgeh, S.S., Montesano, G., Garway-Heath, D.: Bio-inspired attentive segmentation of retinal oct imaging. In: Ophthalmic Medical Image Analysis: 7th International Workshop, OMIA 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 8, 2020, Proceedings 7. pp. 1–10. Springer (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Li, D., Wu, J., He, Y., Yao, X., Yuan, W., Chen, D., Park, H.C., Yu, S., Prince, J.L., Li, X.: Parallel deep neural networks for endoscopic oct image segmentation. Biomedical optics express <span class="ltx_text ltx_font_bold" id="bib.bib13.1.1">10</span>(3), 1126–1135 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Li, Q., Li, S., He, Z., Guan, H., Chen, R., Xu, Y., Wang, T., Qi, S., Mei, J., Wang, W.: Deepretina: layer segmentation of retina in oct images using deep learning. Translational vision science &amp; technology <span class="ltx_text ltx_font_bold" id="bib.bib14.1.1">9</span>(2), 61–61 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Ouyang, J., Mathai, T.S., Lathrop, K., Galeotti, J.: Accurate tissue interface segmentation via adversarial pre-segmentation of anterior segment oct images. Biomedical Optics Express <span class="ltx_text ltx_font_bold" id="bib.bib15.1.1">10</span>(10), 5291–5324 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Pekala, M., Joshi, N., Liu, T.A., Bressler, N.M., DeBuc, D.C., Burlina, P.: Deep learning based retinal oct segmentation. Computers in biology and medicine <span class="ltx_text ltx_font_bold" id="bib.bib16.1.1">114</span>, 103445 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Rebuffi, S.A., Gowal, S., Calian, D.A., Stimberg, F., Wiles, O., Mann, T.A.: Data augmentation can improve robustness. Advances in Neural Information Processing Systems <span class="ltx_text ltx_font_bold" id="bib.bib17.1.1">34</span>, 29935–29948 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Ruan, Y., Xue, J., Li, T., Liu, D., Lu, H., Chen, M., Liu, T., Niu, S., Li, D.: Multi-phase level set algorithm based on fully convolutional networks (fcn-mls) for retinal layer segmentation in sd-oct images with central serous chorioretinopathy (csc). Biomedical optics express <span class="ltx_text ltx_font_bold" id="bib.bib18.1.1">10</span>(8), 3987–4002 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Shorten, C., Khoshgoftaar, T.M.: A survey on image data augmentation for deep learning. Journal of big data <span class="ltx_text ltx_font_bold" id="bib.bib19.1.1">6</span>(1), 1–48 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Stromer, D., Moult, E.M., Chen, S., Waheed, N.K., Maier, A., Fujimoto, J.G.: Correction propagation for user-assisted optical coherence tomography segmentation: general framework and application to bruch’s membrane segmentation. Biomedical Optics Express <span class="ltx_text ltx_font_bold" id="bib.bib20.1.1">11</span>(5), 2830–2848 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Xie, H., Xu, W., Wang, Y.X., Wu, X.: Deep learning network with differentiable dynamic programming for retina oct surface segmentation. Biomedical Optics Express <span class="ltx_text ltx_font_bold" id="bib.bib21.1.1">14</span>(7), 3190–3202 (2023)

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Fri Sep 20 09:23:35 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
